\documentclass{article}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{macros}
\usepackage{fullpage}
\usepackage{stmaryrd}
\usepackage{xspace}
\usepackage{macros}
\usepackage{algorithmic}
\usepackage{algorithm}

\newcommand{\temporaryremove}[1]{}
\def \BISI{\sim}
\def \CL{{\cal L}}
\newcommand\Real {{\mathbb R}}
\def \BP{\textbf{P}}
\def \CN{{\cal N}}
\def \IN{\it in}
\def \OUT{\it out}
\def \Var{{\it Var}}
\def \fv{{\it fv}}
\def \SI{\prec}
\def \Pow#1{\mathcal P(#1)}
\newcommand{\Env}{{\sf Env}}
\def \CE{{\cal E}}
\newcommand{\boxm}[1]{[#1]}
\def \CM{{\cal M}}
\def\squareforqed{\hbox{\rlap{}}}
\def\qed{\ifmmode\squareforqed\else{\unskip\nobreak\hfil
\penalty50\hskip1em\null\nobreak\hfil\squareforqed
\parfillskip=0pt\finalhyphendemerits=0\endgraf}\fi}

\begin{document}
\title{Logical, Metric, and Algorithmic\\ Characterisations of Probabilistic Bisimulation}
\author{
Yuxin Deng \qquad Wenjie Du\\
 Shanghai Jiao Tong University, China\\
 Shanghai Normal University, China}
\maketitle

\begin{abstract}
Many behavioural equivalences or preorders for probabilistic
processes involve a lifting operation that turns a relation on
states into a relation on distributions of states. We show that
several existing proposals for lifting relations can be reconciled
to be different presentations of essentially the same lifting
operation. More interestingly, this lifting operation nicely
corresponds to the Kantorovich metric, a fundamental concept used in
mathematics to lift a metric on states to a metric on distributions
of states, besides the fact the lifting operation is related to the
maximum flow problem in optimisation theory.

The lifting operation yields a neat notion of probabilistic
bisimulation, for which we provide logical, metric, and algorithmic
characterisations. Specifically, we extend the Hennessy-Milner logic
and the modal mu-calculus with a new modality, resulting in an
adequate and an expressive logic for probabilistic bisimilarity,
respectively. The correspondence of the lifting operation and the
Kantorovich metric leads to a natural characterisation of
bisimulations as pseudometrics which are post-fixed points of a
monotone function. We also present an ``on the fly" algorithm to
check if two states in a finitary system are related by
probabilistic bisimilarity, exploiting the close relationship
between the lifting operation and the maximum flow problem.
\end{abstract}

\section{Introduction}
In the last three decades a wealth of behavioural equivalences have
been proposed in concurrency theory. Among them, \emph{bisimilarity}
\cite{Mil89a,Par81} is probably the most studied one as it admits a
suitable semantics, an elegant co-inductive proof technique, as well
as efficient decision algorithms.

In recent years, probabilistic constructs have been proven useful
for giving quantitative specifications of system behaviour. The
first papers on probabilistic concurrency theory
\cite{GJS90,Chr90,larsenskou} proceed by \emph{replacing}
nondeterministic with probabilistic constructs. The reconciliation
of nondeterministic and probabilistic constructs starts with
\cite{HJ90} and has received a lot of attention in the literature
\cite{WL92,SL94,Lowe95,Seg95,HK97,MM97,BS01,JW02,mislove03,CIN05,TKP05,MM07,
DGHMZ07,DGMZ07,DGHM08,DGHM09}.

We shall also work in a framework that features the co-existence of
probability and nondeterminism. More specifically, we deal with
\emph{probabilistic labelled transition systems (pLTSs)}
\cite{DGHMZ07} which are an extension of the usual labelled
transition systems (LTSs) so that a step of transition is in the
form , meaning that state  can perform action 
and evolve into a distribution  over some successor states.
In this setting state  is related to state  by a relation
, say probabilistic simulation, written , if for
each transition  from  there exists a transition
 from  such that  can somehow simulate the
behaviour of  according to . To formalise the
mimicking of  by , we have to \emph{lift}  to
be a relation  between distributions over states and
require .

Various approaches of lifting relations have appeared in the
literature; see e.g. \cite{LS91,SL94,DGHMZ07,DD07,DGHM09}. We will
show that although those approaches appear different, they can be
reconciled. Essentially, there is only one lifting operation, which
has been presented in different forms. Moreover, we argue that the
lifting operation is interesting itself. This is justified by its
intrinsic connection with some fundamental concepts in mathematics,
notably \emph{the Kantorovich metric} \cite{Kan42}. For example, it
turns out that our lifting of binary relations from states to
distributions nicely corresponds to the lifting of metrics from
states to distributions by using the Kantorovich metric. In
addition, the lifting operation is closely related to \emph{the
maximum flow problem} in optimisation theory, as observed by Baier
et al. \cite{BEM00}.

A good scientific concept is often elegant, even seen from many
different perspectives. Bisimulation is one of such concepts in the
traditional concurrency theory, as it can be characterised in a
great many ways such as fixed point theory, modal logics, game
theory, coalgebras etc. We believe that probabilistic bisimulation
is also one of such concepts in probabilistic concurrency theory. As
an evidence, we will provide in this paper three characterisations,
from the perspectives of modal logics, metrics, and decision
algorithms.
\begin{enumerate}
\item Our logical characterisation of probabilistic bisimulation
consists of two aspects: \emph{adequacy} and \emph{expressivity}
\cite{Pnu85}. A logic  is adequate when two states are
 bisimilar if and only if they satisfy exactly the same
set of formulae in . The logic is expressive when each state
 has a characteristic formula  in  such that  is
bisimilar to  if and only if  satisfies . We will
introduce a probabilistic choice modality  to capture the behaviour
of distributions. Intuitively, distribution  satisfies the
formula  if there is a
decomposition of  into a convex combination some
distributions, , and each
 confirms to the property specified by . When the
new modality is added to the Hennessy-Milner logic \cite{HM85} we
obtain an adequate logic for probabilistic bisimilarity; when it is
added to the modal mu-calculus \cite{Koz83} we obtain an expressive
logic.

\item By metric characterisation of probabilistic bisimulation, we
mean to give a pseudometric such that two states are bisimilar if
and only if their distance is  when measured by the pseudometric.
More specifically, we show that bisimulations correspond to
pseudometrics which are post-fixed points of a monotone function,
and in particular bisimilarity corresponds to a pseudometric which
is the greatest fixed point of the monotone function.

\item As to the algorithmic characterisation, we propose an ``on the
fly" algorithm that checks if two states are related by
probabilistic bisimilarity. The schema of the algorithm is to
approximate probabilistic bisimilarity by iteratively accumulating
information about state pairs  where  and  are not
bisimilar. In each iteration we dynamically constructs a relation
 as an approximant. Then we verify if every transition from
one state can be matched up by a transition from the other state,
and their resulting distributions are related by the lifted relation
, which involves solving the maximum flow problem of
an appropriately constructed network, by taking advantage of the
close relation between our lifting operation and the above mentioned
maximum flow problem.
\end{enumerate}

\paragraph{Related work}
Probabilistic bisimulation was first introduced by Larsen and Skou
\cite{LS91}. Later on, it was investigated in a great many
probabilistic models.
An adequate logic for probabilistic bisimulation in a setting similar to our pLTSs has
been studied in \cite{JWL01,PS07}. It is also based on an probabilistic
extension of the Hennessy-Milner logic. The main difference from our
logic in Section~\ref{s:adequate} is the introduction of the
operator . Intuitively, a distribution 
satisfies the formula  when the set of states satisfying
 is measured by  with probability at least . So the
formula  can be expressed by our logic in terms of the
probabilistic choice  by setting
, , , , and .
When restricted to
deterministic pLTSs (i.e., for each state and for each action, there
exists at most one outgoing transition from the state),
probabilistic bisimulations can be characterised by simpler forms of
logics, as observed in \cite{LS91,DEP98,PS07}.

An expressive logic for nonprobabilistic bisimulation has been proposed in \cite{SI94}.
 In this paper we partially extend the results of
\cite{SI94} to a probabilistic setting that admits both
probabilistic and nondeterministic choice. We present a
probabilistic extension of the modal mu-calculus \cite{Koz83}, where
a formula is interpreted as the set of states satisfying it. This is
in contrast to the probabilistic semantics of the mu-calculus as
studied in
 \cite{HK97,MM97,MM07} where formulae denote lower bounds of
probabilistic evidence of properties, and the semantics of the
generalised probabilistic logic of \cite{CIN05} where a mu-calculus
formula is interpreted as a set of deterministic trees that satisfy
it.

The Kantorovich metric has been used by van Breugel \emph{et al.}
for defining behavioural pseudometrics on fully probabilistic
systems \cite{BW01,BW06,BSW07} and reactive probabilistic systems
\cite{BW01b,BW05,BHMW05,BHMW07}; and by Desharnais {\em et al.} for
labelled Markov chains \cite{DGJP99,DGJP04} and labelled concurrent
Markov chains \cite{DGJP02}; and later on by Ferns \emph{et al.} for
Markov decision processes \cite{FPP04,FPP05}; and by Deng \emph{et
al.} for action-labelled quantitative transition systems
\cite{DCPP05}.  One exception is \cite{DLT08}, which proposes a
pseudometric for labelled Markov chains without using the Kantorovich
metric.  Instead, it is based on a notition of -bisimulation, which
relaxes the definition of probabilistic bisimulation by allowing small
perturbation of probabilities.
In this paper we are mainly interested in the
correspondence of our lifting operation to the Kantorovich metric.
The metric characterisation of probabilistic bisimulation in
Section~\ref{s:metric} is merely a direct consequence of this
correspondence.

Decision algorithms for probabilistic bisimilarity and similarity
have been considered by Baier et al. in \cite{BEM00} and Zhang et
al. in \cite{ZHEJ08}. Their algorithms are global in the sense that
a whole state space has to be fully generated in advance. In
contrast, ``on the fly" algorithms are local in the sense that the
state space is dynamically generated which is often more efficient
to determine that one state fails to be related to another. Our
algorithm in Section~\ref{s:algo} is inspired by \cite{BEM00}
because we also reduce the problem of checking if two distributions
are related by a lifted relation to the maximum flow problem of a
suitable network. We generalise the local algorithm of checking
nonprobabilistic bisimilarity \cite{FM90,Lin98} to the probabilistic
setting.

This paper provides a relatively comprehensive account of
probabilistic bisimulation. Some of the results or their variants were mentioned previously 
in \cite{DCPP05,DD09,DD09b,DG10}. Here they are presented in a uniform
way and equipped with detailed proofs.


\paragraph{Outline of the paper} The paper proceeds by recalling a
way of lifting binary relations from states to distributions, and
showing its coincidence with a few other ways in
Section~\ref{s:lift}. The lifting operation is justified in
Section~\ref{s:justify} in terms of its correspondence to the
Kantorovich metric and the maximum flow problem. In
Section~\ref{s:pbisi} we define probabilistic bisimulation and show
its infinite approximation. In Section~\ref{s:logic} we introduce a
probabilistic choice modality, then extend the Hennessy-Milner logic
and the modal mu-calculus so to obtain two logics that are adequate
and expressive, respectively. In Section~\ref{s:metric} we
characterise probabilistic bisimulations as pseudometrics. In
Section~\ref{s:algo} we exploit the correspondence of our lifting
operation to the maximum flow problem, and present a polynomial time
decision algorithm. Finally, Section~\ref{s:conclude} concludes the
paper.


\section{Lifting relations}\label{s:lift}
In the probabilistic setting, formal systems are usually modelled as
distributions over states. To compare two systems involves the
comparison of two distributions. So we need a way of lifting
relations on states to relations on distributions. This is used, for
example, to define probabilistic bisimulation as we shall see in
Section~\ref{s:pbisi}. A few approaches of lifting relations have
appeared in the literature. We will take the one from \cite{DGHM09},
and show its coincidence with two other approaches.

We first fix some notation. A (discrete) probability
distribution\index{probability distribution} over a set  is a
mapping \mbox{} with . The \emph{support}\index{support} of  is
given by . In
this paper we only consider finite state systems, so it suffices to
use distributions with finite support; let , ranged over
by , denote the collection of all such distributions
over .  We use  to denote the point distribution,
satisfying  if , and  otherwise. If  and  is a distribution for each  in some finite
index set , then  is  given by

If  then this is easily seen to be a
distribution in .
Finally, the
\emph{product}\index{product} of two probability distributions
 over  is the distribution 
over  defined by
.


\begin{definition}\label{d:lifting}
Given two sets  and  and a relation . Then  is the smallest relation that
satisfies:
\begin{enumerate}
\item
 implies 

\item
 implies ,
where  is a finite index set and  .
\end{enumerate}
\end{definition}

The lifting construction satisfies the following  useful property
whose proof is straightforward thus omitted.
\begin{proposition}\rm\label{prop:lifting}
Suppose  and
 . If  then
  for some set of
distributions  such that .
\hfill\qed
\end{proposition}

We now look at alternative presentations of
Definition~\ref{d:lifting}. The proposition below is immediate.
\begin{proposition}\label{p:lifting}
Let  and  be distributions over  and ,
  respectively, and . Then
 if and only if  can be
decomposed as follows:
\begin{enumerate}
\item
, where
   is a finite index set and  

\item
For each  there is a state  such that 

\item
. \hfill\qed
\end{enumerate}
\end{proposition}

An important point here is that in the decomposition of 
into , the states  are
\emph{not necessarily distinct}: that is, the decomposition is not
in general unique. Thus when establishing the relationship between
 and , a given state  in  may play a
number of different roles.

From Definition~\ref{d:lifting}, the next two properties follows. In
fact, they are sometimes used in the literature as definitions of
lifting relations instead of being properties (see e.g.
\cite{SL94,LS91}).
\begin{theorem}\label{t:lifting.alternative}
\begin{enumerate}
\item Let  and  be distributions over  and ,
  respectively. Then
   if and only if there
  exists a weight function  such that
  \begin{enumerate}
  \item 
  \item 
  \item .
  \end{enumerate}
\item Let  be distributions over   and
  is an equivalence relation. Then
 if and only if 
for all equivalence class , where 
stands for the accumulation probability .
\end{enumerate}
\end{theorem}
\begin{proof}
\begin{enumerate}
\item
() Suppose . By
Proposition~\ref{p:lifting}, we can decompose  and 
such that ,
, and  for
all . We define the weight function  by letting
 for any . This weight function can be checked to meet our
requirements.
\begin{enumerate}
\item For any , it holds that

\item Similarly, we have .
\item For any , if  then there is some  such that , , and . It follows from
 that .
\end{enumerate}

() Suppose there is a weight function  satisfying the
three conditions in the hypothesis. We construct the index set
 and probabilities
 for each .
\begin{enumerate}
\item It holds that 
because, for any ,

\item Similarly, we have .
\item For each , we have , which implies .
\end{enumerate}
Hence, the above decompositions of  and  meet the
requirement of the lifting .

\item
() Suppose . By
Proposition~\ref{p:lifting}, we can decompose  and 
such that ,
, and  for
all . For any equivalence class , we have
that

where the equality in the third line is justified by the fact that
 iff  since  and .

() Suppose, for each equivalence class , it holds that . We construct the index set
 and
probabilities
 for each
, where  stands for the equivalence class
that contains .
\begin{enumerate}
\item It holds that 
because, for any ,

\item Similarly, we have .
\item For each , we have .
\end{enumerate}
Hence, the above decompositions of  and  meet the
requirement of the lifting .
\end{enumerate}
\end{proof}




\section{Justifying the lifting operation}\label{s:justify}
In our opinion, the lifting operation given in
Definition~\ref{d:lifting} is not only concise but also on the right
track. This is justified by its intrinsic connection with some
fundamental concepts in mathematics, notably the Kantorovich metric.
\subsection{Justification by the Kantorovich metric}\label{s:kan}

We begin with some historical notes. The \emph{transportation
problem} has been playing an important role in linear programming
due to its general formulation and methods of
solution. The original transportation problem, formulated by the French mathematician G. Monge in 1781 \cite{Mon1781}, consists of finding an optimal way of shovelling a pile of sand into
a hole of the same volume. In the 1940s, the Russian mathematician and economist L.V.
Kantorovich, who was awarded a Nobel prize in economics in 1975 for
the theory of optimal allocation of resources, gave a relaxed
formulation of the problem and proposed a variational principle for
solving the problem \cite{Kan42}. Unfortunately, Kantorovich's work
went unrecognized during a long period of time. The later known
\emph{Kantorovich metric} has appeared in the literature under
different names, because it has been rediscovered historically
several times from different perspectives. Many metrics known in
measure theory, ergodic theory, functional analysis, statistics,
etc. are special cases of the general definition of the Kantorovich
metric \cite{Ver06}. The elegance of the formulation, the
fundamental character of the optimality criterion, as well as the
wealth of applications, which keep arising, place the Kantorovich
metric in a prominent position among the mathematical works of the
20th century. In addition, this formulation can be computed in
polynomial time \cite{Orl88}, which is an appealing feature for its
use in solving applied problems. For example, it is widely used to
solve a variety of problems in business and economy such as market
distribution, plant location, scheduling problems etc. In recent
years the metric attracted the attention of computer scientists
\cite{DD09}: it has been used in various different areas in computer
science such as probabilistic concurrency, image retrieval, data
mining, bioinformatics, etc.

Roughly speaking,  the Kantorovich metric provides a way of
measuring the distance between two distributions. Of course, this
requires first a notion of distance between the basic elements that
are aggregated into the distributions, which is often referred to as
the \emph{ground distance}. In other words, the Kantorovich metric
defines a ``lifted" distance between two distributions of mass in a
space that is itself endowed with a ground distance. There are a
host of metrics available in the literature (see e.g. \cite{GS02})
to quantify the distance between probability measures; see
\cite{Rac91} for a comprehensive review of metrics in the space of
probability measures. The Kantorovich metric has an elegant
formulation and a natural interpretation in terms of the
transportation problem.

We now recall the mathematical definition of the Kantorovich metric.
Let  be a separable metric space. (This condition will be
used by Theorem~\ref{t:KRduality} below.)
\begin{definition}\label{d:K} Given any two Borel probability measures  and  on , the \emph{Kantorovich distance} between
 and  is defined by

where  is the \emph{Lipschitz semi-norm} defined by
 for a function
 with  being the set of all real
numbers.
\end{definition}

The Kantorovich metric has an alternative characterisation. We
denote by  the set of all Borel probability measures on 
such that for all , if  then . We write  for the set of
all Borel probability measures on the product space  with
marginal measures  and , i.e. if  then  and
 hold.
\begin{definition}\label{d:L}
For , we define the metric  as follows:

\end{definition}


\begin{lemma}
If  is a separable metric space then  and  are metrics
on . \hfill\qed
\end{lemma}

The famous Kantorovich-Rubinstein duality theorem gives a dual
representation of  in terms of  .
\begin{theorem}
[Kantorovich-Rubinstein \cite{KR58}]\label{t:KRduality} If 
is a separable metric space then for any two distributions
 we have
. \hfill\qed
\end{theorem}

In view of the above theorem, many papers in the literature directly
take Definition~\ref{d:L} as the definition of the Kantorovich
metric. Here we keep the original definition, but it is helpful to
understand  by using . Intuitively, a probability measure
 can be understood as a
\emph{transportation} from one unit mass distribution  to
another unit mass distribution . If the distance 
represents the cost of moving one unit of mass from location  to
location  then the Kantorovich distance gives the optimal total
cost of transporting the mass of  to . We refer the
reader to \cite{Vil03} for an excellent exposition on the
Kantorovich metric and the duality theorem.

Many problems in computer science only involve finite state spaces,
so discrete distributions with finite supports are sometimes more
interesting than continuous distributions. For two discrete
distributions  and  with finite supports
 and , respectively, minimizing
the total cost of a discretised version of the transportation
problem reduces to the following linear programming problem:


Since (\ref{e:lpr}) is a special case of the discrete mass
transportation problem, some well-known polynomial time algorithm
like \cite{Orl88} can be employed to solve it, which is an
attractive feature for computer scientists.

\bigskip
Recall that a pseudometric
  is a function that yields a non-negative real number for each pair
  of elements and satisfies the following: ,
  , and , for any . We say a
  pseudometric  is -bounded if  for any  and
  .
Let  and  be distributions over a finite set  of
states. In \cite{BW01} a -bounded pseudometric  on  is
lifted to be a -bounded pseudometric  on  by
setting the distance  to be the value of the
following linear programming problem:

This problem can be dualised and then simplified to yield the
following problem:

Now (\ref{e:pc1}) is in exactly the same form as (\ref{e:lpr}).

This way of lifting pseudometrics via the Kantorovich metric as
given in (\ref{e:pc1}) has an interesting connection with the
lifting of binary relations given in Definition~\ref{d:lifting}.

\begin{theorem}\label{t:metric.relation}
Let  be a binary relation and  a pseudometric on a state space
 satisfying  for any .
Then it holds that  for any distributions
.
\end{theorem}
\begin{proof}
Suppose . From
Theorem~\ref{t:lifting.alternative}(1) we know there is a weight
function  such that
  \begin{enumerate}
  \item 
  \item 
  \item .
  \end{enumerate}
By substituting  for  in (\ref{e:pc1}), the three
constraints there can be satisfied. For any  we
distinguish two cases:
\begin{enumerate}
\item either 
\item or . In this case we have , which implies
 by (\ref{e:hy}).
\end{enumerate}
Therefore, we always have  for any .
Consequently,  and the optimal value
of the problem in (\ref{e:pc1}) must be , i.e.
, and the optimal solution is determined
by .

The above reasoning can be reversed to show that the optimal
solution of (\ref{e:pc1}) determines a weight function, thus
 implies .
\end{proof}

The above property will be used in Section~\ref{s:metric} to give a
metric characterisation of probabilistic bisimulation (cf.
Theorem~\ref{t:bm}).

\subsection{Justification by network flow}
The lifting operation discussed in Section~\ref{s:lift} is also
related to the maximum flow problem in optimisation theory. This was
already observed by Baier et al. in \cite{BEM00}.

 We briefly recall the basic definitions of
networks. More details can be found in e.g. \cite{Eve79}. A
\emph{network} is a tuple  where  is a
finite directed graph (i.e.  is a set of nodes and  is a set of edges) with two special nodes  (the
\emph{source}) and  (the \emph{sink}) and a \emph{capability}
, i.e. a function that assigns to each edge  a
non-negative number . A \emph{flow function}  for 
is a function that assigns to edge  a real number  such
that
\begin{itemize}
\item  for all edges .
\item Let  be the set of incoming edges to node  and
   the set of outgoing edges from node . Then, for each
  node ,
  
\end{itemize}
The \emph{flow}  of  is given by

The \emph{maximum flow} in  is the supremum (maximum) over the
flows , where  is a flow function in .

 We will see that
the question whether  can be reduced to a
maximum flow problem in a suitably chosen network. Suppose
 and . Let
 where  are pairwise distinct new states, i.e.  for
all . We create two states  and  not contained
in  with . We associate with the pair

 the following network . \begin{itemize}
\item The nodes are .
\item The edges are .
\item The capability  is defined by ,
   and  for all .
\end{itemize}

\temporaryremove{ \begin{figure}
\psset{unit=0.8cm}
\begin{center}
\rput(-5.5,-1){\rnode{source}{\qdisk(0,0){2pt}}}
\rput(5.5,-1){\rnode{sink}{\qdisk(0,0){2pt}}}
\uput[l](-5.5,-1){} \uput[r](5.5,-1){}
\rput(-2.5,1){\rnode{s1}{\qdisk(0,0){2pt}}} \uput[l](-2.5,1){}
\rput(-2.5,-0.5){\rnode{s2}{\qdisk(0,0){2pt}}}
\uput[l](-2.5,-0.25){} \rput(-2.5,-2){}
\rput(-2.5,-3.5){\rnode{sn}{\qdisk(0,0){2pt}}}
\uput[l](-2.5,-3.5){}
\rput(2.5,1){\rnode{t1}{\qdisk(0,0){2pt}}} \uput[r](2.5,1){}
\rput(2.5,-0.5){\rnode{t2}{\qdisk(0,0){2pt}}}
\uput[r](2.5,-0.25){} \rput(2.5,-2){}
\uput[r](2.5,-3.5){}
\rput(2.5,-3.5){\rnode{tn}{\qdisk(0,0){2pt}}}
\ncline[nodesep=2mm]{->}{s1}{t1}\aput{:U}{}
\ncline[nodesep=2mm]{->}{s1}{t2}\aput{:U}{}
\ncline[nodesep=2mm]{->}{s1}{tn}\aput{:U}{}
\ncline[nodesep=2mm]{->}{s2}{t2}\aput{:U}{}
\ncline[nodesep=2mm]{->}{s2}{tn}\bput{:U}{}
\ncline[nodesep=2mm]{->}{sn}{tn}\bput{:U}{}
\ncline[nodesep=2mm]{->}{source}{s1}\aput{:U}{}
\ncline[nodesep=2mm]{->}{source}{s2}\bput{:U}{}
\ncline[nodesep=2mm]{->}{source}{sn}\bput{:U}{}
\ncline[nodesep=2mm]{->}{t1}{sink}\aput{:U}{}
\ncline[nodesep=2mm]{->}{t2}{sink}\bput{:U}{}
\ncline[nodesep=2mm]{->}{tn}{sink}\bput{:U}{}
\uput[d](0,-4.5){ for all }
\end{center}\vskip 4cm
\caption{The network }\label{f:network}
\end{figure}
}
The next lemma appeared as Lemma 5.1 in \cite{BEM00}.
\begin{lemma}\label{l:lift.flow}
Let  be a finite set,  and
. The following statements are equivalent.
\begin{enumerate}
\item There exists a weight function  for  with
  respect to .
\item The maximum flow in  is .
\hfill\qed
\end{enumerate}
\end{lemma}

Since the lifting operation given in Definition~\ref{d:lifting} can
also be stated in terms of weight functions, we obtain the following
characterisation using network flow.
\begin{theorem}\label{t:lift.flow}
Let  be a finite set,  and
. Then  if and
only if the maximum flow in
   is .
\end{theorem}
\begin{proof}
Combining Theorem~\ref{t:lifting.alternative}(1) and
Lemma~\ref{l:lift.flow}.
\end{proof}

The above property will play an important role in
Section~\ref{s:algo} to give an ``on the fly" algorithm for checking
probabilistic bisimilarity.

\section{Probabilistic bisimulation}\label{s:pbisi}
With a solid base of the lifting operation, we can proceed to define
a probabilistic version of bisimulation. We start with a
probabilistic generalisation of labelled transition systems (LTSs).
\begin{definition}
A \emph{probabilistic labelled transition
system}\index{probabilistic labelled transition system}
(pLTS)\footnote{Essentially the same model has appeared in the
literature under different names such as \emph{NP-systems}
\cite{JHW94}, \emph{probabilistic processes} \cite{JW95},
\emph{simple probabilistic automata} \cite{Seg95},
\emph{probabilistic transition systems} \cite{JW02} etc.
Furthermore, there are strong structural similarities with
\emph{Markov
  Decision Processes} \cite{Put94,DGMZ07}.} is a triple\\
, where
\begin{enumerate}
\item  is a set of states;
\item  is a set of actions;
\item  is the transition relation.
\end{enumerate}
As with LTSs, we usually write  in place of
.
A pLTS is \emph{finitely branching} if for each state  the
set  is finite; if moreover  is
finite, then the pLTS is \emph{finitary}.
\end{definition}

In a pLTS, one step of transition leaves a single state but might
end up in a set of states; each of them can be reached with certain
probability. An LTS may be viewed as a degenerate pLTS, one in which
only point distributions are used.

Let  and  are two states in a pLTS, we say  can simulate
the behaviour of  if the latter can exhibit action  and lead
to distribution  then the former can also perform  and
lead to a distribution, say , which can mimic  in
successor states. We are interested in a relation between two
states, but it is expressed by invoking a relation between two
distributions. To formalise the mimicking of one distribution by the
other, we make use of the lifting operation investigated in
Section~\ref{s:lift}.

\begin{definition}\label{d:sbisi2}
A relation  is a {\em probabilistic
  simulation} if  implies
\begin{itemize}
\item if  then there exists some  such that
   and .
\end{itemize}
If both  and  are probabilistic simulations, then
 is a {\em
  probabilistic bisimulation}. The largest probabilistic
  bisimulation, denoted by , is called \emph{probabilistic
  bisimilarity}.
\end{definition}



As in the nonprobabilistic setting, probabilistic bisimilarity can
be approximated by a family of inductively defined relations.
\begin{definition}
Let  be the state set of a pLTS. We define:
\begin{itemize}
\item 
\item , for , if
\begin{enumerate}
\item whenever , there exists some  such
that  and ;
\item whenever , there exists some  such
that  and .
\end{enumerate}
\item 
\end{itemize}
\end{definition}
In general,  is a strictly finer relation than
. However, the two relations coincide when limited to
finitely branching pLTSs.
\begin{proposition}\label{p:app}
On finitely branching pLTSs,  coincides with .
\end{proposition}
\begin{proof}
It is trivial to show by induction that  implies  for all , thus .

Now we show that  is a bisimulation. Suppose
 and . We have to show that there is
some  with  and . Consider the set

For each , we have , which means that there is some  with
. Since  is finitely
branching,  is a finite set. Let . It holds that  for all
, since by a straightforward induction on  we can
show that  implies  for all  with
. By the assumption  we know that
. It follows that there is some  with
 and , so  and hence . By symmetry we also
have that if  then there is some  with
 and .
\end{proof}
Proposition~\ref{p:app} has appeared in \cite{Bai98}; here we have
given a simpler proof.

\section{Logical characterisation}\label{s:logic}
Let  be a logic. We use the notation  to stand for the
set of formulae that state  satisfies. This induces an
equivalence relation on states:  iff .
Thus, two states are equivalent when they satisfy exactly the same
set of formulae.

In this section we consider two kinds of logical characterisations
of probabilistic bisimilarity.
\begin{definition}
[Adequacy and expressivity]
\begin{enumerate}
\item  is \emph{adequate} w.r.t.  if
for any states  and ,


\item  is \emph{expressive} w.r.t.  if for
each state  there exists a \emph{characteristic formula}
 such that, for any states  and ,

\end{enumerate}
\end{definition}
We will propose a probabilistic extension of the Hennessy-Milner
logic, showing its adequacy, and then a probabilistic extension of
the modal mu-calculus, showing its expressivity.
\subsection{An adequate logic}\label{s:adequate}
We extend the Hennessy-Milner logic by adding a probabilistic choice
modality to express the bebaviour of distributions.

\begin{definition}
The class  of modal formulae over , ranged over by
, is defined by the following grammar:
 We call
 a \emph{state formula} and  a \emph{distribution
formula}. Note that a distribution formula  only appears as
the continuation of a diamond modality . We sometimes
use the finite conjunction  as a syntactic
sugar.

The \emph{satisfaction relation}\index{satisfaction relation}
 is defined by
\begin{itemize}
\item  for all .
\item  if  for
  .
\item  if for some ,
   and .
\item  if it is not the case that
  .
\item  if there are
  , for all , with
  , such that .
\end{itemize}
\end{definition}
With a slight abuse of notation, we write  above
to mean that  satisfies the distribution formula .
The introduction of distribution formula distinguishes  from
other probabilistic modal logics e.g. \cite{{JWL01,PS07}}.

It turns out that  is adequate w.r.t. probabilistic
bisimilarity.
\begin{theorem}[Adequacy]\label{p:modal.characterisation}
Let  and  be any two states in a finitely branching pLTS. Then
 if and only if .
\end{theorem}
\begin{proof}
()
 Suppose , we show that  by structural induction on .
\begin{itemize}
\item Let , we clearly have .
\item Let . Then 
  for . So by induction , and we have
  . By symmetry we also have
   implies .
\item Let . So , and by induction
  we have . Thus . By symmetry we
  also have  implies .
\item Let . Then  and 
  for some . So
   and for all  and
   we have . Since , there is some  with 
  and . By
  Proposition~\ref{prop:lifting}  we have that  and . It follows
  that for each  there is some
   with .
  So by induction we have  for all  with .
  Therefore, we have . It follows that .
  By symmetry we also have
  .
\end{itemize}

() We show that the relation  is a probabilistic
bisimulation. Suppose  and . We have to
show that there is some  with  and . Consider the set

 For each , there must be some
  and
  such that (i) either there is a formula  with
 but
 (ii) or there is a formula
 with  but
. In the latter case we set
 and return back to the former
case. So for each  it holds that
 and for each  with 
there is some  with
. Let

It is clear that , hence  by .
It follows that there must be a  with
,

and for each  we have
. This means that  and hence
for each  we
have . It follows that . By symmetry all transitions of  can be matched up
by transitions of .
\end{proof}

\subsection{An expressive logic}
We now add the probabilistic choice modality introduced in
Section~\ref{s:adequate} to the modal mu-calculus, and show that the
resulting probabilistic mu-calculus is expressive w.r.t.
probabilistic bisimilarity.
\subsubsection{Probabilistic modal mu-calculus} Let  be a
countable set of variables.
We define a  set  of modal formulae in positive normal form
given by the following grammar:
  where
,  is a finite index set and . Here
we still write  for a state formula and  a distribution
formula. Sometimes we also use the finite conjunction
 and disjunction .
As usual, we have  and
.

The two fixed point operators  and  bind the
respective variable . We apply the usual terminology of free and
bound variables in a formula and write  for the set of
free variables in .

We use {\em environments}, which binds free variables to sets of
distributions, in order to give semantics to formulae. We fix a
finitary pLTS and let  be its state set. Let
 be the set of
all environments and ranged over by . For a set 
and a variable , we write  for the
environment that maps  to  and  to  for all
.

The semantics of a formula  can be given as the set of states
satisfying it. This entails a semantic functional  defined inductively in Figure
\ref{f:semantics}, where we also apply  to distribution
formulae and  is interpreted as the set of distributions
that satisfy . As the meaning of a closed formula  does
not depend on the environment, we write  for
 where  is an arbitrary environment.

\begin{figure}

\caption{Semantics of probabilistic modal
mu-calculus}\label{f:semantics}
\end{figure}

The semantics of probabilistic modal mu-calculus (pMu) is the same
as that of the modal mu-calculus \cite{Koz83} except for the
probabilistic choice modality which are satisfied by distributions.
The characterisation of {\em least fixed point
  formula}  and {\em greatest fixed point formula}  follows from the well-known Knaster-Tarski fixed point
theorem \cite{Tar55}.

We shall consider (closed) {\em equation systems} of formulae of the
form

where  are mutually distinct variables and
 are formulae having at most  as
free variables. Here  can be viewed as a function
 defined by  for
 and  for other variables .

An environment  is a {\em solution} of an equation system 
if . The existence of
solutions for an equation system can be seen from the following
arguments. The set , which includes all candidates for
solutions, together with the partial order  defined by
 forms a complete lattice. The
{\em equation functional}  given in the
-calculus notation by  is monotonic. Thus, the Knaster-Tarski fixed
point theorem guarantees existence of solutions, and the largest
solution



\subsubsection{Characteristic equation systems}\label{s:ces} As
studied in \cite{SI94}, the behaviour of a process can be
characterised by an equation system of modal formulae. Below we show
that this idea also applies in the probabilistic setting.

\begin{definition}\label{d:cess}
Given a finitary  pLTS, its {\em characteristic equation system}
consists of one equation for each state .

where

with .
\end{definition}

\begin{theorem}\label{t:ces}
Suppose  is a characteristic equation system. Then  if
and only if .
\end{theorem}
\begin{proof}
() Let . We
  first show that

Let , then . Suppose
. We have that
 and, for all 
and , that ,
i.e. . It follows that  and thus
 .

Now we show that  is a bisimulation.
\begin{enumerate}
\item Suppose  and . Then
  . It follows from
  (\ref{e:cf}) that . So
  there exists some  such that  and
  . Now we apply (\ref{e:left}).

\item Suppose  and . Then
  . It follows from
  (\ref{e:cf}) that . Notice that it
  must be the case that  can enable action , otherwise,  and thus  cannot enable  either, in contradiction
  with the assumption . Therefore,
  ,
  which implies
   for some  with
  .
  Now we apply (\ref{e:left}).
\end{enumerate}

() We define the environment  by
 
 It sufficies to show that  is a post-fixed point of
 , i.e.

because in that case we have , thus   implies  which in turn implies .

We first show that

Suppose , by Proposition~\ref{p:lifting}
we have that (i) ,
(ii) , (iii)  for all . We know from (iii) that
. Using (ii) we have that
.
Using (i) we obtain .

Now we are in a position to show (\ref{e:post}). Suppose . We must prove that , i.e.

by (\ref{e:cf}). This can be done by showing that  belongs to
each of the two parts of this intersection.
\begin{enumerate}
\item In the first case, we assume that . Since , there exists some  such that  and
  . By (\ref{e:right}), we get
  . It follows that .

\item In the second case, we suppose  for any action  and distribution . Then by  there exists some
  such that    and . By (\ref{e:right}), we get
 . As a consequence,
 .
 Since this holds for arbitrary action , our desired result
 follows.
\end{enumerate}
\end{proof}


\subsubsection{Characteristic formulae} So far we know how to
construct the characteristic equation system for a finitary pLTS. As
introduced in \cite{Mul98}, the three transformation rules in
Figure~\ref{f:rules} can be used to obtain from an equation system
 a formula whose interpretation coincides with the interpretation
of  in the greatest solution of . The formula thus obtained
from a characteristic equation system is called a {\em
characteristic formula}.
\begin{theorem}
Given a characteristic equation system , there is a
characteristic formula  such that 
for any state . \hfill\qed
\end{theorem}

The above theorem, together with the results in Section~\ref{s:ces},
gives rise to the following corollary.

\begin{corollary}
For each state  in a finitary pLTS, there is a characteristic
formula  such that  iff .
\hfill\qed
\end{corollary}

\begin{figure}
\begin{enumerate}
\item Rule 1: 
\item Rule 2: 
\item Rule 3:  if 
\end{enumerate}


\caption{Transformation rules}\label{f:rules}
\end{figure}


\section{Metric characterisation}\label{s:metric}
In the definition of probabilistic bisimulation probabilities are
treated as labels since they are matched only when they are
identical. One may argue that this does not provide a robust
relation: Processes that differ for a very small probability, for
instance, would be considered just as different as processes that
perform completely different actions. This is particularly relevant
to many applications where specifications can be given as perfect,
but impractical processes and other, practical processes are
considered acceptable if they only differ from the specification
with a negligible probability.

To find a more flexible way to differentiate processes, researchers
in this area have borrowed from mathematics the notion of
metric\footnote{For simplicity, in this section we use the term
metric to denote both metric and pseudometric.  All the results are
based on pseudometrics.}.  A metric is defined as a function that
associates a distance with a pair of elements. Whereas topologists
use metrics as a tool to study continuity and convergence, we will
use them to provide a measure of the difference between two
processes that are not quite bisimilar.

 Since different processes may behave  the same, they will be
  given distance zero in our metric semantics. So we are more
  interested in pseudometrics than metrics.

In the rest of this section, we fix a finite state pLTS
 and provide the set of pseudometrics on  with
the following partial order.
\begin{definition}
The relation  for the set  of -bounded
pseudometrics on  is defined by

\end{definition}
Here we reverse the ordering with the purpose of
  characterizing bisimilarity as the {\em greatest} fixed point (cf:
  Corollary~\ref{c:bimx}).

\begin{lemma}\label{l:latt}
 is a complete lattice.
\end{lemma}
\begin{proof}
The top element is given by ; the bottom
element is given by  if ,  otherwise.
Greatest lower bounds are given by  for any . Finally,
least upper bounds are given by .
\end{proof}


\begin{definition}\label{d:sm}
 is a {\em state-metric} if, for all
  ,  implies:
\begin{itemize}
\item if  then there exists some  such that
   and 
\end{itemize}
\end{definition}
where the lifted metric  was defined in (\ref{e:pc}) via
the Kantorovich metric. Note that if  is a state-metric then it
is also a metric. By  we have
, which implies
\begin{itemize}
\item if  then there exists some  such that
   and .
\end{itemize}
In the above definition, we prohibit  to be  because we
use  to represent the distance between any two incomparable
states including the case where one state may perform a transition
and the other may not.

The greatest state-metric is defined as


It turns out that state-metrics correspond to bisimulations and the
greatest state-metric corresponds to bisimilarity. To make the
analogy closer, in what follows we will characterize 
as a fixed point of a suitable monotone function on . First we
recall the definition of Hausdorff distance.
\begin{definition}
Given a -bounded metric  on , the {\em Hausdorff distance}
between two subsets  of  is defined as follows:

where  and .
\end{definition}
Next we define a function  on  by using the Hausdorff
distance.

\begin{definition}
Let .  is a
pseudometric given by:

\end{definition}

Thus we have the following property.

\begin{lemma}
For all ,  if and only if:
\begin{itemize}
\item if  then there exists some  such that
   and ;
\item if  then there exists some  such that
   and . \hfill\qed
\end{itemize}

\end{lemma}

The above lemma can be proved by directly checking the definition of
, as can the next lemma.
\begin{lemma}\label{l:smfix}
 is a state-metric if and only if . \hfill\qed
\end{lemma}
Consequently we have the following characterisation:


\begin{lemma}\label{l:mono}
 is monotone on . \hfill\qed
\end{lemma}

Because of Lemma \ref{l:latt} and \ref{l:mono}, we can apply
Knaster-Tarski fixed point theorem, which tells us that  is the greatest fixed point of . Furthermore, by
Lemma~\ref{l:smfix} we know that  is indeed a
state-metric, and it is the greatest state-metric.


We now show the correspondence between state-metrics and
bisimulations.



\begin{theorem}\label{t:bm}
Given a binary relation  and a pseudometric  on a
finite state pLTS such that

Then  is a probabilistic bisimulation if and only if  is a
state-metric.
\end{theorem}
\begin{proof}
The result can be proved by using Theorem~\ref{t:metric.relation},
which in turn relies on Theorem~\ref{t:lifting.alternative} (1).
Below we give an alternative proof that uses
Theorem~\ref{t:lifting.alternative} (2) instead.

Given two distributions  over , let us consider
how to compute  if  is an
equivalence relation. Since  is finite, we may assume that
 are all the equivalence classes of 
under . If  for some , then
, which implies  by the first constraint of
(\ref{e:pc}). So for each  there exists some  such
that  for all .
 Thus, some
summands of (\ref{e:pc}) can be grouped together and we have the
following linear program:

with the constraint  for any  with
. Briefly speaking, if  is an equivalence relation
then  is obtained by maximizing the linear
program (\ref{eq:b}).

() Suppose  is a bisimulation and .
From the assumption in (\ref{e:rm}) we know that  is an
equivalence relation.
 By the definition of
 we have . If  then  for
some  such that . To show that
 is a state-metric it suffices to prove . We
know from   and
Theorem~\ref{t:lifting.alternative} (2) that
, for each . It follows that
(\ref{eq:b}) is maximized to be , thus
.

() Suppose  is a state-metric and has the relation in
(\ref{e:rm}).
 Notice that  is
an equivalence relation. We show that it is a bisimulation. Suppose
, which means . If  then
 for some  such that
. To ensure that
, in (\ref{eq:b}) the following two
conditions must be satisfied.
\begin{enumerate}
\item No coefficient is positive. Otherwise, if
   then (\ref{eq:b}) would be
  maximized to a value not less than
  , which is greater than .
\item It is not the case that at least one coefficient is negative and the
  other coefficients are either negative or . Otherwise, by summing up
   all the coefficients, we would get
  
which contradicts the assumption that  and  are
distributions over .
\end{enumerate}

Therefore the only possibility is that all coefficients in
(\ref{eq:b}) are , i.e.,  for any
equivalence class . It follows from
Theorem~\ref{t:lifting.alternative} (2) that
. So we have shown that  is indeed
a bisimulation.
\end{proof}

\begin{corollary}\label{c:bimx}
Let  and  be two states in a finite state pLTS. Then  if and only if .
\end{corollary}
\begin{proof}
() Since  is a bisimulation, by
Theorem~\ref{t:bm} there exists some state-metric  such that
 iff . By the definition of  we
have . Therefore .

() From  we construct a pseudometric  as
follows.

Since  is a state-metric, it is easy to see that  is
also a state-metric. Now we construct a binary relation  such
that  iff . If follows from
Theorem~\ref{t:bm} that  is a bisimulation. If , then  and thus . Therefore we have
the required result  because  is the largest
bisimulation.
\end{proof}




\section{Algorithmic characterisation}\label{s:algo}
In this section we propose an ``on the fly" algorithm for checking
if two states in a finitary pLTS are  bisimilar.

An important ingredient of the algorithm is to check if two
distributions are related by a lifted relation. Fortunately,
Theorem~\ref{t:lift.flow} already provides us a method for deciding
whether , for two given distributions
 and a relation . We construct the network
 and compute the maximum flow with
well-known methods, as sketched in
Algorithm 1.

\begin{algorithm}
\caption{\textbf{Check}}
\begin{tabular}{l}
\emph{Input}: A nonempty finite set , distributions\\
\qquad 
and \\
\emph{Output}: If  then ``yes'' else ``no''\\
\emph{Method}:\\
\qquad Construct the network \\
\qquad Compute the maximum flow  in \\
\qquad If  then return ``no'' else ``yes''.
\end{tabular}
\end{algorithm}
As shown in \cite{CHM90}, computing the maximum flow in a network
can be done in time  and space , where  is
the number of nodes in the network. So we immediately have the
following result.
\begin{lemma}\label{l:check.lift}
The test whether  can be done in time  and space . \hfill\qed
\end{lemma}


\begin{algorithm}
\caption{\textbf{Bisim}}
\parbox[c]{7.8cm}{
\begin{algorithmic}
\STATE \textbf{Bisim} \STATE  \STATE
\textbf{fun} \textbf{Bis}=\{ \STATE \qquad 
\STATE \qquad  \STATE \qquad
\textbf{Match}\} \STATE\} \textbf{handle}
 \STATE \textbf{return}
\textbf{Bis}

\bigskip
\STATE \textbf{Match} \STATE
 \STATE  \IF{} \STATE  \IF{} \STATE
\textbf{raise}  \ENDIF \ENDIF \STATE
\textbf{return} 

\bigskip
\STATE \textbf{MatchAction} \FORALL{}
\FORALL{} \STATE
 \ENDFOR
\ENDFOR \STATE \textbf{return} 

\bigskip
\STATE\textbf{MatchDistribution} \STATE Assume
 and
 \STATE
 \STATE
\textbf{return} \textbf{Check}

\bigskip
\STATE\textbf{Close} \IF{} \STATE
\textbf{return}  \ELSIF{} \STATE
 \STATE \textbf{return} 
\ELSE \STATE \textbf{return} \textbf{Match} \ENDIF
\end{algorithmic}
}
\end{algorithm}

We now present a bisimilarity-checking algorithm by adapting the
algorithm proposed in \cite{Lin98} for value-passing processes,
which in turn was inspired by \cite{FM90}.

The main procedure in the algorithm is \textbf{Bisim}. It
starts with the initial state pair , trying to find the
smallest bisimulation relation containing the pair by matching
transitions from each pair of states it reaches.  It uses three
auxiliary data structures:
\begin{itemize}
\item  collects all state pairs that have already been
  detected as not bisimilar.
\item  collects all state pairs that have already been
  visited.
\item  collects all state pairs that have already been
  visited and assumed to be bisimilar.
\end{itemize}
The core procedure, \textbf{Match}, is called from function
\textbf{Bis} inside the main procedure \textbf{Bisim}. Whenever a
new pair of states is encountered it is inserted into . If
two states fail to match each other's transitions then they are not
bisimilar and the pair is added to . If the current state
pair has been visited before, we check whether it is in .
If this is the case, we return . Otherwise, a loop has been
detected and we make assumption that the two states are bisimilar,
by inserting the pair into , and return . Later on,
if we find that the two states are not bisimilar after finishing
searching the loop, then the assumption is wrong, so we first add
the pair into  and then raise the exception
, which forces the function \textbf{Bis} to run
again, with the new information that the two states in this pair are
not bisimilar. In this case, the size of  has been
increased by at least one. Hence, \textbf{Bis} can only be called
for finitely many times. Therefore, the procedure
\textbf{Bisim} will terminate. If it returns , then the
set  constitutes a bisimulation relation
containing the pair .

The main difference from the algorithm of checking non-probabilistic
bisimilarity in \cite{Lin98} is the introduction of the procedure
\textbf{MatchDistribution}, where we approximate
 by a  binary relation  which is coarser than 
in general, and we check the validity of .
If  does not hold, then
 is invalid either and
\textbf{MatchDistribution} returns \textit{false}
correctly. Otherwise, the two distributions  and 
are considered equivalent with respect to  and we move on to
match other pairs of distributions. The correctness of the algorithm
is stated in the following theorem.

\begin{theorem}\label{t:correctness}
Given two states  and  in a finitary pLTS, the function
\textbf{Bisim} terminates, and it returns \emph{true} if
and only if .
\end{theorem}
\begin{proof}
Let  stand for the -th execution of the function
\textbf{Bis}. Let  and  be the set 
and  at the end of \textbf{Bis}. When \textbf{Bis}
is finished, either a  is raised or no
 is raised. In the former case, ; in the latter case, the execution of the
function \textbf{Bisim} is completed. From function \textbf{Close}
we know that . Now it
follows from the simple fact 
that . Since we are considering
finitary pLTSs, there is some  such that
, when all the non-bisimilar state pairs
reachable from  and  have been found and \textbf{Bisim}
must terminate.

For the correctness of the algorithm, we consider the relation
, where  is the set
 at the end of \textbf{Bis}. Let \textbf{Bis} be
the last execution of \textbf{Bis}. For each , the relation
 can be regarded as an approximation of , as  far as
the states appeared in  are concerned. Moreover, 
is a coarser approximation because if two states  are
re-visited but their relation is unknown, they are assumed to be
bisimilar. Therefore, if \textbf{Bis} returns ,
then . On the other hand, if
\textbf{Bis} returns , then  constitutes
a bisimulation relation containing the pair . This
follows because   which basically
means that whenever  and  there exists
some transition  such that
, i.e.
. Indeed, this rules out the possibility
that  as otherwise we would have
 by Proposition~\ref{p:app}, that is
 for some . The latter means that some
transition  exists such that for all
 we have , or
symmetrically with the roles of  and  exchanged, i.e.
 and  can be distinguished at level , so a
contradiction arises.
\end{proof}

Below we consider the time and space complexities of the algorithm.
\begin{theorem}\label{t:complexity}
Let  and  be two states in a pLTS with  states in total.
The function  terminates in time  and space .
\end{theorem}
\begin{proof}
 The number
of state pairs is bounded by . In the worst case, each
execution of the function  only yields one new
pair of states that are not bisimilar. The number of state pairs
examined in the first execution of  is at most
, in the second execution is at most , .
Therefore, the total number of state pairs examined is at most
. When a state pair  is
examined, each transition of  is compared with all transitions of
 labelled with the same action. Since the pLTS is finitely
branching, we could assume that each state has at most  outgoing
transitions. Therefore, for each state pair, the number of
comparisons of transitions is bound by . As a comparison of two
transitions calls the function \textbf{Check} once, which requires
time  by Lemma~\ref{l:check.lift}. As a result,
examining each state pair takes time .
Finally, the worst case time complexity of executing
 is .

The space requirement of the algorithm is easily seen to be
, in view of Lemma~\ref{l:check.lift}.
\end{proof}

\begin{remark} With mild modification, the above algorithm can be adapted to
check probabilistic similarity. We simply remove the underlined part
in the function ; the rest of the algorithm
remains unchanged. Similar to the analysis in
Theorems~\ref{t:correctness} and \ref{t:complexity}, the new
algorithm can be shown to correctly check probabilistic similarity
over finitary pLTSs; its worst case time and space complexities are
still  and  , respectively.
\end{remark}

\section{Conclusion}\label{s:conclude}
To define behavioural equivalences or preorders for probabilistic
processes often involves a lifting operation that turns a binary
relation  on states into a relation  on
distributions over states. We have shown that several different
proposals for lifting relations can be reconciled. They are nothing
more than different forms of essentially the same lifting operation.
More interestingly, we have discovered that this lifting operation
corresponds well to the Kantorovich metric, a fundamental concept
used in mathematics to lift a metric on states to a metric on
distributions over states, besides the fact the lifting operation is
related to the maximum flow problem in optimisation theory.

The lifting operation leads to a neat notion of probabilistic
bisimulation, for which we have provided logical, metric, and
algorithmic characterisations.
\begin{enumerate}
\item We have
introduced a probabilistic choice modality to specify the behaviour
of distributions of states. Adding the new modality to the
Hennessy-Milner logic and the modal mu-calculus results in an
adequate and an expressive logic w.r.t. probabilistic bisimilarity,
respectively.

\item Due to the correspondence of the lifting operation and the
Kantorovich metric, bisimulations can be naturally characterised as
pseudometrics which are post-fixed points of a monotone function,
and bisimilarity as the greatest post-fixed point of the funciton.

\item We have presented an ``on the fly" algorithm to check if two
states in a finitary pLTS are bisimilar. The algorithm is based on
the close relationship between the lifting operation and the maximum
flow problem.
\end{enumerate}
In the belief that a good scientific concept is often elegant, even
seen from different perspectives, we consider the lifting operation
and probabilistic bisimulation as two concepts in probabilistic
concurrency theory that are formulated in the right way.


\bibliographystyle{abbrv}
\bibliography{main-bibfile}

\end{document}
