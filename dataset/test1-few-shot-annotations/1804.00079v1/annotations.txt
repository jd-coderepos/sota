[{'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MultiNLI', 'Metric': 'Matched', 'Score': '71.4'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MultiNLI', 'Metric': 'Mismatched', 'Score': '71.3'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'SentEval', 'Metric': 'MRPC', 'Score': '78.6/84.4'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'SentEval', 'Metric': 'SICK-R', 'Score': '0.888'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'SentEval', 'Metric': 'SICK-E', 'Score': '87.8'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'SentEval', 'Metric': 'STS', 'Score': '78.9/78.6'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'MRPC', 'Metric': 'Accuracy', 'Score': '78.6%'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'MRPC', 'Metric': 'F1', 'Score': '84.4%'}}]
