[{'LEADERBOARD': {'Task': 'Image-to-Image Translation', 'Dataset': 'RaFD', 'Metric': 'Classification Error', 'Score': '5.99%'}}, {'LEADERBOARD': {'Task': 'Image-to-Image Translation', 'Dataset': 'Cityscapes Labels-to-Photo', 'Metric': 'Class IOU', 'Score': '0.11'}}, {'LEADERBOARD': {'Task': 'Image-to-Image Translation', 'Dataset': 'Cityscapes Labels-to-Photo', 'Metric': 'Per-class Accuracy', 'Score': '17%'}}, {'LEADERBOARD': {'Task': 'Image-to-Image Translation', 'Dataset': 'Cityscapes Labels-to-Photo', 'Metric': 'Per-pixel Accuracy', 'Score': '52%'}}, {'LEADERBOARD': {'Task': 'Image-to-Image Translation', 'Dataset': 'Cityscapes Photo-to-Labels', 'Metric': 'Per-pixel Accuracy', 'Score': '58%'}}, {'LEADERBOARD': {'Task': 'Image-to-Image Translation', 'Dataset': 'Cityscapes Photo-to-Labels', 'Metric': 'Per-class Accuracy', 'Score': '22%'}}, {'LEADERBOARD': {'Task': 'Image-to-Image Translation', 'Dataset': 'Cityscapes Photo-to-Labels', 'Metric': 'Class IOU', 'Score': '0.16'}}, {'LEADERBOARD': {'Task': 'Image-to-Image Translation', 'Dataset': 'photo2vangogh', 'Metric': 'Frechet Inception Distance', 'Score': '151.4'}}, {'LEADERBOARD': {'Task': 'Image-to-Image Translation', 'Dataset': 'photo2vangogh', 'Metric': 'Number of params', 'Score': '28.2M'}}, {'LEADERBOARD': {'Task': 'Image-to-Image Translation', 'Dataset': 'zebra2horse', 'Metric': 'Frechet Inception Distance', 'Score': '110.5'}}, {'LEADERBOARD': {'Task': 'Image-to-Image Translation', 'Dataset': 'zebra2horse', 'Metric': 'Number of params', 'Score': '28.2M'}}, {'LEADERBOARD': {'Task': 'Image-to-Image Translation', 'Dataset': 'horse2zebra', 'Metric': 'Frechet Inception Distance', 'Score': '89.7'}}, {'LEADERBOARD': {'Task': 'Image-to-Image Translation', 'Dataset': 'horse2zebra', 'Metric': 'Number of params', 'Score': '28.2M'}}, {'LEADERBOARD': {'Task': 'Image-to-Image Translation', 'Dataset': 'vangogh2photo', 'Metric': 'Frechet Inception Distance', 'Score': '163.4'}}, {'LEADERBOARD': {'Task': 'Image-to-Image Translation', 'Dataset': 'vangogh2photo', 'Metric': 'Number of Params', 'Score': '28.2M'}}, {'LEADERBOARD': {'Task': 'Unsupervised Image-To-Image Translation', 'Dataset': 'Freiburg Forest Dataset', 'Metric': 'PSNR', 'Score': '18.57'}}, {'LEADERBOARD': {'Task': 'Multimodal Unsupervised Image-To-Image Translation', 'Dataset': 'Cats-and-Dogs', 'Metric': 'CIS', 'Score': '0.076'}}, {'LEADERBOARD': {'Task': 'Multimodal Unsupervised Image-To-Image Translation', 'Dataset': 'Cats-and-Dogs', 'Metric': 'IS', 'Score': '0.813'}}, {'LEADERBOARD': {'Task': 'Multimodal Unsupervised Image-To-Image Translation', 'Dataset': 'EPFL NIR-VIS', 'Metric': 'PSNR', 'Score': '17.38'}}, {'LEADERBOARD': {'Task': 'Multimodal Unsupervised Image-To-Image Translation', 'Dataset': 'Edge-to-Shoes', 'Metric': 'Quality', 'Score': '36.0%'}}, {'LEADERBOARD': {'Task': 'Multimodal Unsupervised Image-To-Image Translation', 'Dataset': 'Edge-to-Shoes', 'Metric': 'Diversity', 'Score': '0.010'}}, {'LEADERBOARD': {'Task': 'Multimodal Unsupervised Image-To-Image Translation', 'Dataset': 'Edge-to-Handbags', 'Metric': 'Quality', 'Score': '40.8%'}}, {'LEADERBOARD': {'Task': 'Multimodal Unsupervised Image-To-Image Translation', 'Dataset': 'Edge-to-Handbags', 'Metric': 'Diversity', 'Score': '0.012'}}]
