[{'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VCR (QA-R) test', 'Metric': 'Accuracy', 'Score': '78.4'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-dev', 'Metric': 'Accuracy', 'Score': '71.79'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-dev', 'Metric': 'Accuracy', 'Score': '71.16'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VCR (Q-A) dev', 'Metric': 'Accuracy', 'Score': '75.5'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VCR (Q-A) dev', 'Metric': 'Accuracy', 'Score': '73.8'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VCR (Q-AR) test', 'Metric': 'Accuracy', 'Score': '59.7'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-std', 'Metric': 'overall', 'Score': '72.2'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VCR (Q-A) test', 'Metric': 'Accuracy', 'Score': '75.8'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VCR (Q-AR) dev', 'Metric': 'Accuracy', 'Score': '58.9'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VCR (Q-AR) dev', 'Metric': 'Accuracy', 'Score': '55.2'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VCR (QA-R) dev', 'Metric': 'Accuracy', 'Score': '77.9'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VCR (QA-R) dev', 'Metric': 'Accuracy', 'Score': '74.4'}}, {'LEADERBOARD': {'Task': 'Image-text matching', 'Dataset': 'CommercialAdsDataset', 'Metric': 'ADD(S) AUC', 'Score': '86.27'}}]
