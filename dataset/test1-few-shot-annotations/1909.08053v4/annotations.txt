[{'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'RACE', 'Metric': 'Accuracy', 'Score': '90.9'}}, {'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'RACE', 'Metric': 'Accuracy (High)', 'Score': '90.0'}}, {'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'RACE', 'Metric': 'Accuracy (Middle)', 'Score': '93.1'}}, {'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'RACE', 'Metric': 'Accuracy', 'Score': '89.5'}}, {'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'RACE', 'Metric': 'Accuracy (High)', 'Score': '88.6'}}, {'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'RACE', 'Metric': 'Accuracy (Middle)', 'Score': '91.8'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'PIQA', 'Metric': 'Accuracy', 'Score': '82.0'}}, {'LEADERBOARD': {'Task': 'Language Modelling', 'Dataset': 'WikiText-103', 'Metric': 'Test perplexity', 'Score': '10.81'}}, {'LEADERBOARD': {'Task': 'Language Modelling', 'Dataset': 'WikiText-103', 'Metric': 'Number of params', 'Score': '8300M'}}]
