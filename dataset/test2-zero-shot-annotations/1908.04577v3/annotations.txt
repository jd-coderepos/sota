[{'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'QNLI', 'Metric': 'Accuracy', 'Score': '99.2%'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'WNLI', 'Metric': 'Accuracy', 'Score': '89.7%'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'RTE', 'Metric': 'Accuracy', 'Score': '88.7%'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MultiNLI', 'Metric': 'Matched', 'Score': '91.1'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MultiNLI', 'Metric': 'Mismatched', 'Score': '90.7'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'MRPC', 'Metric': 'Accuracy', 'Score': '91.5%'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'MRPC', 'Metric': 'F1', 'Score': '93.6%'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'STS Benchmark', 'Metric': 'Pearson Correlation', 'Score': '0.928'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'STS Benchmark', 'Metric': 'Spearman Correlation', 'Score': '0.924'}}, {'LEADERBOARD': {'Task': 'Paraphrase Identification', 'Dataset': 'WikiHop', 'Metric': 'Accuracy', 'Score': '90.7%'}}, {'LEADERBOARD': {'Task': 'Sentiment Analysis', 'Dataset': 'SST-2 Binary classification', 'Metric': 'Accuracy', 'Score': '97.1'}}, {'LEADERBOARD': {'Task': 'Linguistic Acceptability', 'Dataset': 'CoLA', 'Metric': 'Accuracy', 'Score': '69.2%'}}]
