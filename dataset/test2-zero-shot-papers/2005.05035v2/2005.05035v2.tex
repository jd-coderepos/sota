\documentclass[12pt,a4paper]{article}
\RequirePackage[margin=25mm]{geometry}
\RequirePackage[colorlinks,allcolors=red!70!black]{hyperref}
\usepackage{latexsym,amsmath,amsfonts,amssymb,bm}
\RequirePackage[textsize=scriptsize]{todonotes}
\marginparwidth 24mm \marginparsep .1mm
\RequirePackage[normalem]{ulem}

\DeclareMathOperator{\argmax}{argmax}
\DeclareMathOperator{\aeiou}{aeIOU}
\DeclareMathOperator{\relu}{ReLU}
\def\Tall{\mathfrak{T}}
\def\train{\text{tr}}
\def\eval{\text{ev}}
\def\pred{\text{pr}}
\def\iou{\text{IOU}}
\def\R{\mathbb{R}}
\def\C{\mathbb{C}}
\def\bs{\bm{s}}
\def\br{\bm{r}}
\def\bo{\bm{o}}
\def\bt{\bm{t}}
\def\shortname{TimePlex}
\def\complex{CX}

\begin{document}

\title{TKBC}
\author{PJ \and SR \and M \and SC}
\date{}
\maketitle


\section{Structured learning for time prediction}

 is ``all time''.
Scoring function  for an instant~.
Can return any real value, positive or negative.
Suppose we define additively .
During training, we want  for any .
During inference we want .
As is common in structured learning, there are too many , although `only'  in case all  are single contiguous intervals.
Using margin scaling, we want 
 for any , where  is the  loss.
Loss-augmented inference (used at training time to add constraints incrementally) amounts to searching for .
I.e.,  \todo{you mean 1- aeIOU here sc: 1-arIOU should be large} should be small and  should be large.
We could of course do this in  time by exhaustive search. 
Then we can use standard \href{https://www.cs.cornell.edu/people/tj/svm_light/svm_struct.html}{SVMstruct}, which is likely to be faster than adding  constraints for each instance into the QP.

Converted from constraints to hinge losses, the relevant part of the objective looks like
.  DL folks will usually sample some  and write the softplus version
 or even , which we will minimize wrt complex embeddings used inside~.
(We should draw some s disjoint from  at various distances and of various duration, then some s overlapping  to diverse extents and having various duration.  The goal is to get a good range of~s.)

Once time prediction training loss is cast as above, it may not remain directly comparable with cross-entropy (or some other) loss of predicting  or~.  Unlike in the manuscript, we now have to worry about blending link and time interval prediction losses.

\section{Improved pairwise gadget}
Notation:\\
 - query\\
 - relation in query\\
 - time in query \\
Candidate entity-  \\
All facts in train KB with e as subject are referred to as 'links' of e.\\
 - relation of an arbitrary link of \\
 - time for that link\\

Feature for query relation   is Gaussian density of observed time difference  given trained mean  and variance  (initialized with statistics on train KB)\\
Thus, num features for e = num links of e.\\\\
To allow the feature to become negative, we add a trainable offset to the gaussian density, which is a function of the relation pair.\\
\phi^\text{Pair}(e,r,o,t)= \sum (\\ \\

For recurrent relations gadget, we learn a weight for each relation (instead of relation pair like in pairwise). \\
Feature for query relation is same as before (gaussian density), except we only consider links with the \textbf{same relation} AND the \textbf{same object} as that of query. In case of multiple such links, we pick the one with minimum time difference.\\
Similar to pairwise, we add a trainable offset to the gaussian density, which is now a function of the query relation.

\phi^\text{Recurrent}(e,r,o,t)=(

\\
TODO-
1. Set minimum threshold.
2. Add a bias if the relation has never repeated.













\begingroup
\color{blue}

\section{Introduction}
\sout{struck through} means transferred to manuscript
\begin{itemize}
    \item \sout{KBC popular - timeKBC hasn't been explored a lot -- more over the most central task around time-KBC i.e time interval prediction has been overlooked.}

    \item \sout{Why time info in KB important?
    Time-KBC scenarios. (a) Life of a facts 
    (fact true for a time span, event occur only at a time) - events, short lived facts, long lived facts. -- Barak Obama is the President of USA is only true from 2009 to 2017. [improvise motivation]
    Trump is the president of US (2017-onwards). If time onfo was missing -- model might not be able to learn common sense things like there can be only one president of a country at a given time.      (b) died in can happen only after someone was born.}
    
    \item \sout{Models which perform link prediction - need to be carefully evaluated - prev work overrated (or underrates) the performance - time based filtering described here, and how it needs to be different for event-based datasets and fact-based datasets.}
    
    \item \sout{Time interval prediction is a new task, we need to carefully design the evaluation metric.}

    \item Time agnostic superior baselines - Complex..we beat it on all dataset



    \item Strong frequency based baselines to demonstrate the quality of the proposed models.
    
    \item \sout{Contributions list}
\end{itemize}

\section{Experiments}
\begin{itemize}
    \item Link pred performance
    \item Sample predictions
    \item Time interval prediction performance
    \begin{itemize}
        \item Time interval inference procedures
        \begin{itemize}
            \item Greedy coalescing
            \item Exhaustive interval search
        \end{itemize}
    \end{itemize}
    \item percent time violation in top predictions of time ignoring (CX) model and time aware model
    \begin{itemize}
        \item Pairwise model
    \end{itemize}
    \item Relation ordering - Can we generate life span (biography) of an average person automatically -- he was born in x <T>, he graduated in y <T>, he died in z<T>.
    \item How logical are time embeddings? - nearby times are close, do they follow order, do they understand duration?
    \item how model performance varies with missing time 
    \item Relation wise performance of different models (time aware and time-agnostic)
    \item Performance of model as missing time increases
    \item Correlation between aeIoU and IOU for overlapping and non-overlapping samples.
\end{itemize}


\subsection{Summary results}

Baseline model details - Add table of scoring function of Complex,
\todo{discuss coalescing} HyTE, TA-DistMult.

\begin{itemize}
\item how model performance varies with missing time 
\item Relation wise performance drill-down of different models (time aware and time-agnostic)
\item percent time violation in top predictions of time ignoring (\complex{}) model and time aware model
\item Correlation between aeIoU and IOU for overlapping and non-overlapping samples.
\end{itemize}


\endgroup









\end{document}
