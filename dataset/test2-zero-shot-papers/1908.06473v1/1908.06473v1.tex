\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bbm}
\usepackage[american]{babel}



\makeatletter
\newif\if@restonecol
\makeatother
\let\algorithm\relax
\let\endalgorithm\relax
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}\usepackage{algpseudocode}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}  \renewcommand{\algorithmicensure}{\textbf{Output:}} 

\usepackage{bm}

\usepackage{multirow} 

\newcommand{\squishlist}{
	\begin{list}{}
		{ \setlength{\itemsep}{0pt}
			\setlength{\parsep}{2pt}
			\setlength{\topsep}{2pt}
			\setlength{\partopsep}{0pt}
			\setlength{\leftmargin}{1em}
			\setlength{\labelwidth}{1em}
			\setlength{\labelsep}{0.5em} } }
	\newcommand{\squishend}{
\end{list} }




\usepackage[pagebackref=true,breaklinks=true,colorlinks,bookmarks=false]{hyperref}

\iccvfinalcopy 

\def\iccvPaperID{3286} \def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\ificcvfinal\pagestyle{empty}\fi
\begin{document}
	
\title{From Open Set to Closed Set: Counting Objects by Spatial Divide-and-Conquer\thanks{
			Haipeng Xiong and Hao Lu contributed equally. Zhiguo Cao is the corresponding author.
		}
	}
	
	\author{Haipeng Xiong, Hao Lu, Chengxin Liu, Liang Liu, Zhiguo Cao, Chunhua Shen\\
		Huazhong University of Science and Technology, China\\
		The University of Adelaide, Australia\\
		{\tt\small \{hpxiong,zgcao\}@hust.edu.cn,  hao.lu@adelaide.edu.au }
\and
}
	
	\maketitle
	\thispagestyle{empty}
	
\begin{abstract}
		


		Visual counting, a task that predicts the number of objects from an image/video, is an open-set problem by nature, i.e., the number of population can vary in  in theory. However, the collected images and labeled count values are limited in reality, which means only a small closed set is observed. Existing methods typically model this task in a regression manner, while they are likely to suffer from an unseen scene with counts out of the scope of the closed set. In fact, counting is decomposable. A dense region can always be divided until sub-region counts are within the previously observed closed set. Inspired by this idea, we propose a simple but effective approach, Spatial Divide-and-Conquer Network (S-DCNet). 
S-DCNet only learns from a closed set but can generalize well to open-set scenarios via S-DC. S-DCNet is also efficient. To avoid repeatedly computing sub-region convolutional features, S-DC is executed on the feature map instead of on the input image.
S-DCNet achieves the state-of-the-art performance on three crowd counting datasets (ShanghaiTech, UCF\_CC\_50 and UCF-QNRF),  a vehicle counting dataset (TRANCOS) and a plant counting dataset (MTC). Compared to the previous best methods, S-DCNet brings a  relative improvement on the ShanghaiTech Part\_B,  on the UCF-QNRF,  on the TRANCOS and  on the MTC. Code has been made available at: \url{https://github.com/xhp-hust-2018-2011/S-DCNet}.
		
	\end{abstract}
	
\section{Introduction}\label{sec:intro}
	
	The task of visual counting in Computer Vision is to infer the number of objects (people, cars, maize tassels, etc.) from an image/video. It has wide applications, such as automatic crowd management~\cite{UCFCC50_2013_CVPR,Compose_Loss_2018_ECCV,blobs_2018_ECCV,Zhang_2015_CVPR,MCNN_2016_CVPR}, traffic monitoring~\cite{TRANCOSdataset_IbPRIA2015,O2016Towards_CCNN}, and crop yield estimation~\cite{Fernandezgallego2018Wheat,Giuffrida2015Learning_global,Lu2017TasselNet}. Extensive attention has been received in recent years.
	
	\begin{figure}[t]
		\begin{center}
\includegraphics[width=0.8\linewidth]{Patch_CSRNet_rmse.jpg}
		\end{center}
		\vspace{-10pt}
		\caption{ The histogram of count values of  local patches on the test set of ShanghaiTech Part\_A dataset~\cite{MCNN_2016_CVPR}. The orange curve denotes the relative mean absolute error (rMAE) of CSRNet~\cite{CSRNet_2018_CVPR} on local patches. }
\label{fig:image_dis_rmae}
		\vspace{-10pt}
	\end{figure}
	
	Counting is an open-set problem by nature as a count value can range from  to  in theory. It is thus typically modeled in a regression manner. Benefiting from the success of convolutional neural networks (CNNs), state-of-the-art deep counting networks
often adopt a multi-branch architecture to enhance the feature robustness to dense regions~\cite{SwitchCNN_2017_CVPR,SANet_2018_ECCV,MCNN_2016_CVPR}. 
However, the observed patterns in datasets are limited in practice, which means networks can only learn from a closed set. \emph{Are these counting networks still able to generate accurate predictions when the number of objects is out of the scope of the closed set?}
	Meanwhile, observed local counts exhibit a long-tailed distribution shown in Figure~\ref{fig:image_dis_rmae}. Extremely dense patches are rare while sparse patches take up the majority. As what can be observed, the relative mean absolute error (rMAE) increases significantly with increased local density. \emph{Is it necessary to set the working range of CNN-based regressors to the maximum count value observed, even with a majority of samples are sparse such that the regressor works poorly in this range?}
	
	In fact, counting has an unique property---spatially decomposable. The above problem can be largely alleviated with the idea of spatial divide-and-conquer (S-DC). Suppose that a network has been trained to accurately predict a closed set of counts, say . When facing an image with extremely dense objects, one can keep dividing the image into sub-images until all sub-region counts are less than . Then the network can accurately count these sub-images and sum over all local counts to obtain the global image count. Figure~\ref{fig:image_divide_example} graphically depicts the idea of S-DC. A follow-up question is how to spatially divide the count. A naive way is to upsample the input image, divide it into sub-images and process sub-images with the same network. This way, however, is likely to blur the image and lead to exponentially-increased computation cost and memory consumption when repeatably extracting the feature map. Inspired by RoI pooling~\cite{girshick2015fast}, we show that it is feasible to achieve S-DC on the feature map, as conceptually illustrated in Figure~\ref{fig:feature_divide}. By decoding and upsampling the feature map, the later prediction layers can focus on the feature of local areas and predict sub-region counts accordingly.
	
	\begin{figure}[t]
		\begin{center}
\includegraphics[width=0.8\linewidth]{image_divide.jpg}
		\end{center}
		\vspace{-10pt}
		\caption{An illustration of spatial divisions. Suppose that the closed set of counts is . In this example, dividing the image for one time is inadequate to ensure that all sub-region counts are within the closed set. For the top left sub-region, it needs a further division. }
		\label{fig:image_divide_example}
	\end{figure}
	
	
	\begin{figure}[t]
		\begin{center}
\includegraphics[width=0.9\linewidth]{feature_divide.jpg}
		\end{center}
		\vspace{-10pt}
		\caption{ Spatial divisions on the input image (left) and the feature map (right). Spatially dividing the input image is straightforward. The image is upsampled and fed to the same network to infer counts of local areas. The orange dashed line is used to connect the local feature map, the local count and the sub-image. S-DC on the feature map avoids redundant computations and is achieved by upsampling, decoding and dividing the feature map of high resolution.}
		\label{fig:feature_divide}
		\vspace{-10pt}
	\end{figure}
	
	To realize the above idea, we propose a simple but effective Spatial Divide-and-Conquer Network (S-DCNet). S-DCNet learns from a closed set of count values but is able to generalize to open-set scenarios. Specifically, \mbox{S-DCNet} adopts a VGG16~\cite{Simonyan2014Very_VGG16}-based encoder and an UNet~\cite{Unet2015U}-like decoder to generate multi-resolution feature maps. All feature maps share the same counting predictor. Inspired by~\cite{li2018deep}, in contrast to the conventional density map regression, we discretize continuous count values into a set of intervals and design the counting predictor to be a classifier. Further, a division decider is designed to decide which sub-region should be divided and to merge different levels of sub-region counts into the global image count. We show through a controlled toy experiment that, even given a closed training set, S-DCNet effectively generalizes to the open test set. The effectiveness of \mbox{S-DCNet} is further demonstrated on three crowd counting datasets (ShanghaiTech~\cite{MCNN_2016_CVPR}, UCF\_CC\_50~\cite{UCFCC50_2013_CVPR} and UCF-QNRF~\cite{Compose_Loss_2018_ECCV}), a vehicle counting dataset (TRANCOS~\cite{TRANCOSdataset_IbPRIA2015}), and a plant counting dataset (MTC~\cite{Lu2017TasselNet}). Results show that S-DCNet indicates a clear advantage over other competitors and sets the new state-of-the-art across five datasets.
	
	The main contribution of this work is that we propose to transform open-set counting into a closed-set problem. We show through extensive experiments that a model learned in a closed set can effectively generalize to the open set with the idea of S-DC. 





	
\section{Related Work}
	Current CNN-based counting approaches are mainly built upon the framework of local regression. According to their regression targets, they can be categorized into two categories: density map regression and local count regression. We first review these two types of regression. Since S-DCNet learns to classify counts, some works that reformulate the regression problem are also discussed.
	
	\vspace{-10pt}
	\paragraph{Density Map Regression}
	The concept of density map was introduced in~\cite{vlaz2010denlearn}. The density map contains the spatial distribution of objects, thus can be smoothly regressed. Zhang \etal~\cite{Zhang_2015_CVPR} first adopted a CNN to regress local density maps. Then almost all subsequent counting networks followed this idea. Among them, a typical network architecture is multi-branch. MCNN~\cite{MCNN_2016_CVPR} and Switching-CNN~\cite{SwitchCNN_2017_CVPR} used three columns of CNNs with varying receptive fields to depict objects of different scales. SANet~\cite{SANet_2018_ECCV} adopted Inception~\cite{GoogleNet_2015_CVPR}-liked modules to integrate extra branches. 
	CP-CNN~\cite{CPCNN_2017_ICCV} added two extra density-level prediction branches to combine global and local contextual information. ACSCP~\cite{ACSCP_2018_CVPR} inserted a child branch to match cross-scale consistency and an adversarial branch to attenuate the blurring effect of the density map. ic-CNN~\cite{ICNN_2018_ECCV} incorporated two branches to generate high-quality density maps in a coarse-to-fine manner. IG-CNN~\cite{Divide_grow_2018_CVPR} and D-ConvNet~\cite{DeepNegCor_2018_CVPR} drew inspirations from ensemble learning and trained a series of networks or regressors to tackle different scenes. DecideNet~\cite{DecideNet_2018_CVPR} attempted to selectively fuse the results of density map estimation and object detection for different scenes. Unlike multi-branch approaches, Idrees \etal~\cite{Compose_Loss_2018_ECCV} employed a composition loss and simultaneously solved several counting-related tasks to assist counting. CSRNet~\cite{CSRNet_2018_CVPR} benefited from dilated convolution which effectively expanded the receptive field to capture contextual information.
	
	Existing deep counting networks aim to generate high-quality density maps. However, density maps are actually in the open set as well. Detailed discussion of the open set problem in density maps is provided in the Supplement.



	\vspace{-10pt}
	\paragraph{Local Count Regression}
	Local count regression directly predicts count values of local image patches. This idea first appeared in~\cite{chen2012feature} where a multi-output regression model was used to regress region-wise local counts simultaneously.~\cite{Count_ception_2017_ICCVW} and~\cite{Lu2017TasselNet} introduced such an idea into deep counting. Local patches were first densely sampled in a sliding-window manner with overlaps, and a local count was then assigned to each patch by the network. Inferred redundant local counts were finally normalized and fused to the global count. Stahl \etal~\cite{tip2019divide} regressed the counts for object proposals generated by Selective Search~\cite{Uijlings2013Selective} and combined local counts using an inclusion-exclusion principle. Inspired by subitizing, the ability for a human to quickly counting a few objects at a glance, Chattopadhyay \etal~\cite{Count_everyday_2017_CVPR} transferred their focus to the problem of counting objects in everyday scenes. The main challenge thus became large intra-class variances rather than the occlusions and perspective distortions in crowded scenes.
	


	While some above methods~\cite{Count_everyday_2017_CVPR,tip2019divide} also leverage the idea of spatial divisions, they still regress the open-set counts. Although local-region patterns are easier to be modelled than the whole image, the observed local patches are still limited. Since only finite local patterns (a closed set) can be observed, new scenes in reality have a high probability including objects out of the range (an open set). Moreover, dense regions with large count values are rare (Figure~\ref{fig:image_dis_rmae}) and the networks may suffer from sample imbalance. In this paper, we show that a counting network is able to learn from a closed set with a certain range of counts, say , and then generalizes to an open set (including counts ) via S-DC. 
	


	\vspace{-10pt}
	\paragraph{Beyond Naive Regression}
	
	Regression is a natural way to estimating continuous variables, such as age and depth. However, some literatures suggest that regression is encouraged to be reformulated as an ordinal regression problem or a classification problem, which enhances performance and benefits optimization~\cite{Cumulative_2013_CVPR,Ordinal_depth_2018_CVPR,li2018deep,Ordinal_age_2016_CVPR}. Ordinal regression is usually implemented by modifying well-studied classification algorithms and has been applied to the problem of age estimation~\cite{Ordinal_age_2016_CVPR} and monocular depth prediction~\cite{Ordinal_depth_2018_CVPR}. Li~\etal~\cite{li2018deep} further showed that directly reformulating regression to classification was also a good choice. Since count values share a similar property like age and depth, it motivates us to follow such a reformulation. In this work, S-DCNet follows~\cite{li2018deep} to discretize local counts and classify count intervals. Indeed, we observe in experiments that classification with S-DC works better than direct regression.
	
	\section{Spatial Divide-and-Conquer Network}
	
	In this section, we describe the transformation from quantity to interval which transfers count values into a closed set. We also explain in detail our proposed S-DCNet.


	\subsection{From Quantity to Interval }
Instead of regressing an open set of count values, we follow~\cite{li2018deep} to discretize local counts and classify count intervals. Specifically, we define an interval partition of  as , , , ... ,  and . These  sub-intervals are labeled to the -th to the -th classes, respectively. For example, if a count value is within , it is labeled as the -th class. In practice,  should be not greater than the max local count observed in the training set.


	The median of each sub-interval is adopted when recovering the count from the interval. Notice that, for the last sub-interval ,  will be used as the count value if a region is classified into this interval. It is clear that \emph{adopting  for the last class will cause a systematic error}, but the error can be mitigated via S-DC as what we will show in experiments.
	
	
	
	
	\begin{figure*}[t]
		\begin{center}
\includegraphics[width=0.8\linewidth]{SDCNet_architecture.jpg}
		\end{center}
		\vspace{-10pt}
		\caption{ The architecture of S-DCNet (left) and a two-stage S-DC process (right). S-DCNet adopts all convolutional layers in VGG16~\cite{Simonyan2014Very_VGG16} while the first two convolutional blocks are simplified as  in the figure. An UNet~\cite{Unet2015U}-like decoder is employed to upsample and divide the feature map as per Figure~\ref{fig:feature_divide}. A shared classifier and a division decider receive divided feature maps, and respectively, generate division counts s and division masks s, for  After obtaining these results,  and  are merged to the -th division count  shown in the right sub-figure. Specially, we average each count of low resolution into the corresponding  area of high resolution before merging ( shown in the figure). ``" denotes the Hadamard product. Note that, the  local patch is only used as an example for readers to understand the pipeline of S-DCNet. Since S-DCNet is a fully convolutional network, it can process images of arbitrary sizes  and return s of size . The structures for the classifier and the division decider are presented in Table~\ref{tab:classifer_div_decider}.}
		\label{fig:SDCNet_architecture}
		\vspace{-10pt}
	\end{figure*}
	
	\begin{table}\footnotesize
		\begin{center}
			\begin{tabular}{|c|c|}
				\hline
				classifier & division decider\\
				\hline\hline
				
				 AvgPool, s &   AvgPool, s  \\
				 Conv, , s  &  Conv, , s  \\
				 Conv, , s  &  Conv, , s \\
				&Sigmoid\\
				
				\hline
			\end{tabular}
		\end{center}
		\caption{The architecture of \textit{classifier} and \textit{division decider}.  denotes average pooling. Convolutional layers are defined in the format:  ,  , . Each convolutional layer is followed by a ReLU function except the last layer. In particular, a \textit{sigmoid} function is employed at the end of \textit{division decider} to generate soft division masks.}
		\label{tab:classifer_div_decider}
	\end{table}     
	
	
	\subsection{Single-Stage Spatial Divide-and-Conquer}  \label{sec:S-DCNet_Arc}   
	As shown in Figure~\ref{fig:SDCNet_architecture}, S-DCNet includes a VGG16~\cite{Simonyan2014Very_VGG16} feature encoder, an UNet~\cite{Unet2015U}-like decoder, a count-interval classifier and a division decider. The structure of the classifier and the division decider are shown in Table~\ref{tab:classifer_div_decider}. Notice that, the first average pooling layer in the classifier has a stride of , so the final prediction has an output stride of .
	
	The feature encoder removes fully-connected layers from the pre-trained VGG16. Suppose that the input patch is of size . Given the feature map  (extracted from the Conv5 layer) with  resolution of the input image, the classifier predicts the class label of the count interval  conditioned on . The local count , which denotes the count value of the  input patch, can be recovered from . Note that  is the local count without S-DC, which is also the final output of previous approaches~\cite{Count_everyday_2017_CVPR,Count_ception_2017_ICCVW,Lu2017TasselNet}.  
	
	We execute the first-stage S-DC on the fused feature map .  is divided and sent to the shared classifier to produce the division count . Concretely,  is upsampled by  in an UNet-like manner to . Given , the classifier fetches the local features that correspond to spatially divided sub-regions, and predicts the first-level division counts . Each of the  elements in  denotes a sub-count of the corresponding  sub-region.
	
	With local counts  and , the next question is to decide where to divide. We learn such decisions with another network module, division decider, as depicted in the right part of Figure~\ref{fig:SDCNet_architecture}. At the first stage of S-DC, the division decider generates a soft division mask  of the same size as  conditioned on  such that for any .  means no division is required at this position, and the value in  is used.  implies that here the initial prediction should be replaced with the division count in . Since  and  are both  times larger than ,  is upsampled by  to , and the count is averaged into the  local area in . The first-stage division result  can thus be computed as 
	
	where  denotes a matrix filled with  and is with the same size of . ``" denotes the Hadamard product.  is an averaging re-distribution operator (equally dividing a count value into a  region).
	
	\iffalse
	They are defined as eq.~\ref{Cross_Entropy_Loss} and ~\ref{L1Loss} separately.
	
	
	
	
	\fi
	
	\begin{algorithm}[!t] \small
		\caption{ Multi-Stage S-DC}
		\label{alg:Overall algorith}
		\LinesNumbered
		\KwIn{Image  and division time }\KwOut{Image count }
		
		Extract  from \;
		
		Generate  given  with the classifier, and recover  from \;



		Initialize \;
		
\For{ \textbf{to} }
		{
			Decode  to \;
			
			Process  with the classifier and the division decider to obtain  and the division mask \;
			
Recover  from \;
			
			Update  as per Eq.~\ref{merge_12345} \;  	
		}
		
Integrate over  to obtain the image count \;
		
		
\textbf{return} 
	\end{algorithm}
	
	\subsection{Multi-Stage Spatial Divide-and-Conquer}
	
	S-DCNet can execute multi-stage S-DC by further decoding, dividing the feature map until reaching the output of the first convolutional block. In this sense, the maximum division time is  in VGG16 (actually we show later in experiments that a two-stage division is adequate to guarantee satisfactory performance). In multi-stage S-DC,  () is merged in a recursive manner as 
	
	
We employ two types of standard loss functions to train S-DCNet: several cross-entropy losses s that correspond to different classification outputs s, and a  loss  for the final division output  ( denotes the division time). S-DCNet is learned in a multi-task manner where the overall loss  is a summation of all losses, i.e., \mbox{}. Note that,  is essential to provide an implicit supervision signal for learning s. Multi-stage S-DCNet is summarized in Algorithm~\ref{alg:Overall algorith}.


	\section{Open Set or Closed Set? A Toy-Level Justification}
As aforementioned, counting is an open-set problem while the model is learned in a closed set. \emph{Can a closed-set counting model really generalize to open-set scenarios?} Here we show through a controlled toy experiment that, the answer is \textit{no}. Inspired by~\cite{vlaz2010denlearn}, we synthesize a cell counting dataset to explore the counting performance outside a closed training set.
	
	\iffalse
	\begin{figure}[t]
		\begin{center}
			\includegraphics[width=0.8\linewidth]{toy_regression.jpg}
		\end{center}
		\vspace{-10pt}
		\caption{An example of univariate regression with . We adopt a three-layer multi-layer perception (MLP) with  hidden units as the regressor. Training samples are within the range of . It can be observed the regressor performs precisely in the training range while fails outside such a range. }
		\label{fig:toy_regression}
		\vspace{-10pt}
	\end{figure}
	\fi
	
	\vspace{-10pt}
	\paragraph{Synthesized Cell Counting Dataset}
	We first generate   images with  sub-regions containing only  cells to construct the training set (a closed set). To generate an open testing set, we further synthesize  images with sub-region counts evenly distributed in the range of . 


	\vspace{-10pt}
	\paragraph{Baselines and Protocols}
	We adopt three approaches for comparisons, they are: 
	\textbf{i}) a regression baseline with pretrained VGG16 as the backbone and the \textit{classifier} module used in S-DCNet as the backend except that the output channel is modified to .  loss is used. This approach directly regresses the open-set counts;
	\textbf{ii}) a classification baseline with the same VGG16 and the \textit{classifier} settings as S-DCNet, without S-DC;
	\textbf{iii}) our proposed S-DCNet, which learns from a closed set but adapts to the open set via S-DC.  
	
	Regarding the discretization of count intervals, we choose  as the step because cells can be partially presented in local patches. As a consequence, we have a partition of , ,, ... , and . All approaches are trained with standard stochastic gradient descent (SGD). The learning rate is initially set to 0.001 and is decreased by  when the training error stagnates.
	
	\vspace{-10pt}
	\paragraph{Observations}
	According to Figure~\ref{fig:simulated_d_t}, it can be observed that both regression and classification baselines work well in the range of the closed set (), but the counting error increases rapidly when counts are larger than . This suggests a conventional counting model learned in a closed set cannot generalize to the open set. However, S-DCNet can achieve accurate predictions even on the open set, which confirms the advantage of S-DC.


	
	\begin{figure}[t]
		\begin{center}
			\includegraphics[width=\linewidth]{simulated_dataset_and_train.jpg}
		\end{center}
		\vspace{-10pt}
		\caption{A toy-level justification. \textbf{(a)} Some  images in the simulated cell counting dataset. The numbers denote the range of local counts of  sub-regions. \textbf{(b)} The mean absolute error (MAE) of different methods versus  sub-region counts. 
S-DCNet(N) means -stage S-DCNet.}
		\label{fig:simulated_d_t}
		\vspace{-10pt}
	\end{figure}
	
	
	\section{Experiments on Real-World Datasets}
	
	Extensive experiments are further conducted to demonstrate the effectiveness of S-DCNet on real-world datasets. We first describe some essential implementation details. After that, an ablation study is conducted on the ShanghaiTech Part\_A~\cite{MCNN_2016_CVPR} dataset to highlight the benefit of S-DC. Finally, we compare S-DCNet against current state-of-the-art methods on five public datasets. Mean Absolute Error (MAE) and Root Mean Squared Error (MSE) are used as the evaluation metrics following~\cite{MCNN_2016_CVPR}.
	


	\subsection{Implementation Details}
	
\paragraph{Interval Partition}\label{One_two_linear}
	
	We generate ground-truth counts of local patches by integrating over the density maps. The counts are usually not integers, because objects can partly present in cropped local patches. We evaluate two different partition strategies. In the first partition, we choose  as the step and generate partitions as , ,, ... , and , where  denotes the maximum count of the closed set. This partition is named as \texttt{One-Linear Partition}.
	
	In the second partition, we further finely divide the sub-interval , because this interval contains a sudden change from no object to part of an object, and a large proportion of objects lie in this sub-interval. A small step of  is used to divide this interval. We call this partition \texttt{Two-Linear Partition}.  
	


	
	\vspace{-10pt}
	\paragraph{Data Augmentation}
	We follow the same data augmentation used in~\cite{CSRNet_2018_CVPR}, except for the UCF-QNRF dataset~\cite{Compose_Loss_2018_ECCV}. In particular,  sub-images of  resolution are cropped from the original image. The first  sub-images are from four corners, and the remaining  are randomly cropped. Random scaling and mirroring are also performed. For the UCF-QNRF dataset~\cite{Compose_Loss_2018_ECCV}, we follow the same setting as in~\cite{Compose_Loss_2018_ECCV} and crop the original image into  sub-images.
	
	\vspace{-10pt}
	\paragraph{Training Details}
	S-DCNet is implemented with \texttt{PyTorch}. We train S-DCNet using standard SGD. The encoder in S-DCNet is directly adopted from convolutional layers of VGG16~\cite{Simonyan2014Very_VGG16} pretrained on ImageNet, and the other layers employ random Gaussian initialization with a standard deviation of . The learning rate is initially set to  and is decreased by  when the training error stagnates. We keep training until convergence. For the ShanghaiTech, UCF\_CC\_50, TRANCOS and MTC datasets, the batch size is set to . For the UCF-QNRF dataset, the batch size is set to 16 following~\cite{Compose_Loss_2018_ECCV}. 
	
	\subsection{Ablation Study on the ShanghaiTech Part\_A}
\paragraph{Is S-DCNet Robust to ?}


When reformulating the counting problem into classification, a critical issue is how to choose , which defines the closed set. Hence, it is important that S-DCNet is robust to the choice of .
	
	We conduct a statistical analysis on count values of local patches in the training set, and then set  with the quantiles ranging from  to  (decreased by ). Two-stage S-DCNet is evaluated. Another baseline of classification without S-DC is also used to explore whether counting can be simply modeled in a closed-set classification manner. To be specific, we reserve the VGG16 encoder and the classifier in this classification baseline.
	
	Results are presented in Figure~\ref{fig:mae_versus_cmax}. It can be observed that the MAE of the classification baseline increases rapidly with decreased . This result is not surprising, because the model is constrained to be visible to count values not greater than .  This suggests that counting cannot be simply transformed into closed-set classification. However, with the help of S-DC, S-DCNet exhibits strong robustness to the changes of . It seems the systematic error brought by  can somewhat be alleviated with S-DC. 
	Regarding how to choose concrete , the maximum count of the training set seems not the best choice, while some small quantiles even deliver better performance. Perhaps a model is only able to count objects accurately within a certain degree of denseness. We also notice \texttt{Two-Linear Partition} is slightly better than \texttt{One-Linear Partition}, which indicates that the fine division to the  sub-interval has a positive effect.


	\begin{figure}[t]
		\begin{center}
\includegraphics[width=0.8\linewidth]{mae_versus_quantiles.jpg}
		\end{center}
		\vspace{-10pt}
		\caption{The influence of  to S-DCNet on the ShanghaiTech Part\_A dataset~\cite{MCNN_2016_CVPR}. 
The numbers in the brackets denote quantiles of the training set, for example,  () means the  quantile is . `VGG16~Encoder' is the classification baseline without \mbox{S-DC}. 
`One-Linear' and `Two-Linear' are defined in Section~\ref{One_two_linear}.}
		\label{fig:mae_versus_cmax}
		\vspace{-10pt}
	\end{figure}
	
	\begin{figure*}
		\begin{minipage}{\textwidth}
			
\makeatletter\def\@captype{table}\makeatother
			\begin{minipage}{.23\textwidth}
				\centering
				\footnotesize
				\begin{tabular}{|c|c|c|}
					\hline
					Division time & MAE &MSE\\
					\hline
					0 & 76.0 & 142.5\\		  
					1 & 62.2 & 103.4\\
					2 & \textbf{58.3} & \textbf{95.0}\\
					3 & 60.1 & 99.8\\	 
					4 & 61.9 & 107.2\\
					\hline
				\end{tabular}
				\vspace{1pt}
				\caption{Results of S-DCNet with different S-DC stages. The best performance is boldfaced.\newline}
				\label{tab:div_time}
\end{minipage}
			\hfill
\makeatletter\def\@captype{table}\makeatother
			\begin{minipage}{.34\textwidth}
				\centering
				\footnotesize
				\begin{tabular}{|l|c|c|c|c|c|c|c|}
					\hline
					Method           & MAE &MSE\\
					\hline
					
					classification   & 77.4 &  149.3  \\   
					regression       & 68.9 & 112.1   \\
					open-set regression + S-DC & 66.6 & 107.9	   \\  
					closed-set regression + S-DC  &64.7  & 105.7   \\ \hline
					S-DCNet (2)      & \textbf{58.3} & \textbf{95.0}\\
					
					\hline
				\end{tabular}
				\vspace{5pt}
				\caption{Effect of S-DC. Two classification and regression baselines are compared against S-DCNet. S-DCNet (2) denotes two-stage S-DCNet. The best performance is boldfaced.}
\label{tab:reg_cls_div} 
			\end{minipage}
			\hfill
\makeatletter\def\@captype{table}\makeatother
			\begin{minipage}{.34\textwidth}
				\centering
				\footnotesize
				\addtolength{\tabcolsep}{4.5pt}
				\begin{tabular}{|c|c|c|c|}
\hline
					  &   & MAE   &MSE\\
					\hline
					&\checkmark& 301.4& 396.9  \\
					\checkmark&          &88.4	 & 128.8   \\
					\checkmark &\checkmark& \textbf{58.3} & \textbf{95.0}\\
					
					\hline
				\end{tabular}
				\vspace{5pt}
				\caption{Effect of different loss functions. Note that, multi-stage predictions are averaged if  is not applied, because the division decider cannot receive supervision signal during training. The best performance is boldfaced.\newline}
\label{tab:loss_ablation} 
			\end{minipage}
			
		\end{minipage}
		\vspace{-10pt}
	\end{figure*}
	
	According to the above results, S-DCNet is robust to  in a wide range of values, and  is generally encouraged to be set less than the maximum count value observed. In addition, there is no significant difference between two kinds of partitions. For simplicity, we set  to be the  quantile and adopt \texttt{Two-Linear Partition} in the following experiments.
	
	\vspace{-10pt}
	\paragraph{How Many Times to Divide?}
S-DCNet can apply S-DC up to  times, but how many times are sufficient? Here we evaluate S-DCNet with different division stages. Quantitative results are listed in Table~\ref{tab:div_time}. It can be observed that applying two-stage S-DC is clearly adequate.
	
	\vspace{-10pt}
	\paragraph{The Effect of S-DC}
	To highlight the effect of S-DC, we compare S-DCNet against several regression and classification baselines. These baselines adopt the same architecture of VGG16 encoder and the classifier in S-DCNet. \textit{classification} is the result of  without S-DC, and  is set to be the  quantile (). For all regression baselines, we modify the output channel of the classifier to be  and employ the  loss. We set three regression baselines. \textit{regression} predicts counts without S-DC. To justify whether S-DC can also work in regression, we adapt the S-DC idea to regression under both open-set and closed-set settings. \textit{open-set regression + S-DC} is straight-forward. We do not limit the output range, and it can vary from  to . \textit{closed-set regression + S-DC} indicates that the output range is constrained within  ( is set to  for a fair comparison), and large outputs will be clipped to .
	
	Results are shown in Table~\ref{tab:reg_cls_div}. We can see that counting by classification without S-DC suffers from the limitation of  and performs even worse than regression. In addition, regression can also benefit from S-DC, and it is encouraged to limit the output range of the regressor in a closed set. Moreover, with S-DC, S-DCNet significantly reduces the counting error and outperforms both the classification and regression baselines by a large margin. This verifies our argument that it is more effective to reformulate counting in classification than in regression. Perhaps the optimization is easier and less sensitive to sample imbalance in classification than in regression. Whatever, at least one thing is made clear: a counting model can learn from a closed set and generalize well to a open set via S-DC.
	






	






	We further analyze the counting error of  local patches in detail. As shown in Figure~\ref{fig:patch_div_err}, we observe that the direct single-branch prediction without S-DC (predicting ,  and  from ,  and , respectively) performs worse than the regression baseline, which can be attributed to the limited  of the classifier. After embedding the S-DC strategy to divide and merge the count map of multiple resolutions, counting errors significantly reduce. Such a benefit is even much obvious in dense patches with local counts greater than . It justifies our argument that, instead of regressing a large count value directly, it is more accurate to count dense patches through S-DC. 
	
\begin{figure}[t]
		\begin{center}
\includegraphics[width=0.8\linewidth]{Patch_div_err.jpg}
		\end{center}
		\vspace{-10pt}
		\caption{Counting errors of  local patches on the test set of ShanghaiTech Part\_A~\cite{MCNN_2016_CVPR}.  denotes direct local counts regression using VGG16. ,  and  are single-branch predictions conditioned on ,  and , respectively.  denotes two-stage S-DCNet, which fuses the predictions of ,  and  with S-DC.}
		\label{fig:patch_div_err}
		\vspace{-10pt}
	\end{figure}
	




	\vspace{-10pt}
	\paragraph{Loss Functions Also Matter}
	We further validate the effect of different loss functions used in S-DCNet and report the results in Table~\ref{tab:loss_ablation}. S-DCNet works poorly when trained with only . This is not surprising, because no supervision signal is provided to multi-stage division results. In addition, it seems necessary for the division decider to decide where to divide, because S-DCNet greatly benefits from the help of merging loss .
	
	Through the visualizations of s in Fig.~\ref{fig:w_visual}, we observe that reasonably good divisions can be achieved with the supervision of . This has another benefit, the network can learn when to divide not just in counts larger than .
	
	\begin{figure}[!t]
		\begin{center}
\includegraphics[width=1.0\linewidth]{visual_w.jpg}
		\end{center}
		\vspace{-10pt}
		\caption{Visualizations of s in S-DCNet. The brighter the image is, the greater the values are. In the input image, count values greater than  are indicated by yellow regions. It is clear that  appropriately identifies regions to be divided.}
		\label{fig:w_visual}
	\end{figure}
	
	
	


	
	\subsection{Comparison with State of the Art}
According to the ablation study, the final configurations for S-DCNet are summarized in Table~\ref{tab:compare_setting}. Qualitative results are shown in the Supplement.
	
	
	\begin{table}\footnotesize
		\centering
		\addtolength{\tabcolsep}{4pt}
		\begin{tabular}{|l|c|c|c|c|}
			\hline
			Dataset &  &max& Gaussian kernel\\
			\hline
			SH Part\_A~\cite{MCNN_2016_CVPR}&22.0	& 148.5 &\multirow{3}{*}{Geometry-Adaptive}\\ \cline{1-3} 
			UCF\_CC\_50~\cite{UCFCC50_2013_CVPR}&  &  &\\	\cline{1-3} 
			UCF-QNRF~\cite{Compose_Loss_2018_ECCV}& 8.0 & 131.5& \\ \cline{1-4}
			SH Part\_B~\cite{MCNN_2016_CVPR}& 7.0 & 83.0&  Fixed: \\ \cline{1-4}
			Trancos~\cite{TRANCOSdataset_IbPRIA2015}& 5.0 & 24.5& Fixed: \\	   \cline{1-4}
			MTC~\cite{Lu2017TasselNet}& 3.5 & 8.0& Fixed: \\	   \cline{1-4}
			\hline
			Partition& \multicolumn{3}{c|}{Two-Linear}\\ \cline{1-4}
			Type of~ &\multicolumn{3}{c|}{ quantile}\\ \cline{1-4}
			\hline
		\end{tabular}
		\vspace{5pt}
		\caption{Overall configurations of S-DCNet.  denotes the maximum count of local patch in the training set, while  is the maximum count set for the closed set in S-DCNet.  is used to generate density maps from dotted annotations. Specially, since UCF\_CC\_50 adopts 5-fold cross-validation,  and  are set differently for each fold.}
		\label{tab:compare_setting}
		\vspace{-10pt}
	\end{table} 
	
	
	\begin{figure*}
		\begin{minipage}{\textwidth}
			
\makeatletter\def\@captype{table}\makeatother
			\begin{minipage}{.38\textwidth}
				\centering
				\footnotesize
				\begin{tabular}{|l|c|c|c|c|}
					\hline
					&\multicolumn{2}{c|}{Part A} &
					\multicolumn{2}{c|}{Part B}\\
					\hline
					Method & MAE &MSE& MAE &MSE\\
					\hline
					Zhang \textit{et~al.}~\cite{Zhang_2015_CVPR}&181.8&277.7&32.0&49.8\\
CP-CNN~\cite{CPCNN_2017_ICCV} &73.6 & 106.4 &20.1&30.1\\
					D-ConvNet~\cite{DeepNegCor_2018_CVPR} &73.5	&112.3&18.7	&26.0\\
					IG-CNN~\cite{Divide_grow_2018_CVPR}&72.5	&118.2	&13.6&21.1\\
					DRSAN~\cite{DRSAN2018Crowd}&69.3	&96.4 &11.1&18.2\\
					CSRNet~\cite{CSRNet_2018_CVPR}&68.2 & 115.0 &10.6&16.0\\
					SANet~\cite{SANet_2018_ECCV}&67.0	&104.5 &8.4&13.6\\
					SPN~\cite{SPN_2019_WACV}&61.7&99.5&9.4&14.4\\
\hline
					S-DCNet & \textbf{58.3} & \textbf{95.0}& \textbf{6.7}	  & \textbf{10.7}  \\	   
					\hline
				\end{tabular}  
				\vspace{5pt}
				\caption{Comparison with state-of-the-art approaches on the test set of ShanghaiTech~\cite{MCNN_2016_CVPR} dataset. The best performance is boldfaced.}
				\label{tab:compare_SHAB}
			\end{minipage}
			\hfill
\makeatletter\def\@captype{table}\makeatother
			\begin{minipage}{.25\textwidth}
				\centering
				\footnotesize
				\begin{tabular}{|l|c|c|}
					\hline
					Method & MAE &MSE\\
					\hline
					Idrees\textit{et~al.}~\cite{UCFCC50_2013_CVPR}&468.0&590.3\\
					Zhang\textit{et~al.}~\cite{Zhang_2015_CVPR}&467.0&498.5\\
					IG-CNN~\cite{Divide_grow_2018_CVPR}&291.4&349.4\\
					D-ConvNet~\cite{DeepNegCor_2018_CVPR}&288.4&404.7\\
					CSRNet~\cite{CSRNet_2018_CVPR}&266.1& 397.5\\
					
					SANet~\cite{SANet_2018_ECCV}&258.4	&334.9\\
					DRSAN~\cite{DRSAN2018Crowd}&219.2	&\textbf{250.2}\\
\hline
					S-DCNet & \textbf{204.2} & 301.3\\
					
					\hline
				\end{tabular}
				\vspace{0pt}
				\caption{Comparison with state-of-the-art approaches on the test set of UCF\_CC\_50~\cite{UCFCC50_2013_CVPR} dataset. The best performance is boldfaced.\newline}
				\label{tab:compare_UCF_CC}    
			\end{minipage}
			\hfill
\makeatletter\def\@captype{table}\makeatother
			\begin{minipage}{.30\textwidth}
				\centering
				\footnotesize
				\begin{tabular}{|l|c|c|}
					\hline
					Method & MAE &MSE\\
					\hline
					Idrees\textit{et~al.}~\cite{UCFCC50_2013_CVPR}&315&508\\
					MCNN~\cite{MCNN_2016_CVPR}&277&426\\
					Encoder-Decoder~\cite{En_De2017segnet}& 270 &478\\
					CMTL~\cite{CMTL2017CNN}&252&514\\
					Switching-CNN~\cite{SwitchCNN_2017_CVPR}&228&445\\
					Base Network~\cite{Compose_Loss_2018_ECCV}& 163& 227\\
					Composition Loss~\cite{Compose_Loss_2018_ECCV}&132&191\\
					\hline
					S-DCNet & \textbf{104.4}&\textbf{176.1}	\\
					
					\hline
				\end{tabular}
				\vspace{5pt}
				\caption{Comparison with state-of-the-art approaches on the test set of UCF-QNRF~\cite{Compose_Loss_2018_ECCV} dataset. The best performance is boldfaced.\newline}
				\label{tab:compare_UCF-QNRF}    
			\end{minipage}
			\vfill
			\vspace{5pt}
\makeatletter\def\@captype{table}\makeatother
			\begin{minipage}{.5\textwidth}
				\centering
				\footnotesize
				\addtolength{\tabcolsep}{2pt}
				\begin{tabular}{|l|c|c|c|c|}
					\hline
					Method &GAME(0) &GAME(1)&GAME(2)&GAME(3)\\
					\hline
CCNN~\cite{O2016Towards_CCNN}&12.49 &16.58 &20.02 &22.41\\
					Hydra-3s~\cite{O2016Towards_CCNN}&10.99 &13.75 &16.69 &19.32\\
					CSRNet~\cite{CSRNet_2018_CVPR}&3.56 &5.49 &8.57 &15.04\\
					SPN~\cite{SPN_2019_WACV}&3.35 &4.94 &6.47 &9.22\\
					\hline
					S-DCNet & \textbf{2.92} &\textbf{4.29} &\textbf{5.54} &\textbf{7.05}\\
					\hline
				\end{tabular}
				\vspace{0pt}
				\caption{Comparison with state-of-the-art approaches on the test set of TRANCOS~\cite{TRANCOSdataset_IbPRIA2015} dataset. The best performance is boldfaced.}
				\label{tab:compare_Trancos}    
			\end{minipage}
			\hfill
\makeatletter\def\@captype{table}\makeatother
			\begin{minipage}{.46\textwidth}
				\centering
				\footnotesize
				\addtolength{\tabcolsep}{2pt}
				\begin{tabular}{|l|c|c|}
					\hline
					Method & MAE &MSE\\
					\hline
					
GlobalReg~\cite{tota2015counting}             & 19.7 & 23.3\\
					DensityReg~\cite{vlaz2010denlearn}             & 11.9 & 14.8\\
					CCNN~\cite{O2016Towards_CCNN}                  & 21.0 & 25.5\\
					TasselNet~\cite{Lu2017TasselNet}		       & 6.6 & 9.6\\
					\hline
					S-DCNet & \textbf{5.6} &\textbf{9.1}\\
					\hline
				\end{tabular}
				\vspace{5pt}
				\caption{Comparison with state-of-the-art approaches on the test set of MTC~\cite{Lu2017TasselNet} dataset. The best performance is boldfaced.}
				\label{tab:compare_MTC}    
			\end{minipage}
			\hfill
			
			
		\end{minipage}
		\vspace{-10pt}
	\end{figure*}
	
	
	
	\vspace{-10pt}
	\paragraph{The ShanghaiTech Dataset}
	The ShanghaiTech crowd counting dataset~\cite{MCNN_2016_CVPR} is consisted of two parts: Part\_A and Part\_B. Part\_A includes  images for training and  for testing. This part represents highly congested scenes. Part\_B contains  images in relatively sparse scenes, where  images are used for training and  for testing. Quantitative results are listed in Table~\ref{tab:compare_SHAB}. Our method outperforms the previous state-of-the-art SPN~\cite{SPN_2019_WACV} and SANet~\cite{SANet_2018_ECCV} with a  relative improvement in Part\_A and  in Part\_B, respectively. These results suggest S-DCNet is able to adapt to both sparse and crowded scenes. 
	
\iffalse
	\begin{table}\footnotesize
		\begin{center}
			\begin{tabular}{|l|c|c|c|c|}
				\hline
				&\multicolumn{2}{c|}{Part A} &
				\multicolumn{2}{c|}{Part B}\\
				\hline
				Method & MAE &MSE& MAE &MSE\\
				\hline\hline
				Zhang \textit{et~al.}~\cite{Zhang_2015_CVPR}&181.8&277.7&32.0&49.8\\
CP-CNN~\cite{CPCNN_2017_ICCV} &73.6 & 106.4 &20.1&30.1\\
				D-ConvNet~\cite{DeepNegCor_2018_CVPR} &73.5	&112.3&18.7	&26.0\\
				IG-CNN~\cite{Divide_grow_2018_CVPR}&72.5	&118.2	&13.6&21.1\\
				DRSAN~\cite{DRSAN2018Crowd}&69.3	&96.4 &11.1&18.2\\
				CSRNet~\cite{CSRNet_2018_CVPR}&68.2 & 115.0 &10.6&16.0\\
				SANet~\cite{SANet_2018_ECCV}&67.0	&104.5 &8.4&13.6\\
				SPN~\cite{SPN_2019_WACV}&61.7&99.5&9.4&14.4\\
S-DCNet (ours) & \textbf{58.3} & \textbf{95.0}& \textbf{6.7}	  & \textbf{10.7}  \\	   
				\hline
			\end{tabular}
		\end{center}
		\caption{Comparison with State-of-the-Art Counting Approaches on the Test Set of ShanghaiTech~\cite{MCNN_2016_CVPR} dataset. The best performance is boldfaced.}
		\label{tab:compare_SHAB}
	\end{table}  
	\fi


	\vspace{-10pt}
	\paragraph{The UCF\_CC\_50 Dataset}
	
	UCF\_CC\_50~\cite{UCFCC50_2013_CVPR} is a tiny crowd counting dataset with  images in extremely crowded scenes. The number of people within an images varies from  to . We follow the 5-fold cross-validation as in~\cite{UCFCC50_2013_CVPR}. Results are shown in Table~\ref{tab:compare_UCF_CC}. Our method surpasses the previous best method, DRSAN~\cite{DRSAN2018Crowd}, with a  relative improvement in \textit{MAE}.

\iffalse
	\begin{table}\footnotesize
		\begin{center}
			\begin{tabular}{|l|c|c|}
				\hline
				Method & MAE &MSE\\
				\hline\hline
				Idrees\textit{et~al.}~\cite{UCFCC50_2013_CVPR}&468.0&590.3\\
				Zhang\textit{et~al.}~\cite{Zhang_2015_CVPR}&467.0&498.5\\
				IG-CNN~\cite{Divide_grow_2018_CVPR}&291.4&349.4\\
				D-ConvNet~\cite{DeepNegCor_2018_CVPR}&288.4&404.7\\
				CSRNet~\cite{CSRNet_2018_CVPR}&266.1& 397.5\\
				
				SANet~\cite{SANet_2018_ECCV}&258.4	&334.9\\
				DRSAN~\cite{DRSAN2018Crowd}&219.2	&\textbf{250.2}\\


				S-DCNet (ours) & \textbf{204.2} & 301.3\\
				
				\hline
			\end{tabular}
		\end{center}
		\caption{Comparison with State-of-the-Art Counting Approaches on the Test Set of UCF\_CC\_50~\cite{UCFCC50_2013_CVPR} dataset. The best performance is boldfaced.}
		\label{tab:compare_UCF_CC}
	\end{table} 
	\fi


	\vspace{-10pt}
	\paragraph{The UCF-QNRF Dataset} 
	UCF-QNRF~\cite{Compose_Loss_2018_ECCV} is a large crowd counting dataset with  high-resolution images and  million head annotations. There are  training images and  test images. It contains extremely congested scenes where the maximum count of an image can reach . We follow the same image processing as in~\cite{Compose_Loss_2018_ECCV} and report results in Table~\ref{tab:compare_UCF-QNRF}. Our method reaches the state-of-the-art performance and surpasses the previous best method with a  boost in \textit{MAE}. We surprisingly notice that S-DCNet only learn from a closed set with , which is only  of the maximum count  according to Table~\ref{tab:compare_setting}. S-DCNet, however, generalizes to large counts effectively and predicts accurate counts. 


\iffalse
	\begin{table}\footnotesize
		\begin{center}
			\begin{tabular}{|l|c|c|}
				\hline
				Method & MAE &MSE\\
				\hline\hline 
				Idrees\textit{et~al.}~\cite{UCFCC50_2013_CVPR}&315&508\\
				MCNN~\cite{MCNN_2016_CVPR}&277&426\\
				Encoder-Decoder~\cite{En_De2017segnet}& 270 &478\\
				CMTL~\cite{CMTL2017CNN}&252&514\\
				Switching-CNN~\cite{SwitchCNN_2017_CVPR}&228&445\\
				Base Network~\cite{Compose_Loss_2018_ECCV}& 163& 227\\
				Composition Loss~\cite{Compose_Loss_2018_ECCV}&132&191\\
				S-DCNet (ours) & \textbf{104.4}&\textbf{176.1}	\\
				
				\hline
			\end{tabular}
		\end{center}
		\caption{Comparison with State-of-the-Art Counting Approaches on the Test Set of UCF-QNRF~\cite{Compose_Loss_2018_ECCV} dataset. The best performance is boldfaced.}
		\label{tab:compare_UCF-QNRF}
	\end{table}  
	\fi


	\vspace{-10pt}
	\paragraph{The TRANCOS Dataset}
	Aside from crowd counting, we also evaluate S-DCNet on a vehicle counting dataset, TRANCOS~\cite{TRANCOSdataset_IbPRIA2015}, to see its generalization ability. TRANCOS contains  images of congested traffic scenes in various perspectives. It adopts the Grid Average Mean Absolute Error (GAME)~\cite{TRANCOSdataset_IbPRIA2015} as the evaluation metric.  divides an image into  non-overlapping sub-regions and accumulates of the  over sub-regions. Larger  implies better local predictions. In particular,  downgrades to . 
\iffalse
	which is defined as
	
	where  denotes the number of images.  and  are the predicted and ground-truth count of the -th sub-region, respectively. 
	\fi
	Results are listed in Table~\ref{tab:compare_Trancos}. S-DCNet surpasses other methods under all  metrics, and particularly, delivers a  relative improvement on . This suggests S-DCNet not only achieves accurate global predictions but also behaves well in local regions. 
	
\iffalse
	\begin{table}\footnotesize
		\begin{center}
			
			\begin{tabular}{|l|c|c|c|c|}
				\hline
				Method &GAME(0) &GAME(1)&GAME(2)&GAME(3)\\
				\hline\hline
CCNN~\cite{O2016Towards_CCNN}&12.49 &16.58 &20.02 &22.41\\
				Hydra-3s~\cite{O2016Towards_CCNN}&10.99 &13.75 &16.69 &19.32\\
				CSRNet~\cite{CSRNet_2018_CVPR}&3.56 &5.49 &8.57 &15.04\\
				SPN~\cite{SPN_2019_WACV}&3.35 &4.94 &6.47 &9.22\\
				S-DCNet (ours) & \textbf{2.92} &\textbf{4.29} &\textbf{5.54} &\textbf{7.05}\\
				
				\hline
			\end{tabular}
		\end{center}
		\caption{Comparison with State-of-the-Art Counting Approaches on the Test Set of TRANCOS~\cite{TRANCOSdataset_IbPRIA2015} dataset. The best performance is boldfaced.}
		\label{tab:compare_Trancos}
	\end{table}
	\fi


	\vspace{-10pt}
	\paragraph{The MTC Dataset}
	We further evaluate our method on a plant counting dataset, i.e., the MTC dataset~\cite{Lu2017TasselNet}. The MTC dataset contains  high-resolution images of maize tassels collected from 2010 to 2015 in the wild field. In contrast to people or vehicles that have similar physical sizes, maize tassels are with heterogeneous physical sizes and are self-changing over time. We think this dataset is suitable for justifying the robustness of S-DCNet to object-size variations. We follow the same setting as in~\cite{Lu2017TasselNet} and report quantitative results in Table~\ref{tab:compare_MTC}. Although the previous best method, TasselNet~\cite{Lu2017TasselNet}, already exhibits accurate results, S-DCNet still shows a certain degree of improvement. 
	
\iffalse\begin{table}\footnotesize
		\begin{center}
			\begin{tabular}{|l|c|c|}
				\hline
				Method & MAE &MSE\\
				\hline\hline
				
GlobalReg~\cite{tota2015counting}             & 19.7 & 23.3\\
				DensityReg~\cite{vlaz2010denlearn}             & 11.9 & 14.8\\
				CCNN~\cite{O2016Towards_CCNN}                  & 21.0 & 25.5\\
				TasselNet~\cite{Lu2017TasselNet}		       & 6.6 & 9.6\\
				S-DCNet (ours) & \textbf{5.6} &\textbf{9.1}\\
				
				\hline
			\end{tabular}
		\end{center}
		\caption{Comparison with State-of-the-Art Counting Approaches on the Test Set of MTC~\cite{Lu2017TasselNet} dataset. The best performance is boldfaced.}
		\label{tab:compare_MTC}
	\end{table}
	\fi




	\section{Conclusion}
	Counting is an open-set problem in theory, but only a finite closed set can be observed in reality. This is particularly true because any dataset is always a sampling of the real world. Inspired by the decomposable property of counting, we propose to transform the open-set counting into a closed-set problem, and address the problem with the idea of S-DC. We realize S-DC in a deep counting network termed S-DCNet. We show through a toy experiment and extensive evaluations on standard benchmarks that, even given a closed training set, S-DCNet can effectively generalize to open-set scenarios.
	
	For future work, we will test the adaptability of S-DC on other network architectures.


	\vspace{-10pt}
	\paragraph{Acknowledgements}
	This work was supported by the Natural Science Foundation of China under Grant No. 61876211.
	
	
	{\small
		\bibliographystyle{ieee_fullname}
		\bibliography{egbib}
	}

\section{Supplementary Materials}
	In this Supplement, we provide further clarifications and discussions on the motivation of S-DCNet, compare S-DCNet with other related ideas, and show qualitative results on evaluated datasets.

\subsection{The Open-Set Problem of Density Maps}
Density maps are actually in the open set as well. As shown in Fig.~\ref{fig:toy_exp}(b) (top), for a single point, different kernel sizes lead to different density values. When multiple objects exist and are close, density patterns are even much diverse as in Fig.~\ref{fig:toy_exp}(b) (bottom). Since observed samples are limited, density maps are certainly in an open set.

We add another baseline of CSRNet~\cite{CSRNet_2018_CVPR} to the toy experiment in Fig.~\ref{fig:toy_exp}(a). CSRNet also performs worse than S-DCNet in the open set (), which implies the open-set problem also exists in density map based methods.

Furthermore, density map cannot be used in S-DCNet, because it is not spatially divisible. This is determined by its physical definition. However, local counts can. Thus we adopt local counts in S-DCNet rather than density maps.

\begin{figure}[!ht]
	\begin{center}
\includegraphics[width=0.60\linewidth]{densitymap_openset_toy.jpg}
	\end{center}
	\vspace{-10pt}
	\caption{(a) The toy-level experiment with an extra ``CSRNet'' baseline. (b) Density values along one axis with various kernels (top), and with two kernels with different relative distances.}
	\label{fig:toy_exp}
	\vspace{-15pt}
\end{figure}

\subsection{Relation to Other Methods}
\paragraph{IG-CNN~\cite{Divide_grow_2018_CVPR}}
IG-CNN drew inspirations from ensemble learning and trained a series of networks to tackle different scenes. While our S-DCNet focuses on inducing and utilizing physical laws, such as the “open set” problem in counting and the spatial divisibility of local counts. We propose to transform the open-set counting into a closed-set problem via spatial divide-and-conquer.  

\paragraph{Attention Mechanisms}
Despite it is possible to provide explicit supervision to , we find that S-DCNet already can produce reasonably good divisions with the implicit supervision provided by . This has another benefit, the network can learn when to divide not just in counts larger than . The visualizations of s in Fig.~\ref{fig:w_visual} further justify our point. To highlight the difference against attention, we remove the division decider and generate a three-channel output conditioned on , then process it with softmax to obtain . The final count is merged as . In SHTech PartA, it has   and   (worse than S-DCNet). As per the visualization of  in Fig.~\ref{fig:w_visual}, we find the attention only focuses on the highest resolution and no effect of division is observed. In addition, S-DCNet executes fusion progressively, while attention fuses the prediction in a single step.

\begin{figure}[!ht]
	\begin{center}
\includegraphics[width=0.65\linewidth]{w_SDC_att.jpg}
	\end{center}
	\vspace{-15pt}
	\caption{Visualization of  for S-DCNet (top) and the attention baseline (bottom). The lighter the image is, the greater the values are. In the input image, count values greater than  are indicated by yellow regions.}
	\label{fig:w_visual}
	\vspace{-15pt}
\end{figure}


\subsection{Further Discussions on S-DCNet}
\paragraph{The necessity to distinguish counting task into open set and closed set scenarios}
One may raise the concern like: the relevance of distinguishing counting to an open set and closed set is unnecessary if each data point (head) is treated separately and the network learns to count each data point. If the network can count each head well, counting should already be addressed by detection networks. However, detection performs poorly when objects seriously overlap. This is why the notion of density map is introduced in~\cite{vlaz2010denlearn}, and density-based networks beat detection networks in counting. 
It is thus not suitable to treat each point separately, and distinguishing counting to an open set and closed set makes sense.
\paragraph{Generating ground-truth local counts}
Generating local counts directly from point annotations does not take partial objects cropped in patches into account. Density maps naturally tackle this situation. Thus we generate ground-truth counts of local patches by integrating over the density maps. This strategy is only utilized during training, while the point annotations are still used to calculate errors during validation.
\paragraph{If one position in  is , which means the initial prediction should not be replaced. Is it possible that the same position in  is ?}
In theory, it is possible, because each division decision is independent. However, in practice, we do not observe such a behaviour of  (Fig.~\ref{fig:w_visual}). Even this situation appears, we do not think it will be a problem.  gives the second chance for division if the division decider makes a wrong decision in .
\paragraph{Why  is performing much worse than  and  in S-DCNet?}
,  and  are trained jointly in S-DCNet and greatly influenced by the loss of . As shown in Fig.~\ref{fig:w_visual},  focus on local patches with high density, which means  will push  to predict well on these patches and ignore others. High density patches, however, only occupy a small fraction.  thus tends to predict worse than  and . This may also explain why three-stage/four-stage S-DCNet performs worse than two-stage S-DCNet.

\subsection{Qualitative Results of S-DCNet}
We present some qualitative results of two-stage S-DCNet on five benchmarks (ShanghaiTech, UCF\_CC\_50, UCF-QNRF, TRANCOS and MTC) in Fig.~\ref{fig:SHA_res} to~\ref{fig:MTC_res}. S-DCNet predicts the local count map conditioned on the input image, where each element denotes a count value of the corresponding  local area. Meanwhile, since the output stride of S-DCNet is , we pad the original image with zeros to ensure that the length and width are multiples of . 


\begin{figure*}[th]
	\begin{center}
\includegraphics[width=0.8\linewidth]{SHA_res.jpg}
	\end{center}
\caption{Some samples generated by S-DCNet from the test set of ShanghaiTech Part\_A dataset. The left column shows the original images, while the middle and right columns display the ground truth and predicted count maps respectively.}
	\label{fig:SHA_res}
	\vspace{-10pt}
\end{figure*}


\begin{figure*}[th]
	\begin{center}
\includegraphics[width=0.8\linewidth]{SHB_res.jpg}
	\end{center}
\caption{Some samples generated by S-DCNet from the test set of ShanghaiTech Part\_B dataset. The left column shows the original images, while the middle and right columns display the ground truth and predicted count maps respectively.}
	\label{fig:SHB_res}
	\vspace{-10pt}
\end{figure*}

\begin{figure*}[th]
	\begin{center}
\includegraphics[width=0.8\linewidth]{UCF_CC_50_res.jpg}
	\end{center}
\caption{Some samples generated by S-DCNet from the test set of UCF\_CC\_50 dataset. The left column shows the original images, while the middle and right columns display the ground truth and predicted count maps respectively.}
	\label{fig:UCFCC50_res}
	\vspace{-10pt}
\end{figure*}


\begin{figure*}[th]
	\begin{center}
\includegraphics[width=0.8\linewidth]{UCQF_res.jpg}
	\end{center}
\caption{Some samples generated by S-DCNet from the test set of UCF-QNRF dataset. The left column shows the original images, while the middle and right columns display the ground truth and predicted count maps respectively.}
	\label{fig:UCQF_res}
	\vspace{-10pt}
\end{figure*}

\begin{figure*}[th]
	\begin{center}
\includegraphics[width=0.8\linewidth]{TRANCOS_res.jpg}
	\end{center}
\caption{Some samples generated by S-DCNet from the test set of TRANCOS dataset. The left column shows the original images, while the middle and right columns display the ground truth and predicted count maps respectively.}
	\label{fig:TRANCOS_res}
	\vspace{-10pt}
\end{figure*}

\begin{figure*}[th]
	\begin{center}
\includegraphics[width=0.8\linewidth]{MTC_res.jpg}
	\end{center}
\caption{Some samples generated by S-DCNet from the test set of MTC dataset. The left column shows the original images, while the middle and right columns display the ground truth and predicted count maps respectively.}
	\label{fig:MTC_res}
	\vspace{-10pt}
\end{figure*}

	
\end{document}
