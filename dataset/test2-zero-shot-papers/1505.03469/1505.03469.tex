\documentclass[11pt]{article}

\usepackage{fullpage,verbatim,amsmath,amssymb,amsthm,float,color}
\usepackage[utf8]{inputenc}
\usepackage{setspace}

\ifx\pdftexversion\undefined
  \usepackage[dvips]{graphicx}
\else
  \usepackage[pdftex]{graphicx}
  \DeclareGraphicsRule{*}{mps}{*}{}
\fi




\setstretch{0.95}


\newtheorem{lemma}{Lemma}
\newtheorem{claim}{Claim}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}


\floatstyle{ruled}
\newfloat{algorithm}{thp}{lop}
\floatname{algorithm}{Algorithm}




\floatstyle{ruled}
\newfloat{algorithm}{thp}{lop}
\floatname{algorithm}{Algorithm}

\newcommand{\R}{\ensuremath{\mathcal{R}}}
\newcommand{\D}{\ensuremath{\mathcal{D}}}
\newcommand{\A}{\ensuremath{\mathcal{A}}}
\newcommand{\E}{\ensuremath{\mathcal{E}}}
\newcommand{\M}{\ensuremath{\mathcal{M}}}
\newcommand{\algA}{\ensuremath{\mathcal{A}}}
\newcommand{\correct}{\mathit{correct}}
\newcommand{\faulty}{\mathit{faulty}}
\newcommand{\N}{\mathbb{N}}

\newcommand{\C}{\ensuremath{\mathsf{C}}}
\newcommand{\EC}{\ensuremath{\mathsf{EC}}}
\newcommand{\EIC}{\ensuremath{\mathsf{EIC}}}
\newcommand{\ETOB}{\ensuremath{\mathsf{ETOB}}}
\newcommand{\TOB}{\ensuremath{\mathsf{TOB}}}
\newcommand{\ignore}[1]{}

\def\Time{\mathbb{T}}
\def\Patterns{\mathbb{F}}

\def\Om{\ensuremath{\Omega}}
\def\fd{failure detector}
\def\cfd{\ensuremath{?\P+\DS}}
\def\to{\rightarrow}

\def\Nat{\ensuremath{\mathbb{N}}}

\def\nnll{\refstepcounter{linenumber}\lf\thelinenumber:}

\def\get{\leftarrow}


\newcommand{\id}[1]{\mbox{\textit{#1}}}\newcommand{\res}[1]{\mbox{\textbf{#1}}}

\ignore{
\ifx\pdftexversion\undefined
  \usepackage[dvips]{graphicx}
\else
  \usepackage[pdftex]{graphicx}
  \DeclareGraphicsRule{*}{mps}{*}{}
\fi
}




\newcommand{\btb}{\begin{tabbing}}
\newcommand{\etb}{\end{tabbing}}

\newcommand{\be}{\begin{itemize}}
\newcommand{\ee}{\end{itemize}}
\newcommand{\bn}{\begin{enumerate}}
\newcommand{\en}{\end{enumerate}}

\newcommand{\bc}{\begin{center}}
\newcommand{\ec}{\end{center}}
\newcommand{\ul}{\underline}
\newcommand{\bs}{\bigskip}
\newcommand{\ms}{\medskip}
\renewcommand{\ss}{\smallskip}

\newcommand{\bfg}{\begin{figure}[th]}
\newcommand{\efg}{\end{figure}}

\newcommand{\etal}{et al.\ }





\newcommand{\compose}{\times}
\newcommand{\hide}{\setminus}
\newcommand{\projectaut}[2]{\project{#1}{#2}}
\newcommand{\pl}{\parallel}
\newcommand{\project}{\pj}
\newcommand{\proj}{\pj}
\newcommand{\pj}{\raisebox{0.2ex}{}}






\newcommand{\dec}[1]{\textit{dec}(#1)}
\newcommand{\init}[1]{\textit{init}(#1)}







\newcommand{\intrdef}{\emph}    \newcommand{\intr}[1]{\emph{#1\/}}              


\newcommand{\empi}[1]{\emph{#1\/}}              

\newcommand{\case}[1]{\textit{Case #1: }} 
\newcommand{\scase}[1]{\textit{Subcase #1: }} 
\newcommand{\sscase}[1]{\textit{Subsubcase #1: }} 
\newcommand{\ssscase}[1]{\textit{Subsubsubcase #1: }} 





\newcommand{\bigand}{\bigwedge}
\newcommand{\bigor}{\bigvee}
\newcommand{\UN}{\bigcup}
\newcommand{\ch}{\mbox{}}
\renewcommand{\d}{\, . \,}      \newcommand{\df}{\mbox{}}
\newcommand{\eqv}{\equiv}
\newcommand{\ex}{\exists}
\newcommand{\fa}{\forall}
\newcommand{\halfind}{\hspace*{1.5em}}
\newcommand{\ifof}{\Longleftrightarrow} \newcommand{\imp}{\Rightarrow}          \newcommand{\ind}{\hspace*{3.0em}}
\newcommand{\ints}{\cap}
\renewcommand{\l}{\ell}
\newcommand{\la}[1]{\mbox{}}

\newcommand{\lra}{\mbox{}}
\newcommand{\oneton}{\{1..n\}}
\newcommand{\pind}{\hspace*{3.0em}}
\newcommand{\s}{\mbox{}}
\newcommand{\sat}{\models}
\newcommand{\spc}{\mbox{\vspace{-0.25in}}}
\newcommand{\st}[2]{\mbox{}} \newcommand{\sub}{\subseteq}
\newcommand{\tl}[1]{\mbox{}}\newcommand{\tpl}[1]{\ensuremath{\langle #1 \rangle}}
\newcommand{\un}{\cup}
\newcommand{\up}{\raisebox{0.2ex}{}}
\newcommand{\dn}{\mbox{}}

\newcommand{\struct}[2]{\raisebox{-0.1in}{}}

\newcommand{\MIN}{\mathrm{MIN}}





\newenvironment{example}{\textbf{Example.}}{}





\newcommand{\I}{{\cal I}}

\newcommand{\lla}[2]{\mbox{}}
\newcommand{\Lla}[2]{\mbox{}}


\newcommand{\agent}[1]{\textit{agent}(#1)}
\newcommand{\receiver}[1]{\textit{receiver}(#1)}
\newcommand{\receive}[1]{\textit{receive}(#1)}



\newcommand{\acts}{\textit{acts}}
\newcommand{\esig}{\textit{esig}}
\newcommand{\exec}{\textit{exec}}
\newcommand{\ext}[1]{\textit{ext}(#1)}
\newcommand{\frag}{\textit{frag}}
\newcommand{\inp}{\textit{in}}
\renewcommand{\int}{\textit{int}}
\newcommand{\local}{\textit{local}}
\newcommand{\out}{\textit{out}}
\newcommand{\sig}{\textit{sig}}
\newcommand{\signal}{\kappa}
\newcommand{\start}{\textit{start}}
\newcommand{\states}{\textit{states}}
\newcommand{\steps}{\textit{steps}}
\newcommand{\trace}{\textit{trace}}
\newcommand{\traces}[1]{\textit{traces}(#1)}
\newcommand{\ltraces}[1]{\textit{livetraces}(#1)}

\newcommand{\bottom}{\perp}
\newcommand{\cat}{^\frown}

\newcommand{\lpsim}{\leq_F^\l}  \newcommand{\lpreorder}{\sqsubseteq_\l} \newcommand{\spreorder}{\sqsubseteq_s}  \newcommand{\simu}{\leq}




\newcommand{\first}[1]{\mathit{first}(#1)}   
\newcommand{\action}[1]{\mathit{action}(#1)}   
\newcommand{\last}[1]{\mathit{last}(#1)}   
\newcommand{\trans}[1]{\mathit{transition}(#1)}   

\newcommand{\sched}[1]{\mathit{schedule}(#1)}   
\newcommand{\sg}{\sigma}
\newcommand{\gm}{\gamma}
\newcommand{\task}[1]{\mathit{task}(#1)}   
\newcommand{\finitetraces}[1]{\mathit{finite\!-\!traces}(#1)}







\newcommand{\buffer}{\mathit{buffer}}
\newcommand{\buf}{\mathit{buffer}}
\newcommand{\compute}{\textit{compute}}
\newcommand{\dummy}{\mathit{dummy}}
\newcommand{\fail}{\mathit{fail}}
\newcommand{\failed}{\textit{failed}}
\newcommand{\query}{\textit{query}}
\newcommand{\head}{\textit{head}}
\newcommand{\glob}{\textit{glob}}
\newcommand{\invoke}{\textit{invoke}}                  
\newcommand{\invbuffer}{\textit{inv-buffer}}
\newcommand{\ib}{\textit{inv-buffer}}
\newcommand{\invs}{\textit{invs}}                  
\newcommand{\newval}{\textit{newval}}
\newcommand{\perform}{\textit{perform}}
\newcommand{\respbuffer}{\textit{resp-buffer}}                  
\newcommand{\rb}{\textit{resp-buffer}}                  
\newcommand{\response}{\textit{response}}     
\newcommand{\resps}{\textit{resps}}     
\newcommand{\service}[1]{\textit{service}(#1)}
\newcommand{\val}{\textit{val}}



\renewcommand{\P}{(P_1 \parallel \cdots \parallel P_n, O_1, \ldots, O_m, \A)}
\newcommand{\Pthree}{(P_1 \!\parallel\! P_2 \!\parallel\! P_3, O_1, \ldots, O_m, \A)}
\newcommand{\Ps}{P_1 \parallel \cdots \parallel P_n}    

\newcommand{\parts}[1]{\textit{participants}(#1)}





\newcommand{\agree}{\texttt{agree}}                     \newcommand{\al}{\alpha}                                \newcommand{\decide}[1]{\mbox{\textit{decide}()}}   \newcommand{\evS}{\diamond{\cal S}}                     \newcommand{\indist}[1]{\stackrel{#1}{\sim}}    
\newcommand{\incr}{\mathit{incr}}                       \newcommand{\inst}{\mathit{instance}}                   \newcommand{\jam}{\mathtt{jam}}                         \newcommand{\mininst}{\mathit{min\_inst}}               \newcommand{\op}{\mathtt{op}}                           \newcommand{\reducible}{\preceq}                \newcommand{\schedule}{\mathit{schedule}}   
\newcommand{\sticky}{\texttt{sticky}\xspace}



\newcommand{\pdecide}[1]{\texttt{pseudo-decide}()}









\newcommand{\ea}{\Diamond \Box} 





\newcommand{\alw}{\Box} \newcommand{\ev}{\Diamond} \newcommand{\nxt}{\bigcirc} 




























\def\ioisize{\footnotesize}


\newcommand{\ioi}[3]{\bgroup\ioisize \begin{tabbing}
XX\=XX\=    \kill           Input:\+ \\                 #1 \-  \\
Output: \+ \\
  #2 \- \\
Internal: \+\\
  #3 \-
\end{tabbing} \egroup} 

\newcommand{\io}[2]{\bgroup\ioisize \begin{tabbing}
XX\=XX\=    \kill           Input:\+ \\                 #1 \-  \\
Output: \+ \\
  #2 \- 
\end{tabbing} \egroup} 

\newcommand{\ioti}[4]{\bgroup\ioisize \begin{tabbing}
XX\=XX\=    \kill           Input:\+ \\                 #1 \-  \\
Output: \+ \\
  #2 \- \\
Time-passing: \+ \\
  #3 \- \\
Internal: \+\\
  #4 \-
\end{tabbing} \egroup} 

\newcommand{\ei}[2]{\bgroup\ioisize \begin{tabbing}
XX\=XX\=    \kill           External:\+ \\              #1 \-  \\
Internal: \+\\
  #2 \-
\end{tabbing} \egroup} 



\def\iocodesize{\scriptsize}
 
\newcommand{\iocodeonecol}[1]{\begin{center}\iocodesize
\begin{minipage}[t]{.95\linewidth}
\hbox to\linewidth{}
#1
\end{minipage}
\end{center}}

\newcommand{\iocode}[2]{\vspace{-15pt}\begin{center}\iocodesize
\begin{minipage}[t]{.475\linewidth}
\hbox to\linewidth{}
#1
\end{minipage}
\hspace{.01\linewidth} 
\begin{minipage}[t]{.475\linewidth}
\hbox to\linewidth{}
#2
\end{minipage}
\end{center}}

\newcommand{\ef}[2]{\begin{tabbing}         \= XXX\=XX\=XX\=XX\=XX\=   \kill
\protect #1\\
\>Eff: \+ \+ \>
   #2  \- \-
\end{tabbing}}


\newcommand{\prcef}[3]{\begin{tabbing}        \= XXX\=XX\=XX\=XX\=  \kill
\protect #1\\
\>Pre: \+ \+ \>
  #2  \-  \- \\ 
\>Eff: \+  \+ \>
  #3 \- \- 
\end{tabbing}} 


\newcommand{\prc}[2]{\begin{tabbing}        \= XXX\=XX\=XX\=XX\=  \kill
\protect #1\\
\>Pre: \+ \+ \>
  #2  \-  \- 
\end{tabbing}} 


\newlength\Mwidth
\newlength\jsawidth

\def\statedef#1{\def\auxstatedef{#1}\def\auxempty{}\settowidth{\Mwidth}{M}
\jsawidth=\textwidth
\advance\jsawidth by -7cm
\advance\jsawidth by -\Mwidth
\advance\jsawidth by -10\tabcolsep
\advance\jsawidth by -6\arrayrulewidth
\begin{trivlist}\item[]\begin{tabular}{|p{2.5cm}|c|p{2.2cm}|p{2.3cm}|p{\jsawidth}|}
\hline
{\bf Variable} & \phantom{M} & {\bf Type} & {\bf Initially} & {\bf Description}\\
\hline\hline}
\def\endstatedef{\\ 
\ifx\auxstatedef\auxempty
  \hline
\else \hline\hline
   \multicolumn{5}{|l|}{\auxstatedef}\\\hline
 \fi
\end{tabular}\end{trivlist}}

\def\statetext{\begin{minipage}[t]{\linewidth}}
\def\endstatetext{\end{minipage}\vspace{2pt}}





\newcommand{\ifstmnt}[2]{\ifbranch{if #1 then}{#2}}

\newcommand{\ifbranch}[2]{\begin{tabbing}         XX\= XXX\=XX\=XX\=XX\=XX\=   \kill
\protect #1\\
\>\+ \+ \>
   #2  \- \-
\end{tabbing}}




\newcommand{\statevar}[1]{\ms{#1}}



\newcommand{\arrow}[1]{\raisebox{0ex}[2ex]{\raisebox{-.25ex}{}}}
\newcommand{\sarrow}[2]{\raisebox{0ex}[2ex]{\raisebox{-.25ex}{}}\!_{#2}\,}




\newcommand{\automatontitle}[1]{\vspace{2ex} \noindent \textbf{#1}\\}

\newenvironment{signature}[1][Signature]{\noindent\textbf{#1}\iocodesize\vspace{-2ex}}{}

\newenvironment{statevarlist}[1][State]{\noindent\textbf{#1}\iocodesize\vspace{-1ex}
\begin{description}}{\end{description}}

\newenvironment{actionlist}[1][Actions]{\noindent\textbf{#1}\iocodesize}{}

\newenvironment{tasks}[1][Tasks]{\noindent\textbf{#1}\iocodesize}{}




\newcommand{\inputaction}[2]{\ef{\textbf{Input} #1}{#2}}
\newcommand{\outputaction}[3]{\prcef{\textbf{Output} #1}{#2}{#3}}
\newcommand{\internalaction}[3]{\prcef{\textbf{Internal} #1}{#2}{#3}}













\usepackage{calc}       

\renewcommand{\iocode}[3][.475]{\vspace{-15pt}\begin{center}\iocodesize
\begin{minipage}[t]{#1\linewidth}
\hbox to\linewidth{}
#2
\end{minipage}
\hspace{.01\linewidth} 
\begin{minipage}[t]{.95\linewidth-#1\linewidth}
\hbox to\linewidth{}
#3
\end{minipage}
\end{center}}




\newcommand{\MP}[1]{}
\newcommand{\rmv}[1]{}
\newcommand{\BN}{{\bf N}}

\newcommand{\vote}{\textsc{vote}}
\newcommand{\yes}{\textrm{Yes}}
\newcommand{\no}{\textrm{No}}
\newcommand{\commit}{\textrm{Commit}}
\newcommand{\abort}{\textrm{Abort}}

\newcommand{\qc}{QC} 

\newcommand{\nbac}{NBAC}


\newcommand{\propose}{\textsc{propose}}
\newcommand{\myproposal}{\textit{myproposal}}
\newcommand{\mydecision}{\textit{mydecision}}

\newcommand{\myvote}{\textit{myvote}}

\newcommand{\Q}{\textrm{Q}}





\newcommand{\T}{\Upsilon}


\newcommand{\fs}{failure signal}
\newcommand{\FS}{\mathcal{FS}}
\newcommand{\Psihat}{\hat{\Psi}}
\newcommand{\green}{\textbf{green}}
\newcommand{\red}{\textbf{red}}

\newcommand{\qm}{\textbf{}}
\newcommand{\PHO}{\Psihat\textit{-output}}
\newcommand{\PO}{\Psi\textit{-output}}
\newcommand{\OO}{\Omega\textit{-output}}
\newcommand{\SO}{\Sigma\textit{-output}}


\newcommand{\btm}[1]{{#1}^{\qm}}
\newcommand{\alt}[1]{\textbf{alt}({#1)}}

\def\ch{}
\def\assn{\leftarrow}
\def\lf{\tiny}
\newcounter{linenumber}
\def\rrnnll{\setcounter{linenumber}{0}}
\def\nnll{\refstepcounter{linenumber}\lf\thelinenumber}














\newenvironment{nproof}[1][]{
\ifthenelse{\equal{#1}{}}
           {\medskip\noindent{\textsc{Proof.}\enspace}}
           {\medskip\noindent{\textsc{#1.}\enspace}}
}
{\medskip}
 





\begin{document}
\sloppy

\title{The Weakest Failure Detector for Eventual Consistency}

\author{
Swan Dubois\protect\footnote{Sorbonne Universit\'es, UPMC Universit\'e
  Paris 6, \'Equipe REGAL, LIP6, F-75005, Paris, France;
CNRS, UMR 7606, LIP6, F-75005, Paris, France;
Inria, \'Equipe-projet REGAL, F-75005, Paris, France;
firstname.lastname@lip6.fr}
\hspace{1cm}Rachid Guerraoui\protect\footnote{\'Ecole Polytechnique F\'ed\'erale de Lausanne, Switzerland; rachid.guerraoui@epfl.ch}
\hspace{1cm}Petr Kuznetsov\protect\footnote{T\'el\'ecom ParisTech;
   petr.kuznetsov@telecom-paristech.fr}\thanks{The research leading to these results has
  received funding from the Agence Nationale de la Recherche,  under
  grant agreement N ANR-14-CE35-0010-01, project DISCMAT.}
\\
Franck Petit\protect\footnotemark[1]
\hspace{1cm} Pierre Sens\protect\footnotemark[1]
}

\date{}


\maketitle


\begin{abstract}
In its classical form,  a \emph{consistent} replicated service requires
all replicas to witness the same evolution of the service state.
Assuming a message-passing environment with a majority of
correct processes, the necessary and sufficient information about
failures for implementing a general state machine replication scheme
ensuring consistency is captured by the  failure detector.


This paper shows that
in such a message-passing environment,   is also the weakest failure detector
to implement
an \emph{eventually consistent} replicated service,
where replicas are expected to agree on the evolution of the service state only after some
(\emph{a priori} unknown) time.

In fact, we show that  is the weakest to implement
eventual consistency in \emph{any} message-passing environment, {\em i.e.}, under any assumption on when and
where
failures might occur.
Ensuring (strong) consistency in any environment
requires, in addition to ,
the quorum failure detector
.
Our paper thus captures, for the first time,
an exact computational difference between
building a replicated state machine that ensures consistency and
one that only ensures eventual consistency.
\end{abstract}

\section{Introduction}


State machine replication~\cite{Lam77,Sch90}  is the most studied
technique to build a highly-available and consistent distributed
service.
Roughly speaking, the idea consists in replicating the service, modeled as a state machine,
over several processes and ensuring that all replicas behave like one
correct and available state machine,
despite concurrent invocations of operations and failures of
replicas.
This is typically captured using the abstraction of a \emph{total
  order broadcast}~\cite{CT96}, where messages represent invocations
of the service operations from clients to replicas (server
processes).
Assuming that the state machine is
deterministic, delivering the invocations in the same total order
ensures indeed that the replicas behave like a single state
machine. Total order broadcast is, in turn, typically implemented by
having the processes agree on which batch of messages to execute next,
using the \emph{consensus} abstraction~\cite{Lam98,CT96}.
(The two abstractions, consensus and total order broadcast, were shown to be equivalent~\cite{CT96}.)

Replicas behaving like a single one is a
property generally called \emph{consistency}. The
sole purpose of the  abstractions underlying the state machine
replication scheme, namely consensus and total order broadcast, is precisely to ensure
this consistency, while providing at the same time \emph{availability},
namely that the replicated service does not stop responding. The inherent costs
of these abstractions are sometimes considered too high, both in
terms of
the necessary computability assumptions about the underlying
system~\cite{FLP85,CHT96,Bre00}, and
the number of communication steps needed to deliver an
invocation~\cite{Lam98,Lam06}.

An appealing approach to circumvent these costs is to trade
consistency with what is sometimes called \emph{eventual consistency}~\cite{SS05, Vogels2009}:
namely to give up the requirement that the replicas  \emph{always} look the
same, and replace it with the requirement that they only look the same
\emph{eventually}, {\em i.e.}, after a finite but not \emph{a priori} bounded
period of time.
Basically, \emph{eventual consistency} says that the replicas can
diverge for some period, as long as this period is finite.

Many systems claim to implement general state machines that ensure
eventual consistency in message-passing  systems, {\em
  e.g.},~\cite{Cassandra, DeCandia2007}.
But, to our knowledge,  there has been no theoretical study of the
exact assumptions on the information about failures underlying those implementations.
This paper is the first to do so:  using the  formalism of failure detectors~\cite{CT96,CHT96},
it addresses the question of the minimal information about failures needed to implement an eventually consistent replicated state machine.

It has been shown in~\cite{CHT96} that, in a message-passing environment with
a majority of correct processes, the weakest failure detector to
implement consensus (and, thus, total order broadcast~\cite{CT94}) is the \emph{eventual
  leader} failure detector, denoted . In short,  outputs, at
every process, a \emph{leader} process so that, eventually, the same
correct process is considered leader by all.
 can thus be viewed as the weakest failure detector to implement a
generic replicated state machine ensuring
consistency and availability in an environment with a majority of correct
processes.

We show in this paper that, maybe
surprisingly, the weakest failure detector to implement an
\emph{eventually consistent}  replicated service in this environment
(in fact, in \emph{any} environment) is still .
We prove our result via an interesting generalization of the
celebrated ``CHT proof'' by Chandra, Hadzilacos and Toueg~\cite{CHT96}.
In the CHT proof, every process periodically extracts the identifier of a process that is
expected to be correct (the \emph{leader}) from the \emph{valencies} of an ever-growing collection
of locally simulated runs. 
We carefully adjust the notion of valency to apply this approach to the weaker
abstraction of \emph{eventual consensus}, which we show to be necessary
and sufficient to implement eventual consistency.

Our result becomes less surprising if we
realize that a correct majority prevents the system from being
\emph{partitioned}, and we know that both consistency and availability
cannot be achieved while tolerating partitions~\cite{Bre00,GL02,DFG10}.
Therefore, in a system with a correct majority of processes, there is no gain in
weakening consistency:  (strong) consistency requires the same
information about failures as eventual one.
In an arbitrary environment, however, {\em i.e.}, under any
assumptions on when and where failures may occur,
the weakest failure detector for consistency is known to be ,
where ~\cite{DFG10}
returns a set of processes (called a \emph{quorum}) so that every
two such quorums intersect at any time and there is a time after which
all returned quorums contain only correct processes.
We show in this paper that ensuring eventual consistency does not
require : only  is needed,  even if we do not assume a
 majority of correct processes. Therefore, 
represents the exact difference
between consistency and eventual consistency.
Our result thus theoretically backs up partition-tolerance~\cite{Bre00,GL02} as one of the main motivations
behind the very notion of eventual consistency.

We establish our results through the following steps:


\begin{itemize}\itemsep0pt

\item We give precise definitions of the notions of {\em eventual
  consensus} and
{\em eventual total order broadcast}.
We show that the two abstractions are equivalent. These underlie 
the intuitive notion of eventual consistency implemented in many
replicated services~\cite{DeCandia2007,Cooper2008,Chang2008}.


\item We show how to extend the celebrated CHT proof~\cite{CHT96}, initially establishing
that  is necessary for solving consensus, to the context of eventual consensus.
Through this extension, we indirectly highlight a  hidden power of the
technique proposed in~\cite{CHT96} that somehow provides more
than was used in the original CHT proof.


\item We present an algorithm that uses  to implement, in any message-passing
  environment,  an eventually consistent replicated service.
The algorithm features three interesting properties:
(1) An invocation can be performed after
  the optimal number of two communication steps, even if a majority of processes is not correct and even
  during periods when processes disagree on the leader, i.e., partition
  periods; \footnote{Note that three communication steps are, in the worst case, necessary when
strong consistency is required~\cite{Lam06}. }  (2) If  outputs the same leader at all
processes from the very beginning, then the algorithm implements total
order broadcast and hence ensures consistency;
(3) \emph{Causal} ordering is ensured even during periods where
 outputs different leaders at different processes.


\end{itemize}



The rest of the paper is organized as follows.
We present our system model and basic definitions in Section~\ref{sec:model}.
In Section~\ref{sec:defs}, we introduce abstractions for
implementing
eventual consistency: namely, eventual consensus and eventual total
order broadcast, and we prove them to be equivalent.
We show in Section~\ref{sec:WFD} that the weakest failure detector for eventual consensus in any message-passing
environment is .
We present in Section~\ref{sec:ETOB} our algorithm that implements eventual total order broadcast using  in
any environment.
Section~\ref{sec:related} discusses related
work, and Section~\ref{sec:conclu} concludes the paper.
In the optional appendix, we present some proofs omitted from the main
paper, discuss an alternative (seemingly relaxed but equivalent) definition of eventual
consensus, and recall basic steps of the CHT proof.

\section{Preliminaries}
\label{sec:model}


We  adopt the classical model of distributed systems provided with the
failure detector abstraction proposed in~\cite{CT96,CHT96}.
In particular we employ the simplified version of the model proposed in~\cite{GHKT12,JT08}.

We consider a message-passing system  with a set of
	processes  ().
	Processes execute steps of computation asynchronously, {\em i.e.}, there is
	no bound on the delay between steps.
However, we assume a discrete global clock
	to which the processes do not have access.
The range of this clock's ticks is .
Each pair of processes are connected by a reliable link.

Processes may fail by \emph{crashing}.
A \emph{failure pattern} is a function ,
	where  is the set of processes that have crashed by time .
We assume that processes never recover from crashes, \emph{i. e.}, .
Let 
	be the set of \emph{faulty} processes in a failure pattern ;
	and  be
	the set of \emph{correct} processes in .
An \emph{environment}, denoted , is a set of failure patterns.



A \emph{failure detector history  with range } is a function ,
	where  is interpreted as the value output by the failure detector module
	of process  at time .
A \emph{failure detector  with range } is a function
	that maps every failure pattern  to
	a nonempty set of failure detector histories.
 denotes the set of all possible failure detector histories
	that may be output by  in a failure pattern .

For example, at each process, the \emph{leader failure detector}  outputs the id of a process;
	furthermore, if a correct process exists, then there is a time after which
	 outputs the id of the same correct process at every correct process.
Another example is the \emph{quorum failure detector} , which
	outputs a set of processes at each process.
Any two sets output at any times and by any processes intersect, and
	eventually every set output at any correct process
	consists of only correct processes.

An \emph{algorithm}  is modeled as a collection of 
deterministic automata, where  specifies the behavior of
process .
Computation proceeds in \emph{steps} of these automata.
In each step, identified as a tuple , a process  atomically
(1) receives a single message  (that can be the empty message
) or accepts an \emph{input} (from the
external world),
(2)  queries its local failure detector module
	and receives a value , (3) changes its state according to
        , and (4) sends a message
        specified by  for the new state to every process or
        produces an \emph{output} (to the external world).
Note that the use of  ensures that a step of a process is
always enabled, even if no message is sent to it.  	

A \emph{configuration} of an algorithm  specifies the local
state of each process and the set of messages in transit.
In the \emph{initial} configuration of , no message is in
transit and each process  is in the initial state of the automaton .
A \emph{schedule}  of  is a finite or infinite sequence of
steps of  that respects   for each .

Following~\cite{JT08}, we model inputs and outputs of processes using \emph{input histories}
 and \emph{output histories}  that specify the inputs each
process receives from its application and
the outputs each process returns to the application over time.
A \emph{run of algorithm  using failure detector  in
  environment } is
        a tuple , where  is a failure pattern in ,
         is a failure detector history in ,
         and  are input and output histories of ,
         is a schedule of , and
         is a list of increasing times in ,
        where  is the time when step  is taken.
        , the failure detector values received by steps
        in  are consistent with , and  and  are
        consistent with .
An infinite run of  is \emph{admissible}
if (1) every correct process takes an infinite number of steps in ;
        and (2) each message sent to a correct process is eventually received.






We then define a distributed-computing \emph{problem}, such as consensus or total
order broadcast, as a set of tuples  where  is an
input history and  is an output history.
An algorithm  using a failure detector  solves a problem  in
an environment   if
in every admissible run of  in , the input and output histories
are in .
Typically, inputs and outputs represent
invocations and responses of \emph{operations} exported by the
implemented abstraction.
If there is an algorithm that solves  using , we sometimes,
with a slight language abuse, say that  \emph{implements} .


Consider two problems  and . A \emph{transformation from  to
   in an environment }~\cite{HT94}  is
  a map  that, given any algorithm 
  solving  in , yields an algorithm   solving  in
  .
The transformation is \emph{asynchronous} in the sense that 
is used as a ``black box'' where  is
obtained by feeding inputs to  and using the returned outputs to
solve .
Hence, if  is solvable in  using a failure detector ,
the existence of a transformation  in  establishes
that  is also solvable in  using .
If, additionally, there exists a transformation from  to   in , we
say that  and  are \emph{equivalent in }.

Failure detectors can be partially ordered based on their ``power'':
	failure detector  is \emph{weaker than}
	failure detector  in  if there is an algorithm
	that \emph{emulates} the output of  using  in ~\cite{CHT96,JT08}.
If  is weaker than , any problem that can be solved with
	 can also be solved with .
For a problem ,
	 is the \emph{weakest} failure detector to solve  in  if
	(a)~there is an algorithm that uses  to solve  in , and
	(b)~ is weaker than any failure detector  that can
be used to solve  in .




\section{Abstractions for Eventual Consistency}
\label{sec:defs}


We define two basic abstractions that capture the notion of eventual
consistency: eventual total order broadcast and eventual consensus.
We show that the two abstractions are equivalent: each of them can be
used to implement the other.

\paragraph{Eventual Total Order Broadcast (\ETOB)}
The \emph{total order broadcast} (\TOB) abstraction~\cite{HT94} exports one operation
 and
maintains, at every process , an output variable .
Let  denote the value of  at time .
Intuitively,  is the sequence of messages  \emph{delivered}
by time .
We write  if  appears in .

A process  \emph{broadcasts a message  at time
} by a call to .
We say that a process  \emph{stably delivers a message  at time }
if  appends  to  and  is never removed from  after
that, {\em i.e.},
 and : .
Note that if a message is delivered but not \emph{stably} delivered by  at time ,
it appears in  but not in  for some .

Assuming that broadcast messages are distinct, the \TOB~abstraction satisfies:
\begin{description}\itemsep0pt
\item[\TOB-Validity] If a correct process  broadcasts a message
   at time , then  eventually stably delivers , i.e.,   for some .

\item[\TOB-No-creation] If , then  was broadcast by
  some process  at some time .

\item[\TOB-No-duplication] No message appears more than once in
  . 

\item[\TOB-Agreement] If a message  is stably delivered by some
  correct process  at time , then  is eventually stably delivered by every correct process .

\item[\TOB-Stability] For any correct process ,  is a prefix of  for all , .

\item[\TOB-Total-order] Let  and  be any two correct processes such that two messages  and  appear in  and  at time . If  appears before  in , then  appears before  in .
\end{description}
We then introduce the \emph{eventual  total order broadcast} (\ETOB)
abstraction, which  maintains the same inputs and outputs as \TOB~(messages are broadcast by a call to ) and
satisfies, in every admissible run,
the \TOB-Validity, \TOB-No-creation, \TOB-No-duplication, and
\TOB-Agreement properties,
plus the following relaxed properties for some :
\begin{description}\itemsep0pt
\item[\ETOB-Stability] For any correct process ,  is a prefix of 
  for all , .
\item[\ETOB-Total-order] Let   and  be correct processes such that
  messages  and  appear in  and  for some
  . If  appears before  in , then  appears before  in .
\end{description}
As we show in this paper, satisfying the following optional (but
useful) property in \ETOB~does not require more information about failures.
\begin{description}
\item[\TOB-Causal-Order] Let  be a correct process such that two messages  and  appear in  at time . If  depends causally of , then  appears before  in .
\end{description}

Here we say that a message  \emph{causally depends} on a message  in a run ,
and write , if one of the following conditions
holds in : (1) a process  sends  and
then sends , (2) a process  receives  and then sends
, or (3) there exists  such that  and
.       


\paragraph{Eventual Consensus (\EC)}
The \emph{consensus} abstraction (\C)~\cite{FLP85} exports, to every process , a
single operation  that takes a
binary argument and
returns a binary response (we also say \emph{decides})  so that the following properties are
satisfied:

\begin{description}\itemsep0pt
\item[\C-Termination] Every correct process eventually returns a response to .
\item[\C-Integrity] Every process returns a response at most once.
\item[\C-Agreement] No two processes return different values.
\item[\C-Validity] Every value returned was previously proposed.
\end{description}
The \emph{eventual  consensus} (\EC) abstraction exports, to
every process , operations ,
,  that take binary arguments and return
binary responses. Assuming that, for all
,  every process invokes
 as soon as
it returns a response to , the abstraction guarantees that,
in every admissible run, there exists , such that the following properties are satisfied:
\begin{description}\itemsep0pt
\item[\EC-Termination] Every correct process eventually returns a response to  for all .
\item[\EC-Integrity] No process responds twice to
   for all .
\item[\EC-Validity] Every value returned to  was previously proposed to  for all .
\item[\EC-Agreement] No two processes return different values to  for all .
\end{description}
It is straightforward to transform the binary version of {\EC} into a
multivalued one with unbounded set of inputs~\cite{MRT00-mv}. In the following, by referring to
{\EC} we mean a multivalued version of it.

\paragraph{Equivalence between \EC~and \ETOB}
It is well known that, in their classical forms, the consensus and the total order broadcast abstractions are equivalent \cite{CT96}. In this section, we show that a similar result holds for our eventual versions of these abstractions.

The intuition behind the transformation from {\EC} to {\ETOB} is the
following.  Each time a process  wants to ETOB-broadcast a message , 
sends  to each process.
Periodically,  every process  proposes its current
sequence of messages received so far to  \EC.
This sequence is built by concatenating the last output of  
\EC (stored in a local variable ) to the batch of all
messages received by the process and not yet present in .
The output of {\EC} is stored in , i.e.,
at any time, each process delivers the last sequence of messages
returned by {\EC}.

The correctness of this transformation follows from the fact that  \EC eventually returns consistent
responses to the processes. Thus, eventually, all processes agree on
the same linearly growing sequence of stably delivered messages.
Furthermore, every message broadcast by a
correct process eventually appears either in the delivered message sequence or
in the batches of not yet delivered messages at all correct
processes. Thus, by {\EC}-Validity of {\EC}, every message
\ETOB-broadcast by a correct process is eventually stored
in  of every correct process  forever.
By construction, no message appears in  twice or if it was not previously
\ETOB-broadcast.
Therefore, the
transformation satisfies the properties of {\ETOB}.

The transformation from \ETOB~to \EC~is as follows. At each invocation of the
\EC~primitive, the process broadcasts a message using the
\ETOB~abstraction. This message contains the proposed value and the
index of the consensus instance. As soon as a message corresponding
to a given eventual consensus instance is delivered by process  (appears in ), 
returns the value contained in the message.

Since the \ETOB~abstraction guarantees that every process eventually
stably delivers the same sequence of messages, there exists a consensus instance
after which the responses of the transformation to all alive processes
are identical.
Moreover, by \ETOB-Validity, every message \ETOB-broadcast by a
correct process  is eventually stably delivered.
Thus, every correct process eventually returns from any \EC-instance
it invokes.
Thus, the transformation satisfies the \EC~specification.


\begin{theorem}\label{th:EquivalenceECETOB}
In any environment , \EC~and \ETOB~are equivalent.
\end{theorem}
\begin{proof}
\paragraph{From {\EC} to {\ETOB}} 
To prove this result, it is sufficient to provide a protocol that
implements \ETOB~in an environment  knowing that there
exists a protocol that implements \EC~in this environment. This
transformation protocol  is stated
in Algorithm~\ref{algo:ECtoETOB}. 
Now,  we are going to prove that  implements \ETOB.

Assume that there exists a message  broadcast by a correct process
 at time . As  is correct, every correct process receives
the message  in a finite time. Then,  appears in the set
 of all correct processes in a finite time. Hence, by the
termination property of \EC~and the construction of the function
, there exists  such that  is included in any
sequence submitted to . By the \EC-Validity
and the \EC-Termination properties, we deduce that  stably delivers  in a finite time, that proves that  satisfies the \TOB-Validity property.

If a process  delivers a message  at time , then 
appears in the sequence responded by its last invocation of
. By construction and by the \EC-Validity
property, this sequence contains only messages that appear in the set  of a process  at the time  invokes . But this set is incrementally built at the reception of messages  that contains only messages broadcast by a process. This implies that  satisfies the \TOB-No-creation.

As the sequence outputted at any time by any process is the response to its last invocation of  and that the sequence submitted to any invocation of this primitive contains no duplicated message (by definition of the function ), we can deduce from the \EC-Validity property that  satisfies the \TOB-No-duplication.

Assume that a correct process  stably delivers a message ,
i.e., there exists a time after which  always appears in .
By the algorithm,  always appears in the response of
 to  after this time.
As \EC-Agreement property is eventually satisfied, we can deduce that
 always appears in the response of  for any
correct process after some time. Thus, any correct process stably
delivers , and  satisfies the \TOB-Agreement.

Let  be the time after which the \EC~primitive satisfies \EC-Agreement and \EC-Validity.

Let  be a correct process and . Let  (respectively ) be the integer such that  (respectively ) is the response of  (respectively ). By construction of the protocol and the \EC-Agreement and \EC-Validity properties, we know that, after time , the response of  to correct processes is a prefix of the response of . As we have , we can deduce that  satisfies the \ETOB-Stability property.

Let  and  be two correct processes such that two messages  and  appear in  and  at time . Let  be the smallest integer such that  and  appear in the response of . By the \EC-Agreement property, we know that the response of  is identical for all correct processes. Then , by the \ETOB-Stability property proved above, that implies that, if  appears before  in , then  appears before  in . In other words,  satisfies the \ETOB-Total-order property.

In conclusion,  satisfies the \ETOB~specification in an environment  provided that there exists a protocol that implements \EC~in this environment.

\begin{algorithm}
\caption{: transformation from \EC~to \ETOB~for process }\label{algo:ECtoETOB}
\small
\begin{description}\itemsep0pt
\item[Output variable:]~\\
: sequence of messages of  (initially empty) outputted at any time by 

\item[Internal variables:]~\\
: set of messages of  (initially empty) containing all messages received by ~\\
: integer (initially ) that stores the number of the last instance of consensus invoked by 

\item[Messages:]~\\
  with  a message of 

\item[Functions:]~\\
 sends  to all processes (including )\\
 returns a sequence containing all messages from the set 

\item[On reception of  from the application]~\\


\item[On reception of  from ]~\\


\item[On reception of  as response of ]~\\
\\
\\


\item[On local timeout]~\\
If  then\\


\end{description}
\normalsize
\end{algorithm}

\paragraph{From {\ETOB} to {\EC}} To prove this result, it is sufficient to provide a protocol that
implements \EC~in an environment  given a protocol that
implements \ETOB~in this environment. This transformation protocol
 is stated  in Algorithm
\ref{algo:ETOBtoEC}. Now, we are going to prove that  implements \EC.

Let  be a correct process that invokes  with . Then, by fairness and the \TOB-Validity property, the construction of the protocol implies that the \ETOB~primitive delivers the message  to  in a finite time. By the use of the local timeout, we know that  returns from  in a finite time, that proves that  satisfies the \EC-Termination property.

The update of the variable  to  for any process  that invokes  and the assumptions on operations  ensure us that  executes at most once the function\linebreak . Hence,  satisfies the \EC-Integrity property.

Let  be the time after which the \ETOB-Stability and the \ETOB-Total-order properties are satisfied. Let  be the smallest integer such that any process that invokes  in run  invokes it after .

If we assume that there exist two correct processes  and  that return different values to  with , we obtain a contradiction with the \ETOB-Stability, \ETOB-Total-order, or \TOB-Agreement property. Indeed, if  returns a value after time , that implies that this value appears in  and then, by the \TOB-Agreement property, this value eventually appears in . If  returns a different value from , that implies that this value is the first occurrence of a message associated to  in  at the time of the return of . After that,  cannot satisfy simultaneously the \ETOB-Stability and the \ETOB-Total-order properties. This contradiction shows that  satisfies the \EC-Agreement property.

If we assume that there exists a process  that returns to  with  a value that was not proposed to , we obtain a contradiction with the \TOB-No-creation property. Indeed, the return of  from  is chosen in  that contains the output of the \ETOB~primitive and processes broadcast only proposed values. This contradiction shows that  satisfies the \EC-Validity property.

In conclusion,  satisfies the \EC~specification in an environment  provided that there exists a protocol that implements \ETOB~in this environment.
\end{proof}

\begin{algorithm}
\caption{: transformation from \ETOB~to \EC~for process }\label{algo:ETOBtoEC}
\small
\begin{description}\itemsep0pt
\item[Internal variables:]~\\
: integer (initially ) that stores the number of the last instances of consensus invoked by \\
: sequence of messages (initially empty) outputted to  by the \ETOB~primitive

\item[Functions:]~\\
: returns the value  such that  is the first message of the form  in  if such messages exist,  otherwise\\
: returns the value  as response to 

\item[On invocation of ]~\\
\\


\item[On local time out]~\\
If  then\\

\end{description}
\normalsize
\end{algorithm}
 








\section{The Weakest Failure Detector for \EC}
\label{sec:WFD}

In this section, we show that  is necessary and sufficient for
implementing the eventual consensus abstraction \EC:

\begin{theorem}\label{th:WFDforEC}
In any environment ,  is the weakest failure detector for \EC.
\end{theorem}


\paragraph{ is necessary for \EC}
Let  be any environment.
We show below that  is weaker
than any failure detector  that can be used to solve {\EC} in .
Recall that implementing  means outputting, at every process,
        the identifier of a \emph{leader} process so that eventually,
         the same correct leader is output permanently at all correct
        processes.

First,  we briefly recall the arguments use by Chandra et al.~\cite{CHT96} in
the original CHT proof deriving  from any algorithm solving
consensus (to get a more detailed survey of the proof please rever
to Appendix~\ref{app:cht} or~\cite[Chapter 3]{fd-survey}).
The basic observation there is that
	a run of any algorithm using a failure detector
	induces a \emph{directed acyclic graph} (DAG).
The DAG contains a sample of failure detector values output by  in the current run
	and captures causal relations between them.
Each process  maintains  a local copy of the DAG, denoted by :
 periodically queries its failure detector module, updates 
by connecting every vertex of the DAG with the vertex containing the
returned failure-detector value with an edge, and broadcasts the DAG.
An edge from vertex  to vertex 
        is thus interpreted as `` queried  for the th time and
        obtained value  and after that  queried  for the
        th time and obtained value ''.
Whenever  receives a DAG  calculated earlier by , 
merges  with .
As a result, DAGs maintained by the correct processes converge to the same
infinite DAG .
The DAG  is then used by  to simulate a number of runs of
the given consensus algorithm  for all possible inputs to the processes.
All these  runs are organized in the form of a \emph{simulation
  tree} .
The simulation trees  maintained by the correct
processes converge to the same infinite simulation tree .

The outputs produced in the simulated runs of  are then used by 
to compute the current estimate of .
Every vertex  of  is assigned a valency tag based on the
decisions taken in all its \emph{extensions} (descendants of  in
):  is assigned a tag
 if   has an extension in which some process decides
.
A vertex is bivalent if it is assigned both  and .
It is then shown in~\cite{CHT96} that by locating the same bivalent vertex in the
limit tree , the correct process can eventually extract
the identifier of the same correct process.
(More details can be found in Appendix~\ref{app:cht} and~\cite{CHT96,fd-survey}.)

We show that this method, originally designed for
consensus, can be extended to eventual consensus (i.e., to the  weaker {\EC} abstraction). The extension is not trivial 
and requires carefully adjusting the notion of valency of a vertex in the
simulation tree.

\begin{lemma}\label{lem:NecessityOmegaEC}
In every environment , if a failure detector  implements \EC~in , then  is weaker than  in .
\end{lemma}

\begin{proof}
Let  be any algorithm that implements \EC~using
a failure detector  in an environment .
As in~\cite{CHT96}, every process  maintains a failure detector sample
stored in DAG  and periodically uses  to simulate a set of
runs of  for all possible sequence of inputs of {\EC}.
The simulated runs are organized by  in an ever-growing \emph{simulation
tree} .
A vertex of  is the schedule of a finite run of 
``triggered'' by a path in  in which every process starts with invoking
, for some , takes steps using the failure detector
values stipulated by the path in  and, once 
is complete, eventually invokes
, for some .
(For the record, we equip each vertex of  with the path in  used to produce it.)
A vertex is connected by an edge to each one-step extension
of it.~\footnote{In~\cite{CHT96},  the simulated schedules form
  a \emph{simulation forest}, where a distinct simulation tree
  corresponds to each initial configuration encoding
  consensus inputs. Here we
  follow~\cite{JT08}: there is a single initial configuration and inputs
  are encoded in the form of input histories. As a result, we get a
  single simulation tree where branches depend on the parameters of
   calls.}

Note that in every admissible infinite simulated run,
\EC-Termination, \EC-Integrity and \EC-Validity
are satisfied and that there is 
such that for all , the invocations and responses of
 satisfy the \EC-Agreement.

Since processes periodically broadcast their DAGs,
the simulation tree  constructed locally by a correct process 
\emph{converges} to an infinite simulation tree ,
in the sense that every finite subtree of
  is eventually part of .
The infinite simulation tree , starting
from the initial configuration of  and, in the limit, contains
all possible schedules that can triggered by the paths DAGs .

Consider a vertex  in  identifying a unique finite
schedule of a run  of  using  in the current failure
pattern . For , we say that  is \emph{-enabled} if  or 
contains a response from  at some process.
Now we associate each vertex  in  with a set of
\emph{valency tags} associated with each ``consensus instance''  ,
called the \emph{-tag} of , as follows:

\begin{itemize}
\item If  is -enabled and has a
descendant (in ) in which  returns , then
 is added to the -tag of .

\item If  is -enabled and has a descendant in which two
different values are returned by , then  is added to
the -tag of .

\end{itemize}

If  is not -enabled, then its -tag is empty.
If the -tag of  is , , we say that
  is \emph{-valent} (\emph{-univalent}).  If the
-tag is ,  then we say that  is -\emph{bivalent}.
If the -tag of  contains , we say that  is \emph{-invalid}

Since  ensures \EC-Termination in all admissible runs extending ,
each -enabled vertex , the -tag of  is non-empty.
Moreover, \EC-Termination and \EC-Validity imply that a vertex
in which no process has invoked  yet has a
descendant in which  returns  and a
descendant in which  returns .
Indeed, a run in which only ,  is proposed in instance
 and every correct process takes enough steps must contain  as
an output.
Thus:

\begin{enumerate}
\item[(*)] For each vertex , there exists  and ,
a descendant of , such that -tag of  contains .
\end{enumerate}

\begin{algorithm}[t]
\caption{Locating a bivalent vertex in .}\label{alg:bivalent}
\footnotesize
\\
 root of \\
while true do\\

\normalsize
\end{algorithm}

If the ``limit tree''  contains a -bivalent vertex, we
can apply the arguments of~\cite{CHT96} to extract . Now we show that such a vertex exists in .  Then we
can simply let every process locate the ``first'' such vertex in its
local tree .
To establish an order on the vertices, we can associate
each vertex  of  with the value 
such that vertex  of  is used to
simulate the last step of  (recall that we equip
each vertex of  with the corresponding path).
Then we order vertices of  in the order consistent with the
growth of . Since every vertex in  has only finitely many
incoming edges, the sets of vertices having the same value of  are
finite.
Thus, we can break the ties in the -based order using any
deterministic procedure on these finite sets.

Eventually, by choosing the first -bivalent vertex in their local
trees , the correct processes will eventually stabilize on the same
-bivalent vertex  in the limit tree 
and apply the CHT extraction procedure to
derive the same correct process based on -tags assigned to
's descendants.

It remains to show  that  indeed contains a -bivalent
vertex for some .  Consider the procedure described in
Algorithm~\ref{alg:bivalent} that intends to locate such a  vertex, starting with the root of the tree.

For the currently considered -enabled vertex  that is \emph{not}
-bivalent (if it is -bivalent, we
are done), we use (*) to locate , a descendant of , such that
(1)~in , two processes return different values in  in
,
(2)~in , every correct process has completed  and
has received every message sent to it in , and
(3)~the -tag of  contains .

Thus, the procedure in Algorithm~\ref{alg:bivalent}  either terminates by locating a -bivalent tag and then we
are done, or it never terminates. Suppose, by contradiction, that the procedure
never terminates. Hence, we have an
infinite admissible run of  in which no agreement is
provided in infinitely many instances of consensus.  Indeed, in the
constructed path along the tree, every correct process appears
infinitely many times and receives every message sent to it.
This admissible run violated the \EC-Agreement property of \EC---a contradiction.

Thus, the correct processes will eventually locate the same
-bivalent vertex and then, as in~\cite{CHT96},  stabilize extracting the same correct process identifier to emulate .
\end{proof}

\paragraph{ is sufficient for \EC}
Chandra and Toueg proved that  is sufficient to implement the
classical version of the consensus abstraction in an environment
where a majority of processes are correct \cite{CT96}. In this
section, we extend this result to the eventual consensus abstraction for any environment.

The proposed implementation of \EC~is very simple. Each process has access to an  failure detector module.
Upon each invocation of the \EC~primitive, a process broadcasts the
proposed value (and the associated consensus index).
Every process stores every received value.
Each process  periodically checks whether it has received a value for the current consensus instance from the process
that it currently believes to be the leader.  If so,  returns this value.
The correctness of this \EC~implementation relies on the fact that,
eventually, all correct processes trust the same leader
(by the definition of  ) and then decide (return responses) consistently on the values proposed by this process. 



\begin{lemma}\label{lem:SufficiencyOmegaEC}
In every environment , \EC~can be implemented using .
\end{lemma}
\begin{proof}
We propose such an implementation in Algorithm~\ref{algo:EC}. Then, we
prove that any admissible run  of the algorithm in any environment

satisfies the \EC-Termination, \EC-Integrity, \EC-Agreement, and \EC-Validity properties.

Assume that a correct process never returns from an invocation of
 in . Without loss of generality, denote by
 the smallest integer such that a correct process  never
returns from the invocation of . This implies
that  always evaluates  to
. We know by definition of  that, eventually, 
always returns the same correct process . Hence, by construction
of ,  returns from ,...,
 and then sends the message
 to all processes in a finite time. As  and
 are correct,  receives this message and updates
 to  in a finite time. Therefore, the
algorithm satisfies the \EC-Termination property.

The update of the variable  to  for any process 
that invokes  and the assumptions on operations
 ensure us that  executes at most once the
function \linebreak . Hence, the
\EC-Integrity property is satisfied.

Let  be the time from which the local outputs of 
are identical and constants for all correct processes in . Let 
be the smallest integer such that any process that invokes
 in  invokes it after .

Let  be an integer such that . Assume that  and
 are two processes that respond to . Then,
they respectively execute the function
 and
. By construction of , we
can deduce that . That implies that  and
 both received a message  from . As 
sends such a message at most once, we can deduce that
, that proves that ensures
the \EC-Agreement property.

Let  be an integer such that . Assume that  is
a process that respond to . The value returned
by  was previously received from  in a message of type
. By construction of the protocol,  sends only one
message of this type and this latter contains the value proposed to
, hence, the \EC-Validity property is satisfied.

Thus, Algorithm~\ref{algo:EC} indeed implements \EC~in any
environment using .
\end{proof}

\begin{algorithm}
\caption{\EC~using : algorithm for process }\label{algo:EC}
\small
\begin{description}\itemsep0pt
\item[Local variables:]~\\
: integer (initially ) that stores the number of the last instances of consensus invoked by \\
: two dimensional tabular that stores a value for each pair of processes/integer (initially )

\item[Functions:]~\\
 returns the value  as a response to 

\item[Messages:]~\\
 with  and 

\item[On invocation of ]~\\
\\
  to all

\item[On reception of  from ]~\\


\item[On local time out]~\\
If  do\\


\end{description}
\normalsize
\end{algorithm}



\section{An Eventual Total Order Broadcast Algorithm}
\label{sec:ETOB}

We have shown in the previous section that  is the weakest
failure detector for the {\EC} abstraction (and, by Theorem~\ref{th:EquivalenceECETOB}, the
{\ETOB} abstraction) in any environment.
In this section, we describe an algorithm that directly implements \ETOB~using
 and which we believe is interesting in its own right. 

The algorithm has  three interesting properties.   First, it
needs only two communication steps to deliver any message when the leader does not change,  whereas algorithms implementing
classical \TOB~need at least three communication steps in this case.
Second,  the algorithm actually implements total order broadcast if
 outputs the same leader at all processes from the very beginning.
Third, the algorithm additionally ensures the property of  \TOB-Causal-Order,
which does not require more information about faults.

The intuition behind this algorithm is as follows. Every process that intends to \ETOB-broadcast
a message sends it to all other processes.
Each process  has access to an  failure
detector module and maintains a DAG that stores the set of messages
delivered so far together with their causal dependencies.
As long as  considers itself the leader (its module of 
outputs ), it periodically sends to all processes a sequence of
messages computed from its DAG so that the sequence respects the causal order and admits the last delivered sequence as a prefix.
A process that receives a sequence of messages delivers it only if it has 
been sent by the current leader output by .
The correctness of this algorithm directly follows from the properties
of . Indeed, once all correct processes trust the same leader,
this leader promotes its own sequence of messages, which 
ensures the \ETOB~specification. 

The pseudocode of the algorithm  is given in Algorithm
\ref{algo:ETOB}).
Below we present the proof of its correctness,  including the proof that the algorithm
additionally ensures \TOB-Causal-Order.

\begin{algorithm}[t]
\caption{: protocol for process }\label{algo:ETOB}
\footnotesize
\begin{description}\itemsep0pt

\item[Output variable:]~\\
: sequence of messages  (initially empty) output by 

\item[Internal variables:]~\\
: sequence of messages  (initially empty) promoted by  when \\
: directed graph on messages of  (initially empty) that contains causality dependencies known by 

\item[Messages:]~\\
  with  a directed graph on messages of \\
 with  a sequence of messages 

\item[Functions:]~\\
 adds the node  and the set of edges  to \\
 replaces  by the union of  and \\
 replaces  by one of the sequences of messages  such that  is a prefix of ,  contains once all messages of , and for every edge  of ,  appears before  in 

\item[On  from the application]~\\
\\
  to all

\item[On reception of  from ]~\\
\\


\item[On reception of  from ]~\\
If  then\\


\item[On local time out]~\\
If  then\\


\end{description}
\normalsize
\end{algorithm}

\begin{lemma}\label{lem:etob}
In every environment , Algorithm  implements \ETOB~using . 
\end{lemma}
\begin{proof}
First, we prove that any run  of  in any environment  satisfies the \TOB-Validity, \TOB-No-creation, \TOB-No-duplication, and \TOB-Agreement properties.

Assume that a correct process  broadcasts a message  at time  for a given . We know that  outputs the same correct process  to all correct processes in a finite time. As  is correct, it receives the message  from  (that contains ) in a finite time. Then,  includes  in its causality graph (by a call to ) and in its promotion sequence (by a call to ). As  never removes a message from its promotion sequence and is outputted by ,  adopts the promotion sequence of  in a finite time and this sequence contains , that proves that  satisfies the \TOB-Validity property.

Any sequence outputted by any process is built by a call to  by a process .  This function ensures that any message appearing in the computed sequence appears in the graph . This graph is built by successive calls to  that ensure that the graph contains only messages received in a message of type . The construction of the protocol ensures us that such messages have been broadcast by a process. Then, we can deduce that  satisfies the \TOB-No-creation property.

Any sequence outputted by any process is built by a call to  that ensures that any message appears only once. Then, we can deduce that  satisfies the \TOB-No-duplication property.

Assume that a correct process  stably delivers a message  at time 
for a given . We know that  outputs the same
correct process  to all correct processes after some finite
time. Since  appears in every  such that , we
derive that  appears infinitely in  from a given point
of the run. Hence, the construction of the protocol and the correctness
of  implies that any correct process eventually stably delivers
, and   satisfies the \TOB-Agreement property.

We now prove that, for any environment , for any run  of  in , there exists a  satisfying \ETOB-Stability, \ETOB-Total-order, and \TOB-Causal-Order properties in . Hence, let  be a run of  in an environment . Let us define:
\begin{itemize}
\item  the time from which the local outputs of  are identical and constant for all correct processes in ;
\item  the longest communication delay between two correct processes in ;
\item  the longest local timeout for correct processes in ;
\item 
\end{itemize}

Let  be a correct process and  be the correct elected by  after . Let  and  be two integers such that . As the output of  is stable after  and the choice of  ensures us that  receives at least one message of type  from , we can deduce from the construction of the protocol that there exists  and  such that  and . But the function  used to build  ensures that  is a prefix of . Then,  satisfies the \ETOB-Stability property after time .

Let  and  be two correct processes such that two messages  and  appear in  and  at time . Assume that  appears before  in . Let  be the correct elected by  after . As the output of  is stable after  and the choice of  ensures us that  and  receive at least one message of type  from , the construction of the protocol ensures us that we can consider  and  such that  and . The definition of the function  executed by  allows us to deduce that either  is a prefix of  or  is a prefix of . In both cases, we obtain that  appears before  in , that proves that  satisfies the \ETOB-Total-order property after time .

Let  be a correct process such that two messages  and  appear in  at time . Assume that  when  is broadcast. Let  be the process trusted by  at the time  adopts the sequence . If  appears in , that implies that the edge  appears in  at the time  executes  (since  previously executed  that includes at least  and the set of edges  in ). The construction of  ensures us that  appears before  in , that proves that  satisfies the \TOB-Causal-Order property.

In conclusion,  is an implementation of \ETOB~assuming that processes have access to the  failure detector in any environment.
\end{proof}




\section{Related Work}
\label{sec:related}


Modern data service providers such as Amazon's Dynamo
\cite{DeCandia2007},  Yahoo's PNUTs~\cite{Cooper2008} or Google
Bigtable distributed storage~\cite{Chang2008} are intended to offer
highly available services. They consequently replicate those services
over several server processes. In order to  tolerate process failures as well
as partitions, they consider eventual consistency~\cite{SS05,
  Vogels2009,Singh2009}. 
  
The term {\em eventual} consensus was introduced in~\cite{KMO11}. It
refers to one instance of consensus which stabilizes at the end; not multiple instances as we consider in this paper.
In~\cite{Dolev2010}, a self-stabilizing form of consensus was proposed: 
assuming a self-stabilizing implementation of  (also described in the paper) and executing a sequence of consensus instances,   validity and  agreement are eventually ensured. Their consensus abstraction is close to ours but the authors focused on the shared-memory model and did not address the question of the weakest failure detector.

In~\cite{Fekete1996}, the intuition behind eventual consistency was
captured through the concept of eventual serializability. Two kinds of operations
were defined: (1) a
``stable'' operation of which response needs to be totally ordered
after  all operations preceding it and (2) ``weak'' operations of
which responses might not reflect all their preceding operations.
Our {\ETOB} abstraction captures consistency with respect to the
``weak'' operations. (Our lower bound on the necessity of 
 naturally extends to the stronger definitions.)


Our perspective on eventual consistency is closely related to the
notion of \emph{eventual linearizability} discussed recently
in~\cite{Serafini2010} and~\cite{GR14}.
It is shown in~\cite{Serafini2010} that the weakest failure detector
to boost eventually linearizable objects to linearizable ones is
.  We are focusing primarily on the weakest failure
detector to \emph{implement} eventual
consistency,
so their result is orthogonal to ours.




In~\cite{GR14}, eventual linearizability is
compared against linearizability in the context of implementing
specific objects in a shared-memory context.
It turns out that an eventually linearizable implementation of a \textit{fetch-and-increment}
object is as hard to achieve as a linearizable one.
Our {\ETOB} construction can be seen as an \emph{eventually
linearizable universal construction}: given any sequential
object type, {\ETOB} provides an eventually linearizable
concurrent implementation of it.
Brought to the message-passing environment with a correct majority,
our results complement~\cite{GR14}:
we show that in this setting, an eventually consistent replicated
service  (eventually linearizable object with a sequential
specification) requires exactly the same information about failures
as a consistent (linearizable) one.






\section{Concluding Remarks}

\label{sec:conclu}



This paper defined the abstraction of eventual total order broadcast and proved its
equivalence to eventual consensus: two fundamental building
blocks to implement a general replicated state machine that ensures eventual consistency.
We proved that the weakest failure detector to implement
these abstractions is , in any message-passing environment.
We could hence determine the gap between
building a general replicated state machine that ensures consistency in a message-passing system and one
that ensures only eventual consistency.
In terms of information about failures, this gap is precisely captured
by failure detector ~\cite{DFG10}. In terms of time
complexity, the gap is exactly one message delay: an operation on the strongly
consistent replicated must, in the worst case, incur three
communication steps~\cite{Lam06}, while one build using our eventually total order 
broadcast protocol  completes an operation in the optimal number of two communication steps.


Our {\ETOB} abstraction captures a form of eventual consistency
implemented in multiple replicated
services~\cite{DeCandia2007,Cooper2008,Chang2008}. In addition  to
eventual consistency guarantees, such systems sometimes produce
indications when a prefix of operations on the replicated service is
\emph{committed}, i.e., is not subject to further changes.
A prefix of operations can be committed, \emph{e.g.}, in sufficiently
long periods of synchrony, when a majority of correct processes elect
the same leader and  all incoming and outgoing messages of
the leader to the correct majority are delivered within some fixed bound.
We believe that such indications could easily be implemented, during
the stable periods, on top of {\ETOB}. 
Naturally, our results imply that  is necessary for such systems too. 

Our {\EC} abstraction assumes eventual agreement, but requires
integrity and validity to be always ensured.
Other definitions of eventual consensus could be considered. In
particular, we have studied an eventual
consensus abstraction assuming, instead of eventual agrement, \emph{eventual integrity}, \emph{i.e.}, a bounded number of decisions
in a given consensus instance could be revoked a finite
number of times. In Appendix~\ref{app:eic}, 
we define this abstraction 
of eventual \emph{irrevocable} consensus  (\EIC) more precisely and show 
that it is equivalent to our  {\EC} abstraction.













\def\noopsort#1{} \def\No{\kern-.25em\lower.2ex\hbox{\char'27}}
  \def\no#1{\relax} \def\http#1{{\\{\small\tt
  http://www-litp.ibp.fr:80/{}#1}}}
\begin{thebibliography}{10}

\bibitem{Bre00}
E.~A. Brewer.
\newblock Towards robust distributed systems (abstract).
\newblock In {\em Proceedings of the Nineteenth Annual ACM Symposium on
  Principles of Distributed Computing}, PODC '00, pages 7--, 2000.

\bibitem{CHT96}
T.~D. Chandra, V.~Hadzilacos, and S.~Toueg.
\newblock The weakest failure detector for solving consensus.
\newblock {\em J.~ACM}, 43(4):685--722, July 1996.

\bibitem{CT96}
T.~D. Chandra and S.~Toueg.
\newblock Unreliable failure detectors for reliable distributed systems.
\newblock {\em J.~ACM}, 43(2):225--267, Mar. 1996.

\bibitem{Chang2008}
F.~Chang, J.~Dean, S.~Ghemawat, W.~C. Hsieh, D.~A. Wallach, M.~Burrows,
  T.~Chandra, A.~Fikes, and R.~E. Gruber.
\newblock Bigtable: A distributed storage system for structured data.
\newblock {\em ACM Trans. Comput. Syst.}, 26(2):4:1--4:26, June 2008.

\bibitem{CT94}
B.~Charron-Bost and G.~Tel.
\newblock Approximation d'une borne inf\'erieure r\'epartie.
\newblock Technical Report LIX/RR/94/06, Laboratoire d'Informatique LIX,
  \'Ecole Polytechnique, Sept. 1994.

\bibitem{Cooper2008}
B.~F. Cooper, R.~Ramakrishnan, U.~Srivastava, A.~Silberstein, P.~Bohannon,
  H.-A. Jacobsen, N.~Puz, D.~Weaver, and R.~Yerneni.
\newblock Pnuts: Yahoo!'s hosted data serving platform.
\newblock {\em Proc. VLDB Endow.}, 1(2):1277--1288, Aug. 2008.

\bibitem{DeCandia2007}
G.~DeCandia, D.~Hastorun, M.~Jampani, G.~Kakulapati, A.~Lakshman, A.~Pilchin,
  S.~Sivasubramanian, P.~Vosshall, and W.~Vogels.
\newblock Dynamo: Amazon's highly available key-value store.
\newblock In {\em Proceedings of Twenty-first ACM SIGOPS Symposium on Operating
  Systems Principles}, SOSP '07, pages 205--220, New York, NY, USA, 2007. ACM.

\bibitem{DFG10}
C.~Delporte-Gallet, H.~Fauconnier, and R.~Guerraoui.
\newblock Tight failure detection bounds on atomic object implementations.
\newblock {\em J.~ACM}, 57(4), 2010.

\bibitem{Dolev2010}
S.~Dolev, R.~I. Kat, and E.~M. Schiller.
\newblock When consensus meets self-stabilization.
\newblock {\em Journal of Computer and System Sciences}, 76(8):884 -- 900,
  2010.

\bibitem{Fekete1996}
A.~Fekete, D.~Gupta, V.~Luchangco, N.~Lynch, and A.~Shvartsman.
\newblock Eventually-serializable data services.
\newblock In {\em Proceedings of the Fifteenth Annual ACM Symposium on
  Principles of Distributed Computing}, PODC '96, pages 300--309, New York, NY,
  USA, 1996. ACM.

\bibitem{FLP85}
M.~J. Fischer, N.~A. Lynch, and M.~S. Paterson.
\newblock Impossibility of distributed consensus with one faulty process.
\newblock {\em J.~ACM}, 32(2):374--382, Apr. 1985.

\bibitem{fd-survey}
F.~C. Freiling, R.~Guerraoui, and P.~Kuznetsov.
\newblock The failure detector abstraction.
\newblock {\em ACM Comput. Surv.}, 43(2):9:1--9:40, Feb. 2011.

\bibitem{GL02}
S.~Gilbert and N.~Lynch.
\newblock Brewer's conjecture and the feasibility of consistent, available,
  partition-tolerant web services.
\newblock {\em SIGACT News}, 33(2):51--59, June 2002.

\bibitem{GHKT12}
R.~Guerraoui, V.~Hadzilacos, P.~Kuznetsov, and S.~Toueg.
\newblock The weakest failure detectors to solve quittable consensus and
  nonblocking atomic commit.
\newblock {\em SIAM J. Comput.}, 41(6):1343--1379, 2012.

\bibitem{GR14}
R.~Guerraoui and E.~Ruppert.
\newblock A paradox of eventual linearizability in shared memory.
\newblock In {\em Proceedings of the 2014 ACM Symposium on Principles of
  Distributed Computing}, PODC '14, pages 40--49, 2014.

\bibitem{HT94}
V.~Hadzilacos and S.~Toueg.
\newblock A modular approach to fault-tolerant broadcasts and related problems.
\newblock Technical Report TR 94-1425, Department of Computer Science, Cornell
  University, May 1994.

\bibitem{JT08}
P.~Jayanti and S.~Toueg.
\newblock Every problem has a weakest failure detector.
\newblock In {\em PODC}, pages 75--84, 2008.

\bibitem{KMO11}
F.~Kuhn, Y.~Moses, and R.~Oshman.
\newblock Coordinated consensus in dynamic networks.
\newblock In {\em Proceedings of the 30th Annual ACM Symposium on Principles of
  Distributed Computing (PODC)}, pages 1--10. ACM, 2011.

\bibitem{Cassandra}
A.~Lakshman and P.~Malik.
\newblock Cassandra: A decentralized structured storage system.
\newblock {\em SIGOPS Oper. Syst. Rev.}, 44(2):35--40, Apr. 2010.

\bibitem{Lam77}
L.~Lamport.
\newblock Proving the correctness of multiprocessor programs.
\newblock {\em Transactions on software engineering}, 3(2):125--143, Mar. 1977.

\bibitem{Lam98}
L.~Lamport.
\newblock The {Part-Time} parliament.
\newblock {\em ACM Transactions on Computer Systems}, 16(2):133--169, May 1998.

\bibitem{Lam06}
L.~Lamport.
\newblock Lower bounds for asynchronous consensus.
\newblock {\em Distributed Computing}, 19(2):104--125, 2006.

\bibitem{MRT00-mv}
A.~Mostefaoui, M.~Raynal, and F.~Tronel.
\newblock From binary consensus to multivalued consensus in asynchronous
  message-passing systems.
\newblock {\em Inf. Process. Lett.}, 73(5-6):207--212, Mar. 2000.

\bibitem{SS05}
Y.~Saito and M.~Shapiro.
\newblock Optimistic replication.
\newblock {\em ACM Comput. Surv.}, 37(1):42--81, Mar. 2005.

\bibitem{Sch90}
F.~B. Schneider.
\newblock Implementing fault-tolerant services using the state machine
  approach: A tutorial.
\newblock {\em ACM Computing Surveys}, 22(4):299--319, Dec. 1990.

\bibitem{Serafini2010}
M.~Serafini, D.~Dobre, M.~Majuntke, P.~Bokor, and N.~Suri.
\newblock Eventually linearizable shared objects.
\newblock In A.~W. Richa and R.~Guerraoui, editors, {\em Proceedings of the
  29th Annual ACM Symposium on Principles of Distributed Computing}, pages
  95--104. ACM, 2010.

\bibitem{Singh2009}
A.~Singh, P.~Fonseca, P.~Kuznetsov, R.~Rodrigues, and P.~Maniatis.
\newblock Zeno: Eventually consistent byzantine-fault tolerance.
\newblock In {\em Proceedings of the 6th USENIX Symposium on Networked Systems
  Design and Implementation}, NSDI'09, pages 169--184, Berkeley, CA, USA, 2009.
  USENIX Association.

\bibitem{Vogels2009}
W.~Vogels.
\newblock Eventually consistent.
\newblock {\em Commun. ACM}, 52(1):40--44, Jan. 2009.

\end{thebibliography}

\newpage

\appendix


\ignore{


\section{Omitted proofs}


\subsection{Proof of Theorem~\ref{th:EquivalenceECETOB}}\label{sec:EquivalenceECETOB}


\paragraph{From {\EC} to {\ETOB}}
To prove this result, it is sufficient to provide a protocol that implements \ETOB~in an environment  knowing that there exists a protocol that implements \EC~in this environment. This transformation protocol  is stated in Algorithm \ref{algo:ECtoETOB}. Now, we are going to prove that  implements \ETOB.

Assume that there exists a message  broadcast by a correct process
 at time . As  is correct, every correct process receives
the message  in a finite time. Then,  appears in the set
 of all correct processes in a finite time. Hence, by the
termination property of \EC~and the construction of the function
, there exists  such that  is included in any
sequence submitted to . By the \EC-Validity
and the \EC-Termination properties, we deduce that  stably delivers  in a finite time, that proves that  satisfies the \TOB-Validity property.

If a process  delivers a message  at time , then 
appears in the sequence responded by its last invocation of
. By construction and by the \EC-Validity
property, this sequence contains only messages that appear in the set  of a process  at the time  invokes . But this set is incrementally built at the reception of messages  that contains only messages broadcast by a process. This implies that  satisfies the \TOB-No-creation.

As the sequence outputted at any time by any process is the response to its last invocation of  and that the sequence submitted to any invocation of this primitive contains no duplicated message (by definition of the function ), we can deduce from the \EC-Validity property that  satisfies the \TOB-No-duplication.

Assume that a correct process  stably delivers a message ,
i.e., there exists a time after which  always appears in .
By the algorithm,  always appears in the response of
 to  after this time.
As \EC-Agreement property is eventually satisfied, we can deduce that
 always appears in the response of  for any
correct process after some time. Thus, any correct process stably
delivers , and  satisfies the \TOB-Agreement.

Let  be the time after which the \EC~primitive satisfies \EC-Agreement and \EC-Validity.

Let  be a correct process and . Let  (respectively ) be the integer such that  (respectively ) is the response of  (respectively ). By construction of the protocol and the \EC-Agreement and \EC-Validity properties, we know that, after time , the response of  to correct processes is a prefix of the response of . As we have , we can deduce that  satisfies the \ETOB-Stability property.

Let  and  be two correct processes such that two messages  and  appear in  and  at time . Let  be the smallest integer such that  and  appear in the response of . By the \EC-Agreement property, we know that the response of  is identical for all correct processes. Then , by the \ETOB-Stability property proved above, that implies that, if  appears before  in , then  appears before  in . In other words,  satisfies the \ETOB-Total-order property.

In conclusion,  satisfies the \ETOB~specification in an environment  provided that there exists a protocol that implements \EC~in this environment.

\begin{algorithm}
\caption{: transformation from \EC~to \ETOB~for process }\label{algo:ECtoETOB}
\small
\begin{description}\itemsep0pt
\item[Output variable:]~\\
: sequence of messages of  (initially empty) outputted at any time by 

\item[Internal variables:]~\\
: set of messages of  (initially empty) containing all messages received by ~\\
: integer (initially ) that stores the number of the last instance of consensus invoked by 

\item[Messages:]~\\
  with  a message of 

\item[Functions:]~\\
 sends  to all processes (including )\\
 returns a sequence containing all messages from the set 

\item[On reception of  from the application]~\\


\item[On reception of  from ]~\\


\item[On reception of  as response of ]~\\
\\
\\


\item[On local timeout]~\\
If  then\\


\end{description}
\normalsize
\end{algorithm}



\paragraph{From {\ETOB} to {\EC}}
To prove this result, it is sufficient to provide a protocol that
implements \EC~in an environment  given a protocol that
implements \ETOB~in this environment. This transformation protocol
 is stated  in Algorithm
\ref{algo:ETOBtoEC}. Now, we are going to prove that  implements \EC.

Let  be a correct process that invokes  with . Then, by fairness and the \TOB-Validity property, the construction of the protocol implies that the \ETOB~primitive delivers the message  to  in a finite time. By the use of the local timeout, we know that  returns from  in a finite time, that proves that  satisfies the \EC-Termination property.

The update of the variable  to  for any process  that invokes  and the assumptions on operations  ensure us that  executes at most once the function\linebreak . Hence,  satisfies the \EC-Integrity property.

Let  be the time after which the \ETOB-Stability and the \ETOB-Total-order properties are satisfied. Let  be the smallest integer such that any process that invokes  in run  invokes it after .

If we assume that there exist two correct processes  and  that return different values to  with , we obtain a contradiction with the \ETOB-Stability, \ETOB-Total-order, or \TOB-Agreement property. Indeed, if  returns a value after time , that implies that this value appears in  and then, by the \TOB-Agreement property, this value eventually appears in . If  returns a different value from , that implies that this value is the first occurrence of a message associated to  in  at the time of the return of . After that,  cannot satisfy simultaneously the \ETOB-Stability and the \ETOB-Total-order properties. This contradiction shows that  satisfies the \EC-Agreement property.

If we assume that there exists a process  that returns to  with  a value that was not proposed to , we obtain a contradiction with the \TOB-No-creation property. Indeed, the return of  from  is chosen in  that contains the output of the \ETOB~primitive and processes broadcast only proposed values. This contradiction shows that  satisfies the \EC-Validity property.

In conclusion,  satisfies the \EC~specification in an environment  provided that there exists a protocol that implements \ETOB~in this environment.


\begin{algorithm}
\caption{: transformation from \ETOB~to \EC~for process }\label{algo:ETOBtoEC}
\small
\begin{description}\itemsep0pt
\item[Internal variables:]~\\
: integer (initially ) that stores the number of the last instances of consensus invoked by \\
: sequence of messages (initially empty) outputted to  by the \ETOB~primitive

\item[Functions:]~\\
: returns the value  such that  is the first message of the form  in  if such messages exist,  otherwise\\
: returns the value  as response to 

\item[On invocation of ]~\\
\\


\item[On local time out]~\\
If  then\\

\end{description}
\normalsize
\end{algorithm}

\subsection{Proof of Lemma \ref{lem:SufficiencyOmegaEC}}\label{sec:SufficiencyOmegaEC}

\begin{proof}
We propose such an implementation in Algorithm~\ref{algo:EC}. Then, we
prove that any admissible run  of the algorithm in any environment

satisfies the \EC-Termination, \EC-Integrity, \EC-Agreement, and \EC-Validity properties.

Assume that a correct process never returns from an invocation of
 in . Without loss of generality, denote by
 the smallest integer such that a correct process  never
returns from the invocation of . This implies
that  always evaluates  to
. We know by definition of  that, eventually, 
always returns the same correct process . Hence, by construction
of ,  returns from ,...,
 and then sends the message
 to all processes in a finite time. As  and
 are correct,  receives this message and updates
 to  in a finite time. Therefore, the
algorithm satisfies the \EC-Termination property.

The update of the variable  to  for any process 
that invokes  and the assumptions on operations
 ensure us that  executes at most once the
function \linebreak . Hence, the
\EC-Integrity property is satisfied.

Let  be the time from which the local outputs of 
are identical and constants for all correct processes in . Let 
be the smallest integer such that any process that invokes
 in  invokes it after .

Let  be an integer such that . Assume that  and
 are two processes that respond to . Then,
they respectively execute the function
 and
. By construction of , we
can deduce that . That implies that  and
 both received a message  from . As 
sends such a message at most once, we can deduce that
, that proves that ensures
the \EC-Agreement property.

Let  be an integer such that . Assume that  is
a process that respond to . The value returned
by  was previously received from  in a message of type
. By construction of the protocol,  sends only one
message of this type and this latter contains the value proposed to
, hence, the \EC-Validity property is satisfied.

Thus, Algorithm~\ref{algo:EC} indeed implements \EC~in any
environment using .
\end{proof}

\begin{algorithm}
\caption{\EC~using : algorithm for process }\label{algo:EC}
\small
\begin{description}\itemsep0pt
\item[Local variables:]~\\
: integer (initially ) that stores the number of the last instances of consensus invoked by \\
: two dimensional tabular that stores a value for each pair of processes/integer (initially )

\item[Functions:]~\\
 returns the value  as a response to 

\item[Messages:]~\\
 with  and 

\item[On invocation of ]~\\
\\
  to all

\item[On reception of  from ]~\\


\item[On local time out]~\\
If  do\\


\end{description}
\normalsize
\end{algorithm}

\subsection{Proof of Correctness of Algorithm \ref{algo:ETOB}}\label{sub:ETOB}


\begin{algorithm}[t]
\caption{: protocol for process }\label{algo:ETOB}
\footnotesize
\begin{description}\itemsep0pt

\item[Output variable:]~\\
: sequence of messages  (initially empty) output by 

\item[Internal variables:]~\\
: sequence of messages  (initially empty) promoted by  when \\
: directed graph on messages of  (initially empty) that contains causality dependencies known by 

\item[Messages:]~\\
  with  a directed graph on messages of \\
 with  a sequence of messages 

\item[Functions:]~\\
 adds the node  and the set of edges  to \\
 replaces  by the union of  and \\
 replaces  by one of the sequences of messages  such that  is a prefix of ,  contains once all messages of , and for every edge  of ,  appears before  in 

\item[On reception of  from the application]~\\
\\
  to all

\item[On reception of  from ]~\\
\\


\item[On reception of  from ]~\\
If  then\\


\item[On local time out]~\\
If  then\\


\end{description}
\normalsize
\end{algorithm}


\begin{proof}
First, we prove that any run  of  in any environment  satisfies the \TOB-Validity, \TOB-No-creation, \TOB-No-duplication, and \TOB-Agreement properties.

Assume that a correct process  broadcasts a message  at time  for a given . We know that  outputs the same correct process  to all correct processes in a finite time. As  is correct, it receives the message  from  (that contains ) in a finite time. Then,  includes  in its causality graph (by a call to ) and in its promotion sequence (by a call to ). As  never removes a message from its promotion sequence and is outputted by ,  adopts the promotion sequence of  in a finite time and this sequence contains , that proves that  satisfies the \TOB-Validity property.

Any sequence outputted by any process is built by a call to  by a process .  This function ensures that any message appearing in the computed sequence appears in the graph . This graph is built by successive calls to  that ensure that the graph contains only messages received in a message of type . The construction of the protocol ensures us that such messages have been broadcast by a process. Then, we can deduce that  satisfies the \TOB-No-creation property.

Any sequence outputted by any process is built by a call to  that ensures that any message appears only once. Then, we can deduce that  satisfies the \TOB-No-duplication property.

Assume that a correct process  stably delivers a message  at time 
for a given . We know that  outputs the same
correct process  to all correct processes after some finite
time. Since  appears in every  such that , we
derive that  appears infinitely in  from a given point
of the run. Hence, the construction of the protocol and the correctness
of  implies that any correct process eventually stably delivers
, and   satisfies the \TOB-Agreement property.

We now prove that, for any environment , for any run  of  in , there exists a  satisfying \ETOB-Stability, \ETOB-Total-order, and \TOB-Causal-Order properties in . Hence, let  be a run of  in an environment . Let us define:
\begin{itemize}
\item  the time from which the local outputs of  are identical and constant for all correct processes in ;
\item  the longest communication delay between two correct processes in ;
\item  the longest local timeout for correct processes in ;
\item 
\end{itemize}

Let  be a correct process and  be the correct elected by  after . Let  and  be two integers such that . As the output of  is stable after  and the choice of  ensures us that  receives at least one message of type  from , we can deduce from the construction of the protocol that there exists  and  such that  and . But the function  used to build  ensures that  is a prefix of . Then,  satisfies the \ETOB-Stability property after time .

Let  and  be two correct processes such that two messages  and  appear in  and  at time . Assume that  appears before  in . Let  be the correct elected by  after . As the output of  is stable after  and the choice of  ensures us that  and  receive at least one message of type  from , the construction of the protocol ensures us that we can consider  and  such that  and . The definition of the function  executed by  allows us to deduce that either  is a prefix of  or  is a prefix of . In both cases, we obtain that  appears before  in , that proves that  satisfies the \ETOB-Total-order property after time .

Let  be a correct process such that two messages  and  appear in  at time . Assume that  when  is broadcast. Let  be the process trusted by  at the time  adopts the sequence . If  appears in , that implies that the edge  appears in  at the time  executes  (since  previously executed  that includes at least  and the set of edges  in ). The construction of  ensures us that  appears before  in , that proves that  satisfies the \TOB-Causal-Order property.

In conclusion,  is an implementation of \ETOB~assuming that processes have access to the  failure detector in any environment.
\end{proof}
}

\section{Discussion on Eventual Consensus}
\label{app:eic}


Our definition of Eventual Consensus \EC~relaxes the Agreement property which holds after a finite number of operations. We could instead relax the Integrity property where processes can change their decisions a finite number of times. We discuss here the resulting abstraction.

\subsection{Eventual Irrevocable Consensus (\EIC)}

The \emph{eventual irrevocable consensus} (\EIC) abstraction exports, to every process , operations , ,  that take binary arguments and return binary responses. If a process  responds more than once to  for some , we consider that the response of  to  at time  is its last response to  before .

Assuming that every process receives  as soon as it returns a (first) response to  for all , the abstraction guarantees, for every run, there exists  such that the following properties are satisfied:

\begin{description}\itemsep0pt
\item[\EIC-Termination] Every correct process eventually returns a response to  for all .
\item[\EIC-Integrity] No process responds twice to  for all .
\item[\EIC-Agreement] No two processes return infinitely different values to  for any .
\item[\EIC-Validity] Every value returned to  was previously proposed to  for all .
\end{description}

\begin{theorem}\label{th:EquivalenceECEIC}
In every environment , \EC~and \EIC~are equivalent.
\end{theorem}

\subsection{Transformation from \EC~to \EIC}

\begin{lemma}\label{lem:ECtoEIC}
In every environment , there exists a transformation from \EC~to \EIC.
\end{lemma}

\begin{proof}
To prove this result, it is sufficient to provide a protocol that implements \EIC~in an environment  knowing that there exists a protocol that implements \EC~in this environment. This transformation protocol  is stated in Algorithm \ref{algo:ECtoEIC}. Now, we are going to prove that  implements \EIC.

As any invocation of  by a correct process  leads to an invocation of  by the same process, the \EC-Termination property ensures us that  receives eventually a response (a sequence ) from the \EC~primitive. Before this response, we have . By the \EC-Validity property, we know that  is a value proposed by one process (hence not equal to ). Then, the construction of the protocol ensures us that  is executed in a finite time, that proves that  satisfies the \EIC-Termination property.

Let  be the index after which the \EC~primitive satisfies \EC-Agreement property. Let  be the smallest time where all correct processes receive the response of .

After time , we know that the sequences  returned to all process are identical. Then, the construction of the protocol ensures us that every sequence submitted to the \EC~primitive is prefixed by the last sequence returned by this primitive. Hence, the \EC-Agreement property ensures us that, after time ,  is executed only for the last value of the decision sequence and only when this sequence grows, that proves that  satisfies the \EIC-Integrity property.

Assume that two processes  and  return forever two different values for  for some . By the \EIC-Integrity property proved above, we know that  and  take at most one decision for  after time . That implies that  and  return different values at their last decision. Then, we can deduce that  forever, that is contradictory with the definition of  or with the \EC-Agreement property. This contradiction shows us that  satisfies the \EIC-Agreement property.

The fact that  satisfies the \EIC-Validity directly follows from the \EC-Validity.

In conclusion,  satisfies the \EIC~specification in an environment  provided that there exists a protocol that implements \EC~in this environment.
\end{proof}

\begin{algorithm}
\caption{: transformation from \EC~to \EIC~for process }\label{algo:ECtoEIC}
\small
\begin{description}\itemsep0pt
\item[Internal variables:]~\\
: sequence of values decided by  (initially )

\item[Functions:]~\\
 returns the value  as a response to 

\item[On invocation of ]~\\


\item[On reception of  as response of ]~\\
For  from  to  do\\
\\


\end{description}
\normalsize
\end{algorithm}

\subsection{Transformation from \EIC~to \EC}

\begin{lemma}\label{lem:EICtoEC}
In every environment , there exists a transformation from \EIC~to \EC.
\end{lemma}

\begin{proof}
To prove this result, it is sufficient to provide a protocol that implements \EC~in an environment  knowing that there exists a protocol that implements \EIC~in this environment. This transformation protocol  is stated in Algorithm \ref{algo:EICtoEC}. Now, we are going to prove that  implements \EC.

As any invocation of  by a correct process  leads to an invocation of  by the same process, the \EIC-Termination property ensures us that  receives eventually at least one response from the \EIC~primitive. The use of the counter  allows us to deduce that only the first response from the \EIC~primitive leads to a decision for  by , that proves that  satisfies the \EC-Termination and the \EC-Integrity properties.

The construction of the protocol and the \EIC-Agreement and the \EIC-Validity properties trivially imply that  satisfies the \EC-Agreement and the \EC-Validity properties.

In conclusion,  satisfies the \EC~specification in an environment  provided that there exists a protocol that implements \EIC~in this environment.
\end{proof}

\begin{algorithm}
\caption{: transformation from \EIC~to \EC~for process }\label{algo:EICtoEC}
\small
\begin{description}\itemsep0pt
\item[Internal variables:]~\\
: integer (initially ) that stores the number of the last instance of consensus invoked by 

\item[Functions:]~\\
 returns the value  as a response to 

\item[On invocation of ]~\\
\\


\item[On reception of  as response of ]~\\
If  then\\


\end{description}
\normalsize
\end{algorithm}

\section{Background on the CHT proof}
\label{app:cht}

Let  be any environment,  be any {\fd} that can be used
	to solve consensus in , and  be any algorithm that solves consensus
	in  using .
We  determine a reduction algorithm  that, using failure
	detector  and algorithm ,
	implements  in .
Recall that implementing  means outputting, at every process,
	the id of a process so that eventually,
	the id of the same correct process is output permanently at all correct
	processes.

\subsection{Overview of the reduction algorithm}
\label{subsec:cht:overview}


The basic idea underlying  is to have each process
	locally {\em simulate} the overall distributed system
	in which the processes execute several runs of 
	that \emph{could have happened} in the current failure
	pattern and {\fd} history.
Every process then uses these runs to extract .

In the local simulations, every process  feeds algorithm 
	with a set of proposed values, one for each process of the
	system. Then all automata composing  are triggered
	locally by  which emulates,
	for every simulated run of , the states of all processes as well as
	the emulated buffer of exchanged messages.

Crucial elements that are needed for the simulation
	are (1) the values from {\fd}s
	that would be output by  as well as
	(2) the order according to which the processes
	are taking steps.
For these elements, which we call the stimuli of
	algorithm , process  periodically queries its {\fd} module
	and exchanges the {\fd} information with the other processes.


The reduction algorithm  consists of two tasks that are run
	in parallel at every process:
	the \emph{commmuncation task} and the \emph{computation task}.
In the communication task, every process maintains ever-growing stimuli
	of algorithm  by periodically querying its {\fd} module
	and sending the output to all other processes.
In the computation task, every process periodically feeds the stimuli
	to algorithm , simulates several runs of ,
	and computes the current emulated output of .


\subsection{Building a DAG}
\label{subsec:cht:dag}


The communication task of algorithm  is presented in Figure~\ref{fig:CHT-comm}.
Executing this task,  knows more and more of the processes'
	{\fd} outputs and temporal relations between
	them.
All this information is pieced together in a single data structure,
	a directed acyclic graph (DAG) .
Informally, every vertex  of  is a {\fd} value
``seen'' by  in its -th query of its {\fd} module.
An edge   can be  interpreted as
	`` saw {\fd} value  (in its -th query)
\emph{before}  saw {\fd} value  (in its -th query)''.

\begin{figure}[tbp]
\hrule \vspace{2mm}
{\small
\begin{tabbing}
 bbb\=bb\=bb\=bb\=bb\=bb\=bb\=bb \=  \kill
\>  empty graph\\
\> \\
\> \textbf{while} true \textbf{do}\\
\>\>	receive message \\
\smallskip
\>\> 	 query {\fd} \\
\smallskip
\>\>	\\
\>\> \textbf{if}  is of the form  \textbf{then} \\
\>\>	add  and edges from all vertices of  to  to \\
\>\>	send  to all 
\end{tabbing}
\hrule
}
\caption{Building a DAG: process }
\label{fig:CHT-comm}
\end{figure}

DAG  has some special properties which follow from its construction.
Let  be the current failure pattern in  and 
	be the current {\fd} history in .
Then: \begin{enumerate}
\item[(1)]  The vertices of  are of the form  where ,
 and .
There is a mapping ,
associating a time with every vertex of ,
such that:
\begin{enumerate}
\item[(a)] For any vertex ,  and .
That is,  is the value output by 's {\fd} module at time .

\item[(b)] For any edge  in , .
That is, any edge in  reflects the temporal order
	in which the {\fd} values are output.
\end{enumerate}
\item[(2)] If  and  are vertices of , and , then
 is an edge of .
\item[(3)]  is transitively closed: if  and  are edges of ,
	then  is also an edge of .
\item[(4)] For all correct processes  and  and all times ,
	there is a time , a  and a
	 such that for every  vertex  of ,
	 is an edge of .\footnote{
	For any variable  and time ,  denotes
	the value of  at time .}
\end{enumerate}


Note that properties (1)--(4) imply that, for every correct process ,  and ,
	there is a time  such that  contains a path
	, such that
	(a) every correct process appears at least  times in ,
	and (b) for any path  in ,  is also a path in .



\subsection{Simulation trees}
\label{subsec:cht:simulation}


Now DAG  can be used to simulate runs of .
Any path   
	through  gives the order in which
	processes ,   ``see'', respectively,
	{\fd} values ,  .
That is,  contains an activation schedule and {\fd}
	outputs for the processes to execute steps of
	's instances.
Let  be any initial configuration of .
Consider a schedule  that is applicable to 
	and \emph{compatible with },
	i.e.,  and , , where
	 is a message addressed to  (or the null message ).

All schedules that are applicable to  and compatible with paths in 
	can be represented as a tree , called the
	\emph{simulation tree induced by  and }.
The set of vertices of  is the set of all schedules  that are applicable to 
	and compatible with paths in .
The root of  is the empty schedule .
There is an edge from  to  if and only if  for a step ;
	the edge is labeled .
Thus, every vertex  of  is associated with a sequence
	of steps  consisting of labels of the edges
	on the path from  to .
In addition, every descendant of  in  corresponds to 	
	an extension of .

The construction of  implies that, for any vertex  of ,
	there exists a partial run
	 of  where  is the current failure pattern and
	 is the current {\fd} history.
Thus, if in , correct processes appear sufficiently often
	and receive sufficiently many messages sent to them,
	then every correct (in ) process decides in .

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=.9]{CHT-dag-tree.0}
  \caption{A DAG and a tree}
  \label{fig:dag-tree}
\end{figure}

In the example depicted in Figure~\ref{fig:dag-tree},
	a DAG (a) induces a simulation tree a portion of which is shown in (b).
There are three non-trivial paths in the DAG: ,
	, 
	and .
Every path through the DAG and an initial configuration 
	induce at least one schedule in the simulation tree.
Hence, the simulation tree has at least three leaves:
	  ,  , and
	.
Recall that  is the empty message: since the message buffer is empty in ,
	no non-empty message can be received in the first step of any schedule.

\subsection{Tags and valences}
\label{subsec:cht:valence}


Let ,  denote the initial configuration of 
	in which processes  propose  and the rest (processes
	) propose .
In the computation task of the reduction algorithm, every process
	 maintains an ever-growing \emph{simulation forest}
	
	where  () denotes
	the simulation trees induced by  and initial configurations
	.

For every vertex of the simulation forest, 
	assigns a set of \emph{tags}.
Vertex  of tree  is assigned a tag  if and only if
	 has a descendant  in  such that
	 decides  in .
We call the set tags the \emph{valence} of the vertex.
By definition, if  has a descendant with a tag , then  has tag .
Validity of consensus ensures that the set of tags is a subset of .


Of course, at a given time, some vertices of the simulation forest  might not have
	any tags because the simulation stimuli are not sufficiently long yet.
But this is just a matter of time: if  is correct, then
	every vertex of 's simulation forest will eventually have an extension	
	in which correct processes appear sufficiently often for 
	to take a decision.
	
A vertex  of  is \emph{-valent} if it has exactly one tag 
	(only  can be decided in 's extensions in ).
A -valent vertex is analogously defined.
If a vertex  has both tags  and  (both  and  can be decided
	in 's extensions), then we say that  is \emph{bivalent}.\footnote{
		The notion of valence was first defined in~\cite{FLP85} as
		the set of values than are decided in
		\emph{all} extensions of a given execution.
		Here we define the valence as only a subset of these values,
		defined by the simulation tree.}

It immediately follows from Validity of consensus that
	the root of  can at most be -valent,
	and the root of  can at most be -valent
	(the roots of  and  cannot
	be bivalent).


\subsection{Stabilization}
\label{subsec:cht:stabilization}


Note that the simulation trees can only grow with time.
As a result, once a vertex of the simulation forest  gets a tag , it
	cannot lose it later.
Thus, eventually every vertex of  stabilizes being
	-valent, -valent, or bivalent.
Since correct processes keep continuously exchanging the {\fd} samples
	and updating their simulation forests,
	every simulation tree computed by a correct process at any given time
	will eventually be a subtree of the simulation forest of every correct process.

Formally, let  be any correct process,  be any time, 
	be any index in , and  be any vertex of
	. Then:\begin{enumerate}

\item[(i)] There exists a non-empty  such that
	there is a time after which the valence of  is .
	(We say that the valence of  \emph{stabilizes} on  at .)

\item[(ii)] If the valence of  stabilizes on  at , then
	for every correct process , there is a time after
	which  is a vertex of  and
	the valence of  stabilizes on  at .

\end{enumerate}

Hence, the correct processes eventually agree on the same tagged simulation
	subtrees.
In discussing the stabilized tagged simulation forest,
	it is thus convenient to consider the \emph{limit}
	infinite DAG  and the \emph{limit} infinite simulation
	forest 
	such that for all  and all correct processes ,
	 and
	.


	
\subsection{Critical index}
\label{subsec:cht:critical}


Let  be any correct process.
We say that index  is \emph{critical}
	if \emph{either} the root of  is bivalent \emph{or}
	the root of  is -valent and the root of  is -valent.
In the first case, we say that  is \emph{bivalent critical}.
In the second case, we say that
	 is \emph{univalent critical}.

\begin{lemma}
\label{lemma:cht-critical}
There is at least one critical index in .
\end{lemma}
\begin{proof}
Indeed, by the Validity property of consensus, the root of  is -valent,
	and the root of  is -valent.
Thus, there must be an index  such that
	the root of  is -valent,
	and  is either
	-valent or bivalent.
\end{proof}

\noindent
Since tagged simulation forests computed at the correct processes tend
	to the same infinite tagged simulation forest,
	eventually, all correct processes compute the same \emph{smallest} critical
	index  of the same type (univalent or bivalent).
Now we have two cases to consider for the smallest critical index: (1)  is univalent critical, or
	(2)  is bivalent critical.

\ignore{
Before extracting a correct process from the simulated forest,
	we observe the following:
\begin{lemma}
\label{lemma:cht-similar}
Let  and  be two vertices of  and  be a process
	 such that for all ,
	the states of  in  and  are identical.
If  is -valent and  is -valent, then  is correct.
\end{lemma}
\begin{proof}
By contradiction, assume that  is faulty.
Let  be induced by a path  in , and let  be
	induced by a path  in .
Then  contains infinite paths  and  such that in ,
	 does not participate and every correct process participates infinitely often.
Then  contains a schedule 
	that is applicable to  (induced by a prefix of  and ) in which
	 does not take steps and every correct process  decides.
Since  is -valent,  decides  in .
But  is the only process that has different states in
	, and  and  does not take part in .
Thus,  (induced by a prefix of  and ) is also a vertex of ,
	and  decides  in .
But the root of  is -valent
	--- a contradiction.
\end{proof}
}

\subsubsection*{(1) Handling univalent critical index}
\label{subsec:cht:univalent}


\begin{lemma}
\label{lemma:cht-univalent}
If  is univalent critical, then  is correct.
\end{lemma}
\begin{proof}
By contradiction, assume that  is faulty.
Then  contains an infinite path  in which  does not participate
	and every correct process participates infinitely often.
Then  contains a vertex  such that  does not take steps in  and some correct process  decides in .
Since  is -valent,  decides  in .
But  is the only process that has different states in
	 and , and  does not take part in .
Thus,  is also a vertex of 
	and  decides  in .
But the root of  is -valent
	--- a contradiction.
\end{proof}


\subsubsection*{(2) Handling bivalent critical index}
\label{subsec:cht:bivalent}


Assume now that the root of  is \emph{bivalent}.
Below we show that  then contains a \emph{decision gadget}, i.e.,
	a finite subtree which is either a \emph{fork} or a \emph{hook}
	(Figure~\ref{fig:CHT-fork-hook}).

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=.85]{CHT-fork-hook.0}
  \caption{A fork and a hook}
  \label{fig:CHT-fork-hook}
\end{figure}


A fork (case (a) in Figure~\ref{fig:CHT-fork-hook}) consists of a bivalent
	vertex  from which two \emph{different} steps by the
	\emph{same} process , consuming the same message ,
	are possible which lead, on the one hand, to
	a -valent vertex  and, on the other hand, to a -valent vertex
	.

A hook (case (b) in Figure~\ref{fig:CHT-fork-hook}) consists of a
	bivalent vertex , a vertex  which is reached by
	executing a step of some process , and two vertices
	 and  reached by applying \emph{the same} step of process 
	to, respectively,  and .
Additionally,  must be -valent and  must be -valent (or vice
	versa; the order does not matter here).

In both cases, we say that  is the \emph{deciding process}, and
	 is the \emph{pivot} of the decision gadget.



\begin{lemma}
\label{lemma:cht-deciding}
The deciding process of a decision gadget is correct.
\end{lemma}
\begin{proof}
Consider any decision gadget  defined by a pivot ,
	vertices  and  of opposite
	valence and a deciding process .
By contradiction, assume that  is faulty.
Let ,  and  be the simulation stimuli of, respectively,
	,  and .
Then  contains an infinite path  such that
	(a) , , 
	are paths in , and
	(b)  does not appear
	and the correct processes appear infinitely often in .

Let  be a fork (case (a) in Figure~\ref{fig:CHT-fork-hook}).
Then there is a finite schedule  compatible with a prefix of  and
	applicable to  such that some correct process
	 decides in ;
	without loss of generality, assume that  decides .
Since  is the only process that can distinguish  and ,
	and  does not appear in ,
	 is also applicable to .
Since  is a path of  and  is compatible with a prefix of ,
	it follows that   is a vertex of .
Hence,  also decides  in .
But  is -valent --- a contradiction.

Let  be a hook (case (b) in Figure~\ref{fig:CHT-fork-hook}).
Then there is a finite schedule  compatible with a prefix of  and
	applicable to  such that some correct process
	 decides in .
Without loss of generality, assume that  is -valent, and hence  decides 
	in  .
Since  is the only process that can distinguish  and ,
	and  does not appear in ,
	 is also applicable to .
Since  is a path of  and  is compatible with a prefix of ,
	it follows that   is a vertex of .
Hence,  also decides  in 
But  is -valent --- a contradiction.
\end{proof}

\noindent
Now we need to show that any bivalent simulation tree  contains at
	least one decision gadget .


\begin{lemma}
\label{lemma:cht-bivalent}
If  is bivalent critical, then  contains a decision gadget.
\end{lemma}
\begin{proof}
Let  be a bivalent critical index.
In Figure~\ref{fig:CHT-gadget}, we present a procedure
	which goes through .
The algorithm starts from the bivalent root of  and
	terminates when a hook or a fork has been found.

\begin{figure}[htbp]
\hrule \vspace{2mm} {\small
\begin{tabbing}
 bbb\=bb\=bb\=bb\=bb\=bb\=bb\=bb \=  \kill
    \> \\
    \> \res{while} \id{true} \res{do}\\
    \>\> choose the next correct process in a round robin fashion\\
    \>\> choose the oldest undelivered message addressed to  in \\
    \>\> \res{if}  has a descendant  in  (possibly ) such that,
		for some ,\\
    \>\>\>\>  is a bivalent vertex of  \\
    \>\> \res{then} \\
    \>\> \res{else} \res{exit}
 \end{tabbing}
\hrule }
  \caption{Locating a decision gadget}
  \label{fig:CHT-gadget}
\end{figure}

We show that the algorithm indeed terminates.
Suppose not.
Then the algorithm locates an infinite \emph{fair path} through the
	simulation tree, i.e., a path in which all correct processes get
	scheduled infinitely often and every message sent to a correct
	process is eventually consumed.
Additionally, this fair path goes through bivalent states only.
But no correct process can decide in a bivalent state 
	(otherwise we would violate the Agreement property of consensus).
As a result, we constructed a run of  in which no correct process ever decides
	--- a contradiction.

Thus, the algorithm in Figure~\ref{fig:CHT-gadget} terminates.
That is, there exist a bivalent vertex , a correct process ,
	and a message  addressed to  in  such that
	
\begin{description}
\item[(*)] For all descendants  of  (including )
	and all ,  is \emph{not}
	a bivalent vertex of .
\end{description}

In other words, any step of  consuming message  brings any descendant of 
	(including  itself) to either a -valent or a -valent state.
Without loss of generality, assume that, for some ,  is
	a -valent vertex of .
Since  is bivalent, it must have a -valent descendant .

If  includes a step in which  consumes , then we define 
	as the vertex of  such that, for some ,  is a prefix of .
If  includes no step in which  consumes , then we define .
Since  is correct, for some ,  is a vertex of .
In both cases, we obtain  such that for some ,
	 is a -valent vertex of .

Let the path from  to  go through the vertices
	.
By transitivity of , for all ,
	 is a vertex of .
By (*),  is either -valent or -valent
	vertex of .

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=.87]{CHT-path.0}
  \caption{Locating a fork (Case~1) or a hook (Case~2)}
  \label{fig:CHT-path}
\end{figure}

Let  be the lowest index such that  brings 
to a -valent state. We know that such an index exists, since   is -valent
and all such resulting states are either -valent or -valent.

Now we have the following two cases to consider: (1) , and (2) .

Assume that , i.e.,  applied to  brings it to a -valent state.
But we know that there is a step  that brings  to a -valent state
	(Case~1 in Figure~\ref{fig:CHT-path}).
That is, a fork is located!

If , we have the following situation.
Step  brings  to a -valent state,
	and  to a -valent state
	(Case~2 in Figure~\ref{fig:CHT-path}).
But that is a hook!
				
As a result, any bivalent infinite simulation tree has at least one decision gadget.
\end{proof}

\subsection{The reduction algorithm}
\label{subsec:cht:reduction}


Now we are ready to complete the description of .
In the computation task (Figure~\ref{fig:CHT-comp}), every process 
	periodically extracts the current \emph{leader} from its
	simulation forest, so that eventually
	the correct processes agree on the same correct leader.
The current leader is stored in variable .

\begin{figure}[htbp]
\hrule \vspace{2mm} {\small
\setcounter{linenumber}{0}
\begin{tabbing}
 bbb\=bb\=bb\=bb\=bb\=bb\=bb\=bb \=  \kill
\>Initially:\\
\>\> for :  empty graph\\
\>\> \\
\\
\> \textbf{while} true \textbf{do}\\
\\
\>\>\{ Build and tag the simulation forest induced by  \}\\
\>\>	\textbf{for} 	\textbf{do} \\
\>\>\> 		 simulation tree induced by  and \\
\>\>\>		\textbf{for} every vertex  of :\\
\>\>\>\> 			\textbf{if}  has a descendant  such that  decides 
				in  \textbf{then} \\
\>\>\>\>\>			add tag  to \\
\\
\>\>\{ Select a process from the tagged simulation forest \}\\
\>\>	\textbf{if} there is a critical index \textbf{then}\\
\>\>\> 		 the smallest critical index\\
\>\>\>		\textbf{if}  is univalent critical \textbf{then}  \\
\>\>\> 		\textbf{if}  has a decision gadget \textbf{then}\\
\>\>\>\>			 the deciding process of the smallest
				decision gadget in  
\end{tabbing}
\hrule }
\caption{Extracting a correct leader: code for each process }
\label{fig:CHT-comp}
\end{figure}

Initially,  elects itself as a leader.
Periodically,  updates its simulation forest  by incorporating more
	simulation stimuli from .
If the forest has a univalent critical index , then  outputs  as
	the current leader estimate.
If the forest has a bivalent critical index  and  contains
	a decision gadget, then  outputs the deciding process of \emph{the smallest} decision
	gadget in  (the ``smallest'' can be well-defined,
	since the vertices of the simulation tree are countable).

Eventually, the correct processes locate the same \emph{stable} critical index .
Now we have two cases to consider:

\begin{enumerate}
\item[(i)]  is univalent critical.
	By Lemma~\ref{lemma:cht-univalent},  is correct.
\item[(ii)]  is bivalent critical.
	By Lemma~\ref{lemma:cht-bivalent}, the limit simulation tree 
		 contains a decision gadget.
	Eventually, the correct processes locate the same decision gadget
		 in  and compute the deciding process 
		of .
	By Lemma~\ref{lemma:cht-deciding},  is correct.
\end{enumerate}

Thus, eventually, the correct processes elect the same correct leader
	---  is emulated!






\end{document}
