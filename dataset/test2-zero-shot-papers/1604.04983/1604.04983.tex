\documentclass[a4paper,UKenglish]{lipics} 


\usepackage{macrosNew}
\Bleck

\usepackage{microtype}\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath} 
\usepackage{graphicx}
\usepackage{tikz-cd} \usepackage{enumitem} 

\bibliographystyle{plain}

\newcommand\Hid {\textbf{hid}}
\newcommand\Gets {{:}{=}\,}
\newcommand\Mod {\mathbin{\bf mod}}
\newcommand\Then {\textbf{then}}

\title{Compositional security  and collateral leakage}


\author[1]{N Bordenabe}
\author[1]{A McIver}
\author[2]{C Morgan}
\author[1]{T Rabehaja}
\affil[1] {Dept. Computing,
 Macquarie University, Sydney}
\affil[2]{Data61 \& UNSW,
  Sydney}
\authorrunning{Bordenabe, McIver, Morgan and Rabehaja} 



\keywords{Quantitative information flow, program semantics, secure refinement.}



\newcommand\DaleniusVar[2]{ {#1}^#2  }

\begin{document}

\maketitle

\begin{abstract}
In quantitative information flow we say that program  is ``at least as secure as''  just when the amount of secret information flowing from  is never more than flows from , with of course a suitable quantification of ``flow''.  
This secure-refinement order  is \emph{compositional} just when  implies  for any context , again with a suitable definition of ``context''.

Remarkable however is that leaks caused by executing  might not be limited to their declared variables: they might impact  correlated secrets in variables declared and initialised in some broader context to which  do not refer even implicitly. We call such  leaks \emph{collateral} because their effect is felt in domains of which (the programmers of)  might be wholly unaware: our inspiration is the ``Dalenius'' phenomenon for  statistical databases \cite{Dalenius:1977aa,Dwork:2006aa}. 

We show that a proper treatment of these collateral leaks is necessary for a compositional program semantics for read/write ``open'' programs. By adapting a recent Hidden-Markov denotational model for non-interference security \cite{McIver:2014ab,McIver:15}, so that it becomes ``collateral aware'', we give techniques and examples (e.g.\ public-key encryption) to show how collateral leakage can be calculated and then bounded in its severity.
\end{abstract}

\section{Introduction}\label{s1336}

The problem of information disclosure in the context of statistical databases was formulated by Dalenius as an ideal privacy goal: 
``Nothing about an individual should be learnable from the database that cannot be learned without access to the database''
\cite{Dalenius:1977aa}.  Later he  argued the infeasibility of such a strict goal; more recently Dwork \cite{Dwork:2006aa} addressed the same concern
demonstrating that 
whenever there is a (known)  \emph{correlation} between two pieces of information, anything learned about one piece implies that something might also be learned about the other.  In secure programming generally, i.e.\ not only read-only databases, this corresponds to leaking information about a secret ``high-level'' variable {\Pf X}, which then consequentially leaks information about a different high-level variable {\Pf Z} that \emph{does not appear in the program at all}, but is known via ``auxiliary information'' to be correlated with the initial value of {\Pf X}. Because of the generality of this programming-language perspective, we call this effect \label{g13928}\emph{collateral leakage}.
 
Here we study this broader phenomenon of collateral leakage
in the general setting of read/write programs operating as ``open systems''. Because  \cite{Alvim:2014aa} studied Dalenius leakage in terms of abstract channels (read-only programs), and \cite{McIver:15} explored the semantics of information flow for read/write programs operating as ``closed systems'' without external correlation, this work can be see as bringing the two together:
we compute general bounds on collateral leakage for read/write open systems, and we adapt our earlier fully abstract program semantics to treat it compositionally. 

The following ``password'' example helps to illustrate the issues.
\newpage 

\begin{figure}
 {\Pf\small
  \begin{tabular}{c}
   // Password X is initially uniformly distributed over . \\\-2.5ex]
    X\From\ [A,B,C] &  \\
    leak [{\Pf X},{\Pf X}] &  \\
   \end{tabular}
   \hspace{16em}
   \begin{tabular}[t]{ll}
    \textsf{``Strict'' user} \\\hline\ \\
    leak [{\Pf X},{\Pf X}] &  \\
   \end{tabular}\\\\
   \begin{tabular}{l@{~}l}
        & {\it {\Pf[...]} is the uniform distribution over {\Pf\{...\}}; and {\Pf X\From} assigns to {\Pf X} from a distribution.} \\
    ^+\CalX^-^\dagger^+^-^+^-^+^-\dagger\{\textsf{A},\textsf{B},\textsf{C}\}{\Pf X}{\Pf X}{\Pf Z}\CalX\CalY\CalX\CalY\CalX\CalX{\MFun}\CalYC\In\CalX{\MFun}\CalYC_{x,y}xyyxxC_{x,-}yC_{-,y}\CalS\Dist\CalS\CalSC_{x,-}C\In\CalX{\MFun}\CalY\Dist\CalY\CalX{\times}\CalY\CalX{\MFunR}\CalY\CalY\CalX\Dist\CalX{\Fun}\Dist^2\CalX\CalX\Dist\CalX\CalX\Dist(\Dist\CalX)\Dist^2\CalX\CalXy\In\CalYy\In\CalYyC\In\CalX{\MFun}\CalY\pi\In\CalX\Delta\In\Dist^2\CalXJ{\In}\Dist(\CalX{\times}\CalY)J_{x,y}\Defs \pi_xC_{x,y}yJ_{-,y}yy\piy\pi{\Apply}CJ[-]y\Delta=[\pi{\Apply}C]^+^-[\textsf{A},\textsf{B},\textsf{C}][\,[\textsf{B},\textsf{C}],[\textsf{C},\textsf{A}],[\textsf{A},\textsf{B}]\,]\CalXg\GainF{\CalW}\CalX = \CalW{\Fun}\CalX{\Fun}\Realw\In\CalW\CalWg\In\GainF{}\CalX[0,1][0,1]gwxg.w\CalX{\Fun}\Realgwg.wg.w.x(g.w)x\CalX\pi\CalX\Exp{\pi} g.w\Exp{\pi}{f}f\In\CalX{\Fun}\Real\pi\In\Dist Xxg.w.x\Realwx\CalW\CalXw\CalX\CalW{=}\CalXg.w.x = (\textrm{1 if  else 0})\BVg\CalW\CalWg\In\GainF{}\CalXgV_g\In\Dist\CalX{\Fun}\RealV_g[\pi]\Pi\In\Dist\CalXw\In\CalWg.w\pi\max_w(\Exp{\pi}{g.w})V_\BVgVV_g\Delta\Delta\In\Dist^2\CalXV_g\Delta\Dist\CalXV_g[\pi{\Apply}C]g\piC[-]V_g[\pi]V_g\pi\piC\piCggC\pig\log_2g\call_\forall(\forall, C)\call_\BVg(\forall, C)\CalZC\In\CalX{\MFun}\CalY\CalZ\CalX\CalZ\CalX\CalY\CalX\CalZ\CalX,\CalY,\CalZ\Pi\In\Dist(\CalZ{\times}\CalX)C\leftmarg\pi\CalZ\Pi\rightchan\Pi\CalZ{\MFun}\CalX\Pi = \leftmarg\pi{\Apply}\rightchan\Pi\Pi\Pi_{z,x}\leftmarg\pi_z\rightchan\Pi_{z,x}\leftmarg\pi\rightchan\Pi\rightchan\Pi{\MMult}CD\CalZ{\MFun}\CalYCD\rightchan\Pi{\MMult}C\rightchan\PiC\CalZ/\PiC\call_\forall(\leftmarg\pi, \rightchan\Pi{\MMult}C)C\CalZ\Pi\CalXMM_{x,x'}xx'CM\CM{C}{M}\CalX\MFun\CalY{\times}\CalX\CM{C}{M}_{x,y,x'} = C_{x,y}M_{x,x'}\CalX\CalY{\times}\CalXCMy,x'xH^{1,2}\CalX\MFun\CalY{\times}\CalX\CalX\MFun\CalY^2{\times}\CalXxx'x''(y^1,y^2)\CalY^2y^2x'x\CM{C}{M}C^{1,2},M^{1,2}C,M\CM{C^1}{M^1};\CM{C^2}{M^2} = \CM{C}{M}\CalX\CalY^{1,2}\CalY^1{\times}\CalY^2\MH\CalX\CalX\CalYH\MHH\chan.H\CalX{\MFun}\CalY(\chan.H)_{x,y}\Defs \sum_{x'}H_{xyx'}H\Pi\In\Dist(\CalZ{\times}\CalX)\rightchan\Pi{\MMult}\chan.H\rightchan\PiHHH = H^1;H^2;\cdots;H^NH^nyHy^1\cdots y^Ny^{n{+}1}{(x')}^nH^nH^n\CM{C^n}{M^n}H\CM{C}{M}(C^1{\Par}C^2)_{x,(y^1,y^2)} = C^1_{x,y^1}C^2_{x,y^2}MH\chan.HH\chan.H\call_\forall(\forall, \chan.H)H\CCap.HH{=}\CM{C}{M}H{=}\CM{C}{M};H'\call_\forall(\forall, \chan.H) \le \CCap.HM\CalZ\Pi\call_\forall(\forall,C)  = \call_\BVg(\Uni{\CalX}, C){\Uni{\CalX}}{\cal X}\Pi\CalZH\Pi\In\Dist(\CalZ{\times}\CalX)\leftmarg\pi,\rightmarg\pi\Pi\CalZ,\CalX\rightchan\Pi\hat{g}\In\GainF{\CalZ}\CalZ\hat{g}^{\joint}\In \GainF{\CalZ}\CalXH\CalZgH\CalX\pi\In\Dist\CalXH\Pi\Uni{\CalX}{\cal X}\leftmarg\pi,\rightchan\Pi\leftchan\Pi\rightchan\Pib^eb,eb^ee2{\cal D}\{2, 3, 5\}\CalD{\Pf E}\CalD{=}\{2\}\CalD{=}\{2,3\}\CalD{=}\{2,3,5\}\CalD{=}\{2\}\call_\BVg\call_{\forall}\call_\BVg(\forall, \textit{Prog})\CalD[\textsf{A},\textsf{B},\textsf{C}][\,[\textsf{B},\textsf{C}],[\textsf{C},\textsf{A}],[\textsf{A},\textsf{B}]\,]\dag[\,[\textsf{A},\textsf{B},\textsf{C}]\,][\,[{\cdots}]\,][\textsf{A},\textsf{B},\textsf{C}][\textsf{A}\At{\NF{1}{2}},\textsf{B}\At{\NF{1}{4}},\textsf{C}\At{\NF{1}{4}}]\NF{1}{2}\NF{1}{4}\NF{1}{3}\Ref\Dist^2\CalX\Ref\Delta^{1,2}\Delta^1\Ref\Delta^2V_g(\Delta^1)\geq V_g(\Delta^2)gV_gg[\,[\textsf{A},\textsf{B},\textsf{C}]\,]\lg3\approx1.58\NF{1}{2}{\cdot}1+\NF{1}{4}{\cdot}2+\NF{1}{2}{\cdot}2 = 1.5[\,[\textsf{A},\textsf{B},\textsf{C}]\,]\NF{1}{3}\NF{2}{3}\Dist\CalX{\Fun}\Dist^2\CalX\HMMSem{C}.\pi = [\pi{\Apply}C]\HMMSem{-}\CalX\MFun\CalY{\times}\CalXH\In\MH\Dist\CalX{\MFun}\Dist^2(\CalX{\times}\CalX')\pi[\pi{\Apply}H](\pi{\Apply}H)_{x,y,x'} = \pi_x H_{x,y,x'}\CalY\CalY{\times}(\CalX{\times}\CalX')\Dist^2(\CalX{\times}\CalX')\CalX\CalX'\HMMSem{H}\HMMSem{\cdot}\Dist\CalX{\MFun}\Dist^2\CalXh\CalZ\CalZh^{\CalZ}\In\Dist(\CalZ{\times}\CalX){\Fun}\Dist^2(\CalZ{\times}\CalX')\Pi\In\Dist(\CalZ{\times}\CalX)\Dist^2(\CalZ{\times}\CalX')h^\CalZh_{1,2}\In\Dist\CalX{\MFun}\Dist^2(\CalX{\times}\CalX')h_{1,2}h_1;h_2h_1\BSemi\,h_2^\CalX\BSemi\CalX{\times}\CalX'-^\CalX\CalZ\CalX\CalX\CalX'\HMMSem{H^1;H^2} = \HMMSem{H^1}\BSemi\HMMSem{H^2}\Pi{\In}\Dist(\CalZ{\times}\CalX)Z\In\CalZ{\MFunR}\CalX\CalX\pi{\In}\Dist\CalX\Pi=Z{\ApplyR}\pi\Pi_{z,x}=Z_{z,x}\pi_x\delta\In\Dist(\CalX{\times}\CalX')Z{\MMult}\delta\Dist(\CalZ{\times}\CalX')\Dist(Z\cdot)\Dist^2(\CalX{\times}\CalX')\Dist^2(\CalZ{\times}\CalX'){\Dist\CalX}h\Dist(\,\overbrace{\Dist(\CalX{\times}\CalX')}\,)Z{\ApplyR}\cdotZ\cdot\Dist(Z\cdot)\Dist(\CalZ{\times}\CalX)h^\CalZ\Dist(\CalZ{\times}\CalX')\Dist(\,\Dist(\CalZ{\times}\CalX')\,)\Pi\In\Dist(\CalZ{\times}\CalX)\Pi\pi{\In}\CalXZ\In\CalZ{\MFunR}\CalX\CalZ\Pix\pi.x{=}0\Dist(Z\cdot)h\pi\CalZh^\CalZh^\CalZ\Pi\In\Dist(\CalZ{\times}\CalX)\Dist\CalX\Fun\Dist^2(\CalX{\times}\CalX')\Dist(\CalZ{\times}\CalX)\Fun\Dist^2(\CalZ{\times}\CalX')V_gg\In\CalW{\Fun}(\CalX{\times}\CalX'){\Fun}\Realh_1{\Ref}h_2V_g(h_1.\pi)\geq V_g(h_2.\pi)g\pi\In\Dist\CalX\Ref\HMMSem{\cdot}\CalX\CalZ{\times}\CalX\pi\In\Dist\CalX[\,[0]\,]\Pf X:= Z;(-)h\CalZh^{{\times}\CalZ}\In\Dist(\CalZ{\times}\CalX)\Fun\Dist^2(\CalZ{\times}\CalX)^2\CalX'h^{\CalX{\times}\CalZ^2}\Dist(\CalZ^2{\times}\CalX^2)\Fun\Dist^2(\CalZ{\times}\CalX)^2\CalX\CalZ\Dist\zeta\In\CalZ{\times}\CalX\to(\CalZ{\times}\CalX)^2\zeta.(z,x) = (z,x,z,x)h^{\times\CalZ}h^{\CalZ^2{\times}\CalX}\circ\Dist\zeta\Dist(\CalZ{\times}\CalX)\to\Dist^2(\CalZ{\times}\CalX)^2h_{1,2}\In\Dist\CalX\to\Dist^2\CalX^2h_1\Ref h_2\Lift{h_1}{\CalZ}\Ref\Lift{h_2}{\CalZ}\CalZ\Dist\CalX\to\Dist^2\CalX^2\CalZg\Refgg\Ref\HMMSem{P}{=}\HMMSem{Q}\Implies\HMMSem{{\cal C}(P)}{=}\HMMSem{{\cal C}(Q)}\HMMSem{{\cal C}(-)}V_gP{\NRef}QP,Q\cal C\pi\pi{\cal C}(P){\cal C}(Q)gM^gP,QgP;M^gQ;M^gV_\BVgg\textsf{Lax}{\NRef}\textsf{Strict}g\CalX'\CalX'\dagg\CalX{\times}\CalX'\Pi^g\CalZ{=}\CalW\CalX\textsf{Lax}\textsf{Strict}\Pi^g\CalWgg\CalX[{\cdots}]\From{\Pf X}^+,{\Pf X}^-\CalX{\MFun}\CalY\CalX{\MFunR}\CalYC_{x,y},C_{x,-},C_{-,y}\Dist\pi{\Apply}C\CalY{\times}\CalX\piC[\textrm{joint distribution}]\Dist^2\Dist\CalX{\Fun}\Dist^2\CalX\CalW\Exp{\pi}{f}f\pig\In\GainF{}\CalX\BVgg\CalW{=}\CalXV_\BVgV_g\In\Dist\CalX{\Fun}\RealV_gg\call_gg\MMult\leftmarg{\pi},\rightchan{\Pi}\CM{C}{M}CM\chan\Par \CCap\Uni{\CalX}\CalX[\textsf{A}\At{\NF{1}{2}},\textsf{B}\At{\NF{1}{4}},\textsf{C}\At{\NF{1}{4}}]\Ref\HMMSem{\cdot}\pi{\Apply}H\CalX{\times}\CalY{\times}\CalX'\piH\Dist\CalX{\Fun}\Dist^2\CalX^2\Dist\CalX{\Fun}\Dist^2(\CalX{\times}\CalX')\CalX{=}\CalX'\CalX\Dist\CalX{\Fun}\Dist^2(\CalX{\times}\CalX')\HMMSem{H}H\In\CalX{\MFun}\CalY{\times}\CalX'h^{\CalZ}h^{{\times}\CalZ}\CalZ\zetah^{{\times}\CalZ}\NC_\CalX\CalX\Id_\CalX\CalX\CM{}{M}\CM{\NC}{M}\CM{C}{}\CM{C}{\Id}\Unit\{\Unit\}{\CalX} = \{{\Pf A},{\Pf B},{\Pf C}\}\CalX{\MFun}\CalX\CalX{\MFun}\CalY\CalY{=}\CalX\CalX\Fun\CalY{\times}\CalX\CalY\CalX\{\Unit\}{\CalX} = \{{\Pf A},{\Pf B},{\Pf C}\}^\ast^+^-^\dagger^+^-^\      & {\it {\Pf X} is the letter following {\Pf X}, and {\Pf X} the preceding.} \
 M^{L1}:\hspace{5em}
 \STRUT\left(
  \begin{array}{l@{}ccc}
   \ROW{\Pf A}&\COL{\Pf A}\NF{1}{3} & \COL{\Pf B}\NF{1}{3} & \COL{\Pf C}\NF{1}{3} \\
   \ROW{\Pf B}&\NF{1}{3} & \NF{1}{3} & \NF{1}{3} \\
   \ROW{\Pf C}&\NF{1}{3} & \NF{1}{3} & \NF{1}{3} \\
  \end{array}
 \right)
 \hspace{3em}\parbox{10em}{For \textsf{Lax} the input is ignored; the output is a uniform choice over .}

M^{S1}:\hspace{5em}
\STRUT\left(
  \begin{array}{l@{}ccc}
   \ROW{\Pf A}& \COL{\Pf A}0 & \COL{\Pf B}\NF{1}{2} & \COL{\Pf C}\NF{1}{2} \\
   \ROW{\Pf B}& \NF{1}{2} & 0 & \NF{1}{2} \\
   \ROW{\Pf C}& \NF{1}{2} & \NF{1}{2} & 0 \\
  \end{array}
 \right)
 \hspace{3em}\parbox{10em}{For \textsf{Strict} the output is a uniform choice over anything \emph{but} the input.}

 C^{2}:\hspace{5em}
 \STRUT\left(
  \begin{array}{l@{}ccc}
   \ROW{\Pf A}& \COL{\Pf A}0 & \COL{\Pf B}\NF{1}{2} & \COL{\Pf C}\NF{1}{2} \\
   \ROW{\Pf B}& \NF{1}{2} & 0 & \NF{1}{2} \\
   \ROW{\Pf C}& \NF{1}{2} & \NF{1}{2} & 0 \\
  \end{array}
 \right)
 \hspace{3em}\parbox{12em}{The over-the-shoulder leak is uniformly any value not equal to the current state.}

 \STRUT\left(
  \begin{array}{l@{}ccc}
   \ROW{\Pf A}&\COL{\Unit\Pf A}\NF{1}{3} & \COL{\Unit\Pf B}\NF{1}{3} & \COL{\Unit\Pf C}\NF{1}{3} \\
   \ROW{\Pf B}&\NF{1}{3} & \NF{1}{3} & \NF{1}{3} \\
   \ROW{\Pf C}&\NF{1}{3} & \NF{1}{3} & \NF{1}{3} \\
  \end{array}
 \right)
\hspace{8em}
 \STRUT\left(
  \begin{array}{l@{}ccc}
   \ROW{\Pf A}&\COL{\Unit\Pf A}0 & \COL{\Unit\Pf B}\NF{1}{2} & \COL{\Unit\Pf C}\NF{1}{2} \\
   \ROW{\Pf B}&\NF{1}{2} & 0 & \NF{1}{2} \\
   \ROW{\Pf C}&\NF{1}{2} & \NF{1}{2} & 0 \\
  \end{array}
 \right)

 \STRUT\left(
  \begin{array}{l@{}ccccccccc}
   & \COL{\Pf AA}~~~ & \COL{\Pf AB}~~~ & \COL{\Pf AC}~~~ & \COL{\Pf BA}~~~ & \COL{\Pf BB}~~~ & \COL{\Pf BC}~~~ & \COL{\Pf CA}~~~ & \COL{\Pf CB}~~~ & \COL{\Pf CC}~~~ \

\subsection{Sequential composition of \HMM-steps}
To get the \HMM\ representation of the two programs, we use the definition of \HMM\ sequential composition \Eqn{e1555} in \Sec{s1735}, which we repeat here for convenience:

We have two versions of , one for each of \textsf{Lax} and \textsf{Strict}, and a single version of  that applies to both. Type  is the unit ; and type  is the same as . Our composite \HMM\ (no longer simply an \HMM-step) will have observables' type , because we can drop the unit type;
\footnote{The Cartesian product  is isomorphic to  alone: we have \HMM-composed  and  to get , isomorphically .}
and its output type is still . For \textsf{Lax} the result is this \HMM, obtained by applying \Eqn{e1555} to \textsf{Lax}'s  and the common :
-1em]
   \ROW{\Pf A}& 0 & \NF{1}{6} & \NF{1}{6} & \NF{1}{6} & 0 & \NF{1}{6} & \NF{1}{6} & \NF{1}{6} & 0 \\
   \ROW{\Pf B}& 0 & \NF{1}{6} & \NF{1}{6} & \NF{1}{6} & 0 & \NF{1}{6} & \NF{1}{6} & \NF{1}{6} & 0 \\
   \ROW{\Pf C}& 0 & \NF{1}{6} & \NF{1}{6} & \NF{1}{6} & 0 & \NF{1}{6} & \NF{1}{6} & \NF{1}{6} & 0 \\
  \end{array}
 \right)
 \hspace{2em}\parbox{17em}{\small For \textsf{Lax} the rows are identical, because the input is ignored; the result is uniformly distributed over outcomes in which the leaked value and the new state are different.}

 \STRUT\left(
  \begin{array}{l@{}ccccccccc}
     & \COL{\Pf AA}~~~ & \COL{\Pf AB}~~~ & \COL{\Pf AC}~~~ & \COL{\Pf BA}~~~ & \COL{\Pf BB}~~~ & \COL{\Pf BC}~~~ & \COL{\Pf CA}~~~ & \COL{\Pf CB}~~~ & \COL{\Pf CC}~~~ \

\subsection{The semantic view: hypers for \textsf{Lax}}
We are now interested in the hypers produced by each of the two \HMM's just above when they are applied to the uniform prior  that assigns probability  to each of {\Pf A},{\Pf B},{\Pf C}, an assumption we have made for this example). We do \textsf{Lax} first: the joint distribution in , where we are now referring to the final state with a prime, is obtained by multiplying each row of the \HMM\ by the corresponding prior probability (in this case  for all of them), giving
-1em]
   \ROW{\Pf A}& 0 & \NF{1}{18} & \NF{1}{18} & \NF{1}{18} & 0 & \NF{1}{18} & \NF{1}{18} & \NF{1}{18} & 0 \\
   \ROW{\Pf B}& 0 & \NF{1}{18} & \NF{1}{18} & \NF{1}{18} & 0 & \NF{1}{18} & \NF{1}{18} & \NF{1}{18} & 0 \\
   \ROW{\Pf C}& 0 & \NF{1}{18} & \NF{1}{18} & \NF{1}{18} & 0 & \NF{1}{18} & \NF{1}{18} & \NF{1}{18} & 0 \\
  \end{array}
 \right)
\hspace{2em}\parbox{15em}{\small To convert this to a hyper on , we abstract from , the first component of each column.}
\label{e1743}
 [\,[\,{\Pf A},{\Pf B},{\Pf C}\,]{\times}[\,{\Pf B},{\Pf C}\,],\quad[\,{\Pf A},{\Pf B},{\Pf C}\,]{\times}[\,{\Pf A},{\Pf C}\,],\quad[\,{\Pf A},{\Pf B},{\Pf C}\,]{\times}[\,{\Pf A},{\Pf B}\,]\,]~.

 [\,[\,{\Pf B},{\Pf C}\,],\,[\,{\Pf A},{\Pf C}\,],\,[\,{\Pf A},{\Pf B}\,]\,]~,

 \STRUT\left(
  \begin{array}{l@{}ccccccccc}
   & \COL{\Pf AA}~~~ & \COL{\Pf AB}~~~ & \COL{\Pf AC}~~~ & \COL{\Pf BA}~~~ & \COL{\Pf BB}~~~ & \COL{\Pf BC}~~~ & \COL{\Pf CA}~~~ & \COL{\Pf CB}~~~ & \COL{\Pf CC}~~~ \
Again we concentrate on just one observation {\Pf A}, in which case, the posterior in  is .\footnote{Take each of the non-zero entries under a column with left component {\Pf A}; retain only  and , dropping the {\Pf A}; and, since all the probabilities are the same, form the uniform distribution on that.}
For observation {\Pf B}, analogously we get  ; for observation {\Pf C} we get  . Since the observations (again) have equal  probabilities, the overall hyper in  is again uniform:


Now if we project this hyper, for \textsf{Strict}, onto its second component (the final state), we get the same hyper in  as for \textsf{Lax} just above. But if we project onto the first component (the initial state), this time we get posterior 

which we constructed just by erasing the second component of each pair in \Eqn{e1719}. The ``uniform distribution'' with repeated components in the list gives proportionally more probability to the repetitions: written in the conventional way, for \Eqn{e1721} we would get

which is indeed the same as \Eqn{e0906} in \Sec{s1330} above.

\subsection{The semantics of composition, and relative security}
The above constructions started from Markov- and channel matrices, converted them into \HMM-step matrices, and then sequentially composed those matrices according to \Eqn{e1734}. The semantic alternative is to take the denotations at the very beginning, i.e.\ the abstract \HMM's corresponding to the individual program fragments, and then to compose them according to the \emph{semantic} definition at \Def{d1305}. The essential property  referred to there ensures that the outcome would have been the same. Thus, either way, we can summarise all the above by saying that \textsf{Lax}, as an abstract \HMM, takes prior  to hyper \Eqn{e1743} which, when projected onto the initial component  is  --- showing that indeed \textsf{Lax} releases nothing about the initial state. The same procedure with \textsf{Strict} however gives the initial-state hyper \Eqn{e1722} which is \emph{strictly less secure} than  in the hyper-order . This can be demonstrated even with Bayes Vulnerability , which is  for  but  for \Eqn{e1722} --- but, more significantly, that strict-less-secure relation means that \emph{for any } applying  to  will give no worse (i.e.\ no higher) vulnerability than applying it to \Eqn{e1722} or, equivalently, to \Eqn{e0906}.

\newpage
\section{Proofs for \Sec{s1221}}\label{a1626}
\subsection*{Proof for \Lem{l1029} \AppFrom{from \Sec{s1101}}}
\Cf{Why is this material all in Annabelle's colour?}
{\Ax
Let  be an \HMM\ and  an \HMM-step. Then 
where \C{in general } is parallel composition of channels. The  cannot be discarded, since it affects the prior of the ``tail''  of the sequential composition.
\begin{proof}
We prove each equality independently:

\begin{Reason}
	\Step{}{
		(\chan.\CM{C}{M})_{x,y}
	}
	\StepR{}{Def.~}{
		\sum_{x'} \CM{C}{M}_{x,y,x'}
	}
	\StepR{}{Def.~\HMM-matrix}{
		\sum_{x'} C_{x,y}M_{x,x'}
	}
	\StepR{}{ is stochastic}{
		C_{x,y}
	}
\end{Reason}

\begin{Reason}
	\Step{}{
		(\chan.(\CM{C}{M};H))_{x,(y_1, \dots , y_{n})}
	}
	\StepR{}{Def.~}{
		\sum_{x'} (\CM{C}{M};H)_{x,(y_1, \dots , y_{n}), x'}
	}
	\StepR{}{Def.~}{
		\sum_{x'} \sum_{x''} \CM{C}{M}_{x,y_1, x''} H_{x'', (y_2, \dots , y_{n}), x'}
	}
	\StepR{}{Def.~\HMM-matrix}{
		\sum_{x'} \sum_{x''} C_{x,y_1} M_{x, x''} H_{x'', (y_2, \dots , y_{n}), x'}
	}
	\StepR{}{Move stuff around}{
		C_{x,y_1} \sum_{x''}  M_{x, x''} \sum_{x'} H_{x'', (y_2, \dots , y_{n}), x'}
	}
	\StepR{}{Def.~}{
		C_{x,y_1} \sum_{x''}  M_{x, x''} (\chan.H)_{x'', (y_2, \dots , y_{n})}
	}
	\StepR{}{Matrix multiplication}{
		C_{x,y_1} (M\CProd \chan.H)_{x, (y_2, \dots , y_{n})}
	}
	\StepR{}{Parallel composition}{
		(C;(M\CProd \chan.H))_{x, (y_1, y_2, \dots , y_{n})}\quad.
	}
\end{Reason}

\end{proof}
}

\subsection*{Proof for \Lem{l1519} \AppFrom{from \Sec{s1101}}}

{\Ax
For any  let  be defined

Then  where we interpret the stochastic matrix  (rhs)
as a channel.
\begin{proof}

We use induction in the number of \HMM-steps of .

Base case:  has only one step.
\begin{Reason}
	\Step{}{
		\call_\forall(\forall, \chan.\CM{C}{M})
	}
	\StepR{}{Def.~}{
		\call_\forall(\forall, C)
	}
\StepR{}{Def.~}{
		\CCap.\,\CM{C}{M}
	\quad .
	}
\end{Reason}

Inductive step: assume the lemma is true for \HMM's composed of  steps. Let , where  has  steps.
\begin{Reason}
	\Step{}{
		\call_\forall(\forall, \chan.(\CM{C}{M};H'))
	}
	\StepR{}{Def.~}{
		\call_\forall(\forall, C \parallel (M \CProd \chan.H'))
	}
	\StepR{}{\cite[Thm.~5.1]{Alvim:2012aa}}{
		\call_\BVg(\Uni{\CalX}, C \parallel (M \CProd \chan.H'))
	}
	\StepR{}{\cite[Cor.~7]{Espinoza:2013aa}}{
		\call_\BVg(\Uni{\CalX}, C) +  \call_\BVg(\Uni{\CalX}, M \CProd \chan.H')
	}
	\StepR{}{\cite[Thm.~6]{Espinoza:2013aa}}{
		\call_\BVg(\Uni{\CalX}, C) +  \min(\call_\BVg(\Uni{\CalX}, M),  \call_\BVg(\Uni{\CalX}, \chan.H'))
	}
	\StepR{}{\cite[Thm.~5.1]{Alvim:2012aa}}{
		\call_\BVg(\Uni{\CalX}, C) +  \min(\call_\BVg(\Uni{\CalX}, M),  \call_\forall(\forall, \chan.H'))
	}
	\StepR{}{Inductive hypothesis}{
		\call_\BVg(\Uni{\CalX}, C) +  \min(\call_\BVg(\Uni{\CalX}, M),  \CCap.H')
	}
		\StepR{}{monotonicity}{
		\call_\forall(\forall, C) +  \min(\call_\forall(\forall, M),  \CCap.H')
	}
	\StepR{}{Def.~}{
		\CCap.\,(\CM{C}{M};H')
		\quad.
	}
\end{Reason}
\Af{Added a monotonicity step.}

\end{proof}


}

\subsection*{Example showing that \Lem{l1519} can be conservative  \AppFrom{from \Sec{s1101}}}

Consider the following program fragment. 

{\tt\small
\begin{tabbing}
 // \textit{Prog: \XS\ is \C{initialised} uniformly at random.}\\
 xs:= xs  xs~; \\
 leak xs[0]  xs[1]~;\\
 xs:= xs  xs\\
\end{tabbing}}


Hidden variable {\tt xs} is set initially uniformly at random over the four possible arrays of length two having  entries.
Next the array values are all flipped (probability ) or all left alone (probability ); afterwards the value of either the first or second bit is leaked, but only the value is observed. Finally {\tt xs} is updated again. 

We model this as \Cr{two}{three} \HMM\ basic steps : \C{}, where  corresponds to the first update of {\tt xs},  corresponds to the {\tt leak} statement and  the last update of {\tt xs}. \C{But from \App{a1005} we can combine the second and third, writing it as just the two steps .} Applying \Lem{l1519} we find

\begin{Reason}
\Step{}
{ \CCap.\,H}
\Step{}
{\call_\BVg(\Uni{\CalX},I) + \min(\call_\BVg(\Uni{\CalX}, M_1), \CCap.(\CM{C_2}{M_2}))}
\StepR{}{Identity channel leaks nothing; \Lem{l1519}}
{ \min(\call_\BVg(\Uni{\CalX}, M_1), \call_\BVg(\Uni{\CalX}, C_2))~.}
\end{Reason}

We compute the values of the relevant matrices as follows:



Finally we compute the leakages:


Hence .

However we can get an exact computation of leakage by calculating  exactly via \Lem{l1029}, which gives
 where



So finally we have , which is considerably less than .

\subsection*{Proof for \Thm{t1008} \AppFrom{from \Sec{s1101}}}

Given  and  with  resp.\  the marginals 
of \/  on , define conditional  as in \Sec{s1124}, there exists  and  such that



\begin{proof}
Let , that is,  is the minimum non-zero probability in .
The first equality follows from \cite{Alvim:2014aa}[Theorem 10], with  
, whenever  and , and is zero otherwise.

We prove the second equality as follows. Let  and let  in  be such that .
Next, given , define  
by


We now reason as follows  that .
\begin{Reason}
\Step{}{
V_{g}[\margz{\Apply}\chanz{\CProd} C]
}
\StepR{}{Def.~}{
\sum_{y\In\CalY} \max_{w\In\calw} \sum_{z\In\CalZ} \margz_z (\chanz\CProd C)_{z,y}  g.w.z
}
\StepR{}{cascading}{
\sum_{y\In\CalY} \max_{w\In\calw} \sum_{z\In\CalZ} \margz_z (\sum_{x\In\CalX}\chanz_{z,x} C_{x,y}) g.w.z
}
\StepR{}{move stuff}{
\sum_{y\In\CalY} \max_{w\In\calw} \sum_{z\In\CalZ, x\In\CalX} (\margz_z \chanz_{z,x})C_{x,y}  g.w.z
}
\StepR{}{}{
\sum_{y\In\CalY} \max_{w\In\calw} \sum_{z\In\CalZ, x\In\CalX} (\margx_x \chanx_{x,z})C_{x,y}  g.w.z
}
\StepR{}{move stuff}{
\sum_{y\In\CalY} \max_{w\In\calw} \sum_{x\In\CalX} \margx_x C_{x,y} (\sum_{z\In\CalZ} \chanx_{x,z}  g.w.z)
}
\StepR{}{Def.~}{
\sum_{y\In\CalY} \max_{w\In\calw} \sum_{x\In\CalX} \margx_x C_{x,y}  g^\joint.w.x
}
\StepR{}{Def.~}{
V_{g^\joint}[\margx{\Apply}C]~.
}\
\end{Reason}

The proof of  is similar, implying that  as required.
\end{proof}


\subsection*{Proof for \Thm{t1203} \AppFrom{from \Sec{s1101}}} 


Given  and  as above,
we have

where  are as defined in \Thm{t1008},
and  is the uniform probability distribution over .


\begin{proof}
It is enough to show the following:

The first inequality follows from the right capacity bound from \cite[Cor 23]{Alvim:2014aa}; the equality then follows from  \cite[Thm 10]{Alvim:2014aa}. 
\end{proof}

\section{An example: Obfuscated exponentiation \AppFrom{from \Sec{ss1055}}}\label{s1157Z}\label{s1357A}
In this section \C{give the details of the leakage calculations for the example from \Sec{ss1055}. For convenience we repeat the program at \Fig{f1143R}.}

\begin{figure}
{\Pf\begin{tabular}{ll}
\multicolumn{2}{l}{\Cx// B for base, the cleartext; E for exponent, the key:\ precondition is B,E >= 0,0 .} \\
\multicolumn{2}{l}{\Cx// P for power, the ciphertext.} \\
P:= 1 \\
\multicolumn{2}{l}{while E!=0\quad \Cx// Invariant is P*(B\textasciicircum E) = , where  are initial values of B,E .} \\
~~ D\From\ [2,3,5] & // D for divisor;\ uniform choice from \{2,3,5\}. \\
~~ R:= E mod D; & // R for remainder.\\
~~ if R!=0 then P:= P*B\textasciicircum R fi & // \fbox{Side-channel}:\ is E divisible exactly by D ? \\
~~ B:= B\textasciicircum D & // D is small:\ assume no side-channel here. \\
~~ E:= E div D & // State update of E here.\ (No side-channel.) \\
end \\
\multicolumn{2}{l}{// Now P= and E=0:\ but what has an adversary learned about the initial ~?}
\end{tabular}}

\bigskip
{\small Although our state comprises {\Pf B},{\Pf E},{\Pf P},{\Pf D},{\Pf R} we concentrate only on the secrecy of {\Pf E}. \C{In particular, we are not trying to discover {\Pf B} or {\Pf P} in this case; and {\Pf D},{\Pf R} are of no external significance afterwards anyway.}}
\caption{Defence against side channel analysis in exponentiation: a repeat of \Fig{f1143}}\label{f1143R}
\end{figure}

The well-known fast method of computing  from a base  exponent  is a to employ a ``divide and conquer'' method to avoid the exponential time taken to perform  multiplications. But in the most straightforward implementations, side-channels can reveal whether the current value of the exponent was decremented or divided by two, effectively revealing the exponent's bits one-by-one from least- to most significant. \C{In cryptographic applications, this reveals the secret key} \cite{Walter02a}.

A defence against that is to vary unpredictably the divisor that decreases the exponent on each iteration: not always 2, but say sometimes 3 and sometimes 5. This makes the algorithm (slightly) less efficient but, in compensation, much complicates the side-channel analysis that in the 2-case reveals everything.
The code in \Fig{f1143R} shows how: a fresh random divisor  is chosen from a fixed set , independently each time round the loop; in \Fig{f1143R} we use . (The original, insecure algorithm uses .) Since a higher divisor offers more security, but takes longer to compute, the precise choice of  can be thought of as selecting a trade-off between information leakage and performance.\footnote{Walter \cite{Walter02a} gives a nice summary of various issues offering tradeoffs between leakage and performance. That algorithm is intended to provide more security by obfuscating further the pattern of if-branching. For simplicity we do not do that full analysis here.} 

We assume that all variables are secret: for the example we assume the adversary seeks the exponent  only, that is the secret key, not e.g.\ a particular message. His side-channel is the {\Pf if}-statement: where he learns whether  is exactly divible by ; complicating his analysis however is that he does not know exactly what  is on each occasion.

We model this as an \HMM\ as follows.
We represent the state as a tuple  containing the values of each variable in the program.
We can then model the statement  as a Markov update  that uniformly assigns a fresh value to  while leaving the rest of the variables untouched. That is, it maps each tuple  to a tuple  with probability  for each . 
The assignment then following can be modeled as a deterministic Markov , mapping  to .
We assume pessimistically that the observer can learn whether or not the statement  was executed, which logically is equivalent to observing the evaluation of the guard  of the  statement. We model this flow as a
an \HMM\ comprising a deterministic channel  and a Markov .  outputs, for each state , whether  is 0 or not. 
The (also deterministic) Markov part  updates the state  to  only when , otherwise the state remains unchanged. 
Finally, the last two assignments correspond to deterministic Markov updates  and , mapping a state  to  and  respectively.

We can express the program of \Fig{f1143} as an \HMM\ built as the sequential composition 

using the \HMM-step notations from \Sec{s1735}, whose good behaviour in representing our intentions is justified in \App{a1005}.

However, the exact number of iterations depends on the initial value of . To simplify the analysis we will always assume  a fixed number of iterations (equal to the minimum number of iterations required for the program to yield the right result in every case). For instance, if {\Pf E} can take values from 0 to 15 (4 bits), then the maximum number of iterations is 4: on each iteration, {\Pf E} is divided at least by 2, and therefore after 4 iterations the value of {\Pf E} is guaranteed to be 0. (``Extra iterations'', i.e.\ when {\Pf E} is already zero, have no effect.) Once we have an \HMM, say , we can calculate  using \Lem{l1029} and, once we have , we can calculate its min-leakage. From \Thm{t1203},
\Af{Do you mean  \Thm{t1203}? \Nx Yes, although it is a *bound* on the leakage (we still don't know neither the
correlation nor the gain function!)}
that gives also Dalenius leakage, which in this case represents the leakage related to the initial value of . \Tbl{table:leakage} shows the result of computing this leakage \Tr{, in addition to the execution time of each case.}{for different sets of divisors.}

\section{Some notations and properties of \HMM\ steps \AppFrom{used in \App{s1157Z}}}\label{a1005}

In \Sec{s1735} it was remarked that the single, uniform definition of  for \HMM's ``essentially'' treats pure markovs and pure channels differently. That difference is possible because markovs and channels are encoded differently within \HMM's. First we give the details for classical \HMM's; then further below we address abstract \HMM's.\label{a1320}
\Cf{Found this text ``orphaned'' in the appendix: where is it from?}
\label{g1255}
The \emph{degenerate} channel that leaks nothing about  can be regarded as having an anonymous singleton set as its observations, a single-column matrix containing only 1's. We write it  for ``no channel'' on state-space ; usually we omit the . The degenerate markov that makes no change is the identity (matrix) on , which we write . We abbreviate  by  and  by , calling them (as \HMM's) \emph{pure} channels and pure markovs, and we note these properties of composition:
\begin{enumerate}
\item ~, i.e.\ that  is equivalent to ``just '' and then ``just ''. \item\label{i1452}  where  defined  is the \emph{parallel composition} of its constituents, i.e.\ that `` and then '' is the same as  and  together because  passes the state on, unchanged, to . \item , where  is the (usual) Markov composition of its constituents, i.e.\ matrix multiplication.
\end{enumerate}
The \HMM-composition of pure channels and composition of pure markovs is what allows us to combine channels and markovs and then treat them with the same definition of sequential composition, as is done in \App{s1157Z} with one long (associative) sequential composition of the loop body's constituents, then unfolded as explained there to eliminate the loop: their different purposes are automatically respected.

The essential property referred to in \Def{d1305} of \Sec{s1449} guarantees that this same respect for markovs' difference from channels is achieved in the semantic domain as well. Using \cite{McIver:2014ab,McIver:15} this can be exploited to remain entirely in the semantic domain, including the loop explicitly without having to unfold it.

\newpage
\section{Proofs and materials supporting \Sec{s1138}}\label{a1215}{\Cx \subsection*{On ``healthiness'' of abstract \HMM's\AppFrom{from \Sec{s1449}}}
The denotations of our 's in  are functions in ; but not all functions in that space are  for some . The ones that are have\Td{ here} been called abstract \HMM's, and they have properties that we use in the proofs below.

A common technique in semantics is to identify \emph{characteristic} properties of denotations, which can then lead to further insights. They are expressed in semantic terms, as we did for example in \cite[VIIA]{McIver:15} for collateral-\emph{unaware} abstract \HMM's, calling them ``healthiness conditions''.\footnote{\Cx A conspicuous example of this is Dijkstra's healthiness conditions for predicate transformers on sequential programs: the principal one was conjunctivity. Originally \cite{Dijkstra:76} Dijkstra proved by structural induction over program texts that all program denotations were healthy; later researchers instead used healthiness to characterise a subspace of predicate transformers, and then proved that all programs' denotations lay within it --- the same proof, but a different point of view. That more semantic view allowed later the expansion of healthiness, to include e.g.\ miracles and angelic choice, which in turn lead to new programming-language features that could denote the members of the expanded set.}
An advantage of that is the possible discovery of more general properties that secure computations' (semantics) should have.
Although we do not introduce collateral-aware healthiness here, it is a clear target for future work.
}

\subsection*{Proofs of lemmas and theorems\AppFrom{from \Sec{s1449}}}

\Cf{Removed this (for now):\begin{quote}
\subsection*{Collateral-aware abstract \HMM's\AppFrom{from \Sec{s1449}}}
\C{We say that a function in our semantic space, some , is \emph{healthy}} if for every collateral type , there exists a \emph{unique} -lifting \C{function}  such that the diagram in \Fig{f1041} commutes for every \Cr{channel}{right conditional} . That is, the healthiness of  postulates the existence \C{for every collateral type } of an  that depends only on .
\Cd{This map is independent of the channel .}\C{This confuses me, at least for now :-) Which map? Is it ? By ``map'' do you mean ``function''? \T{Yes, I meant  is independent of the right conditional . I meant to emphasises that we mean  rather than . From habit, I assume "function = one valued" and "map = total function".}}

Notice when the map  exists then it is necessarily unique because every joint distribution  can be decomposed into a right \Cr{channel}{conditional}  and right marginal  such that .\footnote{\Cx If  is not full support on  then  is not unique: but see \Lem{l1241} below.}.
More precisely, if \C{some other}  made the diagram in \Fig{f1041} commute (\C{for every right conditional }),
then
\C{This seems strangely presented. I guess by ``exists'' you mean ``is single valued'', i.e.\ ``is a function in spite of the left hand arrow's going the wrong way?\T{Yes. That is another way of looking at it, i.e. we have a family of  (thus relational) instead of a single . Notice however that the diagram implicitly assumes that every arrow is indeed an arrow, in particular, they are single-valued functions (they also need to be continuous and superlinear but we don't care about that, these have been proven in LiCS15).}}


Healthy 's exist in abundance: if  is a \HMM\ matrix, then for example  is always healthy\C{, because we can define} , for every joint distribution  with right channel resp. marginal  and . The following lemma \C{shows that  does not depend on the particular choice of right conditional , where more than one is possible}.


\C{Lemma~\ref{l1241Z}  does not depend on the particular choice of right conditional , where more than one is possible.}

\begin{lemma}\label{l1241Z}
Let  be a \HMM\ matrix, and  be channels and  a distribution. If  then .

\begin{proof}
This follows immediately from the fact that for every inner  of \C{the hyper} , we have  when . \C{In particular, when  because  for all , which is the only case where  and  can differ, then also  and so  for all .}
\C{Need to think about this more.}
\end{proof}
\end{lemma}

\end{quote}
}{\Cx Lemma~\ref{l1241} shows that  in \Fig{f1041} is well defined whenever  for some . The principal fact is that possible variation in the choice of the right-conditional , at left, does not affect the value produced by  at right.
\begin{lemma}\label{l1241}
Let  be an abstract \HMM; then  from \Fig{f1041} is well defined. \AppFrom{from \Sec{s1449}} \\ 

\begin{proof} Let  for some , and  let  be a joint distribution in  with right marginal  and  a right-conditional so that . If  is unique, then the result is trivial because  is given by the composition of the bottom- and right-hand arrows acting on  in \Fig{f1041}.

If however  is not unique, it can only be at elements  where  is 0, the well known issue that the all-zero column  cannot be normalised: but equally well known is that ``it doesn't matter'' because any arbitrary value chosen for  will be multiplied by 0 in .

It doesn't matter on the right, either, because a property of abstract 's inherited from their originating 's is that if  then the sub-vector  of the joint distribution  is all zero; that means, in turn, that in all inners  of the hyper  derived from that joint distribution (by abstracting from ) the probability  for that , and for for any , will be zero as well. Thus, again, variation of  at that  does not matter.

{\Tx In all cases,

holds whenever .}
\end{proof}
\end{lemma}
}

\Cf{I suggest leaving the below out: we want abstract \HMM's to be the healthy 's, I think; and we don't want to focus people on pathological cases.
\begin{quote}\Bx
There are also many unhealthy abstract \HMM s. For instance, the existence of  requires that  ``copies'' the initial value into the first component in . Without this condition, \Lem{l1241} does not hold.\end{quote}}

\subsection*{Proof for \Thm{t0639C} \AppFrom{from \Sec{s1449}}}

Since , it suffices to prove the following result.

\begin{theorem}
	Let  be two abstract \HMM's. Then  iff  for all extension .
	
\begin{proof}	
	Let us assume that  and let  with a right-conditional  and right marginal , i.e. . Let  for . Recall from \cite[Def.~6]{McIver:12} that two hypers satisfy  in  iff there exists a super  such that  (the outer average) and  (the inner average)
	\footnote{Here,  is the usual Giry monad, see \cite{Giry:81,McIver:12,McIver:15}.}. We say that  \emph{witnesses} the refinement .
	Let us show that the super   witnesses the refinement  in , i.e.
	
	
	Both equalities can be stated using the diagrams given in \Fig{f1132A}-(a,b). Let us show that these diagrams indeed commute.
	\begin{figure}[!h]
		\centering
		\begin{minipage}{.32\textwidth}
			\begin{tikzcd}
				\Dist^2\CalX^2\arrow{r}{\Dist (Z{\MMult})}& \Dist^2(\CalZ{\times}\CalX) \\
				\Dist^3\CalX^2\arrow[swap]{r}{\Dist^2 (Z{\MMult})}\arrow{u}{\Dist\mu_{\CalX^2}}&\arrow[swap]{u}{\Dist\mu_{(\CalZ{\times}\CalX)}} \Dist^3(\CalZ{\times}\CalX) \\
			\end{tikzcd}
			\\\centering (a)
		\end{minipage}
		\begin{minipage}{.32\textwidth}
			\begin{tikzcd}
				\Dist^2\CalX^2\arrow{r}{\Dist (Z{\MMult})}& \Dist^2(\CalZ{\times}\CalX) \\
				\Dist^3\CalX^2\arrow[swap]{r}{\Dist^2 (Z{\MMult})}\arrow{u}{\mu_{\Dist\CalX^2}}&\arrow[swap]{u}{\mu_{\Dist(\CalZ{\times}\CalX)}} \Dist^3(\CalZ{\times}\CalX) \\
			\end{tikzcd}
			\\\centering (b)
		\end{minipage}
		\begin{minipage}{.32\textwidth}
			\begin{tikzcd}
				\Dist\CalX^2\arrow{r}{(Z{\MMult})}& \Dist(\CalZ{\times}\CalX) \\
				\Dist^2\CalX^2\arrow[swap]{r}{\Dist (Z{\MMult})}\arrow{u}{\mu_{\CalX^2}}&\arrow[swap]{u}{\mu_{\CalZ{\times}\CalX}} \Dist^2(\CalZ{\times}\CalX) \\
			\end{tikzcd}
			\\\centering (c)
		\end{minipage}
		\caption{The multiplication  commutes with inner () and outer () averages.}\label{f1132A}
	\end{figure}
	
	For the diagram in \Fig{f1132A}-(a)(inner-average), it suffices to show \Fig{f1132A}-(c) commutes 	because -lifting preserves commutative diagrams. This essentially follows from the linearity of . Let us first recall the definition of multiplication in the Giry monad. Given a (polish) space  and a Borel set , the multiplication  is defined by the expected value of the evaluation function  where  for every . We have, for every ,
	
	We simply write  when  is the singleton . Recall also that given a measurable function , the push-forward of  by  is  where, for every Borel set  and measure , we have
	
	A very useful result links the constructor  with integrals. Let  and  be measurable functions and  be a Borel measure. We know that  so we can integrate  wrt it. In fact, Giry has proven in \cite[Sec. 3 p.70]{Giry:81} that 
	
	We are now ready to prove that all diagrams in \Fig{f1132A} commute. For  \Fig{f1132A}-(c), let  be an arbitrary hyper and . On the one hand,	
	\begin{Reason}
		\Step{}{
			\left(\mu_{\CalZ{\times}\CalX}{\circ}\Dist(Z{\MMult}).\Delta\right)_{z,x'}
		}
		\StepR{}{Eqn.~\Eqn{e2044}}{
			\int \epsilon_{(z,x')}\mathrm{d}\Dist(Z{\MMult}).\Delta
		}
		\StepR{}{Eqn.~\Eqn{e1502}}{
			\int \epsilon_{(z,x')}{\circ} (Z{\MMult})\mathrm{d}\Delta
		}
	\end{Reason}
	On the other hand, we have
	\begin{Reason}
		\Step{}{
			(Z{\MMult}(\mu_{\CalX^2}.\Delta))_{z,x'}
		}	
		\StepR{}{Def.~matrix multiplication}{
			\sum_x Z_{z,x}(\mu_{\CalX^2}.\Delta)_{x,x'}
		}
		\StepR{}{Eqn.~\Eqn{e2044}}{
			\sum_x Z_{z,x}\int \epsilon_{(x,x')}	\mathrm{d}\Delta
		}
		\StepR{}{Integration is linear}{
			\int\sum_x Z_{z,x}\epsilon_{(x,x')}\mathrm{d}\Delta
		}
	\end{Reason}
	Thus, it remains to show that the integrands in the last lines of the reasoning above are the same. Let , we have
	
	Hence, \Fig{f1132A}-(c) commutes and its -lift gives the inner-average commutative diagram.
	
	We now prove that \Fig{f1132A}-(b) (outer-average) commutes. Let  and  be a Borel subset of . On the one hand, we have 
	\begin{Reason}
		\Step{}{
			\left(\mu_{\Dist(\CalZ{\times}\CalX)}{\circ}\Dist^2(Z{\MMult})\right).\Gamma.O
		}
		\StepR{}{Def.~()}{
			\left(\mu_{\Dist(\CalZ{\times}\CalX)}.\left(\Dist^2(Z{\MMult}).\Gamma\right)\right).O
		}
		\StepR{}{Eqn.~\Eqn{e2044}}{
			\int \epsilon_O\mathrm{d}\Dist^2(Z{\MMult}).\Gamma
		}
		\StepR{}{Eqn.~\Eqn{e1502}}{
			\int \epsilon_O{\circ}\Dist(Z{\MMult})\mathrm{d}\Gamma
		}
	\end{Reason}
	
	On the other hand, we have
	\begin{Reason}
		\Step{}{
			\left(\Dist(Z{\MMult}){\circ}\mu_{\Dist\CalX^2}\right).\Gamma.O
		}
		\StepR{}{Def.~()}{
			\Dist(Z{\MMult}).(\mu_{\Dist\CalX^2}.\Gamma).O
		}
		\StepR{}{Def.~push-forward \Eqn{e2155}}{
			(\mu_{\Dist\CalX^2}.\Gamma).((Z{\MMult})^{-1}.O)
		}
		\StepR{}{Eqn.~\Eqn{e2044}}{
			\int \epsilon_{(Z{\MMult})^{-1}.O}\mathrm{d}\Gamma
		}
	\end{Reason}
	As before, it remains to show that the integrands are equal. For every hyper , we have
	\begin{Reason}
		\Step{}{
			\left(\epsilon_O{\circ\Dist(Z{\MMult})}\right).\Delta
		}
		\StepR{}{Def.~()}{
			\epsilon_O.(\Dist(Z{\MMult}).\Delta)
		}
		\StepR{}{Def.~}{
			\Dist(Z{\MMult}).\Delta.O
		}
		\StepR{}{Def.~push-forward \Eqn{e2155}}{
			\Delta.((Z{\MMult})^{-1}.O)
		}
		\StepR{}{Def.~}{
			\epsilon_{(Z{\MMult})^{-1}.O}.\Delta	
		}
	\end{Reason}
	This concludes that \Fig{f1132A}-(b) commutes.
	
	Conversely, assume  for every extension . For , we have . Let  and  such that  has  on the diagonal and  anywhere else. It follows from Equation \Eqn{e1150} that  and thus .
\end{proof}
\end{theorem}

\subsection*{Proof that  preserves sequential composition \AppFrom{from \Sec{s1449}}}
\begin{lemma}\label{l1653}
Let  be \HMM\ matrices. We have .

\begin{proof}
Let  be a prior. On the one hand, let  be observations associated to the inner  in . That is, for pair  of initial and final value:


where the normalisation constant is defined as in \Sec{s1540}:

On the other hand, let us have a look at the inners of . Let one such inner be . By Equation~\Eqn{e1150}, we have  where the right-conditional and right marginal satisfy . Therefore, there exists some inner  of  such that  for some inner  of  and . Thus

for some observations . Hence
\begin{Reason}
\Step{}{
	\delta_{x,x'}
}
\StepR{}{}{
	(Z{\MMult}\rho)_{x,x'}
}
\StepR{}{Def.~}{
	\sum_u Z_{x,u}\rho_{u,x'}
}
\StepR{}{Def.~of  above}{
	\sum_u Z_{x,u}\frac{\RMarg{\gamma}_u H^2_{u,y_2,x'}}{\Norm_{H^2,\RMarg{\gamma},y_2}}
}
\StepR{}{}{
	\sum_u \gamma_{x,u}\frac{ H^2_{u,y_2,x'}}{\Norm_{H^2,\RMarg{\gamma},y_2}}
}
\StepR{}{Def.~of  above}{
	\sum_u \frac{\pi_{x} H^1_{x,y_1,u}}{\Norm_{H^1,\pi,y_1}}\frac{ H^2_{u,y_2,x'}}{\Norm_{H^2,\RMarg{\gamma},y_2}}
}
\StepR{}{Def.~}{
	\frac{ \pi_{x} (H^1;H^2)_{x,(y_1,y_2),x'}}{\Norm_{H^1,\pi,y_1}\Norm_{H^2,\RMarg{\gamma},y_2}}
}
\end{Reason}
It remains to prove that  (this essentially tells us that it does not matter whether we apply the normalisation process for each component in the sequential composition or we leave it until the end and just carry out normal \HMM\ multiplication at the matrix level).
\begin{Reason}
\Step{}{\Norm_{H^1,\pi,y_1}\Norm_{H^2,\RMarg{\gamma},y_2}}
\StepR{}{Def.~}{
	\sum_{u,x'}{\RMarg{\gamma}_u H^2_{u,y_2,x'} \Norm_{H^1,\pi,y_1}}
}
\StepR{}{}{
	\sum_{u,x'}{\sum_x\gamma_{x,u} H^2_{u,y_2,x'} \Norm_{H^1,\pi,y_1}}
}
\StepR{}{Substituting }{
	\sum_{u,x'}{\sum_x\frac{\pi_{x} H^1_{x,y_1,u}}{\Norm_{H^1,\pi,y_1}} H^2_{u,y_2,x'} \Norm_{H^1,\pi,y_1}}
}
\StepR{}{Simplification with  ()}{
	\sum_{u,x'}{\sum_x\pi_{x} H^1_{x,y_1,u} H^2_{u,y_2,x'}}
}
\StepR{}{Arith.}{
	\sum_{x,x'}\pi_{x} \sum_u{H^1_{x,y_1,u} H^2_{u,y_2,x'}}
}
\StepR{}{Def.~}{
	\sum_{x,x'}\pi_{x} (H^1\GComp H^2)_{x,y_2,x'}
}
\StepR{}{Def.~of }{
	\Norm_{(H^1\GComp H^2),\pi,(y_1,y_2)}~.
}
\end{Reason}
() This step assumes the normalising constant  is not zero. If it is zero, then the equality we want to prove clearly holds.

Hence,   and   have the exact same inners associated to the same respective outer probabilities. 
\end{proof}
\end{lemma}

\subsection*{Proof that sequential composition \AppFrom{from \Sec{s1449}} \\ respects behavioural equivalence}

\begin{theorem}\label{t1329}
	If  and  then .
\end{theorem}

Let us firstly prove a very important property of \HMM s: they transform gain functions. We construct, for every , a gain function  where

for every strategy  and . We have the following properties of .

\begin{lemma}\label{l1449}
Let  be \HMM s and  be a prior. For every gain function , we have:
\begin{enumerate}
	\item ,\label{p1449a}
	\item .\label{p1449b}
\end{enumerate} 

\begin{proof}
For \ref{p1449a}., we have 
\begin{Reason}
	\StepR{}{Def.~}{
		\sum_y\max_{w{\In}{\cal W}} \sum_{x,x'}g.w.(x,x') H_{x,y,x'}\pi_{x}
	}
	\StepR{}{Swap  and }{
		\max_{\sigma{\In}\CalY\to{\cal W}}\sum_{y}\sum_{x,x'}g.(\sigma.y).(x,x') H_{x,y,x'}\pi_{x}
	}
	\StepR{}{Def.~}{
		\max_{\sigma{\In}\CalY\to{\cal W}}\sum_{x}g^H.\sigma.(x,x)\pi_{x}
	}
	\StepR{}{Def.~}{
		\GTest{\LHyp{\pi}}{g^H}
	}	
\end{Reason}
For \ref{p1449b}., let . We have
\begin{Reason}
	\Step{}{(g^K)^H.\sigma.(x,x')}
	\StepR{}{Def.~}{
		\sum_{y,u}g^K.(\sigma.y).(x,u) H_{x',y,u}
	}
	\StepR{}{Def.~}{
		\sum_{y,u} \sum_{y',v}g.(\sigma.y.y').(x,v) K_{u,y,v} H_{x',y,u}
	}
	\StepR{}{Swap sums}{
		\sum_{y} \sum_{y',v}g.(\sigma.y.y').(x,v) \sum_uH_{x',y,u} K_{u,y,v}
	}
	\StepR{}{Def.~}{
		\sum_{y,y'}\sum_v g.(\sigma.y.y').(x,v) (H;K)_{x',(y,y'),v}
	}
	\StepR{}{Def.~}{
		g^{H;K}.\sigma.(x,x')
	}
\end{Reason}
as required.	
\end{proof}
\end{lemma}
Now, we can prove \Thm{t1329}.

\begin{proof}[Proof of \Thm{t1329}]
Let , ,  be a gain function and  be a prior. On the one hand, assume  and let us show that .
	
\begin{Reason}
	\Step{}{
		\GTest{\LHyp{\LRJoint{\pi}{(H\GComp K)}}}{g}	
	}
	
	\StepR{}{\Lem{l1449}.\ref{p1449a}}{
		\GTest{\LHyp{\pi}}{g^{H;K}}
	}
	
	\StepR{}{\Lem{l1449}.\ref{p1449b}}{
		\GTest{\LHyp{\pi}}{(g^K)^H}
	}
	
	\StepR{}{\Lem{l1449}.\ref{p1449a}}{
		\GTest{\LHyp{\LRJoint \pi H}}{g^K}
	}
	
	\StepR{}{}{
		\GTest{\LHyp{\LRJoint \pi H'}}{g^{K}}
	}
	
	\StepR{}{\Lem{l1449}.\ref{p1449a} and \Lem{l1449}.\ref{p1449b}}{
		\GTest{\LHyp{\LRJoint{\pi}{(H'\GComp K)}}}{g}		
	}
\end{Reason}

On the other hand, assume  and let us show that . For each observation  of , we consider the associated inner  and outer  where

where  is the usual column normalising constant. Then
\begin{Reason}
	\Step{}{
		\GTest{\LHyp{\LRJoint{\pi}{(H'\GComp K)}}}{g}
	}
	
	\StepR{}{Def.~'s}{
		\sum_y p^y\GTest{\LHyp{\LRJoint{\delta_y}{K}}}{g}
	}
	
	\StepR{}{}{
		\sum_y p^y\GTest{\LHyp{\LRJoint{\delta_y}{K'}}}{g}
	}
	
	\StepR{}{Def.~'s}{
		\GTest{\LHyp{\LRJoint{\pi}{(H'\GComp K')}}}{g}
	}
\end{Reason}
Hence,  follows by transitivity of .
\end{proof}

\newpage
\section{Reduction to Bayes vulnerability via a collateral context \AppFrom{from \Sec{s0908}}}\label{a1002}

In \Sec{s0908} we asked whether the refinement relation  from \Sec{s1330} was too strong, and recalled that in \cite{mcivermeinicke10a} a construction was given that reduced refinement to Bayes vulnerability, at least for closed systems without collateral correlations: if  then there was a context ``post-compose with program \/'' and a prior  such that the two hypers

had \emph{Bayes} vulnerabilities in particular ``the wrong way around'', i.e.\ that . That justified the failure of refinement, for if  then we cannot, for any prior and , have that  is \emph{more} Bayes vulnerable than .

That argument does not however work directly for refinements that are rejected because of \emph{collateral} correlations: the post-composing  does not have access to the initial states of  if those programs modify the state. A very direct (and somewhat brutal) work-around would be to re-use the construction of \cite{mcivermeinicke10a} by putting  into a context that preserved the input by first copying it into {\Pf Z} say, then executing  resp.\ and finally introducing an  as before but one that operated not on {\Pf X} directly but rather on the preserved copy held in {\Pf Z}. Because neither of  assign to {\Pf Z}, it would still contain {\Pf X}'s original value; but \emph{leaks} in  from {\Pf X} would be reflected in different hypers  resulting from each. That is, informally we would have a collateral context containing declaration {\Pf var Z{:}} and the code

where  is the distinguishing  from \cite{mcivermeinicke10a} but operating on {\Pf Z} instead of {\Pf X}.

A more convincing approach however is to use the gain function  that distinguishes  to make a ``pre'' collateral correlation  instead of a ``post'' assignment . It has been shown that the  can be derived from the ; but a more direct route is the following.

Assume the programs  are indistinguishable wrt.\ the hypers on their final states (else we could simply appeal to \cite{mcivermeinicke10a}), but that they differ wrt.\ their information-flow effect on the initial state. Using   from \Lem{l1029} in \Sec{s1101}, take  and , the effective channels of  resp.\ and let  resp.\ be the hypers resulting from the action of those channels respectively on the prior . By assumption , and so there is some gain-function  with . It is shown in \cite{Smith:aa}, but considering only channels (not \HMM-programs), that there is indeed a collateral correlation  such that 

where  is the hyper resulting from the joint distribution in  formed by the matrix multiplication of the joint distribution  by the stochastic .

Thus we have shown that if the -vulnerabilities of  and  wrt.\ some  and  mandate , then the collateral \emph{Bayes} vulnerabilities of  are the wrong way around for some collateral correlation  (whose right-marginal is of course ); general -discsimination is again, as in \cite{mcivermeinicke10a}, reduced to Bayes-vulnerability discrimination and compositionality.

\end{document}
