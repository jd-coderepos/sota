\documentclass{LMCS} 

\usepackage{enumerate}
\usepackage{hyperref}

\usepackage{eucal,,amssymb, amsbsy,amsthm}


\newcommand\cX{\ol{X}}
\newcommand\cx{\ol{x}}
\newcommand\ol[1]{\overline{#1}}
\newcommand\euro{\kern1pt\text{{\sffamily c}\kern-5.5pt\rule[2.7pt]{4.5pt}{.4pt}\kern-4.5pt\rule[1.8pt]{4.3pt}{.4pt}\kern1pt}}
\newcommand\Neut{\EuScript{N}}
\newcommand\seq{\subseteq}
\newcommand\eqdef{=_{\rm def}}
\newcommand\set[2]{\bigl\{\,#1\bigm| #2\,\bigr\}}
\newcommand\powerset[1]{\EuScript{P}(#1)}
\newcommand\bs{\text{\rm bin}_k}
\newcommand\CV{{\EuScript{V}}}
\newcommand{\Most}{{\rm Most^1}}
\newcommand{\bin}{{\rm bin}}
\newcommand{\mi}{{\rm min}}
\newcommand{\ma}{{\rm max}}

\newcommand\AC{{\rm AC}^0}
\newcommand\ATIME{{\rm ATIME}}
\newcommand{\pspace}{{\rm PSPACE}}
\newcommand{\np}{{\rm NP}}
\newcommand{\tc}{{\rm TC}^0}
\newcommand{\TC}{{\rm TC}^1}
\newcommand{\SAC}{{\rm SAC^1}}
\newcommand{\NC}{{\rm NC^1}}
\newcommand\dspace{\text{\rm DSPACE}}
\newcommand\dtime{\text{\rm DTIME}}
\newcommand\NLIN{\text{\rm NLIN}}
\newcommand{\tally}{{\rm tally}}
\newcommand\REG{{\rm REG}}
\newcommand\LOGCFL{{\rm LOGCFL}}
\newcommand\CFL{{\rm CFL}}
\newcommand\DLOG{{\rm DLOGTIME}}
\newcommand{\ASPACETS}{{\rm ASPACE\text{-}TREESIZE}}
\newcommand{\NSPACE}{{\rm NSPACE}}
\newcommand\ACC{{\rm ACC}^0}
\newcommand\modPH{{\rm Mod\text{-}PH}}
\newcommand\lmodPH{{\rm Mod\text{-}LinH}}
\newcommand\CH{{\rm CH}}
\newcommand\lCH{{\rm Lin\text{-}CH}}
\newcommand\Modq{{\rm Mod_qP}}
\newcommand\ph{{\rm PH}}
\newcommand\pp{{\rm PP}}

\newcommand{\mA}{{\mathfrak A}}
\newcommand{\bit}{{\rm BIT}}
\newcommand\CA{{\EuScript{A}}}
 \newcommand\Mod{\text{\rm Mod}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\dom}{{\rm dom}}
\newcommand{\MOD}{{\rm MOD}_q}
\newcommand{\Maj}{{\rm Maj}}


\newcommand\FO{\text{\rm FO}}
\newcommand\SO{{\rm SO}}
\newcommand\SOM{{\rm SOM}}
\newcommand\QM{Q_M}
\newcommand\QL{Q_L}
\newcommand\Mon{\text{\rm Mon}}
\newcommand\Grp{\text{\rm Grp}}
\newcommand\QMon{Q_{\Mon}}
\newcommand\QGrp{Q_{\Grp}}
\newcommand\msQ{\text{\rm mon-}Q^1}
\newcommand\msQL{\msQ_{L}}
\newcommand\msQMon{\msQ_{\Mon}}
\newcommand\msQGrp{\msQ_{\Grp}}
\newcommand\QmodM{\text{\rm mon-}Q^{\star}_{\Mon}}
\newcommand\Qmod{\text{\rm mon-}Q^{\star}_{\Grp}}
\newcommand\QmodL{\text{\rm mon-}Q^{\star}_L}
\newcommand\QmodH{\text{\rm mon-}Q^{\star}_{{\rm pad}(H)}}
\newcommand\msQH{\text{\rm mon-}Q^1_{{\rm pad}(H)}}
\newcommand\msQA{\text{\rm mon-}Q^1_{{\rm pad}(A)}}
\newcommand\qfree{\text{\rm QF}}
\newcommand\QmodMaj{\text{\rm mon-}Q^{\star}_{\rm Maj}}

\newcommand\msQC{\text{\rm mon-}Q^1_{\mathcal{C}}}
\newcommand\QmodC{\text{\rm mon-}Q^{\star}_{\mathcal{C}}}


\newcommand\QmodMS{\text{\rm mon-}Q^{\star}_{\REG^s}}
\newcommand\QmodS{\text{\rm mon-}Q^{\star}_{\CFL^s}}


\newcommand\leaf{\textrm{leafstring}}
\newcommand\Leaf{{\rm Leaf}}
\newcommand\BLeaf{{\rm BLeaf}}
\newcommand\LeafP{\Leaf^{\rm P}}
\newcommand\BLeafP{\BLeaf^\P}
\newcommand\leafM{{\rm leafstring}^{M}}
\newcommand\LeafM{{\rm Leaf}^M}
\newcommand\leqplt{\leq^{{\rm plt}}_m}
\newcommand\LeafFA{\Leaf^{\text{\rm FA}}}

\def\doi{6 (3:25) 2010}
\lmcsheading {\doi}
{1--22}
{}
{}
{Sep.~21, 2009}
{Sep.~20, 2010}
{}

\begin{document}

\title[On Second-Order Monadic Monoidal and Groupoidal Quantifiers]{On Second-Order Monadic Monoidal and Groupoidal Quantifiers\rsuper*}


\author[J.~Kontinen]{Juha Kontinen\rsuper a}
\address{{\lsuper a}Department of Mathematics and Statistics, University of Helsinki, P.O. Box 68, FI-00014 University of Helsinki, Finland}
\email{juha.kontinen@helsinki.fi}
\thanks{{\lsuper a}Supported by grant 127661 of the Academy of Finland}

\author[H.~Vollmer]{Heribert Vollmer\rsuper b}
\address{{\lsuper b}Institut f\"ur Theoretische Informatik, Universit\"at
Hannover, Appelstra\ss e 4, 30167 Hannover, Germany}
\email{vollmer@thi.uni-hannover.de}
\thanks{{\lsuper b}Supported partially by DFG grants VO 630/6-1 and 6-2}

\keywords{Monoid, groupoid, word-problem, leaf language,  second-order generalized quantifier, computational complexity, descriptive complexity}
\subjclass{F.4.1, F.4.3}
\titlecomment{{\lsuper*}A previous version of this paper appeared in the Proceedings of the Workshop on Logic, Language, Information and Computation 2008, Springer Lecture Notes in Computer Science Vol.~5110, pp.~238--248, Springer Verlag, 2008.}

\begin{abstract}
We study logics defined in terms of second-order monadic monoidal and groupoidal quantifiers.
These are generalized quantifiers defined by monoid and groupoid
word-problems, equivalently, by regular and context-free languages. We give a computational classification 
of the expressive power of these logics over strings with varying built-in predicates. In particular, we show that  
 can be logically characterized in terms of  second-order monadic monoidal quantifiers. 
\end{abstract}
 

\maketitle

\section{Introduction}


\noindent We study logics defined in terms of so-called second-order
monadic monoidal and groupoidal quantifiers.  These are generalized
quantifiers defined by monoid and groupoid word-problems,
equivalently, by regular and context-free languages.  A
\emph{groupoid} is a finite multiplication table with an identity
element.  For a fixed groupoid , each  defines a
-word-problem, i.e., a language  composed of all
words , over the alphabet , that can be bracketed in such a way
that  multiplies out to an element of . The word-problem of a
\emph{monoid}, i.e., an associative groupoid, is defined analogously.
Groupoid word-problems relate to context-free languages in the same
way as monoid word-problems relate to regular languages: every such
word-problem is context-free, and every context-free language is a
homomorphic pre-image of a groupoid word-problem (this result is
credited to Valiant in \cite{belemc93}).

In descriptive complexity, (first-order) monoidal quantifiers have been studied extensively in 
connection to the complexity class  and its sub-classes (see  \cite{baimst90,bacostth92,str94, stthth95}). However, in
 order to define  non-regular languages in terms of monoidal quantifiers, some built-in relations, in addition to , need to be assumed. It was shown already in \cite{baimst90} that first-order logic with unnested unary  monoidal quantifiers characterizes the class of regular languages, ,  over strings without auxiliary built-in relations. This characterization of  was generalized in  \cite{lamcscvo01} to allow also non-unary monoidal quantifiers, even  with arbitrary nestings.  In \cite{MR1908783},  the same was shown to hold   for 
 second-order monadic monoidal  quantifiers:

In \eqref{monoidcase},  denotes  existential second-order monadic logic and the  logic  consists of all formulas in which 
a monadic second-order monoidal quantifier  is applied to 
an appropriate tuple of -formulas without further occurrences of
second-order quantifiers. On the other hand, in 
 arbitrary nestings of monoidal quantifiers are allowed. Here a crucial assumption is that there are no auxiliary built-in relations, besides the order, since already , i.e.,  second-order monadic logic with built-in  addition, defines exactly the languages in the linear fragment of the polynomial hierarchy \cite{MR1465635}. 

We see that with monoidal quantifiers the situation is clear-cut, i.e., formulas with
monadic second-order monoidal  quantifiers cannot define non-regular
languages. On the other hand,  over strings with built-in arithmetic  (i.e.,  built-in  and ) the classes in \eqref{monoidcase} are presumably not
equal, e.g.,   and already in  -complete languages can be defined as we show below in     Corollary \ref{monpspace}. 


In \cite{belemc93}, the  elaborate theory connecting  monoids  to the fine structure of   was generalized 
to groupoids and . It was shown  in \cite{belemc93} that there exists a single groupoid whose word-problem is complete for  under -reductions, implying also a logical characterization for  in terms of first-order groupoidal quantifiers. Building on this result, a systematic investigation of  first-order groupoidal quantifiers was initiated in  \cite{lamcscvo01}. 

In \cite{MR1908783} it was asked what is the relationship of the corresponding (second-order) logics  if
 monoidal quantifiers are replaced by groupoidal quantifiers in \eqref{monoidcase}.  Here we  address this question and show the following (see Corollary \ref{cor}):

It is interesting to note that for  groupoidal quantifiers we have a similar collapse result as for monoidal quantifiers, but this time assuming  built-in arithmetic on the left. Note that, over ordered structures, the relations  and  are definable in the logic   (see \cite{baimst90} and \cite{lamcscvo01}).   It is  an open question whether the built-in relations  and  are really needed  for the equivalence in  \eqref{main} to hold.

In the literature,   second-order monadic quantifiers have been studied under two slightly different  semantics
(for each , quantifiers  and   ).  We will  show
that the analogue of \eqref{main} for the alternative  semantics  remains valid even if we drop the  built-in predicates  and  from , i.e.,

Since the logics in  \eqref{main} and \eqref{mainr2} are all equivalent (see Corollary \ref{cor}), it follows that the 
only remaining open question regarding the equivalences between  logics with groupoidal quantifiers  is whether

This question is directly concerned with the problem of pinning down the exact expressive power of the so-called finite leaf automata with
context-free leaf languages (see Theorem \ref{neutral} and Corollary \ref{Grppspace}). 

In this paper we aim for a concise classification of the expressive power of the  logics with second-order monadic monoidal and groupoidal quantifiers.
We first note that the difference  between the two semantics, i.e.,  and , disappears assuming  built-in arithmetic. This already simplifies the picture considerably. However, especially in the monoidal case, the expressive power of the quantifiers   without built-in arithmetic remains open.  For groupoidal quantifiers, we find that 

where   equals the class of languages whose tally version resides in .
For monoidal quantifiers, we show that  

Table \ref{table:summary} below contains a  summary of  our complexity results. 

\section{Preliminaries}



\noindent We follow standard notation for second-order monadic logic
with linear order, see, e.g., \cite{str94}. We mainly restrict our
attention to {\em string structures}, i.e., structures of {\em string
  signatures} , where all
the predicates  are unary. We assume that the universe
 of each structure  is of the form 
and that the logic's linear order symbol refers to the numerical order
on . We restrict attention to structures  in
which the interpretations  of the predicates 
satisfy the following: ,
for , and . Such
-structures correspond to strings over the alphabet
 in the usual way.

An alphabet  is a finite set of symbols. For technical reasons to be motivated shortly, we assume that every alphabet  has a built-in linear
order, and, to indicate that order, we write alphabets as sequences of symbols, e.g., in the above case we write . 
The set of all finite -strings is denoted by 
and , where  is the empty string. For a string ,  denotes the length of  and     the number of occurrences of  the letter  in . The concatenation of the strings  and  is denoted by , and  denotes the string , where  for .  
For  and , the letter  is a {\em neutral letter} of  if  for all , we have . The class of languages that have a neutral letter is denoted by .


For a signature , the first-order -formulas, , are built
 from first-order variables in the usual way, using the Boolean connectives , the  predicates  together with , the
constants  and , the first-order  quantifiers
, and parentheses.  extends  in terms of
unary second-order variables and second-order quantifiers .
(The letters SOM stand for second order monadic logic; in
the literature, this logic is sometimes denoted by MSO.) 

For a complexity class  and logics  and , we write 
  
 if for every string signature  (unless otherwise specified), and every sentence  there is an equivalent sentence  . Analogously, we write   if the class of languages, over any alphabet, which can be defined in  is contained in  . We write    ()  if    and   (   and  ).
It is known \cite{mcpa71} that  is equal to the class
of star-free regular languages and that , where   is the class of  regular languages (see \cite{buel58,bue62,tra61}).

Sometimes we assume that our structures (and logics) are  equipped with auxiliary built-in
predicates in addition to , e.g.,  the ternary predicates  and . The predicates   and  are defined as

The predicate  is a further important predicate which is defined  by:  holds iff the bit with weight   is  in the binary representation of . The presence of  built-in predicates is signalled, e.g., by  the notation  and . It is well known that   (see \cite{imm99}).   In fact,
it was shown in \cite{DDLW} that  alone can define the corresponding canonical ordering, i.e.,  the symbol   can  dropped from   without a loss in expressive power.  


\subsection{Generalized quantifiers}
Next, we extend logics in terms of generalized quantifiers. The Lindstr{\"o}m quantifiers of Definition \ref{grquant}
are precisely what has been referred to as ``Lindstr{\"o}m quantifiers on strings''
\cite{buvo98}. The original more general definition \cite{lin66} uses
transformations to arbitrary structures, not necessarily of string
signature.
\begin{defi}\label{grquant}
Consider a language  over an alphabet . Such a language gives rise to a Lindstr{\"o}m quantifier ,
that may be applied to any sequence of  formulas as follows:

Let  be a -tuple of pairwise distinct variables. Let   be a structure and . 
We assume the
lexicographic ordering on , and we write  for the sequence of potential values
taken on by .  The -ary \emph{Lindstr{\"o}m quantifier} 
binding  takes a meaning if  formulas, each having as
free variables the variables in  (and possibly others), are
available.  Let , , ,
 be these  formulas.  Then

 iff the word of length  whose th letter, , is

belongs to .
\end{defi}

As an example, take  and consider ; then  is the usual first-order
existential quantifier. Similarly, the universal quantifier can be
expressed using the language . Finally,  for   and  ,  the quantifiers  are known as modular counting
quantifiers \cite{str94}. 


\begin{defi}Let  be a signature,    a language over an alphabet , and  a class of languages.
\begin{enumerate}[]
\item The set of -formulas, , of the logic  consists of all formulas of the form
 
where, for some ,  is a -tuple of pairwise distinct variables, and   is a -formula for .

\item The set of -formulas,  ,  of the logic   is defined by extending the formula formation rules of   by the following clause:
if, for some ,  is a -tuple of pairwise distinct  variables, and  is a formula for , then 
 
is a formula, too.
\item Define the sets of -formulas of the logics  and  by

\end{enumerate}
\end{defi}
\noindent
In this article we are especially interested in quantifiers defined by monoid and groupoid word-problems.
\begin{defi}\label{grpmon}
A {\em groupoidal quantifier\/} ({a \em monoidal quantifier\/}) is a Lindstr{\"o}m quantifier 
where  is a word-problem of some finite groupoid (monoid).
The usage of groupoidal quantifiers and monoidal quantifiers in our logical language is signalled by the subscripts  and , respectively. We define 

where  () is the class of all  word-problems of finite groupoids (monoids).   
\end{defi}

 Second-order Lindstr{\"o}m quantifiers on strings were introduced in
\cite{buvo98}. Here, we are mainly interested in those binding only
set variables (i.e., unary relations), so-called \emph{monadic quantifiers}. For each language ,
we define two monadic quantifiers  and  with slightly different
interpretations. It turns out that the interpretation , which was used in \cite{MR1908783},
is natural in the context of finite leaf automata. On the other hand, the quantifier
 is the exact second-order analogue of the corresponding first-order quantifier .

\begin{defi}\label{lind2}
Consider a language  over an alphabet . Let  be a -tuple of   pairwise distinct  unary
second-order variables and let   be a structure with .   There are 
different instances (assignments) of  over . We assume the following
ordering on those instances: Let each instance of a single  be
encoded by the bit string  with the meaning . Then
\begin{enumerate}[(1)]
\item\label{a} we encode an instance of  by the bit
string

and order the instances lexicographically by
their codes.
\item\label{b} we  encode an instance of  by the bit
string

 and order the instances lexicographically by
their codes.
\end{enumerate}
The \emph{monadic second-order Lindstr{\"o}m quantifier\/}  (respectively ) binding  takes
a meaning if  formulas, each having free variables , are
available.  Let , , ,
 be these  formulas.  Then 

 iff the
word of length  whose th letter, , is

belongs to . Above,  denotes the sequence
of all instances ordered as in \eqref{a}. The notation  is used when the instances are ordered according to  \eqref{b}.
\end{defi}
Again, taking as examples the languages  and
, we obtain the usual second-order monadic existential and
universal quantifiers. Note that for  the quantifiers 
and  are ``equivalent''. This is due to the fact that,  for the
membership in , the order of the letters in a word does not matter.



\begin{defi}Let  be a signature,    a language over an alphabet , and  a class of languages.
\begin{enumerate}[]
\item The set of -formulas, , of the logic    consists of 
all formulas of the form
  
where, for some ,  is a -tuple of pairwise distinct  unary second-order variables, and   is a -formula with variables , for . 

\item The set of -formulas, ,  of the logic  is defined by extending the formula formation rules of  by the following clause:
if, for some ,  is a -tuple of pairwise distinct  unary second-order variables, and  is a formula for , then 
     
is a formula, too.

\item Define the sets of -formulas of the logics  and  by


\item The logics , , , and   are defined analogously by replacing
 everywhere with .
\end{enumerate}
\end{defi}
\noindent
Analogously to the first-order case (see Definition \ref{grpmon}), we
use the subscripts   and  to indicate that all  groupoidal quantifiers or monoidal quantifiers are available in the corresponding logic, e.g., , where    is the class of all  word-problems of finite groupoids.



The next proposition shows that the difference between the two semantics of second-order monadic quantifiers disappears in the presence of built-in arithmetic (or if the  arithmetic predicates are definable). Below, we write  for the relation defined by the formula  in a structure , i.e., if  has   free variables, then     
 

\begin{lem}\label{suffle} Let  be  unary second-order variables. There are -formulas
  and   such that for all    and  , (where   is encoded by  as in Definition \ref{lind2}) it holds that the encoding of   as a bit string as in clause \ref{a} of Definition \ref{lind2} results with 

and the encoding of  as a bit string as in clause \ref{b} of Definition \ref{lind2} results with 

\end{lem}
\proof 
Let us show how to construct the formulas  . The idea simply is that 

should hold if the bit in position  from the left in \eqref{fs}  is  if and only if   and , where
, , , and  . This condition can be easily expressed in . The formulas   can be constructed completely analogously. 

Note also that the formulas   define a  permutation of -tuples of unary relations  and that   define the  inverse of this permutation.
\qed


\begin{prop}\label{sufflecor}For any , .
\end{prop}
\proof
 by Lemma \ref{suffle},   can be expressed as 

Analogously,  can be expressed as  
\vskip6 pt

\noindent By Proposition \ref{sufflecor}, the two semantics of
second-order quantifiers coincide for all the logics (with built-in or
definable arithmetic) considered in this article.

\begin{rem}\label{mary} Let  and  be as in Definition \ref{lind2}. It is worth noting that, for , the -ary second-order quantifiers  and  can be defined  by  straightforward modifications to Definition \ref{lind2}. The -ary quantifiers binds  a -tuple   (for some ) of -ary second-order variables in  many formulas.  Each  is encoded by the bit string  with the meaning  if and only if  the th tuple in the lexicographic ordering of  is in . The semantics of the -ary quantifiers  and  can be now defined analogously to Definition \ref{lind2}.
We use the notation 
   and   for the analogues of   and  in which the -ary quantifiers  and  are allowed for  .
\end{rem}


We end this section by showing that, in the non-monadic case, the analogue of Proposition \ref{sufflecor} holds without built-in arithmetic if  has a neutral letter.  
\begin{prop}\label{sufflemary} For any , 
  .
\end{prop}
\proof We may assume that  has an  alphabet , where  is a neutral letter. 

We will first show that . The idea of the proof is to show that a formula  can be replaced by 
a formula  in which only one second-order variable with higher arity is quantified. Now, in  , the quantifier  can be replaced by  since the difference of the two semantics only appears if more than one variable is quantified. The converse inclusion follows directly from the fact that  (see Theorem \ref{conn}).  

Let  be of the   
 
where  is a tuple of -ary second-order variables. It is straightforward to construct a formula 
 
where the arity of  is , which is equivalent to  over structures  with . Let  be a structure such that  and .  The idea is to encode the tuple  by a unique -ary relation 

where  is the length  binary representation of . This ensures that  the  ordering of the tuples  (see Definition \ref{lind2} and Remark \ref{mary}) coincides with the ordering of the corresponding codes . Therefore, it suffices to construct the formulas  in such a way that, for all    

and,  if  for all , then   implying that  the formulas  output the neutral letter when  is interpreted by the relation . 

In order to ensure that   
 and  are equivalent also over structures  for which , we may further replace the formulas 
 by formulas , where each  , for , is also -ary and  has the following form

where  simulates the behavior of  on structures with cardinality  (on structures with cardinality  the quantifiers  and  are equivalent).  Note that, for  with , the formulas
  output the neutral letter if  for some . It follows that for all 


For the converse, it suffices to note that a
polynomial-time non-deterministic Turing machine with the leaf language  can  easily evaluate sentences of  implying that   (see \cite{buvo98}). Therefore, by Theorem \ref{conn}, we get that .
\qed

\subsection{Leaf languages}\label{leafl}
In this section we give a brief introduction to the leaf languages approach in computational complexity.

 The leaf languages approach was introduced by Bovet, Crescenzi and Silvestri in \cite{bocrsi92} and independently by Vereshchagin in \cite{ver93a}. In this approach the acceptance of a word input to a nondeterministic Turing machine depends only on the values printed at the leaves of the computation tree. 

Let  be a nondeterministic Turing machine which halts on every computation path with some order on the nondeterministic choices. The order of the nondeterministic choices induces a left-to-right ordering of all the leaves in the computation tree of  on input . Define  to be the concatenation of the symbols printed at the leaves of the computation tree in this order. Given now a language  , the class  contains those languages  for which there is a polynomial-time non-deterministic Turing machine  such that for all inputs :  iff  .

Let us look at some examples. Define . 
\begin{exa} The following leaf language classes are well known:
\begin{enumerate}[]
\item ,
\item ,
\item .
\end{enumerate}
\end{exa}
\noindent
In \cite{buvo98} complexity classes defined by  leaf languages were  logically characterized in terms of generalized second-order quantifiers. In particular, for every language  that has a
 neutral letter the following was shown to hold. 
\begin{thm}[\cite{buvo98}]\label{conn}
For any , .
\end{thm}
Note that, for Theorem \ref{conn} to hold, the quantifier  must be
allowed to bind relation variables of arbitrary arity (see Remark \ref{mary}). 
Although the -ary second-order quantifiers  and   differ, in Theorem \ref{conn} we can equivalently use the semantics  instead of    by Proposition \ref{sufflemary}. 




Since it is known that there are regular languages , e.g., the word-problem for
the group , for which  \cite{helascvowa93}, we conclude that for
such ,

\subsection{Finite leaf automata}
The automata theoretic analogue of a Turing machine with a leaf language is the so-called finite leaf automaton \cite{pevo01}.

A \emph{finite leaf automaton} is a tuple
 where  is a finite set of
states,  is an alphabet, the input alphabet,
 is the transition
function,  is the  initial state,  is an
alphabet, the  leaf alphabet, and  is a function that associates a state  with its
 value .  The sequence , for 
and , contains all possible successor states of  when
reading letter  while in state , and the order of letters in
that sequence defines a total order on these successor states.
This definition allows the same state to appear more than once as a
successor in .

Let  be as above.  The computation tree  of  on input
 is a labeled directed rooted tree defined as follows:
\begin{enumerate}[]
\item The root of  is labeled .
\item Let  be a node in  labeled by , where
 (the empty word),  for ,
.  Let . Then  has 
children in , and these are labeled by
 in this order.
\end{enumerate}
If we look at the tree  and attach the symbol  to a
leaf in this tree with label , then  is
defined to be the string of symbols attached to the leaves, read from
left to right in the order induced by .


\begin{defi}
For , the class  consists of all languages
, for which there is a leaf automaton  as just
defined, with input alphabet  and leaf alphabet  such
that for all ,  iff . If  is  a class of languages then
.
\end{defi}

In \cite{pevo01} the acceptance power of leaf automata with different kinds of leaf languages was examined.
 It was shown that,
with respect to  resource-bounded leaf language classes, there is not much difference, e.g., between automata and Turing
machines.  On the other hand, if the leaf language class is a formal language class then the differences can be huge. In particular, it was shown   that

 while it is known that

 In \cite{pevo01}
the power of   was left as an open question. The only upper
and lower bounds known at that time were .
Recently  it was  shown by Lohrey \cite{loh08} that indeed  does contain a -complete language.

In \cite{MR1908783} the class  was logically characterized assuming that
the language  has a neutral letter.
\begin{thm}[\cite{MR1908783}]\label{neutral}
For any , .
\end{thm}

\begin{cor}\label{Grppspace}-complete languages can be defined in  .
\end{cor}
\proof By the result of  \cite{loh08}, there is a language  such that the class   contains
a   -complete language.  Since  reduces via a length-preserving homomorphism 
to some  groupoid word-problem  \cite{belemc93}, it follows that also the class   contains a  -complete language.
\qed

\subsection{Complexity theory}

We assume familiarity with the basic notions in formal languages and complexity theory, e.g., complexity classes such as , , , and . 
 and  refer to the regular and context-free languages. Also,  denotes the closure of  under log-space reductions.

In this article  , ,  , , and   refer to the classes of languages recognized by -uniform families  of  polynomial-size circuits with the following kinds of gates: 
\begin{enumerate}[]
\item[:] the circuit  may have NOT, unbounded fan-in AND and OR gates, and constant depth.
\item[:]  the circuit  may have NOT, unbounded fan-in AND, OR and   gates, and constant depth.
\item[:] the circuit  may have NOT, unbounded fan-in AND, OR, and MAJORITY gates, and constant depth.
\item[:]  the circuit  may have NOT,  bounded fan-in AND and OR gates, and  depth.
\item[:]  the circuit  may have input level NOT gates,  bounded fan-in AND and unbounded fan-in OR gates, and  depth.
\end{enumerate}
 The requirement of -uniformity means that , as a family of  directed acyclic graphs, can be recognized by a deterministic Turing machine, with random access to its input,  in time  (see \cite{vol99} for details). Note that, e.g., the classes  and  are defined analogously as above but allowing  circuit-depth. 

In this article we also discuss certain complexity classes defined in terms of alternating Turing machines.  We denote by , the class of languages which can be recognized in time   by some  alternating Turing machine.  

Let  be an alternating Turing machine accepting  and denote by  the computation tree  produced by  with input . An \emph{accepting computation subtree}  of  on input  is a subtree of   witnessing that  accepts . The idea is that all the nodes in  must be accepting configurations, and, furthermore,  must contain the initial configuration, i.e., the  root of , all successors of universal configurations, and exactly one successor of each existential configuration.  

We say that an alternating machine  is \emph{tree-size bounded} by  if for every  accepted by  there is an accepting computation subtree of  on input  which has at most  nodes. 
Let now 
 
 denote the class of languages which can be recognized by an  alternating Turing machine  which is  space bounded by  and tree-size bounded by . 

The following (non-trivial)  inclusions and  equalities are known to hold among the classes defined above: 

The last two equalities where shown by Venkateswaran  \cite{ven91} and  Ruzzo \cite{ruz80}, respectively.


\section{Groupoidal quantifiers}

\noindent In this section we consider second-order monadic groupoidal
quantifiers. We show that the extension of  in terms of all
second-order monadic groupoidal quantifiers collapses in expressive
power to its fragment  (respectively to
).

The following result on first-order groupoidal quantifiers will be central for our reasoning.
Below,  refers to the set of quantifier-free formulas (of suitable signature) in which the predicates  and  do not appear.

\begin{thm}[\cite{lamcscvo01}]\label{grup}  
\end{thm}
We shall use the following  version  of Theorem \ref{grup}.

\begin{lem}\label{new}Let , where  are  constant symbols. Then on -structures

\end{lem}
\proof The idea of the proof is to translate  into  of a suitable string signature using a simple encoding of -structures into strings. By Theorem \ref{grup}, we may then replace  by an equivalent formula . Finally, we show that  can be translated back to a formula
 in such  a way that   and  are equivalent.
 
Suppose that  is a class of -structures definable by .
We shall encode  as a class of strings over signature
, where  is some fixed enumeration of
the subsets of . We associate every -structure  with a unique string
 over the same universe in the following way. For ,  define

Note that the predicate  is interpreted by the set  where  is the universe of .

 Let  be acquired from  by replacing atomic subformulas
of the form  by  and  by the formula .
It is now obvious how to translate atomic formulas using the predicates , and , e.g., the formula  is replaced by . It is easy to show using induction on the construction of  that for all -structures
 , 

By Theorem \ref{grup} there is a sentence  which is equivalent to 
over strings. Let  be acquired from  by replacing subformulas    by

 Again by induction on   we get that for all -structures
 ,

 It follows that  defines .
\qed

We are now ready for the main result of this section. Note that the built-in predicates   and  are definable 
already in terms of (first-order) majority quantifiers (see  \cite{baimst90} and \cite{lamcscvo01}) and hence definable in the logics  in which groupoidal quantifies are allowed to be nested.

\begin{thm}\label{11}  .
\end{thm}
\proof 
Fix a signature .
Suppose that   is a sentence. We will show how to construct a sentence  of the logic 
  equivalent to . The idea of the proof is to represent 
 , and the  language of signature  defined by ,  in terms of  , and the class of -structures defined by ,  where   and  are constant symbols. More precisely, by representing  -structures of cardinality  by -structures of cardinality , we can replace second-order variables over the domain  by first-order variables ranging over  using the -predicate. Then we apply Lemma \ref{new} to get a formula     equivalent to . Finally, we show that  can be translated back to a formula   in such a way that the original formula  and  are equivalent.  

Denote by  the signature where each  is a constant symbol. For a -structure
, let  be the following -structure

where  is the unique integer () whose binary representation is given by
 where  .

We shall first show that there is a sentence  such that
for all -structures ,

The translation   is defined inductively as follows.  For  of the form  or , , and in the remaining  cases (we may exclude the definable  constants ,  , and the  second-order existential quantifier  from  since  is available)  the translation is defined in the following way:

It is straightforward to show using induction on the construction of , that for all  -structures  and assignments ,
 
where the  assignment  over  is defined such that  , for all first-order variables , and, for a second-order : if , then  is the unique  whose length  binary representation is given by
 where  .  

Above, we use the predicate   which is definable in  (see, e.g., \cite{imm99}). Note also that, using   the predicate ,  the integer  can be  easily defined over the structure .
 
By Lemma \ref{new}, there is a sentence

where each  is quantifier-free and does not contain the predicates  and , equivalent to .
The idea is now to translate  into  
by  changing first-order variables to second-order variables. Denote by  the formula
,
and by  the first-order formula defining the ordering of subsets when treated  as length  binary strings. The translation  
is now defined by

Above,   is  either min, max, , for , or a variable , and, respectively,  is  either , , , or . A straightforward  induction implies, in particular, that for all sentences , and -structures 

where   is defined as above. It is now immediate that  and the original  sentence  are equivalent.
\qed

Note that, by Proposition \ref{sufflecor},  we do not need to consider the semantics  separately. By combining 
Theorem \ref{11} and Proposition \ref{sufflecor}, we get
\begin{cor}\label{cor}

\end{cor}\vskip3 pt

\noindent We close this section by showing that a much stronger analogue of Corollary \ref{cor} holds. Recall that the so-called Greibach's hardest context-free language  is a  nondeterministic
version of the Dyck language , the language of all syntactically correct sequences consisting of letters for two types of parentheses. It is known that every  reduces to  under some homomorphism \cite{gre73}. It was shown in \cite{lamcscvo01} that the statement of Theorem \ref{grup} remains valid even if the
logic  is replaced by the logic , where  is  extended by a neutral letter. This result directly implies the following strengthening of Corollary \ref{cor}.

\begin{thm}\label{Greibach}

\end{thm}
\proof The proof is analogous to the proof of Theorem \ref{11}. It suffices to prove the last equality in the statement of the theorem. Suppose that   is a sentence. By an analogous argument as in the proof of Theorem \ref{11}, we first translate
 into a sentence . Then we replace  by an equivalent sentence . Now, again by an analogous argument as in the proof of Theorem \ref{11},  can be translated back to the logic  .\qed

\section{Monoidal quantifiers}

\noindent In this section we consider second-order monadic monoidal
quantifiers.

As already mentioned, the following result completely characterizes the picture in the case of the semantics  without built-in arithmetic.
\begin{thm}[\cite{MR1908783}]\label{monoids}

\end{thm}
Interestingly, the expressive power of  monoidal quantifiers collapses to regular languages when  built-in arithmetic is not present. Under reasonable complexity theoretic assumptions,  the corresponding equalities between the logics in Theorem \ref{monoids} do not hold with built-in arithmetic. Furthermore, it is an open question if the analogue of Theorem \ref{monoids} holds with respect  to the semantics . Again, by Proposition \ref{sufflecor}, we however know that the  semantics coincide assuming built-in arithmetic. 

\begin{thm}\label{MonoidswA} The following equivalences hold
\begin{enumerate}[\em(1)]
\item\label{MonoidswA1} ,
\item\label{MonoidswA2} .
\end{enumerate}
\end{thm}
\noindent
Note that also in equivalence \ref{MonoidswA2} of  Theorem \ref{MonoidswA}  the arithmetic predicates (in fact  would also suffice) need to be assumed by Theorem \ref{monoids}, i.e.,  and   are not definable  in .  It is an open question whether the equivalences of Theorem \ref{MonoidswA} hold without built-in arithmetic.


\section{Complexity results}
\noindent In this section we study the data complexity of the logics
discussed in the previous sections.

We begin with a simple logical padding argument which allows us to utilize Theorem \ref{conn} in the context of second-order monadic quantifiers. Recall  that, in the statement of  Theorem \ref{conn}, the  quantifier  is allowed to bind relation variables of arbitrary arity (see Remark \ref{mary}).  Below, we do not distinguish notationally between a string  of alphabet ,  and the string structure of signature  corresponding to .   
\begin{prop}\label{padd}Let  be a language and suppose that a language  of alphabet   is definable by a sentence .
Let  be the arity of the relations quantified in  and . Then the language

is definable in .
\end{prop}
\proof 
Let  be of the form

where each of the relations  has arity .  Define a translation     as follows. For  of the form ,  , or , , and in the remaining  cases (we exclude the definable constants  and ) the translation is defined in the following way:

It is straightforward to show using induction on   that for all  and assignments 

where  agrees with  with respect to first-order variables, and 

 Note also that, by our conventions, the universe of   is   hence there is 1-1 correspondence between the subsets of 
 and the -ary relations over the universe, , of .

Finally, the language  is defined by , where  and 


\noindent Proposition \ref{padd} shows that logics
 can be quite powerful. In fact, it is apparent
from the proof that if, e.g.,  in the
proof of Proposition \ref{padd} defines a -complete language,
then the language defined by  is
also -complete.


\begin{cor}\label{monpspace} In the logic ,  -complete languages can be defined.  
\end{cor}
\proof  This follows, e.g., by the fact that 

where  is the word-problem for the group  (see Section \ref{leafl}), and by Proposition \ref{sufflecor}.
\qed\vskip3 pt

\noindent Recall that in the case of groupoidal quantifiers, already
in  -complete languages can be defined by
Corollary \ref{Grppspace}.

Next we show that the logics  and  capture the exponential versions of the language classes captured by the logics   and . As already noted in Theorem \ref{grup},  the logic  corresponds to   \cite{lamcscvo01}. On the other hand, in  \cite{baimst90} it was show that 

\begin{defi} For , denote by  the binary representation of  without leading zeros. Let   and . Define now  as
  
\end{defi}\vskip6 pt

\noindent Let us now define the classes of languages
 and  by

The following is easily seen to hold:
\begin{prop}\label{easy}The following equalities hold
\begin{enumerate}[\em(1)]
\item ,
\item .
\end{enumerate}
\end{prop}
\proof
The first equality is obvious and the second follows from Ruzzo's characterization  of : 

  (see  \cite{ruz80} and \cite{vol99}).
\qed

\begin{rem} By the above, we immediately get that     It is also straightforward to show that   includes the languages that can be recognized in  linear time on a Threshold Turing machine (introduced in  \cite{pasc88}).
\end{rem}

The main result of  this section can be now stated as follows:
\begin{thm}\label{compres}The following equivalences hold
\begin{enumerate}[\em(1)]
\item\label{main1} , 
\item\label{main2} 
\end{enumerate}
\end{thm}
\proof We will prove equivalence \ref{main2}. Equivalence \ref{main1} is proved  analogously using the fact that 
  (see  \eqref{ATIME(logn)}).

 We will show that,  for all ,   is definable in   iff . Since , it suffices to show that for all ,   is definable in   iff  is definable in  . 


We will first
show that if  is definable in  , then  can be defined in .
The idea is now to translate formulas between  string structures 

  and

  where  , , and . Some technical difficulties arise here, which were not encountered  in the proof of  Theorem \ref{11}, due to the fact that the sizes of the universes of   and  are not necessarily exactly of the form  and  for some . 

We define a translation    of    into   below. 
Analogously to the  proof of  Theorem \ref{11},  it can be shown using  induction  on ,  that for all   and assignments ,
 
The assignment  is defined  so that it agrees with  on first-order variables , and, for a variable , corresponding to a second-order variable  , , where  and  iff . 

The translation   is defined inductively as follows.
For  of the form  or , , and in the remaining  cases (again, we exclude the definable constants , , and the  second-order existential quantifier from  since  is available) the translation  is defined in the following way  (recall that by  \eqref{w} and \eqref{n} we have  ):

Note that, e.g.,  the formula  above can be easily constructed even though  the integer  
is not in the universe of the structure .   Without loss of generality,    we may  assume that the letter  in the alphabet   of  is a neutral letter. Now 
the formula , used to translate , ensures that the interpretation  of the tuple  does correspond to some tuple of unary relations . The problem is that there can be more tuples  than tuples . The formula  is defined as

Now if  is not satisfied by , then none of the formulas 
will be satisfied and hence these formulas produce the neutral letter  when  is interpreted as .

We conclude that, by the above,  if  is defined by a sentence , then the  sentence 

defines .

We will next define a formula translation    mapping   into . Again,
an analogous induction on the construction of  shows, in particular, that  for all sentences  and all , 

The translation   is defined by replacing first-order variables by unary second-order variables:

Above,    denotes the formula . Also  ,  , and    are  formulas defining the ordering, addition, and multiplication of unary relations,  when treated  as binary strings. Finally,
the formula  is simply

and it has an analogous role here as  had above. Again, we may assume
that  is a neutral letter of  when translating the quantifier .


By the above, it holds that  for all : if , then  is definable in . In order to complete the proof, it suffices to show that    is  definable in 
iff    is  definable in .  Note that on the computational side,  and  are easily definable from each other. On the logical side, it follows from the fact that   is  closed under logical reductions  for which the target structure   has size linear in . The idea is that if   then  subsets of  can be encoded by   subsets over  and, hence, such a formula translation can be defined in terms of second-order monadic quantifiers. 
 This implies\footnote{More generally, it also implies that  captures  over all string signatures, since a string  of any signature can be encoded in binary with length .}, in particular, that for any sentence  we can construct a sentence  which holds over  iff . We do not give the proof here but refer to the proof of Corollary 8.6 in \cite{Kon3} in which an analogous result is proved for the extension of  in terms of the second-order monadic majority quantifier.
\qed

Finally, we turn to the case of symmetric (commutative) languages. It is obvious that, for a symmetric language , the quantifiers   and  are equivalent. Let  and  denote the classes of symmetric context-free and regular languages, respectively. 

Denote by  the linear analogue of the class . Recall that    is the oracle hierarchy, analogous to the polynomial hierarchy , in which the building block of the hierarchy is   and the   level is defined by allowing access to oracles from the Boolean closure of the th level. Similarly, we denote by  the linear analogue of the counting hierarchy , which is the oracle hierarchy with  as the building block. 

The expressive power of second-order monadic quantifiers defined by symmetric regular and context-free languages can be  characterized as follows:  
\begin{thm}\label{symm}The following equivalences hold
\begin{enumerate}[\em(1)]
 \item\label{symm1} 
\item\label{symm2} 
\end{enumerate}
\end{thm}
\proof Let us first show equivalence \ref{symm2}. Note that by Parikh's theorem on context-free languages, every symmetric context-free language is already in  and, by \cite{baimst90}, . Therefore, we get that 

by an analogous argument as in Theorem \ref{11}. In \cite{Kon3} it was shown that 

hence the claim follows. 

For equivalence \ref{symm1}, note that  (see \cite{baimst90}) and that, analogously to    and ,   is the logarithmic analogue of  (see \cite{algo94,all99}).  Hence, by standard padding  we get that  and, mimicking the proof of Theorem \ref{compres}, it follows that  
\vskip6 pt

\noindent We conclude this section by the following table summarising the results on the  data-complexity of the logics studied in this paper. 
\begin{table}[h]
\caption{Summary of the results}
\centering
\begin{tabular}{|c| c| c|c| }
\hline \hline
Logic \& built-ins &  &  & Result  \\
\hline \hline
  &  & -comp. & Thm \ref{monoids} \cite{MR1908783}, Cor \ref{monpspace} \\

  &  & -comp. &\cite{bue62, tra61}, Cor \ref{monpspace}  \\
\hline
  &   &  & Thm \ref{monoids} \cite{MR1908783},  Thm \ref{compres}   \\

   &   &   & \cite{bue62, tra61},  Thm \ref{compres}  \\
\hline
  & -comp. &    &  Cor \ref{Grppspace} \cite{loh08},   Thm \ref{compres} \\

  &  & &  Thm \ref{compres}    \\
\hline
 &  & &   Thm \ref{compres}   \\

 &  & & Thm \ref{compres}    \\
\hline
 &  &  &  Thm \ref{monoids} \cite{MR1908783}, Thm \ref{symm}   \\

 &  & &Thm \ref{symm}    \\
\hline 
\end{tabular}
\label{table:summary}
\end{table}
\section{Conclusion}
\noindent We conclude with two questions for further study.
The main open question regarding  groupoidal quantifiers is  to determine whether the two variants of
semantics for second-order groupoidal quantifiers coincide in the most restricted case studied in this paper, i.e., is it the case that

A positive answer would imply that

This would strengthen the recent -hardness result \cite{loh08} considerably (showing that  contains -complete problems, and answering the open question from \cite{MR1908783}).

The second open question concerns the expressive power of the quantifiers , for a  regular . It is an open question whether non-regular languages can be defined in   .

\bibliographystyle{abbrv}
\bibliography{Leafbib}



\end{document}
