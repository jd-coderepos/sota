\documentclass[12pt]{llncs}

\usepackage{a4wide,times}

\usepackage{pgf,tikz}
\pgfrealjobname{thesis}
\usetikzlibrary{arrows}
\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{shapes.misc}
\usetikzlibrary{fit}
\usetikzlibrary{patterns}
\usetikzlibrary{decorations.pathreplacing}

\setcounter{tocdepth}{2}

\makeatletter
\renewenvironment{table}
               {\setlength\abovecaptionskip{10\p@}\setlength\belowcaptionskip{10\p@}\@float{table}}
               {\end@float}
\renewenvironment{table*}
               {\setlength\abovecaptionskip{10\p@}\setlength\belowcaptionskip{10\p@}\@dblfloat{table}}
               {\end@dblfloat}
\makeatother

\usepackage{rotating,listings}
\usepackage{longtable,paralist}
\usepackage{multicol}
\usepackage[hang,small,bf]{caption}



\usepackage[FIGBOTCAP,TABBOTCAP]{subfigure}
\renewcommand{\subfigcapskip}{1ex}

\renewcommand{\thesubtable}{\thetable.\arabic{subtable}}
\renewcommand{\thesubfigure}{\thefigure.\arabic{subfigure}}
\makeatletter
\renewcommand{\p@subtable}{}
\renewcommand{\p@subfigure}{}
\renewcommand{\@thesubtable}{\textbf{Table \thesubtable:}\hskip\subfiglabelskip}
\renewcommand{\@thesubfigure}{\textbf{Fig. \thesubfigure:}\hskip\subfiglabelskip}
\makeatother

\usepackage{needspace}
\usepackage{ifthen}

\lstset{basicstyle=\ttfamily\small, commentstyle=\color{darkgray}, belowskip=-0.2cm, lineskip=-3pt, tabsize=3}
\lstset{numbers=left, numberstyle=\color{gray}\footnotesize, stepnumber=1, numbersep=5pt,xleftmargin=5mm}
\lstset{frame=bt,framexleftmargin=5mm}
\lstset{escapeinside={(*@}{@*)}}

\usepackage{booktabs} 

\usepackage{graphicx} \setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio}
\graphicspath{{graphics/}}

\usepackage{xspace} \usepackage{units} 

\newcommand{\tp}{digram\xspace}
\newcommand{\tps}{digrams\xspace}
\newcommand{\ltp}{Digram\xspace}
\newcommand{\ltps}{Digrams\xspace}

\newcommand{\trp}{\mbox{TreeRePair}\xspace}

\newcommand{\hairsp}{\hspace{1pt}}\newcommand{\TODO}{\textcolor{red}{\bf TODO!}\xspace}
\newcommand{\ie}{\mbox{\textit{i.\hairsp{}e.}}\xspace}
\newcommand{\eg}{\mbox{\textit{e.\hairsp{}g.}}\xspace}
\newcommand{\cf}{\textit{cf.}~}

\usepackage{amsmath,amssymb}


\pagestyle{plain}

\begin{document}

\title{Tree structure compression with RePair}
\author{Markus Lohrey\inst{1,}\thanks{The first author 
is supported by the DFG  research project ALKODA.} 
\and Sebastian Maneth\inst{2} \and  Roy Mennicke\inst{1}
\institute{
Universit\"at
Leipzig, Institut f\"ur Informatik, Germany
\and
NICTA and University of New South Wales, Australia
\\
\email{lohrey@informatik.uni-leipzig.de,
  sebastian.maneth@nicta.com.au,
  roy@mennicke.info}}}

\maketitle

\begin{abstract}
In this work we introduce a new linear time compression algorithm,
called "Re-pair for Trees", which compresses ranked ordered trees
using linear straight-line context-free tree grammars. Such grammars
generalize straight-line context-free string grammars and allow basic
tree operations, like traversal along edges, to be executed without
prior decompression. Our algorithm can be considered as a
generalization of the "Re-pair" algorithm developed by N. Jesper
Larsson and Alistair Moffat in 2000. The latter 
algorithm is a dictionary-based compression algorithm for strings. 
We also introduce a succinct coding which is specialized in further
compressing the grammars generated by our algorithm. This is
accomplished without loosing the ability do directly execute queries
on this compressed representation of the input tree. Finally, we
compare the grammars and output files generated by a prototype of the
Re-pair for Trees algorithm with those of similar compression
algorithms. The obtained results show that that 
our algorithm outperforms its competitors 
in terms of compression ratio, runtime and memory usage.
\end{abstract}



\section{Introduction}

\subsection{Motivation}

Trees are nowadays a common data structure used in computer science to
represent data hierarchically. This is, for instance, evidenced by XML
documents which are widely used after their introduction in 1996. They
are sequential representations of ordered unranked trees.	When
processing trees it is often convenient to hold the tree structure in
memory in order to retain fast and random access to its
nodes. However, this often leads to a heavy resource consumption in
terms of memory usage due to the necessary pointer structure which
represents the tree structure. The space needed to load an entire XML
document into main memory in order to access it through a DOM proxy is
usually 3--8 times larger than the size of the document itself
\cite{Wang07space}. Therefore, it is essential for very large tree
structures to use a memory 
efficient representation. 

In \cite{Frick03query,Buneman03path} directed acyclic graphs (DAGs) were proposed to overcome 
this problem. By sharing common subtrees one is able to reduce the
size of the in-memory representation by a factor of about 10
\cite{Buneman03path}. One of the most appealing properties of this
representation is that queries like the ones of the XPath language can
be directly executed on the compressed representation, \ie, it is not
necessary to completely unfold the DAG.

Later, in \cite{Busatto08efficient} so called linear straight-line
context-free tree grammars were proposed as a more succinct
representation of an input tree. These grammars represent exactly one
tree and generalize the concept of sharing common subtrees to the
sharing of repeating tree patterns. Most important, this new
representation is still queryable, \ie, queries can be evaluated
without prior decompression. At the same time, the complexity of
querying, e.g., using XQuery, stays the same as for 
DAGs \cite{Lohrey2006complexity}.

However, finding the smallest linear straight-line context-free tree
grammar generating a given tree is NP-hard. Already finding the
smallest context-free string grammar for a given string is NP-complete
\cite{Charikar05smallest}. In \cite{Busatto08efficient} an algorithm
called BPLEX was introduced which generates a small linear
straight-line context-free tree grammar for a given input tree. On
average, the resulting grammar is 3.5--4 times smaller than the
minimal DAG (in terms of the number of edges). 
An implementation of this algorithm, which 
processes the underlying tree structure of XML documents, was also provided.

\subsection{Main Contribution}

Our main contribution is a compression algorithm, called "Re-pair for
Trees", which is based on linear straight-line context-free tree
grammars. Our investigations show that, regarding our test data, the
grammars generated by Re-pair for Trees are always smaller than the
grammars produced by the BPLEX algorithm. In addition, our algorithm

outperforms BPLEX 
in terms of runtime and memory usage. Note that especially 
runtime was a huge drawback of the BPLEX implementation.

The Re-pair for Trees algorithm is a generalization 
of the "Re-pair" algorithm which was developed by \textsc{Larsson} and
\textsc{Moffat} in \cite{larsson2000off}. The latter algorithm is an
offline dictionary-based compression method for strings consisting of
a simple but powerful phrase derivation method and a compact
dictionary encoding. A \emph{dictionary-based} compression algorithm
is an algorithm where the input message is parsed into a sequence of
phrases selected from a dictionary. Since the reference to a phrase in
the dictionary is more compact than the phrase itself often a
considerable compression can be achieved. Re-pair's dictionary is
inferred \emph{offline} since it is generated by considering the whole 
input message and since it is written out as a 
part of the compressed data so that it is available to the decoder.
\begin{figure}[t]
	\centering
	\renewcommand{\arraystretch}{2.0}
	\begin{tabular}{lcc}
		Source message:&&{\renewcommand{\arraystretch}{1.0}
			}\\
		After the replacement of :&&{\renewcommand{\arraystretch}{1.0}
			}
	\end{tabular}
	\caption{The pair  is replaced by the new symbol .}
	\label{fig:repalg}
\end{figure}
The name Re-pair stands for "recursive pairing" and describes the idea
of the algorithm. The latter is to count the frequencies of all pairs
formed by two adjacent symbols of the source message, replacing the
most frequent pair by a new symbol (see Fig.~\ref{fig:repalg}),
updating the frequency counters of all involved pairs and repeating
this process until there are no pairs occurring twice in 
the source message. This compression technique allows 
searching the compressed data without prior decompression.

\subsection{Organization of this Work}

In Sect.~\ref{ch:repairAlgorithm} we explain in detail the two steps
of which the Re-pair for Trees algorithm consists. We also present a
complete example of a run of our algorithm and consider the
compressibility of special types of trees depending on the maximal
rank allowed for a nonterminal. Sect.~\ref{ch:implementationDetails}
explains some of the implementation details for the Re-pair for Trees
algorithm which is called \trp. In particular, we elaborate on its
linear runtime, the internal data structures used and its efficient
in-memory representation of the input tree. Moreover, in
Sect.~\ref{ch:succinctCoding} we present a succinct coding which is
specialized in further compressing the grammars generated by the
Re-pair for Trees algorithm without loosing the ability to directly
execute queries on this compressed representation of the input
tree. By using a combination of multiple Huffman codings, a run-length
coding and a fixed-length coding the resulting file sizes are always
smaller than the sizes of the files generated by competing compression
algorithms when executed on our test data. In
Sect.~\ref{ch:experimentalResults} we compare the compression results
of our implementation of the Re-pair for Trees algorithm with several
other compression algorithms. In particular, we consider BPLEX and
"Extended-Repair". The latter algorithm is also based on the Re-pair
for strings algorithm and was independently developed at the
University of Paderborn, Germany \cite{Krislin08repair,Boettcher10clustering}. 


\section{Preliminaries}

In the following,  denotes
the set of non-zero natural numbers. For a set  we denote by 
 the set of all finite words over . 
For  we define . 
The empty word is denoted by .

We sometimes surround an element of  by square brackets in
order to emphasize that we currently consider it a character instead
of a number. For instance, for the sequence of integers 
 we shortly write  instead of  to clarify that we are not dealing with the fifth power of .

\subsection{Labeled Ordered Tree}

A \emph{ranked alphabet} is a tuple
, where  is a finite set of
\emph{function symbols} and the function
 assigns to each
 its \emph{rank}. Furthermore, we define
.
We fix a ranked alphabet  in the following.
An \emph{-labeled ordered tree} 
is a pair , where
\begin{enumerate}[(1)]
	\item  is a finite set of \emph{nodes},
	\item ,
	\item if , then also , and
	\item if  and , then  if and only if .
\end{enumerate}
The node  is called the \emph{root} of
. By , where
 and
, we denote the \emph{index}  of the node ,
\ie,  is the -th child of its parent node. Furthermore, we
define . The \emph{size} of  is given by the
number of edges of which it consists, \ie, we have
. The \emph{depth} of the tree  is
. We identify an
-labeled tree  with a term in the usual way: if
, then this term is
, where  is the term associated with the
subtree of  rooted at node , where . The set
of all 
-labeled trees is .
\begin{example}\label{ex:tree}
	In Fig.~\ref{fig:tree} an -labeled ordered tree  is shown. We have
	
\end{example}
\begin{figure}[t]\centering
	\centering
	\begin{tikzpicture}[->,>=stealth',semithick]
		\tikzstyle{level 1}=[level distance=0.8cm, sibling distance=1.5cm]
		\tikzstyle{level 2}=[level distance=0.8cm, sibling distance=0.75cm]
		\tikzstyle{level 3}=[level distance=0.8cm, sibling distance=0.4cm]

		\node {}
			child {node {}
				child {node {}
					child {node {}}
					child {node {}}
				}
				child {node {}
					child {node {}}
					child {node {}}
				}
			}
			child {node {}
				child {node {}
					child {node {}}
					child {node {}}
				}
				child {node {}
					child {node {}}
					child {node {}}
				}
			}
			child {node {}
				child {node {}}
			}
		;
	\end{tikzpicture}
	\caption{-labeled ordered tree }\label{fig:tree}
\end{figure}
We fix a countable set  with
 of \emph{(formal context-)
  parameters} (below we also use a distinguished parameter
). The set of all -labeled trees
with parameters from  is denoted by
. Formally, we consider 
parameters as function symbols of rank  and define . 
The tree  is said to be \emph{linear} if every
parameter  occurs at most once in . By
 we denote the tree that is obtained by
replacing in  for every  every 
-labeled leaf with , where 
 and .
A \emph{context} is a tree  
in which the distinguished parameter  appears exactly once. 
Instead of  we write briefly .
Let  such that for every  there
exists a node  with . We say
that \emph{ is a tree pattern occurring in } if there exist a context  and trees  
such that


\subsection{SLCF Tree Grammar}

For further consideration, let us fix a countable infinite set
 of symbols of rank  with
 and
. 
Hence, every finite subset 
 is a ranked alphabet.
A \emph{context-free tree grammar (over the 
ranked alphabet )} or short \emph{CF tree grammar} is a triple , where
\begin{enumerate}[(1)]
	\item  is a finite set of \emph{nonterminals},
	\item  (the set of \emph{productions}) is a finite set of
          pairs , where , ,
          , each of the parameters
           appears in ,
          and\footnote{In contrast to
            \cite{Lohrey09parameterreduction}, our definition of a
            context-free tree grammar inherits productivity, \ie,
             and each parameter
             appears in  for every
            . This is justified by the fact that the 
            grammars generated by the Re-pair for Trees algorithm are always productive.}
	\item  is 
the \emph{start nonterminal} of rank .
\end{enumerate}
We assume that every nonterminal  
as well as every terminal symbol from  
occurs in the right-hand side  of some production . 

Let us define the derivation relation  on
 as follows:  iff there exists a production  with
, a context , and trees  such that 
 and . Let

The \emph{size}  of the CF tree grammar  is defined by

That means that  equals the sum of the numbers of edges of the right-hand sides of 's productions.
We consider the following restrictions on context-free tree grammars:
\begin{itemize}
	\item  is \emph{-bounded} (for ) if  for every .
	\item  is \emph{monadic} if it is -bounded.
	\item  is \emph{linear} if for every  the term  is linear.
\end{itemize}
Let  be a CF tree grammar. 
We denote the set of all nodes in the right-hand 
sides of 's productions which are labeled by the nonterminal  by , \ie,

Furthermore, let us define the following relation:

A \emph{straight-line context-free tree grammar (SLCF tree grammar)} 
is a CF tree grammar , where
\begin{enumerate}[(1)]
	\item\label{slcf_grammar_cond1} for every  there is \emph{exactly one} production  with left-hand side , and
	\item\label{slcf_grammar_cond2} the relation  is acyclic.
\end{enumerate}
The conditions (\ref{slcf_grammar_cond1}) and 
(\ref{slcf_grammar_cond2}) ensure that  contains exactly one tree, which we denote by .
Let  be an SLCF tree grammar. 
We call the reflexive transitive closure of 
 the \emph{hierarchical order} 
of  and denote it by .

\begin{example}
	Consider the (linear and monadic) SLCF tree grammar  given by the following productions:
	
	We have , where  is the tree from Example \ref{ex:tree} on page \pageref{ex:tree}.
\end{example}
SLCF tree grammars can be considered as a generalization of the
well-known DAGs (see, for instance, \cite{Lohrey2006complexity} for a
common definition). Whereas the latter is a structure preserving
compression of a tree by sharing common subtrees (see
Fig.~\ref{fig:subtree} for a depiction), SLCF tree grammars broaden
this concept to the sharing of repeated 
tree patterns in a tree (see Fig.~\ref{fig:subpattern}). 
Actually, a DAG can be considered as a -bounded SLCF tree grammar.
\begin{figure}[t]
        \centering
	\subfigure[{A tree  containing two occurrences of the very same subtree .}]{
		\begin{tikzpicture}[semithick,scale=.09]
		
			\draw (0,0) -- +(3,0) -- +(12,16) -- +(21,0) -- + (23,0) -- +(32,16) -- +(41,0) -- +(50,0) -- +(25,45) -- +(0,0);
			\draw +(22,28) node {\large };
			
			\foreach \x in {3,23} {
			\begin{scope}[xshift=\x cm, yshift=-4cm]
				\filldraw (9,16) circle (10pt);
				\filldraw (9,20) circle (10pt);
				\draw[densely dotted] (9,16) -- +(0,4);
				\filldraw[fill=black!10, draw=black] (0,0) -- +(9,16) -- +(18,0) -- +(0,0);
				\draw (9,6) node {};
			\end{scope}
			}
		\end{tikzpicture}
		\label{fig:subtree}
	}
	\hspace{2cm}
	\subfigure[{A tree  containing two occurrences of the tree pattern .}]{
		\begin{tikzpicture}[semithick,scale=.09]
		
			\draw (0,0) -- +(50,0) -- +(25,45) -- +(0,0);
			\draw +(22,28) node {\large };
	
			\foreach \xs/\ys/\lr in {10/5/2, 25/17/-2} {
				\begin{scope}[xshift=\xs cm, yshift=\ys cm]
					\filldraw[fill=black!10, draw=black] (0,0) -- +(12,0) -- +(6,10) -- +(0,0);
					\filldraw (0,0) circle (10pt);
					\draw[thin,densely dotted] (0,0) -- +(-1,-3) -- +(0,0) -- +(1,-3);
					\filldraw +(4,0) circle (10pt);
					\draw[thin,densely dotted] +(4,0) -- +(3,-3) -- +(4,0) -- +(5,-3);
					\filldraw +(8,0) circle (10pt);
					\draw[thin,densely dotted] +(8,0) -- +(7,-3) -- +(8,0) -- +(9,-3);
					\filldraw +(12,0) circle (10pt);
					\draw[thin,densely dotted] +(12,0) -- +(11,-3) -- +(12,0) -- +(13,-3);
					\draw +(6,3) node {};
					\filldraw (6,10) circle (10pt);
					\draw[thin,densely dotted] (6,10) -- +(\lr,3);
				\end{scope}
			}
		\end{tikzpicture}
		\label{fig:subpattern}
	}
\end{figure}

Let  be a linear SLCF tree grammar. We define the function

which computes for every production 
 its contribution to a small 
representation of the tree  by the linear SLCF tree grammar .
The value  specifies the number of
edges by which the production with left-hand side  reduces the size
of the grammar . However,  is
not restricted to positive values. In particular, for a production
 with  we have 
. 
Thus, a production which is only referenced once can 
be safely removed from the grammar without increasing the size of . 

Context-free tree grammars \cite{tata2007} and especially SLCF tree
grammars have been thoroughly studied recently. 
In theory, SLCF tree grammars in theory can be exponentially 
more succinct than DAGs \cite{Lohrey2006complexity}, which already can achieve exponential compression ratios.
Furthermore, in \cite{Lohrey2006complexity} various membership and
complexity problems were considered. It was shown that in many cases
the same complexity bounds hold as for DAGs. In particular, it was
pinpointed that for a given nondeterministic tree automaton 
and a linear, -bounded SLCF tree grammar  it can be
checked in polynomial time if  is accepted by
 -- provided that  is a constant. This is a worth
mentioning result since in the context of XML, for instance, 
tree automata are used to type check XML documents against an XML schema (\cf \cite{Murata05taxonomy,Neven02automata}).
Moreover, this result was further improved in
\cite{Lohrey09parameterreduction}, where it was shown 
that every linear SLCF tree grammar can be transformed in polynomial time into a monadic
(and linear) one. Together with the above mentioned result from
\cite{Lohrey2006complexity}, a polynomial time
algorithm for testing if a given nondeterministic tree automaton
accepts a tree given by a linear SLCF tree grammar 
(of arbitrary maximal rank for the nonterminals) can be obtained.

In \cite{Busatto08efficient} the so called BPLEX algorithm was
presented. It produces for a given -bounded SLCF tree grammar
, \ie,  represents a DAG, in time
 an equivalent linear SLCF tree grammar
, where
 and
 is -bounded 
( is an input parameter). Experiments have shown that  is approximately 2--3 times smaller than .

Moreover, in \cite{Lohrey09parameterreduction} it was proved that the
evaluation problem for core XPath (the navigational part of XPath)
over SLCF tree grammars is PSPACE-complete just as this was proved
earlier for DAG-compressed trees by \textsc{Frick}, \textsc{Grohe} and
\textsc{Koch} in \cite{Frick03query}. The evaluation problem for XPath
asks whether a given node in a given tree is selected by a given XPath
expression. This result is remarkable since with SLCF tree grammars
one achieves better compression 
ratios than with DAGs.

\subsection{XML Terminology}

Regarding XML documents, we use the official terminology introduced in
\cite{Yergeau08}. Thus an XML document contains one or more
\emph{elements} which are either delimited by \emph{start-tags} and
\emph{end-tags} or by an \emph{empty-element tag}. The text between
the start-tag and the end-tag of an element is called the element's
\emph{content}. An element with no content is said to be 
\emph{empty}. There is exactly one element, called \emph{root}, which does not appear in the content of any other element.
\begin{figure}[t]\small
	
	\caption{An simplified XML document.\label{fig:XmlDocument}}
\end{figure}
\begin{example}\label{ex:XmlDocument}
The simplified XML document from Fig.~\ref{fig:XmlDocument} consists
of 21 elements of the five types \texttt{books}, \texttt{book},
\texttt{author}, \texttt{title} and \texttt{isbn}. The elements of
type \texttt{books} and \texttt{book} are delimited by start- and
end-tags and exhibit element content. The remaining elements are empty
elements delimited by 
empty-element tags. The root of the XML document is the element of type \texttt{books}.
\end{example}
The \emph{name} in the start- and end-tags of an 
element give the element's \emph{type}. Elements can 
specify \emph{attributes} by using name-value pairs. Consider for instance the element
\begin{verbatim}
      <phone prefix="012">3456</phone>
\end{verbatim}
exhibiting one attribute specification with attribute name \texttt{prefix} and attribute value \texttt{012}.

In addition to these terms we denote by \emph{XML document tree} 
the nested structure of elements which is left after 
removing all character data and attribute specifications from an XML document.

\subsection{Binary Tree Model}\label{sec:binaryTreeModel}

An XML document tree can be considered as an unranked tree, \ie, nodes
with the same label possibly have a varying number of
children. Figure~\ref{fig:XmlDocumentTree} shows the XML document tree
of the XML document from Example \ref{ex:XmlDocument}. In our case,
the XML document tree is a ranked tree, \ie, all nodes with the same
label exhibit the same number of children. However, the XML document
might as well have contained an element of type \verb|book| exhibiting
a second \verb|author| child element. In this case, 
we would have not obtained a ranked tree.
\begin{figure*}[t]
	\centering \begin{tikzpicture}[->,>=stealth',semithick]
		\tikzstyle{level 1}=[level distance=1.2cm, sibling distance=3cm]
		\tikzstyle{level 2}=[level distance=1.2cm, sibling distance=0.9cm]

		\node {}
			child {node {}
				child {node {}}
				child {node {}}
				child {node {}}
			}
			child {node {}
				child {node {}}
				child {node {}}
				child {node {}}
			}
			child {node {}
				child {node {}}
				child {node {}}
				child {node {}}
			}
			child {node {}
				child {node {}}
				child {node {}}
				child {node {}}
			}
			child {node {}
				child {node {}}
				child {node {}}
				child {node {}}
			}
		;
	\end{tikzpicture}
	\caption{XML document tree of the XML document listed in Fig.~\ref{fig:XmlDocument}}\label{fig:XmlDocumentTree}
\end{figure*}

In the next section we will learn that our Re-pair for Trees algorithm
operates on ranked trees only. Therefore, in general, a transformation
of an XML document tree becomes necessary. A common way of modeling
such a tree in a ranked way is to transform it into a binary
-labeled ordered tree  by encoding first-child and
next-sibling relations. 
In fact, 
\begin{itemize}
	\item the first child element of an XML element becomes the left child of the node representing its parent element and 
	\item the right sibling element of another element becomes the right-child of the node representing its left sibling (\cf Fig.\ \ref{fig:binaryRepresentation}).
\end{itemize}
\begin{figure}[t]
	\centering
	\begin{tikzpicture}
		[bend angle=25, node distance=0.25cm,text height=1.5ex,
		place/.style={},
		pre/.style={<-,>=stealth'},
		post/.style={->,>=stealth'}]
		\node[place] (books) {};
		
		\node[place] (book1) [below=of books] {}
			edge [pre] (books);
		\node[place] (author1) [below=of book1] {}
			edge [pre] (book1);
		\node[place] (title1) [below=of author1] {}
			edge [pre] (author1);
		\node[place] (isbn1) [below=of title1] {}
			edge [pre] (title1);
			
		\node[place] (book2) [right=of book1] {}
			edge [pre] (book1);
			
		\node[place] (book4) [right=of book2] {}
			edge [pre] (book2);
		\node[place] (author4) [below=of book4] {}
			edge [pre] (book4);
		\node[place] (title4) [below=of author4] {}
			edge [pre] (author4);
		\node[place] (isbn4) [below=of title4] {}
			edge [pre] (title4);
			
		\draw[decorate,decoration={brace,mirror}] ([xshift=-5pt]isbn1.south) -- ([xshift=5pt]isbn4.south) node[midway,sloped,below=2pt] { times};

		\node[place] (book5) [right=of book4] {}
			edge [pre] (book4);
		\node[place] (author5) [below=of book5] {}
			edge [pre] (book5);
		\node[place] (title5) [below=of author5] {}
			edge [pre] (author5);
		\node[place] (isbn5) [below=of title5] {}
			edge [pre] (title5);
	\end{tikzpicture}
	\caption{Binary tree representation of the XML 
            document tree from Fig.~\ref{fig:XmlDocumentTree}.\label{fig:binaryRepresentation}}
\end{figure}
Note that a node representing a leaf (resp.~a last sibling) of the XML
document has no left (resp.~no right) child in the binary tree model
representation. Therefore  does not consist of the
element types of the XML document but of special versions of the
element types indicating that the left, the right, both or no children
are missing. In Fig.~\ref{fig:binaryRepresentation} this is denoted by
superscripts at the end of the element types. These superscripts are
listed in Table \ref{tab:superscriptsAndTheirMeanings} 
together with their meanings.
\begin{table}[h]
	\centering
\begin{tabular*}{3.6cm}{c@{\extracolsep{\fill}}l}
		\toprule
		Superscript&Meaning\\
		\midrule
		00&no children\\
		10&no right child\\
		01&no left child\\
		11&two children\\
		\bottomrule
	\end{tabular*}
	\caption{The superscripts and their meanings.}\label{tab:superscriptsAndTheirMeanings}
\end{table}
Let us point out that another way of preserving the rankedness along
with circumventing the introduction of special labels with a lower
rank is the introduction of placeholder nodes. These can be used to
indicate missing left or right children. However, our experiments
showed that our implementation of Re-pair for Trees achieves slightly
less competitive 
compression results in this setting.

In \cite{Busatto08efficient} it was stated that the binary tree model
allows access to the next-in-preorder and previous-in-preorder node in
, where  refers to the longest path
from the root of the XML document to one of its leaves. Furthermore,
in \cite{Milo03typechecking} it was demonstrated that XML query
languages can be readily evaluated on the binary tree model.


\section{Re-Pair for Trees}\label{ch:repairAlgorithm}

In this section we study the Re-pair for Trees algorithm in detail.
It consists of two steps, namely, a \emph{replacement step} and a \emph{pruning step}. Furthermore, a detailed example of a run of our algorithm is presented. Finally, we investigate the impact of a possible restriction on the maximal rank allowed for nonterminals.

\subsection{Digrams}

In order to be able to elaborate on our Re-pair for Trees algorithm we need the following definitions. Recall that we have fixed a ranked alphabet  of function symbols, a set  of nonterminals and a set  of parameters. We define the set of triples

A \emph{\tp} is a triple . The symbol  is called the \emph{parent symbol of the \tp } and  is called the \emph{child symbol of the \tp }, respectively. We define

where  and . Let . We further define the set

Obviously, it holds that .
We can consider  as the tree pattern which is represented by the \tp . We usually denote \tps by possibly indexed lowercase letters  of the Greek alphabet.
An \emph{occurrence} of the \tp  within the tree 
 is a node  at which a subtree
	
with , is rooted. 
The \emph{set of all occurrences of the \tp  in } is denoted by 
.

Let  and . 
Two occurrences  are \emph{overlapping} 
if one of the following equations holds: ,  or .  
Otherwise, \ie, if  and  
are not overlapping,  and  are said to be \emph{non-overlapping}.
A subset  is said to be overlapping 
if there exist overlapping , otherwise it is called
\emph{non-overlapping}.
It is easy to see that the set  is non-overlapping if . 
In contrast, if we have , the set  potentially 
contains overlapping occurrences. Consider the following example:
\begin{example}
Let  be the tree depicted in Fig.~\ref{fig:treeOfOverlappingOccs} and let . Hence, , where on the one hand  and  and on the other hand  and  are overlapping occurrences of .
\end{example}
\begin{figure}[t]
	\centering
		\begin{tikzpicture}[->,>=stealth',semithick,level distance=0.8cm, sibling distance=1.5cm]
			\tikzstyle{fan}=[anchor=north,isosceles triangle, shape border uses incircle,inner sep=0.5pt,shape border rotate=90,draw]
			
			\node {} [child anchor=north] child {node [fan] {}}
				child {node [below=2pt] {}
					child {node [fan] {}}
					child {node [below=5pt] {}
						child {node [fan] {}}
						child {node [below=2pt] {}
							child {node [fan] {}}
							child {node [fan] {}}
						}
					}
				}
			;
		\end{tikzpicture}
	\caption{Tree  consisting of nodes labeled by the terminal  and the subtrees . We have to deal with overlapping occurrences of the \tp .}\label{fig:treeOfOverlappingOccs}
\end{figure}
Let  and . Let  be a non-overlapping set. Furthermore, let us assume that  is overlapping for all , \ie,  is maximal with respect to inclusion among non-overlapping subsets. Then  is not necessarily maximal with respect to cardinality.
\begin{example}\label{ex:maximality}
	Consider the tree  which is depicted in Fig.~\ref{fig:treeOfOverlappingOccs}. Let . We have . Let . The set  is non-overlapping and  is overlapping for all . However,  is not maximal with respect to cardinality. Consider the non-overlapping subset . We have .
\end{example}
Example \ref{ex:maximality} shows us that we cannot choose an arbitrary subset  which is non-overlapping and maximal with respect to inclusion to obtain a set which is maximal with respect to cardinality. 
Let us also point out that the set  may contain more than one maximal (with respect to cardinality) non-overlapping subset. 
\begin{example}
Consider the tree  over the ranked alphabet . The sets  and  are both maximal with respect to cardinality.
\end{example}
\begin{figure}[tb]
\lstset{emph={FUNCTION,ENDFUNC,while,endwhile,true,for,if,else,then,do,endif,endfor,return}, emphstyle=\bfseries,morecomment=[l]{//},commentstyle=\color{gray}}
\begin{lstlisting}
FUNCTION next-in-postorder((*@@*)) // let (*@\color{gray}@*)
	if ((*@@*)) then
		(*@@*)walk-down((*@@*), (*@@*));
	else	
		(*@@*);
		(*@@*);
		
		if ((*@@*)) then
			(*@@*);
			(*@@*)walk-down((*@@*), (*@@*));	
		endif
	endif
	return (*@@*);
ENDFUNC

FUNCTION walk-down((*@@*), (*@@*)) // let (*@@*)
	while (true) do
		if ((*@@*)) then
			(*@@*);
		else
			return (*@@*);
		endif
	endwhile
ENDFUNC
\end{lstlisting}
	\caption{The algorithm which is used to traverse a tree in postorder.}\label{lst:traversalAlgorithm}
\end{figure}
\begin{figure}[tb]
	\lstset{emph={FUNCTION,ENDFUNC,return,for,if,then,do,endif,endfor,while,endwhile}, emphstyle=\bfseries,morecomment=[l]{//},commentstyle=\color{gray}}
	\begin{lstlisting}
FUNCTION retrieve-occurrences((*@@*)) // let (*@\color{gray}@*)
	(*@@*); (*@@*);
	while (true) do
		(*@@*)next-in-postorder((*@@*), (*@@*));
		if ((*@@*)) then
			(*@@*)
		endif
		if ((*@@*)) then
			return (*@@*);
		endif
	endwhile
ENDFUNC
	\end{lstlisting}
	\caption{The function \texttt{retrieve-occurrences} which is used to construct the set  for a \tp  and a tree .}\label{lst:functionRetrieveOccurrences}
\end{figure}
The algorithm \texttt{retrieve-occurrences()}
from Fig.~\ref{lst:functionRetrieveOccurrences} computes one non-over\-lapping subset of  which we denote by . Lemma \ref{lemma:occtIsMaximal} ascertains that this subset is maximal with respect to cardinality.
Using the function \verb|next-in-postorder| listed in Fig.~\ref{lst:traversalAlgorithm} we traverse the tree  in postorder. We begin by passing the parameters  and  and obtain the first node  of  in postorder. The second node in post order is obtained by passing the parameters  and . This step can be repeated to traverse the whole tree  in postorder.
For every node  which is encountered during the postorder traversal it is checked if  is an occurrence of  and if it is non-overlapping with all occurrences already contained in the current set . If both conditions are fulfilled, the node  is added to . 

Now, let us assume that we have constructed the set  using the function \texttt{retrieve-occurrences}. If  in  we have 
. In the following, we show that the subset  is maximal with respect to cardinality.
\begin{lemma}\label{lemma:occtIsMaximal}
	Let  and . Let  be non-overlapping and maximal with respect to cardinality. Then the equation  holds.
\end{lemma}
\begin{proof}
	In the following we briefly write "maximal" for "maximal with
        respect to cardinality". Let ,  and  as
        above. The graph  with

is a disjoint union of paths. Maximal non-overlapping subsets of  exactly correspond to maximum matchings in . Clearly, a path with an odd number of edges has a unique maximum matching, whereas a path with an even number of edges has two maximum matchings: one containing the first edge (in direction from the root) and one containing the last edge on the path. Intuitively, the algorithm from Fig.~\ref{lst:functionRetrieveOccurrences} finds the maximum matching in  which contains for every path with an even number of edges the last edge in direction from the root.
\qed
\end{proof}
Let ,  and . By  we denote the tree which is obtained by replacing all occurrences from  in the tree  by the nonterminal  (in parallel). More precisely, we replace every subtree

where , which is rooted at an occurrence  by a new subtree .
\begin{example}
Consider the tree  which is depicted in Fig.~\subref{fig:replacementProcessBefore}. We have ,	where . By replacing the \tp  in  by a nonterminal  we obtain the tree  which is depicted in Fig.~\subref{fig:replacementProcessAfter}.
\end{example}
\begin{figure}[tb]
	\begin{center}
	\subfigure[The tree .]{
		\parbox{6.3cm}{
		\beginpgfgraphicnamed{figReplacementProcessBefore}
		\begin{tikzpicture}[->,>=stealth']
			\tikzstyle{level 1}=[level distance=0.8cm, sibling distance=3.2cm]
			\tikzstyle{level 2}=[level distance=0.8cm, sibling distance=1.6cm]
			\tikzstyle{level 3}=[level distance=0.8cm, sibling distance=0.8cm]
			\tikzstyle{level 4}=[level distance=0.8cm, sibling distance=0.4cm]
			\node {}
				child {node {}
					child {node {}
						child {node {}
							child {node {}}
							child {node {}}
						}
						child {node {}
							child {node {}}
							child {node {}}
						}
					}
					child {node {}
						child {node {}
							child {node {}}
							child {node {}}
						}
						child {node {}
							child {node {}}
							child {node {}}
						}
					}
				}
				child {node {}
					child {node {}
						child {node {}
							child {node {}}
							child {node {}}
						}
						child {node {}
							child {node {}}
							child {node {}}
						}
					}
					child {node {}
						child {node {}
							child {node {}}
							child {node {}}
						}
						child {node {}
							child {node {}}
							child {node {}}
						}
					}
				}
			;
		\end{tikzpicture}
		\endpgfgraphicnamed
		}
		\label{fig:replacementProcessBefore}
	}
	\hspace{1cm}
	\subfigure[{The tree .}]{
		\parbox{6.3cm}{
		\beginpgfgraphicnamed{figReplacementProcessAfter}
		\begin{tikzpicture}[->,>=stealth']
			\tikzstyle{level 1}=[level distance=0.8cm, sibling distance=3.2cm]
			\tikzstyle{level 2}=[level distance=0.8cm, sibling distance=1.6cm]
			\tikzstyle{level 3}=[level distance=0.8cm, sibling distance=0.8cm]
			\tikzstyle{level 4}=[level distance=0.8cm, sibling distance=0.4cm]
			\node {}
				child[sibling distance=2.7cm] {node {}
					child {node {}
						child[sibling distance=0.4cm] {node {}
							child {node {}}
							child {node {}}
						}
						child {node {}}
						child[sibling distance=0.4cm] {node {}}
					}
					child {node {}
						child[sibling distance=0.4cm] {node {}
							child {node {}}
							child {node {}}
						}
						child {node {}}
						child[sibling distance=0.4cm] {node {}}
					}
				}
				child {node {}
					child[sibling distance=0.4cm] {node {}
						child[sibling distance=0.4cm] {node {}}
						child[sibling distance=0.4cm] {node {}}
					}
					child {node {}}
					child[sibling distance=0.4cm] {node {}}
				}
				child[sibling distance=1.6cm] {node {}
					child[sibling distance=0.4cm] {node {}
						child[sibling distance=0.4cm] {node {}}
						child[sibling distance=0.4cm] {node {}}
					}
					child {node {}}
					child[sibling distance=0.4cm] {node {}}
				}
			;
		\end{tikzpicture}
		\endpgfgraphicnamed
		}
		\label{fig:replacementProcessAfter}
	}
	\end{center}
	\stepcounter{figure}
\end{figure}
For  and , we define

The function  associates with every tree  a \tp  which occurs in  most frequently (with respect to all \tps from ). If there are multiple most frequent \tps, we can choose any of them. In contrast, we have  if there is no most frequent \tp. If  there is no most frequent pair if and only if the tree  consists of exactly one node. Now let us assume that . We have  if and only if  consists of exactly one node or if for all \tps  occurring in  it holds that . 

In the sequel, if we do not specify the maximal rank allowed for a nonterminal, we always assume that . For convenience we write  instead of , \ie, we omit the symbol .

\subsection{Replacement of \ltps}\label{sec:replacementStep}

In this section we introduce the first step of our Re-pair for Trees algorithm, namely, the \emph{replacement step}. Let  be the maximal rank allowed for a nonterminal\footnote{Regarding our implementation of the Re-pair for Trees algorithm which is described in Sect.~\ref{ch:implementationDetails},  is a parameter which can be specified by the user.} and let the tree  be the input of our algorithm.

We describe a run of the Re-pair for Trees algorithm by a sequence of  linear SLCF tree grammars
, where . For every  we have , ,  and . 
The grammar  contains solely the start production , where . We obtain the grammar  by replacing the \tp  in the right-hand side of 's start production  by a new nonterminal  (). We set

where .

The computation stops if there is no \tp  occurring at least twice in the start production of the current grammar, \ie, either the equation  or the equation  holds. In contrast, for all  we have .

Note that the linear SLCF tree grammar  is almost in Chomsky normal form (CNF) as it is defined in \cite{Lohrey09parameterreduction}. By appropriately transforming the right-hand side of  (as it is described in the proof of Proposition 5 of \cite{Lohrey09parameterreduction}) and introducing a production with right-hand side  for every terminal  () we would obtain a linear SLCF tree grammar which perfectly meets the requirements of the CNF.

The linear SLCF tree grammar  can only be considered an intermediate result, since it potentially consists of productions which do not contribute to a compact representation of the input tree . Therefore, we get rid of unprofitable productions by eliminating them during the so-called \emph{pruning step}. The latter, which is described in the next section, is executed directly after the replacement step.

\subsection{Pruning the Grammar}\label{sec:pruningStep}

Let  be a linear SLCF tree grammar. We \emph{eliminate} a production  from  as follows: 
	\begin{enumerate}[(1)]
		\item For every reference  we replace the subtree  rooted at  by the tree
			
			where  and . 
		\item We update the set of productions by setting 
			
	\end{enumerate}
Let  be the linear SLCF tree grammar generated in the replacement step of our algorithm, \ie, we have . Let  and let

be a sequence of all nonterminals of  in hierarchical order, \ie, the following conditions hold:
\begin{enumerate}[(i)]
	\item 
	\item 
\end{enumerate}
Let , where  and . If we eliminate  this may have an impact on the value of
 from \eqref{def:savValue}. We need to differentiate between two cases:
\begin{enumerate}[(1)]
	\item B_it_j
	
		If  occurs in , \ie, , then  is increased because of the elimination of . At the same time,  goes up if we have . The increase of  is due to the fact that we can assume that the inequality  holds. Every production which was introduced in the replacement step represents a \tp and therefore consists of at least two nodes labeled by the parent and child symbol, respectively, of this \tp.
	\item B_jt_i
	
		If  occurs in , \ie, , then  and therefore  are possibly increased by eliminating . In fact, both values go up if .
\end{enumerate}

\paragraph*{First phase} In the first phase of the pruning step, we eliminate every production  with . That way we achieve not only a possible reduction of the size of  (because we have  for every  referenced only once) but we also decrement the number of nonterminals  each time we eliminate such a production.

\paragraph*{Second phase} In the second phase of the pruning step we eliminate all remaining inefficient productions. We consider a production  as inefficient if . 
Unfortunately, this time we have to deal with a rather complex optimization problem. In contrast to the first phase, the decision whether to eliminate a production  or not does now depend on the value . However, the latter may be increased by eliminating other nonterminals (see the above case distinction). This forces us to use a heuristic to decide what productions to remove next from the grammar. In fact, after completing the first phase, we cycle through the remaining productions in their reverse hierarchical order. For every  we check if . If this proves to be true, we eliminate . That way  and  are possibly further reduced.

The following example shows that the size of the final grammar generated by the Re-pair for Trees algorithm may depend on the order in which possible inefficient productions are eliminated.
\begin{example}\label{ex:differentOrdersPruningStep}
	Consider the linear SLCF tree grammar , where  and  is the following set of productions:
	
	Let us assume that the grammar  was generated by the replacement step of our algorithm and that we now want to remove all inefficient productions. We have  and , \ie, the productions with left-hand sides  and  do not contribute to a small representation of the input tree . Let us consider the following two cases:
	\begin{enumerate}[(1)]
		\item If we eliminate the production with left-hand side , we obtain the grammar , where  and  is the following set of productions:
			
			We have  and , \ie, the production with left-hand side  is not considered inefficient.
		\item In contrast, the elimination of the production with left-hand side  yields the linear SLCF tree grammar , where  and  is the following set of productions:
			
			We also eliminate the production with left-hand side  since we have . This leads to an updated grammar , where  and  contains solely the production
			
			We have .
	\end{enumerate}
	This case distinction shows that the order in which inefficient productions are eliminated has an influence on the size of the final grammar (since ). Let us consider the sequence  which is the only way to enumerate the nonterminals from  in hierarchical order. Due the fact that the above described heuristic cycles through the productions in their reverse hierarchical order to eliminate inefficient productions we would obtain the larger grammar  if we would execute the pruning step with  as the input grammar.
\end{example}
Given the above example one might expect better compression results if the inefficient productions are eliminated in the order of their -values, \ie, if we would proceed as follows: as long as their is a production whose left-hand side has a -value smaller or equal to  we remove a production whose left-hand side has the smallest occurring -value. However, our investigations showed that this approach leads to unappealing final grammars --- at least for our set of test input trees. The grammars generated by this approach exhibit nearly the same number of edges but much more nonterminals (about 50\% more) compared to the grammars obtained using the above heuristic.

\bigskip

\noindent Note that it is not possible to already detect \tps leading to inefficient productions during the replacement step. For instance, we would not act wisely if we would ignore \tps occurring only twice and exhibiting a large number of parameters a priori.
\begin{example}
	Imagine an input tree  comprising two instances of a large tree pattern . Let  for all , . Furthermore, let us assume that all symbols in the tree pattern  are not occurring outside of this pattern. For every \tp  occurring in the tree pattern  (whose replacement may firstly lead to a production with a large number of parameters) we would have . It becomes clear that this great redundancy in the input tree , which can be represented by a production with right-hand side , would not be detected if we would not carry out these initially anything but efficient seeming \tp replacements.
\end{example}

\subsection{Complete Example}

Let the tree depicted in Fig.~\ref{fig:binaryRepresentation} be our input tree  and let there be no restrictions on the maximal rank allowed for a nonterminal. We set , where  and  solely contains the production . Table \subref{tab:pairs0iteration} shows every \tp  encountered in  along with its number of non-overlapping occurrences . Furthermore, this table tells us that the two \tps  and  are the most frequent \tps occuring in . We decide to replace the former \tp and therefore have .

\begin{table}[t]
\centering
\parbox{14.5cm}{
		\footnotesize
		\subtable[All \tps encountered in the input tree  and their number of non-overlapping occurrences.]{
			\begin{tabular}{p{2.1cm}c}
				\toprule
				\tp &\\
				\midrule
				&\\
				&\\
				&\\
				&\\
				&\\
				&\\
				&\\
				\bottomrule
			\end{tabular}
			\label{tab:pairs0iteration}
		}
		\hfill
		\subtable[All \tps encountered in the tree  and their number of non-overlapping occurrences.]{
			\begin{tabular}{p{2.1cm}c}
				\toprule
				\tp &\\
				\midrule
				&\\
				&\\
				&\\
				&\\
				&\\
				&\\
				&\\
				\bottomrule
			\end{tabular}
			\label{tab:pairs1iteration}
		}
		\hfill
		\subtable[All \tps encountered in the tree  and their number of non-overlapping occurrences.]{
			\begin{tabular}{p{2.1cm}c}
				\toprule
				\tp &\\
				\midrule
				&\\
				&\\
				&\\
				&\\
				&\\
				&\\
				&\\
				\bottomrule
			\end{tabular}
			\label{tab:pairs2iteration}
		}
	}
	\stepcounter{table}
\end{table}

\begin{figure}[t]
	\centering
	\begin{tikzpicture}
		[bend angle=25, node distance=0.25cm, text height=1.5ex,
		place/.style={},
		pre/.style={<-,>=stealth'},
		post/.style={->,>=stealth'}]
		\node[place] (books) {};
		
		\node[place] (book1) [below=of books] {}
			edge [pre] (books);
		\node[place] (author1) [below=of book1] {}
			edge [pre] (book1);
		\node[place] (A1) [below=of author1] {}
			edge [pre] (author1);
	
		\node[place] (book2) [right=of book1] {}
			edge [pre] (book1);

		\node[place] (book4) [right=of book2] {}
			edge [pre] (book2);
		\node[place] (author4) [below=of book4] {}
			edge [pre] (book4);
		\node[place] (A4) [below=of author4] {}
			edge [pre] (author4);
			
		\draw[decorate,decoration={brace,mirror}] ([xshift=-5pt]A1.south) -- ([xshift=5pt]A4.south) node[midway,sloped,below=2pt] { times};

		\node[place] (book5) [right=of book4] {}
			edge [pre] (book4);
		\node[place] (author5) [below=of book5] {}
			edge [pre] (book5);
		\node[place] (A5) [below=of author5] {}
			edge [pre] (author5);
	\end{tikzpicture}
	\caption{Tree  which evolved from the input tree  in the first iteration of our computation.}\label{fig:treeAfterFirstRepl}
\end{figure}
Now, in the first iteration of our computation, we generate a new linear SLCF tree grammar  as follows. We introduce a new nonterminal  and set . After that, we introduce the new production , where . Finally, we set , where we have . The tree  is depicted in Fig.~\ref{fig:treeAfterFirstRepl}.

In the second iteration, during which we generate the grammar , we have  as it can be seen in Table \subref{tab:pairs1iteration}. Again, we introduce a new nonterminal  with right-hand side , set  and set , where  (see Fig.~\ref{fig:treeAfterSecondRepl}).
\begin{figure}[t]
	\centering
	\begin{tikzpicture}
		[bend angle=25, node distance=0.25cm, text height=1.5ex,
		place/.style={},
		pre/.style={<-,>=stealth'},
		post/.style={->,>=stealth'}]
		\node[place] (books) {};
		
		\node[place] (book1) [below=of books] {}
			edge [pre] (books);
		\node[place] (B1) [below=of book1] {}
			edge [pre] (book1);
				
		\node[place] (book2) [right=of book1] {}
			edge [pre] (book1);
				
		\node[place] (book4) [right=of book2] {}
			edge [pre] (book2);
		\node[place] (B4) [below=of book4] {}
			edge [pre] (book4);
			
		\draw[decorate,decoration={brace,mirror}] ([xshift=-5pt]B1.south) -- ([xshift=5pt]B4.south) node[midway,sloped,below=2pt] { times};
		
		\node[place] (book5) [right=of book4] {}
			edge [pre] (book4);
		\node[place] (B5) [below=of book5] {}
			edge [pre] (book5);
	\end{tikzpicture}
	\caption{Tree  which evolved from the tree  in the second iteration of our computation.}\label{fig:treeAfterSecondRepl}
\end{figure}
We have  (\cf Table \subref{tab:pairs2iteration}) in the third iteration of our algorithm. This time, we need to introduce a new nonterminal , \ie, a nonterminal with one parameter, with right-hand side . We obtain the grammar , where

by replacing the  occurrences of .

In the fourth and last iteration the \tp  is replaced by a new nonterminal . Therefore, we obtain the grammar  with  edges and  nonterminals, where we have  and  is the following set of productions:

Finally, in the pruning step, we begin with merging the right-hand
side of  with the right-hand side of  since
, \ie, it is only referenced
once. This yields the updated production
. Furthermore,
we roll back the replacement of the \tp  due to the
fact that it does not contribute to the reduction of the total number
of edges. Although the production with left-hand side  is
referenced twice in the right-hand sides of  and
removes redundancy this gain is neutralized by the necessary edge to
the parameter node. This is indicated by the
 value of , see \eqref{def:savValue}:

With these adjustments we obtain the linear SLCF tree grammar \label{exampleGrammar}, where  and  is the following set of productions:

Compared to the grammar  it has the same number of edges (namely 10) but nearly half as much nonterminals only.

\subsection{Another Example}

It is very unlikely to be confronted with an XML document tree which, in the binary tree model, is represented by a perfect binary tree\footnote{A \emph{perfect binary tree} is a binary tree in which every node is either of rank  or  and all leaves are at the same level (\ie, the paths to the root are of the same length). In contrast, a \emph{full binary tree} has no restrictions on the level of the leaves, \ie, the only requirement is that every node is either of rank  or .}. Nevertheless we want to investigate the compression performance of our algorithm on this kind of trees since it is an interesting aspect from a theoretical point of view. Last but not least our undertaking is justified by the fact that the actual Re-pair for Trees algorithm is not restricted to applications processing XML files but can be used in other applications as well. The latter, in turn, may exhibit ranked trees similar to full binary trees.

Let  be a sufficiently large perfect binary tree of which each inner node is labeled by a terminal  and each leaf is labeled by a terminal . A run of Re-pair for Trees on  consists of  iterations folding the input tree beginning at its leaves, where . Thus, in the first two iterations, the \tps formed by the leaf nodes and their parents are replaced. We obtain the productions  and  each occurring  times. Now, we undertake further \tp replacements in a bottom up fashion. 
In the -th and -th iteration we replace two \tps resulting in the productions  and , respectively, where . 

The production with left-hand side  occurs only once for every . Therefore, in the pruning step, for every  the production with left-hand side  is eliminated by merging its right-hand side with the right-hand side of the production with left-hand side . In particular, the production with left-hand side  is merged with the production for  resulting in a production .

Finally, we obtain a linear SLCF tree grammar with  nonterminals --- including the left-hand side of the start production  --- and a total of  edges. Note that even though some of the intermediate productions exhibit parameters the final grammar consists only of nonterminals of rank . Thus, the generated grammar is a DAG and in this particular case the minimal DAG of the input tree.
\begin{figure}[tb]
	\small
	\centering
\parbox{14.5cm}{
		\subfigure[Perfect binary tree  of height 4]{
			\parbox[t]{6cm}{
			\beginpgfgraphicnamed{figPerfectBinaryTree}
			\begin{tikzpicture}[->,>=stealth']
				\tikzstyle{level 1}=[level distance=0.8cm, sibling distance=3.2cm]
				\tikzstyle{level 2}=[level distance=0.8cm, sibling distance=1.6cm]
				\tikzstyle{level 3}=[level distance=0.8cm, sibling distance=0.8cm]
				\tikzstyle{level 4}=[level distance=0.8cm, sibling distance=0.4cm]
				\node {}
					child {node {}
						child {node {}
							child {node {}
								child {node {}}
								child {node {}}
							}
							child {node {}
								child {node {}}
								child {node {}}
							}
						}
						child {node {}
							child {node {}
								child {node {}}
								child {node {}}
							}
							child {node {}
								child {node {}}
								child {node {}}
							}
						}
					}
					child {node {}
						child {node {}
							child {node {}
								child {node {}}
								child {node {}}
							}
							child {node {}
								child {node {}}
								child {node {}}
							}
						}
						child {node {}
							child {node {}
								child {node {}}
								child {node {}}
							}
							child {node {}
								child {node {}}
								child {node {}}
							}
						}
					}
				;
			\end{tikzpicture}
			\endpgfgraphicnamed
			}
			\label{fig:perfectBinaryTree}
		}
		\hfill
		\subfigure[Productions before the pruning step without the start production.]{
			\parbox[b]{3.3cm}{}
			\label{fig:prodPerfectBinaryTree}
		}
		\hfill
		\subfigure[Productions after the pruning step.]{
			\parbox[b]{3.3cm}{}
			\label{fig:prodPerfectBinaryTreeAfterPruning}
		}
	}
	\stepcounter{figure}
\end{figure}
\begin{example}
	Let  be the perfect binary tree from Fig.~\subref{fig:perfectBinaryTree} with 30 edges and . A run of Re-pair for Trees initially generates the 6 productions listed in Fig.~\subref{fig:prodPerfectBinaryTree}. After the pruning step we finally obtain the linear SLCF tree grammar , where  and the set of productions  consists of the productions from Fig.~\subref{fig:prodPerfectBinaryTreeAfterPruning}. The size of  is .
\end{example}

\subsection{Unlimited Maximal Rank}\label{sec:observations}

It seems natural to assume that, in general, trees can be compressed best by the Re-pair for Trees algorithm if there are no restrictions on the maximal rank of a nonterminal. However, it turns out that there are (not so uncommon) types of trees for which the opposite is true. Firstly, in this section, we will construct a set of trees whose compressibility is best if there are no restrictions on the maximal rank of a nonterminal. After that, in the succeeding section, we will present a set of trees whose compressibility is best when restricting the maximal rank to .

Let us consider the infinite set  of trees, where for all  the tree  has the following properties:
\begin{itemize}
	\item The tree  is a perfect binary tree of depth .
	\item Each inner node of  is labeled by the terminal .
	\item Each leaf of  is labeled by a unique terminal from , \ie, there do not exist two different leaves which are labeled by the same symbol.
\end{itemize}

\begin{figure}[p]
      \centering
	\newcommand{\ldistance}{7}
	\newcommand{\innersize}{0.6}
	\newcommand{\colorOne}{green!50!black}
	\newcommand{\colorTwo}{blue!50!black}
	\newcommand{\colorThree}{red!50!black}
	\subfigure[The tree .]{
		\begin{tikzpicture}
			[level distance=\ldistance mm,
			inner/.style={fill=black,draw=black,circle,inner sep=\innersize pt},
			leaf/.style={fill=white,draw=black,circle,inner sep=0.5pt},
			level 1/.style={sibling distance=76.8mm,level distance=5mm},
			level 2/.style={sibling distance=38.4mm,level distance=5mm},
			level 3/.style={sibling distance=19.2mm,level distance=5mm},
			level 4/.style={sibling distance=9.6mm},
			level 5/.style={sibling distance=4.8mm},
			level 6/.style={sibling distance=2.4mm},
			level 7/.style={sibling distance=1.2mm},
			level 8/.style={sibling distance=0.6mm}
			]
			
			\node[inner,\colorOne] {}
				child foreach \i/\color in {1/black,2/\colorOne} {node[inner,draw=\color,fill=\color] (\i) {} edge from parent[draw=\color]
					child foreach \ii/\color in {1/black,2/black} {node[inner,draw=\colorOne,fill=\colorOne] {} edge from parent[draw=\color]
						child foreach \iii/\color in {1/black,2/\colorOne} {node[inner,draw=\color,fill=\color] {} edge from parent[draw=\color]
							child foreach \iiii/\color in {1/black,2/black} {node[inner,draw=\colorOne,fill=\colorOne] {} edge from parent[draw=\color]
								child foreach \iiiii/\color in {1/black,2/\colorOne} {node[inner,draw=\color,fill=\color] {} edge from parent[draw=\color]
									child foreach \iiiii/\color in {1/black,2/black} {node[inner,draw=\colorOne,fill=\colorOne] {} edge from parent[draw=\color]
										child foreach \iiiii/\color in {1/black,2/\colorOne} {node[inner,draw=\color,fill=\color] {} edge from parent[draw=\color]
											child foreach \iiiiii/\color in {1/black,2/black} {node[leaf] {}  edge from parent[draw=\color]}
										}
									}
								}
							}
						}
					}
				}
			;
		\end{tikzpicture}
		\label{fig:unlimitedRank1}
	}
		
	\vspace{0.5cm}
	
	\subfigure[The tree  after replacing the \tp .]{
		\begin{tikzpicture}
			[level distance=\ldistance mm,
			inner/.style={fill=\colorOne,draw=\colorOne,circle,inner sep=\innersize pt},
			A/.style={inner}, leaf/.style={fill=white,draw=black,circle,inner sep=0.5pt},
			level 1/.style={sibling distance=76.8mm,level distance=5mm},
			level 2/.style={sibling distance=38.4mm,level distance=5mm},
			level 3/.style={sibling distance=19.2mm,level distance=5mm},
			level 4/.style={sibling distance=9.6mm},
			level 5/.style={sibling distance=4.8mm},
			level 6/.style={sibling distance=2.4mm},
			level 7/.style={sibling distance=1.2mm},
			level 8/.style={sibling distance=0.6mm}
			]
			
			\node[A] {}
				child[sibling distance=63mm] {node[inner] {} edge from parent[draw=\colorOne]
					child[sibling distance=38mm] foreach \j in {1,2} {node[A] {} edge from parent[draw=black]
						child[sibling distance=14.4mm] {node[inner] {} edge from parent[draw=\colorOne]
							child[sibling distance=9mm] foreach \ii in {1,2} {node[A] {} edge from parent[draw=black]
								child[sibling distance=3.6mm] {node[inner] {} edge from parent[draw=\colorOne]
									child[sibling distance=1.8mm] foreach \iiii in {1,2} {node[A] {} edge from parent[draw=black]
										child[sibling distance=0.6mm] {node[inner] {} edge from parent[draw=\colorOne]
											child foreach \iiiiii in {1,2} {node[leaf] {} edge from parent[draw=black]}
										}
										child[sibling distance=0.6mm] foreach \iiiiii in {1,2} {node[leaf] {} edge from parent[draw=black]}
									}
								}
								child[sibling distance=1.8mm] foreach \iiii in {1,2} {node[A] {} edge from parent[draw=black]
									child[sibling distance=0.6mm] {node[inner] {} edge from parent[draw=\colorOne]
										child[sibling distance=0.6mm] foreach \iiiiii in {1,2} {node[leaf] {} edge from parent[draw=black]}
									}
									child[sibling distance=0.6mm] foreach \iiiiii in {1,2} {node[leaf] {} edge from parent[draw=black]}
								}
							}
						}
						child[sibling distance=9mm] foreach \ii in {1,2} {node[A] {} edge from parent[draw=black]
							child[sibling distance=3.6mm] {node[inner] {} edge from parent[draw=\colorOne]
								child[sibling distance=1.8mm] foreach \iiii in {1,2} {node[A] {} edge from parent[draw=black]
									child[sibling distance=0.6mm] {node[inner] {} edge from parent[draw=\colorOne]
										child[sibling distance=0.6mm] foreach \iiiiii in {1,2} {node[leaf] {} edge from parent[draw=black]}
									}
									child[sibling distance=0.6mm] foreach \iiiiii in {1,2} {node[leaf] {} edge from parent[draw=black]}
								}
							}
							child[sibling distance=1.8mm] foreach \iiii in {1,2} {node[A] {} edge from parent[draw=black]
								child[sibling distance=0.6mm] {node[inner] {} edge from parent[draw=\colorOne]
									child[sibling distance=0.6mm] foreach \iiiiii in {1,2} {node[leaf] {} edge from parent[draw=black]}
								}
								child[sibling distance=0.6mm] foreach \iiiiii in {1,2} {node[leaf] {} edge from parent[draw=black]}
							}
						}
					}
				}
				child[sibling distance=38mm] foreach \jj in {1,2} {node[A] {} edge from parent[draw=black]
					child[sibling distance=14.4mm] {node[inner] {} edge from parent[draw=\colorOne]
						child[sibling distance=9mm] foreach \ii in {1,2} {node[A] {} edge from parent[draw=black]
							child[sibling distance=3.6mm] {node[inner] {} edge from parent[draw=\colorOne]
								child[sibling distance=1.8mm] foreach \iiii in {1,2} {node[A] {} edge from parent[draw=black]
									child[sibling distance=0.6mm] {node[inner] {} edge from parent[draw=\colorOne]
										child[sibling distance=0.6mm] foreach \iiiiii in {1,2} {node[leaf] {} edge from parent[draw=black]}
									}
									child[sibling distance=0.6mm] foreach \iiiiii in {1,2} {node[leaf] {} edge from parent[draw=black]}
								}
							}
							child[sibling distance=1.8mm] foreach \iiii in {1,2} {node[A] {} edge from parent[draw=black]
								child[sibling distance=0.6mm] {node[inner] {} edge from parent[draw=\colorOne]
									child[sibling distance=0.6mm] foreach \iiiiii in {1,2} {node[leaf] {} edge from parent[draw=black]}
								}
								child[sibling distance=0.6mm] foreach \iiiiii in {1,2} {node[leaf] {} edge from parent[draw=black]}
							}
						}
					}
					child[sibling distance=9mm] foreach \ii in {1,2} {node[A] {} edge from parent[draw=black]
						child[sibling distance=3.6mm] {node[inner] {} edge from parent[draw=\colorOne]
							child[sibling distance=1.8mm] foreach \iiii in {1,2} {node[A] {} edge from parent[draw=black]
								child[sibling distance=0.6mm] {node[inner] {} edge from parent[draw=\colorOne]
									child[sibling distance=0.6mm] foreach \iiiiii in {1,2} {node[leaf] {} edge from parent[draw=black]}
								}
								child[sibling distance=0.6mm] foreach \iiiiii in {1,2} {node[leaf] {} edge from parent[draw=black]}
							}
						}
						child[sibling distance=1.8mm] foreach \iiii in {1,2} {node[A] {} edge from parent[draw=black]
							child[sibling distance=0.6mm] {node[inner] {} edge from parent[draw=\colorOne]
								child[sibling distance=0.6mm] foreach \iiiii in {1,2} {node[leaf] {} edge from parent[draw=black]}
							}
							child[sibling distance=0.6mm] foreach \iiiiii in {1,2} {node[leaf] {} edge from parent[draw=black] }
						}
					}
				}
			;
		\end{tikzpicture}
		\label{fig:unlimitedRank2}
	}
		
	\vspace{0.5cm}
	
	\subfigure[The tree  after the second iteration, \ie, after replacing the \tps  and .]{
		\begin{tikzpicture}
			[level distance=\ldistance mm,
			inner/.style={fill=black,draw=black,circle,inner sep=\innersize pt},
			A/.style={inner}, B/.style={inner}, leaf/.style={fill=white,draw=black,circle,inner sep=0.5pt},
			level 1/.style={sibling distance=76.8mm,level distance=5mm},
			level 2/.style={sibling distance=38.4mm,level distance=5mm},
			level 3/.style={sibling distance=19.2mm},
			level 4/.style={sibling distance=9.6mm},
			level 5/.style={sibling distance=4.8mm},
			level 6/.style={sibling distance=2.4mm},
			level 7/.style={sibling distance=1.2mm},
			level 8/.style={sibling distance=0.6mm}
			]
			
			\node[B,draw=\colorOne,fill=\colorOne] {}
				child[sibling distance=38.4mm,draw=\colorOne,fill=\colorOne] foreach \ii/\color in {1/black,2/black,3/black,4/\colorOne} {node[B,draw=\color,fill=\color] {} edge from parent[draw=\color]
					child[sibling distance=9.6mm] foreach \iiii in {1,2,3,4} {node[B,draw=\colorOne,fill=\colorOne] {}  edge from parent[draw=black]
						child[sibling distance=2.4mm] foreach \iiiii/\color in {1/black,2/black,3/black,4/\colorOne} {node[B,draw=\color,fill=\color] {} edge from parent[draw=\color]
							child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4} {node[leaf] {}  edge from parent[draw=black]}
						}
					}
				}
			;
		\end{tikzpicture}
		\label{fig:unlimitedRank3}
	}
		
	\vspace{0.5cm}
	
	\subfigure[The tree which remains after replacing the \tp  in the tree from Fig.~\subref{fig:unlimitedRank3}.]{
		\begin{tikzpicture}
			[level distance=\ldistance mm,
			inner/.style={fill=black,draw=black,circle,inner sep=\innersize pt},
			A/.style={inner},
			B/.style={inner},
			leaf/.style={fill=white,draw=black,circle,inner sep=0.5pt}
			]
			
			\node[B,draw=\colorOne,fill=\colorOne] {}
				child[sibling distance=35mm] {node[B] {}
					child[sibling distance=9.6mm] foreach \iiii in {1,2,3,4} {node[B,draw=\colorOne,fill=\colorOne] {}
						child[sibling distance=2.4mm] foreach \iiiii/\color in {1/black,2/black,3/\colorOne} {node[B,draw=\color,fill=\color] {} edge from parent[draw=\color]
							child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4} {node[leaf] {}  edge from parent[draw=black]}
						}
						child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4} {node[leaf] {} edge from parent[draw=black]}
					}
				}
				child[sibling distance=33mm] {node[B] {}
					child[sibling distance=9.6mm] foreach \iiii in {1,2,3,4} {node[B,draw=\colorOne,fill=\colorOne] {}
						child[sibling distance=2.4mm] foreach \iiiii/\color in {1/black,2/black,3/\colorOne} {node[B,draw=\color,fill=\color] {} edge from parent[draw=\color]
							child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4} {node[leaf] {}  edge from parent[draw=black]}
						}
						child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4} {node[leaf] {} edge from parent[draw=black]}
					}
				}
				child[sibling distance=27mm] {node[B,draw=\colorOne,fill=\colorOne] {} edge from parent[draw=\colorOne]
					child[sibling distance=9.6mm] foreach \iiii in {1,2,3,4} {node[B,draw=\colorOne,fill=\colorOne] {} edge from parent[draw=black]
						child[sibling distance=2.4mm] foreach \iiiii/\color in {1/black,2/black,3/\colorOne} {node[B,draw=\color,fill=\color] {} edge from parent[draw=\color]
							child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4} {node[leaf] {}  edge from parent[draw=black]}
						}
						child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4} {node[leaf] {} edge from parent[draw=black]}
					}
				}
				child[sibling distance=9.6mm] {node[B,draw=\colorOne,fill=\colorOne] {}
					child[sibling distance=2.4mm] foreach \iiiii/\color in {1/black,2/black,3/\colorOne} {node[B,draw=\color,fill=\color] {} edge from parent[draw=\color]
						child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4} {node[leaf] {}  edge from parent[draw=black]}
					}
					child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4} {node[leaf] {} edge from parent[draw=black]}
				}
				child[sibling distance=9.6mm] foreach \iiii in {1,2,3} {node[B,draw=\colorOne,fill=\colorOne] {}
					child[sibling distance=2.4mm] foreach \iiiii/\color in {1/black,2/black,3/\colorOne} {node[B,draw=\color,fill=\color] {} edge from parent[draw=\color]
						child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4} {node[leaf] {}  edge from parent[draw=black]}
					}
					child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4} {node[leaf] {} edge from parent[draw=black]}
				}
			;
		\end{tikzpicture}
		\label{fig:unlimitedRank4}
	}
	
	\vspace{0.5cm}
	
	\subfigure[The tree  after  iterations of our algorithm. We obtained a -ary tree whose inner nodes are labeled by the nonterminal .]{
		\begin{tikzpicture}
			[level distance=\ldistance mm,
			inner/.style={fill=black,draw=black,circle,inner sep=\innersize pt},
			A/.style={inner}, B/.style={inner}, leaf/.style={fill=white,draw=black,circle,inner sep=0.5pt},
			level 1/.style={sibling distance=76.8mm},
			level 2/.style={sibling distance=38.4mm},
			level 3/.style={sibling distance=19.2mm},
			level 4/.style={sibling distance=9.6mm},
			level 5/.style={sibling distance=4.8mm},
			level 6/.style={sibling distance=2.4mm},
			level 7/.style={sibling distance=1.2mm},
			level 8/.style={sibling distance=0.6mm}
			]
			
			\node[B] {}
				child[sibling distance=9.6mm] foreach \ii in {1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16} {node[B] {}
					child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16} {node[leaf] {}}
				}
			;
		\end{tikzpicture}
		\label{fig:unlimitedRank5}
	}
	\stepcounter{figure}
\end{figure}
\begin{example}\label{ex:unlimitedRank1}
	Figure \subref{fig:unlimitedRank1} shows a simplified depiction of the tree . The inner nodes labeled by the symbol  are represented by a circle filled with paint. In contrast, the leaves, of which each is labeled by a unique symbol from , are depicted by a circle which is not filled with paint. 
	
	The tree  is compressed by a run of our algorithm as follows. The \tps  and  occur equally often in . It makes no difference to the size of the final grammar whether we replace the former or the latter. Let us replace the \tp  (whose occurrences are painted in green in Fig.~\subref{fig:unlimitedRank1}) by a nonterminal  with right-hand side . We obtain the tree of the form shown in Fig.~\subref{fig:unlimitedRank2}. After that, the \tp , which occurs the same number of times as  did, is replaced by the nonterminal  with right-hand side . The occurrences of  are marked with green paint in Fig.~\subref{fig:unlimitedRank2}. The right-hand side of the nonterminal  is merged with the right-hand side of  during the pruning step since  is only referenced once. This yields the production with left-hand side  and right-hand side . 
	
	After the replacement of the above two \tps the right-hand side of the start production is a -ary tree of depth  whose inner nodes are labeled by  (see Fig.~\subref{fig:unlimitedRank3}).
	Now, the \tps
	 
	occur equally often. Again, the order of the \tp replacements makes no difference to the final grammar. Assuming that at first we replace the \tp , which is marked with green paint in Fig.~\subref{fig:unlimitedRank3}, by a new nonterminal , we obtain the tree shown in Fig.~\subref{fig:unlimitedRank4}. After that, the \tps ,  and  are replaced in three additional iterations. The above four \tp replacements result in a new production
	
	after pruning the grammar. The remaining tree is a 16-ary tree of depth  (of the form depicted in Fig.~\subref{fig:unlimitedRank5}) whose inner nodes are labeled by the nonterminal . In this tree there is no \tp occurring more than once. Therefore, the execution of our algorithm stops.
\end{example}
\begin{figure}[tb]
	\centering\footnotesize
	\begin{tikzpicture}[semithick]
		\tikzstyle{level 1}=[level distance=1.35cm, sibling distance=3.5cm]
		\tikzstyle{level 2}=[level distance=1.35cm, sibling distance=0.8cm]
		\begin{scope}[->,>=stealth']
			\node {}
				child {node (B1) {}
					child {node {}}
					child {node (y11) {}}
					child[missing] {node {}}
					child {node (y12) {}}
				}
				child {node (B2) {}
					child {node {}}
					child {node (y21) {}}
					child[missing] {node {}}
					child {node (y22) {}}
				}
				child[missing] {node {}}
				child[sibling distance=4cm] {node (Bn) {}
					child[sibling distance=2cm] {node {}}
					child[sibling distance=2cm] {node (y31) {}}
					child[missing] {node {}}
					child[sibling distance=1.2cm] {node (y32) {}}
				}
			;
		\end{scope}
		
		\draw[dotted] ([xshift=1cm]B2.center) -- ([xshift=-1cm]Bn.center);
		\draw[dotted] ([xshift=1cm]y11.center) -- ([xshift=-1cm]y12.center);
		\draw[dotted] ([xshift=1cm]y21.center) -- ([xshift=-1cm]y22.center);
		\draw[dotted] ([xshift=1cm]y31.center) -- ([xshift=-0.5cm]y32.center);
	\end{tikzpicture}
	\caption{Right-hand side  of the nonterminal , where  and .}\label{fig:rhsOfB}
\end{figure}

\bigskip

\noindent Now, we want to analyze the behavior of Re-pair for Trees on a tree from  in general. Let  and let  be the following function:

Let  be a sequence of nonterminals where for all  the following conditions are fulfilled:
\begin{itemize}
	\item 
	\item  is the right-hand side of 
	\item If , we have  and if , the tree  is of the form shown in Fig.~\ref{fig:rhsOfB}, where .
\end{itemize}
Regarding the nonterminals  and  from Example \ref{ex:unlimitedRank1}, we have  and \mbox{}, respectively. Let . The following two equations hold:

For convenience, we define .

Now assume that we have an unlimited maximal rank allowed for a nonterminal. After   iterations on  we have obtained the nonterminals . The right-hand side of the start nonterminal is a -ary tree of height  (see also Example~\ref{ex:unlimitedRank1}, where ). At this point, no further replacements are carried out. For each of the generated nonterminals  we have

where  (\cf Fig.~\ref{fig:rhsOfB}). Hence, we have

since . Therefore, none of the nonterminals  will be eliminated in the pruning step.

Now assume that the maximal rank is , \ie, we have . Choose the smallest  such that
\begin{figure}[tb]
	\centering
	\begin{tikzpicture}[semithick]
		\tikzstyle{level 1}=[level distance=1.35cm]
		\tikzstyle{level 2}=[level distance=1.35cm]
		\begin{scope}[->,>=stealth']
			\node {}
				child {node (y1) {}}
				child {node (y2) {}}
				child[missing] {node (y3) {}}
				child {node (y4) {}}
				child[sibling distance=2.5cm] {node (B2) {}
					child[sibling distance=1.25cm] {node (y20) {}}
					child[sibling distance=1.25cm] {node (y21) {}}
					child[missing] {node {}}
					child[sibling distance=0.75cm] {node (y22) {}}
				}
				child[missing] {node {}}
				child[sibling distance=2.75cm] {node (Bn) {}
					child[sibling distance=1.75cm] {node (y30) {}}
					child[sibling distance=1.75cm] {node (y31) {}}
					child[missing] {node {}}
					child[sibling distance=1.2cm] {node (y32) {}}
				}
			;
		\end{scope}
		
		\draw[dotted] ([xshift=1cm]B2.center) -- ([xshift=-1cm]Bn.center);
		\draw[dotted] ([xshift=0.6cm]y2.center) -- ([xshift=-0.6cm]y4.center);
		\draw[dotted] ([xshift=1cm]y21.center) -- ([xshift=-1cm]y22.center);
		\draw[dotted] ([xshift=1cm]y31.center) -- ([xshift=-1cm]y32.center);
		
		\draw[decorate,decoration={brace,mirror}] ([xshift=-7pt]y1.south) -- ([xshift=8pt]y4.south) node[midway,sloped,below=2pt] {\footnotesize  many};
		\draw[decorate,decoration={brace,mirror}] ([xshift=-10pt,yshift=4pt]B2.south) -- ([xshift=10pt,yshift=4pt]Bn.south) node[midway,sloped,below=2pt] {\footnotesize  many};
		\draw[decorate,decoration={brace,mirror}] ([xshift=-13pt]y20.south) -- ([xshift=10pt]y22.south) node[midway,sloped,below=2pt] {\footnotesize  many};
		\draw[decorate,decoration={brace,mirror}] ([xshift=-20pt]y30.south) -- ([xshift=18pt]y32.south) node[midway,sloped,below=2pt] {\footnotesize  many};
	\end{tikzpicture}
	\caption{Right-hand side of the nonterminal , where .}\label{fig:rhsOfC}
\end{figure}

Thus,  is the first nonterminal in the sequence  with a rank bigger than . Let us consider a run of Re-pair for Trees on a tree  with . Then, as above, the nonterminals  will be obtained after  iterations (if we would prune the corresponding grammar by now). At this point, the right-hand side of the start production is a -ary tree of height , where all inner nodes are labeled by the nonterminal . Now, we can carry out  additional \tp replacements leading to the nonterminals , where

and . We claim that

holds. To see this, let us assume that . We have

However, this contradicts (\ref{eq:BiggerThanM}).
\begin{figure}[tb]
	\centering
	\newcommand{\ldistance}{7}
	\newcommand{\innersize}{0.6}
	\begin{tikzpicture}
		[level distance=\ldistance mm,
		inner/.style={fill=black,circle,inner sep=\innersize pt},
		A/.style={inner},
		B/.style={inner},
		leaf/.style={fill=white,draw=black,circle,inner sep=0.5pt}
		]
		
		\node[B] {}
			child[sibling distance=20mm] {node[B] {}
				child[sibling distance=9.6mm] foreach \iiii in {1,2,3,4} {node[B] {}
					child[sibling distance=1.2mm] {node[B] {}
						child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4} {node[leaf] {}}
					}
					child[sibling distance=0.7mm] {node[B] {}
						child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4} {node[leaf] {}}
					}
					child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4,5,6,7,8} {node[leaf] {}}
				}
			}
			child[sibling distance=15mm] {node[B] {}
				child[sibling distance=9.6mm] foreach \iiii in {1,2,3,4} {node[B] {}
					child[sibling distance=1.2mm] {node[B] {}
						child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4} {node[leaf] {}}
					}
					child[sibling distance=0.7mm] {node[B] {}
						child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4} {node[leaf] {}}
					}
					child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4,5,6,7,8} {node[leaf] {}}
				}
			}
			child[sibling distance=9.6mm] {node[B] {}
				child[sibling distance=1.2mm] {node[B] {}
					child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4} {node[leaf] {}}
				}
				child[sibling distance=0.7mm] {node[B] {}
					child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4} {node[leaf] {}}
				}
				child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4,5,6,7,8} {node[leaf] {}}
			}
			child[sibling distance=9.6mm] foreach \iiii in {1,2,3,4,5,6,7} {node[B] {}
				child[sibling distance=1.2mm] {node[B] {}
					child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4} {node[leaf] {}}
				}
				child[sibling distance=0.7mm] {node[B] {}
					child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4} {node[leaf] {}}
				}
				child[sibling distance=0.6mm] foreach \iiiiii in {1,2,3,4,5,6,7,8} {node[leaf] {}}
			}
		;
	\end{tikzpicture}
	\caption{Right-hand side of the current start production after replacing the \tp .}\label{fig:unlimitedRankLimitedExample}
\end{figure}

In case , we can argue as follows: After the pruning step, the nonterminals  form one nonterminal  with  (see Fig.~\ref{fig:rhsOfC}). It occurs at least  many times according to (\ref{eq:refBi}) (the nonterminal  occurs as often as  does after  iterations on  in the unlimited case). Each occurrence of  reduces the size of the corresponding grammar by  edges and the right-hand side of  consists of  edges (see Fig.~\ref{fig:rhsOfC}). Now, let us consider the -value of  (assuming that  is the current grammar after  iterations):

Thus, we have , \ie, the nonterminal  is not eliminated during the pruning step. 
\begin{example}\label{ex:unlimitedRank2}
	Let us assume that the maximal rank for a nonterminal is restricted to  in Example \ref{ex:unlimitedRank1}. In this case we are able to undertake exactly one additional \tp replacement in the tree from Fig.~\subref{fig:unlimitedRank4} resulting in a new nonterminal . If we replace the \tp , we obtain the tree shown in Fig.~\ref{fig:unlimitedRankLimitedExample}. We have ,  and . After the pruning step, the right-hand side of  is of the form 
	
\end{example}
\bigskip
We can further state that the nonterminal  is not eliminated since it occurs  times in the right-hand side of  (see Fig.~\ref{fig:rhsOfC}) and  times in the right-hand side of the current start production (below each occurrence of  there are  occurrences of  and  occurs at least  times). Therefore, we have

Because of (\ref{eq:rankBiggerH}), the inequality  holds. As shown before for the unlimited rank, in this case  has a -value bigger than  and therefore the nonterminals  are not eliminated.

Let  be the grammar which is obtained after  iterations on the tree  when restricting the maximal rank to  and let  be the current grammar after  iterations on  when an unlimited rank is allowed. We can conclude that  holds --- no matter whether we have  or  --- because of the following two facts:
\begin{enumerate}[(1)]
	\item Each occurrence of  saves  edges (see Fig.~\ref{fig:rhsOfB}) and therefore according to (\ref{eq:rankBiggerH}) more than an occurrence of  does. The nonterminals  and  occur equally often. However,  is only existent if .
	\item The nonterminals  (which are existent in both grammars,  and ) and the nonterminals  and  are not eliminated during the pruning step.
\end{enumerate}
Let  () be the final grammar which is generated by a run of Re-pair for Trees on the tree  when restricting the maximal rank of a nonterminal to  (not restricting the maximal rank). We have  and . The latter holds because with every additional \tp replacement at least one edge is absorbed and because during the pruning step only nonterminals with a -value smaller than or equal to  are eliminated. Therefore  holds. Thus, we have shown that, in general, the trees from  can be compressed best if there are no restrictions on the maximal rank allowed for a nonterminal.
\begin{example}
	Table \ref{tbl:comparisonRuns} shows a comparison of the grammars generated by different runs of our algorithm on the trees ,  and  from . By  () we denote the final grammar which is generated when restricting the maximal rank to  (not restricting the maximal rank).
\end{example}

\subsection{Limiting the Maximal Rank}\label{sec:limitingTheMaximalRank}

\begin{table}[tb]
	\centering
		\begin{tabular}{crrrr}
			\toprule
			Tree		&	&	&&\\
			\midrule
					&					&	&			&\\
					&					&	&			&\\
					&				&&			&\\
			\bottomrule
		\end{tabular}
	\caption{Comparison of the sizes of the final grammars.}\label{tbl:comparisonRuns}
\end{table}

In the preceding section we investigated a set of trees whose compressibility was best if we did not restrict the maximal rank of a nonterminal. Now, we want to construct a set of trees which behaves contrarily, \ie, we construct trees which can be compressed best if we limit the maximal rank of a nonterminal to . In order to make it easier to quickly understand the following definition we want to refer the reader to Fig.~\subref{fig:unlimitedCaseRhsG0} which shows one of the trees we define in the sequel.

First of all, let us define a labeling function , where

and . Now, we define for all  the tree , where

and

Let us define . In the following we will show that for every run of Re-pair for Trees on a tree  we have , where  is the grammar generated when allowing a maximal rank of  for a nonterminal and  is the resulting grammar when there is no restriction on the maximal rank.

Let us consider a run  of the Re-pair for Trees algorithm on the tree  with no restrictions on the maximal rank of a nonterminal, where ,  is the start production of  and . In the first iteration of our computation the \tp  is the most frequent \tp, \ie, . This is because of  whereas for every  the inequality

holds. Therefore, we replace the \tp  by a new nonterminal  and obtain . In every subsequent iteration  we replace  by a new nonterminal , where . For every  the right-hand side of the start production of the grammar  is given by the tree , where


\begin{figure}[p]
	\small
	\centering
\parbox{14.5cm}{
		\subfigure[The tree  which is the right-hand side of 's start production.]{
			\begin{tikzpicture}[->,>=stealth',semithick,level distance=0.8cm, sibling distance=1.1cm]
				\begin{scope}[xshift=-2.5cm]
				\draw[draw=white] (-1,0) -- (-1,-1);
				\node (f1) {} [grow=-110]
					child {node {}}
					child {node (f2) {}
						child {node {}}
						child {node (f3) {}
							child {node {}}
							child {node (f4) {}
								child {node {}}
								child {node (f5) {}
									child {node {}}
									child {node (f6) {}
										child {node {}}
										child {node (f7) {}
											child {node {}}
											child {node (f8) {}
												child {node {}}
												child[missing] {node {}}
											}	
										}	
									}			
								}
							}
						}
					}
				;

				\end{scope}
				\begin{scope}[xshift=0.25cm]
				\node (f9) {} [grow=-110]
					child {node {}}
					child {node (f10) {}
						child {node {}}
						child {node (f11) {}
							child {node {}}
							child {node (f12) {}
								child {node {}}
								child {node (f13) {}
									child {node {}}
									child {node (f14) {}
										child {node {}}
										child {node (f15) {}
											child {node {}}
											child {node (f16) {}
												child {node {}}
												child {node {}}
											}	
										}	
									}			
								}
							}
						}
					}
				;
				\end{scope}
				
				\clip (2,0.7) rectangle (-3,-7.5); \draw (f8) .. controls +(3,-3) and +(-3,3) .. (f9);
			\end{tikzpicture}
			\label{fig:unlimitedCaseRhsG0}
		}
		\hfill
		\subfigure[The right-hand side of 's start production.]{
			\begin{tikzpicture}[->,>=stealth',semithick,level distance=1cm, sibling distance=1cm,scale=0.9]
				\tikzstyle{fan}=[anchor=north,isosceles triangle, shape border uses incircle,inner sep=0.5pt,shape border rotate=90,draw]
			
				\node (f1) {} [grow=-105]
					child {node {}}
					child {node {}}
					child {node (f2) {}
						child {node {}}
						child {node {}}
						child {node (f3) {}
							child {node {}}
							child {node {}}
							child {node (f4) {}
								child {node {}}
								child {node {}}
								child {node (f5) {}
									child {node {}}
									child {node {}}
									child {node (f6) {}
										child {node {}}
										child {node {}}
										child {node (f7) {}
											child {node {}}
											child {node {}}
											child {node (f8) {}
												child {node {}}
												child {node {}}
												child {node {}}
											}
										}
									}
								}
							}
						}
					}
				;
			\end{tikzpicture}
			\label{fig:unlimitedCaseRhsG1}
		}
		\\
		\vspace{1cm}
		\\
		\subfigure[The right-hand side of 's start production.]{
			\begin{tikzpicture}[->,>=stealth',semithick,level distance=1cm, sibling distance=1cm,scale=0.95]
				\tikzstyle{fan}=[anchor=north,isosceles triangle, shape border uses incircle,inner sep=0.5pt,shape border rotate=90,draw]
			
				\node (f1) {} [grow=-125]
					child {node {}}
					child {node {}}
					child {node {}}
					child {node {}}
					child {node (f2) {}
						child {node {}}
						child {node {}}
						child {node {}}
						child {node {}}
						child {node (f3) {}
							child {node {}}
							child {node {}}
							child {node {}}
							child {node {}}
							child {node (f4) {}
								child {node {}}
								child {node {}}
								child {node {}}
								child {node {}}
								child {node {}}
							}
						}
					}
				;
			\end{tikzpicture}
			\label{fig:unlimitedCaseRhsG2}
		}
		\hfill
		\subfigure[The right-hand side of 's start production.]{
			\begin{tikzpicture}[->,>=stealth',semithick,level distance=1cm, sibling distance=0.9cm,scale=0.85]
				\tikzstyle{fan}=[anchor=north,isosceles triangle, shape border uses incircle,inner sep=0.5pt,shape border rotate=90,draw]
			
				\node {} [grow=-133]
					child {node {}}
					child {node {}}
					child {node {}}
					child {node {}}
					child {node {}}
					child {node {}}
					child {node {}}
					child {node {}}
					child {node {}
						child {node {}}
						child {node {}}
						child {node {}}
						child {node {}}
						child {node {}}
						child {node {}}
						child {node {}}
						child {node {}}
						child {node {}}
					}
				;
			\end{tikzpicture}
			\label{fig:unlimitedCaseRhsG3}
		}
	}
	\stepcounter{figure}
\end{figure}
\begin{example}
The Figs.~\subref{fig:unlimitedCaseRhsG0}, \subref{fig:unlimitedCaseRhsG1}, \subref{fig:unlimitedCaseRhsG2} and \subref{fig:unlimitedCaseRhsG3} show the right-hand sides of the start productions of the grammars , ,  and  generated by a run of our algorithm on the tree .
\end{example}
In order to argue that we have  for every , we investigate the number of occurrences of all \tps occurring in the right-hand side of 's start production. Firstly, it is easy to verify that . In contrast, for every  and  the inequality  holds. This is because every power of  is not divisible by , \ie, for every  and every  we have 

Due to the fact that we do not replace \tps with child symbols , , ,  or , the right-hand side of 's start production has to contain at least  nodes labeled by these symbols, \ie, we can conclude that . Therefore the compression ratio cannot be better than 50\%.

In contrast, a run  of our
algorithm on the tree  leads to a significantly better compression ratio 
when restricting the maximal rank of a nonterminal to , where 
\mbox{}, \mbox{},
 is the start production of  and
. In the first iteration we have
, since a replacement of 
would result in a nonterminal with a rank greater than . Therefore
only the \tps , , , , 
and subsequent \tps can be replaced. It turns out that after the first
nine iterations the pattern  is
represented by a new nonterminal  with
. The actual order of the replacements within
the first nine iterations depends on the method used to choose a most
frequent \tp when there are multiple most frequent \tps. Refer to
Example \ref{ex:limitedRankBetterLimitedRank} for one possible proceeding.

\begin{table}[tb]
	\centering
		\begin{tabular}{cccc}
			\toprule
			Iteration	&Replaced \tp		&New nonterminal	&\cf Figure\\
			\midrule
						&		&			&\subref{fig:limitedCaseRhsG1}\\
						&		&			&\subref{fig:limitedCaseRhsG2}\\
						&	&			&\subref{fig:limitedCaseRhsG3}\\
						&		&			&\subref{fig:limitedCaseRhsG4}\\
						&		&			&\subref{fig:limitedCaseRhsG5}\\
						&	&			&\subref{fig:limitedCaseRhsG6}\\
						&	&			&\subref{fig:limitedCaseRhsG7}\\
						&		&			&\subref{fig:limitedCaseRhsG8}\\
						&	&			&\subref{fig:limitedCaseRhsG9}\\
			\bottomrule
		\end{tabular}
	\caption{A run of Re-pair for Trees on the tree  with a maximal nonterminal rank of .}\label{tbl:limitedRankBetterLimitedCaseExample}
\end{table}
The right-hand side of 's start production is a degenerated tree mainly consisting of consecutive nonterminals . The corresponding nodes --- there are roughly  of them --- are then boiled down using approximately  \tp replacements. Therefore the number of total edges of the resulting grammar is in , \ie, it is of logarithmic size (the size of the input tree  is ). Thus, we were able to construct a set of trees which exhibit a better compressibility when restricting the maximal rank of a nonterminal to .
\begin{example}\label{ex:limitedRankBetterLimitedRank}
	Let us consider a run of Re-pair for Trees on the tree  when restricting the maximal rank of a nonterminal to  (see Fig.~\subref{fig:limitedCaseRhsG0} for a depiction of ). Table \ref{tbl:limitedRankBetterLimitedCaseExample} shows one of several possible orders of \tp replacements and the Fig.~\ref{fig:limitedCaseRhsG0-G9} shows how the right-hand sides of the start productions evolve.
\end{example}
			
\begin{figure}[p]
\centering
	\parbox{14.5cm}{
		\subfigure {
				\begin{tikzpicture}[scale=0.8,->,>=stealth',semithick,level distance=0.8cm, sibling distance=1.1cm]
					\begin{scope}[xshift=-2.5cm]
\node (f1) {} [grow=-110]
						child {node {}}
						child {node (f2) {}
							child {node {}}
							child {node (f3) {}
								child {node {}}
								child {node (f4) {}
									child {node {}}
									child {node (f5) {}
										child {node {}}
										child {node (f6) {}
											child {node {}}
											child {node (f7) {}
												child {node {}}
												child {node (f8) {}
													child {node {}}
													child[missing] {node {}}
												}	
											}	
										}			
									}
								}
							}
						}
					;
	
					\end{scope}
					\begin{scope}[xshift=0.25cm]
					\node (f9) {} [grow=-110]
						child {node {}}
						child {node (f10) {}
							child {node {}}
							child {node (f11) {}
								child {node {}}
								child {node (f12) {}
									child {node {}}
									child {node (f13) {}
										child {node {}}
										child {node (f14) {}
											child {node {}}
											child {node (f15) {}
												child {node {}}
												child {node (f16) {}
													child {node {}}
													child {node {}}
												}	
											}	
										}			
									}
								}
							}
						}
					;
					\end{scope}
					
					\clip (2,0.7) rectangle (-3,-7.5); \draw (f8) .. controls +(3,-3) and +(-3,3) .. (f9);
				\end{tikzpicture}
				\label{fig:limitedCaseRhsG0}
		}
		\hfill
		\subfigure {
				\begin{tikzpicture}[scale=0.8,->,>=stealth',semithick,level distance=0.8cm, sibling distance=1.1cm]
					\begin{scope}[xshift=-2.5cm]
					\node {} [grow=-110]
						child[missing] {node {}}
						child {node {}
							child {node {}}
							child {node {}
								child {node {}}
								child {node {}
									child {node {}}
									child {node {}
										child {node {}}
										child {node {}
											child[missing] {node {}}
											child {node {}
												child {node {}}
												child {node (f8) {}
													child {node {}}
													child[missing] {node {}}
												}	
											}	
										}			
									}
								}
							}
						}
					;
					\end{scope}
					\begin{scope}[xshift=0.25cm]
					\node (f9) {} [grow=-110]
						child {node {}}
						child {node {}
							child {node {}}
							child {node {}
								child[missing] {node {}}
								child {node {}
									child {node {}}
									child {node {}
										child {node {}}
										child {node {}
											child {node {}}
											child {node {}
												child {node {}}
												child {node {}
													child[missing] {node {}}
													child {node {}}
												}	
											}	
										}			
									}
								}
							}
						}
					;
					\end{scope}
					
					\clip (2,0.7) rectangle (-3,-7.5); \draw (f8) .. controls +(3,-3) and +(-3,3) .. (f9);
				\end{tikzpicture}
				\label{fig:limitedCaseRhsG1}
		}
		\hfill
		\subfigure {
				\begin{tikzpicture}[scale=0.8,->,>=stealth',semithick,level distance=0.8cm, sibling distance=1.1cm]
					\begin{scope}[xshift=-2.5cm]
					\node {} [grow=-110]
						child[missing] {node {}}
						child {node {}
							child[missing] {node {}}
							child {node {}
								child {node {}}
								child {node {}
									child {node {}}
									child {node {}
										child {node {}}
										child {node {}
											child[missing] {node {}}
											child {node {}
												child[missing] {node {}}
												child {node (f8) {}
													child {node {}}
													child[missing] {node {}}
												}	
											}	
										}			
									}
								}
							}
						}
					;
					\end{scope}
					\begin{scope}[xshift=0.25cm]
					\node (f9) {} [grow=-110]
						child {node {}}
						child {node {}
							child {node {}}
							child {node {}
								child[missing] {node {}}
								child {node {}
									child[missing] {node {}}
									child {node {}
										child {node {}}
										child {node {}
											child {node {}}
											child {node {}
												child {node {}}
												child {node {}
													child[missing] {node {}}
													child {node {}}
												}	
											}	
										}			
									}
								}
							}
						}
					;
					\end{scope}
					
					\clip (2,0.7) rectangle (-3,-7.5); \draw (f8) .. controls +(3,-3) and +(-3,3) .. (f9);
				\end{tikzpicture}
				\label{fig:limitedCaseRhsG2}
		}
		\\
		\vspace{0.5cm}
		\subfigure {
				\begin{tikzpicture}[scale=0.8,->,>=stealth',semithick,level distance=0.8cm, sibling distance=1.1cm]
					\begin{scope}[xshift=-2.5cm]
					\node {} [grow=-110]
							child[missing] {node {}}
							child {node {}
								child {node {}}
								child {node {}
									child {node {}}
									child {node {}
										child {node {}}
										child {node {}
												child[missing] {node {}}
												child {node (f8) {}
													child {node {}}
													child[missing] {node {}}
												}	
										}			
									}
								}
							}
					;
					\end{scope}
					\begin{scope}[xshift=0.25cm]
					\node (f9) {} [grow=-110]
						child {node {}}
						child {node {}
							child {node {}}
							child {node {}
									child[missing] {node {}}
									child {node {}
										child {node {}}
										child {node {}
											child {node {}}
											child {node {}
												child {node {}}
												child {node {}
													child[missing] {node {}}
													child {node {}}
												}	
											}	
										}			
									}
							}
						}
					;
					\end{scope}
					
					\clip (2,0.9) rectangle (-3,-6.5); \draw (f8) .. controls +(3,-3) and +(-3,3) .. (f9);
				\end{tikzpicture}
				\label{fig:limitedCaseRhsG3}
		}
		\hfill
		\subfigure {
				\begin{tikzpicture}[scale=0.8,->,>=stealth',semithick,level distance=0.8cm, sibling distance=1.1cm]
					\begin{scope}[xshift=-2.5cm]
					\node {} [grow=-110]
							child[missing] {node {}}
							child {node {}
								child[missing] {node {}}
								child {node {}
									child {node {}}
									child {node {}
										child {node {}}
										child {node {}
												child[missing] {node {}}
												child {node (f8) {}
													child[missing] {node {}}
													child[missing] {node {}}
												}	
										}			
									}
								}
							}
					;
					\end{scope}
					\begin{scope}[xshift=0.25cm]
					\node (f9) {} [grow=-110]
						child {node {}}
						child {node {}
							child {node {}}
							child {node {}
									child[missing] {node {}}
									child {node {}
										child[missing] {node {}}
										child {node {}
											child {node {}}
											child {node {}
												child {node {}}
												child {node {}
													child[missing] {node {}}
													child {node {}}
												}	
											}	
										}			
									}
							}
						}
					;
					\end{scope}
					
					\clip (2,0.9) rectangle (-3,-6.5); \draw (f8) .. controls +(3,-3) and +(-3,3) .. (f9);
				\end{tikzpicture}
				\label{fig:limitedCaseRhsG4}
		}
		\hfill
		\subfigure {
				\begin{tikzpicture}[scale=0.8,->,>=stealth',semithick,level distance=0.8cm, sibling distance=1.1cm]
					\begin{scope}[xshift=-2.5cm]
					\node {} [grow=-110]
							child[missing] {node {}}
							child {node {}
								child[missing] {node {}}
								child {node {}
									child[missing] {node {}}
									child {node {}
										child {node {}}
										child {node {}
												child[missing] {node {}}
												child {node (f8) {}
													child[missing] {node {}}
													child[missing] {node {}}
												}	
										}			
									}
								}
							}
					;
					\end{scope}
					\begin{scope}[xshift=0.25cm]
					\node (f9) {} [grow=-110]
						child[missing] {node {}}
						child {node {}
							child {node {}}
							child {node {}
									child[missing] {node {}}
									child {node {}
										child[missing] {node {}}
										child {node {}
											child[missing] {node {}}
											child {node {}
												child {node {}}
												child {node {}
													child[missing] {node {}}
													child {node {}}
												}	
											}	
										}			
									}
							}
						}
					;
					\end{scope}
					
					\clip (2,0.9) rectangle (-3,-6.5); \draw (f8) .. controls +(3,-3) and +(-3,3) .. (f9);
				\end{tikzpicture}
				\label{fig:limitedCaseRhsG5}
		}
		\\
		\vspace{0.5cm}
		\subfigure {
				\begin{tikzpicture}[scale=0.8,->,>=stealth',semithick,level distance=0.8cm, sibling distance=1.1cm]
					\begin{scope}[xshift=-2.5cm]
					\node {} [grow=-110]
								child[missing] {node {}}
								child {node {}
									child[missing] {node {}}
									child {node {}
										child {node {}}
										child {node (f8) {}
													child[missing] {node {}}
													child[missing] {node {}}
										}			
									}
								}
					;
					\end{scope}
					\begin{scope}[xshift=0.25cm]
					\node (f9) {} [grow=-110]
						child[missing] {node {}}
						child {node {}
							child {node {}}
							child {node {}
										child[missing] {node {}}
										child {node {}
											child[missing] {node {}}
											child {node {}
												child {node {}}
												child {node {}
													child[missing] {node {}}
													child {node {}}
												}	
											}	
										}			
							}
						}
					;
					\end{scope}
					
					\clip (2,1) rectangle (-3,-5.5); \draw (f8) .. controls +(3,-3) and +(-3,3) .. (f9);
				\end{tikzpicture}
				\label{fig:limitedCaseRhsG6}
		}
		\hfill
		\subfigure {
				\begin{tikzpicture}[scale=0.8,->,>=stealth',semithick,level distance=0.8cm, sibling distance=1.1cm]
					\node {} [grow=-110]
						child[missing] {node {}}
						child {node {}
							child {node {}}
							child {node (f8) {}
								child[missing] {node {}}
								child {node {}
									child {node {}}
									child {node {}
										child[missing] {node {}}
										child {node {}
											child {node {}}
											child {node {}
												child[missing] {node {}}
												child {node {}}
											}	
										}			
									}
								}
							}			
						}
					;
				\end{tikzpicture}
				\label{fig:limitedCaseRhsG7}
		}
		\hfill
		\subfigure {
				\begin{tikzpicture}[scale=0.8,->,>=stealth',semithick,level distance=0.8cm, sibling distance=1.1cm]
					\node {} [grow=-110]
						child[missing] {node {}}
						child {node {}
							child[missing] {node {}}
							child {node (f8) {}
								child[missing] {node {}}
								child {node {}
									child[missing] {node {}}
									child {node {}
										child[missing] {node {}}
										child {node {}
											child[missing] {node {}}
											child {node {}
												child[missing] {node {}}
												child {node {}}
											}	
										}		
									}
								}
							}			
						}
					;
				\end{tikzpicture}
				\label{fig:limitedCaseRhsG8}
		}
		\hfill
		\subfigure {
				\begin{tikzpicture}[scale=0.8,->,>=stealth',semithick,level distance=0.8cm, sibling distance=1.1cm]
					\node {} [grow=-110]
							child[missing] {node {}}
							child {node (f8) {}
									child[missing] {node {}}
									child {node {}
											child[missing] {node {}}
											child {node {}
												child[missing] {node {}}
												child {node {}}
											}	
									}
							}			
					;
				\end{tikzpicture}
				\label{fig:limitedCaseRhsG9}
		}
	}
	\caption{\label{fig:limitedCaseRhsG0-G9}The right-hand sides for the nonterminals }
	\stepcounter{figure}
\end{figure}


\section{Implementation Details}\label{ch:implementationDetails}

We implemented a prototype of the Re-pair for Trees algorithm, named \trp, running on XML documents. In the sequel, we demonstrate that it produces for any XML document tree in  time a linear -bounded SLCF tree grammar , where  is a constant,  and  is the binary representation of the input tree.

There are several reasons to restrict the maximal rank to a constant . One of them is that only this way we are able to obtain a linear-time implementation. Another reason is that for every -bounded linear SLCF tree grammar  generated by \trp it can be checked in polynomial time if a given tree automaton accepts  (using a result from \cite{Lohrey2006complexity}). Last but not least, Sect.~\ref{sec:limitingTheMaximalRank} on page \pageref{sec:limitingTheMaximalRank} showed us that for flat XML documents leading to a right-leaning binary tree it is quite promising to restrict the maximal rank. The latter reason is also supported by our experiments with different maximal ranks on our test set of XML documents. 

On average, a maximal rank of  leads to the best compression performance (\cf Sect.~\ref{sec:resultsWithDifferentMaximalRanks} on page \pageref{sec:resultsWithDifferentMaximalRanks}). Due to this fact \trp generates -bounded linear SLCF tree grammars by default. This can be adjusted by using the \verb|-max_rank| switch.

\subsection{Reading the Input Tree}

The XML document tree of the input file can be directly transformed into a binary \mbox{-labeled} tree .\footnote{Refer to Sect.~\ref{sec:binaryTreeModel} on page \pageref{sec:binaryTreeModel} for an explanation of the binary tree model.} The XML document is parsed by a SAX-like parser calling the functions \verb|start-element| and \verb|end-element| (see Figs.~\ref{lst:functionStartElement} and \ref{lst:functionEndElement}) of an object taking care of the tree construction. The latter is called \emph{tree constructor} in the sequel. 

The tree constructor uses three stacks to properly encode the SAX events. Firstly, the stack \verb|index_stack| keeps track of the index\footnote{Analogously to our definition for ranked trees: If an element is the -th child of its parent element, then the index of this element is .} of the current element read. The stack \verb|name-stack| stores the element types of the elements in order to be able to update the labeling function  within the \verb|end-element| function. Together with the stack \verb|hierarchy_stack|, which is used to maintain the current sequence of parents within , enough information stands by to encode the SAX events.

\begin{figure}[tb]
\lstset{emph={FUNCTION,ENDFUNC,return,traverse,endtraverse,for,if,else,then,do,endif,endfor}, emphstyle=\bfseries, emph={[2]index_stack,hierarchy_stack,name_stack,name}, emphstyle={[2]\slshape}, morecomment=[l]{//}}
\begin{lstlisting}{}
FUNCTION start-element(name)
	if (hierarchy_stack is not empty) then
		(*@@*)index_stack.top()(*@@*);
		index_stack.pop();
		index_stack.push((*@@*));

		(*@@*)hierarchy_stack.top();
		
		if ((*@@*)) then (*@@*)
		else	(*@@*)
		endif
		
		name_stack.push(name);
	else
		(*@@*);
		(*@@*)name(*@@*);
	endif
	
	(*@@*);

	index_stack.push((*@@*));
	hierarchy_stack.push((*@@*));
ENDFUNC
\end{lstlisting}
\caption{The start-element function which is called for every start-tag.}\label{lst:functionStartElement}
\end{figure}

To be more precise, if the parser encounters a start-tag, it extracts the element type of the element and passes it to the tree constructor by calling the function \verb|start-element|. If it is the first call of \verb|start-element|, we must be dealing with the root of the document. Thus, the stack \verb|hierarchy_stack| is empty and the \verb|else|-part beginning in line 15 is processed. First of all, the variable  is identified with  (and later added to the set ). Afterwards, the labeling function  is updated accordingly. Since, in the binary tree model, the root has no sibling nodes and since it is assumed that the input tree consists of at least two nodes, it is clear that the terminal symbol labeling the root node will have a left child but no right child (therefore the superscript  in line 16).

If we consider a subsequent call of \verb|start-element|, the hierarchy stack is not empty and therefore the \verb|if|-part is processed. Firstly, the index stack is updated in the lines 3--5 and after that the node  is retrieved from the hierarchy stack (line 7). The tree node  will be the parent of the node which is added in the following. We introduce a new node  which is later (but still in the same call of this function) added to  (line 19). The node  becomes the left child of  if it represents the first child element of the element which is represented by . In contrast,  becomes a right child if the current index  is greater than one, \ie, if the element being processed is a sibling element of the element represented by . Regarding the node , we are unable to update the labeling function  at this time since we do not know if the XML element being processed has children or sibling elements. 

\begin{figure}[tb]
\lstset{emph={FUNCTION,ENDFUNC,return,traverse,endtraverse,for,if,else,then,do,endif,endfor,repeat,endrepeat,times}, emphstyle=\bfseries, emph={[2]index_stack,hierarchy_stack,name_stack,name,lchild,rchild}, emphstyle={[2]\slshape}, morecomment=[l]{//}}
\begin{lstlisting}{}
FUNCTION end-element
	(*@@*)index_stack.top();
	repeat (*@@*) times
		(*@@*)hierarchy_stack.top();
		name(*@@*)name_stack.top();

		(*@@*), (*@@*);
		if ((*@@*)) then
			(*@@*);
		endif
		if ((*@@*)) then
			(*@@*);
		endif

		(*@@*)name(*@@*);

		hierarchy_stack.pop();
		name_stack.pop();
	endrepeat
	index_stack.pop();
ENDFUNC
\end{lstlisting}
\caption{The end-element function which is called for every end-tag encountered in the input XML document.}\label{lst:functionEndElement}
\end{figure}

If an end-tag is encountered by the input parser, the function \verb|end-element| listed in Fig.~\ref{lst:functionEndElement} is called. Now, the index of the current XML element is consulted in order to bubble up the sequence of parents stored by the hierarchy stack the correct number of times. Lastly, after processing the \verb|repeat| loop, the node representing the first child element of the current XML element (the end-tag of its last child element was just read) is on top of the hierarchy stack. For every node  which is removed from the hierarchy stack within the \verb|repeat| loop the labeling function  is updated.

\begin{example}
Fig.~\ref{fig:constructionOfBinaryTree} shows the evolution of the
data structures after the first calls to the functions \texttt{start-element()}
and \texttt{end-element()}, respectively, when parsing the input tree
from Fig.~\ref{fig:XmlDocumentTree}. It shows the content of the three
stacks after the body of the corresponding function has been executed,
where \textsf{is} denotes the index stack, \textsf{hs} denotes the
hierarchy stack and \textsf{ns} denotes the name stack. Regarding
Fig.~\ref{fig:constructionOfBinaryTree}, the element on top of the
stack is always the upper element in the depiction of the
corresponding stack. If there has not been assigned a label to a node,
\ie, the labeling function  has not been updated accordingly
yet, the node is depicted in brackets.
\end{example}
\begin{figure}[p]
\small
\centering
	\parbox{16cm}{
	\begin{multicols}{2}
	\begin{enumerate}[(1)]
		\item Function call \texttt{start-element(books)}
			
			\begin{raggedleft}
				\parbox{3cm}{
					\begin{center}
						\begin{tabular}{ccc}
							&&\\
							\midrule
							\textsf{is}&\textsf{hs}&\textsf{ns}\\\bottomrule
						\end{tabular}
					\end{center}
				}
				\hspace{1cm}
				\parbox{1.5cm}{
					\begin{raggedleft}
						\begin{tikzpicture}
							[bend angle=25, node distance=0.25cm,text height=1.5ex,
							place/.style={},
							pre/.style={<-,>=stealth'},
							post/.style={->,>=stealth'}]
							\node[place] (books) {};
						\end{tikzpicture}
					\end{raggedleft}
				}
			\end{raggedleft}
		\item Function call \texttt{start-element(book)}
		
			\begin{raggedleft}
				\parbox{3cm}{
					\begin{center}
						\begin{tabular}{ccc}
							&&\\
							&&\\
							\midrule
							\textsf{is}&\textsf{hs}&\textsf{ns}\\\bottomrule
						\end{tabular}
					\end{center}
				}
				\hspace{1cm}
				\parbox{1.5cm}{
					\begin{raggedleft}
						\begin{tikzpicture}
							[bend angle=25, node distance=0.25cm,text height=1.5ex,
							place/.style={},
							pre/.style={<-,>=stealth'},
							post/.style={->,>=stealth'}]
							\node[place] (books) {};
							
							\node[place] (book1) [below=of books] {}
								edge [pre] (books);
						\end{tikzpicture}
					\end{raggedleft}
				}
			\end{raggedleft}
		\item Function call \texttt{start-element(author)}
		
			\begin{raggedleft}
				\parbox{3cm}{
					\begin{center}
						\begin{tabular}{ccc}
							&&\\
							&&\\
							&&\\
							\midrule
							\textsf{is}&\textsf{hs}&\textsf{ns}\\\bottomrule
						\end{tabular}
					\end{center}
				}
				\hspace{1cm}
				\parbox{1.5cm}{
					\begin{raggedleft}
						\begin{tikzpicture}
							[bend angle=25, node distance=0.25cm,text height=1.5ex,
							place/.style={},
							pre/.style={<-,>=stealth'},
							post/.style={->,>=stealth'}]
							\node[place] (books) {};
							
							\node[place] (book1) [below=of books] {}
								edge [pre] (books);
							\node[place] (author1) [below=of book1] {}
								edge [pre] (book1);
						\end{tikzpicture}
					\end{raggedleft}
				}
			\end{raggedleft}
		\item Function call \texttt{end-element()}
		
			\begin{raggedleft}
				\parbox{3cm}{
					\begin{center}
						\begin{tabular}{ccc}
							&&\\
							&&\\
							&&\\
							\midrule
							\textsf{is}&\textsf{hs}&\textsf{ns}\\\bottomrule
						\end{tabular}
					\end{center}
				}
				\hspace{1cm}
				\parbox{1.5cm}{
					\begin{raggedleft}
						\begin{tikzpicture}
							[bend angle=25, node distance=0.25cm,text height=1.5ex,
							place/.style={},
							pre/.style={<-,>=stealth'},
							post/.style={->,>=stealth'}]
							\node[place] (books) {};
							
							\node[place] (book1) [below=of books] {}
								edge [pre] (books);
							\node[place] (author1) [below=of book1] {}
								edge [pre] (book1);
						\end{tikzpicture}
					\end{raggedleft}
				}
			\end{raggedleft}
		\item Function call \texttt{start-element(title)}
		
			\begin{raggedleft}
				\parbox{3cm}{
					\begin{center}
						\begin{tabular}{ccc}
							&&\\
							&&\\
							&&\\
							&&\\
							\midrule
							\textsf{is}&\textsf{hs}&\textsf{ns}\\\bottomrule
						\end{tabular}
					\end{center}
				}
				\hspace{1cm}
				\parbox{1.5cm}{
					\begin{raggedleft}
						\begin{tikzpicture}
							[bend angle=25, node distance=0.25cm,text height=1.5ex,
							place/.style={},
							pre/.style={<-,>=stealth'},
							post/.style={->,>=stealth'}]
							\node[place] (books) {};
							
							\node[place] (book1) [below=of books] {}
								edge [pre] (books);
							\node[place] (author1) [below=of book1] {}
								edge [pre] (book1);
							\node[place] (title1) [below=of author1] {}
								edge [pre] (author1);
						\end{tikzpicture}
					\end{raggedleft}
				}
			\end{raggedleft}
		\item Function call \texttt{end-element()}
		
			\begin{raggedleft}
				\parbox{3cm}{
					\begin{center}
						\begin{tabular}{ccc}
							&&\\
							&&\\
							&&\\
							&&\\
							\midrule
							\textsf{is}&\textsf{hs}&\textsf{ns}\\\bottomrule
						\end{tabular}
					\end{center}
				}
				\hspace{1cm}
				\parbox{1.5cm}{
					\begin{raggedleft}
						\begin{tikzpicture}
							[bend angle=25, node distance=0.25cm,text height=1.5ex,
							place/.style={},
							pre/.style={<-,>=stealth'},
							post/.style={->,>=stealth'}]
							\node[place] (books) {};
							
							\node[place] (book1) [below=of books] {}
								edge [pre] (books);
							\node[place] (author1) [below=of book1] {}
								edge [pre] (book1);
							\node[place] (title1) [below=of author1] {}
								edge [pre] (author1);
						\end{tikzpicture}
					\end{raggedleft}
				}
			\end{raggedleft}
			\needspace{4\baselineskip}
		\item Function call \texttt{start-element(isbn)}
		
			\begin{raggedleft}
				\parbox{3cm}{
					\begin{center}
						\begin{tabular}{ccc}
								&			&\\
								&			&\\
								&			&\\
								&				&\\
								&	&\\
							\midrule
							\textsf{is}&\textsf{hs}&\textsf{ns}\\\bottomrule
						\end{tabular}
					\end{center}
				}
				\hspace{1cm}
				\parbox{1.5cm}{
					\begin{raggedleft}
						\begin{tikzpicture}
							[bend angle=25, node distance=0.25cm,text height=1.5ex,
							place/.style={},
							pre/.style={<-,>=stealth'},
							post/.style={->,>=stealth'}]
							\node[place] (books) {};
							
							\node[place] (book1) [below=of books] {}
								edge [pre] (books);
							\node[place] (author1) [below=of book1] {}
								edge [pre] (book1);
							\node[place] (title1) [below=of author1] {}
								edge [pre] (author1);
							\node[place] (isbn1) [below=of title1] {}
								edge [pre] (title1);
						\end{tikzpicture}
					\end{raggedleft}
				}
			\end{raggedleft}
		\item Function call \texttt{end-element()}
		
			\begin{raggedleft}
				\parbox{3cm}{
					\begin{center}
						\begin{tabular}{ccc}
								&			&\\
								&			&\\
								&			&\\

								&				&\\
								&	&\\
							\midrule
							\textsf{is}&\textsf{hs}&\textsf{ns}\\\bottomrule
						\end{tabular}
					\end{center}
				}
				\hspace{1cm}
				\parbox{1.5cm}{
					\begin{raggedleft}
						\begin{tikzpicture}
							[bend angle=25, node distance=0.25cm,text height=1.5ex,
							place/.style={},
							pre/.style={<-,>=stealth'},
							post/.style={->,>=stealth'}]
							\node[place] (books) {};
							
							\node[place] (book1) [below=of books] {}
								edge [pre] (books);
							\node[place] (author1) [below=of book1] {}
								edge [pre] (book1);
							\node[place] (title1) [below=of author1] {}
								edge [pre] (author1);
							\node[place] (isbn1) [below=of title1] {}
								edge [pre] (title1);
						\end{tikzpicture}
					\end{raggedleft}
				}
			\end{raggedleft}
		\item Function call \texttt{end-element()}
		
			\begin{raggedleft}
				\parbox{3cm}{
					\begin{center}
						\begin{tabular}{ccc}
								&				&\\
								&	&\\
							\midrule
							\textsf{is}&\textsf{hs}&\textsf{ns}\\\bottomrule
						\end{tabular}
					\end{center}
				}
				\hspace{1cm}
				\parbox{1.5cm}{
					\begin{raggedleft}
						\begin{tikzpicture}
							[bend angle=25, node distance=0.25cm,text height=1.5ex,
							place/.style={},
							pre/.style={<-,>=stealth'},
							post/.style={->,>=stealth'}]
							\node[place] (books) {};
							
							\node[place] (book1) [below=of books] {}
								edge [pre] (books);
							\node[place] (author1) [below=of book1] {}
								edge [pre] (book1);
							\node[place] (title1) [below=of author1] {}
								edge [pre] (author1);
							\node[place] (isbn1) [below=of title1] {}
								edge [pre] (title1);
						\end{tikzpicture}
					\end{raggedleft}
				}
			\end{raggedleft}
		\item Function call \texttt{start-element(book)}
		
			\begin{raggedleft}
				\parbox{3cm}{
					\begin{center}
						\begin{tabular}{ccc}
								&			&\\
								&				&\\
								&	&\\
							\midrule
							\textsf{is}&\textsf{hs}&\textsf{ns}\\\bottomrule
						\end{tabular}
					\end{center}
				}
				\hspace{1cm}
				\parbox{1.5cm}{
					\begin{raggedleft}
						\begin{tikzpicture}
							[bend angle=25, node distance=0.25cm,text height=1.5ex,
							place/.style={},
							pre/.style={<-,>=stealth'},
							post/.style={->,>=stealth'}]
							\node[place] (books) {};
							
							\node[place] (book1) [below=of books] {}
								edge [pre] (books);
							\node[place] (author1) [below=of book1] {}
								edge [pre] (book1);
							\node[place] (title1) [below=of author1] {}
								edge [pre] (author1);
							\node[place] (isbn1) [below=of title1] {}
								edge [pre] (title1);
								
							\node[place] (book2) [right=of book1] {}
								edge [pre] (book1);
						\end{tikzpicture}
					\end{raggedleft}
				}
			\end{raggedleft}
		\item Function call \texttt{start-element(book)}
		
			\begin{raggedleft}
				\parbox{3cm}{
					\begin{center}
						\begin{tabular}{ccc}
								&			&\\
								&			&\\
								&				&\\
								&	&\\
							\midrule
							\textsf{is}&\textsf{hs}&\textsf{ns}\\\bottomrule
						\end{tabular}
					\end{center}
				}
				\hspace{1cm}
				\parbox{1.5cm}{
					\begin{raggedleft}
						\begin{tikzpicture}
							[bend angle=25, node distance=0.25cm,text height=1.5ex,
							place/.style={},
							pre/.style={<-,>=stealth'},
							post/.style={->,>=stealth'}]
							\node[place] (books) {};
							
							\node[place] (book1) [below=of books] {}
								edge [pre] (books);
							\node[place] (author1) [below=of book1] {}
								edge [pre] (book1);
							\node[place] (title1) [below=of author1] {}
								edge [pre] (author1);
							\node[place] (isbn1) [below=of title1] {}
								edge [pre] (title1);
								
							\node[place] (book2) [right=of book1] {}
								edge [pre] (book1);
							\node[place] (author2) [below=of book2] {}
								edge [pre] (book2);
						\end{tikzpicture}
					\end{raggedleft}
				}
			\end{raggedleft}
	\end{enumerate}
	\end{multicols}
	}
	\caption{Content of the stacks after each call of the \texttt{start-element()} and \texttt{end-element()}, respectively, functions when parsing the tree from Fig.~\ref{fig:XmlDocumentTree}. In addition at each step their is a depiction of the binary tree which is constructed so far.}\label{fig:constructionOfBinaryTree}
\end{figure}
The binary representation of the input tree can be obtained in linear runtime since the function \verb|start-element| and the function \verb|end-element|, respectively, are each called only once for every node of the input tree. Furthermore, the body of the \verb|repeat| loop of the latter function is executed once for every input node (except for the root node).

\paragraph{Re-pair for Trees on Multiary Trees}\label{par:RemarksMultiaryModel}

Another way of modeling an XML document tree in a ranked way is the multiary tree model. In contrast to the binary tree model (which we described in Sect.~\ref{sec:binaryTreeModel} on page \pageref{sec:binaryTreeModel}), this model does not encode the input tree by a binary tree but it turns the input tree into a ranked tree by introducing a terminal symbol for each element type/number of children combination which occurs in the input tree. Let us assume that an element type occurs three times and that there are three different numbers of children attach to the corresponding elements. In the multiary tree model, there are introduced three different terminal symbols.

During our investigations we also evaluated a \trp version based on the multiary tree model. However, this modified version of our algorithm was outperformed by the original version in terms of compression ratio. This is due to the nature of typical XML documents. XML elements encountered in real-world XML documents often exhibit a long list of children elements. Therefore, compared to the binary tree model, a multiary tree model representation of an XML document leads to a higher number of different \tps occurring less often. This, in turn, reduces \trp's ability to compress the XML document tree by the same degree as it is possible for the binary case.
\begin{example}
Consider for example the XML document tree from Fig.~\ref{fig:XmlDocumentTree}. The element of type \verb|books| has five children elements of type , \ie, each of the five \tps

occurs only once. None of these \tps is replaced by TreeRePair since a replacement is only reasonable if the corresponding \tp occurs at least twice. In contrast, the binary tree model  leads to two occurrences of the \tp  which can be replaced by a new nonterminal symbol in a run of \trp (\cf Fig.~\ref{fig:binaryRepresentation}).
\end{example}



\subsection{Representing the Input Tree in Memory}\label{sec:representingTreeInMemory}


In this section we show that the ranked input tree of our algorithm can be efficiently stored as a DAG in memory. This DAG representation can be made nearly transparent to the rest of the algorithm (\cf Sect.~\ref{sec:impactDag} on page \pageref{sec:impactDag}).\footnote{Note that the DAG representation can also be circumvented by using the \texttt{-no\_dag} switch. In this case the whole binary tree with all its possible redundancy is constructed in main memory.} Thus, by default, the tree constructor of our prototype does not only directly transform the XML document tree into a ranked representation but also infers the corresponding minimal -bounded SLCF tree grammar , \ie, the minimal DAG, of the latter on the fly.

In \cite{Buneman03path} it has been demonstrated that the representation of XML document trees based on the concept of sharing subtrees is highly efficient. Their experiments have shown that in several cases the size of the DAG was less than 10\% of the uncompressed XML document tree. Therefore, the sharing of common subtrees enables us to load large XML documents trees which would have otherwise exceeded the computation resources. In addition to that it avoids time consuming swapping and the repetitive re-computation of the same results concerning subtrees that are shared.

Now, let us elaborate on how one can infer the DAG of the ranked representation  of the XML document tree. The tree constructor must check for every node which is removed from the hierarchy stack in the \verb|end-element| function if the subtree rooted at this node can be shared. This can be accomplished by calling the function \verb|share-subtree| listed in 
Fig.~\ref{lst:methodShareTree}. To better understand this function, let us assume that we want to check if the subtree  rooted at a node  can be shared. If we already encountered an exact copy of  while reading the input tree, all subtrees of  must have been shared before. Thus, the tree  must be of depth 1 and all children nodes must be labeled by nonterminals of the DAG grammar . Therefore, it is only necessary to compare the labels of the root of  and its direct children with those of all subtrees encountered until now. This can be done in constant time with the help of a hash table.

Now, let us assume that we have processed an exact copy of  earlier, \ie,  can be shared. Thus, the condition in line 3 is evaluated to \verb|true| and the \verb|subtrees_ht| hash table contains . Hence, the \verb|else|-part beginning in line 6 is processed. If there already exists a nonterminal  with right-hand side  then we set . We can check this in  time because with each entry of the hash table \verb|subtrees_ht| we can store a pointer to the corresponding production. Otherwise, \ie, if there exists no  with , we introduce a new nonterminal  with right-hand side  and replace the first occurrence  of the subtree  by . There can be only one earlier occurrence of the subtree  since otherwise we would already have inserted a corresponding production. Furthermore, we can guarantee constant time access to  because with each entry in the hash table \verb|subtrees_ht| we can store a pointer to the corresponding first occurrence. Finally, we add the subtree rooted at the node  to the hash table if all of its subtrees are shared. We do not need to insert the subtree rooted at the node  since we will process  in a later step (since we are traversing the input tree in postorder). In contrast, if  was not encountered until now, we add it to the hash table \verb|subtrees_ht| (line 5) in order to be able to share possible later occurrences of it.

Initially, \ie, after reading the input tree, all shared subtrees are of depth 1. In order to reduce the number of nonterminals of the DAG grammar (without increasing the number of total edges) all productions referenced only once are eliminated. All in all, the inferring of the DAG grammar needs linear time and can be conveniently combined with the step of transforming the input tree into a ranked tree.
\begin{figure}[tb]
\lstset{emph={FUNCTION,ENDFUNC,return,traverse,endtraverse,for,if,else,then,do,endif,endfor,repeat,endrepeat,times}, emphstyle=\bfseries, emph={[2]subtrees_ht}, emphstyle={[2]\slshape}, morecomment=[l]{//}}
\begin{lstlisting}{}
FUNCTION share-subtree((*@@*))
	let (*@@*) be the subtree rooted at (*@@*);
	if ((*@@*)) then
		if (subtrees_ht does not contain (*@@*)) then
			insert (*@@*) into subtrees_ht;
		else
			if ((*@@*)) then
				(*@@*);
			else
				choose nonterminal (*@@*);
				(*@@*); (*@@*);
				let (*@@*) be the node at which the first 
							occurrence of (*@@*) is rooted;
				replace subtree rooted at (*@@*) by (*@@*);
				
				(*@@*);
				if ((*@@*)) then
					let (*@@*) be the subtree rooted at (*@@*);
					insert (*@@*) into subtrees_ht;
				endif
			endif
			
			replace subtree rooted at (*@@*) by (*@@*);
		endif
	endif
ENDFUNC
\end{lstlisting}
\caption{The function \texttt{share-subtree} which checks for the subtree rooted at the node  if it can be shared. If this is the case then the sharing is performed.}\label{lst:methodShareTree}
\end{figure}

\subsection{Utilized Data Structures}

The data structures we use in our implementation are similar to those used in \cite{larsson2000off}. In order to be able to focus on the essentials, we do not pay attention to the fact that, internally, the input tree is represented by a DAG.

Let us assume that the binary input tree  has been generated by our implementation after reading a corresponding XML document tree. Hence, the tree  is the ranked representation of the latter. In main memory, every node  is represented by an object exhibiting several pointers. These allow constant time access to the parent and all children of the node  and to the possible next and previous occurrences of the \tp , where . The pointers to the next and previous occurrences of  form a doubly linked list of all the occurrences in . We call this type of list an \emph{occurrences list (of )} in the sequel.\footnote{During our investigations we also implemented a \trp version avoiding these doubly linked lists of occurrences. Instead, for every \tp, we used a hashed set storing pointers to all occurrences. However, this version had no benefits compared to the doubly linked list approach but lead to slightly longer runtimes. Considering the memory usage, in some cases it achieved better results while in others a substantial increase was noticed.} The specific order of the occurrences in an occurrences list is not relevant.

Every \tp is represented by a special object. It exhibits two pointers which reference the first and the last element of the corresponding occurrences list. Let us consider a \tp  with , where  and . Then the corresponding object exhibits two more pointers which point to the next and previous, respectively, \tp  with . These pointers form a doubly linked list of all \tps occurring  times. We denote this type of list the \emph{-th \tp list}. In contrast, all \tps  with  are organized in one doubly linked list which is called the \emph{top \tp list}.

These doubly linked lists of \tps are again referenced by a \emph{\tp priority queue}. This queue consists of  entries. The -th entry stores a pointer to the head of the -th \tp list, where . The -th entry references the head of the top \tp list. Refer to Sect.~\ref{sec:complexityReplacementStep} on page \pageref{sec:complexityReplacementStep} for an explanation on why we designed the \tp lists and priority queue as described above. Lastly, there is a \emph{\tp hash table} storing pointers to all occurring \tps. It allows constant time access to all \tps and therefore constant time access to the first occurrence of each \tp.

Let us consider the following example to see how the utilized data structures work.
\begin{figure}[t]
	\centering
	\begin{tikzpicture}[->,>=stealth',semithick]
		\tikzstyle{level 1}=[level distance=0.8cm, sibling distance=1.5cm]
		\tikzstyle{level 2}=[level distance=0.8cm, sibling distance=0.75cm]
		\tikzstyle{level 3}=[level distance=0.8cm, sibling distance=0.75cm]
		\tikzstyle{fan}=[anchor=north,isosceles triangle, shape border uses incircle,inner sep=0.5pt,shape border rotate=90,draw]

		\node {}
			child {node {}
				child {node {}}
				child {node {} [child anchor=north]
					child {node {}}
					child {node {}}
				}
			}
			child {node {}
				child {node {}}
				child {node {} [child anchor=north]
					child {node {}}
					child {node {}}
				}
			}
		;
	\end{tikzpicture}
	\caption{The tree   modeled by the node objects from Fig.~\ref{fig:dataStructures}.}\label{fig:dataStructuresTree}
\end{figure}
\begin{example}
	Let us assume that the tree  shown in Fig.~\ref{fig:dataStructuresTree} has been generated by our implementation after reading a corresponding XML document tree. Then Fig.~\ref{fig:dataStructures} shows a simplified depiction of the data structures used to efficiently replace the \tps in the replacement step. All non-null pointers are represented by arrows starting in a filled circle and ending in an empty circle. A filled circle without an outgoing arrow denotes a null pointer.
	
	With respect to Fig.~\ref{fig:dataStructures}, there is a total of  node objects representing tree nodes labeled by the two symbols  and . An instance of a tree node  is represented by a tabular box as it is shown in Fig.~\ref{fig:representationOfNode}. Unlike depicted, in our implementation a symbol is not directly stored within the node structure but for every unique symbol there is an object which is referenced by the corresponding nodes. The upper left empty circle of the box represents the memory address of the tree node instance. Thus, every arrow representing a pointer to the latter will end in this empty circle. 
\begin{figure}[t]
	\renewcommand{\subfigcapmargin}{-0.5cm}
	\hfill
	\subfigure[{A graphical representation of an object representing a tree node labeled by .}]{
		\begin{tikzpicture}[semithick,scale=0.095,text height=1.5ex,text depth=.25ex]
			\begin{scope}
			\draw (0,0) -- +(35,0) -- +(35,16) -- +(0,16) -- +(0,0);
			\draw (10,0) -- (10,16);
			\draw[thin] (27,0) -- (27,16);
			\draw[thin] (31,0) -- (31,12);
			\foreach \y/\name in {12/parent,8/children,4/next,0/previous} {
				\draw (10,\y) -- (35,\y);
				\draw (10,\y-0.5) node[anchor=south west] {\footnotesize\textsf{\name}};
			}
			\draw (5,8) node[anchor=center] {\Large };
		
			\begin{scope}[darkgray]
				\fill (31,14) circle (0.75);
				\fill (29,10) circle (0.75);
				\fill (33,10) circle (0.75);
				\fill (29,6) circle (0.75);
				\fill (33,6) circle (0.75);
				\fill (29,2) circle (0.75);
				\fill (33,2) circle (0.75);
			\end{scope}
		
			\filldraw[draw=black,fill=white] (0,16) circle (1);
			\end{scope}
		\end{tikzpicture}
		\label{fig:representationOfNode}
	}
	\hfill
	\subfigure[{A graphical representation of a \tp .}]{
		\begin{tikzpicture}[semithick,scale=0.095,text height=1.5ex,text depth=.25ex]
			\draw (0,0) -- (26,0) -- (26,14) -- (0,14) -- (0,0);
			\draw (0,4) -- (26,4);
			\draw (0,8) -- (26,8);
			
			\filldraw[fill=white,draw=black] (0,14) circle (1);
	
			\draw (13,11) node {};

			\draw (13,0) -- (13,8);
			\draw[thin] (9,0) -- (9,8);
			\draw[thin] (22,0) -- (22,8);
	
			\draw (0-0.5,4-0.5) node[anchor=south west] {\footnotesize\textsf{prev}};
			\draw (13-0.5,4-0.5) node[anchor=south west] {\footnotesize\textsf{next}};
			\draw (0-0.5,0-0.5) node[anchor=south west] {\footnotesize\textsf{first}};
			\draw (13-0.5,0-0.5) node[anchor=south west] {\footnotesize\textsf{last}};
			
			\begin{scope}[darkgray]
				\fill (11,6) circle (0.75);	
				\fill (24,6) circle (0.75);	
				\fill (11,2) circle (0.75);	
				\fill (24,2) circle (0.75);
			\end{scope}
		\end{tikzpicture}
		\label{fig:representationOfPair}
	}
	\hfill
\end{figure}
The filled circle in the first row of the tabular box represents the pointer to the possible parent node . The pointer to the -th child  of the node  is depicted by an arrow starting at the filled circle in the -th column of the \verb|children| row, where . Analogously, a pointer to a possible next (previous) occurrence of the \tp  is represented by a filled circle in the -th column of the row labeled by \verb|next| (\verb|previous|, respectively), where .
	
	Each \tp , ,  and  is represented by a tabular box (see Fig.~\ref{fig:representationOfPair}). Again, unlike depicted, in our implementation a symbol is not directly stored within the \tp structure but the latter contains two pointers to the objects representing  and .
	The first and the last element of the occurrences list of the \tp  are referenced by the \verb|first| and \verb|last| pointers of the object representing the \tp . The pointers \verb|prev| (previous) and \verb|next| are part of the -th \tp list if  and . Otherwise they belong to the top \tp list.
	
	The \tp  forms a trivial doubly linked list, namely, the 1st \tp list. The latter is referenced by the entry  of the priority queue. The \tp  forms the (trivial) top \tp list which is referenced by the entry  of the priority queue. In contrast, the \tps  and  each occur twice and therefore point to each other with their \texttt{next} and \texttt{previous} pointers, respectively. The first element of the resulting 2nd \tp list is referenced by the entry  of the priority queue. The \tp hash table stores the pointers to all four occurring \tps.
\end{example}

\begin{figure}[p]
\vspace{-0.5cm}
	\hspace{-4.2cm}
\begin{tikzpicture}[semithick,scale=0.095,text height=1.5ex,text depth=.25ex]
	
\filldraw[fill=black!15,draw=black!20] (60,35) -- (110,35) -- (110,130) -- (60,130) -- (60,35);
		\draw (85,125) node[anchor = north] { \ltp Hash Table };
		
		\begin{scope}[xshift=74cm,yshift=40cm]
			\draw (0,0) -- (22,0) -- (22,75) -- (0,75) -- (0,0);
			\draw[thin] (6,0) -- (6,75);
			
			\foreach \y/\pair in { 14/{},20/{(f,2,f)}, 30/{}, 36/{(f,1,a)}, 42/{(f,1,f)}, 56/{}, 62/{(f,2,a)} } {
				\draw (0,\y) -- (22,\y);
				\draw (14,\y - 3) node[anchor=center] {};
			}
			
			\draw[dotted] (14,2) -- (14,12);
			\draw[dotted] (14,22) -- (14,28);
			\draw[dotted] (14,44) -- (14,54);
			\draw[dotted] (14,64) -- (14,73);



			\draw (3,42 - 3) node[inner sep=0pt] (ht1pointer) {};
			\fill[darkgray] (3,42 - 3) circle (0.75);
			
			\draw (3,62 - 3) node[inner sep=0pt] (ht2pointer) {};
			\fill[darkgray] (3,62 - 3) circle (0.75);
			
			\draw (3,20 - 3) node[inner sep=0pt] (ht3pointer) {};
			\fill[darkgray] (3,20 - 3) circle (0.75);
			
			\draw (3,36 - 3) node[inner sep=0pt] (ht4pointer) {};
			\fill[darkgray] (3,36 - 3) circle (0.75);
		\end{scope}
	
\filldraw[fill=black!15,draw=black!20] (-70,100) -- (55,100) -- (55,130) -- (-70,130) -- (-70,100);
		\draw (-65,125) node[anchor = north west] { \ltp Priority Queue };
		
		\begin{scope}[xshift=-62.5cm,yshift=106cm]
			\draw (0,0) -- (108,0) -- (108,10) -- (0,10) -- (0,0);
			\draw (0,4)[thin] -- (108,4);
			\foreach \x/\number/\name in {36/1/1,72/2/2,108/3/\geq3} {
				\draw (\x,0) -- (\x,10);
				\draw (\x-18,7) node[anchor=center] {\large };
				\draw (\x-18,2) node[inner sep=0pt] (queue\number pointer) {};
				\fill (\x-18,2) circle (0.75);
			}
		\end{scope}
	
\filldraw[fill=black!15,draw=black!20] (-70,35) -- (55,35) -- (55,95) -- (-70,95) -- (-70,35);
		\draw (-65,40) node[anchor = south west] { Doubly Linked \ltps };
				
		\fill[fill=black!3] (-60,48) -- (-30,48) -- (-30,88) -- (-60,88) -- (-60,48);
		\fill[fill=black!3] (-23,48) -- (7,48) -- (7,88) -- (-23,88) -- (-23,48);
		\fill[fill=black!3] (14,48) -- (44,48) -- (44,88) -- (14,88) -- (14,48);
		
		\foreach \xshift/\yshift/\name/\pair in
		 {-58/72/pair1/{(f,1,f)},-21/72/pair2/{(f,2,a)},
		 -21/50/pair3/{(f,2,f)},16/72/pair4/{(f,1,a)}} {
			\begin{scope}[xshift=\xshift cm,yshift=\yshift cm]
				\draw (0,0) -- (26,0) -- (26,14) -- (0,14) -- (0,0);
				\draw (0,4) -- (26,4);
				\draw (0,8) -- (26,8);
				
				\draw (0,14) node[inner sep=2] (\name address) {};
				\filldraw[fill=white,draw=black] (0,14) circle (1);
		
				\draw (13,11) node {};

				\draw (13,0) -- (13,8);
				\draw[thin] (9,0) -- (9,8);
				\draw[thin] (22,0) -- (22,8);
	
				\draw (0-0.5,4-0.5) node[anchor=south west] {\footnotesize\textsf{prev}};
				\draw (13-0.5,4-0.5) node[anchor=south west] {\footnotesize\textsf{next}};
				\draw (0-0.5,0-0.5) node[anchor=south west] {\footnotesize\textsf{first}};
				\draw (13-0.5,0-0.5) node[anchor=south west] {\footnotesize\textsf{last}};
			
				\begin{scope}[darkgray]
				\draw (11,6) node[inner sep=0pt] (\name prev) {};
				\fill (11,6) circle (0.75);	
				\draw (24,6) node[inner sep=0pt] (\name next) {};
				\fill (24,6) circle (0.75);	
				\draw (11,2) node[inner sep=0pt] (\name first) {};
				\fill (11,2) circle (0.75);	
				\draw (24,2) node[inner sep=0pt] (\name last) {};
				\fill (24,2) circle (0.75);
				\end{scope}
			\end{scope}
		}
		
\begin{scope}[->,>=stealth',darkgray,shorten >=-4pt]
			\draw (ht1pointer) .. controls +(-20,30) and +(5,20) .. (pair1address);
			\draw (ht2pointer) .. controls +(-20,10) and +(5,10) .. (pair2address);
			\draw (ht3pointer) .. controls +(-20,10) and +(5,5) .. (pair3address);
			\draw (ht4pointer) .. controls +(-20,20) and +(5,10) .. (pair4address);
		\end{scope}
		
\begin{scope}[->,>=stealth',darkgray,dashed]
			\draw (queue1pointer) .. controls +(10,-10) and +(-10,10) .. (pair1address);
			\draw (queue2pointer) .. controls +(10,-10) and +(-10,10) .. (pair2address);
			\draw (queue3pointer) .. controls +(10,-10) and +(-10,10) .. (pair4address);
		\end{scope}
		
\begin{scope}[->,>=stealth',darkgray,densely dotted]
			\draw (pair3prev) .. controls +(-22,-12) and +(-8,5) .. (pair2address);
			\draw (pair2next) .. controls +(20,-15) and +(-15,10) .. (pair3address);
		\end{scope}

\filldraw[fill=black!15,draw=black!20] (-70,30) -- (110,30) -- (110,-100) -- (-70,-100) -- (-70,30);
		
\fill[fill=black!3] (-14,-23) -- (47,-23) -- (17,8) -- (-14,-23);
		\fill[fill=black!3] (-43,-54) -- (-3,-54) -- (-14,-23) -- (-43,-54);
		\fill[fill=black!3] (36,-54) -- (77,-54) -- (47,-23) -- (36,-54);
		\fill[fill=black!3] (-39,-85) -- (1,-85) -- (-3,-54) -- (-39,-85);
		\fill[fill=black!3] (46,-85) -- (86,-85) -- (77,-54) -- (46,-85);
		
\draw (-65,25) node[anchor=north west] { Tree Nodes };
	
\foreach \xshift/\yshift/\name/\symbol in {0/0/node1/f,-30/-31/node2/f,30/-31/node3/f,-20/-62/node5/f,60/-62/node7/f} {
			\begin{scope}[xshift=\xshift cm,yshift=\yshift cm]
				\draw (0,0) -- +(35,0) -- +(35,16) -- +(0,16) -- +(0,0);
				\draw (10,0) -- (10,16);
				\draw[thin] (27,0) -- (27,16);
				\draw[thin] (31,0) -- (31,12);
				\foreach \y/\name in {12/parent,8/children,4/next,0/previous} {
					\draw (10,\y) -- (35,\y);
					\draw (10,\y-0.5) node[anchor=south west] {\footnotesize\textsf{\name}};
				}
				\draw (5,8) node[anchor=center] {\Large };
			
				\begin{scope}[darkgray]
				\draw (31,14) node[inner sep=0pt] (\name parent) {};
				\fill (31,14) circle (0.75);
				\draw (29,10) node[inner sep=0pt] (\name child1) {};
				\fill (29,10) circle (0.75);
				\draw (33,10) node[inner sep=0pt] (\name child2) {};
				\fill (33,10) circle (0.75);
				\draw (29,6) node[inner sep=0pt] (\name next1) {};
				\fill (29,6) circle (0.75);
				\draw (33,6) node[inner sep=0pt] (\name next2) {};
				\fill (33,6) circle (0.75);
				\draw (29,2) node[inner sep=0pt] (\name prev1) {};
				\fill (29,2) circle (0.75);
				\draw (33,2) node[inner sep=0pt] (\name prev2) {};
				\fill (33,2) circle (0.75);
				\end{scope}
			
				\draw (0,16) node[inner sep=2] (\name address) {};
				\filldraw[fill=white,draw=black] (0,16) circle (1);
				
				\draw (0,0) node[inner sep=0pt] (\name southwest) {};
				\draw (35,0) node[inner sep=0pt] (\name southeast) {};
				\draw (35,16) node[inner sep=0pt] (\name northeast) {};
				\draw (0,16) node[inner sep=0pt] (\name northwest) {};
			\end{scope}
		}
		
\foreach \xshift/\yshift/\name/\symbol in {-60/-62/node4/a,20/-62/node6/a,-55/-93/node8/a,-15/-93/node9/a,30/-93/node10/a,70/-93/node11/a} {
			\begin{scope}[xshift=\xshift cm,yshift=\yshift cm]
				\draw (0,0) -- +(35,0) -- +(35,16) -- +(0,16) -- +(0,0);
				\draw (10,0) -- (10,16);
				\draw[thin] (27,12) -- (27,16);
\foreach \y/\name in {12/parent} {
					\draw (10,\y) -- (35,\y);
					\draw (10,\y-0.5) node[anchor=south west] {\footnotesize\textsf{\name}};
				}
				\draw (5,8) node[anchor=center] {\Large };
			
				\draw (31,14) node[inner sep=0pt] (\name parent) {};
				\fill (31,14) circle (0.75);
			
				\draw (0,16) node[inner sep=2] (\name address) {};
				\filldraw[fill=white,draw=black] (0,16) circle (1);
			\end{scope}
		}
		
\begin{scope}[->,>=stealth',darkgray]
			\draw (node2parent) .. controls +(-5,15) and +(-30,-30) .. (node1address);
			\draw (node3parent) .. controls +(-10,20) and +(-40,-40) .. (node1address);
			\draw (node4parent) .. controls +(-5,15) and +(-30,-30) .. (node2address);
			\draw (node5parent) .. controls +(-10,20) and +(-40,-40) .. (node2address);
			\draw (node6parent) .. controls +(-5,15) and +(-30,-30) .. (node3address);
			\draw (node7parent) .. controls +(-10,20) and +(-40,-40) .. (node3address);
			
			\begin{scope}[shorten >=-4pt]
				\draw (node8parent) .. controls +(7.5,10) and +(-7.5,-25) .. (node5address);
				\draw (node9parent) .. controls +(-5,15) and +(-11,-40) .. (node5address);
				\draw (node10parent) .. controls +(7.5,10) and +(-7.5,-25) .. (node7address);
				\draw (node11parent) .. controls +(-5,15) and +(-11,-40) .. (node7address);
			\end{scope}
		\end{scope}
		
\begin{scope}[->,>=stealth',gray,densely dotted]
			\draw (node1child1) .. controls +(50,-30) and +(-35,20) .. (node2address);
			\draw (node1child2) .. controls +(38,-25) and +(-25,15) .. (node3address);
			\draw (node2child1) .. controls +(50,-30) and +(-35,20) .. (node4address);
			\draw (node2child2) .. controls +(38,-25) and +(-25,15) .. (node5address);
			\draw (node3child1) .. controls +(50,-30) and +(-35,20) .. (node6address);
			\draw (node3child2) .. controls +(38,-25) and +(-25,15) .. (node7address);
			
			\draw (node5child1) .. controls +(50,-30) and +(-35,20) .. (node8address);
			\draw (node5child2) .. controls +(38,-25) and +(-25,15) .. (node9address);
			\draw (node7child1) .. controls +(50,-30) and +(-35,20) .. (node10address);
			\draw (node7child2) .. controls +(38,-25) and +(-25,15) .. (node11address);
		\end{scope}
		
\begin{scope}[->,>=stealth',darkgray,densely dashed]
\draw (node5next2) .. controls +(10,-10) and +(-10,15) .. (node7address);
			\draw (node7prev2) .. controls +(10,-20) and +(-10,15) .. (node5address);
			
\draw (node2next2) .. controls +(15,-15) and +(-15,15) .. (node3address);
			\draw (node3prev2) .. controls +(-50,-30) and +(50,30) .. (node2address);
			
\draw (node2next1) .. controls +(38,-25) and +(-15,15) .. (node5address);
			\draw (node5prev1) .. controls +(-60,-25) and +(-15,15) .. (node2address);
			
			\draw (node5next1) .. controls +(38,-25) and +(-15,15) .. (node3address);
			\draw (node3prev1) .. controls +(-10,-15) and +(-35,20) .. (node5address);
			
			\draw (node3next1) .. controls +(38,-25) and +(-15,15) .. (node7address);
			\draw (node7prev1) .. controls +(40,15) and +(20,25) .. (node3address);
		\end{scope}
		
\begin{scope}[->,>=stealth',darkgray]
\draw (pair1first) .. controls +(25,-20) and +(-35,5) .. (node1address);
			\draw (pair1last) .. controls +(15,-20) and +(-35,5) .. (node1address);
			
\draw (pair2first) .. controls +(90,-24) and +(-90,40) .. (node5address);
			\draw (pair2last) .. controls +(15,-5) and +(60,15) .. (node7address);
			
\draw (pair3first) .. controls +(-15,-20) and +(20,5) .. (node2address);
			\draw (pair3last) .. controls +(-15,-20) and +(60,40) .. (node3address);
			
\draw (pair4first) .. controls +(25,-20) and +(-35,5) .. (node2address);
			\draw (pair4last) .. controls +(-5,-25) and +(60,15) .. (node7address);
		\end{scope}
	\end{tikzpicture}
\caption{A simplified depiction of a part of the data structures used by our implementation.}\label{fig:dataStructures}
\end{figure}

\subsection{Complexity of the \trp Algorithm}\label{sec:complexityReplacementStep}

\begin{theorem}
For any given input tree with  edges, \trp produces in time
 a -bounded linear SLCF tree grammar
, where  is a constant,  
is the binary representation of the input tree, and
. 
\end{theorem}
It is straightforward to come up with a linear time implementation of the pruning step of the Re-pair for Trees algorithm (\cf Sect.~\ref{sec:pruningStep} on page \pageref{sec:pruningStep}). Therefore, we just want to investigate the complexity of the replacement step which was described in Sect.~\ref{sec:replacementStep} on page \pageref{sec:replacementStep}.

With every replacement of a \tp occurrence one edge of the input tree is absorbed. Therefore, a run of \trp can consist of at most  iterations, where  is the size of the input tree. Each replacement of an occurrence can be accomplished in  time since at most  children need to be reassigned --- in our implementation, the reassignment of a child node is just a matter of updating two pointers.\footnote{As already mentioned at the beginning of this section on page \pageref{ch:implementationDetails}: The maximal rank of a nonterminal of a grammar generated by \trp is . The constant  can be specified by a command line switch.} For every production which is introduced during a run of our algorithm it holds that the right-hand side  is of size , \ie, it can be constructed in constant time. 

However, to show that the replacement step can be performed in linear time two more aspects need to be considered. Imagine that we are in the -th iteration of our algorithm (and  is the current grammar). Let  be the right-hand side of 's start production.
\begin{enumerate}[(1)]
	\item \emph{Updating the sets of non-overlapping occurrences}
	
		In every iteration of our algorithm we need to know the number of occurrences of each \tp. Only in that case we are able to determine the most frequent \tp. In addition, for replacing the \tp , we need to know . How can we compute the set  for every \tp  without traversing the whole right-hand side of the current start production in each iteration?
	\item \emph{Retrieving the most frequent \tp} 
	
		Let us assume that there is an up to date set  available for every  occurring in  (in the form of occurrences lists). How do we determine the most frequent \tp in constant time?
\end{enumerate}
In the following we consider each of the above aspects in detail.

\subsubsection{Updating the Sets of Non-overlapping Occurrences}

Let the binary tree  be our input tree. At the beginning of the replacement step the set  for every \tp  occurring in  is initially constructed. This is done by parsing the tree  in a similar way as it is done in the function \texttt{retrieve-occurrences} which is listed in Fig.~\ref{lst:functionRetrieveOccurrences}. However, during the traversal not only one \tp is considered but for every encountered \tp  the set  is constructed. Fig.~\ref{lst:functionRetrieveAllOccs} shows a possible function which accomplishes this task.
\begin{figure}[tb]
	\lstset{emph={FUNCTION,ENDFUNC,return,for,if,else,then,do,endif,endfor,while,endwhile}, emphstyle=\bfseries,morecomment=[l]{//},commentstyle=\color{gray}}
	\begin{lstlisting}
FUNCTION retrieve-all-occs((*@@*))
	(*@@*);
	while (true) do
		(*@@*)next_in_postorder((*@@*), (*@@*));
		if ((*@@*)) then
			(*@@*);
			if ((*@@*)) then
				(*@@*)
			endif
		else
			return;
		endif
	endwhile
ENDFUNC
	\end{lstlisting}
	\caption{The function \texttt{retrieve-all-occs} which is used to construct the set  for every \tp  occurring in the tree . It uses the function \texttt{next-in-postorder} listed in Fig.~\ref{lst:traversalAlgorithm}.}\label{lst:functionRetrieveAllOccs}
\end{figure}

Therefore, in the first iteration of our computation we have up to date sets of non-overlapping occurrences at hand. However, we cannot afford to redo this traversal in every subsequent iteration. In this case we would not be able to achieve a linear runtime of our algorithm.

Fortunately, there is another way of keeping track of the sets of non-overlapping occurrences. It relies on the fact that every replacement of an \tp occurrence  only involves those occurrences in the neighborhood of  which overlap with .
\begin{example}
	Let us consider the tree  which is depicted in Fig.~\ref{fig:absorbedOccurrences}. The occurrences which would be absorbed by the replacement of the occurrence  of the \tp  are highlighted.
\end{example}
For every \tp  we set  and base all upcoming computations on the set . In particular we use them to determine the most frequent \tp in each iteration. 

Let us consider the -th iteration of a run  of Re-pair for Trees on the input tree , where  and . Then  is the current grammar. Let  be the right-hand side of . Let us assume that an up to date set  for every  which is occurring in  is at hand. Further, let us assume that  and let .

\begin{figure}[tb]
	\centering\small
	\pgfdeclarelayer{background layer}
	\pgfsetlayers{background layer,main}
	\begin{tikzpicture}[semithick,level distance=1.3cm,sibling distance=0.75cm,text height=1.5ex,scale=0.9]
		\tikzstyle{fan}=[anchor=north,isosceles triangle, shape border uses incircle,inner sep=0.5pt,shape border rotate=90,draw]
		
		\begin{scope}[->,>=stealth']
		\node (epsilon) {}
			child[sibling distance=4cm] {node (1) {}
				child[sibling distance=1cm] {node (11) {}}
				child[sibling distance=1cm] {node (12) {}}
				child[sibling distance=1cm] {node (12) {}}
				child[sibling distance=1cm] {node (12) {}}
			}
			child {node (2) {} child {node[outer sep=3pt] (21) {}
					child[sibling distance=1.5cm] {node[outer sep=2pt] (211) {}
						child[sibling distance=1cm] {node (2111) {}}
						child[sibling distance=1cm] {node (2112) {} }
						child[sibling distance=1cm] {node (2113) {} }
					}
					child[sibling distance=1.5cm] {node (212) {}}
					child[sibling distance=1cm] {node[outer sep=2pt] (213) {}
						child {node (2131) {}}
						child {node (2132) {} }
						child {node (2133) {} }
					}
					child[missing] {node {}}
					child {node (214) {} }
				}
				child[sibling distance=1cm] {node (22) {}}
			}
			child[sibling distance=3cm] {node (3) {}
				child[sibling distance=1cm] {node (31) {}}
				child[sibling distance=1cm] {node[outer sep=2pt] (32) {}
					child {node (321) {}}
					child {node (322) {} }
					child {node (323) {} }
				}
			}
		;
		\end{scope}
		
		\begin{pgfonlayer}{background layer}
			\begin{scope}[rounded corners,fill=black!10,draw=gray,dashed]
\filldraw[fill=black!10!white] ([xshift=6pt,yshift=7pt] 2.center) -- ([xshift=-3pt,yshift=7pt] 2.center) -- ([xshift=-5pt,yshift=5pt] 21.center) -- ([xshift=-10pt,yshift=2pt] 211.center) -- ([xshift=-10pt,yshift=-5pt] 211.center) -- ([xshift=-9pt,yshift=-5pt] 213.center) -- ([xshift=-7pt,yshift=0pt] 2131.center) -- ([xshift=-7pt,yshift=-5pt] 2131.center) -- ([xshift=7pt,yshift=-5pt] 2133.center) -- ([xshift=7pt,yshift=0pt] 2133.center) -- ([xshift=9pt,yshift=-5pt] 213.center) -- ([xshift=10pt,yshift=-5pt] 214.center) -- ([xshift=10pt,yshift=2pt] 214.center) -- ([xshift=6pt,yshift=5pt] 21.center) -- cycle;
			\end{scope}
		\end{pgfonlayer}		
	\end{tikzpicture}
	\caption{The tree . All occurrences which would be absorbed by the replacement are highlighted.}\label{fig:absorbedOccurrences}
\end{figure}
\begin{figure}[tb]
	\lstset{emph={FUNCTION,ENDFUNC,return,traverse,endtraverse,for,if,else,then,do,endif,endfor,repeat,endrepeat,times}, emphstyle=\bfseries, emph={[2]subtrees_ht}, emphstyle={[2]\slshape}, morecomment=[l]{//}}
	\begin{lstlisting}
FUNCTION remove-absorbed-occs((*@@*))
	if ((*@@*)) then
		(*@@*);
		(*@@*);
	endif
	
	for ((*@@*)) do
		(*@@*);
		(*@@*);
	endfor
	
	for ((*@@*)) do
		(*@@*);
		(*@@*);
	endfor
ENDFUNC	
	\end{lstlisting}
	\caption{Listing of the function \texttt{remove-absorbed-occs} which removes all absorbed occurrences from the  sets.}\label{lst:remove-absorbed-occs}
\end{figure}
\begin{figure}[tb]
\lstset{emph={FUNCTION,ENDFUNC,return,traverse,endtraverse,for,if,else,then,do,endif,endfor,repeat,endrepeat,times}, emphstyle=\bfseries, emph={[2]subtrees_ht}, emphstyle={[2]\slshape}, morecomment=[l]{//}}
	\begin{lstlisting}
FUNCTION add-new-occs((*@@*))
	if ((*@@*)) then
		(*@@*);
		(*@@*);
	endif
	
	for ((*@@*)) do
		(*@@*);
		(*@@*);
	endfor
ENDFUNC	
	\end{lstlisting}
	\caption{Listing of the function \texttt{add-new-occs} which adds all newly created occurrences to the  sets.}\label{lst:add-new-occs}
\end{figure}
Before the actual replacement of the occurrence  we make use of the function listed in Fig.~\ref{lst:remove-absorbed-occs}. The function call \texttt{remove-absorbed-occs(}\texttt{)} removes all occurrences which will be absorbed by the upcoming replacement from the sets . After the replacement of  by a new node  with  we call the function \verb|add-new-occs| (which is listed Fig.~\ref{lst:add-new-occs}) and pass the tree  and the node . The function \verb|add-new-occs| adds all new occurrences which arose by the introduction of  to the sets of non-overlapping occurrences. Finally, after all occurrences from  have been replaced, we set  for all  occurring in .

Let  be a \tp occurring in . The above computed set  may not be equal to the actual set  as it would be constructed by a complete postorder traversal of  using the function \texttt{retrieve-occurrences} from Fig.~\ref{lst:functionRetrieveOccurrences}. 
\begin{example}
Consider, for instance, the tree  depicted in Fig.~\ref{fig:treeComputationOccSets}. Let . In the first iteration of our algorithm, we would obtain . Now, let us assume that we replace the \tp  (we could easily enlarge  such that  is the most frequent \tp and still show the same). After performing this replacement and especially after calling the functions \verb|remove-absorbed-occs| and \texttt{add-new-occs} we would have . However, a postorder traversal of the updated tree  would result in . 
\end{example}
\begin{figure}[t]
	\centering
	\begin{tikzpicture}[->,>=stealth',semithick,level distance=0.8cm, sibling distance=1.5cm]
		\tikzstyle{fan}=[anchor=north,isosceles triangle, shape border uses incircle,inner sep=0.5pt,shape border rotate=90,draw]
			
		\node {} child {node {}}
			child {node {}
				child {node {}}
				child {node {}
					child {node {}}
					child {node {}}
				}
			}
		;
	\end{tikzpicture}
	\caption{Tree  consisting of nodes labeled by the terminal symbols . We have to deal with three overlapping occurrences of the \tp .}\label{fig:treeComputationOccSets}
\end{figure}
Updating the sets of non-overlapping occurrences
takes constant time per occurrence replacement. At most 
occurrences need to be removed by the function 
\texttt{remove-absorbed-occs} and at most 
occurrences need to be added by the function \texttt{add-new-occs}. An
occurrence  of a \tp  can be removed from the occurrences
list of  in constant time by setting the \verb|next| and
\verb|previous| pointers of the corresponding node object to null. In
addition, if  is the first (last) occurrence in the occurrence list
of  the \verb|first| (\verb|last|) pointer of the object
representing the \tp  needs to be updated. This can also be
accomplished in constant time by using the \tp hash table. 
Analogously, an occurrence can be added to an occurrences list in  time.

\subsubsection{Retrieving the Most Frequent \ltp}

We now investigate the time needed to obtain the most frequent \tp in an iteration of our algorithm. First of all, let us state the following fact: Let  and let  be a run of Re-pair for Trees, where ,  and  for every . Then

holds for every .\footnote{Intuitively, we define  if .} For every \tp  occurring in  it holds that  and for every \tp  which was introduced in  it holds that , where .

It is easy to see that, if the top \tp list is empty, we can obtain the most frequent \tp in constant time. We just need to walk down the remaining  \tp lists and choose the first element of the first non-empty list. In every iteration, after we have determined the most frequent \tp, we remember the first non-empty \tp list in order to save ourself the needless and time-consuming rechecking of the empty \tp lists.

Now, let us assume that the top \tp list, \ie, the doubly linked list of all \tps occurring at least  times, is not empty. We need to scan all elements in it since the \tps contained are not ordered by their frequency. There can be roughly at most  \tps in the top \tp list. Therefore, we need roughly  time to retrieve the most frequent \tp. However, by the replacement of this \tp at least  edges are absorbed. It is easy to see that, all in all, obtaining the most frequent \tp needs constant time on average.

In a run of \trp we can replace at most  \tp occurrences and, as shown before, the replacement of each occurrence, the update of the sets of non-overlapping occurrences and the determination of the most frequent pair can be accomplished in constant time per occurrence replacement. Thus, the whole replacement step can be completed in linear time.

\subsection{Impact of the DAG Representation}\label{sec:impactDag}

In the preceding section, dealing with the complexity of our implementation of the Re-pair for Trees algorithm, we did not pay attention to the underlying DAG representation of the input tree. This enabled us to concentrate on the essentials. Nevertheless, we have to clarify the impact of this representation, particularly concerning the compression performance and the runtime of our implementation, since \trp uses it by default. Only by starting \trp with the \texttt{-no\_dag} switch it forgos the DAG representation and loads the whole input tree into main memory.


Let  be a -bounded SLCF tree grammar. We assume without loss of generality that for every  it holds that . Let ,  and . We define the function \texttt{unfold} using the algorithm listed in Fig.~\ref{lst:functionUnfold}.
It holds that  and it also holds that

Let us consider a run  of \trp, where , ,  and . Then, in our implementation,  is represented by a \mbox{-bounded} (linear) SLCF tree grammar , \ie, we have , by default.

\begin{figure}[tb]	\lstset{emph={FUNCTION,ENDFUNC,return,traverse,endtraverse,for,if,else,then,do,endif,endfor,repeat,endrepeat,times}, emphstyle=\bfseries, emph={[2]subtrees_ht}, emphstyle={[2]\slshape}, morecomment=[l]{//}}
	\begin{lstlisting}
FUNCTION unfold((*@@*))
	let (*@@*) and (*@@*);
	if (*@@*) then
		(*@@*);
		for each (*@@*) do
			(*@@*);
		endfor
	else
		(*@@*);
	endif
	return (*@@*);
ENDFUNC
	\end{lstlisting}
	\caption{The algorithm which computes , where we have  and .}\label{lst:functionUnfold}
\end{figure}
\begin{figure}[tb]
	\lstset{emph={FUNCTION,ENDFUNC,return,for,if,else,then,do,endif,endfor,while,endwhile}, emphstyle=\bfseries,morecomment=[l]{//},commentstyle=\color{gray}}
	\begin{lstlisting}
FUNCTION retrieve-all-occs-dag((*@@*))
	(*@@*);
	while (true) do
		(*@@*)next_in_postorder((*@@*), (*@@*));
		if ((*@@*)) then
			if ((*@@*)) then
				(*@@*);
				if ((*@@*)) then
					(*@@*);
				endif
			else
				let (*@@*) be the right-hand side of (*@@*);
				if ((*@@*) then
					(*@@*);
					(*@@*);
				endif
			endif
		else
			return;
		endif
	endwhile
ENDFUNC
	\end{lstlisting}
	\caption{The function \texttt{retrieve-all-occs} listed in Fig.~\ref{lst:functionRetrieveAllOccs} adapted for the DAG case. For every  the set  is initially set to .}\label{lst:functionRetrieveAllOccsDAG}
\end{figure}

\subsubsection{Constructing the Sets of Non-overlapping Occurrences} 

In the first iteration of Tree\-Re\-Pair we need to construct the set  for every \tp  occurring in . Our first try to accomplish this could be a postorder traversal of all the right-hand sides of 's productions using the function \texttt{retrieve-all-occs} listed in Fig.~\ref{lst:functionRetrieveAllOccs} on page \pageref{lst:functionRetrieveAllOccs}. However, when traversing the right-hand sides of the DAG grammar  individually, we do not consider occurrences spanning two productions of the DAG.
\begin{figure}[t]
	\centering
	\begin{tikzpicture}[->,>=stealth',semithick]
		\tikzstyle{level 1}=[level distance=0.8cm, sibling distance=1.5cm]
		\tikzstyle{level 2}=[level distance=0.8cm, sibling distance=0.5cm]
		\node {}
			child {node {}
				child {node {}}
				child {node {}}
				child {node {}}
			}
			child {node {}
				child {node {}}
				child {node {}}
				child {node {}}
			}
		;
	\end{tikzpicture}
	\caption{The tree  which can be represented by a DAG grammar with productions  and .}\label{fig:missedOccurrences}
\end{figure}
\begin{example}
Consider the DAG grammar , where  and  contains the two productions  and . It is a compressed representation of the tree  depicted in Fig.~\ref{fig:missedOccurrences}. If we would use the function \texttt{retrieve-all-occs} to determine all \tp occurrences in the right-hand sides of 's productions, we would not capture the node  which is an occurrence for both the \tp  and the \tp .
\end{example}
As we have seen, it is necessary to modify the \texttt{retrieve-all-occs} function slightly to also take occurrences spanning two productions into account. We use the algorithm listed in Fig.~\ref{lst:functionRetrieveAllOccsDAG} to obtain the set  for every right-hand side  of 's productions and every \tp  occurring in . After that, we set

We test in line 13 of the \texttt{retrieve-all-occs} function if  has equal parent and child symbols. If this proves to be true, we do not add the corresponding occurrence to , \ie, we do not consider occurrences of a \tp with equal parent and child symbols spanning two productions of the DAG. If we would do so, we would possibly register overlapping occurrences and run into problems during a later replacement of . Consider the following example:
\begin{figure}[t]
	\centering
	\begin{tikzpicture}[->,>=stealth',semithick]
		\tikzstyle{level 1}=[level distance=0.8cm, sibling distance=1.75cm]
		\tikzstyle{level 2}=[level distance=0.8cm, sibling distance=1cm]
		\tikzstyle{level 3}=[level distance=0.8cm, sibling distance=0.75cm]	
		\node {}
			child {node {}
				child {node {}}
				child {node {}
					child {node {}}
					child {node {}}
				}
			}
			child {node {}
				child {node {}}
				child {node {}
					child {node {}}
					child {node {}}
				}
			}
		;
	\end{tikzpicture}
	\caption{The tree  which can be represented by a DAG grammar with productions  and .}\label{fig:impactDagExample}
\end{figure}
\begin{example}
Consider the DAG grammar  given by the productions , where ,  and . It is a compressed representation of the tree  depicted in Fig.~\ref{fig:impactDagExample}. We use the algorithm from Fig.~\ref{lst:functionRetrieveAllOccsDAG} to obtain the sets  for  and every \tp  occurring . Let us assume that we omit the check in line 13, \ie, we also consider occurrences of \tps with equal parent and child symbols spanning two productions. The union
	
	contains the overlapping occurrences  and  of the \tp .
\end{example}
The precaution from line 13 leads sometimes to situations in which we replace fewer occurrences of a \tp with equal parent and child symbols as we would replace when not using the DAG representation.
\begin{figure}[t]
	\centering
	\begin{tikzpicture}[->,>=stealth',semithick]
		\tikzstyle{level 1}=[level distance=0.8cm, sibling distance=1.75cm]
		\tikzstyle{level 2}=[level distance=0.8cm, sibling distance=1cm]
		\tikzstyle{level 3}=[level distance=0.8cm, sibling distance=0.75cm]	
		\node {}
			child {node {}
				child {node {}}
				child {node {}
					child {node {}}
					child {node {}
						child {node {}}
						child {node {}
							child {node {}}
							child {node {}}
						}
					}
				}
			}
			child {node {}
				child {node {}}
				child {node {}
					child {node {}}
					child {node {}
						child {node {}}
						child {node {}
							child {node {}}
							child {node {}}
						}
					}
				}
			}
		;
	\end{tikzpicture}
	\caption{Tree  with seven overlapping occurrences of the \tp .}\label{fig:impactDagExample2}
\end{figure}
\begin{example}
Consider the tree  from
Fig.~\ref{fig:impactDagExample2} which can be represented by the DAG
grammar consisting of the two productions  and  with  and . After
careful counting one can tell that  exhibits at most four
non-overlapping occurrences of the \tp . However, if
we use the above function \verb|retrieve-all-occs-dag| we only capture
three of them. We obtain 
,  and therefore

\end{example}
Even though this approach does not capture all the occurrences which could be captured when not using the DAG representation, it still achieves a competitive compression performance on our set of test files (\cf Sect.~\ref{sec:resultsWithoutDag} on page \pageref{sec:resultsWithoutDag}). It seems that a more involved method of dealing with \tps with equal parent and child symbols spanning two productions would necessitate a partial unfolding of the DAG. The latter, however, would certainly result in a longer runtime.

\begin{figure}[tb]
	\lstset{emph={FUNCTION,ENDFUNC,return,traverse,endtraverse,for,each,if,else,then,do,endif,endfor,repeat,endrepeat,times}, emphstyle=\bfseries, emph={[2]subtrees_ht}, emphstyle={[2]\slshape}, morecomment=[l]{//}}
	\begin{lstlisting}
FUNCTION remove-absorbed-occs-dag((*@@*))
	if ((*@@*)) then
		remove-occ-dag((*@@*));
	else
		let (*@@*) be the right-hand side of (*@@*);
		for each (*@@*) do
			remove-occ-dag((*@@*));
		endfor
	endif
	
	for ((*@@*)) do
		remove-occ-dag((*@@*));
	endfor
	
	for ((*@@*)) do
		remove-occ-dag((*@@*));
	endfor
ENDFUNC	

FUNCTION remove-occ-dag((*@@*))
	if ((*@@*)) then
		(*@@*);
	else
		let (*@@*) be the right-hand side of (*@@*);
		(*@@*);
	endif
	(*@@*);
ENDFUNC	
	\end{lstlisting}
	\caption{Listing of the function \texttt{remove-absorbed-occs-dag} which removes all absorbed occurrences from the  sets when using the DAG mode.}\label{lst:remove-absorbed-occs-dag}
\end{figure}
\begin{figure}[tb]
\lstset{emph={FUNCTION,ENDFUNC,return,traverse,endtraverse,for,if,else,then,do,endif,endfor,repeat,endrepeat,times}, emphstyle=\bfseries, emph={[2]subtrees_ht}, emphstyle={[2]\slshape}, morecomment=[l]{//}}
	\begin{lstlisting}
FUNCTION add-new-occs-dag((*@@*))
	if ((*@@*)) then
		add-occ-dag((*@@*));
	else
		let (*@@*) be the right-hand side of (*@@*);
		for each (*@@*) do
			add-occ-dag((*@@*));
		endfor
	endif
	
	for ((*@@*)) do
		add-occ-dag((*@@*));
	endfor
ENDFUNC	

FUNCTION add-occ-dag((*@@*))
	if ((*@@*)) then
		(*@@*);
	else
		let (*@@*) be the right-hand side of (*@@*);
		(*@@*);
	endif
	(*@@*);
ENDFUNC	
	\end{lstlisting}
	\caption{Listing of the function \texttt{add-new-occs-dag} which adds all new occurrences to the  sets when using the DAG mode.}\label{lst:add-new-occs-dag}
\end{figure}

\subsubsection{Updating the Sets of Non-overlapping Occurrences}

Considering the graph representation of a DAG, a tree node can exhibit multiple parent nodes. In fact, a node has multiple parent nodes if it is the root of the right-hand side of a production of the corresponding DAG grammar and if this production is referenced multiple times.

To capture all \tp occurrences which are absorbed by the replacement of a \tp we need to take care of the above fact. The \texttt{remove-absorbed-occs} function listed in Fig.~\ref{lst:remove-absorbed-occs} needs to be adapted accordingly. Instead of removing one occurrence formed by the node being replaced and its parent, we need to iterate over possibly multiple parents and remove all corresponding occurrences. In Fig.~\ref{lst:remove-absorbed-occs-dag} the function \texttt{remove-absorbed-occs-dag} is listed which incorporates this necessary modification. Analogously, the function \texttt{add-new-occs} listed in Fig.~\ref{lst:add-new-occs} must be modified to work properly in the DAG mode. Fig.\ref{lst:add-new-occs-dag} shows an adapted version.

It is easy to see that our linear runtime is not negatively affected by this loop over all parents. Far from it --- as mentioned earlier, the DAG representation saves us time by avoiding repetitive re-calculations.

\subsubsection{Replacing the \ltps} 

The third and last scenario in which we have to take special care of the DAG representation is when replacing an occurrence of a \tp  spanning two productions of the DAG grammar. Due to our restriction on \tps with equal parent and child symbols the \tp  has to have different parent and child symbols. In the following we want to use an example to describe what needs to be done when replacing the \tp .
\begin{figure}[t]
	\centering
	\begin{tikzpicture}[->,>=stealth',semithick]
		\tikzstyle{level 1}=[level distance=0.8cm, sibling distance=1.75cm]
		\tikzstyle{level 2}=[level distance=0.8cm, sibling distance=1cm]
		\tikzstyle{level 3}=[level distance=0.8cm, sibling distance=0.75cm]	
		\node {}
			child {node {}
				child {node {}}
				child {node {}
					child {node {}}
					child {node {}}
				}
			}
			child {node {}
				child {node {}}
				child {node {}}
			}
		;
	\end{tikzpicture}
	\caption{Depiction of the -labeled tree . We have .}\label{fig:impactDagExample3}
\end{figure}
\begin{example}
Consider the DAG grammar given by the productions  and  which represents the -labeled tree  depicted in Fig.~\ref{fig:impactDagExample3}.
Imagine that we want to replace the sole occurrence of the \tp , \ie, an occurrence spanning two productions.\footnote{For the sake of convenience, our example uses a rather small tree and we decide to replace a \tp occurring only once. We could easily enlarge  such that  occurs multiple times and still show the following.} In order to do that we mainly have to complete the following three steps.
\begin{enumerate}[(1)]
	\item We first have to introduce for every child of the node labeled by  a new production. Thus, we obtain two new productions  and . We can skip this step for every child node which is already labeled by a nonterminal of the DAG grammar. 
	\item We need to update the production with left-hand side  to . 
	\item Finally, we introduce a new nonterminal  representing the \tp  and update the production for  to
		
\end{enumerate}
The above steps are only necessary if the production with left-hand side  is referenced more than once. Otherwise we could have directly connected the children of  to the newly introduced node labeled by  and removed the production with left-hand side  from the grammar.
\end{example} 
Since at most  new productions need to be introduced, the replacement of a \tp occurrence can still be accomplished in constant time. All in all, it has become clear that even when representing the input tree of our algorithm as a DAG our implementation runs in linear time.

\subsection{Technical Details on the Prototype}

The source code of the \trp prototype and its documentation is available at the Google Code\texttrademark\space open source developer site. It can be accessed by visiting the following web page:
\begin{center}
	\url{http://code.google.com/p/treerepair}
\end{center}
However, the implementation should be considered to be of alpha quality. There is still a lot of testing to be done. 

We also implemented a decompressor called \mbox{TreeDePair} which is contained in the \trp distribution. It is not optimized in terms of time and memory usage.

The software is licensed under the GPLv3 license which is available at
\begin{center}
	\url{http://www.gnu.org/licenses/gpl-3.0.txt}
\end{center}
It is implemented using the C++ programming language and can be compiled at least under the Windows and Linux operating systems. For compile instructions and library requirements, see the \texttt{README.txt} file in the root directory of the \trp distribution.

\section{Succinct Coding}\label{ch:succinctCoding}

In order to achieve a compact representation of the input tree of our \trp algorithm we further compress the generated linear SLCF tree grammar by a binary succinct coding. The technique we use is loosely based on the DEFLATE algorithm described in \cite{Deutsch96deflate}. In fact, we use a combination of a fixed-length coding, multiple Huffman codings and a run-length coding to encode different aspects of the grammar (\cf Fig.~\ref{fig:encodingsHierarchy}).
\begin{figure}[t]
	\centering\small
	\begin{tikzpicture}
		[bend angle=25, node distance=0.1cm,text depth=0.1ex,box/.style={draw=black,minimum width=4.5cm},arrow/.style={->,>=stealth'}]

		\node[box] (fixed) {Fixed-length coding};
		\node[box] (super) [below=of fixed] {Super Huffman coding};
		\node[box] (runbase) [below=of super] {Run-length coding};
		\node[box] (base) [below=of runbase] {3 Base Huffman codings};
		\node[box,draw=gray,font=\color{gray}] (content) [below=of base] {Linear SLCF tree grammar};
		
		\draw[arrow] ([xshift=-0.3cm]content.south west) -- ([xshift=-0.3cm]fixed.north west);
	\end{tikzpicture}
	\caption{Hierarchy of the employed encodings.}\label{fig:encodingsHierarchy}
\end{figure}

In spite of the fact that we obtain an extremely compact binary representation of the generated SLCF tree grammar we are still able to directly execute queries on it with little effort. Basically, we only have to reconstruct the Huffman trees to be able to partially decompress the grammar on demand.

In \cite{Maneth08xml} many different variants of succinct codings specialized in SLCF tree grammars were investigated. Among them there was one encoding scheme which turned out to achieve the best compression performance in general --- at least with respect to the set of sample SLCF tree grammars which was used in this work. However, our experiments show that, regarding the SLCF tree grammars generated by \trp, this encoding is outperformed by the succinct coding which we present in this section.

\subsection{General Remarks}\label{sec:succinctCodingGeneralRemarks}

In this section, we want to elaborate on the following topics: How do we need to modify the pruning step of our algorithm to make our succinct coding as efficient as possible? How does \trp efficiently deal with parameter nodes? How can we serialize a Huffman tree in a compact way?

\subsubsection{Inefficient Productions}

Our experiments showed that, at least for our set of test XML documents, we achieve better compression results in terms of the size of the output file if we slightly modify the pruning step of our algorithm. It turns out that our succinct coding, which we describe in the following sections, is most efficient if we prune all productions with a -value smaller than or equal to  (instead of pruning all productions with a -value smaller than or equal to  as it is described in Sect.~\ref{sec:pruningStep} on page \pageref{sec:pruningStep}). However, we use this modification only if we make the size of the output file a top priority (by using the switch \texttt{-optimize filesize}). Otherwise, when optimizing the number of edges of the final grammar (\ie, when using the switch \texttt{-optimize edges}), we stick to the original version of the pruning step.

\subsubsection{Handling of Parameter Nodes}\label{sec:handlingOfParameterNodes}

Let  be the linear SLCF tree grammar which was generated by a run of \trp. Then, for every production  it holds that  labels the -th parameter node of  in preorder, where . Due to this fact it is sufficient to represent the parameter symbols  by a single parameter symbol . Let  be another production and let  with . Now, let us assume that we want to eliminate the production  and that we use only a single parameter symbol labeling all parameter nodes. It is clear that the -th (in preorder) parameter node of  must be replaced by the subtree which is rooted at the -th child of . 

Our implementation takes advantage of the above simplification, \ie, it uses only one parameter symbol  for every occurring parameter node.

\subsubsection{Serializing Huffman trees}\label{sec:serializingHuffmanTrees}

As stated in \cite{Deutsch96deflate}, it is sufficient to only write out the lengths of the generated codes to be able to reconstruct a Huffman tree at a later date. However, this requires the decompressor to be aware of the following.
\begin{itemize}
	\item What symbols are encoded by the corresponding Huffman tree?
	\item In what order are their code lengths listed?
\end{itemize}
In our case only integers need to be encoded by Huffman codings because we will encode all symbols by integers (see Sect.~\ref{sec:contentsOutputFile} on page \pageref{sec:contentsOutputFile}). Hence, it is obvious to use the natural order of integers to list the lengths of the generated codes. Let us assume that  is the biggest integer which needs to be encoded and which was assigned a code to, respectively. We just need to loop over all integers  in their natural order and print out the corresponding code length for each of it. For every  for which no code was assigned to we print out a code length of .

In order to solely rely on the code lengths there is still something which needs to be considered. We are required to assign new codes to the integers based on the lengths of their original codes. More precisely, the new code assignment has to fulfill the following two requirements.
\begin{enumerate}[(1)]
	\item\label{CodeLengthsReq1} All codes of the same code length exhibit lexicographically consecutive values when ordering them in the natural order of the integers they represent.
	\item\label{CodeLengthsReq2} Shorter codes lexicographically precede longer codes.
\end{enumerate}
This reorganization of the Huffman codes does not affect the compression performance of the coding since only codes of the same length are swapped. The following example is based on an example from \cite{Deutsch96deflate}.
\begin{example}
	Imagine that we want to use a Huffman coding to encode the letters , ,  and  which are each occurring multiple times in a data stream. Let us assume that we obtain the Huffman codes listed in Table \ref{tbl:huffmanCodingExampleBefReordering}. In order to be able to store the corresponding Huffman tree by only writing out the lengths of the Huffman codes we need to assign new codes to the letters. Table \ref{tbl:huffmanCodingExampleAfterReordering} shows the newly assigned codes which fulfill the above two requirements (\ref{CodeLengthsReq1}) and (\ref{CodeLengthsReq2}).
\begin{table}[t]
	\small
	\renewcommand{\subfigcapmargin}{-1cm}
	\hfill
	\subtable[{Huffman coding before the reorganization of the codes. The letters are listed in their natural order, \ie, in alphabetic order.}]{
	\centering
		\begin{tabular*}{2.5cm}{c@{\extracolsep{\fill}}c}
			\toprule
			Symbol&Code\\
			\midrule
				&\\
				&\\
				&\\
				&\\
			\bottomrule
		\end{tabular*}
	\label{tbl:huffmanCodingExampleBefReordering}
	}
	\hfill
	\subtable[{Huffman coding from Table \ref{tbl:huffmanCodingExampleBefReordering} after the reorganization of the codes.}]{
	\centering
		\begin{tabular*}{2.5cm}{c@{\extracolsep{\fill}}c}
			\toprule
			Symbol&Code\\
			\midrule
				&\\
				&\\
				&\\
				&\\
			\bottomrule
		\end{tabular*}
	\label{tbl:huffmanCodingExampleAfterReordering}
	}
	\hfill
\end{table}
Now, let us assume that the decompressor expects the code lengths to be the lengths of codes assigned to the letters of the Latin alphabet and that these code lengths are ordered in the natural order of the letters they represent. Then, the corresponding Huffman tree can be unambiguously represented by the following sequence of code lengths: . Note that we need to insert a code length of  at the position of the letter  since there is no code assigned to the letter .
\end{example}

\subsection{Contents of the Output File}\label{sec:contentsOutputFile}

In this section we want to elaborate on the information which needs to be stored in the output file of our algorithm in order to be able to reconstruct the generated linear SLCF tree grammar at a later date. We also want to demonstrate how this data can be efficiently represented. However, at this time we do not pay attention to the fixed-length, run-length or Huffman codings which are employed in a subsequent step of the encoding process. For the sake of simplicity we consider these encodings in separate subsections of this section.

Let  be the linear SLCF tree grammar which was generated by a run of \trp. Before we are able to compile the information which needs to be written out we need to assign to every symbol from  a unique integer. In fact, we assign to every symbol from  a unique ID from the set \mbox{}. We assign the ID  to , \ie, to the special symbol labeling all parameter nodes in the right-hand sides of 's productions. Finally, we associate with every symbol from the set of nonterminals  a unique ID from the set . The IDs are assigned to the nonterminals in such a way that the nonterminal  has a higher ID than the nonterminal  if  holds.

\subsubsection{Writing out the Necessary Informations}

Now, we are able to write out the information needed to reconstruct  in four steps. Bear in mind that the values mentioned below are not directly written to the output file but that they are additionally encoded by a combination of multiple Huffman codings, a run-length coding and a fixed-length coding later on. 

\paragraph*{First step} In the first step, we write out the number of terminal symbols  and the number of introduced productions , \ie, we are not counting the start production. By handing over this information to the decompressor we avoid the insertion of separators marking, for instance, the end of the enumeration of elements types (which are written out in the third step).

\paragraph*{Second step} In the second step, we directly append a representation of the children characteristics of the terminal symbols. By children characteristics we mean their rank and, concerning terminal symbols of rank , if we are dealing with a left or a right child.\footnote{Consult Sect.~\ref{sec:binaryTreeModel} on page \pageref{sec:binaryTreeModel} for an explanation on why this information is necessary to reconstruct the input tree.} Due to the fact that all terminal symbols have a rank of at most two, we can encode this information using two bits per symbol. Table \ref{tbl:childrenCharacteristics} lists all the bit strings we use together with a brief description of their meanings.
\begin{table}[t]
	\centering\small
\begin{tabular*}{4cm}{c@{\extracolsep{\fill}}l}
		\toprule
		Bit string&Description\\
		\midrule
		&rank \\
		&rank , right child\\
		&rank , left child\\
		&rank \\
		\bottomrule
	\end{tabular*}
	\caption{The bit strings encoding the children characteristics together with their meaning.}\label{tbl:childrenCharacteristics}
\end{table}
We write out the children characteristics as follows: Firstly, we print out a bit string from Table \ref{tbl:childrenCharacteristics} representing a certain children characteristic. After that we append the number of corresponding terminal symbols and finally we enumerate their IDs. We do this for the characteristics ,  and . We omit the enumeration of all terminal symbols with a rank of  since their IDs can be reconstructed with the information in hand. In fact, we just need to subtract the set of IDs of all terminal symbols with children characteristics ,  and  from the set of IDs of all terminal symbols from  (which is ). 

Furthermore, it is not necessary to print out the ranks of the nonterminals from  since these can be easily reconstructed by counting the number of parameter nodes in the corresponding right-hand sides. The latter are written to the output file in the fourth step.

\paragraph*{Third step} In this step, we print the element types of the terminal symbols in the ascending order of their IDs to the output file. We do this by writing out the ASCII code of every single letter. The individual names are terminated by the ASCII character \texttt{ETX} which is assumed not to be used within the element types of the terminal symbols.

\paragraph*{Fourth step} In this last step we serialize the productions of  in the ascending order of the IDs of their left-hand sides. For every production  we just write out the IDs of the labels of 's nodes in preorder. We do not need to use special marker symbols to indicate the nesting structure of the symbols and their IDs, respectively. When parsing the output file this hierarchy can be easily obtained by taking care of the individual ranks of the symbols.

We can also omit the specification of the left-hand side  since both, its ID and its rank, can be reconstructed with the information in hand. Imagine that we are parsing the output file to reconstruct the productions of . If we are parsing the -th production, the ID of its left-hand side must be , where . As already mentioned, the rank of the left-hand side can be obtained by counting the parameter nodes in the right-hand side once this has been reconstructed.

Note that it is superfluous to insert separators between the representations of the productions from  since their boundaries can be calculated based on the ranks of the symbols. Again, imagine that we are trying to reconstruct the productions of  by parsing the output file of our algorithm. Let  be the first production we encounter. The tree  can only consist of nodes labeled by terminal symbols, \ie, we must have .\footnote{This is due to the fact that we have written out the productions in the ascending order of the IDs of their left-hand sides. These IDs were assigned to the nonterminals in such a way that the nonterminal  has a higher ID than  if  holds. Therefore, the right-hand side of , which is the first production which was written out, does not contain any node labeled by a nonterminal from .} The ranks of all symbols from  are known since the necessary information was written to the compressed file in the second step. Therefore, we can easily reconstruct  by iteratively parsing the corresponding IDs in the output file. While doing so we are also able to count the number of occurrences of the symbol  in . Thus, we are aware of the value of . After that, we proceed with decoding the second production  by iteratively parsing the next IDs. We have , \ie, the ranks of all occurring symbols are known. That way all productions from  can be reconstructed.
\begin{example}\label{ex:mainExampleEncoding}
	In order to get a clear picture of the representation described above we apply the previous four steps to the linear SLCF tree grammar  over the ranked alphabet  from Sect.~\ref{exampleGrammar} on page \pageref{exampleGrammar}, \ie, we have  and  is the following set of productions:

	First of all, we assign to every symbol from  a unique ID as it is shown in Fig.~\ref{tbl:succinctCodingAssignedIds}. After that we are able to write out the grammar exactly as described above resulting in the value sequence depicted in Fig.~\ref{fig:valueSequence}. We accomplish this task in four steps: 
\begin{figure}[t]
	\centering
	\begin{tabular*}{3cm}{l@{\extracolsep{\fill}}l}
		\toprule
		Symbol&ID\\
		\midrule
				&\\
				&\\
				&\\
				&\\
				&\\
				&\\
								&\\
							&\\
							&\\
		\bottomrule
	\end{tabular*}
	\caption{All symbols with the ID assigned to them. The symbol  is the symbol used to label the parameter nodes in the right-hand sides of 's productions.}\label{tbl:succinctCodingAssignedIds}
\end{figure}
\begin{enumerate}[(1)]
	\item We begin by writing out the number of terminals () directly followed by the number of nonterminals minus the start nonterminal (2) --- see the values 0 and 1 in the depiction. 
	\item After that the children characteristics of all terminal symbols are written to the file. We begin by specifying all terminal symbols of rank  (values 2--4). This is done by firstly writing out the bit string  and the number of corresponding symbols (). Finally, the ID  of the terminal symbol , which is the sole terminal symbol of rank , is listed. 
	
		Analogously, the terminal symbols with children characteristics  and  are enumerated (values 5--12).
	\item Now, the element types of all terminal symbols are exported to the output file (values 13--46). For each of them the decimal value of each ASCII character is written out. The element type \emph{books}, for instance, is encoded by the sequence , , , , . 
	\item Finally, the productions from  are written out in the ascending order of the IDs of their left-hand sides. Thus, the production with left-hand side  is serialized as the very first production (values 47--49). It is encoded by the unambiguous sequence of IDs  representing the terminal symbols ,  and  of the right-hand side of  in preorder.
		Afterwards the remaining productions with left-hand sides  (values 50--52) and  (values 53--59) are printed to the output file in this order. 
\end{enumerate}
\end{example}
\begin{figure}[tb]
\centering
		\pgfdeclarelayer{background}
		\pgfsetlayers{background,main}
		\begin{tikzpicture}[semithick]
			\pgfmathsetmacro{\cols}{16}
			\pgfmathsetmacro{\zero}{0}
			\pgfmathsetmacro{\hei}{0.5}
			
			\pgfmathdivide{\hei}{2}
			\pgfmathsetmacro{\halfhei}{\pgfmathresult}
			
			\pgfmathsetmacro{\dist}{1.8}
			\newcounter{curval}
			\setcounter{curval}{0}
		
			\foreach \content in {6,2,00,1,2,01,2,3,4,10,2,1,5,98,111,111,107,115,3,105,115,98,11
0,3,116,105,116,108,101,3,97,117,116,104,111,114,3,98,111,111,
107,3,98,111,111,107,3,4,3,2,6,8,7,1,9,9,9,9,5,8} {
				\pgfmathmod{\value{curval}}{\cols}
				\pgfmathsetmacro\mod\pgfmathresult

\pgfmathdivide{\value{curval}}{\cols}
					\pgfmathfloor{\pgfmathresult}
\pgfmathsetmacro{\div}{\pgfmathresult}


				\pgfmathmultiply{\div}{\dist}
				\pgfmathsetmacro{\y}{\pgfmathresult}
				
				\begin{scope}[xshift=\mod cm,yshift=-\y cm]
				
					\draw (0.5,-0.5) node[inner sep=0pt, outer sep=0pt] (value\arabic{curval}southeast) {};
					\draw (0.5,0.5) node[inner sep=0pt, outer sep=0pt] (value\arabic{curval}northeast) {};
					\draw (-0.5,-0.5) node[inner sep=0pt, outer sep=0pt] (value\arabic{curval}southwest) {};
					\draw (-0.5,0.5) node[inner sep=0pt, outer sep=0pt] (value\arabic{curval}northwest) {};
					\draw (0,0) node[inner sep=0pt, outer sep=0pt] (value\arabic{curval}center) {};
					\draw (0,0.5) node[inner sep=0pt, outer sep=0pt] (value\arabic{curval}northcenter) {};
				
\draw (-0.5,-0.5) -- (0.5,-0.5) -- (0.5,0.5) -- (-0.5,0.5) -- cycle;
\draw (0,0) node[anchor=center] {};
					\draw (-0.5,0.5) node[anchor=north west, gray] {\scriptsize\arabic{curval}};
\end{scope}
				
				\stepcounter{curval}
			}
			
			\begin{scope}[pattern color=gray]
\filldraw[draw=black,fill=lightgray,pattern=north west lines] (value2northwest) -- (value12northeast) -- ([xshift=0pt,yshift=\hei cm]value12northeast.center) -- ([xshift=0pt,yshift=\hei cm]value2northwest.center) -- (value2northwest);
				\draw ([yshift=\halfhei cm]value7northcenter) node[anchor=center, black,fill=white, inner sep=2pt] {\footnotesize children characteristics};
			
\filldraw[draw=black,fill=lightgray,pattern=dots] (value13northwest) -- (value15northeast) -- ([xshift=0pt,yshift=\hei cm]value15northeast.center) -- ([xshift=0pt,yshift=\hei cm]value13northwest.center) -- (value13northwest);
				\filldraw[draw=black,fill=lightgray,pattern=dots] (value16northwest) -- (value31northeast) -- ([xshift=0pt,yshift=\hei cm]value31northeast.center) -- ([xshift=0pt,yshift=\hei cm]value16northwest.center) -- (value16northwest);
				\filldraw[draw=black,fill=lightgray,pattern=dots] (value32northwest) -- (value46northeast) -- ([xshift=0pt,yshift=\hei cm]value46northeast.center) -- ([xshift=0pt,yshift=\hei cm]value32northwest.center) -- (value32northwest);
				\draw ([yshift=\halfhei cm]value24northwest) node[anchor=center,black,fill=white,inner sep=2pt] {\footnotesize element types};
				
\filldraw[draw=black,fill=lightgray,pattern=north east lines] (value46northwest) -- (value47northeast) -- ([xshift=0pt,yshift=\hei cm]value47northeast.center) -- ([xshift=0pt,yshift=\hei cm]value47northwest.center) -- (value47northwest);
				\filldraw[draw=black,fill=lightgray,pattern=north east lines] (value48northwest) -- (value59northeast) -- ([xshift=0pt,yshift=\hei cm]value59northeast.center) -- ([xshift=0pt,yshift=\hei cm]value48northwest.center) -- (value48northwest);
				\draw ([xshift=0cm,yshift=\halfhei cm]value53northeast) node[anchor=center, black,fill=white, inner sep=2pt] {\footnotesize productions};
			\end{scope}
			
			\begin{pgfonlayer}{background}
				\foreach \l/\r/\lc/\rc in {2/4/lightgray/white,5/8/lightgray/white,9/12/lightgray/white,13/15/lightgray/black!05,16/17/black!05/white,19/22/lightgray/white,24/28/lightgray/white,30/31/lightgray/black!10,32/35/black!10/white,37/40/lightgray/white,42/45/lightgray/white,47/47/lightgray/black!10,48/49/black!10/white,50/52/lightgray/white,53/59/lightgray/white} {
					\shade[left color=\lc,right color=\rc] (value\l northwest.center) rectangle (value\r southeast.center);
				}
			\end{pgfonlayer}

			\begin{scope}[anchor=south east, darkgray]
			\draw (value13southeast) node {\scriptsize'b'};
			\draw (value14southeast) node {\scriptsize'o'};
			\draw (value15southeast) node {\scriptsize'o'};
			\draw (value16southeast) node {\scriptsize'k'};
			\draw (value17southeast) node {\scriptsize's'};
			\draw (value18southeast) node {\scriptsize'ETX'};
			\draw (value19southeast) node {\scriptsize'i'};
			\draw (value20southeast) node {\scriptsize's'};
			\draw (value21southeast) node {\scriptsize'b'};
			\draw (value22southeast) node {\scriptsize'n'};
			\draw (value23southeast) node {\scriptsize'ETX'};
			\draw (value24southeast) node {\scriptsize't'};
			\draw (value25southeast) node {\scriptsize'i'};
			\draw (value26southeast) node {\scriptsize't'};
			\draw (value27southeast) node {\scriptsize'l'};
			\draw (value28southeast) node {\scriptsize'e'};
			\draw (value29southeast) node {\scriptsize'ETX'};
			\draw (value30southeast) node {\scriptsize'a'};
			\draw (value31southeast) node {\scriptsize'u'};
			\draw (value32southeast) node {\scriptsize't'};
			\draw (value33southeast) node {\scriptsize'h'};
			\draw (value34southeast) node {\scriptsize'o'};
			\draw (value35southeast) node {\scriptsize'r'};
			\draw (value36southeast) node {\scriptsize'ETX'};
			\draw (value37southeast) node {\scriptsize'b'};
			\draw (value38southeast) node {\scriptsize'o'};
			\draw (value39southeast) node {\scriptsize'o'};
			\draw (value40southeast) node {\scriptsize'k'};
			\draw (value41southeast) node {\scriptsize'ETX'};
			\draw (value42southeast) node {\scriptsize'b'};
			\draw (value43southeast) node {\scriptsize'o'};
			\draw (value44southeast) node {\scriptsize'o'};
			\draw (value45southeast) node {\scriptsize'k'};
			\draw (value46southeast) node {\scriptsize'ETX'};
			\end{scope}
		\end{tikzpicture}
	\caption{Representation of the grammar  from Example \ref{ex:mainExampleEncoding}.}\label{fig:valueSequence}
\end{figure}

\subsubsection{Possible Optimizations}

Of course, there is still room to further reduce the data which needs to be written to the output file. Consider, for instance, terminal symbols of the same element type but different children characteristics. In the case of our implementation, the element type of these symbols is written to the file two or three times in the second step. However, an optimization with respect to this redundancy does only lead to marginally better compression results. This is due to the fact that typically the major part of the output file is the enumeration of the productions.

Still regarding the second step, we could at first determine the most frequent children characteristic and omit the enumeration of all corresponding terminal symbols. This dynamic approach certainly leads to a small reduction of the size of the output file compared to always skipping the children characteristic .

Another aspect which confesses optimization potential are possible long lists of the parameter symbol  which emerge when writing out the right-hand sides of productions with a higher rank. In this case, run-length coding can lead to a better compression performance. However, we did not further investigate this matter since we focus on generating grammars with nonterminals with a maximal rank of .

\subsection{Employing Multiple Types of Encodings}\label{sec:huffmanCoding}

Even though a Huffman tree has to be serialized for every Huffman coding used within our output file, we decided in favor of using four distinct Huffman codings. We use three of them for encoding 
\begin{itemize}
	\item the start production, 
	\item the remaining productions, the children characteristics of the terminal symbols and the numbers of terminals and nonterminals, and finally
	\item the names of the terminals.
\end{itemize}
In the sequel, we call these three Huffman codings the \emph{base Huffman codings}. The fourth Huffman coding, which we call \emph{super Huffman coding}, is used to encode the Huffman trees of the above codings. Our tests with different numbers of Huffman codings revealed that, in general, the above approach leads to the best compression results. This is at least true for most of the XML test documents we used.

\subsubsection{Base Huffman Codings}

We serialize the three base Huffman codings by writing out the lengths of the generated codes as it is described in Sect.~\ref{sec:serializingHuffmanTrees} on page \pageref{sec:serializingHuffmanTrees}. However, we additionally apply a run-length coding and the super Huffman coding to achieve a compact binary representation. In Sect.~\ref{sec:run-lengthCoding} on page \pageref{sec:run-lengthCoding} we elaborate on how exactly the run-length coding works. We briefly call the length of a code of a base Huffman coding a \emph{base code length} in the sequel. Analogously, we denote the lengths of the codes of the super Huffman coding by the term \emph{super code lengths}.

We output the number of base code lengths in front of every serialized base Huffman coding, \ie, in front of every enumeration of base code lengths. That way the decompressor knows how many bits are part of this binary representation.
Let us point out that this number of code lengths is encoded using  bits instead of using the super Huffman coding, where  is a constant which is fixed at compile time. We do this due to the following fact. Let  be the number of code lengths and let us assume that we encode , which is usually many times larger than the maximum over all code lengths, using the super Huffman coding. This would result in a big gap of unused integers between the super code lengths and . This again would lead to a long list of 's when storing the super Huffman tree by enumerating its code lengths. In general, this leads to a reduced compression performance compared to a fixed-length coding of  using  bits.

\subsubsection{Super Huffman Coding}

The super Huffman coding will also be stored by the sequence of its code lengths. However, the relatively small set of integers is encoded by a fixed-length coding using  bits, where  is the smallest possible number of bits which can be used to encode all super code lengths. More precisely, we serialize the super Huffman coding in three steps:
\begin{enumerate}[(1)]
	\item First of all, we print out the binary representation of the number  using  bits, where  is a fixed number of bits which is specified at compile time.
	\item Let  be the biggest base code length. We print out the binary representation of  using  bits. With this information the decompressor knows that the next  bits make up the list of super code lengths.
	\item Finally, the binary representations of the  many super code lengths are written to the output file using  bits for each code length. The super code lengths are printed in the natural order of the integers which are represented by the corresponding codes.
\end{enumerate}

\subsubsection{Run-length Coding of the Base Code Lengths}\label{sec:run-lengthCoding}

In this section we explain the run-length coding which is applied to the enumerations of code lengths used to write all base Huffman codings to the output file. This additional encoding marks a major contribution to the compactness of our representation. The bigger a code length is, the more different codes of that length are possible. At the same time a sequence of several occurrences of the same code length within the enumeration of all code lengths becomes more likely. In addition, our experience shows that it frequently happens that there is a longer run of 's in the list of all code lengths due to symbols which no codes were assigned to. 
\begin{example}
Consider, for instance, the example from Sect.~\ref{sec:mainExampleHuffman} and in particular the base Huffman coding  which is listed in Table \ref{tbl:mainExampleHuffmanCodingNames} on page \pageref{tbl:mainExampleHuffmanCodingNames}. This Huffman coding does not assign codes to the symbols --. This results in a sequence of  zeros within the enumeration of the code lengths of .
\end{example}
\begin{definition}
	Let , where . In the following we denote by  the (-padded) binary representation  of , \ie, the following holds:

\end{definition}
We encode an enumeration of code lengths using a run-length coding as follows: Let us assume that  is the maximum code length. Then we use the three additional integers ,  and  to indicate certain types of runs --- we call them \emph{run indicators} in the sequel. Principally, all runs with a length less than or equal to  are straightly written to the output file. In contrast, a run of a code length  exceeding this bound is encoded as follows:
\begin{itemize}
	\item If we have , we use the run indicator  and a bit string with a length of  to indicate -- repetitions of the code length . If  is the length of the run of  and  (\ie, ), then this run is encoded as follows:
		\begin{itemize}
			\item if :
				
			\item if :
				
		\end{itemize}
		Note that  denotes  many consecutive 's.
	\item If we have , we use the run indicator  with an appended bit string of length  to  denote -- repetitions of . In contrast, we use the run indicator  together with a bit string of length  to encode -- repeated 's.
	
		If  is the length of the run of 's and  (\ie, ), then this run is encoded as follows:
		\begin{itemize}
			\item if :
				
			\item if :
				
			\item if :
				
		\end{itemize}
\end{itemize}
\begin{table}
	\footnotesize
	\hfill
	\subtable[{Huffman coding  used to encode the start production.}]{
	\centering
	\begin{tabular*}{4.7cm}[b]{r@{\extracolsep{\fill}}r@{\extracolsep{\fill}}r}
		\toprule
		Symbol&Old code&New code\\
		\midrule
		&		&\\
		&	&\\
		&	&\\
		&	&\\
		&		&\\
		\bottomrule
	\end{tabular*}
	\label{tbl:mainExampleHuffmanCodingStartProduction}
	}
	\hfill
	\subtable[{Huffman coding  used to encode the productions from , the children characteristics, and numbers of terminals and nonterminals.}]{
	\centering
	\begin{tabular*}{4.7cm}[b]{r@{\extracolsep{\fill}}r@{\extracolsep{\fill}}r}
		\toprule
		Symbol&Old code&New code\\
		\midrule
		&	&\\
		&		&\\
		&		&\\
		&	&\\
		&	&\\
		&	&\\
		&	&\\
		&	&\\
		\bottomrule
	\end{tabular*}
	\label{tbl:mainExampleHuffmanCodingProductions}
	}
	\hfill
\end{table}
\begin{table}
	\footnotesize
	\hfill
	\subtable[{Huffman coding  used to encode the names of the terminal symbols.}]{
	\centering
	\begin{tabular*}{4.7cm}[b]{r@{\extracolsep{\fill}}r@{\extracolsep{\fill}}r}
		\toprule
		Symbol	&Old code	&New code\\
		\midrule
				&		&\\
				&		&\\
				&		&\\
			&		&\\
			&		&\\
			&		&\\
			&		&\\
			&	&\\
			&	&\\
			&		&\\
			&		&\\
			&		&\\
			&		&\\
			&		&\\
		\bottomrule
	\end{tabular*}
	\label{tbl:mainExampleHuffmanCodingNames}
	}
	\hfill
	\subtable[{Super Huffman coding used to encode the code lengths of the base Huffman codings.}]{
	\centering
	\begin{tabular*}{4.7cm}[b]{r@{\extracolsep{\fill}}r@{\extracolsep{\fill}}r}
		\toprule
		Symbol	&Old code	&New code\\
		\midrule
				&			&\\
				&	&\\
				&		&\\
				&		&\\
				&		&\\
				&		&\\
				&		&\\
				&	&\\
		\bottomrule
	\end{tabular*}
	\label{tbl:mainExampleSuperHuffmanCoding}
	}
	\hfill
\end{table}
\begin{example}
	Consider the following sequence of integers:
	\begin{center}
		
	\end{center}
	Now, let us assume that we want to encode the above sequence using our run-length coding. Obviously, we have . The above run of 's with a length of 6 is represented by the sequence  since we have  and . In contrast, the run of 's with a length of  leads to the sequence  because it holds that  and that . All in all, we obtain the sequence .
\end{example}
Surprisingly, our investigations evinced that an approach which dynamically adjusts the length of the bit strings used in the above encoding depending on the size of the input grammar does not lead to significantly better compression results.

\subsubsection{Example}\label{sec:mainExampleHuffman}

This example continues the encoding of the linear SLCF tree grammar  from Example \ref{ex:mainExampleEncoding} on page \pageref{ex:mainExampleEncoding}. The Tables \ref{tbl:mainExampleHuffmanCodingStartProduction}, \ref{tbl:mainExampleHuffmanCodingProductions} and \ref{tbl:mainExampleHuffmanCodingNames} list the three base Huffman codings, called ,  and  in the sequel, which are calculated by our implementation. The columns labeled \emph{Old code} show the initial Huffman codes while the columns labeled \emph{New code} list the newly assigned codes after the necessary reorganization described in Sect.~\ref{sec:serializingHuffmanTrees} on page \pageref{sec:serializingHuffmanTrees}.

While Fig.~\ref{fig:valueSequence} on page \pageref{fig:valueSequence} shows the second part of the output file as it is generated by a run of \trp the Fig.~\ref{fig:mainExampleFirstPartOutputFile} shows the first part of it. The latter stores the base Huffman codings ,  and  together with the corresponding super Huffman coding. For the sake of clarity the corresponding values are denoted by their integer representation instead of by their fixed-length or Huffman code. The Huffman coding  from Table \ref{tbl:mainExampleHuffmanCodingStartProduction}, for instance, is given by the sequence of code lengths ranging from value 13 to value 22, where value 12 informs us about the length of this sequence. Analogously, the code lengths of the Huffman codings  and  are given by the values 24--32 and 34--60, respectively. The sequence of code lengths of the Huffman coding  exhibits a longer run, namely,  consecutive occurrences of the code length . This run is encoded by the run indicator  and the bit string , where  is the maximal length of a code from .

\begin{figure}[bt]
\centering
		\pgfdeclarelayer{background}
		\pgfsetlayers{background,main}
		\begin{tikzpicture}[semithick]
			\pgfmathsetmacro{\cols}{16}
			\pgfmathsetmacro{\zero}{0}
			\pgfmathsetmacro{\hei}{0.5}
			
			\pgfmathdivide{\hei}{2}
			\pgfmathsetmacro{\halfhei}{\pgfmathresult}
			
			\pgfmathsetmacro{\dist}{1.8}
			\newcounter{curvaltwo}
			\setcounter{curvaltwo}{0}
		
			\foreach \content in {3,10,1,6,4,3,3,3,5,0,0,6,10,2,4,0,0,0,4,0,0,3,1,9,0,4,2,2,3,4,3,
			4,4,118,0,0,0,3,9,{\hfill 101\newline\hfill 0010},5,3,0,0,5,0,0,5,4,0,4,6,0,6,2,0,0,5,4,3,5} {
				\pgfmathmod{\value{curvaltwo}}{\cols}
				\pgfmathsetmacro\mod\pgfmathresult

\pgfmathdivide{\value{curvaltwo}}{\cols}
					\pgfmathfloor{\pgfmathresult}
\pgfmathsetmacro{\div}{\pgfmathresult}


				\pgfmathmultiply{\div}{\dist}
				\pgfmathsetmacro{\y}{\pgfmathresult}
				
				\begin{scope}[xshift=\mod cm,yshift=-\y cm]
				
					\draw (0.5,-0.5) node[inner sep=0pt, outer sep=0pt] (value\arabic{curvaltwo}southeast) {};
					\draw (0.5,0.5) node[inner sep=0pt, outer sep=0pt] (value\arabic{curvaltwo}northeast) {};
					\draw (-0.5,-0.5) node[inner sep=0pt, outer sep=0pt] (value\arabic{curvaltwo}southwest) {};
					\draw (-0.5,0.5) node[inner sep=0pt, outer sep=0pt] (value\arabic{curvaltwo}northwest) {};
					\draw (0,0) node[inner sep=0pt, outer sep=0pt] (value\arabic{curvaltwo}center) {};
					\draw (0,0.5) node[inner sep=0pt, outer sep=0pt] (value\arabic{curvaltwo}northcenter) {};
				
\draw (-0.5,-0.5) -- (0.5,-0.5) -- (0.5,0.5) -- (-0.5,0.5) -- cycle;
\draw (0,0) node[anchor=center,text centered,text width=0.8cm] {};
					\draw (-0.5,0.5) node[anchor=north west, gray] {\scriptsize\arabic{curvaltwo}};
\end{scope}
				
				\stepcounter{curvaltwo}
			}
			
			\begin{scope}[pattern color=gray]
\filldraw[draw=black,fill=lightgray,pattern=north west lines] (value1northwest) -- (value11northeast) -- ([xshift=0pt,yshift=\hei cm]value11northeast.center) -- ([xshift=0pt,yshift=\hei cm]value1northwest.center) -- (value1northwest);
				\draw ([yshift=\halfhei cm]value6northcenter) node[anchor=center, black,fill=white, inner sep=2pt] {\footnotesize super Huffman coding};
			
\filldraw[draw=black,fill=lightgray,pattern=dots] (value12northwest) -- (value15northeast) -- ([xshift=0pt,yshift=\hei cm]value15northeast.center) -- ([xshift=0pt,yshift=\hei cm]value12northwest.center) -- (value12northwest);
				\filldraw[draw=black,fill=lightgray,pattern=dots] (value16northwest) -- (value22northeast) -- ([xshift=0pt,yshift=\hei cm]value22northeast.center) -- ([xshift=0pt,yshift=\hei cm]value16northwest.center) -- (value16northwest);
				\draw ([yshift=\halfhei cm]value19northcenter) node[anchor=center,black,fill=white,inner sep=2pt] {\footnotesize base Huffman coding };
				
\filldraw[draw=black,fill=lightgray,pattern=north east lines] (value23northwest) -- (value31northeast) -- ([xshift=0pt,yshift=\hei cm]value31northeast.center) -- ([xshift=0pt,yshift=\hei cm]value23northwest.center) -- (value23northwest);
				\filldraw[draw=black,fill=lightgray,pattern=north east lines] (value32northwest) -- (value32northeast) -- ([xshift=0pt,yshift=\hei cm]value32northeast.center) -- ([xshift=0pt,yshift=\hei cm]value32northwest.center) -- (value32northwest);
				\draw ([yshift=\halfhei cm]value27northcenter) node[anchor=center,black,fill=white,inner sep=2pt] {\footnotesize base Huffman coding };
				
\filldraw[draw=black,fill=lightgray,pattern=checkerboard light gray] (value33northwest) -- (value47northeast) -- ([xshift=0pt,yshift=\hei cm]value47northeast.center) -- ([xshift=0pt,yshift=\hei cm]value33northwest.center) -- (value33northwest);
				\filldraw[draw=black,fill=lightgray,pattern=checkerboard light gray] (value48northwest) -- (value60northeast) -- ([xshift=0pt,yshift=\hei cm]value60northeast.center) -- ([xshift=0pt,yshift=\hei cm]value48northwest.center) -- (value48northwest);
				\draw ([xshift=0cm,yshift=\halfhei cm]value40northwest) node[anchor=center, black,fill=white, inner sep=2pt] {\footnotesize base Huffman coding };
			\end{scope}
			
			\begin{pgfonlayer}{background}
				\foreach \l/\r/\lc/\rc in {1/1/lightgray/lightgray,12/12/lightgray/lightgray,23/23/lightgray/lightgray,33/33/lightgray/lightgray} {
					\shade[left color=\lc,right color=\rc] (value\l northwest.center) rectangle (value\r southeast.center);
				}
			\end{pgfonlayer}
		\end{tikzpicture}
	\caption{Depiction of the part of the output file which contains the serialized four Huffman codings.}\label{fig:mainExampleFirstPartOutputFile}
\end{figure}

The super Huffman coding listed in Table \ref{tbl:mainExampleSuperHuffmanCoding} is written to the output file (values 2--11) using 3 bits per integer as it is stated by the value 0 of the output file. There need to be enumerated  super code lengths since  values --- the base code lengths  and the run indicators  which are used by the base Huffman coding  --- need to be encoded.


\section{Experimental Results}\label{ch:experimentalResults}

In the following, we compare the compression performance of our implementation of the Re-pair for Trees algorithm with existing algorithms. Furthermore, we will check the impact of the DAG representation of the input tree on the compression factors achieved and we will learn about the influences of small changes to the maximal rank allowed for a nonterminal.

\subsection{XML Documents Used}

The set of XML documents we used for investigating the performance of \trp consists of 23 files with different characteristics (\cf Table \ref{tbl:characteristicsXmlDocuments}). Most of them were used in past papers evaluating various XML compressors and therefore may be familiar to the reader. The original files can be obtained from the sources listed in Table \ref{tbl:sourcesOfXmlDocuments}. In all cases character data, attributes, comments, namespace information were removed from the XML files, \ie, the XML documents consist only of start tags, end tags and empty element tags. We do so, because, at this time, \trp ignores this information and solely concentrates on the XML document tree.

\begin{table}[t]
\centering
		\begin{tabular}{lrrrrrr}\toprule
		XML document						&File size (kb)&\#\,Edges	&Depth	&\#\,Element types	&Source\\
		\midrule
		\texttt{1998statistics}			&349			&28\,305		&5		&46				&1\\
		\texttt{catalog-01}				&4\,219		&225\,193		&7		&50				&9\\
		\texttt{catalog-02}				&44\,656		&2\,390\,230	&7		&53				&9\\
		\texttt{dictionary-01}				&1\,737		&277\,071		&7		&24				&9\\
		\texttt{dictionary-02}				&17\,128		&2\,731\,763	&7		&24				&9\\
		\texttt{dblp}						&117\,822		&10\,802\,123	&5		&35				&2\\
		\texttt{EnWikiNew}				&4\,843		&404\,651		&4		&20				&3\\
		\texttt{EnWikiQuote}				&3\,134		&262\,954		&4		&20				&3\\
		\texttt{EnWikiSource}			&13\,457		&1\,133\,534	&4		&20				&3\\
		\texttt{EnWikiVersity}			&5\,887		&495\,838		&4		&20				&3\\
		\texttt{EnWikTionary}			&99\,201		&8\,385\,133	&4		&20				&3\\
		\texttt{EXI-Array}				&5\,347		&226\,522		&9		&47				&5\\
		\texttt{EXI-factbook}			&1\,214		&55\,452		&4		&199				&5\\
		\texttt{EXI-Invoice}				&266			&15\,074		&6		&52				&5\\
		\texttt{EXI-Telecomp}			&3\,700		&177\,633		&6		&39				&5\\
		\texttt{EXI-weblog}				&1\,104		&93\,434		&2		&12				&5\\
		\texttt{JST\_gene.chr1}			&4\,202		&216\,400		&6		&26				&8\\
		\texttt{JST\_snp.chr1}				&13\,795		&655\,945		&7		&42				&8\\
		\texttt{medline02n0328}			&51\,751		&2\,866\,079	&6		&78				&6\\
		\texttt{NCBI\_gene.chr1}			&6\,862		&360\,349		&6		&50				&8\\
		\texttt{NCBI\_snp.chr1}			&63\,941		&3\,642\,224	&3		&15				&8\\
		\texttt{sprot39.dat}				&111\,175		&10\,903\,567	&5		&48				&7\\
		\texttt{treebank}				&19\,551		&2\,447\,726	&36		&251				&4\\
		\bottomrule
		\end{tabular}
	\caption{Characteristics of the XML documents used in our tests. The values in the "Source"-column match the source IDs in Table \ref{tbl:sourcesOfXmlDocuments}. The depth of an XML document tree specifies the length (number of edges) of the longest path from the root of the tree to a leaf.}
	\label{tbl:characteristicsXmlDocuments}
\end{table}

\begin{table}[tb]
	\footnotesize\centering
	\begin{tabular}{cl}
		\toprule
		ID&Source\\
		\midrule
		1&\url{http://www.cafeconleche.org/examples}\\
		2&\url{http://dblp.uni-trier.de/xml}\\
		3&\url{http://download.wikipedia.org/backup-index.html}\\
		4&\url{http://www.cs.washington.edu/research/xmldatasets}\\
		5&\url{http://www.w3.org/XML/EXI}\\
		6&\url{http://www.ncbi.nlm.nih.gov/pubmed}\\
		7&\url{http://expasy.org/sprot}\\
		8&\url{http://snp.ims.u-tokyo.ac.jp}\\
		9&\url{http://softbase.uwaterloo.ca/~ddbms/projects/xbench}\\
		\bottomrule
	\end{tabular}
	\caption{Sources of the XML documents from Table \ref{tbl:characteristicsXmlDocuments}.}
	\label{tbl:sourcesOfXmlDocuments}
\end{table}

\subsection{Algorithms Used in Comparison}

Basically, we compare our implementation of Re-pair for Trees with two
other compression algorithms based on linear SLCF tree grammars,
namely, BPLEX \cite{Busatto08efficient} and Extended-Repair
\cite{Krislin08repair,Boettcher10clustering}. The former is a
sliding-window based linear time approximation algorithm. It searches
bottom-up in a fixed window for repeating tree patterns. The size of
the sliding window, the maximal pattern size and the maximal rank of a
nonterminal can be specified as input parameters. 
One of the main drawbacks of BPLEX is that there exists only a slowly running implementation of it.

Extended-Repair (which we sometimes call E-Repair in the
sequel) is an algorithm developed by a group from 
the University of Paderborn, Germany 
\cite{Krislin08repair,Boettcher10clustering}. This algorithm is, just
like our Re-pair for Trees algorithm, based on the Re-pair algorithm
introduced in \cite{larsson2000off}. However, it was independently
developed and exhibits some fundamental differences to our
algorithm. One of the main differences is that the Extended-Repair
algorithm at first generates a DAG of the input tree and then
processes each part of it individually, \ie, it generates multiple
grammars which are combined in the end. The individual parts of the
input tree are called "repair packets". The maximal size of each
packet can be specified by an input parameter (default is 20\,000
edges). The author of \cite{Krislin08repair} points out that this
packet-based behavior may have a negative impact on the compression
performance of the Extended-Repair algorithm. Our own investigations
concerning a \trp version running on the DAG of the input tree instead 
of on the whole tree support this point of view. 

In \cite{Krislin08repair} it is shown that Extended-Repair achieves a much better
compression ratio on the XML document \texttt{NCBI\_snp.chr1},
when the input tree is not broken down into packets (this can 
be achieved by choosing the maximum packet size large enough). 
However, our experiments show that at
the same time the memory requirements and the runtime of the
Extended-Repair algorithm rise drastically. Note that, regarding our
algorithm, the DAG representation is merely used to save memory
resources and is almost completely 
transparent to the overlying \tp replacement process 
(\cf Sect.~\ref{sec:impactDag} on page \pageref{sec:impactDag}). 

\subsection{Testing Environment}

Our experiments were done on a computer with an Intel\textregistered\space Core\texttrademark\space2 Duo CPU T9400 processor, four gigabytes of RAM and the Linux operating system. Every algorithm was executed on a single processor core, \ie, no algorithm was able to make use of multiprocessing. \trp and BPLEX were compiled with the \texttt{gcc}-compiler using the \texttt{-O3} (compile time optimizations) and \texttt{-m32} (\ie, we generated them as 32bit-applications) switches. We were not able to compile the \texttt{succ}-tool of the BPLEX distribution with compile time optimizations (\ie, using the \texttt{-O3} switch). This tool is used to apply a succinct coding to a grammar generated by the BPLEX algorithm.  However, this should not have a great influence on the runtime measured for BPLEX since the \texttt{succ}-tool usually executes quite fast compared to the runtime of the actual BPLEX algorithm. In contrast, Extended-Repair is an application written in Java\texttrademark\space for which we only had the bytecode at hand, \ie, we did not have access to the source code of it. We executed Extended-Repair using the Java SE Runtime Environment\texttrademark\space in version \texttt{1.6.0\_15}.

During the execution of the algorithms we always measured their memory usage. We accomplished this by constantly polling the \texttt{VmRSS}-value which is printed out by executing the command \texttt{cat /proc/<pid>/status}, where \texttt{<pid>} is the process ID assigned to the algorithm. In the first second of the execution of an algorithm this value was checked every ten milliseconds and after that the frequency was slowly reduced to one second.

Every time we executed BPLEX we used its default input parameters, namely, window size: 20\,000, maximal pattern size: 20, maximal rank: 10. In order to be able to test BPLEX together with every file of our set of test XML documents we needed to explicitly allow large stack sizes using the standard tool \texttt{ulimit}.

\begin{table}[tb]
	\centering\small
	\begin{tabular}{lrrrrr}
		\toprule
		&\trp&BPLEX&E-Repair&mDAG&bin. mDAG\\
		\midrule
		Edges (\%)&2.9&3.4&4.1&12.8&18.3\\
		\#\,NTs&4\,753&13\,660&6\,522&2\,075&5\,320\\
		\midrule
		Time (sec)&10&322&63&-&-\\
		Mem (MB)&47&536&401&-&-\\
		File size (\%)&0.46&0.71&0.61&-&-\\
		\bottomrule
	\end{tabular}
	\caption{Average values of the characteristics of the generated grammars and of the corresponding runs of the algorithms.}
	\label{tbl:avgValuesOfCharacteristicsOptimizeEdges}
\end{table}

\subsection{Comparison of the Generated Grammars}

In this section, we compare the final grammars generated by the algorithms \trp, BPLEX and Extended-Repair. All algorithms were instructed to minimize the number of edges of the generated grammar. For \trp, we achieved this behavior by specifying the \texttt{-optimize edges} input parameter. Regarding Extended-Repair, we used the supplied \texttt{ConfEdges.xml} configuration file which is supposed to make Extended-Repair minimize the number of edges. The BPLEX algorithm was executed with its default input parameter values and no changes were made to the generated grammar (besides pruning nonterminals which are referenced only once by using the supplied \texttt{gprint} tool).

Table \ref{tbl:avgValuesOfCharacteristicsOptimizeEdges} shows the average values of the essential characteristics of the final grammars generated by the three competing algorithms. The first row shows the average compression factors in terms of the number of edges in percent. The edge compression factor is computed as follows: if  is the binary representation of the input tree and  is the final grammar, we obtain the edge compression factor by computing . The second row shows the average number of nonterminals of the final grammars. For the sake of completeness, the average runtimes (in seconds), the average memory usages (in megabytes) and the average file size compression factors are also listed. The compression factor in terms of file size specifies the ratio between the size of the input file and the file size of the succinct coding of the final grammar in percent.

We also added two columns to Table \ref{tbl:avgValuesOfCharacteristicsOptimizeEdges} showing the average number of edges and the average number of nonterminals of the minimal DAGs of the input trees (mDAG) and the minimal DAGs of the binary representations of the input trees (bin. mDAG).

As it can be seen, on average, \trp generates the smallest linear SLCF tree grammars (in terms of the number of edges) compared to the other two algorithms. At the same time, its grammars exhibit a small number of nonterminals. It outperforms BPLEX and Extended-Repair in terms of runtime and memory usage. The speed and moderate requirements on main memory are a result of the transparent DAG representation of the input tree and the many optimizations we made to the source code of \trp during our investigations.

\begin{table}[tb]
	\centering\small
	\begin{tabular}{lrrrrrr}
		\toprule
		&\trp&BPLEX&E-Repair&XMill&gzip&bzip2\\
		\midrule
		File size (\%)&0.45&0.57&0.61&0.47&1.36&0.58\\
		\midrule
		Time (sec)&10&329&167&119&\,1&16\\
		Mem (MB)&47&536&399&7&-&7\\
		Edges (\%)&3.0&3.9&4.1&-&-&-\\
		\#\,NTs&2\,642&2\,796&7\,003&-&-&-\\
		\bottomrule
	\end{tabular}
	\caption{Average values of the characteristics of the runs of the three algorithms when making a small size of the output file top priority.}\label{tbl:avgValuesOfCharacteristicsOptimizeFileSize}
\end{table}

Figure \ref{fig:diagramEdgesCompression} on page \pageref{fig:diagramEdgesCompression} gives an impression on how each of the three algorithms performs on the individual XML documents in terms of the size of the final grammar in edges. For each file, the algorithm which generates the largest grammar is set to 100\%. In Appendix \ref{sec:detailedResultsOptimizationEdges} on page \pageref{sec:detailedResultsOptimizationEdges} there is a detailed table listing all relevant characteristics of the runs of the algorithms on the set of test XML documents.

\subsection{Comparison of Output File Sizes}

In this section, we concentrate on the sizes of the files generated by the runs of the algorithms on our set of test XML documents. In fact, we execute each algorithm in a mode in which the size of the resulting file is made a top priority. For \trp, we achieve this by specifying the input parameter \texttt{-optimize filesize} and for Extended-Repair, we get such a behavior by using the supplied \texttt{ConfSize.xml} configuration file and the \texttt{-s 4} switch. The latter chooses a certain succinct coding of the Extended-Repair distribution which is supposed to generate very small representations of the generated grammar. Regarding BPLEX, we first apply the supplied \texttt{gprint}-tool using the parameters \texttt{-\xspace-prune} and \texttt{-\xspace-threshold 14}. After that we use the \texttt{succ}-tool of the BPLEX distribution together with the parameter \texttt{-\xspace-type 68} to generate a Huffman coding-based succinct coding of the corresponding grammar. In \cite{Maneth08xml} it is stated that this approach leads to the best compression performance of BPLEX in general (in terms of file size).

In addition to the above three algorithms, we also consider the compression results produced by gzip, bzip2\footnote{For more information about the gzip algorithm, see \url{http://www.gzip.org}. For bzip2, see \url{http://www.bzip.org}.} and XMill 0.8 \cite{liefke2000xmill}. We include them in our comparison to make it easier to get a handle for common compression rates and runtimes. The first two algorithms are widely used general purpose file compressors which, of course, produce a non-queryable compressed representation of the input file. In contrast, XMill is a compressor specialized in compressing the structure and, in particular, the character data of XML documents. In fact, it mainly concentrates on how to group the character data of an XML document in such a way that it can be efficiently compressed by general purpose compressors like gzip. Since its implementation does not exhibit a special "only consider the structure of the XML document" mode, it may be unfair to directly compare its compression results with those of \trp, BPLEX or Extended-Repair. However, we included its compression results, which we obtained using its default input parameters, because we were interested in its performance in this setting.

Table \ref{tbl:avgValuesOfCharacteristicsOptimizeFileSize} shows the average sizes of the output files generated by the six algorithms mentioned above. For the sake of completeness, the average runtime, the average memory usage, the average number of edges and the average number of nonterminals are also listed. Again, \trp outperforms BPLEX and Extended-Repair regarding all considered characteristics. Surprisingly, its queryable output files are even smaller than the non-queryable ones produced by the highly optimized gzip and bzip2 algorithms. However, gzip (but interestingly not bzip2) runs much faster than \trp on our test data.

Figure \ref{fig:diagramFileSizeCompression} gives an impression on how each of the six algorithms performs on the individual XML documents in terms of the size of the generated output file. For each file, the algorithm which generates the biggest output file is set to 100\%. In Appendix \ref{sec:detailedResultsOptimizationFileSize} on page \pageref{sec:detailedResultsOptimizationFileSize} there is a detailed table listing all relevant characteristics of the runs of the algorithms on our set of test XML documents.

\begin{figure}[p]
	\subfigure[{Comparison of the number of edges of the final grammars.}]{
		\centering
		\includegraphics{diagramEdgesCompressionFactorRelative}
		\label{fig:diagramEdgesCompression}
	}
	\subfigure[{Comparison of the sizes of the output files.}]{
		\centering
		\includegraphics{diagramCompressionFactorRelative}
		\label{fig:diagramFileSizeCompression}
	}
\end{figure}

\subsection{Results without DAG Representation}\label{sec:resultsWithoutDag}

Table \ref{tbl:avgValuesOfCharacteristicsNoDag} shows a comparison between the compression results of \trp when using and when not using, respectively, the DAG representation described in Sect.~\ref{sec:representingTreeInMemory} on page \pageref{sec:representingTreeInMemory}. The left column shows the values obtained when executing \trp with its default parameters in edge optimization mode, \ie, we are only using the \texttt{-optimize edges} switch since our algorithm uses the DAG representation by default. In contrast, the right column is a result of running \trp with the \texttt{-no\_dag} and \texttt{-optimize edges} switches.  Again, in Appendix \ref{sec:detailedResultsNoDag} on page \pageref{sec:detailedResultsNoDag}, there is a detailed table listing all relevant characteristics of the runs of the two \trp configurations on each test XML document.

\begin{table}[tb]
	\centering\small
	\begin{tabular}{lrr}
		\toprule
		&with DAG&without DAG\\
		\midrule
		Edges (\%)&2.86&2.84\\
		\#\,NTs&4\,753&4\,620\\
		File size (\%)&0.463&0.459\\
		Time (sec)&9.8&11.2\\
		Mem (MB)&47&188\\
		\bottomrule
	\end{tabular}
	\caption{Average values of the characteristics of the runs of \trp with and without the DAG representation of the input tree.}\label{tbl:avgValuesOfCharacteristicsNoDag}
\end{table}

Regarding the differences between the compression results of \trp and the ones of the competing algorithms, it can be said that the DAG representation only has a minor impact on the compression performance of our algorithm. However, we can state that it drastically reduces the memory demands of \trp\space--- it slashes the memory consumption by a factor of 4. Interestingly, even without the DAG representation, \trp uses only half as much main memory as Extended-Repair does (\cf Table~\ref{tbl:avgValuesOfCharacteristicsOptimizeEdges}). Furthermore, the DAG representation leads to a faster compression speed since it saves repetitive recalculations concerning equal subtrees.

\subsection{Results with Different Maximal Ranks}\label{sec:resultsWithDifferentMaximalRanks}

\begin{table}[tb]
	\centering\small
	\begin{tabular}{lrrrrrrr}
		\toprule
		Max. rank&0&1&2&3&4&5&6\\
		\midrule
		Edges (\%)&55.02&3.29&2.92&2.89&2.86&2.89&2.89\\
		\#\,NTs&1\,265&5\,539&4\,712&4\,916&4\,753&4\,956&4\,958\\
		File size (\%)&2.12&0.51&0.47&0.47&0.46&0.47&0.46\\
		Time (sec)&7.0&8.4&9.3&9.5&9.6&9.8&9.8\\
		Mem (MB)&44&44&45&47&47&47&47\\
		\bottomrule
	\end{tabular}
	\caption{Average values of the characteristics of the runs of \trp with different maximal ranks allowed for a nonterminal.}\label{tbl:avgValuesOfCharacteristicsRanks}
\end{table}

We executed TreeRePair using the \texttt{-optimize edges} (\ie, we
enabled the edge optimization mode) and the \texttt{-max\_rank}
switches. Each time, we specified a different maximal rank for a
nonterminal in order to get information concerning its influence on 
the compression performance. Table~\ref{tbl:avgValuesOfCharacteristicsRanks} shows that, regarding our
set of test XML documents, a maximal rank 
of 4 leads to the best compression results on average. 

At the same time, we can see that even when restricting the maximal
rank to 1 \trp performs better than BPLEX and Extended-Repair (\cf
Table~\ref{tbl:avgValuesOfCharacteristicsOptimizeEdges}). The fact
that large maximal ranks can lead to a worse compression ratio can be
explained by the trees from Sect.~\ref{sec:limitingTheMaximalRank} on
page \pageref{sec:limitingTheMaximalRank}. Note that the trees from
this section are basically long lists. Although this is not the case
for our test trees, their shape is nevertheless similar to a list
structure. In any case, its quite distinct from the shape of a full
binary tree, where an unlimited maximal rank leads to 
the best compression ratio (\cf Sect.~\ref{sec:observations} on page \pageref{sec:observations}).



\newcommand{\etalchar}[1]{}
\begin{thebibliography}{BPSM{\etalchar{+}}08}

\bibitem[BGK03]{Buneman03path}
Peter Buneman, Martin Grohe, and Christoph Koch.
\newblock Path queries on compressed {XML}.
\newblock In {\em VLDB 2003: Proceedings of the 29th international conference
  on very large data bases}, pages 141--152. VLDB Endowment, 2003.

\bibitem[BHK10]{Boettcher10clustering}
Stefan B{\"o}ttcher, Rita Hartel, and Christoph Krislin.
\newblock Clu{X}: Clustering {XML} sub-trees.
\newblock In {\em ICEIS 2010: Proceedings of the 12th International Conference
  on Enterprise Information Systems}, 2010.

\bibitem[BLM08]{Busatto08efficient}
Giorgio Busatto, Markus Lohrey, and Sebastian Maneth.
\newblock Efficient memory representation of {XML} document trees.
\newblock {\em Information Systems}, 33(4-5):456 -- 474, 2008.

\bibitem[BPSM{\etalchar{+}}08]{Yergeau08}
Tim Bray, Jean Paoli, C.~Michael Sperberg-McQueen, Eve Maler, and Fran\c{c}ois
  Yergeau.
\newblock Extensible markup language ({XML}) 1.0.
\newblock W3c recommendation, XML Core Working Group, World Wide Web
  Consortium, November 2008.

\bibitem[CDG{\etalchar{+}}07]{tata2007}
H.~Comon, M.~Dauchet, R.~Gilleron, C.~L\"oding, F.~Jacquemard, D.~Lugiez,
  S.~Tison, and M.~Tommasi.
\newblock Tree automata techniques and applications.
\newblock \url{http://www.grappa.univ-lille3.fr/tata}, 2007.

\bibitem[CLL{\etalchar{+}}05]{Charikar05smallest}
Moses Charikar, Eric Lehman, April Lehman, Ding Liu, Rina Panigrahy, Manoj
  Prabhakaran, Amit Sahai, and Abhi Shelat.
\newblock The smallest grammar problem.
\newblock {\em IEEE Trans. Inform. Theory}, 51(7):2554--2576, 2005.

\bibitem[Deu96]{Deutsch96deflate}
P.~Deutsch.
\newblock {DEFLATE} compressed data format specification version 1.3.
\newblock \url{http://tools.ietf.org/html/rfc1951}, 1996.

\bibitem[FGK03]{Frick03query}
Markus Frick, Martin Grohe, and Christoph Koch.
\newblock Query evaluation on compressed trees (extended abstract).
\newblock In {\em LICS '03: Proceedings of the 18th Annual IEEE Symposium on
  Logic in Computer Science}, pages 188--197. IEEE Computer Society Press,
  2003.

\bibitem[Kri08]{Krislin08repair}
Christoph Krislin.
\newblock Optimierung grammatik-basierter {XML}-{K}ompression.
\newblock Diplomarbeit, Faculty for Electrical Engineering, Computer Science
  and Mathematics, University of Paderborn (Germany), 2008.

\bibitem[LM00]{larsson2000off}
N.~Jesper Larsson and Alistair Moffat.
\newblock {Off-line dictionary-based compression}.
\newblock {\em Proceedings of the IEEE}, 88(11):1722--1732, 2000.

\bibitem[LM06]{Lohrey2006complexity}
Markus Lohrey and Sebastian Maneth.
\newblock The complexity of tree automata and {XP}ath on grammar-compressed
  trees.
\newblock {\em Theoretical Computer Science}, 363(2):196 -- 210, 2006.

\bibitem[LMSS09]{Lohrey09parameterreduction}
Markus Lohrey, Sebastian Maneth, and Manfred Schmidt-Schauss.
\newblock Parameter reduction in grammar-compressed trees.
\newblock In {\em Proceedings of FOSSACS 2009, number 5504 in Lecture Notes in
  Computer Science}, pages 212--226. Springer, 2009.

\bibitem[LS00]{liefke2000xmill}
H.~Liefke and D.~Suciu.
\newblock {XMill: an efficient compressor for XML data}.
\newblock In {\em Proceedings of the 2000 ACM SIGMOD International Conference
  on Management of Data}, page 164. ACM Press, 2000.

\bibitem[MLMK05]{Murata05taxonomy}
Makoto Murata, Dongwon Lee, Murali Mani, and Kohsuke Kawaguchi.
\newblock Taxonomy of {XML} schema languages using formal language theory.
\newblock {\em ACM Transactions on Internet Technology}, 5(4):660--704, 2005.

\bibitem[MMS08]{Maneth08xml}
Sebastian Maneth, Nikolay Mihaylov, and Sherif Sakr.
\newblock {XML} tree structure compression.
\newblock {\em International Workshop on Database and Expert Systems
  Applications}, pages 243--247, 2008.

\bibitem[MSV03]{Milo03typechecking}
Tova Milo, Dan Suciu, and Victor Vianu.
\newblock Typechecking for {XML} transformers.
\newblock {\em Journal of Computer and System Sciences}, 66(1):66 -- 97, 2003.

\bibitem[Nev02]{Neven02automata}
Frank Neven.
\newblock Automata theory for {XML} researchers.
\newblock {\em SIGMOD Record}, 31(3):39--46, 2002.

\bibitem[WLH07]{Wang07space}
Fangju Wang, Jing Li, and Hooman Homayounfar.
\newblock A space efficient {XML} {DOM} parser.
\newblock {\em Data \& Knowledge Engineering}, 60(1):185 -- 207, 2007.

\end{thebibliography}


\newpage

\appendix

\section{Detailed Test Results}\label{ch:detailedResults}

\subsection{Optimization of Total Number of Edges}\label{sec:detailedResultsOptimizationEdges}

\begin{longtable}{lrrrrr}
			\toprule
\textbf{Algorithm}&\textbf{Edges}&\textbf{File size}&\textbf{\#NTs}&\textbf{Time}&\textbf{Mem (MB)}\\\midrule
\endhead
			\toprule
\textbf{Algorithm}&\textbf{Edges}&\textbf{File size}&\textbf{\#NTs}&\textbf{Time}&\textbf{Mem (MB)}\\
\endfirsthead
			\midrule\multicolumn{6}{c}{\emph{1998statistics}}\\*
			TreeRePair&1.68\%&0.20\%&54&100ms&1\\*
			BPLEX&1.80\%&0.34\%&168&1.813s&295\\*
			E-Repair&1.69\%&0.24\%&37&7.518s&114\\*
			bin. mDAG&8.49\%&-&31&-&-\\*
			mDAG&4.87\%&-&15&-&-\\
			\midrule\multicolumn{6}{c}{\emph{catalog-01}}\\*
			TreeRePair&1.69\%&0.10\%&400&887ms&2\\*
			BPLEX&2.22\%&0.22\%&1251&6.548s&315\\*
			E-Repair&1.63\%&0.12\%&291&9.975s&279\\*
			bin. mDAG&3.10\%&-&520&-&-\\*
			mDAG&3.80\%&-&506&-&-\\
			\midrule\multicolumn{6}{c}{\emph{catalog-02}}\\*
			TreeRePair&1.11\%&0.07\%&965&9.409s&10\\*
			BPLEX&1.38\%&0.11\%&3045&30s&512\\*
			E-Repair&1.52\%&0.11\%&1499&42s&511\\*
			bin. mDAG&2.22\%&-&805&-&-\\*
			mDAG&1.39\%&-&792&-&-\\
			\midrule\multicolumn{6}{c}{\emph{dblp}}\\*
			TreeRePair&3.89\%&0.59\%&25250&43s&227\\*
			BPLEX&4.27\%&0.73\%&38712&57m 42s&1644\\*
			E-Repair&5.65\%&0.68\%&30430&4m 34s&510\\*
			bin. mDAG&19.36\%&-&6592&-&-\\*
			mDAG&11.11\%&-&3378&-&-\\
			\midrule\multicolumn{6}{c}{\emph{dictionary-01}}\\*
			TreeRePair&7.72\%&1.54\%&1676&1.010s&9\\*
			BPLEX&8.43\%&2.37\%&3994&44s&323\\*
			E-Repair&8.71\%&1.83\%&1248&16s&433\\*
			bin. mDAG&27.99\%&-&2058&-&-\\*
			mDAG&21.07\%&-&448&-&-\\
			\midrule\multicolumn{6}{c}{\emph{dictionary-02}}\\*
			TreeRePair&5.92\%&1.38\%&9757&11s&69\\*
			BPLEX&6.58\%&1.95\%&23209&6m 12s&587\\*
			E-Repair&8.52\%&1.83\%&11672&1m 40s&494\\*
			bin. mDAG&24.93\%&-&16281&-&-\\*
			mDAG&19.96\%&-&2414&-&-\\
			\midrule\multicolumn{6}{c}{\emph{EnWikiNew}}\\*
			TreeRePair&2.29\%&0.21\%&667&1.585s&8\\*
			BPLEX&2.40\%&0.30\%&1369&35s&337\\*
			E-Repair&2.42\%&0.24\%&476&12s&347\\*
			bin. mDAG&17.31\%&-&23&-&-\\*
			mDAG&8.67\%&-&29&-&-\\
			\midrule\multicolumn{6}{c}{\emph{EnWikiQuote}}\\*
			TreeRePair&2.42\%&0.21\%&452&1.158s&7\\*
			BPLEX&2.56\%&0.31\%&985&25s&321\\*
			E-Repair&2.58\%&0.26\%&323&9.924s&290\\*
			bin. mDAG&18.14\%&-&19&-&-\\*
			mDAG&9.09\%&-&25&-&-\\
			\midrule\multicolumn{6}{c}{\emph{EnWikiSource}}\\*
			TreeRePair&1.10\%&0.10\%&861&4.927s&26\\*
			BPLEX&1.28\%&0.16\%&1895&1m 9s&418\\*
			E-Repair&1.82\%&0.18\%&1106&23s&500\\*
			bin. mDAG&17.52\%&-&19&-&-\\*
			mDAG&8.77\%&-&24&-&-\\
			\midrule\multicolumn{6}{c}{\emph{EnWikiVersity}}\\*
			TreeRePair&1.44\%&0.13\%&525&2.107s&12\\*
			BPLEX&1.53\%&0.18\%&1043&34s&347\\*
			E-Repair&1.61\%&0.15\%&423&12s&437\\*
			bin. mDAG&17.60\%&-&19&-&-\\*
			mDAG&8.81\%&-&24&-&-\\
			\midrule\multicolumn{6}{c}{\emph{EnWikTionary}}\\*
			TreeRePair&0.97\%&0.11\%&4535&36s&183\\*
			BPLEX&1.09\%&0.14\%&6402&8m 58s&1287\\*
			E-Repair&1.48\%&0.15\%&6315&1m 33s&540\\*
			bin. mDAG&17.32\%&-&26&-&-\\*
			mDAG&8.66\%&-&30&-&-\\
			\midrule\multicolumn{6}{c}{\emph{EXI-Array}}\\*
			TreeRePair&0.41\%&0.03\%&123&1.281s&14\\*
			BPLEX&0.65\%&0.06\%&383&42s&322\\*
			E-Repair&0.53\%&0.05\%&142&8.017s&320\\*
			bin. mDAG&56.51\%&-&8&-&-\\*
			mDAG&42.20\%&-&13&-&-\\
			\midrule\multicolumn{6}{c}{\emph{EXI-factbook}}\\*
			TreeRePair&2.35\%&0.31\%&145&271ms&2\\*
			BPLEX&4.11\%&0.77\%&1423&5.138s&298\\*
			E-Repair&2.58\%&0.31\%&146&11s&408\\*
			bin. mDAG&9.16\%&-&236&-&-\\*
			mDAG&8.07\%&-&293&-&-\\
			\midrule\multicolumn{6}{c}{\emph{EXI-Invoice}}\\*
			TreeRePair&0.68\%&0.21\%&14&74ms&1\\*
			BPLEX&0.62\%&0.30\%&40&1.483s&293\\*
			E-Repair&0.93\%&0.24\%&20&4.689s&119\\*
			bin. mDAG&13.74\%&-&6&-&-\\*
			mDAG&7.12\%&-&15&-&-\\
			\midrule\multicolumn{6}{c}{\emph{EXI-Telecomp}}\\*
			TreeRePair&0.07\%&0.01\%&21&780ms&3\\*
			BPLEX&0.06\%&0.02\%&47&9.684s&310\\*
			E-Repair&0.08\%&0.02\%&21&11s&452\\*
			bin. mDAG&11.15\%&-&10&-&-\\*
			mDAG&5.59\%&-&15&-&-\\
			\midrule\multicolumn{6}{c}{\emph{EXI-weblog}}\\*
			TreeRePair&0.06\%&0.01\%&13&324ms&3\\*
			BPLEX&0.04\%&0.01\%&24&9.097s&303\\*
			E-Repair&0.05\%&0.02\%&11&7.868s&279\\*
			bin. mDAG&18.19\%&-&2&-&-\\*
			mDAG&9.10\%&-&2&-&-\\
			\midrule\multicolumn{6}{c}{\emph{JST\_gene.chr1}}\\*
			TreeRePair&1.84\%&0.10\%&354&874ms&3\\*
			BPLEX&2.19\%&0.19\%&1113&11s&315\\*
			E-Repair&2.99\%&0.17\%&126&8.006s&233\\*
			bin. mDAG&6.75\%&-&114&-&-\\*
			mDAG&4.24\%&-&76&-&-\\
			\midrule\multicolumn{6}{c}{\emph{JST\_snp.chr1}}\\*
			TreeRePair&1.51\%&0.09\%&856&3.150s&8\\*
			BPLEX&2.15\%&0.21\%&4193&31s&360\\*
			E-Repair&1.54\%&0.10\%&634&15s&445\\*
			bin. mDAG&6.20\%&-&282&-&-\\*
			mDAG&3.59\%&-&242&-&-\\
			\midrule\multicolumn{6}{c}{\emph{medline02n0328}}\\*
			TreeRePair&4.13\%&0.35\%&9064&16s&79\\*
			BPLEX&5.17\%&0.62\%&33976&5m 52s&574\\*
			E-Repair&6.73\%&0.54\%&13010&1m 32s&479\\*
			bin. mDAG&25.84\%&-&20013&-&-\\*
			mDAG&22.80\%&-&3960&-&-\\
			\midrule\multicolumn{6}{c}{\emph{NCBI\_gene.chr1}}\\*
			TreeRePair&1.37\%&0.09\%&504&1.374s&4\\*
			BPLEX&2.38\%&0.28\%&3631&14s&327\\*
			E-Repair&1.68\%&0.11\%&328&10s&308\\*
			bin. mDAG&3.98\%&-&605&-&-\\*
			mDAG&4.45\%&-&436&-&-\\
			\midrule\multicolumn{6}{c}{\emph{NCBI\_snp.chr1}}\\*
			TreeRePair&\,0.01\%&\,0.01\%&17&15s&80\\*
			BPLEX&\,0.01\%&\,0.01\%&23&2m 6s&770\\*
			E-Repair&0.03\%&0.01\%&291&37s&504\\*
			bin. mDAG&22.22\%&-&2&-&-\\*
			mDAG&11.11\%&-&2&-&-\\
			\midrule\multicolumn{6}{c}{\emph{sprot39.dat}}\\*
			TreeRePair&2.30\%&0.38\%&20224&43s&178\\*
			BPLEX&3.16\%&0.79\%&111167&14m 41s&1446\\*
			E-Repair&4.27\%&0.59\%&33102&3m 48s&499\\*
			bin. mDAG&13.18\%&-&31116&-&-\\*
			mDAG&16.07\%&-&10243&-&-\\
			\midrule\multicolumn{6}{c}{\emph{treebank}}\\*
			TreeRePair&20.72\%&4.41\%&32857&22s&164\\*
			BPLEX&23.29\%&6.16\%&76109&21m 27s&645\\*
			E-Repair&34.85\%&6.03\%&48358&6m 50s&526\\*
			bin. mDAG&59.42\%&-&43586&-&-\\*
			mDAG&53.75\%&-&24746&-&-\\
			\bottomrule
		\end{longtable}



\newpage

\subsection{Optimization of File Size}\label{sec:detailedResultsOptimizationFileSize}

\begin{longtable}{lrrrrr}
			\toprule
\textbf{Algorithm}&\textbf{Edges}&\textbf{File size}&\textbf{\#NTs}&\textbf{Time}&\textbf{Mem (MB)}\\\midrule
\endhead
			\toprule
\textbf{Algorithm}&\textbf{Edges}&\textbf{File size}&\textbf{\#NTs}&\textbf{Time}&\textbf{Mem (MB)}\\
\endfirsthead
			\midrule\multicolumn{6}{c}{\emph{1998statistics}}\\*
			TreeRePair&1.77\%&0.20\%&35&109ms&1\\*
			BPLEX&2.19\%&0.25\%&27&2.018s&295\\*
			E-Repair&1.68\%&0.24\%&37&4.578s&108\\*
			bzip2&-&0.29\%&-&229ms&4\\*
			gzip&-&0.81\%&-&8ms&-\\*
			XMill&-&0.24\%&-&2.728s&2\\
			\midrule\multicolumn{6}{c}{\emph{catalog-01}}\\*
			TreeRePair&1.76\%&0.10\%&279&898ms&2\\*
			BPLEX&2.23\%&0.14\%&342&6.834s&315\\*
			E-Repair&2.77\%&0.19\%&236&11s&349\\*
			bzip2&-&0.24\%&-&2.701s&8\\*
			gzip&-&0.85\%&-&51ms&-\\*
			XMill&-&0.11\%&-&12s&2\\
			\midrule\multicolumn{6}{c}{\emph{catalog-02}}\\*
			TreeRePair&1.12\%&0.07\%&770&10s&10\\*
			BPLEX&1.27\%&0.08\%&948&32s&512\\*
			E-Repair&1.49\%&0.12\%&1692&47s&521\\*
			bzip2&-&0.23\%&-&28s&8\\*
			gzip&-&0.81\%&-&450ms&-\\*
			XMill&-&0.09\%&-&1m 58s&12\\
			\midrule\multicolumn{6}{c}{\emph{dblp}}\\*
			TreeRePair&4.03\%&0.58\%&14533&43s&227\\*
			BPLEX&4.52\%&0.65\%&11693&61m 15s&1644\\*
			E-Repair&5.52\%&0.68\%&35125&42m 48s&516\\*
			bzip2&-&0.56\%&-&1m 11s&8\\*
			gzip&-&1.30\%&-&1.230s&-\\*
			XMill&-&0.53\%&-&11m 36s&15\\
			\midrule\multicolumn{6}{c}{\emph{dictionary-01}}\\*
			TreeRePair&8.08\%&1.47\%&930&1.117s&9\\*
			BPLEX&9.67\%&1.85\%&1044&46s&323\\*
			E-Repair&8.51\%&1.81\%&1428&19s&462\\*
			bzip2&-&1.52\%&-&1.313s&7\\*
			gzip&-&3.07\%&-&39ms&-\\*
			XMill&-&1.49\%&-&17s&2\\
			\midrule\multicolumn{6}{c}{\emph{dictionary-02}}\\*
			TreeRePair&6.15\%&1.32\%&5024&11s&69\\*
			BPLEX&7.56\%&1.63\%&5424&6m 12s&587\\*
			E-Repair&8.30\%&1.81\%&13698&1m 57s&475\\*
			bzip2&-&1.52\%&-&15s&7\\*
			gzip&-&3.05\%&-&279ms&-\\*
			XMill&-&1.49\%&-&2m 41s&13\\
			\midrule\multicolumn{6}{c}{\emph{EnWikiNew}}\\*
			TreeRePair&2.38\%&0.20\%&390&1.721s&8\\*
			BPLEX&2.63\%&0.23\%&335&35s&337\\*
			E-Repair&2.42\%&0.24\%&476&12s&369\\*
			bzip2&-&0.26\%&-&2.999s&8\\*
			gzip&-&0.90\%&-&57ms&-\\*
			XMill&-&0.23\%&-&23s&2\\
			\midrule\multicolumn{6}{c}{\emph{EnWikiQuote}}\\*
			TreeRePair&2.51\%&0.20\%&274&1.195s&7\\*
			BPLEX&2.81\%&0.23\%&236&25s&321\\*
			E-Repair&2.58\%&0.26\%&323&10s&268\\*
			bzip2&-&0.28\%&-&2.013s&8\\*
			gzip&-&0.93\%&-&36ms&-\\*
			XMill&-&0.24\%&-&15s&2\\
			\midrule\multicolumn{6}{c}{\emph{EnWikiSource}}\\*
			TreeRePair&1.14\%&0.10\%&515&5.025s&26\\*
			BPLEX&1.40\%&0.13\%&535&1m 10s&418\\*
			E-Repair&1.82\%&0.18\%&1127&23s&488\\*
			bzip2&-&0.16\%&-&8.742s&8\\*
			gzip&-&0.63\%&-&131ms&-\\*
			XMill&-&0.12\%&-&1m 4s&9\\
			\midrule\multicolumn{6}{c}{\emph{EnWikiVersity}}\\*
			TreeRePair&1.50\%&0.12\%&303&2.244s&12\\*
			BPLEX&1.70\%&0.15\%&287&36s&347\\*
			E-Repair&1.61\%&0.15\%&423&13s&415\\*
			bzip2&-&0.19\%&-&3.698s&8\\*
			gzip&-&0.69\%&-&59ms&-\\*
			XMill&-&0.15\%&-&28s&2\\
			\midrule\multicolumn{6}{c}{\emph{EnWikTionary}}\\*
			TreeRePair&1.00\%&0.11\%&2575&37s&183\\*
			BPLEX&1.15\%&0.13\%&2062&9m 13s&1287\\*
			E-Repair&1.48\%&0.15\%&6314&1m 40s&526\\*
			bzip2&-&0.17\%&-&57s&8\\*
			gzip&-&0.68\%&-&938ms&-\\*
			XMill&-&0.13\%&-&7m 25s&15\\
			\midrule\multicolumn{6}{c}{\emph{EXI-Array}}\\*
			TreeRePair&0.44\%&0.03\%&75&1.393s&14\\*
			BPLEX&0.77\%&0.05\%&124&43s&322\\*
			E-Repair&0.51\%&0.05\%&155&7.833s&312\\*
			bzip2&-&0.05\%&-&3.250s&8\\*
			gzip&-&0.37\%&-&67ms&-\\*
			XMill&-&0.03\%&-&10s&6\\
			\midrule\multicolumn{6}{c}{\emph{EXI-factbook}}\\*
			TreeRePair&2.51\%&0.31\%&99&356ms&2\\*
			BPLEX&6.44\%&0.58\%&170&5.333s&298\\*
			E-Repair&2.59\%&0.31\%&151&12s&438\\*
			bzip2&-&0.78\%&-&854ms&8\\*
			gzip&-&1.10\%&-&17ms&-\\*
			XMill&-&0.29\%&-&5.248s&1\\
			\midrule\multicolumn{6}{c}{\emph{EXI-Invoice}}\\*
			TreeRePair&0.72\%&0.21\%&11&147ms&2\\*
			BPLEX&0.78\%&0.28\%&8&1.406s&293\\*
			E-Repair&0.91\%&0.24\%&21&4.320s&113\\*
			bzip2&-&0.30\%&-&191ms&3\\*
			gzip&-&0.64\%&-&7ms&-\\*
			XMill&-&0.26\%&-&1.256s&2\\
			\midrule\multicolumn{6}{c}{\emph{EXI-Telecomp}}\\*
			TreeRePair&0.08\%&0.01\%&12&829ms&3\\*
			BPLEX&0.07\%&0.02\%&15&9.548s&310\\*
			E-Repair&0.08\%&0.02\%&24&13s&450\\*
			bzip2&-&0.09\%&-&2.363s&8\\*
			gzip&-&0.45\%&-&36ms&-\\*
			XMill&-&0.02\%&-&11s&2\\
			\midrule\multicolumn{6}{c}{\emph{EXI-weblog}}\\*
			TreeRePair&0.06\%&0.01\%&9&400ms&3\\*
			BPLEX&0.05\%&0.01\%&12&9.004s&303\\*
			E-Repair&0.05\%&0.02\%&12&7.942s&288\\*
			bzip2&-&0.06\%&-&720ms&8\\*
			gzip&-&0.40\%&-&14ms&-\\*
			XMill&-&0.02\%&-&8.342s&2\\
			\midrule\multicolumn{6}{c}{\emph{JST\_gene.chr1}}\\*
			TreeRePair&1.91\%&0.10\%&227&906ms&3\\*
			BPLEX&2.42\%&0.13\%&211&11s&315\\*
			E-Repair&2.99\%&0.17\%&128&9.947s&211\\*
			bzip2&-&0.14\%&-&2.599s&8\\*
			gzip&-&0.67\%&-&43ms&-\\*
			XMill&-&0.10\%&-&14s&2\\
			\midrule\multicolumn{6}{c}{\emph{JST\_snp.chr1}}\\*
			TreeRePair&1.58\%&0.08\%&537&3.213s&8\\*
			BPLEX&2.45\%&0.14\%&569&32s&360\\*
			E-Repair&1.51\%&0.10\%&673&15s&453\\*
			bzip2&-&0.18\%&-&9.251s&8\\*
			gzip&-&0.79\%&-&149ms&-\\*
			XMill&-&0.09\%&-&40s&8\\
			\midrule\multicolumn{6}{c}{\emph{medline02n0328}}\\*
			TreeRePair&4.32\%&0.34\%&4923&16s&79\\*
			BPLEX&6.47\%&0.46\%&6717&5m 45s&574\\*
			E-Repair&6.71\%&0.54\%&13243&1m 38s&477\\*
			bzip2&-&0.49\%&-&31s&7\\*
			gzip&-&1.26\%&-&544ms&-\\*
			XMill&-&0.34\%&-&2m 13s&13\\
			\midrule\multicolumn{6}{c}{\emph{NCBI\_gene.chr1}}\\*
			TreeRePair&1.43\%&0.09\%&354&1.442s&4\\*
			BPLEX&3.00\%&0.16\%&464&14s&327\\*
			E-Repair&1.66\%&0.11\%&342&10s&265\\*
			bzip2&-&0.15\%&-&4.110s&8\\*
			gzip&-&0.71\%&-&65ms&-\\*
			XMill&-&0.08\%&-&21s&8\\
			\midrule\multicolumn{6}{c}{\emph{NCBI\_snp.chr1}}\\*
			TreeRePair&\,0.01\%&\,0.01\%&11&15s&80\\*
			BPLEX&\,0.01\%&\,0.01\%&15&2m 6s&770\\*
			E-Repair&0.03\%&0.01\%&292&33s&465\\*
			bzip2&-&0.03\%&-&40s&8\\*
			gzip&-&0.39\%&-&578ms&-\\*
			XMill&-&0.00\%&-&3m 45s&14\\
			\midrule\multicolumn{6}{c}{\emph{sprot39.dat}}\\*
			TreeRePair&2.41\%&0.37\%&11699&43s&178\\*
			BPLEX&4.33\%&0.53\%&11783&13m 43s&1446\\*
			E-Repair&4.25\%&0.59\%&33700&3m 59s&497\\*
			bzip2&-&0.45\%&-&1m 11s&8\\*
			gzip&-&1.20\%&-&1.122s&-\\*
			XMill&-&0.36\%&-&9m 52s&15\\
			\midrule\multicolumn{6}{c}{\emph{treebank}}\\*
			TreeRePair&21.59\%&4.28\%&17186&22s&164\\*
			BPLEX&26.21\%&5.37\%&21302&21m 36s&646\\*
			E-Repair&34.53\%&6.01\%&51470&7m 44s&514\\*
			bzip2&-&5.26\%&-&6.407s&7\\*
			gzip&-&9.65\%&-&843ms&-\\*
			XMill&-&4.51\%&-&1m 36s&12\\
			\bottomrule
		\end{longtable}



\newpage

\subsection{Without Using DAG Representation}\label{sec:detailedResultsNoDag}

\begin{longtable}{lrrrrr}
			\toprule
\textbf{Algorithm}&\textbf{Edges}&\textbf{File size}&\textbf{\#NTs}&\textbf{Time}&\textbf{Mem (MB)}\\\midrule
\endhead
			\toprule
\textbf{Algorithm}&\textbf{Edges}&\textbf{File size}&\textbf{\#NTs}&\textbf{Time}&\textbf{Mem (MB)}\\
\endfirsthead
			\midrule\multicolumn{6}{c}{\emph{1998statistics}}\\*
			Without DAG&1.62\%&0.20\%&53&121ms&4\\*
			With DAG&1.68\%&0.20\%&54&214ms&1\\
			\midrule\multicolumn{6}{c}{\emph{catalog-01}}\\*
			Without DAG&1.69\%&0.10\%&400&1.381s&20\\*
			With DAG&1.69\%&0.10\%&400&1.022s&3\\
			\midrule\multicolumn{6}{c}{\emph{catalog-02}}\\*
			Without DAG&1.11\%&0.07\%&967&15s&199\\*
			With DAG&1.11\%&0.07\%&965&9.584s&10\\
			\midrule\multicolumn{6}{c}{\emph{dblp}}\\*
			Without DAG&3.89\%&0.59\%&25039&55s&1015\\*
			With DAG&3.89\%&0.59\%&25250&44s&227\\
			\midrule\multicolumn{6}{c}{\emph{dictionary-01}}\\*
			Without DAG&7.63\%&1.51\%&1622&1.238s&25\\*
			With DAG&7.72\%&1.54\%&1676&1.044s&9\\
			\midrule\multicolumn{6}{c}{\emph{dictionary-02}}\\*
			Without DAG&5.88\%&1.36\%&9390&12s&238\\*
			With DAG&5.92\%&1.38\%&9757&11s&69\\
			\midrule\multicolumn{6}{c}{\emph{EnWikiNew}}\\*
			Without DAG&2.28\%&0.21\%&656&2.042s&37\\*
			With DAG&2.29\%&0.21\%&667&1.732s&8\\
			\midrule\multicolumn{6}{c}{\emph{EnWikiQuote}}\\*
			Without DAG&2.41\%&0.21\%&458&1.320s&24\\*
			With DAG&2.42\%&0.21\%&452&1.223s&7\\
			\midrule\multicolumn{6}{c}{\emph{EnWikiSource}}\\*
			Without DAG&1.09\%&0.10\%&863&5.652s&101\\*
			With DAG&1.10\%&0.10\%&861&5.087s&26\\
			\midrule\multicolumn{6}{c}{\emph{EnWikiVersity}}\\*
			Without DAG&1.43\%&0.13\%&522&2.472s&45\\*
			With DAG&1.44\%&0.13\%&525&2.229s&12\\
			\midrule\multicolumn{6}{c}{\emph{EnWikTionary}}\\*
			Without DAG&0.97\%&0.11\%&4539&42s&743\\*
			With DAG&0.97\%&0.11\%&4535&38s&183\\
			\midrule\multicolumn{6}{c}{\emph{EXI-Array}}\\*
			Without DAG&0.40\%&0.03\%&122&1.378s&21\\*
			With DAG&0.41\%&0.03\%&123&1.394s&14\\
			\midrule\multicolumn{6}{c}{\emph{EXI-factbook}}\\*
			Without DAG&2.34\%&0.31\%&144&331ms&6\\*
			With DAG&2.35\%&0.31\%&145&330ms&2\\
			\midrule\multicolumn{6}{c}{\emph{EXI-Invoice}}\\*
			Without DAG&0.61\%&0.21\%&12&85ms&3\\*
			With DAG&0.68\%&0.21\%&14&124ms&1\\
			\midrule\multicolumn{6}{c}{\emph{EXI-Telecomp}}\\*
			Without DAG&0.06\%&0.01\%&17&1.132s&17\\*
			With DAG&0.07\%&0.01\%&21&850ms&3\\
			\midrule\multicolumn{6}{c}{\emph{EXI-weblog}}\\*
			Without DAG&0.05\%&0.01\%&10&607ms&10\\*
			With DAG&0.06\%&0.01\%&13&400ms&3\\
			\midrule\multicolumn{6}{c}{\emph{JST\_gene.chr1}}\\*
			Without DAG&1.73\%&0.09\%&299&1.365s&21\\*
			With DAG&1.84\%&0.10\%&354&910ms&3\\
			\midrule\multicolumn{6}{c}{\emph{JST\_snp.chr1}}\\*
			Without DAG&1.50\%&0.09\%&841&4.187s&59\\*
			With DAG&1.51\%&0.09\%&856&3.287s&8\\
			\midrule\multicolumn{6}{c}{\emph{medline02n0328}}\\*
			Without DAG&4.11\%&0.34\%&8524&17s&235\\*
			With DAG&4.13\%&0.35\%&9064&17s&79\\
			\midrule\multicolumn{6}{c}{\emph{NCBI\_gene.chr1}}\\*
			Without DAG&1.37\%&0.09\%&486&1.959s&32\\*
			With DAG&1.37\%&0.09\%&504&1.498s&4\\
			\midrule\multicolumn{6}{c}{\emph{NCBI\_snp.chr1}}\\*
			Without DAG&\,0.01\%&\,0.01\%&13&18s&337\\*
			With DAG&\,0.01\%&\,0.01\%&17&15s&80\\
			\midrule\multicolumn{6}{c}{\emph{sprot39.dat}}\\*
			Without DAG&2.31\%&0.37\%&18516&55s&936\\*
			With DAG&2.30\%&0.38\%&20224&44s&178\\
			\midrule\multicolumn{6}{c}{\emph{treebank}}\\*
			Without DAG&20.71\%&4.41\%&32786&14s&215\\*
			With DAG&20.72\%&4.41\%&32857&22s&164\\
			\bottomrule
		\end{longtable}



\end{document}
