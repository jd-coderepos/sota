\documentclass{LMCS}


\makeatletter
\@ifundefined{lhs2tex.lhs2tex.sty.read}{\@namedef{lhs2tex.lhs2tex.sty.read}{}\newcommand\SkipToFmtEnd{}\newcommand\EndFmtInput{}\long\def\SkipToFmtEnd#1\EndFmtInput{}}\SkipToFmtEnd

\newcommand\ReadOnlyOnce[1]{\@ifundefined{#1}{\@namedef{#1}{}}\SkipToFmtEnd}
\usepackage{amstext}
\usepackage{amssymb}
\usepackage{stmaryrd}
\DeclareFontFamily{OT1}{cmtex}{}
\DeclareFontShape{OT1}{cmtex}{m}{n}
  {<5><6><7><8>cmtex8
   <9>cmtex9
   <10><10.95><12><14.4><17.28><20.74><24.88>cmtex10}{}
\DeclareFontShape{OT1}{cmtex}{m}{it}
  {<-> ssub * cmtt/m/it}{}
\newcommand{\texfamily}{\fontfamily{cmtex}\selectfont}
\DeclareFontShape{OT1}{cmtt}{bx}{n}
  {<5><6><7><8>cmtt8
   <9>cmbtt9
   <10><10.95><12><14.4><17.28><20.74><24.88>cmbtt10}{}
\DeclareFontShape{OT1}{cmtex}{bx}{n}
  {<-> ssub * cmtt/bx/n}{}
\newcommand{\tex}[1]{\text{\texfamily#1}}	

\newcommand{\Sp}{\hskip.33334em\relax}


\newcommand{\Conid}[1]{\mathit{#1}}
\newcommand{\Varid}[1]{\mathit{#1}}
\newcommand{\anonymous}{\kern0.06em \vbox{\hrule\@width.5em}}
\newcommand{\plus}{\mathbin{+\!\!\!+}}
\newcommand{\bind}{\mathbin{>\!\!\!>\mkern-6.7mu=}}
\newcommand{\rbind}{\mathbin{=\mkern-6.7mu<\!\!\!<}}\newcommand{\sequ}{\mathbin{>\!\!\!>}}
\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}
\usepackage{polytable}

\@ifundefined{mathindent}{\newdimen\mathindent\mathindent\leftmargini}{}

\def\resethooks{\global\let\SaveRestoreHook\empty
  \global\let\ColumnHook\empty}
\newcommand*{\savecolumns}[1][default]{\g@addto@macro\SaveRestoreHook{\savecolumns[#1]}}
\newcommand*{\restorecolumns}[1][default]{\g@addto@macro\SaveRestoreHook{\restorecolumns[#1]}}
\newcommand*{\aligncolumn}[2]{\g@addto@macro\ColumnHook{\column{#1}{#2}}}

\resethooks

\newcommand{\onelinecommentchars}{\quad-{}- }
\newcommand{\commentbeginchars}{\enskip\{-}
\newcommand{\commentendchars}{-\}\enskip}

\newcommand{\visiblecomments}{\let\onelinecomment=\onelinecommentchars
  \let\commentbegin=\commentbeginchars
  \let\commentend=\commentendchars}

\newcommand{\invisiblecomments}{\let\onelinecomment=\empty
  \let\commentbegin=\empty
  \let\commentend=\empty}

\visiblecomments

\newlength{\blanklineskip}
\setlength{\blanklineskip}{0.66084ex}

\newcommand{\hsindent}[1]{\quad}\let\hspre\empty
\let\hspost\empty
\newcommand{\NB}{\textbf{NB}}
\newcommand{\Todo}[1]{\textbf{To do:}~#1}

\EndFmtInput
\makeatother
\ReadOnlyOnce{polycode.fmt}\makeatletter

\newcommand{\hsnewpar}[1]{{\parskip=0pt\parindent=0pt\par\vskip #1\noindent}}

\newcommand{\hscodestyle}{}



\newcommand{\sethscode}[1]{\expandafter\let\expandafter\hscode\csname #1\endcsname
   \expandafter\let\expandafter\endhscode\csname end#1\endcsname}



\newenvironment{compathscode}{\par\noindent
   \advance\leftskip\mathindent
   \hscodestyle
   \let\\=\@normalcr
   \let\hspre\pboxed}{\endpboxed\let\hspost\pboxed}{\endpboxed\parray}{\endparray\parray}{\endparray\pboxed}{\endpboxed\def\column##1##2{}\let\>\undefined\let\<\undefined\let\\\undefined
   \newcommand\>[1][]{}\newcommand\<[1][]{}\newcommand\ }

\newcommand{\inlinehs}{\sethscode{inlinehscode}}



\newenvironment{joincode}{\let\orighscode=\hscode
   \let\origendhscode=\endhscode
   \def\endhscode{\def\hscode{\endgroup\def\@currenvir{hscode}\\}\begingroup}
\orighscode\def\hscode{\endgroup\def\@currenvir{hscode}}}{\origendhscode
   \global\let\hscode=\orighscode
   \global\let\endhscode=\origendhscode}

\makeatother
\EndFmtInput






               



\usepackage{amsmath, amssymb, booktabs, enumerate, graphicx, hyperref, mathpartir, tikz, url}

\newcommand{\skippres}[1]{}
\skippres{


\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thmx]{Lemma}
\newtheorem{prop}[thmx]{Proposition}
\newtheorem{rem}[thmx]{Remark}
\newtheorem{thmDefinition}[thmx]{Definition}
\newtheorem{thmExample}[thmx]{Example}



}

\newcommand{\defqed}{\hfill\vspace{1ex}}
\newcommand{\exqed}{\hfill\vspace{1ex}}

\newcommand{\coq}{Coq}
\newcommand{\xml}{XML}
\newcommand{\json}{JSON}
\newcommand{\ML}{\textsf{ML}}
\newcommand{\TRX}{TRX}

\newcommand{\LLk}{\textit{LL(k)}}
\newcommand{\LRk}{\textit{LR(k)}}
\newcommand{\LALRk}{\textit{LALR(k)}}
\newcommand{\LALRone}{\textit{LALR(1)}}

\newcommand{\comment}[1]{}
\newcommand{\todo}[1]{{\par\framebox{\parbox{0.4\textwidth}{TODO: #1}}\par}}

\newcommand{\GG}{\mathcal{G}}
\newcommand{\QQ}{\mathcal{Q}}
\newcommand{\QQfin}{{\QQ}_{\operatorname{fin}}}
\newcommand{\LL}{\mathcal{L}}
\newcommand{\PP}{\mathcal{P}}
\newcommand{\TT}{\mathcal{T}}
\newcommand{\RR}{\mathcal{R}}
\newcommand{\String}{\mathcal{S}}
\newcommand{\VV}{\mathcal{V}}
\newcommand{\nat}{\mathbb{N}}

\newcommand{\NT}{\VV_N}
\newcommand{\T}{\VV_T}
\newcommand{\RES}{\RR}

\newcommand{\ES}{\mathid{E}}
\newcommand{\PD}{\mathid{P_{exp}}}
\newcommand{\PS}{v_{\mathid{start}}}
\newcommand{\PT}{\mathid{P_{type}}}

\newcommand{\propSet}{\mathbb{P}}
\newcommand{\propEsym}{0}
\newcommand{\propNEsym}{{>0}}
\newcommand{\propNFsym}{\ge0}
\newcommand{\propFsym}{\bot}
\newcommand{\propSE}{\propSet_{\propEsym}}
\newcommand{\propSNE}{\propSet_{\propNEsym}}
\newcommand{\propSF}{\propSet_{\propFsym}}
\newcommand{\pegProp}[2]{#1 \in \propSet_{#2}}
\newcommand{\pegNProp}[2]{#1 \notin \propSet_{#2}}

\newcommand{\notPropE}[1]{\pegNProp{#1}{\propEsym}}
\newcommand{\propE}[1]{\pegProp{#1}{\propEsym}}
\newcommand{\propNE}[1]{\pegProp{#1}{\propNEsym}}
\newcommand{\propNF}[1]{\pegProp{#1}{\propNFsym}}
\newcommand{\propF}[1]{\pegProp{#1}{\propFsym}}

\newcommand{\WFset}{\mathid{WF}}
\newcommand{\WF}[1]{#1 \in \WFset}

\newcommand{\choiceOP}{/}
\newcommand{\choiceOPs}{\xx\choiceOP\xx}
\newcommand{\seqOP}{;}
\newcommand{\seqOPs}{\, \seqOP \,}
\newcommand{\plusOP}{+}

\newcommand{\emptye}{\epsilon}
\newcommand{\anychar}{[\cdot]}
\newcommand{\term}[1]{[#1]}
\newcommand{\lit}[1]{[\text{``''}]}
\newcommand{\xx}{\ \ }

\newcommand{\pseq}[2]{#1 \seqOP #2}
\newcommand{\pchoice}[2]{#1 \choiceOP #2}
\newcommand{\prep}[1]{#1*}
\newcommand{\pnot}[1]{!#1}
\newcommand{\pcoerce}[2]{#1 [\mapsto] #2}
\newcommand{\pcoerces}[2]{\pcoerce{#1 \xx}{\xx #2}}
\newcommand{\pcoercef}[2]{\pcoerces{#1}{{\, \lambda x\,.\,#2}}}
\newcommand{\dropResult}{[\sharp]}
\newcommand{\prange}[2]{[#1\!\!-\!\!#2]}
\newcommand{\pplus}[1]{{#1 \plusOP}}
\newcommand{\pand}[1]{\& #1}
\newcommand{\popt}[1]{{#1 ?}}

\newcommand{\midx}{\;\mid\;}
\newcommand{\mathid}[1]{\operatorname{#1}}
\newcommand{\imp}{\Rightarrow}
\newcommand{\set}[1]{\{#1\}}

\newcommand{\emptyList}{[]}
\newcommand{\cons}[2]{#1::#2}
\newcommand{\xs}{xs}
\newcommand{\xxs}{\cons{x}{\xs}}
\newcommand{\vs}{vs}
\newcommand{\vvs}{\cons{v}{\vs}}

\newcommand{\pegsemX}[5]{(#1, #2) \stackrel{\scriptscriptstyle #3}{#5} #4}
\newcommand{\pegsemx}[4]{\pegsemX{#1}{#2}{#3}{#4}{\leadsto}}
\newcommand{\notpegsemx}[3]{\pegsemX{#1}{#2}{}{#3}{\not\leadsto}}
\newcommand{\pegsem}[3]{\pegsemx{#1}{#2}{}{#3}}
\newcommand{\typei}[2]{#1\, :\, #2}

\newcommand{\pex}{\Delta}
\newcommand{\Pex}[1]{\Delta_{#1}}

\newcommand{\fail}{\bot}
\newcommand{\ok}[1]{\surd_{\!#1}}
\newcommand{\Ok}[2]{\surd^{\,#1}_{\,#2}}

\newcommand{\type}[1]{\mathrm{#1}}
\newcommand{\Type}{\type{Type}}
\newcommand{\TrueT}{\type{True}}
\newcommand{\Char}{\type{char}}
\newcommand{\StringT}{\type{string}}
\newcommand{\List}[1]{\type{list}\,#1}
\newcommand{\Option}[1]{\type{option}\,#1}
\newcommand{\NoneT}{\type{None}}
\newcommand{\SomeT}[1]{\type{Some}\;#1}

\newcommand{\ie}{\textit{i.e.}}
\newcommand{\resp}{\textit{resp.}}
\newcommand{\etc}{\textit{etc}}
\newcommand{\FIXME}{\framebox{\textbf{... MISSING ...}}}

\newcommand{\strlen}[1]{|#1|}
\newcommand{\subexp}{\sqsubseteq}

\newcommand{\NTid}[1]{\mathtt{#1}}
\newcommand{\NTnumber}{\NTid{number}}
\newcommand{\NTdigit}{\NTid{digit}}
\newcommand{\NTws}{\NTid{ws}}
\newcommand{\NTterm}{\NTid{term}}
\newcommand{\NTfactor}{\NTid{factor}}
\newcommand{\NTinput}{\NTid{input}}
\newcommand{\NTexpr}{\NTid{expr}}

\newcommand{\NTif}{\NTid{IF}}
\newcommand{\NTreserved}{\NTid{reserved}}
\newcommand{\NTident}{\NTid{identifier}}
\newcommand{\NTletter}{\NTid{letter}}
\newcommand{\NTstmt}{\NTid{stmt}}

\newcommand{\NCif}{\NTid{IF}}
\newcommand{\NCelse}{\NTid{ELSE}}
\newcommand{\NClp}{\NTid{(}}
\newcommand{\NCrp}{\NTid{)}}

\newcommand{\digListToNat}{\mathid{digListToNat}}
\newcommand{\coqid}[1]{\textit{#1}}
 
\theoremstyle{definition}


\def\doi{7 (2:18) 2011}
\lmcsheading {\doi}
{1--26}
{}
{}
{Jun.~14, 2010}
{Jun.~23, 2011}
{}   

\begin{document}

\title{TRX: A Formally Verified Parser Interpreter\rsuper*}

\author[A.~Koprowski]{Adam Koprowski}
\address{MLstate, Paris, France}
\email{Adam.Koprowski@mlstate.com, Henri.Binsztok@mlstate.com}

\author[H.~Binsztok]{Henri Binsztok}
\address{\vskip-6 pt}


\keywords{parser generation, formal verification, coq proof assistant, parsing expression grammars, recursive descent parsing}
\subjclass{D.3.4, D.2.4, F.3.1, F.4.2}


\titlecomment{{\lsuper*}An extended abstract of this paper appeared in the Proceedings of the 19th
European Symposium on Programming \cite{KopBin10esop}.}

\begin{abstract}
Parsing is an important problem in computer science and yet
surprisingly little attention has been devoted to its formal verification.
In this paper, we present TRX: a parser interpreter formally developed
in the proof assistant \coq, capable of producing formally correct parsers. 
We are using parsing expression grammars (PEGs), a formalism essentially 
representing recursive descent parsing, which we consider an attractive 
alternative to context-free grammars (CFGs). From this formalization we 
can extract a parser for an arbitrary PEG grammar with the warranty of 
total correctness, i.e., the resulting parser is terminating and correct 
with respect to its grammar and the semantics of PEGs; both properties 
formally proven in \coq.
\end{abstract}

\maketitle

\section{Introduction}\label{sec:intro}

Parsing is of major interest in computer science.
Classically discovered by students as the first step in compilation, parsing is present in almost every program which performs data-manipulation. 

For instance, the Web is built on parsers. The HyperText Transfer Protocol (HTTP) is a parsed dialog between the client, or browser, and the server. This protocol transfers pages in HyperText Markup Language (HTML), which is also parsed by the browser.  When running web-applications, browsers interpret JavaScript programs which, again, begins with parsing.  Data exchange between browser(s) and server(s) uses languages or formats like \xml\ and \json. Even inside the server, several components (for instance the trio made of the HTTP server Apache, the PHP interpreter and the MySQL database) often manipulate programs and data dynamically; all require parsers.

Parsing is not limited to compilation or the Web: securing data flow entering a
network, signaling mobile communications, and manipulating domain specific languages
(DSL) all require a variety of parsers.

The most common approach to parsing is by means of \textit{parser generators}, which
take as input a grammar of some language and generate the source code of a parser for 
that language. They are usually based on regular expressions (REs) 
and context-free grammars (CFGs), the latter expressed in Backus-Naur Form (BNF) syntax.
They typically are able to deal with some subclass of context-free languages, the
popular subclasses including \LLk, \LRk\ and \LALRk\ grammars. Such grammars are usually
augmented with semantic actions that are used to produce a parse tree or an abstract
syntax tree (AST) of the input.

What about \emph{correctness} of such parsers? 
Yacc is the most widely used parser generator and a mature program and yet the reference book about this tool~\cite{lexyacc} devotes a whole section (``Bugs in Yacc'') to discuss common bugs in its distributions.
Furthermore, the code generated by such tools often contains huge parsing tables making it near impossible for manual inspection and/or verification. In the recent article about CompCert~\cite{Ler09}, an impressive project formally verifying a compiler for a large subset of C, the introduction starts with a question ``Can you trust your compiler?''.  Nevertheless, the formal verification starts on the level of the AST and does not concern the parser~\cite[Figure 1]{Ler09}.
Can you trust your parser?

\emph{Parsing expression grammars} (PEGs) \cite{For04} are an alternative to CFGs,
that have recently been gaining popularity. In contrast to CFGs they are unambiguous and allow 
easy integration of lexical analysis into the parsing phase. Their implementation is easy, 
as PEGs are essentially a declarative way of specifying recursive descent parsers \cite{Bur75}. 
With their backtracking and unlimited look-ahead capabilities they are expressive enough to 
cover all \LLk\ and \LRk\ languages as well as some non-context-free ones. However, recursive 
descent parsing of grammars that are not \LLk\ may require exponential time. A solution to 
that problem is to use memoization giving rise to \emph{packrat parsing} and ensuring linear 
time complexity at the price of higher memory consumption~\cite{AhoUll72,For02,For02mth}.
It is not easy to support (indirect) left-recursive rules in PEGs, as they lead to 
non-terminating parsers \cite{WarEA08}.

In this paper we present \TRX: a PEG-based parser interpreter \emph{formally developed} in the
proof assistant \coq\ \cite{Coq,BerCas04}. As a result, expressing a grammar in \coq\
allows one, via its extraction capabilities \cite{Let08}, to obtain a parser for this grammar
with \emph{total correctness guarantees}. That means that the resulting parser is terminating 
and correct with respect to its grammar and the semantics of PEGs; both of those 
properties formally proved in \coq. Moreover every definition and theorem presented in 
this paper has been expressed and verified in \coq.

Our emphasis is on the \emph{practicality} of such a tool. We perform two case studies: on a simple
XML format but also on the full grammar of the Java language. We present benchmarks indicating
that the performance of obtained parsers is reasonable. We also sketch ideas on how it can be
improved further, as well as how TRX could be extended into a tool of its own, freeing its 
users from any kind of interaction with Coq and broadening its applicability.

This work was carried out in the context of improving safety and security of OPA (One Pot Application):
an integrated platform for web development \cite{OPA}. As mentioned above parsing is of
uttermost importance for web-applications and \TRX\ is one of the components in the 
OPA platform.

The remainder of this paper is organized as follows. We introduce PEGs in Section~\ref{sec:pegs} 
and in Section~\ref{sec:pegs-actions} we extend them with semantic actions.
Section~\ref{sec:pegs-wf} describes a method for checking that there is no (indirect)
left recursion in a grammar, a result ensuring that parsing will terminate.
Section~\ref{sec:pegs-int} reports on our experience with putting the ideas of the preceding
sections into practice and implementing a formally correct parser interpreter in \coq.
Section~\ref{sec:pegs-ex} is devoted to a practical evaluation of this interpreter and contains 
case studies of extracting \xml\ and Java parsers from it, presenting a benchmark of
\TRX\ against other parser generators and giving an account of our experience with 
extraction. We discuss related work in Section~\ref{sec:relwork}, present ideas for
extensions and future work in Section~\ref{sec:discussion} and conclude in Section~\ref{sec:concl}.

 \section{Parsing Expression Grammars (PEGs)}\label{sec:pegs}

The content of this section is a different presentation of the 
results by Ford~\cite{For04}. For more details we refer to the original article.
For a general overview of parsing we refer to, for instance, Aho, Seti \& Ullman~\cite{AhoEA86}.

PEGs are a formalism for parsing that is an interesting alternative to 
CFGs. We will formally introduce them along with their semantics in
Section~\ref{sec:peg_def}. PEGs are gaining popularity recently due to 
their ease of implementation and some general desirable properties that 
we will sketch in Section~\ref{sec:peg_vs_cfg}, while comparing them to CFGs.

\subsection{Definition of PEGs}\label{sec:peg_def}

\begin{defi}[Parsing expressions]\label{pexp}
We introduce a set of \emph{parsing expressions}, , over a finite
set of terminals  and a finite set of non-terminals . 
We denote the set of strings as  and a string  
is a list of terminals .
The inductive definition of  is given in Figure~\ref{peg-exp-fig}.
\defqed
\end{defi}

\begin{figure}[t!]
\begin{center}

\end{center}
\caption{Parsing expressions}
\label{peg-exp-fig}
\end{figure}

Later on we will present the formal semantics but 
for now we informally describe the language expressed by such parsing expressions.

\begin{iteMize}{}
  \item \emph{Empty expression}  always succeeds without consuming 
    any input.
  \item \emph{Any-character} , a \emph{terminal}  and
    a \emph{range}  all consume a single terminal from the input but they expect
    it to be, respectively: an arbitrary terminal, precisely  and in the range
    between  and .
  \item \emph{Literal}  reads a string (\ie, a sequence of terminals)  from
    the input.
  \item Parsing a \emph{non-terminal}  amounts to parsing the expression 
    defining .
  \item A \emph{sequence}  expects an input conforming to 
     followed by an input conforming to .
  \item A \emph{choice}  expresses a \emph{prioritized} 
    choice between  and . This means that  will be tried only if
     fails.
  \item A \emph{zero-or-more (\resp\ one-or-more) repetition} 
     (\resp\ ) consumes zero-or-more (\resp\ one-or-more) 
    repetitions of  from the input. Those operators are \emph{greedy}, \ie,
    the longest match in the input, conforming to , will be consumed.
  \item An \emph{and-predicate (\resp\ not-predicate)}  (\resp\ ) 
    succeeds only if the input conforms to  (\resp\ does not conform to ) but does 
    not consume any input.
\end{iteMize}\medskip

\noindent We now define PEGs, which are essentially a finite set of
non-terminals, also referred to as \emph{productions}, with their
corresponding parsing expressions.

\begin{defi}[Parsing Expressions Grammar (PEG)]\label{peg}
  A parsing expressions grammar (PEG), , is a tuple
, where:
\begin{iteMize}{}
  \item  is a finite set of terminals,
  \item  is a finite set of non-terminals,
  \item  is the interpretation of the productions, \ie,  and
  \item  is the start production, .  \defqed
\end{iteMize}
\end{defi}

We will now present the formal semantics of PEGs. 
The semantics is given by means of tuples , which indicate 
that parsing expression  applied on a string  gives,
in  steps, the result , where  is either , denoting that parsing failed, 
or , indicating that parsing succeeded and  is what remains to be 
parsed. We will drop the  annotation whenever irrelevant.

\begin{figure}[t!]
\begin{center}
15pt]
\inferrule{ }{\pegsemx{\anychar}{\emptyList}{1}{\fail}} &
\inferrule{ }{\pegsemx{\term{x}}{\xxs}{1}{\ok{\xs}}} &
\inferrule{ }{\pegsemx{\term{x}}{\emptyList}{1}{\fail}} \15pt]
\inferrule{\pegsemx{e_1}{s}{m}{\fail}}{\pegsemx{\pseq{e_1}{e_2}}{s}{m+1}{\fail}} &
\inferrule{\pegsemx{e_1}{s}{m}{\ok{s'}} \\ \pegsemx{e_2}{s'}{n}{r}}{\pegsemx{\pseq{e_1}{e_2}}{s}{m+n+1}{r}} &
\inferrule{\pegsemx{e_1}{s}{m}{\fail} \\ \pegsemx{e_2}{s}{n}{r}}{\pegsemx{\pchoice{e_1}{e_2}}{s}{m+n+1}{r}} \
\end{center}
\caption{Formal semantics of PEGs}
\label{peg-sem-fig}
\end{figure}

The complete semantics is presented in Figure~\ref{peg-sem-fig}. Please note
that the following operators from Definition~\ref{pexp} can be derived and
therefore are not included in the semantics:




\subsection{CFGs vs PEGs}\label{sec:peg_vs_cfg}

The main differences between PEGs and CFGs are the following:
\begin{iteMize}{}
  \item the choice operator, , is \emph{prioritized}, \ie, 
     is tried only if  fails;
  \item the repetition operators,  and , are \emph{greedy},
    which allows to easily express ``longest-match'' parsing, which is almost
    always desired;
  \item \emph{syntactic predicates} \cite{ParQuo94},  and , both of which consume
    no input and succeed if , respectively, succeeds or fails. This effectively
    provides an \emph{unlimited look-ahead} and, in combination with choice, 
    limited \emph{backtracking} capabilities.
\end{iteMize}\medskip

\noindent An important consequence of the choice and repetition operators being deterministic 
(choice being prioritized and repetition greedy) is the fact that PEGs are 
\emph{unambiguous}. We will see a formal proof of that in Theorem~\ref{thm:peg_unambig}.
This makes them unfit for processing natural languages, 
but is a much desired property when it comes to grammars for programming 
languages. 

Another important consequence is ease of implementation. Efficient algorithms are
known only for certain subclasses of CFGs and they tend to be rather complicated. 
PEGs are essentially a declarative way of specifying \emph{recursive descent parsers}~\cite{Bur75}
and performing this type of parsing for PEGs is straightforward (more
on that in Section~\ref{sec:pegs-int}). By using the technique of
\emph{packrat parsing} \cite{AhoUll72,For02}, \ie, essentially adding memoization to the
recursive descent parser, one obtains parsers with linear time complexity guarantees. 
The downside of this approach is high memory requirements: the worst-time space complexity 
of PEG parsing is linear in the size of the input, but with packrat parsing the
constant of this correlation can be very high. For instance Ford reports on a factor 
of around 700 for a parser of Java \cite{For02}.

CFGs work hand-in-hand with REs. The \emph{lexical analysis}, breaking up the input 
into tokens, is performed with REs. Such tokens are subject to \emph{syntactical analysis},
which is executed with CFGs. This split into two phases is not necessary with PEGs, 
as they make it possible to easily express both lexical and syntactical rules with
a single formalism. We will see that in the following example.



\begin{exa}[PEG for simple mathematical expressions]\label{math_peg}
 Consider a PEG for simple mathematical expressions over 5 non-terminals:
   
with the following productions ( function from Definition~\ref{peg}):

Please note that in this and all the following examples we write the
sequence operator  implicitly as . The starting 
production is .

First, let us note that lexical analysis is incorporated into this grammar by means
of the  production which consumes all white-space from the beginning of the input.
Allowing white-space between ``tokens'' of the grammar comes down to placing 
the call to this production around the terminals of the grammar. If one does not 
like to clutter the grammar with those additional calls then a simple solution is
to re-factor all terminals into separate productions, which consume not only the terminal
itself but also all white-space around it.

Another important observation is that we made addition (and also multiplication) right-associative.
If we were to make it, as usual, left-associative, by replacing the rule 
for  with:



\noindent then we get a grammar that is left-recursive. Left-recursion (also indirect or mutual)
is problematic as it leads to non-terminating parsers. We will come back to this issue
in Section~\ref{sec:pegs-wf}. 
\exqed
\end{exa}

PEGs can also easily deal with some common idioms often encountered in practical 
grammars of programming languages, which pose a lot of difficulty for CFGs, such
as modular way of handling reserved words of a language and a ``dangling'' else problem 
--- we present them on two examples and refer for more details to Ford~\cite[Chapter 2.4]{For02mth}.

\begin{exa}[Reserved words]
One of the difficulties in tokenization is that virtually every programming 
language has a list of \emph{reserved words}, which should not be accepted 
as identifiers. PEGs allow an elegant pattern to deal with this problem:

The rule  for identifiers reads a non-empty list of letters 
but only after checking, with the not-predicate, that there is no 
reserved word at this position. The rules for the reserved words 
ensure that it is not followed by a letter (``''
is a valid identifier) and consume all the following white space.
In this example we only presented a single reserved word ``''
but adding a new word requires only adding a rule similar to  
and extending the choice in .
\exqed
\end{exa}

\begin{exa}[``Dangling'' else]
Consider the following part of a CFG for the C language:

According to this grammar there are two possible readings of a statement

as the ``'' branch can be associated either with the 
outer or the inner . The desired way to resolve this 
ambiguity is usually to bind this  to the innermost construct.
This is exactly the behavior that we get by converting this CFG to a PEG
by replacing the symmetrical choice operator ``'' of CFGs with the
prioritized choice of PEGs ``''.
\exqed
\end{exa}
 \section{Extending PEGs with Semantic Actions}\label{sec:pegs-actions}

\subsection{XPEGs: Extended PEGs}

  In the previous section we introduced parsing expressions, which can be
used to specify which strings belong to the grammar under consideration.
However the role of a parser is not merely to recognize whether an input is
correct or not but also, given a correct input, to compute its representation
in some structured form. This is typically done by extending grammar expressions
with \emph{semantic values}, which are a representation of the result of parsing 
this expression on (some) input and by extending a grammar with \emph{semantic
actions}, which are functions used to produce and manipulate the semantic 
values. Typically a semantic value associated with an expression will be
its parse tree so that parsing a correct input will give a \emph{parse tree} of this
input. For programming languages such parse tree would represent the AST of 
the language.

In order to deal with this extension we will replace the simple type of parsing 
expressions  with a family of types , where the index 
is a type of the semantic value associated with the expression.
We also compositionally define default semantic values for all types of 
expressions and introduce a new construct: coercion, , which 
converts a semantic value  associated with  to . 

Borrowing notations from \coq\ we will use the following types:
\begin{iteMize}{}
  \item  is the universe of types.
  \item  is the singleton type with a single value .
  \item  is the type of machine characters. It corresponds to the type of 
    terminals , which in concrete parsers will always be instantiated
    to .
  \item  is the type of lists of elements of  for any 
    type . Also .
\item  is the type of -tuples of elements  with 
     for any types .
    If  is an -tuple then  is its 'th projection.
  \item  is the type optionally holding a value of type ,
    with two constructors  and  with .
\end{iteMize}

\begin{defi}[Parsing expressions with semantic values]\label{PExp}
We introduce a set of \emph{parsing expressions with semantic values}, , 
as an inductive family indexed by the type  of semantic values of
an expression. The typing rules for  are given in 
Figure~\ref{peg-exp-prod-fig}. 
\defqed
\end{defi}

Note that for the choice operator  the types of semantic values 
of  and  must match, which will sometimes require use of the coercion 
operator .

Let us again see the derived operators and their types, as we need to insert
a few coercions:

where .

\begin{figure}[t!]
\begin{center}
15pt]
\inferrule{A \in \NT}{\typei{A}{\Pex{\PT(A)}}} &
\qquad \inferrule{\typei{e_1}{\Pex{\alpha}} \\ \typei{e_2}{\Pex{\beta}}}{\typei{\pseq{e_1}{e_2}}{\Pex{\alpha * \beta}}} &
\qquad \inferrule{\typei{e_1}{\Pex{\alpha}} \\ \typei{e_2}{\Pex{\alpha}}}{\typei{\pchoice{e_1}{e_2}}{\Pex{\alpha}}} \
\end{center}
\caption{Typing rules for parsing expressions with semantic actions}
\label{peg-exp-prod-fig}
\end{figure}

  The definition of an extended parsing expression grammar (XPEG) is 
as expected (compare with Definition~\ref{pexp}).

\begin{defi}[Extended Parsing Expressions Grammar (XPEG)]\label{pegs-prod-peg}
  An extended parsing expressions grammar (XPEG), , is a tuple
 , where:
\begin{iteMize}{}
  \item  is a finite set of terminals,
  \item  is a finite set of non-terminals,
  \item  is a function that gives types of semantic 
    values of all productions.
  \item  is the interpretation of the productions of the grammar, \ie,
     and
  \item  is the start production, . \defqed
\end{iteMize}
\end{defi}

  We extended the semantics of PEGs from Figure~\ref{peg-sem-fig} to semantics
of XPEGs in Figure~\ref{peg-sem-prod-fig}.
 
\newcommand{\rsucc}[1]{#1_{\surd}}
\newcommand{\rfail}[1]{#1_{\bot}}
\newcommand{\repS}{\rsucc{rep}}
\newcommand{\repF}{\rfail{rep}}

\begin{figure}[t!]
\begin{center}
15pt]
\inferrule{ }{\pegsemx{\anychar}{\emptyList}{1}{\fail}} &
\inferrule{\pegsemx{e_1}{s}{m}{\fail} \\ \pegsemx{e_2}{s}{n}{r}}{\pegsemx{\pchoice{e_1}{e_2}}{s}{m+n+1}{r}} &
\inferrule{\pegsemx{e_1}{s}{m}{\Ok{v}{s'}}}{\pegsemx{\pchoice{e_1}{e_2}}{s}{m+1}{\Ok{v}{s'}}} \15pt]
\inferrule{\pegsemx{e_1}{s}{m}{\Ok{v_1}{s'}} \\ \pegsemx{e_2}{s'}{n}{\fail}}{\pegsemx{\pseq{e_1}{e_2}}{s}{m+n+1}{\fail}} &
\inferrule{\pegsemx{e_1}{s}{m}{\Ok{v_1}{s'}} \\ \pegsemx{e_2}{s'}{n}{\Ok{v_2}{s''}}}{\pegsemx{\pseq{e_1}{e_2}}{s}{m+n+1}{\Ok{(v_1,v_2)}{s''}}} &
\inferrule{\pegsemx{e_1}{s}{m}{\fail}}{\pegsemx{\pseq{e_1}{e_2}}{s}{m+1}{\fail}} \15pt]
\inferrule{\pegsemx{e}{s}{m}{\Ok{v}{s'}}}{\pegsemx{\pnot{e}}{s}{m+1}{\fail}} &
\inferrule{\pegsemx{e}{s}{m}{\Ok{v}{s'}}}{\pegsemx{\pcoerce{e}{f}}{s}{m+1}{\Ok{f(v)}{s'}}} &
\inferrule{\pegsemx{e}{s}{m}{\fail}}{\pegsemx{\pcoerce{e}{f}}{s}{m+1}{\fail}}
\end{array}

\begin{array}{r @{\ \ ::=\ \ } l l}
\NTws     & \prep{(
               \term{{\text{\textvisiblespace }}} 
            \choiceOPs
                \term{{\backslash t}}
            )} & \xx\dropResult \\
\NTnumber & \pplus{\prange{0}{9}}          & \pcoerces{}{\digListToNat} \\
\NTterm   & \NTws \xx \NTnumber \xx \NTws  & \pcoercef{}{x_2} \\
\multicolumn{1}{r}{\choiceOPs} & \NTws \xx \term{{(}} \xx \NTexpr \xx \term{{)}} \xx \NTws & \pcoercef{}{x_3} \\
\NTfactor & \NTterm \xx \term{{*}} \xx \NTfactor & \pcoercef{}{x_1 * x_3} \\
\multicolumn{1}{r}{\choiceOPs} & \NTterm \\
\NTexpr   & \NTfactor \xx \term{{+}} \xx \NTexpr & \pcoercef{}{x_1 + x_3} \\
\multicolumn{1}{r}{\choiceOPs} & \NTfactor \\
\end{array}

 \NTexpr \ ::= \ \NTexpr \xx \term{{+}} \xx \NTfactor \choiceOPs \NTfactor

 \NTid{A} \ ::= \ \NTid{B} \choiceOPs \NTid{C} \xx \pnot{\:\!\NTid{D}} \xx \NTid{A}

 \ES(\GG) = \set{e' \mid e' \subexp e, e \in \PD(A), A \in \NT}

\begin{array}{ccccccc}
\inferrule{ }{\propE{\emptye}}   &
\quad \inferrule{ }{\propNE{\anychar}} &
\quad \inferrule{ }{\propF{\anychar}}  &
\quad \inferrule{a \in \T}{\propNE{\term{a}}} &
\quad \inferrule{a \in \T}{\propF{\term{a}}}   &
\quad \inferrule{\propF{e}}{\propE{\prep{e}}}   &
\quad \inferrule{\propNE{e}}{\propNE{\prep{e}}}
\end{array}

\begin{array}{c@{\qquad}c}
\inferrule{\star \in \set{\propEsym, \propNEsym, \propFsym} \\ A \in \NT \\ \pegProp{\PD(A)}{\star}}{\pegProp{A}{\star}} &
\inferrule{\propF{e_1} \lor (\propNF{e_1} \land \propF{e_2})}{\propF{\pseq{e_1}{e_2}}} \15pt]
\inferrule{\propE{e_1} \lor (\propF{e_1} \land \propE{e_2})}{\propE{\pchoice{e_1}{e_2}}} &
\inferrule{\propF{e_1} \\ \propF{e_2}}{\propF{\pchoice{e_1}{e_2}}} \
\end{center}
\caption{Deriving grammar properties.}
\label{peg-prop-fig}
\end{figure}

We define three groups of properties over parsing expressions: 
\begin{iteMize}{}
  \item ``'': parsing expression can succeed without consuming any input,
  \item ``'': parsing expression can succeed after consuming some input and
  \item ``'': parsing expression can fail.
\end{iteMize}

We will write  to indicate that the expression  has property ``''
(similarly for  and ). We will also write  to denote
. We define inference rules for deriving those properties 
in Figure~\ref{peg-prop-fig}.

We start with empty sets of properties and apply those inference rules 
over  until reaching a fix-point. 
The existence of the fix-point is ensured by the fact that we extend those
property sets monotonically and they are bounded by the finite set . We 
summarize the semantics of those properties in the following lemma:

\begin{lem}[\cite{For04}]\label{th:pegProp}
For arbitrary  and :
\begin{iteMize}{}
 \item if  then ,
 \item if  and  then  and
 \item if  then .
\end{iteMize}
\end{lem}
\begin{proof}
Induction over . All cases easy by the induction hypothesis
and semantical rules of XPEGs, except for  which requires
use of Lemma~\ref{thm:peg_loop_cond}.
\end{proof}

Those properties will be used for establishing well-formedness of a PEG, as we will see
in the following section. It is worth noting here that checking whether
 also plays a crucial role in the formal approach to parsing developed by
Danielsson~\cite{Dan10} (we will say more about his work in Section~\ref{sec:relwork}).

It is also interesting to consider such a simplified analysis in our setting, \ie,
only considering  and collapsing derivations of Figure~\ref{peg-prop-fig}
by assuming  and  hold for every expression . At first
it seems we would lose some precision by such an over-approximation as for instance
that would lead us to conclude , whereas in fact this
expression can never succeed without consuming any input (as, quite simply, it
can \emph{never} succeed). As we will see soon this would lead us to reject
a valid definition:

However, this definition of  is not very interesting as it always fails.
In fact, we conjecture that the differences occur only in such degenerated cases
and that in practice such a simplified analysis would be as efficient as that
of~\cite{For04}.

\subsection{PEG well-formedness}\label{sec:pegs-wf-wf}

Using the semantics of those properties of parsing expression we can perform the 
completeness analysis of . We introduce a set of well-formed expressions
 and again iterate from an empty set by using derivation rules from
Figure~\ref{peg-wf-fig} over  until reaching a fix-point. 

\begin{figure}[t!]
\begin{center}
15pt]
\inferrule{\WF{e_1} \\ \propE{e_1} \imp \WF{e_2}}{\WF{\pseq{e_1}{e_2}}} &
\inferrule{\WF{e_1} \\ \WF{e_2}}{\WF{\pchoice{e_1}{e_2}}} &
\inferrule{\WF{e},\quad\notPropE{e}}{\WF{\prep{e}}}
\end{array}

  \exists_{n, r}\; \pegsemx{e}{s}{n}{r}

  \ensuremath{\Varid{wf\char95 measure}} ::= \strlen{\ES(\GG)} - \strlen{\ensuremath{\Varid{wf}}}

  \ensuremath{\Varid{wf}} \subseteq \ensuremath{\Varid{wf\char95 derive}\;\Varid{wf}} \\
  \ensuremath{\Varid{wf}} \subseteq \ES(\GG) \implies \ensuremath{\Varid{wf\char95 derive}\;\Varid{wf}} \subseteq \ES(\GG) 

  {(e_1, s_1) \succ (e_2, s_2)} \quad{\iff}\quad
  {
  \exists_{n_1, r_1, n_2, r_2}\ 
    {\pegsemx{e_1}{s_1}{n_1}{r_1}} \land 
    {\pegsemx{e_2}{s_2}{n_2}{r_2}} \land 
    {n_1 > n_2}
  }
\blanklineskip]\>[3]{}\ensuremath{\mathbf{Program}}\;\ensuremath{\mathbf{Definition}}\;\Varid{do\char95 parse}\;(\Varid{grammar}\mathbin{:}\Varid{string})\;(\Varid{input}\mathbin{:}\Varid{string})\mathbin{:=}{}\<[E]\\
\>[3]{}\hsindent{2}{}\<[5]\>[5]{}\ensuremath{\mathbf{match}}\;\Varid{parse}\;\Conid{PEG\char95 grammar}\;\Varid{grammar}\;\ensuremath{\mathbf{with}}{}\<[E]\\
\>[3]{}\hsindent{2}{}\<[5]\>[5]{}\mid \Conid{PR\char95 ok}\;\anonymous \;\Varid{peg}\Rightarrow \Varid{parse}\;(\Varid{promote}\;\Varid{peg})\;\Varid{input}{}\<[E]\\
\>[3]{}\hsindent{2}{}\<[5]\>[5]{}\mid \Conid{PR\char95 fail}\Rightarrow \Conid{PR\char95 fail}{}\<[E]\\
\>[3]{}\hsindent{2}{}\<[5]\>[5]{}\ensuremath{\mathbf{end}}.{}\<[E]\ColumnHook
\end{hscode}\resethooks
Here \ensuremath{\Conid{PEG\char95 grammar}} is the grammar for PEGs. The main \ensuremath{\Varid{do\char95 parse}} function takes
two arguments: \ensuremath{\Varid{grammar}} with the textual description of the grammar to use and
\ensuremath{\Varid{input}} being the \ensuremath{\Varid{input}} which we want to parse using the given \ensuremath{\Varid{grammar}}. We use
\ensuremath{\Conid{PEG\char95 grammar}} to parse \ensuremath{\Varid{grammar}} and, hopefully, obtain its internal representation
\ensuremath{\Varid{peg}\mathbin{:}\Varid{pexp}}, in which case we again invoke \ensuremath{\Varid{parse}} with \ensuremath{\Varid{promote}\;\Varid{peg}} grammar and
\ensuremath{\Varid{input}} as the input string. Extracting \ensuremath{\Varid{do\char95 parser}} would give us a generic
recognizer, that could be used without Coq (or any knowledge thereof).

Admittedly, in practice we are rarely interested in merely validating the input;
usually we really want to \textit{parse} it, obtaining its structural representation.
How can the above approach be extended to accommodate that and still result in a
stand-alone tool, not requiring interaction with Coq?

One option would be to move from interpretation to code generation and then using 
the target language to express semantic actions. An additional advantage is that this
should result in a big performance gain (compare the performance of TRX and TRX-int in 
Figure~\ref{fig:trx-perf}). But that would be a major undertaking requiring 
reasoning with respect to the target language's semantics for the correctness proofs
and some sort of (formally verified) termination analysis for that language, to 
ensure termination of the code of semantic actions (and hence the generated parser). 

The aforementioned termination problem for a parser generator could be simplified 
by restricting the code allowed in semantic actions to some subset of the target 
language, which is still expressive enough for this purpose but for which the termination 
analysis is simpler. For instance for a purely functional target language one could
disallow recursion altogether in productions (making termination evident), only allowing 
use of some predefined set of combinators (to improve expressivity of semantic actions), 
which could be proven terminating manually.

Another solution would be not to use semantic actions altogether, but construct a
parse tree, the shape of which could be influenced by annotations in the grammar.
This is the approach used, for instance, in the Ocaml PEG-based parser generator
Aurochs~\cite{aurochs}. We believe this is a promising approach that we hope
to explore in the future work.

\bigskip
A complete different approach to developing a practical, certified parser generator
would be the standard technique of verification \emph{a posteriori}: use an untrusted
parser that, apart from its result, generates some sort of a certificate (parse tree)
and develop a (formally correct) tool to verify, using the certificate, that the output
of the tool (for a given input and given grammar) is correct. The attractiveness of this
approach lies in the fact that such a verifier would typically be much
simpler than the parser itself. There are two problems with this approach though:
\begin{iteMize}{}
 \item this approach could at best give us partial correctness guarantees, as we
   would not be able to ensure termination of the un-trusted parser (unless we
   also prove it in some way);
 \item if the parsing is successul it is relatively clear what a certificate should be
   (parse tree), but what if it is not? How can we certify incorrectness of input
   with respect to the grammar?
\end{iteMize}

\bigskip
Apart from making the certified TRX a Coq independent, standalone tool and moving
from interpretation to code generation we also identify a number of other possible 
improvements to TRX as future work:

\begin{enumerate}[(1)]
 \item\label{future:performance} 
   Linear parsing time with PEGs can be ensured by using packrat parsing~\cite{For02},
   \ie, enhancing the parser with memoization. This should be relatively easy to 
   implement (it has, respectively, no and little impact on the termination and 
   correctness arguments for certified TRX), but induces high memory costs
   (and some performance overhead), so it is not clear whether this would be 
   beneficial. An alternative would be to develop (formally verified?) tools
   to perform grammar analysis and warn the user in case the grammar can lead to
   exponential parsing times.

 \item Another important aspect is that of left-recursive grammars, which
   occur naturally in practice. At the moment it is the responsibility of
   the user to eliminate left-recursion from a grammar. In the future, we
   plan to address this problem either by means of left-recursion elimination
   \cite{For02mth}, \ie, transforming a left-recursive grammar to an equivalent 
   one where left-recursion does not occur (this is not an easy problem in 
   presence of semantic actions, especially if one also wants to allow mutually 
   left-recursive rules). Another possible approach is an extension to the 
   memoization technique that allows dealing with left-recursive rules~\cite{WarEA08}.

 \item\label{future:errmsg}
   Finally support for \emph{error messages}, for instance following that of
   the PEG-based parser generator Puppy~\cite{For02mth}, would greatly
   improve usability of TRX.
\end{enumerate}
\section{Conclusions}\label{sec:concl}

In this paper we described a \coq\ formalization of the theory of PEGs and,
based on it, a formal development of \emph{\TRX: a formally verified parser 
interpreter for PEGs}. This allows us to write a PEG, together with its 
semantic actions, in \coq\ and then to extract from it a \emph{parser with 
total correctness guarantees}. That means that the parser will terminate 
on all inputs and produce parsing results correct with respect to the 
semantics of PEGs. 
Considering the importance of parsing, this result appears as a first step 
towards a general way to bring added quality and security to all kinds of software .

The emphasis of our work was on \emph{practicality}, so apart from treating
this as an interesting academic exercise, we were aiming at obtaining a 
tool that scales and can be applied to real-life problems. We performed
a case study with a (complete) Java grammar and demonstrated that the resulting 
parser exhibits a reasonable performance. We also stressed the importance
of making those results available to people outside of the small circle 
of theorem-proving experts and presented a plan of doing so as future
work.



\subsection*{Acknowledgments}
We would like to thank Matthieu Sozeau for his invaluable help with the
Program feature~\cite{Soz07} of \coq\ and the anonymous referees for their
helpful comments, which greatly improved presentation of this paper.
Also the very pragmatic (and immensely helpful) book of Chlipala~\cite{Chl09},
as well as friendly advice from people on Coq's mailing list turned out to
be invaluable in the course of this work.
 


\bibliographystyle{alpha}
\bibliography{paper}



\end{document}
