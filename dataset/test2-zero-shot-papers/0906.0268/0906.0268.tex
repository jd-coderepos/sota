\documentclass[times, 10pt,twocolumn]{article} 
\usepackage{times}
\usepackage{latex8}
\usepackage[american]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{color}
\usepackage[boxruled]{algorithm2e}

\definecolor{lightgray}{gray}{0.95}
\definecolor{darkgray}{gray}{0.65}

\newenvironment{DIFnomarkup}{}{}

\newcommand{\equals}{\stackrel{\mathrm{def}}{=}}
\newcommand{\gp}[1]{\stackrel{(#1)}{\tiny >}}

\newcommand{\dm}{\mbox{\textsf{DM}}} 
\newcommand{\edf}{\mbox{\textsf{EDF}}}
\newcommand{\agr}{\mbox{\textsf{AGR}}}
\newcommand{\mora}{\mbox{\textsf{MORA}}}
\newcommand{\mote}{\mbox{\textsf{MOTE}}}
\newcommand{\maxmethod}{\mbox{\textsf{MAX}}}
\newcommand{\off}{\mbox{\textsf{OFF}}}
\newcommand{\moraote}{\mbox{\textsf{MORAOTE}}}
\newcommand{\dra}{\mbox{\textsf{DRA}}}
\newcommand{\smax}{\operatorname{Smax}}
\newcommand{\soff}{\operatorname{Soff}}
\newcommand{\somme}{\operatorname{sum}}
\newcommand{\offline}{\operatorname{off}}
\newcommand{\rem}{\operatorname{rem}}
\newcommand{\next}{\operatorname{next}}
\newcommand{\disp}{\operatorname{disp}}
\newcommand{\idle}{\operatorname{idle}}
\newcommand{\nextdisp}{\operatorname{nextdisp}}
\newcommand{\edff}[1]{\mbox{\textsf{EDF}}}

\newcommand{\wait}{\operatorname{wait}}
\newcommand{\run}{\operatorname{run}}
\newcommand{\act}{\operatorname{actual}}

\newcommand{\arem}{\rem^{\offline}}
\setlength{\tabcolsep}{5pt}
\setlength{\fboxsep}{5pt}
\renewcommand{\arraystretch}{1.5}

\newtheorem{Theorem}{Theorem} 
\newtheorem{Corollary}{Corollary}
\newtheorem{Example}{Example} 
\newtheorem{Lemma}{Lemma} 
\newtheorem{Consequence}{Consequence} 
\newtheorem{Property}{Property} 
\newtheorem{Definition}{Definition}
\newtheorem{ARule}{-Rule}
\newtheorem{Rule}{Rule}
\newtheorem{Conjecture}{Conjecture}
\newtheorem{Observation}{Observation}
\newtheorem{OP}{Open Problem}
\newtheorem{Condition}{Schedulability Condition}

\newenvironment{proof}[1][Proof]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{definition}[1][Definition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{example}[1][Example]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{remark}[1][Remark]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

\newcommand{\qed}{\rule{7pt}{7pt}}
        



\newcommand{\quadrillage}[4]{ \begin{picture}(#1,#2)
\multiput(0,0)(1,0){#1}{
     \multiput(0,0)(0,0.2){#4}{\circle*{.01}}
}
\end{picture}
}

\newcommand{\lignevert}[3]{
\put(0.3,#1){#3}
\multiput(0,0)(0,0.2){#2}{\circle*{.01}}
}

\newcommand{\lignehor}[1]{
\multiput(0.2,0)(0.2,0){#1}{\circle*{.01}}
}


\newcommand{\doublefleche}[2]{
\put(0,0){\vector(1,0){#1}}
\put(#1,0){\vector(-1,0){#1}}
}

\newcommand{\doubleflechecaption}[2]{
\put(0,0){\vector(1,0){#1}}
\put(#1,0){\vector(-1,0){#1}}
\put(0,0.3){\makebox(#1,0)[c]{#2}}
}

\newcommand{\dashbusy}[4]{
\begin{picture}(#4,3)
\put(0,0){\makebox(0,1)[c]{#1}}
\put(#4,0){\makebox(0,1)[c]{#2}}
\put(0,1){\dashbox{0.2}(#4,1)[c]} 
\put(0,2){\makebox(#4,1){#3}}
\end{picture}
}

\newcommand{\busyColorText}[6]{
\begin{picture}(#4,3)
\put(0,0){\fcolorbox{black}{#6}{\makebox(0,1)[c]{#1}}}
\put(#4,0){\fcolorbox{black}{#6}{\makebox(0,1)[c]{#2}}}
\put(0,1){\fcolorbox{black}{#6}{\framebox(#4,1)[c]{#5}}}
\put(0,2){\fcolorbox{black}{#6}{\makebox(#4,1){#3}}}
\end{picture}
}

\newcommand{\busyText}[5]{
\begin{picture}(#4,3)
\put(0,0){\makebox(0,1)[c]{#1}}
\put(#4,0){\makebox(0,1)[c]{#2}}
\put(0,1){\framebox(#4,1)[c]{#5}}
\put(0,2){\makebox(#4,1){#3}}
\end{picture}
}

\newcommand{\dashbusyText}[5]{
\begin{picture}(#4,3)
\put(0,0){\makebox(0,1)[c]{#1}}
\put(#4,0){\makebox(0,1)[c]{#2}}
\put(0,1){\dashbox{0.2}(#4,1)[c]{#5}}
\put(0,2){\makebox(#4,1){#3}}
\end{picture}
}

\newcommand{\request}{
\begin{picture}(1,3)
\put(0,3){\vector(0,-1){1}}
\end{picture}
}

\newcommand{\requestText}[1]{
\begin{picture}(1,3)
\put(0,3){\vector(0,-1){1}}
\put(-1,3.5){#1}
\end{picture}
}

\newcommand{\idleinstant}{
\begin{picture}(1,3)
\put(0,0){\line(0,1){9}}
\end{picture}
}

\newcommand{\requestsymb}{
\begin{picture}(1,1)
\put(0.5,1){\vector(0,-1){1}}
\end{picture}
}

\newcommand{\deadline}[1]{
\begin{picture}(1,3)
\put(0,1){\circle{0.5}}
\put(0,0){\makebox(1,1)[l]{#1}}
\end{picture}
}

\newcommand{\deadlinesymb}{
\begin{picture}(1,1)
\put(0.5,0.5){\circle{0.7}}
\end{picture}
}

\newcommand{\failure}{
\begin{picture}(1,3)
\thicklines
\put(0,0){\vector(0,1){1}}
\end{picture}
}

\newcommand{\failuresymb}{
\begin{picture}(1,1)
\thicklines
\put(0.5,0){\vector(0,1){1}}
\end{picture}
}

\newcommand{\interval}[4]{
\begin{picture}(#4,3)
\put(0,0){\makebox(#4,1)[l]{#1}}
\put(0,0){\makebox(#4,1)[r]{#2}}
\put(0,1){\line(0,1){0.5}}
\put(#4,1){\line(0,1){0.5}}
\put(0,1){\line(1,0){#4}}
\put(0,2){\makebox(#4,1){#3}}
\end{picture}

}

    
\title{: an Energy-Aware Slack Reclamation Scheme for \\ Scheduling Sporadic Real-Time Tasks upon Multiprocessor Platforms}
\author{Vincent Nelis \and Jo\a"el Goossens}
\begin{document}
\maketitle
\footnotetext[1]{Universit\'e Libre de Bruxelles (U.L.B.) CP 212, Department of Computer Science, 50 Av. F.D.~ Roosevelt, B-1050 Brussels, Belgium.}
\addtocounter{footnote}{1}
\footnotetext[2]{Supported by the Belgian National Science Foundation (F.N.R.S.) under a F.R.I.A. grant.}
\addtocounter{footnote}{1}

\begin{abstract}
In this paper, we address the global and preemptive energy-aware scheduling problem of sporadic constrained-deadline tasks on DVFS-identical multiprocessor platforms. We propose an online slack reclamation scheme which profits from the discrepancy between the worst- and actual-case execution time of the tasks by slowing down the speed of the processors in order to save energy. Our algorithm called  takes into account the application-specific consumption profile of the tasks. We demonstrate that  does not jeopardize the system schedulability and we show by performing simulations that it can save up to  of energy (in average) compared to execution without using any energy-aware algorithm. 
\end{abstract}

\Section{Introduction}

\textbf{Context of the study.} Nowadays, many modern processors can operate at various supply voltages, where different supply voltages lead to different clock frequencies and to different processing speeds. Since the power consumption of a processor is usually a convex and increasing function of its speed, the slower its speed is, the less its consumption is~\cite{Kuo:06}. Among the most recent and popular such processors, one can cite the Intel PXA27x processor family~\cite{IntelDatasheet:05}, used by many PDA devices~\cite{UrlDevice}. 

Many computer systems, especially embedded systems, are now equipped with such voltage (speed) scaling processors and adopt various energy-efficient strategies for managing their applications intelligently. Moreover, many recent energy-constrained embedded systems are built upon multiprocessor platforms because of their high-computational requirements. As pointed out in~\cite{BaAn:03,AndersonBaruah:04}, another advantage is that multiprocessor systems are more energy efficient than equally powerful uniprocessor platforms, because raising the frequency of a single processor results in a \emph{multiplicative} increase of the consumption while adding processors leads to an \emph{additive} increase. 

Supported by this emerging technology, the Dynamic Voltage and Frequency Scaling (DVFS)~\cite{Chen:07} framework becomes a major concern for multiprocessor power-aware embedded systems. For real-time systems, this framework consists in reducing the system energy consumption by adjusting the working voltage and frequency of the processors, while respecting all the timing constraints. 


\textbf{Previous work.} There are a large number of researches about the \emph{uni}processor energy-aware real-time scheduling problem~\cite{AyMeMoMe:04,Bansal:04,Irani:03,IsYa:98,YaDeSh:95}. Among those, many \emph{slack reclamation} approaches have been developed over the years. Such techniques dynamically collect the unused computation times at the end of each early task completion and share it among the remaining pending tasks. Examples of such approaches include the ones proposed in~\cite{AyMeMoMe:04,pillai01,ShCh:99,ZhCh:02}. Some reclaiming algorithms even anticipate the early completion of tasks for further reducing the CPU speed~\cite{AyMeMoMe:04,pillai01}, some having different levels of ``aggressiveness''~\cite{AyMeMoMe:04}.

In~\cite{Chen:07}, Kuo et al.\@ propose a state-of-art about energy-aware algorithms in \emph{multi}processor environment. As it is mentioned in this state-of-art, many studies (see for instance~\cite{ChHsChYaPaKu:04,ChenKuo:05,Kuo:06,ChenKuo:06,ZhuMelhemChilders:01,YangChenKuo:05}) consider the \emph{frame-based task model}, i.e., all the tasks share a common deadline and this ``frame'' is indefinitely repeated. Among the most interesting studies which consider this task model, Zhu et al.\@~\cite{ZhuMelhemChilders:01} explored \emph{online} slack reclamation schemes (i.e., running during the system execution) for dependent and independent tasks. In~\cite{ChenKuo:06}, Kuo et al.\@ propose a set of energy-efficient scheduling algorithms with different task remapping and slack reclamation schemes. In~\cite{Kuo:06}, the authors address independent tasks, where task migrations are not allowed. In~\cite{ChHsChYaPaKu:04}, the authors provide some techniques with and without allowing task migration, while assuming that tasks share the same power consumption function and each processor may run at a selected speed, independently from the speeds of the others. In~\cite{ChenKuo:05}, the authors consider that tasks are allowed to have different power consumption functions. In~\cite{YangChenKuo:05}, energy-aware multiprocessor scheduling of frame-based tasks was explored for multiprocessor architectures, in which all the processors must share the same speed at any time. Finally the authors of~\cite{BertenGoossens:08} propose a slack reclamation scheme for identical multiprocessor platforms, while considering frame-based tasks of which the distribution of the computation times is assumed to be known.

Targeting a \emph{sporadic task model}, Anderson and Baruah~\cite{AndersonBaruah:08} explored the trade-off between the total energy consumption of task executions and the number of required processors, where all the tasks run at the same common speed. In previous work~\cite{Nelis:08}, we provided a technique that determines the minimum common offline speed for every task under global-\edf\ policy~\cite{Baker:03}, while considering identical multiprocessor platforms. Furthermore, we proposed in the same study an \emph{online} algorithm called  which was, to the best of our knowledge, the first to address the global and preemptive energy-aware scheduling problem of sporadic constrained-deadlines tasks on multiprocessors. The main idea of  is to anticipate at run-time the coming idle instants in the schedule in order to reduce the processors speed accordingly. This algorithm cannot be considered as a slack reclamation scheme since it does not directly take advantage from early tasks completion, but it can be combined with slack reclaiming techniques (and in particular with ) in order to improve the energy savings.

\textbf{Contribution of the paper.} In this paper, we propose a \emph{slack reclamation scheme} called  for the global and preemptive energy-aware scheduling problem of \emph{sporadic constrained-deadline real-time tasks} on a \emph{fixed number of DVFS-capable processors}. According to~\cite{Chen:07} and to the best of our knowledge, this is the first work which addresses a slack reclamation scheme in this context. Although most previous studies on multiprocessor energy-efficient scheduling assumed that the actual execution time of a task is equal to its Worst-Case Execution Time (WCET), such that those in~\cite{AlEnawyAydin:05,AydinYang:03,ChHsChYaPaKu:04,YangChenKuo:05} for instance, this work is motivated by the scheduling of tasks in practice, where tasks might usually complete earlier than their WCET~\cite{AyMeMoMe:04,ZhuMelhemChilders:01}. The proposed algorithm  is an \emph{online} scheme which exploits early task completions by using as much as possible the unused time to reduce the speed of the processors. Although it has been inspired from the \emph{uni}processor ``Dynamic Reclaiming Algorithm'' () proposed in~\cite{AyMeMoMe:04}, the way in which it profits from the unused time is very different from the  since  takes into account the application-specific consumption profile of the tasks.

\textbf{Organization of the paper.} The document is organized as follows: in
Section~\ref{sec:model}, we introduce our model of computation, in particular our task and platform model; 
in Section~\ref{sec:mora}, we present our online slack reclamation technique called  and we prove its correctness; 
in Section~\ref{sec:experiments}, we present our simulation results
and in Section~\ref{sec:conclusion}, we introduce future research directions and we conclude. 

\Section{Model of computation}
\label{sec:model}

\SubSection{Platform model}
\label{sec:platform}

\begin{table}
\centering
\begin{footnotesize}
\begin{tabular}{| r || c | c | c | c | c |}
\hline
Processor Type & \multicolumn{5}{ c |}{Intel XScale~\cite{IntelXScale}} \\
\hline
Frequency (MHz):  & 150 & 400 & 600 & 800 & 1000 \\
\hline 
Speed:  & 0.15 & 0.4 & 0.6 & 0.8 & 1.0 \\
\hline
Voltage (V) & 0.75 & 1.0 & 1.3 & 1.6 & 1.8 \\
\hline
Power in run mode (mW):  & 80 & 170 & 400 & 900 & 1600 \\
\hline
Power in idle mode (mW):  & \multicolumn{5}{ c |}{40} \\
\hline
\end{tabular}
\end{footnotesize}
\label{tab:processor_characterisitc}
\caption{Intel XScale characteristics}
\vspace{-1ex}
\end{table}

We consider multiprocessor platforms composed of a known and fixed number  of DVFS-\emph{identical} processors . ``DVFS-identical'' means that (i) all the processors have the same profile (in term of consumption, computational capabilities, etc.) and are interchangeable, (ii) two processors running at a same frequency execute the same amount of execution units, and (iii) all the processors have the same minimal and maximal operating frequency denoted by  and , respectively. The processors are referred to as \emph{independent}, with the interpretation that they can operate at different frequencies at the same time~\cite{Talpes:05,Magklis:03}. Furthermore, we assume that each processor can dynamically adapt its operating frequency (and voltage) at any time during the system execution, independently from each other. The time overheads on frequency (voltage) switching are assumed to be negligible, such as in many researches~\cite{AydinMelhem:01,Bansal:04,Levner:04,YaDeSh:95,Zhuo:05}.

We define the notion of \emph{speed}  of a processor as the ratio of its operating frequency  over its maximal frequency, i.e.:  -- with the interpretation that a job that executes on a processor running at speed  for  time units completes  execution units. When only  discrete frequencies are available to a processor, they are sorted in the increasing order of frequency and denoted by . For each frequency  such that , we denote by  the corresponding speed (i.e., ) and by  the power consumption (energy consumption rate) per second while the processor is running at speed . The available frequencies and the corresponding core voltages of the Intel XScale processor~\cite{IntelXScale} that will be used in our experiments are outlined in Table 1. Notice that, from our definition of the processor speed,  is  whatever the considered processor. Moreover, due to the finite number of speeds that are available to any practical processor, any speed  computed by any energy-aware algorithm must be translated into one of the available speeds. In this work, this translation is performed by the function .



\SubSection{Application model}

A real-time system  is a set of  functionalities denoted by . Every functionality  is modeled by a \emph{sporadic constrained-deadline} task characterized by three parameters  -- a Worst-Case Execution Time (WCET)  {at maximal processors speed } (expressed in milliseconds for instance), a minimal inter-arrival delay  and a relative deadline  -- with the interpretation that the task  generates successive \emph{jobs}  (with ) arriving at times  such that  (with ), each such job has a worst-case execution time of at most  time units (at maximal processors speed ), and must be completed at (or before) its absolute deadline noted . According to our definition of the processors speed, a processor running at speed  may take up to  time units to complete a job  and, at a given speed , its WCET is . Notice that, since , successive jobs of any task  do not interfere with each other. 

We define the \emph{density}  of the task  as the ratio of its WCET at maximal speed  over its deadline, i.e., . We assume that this ratio is not larger than  for every task, since a task with a density larger than  is never able to meet its deadlines (since task parallelism is forbidden in this work). The \emph{maximal density}  \emph{of the system} is defined as  and its \emph{total density} is defined as . In our study, all the tasks are assumed to be \emph{independent}, i.e., there is no communication, no precedence constraint and no shared resource (except the processors) between them. 

At any time  in any schedule , a job  is said to be \emph{active} iff  and it is not completed yet in . Moreover, an active job is said to be \emph{running} at time  in  if it is executing on a processor. Otherwise, the active job is pending in a ready-queue of the operating system and we say that it is \emph{waiting}. Furthermore, a job is said to be \emph{dispatched} at time  in  if it passes from the waiting state to the running state at time .

Although certain benchmarks provide measured power consumption, we should not ignore that different applications may have different instruction sequences and require different function units in the processor, thus leading to different dynamic consumption profiles. As it was already done in~\cite{RXu:07}, we hence introduce a measurable parameter  for each task  that reflects this application-specific power difference between the applications and the measured benchmark. Accordingly, the consumption of any task  executed for  time unit at speed  can be estimated by ~\cite{RXu:07}, where  and  are defined as in Table 1. In the remainder of this paper, we denote by  the energy consumed by the task  when executed for  time units at speed  and we define it as . As we will see in Section~\ref{sec:principemora},  uses these energy consumption functions in order to improve the energy saving that it provides. This improvement makes  very different from the \emph{uni}processor dynamic reclaiming algorithm  proposed in~\cite{AyMeMoMe:04}.

\SubSection{Scheduling specifications}
\label{sec:scheduler}

We consider in this study the \emph{global} scheduling problem of sporadic constrained-deadlines tasks on multiprocessor platforms. ``Global'' scheduling algorithms, on the contrary to partitioned algorithms, allow different tasks and \emph{different} jobs of the same task to be executed upon \emph{different} processors. Furthermore, we consider \emph{preemptive} scheduling and \emph{Fixed Job-level} Priority assignment (FJP), with the following interpretations. In the \emph{preemptive global scheduling problem}, every job can start its execution on any processor and \emph{may migrate at run-time} to any other processor if it gets meanwhile preempted by a higher-priority job. We assume in this paper that preemptions are carried out with no loss or penalty. \emph{Fixed Job-level Priority assignment} means that the scheduler assigns a priority to jobs as soon as they arrive and every job keeps its priority constant until it completes. \emph{Global Deadline Monotonic} and \emph{Global Earliest Deadline First}~\cite{Baker:03} are just some examples of such scheduling algorithms. 

\Section{The Multiprocessor Online Reclaiming Algorithm (\mora)}
\label{sec:mora} 

\SubSection{Notations}
\label{sec:notations}
\emph{During the system execution}, every \emph{active} job  has two associated speeds noted  and . The speed  denotes \emph{the speed that a processor adopts while executing }. We assume that these execution speeds  can be modified at any time during the system execution, even during the execution of , and it is instantaneously reflected on the processor speed. On the other hand, the speed  is the \emph{offline precomputed execution speed} of , in the sense that the value of  is always set to  at  arrival time. These offline speeds  are determined \emph{before} the system execution and remain always constant at run-time. They may be simply set to the maximal processors speed , or they can be determined by an \emph{offline} energy-aware strategy, such that the one proposed in~\cite{Nelis:08} for instance. These offline speeds \emph{must ensure that all the deadlines are met} when the set of tasks is scheduled upon the  processors, even if every job of every task presents its WCET. Notice that, since each task generates an infinity of jobs, the method proposed in~\cite{Nelis:08} determines a common speed for every task and assumes that every job  inherits from the offline speed of  at run-time.

 is based on reducing \emph{online} (i.e., while the system is running) the execution speed  of the jobs in order to provide energy savings \emph{while still meeting all the deadlines}. To achieve this goal,  detects whenever the speed  of an active job  can safely be reduced by performing comparison between the schedule which is actually produced (called the \emph{actual schedule} hereafter) and the \emph{offline schedule} defined below. We will see in the remainder of this section that our algorithm  \emph{always refers to this offline schedule} in order to produce the actual one.

\begin{Definition}[The offline schedule]
The offline schedule is the schedule produced by the considered scheduling algorithm on which every job of every task  runs at its offline speed  and presents its WCET.
\end{Definition}

Figure~\ref{fig:notations}.(a) depicts an example of an offline schedule and illustrates the notations that will be used throughout the paper. In this picture, a 5-tasks system is executed upon 2 processors, where only the first job of each task is represented. The characteristics of the tasks are the following (remember that ):  and . Assuming Global-, we have the following priority order: . Furthermore, we assume in this example that the offline speed  of every job  is the maximal processors speed .

\begin{figure}[h!]
\centering
  {\footnotesize \setlength{\unitlength}{0.37cm}
\begin{picture}(22,14)
\put(1,0){\vector(1,0){21}}
\put(21,-1){time}
\put(1.9,-0.5){\tiny }
\put(2.9,-0.5){\tiny }
\put(3.9,-0.5){\tiny }
\put(4.9,-0.5){\tiny }
\put(5.9,-0.5){\tiny }
\put(6.9,-0.5){\tiny }
\put(7.9,-0.5){\tiny }
\put(8.9,-0.5){\tiny }
\put(9.9,-0.5){\tiny }
\put(10.9,-0.5){\tiny }
\put(11.9,-0.5){\tiny }
\put(12.9,-0.5){\tiny }
\put(13.9,-0.5){\tiny }
\put(14.9,-0.5){\tiny }
\put(15.9,-0.5){\tiny }
\put(16.9,-0.5){\tiny }
\put(17.9,-0.5){\tiny }
\put(18.9,-0.5){\tiny }
\put(19.9,-0.5){\tiny }

\put(0,13){(a) Offline schedule.}
\put(0,10.5){}
\put(0,9){}
\multiput(2,8)(1,0){21}{
     \multiput(0,0)(0,0.35){11}{\tiny }
}
\put(5.1,10){}
\put(2.1,10){\framebox(6,1)[c]{}}
\put(8.1,10){\framebox(8,1)[c]{}}
\put(8.1,11.6){\line(0,-1){.7}}
\put(8.4,11.3){\tiny }
\put(2.1,8.6){\framebox(6,1)[c]{}}
\put(8.1,8.6){\framebox(2,1)[c]{}}
\put(8.1,7.9){\line(0,1){.7}}
\put(5.5,7.3){\tiny }
\put(10.1,8.6){\framebox(6,1)[c]{}}
\put(10.1,7.9){\line(0,1){.7}}
\put(9.5,7.3){\tiny }

\put(20.1,7.7){\deadline}
\put(17.1,7.7){deadline of }


\put(0,6){(b) Actual schedule.}
\put(0,4){}
\put(0,2.5){}
\multiput(2,1)(1,0){21}{
     \multiput(0,0)(0,0.35){13}{\tiny }
}
\put(2.1,3.5){\framebox(3,1)[c]{}}
\put(8.1,3.5){\framebox(3,1)[c]{}}
\put(2.1,2.1){\framebox(2,1)[c]{}}
\put(8.1,2.1){\framebox(2,1)[c]{}}
\put(10.1,2.1){\framebox(6,1)[c]{}}
\put(20.1,1.2){\deadline}
\put(17.1,1.2){deadline of }
\end{picture}
}
\caption{Offline and actual schedules.}
\label{fig:notations}
\end{figure}

At run-time, \emph{whenever any job is dispatched to any processor  in the offline schedule,  also dispatches it to  in the actual one}. That is, assuming the same set of tasks as in Figure~\ref{fig:notations}.(a), Figure~\ref{fig:notations}.(b) depicts the actual schedule that is produced if the \emph{actual execution time} of the jobs  are respectively . At any time , we denote by  and  the worst-case \emph{remaining} execution time of job  at speed  in the actual and offline schedule, respectively. We assume that these quantities are updated at run-time for every active job . For instance in Figure~\ref{fig:notations} at time , we have  (since  completes at time  in the actual schedule) and . Notice that from our definition of a processor speed, the worst-case \emph{remaining} execution time of job  at speed  in the actual and offline schedule is  and , respectively. We denote by  the earliest time at which  is dispatched in the offline schedule, when only the set of active jobs at time  in the offline schedule are considered. For instance in Figure~\ref{fig:notations}.(a) we have  and . Finally,  denotes the earliest instant after time  at which a job which is not completed in the actual schedule at time  is dispatched to  in the offline schedule. Again, only the set of active jobs at time  in the offline schedule are considered to compute . For instance in Figure~\ref{fig:notations}.(a) we have  and .

\SubSection{The -queue}

Since the jobs arrival times are unknown while considering the sporadic task model, computing and storing the entire offline schedule cannot be done \emph{before the system execution}. Hence, our algorithm only stores and updates at run-time a \emph{sufficient part} of the offline schedule. This kind of approach (i.e., using a dynamic data structure for embodying a sufficient part of the offline schedule) was previously proposed in~\cite{AyMeMoMe:04}. As in~\cite{AyMeMoMe:04}, we call this data structure \emph{-queue}. The \emph{-queue} is a list that contains, at any time , the worst-case remaining execution time  of every active jobs  \emph{in the offline schedule}. This list is managed according to the following rules, which are widely inspired from~\cite{AyMeMoMe:04}.

\begin{ARule}
\label{arule:1}
At any time, the -queue is sorted by decreasing order of the job priorities, with the  highest priority jobs at the head of the queue.
\end{ARule}

\begin{ARule}
\label{arule:2}
Initially the -queue is empty. 
\end{ARule}

\begin{ARule}
\label{arule:3}
Upon arrival of a job  at time ,  inserts its WCET  into the -queue in the correct priority position. This happens only once for each arrival, no re-insertion at return from preemptions. 
\end{ARule}

\begin{ARule}
\label{arule:4}
As time elapses, the  fields  (if any) at the head of the -queue are decreased with a rate proportional to the offline speeds . Whenever one field reaches zero, that element is removed and the update continues, still with the  first elements (if any). Obviously, no update is performed when the -queue is empty.
\end{ARule}

For the same reasons than those explained in~\cite{AyMeMoMe:04}, the following observation holds.
\begin{Observation}
\label{obs:1}
At any time , the -queue updated according to -Rules~\ref{arule:2}--\ref{arule:4} contains only the jobs that would be active at time  in the offline schedule. Moreover, the  fields contain the worst-case remaining execution time of every active job  at time  in the offline schedule.
\end{Observation}

By consulting the -queue at any time ,  is able to get the required information about any active jobs  in the offline schedule, i.e., its worst-case remaining execution time , its next dispatching time  and the next job dispatching time  on any processor . Due to the space limitation, we omitted the implementation details about the procedures which compute  and .

Notice that, as explained in~\cite{AyMeMoMe:04}, the dynamic reduction of  from -Rule~\ref{arule:4} does not need to be performed at every clock cycle. Instead, for efficiency, we perform the reduction only \emph{before}  modifies a speed, by taking into account the time elapsed since the last update. Formally, if  time units elapsed, the  fields at the head of the -queue are updated as follows: . The above approach relies on two facts: as we will see in the next section, the speed adjustment decisions will be taken only at job arrival time (i.e., the execution speed of the arriving job is set to its offline speed), job dispatching time in the offline schedule and whenever a processor is about to get idle in the actual schedule. Hence, it is necessary to have an accurate -queue only at these instants. Second, between these instants, each task is effectively executed non-preemptively in the actual schedule. 

\SubSection{Principle of }
\label{sec:principemora}
As explained in Section~\ref{sec:notations}, whenever a job is dispatched in the offline schedule, it is also dispatched in the actual one. However, as we will see below,  profits from an early job completion by starting the execution of some other jobs \emph{earlier in the actual schedule than in the offline one}. As a result,  when a job (say ) is dispatched at time  in the offline schedule (and thus also in the actual one), its worst-case remaining execution time  could be lower than  if it was executed earlier in the actual schedule. For example, Figure~\ref{fig:first_rule} depicts the same set of tasks than in Figure~\ref{fig:notations}. At time ,  completes in the actual schedule on processor  and leaves  unused time units. These  time units are reclaimed by starting the execution of  (we will see below how  selects the job which profits from the slack time) and therefore, when  is dispatched to  in the offline schedule at time , it is also dispatched to  in the actual one and we have . The difference between these remaining execution times is called the \emph{earliness} of the job and we denote it by . According to this earliness, whenever any job  is dispatched in both schedules, its execution speed  may \emph{safely} be reduced to  so that . Indeed, under this speed ,  would complete simultaneously in both schedules if it presents its WCET. This leads to the first rule of .

\begin{small}
\begin{Rule}
\label{rule:1}
Any job  which is dispatched to any processor  at time  in the offline schedule is also dispatched to  at time  in the actual one and its execution speed  is modified according to

\end{Rule}
\end{small}


The main idea of  can be summarized as follows. \emph{When any job completes in the actual schedule without consuming its WCET, the unused time may be reclaimed by starting the execution of any waiting job earlier; and since this waiting job receives additional time for its execution, it can thereby reduce its execution speed}. Using this concept, Figure~\ref{fig:first_rule} depicts an example of how  takes advantage from an early job completion. When  completes at time  in the actual schedule,  selects a waiting job (here, ) and executes it during the  time units left by . Since  is granted to use  additional time units,  reduces its execution speed  so that its worst-case remaining execution time increases by  time units. The selected job is the one for which the resulting speed reduction leads to the highest energy saving. Formally,  selects a waiting job and decreases its execution speed as described by Rule~\ref{rule:2}.

\begin{figure}[h!]
  {\footnotesize \setlength{\unitlength}{0.37cm}
\begin{picture}(22,11)
\put(1,0){\vector(1,0){21}}
\put(21,-1){time}
\put(1.9,-0.5){\tiny }
\put(2.9,-0.5){\tiny }
\put(3.9,-0.5){\tiny }
\put(4.9,-0.5){\tiny }
\put(5.9,-0.5){\tiny }
\put(6.9,-0.5){\tiny }
\put(7.9,-0.5){\tiny }
\put(8.9,-0.5){\tiny }
\put(9.9,-0.5){\tiny }
\put(10.9,-0.5){\tiny }
\put(11.9,-0.5){\tiny }
\put(12.9,-0.5){\tiny }
\put(13.9,-0.5){\tiny }
\put(14.9,-0.5){\tiny }
\put(15.9,-0.5){\tiny }
\put(16.9,-0.5){\tiny }
\put(17.9,-0.5){\tiny }
\put(18.9,-0.5){\tiny }
\put(19.9,-0.5){\tiny }

\put(0,10.5){(a) Offline schedule.}
\put(0,8.5){}
\put(0,7){}
\multiput(2,6)(1,0){21}{
     \multiput(0,0)(0,0.35){11}{\tiny }
}

\put(2.1,8){\framebox(6,1)[c]{}}
\put(8.1,8){\framebox(8,1)[c]{}}
\put(2.1,6.6){\framebox(6,1)[c]{}}
\put(8.1,6.6){\framebox(2,1)[c]{}}
\put(10.1,6.6){\framebox(6,1)[c]{}}
\put(20.1,5.7){\deadline}
\put(17.1,5.7){deadline of }

\put(0,5){(b) Actual schedule.}
\put(0,3){}
\put(0,1.5){}
\multiput(2,0)(1,0){21}{
     \multiput(0,0)(0,0.35){13}{\tiny }
}

\put(2.1,3){\framebox(3,1)[c]{}}
\put(8.1,3){\framebox(3,1)[c]{}}
\put(2.1,1.6){\framebox(2,1)[c]{}}
\put(4.1,1.6){\framebox(4,1)[c]{}}
\put(4.1,1.6){}
\put(8.1,1.6){\framebox(2,1)[c]{}}
\put(10.1,1.6){\framebox(6,1)[c]{}}
\put(20.1,0.7){\deadline}
\put(17.1,0.7){deadline of }

\end{picture}
}
\caption{Rules~\ref{rule:1} and~\ref{rule:2} of .}
\label{fig:first_rule}
\end{figure}

\begin{small}
\begin{Rule}
\label{rule:2}
Whenever any processor  is about to get idle at time  in the actual schedule,
\begin{description}
\item[Step 1.] Use the -queue to compute the next dispatching time  on processor  and proceed to the steps 2--5 for every waiting job  at time  in the actual schedule.
\item[Step 2.] Compute the amount  of additional time units that  could reclaim in the actual schedule if it was dispatched at time , i.e.,

In Figure~\ref{fig:first_rule} we have  and  . 
\item[Step 3.] Compute what would be the resulting execution speed  if  was granted to use both its earliness and these  additional time units, i.e.,  is computed so that , thus leading to

\item[Step 4.] Estimate what would be the resulting execution speed  if  was not granted to use these  additional time units. According to Rule~\ref{rule:1},  will be modified to  when  will be dispatched in the offline schedule (say at time ). By assuming that  will not be executed in the actual schedule until time , we will have  and from Expression~\ref{equ:speedreduction2}

\item[Step 5.] Compute the energy saving  between execution at speed  and at speed :

\item[Step 6.] Dispatch the job  with the largest  to processor . If  for all the waiting jobs, then dispatch the waiting job  (if any) with the highest priority in order to complete it earlier and to potentially increase the length of future slack time. 
\item[Step 7.]  If there is a selected job , set its execution speed  to the computed one . Otherwise, turn the processor  into the idle mode.
\end{description}
\end{Rule}
\end{small}


Notice that, if a processor is about to be idle in the actual schedule exactly when a job is dispatched in the offline one, \emph{only Rule~\ref{rule:1} is applied}. Algorithm~\ref{algo:mora} presents the pseudo-code of  and we demonstrate its correctness in the following section. 

\incmargin{.2em} 
\linesnotnumbered
\begin{algorithm}[h!]
\begin{scriptsize}
\lnl{} Determine the offline speed  of every job  \;
\lnl{} -queue  \;
\vspace{0.2cm}

\textbf{At job arrival (say ) at time :} 

\Indp
\lnl{} Update the -queue according to -Rule~\ref{arule:4} \;
\lnl{} Insert the value of  into the -queue according to -Rule~\ref{arule:3} \;
\lnl{} Set  to  \;
\Indm
\vspace{0.2cm}

\textbf{Whenever any processor  is about to get idle at time :} 

\Indp
\lnl{} Update the -queue according to -Rule~\ref{arule:4} \;
\lnl{} apply Rule~\ref{rule:2} \;
\Indm
\vspace{0.2cm}

\textbf{Whenever any job  is dispatched to any processor  in the offline schedule at time :} 

\Indp
\lnl{} Update the -queue according to -Rule~\ref{arule:4} \;
\lnl{} \lIf{(a job  is running on )}{Preempt } \;
\lnl{} apply Rule~\ref{rule:1} \;
\Indm
\caption{}
\label{algo:mora}
\end{scriptsize}
\end{algorithm}
\decmargin{.2em} 


\SubSection{Correctness of }
\label{sec:proofs}

In this section, we formally prove that using  does not jeopardize the system schedulability.

\begin{Lemma}
\label{lem:wait_run}
Let  be any preemptive and FJP global scheduling algorithm and let  be any set of real-time tasks. Suppose that  is scheduled by  while using , and at time  during the system execution we have  and :

Then,  with  such that  running at time  in the offline schedule and waiting at time  in the actual one.
\begin{proof} 
The proof is obtained by contradiction. Suppose that at any time  such that ,  running in the offline schedule and waiting in the actual one. It implies that at time  in the offline schedule, there are at most  jobs with an higher priority than , whereas there are at least  such jobs in the actual one. In other words, there is at least one job (say ) at time  with an higher priority than , such that  is completed in the offline schedule, and not in the actual one. For this job, it holds that , leading to contradiction with our hypothesis. The property follows. \hfill \qed
\end{proof}
\end{Lemma}

\begin{Lemma}
\label{cor:rule1}
Let  be any preemptive and FJP global scheduling algorithm and let  be any set of real-time tasks. Suppose that  is scheduled by  while using , and at time  during the system execution we have  and :

Then,  with  such that  running at time  in the offline schedule and such that the last speed modification of  was performed according to Rule~\ref{rule:2}.
\begin{proof} 
The proof is obtained by contradiction. Suppose that at time  with ,  running at time  in the offline schedule and such that the last modification of  was performed according to Rule~\ref{rule:2}. Let  and  be the largest instants before time  at which  was dispatched in the actual and offline schedule, respectively. Notice that the case where  is not dispatched before time  in the actual schedule leads to a contradiction of Lemma~\ref{lem:wait_run}. Therefore, only two cases may arise: (i) , in this case  would have been modified at time  according to Rule~\ref{rule:1}, leading to a contradiction of our hypothesis, or (ii) , which leads to a contradiction of Lemma~\ref{lem:wait_run}. The property follows. \hfill\qed
\end{proof}
\end{Lemma}

\begin{Theorem}
Let  be any preemptive and FJP global scheduling algorithm and let  be any set of real-time tasks which is schedulable by  when every job  is executed at its offline speed . Then, every job deadline is still met when the system is scheduled by  while using .
\begin{proof}
The proof consists in showing that  we have

while using . Indeed, since the offline schedule meets all the deadlines, we have  . Therefore, having  leads to  , meaning that the actual schedule also meets all the deadlines. 

Initially at time , we obviously have  . Now, let  be any instant and suppose that  and  we have . We prove in the following that it yields

where  denotes the earliest instant after time  such that one of the following events occurs: arrival of a job, deadline of a job, completion of a job in the actual schedule or in the offline schedule, dispatching of a job in the actual schedule or in the offline schedule. Obviously if Inequality~\ref{equ:rem_next} holds then Inequality~\ref{equ:goal} also holds since  can denote every job deadline.

From the definition of , every processor of both schedules is either idle or it executes one and only one job during any time interval . In other words, the state (waiting or running) of any active jobs in any schedule does not change during any time interval . As a result, the following relations hold at time :
\begin{itemize}
\item For any waiting job  in the actual schedule:

\item For any waiting job  in the offline schedule:

\item For any running job  in the actual schedule:

\end{itemize}

The first part of the proof shows that Inequality~\ref{equ:rem_next} holds for every waiting job at time  in the actual schedule and the second part shows that it also holds for every running job at time  in the actual schedule.

\paragraph{Part 1.} Let  be any waiting job at time  in the actual schedule. From Lemma~\ref{lem:wait_run}, we know that  is also waiting at time  in the offline one and since by hypothesis , we know from Equalities~\ref{equ:rel1} and~\ref{equ:rel3} that . The property follows.

\paragraph{Part 2.} Let  be any running job at time  in the actual schedule. Regarding its execution speed , only two cases may occur: its last modification was performed by Rule~\ref{rule:1} (case 1) or by Rule~\ref{rule:2} (case 2).

\paragraph{Case 1.}  is running at time  in the actual schedule and the last modification of  was performed according to Rule~\ref{rule:1} when it was dispatched in the offline schedule (say at time ). By hypothesis, we have  and we know that  is executed non-preemptively in both schedules during the time interval . Indeed, if it was preempted in the offline schedule, it would have been also preempted in the actual one according to Rule~\ref{rule:1}. However in the actual schedule,  is running at times  and . Therefore, its speed would have been modified according to Rule~\ref{rule:2} at its re-dispatching time if it was preempted during . As a result, from our interpretation of the processor speed we get
\begin{small}

\end{small}
and
\begin{small}

\end{small}

\noindent After the speed modification by Rule~\ref{rule:1} at time , we know from Expression~\ref{equ:speedreduction2} that  and Equality~\ref{equ:temp1} can be rewritten as
\begin{scriptsize}

\end{scriptsize}

\noindent Finally, notice that multiplying the right-hand side of the above Equality by  leads to the right-hand side of Equality~\ref{equ:temp2}. Since by hypothesis , we have  and therefore . The property follows.

\paragraph{Case 2.}  is running at time  in the actual schedule and the last modification of  was performed according to Rule~\ref{rule:2}. Therefore, we know from Lemma~\ref{cor:rule1} that  is waiting at time  in the offline schedule, and since by hypothesis , we know from Equalities~\ref{equ:rel3} and~\ref{equ:rel2} that . The theorem follows. \hfill\qed
\end{proof}
\end{Theorem}

\Section{Simulation results}
\label{sec:experiments}

In this section, we compare the effectiveness of  with other energy-aware algorithms. However, it is meaningful to only compare  with approaches that consider the same models of computation and the most related paper to ours is~\cite{Nelis:08}, where two methods with the same task and platform model are proposed. However, these two methods do not take into account the application-specific parameter  of task . The first method proposed in~\cite{Nelis:08} (that we denote by  hereafter) is an offline speed determination technique for Global- which determines an unique and constant speed  for all the processors such that all the job deadlines are met under this speed. In our simulations, this  method is used by  in order to provide the offline speed  of every job , i.e.,  is determined at line 1 of Algorithm~\ref{algo:mora} and  is set to  between lines 4 and 5. The second method proposed in~\cite{Nelis:08} is the  algorithm. At run-time, it anticipates the coming idle instants in the schedule and adjusts the speed of the processors accordingly, i.e., it reduces the processors speed in order to minimize the proportion of time during which the system is idle. Since this algorithm is also based on the concept of the offline speeds, we consider that  is also used to provide it. Although  could also be compared with frame-based scheduling algorithms (since the sporadic task model is a generalization of the frame-based task model), we do not perform such comparisons in this paper.

In our simulations, we schedule \emph{periodic implicit-deadline systems} (i.e., ,  is here the \emph{exact} inter-arrival delay between successive jobs and ). The energy consumption of each generated system is computed by simulating three methods: ,  and , i.e., a combination of the  and . Indeed, since these algorithms do not interfere with each other, the  rule can be applied \emph{on the offline speeds} just \emph{before applying Rule~\ref{rule:1}} of  (i.e., between lines 9 and 10 of Algorithm~\ref{algo:mora}). Although the implementation details of  are omitted here due to the space limitation, we will see in our simulation results that this combination always improves the provided energy savings. The consumptions provided by these three methods are compared with the consumption of the  method, where all the jobs are executed at the maximal processors speed . That is, we consider that the consumption by  is  and the consumptions of the other methods are normalized.

In every simulation, we generated  set of tasks with a total density  within  where , leading to an amount of  generated task sets for each simulation. The upper bound on  (i.e., 10) was chosen in order to cover a large number of systems while keeping the simulation time reasonable. For a given \emph{total density}, tasks densities  are uniformly generated within  until the total density  reaches the expected one (the upper bound  on the tasks density will be discussed later). Notice that the number  of tasks is not fixed beforehand, i.e., it depends on this step that generates task densities. Next, other task parameters ,  and  are randomly generated according to their respective density . Finally, the application-specific parameters  are uniformly chosen in  so that the consumption of the tasks varies between  and  of the power of the measured benchmark. 

Once a set of tasks is generated, it is executed during  hyper-periods (i.e. the least common multiple of the task periods) by the four methods , ,  and . This upper bound on systems execution time was chosen to ensure that every task generates at least  jobs (for the same reason as those mentioned above). During each system execution, the actual execution time of every job  is uniformly generated in . This lower bound  was chosen in order to reflect the fact that a job may take up to  times less than its WCET. Finally, for every generated task set , the number  of processors must be sufficient to schedule  by  without missing any deadline. Hence, we set  to the lowest integer that passes one of the following -schedulability tests: the \emph{density-based} test~\cite{Goossens2003Priority-driven}, the \emph{load-based} test~\cite{BaruahBaker:08} and the test denoted Test 13 in~\cite{LivreBaruah}. Simulations were performed while considering different scheduling algorithms (Global- and Global-) and various processor models. However, due to the space limitation, we only depict in this paper the results provided by Global- on Intel XScale processors (outlined in Table 1 page~\pageref{tab:processor_characterisitc}). 

\begin{Observation}
\label{obs:2}
The effectiveness of both  and  mainly relies on the ratio , but antagonistically. 
\end{Observation}

This observation stems from the fact that  saves energy via the waiting jobs whereas  profits from the absence of waiting jobs. When  tends to , jobs tend to never wait for a free processor and  therefore provides significant energy savings whereas the effectiveness of  is almost null. On the other hand when  tends to , processors tend to consecutively execute several distinct jobs and jobs are often waiting. As a result,  is often able to reclaim unused time and provides important energy savings whereas the effectiveness of  is negligible.

According to our task generation process, we are not able to directly set the ratio  to any given value. However, the number  of processors is obtained by using a combination of \emph{sufficient} schedulability tests and the accuracy of these tests mainly relies on . Basically, the ratio  increases as  becomes larger and since the generated task sets are more likely to have a large  when the upper bound  is high, we can indirectly control the ratio  via . The Y-axis of Figure 3 represents the ratio  obtained from the used schedulability tests when  varies within  and  varies within  with a step of . 

For every  multiple of  within ,  set of tasks were generated by the generation process described above and the resulting average consumptions of the ,  and  are depicted in Figure 4. The Y-axis is the average energy consumption of every method compared with the  method (in ) and the X-axis is the corresponding value of  during the simulation. As we can see, Figures 3 and 4 clearly corroborate Observation~\ref{obs:2}. Moreover, Figure 4 shows that  can save up to  of energy (in average) over the  method (for ) and the algorithm  provides important energy savings for various values of . Notice that a part of the energy savings is explained by the use of the  method, which leads  and  to an energy savings of about  when  tends to 0 and 1, respectively. Furthermore, although other processor models and scheduling algorithms led to different average consumptions, the \emph{evolution} of the consumption with respect to  remains similar than in Figure 4.

\Section{Conclusion}
\label{sec:conclusion}

In this paper, we propose a slack reclamation scheme called  which reduces the energy consumption while scheduling a set of \emph{sporadic constrained-deadline tasks} by a \emph{global}, \emph{preemptive} and FJP algorithm on a \emph{fixed number of DVFS-identical processors}. According to~\cite{Chen:07} and to the best of our knowledge, we are the firsts to address such approach in this context. The proposed algorithm  exploits early job completions at run-time by starting the execution of the next waiting jobs at a lower speed. Compared with other reclaiming algorithms such that the  proposed in~\cite{AyMeMoMe:04},  takes into account the application-specific consumption profile of the tasks in order to improve the energy saving that it provides. Moreover, we proved that using  does not jeopardize the system schedulability and we show in our simulations that it can save up to  of energy (in average) compared to execution without using any energy-aware algorithm. 

\begin{figure}[h!]
\begin{center}
\includegraphics[height=.3\textwidth,width=.5\textwidth]{ratios.pdf}
\label{fig:ratios}
\vspace{-5ex}
\caption{Ratio  for different values of }
\vspace{-3ex}
\end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[height=.3\textwidth,width=.5\textwidth]{hist.pdf}
\label{fig:hist}
\vspace{-5ex}
\caption{Average consumptions of ,  and  for various values of  under Global- on Intel XScale processors.}
\end{center}
\end{figure}

In our future works, we aim to specialize  so that it will take into account more practical constraints such that preemption costs, migration costs and time overheads due to the multiple frequency switching. Moreover, we aim to extend our processor model in order to handle the various idle and sleep modes of the processors and to take into account the energy costs due to frequency switching. In other future works, we also aim to propose a new multiprocessor reclamation scheme which anticipates the early completion of jobs for further reducing the CPU speed. This approach will be based on statistical informations about tasks that are assumed to be known \emph{a priori}. Some \emph{uni}processor energy-aware algorithms already exploit this concept (see the  algorithm proposed in~\cite{AyMeMoMe:04} for instance).

\bibliographystyle{latex8}
\bibliography{energy}



\end{document}
