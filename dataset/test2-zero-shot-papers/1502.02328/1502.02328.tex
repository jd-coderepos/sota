\documentclass[english]{article}
\usepackage{fullname}
\usepackage{fullpage}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{latexsym}
\usepackage{amsmath} \usepackage{amssymb}
\usepackage{amsfonts} \makeatletter
\usepackage{times}

\newcommand\secref[1]{\ifthenelse{\equal{#1}{}}{}{Section~\ref{s:#1}}}
\newcommand\inside{\beta}
\newcommand\reachfrom{B}
\newcommand\outside{\alpha}
\newcommand\reachto{A}
\newcommand\true{\algkey{true}}
\newcommand\false{\algkey{false}}
\newcommand\textlet[2]{\textit{let }{#1}\equiv{#2}}
\newcommand\sts{\textit{sidetracks}}
\newcommand\msts{{\#s}}
\newcommand\besttree{\pi\kstar}
\newcommand\nil{\emptyset}
\newcommand{\alias}       [2]{\@ifdefinable #1{\let #1 #2}}
\alias\realias\let
\newcommand{\providealias}[2]{\@ifundefined #1{\let #1 #2}}
\newcommand{\mts}{MT_\Sigma}
\newcommand\ternary[3]{
  \left\{ \begin{array}{ll}
      {#2}
      & \textit{if }{#1}\\
      {#3}
      & \textit{otherwise}
    \end{array} \right.
}


  \newcommand\hastails{{tail nodes }}
  \newcommand\hashead{{head }}

\newcommand\geneq{{\approx}}

\newcommand\comment[1]{}
\newcommand\into{\rightarrow}
\newcommand\powset[1]{\mathcal{P}(#1)}
\newcommand\logand{\wedge}
\newcommand\logor{\vee}
\newcommand\union{\cup}
\newcommand\intersect{\cap}
\newcommand\concat{\cdot}
\newcommand\bigconcat{\bullet}
\newcommand\assign{\leftarrow}
\newcommand\naturals{\mathbb{N}}
\newcommand\reals{\mathbb{R}}
\newcommand\positivereals{\mathbb{R}^{+}}
\newcommand\negativereals{\mathbb{R}^{-}}
\newcommand\nonnegreals{(\reals - \negativereals)}
\newcommand\nonnegints{(\naturals \union\{0\})}
\newcommand\domain[1]{\text{dom }#1}
\alias\coll\mathcal
\newcommand\multiset[1]{\coll{M}(#1)}
\newcommand\seqn[2]{({#1}_{1},\ldots,{#1}_{#2})}

\newcommand\invisfootnote[1]{
  \renewcommand{\thefootnote}{}
  \footnotetext[0]{#1}
  \renewcommand{\thefootnote}{\arabic{footnote}}
}

\newcommand\transformsto{\rightarrow}
\newcommand\derives{\Rightarrow}
\newcommand\logimplies{\implies} \newcommand\st{\;|\;}
\newcommand\bigst{\;\bigl | \;}
\newcommand{\nth}[2]{#1\textsuperscript{\textit{#2}}}
\newcommand{\kstar}{^{\star}}
\newcommand\algname[1]{\textbf{#1}}
\newcommand\algkey[1]{\algname{#1}}
\newcommand\al[1]{\text{#1}}
\newcommand\cls[1]{\textbf{#1}}
\newcommand\url[1]{#1}
\newcommand\newVar[2]{\newcommand{#1}{#2}} 

\newcommand\PQ[1]{\algname{HEAP-{#1}}}
\newcommand\fnote[1]{({#1})}
\newcommand\Adj{\textit{Adj}}
\newcommand\Adji{\textit{Adj}^{-1}}


\newVar{\startnode}{\omega}

\newcommand\derivess[1]{\derives_{#1}}
\newcommand\derivesc[1]{\derives_{#1}\kstar}
\newcommand\derivesl[1]{\derives_{#1}^{L*}}

\newcommand\algref[1]{Algorithm~\ref{#1}}


\title{Context-free Algorithms}   \author{Jonathan Graehl \\ SDL Research \thanks{Work done at University of Southern California, Information Sciences Institute, 4676 Admiralty Way, Marina del Rey, CA 90292}
}
\date{July 20, 2005}    

\begin{document}
\maketitle

\begin{abstract}
  Algorithms on grammars/transducers with context-free derivations: hypergraph reachability, shortest path, and inside-outside pruning of 'relatively useless' arcs that are unused by any near-shortest paths.

\end{abstract}

\section{Introduction}
We present algorithms on context-free grammars (and also on hypergraphs and regular tree grammars, which share the same context-free derivation rule): hypergraph reachability, shortest path, and inside-outside pruning of 'relatively useless' arcs that are unused by any near-shortest paths. \secref{notation} is optional for those already familiar with regular tree grammars (analogous to derivation trees of context free grammars) and/or hypergraphs.

\section{Notation}
\label{s:notation}
\label{sec1}
\subsection{Strings}

 are the \emph{strings over alphabet }.  For
 the \emph{length} of  is  and the
\emph{th letter} is , for all , and the concatenation of a sequence of
letters by index is .  \emph{Concatenation} of strings is specified by
the  operator, where .
\comment{Naturally, .}
\comment{:

}

\comment{
The \emph{letters in } are .
The \emph{spans} of  are
, and the
\emph{substring at span } of  is , with .
The \emph{subsequences} of  are given
by a \emph{subsequence map} :

A subsequence of  by map  is .  (The subsequences of  are ).  For a letter  there is exactly one maximal
subsequence consisting of repetitions of that letter, and its map is
:

Note the  superscript, which, if omitted, is assumed to be the usual
equality ().  Different  predicates can be useful for matching on
projections of .  This convention will be assumed throughout.

We can extend a function , to sequences by mapping it over each element , where .
}

\subsection{Multisets}

A \emph{multiset  of } is a partial function , or
equivalently, a functional binary relation .  The
class of multisets of  is written .  If ,
we say , , and the \emph{multiplicity of  in } is
.  Intuitively, the multiplicity is the number of times an element occurs.
The \emph{domain of } is . In some cases it is
convenient to interpret  as a total function from 
where .  A set  can be interpreted as a
multiset where each  has multiplicity .  A sequence
 can also be seen as a multiset with
 (after all, another notation of a multiset is just a
set listed without removal of duplicates, e.g. ).

\comment{
The \emph{intersection}, or \emph{product}, of multisets  and  is .  Their \emph{union}, or \emph{sum} is  defined by
 where .  The \emph{size} of a multiset  is .  A multiset  can be \emph{scaled} by a constant : .

The \emph{factorial of a multiset } is the set of unique permutations
 that are equivalent to  when considered as a
multiset.  The number of unique permutations of a multiset  is given by

since all the  ways of reordering
the  identical items  are indistinguishable.  The multiset
factorial of a sequence can be generated in the tradition of sequence
permutations, except doing nothing when two items to be swapped are equal,
instead of explicitly counting the multiplicity of the unique elements.
}

\subsection{Trees}

 is the set of \emph{(rooted, ordered, labeled, finite) trees over
  alphabet .}

 are the \emph{trees over alphabet , indexed by }---the subset of  where only leaves may be labeled by .
(.)  \emph{Leaves} are nodes with no children.

The \emph{nodes} of a tree \emph{t} are identified one-to-one with its
\emph{paths}: \emph{} ().  The path
to the root is the empty sequence  and  \emph{extended by} 
is , where  is concatenation.

For ,  is the number of children, or \emph{rank},
of the node at  in , and  is its \emph{label}. The \emph{root of } is . The
\emph{ranked label} of a node is the pair
. For , the \nth{}{th} \emph{child} of the node at  is located at
\emph{path} .  The \emph{subtree at path  of } is ,
defined by  and
.  The
\emph{children of } are , with
.

The \emph{paths to  in } are .
A \emph{frontier} is a set of paths  that are \emph{pairwise
  prefix-independent}:



A \emph{frontier of t} is a frontier .

For ,  is the
\emph{substitution of  for } in , where the subtree at path  is
replaced by . For a frontier  of , the \emph{mass substitution of 
  for the frontier  in } is written  and
is equivalent to substituting the  for the  serially in any order.


The \emph{yield of  in}  is ,
\comment{
  the concatenation (in lexicographic order\footnote{, ,  }) over paths
  to leaves  (such that ) of
  ---that is,
}
the string formed by reading out the leaves
labeled with  in left-to-right order.
The usual case (the \emph{yield of
  }) is .

We may also consider the \emph{monadic strings} in , , obtained by reading off the
labels along some path from the root down.
The paths that read off a monadic string  in  are , and the string of labels along a path is
 (so ).  Then  and
 is the sequence of \emph{subtrees of  along the monadic
  string } (in lexicographic path order):

Naturally, the path in  to the \nth{}{th} element of  is
the \nth{}{th} (in lexicographic order) .

\comment{
The \emph{-labeled-children of } are contained in the subsequence
:

}

\subsection{Regular Tree Grammars}

A \emph{weighted regular tree grammar} (\cls{wRTG})  is a quadruple
  , where  is the alphabet,  is the finite set of
  \emph{nonterminals},  is the \emph{start (or initial) nonterminal},
  and \emph{} is the
  finite set of \emph{weighted productions} ().
  We define the binary relation  (\emph{single-step derives in G})
  on , pairs of trees and \emph{derivation histories}, which are logs of (location, production used):



where  iff tree  may be derived
  from tree  by using the rule  to replace the nonterminal
  leaf  at path  with .  For a derivation history
  , the \emph{weight of } is , and call  \emph{leftmost} if .\footnote{, ,  }

  The reflexive, transitive closure of
   is written  (\emph{derives in }), and
  the restriction of  to leftmost derivation histories is
   (\emph{leftmost derives in }).

  The \emph{weight of  becoming  in } is , the sum of weights of all unique
  (leftmost) derivations transforming  to , and the \emph{weight of  in } is
  .  The \emph{weighted regular tree language produced by
    } is .

  The \emph{derivation tree grammar} for a \cls{wRTG}  is , where
  
  ( is the tree with root label , rank , and \nth{i}{th} child leaf ).  The produced trees are called \emph{derivation trees} and correspond one-to-one with tree-producing derivations in .




\comment{
  \subsection{Unordered Trees}

  Just like a multiset is a sequence where we don't care about the order of its
  elements, we can consider trees where we don't care about the order of
  children. Call  the set of \emph{(rooted, labeled, finite) unordered trees
    over alphabet }.

  The root's label is \emph{}; its rank would be
  ).  Paths are not defined for unordered trees, but, as
  with ordered trees, we are interested in the subtrees descended along paths
  labeled by a monadic string, :
  
  As for ordered trees, we let  be a multiset (instead of a sequence) with
  multiplicity for  .
\comment{
Similarly, we define .
}

  An ordered tree  can be interpreted as an unordered tree  by the recursive
  rule  that 
  (sequence interpreted as a multiset).  Then, properties related to monadic
  strings  of  should be the same multiset in the ordered  as in
  ---for example, .
}

  \subsection{Hypergraphs}

  A \emph{(directed) hypergraph } is a pair  where  is a set
  of \emph{vertices} (or \emph{nodes}) of , and  are the \emph{edges} (or
  \emph{hyperarcs}) of .  An edge
   has \emph{head
    }, \emph{tails }, and \emph{cost function }.  The cost
  function for an edge maps the costs of reaching its tails to the cost of
  reaching the head through that edge.

  In a hypergraph, ---the tails are subsets of the vertices.

\comment{For a \emph{multi-hypergraph}, ---the tails are a
  multiset of vertices.  } In an \emph{ordered multi-hypergraph},
  ---the tails are ordered sequences.

  Typically hyperarc cost functions are symmetric; if not, then the order of
  arguments is the same as the order of tails.
, or for unordered hypergraphs,  fixed by some arbitrary total order  on .
  The usual cost function
  is given by , where 
  is the \emph{length} of the edge.  A typical asymmetric cost function would
  combine tail hyperpath costs with different weights for each tail.

  We say there is a \emph{hyperpath from  to  in
  }, written , if .  A \emph{hyperpath-tree
  } is a tree labeled by edges, corresponding to a proof
  of  (with a separate proof for each multiple occurrence of a
  tail vertex - note: the usual B-hyperpath allows only a single incoming
  hyperarc/proof of each vertex - our hyperpath-trees are more like derivations
  in a context-free grammar).  The \emph{cost} of a hyperpath-tree  is
  written  and is computed bottom-up for each subtree with root label 
  using .

\comment{
  The hyperpath-trees of an ordered multi-hypergraph are ordered trees () with subtree
   giving the proof used for the \nth{i}{th} tail, while the
  hyperpath-trees of an unordered (multi-)hypergraph are unordered () trees.  For
  each node in a hyperpath-tree with edge label , there is exactly one child subtree for each
  instance of a tail , with root edge label  having the same head
  .

  There is a many-to-one cost-preserving correspondence between hyperpath-trees in an
  ordered multi-hypergraph  and a derived multi-hypergraph 
  with  (by interpreting the tails as multisets instead of sequences).  Each
  unordered hyperpath-tree  describes a set 
  of unique equivalent
  ordered hyperpath-trees in ---
  essentially (recursively) all permutations of ,
  but with the child root edge dictating which tail positions it can attach to
  ().

  Another way to look at this is that we can
  specify the ordered child index  as being the \nth{n}{th} least having
  corresponding to the tail vertex .  That is, for an ordered
  hyperarc  with ,  gives the location of a particular
  instance of a tail.

  We can compute  but need to check for identical
  subtrees in order to not count their inversion twice (this is done implicitly by
  iterating over unique items in the multiset ):
  
}
  For any derivation grammar  of \cls{wRTG} ,
  there is an equivalent ordered multi-hypergraph  with an edge 
  for each production  such that ,
  , and the usual
  cost function with .  The hyperpath-trees  are exactly
  the derivation trees for , with the cost of the hyperpath-tree equal to the 
  of the weight of the tree (obviously, the labels of the hyperpath-tree are
   and the labels of the derivation tree are , but there is an
  isomorphism between them, due to the construction of ).

  A hypergraph  may be interpreted as a multigraph  with an edge for every
  tail of each hyperarc ().  We can
  refer to \emph{simple} (or \emph{monadic}) paths corresponding to the usual
  paths in the graph.  In fact, monadic strings  of hyperarcs from a hyperpath-tree
  for  correspond to a simple path in .

  \section{Pruning Along a Hyperpath-Tree}

  If we are only interested in hyperpath-trees , we can \emph{prune
     along  to } by eliminating vertices and hyperarcs that don't
  appear in any (cheap) hyperpath-tree.  This is analogous to the problem of reducing
  a context free grammar by eliminating useless nonterminals \cite{hopcroft},
  except that we wish to also eliminate those useful only for high-cost
  hyperpath-trees.

  Since we care only for the existence of a (cheapest) path for each node, tails
  of edges may be considered as sets while addressing this problem, so that
  multiply appearing tails  in a multi-hypergraph always reuse the same
  hyperpath-tree .  We assume the cost function , where  is the cost due to the hyperpath-tree  and  is a weight given to -tails of that edge.

  Unweighted pruning consists of first eliminating vertices (and hyperarcs they
  occur in) that cannot be reached from the start, and second, eliminating from
  the remainder all those that do not lie along any hyperpath-tree to the destination.
  The first step can be performed in linear time by \algref{algo_reachfrom}.

  \begin{algorithm}
    \DontPrintSemicolon

    \caption{
      Single-source-set hypergraph reachability
    }

    \KwIn{

      A set of source nodes  in a hypergraph , nodes ,
      and hyperarcs  indexed by .  Each hyperarc
      has \hastails and \hashead.

    }

    \KwOut{

      For all ,  if ,  otherwise.
      Time complexity is  where  is the total size of the input.

    }

    \Begin{

      \lFor{}{
        \;
        \;
      }

      \For{,\text{ index of a hyperarc }}{
        \;
        \tcc{  is the number of tail nodes remaining before edge  fires.}
        \lFor{}{\;
        }
      }

      \lFor{}{\algname{REACH}(y)\;}

    }
    \BlankLine
    
    \Begin{
      \If{}{
        \;
        \For{}{
          \If{}{
            \;
            \lIf{}{\;}
          }
        }
      }
    }
    \label{algo_reachfrom}
  \end{algorithm}

  The weighted version of \algref{algo_reachfrom} establishes the
  lowest cost way of reaching each vertex from a start set (or that
  there is none).  \algref{algo_knuth}, adapted from
  \cite{knuthgrammar} (first published in \cite{poweroftree}), is an
  extension of the graph shortest path problem \cite{dijkstra} to the
  hypergraph case.  It works the same except that vertices are visited
  in increasing order of the cost of reaching them from , and so
  requires a priority queue.  Activated hyperarcs serve to potentially
  lower the cost of reaching their head, but visiting the head is
  deferred until it is certain that its minimal cost hyperpath-tree is
  known.  This is in contrast to the simple depth first approach in
  the unweighted case, where the head is visited immediately with a
  recursive function call (using the implicit program stack for
  queuing nodes).

\newcommand\sink{\omega}
\newcommand\countnonterm{{\#}}

  \begin{algorithm}
    \DontPrintSemicolon

    \caption{
      \algname{ViterbiInside}: single-source-set, multi-destination shortest hyperpath-trees.}

    \KwIn{

      A set of source nodes  with initial costs , and a hypergraph with  nodes , and  hyperarcs
       indexed by .  Each hyperarc has \hastails, \hashead, and superior cost
      function  \fnote{ is \emph{superior} iff
        
        \cite{knuthgrammar}} of variables .  The cost functions are
      implemented by constant time operations \algname{BIND}() and \algname{INF}(), which returns a lower
      bound on the cost given the variables bound so far.

      For a context-free grammar or regular tree grammar, introduce a fictitious
      sink nonterminal  to the rhs of terminal rules.  Now let the  be
      the nonterminals, and let  be .  For each \nth{i}{th} rule,
      let  be the lhs nonterminal,  be the set of rhs nonterminals
      (or  if there are none).  Finally, initialize
      \algname{INF}() to , the negative log rule
      probability of rule , and define \algname{BIND}()
      as increasing \algname{INF}() by , where
       is the number of occurrences of nonterminal  in
      rule .


    }

    \KwOut{

      For all ,  is the index of the cheapest hyperarc with
      head , giving the predecessor
      relation of the cheapest unordered hyperpath-tree from the ), and
       is minimum cost of reaching .   if there is no
      cost-improving edge to .  Time complexity is  where (
      is the total size of the input) if a Fibonacci heap is used, or
       if a binary heap is used.

    }

    \Begin{

      \For{}{
        \lIf{}{\;}
        \lElse{\;}
        \;
        \;
      }

      \;

      \lFor{}{\;}

      \For{,\text{ index of a hyperarc }}{
        \;
        \tcc{  is the number of tail nodes remaining before edge  fires.}
        \lFor{}{\;
        }
      }

      \While{}{
        \;
        \For{}{\tcc{ edge  with  as a tail}
          \If{}{
            \;
            \;
            \If{}{
              \;
              \If{}{
                \lIf{}{\;}
                \lElse{\;}
                \;
                \;
              }
            }
          }
        }
      }

    }

    \label{algo_knuth}
  \end{algorithm}


  Having eliminated parts of the hypergraph that aren't reachable from , it still remains to further remove any parts that don't contribute to reaching .  In \algref{algo_reachto}, we perform a simple depth-first traversal from heads to tails of
  hyperarcs, starting with the destination , ultimately
  saving only vertices that can help reach .

  \newcommand\hrestrict[2]{{{#1}\langle {#2} \rangle}}

  To see how this works, let the \emph{restriction} of hypergraph  to a subset of
  its vertices  be .  First, run \algref{algo_reachfrom} on
   to find , then second, run
  \algref{algo_reachto} on the resulting restriction  to
  find .  Then the
  hypergraph  has the same hyperpath-trees  as , and is the minimal such.

  The order of these steps is essential - there
  may be vertices that only help reach  through hyperarcs that are eliminated
  in \algref{algo_reachfrom}.  In the second step, we qualify each node  that is connected through  to  as
  participating in a path to  automatically, which is sound only if we can assume some
  path from , for all .  But the first step guarantees this by removing all nodes that aren't reachable from .

  \begin{algorithm}
    \DontPrintSemicolon

    \caption{
      Single-destination hypergraph reachability
    }

    \KwIn{

      A destination node  in a hypergraph , with  nodes ,
      and  hyperarcs  indexed by .  Each hyperarc
      has \hastails and \hashead.

    }

    \KwOut{

      For all ,  if there is a hyperpath-tree
       such that ,  otherwise.  Time complexity
      is  where  is the total size of the input (this is simple
      depth-first search on the projected regular graph).

    }

    \Begin{
      \lFor{}{
        \;
      }
      \algname{USE}(y)\;
    }
    \BlankLine
    
    \Begin{
      \;
      \For{}{
        \If{}{
          \;
        }
      }

    }
    \label{algo_reachto}
  \end{algorithm}

  What we are really doing is reversing a hypergraph by interpreting it as a
  monadic graph consisting of all edges formed by selecting just one tail of
  each hyperarc, and plugging in a default rule for completing the omitted
  siblings.  We can extend this strategy to the weighted case, using the
  shortest hyperpath-tree  () (from from
  \algref{algo_knuth}) for each omitted sibling .  Then we can attribute to
  each monadic arc the cost of those omitted hyperpath-trees (), in
  addition to the cost of its original hyperarc.  Then we can perform the usual
  single-source shortest graph paths computation\cite{dijkstra} on the this
  reverse monadic graph.

  Since any subtree of a shortest hyperpath-tree  is a
  shortest hyperpath-tree from  to its root-head , we can
  decompose the shortest hyperpath-tree using node  into the shortest
  \emph{inside}  plus the \emph{outside}  formed by
  reconstituting a path in the monadic graph with the default interpretation of
  omitted siblings.  The outside part is an almost-hyperpath-tree, missing only
  an inside subtree for  (an outside tree would be a hyperpath-tree
  from ).  This is the insight behind the
  inside-outside algorithm\cite{InsideOutside} for training context free string
  grammars, and also its extension to training tree transducers\cite{TTT}.

  Note that this decomposition means that the cost functions for hyperarcs must
  be separable into an independent sum over parts due to the tails and a part
  due to the arc.

  In \algref{algo_dijkstra}, we implicitly perform this reversal and
  monadification of a hypergraph and obtain for each vertex  the cheapest way
  to complete the hyperpath-tree  into  (by
  that we mean adjoining some inside hyperpath-tree  with , using
  parent  with total outside cost (leaving out the cost of ) .

  Then, the \emph{utility} of , or the cost of the
  cheapest hyperpath-tree using it, is just  and the utility of hyperarc  is .  It is then easy to select
  vertices and edges for removal based on some criteria on their utility
  relative to the cost of the cheapest hyperpath-tree , which is
  .

  \algref{algo_prune_relatively_useless} selects the minimal
  subset of the hyperarcs and vertices necessary to include the best
  hyperpath-tree  with cost  and all hyperpath-trees
  with cost no worse than .

\newcommand\holdout[3]{{\algname{COSTEXCEPT_{#1}({#2},{#3})}}}

  \begin{algorithm}
    \DontPrintSemicolon

    \caption{
      \algname{ViterbiOutside} - single-destination, shortest outside hyperpath-trees
    }


    \KwIn{

      A destination  and default (inside) costs  for
      reaching each  from  (computed with \algname{ViterbiInside}), for a
      hypergraph with  nodes , and  hyperarcs  indexed by
      .

\comment{
      Each hyperarc has \hastails, \hashead, and superior cost function
      .  The cost function is provided as an amortized constant time operation that builds up the cost of using the default cost ways to reach the tails of an edge, then taking the edge, but holding out one instance of a tail ,
      , for example, in , everything but the last term (a constant time operation) is constant with respect to v and the constant takes just O() time to compute.
}
      Each hyperarc has length (i.e. cost to use) , a
      multiset of tails , and \hashead.  The cost for
      hyperpath-tree from  using edge  and the best hyperpath-trees from  to each of its tails  with cost  is
       (where m is the number of occurrences of  in the tails), but other cost functions are possible - what is
      important is the ability to build up the cost for using an edge assuming the default for its tails, and later subtract out the contribution from the default of a single
      instance of a tails.

  }

    \KwOut{

      For all ,  is the index of the hyperarc used to reach
       from  (or 0 if none was taken) with the minimum outside cost = given by assuming
      the default cost way to was used to reach its siblings from .  Time complexity is
       where ( is the total size of the input) if a Fibonacci
      heap is used, or  if a binary heap is used.

    }
    \Begin{
      \For{}{
        \;
        \;
        \;
}
      \For{,\text{ index of a hyperarc }
        }{
        \lFor{}{\;}
      }
      \;
      \;
      \;
      \While{}{
        \;
        \For{}{
                              \tcc{ edge  with  as a head}
           \tcc{ c=total cost of }\;
\For{}{
 \tcc{  is the proposed improved outside cost for  through , removing }\;
            \If{}{
              \lIf{}{\;}
              \lElse{\;}
              \;
              \;
            }
          }
        }
      }
    }

    \label{algo_dijkstra}
  \end{algorithm}

    \newcommand\goodenough{\kappa}
  \begin{algorithm}
    \DontPrintSemicolon

    \caption{
      Prune relatively-useless vertices and hyperarcs
    }

    \KwIn{

       and , the Viterbi inside and outside costs of
      each vertex V over all hyperpath-trees from  (computed with
      \algname{ViterbiInside} and \algname{ViterbiOutside}) in a hypergraph
       with  hyperarcs  indexed by .  Each hyperarc has \hastails and \hashead.  The cost for
      hyperpath-tree from  using edge  and the best
      hyperpath-trees from  to each of its tails  with cost 
      is , where  is the
      weight on hyperarc  and  is a weight, e.g. the number of occurrences
      of  in the rhs of a grammar production.

       is a beam (cost distance from the best hyperpath-tree).

    }

    \KwOut{

      For all ,  is the cost of the best
      hyperpath-tree  such that  is used in , or
       if none exists,  iff that cost is not more worse
      than  from the best .

      Time complexity is  where  is the total size of the input.
      (total complexity including \algname{ViterbiInside} is ).

    }

    \Begin{
        \;
      \;
      \For{}{
        \;
      }
      \For{}{
        \;
      }
      \lFor{}{
        \;
      }
    }

    \label{algo_prune_relatively_useless}
  \end{algorithm}

  \bibliographystyle{fullname}
  \bibliography{tree}

\end{document}
