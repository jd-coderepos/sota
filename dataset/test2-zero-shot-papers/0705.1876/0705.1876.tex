\documentclass[letterpaper,11pt]{article}
\usepackage{fullpage,epsf,epsfig,latexsym,amsmath,amsthm,amssymb,url}

\newcommand{\Zset}{{\mathbb{Z}}}
\newcommand{\Nset}{{\mathbb{N}}}
\newcommand{\Rset}{{\mathbb{R}}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{example}[section]{Example}
\newcommand{\remove}[1]{}
\newcommand{\F}{\vspace*{\smallskipamount}}
\newcommand{\FF}{\vspace*{\medskipamount}}
\newcommand{\FFF}{\vspace*{\bigskipamount}}
\newcommand{\B}{\vspace*{-\smallskipamount}}
\newcommand{\BB}{\vspace*{-\medskipamount}}
\newcommand{\BBB}{\vspace*{-\bigskipamount}}
\newcommand{\T}{\hspace*{2em}}
\newcommand{\TT}{\hspace*{4em}}
\newcommand{\TTT}{\hspace*{6em}}
\newcommand{\TTTT}{\hspace*{8em}}
\newcommand{\TTTTT}{\hspace*{10em}}
\newcommand{\TTTTTT}{\hspace*{12em}}
\newcommand{\TTTTTTT}{\hspace*{14em}}
\newcommand{\TTTTTTTT}{\hspace*{16em}}
\newcommand{\st}[1]{{\small\tt #1}}
\newcommand{\WA}{{\it Write-All\/}}

\newcommand{\diff}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\bra}[1]{\left(#1\right)}
\newcommand{\cei}[1]{\lceil #1 \rceil}
\newcommand{\flo}[1]{\lfloor #1 \rfloor}
\renewcommand{\Pr}[1]{\Prsymbol\left[#1\right]}
\newcommand{\Exp}[1]{\Expsymbol\left[#1\right]}
\newcommand{\Var}[1]{\Varsymbol\left[#1\right]}
\newcommand{\Cov}[1]{\Covsymbol\left[#1\right]}
\newcommand{\card}[1]{\left|#1\right|}
\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\setst}[2]{{\left\{#1\;\vrule\;#2\right\}}}
\newcommand{\Prsymbol}{\mathop\mathsf{Pr}}
\newcommand{\Expsymbol}{\mathop\mathsf{Exp}}
\newcommand{\Varsymbol}{\mathop\mathsf{Var}}
\newcommand{\Covsymbol}{\mathop\mathsf{Cov}}

\renewcommand{\a}{\mbox{}}
\renewcommand{\b}{\mbox{}}
\renewcommand{\c}{\mbox{}}
\renewcommand{\d}{\mbox{}}
\newcommand{\e}{\mbox{}}
\newcommand{\f}{\mbox{}}
\newcommand{\g}{\mbox{}}
\newcommand{\h}{\mbox{}}
\renewcommand{\i}{\mbox{}}
\renewcommand{\j}{\mbox{}}
\renewcommand{\k}{\mbox{}}
\renewcommand{\l}{\mbox{}}
\newcommand{\m}{\mbox{}}
\newcommand{\n}{\mbox{}}
\renewcommand{\o}{\mbox{}}
\newcommand{\p}{\mbox{}}
\newcommand{\q}{\mbox{}}
\renewcommand{\r}{\mbox{}}
\newcommand{\s}{\mbox{}}
\renewcommand{\t}{\mbox{}}
\renewcommand{\u}{\mbox{}}
\newcommand{\w}{\mbox{}}
\newcommand{\x}{\mbox{}}
\newcommand{\y}{\mbox{}}
\newcommand{\z}{\mbox{}}

\newcommand{\fa}{\mbox{{\scriptsize }}}
\newcommand{\fb}{\mbox{{\scriptsize }}}
\newcommand{\fc}{\mbox{{\scriptsize }}}
\newcommand{\fd}{\mbox{{\scriptsize }}}
\newcommand{\fe}{\mbox{{\scriptsize }}}
\newcommand{\ff}{\mbox{{\scriptsize }}}
\newcommand{\fg}{\mbox{{\scriptsize }}}
\newcommand{\fh}{\mbox{{\scriptsize }}}
\newcommand{\fii}{\mbox{{\scriptsize }}}
\newcommand{\fj}{\mbox{{\scriptsize }}}
\newcommand{\fk}{\mbox{{\scriptsize }}}
\newcommand{\fl}{\mbox{{\scriptsize }}}
\newcommand{\fm}{\mbox{{\scriptsize }}}
\newcommand{\fn}{\mbox{{\scriptsize }}}
\newcommand{\fo}{\mbox{{\scriptsize }}}
\newcommand{\fp}{\mbox{{\scriptsize }}}
\newcommand{\fq}{\mbox{{\scriptsize }}}
\newcommand{\fr}{\mbox{{\scriptsize }}}
\newcommand{\fs}{\mbox{{\scriptsize }}}
\newcommand{\ft}{\mbox{{\scriptsize }}}
\newcommand{\fu}{\mbox{{\scriptsize }}}
\newcommand{\fv}{\mbox{{\scriptsize }}}
\newcommand{\fw}{\mbox{{\scriptsize }}}
\newcommand{\fx}{\mbox{{\scriptsize }}}
\newcommand{\fy}{\mbox{{\scriptsize }}}
\newcommand{\fz}{\mbox{{\scriptsize }}}

\begin{document}

\title{Scheduling Dags under Uncertainty\thanks{Preliminary version of this work appeared in the Proceedings of the 17th ACM Symposium on Parallelism in Algorithms and Architectures (SPAA'05). Research performed in part during a visit to the Division of Mathematics and Computer Science, Argonne National Laboratory, Argonne, IL 60439 supported by NSF grant ITR-800864, and a stay with the Department of Computer Science, University of Alabama, Tuscaloosa, AL 35487.}
\author{
    Grzegorz Malewicz\\
    \small Department of Engineering\\
    \small Google, Inc.\\
    \small Mountain View, CA 94043, USA\\
    \small malewicz@google.com\\
}
}

\maketitle

\begin{abstract}
This paper introduces a parallel scheduling problem where a directed acyclic graph modeling  tasks and their dependencies needs to be executed on  unreliable workers. Worker  executes task  correctly with probability .
The goal is to find a regimen , that dictates how workers get assigned to tasks (possibly in parallel and redundantly) throughout execution, so as to minimize the expected completion time. 
This fundamental parallel scheduling problem arises in grid computing and project management fields, and has several applications.

We show a polynomial time algorithm for the problem restricted to the case when dag width is at most a constant and the number of workers is also at most a constant. These two restrictions may appear to be too severe. However, they are fundamentally required. Specifically, we demonstrate that the problem is NP-hard with constant number of workers when dag width can grow, and is also NP-hard with constant dag width when the number of workers can grow. When both dag width and the number of workers are unconstrained, then the problem is inapproximable within factor less than , unless P=NP.
\end{abstract}

{\bf Keywords:} algorithms and theory, combinatorial optimization, grid computing, Markov chains, probabilistic failures, project management, resource constraints, scheduling of dags.

\section{Introduction}


Grid computing infrastructures have been developed over the past several years to enable execution of computations on shared distributed resources~\cite{FosterK04}. The machines, disks and network often operate at a slower pace or stop operating, due to hardware and software failures and sharing. Nevertheless, there is significant demand to perform scientific computations with complex task dependencies on grids (cf. \cite{Ann02,Ber+03,Inspiral,H+05}). Among the most important remaining challenges is to determine how to quickly execute large-scale, sophisticated computations using unreliable resources. When a task fails to get computed correctly, then the progress of execution may be delayed because dependent tasks cannot be executed pending successful execution of the task.
It is conceivable that task dependencies and resource reliabilities play a significant role in the ability to execute computations quickly. Therefore, one would like to determine relationships among these factors, and develop algorithms for quick execution of complex computations using unreliable resources.


A similar problem arises when managing projects~\cite{HL01} such as production planning or software development. Here a collection of activities and precedence constraints are given. Workers can be assigned to perform the activities. In practice, a worker assigned to an activity may fail to perform it. For example, if an activity consists of writing a piece of code and testing it, it could happen that the test fails. The manager of the project may be able to estimate the success probability of a worker assigned to an activity based on prior experience with the worker. The manager may be able to redundantly assign workers to an activity. For example, two workers may independently write a piece of code and test it; if at least one test succeeds, the activity is completed. Thus the manager faces a problem of how to assign workers to activities, possibly in parallel and redundantly, over the course of the project, so as to minimize the total time of conducting the project.






These two application areas motivate the study of the following fundamental parallel computing scheduling problem. A directed acyclic graph (dag) is given representing  {\em tasks} and their dependencies. There are  {\em workers}. At any given unit of time workers are assigned in some way to the tasks that are ``eligible'' based on precedence constraints and tasks executed thus far (any worker is assigned to at most one task at a time; more than one task may get assigned; more than one worker can be assigned to a task; workers can idle). The workers then {\em attempt} to execute the assigned tasks. The attempt of worker  to execute task  {\em succeeds} with probability . In the next unit of time workers are again assigned to tasks. The execution proceeds in this manner until the  tasks have been executed. The goal is to determine a regimen , that dictates how workers get assigned to tasks throughout execution, that minimizes the expected completion time.




\F
\subsection{Contributions}
In this paper we propose and investigate a parallel scheduling problem of executing dags using unreliable workers. Our specific contributions are as follows:
\begin{itemize}
\item[(i)] We introduce a new combinatorial optimization problem: given a dag  with  tasks and  workers such that  is the probability that worker  executes task  correctly, find a regimen  that minimizes the expected completion time.
\end{itemize}

We show that the ability to solve this problem in polynomial time depends in a crucial way on two natural parameters of the problem: the number of workers and the {\em width} of the dag . The latter parameter denotes the maximum cardinality of an {\em antichain} (all technical terms are defined in Section~\ref{s.def}).

\begin{itemize}
\item[(ii)] We develop a polynomial time algorithm that finds an optimal regimen for a restricted version of the problem. Specifically, we assume that the width of the dag  is at most a constant, {\em and also} that the number of workers is at most a constant. Note that our algorithm allows the dag to have complex structure and dag size to grow, however the dag must be ``narrow''. The algorithm uses a dynamic programming approach. Given dag , we construct a directed graph  called {\em admissible evolution of execution} that contains all possible sets of tasks that a regimen can have executed at a point of time, and how one set could result form another within one unit of time. This graph  turns out to be a dag. We then formulate a recurrence to define a regimen for a node of  based on definitions for the children of the node. 

\item[(iii)] We sharply contrast our algorithmic results with complexity lower bounds, by demonstrating that our restrictions are fundamentally necessary. Specifically, we show that the optimization problem is NP-hard when dag width is constant while the number of workers can grow, and is also NP-hard when the number of workers is constant while dag width can grow. Moreover, if both dag width and the number of workers are unconstrained, then we show that the problem cannot be approximated with a factor less than , unless P=NP.
\end{itemize}


Our reductions demonstrate that the complexity of the problem is quite steep. 
First, the problem is trivial when the dag has just one task. Simply then an optimal regimen assigns all workers to that task. However, the problem becomes NP-hard when dag has just two independent tasks! (Arguably this is the ``second simplest'' dag.) 
Second, the problem is easy when there is just one worker. Simply then an optimal regimen follows any topological sort and assigns the (only) worker to the task at hand. However, the problem becomes NP-hard when there are just two workers! 

\F\F
\subsection{Related work}
There are several studies that deal with scheduling under constrained resources~\cite{OU95,NR01}. Many such problems are NP-hard~\cite{CK04}, and the studies typically focus on heuristic approaches. Our work differs from the studies because we also consider resource failures.
More closely related are results~\cite{MT97} on scheduling where each task can be executed in one of a few ways. Each way has certain resource requirements, duration, and failure probability. After execution failure, the task is reexecuted fault-free. The goal is to minimize the expected completion time. Several heuristics are proposed. A similar model is studied~\cite{TMY95} with the goal of maximizing the probability of successful completion using heuristics.

In project scheduling under uncertainty~\cite{HL05,FAP98a,FAP98b} each task has a duration that is a random variable and a requirement on the amount of different resources needed to perform the task. There is a fixed amount of each resource available. The goal is to determine how to assign resources to tasks over the execution of the project to minimize the expected completion time. Our problem is similar because workers can be treated as a resource. However, our problem is different because we allow multiple workers to be assigned to a task, which modifies the distribution of task duration.
A model is studied~\cite{TN03} where the execution time of each task in a dag is a random variable with a certain distribution that depends on the amount of resources assigned to the task. Execution may fail if it takes longer than a threshold. The goal is to maximize the probability of completion. Several heuristics have been proposed.

One of the goals of stochastic scheduling is to minimize the expected completion time when task durations are random variables and tasks need to be scheduled on parallel machines. Such problem was studied for independent tasks~\cite{KRT00,GI99} and for dependent tasks~\cite{SU01}, however, under a different setting, because we assume that two or more machines may be assigned to the same task, which may modify the probability distribution of task duration. 
Other related problems are the Network Reliability Problem and the Network Survivability Problem~\cite{GJ79} that model failures probabilistically, but have different optimization goals.


\remove{
Several interesting results on robust scheduling are related to our work (cf.~\cite{AMSK04,STW98,KY96}). Here the goal is to derive schedules whose performance according a given metric is controlled when the input differs from a specific input in a controlled manner.
}


Computing tasks over the Internet poses distinct challenges.
It is known~\cite{GaoM04} which dependent tasks should be executed by a reliable server and which by workers whose unreliability is modeled probabilistically, so as to maximize the expected number of correct tasks, under a constraint on completion time.
A similar probabilistic model is studied~\cite{Sar02} for independent tasks.
Also related is the problem of scheduling tasks so as to render tasks eligible for allocation to workers (hence for execution) at the maximum possible rate~\cite{Rosenberg04,RosenbergY04,MRY05,MalewiczR04,MFRW07,CMR07}.

\remove{
Pebble Games have been used to model scheduling problems on dags~\cite{PatersonH70,Cook74,HopcroftPV77,HongK81,RosenbergS83}. In this model we are given a supply of pebbles and certain rules that restrict how pebbles can be placed on the dag's nodes. The goal is to determine how to place the pebbles on the nodes (i.e., how to ``play the game'') to meet a certain performance goal. 
}

There are several systems in grid computing and project management fields that are related to our work. Condor~\cite{TTL05}, for example, executes computations with complex task dependencies. The clients to which tasks are sent are commonly unreliable. Condor assigns any task to one computer at a time (no redundancy), and uses a
``FIFO'' topological sort to sequence task submissions. This may sometimes lead to an ineffective use of computing resources.
One example of a project management system is the Microsoft Project 2003~\cite{MsftProj03}. The system can estimate project duration using a PERT algorithm based on a probabilistic model of duration of a task, but does not take into account resource constraints.

In a companion to this paper the author explores~\cite{Mal05b} implementation details and experiments with the algorithm. Specifically, a range of theoretical and practical approaches are proposed to craft an efficient implementation of the algorithm. The benefits of the approaches and scalability of the implementation are evaluated experimentally.

Approximation algorithms for several cases of the problem studied in this paper were recently given~\cite{LR07,L07}. The case of independent tasks was shown to admit an -approximation. Richer dependency structures also admit approximations. For disjoint chains, an
-approximation was given. A collection of directed out- or in-trees admits an -approximation, while a directed forest admits an -approximation.

\subsection{Paper organization}
The remainder of paper is structured as follows. In Section~\ref{s.def}, we define a model of executing dags where workers can fail with certain probabilities, and formulate an optimization problem of minimizing the expected completion time. In Section~\ref{s.alg}, we give a polynomial time algorithm for the problem with dags that have constant width and where the number of workers is constant. Finally, in Section~\ref{s.complexity}, we explain why restricting dag width and the number of workers is fundamentally required.

\section{Model and background}

\label{s.def}

A {\it directed graph}  is given by a set of {\it nodes} 
and a set of {\it arcs} (or, {\it directed edges}) , each
having the form , where .  A {\it
path} in  is a sequence of arcs that share adjacent endpoints, as
in the following path from node  to node : .  A {\it dag} ({\it directed
acyclic graph})  is a directed graph that has no cycles; i.e., in
a dag, no path of the preceding form has .
Given an arc ,  is a {\em parent} of
, and  is a {\em child} of  in .  Each parentless node of
 is a {\em source (node)}, and each childless node is a {\em sink
(node)}; all other nodes are {\em internal}.

Given a dag, an {\em antichain} is a set of its nodes such that no two are ``comparable'' i.e., for any two distinct nodes  and  from the set, there is no path from  to  nor from  to . The largest cardinality of an antichain is called {\em width} of the dag.
A {\em chain} is a path. A set of chains is said to {\em cover} the dag if every node of the dag is a node in at least one of the chains (chains may ``overlap''). A Dilworth's Theorem~\cite{Dil50} states that dag width is equal to the minimum number of chains that cover the dag.

A computation is modeled by a dag. Then the nodes are called {\em tasks} and for concreteness we assume that . We denote a set  by . Arcs specify dependencies among tasks: given an arc ,  cannot be executed until  has been. A set of tasks {\em satisfies precedence constraints} if, for every task in the set, every parents of the task is also in the set. Given such set , we denote by  the set of tasks not in  every of whose parent is in ; tasks in this set are called {\em eligible} when tasks  have been executed. (So any source not in  is eligible.)


The execution of tasks is modeled by the following game.
There are  {\em workers} identified with elements of . Let  be a set of tasks that satisfies precedence constraints. The game starts with , and proceeds in {\em rounds}. During a round, workers are assigned to tasks in  according to a regimen . The regimen specifies an assignment  that maps each worker to an element of the set  i.e., either to a task that is eligible in this round, or to a distinguished element . Note that the assignment is determined by the set of tasks . The assignment enables directing multiple workers to the same task, or to different tasks; workers can also idle. 
Then each worker that was assigned to a task {\em attempts} to execute the task.
The attempt of worker  assigned to task  {\em succeeds} with probability  independently of any other attempts. We assume that there is at least one worker that has non-zero probability of success, for any given task. A task is {\em executed} in this round if, and only if, at least one worker assigned to the task has succeeded. Every executed task is added to , and the game proceeds to the next round. It could be the case that every attempt has failed; then the set  remains unchanged, and in the next round worker assignment remains unchanged, too.
Formally, a regimen  is a function , such that for any subset  of tasks that satisfies precedence constraints, the value  is a function from  to the set .
The game proceeds until a round when every sink of  is in . We say that the game {\em ends} in such round.

The quality of the game is determined by how quickly the game ends. Specifically, the number of rounds of the game, beyond the first round, until the round when the game ends is called {\em time to completion} of regimen  starting with tasks  already executed. This time is a random variable. When  is empty, we call the time simply {\em completion time}.
Our goal is to find a regimen  that minimizes the expected completion time. We call this goal the Recomputation and Overbooking allowed Probabilistic dAg Scheduling Problem (ROPAS).

\FF
\noindent
{\bf ROPAS}\\
{\it Instance:} A dag  describing dependencies among  tasks,  workers such that worker  succeeds in executing task  with probability , and that for any task  there is worker  with .\\
{\it Objective:} Find a regimen  that minimizes the expected completion time.
\FF

We observe that the optimization problem yields a finite expectation.
Let  be a subset of tasks that satisfies precedence constraints. Denote by  the minimum expected time to completion across regimens that start with tasks  already executed. 
The subsequent lemma states that  is finite. 
The proof, while simple, is presented here in detail to help the reader gain familiarity with our notation. 

\begin{lemma}
\label{l.finite}
For any set  of tasks that satisfies precedence constraints,  is finite.
\end{lemma}

\remove{**********************
\begin{proof}[sketch]
We take a topological sort, and assign all workers to successive unexecuted tasks. This yields a finite expectation, so  must be finite, too.
\end{proof}
**********************}

\begin{proof}
We define a regimen that has finite expectation; thus minimum expectation must be finite, too. We take a topological sort  of the subdag of  induced by tasks not in . Note that it is possible to execute tasks in the order of the sort because once tasks in  and  have been executed, task  is eligible. Our regimen will follow this order, each time assigning every worker to the task at hand. The probability that every worker fails to execute task  is , which by assumption is strictly smaller than . Thus the expected time to execute the task is , because execution time follows geometric distribution. We can use linearity of expectation to conclude that the expected time to completion for the regimen is just the sum of expectations for each individual task in the sort. Thus  is at most , as desired. 
\end{proof}






\section{Scheduling algorithm for a restricted problem}
\label{s.alg}

This section presents a polynomial time algorithm that finds an optimal regimen for a restricted version of the ROPAS Problem. Specifically, we make two assumptions: (1) the dag  has at most a constant width, and (2) the number of workers is at most a constant. These two restrictions may appear to be quite severe, and perhaps too restrictive! However, they are fundamentally necessary, as we shall see in Section~\ref{s.complexity}.


We construct a directed graph that models how computation can evolve. The graph  called {\em admissible evolution of execution} for  (an example is in Figure~\ref{f.aec}) is constructed inductively. Each node of  will be a subset of nodes of . We begin with a set . For any node  that does not contain every sink of , we calculate the set of eligible tasks  in . We then take the non-empty subsets , add to  a node , if it is not there already, and add to  an arc , if it is not there already. Since  is finite, the inductive process clearly defines a unique directed graph . The structure of this graph is explained in the subsequent lemma.


\begin{lemma}
\label{l.dag}
Let  be the admissible evolution of execution for a dag . Then  is dag. Its nodes are exactly the sets of tasks that satisfy precedence constraints. It has a single source  and a single sink .
\end{lemma}

\begin{proof}
We verify the assertions in turn.
The graph  cannot have any cycle, because any arc points from a node  to a node , but  has larger cardinality than the set .

Nodes of  are exactly the sets of tasks that satisfy precedence constraints. Indeed, if  satisfies precedence constraints, then clearly so does its union with any subset of . Thus any node of  satisfies precedence constraints. Now pick any subset  of tasks that satisfies precedence constraints. Let  be a topological sort of the subdag of  induced by . Clearly,  belongs to the set of tasks eligible when tasks  have been executed, for any . So if  is a node of , so is . Since  is a node of ,  must also be. A corollary to this is that  is a node of .

We add a node  to  only if there is an arc leading to  from some other node. So  cannot be a source. However,  is a source because no arc leads to a set with the same number or fewer elements.

Pick any node  of  and suppose that it does not contain the sinks of . By looking at a topological sort of  we notice that there is a task of  not in  such that every parent in  of the task is in . Thus  is not empty, and so  has a child in . Pick any node  of  that contains every sink of . Since  satisfies precedence constraints, it contains every task, and so . But  is empty, so  has no children in .
\end{proof}


Given a regimen , we can convert  into a Markov chain that models how execution can evolve for this particular regimen. Specifically, for any node  of ,  defines the assignment of workers to tasks from , thus yielding transition probabilities form  back to  and to the children of  in . The expected time to completion is then just the expected hitting time of the sink of . We can use Markov chain theory to relate expected times to completion for the nodes of  as follows.

\begin{theorem}[\cite{Nor97}]
\label{t.recursive}
Consider a regimen  and a set  of tasks that satisfies precedence constraints and does not contain all sinks of .
Let  be the distinct subsets of , and .
Let  be the probability that  is exactly the set of tasks executed by workers in the assignment . Let . Then

where  is the expected time to completion for regimen  starting with tasks  already executed, and by convention  and .
\end{theorem}

Our goal, however, is not to compute the expected completion time for a given regimen, but rather find a regimen that minimizes the expectation. For this purpose, we give a dynamic programming algorithm called OPT that defines a regimen called . Since  has no cycles, we can hope to apply the recurrence of Theorem~\ref{t.recursive} starting from the sink and backtracking towards the source. Specifically, we initialize the regimen arbitrarily. Then we take a topological sort  of  and process it in the reverse order of the sort. See Figure~\ref{f.pseudocode} for a pseudocode. When we process a node  of , we define two values: a number  and an assignment .
We begin by setting  to  and  so that each worker is assigned to . 
Now let , and let us discuss how  and  are defined. Let  be the distinct subsets of , such that . We consider the distinct  assignments of the  workers to the tasks of , but not to . For any assignment, we calculate the probability  that  is exactly the set of tasks executed by workers in the assignment. If , then we compute the weighted sum . We pick an assignment that minimizes the sum. We set  to the minimum, and  to the assignment that achieves the minimum. Then we move back in the topological sort to process another node, by decreasing . After the entire sort has been processed, the regimen  has been determined.

\begin{figure}[!t]
\footnotesize 

Data structure:  is a dictionary that maps nodes of  to distinct floating point variables\\

\begin{tabular}{ll}
  \begin{tabular}{l}
 \\
{\tt01}~ let  be a topological sort of \\
{\tt02}~ \\
{\tt03}~ for  downto  do \\
{\tt04}~\T \\
{\tt05}~\T for all assignments  of workers to \\
{\tt06}~\TT let  be the assigned tasks\\
{\tt07}~\TT \\
  \end{tabular}
&
  \begin{tabular}{l}
{\tt08}~\TT for all nonempty subsets \\
{\tt09}~\TTT let AD \\
{\tt10}~\TTT \\
{\tt11}~\TT let  \\
{\tt12}~\TT if \\
{\tt13}~\TTT \\
{\tt14}~\TTT \\
{\tt15}~\T \\
  \end{tabular}
\end{tabular}

\caption{An algorithm for constructing an optimal regimen , for a dag  describing dependencies among  tasks, and  workers such that worker  executes task  successfully with probability .}
\label{f.pseudocode}
\end{figure}


Our goal is twofold. First, we show that the regimen  indeed minimizes the expected completion time. We do this by considering an extended algorithm OPT where workers can idle. This freedom matches that defined in ROPAS and we can use the recurrence to demonstrate that OPT solves ROPAS. We then argue that idling is not needed, because an optimum can be found among regimens where every worker always gets assigned to a task. We, hence, prove that  solves ROPSA, too. We conclude by showing that OPT runs in polynomial time when dag width and the number of workers are at most a constant.


It is convenient to consider an extended version OPT of the algorithm where workers are allowed to idle. Specifically, when processing , we consider the  distinct assignments of the  workers to the tasks of  or to . The regimen resulting from processing the topological sort is denoted by . The following proposition explains why the extended algorithm finds best regimen. (Note a ``strong'' sequence of quantifiers---a {\em single} regimen that is optimal for all  of  when competing with any regimen that start with .)

\begin{proposition}
\label{p.dp}
When the algorithm OPT halts, thus computing a regimen , for any node  of , the expected time to completion for the regimen starting with tasks  already executed is equal to the minimum expected time to completion  that any regimen can achieve starting with tasks  already executed.
\end{proposition}

\remove{**********************
\begin{proof}[sketch]
We show that as we process the topological sort, we maintain an invariant that for all sets  subsequent to  in the sort, regimen  achieves  when starting with . When processing a set , an optimal regimen starting with  will have, by Theorem~\ref{t.recursive}, expectation expressed as expectations for sets subsequent in the sort. By the invariant they must be at least the corresponding expectations for . Hence  can be selected optimally.
\end{proof}
**********************}

\begin{proof}
Let  be the topological sort of  which was used by the algorithm OPT. We argue that the following invariant parameterized by  holds during the reverse processing of the sort:
\begin{quote}
For all  such that ,  and  is equal to the expected time to completion of  that starts with tasks  already executed.
\end{quote}

This invariant is clearly true for . Indeed, by Lemma~\ref{l.dag},  has just one sink which is equal to , and so . If every task is already executed, the minimum expected time to completion is zero. The algorithm, thus, correctly assigns zero to . The expectation of any regimen that starts with every task already executed is zero, and so the value of  is satisfactory.

Now pick any . We shall see that after OPT has processed , the invariant is true for  decreased by one. Let . Since  is not a sink of , it has at least one child. Let  be the children.

We first argue that the value assigned to  is at most the minimum expected time to completion .
Pick a regimen  that achieves the minimum when starting with tasks  already executed. Some workers may get assigned to  in . Lemma~\ref{l.finite} ensures that  is finite. We can use Theorem~\ref{t.recursive} to express the expectation of the regimen as a weighted sum 

of expected times  to completion for  starting with tasks from the sets  already executed. By the invariant , and so the expectation  is at least . The dynamic program considers every assignment as a candidate for , and the assignment  in particular. For this assignment the algorithm calculates the weighted sum . Hence the weighted sum is at most . The algorithm selects an assignment that minimizes the weighted sum, so the value of  is at most , as desired.

After values of  and  have been selected, the value of  is clearly equal to the expectation of  starting with  already executed. Indeed, for any assignment considered by the algorithm, the weighted sum is, by Theorem~\ref{t.recursive}, equal to the expected time to completion of  that starts with tasks  already executed and uses this assignment in place of .

Since  has expectation  and  is at most , the expected time to completion for  starting with  already executed is actually equal to . Hence the invariant holds when  gets decreased by one. This completes the proof.
\end{proof}

We will use this result to show that it is not necessary for workers to idle. We begin by observing that, roughly speaking, ``more done, less time remaining to complete'', as detailed in the subsequent lemma.

\begin{lemma}
\label{l.monotone}
For any subsets  of tasks that satisfy precedence constraints, .
\end{lemma}

\begin{proof}
It is sufficient to prove the lemma with an additional restriction on . Specifically, the proof considers any  as stated, any , and . The proof is by the reverse induction on the cardinality of . The theorem is obvious when , because then .


For the inductive step, take  of cardinality at most . Consider the regimen . By Proposition~\ref{p.dp} the expected time to completion when  starts with tasks  already executed is , for any  that satisfies precedence constraints. Let  be the tasks to which  assigns workers. Since  is finite, . Let  be the probability that at least one worker assigned to task  succeeds. 
Let  be the probability that exactly the set of tasks indexed by  gets executed in  among tasks indexed by . We can use Theorem~\ref{t.recursive} to express the expected time to completion for  as

with .

We begin with a few special cases that are simpler to analyze and that simplify the follow-up analysis. 
Suppose first that  does not assign any worker to . Then each assigned task is still eligible when tasks  have been executed. Hence we can define a new regimen  equal to  except that . But then the expected time to completion for  starting with tasks  already executed is

Clearly, by the inductive assumption, . So . Since , we have that , as desired. 
Hence in the remainder we can assume that .
Suppose now that . Then  is equal to  plus  (because  cannot be ), and so clearly the latter is less than . A similar conclusion follows when  but . 

After having tackled the simpler special cases, we proceed to the final, most interesting, case when , , and at least one of  is strictly greater than . 
The Equation~(\ref{eq.B_X}) for  contains probabilities of events, and it is convenient to partition the events into three groups:
\begin{itemize}
\item[(i)] only task  gets executed, which occurs with probability ,
\item[(ii)] precisely the tasks indexed by a non-empty set  get executed and also task , which occurs with probability ,
\item[(iii)] precisely the tasks indexed by a non-empty set  get executed but not task , which occurs with probability .
\end{itemize}


The Equation~(\ref{eq.B_X}) for  has a summation where a probability from the second group is multiplied by , while a probability from the third group by . By the inductive assumption, , since  is not empty. Hence the latter can be replaced by the former, and the resulting expression will not increase. But then we can pairwise combine each summand of group (ii) with the corresponding summand of group (iii), and obtain 

where  is the probability that exactly the set of tasks indexed by  gets executed among tasks from . Let us denote the big summation by . It is now enough to show that 

In order to verify this inequality, we transform it to an equivalent form by multiplying both sides by the denominator and grouping for 

because .
We notice that the left hand side is the expected time to completion of a regimen  that starts with tasks  already executed. This regimen  is equal to  except that when tasks  need to be executed, the regimen assigns workers to tasks the way  does, omitting these workers assigned to  (such workers do not get assigned then at all). Since  is the minimum expectation, it must indeed be smaller or equal to the expectation of that regimen .

This completes the inductive step and the proof.
\end{proof}

We use the lemma to argue that when processing , it is sufficient to consider assignments  that map every worker to an eligible task, i.e., we do not need to assign any worker to .


\begin{proposition}
For any set  of tasks that satisfies precedence constraints and does not contain every sink of , there is a regimen  such that  assigns every worker to a task of  and the expected time to completion of  that starts with tasks  already executed is  (i.e., minimum).
\end{proposition}


\begin{proof}
We shall construct the regimen  using the regimen  of Proposition~\ref{p.dp}. We will show that the expectation of  is at most that of , and since the latter is minimum, the expectations will have to be equal. 

Let us first make a few observations about . Let  be the tasks to which  assigns workers. We know that . If every worker has been assigned by  to a task, then the claim follows. We, therefore, assume that there is at least one worker not assigned by  to any task. 

We construct a regimen . Let  be the set of workers not assigned by  to any task. We define  to be equal to  except that the assignment  also assigns every worker from  to task . Let  be the probability that at least one worker from  succeeds when assigned to , . We shall argue that the expected time to completion for  starting with tasks  already executed, , is at most .

Let us compare equations for  and . As earlier, let  be the probability that exactly the tasks indexed by  get executed. We can express  using Theorem~\ref{t.recursive} as

and we know that .
Similarly, we can express . We notice that for any , , the event that exactly the tasks in  are executed in  can be decomposed into two mutually exclusive ``subevents'': at least one worker from  succeeds, and every worker from  fails. Hence

even if  for some .

We make two simplifying assumptions. Notice that if , then workers of  always fail, and so  is then obviously equal to . Notice also that if  then there must be a task that is certainly executed. We can then reassign workers of  to that task instead of to , and the resulting  will also be equal to . Therefore, we can assume without loss of generality that  and .

We will modify the expression for  to make it look more like . By Lemma~\ref{l.monotone}, we know that . Hence we can replace the former with the latter in the expression for , pairwise combine terms, and obtain a bound

that begins to resemble the expression for . 

We shall conclude that the bound in Equation~(\ref{eq.T_X}) is at most , which will mean that , as desired, because then of course . Let  denote the summation in the enumerator. We restate our goal as that of showing that

But this inequality can be equivalently expressed as

because . However, by Lemma~\ref{l.monotone},  is indeed at most , and thus the proof is completed.
\end{proof}

\begin{corollary}
\label{dp.correctness}
The algorithm  finds a regimen  that minimizes the expected completion time.
\end{corollary}


\begin{figure*}[ht!]
\centerline{\epsfig{file=aec.eps,width=6.45in}}
\caption{Depicted is the dag , called admissible evolution of execution, constructed for the given dag . The dashed boxes and dashed arrows represent nodes and arcs of . Depicted are also optimal regimens for the case of two workers, where each has the same probability  of executing successfully any given task. Each box contains: a subset of executed tasks of  (black), and tasks that are eligible then (green); the minimum expected time to completion (upper left hand corner); and how the two workers should be assigned to eligible tasks so as to yield the expectation (same-color ``'' signs)---every assignment that yields this expectation is shown, except for symmetric assignments where workers could be swapped. Note that in the first round the two workers must be assigned to distinct tasks, if not then the expected completion time is not minimized.
\label{f.aec}}
\end{figure*}


We now tackle the second subgoal of showing that the algorithm runs in polynomial time for dags of at most a constant width and when the number of workers is at most a constant.
Let  be the width of . By Dilworth's Theorem, the dag  can be covered by  chains. If any task of the chain is executed, so must be every preceding task in the chain. Each chain can have length at most . Hence, there are at most  distinct subsets of tasks that satisfy precedence constraints. 
When the algorithm processes a node of , it considers assignments of workers to eligible tasks. Any worker can, therefore, be assigned in at most  ways, and so there are at most  assignments. We notice that for a given assignment, we actually only need to evaluate probabilities  for at most  of the sets , because the workers can get assigned to at most  different tasks, and so probabilities associated with sets that are not subsets of these tasks must be zero, and so can be omitted from the weighted sum. This yields the main result of this section.



\begin{theorem}
\label{dp.final}
The algorithm OPT solves the ROPAS Problem in polynomial time when dag width is bounded by a constant and the number of workers is also bounded by a constant.
\end{theorem}

An example of an application of the algorithm to a dag is given in Figure~\ref{f.aec}. 




\section{Complexity of scheduling}
\label{s.complexity}

This section shows fundamental reasons why the algorithm presented in the previous section is so restricted. Recall that the algorithm restricts both the number of workers {\em and} dag width to at most a constant. It turns out that ROPAS is NP-hard if the number of workers can grow while dag width is at most a constant, {\em or} if dag width can grow while the number of workers is at most a constant. Therefore, a polynomial time algorithm for the problem must restrict both dag width {\em and} the number of workers, unless . We also show that if we allow the number of workers to grow and at the same time dag width to grow, then the problem is inapproximable within factor less than , unless P=NP.

Our reductions demonstrate that the complexity of the ROPAS Problem is quite steep. 
First, the problem is trivial when the dag has just one task. Simply then an optimal regimen assigns every worker to that task. However, the problem becomes NP-hard when dag has just two independent tasks! (Arguably this is the ``second simplest'' dag.) Intuitively, the hardness results from the difficulty to perfectly load balance unreliable workers across eligible tasks.
Second, the problem is easy when there is just one worker. Simply then an optimal regimen follows any topological sort and assigns the (only) worker to the task at hand. However, the problem becomes NP-hard when there are just two workers! Intuitively, here hardness is a consequence of possible complex task dependencies which make it difficult to determine how to pick tasks for execution so that sufficiently many tasks become eligible thus preventing workers from compulsory idling.


\subsection{Scheduling narrow dags with many workers is NP-hard}
\label{s.narrow_many}

In this section we show that ROPAS restricted to the dag with two independent tasks, but where the number of workers can grow, is NP-hard. For this purpose we introduce two auxiliary problems and determine their complexities. The first of them is the Multiplicative Partition Problem.

\FF
\noindent
{\bf Multiplicative Partition (MP)}\\
{\it Instance:} Number , integer sizes .\\
{\it Question:} Is there a set  such that 
~?
\FF

It is tempting to try to show NP-completeness of MP by a reduction from the well-known Partition Problem. Here we could hope to use the fact that 

if, and only if, 
. Unfortunately, an  takes space exponential with respect to the space taken by . The issue of space explosion can be avoided by carrying out a more subtle reduction from the Exact Cover by 3-Sets (X3C) Problem that uses certain 
fundamental
facts from Number Theory.


\begin{lemma}
The MP Problem is NP-complete.
\end{lemma}

\begin{proof}
We will show a reduction from the Exact Cover by 3-Sets Problem to the Multiplicative Partition Problem.

Pick any instance of X3C---a collection  of -element subsets of the set , . Recall that the instance is positive if, and only if, there is a subcollection of  such that every element of  occurs in exactly one subset of the subcollection. We can assume that  and that the union of every subset of  is , as otherwise the instance of X3C is definitely negative.
We build an instance of MP as follows. We begin by enumerating the first consecutive primes . By the Prime Number Theorem (see e.g., \cite{IR90}) the prime  has value . Therefore, we can enumerate the primes in time  using the Eratosthenes sieve; this time is polynomial with respect to the size of the instance of X3C. 
The instance of the MP Problem will have  sizes. The first  are defined as products of primes indexed by the elements of subsets i.e., . Note that 's are fairly small, so that each  is . 
We add two ``dummy'' sizes. Let  be the product of sizes  through , and  be the product of the first  primes; each is , so sufficiently small. Note that  is an integer, because . We define  and . Therefore, the instance of the MP Problem can be represented in time and space polynomial with respect to , as desired.

Suppose that the instance of X3C is positive, and let  be the indices that define the subcollection. But then  is the product of all primes from  to . So then  is equal to the product of the 's divided by the product of these primes. Therefore,

and so the instance of MP is positive.


Suppose that the instance of MP is positive, and let  be a subset such that . Note that there are only two sizes,  and , that have the prime  as a factor. But two natural numbers are equal if, and only if, they have the same factorization. Thus in order for the products to be equal, either  or  is in , but not both. We can assume, without loss of generality, that  is in .
Let , and  be the elements not in  and other than . But then 

which can be equivalently expressed as

Of course,  and  partition , so . Thus
, and since the numbers are positive, . Therefore, there is a selection of the 's whose product contains each prime from  to  exactly once. This set  defines a subcollection of  such that every element of  is contained in exactly one subset of the subcollection. So the instance of X3C is positive.
\end{proof}



The MP Problem is used to demonstrate NP-hardness of the second auxiliary problem called Partition with Minimum Sum of Products.

\FF
\noindent
{\bf Partition with Minimum Sum of Products (PMSP)}\\
{\it Instance:} Number , rational numbers  .\\
{\it Objective:} Find a set  that minimizes
 
\FF

\begin{lemma}
The PMSP Problem is NP-hard.
\end{lemma}

\remove{**********************
\begin{proof}[Proof sketch.]
The proof is based on the fact that for any , the function  defined for  is minimized exactly when . We avoid using irrational numbers by selecting the  appropriately.
\end{proof}
**********************}

\begin{proof}
We give a polynomial time Turing reduction of MP to PMSP. Specifically, we show how to find an answer to a given instance of MP by inspecting the minimum value for an appropriately constructed instance of PMSP. The proof is based on the fact that for any , the function  defined for  is minimized exactly when . The difficulty is to ensure that we compute using rational numbers only.

Pick any instance of the MP Problem and let  be the positive integer sizes, each at least . We define an instance of the PMSP Problem by taking , where . Then , as desired. 
We shall see that we can decide exactly when the instance of MP is positive, just by checking if the minimum for the instance of PMSP is equal to the value .

Let us see when the product  achieves that value. Let . Then

with equality only when . The crucial observation is that  is just , which is a rational number. Thus we can invoke an oracle that solves PMSP on the instance that we have constructed, then inspect the minimum returned by the oracle, and determine whether or not there exists  such that . But the equation can be equivalently written as
, which is equivalent to . This in turn is equivalent to . But this is equivalent to 
. So 
the instance of MP is positive if, and only if, the minimum for the instance of PMSP is equal to 
.
\end{proof}

We have prepared a toolset, and now we are ready to show the main hardness result of this subsection.

\begin{theorem}
The ROPAS Problem restricted to the dag with two independent tasks (where the number of workers may grow) is NP-hard.
\end{theorem}

\begin{proof}
We give a polynomial time Turing reduction of PMSP to ROPAS. Pick any , and let us consider a dag with just two isolated nodes, call them left task and right task. There are  workers. We define the probability of success of worker ,  and , to be , and denote it simply by . Pick a regimen  that minimizes the expected completion time. Let  be the set of workers assigned by  to the left task i.e., assigned when both tasks are eligible. We shall argue that the expected completion time is minimized if, and only if,  is minimized. Therefore, a best regimen can be transformed to a solution to the instance of PMSP.

In order to show the equivalence, we make a sequence of observations about the assignments that the regimen must make. Let  be the workers assigned by  to the right task. Hence  and  are disjoint and included in . Let  be the probability that at least one left worker succeeds, and  that at least one right succeeds. We can use Theorem~\ref{t.recursive} to calculate the expected completion time  

where  is the expected time to completion by the regimen starting with the left task already executed, and  starting with the right task already executed. 

We can simplify this expression by observing that  and  are equal. Indeed, treating sets  and  as constants, we notice that  is minimized when  and  are minimized. Let  be the set of workers assigned to the left task in  i.e., when the right task has been executed and the left one is the only eligible task. Then the expected time to completion   is . Since , this expectation is clearly minimized if, and only if, . We can apply the same argument to conclude that the regimen assigns every worker to the right task when the task is the only one remaining to be executed. Therefore, . Let us denote this expectation by . Observe that . Hence 


We notice that  assigns every worker to a task.
 In order to show this, we demonstrate that the expectation decreases as  or  increase. We notice that the formula is symmetric with respect to  and , so we only calculate its partial derivative with respect to 

This derivative is strictly negative for any . So the expectation is minimized when  and  are maximized. This is equivalent to the condition that every worker must be assigned; in other words, the sets  and  partition the set . 

Let us summarize our observations so far: the regimen initially assigns every worker to a task, and when one task remains to be executed, the regimen assigns every worker to the task.

With these observations, we turn back to determining under what circumstances  is minimized. Since  and  partition , then  is just the probability that at least one of the  workers succeeds, the value of which is independent of how workers are assigned to left and right task. Thus the expectation is minimized if, and only if,  is maximized across partitions  and  of , since  is now a constant. But

and since  and  is a partition, the expression in the third big parenthesis does not depend on the choice of  and . So the expression is maximized, for a partition  and  that minimizes


We summarize the observations that we have made so far. A regimen minimizes expectation if, and only if, its set  minimizes  and the set . Thus the theorem is proven.
\end{proof}




\subsection{Scheduling wide dags with few workers is NP-hard}
\label{s.wide_few}

We show that the ROPAS Problem restricted to two workers, but where dag width can grow, is NP-hard. Toward this end, we first establish NP-completeness of an auxiliary problem. Using this problem, we establish NP-completeness of other problem. Finally, that other problem is used in a polynomial time Turing reduction that yields NP-hardness of the restricted ROPAS Problem.


We first demonstrate how to modify a reduction of Johnson~\cite{Joh87} to fit our purpose. The reduction is from a variant of Clique to the Balanced Complete Bipartite Subgraph Problem (cf.~\cite{Pee03}). The reduction takes a graph on  nodes and  edges, and produces a bipartite graph with  nodes on the left and  nodes on the right. The question of finding a -clique in the original graph is show to be equivalent to that of finding a balanced complete bipartite subgraph with  nodes on the left and the same number of nodes on the right. Since , we can pad the bipartite graph with isolated nodes for uniformity, and then the resulting problem is NP-complete.


\FF
\noindent
{\bf Fixed Ratio Balanced Complete Bipartite Subgraph (FIRBCBS)}\\
{\it Instance:} Number , bipartite graph  with  nodes on the left and  on the right.\\
{\it Question:} Does  contain a balanced complete bipartite subgraph with  nodes on the left and  on the right?
\FF

\begin{lemma}[\cite{Joh87}]
The FIRBCBS Problem is NP-complete.
\end{lemma}

The FIRBCBS Problem can be reduced to an auxiliary problem of finding many subsets whose union is small. 

\FF
\noindent
{\bf Fixed Ratio Many Subsets with Small Union (FIRMSSU)}\\
{\it Instance:} Number , nonempty subsets  of the set  whose union is .\\
{\it Question:} Are there  of these subsets whose union has cardinality at most ?
\FF

The following lemma generalizes an earlier result of~\cite{GaoM04}.
We can prove the lemma using FIRBCBS and padding.

\begin{lemma}
The FIRMSSU Problem is NP-complete.
\end{lemma}

\begin{proof}
Take any instance of FIRBCBS. We consider the  by  matrix  that is the ``complement'' of the adjacency-matrix of  i.e.,  if left node  is linked to right node , and  if they are not linked. Its rows and columns can be (independently) rearranged so that the  by  submatrix in the upper left hand corner contains only zeros if, and only if, the instance is positive. 
Now we will pad  by adding ``strips'' of certain widths (a sketch is in Figure~\ref{f.padding}). Pick the smallest  such that . Notice that for such , . Let  and . This implies that . We then add  rows and  columns, every filled with zeros, then  rows and  columns, every filled with ones. 
The resulting matrix  has the property that its rows and columns can be (independently) rearranged so that the  by  rectangle in the upper left hand corner contains only zeros if, and only if, the instance is positive. The matrix also has at least one row and one column containing only ones, because .


We define an instance of FIRMSSU such that each column of  is a characteristic vector of a subset. This clearly yields a desired instance and completes the reduction.
\end{proof}

\begin{figure}[htb]
\centerline{\epsfig{file=padding.eps,width=3.2in}}
\caption{A padding pattern in the reduction from FIRBCBS to FIRMSSU; light grey areas correspond to ones, dark grey to zeros.
\label{f.padding}}
\end{figure}


We are now ready to prove the main hardness result of the subsection.

\begin{theorem}
\label{t.two}
The ROPAS Problem restricted to two workers (where the dag width may grow) is NP-hard.
\end{theorem}

\begin{proof}
We give a polynomial time Turing reduction from FIRMSSU to ROPAS---by checking if the minimum expectation is small enough we can determine exactly when a given instance of FIRMSSU is positive. 

Take any instance of FIRMSSU with  nonempty subsets  on .
We construct an instance of ROPAS with two workers. The dag will have three levels (an example is in Figure~\ref{f.reduction_wide}).
We start with a bipartite dag with  sources  and  sinks . Sources are partitioned into  groups of cardinality  each. There is an arc leading from a source of group  to a sink  exactly when  is in the set . 
There are  extra sources . Arcs lead from every extra source to every sink . 
There are  internal tasks . Arcs lead from every source of  to every internal task of . 
There are  extra sinks . Arcs lead from every internal task of  to every extra sink of . 
The first worker is certain to execute every task from  and , while the second worker fails on any. The second worker is certain to execute every task from ,  and , while the first worker fails on any.

\begin{figure}[htb]
\centerline{\epsfig{file=reduction_wide_two_workers.eps,width=3.3in}}
\caption{An example of a reduction from FIRMSSU to ROPAS with two workers and unconstrained dag width. The dag has three levels denoted by ,  and . Tasks in sets  and  are executed only by the first worker; tasks in sets ,  and  only by the second worker.
\label{f.reduction_wide}}
\end{figure}

Suppose that the instance of FIRMSSU is positive i.e., there are  subsets whose union is at most . Let  be the union of the  subsets---if  has cardinality less than , add to  arbitrary elements of  so as to increase the cardinality of  to . We construct a regimen. The second worker executes sources  during the first  rounds. Hence the  internal tasks of  become eligible. Meanwhile, the first worker executes the  sources of  from the groups corresponding to . As a result, at least  sinks of  become eligible. Following round , the second worker begins executing the eligible sinks of , and computes  of them by the end of round . Meanwhile, the first worker executes the  internal tasks , which makes every of the  sinks of  eligible. Following round , the second worker executes  sinks of , while the first worker resumes executing the remaining  sources of . Thus by the end of round , the remaining  unexecuted sinks of  are eligible. Finally, the second worker executes these sinks. Hence the computation is completed at the end of round .

Suppose now that the instance of FIRMSSU is negative. Pick any regimen. For the reason that the instance is negative, the union of any  subsets has cardinality at least . But the cardinality of any group is , so at least  sources of  must be executed in order to have  sinks of  eligible. Therefore, at most  sinks of  can get executed by the end of round . By the end of this round, no sinks of  can be executed, because each depends on the execution of  other tasks. Hence, by the end of that round, there are at least  unexecuted tasks that can only be executed by the second worker. As a result the regimen takes at least  rounds to complete computation.
\end{proof}



\subsection{Scheduling wide dags with many workers is inapproximable}

We have seen that ROPAS is NP-hard either when dag can have large width or when the number of workers can be large. It is, therefore, interesting to see how hard the problem is when not only dag width but also the number of workers can be large. Here we show that then ROPAS is inaproximable with a factor less than , unless P=NP.

\begin{theorem}
The ROPAS Problem cannot be approximated with factor less than , unless P=NP.
\end{theorem}

\begin{proof}
The proof constructs a dag similar to that in the proof of Theorem~\ref{t.two}. Since we can afford many workers, the execution of the dag can be completed in as few as four rounds under favorable circumstances. When circumstances are not favorable, any regimen needs five rounds or more because some workers will necessarily idle. This yields a desired gap.

Specifically, we show a gap creating reduction from FIRMSSU to ROPAS.
Take any instance of FIRMSSU with  nonempty subsets  on . 
We construct an instance of the ROPAS Problem as follows. 
There are  workers. For any task and any worker, the probability that the worker succeeds in executing the task is one. The dag has three levels (an example is in Figure~\ref{f.reduction}). There are  sources, denoted by , partitioned into  groups, associated with numbers  through , of two tasks each. There are  internal tasks, denoted by , associated with numbers  through . Any source from  from group  is linked to the internal task  from . In addition, there are  extra internal tasks, denoted by . Each source from  is linked to every internal task from . There are  sinks, denoted by , associated with subsets  through . Any internal task  from  is linked to sink  if, and only if,  is in the subset . In addition, there are  extra sinks, denoted by . Each internal task from  is linked to every sink from .
We shall see that there is a gap in the minimum expected time to completion for the instance of ROPAS, that differentiates the case when the instance of FIRMSSU is positive from the case when it is negative. 


Suppose that the instance of FIRMSSU is positive i.e., there are  of the subsets whose union has cardinality at most . We will argue that the minimum expected time to completion is at most . Let  be the union of the  subsets---if  has cardinality less than , add to  arbitrary elements of  so as to increase the cardinality of  to . The set  represents  internal tasks from . 
We describe a regimen. In the first round, we execute the  sources from  the children of which are the  internal tasks from  associated with tasks of . This makes the tasks associated with  eligible. In the second round, we execute the  eligible tasks from . Because the instance is positive,  sinks from  become eligible. In addition, we execute the remaining  sources from . Because now every source is executed, the remaining  internal tasks are eligible at the end of the second round. In the third round, we execute the  eligible sinks from  and the  eligible internal tasks from  and . Because now every internal task is executed, any non-executed sink is eligible. In the fourth round, we executed the remaining  sinks.

Suppose that the instance of FIRMSSU is negative i.e., the union of any  of the subsets has cardinality  or more. Take an arbitrary regimen. We will argue that any execution must take at least five rounds. 
At the end of the first round, at most  internal tasks can be eligible, and these must be tasks from . Indeed, each task from  is connected to each of the  sources from , while at most  of them have been executed; also any internal task from  is connected to two distinct sources.
Therefore, in round two, the only internal tasks that can get executed are at most  tasks from . Because the instance is negative, any  subsets have cardinality  or more, and so one would have to execute at least  tasks from  to make  sinks from  eligible. Thus at most  sinks from  can become eligible at the end of the second round. But there are  sinks in total, so at least  of them are not eligible then.
In round three, some nodes get executed, but none of the  sinks. Even if every of these sinks is eligible at the end of round three, then in round four at most  of them can get executed, leaving one unexecuted at the end of round four. 
So the regimen requires at least five rounds to complete computation.
\end{proof}

\begin{figure}[htb]
\centerline{\epsfig{file=reduction_inapprox.eps,width=6in}}
\caption{Example of reduction from FIRMSSU to ROPAS with unconstrained number of workers and dag width. The dag has three levels denoted by ,  and . Every worker can execute any task.
\label{f.reduction}}
\end{figure}

\FF
{\bf Acknowledgements.}
The author thanks Bruce R. Barkstrom of NASA Langley Research Center and Jennifer M. Schopf of Argonne National Laboratory for motivating this study, and Arnold L.~Rosenberg of University of Massachusetts Amherst for discussions on dag scheduling. One missing part of ``the square'' was proven by inspiration of Xiuning Le.
\FF



\begin{thebibliography}{99}
\FF

\remove{****************
\bibitem{AMSK04}
Ali, S., Maciejewski, A.A., Siegel, H.J., Kim, J.-K.:
Measuring the robustness of a resource allocation.
IEEE Transactions on Parallel and Distributed Systems.
Vol. 15(7) (2004) 630--641
**************}

\bibitem{Ann02}
Annis, J., Zhao, Y., Voeckler, J., Wilde, M., Kent, S.,
Foster, I.: Applying Chimera Virtual Data Concepts to
Cluster Finding in the Sloan Sky Survey. ACM/IEEE
Conference on Supercomputing (2002) 1--14

\bibitem{Ber+03}
Berriman, B., Bergou, A., Deelman, E., Good, J., Jacob, J., Katz, D., Kesselman, C., Laity, A., Singh, G., Su, M.-H., Williams, R.:
Montage: A Grid-Enabled Image Mosaic Service for the NVO.
Astronomical Data Analysis Software \& Systems (2003)

\remove{************
\bibitem{CW79}
Carter, J.L., Wegman, M.N.:
Universal classes of hash functions.
Journal of Computer and System Sciences, 
Vol. 18(2) (1979) 143--154

\bibitem{Dagman}
Condor Manual, Condor Team, University of Wisconsin-Madison
{\small \url{http://www.cs.wisc.edu/condor/manual/v6.7/2_11DAGMan_Applications.html}} (2004)
************}

\remove{
\bibitem{Cook74}
Cook, S.A.: 
An observation on time-storage tradeoff.
Journal of Computer and System Sciences, 
Vol.~9 (1974) 308--316
}

\bibitem{CMR07}
Cordasco, G., Malewicz, G., Rosenberg, A.:
Advances in IC-Scheduling Theory: Scheduling Expansive and Reductive Dags and Scheduling Dags via Duality. IEEE Transactions on Parallel and Distributed Systems (2007) to appear 

\bibitem{CLRS}
Cormen, T.H., Leiserson, C.E., Rivest, R.L., Stein, C.: Introduction to Algorithms (2nd Edition). MIT Press (2001)

\bibitem{CK04}
Crescenzi, P., Kann, V. (eds.):
A compendium of NP optimization problems.
{\small\url{http://www.nada.kth.se/~viggo/wwwcompendium/node173.html}} 

\remove{************
\bibitem{CHM97}
Czech, Z.J., Havas, G., Majewski, B.S.:
Perfect hashing, Fundamental Study.
Theoretical Computer Science, Vol.182 (1997) 1--143

\bibitem{DKMMRT94}
Dietzfelbinger, M., Karlin, A., Mehlhorn, K., Meyer auf der Heide, F., Rohnert, H., Tarjan, R.E.:
Dynamic Perfect Hashing: Upper and Lower Bounds.
SIAM Journal on Computing, Vol. 23(4) (1994) 738--761
************}

\bibitem{Inspiral}
Deelman, E., Kesselman, C., Mehta, G.,  Meshkat, L., Pearlman, L., Blackburn, K., Ehrens, P., Lazzarini, A., Williams, R., Koranda, S.: 
GriPhyN and LIGO, building a virtual data grid for gravitational wave scientists.
High Performance Distributed Computing (HPDC'02) (2002) 225--234. 

\bibitem{Dil50}
Dilworth, R.P.:
A decomposition theorem for partially ordered sets.
Annals of Mathematics, Vol. 51 (1950) 161--166

\remove{
\bibitem{EN86}
Elsayed, E.A., Nasr, N.Z.:
Heuristics for resource-constrained scheduling.
International Journal of Production Research, Vol. 24(2) (1986) 299--310
}

\remove{************
\bibitem{FM96}
Farach, M., Muthukrishnan, S.:
Perfect Hashing for Strings: Formalization and Algorithms.
Combinatorial Pattern Matching (1996) 130--140
************}

\bibitem{FAP98a}
Fernandez, A., Armacost, R., Pet-Edwards, J.:
Understanding Simulation Solutions to Resource constrained Project Scheduling Problems with Stochastic task Durations.
Engineering Management Journal, Vol. 10(4) (1998) 5--13

\bibitem{FAP98b}
Fernandez, A., Armacost, R.L., Pet-Edwards, J.:
A Model for the Resource Constrained Project Scheduling Problem with Stochastic Task Durations.
7th Industrial Engineering Research Conference Proceedings
(1998)

\bibitem{FosterK04}
Foster, I., Kesselman, C. [eds.]:
The Grid: Blueprint for a New Computing Infrastructure, 2nd
ed.
Morgan-Kaufmann, San Francisco, CA (2004)

\remove{************
\bibitem{FKS84}
Fredman, M.L., Koml\'{o}s, J., Szemer\'{e}di, E.:
Storing a sparse table with O(1) worst case access time.
Journal of the ACM, Vol. 31(3) (1984) 538--544
************}

\bibitem{GaoM04}
Gao, L., Malewicz, G.,: Toward Maximizing the Quality of Results of Dependent Tasks Computed Unreliably. Theory of Computing Systems (2007) available online

\bibitem{GJ79}
Garey, M.R., Johnson, D.S.: 
Computers and Intractability.  
Freeman, New York (1979) 

\remove{************
\bibitem{Graphviz}
Graphviz - Graph Visualization Software, AT\&T Research {\small\url{http://www.graphviz.org}} 
************}

\bibitem{GI99}
Goel, A., Indyk, P.:
Stochastic load balancing and related problems.
40th Annual Symposium on Foundations of Computer Science (FOCS) (1999) 579--586

\bibitem{HL01}
Hillier, F.S., Lieberman, G.J.:
Introduction to Operations Research, 8th ed.
McGraw-Hill (2004)

\bibitem{HL05}
Herroelen, W., Leus, R.:
Project scheduling under uncertainty: Survey and research potentials.
European Journal of Operational Research, Vol. 165(2) (2005) 289--306

\remove{
\bibitem{HongK81}
Hong, J.-W., Kung, H.T.:
I/O complexity: the red-blue pebble game.  
13th ACM Symposium on Theory of Computing (STOC) (1981) 326--333
}

\remove{
\bibitem{HopcroftPV77}
Hopcroft, J.E., Paul, W., Valiant, L.G.:
On time versus space.
Journal of the ACM, Vol.~24 (1977) 332--337
}

\bibitem{H+05}
Horn, J.V., Dobson, J., Woodward, J., Wilde, M., Zhao, Y., Voeckler, J., Foster, I.:
Grid-Based Computing and the Future of Neuroscience Computation.  Methods in Mind, MIT Press, (2005). 

\bibitem{IR90}
Ireland, K., Rosen, M.:
A Classical Introduction to Modern Number Theory, 2nd ed.
Springer-Verlag (1990)

\bibitem{Joh87}
Johnson, D.S.:
The NP-completeness column: An ongoing guide.
Journal of Algorithms, Vol. 8(3) (1987) 438--448


\remove{
\bibitem{KY96}
Kouvelis, P., Yu, G.:
Robust Discrete Optimization and its Applications.
Kluwer Academic Publishers (1996)
}

\bibitem{KRT00}
Kleinberg, J., Rabani, Y., Tardos, E.:
Allocating Bandwidth for Bursty Connections.
SIAM Journal on Computing, Vol. 30(1) (2000) 191--217

\remove{************
\bibitem{KnuVol3}
Knuth, D.E.:
The Art of Computer Programming, Volume 3, Second Edition.
Addison-Wesley (1998)
************}

\bibitem{LR07}
Lin, G., Rajaraman, R.:
Approximation Algorithms for Multiprocessor Scheduling under Uncertainty.
19th ACM Symposium on Parallelism in Algorithms and Architectures (2007) to appear

\bibitem{L07}
Lin, G.:
New paradigms and approximation algorithms for optimization under uncertainty.
Ph.D. Dissertation, College of Computer and Information Science, Northeastern University (2006)

\remove{
\bibitem{MCG82}
McGinnis, L.F.:
Project Scheduling with Resource Considerations.
Proceedings of the Annual Industrial Engineering Conference (1982) 463--466
}

\bibitem{Mal05b}
Malewicz, G.:
Implementation and Experiments with an Algorithm for Parallel Scheduling of Complex Dags under Uncertainty. Submitted for publication. Preliminary version 8th Workshop on Algorithm Engineering and Experiments (ALENEX'06) (2006) 66--74

\bibitem{MFRW07}
Malewicz, G., Foster, I., Rosenberg, A., Wilde, M.: A Tool for Prioritizing DAGMan Jobs and Its Evaluation. Journal of Grid Computing Vol. 5(2) (2007) 197--212

\bibitem{MalewiczR04}
Malewicz, G., Rosenberg, A.L.:
On batch-scheduling dags for
Internet-based computing. 
11th European Conference on Parallel Processing (Euro-Par) (2005) 262--271

\bibitem{MRY05}
Malewicz, G., Rosenberg, A., Yurkewych, M.: Toward a Theory for Scheduling Dags in Internet-Based Computing. IEEE Transactions on Computers, Vol. 55(6) (2006) 757--768 


\bibitem{MsftProj03}
Microsoft Project 2003
{\small\url{http://www.microsoft.com/office/project/default.asp}}

\bibitem{MT97}
Mori, M., Tseng, C.:
A Resource Constrained Project Scheduling Problem with Reattempt at Failure: A Heuristic Approach.
Journal of the Operations Research Society of Japan, Vol. 40(1) (1997) 33--44

\bibitem{NR01}
Narasimhan, M., Ramanujam, J.:
A fast approach to computing exact solutions to the resource-constrained scheduling problem. 
ACM Transactions on Design Automation of Electronic Systems,
Vol. 6(4) (2001) 490--500

\bibitem{Nor97}
Norris, J.R.:
Markov Chain.
Cambridge University Press (1997)

\bibitem{OU95}
\"{O}zdamar, L., Ulusoy, G.:
A survey on the resource-constrained project scheduling problem.
IIE Transactions, Vol. 27 (1995) 574--586

\remove{************
\bibitem{Pag99}
Pagh, R.:
Hash and Displace: Efficient Evaluation of Minimal Perfect Hash Functions.
Workshop on Algorithms and Data Structures (WADS) (1999) 49--54
************}


\remove{
\bibitem{PatersonH70}
Paterson, M.S., Hewitt, C.E.:
Comparative schematology.
Project MAC Conference on Concurrent Systems and Parallel Computation, ACM Press (1970) 119--127
}

\bibitem{Pee03}
Peeters, R.:
The maximum edge biclique problem is {NP}-complete.
Discrete Applied Mathematics, Vol. 131(3) (2003)  651--654

\bibitem{Rosenberg04}
Rosenberg, A.L.:
On scheduling mesh-structured computations for
Internet-based computing.
IEEE Transactions on Computers, Vol. 53 (2004) 1176--1186

\remove{
\bibitem{RosenbergS83}
Rosenberg, A.L., Sudborough, I.H.:
Bandwidth and pebbling.
Computing Vol.~31 (1983) 115--139
}

\bibitem{RosenbergY04}
Rosenberg, A.L., Yurkewych, M.:
Guidelines for scheduling some
common computation-dags for Internet-based computing.  
IEEE Transactions on Computers, Vol. 54(4) (2005)
428--438

\bibitem{Sar02}
Sarmenta, L.F.G.:
Sabotage-tolerance mechanisms for volunteer computing systems.
Future Generation Computer Systems, Vol. 18(4) (2002) 561--572

\remove{
\bibitem{STW98}
Sotskov, Y.N., Tanaev, V.S., Werner, F.:
On the Stability Radius of an Optimal Schedule: a Survey and Recent Developments.
Industrial Applications of Combinatorial Optimization, Kluwer Academic Publishers (1998) 72--108
}

\bibitem{SU01}
Skutella, M., Uetz, M.:
Scheduling precedence-constrained jobs with stochastic processing times on parallel machines.
12th ACM-SIAM Symposium on Discrete Algorithms (SODA) (2001) 589--590

\bibitem{TTL05}
Thain D., Tannenbaum, T., Livny, M.: 
Distributed computing in practice: the Condor experience. 
Concurrency and Computation: Practice and Experience, Vol. 17 (2005) 323--356

\bibitem{TMY95}
Tseng, C.C., Mori, M., Yajima, Y.:
A project scheduling model considering the success probability.
Proc. of the Association of Asian Pacific Operational Research Societies (APROS) (1994) 399--406

\bibitem{TN03}
Turnquist, M.A., Nozick, L.K.:
Allocating Time and Resources in Project Management Under Uncertainty.
36th Annual Hawaii International Conference on System Sciences (HICSS) (2003) 250c

\end{thebibliography}






\remove{*********************

\renewcommand{\thetheorem}{2.1}

\begin{lemma}
For any set  of tasks that satisfies precedence constraints,  is finite.
\end{lemma}

\begin{proof}
We define a regimen that has finite expectation; thus minimum expectation must be finite, too. We take a topological sort  of the subdag of  induced by tasks other than . Note that it is possible to execute tasks in the order of the sort because once tasks  and  have been executed, task  is eligible. Our regimen will follow this order, each time assigning all workers to the task at hand. The probability that every worker fails to execute task  is , which by assumption is strictly smaller than . Thus the expected time to execute the task is , because execution time follows geometric distribution. We can use linearity of expectation to conclude that the expected time to completion for the regimen is just the sum of expectations for each individual task in the sort. Thus the expectation is at most , which is finite. 
\end{proof}

\renewcommand{\thetheorem}{3.1}

\begin{lemma}
Consider a regimen  and a set  of tasks that satisfies precedence constraints and does not contain all sinks of . Let the expected time to completion for the regimen starting with tasks  already executed be finite.
Let  be all the distinct subsets of , and .
Let  be the probability that  is the set of tasks executed by workers in the assignment . Let . Then

where  is the expected time to completion for regimen  starting with tasks  already executed.
\end{lemma}

\begin{proof}
Recall that the time to completion is determined by iterating the following three steps of a random process until  contains all sinks of : (1) workers get assigned to tasks of  as given by the function , (2) workers attempt to execute the assigned tasks, (3) tasks executed in step (2) are added to . Our goal is to compute the expected time to completion.

Let  be a random variable equal to the time to completion for the regimen that starts with tasks  already executed. Note that  is not empty.
The variable can be represented as a sum of two random variables: the time  spent until, and including the moment when, at least one task of  has been executed, and the remaining time  to completion.
By assumption  is finite. Since  and  are non-negative,  and  are finite, too. Hence we can use linearity of expectation to write


Let us calculate each of the two expectations. The first is particularly easy, because  has geometric distribution with probability of success equal to . This probability cannot be zero because if so then  would be infinite. So .


How about ? Since the expectation is finite, the probability that  is infinite is zero. Hence we can write the expectation as a series

that converges absolutely.
But the event ``remaining time is '' is a disjunction of  mutually exclusive events: ``(remaining time is ) {\em and} ( is the set of tasks first executed by workers)'', for . Somewhat abusing notation, let us denote by  the event `` is the set of tasks first executed by workers''. We can ignore these events that do not occur, and then 

But for such , 

Thus the series
nD_i converges absolutely. We can, therefore, rearrange the following sum of series

and conclude that it is equal to .
But the expression in brackets is just , since again it is unlikely that the remaining time is infinite given that , when . Thus , since when , then , irrespective of the value of .
\end{proof}


\renewcommand{\thetheorem}{3.2}

\begin{lemma}
Let  be the admissible evolution of execution for a dag . Then  is dag. Its nodes are exactly the sets of tasks that satisfy precedence constraints. It has a single source  and a single sink .
\end{lemma}

\begin{proof}
We verify the assertions in turn.
The graph  cannot have any cycle, because any arc points from a node  to a node  that is a set with strictly more elements than the set .

Nodes of  are exactly the sets of tasks that satisfy precedence constraints. Indeed, if  satisfies precedence constraints, then clearly so does its union with any subset of . Thus any node of  satisfies precedence constraints. Now pick any subset  of tasks that satisfies precedence constraints. Let  be a topologically sort of the subdag of  induced by . Clearly,  belongs to the set of tasks eligible when tasks  have been executed, for any . So if  is a node of , so is . Since  is a node of ,  must also be. A corollary to this is that  is a node of .

We add a node  to  only if there is an arc leading to  from some other node. So  cannot be a source. However,  is a source because no arc leads to a set with the same number or fewer elements.

Pick any node  of  and suppose that it does not contain all sinks of . By looking at a topological sort of  we notice that there is a task of  not in  all whose parents in  are in . Thus  is not empty, and so  has a child in . Pick any node  of  that contains all sinks of . Since  satisfies precedence constraints, it contains all tasks, and so . But  is empty, so  has no children in .
\end{proof}


\renewcommand{\thetheorem}{3.3}

\begin{theorem}
When the algorithm OPT halts, for any node  of , the expected time to completion for regimen  starting with tasks  already executed is equal to the minimum expected time to completion that any regimen can achieve starting with tasks  already executed.
\end{theorem}

\begin{proof}
Let  be the topological sort of  which was used by the algorithm OPT. We argue that the following invariant holds during the reverse processing of the sort:
\begin{quote}
For all  such that ,  and  is equal to the expected time to completion of  that starts with tasks  already executed.
\end{quote}

This invariant is clearly true for . Indeed, by Lemma~\ref{l.dag},  has just one sink which is equal to , and so . If all tasks are already executed, the minimum expected time to completion is zero. The algorithm, thus, correctly assigns zero to . The expectation of any regimen that starts with all tasks already executed is zero, and so the (arbitrary) value of  is satisfactory.

Now pick any . We shall see that after OPT has processed  the invariant is true for  decreased by one. Let . Since  is not a sink of , it has at least one child. Let  be the children.

We first argue that the value assigned to  is at most the minimum expected time to completion .
Pick a regimen  that achieves the minimum when starting with tasks  already executed. Lemma~\ref{l.finite} ensures that  is finite. Hence we can use Theorem~\ref{t.recursive} to express the expectation of the regimen as a weighted sum 

of expected times  to completion for  starting with tasks from the sets  already executed. By the invariant , and so the expectation  is at least . The dynamic program considers all assignments as candidates for , and the assignment  in particular. For this assignment the algorithm calculates the weighted sum . Hence the weighted sum is at most . The algorithm selects an assignment that minimizes a weighted sum, so the value of  is at most , as desired.

After values of  and  have been set, the value of  is clearly equal to the expectation of  starting with  already executed. Indeed, for any assignment considered by the algorithm, the weighted sum is, by Theorem~\ref{t.recursive}, equal to the expectation of  that uses this assignment in place of  and starts with tasks  already executed.

Since  has expectation  and  is at most , the expected time to completion for  starting with  already executed is actually equal to . Hence the invariant holds when  gets decreased by one. This completes the proof of the theorem. 
\end{proof}


\renewcommand{\thetheorem}{4.1}

\begin{lemma}
The MP Problem is NP-complete.
\end{lemma}

\begin{proof}
We will show a reduction from the Exact Cover by 3-Sets Problem to the Multiplicative Partition Problem.

Pick any instance of X3C---a collection  of -element subsets of the set , . Recall that the instance is positive if, and only if, there is a subcollection of  such that every element of  occurs in exactly one subset of the subcollection. We can assume that  and that the union of all subsets of  is , as otherwise the instance of X3C is definitely negative.
We build an instance of MP as follows. We begin by enumerating the first consecutive primes . By the Prime Number Theorem (see e.g., \cite{IR90}) the prime  has value . Therefore, we can enumerate the primes in time  using the Eratosthenes sieve; this time is polynomial with respect to the size of the instance of X3C. 
The instance of the MP Problem will have  sizes. The first  are defined as products of primes indexed by the elements of subsets i.e., . Note that 's are fairly small, so that each  is . 
We add two ``dummy'' sizes. Let  be the product of sizes  through , and  be the product of the first  primes; each is , so sufficiently small. Note that  is an integer, because . We define  and . Therefore, the instance of the MP Problem can be represented in time and space polynomial with respect to , as desired.

Suppose that the instance of X3C is positive, and let  be the indices that define the subcollection. But then  is the product of all primes from  to . So then  is equal to the product of all 's divided by the product of these primes. Therefore,

and so the instance of MP is positive.


Suppose that the instance of MP is positive, and let  be a subset such that . Note that there are only two sizes,  and , that have the prime  as a factor. But two natural numbers are equal if, and only if, they have the same factorization. Thus in order for the products to be equal, either  or  is in , but not both. We can assume, without loss of generality, that  is in , because the roles of  and its complement are symmetric. Let , and  be all elements not in  and other than . But then 

which can be equivalently expressed as

Of course,  and  partition , so . Thus
, and since the numbers are positive, . Therefore, there is a selection of the 's whose product contains each prime from  to  exactly once. This set  defines a subcollection of  such that every element of  is contained in exactly one subset of the subcollection. So the instance of X3C is positive.
\end{proof}


\renewcommand{\thetheorem}{4.2}

\begin{lemma}
The PMSP Problem is NP-hard.
\end{lemma}

\begin{proof}
We give a polynomial time Turing reduction of MP to PMSP. Specifically, we show how to find an answer to a given instance of MP by inspecting the minimum value for an appropriately constructed instance of PMSP. The proof is based on the fact that for any , the function  defined for  is minimized exactly when . The difficulty is to ensure that we compute using rational numbers only.

Pick any instance of the MP Problem and let  be the positive integer sizes, each at least . We define an instance of the PMSP Problem by taking , where . Then , as desired. 
We shall see that we can decide exactly when the instance of MP is positive, just by checking if the minimum for the instance of PMSP is equal to the value .

Let us see when the product  achieves that value. Let . Then

with equality only when . The crucial observation is that  is just , which is a rational number. Thus so we can invoke an oracle that solves PMSP on the instance that we have constructed, then inspect the minimum returned by the oracle, and determine whether or not there exists  such that . But the equation can be equivalently written as
, which is equivalent to . This in turn is equivalent to . But this is equivalent to 
. So 
the instance of MP is positive if, and only if, the minimum for the instance of PMSP is equal to 
.
\end{proof}


\renewcommand{\thetheorem}{4.5}

\begin{lemma}
The FIRMSSU Problem is NP-complete.
\end{lemma}

\begin{proof}
Take any instance of FIRBCBS. We can consider the  by  matrix  that is the ``complement'' of adjacency-matrix of  i.e.,  if left node  is linked to right node , and  if they are not linked. Its rows and columns can be (independently) rearranged so that the  by  submatrix in the upper left hand corner contains only zeros if, and only if, the instance is positive. 
Now we will pad  by adding ``strips'' of certain widths (a sketch is in Figure~\ref{f.padding}). Pick the smallest  such that . Notice that for such , . Let  and . This implies that . We then add  rows and  columns, all filled with zeros, then  rows and  columns, all filled with ones. 
The resulting matrix  has the property that its rows and columns can be (independently) rearranged so that the  by  rectangle in the upper left hand corner contains only zeros if, and only if, the instance is positive. The matrix also has at least one row and one column containing only ones, because .


We define an instance of FIRMSSU such that each column of  is a characteristic vector of a subset. This clearly yields a desired instance and completes the reduction.
\end{proof}


\renewcommand{\thetheorem}{4.7}

\begin{theorem}
The ROPAS Problem cannot be approximated with factor lower than , unless P=NP.
\end{theorem}

\begin{proof}
We show a gap creating reduction from FIRMSSU to ROPAS.
Take any instance of FIRMSSU with  nonempty subsets  on . 
We construct an instance of the ROPAS Problem as follows. 
There are  workers. For any task and any worker, the probability that the worker succeeds in executing the task is one. The dag has three levels (an example is in Figure~\ref{f.reduction}). There are  sources, denoted by , partitioned into  groups, associated with numbers  through , of two tasks each. There are  internal tasks, denoted by , associated with numbers  through . Any source from  from group  is linked to the internal task  from . In addition, there are  extra internal tasks, denoted by . Each source from  is linked to every internal task from . There are  sinks, denoted by , associated with subsets  through . Any internal task  from  is linked to sink  if, and only if,  is in the subset . In addition, there are  extra sinks, denoted by . Each internal task from  is linked to every sink from .
We shall see that there is a gap in the minimum expected time to completion for the instance of ROPAS, that differentiates the case when the instance of FIRMSSU is positive from the case when it is negative. 


Suppose that the instance of FIRMSSU is positive i.e., there are  of the subsets whose union has cardinality at most . We will argue that the minimum expected time to completion is at most . Let  be the union of the  subsets---if  has cardinality less than , add to  arbitrary elements of  so as to increase the cardinality of  to . The set  represents  internal tasks from . 
We describe a regimen. In the first round, we execute the  sources from  the children of which are the  internal tasks from  associated with tasks of . This makes the tasks associated with  eligible. In the second round, we execute the  eligible tasks from . Because the instance in positive,  sinks from  become eligible. In addition, we execute the remaining  sources from . Because now all sources are executed, the remaining  internal tasks become eligible. In the third round, we execute the  eligible sinks from  and the  eligible internal tasks from  and . Because now all internal tasks are executed, any non-executed sink is eligible. In the fourth round, we executed the remaining  sinks.

Suppose that the instance of FIRMSSU is negative i.e., the union of any  of the subsets has cardinality  or more. Take an arbitrary regimen. We will argue that any execution must take at least five rounds. 
At the end of the first round, at most  internal tasks can be eligible, and these must be tasks from . Indeed, each task from  is connected to each of the  sources from , while at most  of them have been executed; also any internal task from  is connected to two distinct sources.
Therefore, in round two, the only internal tasks that can get executed are at most  tasks from . Because the instance is negative, any  subsets have cardinality  or more, and so one would have to execute at least  tasks from  to make  sinks from  eligible. Thus at most  sinks from  can become eligible at the end of the second round. But there are  sinks in total, so at least  of them are not eligible then.
In round three, some nodes get executed, but none of the  sinks. Even if these sinks are all eligible at the end of round three, then in round four at most  of them can get executed, leaving one unexecuted at the end of round four. 
So the regimen requires at least five rounds to complete computation.
\end{proof}




\FFF
\FFF
\FFF
\FFF

\begin{figure}[htb]
\centerline{\epsfig{file=reduction_inapprox.eps,width=6in}}
\caption{Example of reduction from FIRMSSU to ROPAS with unconstrained number of workers and dag width. The dag has three levels denoted by ,  and . Every worker can execute any task.
\label{f.reduction}}
\end{figure}


\begin{figure}[htb]
\centerline{\epsfig{file=padding.eps,width=3.2in}}
\caption{A padding pattern in the reduction from FIRBCBS to FIRMSSU; light grey areas correspond to ones, dark grey to zeros.
\label{f.padding}}
\end{figure}

*********************}

\end{document}
