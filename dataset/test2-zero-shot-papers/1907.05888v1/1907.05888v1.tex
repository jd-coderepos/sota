\documentclass[twocolumn]{svjour3}          

\smartqed  

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{newtxtext,newtxmath}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{epsfig,graphics}
\usepackage{latexsym}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{cite}
\usepackage{citeref}
\usepackage{subfigure}
\usepackage[misc]{ifsym}
\usepackage[export]{adjustbox}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{mathtools,xparse}
\usepackage{pgfplots}
\usepackage{tikz}
\usepackage{tkz-euclide}
\usetkzobj{all}
\usetikzlibrary{positioning}
\usetikzlibrary{shapes,arrows}
\usetikzlibrary{shadows, positioning,arrows.meta,shapes.geometric}
\usepackage[flushleft]{threeparttable}
\usepackage{floatrow}
\usepackage{wrapfig}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{etex}




\begin{document}

\title{Regularized HessELM and Inclined Entropy Measurement for Congestive Heart Failure Prediction}









\author{Apdullah Yay{\i}k \and Yakup Kutlu \and G\"{o}khan Altan}






\institute{A. Yay{\i}k (\Letter)  \at Military Academy \\National Defence University, Ankara, Turkey\\  email: ayayik@kho.edu.tr\\
Y. Kutlu \at Department of Computer Engineering,\\\.{I}skenderun Technical University, Hatay, Turkey\\
G. Altan \at Department of Computer Engineering,\\\.{I}skenderun Technical University, Hatay, Turkey
}




\maketitle
\begin{abstract}
Our study concerns with automated predicting of congestive heart failure (CHF) through the analysis of electrocardiography (ECG) signals. A novel machine learning approach, regularized hessenberg decomposition based extreme learning machine (R-HessELM), and feature models; squared, circled, inclined and grid entropy measurement were introduced and used for prediction of CHF. This study proved that inclined entropy measurements features well represent characteristics of ECG signals and together with R-HessELM approach overall accuracy of 98.49\% was achieved.

\keywords{Congestive heart failure \and Entropy measurements \and Extreme learning machine \and Hessenberg decomposition \and Regularization}
\end{abstract}

\section{Introduction}
\label{intro}
Congestive heart failure (CHF) is a serious medical condition (not a disease) that inhibits the heart performing the circulatory activities throughout the body, since the heart can not pump sufficient blood that tissues need. Its symptoms are generally breathless, ankle swelling and fatigue. It is associated with significant decrease in quality of life and high degrees of debility, morbidity and mortality. According to British Society for Heart Failure report on March 2016, in United Kingdom approximately 900.000 people are exposed to CHF, 5\% of emergency admissions are related with  CHF and its treatment processes  consume 2\% of all national health service expenditure \cite{ref1}. Since it is epidemic not only across Europe also worldwide, the need of early diagnosis (prediction its existence) is a very important issue. Unfortunately, it could not be assessed with ease using clinical techniques. European Society of Cardiology guidelines in 2016 recommend the following procedure to diagnose CHF. Clinical history of the patient,  physical examination, characterized symptoms also electrocardiography (ECG) record while resting are analyzed. If at least one of the components is not normal,  plasma Natriuretic Peptides is to be examined to decide whether echocardiography is needed \cite{ref2}. In order to provide rapid and reliable  diagnosis,  automatic prediction based on data mining or machine learning techniques using only  ECG data is a vital research area. 

For the last decade, several signal processing and machine learning approaches were utilized on ECG signal to predict CHF. Researchers heavily focused on revealing robust features from power spectrum of ECG signal. In particular, statistical values of  discrete wavelet transform \cite{ref3, ref4} wavelet decomposition \cite{ref5} and continuous wavelet transform \cite{ref6} were extracted. Whereas, few studies focused on time-series properties of ECG signal, such as Poincare \cite{ref7, ref8}, RR intervals \cite{ref9,ref10}, second-order difference plot (SODP) \cite{ref11, ref12}. \.{I}\c{s}ler and Kuntalp analyzed heart-rate variability (HRV) with many feature extracting techniques not only based on power spectrum also time-frequency approaches \cite{ref13}. Measure of complex correlation to quantify temporal variability in the Poincare plot was introduced by Karmakar et al. \cite{ref14}. They reported efficiency of central tendency measure of the RR interval and radial distance of Teager energy scatter plot to predict CHF. Thuraisingham \cite{ref15} analyzed SODP of RR intervals. In addition, he introduced a classification system that employs statistical procedure. Cohen et al.\cite{ref12} analyzed SODPs and central tendency measures. Zheng et al. proposed least square support vector machines (LS-SVM) model with heart sound and cardiac reverse features that predict CHF. Additionally, they showed that it outperforms neural network and hidden-markow model \cite{ref16}. Altan et al proposed an early diagnosis model for CHF by applying Hilbert-Huang Transform to the ECG signal. They extracted high-order statistical features form several frequency modulations \cite{ref17}.

Our study concerns with prediction of CHF with a reliable intelligence system. Novel approaches for distributing peaks named squared entropy measurement (SEM), inclined entropy measurement (IEM) and grid entropy measurement (GEM) for extracting several scattered features were introduced. In back-propagation (BP) algorithm, minimizing loss function is controlled using a different data, namely validation set, excluded from training set to avoid over-fitting, in other words to make it gain generalization capability. However, extreme learning machine (ELM) cannot gain a generalization capability using necessarily the same approach in BP. Recently, Cao et al.  proposed that ELM with singular value decomposition (SVD) method can gain generalization ability with considering performance of pseudoinversing in leave-one out (LOO) model when computing loss function mean square error (MSE) \cite{ref18}. Therefore, they put regularization term to the denominator of classical MSE, in order to optimally select regularization term by observing effect of pseudoinversing. In this study this approach is extended to recently introduced hessenberg decomposition based ELM in \cite{ref18}.

In the following section, the data acquisition, preprocessing steps, methods of feature extraction, classifiers and performance measures are presented. In Sect. \ref{resultsandconclusions}, results are given and analyzed. Discussions about the results are in Sect. \ref{discussion}.

\section{Materials and Methods} 
\label{sec:Materials and Methods}
The system architecture and data processing are illustrated in Figure \ref{figure1}.

\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{Fig1.png}
    \caption{The proposed system for the predicting CHF}
    \label{figure1}
\end{figure}

\subsection{Data Acquisition}
In this study CHF Database and Normal Sinus Rhythm Database which are freely available on Physionet web site \cite{ref20} were used.  The CHF database consists of 24 hour ECG signals with 250 Hz sampling  frequency from 15 patients (aged between 22 and 71) exposed to CHF and  Normal sinus rhythm database consists of ECG signals with 128 Hz sampling frequency (resampled to 256 Hz with cubic splines) from 18 healthy people (aged between 20 and 50). ECG recordings had power line interference and baseline wander effects because of respiration. Baseline wander and Power line interference consist of low frequency components and high frequency components, respectively. ECG recordings were filtered with two median filters to eliminate the baseline wander and with a notch filter to eliminate power-line frequency \cite{ref21}. 

\subsection{Second-Order Difference Plot (SODP)}
Second-order difference plot (SODP) was originated from Poincare plot \cite{ref8}. It scatters consecutive difference values with second degree over the Cartesian coordinate system. For  is data matrix where  vectors are rows and n is the number of attributes. SODP values for  row is calculated as follows,



Plotting a against b in (\ref{sodp}) gives SODP. SODP provides observing the statistical situation of consecutive differences in time series data. In this study, four types of SODP whose peak-to-peak points were distributed geometrically distinct from each other were investigated.

\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{Fig2.png}
    \caption{Peak representation of 1 s ECG data used in this study}
    \label{figure2}
\end{figure}


In order to predict CHF accurately, features that are related to characteristic structure of ECG recordings needs to be extracted. SODP distributes ECG data peaks in Figure \ref{figure2} into different regions of Cartesian coordinate system according to amplitude variability. While P and T peaks refer to little rate amplitude increase and decrease, Q and S peaks refer to little rate decrease and increase, R peaks refer to high rate amplitude increase and decrease on ECG signal. All peaks increase and decrease regularly, except for P and T peaks. In SODP; while P, T, Q and S peaks fall near and above x axis and near and below x axes, R peaks fall above and away from x axes and below and away from x axes. Therefore, increasing and decreasing rate, regularity of peak fluctuations and closeness to x axes are significant properties that help characterize ECG signal.

In this study; to extract discriminative information from SODP, cumulative number of data in circled, squared, inclined and grid regions were calculated. Novel feature models; circled entropy measurement (CEM) that calculates data fall over circled pieced regions,  squared entropy measurement (SEM) that calculates data fall over squared pieced regions, inclined entropy measurement (IEM) that calculates data fall over inclined pieced regions, grid entropy measurement (GEM) that calculates data fall over grid pieced regions in SODP were introduced. These feature models for CHF and Normal ECG data are indicated in Figure \ref{figure3}. SEM and CEM methods captures similar ratio of changes in ECG peaks with different accuracies. IEM captures wide-range of changes in ECG peaks. IEM method can detect number of regularly increasing and decreasing, only instantaneous increasing after decreasing and only instantaneous decreasing after increasing characteristic of ECG peaks. GEM captures local fluctuations of ECG data in Cartesian system. GEM detects number of fluctuations in ECG peaks according to axis distance information. MATLAB script for feature models is shared for practitioners \footnote{https://github.com/apdullahyayik/time-series-analysis}

\begin{figure*}\centering
  \subfigure[]{\label{fig:A}\includegraphics[width=0.26\textwidth]{Fig3_a.png}
            }\subfigure[]{\label{fig:B}\includegraphics[width=0.26\textwidth]{Fig3_b.png}
            }\subfigure[]{\label{fig:C}\includegraphics[width=0.27\textwidth]{Fig3_c.png}
            }\subfigure[]{\label{fig:D}\includegraphics[width=0.25\textwidth]{Fig3_d.png}
           }\\
\subfigure[]{\label{fig:E}\includegraphics[width=0.26\textwidth]{Fig3_e.png}
            }\subfigure[]{\label{fig:F}\includegraphics[width=0.26\textwidth]{Fig3_f.png}
            }\subfigure[]{\label{fig:G}\includegraphics[width=0.26\textwidth]{Fig3_g.png}
            }\subfigure[]{\label{fig:H}\includegraphics[width=0.26\textwidth]{Fig3_h.png}
            }
\caption{SODP of ECG data (belonging to patients exposed to CHF) with (a) inclined, (c) squared, (e) circled (g) grid entropy measurements and SODP of  ECG data (belonging to healthy person) with (b) inclined, (d) squared, (f) circled, (h) grid entropy measurements}\label{figure3}\end{figure*}

\subsection{Normalization}
Prior to classification, features were linearly normalized using \ref{normalization} within the range 

where  and  represent respectively the lowest and highest values of each feature. The normalization coefficients, which were extracted from the training data, were stored to normalize the test data as well.


\subsection{Extreme Learning Machine (ELM)}
Conventional ELM \cite{ref22} is a fully-connected single-hidden layer feed-forward neural network (SLFN) that has random number of nodes in hidden layer. Its structure is illustrated in Figure \ref{figure4}. In the input layer, weights and biases are assigned randomly, whereas in the output layer, weights are computed with non-iterative linear optimization technique based on generalized-inverse. Hidden layer with non-linear activation function makes non-linear input data linearly-separable. Let  be a sample set, with n distinct samples, where   is the  is input sample and  is the  desired output. With m hidden neurons, the output of  hidden layer is given by (where k<m);


 and  desired output is given by;
 


where  is the activation function,  is the output of hidden neurons,  is the input layer weight matrix,  is the output layer weight matrix,  is the bias value of hidden neuron and  is the desired target in the training set. In training set, ELM with n neurons in hidden layer approximates input samples with zero error such that  where  is network output computed with using  in (\ref{elm3}). But in this case due to over-fitting generalization capacity becomes very poor.

\begin{figure}
\centering
\tikzset{neuron missing/.style={
    draw=none, 
    scale=4,
    text height=0.333cm,
    execute at begin node=\color{black}
  },
}

\begin{tikzpicture}[x=1.5cm, y=1.5cm, >=stealth]

\foreach \m/\l [count=\y] in {1,2,3}
{
 \node [circle,fill=gray!50,minimum size=1cm] (input-\m) at (0,2.5-\y) {};
}
\foreach \m/\l [count=\y] in {4}
{
 \node [circle,fill=gray!50,minimum size=1cm ] (input-\m) at (0,-2.5) {};
}
 
 \node [neuron missing]  at (0,-1.5) {};
 

\foreach \m [count=\y] in {1}
  \node [circle,fill=gray!50,minimum size=1cm ] (hidden-\m) at (2,0.75) {};
  
\foreach \m [count=\y] in {2}
  \node [circle,fill=gray!50,minimum size=1cm ] (hidden-\m) at (2,-1.85) {};
  
 \node [neuron missing]  at (2,-0.3) {};


\foreach \m [count=\y] in {1}
  \node [circle,fill=gray!50,minimum size=1cm ] (output-\m) at (4,0.6-\y) {};
 


\foreach \l [count=\i] in {1,2,3,n}
  \draw [<-] (input-\i) -- ++(-1,0)
    node [above, midway] {};

\foreach \l [count=\i] in {1,m}
  \node [above] at (hidden-\i.north) {};

\foreach \l [count=\i] in {1}
  \draw [->] (output-\i) -- ++(1,0)
    node [above, midway] {};




    \draw [->] (input-1) -- (hidden-1)
    node[above, midway]{};
    \draw [->] (input-1) -- (hidden-2)
    node at (1.1,0) {};
   
   \draw [->] (input-2) -- (hidden-1)
    node[above, midway]{};
    \draw [->] (input-2) -- (hidden-2)
     node at (1,-0.4) {};
    
    \draw [->] (input-3) -- (hidden-1)
    node[above, midway]{};
    \draw [->] (input-3) -- (hidden-2)
   node at (1,-1){};
    
    \draw [->] (input-4) -- (hidden-1)
    node at (0.45,-1.4) {};
    \draw [->] (input-4) -- (hidden-2)
    node at (0.6,-2.1) {};
    
\draw [->] (hidden-1) -- (output-1)
     node[above, midway]{};
     \draw [->] (hidden-2) -- (output-1)
     node[above, midway]{};

\foreach \l [count=\x from 0] in {Input, Hidden, Output}
\node [align=center, above] at (\x*2,2) {\l \\ layer};

\end{tikzpicture}
\caption{Structure of ELM}
\label{figure4}
\end{figure}
\label{ELM1}

Hidden layer neuron number m must be selected randomly or empirically, such that m<n to prevent overfitting. Inverse of  can not be determined directly if   is not a full-rank matrix. Pseudoinverse of the matrix , namely , can be computed via least square solution. To stabilize the pseudoinverse numerically, regularized least squares solution in (\ref{elm4}) is used,


where  is regularization parameter that enables linear independence of columns of . This solution is accurate as long as square matrix  is invertible. In SLFN, it is singular in most of the cases since there is tendency to select m<<n. In conventional ELM, Huang et. al. \cite{ref22} has solved this problem using SVD \cite{ref23} method. However, SVD is very slow when dealing with large data and has low-convergence to real solution \cite{ref24,ref25}.

\subsection{Hessenberg Decomposition ELM HessELM}
Since (\ref{elm3})  is an under-determined system of equation,  pseudoinverse of hidden layer output matrix  is formed as \footnote{Hessenberg decomposition works only for square matrices, therefore least square solution is needed.}

to reach , square matrix  can be decomposed using hessenberg decomposition.

where Q  is a unitary matrix and U is an upper hessenberg matrix. When  is substituted in (\ref{hesselm1})





where U is an upper hessenberg matrix that is also symmetric and tridiagonal. When considering singularity conditions, it is reached that  and matrix U is non-singular therefore,  exists. Target values are reached and learning are achieved as follows, output weights are reached and put in its place in \ref{elm3}.

\subsection{Leave-One-Out (LOO) Error Based Optimization}
Leave-one-out (LOO) is a parameter optimization and model selection method used in machine learning. LOO method is used to select optimum regularization parameter  in (\ref{elm4}) that minimizes mean square error predicted residual sum of squares  in \ref{loo1}.  is calculated as,


where  is  diagonal  value on diagonal of . Using \ref{hesselm1} HAT is calculated as,


Cao et. al \cite{ref18} introduced implementation of  in ELM with SVD method in (\ref{loo3}).


   



H matrix is decomposed into  using SVD method. Note that in \ref{loo3} calculation of HAT is irrelevant with U. In this study implementation of  in ELM with hessenberg decomposition method was introduced MATLAB scripts for regularized hessenberg decomposition based ELM (R-HessELM) is shared for practitioners \footnote{https://github.com/apdullahyayik/Regularized-HessELM}




\begin{table*}
\centering
\caption{Performances of CHF prediction}
\label{Table1}
\begin{tabular}{@{}llccc@{}}
\toprule
Feature Model                     & Classifier   & Precision (\%) & Sensitivity (\%) & Overall Accuracy (\%) \\ \midrule
\multirow{4}{*}{Circled Entropy}  & ELM          & 92.05          & 93.25            & 92.42                  \\
                                  & R-ELM ()     & 93.37          & 94.36            & 93.43                  \\
                                  & HessELM      & 92.73          & 93.91            & 93.93                  \\
                                  & R-HessELM () & 97.26          & 97.77            & 96.36                  \\
\multirow{4}{*}{Inclined Entropy} & ELM          & 97.2           & 97.87            & 97.98                  \\
                                  & R-ELM ()     & 97.09          & 98.04            & 98.48                  \\
                                  & HessELM      & 96.95          & 97.39            & 97.87                  \\
                                  & R-HessELM () & 98.05          & 98.3             & \textit{98.49}                  \\
\multirow{4}{*}{Squared Entropy}  & ELM          & 95.37          & 96.06            & 95.45                  \\
                                  & R-ELM ()     & 96.69          & 97.12            & 95.55                  \\
                                  & HessELM      & 96.32          & 97.09            & 96.26                  \\
                                  & R-HessELM () & 97.47          & 97.98            & 96.76                  \\
\multirow{4}{*}{Grid Entropy}     & ELM          & 91.32          & 92.85            & 95.05                  \\
                                  & R-ELM ()     & 92.41          & 93.73            & 95.96                  \\
                                  & HessELM      & 92.87          & 94.31            & 95.75                  \\
                                  & R-HessELM () & 93.98          & 95.15            & 96.16                  \\ \cmidrule(l){1-5} 
\end{tabular}
\end{table*}

Algorithm 1 provides the detail implementation of LOO based output layer weight matrix calculation with regularized HessELM.

\begin{algorithm}
\caption{Computing weights with regularized HessELM}\label{alg:euclid}
\begin{algorithmic}[1]\\
Calculate Hessenberg Decomposition of , 
\Procedure{Compute Weights}{}
\While{} 
\State 
\State 
\State 
\State 
\State 
\EndWhile{\textbf{end}}
\State \textbf{find}  corresponding to \textbf{min}()
\State \\
\Return 
\EndProcedure
\end{algorithmic}
\end{algorithm}


\begin{figure*}\subfigure[]{\label{fig:A1}\includegraphics[width=0.33\textwidth]{Fig4_a.png}
            }\subfigure[]{\label{fig:B1}\includegraphics[width=0.35\textwidth]{Fig4_b.png}
            }\\
\subfigure[]{\label{fig:C1}\includegraphics[width=0.35\textwidth]{Fig4_c.png}
            }\subfigure[]{\label{fig:D1}\includegraphics[width=0.35\textwidth]{Fig4_d.png}
           }\\
\subfigure[]{\label{fig:E1}\includegraphics[width=0.35\textwidth]{Fig4_e.png}
            }\subfigure[]{\label{fig:F1}\includegraphics[width=0.35\textwidth]{Fig4_f.png}
            }\\
\subfigure[]{\label{fig:G1}\includegraphics[width=0.35\textwidth]{Fig4_g.png}
            }\subfigure[]{\label{fig:H1}\includegraphics[width=0.35\textwidth]{Fig4_h.png}
            }
\caption{Overall accuracy and  values with regard to regularization parameter of ELM with (a.1)  circled, (b.1) squared, (c.1) inclined (d.1) grid entropy measurements and HessELM with (a.2)  circled, (b.2) squared, (c.2) inclined (d.2) grid entropy measurements}\label{figure5}\end{figure*}


\section{Results and Conclusions}
\label{resultsandconclusions}
In this study we proposed pattern recognition approach for predicting CHF medical condition from ECG recordings. Optimally selection of regularization parameter of ELM with SVD in \cite{ref18} was extended to ELM with hessenberg decomposition introduced in \cite{ref19}. The designed system used 4 number of entropy measurements, CEM, SEM, IEM and GEM of SODP in ECG time-series, as discriminative features. The presented R-HessELM, which uses IEM features resulted in an overall accuracy of 98.49\%.

In Figure \ref{figure5}, the effect of regularization parameter (between  and ) on both overall accuracy and  value for ELM and HessELM classifiers with proposed feature models are shown. One can see that larger regularization parameter yields to   larger  value and lower performance accuracy. As it is suggested   and performances are inversely proportional with each other \ref{result1} in particular between  and . If regularization parameter converges to zero, performances do not rise although  value decreases. Therefore, in proposed classifier model, first task should be selecting optimum regularization parameter with regard to only minimum   value, not performances to reduce complexity.



\begin{table*}
\centering
\caption{Comparisons of studies}
\label{table2}
\begin{tabular}{@{}llllll@{}}
\toprule
Study                   & Class                                                                                             & Feature Model                                                                                                                 & Feature Size & Classifier                                                             & Overall Accuracy (\%)                                            \\ \midrule
Asyal{\i}, 2003  \cite{ref35}          & Normal CHF                                                                                        & \begin{tabular}[c]{@{}l@{}}Standard Deviation\\ Normal to Normal\end{tabular}                                                 & -            & BayesNET                                                               & 89.95                                                            \\
\.{I}\c{s}ler and Kuntalp, 2007 \cite{ref13}  & Normal CHF                                                                                        & \begin{tabular}[c]{@{}l@{}}Wavelet Entropy\\ Poincare Plot\\ Fast Fourier  Transform\\ Genetic feature selection\end{tabular} & 9            & k-nn                                                                   & 93.98                                                            \\
Ubeyli, 2009   \cite{ref36}         & \begin{tabular}[c]{@{}l@{}}NormalCHF\\ Ventricular Arrhythmia \\ Atrial Fibrillation\end{tabular} & Eigenvector Method                                                                                                            & -            & \begin{tabular}[c]{@{}l@{}}Recurrent Neural\\ Network\end{tabular}     & 98.06                                                            \\
Thuraisingham, 2009 \cite{ref33}    & Normal CHF                                                                                        & \begin{tabular}[c]{@{}l@{}}SODP Central \\ Tendency\end{tabular}                                                              & -            & k-nn                                                                   & Almost 100\%                                                     \\
Kamath, 2012 \cite{ref34}            & Normal CHF                                                                                        & \begin{tabular}[c]{@{}l@{}}Teager Energy of \\ Poincare Plot\end{tabular}                                                     & -            &                                                                        & Almost 100\%                                                     \\
Yu and Lee, 2012 \cite{ref26}       & Normal CHF                                                                                        & \begin{tabular}[c]{@{}l@{}}Bispectrum-related \\ features, Genetic \\ feature selection\end{tabular}                          & -            & SVM                                                                    & 96.38                                                            \\
Yu and Lee, 2012 \cite{ref27}        & Normal CHF                                                                                        & \begin{tabular}[c]{@{}l@{}}UCIMFS, MIFS,CMIFS,\\ mRMR and\\ MI-based greedy\\ feature selection\end{tabular}                  & 15           & SVM                                                                    & 97.59                                                            \\
Orhan, 2013  \cite{ref32}           & Normal CHF                                                                                        & \begin{tabular}[c]{@{}l@{}}Equal Frequency in \\ Amplitude(EFiA)\\ Equal Width in Time\\ (EWiE)\end{tabular}                  & -            & \begin{tabular}[c]{@{}l@{}}Linear \\ Regression\end{tabular}           & 99.3                                                             \\
Liu et al., 2014 \cite{ref28}      & Normal CHF                                                                                        & \begin{tabular}[c]{@{}l@{}}Three nonstandard\\ HRVmeasures\\ (i.e. SUM\_TD, \\ SUM\_FD and \\ SUM\_IE)\end{tabular}           & -            & SVM                                                                    & 100                                                              \\
Narin et. al, 2014 \cite{ref29}     & Normal CHF                                                                                        & \begin{tabular}[c]{@{}l@{}}Wavelet Transform\\ Backward elimination\\ Method\end{tabular}                                     & -            & SVM                                                                    & 91.56                                                            \\
Heinze et al., 2014 \cite{ref30}    & Normal CHF                                                                                        & Power spectral Density                                                                                                         & -            & \begin{tabular}[c]{@{}l@{}}Learning Vector\\ Quantization\end{tabular} & \begin{tabular}[c]{@{}l@{}}13.6\% error\\ at 50 min\end{tabular} \\
Majahan et al., 2017 \cite{ref31}   & Normal CHF                                                                                        & \begin{tabular}[c]{@{}l@{}}Probabilistic symbol\\ pattern Recognition\end{tabular}                                            & -            & \begin{tabular}[c]{@{}l@{}}Decision\\ Trees\end{tabular}               & 99.5                                                             \\
Acharya et al., 2017 \cite{ref37}      & Normal CHF                                                                                        & \begin{tabular}[c]{@{}l@{}}Empirical mode \\ Decomposition\end{tabular}                                                       & 13           & SVM                                                                    & 97.64                                                            \\
This study              & Normal CHF                                                                                        & \begin{tabular}[c]{@{}l@{}}Incline Entropy  \\ Measures (IEM) \\ of SODP\end{tabular}                                         & 17           & \begin{tabular}[c]{@{}l@{}}Regularized\\ HessELM\end{tabular}          & 98,41                                                            \\ \bottomrule
\end{tabular}
\end{table*}


5 fold cross-validated classification performances with selected specific regularization parameter are detailed in Table \ref{Table1}. The highest overall accuracy was achieved with 98.49\%, precision with 98.05\% and sensitivity with 98.30\% using hessenberg decomposition based extreme learning machine () and IEM features. Since amplitude and interval of R peaks have significant and discriminant role in CHF medical condition of ECG recordings, IEM features that capture wide-range of changes, in particular R peaks,  result in better performance than other approaches for CHF prediction.


\section{Discussion}
\label{discussion}
Our study shows that the use of regularized HessELM which considers effective pseudoinversing to predict the medical condition of ECG signal can yield considerably high performances. Entropy measurements of SODP on Cartesian system aimed at describing the amplitude  distributions of ECG time-series.

As suggested by the SODPs in Figure \ref{figure3} it appears to be a difference on data distribution, with normal recordings fewer points at the center of Cartesian system than CHF ones. This tendency is captured by the utilized entropy measurements, which works as effective predictors. The early predictions of  CHF result in successfully managing the treatment process and preventive revulsion for medical purposes. The predisposition of the embedded systems into medical processes with high prediction performance rates of precision, sensitivity, and overall accuracy provides enhancing the diagnostic tools. Consistency of performance observed would imply the possibility of designing embedded systems of CHF predictors.

HessELM model has the ability to perform more accurate performances than  conventional one using various entropy measurements on SODP. Furthermore, regularized approaches of both models could achieve high performance  when regularization parameter was chosen between e-10 and e-18. The SODP dispersion of the ECG signals from both healthy and CHF subjects pictures as an elliptical-shaped form on Cartesian system. IEM features enable most detailed quantization of the SODP considering the characteristics of such elliptical-shape. In other words, it performs segmentation of SODP depending on the slope of the propagation. That is why it is the most responsible entropy measurement for CHF predictions on ECG signals.
To improve the performance rate of extreme learning machines, further investigations need to be performed. For instance, a robust feature selection algorithm that provides rejection of redundant information from ECG data, may lead to even higher prediction performances.

\section*{\small{Compliance with ethical standards}}
\textbf{\small{Conflict of interest}} \small{The authors declare that there is no conflict of interest.}

\bibliographystyle{spmpsci}      \begin{thebibliography}{10}
\providecommand{\url}[1]{{#1}}
\providecommand{\urlprefix}{URL }
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{DOI~\discretionary{}{}{}#1}\else
  \providecommand{\doi}{DOI~\discretionary{}{}{}\begingroup
  \urlstyle{rm}\Url}\fi

\bibitem{ref37}
Acharya, U.R., Fujita, H., Sudarshan, V.K., Oh, S.L., Muhammad, A., Koh, J.E.,
  Tan, J.H., Chua, C.K., Chua, K.P., San~Tan, R.: Application of empirical mode
  decomposition (emd) for automated identification of congestive heart failure
  using heart rate signals.
\newblock Neural Computing and Applications \textbf{28}(10), 3073--3094 (2017)

\bibitem{ref20}
{A.L. Goldberger and coworkers}: {PhysioBank, PhysioToolkit, and PhysioNet:
  Components of a New Research Resource for Complex Physiologic Signals}.
\newblock Circulation 101(23):e215-e220  (2000)

\bibitem{ref17}
Altan, G., Kutlu, Y., Allahverdi, N.: {A new approach to early diagnosis of
  congestive heart failure disease by using Hilbert--Huang transform}.
\newblock Computer methods and programs in biomedicine \textbf{137}, 23--34
  (2016)

\bibitem{ref7}
Anuradha, B., Reddy, V.C.V.: {Cardiac Arrhythmia Classification Using Fuzzy
  Classifiers}.
\newblock Journal of Theoretical and Applied Information Technology pp.
  353--359 (2008)

\bibitem{ref35}
Asyali, M.H.: {Discrimination Power of Long-Term Heart Rate Variability
  Measures}.
\newblock 25th Annual International Conference of the IEEE Engineering in
  Medicine and Biology Society, Cancun, pp. 4--7 (2003)

\bibitem{ref18}
Cao, J., Zhang, K., Luo, M., Yin, C., Lai, X.: {Extreme learning machine and
  adaptive sparse representation for image classification}.
\newblock Neural networks \textbf{81}, 91--102 (2016)

\bibitem{ref1}
Donkor, A., McDonagh, T., Hardman, S.: {British Heart Failure Report}.
\newblock Tech. rep., Institute of Cardiovascular Science (2016)

\bibitem{ref23}
Golub, G.H., Reinsch, C.: {Singular value decomposition and least squares
  solutions}.
\newblock Numerische Mathematik \textbf{14}(5), 403--420 (1970)

\bibitem{ref30}
Heinze, C., Sommer, D., Trutschel, U., Golz, M.: Discrimination and relevance
  determination of heart rate variability features for the identification of
  congestive heart failure.
\newblock In: Cardiovascular Oscillations (ESGCO), 2014 8th Conference of the
  European Study Group on, pp. 219--220. IEEE (2014)

\bibitem{ref3}
Homaeinezhad, M., Atyabi, S., Tavakkoli, E., Toosi, H., Ghaffari, A.,
  Ebrahimpour, R.: {ECG arrhythmia recognition via a neuro-SVM–KNN hybrid
  classifier with virtual QRS image-based geometrical features}.
\newblock Expert Systems with Applications \textbf{39}(2), 2047--2058 (2012).
\newblock \doi{10.1016/j.eswa.2011.08.025}

\bibitem{ref24}
Horata, P., Chiewchanwattana, S., Sunat, K.: {Robust extreme learning machine}.
\newblock Neurocomputing \textbf{102}, 31--44 (2013)

\bibitem{ref5}
Hossen, A., Al-Ghunaimi, B.: {A wavelet-based soft decision technique for
  screening of patients with congestive heart failure}.
\newblock Biomedical Signal Processing and Control \textbf{2}(2), 135--143
  (2007).
\newblock \doi{10.1016/j.bspc.2007.05.008}

\bibitem{ref22}
Huang, G.b., Zhu, Q.y., Siew, C.k.: {Extreme learning machine : Theory and
  applications}.
\newblock Neurocomputing \textbf{70}, 489--501 (2006).
\newblock \doi{10.1016/j.neucom.2005.12.126}

\bibitem{ref13}
I\c{s}ler, Y., Kuntalp, M.: {Combining classical HRV indices with wavelet
  entropy measures improves to performance in diagnosing congestive heart
  failure.}
\newblock Computers in biology and medicine \textbf{37}(10), 1502--10 (2007).
\newblock \doi{10.1016/j.compbiomed.2007.01.012}

\bibitem{ref34}
Kamath, C.: {A new approach to detect congestive heart failure using sequential
  spectrum of electrocardiogram signals.}
\newblock Medical engineering {\&} physics \textbf{34}(10), 1503--9 (2012).
\newblock \doi{10.1016/j.medengphy.2012.03.001}

\bibitem{ref11}
Kamath, C.: {A new approach to detect congestive heart failure using Teager
  energy nonlinear scatter plot of R-R interval series.}
\newblock Medical engineering {\&} physics \textbf{34}(7), 841--8 (2012).
\newblock \doi{10.1016/j.medengphy.2011.09.026}

\bibitem{ref14}
Karmakar, C.K., Gubbi, J., Khandoker, A.H., Palaniswami, M.: {Analyzing
  temporal variability of standard descriptors of Poincar{\'{e}} plots.}
\newblock Journal of electrocardiology \textbf{43}(6), 719--24 (2010).
\newblock \doi{10.1016/j.jelectrocard.2010.09.001}

\bibitem{ref28}
Liu, G., Wang, L., Wang, Q., Zhou, G., Wang, Y., Jiang, Q.: A new approach to
  detect congestive heart failure using short-term heart rate variability
  measures.
\newblock PloS one \textbf{9}(4), e93,399 (2014)

\bibitem{ref31}
Mahajan, R., Viangteeravat, T., Akbilgic, O.: Improved detection of congestive
  heart failure via probabilistic symbolic pattern recognition and heart rate
  variability metrics.
\newblock International journal of medical informatics \textbf{108}, 55--63
  (2017)

\bibitem{ref21}
Martis, R.J., Acharya, U.R., Lim, C.M., Suri, J.S.: {Characterization of ECG
  beats from cardiac arrhythmia using discrete cosine transform in PCA
  framework}.
\newblock Knowledge-Based Systems \textbf{45}, 76--82 (2013).
\newblock \doi{10.1016/j.knosys.2013.02.007}

\bibitem{ref12}
{Maurice E.Cohen}, D.L.H., Deedwania, P.C.: {Applying Continuous chaotic
  Modeling to Cardiac Signal Analysis}.
\newblock Engineering in Medicine and Biology pp. 97--102 (1996)

\bibitem{ref6}
Moavenian, M., Khorrami, H.: {A qualitative comparison of Artificial Neural
  Networks and Support Vector Machines in ECG arrhythmias classification}.
\newblock Expert Systems with Applications \textbf{37}(4), 3088--3093 (2010).
\newblock \doi{10.1016/j.eswa.2009.09.021}

\bibitem{ref29}
Narin, A., Isler, Y., Ozer, M.: Investigating the performance improvement of
  hrv indices in chf using feature selection methods based on backward
  elimination and statistical significance.
\newblock Computers in biology and medicine \textbf{45}, 72--79 (2014)

\bibitem{ref32}
Orhan, U.: {Real-time CHF detection from ECG signals using a novel
  discretization method.}
\newblock Computers in biology and medicine \textbf{43}(10), 1556--62 (2013).
\newblock \doi{10.1016/j.compbiomed.2013.07.015}

\bibitem{ref2}
Ponikowski, P., Voors, A.A., Anker, S.D., Bueno, H., Cleland, J.G.F., Coats,
  A.J.S., Falk, V., Gonz{\'{a}}lez-Juanatey, J.R., Harjola, V.P., Jankowska,
  E.A., Others: {2016 ESC Guidelines for the diagnosis and treatment of acute
  and chronic heart failure: The Task Force for the diagnosis and treatment of
  acute and chronic heart failure of the European Society of Cardiology (ESC)
  Developed with the special contribution o}.
\newblock European heart journal \textbf{37}(27), 2129--2200 (2016)

\bibitem{ref4}
Rai, H.M., Trivedi, A., Shukla, S.: {ECG signal processing for abnormalities
  detection using multi-resolution wavelet transform and Artificial Neural
  Network classifier}.
\newblock Measurement \textbf{46}(9), 3238--3246 (2013).
\newblock \doi{10.1016/j.measurement.2013.05.021}

\bibitem{ref15}
Thuraisingham, R.: {A Classification System to Detect Congestive Heart Failure
  Using Second-Order Difference Plot of RR Intervals.}
\newblock Cardiology research and practice \textbf{2009}, 807,379 (2010).
\newblock \doi{10.4061/2009/807379}

\bibitem{ref33}
Thuraisingham, R.: {A Classification System to Detect Congestive Heart Failure
  Using Second-Order Difference Plot of RR Intervals.}
\newblock Cardiology research and practice \textbf{2009}, 807,379 (2010).
\newblock \doi{10.4061/2009/807379}

\bibitem{ref9}
Tsipouras, M.G., Fotiadis, D.I., Sideris, D.: {An arrhythmia classification
  system based on the RR-interval signal.}
\newblock Artificial intelligence in medicine \textbf{33}(3), 237--50 (2005).
\newblock \doi{10.1016/j.artmed.2004.03.007}

\bibitem{ref25}
Tzeng, J.: {Split-and-combine singular value decomposition for large-scale
  matrix}.
\newblock Journal of Applied Mathematics  (2013)

\bibitem{ref36}
{\"U}beyli, E.D., G{\"u}ler, {\.I}.: Features extracted by eigenvector methods
  for detecting variability of eeg signals.
\newblock Pattern Recognition Letters \textbf{28}(5), 592--603 (2007)

\bibitem{ref19}
Yayik, A.: {Enhancing Extreme Learning Machine: Novel Extensions and
  Applications to Optimizing Visual Stimuli for Brain Computer Interface}.
\newblock Ph.D. thesis, Mustafa Kemal University, Graduate School and Applied
  Sciences, Department of Informatics Doctorate Thesis (2017)

\bibitem{ref8}
Yayik, A., Kutlu, Y.: {Diagnosis of congestive heart failure using Poincare map
  plot}.
\newblock In: 2012 20th Signal Processing and Communications Applications
  Conference, SIU 2012, Proceedings (2012).
\newblock \doi{10.1109/SIU.2012.6204457}

\bibitem{ref26}
Yu, S.N., Lee, M.Y.: Bispectral analysis and genetic algorithm for congestive
  heart failure recognition based on heart rate variability.
\newblock Computers in biology and medicine \textbf{42}(8), 816--825 (2012)

\bibitem{ref27}
Yu, S.N., Lee, M.Y.: Conditional mutual information-based feature selection for
  congestive heart failure recognition using heart rate variability.
\newblock Computer methods and programs in biomedicine \textbf{108}(1),
  299--309 (2012)

\bibitem{ref16}
Zheng, Y., Guo, X., Qin, J., Xiao, S.: {Computer-assisted diagnosis for chronic
  heart failure by the analysis of their cardiac reserve and heart sound
  characteristics}.
\newblock Computer methods and programs in biomedicine \textbf{122}(3),
  372--383 (2015)

\bibitem{ref10}
Zidelmal, Z., Amirou, A., Ould-Abdeslam, D., Merckle, J.: {ECG beat
  classification using a cost sensitive classifier.}
\newblock Computer methods and programs in biomedicine \textbf{111}(3), 570--7
  (2013).
\newblock \doi{10.1016/j.cmpb.2013.05.011}

\end{thebibliography}
 





\end{document}
