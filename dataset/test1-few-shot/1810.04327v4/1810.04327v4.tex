

\documentclass{article}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} 

  
\usepackage{hyperref}

\newcommand{\theHalgorithm}{\arabic{algorithm}}



\usepackage[accepted]{icml2019}

\icmltitlerunning{Complementary-Label Learning for Arbitrary Losses and Models}

\usepackage{amsmath,amsthm,amsfonts,amssymb}
\usepackage{bm}
\usepackage{comment}
\usepackage{tablefootnote}
\usepackage{multirow}
\usepackage{hhline}\usepackage{graphicx}


\usepackage{algorithm,algorithmic}



\usepackage[font=small,labelfont=bf]{caption}
\usepackage{url}

\newcommand{\average}[1]{\ensuremath{\langle#1\rangle} }
\newcommand{\jump}[1]{\ensuremath{[\![#1]\!]} }
\DeclareMathOperator*{\argmin}{\mathrm{arg\,min}}
\DeclareMathOperator*{\argmax}{\mathrm{arg\,max}}
\newcommand{\bmA}{\bm{A}}\newcommand{\bmB}{\bm{B}}\newcommand{\bmC}{\bm{C}}\newcommand{\bmD}{\bm{D}}\newcommand{\bmE}{\bm{E}}\newcommand{\bmF}{\bm{F}}\newcommand{\bmG}{\bm{G}}\newcommand{\bmH}{\bm{H}}\newcommand{\bmI}{\bm{I}}\newcommand{\bmJ}{\bm{J}}\newcommand{\bmK}{\bm{K}}\newcommand{\bmL}{\bm{L}}\newcommand{\bmM}{\bm{M}}\newcommand{\bmN}{\bm{N}}\newcommand{\bmO}{\bm{O}}\newcommand{\bmP}{\bm{P}}\newcommand{\bmQ}{\bm{Q}}\newcommand{\bmR}{\bm{R}}\newcommand{\bmS}{\bm{S}}\newcommand{\bmT}{\bm{T}}\newcommand{\bmU}{\bm{U}}\newcommand{\bmV}{\bm{V}}\newcommand{\bmW}{\bm{W}}\newcommand{\bmX}{\bm{X}}\newcommand{\bmY}{\bm{Y}}\newcommand{\bmZ}{\bm{Z}}\newcommand{\bma}{\bm{a}}\newcommand{\bmb}{\bm{b}}\newcommand{\bmc}{\bm{c}}\newcommand{\bmd}{\bm{d}}\newcommand{\bme}{\bm{e}}\newcommand{\bmf}{\bm{f}}\newcommand{\bmg}{\bm{g}}\newcommand{\bmh}{\bm{h}}\newcommand{\bmi}{\bm{i}}\newcommand{\bmj}{\bm{j}}\newcommand{\bmk}{\bm{k}}\newcommand{\bml}{\bm{l}}\newcommand{\bmm}{\bm{m}}\newcommand{\bmn}{\bm{n}}\newcommand{\bmo}{\bm{o}}\newcommand{\bmp}{\bm{p}}\newcommand{\bmq}{\bm{q}}\newcommand{\bmr}{\bm{r}}\newcommand{\bms}{\bm{s}}\newcommand{\bmt}{\bm{t}}\newcommand{\bmu}{\bm{u}}\newcommand{\bmv}{\bm{v}}\newcommand{\bmw}{\bm{w}}\newcommand{\bmx}{\bm{x}}\newcommand{\bmy}{\bm{y}}\newcommand{\bmz}{\bm{z}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}

\newcommand{\pr}{\mathrm{Pr}}
\newcommand{\bE}{\mathbb{E}}
\newcommand{\bR}{\mathbb{R}}
\newcommand{\cG}{\mathcal{G}}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\cO}{\mathcal{O}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\cX}{\mathcal{X}}
\newcommand{\fR}{\mathfrak{R}}
\newcommand{\OVA}{{\mathrm{OVA}}}
\newcommand{\PC}{{\mathrm{PC}}}

\begin{document}

\twocolumn[
\icmltitle{Complementary-Label Learning for Arbitrary Losses and Models}







\begin{icmlauthorlist}
\icmlauthor{Takashi Ishida}{utokyo,riken}
\icmlauthor{Gang Niu}{riken}
\icmlauthor{Aditya Krishna Menon}{google}
\icmlauthor{Masashi Sugiyama}{riken,utokyo}
\end{icmlauthorlist}

\icmlaffiliation{utokyo}{The University of Tokyo}
\icmlaffiliation{riken}{RIKEN}
\icmlaffiliation{google}{Google Research}

\icmlcorrespondingauthor{Takashi Ishida}{ishida@ms.k.u-tokyo.ac.jp}

\icmlkeywords{complementary labels, weakly-supervised learning}

\vskip 0.3in
]





\printAffiliationsAndNotice{}  

\begin{abstract}
In contrast to the standard classification paradigm where
the true class is given to each training pattern,
\emph{complementary-label learning} only uses training patterns each equipped
with a complementary label,
which only specifies one of the classes that the pattern does \emph{not} belong to.
The goal of this paper is to derive a novel framework of complementary-label learning with an unbiased estimator of the classification risk, for arbitrary losses and models---all existing methods have failed to achieve this goal.
Not only is this beneficial for the learning stage, it also makes model/hyper-parameter selection (through cross-validation) possible without the need of any ordinarily labeled validation data, while using any linear/non-linear models or convex/non-convex loss functions.
We further improve the risk estimator by a non-negative correction and gradient ascent trick, and demonstrate its superiority through experiments.
\end{abstract}

\section{Introduction}
Modern classification methods usually require massive data with high-quality labels, but preparing such datasets is unrealistic in many domains.
To mitigate the problem, previous works have investigated ways to learn from weak supervision: \emph{semi-supervised learning} \citep{chapelle06SSL,miyato16iclr,kipf17iclr,sakai17icml,tarvainen17nips,oliver18neurips}, \emph{noisy-label learning} \citep{natarajan13nips,menon15icml,patrini17cvpr,ma18icml,han18neurips,charoenphakdee19icml}, \emph{positive-unlabeled learning} \citep{elkan08kdd,christo14nips,kiryo17nips}, \emph{positive-confidence learning} \citep{ishida18nips}, \emph{similar-unlabeled learning} \citep{bao18icml}, \emph{unlabeled-unlabeled learning} \citep{duPlessis13taai,nan19iclr}, and others.

In this paper, we consider learning from another natural type of weak supervision called \emph{complementary-label learning} \citep{ishida17nips,yu17eccv}, where the label only specifies one of the classes that the pattern does \emph{not} belong to.  For example, a crowdsourced worker can tell us a pattern does not belong to a certain class, instead of identifying the correct class.
In contrast to the ordinary case where the true class is given to each pattern (which often needs to be chosen out of many candidate classes precisely), collecting these complementary labels is obviously much easier and less costly.

Another potential application is collecting survey data that requires extremely private questions \citep{ishida17nips}.  It would be less mentally demanding, if we explain to the respondent that we will transform their provided true label to a complementary label, before the data is saved into the database. This might become common in the future where privacy concerns are increasing.

A natural question is, however, is it possible to learn from such complementary labels (without \emph{any} true labels)?

The problem has previously been tackled by \citet{ishida17nips},
showing that the classification risk can be recovered only from complementarily labeled data.
They also gave theoretical analysis with a statistical consistency guarantee.
However, they required strong restrictions on the loss functions, allowing only one-versus-all and pairwise comparison multi-class loss functions \citep{ova}, with certain non-convex binary losses.
This is a severe limitation since the softmax cross-entropy loss, which cannot be expressed by the two losses above, is the most popular loss in deep learning nowadays.

Later, \citet{yu17eccv} proposed a different formulation for complementary labels by employing the forward loss correction technique \citep{patrini17cvpr} to adjust the learning objective, but limiting the loss function to softmax cross-entropy loss.
Their proposed risk estimator is not necessarily \emph{unbiased} but the minimizer is theoretically guaranteed to be \emph{consistent} with the minimizer of the risk for ordinary labels (under an implicit assumption on the model for convergence analysis).
They also extended the problem setting to where complementary labels are chosen in an uneven (biased) way.

In this paper, we first derive an unbiased risk estimator with a general loss function, making \emph{any} loss functions available for use: not only the softmax cross-entropy loss function but other convex/non-convex loss functions can also be applied. We also do not have implicit assumptions on the classifier, allowing both linear and non-linear models.
We also prove that our new framework is a generalization of previous complementary-label learning \citep{ishida17nips}.

\citet{yu17eccv} does not have an unbiased risk estimator, which means users will need clean data with true labels to calculate the error rate during the validation process.
On the other hand, our proposed unbiased risk estimator can handle \emph{complementarily} labeled validation data not only for our learning objective, but also for that of \citet{yu17eccv}.
This is helpful since collecting clean data is usually much more expensive.  Note that in the example of survey with extremely private questions explained earlier, it may be impossible to even collect a small number of validation data with true labels.

Finally, our proposed unbiased risk estimator has an issue that the classification risk can attain negative values after learning, leading to overfitting.
We further propose a non-negative correction to the original unbiased risk estimator to improve our estimator.
The modified objective is no longer guaranteed to be an unbiased risk estimator, but the unbiased risk estimator can still be used for validation procedures for this modified learning objective.
We experimentally show that our proposed method is comparable to or better than previous methods \citep{ishida17nips,yu17eccv} in terms of classification accuracy.

A summary of our contributions is as follows:
\begin{itemize}
  \item We propose a new unbiased risk estimator, allowing usage of any loss (convex, non-convex) and any model (parametric, non-parametric) for complementary-label learning.
  \item This risk can be used not only as a learning objective, but as a validation criterion even for other methods, such as \citet{ishida17nips} and \citet{yu17eccv}.
  \item We further investigate correction schemes to make complementary-label learning practical and demonstrated the performance in experiments.
\end{itemize}

\begin{table*}[t]
\center
  \caption{Comparison of two proposed complementary-label methods with previous works.  We first propose a general unbiased risk estimator for complementary labels that has no restrictions on loss functions and models.  We next propose a modified non-negative formulation which solves overfitting issues and leads to better experimental results. Even though the non-negative formulation is no longer an unbiased estimator as a learning objective, the unbiased estimator can be used in the validation procedure.}
  \label{tb:compareproposed}
  \begin{tabular}{@{\ }l|ccccc@{\ }}
\toprule
\multirow{2}{*}{Methods} & \multirow{2}{*}{\shortstack{loss assump.\\free}} & \multirow{2}{*}{\shortstack{model assump.\\free}} & \multirow{2}{*}{\shortstack{unbiased\\estimator}} &  \multirow{2}{*}{\shortstack{explicit risk\\correction}} \\
&&&\\\midrule
\citet{ishida17nips} &  &  && \\
\citet{yu17eccv} &  &  &&\\\midrule
Proposed (General formulation) &  &  &&\\
Proposed (Non-negative formulation) &  &  & &\\
\bottomrule
  \end{tabular}
\end{table*}

\section{Review of previous works}
\label{sc:review}
In this section, we introduce some notations and review the formulations of learning from ordinary labels, learning from complementary labels, learning from ordinary \& complementary labels, and learning from partial labels.
\subsection{Learning from ordinary labels}
Let  be an instance space and  be the joint distribution over  for class label set , with random variables .
The data at hand is sampled independently and identically from the joint distribution: .
The joint distribution  can be either decomposed into class-conditionals  and base rate , where  and , or the marginal  and class-probability function , where ,  and  is the conditional probability simplex for  classes.
A loss is any . The decision function is any  and  is the -th element of .
The risk for the decision function  with respect to loss  and implicit distribution  is:

where  denotes the expectation.  Two useful equivalent expressions of classification risk \eqref{risk:ordinary} used in later sections are

where,

The goal of classification is to learn the decision function  that minimizes the risk.  In the usual classification case with ordinarily labeled data at hand, approximating the risk empirically is straightforward:

Some well known multi-class loss functions are one-versus-all and pairwise comparison losses:

where  is a binary loss function.
\subsection{Learning from complementary labels}
Next we consider the problem of learning from complementary labels \citep{ishida17nips}.  We observe patterns each equipped with a complementary label  sampled independently and identically from a different joint distribution .  We denote random variables as .
As before, we assume this distribution can be decomposed into either class-conditionals  and base rate , or marginal  and class-probability function , where , , , , and  is the complementary label.

Without any assumptions on , it is impossible to design a suitable learning procedure.
The assumption for unbiased complementary learning used in \citet{ishida17nips} was


where  is a matrix that takes  on diagonals and  on non-diagonals.

This assumption implies all other labels are chosen with uniform probability.  This can be forced by designing the data collecting system to first pick up a label randomly and then ask the worker if the data belong to the label with a yes or no.  When the answer is no, we will attach that label as the complementary label, and the data will follow the uniform assumption.
Under this assumption, \citet{ishida17nips} proved that they can recover the classification risk \eqref{risk:ordinary} from an alternative formulation using only complementarily labeled data when the loss function satisfies certain conditions.
More specifically, usable loss functions are one-versus-all or pairwise comparison multi-class loss functions \citep{ova}:

each with binary loss function  that satisfies , such as ramp loss  or sigmoid loss .

Having an unbiased risk estimator is also helpful for the validation process.  Since we do not have ordinary labels in our validation set in the complementary-label learning setting, we cannot follow the usual validation procedure that uses zero-one error or accuracy.  If we have an unbiased estimator of the original classification risk (which can be interpreted as zero-one error), we can use the empirical risk for (cross)-validated complementary data to select the best hyper-parameter or deploy early stopping.

An extension of the above method was considered in \citet{yu17eccv} by using a different assumption than \eqref{unbiased-complementary-label-assumption}:
there is some bias amongst the possible complementary labels that can be chosen, thus the non-diagonals of  is not restricted to .
However, one will need to estimate  beforehand, which is fairly difficult without strong assumptions.
Furthermore, in this setup, it is necessary to encourage the worker to provide more difficult complementary labels, for example, by giving higher rewards to certain classes.  Otherwise, the complementary label given by the worker may be too obvious and uninformative.  Even though the two assumptions are mathematically similar, the data generation process may be different.  In this paper we focus on the former assumption.

Unlike \citet{ishida17nips}, \citet{yu17eccv} did not directly provide a risk estimator, but they showed that the \emph{minimizer} of their learning objective agrees with the minimizer of the original classification risk \eqref{risk:ordinary}.
Note that, in their formulation, the loss function is restricted to the softmax cross-entropy loss. Furthermore, the use of a highly non-linear model is supposed for consistency guarantee in their theoretical analysis.
Since the learning objective of \citet{yu17eccv} does not correspond to the classification risk, one will need clean data with true labels to calculate the error rate during the validation process.
On the other hand, our proposed risk estimator in this paper can cope with \emph{complementarily} labeled validation data not only for our own learning objective, but can be used to select hyper-parameters for others such as \citet{yu17eccv}.

\subsection{Learning from ordinary \& complementary labels}
In many practical situations, we may also have ordinarily labeled data in addition to complementarily labeled data.  \citet{ishida17nips} touched on the idea of crowdsourcing for an application with both types of data.
For example, we may choose one of the classes randomly by following the uniform distribution, with probability  for each class, and ask crowdworkers whether a pattern belongs to the chosen class or not.
Then the pattern is treated as ordinarily labeled if the answer is yes; otherwise, the pattern is regarded as complementarily labeled.
If the true label was  for a pattern, we can naturally assume that the crowdworker will answer yes by 
 and no by .
This way, ordinarily labeled data can be regarded as patterns from , and complementarily labeled data from , justifying the assumption of unbiased complementary learning \eqref{unbiased-complementary-label-assumption}.

In \citet{ishida17nips}, they considered a convex combination of the classification risks derived from ordinarily labeled data and complementarily labeled data:

where  and  is a hyper-parameter that interpolates between the two risks.
The combined (also unbiased) risk estimator can utilize both kinds of data in order to obtain better classifiers, which was demonstrated to perform well in experiments.

\subsection{Learning from partial labels}
In \emph{learning from partial labels} \citep{partial}, a candidate set of labels (which includes the correct class) is given to each pattern.  A different way to view complementary label is a candidate set that includes every class except the complementary label.  Even though the proposed method of \citet{partial} shows statistical consistency, it does not give an unbiased estimator of the classification risk.  Further, it has different assumptions, e.g., dominance relation, while \citet{ishida17nips} and this paper focus on  assumption \eqref{unbiased-complementary-label-assumption} with different data generation process and applications.

\section{Proposed method}\label{sc:proposed_method}
As discussed in the previous section, the method by \citet{ishida17nips} works well in practice, but it has restriction on the loss functions---the popular softmax cross-entropy loss is not allowed.
On the other hand, the method by \citet{yu17eccv} allows us to use the softmax cross-entropy loss, but it does not directly provide an estimator of the classification risk and thus model selection is problematic in practice.

We first describe our general unbiased risk formulation in Section \ref{sc:general_risk_formulation}.
Then we discuss how the estimator can be further improved in Section \ref{sec:necessity}.
Thirdly, we propose a way for our risk estimator to avoid overfitting by a \emph{non-negative risk estimator} in Section \ref{sc:nn_risk_estimator}.
Finally, we show practical implementation of our risk estimator with stochastic optimization methods in Section \ref{sc:implementation}.

\subsection{General risk formulation}
\label{sc:general_risk_formulation}
First, we describe our general unbiased risk formulation.
We give the following theorem, which allows unbiased estimation of the classification risk from complementarily labeled patterns:
\begin{theorem}\label{theorem:R(f)}
For any ordinary distribution  and complementary distribution  related by \eqref{unbiased-complementary-label-assumption} with decision function , and loss , we have

for the complementary loss

or equivalently,

where
 is a  identity matrix and  is a -dimensional column vector with  in each element.
\end{theorem}
Proof can be found in Appendix \ref{sec:theorem1proof}.
It is worth noting that, in the above derivation,
there are no constraints on the loss
function and classifier.
Thus, we can use any loss (convex/non-convex) and any model (linear/non-linear, parametric/non-parametric) for complementary learning.

Next, we show the relationship between our proposed framework and previous complementary-label learning \citep{ishida17nips}.
\begin{corollary}\label{corollary}
If one-versus-all loss \eqref{comp-ova} or pairwise comparison loss \eqref{comp-pc} is used with binary loss function that satisfy , the classification risk can be written as,

where  and  are non-negative constants that satisfy  for all  and  for all  and .
\end{corollary}
Proof can be found in Appendix \ref{sec:corollary2proof}.  Since this is equivalent to the first two Theorems in \citet{ishida17nips}, our proposed version is a generalization of the previous unbiased complementary-label learning framework.

The key idea of the proof in Theorem \ref{theorem:R(f)} is to not rely on the condition
that  is a constant for all ,
used in \citet{ishida17nips}, which is inspired by the property of binary 0-1 loss ,
where  is  if  and  otherwise.
Such a technique was also used when designing unbiased risk estimators for learning from positive and unlabeled data in a binary classification setup \citep{christo14nips}, but was later shown to be unnecessary \citep{christo15icml}.
Note that Theorem \ref{theorem:R(f)} can be regarded as a special case of a framework proposed for learning from weak labels \citep{jesus14ecml}.

By using \eqref{scalar_complementary_loss}, the classification risk can be written as

Here, we rearrange our complementarily labeled dataset as , where  denotes the samples complementarily labeled as class .
Then, this expression of the classification risk can be approximated by,

where  is the number of patterns complementarily labeled as the th class.

\subsection{Necessity of risk correction}
\label{sec:necessity}
The original expression of the classification risk \eqref{risk:ordinary} includes an expectation over non-negative loss , so the risk and its empirical approximator are both lower-bounded by zero.
On the other hand, the expression \eqref{risk:general_complementary} derived above contains a negative element. Although \eqref{risk:general_complementary} is still non-negative by definition, due to the negative term, its empirical estimator can go negative, leading to over-fitting.

\begin{figure*}
\centering
  \centering
  \includegraphics[bb = 0 0 1376 259, scale = 0.50]{3figs.png}
  \caption{The left and middle graphs shows the total risk \eqref{emp:general} (in black color) and the risk decomposed into each \emph{ordinary} class term \eqref{eq:counterparts} (in other colors) for training data with linear and MLP models, respectively.
  The right graph shows the corresponding test accuracy for both models.}
  \label{fig:negativerisk}
\end{figure*}

We elaborate on this issue with an illustrative numerical example.
In the left graph of Figure \ref{fig:negativerisk}, we show an example of training a linear model trained on the handwritten digits dataset MNIST\footnote{See \url{http://yann.lecun.com/exdb/mnist/}.}, with complementary labels generated to satisfy \eqref{unbiased-complementary-label-assumption}.  We used \emph{Adam} \citep{kingma15iclr} for optimization with learning rate , mini-batch size of 100, and weight decay of  with 300 epochs.  The empirical classification risk \eqref{emp:general} is shown in black.
We can see that the empirical classification risk continues decreasing and can go below zero at around 100 epochs.  The test accuracy on the right graph hits the peak also at around epoch 100 and then the accuracy gradually deteriorates.

This issue stands out even more significantly when we use a flexible model.  The middle graph shows the empirical classification risk for a multilayer perceptron (MLP) with one hidden layer ( units), where \emph{ReLU} \citep{relu} was used as the activation function.
The optimization setup was the same as the case of the linear model above.
We can see the empirical risk decreasing much more quickly and going negative.
Correspondingly, as the right graph shows, the test accuracy drops significantly after the empirical risk goes negative.

In fact, a similar issue is already implicit in the original paper by \citet{ishida17nips}: According to Corollary \ref{corollary} (or Theorem 1 in \citet{ishida17nips}), the unbiased risk estimator includes subtraction of a positive constant term which increases with respect to the number of classes.
This means that the learning objective of \citet{ishida17nips} has a (negative) lower bound.

\subsection{Non-negative risk estimator}
\label{sc:nn_risk_estimator}
As we saw in Section \ref{sec:necessity}, our risk estimator can suffer from overfitting due to the non-negative issue.
Here, we propose a correction to the risk estimator to overcome this problem.

Each term in the risk with ordinary labels (right-hand side of \eqref{risk:class_prior_decomposition}), which corresponds to each class, is non-negative.
We can reformulate \eqref{risk:general_complementary} in order to show the counterpart for each non-negative term in the right-hand side of \eqref{risk:class_prior_decomposition} for complementarily labeled data as

These counterparts \eqref{eq:counterparts} were originally non-negative when ordinary labels were used.
In the left and middle graphs of Figure \ref{fig:negativerisk}, we plot the decomposed risks with respect to each \emph{ordinary} class \eqref{eq:counterparts} (shown in different colors).
We can see that the decomposed risks for all classes become negative eventually.
Based on this observation, our basic idea for correction is to enforce non-negativity for each ordinary class, with the expression based on complementary labels.
More specifically, we propose a non-negative version by

\eqref{non-negative-risk} is equivalent to \eqref{eq:counterparts}, since  if  is non-negative.
By using the datasets used for \eqref{emp:general}, this non-negative risk can be na\"ively approximated by the sample average as

The empirical version of \eqref{eq:counterparts} may suffer from a negative objective, but \eqref{emp_nn} is non-negative (even though their population versions are equivalent.)

Enforcing the reformulated risk to become non-negative was previously explored in \citet{kiryo17nips}, in the context of binary classification from positive and unlabeled data.  The positive class risk is already bounded below by zero in their case (because they have true positive labels), so there was a max operator only on the negative class risk.  We follow their footsteps, but since our setting is a multi-class scenario and also differs by not having \emph{any} true labels, we put a max operator on each of the  classes.
\begin{algorithm}[t]
  \caption{Complementary-label learning with gradient ascent}
  \label{alg:ascent}
  \begin{algorithmic}
    \STATE \textbf{Input:} complementarily labeled training data , where  denotes the samples complementarily labeled as class ;
    \STATE \textbf{Output:} model parameter  for 
  \end{algorithmic}
  \begin{algorithmic}[1]
    \STATE Let  be an external SGD-like stochastic optimization algorithm such as \citet{kingma15iclr}
    \STATE \textbf{while} no stopping criterion has been met:
    \STATE \quad Shuffle  into  mini-batches;
    \STATE \quad \textbf{for}  \textbf{to} :
    \STATE \qquad Denote  as the -th mini-batch for complementary class 
    \STATE \qquad Denote 
    \STATE \qquad \textbf{if} :
    \STATE \qquad\quad Denote 
    \STATE \qquad\quad Set gradient ;
    \STATE \qquad\quad Update  by  with its current step size ;
    \STATE \qquad \textbf{else}:
    \STATE \qquad\quad Denote 
    \STATE \qquad\quad Set gradient ;
    \STATE \qquad\quad Update  by  with a discounted step size ;
  \end{algorithmic}
\end{algorithm}
\subsection{Approximate non-negative risk estimator}
\label{sc:implementation}
\begin{figure*}[t]
\vspace{-5mm}
\centering
\subfigure[MNIST, linear]{\includegraphics[bb = 0 0 351 348, scale = 0.3339]{mnist_linear.png}}
\hspace{0.001\textwidth}
\subfigure[MNIST, MLP]{\includegraphics[bb = 0 0 351 348, scale = 0.3339]{mnist_mlp.png}}
\hspace{0.001\textwidth}
\subfigure[Fashion-MNIST, linear]{\includegraphics[bb = 0 0 351 348, scale = 0.3339]{fashion_linear.png}}
\hspace{0.001\textwidth}
\subfigure[Fashion-MNIST, MLP]{\includegraphics[bb = 0 0 351 348, scale = 0.3339]{fashion_mlp.png}}\\
\vspace{-3mm}
\subfigure[Kuzushiji-MNIST, linear]{\includegraphics[bb = 0 0 351 348, scale = 0.3339]{kuzushi_linear.png}}
\hspace{0.001\textwidth}
\subfigure[Kuzushiji-MNIST, MLP]{\includegraphics[bb = 0 0 351 348, scale = 0.3339]{kuzushi_mlp.png}}
\hspace{0.001\textwidth}
\subfigure[CIFAR-10, DenseNet]{\includegraphics[bb = 0 0 351 348, scale = 0.3339]{cifar10_densenet.png}}
\hspace{0.001\textwidth}
\subfigure[CIFAR-10, ResNet]{\includegraphics[bb = 0 0 351 348, scale = 0.3339]{cifar10_resnet.png}}
\caption{Experimental results for various datasets and models.  Dark colors show the mean accuracy of 5 trials and light colors show standard deviation.}\label{fig:results}
\end{figure*}
\paragraph{Implementation with max operator}
We now illustrate how to design a practical implementation under stochastic optimization for our non-negative risk estimator.
An unfortunate issue is that the minimization of \eqref{emp_nn} is not point-wise due to the max-operator, thus cannot be used directly for stochastic optimization methods with mini-batch.  However, an upper bound of the risk can be minimized in parallel by using mini-batch as the following,

where  is the empirical version of the expectation and  is the number of mini-batches.
\paragraph{Implementation with gradient ascent}
If the objective is negative for a certain mini-batch, the previous implementation based on the max operator will prevent the objective to further \emph{decrease}.  However, if the objective is already negative, that mini-batch has already started to overfit.  The max operator cannot contribute to decrease the degree of overfitting. From this perspective, there is still room to improve the overfitting issue, and it would be preferable to \emph{increase} itself to make this mini-batch less overfitted.

Our idea is the following.
We denote the risk that corresponds to the th ordinary class for the th mini-batch as

and the total risk as
.
When , we conduct gradient descent as usual with gradient .
On the other hand, if , we first squash the class-decomposed risks over  to  with a min operator, and then sum the results:

Next we set the gradient in the opposite direction with .  Conceptually, we are going \emph{up} the gradient  for \emph{only} the class-decomposed risks below , to avoid the class-decomposed risks that are already large to further increase.
Note that  is a hyper-parameter that controls the tolerance of negativity.   would mean there is zero tolerance, but in practice we can also have  for a threshold that allows some negative () or positive () amount.
The procedure is shown in detail in Algorithm \ref{alg:ascent}.
\begin{table*}[t]
  \center
  \small
  \caption{Test mean and standard deviation of the classification accuracy for 4 trials.  Method name outside (inside) parenthesis shows the criterion of training (validation) objective.  Best is shown in {\bf bold} or \underline{underline} for column 24 or column 26, respectively.}
  \label{tb:validation}
  \tabcolsep=0.2cm
    \begin{tabular}{l|ccc|cc}\toprule
    Dataset & \emph{GA (Free)} & \emph{PC (PC)} & \emph{Fwd (Fwd)} & \emph{PC (Free)} & \emph{Fwd (Free)} \\\midrule
    MNIST&&&\bm{}&&\underline{}\\\midrule
    Fashion&&&&& \\\midrule
    Kuzushiji&\bm{}&&&&\underline{} \\\midrule
    CIFAR-10&&&&& \\\bottomrule
  \end{tabular}
\end{table*}
\section{Experiments}
\label{sc:experiments}
In this section, we compare the 3 methods that we have proposed in Section \ref{sc:proposed_method}, which are \emph{Free} (Unbiased risk estimator that is loss assumption free, based on Eq. \eqref{emp:general}), \emph{Max Operator} (based on Eq. \eqref{emp_nn_minibatch}), and \emph{Gradient Ascent} (based on Alg.\ref{alg:ascent}).
For \emph{Gradient Ascent}, we used  and  for simplicity.
Mini-batch size was set to .
We also compare with two baseline methods: Pairwise comparison (\emph{PC}) with ramp loss from \citet{ishida17nips} and \emph{Forward} correction from \citet{yu17eccv}.
For training, we used only complementarily labeled data, which was generated so that the assumption of \eqref{unbiased-complementary-label-assumption} is satisfied.
This is straightforward when the dataset has a uniform (ordinarily-labeled) class prior, because it reduces to just choosing a class randomly other than the true class.

In Appendix \ref{sec:datasets}, we explain the details of the datasets used in the experiments: MNIST, Fashion-MNIST, Kuzushiji-MNIST, and CIFAR-10.
The implementation is based on Pytorch\footnote{\url{https://pytorch.org}} and our demo code is available online\footnote{\url{https://github.com/takashiishida/comp}}.

\subsection{Comparison of all epochs during training}
\label{sec:all_epochs_exp}
\paragraph{Setup}
For MNIST, Fashion-MNIST, and Kuzushiji-MNIST, a linear-in-input model with a bias term and a MLP model () was trained with softmax cross-entropy loss function (except \emph{PC}) for  epochs.
Weight decay of  for weight parameters and learning rate of  for Adam \citep{kingma15iclr} was used.

For CIFAR-10, DenseNet \citep{huang2017cvpr} and ResNet-34 \citep{he2016cvpr} were used with weight decay of  and initial learning rate of .  For optimization, stochastic gradient descent was used with the momentum set to .  Learning rate was halved every  epochs.

\paragraph{Results}
We show the accuracy for all  epochs on test data to demonstrate how the issues discussed in Section \ref{sec:necessity} appear and how different implementations in Section \ref{sc:implementation} are effective. In Figure \ref{fig:results}, we show the mean and standard deviation of test accuracy for 4 trials on test data evaluated with ordinary labels.

First we compare our 3 proposed methods with each other.
For linear models in MNIST, Fashion-MNIST, and Kuzushiji-MNIST, all proposed methods work similarly.
However in the case of using a more flexible MLP model or using DenseNet/ResNet in CIFAR-10, we can see that \emph{Free} is the worst, \emph{Max Operator} is better and \emph{Gradient Ascent} is the best out of the proposed three methods for most of the epochs (\emph{Free}  \emph{Max Operator}  \emph{Gradient Ascent}).
These results are consistent with the discussions of overfitting in Section \ref{sec:necessity} and the motivations for different implementations in Section \ref{sc:implementation}.

Next, we compare with baseline methods.
For linear models, all methods have similar performance.
However for deep models (MLP, DenseNet, and ResNet), the superiority stands out for \emph{Gradient Ascent} for all datasets.

\subsection{Experiments with validation process}
\label{sec:validation_experiments}
\paragraph{Setup}
Next, we perform experiments with a train, validation, and test split.  The dataset is constructed by splitting the original training data used in the previous experiments into train/validation with a 9:1 ratio.  Note that the validation data only has complementary labels since it is splitted from the set of complementarily labeled training data.
We use the same MLP models for MNIST, Fashion-MNIST, and Kuzushiji-MNIST.
We use DenseNet for CIFAR-10.

Since \emph{Gradient Ascent (GA)} seemed to work better than \emph{Free} and \emph{Max Operator} previously, we omit \emph{Free} and \emph{Max Operator} and compare \emph{GA} with baseline methods (\emph{PC} and \emph{Forward(Fwd)}).
For the validation objective, we used the corresponding criterion for each method, which is shown in the first 3 columns with parenthesis, in Table \ref{tb:validation}.
We also conducted experiments using our proposed general unbiased estimator \emph{Free} as the validation criterion for baseline methods (\emph{PC} and \emph{Fwd}), which is shown in the last 2 columns in Table \ref{tb:validation}.
SGD with momentum of  was used for  epochs.
Weight-decay was fixed to  and learning rate candidates are \{, , , , , \} for CIFAR-10 and \{, , , , , \} for other datasets.
For CIFAR-10, we added learning rate decay with the same settings from Section \ref{sec:all_epochs_exp}.

\paragraph{Results}
In Table \ref{tb:validation}, we showed the mean and standard deviation of test accuracy for 4 trials, with the model that gave the best validation score out of all epochs for all hyper-parameter candidates.
By comparing the first 3 columns, \emph{GA} seems to work well.
We can also observe that in most cases, \emph{PC (Free)} and \emph{Fwd (Free)} performs similarly or better than \emph{PC (PC)} and \emph{Fwd (Fwd)}, respectively. This confirms the discussion in earlier sections that our general unbiased risk estimator is useful not only as a learning objective, but also useful as a validation objective for baseline methods.

\section{Conclusion}\label{sc:conclusion}
We first proposed a general risk estimator for learning from complementary labels that does not require restrictions on the form of the loss function or the model.
However, since the proposed method suffers from overfitting, we proposed a modified version to alleviate this issue in two ways and have better performance.
At last, we conducted experiments to show our proposed method outperforms or is comparable to current state-of-the-art methods for various benchmark datasets and for both linear and deep models.

Recently, \emph{complementary-label learning} has been applied to \emph{online learning} \citep{kaneko19arxiv}, \emph{generative discriminative learning} \citep{xu19arxiv}, and \emph{medical image segmentation} \citep{rezaei19mta}.  This implies applying the idea of complementary labels to other domains may be useful, which can be an interesting future direction.
\newpage
\section*{Acknowledgments}
TI was supported by Sumitomo Mitsui DS Asset Management. MS was supported by JST CREST JPMJCR1403.
We thank the anonymous reviewers for the helpful suggestions.

\bibliography{example_paper}
\bibliographystyle{icml2019}

\clearpage
\appendix

\section{Proof of Theorem \ref{theorem:R(f)}}\label{sec:theorem1proof}
\begin{proof}
First of all,

The first equality holds since the marginal distribution is equivalent for  and  and we assume \eqref{unbiased-complementary-label-assumption}.
Consequently,

More simply, we have
.
Finally, we transform the classification risk,

for the complementary loss,
,
which concludes the proof.
\end{proof}

\section{Proof of Corollary \ref{corollary}}\label{sec:corollary2proof}
\begin{proof}

The second equality holds because we use \eqref{scalar_complementary_loss}.  The third equality holds because we are using losses that satisfy  for all  and  for all  and .  The 4th equality rearranges terms.  The 5th equality holds because  for  and .  This can be easily shown by using  and  for , and  and  for .
\end{proof}

\begin{table}[]
  \center
  \small
  \caption{Summary statistics of benchmark datasets.  In the experiments with validation dataset in Section \ref{sec:validation_experiments}, train data is further splitted into train/validation with a ratio of 9:1. Fashion is Fashion-MNIST and Kuzushiji is Kuzushiji-MNIST.}
  \tabcolsep=0.07cm
    \begin{tabular}{l|cc|cccc|c}\toprule
    Name & \# Train & \# Test & \# Dim & \# Classes & Model\\\midrule
    MNIST &60k&10k&784& 10 & Linear, MLP\\\midrule
    Fashion &60k&10k&784& 10 & Linear, MLP\\\midrule
    Kuzushiji &60k&10k&784& 10 & Linear, MLP\\\midrule
    CIFAR-10 &50k&10k&2,048& 10 & DenseNet, Resnet\\\bottomrule
  \end{tabular}
  \label{tb:summary_datasets}
\end{table}

\section{Datasets}
\label{sec:datasets}
In the experiments in Section \ref{sc:experiments}, we use 4 benchmark datasets explained below.
The summary statistics of the four datasets are given in Table \ref{tb:summary_datasets}.
\begin{itemize}
\item MNIST\footnote{\url{http://yann.lecun.com/exdb/mnist/}} \citep{Lecun98gradient-basedlearning} is a 10 class dataset of handwritten digits:  and .  Each sample is a  grayscale image.
\item Fashion-MNIST\footnote{\url{https://github.com/zalandoresearch/fashion-mnist}} \citep{fashion} is a 10 class dataset of fashion items: T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, and Ankle boot.  Each sample is a  grayscale image.
\item Kuzushiji-MNIST\footnote{\url{https://github.com/rois-codh/kmnist}} \citep{clanuwat18neurips} is a 10 class dataset of cursive Japanese (``Kuzushiji'') characters.  Each sample is a  grayscale image.
\item CIFAR-10\footnote{\url{https://www.cs.toronto.edu/~kriz/cifar.html}} is a 10 class dataset of various objects: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck.  Each sample is a colored image in  RGB format.  It is a subset of the 80 million tiny images dataset \citep{Torralba08pami}.
\end{itemize}

\newpage
\onecolumn
\section*{Errata (Nov. 19, 2019)}

We have found errors in our previous implementation for the forward method \citep{yu17eccv}, and would like to report the updated results based on the fixed implementation.

In Figure \ref{fig:updatedresults}, the forward method performs better than previously reported.  This is especially true for linear models.  For neural network models,  the results seem to be dataset-dependent:  For MNIST and Fashion-MNIST, the proposed gradient ascent method is similar to the forward method.  For Kuzushiji-MNIST, the proposed gradient ascent method is still better than the forward method.  For CIFAR-10, the proposed gradient ascent method with DenseNet still performs the best with around 40\% accuracy.  In Table \ref{tb:validation2}, the proposed gradient ascent method is better for CIFAR-10, but the forward method is better for MNIST and Fashion-MNIST.  The two methods perform similarly for Kuzushiji-MNIST.

Addtionally, we investigate the reason behind the good performance of forward methods with a linear model.  In Figure \ref{fig:conf}, we visualize the reliability diagrams  \cite{confcalibration} and histograms of the softmax output of the forward method, for MNIST, Fashion-MNIST, and Kuzushiji-MNIST.  We can see that the linear model is much more confidence-calibrated compared to MLP models.  The forward method requires the model to be flexible in order to guarantee that the solution gives the true class posterior under the clean joint distribution, given uncountably infinite training data.  In the figures, however, we can see that with finite training data, a flexible model can be over-confident (further away from the gray dotted line), while a linear model is more confidence-calibrated (more closer to the gray dotted line).

\begin{figure*}[h]
\vspace{-5mm}
\centering
\subfigure[MNIST, linear]{\includegraphics[bb = 0 0 351 348, scale = 0.3339]{new_mnist_linear.png}}
\hspace{0.001\textwidth}
\subfigure[MNIST, MLP]{\includegraphics[bb = 0 0 351 348, scale = 0.3339]{new_mnist_mlp.png}}
\hspace{0.001\textwidth}
\subfigure[Fashion-MNIST, linear]{\includegraphics[bb = 0 0 351 348, scale = 0.3339]{new_fashion_linear.png}}
\hspace{0.001\textwidth}
\subfigure[Fashion-MNIST, MLP]{\includegraphics[bb = 0 0 351 348, scale = 0.3339]{new_fashion_mlp.png}}\\
\vspace{-3mm}
\subfigure[Kuzushiji-MNIST, linear]{\includegraphics[bb = 0 0 351 348, scale = 0.3339]{new_kuzushi_linear.png}}
\hspace{0.001\textwidth}
\subfigure[Kuzushiji-MNIST, MLP]{\includegraphics[bb = 0 0 351 348, scale = 0.3339]{new_kuzushi_mlp.png}}
\hspace{0.001\textwidth}
\subfigure[CIFAR-10, DenseNet]{\includegraphics[bb = 0 0 351 348, scale = 0.3339]{new_cifar10_densenet.png}}
\hspace{0.001\textwidth}
\subfigure[CIFAR-10, ResNet]{\includegraphics[bb = 0 0 351 348, scale = 0.3339]{new_cifar10_resnet.png}}
\caption{Updated results of Figure \ref{fig:results}.  The forward method has been swapped with the fixed implementation.}
\label{fig:updatedresults}
\end{figure*}
\begin{table*}[h] 
  \center
  \small
  \caption{Updated results of Table \ref{tb:validation}.  The results in the 4th and 6th columns have been swapped with the fixed implementation.}
  \label{tb:validation2}
  \tabcolsep=0.2cm
    \begin{tabular}{l|ccc|cc}\toprule
    Dataset & \emph{GA (Free)} & \emph{PC (PC)} & \emph{Fwd (Fwd)} & \emph{PC (Free)} & \emph{Fwd (Free)} \\\midrule
    MNIST&&&&&\\\midrule
    Fashion&&&&& \\\midrule
    Kuzushiji&&&&& \\\midrule
    CIFAR-10&&&&& \\\bottomrule
  \end{tabular}
\end{table*}
\begin{figure*}[h]
\centering
  \centering
  \includegraphics[bb = 0 0 1287 802, scale = 0.52]{confidence.png}
  \caption{The bottom figures show the histogram of the output of the softmax layer in the forward method, with 10 bins in the horizontal axis, for MNIST, Fashion-MNIST, and Kuzushiji-MNIST.  The light blue color shows the linear model and the dark blue color shows the MLP model.  The top figures show the reliability diagrams for the same datasets.  The vertical axis shows the proportion of correct predictions in each bins.  The gray dotted line shows the identity function as an ideal case.}
  \label{fig:conf}
\end{figure*}

\end{document}
