\documentclass[10.5pt,a4paper]{article}
\usepackage[latin9]{inputenc}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{esint}
\usepackage{amssymb}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{color}
\makeatletter



\theoremstyle{remark}
  \newtheorem{example}{\protect\examplename}
\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}
 \theoremstyle{plain}
 \newtheorem{defn}{\protect\definitionname}
\theoremstyle{remark}
\newtheorem{rem}{\protect\remarkname}
\theoremstyle{plain}
\newtheorem{prop}{\protect\propositionname}
\theoremstyle{plain}
\newtheorem{lem}{\protect\lemmaname}
\providecommand{\lemmaname}{Lemma}
\providecommand{\propositionname}{Proposition}
\providecommand{\remarkname}{Remark}
\providecommand{\examplename}{Example}
\providecommand{\definitionname}{Definition}
\providecommand{\theoremname}{Theorem}


\usepackage{amsfonts}\usepackage{color}\usepackage{mathrsfs}\usepackage{wasysym}\usepackage{float}

\textheight 25cm
 \textwidth 15cm
 \topmargin -1cm
 \oddsidemargin 0cm
 \evensidemargin -0.25cm
 \hoffset 0.5cm
 \marginparsep 0cm
 \headsep
 \baselineskip
 \marginparwidth 0cm
 \headheight 0cm
 \columnsep 0cm

\makeatother

\begin{document}

\title{Stochastic stability and stabilization of a class of state-dependent
jump linear systems\footnote{\textit{preprint submitted to Nonlinear Analysis: Hybrid Systems}}}


\author{Shaikshavali Chitraganti\thanks{CRAN--CNRS UMR 7039, Universit\'{e} de Lorraine, 54500 Vandoeuvre-l\'{e}s-Nancy, France.} \and Samir Aberkane\footnotemark[2] \and Christophe Aubrun\footnotemark[2] }
\date{}

\maketitle
\thispagestyle{empty} 
\begin{abstract}
This paper deals a continuous-time state-dependent jump linear
system, a particular kind of stochastic switching system. In particular,
we consider a situation when the transition rate of the random jump
process depends on the state variable, and addressed the problem of
stochastic stability and stabilization analysis for the proposed system.
Numerically solvable sufficient conditions for the stochastic stability
and stabilization of the proposed system is established in terms of
linear matrix inequalities. The obtained results are illustrated in
numerical examples.
\end{abstract}
\section{Introduction}\label{section:introduction}

Systems subject to random abrupt changes can be modeled by Random Jump linear systems (RJLS) such as manufacturing systems, networked control systems, economics and finance \textit{etc}. RJLS are a special class of hybrid systems, typically, described by a set of classical differential (or difference) equations and a random jump process governing the jumps among them.

When the random jump process of RJLS is assumed to be a finite state time-homogeneous Markovian process with a known transition rate (or probability), then this particular class of systems are widely known as Markov jump linear systems (MJLS) in the literature. The theory of stability, optimal and robust control, as well as important applications of MJLS can be found for instance in \cite{feng}, \cite{mariton}, \cite{kozin}, \cite{yji}, \cite{fangphd} and the references therein. In general, the studies of MJLS assume that the underlying random process is time-homogeneous Markov, which is quite a restrictive assumption. 

In this article, we consider the analysis of RJLS where the random
jump process depends on the state variable. Such class of systems
are referred to as ``state-dependent jump linear systems (SDJLS)''
in this article. The given problem is motivated by following scenarios.
In fault tolerant control systems, the failure rate of a component
generally depends on its age, wear, accumulated stress etc. It is
reasonable to assume that the failure rate of a component at time
 depends on the state of the component at age , see for example
\cite{bergman}. In this case, state variable may be a measure of
wear, accumulated stress of component etc., which affect its failure
rate. As an another scenario, consider a case of stock market with
two regimes: up and down. The transition rate between the regimes
usually result from the state of economy, the general mood of the
investors in the market etc., which can be regarded in general as
the state of the market. Also, for instance, in \cite{motivation1},
the authors dealt with the problem of describing the underlying reasons
for the failure mechanism of a process and modelled the degradation
or wear of the process as a Markov process whose transitions depend
on the state of the process. As an application, the wear of cylinder
lines in a heavy-duty marine diesel engines is considered as a state-dependent
Markov process. Also, let us consider a modelling of macroeconomic
and financial time series. In \cite{motivation2}, a regime-switching
model for the sample path of a time series is examined, where the
transition probabilities between the regimes depend on the state variable.
One can find more examples or scenarios of this kind in the literature.

To the best of the authors' knowledge, only a few works have been
carried out on stability and control of SDJLS. In \cite{yin2009hybrid},
a study of hybrid switching diffusion processes, a kind of state-dependent
jump non-linear systems, has been carried out by treating existence,
uniqueness, stability of the solutions etc. In \cite{sworder1973},
the authors considered that the transition rate of the random jump
process depends on both the state variable and the control input in
such a way that both the state variable and the control input affect
the time scale of the random jump process, thus affecting its transition
rate, and obtained a control policy for a given functional using stochastic
maximum principle. A model for planning and maintenance in flexible
manufacturing system is proposed in \cite{boukas1990}, where the
failure rate of a machine depends on the state variable, and computed
an optimal control using dynamic programming. In \cite{filar2001},
a two-time scale model of production plant is considered as a jump
diffusion model where the failure rate of a machine depends on the
state variable, and obtained an optimal control. 

In this article, we consider the state-dependent transition rates
explicitly as: the transition rates vary depending on which set the
state of the system belongs to. This is a reasonable assumption because
the state of the system at any time belong to one of the predefined
sets, and the transition rate can be considered to have different
values across the predefined sets. The major difference of the current
work in this article with the existing literature on RJLS is that
the random jump process does not follow Markov property. Under the
given assumption that the transition rates vary depending on the set
to which the state of the system belongs to, we prove that the times
at which the change of transition rates occur are stopping times and
accordingly we consider a Dynkin's formula with stopping
Utilizing this formalism, we obtained numerically tractable
sufficient conditions for stochastic stability and stabilization in
terms of linear matrix inequalities (LMIs), though for a restricted
class of SDJLS described in section \ref{section:mathematical}.

The rest of the article is organized as follows: section \ref{section:mathematical}
gives the description of a mathematical model of the SDJLS studied
in this article. In section \ref{section:mainresult}, sufficient
conditions for the stochastic stability and stabilization of the SDJLS
are obtained. In section \ref{section:examples}, numerical examples
are given to illustrate the proposed results, and the concluding remarks
are addressed in section \ref{section:conclusions}.

\textit{Notation} : Let  be the n-dimensional real
Euclidean space.  is the transpose of a matrix . 
represent the minimum eigenvalue of a matrix . Given two matrices
 and ,  (or ) denotes that the matrix
 is positive definite (or negative definite). The standard vector
norm in  is indicated by  the corresponding
induced norm of a matrix  by . Let 
be the set of rational numbers and  be the set of
natural numbers including 0. The operator  denotes the union
and  denotes intersection. Given two sets  
denotes the set  The empty set is represented by .
For any   represents the minimum of
two numbers . is the standard indicator function
which has a value  if , otherwise has a value . The
mathematical expectation of a random variable  is denoted by .
Let  be an arbitrary functional of a stochastic process
; denote  as the expectation
of the functional  at .



\section{Mathematical Model}\label{section:mathematical}
Consider a SDJLS in a fixed probability space 

where  is the state vector, 
is the initial state,  be
system matrices which depend on . Let ,
describing the mode of the system at time , be a finite space
continuous time jump process whose transitions depends on the state
variable  as follows, for  : 

where  and 
Let  We assume that ,
 and 
for any . For each , 
is the transition rate of  from mode  to mode 
with  for , and .
It represents the probability per time unit that  makes
a transition from mode  to mode .  is little- notation
defined by  A trivial
remark here is that  in  as per (\ref{eq:rt_intro_old}) is a
notation followed in this article, but one should not get confused with the actual power of transition rates.

From the assumption 
and  for any , at any
time ,  belongs to one of the sets , ,
accordingly the transition rate of  is from
(\ref{eq:rt_intro_old}). Observe that the transition rate of 
depends on the state variable , hence we call the system (\ref{sys:system_old})
as SDJLS.

We slightly change the notations of the SDJLS (\ref{sys:system_old})
and the mode  (\ref{eq:rt_intro_old}) such that the dealing
of the state dependence becomes simpler. For this purpose consider
, which provide the information of state
variable  at each time  as



Let  (which is equivalent to ),
denote the mode of the system at time , be a finite space continuous
time jump process whose transitions depends on . Implicitly, 
 depends on the state variable  as follows, for ,

where , for  is defined in (\ref{eq:rt_intro_old})

Accordingly, we can describe the SDJLS (\ref{sys:system_old}) as

where  be system matrices
(which are equivalent to ) which depend on .
From now onwards, we analyse the system (\ref{sys:system}) with jupm
process (\ref{eq:rt_intro}), which is equivalent to analysing the
system (\ref{sys:system_old}) with jump process (\ref{eq:rt_intro_old}).
\begin{rem}
\label{remark:existence} One can observe that the overall system
(\ref{sys:system}) is nonlinear due to the presence of jump process
. The existence and uniqueness of solution to the
system (\ref{sys:system}) follows directly from theorem 2.1 of \cite{yin2009hybrid}.
\end{rem}
\begin{rem}Observe that, conditioning on , 
depends on  for any , and from (\ref{sys:system}), which
in turn depends on , . Hence 
is not a Markov process. However 
is a joint Markov process. This point is stated and proved in the
following lemma. \end{rem}

\begin{lem}
\label{lemma:joint_Markov_process} 
is a joint Markov process.\end{lem}
\begin{proof}
Given in the Appendix.
\end{proof}
The solution to (\ref{sys:system}) can be constructed as presented
in the sequel. In that direction, we define first exit times from
the sets  for . We use a convention . 
\begin{itemize}
\item Step : Let , where .
Define  as the first exit time from  as 


\item Step 1: Let , where ,
. Define  as the first exit time
from  after  as 


\item Step 2: Let , where ,
. Define  as the first exit time
from  after  as 


\end{itemize}
In general, at any step , given , 
of the previous step  which is defined in a similar manner above,
\begin{itemize}
\item Step : Let , where ,
. Define  as the first exit time
from  after  as 


\end{itemize}
where the random flows  are defined in the sequel.
We describe, in general, one of the random flows 
in (\ref{eq:tau}), at step , with ,
using which any random flow of (\ref{sys:system}) can be described
in a similar fashion. At step , during the interval ,
with : let  be the
number of regime transitions of  ; let 
be the sequence of regimes visited by ; let 
be the successive sojourn times of , which are independent
exponentially distributed random variables with parameter .
Let  Then
 is given by,



\begin{rem}
\label{rem:sigma_r_reform}Notice that, from step , step ,
 step ,  and 
can be described alternatively for  by 

and

where  and ,

\end{rem}

\begin{rem}
Though the alternative reformulations of  and 
in remark \ref{rem:sigma_r_reform} seems not much useful at this
point, but the results of section \ref{section:mainresult} will be
based on these reformulations.
\end{rem}
\begin{rem}\label{remark:gen_mjls}From step 0, given 
for  if  then 
for all  In this case the overall system (\ref{sys:system})
is equivalent to time-homogeneous MJLS with jump process being time-homogeneous
Markov with parameter \end{rem}

\noindent We define the stopping time in the sequel and prove that
the first exit times ,  
are the stopping times.
\begin{defn}
\noindent Let  be a filtered
probability space, then a random variable 
(it may take the value ) is called a stopping time
if  for any , i.e; the event
 is -measurable, which implies the
event  is completely determined by the knowledge of
. \end{defn}

The following lemma shows that the first exit times given above are in fact stopping times.
\begin{lem}
\label{lemma:stopping_time} The first exit times , described in step 0, step 1, step 2,  are stopping times.\end{lem}
\begin{proof}
Given in the Appendix.
\end{proof}

Based on lemma \ref{lemma:joint_Markov_process} and lemma \ref{lemma:stopping_time}, we provide a Dynkin's formula that will be used in the next section.

\begin{defn} Let  be a Markov process
and ,, are stopping times. Let
. For any suitable
Lyapunov function , the Dynkin's formula can described
as \cite{sri}, \cite{karimi},


where  is the infinitesimal generator of .
Here , and , where 
and . \end{defn}
In general,    can be understood as the average time rate of change of the function  given  at time . Also observe that, since  is Markov process, for any , the expectation terms in (\ref{eq:dynkin}) are
conditioned on , instead of the natural filtration of  on the interval .


\section{Main Results\label{section:mainresult} }
In this section, we present sufficient conditions for stochastic stability
and stabilization of the system (\ref{sys:system}). 

\subsection{Stochastic stability}
We begin with a definition of stochastic stability,

\begin{defn} For system (\ref{sys:system}), the equilibrium point
 is \textit{stochastically stable} if, for any 
and any  and ,

\end{defn}

\noindent We now provide a sufficient condition for stochastic stability. 
\begin{thm}
\noindent \label{theorem:1} The system (\ref{sys:system}) is stochastically
stable if there exist positive definite matrices ,  for
all  and for all , satisfying 


 where  is defined in (\ref{eq:rt_intro_old}).
\end{thm}
\noindent \textit{Proof}: Consider a ,
which is quadratic and positive in , hence a Lyapunov candiate
function. Let the infinitesimal generator of , for any  and for any , be given by,

The above derivation is quite straight forward and follows the similar
approach as given in \cite{boukasbook}, \cite{costabook2012} for
example. Hence, by (\ref{lmi:1}),

From (\ref{eq:dynkin}), consider for any 

 where   and  are given
in (\ref{eq:dynkin}). Let 
be the successive states visited by  similar to remark
\ref{rem:sigma_r_reform}. Then 

By (\ref{eq:lvmin}), 

By denoting ,
one obtains, 

By rearranging the terms, 


\noindent Thus, 

By letting , 

Thus the system (\ref{sys:system}) is stochastically stable.\hfill{}


\begin{rem}Similar to remark \ref{remark:gen_mjls}, from step 0,
given  for  if 
then the overall system (\ref{sys:system}) is equivalent to time-homogenous
MJLS. And LMIs (\ref{lmi:1}) are equivalent to the LMIs given in
theorem 1 of \cite{boukasbook} with the transition rate \end{rem}


\subsection{Stochastic stabilization}

In this section we provide a sufficient condition for stochastic stabilization
with state feedback controller. Consider the system (\ref{sys:system})
with control input  

where .

We make use of the theorem \ref{theorem:1} to design a state-feedback
stabilizing controller such that the system (\ref{sys:system_withipold})
is stochastically stable. We assume that the system mode 
is available in real time, which lead to a state feedback control
law of the form 

then the overall system is given by


where 

\begin{rem}Since the system (\ref{sys:system_withip}) is identical
to the system (\ref{sys:system}), the existence and uniqueness of the solutions
of (\ref{sys:system_withip}) follow from remark \ref{remark:existence}.\end{rem}

The following theorem provides a sufficient condition for the existence
of a stabilizing controller of the form (\ref{eq:stateFB}).

\begin{thm}\label{theorem:stabilization_SS} Consider the system
(\ref{sys:system_withipold}) with  and 
described in (\ref{eq:sigma_intro}) and (\ref{eq:rt_intro}). If
there exist matrices , and , for each 
such that, 

for each ,  where 

then the system (\ref{sys:system_withipold}) is stochastically stabilized
by (\ref{eq:stateFB}), and the stabilizing controller is given by

\end{thm} 
\begin{proof}
The proof is an immediate extension of theorem 11 of \cite{boukasbook}.
\end{proof}

\section{Illustrative Examples}\label{section:examples} 
In this section, two numerical examples
are presented to illustrate the proposed results.\\
\begin{example}\label{example:1}


\noindent Consider the SDJLS (\ref{sys:system_old})
with . Let
, be the state-dependent jump process given
by (\ref{eq:rt_intro_old}), with ,
,
and for  the transition rate matrices of 
are given by


Let 

Then, from theorem \ref{theorem:1}, the LMIs (\ref{lmi:1}), are
satisfied with
 
Hence, the system (\ref{sys:system_old}) is stochastically stable.
With , , a sample  with
the corresponding stopping times , , 
are given in step 0, step 1, are plotted in figure \ref{fig:rt};
the corresponding sample state trajectories of the system are shown
in figure \ref{fig:states}.



\begin{figure}[h]
        \centering
        \begin{subfigure}[b]{0.45\textwidth}
                \includegraphics[width=\textwidth,height=5cm]{modes}
				\caption{A sample  and the corresponding stopping times }
               \label{fig:rt} 
        \end{subfigure}~ \begin{subfigure}[b]{0.45\textwidth}
                \includegraphics[width=\textwidth,height=5cm]{states}
				\caption{State trajectories of the system: a single sample path }
                \label{fig:states}
        \end{subfigure}
\caption{Plots of example 1 }\label{fig:example1}
\end{figure}
\end{example}


\begin{example} \label{example:2}
 In this example we utilize the result of theorem
\ref{theorem:stabilization_SS} to synthesize a state feedback controller
of form (\ref{eq:stateFB}) that stochastically stabilizes (\ref{sys:system_withipold}).
Let  consists of the same parameters as
example \ref{example:1}. Let
 
By solving the LMIs (\ref{lmi:stabilization}),
we obtain:

and the feedback gains are obtained as: 
 
 With , , a single sample path simulation corresponding
to a realization of  is given in figure \ref{fig:rt_fb};
a sample state trajectories of the closed loop system resulting from
the obtained controller are shown in figure \ref{fig:states_fb}.
It can be observed that the closed loop system is stochastically stable.




\begin{figure}[h]
\centering
                \begin{subfigure}[b]{0.45\columnwidth}
                \includegraphics[width=\columnwidth,height=5cm]{stabilization_modes}
	\caption{A sample  \textcolor{white}{i ttttt ttt tt err rrr rrr rr tt tt tt tt r}	
			}
               \label{fig:rt_fb} 
        \end{subfigure}~ \begin{subfigure}[b]{0.45\columnwidth}
                \includegraphics[width=\columnwidth,height=5cm]{stabilization_states}
	\caption{State trajectories of the closed loop system: a single sample path }
                \label{fig:states_fb}
        \end{subfigure}
\caption{Plots of example 2 }\label{fig:example2}
\end{figure}
\end{example} 

\section{Conclusions}\label{section:conclusions}
 In this paper we have treated the stochastic
stability and stabilization of a state-dependent jump linear system.
We utilized the stopping times as a pointer to capture the evolution
of the state variable, and used the Dynkin's formula to obtain sufficient
condition in terms of linear matrix inequalities. Using the sufficient
condition, we synthesize a state-feedback controller which stochastically
stabilizes the system. 

\section*{Appendix}

\textbf{Proof of Lemma  \ref{lemma:joint_Markov_process}:} 
We follow the approach used in \cite{hybridge}
and \cite{maobook} to prove. We prove in the sequel that 
is jointly Markovian which is equivalent to state that 
is a joint Markov process, because the evolution of  is
captured in  and  from (\ref{eq:sigma_intro})
and (\ref{eq:rt_intro}). Let  denote the natural filtration of
 on the interval , and 
denote the natural filtration of  on the interval
. Let  and  from (\ref{sys:system_old})
and (\ref{eq:rt_intro_old}) be denoted , starting from ,
as 

Denote the joint process  starting from
 as 

with ,
which is simply . For , 
describes the process on  with ,
thus it is -measurable. Let  be an arbitrary
-measurable random variable. For ,
 can be described as a -measurable
process on  with initial condition .
Thus we can write 

Let  be a set in the -algebra of Borel sets on .
Then 

which completes the proof. \hfill{}




\noindent \textbf{Proof of Lemma \ref{lemma:stopping_time}:} Let  denote
the natural filtration of  on the interval
. Consider 

 From the above argument, observe that, each event 
is -measurable for all .
Consequently the event  is also -measurable,
as the complement of the intersection of -measurable
events are also -measurable. Thus  is
a stopping time. The similar arguments are applied to \hfill{}

\bibliographystyle{plain}
\bibliography{References_syscon_13}
 
\end{document}
