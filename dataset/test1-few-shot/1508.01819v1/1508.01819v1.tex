


\documentclass[graybox]{svmult}



\usepackage{mathptmx}       \usepackage{helvet}         \usepackage{courier}        \usepackage{type1cm}        \usepackage{makeidx}         \usepackage{graphicx}        \usepackage{multicol}        \usepackage[bottom]{footmisc}\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{latexsym}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{color}
\usepackage{amsfonts}
\usepackage{bbm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{epstopdf}
\usepackage{subfigure}
\usepackage{enumerate}
\RequirePackage{xspace}
\usepackage[ruled, section]{algorithm}
\usepackage{algpseudocode}
\RequirePackage[colorlinks,citecolor=blue,urlcolor=blue]{hyperref}







\newcommand{\argmax}[1]{\mathop{\text{argmax}}_{#1}}
\newcommand{\argmin}[1]{\mathop{\text{argmin}}_{#1}}

\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}







      
\renewcommand{\E}{\mathbb E}
\newcommand{ \R}{ \mathbb R}
\renewcommand{\Pr}{ \mathrm P}
\renewcommand{\D}{ \mathbb D}
\newcommand{ \s}{ \mathcal S }
\newcommand{ \cM}{ \mathcal M }
\newcommand{ \ct}{ \mathcal T }
\newcommand{ \cg}{ \mathcal G }
\newcommand{ \cb}{ \mathcal B}
\newcommand{ \cd}{ \mathcal D}
\newcommand{ \cp}{ \mathcal P}
\newcommand{ \cf}{ \mathcal F}
\newcommand{ \cx}{ \mathcal X}
\newcommand{ \cy}{ \mathcal Y}
\newcommand{ \cC}{ \mathcal C}
\newcommand{ \cR}{ \mathcal R}
\newcommand{ \cL}{ \mathcal L }
\newcommand{ \cQ}{ \mathcal Q}
\newcommand{ \cV}{ \mathcal V}
\newcommand{ \pxy}{ {\bf P_{x,y}}}
\newcommand{\ga}{\alpha}
\newcommand{\gb}{\beta}
\newcommand{\gd}{\delta}
\newcommand{\gre}{\epsilon}
\newcommand{\gve}{\varepsilon}
\newcommand{\bgt}{\Theta}
\newcommand{\gt}{\theta}
\newcommand{\gl}{\lambda}
\newcommand{\gs}{\sigma}
\newcommand{\om}{\omega}
\newcommand{\gS}{\Sigma}
\newcommand{\gm}{\gamma}
\newcommand{\G}{\Gamma}
\newcommand{\Om}{\Omega}
\newcommand{\gkp}{\kappa}
\newcommand{\ba}{\mathbf{A}}
\newcommand{\bh}{\mathbf{H}}
\newcommand{\bj}{\mathbf{J}}
\newcommand{\bw}{\mathbf{W}}
\newcommand{\bld}{\mathbf{D}}
\newcommand{\br}{\mathbf{R}}
\newcommand{\bc}{\mathbf{C}}
\newcommand{\tr}{\text{tr} }
\newcommand{\rar}{ \rightarrow}
\newcommand{\uar}{ \uparrow}
\newcommand{\imp}{ \Rightarrow}
\newcommand{\bftext}{\textbf}
\newcommand{\del}{\partial}
\newcommand{\rchi} {\raisebox{0.7mm}{} }
\newcommand{\V}[1]{\ensuremath{\boldsymbol{#1}}\xspace}
\newcommand{\til}[1]{\ensuremath{\tilde{#1}}}


\newcommand{\real}{\ensuremath{\mathbb{R}}}
\newcommand{\footn}{\ensuremath{\footnotesize}}
\newcommand{\mydefn}{\ensuremath{: \, =}}
\renewcommand{\baselinestretch}{1.25}



\makeindex             



\begin{document}

\title*{Spectral Clustering and Block Models: A Review And A New Algorithm}
\author{Sharmodeep Bhattacharyya and Peter J. Bickel}
\institute{Sharmodeep Bhattacharyya \at Oregon State University, Department of Statistics, 44 Kidder Hall, Corvallis, OR, \email{bhattash@science.oregonstate.edu}
\and Peter J. Bickel \at University of California at Berkeley, Department of Statistics, 367 Evans Hall, Berkeley, CA \email{bickel@stat.berkeley.edu}}
\maketitle





\abstract{We focus on spectral clustering of unlabeled graphs and review some results on clustering methods which achieve weak or strong consistent identification in data generated by such models. We also present a new algorithm which appears to perform optimally both theoretically using asymptotic theory and empirically.}

\section{Introduction}
\label{intro}


Since its introduction in \cite{MR0318007}, spectral analysis of various matrices associated to groups has become one of the most widely used clustering techniques in statistics and machine learning.

In the context of unlabeled graphs, a number of methods, all of which come under the broad heading of spectral clustering have been proposed. These methods based on spectral analysis of adjacency matrices or some derived matrix such as one of the Laplacians (\cite{shi2000normalized}, \cite{ng2002spectral}, \cite{MR2396807}, \cite{MR2893856}, \cite{MR3010899}) have been studied in connection with their effectiveness in identifying members of blocks in exchangeable graph block models. In this paper after introducing the methods and models, we intend to review some of the literature. We relate it to the results of Mossel, Neeman and Sly (2012) \cite{mossel2012stochastic} and Massouli\'{e} (2014) \cite{massoulie2014community}, where it is shown that for very sparse models, there exists a phase transition below which members cannot be identified better than chance and also showed that above the phase transition one can do better using rather subtle methods. In \cite{bhattacharyya2014community} we develop a spectral clustering method based on the matrix of geodesic distances between nodes which can achieve the goals of the work we cited and in fact behaves well for all unlabeled networks, sparse, semi-sparse and dense. We give a statement and sketch the proof of these claims in \cite{} but give a full argument for the sparse case considered by the above authors only in this paper. We give the necessary preliminaries in Section 2, more history in Section 3 and show the theoretical properties of the method in Section 4.

\section{Preliminaries}
\label{sec_prel}
There are  many standard methods of clustering based on numerical similarity matrices which are discussed  in a number of monographs (Eg:Hartigan \cite{MR0405726}, Leroy and Rousseuw \cite{MR914792}). We shall not discuss these further. Our focus is on unlabeled graphs of  vertices characterized by adjacency matrices,  for  data points. With  if there is an edge between  and  and  otherwise. The natural assumption then is, . Our basic goal is to divide the points in  sets  such that on some average  criterion the points in a given subset are more similar to each other than to those of other subsets. Our focus is on methods of clustering based on the spectrum (eigenvalues and eigenvectors) of  or related matrices. 




\subsection{Notation and Formal Definition of Stochastic Block Model}
\label{sec_sbm}
\begin{definition}
\label{def_sbm}
A graph  generated from the \textbf{stochastic block model} (SBM) with  blocks and parameters  and  can be defined in following way - each vertex of graph  is assigned to a community . The  are independent outcomes of multinomial draws with parameter , where  for all . Conditional on the label vector , the edge variables  for  are independent Bernoulli variables with

where  and  are  symmetric matrices. We call  the \textbf{connection probability} matrix and  the \textbf{kernel} matrix for the connection. So, we have  for all ,  and  element-wise.
\end{definition}
By definition , and  (no self-loops). 

This formulation is a reparametrization due to Bickel and Chen (2009) \cite{bickel2009nonparametric} of the definition of Holland and Leinhardt \cite{holland1983stochastic}. It permits separate consideration asymptotically of the density of the graph and its structure as follows:

with   depending on n. . We can interpret   as the unconditional  probability of an edge and  essentially as  


Set . 
\begin{enumerate}
\item Define the matrices as  and .
\item Note that the eigenvalues of  are the same as the symmetric matrix  and in particular are real-valued. 
\item The eigenvalues of the expected adjacency matrix  are also the same as those of  but with multiplicities. We denote the eigenvalues by their absolute order, . 
\end{enumerate}
Let us denote , , as the eigenvectors of  corresponding to the eigenvalues . If a set of 's are equal to , we choose eigenvectors from the eigenspace corresponding to the  as appropriate. Then, we have,  and  as the left and right eigenvectors of . Also, . The spectral decomposition of ,  and  are


\subsection{Spectral Clustering}
\label{sec_specc}
The basic goal of community detection is to infer the node labels  from the data. Although we do not explicitly consider parameter estimation, they can be recovered from , an estimate of  by

where, 








There are a number of approaches for community detection based on modularities (\cite{girvan2002community}, \cite{bickel2009nonparametric}), maximum likelihood and variational likelihood (\cite{MR2988467}, \cite{MR3127853}) and approximations such as  semidefinite programming approaches \cite{amini2014semidefinite}, pseudolikelihood \cite{MR3127859} but these all tend to be computationally intensive  and/or require good initial assignments of blocks. The methods which have proved both computationally effective and asymptotically correct in a sense we shall discuss are related to spectral analysis of the adjacency or related matrices.They differ in important details.  

Given an   symmetric matrix  based on , the algorithms are of the form:
\begin{enumerate}
\item Using the spectral decomposition of  or a related generalized eigenproblem.
\item Obtain an   matrix of   vectors. 
\item Apply  means clustering to  the   -dimensional  row  vectors  of the matrix  of Step 2.
\item Identify  the indices of the rows  belonging to cluster  ,  with vertices belonging to block .
\end{enumerate}

In addition to , three graph Laplacian matrices discussed by von Luxburg (2007) \cite{von2007tutorial}, have been considered  extensively, as well as some others we shall mention briefly below and the matrix we shall  show has optimal asymptotic properties and discuss in greater detail. The matrices popularly considered are:
\begin{itemize}
\item :  the graph Laplacian.
\item : the random walk Laplacian.
\item : the symmetric Laplacian. 
\end{itemize}

Here , the diagonal matrix whose diagonal is  the vector  of row sums of .
She considers  optimization problems which are relaxed versions of  combinatorial problems which implicitly define clusters as sets of nodes with more internal than external edges.  and  appear in two of these relaxations. 


The form of step 2 differs for  and   with  the  vectors of the  problem corresponding to the top  eigenvalues of the generalized eigenvalue problem  ,while the  -dimensional vectors of the  problem are obtained by normalizing the rows of the matrix of  eigenvectors corresponding to the  top  eigenvalues  of . Their relation to the  block model is through asymptotics. 

Why is spectral clustering expected to work? Given  generated by a -block model, let  where,  is the number of vertices assigned to type . Then we can write,

where,  is a permutation matrix and  has succesive blocks of  rows,  rows and so on with all the vectors in each row the same. Thus . The same is true of the asymptotic limit of  given .

If asymptotics as  justify concentration of  or  around their expectations then we expect all eigenvalues other than the largest  in absolute value are small. It follows that the  rows of the  eigenvectors associated with the top  eigenvalues should be resolvable into  clusters in  with cluster members identified with rows of , see \cite{MR2893856}, \cite{MR3010899} for proofs.

\subsection{Asymptotics}
\label{sec_asymp}
Now we can consider several  asymptotic regimes  as . Let   be the average degree of the graph.
\begin{itemize}
\item[(I)] \hspace{0.05in} The \emph{dense} regime:  .
\item[(II)] \hspace{0.05in} The \emph{semi dense} regime: .
\item[(III)]  \hspace{0.05in} The \emph{semi sparse} regime: Not semidense but .
\item[(IV)] \hspace{0.05in} The \emph{sparse} regime: .
\end{itemize}

Here are some results in the different regimes. We define a method of vertex assignment  to communities  as a random map  where randomness comes through the dependence of delta on  as a function. Thus spectral clustering using  the various matrices  which depend on  is such a .

\begin{definition}
 is said to be \emph{strongly consistent} if 

\end{definition}
Note that  the blocks are only determined up to permutation.

Bickel and Chen (2009) \cite{bickel2009nonparametric} show that  in the (semi) dense regime a method called profile likelihood is strongly consistent  under minimal identifiability conditions and later this result was extended \cite{MR3127853} to fitting by maximum likelihood or variational likelihood. In fact, in the (semi) dense regime, the block model likelihood asymptotically agrees with the joint likelihood of   and vertex block identities so that efficient estimation of all parameters is possible. It is easy to see that the result cannot  hold in the (semi)sparse regime since  isolated points then exist with probability 1.

Unfortunately all of these methods are computationally  intensive. Although spectral clustering is not strongly consistent, a slight variant, reassigning vertices in any cluster  which are maximally connected to another cluster  rather than  , is strongly consistent.
\begin{definition}
 is said to be \emph{weakly consistent} if and only if 

\end{definition}

Spectral clustering applied  to   \cite{MR3010899} or the Laplacians (\cite{MR2893856} in the manner we have described) has been shown to be weakly consistent in the semi dense to dense regimes. Even weak consistency fails for parts of the sparse regime \cite{abbe2014exact}. The best that can be hoped for is . A sharp problem has been posed and eventually resolved  in a series of papers, Decelle et al \cite{decelle2011asymptotic}, Mossel et al \cite{mossel2013proof}. These writers considered the  case . First, Decelle  et al. \cite{decelle2011asymptotic} argued on physical grounds that if, , then    for any method  and parameters are unestimable from the data even if they satisfy the minimal identifiability conditions  given below. On the other hand  Mossel et al \cite{mossel2013proof} and independently  Massoulie et al \cite{massoulie2014community}, devised admittedly slow methods such that if  then  and parameters can be estimated consistently. 

We now present a fast spectral clustering method given in greater detail in \cite{bhattacharyya2014community} which yields weak consistency  for the semisparse regime on and also has the properties of  the Mossel et al and Massoulie methods. In fact, it reaches the phase transition threshold  for all K not just K=2, but still restricted to , all  and   independent of  for all . 

We note that Zhao et. al. (2015) \cite{gao2015achieving} exhibit a two-stage algorithm which exhibits the same behavior but its properties in sparse case are unknown. The algorithm given in the next section involves spectral clustering of a new matrix, that of all geodesic distances between  and . 



\section{Algorithm}
\label{sec_prel}
As usual let , an undirected graph on  vertices be the data. denote the vertex set by  and the edge set by  with cardinalities  and .







As usual a path between vertices  and  is a set of edges  and the length of such a path is .

The algorithm we propose depends on the graph distance or geodesic distance between vertices in a graph.
\begin{definition}
\label{def_geo_dis}
The \textbf{Graph} or \textbf{Geodesic distance} between two vertices  and  of graph  is given by the length of the shortest path between the vertices  and , if they are connected. Otherwise, the distance is infinite.
\end{definition}
So, for any two vertices , graph distance,  is defined by

For implementation, we can replace  by , when,  and  are not connected, since any path with loops can not be a geodesic. The main steps of the algorithm are as follows
\begin{enumerate}
\item[1.] Find the graph distance matrix  for a given network but with distance upper bounded by . Assign non-connected vertices an arbitrary high value.
\item[2.] Perform hierarchical clustering to identify the giant component  of graph . Let .
\item[3.] Normalize the graph distance matrix on ,  by 

\item[4.] Perform eigenvalue decomposition on .
\item[5.] Consider the top  eigenvectors of normalized distance matrix  and  be the  matrix formed by arranging the  eigenvectors as columns in . Perform -means clustering on the rows , that means, find an  matrix , which has  distinct rows and minimizes .
\item[6.] (Alternative to 5.) Perform Gaussian mixture model based clustering on the rows of , when there is an indication of highly-varying average degree between the communities.
\item[7.] Let  be the block assignment function according to the clustering of the rows of  performed in either Step 5 or 6.
\end{enumerate}
Here are some important observations about the implementation of the algorithm -
\begin{itemize}
\item[(a)] \hspace{0.02in} There are standard algorithms for graph distance finding in the algorithmic graph theory literature. In the algorithmic graph theory literature the problem is known as the \textbf{all pairs shortest path} problem. The two most popular algorithms are Floyd-Warshall \cite{floyd1962algorithm} \cite{warshall1962theorem} and Johnson's algorithm \cite{johnson1977efficient}. 
\item[(b)] \hspace{0.02in} Step 3 of the algorithm is nothing but the classical multi-dimensional scaling (MDS) of the graph distance matrix. 
\item[(c)] \hspace{0.02in} In the Step 5 of the algorithm -means clustering is appropriate if the expected degree of the blocks are equal. However, if the expected degree of the blocks are different, this leads to multi scale behavior in the eigenvectors of the normalized distance matrix and bad behavior in practice. So, we perform Gaussian Mixture Model (GMM) based clustering instead of -means to take into account that.
\end{itemize}

General theoretical results on the algorithm will be given in \cite{bhattacharyya2014community}. In this paper, we first restrict to the sparse regime 
We do so because the arguments in the sparse regime are essentially different from the others. Curiously, it is in the sparse and part of the semi-sparse regime only that the matrix  concentrates to an  matrix with  distinct types of row vectors as for the other methods of spectral clustering. It does not concentrate in the dense regime, while the opposite is true of  and . They do not concentrate outside the semidense regime. That the geodesic matrix does not concentrate in the dense regime can easily be seen since asymptotically all geodesic paths are of constant length. But the distributions of path lengths differs from block to block ensuring that the spectral clustering works. But we do not touch this further here.



\section{Theoretical Results}
\label{sec_geo_theory}


Throughout this section we take  and specialize to the case 

where,  is the identity and . That is, all  blocks have the same probability  of connecting two block members and probability  of connecting members of two different blocks and . We also assume that , , all blocks are asymptotically of the same size. 
We restrict ourselves to this model here because it is the one treated by Mossel, Neeman and Sly (2013) \cite{mossel2013proof} and already subtle technical details are not obscured. Here is the result we prove.
\begin{theorem}
\label{thm_mis}
For the given model, if

and our algorithm is applied,  results and  is the true assignment function, then, 

\end{theorem}
\textbf{Notes:} \begin{enumerate}
\item \eqref{eq_main_cond} marks the phase transition conjectured by \cite{decelle2011asymptotic}.
\item A close reading of our proof shows that as , .
\end{enumerate}

We conjecture that our conclusion in fact holds under the following conditions,
\begin{itemize}
\item[(A1)]\label{ass_main1}\hspace{0.1in} We consider , ,  and . For , there exists a  such that  for all . Also, , for .
\item[(A2)]\label{ass_main2}\hspace{0.1in} Each vertex has the same asymptotic average degree , that is,

\item[(A3)]\label{ass_main3}\hspace{0.1in} We assume that
 
or alternatively, there exists real positive , such that,


\end{itemize}
Note that (A1)-(A3) all hold for the case we consider. In fact, under our model,

with (A3) being the condition of the Theorem.

Our argument will be stated in a form that is generalizable and we will indicate revisions in intermediate statements as needed, pointing in particular to a lemma whose conclusion only holds if an implication of (A3) we conjecture is valid.

The theoretical analysis of the algorithm has two main parts -
\begin{itemize}
\item[I.] Finding the limiting distribution of graph distance between two typical vertices of type  and type  (where, ). This part of the analysis is highly dependent on results from multi-type branching processes and their relation with stochastic block models. The proof techniques and results are borrowed from \cite{bollobas2007phase}, \cite{bhamidi2011first} and \cite{athreya1972branching}.
\item[II.] Finding the behavior of the top  eigenvectors of the graph distance matrix  using the limiting distribution of the typical graph distances. This part of analysis is highly dependent on perturbation theory of linear operators. The proof techniques and results are borrowed from \cite{kato1995perturbation}, \cite{chatelin1983spectral} and \cite{MR3010899}.
\end{itemize}
We will state two theorems corresponding to I and II above.

\begin{theorem}
\label{thm_geo_dis_bnd}
Under our model, the graph distance  between two uniformly chosen vertices of type  and  respectively, conditioned on being connected, satisfies the following asymptotic relation -
\begin{itemize}
\item[(i)] If , for any , as , 

where,  is the minimum real positive , which satisfies the relation below,

\item[(ii)] 
If , for any , as , 

where,  is the minimum real positive , which satisfies the relation below, 

\end{itemize}
\end{theorem}


In Theorem \ref{thm_geo_dis_bnd} we have a point-wise result. To use matrix perturbation theory for part II we need the following.
\begin{theorem}
\label{thm_geo_dis}
Let  be the restriction of the geodesic matrix to vertices in the big component of . Then, under our model, 

where, , if  and  have same type and , otherwise, where,  and  are solutions  in Eq. \eqref{eq_sbm_ev1} and \eqref{eq_sbm_ev2} respectively.
\end{theorem}
To generalize Theorem \ref{thm_mis}, we need appropriate generalizations of Theorem \ref{thm_geo_dis_bnd} and \ref{thm_geo_dis}. Heuristically, it may be argued that the generalizations ,  should satisfy the equations,

Our conjecture is that (A1)-(A3) imply that the equations have asymptotic solutions and that the statements of Theorem \ref{thm_geo_dis_bnd} and \ref{thm_geo_dis} hold with obvious modifications.

Note that in Theorem \ref{thm_geo_dis_bnd}, since ,  there are effectively only two equations and modifications are also needed for other degeneracies in the parameters. We next turn to a branching process result in \cite{bordenave2015non} which we will use heavily.  






\subsection{A Key Branching Process Result}
\label{sec_br_proc}
As others have done we link the network formed by SBM with the tree network generated by multi-type Galton-Watson branching process. In our case, the Multi-type branching process (MTBP) has type space , where a particle of type  is replaced in the next generation by a set of particles distributed as a Poisson process on  with intensity . Recall the definitions of ,  and  from Section \ref{sec_sbm}. We denote this branching process, started with a single particle of type , by . We write  for the same process with the type of the initial particle random, distributed according to . According to Theorem 8.1 of Chapter 1 of \cite{mode1971multitype}, the branching process has a positive survival probability if , where,  is the Perron-Frobenius eigenvalue of , a positive regular matrix. Recall that for our special , .

\begin{definition}
\label{def_survival_prob}
\begin{itemize}
\item[(a)] Define  as the probability that the branching process, , survives for eternity. 
\item[(b)] Define,

as the \textbf{survival probability} of the branching process  given that its initial distribution is 
\end{itemize}
\end{definition}














We denote  as the population of particles of  different types, with  denoting particles of type , at generation  for the Poisson multi-type branching process , with  and  as defined in Section \ref{sec_geo_theory}. From Theorem 24 of \cite{bordenave2015non}, we get that 
\begin{theorem}[\cite{bordenave2015non}]
\label{thm_bp1}
Let  and  be fixed. There exists  such that with probability at least , for all , all , with , 

\end{theorem}
\begin{itemize}
\item[\textbf{Remark:}] \hspace{0.4in}The above stated theorem is a special case of the general theorem stated in \cite{bordenave2015non}. The general theorem is required for generalizing Theorem \ref{thm_mis}. The general version of the theorem is
\begin{theorem}[\cite{bordenave2015non}]
\label{thm_bp2}
Let  and  be fixed. There exists  such that with probability at least , for all  (where,  is the largest integer such that  for all ), all , with , 

and for all , for all , 

Finally, for all , all , .
\end{theorem}
\end{itemize}



\subsection{The Neighborhood Exploration Process}
\label{sec_nbhd_exp}
The neighborhood exploration process of a vertex  in graph  generated from an SBM gives us a handle on the link between local structures of a graph from SBM and multi-type branching process. Recall the definitions of SBM parameters from Section \ref{sec_sbm} and the definitions of Poisson multi-type branching process from Section \ref{sec_br_proc} . We assume all vertices of graph  generated from a stochastic block model has been assigned a community or type  (say) for vertex . 


The \textit{neighborhood exploration process}, , of a vertex  in graph , generates a \emph{spanning tree} of the induced subgraph of  consisting of vertices of at most -distance from . 
The spanning tree is formed from the exploration process which starts from a vertex  as the \emph{root} in the random graph  generated from stochastic block model. The set of vertices of type  of the random graph   that are neighbors of  and has not been previously explored are called  and  for  and . So,  are the children of the root  at step  in the spanning tree of the neighborhood exploration process. The neighborhood exploration process is repeated at second step by looking at the neighbors of type  of the vertices in  that has not been previously explored and the set is called  and  for . Similarly,  are the children of vertices  at step  in the spanning tree of the neighborhood exploration process. The exploration process is continued until step . Note that the process stops when all the vertices in  has been explored. So, if  is connected, then,  the diameter of the graph .


Since, we either consider  connected or only the giant component of , the neighborhood exploration process will end in a finite number of steps but the number of steps may depend on  and is equal to the diameter, , of the connected component of the graph containing the root . It follows from Theorem 14.11 of \cite{bollobas2007phase} that






Now, we find a coupling relation between the \textit{neighborhood exploration process} of a vertex of type  in stochastic block model and a multi-type Galton-Watson process,  starting from a vertex of type . The Lemma is based on Proposition 31 of \cite{bordenave2015non}.

\begin{lemma}
\label{lemma_brpr_sbm}
Let  be a sequence such that  and . Let  be the random rooted tree associated with the Poisson multi-type Galton-Watson branching process defined in Section \ref{sec_sbm} started from  and  be the spanning tree associated with neighborhood exploration process of random SBM graph  starting from . For , where  is the number of steps required to explore  vertices in , the total variation distance, , between the law of  and  at step  goes to zero as .
\end{lemma}
\begin{proof}
Let us start the neighborhood exploration process starting with vertex  of a graph generated from an SBM model with parameters . Correspondingly the multi-type branching process starts from a single particle of type , where,  is the type or class of vertex  in SBM. 

Let  be such that , where,  is defined in the Lemma statement.
Now, for such a , let  be leaves of  at time  starting from a vertex  generated by step  of class . Let  be the vertices exposed at step  of the exploration process starting from a vertex of class , where, . Now, if  is of type , then, we have  follows  and  follows  for , where,  is the number of unused vertices of type  remaining at time  for . Also,  for different  are independent. Note that  for . So, since, we have  for , we get that,



Now, we know that,

So, now, we have,

where,  is the distribution of  under neighborhood exploration process and  is the distribution of  under the branching process, and hence Lemma \ref{lemma_brpr_sbm} follows.
\end{proof}



Now, we restrict ourselves to the giant component of . The size of the giant component of , , of a random graph generated from SBM is related to the multi-type branching process through its survival probability as given in Definition \ref{def_survival_prob}. According to Theorem 3.1 of \cite{bollobas2007phase}, we have,

Under this additional condition of restricting to the giant component, the branching process can be coupled with another branching process with a different kernel. The kernel of that branching process is given in following lemma.
\begin{lemma}
\label{lemma_brpr_cond}
If  is in giant component of , the new branching process has kernel . 
\end{lemma}
\begin{proof}
The proof is given in Section 10 of \cite{bollobas2007phase}.
\end{proof}
Since, we will be restricting ourselves to the giant component of , we shall be using the  matrix as the connectivity matrix in stead of . We abuse notation by referencing to the matrix  as  too.

We proceed to prove the limiting behavior of typical distance between vertices  and  of , where, . We first try to find a lower bound for distance between two vertices. We shall separately give an upper bound and lower bounds for the distance between two vertices of the same type and different types. 

\begin{lemma}
\label{lm_low_bnd}
Under our model, for vertices , if 
\begin{itemize}
\item[(a)] \hspace{0.05in} type of  type of  (say), then, 

where,  is the minimum real positive , which satisfies Eq. \eqref{eq_sbm_ev1},
\item[(b)] \hspace{0.05in} type of   type of  (say), then, 

where,  is the minimum real positive , which satisfies Eq. \eqref{eq_sbm_ev2}.
\end{itemize}
\end{lemma}
\begin{proof}
Let  denote the -distance set of  in , i.e., the set of vertices of  at graph distance exactly  from , and let  denote the -neighborhood  of . Let  denote the set of vertices of type  at -distance in  and let  denote the -neighborhood  of  consisting of vertices of type . Let  be the number of particles at generation  of the branching process  and  be the number of particles at generation  of the branching process  of type . So,  and .

Lemma \ref{lemma_brpr_sbm} involved first showing that, for  large enough, the neighborhood exploration process starting at a given vertex  of  with type  could be coupled with the branching process , where the  is defined by Lemma \ref{lemma_brpr_cond}. As noted we identify  with . 

The neighborhood exploration process and multi-type branching process can be coupled so that for every ,  is at most the number , where,  is number of particles in generation  of  and in  generations at most  vertices of  have been explored. 


From Theorem \ref{thm_bp1}, we get that with high probability

Since, for any , we get the unique representation, , for any basis  of . If we take , where,  is the unit vector with  at -th co-ordinate and  elsewhere, , we can get

Now, under our model one representation of the eigenvectors is , , , , \\ .
Now using the representation of eigenvectors for branching process starting from vertex of type , , we get with high probability

So, we can simplify, for each  with , with high probability,





Set , where,  is the solution to the equation

and set , where,  is the solution to the equation

where,  is fixed and small. Note that both  and  are of the order . Thus, with high probability, for  of type  and ,

So, summing over  and , where,  and , we have, 

and so with high probability

The above statement is equivalent to

for any fixed . 
\end{proof}



Now, we upper bound the typical distance between two vertices of SBM graph .


\begin{lemma}
\label{lm_up_bnd2}
Under our model, for vertices  and conditioned on the event that the exploration process starts from a vertex in the giant component of , if, 
\begin{itemize}
\item[(a)] \hspace{0.05in} type of  type of  (say), then, 

where,  is the minimum real positive , which satisfies Eq. \eqref{eq_sbm_ev1},
\item[(b)] \hspace{0.05in} type of  type of  (say), then, 

where,  is the minimum real positive , which satisfies Eq. \eqref{eq_sbm_ev2}.
\end{itemize}
\end{lemma}
\begin{proof}
We consider the multi-type branching process with probability kernel   and the corresponding random graph  generated from stochastic block model has in total  nodes. We condition that branching process  survives.

Note that an upper bound  is obvious, since we are bounding a probability, so it suffices to prove a corresponding lower bound. We may and shall assume that  for some  . 

Again, let  denote the -distance set of  in , i.e., the set of vertices of  at graph distance exactly  from , and let  denote the -neighborhood  of . Let  denote the set of vertices of type  at -distance in  and let  denote the -neighborhood  of  consisting of vertices of type . Let  be the number of particles at generation  of branching process  and  be the number of particles at generation  of branching process  of type . So,  and .

By Lemma \ref{lemma_brpr_sbm}, for ,

for all  s.t. . This relation between the number of vertices at generation  of type  of branching process , denoted by  and the number of vertices of type  at distance  from  for the neighborhood exploration process of , denoted by  becomes highly important later on in this proof, where, . Note that the relation only holds when  for some  such that  as .





From Theorem \ref{thm_bp1} of the branching process, we get that with high probability



Now following the same line of argument as in proof of Lemma \ref{lm_low_bnd}, for each  with , with high probability we get that,


Let  be the integer part of , where,  is the solution to the equation

Thus conditioned on survival of the branching process , . 
Set , where,  is the solution to the equation

Thus conditioned on survival of branching process ,  for .
Furthermore .


Now, we have conditioned that the branching process with kernel  is surviving. The right-hand side tends to  as . Hence, given any fixed , if we choose  small enough, and for large enough , we have


Now, the neighborhood exploration process and branching process can be coupled so that for every ,  is at most the number  of particles in generation  of  from Lemma \ref{lemma_brpr_sbm} and Eq \eqref{eq_brpr_count1}. So, we have for  of type , with high probability,

if  is small enough, since  is integer part of  and  is the integer part of , where,  and  are solutions to Eq. \eqref{eq_eq1} and \eqref{eq_eq2}. Note that the power  here is arbitrary, we could have any power in the range . 
So, now, we are in a position to apply Eq \eqref{eq_brpr_count1}, as we have , with .

Now let  and  be two fixed vertices of , of types  and  respectively. We explore both their neighborhoods at the same time, stopping either when we reach distance  in both neighborhoods, or we find an edge from one to the other, in which case  and  are within graph distance . We consider two independent branching processes , , with  and  vertices of type  in generation  respectively. By the previous argument, with high probability we encounter  vertices in the exploration so, by the argument leading to \eqref{eq_brpr_count1}, whp either the explorations meet, or 

with the explorations not meeting, where,  is the branching process starting from , for . Using bound on  and the independence of the branching processes, it follows that for , 

and for ,

Write these probabilities as , . We now show that  and since , we will have .
We have not examined any edges from  to , so these edges are present independently with their original unconditioned probabilities. 
For any end vertex types , , the expected number of these edges is at least  for first probability and  for second probability. Choosing  such that , this expectation is . It follows that at least one edge is present with probability . If such an edge is present, then  for first probability and  for second probability. So, the probability that the second event in the above equation holds but not the first is . Thus, the last equation implies that

where,  is arbitrary. Choosing  small enough, we have . As  is arbitrary, we
have

and the lemma follows.
\end{proof}

The equations \eqref{eq_sbm_ev1} and \eqref{eq_sbm_ev2} control the asymptotic bounds for the graph distance  between two vertices  and  in . Under the condition (A3) it follows that . If we consider , where,  is a constant, then the equations \eqref{eq_sbm_ev1} and \eqref{eq_sbm_ev2} can be written in the form of quadratic equations. So, the solutions  and  exist under the condition  and  are of the order  and the resulting solutions  and  are both of the order . Also, from the expression of the solutions  and , the limits  and  exist and we shall define the limit as  and  respectively.  

\subsection{Proof of Theorem \ref{thm_geo_dis_bnd} and Theorem \ref{thm_geo_dis}}
\label{sec_det_geo}
\subsubsection{Proof of Theorem \ref{thm_geo_dis_bnd}}
We shall try to prove the limiting behavior of the typical graph distance in the giant component as . The Theorem essentially follows from Lemma \ref{lm_low_bnd} - \ref{lm_up_bnd2}. Under the conditions mentioned in the Theorem, part (a) follows from Lemma \ref{lm_low_bnd}(a) and \ref{lm_up_bnd2}(a) and part (b) follows from Lemma \ref{lm_low_bnd}(b) and \ref{lm_up_bnd2}(b).
\subsubsection{Proof of Theorem \ref{thm_geo_dis}}
From Definition \ref{def_geo_dis}, we have that  graph distance between vertices  and , where, .
From Lemma \ref{lm_low_bnd}, we get for any vertices  and  with high probability, 

Also, from Lemma \ref{lm_up_bnd2}, we get

Now,  and  are asymptotically constant as both  and  are of the order  as follows from equations \eqref{eq_sbm_ev1} and \eqref{eq_sbm_ev2}. So, putting the two statements together, we get that with high probability,

since, by Lemma \ref{lemma_brpr_sbm},  and  as .
So, putting the two cases together, we get that with high probability, for some ,

Hence, for some ,


We have completed proofs of Theorems \ref{thm_geo_dis_bnd} and \ref{thm_geo_dis}.

\subsection{Perturbation Theory of Linear Operators}
\label{sec_det_pert}
We now establish part II of our program.  can be considered as a perturbation of the operator .

The Davis-Kahan Theorem \cite{davis1970rotation}] gives a bound on perturbation of eigenspace instead of eigenvector, as discussed previously. 
\begin{theorem}[Davis-Kahan (1970)\cite{davis1970rotation}]
\label{thm_dk}
Let  be symmetric, suppose  is an interval, and suppose for some positive integer  that  are such that the columns of  form an orthonormal basis for the sum of the eigenspaces of  associated with the eigenvalues of  in  and that the columns of  form an orthonormal basis for the sum of the eigenspaces of  associated with the eigenvalues of  in . Let  be the minimum distance between any eigenvalue of  in  and any eigenvalue of  not in  . Then there exists an orthogonal matrix  such that .
\end{theorem}

\subsection{Proof of Theorem \ref{thm_mis}} 
\label{sec_proof_thm}
The behavior of the eigenvalues of the limiting operator  can be stated as follows -
\begin{lemma}
Under our model, the eigenvalues of  - , can be bounded as follows -



Also, With high probability it holds that  and \\ 
.
\end{lemma} 
\begin{proof}
The matrix  is a block matrix with blocks of sizes , with . The elements of th block are all same and equal to , if  and equal to , if . Note, diagonal of  is zero, as diagonal of  is also zero. Now, we have the eigenvalues of the  matrix of the values in  to be . If we consider, , then, if , we will have . So, under our model, we have that . So, because of repetitions in the block matrix  and , since, by assumption (A3), , for all . Now, the rest of the eigenvalues of  is zero, so the rest of eigenvalues of  is .


Now, about the second part of Lemma, By Weyl's Inequality, for all ,

Since, from (A1)-(A3), it follows that , for some constant , so,  for large  and .
\end{proof}
Now, let  be the eigenspace corresponding to the top  absolute eigenvalues of  and  be the eigenspace corresponding to the top  absolute eigenvalues of . Using Davis-Kahan
\begin{lemma}
\label{lm_eigsp}
With high probability, there exists an orthogonal matrix  such that 
\end{lemma}
\begin{proof}
The top  eigenvalues of both  and  lies in  for some . Also, the gap  between top  and th eigenvalues of matrix . So, now, we can apply Davis-Kahan Theorem \ref{thm_dk} and Theorem \ref{thm_geo_dis}, to get that,
 
\end{proof}

Now, the relationship between the rows of  can be specified as follows -
\begin{lemma}
\label{lm_rows}
For any two rows  of  matrix, , if type of  type of .
\end{lemma} 
\begin{proof}
The matrix  is a block matrix with blocks of sizes , with . The elements of th block are all same and equal to , if  and equal to , if . Note, diagonal of  is zero, as diagonal of  is also zero. Now, we have the rows of eigenvectors of the  matrix of the values in  that have a constant difference. Under our model, we have that . So, because of repetitions in the block matrix, rows of  as well as the projection of  into into its top  eigenspace has difference of order  between rows of matrix. 
\end{proof}

Now, if we consider -means criterion as the clustering criterion on , then, for the -means minimizer centroid matrix  is an  matrix with  distinct rows corresponding to the  centroids of -means algorithm. By property of -means objective function and Lemma \ref{lm_eigsp}, with high probability,


By Lemma \ref{lm_rows}, for large , we can get constant , such that,  balls, , of radius  around  distinct rows of  are disjoint.

Now note that with high probability the number of rows  such that  is at most , with arbitrarily small constant . If the statement does not hold then,

So, we get a contradiction, since . Thus, the number of mistakes should be at most , with arbitrarily small constant . 

So, for each , if  is the type of  and  is the type of  as estimated from applying -means on top  eigenspace of geodesic matrix , we get that for arbitrarily small constant, , 

So, for constant  and , we get  such that, 



\section{Conclusion}
\label{conclusion}
We have given an overview of spectral clustering in the context of community detection of networks and clustering. We have also introduced a new method of community detection in the paper and we have shown bounds on theoretical performance of the method. 




\bibliographystyle{spmpsci}
\bibliography{network_geodesic_oslo}

\end{document}
