\subsection{Upper Bound}

We now present an algorithm for \textsc{Basic-Counting} that provides a -additive approximation  for  over a binary stream with near-optimal memory.
Denote .
For simplicity, we assume that  and  are integers.
Intuitively, our algorithm partitions the stream into  \emph{blocks} of size , representing each using a single bit. A set bit corresponds to a count of  in the input stream, while a clear bit corresponds to a count of 0. We then use an ``optimistic'' approach to reduce the error -- the number of ones in the input stream not counted using the bit array is \emph{propagated} to the next block; this means a block might be represented with , even if it contains only a single set bit. Surprisingly, we show that this approach allows us to keep the error bounded and that the errors do not accumulate.
We keep a counter  for the number of s.
At the end of a block, if  is larger than , we mark the current block and subtract  from , propagating the remainder to the next block.
Our algorithm answers queries by multiplying the number of marked blocks in the current window by , making corrections to reduce the error.
We maintain the following variables:
\begin{description}
\item[] - a counter for the number of ones.
\item[] - a bit-array of size .
\item[] - the index of the ``oldest'' block in .
\item[] - the sum of all bits in .
\item[] - a counter for the current offset within the block.
\end{description}
\normalsize
Every arriving bit is handled as follows: We increment , and if the bit is set we also increment .
At the end of a block, we check if  exceeds . If so, we subtract  from  and set the bit .
This way, the reduction in  is compensated for by the newly set bit in .
The previous value of , holding information about s that just left the window, is forgotten.

To answer a query the algorithm returns the number of set bits in  multiplied by the block size .
We then add the value of , which represents the number of ones not yet recorded in , and subtract , as  bits of the oldest recorded block have already left the window.
Finally, we remove any bias from the estimation by subtracting  (half a block).

In order to answer queries without iterating over , we maintain another variable , which keeps track of the number of ones in .
The entire pseudo-code is given in Algorithm~\ref{alg:BasicCounting}.

\begin{algorithm}[tb]
\caption{Additive Approximation of Basic Counting}\label{alg:BasicCounting}
\begin{algorithmic}[1]
\State Initialization: .
\Function{add}{Bit }
\If {}
	\State 
	\If {}
		\State 
		\State 
	\Else
		\State 
		\State 
	\EndIf
	\State 
	\State 
	\State 	
\Else
	\State 
	\State 
\EndIf
\EndFunction

\Function{Query}{}
\State \Return {}
\EndFunction
\end{algorithmic}
\end{algorithm}
%
 



\begin{theorem} \label{thm:approximation-ratio-bc}
Algorithm~\ref{alg:BasicCounting} provides a -additive approximation of \bc{}.
\end{theorem}
\begin{proof}
First, let us introduce some notations used in the proof.
Assume that the index of the last bit is , where  is the last bit of a block and .
 is considered after  bits have been processed.
We denote  the value of  \emph{after} adding bit .

The setting for the proof is given in Figure \ref{fig:basic-counting}.
We aim to approximate

\begin{figure}[t!]
\centering
\includegraphics[width=0.8\linewidth,natwidth=1840,natheight=609]{basiccounting.png}
\caption{The setting for the proof of Theorem~\ref{thm:approximation-ratio-bc}.  is cyclic -  represents the oldest block and  the newest completed block.}
\label{fig:basic-counting}
\end{figure}
Our algorithm uses the following approximation:

At times ,  is incremented once for every set bit in the input stream.
At the end of block , if  is reduced by , then  is set and will not be cleared before time .
Therefore, 
Substituting  in \eqref{eq:bc-approximation1}, we get


Plugging
the definition of , we get
.
Therefore, the error is

\noindent
We consider two cases:
\begin{description}
\item [] This means that  had crossed the threshold by time , i.e.

and equivalently .
  Thus, on one side

To bound the error from above we use the fact that the value of  at the end of a block never exceeds .
This can be shown by induction, as  is incremented at most  times during one block, and then reduced by  if it exceeds the block size.
Therefore,

\item [:] Similarly, this means that  was lower than the threshold at the end of block , hence
     or equivalently,
    
    Thus, our error is bounded from below by
    
    and from above by
    
\end{description}

We have established that in all cases the absolute error is at most  as required.
\end{proof}



We next prove that the memory requirement of Algorithm~\ref{alg:BasicCounting} is nearly optimal.
\begin{theorem}
\label{thm:counting-memory}
Algorithm \ref{alg:BasicCounting} requires
 bits of memory.
\end{theorem}

\begin{proof}
We represent  using  bits,  using
 bits and  using  bits.
Additionally,  requires  bits, and  another  bits.
Overall, the number of bits required is

\end{proof}

Theorem \ref{thm:BasicCountingLB} shows that our algorithm uses at most twice as much memory as required by the lower bound (up to a constant number of bits) for every \emph{constant} .
When  is not constant, our memory requirement is at most 3 times the lower bound, as shown in the following lemma.

\begin{corollary}
\label{lemma:algorithm-ratio}
For any , the ratio between the memory consumption of Algorithm~\ref{alg:BasicCounting} and the lower bound for additive approximations for \textsc{Basic-Counting} is

\end{corollary}

Since the proof is very technical, we defer it to Appendix \ref{appendix-bc-optimality}.
