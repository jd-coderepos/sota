\documentclass[a4paper]{article}
\usepackage[latin1]{inputenc} \usepackage[T1]{fontenc} \usepackage{RR,RRthemes}
\usepackage{hyperref}

\usepackage[dvips]{epsfig,graphicx}
\usepackage{verbatim}
\usepackage{array}
\usepackage{color}
\usepackage{colortbl}
\usepackage{fancybox}
\usepackage{longtable}
\usepackage{epsfig}
\usepackage{amsmath,amsfonts}
\usepackage{amssymb}

\pagestyle{myheadings}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{rotating}
\usepackage{longtable,dcolumn,multirow}
\def\rit{\hbox{\it I\hskip -2pt R}}
\def\nit{\hbox{\it I\hskip -2pt N}}
\def\cit{\hbox{\it l\hskip  -6pt C\/}}
\def\lcit{\hbox{\it l\hskip -10.5pt C\/}}
\def\fiteps{\hbox{\it l\hskip -2pt F\/}_\epsilon}
\def\fit{\hbox{\it l\hskip -2pt F\/}}
\def\lsim{\hbox{\hspace{-.7cm} {\stackrel{<}\sim} }}
\def\gsim{\hbox{\hspace{-.7cm} {\stackrel{>}\sim} }}
\def\co{\boldsymbol{i}}
\newcommand{\ds}[2]{\displaystyle{\frac{#1}{#2}}}
\newcommand{\nb}[2]{ #1 \enskip 10^{#2} }
\newcommand{\norm}[1]{\Vert {#1}\Vert }
\newcommand{\neuc}[1]{\left \Vert {#1} \right \Vert_2 }
\newcommand{\nfro}[1]{\Vert {#1}\Vert_F }
\newcommand{\dab}{(\Delta A,\Delta b)}
\newcommand{\dA}{\Delta A}
\newcommand{\db}{\Delta b}
\newcommand{\tx}{\tilde{x}}
\newcommand{\mcg}{{\cal {M}}_{g'}}
\newcommand{\finproof}{\begin{flushright}  \end{flushright}}
\newcommand{\zc}{0_{n,1}}
\newcommand{\zr}{0_{1,n}}

\newtheorem{propos}{Proposition}
\newtheorem{theo}{Theorem}
\newtheorem{coro}{Corollary}
\newtheorem{defi}{Definition}
\newtheorem{Remark}{Remark}
\newtheorem{Algo}{Algorithm}
\newcommand{\alg}[1]{\Algo: {\rm {#1}}}

\RRdate{D\'ecembre 2010}

\RRauthor{Marc Baboulin\thanks{Universit\'e Paris-Sud and INRIA, France
   ({\tt marc.baboulin@inria.fr}).}
  \and
Serge Gratton\thanks{ENSEEIHT and CERFACS, France
   ({\tt serge.gratton@enseeiht.fr}).}
}
\authorhead{Baboulin \& Gratton}
\RRtitle{Une contribution au conditionnement du probl\`eme de moindres carr\'es totaux}
\RRetitle{A contribution to the conditioning of the total least squares problem}
\titlehead{Conditioning of the total least squares}
\RRnote{Also appeared as LAPACK Working Note 236}
\RRresume{Nous d\'erivons des formules exactes pour le conditionnement d'une fonction lin\'eaire de la solution d'un probl\`eme de moindres carr\'es totaux. Etant donn\'e un syst\`eme lin\'eaire sur-d\'etermin\'e , nous montrons que ce conditionnement peut \^etre calcul\'e en utilisant les valeurs singuli\`eres et les vecteurs singuliers \`a droite de  et .
Nous proposons aussi une borne sup\'erieure qui n\'ecessite le calcul de la plus grande et de la plus petite valeur singuli\`ere de 
ainsi que de la plus petite valeur singuli\`ere de . Dans des exemples num\'eriques, nous comparons ces conditionnements et les 
bornes d'erreur directe correspondantes avec les erreurs estimatives donn\'ees dans ~\cite{vava91}.
}
\RRabstract{
We derive closed formulas for the condition number of a linear function of the total least squares solution.
Given an over determined linear system , we show that this condition number can be
computed using the singular values and the right singular vectors of  and .
We also provide an upper bound that requires the computation of the largest and the smallest singular value of 
and the smallest singular value of .
In numerical examples, we compare these values and the resulting forward error bounds
with the error estimates given in~\cite{vava91}.}
\RRmotcle{moindres carr\'es totaux, conditionnement, perturbations normwise,
mod\`ele d'erreur dans les variables}
\RRkeyword{total least squares, condition number, normwise perturbations, errors-in-variables model}
\RRprojet{Grand-Large}  \RRdomaine{Informatique/Analyse num\'erique} \RCSaclay 

\begin{document}
\RRNo{7488}
\makeRR   

\bibliographystyle{plain}

\section{Introduction}
Given a matrix  and an observation vector , the standard
over determined linear least squares (LS) problem consists in finding a vector  such that  is the best approximation of .
Such a problem can be formulated using what is referred to as the linear statistical model

where  is a vector of random errors having expected value
 and variance-covariance .

In the linear statistical model, random errors affect exclusively the observation vector  while  is considered as known exactly. However it is often more realistic to consider that measurement errors might also affect .
This case is treated by the statistical model referred to as Errors-In-Variables model (see e.g~\cite[p. 230]{vava91} and ~\cite[p. 176]{BJORCK}),
where we have the relation

In general it is assumed in this model that the rows of  are independently and identically distributed with common zero mean vector and common covariance matrix.
The corresponding linear algebra problem, discussed originally in~\cite{GVL.80}, is
called the Total Least Squares (TLS) problem and can be expressed as:

where  denotes the Frobenius matrix norm.
As mentioned in~\cite[p. 238]{vava91}, the TLS method enables us to obtain a more
accurate solution when entries of  are perturbed under certain conditions.

In error analysis, condition numbers are considered as fundamental tools since they
measure the effect on the solution of small changes in the data.
In particular the conditioning of the least squares problem was extensively studied in the numerical linear algebra literature (see e.g~\cite{BJORCK,CHA.IPS.95,COHI.99.1,CDW.07,ELDEN,GR.96,HIGHAM,IPSEN,KEN.LAU.98,STEWART}).
The more general case of the conditioning of a linear function of an LS solution was studied
in~\cite{ABG.07} and~\cite{BG.09} when perturbations on data are measured respectively normwise and componentwise
(note that the componentwise and normwise condition numbers for LS problems were also treated in~\cite{CDW.07} but without the generalization to a linear function of the solution).
Moreover we can find in~\cite{BDGL.09} algorithms
using the software libraries LAPACK~\cite{LAPACK} and ScaLAPACK~\cite{SCALAPACK}
as well as physical applications.

The notion of {\bf Total Least Squares} was initially defined in the seminal paper~\cite{GVL.80} that was the first to propose a numerically stable algorithm. Then various aspects of the TLS problem were developed in the comprehensive book~\cite{vava91} including a large survey of theoretical bases, computational methods and applications but also sensitivity analysis with for instance upper bounds for the TLS perturbation.
The so-called {\bf Scaled Total Least Squares} (STLS) problem
(,
for a given scaling parameter )
was formulated in~\cite{CORE} in which were addressed the difficulties coming from non existence of TLS solution.
In a recent paper~\cite{WEI.09}, we can find sharp estimates of the normwise, mixed and componentwise
condition numbers of the Scaled Total Least Squares (STLS) problem.

Here we are concerned with the TLS problem, which is a special case of the STLS problem,
and we will consider perturbations on data  that are measured normwise using a product norm.
Contrary to~\cite{WEI.09}, we will consider the general case of the conditioning of ,
linear function of the TLS solution for which we will derive an exact formula.
The common situations correspond to the special cases where  is the identity matrix
(condition number of the TLS solution) or a canonical vector
(condition number of one solution component).
The conditioning of a nonlinear function of a TLS solution can also be obtained
by replacing, in the condition number expression, the quantity  by the Jacobian matrix at the solution.

We notice that the normwise condition number expression proposed in~\cite{WEI.09} is based on the evaluation of the norm of a matrix expressed as a Kronecker product resulting in large matrices which may be, as pointed out by the authors, impractical to compute, especially for large size problems.
We propose here a computable expression for the resulting condition number (exact formula and upper bound) using data that could be already available from the TLS solution process, namely by-products of the SVD decomposition of  and .
We also make use of the adjoint operator which enables us to work on a space of lower dimension
and we propose a practical algorithm based on the power method.

\section{Definitions and notations}
\subsection{The total least squares problem}

Let  and , with .
Following~\cite{vava91}, we consider the two singular value decompositions
of , and  :  and
. We also set ,
,
where the singular values are in nonincreasing order,
and define , and .
From~\cite[p. 178]{BJORCK}, we have the interlacing property

We consider the total least squares problem expressed in Equation~(\ref{tls})
and we assume in this text that the {\em genericity } condition  holds
(for more information about the "nongeneric" problem see e.g~\cite{vava91,CORE}).
From~\cite[Theorems~2.6 and~2.7]{vava91}, it follows that
the TLS solution  exists, is unique, and satisfies

In addition,  is an eigenvector of
 associated with the simple eigenvalue ,
i.e  guarantees that  is not a
semi-simple eigenvalue of . As for linear least squares problems,
we define the total least squares residual
, which enables us to write

As mentioned in~\cite[p. 35]{vava91}, the TLS solution is obtained by scaling the last right singular vector  of
 until its last.
component is  and, if  denotes the th component of , we have

The TLS method involves an SVD computation and the
computational cost is higher than that of a classical LS problem
(about  as mentioned in~\cite[p. 598]{GOLUB},
to be compared with the approximately  flops
required for LS solved via Householder QR factorization). However, there exist faster methods
referred to as "partial SVD" (PSVD) that calculate only the last right singular vector or a basis
of the right singular subspace associated with the smallest singular values of 
(see~\cite[p. 97]{vava91}).
\subsection{Condition number of the TLS problem}
To measure the perturbations on data  and , we consider
the product norm defined on  by  
and we take the Euclidean norm  for the solution space .
In the following, the  identity matrix is denoted by .

Let  be a given  matrix, with . We suppose here that  is not
perturbed numerically and we  consider  the mapping

Since  is simple,  is a Fr\'echet-differentiable
function of  and , and the genericity assumption ensures that
the matrix  is also Fr\'echet-differentiable
in a neighborhood of . As a result,  is Fr\'echet-differentiable
in a neighborhood of .

The approach that we follow here is based on the work by~\cite{geur82,rice.66} where the mathematical difficulty of a problem is measured by the norm of the Fr\'echet derivative of the problem solution expressed as a function of data. This measure is an attainable bound at first order, and may therefore be approximate when large perturbations are considered.

Using the definition given in~\cite{geur82,rice.66},
we can express the condition number
of , linear function of the TLS solution as


 is sometimes called the {\it absolute} condition number of  as opposed to the {\it relative} condition number of  and defined, when  is nonzero by


In the remainder, the quantity  will be simply referred to as the TLS condition number,
even though the proper conditioning of the TLS solution
corresponds to the special case when  is the identity matrix.\\
In the expression , the "." operator denotes that we apply the linear function  to the
variable . We will use this notation throughout this paper to designate the image of a vector or a matrix by a linear function.
\begin{Remark}
{\rm
The case where , with  being a
differentiable nonlinear function mapping  to 
is also covered because we have

and  would correspond to the Jacobian matrix .
The nonlinear function  can be for instance the Euclidean norm of part of the solution
(e.g in the computation of Fourier coefficients when we are interested in the quantity of signal in a given frequency band).
}
\end{Remark}
\section{Explicit formula for the TLS condition number}
\subsection{Fr\'echet derivative}
In this section, we compute the Fr\'echet d\'erivative of  under
the genericity assumption, which enables us to obtain an explicit formula for the TLS condition number
in Proposition~\ref{propcn}.
\begin{propos}
\label{prop:der}
Under the genericity assumption,   is Fr\'echet differentiable
in a neighborhood of . Setting ,
the Fr\'echet derivative
of  at  is expressed by

\end{propos}
{
\underline{Proof:}
The result is obtained from the chain rule.
Since , expressed in Equation~(\ref{expvp}), is a simple eigenvalue
of  with corresponding unit
eigenvector ,
 is differentiable in a neighborhood of  and then we have

yielding


Applying the chain rule to , we obtain


The chain rule now applied to  leads to

which gives the result.
\finproof
}

We now introduce the vec operation that stacks all the columns of a matrix into
a long vector:  for , vec.
Let  denote the permutation matrix that represents
the matrix transpose by .  We remind also that
, where  denotes the Kronecker product of two matrices
~\cite[p. 21]{KRONECKER}.

Let us now express the matrix representing , denoted by .
Since , we have
 and setting in addition , we obtain from~(\ref{funct})

Then we get

But we have  and then, from Proposition~\ref{prop:der}
and using the definition of  given in Expression~(\ref{exp:defcn}),
we get the following proposition that expresses the TLS condition number in terms of the norm of a matrix.
\begin{propos}
\label{propcn}
The condition number of  is given by

where

\end{propos}
\subsection{Adjoint operator and algorithm}\label{sec:adj}
Computing  reduces to computing the spectral norm
of the  matrix . For large values of
 or , it is not possible to build explicitly the generally
dense matrix . Iterative techniques based on the power method~\cite[p. 289]{HIGHAM} or on the
Lanczos  method~\cite{GOLUB} are better suited. These algorithms
involve however the computation of the product of  by a
vector . We describe now how to perform this operation.

Using successively the fact that , ,
 and  we have

and since for any matrix  we have , we get


This leads us to the following proposition.
\begin{propos}
\label{prop:adj}
The adjoint operator of  using the scalar products\\
 and  respectively on
 and  is

In addition,  if  we have

\end{propos}

{
\underline{Proof:}
Let us denote by   the scalar product  on .
We have  for any ,

Using now the fact that, for matrices  and  of identical sizes,\\
,
we get

which concludes the first part of the proof.

For the second part, we
use

Since , we have , and

and the result follows from the relation 
\finproof
}
\begin{Remark}
{\rm
The special case  recovers the situation where we compute the conditioning
of the th solution component.
In that case  is the th canonical vector of  and, in
Equation~(\ref{kap1}),
 is the th row of  and
 is the th row of .
}
\end{Remark}

Using~(\ref{funct}) and~(\ref{functt}), we can now write in Algorithm 1
the iteration of the power method (~\cite[p. 289]{HIGHAM}) to compute the TLS condition number .

\setlength{\fboxsep}{0.45cm}
\setlength{\fboxrule}{0.02cm}
\begin{center}
\fbox{
\begin{minipage}{0.8\textwidth}
{\bf Algorithm 1} : Condition number of TLS problem
\begin{description}
\item[~] Select initial vector 
\item[~] {\bf for p=1,2,...}
\item[~] \hspace{0.5cm} 
\item[~] \hspace{0.5cm} 
\item[~] \hspace{0.5cm} 
\item[~] \hspace{0.5cm} 
\item[~] {\bf end}
\item[~] 
\end{description}
\end{minipage}
}
\end{center}
The quantity  computed by Algorithm 1 is the largest eigenvalue of .
Since  then the condition number  is also the largest singular value of  i.e .
As mentioned in~\cite[p. 331]{GOLUB}, the algorithm will converge if the initial  has a component in the direction of the corresponding dominant eigenvector of . When there is an estimate of this dominant eigenvector, the initial  can be set to this estimate but in many implementations,  is initialized as a random vector.
The algorithm is terminated by a "sufficiently" large number of iterations or by
evaluating the difference between two successive values of  and comparing it to a tolerance given by the user.

\subsection{Closed formula}
Using the adjoint formulas obtained in Section~\ref{sec:adj}, we now get a closed formula for the total least squares conditioning.
\begin{theo}
\label{theo:cond}
We consider the total least squares problem and assume that the genericity assumption holds.
Setting ,
then the condition number of , linear function of the TLS solution, is expressed by

where  is the  symmetric matrix

\end{theo}
{
\underline{Proof:}
We have
. If  is a unit vector in , then using Equation~(\ref{exp:adj}) we obtain

For all vectors  and , we have . Moreover we have

Thus

i.e
 with

Replacing  by
, Equation~(\ref{exp1:C}) simplifies to

But  and, since from Equation~(\ref{soltls}) we have ,
we get

From Equation~(\ref{expvp}) we also have  and thus
Equation~(\ref{exp2:C}) becomes

\finproof
}
\section{TLS condition number and SVD}
\subsection{Closed formula and upper bound}

Computing  using Theorem~\ref{theo:cond} requires the explicit formation of the normal equations matrix  which is a source of rounding errors and also generates an extra computational cost of about  flops. In practice the TLS solution is obtained by Equation~(\ref{exp:basicsol}) and involves an SVD computation.
In the following theorem, we propose a formula for  that can be computed with quantities that may be already available from the solution process.
In the following  (resp. ) denotes the zero column (resp. row) vector of length .
\begin{theo}
\label{theo:cntls}
Let  and  be the matrices whose columns are the right singular vectors of respectively  and  associated with the singular values
 and . Then the condition number of , linear function of the TLS solution is expressed by


When  is the identity matrix, then the condition number reduces to

\end{theo}

{
\underline{Proof:}
From , we have
 and

leading to

From Equation~(\ref{exp:basicsol}), we have 
and, since  is a unit vector, .
Then Equation~(\ref{exp:demcntls1}) can be expressed in matrix notation as

The quantity 
corresponds to the left-hand side of Equation~(\ref{exp:demcntls2}) in which the last row and the last column have
been removed. Thus it can also be written

and the matrix  from Theorem~\ref{theo:cond} can be expressed

Moreover from , we have
 and

Hence  and
.\\
We also have \\
Then, by replacing in Equation~(\ref{exp:demcntls3}), we obtain
 with
.
As a result, using Theorem~\ref{theo:cond},

When , we use the fact that  is an orthogonal matrix and can be removed from the expression of
.
\finproof
In many applications, an upper bound would be sufficient to give an estimate of the conditioning of the TLS solution. The following corollary gives an upper bound for .
\begin{coro}
\label{coro:ubcntls}
The condition number of , linear function of the TLS solution is bounded by

\end{coro}
{
\underline{Proof:}
This result comes from the inequality
, followed by
 and
.
\finproof

\subsection{Numerical examples}
In the following examples we study the condition number of  i.e  is here the identity matrix .
Then, to simplify the notations, we removed the variable  from the expressions and the condition number of 
 will be denoted by  and its upper bound by .
All the experiments were performed with MATLAB 7.6.0 using a machine precision .
\subsubsection{First example}
In the first example we consider the TLS problem  where  is defined by

where  and  are random unit vectors,
 for a given parameter .
The quantity  measures the distance of our problem to
nongenericity and, due to Equation~(\ref{interlace}), we have in exact arithmetic

Then by varying , we can generate different TLS problems and by considering small values of , it is possible to study the behavior of the TLS condition number in the context of close-to-nongeneric problems.
The TLS solution  is computed using an SVD of  and Equation~(\ref{exp:basicsol}).

In Table~\ref{tab:num2}, we compare the exact condition number  given in Theorem~\ref{theo:cntls},
the upper bound  given in Corollary~\ref{coro:ubcntls},
and the upper bound obtained from~\cite[p. 212]{vava91}
and expressed by

We also report the condition number computed by Algorithm 1, denoted by ,
and the corresponding number of power iterations
(the algorithm terminates when the difference between two successive values is lower than ).
When  decreases, the TLS problem becomes worse conditioned and there is a factor 
between the exact condition number  and its upper bound .
We also observe that  is an estimate of better order of magnitude than
 and that, for small values of ,  is much less reliable.
 is always equal or very close to .
\begin{table}[hbtp!]
\centering
\caption{TLS conditioning for several values of .}
\vspace{0.4cm}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
&&&&&\\
&&&&&\#iter\\
&&&&&\\
\hline
&&&&&\\
\hline
&&&&&\\
\hline
&&&&&\\
\hline
&&&&&\\
\hline
\end{tabular}
\label{tab:num2}
\end{table}
\subsubsection{Second example}
Let us now consider the following example from~\cite[p. 42]{vava91} also used in ~\cite{WEI.09} where

The exact solution of the TLS problem  can be computed analytically~\cite[p. 42]{vava91} and is equal to .
We consider a random perturbation  of small norm  and we denote by  the computed solution of the perturbed system .

In Table~\ref{tab:num1}, we report for several values of  the {\it relative} condition number as defined in~(\ref{exp:defcnrel})
and we compare the computed relative forward error  with the forward error bounds that can be expected from the computation of  and its upper bounds  and .
Since the condition number corresponds to the worst case in error amplification at first order, these quantities are, as observed in Table~\ref{tab:num1}, always larger than the computed forward error
(there is approximately a factor  between those quantities).
We also observe that, in this example,  and  produce forward error estimates that are of same order of magnitude.
\begin{table}[hbtp!]
\centering
\caption{Forward error and upper bounds for a perturbed TLS problem.}
\vspace{0.4cm}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
&&&&&\\
&&& &&\\
&&&&&\\
\hline
50&&&&&\\
\hline
100&&&&&\\
\hline
500&&&&&\\
\hline
1000&&&&&\\
\hline
\end{tabular}
\label{tab:num1}
\end{table}
\section{Conclusion}
We proposed sensitivity analysis tools for the total least squares problem when the genericity condition is satisfied.
We provided closed formulas for the condition number of a linear function of the TLS solution when the perturbations
of data are measured normwise.
We also described an algorithm based on an adjoint formula and we expressed this condition number and an upper bound
of it in terms of the SVDs of  and . We illustrated the use for these quantities in two numerical examples.

\bibliography{biblio}

\newpage
\tableofcontents

\end{document}
