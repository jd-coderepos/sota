


\documentclass[a4paper,USenglish,numberwithinsect]{lipics}



\usepackage{etex} \usepackage[]{graphicx}
\pagestyle{headings}
\usepackage{etoolbox} 

\newif\ifignore \ignorefalse
\newcommand{\auxproof}[1]{
\ifignore\mbox{}\newline
\textbf{BEGIN: AUX-PROOF} \dotfill\newline
{#1}\mbox{}\newline
\textbf{END: AUX-PROOF}\dotfill\newline
\fi}
\def\comment#1{\ifignore \marginpar[\renewcommand{\baselinestretch}{0.9}\raggedleft\sloppy{}#1]{\renewcommand{\baselinestretch}{0.9}\raggedright\sloppy{}#1}\fi}







\usepackage{hhline}
\usepackage{fancybox,amssymb,amstext,amsmath,stmaryrd,wasysym,cite,proof,mathtools}
\usepackage[pdftex,all]{xy}
\usepackage{xspace}
\allowdisplaybreaks[1] \usepackage{pstricks}


\xyoption{v2}
\xyoption{curve}
\xyoption{2cell}
\SelectTips{cm}{}  \UseAllTwocells
\SilentMatrices
\def\labelstyle{\scriptstyle}
\def\twocellstyle{\scriptstyle}
\newdir{ >}{{}*!/-8pt/@{>}}  
\newdir{|>}{!/1.6pt/@{|}*:(1,-.2)@^{>}*:(1,+.2)@_{>}}
\newdir{pb}{:(1,-1)@^{|-}}
  \def\pb#1{\save[]+<20 pt,0 pt>:a(#1)\ar@{pb{}}[]\restore}
\newcommand{\shifted}[3]{\save[]!<#1,#2>*{#3}\restore}




\usepackage{wrapfig}
\setlength{\intextsep}{.1\intextsep}
\setlength{\columnsep}{.7\columnsep}



\setlength{\abovecaptionskip}{2pt}


\newcommand{\true}{\mathtt{True}}
\newcommand{\false}{\mathsf{False}}
\newcommand{\X}{\mathsf{X}}
\newcommand{\F}{\mathsf{F}}
\newcommand{\Fdisc}[1]{\mathop{\F\raisebox{-.2ex}[0ex][0ex]{}}\nolimits}
\newcommand{\G}{\mathsf{G}}
\newcommand{\Gdisc}[1]{\mathop{\G\raisebox{-.2ex}[0ex][0ex]{}}\nolimits}
\newcommand{\U}{\mathbin{\mathsf{U}}}
\newcommand{\R}{\mathbin{\mathsf{R}}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Sbb}{\mathbb{S}}

\newcommand{\Lang}{\mathcal{L}}

\newcommand{\A}{\mathcal{A}}
\newcommand{\Ap}{\mathcal{A}^{\mathrm{p}}}
\newcommand{\Ana}{\mathcal{A}^{\mathrm{na}}}
\newcommand{\K}{\mathcal{K}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\Dexp}{\D_{\expo}}
\newcommand{\Fcal}{\mathcal{F}}
\newcommand{\Fcalmc}{\Fcal_{\mathrm{mc}}}
\newcommand{\Pcal}{\mathcal{P}}

\newcommand{\expo}{\mathrm{exp}}

\newcommand{\coloneqq}{\mathrel{\mathop:}=}

\newcommand{\LTLdE}{\textrm{LTL}^\mathrm{disc}[\Dexp]}
\newcommand{\LTLd}[1]{\textrm{LTL}^\mathrm{disc}[#1]}
\newcommand{\LTLdD}{\LTLd{\D,\Fcal}}
\newcommand{\Sub}{\mathop{\mathrm{Sub}}\nolimits}
\newcommand{\place}{\underline{\phantom{n}}\,} \newcommand{\run}{\mathop{\mathrm{run}}\nolimits}
\newcommand{\pathrm}{\mathop{\mathrm{path}}\nolimits}
\newcommand{\ttrue}{\mathtt{t{\kern-1.5pt}t}}
\newcommand{\ffalse}{\mathtt{f{\kern-1.5pt}f}}
\newcommand{\qp}{\mathop{\mathrm{qp}}\nolimits}
\newcommand{\sem}[1]{\llbracket #1 \rrbracket} 
\newcommand{\dotminus}{\mathbin{\scriptstyle\dot{\smash{\textstyle-}}}}
\newcommand{\AP}{\mathit{AP}}
\newcommand{\concatseq}{\mathbin{:}}

\newcommand{\deletewords}[1]{}    \newcommand{\deletelinebreak}{}   \newcommand{\addwords}[1]{#1}     \newcommand{\movewordsfrom}[2]{}  \newcommand{\movewordsto}[2]{#1}  \newcommand{\replacewords}[2]{#2} 

\setcounter{totalnumber}{10}







\theoremstyle{definition}
\newtheorem{defi}{Definition}[section]

\theoremstyle{remark}
\newtheorem{rem}[defi]{Remark}
\newtheorem{exam}[defi]{Example}
\newtheorem{notation}[defi]{Notation}

\theoremstyle{plain}
\newtheorem{prop}[defi]{Proposition}
\newtheorem{cor}[defi]{Corollary}
\newtheorem{lem}[defi]{Lemma}
\newtheorem{sublem}[defi]{Sublemma}
\newtheorem{thm}[defi]{Theorem}



\AtEndEnvironment{thebibliography}{
}

\title{Near-Optimal Scheduling  for
 LTL with Future Discounting}


\author{Shota Nakagawa}
\author{Ichiro Hasuo}

\affil{Department of  Computer Science, The University of Tokyo
}

\authorrunning{S. Nakagawa and I. Hasuo} 

\Copyright{Shota Nakagawa and Ichiro Hasuo} 

\subjclass{F.1.1 Models of Computation}

\keywords{quantitative verification,
optimization,
temporal logic} 

\serieslogo{}\volumeinfo {Billy Editor and Bill Editors}{2}{Conference title on which this volume is based on}{1}{1}{1}\EventShortName{}
\DOI{10.4230/LIPIcs.xxx.yyy.p}

\begin{document}








\maketitle              

 \begin{abstract}
  We study the search problem for optimal schedulers for the \emph{linear temporal
  logic (LTL) with future discounting}.  The logic, introduced by
  Almagor, Boker and Kupferman, is a quantitative variant of LTL in
  which an event in the far future has only discounted contribution to a
  truth value (that is a real number in the unit interval ). The
  precise problem we study---it naturally arises e.g.\ in search for a
  scheduler that recovers from an internal error state as soon as
  possible---is the following: given a Kripke frame, a formula and a
  number in  called a \emph{margin}, find a path of the Kripke
  frame that is optimal with respect to the formula up to the prescribed
  margin (a truly optimal path may not exist). We present an algorithm
  for the problem; it works even in the extended setting with 
  propositional quality operators, a setting where (threshold)
  model-checking is known to be undecidable.
















  


  





  




  




\end{abstract}







\section{Introduction}\label{sec:intro}
In the field of \emph{formal methods} where a mathematical approach is
taken to modeling and verifying systems, the conventional theory
is built around the Boolean notion of truth: if a given system
satisfies a given specification, or not. This \emph{qualitative} theory
has produced an endless list of notable achievements from hardware
design to communication protocols. Among many techniques,
\emph{automata-based} ones for verification and synthesis have been
particularly successful in serving engineering needs, by offering 
a specification method by temporal logic and  push button-style
algorithms. See e.g.~\cite{Vardi96anautomata-theoretic,PnueliR89}.

However, trends today in the use of computers---computers as
part of more and more \emph{heterogeneous} systems---have pushed
researchers to turn to \emph{quantitative} consideration of systems,
too. For example, in an \emph{embedded system} where
a microcomputer 
controls a bigger system  with  mechanical/electronic components, 
concerns include  \emph{real-time properties}---if an expected task
is finished within the prescribed deadline---and \emph{resource consumption}
e.g.\ with respect to electricity, memory, etc. 

Quantities in formal methods can thus arise from a specification (or
 an \emph{objective}) that is quantitative in nature. Another
source of quantities are systems that are themselves quantitative, such
as one with
probabilistic 
behaviors.


Besides, quantities  can arise simply via \emph{refinement} of the Boolean notion of
 satisfaction. For example, consider 
the usual interpretation of the \emph{linear
 temporal logic (LTL)} formula
 ---it 
is satisfied by a sequence 
 
if there exists  such that . 
 It has the following natural
 quantitative refinement, where the modality  is replaced with 
 a \emph{discounted} modality :

This value  is a
quantitative \emph{truth value} and is like \emph{utility} in the
game-theoretic terminology.
Such  refinements allow quantitative  reasoning about
so-called \emph{quality of service (QoS)}, specifically ``how soon 
becomes true'' in this example. Another example is a quantitative
variation  of , where
---where  is the least index such that
  ---meaning that violation of  in the far future only has a small
negative
impact.


\noindent\textbf{: LTL with Future Discounting}\quad
The last examples are about quantitative refinement of temporal
specifications. An important step in this direction is taken
in the recent work~\cite{AlmagorBK14}.
There various useful quantitative refinements in
LTL---including the last examples---are unified under the notion of
\emph{future discounting}, an idea first presented in~\cite{AlfaroHM03}
in the field of formal methods. They introduce a clean syntax of
the logic  ---called
\emph{LTL with discounting}---that combines: 1) a ``discounting until'' operator
; 2) the usual features of LTL such as the non-discounting
one ;  and 3) so-called propositional
quality operators such as the (binary) average operator , in
addition to  and . In~\cite{AlmagorBK14} they define its semantics; and importantly, they
show that  usual automata-theoretic techniques for verification and
synthesis (e.g.\ from~\cite{Vardi96anautomata-theoretic,PnueliR89})
mostly remain applicable.  

Probably the most important algorithm in~\cite{AlmagorBK14} is for the
\emph{threshold model-checking problem}: given a Kripke structure ,
a formula  and a \emph{threshold} , it asks if 
, i.e.\ 
the
worst case truth value of a path of  is above  or
not.
The core idea of
 the algorithm
is what we call an \emph{event horizon}: assuming that a discounting
function  in  tends to  as time goes by, and
that , there exists a time beyond which nothing is 
significant enough
to change the answer to the threshold model-checking problem.
In this case we can approximate an infinite path by its finite prefix.


\noindent
\textbf{Our Contribution: Near-Optimal Scheduling for
}\quad
Now that a temporal formula  assigns quantitative \emph{truth}
or \emph{utility}  to each path , a natural task is
to find a path  in a given Kripke structure  that achieves the
optimal. On the ground that the logic  from~\cite{AlmagorBK14} is capable of 
expressing many common specifications encountered in real-world
problems, finding an optimal path---i.e.\ resolving nondeterminism in
the best possible way---must have numerous applications. The situation
is similar to one with \emph{timed automata}, for which optimal
scheduling problems are studied e.g.\ in~\cite{AbdeddaimAM06}. 


It turns out, however, that 
a (truly) optimal path need not exist
(Example~\ref{exam:optimalityNotAchievable}):
 is obviously a limit point but no
 achieves . This leads us to the
following \emph{near}-optimal scheduling problem:
\begin{quote}
 \textbf{Near-optimal scheduling.}
 Given a Kripke structure , an  formula  and a
 \emph{margin}
 , find a path  that is
 \emph{-optimal}, that is,
 
\end{quote}
We study automata-theoretic algorithms
for this problem. In the basic setting where there are no propositional
quality operators, we can find  a straightforward algorithm  that conducts
binary search using the model-checking algorithm
from~\cite{AlmagorBK14}. 
Our main contribution, however,  is
 an alternative algorithm  that
takes the usual workflow: it
constructs, from
a formula  and a margin , 
 an automaton 
 with which we combine a system model ;
running a nonemptiness check-like algorithm to the resulting automaton then
yields an answer. 

On  the one hand, our (alternative) algorithm  resembles the one in~\cite{AlmagorBK14}. 
In particular it  relies on the idea of event horizon:
a margin  in our setting plays the role
of a threshold  in~\cite{AlmagorBK14} and
enables us to ignore events in the far future.


On the other hand, a major difference from~\cite{AlmagorBK14} 
is that we translate a specification
 into an automaton that is itself quantitative
(what we call a \emph{-acceptance
automaton}, with  Boolean
branching and -acceptance values). This is 
unlike~\cite{AlmagorBK14} where the target automaton
is totally Boolean.
An advantage of  -acceptance
automata is that they allow optimal path search 
much like
emptiness of B\"uchi automata is checked (via
lasso computations). 
Applied to our current problem, 
this enables us to directly find a
near-optimal path
for 
without knowing the optimal value
.

\noindent
\textbf{Presence of  and Other Propositional Quality Operators}\quad
Notably,  our  (alternative) algorithm is shown to work even in the presence
 of
 any propositional quality operators that are \emph{monotone} and
 \emph{continuous} (in the sense we will define later; an example is the
 average operator ). 
Those operators makes the logic  more complex: indeed~\cite{AlmagorBK14}
shows that, in presence of 
 the average operator , the model-checking problem for the logic
  becomes
 undecidable.
 The binary-search algorithm mentioned earlier (that
 repeats model checking) ceases to work for this reason; our
 alternative algorithm works, nevertheless.





We analyze the complexity of the proposed algorithm, focusing on a certain
subclass of the logic  (\S\ref{subsec:complexity}). Furthermore
we present our prototype implementation and some experimental
results (\S\ref{sec:experiments}). They all seem to suggest the following: addition of propositional
quality
operators (like the average operator ) does incur substantial
computational costs---as is expected from the fact that  makes
model checking undecidable; still our automata-theoretic approach is a
viable approach, potentially applicable to optimization 
problems in the field of model-based system design. 

The significance of the average operator  in
envisaged applications is that it allows one to \emph{superpose} multiple
objectives. For example, one would want an event  as soon as
possible, but at the same time avoiding a different event  as long as
possible. This is a trade-off situation and the formula
---with suitable discounting
functions ---represents a 50-50 trade-off. Other
 trade-off ratios can be represented as (monotone and continuous) proportional quality operators, too,
and our algorithm accommodates them.








\noindent
\textbf{Related Work}\quad
Quantitative  temporal logics and their decision procedures
have  been a very active research
topic~\cite{AlmagorBK14,AlmagorBK13,AlfaroHM03,BouyerMM14,FaellaLS08}. 
 We shall lay them out along a basic taxonomy. We denote by   (the model of) the
system against which a specification formula  is verified (or tested, synthesized,
etc.).


\begin{itemize}
\item
  \textit{Quantitative vs.\ Boolean system models.} Sometimes we need
       quantitative considerations just because the system
         itself is quantitative. This is the case e.g.\ when  is a Markov chain, a Markov decision
       process, a timed or hybrid automaton, etc. In the current work
        is a Kripke structure and is Boolean.

\item
 \textit{Quantitative vs.\ Boolean truth values.} The previous
       distinction is quite orthogonal to whether a formula 
       has truth values from  (or another continuous domain), or from
       . For example, the temporal logic PCTL~\cite{HanssonJ94} for
       reasoning about probabilistic systems has modalities
       like  (`` with a probability 
       '') and has Boolean interpretation.  In  studied  here,
       truth values are from .

\item
 \textit{Linear time vs.\ branching time.} This distinction is
       already there in the qualitative/Boolean
       setting~\cite{vanGlabbeek01}---its probabilistic variant is
       studied in~\cite{CheungSV07}---and gives rise to temporal logics
       with the corresponding flavors (LTL vs.\ CTL, ).
       In fact the idea of future discounting is first introduced to 
       a branching-time logic in~\cite{AlfaroHM03}, where an
       approximation algorithm for truth values is presented.



\item
 \textit{Future discounting vs.\ future averaging.} The temporal
       quantitative operators in  are \emph{discounting}---an
     event's significance tends to  as time proceeds---a fact that
       benefits model checking  via event horizons. 
        Different  temporal
       quantitative operators are studied in~\cite{BouyerMM14}, including the
       \emph{long-run average} operator . 
     Presence of , however, makes most
       common decision problems undecidable~\cite{BouyerMM14}.

\end{itemize}

In~\cite{FaellaLS08} LTL (without additional quantitative operators)
is interpreted over the unit interval , and its model-checking
problem against quantitative systems  is shown to be decidable. 
In this setting---where the LTL connectives are interpreted by
   idempotent operators 
and ---the variety of truth values arises only from a finite-state
quantitative system , hence is finite.




In~\cite[Thm.~4]{AlmagorBK14} it is proved that the \emph{threshold
synthesis} problem for the logic  (see Def.~\ref{def:LTLdDSyntax}) is feasible. This problem asks:
given a partition of atomic propositions into the input and output
signals, an  formula  and , to come up with a transducer (i.e.\ a finite-state strategy)
 that makes the truth value of  at least
. 
We remark that this is
different from the near-optimal scheduling problem that we
solve
in this paper. The \emph{synthesis} problem
in~\cite[\S{}2.2]{AlmagorBK13}, without a threshold, is closer to ours.


Automata- (or game-) theoretic approaches are  taken 
in~\cite{BloemCHJ09,CernyCHRS11}
to the synthesis of controllers or programs with better
quantitative performance, too. In these papers, a specification is 
given itself as an automaton, instead of a temporal formula in the
current work. Another difference is that, in~\cite{BloemCHJ09,CernyCHRS11}, utility is computed
along a path by limit-averaging, not future discounting. The algorithms in~\cite{BloemCHJ09,CernyCHRS11} therefore rely on 
those which are known for mean-payoff games, including the ones
in~\cite{ChatterjeeHJ05}.

More and more
diverse quantitative measures of systems' QoS are studied recently:
from best/worst case probabilities and costs, to quantiles,
conditional probabilities and ratios. See~\cite{BaierDK14} and the
references
therein.  Study of such in  is future work.

In~\cite{ChatterjeeDH10} so-called \emph{cut-point languages} of 
weighted automata are studied.
Let  be the quantitative 
language of a weighted automata .
For a threshold , the cut-point language of  is 
the set consisting of all words  such that .
In~\cite{ChatterjeeDH10} it is proved that the cut-point languages of 
deterministic limit-average automata and those of discounted-sum automata 
are -regular if the threshold  is \emph{isolated}, that is, 
there is no word  such that  is close to . 
We expect that similar properties for the logic  are not hard to
establish, although details are yet to be worked out.












\noindent
\textbf{Organization of the Paper} \quad
In~\S{}\ref{sec:syntaxAndThresholdProblem} we review the logic
 and known results on threshold model checking and
satisfiability,
all from~\cite{AlmagorBK14}. We introduce  quantitative
variants of (alternating) B\"uchi automata, called
(alternating)  -acceptance automata,
in~\S{}\ref{sec:zeroOneAutomata}, with  auxiliary observations on their
relation to \emph{fuzzy automata}~\cite{Rahonis05}.
These automata
play a central role in~\S{}\ref{sec:nearOptimalSchedulerSynth} where we
formalize and solve the near-optimal scheduling problem for the logic
 (under certain assumptions on  and ).
We also study complexities, focusing on the average operator  as
the only propositional quality operator. In~\S{}\ref{sec:experiments} we
present our implementation and some experimental results;
in~\S{}\ref{sec:conclFutureWork} we conclude, citing some future work.
Omitted proofs are found in Appendix~\ref{appendix:omittedproofs}.



\noindent
\textbf{Notations and Terminologies} \quad
We shall fix some notations and terminologies, mostly
following~\cite{AlmagorBK14}.  They are all standard.

The powerset of a set  is denoted by .
We fix the set   of \emph{atomic propositions}.
 A
\emph{computation} (over ) is an infinite sequence  over the alphabet
 . 
For , 
 
denotes the suffix of  starting from its -th element.


A \emph{Kripke structure} over  is a tuple  of:  
  a finite set  of states; a  transition
 relation 
  
that is left-total (meaning that ), and a labeling function  . 
We follow~\cite{KupfermanVW00} and call an infinite sequence   of states , such that
  for each ,  a \emph{path} of
  a Kripke structure .
The set of paths of  is
 denoted by . A path
 gives rise to a computation
; the
  latter is  denoted by .

Given a set , 
  denotes, as
 usual, the set of positive propositional formulas (using
 ) over   as atomic
 propositions.




\section{The Logic , and Its Threshold Problems}
\label{sec:syntaxAndThresholdProblem}
Here we recall from~\cite{AlmagorBK13,AlmagorBK14}  our target
logic, and some existing (un)decidability results.

The logic   extends LTL with: 1) 
propositional quality operators~\cite{AlmagorBK13} like the 
average operator ; and 2) discounting in temporal
operators~\cite{AlmagorBK14}. In~\cite{AlmagorBK14} the two extensions
have been studied separately because their coexistence leads to undecidability
of the (threshold) model-checking problem; here we put them altogether.

\auxproof{The logic is quantitative---a truth value is a
number in the unit interval  rather than a Boolean value from
. The logic features fixed point operators with
future discounting. 
}

 The logic  has two parameters: 
a set  of discounting
functions; and a set  of propositional connectives,
called propositional quality operators. 
\begin{defi}[discounting function~\cite{AlmagorBK14}]\label{def:discountFunction}
 A \emph{discounting function} is a strictly decreasing function  such that . A
 special case is an \emph{exponential discounting function}
 , where , that is defined by
 . 

 The set
 is that of exponential discounting
 functions.
\end{defi}

\auxproof{
\begin{rem}An extension of the framework is proposed in~\cite{AlmagorBK14} where a discounting functions  need
 not tend to . It is claimed that
 such an extension, e.g.\ when  tends to , is suited for
 the situation where we are (not totally pessimistic but) ambivalent
 about the future. This extension does not change the algorithmic
 results in~\cite{AlmagorBK14}, nor here. It is
 enough that the limit value  is statically known so that
 we can use the value in construction of automata.
\end{rem}
}



\begin{defi}[(monotone and continuous) propositional quality
 operator~\cite{AlmagorBK13}]\label{def:propositionalQualityOperator}
 Let  be a natural number.
 A -ary \emph{propositional quality operator} is a 
 function
 . 

 We will eventually restrict to  propositional quality operators that are 
 \emph{monotone} (wrt.\ the usual order between real numbers)
 and \emph{continuous} (wrt.\ the usual Euclidean topology). 
 The set of monotone and continuous propositional quality operators
is denoted by .
\end{defi}


\begin{exam}\label{exam:propositionalQualityOperator}
 A prototypical example of a propositional quality operator is 
the \emph{average operator} , defined
 by . (Note that  is a
 ``propositional'' average operator and is different from the
 ``temporal'' average operator 
 in~\cite{BouyerMM14}). The operator  is monotone and
 continuous. 
 Other (unary) examples from~\cite{AlmagorBK13ExtendedPreprint} include: 
  and
  (they
 are explained in~\cite{AlmagorBK13ExtendedPreprint} to express \emph{competence} and \emph{necessity}, respectively).
 The conjunction and disjunction connectives , interpreted 
 by  infimums and supremums in , can also be regarded as binary
 propositional quality operators. They are  monotone and
 continuous, too. 
\end{exam}



Recall that the set   is that of atomic propositions. 
\begin{defi}[]\label{def:LTLdDSyntax}
Given a set  of discounting functions and a set  of propositional quality operators, the \emph{formulas} of 
are defined by the  grammar:
 
 where ,  is a discounting function and
  is a propositional quality operator (of a suitable arity). 
 We adopt the usual notation conventions: 

and 
. The same goes for discounting operators:

and 
.
\end{defi}
As we have already discussed, 
the logic  extends the usual LTL with: 1) discounted
temporal operators like  (cf.~(\ref{eq:introDiscounting}));
and 2) propositional quality operators like  that operate, on
 truth values from  that arise from the discounted modalities, in
 the ways other than  and  do. The  precise
 definition below
closely follows~\cite{AlmagorBK13,AlmagorBK14}.




\begin{defi}[semantics of ~\cite{AlmagorBK13,AlmagorBK14}]\label{def:LTLdDSemantics}
Let  be a computation (see~\S{}\ref{sec:intro}), and
  be an  formula.
 The \emph{truth value}  of  in 
 is a real number in  defined
as follows. Recall that  is a
 suffix of .

\end{defi}
Compare the semantics of 
and that of . The former is a
straightforward quantitative analogue of the usual Boolean semantics;
the latter additionally includes ``discounting'' by
. Recall that a discounting function  is
deemed to be strictly decreasing; this allows us to express intuitions
like in~(\ref{eq:introDiscounting}).

\begin{prop}\label{lem:maxTruthValOfDiscountedUntil}
 The truth value 
 lies between  and . \qed
\end{prop}

We extend the semantics to Kripke structures (see~\S{}\ref{sec:intro}). 
\begin{defi}
 Let  be a Kripke structure and  be a path of . 
 The truth value  of  in the path  is defined by
 , where
  is the computation 
 induced by  (see~\S{}\ref{sec:intro}). 
The truth value  of  in  is defined by .
\end{defi}
\auxproof{
The choice of infimum (instead of ) in the definition of  is due to~\cite{AlmagorBK14} and is more natural, modeling
the worst case value, when we consider
the threshold model-checking problem (see
below).
}





\begin{rem} 
 Later in this paper we will restrict to propositional quality operators 
 that are monotone and
 continuous, i.e.\   with . 
 Such a logic can nevertheless express some non-monotonic 
 operators with the help of negation. For example, the function
  can be expressed as 
 a combination , using
 and 
 (note that  )---i.e.\ as the semantics of the formula
 . A nonexample is the function 
  that oscillates infinitely often in .
\end{rem}



The following ``threshold'' problems are studied
in~\cite{AlmagorBK14,AlmagorBK13ExtendedPreprint}. It is shown that the logic
---i.e.\ without propositional quality operators
other than ---has those problems decidable. Adding the
average operator  makes them undecidable~\cite{AlmagorBK14},
while adding 
(Example~\ref{exam:propositionalQualityOperator}) maintains decidability~\cite{AlmagorBK13ExtendedPreprint}.
Here the complexities are  in terms of a suitable notion
  of the size of  
 (see~\cite{AlmagorBK14}). 




\begin{thm}[\cite{AlmagorBK14}]\label{thm:thresholdModelCheckingDecidable}
 The \emph{threshold model-checking problem} for  is:
given a
 Kripke structure , an  formula  and a threshold ,  decide whether . It
 is decidable; when restricted to  and , the problem is in PSPACE in  and in the description of  , and in NLOGSPACE in the
 size of . 


 The \emph{threshold satisfiability problem} for  is:
given an  formula , a threshold 
and   , decide whether there exists a computation  such that . This is decidable; when restricted to  
and , the problem is in PSPACE in  and in the description of  . \qed
\end{thm}
\begin{thm}[\cite{AlmagorBK14}]\label{thm:averageUndecidable}
  For  where , both the
 threshold model-checking problem and the threshold satisfiability problem are undecidable.
 \qed
\end{thm}













\section{-Acceptance B\"uchi Automata}
\label{sec:zeroOneAutomata}

Our algorithm for near-optimal scheduling relies on a certain
notion of quantitative automaton---called \emph{-acceptance B\"uchi
automaton}, see Def.~\ref{def:zeroOneAcceptanceBuchi}---and an algorithm for its optimal value problem
(Lem.~\ref{lem:lassoOptimalityForQuantitativeAcceptAutom}).
The notion is not
extensively studied in the literature,   to the best of our knowledge.

In a -acceptance B\"uchi
automaton 
each state has a real value
,
instead of 
a Boolean value
 , of acceptance.
Note that branching is Boolean (i.e.\ nondeterministic) and not
-weighted. 
 In Appendix~\ref{appendix:fuzzyAndZeroOne}
we study a relationship to so-called \emph{fuzzy automata} (see
e.g.~\cite{Rahonis05}) and
show
that adding weights to branching does not increase expressivity when it
comes to (weighted) languages.



 \begin{defi}[{}-acceptance automaton]
  \label{def:zeroOneAcceptanceBuchi}
  A \emph{-acceptance B\"uchi automaton}---or simply a
  \emph{-acceptance automaton} henceforth---is , where  is a finite  alphabet,
  is a finite set of states,  is a set of initial
 states,  is a
 transition function and  is 
 a function that assigns an \emph{acceptance value} to each state.
  We define the (weighted) language  of  by
  
 where the sets  and  are defined as
  usual. Precisely:
\begin{itemize}
 \item For an infinite word , a \emph{run} over 
       of  is an infinite alternating sequence
        such that: 1)  is a
       state and  is a letter, for all ; 2)
       ; and 3)
        for all . The set of
       runs over  is denoted by  .
 \item Given a run , the set
        is defined by
       q\rho.
\end{itemize}
\end{defi}
 Note that, when we restrict to Boolean acceptance values (i.e.\
), 
the acceptance value in~(\ref{eq:acceptanceZeroOneAutom})
precisely coincides with the one in the usual notion of B\"{u}chi
automaton.
Note also that, in~(\ref{eq:acceptanceZeroOneAutom}), we take the
maximum of finitely many values (the state space  is finite).

\auxproof{
{}-acceptance B\"uchi automata are quantitative extension of B\"uchi
automata. The extension, however, does not incur too much additional 
complexity. For example its threshold acceptance problem can be solved
by a B\"uchi automaton.

\begin{lem}
  Let  be a {}-acceptance B\"uchi automaton,
 , and .
 \begin{enumerate}
  \item There exists an (ordinary) B\"uchi automaton  such that 
  .
  \item Let  , and
   be an (ordinary) B\"uchi
	automaton. We have
  .
 \end{enumerate}
\end{lem}
\begin{proof}
 For 1., let  and let
 . \qed
\end{proof}
}






The following observation, though not hard, is a key fact for
our search algorithm. 
It is a quantitative
 analogue
of emptiness check in usual (Boolean) automata.
\begin{lem}[the optimal value problem for {}-acceptance automata]\label{lem:lassoOptimalityForQuantitativeAcceptAutom}
  Let  be a {}-acceptance B\"uchi automaton.
There exists the maximum
 
 of .
Moreover, 
there is an algorithm that computes 
the value  
as well as a run  
that realizes the maximum.


\end{lem}
\auxproof{Note that
existence of 
 (as opposed to a supremum)
is nontrivial.
}
\begin{proof}
 The algorithm is much like the one for emptiness check of (ordinary)
B\"uchi automata, searching for a suitable lasso computation. More
concretely: consider those states  which are both reachable from some
initial state and reachable from  itself. Let  be one, among those
 states, with the
greatest acceptance value . It is easy to show that a lasso
computation with the state  as a ``knot'' gives the run
 that we seek for.
\end{proof}





 Our algorithm first translates a formula    into an
\emph{alternating} -acceptance automata. 
\begin{defi}[alternating {}-acceptance automaton]\label{def:alternative_buchi}
  An \emph{alternating {}-acceptance (B\"uchi) automaton} is a tuple , where  is a finite alphabet,
  is a finite set of states,  is a set of initial
 states,  is a transition function and  gives
 acceptance values.  Recall (\S{}\ref{sec:intro})
 that  is the set of positive
 propositional combinations of  and .



  We define the (weighted) language  of  by
  
  where \emph{runs}, \emph{paths} and the function  are
 formally defined much like with the usual alternating
 automata. Precisely:
 \begin{itemize}
  \item A run is much like with the usual alternating
 automata. Precisely, let  be an alternating
	-acceptance automaton and 
  be an infinite word.
	A \emph{run}  of   over 
  is a (possibly infinite-depth) tree subject to the following.
	\begin{itemize}
	 \item Each node  of the tree  is labeled from .
\auxproof{	       That is, either by a state 
	       or a number .
}
	 \item The root of  is labeled with an initial state
	       .
	 \item Any node  labeled with a number  is a leaf.
	 \item Consider an arbitrary node  that is labeled 
	with a state . Assume that  is of depth ; and 
	       let the labels of 's children be .
We require  
	       , where:  is the
	       -successor of  in ; and 
	       designates the obvious Boolean notion of satisfaction
	       (where we think of elements of  as atomic variables).
	\end{itemize}
	The set  is that of all runs of  over the word
	.
  \item A \emph{path}  of a run  is simply a (finite or
	infinite) path in the tree , from the root of . 
	A path  is finite only
	when its last state is a leaf of .
	The set of paths of  is denoted by .
  \item The function 
 in~(\ref{eq:langOfAFBA}) is defined as follows. 
	If  is an
	infinite path,  each node  in  is labeled with
	a state  of . We define
 
	Assume now that  is finite, say
	. Then the last node 
	is labeled either by  or .
	In the former case we define
	 
	(i.e.\  returns the label of ).
 In the latter
	case,
we have that  is
	propositionally equivalent to  (``truth'') by the
	definition of run. We define
	.
\end{itemize}
\end{defi}
In the above we used  and  (not 
or ) since  is a finite set.


\begin{prop}\label{prop:ABAtoNBA}
  Let  be an alternating
 {}-acceptance  automaton. There exists a {}-acceptance
 automaton  such that . 
\qed
\end{prop}
The  construction of  is a quantitative adaptation of the
 one in~\cite{MiyanoH84} that turns an alternating -automaton into
a  nondeterministic one. In our adaptation we use what we call
 \emph{exposition flags}, an idea that is potentially useful in other
 settings with B\"uchi-type acceptance conditions, too. 
See Appendix~\ref{pf:lemABAtoNBA} for details of the proof and the
 construction therein.



Later we will also use the fact that
-acceptance automata are closed under monotone propositional
quality operators (Def.~\ref{def:propositionalQualityOperator}).  


\begin{prop}\label{prop:ClosedUnderIncOperator}
  Let  be monotone, and
 be
-acceptance automata
 over a common alphabet . There is a -acceptance
 automaton  such that
  for each . \qed
\end{prop}


\begin{rem}
 Prop.~\ref{prop:ABAtoNBA} and~\ref{prop:ClosedUnderIncOperator} are
 essentially two separate constructions that deal with: the connectives
  and ; and the other propositional quality operators, respectively. 
 One can alternatively think of  and  as special cases of the latter 
 (Example~\ref{exam:propositionalQualityOperator}) and  use
 Prop.~\ref{prop:ClosedUnderIncOperator} altogether. 
This however results in a worse
complexity: the powerset-like construction in Prop.~\ref{prop:ABAtoNBA}
 exploits the commutativity, idempotency and associativity of  to 
 suppress the number of states, while such  is not done in the
 product-like
 construction in Prop.~\ref{prop:ClosedUnderIncOperator}.
\end{rem}

A generalization of -acceptance automaton
  is naturally obtained by making transitions also
-weighted. The result is called \emph{fuzzy automaton}
  and studied e.g.\ in~\cite{Rahonis05}.
  In Appendix~\ref{appendix:fuzzyAndZeroOne} we show that this generalization does not add expressivity. In
  fact we prove a more general result there, parametrizing 
  into a suitable semiring 
  .




\section{Near-Optimal Scheduling for  }
\label{sec:nearOptimalSchedulerSynth}
In~\cite{AlmagorBK14,AlmagorBK13ExtendedPreprint} the threshold
model-checking problem for the logic 
is studied. 
In this paper, instead, we are interested in the following problem:  what
path of a given Kripke structure  is the best for a given
 formula . 


\begin{wrapfigure}[2]{r}{0pt}
\end{wrapfigure}
 In general, however, there does not exist an optimal path 
 of , i.e.\ one that achieves . 

\begin{exam}[optimality not achievable]\label{exam:optimalityNotAchievable}
Take a formula 
 and the Kripke structure  shown in the above.  
This example illustrates that the existence of an optimal path is 
not guaranteed in general: indeed, whereas  in this example, there is no path   that achieves .

 More specifically: we first
 note that, in each 
 path  of the Kripke structure,   is true
 at most once. The later the state  occurs in a path , the bigger the
 truth value  is;  moreover the value  tends to  (since  tends to ). 
 However there is no path  that achieves exactly : if  is postponed indefinitely, no state in
  satisfies , in which case  is 
 everywhere false and hence .
\end{exam}



We thus strive for \emph{near}-optimality, allowing
a prescribed margin .





\begin{defi}\label{def:nearOptimalPathSynthesis}
 The \emph{near-optimal scheduling} problem for  is:
given a Kripke structure , an  formula  and a positive real number , to
find a path  such that . 
\end{defi}
Ultimately we will show that the problem in the above is decidable (Thm.~\ref{thm:main}), when all
the propositional quality operators are monotone and continuous
(). 


We first note that, in the special case for 
 (i.e.\ no propositional quality operators), there is a straightforward binary search algorithm
that 
relies on the (threshold) model-checking algorithm
in~\cite{AlmagorBK14} (Thm.~\ref{thm:thresholdModelCheckingDecidable}). Specifically, the binary search algorithm
repeatedly conducts threshold model-checking for:
 the threshold  in the first round;   or
  in the second round,
       depending on the outcome of the first round;  then
       for  or , depending on the outcome of the second round; and so on.  
Given a margin
       ,  this way, we need   rounds. 
This binary search algorithm is rather effective (see~\S{}\ref{sec:experiments}).


However the binary search algorithm does not work in presence of the
average operator , simply because the threshold model-checking
problem is undecidable (Thm.~\ref{thm:averageUndecidable}). Our main
contribution is a novel algorithm for near-optimal scheduling
that works even in this case (and more generally for the logic
). 
Our algorithm  first translates a formula  and a margin
 to an
alternating
-acceptance automaton , which is further
turned into a -acceptance automaton 
(Prop.~\ref{prop:ABAtoNBA}). The resulting automaton---after  taking the
product  
with ---is amenable to optimal value search
(Lem.~\ref{lem:lassoOptimalityForQuantitativeAcceptAutom}), yielding
a solution to the original problem.









In the rest of the section we describe our algorithm.
We shall however  first
  restrict to the logic 
 for the sake of presentation (although this basic fragment allows binary
search). After describing
the basic algorithm for 
in~\S{}\ref{subsec:algorithmWithoutPropositional},
in~\S{}\ref{subsec:algorithmWithPropositional} we explain how it can be
modified to accommodate propositional quality operators.





\subsection{Our Algorithm, When Restricted to
  }\label{subsec:algorithmWithoutPropositional}
Our translation of   and
 to an automaton 
 is  an extension of the standard
translation from LTL formulas to alternating B\"{u}chi automata (e.g.\
in~\cite{Vardi96anautomata-theoretic}), with: 
\begin{itemize}
 \item  incorporation of
quantities---accumulation of discount factors, more specifically---by
	means of what we call \emph{discount sequences}; and
 \item cutting off those events which are  far in the future---the idea of \emph{event horizon} from~\cite{AlmagorBK14}.
\end{itemize}
The extension is not complicated on the conceptual level. Its
details need care, however, especially in handling negations and alternation of
greatest and least fixed points. 

As preparation, we recall some definitions and notations from~\cite{AlmagorBK14}. 
\begin{defi}[, ~\cite{AlmagorBK14}]
 Let  be a discounting function. We define a discounting
 function  by
  
for each .


For an  formula , the
 \emph{extended closure}  of
 ~\cite{AlmagorBK14} is defined by 

where  denotes the set of subformulas of .
\end{defi}

\subsubsection{Discounting Sequences}\label{subsubsec:discountSeq}
 We go on to technical details.
 In the alternating -acceptance automaton
  that we shall construct, a state is a pair 
  of a formula  and a \emph{discount sequence} 
 .
\begin{defi}[discount sequence]\label{def:discountSequence}
 A \emph{discount sequence} is a sequence  of real numbers with a nonzero length ( for
 each ). 
\end{defi}
The notion of discount sequence is a quantitative extension of that of
\emph{priority} in parity automata. Specifically, the length  of a
discount sequence  corresponds to a
priority---i.e.\ the alternation depth of greatest and least fixed
points.
Each real number  in the sequence, in turn, stands for the accumulated 
discount factor in each level of fixed-point alternation. 
For example,  the formula 
   will induce a discount sequence

 of
 length 3---where  and  are the numbers of steps for
 which 
the three discounting temporal operators
, 
 and 

 ``have waited,'' respectively.

We use three operators  that act on discount
sequences; the 
intuitions are as follows. The first two are for accumulating discount
factors: we use 
in case there is no alternation of greatest and least fixed points; and
we use
 in case there is. Examples are:

Note that in the former the length is preserved, while in the latter the
sequence gets longer by one.
\begin{defi}[,  ]\label{def:operationsOnDiscountSeqOdotAndCdot}
 The  operator  
takes a discount sequence 
 and a discount factor  as arguments, and multiplies
 the last element of    by . That is,

The operator  is simply the concatenation operator: given 

 and  , the sequence  is  of length .
\end{defi}

We use the operator  in  to let a
discount sequence  act on a truth value . 
\begin{defi}[]\label{def:operationsOnDiscountSeq}
 The operator  takes 
 and  as
 arguments. The value  is defined inductively by:
 
\end{defi}


The intuition behind the action  is most visible
in~(\ref{eq:inductiveDefOfAction}), where  and  denote
multiplication of real numbers. Given a discount sequence
:  1) we apply the final discount factor  to 
the truth value , obtaining ; 2) the alternation between 
greatest and least fixed points is taken into account, by taking
the negation  (cf.\ Def.~\ref{def:LTLdDSemantics}); and
 3)
we apply the remaining sequence  inductively and obtain . An example is
.

 The following  relationship between 
and  is easily seen to hold:


The three operators  defined in the above 
will be used shortly, in the construction of the automaton
. Their roles are briefly discussed after Def.~\ref{def:ABAforLTL}.

\subsubsection{Construction of }
 We  describe the construction of ,
for a formula  of  and a margin
.  We subsequently discuss  ideas
behind it, comparing the definition with other known constructions.


We first define 
 that is infinite-state, and obtain 
 as the reachable part. The latter will be shown to
be finite-state (Lem.~\ref{lem:AphiEpsIsFiniteState}).

\begin{defi}[the automata ]\label{def:ABAforLTL}
  Let  be an   formula and . We define an alternating {}-acceptance automaton
  as
 follows. 
 Its state space  is ; hence a state is a pair  of a formula and a discount sequence.
The transition function  is defined as 
in Table~\ref{table:transitionFuncOfAp}, where we let
 
 and  .
\begin{table}[tbp]\centering
\small
  
\begin{minipage}{\textwidth}\small
 For  we make cases. Let 
	 . If
:
	  
	  otherwise, i.e.\ if 	 :
   
\end{minipage}
\caption{Transition function  of }
 \label{table:transitionFuncOfAp}
\end{table}


  The set  of the initial states of  is . The acceptance function  is
  

 The alternating -acceptance automaton 
 is defined to be the restriction of   to the states that
 are
 reachable from the initial state . 
\end{defi}
\auxproof{To slightly optimize the automaton one can take
 .
}
Examples of  are
in Fig.~\ref{fig:exampleTranslation}--\ref{fig:exampleTranslation2},
where

and
.
There a discount sequence
 is denoted by  for readability.

\begin{figure}[tbp]\centering
\iffalse
\psscalebox{1 1} {
\psset{unit=20pt,arrowsize=0.2 3.0,arrowlength=1.4,arrowinset=0.4}
\begin{pspicture}(0,-6.0379686)(16.4,6.0379686)
\psframe[linecolor=black, linewidth=0.04, dimen=outer](9.2,6.0379686)(3.2,4.837969)
\psframe[linecolor=black, linewidth=0.04, dimen=outer](5.2,2.8379688)(0.0,1.6379688)
\psframe[linecolor=black, linewidth=0.04, dimen=outer](13.6,2.8379688)(8.4,1.6379688)
\psframe[linecolor=black, linewidth=0.04, dimen=outer](6.0,0.43796876)(2.4,-0.76203126)
\psframe[linecolor=black, linewidth=0.04, dimen=outer](16.4,-0.36203125)(10.8,-1.5620313)
\psframe[linecolor=black, linewidth=0.04,
 dimen=outer](10.4,-0.36203125)(6.6,-1.5620313)
\psframe[linecolor=black, linewidth=0.04, dimen=outer](12.4,-3.5620313)(8.6,-4.762031)
\psline[linecolor=black, linewidth=0.04]{->}(6.0,4.837969)(6.0,4.0379686)(4.4,2.8379688)
\psline[linecolor=black, linewidth=0.04]{->}(6.0,4.0379686)(8.8,2.8379688)
\psline[linecolor=black, linewidth=0.04]{->}(1.2,1.6379688)(0.4,-1.5620313)
\psline[linecolor=black, linewidth=0.04]{->}(4.0,1.6379688)(4.0,0.43796876)
\psline[linecolor=black, linewidth=0.04]{->}(4.0,-0.76203126)(4.0,-1.5620313)
\psline[linecolor=black, linewidth=0.04]{->}(8.8,4.837969)(12.8,2.8379688)
\psline[linecolor=black, linewidth=0.04]{->}(10.0,1.6379688)(10.0,0.83796877)(8.8,-0.36203125)
\psline[linecolor=black, linewidth=0.04]{->}(10.0,0.83796877)(11.6,-0.36203125)
\psline[linecolor=black, linewidth=0.04]{->}(12.8,1.6379688)(14.8,-0.36203125)
\psline[linecolor=black, linewidth=0.04]{->}(9.2,-1.5620313)(10.8,-3.5620313)
\psline[linecolor=black, linewidth=0.04]{->}(8.0,-1.5620313)(6.4,-3.5620313)
\psline[linecolor=black, linewidth=0.04]{->}(14.8,-1.5620313)(14.8,-2.3620312)
\psline[linecolor=black, linewidth=0.04]{->}(10.8,-4.762031)(10.8,-5.5620313)
\psline[linecolor=black, linewidth=0.04]{->}(2,5.6379685)(3.2,5.6379685)
\rput[bl](10.8,4.0379686){}
\rput[bl](14.0,0.83796877){}
\rput[bc](6.6,-2.4620313){}
\rput[bc](0.0,0.43796876){}
\rput[bl](10.4,-2.7620313){}
\rput[bc](5.2,4.0379686){}
\rput[bc](9.2,0.83796877){}
\rput[bl](4.4,0.83796877){}
\rput[bc](6.2,5.4379685){}
\rput[bc](2.6,2.2379686){}
\rput[bc](11.0,2.2379687){ }
\rput[bc](4.2,-0.21803125){}
\rput[bc](8.6,-0.96203126){ }
\rput[bc](13.6,-0.96203126){ }
\rput[bc](10.6,-4.1620315){ }
\rput[bc](0.0,-1.9620312){}
\rput[bc](4.0,-1.9620312){}
\rput[bc](6.4,-3.9620314){}
\rput[bc](10.4,-5.9620314){}
\rput[bc](14.8,-2.6){}
\rput[bc](6,3.8){}
\rput[bc](10,0.6){}
\end{pspicture}
} 
\fi
\begin{minipage}[]{.5\textwidth}
 \includegraphics[width=\textwidth]{discountingLTLpics1.pdf}
 \caption{The automaton 
  for\\  and 
 }
 \label{fig:exampleTranslation}
\end{minipage}
\begin{minipage}[]{.48\textwidth}
\includegraphics[width=\textwidth,clip,trim=0cm 4.5cm 3cm 0cm]{discountingLTLpics2.pdf}
\caption{The automaton 
 for\\  and . The double-lined nodes  have
 the acceptance value .
}
\label{fig:exampleTranslation2}
\end{minipage}
\end{figure}

\iffalse
\begin{figure}[tbp]
\centering
 \psscalebox{1 1} {
\psset{unit=20pt,arrowsize=0.2 3.0,arrowlength=1.4,arrowinset=0.4}
\begin{pspicture}(0,-6.0379686)(16.4,6.0379686)
\psframe[linecolor=black, linewidth=0.04, dimen=outer](5.2,6.0379686)(1.2,4.837969)
\psframe[linecolor=black, linewidth=0.04, dimen=outer, doubleline=true](5.2,2.8379688)(2.0,1.6379688)
\psframe[linecolor=black, linewidth=0.04, dimen=outer](10.4,2.8379686)(6.4,1.637969)
\psframe[linecolor=black, linewidth=0.04, dimen=outer, doubleline=true](10.4,-0.36)(7.2,-1.6)
\psframe[linecolor=black, linewidth=0.04, dimen=outer](15.6,-0.34)(11.6,-1.56)
\psline[linecolor=black, linewidth=0.04]{->}(2.5,4.837969)(2.5,4.0379686)(0.4,2.6379688)
\psline[linecolor=black, linewidth=0.04]{->}(2.5,4.0379686)(4.0,2.8379688)
\psline[linecolor=black, linewidth=0.04]{->}(4.0,4.837969)(7.0,2.8379688)
\psline[linecolor=black, linewidth=0.04]{->}(3.0,1.637969)(3.0,0.8379686)(0.9,-0.56)
\pscurve[linecolor=black, linewidth=0.04,showpoints=false]{->}(3.0,0.8379686)(4.0,-0.16)(5.0,0.8379686)(4.8,1.6379688)
\psline[linecolor=black, linewidth=0.04]{->}(7.7,1.637969)(7.7,0.8379686)(5.6,-0.56)
\psline[linecolor=black, linewidth=0.04]{->}(7.7,0.8379686)(9.2,-0.36)
\psline[linecolor=black, linewidth=0.04]{->}(9.2,1.637969)(12.2,-0.36)
\psline[linecolor=black, linewidth=0.04]{->}(8.2,-1.56)(8.2,-2.36)(6.1,-3.76)
\pscurve[linecolor=black, linewidth=0.04,showpoints=false]{->}(8.2,-2.36)(9.2,-3.36)(10.2,-2.36)(10.0,-1.6)
\psline[linecolor=black, linewidth=0.04]{->}(13.0,-1.56)(13.0,-2.36)
\rput[bc](1.76,4.2379686){}
\rput[bc](7.0,1.03796877){}
\rput[bc](7.48,-2.2020313){}
\rput[bc](2.26,1.03796876){}
\rput[bc](6.2,4.0379686){}
\rput[bc](11.4,0.83796877){}
\rput[bc](3.2,5.4379685){}
\rput[bc](3.6,2.2379686){}
\rput[bc](8.5,2.2379687){ }
\rput[bc](8.8,-0.96){ }
\rput[bc](13.7,-0.96203126){ }
\rput[bc](0.4,2.4){}
\rput[bc](0.9,-0.8){}
\rput[bc](5.6,-0.8){}
\rput[bc](6.1,-4.0){}
\rput[bc](13.0,-2.6){}
\rput[bc](2.5,3.6379686){}
\rput[bc](3.0,0.4379686){}
\rput[bc](7.7,0.4379686){}
\rput[bc](8.2,-2.76){}
\end{pspicture}
}
\caption{The automaton 
 for  and . The double-lined nodes  have
 the acceptance value .
}
\label{fig:exampleTranslation2}
\end{figure}
\fi


Some remarks on Def.~\ref{def:ABAforLTL} are in order.






\noindent
\textbf{In Absence of Discounting (Sanity Check)}\quad 
If the formula  contains no discounting operator ,
then the construction essentially coincides the usual one
in~\cite{Vardi96anautomata-theoretic} that translates a (usual) LTL
formula to an alternating B\"uchi automaton. To see it, 
recall that the length  of a discount sequence plays the
role of a priority in parity automata (\S{}\ref{subsubsec:discountSeq}).
Therefore in the first case of~(\ref{eq:acceptanceFunc}),   being
even means that we are in fact dealing with a greatest fixed point. This
makes the state accepting (in the B\"{u}chi sense), much like in~\cite{Vardi96anautomata-theoretic}.


\noindent 
\textbf{ is Quantitative} \quad
The acceptance values of the states of 
       are Boolean (see~(\ref{eq:acceptanceFunc})). Nevertheless the automaton
       is quantitative, in that non-Boolean values from 
       appear
       as atomic propositions in the range 
       of the transition  (they occur at the leaves in Fig.~\ref{fig:exampleTranslation}--\ref{fig:exampleTranslation2}). Once we transform
        to a
       non-alternating
       automaton (Prop.~\ref{prop:ABAtoNBA}), these non-Boolean
       propositional values
       give rise to non-Boolean acceptance values.

\noindent 
\textbf{Event Horizon} \quad 
A fundamental idea from~\cite{AlmagorBK14} is the following. A discounting operator, in presence of
a threshold (in~\cite{AlmagorBK14}) or a nonzero margin (here), allows an exact
representation by a (finitary) formula without a fixed point
operator. The latter means, for example:

and so on. Note that in~(\ref{eq:finReprOfDiscountOpr1}), whatever happens after two time units
has contributions less than  and
therefore never enough to make up the threshold. The example~(\ref{eq:finReprOfDiscountOpr2})
is similar, with events in the future having only negligible negative
contributions. In other words:  fixed point operators with discounting have
an \emph{event horizon}---in the above examples~(\ref{eq:finReprOfDiscountOpr1}--\ref{eq:finReprOfDiscountOpr2}) it lies between   and
---nothing beyond which  matters.

This idea of event horizon is used in the distinction
between~(\ref{eq:defDeltaBeyondEventHorizon})
and~(\ref{eq:defDeltaWithinEventHorizon}). The value  is, as we shall see, the greatest contribution
to a truth value that the events henceforth potentially have.  In case it is smaller
than the margin  we can safely ignore the \emph{positive}
contribution henceforth and take
 the smallest possible truth value
---much like the disjunct
 is truncated
in~(\ref{eq:finReprOfDiscountOpr1}). This is what is done in the first case
in~(\ref{eq:defDeltaBeyondEventHorizon}). 
The second case 
in~(\ref{eq:defDeltaBeyondEventHorizon}) is about a greatest fixed point
and
we truncate the \emph{negative} contributions of the events beyond the event
horizon---this is much like the obligation
 is lifted
in~(\ref{eq:finReprOfDiscountOpr2}). In this case we use the greatest truth
value possible, namely . This is what is done
in~(\ref{eq:defDeltaBeyondEventHorizon}).









\noindent 
\textbf{Use of Discount Sequences} \quad
Discount sequences  are used for two purposes. Firstly, as
we already described,
its length
 indicates the alternation between positive and negative views on a
formula---observe that a discount sequence gets longer in~(\ref{eq:201507281451}).  Consequently many clauses in the definition of 
distinguish
cases according to the parity of . Secondly it records all
the discount factors that have been
encountered. See~(\ref{eq:defDeltaWithinEventHorizon}), where the last
element of  is multiplied by the newly encountered factor
 and updated to . 
Such accumulation  of 
discount factors acts on a truth value via the   operator, like
in~(\ref{eq:defDeltaBeyondEventHorizon}) and in the definition of . 





\begin{lem}\label{lem:AphiEpsIsFiniteState}
 The automaton  has only finitely many states.
 \qed
\end{lem}



The following ``correctness lemma'' claims that  
conducts the expected task. 
\begin{lem}\label{lem:correctnessOfA}
  Let  be an  formula and  be a
 positive real number. 
For each computation , we
 have
\qed
\end{lem}


\subsubsection{The Algorithm}\label{subsubsec:theAlgorithmWithoutPropositional}
 After the construction of
 , 
the algorithm proceeds in the following manner.
We first translate  to a (non-alternating)
{}-acceptance automaton (relying on Prop.~\ref{prop:ABAtoNBA}).

\begin{cor}\label{cor:NBAforLTL}
  Let  be an   formula and  be a
 positive real number. There exists a (non-alternating) {}-acceptance automaton  such that 
  
for each computation .
\qed
\end{cor}


Towards the solution of the near-optimal 
scheduling problem (Def.~\ref{def:nearOptimalPathSynthesis}), we
construct the \emph{product} of

in
Cor.~\ref{cor:NBAforLTL}
and the given Kripke structure . Since transitions of
{}-acceptance automata are nondeterministic, this product can be
defined just as usual.
\begin{defi}\label{def:productAutomata}
  Let  be a
 {}-acceptance automaton and  be a Kripke
 structure.  Their \emph{product}  
is a 
 {}-acceptance automaton
 ---over a singleton alphabet
 ---defined by:
 ; ; ; and .
\end{defi}
\begin{lem}\label{lem:fromOptimalInATimesKToOptimalInA}
 Let 

be an optimal run of the automaton  (that necessarily
 exists by Lem.~\ref{lem:lassoOptimalityForQuantitativeAcceptAutom}).
The path  realizes the optimal
       value of , that is,
.
\qed
\end{lem}




\begin{thm}[optimal scheduling for ]\label{thm:mainWithoutPropositional}
 Assume the setting of  Def.~\ref{def:nearOptimalPathSynthesis}, 
 and that  (i.e.\ the formula  contains no
 propositional quality operators).
Let 

 be an optimal run (computed by
 Lem.~\ref{lem:lassoOptimalityForQuantitativeAcceptAutom}) for the
 -acceptance automaton 
 constructed as in Def.~\ref{def:ABAforLTL}, Cor.~\ref{cor:NBAforLTL}
 and Def.~\ref{def:productAutomata}. Then the path
  is a solution to the near-optimal scheduling problem (Def.~\ref{def:nearOptimalPathSynthesis}). 

Moreover,
 the solution   can be chosen to be ultimately
 periodic.
\qed
\end{thm}







\auxproof{ We can search for a near-worst scheduler, too, by seeking for an optimal
 path for .
}














\subsection{Our General Algorithm for
  }\label{subsec:algorithmWithPropositional}
Our general algorithm works in the setting of ---i.e.\ in
the presence of monotone and continuous propositional quality operators like ---where 
threshold model checking is potentially undecidable~\cite{AlmagorBK14}
and therefore the binary-search algorithm (described after
Def.~\ref{def:nearOptimalPathSynthesis}) may not work. 

The general algorithm is a (rather straightforward)
adaptation of the one we described for

(\S{}\ref{subsec:algorithmWithoutPropositional}). Here
 we construct the 
  alternating -acceptance automaton 
  \emph{inductively} on the construction on the formula :
       \begin{itemize}
	\item When the outermost connective is other than a
	      propositional quality operator, the construction is 
	      much like in Def.~\ref{def:ABAforLTL}.
	\item When the outermost connective is  a
	      propositional quality operator, we rely on
	      Prop.~\ref{prop:ClosedUnderIncOperator}. 
       \end{itemize}
 The rest of the algorithm (i.e.\ the part described
 in~\S{}\ref{subsubsec:theAlgorithmWithoutPropositional}) remains
 unchanged. 
 An extensive description of the details of the construction
 is deferred to Appendix~\ref{appendix:generalAlgorithmDetails}.

\begin{thm}[main theorem, optimal scheduling for ]\label{thm:main}
 In the setting of Def.~\ref{def:nearOptimalPathSynthesis}, 
 assume that  (i.e.\ all the propositional
 quality operators in  are monotone and continuous).
 Then the near-optimal scheduling problem is decidable.
\qed
\end{thm}


\subsection{Complexity}
\label{subsec:complexity}
The two parameters  and  in ---i.e.\ discounting functions
(Def.~\ref{def:discountFunction}) and propositional quality operators
(Def.~\ref{def:propositionalQualityOperator})---are both relevant to
 the  complexity of our algorithm. Formulating a
complexity result is hard when these parameters are left open.  We therefore
restrict to:
\begin{itemize}
 \item exponential discounting functions
(Def.~\ref{def:discountFunction}), i.e.\ , as is
       done
in~\cite{AlmagorBK14}; and
 \item the average operator , i.e.\ .
\end{itemize} 
We use the definition
  
of the size of a formula , which is from~\cite{AlmagorBK14}: it
reflects the description length of  that appears in
 discounting
functions, as well as the length of 
as an expression.



\begin{prop}[size of  ]\label{prop:sizeOfAltAutom}
  Let  be an  formula and 
 be a positive rational number.  The size of the state space of
 the alternating -acceptance automaton
  is singly exponential in  and in the length of the description of . \qed
\end{prop}
\begin{thm}[complexity for ] \label{thm:mainComplexity}
The near-optimal scheduling problem for  is: in
 EXPSPACE in  and in the description length of
 ; and in NLOGSPACE in the size of . 
\qed
\end{thm}

In case of absence of propositional quality operators
(i.e.\ ), we can further 
optimize the complexity by using a heuristic and  avoiding the exponential blowup  from 
 to  . This yields 
the following complexity result, which is also achievable by the
binary-search
algorithm.

\begin{thm}[complexity for ] \label{thm:mainComplexityWithoutPropositional}
The near-optimal scheduling problem for  is: in
 PSPACE in  and in the description length of
 ; and in NLOGSPACE in the size of . 
\qed
\end{thm}




















\section{Experiments}\label{sec:experiments}
We implemented our algorithm
in~\S{}\ref{sec:nearOptimalSchedulerSynth} that solves the near-optimal
scheduling for . The implementation is
in OCaml.
The following  experiments were on
a MacBook Pro laptop
 with a Core i5 processor (2.7 GHz) and 16 GB RAM. 
\begin{table}[tb]
\scriptsize
\begingroup
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{c|c|c|c|c|c|c}& \multicolumn{2}{c|}{} & \multicolumn{2}{c|}{} & \multicolumn{2}{c}{} \\ \cline{2-7}
formula  \textbackslash\; \#(states) & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c}{} 
 \\ \hhline{=|=|=|=|=|=|=}

 & 5 & 10 & 7 & 14 & 8 & 16 \\ \hline

 & 231 & 462 & 391 & 782 & 460 & 920 \\ \hline
 & 15 & 36 & 28 & 85 & 36 & 121
\\ \hline\hline

 & 33 & 128 & 61 & 1859 & 78 & 7421 \\ \hline

 & 29 & 272 & 55 & 6659 & 71 & 32703 \\ \hline

 & 46 & 477 & 97 & 29655 & 141 & timeout (2 min.) \\ \hline\hline
 & 14 & 19 & 20 & 27 & 23 & 31
\end{tabular}
\endgroup
\caption{Size of the alternating -acceptance automaton , and -acceptance automaton }
\label{table:numberOfStates}


\begingroup
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{c|c|c|c|c}margin  & \#(states of ) & max.\ outgoing degree of  & 
 time (sec)  &  space (MB) \\ \hhline{=====}
  & 100 & 3 & 0.085508 & 5.861 \\ \cline{3-5}
  &  & 10 & 0.114427 & 9.368 \\ \cline{2-5}
  & 200 & 3 & 0.186989 & 10.586 \\ \cline{3-5}
  &  & 10 & 0.249392 & 18.216 \\ \cline{1-5}
  & 100 & 3 & 5.928842 & 199.782 \\ \cline{3-5}
  & & 10 & 8.108335 & 405.884 \\ \cline{2-5}
 & 200 & 3 & 10.750703 & 405.313 \\ \cline{3-5}
 &  & 10 & 18.250345 & 851.255 
\end{tabular}
\endgroup
\caption{Time and space consumption of our algorithm for near-optimal scheduling, for the formula  and a randomly generated
 Kripke structure . For each choice of the number of states ( or ) and of
 the maximum outgoing degree ( or ), we randomly generated 
 instances of  and the above shows the average}
\label{table:timeSpaceConsumption}
 
\begingroup
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{c|c|c|c|c}& \multicolumn{2}{c|}{} & \multicolumn{2}{c}{} \\ \cline{2-5}
 &  time (sec)  &  space (MB) &  time (sec)  &  space (MB) 
 \\ \hhline{=====}
our algorithm (\S{}\ref{subsec:algorithmWithoutPropositional}) & 18.918600 & 897.111 & 0.019800 & 4.629 \\ \hline
binary search & 0.047200 & 5.140390 & 0.069500 & 5.567
\end{tabular}
\endgroup
\caption{(Comparison with binary search, in absence of ) Time and space consumption for near-optimal scheduling, for the margin  and a randomly
 generated Kripke structure  ( states, max.\ outgoing degree , average over
  instances)}
\label{table:comparisonWithBinarySearch}
\end{table}
In Table~\ref{table:numberOfStates}, for each choice of  and
,  we show the size of the alternating automaton
,
and the non-alternating  that results
from . 
The first three rows have no , in which case the implementation
scales well for bigger bases (i.e.\ discount functions that decrease more
slowly). We observe that presence of  incurs substantial
computational costs: the small increase of bases from  (the
fourth row) to
  (the sixth row) makes  much
 bigger, resulting in  one timeout. This is as expected, however: 
 makes other problems  harder too, such as model checking (undecidable).

In Table~\ref{table:timeSpaceConsumption} we fix a formula  and measure time and space
 consumption, for various choices of a margin  and a Kripke
 structure . 
 Kripke structures  were randomly generated: 
we first set the number of states (100 or 200) and the maximum outgoing
  degree of  (3 or 10); for each state we fixed its outgoing degree,
  from the uniform distribution from  to the maximum (that we had
  already fixed); and then, for each outgoing edge, its target state is chosen
  from the uniform distribution over the set of states.
We observe that time and space consumption grows significantly as the
 problem becomes more difficult. However, for problem instances of a
 considerable size we still see manageable costs: a
 margin  (2\%) is fairly small, and 
 a Kripke structure  with  states is likely to be capable of
 modeling many communication protocols.

In Table~\ref{table:comparisonWithBinarySearch}, for reference, we
compare our algorithm in~\S{}\ref{subsec:algorithmWithoutPropositional}
with the binary-search algorithm that exploits the model-checking
algorithm in~\cite{AlmagorBK14} (we also implemented the latter). We
emphasize again that the latter does not work in presence of
. Our experience shows that the binary-search algorithm can in
some
cases be faster by a magnitude (e.g.\ for the first formula here), but not
always (for the second formula our algorithm is a few times faster). 

 Those experimental results indicate that, although presence of the
 average operator  incurs significant computational cost (as
 expected), 
 automata-based optimal scheduling for
  is potentially a
 viable approach. It is not that
 our algorithm scales up to huge problem instances, but systems of
 hundreds of states can be handled without difficulties.
Identification of concrete real-world challenges,
 and enhancement of the tool's efficiency to match up to them, is an important
 direction of future work.



















\section{Conclusions and Future Work}\label{sec:conclFutureWork}
For the quantitative logic  with future
discounting~\cite{AlmagorBK14}, we formulated a natural problem of
synthesizing near-optimal schedulers,
 and presented an algorithm. The latter relies on: the existing 
idea of \emph{event horizon}  exploited in~\cite{AlmagorBK14}  for the
threshold model checking problem, as well as a supposedly widely-applicable 
technique of translation to -acceptance automata and a
lasso-style optimal value algorithm for them.

Here are several directions of future work.

\noindent
\textbf{Controller Synthesis for Open Systems}
We note that the current results are focused on \emph{closed} systems.
For \emph{open} or \emph{reactive} systems (like a server that responds
to requests that come from the environment) we would wish to synthesize a \emph{controller}---formally  a
\emph{strategy} or a \emph{transducer}---that achieves a near-optimal
performance. 

An envisaged workflow,
following the one in~\cite{Vardi96anautomata-theoretic}, is as follows. 
We will use the same automaton 
(Def.~\ref{def:ABAforLTL}). It is then: 1) determinized,
2) transformed into a tree automaton that accepts the desired strategies,
and 3) the optimal value of the tree automaton is checked, much like 
in
Lem.~\ref{lem:lassoOptimalityForQuantitativeAcceptAutom}. While the
step 2) will be straightforward, the steps 1) and 3)
(namely: determinization of -acceptance automata, and the optimal
value
problem for ``-acceptance Rabin automata'') are yet to be
investigated.
Another possible workflow is by an adaptation of the Safraless algorithm~\cite{KupfermanPV06}.

\noindent
\textbf{Probabilistic Systems and } 
Here and in~\cite{AlmagorBK14} the system model is a Kripke structure
that is nondeterministic. Adding probabilistic branching will gives us 
a set of new problems to be solved: for Markov chains
the threshold
model-checking problem can be formulated; for Markov decision processes, 
we have both the threshold
model-checking problem and the near-optimal scheduling problem.
Furthermore, another axis of variation is given by
whether we consider the expected value or the worst-case value. In the
latter case we would wish to exclude truth values that arise
with probability .
 All these variations have important
applications in various areas.













\paragraph*{Acknowledgments}
Thanks are due to
Shaull Almagor,
  Shuichi Hirahara, and
the anonymous referees,
 for useful discussions and comments.
The authors are supported by
   Grants-in-Aid No.\
24680001, 15KT0012 and 15K11984, JSPS.


\bibliographystyle{plain}  \bibliography{myref}






\newpage
\appendix






\section{Our General Algorithm for , Further Details}
\label{appendix:generalAlgorithmDetails}
In this section, we extend~\S{}\ref{subsec:algorithmWithPropositional}
and describe details of the construction of 
for a formula  of . 
We inductively construct an alternating -acceptance automaton 
---that is also parametrized by 
a discount sequence . Then the automaton 
  is defined by 
 (for the sequence
 of length one).
\begin{lem}\label{lem:correctnessWithPropositional}
  Let  be an  formula,  be a
 positive real number, and  be a discount sequence (Def.~\ref{def:discountSequence}). There exists an
alternating
-acceptance automaton  such that,
for each computation , 
  
\end{lem}

\begin{proof}
  The proof is inductive on the construction of .\footnote{To
 be precise, we have two nested induction: the outer one is with respect
 to the number of propositional quality operators occurring in
 ; and the inner one is with respect to the size of a formula .} In this proof
 we assume without loss of generality that an alternating
 -acceptance automaton has exactly one initial state, and
 consequently, the initial state of 
 shall be denoted by . For the case
 where the outermost connective of  is other than a
 propositional quality operator, we only describe the construction of
 . The correctness of this automaton
 can be proved in a similar way to the proof of
 Lem.~\ref{lem:correctnessOfA}:
recall that Lem.~\ref{lem:correctnessOfA} is also proved by induction on the construction of a formula. 
  
  Suppose that . We define  
  where  and 
  . 
  
  Suppose that . We define  where 

 
 Suppose that  and that
  is odd. By the induction hypothesis, for each of , there exists  that satisfies the postulated condition. Then we define  as follows. Its state space  is . The transition function  is

  The acceptance function  is


 Suppose that  and that
  is even. By the induction hypothesis, for each of , there exists  that satisfies the postulated condition. Then we define  as follows. Its state space  is . The transition function  is

  The acceptance function  is


Suppose that . By the induction hypothesis, there exists  that satisfies the postulated condition. Let .

 Suppose that . By the induction hypothesis, there exists  that satisfies the postulated condition. Then we define  as follows. Its state space  is . The transition function  is

  The acceptance function  is


 Suppose that  and that
  is odd. By the induction hypothesis, for each of , there exists  that satisfies the postulated condition. Then we define  as follows. Its state space  is . The transition function  is

  The acceptance function  is


 Suppose that  and that
  is even. By the induction hypothesis, for each of , there exists  that satisfies the postulated condition. Then we define  as follows. Its state space  is . The transition function  is

  The acceptance function  is


  Suppose that  and
 that  is odd. Since , there
 exists a natural number  such that
  (i.e.\
  is beyond the event
horizon). We construct  by induction
 on  backwards, that is, starting from  and
 decrementing  one by one until .
 If , we define  
  where  and 
  .
  Otherwise, we define 
 as follows. By the induction hypothesis, for each of , there exists  that satisfies the postulated condition. Moreover, there exists . We define the state space  of  by . The transition function  is

  The acceptance function  is


  Suppose that  and that  is even. Similarly to the case where  is odd, we construct  by induction on  backwards.
 If , we define  
  where  and 
  .
  Otherwise, we define 
 as follows. By the induction hypothesis, for each of , there exists  that satisfies the postulated condition. Moreover, there exists . We define the state space  of  by . The transition function  is

  The acceptance function  is


  Suppose that  where  and that  is odd. Since  is continuous and
 its domain  is bounded and closed in the Euclidean space , this function  is uniformly continuous by the Heine–Cantor theorem. By the monotonicity and the uniform continuity, there exists  such that, for each , 
  
  where  is defined by . By the  induction hypothesis, there exist  such that, for , 
  
  for each . Since  is
 odd, the function  defined by  is
 monotone in . Since the class of languages of alternating
 -acceptance automata and that of -acceptance automata are
 the same by Prop.~\ref{prop:ABAtoNBA}, the closure property in
 Prop.~\ref{prop:ClosedUnderIncOperator} remains true even if -acceptance automata are replaced by alternating -acceptance automata. Hence, there exists  defined in Prop.~\ref{prop:ClosedUnderIncOperator}. 
 By~(\ref{eq:newEpsilon}) and the definition~(\ref{eq:actionExplicitly}) of the operator , we have
  
 Hence, if we define  by
 , 
it
satisfies the postulated condition.
  
  Suppose that  where  and that  is even. Let  be a prefix of . Then we have
 . We
 define a function  by
 . Let . It is obvious that
 . Moreover, we have  for each
 , and  is odd. Therefore
 there exists  because of the
 previous case (i.e.\ when  is odd),\footnote{Recall that
 we are currently running two nested induction, with the outer one being with respect
 to the number of propositional quality operators.} 
and we take this as . Then  satisfies the postulated condition.
\end{proof}

Once  is constructed, the procedure described in \S{}\ref{subsubsec:theAlgorithmWithoutPropositional} works regardless of the presence of propositional quality operators.
 





\section{Omitted Proofs}\label{appendix:omittedproofs}

\subsection{Proof of Prop.~\ref{prop:ABAtoNBA}
}
\label{pf:lemABAtoNBA}
 \begin{proof}
\auxproof{  (Miyano,Hayashi (1984) Alternating Finite Automata on
  omega-Words.)}
  We first describe the formal construction; intuitions follow shortly.
  
  Without loss of generality, we can assume that a positive Boolean formula  is a
 disjunctive normal form; 
therefore the transition function is of the type
 . 
 More concretely,
 for each  and , 
 the formula  is a disjunction of formulas of the form

where  and  are
 atomic propositions (we  changed their order suitably). Moreover, since the conjunction 

 is equivalent to a single atomic proposition , we  assume that any disjunct of the DNF formula  is of
 the form 



Let  be the set of acceptance values that occur in , and
  be the set of values from   (i.e.\ atomic
 propositions from ) that
 occur in the transition function , that is,

We define  as follows.
  
The transition function  is defined as follows.
Let
  be a state
in , and . Then  is defined,
  in case , by:
+.7cm]
 \min\{v,u^{1},\dotsc,u^{n}\}\,,
 \\
 b'
 \end{array}
 \right)
 \;\right.\;
 \right.
 \qquad\qquad
 \\
 \Bigl.
 \Bigl.
 \Bigr|\quad
 \bigl(\,(q^{i}_{1}\land\cdots\land q^{i}_{l_{i}})\land
 u^{i}\,\bigr)\in\delta(q^{i},a)\,,\quad b'\in\{\ttrue,\ffalse\}
 \quad
 \Bigr\}\enspace;
\end{aligned}
\label{eq:defDeltaPrimeExternalizing}
 \left\{\quad
\left.
  \left(
\begin{array}{c}
  \left\{
 \begin{array}{c}
  \bigl(\,q^{1}_{1},\, F(q^{1}_{1})\,\bigr)\,,\; \dotsc,\;
    \bigl(\,q^{1}_{l_{1}},\, F(q^{1}_{l_{1}})\,\bigr),
 \\
  \vdots
 \\
  \bigl(\,q^{n}_{1},\, F(q^{n}_{1})\,\bigr)\,,\; \dotsc,\;
    \bigl(\,q^{n}_{l_{n}},\, F(q^{n}_{l_{n}})\,\bigr)
 \end{array}
 \right\}\,,
\
  In each case ( or ), different -successors of
   arise from: 1) different choices of a disjunct
of a DNF formula , for ; and 2) different choices of 
 (it can always be chosen from  and ).

In the setting of~\cite{MiyanoH84} (that is Boolean instead of
 quantitative), the state space  of the nondeterministic automaton obtained as a translation of
  an alternating one is .
  Its quantitative adaptation  occurs as
  the first component of 
  in our above
  quantitative construction;
the rest 
   of  is there
  for handling
   quantitative 
acceptance.

It is not hard to see that  and  have the same language.\footnote{ A  more rigorous proof can be given via formulating an
 acceptance game for an alternating -acceptance automaton.
}
For example, in a state
  of :
\begin{itemize}
 \item The pair  is that of the \emph{current state} and 
  what we call the \emph{internally accumulated acceptance value}.
 \item The set   stands for the \emph{conjunction} of these pairs.
 \item The second component  of  is for
       keeping track of: the values at the
       leaves
       of the corresponding run tree, more precisely the smallest among such.
 \item The flag  is called an \emph{exposition
       flag}: it determines if
       the internally accumulated  acceptance values
        should be exposed or not.  
       Note the definition of : the acceptance value of a state of
        
       is nonzero only if the exposition flag  is . 
\end{itemize}
Let us comment on the definition of the transition function . 
  Starting from ---in which the ``current state'' is the
 conjunction ---we choose one disjunct 
  
for
 each  and the ``next state'' is

If the exposition flag  is  then we keep accumulating
the acceptance values that we have seen since the last exposition,
 resulting
in the occurrence of 
 in~(\ref{eq:defDeltaPrimeNotExternalizing}). If the flag is 
then the internally accumulated acceptance values are ``used'' (see the
 definition of ), and these values must be ``forgotten'' so that we
  simulate a B\"uchi-like acceptance condition for . Therefore
in~(\ref{eq:defDeltaPrimeExternalizing}), there are
 no  occurring and we have a fresh start.
\end{proof}


 
The state space  of  in the previous proof can actually be
smaller: we can identify two states  and  if  holds for each ---this is the case for example when
 and .  Therefore
we only need states  such that , that is,  can be regarded as a partial
function. Summarizing, we can reduce the state space to . The size
of the first component is , while it was
 before this optimization.

\subsection{Proof of Prop.~\ref{prop:ClosedUnderIncOperator}}
The proof is an adaptation of that of Prop.~\ref{prop:ABAtoNBA}. Here we
combine the usual construction of synchronous products of automata, with
the idea of exposition flags.
\begin{proof}
  Let  for each .  We define  as follows. Its state space  is  where
 . The set  of initial states is . The acceptance function is defined by
  
  The transition function 
 is defined as follows. Let , and .
  
 We shall prove that the automaton  indeed
 satisfies the requirement. Recall that, by definition, a
 -acceptance automaton has no dead ends.  Let  be an infinite word. 

 On the one hand, it follows
 easily from
 the above definition (in
 particular~(\ref{eq:propClosedUnderIncOperator1})) that if ,
 there exist  such that:
 , and  for each . Hence the monotonicity of  yields . 

 On the other hand, assuming that
  for each , 
 it is not hard to see that
 . 
 Here the intuition about the automaton 
  , and especially its state
 , is as follows.
 \begin{itemize}
  \item The automaton  is essentially a
	synchronous product of ; the state
	 is the current state of the constituent
	automaton .
  \item Each  constituent
	automaton  is additionally equipped with a register 
	for storing ``the greatest acceptance value that is recently seen.''
The value  is the one stored in that register. 
  \item The flag  decides if the stored
	acceptance value  is ``exposed'' or
	not. See~(\ref{eq:propClosedUnderIncOperator1}) where the
	acceptance value of the composed automaton 
	  is nonzero only if .
	Also observe that, in~(\ref{eq:propClosedUnderIncOperator2}),
	the register  is reset to the current acceptance value
	 when the register is exposed (i.e.\ ).
 \end{itemize}
Following this intuition, it is not hard to see that the claimed fact   is witnessed by a run
 such that: it does not expose the register values before
all the
 registers acquire the values ; and once they
 have all done so, the register values are exposed by setting .


 From the above two inequalities, we conclude that
 .
\end{proof}



\subsection{Proof of Lem.~\ref{lem:AphiEpsIsFiniteState}}
\label{pf:lemAphiEpsIsFiniteState}
\begin{proof}
 The state space  of
  is infinite for three reasons: 1) 
 the extended closure
 contains 
 for unbounded   (see~(\ref{eq:defXcl})); 2)  discount factors 
 occurring in  are multiples of numbers from an infinite set 
 ; and 3) the length of a discount sequence
  is potentially unbounded. 

 We can easily see that the reason 3) is not a problem for us: in the construction of 
 (Def.~\ref{def:ABAforLTL}), the length of
 a discount sequence  grows only when we encounter negation
(i.e.\ in the definition of ). 
Therefore in a reachable state  of , the
 length of  is bounded by the number of negation operators
 occurring in .

 To see that the reasons 1) and 2) are not problematic either, note that
 we obtain new states for these reasons only in the
 clause~(\ref{eq:defDeltaWithinEventHorizon}) of the definition of . This clause is applied only when 
 	 , a
 condition satisfied by
 only finitely many reachable states of :
\begin{itemize}
 \item The discount function  here is of the form
       ,
       where  occurs in the original formula  and . Since a discounting function  tends to 
       (Def.~\ref{def:discountFunction}),
       
       tends to  as , too, making only finitely many 
       suitable.
 \item Each discount factor  in  is a multiple
       , where
        is a discounting function occurring in  and
       . They must at least satisfy
       : since  tends to , this allows only finitely many
       choices of , for each . Furthermore, the
       (necessary) condition that 
       
       bounds the length  of the multiple, too.   
\end{itemize}
\end{proof}


\subsection{Proof of Lem.~\ref{lem:correctnessOfA}}
\label{pf:lemcorrectnessOfA}
\begin{proof}
 In what follows
  let  denote the state space of ;
  denote its transition function;
and  denote its acceptance function.
For each ,  we define an alternation -acceptance automaton 
 by changing the initial
 state to , that is,
. Suppose
 that . 
 We prove the following more general statement, inductively on the
 construction of :

  for each .

  The cases where , , ,  or  are straightforward. Here we only prove the case where
 . 
 By the definition of the automaton  we have
 , and the latter value lies in the interval
 
 by the induction hypothesis. Now we obtain

 as required. Here the former equality is due to the definition of
 ; the latter is the semantics of .








   
  Suppose  ; we first deal with the case
 when  is odd. 
Let . 
We note that, since   is odd, the function
  is monotone and
 continuous (see~(\ref{eq:actionExplicitly})). This is used in:
  
Now let us take a closer look at how the value  is defined for an alternating
 -acceptance automaton . As seen in
 Def.~\ref{def:alternative_buchi}, the notions of run tree and path
 are Boolean; a non-Boolean value arises for the first time as the
 ``utility''  of a path  of a run tree. 
According to Def.~\ref{def:ABAforLTL} of 
  (in particular the definition of ),  any possible run tree 
 from the state  is of one of the following forms:
\begin{itemize}
 \item the second disjunct  is chosen all the way
       (Fig.~\ref{fig:untilRunTree}, left),
or
 \item the first disjunct  is eventually hit
       (Fig.~\ref{fig:untilRunTree}, right).
\end{itemize}
\begin{figure}[tbp] 
\includegraphics[width=\textwidth]{discountingLTLpics3.pdf}
 \caption{Possible run trees from the state  in , when  is
 odd}
\label{fig:untilRunTree}
\end{figure}
In the former case, the utility
  of such a run tree 
 is given by
, 
where the first value  is induced by the
 rightmost path in Fig.~\ref{fig:untilRunTree}, left.  We have
 by definition
 (see~(\ref{eq:acceptanceFunc})); therefore the utility obtained in this
 case is .

In the latter
 case, assume that the second disjunct 
  
 is hit at depth . The tree's utility is then given by
 where, again, the first value 
 arises
 from the rightmost path in Fig.~\ref{fig:untilRunTree}, right.

Putting all these together, we have

as required.


  Suppose that  and that  is
 even. Let . Since  is antitone and continuous, the second
 equality below holds.
  
  We use the following observation. It is a quantitative adaptation of 
  the classic duality between the temporal operators  and 
 (``release'').
  \begin{sublem}\label{sublem:quantitativeUntilAndRelease}
   Let
 and
  all be real numbers in . We have
  
that is, denoting binary  and  by  and :
  
  \end{sublem}
  \begin{proof} (Of Sublem.~\ref{sublem:quantitativeUntilAndRelease})
   We distinguish two cases. Let us first assume that there exists
    such that .
   Let  be the least number among such, that is,  satisfies that
   
   Moreover, let  be a number such that . 
   We have 
  
  Since we have

 for each ,
  
  and we obtain
  
Now we compare the last value 
   with 
 the right-hand side of our goal~(\ref{eq:goalofSublemquantitativeUntilAndRelease}).
By the definition of  and , for each , we have 
   
yielding

The last inequality holds for each , too:
   
Consequently
   
We turn to the other part 
of the right-hand side of~(\ref{eq:goalofSublemquantitativeUntilAndRelease}).
   By the definition of  and , we have . Therefore
   
   By~(\ref{eq:supLeqInf}) and~(\ref{eq:infLeqInf}), 
   
   on the one hand. 
   On the other hand,  since ,
   
   By~(\ref{eq:leqAtFirstCase}) and~(\ref{eq:geAtFirstCase}), 
   
   By~(\ref{eq:infAtFirstCase}) and~(\ref{eq:infSupEqualAtFirstCase}), 
  
This establish the claim, in our first case where there exists
    such that .

In the other case we assume  that  for each . By this assumption, 
  
  for each .
  Therefore
  
 
Let us now fix . For each  we have 
  , where the latter inequality holds because of the assumption.
Therefore ; this is used in

   This holds for any ; therefore
  .
 This yields
	, which is combined with~(\ref{eq:infAtSecondCase}) and 
   proves the claim~(\ref{eq:goalofSublemquantitativeUntilAndRelease}). 
This concludes the proof of
   Sublem.~\ref{sublem:quantitativeUntilAndRelease}. 
  \end{proof}

 We turn back to the proof of Lem.~\ref{lem:correctnessOfA}.
By letting  
and  in
 Sublem.~\ref{sublem:quantitativeUntilAndRelease}, we obtain
  

  By~(\ref{eq:untilEven}) and~(\ref{eq:distrInfSup}), we have
  
  Let us now look at the value 
. 
We analyze  possible run trees  starting from the state
, much like in the previous case where
  is odd (in the current case it is even). It is easily seen
 from Def.~\ref{def:ABAforLTL} that  is of one of the forms shown
 in Fig.~\ref{fig:untilRunTreeEven}.
\begin{figure}[tbp] 
\includegraphics[width=\textwidth]{discountingLTLpics4.pdf}
 \caption{Possible run trees from the state  in , when  is
even. The double-lined nodes  have
 the acceptance value .}
\label{fig:untilRunTreeEven}
\end{figure}
\begin{itemize}
 \item 
  If  is of the form in Fig.~\ref{fig:untilRunTreeEven} on the left, its utility
   
  is 
 ; note that the rightmost path's value of  is 
 and hence does not appear here. 
 \item 
  If  is of the form in Fig.~\ref{fig:untilRunTreeEven} on the
       right, its utility    
  is given by
   where  is the depth of the last occurrence of the node .
\end{itemize}
The value 

is defined as the supremum of these utilities.  Therefore:
  
concluding the case when   and  is
 even. 


  Suppose that  and that
   is odd. 
 We prove the claim by induction on , going backwards, decrementing
  starting from the event
 horizon towards . As the base case, assume that  is big enough and we are
 beyond the event horizon, that is,  .
Let  and
  . 
Then we have
 , by   Lem.~\ref{lem:maxTruthValOfDiscountedUntil}
 and that . It follows
 from~(\ref{eq:actionExplicitly}) that we have 

(note that  is odd). Therefore



Now, as the step case, assume that   and that the claim has been shown for
 . The  analogue below of
  follows easily from Def.~\ref{def:LTLdDSemantics}:

Therefore

where the first equality is due to the monotonicity of
 , and the second is by~(\ref{eq:odotAndBoxtimes}).
Now

by Def.~\ref{def:ABAforLTL}. 
By the induction hypothesis (the claim has been shown for simpler
 formulas as well as ), a lower bound of the above value is given by

Similarly an upper bound  is obtained by the induction hypothesis
 and~(\ref{eq:201410152355}). This proves the claim.






The remaining case where 
  and 
   is even is similar to the last case. 
We describe only the base case of induction, where  is  big enough so that
 . By
 Lem.~\ref{lem:maxTruthValOfDiscountedUntil}
 we have ; therefore

By~(\ref{eq:actionExplicitly}) and that  is even, we have

Hence

This concludes the proof.
\end{proof}


\subsection{Proof of Lem.~\ref{lem:fromOptimalInATimesKToOptimalInA}}
\label{pf:lemfromOptimalInATimesKToOptimalInA}
\begin{proof}
 It follows easily from the definition that there is a bijective
 correspondence between: a run  of ; and a pair  of
 a path  of  and 
 a run  over  of . Moreover, 
 the acceptance value of  in  is equal to
 that of  in . The claim follows immediately.
\end{proof}


\subsection{Proof of Thm.~\ref{thm:mainWithoutPropositional}}
\label{pf:thmmain}
\begin{proof}
 
The solution   thus obtained arises from a lasso
 computation of  (by the algorithm
 in Lem.~\ref{lem:lassoOptimalityForQuantitativeAcceptAutom}), hence is
 ultimately periodic.
\end{proof}

\subsection{Proof of Prop.~\ref{prop:sizeOfAltAutom}}
\label{pf:propsizeOfAltAutom}
\begin{proof}
  In the proof of Lem.~\ref{lem:correctnessWithPropositional}, we construct  inductively.
 We shall therefore prove, inductively on the construction on , that the size of the state space of  is singly exponential in  and in the length of the description of .
 
 In the case where  or
 , the claim is obvious.
 
 Suppose that  where . Let . Recall that
 the construction of 
  in
 Lem.~\ref{lem:correctnessWithPropositional}
 is by backward induction on , from  to . 
 In the base case when ,  we have
  (beyond the event
 horizon);  in this case
 the size of the state space of  is
 one. In the step case, the state space of
  is the union of: 
 those of the two automata for  and ;
 that of the automaton ; and 
 the singleton of the initial state of
 . 
 Overall, the state space of
  increases as  decreases, and the
 maximum is when ---in which case the state space of
  is roughly 
 copies of
those of the two automata for  and . 
Now we appeal to the fact used in~\cite{AlmagorBK14} that the value
  is
 polynomial in the length of the description of ---hence in 
---and
 .\footnote{It is not explicit in~\cite{AlmagorBK14} what
 is meant by the description length of . For the claimed
 fact to be true---that
  is
 polynomial in the length of the description of ---we expect it to be  where .
 For example, when ,  we have
 
  where for the last inequality we used . 
  This is linear in .
 }
 By this fact and the induction hypothesis, the size of the state space of  is singly exponential in  and in the length of the description of .
 
 Suppose that . Since
 ,
 we have  coincide with
 ---where the latter is defined
 in Prop.~\ref{prop:ClosedUnderIncOperator}. (We note that the
 construction  in Prop.~\ref{prop:ClosedUnderIncOperator} can be readily
 adapted to
\emph{alternating} -acceptance automata, too.) Hence the size of the state space of  is polynomial in those of  and . By the induction hypothesis, the size of the state space of  is singly exponential in  and in the length of the description of .
\end{proof}


\subsection{Proof of Thm.~\ref{thm:mainComplexity}}
\begin{proof}
 The construction in Prop.~\ref{prop:ABAtoNBA} (from  to
 ) results in 
 that is exponentially bigger than ; the size of 
 the product 
 (Def.~\ref{def:productAutomata}) is linear in those of
  and ; and finding
 an optimal run by
 Lem.~\ref{lem:lassoOptimalityForQuantitativeAcceptAutom} is in
 NLOGSPACE. Combined with Prop.~\ref{prop:sizeOfAltAutom}, the overall
 complexity is EXPSPACE in  and NLOGSPACE in the size of .
\end{proof}


\subsection{Proof of Thm.~\ref{thm:mainComplexityWithoutPropositional}}
Firstly we give an alternative proof to the following statement (that is
a restriction of Prop.~\ref{prop:sizeOfAltAutom}). It is used in the
proof of Thm.~\ref{thm:mainComplexityWithoutPropositional}.

\begin{sublem}[size of  , for ]\label{sublem:sizeOfAltAutomWithoutPropositional}
  Let  be an  formula and 
 be a positive rational number.  The size of the state space of
 the alternating -acceptance automaton
  is singly exponential in  and in the length of the description of . \qed
\end{sublem}
\begin{proof} (Of Sublem.~\ref{sublem:sizeOfAltAutomWithoutPropositional})
   Recall that a state of  is a pair
  
 of  and . 
 We first claim that the number of different 's is polynomial in 
  and . The claim is obvious
 except for the number of the formulas  of the form
 , for varying .
 Let
  be the maximum number 
in  
 used as the base of an exponential discounting function.
 For each subformula  of ,
 the numbers  for which we have a state
 
 in  is bounded by . Now we appeal to the fact used in~\cite{AlmagorBK14} that the value
  is
 polynomial in the length of the description of ---hence in 
 ---and
 .





 Our second claim is that the number of different 's occurring
 in states of   is exponential in
  and the description length of 
 , hence is the bottleneck in complexity. The length of a discount sequence  
 is bounded by the number of negations in , therefore by
  . Each entry  is a multiple
  of 
 different discounting bases  (there are 
 at most   -many such), and since its value 
 must be bigger than ,  the length  of such a multiple is at most
 . Therefore
 the number of candidates for  is bounded by
 ; appealing to
 the fact (see~\cite{AlmagorBK14}) that  is
 polynomial in the length of the description of  and
 , we obtain the claim.
\end{proof}

\begin{proof} (Of Thm.~\ref{thm:mainComplexityWithoutPropositional}, sketch) 
 We describe how to avoid 
the exponential blowup in the translation from 
 to  .

 Looking at the construction of Prop.~\ref{prop:ABAtoNBA} in case of
 , we have , therefore

Here the original state space  is bounded by 
 , where
  is a finite set and the second component 
 is from the
 proof of Prop.~\ref{sublem:sizeOfAltAutomWithoutPropositional}.

The optimization lies in the reduction of

that occurs in~(\ref{eq:201410162348}) to 
 hence from a double exponential to a single
 exponential; 
recall from the proof  
 of Prop.~\ref{sublem:sizeOfAltAutomWithoutPropositional} that  is exponential and  is polynomial, in  and the
 description length of . 

The reduction is done concretely
 as follows. Given a set 

 of states of  with a common first component , we suppress the
 set into the
 function 
 
  that does the same job. The latter is a piecewise linear function on
  and hence is presented as a disjunction of pairs  of  a linear function  and its domain (here ). Now  is represented by some discount sequence
 so
 there are at most -many of them. A point   is expressed as the cross point of two linear functions,
 each represented by a discount sequence.
The same goes for . 
 Moreover, disjunction is taken out of a single state in the resulting
 automaton---from alternating to non-alternating we only need to bundle
 up states in conjunction. 
In summary, to express 
 the piecewise linear function in~(\ref{eq:piecewiseLinear}) we need:  to
 represent ;  to represent ; and
 to represent , resulting in 
 in~(\ref{eq:QfiveTimes}). 

 We consider all those sets in the form
 of~(\ref{eq:aSetToBeSuppressed}), therefore we need 
 for each formula . The set  is in~(\ref{eq:QfiveTimes}) to take
 care of the case when the set~(\ref{eq:aSetToBeSuppressed}) for the
 formula  is empty.
\end{proof}


\section{Reduction of Fuzzy Automata to -Acceptance Automata}
\label{appendix:fuzzyAndZeroOne}
A generalization of -acceptance automaton
  is naturally obtained by making transitions also
-weighted. The result is called \emph{fuzzy automaton}
  and studied e.g.\ in~\cite{Rahonis05}.
  Here we show that this generalization does not add expressivity. In
  fact we prove a more general result, parametrizing 
  into a general semiring 
   (under certain conditions).





We
follow~\cite{DrosteP07} and
impose certain conditions on a semiring  of weights.
\begin{defi}[\cite{DrosteP07}]\label{def:conditionsOnSemiring}
A tuple  is called an \emph{ordered semiring} if  is a semiring,  is a partially ordered set and both  and  are monotonic.

 An ordered semiring  is said to be
 \emph{lattice-complete} if:  is a complete lattice; the units
  of  satisfy  for each ; and  
  
  for each family  and each . We define an
 infinite sum, as usual, by
  
  where  is the set of finite subsets
 of .

 A semiring is \emph{locally finite} if the underlying monoid  is locally
 finite, that is: for each finite subset , the submonoid of  generated by  is finite.
\end{defi}
The notion of -weighted (B\"uchi) automaton is
studied in~\cite{DrosteP07}, from which the following definition is taken.
\begin{defi}[-acceptance (B\"uchi) automaton, -weighted (B\"uchi) automaton]
  Let  be a lattice-complete semiring. A \emph{-acceptance (B\"uchi) automaton} is a tuple , where  is a finite  alphabet,
  is a finite set of states,  is a set of initial
 states,  is a
 transition function and  is 
 a function that assigns an \emph{acceptance value} to each state.
  We define the language  of  as
  
  
  A \emph{-weighted (B\"uchi) automaton} is a tuple , where  is a finite  alphabet,  is a
 finite set of states,  is a function assigns an
 \emph{initial weight} to each state,  is a (-weighted) transition function
 and  is a function assigns an \emph{acceptance value} to each state.
  We define the language  of  by
  
\end{defi}


These notions specialize to -acceptance automaton and fuzzy automaton~\cite{Rahonis05}
 by taking the fuzzy semiring  as  in the above definitions.

Locally finiteness of a semiring~\cite{DrosteP07} is central in the
following result. Its proof is not hard but
 the result is not explicit in~\cite{DrosteP07} or elsewhere.
\begin{lem}\label{lem:nondeterminization}
  Let  be a lattice-complete semiring
 and  be a -weighted
automaton.
 If
 is locally finite (Def.~\ref{def:conditionsOnSemiring}),
 there exists a -acceptance
automaton  such that
 .
\end{lem}
\begin{proof}
 Let  be the submonoid of  generated by
 the (finite) set of weights of transitions occurring in , that is,
 . The set  is
 finite since  is locally finite.
We now define  as follows.
 
 The proof of  is straightforward.
\end{proof}

It is straightforward that the fuzzy semiring  is locally
finite. This leads to:
\begin{cor}
  Let  be a fuzzy automaton. There exists a -acceptance 
  automaton  such that 
 .
\qed
\end{cor}

The main results of~\cite{Rahonis05,DrosteP07} concern the
characterization of so-called \emph{-rational formal power
series} over ---those which are generated by
-regular-like expressions---by -\emph{weighted} B\"uchi
automata. Lem.~\ref{lem:nondeterminization} therefore gives us another
characterization by -\emph{acceptance} B\"uchi automata.








\end{document}
