[{'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'GQA test-dev', 'Metric': 'Accuracy', 'Score': '60.0'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-dev', 'Metric': 'Accuracy', 'Score': '69.9'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'A-OKVQA', 'Metric': 'MC Accuracy', 'Score': '41.6'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'A-OKVQA', 'Metric': 'DA VQA Score', 'Score': '25.9'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-std', 'Metric': 'overall', 'Score': '72.5'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'GQA Test2019', 'Metric': 'Accuracy', 'Score': '62.71'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'GQA Test2019', 'Metric': 'Binary', 'Score': '79.79'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'GQA Test2019', 'Metric': 'Open', 'Score': '47.64'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'GQA Test2019', 'Metric': 'Consistency', 'Score': '93.1'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'GQA Test2019', 'Metric': 'Plausibility', 'Score': '85.21'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'GQA Test2019', 'Metric': 'Validity', 'Score': '96.36'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'GQA Test2019', 'Metric': 'Distribution', 'Score': '6.42'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'GQA Test2019', 'Metric': 'Accuracy', 'Score': '60.33'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'GQA Test2019', 'Metric': 'Binary', 'Score': '77.16'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'GQA Test2019', 'Metric': 'Open', 'Score': '45.47'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'GQA Test2019', 'Metric': 'Consistency', 'Score': '89.59'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'GQA Test2019', 'Metric': 'Plausibility', 'Score': '84.53'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'GQA Test2019', 'Metric': 'Validity', 'Score': '96.35'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'GQA Test2019', 'Metric': 'Distribution', 'Score': '5.69'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'GQA test-std', 'Metric': 'Accuracy', 'Score': '60.3'}}, {'LEADERBOARD': {'Task': 'Visual Reasoning', 'Dataset': 'NLVR2 Test', 'Metric': 'Accuracy', 'Score': '76.2'}}, {'LEADERBOARD': {'Task': 'Visual Reasoning', 'Dataset': 'NLVR2 Dev', 'Metric': 'Accuracy', 'Score': '74.9'}}]
