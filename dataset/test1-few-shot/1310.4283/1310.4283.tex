\documentclass[]{llncs}

\usepackage[]{textcomp}
\usepackage[]{microtype}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[]{stmaryrd}
\usepackage[]{amssymb}
\usepackage[]{amsmath}


\usepackage{hyperref}

\bibliographystyle{splncs}


\title{Abstract interpretation as anti-refinement}

\author{Arnaud Spiwack}

\institute{Inria Paris-Rocquencourt\\\textsc{Ens}, 45 rue d'Ulm, 75230 Paris Cedex 05, France\\
\email{arnaud@spiwack.net}}

\begin{document}
  \maketitle
\begin{abstract}
    This article shows a correspondence between abstract interpretation of imperative programs and the refinement calculus: in the refinement calculus, an abstract interpretation of a program is a specification which is a function.
\par
This correspondence can be used to guide the design of mechanically verified static analyses, keeping the correctness proof well separated from the heuristic parts of the algorithms.
  \end{abstract}
\section{Introduction}
  A mathematical way to describe a static analysis is to see it as a program which tries to prove a theorem about programs. It may fail to do so, but if it succeeds, it effectively acts as a proof of the said theorem. The proof, however, is essentially impossible to check by a human.
\par
To increase the level of trust in a static analysis tool, the tool can be mechanically verified, for instance in Coq~\cite{coq}, thus ensuring that the produced proof is always correct. In the design of a static analysis tool, some parts are crucial for correctness, while other are heuristic. For instance, a static analysis can choose to lose precision to gain performance. Hence, from the point of view of he who wants to ensure the correctness, a static analysis can be seen as an interplay between a correctness enforcer and an heuristic-providing oracle. The question addressed in this article is how to formalise this interplay.
\par
To that end, we use the refinement calculus~\cite{Back1998,VonWright1994}. The refinement calculus is a well-established method for proving program properties. It comes with a natural notion of interaction, generally used to model the interaction between the implementer of a unit of code and its user. In the context of this article, the correctness enforcer plays the role of the implementer while the oracle is the user.
\par
Specifically, this article shows the connection between static analysis by abstract interpretation~\cite{Cousot1992} and the refinement calculus. Namely, it shows that an abstract domain constructs a \emph{specification} of the analysed program, which happens to be given by a function. This correspondence is instrumental in the design of Cosa~\cite{cosa}, a Coq formalisation of a shape analysis.
\par
The two subjects have some notation overlap, hence some unconventional notations will be used. The author apologises, but hopes that practitioners of both subjects will not find the notations too surprising or confusing.
  \section{Predicate transformers}
\par
Edsger Dijkstra introduced the idea of using predicate transformers as semantics of imperative programs~\cite{Dijkstra1978}. The idea is to associate to each program  a function , its \emph{weakest liberal precondition} operator, such that for a property  of program states,  is the weakest condition on the initial state, such that after running , if  terminates, then  holds.
\par
Weakest liberal precondition accounts for partial correctness. Alternatively, one could use the weakest precondition operator (which additionally imposes that  terminates) to account for total correctness. Termination is not our purpose here, and we will identify programs with their weakest liberal precondition operator.
\par
Predicate transformer semantics is the starting point of refinement calculus~\cite{Back1998}, and is also commonly used in abstract interpretation -- see~\cite{Cousot1997a} for a discussion of weakest liberal precondition in relation to abstract interpretation.
\par
\subsection{Basic definitions}
\par
We will call \emph{predicate transformers} monotone functions in  for some sets  and , and write  for the set of predicate transformers. The set  inherits the complete lattice structure of  and , equipped with the lattice operations of , is also a complete lattice. We write  for the inherited order.
\par
We shall call the following operations of predicate transformers \emph{regular operations}. They have a direct interpretation as program constructs. Programs will be interpreted as homogeneous predicate transformers , however the regular operations also work with general predicate transformers .
  \begin{description}
    \item[Sequence] 
\par
Reads as ``do  then do ''. The definition of sequence emphasises the fact that the weakest liberal precondition semantics is a \emph{backward} semantics. Sequence is associative, and monotone:
                  \begin{itemize}
      \item 
      \item 
    \end{itemize}
    \item[Skip] 
\par
Does not do anything. Skip is neutral for sequence:
              \begin{itemize}
      \item 
    \end{itemize}
    \item[Choice] 
\par
Non-deterministic choice. Choice is associative, commutative and monotone. Moreover sequence distributes on the right over choice:
                \begin{itemize}
      \item 
      \item 
      \item 
      \item 
    \end{itemize}
    \item[Hang] 
\par
Hang loops indefinitely. It is neutral for choice, sequence distributes on the right over it, and it is the largest predicate transformer:
               \begin{itemize}
      \item 
      \item 
      \item 
    \end{itemize}
    \item[Iteration] , for , is the largest fixed point of the (monotone) function which maps  to . It runs  in sequence a non-deterministic number of times (including none, and infinitely many). It has the following properties~\cite[Chapter 21]{Back1998}:
               \begin{itemize}
      \item 
      \item 
    \end{itemize}
  \end{description}
\par
It should be noted that despite the name ``regular operations'', predicate transformers do not form a Kleene algebra under these operations. Indeed the left distributivity laws are missing:  and  do not hold in general.
\par
\subsection{Programs}\label{latex_lib_label_1}
\par
In this setting, a programming language consists in a set  of states together with a set  of \emph{basic instructions}. A program in the language  is an element of the subset of  generated by  and the regular operations.
\par
The use of non-deterministic choice and iterations make the programs non-deterministic. This is a natural setting for both program refinement and abstract interpretation. However, a typical programming language will feature a set of tests  such that for all , there is , and  is an instruction, such that .
\par
With this assumption, the usual deterministic programming constructs can be recovered: , and .
\par
\par
\begin{example}
    As an example, let us consider a language with a single memory cell containing an integer. In other words, . It has two tests,  and , whose semantics are given by:
    \begin{itemize}
      \item 
      \item 
    \end{itemize}
    and a operation , which decrements the integer held in the state. Its semantics is given by:
    \begin{itemize}
      \item 
    \end{itemize}
\par
This language expresses, for example, the simple program whose effect is to decrease the integer held in the state until it is non-positive. We shall call this program :
    \begin{itemize}
      \item 
    \end{itemize}
  \end{example}
\par
\par
\subsection{Relations}
\par
A relation is usually seen as a subset of , however, it will be more convenient to see them, equivalently, as functions of .
\par
Given a relation , we can extend it to a predicate transformer in two ways:
  \begin{itemize}
    \item  defined by xX
    \item  defined by 
  \end{itemize}
  The predicate transformers  and  form a Galois connection \emph{i.e.}:
  \begin{itemize}
    \item 
  \end{itemize}
  or equivalently:
  \begin{itemize}
    \item 
    \item 
  \end{itemize}
  In fact, every Galois connection between powersets is of that form. This is due to the general fact about complete lattices that a left adjoint -- like  -- is the same thing as a function which preserves joins. In the case of powersets, a function which preserves joins is characterised by its action on singletons, hence is of the form .
\par
Identifying a function  to its graph, we hence have a Galois connection between  and . These are better known as the direct image and the inverse image of , which we will write  and  respectively. We shall make use of the following consequence of their being a Galois connection:
  \begin{itemize}
    \item 
  \end{itemize}
\par
The properties of Galois connections can also be read directly in terms of the predicate transformer lattice:
  \begin{itemize}
    \item 
    \item 
    \item 
    \item 
  \end{itemize}
  \section{Abstract interpretation}\label{latex_lib_label_2}
\par
Abstract interpretation~\cite{Cousot1992} is a framework for static analysis in which the objects of study are called \emph{domains}. As general as the definitions in this section are, they fail to capture the full generality of abstract interpretation. However, they are sufficient for most purposes -- at least for imperative languages.
\par
Fixing a programming language , the powerset  is called the concrete domain and the interpretation of a program as a predicate transformer  is called the concrete semantics.
\par
A departure from common practice is that the concrete semantics, the weakest liberal precondition, is backward -- \emph{i.e.} a function from a set of final states to corresponding initial states -- whereas often the concrete semantics is chosen to be forward. This choice has been made to stay closer to the practice in refinement calculus. Having a backward concrete semantics does not, however, constrain the analysis to be backward too. In the rest of the paper we will mainly consider forward analysis. Moreover, forward semantics are usually constructed from a relational semantics, \emph{i.e.} they are of the form , in which case  will be our backward semantics.
\par
An abstract domain is a set  together with a concretisation function  and extra material to construct an \emph{abstract semantics} to each program. The abstract semantics of a program is a forward function  which has the following correctness property:
  \begin{itemize}
    \item 
  \end{itemize}
  Which can, equivalently be stated as:
  \begin{itemize}
    \item 
  \end{itemize}
  This phrasing of the correctness property may look a bit contorted to the practitioner of abstract interpretation. It is the consequence of having a backward concrete semantics and a forward abstract semantics. When the concrete semantics is of the form , then this correctness property coincides with the more familiar one:
  \begin{itemize}
    \item 
  \end{itemize}
\par
Abstract domains are meant to be composed. For that reason, the abstract semantics  is computed out of more atomic functions, which are, in particular, stable by Cartesian product. Writing  for the order induced on  by the concretisation function, the abstract domain comes equipped with the following:
  \begin{description}
    \item[Join] An operator  such that:
    \begin{itemize}
      \item 
      \item 
    \end{itemize}
    \item[Post-fixed point] An operator  such that:
    \begin{itemize}
      \item 
      \item 
    \end{itemize}
\par
Typically, the post-fixed point operator is derived from a widening operator , which has the following properties:
    \begin{itemize}
      \item 
      \item 
      \item For every increasing sequence , the sequence  defined by  and  verifies .
    \end{itemize}
    Then, taking, mutually recursively, , , and  such as above, we can then define  as any  such that .
    \item[Transfer functions] An abstract semantics  of the instruction 
  \end{description}
\par
The abstract semantics  of the program  is defined by induction on  where the base case is given by the transfer functions. The correction of  follows from the properties stated above.
  \begin{itemize}
    \item 
    \item 
    \item 
    \item  can be chosen arbitrarily
    \item 
  \end{itemize}
\par
\par
\begin{example}
    Let us define an abstract domain for the example language of Section~\ref{latex_lib_label_1}: we shall abstract the state -- a single integer -- by the signs it may take. More precisely, we take for  the non-empty sets in  and the concretisation is defined as:
    \begin{itemize}
      \item 
    \end{itemize}
    The abstract transfer function for guard instructions constrain the abstract state to the relevant signs.
    \begin{itemize}
      \item 
      \item 
    \end{itemize}
    The abstract transfer function for the decrementing command maps positive to non-negative and non-positive to negative:
    \begin{itemize}
      \item 
      \item 
      \item 
      \item x{s}^{\sharp }
    \end{itemize}
    Since the abstract state space is a powerset, we can use union as the abstract join, and since it is finite, union is also a widening:
    \begin{itemize}
      \item 
    \end{itemize}
\par
Now that the abstract domain is set up, let us run the abstract interpretation on the program  from Section~\ref{latex_lib_label_1} with the input state :
    \begin{enumerate}
      \item Entering the loop with initial state 
      \item Applying : state becomes 
      \item Applying : state becomes 
      \item Invariant found after one iteration: 
      \item Applying : final state is 
    \end{enumerate}
  \end{example}
\par
\section{Data refinement}
\par
Refinement calculus~\cite{Back1998,VonWright1994} is a discipline to prove the correctness of imperative programs, in a spirit close to Hoare logic. It arises from the remark that, if most predicate transformers do not represent programs, they still represent program \emph{specifications}. Specifications are then \emph{refined} into more precise specifications, and eventually into programs.
\par
A key point of the refinement calculus is that the refined specification need not act on the same state as the abstract one. It is typical to use ideal objects -- like multisets -- on the abstract side, and more concrete datatypes -- like linked lists -- on the refined side.
\par
We say~\cite{VonWright1994} that  is refined by  through the \emph{coupling invariant} , written , when . Intuitively  is an action which transforms concrete states into abstract states, so  reads ``doing  then abstracting the state is more precise than abstracting the state then doing ''. To emphasise that the type of the state has changed, this relation is often called a \emph{data refinement}.
\par
\par
\begin{example}
    Specifications of imperative programs are typically given as pairs of a precondition and a postcondition. For instance: under the precondition that the initial state is a non-positive integer, the postcondition that the state is  holds after the program has been run. Both preconditions and postconditions can be expressed systematically as (backward) predicate transformers; they can be paired up into a full specification using sequence:
    \begin{itemize}
      \item 
      \item 
      \item 
    \end{itemize}
    So that  is either all of  if  or the empty set otherwise, and  simply ignores the states in  which do not verify the precondition.
\par
The program  from Section~\ref{latex_lib_label_1} meets the specification , however, the state is represented as the \emph{opposite} integer. Hence we have an  which reflects this representation:
    \begin{itemize}
      \item 
      \item 
    \end{itemize}
    As per the definition of refinement, the statement that the program  implements the specification reads
    \begin{itemize}
      \item 
    \end{itemize}
    It is equivalent to the statement that the precondition entails the weakest liberal precondition of :
    \begin{itemize}
      \item 
    \end{itemize}
    which is the typical proof obligation in a Hoare logic setting.
\par
The take away from data refinement is that it does not matter what coupling invariant is used, as long as \emph{all the function use the same coupling invariant}. Or, more realistically, under some separation property, if all the function \emph{which have access to some part  of the state} all have coupling invariants which agree on .
\par
In practice there are two reasons to refine the type of (a part of) the state: it may be that it is an ideal type, say finite sets of integer, which may be refined into an actual concrete data type, for instance list of integers. Or it may be that the proposed data type is not efficient, and will be refined into a more efficient representation -- list of integers could be refined into binary trees.
  \end{example}
\par
\par
\section{Abstract interpretation in refinement calculus}
\par
The main result of this article is that abstract interpretation can be characterised in the language of the refinement calculus: an abstract interpretation of a program  is a \emph{specification} verified by  which is also a function.
\par
\begin{theorem}
    \label{latex_lib_label_4}The soundness condition of abstract interpretation is a refinement condition:
         
  \end{theorem}
  \begin{proof}
    We have the following equivalent characterisation, thanks to the Galois connection properties:
    \begin{itemize}
      \item 
    \end{itemize}
    From which it follows that:
    \begin{list}{}{}
      \item 
      \item {\small{(Definition of sequence)}}
      \item 
      \item {\small{(Definition of inclusion)}}
      \item 
      \item {\small{(Definition of  and basic property of )}}
      \item 
      \item {\small{(Definition of )}}
      \item 
      \item {\small{( by  and  by monotonicity of )}}
      \item 
    \end{list}
  \end{proof}
\par
In~\cite{Cousot1992a}, Cousot \& Cousot describe abstract interpretation of inference rule systems. Their approach to defining abstract interpretation resembles refinement calculus, they use, in particular, the remark that inference rule systems can be represented as predicate transformers. Theorem~\ref{latex_lib_label_4} further illuminates the connection.
\par
Although so far we have mostly considered forward analyses, a similar characterisation to Theorem~\ref{latex_lib_label_4} holds for backward analysis:
  \begin{theorem}
    
  \end{theorem}
\par
In traditional refinement calculus, the process consists in starting with an abstract definition, and refine it towards a more concrete definition, weakening the preconditions, strengthening the postconditions while making the state more suitable for execution. In static analysis, refinement calculus is used somewhat backwards: starting from a concrete implementation, it is refined into a more abstract definition, in effect strengthening the precondition and weakening the postconditions, while still making the state more suitable for execution.
\par
\section{Conclusion}
  A previous work by Sylvain Boulmé and Michaël Périn~\cite{Boulme2013} uses refinement calculus as a mean to check, in Coq, the correctness of a certificate validation procedure for certificate meant to be output by an abstract interpreter. Although this work is at the intersection of abstract interpretation and refinement calculus, it does not try to establish a connection between refinement calculus and the correctness condition of the abstract interpretation procedure.
\par
The present article shows that the language of abstract interpretation can be recast in terms of the refinement calculus. This has been used in the formalisation of Cosa~\cite{cosa}, a Coq verified implementation of an abstract domain for shape analysis. Cosa targets Compcert C~\cite{compcert}, and uses numerical domains by David Pichardie \& \emph{al}~\cite{Blazy2013}.
\par
Cosa relies on a variant of the refinement calculus introduced by Peter Hancock based not on predicate transformers but on so-called \emph{interaction structures}~\cite{Hancock}. Compared to predicate transformers, interaction structures carry more information: the set of predicate transformers can be seen as a quotient of the set of interaction structures. The additional information contained in interaction structures can be used to derive a datatype of \emph{strategies} which the oracle is charged with providing, hence formalising the separation between the oracle, which has no bearing on the correctness and does not need to be mechanically verified, and the rules constituting the domain which ensure correctness.
\par
Interaction structures were initially developed as a variant of refinement calculus suitable for type theory. Thanks to the results of this article, interaction structures can be also leveraged for abstract interpretation.
  \bibliography{library}
\end{document}
