\documentclass[energies,article,accept,moreauthors,pdftex,12pt,a4paper]{mdpi}
\setcounter{page}{1}
\lastpage{x}
\doinum{10.3390/------}
\pubvolume{6}
\pubyear{2013}
\history{Received: 1 July 2013; in revised form: 17 August 2013 / Accepted: 21 August 2013 / \linebreak Published: xx}

\usepackage[utf8]{inputenc}
\usepackage{import}
\usepackage{xspace}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{color}
\usepackage[table]{xcolor}
\usepackage{comment}
\usepackage{soul}
\usepackage{booktabs}
\usepackage{pdflscape}

\newcommand{\grad}[1]{C\xspace}
\newcommand{\ann}{ANN\xspace}
\newcommand{\anns}{ANNs\xspace}
\newcommand{\openhab}{openHAB\xspace}
\newcommand{\caes}{CAES\xspace}
\newcommand{\mcs}{MCS\xspace}
\newcommand{\knx}{KNX\xspace}
\newcommand{\rest}{REST\xspace}
\newcommand{\smlhouse}{SMLhouse\xspace}
\newcommand{\smlsystem}{SMLsystem\xspace}
\newcommand{\ios}{iOS\xspace}
\newcommand{\best}{BEST\xspace}
\newcommand{\comb}{COMB-EXP\xspace}
\newcommand{\combeq}{COMB-EQ\xspace}
\newcommand{\model}[1]{\theta_{#1}}
\newcommand{\data}{\mathcal{D}}
\newcommand{\combw}{\alpha}

\newcommand{\sequence}[1]{\bar{#1}}
\newcommand{\mean}[1]{\mathbb{E}[#1]}


\Title{Towards Energy Efficiency: Forecasting Indoor Temperature via Multivariate Analysis}

\Author{Francisco Zamora-Mart\'inez *, Pablo Romeu, Paloma Botella-Rocamora and Juan Pardo}
\address[1]{Escuela Superior de Ense\~nanzas T\'ecnicas, Universidad CEU Cardenal Herrera, C/ San Bartolom\'e 55, Alfara del Patriarca  46115, Valencia, Spain; E-Mails: pablo.romeu@uch.ceu.es (P.R.); pbotella@uch.ceu.es (P.B.-R.); juan.pardo@uch.ceu.es (J.P.)}

\corres{E-Mail: francisco.zamora@uch.ceu.es; \linebreak Tel.: +34-961-36-90-00 (ext. 2361).}

\abstract{The small medium large system (\smlsystem) is a house built at the Universidad CEU Cardenal Herrera (CEU-UCH) for participation in the Solar Decathlon 2013 competition. Several technologies have been integrated to reduce power
 consumption. One of these is a forecasting system based on artificial neural
 networks (\anns), which is able to predict indoor temperature in the near
 future using captured data by a complex monitoring system as the input. A study
 of the impact on forecasting performance of different covariate combinations
 is presented in this paper. Additionally, a comparison of ANNs with the standard
 statistical forecasting methods is shown. The research in this paper has been
 focused on forecasting the indoor temperature of a house, as it is directly
 related to HVAC---heating, ventilation and air conditioning---system
 consumption. HVAC systems at the \smlsystem house represent  of the
 overall power consumption. The energy used to maintain temperature was measured to
 be -- of the energy needed to lower it. Hence, these forecasting
 measures allow the house to adapt itself to future temperature conditions by
 using home automation in an energy-efficient manner. Experimental results
 show a high forecasting accuracy and therefore, they might be used to
 efficiently control an HVAC system.}

\keyword{energy efficiency; time series forecasting; artificial neural networks}

\begin{document}


\section{Introduction}


\label{sec:introduction}
Nowadays, as the Spanish Institute for Diversification and Saving of Energy
(IDAE) \cite{IDAE} of the Spanish Government says, energy is becoming a precious
asset of incalculable value, which converted from electricity, heat or fuel,
makes the everyday life of people easier and more comfortable. Moreover, it
is also a key factor to make the progress of industry and
business feasible.

Spanish households consume  of the total energy expenditure
of the country \cite{IDAE}. In the European Union (EU), primary energy consumption
in buildings represents about  of the total \cite{Ferreira}. In the whole
world, recent studies say that energy in buildings also represents a  rate
of the total consumed energy, where more than half is used by heating, ventilation and air conditioning (HVAC) systems \cite{Alvarez}.

Energy is a scarce resource in nature, which has an important cost, is
finite and must be shared. \linebreak Hence, there is a need to design and implement new
systems at home, which should be able to produce and use energy efficiently and
wisely, reaching a balance between consumption and streamlined comfort. A person
could realize his activities much easier if his comfort is ensured and there are
no negative factors (e.g., cold, heat, low light, noise, low air quality, {\it etc.})
to disturb him. With the evolution of technology, new parameters have become more
controllable, and the requirements for people's comfort level \linebreak have increased.

Systems that let us monitor and control such aspects make it necessary to refer
to what in reference \cite{Arroyo} is called ``Ambient Intelligence'' (AmI). This refers
to the set of user-centered applications that integrate ubiquitous and
transparent technology to implement intelligent environments with natural
interaction. The result is a system that shows an active behavior (intelligent),
anticipating possible solutions adapted to the context in which such a system is
located. The term, home automation, can be defined as it is mentioned
in reference \cite{Sierra}, as the set of services provided by integrated technology
systems to meet the basic needs of security, communication, energy management
and comfort of a person and his immediate environment. Thus, home automation can
be understood as the discipline which studies the development of intelligent
infrastructures and information technologies in buildings. In this paper, the concept of smart
 buildings is used in this way, as constructions that involve this kind
of solution.

In this sense, the School of Technical Sciences at the University CEU-UCH has built a solar-powered house, known as the Small Medium Large System (\smlsystem), which
integrates a whole range of different technologies to improve energy efficiency, allowing it to be a near-zero energy house. \linebreak The house has been constructed to participate in the 2012 Solar
Decathlon Europe competition. \linebreak Solar Decathlon Europe \cite{solar} is an
international competition among universities, which promotes research in the
development of  energy-efficient houses. The objective of the participating teams is to
design and build houses that consume as few natural resources as possible and
produce minimum waste products during their lifecycle. Special emphasis is
placed on reducing energy consumption and on obtaining all the needed energy
from the sun. The \smlsystem house includes a Computer-Aided Energy Saving
System (\caes). The \caes is the system that has been developed for the contest,
which aims to improve energy efficiency using home automation devices. This system
has different intelligent modules in order to make predictions about energy
consumption and production.

To implement such intelligent systems, forecasting techniques in the area of
artificial intelligence can be applied. Soft computing is widely used in
real-life applications~\cite{2009:Wu,2012:Taormina}. In fact, artificial neural networks
(\anns) have been widely used for a range of applications in the area of energy
systems \linebreak modeling \cite{Karatasou, 2006:energyandbuildings:ruano, Ferreira,
 2012:kdir:zamora}. The literature demonstrates their capabilities to work with
time series or regression, over other conventional methods, on non-linear
process modeling, such as energy consumption in buildings. Of special interest to
this area is the use of \anns for forecasting the room air temperature as a
function of forecasted weather parameters (mainly solar radiation and air
temperature) and the actuator (heating, ventilating, cooling) state or manipulated
variables, and the subsequent use of these mid-/long-range prediction models for
a more efficient temperature control, both in terms of regulation and energy
consumption, as can be read in reference \cite{2006:energyandbuildings:ruano}.

Depending on the type of building, location and other factors, HVAC systems
may represent up to  of the total energy
consumption of a building \cite{Ferreira,Alvarez}. 
The activation/deactivation of such systems depends
on the comfort parameters that have been established, one of the most being indoor temperature, directly related to the notion of
comfort. Several authors have been working on this idea; \linebreak in reference \cite{Ferreira},
an excellent state-of-the-art system can be found. This is why the development of an \ann
to predict such values could help to improve overall energy consumption,
balanced with the minimum affordable comfort of a home, in the case that these values are
well anticipated in order to define efficient energy control actions.

This paper is focused on the development of an \ann module to predict the behavior
of indoor temperature, in order to use its prediction to reduce energy
consumption values of an HVAC system. The architecture of the
overall system and the variables being monitored and controlled are presented.
Next, how to tackle the problem of time series forecasting for the indoor temperature is
depicted. \linebreak Finally, the \ann experimental results are presented and compared to
standard statistical techniques.
Indoor temperature forecasting is an interesting problem which has been widely
studied in the literature, for example,
in~\cite{2008:EandB:Neto,Ferreira,Alvarez,2012:EandB:olderwurtel,2013:ESA:Mateo}. We
focus this work in multivariate forecasting using different
weather indicators as input features. In addition, two combinations of forecast models have been
compared.

In the conclusion, it is studied how the predicted results are integrated with the energy consumption parameters and comfort levels of the \smlsystem.

\section{\smlhouse and \smlsystem Environment Setup}

The Small Medium Large House (\smlhouse) and \smlsystem solar houses (more info about both projects can be found here: http://sdeurope.uch.ceu.es/)
have been built to participate in the Solar Decathlon 2010 and 2012 \cite{solar}, respectively, and aim to serve as prototypes for improving energy efficiency.
The competition focus on reproducing the normal behavior of the inhabitants of a house, requiring competitors to maintain comfortable conditions inside the house---to maintain temperature, CO and humidity within a range, performing common tasks like using the oven cooking, watching television (TV), shower, {\it etc.}, while using as little electrical power as possible.

As stated in reference
\cite{DBLP:conf/infocom/PanYWXPPW12}, due to thermal inertia, it is more efficient to maintain a temperature of a room or building than cooling/heating it. Therefore, predicting indoor temperature in
the \smlsystem could reduce HVAC system consumption
using future values of temperature, and then deciding whether to activate the
heat pump or not to maintain the current temperature, regardless of its present value. To build an indoor temperature prediction module, a minimum of several weeks of sensing data are needed. Hence, the prediction module was trained using historical sensing data from the \smlhouse, 2010, in order to be applied in the \smlsystem.

The \smlhouse monitoring database is large enough to estimate forecasting models, therefore its database has been used to tune and analyze forecasting methods for
indoor temperature, and to show how they could be improved using different sensing data as
covariates for the models. This training data was used for the \smlsystem prediction
module.

The \smlsystem is a modular house built basically using wood. It was designed to
be an energy self-sufficient house, using passive strategies and water heating
systems to reduce the amount of electrical power needed to operate the house.

The energy supply of the \smlsystem is divided into solar power generation
and a domestic hot water (DHW) system. The photovoltaic solar system is responsible
for generating electric power by using twenty-one solar panels.
These panels are installed on the roof and at the east and west facades.
\linebreak The energy generated by this system is managed by a device to inject energy into the house,
or in case there is an excess of power, to the grid or a battery system.
The thermal power generation is performed using a solar panel that produces
DHW for electric energy savings.

The energy demand of the \smlsystem house is divided into three main groups: HVAC,
house appliances and lighting and home electronics (HE). The HVAC
system consists of a heat pump, \linebreak which is capable of heating or cooling water, in addition to a
rejector fan. Water pipes are installed inside the house, and a fan coil system distributes
the heat/cold using ventilation.
As shown in reference \cite{eebuildings}, \linebreak the HVAC system is the main contributor to
residential energy consumption, using  of total power in U.S. households or  of total power in European residential buildings.
In the \smlsystem,  \linebreak the HVAC had a peak consumption of up to  kW
when the heat pump was activated and, as shown in Table~\ref{tab:consumption},
it was the highest power consumption element of the \smlsystem in the contest
with  of total consumption. This is consistent with data from studies mentioned
 as the competition was held in Madrid (Spain) at the end of September.
The house has several energy-efficient appliances that are
used during the competition. Among them, there is a washing machine,
refrigerator with freezer, an induction hob/vitroceramic and a conventional oven.
Regarding the consumption of the washing machine and dishwasher,
they can reduce the \smlsystem energy demand due to the DHW system.
\linebreak The DHW system is capable of heating water to high temperatures. Then, when water
enters into these appliances, the resistor must be activated for a short time only to reach
the desired temperature. \linebreak The last energy-demanding group consists of several electrical outlets
(e.g., TV, computer, Internet router and others).

\begin{table}[H] \footnotesize \centering
 \begin{tabular}{cccc}
 \toprule
	{\bf System} & {\bf Power peak (kW)} & {\bf Total power (Wh)} & {\bf Percentage} \\
	 \midrule
 HVAC &  &  &  \\ 

 Home appliances & - & 	&  \\

 Lighting \& HE &  &  &  \\
 \bottomrule 
 \end{tabular}
 \caption{Energy consumption per subsystem. HVAC: heating, ventilation and air conditioning; HE: home electronics.\label{tab:consumption}}
\end{table}




Although the energy consumption of the house could be improved, the installed
systems let the \smlsystem house be a near-zero energy building, producing
almost all the energy at the time the inhabitants need it. This performance won the second place at the energy balance contest of the Solar Decathlon
competition. The classification of the Energy Balance contest can be found
 here: http://monitoring.sdeurope.org/index.php?action=scoring\&scoring=S4~.



A sensor and control framework shown in Figure~\ref{fig:plano_sensores}
has been used in the \smlsystem. It is operated by a Master Control
Server (\mcs) and the European home automation standard protocol
known as Konnex (\knx) (neither KNX nor Konnex are acronyms: http://ask.aboutknx.com/questions/430/abbreviation-knx)
 has been chosen for monitoring and sensing.
\knx modules are grouped by functionality: analog or binary inputs/outputs,
gateways between transmission media, weather stations, CO detectors, {\it etc}.
The whole system provides  sensor values and  actuators.
In the proposed system, the immediate execution actions had been programmed to
operate without the involvement of the \mcs, such as controlling ventilation,
the HVAC system and the DHW system. Beyond this basic level, the \mcs
can read the status of sensors and actuators at any time and can
perform actions on them via an Ethernet gateway.

\begin{figure}[H]
 \centering
 \includegraphics[width=0.8\textwidth]{figures/plano_sensores}
 \caption{\smlsystem sensors and actuators map.\label{fig:plano_sensores}}
\end{figure}


A monitoring and control software was developed following a three-layered scheme.
In the first layer, data is acquired from the \knx bus using a \knx-IP (Internet Protocol) bridge device.
The Open Home Automation Bus  (\openhab)~\cite{openhab} software performs
the communication between \knx and our software.
In the second layer, it is possible to find a data persistence module that
has been developed to collect the values offered by \openhab with a
sampling period of 60 s. Finally, the third layer is
composed of different software applications that are able to
intercommunicate: a mobile application has been developed to let the
user watch and control the current state of domotic devices;
and different intelligence modules are being developed also, for instance,
the \ann-based indoor temperature forecasting module.

The energy power generation systems described previously are monitored by a software
controller. It includes multiple measurement sensors, including the voltage and
current measurements of photovoltaic panels and batteries. Furthermore, the
current, voltage and power of the grid is available. The system power
consumption of the house has sensors for measuring power energy values for each
group element. The climate system has power consumption sensors for the whole
system, and specifically for the heat pump. The HVAC system is composed of
several actuators and sensors used for operation. Among them are the inlet and
outlet temperatures of the heat rejector and the inlet and outlet temperatures
of the HVAC water in the \smlsystem. In addition, there are fourteen switches for
internal function valves, for the fan coil system, for the heat pump
and the heat rejector. The DHW system uses a valve and a pump to control water
temperature. Some appliances have temperature sensors which are also monitored.
The lighting system has sixteen binary actuators that can be operated manually by
using the wall-mounted switches or by the \mcs. The \smlsystem has indoor
sensors for temperature, humidity and CO. Outdoor sensors are also
available for lighting measurements, wind speed, rain, irradiance and
temperature.

\section{Time Series Forecasting}\label{sec:forecasting}

Forecasting techniques are useful in terms of energy efficiency, because they
help to develop predictive control systems. This section introduces formal
aspects and forecasting modeling done for this work. Time series are data
series with trend and pattern repetition through time. They can be formalized as
a sequence of scalars from a variable , obtained as the output of the observed process:

\vspace {-12pt}

a fragment beginning at position  and ending at position 
will be denoted by .

Time series forecasting could be grouped as \emph{univariate forecasting} when
the system forecasts variable  using only past values of , and
\emph{multivariate forecasting} when the system forecasts variable  using
past values of  plus additional values of other variables. Multivariate
approaches could perform better than univariate when additional variables cause
variations on the predicted variable , as is shown in the experimental section.

Forecasting models are estimated given different parameters: the number of past
values, the size of the future window, and the position in the future of the
prediction (future horizon). Depending on the size of the future window and how it
is produced~\cite{2012:JESA:taieb}, forecasting approaches are denoted as: \linebreak 
\emph{single-step-ahead forecasting} if the model forecasts only the next time
step; \emph{multi-step-ahead iterative forecasting} if the model forecasts only
the next time step, producing longer windows by an iterative process; and
\emph{multi-step-ahead direct forecasting}~\cite{Cheng_Tan_Gao_Scripps_2006} if
the model forecasts in one step a large future window of size . Following
this last approach, two different major model types exist:

\begin{itemize}
\item \emph{Pure direct}, which uses  forecasting models, one for each
 possible future horizon.
\vspace {-9pt}
\item \emph{Multiple input multiple output} (MIMO), which uses one model to
 compute the full  future window. This approach has several advantages due to the joint learning of inputs and outputs, which allows the model to learn
 the stochastic dependency between predicted values. Discriminative models, as
 \anns, profit greatly from this
 input/output mapping. Additionally, \anns are able to learn non-linear
 dependencies.
\end{itemize}

\subsection{Forecast Model Formalization}\label{sec:forecastmodel}

A forecast model could be formalized as a function , which receives as inputs
the interest variable () with its past values until current time  and a
number  of covariates (), also with its
past values, until current time  and produces a future window of size 
for the given  variable:

\vspace {-9pt}


 being the  past values of
variable/covariate .



The number of past values  is important to ensure good performance of the
model, however, it is not easy to estimate this number exactly. In this work, it
is proposed to estimate models for several values of  and use the model
that achieves better performance, denoted as \best. It is known in the machine learning community that ensemble methods achieve better
generalization~\cite{1991:neuralcomputing:jacobs,2006:icaisc:raudys,Yu20082623}.
Several possibilities could be found in the literature, such as vote combination,
linear combination (for which a special case is the uniform or mean combination),
or in a more complicated way, modular neural networks~\cite{1994:nn:Happel}.
Hence, it is also proposed to combine the outputs of all estimated models for each different
value of , following a linear combination scheme (the linear combination is also known as ensemble averaging),
which is a simple, but effective method of combination, greatly extended to the machine
learning community. Its major benefit is the reduction of overfitting problems
and therefore, it could achieve better performance than a unique \ann.
The quality of the combination depends on the correlation of the \anns,
theoretically, as the more decorrelated the models are, the better the
combination is. In this way, different input size
 \anns were combined, with the expectation that they will be less correlated between themselves than other kinds of combinations, as modifying hidden layer size or other hyper-parameters.

A linear combination of forecasts models, given a set  of  forecast models, \linebreak with the same future window size (), follows this equation:

\vspace {-6pt}


where  is the combination weight given to the model
; and  is its corresponding  function, as
described in Section~\ref{sec:forecastmodel}. The weights are constrained to sum
one, . This formulation allows one to combine forecast
models with different input window sizes for each covariate, but all of them
using the same covariate inputs. Each weight  will be estimated
following two approaches:

\begin{itemize}
\item Uniform linear combination:  for . Models following this approach will be denoted as \combeq. 


\vspace {-6pt}
\item Exponential linear combination (softmax):

 
for ,  being an inverted loss-function (error function) value for the
model , given the dataset . It will be computed using a
validation dataset. In this paper, the loss-function will be the mean absolute error
(MAE), defined in Section~\ref{sec:evalmeasures}, because it is more robust on
outlier errors than other quadratic error measures. This approach will be
denoted as~\comb.
\end{itemize}

\subsection{Evaluation Measures}\label{sec:evalmeasures}

The performance of forecasting methods over one time series could be assessed by
several different evaluation functions, which measure the empirical error of the
model. In this work, for a deep analysis of the results, three different error
functions are used: MAE, root mean square error (RMSE)
and symmetric mean absolute percentage of error (SMAPE). The error is computed
comparing target values for the time series , and its corresponding time series prediction , using the model :

\vspace {-12pt}


The results could be measured over all time series in a given dataset  as:
\vspace {-3pt}

 being the size of the
dataset and , the loss-function defining MAE, RMSE, and SMAPE.

\subsection{Forecasting Data Description}


One aim of this work is to compare different statistical methods to forecast
indoor temperature given previous indoor temperature values. The correlation
between different weather signals and indoor temperature will also be analyzed.

In our database, time series are measured with a sampling period of 
min. However, in order to compute better forecasting models,
each time series is sub-sampled with a period of  min, computing the mean of
the last  values (for each hour, this mean is computed at 0 min, 15
min, 30 min and 45 min). The output of this preprocessing is the
data series , where:

\vspace {-6pt}



\vspace {6pt}

One time feature and five sensor signals were taken into consideration:

\begin{itemize}
\item Indoor temperature in degrees Celsius, denoted by variable . This
 is the interesting \linebreak forecasted variable.
\vspace {-9pt}
\item Hour feature in Universal Time Coordinated (UTC), extracted from the
 time-stamp of each pattern, denoted by variable . The hour of the day is
 important for estimating the Sun's position.
\vspace {-9pt}
\item Sun irradiance in , denoted by variable
 . It is correlated with temperature, because more irradiance will mean
 more heat.
\vspace {-9pt}
\item Indoor relative humidity percentage, denoted by variable . The humidity
 modifies the inertia of the temperature.
\vspace {-9pt}
\item Indoor air quality in CO ppm (parts per million), denoted by variable
 . The air quality is related to the number of persons in the house, and a
 higher number of persons means an increase in temperature.
\vspace {-9pt}
\item Raining Boolean status, denoted by variable . The result of
 sub-sampling this variable is the proportion of minutes in sub-sampling period
 , where raining sensor was activated with \verb+True+.
\end{itemize}

To evaluate the forecasting models' performance, three partitions of our dataset
were prepared: \linebreak a \emph{training partition} composed of  time series over 
days---the model parameters are estimated to reduce the error in this data;
a \emph{validation partition} composed of  time series over seven days---this is
needed to avoid over-fitting during training, and also to compare and study the
models between themselves; training and validation were performed in March 2011; a \emph{test partition} composed of \linebreak  time series over seven days in June 2011. At the end, the forecasting error in this partition will be provided,
evaluating the generalization ability of this methodology. The validation partition
is sequential with the training partition. The test partition is one week ahead of
the last validation point.

\section{Forecasting Methods}
\vspace {-12pt}
\subsection{Standard Statistical Methods}

Exponential smoothing and auto-regressive integrated moving average models
(ARIMA) are the two most widely-used methods for time series forecasting. These
methods provide complementary approaches to the time series forecasting
problems. Therefore, exponential smoothing models are based on a description of trend
and seasonality in the data, while ARIMA models aim to describe its
autocorrelations. Their results have been considered as a reference to compare to the
\ann results.

On the one hand, exponential smoothing methods are applied for forecasting. These
methods were originally classified by~\cite{1969:journal:pegels} according to
their taxonomy. This was later extended by~\cite{1985:journal:gardner}, \linebreak modified
by~\cite{2002:journal:hyndman} and extended by~\cite{2003:journal:taylor},
giving a total of fifteen methods. These methods could have different behavior
depending on their error component [\emph{A} (additive) and \textit{M} (multiplicative)],
trend component [\emph{N} (none), \textit{A} (additive), \textit{Ad} (additive damped),
 \textit{M} (multiplicative) and \textit{Md} (multiplicative damped)] and seasonal component
[\emph{N} (none), \textit{A} (additive) and \textit{M} (multiplicative)]. To select the best-fitting
models within this framework, each possible model was estimated for the training
partition, and the two best models were selected. To carry out this selection,
Akaike's Information Criterion (AIC) was used as suggested by some works in the
literature \cite{Billah2006239,snyder2009exponential}. The selected models were:
\linebreak the first model with multiplicative error, multiplicative damped trend and without
the seasonal component (MMdN model), and the second model with additive error, additive
damped trend and without the seasonal component (AAdN model). The MMdN model was
chosen for the validation partition in order to minimize the MSE.

On the other hand, ARIMA models were estimated. The widely known ARIMA approach was first introduced by Box and Jenkins \cite{Box.Jenkins1976} and provides
a comprehensive set of tools for univariate time series modeling and forecasting.
These models were estimated for our data with and without covariates.
\linebreak The last value of variable hour (), codified as a factor---using 24 categories (0 to 23), ---and the hour as a continuous variable were used as covariates.

Either linear and quadratic form of this quantity were used, but linear performs
worst. Therefore, three model groups are used: ARIMA without covariates (ARIMA), with
covariate  as a factor (ARIMAF) and with covariate  as a quadratic
form (ARIMAQ). The best models for each group were estimated for the training
partition, and in all cases, the non-seasonal ARIMA(2,1,0) model was selected for
the ARIMA part of each model using AIC. The best results, in terms of MSE,
were obtained in models with covariate time as a factor and covariate time as a
quadratic form.

The forecast library in the statistical package R~\cite{Rcommander} was used for
these analyses.

\subsection{ANNs}

Estimation of \ann forecast models needs data preprocessing and normalization of
input/output values in order to ensure better performance results.

\subsubsection{Preprocessing of Time Series for ANNs}

The indoor temperature variable () is the interesting forecasted variable. In
order to increase model generalization, this variable is differentiated, and a
new  signal sequence is obtained following
this equation:

\vspace {-9pt}


The differentiation of indoor temperature shows that is important to
achieve good generalization results, and it is based on previous work where undifferentiated data has been used~\cite{2012:kdir:zamora}.

The time series corresponding to sun irradiance (), indoor relative
humidity (), \linebreak air quality () and rain () are normalized,
subtracting the mean and dividing by the standard deviation, computing new signal
sequences, :


\vspace {-6 pt}

\noindent where  is the mean value of the sequence;
 and  is the standard
deviation. \linebreak These two parameters may be computed over the training dataset. For
the hour component (), a different approach is followed. It is represented
as a locally-encoded category, which consists of using a vector with 
components, where  components are set to 0, and the component that
indicates the hour value is set to 1. This kind of encoding avoids the big
jump between 23 and 0 at midnight, \linebreak but forces the model to learn the
relationship between adjacent hours. Other approaches for hour encoding could be
done in future work.

\subsubsection{ANN Description}

\anns has an impressive ability to learn complex mapping functions, as they are universal function approximators~\cite{bishop:95} and are widely used in
forecasting~\cite{Zhang199835,2006:energyandbuildings:ruano,Yu20082623,2011:energyandbuildings:escriva}.

\anns are formed by one input layer, an output layer, and a few numbers of hidden
layers. Figure~\ref{fig:nn} is a schematic representation of an \ann with
two hidden layers for time series forecasting.
The inputs of the \ann are past values of covariates, and the output layer is formed
by the  future window predicted values, following the MIMO approach described
in Section~\ref{sec:forecasting}, which has obtained better accuracy in previous
experimentation~\cite{2012:kdir:zamora}.

\begin{figure}[H]
 \centering
 \includegraphics[width=0.5\columnwidth]{figures/nn}
 \caption{Artificial neural network (ANN) topology for time series forecasting.\label{fig:nn}}
\end{figure}


The well-known error-backpropagation (BP)
algorithm~\cite{1988:nature:rumelhart} has been used in its on-line version to estimate the \ann weights, adding a momentum term and an L2
regularization term (weight decay).
Despite that theoretically algorithms more advanced than BP exists nowadays, BP is easier to implement at the empirical level, and a correct adjustment of
momentum and weight decay helps to avoid bad local minima.
The BP minimizes the mean
square error (MSE) function with the addition of the regularization term weight
decay, denoted by , useful for avoiding over-fitting and improving
generalization:
\vspace {-3pt}

\vspace {6pt}
\noindent where  is a set of all weights of
the \ann (without the bias); and  is the value of the -th weight.
\vspace {-6pt}

\section{Experimental Results}

Using the data acquired during the normal functioning of the house, experiments were
performed to obtain the best forecasting model for indoor
temperature. First, an exhaustive search of model hyper-parameters was done for each
covariate combination. Second, different models were trained for different
values of past size for indoor temperature , and a comparison among
different covariate combinations and \ann \textit{vs}. standard statistical methods has
been performed. A comparison of a combination of forecasting models has also been performed. In all cases, the future window size  was set to ,
corresponding to a three-hour forecast.

A grid search exploration was done to set the best hyper-parameters of the system
and \ann topology, fixing covariates  to a past size,  and , searching  \linebreak combinations of:
\vspace {-3 pt}

\begin{itemize}
\item different covariates of the model input;
\vspace {-9pt}
\item different values for \ann hidden layer sizes;
\vspace {-9pt}
\item learning rate, momentum term and weight decay values.
\end{itemize}
\vspace {-3 pt}

Table~\ref{tab:modelparams} shows the best model parameters found by this grid
search. For illustrative purposes, Figures~\ref{fig:dhnumh1}~and~\ref{fig:dhnumh2} show box-and-whisker plots of the hyper-parameter grid
search performed to optimize the \ann model, . They show big differences between one-
and two-hidden layer \anns, two-layered \anns being more difficult to train for this particular model. The learning rate shows a big impact in
performance, while momentum and weight decay seems to be less important. This
grid search was repeated for all the tested covariate combinations, and the
hyper-parameters that optimize MAE were selected in the rest of the
paper.

\begin{table}[H]
 \footnotesize \centering
 \begin{tabular}{cccccccc}
\toprule
 {\bf Covariates} & {\boldmath } & {\boldmath } & {\boldmath } & {\bf Hidden layers}\\
 \midrule
    &  &  &  &  tanh-- tanh\\
    &  &  &  &  tanh-- tanh\\
    &  &  &  &{ tanh}\\
    &  &  &  &  tanh-- tanh\\
    &  &  &  &{ tanh}\\
    &  &  &  &  logistic-- logistic\\
    &  &  &  &{ logistic}\\
   &  &  &  &{ tanh}\\
   &  &  &  &  logistic-- logistic\\
   &  &  &  &  tanh-- tanh\\
  &  &  &  &  tanh-- tanh\\
\bottomrule 
 \end{tabular}
 \normalsize
 \caption{Training parameters depending on the input covariates combination
 ( is the learning rate,  is the momentum term, and  is weight
 decay).}\label{tab:modelparams}
\end{table}

\begin{figure}[H]
 \begin{center}
 \includegraphics[width=0.7\textwidth]{graficas/plot-box-nh1.pdf}
 \end{center}
 \caption{Mean absolute error
(MAE) box-and-whisker plots for \anns with one hidden layer and
 the hyper-parameters of the grid search performed to optimize the \ann model,
 .  The x-axis of the learning rate, momentum and weight decay are
 log-scaled.}
\label{fig:dhnumh1}
\end{figure}
\vspace {-18 pt}
\begin{figure}[H]
 \begin{center}
 \includegraphics[width=0.7\textwidth]{graficas/plot-box-nh2.pdf}
 \end{center}
 \caption{MAE box-and-whisker plots for \anns with two hidden layers
 and the \protect\linebreak hyper-parameters of the grid search performed to optimize the \ann
 model, . \protect\linebreak The x-axis of the learning rate, momentum and weight decay are
 log-scaled.}\label{fig:dhnumh2}
\end{figure}


\newpage

\subsection{Covariate Analysis and Comparison between Different Forecasting Strategies}

For each covariate combination, and using the best model parameters obtained
previously, different model comparison has been performed. Note
that the input past size of covariates is set to \linebreak = 5 time
steps, that is,  min, and to . For forecasted variable ,
models with sizes  were trained.

A comparison between \best, \combeq and \comb approaches was performed and
shown in Table~\ref{tab:valresults}. Figure~\ref{fig:val-smape} plots the same
results for a better confidence interval comparison. Table~\ref{tab:combs} shows
\combeq weights used in experimentation, obtained following
Equation~\ref{eq:comb} and using MAE as the \linebreak loss-function. From all these
results, the superiority of \anns \textit{vs}. standard statistical methods is clear,
with clear statistical significance and with a confidence greater than . Different
covariate combinations for \ann models show that the indoor temperature
correlates well with the hour () and sun irradiance (), and the combination
of these two covariates () improves the model in a significant way (
confidence) with input . The addition of more covariates is slightly
better in two cases ( and ), but the differences are not
important. With only the hour and sun irradiance, the \ann model has enough
information to perform good forecasting. Regarding the combination of models,
in some cases, the \comb approach obtains consistently better results than
\combeq and \best, but the differences are not important.

A deeper analysis could be done if comparing the SMAPE values for each possible
future horizon, as Figure~\ref{fig:val-180} shows. A clear trend exists: error
increases with the enlargement of the future horizon. Furthermore, an enlargement of
the confidence interval is observed with the enlargement of the future horizon. In all
cases, \ann models outperform statistical methods. For shorter horizons (less than or
equal to  min), the differences between all \ann models are
insignificant. For longer horizons (greater than  min), a combination of
covariates  achieve a significant result (for a confidence of )
compared with the  combination. As was shown in these results, the addition
of covariates is useful when the future horizon increases, probably because the
impact of covariates into indoor temperature becomes stronger over time.

Finally, to compare the generalization abilities of the proposed best models, the error
measures for the test partition are shown in Table~\ref{tab:testresults} and
Figure~\ref{fig:test-smape}. All error measures show better
performance in the test partition, even when this partition is two weeks ahead of
training and contains hotter days than the training and validation partitions. The reason for
this better performance might be that the test series has increasing/decreasing
temperature cycles that are more similar to the training partition than the cycles in the validation partition. The
differences between models are similar, and the most significant combination of
covariates is time hour and sun irradiance () following the \comb
strategy, achieving a SMAPE, MAE,
and RMSE.

\begin{table} [H]
\scriptsize \centering

 \begin{tabular}{cccccccccc}
 \toprule
 \bf {Model} & \multicolumn{3}{c}{\bf {SMAPE}} & \multicolumn{3}{c}{\bf {MAE}} & \multicolumn{3}{c}{\bf {RMSE}}\\
 \midrule
 \multicolumn{10}{c}{Standard statistical models}\\
 \hline
 ARIMA-   &  &  &  &  &  &  &  &  & \\
 ARIMAQ-   &  &  &  &  &  &  &  &  & \\
 ARIMAF-   &  &  &  &  &  &  &  &  & \\
 ETS-   &  &  &  &  &  &  &  &  & \\
\hline
 \multicolumn{10}{c}{\ann models}\\
 \hline
 BEST-   &  &  &  &  &  &  &  &  & \\
 CEQ-   &  &  &  &  &  &  &  &  & \\
 CEXP-   &  &  &  &  &  &  &  &  & \\
 \hline
 BEST-   &  &  &  &  &  &  &  &  & \\
 CEQ-   &  &  &  &  &  &  &  &  & \\
 CEXP-   &  &  &  &  &  &  &  &  & \\
 \hline
 BEST-   &  &  &  &  &  &  &  &  & \\
 CEQ-   &  &  &  &  &  &  &  &  & \\
 CEXP-   &  &  &  &  &  &  &  &  & \\
 \hline
 BEST-  &  &  &  &  &  &  &  &  & \\
 CEQ-   &  &  &  &  &  &  &  &  & \\
 \rowcolor{lightgray}
 CEXP-  &  &  &  &  &  &  &  &  & \\
 \hline
 BEST-  &  &  &  &  &  &  &  &  & \\
 CEQ-   &  &  &  &  &  &  &  &  & \\
 CEXP-  &  &  &  &  &  &  &  &  & \\
 \hline
 BEST-  &  &  &  &  &  &  &  &  & \\
 CEQ-   &  &  &  &  &  &  &  &  & \\
 CEXP-  &  &  &  &  &  &  &  &  & \\
 \hline
 BEST-  &  &  &  &  &  &  &  &  & \\
 CEQ-   &  &  &  &  &  &  &  &  & \\
 CEXP-  &  &  &  &  &  &  &  &  & \\
 \hline
 BEST-  &  &  &  &  &  &  &  &  & \\
 CEQ-  &  &  &  &  &  &  &  &  & \\
 CEXP-  &  &  &  &  &  &  &  &  & \\
 \hline
 BEST-  &  &  &  &  &  &  &  &  & \\
 CEQ-  &  &  &  &  &  &  &  &  & \\
 CEXP-  &  &  &  &  &  &  &  &  & \\
 \hline
 BEST-  &  &  &  &  &  &  &  &  & \\
 CEQ-  &  &  &  &  &  &  &  &  & \\
 CEXP-  &  &  &  &  &  &  &  &  & \\
 \hline
 BEST- &  &  &  &  &  &  &  &  & \\
 CEQ- &  &  &  &  &  &  &  &  & \\
 CEXP- &  &  &  &  &  &  &  &  & \\
 \bottomrule 
 \end{tabular}
 \normalsize
 \caption{Symmetric mean absolute percentage of error (SMAPE), MAE and root mean square error (RMSE) results on the validation
 partition comparing different models, input features and combination schemes
 with the  confidence interval. BEST refers to the best past size \ann,
 CEQ refers to \combeq \anns, and CEXP refers to \comb \anns. Bolded face
 numbers are the best results, and the gray marked row is the most significant
 combination of covariates. ARIMA: auto-regressive integrated moving average models; ARIMAQ: ARIMA with covariate  as a quadratic
form (ARIMAQ); ARIMAF: ARIMA with covariate  as a factor.}
\label{tab:valresults}
\end{table}

\begin{figure}[H]
 \centering
 \includegraphics[width=0.7\textwidth]{graficas/grafica-SMAPE}\\
 \caption{SMAPE error plot with  confidence interval for models
 of Table~\ref{tab:valresults} on the validation partition.\label{fig:val-smape}}
\end{figure}

\begin{table}[H]
\scriptsize \centering
 \begin{tabular}{cccccccccccc}
 \toprule
 &\multicolumn{11}{c}{{\bf \comb combination weights for every  variable input size (min)}}\\ \cline{2-12}
\raisebox{2ex}[0pt]{{\bf Input covariates}} &  &  &  &  &  &  &  &  &  &  & \\
 \midrule
    &  &  &  &  &  &  &  &  &  &  &  \\
\hline
    &  &  &  &  &  &  &  &  &  &  &  \\
\hline
    &  &  &  &  &  &  &  &  &  &  &  \\
\hline
    &  &  &  &  &  &  &  &  &  &  &  \\
\hline
    &  &  &  &  &  &  &  &  &  &  &  \\
\hline
    &  &  &  &  &  &  &  &  &  &  &  \\
\hline
    &  &  &  &  &  &  &  &  &  &  &  \\
\hline
   &  &  &  &  &  &  &  &  &  &  &  \\
\hline
   &  &  &  &  &  &  &  &  &  &  &  \\
\hline
   &  &  &  &  &  &  &  &  &  &  &  \\
\hline
  &  &  &  &  &  &  &  &  &  &  &  \\
 \bottomrule 
 \end{tabular}
 \normalsize
 \caption{Combination weights of every input size of  for the \comb models
 given tested covariates combinations. All co-variables have an input size of
  ( min). \protect\linebreak Bold numbers are the best input sizes.}
\label{tab:combs}
\end{table}

\begin{figure}[H]
 \centering
 \includegraphics[width=0.95\textwidth]{graficas/grafica}\\
 \caption{SMAPE error plot with  confidence interval of each of
 the  future horizon predicted values (from 15 min forecast to 180
 min forecast.)\label{fig:val-180}}
\end{figure}

\begin{table}[H]
 \scriptsize \centering

 \begin{tabular}{ccccccccccc}
 \toprule
 {\bf Model} & \multicolumn{3}{c}{{\bf SMAPE}} & \multicolumn{3}{c}{{\bf MAE}} & \multicolumn{3}{c}{{\bf RMSE}}\\
 \midrule
 ETS-d &  &  &  &  &  &  &  &  & \\
 \hline
 BEST-   &  &  &  &  &  &  &  &  & \\
 CEQ-   &  &  &  &  &  &  &  &  & \\
 CEXP-   &  &  &  &  &  &  &  &  & \\
 \hline
 BEST-  &  &  &  &  &  &  &  &  & \\
 CEQ-   &  &  &  &  &  &  &  &  & \\
 \rowcolor{lightgray}
 CEXP-  &  &  &  &  &  &  &  &  & \\
 \hline
 BEST-  &  &  &  &  &  &  &  &  & \\
 CEQ-  &  &  &  &  &  &  &  &  & \\
 CEXP-  &  &  &  &  &  &  &  &  & \\
 \hline
 BEST-  &  &  &  &  &  &  &  &  & \\
 CEQ-  &  &  &  &  &  &  &  &  & \\
 CEXP-  &  &  &  &  &  &  &  &  & \\
 \hline
 BEST- &  &  &  &  &  &  &  &  & \\
 CEQ- &  &  &  &  &  &  &  &  & \\
 CEXP- &  &  &  &  &  &  &  &  & \\
 \bottomrule
 \end{tabular}

 \normalsize
 \caption{SMAPE, MAE and RMSE results on test partition
 comparing the best models with the  confidence interval. Bolded face
 numbers are the best results, and the gray marked row is the most significant
 combination of covariates.}\label{tab:testresults}
\end{table}

\vspace {-9 pt}

\begin{figure}[H]
 \centering
 \includegraphics[width=0.6\textwidth]{graficas/grafica-SMAPE-TEST}\\
 \caption{SMAPE error plot with the  confidence interval for the models
 of Table~\ref{tab:testresults} in the test partition.\label{fig:test-smape}}
\end{figure}

In order to perform a better evaluation, the conclusions above are compared with
mutual information (MI), shown in Table~\ref{tab:MI}. Probability densities have
been estimated with histograms, making the assumption of independence between
time points, which is not true for time series~\cite{2009:arxiv:papana}, but
is enough for our contrasting purpose. The behavior of the \anns is similar to the MI
study. Sun irradiance () covariates show high MI with indoor temperature
(), which is consistent with our results. Humidity () and air quality ()
MI with indoor temperature () is higher than sun irradiance, which seems
contradictory with our expectations. However, if we compute MI only during the day
(removing the night data points), the sun irradiance shows higher MI with indoor
temperature than other covariates. Regarding the hour covariate, it shows lower
MI than expected, probably due to the cyclical shape of the hour, which breaks abruptly
with the jump between 23 and 0, affecting the computation of histograms.

\begin{table}[H]
 \footnotesize \centering
 \begin{tabular}{cccccccc}
 \toprule
  {\bf Data}& {\bf Algorithm}& {\boldmath } & {\boldmath } & {\boldmath } & {\boldmath } & {\boldmath } & {\boldmath }\\ \midrule
 & MI (for ) &  &  &  &  &  & \\
\cline {2-8}
 \raisebox{1.5ex}[0pt] {Validation set}&Normalized MI (for ) &  &  &  &  &  & \\
 \hline
 Validation set,  &MI (for ) &  &  &  &  &  & \\
\cline {2-8}
 removing night data points & Normalized MI (for ) &  &  &  &  &  & \\
 \bottomrule
 \end{tabular}
 \caption{Mutual Information (MI) and normalized MI between
 considered covariates and the indoor temperature, for the validation
 set.}\label{tab:MI}
\end{table}

\section{Conclusions}

An overview of the monitoring and sensing system developed for the \smlsystem
solar powered house has been described. This system was employed during the participation at the Solar Decathlon Europe 2012 competition. The research in
this paper has been focused on how to predict the indoor temperature of a house,
as this is directly related to HVAC system consumption. HVAC systems represent
 of the overall power consumption of the \smlsystem house. Furthermore,
performing a preliminary exploration of the \smlsystem competition data, the energy
used to maintain temperature was found to be -- of the energy needed
to lower it. Therefore, an accurate forecasting of indoor temperature could
yield an energy-efficient control.

An analysis of time series forecasting methods for prediction of indoor
temperature has been performed. A multivariate approach was followed, showing
encouraging results by using \ann models. Several combinations of covariates,
forecasting model combinations, comparison with standard statistical methods
and a study of covariate MI has been performed. Significant improvements were
found by combining indoor temperature with the hour categorical variable and sun
irradiance, achieving a MAE degrees Celsius (SMAPE). The addition of more covariates different from hour and sun
irradiance slightly improves the results. The MI study shows that humidity and
air quality share important information with indoor temperature, but probably,
the addition of these covariates does not add different information from which is indicated by hour and sun irradiance. The combination of \ann models
following the softmax approach (\comb) produce consistently better forecasts,
but the differences are not important. The data available for this study was
restricted to one month and a week of a Southern Europe house. It might be interesting to
perform experiments using several months of data in other houses, as weather
conditions may vary among seasons and locations.

As future work, different techniques for the combination of forecasting models
could be performed. \linebreak A deeper MI study to understand the relationship
between covariates better would also be interesting. The use of second order methods to
train the \ann needs to be studied. In this work, for the \ann models, the hour
covariate is encoded using 24 neurons; other encoding methods will be studied, for example, using splines, sinusoidal functions or a neuron with
values between 0 and 23.

Following these results, it is intended to design a
predictive control based on the data acquired \linebreak from \anns, for example, from
this one that is devoted to calculating the indoor temperature, extrapolating this
methodology to other energy subsystems that can be found in a home.

\acknowledgements{Acknowledgments}

This work has been supported by Banco Santander and CEU Cardenal Herrera University 
through the project Santander-PRCEU-UCH07/12.

\conflictofinterests{Conflicts of Interest}

The authors declared not conflict of interest.

\bibliographystyle{mdpi}
\makeatletter
\renewcommand\@biblabel[1]{#1. }
\makeatother


\begin{thebibliography}{----}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Instituto para la diversificaci\'on y ahorro de la energ\'ia
 (IDAE)}(2011)]{IDAE}
{\em {Practical Guide to Energy. Efficient and Responsible
 Consumption}}; \newblock {Instituto para la Diversificaci\'on y Ahorro de la Energ\'ia (IDAE): Madrid, Spain},
\newblock 2011.

\bibitem[Ferreira \em{et~al.}(2012)Ferreira, Ruano, Silva, and Concei{\c
 c}{\~a}o]{Ferreira}
Ferreira, P.; Ruano, A.; Silva, S.; Concei{\c c}{\~a}o, E.
\newblock Neural networks based predictive control for thermal comfort and
 energy savings in public buildings.
\newblock {\em Energy Build.} {\bf 2012}, {\em 55},~238--251.

\bibitem[{\'A}lvarez \em{et~al.}(2012){\'A}lvarez, Redondo, Camponogara,
 Normey-Rico, Berenguel, and Ortigosa]{Alvarez}
{\'A}lvarez, J.D.; Redondo, J.L.; Camponogara, E.; Normey-Rico, J.; Berenguel, M.;
 Ortigosa, P.M.
\newblock Optimizing building comfort temperature regulation via model
 predictive control.
\newblock
\newblock {\em Energy Build.} {\bf 2012}, {\it 57},~361--372.

\bibitem[Arroyo \em{et~al.}(2006)Arroyo, Gea, Garrido, and Haya]{Arroyo}
Arroyo, R.F.; Gea, M.; Garrido, J.L.; Haya, P.A. Dise{\~n}o e Implementaci{\'o}n de
 Tareas Colaborativas en un Entorno de Inteligencia Ambiental para el
Aprendizaje [in Spainish]. 
\newblock In {\em Interacci{\'o}n 2006---Dise{\~n}o de la Interacci{\'o}n
 Persona-Ordenador: Tendencias y Desaf{\'\i}os}; Lince Artes Gr{\'a}ficas: Ciudad Real, Spain,
 2006;
\newblock pp. 97--107.

\bibitem[Sierra \em{et~al.}(2005)Sierra, Hossian, Garc\'ia, and Marino]{Sierra}
Sierra, E.; Hossian, A.; Garc\'ia-Mart\'nez, R.; Marino, P.
\newblock {Expert System for Intelligent Control of Environmental Variables of
 a Energy-Efficient Building}.
\newblock {In Proceedings of XI Workshop in Information Processing and Control, National University of Rio Cuarto, Crdoba Province, Argentina},
\newblock 2005; pp.~446--452.

\bibitem[{United States Department of Energy}(2012)]{solar}
{United States Department of Energy}.
\newblock {Solar Decathlon Europe Competition}, 2012.
\newblock
\newblock {Available online: http://www.solardecathlon.gov (accessed on 20 June 2013)}.

\bibitem[Taormina \em{et~al.}(2012)Taormina, wing Chau, and
 Sethi]{2012:Taormina}
Taormina, R.; Chau, K.W.; Sethi, R.
\newblock Artificial neural network simulation of hourly groundwater levels in
 a coastal aquifer system of the Venice lagoon.
\newblock {\em Eng. Appl. Artif. Intill.} {\bf 2012},
\newblock {\em 25},~\linebreak1670--1676.

\bibitem[Wu \em{et~al.}(2009)Wu, Chau, and Li]{2009:Wu}
Wu, C.L.; Chau, K.W.; Li, Y.S.
\newblock Predicting monthly streamflow using data-driven models coupled with
 data-preprocessing techniques.
\newblock {\em Water Resour. Res.} {\bf 2009},
\newblock {\em 45}, W08432, doi: 10.1029/2007WR006737.

\bibitem[Karatasou \em{et~al.}(2006)Karatasou, Santamouris, and
 Geros]{Karatasou}
Karatasou, S.; Santamouris, M.; Geros, V.
\newblock Modeling and predicting building's energy use with artificial neural
 networks: Methods and results.
\newblock {\em Energy Build.} {\bf 2006},
\newblock {\em 38},~949--958.

\bibitem[Ruano \em{et~al.}(2006)Ruano, Crispim, Concei{\c c}{\~a}o, and
 L{\'u}cio]{2006:energyandbuildings:ruano}
Ruano, A.; Crispim, E.; Concei{\c c}{\~a}o, E.; L{\'u}cio, M.
\newblock Prediction of building's temperature using neural networks models.
\newblock {\em Energy Build.} {\bf 2006},
\newblock {\em 38},~682--694.

\bibitem[Zamora-Mart{\'\i}nez \em{et~al.}(2012)Zamora-Mart{\'\i}nez, Romeu,
 Pardo, and Tormo]{2012:kdir:zamora}
Zamora-Mart{\'\i}nez, F.; Romeu, P.; Pardo, J.; Tormo, D.
\newblock {Some Empirical Evaluations of a Temperature Forecasting Module Based
 on Artificial Neural Networks for a Domotic Home Environment}. In Proceedings of International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management (IC3K)-Knowledge Discovery Information Retrieval (KDIR),
\newblock Barcelona, Spain, 
\newblock 4--7 October 2012; pp. 206--211.

\bibitem[Neto and Fiorelli(2008)]{2008:EandB:Neto}
Neto, A.H.; Fiorelli, F.A.S.
\newblock Comparison between detailed model simulation and artificial neural
 network for forecasting building energy consumption.
\newblock {\em Energy Build.} {\bf 2008},
\newblock {\em 40},~2169--2176.

\bibitem[Oldewurtel \em{et~al.}(2012)Oldewurtel, Parisio, Jones, Gyalistras,
 Gwerder, Stauch, Lehmann, and Morari]{2012:EandB:olderwurtel}
Oldewurtel, F.; Parisio, A.; Jones, C.N.; Gyalistras, D.; Gwerder, M.; Stauch,
 V.; Lehmann, B.; Morari, M.
\newblock Use of model predictive control and weather forecasts for energy
 efficient building climate control.
\newblock {\em Energy Build.} {\bf 2012},
\newblock {\em 45},~15--27.

\bibitem[Mateo \em{et~al.}(2013)Mateo, Carrasco, Sellami, Milln-Giraldo,
 Domnguez, and Soria-Olivas]{2013:ESA:Mateo}
Mateo, F.; Carrasco, J.J.; Sellami, A.; Milln-Giraldo, M.; Domnguez, M.;
 Soria-Olivas, E.
\newblock Machine learning methods to forecast temperature in buildings.
\newblock {\em Expert Syst. Appl.} {\bf 2013},
\newblock {\em 40},~1061--1068.

\bibitem[Pan \em{et~al.}(2012)Pan, Yuan, Wang, Xu, Peng, Peng, and
 Wan]{DBLP:conf/infocom/PanYWXPPW12}
Pan, D.; Yuan, Y.; Wang, D.; Xu, X.; Peng, Y.; Peng, X.; Wan, P.J.
\newblock Thermal Inertia: Towards an Energy Conservation Room Management System.
\newblock In Proceedings of INFOCOM,  2012 IEEE, Orlando, FL, USA, 25--30 March 2012;
\newblock pp. 2606--2610.

\bibitem[{World Business Council for Sustainable
 Development}(2009)]{eebuildings}
{\it Energy Efficiency in Buildings: Transforming the Market}; 
\newblock {World Business Council for Sustainable Development: Geneva, Switzerland},
\newblock 2009.

\bibitem[Kreuzer and Eichst\"adt-Engelen(2011)]{openhab}
Kreuzer, K.; Eichst\"adt-Engelen, T.
\newblock {The OSGI-based Open Home Automation Bus}, 2011.
\newblock
\newblock {Available online: http://www.openhab.org (accessed on 20 June 2013)}.

\bibitem[Ben~Taieb \em{et~al.}(2012)Ben~Taieb, Bontempi, Atiya, and
 Sorjamaa]{2012:JESA:taieb}
Ben~Taieb, S.; Bontempi, G.; Atiya, A.F.; Sorjamaa, A.
\newblock {A review and comparison of strategies for multi-step ahead time
 series forecasting based on the NN5 forecasting competition}.
\newblock {\em Expert Syst. Appl.} {\bf 2012},
\newblock {\em 39},
\newblock ~7067--7083.

\bibitem[Cheng \em{et~al.}(2006)Cheng, Tan, Gao, and
 Scripps]{Cheng_Tan_Gao_Scripps_2006}
Cheng, H.; Tan, P.N.; Gao, J.; Scripps, J.
\newblock Multistep-ahead time series prediction.
\newblock {\em Adv. Knowl. Discov. Data Min.} {\bf 2006},
\newblock {\em 3918},~765--774.

\bibitem[Jacobs \em{et~al.}(1991)Jacobs, Jordan, Nowlan, and
 Hinton]{1991:neuralcomputing:jacobs}
Jacobs, R.A.; Jordan, M.I.; Nowlan, S.J.; Hinton, G.E.
\newblock Adaptive mixtures of local experts.
\newblock {\em Neural~Comput.} {\bf 1991},
\newblock {\em 3},~79--87.

\bibitem[Raudys and Zliobaite(2006)]{2006:icaisc:raudys}
Raudys, .; Zliobaite, I.
\newblock The Multi-Agent System for Prediction of Financial Time Series. \linebreak In Proceedings of the 8th International Conference on Artificial
 Intelligence and Soft \linebreak Computing---ICAISC 2006, Zakopane, Poland, 25--29 June 2006;
\newblock pp. 653--662.

\bibitem[Yu \em{et~al.}(2008)Yu, Wang, and Lai]{Yu20082623}
Yu, L.; Wang, S.; Lai, K.K.
\newblock {Forecasting crude oil price with an EMD-based neural network
 ensemble learning paradigm}.
\newblock {\em {Energy Econ.}} {\bf 2008},
\newblock {\em 30},~2623--2635.

\bibitem[Happel and Murre(1994)]{1994:nn:Happel}
Happel, B.L.; Murre, J.M.J.
\newblock Design and evolution of modular neural network architectures.
\newblock {\em Neural~Netw.} {\bf 1994},
\newblock {\em 7},~985--1004.

\bibitem[Pegels(1969)]{1969:journal:pegels}
Pegels, C.
\newblock Exponential forecasting: Some new variations.
\newblock {\em Manag. Sci.} {\bf 1969},
\newblock {\em 15},~311--315.

\bibitem[Gardner(1985)]{1985:journal:gardner}
Gardner, E.S.
\newblock Exponential smoothing: The state of the art.
\newblock {\em J. Forecast.} {\bf 1985},
\newblock {\em 4},~1--28.

\bibitem[Hyndman \em{et~al.}(2002)Hyndman, Koehler, Snyder, and
 Grose]{2002:journal:hyndman}
Hyndman, R.; Koehler, A.; Snyder, R.; Grose, S.
\newblock A state space framework for automatic forecasting using exponential smoothing methods.
\newblock {\em Int. J. Forecast.} {\bf 2002},
\newblock {\em 18},~439--454.

\bibitem[Taylor(2003)]{2003:journal:taylor}
Taylor, J.
\newblock Exponential smoothing with a damped multiplicative trend.
\newblock {\em Int. J. Forecast.} {\bf 2003},
\newblock {\em 19},~715--725.

\bibitem[Billah \em{et~al.}(2006)Billah, King, Snyder, and
 Koehler]{Billah2006239}
Billah, B.; King, M.L.; Snyder, R.D.; Koehler, A.B.
\newblock Exponential smoothing model selection for~forecasting.
\newblock {\em Int. J. Forecast.} {\bf 2006},
\newblock {\em 22},~239--247.

\bibitem[Snyder and Ord(2009)]{snyder2009exponential}
Snyder, R.D.; Ord, J.
\newblock {\it Exponential Smoothing and the Akaike Information Criterion}; Working Paper 4/09;
\newblock
\newblock {Monash University: Melbourne, Australia, June 2009}.

\bibitem[Box and Jenkins(1976)]{Box.Jenkins1976}
Box, G.E.; Jenkins, G.M.
\newblock {\em Time Series Analysis: Forecasting and Control}; Honden Day: San~Francisco, CA, USA, 
\newblock 1976.

\bibitem[{R Development Core Team}(2005)]{Rcommander}
{ The R Development Core Team}.
\newblock R: A Language and Evironment for Statistical Computing, 2005.
\newblock
\newblock {Available online: http://www.R-project.org (accessed on 20 June 2013)}.

\bibitem[Bishop(1995)]{bishop:95}
Bishop, C.M.
\newblock {\em Neural Networks for Pattern Recognition}; Oxford University
 Press: Oxford, UK,~1995.

\bibitem[Zhang \em{et~al.}(1998)Zhang, Patuwo, and Hu]{Zhang199835}
Zhang, G.; Patuwo, B.E.; Hu, M.Y.
\newblock {Forecasting with artificial neural networks: The state of the art}.
\newblock {\em {Int. J. Forecast.}} {\bf 1998},
\newblock {\em 14},~35--62.

\bibitem[Escriv\'a-Escriv\'a \em{et~al.}(2011)Escriv\'a-Escriv\'a,
 \'Alvarez-Bel, Rold\'an-Blay, and
 Alc\'azar-Ortega]{2011:energyandbuildings:escriva}
Escriv\'a-Escriv\'a, G.; \'Alvarez-Bel, C.; Rold\'an-Blay, C.;
 Alc\'azar-Ortega, M.
\newblock New artificial neural network prediction method for electrical
 consumption forecasting based on building end-uses.
\newblock {\em Energy Build.} {\bf 2011},
\newblock {\em 43},~3112--3119.

\bibitem[Rumelhart \em{et~al.}(1988)Rumelhart, Hinton, and
 Williams]{1988:nature:rumelhart}
Rumelhart, D.E.; Hinton, G.E.; Williams, R.J.
\newblock Learning Representations by Back-Propagating Errors. In {\it Neurocomputing: Foundations of Research};  MIT Press: Cambridge, MA, USA, 1988;
\newblock pp.  696--699.

\bibitem[Papana and Kugiumtzis(2009)]{2009:arxiv:papana}
Papana, A.; Kugiumtzis, D.
\newblock Evaluation of mutual information estimators for time series.
\newblock
\newblock {\em Int. J. Bifurc. Chaos} {\bf 2009}, {\it 19},~4197--4215.

\end{thebibliography}

\end{document}
