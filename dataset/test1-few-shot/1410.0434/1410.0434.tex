\documentclass[10pt,twocolumn,twoside]{IEEEtran}


\usepackage{amsbsy,amsmath,amsfonts,amssymb,amsbsy,subfigure,booktabs,multirow}
\usepackage{bm,cite,graphicx,psfrag,pstricks,theorem,tikz,times,url,verbatim}
\usetikzlibrary{shapes,snakes,calendar,matrix,backgrounds,folding}
\usepackage[english]{babel}
\usetikzlibrary{arrows,automata}
\usetikzlibrary{calc} \interdisplaylinepenalty=2500
\usetikzlibrary{decorations.pathmorphing} 

\newcommand{\wmpg}{0.32\linewidth}
\newcommand{\wwmpg}{0.42\linewidth}
\newcommand{\fighh}{4.5cm}
\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\ben}{\begin{enumerate}}
\newcommand{\een}{\end{enumerate}}
\newcommand{\bc}{\begin{cases}}
\newcommand{\ec}{\end{cases}}
\newcommand{\bd}{\begin{description}}
\newcommand{\ed}{\end{description}}
\newcommand{\e}{\item}
\newcommand{\be}{}
\newcommand{\bea}{}
\newcommand{\eq}[1]{(\ref{eq:#1})}
\newcommand{\de}[1]{\,\mathrm{d}#1}
\newcommand{\back}{\!\!\!\!\!}
\newcommand{\meas}[1]{\,\,\,\!\!\mathrm{#1}}
\newcommand{\vup}{\vspace{-1mm}}
\newcommand{\dd}{\textrm{-}}
\newcommand{\bs}{\boldsymbol}



\newcommand\T{\rule{0pt}{2.0ex}}
\newcommand\B{\rule[-0.8ex]{0pt}{0pt}}


\newtheorem{thm}{Theorem}
\newtheorem{fact}{Fact}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{conj}{Conjecture}
\newtheorem{property}{Properties}
\newtheorem{propos}{Proposition}
\newtheorem{corol}{Corollary}
\newtheorem{ass}{Assumption}
\newtheorem{example}{Example}
\newtheorem{algo}{Algorithm}

\theoremstyle{plain}
\newtheorem{remark}{Remark}
\newtheorem{remarks}{Remarks}

\newcommand{\me}{\mathrm{e}}
\newcommand{\mi}{\mathrm{i}}
\newcommand{\md}{\mathrm{d}}
\newcommand{\ve}{\boldsymbol}
\newcommand{\mb}{\mathbf}
\newcommand{\mbb}{\mathbb}
\newcommand{\mc}{\mathcal}
\newcommand{\mr}{\mathrm}
\newcommand{\scr}{\scriptsize}
\newcommand{\sm}{\small}
\newcommand{\foot}{\footnotesize}
\newcommand{\mH}{\mr{H}}
\newcommand{\mT}{T}
\newcommand{\mE}{\mr{E}}
\newcommand{\nn}{\nonumber}
\newcommand{\figw}{0.8\columnwidth}
\newcommand{\figww}{0.6\columnwidth}
\newcommand{\figSpace} {\vspace{-10pt}}



\newcommand{\ks}[1]{\textcolor{blue}{[KS: #1]}}
\newcommand{\pc}[1]{\textbf{(PC: #1)}}
\newcommand{\mz}[1]{\textbf{(MZ: #1)}}
\newcommand{\nm}[1]{\textcolor{red}{\textbf{[NM: #1]}}}
\newcommand{\um}[1]{\textcolor{blue}{\textbf{[UM: #1]}}}
\newcommand{\edit}[1]{{\color{EditColor}{#1}}}

\graphicspath{{./Figures/}
}

\begin{document}

\title{
Cross-layer design of distributed sensing-estimation with quality feedback, Part II: Myopic schemes
}

\author{Nicol\`{o}~Michelusi~and~Urbashi~Mitra


\thanks{Copyright (c) 2014 IEEE. Personal use of this material is permitted. However, permission to use this material for any other purposes must be obtained from the IEEE by sending a request to pubs-permissions@ieee.org.}
\thanks{N. Michelusi and U. Mitra are with the Department of Electrical Engineering, University of Southern California. email addresses: \{michelus,ubli\}@usc.edu.}
\thanks{This research has been funded in part by the following grants:
ONR N00014-09-1-0700, CCF-0917343, CCF-1117896, CNS-1213128, AFOSR FA9550-12-1-0215, and DOT CA-26-7084-00.
N. Michelusi is in part supported by AEIT (Italian association of electrical engineering) through the scholarship "Isabella Sassi Bonadonna 2013".
}
\thanks{Parts of this work have appeared in \cite{MicheAllerton,MicheGlobalsip}.}
}

\maketitle
\noindent\begin{abstract}
 This two-part paper presents a feedback-based cross-layer framework for distributed sensing and estimation of a dynamic process by a wireless sensor network (WSN).  Sensor nodes wirelessly communicate measurements to the fusion center (FC). Cross-layer factors such as packet collisions and the sensing-transmission costs are considered. Each SN adapts its sensing-transmission action based on its own local observation quality and the estimation quality feedback from the FC under cost constraints for each SN. In this second part, low-complexity \emph{myopic} sensing-transmission policies (MPs) are designed to optimize a trade-off between performance and the cost incurred by each SN. The MP is computed in closed form for a \emph{coordinated} scheme, whereas an iterative algorithm is presented for a \emph{decentralized} one, which converges to a local optimum. The MP dictates that, when the estimation quality is poor, only the \emph{best} SNs activate, otherwise all SNs remain idle to preserve energy. For both schemes, the threshold on the estimation quality below which the SNs remain idle is derived in closed form, and is shown to be independent of the number of channels. It is also proved that a single channel suffices for severely energy constrained WSNs. The proposed MPs are shown to yield near-optimal performance with respect to the optimal policy of Part~I~\cite{MichelusiP1}, at a fraction of the complexity, thus being more suitable for practical WSN deployments.
\end{abstract}
\vspace{-3mm}
\section{Introduction}
 Wireless sensor networks (WSNs) enable the monitoring of large areas via many low powered sensor nodes (SNs)
with data acquisition, processing and communication capabilities \cite{Romer}.
However, WSN design is challenged by
the high optimization complexity typical of multi-agent systems~\cite{Bernstein},
necessitating decentralized SN operation based on \emph{local} information and limited feedback,
and needs to explicitly consider the resource constraints of SNs.

In this two part paper, we present a {feedback-based} cross-layer framework for distributed sensing and estimation of a time-correlated random process at a fusion center (FC),
based on noisy measurements collected from nearby SNs,
which accounts for cross-layer factors such as the shared wireless channel, resulting in collisions among SNs, the sensing and transmission costs,
and the \emph{local} state and local view of the SNs.
In order to cope with the uncertainties and stochastic dynamics introduced by these cross-layer components,
the FC broadcasts feedback information to the SNs, based on the estimation quality achieved, thus enabling 
adaptation of their sensing-transmission action.
We design joint sensing-transmission policies with
the goal to minimize the mean squared estimation error (MSE) at the FC,
under a constraint on the sensing-transmission cost incurred by each SN.

In Part I, 
we provided a theoretical foundation for the reduction of the system complexity,
arising from the local asymmetries
 due to the decentralized operation of SNs, their local state and local view, and the multi-agent nature of the system,
 by exploiting the \emph{statistical symmetry} of the WSN with respect to the local view of the SNs and the \emph{large network approximation}.
However, the
dynamic programming (DP) algorithms designed in Part I
still have high complexity. In this second part, building on the results derived in Part I, 
we design low-complexity \emph{myopic policies} for a \emph{coordinated scheme},
where the FC schedules the action (sense and transmit, or remain idle) of each SN, and 
a \emph{decentralized scheme}, where the SNs determine their action in a decentralized fashion,
based on the feedback information and on their local accuracy state.
These myopic policies are designed in such a way as to optimize a trade-off between the MSE at the FC and the
sensing-transmission cost incurred by each SN.


For the coordinated scheme, we derive the myopic policy in closed form. For the decentralized scheme,
we present an iterative algorithm based on the bisection method \cite{bisection}, which converges provably to a local optimum of the myopic cost function.
Similar to the optimal policy derived via DP, the myopic policy dictates that, when the estimation quality at the FC is poor, the 
SNs with the best observation quality activate  by collecting high accuracy measurements and transmit them to the FC, to improve the estimation quality.
In contrast, if the estimation quality is good, the SNs stay idle to preserve energy. For both schemes, we derive, in closed form,  the value of the threshold on the estimation quality below which the SNs remain idle, and show that it is independent of the number of channels  employed. Additionally, we prove that, for severely energy constrained systems, one orthogonal channel () suffices. Numerically, we show that  the myopic policies achieve near-optimal performance with respect to the globally optimal DP policy, at a fraction of the complexity, and are thus suitable for implementation in practical WSN deployments.

The problem of decentralized estimation and detection has seen a vast research effort in the last decade,
especially in the design of optimal schemes 
for parameter estimation \cite{Xiao,Thatte,Xiao2}, hypothesis testing \cite{Ray,Tsitsiklis,Chamberland}, tracking \cite{Saber,Epstein} and random field estimation \cite{Fang}.
Distributed estimation in bandwidth-energy constrained environments has been considered in \cite{Chieh,Ribeiro,Msechu,Junlin}, for a static setting.
 Estimation and detection problems exploiting
feedback information from the FC have been investigated in \cite{Dogandzic,Peng,Kreidl,Dey},
\emph{e.g.}, enabling adaptation of the SNs' quantizers in the estimation of a finite state Markov chain \cite{Dey}.
A consensus based approach for distributed multi-hypothesis testing has been studied in~\cite{Saligrama}.

Differently from these works, we employ a cross-layer perspective, \emph{i.e.}, we jointly consider and optimize the resource constraints typical of WSNs,
such as the shared wireless channel, resulting in collisions among SNs, the time-varying sensing capability of the SNs, their decentralized decisions,
and the cost of sensing and data transmission, and propose a feedback mechanism from the FC to enable \emph{adaptation} and cope with the random fluctuations  in the overall measurement quality collected at the FC,
induced by these cross-layer factors.
This is in contrast to, \emph{e.g.}, \cite{Dey}, where adaptation serves to cope with the distortion introduced by quantization.
We do not consider the problem of quantizer design,
and focus instead on a  \emph{censoring} approach \cite{Appadwedula,Msechu},
 \emph{i.e.}, quantization is fixed and sufficiently fine-grained, so that the measurements received at the FC can be approximated as Gaussian.
In fact, in light of our cross-layer design perspective, quantization may be less relevant due to the overhead required to perform essential tasks such as
synchronization and channel estimation~\cite{Appadwedula}.

Distributed Kalman filtering for WSNs has been proposed in \cite{Olfati},
using a consensus approach and local Kalman filters at each SN. 
In this paper, Kalman filtering is employed only at the FC, which collects unfiltered observations from the SNs.
In fact, due to the poor estimation capability of SNs and their energy constraints, which force them to 
 remain idle most of the time,
the performance gain achievable by exploiting the time-correlation via local Kalman filtering may be small.

 This paper is organized as follows.
  In Secs. \ref{model}, we present the system model
and some preliminary results from Part~I.
  In Secs. \ref{analysisCoord} and \ref{analysisDistr}, we derive the myopic policy for the coordinated and decentralized schemes, respectively.
In Sec.~\ref{numres}, we provide numerical results.
In Sec. \ref{conclusions}, we conclude the paper.
The analytical proofs are provided in the Appendix.

\vspace{-3mm}
\section{System Model}
\label{model}

 \begin{table*}[t]
\caption{Main system parameters}
\label{tab1}
\vspace{-5mm}
\begin{center}
\footnotesize
\scalebox{0.88}{
\begin{tabular}{|c| l | c | l | c | l | c | l |}
\hline\T\B & random process to be tracked
&
& local ambient SNR
 &
& measurement of SN  in slot 
&
& accuracy state with 
 s.s.d. 
  \\\hline\T\B 
  & time-correlation parameter
&& local measurement SNR
&& activation of SN , slot 
&& channel ID for SN , slot 
\\\hline\T\B
 & aggregate SNR at FC
& & sensing cost
& & transmission cost
 && \# channels available, 
 \\\hline\T\B
 & prior variance 
& & posterior variance 
& & SN activation  probability 
&  & \# of SNs, 
\\\hline\T\B 
& normalized unitary sensing cost &
 & average MSE
&
 & 
\multicolumn{3}{l|}{
average sensing-transmission cost of SN 
}
\\
\hline
\end{tabular}
}
\end{center}
\vspace{-5mm}
\end{table*}

\noindent In this section, we present the system model, whose parameters are listed in Table \ref{tab1}.
 Consider a WSN with one FC, depicted in Fig.~\ref{fig:WSN}, whose goal
 is to track a random process 
 following the  scalar linear Gaussian state space~model
  
 based on measurements collected  by  nearby SNs.
In~(\ref{markovstate}),  is the slot index,
  is the \emph{time-correlation parameter}  and .
 We denote the statistical power of  as ,
 and assume  , since any other value can be obtained by scaling.
  Each slot is divided in three phases:
 \begin{enumerate}
 \item \emph{FC instruction} , broadcasted by the FC (Sec.~\ref{FCinstruct});
 \item \emph{Sensing and transmission to FC}: each SN, given , selects its
 sensing-transmission action (Sec. \ref{ph2});
 \item \emph{Estimation at FC}: given the measurements collected, the FC estimates  via Kalman filtering (Sec. \ref{P3}).
 \end{enumerate}
 
 \begin{figure}
    \centering
\scalebox{0.5}{
\begin{tikzpicture}
\draw [ultra thick, ->] (0,0) -- (-0.7,-0.35);
\node at (-1.6,-.5) {Estimate };
\draw [ultra thick, ->] (3,0) -- (0+0.5,0);
\draw [ultra thick, ->] (-2.12,2.12) -- (0-0.3535,0+0.3535);
\draw [ultra thick, ->] (0,-3) -- (0,0-0.5);
\node at (6,-2) {Process };
\draw [fill=black,draw=black,thick,text=white] (0,0) circle [radius=0.5];
\draw [fill=gray,draw=black,thick,text=white] (3,0) circle [radius=0.5];
\node at (3,0) {SN1};
\node at (4,0) {};
\draw [ultra thick, ->] (3.7,0) -- (3.5,0);
\def\x{3.5}
\def\y{0.35}
\draw [fill=white, ultra thick] (2.12,2.12) circle [radius=0.5];
\node at (2.12,2.12) {SN2};
\node at (2.83+0.2,2.83-0.2) {};
\draw [ultra thick,dashed, ->] (0,0) -- (2.47-0.7,2.47-0.7);
\draw [ultra thick, ->] (2.62,2.62) -- (2.47,2.47);
\def\x{2.12+0.6}
\def\y{2.12-0.25}
\draw [fill=white, ultra thick] (0,3) circle [radius=0.5];
\node at (0,3) {SN3};
\node at (0,4) {};
\draw [ultra thick,dashed, ->] (0,0) -- (0,2.5);
\draw [ultra thick, ->] (0,3.7) -- (0,3.5);
\def\x{0.6}
\def\y{3-0.25}
\draw [fill=gray,draw=black,thick,text=white] (-2.12,2.12) circle [radius=0.5];
\node at (-2.12,2.12) {SN4};
\node at (-2.83,2.83) {};
\draw [ultra thick, ->] (-2.62,2.62) -- (-2.47,2.47);
\def\x{-2.12-1.2-0.6}
\def\y{2.12-0.25}
\draw [fill=white, ultra thick] (-3,0) circle [radius=0.5];
\node at (-3,0) {SN5};
\node[above] at (-1.5,0) {};
\node at (-4,0) {};
\draw [ultra thick,dashed, ->] (0,0) -- (-2.5,0);
\draw [ultra thick, ->] (-3.7,0) -- (-3.5,0);
\def\x{-3.5-1.2}
\def\y{0.35}
\draw [fill=white, ultra thick] (-2.12,-2.12) circle [radius=0.5];
\node at (-2.12,-2.12) {SN6};
\node at (-2.83-0.2,-2.83+0.2) {};
\draw [ultra thick,dashed, ->] (0,0) -- (-2.47+0.7,-2.47+0.7);
\draw [ultra thick, ->] (-2.62,-2.62) -- (-2.47,-2.47);
\def\x{-2.12-1.2-0.6}
\def\y{-2.12-0.25}
\draw [fill=gray,draw=black,thick,text=white] (0,-3) circle [radius=0.5];
\node at (0,-3) {SN7};
\node at (0,-4) {};
\draw [ultra thick, ->] (0,-3.7) -- (0,-3.5);
\def\x{0-1.2-0.6}
\def\y{-3-0.25}
\draw [fill=white, ultra thick] (2.12,-2.12) circle [radius=0.5];
\node at (2.12,-2.12) {SN8};
\node at (2.83,-2.83) {};
\draw [ultra thick,dashed, ->] (0,0) -- (2.47-0.7,-2.47+0.7);
\draw [ultra thick, ->] (2.62,-2.62) -- (2.47,-2.47);
\def\x{2.12+0.6}
\def\y{-2.12-0.25}
\node [text=white] at (0,0) {FC};
\draw[->,decorate, decoration={snake, segment length=7mm, amplitude=1mm}] (5,-1.7) -- (4,-0.3);
\draw[->,decorate, decoration={snake, segment length=7mm, amplitude=1mm}] (4.4,-2) -- (3,-2.5);
\draw[->,decorate, decoration={snake, segment length=7mm, amplitude=1mm}] (6,-1.7) -- (3.6,2.4);
\end{tikzpicture}}
\vspace{-3mm}
\caption{{A WSN for distributed estimation, with FC quality feedback.
Each SN decides to either remain idle with cost  or to collect and transmit to the FC the measurement  of  with local measurement SNR  and cost . The shared wireless channel results in collisions and packet losses. The FC, 
based on the measurements received, computes an MMSE estimate of , , and broadcasts the instruction  based on the estimation quality 
achieved,
which is used by the SNs to adjust their sensing-transmission parameters for the next slot.}}\label{fig:WSN}
\vspace{-5mm}
\end{figure}
 \vspace{-3mm}
\subsection{Sensing and transmission to FC}
 \label{ph2}
\noindent  Each SN, at the beginning of slot , given the instruction  broadcasted by the FC,
  selects (possibly, in a randomized fashion) 
  the sensing-transmission parameters , 
 where  is the \emph{activation} decision of SN ,
  is the \emph{local measurement SNR} specified below, and  is the \emph{channel index}.
 {If , SN  remains idle, hence  (no measurement collected) and  (no channel selected).
On the other hand, if , then  and
 the measurement of  by SN  is given by}

where  is the \emph{ambient noise},
and  is the \emph{measurement noise} introduced by the sensing apparatus,
independent of each other, over time and across SNs,
   is the  \emph{local ambient SNR}, and  is the
   \emph{local measurement SNR}, controlled by the th SN, resulting in the sensing cost , where  is a constant.
   The transmission cost is denoted as , common to all SNs,
   so that the overall sensing-transmission cost
is .
We define the \emph{normalized unitary sensing cost} , and
 the \emph{sample average sensing-transmission cost for SN } over a time horizon of length  as



The \emph{accuracy state} , taking values in the finite set , models the ability of SN  to accurately measure .
We model it as a Markov chain with transition probability  and steady state distribution ,
i.i.d. across SNs, and we let .
  We denote the best accuracy state as ,
and, without loss of generality, we assume  and .
 We denote the general scenario where  follows a Markov chain as \emph{Markov-} scenario,
and the special cases where   deterministically 
and  is i.i.d. over time as \emph{best-} and \emph{i.i.d.-} scenarios, respectively.
   The  SNs share 
 a set of  orthogonal single-hop wireless channels to report their measurements to the FC.
 We employ the collision channel model, \emph{i.e.},
 the transmission on a given channel is successful if and only if one SN transmits in that channel. 



\subsection{MMSE estimator at the FC via Kalman filtering}
\label{P3}
\noindent  Let  be the \emph{transmission outcome} for SN , \emph{i.e.},
    if and only if its transmission is successful. Then, the weighted average measurement
   
   is a sufficient statistic for ,
   where we have defined the \emph{local SNR} for SN 
   
    Given the transmission outcome and ,
    is a Gaussian random variable with mean  and variance
   ,
where we have defined the \emph{aggregate SNR} collected at the FC as



 Let  and  be the posterior mean (\emph{i.e.}, the MMSE estimate)
and variance of  at the FC at the end of slot ,
\emph{i.e.},  is the belief of the FC
of .
 Before collecting the measurements from the SNs in slot ,
 using~(\ref{markovstate}),
 the belief of the FC of  is ,
 where  is the \emph{prior variance} of ,
defined recursively as

Then, upon collecting the weighted average measurement ~(\ref{bari})
 with aggregate SNR ,
the FC updates the \emph{posterior variance}  and  mean  of  as

The function  determines  the prior variance of , given the posterior variance of ,
whereas  determines the posterior variance of , given its prior variance ,
as a function of the aggregate SNR  collected at the FC.
The MSE in slot  is thus

We define the \emph{sample average MSE} under  over a time horizon of length  as

where .

\vspace{-3mm}
\subsection{FC instruction policy}
\label{FCinstruct}
\begin{table}[t]

\caption{FC instruction  policy}
\label{tabins}
\vspace{-7mm}
\begin{center}
\footnotesize
\scalebox{0.83}{
\begin{tabular}{|c| c | c | c |}
\hline\T\B 
\multirow{2}{*}{\em Scheme} & \multirow{2}{*}{\em Activity }  & \em Local measurement & \multirow{2}{*}{\em Channel ID }\\
&  &\em SNR  & 
\\\hline\T\B 
{\bf Coordinated}    & Centralized,  FC & Centralized,  FC & Centralized,  FC
\\\hline\T\B 
\multirow{2}{*}{{\bf Decentralized}} & Local, w.p.  & Local,  & \multirow{2}{*}{Local, random}
\\
 &  given by FC &   given by FC  &
\\
\hline
\end{tabular}
}
\end{center}
\vspace{-7mm}
\end{table}
\noindent At the beginning of each slot ,
the FC broadcasts an
\emph{instruction} , which, together with the local accuracy state ,
is employed by SN  to select . We consider the following schemes:
\subsubsection{Coordinated scheme}
  In the coordinated scheme, given , the FC schedules the sensing-transmission action  of  each SN.
Note that each SN is required to report its accuracy state to the FC,
whenever its value changes.
The communication overhead required to collect such information at the FC is analyzed in Part I.
Therefore, the instruction takes the form , where
.
Since  is perfectly known at the FC at the beginning of slot ,
 letting  be the belief of  at the FC, we have that
   ,
  where  is the indicator function. 
The value  is selected 
based on , and 
according to some (possibly, non-stationary) \emph{instruction policy} .
\subsubsection{Decentralized scheme}
 In the decentralized scheme, the FC specifies ,
  where  and 
  are, respectively,
the activation probability and 
the local measurement SNR functions  employed by each SN to select their sensing-transmission strategy in a decentralized manner, as a function of the local accuracy state .
Therefore,  takes value in the set ,
and is generated according to some (possibly, non-stationary) policy , where

is the belief state of the accuracy state vector , given the history of observations collected up to time  at the FC, . 
Given 

and the local accuracy state ,
 SN  chooses its action 
as  with probability ,
 otherwise; if , then
 and  is chosen uniformly from the set of  channels 
(if , then ).
Due to the randomized channel accesses, this scheme may result in collisions among SNs.
The distribution of the number of successful transmissions when each SN transmits with probability  is denoted as
, and its distribution is characterized in \cite[Prop.~4]{MichelusiP1} and, for the case , in \cite[Corollary 1]{MichelusiP1}.

\vspace{-3mm}
\subsection{Performance metrics and optimization problem}
\label{sec:optprob}
\noindent Given the initial prior variance and distribution  , and the instruction policy ,
we define the average MSE and sensing-transmission cost of SN   over a finite horizon of length 
as 
where  is the sample average MSE given by (\ref{RT}),
and 
is the \emph{sample average sensing-transmission cost for SN }, given by (\ref{ctn}).
The expectation is computed with respect to the activation, local measurement SNR, accuracy state and medium access processes 
, induced by policy .
 In particular, we are interested in the infinite horizon   (average long-term performance)
 and ,
 so that we will drop the dependence  on ,  and  in the following treatment, whenever possible.


In Part I,
we have studied the problem of determining the optimal instruction policy  such that

where  is the Lagrange multiplier, which trades off MSE and sensing-transmission cost.
The problem (\ref{optproblag}) can be solved
via DP \cite{Bertsekas2005}.
Due to the high dimensional optimization involved, in Part I
we have derived structural properties of  for the
\emph{best-} scenario, by exploiting the \emph{statistical symmetry} of the WSN and the \emph{large network} approximation,
based on which DP can be solved more efficiently. For the coordinated scheme, we have also
shown that a constant policy which collects a constant aggregate SNR sequence  in each slot is optimal
in some special cases \cite[Theorem 2]{MichelusiP1}. We have then extended these results to the \emph{Markov-} scenario.

\vspace{-5mm}
\subsection{{Complexity of DP}}
\label{complanal}
\noindent Despite the significant computational reduction achieved by exploiting
 the statistical symmetry and large network approximation, DP has high complexity.
In fact, the optimization problem in each DP stage is non-convex, and the action space is very large.
Specifically, the DP algorithm for the coordinated scheme,\footnote{We remark that, owing to the large network approximation, the DP algorithms
are defined only in the \emph{best}- scenario, where the belief  is constant, 
 based on which an heuristic scheme is defined
for the \emph{Markov}- scenario, see Part I.} provided here for convenience, is given by

\noindent {\bf COORD-DP: DP algorithm for the coordinated scheme, \emph{best-} scenario.}
 For , solve, ,
  
where , and  are given in \cite[Prop.~3]{MichelusiP1}. The optimizer, , is the optimal aggregate SNR collected at the FC in slot ,
from which the optimal number of SNs activated is ,
with local measurement SNR .
\hfill\QED

 In order to implement the above DP algorithm,
the cost-to-go function  is evaluated only in
 equally spaced sample points, rather than the  interval ,
\emph{i.e.},
 
For each sample point , the optimal aggregate SNR  can be determined approximately
as follows:
 first, the space  is quantized into  equally spaced  points,
 
  (the sample point  is not included since it correspond to an infinite local measurement SNR, which is unfeasible). 
  Assuming an approximation of the cost-to-go function  in (\ref{DPgenCOORD}) 
  is available from the previous DP stages, the term  in (\ref{DPgenCOORD}) 
  can then be approximated via linear interpolation.
An approximation of  can then be obtained via exhaustive search over the set ,
with precision roughly given by .\footnote{However, notice that, since the cost function in (\ref{DPgenCOORD}) is generally non-convex, the precision of such solution cannot be guaranteed.}
 Therefore, in order to accomplish a target precision ,
  each DP stage requires  evaluations of the cost-to-go function.
 If  stages are performed, the overall complexity scales with .
 
 Similarly, the DP algorithm for the decentralized scheme is given by
 
 \noindent {\bf DEC-DP: DP algorithm for the decentralized scheme, \emph{best-} scenario.}
 For , solve, ,
  
where , 
is the \emph{normalized activation probability per channel}, and
 is the distribution of  for  \cite[Corollary 1]{MichelusiP1}.
The optimizer, , is the optimal normalized activation probability and local measurement SNR in slot ,
from which the activation probability is given by .
\hfill\QED

In this case, for each ,
 an approximation of the optimal  can be obtained via exhaustive search over the grid 
 , where 
 
and ,  are the number of samples.
 Note that the choice of the samples for the local measurement SNR, , is such that the
 interval of feasible values for the local  SNR~(\ref{Slocal}), , is uniformly quantized.
 The points  are not included in the search grid, since, when the transmission probability is zero, all SNs are inactive and
 their local measurement SNR is .
 Similarly, , since the measurements collected with local measurement SNR  are not informative and do not need to be transmitted.
 The precision in the evaluation of  is roughly ,
 whereas the optimal local SNR (\ref{Slocal}) is evaluated with precision roughly given by .
 Each DP stage thus involves  evaluations of the cost-to-go function (\ref{DPzeta}),
 so that the overall complexity after  stages scales approximately as .

Since the SNs typically have limited computational capability, in this paper, we focus on low-complexity control policies,
which can be implemented in practical systems.
Specifically, we investigate the \emph{myopic policy} (MP), defined as the solution of the optimization problem

where  depends on the specific scheme considered,
and the expectation is 
computed with respect to the aggregate SNR collected at the FC, induced 
by policy , and the sensing-transmission decisions of the SNs.
Such policy neglects the impact of the current decision on the future, and only optimizes the current cost,
hence it corresponds to the first DP stage ().
In particular, the overall cost balances the expected MSE in slot , ,
and the expected sensing-transmission cost incurred by each SN in slot , .
We denote the average long-term MSE and sensing-transmission cost under the MP, for a specific value of , as  and , respectively.
\vspace{-3mm}
\begin{remark}
\label{rem1}
We note the following beneficial property of the MP:
given  and , the next state is ;
therefore, the minimization of the expected MSE ,
implicit in the definition of the MP (\ref{MPgen}), also yields a minimization of the expected prior variance in the next slot, 
, \emph{i.e.}, the MP not only minimizes the present cost in slot ,
but, on average,  also moves  the system to a "good" next state associated to a more accurate estimate of .
Furthermore, note that the MP is optimal when the process  is i.i.d. () and  is i.i.d. over time.
In fact, in this case, the sensing-transmission decision in slot  does not affect the next state  and the future cost, hence  in each slot.
\end{remark}
\section{Myopic Policy: Coordinated scheme}
\label{analysisCoord}
\noindent In this section, we analyze the MP for the coordinated scheme.
As in Part I, we first investigate the \emph{best-} scenario, and then extend the analysis
 to the \emph{Markov-} scenario.
\vspace{-2mm}
\subsection{\emph{Best-} scenario}
\label{bestomegacoord}
\noindent In this case, the belief  is constant and  can be neglected.
From (\ref{MPgen}), using the structural properties of \cite[Prop.~2]{MichelusiP1}, \emph{i.e.}, , the MP is defined as

where  is the number of SNs activated and 
is the common local measurement SNR. 
The  SNs are selected randomly from the set of  SNs.
The following theorem derives a closed-form expression of the MP.
We denote by  for  the ceiling operation.
\vspace{-7mm}
\begin{thm}
\label{lemMPclosedform}
Let ,
,
,
and, for ,

 We have the following cases:
 
\noindent \emph{i)} if , then ;

\noindent \emph{ii)} if , for some , then  with probability ,
  otherwise, for some ;

\noindent \emph{iii)} otherwise, , where   is the unique  such that  . 

\noindent \emph{iv)} In all cases,

\end{thm}
\noindent\emph{Proof:}
See Appendix \ref{proofoflemMPclosedform}.
\hfill\QED

\noindent Note that, when , for some , the choice of  is probabilistic.
This is because both solutions  and 
attain the same cost in (\ref{MPcost}). By varying the probability , different trade-offs between MSE and sensing-transmission cost are obtained. 
The case  is of no interest, since the sensing-transmission cost
in (\ref{MPcost}) becomes too large, thus forcing the trivial MP .

The threshold  is an increasing function of .
The implication is that, the poorer the estimate of , \emph{i.e.}, the larger , the more SNs activated,
and thus the larger the sensing-transmission costs incurred. 
In other words, the limited resources available are allocated only when the FC is most uncertain about the state, \emph{i.e.}, when the estimate of
  is poor and needs to be improved. On the other hand, the SNs are kept idle when the FC has an accurate estimate of , in order to preserve energy.
Moreover,  is a piecewise increasing function of , except at the boundaries  corresponding to transitions in the number of SNs activated, increasing function of  and decreasing function of .
In fact,  determines the error floor in the measurement collected by each SN, so that,
as  increases and the ambient noise becomes less relevant,
or the sensing cost decreases (as a consequence of decreasing ),
 there is a stronger incentive to collect more accurate measurements.

The next proposition gives properties of the performance achieved by the MP, in the asymptotic regime .
\begin{propos}
\label{lemperformance}
In the limits  and ,
 the MP attains the following average long-term performance:

where

\end{propos}
\noindent\emph{Proof:}
See  Appendix \ref{proofoflemperformance}.
\hfill\QED

\noindent As expected, when , the sensing-transmission cost becomes dominant in the overall MP cost function,
hence the SNs are forced to remain idle in each slot. The resulting sensing-transmission cost is zero, and the MSE is , since no measurements are received at the FC.
On the other hand, when , the MSE cost becomes dominant. In this case, all  channels are used to transmit 
the measurements to the FC in each slot, and each measurement is collected with infinitely large measurement SNR , so that the aggregate SNR collected at the
FC is , hence the sensing-transmission cost converges to  and the MSE  to 
\cite[Prop.~7]{MichelusiP1}.

\subsubsection{Complexity of the MP}
\label{complmpcoord}
Note that the MP for the coordinated scheme can be determined in closed form, and therefore its complexity scales with , the number of 
sample points in the prior variance state space .
Therefore, a significant complexity reduction is achieved with respect to DP (\ref{DPgenCOORD}),
with complexity   (Sec. \ref{complanal}).


In the next section, we further specialize the analysis to the case , which provides further insights on the structure of the MP. In this case, the measurement  collected by SN  is only subject to
additive Gaussian measurement noise, whereas the ambient noise is zero.
\vspace{-3mm}
\subsection{\emph{Best-} scenario with }
\noindent We have the following corollary of Theorem~\ref{lemMPclosedform}.
\begin{corol}
\label{corolMPclosedform}
Let 
and


\noindent \emph{i)} If  , then the MP is  and


\noindent \emph{ii)} If , the MP is .

\noindent \emph{iii)} Finally, if , the MP is
,  with probaility ,
and
 ,  with probability , for some .
\end{corol}
Corollary \ref{corolMPclosedform}
 dictates that, when , only one SN may activate, \emph{i.e.}, the sensing-transmission burden
 is concentrated on a single SN, whereas all the other SNs remain idle.
In fact, the ambient noise provides an SNR floor in the quality of the measurement collected by each SN.
When  is finite, \emph{i.e.}, the ambient noise is non-zero, it may be desirable to collect multiple measurements from multiple sensors, in order to average out the effect 
of the ambient noise, despite the fact that a large transmission cost may be incurred.
On the other hand, when  is infinite, \emph{i.e.}, the ambient noise is zero, there is no need to average out the ambient noise, hence it is beneficial to 
collect a highly accurate measurement from one SN only, in order to minimize the transmission cost.
This result implies that one orthogonal channel () suffices in this case.
Alternatively, in order to collect the target aggregate SNR , the FC should activate 
  SNs with local SNR .
 The resulting overall network cost is
 , minimized by .
  

 
 
 
In the next theorem we characterize, in closed form, the performance of the MP when .
To this end, we define
  to be the unique solution of , where
 
In the statement of the theorem and in its proof, we make use of properties of  and , stated in Prop.~\ref{eta} in Appendix~\ref{proofofeta}.
\begin{thm}
\label{lemSAinf}
Let , , , .

\noindent \emph{i)} If , then


\noindent \emph{ii)} Otherwise (),

\end{thm}
\noindent\emph{Proof:}
See  Appendix \ref{proofoflemSAinf}.
\hfill\QED

\noindent
{Consider the case  (a similar argument holds for the case ).
The parameter  represents the \emph{transmission period}, \emph{i.e.}, one SN is activated once every  slots, whereas all SNs stay idle in the 
remaining  slots.
On the other hand,  is the minimum posterior variance achieved when one SN is activated and its measurement is collected at the FC.
During the idle period, no measurements are collected, hence the posterior variance increases in each slot.
As discussed in \cite[Remark 5]{MichelusiP1}, this pattern of periodic transmissions with period  can be reduced
by including a term which accounts for the \emph{outage event}  in the MP cost function.
Clearly, as  increases, the transmission period  augments,
hence the SNs are activated less frequently resulting in a lower cost and poorer MSE performance.
Similarly,  increases since a smaller local measurement SNR is employed by the active SN (see (\ref{SAinf})).}
 By varying , 
where

we obtain different operational points .
The next proposition states properties of the cost-MSE graph .
To this end, we define the following ordering of the elements in : let 
,  with ;
then,  if either
, or  and
 .
\begin{propos}
\label{lemconvex}

\noindent \emph{i)}  is continuous.

\noindent \emph{ii)}    is decreasing in ,
 whereas   is increasing in ,
 \emph{i.e.},

\end{propos}
\noindent\emph{Proof:}
See Appendix \ref{proofoflemconvex}.
\hfill\QED

\noindent 
Prop. \ref{lemconvex} shows a desirable property of the MP for the special case .
In particular, the larger , \emph{i.e.} the more resource constrained the system, the smaller the sensing-transmission cost and the larger the
MSE. The implication is that we can tune  in order to achieve the desired trade-off between
cost and MSE. Note that 
 (\ref{decreasing}) is not expected. In fact, the MP is designed to minimize only the instantaneous cost (\ref{MPcost}),
not the average long-term performance. 
  The more general case  is difficult to analyze, due to the complex structure of the MP and the resulting evolution of .
  In the next section, we analyze the \emph{Markov-} scenario.
  \vspace{-3mm}
  \subsection{\emph{Markov-} scenario}
\noindent In this case, the accuracy state of each SN fluctuates over time according to a Markov chain, thus causing random fluctuations
in the aggregate SNR collected at the FC.
 The optimal policy is difficult to characterize,
 due to the high dimensionality of the problem.
 Herein, as in Part I, we define a \emph{sub-optimal coordinated MP}, based 
 on the MP derived in Sec. \ref{bestomegacoord}.
 Specifically, 
 let 
be a ranking of SNs indexed by , such that 
is the label of the SN with the th highest accuracy state,
\emph{i.e.}, .
 
 Let  be a \emph{virtual prior variance process}, generated as if all measurements were collected with
 the best accuracy state . Starting from , we thus have ,
 where .
 We define the sub-optimal coordinated MP (SCMP) as follows.


  \noindent\textbf{SCMP}:
Given , the virtual prior variance state , and , 
the
  SNs with the best accuracy state are activated  in slot ,
 with local measurement SNR ,


In the \emph{best-} scenario, SCMP simplifies to the MP given by Theorem~\ref{lemMPclosedform}.
 In the next proposition, we derive a bound to the average long-term performance of SCMP 
in the \emph{Markov-} scenario,
, with respect to the performance achieved
in the \emph{best-} scenario, .
Its proof is similar to the proof of \cite[Theorem 3]{MichelusiP1}, and is thus omitted.
\begin{propos}
Under the SCMP, if  
and , then  and

\end{propos}
Note that SCMP achieves the same average long-term cost as if all the SNs could sense with the best accuracy state .
This is a consequence of the fact that SCMP is generated according to the virtual prior variance  state , whose evolution
emulates that of the \emph{best-} scenario.
In the next section, we analyze the MP for the decentralized scheme.
\vspace{-3mm}
\section{Myopic Policy: Decentralized scheme}
\label{analysisDistr}
\noindent We first investigate the \emph{best-} scenario, and then
 extend our analysis to the \emph{Markov-} scenario.
 \vspace{-3mm}
\subsection{\emph{Best-} scenario}
\label{bestomegadistr}
\noindent In the decentralized scheme, the MP is defined as

where  is the number of packets successfully received at the FC, as a result of having each node transmit
with probability  in one of the  orthogonal channels available.

We focus on the \emph{large network} approximation, \emph{i.e.},
on the asymptotic  scenario of large number of SNs
, where we fix the \emph{normalized activation probability} , and optimize over the values of  and .
Then, the MP for  is defined as

where, letting  in (\ref{DPMP}), we have defined

  we have used the fact that
  converges to a binomial random variable with  trials and success probability
  \cite[Corollary~1]{MichelusiP1},
and we have defined the PMF of the binomial distribution .
The following theorem characterizes the solution of (\ref{DPMP2}).
\vspace{-3mm}
\begin{thm}
\label{lemMPdistr}
Let
,
where  is defined in Theorem~\ref{lemMPclosedform},
and  be given by (\ref{vth}) for .

\noindent\emph{i)} If ,
then .

\noindent\emph{ii)} Otherwise, 
must simultaneously solve,
for some , ,

where the expectation is computed with respect to the PMF of .
Moreover,


\end{thm}
\noindent\emph{Proof:}
See Appendix \ref{proofoflemMPdistr}.
\hfill\QED

\noindent
The MP dictates that the SNs activate only when the estimation quality at the FC is poor, \emph{i.e.},
 , in order to improve the estimate, and remain idle to preserve energy when it is accurate ().
 Therefore, the MP induces an efficient utilization of the scarce resources available in the system.
 Interestingly, the threshold on the prior variance state, , and on the Lagrange multiplier, ,
 have the same expression as in the coordinated scheme (see Theorem~\ref{lemMPclosedform}).
 These thresholds are independent of the number of channels . This is because, when ,
 the sensing-transmission cost dominates the cost function defining the MP, hence the SNs activate with (normalized) probability close to
 zero. It follows that, with high probability, only one channel will be occupied, and the remaining channels remain unused. 
 The practical implication is that, when ,
 \emph{i.e.}, the WSN is severely energy constrained,  suffices. 
 
 Note that the MP, when , must simultaneously solve
   and 
 . This is a set of \emph{necessary} conditions, but they may not be sufficient.
 In fact, the cost function defining the MP in (\ref{DPMP2}) is, in general, non-convex with respect to .
 We now present an iterative algorithm to determine a \emph{local} minimum of (\ref{DPMP2}), for the case .
 \vspace{-3mm}
 \begin{algo}\label{algoMP}\\
\noindent 1) Let , ;

\noindent 2) given , determine

as follows: if , set ;
if , set ;
otherwise, determine  as the unique 
  such that , using the \emph{bisection method} \cite{bisection};
 
\noindent 3) given , determine

as follows: if , set ;
otherwise, determine  as the unique 
  such that , using the \emph{bisection method};

\noindent 4) update  and repeat from steps 2) and 3) until convergence; return ,
.
\end{algo}
Note that Algorithm \ref{algoMP} is guaranteed to converge to a \emph{local} minimum of the MP cost function (\ref{DPMP2}),
since, at each step 2-3), the function  is minimized while keeping the other parameter fixed, and
 the MP solution  lies in the bounded set .
In steps 2{-}3), we have used the fact that  and 
are the derivatives of   with respect to  and ,
and these functions are increasing in  and , respectively (see Appendix~\ref{proofoflemMPdistr}).

A corollary of Theorem \ref{lemMPdistr} is given below, for the case .
\begin{corol}
\label{sdfsdf}
Let .

\noindent \emph{i)} If ,
then .

\noindent \emph{ii)} 
Otherwise, 

and  is the unique  solving

\end{corol}
For this case, a stronger result can be proved: the solution is a global minimum of (\ref{DPMP2}), rather than a local one for the general case .
  can be determined using the bisection method \cite{bisection},
 by exploiting the fact that (\ref{solvez}) is an increasing function of .
 Note that, for fixed ,  is an increasing function of  and , and decreasing function of 
  and  (however,  is also a function of these parameters via (\ref{solvez})). In fact, the larger  (\emph{i.e.}, the smaller the
 error floor induced by the ambient noise) or
  (\emph{i.e.}, the poorer the quality of the estimate),
 or the smaller  (\emph{i.e.}, the smaller the sensing cost) or  (\emph{i.e.}, the milder the cost constraint),
 the stronger the incentive to sense with higher local measurement SNR.
By further specializing Corollary \ref{sdfsdf} to  (no transmission cost),  (no ambient noise) and , we obtain the
 MP \cite[Sec. II.B]{MichelusiP1}.


\subsubsection{Complexity of the MP}
\label{complmpdec}
Unlike the coordinated scheme,
the MP for the decentralized one cannot be determined in closed form.
For each ,
in order to determine  in step 2) of Algorithm \ref{algoMP} with precision \footnote{The precision is evaluated with respect to the local SNR (\ref{Slocal}), in order to have a fair comparison with the analysis in Sec. \ref{complanal}} using the bisection method \cite{bisection},
at most 
evaluations of  are needed (each corresponding to an iteration of the bisection method), where 
 is a constant which depends on the initial search interval .
Similarly, in order to determine  in step 3) of Algorithm~\ref{algoMP} with precision  using the bisection method,
at most 
evaluations of  are needed (each corresponding to an iteration of the bisection method), where 
 is a constant which depends on the initial search interval .
For  we thus obtain  
and . 
Assuming steps 2) and 3) of Algorithm~\ref{algoMP}  are repeated  times, the
overall complexity thus scales as .
We conclude that the complexity of the MP algorithm scales with the logarithm of ,
and thus provides a significant complexity reduction with respect to DP (\ref{DPzeta}),
whose complexity scales linearly with  (Sec.~\ref{complanal}).
We have verified numerically that Algorithm \ref{algoMP} typically converges in few iterations ().
In the special case  studied in Corollary~\ref{sdfsdf},  can be determined exactly as a function of
, whereas 
 can be determined via one run of the bisection method \cite{bisection} to solve (\ref{solvez}), resulting in the overall complexity 
 .

 
 
\vspace{-3mm}
\subsection{\emph{Markov-} scenario}
\noindent We now discuss the \emph{Markov-} scenario.
 As for the coordinated scheme, we define a \emph{sub-optimal decentralized MP} (SDMP), based 
 on the MP derived in Sec. \ref{bestomegadistr}.
 
   \noindent\textbf{SDMP}: 
Given  and
the value of  fed back from the FC,
the activation probability is defined as

and the local measurement SNR as ,
where  uniquely solves~.
\hfill\QED

\begin{figure}[t]
\centering
\includegraphics[width = .85\linewidth,trim = 10mm 4mm 10mm 9mm,clip=true]{figMPNS20_c}
\vspace{-3mm}
\caption{MSE as a function of the network cost, \emph{best-} scenario, .}\vspace{-5mm}
\label{NS20}
\end{figure}


\noindent Note that
,
\emph{i.e.}, all SNs activate with \emph{marginal} normalized probability ,
with respect to the steady state distribution of .

The performance of the sub-optimal decentralized MP is difficult to characterize. In fact, due to the Markov property of the accuracy state ,
the number of collisions and successful transmissions are correlated over time.
However, the following proposition holds in the \emph{i.i.d.-} scenario.
To this end, we denote by

and 
the performance in the
\emph{i.i.d.-}  and \emph{best-} scenarios, respectively.
\begin{propos}
In the \emph{i.i.d.-} scenario, if
, then 
, .
\end{propos}
As shown in Part I, this is a consequence of the fact that, if the conditions of the proposition hold, 
then ,
hence only the SNs with the best accuracy state may activate under SDMP, so that there is no degradation in the aggregate SNR collected at the FC, ,
compared to the \emph{best-} scenario. In other words, a densely deployed WSN provides \emph{sensing diversity}.


\section{Numerical Results}\label{numres}
\noindent In this section, we provide numerical results.
Unless otherwise stated, we consider a WSN of size  SNs (\emph{small} and \emph{large} WSN, respectively).
We let , , , , and .
We consider the \emph{best-} scenario only. Similar considerations hold for the \emph{Markov-} scenario.
The interested reader is referred to Part~I for a numerical evaluation of the \emph{Markov-} scenario.
We consider the following schemes, evaluated via Monte-Carlo simulation over  slots:

\noindent \emph{COORD-DP}: optimal coordinated scheme, obtained via  DP iterations (see Part I);
 
 \noindent  \emph{DEC-DP}:  optimal decentralized scheme, obtained via  DP iterations (see Part I);

\noindent
 \emph{COORD-SNR}: max coordinated aggregate SNR scheme; non-adaptive policy which maximizes the expected aggregate SNR at the FC, under cost constraints for the SNs (see Part~I);

\noindent
 \emph{DEC-SNR}: max decentralized aggregate SNR scheme; non-adaptive policy which maximizes the expected aggregate SNR at the FC, under cost constraints for the SNs (see Part~I);

\noindent \emph{COORD-MP}: MP for the coordinated scheme (Sec. \ref{analysisCoord});
 
 \noindent  \emph{DEC-MP}: MP for the decentralized scheme (Sec. \ref{analysisDistr}), derived via Algorithm \ref{algoMP}.


\begin{figure}[t]
\centering
\includegraphics[width = .85\linewidth,trim = 10mm 4mm 10mm 9mm,clip=true]{figMPNS100_c}
\vspace{-3mm}
\caption{MSE as a function of the network cost, \emph{best-} scenario, .}\vspace{-5mm}
\label{NS100}
\end{figure}



In Figs. \ref{NS20} and  \ref{NS100}, we plot the
 MSE (\ref{Cest}) as a function of the network sensing-transmission cost  (\ref{CSN})
 for the small and large WSN scenarios, respectively,  obtained by varying the Lagrange multiplier .
We notice that, in both cases, COORD-MP and DEC-MP incur no performance degradation with respect to
their DP counterparts COORD-DP and DEC-DP, respectively, at a fraction of the complexity.
As conjectured in Remark \ref{rem1}, this is because the MP not only minimizes the present cost in slot ,
but, on average,  also moves  the system to a "good" next state.
{Therefore, as shown in Part I, similar to the DP policies, also the MP outperforms the technique proposed in \cite{Msechu}.}
On the other hand, the non-adaptive schemes  COORD-SNR and DEC-SNR incur a significant performance degradation,
since they greedily maximize the expected aggregate SNR collected at the FC, , but do not take into account 
the fluctuations in , and hence, 
 in the
quality state , resulting from cross-layer factors such as the decentralized access decisions of the SNs and the uncertain channel outcomes.


In Fig. \ref{figstruct}, we plot the structure of DEC-DP and DEC-MP as a function of the quality state .
We note that, as  increases,
\emph{i.e.}, the estimate of  is less accurate,
 both  and  increase,
 in order to achieve a higher estimation accuracy.
 On the other hand, when the estimation accuracy is good ( for DEC-DP and  for DEC-MP),
  the activation probability is zero, so that the SNs can
 save energy.
 The threshold on the estimation quality below which the SNs remain idle, , is given in closed form by (\ref{vth}) for .
Note that the normalized activation probability is larger for DEC-MP than for DEC-DP. The resulting higher transmission cost for the former is balanced
by employing a smaller local measurement SNR , incurring smaller sensing cost,
 so that the overall sensing-transmission cost is the same for both schemes.
Finally, note that, for both schemes, the local measurement SNR is approximately constant for all values of the quality state , thus suggesting
that adaptation of the activation probability is more critical than adaptation of the local measurement SNR. 
A practical implication is that
a lower optimization complexity can be achieved by 
adapting only the former, while
using a constant value for the latter.

\begin{figure}[t]
\centering
\includegraphics[width = .85\linewidth,trim = 10mm 4mm 10mm 9mm,clip=true]{figMPstruc}
\vspace{-3mm}
\caption{Structure of DEC-DP and  DEC-MP  as a function of the prior variance .
The corresponding simulated network cost is  and the MSE is  for both schemes.}\vspace{-5mm}
\label{figstruct}
\end{figure}



Finally, in Fig. \ref{figstructCOORD}, we plot COORD-DP and COORD-MP as a function of the quality state .
Similar to the decentralized scheme, as proved in Theorem~\ref{lemMPclosedform},
  activations are of threshold type, \emph{i.e.}, one SN is activated only if , otherwise all SNs remain idle.
Moreover, as can be observed from the figure and analytically from (\ref{optSM}),
 the local measurement SNR increases with , in order to achieve higher estimation accuracy when
the estimation quality at the FC is poor.
\vspace{-3mm}
\section{Conclusions}\label{conclusions}
 \noindent In this paper, we have proposed a cross-layer distributed sensing-estimation framework for WSNs,
 which exploits the quality feedback information from the FC.
 Our cross-layer design approach allows one to model the time-varying capability 
 of the SNs to accurately sense the underlying process,
  the scarce channel access resources shared by the SNs, as well as sensing-transmission costs.
We have proposed a coordinated scheme, where the FC schedules the action of each SN,
 and a more scalable decentralized scheme, where each SN performs a local decision to sense-transmit or remain idle, based on the FC quality feedback and
 the local observation quality.
  In this second part, we have designed low-complexity myopic policies.
For the coordinated scheme, we have shown that the myopic policy can be characterized in closed form. For the decentralized scheme, we have presented an iterative algorithm which converges provably to a local optimum of the myopic cost function.
Numerically, we have shown that the myopic policies achieve near-optimal performance,
 at a fraction of the complexity with respect to the optimal policy derived via dynamic programming,
 and thus are more suitable for implementation in practical WSN deployments.




\begin{figure}[t]
\centering
\includegraphics[width = .85\linewidth,trim = 10mm 4mm 10mm 9mm,clip=true]{figstrucCOORD}
\vspace{-3mm}
\caption{Structure of COORD-DP and  COORD-MP  as a function of the prior variance .
The corresponding simulated network cost is  and the MSE is  for both schemes.}\vspace{-5mm}
\label{figstructCOORD}
\end{figure}


\appendices
\vspace{-3mm}
\section{}
\label{proofoflemMPclosedform}
\noindent\emph{Proof of Theorem \ref{lemMPclosedform}:}
We first optimize (\ref{MPcost}) with respect to the local measurement SNR , for a fixed .
Since (\ref{MPcost}) is convex with respect to , by computing the derivative with respect to
 and setting it to zero, and forcing the solution to be non-negative, since , we obtain the optimal 

We now optimize with respect to the number of active SNs .
Note that, if , then , hence
 the optimal number of active SNs is .
 Otherwise (), after plugging  into the cost function (\ref{MPcost}), we obtain the cost function

hence .
In order to solve this problem, we study the function .
We have

hence .
Note that 

hence  is an increasing function of .
Solving with respect to ,  is equivalent to

 Note that (\ref{cond1000}) cannot hold if , since  and the left hand expression would be strictly positive. Therefore,  for (\ref{cond1000}) to hold. Solving with respect to , it can be shown that
 (\ref{cond1000}) is equivalent to the union of  and
  
 where the second inequality in (\ref{sdfsfds}) can be proved using the fact that  for (\ref{cond1000}) to hold.
 Note that, since , the inequality (\ref{sdfsfds}) cannot hold, hence
 
Let , whose solution is given as in the statement of the theorem.
 Clearly, .
From (\ref{must}), we then have .
On the other hand, for , we have that 
.
Note that .
It follows that, if , then 
, and therefore .
In this case, , hence .
On the other hand, if , then ,
hence , . In this case,
, hence .
Finally, if
 , 
 letting ,
we have , or equivalently ,
hence , and
, or equivalently .
In particular,  and , \emph{i.e.},
 and .
If , we have , hence both  and  minimize  and
the choice of  is probabilistic.

To conclude, we show that it suffices to consider .
We show that, if , then the MP solution is forced to , so that all SNs remain idle at all times.
This occurs if , since , \emph{i.e.},

or equivalently:

\noindent 1) If the right hand expression in (\ref{aaaaa}) is negative, \emph{i.e.},
;

\noindent 2) If  and, by squaring each side of (\ref{aaaaa}),

We further distinguish the following subcases:

\noindent 2.a) if , then (\ref{rrr}) is equivalent to ;

\noindent 2.b) if , then (\ref{rrr}) is equivalent to ;

\noindent 2.c) finally, if , then (\ref{rrr}) is equivalent to

Note that the upper bound is redundant since, 
using the fact that 
, we obtain the tighter bound

hence (\ref{rrr}) is equivalent to 

Combining the cases 1) and 2), (\ref{aaaaa}) holds  if .
Hence, in order to avoid the trivial MP solution ,
  must satisfy the condition of the theorem.
 
 Finally, the optimal  is given by . The theorem is thus proved.
\hfill\QED

\vspace{-3mm}
\section{}
\label{proofoflemperformance}
\noindent\emph{Proof of Prop. \ref{lemperformance}:}
When , we have
,
.
Therefore, since , from Theorem~\ref{lemMPclosedform} we have , hence all channels are occupied.
Moreover, , so that the sensing-transmission cost in each slot is , and the aggregate SNR collected at the FC in each slot is . The result follows from \cite[Prop.~7]{MichelusiP1}.
Now, consider the case . In this case, we have ,
by definition of . Therefore, it follows that , so that
 the sensing-transmission cost in each slot , and the aggregate SNR collected at the FC in each slot is .
\hfill\QED

\vspace{-3mm}
\section{}
\label{proofofeta}
\begin{propos}[Properties of  and ]
\label{eta}
 is a decreasing function of  and increasing function of .
Additionally, , , and .
\end{propos}
\noindent\emph{Proof:}
The first part can be proved by inspection, \emph{i.e.}, by solving   and
.
We have , hence , ,
and .
Finally, , and thus necessarily , since  
is a decreasing function of .~\hfill\QED

\vspace{-3mm}
\section{}
\label{proofoflemSAinf}
\noindent\emph{Proof of Theorem~\ref{lemSAinf}:}
We prove the theorem only for the case  and . A similar proof holds for the case
 or , the only difference being in the initial transient behavior (which does not affect the
average long-term performance). In the proof, we define , for .

Let , for some  (for any , such  exists and is unique).
Since , we have , hence,
from Corollary \ref{corolMPclosedform}, , .
Then we have ,  ,
with cost .

In the following stages , let  for some . This is true for , since .
Then, from Corollary~\ref{corolMPclosedform}:

\noindent 1) if , then , , ,
, with cost ;

\noindent 2) if , then, with probability , , , ,
, with cost ;
otherwise, with probability ,
, , ,
, with cost ;
  
  \noindent 3) if , then
, , ,
, with cost .

Since  is a non-decreasing sequence,
and using the definition of  as the unique solution of  (see (\ref{etak})),
 we have that ,
 and  and  .
It follows that, if  for some , then .
If , then, with probability  (where  if ), ; otherwise, .
Finally, if , then .
The prior variance process  thus follows a time-homogeneous, finite-state Markov chain,
taking value from the set . Let  be the long-term time-average probability that , defined as 

By solving the steady state equations, it is given by

By averaging with respect the steady-state distribution ,
the average long-term sensing-transmission cost incurred by each SN under the MP is thus given by

since transmissions occur only if  (with probability ) or 
 (with probability ), yielding (\ref{Cinf}).
Similarly, the average long-term MSE is given by

since no transmissions occur in states , hence ,
yielding  (\ref{Rinf}).
\hfill\QED

\vspace{-3mm}
\section{}
\label{proofoflemconvex}
\noindent\emph{Proof of Prop. \ref{lemconvex}:}
Using the fact that  for , we
obtain that
the average long-term expressions (\ref{Rinf}) and (\ref{Cinf}) are continuous functions of 
.
Similarly, (\ref{Rinf}) and (\ref{Cinf}) are continuous functions of , for .
Continuity at the boundaries holds by inspection of (\ref{Rinf}), (\ref{Cinf}).

Now, we prove that  and 
are, respectively, increasing and decreasing functions of ,
and that  and 
are, respectively, decreasing and increasing functions of .
The property (\ref{decreasing}) then follows from this and the continuity.
From (\ref{Rinf}) and (\ref{Cinf}), for  and  we have

where we have used the fact that , hence .
Similarly, for ,  and , we have

hence .
This is verified, since
, so that .
Similarly, 

By solving  by definition of , 
with respect to  as a function of , and using (\ref{etak}) and (\ref{vth}),
we obtain

 Replacing (\ref{th}) in (\ref{derivCinfp}), and letting ,
 we obtain

We have

It follows that , hence
 , thus proving
 (\ref{decreasing}).
\hfill\QED
\vspace{-3mm}
\section{}
\label{proofoflemMPdistr}
\noindent\emph{Proof of Theorem \ref{lemMPdistr}:}
Let, for ,

\subsection{Optimal  given }
\noindent It can be shown that

where we have used the fact that 

The argument within the expectation in (\ref{fdsfds}) is concave in . If , using Jensen's inequality \cite{Boyd},
we thus obtain

where we have used the fact that .
It follows that  increases for , hence  and we optimize over  hereafter.
By multiplying each side of (\ref{fdsfds}) by , we obtain that
 is equivalent to .
We have the following property of .
\begin{propos}
\label{incrG}
 is an increasing function of .
\end{propos}
\noindent\emph{Proof:}
See Appendix \ref{AppincrG}.
\hfill\QED

\noindent Using Prop. \ref{incrG} and the fact that 
 , we obtain the following cases, depending on the sign of
if , 
  then  and ;
otherwise,
  is the unique  such that .
\subsection{Optimal  given }
\noindent Let . It can be shown that

hence  is convex in , for a fixed , .
We have
 and

Then, if , \emph{i.e.},
, we have , hence 
.
Otherwise (),
 is the unique  such that .
By evaluating  in , it can be shown that

Therefore, necessarily .


We now prove that the MP is .
In fact, if there exists some  such that , for such  we have that 

and, for all ,
, 
hence the MP satisfies  (in fact,  has sub-optimal cost ).

On the other hand, if , it follows that
, hence the MP satisfies  .
We conclude that .
We thus minimize  with respect to . It can be shown that  is a convex function of .
By setting the derivative with respect to  to zero and forcing the solution to be non-negative (since ), we obtain

By evaluating the function  when , hence ,
we obtain
, hence  if .
We now consider the case . After rearranging the terms, we obtain

Solving  with respect to , it can be shown that this is equivalent to ,
and therefore .

Finally, we  show that the MP lies within (\ref{boundz}) and (\ref{boundSM}), when .
By contradiction, if ,
then , hence
, yielding a contradiction.
Hence, necessarily,  .
On the other hand, if , then , yielding a contradiction.
Therefore, we must have . By solving it with respect to 
, we obtain (\ref{boundSM}).
Using the fact that , it can be shown  that 
. Moreover, in general, ,
so that
the upper/lower bounds are not tight.
\hfill\QED
\vspace{-3mm}
\section{}
\label{AppincrG}
\noindent\emph{Proof of Prop. \ref{incrG}:}
We have
 
where the inequality is obtained by minimizing with respect to , yielding , and we have defined, for
 and ,

By rearranging the terms, we obtain, for .



We now prove that , by induction on .
For ,  from (\ref{sb}) we obtain .
Now, assume that, for some  , . We prove that this implies .
It can be shown that 
the derivative of  with respect to  is given by

hence .
The result follows since  by inspection.
\hfill\QED
\bibliographystyle{IEEEtranS}
\bibliography{IEEEabrv,References}



\end{document}