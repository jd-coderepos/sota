



\documentclass[11pt]{article}
\usepackage{coling2020}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmic}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\renewcommand{\algorithmiccomment}[1]{\bgroup\hfill//~#1\egroup}

\usepackage[export]{adjustbox}
\usepackage{caption}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{subfig}




\colingfinalcopy 




\title{TPLinker: Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking}







\author{
  Yucheng Wang\textsuperscript{1}, Bowen Yu\textsuperscript{1}\thanks{{} {} Corresponding author.}, Yueyang Zhang\textsuperscript{2}\\ 
  \bf Tingwen Liu\textsuperscript{1}, Hongsong Zhu\textsuperscript{1}, Limin Sun\textsuperscript{1}\\
  \textsuperscript{1}School of Cyber Security, University of Chinese Academy of Sciences \\
  \textsuperscript{1}Institute of Information Engineering, Chinese Academy of Sciences \\
  \textsuperscript{2}Baidu, Inc. \\
  {\tt \{wangyucheng,yubowen,liutingwen,zhuhongsong,sunlimin\}@iie.ac.cn}\\
  {\tt zhangyueyang@baidu.com}
 }

\date{}

\begin{document}
\maketitle
\begin{abstract}
Extracting entities and relations from unstructured text has attracted increasing attention in recent years but remains challenging, due to the intrinsic difficulty in identifying overlapping relations with shared entities. Prior works show that joint learning can result in a noticeable performance gain.  However, they usually involve sequential interrelated steps and suffer from the problem of exposure bias. At training time, they predict with the ground truth conditions while at inference it has to make extraction from scratch. This discrepancy leads to error accumulation. To mitigate the issue, we propose in this paper a one-stage joint extraction model, namely, TPLinker, which is capable of discovering overlapping relations sharing one or both entities while immune from the exposure bias. TPLinker formulates joint extraction as a token pair linking problem and introduces a novel handshaking tagging scheme that aligns the boundary tokens of entity pairs under each relation type. Experiment results show that TPLinker performs significantly better on overlapping and multiple relation extraction, and achieves state-of-the-art performance on two public datasets\footnote{The source code of this paper can be obtained from https://github.com/131250208/TPlinker-joint-extraction}.
\end{abstract}

\blfootnote{










    \hspace{-0.65cm}  This work is licensed under a Creative Commons 
    Attribution 4.0 International License.
    License details:
    \url{http://creativecommons.org/licenses/by/4.0/}.
}

\section{Introduction}
Extracting entities and relations from unstructured texts is  an essential step in automatic knowledge base construction~\cite{takanobu2019hierarchical}.
Traditional pipelined approaches first extract entity mentions and then classify the relation types between candidate entity pairs.
However, due to the complete separation of entity detection and relation classification, these models ignore the interaction and correlation between the two subtasks, being susceptible to cascading errors~\cite{li2014incremental}.

In the last few years, there has been increasing research interest in building joint models to simultaneously extract entities and relations.
Recent works show that joint learning approaches can effectively integrate the information of entity and relation, and therefore achieve better performance in both subtasks~\cite{dai2019joint,tan2019jointly}.
~\newcite{zheng2017joint} proposed a unified tagging scheme to convert joint extraction to a sequence labeling problem but lacks the elegance to identify overlapping relations: one entity may participate in multiple relations in the same text (Figure~\ref{fig:overlapping_patterns}).

\begin{figure}[htb]
    \centering
    \includegraphics[scale=0.48]{Figures/overlapping_patterns.png}
o    \caption{Examples of the Normal, SingleEntityOverlap (SEO), and EntityPairOverlap (EPO) cases. The overlapping entities are marked in blue. }
    \label{fig:overlapping_patterns}
\vspace{-0.1in}
\end{figure}

Most existing models in handling EntityPairOverlap~(EPO) and SingleEntiyOverlap~(SEO) cases can be categorized into two classes: decoder-based and decomposition-based.
Decoder-based models use encoder-decoder architecture where the decoder extracts one word or one tuple at a time like machine translation models~\cite{zeng2018extracting,nayak2019effective}.
Decomposition-based models first distinguish all the candidate subject entities that may be involved with target relations, then label corresponding object entities and relations for each extracted subject~\cite{li2019entity,yu2020jointer,wei2020CasRel}.
Although these methods have achieved reasonable performance, they all suffer from the same problem: exposure bias.
For the decoder-based method, at training time, the ground truth tokens are used as context while at inference the entire sequence is generated by the resulting model on its own, and hence the previous tokens generated by the model are fed as context.
As a result, the predicted tokens at training and inference are drawn from different distributions, namely, from the data distribution as opposed to the model distribution\cite{zhang2019bridging}.
Similarly, the decomposition-based method uses the gold subject entity as specific input to guide the model extract object entities and relations during the training process while at inference the input head-entity is given by a trained model, leading to a gap between training and inference.

In this paper, we present a one-stage method for joint extraction of entities and overlapping relations, namely TPLinker, which bridges the gap between training and inference.
TPLinker transforms the joint extraction task as a \textbf{T}oken \textbf{P}air \textbf{Link}ing problem.
Given a sentence, two positions  and a specific relation , TPLinker is to answer three Yes/No pseudo questions: ``Whether  and  are the start and end positions of the same entity respectively?'', ``Whether  and  are the start positions of two entities with  relation respectively?'' and ``Whether  and  are the end positions of two entities with  relation respectively?''
To this end, we design a handshaking tagging scheme that annotates three token link matrices for each relation to answer the above three questions.
These link matrices are then used to decode different tagging results, from which we can extract all entities and their overlapping relations. 
Intuitively, TPLinker does not contain any inter-dependency extraction steps,  so it avoids the dependence on ground truth conditions at training time, realizing the consistency of training and testing.

We evaluate our method on two public datasets: NYT~\cite{riedel2010modeling} and WebNLG~\cite{gardent2017creating}. 
Experimental results show that TPLinker outperforms previous works and achieves the state- of-the-art results on the benchmark datasets.
Further analysis demonstrates that TPLinker significantly improves the performance on Normal, SEO, EPO, and multiple relation extraction.


 \section{Related Work}
Researchers proposed several methods to extract both entities and relations.
Traditional pipelined methods~\cite{zelenko2003kernel,chan2011exploiting} neglect the relevance of entity extraction and relation prediction. 
To resolve this problem, several joint models have been proposed. 
Feature-based works~\cite{yu2010jointly,miwa2014modeling} need a complicated process of feature engineering and heavily depend on NLP tools for feature extraction. 
Neural models for joint relation extraction are investigated in recent studies~\cite{gupta2016table,zheng2017joint}, they show promising results but completely giving up overlapping relations. 
To address this problem, a variety of neural networks for joint extraction of entities and overlapping relations are proposed. 
\newcite{dai2019joint} extracted triplets by tagging one sentence for  times with a position-aware attention mechanism. 
\newcite{tan2019jointly} solved this task via ranking with translation mechanism. 
\newcite{takanobu2019hierarchical} firstly determined relations and then recognized entity pairs via reinforcement learning. 
\newcite{li2019entity} cast joint extraction as a multi-turn QA problem and generated questions by relation-specific templates. 
\newcite{sun2019joint} constructed an entity-relation bipartite graph to perform inference on entity types and relation types. 
\newcite{yu2020jointer} presented a unified sequence labeling framework based on a novel decomposition strategy.
However, these methods can only recognize SEO relations in the sentence and fail to extract EPO triplets.

To handle the EPO cases, \newcite{zeng2018extracting} proposed a sequence-to-sequence model to decode overlapping relations but fail to generate multi-word entities.
As the improvement, \newcite{nayak2019effective} employed an encoder-decoder model where the decoder extracts one word at a time like machine translation models.
Besides, \newcite{wei2020CasRel} proposed a novel cascade binary tagging framework that first identifies all possible subject entities in a sentence then identifies all possible relations and object entities for each subject entity.
Actually, these methods decompose the extraction of overlapping relations into several inner-dependency steps, since the decoder needs a recursive decoding process and cascade tagging has to identify subject entities in advance.
Such decomposition makes the task easy to conduct but inevitably causes the exposure bias problem, which leads to error accumulation. 
At training time, they predict the triplets with the ground truth tokens or subjects while at inference they have to rely on the predicted results.
In this paper, we propose a unified tagging method to extract entities and overlapping relations.
Different from previous methods, our model performs in one stage and generates triplets without a gap between training and inference. \section{Methodology}

In this section, we first introduce our handshaking tagging scheme and its decoding algorithm.
Then we detail the TPLinker model structure.


\subsection{Handshaking Tagging Scheme}
\subsubsection{Tagging}
According to the insight that a triplet (, , ) can be determined by aligning the boundary tokens of subject entity  and object entity  conditioned on the relation , we realize one-stage joint extraction by tagging token pairs with link labels.

\begin{figure}[t]
\centering 
\begin{minipage}[t]{0.48\textwidth}
    \includegraphics[scale=0.41]{Figures/handshaking_1.png}
\end{minipage}\begin{minipage}[t]{0.48\textwidth}
    \includegraphics[scale=0.42]{Figures/handshaking_2.png}
\end{minipage}
 \caption{(Best viewed in color.) \textbf{Left}:  A tagging matrix. For the convenience to illustrate, we show all tags in one matrix, in which each color corresponds to a specific kind of tag. \textbf{Right}: An example of the Handshaking Tagging Scheme, the region in shade is not included in the tag sequence. }
 \label{fig:handshaking_tagging}
\end{figure}
As shown in the left panel of Figure~\ref{fig:handshaking_tagging}, given a sentence, we enumerate all possible token pairs and use matrices to tag token links. Formally, three types of links are defined as follows\footnote{For ease of exposition, we use "entity/subject/object head" to represent the start position of one entity/subject/object. Similarly, entity/subject/object tail is defined as the end position.}:
\textbf{1) entity head to entity tail (EH-to-ET)}. The purple tag in the matrix refers to that the two corresponding positions are respectively the start and end token of an entity. For example, ``New York City'' and ``De Blasio'' are two entities in the sentence, therefore, token pair (``New'', ``City'') and (``De'', ``Blasio'') are assigned with purple tag 1.
\textbf{2) subject head to object head  (SH-to-OH)}. The red tag means that two positions are respectively the start token of a paired subject entity and object entity. For example, there is a ``mayor'' relation between ``New York City'' and ``De Blasio'', so the token pair (``New'', and ``De'') is assigned with red tag 1.
\textbf{3) subject tail to object tail  (ST-to-OT)}. The blue tag shares a similar logic with the red tag, which means two positions are respectively the end token of a paired subject entity and object entity. For instance, the token pair (``City'', ``Blasio'') is assigned with blue tag 1.

As we can see from the left panel of Figure~\ref{fig:handshaking_tagging}, the matrix is quite sparse, especially the lower triangular region. Because the entity tail is impossible to appear before the entity head, the tags in the lower triangular region are all zeros, which is a huge waste of memory. 
However, the object entity could appear before the corresponding subject entity,
which means it is not reasonable to drop the lower triangular region directly. Before doing that, we map all tag 1 in the lower triangular region to tag 2 in the upper triangular region, then drop the lower triangular region.
After doing this, it is not a complete matrix anymore, in 
the practical operation, we flatten the rest items into a sequence (the orange sequences in Figure~\ref{fig:framework}) for the convenience of tensor calculation and use a map to remember the positions in the original matrix. 
The sequence is like the handshaking of all tokens, which is the reason why we refer to this scheme as the handshaking tagging scheme. 

\begin{figure}[t]
    \centering
    \includegraphics[scale=0.63]{Figures/framework.png}
    \caption{The Framework of TPLinker. 
    SH is short for subject head, OH is short for object head, ST is short for subject tail, and OT is short for object tail. By decoding, 5 triplets can be extracted: (New York, mayor, De Blasio), (De Blasio, born in, New York), (De Blasio, born in, New York City), (De Blasio, live in, New York), (De Blasio, live in, New York City).
}
    \label{fig:framework}
\vspace{-0.1in}
\end{figure}

The case in the left panel of Figure~\ref{fig:handshaking_tagging} suggests that this tagging scheme can naturally address the SingleEntiyOverlap problem and the nested entity problem from design. 
In this case, ``New York City'' and ``New York'' are nested and share the same object ``De Blasio'', which is a challenging problem for many previous methods. However, by this tagging scheme, both the three entities and the two triplets can be easily decoded (see Section~\ref{sec:decoding}). 
However, this scheme cannot handle the EntityPairOverlap problem because different relations can not be tagged together in the same matrix for the same entity pair. 
To address this issue, we do the same matrix tagging job for each relation type.
Note that EH-to-ET tagging is shared by all relations because it focuses on the general entity extraction without considering the specific relation types.
Overall, as depicted in Figure~\ref{fig:framework}, the joint extraction task is deconstructed into 2+1 sequence labeling subtasks where  denotes the number of pre-defined relation types, each subtask builds a tag sequence of length , where  is the length of the input sentence.
It seems that our tagging scheme is extremely inefficient because the length of the tagging sequence increases in a square number with increasing sentence length.
Fortunately, our experiment reveals that by utilizing a light-weight tagging model on the top of the encoder, TPLinker can achieve competitive running efficiency compared with the state-of-the-art model, since the encoder is shared by all taggers (see Figure~\ref{fig:framework}) and only needs to generate  token representations for once.






\subsubsection{Decoding}\label{sec:decoding}
In the case of Figure~\ref{fig:framework}, (``New'', ``York''), (``New'', ``City'') and (``De'', ``Blasio'') are tagged as 1 in the EH-to-ET sequence, which means ``New York'', ``New York City'', and ``De Blasio'' are three entities. 
For relation ``mayor'', (``New'', ``De'') is tagged as 1 in the SH-to-OH sequence, which means the mayor of the subject starting with ``New'' is the object starting with ``De''. 
(``City'', ``Blasio'') is tagged as 1 in the ST-to-OT sequence, which means that the subject and object are the entities ending with ``City'' and ``Blasio'', respectively. 
Based on the information represented by these three sequences, a triplet can be decoded: (``New York City'', mayor, ``De Blasio''). 

The same logic goes for other relations, but note that the tag 2 has an opposite meaning to the tag 1, which represents a reversal link between tokens. 
For example, (``York'', ``Blasio'') is tagged as 2 in the ST-to-OT sequence of relation ``born in'', which means ``York'' and ``Blasio'' are respectively the tail of a paired object and subject. 
Combined with the other two sequences, the decoded triplet should be (``De Blasio'', born in, ``New York'').

Formally, the decoding process is summarized in Algorithm~\ref{alg:decoding}. 
For each relation, in the beginning, we extract all entity spans from the EH-to-ET sequence and map each head position to the corresponding entities starting with this position by a dictionary . 
Next, for each relation, we firstly decode (subject tail position, object tail position) tuples from the ST-to-OT sequence and add them into a set , and then decode (subject head position, object head position) tuples from the SH-to-OH sequence and lookup all possible entities starting with the head positions in the dictionary .
Finally, we iterate all candidate subject-object pairs to check whether their tail positions are in  . If so, a new triplet is extracted and added into the resulting set . 

\begin{algorithm}[htb]
\footnotesize
\algsetup{
    linenodelimiter = {  }
}
\caption{Handshaking sequence decoding}
\label{alg:decoding}
\begin{algorithmic}[1]
\REQUIRE ~~The EH-to-ET sequence, ; \\
~~~~~~~~~The SH-to-OH sequences of relation , , where  is the pre-defined relation set; \\
~~~~~~~~~The ST-to-OT sequences of relation , ; \\
~~~~~~~~~The map from sequence indices to matrix indices, .\\
\ENSURE the predicted triplet set, .
\STATE  Initialize  \algorithmiccomment{the dictionary that maps entity head position to a set of entities that begin with this head position}

\STATE  Initialize  \COMMENT{the set of (subject tail position, object tail position)}

\STATE  Initialize 

\FOR{ \TO tag sequence length } 
\IF{ = 1}

\STATE add  to [[0]] \COMMENT{ is a tuple (entity head position, entity tail position)}
\ENDIF
\ENDFOR

\FOR{} 

\FOR{ \TO tag sequence length } 
\IF{ = 1}
\STATE add  to  \COMMENT{ is a tuple (subject tail position, object tail position)}
\ELSIF{ = 2}
\STATE  add  to  \COMMENT{ is a tuple (object tail position, subject tail position)}
\ENDIF
\ENDFOR


\FOR{ \TO tag sequence length } 
\IF{ = 1}
\STATE  is a tuple (subject head position, object head position)
\STATE  \algorithmiccomment{Set records the subjects beginning with }
\STATE  \algorithmiccomment{Set records the objects beginning with }
\ELSIF{ = 2}
\STATE  is a tuple (object head position, subject head position
\STATE  
\STATE 
\ENDIF

\FOR{}
\FOR{}
\IF{}
\STATE add  to 
\ENDIF
\ENDFOR
\ENDFOR
\ENDFOR
\ENDFOR

\RETURN 
\end{algorithmic}
\end{algorithm}
\subsection{Token Pair Representation}




Given a sentence  of length , we first map each token  into a low-dimensional contextual vector  by a basic encoder. Then we can generate a representation  for the token pair () as follows:

where  is a parameter matrix and  is a bias vector to be learned during training.
Equation~\ref{equ:tok_pair_rep} is also denoted as Handshaking Kernel in Figure~\ref{fig:framework}.


\subsection{Handshaking Tagger}
We utilize a unified architecture for EH-to-ET, SH-to-OH and ST-to-OT tagging. 
Given a token pair representation , the link label of token pair () is predicted by Equation~\ref{equ:link_tag}.


where  represents the probability of identifying the link of () as . 

\subsection{Loss Function}
We define the training loss as below:






Here,  is the length of the input sentence,  is the true tag, , , and  denote the taggers of EH-to-ET, SH-to-OH and ST-to-OT, respectively. 
%
  \section{Conclusion}
In this paper, we propose an end-to-end sequence labeling model TPLinker for joint extraction of entities and relations based on a novel handshaking tagging strategy, by which the joint extraction task is converted to a token pair linking game. 
To the best of our knowledge, TPLinker is the first one-stage joint extraction model that can extract all kinds of overlapping relations without the influence of exposure bias.
Experimental results show that our model outperforms all baselines and achieves a new state-of-the-art on two public datasets. 
Further analysis especially demonstrates the capabilities of our model on handling sentences with overlapping relations and multiple relations. 
The results also prove that it is of benefit to close up the gap between training and inference. 
In the future, we would like to generalize the token linking idea and explore its performance on other information extraction problems, such as nested name entity extraction and event extraction.  
\section*{Acknowledgements}
This work was supported by the National Key R\&D Program of China (Grant No. 2017YFB0802804).



\bibliographystyle{coling}
\bibliography{coling2020}

















\end{document}
