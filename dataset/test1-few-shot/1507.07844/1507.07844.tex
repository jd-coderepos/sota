
\documentclass[conference]{IEEEtran}

\IEEEoverridecommandlockouts

\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{cite}
\usepackage{amsmath}
\usepackage{stfloats}
\usepackage{booktabs}
\usepackage{array}
\usepackage{tabularx}
\usepackage{slashbox}
\usepackage[dvips]{graphicx}
\usepackage{subfigure}
\usepackage{multirow}
\usepackage{bm}
\usepackage{color}
\usepackage{float}



\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}
\title{Composite Learning Control With Application\\to Inverted Pendulums}




\author{\IEEEauthorblockN{Yongping Pan\IEEEauthorrefmark{1},
Lin Pan\IEEEauthorrefmark{2}\IEEEauthorrefmark{3}, and
Haoyong Yu\IEEEauthorrefmark{1}}
\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Biomedical Engineering, National University of Singapore, Singapore 117575, Singapore
\\\tt\small Email: biepany@nus.edu.sg; bieyhy@nus.edu.sg}
\IEEEauthorblockA{\IEEEauthorrefmark{2}Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg\\
\tt\small Email: lin.pan@uni.lu}
\IEEEauthorblockA{\IEEEauthorrefmark{3}School of Electric and Electronic Engineering, Wuhan Polytechnic University, Wuhan 430023, China}
}


\maketitle


\begin{abstract}
Composite adaptive control (CAC) that integrates direct and indirect adaptive control techniques can achieve smaller tracking errors and faster parameter convergence compared with direct and indirect adaptive control techniques. However, the condition of persistent excitation (PE) still has to be satisfied to guarantee parameter convergence in CAC. This paper proposes a novel model reference composite learning control (MRCLC) strategy for a class of affine nonlinear systems with parametric uncertainties to guarantee parameter convergence without the PE condition. In the composite learning, an integral during a moving-time window is utilized to construct a prediction error, a linear filter is applied to alleviate the derivation of plant states, and both the tracking error and the prediction error are applied to update parametric estimates. It is proven that the closed-loop system achieves global exponential-like stability under interval excitation rather than PE of regression functions. The effectiveness of the proposed MRCLC has been verified by the application to an inverted pendulum control problem.

\end{abstract}


\IEEEpeerreviewmaketitle

\section{Introduction}

Adaptive control is one of the major control techniques of handling uncertainties in nonlinear systems and has still attracted great concern in recent years \cite{Astrom2008, Astolfi2008, Anderson2008, Stefanovic2011, Narendra2011, Casavola2012, Khan2012, Martin2012, Pathak2012, Lavretsky2013, Serrani2013, Sun2013, Barkana2014b, Chan2014, Swarnkar2014, Tao2014}. In particular, \emph{model reference adaptive control} (MRAC) is a popular adaptive control architecture which aims to make an uncertain dynamical system behave like a chosen reference model. The way of parameter estimation in adaptive control gives rise to two different schemes, namely indirect and direct schemes \cite{Ioannou1996}. \emph{Composite adaptive control} (CAC) is an integrated direct and indirect adaptive control technique which aims to achieve better tracking and parameter estimation through faster and smoother parameter adaptation \cite{Slotine1989}. In the CAC, prediction errors are generated by identification models, and both tracking errors and prediction errors are applied to update parametric estimates. The superiority of CAC on performance improvement has been demonstrated in many control designs, where some latest results can be referred to \cite{Naso2010, Patre2010, Hu2010, Mohanty2011, Pan2012, Pan2013b, Wei2013, Dydek2013}. Nevertheless, as in the classical adaptive control, CAC only achieves asymptotic convergence of tracking errors and does not guarantee parameter convergence unless plant states satisfy the condition of persistent excitation (PE) \cite{Ioannou1996}. It is well known that the PE condition is very strict and often infeasible to monitor online in practical control systems \cite{Chowdhary2010a}.

Learning is one of the fundamental features of autonomous intelligent behavior, and it is closely related to parameter convergence in adaptive control \cite{Antsaklis1995}. The benefits brought by parameter convergence include accurate closed-loop identification, exponential stability and robustness against measurement noise \cite{Chowdhary2014}. An emerging \emph{concurrent learning} technique provides a feasible and promising way for achieving parameter convergence without the PE condition in MRAC \cite{Chowdhary2010a, Chowdhary2011, Chowdhary2014}. The difference between the concurrent learning and the composite adaptation lies in how to construct prediction errors. In the concurrent learning, a dynamic data stack constituted by online recorded data is used in constructing prediction errors, singular value maximization is applied to maximize the singular value of the data stack, and exponential convergence of both tracking errors and estimation errors is guaranteed if regression functions of plant uncertainties are excited over a time interval such that sufficiently rich data are recorded in the data stack. Yet in this innovative design, the singular value maximization leads to an exhaustive search over all recorded data, and the requirement on the derivation of all plant states for calculating prediction errors is stringent.

This paper proposes a novel model reference composite learning control (MRCLC) strategy for a class of parametric uncertain affine nonlinear systems. In the composite learning, a modified modelling error that can utilize online recorded data is constructed as the prediction error, a second-order command filter is applied to alleviate the derivation of plant states, and both the tracking error and the prediction error are applied to update parametric estimates. It is proven that the closed-loop system achieves global exponential-like stability under interval excitation (IE) rather than PE of regression functions. Consequently, the limitations of concurrent learning are alleviated by the proposed MRCLC design. The effectiveness and superiority of this approach is verified by the application to an inverted pendulum control problem with the comparison with some existing adaptive control approaches.

The notations of this paper are relatively standard, where , ,  and  denote the spaces of real numbers, positive real numbers, real -dimensional vectors, and -dimensional matrixes, respectively,  and  denote the absolute value and Euclidean-norm, respectively,  denotes the space of bounded signals,  denotes the ball of radius ,  and  are the minimum and maximum functions, respectively, sgn is the sign function, rank is the rank of , diag is a diagonal matrix, and  represents the space of functions whose -order derivatives all exist and are continuous, where , , , and ,  and  are positive integers.

\section{Problem Formulation}

This section discusses the formulation of learning from the classical MRAC. For clear illustration, consider a class of \emph{n}th order affine nonlinear systems as follows \cite{Chowdhary2010a}:

where , , ,  is the vector of plant states,  is the control input, and  is the  model uncertainty. A reference model that characterizes the desired response of the system (\ref{eq01}) is given by

with , in which  is a strictly Hurwitz matrix,  is the vector of reference model states, and   is a bounded reference signal. This study is based on the facts that  is measurable,  is controllable, and  is linearly parameterizable such that \cite{Chowdhary2010a, Chowdhary2011, Chowdhary2014}

in which  is a unknown constant parameter vector,  is a known regression function vector, and  is a known constant. The following definitions are given for facilitating control synthesis.

\textbf{Definition 1} \cite{Chowdhary2010a}: A bounded signal  is of IE over   if there exist constants  with  such that  holds.

\textbf{Definition 2} \cite{Chowdhary2010a}: A bounded signal  satisfies the PE condition if there exist constants  such that  holds, .

Let  be an augmented reference signal, and  be an estimate of . Define a tracking error , and an estimation error . Our objective is to design a proper parametric update law of MRAC such that both  and  exponentially converge to \textbf{0} under the IE rather than the PE conation.


\section{Composite Learning Control Strategy}

\subsection{Review of Previous Results}

From \cite{Ioannou1996}, the MRAC law can be designed as follows:

where  denotes a proportional-derivative (PD) feedback part,  denotes a reference signal feedforward part,  denotes an adaptive part,  and  are control gains, and the design of  satisfies

Thus, one obtains the tracking error dynamics

where  is designed to be strictly Hurwitz. Thus, for any matrix , a unique solution  exists for the following Lyapunov equation:


Let the adaptive law of  be as follows:

where  is a learning rate, and  is a projection operator given by \cite{Ioannou1996}

Choose a Lyapunov function candidate

with  for the closed-loop dynamics composed of (\ref{eq06}) and (\ref{eq08}). It follows from the classical MRAC result of \cite{Ioannou1996} that if  and  is of PE, then the closed-loop system (\ref{eq06}) with (\ref{eq08}) achieves \emph{global exponential stability} in the sense that both the tracking error  and the estimation error  converge to \textbf{0}.

To remove the requirement of the PE condition on  for parameter convergence in \cite{Ioannou1996}, a concurrent learning law of  is proposed in \cite{Chowdhary2010a} as follows:

where  is a certain epoch,  is the number of stored data, and  denotes a modelling error which is regarded as the prediction error calculated by

where ,  and  are online recorded data of ,  and  at the epoch , respectively. Let   be a dynamic data stack. It is shown in the concurrent learning MRAC approach of \cite{Chowdhary2010a} that if   and rank on , then the closed-loop system (\ref{eq06}) with (\ref{eq10}) achieves \emph{global exponential-like stability} in the sense that both the tracking error  and the estimation error  converge to \textbf{0} on . Yet in the approach of \cite{Chowdhary2010a}, fixed-point smoothing must be applied to estimate  in (\ref{eq11}) such that the prediction error  is calculable, and singular value maximization should be applied to exhaustively search the data stack  to maximize its singular value.

\subsection{Composite Learning Control Design}

Define a modified modelling error  as the prediction error, in which

with  and

in which  is an integral duration,  is the minimal singular value of , and  is the time when  reaches its maximum\footnotemark[1]. Then, a composite learning law of  is designed as follows:

in which  is a weight factor.

\footnotetext[1]{The presence of  and  here is only used in the subsequent performance analysis and their values can only be gotten at the control process.}

From  and (\ref{eq12}), the calculation of  can follow the calculation of  as follows:

where  is directly obtainable by (\ref{eq13}) and (\ref{eq14}), and  is not directly obtainable. Multiplying both sides of (\ref{eq06}) by , int\-egrating the resulting equality over  and making some transformations, one gets

in which the time variable  is omitted in the above integral part. Since  is unavailable, a second-order linear filter with unit gain is implemented as follows \cite{Hu2013}:

with  and , where  is the natural frequency,  is the damping factor, and  and  are estimates of  and , respectively. The integral in (\ref{eq16}) effectively reduces the influence of measurement noise on the calculation of . Thus,  in (\ref{eq17}) can be made sufficiently small so that . For simplifying analysis, assume that  as in \cite{Hu2013}. The reasonability of this assumption will also be verified in the subsequent simulations. The following theorem shows the main result of this study.

\textbf{Theorem 1}: Consider the system (\ref{eq01}) driven by the control law (\ref{eq04}) with (\ref{eq14}), where the control gain  is designed to satisfy (\ref{eq05}), and the control gain  is selected to make  in (\ref{eq06}) strictly Hurwitz. If  and  are satisfied with  and   , then the closed-loop system composed of (\ref{eq06}) and (\ref{eq14}) achieves \emph{global exponential-like stability} in the sense that all closed-loop signals are bounded for all  and both the tracking error  and the estimation error  exponentially converge to \textbf{0} on .

\emph{proof:} Firstly, consider the control problem at . Choose the Lyapunov function candidate  in (\ref{eq09}) for the closed-loop system constituted by (\ref{eq06}) and (\ref{eq14}). The time de\-rivative of  along (\ref{eq06}) is as follows:

where (\ref{eq07}) is utilized to obtain (\ref{eq21}). Applying (\ref{eq14}) to (\ref{eq21}), noting  and , and using the pro\-jection operator results in \cite{Ioannou1996}, one obtains

Noting  and , one gets , , which implies that the closed-loop system is stable in the sense that . Since   is satisfied  and  in (\ref{eq09}) is radially unbounded (i.e.  as ), the stability is global. Using , one also obtains  from their definitions. Thus, all closed-loop signals are bounded for all .

Secondly, consider the control problem at . since there exist  and  such that , i.e. the bounded signal  is exciting over , it is obtained from (\ref{eq22}) that

It follows from (\ref{eq09}) and (\ref{eq23}) that

where , which implies that the closed-loop system has global exponential-like stability in the sense that both  and  exponentially converge to \textbf{0} as long as . \hfill 

\section{Application to Inverted Pendulum} \label{Example}

\begin{figure*}[!t]
\centering
\subfigure[]{\includegraphics[width = 3.5in]{Fig01.eps}}\hfill
\subfigure[]{\includegraphics[width = 3.5in]{Fig02.eps}}\hfill
\subfigure[]{\includegraphics[width = 3.5in]{Fig03.eps}}\hfill
\subfigure[]{\includegraphics[width = 3.5in]{Fig04.eps}}\hfill
\subfigure[]{\includegraphics[width = 3.5in]{Fig05.eps}}\hfill
\subfigure[]{\includegraphics[width = 3.5in]{Fig06.eps}}\\
\caption{Simulation trajectories by all controllers. (a) Control performance by the MRAC. (b) Learning performance by the MRAC. (c) Control performance by the MRCAC. (d) Learning performance by the MRCAC. (e) Control performance by the MRCLC. (f) Learning performance by the MRCLC.}
\label{fig01}
\end{figure*}

Consider the following inverted pendulum model \cite{Chowdhary2010a}:

in which  and , . The reference model is given as follows:

For simulations, set ,  while , and  while  \cite{Chowdhary2010a}.

The parameters selection of the proposed control law (\ref{eq04}) with (\ref{eq14}) is based on that of \cite{Chowdhary2010a}, where the details are given as follows: firstly, solve (\ref{eq05}) to obtain ; sec\-ondly, select  so that  is strictly Hurwitz; thirdly, solve (\ref{eq07}) with  to obtain ; fourthly, set   5 s in (\ref{eq13}); fifthly, set  3.5,  6 and  5 in (\ref{eq14}); finally, set  100 and  0.7 in (\ref{eq17}).

Simulations are carried out in MATLAB software running on Windows 7, where the solver is set to be fixed-step ode 5 with the step size being 0.001 s and other settings being default values. The conventional MRAC in \cite{Ioannou1996} and the model reference CAC (MRCAC) with \emph{Q}-modification in \cite{Volyanskyy2010} are selected as baseline controllers, where the reference models and shared parameters of all controllers are set to be the same for fair comparisons. Simulation trajectories by all controllers are depicted Fig. \ref{fig01}. For the control performance, it is shown that the plant state  follows its desired signal  closely with a smooth control input  for all controllers, the MRCAC achieves the worst tracking accuracy [see Fig. \ref{fig01}(c)], and the proposed MRCLC achieves the best tracking accuracy [see Fig. \ref{fig01}(e)]. For the learning performance, it is observed that IE occurs with  rising at  s in this case, the MRAC does not show any parameter convergence [see Fig. \ref{fig01}(b)], the MRCLC shows better parameter estimation than the MRAC but still does not achieve parameter convergence [see Fig. \ref{fig01}(d)], and the proposed MRCLC achieves fast and accurate parameter estimation even the IE is short and weak [see Fig. \ref{fig01}(f)].

\section{Conclusion}

In this paper, a MRCLC strategy has been successfully developed for a class of parametric uncertain affine nonlinear systems such that parameter convergence can be guaranteed by the IE rather than PE condition. The proposed approach has also been applied to an inverted pendulum model, where superior control and learning performances have been demonstrated compared with the conventional MRAC and the MRCAC with Q-modification. Further work would focus on the extension of the composite learning to wider classes of nonlinear systems such as multi-input multi-output affine nonlinear systems \cite{Pan2013a} and strict-feedback nonlinear systems \cite{Pan2015}.


\section*{Acknowledgment}

This work was supported in part by the National Research Foundation of Singapore under Grant NRF2014NRF-POC001-027, in part by the Biomedical Engineering Programme, Age\-ncy for Science, Technology and Research (A*STAR), Sing\-apore under Grant 1421480015, and in part by AFR and FNR programs, Luxembourg.



\begin{thebibliography}{99}

\bibitem{Astrom2008} K. J. Astrom and B. Wittenmark, \textit{Adaptive Control, 2nd ed.} Mineola, NY, USA: Dover, 2008.

\bibitem{Astolfi2008} A. Astolfi, D. Karagiannis, and R. Ortega, \textit{Nonlinear and Adaptive Con\-trol with Applications.} London, UK: Springer, 2008.

\bibitem{Anderson2008} B. D. O. Anderson and A. Dehghani, ``Challenges of adaptive control-past, permanent and future,'' \textit{Annu. Rev. Control}, vol. 32, no. 2, pp. 123-135, Dec. 2008.

\bibitem{Stefanovic2011} M. Stefanovic and M. G. Safonov, \textit{Safe Adaptive Control: Data-Driven Stability Analysis and Robust Synthesis.} London, UK: Springer, 2011.

\bibitem{Narendra2011} K. S. Narendra and Z. Han, ``The changing face of adaptive control: The use of multiple models,'' \textit{Annu. Rev. Control}, vol. 35, no. 1, pp. 1- 12, Apr. 2011.

\bibitem{Casavola2012} A. Casavola, J. Hespanha, and P. Ioannou, ``Special issue on `recent trends on the use of switching and mixing in adaptive control','' \textit{Int. J. Adapt. Control Signal Process.}, vol. 26, no. 8, pp. 690-691, Aug. 2012.

\bibitem{Khan2012} S. G. Khan, G. Herrmann, F. L. Lewis, T. Pipe, and C. Melhuish, ``Reinforcement learning and optimal adaptive control: An overview and implementation examples,'' \textit{Annu. Rev. Control}, vol. 36, no. 1, pp. 42-59, Apr. 2012.

\bibitem{Martin2012} J. M. Martin-Sanchez, J. M. Lemos, and J. Rodellar, ``Survey of indus\-trial optimized adaptive control,'' \textit{Int. J. Adapt. Control Signal Process.}, vol. 26, no. 10, pp. 881-918, Oct. 2012.

\bibitem{Pathak2012} K. B. Pathak and D. M. Adhyaru, ``Survey of model reference adaptive control,'' in Proc. \textit{Nirma University International Conference on Engineering}, Ahmedabad, India, 2012, pp. 1-6.

\bibitem{Lavretsky2013} E. Lavretsky and K. A. Wise, \textit{Robust and Adaptive Control: With Ae\-rospace Applications.} London, UK: Springer, 2013.

\bibitem{Serrani2013} A. Serrani, ``An output regulation perspective on the model reference adaptive control problem,'' \textit{Int. J. Adapt. Control Signal Process.}, vol. 27, no. 1-2, pp. 22-34, Jan. 2013.

\bibitem{Sun2013} J. Sun, M. Krstic, and N. Bekiaris-Liberis, ``Robust adaptive control: leg\-acies and horizons,'' \textit{Int. J. Adapt. Control Signal Process.}, vol. 27, no. 1-2, pp. 1-3, Jan. 2013.



\bibitem{Barkana2014b} I. Barkana, ``Simple adaptive control - a stable direct model reference adaptive control methodology - brief survey,'' \textit{Int. J. Adapt. Control Signal Process.}, vol. 28, no. 7-8, pp. 567-603, Jul. 2014.

\bibitem{Chan2014} L. P. Chan, F. Naghdy, and D. Stirling, ``Application of adaptive con\-trollers in teleoperation systems: A survey,'' \textit{IEEE Trans. Hum.-Mach. Syst.}, vol. 44, no. 3, pp. 337-352, Jun. 2014.


\bibitem{Swarnkar2014} P. Swarnkar, S. K. Jain, and R. K. Nema, ``Adaptive control schemes for improving the control system dynamics: A review,'' \textit{IETE Tech. Rev.}, vol. 31, no. 1, pp. 17-33, Jan-Feb. 2014.

\bibitem{Tao2014} G. Tao, ``Multivariable adaptive control: A survey,'' \textit{Automatica}, vol. 50, no. 11, pp. 2737-2764, Nov. 2014.




\bibitem{Ioannou1996} P. A. Ioannou and J. Sun, \textit{Robust Adaptive Control}. Englewood Cliffs, NJ: Prentice Hall, 1996.

\bibitem{Slotine1989} J.-J. E. Slotine and W. Li, ``Composite adaptive control of robot mani\-pulators,'' \textit{Automatica}, vol. 25, no. 4, pp. 509-519, Jul. 1989.


\bibitem{Naso2010} D. Naso, F. Cupertino, and B. Turchiano, ``Precise position control of tubular linear motors with neural networks and composite learning,'' \textit{Control Eng. Practice}, vol. 18, no. 5, pp. 515-522, May 2010.

\bibitem{Mohanty2011} A. Mohanty and B. Yao, ``Integrated direct/indirect adaptive robust control of hydraulic manipulators with valve deadband,'' \textit{IEEE-ASME Trans. Mechatron.}, vol. 16, no. 4, pp. 707-715, Aug. 2011.

\bibitem{Patre2010} P. M. Patre, S. Bhasin, Z. D. Wilcox, and W. E. Dixon, ``Composite adaptation for neural network-based controllers,'' \textit{IEEE Trans. Autom. Control}, vol. 55, no. 4, pp. 944-950, Apr. 2010.

\bibitem{Hu2010} C. Hu, B. Yao, and Q. Wang, ``Integrated direct/indirect adaptive ro\-bust contouring control of a biaxial gantry with accurate parameter es\-timations,'' \textit{Automatica}, vol. 46, no. 4, pp. 701-707, Apr. 2010.

\bibitem{Pan2012} Y. P. Pan, M. J. Er, and T. R. Sun, ``Composite adaptive fuzzy control for synchronizing generalized Lorenz systems,'' \textit{Chaos}, vol. 22, no. 2, Article ID 023144, Jun. 2012.

\bibitem{Pan2013b} Y. P. Pan, Y. Zhou, T. R. Sun, and M. J. Er, ``Composite adaptive fuzzy  tracking control of uncertain nonlinear systems,'' \textit{Neurocomputing}, vol. 99, pp. 15-24, Jan. 2013.

\bibitem{Wei2013} X. J. Wei, N. Chen, and W. Q. Li, ``Composite adaptive disturbance observer-based control for a class of nonlinear systems with multisource disturbance,'' \textit{Int. J. Adapt. Control Signal Process.}, vol. 27, no. 3, pp. 199-208, Mar. 2013.

\bibitem{Dydek2013} Z. T. Dydek, A. M. Annaswamy, J. J. E. Slotine, and E. Lavretsky, ``Composite adaptive posicast control for a class of LTI plants with known delay,'' \textit{Automatica}, vol. 49, pp. 1914-1924, Jun. 2013.


\bibitem{Chowdhary2010a} G. V. Chowdhary and E. N. Johnson, ``Concurrent learning for convergence in adaptive control without persistency of excitation,'' in Proc. \textit{IEEE Conf. Decision Control}, Atlanta, GA, 2010, pp. 3674-3679.

\bibitem{Chowdhary2014} G. V. Chowdhary, M. Muhlegg, and E. N. Johnson,``Exponential parameter and tracking error convergence guarantees for adaptive controllers without persistency of excitation,'' \textit{Int. J. Control}, vol. 87, no. 8, pp. 1583-1603, May 2014.

\bibitem{Chowdhary2011} G. V. Chowdhary and E. N. Johnson, ``Theory and flight-test validation of a concurrent-learning adaptive controller,'' \textit{J. Guid. Control Dyn.}, vol. 34, no. 2, pp. 592-607, 2011.

\bibitem{Antsaklis1995} P. J. Antsaklis, ``Intelligent learning control,'' \textit{IEEE Control Syst. Mag.}, vol. 15, no. 3, pp. 5-7, Jun. 1995.

\bibitem{Hu2013} J. C. Hu and H. H. Zhang, ``Immersion and invariance based command-filtered adaptive backstepping control of VTOL vehicles,'' \textit{Automatica}, vol. 49, no. 7, pp. 2160-2167, Jul. 2013.

\bibitem{Volyanskyy2010} K. Y. Volyanskyy, W. M. Haddad, and A. J. Calise, ``A new neuroadaptive control architecture for nonlinear uncertain dynamical systems: beyond - and e-modifications,'' \textit{IEEE Trans. Neural Netw.}, vol. 20, no. 11, pp. 1707-1723, Nov. 2009.

\bibitem{Joshi1998} S. V. Joshi, A. Sreenatha, and J. Chandrasekhar, ``Suppression of wing rock of slender delta wings using a single neuron controller,'' \textit{IEEE Trans. Autom. Control Syst. Tech.}, vol. 6, pp. 671-677, Sep. 1998.

\bibitem{Pan2013a} Y. P. Pan and M. J. Er, ``Enhanced adaptive fuzzy control with optimal approximation error convergence,'' \textit{IEEE Trans. Fuzzy Syst.}, vol. 21, no. 6, pp. 1123-1132, Dec. 2013.

\bibitem{Pan2015} Y. P. Pan and H. Y. Yu, ``Dynamic surface control via singular pertu\-rbation analysis,'' \textit{Automatica},vol. 51, pp. 29-33, Jul. 2015.





\end{thebibliography}




\end{document}
