\documentclass{llncs}
\pdfoutput=1

\usepackage[ruled,linesnumbered,noend]{algorithm2e} \usepackage{amsmath} \usepackage{amssymb} \usepackage{cases}

\usepackage{pgfplots}\usepackage{xspace}

\usepackage{graphicx} \usepackage{microtype}

\usepackage{wrapfig} 

\clearpage{}
\newcommand{\centre}[1]{z_{#1}}
\newcommand{\centres}{Z}
\newcommand{\argmax}{\operatorname{argmax}}
\newcommand{\diam}{\operatorname{diam}}
\newcommand{\dist}{\operatorname{dist}}
\newcommand{\ord}{\operatorname{ord}}
\newcommand{\M}{\mathbf{M}}
\newcommand{\LL}{\mathbf{L}}
\newcommand{\f}{\hat{f}}
\newcommand{\e}{\mathbf{e}}
\newcommand{\dhat}{\overline{d}}
\newcommand{\llminimal}{-minimal\xspace}

\newcommand{\ie}{i.\,e.\xspace}
\newcommand{\iec}{i.\,e.,\xspace}
\newcommand{\eg}{e.\,g.\xspace}
\newcommand{\egc}{e.\,g.,\xspace}
\newcommand{\etal}{et al.\xspace}
\newcommand{\Wlog}{w.\,l.\,o.\,g.\ }
\newcommand{\wrt}{w.\,r.\,t.\xspace}

\newcommand{\bter}{BTER\xspace}
\newcommand{\didic}{\textsc{DiDiC}\xspace}
\newcommand{\dibap}{\textsc{DibaP}\xspace}
\newcommand{\bubble}{\textsc{Bubble}\xspace}
\newcommand{\bubfosc}{\textsc{Bubble-FOS/C}\xspace}
\newcommand{\kappart}{\textsc{KaPPa}\xspace}
\newcommand{\metis}{\textsc{METIS}\xspace}
\newcommand{\kmetis}{\textsc{kMETIS}\xspace}
\newcommand{\parmetis}{\textsc{ParMETIS}\xspace}
\newcommand{\jostle}{\textsc{JOSTLE}\xspace}
\newcommand{\psiconsol}{\textsc{TruncCons}\xspace}
\newcommand{\consol}{\texttt{Consolidation}\xspace}
\newcommand{\consols}{\texttt{Consolidations}\xspace}
\newcommand{\asspart}{\texttt{AssignPartition}\xspace}
\newcommand{\compcen}{\texttt{ComputeCenters}\xspace}
\newcommand{\trunccons}{\textsc{TruncCons}\xspace}
\newcommand{\graclus}{\textsc{Graclus}\xspace}
\newcommand{\h}[1]{\ensuremath{h(#1)}}

\newcommand{\disjcup}{\mathop{\dot{\cup}}}

\newcommand{\Aut}{\operatorname{Aut}}
\newcommand{\Pro}[1]{\mathbf{Pr} \left[\,#1\,\right]}
\newcommand{\pro}[1]{\mathbf{Pr} [\,#1\,]}
\newcommand{\Ex}[1]{\mathbb{E} \left[\,#1\,\right]}
\newcommand{\ex}[1]{\mathbb{E} [\,#1\,]}
\newcommand{\hit}{- [\pi]_s (H[v,s]-H[u,s])}

\clearpage{}

\newcommand{\pointset}{\ensuremath{\mathrm{P}}\xspace}
\newcommand{\neighborset}{\ensuremath{\mathrm{N}}}
\newcommand{\candidateset}{\ensuremath{\mathrm{Candidates}}}
\newcommand{\cellset}{\ensuremath{\mathrm{Cells}}}
\newcommand{\overhangset}{\ensuremath{\mathrm{Overhang}}\xspace}
\newcommand{\without}{\ensuremath{\backslash}}
\newcommand{\ringset}{\ensuremath{\varsigma}\xspace}
\newcommand{\containedset}{\ensuremath{\mathrm{Contained}}\xspace}


\newcommand{\TODO}[1]{\todo[size=\small, inline]{#1}}
\newcommand{\hmey}[1]{\textcolor{orange}{[HM: #1]}\xspace}
\newcommand{\mvl}[1]{\textcolor[rgb]{0,0.6,0}{[MvL: #1]}\xspace}
\newcommand{\old}[1]{}


\renewcommand{\floatpagefraction}{0.95}



\pagestyle{plain}

\DeclareMathOperator*{\argmin}{arg\,min}
\begin{document}

\title{Querying Probabilistic Neighborhoods \\ in Spatial Data Sets Efficiently}
\institute{\{moritz.looz-corswarem, meyerhenke\}@kit.edu\\Institute of Theoretical Informatics, Karlsruhe Institute of Technology (KIT), Germany}
\author{Moritz von Looz \and Henning Meyerhenke}




\maketitle

\begin{abstract}
The probability that two spatial objects establish some kind of mutual connection often depends on their proximity.
To formalize this concept, we define the notion of a \emph{probabilistic neighborhood}:
Let  be a set of  points in ,   a query point,  a distance metric, and  a monotonically decreasing function.
Then, the probabilistic neighborhood  of  with respect to  is 
a random subset of  and each point  belongs to  with probability .
Possible applications include query sampling and the simulation of probabilistic spreading phenomena, as well as other scenarios where the probability of a connection between two entities decreases with their distance.
We present a fast, sublinear-time query algorithm to sample probabilistic neighborhoods from planar point sets.
For certain distributions of planar , we prove that our algorithm answers a query in  time with high probability.
In experiments this yields a speedup over pairwise distance probing of at least one order of magnitude, even for rather small data sets with  and also for other point distributions not covered by the theoretical results.


\end{abstract}


\section{Introduction}
\label{sec:introduction}


In many scenarios, connections between spatial objects are not certain but probabilistic, with the probability depending on the distance between them:
The probability that a customer shops at a certain physical store shrinks with increasing distance to it.
In disease simulations, if the social interaction graph is unknown but locations are available, disease transmission 
can be modeled as a random process with infection risk decreasing with distance.
Moreover, the wireless connections between units in an ad-hoc network are fragile and collapse more frequently with higher 
distance. 

For these and similar scenarios, we define the notion of a \emph{probabilistic neighborhood} in spatial data sets:
Let a set  of  points in , a query point , a distance metric , 
and a monotonically decreasing function  be given.
Then, the probabilistic neighborhood  of  with respect to  is 
a random subset of  and each point  belongs to  with probability .
A straightforward query algorithm for sampling a probabilistic neighborhood
would iterate over each point  and sample for each whether it is included in .
This has a running time of  per query point, which is prohibitive for repeated queries in large data sets.
Thus we are interested in a faster algorithm for such a \emph{probabilistic neighborhood query} (PNQ, spoken as ``pink'').
We restrict ourselves to the planar case in this work, but the algorithmic principle is generalizable to higher dimensions.

While the linear-time approach has appeared before in the literature for a particular application~\cite{Aldecoa2015} (without formulating the problem as a PNQ explicitly), we are not aware of previous work performing more efficient PNQs 
with an index structure. For example, the probabilistic quadtree introduced by Kraetzschmar \etal~\cite{kraetzschmar2004probabilistic} 
is designed to store probabilistic occupancy data and gives deterministic results.
Other range queries related to (yet different from) our work as well as deterministic index structures are described in Section~\ref{sec:related}.

\paragraph{Contributions.}
We develop, analyze, implement, and evaluate an index structure and a query algorithm that 
together provide fast probabilistic neighborhood queries in the Euclidean and hyperbolic plane.
Our key data structure for these fast PNQs is a polar quadtree which we adapt from our previous work~\cite{Looz2015HRG}.
Preprocessing for quadtree construction requires  time with high probability\footnote{We say ``with high probability'' (whp) when 
referring to a probability  for sufficiently large .} (whp).

To answer PNQs, we first present a simple query algorithm (Section~\ref{sec:baseline}).
We then improve its time complexity by treating whole subtrees as so-called virtual leaves, see Section~\ref{sec:subtree-aggr}.
As shown by our detailed theoretical analysis, the improved algorithm yields a query
time complexity of  whp to find a probabilistic neighborhood  among  points, for  sufficiently large. This is sublinear if the returned neighborhood  is of size 
-- an assumption we consider reasonable for most applications.
For our theoretical results to hold, the quadtree structure needs to be able to partition the distribution of the point positions in , \ie not all of the probability mass may be concentrated on a single point or line.
In our case of polar quadtrees, this is achieved if the distribution is continuous, integrable, rotationally invariant 
with respect to the origin and non-zero only for a finite area.

Experimental results are shown in Section~\ref{sec:applications}: We apply our query algorithm to generate random graphs
in the hyperbolic plane~\cite{Krioukov2010} in subquadratic time. Graphs with millions of edges can now be generated 
within a few minutes sequentially.
This yields an acceleration of at least one order of magnitude in practice compared to a reference implementation~\cite{Aldecoa2015} that uses linear-time queries. Compared to our previous work on graph generation~\cite{Looz2015HRG}, 
our new algorithm is able to generate a more extensive model.
Even if the distribution of a given point set  is unknown in practice, running times are fast:
As an example of probabilistic spreading behavior, we simulate a simple disease spreading mechanism on real population density geodata.
In this scenario, our fast PNQs are at least two orders of magnitude faster than linear-time queries.

\section{Preliminaries}
\label{sec:prelim}

\subsection{Notation}
\label{sub:notation}
\newcommand{\hyperbolic}{\ensuremath{\mathbb{H}}}
\newcommand{\Euclidean}{\ensuremath{\mathbb{E}}}
Let the input be given as set  of  points. 
The points in  are distributed in a disk  of radius  in the hyperbolic or Euclidean plane, the distribution is given by a probability density function  for an angle  and a radius .
Recall that, for our theoretical results to hold, we require  to be known, continuous and integrable.
Furthermore,  needs to be rotationally invariant -- meaning that  for any radius  and any two angles  and  -- and positive within  ,
so that .
Due to the rotational invariance,  is the same for every  and we can write .
Likewise, we define  as the indefinite integral of  and normalize it so that  (also implying ). The value  then gives the fraction of probability mass inside radius .

For the distance between two points  and , we use  for the hyperbolic and  for the Euclidean case.
We may omit the index if a distinction is unnecessary.
As mentioned, a point  is in the probabilistic neighborhood of query point  with probability .
Thus, a \emph{query pair} consists of a query point  and a function  that maps distances to probabilities.
The function  needs to be monotonically decreasing but may be discontinuous. Note that  can be 
defined differently for each query.
The query result, the probabilistic neighborhood of  \wrt , is denoted by the set .

For the algorithm analysis, we use two additional sets for each query :
\begin{itemize}
 \item : neighbor candidates examined when executing such a query,
 \item : quadtree cells examined during execution of the query.
\end{itemize}
Note that the sets  and  are probabilistic, thus theoretical results about their size are usually only with high probability.

\subsection{Related Work}
\label{sec:related}
\paragraph{Fast deterministic range queries.}
Numerous index structures for fast range queries on spatial data exist.
Many such index structures are based on trees or variations 
thereof, see Samet's book~\cite{Samet:2005:FMM:1076819} for a comprehensive overview.
I/O efficient worst case analysis is usually performed using the EM model,
see \eg~\cite{Arge:2012:ISD:2367574.2367575}. In more applied settings, average-case performance is of
higher importance, which popularized R-trees or newer variants thereof, \eg~\cite{Kamel:1994:HRI:645920.673001}.
Concerning (balanced) quadtrees for spatial dimension , it is known that queries require  time
(thus  in the planar case)~\cite[Ch.~1.4]{Samet:2005:FMM:1076819}.
Regarding PNQs our algorithm matches this query complexity up to a logarithmic factor.
Yet note that, since for general  and  in our scenario all points in the set  could be neighbors, 
data structures for deterministic queries cannot solve a PNQ efficiently without adaptations.

Hu et al.~\cite{Hu2014independent} give a query sampling algorithm for one-dimensional data that,
given a set  of n points in ,  an interval  and an integer, , returns  elements uniformly sampled from .
They describe a structure of  space that answers a query in  time and supports updates in  time.
While also offering query sampling, PNQs differ from the problem considered by Hu et al. in two aspects: We consider two dimensions instead of one and our sampling probabilities are not necessarily uniform,
but can be set by the user by a distance-dependent function.


\paragraph{Range queries on uncertain data.}
During the previous decade probabilistic queries \emph{different} from PNQs have become popular.
The main scenarios can be put into two categories~\cite{pei2008query}: (i) Probabilistic databases contain entries
that come with a specified confidence (\eg sensor data whose accuracy is uncertain) and
(ii) objects with an uncertain location, \ie the location is specified by a probability distribution.
Both scenarios differ under typical and reasonable assumptions from ours: 
Queries for uncertain data are usually formulated to return \emph{all} points in the neighborhood
whose confidence/probability exceeds a certain threshold~\cite{kriegel2007probabilistic},
or computing points that are possibly nearest neighbors~\cite{agarwal2013nearest}.

In our model, in turn, the choice of inclusion of a point  is a random choice for every different . In particular, 
depending on the probability distribution, \emph{all}
nodes in the plane can have positive probability to be part of some other's neighborhood.
In the related scenarios this would only be true with extremely small confidence values or extremely
large query circles.

\paragraph{Applications in fast graph generation.}
One application for PNQs as introduced in Section~\ref{sec:introduction} is the hyperbolic random graph model by Krioukov \etal~\cite{Krioukov2010}. The  graph nodes are represented by points 
thrown into the hyperbolic plane at random\footnote{The probability density in the polar model depends only on radii  and  as well as a growth parameter  and is given by .} and
two nodes are connected by an edge with a probability that decreases with
the distance between them. An implementation of this generative model is
available~\cite{Aldecoa2015}, it performs  neighborhood tests. 
Bringmann et al. provide an algorithm to generate hyperbolic random graphs in expected linear time~\cite{bringmann2015geometric}; to our knowledge no implementation of it exists yet.

In previous work we designed a  
generator~\cite{Looz2015HRG} faster than~\cite{Aldecoa2015} for a restricted model; it runs in 
time whp for the whole graph with  edges. The range queries discussed there are facilitated by a quadtree 
which supports only deterministic queries. Consequently, the queries result in unit-disk graphs in the hyperbolic plane 
and can be considered as a special case of the current work (a step function  with values 0 and 1 results in a deterministic query).

Our major technical inspiration for enhancing the quadtree for probabilistic neighborhoods is the work of 
Batagelj and Brandes~\cite{batagelj2005efficient}. They were the first to present a random sampling 
method to generate Erd\H{o}s-R\'{e}nyi-graphs with  nodes and  edges in  time complexity.
Faced with a similar problem of selecting each of  elements with a constant probability , they designed an 
efficient algorithm (see Algorithm~\ref{algo:fast-batagelji-brandes} in Appendix~\ref{sec:fast-batagelji-brandes}).
Instead of sampling each element separately, they use random jumps of length ,
, with  being a random number uniformly distributed in .


\subsection{Quadtree Specifics}
\label{sub:prelim-quadtree}
Our key data structure is a polar region quadtree in the Euclidean or hyperbolic plane.
While they are less suited to higher dimensions as for example k-d-trees, the complexity is comparable in the plane.
For the (circular) range queries we discuss, quadtrees have the significant advantage of a bounded aspect ratio:
A cell in a k-d-tree might extend arbitrarily far in one direction, rendering theoretical guarantees about the area affected by the query circle difficult to impossible.
In contrast, the region covered by a quadtree cell is determined by its position and level.

We mostly reuse our previous definition~\cite{Looz2015HRG} of the quadtree:
A node in the quadtree is defined as a tuple 
with  and .
It is responsible for a point  exactly if
 and .
We call the region represented by a particular quadtree node its quadtree \emph{cell}.
The quadtree is parametrized by its radius , the  of the root cell.
If the probability distribution  is known (which we assume for our theoretical results), 
we set the radius  to , \ie to the minimum radius that contains the full probability mass.
If only the points are known, the radius is set to include all of them.
While in this latter case the complexity analysis of Section~\ref{sec:baseline} and~\ref{sec:subtree-aggr} does not hold,
fast running times in practice can still be achieved (see Section~\ref{sec:applications}).

 
\section{Baseline Query Algorithm}
\label{sec:baseline}
We begin the main technical part by describing adaptations in the quadtree construction as well as
a baseline query algorithm. This latter algorithm introduces the main idea, but is asymptotically not faster than the 
straightforward approach. In Section~\ref{sec:subtree-aggr} it is then refined to support faster queries.

\subsection{Quadtree Construction}
\label{sub:qt-augment}
\begin{wrapfigure}[18]{R}{0.4\linewidth}
 \centering
\vspace{-3\baselineskip}
 \includegraphics[width=0.9\linewidth]{visualization-point-probabilities}
 \caption{Query over 200 points in a polar hyperbolic quadtree, with  and the query point  marked by a red cross.
Points are colored according to the probability that they are included in the result. Blue represents a high probability, white a probability of zero.}
\label{fig:visualization-point-probabilities}
\end{wrapfigure}

At each quadtree node , we store the size of the subtree rooted there.
We then generalize the rule for node splitting to handle point distributions  as defined
in Section~\ref{sub:notation}:
As is usual for quadtrees, a leaf cell  is split into four children when it exceeds its fixed capacity.
Since our quadtree is polar, this split happens once in the angular and once in the radial direction.
Due to the rotational symmetry of , splitting in the angular direction is straightforward as the angle range is halved: .
For the radial direction, we choose the splitting radius to result in an equal division of probability mass.
The total probability mass in a ring delimited by  and  is .
Since  is positive for  between  and 0, the restricted function  defined above is a bijection.
The inverse  thus exists and we set the splitting radius  to .

Figure~\ref{fig:visualization-point-probabilities} visualizes a point distribution on a hyperbolic disk with 200 points
and Figure~\ref{fig:quadtree-example} its corresponding quadtree.

\begin{figure}[b]
 \includegraphics[width=\linewidth]{visualization-prob-quadtree}
 \caption{Visualization of the data structure used in Figure~\ref{fig:visualization-point-probabilities}.
 Quadtree nodes are colored according to the upper probability bound for points contained in them.
 The color of a quadtree node  is the darkest possible shade (dark = high probability) of any point contained in the subtree rooted at .
 Each node is marked with the number of points in its subtree.}
  \label{fig:quadtree-example}
 \end{figure}

Two results on quadtree properties help to establish the time complexity of quadtree operations.
They are generalized versions of our previous work~\cite[Lemmas~1 and~2]{Looz2015HRG} and state that each quadtree cell contains the same expected number of points and that the quadtree height is  whp (proofs in Appendix~\ref{sec:basic-qt-proofs}).

\begin{lemma}
Let  be a hyperbolic or Euclidean disk of radius ,  a probability distribution on  which fulfills the properties defined in Section~\ref{sub:notation},  a point in  which is sampled from , and  be a polar quadtree on .
Let  be a quadtree cell at depth . Then, the probability that  is in  is .
\label{lemma:node-cell-probabilities}
\end{lemma}
\begin{lemma}
Just as in Lemma~\ref{lemma:node-cell-probabilities}, 
let  be a hyperbolic or Euclidean disk of radius ,  a probability distribution on  which fulfills the properties defined in Section~\ref{sub:notation}, and  be a polar quadtree on .
The expected number of  nodes in  is then in .
\label{lemma:bound-number-quadtree-cells}
\end{lemma}
\begin{proposition}
 \label{thm:quadtree-height}
Let  and  be as in Lemma~\ref{lemma:node-cell-probabilities}.
Let  be a polar quadtree on  constructed to fit .
Then, for  sufficiently large,  whp.
\end{proposition}

A direct consequence from the results above and our previous work~\cite{Looz2015HRG} is the preprocessing
time for the quadtree construction. The generalized splitting rule and storing the subtree sizes only change constant factors.

\begin{corollary}
\label{cor:qt-construction}
Since a point insertion takes  time whp, constructing a quadtree on  points distributed as 
in Section~\ref{sub:notation} takes  time whp.
\end{corollary}

\subsection{Algorithm}
\label{sub:baseline-algo}
The baseline version of our query (Algorithm~\ref{algo:quadnode-probabilistic}) has unfortunately a time complexity of , but serves as a foundation for the fast version (Section~\ref{sec:subtree-aggr}).
It takes as input a query point , a function  and a quadtree cell .
Initially, it is called with the root node of the quadtree and recursively descends the tree.
The algorithm returns a point set  with


\begin{algorithm}[tb]
 \KwIn{query point , prob.\ function , quadtree node }
 \KwOut{probabilistic neighborhood of \textit{q}}
 \;
  )\;\label{line:distanceLB} \tcc{Distance between point and cell}
 =)\;\label{line:probUB} \tcc{Since  is monotonically decreasing, a lower bound for the distance gives an upper bound  for the probability.}
  = number of points in \;
 \If{ is not leaf}{\label{line:notleafcell}
 \tcc{internal node: descend, add recursive result to local set}
 \For{child  children()}{
   add getProbabilisticNeighborhood(, , child) to \neighborset \;\label{line:calling-child}
 }
}
 \Else{\tcc{leaf case: apply idea of Batagelj and Brandes~\cite{batagelj2005efficient}} 
 \For{i=0;  ; i++}{\label{line:loop-iteration} \label{line:candidate-loop}
 \;\label{line:deltaskip}
  += \;\label{line:jumptarget}
 \If{}{
 break\;
 }
  = , c.points[]))/\;\label{line:candidate-confirmation}
 add c.points[] to  with probability \label{line:add-confirmed}
 }
 }
 \Return{}
 \caption{QuadNode.getProbabilisticNeighborhood}
 \label{algo:quadnode-probabilistic}
\end{algorithm}

Algorithm~\ref{algo:quadnode-probabilistic} descends the quadtree recursively until it reaches the leaves.
Once a leaf  is reached, a lower bound  for the distance between the query point  and all the points in  is computed (Line~\ref{line:distanceLB}). Such distance calculations are detailed in Appendix~\ref{sec:distance}.
Since  is monotonically decreasing, this lower bound for the distance gives an upper bound  for the probability that a given point in  is a member of the returned point set (Line~\ref{line:probUB}).
This bound is used to select \emph{neighbor candidates} in a similar manner as Bategelj and Brandes~\cite{batagelj2005efficient}: 
In Line~\ref{line:deltaskip}, a random number of vertices is skipped, so that every vertex in  is selected as a neighbor candidate with probability .
The actual distance  between a candidate  and the query point  is at least  and the probability of  thus at most .
For each candidate, this actual distance  is then calculated and a neighbor candidate is confirmed as a neighbor with probability  in Line~\ref{line:candidate-confirmation}.

Regarding correctness and time complexity of Algorithm~\ref{algo:quadnode-probabilistic}, we can state:

\begin{proposition}
Let  be a quadtree as defined above,  be a query point and  a monotonically decreasing function
which maps distances to probabilities.
The probability that a point  is returned by a PNQ () from Algorithm~\ref{algo:quadnode-probabilistic} is ,
independently from whether other points are returned.
\label{lemma:independent-correct-probabilities}
\end{proposition}

\begin{proposition}
\label{cor:basic-time}
Let  be a quadtree with  points.
The running time of Algorithm~\ref{algo:quadnode-probabilistic} per query on  is  in expectation.
\end{proposition}
The proofs can be found in Appendices~\ref{sub:proof-lemma-indep} and \ref{sec:proof-cor-basic-time}.

\section{Queries in Sublinear Time by Subtree Aggregation}
\label{sec:subtree-aggr}
One reason for the linear time complexity of the baseline query is the fact that every quadtree node is visited.
To reach a sublinear time complexity, we thus aggregate subtrees into \emph{virtual leaf cells} whenever doing so reduces the number of examined cells and does not increase the number of candidates too much.

To this end, let  be a subtree starting at depth  of a quadtree .
During the execution of Algorithm~\ref{algo:quadnode-probabilistic}, a lower bound  for the distance between  and the query point  is calculated,
yielding also an upper bound  for the neighbor probability of each point in .
At this step, it is possible to treat  as a \emph{virtual leaf cell}, sample jumping widths using  as upper bound and use these widths to select candidates within .
Aggregating a subtree to a virtual leaf cell allows skipping leaf cells which do not contain candidates, but uses a weaker bound  and thus a potentially larger candidate set.
Thus, a fast algorithm requires an aggregation criterion which keeps both the number of candidates and the number of examined quadtree cells low.

As stated before, we record the number of points in each subtree during quadtree construction.
This information is now used for the query algorithm:
We aggregate a subtree  to a virtual leaf cell exactly if , the number of points contained in , is below .
This corresponds to less than one expected candidate within .
The changes required in Algorithm~\ref{algo:quadnode-probabilistic} to use the subtree aggregation are minor.
Lines~\ref{line:notleafcell}, \ref{line:candidate-confirmation} and \ref{line:add-confirmed} are changed to:

\LinesNotNumbered
\begin{algorithm}[H]
\nlset{5} \textbf{if}\emph{ is inner node and }\textbf{ then}
\end{algorithm}

\begin{algorithm}[H]
 \nlset{14} neighbor = maybeGetKthElement(, , , , )\;
 \nlset{15} add neighbor to  if not null
\end{algorithm}

The main change consists in the use of the function maybeGetKthElement (Algorithm~\ref{algo:maybe-get-kth-element}, Appendix~\ref{sec:maybe-get-kth-element}).
Given a subtree , an index , , , and , this function descends  to the leaf cell containing the
th element. This element  is then accepted with probability .

Since the upper bound calculated at the root of the aggregated subtree is not smaller than the individual upper bounds at the original leaf cells, Proposition~\ref{lemma:independent-correct-probabilities} also holds for the virtual leaf cells. This establishes the correctness.

The time complexity is given by the following theorem, whose proof can be found in Appendix~\ref{sec:proof-subtree-aggregation-complexitx}.


\begin{theorem}
Let  be a quadtree with  points and  a query pair.
A query  using subtree aggregation has time complexity  whp.
\label{lemma:subtree-aggregation-complexity}
\end{theorem}

\section{Application Case Studies}
\label{sec:applications}
In order to test our algorithm for PNQs, we apply it in two application case studies,
one for Euclidean, the other one for hyperbolic geometry. For the Euclidean case study
we build a simple disease spread simulation as an example for a probabilistic spreading process.
The probability distribution of points is in this case non-uniform and unknown. The hyperbolic application, in turn, is a 
generator for complex networks with a known point distribution. 

\subsection{Probabilistic Spreading}
\label{sub:disease-sim}
When both contact graph and travel patterns of a susceptible population are not known in detail, the resulting spreading behavior of an infectious disease seems probabilistic.
Contagious diseases usually spread to people in the vicinity of infected persons, but an infectious person occasionally bridges larger distances by travel and spreads the disease this way.
We model this effect with our probabilistic neighborhood function , giving a higher probability for small distances and a lower but non-zero probability for larger distances.
Note that this scenario is meant as an example of the probabilistic spreading simulations possible with our algorithm and not as highly realistic from an epidemiological point of view.

In the simulation, the population is given as a set  of points in the Euclidean plane.
 In the initial step, exactly one point (= person) from  is marked as infected. 
Then, in each round, a PNQ is performed
for each infected person .
All points in  become infected in the next round.
We use an SIR model~\cite{hethcote2000mathematics}, \ie previously infected persons recover with a 
certain probability in each round and stay infectious otherwise.
In our simulation, persons recover with a rate of 0.8 and are then immune.

\subsection{Random Hyperbolic Graph Generation}
\label{sec:application-hyperbolic-random-graphs}
Random hyperbolic graphs (RHGs, also see Section~\ref{sec:related}) are a generative graph model for
complex networks. For graph generation one places  points (= vertices) randomly in a hyperbolic disk.
The radius  of the disk can be used to control the average degree of the network.
A pair of vertices is connected by an edge with a probability that depends on the vertices' hyperbolic distance.
This connection probability is given in~\cite[Eq.~(41)]{Krioukov2010} and parametrized by a temperature :

This definition of random hyperbolic graphs is a generalized version of the one considered in our previous work, which was restricted to the special case of .

\subsection{Experimental Settings and Results}
\label{sub:exp-results}
Our implementation uses the NetworKit toolkit~\cite{staudt2014networkit} and is 
written in C++ 11. It is included in NetworKit release 4.1.
Running time measurements were made with g++ 4.8 -O3 on a machine with 128 GB RAM
and an Intel Xeon E5-1630 v3 CPU with four cores at 3.7 GHz base frequency. 
Our code is sequential, as is the reference implementation for random hyperbolic graph
generation~\cite{Aldecoa2015}.

\paragraph{Disease Spread Simulation.}
We experimented on three data sets
taken from NASA population density raster 
data~\cite{nasaGridPop} for Germany, France and the USA. They consist of rectangles with small square cells
(geographic areas) where for each cell the population from the year 2000 is given.
To obtain a set of points, we randomly distribute points in each cell to fit 1/20th of the population density.
Figure~\ref{plot:heatMap-and-hyperbolic-disk} (left) in the appendix shows an example with roughly 4 million points on the map of Germany.
The data sets of France and USA have roughly 3 and 14 million points, respectively.

The number of required queries naturally depends heavily on the simulated disease.
For our parameters, a number of 5000 queries is typically reached within the first dozen steps.
To evaluate the algorithmic speedup, Table~\ref{table:running-time-queries-country} compares running times for 5000 pairwise
distance probing (PDP) queries against 5000 fast PNQs on the three country datasets.
To obtain a similar total number of infections, we use a slightly different probabilistic neighborhood function for each country and divide by the population: .
This results in a slower initial progression for the US.
Our algorithm achieves a speedup factor of at least two orders of magnitude, even including the quadtree construction time.

\begin{table}[bt]
\centering 
\begin{tabular}{l|l|l|l}
 Country & 5000 PDP queries & Construction QT & 5000 QT queries\\
 \hline
 France & 1007 seconds & 1.6 seconds & 1.2 seconds\\ 
 Germany & 1395 seconds & 2.8 seconds & 1.3 seconds\\
 USA & 4804 seconds & 8.7 seconds & 0.7 seconds
\end{tabular}
\smallskip 
\caption{Running time results for polar Euclidean quadtrees on population data.
The query points were selected uniformly at random from , the probabilistic neighborhood function is .
}
\label{table:running-time-queries-country}
\end{table}


\paragraph{Random Hyperbolic Graph Generation.}
An example graph generated from hyperbolic geometry can be seen in Figure~\ref{plot:heatMap-and-hyperbolic-disk} (right) in the appendix.
We compare our generator using PNQs with the only (to our knowledge) previously existing generator for general random hyperbolic graphs~\cite{Aldecoa2015}, \ie those not only following the threshold model.
As seen in Figure~\ref{plot:time-scatter}, our implementation is faster by at least one order of magnitude and the experimental running times support our theoretical time complexity of .
A comparison of the generated graphs with those created by the existing implementation can be found in Appendix~\ref{sec:comparison-previous-impl}. The differences measured by a set of suitable network analysis metrics are within the
range of random fluctuations for the sample size of .

\definecolor{markedcolor}{RGB}{31,120,180}
\definecolor{plottinggreen}{RGB}{178,223,138}
\definecolor{thirdhue}{RGB}{228,26,28}
\newcommand{\aconst}{5.605}
\newcommand{\bconst}{2.18}
\newcommand{\cconst}{1.77}
\begin{figure}[tb]
\centering

 \begin{tikzpicture}[scale=0.9]
 \begin{axis}[ymode=log,xmode=log,xlabel=nodes,ylabel=running time in seconds,legend entries={}, legend pos=outer north east]
 \addplot[only marks, thirdhue] table {plots/1465982453.5281825-cost-native.dat};\addlegendentry{implementation of \cite{Aldecoa2015}};
  \addplot[only marks, plottinggreen] table {plots/1465988533.119531-cost-PNQs-single-threaded.dat};\addlegendentry{our implementation};
  \addplot[thirdhue] expression[domain=512:400000] {2.089 * 10^(-7)*x^2 + 3.311*10^(-4)*x};\addlegendentry{};
  \addplot[plottinggreen] expression[domain=512:1600000] {\aconst *10^(-6)*x + \bconst * 10^(-6)*x*sqrt(x)};\addlegendentry{};
 \end{axis}
\end{tikzpicture}

 \caption{Comparison of running times to generate networks with - vertices, , 0.5 and average degree . The gap between the running times widens, which in the loglog-plot implies a different exponent in the time complexities.
 Running times are fitted with , ,  and . }
 \label{plot:time-scatter}
\end{figure}


\section{Conclusions}
After formally defining the notion of probabilistic neighborhoods, we have presented a
quadtree-based query algorithm for such neighborhoods in the Euclidean and hyperbolic plane.
Our analysis shows a time complexity of , our algorithm is to the best of our knowledge the first to solve the problem asymptotically faster than pairwise distance probing.
With two example applications we have shown that our algorithm is also faster 
in practice by at least one order of magnitude.


\paragraph{Acknowledgements.}
This work is partially supported by German Research Foundation (DFG) grant ME 3619/3-1 within the 
Priority Programme 1736 \emph{Algorithms for Big Data}. The authors thank Mark Ortmann for helpful discussions.


\bibliographystyle{plain}
\bibliography{ProbabilisticQuadtree}

\clearpage
\appendix

\section{Related Algorithmic Idea}
\label{sec:fast-batagelji-brandes}
Our approach was inspired by the following algorithm with optimal linear running time
for Erd\H{o}s-R\'{e}nyi graph generation~\cite{batagelj2005efficient}.

\begin{algorithm}[H]
\KwIn{number of vertices , edge probability }
\KwOut{} 
  = \;
  = 1\;
  = -1\;
 \While{}{
 draw  uniformly at random\;
 \;
 \While{ and }{
 \;
 \;
 }
 \If{}
 {add  to }
 } 
 \caption{Efficient neighborhood generation for Erd\H{o}s-R\'{e}nyi graphs~\cite{batagelj2005efficient}.}
 \label{algo:fast-batagelji-brandes}
\end{algorithm}

\section{Proofs of Section~\ref{sec:baseline}}
\label{sec:basic-qt-proofs}

\subsection{Proof of Lemma~\ref{lemma:node-cell-probabilities}}
\label{sub:proof-lemma-node-cell-probabilities}
\begin{proof}
Due to the similarity of Lemma~\ref{lemma:node-cell-probabilities} to \cite[Lemma 1]{Looz2015HRG}, the proof follows a similar structure.
Let  be a quadtree cell at level , delimited by , ,  and .
As stated in Section~\ref{sub:notation}, we require the point probability distribution to be rotationally invariant.
The probability that a point  is in  is then given by 

The boundaries of the children of  are given by the splitting rules in Section~\ref{sub:qt-augment}.

We proceed with induction over the depth  of .
Start of induction ( = 0):
At depth 0, only the root cell exists and covers the whole disk.
Since , .

Inductive step ():
Let  be a node at depth .
 is delimited by the radial boundaries  and , as well as the angular boundaries  and .
It has four children at depth , separated by  and . Let  be the south west child of .
With Eq.~(\ref{eq:cell-probability-mass}), the probability of  is:
.

Using Equations~(\ref{eq:angular-split}) and~(\ref{eq:radial-split}), this results in a probability of 

As per the induction hypothesis,  is  and  is thus .
Due to symmetry when selecting , the same holds for the south east child of . Together, they contain half of the probability mass of .
Again due to symmetry, the same proof then holds for the northern children as well.
\qed
\end{proof}

\subsection{Proof of Lemma~\ref{lemma:bound-number-quadtree-cells}}
\label{sub:proof-lemma-bound-number-quadtree-cells}
\begin{proof}
A quadtree  containing  points can have at most  non-empty leaf cells. We can thus bound the total number of leaf cells in  by limiting the number of empty cells.

An empty leaf cell occurs when a previous leaf cell  is split.
We consider two cases, depending on how many of the children of  contain points:

\textbf{Case 1:} All but one of the children of  are empty and all points in  are concentrated in one child.
We call a split of this kind an \emph{excess} split, since it did not result in dividing the points in .

\textbf{Case 2:} At least two children of  contain points.

The number of excess splits caused by a pair of points depends on the area they are clustered in.
Two sufficiently close points could cause a potentially unbounded number of excess splits.
However, due to Lemma~\ref{lemma:node-cell-probabilities}, each child cell contains a quarter of the probability mass of its parent cell.
Given two points  in a cell which is split, they end up in different child cells with probability 3/4.

The expected number of excess splits for a point  is thus at most\footnote{Note that the real number of excess splits might be lower, since a split might separate another point from  and .}


Due to the linearity of expectations, the expected number of excess splits caused by  points is then at most .
Each excess split causes four additional quadtree nodes, three of them are empty leaf cells.

If we remove all quadtree nodes caused by excess splits and reconnect the tree by connecting the remaining leaves
to their lowest unremoved ancestor, every inner node in the remaining tree  has at least two non-empty subtrees.
Since a binary tree with  leaves has  inner nodes~\cite{Samet:2005:FMM:1076819} and the branching factor in  is at least two,  also contains at most  inner nodes.

Together with the expected  nodes caused by excess splits, this results in  nodes in  in expectation.
\qed
\end{proof}

\subsection{Proof of Proposition~\ref{thm:quadtree-height}}
\label{sub:proof-quadtree-height}
\begin{proof}
We proved a similar lemma in previous work~\cite{Looz2015HRG}, for hyperbolic geometry only and a restricted family of probability distributions.
The requirement for that proof was that a given point  has a probability of  to land in a given cell at depth .
In Lemma~\ref{lemma:node-cell-probabilities}, we show that this requirement is fulfilled for the quadtrees used in this paper in both Euclidean and hyperbolic geometry.
We can thus reuse the proof of \cite[Lemma 2]{Looz2015HRG}, which we include for the purpose of self-containment:
\end{proof}

\subsubsection{Proof of \cite[Lemma 2]{Looz2015HRG}}
\newcommand{\variable}{n}
\newcommand{\binvariable}{n}

\begin{proof} In a complete quadtree,  cells exist at depth . For analysis purposes only, we construct such 
a complete but initially empty quadtree of height , which has at least  leaf cells.
As seen in Lemma~\ref{lemma:node-cell-probabilities}, a given point has an equal chance to land in each leaf cell.
Hence, we can apply \cite[Lemma~6]{Looz2015HRG} with each leaf cell being a bin and a point being a ball.
(The fact that we can have more than  leaf cells only helps in reducing the average load.)
From this we can conclude that, for  sufficiently large, no leaf cell of the current tree contains more than 1 point with high probability (whp).
Consequently, the total quadtree height does not exceed  whp.

Let  be the quadtree as constructed in the previous paragraph, starting with a complete quadtree of height~ and splitting leaves when their capacity is exceeded.
Let  be the quadtree created in our algorithm, starting with a root node, inserting points and also splitting leaves when necessary, growing the tree downward.

Since both trees grow downward as necessary to accommodate all points, but  does not start with a complete quadtree of height~, the set of quadtree nodes in  is a subset of the quadtree nodes in .
Consequently, the height of  is bounded by  whp as well.
\qed	
\end{proof}


\subsection{Proof of Proposition~\ref{lemma:independent-correct-probabilities}}
\label{sub:proof-lemma-indep}
\begin{proof}
Note that the hyperbolic [Euclidean] distances, which are mapped to probabilities according to the function ,
are calculated by Algorithm~\ref{algo:hyperbolic-distances}
[Algorithm~\ref{algo:Euclidean-polar-distances}], which are presented in Appendix~\ref{sec:distance} (together with their correctness proofs).
We continue the current proof with details for all three main steps.
\paragraph{Step 1:}
Between two points, the jumping width  is given by Line~\ref{line:deltaskip}.
The probability that exactly  points are skipped between two given candidates is :

Note that in Eq.~(\ref{eq:logratio}) the denominator is negative, thus the direction of the inequality is reversed in the transformation.
The transformation from Eq.~(\ref{eq:last-probability}) to Eq.~(\ref{eq:uniform-r-needed}) works since  is uniformly distributed.

Following from Eq.~(\ref{eq:waiting-times}), the probability is  for , and if a point is selected as a candidate, the subsequent point is selected with a probability of .

\paragraph{Step 2:}
Let ,  and  be points in a leaf, with  and let  be a neighbor candidate.
For now we assume that no other points in the same leaf are candidates and consider the probability that  is selected as a candidate depending on whether the intermediate point  is a candidate.

\textbf{Case 2.1:} If point  is a candidate, then point  is selected if  points are skipped after selecting .
Due to Step 1, this probability is 

\textbf{Case 2.2:} If point  is \emph{not} a candidate, then point  is selected if  points are skipped after selecting .
Given that  is not selected, at least  points are skipped.
The conditional probability is then:

As both cases yield the same result, the probability  is independent of whether  is a candidate.

\paragraph{Step 3:}
Let  be a leaf cell in which all points up to point  are selected as candidates.
Due to Step 1, the probability that  is also a candidate, meaning no points are skipped, is .
Due to Step 2, the probability of  being a candidate is independent of whether  is a candidate.
This can be applied iteratively until the beginning of the leaf cell, yielding a probability of  for  being a candidate, independent of whether other points are selected.

A neighbor candidate  is accepted as a neighbor with probability  in Line~\ref{line:candidate-confirmation}.
Since  is an upper bound for the neighborhood probability, the acceptance ratio is between 0 and 1.
The probability for a point  to be in the probabilistic neighborhood computed by Algorithm~\ref{algo:quadnode-probabilistic} is thus:

\qed
\end{proof}


\subsection{Proof of Proposition~\ref{cor:basic-time}}
\label{sec:proof-cor-basic-time}
\begin{proof}
The total time complexity of the query algorithm is determined by the number of recursive calls (Line~\ref{line:calling-child}) and the number of loop iterations (Line~\ref{line:loop-iteration}).
During tree traversal, one recursive call is made for each examined quadtree node.
During examination of a leaf, one loop iteration happens for every examined candidate.
Let the set of neighbors (), candidates () and examined cells () be as defined in Section~\ref{sub:notation}.
The time complexity of the query is then in .

All cells of the quadtree are examined, thus .
If the cells are split using the medians of point positions, then no leaf cell is empty and the tree contains at most  cells.
If cells are split using the theoretical probability distributions, the tree contains at most  cells in expectation due to Lemma~\ref{lemma:bound-number-quadtree-cells}.
It follows that the number of examined cells is in  in expectation.
Since the candidate set is a subset of the point set, the expected number of candidates is at most .
The query time complexity is then in  =  in expectation.
\qed
\end{proof}

\newcommand{\lE}{\ensuremath{\mathrm{leftExtremum}}}
\newcommand{\rE}{\ensuremath{\mathrm{rightExtremum}}}



\subsection{Distance between Quadtree Cell and Point}
\label{sec:distance}
To calculate the upper bound  used in Algorithm~\ref{algo:quadnode-probabilistic}, we need a lower bound for the distance between the query point  and any point in a given quadtree cell.
Since the quadtree cells are polar, the distance calculations might be unfamiliar and we show and prove them explicitly.
For the hyperbolic case, the distance calculations are shown in Algorithm~\ref{algo:hyperbolic-distances} and proven in Lemma~\ref{lemma:hyperbolic-distances}.
The Euclidean calculations are shown in Algorithm~\ref{algo:Euclidean-polar-distances} and proven in Lemma~\ref{lemma:Euclidean-polar-distances}.

\LinesNumbered
\begin{algorithm}
\KwIn{quadtree cell  = (, , , ), query point }
\KwOut{infimum and supremum of hyperbolic distances  to interior of }
\tcc{start with corners of cell as possible extrema}
cornerSet = \{(, ), (, ), (, ), (, )\}\;
a = \;
b = \;
\tcc{Left/Right boundaries}
leftExtremum = \label{line:left-extremum}\;
\If{}{
add  to cornerSet\;
}

b = \;
rightExtremum = \label{line:right-extremum}\;
\tcc{Top/bottom boundaries}
\If{}{
add  to cornerSet\;
}

\If{}{
add  and  to cornerSet\;
}
\;

\If{}{
add  and  to cornerSet\;
}
\tcc{If point is in cell, distance is zero:}
\If{}{
infimum = 0\;
}
\Else{
infimum = \;
}
supremum = \;
\Return{infimum, supremum};

 \caption{Infimum and supremum of distance in a hyperbolic polar quadtree}
 \label{algo:hyperbolic-distances}
\end{algorithm}


\begin{algorithm}
\KwIn{quadtree cell  = (, , , ), query point }
\KwOut{infimum and supremum of Euclidean distances  to interior of }
\tcc{start with corners of cell as possible extrema}
 cornerSet = \{(, ), (, ), (, ), (, )\}\;
\tcc{Left/Right boundaries}
\lE = \;\label{line:left-extremum-Euclidean}
\If{}{
add  to cornerSet\;
}

\rE = \;\label{line:right-extremum-Euclidean}
\If{}{
add  to cornerSet\;
}

\tcc{Top/bottom boundaries}
\If{}{
add  and  to cornerSet\;
}
\;

\If{}{
add  and  to cornerSet\;
}
\tcc{If point is in cell, distance is zero:}
\If{}{
infimum = 0\;
}
\Else{
infimum = \;
}
supremum = \;
\Return{infimum, supremum};
 \caption{Infimum and supremum of distance in a Euclidean polar quadtree}
 \label{algo:Euclidean-polar-distances}
\end{algorithm}


\pagebreak 

\begin{lemma}
 Let  be a quadtree cell and  a point in hyperbolic space.
 The first value returned by Algorithm~\ref{algo:hyperbolic-distances} is the distance of  to .
 \label{lemma:hyperbolic-distances}
\end{lemma}


\begin{proof}
When  is in , the distance is trivially zero.
Otherwise, the distance between  and  can be reduced to the distance between  and the boundary of , :

Since the boundary is closed, this infimum is actually a minimum:

The boundary of a quadtree cell consists of four closed curves:
\begin{itemize}
 \item left: 
 \item right: 
 \item lower: 
 \item upper: 
\end{itemize}
We write the distance to the whole boundary as a minimum over the distances to its parts:


All points on an angular boundary curve  have the same angular coordinate .
Let  for a fixed point .
The distance  can then be reduced to:

The minimum of  on  is the minimum of    and the value at possible extrema.
To find the extrema, we define a function .
Since  is strictly monotone,  has the same extrema as .

The factors  and  do not depend on , to increase readability we substitute them with the constants  and :

The derivative of  is thus:

With some transformations, we get the roots of :
\paragraph*{Case :}
 
For ,  has no extrema in .

\paragraph*{ :}


For  ,  has a single extremum at .
This extremum is calculated for both angular boundaries in Lines \ref{line:left-extremum} and \ref{line:right-extremum} of Algorithm~\ref{algo:hyperbolic-distances}.

If  has an extremum  in , the minimum of  on  is ,  , ,
otherwise it is ,  .

\vspace{1\baselineskip}
A similar approach works for the radial boundary curves. Let  be a radial boundary curve at radius  and angular bounds  and .
Let  be the distance to  restricted to radius .

Similarly to the angular boundaries, we define some constants and a function  with the same extrema as :


\paragraph*{Case: :}

Since  is constant, no extrema exist.

\paragraph*{Case: :}
We obtain the extrema with some transformations:

The distance function  thus has two extrema.

The minimum of  on  is then:


The distance  can thus be written as the minimum of four to ten point-to-point distances. 
Algorithm~\ref{algo:hyperbolic-distances} collects the arguments for these distances in the variable cornerSet and returns the distance minimum as the first return value.
\qed
\end{proof}


\begin{lemma}
 Let  be a polar quadtree in Euclidean space,  a quadtree cell of  and  a point in Euclidean space.
 The first value returned by Algorithm~\ref{algo:Euclidean-polar-distances} is the distance of  to .
 \label{lemma:Euclidean-polar-distances}
\end{lemma}


\begin{proof}
The general distance equation for polar coordinates in Euclidean space is


If the query point  is within , the distance is zero.
Otherwise, the distance between  and  is equal to the distance between  and the boundary of .
We consider each boundary component separately and derive the extrema of the distance function.

\paragraph{Radial boundary.}
When considering the radial boundary, everything but one angle is fixed:

Since the distance is positive and the square root is a monotone function, the extrema of the previous function are at the same values as the extrema of its square :

We set the derivative to zero to find the extrema:


\paragraph{Angular boundary.}
Similar to the radial boundary, we fix everything but the radius:


Again, we define a helper function with the same extrema:

We set the derivative to zero to find the extrema:


An extremum of  on the boundary of cell  is either at one of its corners or at the points derived in Eq.~(\ref{eq:distance-only-angle-squared-derivative}) or Eq.~(\ref{eq:distance-only-angle-radius-derivative}).
If , the minimum over these points and the corners, as computed by Algorithm~\ref{algo:Euclidean-polar-distances}, is the minimal distance between  and any point in .
If  is contained in , the distance is trivially zero.
\qed
\end{proof}

\pagebreak

\section{Algorithm maybeGetKthElement, used in Section~\ref{sec:subtree-aggr}}
\label{sec:maybe-get-kth-element}
\begin{algorithm}[H]
\KwIn{query point , function , index , bound , subtree }
\KwOut{th point of  or empty set}
\If{.isLeaf()}{
acceptance = \;
\If{  acceptance}{
\Return \;
}
\Else{
\Return \;
}
}
\Else{\tcc{Recursive call}
offset := 0\;
\For{child  .children}{
\If{}{\tcc{|child| is the number of points in \emph{child}}
\Return maybeGetKthElement(, ,  - offset, , child)\;
}
offset += \;
}
}
 \caption{maybeGetKthElement}
 \label{algo:maybe-get-kth-element}
\end{algorithm}
\clearpage



\section{Proof of Theorem~\ref{lemma:subtree-aggregation-complexity}}
\label{sec:proof-subtree-aggregation-complexitx}
\begin{proof}
Similar to the baseline algorithm, the complexity of the faster query is determined by the number of recursive calls and the total number of loop iterations across the calls.
The first corresponds to the number of examined quadtree cells, the second to the total number of candidates.
With subtree aggregation, we obtain improved bounds: Lemma~\ref{lemma:subtree-aggregation-candidates} limits the number of candidates to  whp, while Lemma~\ref{lemma:subtree-aggregation-cells} bounds the number of examined quadtree cells to  whp.
Together, this results in a query complexity of  whp.
\qed
\end{proof}

\label{subsubsec:subtree-complexity-notation}
For the lemmas required in the proof of Theorem~\ref{lemma:subtree-aggregation-complexity} we need to introduce some
notation:
Let  be a quadtree with  points,  a subtree of  containing  points,  a query point and  a function mapping distances to probabilities.
The set of neighbors (), candidates () and examined cells () are defined as in Section~\ref{sub:notation}.

For the analysis we divide the space around the query point  into infinitely many bands, based on the probabilities given by .
A point  is in band  exactly if the probability of it being a neighbor of  is between  and :

Based on these bands, we divide the previous sets into infinitely many subsets:
\begin{itemize}
 \item 
 \item 
 \item 
 \item 
\end{itemize}

Note that for fixed , all but at most finitely many of these sets are empty.
We call the quadtree cells in  to be \emph{anchored} in band .
The region covered by a quadtree cell is in general not aligned with the probability bands, thus a quadtree cell anchored in band  () may contain points from higher bands (i.e. with lower probabilities).

We continue with two auxiliary results used in Lemma~\ref{lemma:subtree-aggregation-candidates}:
Lemma~\ref{lemma:half-prob-set} helps in bounding the number of candidates that are in the same band as their (virtual or original) quadtree cell is anchored in.
Lemma~\ref{lemma:ring-root} is used to bound the number of points in a higher band than their original quadtree cell.

\newcommand{\uaqcset}{\ensuremath{\Upsilon}}
\newcommand{\subtreeset}{\ensuremath{\mathcal{\Psi}}\xspace}
\begin{lemma}
Let  be a natural number and let ,  be sets with  and the following property: , .
Further, let the probabilities for membership in  be independent.
Then, the number of points in  is in  with probability at least .
\label{lemma:half-prob-set}
\end{lemma}
\begin{proof}
Let  be a random variable denoting the size of .
Since the individual probabilities for membership in  might be different,  does not necessarily follow a binomial distribution.
We define an auxiliary distribution .
Since all membership probabilities for  are at least 0.5, lower tail bounds derived for  also hold for .

The probability that  is less than  is then~\cite{Hoe63}:


Similar to the proof of Lemma~\ref{lemma:subtree-aggregation-cells}, we conclude with a case distinction:
\paragraph{If :}
The probability  is then .
Thus  with probability at least .

\paragraph{If :}
 is then trivially in .
\qed
\end{proof}


\begin{lemma}
Let  be a polar hyperbolic [Euclidean] quadtree with  points and  a natural number.
Let  be a circle in the hyperbolic [Euclidean] plane and let \subtreeset be the disjoint set of subtrees of  that contain at most  points and are cut by .
Then, the subtrees in \subtreeset contain at most  points with probability at least  for  sufficiently large.
\label{lemma:ring-root}
\end{lemma}

\begin{proof}
This proof is adapted from \cite[Lemma 3]{Looz2015HRG}.
Let  be the minimal depth at which cells have at least  points in expectation.
At most  cells exist at depth , defined by at most  angular and  radial divisions.
When following the circumference of the query circle , each newly cut cell requires the crossing of an angular or radial division.
Each radial and angular coordinate occurs at most twice on the circle boundary, thus each division can be crossed at most twice.
With two types of divisions,  crosses at most  cells at depth .
Since the value of  is at most , this yields  cut cells.
We denote the set of cut cells with \ringset.
Since the cells in \ringset cover the circumference of the circle , a subtree  which is cut by  is either contained within one of the cells in \ringset,
corresponds to one of the cells or contains one.
In the first two cases, all points in  are within the cells of \ringset.
In the second case, at least one cell of \ringset is contained in .
As the subtrees are disjoint, this cell cannot be contained in any other of the considered subtrees.
Thus, there are no more subtrees containing points not in \ringset than there are cells in \ringset, which are less than  many.

Due to Lemma~\ref{lemma:node-cell-probabilities}, the probability that a given point is in a given cell at level  is .
The number of points contained in cells of \ringset thus follows a binomial distribution .
An upper bound for the probability  is given by , thus a tail bound for a slightly different distribution 
also holds for .
In the proof of \cite[Lemma~7]{Looz2015HRG} a similar distribution is considered.
Setting the variable  to , we see that the probability of \ringset containing more than  points is smaller than .

The subtrees in \subtreeset contain at most  points by definition,
thus an upper bound for the number of points in these subtrees is given by  (points not in \ringset) +  (points in \ringset).
This results in at most  points contained in \subtreeset with probability at least .
\qed
\end{proof}

The following Lemmas~\ref{lemma:subtree-aggregation-candidates} and~\ref{lemma:subtree-aggregation-cells} bound the number of examined candidates and examined quadtree cells and are used in the proof of Theorem~\ref{lemma:subtree-aggregation-complexity}.

\begin{lemma}
Let  be a quadtree with  points and  a query pair.
The number of candidates examined by a query using subtree aggregation is in  whp.
\label{lemma:subtree-aggregation-candidates}
\end{lemma}
\begin{proof}
For the analysis we consider each probability band  separately.
As defined above, band  contains points with a neighbor probability of  to .
Among the cells anchored in band , some are original leaf cells and others are virtual leaf cells created by subtree aggregation.
The virtual leaf cells contain less than one expected candidate and thus less than  points. The capacity of the original leaf cells is constant.
All the points in cells anchored in band  have a probability between  and  to be a candidate.
Among the points in virtual or original leaf cells, some are in the same band their cell is anchored in, others are in higher bands.

We divide the set of points within cells anchored in band  into four subsets:
\begin{enumerate}
 \item points in band  and in original leaf cells
 \item points in band  and in virtual leaf cells
 \item points not in band  and in original leaf cells
 \item points not in band  and in virtual leaf cells
\end{enumerate}

The points in the first two sets are unproblematic.
Since the probability that a point in these sets is a neighbor is at least , the probability for a given candidate to be a neighbor is at least .
Due to Lemma~\ref{lemma:half-prob-set}, the number of candidates in these sets is in  whp, which is in  whp.


Points in the third set are in cells cut by the boundary between band  and band .
Since the probabilities are determined by the distance, this boundary is a circle and we can use Lemma~\ref{lemma:ring-root} to bound the number of points to  with probability at least  for  sufficiently large.
The mentioned capacity is the capacity of the original leaf cells.

Likewise, points in the fourth set are in virtual leaf cells cut by the boundary between bands  and .
A virtual leaf cell, which is an aggregated subtree, contains at most  points, otherwise it would not have been aggregated.
Again, using Lemma~\ref{lemma:ring-root}, we can bound the number of points in these sets to  points with probability at least .

We denote the union of the third and fourth sets with .
From the individual bounds derived in the previous paragraphs, we obtain an upper bound for the number of points in  of  with probability at least .
Simplifying the bound, we get that  with probability at least .

Each of the points in  is a candidate with a probability between  and .
The candidates are sampled independently (see Step 2 of Lemma~\ref{lemma:independent-correct-probabilities}). 
While different points may have different probabilities of being a candidate and the total number of candidates does not follow a binomial distribution,
we can bound the probabilities from above with .

We proceed towards a Chernoff bound for the total number of candidates across all overhangs.
Let  denote the random variable representing the candidates within  and let  denote the total number of candidates in overhangs.

The expected value  follows from the linearity of expectations:


(Cells anchored in the band , which has an upper bound  of zero for the neighborhood probability, do not have any candidates and can be omitted here.)

Since the candidates are sampled independently with a probability of at most , we can treat  as a sum of independent Bernoulli random variables without loosing generality.
This allows us to use a multiplicative Chernoff bound~\cite{mitzenmacher2005probability} and we can now give an upper bound for the probability that the overhangs contain more than twice as many candidates as expected:


While the random variable  is written as an infinite sum, all but at most  bands are empty, thus we are only applying the Chernoff bound over finitely many variables.
For each of the at most  non-empty bands, we defined two tail bounds for the number of points in the overhang. 
Including this last bound, we thus have a chain of  tail bounds, each with a probability of at least .
The event that any of these tail bounds is violated is a union over each event that a specific tail bound is violated.
With a union bound~\cite[Lemma 1.2]{mitzenmacher2005probability}, the probability that any of the individual tail bounds is violated is at most .
Since  grows faster than  for  sufficiently large,
we conclude that the total number of candidates is thus bounded by  with probability at least  for  sufficiently large.
The leaf capacity is constant, thus the number of candidates evaluated during execution of a query  is in  whp.
\qed
\end{proof}


We proceed with an auxiliary result necessary for bounding the number of examined quadtree cells in a query:


\begin{lemma}
Let  be a quadtree with  points and  a query pair.
The number of quadtree cells examined by a query using subtree aggregation is in .
\label{lemma:subtree-aggregation-cells}
\end{lemma}

To prove Lemma~\ref{lemma:subtree-aggregation-cells}, we first introduce another auxiliary lemma:
\begin{lemma}
Let  be a hyperbolic or Euclidean disk of radius  and let  be a polar quadtree on  
containing  points distributed according to Section~\ref{sub:notation}.
Let \uaqcset(q,f) be the set of unaggregated quadtree cells that have only (virtual) leaf cells as children (category~C2 in the proof of Lemma~\ref{lemma:subtree-aggregation-cells}).
 With a query using subtree aggregation,  is in  whp.
 \label{lemma:bound-unaggregated-quadtree-cells-with-leaf-children}
\end{lemma}
\begin{proof}
 Let  be such an unaggregated quadtree cell anchored in band  that has only original or virtual leaf cells as children.
 It contains at least  points and has four children, of which at least one is also anchored in band .
 We denote this (virtual) leaf anchored in band  with .
 Since each child of  contains the same probability mass (Lemma~\ref{lemma:node-cell-probabilities}), each point of  is in  with probability :


A point in  is a candidate (in ) with probability , which is between  and  since  is anchored in band .
The probability that a given point  is a candidate in  is then 


Since the point positions and memberships in  are independent, we can bound the number of candidates in  with a binomial distribution .
The probability that  contains no candidates is:


Considered as a function of , this probability is monotonically ascending.
In the limit of , it trends to , a value it never exceeds.
The probability that the cell  contains at least one candidate is then above .

For each cell in \uaqcset, the probability that it contains at least one candidate is .
Let  be the random variable denoting the number of cells in \uaqcset that contain at least one candidate.
We define an auxiliary binomial distribution  and use a tail bound to estimate the number of cells in \uaqcset containing candidates.
Let  be a random variable distributed according to this auxiliary distribution.

We use a tail bound from \cite{ArratiaGordon1989} to limit the probability that  to at most .
Since  was a lower bound for the probability that a cell contains a candidate, this tail bound also holds for .
The probability that the set of \uaqcset contains at least  many candidates is then at least .

We continue with a case distinction:
\paragraph{If :}
The probability  is then smaller than , which is   for sufficiently large .
Thus the number of examined quadtree cells during a query is then linear in the number of candidates.
Due to Lemma~\ref{lemma:subtree-aggregation-candidates}, this is in .

\paragraph{If :} 
The cardinality  is trivially in .
\qed
\end{proof}

The proof of Lemma~\ref{lemma:subtree-aggregation-cells} then follows easily:
\begin{proof}
We split the set of examined quadtree cells into three categories:
\begin{itemize}
 \item leaf cells and root nodes of aggregated subtrees (C1)
 \item parents of cells in the first category (C2)
 \item all other (C3)
\end{itemize}
The third category (C3) then exclusively consists of inner nodes in the quadtree. When following a chain of nodes in category C3 from the root downwards, it ends with a node in category C2.
The size  is thus at most  whp, since the number of elements in a chain cannot exceed the height of the quadtree, which is  by Proposition~\ref{thm:quadtree-height}.

With a branching factor of 4,  holds.

The number of cells in category C2 can be bounded using Lemma~\ref{lemma:bound-unaggregated-quadtree-cells-with-leaf-children} to  with high probability.
The total number of examined cells is thus in .
\qed
\end{proof}

\pagebreak

\section{Visualizations of Experimental Results}
\begin{figure}[ht!]
\centering
\begin{tabular}{lr}
\includegraphics[width=0.55\linewidth]{standalone-heatMap}
\hspace{0.1cm}
&
\hspace{0.1cm}
\includegraphics[width=0.45\linewidth]{plots/visualization-native}
\end{tabular}
 \caption{Left: Twenty-third time step of a simulated disease progression through Germany. 
The colors indicate the number of infected persons within a cell. 
Right: Random hyperbolic graph with 500 nodes and average degree 12.
}
 \label{plot:heatMap-and-hyperbolic-disk}
\end{figure}


\pagebreak


\section{Performance of Baseline Algorithm~\ref{algo:quadnode-probabilistic}}
\label{sec:baseline-performance}
\renewcommand{\aconst}{190}
\renewcommand{\bconst}{275}
\renewcommand{\cconst}{13}
\begin{figure}[h!]
\centering
\begin{tikzpicture}[scale=0.7]
 \begin{axis}[xmode=log,ymode=log,xlabel=edges,ylabel=running time in seconds,legend entries={}, legend pos=outer north east]
  \addplot[scatter,only marks,
	   point meta = explicit symbolic,
	   scatter/classes={
	    f={draw=plottinggreen,fill=plottinggreen },g={draw=thirdhue,fill=thirdhue },h={draw=markedcolor,fill=markedcolor},
i={mark=triangle*, draw=plottinggreen, fill=plottinggreen},
	    j={mark=triangle*, draw, thirdhue, fill=thirdhue},
	    a={mark=diamond*, draw=plottinggreen, fill=plottinggreen},
	    b={mark=diamond*, draw, thirdhue, fill=thirdhue}}
	    ]
	    table[x=m, y=generationTime, meta=label]
          {plots/comparison-time-baseline.dat};
  \addlegendentry{, sub agg.};
  \addlegendentry{, sub agg.};
  \addlegendentry{, sub agg.};
  \addlegendentry{, baseline};
  \addlegendentry{, baseline};
  \addlegendentry{, impl. of \cite{Aldecoa2015}};
  \addlegendentry{, impl. of \cite{Aldecoa2015}};
  \addplot[plottinggreen] expression[domain=15000:400000] {7.94*10^(-8)*10^8 + 4.1*10^(-4)*10^4};\addlegendentry{, theoretical fit for baseline};
  \addplot[thirdhue] expression[domain=150000:3600000] {7.94*10^(-8)*10^10 + 4.1*10^(-4)*10^4};\addlegendentry{, theoretical fit for baseline};
 \end{axis}
\end{tikzpicture}
 \caption{Comparison of running times to generate networks with  to  vertices. Generating a graph requires  queries.
 Shown are running times of the baseline algorithm, queries using subtree aggregation and the implementation of \cite{Aldecoa2015}.
 The theoretical fit is given by the equation  seconds.
 The baseline algorithm is still faster than the previous implementation~\cite{Aldecoa2015}, but much slower than the improved query using subtree aggregation.
 }
 \label{plot:time-baseline-scatter}
\end{figure}



\pagebreak

\section{Fast RHG Generator vs Reference Implementation~\cite{Aldecoa2015}}
\label{sec:comparison-previous-impl}
\begin{figure}[!h]
\centering
\begin{tabular}{cc}
\includegraphics[width=0.41\linewidth]{plots/native-comparison/native-plot-cc} & \includegraphics[width=0.41\linewidth]{plots/native-comparison/plot-cc}\\
\includegraphics[width=0.41\linewidth]{plots/native-comparison/native-plot-degass} & \includegraphics[width=0.41\linewidth]{plots/native-comparison/plot-degass}\\
\includegraphics[width=0.41\linewidth]{plots/native-comparison/native-plot-gamma} & \includegraphics[width=0.41\linewidth]{plots/native-comparison/plot-gamma}\\
\end{tabular} 
\caption{Comparison of clustering coefficients, degree assortativity and measured vs desired power-law exponent .
Shown are the implementation of~\cite{Aldecoa2015} (left) and our implementation (right).
The clustering coefficient describes the ratio of closed triangles to triads in a graph.
Degree assortativity describes whether vertices have neighbors of similar degree.
The degree distribution of random hyperbolic graphs follows a power law, whose exponent  can be adjusted.
In the degree distribution plot, the blue curve is almost always identical to the red curve and thus covered by it.
Values are averaged over 80 runs.}
\label{plot:properties-comparison-I}
\end{figure}
\end{document}
