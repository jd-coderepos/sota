\documentclass[11pt]{article}

\usepackage{epsfig}
\usepackage[section]{algorithm}
\usepackage{algorithmic}

\usepackage{anysize}
\usepackage{amsmath}
\usepackage{amssymb}
\marginsize{1in}{1in}{1in}{1in}

\def\qed{\hbox{\rlap{}}}
\newenvironment{proof}{\par\noindent{\bf Proof:}}{\mbox{}\hfill\\}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\renewcommand{\baselinestretch}{.95}
\newcounter{rem}
\setcounter{rem}{0}
\newcommand{\ignore}[1]{ }
\newcommand{\rem}[1]{
    \marginpar{\refstepcounter{rem}{\tiny\therem: #1}}
}

\begin{document}




\title{The Budgeted Transportation Problem}
\author{S. Kapoor \thanks{Computer Science, IIT,Chicago,IL, e-mail: kapoor@iit.edu} and M. Sarwat\thanks{Amazon.com, Work done at Computer Science, IIT, Chicago, IL, e-mail sarwat@iit.edu}}
\date{}
\maketitle



\begin{abstract}
Consider a transportation problem with sets of sources and sinks. There
are profits and prices on the edges. The goal is to maximize the profit while meeting
the following constraints; the total flow going out of a source must not exceed its
capacity and the total price of the incoming flow on a sink must not exceed its budget.
This problem is closely related to the generalized flow problem.



We propose an auction based primal dual approximation algorithm to solve the problem.
The complexity is  where  is the number
of sources,  is the number of sinks,  is the ratio of the
maximum profit/price  to the minimum profit/price.

We also show how to generalize the scheme to solve a more general version of the
problem, where there are edge capacities and/or the profit function is concave and 
piecewise linear. The complexity of the algorithm depends on  the
number of linear segments, termed , of the profit function.


\end{abstract}



\section{Introduction}
\label{chap_BT}





The Transportation Problem is a fundamental problem in Computer Science. It was 
initially formulated to represent the problem of transporting goods from warehouses to customers.
The mincost version of the problem is also known as the Hitchcock problem after one of its
early formulators \cite{hitchcock41dist}. It is well-known
that while the Transportation problem
can be seen as a special case of the mincost flow problem, the latter can also be transformed 
into the former \cite{papadimitriou}.

The first primal-dual algorithm, called the Hungarian method \cite{Kuhn55Hungarian}, 
was also proposed for 
the Assignment Problem which happens to be a 
special case of the Transportation Problem. More
recently, the Transportation Problem was used by 
Bertsekas \cite{bertsekastutorial} and 
Goldberg and Tarjan  \cite{goldberg87solving} as a natural framework for applying 
auction based algorithms. 

The typical transportation model assumes that there is no loss of goods as the goods are 
transported from the sources to the sinks. In real life, there is often a loss involved. 
For example, in case of  electricity there is loss due to resistance and in case of oil, 
due to evaporation. In case of a delicate merchandise, there might breakage. 
Sometimes, there may even be a gain (e.g. transfer of money: currency conversion).
The loss or gain can be modeled as a price function on the transport from the 
source to the sink.

As an example, consider  a set of depots and a set of retail stations. 
The depots have a certain supply of goods, 
while the retail stations have a limit on their intake capacity.
For every unit transported between a pair of depot and station, 
a certain amount of profit is made
which depends on selling price, cost of transportation etc. 
In addition, consider the situation where goods transported 
suffer a loss 
proportional to the number of units transported.
This factor is unique to each pair as it depends on
the mode of transfer and distance etc. 
In order to measure the net incoming amount at
the stations, we have to account for this loss. 
The intake capacity limit is therefore, on a weighted
sum rather than a simple sum.    

In a more recent context, keyword based advertising is widely applied by 
internet based service companies like Google and
Yahoo. Consider the following model for assigning advertisement space to the 
bidders: each bidder, say , modeled by a sink,
specifies its total budget  and the price  it is willing to pay 
for the th keyword, specified by  source .
An estimate of the number of times a keyword would be invoked in web 
searches provides a capacity  for the th keyword.
Assignment of a keyword  to a bidder  provides a profit .
The goal is to maximize the revenue of the service provider without exceeding the bidders budget.
A version of the problem restricted to an integral setting may be 
found in \cite{andelman04auctions}.
The online version of the problem has been considered in \cite{mehta05adwords}.


In order to model the above and similar problems, we propose a generalization of the 
transportation problem: the Budgeted  Transportation Problem (BTP) which is closely related 
to Generalized Flow Problem. We then present an auction based approximation algorithm. 
We also show how to extend the technique to further generalizations of the problem. 

Like the conventional Transportation Problem, the problem is 
modeled  on a weighted bipartite graph. 
In our version of the problem we consider maximizing the profit in 
transporting/assigning goods
from the sources to the sinks, subject to the following conditions:
Each source,   has a {\it supply} of goods, bounded by a capacity function ,
and each  sink  has a bound on the incoming set of goods, 
specified by a  {\it budget} .
The difference from the conventional transportation problem is that the  budget is a 
bound on the weighted sum of the incomming goods as follows: each  source-sink 
pair  has a {\it price} function  and the bound  is on the 
sum  where  is the amount of goods transported/assigned 
from source  to sink  . 
The goal is to maximize the sum of profits of transporting/assigning goods 
from sources to sinks,
given that the profit obtained by 
transporting/assigning  units is .
The problem can be formally stated as follows: 

Given a bi-partite graph , capacity , 
budget ,
price , profit  the budgeted transportation
problem is to find a flow function 
so as to maximize  subject to capacity constraints, 
and budget constraints .We let  and .

Note that, for simplicity, the price function, like the other functions,
is assumed to be integral in the 
paper. This could be replaced by a  price function to the set of rationals.





We describe an approximation scheme for the budgeted transportation problem.
Our algorithm is a primal-dual auction algorithm.
Auction algorithms have been utilized before in the solution of combinatorial
problems \cite{bertsekastutorial,goldberg87solving} including the classical transportation 
problem \cite{bertsekas89transport}, and more recently for finding market 
equilibrium \cite{garg04auction, garg04auctionbased}. 
Bertsekas et al \cite{bertsekas97anerelaxation} apply the auction mechanism  to 
solve the generalized flow problem but the complexity of that 
algorithm is not polynomial.

While the auction technique has been used before, the application in the current context
is different.  The auction mechanism is used to realize a set of tight edges, i.e. edges 
which satisfy complementary slackness conditions. Paths and cycle are found in a subgraph 
in these set of tight edges. The flow path/cycle could either be flow generating or 
create a flow reduction. The primal-dual nature of our approach allows us to push flow 
along these paths or cycle without worrying about the profit of the path/cycle. The cycle 
can be eliminated in linear time. Our algorithm may be interpreted to have achieved a  
version of cycle-canceling \cite{wayne99apolynomial} without having to compute 
the associated profit.

We achieve a complexity of , 
where  is the number of sources,  is the number of sinks and  is
.
The problem can also be modeled as a generalized flow problem.
This can be done by adding a super source connected to all the sources and a supersink
connected to all the sinks and minimizing the negative of the profit function. 
By using the technique of scaling as in \cite{Luby-Nisan},
the dependancy on  can be replaced by  .
We will thus choose to ignore terms involving , and in fact
, when comparing our results with other results.


There are numerous results 
for maximum/mincost generalized flow and related problems 
\cite{tardos98simple,fleischer99fast,wayne99apolynomial,radzik98faster,oldham99combinatorial,
goldberg91combinatorial,goldfarb96afaster}. 
Some of the currently best known FPTAS for the generalized flow problems
are of complexity  
\cite{fleischer99fast,tardos98simple,radzik98faster} 
for 
maximum  generalized flow and  \cite{fleischer99fast} and 
 \cite{wayne99apolynomial} for minimum 
cost generalized flow. Here, ,  and  is 
the largest integer in cost representation. For the special case, when 
there are no flow generating cycles, the complexities are 
 and 
for maximum and minimum cost generalized flows respectively \cite{fleischer99fast}, where
 is the number of nodes and  is the number of edges in the given graph.


A straight-forward application of the best known generalized flow approximation
algorithm to this problem would require  time
using the minimum cost generalized flow algorithm in \cite{wayne99apolynomial}  
or  time using the algorithm in \cite{fleischer99fast}. 
Our algorithm has a better complexity than the first when
 and is better than the second for all ranges of .

If we use the packing algorithm from \cite{garg98faster} than 
one can solve this problem in
 since we have  rows and  columns
in the primal constraint matrix. Other known combinatorial
algorithms for packing \cite{PST95,GK94}
are also all dependent on .  
After the completion of this work we became aware of 
another result \cite{kouf-young}
which provides a randomized  approximate solution to the 
packing problem in time  where
 is the number of non-zero entries in the specification of
the packing program and  is the number of rows and columns in the
matrix specifying the packing program. As applied to the budgeted
transportation problem this algorithm would 
require  and  would be faster
than our approach when .  

Comparing with algorithms that have a dependence on ,
one recent algorithm for packing problems
is by Bienstock and Iyengar \cite{bienstock:2006}, 
which reduces the packing problem to solve a sequence of 
quadratic programming which in turn are approximated by linear programs.
Consequently, the complexity will have high polynomial dependance on  and
.
We achieve a combinatorial algorithm with 
complexity dependant on  and a low  polynomial
in  and .

\ignore{
Note that the approximation to the budgeted transportation problem does 
not immediately provide an algorithm for the generalized flow problem in general graphs 
since the approximation guarantee does not translate back.
}
We extend our algorithm to solve a generalization of BTP called
the  Budgeted Transshipment 
Problem (BTS). It is similar to BTP except for added edge capacity constraints. 
We achieve the same approximation with no additional time complexity,
i.e .
This is of improved efficiency, 
since, again, to compare this with existing results: the result in \cite{wayne99apolynomial} 
would imply a complexity of
, \cite{fleischer99fast} 
would imply a complexity of
 while  \cite{garg98faster} would imply
a complexity of 
as the number of constraints is now .
The results from \cite{kouf-young} would, again, be of complexity
.


In section \ref{sec_basic}
we present a basic auction based algorithm and show its correctness. In section \ref{sec_modified}
we describe a modified algoritm and discuss its convergence. Since the algorithm is similar to the algorithm for the generalized
problem, BTS, we demonstrate an outline of the algorithm.
Section \ref{sec_extend} extends the result to BTS. In section
\ref{sec_details} we present a detailed algorithm for BTS (which also applies to BTP)
and in subsequent sections the proofs of correctness and complexity of the 
algorithm. The piece-wise linear case is discussed in section~\ref{piece-wise}. 
We conclude in  section \ref{sec_conc5}.
We also  show a relationship between  BTP and  minimum cost generalized flow problems in the appendix (section \ref{sec_relation}). 



\section{Auction Based Algorithm}
\label{sec_auc}
\subsection{The Basic Method}
\label{sec_basic}

In this section, we describe a primal-dual auction framework to 
approximate the maximum profit 
budgeted transportation problem (BTP) to within a factor of . 
The algorithm is a locally greedy algorithm 
where the sources compete against each other for sinks by bidding with lower 
effective 
profit, a quantity defined using dual variables. 
This algorithm will serve to illustrate the methodology. In order to prove
complexity bounds we will, in the next section, refine the algorithm further.

We first model the problem using an LP and also define its dual.


In the remainder of the paper, the variables  and  will refer to
a  source  in  and sink  in , respectively.

The dual of the above program is 




\ignore{
The algorithm maintains a pair of feasible dual and primal
solutions. It works to modify them until all the 
complementary slackness conditions are exactly or 
approximately satisfied.

}

The following variables based on primal and dual variables are
used in the algorithm.

\begin{itemize}
\item
 : the dual variable associated with each source.
\item
 : the dual variable corresponding to the budget constraint on the sink. 
An algorithmic interpretation of  is that it represents
the value of sink . It increases as different sources compete in order to ship flow to it.
At every instance of the algorithm, flow may be pushed onto the sink  
from a source at a given
value of . We term this an assignment of the source at valuation .
Further, at any instance of the algorithm sources are assigned to sinks at two prices (values),
some at value  while others are assigned at 
a {\bf companion valuation}  where 
. 

\item
:  the {\bf valuation} of sink  when assigned to source 
 to ship the flow from  to . It equals   when source  ships
flow to sink .  Subsequently, as  rises, it becomes equal to .
\item
 : the supply (or surplus) remaining at the source .  is  
evaluated as  
 and is implicitly updated in the algorithm.
\item
 : the amount remaining from the budget at sink .
 is evaluated as .
\end{itemize}

Because the input is asssumed to be integral, we note that all the variables
are rationals, with a bound on the absolute value of the denominators.

The initial and primal dual feasible solutions are obtained by the initialization 
procedure \ref{proc_init} {\bf Initialize}.
The algorithm maintains a pair of feasible dual and primal
solutions. It works to modify them until the following
complementary slackness conditions,
which define optimality, are exactly or approximately satisfied.

 

In each iteration, the algorithm \ref{alg_auc} {\bf Auction} picks a source,
, with  
positive surplus, , 
and . It then picks a sink  that provides it the 
largest effective profit, where the profit is specified by the quantity, 
. If the sink is not saturated
flow is pushed from source  to sink  .
If sink  is saturated, flow from a 
source  , that is shipping flow to sink  at a lower of value , is replaced
by flow from , i.e. source  wins over the shipment to sink  from source  by
bidding a higher value () for . 
After the change of flow assignment, it is checked  (\ref{proc_simpleupdate} {\bf UpdateBeta(  ) }) 
that there exists at least one source shipping flow at  the lower value. 
If not, then  is raised, indicating that
shipping flow to  requires paying a higher value (and lower effective profit).
At this stage, 
the process is repeated considering sinks in order of effective profit until \\
(i) either all the surplus
at node  is pushed out or \\
(ii)  


\begin{algorithm}
\begin{algorithmic}[1]
\vspace*{.1in}
\STATE{}
\STATE{}
\STATE{}
\STATE{}
\end{algorithmic}
\caption{{\bf Initialize}}
\label{proc_init}
\end{algorithm}

\begin{algorithm}
\begin{algorithmic}[1]
\vspace*{.1in}
\WHILE{there exists a source  such that 
       and }

\STATE{Pick a sink  such that  is maximized}

\IF{ {\em the sink is saturated, i.e.} }
\label{alg_auc:line31}

\STATE{Find a source , currently assigned at the lower value level i.e.  }
	\IF{}
		\STATE{{\em //determine the amount that can be replaced}}
		\STATE{}
		\STATE{{\em // replace the flow}}
		\STATE{}
		\label{alg_auc:line1}
		\STATE{}
		\label{alg_auc:line2}
		\STATE{}
	\ELSE
		\STATE{{\em // is already shipping to  at the lowest level}} 
		\STATE{{\em //Raise the  assigned value without changing any flow} }
		\STATE { \label{step_betachange}}
	\ENDIF
	\STATE{Update  and }
	\label{alg_auc:line18}

\ELSE
	\STATE{{\em //The sink is unsaturated, push maximum flow possible }}
	\STATE{ {\em //under supply and demand constraint}}
	\STATE{}
	\label{alg_auc:line3}
	\STATE{}
	\label{alg_auc:line4}
	

\ENDIF

\STATE {}
\label{alg_auc:line101}

\IF{}
\STATE{ for all }
\label{alg_auc:line11}
		\vspace*{-2pt}
\STATE{//This ensures there is no further rise in 
 without reducing  to zero}
\ENDIF

\ENDWHILE

\end{algorithmic}
\caption{ {\bf Auction} }
\label{alg_auc}
\end{algorithm}

\begin{algorithm}
\begin{algorithmic}[1]

\vspace*{.1in}

\IF{ = 0} 
	\STATE{}
\ELSIF {}
	\STATE{}
	\STATE{}
\ELSE
	\STATE{//no update required}
\ENDIF

\end{algorithmic}
\caption { {\bf UpdateBeta} ( )}
\label{proc_simpleupdate}
\end{algorithm}
To prove the correctness, we show that primal and dual equations are satisfied
and complentary slackness conditions hold. All line numbers in the
discussion below correspond to the description of {\bf Algorithm 2.2  Auction},
except when stated.
\begin{lemma}
The dual solution maintained by the algorithm is always feasible.
\end{lemma}

\begin{proof}
We observe that the value of  never decreases as the algorithm 
progresses. Therefore,  can only 
become true when  is modified. However, when  is modified, 
it is set to a value  in line \ref{alg_auc:line101}. 
At that point,  for all . 
\end{proof} 
For use in  the next lemma, we define 
the  {\em total price of the incoming flow on sink } to be 
.

\begin{lemma}
The primal solution maintained by the algorithm 
does not exceed the budget constraints. 
\label{primal_feasible1}
\end{lemma}
\begin{proof}
The flow on any edge is increased in lines \ref{alg_auc:line1} and 
\ref{alg_auc:line4}. In line \ref{alg_auc:line1} 
the total price of the incoming flow on sink  increases by . 
It is then reduced by  in line 
\ref{alg_auc:line2}, and therefore, the budget is met. 

In line \ref{alg_auc:line3}, the total price increases by at most 
 and thus the budget is not exceeded.
\end{proof}


\begin{lemma}
The primal solution maintained by the algorithm
 does not violate supply constraints.
\label{primal_feasible2}
\end{lemma}
\begin{proof}
During the algorithm, the increase  in flow, , on an edge  
is always limited by the available supply (line 7 and 21) and
therefore, the supply constraint is clearly satisfied. 
\end{proof}

Combining the above lemmas \ref{primal_feasible1} and \ref{primal_feasible2} 
we conclude:

\begin{lemma}
The primal solution maintained by the algorithm is always feasible.
\end{lemma}









\begin{lemma}
\label{beta-change}
During the course of the algorithm, if sink  is not saturated 
then . Further,  is non-decreasing during the
course of the algorithm.
\end{lemma}
\begin{proof}
The variable  for all   is initialized to zero. It is
subsequently changed by the procedure {\bf UpdateBeta}, which in turn is called only
if the sink  is saturated. That is, line \ref{alg_auc:line18} is executed only when the
``{\bf if}'' condition in line \ref{alg_auc:line31} :  is 
satisfied. Moreover,   only increases in value.
\end{proof}

The following lemma will be useful for bounding the complexity of the various algorithms:
\begin{lemma}
\label{beta-increase}
Suppose , the flow on edge , 
that was pushed at a valuation of sink ,  
=  , is reduced to zero, 
i.e. pushed back to zero. 
Then at the next occurrence of the event that corresponds to  being 
pushed back  on edge ,  
the valuation of sink , .
\end{lemma}
\begin{proof}
This follows from the fact the  is monotonically non-decreasing.
Flow is pushed back on an edge 
only when there is flow on the edge,  
that had been pushed at the companion valuation 
of , where  is the current valuation.
Let flow be pushed back from sink  to source  on edge  
at some time  in the algorithm such that the flow is reduced to zero.
Then when flow is pushed from  to , at a subsequent
time , the  valuation   (line 11), 
since the valuation
of  does not decrease. Consequently, if flow is pushed back again
from  to , the valuation has  increased.
\end{proof}

\begin{lemma}
During the execution of the algorithm,
the Complementary Slackness condition, {\bf  CS1 }
is approximately satisfied for each edge . That is, 
 
\label{lemma_primalCS}
\end{lemma}

\begin{proof}
When flow is pushed on the edge ,  and 
 or is 
(line 2 and 24 in {\bf Algorithm 2.2 Auction}) and the condition is true. 
Note that at this event, .
Subsequently,  or  may change.
We consider the changes 
to  and  and 
to the flow, , between the event in the algorithm
when positive flow is pushed on the edge  and the event when
this pushed flow reduces to zero, being pushed back on edge .
In between the two events, since we assume that ,   is either  or
.
We consider cases
depending on whether  or not.
\begin{enumerate}

\item
. Suppose  does not change but  has
increased by a factor of  .
In this case   has a value equal to , otherwise 
would be zero.
Since the value of   changes 
by a factor of , . 
Note that the value of  can not
increase further unless  reduces to zero.


If  has also changed, it only decreases, 
since  is increasing. 
Therefore, the inequality still holds. 

\ignore{
In every iteration of the algorithm, after possible modification of
,  is recomputed. Note that  can
only increase by a factor of . 
Further note that  during the course of the
algorithm. 
The first time that ,
 becomes zero 
and  is set to  so as to
ensure that flow is pushed back on edge . 
This would result in  possibly becoming zero.
Also, subsequently source  is never considered  for pushing
flow  since line 1 of {\bf Algorithm 2.2 Auction} only
considers vertices with .
Thus  would only increase if .
We consider cases
based on the value of  computed in line 24 of the algorithm,
{\bf Algorithm 2.2 Auction}:

\begin{enumerate}
}
\item
. No future change in the value of  can occur.
Prior to the step at which  is set to zero,
 for some .
This implies that . An increase in
the value of  thus  still results in
.
Thus the inequality holds when  is set to zero.
Further, when  becomes zero, 
the algorithm  sets the value of  to be  so as to
ensure that  is not increased without the event that
flow is pushed back on   and  is reduced to zero. 
And, subsequently, source  is never considered  for pushing
flow  since line 1 of {\bf Algorithm 2.2 Auction} only
considers vertices with .
Thus if flow  then  has not changed. And if
 has changed, the flow is set to zero.
The inequality thus holds.

\ignore{
Note further that the first time  is set to
zero. Prior to this change in  by a factor of , 
.   
Thus , 
}



\ignore{
If ,  can not change   
without reducing  to zero. This can be seen
by observing that in lines \ref{alg_auc:line1} and \ref{alg_auc:line2} of the 
algorithm, the flow with lowest assigned 
value  is replaced. 
And for  to change it must be that  , 
(line 3 in {\bf Algorithm UpdateBeta}).
However, for source , with , the assigned value is  (See
line \ref{alg_auc:line11}).
Thus if  then, since  has not changed,
condition (1) holds true.

In case  ,  can increase to 
. 
But then  implies , since 
 and condition (1)
holds.
}
\ignore{
\item
 is positive. Suppose  does not chan
If , then either 
or .
If  then .
Since  is greater than , . 
Therefore, if the value of   changes 
by a factor of , . 
Since source  is chosen so that  is being pushed at the valuation
,  the value of  can not
increase further unless  reduces to zero.


If  also changes, it only decreases, since  is increasing. 
Therefore, the inequality still holds. 

}

\end{enumerate}

\ignore{
We get

 
by combining all the cases above.
}\end{proof}

Furthermore,
\begin{lemma}
Algorithm 2.2 {\bf Auction}  terminates.
\end{lemma}
\begin{proof}
At each iteration of the algorithm, flow is pushed on an edge and 
 either remains the same or
the value of  increases for some  (Lemma~\ref{beta-change}). 

When flow is pushed on an edge , either (i)  goes to zero  (ii) the budget at a
sink  is met or  (iii) the flow on a back edge  is reduced to zero.
Note that, by lemma~\ref{beta-increase}, in case (iii) flow cannot be pushed (in the forward direction)
on the edge  without
increasing the value of . 

The first event, case (i), results in flow being pushed from  to 
such that  and will happen only once per source-sink pair
until an event where flow is pushed back on an edge  to add to  surplus at 
occurs. Thus this event occurs whenever new surplus is generated, which
is bounded by the number of times  flow is pushed back on an edge without
case (iii) ocurring.
The number of times flow is pushed back on an edge, without reducing the
flow to zero (case (iii)), is bounded since 
the amount of change of flow at every instance is a rational with
bounded denominator.

The second event, case (ii),
happens  at most  times, since after that event
the sink remains saturated during the subsequent operations of the algorithm. 
The third event, case (iii), occurs at most  times before all edges 
leading to a sink have flow reduced to zero, and consequently the value of
 must rise.
This bounds the total number of operations
in the case that  remains the same.
Further, the number of increases of  is bounded since  
increases by a factor of  and its value is bounded above
by . Thus the algorithm terminates in a finite number of steps.
\end{proof}

In order to show good convergence of the algorithm we 
introduce further modifications. However, when the algorithm terminates
then the following is true:
\vspace*{12pt}
\begin{lemma}
At termination, the difference between the value of 
primal solution  and the value of the 
dual solution is at most 
\label{lemma_approx}
\end{lemma}

\begin{proof}
The value of the dual solution is 


When we subtract the value of the primal solution , from the
above, the  difference is



Thus, the total absolute difference is at most  where







From lemma \ref{lemma_primalCS}, we have 



Therefore, 



From the termination condition of the algorithm, we know that for any source
 such that , we have .

Therefore 





For all unsaturated sinks . Therefore, 


Combining all of the above we get the lemma.
\end{proof}












\label{section_auction}


\subsection{Modified Algorithm}
\label{section_modified}
\label{sec_modified}

In order to show the required complexity bound, and make its analysis simpler, we make
a few modifications to the above algorithm. We address the details of
the data structures required and present the complexity analysis.
We also show that the modifications do not affect the correctness of 
algorithm \ref{alg_auc} {\bf Auction} as proved in section \ref{sec_auc}.

We introduce the concept of a preferred edge, back edge and derived graph 
as explained below. 

\paragraph*{Preferred Edge: }
For a given set of values for  and  we designate
a preferred edge  for each source . This edge maximizes
, i.e.  where 
. 
In the case that multiple values of  satisfy the condition, only one is picked.
The source  will be required to push
flow along this edge until the edge is no longer is preferred. 

\paragraph*{Back-edge: }
All edges  such that  and .
Flow is pushed back on these edges.
The set of all such edges is termed .

\paragraph*{Derived Graph: }
We define the capacitated derived graph  with respect to an intermediate solution
maintained by the modified algorithm. This graph consists of all
the sources and sinks in the given bipartite graph and directed edges 
which are either the preferred edges or the back edges.
All the preferred edges are oriented in the forward direction, whereas 
all the back-edges are oriented in the reverse direction, indicating the
directions along which flow will be pushed. The capacity of a preferred edges
is infinite whereas the capacity of a back-edge is the amount of flow carried on
that particular edge. Formally,
  where 
 
and the capacity function 
is as follows:

 



Before starting with the main algorithm, 
the following  preprocessing step eases the description: 
\paragraph{Pre-processing step:}
Consider a preferred edge . If edge  is also a back edge (thus
creating a 2-cycle () in ) and 
is not the only back edge from  then 
the valuation  at which flow is shipped from source  to sink ,
i.e. ,  is increased to .
Note that this modification is not done when the sink has only
one back edge   since the existence of at least one valuation equal to
 does not allow a  raise  in the price of sink . 
This ensures:
\begin{enumerate}
\item
If there is a 2-cycle on sink , sink  has only
one back edge. 

\item
 does not change. 
\end{enumerate}
In the derived graph , if  before the modification then  
after the modification also,
and source  will choose to push flow along its preferred edge.

The algorithm in section~\ref{sec_basic} pushed flow from a source to a sink 
causing flow
to be pushed back to some other source and consequent independant processing of
that  other source was performed.
The modified algorithm in this section, starting from a source with 
a surplus and positive , finds a path along the edges 
of the derived graph  and pushes  the flow according to the type of path discovered,
thus ensuring that the surplus flow is processed in one push of flow along
a flow path.
The path found by the algorithm ends at either
(i)  an unsaturated sink,(ii) a source with  or (iii) a cycle.  










\begin{figure}\centerline{\epsfysize=200pt\epsfbox{ma3.eps}}
\caption{ An example where path ends in a source with } 
\end{figure}


\begin{figure}\centerline{\epsfysize=200pt\epsfbox{ma4.eps}}
\caption{ An example where path ends in a sink with } 
\end{figure}



\begin{figure}\centerline{\epsfysize=200pt\epsfbox{ma5.eps}}
\caption{ Example where the path ends in a cycle}
\end{figure}

We detail the various cases that arise.
A source  is picked such that  and 
.
And  a  path, , is discovered by, say a depth first search,
along the edges of the derived graph .
There are  different types of paths/cycles that may arise.

\begin{enumerate}
\item
{\bf Type-1 paths:} We have two cases, one
where the path finds a  source  where  and the second where
the path finds  an unsaturated sink  where . 
In the first case, let 
and in the second case let . 
In both cases flow is pushed as follows: in the first
case flow is pushed into 
source  (i.e. returned to the source) and in the second
case flow is pushed into a sink (), 
without violating feasibility or complementary slackness conditions. 
However, the flow may be limited by the capacity of the edges on the path, .
We define the capacity of the path,  
as 
The processing of the flow is as follows:
\begin{enumerate}
\item
The flow is limited by the surplus, , 
at the starting source . Push all the surplus
along the path. The surplus at the source disappears.
This is true for both  cases.

\item
The amount of flow is limited by the capacity of an unsaturated sink on 
path  (second case), i.e. . 
In this case, we push enough
flow to saturate the sink and consequently, raise the value of . 

\item
The amount of flow is limited by the capacity of  the path .
In this case, we push flow  from the source along 
the path. Let  be the flow starting at the source.
Let  be the first edge such that .
The amount of flow that can be pushed along this edge is limited by .
Pushing flow along this edge reduces  the capacity of the edge   to .
The surplus   is added to the surplus of the previous source  
which has  as the preferred
edge. 
The flow pushed back through  is accumulated at  as a surplus.
The surplus at   is pushed  further along the path recursively. 
In the end one or more back edges would have zero flow and surplus may be left at
each source ocurring just prior to the sink where the back edge with zero flow is incident.


\end{enumerate}

\item
{\bf Type-II paths:}
The path ends at a 2-cycle ().
A  2-cycle implies  is the only back-edge on sink , as soon as the flow
is again pushed along edge ,  changes 
(line 15, {\bf Algorithm 2.2  Auction}) and the only back edge disappears. 
This results in an increase in the value of .

\item
{\bf Type-III paths:}
A cycle is discovered since one of the sources is encountered again.
Let the path discovered be
denoted by  which is decomposed into
a simple cycle 
and a simple path .
The source  being the {\em entry point}, i.e.,
the first source that appears in the cycle. 
First the flow is pushed along the path  
taking into account the capacities as in Type-I paths.
Any additional surplus that appears at source  is handled as follows. 

Consider an imaginary procedure that simulates sending flow around the cycle, 
, multiple times, while conserving the
flow at each of the intermediate sources in the cycle.

We define  the {\em transfer ratio}  for
a back-edge  w.r.t.  
to be   where  is the preferred edge for 
source  and   is a back edge.

Further define the {\em cumulative transfer ratio}  
for the back-edge  with 
respect to a cycle 
to be the amount that goes through the edge 
if one unit of flow is pushed along the cycle starting at source . This is equal
to . 

Let the cumulative transfer ratio of the cycle be 
. This is the amount of flow that reaches
the first source, , back after being pushed all around the cycle starting with a unit of
flow at . 

Let us call the push of flow once around the cycle as one revolution.
If we were to send the surplus at source ,  units of flow,
repeatedly in this cycle for say,  times, while conserving
the flow at each of the intermediate sources, the total flow shipped through the 
back edge  is  given by the geometric 
series . 
Since this back edge is capacitated, the maximum
number of times flow can be pushed around the cycle before saturating this edge to capacity,
which we term as the {\em limiting number of revolutions},  
is given by . 
This number can be computed in  time. 
It ignores that other edges may also limit the flow.
We thus compute  to compute
the {\em limiting number of revolutions for the cycle}, i.e.
the smallest value of the limiting number of revolutions, computed from  amongst
the back edges in the cycle, .

The flow on the edges of the cycle is modified as:

for forward edges  and

corresponding to back edges.

We consider cases based on the value of :
\begin{enumerate}

\item
. In this case we have a decreasing gain cycle, ,
i.e. the value of the flow
decreases as it is sent around the cycle. We compute the limiting number of 
revolutions for each back edge in the cycle, . 
Note that this number may be infinity for some edges. 
However, this can be determined  
by computing the value to which the geometric series, , converges 
and does not require simulating an infinite sequence of pushes. 






After  rounds, the remaining
surplus at  is reduced to . 
Note that if  is infinity then the surplus at the source,  decreases to zero.
The surplus at every other
source in the cycle remains unchanged.

Consider the cases depending on the value of the surplus at :

(i) the surplus remaining at  becomes zero, or,


(ii) the flow on one of the back edges reduces to zero.
This case occurs when the number of revolutions is limited due to one 
of the back-edges.
Since  integral revolutions need not achieve this, one more sequence
of flow pushes 
around the cycle may be required. 

\item
. In this case the flow increases or remains the same as it 
goes along the
cycle. There  will be thus no decrease of surplus at the starting source vertex . 
However, for each of the back-edges 

{\em is a finite number} since each push of flow around the cycle reduces the capacity of
the back-edges. 
The smallest of these  values is chosen and the maximum 
number of rounds of  flow 
to be pushed around the cycle is computed.
Again, since  integral revolutions need not achieve this, 
it may  require one more sequence of flow pushes  around the cycle 
to reduce the flow on a back-edge to zero.


\end{enumerate}

In the cases above where the surplus is not reduced to zero,
at least one edge is saturated by the flow pushed around the cycle.
Any surplus remaining at other nodes is pushed around the cycle to accumulate
at the source(s) just before the saturated edge(s).


\end{enumerate}

The overall structure of the algorithm is similar to that in 
section~\ref{sec_auc}.
After pushing the flow through the path or cycle discovered, values of 
are updated if required, preferred and back edges computed as necessary and
the algorithm repeats until all surplus is removed or
until complementary slackness conditions are satisfied.
This algorithm is termed as the  {\em Modified Auction} algorithm.

\paragraph{Data Structures:}
In order to determine  for each  we
maintain a heap. This heap can be updated when  changes in
 time. The UpdateBeta procedure, as in the previous algorithm,
utilizes a set data structure
to determine the need for update of  in  time.


We next discuss how this approach  improves the complexity. However,
we can actually solve a more generalized problem, i.e. where 
each edge  has a capacity .
So we defer a formal description and  proofs of the above approach to
section~\ref{Edge-formal}.






\vspace*{12pt}
\subsection{A discussion on the correctness and complexity of Modified Auction } 

We discuss the correctness and  time complexity of the modified algorithm.
Formal proofs are provided when we consider the generalized model including
edge capacities.

\paragraph{Correctness:}
In order to justify that the modified algorithm 
terminates with a  approximate solution, 
first, we observe that while the algorithm \ref{alg_auc} {\bf Auction} 
does not require any particular order 
in which the surplus sources are picked, the sequence of choices of 
the sources from where the surplus is reduced,  as imposed by 
the modifications, still ensures  primal and dual constraints.

In the case that the algorithm encounters cycles,
the modified algorithm 
essentially simulates multiple steps of the algorithm
\ref{alg_auc} {\bf Auction}. The end result is exactly the same if each step was 
performed individually
and repeatedly. The amount of flow shipped out of a source at each step, however, may be 
{\em smaller} than what Algorithm \ref{alg_auc} {\bf Auction} would have shipped out. 
However, the primal and dual constraints are still ensured.

The modified algorithm makes the same changes to the variables ,
 or  as described in the previous section. 
The only modification is in the change to the  variables,  in the 
preprocessing procedure. This 
change does not affect the claim that  for  all  in the proof
of lemma \ref{lemma_primalCS} as  is set to  itself. 
The pre-processing procedure 
leaves at least one back-edge intact; this ensures that 
no change in  takes place as 
a result of the preprocessing. All the arguments involving  are, therefore, unaffected.
Thus primal and dual feasibility is maintained.
Further the complementary slackness conditions are satisfied.

\ignore{
Thus we can state that
\begin{itemize}

\item
The primal solution obtained by the algorithm {\em Modified Auction} is feasible.

\item
The dual solution obtained by the modified algorithm is feasible.

\end{itemize}


Due to the fact that the change in  and consequent changes in other variables are
locally ensured by the same procedure as  in the previous section, the following holds:
\begin{itemize}

\item
The complementary slackness conditions {\bf CS1} and {\bf CS2}
are satisfied exactly and condition {\bf CS3}
is satisfied approximately.

\item
At termination the difference between the value of 
primal solution  and the value of the 
dual solution is at most 

\end{itemize}
}\paragraph{Complexity:}
For the  complexity
we consider the  sequence of steps between two 
successive raises of the value of , termed as a {\bf phase}, in the algorithm.


We use the 
fact that for all , the total number of times the value  
rises is bounded.
We show that each operation during the course of the algorithm
can be charged to a rise in the value of  for some .
In fact, , every rise in the value of  is required 
to be charged at most   times during the  algorithm.
We account for the work required for each push of flow along a path or cycle
via a charging argument. 
There are at most  pushes of flow along edges of a path
before either:
(i) a 2-cycle  is encountered,
\ignore{
If the 2-cycle is between  and , source  increases the
assigned value  to . Since  was the only back-edge
on , there is a change in . We charge the  pushes 
to this rise in .
}
(ii) a source with  is encountered, 
(iii) an unsaturated sink is encountered,
\ignore{
The previous cases can be considered together with this case as they are similar. In both 
these cases, the surplus from a node travels along the edges of the derived graph
and reaches a source or a sink where no further push is required. There
are two cases for each of them:

\begin{itemize}

\item
The surplus at the starting node disappears and no new surplus is created

In this case, we charge the  pushes of flow to the node at which the surplus 
disappeared. We charge such a node only once for the disappearnce of the surplus. 
Note that any subsequent
appearance of surplus will be charged to the creation of the surplus and
is caused only in the case when the flow on 
a back-edge becomes zero, which is the second case explained below.  
There are, therefore, at most  pushes charged to the nodes
before either the surplus at each source is removed or a surplus appears. 

\item
There is a back edge  such that  becomes zero and a new surplus
at  is created where  was the preferred edge for .

In this case we assign a charge of  to
the creation of the surplus at this back edge.
At this step the valuation the edge  has been raised and thus
this back edge can not re-appear unless  changes. We allow an additional
charge of  to pay for the possible disappearance of the flow
from .

There are at most  back-edges on sink . The value  changes 
when the flow on each of these edges is reduced to zero. Therefore,
the total charge on all the back-edges incident out of a sink is at most  
pushes of flow after which there is a change in the value . This 
implies we have  pushes charged to a rise in . 

\end{itemize}
}
or (iv) a cycle is encountered. 
Note that in the last case all the calculations for 
determining the limiting number of
revolutions can be done in  time, since the cumulative transfer ratio can be 
determined by traversing the cycle once. As noted above, in all the cases
that arise when flow is pushed around the cycle,
either the surplus that has been pushed into the cycle reduces to 0 or the flow on one of the back edges is reduced to zero. The 
amount of work can be charged to the disappearance 
of surplus at a source or reduction of flow to zero on a back-edge ,
and hence an
increase in  , subsequently, when all back edges incident to
the sink  have the corresponding flow through them reduced to zero.
The other cases have a similar analysis.
The detailed complexity of the algorithm will be described in the next section.





\ignore{
The algorithm terminates in  time, where\\ .
From  the above, there are  charges per rise in  the  
value . Once a phase is over, the change in value of  causes sources to 
update the heaps (one at each source). This takes no more than  time.

The update  procedure takes  amortized time by maintaining a set of
values of  ,
each value being  either  or .
Thus, we require  at the end of a phase
to update all the data structures. The preprocessing requires  steps. 

Each rise causes the quantity  to grow by a factor of , starting with
. 
For each sink  such that , there exists an  such that  ships flow to  and  thus
. This  leads to . There are  different . Therefore
there can be no more than  total changes in   for all .  
Combining this with the fact that every rise in  is charged   amount
of work and , we have the result.
}
\ignore{
We use a sequence of lemmas.

\begin{lemma} 
\label{lemma_oneloop}
If there is a 2-cycle between a source  and a sink  then there
is no back-edge incident onto   other than .
\end{lemma}

The above  lemma follows directly from  procedure cleanup. The cleanup
procedure removes every 2-cycle unless there is no other back-edge
on the sink .  

\begin{lemma}
, every rise in the value of  is required 
to be charged at most   times during the  algorithm.
\label{lemma_charge}
\end{lemma}

\begin{proof}
We account for the work required for each push of flow along a path or cycle
via a charging argument. 
We consider the following cases that are exhaustive. 

There are at most  pushes of flow along edges of a path
before one of these happens

\begin{enumerate}
\item
A 2-cycle  is encountered

If the 2-cycle is between  and , source  increases the
assigned value  to . Since  was the only back-edge
on , there is a change in . We charge the  pushes 
to this rise in .

\item
A source with  is encountered. This case is analyzed together with the
next case.


\item
An unsaturated sink is encountered.

The previous cases can be considered together with this case as they are similar. In both 
these cases, the surplus from a node travels along the edges of the derived graph
and reaches a source or a sink where no further push is required. There
are two cases for each of them:

\begin{itemize}

\item
The surplus at the starting node disappears and no new surplus is created

In this case, we charge the  pushes of flow to the node at which the surplus 
disappeared. We charge such a node only once for the disappearnce of the surplus. 
Note that any subsequent
appearance of surplus will be charged to the creation of the surplus and
is caused only in the case when the flow on 
a back-edge becomes zero, which is the second case explained below.  
There are, therefore, at most  pushes charged to the nodes
before either the surplus at each source is removed or a surplus appears. 
\ignore{
Appearence of a surplus imples a change in the value
of  at the sink  where the flow on the back edge 
We call the sequence of steps between rises in
 as a phase. There is a change in some  at the 
end of the phase. We charge these  pushes to this rise
in . If no  rises the algorithm terminates.
}
\item
There is a back edge  such that  becomes zero and a new surplus
at  is created where  was the preferred edge for .

In this case we assign a charge of  to
the creation of the surplus at this back edge.
At this step the valuation the edge  has been raised and thus
this back edge can not re-appear unless  changes. We allow an additional
charge of  to pay for the possible disappearance of the flow
from .

There are at most  back-edges on sink . The value  changes 
when the flow on each of these edges is reduced to zero. Therefore,
the total charge on all the back-edges incident out of a sink is at most  
pushes of flow after which there is a change in the value . This 
implies we have  pushes charged to a rise in . 

\end{itemize}

\item
A cycle is encountered. All the calculations for determining the limiting number of
revolutions can be done in  time, since the cumulative transfer ratio can be 
determined by traversing the cycle once. As noted above, in all the cases
that arise when flow is pushed around the cycle,
either the surplus that has been pushed into the cycle reduces to 0 or the flow on one of the back edges is reduced to zero. The 
amount of work can be charged to the disappearance 
of surplus at a source or reduction of flow to zero on a back-edge ,
and hence an
increase in  , subsequently, in the same way as 
described for simple paths above. 

\end{enumerate}

From the case analysis above, we conclude the total charge on a rise
in  is   from case 1 and  from case 2,3 and 4, hence
proving the lemma.
\end{proof}



\begin{lemma}
The algorithm terminates in  time, where\\ .
\end{lemma}

\begin{proof}
From lemma \ref{lemma_charge}, there are  charges per rise in  the  
value . Once a phase is over, the change in value of  causes sources to 
update the heaps (one at each source). This takes no more than  time.

The update  procedure takes  amortized time by maintaining a set of
values of  ,
each value being  either  or .
Thus, we require  at the end of a phase
to update all the data structures. The preprocessing requires  steps. 

Each rise causes the quantity  to grow by a factor of , starting with
. 
For each sink  such that , there exists an  such that  ships flow to  and  thus
. This  leads to . There are  different . Therefore
there can be no more than  total changes in   for all .  
Combining this with the fact that every rise in  is charged   amount
of work and , we have the result.
\end{proof}

\begin{lemma}
The modified algorithm terminates with a  approximate solution.
\end{lemma}


\begin{proof}
The proof follows along similar lines as the proof of the algorithm in section \ref{sec_basic}




Firstly, we observe that while the algorithm \ref{alg_auc} {\bf Auction} 
does not require any particular order 
in which the surplus sources are picked, the sequence of choices of 
the sources from where the surplus is reduced,  as imposed by 
the modifications, still ensures  primal and dual constraints.

In the case of cycles, the modified algorithm 
essentially simulates multiple steps of the algorithm
\ref{alg_auc} {\bf Auction}. The end result is exactly the same if each step was 
performed individually
and repeatedly. The amount of flow shipped out of a source at each step, however, may be 
{\em smaller} than what Algorithm \ref{alg_auc} {\bf Auction} would have shipped out. 
However, the primal and dual constraints are still ensured.

The modified algorithm does not make any additional changes to the variables ,
 or . The only affected variables are  in the 
preprocessing procedure. This 
change does not affect the claim that  for  all  in the proof
of lemma \ref{lemma_primalCS} as  is set to  itself. 
The pre-processing procedure 
leaves at least one back-edge intact; this ensures no changes in  takes place as 
a result of the preprocessing. All the arguments involving  are, therefore, unaffected.

Thus we can state that
\begin{itemize}

\item
The primal solution obtained by the algorithm {\em Modified Auction} is feasible.

\item
The dual solution obtained by the modified algorithm is feasible.

\end{itemize}


Due to the fact that the change in  and consequent changes in other variables are
locally ensured by the same procedure as  in the previous section, the following holds:
\begin{itemize}

\item
The complementary slackness conditions {\bf CS1}and {\bf Cs2}
\ref{sink_cond} 
are satisfied exactly and condition  {\bf Cs3}
is satisfied approximately.

\item
At termination the difference between the value of 
primal solution  and the value of the 
dual solution is at most 

\end{itemize}

We thus conclude with the lemma
\end{proof}

We now conclude the main result

\begin{theorem}
The Maximum Profit Budgeted Transportation Problem can be solved approximately to within
a factor  in   time.
\end{theorem}
}
\section{Edge Capacities}
\label{Edge-formal}

In this section we further generalize the Budgeted Transportation Problem. In this version
each edge has an upper bound on the flow going through. The capacity of each edge
is represented by . We call this problem the Budgeted
Transshipment (BTS) problem. It is easy to see that the budgeted transportation is a special
case where edge capacities are infinite. 

Consider the Linear Program for BTS 



\ \  subject to:



The dual of the above program is 



\ \  subject to:


And the complementary slackness conditions are





\section{Approximation Algorithm for BTS}
\label{sec_extend}

We now present a detailed  approximation algorithm for the BTS problem.

We first (re)define some terms

\paragraph*{Edge dual variable : }
The dual variable associated with each  edge. If  is saturated, 
 is 
set as,   
over all choices of edges  .
It is set to 0  if edge  is unsaturated.

\paragraph*{Preferred Edge: } 
For each source  an edge , termed , such that  is 
unsaturated and  is maximized. Note that in the case 
when more than one edge meet the criteria, one of them is chosen as the preferred
edge. The preferred edges are directed forward (from  to ) in the derived graph. 
Therefore, every forward edge is unsaturated. 
\paragraph*{Back Edge: }
An edge  such that  and .\\

As in the previous algorithm, a derived graph  is used by the algorithm.
The derived graph has vertices as the original vertex set and edges as back edges
and preferred edges. The edges are directed
with the preferred edge from source , , being directed from source
 to a sink , with capacity given by , 
and a back edge directed from a sink  to a source  with capacity .

The algorithm differs from the one in section \ref{sec_auc} in  the
use of the variables . 
To ensure complementary slackness,
this variable becomes non-zero only if 
edge  is saturated. 
This variable is not explicitly maintained but its value can be deduced from
 and .
Its value indicates the extra cost incurred in
using another edge from source .
To ensure complementary slackness conditions,
the value of the variable  implicitly reduces when 
rises and when 
the reduced value becomes zero, the edge  can be designated as a back-edge
such that flow can be pushed back on 
the edge , leaving it unsaturated.


The following additions/modifications are made to the algorithm:

\begin{itemize}

\item
During the initialization,  is set to zero.

\item
 update: This update occurs when  ,
for all unsaturated edges with positive flow. 
See procedure \ref{proc_update}
{\bf update}.

\item
Preprocessing : Before the removal of 2-cycles, for each saturated edge
, if ,  cannot be  a back edge. In case 
, it becomes a back edge. (See procedure \ref{proc_update} 
{\bf update}).


\item
Path/Cycle discovery  and pushing 
of flow: In the BTS problem, the forward edges have a capacity 
as well. While pushing the flow in a path or in a cycle, the bottleneck edges 
could be forward edges in addition to back-edges. 
(See \ref{proc_findpath} {\bf findpath}, \ref{proc_pushpath} {\bf
pushFlowPath} and \ref{proc_pushcycle} {\bf pushFlowCycle}).

\end{itemize}

The algorithm with the above modification is described as Algorithm \ref{alg_modauc} 
{\bf Modified Auction},
along with the associated procedures. 

The algorithm initializes the
primal and dual solution using procedure \ref{proc_modinit} {\bf Initialize}. 
Preprocessing is done in procedure \ref{proc_preprocess} {\bf Preprocess}
to choose the 
preferred edge and eliminate 2-cycles.

It then repeats the following steps:  find a path in the derived 
graph using \ref{proc_findpath} {\bf findpath}; depending on whether the path found
is a simple 
path or contains a cycle, the algorithm pushes flow  using \ref{proc_pushpath} {\bf pushFlowPath} or 
\ref{proc_pushcycle} {\bf pushFlowCycle}. 

Procedure \ref{proc_pushpath} {\bf pushFlowPath} starts with the first source and
moves flow along the path without accumulating it at any of the intermediate sources, unless,
one of the edges on the path is saturated. In this case, the source preceding the edge
accumulates some surplus.

Procedure \ref{proc_pushcycle} {\bf pushFlowCycle} is more involved. It uses 
Procedure \ref{proc_pushpath} {\bf pushFlowPath} to transfer the surplus from the initial source
to the first source that the algorithm encounters in the cyclic part of the path 
(See figure \ref{fig_cyclepush2}).
It then computes the number of pushes of flow through the cycles that are required
to (i) identify bottleneck edges or (ii) push the surplus to zero
(See figure \ref{fig_cyclepush3}).
Note that an extra 
last push may be required 
to transfer the flow from the first source in the cycle to the one just before the 
bottleneck edge as illustrated in figure \ref{fig_cyclepush4}.

When required,  is updated using Procedure \ref{proc_update} {\bf update} and 
preprocessing is done for the next iteration. It also checks if a  saturated edge
  which has a small value of   prior to the
increase in  has the condition
that ,
i.e. the edge is on the verge (i.e.  is close to ) 
of becoming unsaturated and 
allows for the edge to become unsaturated by designating the edge
as a back-edge. 

Each source maintains the effective profit  for all the 
unsaturated edges in a heap. Whenever an edge is saturated, it is removed 
from the heap. When  is set to 0, it is re-inserted into the
heap. Each of these operations requires  time. These operations are performed
when  changes, for any . 

The algorithms terminates when all the complementary slackness conditions are approximately 
met. The algorithm can be analyzed for correctness as well as complexity using the same 
framework as section \ref{section_modified}.

The correctness is shown by proving that both primal and dual solutions are feasible throughout
the execution and complementary slackness conditions are approximately met at termination.

The complexity is analyzed via a charging argument. Each iteration of the algorithm is
charged to one of the events: clearing of surplus at a source, saturation of a sink or 
saturation of an edge. All such charges are then accounted for in the
final analysis.

The details of the algorithm and the proofs are presented in the following section.






\subsection{Detailed Algorithm}
\label{sec_details}

 The modified  algorithm for BTS is presented below in detail, followed by 
proof of correctness and complexity analysis. Since BTP is a special case
of BTS, the algorithm is applicable to both the problems.

\begin{algorithm}
\caption{ {\bf Modified Auction}}
\begin{algorithmic}[1]

\vspace*{.1in}
\STATE{ {\bf Initialize}}
\STATE{{\bf Preprocess}}
\WHILE{ there exists a source  such that  {\bf and} }
\label{alg_modauc:line1}
\STATE{  {\bf FindPath}()}
\IF{ contains a cycle  which is not a 2-cycle at the end of }
\STATE{ {\bf pushFlowPath} () where  is the portion of  before }
\STATE{ {\bf pushFlowCycle }()}
\ELSE
\IF{ does not end with a 2-cycle}
\STATE{ {\bf pushFlowPath}()}
\ELSE
\STATE{// ends at a 2-cycle  }
\STATE{ {\bf pushFlowPath}() where  excludes the last edge }
\STATE{ Eliminate back edge  and let
}

\ENDIF
\ENDIF
\STATE{{\bf Update }}
\ENDWHILE

\end{algorithmic}
\label{alg_modauc}
\end{algorithm}

\begin{algorithm}
\caption{{\bf Initialize}}
\begin{algorithmic}[1]
\vspace*{.1in}

\STATE{ for all }
\label{proc_modinit:line1}
\STATE{ for all }
\label{proc_modinit:line2}

\STATE{ for all }
\label{proc_modinit:line3}
\STATE{ for all }

\end{algorithmic} 

\label{proc_modinit}
\end{algorithm}


\begin{algorithm}
\caption{\bf Preprocess} 
\begin{algorithmic}[1]
\vspace*{.1in}

\FORALL { such that  {\bf and } }
\STATE{Find an unsaturated  such that  is maximized}
\STATE{Make  the preferred edge for source }
\STATE{} 
\label{proc_preprocess:line1}
\STATE{//Remove all 2-cycles unless it involves the only back edge}
\IF{ such that }
\STATE {} 
\ENDIF
\ENDFOR


\end{algorithmic}
\label{proc_preprocess}
\end{algorithm}




\begin{algorithm}
\caption{{\bf  update} } 
\begin{algorithmic}[1]
\vspace*{.1in}

\FORALL {}
\STATE{ //Update  if all assigned sources are shipping at the higher value}
\IF{  such that edge  is unsaturated and  } 
\STATE { }
\label{proc_update:line1}
\FORALL { such that edge  is saturated}
\IF{}
\label{proc_update:line3}
\STATE{//There is an edge with  close to zero, i.e. there is another edge with a larger effective profit}
\STATE{Designate  as a back-edge}
\label{proc_update:line2}
\STATE{//Raise  to  if it is 0 and sink 
 is saturated}
\IF{ {\bf and} }
\STATE{}
\label{proc_update:line10}
\ENDIF

\ENDIF 
\ENDFOR
\ENDIF
\STATE{{\bf Preprocess}}
\ENDFOR

\end{algorithmic}
\label{proc_update}
\end{algorithm}


















\begin{algorithm}
\caption{{\bf pushFlowPath}()}
\begin{algorithmic}[1]
\vspace*{.1in}
\ENSURE{ or }

\STATE{ // is the amount that is transferred. Initially, it is the surplus at the first source
in the path}
\STATE{}
\STATE{ }
\IF{ ends at }
\STATE 
\ENDIF
\FOR{ to } 
\STATE//The transferable amount is subject to the forward and backward edge capacity constraints
\STATE{}
\label{proc_pushpath:line1}
\STATE {}
\label{proc_pushpath:line4}
\STATE {}
\STATE{// is multiplied by the fraction of two prices to reflect the proportional\\
//flow reduction on back edge }
\STATE {}
\label{proc_pushpath:line2}
\STATE {}
\ENDFOR
\IF{}
\STATE{ })
\STATE {}
\ENDIF
\label{proc_pushpath:line3}




\end{algorithmic}
\label{proc_pushpath}
\end{algorithm}
  


\begin{algorithm}
\caption{{\bf pushFlowCycle}()}
\begin{algorithmic}[1]
\vspace*{.1in}

\REQUIRE{ is a cycle in the derived graph}

\STATE{//Compute }
\STATE{ }
\STATE{//Compute limiting number of revolutions for each edge}
\FOR{}
\IF {}
\STATE{}
\STATE{}
\ELSE
\STATE{}
\STATE{}
\ENDIF
\STATE{}
\STATE{}
\ENDFOR
\STATE{}   
\STATE{//  can be } 
\STATE{}
\STATE{}
\STATE{}

\vspace*{.1in}
\STATE{//change the flow on each edge to simulate pushing of multiple revolutions} 
\FOR{ to }
\IF{}
\STATE{}
\ELSE
\STATE{//Compute the convergence of the infinite series }
\STATE{}
\ENDIF
\STATE{}
\STATE{}
\ENDFOR

\vspace*{.1in}
\IF{  is finite}
\STATE{//Send one more cycle of flow ; this will saturate some edge in one revolution}
\STATE{{\bf pushFlowPath}()}

\vspace*{.1in}
\STATE{Let  where the edge  was 
saturated in previous step}
\STATE{{\bf pushFlowPath}()}
\ENDIF

\end{algorithmic}
\label{proc_pushcycle}
\end{algorithm}

\begin{algorithm}
\caption{{\bf findPath}()}
\begin{algorithmic}[1]
\vspace*{.1in}

\REPEAT
\IF { {\bf or} source  already belongs to } 
\STATE {return }
\ENDIF
\STATE{Add source  to }
\STATE{Let  be the sink such that  is }
\label{line_xyz}
\IF { {\bf or} sink  already belongs to }
\STATE { return }
\ENDIF
\STATE{Add sink  to }
\STATE{Let  be a source such that  is a back edge}
\STATE{} 
\UNTIL{\bf false}


\end{algorithmic}
\label{proc_findpath}
\end{algorithm}





\begin{figure}[h]
\centerline{\epsfysize=190pt\epsfbox{cyclePush2.eps}}
\caption{ First we bring the surplus to the first source in the cycle, possibly
          saturating an edge en route}
\label{fig_cyclepush2}
\end{figure}



\begin{figure}[h]
\centerline{\epsfysize=190pt\epsfbox{cyclePush3.eps}}
\caption{Send the flow around the cycle as many times as possible without
saturating any edge}
\label{fig_cyclepush3}
\end{figure}


\begin{figure}[h]
\centerline{\epsfysize=190pt\epsfbox{cyclePush4.eps}}
\caption{Send it one more time possibly saturating an edge and accumulating
surplus at the source before it}
\label{fig_cyclepush4}
\end{figure}





\subsection{Feasibility of the Solutions}

\begin{lemma}
The primal and dual solutions maintained by algorithm \ref{alg_modauc} {\bf Modified Auction}
are feasible throughout its execution.
\label{lemma_BTSfeasible}
\end{lemma}

\begin{proof}
Consider the initial primal solution  for all  (line \ref{proc_modinit:line1}
in Procedure \ref{proc_modinit} {\bf Initialize}). This is clearly a feasible primal solution.

Thereafter, the flow is increased or decreased in Procedures \ref{proc_pushpath} 
{\bf pushFlowPath}  and
\ref{proc_pushcycle} {\bf pushFlowCycle}. Let us consider each possible change.

\begin{enumerate}
\item
Increase/decrease of flow along a forward edge in line \ref{proc_pushpath:line1} of
Procedure \ref{proc_pushpath} {\bf pushFlowPath}. 

\begin{enumerate}
\item
The source constraint is satisfied as the increase in flow on edge  is at 
most the surplus generated at source  in the previous iteration.

\item
Also, the increase is at most the available edge capacity , therefore
edge capacity constraint is satisfied.

\item
The total increase in the price of incoming flow on sink  is 
(line \ref{proc_pushpath:line4}) and the total decrease is 
. Therefore, there
is no net change and the budget constraint remains satisfied and tight. 

\item
The decrease on edge  is  
(line \ref{proc_pushpath:line2}, \ref{proc_pushpath:line3}) where  is at most
. Therefore the decrease
is at most . Thus the positivity constraint on edge flows
is satisfied.
\end{enumerate}


\item
Increase/Decrease in flow in Procedure \ref{proc_pushcycle} {\bf pushFlowCycle}. Everytime the
flow is pushed, the outgoing flow equals the incoming flow on every source
and a proportional amount out of every sink. Therefore,
not only are the source constraints satisfied, but also the
budget constraints on the sink.  The number of times the flow is pushed in the 
cycle is the minimum of  the limiting number of revolutions. Therefore the capacity 
constraints are satisfied. 

The last step uses Procedure \ref{proc_pushpath} {\bf pushFlowPath}, which satisfies the
constraints as explained above.

\end{enumerate}

Now consider the dual solution and its feasibility. For all ,  is 
initialized to  which is clearly larger than 
 as  and  are
zero to begin with (lines \ref{proc_modinit:line2} and \ref{proc_modinit:line3} in
Procedure \ref{proc_modinit} {\bf Initialize}). 

All the instances in the algorithm where these variables change are enumerated below. 
Assuming that the solution is feasible till these changes are made, we 
show the solution is still feasible after the change. 

\begin{enumerate}

\item
The update of  in Procedure \ref{proc_update}  {\bf Update}
at lines \ref{proc_update:line1} and \ref{proc_update:line10} increases it's value. 
Since any increase in   implies a decrease in the value 
,  remains larger 
than .

\item
Change in  :  is assigned a value 
equal to . Therefore,
for every ,  
by construction.



\item
Note that any change in  only occurs when there is a change
in some , it does not change independently.  When it changes, it is set 
to  (see line 
\ref{proc_preprocess:line1} in algorithm \ref{proc_preprocess} {\bf preprocess}). It is
therefore, larger than  for all  as 
.

\end{enumerate}
\end{proof}

\subsection{Complementary Slackness} We prove the following lemma about
the satisfaction of complementary slackness conditions.

\begin{lemma}
The algorithm terminates with the following conditions satisfied

\label{lemma_BTSapprox}
\end{lemma}


\begin{proof} We consider each condition  

\begin{enumerate}


\item{Source slackness condition (\ref{source_cs_condedge}).}
These are the terminating 
condition for algorithm \ref{alg_modauc} (line \ref{alg_modauc:line1}). They are, 
therefore, satisfied at the end. 

\item{Sink slackness condition (\ref{sink_cs_condedge}).} 
Note that  is
initialized to zero (Procedure \ref{proc_modinit}, line \ref{proc_modinit:line2}). Thereafter,  is changed
only when sink  is saturated (Procedure \ref{proc_update}, line \ref{proc_update:line10}). 
Also, once a sink is saturated, it stays saturated. This can be seen by observing that any
decrease of flow along any back-edge only takes place as a result of an increase in
proportional amount of flow along some other edge on this sink.

\item{Edge slackness condition (\ref{edge_cs_condedge}).} 
These are satisfied initially as . Thereafter,
as long as  is greater than zero, the flow does not decrease on this edge as
it is never designated a back edge. Only when  is set to zero 
(Procedure \ref{proc_update}, line \ref{proc_update:line3}),
is the edge allowed to become a back edge. 

\item{Flow slackness condition (\ref{approx_cs_condedge}).} 
Similar to the proof of  lemma~\ref{lemma_primalCS}, we show that the following is  satisfied.


Consider unsaturated edges. Whenever a flow is increased along an edge
 it is a preferred edge. In Procedure \ref{proc_preprocess}, line \ref{proc_preprocess:line1},
whenever an edge is chosen as a preferred edge,  is set to  with
 being zero as it is an unsaturated edge. The slackness condition is therefore, satisfied.
Subsequently,  can rise by a factor of  resulting in a rise of at most 
 in effective profit, still satisfying (\ref{app_cond_mod}). Once 
 has changed,  now becomes a back edge. Now,  can not change any further
 unless this back edge has zero flow
(Procedure \ref{proc_update}, lines 3,4 and 8).
If as a consequence of a rise in ,  is set to zero, 
the inequality (\ref{app_cond_mod})
is true and  no further flow will be pushed from source . 
 cannot rise until all flow is pushed back to source .

Next consider  when the edge is saturated.
In this case  is set to , thereby 
satisfying (\ref{app_cond_mod}).
However, flow may be pushed back on the saturated edge such that it
becomes unsaturated and  is 
set to zero. This happens when  rises. The change in the quantity 
 is no more than ; thus
  just prior to being set to zero. Thus
condition (\ref{app_cond_mod}) is satisfied after the change.
Condition (\ref{approx_cs_condedge}) immediately follows from condition (\ref{app_cond_mod}).  

\end{enumerate}
Hence we conclude the above lemma.
\end{proof}

From the above two lemmas 
we conclude:
\begin{theorem}
The algorithm determines a  primal solution to the BTS problem such
that  where  is the optimal
solution to the BTS problem.
\end{theorem}
\begin{proof}
The proof is similar to the proof  of  lemma~\ref{lemma_approx}.
The value of the dual solution is 


When we subtract the value of the primal solution , from the
above, the  difference is



Thus, the total absolute difference is at most  where









By arguments similar to lemma~\ref{lemma_approx} and using lemma~\ref{lemma_BTSapprox}
we get that the difference is at most  .
\ignore{
From lemma \ref{lemma_primalCS}, we have 



Therefore, 



From the termination condition of the algorithm, we know that for any source
 such that , we have .

Therefore 





For all unsaturated sinks . Therefore, 

}

\end{proof}




\subsection{Complexity}
To prove the complexity we  first consider the effect of the pre-processing
step during the algorithm.
In this step the algorithm
removes every 2-cycle unless there is no other back-edge
on the sink .  

The lemma below follows directly:
\begin{lemma} 
\label{lemma_oneloop}
If there is a 2-cycle between a source  and a sink  then there
is no back-edge incident onto   other than .
\end{lemma}
The algorithm finds path and cycles and pushes flow on edges
of the path or cycles. Each operation corresponding to a 
push of flow on an edge either enables a reduction
in surplus and changes flow to the capacity of the edge. 
If the flow on a back edge reduces to zero, this  leads to
a change on the dual variables  for some sink . 
We attempt to charge the various operation in finding paths or cycles and the
subsequent processing to changes in the dual variables.
\begin{lemma}
Each operation in the  procedures  {\bf pushFlowPath, pushFlowCycle, findPath}
can be charged to a rise in the value of  for some 
such that each rise in the value of  is charged  operations .
\label{lemma_charge}
\end{lemma}
\begin{proof}
We account for the work required for each push of flow along a path or cycle
via a charging argument. 
\ignore{
We will use the following key fact:\\
{\bf Fact 1:} If the flow on edge   at valuation
 is reduced to zero, 
then  occurs as a back edge only when 
the value of  rises to .\\
This fact follows due to the fact the  is monotonically non-decreasing.
Furthermore, flow can only be pushed on edge  at an increased valuation 
and an edge
is termed a back-edge when there is flow on the edge that has been pushed at a valuation of .
}
Procedure {\bf findPath} requires  steps.
Further, during {\bf pushFlowPath}
there are at most  pushes of flow along edges of the path
before one of these happens
\begin{enumerate}
\item
A 2-cycle  is encountered.

If the 2-cycle is between  and , source  increases the
assigned value  to . Since  was the only back-edge
on  (Lemma~\ref{lemma_oneloop}), there is a change in . We charge the  pushes 
to this rise in .

\item
A source with  is encountered. This case is analyzed together with the
next case.


\item
An unsaturated sink is encountered.

The previous cases can be considered together with this case as they are similar. In both 
these cases, the surplus from a node travels along the edges of the derived graph
and reaches a source or a sink where no further push of flow is required. The
following sub-cases arise:

\begin{enumerate}

\item
The surplus at the starting node disappears and no new surplus is created

In this case, we charge the  at most  pushes of flow along the edges of the path
to the node at which the surplus 
disappears. We charge such a node only once for the disappearance of the surplus. 
Note that any subsequent
appearance of surplus will be charged to the creation of the surplus and
is caused only in the case when the flow on 
a back-edge becomes zero, which is the second case explained below.  
Considering all possible source-sink pairs,
there are, therefore, at most  pushes charged to the nodes
before either the surplus at each source is removed or a surplus appears. 
\ignore{
Appearence of a surplus imples a change in the value
of  at the sink  where the flow on the back edge 
We call the sequence of steps between rises in
 as a phase. There is a change in some  at the 
end of the phase. We charge these  pushes to this rise
in . If no  rises the algorithm terminates.
}
\item
There is a back edge  such that  becomes zero and a new surplus
at  is created where  was the preferred edge for .

In this case we charge the push on edges of the path leading to
this back edge, i.e.  a charge of , to
the creation of the surplus at this back edge.
By lemma~\ref{beta-increase} this back edge can not re-appear unless  changes. We allow an additional
charge of  to pay for the possible disappearance of the flow
from .

There are at most  back-edges on sink . The value  changes 
when the flow on each of these edges is reduced to zero. Therefore,
the total charge on all the back-edges incident out of a sink is at most  
pushes of flow after which there is a change in the value . This 
implies we have  pushes charged to a rise in . 

\item
There is a forward edge  which becomes saturated to 
capacity, i.e. .
If a forward edge is saturated, it stays saturated 
until it becomes a back edge when . 
When an edge   becomes a back edge, by lemma~\ref{beta-increase}
this edge cannot occur again as a back edge  until  increases.
We can, therefore charge this
work to the corresponding rise in the value of .
The rise in  could be charged  times as in the
previous case.
Note that as a result of this 
saturating push, surplus 
could be generated on the source just before the edge . 
We put an additional charge 
of  on this edge to pay for the possible disappearance of this surplus in the future. 

\end{enumerate}

\item
A cycle is encountered. In {\bf pushFlowCycle}, 
all the calculations for determining the limiting number of
revolutions can be done in  time, since the cumulative transfer ratio can be 
determined by traversing the cycle once. As noted above, in all the cases
that arise when flow is pushed around the cycle,
either (i) the surplus that has been pushed into the cycle reduces to 0 or (ii) the flow on one of the back edges is reduced to zero or (iii) the flow
on one of the forward edges reaches capacity. The 
amount of work can be charged to either the disappearance 
of surplus at a source, or a  reduction of flow to zero on a back-edge , or
the saturation of a forward edge. This implies  an
increase in  , subsequently, in the same way as 
described for simple paths above. 

\end{enumerate}

From the case analysis above, we conclude the total charge on a rise
in  is   from case 1 and  from case 2,3 and 4, hence
proving the lemma.
\end{proof}



\begin{lemma}
The algorithm terminates in  time, where\\ .
\end{lemma}

\begin{proof}
From lemma \ref{lemma_charge}, there are  charges per rise in  the  
value . Once a phase is over, the change in value of  causes sources to 
update the heaps (one at each source). This takes no more than  time.

The update  procedure takes  amortized time by maintaining a set of
values of  ,
each value being  either  or .
Thus, we require  at the end of a phase
to update all the data structures. The preprocessing requires  steps. 

Each rise causes the quantity  to grow by a factor of , starting with
. 
For each sink  such that , there exists an  such that  ships flow to  and  thus
. This  leads to . There are  different . Therefore
there can be no more than  total changes in   for all .  
Combining this with the fact that every rise in  is charged   amount
of work and , we have the result.
\end{proof}

\ignore{
Consider an 
iteration of the while loop in Algorithm \ref{alg_modauc} {\bf Modified Auction}. 
Each iteration results in either 
(i)   disappearance of flow at either the starting source, or at a sink or in a cycle
(ii) an edge
being saturated in the forward direction or 
(iii) flow being reduced to zero on a back edge.
This is determined by the procedures 
\ref{proc_findpath} \ref{proc_pushpath} and \ref{proc_pushcycle}, each procedure requiring  steps.
After finding a flow path or a cycle, note that either 
flow is reduced to zero at a source  or some
edge on  the path or the cycle is saturated. We consider these cases below:
\begin{itemize}
\item
If the surplus at a source disappears without any edge being saturated, 
we charge this work to this source. There are  sources and each path or
cycle discovery and
push takes  time. Therefore
the total charge is  before surplus at all sources disappears or
 a sink is saturated effecting a
rise in . 

\item
If a forward edge is saturated, it stays saturated unless  increases since a saturated edge
becomes a back edge only when  reduces to zero. We can, therefore charge this
work to the corresponding  rise. Note that as a result of this 
saturating push, surplus 
could be generated on the source just before the edge . We put an additional charge 
of  on this edge to pay for the possible disappearance of this surplus in the future. 

Since each sink could have a total of  edges, the total charge on 
each  rise could be .  

\item
If the bottleneck is a back edge, we similarly charge the  work (including the charge for the possible disappearance 
of accumulated surplus on the preceding source) to the back edge where the 
flow is reduced to zero (also referred to as the back edge being zeroed out).
We then note that
for every  change there are at most  back edges that can be zeroed out, as
once a back-edge is zeroed out, the flow can only increase on this edge if it becomes
the preferred edge i.e.  (see \ref{proc_preprocess}). 
It can then become a back edge again, 
only when   has changed. 
As there are at most  back-edges per sink there is a
total of  charge for each  rise.

\end{itemize}
The Procedure \ref{proc_preprocess} {\bf preprocess} is called after every  change
and in the beginning. 
This procedure updates the preferred edges and back edges for each source connected to 
this sink. The time 
required for updating the back edges is  since the heap has to be updated
for each source, each heap containing  edges.  The preferred edge can then
be updated.


To account for the total work we note that each  rises at most 
 times. There are a total of  different .
Therefore, the total work done is .
Combining this result with lemmas \ref{lemma_BTSfeasible} and \ref{lemma_BTSapprox} 
we conclude:


\begin{theorem}

The budgeted transshipment problem can be solved to within a  
approximation in  time.

\label{theorem_BTScomp}

\end{theorem}
}

\section{Concave, Piecewise Linear Profit}
\label{piece-wise}

We now describe how to extend the above algorithm to a profit function which 
is concave and piecewise linear. We use the common edge splitting technique 
in order to reduce the problem to the linear profit function. This transformation
is very similar to the well known transformation of convex cost mincost flows to
linear mincost flows, see \cite{ahuja}

Given an instance  of the problem with concave piecewise linear profits,
we map it to an instance  of the capacitated but linear profit version.

Let the profit function be defined as  for the edge  and interval
 each interval being of fixed length say , total number of intervals 
being . 

\begin{figure}[h]
\centerline{\epsfysize=170pt\epsfbox{pwlinear1.eps}}
\caption{The profit function for an edge . The slope in an interval  is . Number
of intervals is }
\end{figure}

We then convert the problem by  splitting each edge into  edges, the
th edge being  of capacity
 and profit . The price of each is the same as the one for edge . 

\begin{figure}[h]
\centerline{\epsfysize=180pt\epsfbox{pwlinear2.eps}}
\caption{Construction of multiple edges corresponding to one original edge.}
\end{figure}

It is easy to see that a solution to instance  can be easily converted into a solution for
instance . A solution to , however, can not always be converted into a 
solution for . Nevertheless, any solution to  can always be modified into 
a solution with greater or same profit such that the new solution 
can be transformed into a solution for . 

If for a solution  the following property holds;   such that
  and  and , then we can convert the solution to one for . 

If this property does not hold then the profit can be increased/kept the same
while eliminating such pairs. Transfer 
from the edge  to . The profit  because of
concavity and thus we obtain a more profitable solution. 
Repeating these transfers, we get the property that
  such that
  and  and . 

This approach can also be used to map an approximate solution. As a consequence, the
algorithm \ref{alg_modauc} {\bf Modified Auction} can be used to approximate the above problem
after the appropriate transformation. The transformation, however,
does involve an increase in the number of edges. We conclude with the following result.

\begin{theorem}
The Budgeted Transportation problem where the profit function is piecewise-linear and concave,
can be approximated within a factor of  in 
 time
where  is the number of intervals in the profit function.
\end{theorem}

\section{Conclusion}
\label{sec_conc5}


We have presented an approximation scheme for Budgeted Transportation problem. We further
generalize it to the capacitated version, which can then used to solve the problem
with a non-linear profit version.

The technique used is a kind of primal-dual mechanism based on Auctions. The variables
are modified in small steps in order to maintain approximate slackness conditions. We
use augmenting path based mechanism to improve the complexity of the scheme. However,
because of the nature of the problem, the cycles may arise in addition to simple paths. 
We have shown that the cycles can be handled without too much work. 

An interesting open question is whether it is possible to solve the problem exactly and
as a consequence, generalized flow using the above scheme. 



\bibliographystyle{plain}
\bibliography{ref}

\section{Appendix-Relation to Generalized Flow} 
\label{sec_relation}

Apart from being a natural extension of the Transportation Problem BTP is also
related to a well known flow problem, generalized flows. As mentioned above,
it is a special case of Generalized Flow. It is interesting to see, however, that
there  also exists a reverse relationship. We show how to transform the 
generalized flow problem
to Budgeted Transportation.



\paragraph*{Mincost Generalized Flow: }
We are given a digraph , a cost function , a
capacity function , a multiplier function 
 a source , the supply at the source 
, a sink  and the demand  at the sink. The goal
is to find a flow function,   such that the flow 
is conserved at the nodes,
is multiplied across the arcs and meets the supply and demand constraints, 
while minimizing the total cost of the flow. This problem can be expressed as
the following linear program.







\paragraph*{Mincost Budgeted Transportation: }

This problem is a more generalized version of the conventional 
transportation problem. We are given a bipartite graph , consisting
of sources  and sinks . A supply function 
, a budget function , a cost 
function  and a price function 
. The goal 
is to come up with a flow function  such
that the total flow going out of a source is equal to the supply,
the total price of the flow coming into a sink is equal to the budget,
and the cost of the flow is minimized. The problem is stated below 
as an LP.






We first show that an MCGF problem instance  transforms to a minimum Budgeted
Transportation problem instance. The optima of the two instances are the
same and the solutions themselves can be mapped to each other. The transformation
is valid even for approximate solutions.

Let 
be an instance of the MCGF problem. We transform it
to an instance 
of Mincost Budgeted Transportation problem as follows

\begin{itemize}
\item
For each  node  in , we have a corresponding source
 with capacity .
\item
For each arc   in , we have a corresponding sink in ,
, with budget .


\item
We have one additional sink  with budget equal to the supply  in .
It is connected to the source corresponding to source node  with an
edge whose price is 1 and cost is 0.

\item
Each sink  has two incoming edges from  and , and the
cost and price are as follows




\item
The capacity of the source corresponding to the sink in  is equal to
the demand 



\end{itemize}

Consider a  pair  of flow functions  and  for the instances  and , respectively.
Let these be related to each other according to the relations defined for 
all  pairs in the instance .

Further, for the source  corresponding to the node ,


\begin{lemma}
For a given solution  to the original instance ,  is a feasible solution to
 of the same cost.
\label{FtoFdash} 
\end{lemma}

\begin{proof}
We show that  is a feasible solution to  by showing that it meets the 
constraints \ref{source_cons} and \ref{sink_cons}. 

For each source , except the source ,
the total outgoing flow is the sum of flows
to the sinks corresponding to outgoing and incoming edges on node ,
which is,



Using the mapping of solutions, this is equal to 

Therefore, constraint \ref{source_cons} is met.

For the source , a similar analysis shows that constraint
\ref{source_cons} is met,
since  and .


For each sink  the total price of the incoming flow is 

Therefore, the constraints \ref{sink_cons} are met.

Also, the total cost of  

which is same as the cost of .
\end{proof}

\begin{lemma}
For a given solution  to the  instance ,  is a feasible solution to
 and is of the same cost.
\label{FdashtoF}
\end{lemma}

\begin{proof}
To show that the conservation of flow constraint is met, consider
the total incoming flow on a node , which is 



There are two sets of edges incident on source . The ones
corresponding to incoming edges on node ,  and
others that corresponding to outgoing edges . The sum
of  the flow  on these is equal to . So the the above is



Since the total price of incoming flow on sink  is equal to
 which is
equal to the budget of the sink , the above becomes,


which is equal to the outgoing flow .
For the case of the source and sink, there are no incoming or outgoing
edges, respectively. But,

thus ensuring the sink demand in  and

Thus the outgoing flow at the source,

since .
 

Now we show that the capacity constraints are met. For each edge 
, from constraint 30,  we have


The cost of the solutions are mapped exactly as in the proof of lemma 

\ref{FtoFdash}
\end{proof}

Bey combining the lemmas \ref{FtoFdash} and \ref{FdashtoF} we conclude
the following theorem regarding the equivalence of the two problems. 


\begin{theorem}
Given an instance of the MCGF problem  we can construct an instance
of Budgeted Transportation Problem such that the optimum solutions
of each have the same cost.
\end{theorem}

Also, note that the solutions themselves can be mapped to each other.
Thus, by solving the Budgeted Transportation problem we not only determine
value of the optimum solution, we can also construct the solution itself.
\vspace*{.2in}

\subsection{Mincost to Maxprofit Budgeted Transportation}
In order to minimize the cost, we could maximize the negative of the cost
. The maximization, however, does not clear the sources and as such 
conservation of flow in the mapped solution to the original problem would not 
be achieved.

We can get over this problem by minimizing instead,  where 
is a very large constant. Since every edge has a very large profit, 
the optimum will clear all the sources. Any error  in clearance will
produce a negative term  in the total profit. By choosing
an  large enough,  can be made negligibly small; i.e. smaller
than the granularity of values in the solution of a Linear Program. We refer
to \cite{papadimitriou} for the discussion and bound on this granularity. 

The cost of 
the optimum would be , where  is
an optimum solution for the mincost instance. 
We note that an approximate solution to Maxprofit Budgeted Transportation, would not
immediately lead to an approximation algorithm for Generalized flow.


\end{document}
