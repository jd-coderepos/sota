\documentclass{article}









\usepackage[final, nonatbib]{neurips_2020}

\usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}    \usepackage[hyphens]{url}            \usepackage{booktabs}       \usepackage{amsfonts}       \usepackage{nicefrac}       \usepackage{microtype}      \usepackage[inline]{enumitem}
\usepackage{color}
\usepackage{refcount}
\usepackage{bbm}
\usepackage{makecell}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{multirow}
\usepackage{xspace}
\usepackage{subcaption}


\SetKwInput{KwInput}{Input}
\SetKwInput{KwOutput}{Output}
\SetKwInput{KwData}{Data}


\makeatletter
\usepackage{xspace}
\def\@onedot{\ifx\@let@token.\else.\null\fi\xspace}
\DeclareRobustCommand\onedot{\futurelet\@let@token\@onedot}

\newcommand{\figref}[1]{Fig\onedot~\ref{#1}}
\newcommand{\equref}[1]{Eq\onedot~\eqref{#1}}
\newcommand{\secref}[1]{Sec\onedot~\ref{#1}}
\newcommand{\tabref}[1]{Tab\onedot~\ref{#1}}
\newcommand{\thmref}[1]{Theorem~\ref{#1}}
\newcommand{\prgref}[1]{Program~\ref{#1}}
\newcommand{\algref}[1]{Alg\onedot~\ref{#1}}
\newcommand{\clmref}[1]{Claim~\ref{#1}}
\newcommand{\lemref}[1]{Lemma~\ref{#1}}
\newcommand{\ptyref}[1]{Property\onedot~\ref{#1}}

\def\eg{\emph{e.g}\onedot} \def\Eg{\emph{E.g}\onedot}
\def\ie{\emph{i.e}\onedot} \def\Ie{\emph{I.e}\onedot}
\def\cf{\emph{cf}\onedot} \def\Cf{\emph{Cf}\onedot}
\def\etc{\emph{etc}\onedot} \def\vs{\emph{vs}\onedot}
\def\wrt{w.r.t\onedot} \def\dof{d.o.f\onedot}
\def\etal{\emph{et al}\onedot}


\newcommand\norm[1]{\left\lVert#1\right\rVert}\newcommand{\defi}[1]{\noindent\textbf{Definition #1.}}
\newcommand{\prop}[1]{\noindent\textbf{Proposition #1.}}

\DeclareMathOperator{\infl}{Inf}
\DeclareMathOperator{\ent}{Ent}
\DeclareMathOperator{\var}{Var}

\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}


\renewcommand{}
\renewcommand{}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\X}{\cal X}
\newcommand{\Y}{\cal Y}
\newcommand{\N}{{\cal N}}

\newcommand{\as}[1]{{\color{blue}\small{Alex: #1}}}

\newcommand\blfootnote[1]{\begingroup
  \renewcommand\thefootnote{}\footnote{#1}\addtocounter{footnote}{-1}\endgroup
}


\title{Removing Bias in Multi-modal Classifiers: Regularization by Maximizing Functional Entropies}



\author{
    Itai Gat\\
    Technion\\
       
    \And
    Idan Schwartz\\
    Technion\\
    
    \And
    Alexander Schwing\\
    UIUC\\
    
    \And
    Tamir Hazan\\
    Technion\\
}


\begin{document}

\maketitle

\begin{abstract}
Many recent datasets contain a variety of different data modalities, for instance, image, question, and answer data in visual question answering (VQA). 
When training deep net classifiers on those multi-modal datasets, the modalities get exploited at different scales, i.e., some modalities can more easily contribute to the classification results than others.
This is suboptimal because the classifier is inherently biased towards a subset of the modalities. To alleviate this shortcoming, we propose a novel regularization term based on the functional entropy. Intuitively, this term encourages to balance the contribution of each modality to the classification result. 
However, regularization with the functional entropy is challenging. To address this, we develop a method based on the log-Sobolev inequality, which bounds the functional entropy with the functional-Fisher-information. Intuitively, this maximizes the amount of information that the modalities contribute. 
On the two challenging multi-modal datasets VQA-CPv2 and SocialIQ, we obtain state-of-the-art results while more uniformly exploiting the modalities. In addition, we demonstrate the efficacy of our method on Colored MNIST.

\end{abstract} \section{Introduction}
Multi-modal data is ubiquitous and commonly used in many real-world applications. For instance, discriminative visual question answering systems take into account the question, the image and a variety of answers. In general, we treat data as multi-modal  if it can be partitioned into  semantic features, \eg, color and shape can be treated as multi-modal data.

Training of discriminative classifiers on multi-modal datasets like discriminative visual question answering almost always follows the classical machine learning paradigm: use a common loss function like cross-entropy and employ a standard -norm regularizer (a.k.a.\ weight decay). 
The regularizer favors `simple' classifiers over more complex ones. These classical regularizers  are suitable in traditional machine learning settings that predominantly use a single data modality. Unfortunately, because they favor  `simple' models, their use is detrimental when learning from multi-modal data. Simplicity encourages use of  information from a single modality, which often ends up  biasing the learner. 
For instance, visual question answering models end up being driven by a language prior rather than visual  understanding~\cite{vqa-cp, clever, vqa2, agrawal}. \Eg,  answering `how many...?' questions with `2' regardless of the question. Another popular example consists of colored images whose label is correlated with their color modality and their shape modality. In these cases, standard learners often focus on the `simple' color modality and largely ignore the shape modality \cite{li2019repair, learningNotToLearn}.  

To address this issue, we develop a novel regularization term based on the functional entropy. Intuitively, this term encourages to balance the contribution of each modality to classification. To address the computational challenges of computing the functional entropy we develop a method based on the log-Sobolev inequality which bounds the functional entropy with the functional Fisher information.

We illustrate the efficacy of the proposed approach on the three challenging multi-modal datasets Colored MNIST, VQA-CPv2, and SocialIQ. We find that our regularization maximizes the utilization of essential information. We verify this empirically on the synthetic dataset Colored MNIST. We also evaluate on popular benchmarks, finding that our method permits a state-of-the-art performance on two datasets: SocialIQ (68.53\% \vs 64.82\%) and  VQA-CPv2 (54.55\% \vs 52.05\%). 

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{figures/teas.pdf}
	\caption{We illustrate our approach. In the visual question answering task, we are given a question about an image. Thus, we can partition our input into two modalities: a textual modality, and a visual modality. We measure the modalities' functional Fisher information by evaluating the sensitivity of the prediction by perturbing each modality. We maximize the functional Fisher information by incorporating it into our loss as a regularization term. Our results show that our regularization permits higher utilization of the visual modality.}
	\label{fig:teas}
\end{figure} \section{Related Work}
\textbf{Multi-modal datasets.} 
Over the years, the amount and variety of data that has been used across tasks has grown significantly. 
Unsurprisingly, present-day tasks are increasingly sophisticated and combine multiple data modalities like vision, text, and audio.
In particular, in the past few years, many large-scale multi-modal datasets have been proposed~\cite{clever, vqa2, zadeh2019social, vcr, gqa, visdial}.
Subsequently, multiple works developed strong models to address these datasets~\cite{schwartz2017high, ban, fga, vilbert, bottomup, lxmert, coattention, mcb, mac,AnejaICCV2019,JainZhangCVPR2017,JainCVPR2018,ChatterjeeECCV2018,NarasimhanNeurIPS2018,NarasimhanECCV2018,LinNeurIPS2019}. 
However, recent work also suggests that many of these advanced models predict by leveraging one of the modalities more than the others, \eg, utilizing question type to determine the answer in VQA problems~\cite{vqa-cp, sceneaware, snliBias, clozeBias}. This property is undesirable since 
multi-modal tasks consider all data essential to solve the challenge without overfitting to the dataset. 

\textbf{Bias in datasets.} 
Recently, datasets were proposed to study whether a model can generalize and solve the task or whether it uses a single modalities' features. 
Usually, this evaluation is performed by partitioning data into train and test sets using different distributions. 
For example, VQA-CP~\cite{vqa-cp} is a reshuffle of the VQA~\cite{vqa2} dataset ensuring that question-type distributions differ between train and test splits.  
Another well-known dataset is Colored MNIST~\cite{li2019repair, learningNotToLearn, irm}. In this dataset, each digit class is colored differently in the train set, while samples in the test set remain gray-scale. 
Different approaches were proposed to deal with such problems: Arjovsky~\etal\cite{irm} propose to improve generalization by ensuring that the optimal classifier equals all training distributions. 
Wang~\etal\cite{wang} suggest to regularize the overfitting behavior to different modalities.
Methods like REPAIR~\cite{li2019repair} prevent a model from exploiting dataset biases by re-sampling the training data. 
Kim~\etal\cite{learningNotToLearn} use an adversarial approach to learn unbiased feature representations.
Clark~\etal\cite{vqacp_ensemble} and Cadene~\etal\cite{rubi} suggest methods to overcome language priors using a bias-only model in VQA tasks.

\textbf{Entropy and information in deep nets.} 
Entropy plays a pivotal role in machine learning and has been extensively used in losses and for regularization \cite{graph_intro}. However, its use is confined to probability distributions while we use functional entropy, which has a different form and is defined for any non-negative function. More broadly, other components of information theory have been studied in deep nets,
for example, the information bottleneck criteria~\cite{information_bottleneck, information2}. Other works use information theory to overcome generalization~\cite{learningNotToLearn, krishna2019information, ramakrishnan2018overcoming}. For instance, Krishna~\etal\cite{krishna2019information} propose to maximize the mutual information of the modalities 
by regularizing differences between modality representations. Fisher information is also  used in various machine learning and deep learning settings, \eg, monitoring of the learning process \cite{fisher_matrix}. In contrast, our work considers the \emph{functional} Fisher information of a non-negative function that represents a multi-modal learner, while Fisher information is defined over probability density functions. Also, we use the log-Sobolev inequality between the functional entropy and the functional Fisher information, which does not hold for entropy and Fisher information.   \section{Background}

Discriminative learning constructs mapping between data-instance  and labels  given  training data . We are particularly interested in multi-modal data, where each data-instance  is composed of multiple modalities. For example, a monochrome image  is composed of two data modalities  where  is the monochromatic color tone and  is the  intensity map of the image capturing the shape. Similarly, in discriminative visual question answering,  is composed of a visual modality, a question modality and an answer modality, \ie,  with ,  and  respectively. Generally,  may have  modalities, \ie, , each residing in  Euclidean space, \ie, . 

Discriminative learning searches for the parameters  of a  function which assign a score to each label  given data . In this work we focus on the softmax function .
Its goodness of fit is measured by a loss function, often the cross-entropy loss , where  refers to the indicator function. More generally, the cross-entropy loss between two distributions  is 

Beyond the loss, a typical learning process employs a regularization term which encourages use of the `simplest' function. 
Various regularization terms that favor `simple' functions pose a considerable difficulty for multi-modal problems: deep learners easily find simple functions that ignore  one of the modalities. For example, a simple discriminator for Colored MNIST, which consists of monochromatic images whose colors correlate with their labels, focuses almost exclusively on the color vector to predict the label rather than also assessing the shape of the image. Formally, if the monochromatic images are represented by their color and shape modalities  then the simplest discriminator will only consider the -dimensional color . In this setting, the learned function   avoids all important information within the shape modality . 

In the following we describe the notion of functional entropy in Section~\ref{sec:ent}. In Section~\ref{sec:lsi} we present the log-Sobolev inequality, which bounds the functional entropy of a non-negative function by the functional Fisher information. 
We conclude with the notion of tensorization, which decomposes these components according to their multi-modal spaces. 

\subsection{Functional entropy}
\label{sec:ent}
In this work we consider the functional entropy that is encapsulated in multi-modal problems. Functional entropies are defined over a continuous random variable, \ie, a function  over the Euclidean space  with a probability measure . Here and throughout we use  to refer to a stochastic variable, which we integrate over. The functional entropy of a non-negative function  is 

The functional entropy is non-negative, namely  and equals  zero only if  is a constant. This is in contrast to differential entropy of a continuous random variable with probability density function : , which is defined for  with  and may be negative.
 

\subsection{Functional Fisher information} 
\label{sec:lsi}

Unfortunately, the functional entropy is hard to estimate empirically, since it involves the term . Since the integral can only be estimated by sampling, the logarithm of its estimate is hard to compute in practice. Instead of estimating the functional entropy directly, we use the log-Sobolev inequality for Gaussian measures (cf.~\cite{Bakry14}, Section 5.1.1). This permits to bound the functional entropy with the functional Fisher information. Specifically, for any non-negative function  we obtain   

Hereby,  is the  norm of the gradient of . The functional Fisher information is non-negative, since it is defined for non-negative functions. It is a natural extension of the Fisher information, which is defined for probability density functions. 
  
\subsection{Tensorization and multi-modal data}
\label{sec:tensor}

Functional entropy naturally fits into multi-modal settings that correspond to product probability spaces. For example, when considering discriminative visual-question answering, a data point  resides in the Euclidean product space of the visual modality , the question modality  and the answer modality . This product space property is called tensorization and informally relates the functional entropy of each modality to the overall functional entropy of the system. Generally, consider the product space , where each modality resides in the -dimensional Euclidean space . Consider the product measure  and let 

The tensorization of the functional entropy amounts to 

Here the dimension  is the dimension of , namely  and . Tensorization is well-suited for multi-modal settings, as it provides the means to bound the overall functional entropy of the system using the functional entropies of its modalities.  \section{Regularization by Maximizing Functional Entropies}\label{sec:regularization}
Functional entropy requires a probability measure. In the following we differentiate between multi-modal training points  and general multi-modal points in the probability measure space, which we denote by . We use the training points  to determine the measure and we denote by  the variable of the integrands. In our work we consider a Gaussian product. Given a training point  that resides in the multi-modal space  we define the measure  for the -th modality to be the Gaussian distribution with mean  and variance , where  is the -th modality of the training point  and  is the variance of the coordinate of :

The measure  is the product measure over the different modalities . For example, given a monochromatic image  in the training data, the distribution employed by the functional entropy in Eq.~\eqref{eq:ent} is .  

For each training data point , we define the functional entropy over the deep net softmax function  as

This function measures the sensitivity of the softmax prediction to Gaussian perturbations  of the input, since the random perturbation  is sampled from a Gaussian with an expected value , as described in Eq.~\eqref{eq:Ni}. 

The cross-entropy function is a non-negative function, therefore, it is natural to apply the log-Sobolev inequality for Gaussian measures to bound the functional entropy using the functional Fisher information, in Eq.~\eqref{eq:lsi}:

 
We use the functional Fisher information bound in Eq.~\eqref{eq:lsi} to regularize the training process, in order to implicitly encourage to maximize the information of each modality, while minimizing the training loss. In order to account  for both the loss minimization and the information maximization, we take the inverse information. Given multi-modal training data , our learning objective is 

The hyperparameter  balances between the training loss and the inverse information.

\subsection{Tensorization}\label{sec:regularization_tensorization}
The tensorization argument in Section~\ref{sec:tensor} determines a bound on the functional entropy by its functional entropy over each modality. The tensorization argument is favorable since it permits to consider the functional entropy of each modality separately in the integral of Eq.~\eqref{eq:tensor_ent}, given a point . The tensorization also permits to efficiently approximate  the functional entropy, given a training point : Let  and set . Given this definition, the tensorization in Eq.~\eqref{eq:tensor_ent} reduces to  

We combine this approximation with the log-Sobolev inequality to measure the amount of the functional Fisher information added by each modality, for a given multi-modal training point : 

We recall that  and  is the variable that is being integrated while all other modalities remain fixed to the training point input modality.

Similarly to Eq.~\eqref{eq:learning1}, we may use the tensorized functional Fisher information bound in Eq.~\eqref{eq:ent_reg} to regularize the training process. Given multi-modal training data , our tensorized learning objective is
 \section{Connection Between Functional Entropy and Variance}
Rothaus~\cite{rothaus1985analytic} has shown a connection between the functional entropy of a non-negative function and its variance.

Particularly, when the values of the non-negative function  are small, one can expand the Taylor series of  to show that 

where the residual function  is non-negative and approaches  zero faster than  approaches zero, \ie, .
Interestingly, a similar bound to the log-Sobolev inequality (Eq.~\eqref{eq:lsi}) exists for the variance of continuous random variables , which is widely known as the Poincar\'e inequality: 

The relation between the functional entropy and the variance, expressed in  Eq.~\eqref{eq:ent_var}, suggests that these bounds should behave similarly in practice. To fit the variance into multi-modal settings we need to show tensorization (as in Sec.~\ref{sec:tensor}). In the variance case, this property is called the Efron-Stein theorem (cf.~\cite{ledoux2001concentration}, Proposition 2.2),

Next, we present a similar regularization term to the one described in Sec.~\ref{sec:regularization}. This time we use variance and Poincar\'e inequality.

\subsection{Regularization using Variance}
In Sec.~\ref{sec:regularization}, we were interested in bounding the functional entropy (Eq.~\eqref{eq:bound_fisher_information}), for each training point , of . Similarly, we want to bound the variance of . For this purpose, we can use the Poincar\'e inequality, described in Eq.~\eqref{eq:p},

We use the above inequality to regularize the training process. To consider both the loss minimization and the regularization term we formulate the learning objective,

To fit our multi-modal settings, we need to follow the tensorization process as illustrated in Sec.~\ref{sec:regularization_tensorization}. The same tensorization process can be applied to the variance using the Poincar\'e bound given in Eq.~\eqref{eq:p}.
For tensorized Poincar\'e bound leads to the learning objective 
 \section{Experiments}

\begin{table}[t]
\small
\centering
\caption{Comparison between our proposed regularization terms on the Colored MNIST (multi-modal settings, gray-scale test set), SocialIQ~\cite{zadeh2019social} and Dogs \& Cats~\cite{learningNotToLearn} datasets. We report maximum accuracy observed and accuracy after convergence of the model (Convg). We compare the 4 regularizers specified by the equation numbers. We underline the highest maximum accuracy and bold the highest results after convergence. Using functional Fisher information regularization (Eq.~\eqref{eq:regularization}) leads to a smaller difference between the maximum accuracy and accuracy after convergence. * refers to results we achieve without using our proposed regularization. ** denotes training with weight-decay ( regularization).}
    \begin{subtable}{.45\linewidth}
    \centering
    	\begin{tabular}{l cc}
    	    \multirow{2}{*}{Model} & \multicolumn{2}{c}{Colored MNIST} \\
            \cmidrule(lr){2-3} 	 
            &Convg.&Max\\
            \midrule
            Baseline*&41.112.13&98.31\\
            Baseline**&47.321.12&98.23\\
            \hline
            Eq.~\eqref{eq:ent}&93.680.75&94.44\\
            Eq.~\eqref{eq:var}&94.871.03&96.37\\
            Eq.~\eqref{eq:regularization}&\textbf{96.17}0.63&98.38\\
            Eq.~\eqref{eq:p_regularization}&\textbf{96.24}0.74&\underline{98.52}\\
    	\end{tabular}
    	\caption{Comparison on Colored MNIST.}
    \end{subtable}
    \begin{subtable}{.45\linewidth}
    \centering
        	\begin{tabular}{l cc}
        	    \multirow{2}{*}{Model} & \multicolumn{2}{c}{SocialIQ}\\
                \cmidrule(lr){2-3}
                &Convg.&Max\\
                \midrule
                Baseline*&63.910.26&66.16\\
                Baseline**&65.280.23&66.95\\
                \hline
                Eq.~\eqref{eq:ent}&63.870.34&64.22\\
                Eq.~\eqref{eq:var}&64.360.31&64.93\\
                Eq.~\eqref{eq:regularization}&\textbf{67.93}0.18&\underline{68.53}\\
                Eq.~\eqref{eq:p_regularization}&67.410.21&68.19\\
        	\end{tabular}
        	\caption{Comparison on SocialIQ.}
    \end{subtable}
    \begin{subtable}{1\linewidth}
    \centering
    	\begin{tabular}{l cc cc}
    	    \multirow{2}{*}{Model} & \multicolumn{2}{c}{Dogs \& Cats (TB1)}&\multicolumn{2}{c}{Dogs \& Cats (TB2)} \\
    	    \cmidrule(lr){2-3}
    	    \cmidrule(lr){4-5}
    	    &Convg.&Max&Convg.&Max \\
            \midrule
            Baseline*&79.220.45&80.12&65.511.54&67.38\\
            Baseline**&81.240.23&84.31&68.470.29&71.36\\
            \hline
            Eq.~\eqref{eq:ent}&92.920.46&93.48&85.320.41&85.79\\
            Eq.~\eqref{eq:var}&93.380.27&94.15&85.140.29&85.41\\
            Eq.~\eqref{eq:regularization}&\textbf{94.71}0.37&\underline{95.99}&\textbf{88.11}0.17&\underline{88.48}\\
            Eq.~\eqref{eq:p_regularization}
            &\textbf{94.43}0.24&95.35&87.810.31&88.12\\
    	\end{tabular}
    	\caption{Comparison on Dogs \& Cats.}
    \end{subtable}
	\label{tab:results}
\end{table}

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/inf_gain.pdf}
\caption{Proportions of the Fisher information values during training for SocialIQ, Colored MNIST, VQA-CPv2 and Dogs\&Cats. Using our proposed regularization brings the modalities Fisher information value closer than training without our regularization, a desired property in multi-modal learning. In ColoredMNIST, we observe that training a model with our regularization, the prediction is based on both the shape and the color. Unlike, a model trained without our regularization which makes predictions based on the color only.}
\label{fig:socialiq_information}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth,keepaspectratio]{figures/fig3.pdf}
\caption{Training process with and without regularization. 
We note that generalization significantly improves when using our proposed regularization.}
\centering
\label{fig:plots}
\end{figure}

\begin{table}[t]
    \small
	\centering
	\caption{Comparison between the state-of-the-art on the VQA-CPv2 test set. The best results for each category are in bold. * denotes models that make use of external data.}
	\begin{tabular}{l c cccc}
    \multirow{2}{*}{Model} & \multirow{2}{*}{Overall} & \multicolumn{3}{c}{Answer type} \\
    \cmidrule(r){3-5} &  & Yes/No & Number & Other \\
    \midrule
	    BUTD~\cite{bottomup}&39.34&42.13&12.29&45.29\\
		AdvReg~\cite{ramakrishnan2018overcoming}&41.17&65.49&15.48&35.48\\
		HINT~\cite{hint}*&46.73&67.27&10.61&45.88\\
		RUBi~\cite{rubi}&47.11&68.65&20.28&43.18\\
		SCR~\cite{scr}*&49.45&72.36&10.93&\textbf{48.02}\\
		LMH~\cite{vqacp_ensemble}&52.05&72.58&31.12&46.97\\
        \bottomrule
        LMH +Ours Eq.~\eqref{eq:p_regularization}&54.01  0.27&73.02  1.21&43.15  1.01&47.02  0.28\\
		LMH +Ours Eq.~\eqref{eq:regularization}&\textbf{54.55}  0.29&\textbf{74.03}  1.13&\textbf{49.16}  1.22&45.82  0.37\\
	\end{tabular}
	\label{tab:vqacp}
\end{table}

In the following, we evaluate our proposed regularization on four different datasets. One of the datasets is a synthetic dataset (Colored MNIST), which permits to study whether a classifier leverages the wrong features.  
We show that adding the discussed regularization improves the generalization of a given classifier.
We briefly describe each dataset and  discuss the results of the proposed method. 

\subsection{Colored MNIST}
\textbf{Dataset:} Colored MNIST~\cite{li2019repair, learningNotToLearn} is a synthetic dataset based on MNIST~\cite{mnist}.
The train and validation set consist of 60,000 and 10,000 samples, respectively.
Each sample is biased with a color that correlates with its digit. 
The biasing process  assigns to each digit an RGB vector which represents a mean color. 
Then, each sample receives its color, sampled from a normal distribution with a fixed variance around the digit's mean color. 
This process results in a monochromatic image and high correlation between the digit's color and its label.
To introduce a bias in a multi-modal approach, we split each sample  into a color modality  and a shape (gray-scale representation of the image) modality .
For humans it is evident that a digit should be classified based on its shape and not its color. 
For a learner this fact is not as clear. 
To minimize the loss, it is much easier for a classifier to leverage the color modality, which correlates very well with the label. 
In its nature, Colored MNIST evaluates the generalization of a model since it has a test set that assesses whether a classifier relies solely on color or both the color and the shape.

\textbf{Baseline:} A simple deep net achieves high accuracy on both colored train and colored validation set.
However, on the gray-scale validation set, the network fails drastically, achieving only a 41.11\% accuracy when using the model from the last training epoch. 
We note that the more we train the more the baseline  relies on color rather than shape.
We also compute an upper-bound by training the deep net on a gray-scale version. The upper-bound accuracy on the gray-scale validation set is 98.47\%. 

\textbf{Results:} Adding our proposed regularization encourages to exploit information from both shape and color modalities. 
We provide results in \tabref{tab:results}. \figref{fig:socialiq_information} shows that without entropy regularization, the Fisher information value of the shape is almost zero while adding the regularization results in a higher shape information value than the color. 
This fact complements the classifier's performance on the gray-scale validation set shown in~\figref{fig:plots}. Using functional Fisher information based regularization outperforms the same classifier trained without regularization by almost 55\%. 

\subsection{VQA-CPv2}
\textbf{Dataset:} VQA-CPv2~\cite{vqa-cp} is a re-shuffle of the VQAv2~\cite{VQA} dataset.
Visual question answering (VQA) requires to answer a given question-image pair.
\cite{vqa-cp} observed that the original split of the VQAv2 dataset permits to leverage language priors. 
To challenge models  to not use these priors, the question type distributions of the train and validation set were changed to differ from one another. 
VQA-CPv2 consist of 438,183 samples in the train set and 219,928 samples in the test set. 

\textbf{Results:} We evaluated our method by adding functional Fisher information regularization to the current state-of-the-art~\cite{vqacp_ensemble}. 
In doing so, the result improves  by 2.5\%, achieving 54.55\% accuracy.
We provide a comparison with recent state-of-the-art methods in \tabref{tab:vqacp}.

The authors of \cite{negative-case-vqa, grand-belinkov-2019-adversarial} raise the concern that new regularization methods mainly boost the performance of yes/no questions.
Investigating the improvements due to our result  shows that this is not the case. 
The accuracy difference to the previous state-of-the-art on the different answer types is: yes/no +1.5\%, number +18\%, and other -1\%. 

\subsection{SocialIQ}\label{exp:socialiq}
\textbf{Dataset:} The SocialIQ dataset is designed to develop models for understanding of social situations in videos. Each sample consists of a video clip, a question, and an answer. 
The task is to predict whether the answer is correct or not given this tuple. 
The dataset is split into 37,191 training samples, and 5,320 validation set samples. 
Note that an inherent bias exists in this dataset: specifically the sentiment of the answer provides a good cue. 

\textbf{Baseline:} A simple classifier based on only the answer modality performs significantly better than chance level accuracy (using our settings \textasciitilde6\% more).
Such biases in the train set  lead to a classic case of overfitting.

\textbf{Results:} As seen in \figref{fig:plots}, training without functional Fisher information regularization leads to \textasciitilde80\% accuracy on the train set and \textasciitilde64\% accuracy on the validation set. 
Although, functional Fisher information regularization results in 70\% accuracy on the train set, it improves  validation set accuracy to 67.93\% accuracy. 

We further investigate the information values during the training phase with and without functional Fisher information regularization. 
In \figref{fig:socialiq_information} we observe that without our regularization, the answer modality has the highest information value while the question modality is almost entirely  ignored.
Adding the proposed regularization balances the information between modalities, the desired behavior in multi-modal learning.

\subsection{Dogs and Cats}
\textbf{Dataset:} Following the  settings of Kim~\etal\cite{learningNotToLearn}, we evaluate our models on the biased ``Dogs and Cats'' dataset. 
This dataset comes in two splits: The TB1 set consists of bright dogs and dark cats and contains 10,047 samples. The TB2 set consist of dark dogs and bright cats and contains 6,738 samples. We use the image as a single-modality.

\textbf{Baseline:} The authors show that  training of  ResNet-18~\cite{resnet} on TB1  and testing on TB2 results in a poor performance of 74.98\%.
The authors also show that using TB2 as the train set and TB1 as the test set results in even worse accuracy of 66.45\%.

Functional Fisher information regularization training on TB1 and testing on TB2  with  (see Eq.~\eqref{eq:regularization}) set to equal 3e-10 results in 94.71\% accuracy, exceeding~\cite{learningNotToLearn} by 3.5\%. 
Training on TB2  while testing on TB1 achieves an accuracy of 88.11\%, 1\% higher than \cite{learningNotToLearn}. \section{Conclusion}
Classical regularizers applied on multi-modal datasets lead to models which may ignore one or more of the modalities. This is sub-optimal as we expect all modalities to contribute to classification. To alleviate this concern we study regularization via the functional entropy. It encourages the model to more uniformly exploit the available modalities. 

\noindent\textbf{Acknowledgements:} This work is supported in part by NSF under Grant  1718221,  2008387, NIFA award 2020-67021-32799 and, BSF under Grant 2019783. \section*{Broader Impact}

We study functional entropy based regularizers which enable classifiers to more uniformly benefit from available dataset modalities in multi-modal tasks. We think the proposed method will help to reduce biases that present-day classifiers exploit when being trained on data which contains modalities, some of which are easier to leverage than others.

We think this research will have positive societal implications. 
With machine learning being used more widely, bias from various modalities has become ubiquitous.  Minority groups  are disadvantaged by present-day AI algorithms, which work very well for the average person but are not suitable for other groups. We provide two examples next:
\begin{enumerate}
    \item It is widely believed that criminal risk scores are biased against minorities\footnote{\url{https://www.propublica.org/article/bias-in-criminal-risk-scores-is-mathematically-inevitable-researchers-say}}, and mathematical methods that reduce the bias in machine learning are desperately needed. In our work we show how our regularization allows to reduce the color modality effect in colored MNIST, which hopefully facilitates to reduce bias in deep nets.
    \item Consider virtual assistants as another example: if  pronunciation is not mainstream, replies of AI systems are less helpful. Consequently, current AI ignores parts of society.
\end{enumerate}

To conclude, we think the proposed research is a first step towards machine learning becoming more inclusive. 
\bibliographystyle{unsrt}
\bibliography{references.bib}

\end{document}