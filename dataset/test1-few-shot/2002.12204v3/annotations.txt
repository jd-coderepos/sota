[{'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-dev', 'Metric': 'Accuracy', 'Score': '71.21'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-std', 'Metric': 'overall', 'Score': '71.49'}}, {'LEADERBOARD': {'Task': 'Image Captioning', 'Dataset': 'COCO Captions', 'Metric': 'BLEU-4', 'Score': '39.5'}}, {'LEADERBOARD': {'Task': 'Image Captioning', 'Dataset': 'COCO Captions', 'Metric': 'METEOR', 'Score': '29.3'}}, {'LEADERBOARD': {'Task': 'Image Captioning', 'Dataset': 'COCO Captions', 'Metric': 'ROUGE-L', 'Score': '59.3'}}]
