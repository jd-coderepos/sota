
\documentclass[11pt]{article}

\usepackage{fullpage}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\newcommand{\subf}[1]{{\small\begin{tabular}[t]{@{}c@{}}
  #1
  \end{tabular}}}
\newcommand{\url}[1]{{\tt #1}}

\usepackage[ruled,vlined,linesnumbered]{algorithm2e}

\renewcommand{\log}{\lg}

\newcommand{\0}{\mathit{0}}
\newcommand{\1}{\mathit{1}}

\newcommand{\access}{\mathit{access}}
\newcommand{\rank}{\mathit{rank}}
\newcommand{\rankopen}{\mathit{rankopen}}
\newcommand{\rankclose}{\mathit{rankclose}}
\newcommand{\select}{\mathit{select}}
\newcommand{\selectopen}{\mathit{selectopen}}
\newcommand{\selectclose}{\mathit{selectclose}}

\newcommand{\pred}{\mathit{pred}}
\newcommand{\suc}{\mathit{succ}}

\newcommand{\excess}{\mathit{excess}}
\newcommand{\raiz}{\mathit{root}}
\newcommand{\fchild}{\mathit{fchild}}
\newcommand{\lchild}{\mathit{lchild}}
\newcommand{\nsibling}{\mathit{nsibling}}
\newcommand{\psibling}{\mathit{psibling}}
\newcommand{\parent}{\mathit{parent}}
\newcommand{\isleaf}{\mathit{isleaf}}
\newcommand{\nodemap}{\mathit{nodemap}}
\newcommand{\nodeselect}{\mathit{nodeselect}}
\newcommand{\degree}{\mathit{degree}}

\newcommand{\depth}{\mathit{depth}}
\newcommand{\height}{\mathit{height}}
\newcommand{\deepestnode}{\mathit{deepestnode}}
\newcommand{\subtree}{\mathit{subtree}}
\newcommand{\isancestor}{\mathit{isancestor}}
\newcommand{\levelanc}{\mathit{levelancestor}}
\newcommand{\preorder}{\mathit{preorder}}
\newcommand{\postorder}{\mathit{postorder}}
\newcommand{\inorder}{\mathit{inorder}}
\newcommand{\preorderselect}{\mathit{preorderselect}}
\newcommand{\postorderselect}{\mathit{postorderselect}}
\newcommand{\inorderselect}{\mathit{inorderselect}}

\newcommand{\children}{\mathit{children}}
\newcommand{\child}{\mathit{child}}
\newcommand{\childrank}{\mathit{childrank}}

\newcommand{\lca}{\mathit{lca}}

\newcommand{\numleaves}{\mathit{numleaves}}
\newcommand{\leafrank}{\mathit{leafrank}}
\newcommand{\leafselect}{\mathit{leafselect}}
\newcommand{\leftmostleaf}{\mathit{leftmostleaf}}
\newcommand{\rightmostleaf}{\mathit{rightmostleaf}}

\newcommand{\levelnext}{\mathit{levelnext}}
\newcommand{\levelprev}{\mathit{levelprev}}
\newcommand{\levelleftmost}{\mathit{levelleftmost}}
\newcommand{\levelrightmost}{\mathit{levelrightmost}}

\newcommand{\labeledchild}{\mathit{labeledchild}}
\newcommand{\childrenlabeled}{\mathit{childrenlabeled}}
\newcommand{\childlabel}{\mathit{childlabel}}

\newcommand{\leftchild}{\mathit{leftchild}}
\newcommand{\rightchild}{\mathit{rightchild}}

\newcommand{\fwdsearch}{\mathit{fwdsearch}}
\newcommand{\bwdsearch}{\mathit{bwdsearch}}
\newcommand{\close}{\mathit{close}}
\newcommand{\open}{\mathit{open}}
\newcommand{\enclose}{\mathit{enclose}}
\newcommand{\rmq}{\mathit{rmq}}
\newcommand{\rMq}{\mathit{rMq}}
\newcommand{\mincount}{\mathit{mincount}}
\newcommand{\minselect}{\mathit{minselect}}

\newcommand{\Oh}[1]{\mathcal{O}\!\left(#1\right)}
\newcommand{\polylog}{\mathop{\mathrm{polylog}}}
\newcommand{\poly}{\mathop{\mathrm{poly}}}

\newcommand{\R}{\mathcal{R}}
\newcommand{\V}{\mathcal{V}}
\newcommand{\U}{\mathcal{U}}
\newcommand{\T}{\mathcal{T}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\C}{\mathcal{C}}
\newcommand{\Q}{\mathcal{Q}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\K}{\mathcal{K}}
\newcommand{\Suj}{\mathcal{S}}
\newcommand{\Obj}{\mathcal{O}}
\newcommand{\Lab}{\mathcal{L}}
\newcommand{\Pred}{\mathcal{P}}

\newtheorem{example}{Example}

\DontPrintSemicolon
\SetKwInOut{Input}{\footnotesize Input}
\SetKwInOut{Output}{\footnotesize Output}
\SetKw{KwAnd}{and}
\SetKw{KwOr}{or}
\SetKw{KwNot}{not}
\SetKw{KwTrue}{true}
\SetKw{KwFalse}{false}
\newcommand{\IO}[2]{\Input{\footnotesize #1} \Output{\footnotesize #2}\BlankLine\BlankLine }
\newcommand{\I}[1]{\Input{\footnotesize #1} \BlankLine\BlankLine }
\newcommand{\IOp}[2]{\Input{\footnotesize #1} \Output{\footnotesize #2}\BlankLine }
\newcommand{\NULL}{\mathrm{null}}
\SetKwProg{Fn}{Proc}{}{}

\begin{document}

\title{Simple and Efficient Fully-Functional Succinct Trees}

\author{Joshimar Cordova and Gonzalo Navarro \\
Department of Computer Science, University of Chile \\
{\tt \{jcordova|gnavarro\}@dcc.uchile.cl}}

\maketitle 

\begin{abstract}
The fully-functional succinct tree representation of Navarro and Sadakane
({\em ACM Transactions on Algorithms}, 2014) supports a large number of
operations in constant time using  bits. 
However, the full idea is hard to implement. Only a simplified version with
 operation time has been implemented and shown to be practical 
and competitive. We describe a new variant of the original idea that is much 
simpler to implement and has worst-case time  for the 
operations. An implementation based on this version is experimentally shown to
be superior to existing implementations.
\end{abstract}

\section{Introduction}

Combinatorial arguments show that it is possible to represent any ordinal
tree of  nodes using less than  bits of space: the number of such trees
is the th Catalan number, , and its
logarithm (in base 2 and written  across this paper) is . A simple way to
encode any ordinal tree in  bits is the so-called {\em balanced
parentheses (BP)} representation: traverse the tree in depth-first order,
writing an opening parenthesis upon reaching a node, and a closing one upon
definitely leaving it. Much more challenging is, however, to efficiently
navigate the tree using that representation.

The interest in navigating a -bit representation of a tree, compared to
using a classical -pointers representation, is that those succinct
data structures allow fitting much larger datasets in the faster and
smaller levels of the memory hierarchy, thereby improving the overall system
performance. Note that compression is not sufficient; it must be possible to
operate the data in its compressed form. The succinct representation of 
ordinal trees is one of the most clear success stories in this field. 
Table~\ref{tab:ops} lists the operations that can be supported in constant 
time within  bits of space. These form a rich set that suffices for
most applications.

\begin{table}[t!]
\caption{Operations on ordinal trees, where  and  are node identifiers.}
\label{tab:ops}
\footnotesize
\begin{center}
  \begin{tabular}{lll|l}
  operation & description \\ \hline
 & the tree root \\
   /  & preorder/postorder rank of node  \\
   /  & the node with preorder/postorder  \\
   & whether the node is a leaf \\
   & whether  is an ancestor of  \\
   & depth of node  \\
   & parent of node  \\
   /  & first/last child of node  \\
   /  & next/previous sibling of node  \\
   & number of nodes in the subtree of node  \\
   & ancestor  of  such that  \\
   /  & next/previous node of  with the same depth \\
   /  & leftmost/rightmost node with depth  \\
   & the lowest common ancestor of two nodes  \\
   & the (first) deepest node in the subtree of  \\
   & the height of  (distance to its deepest node) \\
   &  number of children of node  \\
   & -th child of node  \\
   &  number of siblings to the left of node  \\
 & number of leaves to the left and up to node  \\
   & th leaf of the tree \\
   & number of leaves in the subtree of node  \\
   /  & leftmost/rightmost leaf of node  \\
  \hline
  \end{tabular}
\end{center}
\end{table}

The story starts with Jacobson \cite{Jac89}, 
who proposed a simple levelwise representation called LOUDS, which reduced 
tree navigation to two simple primitives on bitvectors:  and 
 (all these primitives will be defined later). 
However, the repertoire of tree operations was limited. Munro and Raman 
\cite{MR01} used for the first time the BP representation, and showed how 
three basic primitives on the parentheses: , , and , 
plus  and , were sufficient to support a significantly wider 
set of operations. The operations were supported in constant time, however
the solution was quite complex in practice. Geary et al.~\cite{GRRR06} retained 
constant times with a much simpler solution to , , and 
, based on a two-level recursion scheme. Still, not all the
operations of Table~\ref{tab:ops} were supported. Missing ones were
added one by one:  \cite{CLL05},  \cite{MRRR12}, 
, , , and  \cite{LY08}. Each such addition
involved extra -bit substructures that were also hard to 
implement.

An alternative to BP, called DFUDS, was introduced by Benoit et 
al.~\cite{BDMRRR05}. It also used  balanced parentheses, but they had a
different interpretation. Its main merit was to support  and related 
operations very easily and in constant time. It did not support, however, 
operations , , , and , which were added 
later \cite{GRR06,JSS12}, again each using  bits and requiring a complex
implementation to achieve constant time.

Navarro and Sadakane \cite{NS14} introduced a new representation based on BP,
said to be {\em fully-functional} because it supported all of the operations
in Table~\ref{tab:ops} in constant time and using a single set of structures.
This was a significant simplification of previous results and enabled the
development of an efficient implementation. The idea was to reduce all the
tree operations to a small set of primitives over parentheses:
, , , and a few variations. The main structure
to implement those primitives was the so-called {\em range min-max tree
(rmM-tree)}, which is a balanced tree of arity  (for a constant
) that supports the primitives in constant time on buckets of 
 parentheses. To handle queries that were not solved 
within a bucket, other structures had to be added, and these were far less simple.

A simple -time implementation using a single binary range min-max 
tree for the whole sequence \cite{ACNS10} was shown to be faster (or use much less space, or both)
than other implementable constant-time representations \cite{GRRR06} in several
real-life trees and navigation schemes. Only the LOUDS representation was
shown to be competitive, within its limited functionality. 
While the  growth was shown to be imperceptible in many real-life
traversals, some stress tests pursued later \cite{JR12} showed
that it does show up in certain plausible situations.

No attempt was made to implement the actual constant-time proposal \cite{NS14}.
The reason is that, while constant-time and -bit space in theory, the 
structures used for inter-bucket queries, as well as the variant of rmM-trees 
that operates in constant time, involve large constants and include structures
that are known to be hard to implement efficiently, such as fusion 
trees \cite{FW93} and compressed bitvectors with optimal redundancy 
\cite{Pat08}. Any practical
implementation of these ideas leads again to the  times already
obtained with binary rmM-trees.

In this paper we introduce an alternative construction that builds on binary
rmM-trees and is simple to implement. It does not reach constant times, but
rather  time, and requires  bits of space.
We describe a new implementation building on these ideas, and experimentally 
show that it outperforms a state-of-the-art implementation of the 
-time solution, both in time and space, and therefore becomes the
new state-of-the art implementation of fully-functional succinct trees.

\section{Basic Concepts}

\subsection{Bits and balanced parentheses}

Given a bitvector , we define  as the number of 
occurrences of the bit  in . We also define  as
the position in  of the th occurrence of the bit . Both primitives
can be implemented in constant time using  bits on top of  
\cite{Cla96}. Note that  and .

A sequence of  parentheses will be represented as a bitvector 
by interpreting `(' as a 1 and `)' as a 0. On such a sequence we define the
operation  as the number of opening minus closing parentheses in
, that is, .
We say that  is {\em balanced} if  for all , and 
. Note that .

In a balanced sequence, every opening parenthesis at  has a matching 
closing parenthesis at  for , and every other parenthesis opening
inside  has its matching parenthesis inside  as well.
Thus the parentheses define a hierarchy. Moreover, we have 
 and  for all . 
This motivates the definition of the following primitives on parentheses
\cite{MR01}:
\begin{description}
        \item[:] the position of the closing parenthesis that matches
		, that is, the smallest  such that
                .
        \item[:] the position of the opening parenthesis that matches
		, that is, the largest  such that
                .
        \item[:] the opening parenthesis of the smallest matching 
		pair that contains position , that is, the largest 
		such that .
\end{description}

It turns out that a more general set of primitives is useful to implement a
large number of tree operations \cite{NS14}, which look forward or backward
for an arbitrary relative excess:

In particular, we have , 
, and .

To implement other tree operations, we also need the following primitives,
which refer to minimum and maximum excess in a range of :
\begin{description}
\item[:] position of the leftmost minimum in ,
.
\item[:] position of the leftmost maximum in ,
.
\item[:] number of occurrences of the minimum in ,
.
\item[:] position of the th minimum in ,
.
\end{description}

\subsection{BP representation of ordinal trees}

As said in the Introduction, an ordinal tree of  nodes is represented with
 parentheses by opening a parenthesis when we arrive at a node and closing
it when we leave the node. The resulting sequence is balanced, and the
hierarchy it defines corresponds to subtree containment. Let us identify
each node with the position of its opening parenthesis in the sequence .
See Figure~\ref{fig:tree}.

\begin{figure}[t]
\centerline{\includegraphics[width=0.8\textwidth]{tree.pdf}}
\caption{An ordinal tree on the left (the node identifiers are their preorder
numbers) and its BP representation on the right, indicating which parentheses
represent each node. For example the node with preorder 5 has identifier 7,
which is its position in the sequence of parentheses.}
\label{fig:tree}
\end{figure}

Many tree operations are immediately translated into the primitives 
we have defined \cite{MR01}: ,
, ,
 iff ,  (if  is not a leaf),
 (if the result  holds  then  has no
next sibling),  (if  then  has no
previous sibling),  (if  is not a leaf),
, ,
, ,
 iff , and .

The primitives  and  yield other tree 
operations \cite{NS14}: ,
,
,
, and
.
The other primitives yield the remaining operations:
,
 for 
(for  it is ),
 unless 
(in which case ),
 unless 
(so ) or  (so ),
, and
.

Finally, the operations on leaves are solved by extending the bitvector 
 and  primitives to count the occurrences of pairs  (which 
represent tree leaves, `()'):  is the number of occurrences of 
 starting in  and  is the position of the th
occurrence of  in . These are easily implemented as extensions of the 
basic  and  primitives, adding other  bits on top of
. Then 
, , 
,
 and finally
.

Therefore, all the operations of Table~\ref{tab:ops} are supported via the
primitives , , , , , and
. We also need  and  on 0, 1, and 10.

\subsection{Range min-max trees}

We describe the simple version of the structure used by Navarro and Sadakane 
\cite{NS14} to solve the primitives. 
We choose a block size . Then, the (binary) range 
min-max tree, or rmM-tree, of  is a complete binary tree where the 
th leaf covers . Each rmM-tree node  stores the following
fields:  is the total excess of the area covered by ,  is the
minimum excess in this area,  is the maximum excess in the area, and
 is the number of times the minimum excess occurs in the area. Since the
rmM-tree is complete, it can be stored without pointers, like a heap.
See Figure~\ref{fig:rmM}.

\begin{figure}[t]
\centerline{\includegraphics[width=0.8\textwidth]{rmM.pdf}}
\caption{The rmM-tree of the parentheses sequence of Figure~\ref{fig:tree}.
The numbers below are .}
\label{fig:rmM}
\end{figure}

Then, an operation like  is solved as follows. First, the block
number  is scanned from position  onwards, looking for 
the desired excess. If not found, then we reset the desired relative excess
to  and consider the leaf  of 
the rmM-tree that covers block . Now we move upwards from , looking for 
its nearest ancestor that contains the answer. At every step, if  is a
right child, we move to its parent. If it is a left child, we see if
, where  is the (right) sibling of . If  is not 
in the range, then update  and move to the parent of .
At some point in the search, we find that  for the
sibling  of , and then start descending from . Let  and  
be its left and right children, respectively. 
If , then we descend to . Otherwise,
we update  and descend to . Finally, we arrive at
a leaf, and scan its block until finding the excess .
Operation  is analogous; we scan in the other direction.

For , we scan the blocks of  and  and, if there are blocks
in between, we consider the fields  of the 
maximal nodes that cover the leaves contained in . Then we identify
the minimum excess in  as the minimum found across the scans and the
maximal nodes. If the first occurrence of the minimum is inside the scanned blocks, that
position is . Otherwise, we must start from the node  that
contained the first occurrence of the minimum and traverse downwards, looking
if the first occurrence was to the left or to the right (by comparing the
fields ). Operation  is analogous. For  we
retraverse the blocks and nodes, adding up the fields
 of the nodes where  is the minimum. Finally,
for , we do the same counting but traverse downward from
the node  where the th occurrence is found, to find its position.

Finally, for primitives  and , we
can compute on the fly the number of 1s inside any node  as
, where  is the size of the area of  covered by
. For , we count the 1s
in the block of  and then climb upwards from the leaf  covering ,
adding up  for each left sibling of  found towards the root. For
 we compute . For , we start from the
root node , going to the left child  if , and otherwise
updating  and going to the right child. For
 we proceed analogously, but using  instead of
. Finally,  and  on  is implemented analogously,
but we need to store a field  storing the number of 10s.

By using small precomputed tables that allow us to scan any block of 
 bits in constant time (i.e., computing the analogous to fields
, , , and  for any chunk of  bits), the total time of the
operations is  bits. The extra space of the rmM-tree over 
the  bits of  is  bits. For example, we can use a
single rmM-tree for the whole , set , and thus have all the
operations implemented in time  within  bits.
This is essentially the practical solution implemented for this structure
\cite{ACNS10}.

\section{An  Time Solution} 

Now we show how to obtain  worst-case time, still within
 extra bits. The main idea (still borrowing from the original
solution \cite{NS14}) is to cut  into  buckets of 
 bits. We maintain one (binary) rmM-tree for each 
bucket. The block size of the rmM-trees is set to . 
This maintains the extra space of each rmM-tree within
 bits, adding up to 
bits. Their operation times also stay .

Therefore, the operations that are solved within a bucket take 
time.  The difficult part is how to handle the operations that span more than 
one bucket: a  or  whose answer is not found
within the bucket of , or a  or similar operation where 
and  are in different buckets.

For each bucket , we will store an entry  with the
excess at its end, and entries  and  with the minimum and maximum absolute excess reached inside the
bucket. These entries require just  bits of 
space. Heavier structures will be added for each operation, as described next.

\subsection{Forward and backward searching}  \label{sec:fwd-large}

The solution for these queries is similar to the original one \cite{NS14},
but we can simplify it and make it more practical by allowing us to take
 time to solve the operation. 
We describe its details for completeness.

We first try to solve  inside the bucket of , 
. If the answer is found in there, we have completed
the query in  time. Otherwise, after scanning the block, we
have computed the new relative excess sought  (which is the original one
minus ). This is converted into absolute with
. 

Now we have to find the answer in the buckets  onwards. We have to find
the smallest  with , and then find the answer inside
bucket . Let us first consider the next bucket. If 
, then the desired excess is reached inside the 
next bucket, and therefore we complete the query by running 
 inside the rmM-tree of bucket .
Otherwise, either  or . Let us consider the first
case, as the other is symmetric (and requires other similar data structures).
The query  works
similarly, except that we look towards the left, therefore it is also analogous.

Since the excess changes by  from one parenthesis to the next, 
it must hold  for all
, that is, there are no holes in the ranges  of consecutive
buckets. Therefore, if , then we simply look for the smallest
 such that .
Note that for this search we would like to consider, given a  where
, only the smallest  such that , as those
values  are not the solution. If we define
a tree where  is the parent of , then we are looking for the nearest
ancestor  of node  where .

The solution builds on a well-known problem called {\em level-ancestor queries}
(an operation we have already considered for our succinct trees). Given a node
 and a distance , we want the ancestor at distance  from . In the
classical scenario, there is an elegant and simple solution to this problem
\cite{BF04}.
It requires  bits of space, but this is just .
The idea is to extract the longest root-to-leaf path and write it on an array
called a {\em ladder}. Extracting this path disconnects the tree into several 
subtrees. Each disconnected subtree is processed recursively, except that each 
time we write a path  of nodes into a new ladder, we continue 
writing the ancestors up to other  nodes. That is, a path  
is converted into a ladder of  nodes (or less if we reach the global
root). Thus the ladders add up to at most  cells.

In the ladders,
each node has a {\em primary} copy, corresponding to the path  where
it belongs, and zero or more {\em secondary} copies, corresponding to paths
that are extended in other ladders. We store a pointer to the primary copy of
each node, and the id of its ancestors at distances , for .
This is where the  words of space are used.

Now, to find the th ancestor of , we compute ,
and find in the tables the ancestor  at distance  of . Then we go
to the ladder where the primary copy of  is written. Because we
extract the longest paths, since  has height at least , the path
 where it belongs must be of length at least , and therefore
the ladder is of length at least . Therefore, the ladder
contains the ancestors of  up to distance at least , and thus the one
we want, at distance , is written in the ladder. Thus we just read
the answer in that ladder and finish.

We must extend this solution so that we find the first ancestor  with 
. Recall that the values  form a decreasing sequence as we
move higher in the sequence of ancestors, and within any ladder. First, we
can find the appropriate  value with a binary search in the ancestors at
distance , so that  is the smallest one such that the ancestor 
at distance  still has . This takes  time.

Now, in the ladder of , we must find the first cell  to its
right with . We solve this by representing all the  values
as  in a bitvector  created for that ladder. Then 
 is the distance from the end of the ladder to the position of
the desired ancestor .

A useful bitvector representation for this matter is the \emph{sarray} by
Okanohara and Sadakane \cite[Sec.~6]{OS07}.\footnote{Other compressed
representations use  further bits, which make them unsuitable for us.}
If the ladder contains 
elements and the maximum value is , then it takes  bits of space (which adds up to just  bits overall, since
 is the maximum excess). It solves  queries in time
 if we represent its internal bitvector  of 
bits with a structure that solves  and  in constant time
\cite{Cla96}. Note that, since the excess changes by  across positions,
it changes by  across buckets, and thus consecutive elements in the
ladder differ by at most . Therefore, it must be , and
the time for the  operation is .

\subsection{Range minima and maxima} \label{sec:rmq-large}

If both  and  fall inside the same bucket, then operations  
and relatives are solved inside their bucket.
Otherwise, the minimum might fall in the bucket of , , in that of , ,
or in a bucket in between. Using the rmM-trees of buckets  and , we
find the minimum  in the range  of bucket 
, and convert it to a global excess, . 
We also find the minimum  in the range  of 
bucket , and convert it to . The 
problem is to find the minimum in the intermediate buckets,
. Once we have this, we easily
solve  as the position of  if ,
otherwise as the position of  if , and otherwise as the
position of  (recall that we want the leftmost position of the minimum).

In the original work \cite{NS14}, they use the most well-known classical
solution to range minimum queries \cite{BF00}. While it solves the problem
for query , it decomposes the query range  into 
overlapping subintervals, and thus it cannot be used to solve the other related
queries, such as counting the number of occurrences of the minimum or finding
its th occurrence. As a result, they resort to complex fixes to handle
each of the other related operations in constant time.

If we can allow ourselves to use  time for the operations,
then a much simpler and elegant solution is possible, using a less known data
structure for range minimum queries \cite{YA10}. It uses  
words, which is  bits, and solves queries in constant time.
The most relevant feature of this solution is that it reduces the query on
interval  to disjoint subintervals, which allows solving the
related queries we are interested in.

Assume  is a power of  and consider a perfect binary tree on top of 
array , of height . The tree nodes with height
 cover disjoint areas of , of length . The tree is stored as a
heap, so we identify the nodes with their position in the heap, starting from
1, and the children of the node at position  are at positions  
and .

For each node  covering , we store two arrays with the
left-to-right and right-to-left minima in , that is, we store
 and
 for all .
Their size adds up to  cells, or
 bits.

Let us call  and . To find the minimum in , we 
compute the lowest node  that covers . Node  is found as follows:
we compute the highest bit where the numbers  and  differ. If this is
the th bit (counting from the left), then node  is of height , and it 
covers the th area of  of size  (left-to-right), where
. That is, it holds  and the range
it covers is .

The value of  can be computed as \footnote{The  operator
        takes two integers and performs the bitwise logical exclusive-or 
operation on them, that is, on each pair of corresponding bits.}. 
If operations  and  are not allowed in the computation model, we can
easily simulate them with small global precomputed tables of size 
, 
which can process any sequence of  bits (note that computing 
requires just to find the most significant 1 in the computer word).

Now we have found the lowest node  that covers  in
the perfect tree. Therefore, for , the left child  of 
covers  and its right child  covers . Then, the minimum
of  is either that of  (which is available at ) or
that of  (available at ). We return the minimum of
both. 

This general mechanism is used to solve all the queries related to ,
as we see next.

\subsubsection{Solving  and } \label{sec:rmq}

The only missing piece for solving  is to find the leftmost 
position of the minimum in . To do this we store other two arrays,
 and , with the leftmost positions of the minima of the bucket ranges
represented in  and , respectively. That is, if  covers , then
 and
.

Thus, once we have the node  that covers , there are two
choices: If  (i.e., the minimum appears 
in the subrange ), the leftmost position is . Otherwise 
(i.e., the minimum appears only in the subrange ) the leftmost
position is . 

Note that any entry from the array  can be
obtained on the fly from the corresponding entry of  and the bucket
array , hence  are only conceptual and we do not store them.
Furthermore, the arrays  are only accessed by nodes that are the
right/left children of their parent, thus we only store one of them in each
node. 

Operation  is solved analogously (needing similar structures , 
,  and  regarding the maxima).

\subsubsection{Solving } \label{sec:mincount}

To count the number of times the minimum appears, we first compute 
, and then add up its occurrences in each of the
three ranges: we add up  in bucket  if
,  in bucket  if ,
and the number of times the minimum appears in  
(i.e., inside buckets  to ) if . To compute this last number,
we store two new arrays,  and , giving the number of times the minimum
occurs in the corresponding areas of  and , that is,
 and
. 

Thus, if , then the minimum appears only on the
left, and the count in buckets  to  is . If 
, it appears only on the right, and the count is
. Otherwise, it appears in both and the count is
.  Once again, a node needs to store only
 or , not both.

\subsubsection{Solving }

To solve  we must see if  falls in the bucket of ,
in the bucket of , or in between. We start by considering , if
. In this case, we compute ,
the number of times  occurs inside bucket . If , then the
th occurrence is inside it, and we answer
. If , then we continue, with
.

If  appears between  and , that is, if , we compute
 as in Section~\ref{sec:mincount}. Again,
if , the answer is the th occurrence of the
minimum in buckets  to . If , we just set .
Finally, if we have not yet solved the query, we return
 within bucket .

To find the th occurrence of  in the buckets  to , we make use
of the arrays  and . If , then the answer is to be
found in the buckets  to . If, instead, , then there
are  occurrences of  in . Thus, if ,
we must find the th occurrence of  in buckets  to . If instead
, we set  and find the th
occurrence of the minimum in buckets  to .

Let us find the th occurrence of  in buckets  to  (the other case
is symmetric, using  instead of ). The minimum in  is . It
also holds that the minimum in  is , for all ,
for some number , and then . Those intervals are
represented in the cells  to , and the number of times
 occurs in them is in  to . Therefore, our 
search for the th minimum spans a contiguous area of : we want
to find the largest  such that . This means
that the th occurrence of  in buckets  to  is in bucket
, in whose rmM-tree we must return .

To find  fast, we record all the values  in 
complemented unary (i.e., number  as ) in a bitvector . Then,
each  counts an occurrence of the minimum and each  counts a bucket. 
To find , we compute
, the sum of the values up to , and then
 is the desired cell , thus 
.

We use again the \emph{sarray} bitvector of Okanohara and Sadakane \cite{OS07}.
It solves  in constant time and  in the same time as
.  There is a 1 per cell in , so the global space is at most  bits.  Since the distance between
consecutive 1s is at most , the time to compute  is
.

Note, in passing, that bitvector  can replace , as it can compute
any cell  in constant time.
Therefore we can use those bitvectors instead of storing arrays  and ,
thus avoiding to increase the space further.

\subsection{Rank and select operations} \label{sec:rs}

The various basic and extended  and  operations are 
implemented similarly as the more complex operations. For , we 
store the  value at the beginning of each bucket, in an array 
, and then compute  inside 
the rmM-tree of bucket . For ,
we store the  values in a bitvector  with 
 for all , then the bucket  where the answer lies is 
, inside whose rmM-tree we must solve 
. Again, with the bitvectors of Okanohara and Sadakane
\cite{OS07}, we do not need to store  because its cells are computed in
constant time as , the space
used is  bits, and the time to compute
 is  because there are at most  0s per 1 in
.

\section{Implementation and Experimental Results}

We now describe an engineered implementation based on our theoretical 
description, and experimentally evaluate it. Engineered implementations often
replace solutions with guaranteed asymptotic complexity by simpler variants 
that perform better in most practical cases. Our new theoretical version is
much simpler than the original \cite{NS14}, and thus most of it can be
implemented verbatim. Still, we further simplify some parts to speed them up
in practice. As a result, our implementation does not fully guarantee
 time complexity, but it turns out to be faster than the 
state-of-the-art implementation that uses  time. As this latter
implementation essentially uses one binary rmM-tree for the whole sequence, our
experiments show that our new way to handle inter-bucket queries is useful in 
practice, reducing both space and time.

\subsection{Implementation}

We use a fixed bucket size of  parentheses (i.e., KB).
Since the \emph{relative} excess inside each bucket are in the range 
 the fields of the nodes of each rmM-tree are stored 
using -bit integers. To reduce space, we get rid of the  fields by 
storing  and  in \emph{absolute} form, not relative to 
their rmM-subtree.\footnote{These values are absolute within their current 
bucket; they are still relative to the beginning of the bucket (otherwise they 
would not fit in  bits).} This is because the field  is used only to 
convert relative values to
absolute.\footnote{Instead, relative values allow making the structure
dynamic, as efficient insertions/deletions become possible \cite{NS14}.}
This reduces the space required by the rmM-tree nodes from 8
to 6 bytes (or 4 bytes if the field \emph{v.n} is not required, as it is
used only in the more complicated operations). The block size of each
rmM-tree, , is parameterized and provides a space-time tradeoff:  the bigger
the block size, the more expensive it is to perform a full scan.  The sequential
scan of a block is performed by lookup tables that handle \emph{chunks} of
either  or  bits. Preliminary tests yielded the following values to be 
reasonable for :  bits (with lookup tables of  bits) and
 bits (with lookup tables of  bits).  In particular, for 
our rmM-trees have height  and a sequential scan of a
block requires up to  table lookups.

The \emph{bucket} arrays  and  are stored in heap form, as 
described. The special tree  of Section~\ref{sec:fwd-large} is built
using a stack-based folklore algorithm that finds the previous-smaller-value
of each element in array  in linear time and space (that is, 
words).  The \emph{ladder} decomposition and pointers to ancestors at
distances  (for some ) in  are implemented verbatim.  To find the
target bucket for operation  we sequentially iterate over
 to find an ancestor whose minimum excess is lower than the
target, then we perform a sequential search in its ladder to find the target
bucket.  Although this implementation does not guarantee 
worst case time, it is cache-friendly and faster than doing a binary search over
the list of sampled ancestors or using the \emph{sarray} bitmap representation
to accelerate the search. On the real datasets that were used for
the experiments, the height of  was in all cases less than , which
fully justifies a sequential scan. A more
sophisticated implementation could resort to the guaranteed -time
method when it detects that the ladder or the list of ancestors are long enough.

For operation  and relatives, the perfect binary tree of 
Section~\ref{sec:rmq-large} is implemented verbatim, except that the bitvector
 is not implemented; a sequential search in  is carried out instead
for . The extended  and  operations were not yet
implemented.

\subsection{Experiemental setup}

To measure the performance of our new implementation we used two public
datasets\footnote{Available at
\url{http://www.inf.udec.cl/~josefuentes/sea2015/}}: \texttt{wiki}, the XML tree
topology of a Wikipedia dump with  parentheses and \texttt{prot},
the topology of the suffix tree of the Protein corpus from the Pizza\&Chili
repository\footnote{Available at \url{http://pizzachili.dcc.uchile.cl/}} with
 parentheses. 

We replicate the benchmark methodology used by
Arroyuelo et al.~\cite{ACNS10}: we fix a probability  and generate a
\emph{sample dataset} of nodes by performing a depth-first traversal of the tree
where we descend to a random child and also descend to each other child
with probability .  All datasets generated consist of at least
 nodes.  Setting  emulates random root-to-leaf
paths while  provides a full traversal of the tree. Intermediate
values of  emulate other tree traversals that occur, for example,
when solving XPath queries or performing approximate string matching on suffix 
trees. We benchmark the operations  for ,
, and . We also benchmark operation  by choosing 
200,000 pairs  at random and classifying the results according to .

All the experiments were ran on a Intel(R) Core(TM) i5 running at GHz with
GB of RAM running Mac OS X 10.10.5.  Our implementation is single-threaded,
written in \texttt{C++}, and compiled with \texttt{clang} version
 with the flags \texttt{-O3} and \texttt{-DNDEBUG}.

As a baseline we use the \texttt{C++} implementation available in the
Succinct Data Structures Library \footnote{Available at
\url{github.com/simongog/sdsl-lite}}(SDSL), which provides an -time
implementation based on the description of Arroyuelo et al.~\cite{ACNS10}.
This library is known for its excellent implementation quality. In particular,
this implementation also stores the fields  and  in absolute form
and discards . It also does not store , as it does not implement the
more complex operations associated with it. For this reason, we will only
compare the structures on the most basic primitives 
 that are also implemented in SDSL. Also, for 
fairness, we {\em do not} account for the space of the field  in our
structure.

\subsection{Experimental results}

Figures~\ref{fig:data} and \ref{fig:data2} (left) show the results for 
 operations with
different values of .  The times reported are in microseconds and are the
average obtained by performing the operation over all the nodes of a
dataset generated for a given parameter value . 
The space is reported in bits per node (\emph{bpn}).
The \emph{new-} prefix refers
to the implementation of our new structure, while \emph{sdsl-} refers
to the SDSL implementation. The three space-time tradeoffs shown in our new
implementation correspond to , , and  (a larger  obtains
lower space and higher time).

For operation , our implementation is considerably faster than
SDSL, while using essentially the same space. For , we are up to 
times faster when using the least space. For larger , the operations
becomes much faster due to the locality of the traversals, and the time
differences decrease, but it they are still over 10\%.

Our implementation is still generally faster for  on \texttt{prot},
whereas on \texttt{wiki} SDSL takes over for larger  values. The maximum
advantage in our favor is seen on operation , where our implementation
is -- times faster when using the least space, with the only exception of
\texttt{prot} with , where we are only 30\% faster.

\begin{figure}[t!]
\centering
\begin{tabular}{cc}
\subf{\includegraphics[width=60mm]{close-0.pdf}} &
\subf{\includegraphics[width=60mm]{open-0.pdf}} \\
\subf{\includegraphics[width=60mm]{close-25.pdf}} &
\subf{\includegraphics[width=60mm]{open-25.pdf}} \\
\subf{\includegraphics[width=60mm]{close-50.pdf}} &
\subf{\includegraphics[width=60mm]{open-50.pdf}} 
\end{tabular}
\caption{Space-time tradeoffs for our new implementation and the SDSL baseline,
for operations  (left) and  (right).}
\label{fig:data}
\end{figure}

\begin{figure}[t!]
\centering
\begin{tabular}{cc}
\subf{\includegraphics[width=60mm]{enclose-0.pdf}} &
\subf{\includegraphics[width=60mm]{rmq.pdf}} \\
\subf{\includegraphics[width=60mm]{enclose-25.pdf}} &
\subf{\includegraphics[width=60mm]{close-hist.pdf}} \\
\subf{\includegraphics[width=60mm]{enclose-50.pdf}} &
\subf{\includegraphics[width=60mm]{open-hist.pdf}} \\
\end{tabular}
\caption{Space-time tradeoffs for our new implementation and the SDSL baseline,
for operation  (left). On the right, the results as a function
of the distance traversed in the parenthesis sequence for , , and 
.}
\label{fig:data2}
\end{figure}

For operation  we show the results classified by , cut into 100 
percentiles. Figure~\ref{fig:data2} (top right) shows the results.
Both structures use the same space, about  bits per node.
On \texttt{prot} we are significantly faster in almost all the spectrum, while 
on \texttt{wiki} we are generally faster by a small margin. The difference owes
to the fact that the tree of \texttt{prot} is much deeper, and therefore the
traversals towards the  positions are more random and less cache-friendly.
In \texttt{wiki}, the root and the highest nodes are the answers to random
s in most cases, so their rmM-trees are likely to be in cache from 
previous queries. On the other hand, we note that the times are basically
constant as a function of .

The other plots on the right of Figure~\ref{fig:data2} we show how the times for
operation  and  evolve as a function of the difference between 
the position that is queried and the one where the answer is found. We use the 
configuration with about  bits per node for both implementations, and
average the query times over all the tree nodes. In general, only a slight 
increase is observed as the distance grows. In the larger sequence {\tt prot}, 
however, there is a sharp increase for the largest distances. This is not 
because the number of operations grows sharply, but it rather owes to a 10X 
increase in the number of cache misses: traversing the
longest distances requires accessing various rmM-tree nodes that no longer fit
in the cache. Note that the highest times, around 0.5 s, are indeed the
typical times obtained in Figure~\ref{fig:data} with , where most of 
the nodes traversed produce cache misses.

\section{Conclusions}

We have described an alternative solution for representing ordinal trees of 
nodes within  bits of space, which solves a large number of
queries in time . While the original solution upon which we
build \cite{NS14} obtains constant times, it is hard to implement and only
variants using  time had been successfully implemented.  We have
presented a practical implementation of our solution and have experimentally
shown that, on real hundred-million node trees, it achieves better space-time
tradeoffs than current state-of-the-art implementations. This shows that the
new design has not only theoretical, but also practical value. Our new
implementation is publicly available at 
{\tt www.dcc.uchile.cl/gnavarro/software}.







\bibliographystyle{plain}
\bibliography{paper}

\end{document}
