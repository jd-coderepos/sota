

\documentclass[11pt, letter]{article}
\pdfoutput=1
\usepackage{sober}
\usepackage{amsthm,amsmath,fullpage,color,graphicx,subfigure,geometry,boxedminipage}
\usepackage{hyperref,verbatim,algorithmic}
\usepackage[section,boxed]{algorithm}


\title{The Forgiving Graph: A distributed data structure for low stretch under adversarial attack} 
\author{Tom Hayes \thanks{Department of Computer Science,  
University of New Mexico,  Albuquerque,  NM 87131-1386;
email: {\tt \{hayes, saia, amitabh\}@cs.unm.edu}. 
This research was partially supported by NSF CAREER Award 0644058,
NSF CCR-0313160, and an AFOSR MURI grant.}
\and Jared Saia   \footnotemark[1]
\and Amitabh Trehan  \footnotemark[1] }


\newtheorem{conjecture}{Conjecture}
\newtheorem{lemma}{Lemma}
\newtheorem{corr}{Corrolary}
\newtheorem{theorem}{Theorem}
\newtheorem{observation}{Observation}







    \renewcommand{\topfraction}{0.9} 
    \renewcommand{\bottomfraction}{0.8} 
    \setcounter{topnumber}{2}
    \setcounter{bottomnumber}{2}
    \setcounter{totalnumber}{4} 
    \setcounter{dbltopnumber}{2} 
    \renewcommand{\dbltopfraction}{0.9} 
    \renewcommand{\textfraction}{0.07} 
    \renewcommand{\floatpagefraction}{0.7} 
\renewcommand{\dblfloatpagefraction}{0.7}



 
\DeclareGraphicsExtensions{.pdf}

\geometry{left=.8in,right=.8in,top=.8in,bottom=1in} 

\newcommand{\RT}{\mathrm{RT}}
\newcommand{\RTfragment}{\mathrm{RTfragment}}
\newcommand{\ID}{\mathrm{ID}}
\newcommand{\SubRT}{\mathrm{SubRT}}
\newcommand{\RTmap}{\mathrm{RTmap}}
\newcommand{\RTID}{\mathrm{RTID}}
\newcommand{\RTportions}{\mathrm{RTportions}}
\newcommand{\RTportion}{\mathrm{RTportion}}
\newcommand{\RTparent}{\mathrm{RTparent}}
\newcommand{\RTchildren}{\mathrm{RTchildren}}
\newcommand{\RThparent}{\mathrm{RThparent}}
\newcommand{\RThchildren}{\mathrm{RThchildren}}
\newcommand{\DASH}{\mathrm{DASH}}
\newcommand{\Nset}{\mathrm{Nset}}
\newcommand{\hparent}{\mathrm{hparent}}
\newcommand{\hleftchild}{\mathrm{hleftchild}}
\newcommand{\hrightchild}{\mathrm{hrightchild}}
\newcommand{\Endpoint}{\mathrm{endpoint}}
\newcommand{\BT}{\mathrm{BT}}
\newcommand{\PrRoots}{\mathrm{PrRoots}}
\newcommand{\Mergeheirs}{\mathrm{Mergeheirs}}
\newcommand{\representative}{\mathrm{Representative}}
\newcommand{\edge}{\mathrm{edge}}
\newcommand{\anchor}{\mathrm{anchor}}
\newcommand{\childrencount}{\mathrm{childrencount}}
\newcommand{\height}{\mathrm{height}}
\newcommand{\False}{\mathrm{FALSE}}
\newcommand{\True}{\mathrm{TRUE}}
\newcommand{\HFT}{\mathrm{HFT}}
\newcommand{\haft}{\mathrm{haft}}
\newcommand{\FT}{\mathrm{FT}}
\newcommand{\Strip}{\mathrm{Strip}}
\newcommand{\Merge}{\mathrm{Merge}}
\newcommand{\Delete}{\mathrm{Delete}}
\newcommand{\DeleteRightmostnode}{\mathrm{DeleteRightmostnode}}
\newcommand{\real}{\mathrm{real}}
\newcommand{\Root}{\mathrm{ROOT}}
\newcommand{\numchildren}{\mathrm{numchildren}}
\newcommand{\Haftmergeprint}{\mathrm{HaftMergePrint}}
\newcommand{\size}{\mathrm{size}}



\newcommand{\will}{\mathrm{will}}
\newcommand{\heir}{\mathrm{heir}}
\newcommand{\helper}{\mathrm{helper}}
\newcommand{\neighbor}{\mathrm{neighbor}}
\newcommand{\neighbors}{\mathrm{neighbors}}
\newcommand{\parent}{\mathrm{parent}}
\newcommand{\rparent}{\mathrm{rparent}}
\newcommand{\children}{\mathrm{children}}
\newcommand{\hchildren}{\mathrm{hchildren}}
\newcommand{\isactiveheir}{\mathrm{isactiveheir}}
\newcommand{\degree}{\mathrm{degree}}
\newcommand{\diam}{\mathrm{diam}}
\newcommand{\distance}{\mathrm{distance}}
\newcommand{\hashelper}{\mathrm{hashelper}}
\newcommand{\nexthparent}{\mathrm{nexthparent}}
\newcommand{\nexthchildren}{\mathrm{nexthchildren}}
\newcommand{\nextparent}{\mathrm{nextparent}}
\newcommand{\Empty}{\emph{EMPTY}}
\newcommand{\helperinwaiting}{\emph{helper-in-waiting}}
\renewcommand{\algorithmiccomment}[1]{// #1} 



\begin{document}
\date{}
\maketitle

\thispagestyle{empty}

\begin{abstract}
We consider the problem of self-healing in peer-to-peer networks that are under repeated attack by an omniscient
adversary. We assume that, over a sequence of rounds, an adversary either inserts a node with arbitrary connections or
deletes an arbitrary node from the network. The network responds to each such change by quick ``repairs," which consist
of adding or deleting a small number of edges.

These repairs essentially preserve closeness of nodes after adversarial deletions, without increasing node degrees by
too much, in the following sense.   At any point in the algorithm, nodes  and  whose distance would have been  in the graph formed by considering only the adversarial insertions (not the adversarial deletions), will be at
distance at most  in the actual graph, where  is the total number of vertices seen so far. Similarly, at any
point, a node  whose degree would have been  in the graph with adversarial insertions only, will have degree at most
 in the actual graph.  Our algorithm is completely distributed and has low latency and bandwidth requirements.

\end{abstract}

\section{Introduction}

Many modern networks are \emph{reconfigurable}, in the sense that the topology of the network can be changed by the
nodes in the network.  For example, peer-to-peer, wireless and mobile networks are reconfigurable.  More generally, many social networks, such as a company's organizational chart; infrastructure networks, such as an airline's transportation network; and biological networks, such as the human brain, are also reconfigurable.  Reconfigurable networks offer the promise of ``self-healing'' in the sense that when nodes in the network fail, the remaining nodes can reconfigure their links to overcome this failure.  In this paper, we describe a distributed data structure for maintaining invariants in a reconfigurable network.  We note that our approach is \emph{responsive} in the sense that it responds to an attack by changing the network topology.  Thus, it is orthogonal and complementary to traditional non-responsive techniques for ensuring network robustness.



This paper builds significantly on results achieved in~\cite{HayesPODC08}, which presented a responsive, distributed data structure called the \emph{Forgiving Tree} for maintaining a reconfigurable network in the fact of attack. The Forgiving Tree ensured two invariants: 1) the diameter of the network never increased by more than a multiplicative factor of  where  is the maximum degree in the graph; and 2) the degree of a node never increased by more than an additive factor of .  

In this paper, we present a new, improved distributed data structure called the \emph{Forgiving Graph}.  The improvements of the Forgiving Graph over the Forgiving Tree are threefold.  First, the Forgiving Graph maintains 
low stretch i.e. it ensures that the distance between any pair of nodes  and  is close to what their distance would be even if there were no node deletions.  It ensures this property even while keeping the degree increase of all nodes no more than a multiplicative factor of .  Moreover, we show that this tradeoff between stretch and degree increase is asymptotically optimal.  Second, the Forgiving Graph handles both adversarial insertions and deletions, while the Forgiving Tree could only handle adversarial deletions (and no type of insertion).  Finally, the Forgiving Graph does not require an initialization phase, while the Forgiving Tree required an initialization phase which involved sending  messages, where  was the number of nodes initially in the network, and had a latency equal to the initial diameter of the network.  Additionally, the Forgiving Graph is divergent technically from the Forgiving Tree, it makes significant use of a novel distributed data structure that we call a Half-full Tree (HaFT). 

\medskip
\noindent {\bf Our Model:} We now describe our model of attack and
network response, which is identical to that of~\cite{HayesPODC08}.  We assume that the network is initially a connected
graph over  nodes.  An adversary repeatedly attacks the
network. This adversary knows the network topology and our
algorithm, and it has the ability to delete arbitrary nodes from the
 network or insert a new node in the system which it can connect to any subset of the nodes currently in the system.  
However, we assume the adversary is constrained in that in any time step it can only delete or insert a single node. 

\medskip
\noindent {\bf Our Results:}  For a peer-to-peer network that has both insertions and deletions, let  be the graph consisting of the original nodes and inserted nodes without any changes due to deletions. Let  be the number of
nodes in . The Forgiving Graph ensures that: 1) the distance between any two nodes of the actual network never increases by more than  times their distance in ; and 2) the degree of any node never increases by more than  times its degree in .  Our algorithm is completely distributed and resource efficient.  Specifically, after deletion, repair takes
 time and requires sending  messages, each of size  where  is the degree
of the node that was deleted. The formal statement and proof of these results is in Section~\ref{subsec: upperbounds}. 

\medskip
\noindent {\bf Related Work:} 
Our work significantly builds on work in~\cite{HayesPODC08} as described above.  There have been numerous other papers that
discuss strategies for adding additional capacity or rerouting in
anticipation of failures \cite{ doverspike94capacity,
frisanco97capacity, iraschko98capacity, murakami97comparative,
caenegem97capacity, xiong99restore}.  Results that
are responsive in some sense include the following.  M\'{e}dard, Finn, Barry, and Gallager
\cite{medard99redundant} propose constructing redundant trees to make
backup routes possible when an edge or node is deleted.  Anderson,
Balakrishnan, Kaashoek, and Morris \cite{anderson01RON} modify some
existing nodes to be RON (Resilient Overlay Network) nodes to detect
failures and reroute accordingly. Some networks have enough redundancy
built in so that separate parts of the network can function on their
own in case of an attack~\cite{goel04resilient}.  In all these past
results, the network topology is fixed.  In contrast, our approach
adds edges to the network as node failures occur.  Further, our
approach does not dictate routing paths or specifically require
redundant components to be placed in the network initially.   Our model of attack and repair builds on earlier work in~\cite{BomanSAS06, SaiaTrehanIPDPS08}.



There has also been recent research in the physics community on
preventing cascading failures.  In the model used for these results,
each vertex in the network starts with a fixed capacity. When a vertex
is deleted, some of its ``load'' (typically defined as the number of
shortest paths that go through the vertex) is diverted to the
remaining vertices.  The remaining vertices, in turn, can fail if the
extra load exceeds their capacities. Motter, Lai, Holme, and Kim have
shown empirically that even a single node deletion can cause a
constant fraction of the nodes to fail in a power-law network due to
cascading failures\cite{holme-2002-65, motter-2002-66}. Motter and Lai
propose a strategy for addressing this problem by intentional removal
of certain nodes in the network after a failure begins
\cite{motter-2004-93}.  Hayashi and Miyazaki propose another strategy,
called emergent rewirings, that adds edges to the network after a
failure begins to prevent the failure from
cascading\cite{hayashi2005}.  Both of these approaches are
shown to work well empirically on many networks.  However, unfortunately, they
perform very poorly under adversarial attack.

\section{Node Insert, Delete and Network Repair Model}
\label{sec:prelim}
 



\begin{figure}[h!]
\caption{The Node Insert, Delete and Network Repair Model -- Distributed View.}
\label{algo:model-2}
\begin{boxedminipage}{\textwidth}
\begin{algorithmic}
\STATE Each node of  is a processor.  
\STATE Each processor starts with a list of its neighbors in .
\STATE Pre-processing: Processors may send messages to and from
their neighbors.
\FOR { to }
\STATE Adversary deletes or inserts a node  from/into , forming .
\IF{node  is inserted} 
\STATE The new neighbors of  may update their information and send messages to and from
their neighbors.
\ENDIF
\IF{node  is deleted} 
\STATE All neighbors of  are informed of the deletion.
\STATE {\bf Recovery phase:}
\STATE Nodes of  may communicate (asynchronously, in parallel) 
with their immediate neighbors.  These messages are never lost or
corrupted, and may contain the names of other vertices.
\STATE During this phase, each node may insert edges
joining it to any other nodes as desired. 
Nodes may also drop edges from previous rounds if no longer required.
\ENDIF
\STATE At the end of this phase, we call the graph .
\ENDFOR
\vspace{10pt}
\hrule
\STATE
\STATE {\bf Success metrics:} Minimize the following ``complexity'' measures:\\
Consider the graph   which is the graph consisting solely of the original nodes and insertions without regard to
deletions and healings. Graph  is  at timestep  (i.e. after the  insertion or deletion).
\begin{enumerate}
\item{\bf Degree increase.}  
\item {\bf Network stretch.} , where, for a graph  and nodes  and  in ,  is the
length of the shortest path between  and  in .
\item{\bf Communication per node.} The maximum number of bits sent by a single node in a single recovery round.
\item{\bf Recovery time.} The maximum total time for a recovery round,
assuming it takes a message no more than  time unit to traverse any edge and we have unlimited local computational power at each node.
\end{enumerate}
\end{algorithmic}
\end{boxedminipage}
\end{figure}
We now describe the details of our node insert, delete and network repair model.  Let  be an arbitrary graph on
 nodes,
which represent processors in a distributed network.  In each step, the adversary either deletes or adds a node. 
After each
deletion, the algorithm gets to add some new edges to the graph, as well as deleting old ones.  At each insertion, the
processors follow a protocol to update their information.
The algorithm's goal is to maintain connectivity in the network, keeping the distance between the nodes small.  At the
same time, the algorithm wants to
minimize the resources spent on this task, including keeping node degree small.  



Initially, each processor only knows its neighbors in , and is unaware of the structure of the rest of .
After each deletion or insertion, only the neighbors of the deleted or inserted vertex are informed that
the deletion or insertion has occured. After this, processors are allowed to communicate by sending a limited number
of messages to their direct  neighbors.  We assume that these messages are always sent and received successfully.  The
processors may also request new edges be added to the graph. The only synchronicity assumption we make is that no
other  vertex is deleted or inserted until the end of this round of computation and communication has concluded.
To make this assumption more reasonable, the per-node communication cost should be very small in  (e.g. at most logarithmic).


We also allow a certain amount of pre-processing to be done before the first attack occurs.  This may, for instance,
be used by the processors to gather some topological information about , or perhaps to 
coordinate a strategy.  Another success metric is the amount of computation and communication needed during this
preprocessing round.  Our full model is described in Figure~\ref{algo:model-2}.



\section{The Forgiving Graph algorithm}
\label{sec:algorithm}

\begin{figure}[t!]
\centering
\includegraphics[scale=0.5]{MakeRTFG}
\caption{Deleted node  replaced by its Reconstruction Tree. The nodes in the triangle are helper nodes
simulated by the real nodes which are in the leaf layer.}
 \label{fig: RT}
\end{figure}

At a high level, our algorithm works as follows:

In our model, an adversary can effect the network in one of two ways: inserting a new node in the network or deleting an
existing node from the network. Node insertion is straightforward and is dependent on the specific policies of the
network. When an insertion happens, our incoming node and its neighbors update the data structures that are
used by our algorithm. We will also assume that nodes maintain neighbor-of-neighbor information.

Each time a node  is deleted, we can think of it as being replaced by a Reconstruction Tree (, for short) which
is a   (discussed in  Section~\ref{sec: hafts}) having ``virtual'' nodes as internal nodes and
neighbors of  as the leaf nodes. Note that each virtual node has a degree of at most  . A single real node itself is a trivial  with one node.
 is formed by merging all the neighboring s of
 using the strip and merge operations from Section~\ref{sec: hafts}.
After a long sequence of such insertions and deletions, we are left with a graph which is a patchwork mix of virtual
nodes and original nodes. 



Also, because the virtual trees (hafts) are balanced binary trees, the deletion of a node  can, at worst, cause the
distances between its neighbors to increase from  to  by travelling through its , where 
 is the degree of  in  (the graph consisting solely of the original nodes and insertions without regard to
deletions and healings). 
However, since this deletion may cause many s to merge and the new  formed may
involve all the nodes in the graph, the distances between any pair of actual surviving nodes may increase by no
 more than a  factor.
 
Since our algorithm is only allowed to add edges and not nodes, 
we cannot really add these virtual nodes to the network.
We get around this by assigning each virtual node to an actual
node, and adding new edges between actual nodes in order to 
allow ``simulation'' of each virtual node.  More precisely,
our actual graph is the homomorphic image of the graph
described above, under a graph homomorphism which fixes 
the actual nodes in the graph and maps each virtual node
to a distinct actual node which is ``simulating'' it.



Note that, because each actual node simulates at most one
virtual node for each of its deleted neighbors, and virtual nodes have degree at most ,
this ensures that the maximum degree increase of our algorithm
is at most  times the node's degree in .

\section{Half-full Trees}
\label{sec: hafts}

\begin{figure}[h!]
\centering
\subfigure[A haft with 7 leaf nodes.]{ \label{sfig: haftexample} \includegraphics{Haftexample} }
\hspace{0.4in}
\subfigure[A haft of n leaves. Every haft is a union of complete binary trees. In our notation,  is a complete binary tree and  is the number of leaf nodes in . The nodes in the square boxes are the nodes not part of a complete tree.]{ \label{sfig: haft-as-join} \includegraphics{Haft} }
\caption{haft (half-full tree)}
\end{figure}


 This section defines half-full trees (\emph{haft}, for short), and describes some of their interesting properties of concern to us.






\begin{description}
\item[Half-full tree:] A haft is a rooted binary tree in which every non-leaf node 
has the following properties:
\begin{itemize}
 \item  has exactly two children.
 \item The left child of  is the root of a complete binary subtree, containing  half or more of 's  descendants.
\end{itemize}
\end{description}

 An example of a haft is shown in figure \ref{sfig: haftexample}. For any positive , there is a single unique haft over  leaf nodes (see lemma~\ref{lemma: hftproperties}), that we refer to as as 


\begin{lemma}
\label{lemma: hftproperties}
Let  be a positive integer. Then, the following are true:
\begin{enumerate}
\item \label{lmitem: hftprop-unique} There is a single unique  with  leaf nodes, that we refer to as .
\item \label{lmitem: hftprop-bin} binary representation (one-to-one correspondence): 
 Let  be the binary representation of . Let  be the
number of ones  in this representation. Let  be the indices of the one bits, and , sorted in descending order. Let  be the complete
binary tree with  leaves. We can break  into a forest of  complete binary trees () by removing  nodes from . 
\item \label{lmitem: hftprop-depth} The depth of  is .
\end{enumerate}
\end{lemma}
\begin{proof}
We now prove parts~\ref{lmitem: hftprop-unique} and \ref{lmitem: hftprop-bin}. Let  be a haft on  leaves. As a
running example, consider the   shown in Figure~\ref{sfig: haft-as-join}.   Let  be the binary
representation of . Let  be the number of ones  in this representation. Let  be the
indices of the one bits sorted in descending order, and . Let  be the complete
binary tree with  leaves. By definition of a haft, there are two cases:
\begin{enumerate}
\item  \emph{  is a complete tree}: This happens when  and . Clearly,  is unique, corresponding
to the complete tree .
\item \emph{  is not a complete tree}: By definition of , the left child of the root is a complete tree and
moreover this tree has half or more of the children of the root. Let  be the number of nodes in a tree .
Since  we know that . Thus, the
complete tree to the left of the root has to be . \\
 Applying the same definition to the right child of the root, we see that either this node heads the tree , or
its left subtree is . Recursively applying this reasoning,  we see that  is a unique tree with
the trees  to  joined by  single nodes (For example in in Figure~\ref{sfig:
haft-as-join}, these  single nodes are marked as square boxes ). It directly follows  that removing these 
nodes leaves us with a forest of  complete binary trees .
\end{enumerate}



For part \ref{lmitem: hftprop-depth}, there are two possibilities:
 \begin{enumerate}
 \item \emph{ is a complete tree:} For a complete tree with  leaves, we know that the depth of the tree is .
\item \emph{ is not a complete tree:} 
We show this by induction on the number of leaf nodes. Consider a  with  leaf nodes. If , the  is
a complete tree so the height is , which is . For larger , we note that the left child of the root heads
a complete subtree with less than  leaf nodes. Thus, the height of this left subtree is no more than .
Moreover, the right child of the root heads a  over no more than  leaf nodes. Thus, by the
inductive hypothesis, this right subtree has height at most . Thus, the height of
 is , where  is a power of 2 and . Since ,
it follows that . Finally, the height of  is , since .

\end{enumerate}


\end{proof}



\subsection{Operations on Hafts}
We Define the following operations on hafts:
\begin{enumerate}
\item \emph{Strip}: Suppose  is a haft with  ones in its binary representation. The Strip operation removes 
 nodes from  returning  a forest of  complete trees. 

\item \emph{Merge}: The Merge operation joins  hafts together using additional isolated single nodes,
to create a single new haft.
\end{enumerate}

We now describe these operations in more detail:

\subsubsection{Strip}
\label{subsec: haftstrip}
The operation  takes a   and returns a forest  of complete trees.  As follows from part \ref{lmitem: hftprop-bin} of lemma \ref{lemma: hftproperties}, each  can be broken into a forest of  complete trees where  is the number of ones in the binary representation of the number of leaves of . We call the roots of these complete trees primary roots. Before we proceed further, let us formally define this concept:

\begin{description}
\item{Primary root:} A primary root is a node in a  that has the following properties:
\begin{itemize}
\item It is the root of a complete subtree.
\item Its parent, if it has one, is not the root of a complete subtree.
\end{itemize}
\end{description}


The  operation works as follows: 
 If   is a complete tree, then return  itself. Note that the root of the  is the only primary root in this case. If  is not a complete tree, then  is obtained as follows: Starting from the root of , traverse the  direct path towards the rightmost leaf of . Remove a node if it is not a primary root. Stop when a primary root or a leaf node (which is a primary root too) is discovered. In figure \ref{sfig: haft-as-join} the  operation removes the nodes indicated by the square boxes. \\
We now give intuition as to why the Strip operation works.
\begin{lemma}
The Strip operation returns the subtrees rooted at all primary roots in the input .
\end{lemma}
\begin{proof}
By the definitions of   and primary root, if a vertex is not the root of a complete subtree, its left
child is guaranteed to be a primary root. Thus, either the root of the  is a primary root or its left child is. If
the left child is a primary root, there can be no other primary root in the left subtree, so we we return the tree rooted at that
child.  Recursively applying the same test to the right child, we get all the primary roots. 
\end{proof}

\begin{figure}[h!]
\centering
\includegraphics[scale=0.7]{HaftDeleteV2}
\caption{Deletion of a node and its helper nodes lead to breakup of RT into components. The Strip operation or a simple variant (for non-hafts) returns a set of complete trees, which can then be merged.} 
\label{fig: HaftStripMerge}
\end{figure}

\subsubsection{Merge}
\label{subsec: haftmerge}
 Every  can be represented as a binary number (by lemma~\ref{lemma: hftproperties}).  Merging s
is analogous to binary addition of the  binary number representations of these trees. The new binary number obtained is
the representation of the half-full tree corresponding to the merge. This is illustrated in figure~\ref{fig:
haftmergebinary}.\\
 The first step of the  operation is to apply the   operation on the input trees. This gives a forest of
complete trees.  These complete trees can be recombined with the help of extra nodes to obtain a new . 
Let  be the number of nodes in a tree . Consider two complete trees
 and  (Size()), with roots  and  respectively, and an extra node . To merge
these trees, make  the left child and  the right child of  by adding edges between them. The merged
tree is always a .
 Thus, the merge operation  is as follows:\\

\begin{enumerate}
\item Apply  to all the hafts to get a forest of  complete trees.
\item Let  be the  complete trees sorted in ascending order of their
size. Traverse the list from the left, let  and  be the first two adjacent trees of the same size and  be a
single isolated vertex, join  and  by making  the parent of the root of  and the root of
, to give a new tree. Reinsert this tree in the correct place in the sorted list. Continue traversal of the
list from the position of the last merge, joining pairs of trees of equal sizes. At the end of this traversal, we are
left with a sorted list of complete trees, all of different sizes.
\item Let    be the sorted list of complete trees obtained after the previous step. Traverse
the list from left to right, joining adjacent trees using single isolated vertices.  Let  be a single isolated
vertex. Join  and  by making the root of  the left child and the root of  the right child of
, respectively. This gives a new haft. Join this haft and   by using another available isolated
vertex, making the larger tree ()  its left child. Continue this process till there is a single haft.
\end{enumerate}


\begin{figure}[h!]
\centering
\includegraphics[scale=0.7]{HaftMergeBinary}
\caption{Merging three hafts. The square shaped vertices are the isolated vertices used to join complete trees.
Merging is analagous to binary number addition, where the number of leaves are represented as binary numbers.}
\label{fig: haftmergebinary}
\end{figure}
























\subsection{Detailed description} 
As mentioned earlier, deletion of  a node  leads to it being replaced by  a Reconstruction Tree (, for short)
in  (Refer to Table~\ref{algo:model-2} for definitions). The  is a   (discussed in  Section~\ref{sec:
hafts}) having ``virtual'' nodes as internal nodes  and neighbors of  as the leaf nodes. 
The real network is a homomorphic image of  this virtual graph. The nodes in the virtual graph refer to the
corresponding processor in the network, as shown in Figure~\ref{fig: processornodes}.  The nodes in  corresponding to
an edge of  in  and forming the leaf nodes in any  are called real nodes, and those internal to a 
and simulated by the real nodes (more precisely, by the processor) are called helper nodes. There is one real node and
at most one helper node corresponding to an edge of  in  i.e. to an edge formed when  or 's neighbor
joined the network.   In Table~\ref{tab: nodedata} we list the information each processor  requires for each edge in
order to execute the ForgivingGraph algorithm. When one of the nodes of the edge gets deleted, in , that node may be
replaced by a helper node.  This end point of the edge is stored in the field  . For an edge , if  is a real
node then the field  is simply the node . If the node  gets deleted, the new endpoint may be a helper
node, though we  still refer to this edge as  i.e. by its name in . Moreover, the processor may now simulate
a helper node corresponding to this edge. Since each edge is uniquely identified, the real nodes and helper nodes
corresponding to that edge can also be uniquely identified. This identification is used by the processors to pass
messages along the correct paths. The \textsc{Forgiving graph} algorithm is given in pseudocode form in Algorithm~\ref{algo: forgiving}
alongwith the required subroutines. For ease of description, the real and helper nodes belonging to the same processor
may not be explicitly distinguished in the code.

\begin{figure}[h!]
\centering
\includegraphics[scale = 0.9]{processornodes}
\caption{The Nodes corresponding to the processor  in the graph . An ellipse denotes a  created on deletion of a
neighbor of .}
\label{fig: processornodes}
\end{figure}

\begin{table}[h!]
\begin{tabular}{|l|p{4.5in}|}
\hline 
\textbf{Processor v: Edge(v,x)}&\\ \cline{2-2}
\hline 
\textbf{Real node fields}&\\ \cline{2-2}
\hline
\texttt{Endpoint}& The node that represents the other end of the edge. For edge(v,x) this will be node  if  is
alive or  if  is not. \\
\texttt{hashelper}& (boolean field). True if there is a helper node simulated by  corresponding to this edge.\\
  \texttt{RTparent} & Parent of  in . Non NULL only if  has been deleted.\\
   \texttt{Representative}& This is  itself. Field used during merging of s. \\
\hline
\textbf{Helper node fields} & Fields for helper node corresponding to the edge. Non NULL only if the helper node exists.
Sometimes, we will refer to a helper field as \emph{edge.helper.field}\\
\cline{2-2}
\hline
 \texttt{hparent}& Parent of helper node. \\
 \texttt{hrightchild}& Right Child of helper node. \\
 \texttt{hleftchild}& Left Child of helper node. \\
 \texttt{height} &  Height of the helper node.\\
 \texttt{childrencount} & The number of descendants of the helper node.\\
 \texttt{Representative}& The unique leaf node of a subtree of a  that does not have a helper node in that
subtree. This node is used during merging of s.\\
\hline
\end{tabular}
\caption{The fields maintained by a processor  for edge, which is an edge in , the graph of only original nodes and  insertions.}
\label{tab: nodedata}
\end{table}


\begin{figure}[h!]
\centering
\includegraphics[scale=0.35]{AnchorMergeV2}
\caption{On deletion of a node , The RTs to be merged are connected by   which is a binary tree. The RTs merge
from the bottom up with their parents till a single RT is left. The nodes in the square boxes are the primary roots. The (red
color) nodes in the circle are excess nodes removed at each step.}
\label{fig: Anchormerge}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[scale=0.7]{RTMergeOnDeletionV2}
\caption{The underlined node  and corresponding helpers are deleted. This leads to the graph breaking into
components which are then merged using  (the binary tree of anchors) and the primary roots in the components. The dashed edges
show the representative for that node.}
\label{fig: RTmerge}
\end{figure}




On deletion of a node, the repair proceeds in two phases. The first phase is a quick  phase in which the neighbors
of the deleted node connect themselves in the form of a binary tree (Algorithm~\ref{algo: fixnode}). These neighbors represent the
independent components created on deletion of the node. Some of these components may not be hafts. We shall refer to
such a subtrees as a . Let  be the processor deleted. Then, we call this tree formed by the 's
neighbors as  and the nodes forming  as \emph{anchors}. Formally, we define an anchor as follows:
\begin{description}
\item[Anchor]: An anchor is the unique designated node in a  or  that takes part in the binary
tree .
\end{description}
 In phase 2,  the s and s forming  have to be merged (Figure~\ref{fig: Anchormerge}). We are only interested in
the complete trees in these since we can discard all other helper nodes. The anchors send probe messages to discover
the primary roots which head these complete trees (Algorithm~\ref{algoline: findprroots}). This is similar to the Strip
operation described in Section~{\ref{subsec: haftstrip}}. The
nodes maintain information about their height and number of their children in their  or . Thus,
they are able to identify themselves as primary roots. At the same time, the nodes outside the complete trees are
identified and marked for removal. The complete trees are then merged pairwise in a bottomup fashion till only a single
haft remains. This is
illustrated in figure \ref{fig: Anchormerge}. At each round, every leaf  in  will merge with its parent
. This can be done in parallel, so that the  number of rounds of merges will be equivalent to the height of the
tree. For two trees to merge, as shown in the Merge operation (Section~\ref{subsec: haftmerge}), an additional node is
needed that will become the parent of these two trees. This node must be simulated by a real node that is not already
simulating a helper node in the trees. Since the number of internal  nodes in a tree is one less than the leaf nodes,
there is exactly one such leaf node for each tree. The roots of these two trees keep the identity of this node. This is
stored in the field Representative (Table~\ref{tab: nodedata}). More  formally, we define a representative as follows:

\begin{description}
\item[Representative]
Given a node , the representative of  is a real node, decided as follows:
\begin{itemize}
 \item If  is a real node, then  itself.
 \item If  is a helper node, then the unique leaf node of 's subtree in 's  that does not have a helper node in that
subtree. 
\end{itemize}
\end{description}

 We now describe a mechanism for merging that we call the representative mechanism. Each node has a representative defined earlier. When
two trees (Note that a tree may even be a single node) are merged (Algorithm~\ref{algo: makeRT} and Algorithm~\ref{algo:
ComputeHaft} ), the representative of
the root of the bigger tree (or of one of the trees, if they have the same size) instantiates a new helper node, and
makes the two roots its children. The new helper node will now inherit as its representative the representative of the
root of the other tree, since this is the node in the merged tree that does not have a helper node in the tree. An
example of merging using this mechanism is shown in Figure~\ref{fig: RTmerge}.
 At the end of each round, we have a  new set of leaf s. Each new leaf is now a
merged haft of the previous leaves and their parent. We need a new anchor for this haft. We can continue having the
anchor of the parent  or  as the anchor. However, this
 node may be one of the extra nodes marked for removal. In this case, the anchor designates one of the nodes that was
 a primary root in its  as the new anchor, passes on its links and removes itself.
 Now, the newly formed leaf hafts may have primary roots which are different from those of the previous ones. The new
anchor will again send probe messages and gather this information and inform the new primary roots of their role. This
process will continue till we are left with a single . This is shown in Figure~\ref{fig: Anchormerge}. 

\section{Results}
\label{sec: Results}

\subsection{Upper Bounds}
\label{subsec: upperbounds}
Let  be the graph consisting solely of the original nodes and insertions without regard to deletions and
healings. Let  and  be the graphs at time . 

\begin{lemma}
\label{lemma: hnodecounts}
Given the real node  in  corresponding to an edge  in ,
\begin{enumerate}
\item \label{lmpart: onehelper} There can be at most one helper node in  corresponding to .
\item  \label{lmpart: twohelper} During the Repair phase, there can be at most two helper nodes corresponding to the edge . Moreover, one of these could also be an anchor in 
\end{enumerate}
\begin{proof}
 As stated earlier, there is only one real node in  corresponding to an edge in  (Figure~\ref{fig:
processornodes}). Also, any real node can only form a leaf node of a , and a helper node can only be an
internal node. We prove  part~\ref{lmpart: onehelper} by contradiction. Suppose there are two helper nodes in  corresponding to
the real node . Let us call these nodes  and . The following cases arise:
\begin{enumerate}
\item \emph{ and  belong to different s:}\\
 By the representative mechanism, a helper node is created only if the real node that simulates it is the representative
of a node (e.g. in line~\ref{algocode: mergeeqrep} in Algorithm~\ref{algo: ComputeHaft}). By definition, the
representative of a node is a unique leaf node in the subtree headed by that node in its . If both  and 
exist and  belong to different s, this implies that node  exists as a leaf node in two different s. This is
a contradiction.
\item \emph{ and  belong to the same :}\\
 Without loss of generality, assume that the  . The following cases arise:
 \begin{enumerate}
  \item \emph{ is a node in the subtree headed by :}
     Note that by the representative mechanism, in a subtree, an internal helper node will be created earlier than the
root of the subtree. Thus, node  will be created before node .
Let node  be the child of node  that had  when  was created. However, 
    could not have been , since by definition,  has to be the unique leaf 
node not  simulating a helper node in 's subtree, but  is already simulating  in 's subtree.
  \item \emph{ is a node not in the subtree headed by :}
   Again, the representaive mechanism and definition of a representative implies that node  was a
representative in two non-intersecting subtrees in the same . This implies that node  occurs as a leaf
twice in that . This is not possible. 
 \end{enumerate}
\end{enumerate}
 Now, we prove part~ \ref{lmpart: twohelper}. As stated earlier, at each stage of the merge procedure, leaf s or
s in  will merge with their parent. Suppose that  is a helper node simulated by real node ,
and  is not part of any complete subtree in such a  or . This means that  will be marked red
and removed when this stage of merge is completed (Refer Figure~\ref{fig: Anchormerge}). Let node  be the root of the
 complete subtree (i.e. a primary root in that ) that has  as a leaf node. 
Node  is an ancestor of node  since  cannot a descendant. By definition, , since 
will be the unique leaf node in 's subtree not simulating a helper node in that subtree.
 When the trees are being merged,  may be asked to create another helper node. Thus,  may have two helper nodes.
 Also, each  or  has exactly one anchor node. This anchor may be  or another node. Thus, in the
repair phase, a real node may simulate upto two helper nodes, and one of these helper nodes may be an anchor.
 However, node  will be removed as soon as this stage is completed, and if  was an anchor, a new anchor is
chosen from the existing nodes. Since at the end of the merge,   collapses to leave one , the extra helper
nodes and the edges from the anchor nodes are not present in , thus, not contradicting part~\ref{lmpart: onehelper}.

\end{proof}
\end{lemma}

\begin{lemma}
\label{lemma: cost}
After each deletion, the repair can take  time to exchange  messages of size , where  is the degree of the deleted node.
\end{lemma}

\begin{proof} There are mainly two types of messages exchanged by the algorithm. They are the probe messages sent by the
\textsc{FindPrRoots()} (Algorithm~\ref{algo: findprroots}) within a  and the messages containing the information
about the primary roots exchanged by the anchors in  and among the primary roots themselves (Algorithm~\ref{algo:
haftmerge}: \textsc{ComputeHaft()}). Let  be the number of s of . Since a helper
node can split a  into maximum 3 parts, and there can be at most  helper nodes, where  is the degree of the
deleted node , .
Now, let us calculate the number of messages:
\begin{itemize}
\item \emph{Probe messages (Algorithm~\ref{algo: findprroots})}: A probe message is generated by a
 an anchor of a . This is similiar to the \emph{Strip} operation
(Section~\ref{subsec: haftstrip}). The path that the probe message follows is the direct path from the originating
node to the rightmost node of the . At the most 2 messages can be generated for every node on the way. Further,
there can be one confirmatory message transmitted from the primary roots back to the anchor. Let  be 
the number of nodes and  be number of probe messages sent in a single .
Thus, 

\item \emph{Exchange of primary roots lists (Algorithm~\ref{algo: haftmerge})}:  At each step of Algorithm~\ref{algo:
bottomupmerge} (\textsc{BottomupRTMerge()}), leaves in  merge with their parents. Let 
be the number of messages exchanged for every such merge.  The anchors of the leaves of  send their primary
roots lists to the parent, which in turn can send both it's list and the sibling's list to the child.  Thus,
. In addition, every anchor will send this list to the primary roots in its , generating at most
another  messages (Let us call this ).
\end{itemize}
As stated earlier, in the , leaves merge with their parents. The number of such merges
before we are left with a single  is . Also, at most 3 s are involved in
each merge. Let  be the total number of messages exchanged. Hence,


 In , leaves and their parents merge. This can be done in parallel such that each time the level of 
reduces by one. Within each , the time taken for message passing is still bounded by 
assuming constant time to pass a message along an edge. Since there are at most  levels, the time
taken for passing the messages is . The biggest message exchanged may have constant size information
about the primary roots of upto two s. This may be the message sent by a parent  in  to its children
. Since there can be at most  primary roots, the size of messages is .
\end{proof}

Here, we state our main theorem. 
 


\begin{theorem}
 
The Forgiving Graph has the following properties:
\label{theorem: forgiving}
\begin{enumerate}
\item\label{th: degree} 
 \emph{Degree increase:} For any node , , where  is the degree of the node . 
\item\label{th: stretch} 
\emph{Stretch:} For any pair of nodes  and , .
\item \label{th: cost}  \emph{Cost:} After each deletion, the repair can take upto  time with  messages of size upto , where  is the degree of the deleted node.
\end{enumerate}
\end{theorem}

\begin{proof}
 Part~\ref{th: degree} follow directly by construction of our algorithm.  For part~\ref{th: degree}, we note that for a
node , any degree increase for  is imposed by the  edges of its helper node to () and . From lemma~\ref{lemma: hnodecounts} part~\ref{lmpart:
onehelper}, we know that, in , node  can play the role of at most one helper node for any of its neighbors in
 at  any time (i.e.  ).
The number of  of a helper node are never more than , because the reconstruction trees are binary trees. 
Thus the total degree of  ( ) is at most  times its degree in  (). 



We next show Part~\ref{th: stretch}, that the stretch of the Forgiving Graph is  , where  is the number
of nodes in . The distance between any two nodes  and  cannot increase by more than the factor of the
longest path in the largest  on the path between  and . This factor is  at the maximum.

 Part~\ref{th: cost} follows from Lemma~\ref{lemma: cost}. Note that besides the commuication of the messsages
discussed, the other operations can be done in constant time in our algorithm.
 
\end{proof}

\pagebreak

\subsection{Lower Bounds}

\label{subsec: lowerbounds}

\begin{theorem}
Consider any self-healing algorithm that ensures that: 1) each node increases its degree by a multiplicative factor of 
at most , where ; and 2) the stretch of the graph
increases by a multiplicative factor of at most . Then, for some initial graph with  nodes, it must be the case that
 .
\end{theorem}

\begin{proof}
Let  be a star on  vertices, where  is the root node, and  has an edge with each of the
other nodes in the graph. The other nodes (besides ) have a degree of only 1. Let  be the graph created after the
adversary deletes the node .  Consider a breadth
first search tree, , rooted at some arbitrary node  in .  We know that the self-healing algorithm can increase
the degree of each node by at most a factor of , thus every node in  besides  can have at most 
children. 
Let  be the height of .  Then we know that .  This implies that   for , or .  Let  be a leaf node in  of largest depth. Then, the distance between  and  in  is  and the distance 
between  and  in  is 2. Thus, , and  , or . 
\end{proof}
\noindent
We note that this lower-bound compares favorably with the general
result achieved with our data structure.  


\section{Conclusion}
We have presented a distributed data structure that withstands
repeated adversarial node deletions by adding a small number of new
edges after each deletion.  Our data structure is efficient and ensures two key
properties, even in the face of both adversarial deletions and adversarial insertions.
First, the distance between any pair of nodes never increases by more than a  multiplicative factor than what the distance would be without the adversarial deletions.  Second, the degree of any node never increases by more than a  multiplicative factor.

Several open problems remain including the following. Can we design algorithms
for less flexible networks such as sensor networks?  For example, what
if the only edges we can add are those that span a small distance in
the original network?  Can we extend the concept of
self-healing to other objects besides graphs?  For example, can we
design algorithms to rewire a circuit so that it maintains its
functionality even when multiple gates fail?

\pagebreak
\newpage
\bibliography{selfheal} 
\bibliographystyle{plain}

\pagebreak
\appendix

\section{ForgivingGraph PseudoCode}

\floatname{algorithm}{Algorithm}
\begin{algorithm}[h!]
\begin{algorithmic}[1]
\STATE Given a Graph 
\REQUIRE{each node of G has a unique ID}
\FOR{each node  } 
\STATE \textsc{Init(v)}.
\ENDFOR
\WHILE {true}
\IF{a vertex  is inserted}
\STATE vertex  and new neighbors add appropriate edges.
\STATE \textsc{Init(v)}.
\ELSIF{a vertex  is deleted}
\STATE \textsc{DeleteFix(v)}
\ENDIF
\ENDWHILE
\end{algorithmic}
\caption{\textsc{Forgiving graph}: The main function.}
\label{algo: forgiving}
\end{algorithm}



 \begin{algorithm}[h!]
 \caption{\textsc{Init(v)}: initialization of the node } 
\label{algo: init}
\begin{algorithmic}[1]
\FOR{each }
\STATE 
\STATE set other fields to NULL.
\ENDFOR
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[h!]
\caption{\textsc{DeleteFix()}: Self-healing on deletion of a node }
\label{algo: fixnode}
\begin{algorithmic}[1]
\STATE 
\FOR{each }
\IF{}
\STATE 
\ENDIF
\STATE 
\ENDFOR
\STATE \label{algoline: BTquickfix} The nodes in  make new edges to make a balanced binary tree .
\STATE \textsc{BottomupRTMerge()}
\STATE delete the edges .
\end{algorithmic}
\end{algorithm}




\begin{algorithm}[ph!]
\caption{\textsc{BottomupRTMerge()}: The nodes of  merge  their s starting from the leaves going
up forming a new . }
\label{algo: bottomupmerge}
\begin{algorithmic}[1]
\IF{ has only one node}
\STATE return
\ENDIF
\FOR{}\label{algoline: findprroots}
 \IF{ is a real node}
 \STATE Let 
 \ELSIF{}
 \STATE \textsc{FindPrRoots( )}
 \ELSIF { OR  OR }
  \STATE Let  \textsc{FindPrRoots()}
  \ELSE
  \STATE  Let  \textsc{FindPrRoots()}
  \ENDIF
\ENDFOR
\FOR{all nodes  s.t. node  is a parent of a leaf in }
\IF{ has two children in }
\STATE \textsc{Haft\_Merge}(,  's left child in ,  's right child in )
\ELSE
\STATE \textsc{Haft\_Merge}(, 's left child, NULL)
\ENDIF
\ENDFOR
\STATE \textsc{BottomupRTMerge()} \COMMENT{The new leaf nodes merge again till only one is left.}
\end{algorithmic}
\end{algorithm}




\begin{algorithm}[ph!]
\caption{\textsc{FindPrRoots}(, numchild, sender, Breakflag): Find the primary roots in the  beginning
with node . If Breakflag is set the tree is  a component of the  formed due to the deletion.}
\label{algo: findprroots}
\begin{algorithmic}[1]
\IF{Breakflag =  AND (sender =  OR sender =  )}
  \STATE  - numchild
\ENDIF
\IF{} \IF {\textsc{TestPrimaryRoot()} = } 
  \STATE return \{,\textsc{FindPrRoots(, Breakflag)} \}
\ELSE
  \STATE return \{\textsc{FindPrRoots(, Breakflag)} \} \COMMENT{Node itself not a primary
root but parent maybe.}
  \ENDIF
\ELSE
\STATE mark node red
  \IF{exists() AND sender != }
   \STATE \textsc{FindPrRoots(, Breakflag)}
   \ELSIF{exists() AND sender != }
   \STATE \textsc{FindPrRoots(, Breakflag)}
   \ELSIF{exists() AND sender != }
   \STATE \textsc{FindPrRoots(, Breakflag)}
\ENDIF
\ENDIF
\end{algorithmic}
\end{algorithm}



\begin{algorithm}[ph!]
\caption{\textsc{TestPrimaryRoot()}: Tell if helper node  is a primary root in  }
\label{algo: testprimaryroot}
\begin{algorithmic}[1]
\IF{} \IF{}
\STATE return 
\ELSIF{}
\STATE return 
 \ENDIF
 \ENDIF
\STATE return  
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[ph!]
\caption{\textsc{Haft\_Merge()}: Merge the hafts mediated by anchors  and }
\label{algo: haftmerge}
\begin{algorithmic}[1]
\STATE Nodes  and  exchange 
\STATE Let  \textsc{MakeRT()}
\IF{ is marked red} \STATE  transfers its edges in  to one of  \COMMENT{ needs to be removed,  needs
to be maintained}
  \ENDIF
 \STATE Remove all helper nodes marked red \COMMENT{Some helper nodes marked red may have been reused and unmarked by
\textsc{MakeRT}}
\end{algorithmic}
\end{algorithm}


\begin{algorithm}[ph!]
\caption{\textsc{MakeRT}(PRoots1, PRoots2, PRoots3): The sets of Primary roots make a new RT }
\label{algo: makeRT}
\begin{algorithmic}[1]
\FOR{all  }
  \STATE Let  \textsc{ComputeHaft}(PRoots1, PRoots2, PRoots3)
  \STATE Make helper nodes and set fields and make edges according to  
 \ENDFOR
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[ph!]
\caption{\textsc{ComputeHaft(}: (Implementation of Haft Merge) The primary roots
compute the new haft}
\label{algo: ComputeHaft}
\begin{algorithmic}[1]
\STATE Let 
\STATE Let  sorted in ascending order of number of children, NodeID
\STATE Suppose  is  where the  are the  ordered primary roots.
\STATE set 
\WHILE{}
  \IF{ }
  \STATE \label{algocode: mergeeqrep} Make helper node . Initialise all its fields
to NULL.
  \STATE Make   the parent of  and 
  \IF{ is a real node}
   \STATE  Set  
   \ELSE
    \STATE Set  
  \ENDIF
  \STATE Set  
  \STATE remove  and insert   in the correct position in .
  \STATE set , 
  \ENDIF
  \STATE set  ,
\ENDWHILE
\STATE set 
\WHILE{}
\STATE \label{algocode: mergeneqrep} Make helper node . Initialise all its fields to
NULL
\STATE Set  
\STATE Set  
\STATE Set  
\STATE Set  
\STATE In , replace  by   
\ENDWHILE
\end{algorithmic}
\end{algorithm}


\end{document}
