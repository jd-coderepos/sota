\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{array}
\usepackage{comment}
\usepackage{subcaption}
\usepackage{capt-of}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{soul}


\pagestyle{plain}
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\cvprfinalcopy 

\begin{document}

\title{Hierarchical Attention-based Age Estimation and Bias Estimation}

\author{
 Shakediel Hiba \qquad Yosi Keller \\
 Bar-Ilan University
}

\twocolumn[{
\renewcommand\twocolumn[1][]{#1}
\vspace{-1em}
\maketitle
\vspace{-1em}
\begin{center}
    \centering
    \vspace{-0.3in}
    \includegraphics[width=\linewidth]{drawings/overview_crop.pdf}
 \captionof{figure}{Model overview. We create K different augmentations from a single
input image, embed each of them via a CNN backbone, and feed the resulting
sequence to a Transformer encoder. The resulting feature
vector is fed into our hierarchical regression, consisting of a classification and a local regression
branches.}
    \label{fig:teaser}
\end{center}}]





\begin{abstract}
In this work we propose a novel deep-learning approach for age estimation
based on face images. We first introduce a dual image
augmentation-aggregation approach based on attention. This allows the
network to jointly utilize multiple face image augmentations whose
embeddings are aggregated by a Transformer-Encoder. The resulting aggregated
embedding is shown to better encode the face image attributes. We then
propose a probabilistic hierarchical regression framework that combines a
discrete probabilistic estimate of age labels, with a corresponding ensemble
of regressors. Each regressor is particularly adapted and trained to refine
the probabilistic estimate over a range of ages. Our scheme is shown to
outperform contemporary schemes and provide a new state-of-the-art age
estimation accuracy, when applied to the MORPH II dataset for age
estimation. Last, we introduce a bias analysis of state-of-the-art age estimation results.
\end{abstract}

\section{Introduction}
\label{sec:introduction}
Age estimation based on facial images is a common task conducted by human
observers on a daily basis. It has been long researched in the computer
vision and biometrics comminutes, as accurate age estimation relates to a
broad span of applications, such as e-commerce \cite{Hakeem2012VideoAF},
age-based face recognition and retrieval \cite{Lanitis2004ComparingDC}, to
name a few. Accurate age estimation entails multiple computational
challenges, uncommon to face detection or recognition. First, the face
appearance variations due to aging are unknown, complex and may be affected
by multiple intrinsic and extrinsic factors, such as ethnicity, gender, and
lifestyle. Second, the appearance aging process changes gradually making the
appearance of nearby ages similar, but notable age differences result in
significant appearance changes. Lastly, available datasets are mostly small,
and highly imbalanced with respect to age and gender. Face-based age estimation is commonly formulated as either a classification
problem, where an age  corresponding to the face  is
classified as either one of  discrete values \cite {eidinger2014age,guo2011simultaneous,chang2011ordinal,ZhengSun2012,ramon2012gender,guo2010human}, or as a scalar regression of , given a high-dimensional embedding of the face  \cite {guo2011simultaneous,guo2010human,eidinger2014age,wang2015age,ChenGong2013,leviage,yi2015age}. The common approach to face-based biometric analysis is to first align the
face image to a canonical spatial frame \cite{RetinaFace}, and analyze the
cropped region of interest. Early approaches utilized local image
descriptors \cite{ramon2012gender} to encode the face images in
high-dimensional representations used for regression by Kernel PLS \cite {guo2011simultaneous}.
The successful use of Deep Learning-based approaches in a gamut of computer
vision tasks, paved the way for deriving end-to-end trainable age estimation
schemes \cite{8017500,deepage} using either classification or regression
losses. Metric learning was used in both shallow \cite{1640964} and
CNN-based \cite{8017500} schemes, where local features were learned using
their age difference as a metric measure. Ranking-based approaches \cite {8099569,7780901, 9145576, Dark_Knowledge} apply ordinal classification to
utilize the ordinal structure of the age labels to improve accuracy.

In this work, we present a CNN-based architecture for facial image-based age
estimation, that is depicted in Fig. \ref{fig:teaser}. First, we introduce
a novel attention-based image embedding based on joint augmentation and
task-specific embedding aggregation implemented by a Transformer Encoder
\cite{AttentionIsAllYouNeed}. Our approach is inspired by Encoder-based
semantic analysis schemes \cite{bert}, where a sequence of word embeddings
is aggregated in a \textit{single} embedding vector by a Transformer
Encoder. Similarly, in the first phase (and contribution) of our approach,
we improve the CNN-based face embedding by augmenting the input image
multiple times in \textit{each} CNN pass and fusing the different embeddings
using a Transformer Encoder. The focal point is to learn an attention-based
aggregated image embedding, that is invariant to appearance and geometrical
variations, in \textit{each} training iteration. In contrast to common
approaches, that encode a \textit{single} augmentation per image, and
aggregate the appearance invariance over \textit{multiple} training epochs.
Second, we introduce a hierarchical probabilistic regression scheme that
jointly learns age classification and regression models. In that, we utilize
the robustness of classification-based age estimation, with the accuracy of
age regressors ensembles, each related to a limited age estimation domain.
We also present a bias analysis of the proposed age estimation scheme, with
respect to ethnicity and gender. This is a fundamental issue in biometrics
in this day and age that was mainly studied in the context of face
recognition \cite{9209125,Gebru,9086771}. To the best of our knowledge, ours
is the first bias analysis in face-based age estimation using a scheme
achieving state-of-the-art (SOTA) accuracy.

In particular, we propose the following contributions:

\begin{itemize}
\item We propose a novel joint augmentation and embedding aggregation
architecture to improve image embedding.

\item We derive a probabilistic hierarchical age estimation scheme where, a
probabilistic age estimate allows to optimally weigh the results of an
ensemble of local age regressors.

\item Both the proposed novel feature extraction and regression framework
are of general applicability, and can be applied, together, or separately to
any high-dimensional regression problem.

\item The proposed scheme is shown to achieve new SOTA accuracy when applied
to contemporary age estimation datasets MORPH II \cite{1613043}.

\item The proposed scheme is analyzed for bias with respect to gender and
ethnicity.
\end{itemize}

\section{Related Work}

\label{sec:Related Work}

Face-based age estimation is easily handled by human observers on a daily
basis, despite the inherent difficulties induced by the varying facial aging
characteristics, and variations across ethnicities, gender and lifestyles.
The significance of ethnicity and gender in face analysis and recognition
was exemplified in the seminal work of Buolamwini and Gebru \cite{Gebru} and
is of particular interest. Guo and Mu \cite{guo2010human} proposed a
two-step procedure where gender and ethnicity are first classified, and the
age is separately estimated for each gender and ethnicity group. Shallow
approaches utilized face embeddings based on local image features, followed
by statistical inference. Thus, Balmaseda \emph{et al}. \cite {ramon2012gender} used Local Binary Pattern (LBP) features and SVM\
classifiers to compute multiscale normalized face images, alongside their
local context. Ranking was used by Zheng and Sun \cite{ZhengSun2012} using a
Ranking SVM, where the age is estimated by first learning ranking
relationships, that were used alongside the reference set to estimate the
age. Eidinger \emph{et al}. \cite{eidinger2014age} proposed a gender and age
classification scheme for non-frontal face images acquired under
uncontrolled conditions. Regression-based approaches formulate the age
estimation problem as a scalar regression given a high-dimensional image
embedding. Chen and Gong \cite{ChenGong2013} introduced a cumulative
attribute for learning a regression model when only sparse and imbalanced
data are available to estimate age and crowd density. Low-level visual
features extracted from sparse and imbalanced image samples are mapped onto
a cumulative attribute space where each dimension is related to a semantic
interpretation.

CNN-based schemes forgo the use of handcrafted image descriptors, in favor
of learnt image embeddings. Thus, Wang and Kambhamettu \cite{wang2015age}
proposed a hierarchical unsupervised neural network architecture to learn
low-level translation-invariant features, used as inputs to a set of
Recursive Neural Networks (RNNs). Manifold learning was applied to capture
the underlying face aging manifold by projecting the feature vector into a
low-dimensional, better discriminative subspace. Hassner and Levi \cite {leviage}, and Yi \emph{et al}. \cite{yi2015age} reported significant
accuracy improvements by formulating the age estimation as a classification
problem, and applying CNNs. Deep metric learning was applied by Sendik et
al. \cite{deepage} to face features computed by a CNN, while a Support
Vector Regressor (SVR) was applied to estimate the age. Deep metric learning
was also used by Liu et al. \cite{8017500}, who proposed a hard quadruplet
mining scheme to improve the resulting embedding, while a regression-based
loss was applied to estimate the age. Rothe et al. \cite{7406390} derived a
classification scheme where the class probability distribution of the
Softmax function was used to compute the empirical expectancy of estimated
age. Pan et al. \cite{Mean-Variance} proposed a multi-task approach, by
first computing the empirical estimation probability of each age using the
Softmax activation function. The  loss, as well as the empirical
variance of the age estimation error were minimized. Malli at al. \cite {Malli_2016} suggested an ensemble of CNN-based classification models, where
each ensemble model was trained to classify within a different age domain.
The final inference was computed by averaging over the models' outputs.
Tree-based approaches were also proposed \cite{8954134, 8578343}. A hybrid
deep Regression Forests approach by Shen et al. \cite{8578343} utilizes both
Regression Forests and deep learning inference. The forest nodes learn
input-adaptive data partitions, and are connected to fully connected CNN\
layers. The Random Forests and CNN were jointly optimized in an end-to-end
approach. Li et al. \cite{8954134} used a tree-based structure where
adjacent tree leaves in nearby branches were jointly connected to create a
continuous transition, as well as an ensemble of local regressors. Each leaf
is connected to a particular local regressor. The ordinality of the
estimated ages was utilized by encoding the age labels is an
ordinality-preserving representation \cite{8099569, 7780901, 9145576, coral}, where each model output determines whether an estimated age is higher than
a given threshold. Such approaches were shown to improve the age
classification accuracy.

\subsection{Attention and Transformers}

The Attention mechanism \cite{DBLP:journals/corr/BahdanauCB14} is a class of
contemporary neural network layers that aggregate the information within
input sequences. The inputs are aggregated by computing aggregation
(attention) weights using the inner products between the input sequences.
Attention layers are often stacked to improve the inference capacity, and
were applied in both sequence-to-sequence (NLP\ translation) and
sequence-to-one (sentiment analysis) problems. In self-attention, the
attention weights are computed with respect to a \textit{single} input
series, and the module is denoted as an \textit{Encoder}. By computing the
inner products between the (single) input sequence and itself, the encoder
maps the input sequence into a higher dimensional space. The inputs to a
\textit{Decoder }are Key and Query sequences used to compute the attention
weights, to aggregate the Value sequence. Attention models allow to
computationally emphasize the contribution of the task-informative image
cues, in contrast to the visual clutter present in most images. Transformers
were introduced by Vaswani et al. \cite{AttentionIsAllYouNeed} as a novel
formulation of attention-based stacked layers, allowing encoding sequences
without RNN layers such as LSTM and GRU. Transformers-based Encoders and
Decoders utilize multiple stacked Multi-Head Attention (MHA) and Feed
Forward layers. In contrast to the sequentially-structured RNNs, the
relative position and sequential order of the sequence elements are induced
by positional encodings, that are added to the Attention embeddings.
Transformers were shown to provide a computationally efficient framework for
most NLP tasks \cite{bert}, achieving SOTA performance, and were also
applied in a gamut of computer vision tasks \cite{DETR,16x16}. In this work
we were inspired by recent attention-based single sentence classification
tasks in NLP \cite{bert}, such as sentiment analysis. The gist of such
approaches is to aggregate and encode an ordered sequence of word embeddings
in a \textit{single} embedding used for inference. Multiple such NLP tasks
\cite{bert} use the same sequence (sentence) Transformer Encoder-based
aggregation, and differ on the particular dataset and training loss per
task. In our approach the sequence of augmented image embeddings is
unordered. Thus, there is no need for positional encoding.

\subsection{Bias Analysis}

\label{subsec:Related bias}

The significant accuracy improvement of face-based biometrics, such as face
recognition, gender and ethnicity identification and age estimation, has
resulted in a proliferation in their deployment in a gamut of applications.
In particular, face-based biometrics were deployed by law-enforcement
agencies and commercial vendors. In their seminal work, Buolamwini and Gebru
\cite{Gebru} showed the inherent bias of contemporary SOTA face recognition
systems with respect to gender and ethnicity. Similarly, Wang et al. \cite {9010843} studied the ethnicity bias for multiple SOTA commercial and
academic face recognition schemes. For that they proposed the Racial Faces
in-the-Wild (RFW) database for which the ethnicity of each subject was
thoroughly validated. They also propose a domain adaptation scheme, shown to
reduce the ethnical bias in face recognition. The accuracy bias of face
recognition due to ethnicity or skin tone was also studied by Krishnapriya
at al. \cite{9001031} who showed that for a fixed decision threshold,
Caucasian face images have a higher false non-matching rate, while the face
image of African-Americans are characterized by a higher false matching
rate. In particular, one-to-many identification might have a low
false-negative identification rate, while having significant false-positive
identification rates. A thorough survey of recent results in biometrics
algorithmic bias\ was presented\ by Drozdowski at al. \cite{9086771}.

The bias in face-based age estimation was first studied by Puc et al. \cite {9287219}, who showed that age estimation accuracy is consistently higher
for men than for women, while ethnicity does not seem to have a significant
or consistent effects. Unfortunately, their analysis was conducted using
non-SOTA approaches, such that MAE 7, compared to MAE
2.5 in contemporary schemes. Also, their analysis was not applied to
contemporary age estimation datasets such as the MORPH Album II \cite {1613043}. Hence, to the best of our knowledge, our work is the first to
report SOTA age estimation results with bias analysis.

\section{Hierarchical attention-based age estimation}

\label{sec:Proposed Method}

In this work we propose a deep-learning-based scheme to estimate a subject's
age  given the face image . An overview of the
proposed scheme is shown in Fig. \ref{fig:teaser}. It consists of two main
building blocks: the first is a novel image embedding architecture based on
a self-attention Transformer Encoder. The second is a hierarchical
regression framework. In the image embedding phase, detailed in Section \ref {subsec:self-atten}, given an input image , we create 
corresponding augmentations , and
compute their corresponding embeddings  using a backbone CNN. The embeddings  are aggregated by a self-attention Transformer
Encoder yielding a fused embedding vector . \
The fused embedding is processed by a hierarchical regression that jointly
utilizes a probabilistic age classifier, and a corresponding ensemble of age
regressors, such that the regressors' output is adaptively weighted by the
classification probabilities, as detailed in Section \ref{subsec:regression}.

\subsection{Self Attention-based Image Embedding}

\label{subsec:self-atten}
\begin{figure}[tbp]
\begin{center}
\centering\includegraphics[width=\columnwidth,height=0.8\columnwidth]{drawings/encoder_crop.pdf}
\end{center}
\caption{The proposed augmentation self-attention-based image embedding. We
create  augmentations  of the
input image , and compute their embeddings  using a backbone CNN. The embeddings are
aggregated by a Transformer Encoder, where the output is given by the
\textit{cls token}.}
\label{fig:encoder}
\end{figure}

We propose a novel augmentation and attention-based image embedding to
compute an image embedding that is robust to appearance variations, as shown
in Fig. \ref{fig:encoder}. For that, each input image  is
augmented  times to create the set of augmented images . The image augmentations that are used, follow previous
works and are detailed in Section \ref{subsec:Implementation Details}. We
also experimented in learning the augmentations using RandAugment \cite {Randaugment}, but this did not improve the accuracy. Each of these image
augmentation  is embedded by a CNN backbone. Any CNN can be used, and we
evaluated multiple backbones, as detailed in Section \ref{sec:Experiments},
to compare against contemporary schemes in which they were used. The set of
embeddings  is aggregated into a single embedding vector  using a Transformer Encoder. As the sequence of augmentations
embeddings are unordered, there is no need for positional encoding, and the
encoding is derived by adding a fully-learnt \textit{class token}  to the encoded series. The aggregated representation  is the Transformer Encoder's output corresponding to the
cls token, as in Fig. \ref{fig:encoder}. The proposed aggregation scheme is
of general applicability and can be applied to any task where the input can
be is augmented.

\subsection{Hierarchical probabilistic age regression}

\label{subsec:regression}
\begin{figure*}[tb]
\begin{center}
\centering\includegraphics[width=0.9\textwidth]{drawings/hierarichal_crop.pdf}
\end{center}
\caption{The proposed hierarchical regression framework. The input feature
vector  is jointly processed by two parallel branches: the upper is
the classifier, while the lower is the regression ensemble . The age estimate
 is given by the empirical expectancy of }
\label{fig:hierarichal}
\end{figure*}

The inference phase in deep learning-based age estimation schemes is based
on either\ classification \cite{leviage,yi2015age} or regression \cite {8099569, 7780901, 9145576, coral}. Classification-based schemes aim to
classify a face image to one of  ages. The
accuracy of regression schemes can be improved by using an ensemble of
regressors  \cite{8954134, 8578343}, where each regressor  estimates the residual regression with respect
to the discrete label  such that the estimated age  is
given by

We propose to jointly utilize the upside of both classification and
regression approaches using the framework shown in Fig. \ref{fig:hierarichal}. We simultaneously apply both an age classifier over a set of ages , \ and an ensemble of residual regressors  as in Eq. \ref {equ:residual}. The classifier robustly estimates the age \textit{probabilities}  that are used to estimate the age
as the expectancy


The classifier is optimized by a multiple losses: the first is the Cross
Entropy loss , and the second is the Mean-Variance Loss \cite {Mean-Variance} consisting of two termsandwhere  is the number of points in a batch. Equation \ref{equ:mean loss}
minimizes the mean square error (MSE) between the empirical expectancy and
the ground truth , while Equ. \ref{equ:var loss} minimizes the
empirical variance of the estimate.

The regression ensemble  is optimizes by a corresponding set of  losses . The overall loss is that given bywhere  are predefined weights
discussed in Section \ref{subsec:Implementation Details}.

Our approach implicitly assumes that the facial aging process is episodic,
implying that although aging is a continuous process, faces related to
nearby ages are more related than far away ones, and that the aging process
differs notably at different life episodes. Thus, each age episode is
locally analyzed by a particular regressor . Even though the aging process is episodic it is still continuous,
and restricting each local regressor  might cause significant marginal effects. The formulation in Eq. \ref{equ:expactancy} allows the classifier and the regressors ensemble  to
communicate via their joint optimization and the end-to-end training.

\section{Experimental Results}

\label{sec:Experiments}

The proposed scheme was experimentally evaluated by applying it to the
contemporary face image datasets detailed in Section \ref{subsec:dataset},
and comparing to the results of state-of-the-art (SOTA) approaches in
Section \ref{subsec:morph AFAD}. The implementation details and evaluation
metrics are reported in Section \ref{subsec:Implementation Details}, and an
ablation study that reviews different variations of our scheme is given in
Section \ref{subsec:Ablation study}. The bias analysis is reported in
Section \ref{subsec:bias}.

\subsection{Datasets}

\label{subsec:dataset}

MORPH Album II \cite{1613043} is one of the largest longitudinal face
databases available. It contains about 55k facial images of 13.5k subjects
whose ages range from 16 to 77, such that each subject is depicted in
multiple images. The identity of the subject in each image is known. All
images are mugshots taken in a controlled environment of good image quality,
centered faces poses and neutral face expressions. The dataset depicts both
genders, and multiple ethnic groups, mostly white and black. Its demographic
and gender breakdown is reported in Table \ref{table:demographic_comparison}.

We follow two evaluation protocols used in previous works to define the
training and testing sets, The first, is the Random-Split (RS) protocol, in
which the face images are randomly split to train and test, such that the
images of the \textit{same} person of the \textit{same} age, might appear in
both train and test sets. This creates a leakage between the train and test
sets, as it essentially mixes age estimation with age recognition. Thus, a
face recognition scheme, with no age estimation training, can achieve
perfect age estimation accuracy. The Second protocol is the
Subject-Exclusive (SE) protocol, where identities are randomly split to be
either train or test, but not both, to avoid leakage. Due to the leakage,
the RS accuracy is significantly higher than the SE scores for \textit{all}
schemes and datasets. Hence, we submit that the RS metric should be
considered less reliable and avoided in future works when possible. In this
work we report RS results due to legacy results we have to compare with. The
MORPH II can be used to evaluate the age estimation accuracy using both
protocols. We avoided using the AFAD dataset \cite{7780901}, where the identities of the
subjects are unknown, implying that only the RS protocol can be applied. Similarly, the FG-NET dataset \cite{cootes2008fg}
consisting of only 1,002 images of 82 subjects, which is too small for our Transformer-driven approach.
\begin{table}[tbh]
\begin{center}
\centering \begin{tabular}{l|l|l|l|l|l}
\hline
& \textbf{Black} & \textbf{White} & \textbf{Asian} & \textbf{Hispanic} &
\textbf{Other} \\ \hline\hline
\textbf{M} & 36,832 & 7,961 & 141 & 1,667 & 44 \\
\textbf{F} & 5,757 & 2,598 & 13 & 102 & 19 \\
\textbf{T} & 42,589 & 10,559 & 154 & 1,769 & 63 \\ \hline
\end{tabular}\end{center}
\caption{The demographic breakdown of the Morph II dataset \protect\cite {1613043}.}
\label{table:demographic_comparison}
\end{table}

\subsection{Implementation Details}

\label{subsec:Implementation Details}

The age estimation accuracy is evaluated by the standard Mean Absolute Error
(MAE) that was used in all previous works. The MAE is calculated using the
mean absolute error between the predicted age  and the
ground truth where  is the number of test images. The lower the MAE the better the
accuracy. We used the Vgg-16 \cite{vgg} and ResNet-34 \cite{7780459} CNN
backbones that were used in previous SOTA\ age estimation schemes, such that
the comparison could be based only on the proposed architecture rather than
the backbone. Each backbone was first trained for recognition over the
training set using the Arcface loss \cite{8953658}. The input face images
were first detected, cropped and aligned by the RetinaFace detector \cite {RetinaFace} and then resized to a size of 224224. The proposed
attention-based aggregation was implemented using a Transformer-Encoder with
four blocks, a dropout of  = 0.1, where each block contains an MHA layer
with four heads. Each input image was augmented to \thinspace images, such that multiple augmentations were randomly applied with a
probability of 0.5: horizontal flips, color jittering, random affine
transformation and randomly erasing small parts of the image, adapted from
\cite{8954382}. We also applied the RandAugment \cite{Randaugment} approach,
but achieved no accuracy improvement. The classifier in Section \ref {subsec:regression} and the corresponding ensemble of classifiers  were applied with
. We used the
Ranger optimizer, a combination of Rectified Adam \cite{Liu2020OnTV} with
the Lookahead technique \cite{Lookahead}, and a Cosine Annealing learning
rate decay \cite{SGDR}. All experiments are conducted using a single NVIDIA
GTX 1080 TI, and the PyTorch framework. The loss hyper-parameters  in Equ. \ref{eq:totatl_loss_term} are set to: {0.2, 0.05, 1, 1}
accordingly, where the parameters 
were taken from \cite{Mean-Variance}, and = is in
accordance with .

\subsection{MORPH II results}

\label{subsec:morph AFAD}

We compare our approach with multiple SOTA methods using the MORPH II
dataset, and the results are reported in Table \ref{table:Morph-II},
respectively. The results of previous schemes are quoted from their
respective publications that used the same protocol specifications as our.
Following previous works, we randomly split the datasets to 80\% train and
20\% test in both the RS and SE\ protocols. Table \ref{table:Morph-II} shows
that our approach outperforms all previous methods on the MORPH II dataset
using both the RS and SE protocols. The RS accuracy (MAE = 1.13) is
significantly higher than the SE accuracy (MAE = 2.53). We attribute that,
as mentioned before, to the leakage in the RS protocol, making the RS
results less indicative.
\begin{table}[th]
\begin{center}
\centering \begin{tabular}{l|l|l|l}
\hline
Method & Backbone & MAE & Protocol \\ \hline\hline
Oh-rank\cite{chang2011ordinal} & AAM & 6.07 & RS \\
Ranking-CNN\cite{8099569} & ALEXNET & 2.96 & RS \\
OR-CNN\cite{7780901} & proprietary & 3.27 & RS \\
M-lsdml\cite{8017500} & RESNET101 & 2.89 & RS \\
Coral\cite{coral} & RESNET34 & 2.64 & RS \\
Dex\cite{7406390} & VGG16 & 3.25 & RS \\
Dex(pretrained)\cite{7406390} & VGG16 & 2.68 & RS \\
M-lsdml\cite{8017500} & VGG16 & 2.91 & RS \\
Mean-Variance\cite{Mean-Variance} & VGG16 & 2.16 & RS \\
BridgeNet\cite{8954134} & VGG16 & 2.63 & RS \\
Knowledge Distil\cite{Dark_Knowledge} & proprietary & 1.95 & RS \\
\textbf{ours} & VGG16 & \textbf{1.13} & RS \\ \hline
Coral\cite{coral} & RESNET34 & 3.27 & SE \\
Mean-Variance\cite{Mean-Variance} & VGG16 & 2.79 & SE \\
soft-ranking\cite{9145576} & RESNET34 & 2.83 & SE \\
soft-ranking\cite{9145576} & VGG16 & 2.71 & SE \\
\textbf{ours} & VGG16 & \textbf{2.53} & SE \\ \hline
\end{tabular}\end{center}
\caption{Age estimation results evaluated using the Morph-II dataset \protect
\ref{table:Morph-II}. We compare with previous SOTA schemes using both the
RS and SE protocols. CNN no-atten relates to applying the proposed scheme
without the attention-based embedding aggregation introduced in Section
\protect\ref{subsec:self-atten}.}
\label{table:Morph-II}
\end{table}
The distribution of the age estimation errors shown in Fig. \ref {fig:estimation_error} resembles a Gaussian distribution around zero, where
most estimation errors () are within an interval of three
years.
\begin{figure}[tbp]
\centering\includegraphics[width=0.9\columnwidth,height=0.63\columnwidth]{figures/estimation_error_not_abs.pdf}
\caption{The distribution of the age estimation errors. The proposed scheme
was applied to the Morph II dataset.}
\label{fig:estimation_error}
\end{figure}
In particular, our hierarchical probabilistic approach outperforms Li et al.
\cite{8954134}, that also divide the age axis into multiple overlapping
sub-domains and employ local regressors over those sub-domains, while using
the same backbone as ours. We also outperform the Mean-Variance approach
\cite{Mean-Variance} that employs the same backbone and losses.
\subsection{Ablation study}

\label{subsec:Ablation study}

In order to evaluate the contribution of each of the proposed algorithmic
components, we conducted multiple ablation studies. In each ablation
experiment we modified a \textit{single} algorithmic component or
hyper-parameter to evaluate it, and applied the resulting implementation to
the MORPH II\ dataset that allows to apply both the RS and SE\ protocols.
The baseline scheme is the one in Table \ref{table:Morph-II}.
\begin{table}[tbh]
\begin{center}
\centering \begin{tabular}{l|l}
\hline
\# Augs & MAE \\ \hline\hline
1 no-encoder & 2.63 \\
2 & 2.6 \\
4 & 2.58 \\
6 & 2.54 \\
\textbf{10} & \textbf{2.53} \\
10 average-pool & 2.58 \\
15 & 2.6 \\ \hline
\end{tabular}\end{center}
\caption{Ablation study of the proposed attention-based
augmentation-aggregation scheme. We compare the performance of our proposed
architecture with different number of augmentations at input (). `1
no-encoder' reffers to using a single augmentation without an encoder. `10
average-pool' reffers to using 10 augmentations that are aggregated by
averaging the activations maps.}
\label{table:ablation-aug}
\end{table}

We first evaluated the attention-based augmentation-aggregation scheme
detailed in Section \ref{subsec:self-atten}. For that we implemented two
additional variations:\ the first (1 no-encoder), is a naive baseline
without augmentations and aggregations, where we only uses a single replica
of the input image. This results in the lowest accuracy of 2.63. When we
apply 10 augmentations using average pooling (10 average-pool), the accuracy
improved to 2.58 compared to the our SOTA of 2.58. As for the number of
augmentations used. The results, shown in Table \ref{table:ablation-aug}
exemplify the effectivity of the proposed augmentation-aggregation. In
particular, using additional augmentations per image improves the estimation
accuracy up to 10 augmentations, applying additional augmentations does not
improve the accuracy.
\begin{table}[tbh]
\begin{center}
\centering \begin{tabular}{l|l|l}
\hline
\# layers & \# heads & MAE \\ \hline\hline
8 & 8 & 2.57 \\
\textbf{4} & \textbf{4} & \textbf{2.53} \\
2 & 2 & 2.55 \\ \hline
\end{tabular}\end{center}
\caption{Ablation study of varying Transformer Encoder parameters: the
number of encoder layers and attention heads.}
\label{tab:encoder_size}
\end{table}

The Encoder configuration was examined by trying out multiple
configurations. The more encoder layers are used, the larger the network's
learning capacity. But, this might also lead to overfitting. Indeed, the
results in Table \ref{tab:encoder_size} show that the `sweet spot' is
achieved for four layers and four MHA. Using a deeper configuration leads to
overfitting. We also verified the choice of the age classification bin size
and corresponding classification ensemble . It follow that the best accuracy is
achieved for .
\begin{table}[tbh]
\begin{center}
\centering \begin{tabular}{l|l}
\hline
Bin size & MAE \\ \hline\hline
10 & 2.56 \\
5 & 2.56 \\
\textbf{1} & \textbf{2.53 } \\ \hline
\end{tabular}\end{center}
\caption{Ablation study of the classification bin size and corresponding
regression ensemble .}
\label{tab:bin_size}
\end{table}

\subsection{Bias Analysis}

\label{subsec:bias}

Following the discussion in Section \ref{subsec:Related bias}, we present a
statistical bias analysis based on the MORPH II dataset, whose gender and
ethnicity breakdown are given in Table \ref{table:demographic_comparison}.
The MORPH II dataset is imbalanced in terms of the age, gender and
ethnicity. Our approach, as well as all prior schemes, was trained by
randomly sampling the dataset, resulting in an ethnically and gender-wise
unbalanced and biased training and test sets. We report for the
first time, to the best of our knowledge, bias estimates that are also
applicable to previous works. In our bias analysis we use the SE protocol
and the proposed SOTA network as in Table \ref{table:Morph-II}.

\textbf{Age bias.} The error distribution vs. the estimated age is reported
in Table \ref{table:morph2_count}. The age estimation errors relate to the given number of training samples per age
range, and the age-related appearance changes, that are difficult to
quantify. The lowest estimation error is for the 15-25 age range. As the number of training samples is relatively small, 
We attribute that to the accelerated rate of physiological appearance changes making the age estimation easier. The
error flattens for the 30-50 age range that contains most of the training
samples, and increases for the 55-70 age range in which here are a limited
number of samples.
\begin{table}[tbh]
\begin{center}
\centering \begin{tabular}{l|l|l|l}
\hline
Age & Samples\# & MAE & Std \\ \hline\hline
15-20 & 3330 & 1.52 & 1.74 \\
20-25 & 9703 & 2.0 & 1.65 \\
25-30 & 8243 & 2.25 & 1.95 \\
30-35 & 6243 & 2.96 & 1.99 \\
35-40 & 8638 & 2.87 & 2.36 \\
40-45 & 7552 & 2.69 & 1.95 \\
45-50 & 5884 & 2.69 & 2.24 \\
50-55 & 3421 & 3.28 & 2.47 \\
55-60 & 1569 & 3.9 & 3.14 \\
60-65 & 399 & 5.99 & 2.94 \\
65-70 & 124 & 6.81 & 2.55 \\ \hline
\end{tabular}\end{center}
\caption{\textbf{Age bias.} The number of MORPH II\ samples per age
category, and the corresponding MAE and standard deviation of the age
estimation error in each category.}
\label{table:morph2_count}
\end{table}

\textbf{Gender and ethnicity bias. }The most common source of estimation
bias in biometrics is due to gender and ethnicity. We study the bias due to ethnicity, as
reported in Fig. \ref{fig:error_per_race}, where there seems to be no
apparent estimation bias. We present the gender-only estimation accuracies in Fig. \ref {fig:error_per_gender}, where the rate of low estimation errors is higher
for man by close to 10\%. We attribute that to a notably larger number of
male training samples. The breakdown of the bias due to gender \textit{and}
ethnicity is given in Fig. \ref{fig:mae_per_gender_per_race}, where the
error for female subjects is higher for all ethnicities. In particular, it
is higher by close to 0.8 and 0.5 years for black and while female subjects,
respectively. The proposed scheme was shown to be
non-biased with respect to ethnicity, despite the imbalanced training set.
But is biased towards female subjects by an average error of 0.7 years. Our
findings coincide with those of Puc et al. \cite{9287219} that used different schemes and evaluation datasets.
\begin{figure}[tbp]
\centering\includegraphics[width=\columnwidth,height=0.6\columnwidth]{figures/error_per_race.pdf}
\caption{\textbf{Ethnicity bias.} The MAE per ethnicity over the Morph II
dataset. There is no apparent ethnicity-related estimation bias.}
\label{fig:error_per_race}
\end{figure}
\begin{figure}[tbp]
\centering\includegraphics[width=\columnwidth,height=0.6\columnwidth]{figures/error_per_gender.pdf}
\caption{\textbf{Gender bias.} Estimation MAE probability per gender over
the Morph II dataset. The probability of low age estimation errors is higher
by close to 10\% for male images. }
\label{fig:error_per_gender}
\end{figure}
\begin{figure}[tbp]
\centering\includegraphics[width=\columnwidth,height=0.6\columnwidth]{figures/mae_per_gender_per_race.pdf}
\caption{\textbf{Gender and ethnicity bias}. Age MAE per ethnicity and
gender. The age MAE for men subjects is better by 0.5-0.7 years.}
\label{fig:mae_per_gender_per_race}
\end{figure}

\section{Conclusions}
In this work we presented a novel deep-learning approach for age estimation
based on face images. First, we show that multiple image augmentations can be jointly encoded and aggregated by a
Transformer-Encoder yielding a robust image embedding. Second, we propose a
probabilistic hierarchical age estimation framework that applies a deep
classifier to estimate the age probabilities. The probability estimates are
used to weigh a corresponding ensemble of local regressors, each adapted to
a particular age sub-domain. The proposed scheme is shown to outperform
contemporary SOTA schemes. We also introduce, for the first time to our
knowledge, a bias analysis of SOTA results in face-based age estimation. We hope that the proposed bias
analysis would be used by others in the field.

\bibliographystyle{plain}
\bibliography{references}

\end{document}
