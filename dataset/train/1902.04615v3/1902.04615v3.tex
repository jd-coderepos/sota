\documentclass{article}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} 

\usepackage{hyperref}

\newcommand{\theHalgorithm}{\arabic{algorithm}}



\usepackage[accepted]{icml2019}

\icmltitlerunning{Gauge Equivariant CNNs}

\usepackage[utf8]{inputenc}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\usepackage{wrapfig}
\usepackage{multirow}

\newcommand{\id}{\mathrm{id}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\GL}[1]{\ensuremath{\operatorname{GL}(#1)}}
\newcommand{\GLR}[1]{\ensuremath{\operatorname{GL}(#1, \mathbb{R})}}
\newcommand{\SLR}[1]{\ensuremath{\operatorname{SL}(#1, \mathbb{R})}}
\newcommand{\E}[1]{\ensuremath{\operatorname{E}(#1)}}
\newcommand{\SE}[1]{\ensuremath{\operatorname{SE}(#1)}}
\renewcommand{\O}[1]{\ensuremath{\operatorname{O}(#1)}}
\newcommand{\SO}[1]{\ensuremath{\operatorname{SO}(#1)}}
\newcommand{\Aff}[1]{\ensuremath{\operatorname{Aff}(#1, \mathbb{R})}}
\newcommand{\Tr}{\ensuremath{\operatorname{Tr}}}
\newcommand{\ind}{\ensuremath{\operatorname{Ind}}}
\newcommand{\res}{\ensuremath{\operatorname{Res}}}
\DeclareMathOperator{\Hom}{Hom}
\newcommand{\corr}{\ensuremath{\star}}
\newcommand{\conv}{\ensuremath{*}}
\newcommand{\h}[1]{\mathrm{h}_{#1}}
\renewcommand{\vec}{\operatorname{vec}}

\newcommand\blfootnote[1]{\begingroup
  \renewcommand\thefootnote{}\footnote{#1}\addtocounter{footnote}{-1}\endgroup
}

\begin{document}

\twocolumn[
\icmltitle{Gauge Equivariant Convolutional Networks and the Icosahedral CNN}





\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Taco S. Cohen}{equal,qc}
\icmlauthor{Maurice Weiler}{equal,quva}
\icmlauthor{Berkay Kicanaoglu}{equal,quva}
\icmlauthor{Max Welling}{qc}
\end{icmlauthorlist}

\icmlaffiliation{qc}{Qualcomm AI Research, Amsterdam, NL.}
\icmlaffiliation{quva}{Qualcomm-University of Amsterdam (QUVA) Lab.}

\icmlcorrespondingauthor{Taco S. Cohen}{taco.cohen@gmail.com}
\icmlcorrespondingauthor{Maurice Weiler}{m.weiler@uva.nl}

\icmlkeywords{Geometric Deep Learning, Equivariant Networks, Equivariance, Deep Learning, Machine Learning, Deep Learning, ICML, Gauge Theory, Fiber Bundles}

\vskip 0.3in
]





\printAffiliationsAndNotice{\icmlEqualContribution} 


\begin{abstract}
    The principle of \emph{equivariance to symmetry transformations} enables a theoretically grounded approach to neural network architecture design.
    Equivariant networks have shown excellent performance and data efficiency on vision and medical imaging problems that exhibit symmetries.
    Here we show how this principle can be extended beyond global symmetries to local gauge transformations.
    This enables the development of a very general class of convolutional neural networks on manifolds that depend only on the intrinsic geometry, and which includes many popular methods from equivariant and geometric deep learning.

    We implement gauge equivariant CNNs for signals defined on the surface of the icosahedron, which provides a reasonable approximation of the sphere.
    By choosing to work with this very regular manifold, we are able to implement the gauge equivariant convolution using a single conv2d call, making it a highly scalable and practical alternative to Spherical CNNs.
    Using this method, we demonstrate substantial improvements over previous methods on the task of segmenting omnidirectional images and global climate patterns.
\end{abstract}


\section{Introduction}

By and large, progress in deep learning has been achieved through intuition-guided experimentation.
This approach is indispensable and has led to many successes, but has not produced a deep understanding of \emph{why and when} certain architectures work well.
As a result, every new application requires an extensive architecture search, which comes at a significant labor and energy cost.

Although a theory that tells us which architecture to use for any given problem is clearly out of reach, we can nevertheless come up with \emph{general  principles} to guide architecture search.
One such rational design principle that has met with substantial empirical success  \cite{winkels3DGCNNsPulmonary2018, zaheerDeepSets2017, lunterEquivariantBayesianConvolutional2018}
maintains that network architectures should be equivariant to symmetries.

Besides the ubiquitous translation equivariant CNN, equivariant networks have been developed for sets, graphs, and homogeneous spaces like the sphere (see Sec. \ref{sec:related_work}).
In each case, the network is made equivariant to the global symmetries of the underlying space.
However, manifolds do not in general have global symmetries, and so it is not obvious how one might develop equivariant CNNs for them.

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.46\textwidth]{figures/sphere_gauge.png}
    \caption{A gauge is a smoothly varying choice of tangent frame on a subset  of a manifold .
    A gauge is needed to represent geometrical quantities such as convolutional filters and feature maps (i.e. fields), but the choice of gauge is ultimately arbitrary.
    Hence, the network should be equivariant to gauge transformations, such as the change between red and blue gauge pictured here.}
    \label{fig:gauge_trafo}
\end{figure}

General manifolds do however have \emph{local gauge symmetries}, and as we will show in this paper, taking these into account is not just useful but \emph{necessary} if one wishes to build manifold CNNs that depend only on the intrinsic geometry.
To this end, we define a convolution-like operation on general manifolds  that is equivariant to local gauge transformations (Fig. \ref{fig:gauge_trafo}).
This \emph{gauge equivariant convolution} takes as input a number of \emph{feature fields} on  of various types (analogous to matter fields in physics), and produces as output new feature fields.
Each field is represented by a number of feature maps, whose activations are interpreted as the coefficients of a geometrical object (e.g. scalar, vector, tensor, etc.) relative to a spatially varying frame (i.e. gauge).
The network is constructed such that if the gauge is changed, the coefficients change in a predictable way so as to preserve their geometrical meaning.
Thus, the search for a geometrically natural definition of ``manifold convolution'', a key problem in geometric deep learning, leads inevitably to gauge equivariance.

Although the theory of gauge equivariant networks developed in this paper is very general, we apply it to one specific manifold: the icosahedron.
This manifold has some global symmetries (discrete rotations), which nicely shows the difference between and interplay of local and global symmetries.
In addition, the regularity and local flatness of this manifold allows for a very efficient implementation using existing deep learning primitives (i.e. conv2d).
The resulting algorithm shows excellent performance and accuracy on segmentation of omnidirectional signals.

Gauge theory plays a central role in modern physics, but has a reputation for being abstract and difficult.
So in order to keep this article accessible to a broad machine learning audience, we have chosen to emphasize geometrical intuition over mathematical formality.

The rest of this paper is organized as follows.
In Sec. \ref{sec:gauge_equivariant_networks},
we motivate the need for working with gauges, and define gauge equivariant convolution for general manifolds and fields.
In section \ref{sec:related_work}, we discuss related work on equivariant and geometrical deep learning.
Then in section \ref{sec:icosahedral_cnns}, we discuss the concrete instantiation and implementation of gauge equivariant CNNs for the icosahedron.
Results on IcoMNIST, climate pattern segmentation, and omnidirectional RGB-D image segmentation are presented in Sec. \ref{sec:experiments}.


\section{Gauge Equivariant Networks}
\label{sec:gauge_equivariant_networks}

Consider the problem of generalizing the classical convolution of two planar signals (e.g. a feature map and a filter) to signals defined on a manifold .
The first and most natural idea comes from thinking of planar convolution in terms of \emph{shifting} a filter over a feature map.
Observing that shifts are symmetries of the plane (mapping the plane onto itself while preserving its structure), one is led to the idea of transforming a filter on  by the symmetries of .
For instance, replacing shifts of the plane by rotations of the sphere, one obtains Spherical CNNs \cite{cohenSphericalCNNs2018}.

This approach works for any \emph{homogeneous space}, where by definition it is possible to move from any point  to any other point  using an appropriate symmetry transformation \cite{kondorGeneralizationEquivarianceConvolution2018, cohenIntertwinersInducedRepresentations2018, cohenGeneralTheoryEquivariant2018}.
On less symmetrical manifolds however, it may not be possible to move the filter from any point to any other point by symmetry transformations.
Hence, transforming filters by symmetry transformations will in general not provide a recipe for weight sharing between filters at all points in .

\begin{figure}
  \centering
  \begin{minipage}[c]{0.18\textwidth}
    \includegraphics[width=2.6cm]{figures/parallel_transport.png}
  \end{minipage}\hfill
  \begin{minipage}[c]{0.3\textwidth}
  \vspace{-0.8 \baselineskip}
  \caption{
       On curved spaces, parallel transport is path dependent. The black vector is transported to the same point via two different curves, yielding different results. The same phenomenon occurs for other geometric objects, including filters.
  }
  \label{fig:parallel_transport}
  \end{minipage}
\end{figure}


Instead of symmetries, one can move the filter by parallel transport \cite{schonsheckParallelTransportConvolution2018}, but as shown in Fig. \ref{fig:parallel_transport}, this leaves an ambiguity in the filter orientation, because parallel transport is \emph{path dependent}.
This can be addressed by using only \emph{rotation invariant} filters \cite{boscainiLearningClassSpecific2015, brunaSpectralNetworksDeep}, albeit at the cost of limiting expressivity.

The key issue is that on a manifold, there is no preferred gauge (tangent frame), relative to which we can position our measurement apparatus (i.e. filters), and relative to which we can describe measurements (i.e. responses).
We must choose a gauge in order to 
numerically represent geometrical quantities and perform computations, but since it is arbitrary, the computations should be independent of it.

This does not mean however that the \emph{coefficients} of the feature vectors should be invariant to gauge transformations, but rather that the feature vector itself should be invariant.
That is, a gauge transformation leads to a change of basis  of the feature space (fiber) at , so the feature vector coefficients  should change equivariantly to ensure that the vector  itself is unchanged.

Before showing how this is achieved, we note that on \emph{non-parallelizable} manifolds such as the sphere, it is not possible to choose a smooth global gauge.
For instance, if we extend the blue gauge pictured in Fig. \ref{fig:gauge_trafo} to the whole sphere, we will innevitably create a singularity where the gauge changes abruptly.
Hence, in order to make the math work smoothly, it is standard practice in gauge theory to work with multiple gauges defined on overlapping charts, as in Fig. \ref{fig:gauge_trafo}.

The basic idea of gauge equivariant convolution is as follows.
Lacking alternative options, we choose arbitrarily a smooth \emph{local} gauge on subsets  (e.g. the red or blue gauge in Fig. \ref{fig:gauge_trafo}).
We can then position a filter at each point , defining its orientation relative to the gauge.
Then, we match an input feature map against the filter at  to obtain the value of the output feature map at .
For the output to transform equivariantly, certain linear constraints are placed on the convolution kernel.
We will now define this formally.


\subsection{Gauges, Transformations, and Exponential Maps}

We define a gauge as a position-dependent invertible linear map , where  is the tangent space of  at .
This determines a frame  in , where  is the standard frame of .

A gauge transformation (Fig. \ref{fig:gauge_trafo}) is a position-dependent change of frame, which can be described by maps  (the group of invertible  matrices).
As indicated by the subscript, the transformation  depends on the position .
To change the frame, simply compose  with , i.e. .
It follows that component vectors  transform as , so that the vector  itself is invariant.

If we derive our gauge from a coordinate system for  (as shown in Fig. \ref{fig:gauge_trafo}), then a change of coordinates leads to a gauge transformation ( being the Jacobian of the coordinate transformation at ).
But we can also choose a gauge  independent of any coordinate system.

It is often useful to restrict the kinds of frames we consider, for example to only allow right-handed or orthogonal frames.
Such restrictions limit the kinds of gauge transformations we can consider.
For instance, if we allow only right-handed frames,  should have positive determinant (i.e. ), so that it does not reverse the orientation.
If in addition we allow only orthogonal frames,  must be a rotation, i.e. .

In mathematical terms,  is called the \emph{structure group} of the theory, and limiting the kinds of frames we consider corresponds to a \emph{reduction of the structure group} \cite{husemollerFibreBundles1994a}.
Each reduction corresponds to some extra structure that is preserved, such as an \emph{orientation} () or \emph{Riemannian metric} ().
In the Icosahedral CNN (Fig. \ref{fig:atlas}), we will want to preserve the hexagonal grid structure, which corresponds to a restriction to grid-aligned frames and a reduction of the structure group to , the group of planar rotations by integer multiples of .
For the rest of this section, we will work in the Riemannian setting, i.e. use .

Before we can define gauge equivariant convolution, we will need the exponential map, which gives a convenient parameterization of the local neighbourhood of .
This map  takes a tangent vector , follows the geodesic (shortest curve) in the direction of  with speed  for one unit of time, to arrive at a point  (see Fig. \ref{fig:exponential_map}, \cite{leeIntroductionRiemannianManifolds2018}).


\subsection{Gauge Equivariant Convolution: Scalar Fields}
\label{sec:gconv_local}

Having defined gauges, gauge transformations, and the exponential map, we are now ready to define gauge equivariant convolution.
We begin with scalar input and output fields.

We define a filter as a locally supported function , where  may be identified with  \emph{via the gauge} .
Then, writing  for , we define the scalar convolution of  and  at  as follows:


\begin{figure}
    \centering
    \includegraphics[width=6.5cm]{figures/expmap_and_frame.png}
    \caption{The exponential map and the gauge .}
    \label{fig:exponential_map}
\end{figure}

The gauge was chosen arbitrarily, so we must consider what happens if we change it.
Since the filter  is a function of a coordinate vector , and  gets rotated by gauge transformations, the effect of a gauge transformation is a position-dependent rotation of the filters.
For the convolution output to be called a scalar field, it has to be invariant to gauge transformations (i.e.  and ).
The only way to make  (Eq. \ref{eq:scalar_conv}) invariant to rotations of the filter, is to make the filter rotation-invariant:


Thus, to map a scalar input field to a scalar output field in a gauge equivariant manner, we need to use rotationally symmetric filters.
Some geometric deep learning methods, as well as graph CNNs do indeed use isotropic filters.
However, this is very limiting and as we will now show, unnecessary if one considers non-scalar feature fields.


\subsection{Feature Fields}
\label{sec:feature_fields}

Intuitively, a field is an assignment of some geometrical quantity (feature vector)  of the same type to each point .
The type of a quantity is determined by its transformation behaviour under gauge transformations.
For instance, the word \emph{vector field} is reserved for a field of tangent vectors , that transform like  as we saw before.
It is important to note that  is an element of a vector space (``fiber'')  attached to  (e.g. the tangent space ).
All  are similar to a canonical feature space , but  can only be considered a function  \emph{locally}, after we have chosen a gauge, because there is no canonical way to identify all feature spaces .

In the general case, the transformation behaviour of a -dimensional geometrical quantity is described by a \emph{representation of the structure group} .
This is a mapping  that satisfies , where  denotes the composition of transformations in , and  denotes multiplication of  matrices  and .
The simplest examples are the trivial representation  which describes the transformation behaviour of scalars, and , which describes the transformation behaviour of (tangent) vectors.
A field  that transforms like  will be called a -field.

In Section \ref{sec:icosahedral_cnns} on Icosahedral CNNs, we will consider one more type of representation, namely the \emph{regular representation} of .
The group  can be described as the  planar rotations by , or as integers  with addition mod .
Features that transform like the regular representation of  are -dimensional, with one component for each rotation.
One can obtain a regular feature by taking a filter at , rotating it by  for , and matching each rotated filter against the input signal.
When the gauge is changed, the filter and all rotated copies are rotated, and so the components of a regular  feature are cyclically shifted.
Hence,  is a  cyclic permutation matrix that shifts the coordinates by  steps for .
Further examples of representations  that are useful in convolutional networks may be found in \cite{cohenSteerableCNNs2017,weiler3DSteerableCNNs2018, thomasTensorFieldNetworks2018, hyPredictingMolecularProperties2018}.


\subsection{Gauge Equivariant Convolution: General Fields}

Now consider a stack of  input feature maps on , which represents a -dimensional -field (e.g.  for a single scalar,  for a vector,  for a regular  feature, or any multiple of these, etc.).
We will define a convolution operation that takes such a field and produces as output a -dimensional -field.
For this we need a filter bank with  output channels and  input channels, which we will describe mathematically as a matrix-valued kernel .

We can think of  as a linear map from the input feature space (``fiber'') at  to the output feature space at , these spaces being identified with  resp.  by the choice of gauge  at .
This suggests that we need to modify Eq. \ref{eq:scalar_conv} to make sure that the kernel matrix  is multiplied by a feature vector at , not one at .
This is achieved by transporting  to  along the unique\footnote{For points that are close enough, there is always a unique geodesic. Since the kernel has local support,  and  will be close for all non-zero terms.} geodesic connecting them, before multiplying by .

As  is transported to , it undergoes a transformation which will be denoted  (see Fig. \ref{fig:parallel_transport}).
This transformation acts on the feature vector  via the representation .
Thus, we obtain the generalized form of Eq. \ref{eq:scalar_conv} for general fields:


Under a gauge transformation, we have:

For  to be well defined as a -field, we want it to transform like .
Or, in other words,  should be gauge equivariant.
This will be the case if and only if  satisfies

One may verify this by making the substitutions of Eq. \ref{eq:subst} in Eq. \ref{eq:parallel_transport_conv} and simplifying using  and Eq. \ref{eq:kernel_constraint}, to find that .

We note that equations \ref{eq:scalar_conv} and \ref{eq:scalar_kernel_constraint} are special cases of \ref{eq:parallel_transport_conv} and \ref{eq:kernel_constraint} for , i.e. for scalar fields.

This concludes our presentation of the general case.
A gauge equivariant  convolution on  is defined relative to a local gauge by Eq. \ref{eq:parallel_transport_conv}, where the kernel satisfies the equivariance constraint of Eq. \ref{eq:kernel_constraint}.
By defining gauges on local charts  that cover  and convolving inside each one, we automatically get a globally well-defined operation, because switching charts corresponds to a gauge transformation (Fig. \ref{fig:gauge_trafo}), and the convolution is gauge equivariant.


\subsection{Locally Flat Spaces}
\label{sec:locally_flat_spaces}

On flat regions of the manifold, the exponential parameterization can be simplified to  if we use an appropriate local coordinate  of .
Moreover, in such a flat chart, parallel transport is trivial, i.e.  equals the identity.
Thus, on a flat region, our convolution boils down to a standard convolution / correlation:

Moreover, we can recover group convolutions, spherical convolutions, and convolution on other homogeneous spaces as special cases as well (see supplementary material).


\section{Related work}
\label{sec:related_work}

\paragraph{Equivariant Deep Learning}
Equivariant networks have been proposed for permutation-equivariant analysis and prediction of sets 
\cite{zaheerDeepSets2017, hartfordDeepModelsInteractions2018}, graphs \cite{kondorCovariantCompositionalNetworks2018, hyPredictingMolecularProperties2018, maronInvariantEquivariantGraph2019}, translations and rotations of the plane and 3D space \cite{oyallonDeepRotoTranslationScattering2015, cohenGroupEquivariantConvolutional2016, cohenSteerableCNNs2017, marcosRotationEquivariantVector2017, weilerLearningSteerableFilters2018, weiler3DSteerableCNNs2018, worrallHarmonicNetworksDeep2017, worrallCubeNetEquivariance3D2018, winkels3DGCNNsPulmonary2018, veelingRotationEquivariantCNNs2018, thomasTensorFieldNetworks2018, bekkersRotoTranslationCovariantConvolutional2018, hoogeboomHexaConv2018}, and the sphere (see below).
\citet{ravanbakhshEquivarianceParameterSharing2017} studied finite group equivariance.
Equivariant CNNs on homogeneous spaces were studied by \cite{kondorGeneralizationEquivarianceConvolution2018} (scalar fields) and \cite{cohenIntertwinersInducedRepresentations2018, cohenGeneralTheoryEquivariant2018} (general fields).
In this paper we generalize G-CNNs from homogeneous spaces to general manifolds.


\paragraph{Geometric Deep Learning}

Geometric deep learning \cite{bronsteinGeometricDeepLearning2016} is concerned with the generalization of (convolutional) neural networks to manifolds.
Many definitions of manifold convolution have been proposed, and some of them (those called ``intrinsic'') are gauge equivariant (although to the best of our knowledge, the relevance of gauge theory has not been observed before).
However, these methods are all limited to particular feature types  (typically scalar), and/or use a parameterization of the kernel that is not maximally flexible.

\citet{brunaSpectralNetworksDeep, boscainiLearningClassSpecific2015} propose to use isotropic (spectral) filters (i.e. scalar field features), while \cite{masciGeodesicConvolutionalNeural2015} define a convolution that is essentially the same as our scalar-to-regular convolution, followed by a max-pooling over orientations, which in our terminology maps a regular field to a scalar field.
As shown experimentally in \cite{cohenGroupEquivariantConvolutional2016, cohenSteerableCNNs2017} and in this paper, it is often more effective to use convolutions that preserve orientation information (e.g. regular to regular convolution).
Another solution is to align the filter with the maximum curvature direction \cite{boscainiLearningShapeCorrespondence2016}, but this approach is not intrinsic and does not work for flat surfaces or uniformly curved spaces like spheres.

\cite{poulenardMultidirectionalGeodesicNeural2018a} define a multi-directional convolution for ``directional functions'' (somewhat similar to what we call regular fields), but they parameterize the kernel by a \emph{scalar} function on the tangent space, which is very limited compared to our matrix-valued kernel (which is the most general kernel mapping  fields to  fields).


\paragraph{Spherical CNNs}
Besides the general theoretical framework of gauge equivariant convolution, we present in this paper a specific model (the Icosahedral CNN), which can be viewed as a fast and simple alternative to Spherical CNNs \cite{cohenSphericalCNNs2018, estevesLearningEquivariantRepresentations2018, boomsmaSphericalConvolutionsTheir2017, suLearningSphericalConvolution2017, perraudinDeepSphereEfficientSpherical2018, jiangSphericalCNNsUnstructured2018, kondorClebschGordanNets2018}.
\citet{liuDeepLearning3D2019} use a spherical grid based on a subdivision of the icosahedron, and convolve over it using a method that is similar to the one presented in Sec. \ref{sec:icosahedral_cnns} (and thus ignores curvature), but this method is not equivariant and does not take into account gauge transformations.
We show in Sec. \ref{sec:experiments} that both are important for optimal performance.


\paragraph{Mathematics \& physics}
To deeply understand gauge equivariant networks, we recommend studying the mathematics of gauge theory: principal \& associated fiber bundles \cite{schullerLecturesGeometricalAnatomy2016, husemollerFibreBundles1994a, steenrodTopologyFibreBundles}.
The work presented in this paper can be understood as replacing the principal -bundle  used in G-CNNs over homogeneous spaces  \cite{cohenGeneralTheoryEquivariant2018} by the frame bundle of , which is another principal -bundle.
More details can be found in the supplementary material.


\section{Icosahedral CNNs}
\label{sec:icosahedral_cnns}

In this section we will describe a concrete method for performing gauge equivariant convolution on the icosahedron.
The very special shape of this manifold makes it possible to implement gauge equivariant convolution in a way that is both numerically convenient (no interpolation is required), and computationally efficient (the heavy lifting is done by a single conv2d call).


\subsection{The Icosahedron}
\label{sec:the_icosahedron}

The icosahedron is a regular solid with  faces,  edges, and  vertices (see Fig. \ref{fig:atlas}, left).
It has  rotational symmetries.
This symmetry group will be denoted\footnote{As an abstract group,  (the alternating group A5), but we use  to emphasize that it is realized by a set of 3D rotations.} .


\subsection{The Hexagonal Grid}
\label{sec:grid}

Whereas general manifolds, and even spheres, do not admit completely regular and symmetrical pixelations, we can define an almost perfectly regular grid of pixels on the icosahedron.
This grid is constructed through a sequence of grid-refinement steps.
We begin with a grid  consisting of the corners of the icosahedron itself.
Then, for each triangular face, we subdivide it into 4 smaller triangles, thus introducing 3 new points on the center of the edges of the original triangle.
This process is repeated  times to obtain a grid  with  points (Fig. \ref{fig:atlas}, left).

Each grid point (pixel) in the grid has 6 neighbours, except for the corners of the icosahedron, which have .
Thus, one can think of the non-corner grid points as hexagonal pixels, and the corner points as pentagonal pixels.

Notice that the grid  is perfectly symmetrical, which means that if we apply an icosahedral symmetry  to a point , we will always land on another grid point, i.e. .
Thus, in addition to talking about gauge equivariance, for this manifold / grid, we can also talk about (exact) equivariance to \emph{global transformations} (3D rotations in ).
Because these global symmetries act by permuting the pixels and changing the gauge, one can see that a gauge equivariant network is automatically equivariant to global transformations.
This will be demonstrated in Section \ref{sec:experiments}.


\subsection{The Atlas of Charts}
\label{sec:atlas}

We define an \emph{atlas} consisting of  overlapping \emph{charts} on the icosahedron, as shown in Fig. \ref{fig:atlas}.
Each chart is an invertible map , where  and .
The regions  and  are shown in Fig. \ref{fig:atlas}.
The maps themselves are linear on faces, and defined by hard-coded correspondences  between the corner points  in  and points  in the planar grid .

\begin{figure}[h!]
    \centering
    \includegraphics[width=8cm]{figures/charts.png}
    \caption{The Icosahedron with grid  for  (left). We define  overlapping charts that cover the grid (center). Chart  is highlighted in gray (left). Colored edges that appear in multiple charts are to be identified. In each chart, we define the gauge by the standard axis aligned basis vectors . For points , the transition between charts involves a change of gauge, shown as  and  (elements of ).
    On the right we show how the signal is represented in a padded array of shape .}
    \label{fig:atlas}
\end{figure}


Each chart covers all the points in  triangular faces of the icosahedron.
Together, the  charts cover all  faces of the icosahedron.

We divide the charts into an \emph{exterior} , consisting of border pixels, and an \emph{interior} , consisting of pixels whose neighbours are all contained in chart .
In order to ensure that every pixel in  (except for the  corners) is contained in the interior of some chart, we add a strip of pixels to the left and bottom of each chart, as shown in Fig. \ref{fig:atlas} (center).
Then the interior of each chart (plus two exterior corners) has a nice rectangular shape , and every non-corner is contained in exactly one interior .

So if we know the values of the field in the interior of each chart, we know the whole field (except for the corners, which we ignore).
However, in order to compute a valid convolution output at each interior pixel (assuming a hexagonal filter with one ring, i.e. a  masked filter), we will still need the exterior pixels to be filled in as well (introducing a small amount of redundancy).
See Sec. \ref{sec:gauge_padding}.


\subsection{The Gauge}
\label{sec:gauge}

For the purpose of computation, we fix a convenient gauge in each chart. This gauge is defined in each  as the constant orthogonal frame , aligned with the  and  direction of the plane (just like the red and blue gauge in Fig. \ref{fig:gauge_trafo}).
When mapped to the icosahedron via (the Jacobian of) , the resulting frames are aligned with the grid, and the basis vectors make an angle of .

Some pixels  are covered by multiple charts.
Although the local frames  are numerically constant and equal in both charts  and , the corresponding frames on the icosahedron (obtained by pushing them though  and ) may not be the same.
In other words, when switching from chart  to chart , there may be a gauge transformation , which rotates the frame at  (see Fig. \ref{fig:gauge_trafo}).

For the particular atlas defined in Sec. \ref{sec:atlas}, the gauge transformations  are always elements of the group  (i.e. rotations by ), so  and we have a -atlas.


\subsection{The Signal Representation}
\label{sec:signal_representation}

A stack of  feature fields is represented as an array of shape , where  is the batch size,  the number of fields,  is the dimension of the fields ( for scalars and  for regular features),  is the number of charts, and  are the height and width of each local chart ( and  at resolution , including a -pixel padding region on each side, see Fig. \ref{fig:atlas}).
We can always reshape such an array to shape , resulting in a  array that can be viewed as a stack of  rectangular feature maps of shape .
Such an array can be input to conv2d.


\subsection{Gauge Equivariant Icosahedral Convolution}

Gauge equivariant convolution on the icosahedron is implemented in three steps: G-Padding, kernel expansion, and 2d convolution / HexaConv \cite{hoogeboomHexaConv2018}.

\subsubsection{G-Padding}
\label{sec:gauge_padding}

\begin{wrapfigure}{r}{0.2\textwidth} 
\centering
    \includegraphics[width=2cm]{figures/gpad.png}
    \caption{G-Padding (scalar signal)}
    \label{fig:gpad}
\end{wrapfigure}
In a standard CNN, we can only compute a valid convolution output at positions  where the filter fits inside the input image in its entirety.
If the output is to be of the same size as the input, one uses zero padding.
Likewise, the IcoConv requires padding, only now the padding border  of a chart consists of pixels that are also represented in the interior of another chart (Sec. \ref{sec:atlas}).
So instead of zero padding, we copy the pixels from the neighbouring chart.
We always use hexagonal filters with 1 ring, which can be represented as a  filter on a square grid, so we pad by 1 pixel.

As explained in Sec. \ref{sec:gauge}, when transitioning between charts one may have to perform a gauge transformation on the features.
Since scalars are invariant quantities, transition padding amounts to a simple copy in this case.
Regular  features (having  orientation channels) transform by cyclic shifts  (Sec. \ref{sec:feature_fields}), where  (Fig. \ref{fig:atlas}), so we must cyclically shift the channels up or down before copying to get the correct coefficients in the new chart.
The whole padding operation is implemented by four indexing + assignment operations (top, bottom, left, right) using fixed pre-computed indices (see Supp. Mat.).


\subsubsection{Weight Sharing \& Kernel Expansion}
\label{sec:kernel_expansion}

\begin{figure}[h!]
    \centering
    \includegraphics[width=2.5cm]{figures/kexp.png}
    \caption{Kernel expansion for scalar-to-regular (; left) and regular-to-regular (; right) convolution. Top: free parameters. Bottom: expanded kernel used in conv2d.}
    \label{fig:kexp}
\end{figure}
For the convolution to be gauge equivariant, the kernel must satisfy Eq. \ref{eq:kernel_constraint}.
The kernel  is stored in an array of shape , with the top-right and bottom-left pixel of each  filter fixed at zero so that it corresponds to a 1-ring hexagonal kernel.

Eq. \ref{eq:kernel_constraint} says that if we transform the input channels (columns) by  and the ouput channels (rows) by , the result should equal the original kernel where each channel is rotated by .
This will the case if we use the weight-sharing scheme shown in Fig. \ref{fig:kexp}.

Weight sharing can be implemented in two ways.
One can construct a basis of kernels, each of which has shape  and has value  at all pixels of a certain color/shade, and  elsewhere.
Then one can construct the full kernel by linearly combining these basis filters using learned weights (one for each  input/output channels and basis kernel) \cite{cohenSteerableCNNs2017, weiler3DSteerableCNNs2018}.
Alternatively, for scalar and regular features, one can use a set of precomputed indices to expand the kernel as shown in Fig. \ref{fig:kexp}, using a single indexing operation.


\subsubsection{Complete Algorithm}

The complete algorithm can be summarized as

Where  and  both have shape , the weights  have shape , and  has shape .
The output of GConv has shape .

On the flat faces, being described by one of the charts, this algorithm coincides exactly with the hexagonal regular convolution introduced in \cite{hoogeboomHexaConv2018}.
The non-zero curvature of the icosahedron requires us to do the additional step of padding between different charts.


\section{Experiments}
\label{sec:experiments}

\subsection{IcoMNIST}

In order to validate our implementation, highlight the potential benefits of our method, and determine the necessity of each part of the algorithm, we perform a number of experiments with the MNIST dataset, projected to the icosahedron.

We generate three different versions of the training and test sets, differing in the transformations applied to the data.
In the N condition, No rotations are applied to the data.
In the I condition, we apply all  Icosahedral symmetries (rotations) to each digit.
Finally, in the R condition, we apply  random continuous rotations  to each digit before projecting.
All signals are represented as explained in Sec. \ref{sec:signal_representation} / Fig. \ref{fig:atlas} (right), using resolution , i.e. as an array of shape .

Our main model consists of one gauge equivariant scalar-to-regular (S2R) convolution layer, followed by  regular-to-regular (R2R) layers and  FC layers (see Supp. Mat. for architectural details).
We also evaluate a model that uses only S2R convolution layers, followed by orientation pooling (a  over the  orientation channels of each regular feature, thus mapping a regular feature to a scalar), as in \cite{masciGeodesicConvolutionalNeural2015}.
Finally, we consider a model that uses only rotation-invariant filters, i.e. scalar-to-scalar (S2S) convolutions, similar to standard graph CNNs \cite{boscainiLearningClassSpecific2015, kipfSemiSupervisedClassificationGraph2017}.
We also compare to the fully -equivariant but computationally costly Spherical CNN (S2CNN).
See supp. mat. for architectural details and computational complexity analysis.

In addition, we perform an ablation study where we disable each part of the algorithm.
The first baseline is obtained from the full R2R network by disabling gauge padding (Sec. \ref{sec:gauge_padding}), and is called the No Pad (NP) network.
In the second baseline, we disable the kernel Expansion (Sec. \ref{sec:kernel_expansion}), yielding the NE condition.
The third baseline, called NP+NE uses neither gauge padding nor kernel expansion, and amounts to a standard CNN applied to the same input representation.
We adapt the number of channels so that all networks have roughly the same number of parameters.

\begin{table}[b]
\small
\centering
\begin{tabular}{c | c c c c c c}
    Arch.  & N/N            & N/I & N/R             & I/ I & I / R & R / R \\
    \hline
    S2CNN & {\tiny } & {\tiny } & {\tiny } & {\tiny } & {\tiny } & {\tiny } \\
    \hline
    NP+NE & {\tiny }  & {\tiny } & {\tiny } & {\tiny } & {\tiny } & {\tiny } \\
    NE    & {\tiny } & {\tiny } & {\tiny } & {\tiny }            & {\tiny }   & {\tiny } \\
    NP    & {\tiny } & {\tiny } & {\tiny } & {\tiny } & {\tiny } & {\tiny } \\
    S2S   & {\tiny } & {\tiny } & {\tiny } & {\tiny }            & {\tiny }   & {\tiny } \\
    S2R   & {\tiny } & {\tiny } & {\tiny } & {\tiny }            & {\tiny }   & {\tiny } \\
    R2R   & {\tiny } & {\tiny } & {\tiny } & {\tiny }            & {\tiny } & {\tiny } \\
\end{tabular}
\caption{IcoMNIST test accuracy (\%) for different architectures and train / test conditions (averaged over 3 runs). See text for explanation of labels.}
\label{tab:mnist}
\end{table}

As shown in Table \ref{tab:mnist}, icosahedral CNNs achieve excellent performance with a test accuracy of up to 99.43\%, which is a strong result even on planar MNIST, for non-augmented and non-ensembled models.
The full R2R model performs best in all conditions (though not significantly in the N/N condition), showing that both gauge padding and kernel expansion are necessary, and that our general (R2R) formulation works better in practice than using scalar fields (S2S or S2R).
We notice also that non-equivariant models (NP+NE, NP, NE) do not generalize well to transformed data, a problem that is only partly solved by data augmentation.
On the other hand, the models S2S, S2R, and R2R are exactly equivariant to symmetries , and so generalize perfectly to -transformed test data, even when these were not seen during training.
None of the models automatically generalize to continuously rotated inputs (R), but the equivariant models are closer, and can get even closer () when using  data augmentation during training.
The fully -equivariant S2CNN scores slightly worse than R2R, except in N/R and I/R, as expected.
The slight decrease in performance of S2CNN for rotated training conditions is likely due to the fact that it has lower grid resolution near the equator.
We note that the S2CNN is slower and less scalable than Ico CNNs (see supp. mat.).

\subsection{Climate Pattern Segmentation}

We evaluate our method on the climate pattern segmentation task proposed by \citet{mudigondaSegmentingTrackingExtreme}.
The goal is to segment extreme weather events (Atmospheric Rivers (AR) and Tropical Cyclones (TC)) in climate simulation data.

We use the exact same data and evaluation methodology as \cite{jiangSphericalCNNsUnstructured2018}.
The preprocessed data as released by \cite{jiangSphericalCNNsUnstructured2018} consists of -channel spherical images at resolution , which we reinterpret as icosahedral signals (introducing slight distortion).
See \cite{mudigondaSegmentingTrackingExtreme} for a detailed description of the data.


We compare an R2R and S2R model (details in Supp. Mat.).
As shown in Table \ref{tab:climate}, our models outperform both competing methods in terms of per-class and mean accuracy.
The difference between our R2R and S2R model seems small in terms of accuracy, but when evaluated in terms of mean average precision (a more appropriate evaluation metric for segmentation tasks), the R2R model clearly outperforms.

\begin{table}[h!]
    \centering
    \begin{tabular}{l c c c c c}
        \toprule
Model & BG & TC & AR & Mean & mAP \\
        \midrule
        {\small Mudigonda et al.}
         & 97 & 74 & 65 & 78.67 & - \\
        {\small Jiang et al.}
         & 97 & 94 & 93 & 94.67 & - \\
        Ours (S2R) & 97.3 & 97.8 & 97.3 & 97.5 & 0.686 \\
        Ours (R2R) & 97.4 & \textbf{97.9} & \textbf{97.8} & \textbf{97.7} & \textbf{0.759} \\
        \bottomrule
    \end{tabular}
    \caption{Climate pattern segmentation accuracy (\%) for BG, TC and AR classes plus mean accuracy and average precision (mAP).}
    \label{tab:climate}
\end{table}


\subsection{Stanford 2D-3D-S}

For our final experiment, we evaluate icosahedral CNNs on the 2D-3D-S dataset \cite{armeniJoint2D3DSemanticData}, which consists of 1413 omnidirectional RGB+D images with pixelwise semantic labels in 13 classes. 
Following \citet{jiangSphericalCNNsUnstructured2018}, we sample the data on a grid of resolution  using bilinear interpolation, while using nearest-neighbour interpolation for the labels.
Evaluation is performed by mean intersection over union (mIoU) and pixel accuracy (mAcc).

The network architecture is a residual U-Net \cite{RFB15a, heDeepResidualLearning2016} with R2R convolutions.
The network consists of a downsampling and upsampling network.
The downsampling network takes as input a signal at resolution  and outputs feature maps at resolutions , with  and  channels.
The upsampling network is the reverse of this.
We pool over orientation channels right before applying softmax.

As shown in table \ref{tab:2d3ds}, our method outperforms the method of \cite{jiangSphericalCNNsUnstructured2018}, which in turn greatly outperforms standard planar methods such as U-Net on this dataset.
\begin{table}[h!]
    \centering
    \begin{tabular}{l c c}
        \toprule
         & mAcc & mIoU \\
        \midrule
        {\small \cite{jiangSphericalCNNsUnstructured2018}}
         &  &  \\
        Ours (R2R-U-Net) &  &  \\
        \bottomrule
    \end{tabular}
    \caption{Mean accuracy and intersection over union for 2D-3D-S omnidirectional segmentation task.}
    \label{tab:2d3ds}
\end{table}


\section{Conclusion}

In this paper we have presented the general theory of gauge equivariant convolutional networks on manifolds, and demonstrated their utility in a special case: learning with spherical signals using the icosahedral CNN.
We have demonstrated that this method performs well on a range of different problems and is highly scalable.

Although we have only touched on the connections to physics and geometry, there are indeed interesting connections, which we plan to elaborate on in the future.
From the perspective of the mathematical theory of principal fiber bundles, our definition of manifold convolution is entirely natural.
Indeed it is clear that gauge invariance is not just nice to have, but \emph{necessary} in order for the convolution to be geometrically well-defined.

In future work, we plan to implement gauge CNNs on general manifolds and work on further scaling of spherical CNNs.
Our chart-based approach to manifold convolution should in principle scale to very large problems, thus opening the door to learning from high-resolution planetary scale spherical signals that arise in the earth and climate sciences.


\section*{Acknowledgements}
We would like to thank Chiyu ``Max'' Jiang and Mayur Mudigonda for help obtaining and interpreting the climate data, and Erik Verlinde for helpful discussions.
\blfootnote{The climate dataset released by \cite{jiangSphericalCNNsUnstructured2018} and the Stanford 2D-3D-S datasets were downloaded and evaluated by QUvA researchers.}

\bibliography{main}
\bibliographystyle{icml2019}

\newpage
\part*{Supplementary Material}

\section{Recommended reading}

For more information on manifolds, fiber bundles, connections, parallel transport, the exponential map, etc., we highly recommend the lectures by \citet{schullerLecturesGeometricalAnatomy2016}, as well as the book \citet{nakaharaGeometryTopologyPhysics2003} which explain these concepts very clearly and at a useful level of abstraction.

For further study, we recommend \cite{sharpeDifferentialGeometryCartan1997, shoshichikobayashiFoundationsDifferentialGeometry1963, husemollerFibreBundles1994a, steenrodTopologyFibreBundles, wendlLectureNotesBundles2008, craneDiscreteDifferentialGeometry2014}.


\section{Mathematical Theory \& Physics Analogy}
\label{sec:theory}

From the perspective of the theory of principal fiber bundles, our work can be understood as follows.
A fiber bundle  is a space consisting of a base space  (the manifold  in our paper), with at each point  a space  called the fiber at .
The bundle is defined in terms of a projection map , which determines the fibers as .
A principal bundle is a fiber bundle where the fiber  carries a transitive and free right action of a group  (the structure group).

One can think of the fiber  of a principal bundle as a (generalized) space of frames at .
Due to the free and transitive action of  on , we have that  is isomoprhic to  as a -space, meaning that it looks like  except that it does not have a distinguished origin or identity element as  does (i.e. there is no natural choice of frame).

A gauge transformation is then defined as a principal bundle automorphism, i.e. a map from  that maps fibers to fibers in a -equivariant manner.
Sometimes the automorphism is required to fix the base space, i.e. project down to the identity map via .
Such a -automorphism will map each fiber onto itself, so it restricts to a -space automorphism on each fiber.

Given a principal bundle  and a vector space  with representation  of , we can construct the associated bundle , whose elements are the equivalence classes of the following equivalence relation on :

The associated bundle is a fiber bundle over the same base space as , with fiber isomorphic to .

A (matter) field is described as a section of the associated bundle , i.e. a map 
 that satisfies .
Locally, one can describe a section as a function  (as we do in the paper), but globally this is not possible unless the bundle is trivial.

The group of automorphisms of  (gauge transformations) acts on the space of fields (sections of the associated bundle).
It is this group that we wish to be equivariant to.

From this mathematical perspective, our work amounts to replacing the principal  bundle\footnote{It is more common to use the letter  for the supergroup and  for the subgroup, but that leads to a principal -bundle , which is inconsistent with the main text, where we use a principal  bundle. So we swap  and  here.}  used in the work on regular and steerable G-CNNs of \citet{cohenGeneralTheoryEquivariant2018,cohenIntertwinersInducedRepresentations2018}, by another principal  bundle, namely the frame bundle of .
Hence, this general theory can describe in a unified way the most prominent and geometrically natural methods of geometrical deep learning \cite{masciGeodesicConvolutionalNeural2015, boscainiLearningShapeCorrespondence2016}, as well as all G-CNNs on homogeneous spaces.

Indeed, if we build a gauge equivariant CNN on a homogeneous space  (e.g. the sphere ), it will (under mild conditions) automatically be equivariant to the left action of  also.
To see this, note that the left action of  on itself (the total space of the principal  bundle) can be decomposed into an action on the base space  (permuting the fibers), and an action on the fibers (cosets) that factors through  (see e.g. Sec. 2.1 of \cite{cohenIntertwinersInducedRepresentations2018}).
The action on the base space preserves the local neighbourhoods from which we compute filter responses, and equivariance to the action of  is ensured by the kernel constraint. 
Since G-CNNs \cite{cohenGeneralTheoryEquivariant2018} and gauge equivariant CNNs employ the most general equivariant map, we conclude that they are indeed the same, for bundles .
Thus, ``gauge theory is all you need''.
(We plan to expand this argument in a future paper)

Most modern theories of physics are gauge theories, meaning they are based on this mathematical framework.
In such theories, any construction is required to be gauge invariant (i.e. the coefficients must be gauge equivariant), for otherwise the predictions will depend on the way in which we choose to represent physical quantities.
This logic applies not just to physics theories, but, as we have argued in the paper, also to neural networks and other models used in machine learning.
Hence, it is only natural that the same mathematical framework is applicable in both fields.

\section{Deriving the kernel constraint}

The gauge equivariant convolution is given by


Under a gauge transformation, we have:


It follows that  is unchanged, because .
Substituting the rest in the convolution equation, we find

Now if  (i.e.  satisfies the kernel constraint), then we get

i.e.  transforms as a -field under gauge transformations.


\section{Additional information on experiments}

\subsection{MNIST experiments}

Our main model consists of  convolution layers and  linear layers.
The first layer is a scalar-to-regular gauge equivariant convolution layer, and the following  layers are regular-to-regular layers.
These layers have  output channels, and stride , respectively.

In between convolution layers, we use batch normalization \cite{ioffeBatchNormalizationAccelerating2015} and ReLU nonlinearities.
When using batch normalization, we average over groups of  feature maps, to make sure the operation is equivariant.
Any pointwise nonlinearity (like ReLU) is equivariant, because we use only trivial and regular representations realized by permutation matrices.

After the convolution layers, we perform global pooling over spatial and orientation channels, yielding an invariant representation.
We map these through 3 FC layers (with  channels) before applying softmax.

The other models are obtained from this one by replacing the convolution layers by scalar-to-regular + orientation pooling (S2R) or scalar-to-scalar (S2S) layers, or by disabling G-padding (NP) and/or kernel expansion (NE), always adjusting the number of channels to keep the number of parameters roughly the same.

The Spherical CNN (S2CNN) is obtained from the R2R model by replacing the S2R and R2R layers by spherical and  convolution layers, respectively, keeping the number of channels and strides the same.
The Spherical CNN uses a different grid than the Icosahedral CNN, so we adapt the resolution / bandwidth parameter  to roughly match the resolution of the Icosahedral CNN.
We use , to get a spherical grid of size .
Note that this grid has higher resolution at the poles, and lower resolution near the equator, which explains why the S2CNN performs a bit worse when trained on rotated data instead of digits projected onto the north-pole.
To implement strides, we reduce the output bandwidth by  at each layer with stride.

The spherical convolution takes a scalar signal on the sphere as input, and outputs scalar signals on , which is analogous to a regular field over the sphere.
 convolutions are analogous to  layers.
We note that this is a stronger Spherical CNN architecture than the one used by \cite{cohenSphericalCNNs2018}, which achieves only  accuracy on spherical MNIST.

The models were trained for  epochs, or  epoch of the  augmented dataset (where each instance is transformed by each icosahedron symmetry , or by a random rotation ).



\subsection{Climate experiments}

For the climate experiments, we used a U-net with regular-to-regular convolutions. 
The first layer is a scalar-to-regular convolution with 16 output channels.
The downsampling path consists of  regular-to-regular layers with stride , and  output channels.
The downsampling path takes as input a signal with resolution  (i.e.  pixels), and outputs one at  (i.e.  pixels).

The decoder is the reverse of the encoder in terms of resolution and number of channels.
Upsampling is performed by bilinear interpolation (which is exactly equivariant), before each convolution layer (which uses stride 1).
As usual in the U-net architecture, each layer in the upsampling path takes as input the output of the previous layer, as well as the output of the encoder path at the same resolution.

Each convolution layer is followed by equivariant batchnorm and ReLU.

The model was trained for  epochs with batchsize .


\subsection{2D-3D-S experiments}

For the 2D-3D-S experiments, we used a residual U-Net with the following architecture.

The input layer is a scalar-to-regular layer with 8 channels, followed by batchnorm and relu.
Then we apply 4 residual blocks with 16, 32, 64, 64 output channels, each of which uses stride=2.
In the upsampling stream, we use 32, 16, 8, 8 channels, for the residual blocks, respectively.
Each upsampling layer receives input from the corresponding downsampling layer, as well as the previous layer.
Upsampling is performed using bilinear interpolation, and downsampling by hexagonal max pooling.

The input resolution is , which is downsampled to  by the downsampling stream.

Each residual block consists of a convolution, batchnorm, skipconnection, and ReLU.


\section{Computational complexity analysis of Spherical and Icosahedral CNNs}

One of the primary motivations for the development of the Icosahedral CNN is that it is faster and more scalable than Spherical CNNs as originally proposed.
The Spherical CNN as implemented by \cite{cohenSphericalCNNs2018} uses feature maps on the sphere  and rotation group  (the latter of which can be thought of a regular field on the sphere), sampled on the SOFT grids defined by \cite{kostelecSOFTFourierTransforms2007}, which have shape  and , respectively (here  is the bandwidth / resolution parameter).
Specifically, the grid points are:

where  form a spherical grid and  form an  grid (for ).
These grids have two downsides.

Firstly, because the SOFT grid consists of equal-lattitude rings with a fixed number of points (2B), the spatial density of points is inhomogeneous, with a higher concentration of points near the poles.
To get a sufficiently high sampling near the equator, we are forced to oversample the poles, and thus waste computational resources.
For almost all applications, a more homogeneous grid is more suitable.

The second downside of the SOFT grid on  is that the spatial resolution (; ) and angular resolution (; ) are both coupled to the same resolution / bandwidth parameter .
Thus, as we increase the resolution of the spherical image, the number of rotations applied to each filter is increased as well, which is undesirable.

The grid used in the Icosahedral CNN addresses both concerns.
It is spatially very homogeneous, and we apply the filters in  orientations, regardless of spatial resolution.

The generalized FFT algorithm used by \cite{cohenGeneralTheoryEquivariant2018} only works on the SOFT grid.
Generalized FFTs for other grids exist \cite{kunisFastSphericalFourier2003}, but are harder to implement.
Moreover, although the (generalized) FFT can improve the asymptotic complexity of convolution for large input signals, the FFT-based convolution actually has worse complexity if we assume a fixed filter size.
That is, the  convolution (used in most layers of a typical Spherical CNN) has complexity  which compares favorably to the naive  spatial implementation.
However, if we use filters with a fixed (and usually small) size, the complexity of a naive spatial implementation reduces to , which is slightly better than the FFT-based implementation.
Furthermore, because the Icosahedral CNN uses a fixed number of orientations per filter (i.e. ), its computational complexity is even better: it is linear in the number of pixels of the grid, and so comparable to  for the SOFT grid.

The difference in complexity is clearly visible in Figures \ref{fig:compute_comparison} and \ref{fig:memory_comparison}, below.
On the horizonal axis, we show the grid resolution  for the icosahedral grid  (for the spherical CNN, we a SOFT grid with roughly the same number of spatial points).
On the vertical axis, we show the amount of wallclock time (averaged over 100 runs) and memory required to run an  convolution (S2CNN) or a regular-to-regular gauge equivariant convolution (IcoNet) at that resolution.
Note that since the number of grid pionts is exponential in , and we use a logarithmic vertical axis, the figures can be considered log-log plots.
Both plots were generated by running a single regular to regular convolution layer at the corresponding resolution  with  input and output channels.
For a fair comparison with IcoCNNs we chose filter grid parameters so3\_near\_identity\_grid(n\_alpha=6, max\_beta=np.pi/16, n\_beta=1, max\_gamma=2*np.pi, n\_gamma=6) for the spherical convolution layer.
To guarantee a full GPU utilization, results were measured on an as large as possible batch size per datapoint and subsequently normalized by that batch size.

\begin{figure}[h!]
    \centering
    \includegraphics[width=8cm]{figures/compute_comparison.png}
    \caption{Comparison of computational cost (in wallclock time) of Icosahedral CNNs (IcoNet) and Spherical CNNs (S2CNN, \cite{cohenSphericalCNNs2018}), at increasing grid resolution .}
    \label{fig:compute_comparison}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=8cm]{figures/memory_comparison.png}
    \caption{Comparison of memory usage of Icosahedral CNNs (IcoNet) and Spherical CNNs (S2CNN, \cite{cohenSphericalCNNs2018}), at increasing grid resolution .}
    \label{fig:memory_comparison}
\end{figure}

As can be seen in Figure \ref{fig:compute_comparison}, the computational cost of running the S2CNN dramatically exceeds the cost of running the IcoCNN, particularly at higher resolutions.
We did not run the spherical CNN beyond resolution , because the network would not fit in GPU memory even when using batch size .

As shown in Figure \ref{fig:memory_comparison}, the Spherical CNN at resolution  uses about 10GB of memory, whereas the Icosahedral CNN uses only about 1GB.
Since we used the maximum batch size with subsequent normalization for each resolution the reported memory consumption mainly reflects the memory cost of the feature maps, not the constant memory cost of the filter banks.

Aside from the theoretical asymptotic complexity, the actual computational cost depends on important implementation details.
Because the heavy lifting of the Icosahedral CNN is all done by a single conv2d call, our method benefits from the extensive optimization of, and hardware support for this operation.
By contrast, the generalized FFT used in the original Spherical CNN uses a conventional FFT, as well as matrix multiplcations with spectral matrices of size  (the  spectrum is matrix-valued, instead of the scalar valued spectrum for commutative groups).
Implementing this in a way that is fast in practice is more challenging.

A final note on scalability.
For some problems, such as the analysis of high resolution global climate or weather data, it is unlikely that even a single feature map will fit in memory at once on current or near-term future hardware.
Hence, it may be useful to split large feature maps into local charts, and process each one on a separate compute node.
For the final results to be globally consistent (so that each compute node makes equivalent predictions for points in the overlap of charts), gauge equivariance is indispensable.


\section{Details on G-Padding}

In a conventional CNN, one has to pad the input feature map in order to compute an output of the same size.
Although the icosahedron itself does not have a boundary, the charts do, and hence require padding before convolution.
However, in order to faithfully simulate convolution on the icosahedron via convolution in the charts, the padding values need to be copied from another chart instead of e.g. padding by zeros.
In doing so, a gauge transformation may be required.

To see why, note that the conv2d operation, which we use to perform the convolution in the charts, implicitly assumes that the signal is expressed relative to a fixed global gauge in the plane, namely the frame defined by the x and y axes.
This is because the filters are shifted along the x and y directions by conv2d, and as they are shifted they are not rotated.
So the meaning of ``right'' and ``up'' doesn't change as we move over the plane; the local gauge at each position is aligned with the global x and y axes.

Hence, it is this global gauge that we must use inside the charts shown in Figure 4 (right) of the main paper.
It is important to note that although all frames have the same numerical expression  relative to the x and y axes, the corresponding frames on the icosahedron itself are different for different charts.
Since feature vectors are represented by coefficients that have a meaning only relative to a frame, they have a different numerical expression in different charts in which they are contained.
The numerical representations of a feature vector in two charts are related by a gauge transformation.

To better understand the gauge transformation intuitively, consider a pixel  on a colored edge in Fig. 4 of the main paper, that lies in multiple charts. 
Now consider a vector attached at this pixel (i.e. in ), pointing along the colored edge.
Since the colored edge may have different orientations when pictured in different charts, the vector (which is aligned with this edge) will also point in different directions in the charts, when the charts are placed on the plane together as in Figure 4.
More specifically, for the choice of charts we have made, the difference in orientation is always one ``click'', i.e. a rotation by plus or minus .
This is the gauge transformation , which describes the transformation at  when switching between chart  and .

The transformation  acts on the feature vector at  via the matrix , where  is the representation of  associated with the feature space under consideration.
In this work we only consider two kinds of representations: scalar features with , and regular features with  equal to the regular representation:

That is, a cyclic permutation of 6 elements.
Since  is a generator of , the value of  at the other group elements is determined by this matrix: .
If the feature vector consists of multiple scalar or regular features, we would have a block-diagonal matrix .

We implement G-padding by indexing operations on the feature maps.
For each position  to be padded, we pre-compute , which can be  or  or .
We use these to precompute four indexing operations (for the top, bottom, left and right side of the charts).
 

\end{document}