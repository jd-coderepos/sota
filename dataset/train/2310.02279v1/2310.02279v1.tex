
\documentclass{article} \usepackage{iclr2024_coNFErence,times}



\usepackage{amsmath,amsfonts,bm}

\newcommand{\figleft}{{\em (Left)}}
\newcommand{\figcenter}{{\em (Center)}}
\newcommand{\figright}{{\em (Right)}}
\newcommand{\figtop}{{\em (Top)}}
\newcommand{\figbottom}{{\em (Bottom)}}
\newcommand{\captiona}{{\em (a)}}
\newcommand{\captionb}{{\em (b)}}
\newcommand{\captionc}{{\em (c)}}
\newcommand{\captiond}{{\em (d)}}

\newcommand{\newterm}[1]{{\bf #1}}


\def\figref#1{figure~\ref{#1}}
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
\def\secref#1{section~\ref{#1}}
\def\Secref#1{Section~\ref{#1}}
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
\def\eqref#1{equation~\ref{#1}}
\def\Eqref#1{Equation~\ref{#1}}
\def\plaineqref#1{\ref{#1}}
\def\chapref#1{chapter~\ref{#1}}
\def\Chapref#1{Chapter~\ref{#1}}
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
\def\algref#1{algorithm~\ref{#1}}
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
\def\partref#1{part~\ref{#1}}
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}

\def\eps{{\epsilon}}


\def\reta{{\textnormal{$\eta$}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}

\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

\newcommand{\pdata}{p_{\rm{data}}}
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}

\newcommand{\laplace}{\mathrm{Laplace}} 

\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}
\newcommand{\smpara}[1]{\left({#1}\right)}
\newcommand{\midpara}[1]{\left[{#1}\right]}
\newcommand{\bigpara}[1]{\left\{{#1}\right\}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\iid}{\overset{\mathrm{iid}}{\sim}}

\usepackage{tikz}
\newcommand{\comp}[2]{\overset{#2}{\underset{{#1}}{\TikCircle}}}
\newcommand{\inner}[2]{\langle#1,#2\rangle}

\newcommand{\grad}[1]{{\nabla_{\bm{#1}}}}
\renewcommand{\div}[1]{{\textup{div}_{\bm{#1}}}}
\newcommand{\parents}{Pa} 

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Tr}{Tr}
\let\ab\allowbreak


\newenvironment{myproof}[2]{\paragraph{\textit{Proof of {#1} {#2}. }}}{\hfill$\blacksquare$}

\newcommand\TikCircle[1][2.5]{\tikz[baseline=-#1]{\draw[thick](0,0)circle[radius=#1mm];}}
\usepackage{xcolor}



\newcommand{\se}[1]{\textcolor{magenta}{[SE: #1]}}



\newcommand{\jcc}[1]{\textcolor{black}{[JC: #1]}}
\newcommand{\jc}[1]{{\color{black}{{#1}}}}
\def\eqref#1{(\ref{#1})}
\newcommand{\djk}[1]{{\color{black}{{#1}}}}
\def\eqref#1{(\ref{#1})}
%
 
\usepackage{svg}
\usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}    \usepackage{hyperref}       \usepackage{url}            \usepackage{booktabs}       \usepackage{amsfonts}       \usepackage{nicefrac}       \usepackage{microtype}      \usepackage{xcolor, color, colortbl}         \usepackage{tikz}
\usepackage[export]{adjustbox}
\usepackage{mathtools}


\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{pifont}\usepackage{xcolor}
\usepackage{calc}
\usepackage{enumerate}
\usepackage[shortlabels]{enumitem}
\usepackage[normalem]{ulem}

\usepackage{mathtools}

\usepackage{subcaption}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{wrapfig}

\usepackage{adjustbox}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{multirow}
\usepackage{threeparttable}
\usepackage{arydshln}
\usepackage{minitoc}



\newtheorem{theorem}{Theorem}\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}{Remark}
\allowdisplaybreaks

\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newsavebox{\leftbox}
\newsavebox{\rightbox}
\newcommand{\cmark}{\ding{51}}\newcommand{\xmark}{\ding{55}}\definecolor{Gray}{gray}{0.9}
\newcommand{\mc}[2]{\multicolumn{#1}{c}{#2}}
\newcommand{\mr}[2]{\multirow{#1}{*}{#2}}
\newcommand{\cc}[1]{\cellcolor{gray!#1}}
\hypersetup{colorlinks}

\makeatletter
\def\adl@drawiv#1#2#3{\hskip.5\tabcolsep
        \xleaders#3{#2.5\@tempdimb #1{1}#2.5\@tempdimb}#2\z@ plus1fil minus1fil\relax
        \hskip.5\tabcolsep}
\newcommand{\cdashlinelr}[1]{\noalign{\vskip\aboverulesep
           \global\let\@dashdrawstore\adl@draw
           \global\let\adl@draw\adl@drawiv}
  \cdashline{#1}
  \noalign{\global\let\adl@draw\@dashdrawstore
           \vskip\belowrulesep}}
\makeatother


\title{Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion}



\author{Dongjun Kim\thanks{Equal contribution}~~\thanks{Work done during an internship at SONY AI} ~\&~Chieh-Hsin Lai$^{*}$ \\
Sony AI\\
Tokyo, Japan \\
\texttt{dongjoun57@kaist.ac.kr}, \texttt{chieh-hsin.lai@sony.com} \\
\And
Wei-Hsiang Liao~\&~Naoki Murata~\&~Yuhta Takida~\&~Toshimitsu Uesaka~\&~Yutong He \\
Sony AI \\
Tokyo, Japan \\
\AND
Yuki Mitsufuji \\
Sony AI, Sony Group Corporation \\
Tokyo, Japan \\
\AND
Stefano Ermon \\
Stanford University \\
CA, USA \\
}



\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}



\iclrfinalcopy \begin{document}


\maketitle
\doparttoc
	\parttoc

\begin{abstract}
Consistency Models (CM)~\citep{song2023consistency}
 accelerate score-based diffusion model sampling at the cost of sample quality but lack a natural way to trade-off quality for speed. To address this limitation, we propose \textbf{C}onsistency \textbf{T}rajectory \textbf{M}odel (CTM), a generalization encompassing CM and score-based models as special cases. CTM trains a single neural network that can -- in a single forward pass -- output scores (i.e., gradients of log-density) and enables unrestricted traversal between any initial and final time along the Probability Flow Ordinary Differential Equation (ODE) in a diffusion process. CTM enables the efficient combination of adversarial training and denoising score matching loss to enhance performance and achieves new state-of-the-art FIDs for single-step diffusion model sampling on CIFAR-10 (FID $1.73$) and ImageNet at $64\times64$ resolution (FID $2.06$). CTM also enables a new family of sampling schemes, both deterministic and stochastic, involving long jumps along the ODE solution trajectories. It consistently improves sample quality as computational budgets increase, avoiding the degradation seen in CM. Furthermore, CTM's access to the score accommodates all diffusion model inference techniques, including exact likelihood computation.
\end{abstract}



\section{Introduction}\label{sec:intro}


\begin{wrapfigure}{r}{0.5\textwidth}
	\vskip -0.4in
	\centering
		\centering		\includegraphics[width=\linewidth]{umbrella_ver2.pdf}
	\caption{A schematic illustration of CTM.}
	\label{fig:umbrella}
 \vskip -0.4in
\end{wrapfigure}

Deep generative models encounter distinct training and sampling challenges. Variational Autoencoder (VAE)~\citep{kingma2013auto} can be trained easily but
 may suffer from posterior collapse, resulting in blurry samples, while Generative Adversarial Network (GAN)~\citep{goodfellow2014generative} generates high-quality samples but faces training instability. Conversely, Diffusion Model (DM)~\citep{sohl2015deep,ho2020denoising, song2020score} addresses these issues by learning the score (i.e., gradient of log-density)~\citep{song2019generative}, which can generate high quality samples.
However, compared to VAE and GAN excelling at fast sampling,  DM involves a gradual denoising process that slows down sampling, requiring numerous model evaluations.

Score-based diffusion models synthesize data by solving the reverse-time (stochastic or deterministic) process corresponding to a prescribed forward process that adds noise to the data~\citep{song2019generative,song2020score}. Although advanced numerical  solvers~\citep{lu2022dpm, zhang2022fast} of Stochastic Differential Equations (SDE) or Ordinary Differential Equations (ODE) substantially reduce the required Number of Function Evaluations (NFE), 
further improvements are challenging 
due to the intrinsic discretization error present in all solvers~\citep{de2021diffusion}. Recent developments in sample efficiency thus focus on directly  estimation of the integral along the sample trajectory, amortizing the computational cost of numerical solvers.
\emph{Distillation models}~\citep{salimans2021progressive} in Figure~\ref{fig:umbrella}, exemplified by the Consistency Model (CM)~\citep{song2023consistency}, presents a promising approach for estimating the integration with a single NFE (Figure~\ref{fig:i_am_fig_1}). 
However, their generation quality does not improve as NFE increase, and there is no straightforward mechanism for balancing computational resources (NFE) with quality.

\begin{figure}[t]
 \vskip -0.05in
    \centering
    \includegraphics[width=0.85\textwidth]{fig_1_ver2.pdf}
    \caption{Training and sampling comparisons of score-based and distillation models with CTM. Score-based models exhibit discretization errors during SDE/ODE solving, while distillation models can accumulate errors in multistep sampling. CTM mitigates these issues with $\gamma$-sampling ($\gamma=0$).}
    \label{fig:i_am_fig_1}
    \vskip -0.1in
\end{figure}

\begin{wrapfigure}{r}{0.48\textwidth}
	\vskip -0.2in
	\centering
		\centering		\includegraphics[width=\linewidth]{FID_oneshot_v2.pdf}
        \vskip -0.1in
 \caption{SOTA on CIFAR-10. Closeness to the origin indicates better performance.}
	\label{fig:cifar_}
 \vskip -0.1in
\end{wrapfigure}
This paper introduces the \emph{\textbf{C}onsistency \textbf{T}rajectory \textbf{M}odel} (CTM) as a unified framework simultaneously assessing both the integrand (score function) and the integral (sample) of the Probability Flow (PF) ODE, thus bridging score-based and distillation models (Figure \ref{fig:umbrella}). CTM estimates both infinitesimal steps (score function) and long steps (integral over any time horizon) of the PF ODE from any initial condition, providing increased  flexibility at inference time. Its score evaluation capability accommodates a range of score-based sampling algorithms based on  solving differential equations~\citep{song2020score}, expanding its applicability across various domains~\citep{saharia2022palette}. In particular, CTM enables exact likelihood computation, setting it apart from previous distillation models. 
Additionally, its integral approximation capability facilitates the incorporation of distillation sampling methods~\citep{salimans2021progressive,song2023consistency} that involve long ``jumps'' along the solution trajectory. This unique feature enables a novel sampling method called \emph{$\gamma$-sampling,} which alternates forward and backward jumps along the solution trajectory, with $\gamma$ governing the level of stochasticity.


CTM's dual modeling capability for both infinitesimal and long steps of the PF ODE greatly enhances its training flexibility as well. It allows concurrent training with reconstruction loss, denoising diffusion loss, and adversarial loss within a unified framework. Notably, by incorporating CTM's training approach with $\gamma$-sampling, we achieve the new State-Of-The-Art (SOTA) performance in both density estimation and image generation for CIFAR-10~\citep{krizhevsky2009learning} (Figure~\ref{fig:cifar_}) and ImageNet~\citep{russakovsky2015imagenet} at a resolution of $64\times64$ (Table~\ref{tab:ImageNet64_baseline}).


\section{Preliminary}\label{sec:preliminary}

In DM~\citep{sohl2015deep,song2020score}, the encoder structure is formulated using a set of continuous-time random variables defined by a fixed forward diffusion process\footnote{This paper can be extended to VPSDE encoding~\citep{song2020score} with re-scaling~\citep{kim2022refining}.}, 
\begin{equation*}\label{eq:sde_forward}
    \diff\mathbf{x}_t =  \sqrt{2t} \diff\mathbf{w}_t,
\end{equation*}
initialized by the data variable, $\mathbf{x}_{0}\sim p_{\text{data}}$. A reverse-time process~\citep{anderson1982reverse} from $T$ to $0$ is established 
    $\diff\mathbf{x}_t =  - 2t \nabla\log p_t(\mathbf{x}_t)  dt + \sqrt{2t} \diff\bar{\mathbf{w}}_t$,
where $\bar{\mathbf{w}}_t$ is the standard Wiener process in reverse-time, and $p_t(\mathbf{x})$ is the marginal density of $\mathbf{x}_t$ following the forward process. The solution of this reverse-time process aligns with that of the forward-time process marginally (in distribution) when the reverse-time process is  initialized with $\mathbf{x}_{T}\sim p_{T}$. The deterministic counterpart of the reverse-time process, called the PF ODE~\cite{song2020score}, is given by \begin{equation*}\frac{\diff \mathbf{x}_t}{\diff t} =  -t \nabla \log p_t (\mathbf{x}_t)=\frac{\mathbf{x}_{t}-\mathbb{E}_{p_{t0}(\mathbf{x}\vert\mathbf{x}_{t})}[\mathbf{x}\vert\mathbf{x}_{t}]}{t},
\end{equation*}
where $p_{t0}(\mathbf{x}\vert\mathbf{x}_{t})$ is the probability distribution of the solution of the reverse-time stochastic process from time $t$ to zero, initiated from $\mathbf{x}_{t}$. Here, $\mathbb{E}_{p_{t0}(\mathbf{x}\vert\mathbf{x}_{t})}[\mathbf{x}\vert\mathbf{x}_{t}]$ is the denoiser function~\citep{efron2011tweedie}, 
an alternative expression for the score function $\nabla\log{p_{t}(\mathbf{x}_{t})}$. For notational simplicity, we omit $p_{t0}(\mathbf{x}\vert\mathbf{x}_{t})$, a subscript in the expectation of the denoiser, throughout the paper. 

In practice, the denoiser $\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{t}]$ is approximated using a neural network $D_{\bm{\phi}}$, obtained by minimizing the Denoising Score Matching (DSM)~\citep{vincent2011connection, song2020score} loss 
$\mathbb{E}_{\mathbf{x}_{0},t,p_{0t}(\mathbf{x}\vert\mathbf{x}_{0})}[\Vert \mathbf{x}_{0}-D_{\bm{\phi}}(\mathbf{x},t) \Vert_{2}^{2}]$, where $p_{0t}(\mathbf{x}\vert\mathbf{x}_{0})$ is the transition probability from time $0$ to $t$, initiated with $\mathbf{x}_{0}$. With the approximated denoiser, the empirical PF ODE is given by
\begin{align*}
    \frac{\diff \mathbf{x}_{t}}{\diff {t}} =\frac{\mathbf{x}_{{t}}-D_{\bm{\phi}}(\mathbf{x}_{t},{t}) }{{t}}.
\end{align*}
Sampling from DM involves solving the PF ODE, equivalent to computing the integral
\begin{align}\label{eq:int_target}
    \int_{T}^{0}\frac{\diff\mathbf{x}_{t}}{\diff t}\diff t=\int_{T}^{0}\frac{\mathbf{x}_{{t}}-D_{\bm{\phi}}(\mathbf{x}_{t},{t}) }{{t}}\diff t\iff \mathbf{x}_{0}=\mathbf{x}_{T}+\int_{T}^{0}\frac{\mathbf{x}_{{t}}-D_{\bm{\phi}}(\mathbf{x}_{t},{t}) }{{t}}\diff t,
\end{align}
where $\mathbf{x}_{T}$ is sampled from a prior distribution $\pi$ approximating $p_T$. 
Decoding strategies of DM primarily fall into two categories: \emph{score-based sampling} with time-discretized numerical integral solvers, and \emph{distillation sampling} where a neural network directly estimates the integral.


\paragraph{Score-based Sampling}
Any off-the-shelf ODE solver, denoted as $\texttt{Solver}(\mathbf{x}_{T},T,0;\bm{\phi})$ (with an initial value of $\mathbf{x}_T$ at time $T$ and ending at time $0$), can be directly applied to solve Eq.~\eqref{eq:int_target}~\citep{song2020score}. For instance, DDIM~\citep{song2020denoising} corresponds to a 1st-order Euler solver, while EDM~\citep{karras2022elucidating} introduces a 2nd-order Heun solver. Despite recent advancements in numerical solvers~\citep{lu2022dpm, zhang2022fast}, further improvements may be challenging due to the inherent discretization error present in all solvers~\citep{de2021diffusion}, ultimately limiting the sample quality obtained with few NFEs.

\paragraph{Distillation Sampling}
Distillation models~\citep{salimans2021progressive,meng2023distillation} successfully amortize the sampling cost by directly estimating the integral of Eq.~\eqref{eq:int_target} with a single neural network evaluation. However, their multistep sampling approach~\citep{song2023consistency} exhibits degrading sample quality with increasing NFE, lacking a clear trade-off between computational budget (NFE) and sample fidelity. Furthermore, multistep sampling is not deterministic, leading to uncontrollable sample variance.
We refer to Appendix~\ref{sec:related_work} for a thorough literature review.

\section{CTM: An Unification of Score-based and Distillation Models}
To address the challenges in both score-based and distillation samplings, we introduce the Consistency Trajectory Model (CTM), which seamlessly integrates both decoding strategies. Consequently, our model is versatile and can perform sampling through either SDE/ODE solving or direct prediction of intermediate points along the PF ODE trajectory.


\subsection{Decoder Parametrization of Consistency Trajectory Models}\label{sec:motivation}

CTM predicts both infinitesimal changes and intermediate points of the PF ODE trajectory. Specifically, we define $G(\mathbf{x}_{t},t,s)$ as the solution of the PF ODE from initial time $t$ with an initial condition $\mathbf{x}_t$ to final time $s\le t$:
\begin{align}\label{eq:oracle_sol}
    G(\mathbf{x}_{t},t,s)&:=\mathbf{x}_{t}+\int_{t}^{s}\frac{\mathbf{x}_{u}-\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{u}]}{u}\diff u.
\end{align}
$G$ can access any intermediate point along the trajectory by varying final time $s$. However, with the current expression of $G$, the infinitesimal change needed to recover the denoiser information (the integrand) can only be obtained by evaluating the $s$-derivative at time $t$, $\frac{\partial}{\partial s}G(\mathbf{x}_{t},t,s)\vert_{s=t}$. Therefore, we introduce a dedicated expression for $G$ using an auxiliary function $g$ to enable easy access to both the integral via $G$ and the integrand via $g$ with Lemma~\ref{th:unification}. 

\begin{lemma}[Unification of score-based and distillation models]\label{th:unification} Suppose that the score satisfies $\sup_{\mathbf{x}}\int_{0}^{T}\norm{\nabla\log p_u(\mathbf{x})}_2 \diff u <\infty$. 
    The solution, $G(\mathbf{x}_{t},t,s)$, defined in Eq.~\eqref{eq:oracle_sol} can be expressed as:
    \begin{align*}
        G(\mathbf{x}_{t},t,s)=\frac{s}{t}\mathbf{x}_{t}+\Big(1-\frac{s}{t}\Big)g(\mathbf{x}_{t},t,s) \,\,\text{ with  }\,\, g(\mathbf{x}_{t},t,s)=\mathbf{x}_{t}+\frac{t}{t-s}\int_{t}^{s}\frac{\mathbf{x}_{u}-\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{u}]}{u}\diff u.
    \end{align*}
    Here, $g$ satisfies:
    \begin{itemize}
        \item When $s=0$, $G(\mathbf{x}_{t},t,0)=g(\mathbf{x}_{t},t,0) $ is the solution of PF ODE at $s=0$, initialized at $\mathbf{x}_t$. 
        \item As $s\rightarrow t$, $g(\mathbf{x}_{t},t,s)\rightarrow \mathbb{E}[\mathbf{x}\vert\mathbf{x}_{t}]$. Hence, $g$ can be defined at $s=t$ by its limit: $g(\mathbf{x}_{t},t,t):=\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{t}]$. \end{itemize}
\end{lemma}

\begin{wrapfigure}{r}{0.3\textwidth}
	\vskip -0.12in
	\centering
	\includegraphics[width=\linewidth]{s_t_plot_ver2.pdf}
	\caption{Learning objectives of Score-based ($t=s$ line), distillation ($s=0$ line), and CTM (upper triangle).}
	\label{fig:s_t_plot}
  \vskip -0.5in
\end{wrapfigure}
Indeed, the $G$'s expression in Lemma~\ref{th:unification} is naturally linked to the Taylor approximation to the integral:
\begin{align*}
    G(\mathbf{x}_{t},t,s)&= \mathbf{x}_{t}+\bigg[(s-t)\frac{\mathbf{x}_{t}-\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{t}]}{t}+\mathcal{O}\big(\abs{t-s}^2\big)\bigg]
\\&=\frac{s}{t}\mathbf{x}_{t}+\Big(1-\frac{s}{t}\Big)
    \big[\underset{=g(\mathbf{x}_t, t, s)}{\underbrace{\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{t}]+\mathcal{O}\left(\abs{t-s}\right)}}\big],
\end{align*}
for any $s\leq t$. 
Here, it is evident that $g$ includes all residual terms in Taylor expansion, which turns to be the discretization error in sampling. The goal of CTM is to approximate this $g$-function using a neural network $g_{\bm{\theta}}$ and estimate the solution trajectory with the parametrization inspired by Lemma~\ref{th:unification} as follows:
\begin{align*}G_{\bm{\theta}}(\mathbf{x}_{t},t,s):=\frac{s}{t}\mathbf{x}_{t}+\Big(1-\frac{s}{t}\Big)g_{\bm{\theta}}(\mathbf{x}_{t},t,s),
\end{align*}
We remark that this parametrization satisfies the initial condition $G_{\bm{\theta}}(\mathbf{x}_{t},t,t)=\mathbf{x}_{t}$ for free, leading to improved training stability\footnote{Ensuring the initial condition's satisfaction is crucial for stable training. Directly estimating $G$ with a network leads to rapid divergence, causing instability as the network output may deviate arbitrarily from the initial condition.}. Appendix~\ref{sec:parametrization} offers further insights into this parametrization.


\subsection{CTM Training}


To achieve trajectory learning, CTM should match the model prediction to the ground truth $G$ by
\begin{align*}
    G_{\bm{\theta}}(\mathbf{x}_{t},t,s)\approx G(\mathbf{x}_{t},t,s),
\end{align*}
for any $s\le t$. We opt to approximate $G$ by solving the empirical PF ODE with a pre-trained score model $D_{\bm{\phi}}$. Our neural network is then trained to align with \djk{the reconstruction}:
\begin{align}\label{eq:global}
    G_{\bm{\theta}}(\mathbf{x}_{t},t,s)\approx \texttt{Solver}(\mathbf{x}_{t},t,s;\bm{\phi}).
\end{align}

In a scenario with no ODE discretization and  no score approximation errors, $\texttt{Solver}$ perfectly reconstructs the PF ODE trajectory, and comparing the prediction and reconstruction in Eq.~\eqref{eq:global} leads $G_{\bm{\theta}^{*}}(\mathbf{x}_{t},t,s)=G(\mathbf{x}_{t},t,s)$ at optimal $\bm{\theta}^{*}$, given sufficient network flexibility. The same conclusion holds by matching the local consistency:
\begin{align}\label{eq:local}
    G_{\bm{\theta}}(\mathbf{x}_{t},t,s)\approx G_{\texttt{sg}(\bm{\theta})}(\texttt{Solver}(\mathbf{x}_{t},t,t-\Delta t;\bm{\phi}),t-\Delta t,s),
\end{align}
where $\texttt{sg}(\cdot)$ is stop-gradient. With the initial condition ($\mathbf{G}_{\bm{\theta}}(\mathbf{x}_{t},t,t)=\mathbf{x}_{t}$) satisfied, matching Eq.~\eqref{eq:local} avoids collapsing to the trivial solution (Proposition~\ref{th:ptw_traj_distill} in Appendix~\ref{sec:convergence_analysis}).

\begin{wrapfigure}{r}{0.33\textwidth}
 \vskip -0.2in
	\centering
		\includegraphics[width=\linewidth]{ctm_model_ver2.pdf}
	\caption{\djk{An illustration of CTM prediction and target at time $s$ with an initial value $\mathbf{x}_t$.}}
	\label{fig:ill_models}
  \vskip -0.3in
\end{wrapfigure}
To estimate the entire solution trajectory with higher precision, we introduce \emph{soft matching}, illustrated in Figure~\ref{fig:ill_models}, ensuring consistency between prediction from $\mathbf{x}_{t}$ and the prediction from $\texttt{Solver}(\mathbf{x}_t, t,u;\bm{\phi})$ for any $u\in[s,t)$:
\begin{align}\label{eq:soft}
    G_{\bm{\theta}}(\mathbf{x}_{t},t,s)\approx G_{\texttt{sg}(\bm{\theta})}\big(\texttt{Solver}(\mathbf{x}_t, t,u;\bm{\phi}),u,s\big).\end{align}
This soft matching spans two frameworks:
\begin{itemize}
\item As $u= s$, Eq.~\eqref{eq:global} enforces \emph{global consistency matching}, i.e., a reconstruction loss.
\item As $u= t-\Delta t$, Eq.~\eqref{eq:local} is \textit{local consistency matching}. Additionally, if $s=0$, it recovers CM's distillation loss.
\end{itemize}

To quantify the dissimilarity between $G_{\bm{\theta}}(\mathbf{x}_{t},t,s)$ and $G_{\texttt{sg}(\bm{\theta})}(\texttt{Solver}(\mathbf{x}_t, t,u;\bm{\phi}),u,s)$ and enforce Eq.~\eqref{eq:soft}, we could use either  distance in pixel space or in feature space. However, the pixel distance may overemphasize the distance at large $s$ due to the diffusion scale, requiring time-weighting adjustments. Furthermore, feature distance requires a time-conditional feature extractor, which can be expensive to train. Hence, we propose to use a feature distance $d$ in clean data space by comparing
\begin{align}
    \mathbf{x}_{\text{est}}(\mathbf{x}_{t},t,s)&:=G_{\texttt{sg}(\bm{\theta})}\Big(G_{\bm{\theta}}(\mathbf{x}_{t},t,s),s,0\Big)\nonumber
    \\ \mathbf{x}_{\text{target}}(\mathbf{x}_{t},t,u,s)&:=G_{\texttt{sg}(\bm{\theta})}\Big(G_{\texttt{sg}(\bm{\theta})}\big(\texttt{Solver}(\mathbf{x}_t, t,u;\bm{\phi}),u,s\big),s,0\Big)\label{eq:target}.
\end{align}
CTM loss is defined as
\begin{align}\label{eq:ctm_loss}
    \mathcal{L}_{\text{CTM}}(\bm{\theta};\bm{\phi})&:=\mathbb{E}_{t\in[0,T]}\mathbb{E}_{s\in[0,t]}\mathbb{E}_{u\in[s,t)}\mathbb{E}_{\mathbf{x}_{0},p_{0t}(\mathbf{x}\vert\mathbf{x}_{0})}\Big[d\big(\mathbf{x}_{\text{target}}(\mathbf{x},t,u,s),\mathbf{x}_{\text{est}}(\mathbf{x},t,s)\big)\Big],
\end{align}
which leads the model's prediction, at optimum, to match with the empirical PF ODE's solution trajectory, defined by the pre-trained DM (teacher), see Appendix~\ref{appendix:general_theory} (Propositions \ref{th:ptw_distill} and \ref{th:density_match}) for details.

\subsection{Training Consistency Trajectory Models}

Training CTM with Eq.~\eqref{eq:ctm_loss} may empirically lead inaccurate estimation of $g_{\bm{\theta}}$ when $s$ approaches $t$. This is due to the learning signal of $g_{\bm{\theta}}$ being scaled with $1-\frac{s}{t}$ by Lemma~\ref{th:unification}, and this scale decreasing to zero as $s$ approaches $t$. Consequently, although our parametrization enables the estimation of both the trajectory and its slope, the accuracy of slope (score) estimation may be degraded. To mitigate this problem, we use Lemma~\ref{th:unification}'s conclusion that
$g(\mathbf{x}_{t},t,t)=\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{t}]$ when $t=s$ and train $g_{\bm{\theta}}$ with the DSM loss\footnote{We opt for the conventional DSM loss instead of minimizing $\mathbb{E}[\Vert D_{\bm{\phi}}(\mathbf{x}_{t},t)-g_{\bm{\theta}}(\mathbf{x}_{t},t,t)\Vert_{2}^{2}]$  with teacher score supervision, as the DSM loss's optimum can recover the true denoiser $g_{\bm{\theta}^{*}}(\mathbf{x}_{t},t,t)=\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{t}]$, whereas teacher score supervision can only reach $D_{\bm{\phi}}$ as its optimum.}
\begin{align*}\mathcal{L}_{\text{DSM}}(\bm{\theta})=\mathbb{E}_{t,\mathbf{x}_{0},\mathbf{x}_{t}\vert\mathbf{x}_{0}}[\Vert \mathbf{x}_{0}-g_{\bm{\theta}}(\mathbf{x}_{t},t,t) \Vert_{2}^{2}].
\end{align*}
Empirically, regularizing $\mathcal{L}_{\text{CTM}}$ with $\mathcal{L}_{\text{DSM}}$ improves score accuracy, which is especially important in large NFE sampling regimes.


\begin{wrapfigure}{r}{0.48\textwidth}
\vskip -0.12in
\begin{minipage}{0.48\textwidth}
\begin{algorithm}[H]
    \centering
    \caption{CTM Training}\label{alg:CTM}
    \begin{algorithmic}[1]
        \Repeat
        \State Sample $\mathbf{x}_{0}$ from data distribution
        \State Sample $\bm{\epsilon}\sim\mathcal{N}(0,I)$
        \State Sample $t\in[0,T]$, $s\in[0,t]$, $u\in[s,t)$
        \State Calculate $\mathbf{x}_{t}=\mathbf{x}_{0}+t\bm{\epsilon}$
        \State Calculate $\texttt{Solver}(\mathbf{x}_t, t,u;\bm{\phi})$
        \State Update $\bm{\theta}\leftarrow\bm{\theta}-\frac{\partial}{\partial\bm{\theta}}\mathcal{L}(\bm{\theta},\bm{\eta})$
        \State Update $\bm{\eta}\leftarrow \bm{\eta}+\frac{\partial}{\partial\bm{\eta}}\mathcal{L}_{\text{GAN}}(\bm{\theta},\bm{\eta})$
        \Until {converged}
    \end{algorithmic}
\end{algorithm}
\end{minipage}
\end{wrapfigure}
On the other hand, CTM, distilling from the teacher model, is constrained by the teacher's $D_{\bm{\phi}}$ performance. This challenge can be mitigated with adversarial training to improve trajectory estimation. The one-step generation of CTM enables us to calculate the adversarial loss efficiently, in the similar way of conventional GAN training: 
\begin{align*}
    \mathcal{L}_{\text{GAN}}(\bm{\theta},\bm{\eta})&=\mathbb{E}_{p_{\text{data}}(\mathbf{x}_{0})}[\log{d_{\bm{\eta}}(\mathbf{x}_{0})}]\\
    &\quad+\mathbb{E}_{t,\mathbf{x}_{t}}\big[\log{\big(1-d_{\bm{\eta}}(\mathbf{x}_{\text{est}})\big)}\big],
\end{align*}
where $d_{\bm{\eta}}$ is a discriminator. This adversarial training allows \emph{the student model (CTM) to beat the teacher model (DM)}. To summarize, CTM allows the integration of  reconstruction-based CTM loss, diffusion loss, and adversarial loss
\begin{align}\label{eq:ultimate_loss}
    \mathcal{L}(\bm{\theta},\bm{\eta}):=\mathcal{L}_{\text{CTM}}(\bm{\theta};\bm{\phi})+\lambda_{\text{DSM}}\mathcal{L}_{\text{DSM}}(\bm{\theta})+\lambda_{\text{GAN}}\mathcal{L}_{\text{GAN}}(\bm{\theta},\bm{\eta}),
\end{align}
in a single training framework, by optimizing $\min_{\bm{\theta}}\max_{\bm{\eta}}\mathcal{L}(\bm{\theta},\bm{\eta})$. Here, $\lambda_{\text{DSM}}\geq 0$ and $\lambda_{\text{GAN}}\geq 0$ are the weighting functions, see Algorithm~\ref{alg:CTM}.

\section{Sampling with  CTM}\label{sec:gamma-sample}


CTM enables score evaluation through $g_{\bm{\theta}}(\bm{x}_t, t, t)$, supporting standard score-based sampling with ODE/SDE solvers. In high-dimensional image synthesis, as shown in Figure~\ref{fig:sample_comparison}'s left two columns, CTM performs comparably to EDM using Heun's method as a PF ODE solver.


\begin{wrapfigure}{r}{0.63\textwidth}
	\vskip -0.26in
	\centering
	\includegraphics[width=\linewidth]{Cat_model_comparison_v6.pdf}
 \vskip -0.05in
	\caption{Comparison of score-based models (EDM), distillation models (CM), and CTM with various sampling methods and NFE trained on AFHQ-cat~\citep{choi2020stargan} $256\times256$.}
	\vskip -0.2in
	\label{fig:sample_comparison}
\end{wrapfigure}
CTM additionally enables time traversal along the solution trajectory, allowing for the newly introduced \emph{$\gamma$-sampling} method, refer to Algorithm~\ref{alg:gamma}  and Figure~\ref{fig:gamma_sampling}. Suppose the sampling timesteps are $T=t_0>\cdots>t_N=0$. With $\mathbf{x}_{t_0}\sim\pi$, where $\pi$ is the prior distribution, $\gamma$-sampling denoises $\mathbf{x}_{t_{0}}$ to time $\sqrt{1-\gamma^{2}}t_{1}$ with $G_{\bm{\theta}}(\mathbf{x}_{t_{0}},t_{0},\sqrt{1-\gamma^{2}}t_{1})$, and perturb this denoised sample with forward diffusion to the noise level at time $t_{1}$. It iterates this back-and-forth traversal until reaching to time $t_N=0$.

Our $\gamma$-sampling is a new distillation sampler that unifies previously proposed sampling techniques, including distillation sampling and score-based sampling.


\begin{figure}[t]
	\centering
	\begin{subfigure}{0.31\linewidth}
		\centering
		\includegraphics[width=\linewidth]{gamma_1.pdf}
		\subcaption{$\gamma=1$ (Fully stochastic)}
	\end{subfigure}
	\begin{subfigure}{0.33\linewidth}
		\centering
		\includegraphics[width=\linewidth]{gamma_mid.pdf}
		\subcaption{$1>\gamma>0\qquad\quad$}
	\end{subfigure}	
 	\begin{subfigure}{0.32\linewidth}
		\centering
		\includegraphics[width=\linewidth]{gamma_0.pdf}
		\subcaption{$\gamma=0$ (Deterministic)}
	\end{subfigure}
	\caption{Illustration of $\gamma$-sampling with varying $\gamma$ value. It denoises with the network evaluation and iteratively diffuses the sample in reverse by $(t_{n}\xrightarrow{\text{Denoise}} \sqrt{1-\gamma^{2}}t_{n+1}\xrightarrow{\text{Noisify}} t_{n+1})_{n=0}^{N-1}$.}
    \label{fig:gamma_sampling}
\end{figure}

\begin{itemize}
\item Figure~\ref{fig:gamma_sampling}-(a): When $\gamma=1$, it coincides to the multistep sampling introduced in CM, which is fully stochastic and results in semantic variation when NFE changes, e.g., compare samples of NFE 4 and 40 with the deterministic sample of NFE 1 in the third column of Figure~\ref{fig:sample_comparison}. With the fixed $\mathbf{x}_{T}$, CTM reproduces CM's samples in the fourth column of Figure~\ref{fig:sample_comparison}.

\item Figure~\ref{fig:gamma_sampling}-(c): When $\gamma=0$, it becomes the deterministic distillation sampling that estimates the solution of the PF ODE. A key distinction between the $\gamma$-sampling and score-based sampling is that CTM avoids sampling errors by directly estimating Eq.~\eqref{eq:oracle_sol}. \jc{However, score-based samplers like DDIM (1st-order Euler solver) or EDM (2nd-order Heun solver) are susceptible to discretization errors from Taylor approximation, especially with small NFE.} (the leftmost column of Figure~\ref{fig:sample_comparison}). Deterministic nature as $\gamma=0$ ensures the sample semantic preserved across NFE changes, visualized in the rightmost column of Figure~\ref{fig:sample_comparison}.

\item Figure~\ref{fig:gamma_sampling}-(b): When $0<\gamma<1$, it generalizes the EDM's stochastic sampler (Algorithm~\ref{alg:EDM}). Appendix~\ref{sec:var_bound} shows that $\gamma$-sampling's sample variances scale proportionally with $\gamma^{2}$.
\end{itemize}


The optimal choice of $\gamma$ depends on practical usage and empirical configuration~\citep{karras2022elucidating,xu2023restart}. Figure~\ref{fig:cat_stroke} demonstrates $\gamma$-sampling in stroke-based generation~\citep{meng2021sdedit}, revealing that the sampler with $\gamma=1$ leads to significant semantic deviations from the reference stroke, while smaller $\gamma$ values yield closer semantic alignment and maintain high fidelity. In contrast, Figure~\ref{fig:sampling_cifar10} showcases $\gamma$'s impact on generation performance. In Figure~\ref{fig:sampling_cifar10}-(a), $\gamma$ has less influence with small NFE, but the setup with $\gamma\approx 0$ is the only one that resembles the performance of the Heun's solver as NFE increases. Additionally, CM's multistep sampler ($\gamma=1$) significantly degrades sample quality as NFE increases. This quality deterioration concerning $\gamma$ becomes more pronounced with higher NFEs, shown in Figure~\ref{fig:sampling_cifar10}-(b), potentially attributed to error accumulation during the iterative long ``jumps'' for \djk{denoising}. We explain this phenomenon using a 2-step $\gamma$-sampling example in the following theorem, see Theorem~\ref{th:sampling_agg_error_N_steps} for a generalized result for $N$-steps.

\begin{figure*}[t]
	\centering
	\includegraphics[width=\linewidth]{cat_stroke.pdf}
	\caption{$\gamma$ controls sample variance in stroke-based generation (see Appendix~\ref{subsec:traj_control}).}
	\label{fig:cat_stroke}
\end{figure*}

\begin{wrapfigure}{r}{0.6\textwidth}
\vskip -0.1in
	\centering
	\begin{subfigure}{0.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{FID_by_nfe.pdf}
		\subcaption{FID by NFE}
	\end{subfigure}
	\begin{subfigure}{0.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{FID_by_gamma.pdf}
		\subcaption{Sensitivity to $\gamma$}
	\end{subfigure}	
	\caption{(a) CTM enables score-based sampling and distillation $\gamma$-sampling on CIFAR-10. (b) The FID degrade highlights the importance of trajectory learning.}
	\label{fig:sampling_cifar10}
	\vskip -0.2in
\end{wrapfigure}
\begin{theorem}[(Informal) 2-steps $\gamma$-sampling]\label{th:sampling_agg_error_2_steps}
Let $t\in(0,T)$ and $\gamma \in [0,1]$. Denote $p_{\bm{\theta}^{*},2}$ as the density obtained from the $\gamma$-sampler with the optimal CTM, following the transition sequence $T\rightarrow\sqrt{1-\gamma^2}t\rightarrow t \rightarrow 0$, starting from $p_T$. Then
$D_{TV}\left( p_{\text{data}}, p_{\bm{\theta}^{*},2}\right)
         = \mathcal{O}\big(\sqrt{T-\sqrt{1-\gamma^2}t+ t}  \big)$.
\end{theorem}
When it becomes $N$-steps, $\gamma=1$-sampling iteratively conducts long jumps from $t_n$ to $0$ for each step $n$, which aggregates the error to be $\mathcal{O}(\sqrt{T + t_1+\cdots+t_N})$. \jc{In contrast, such time overlap between jumps does not occur in $\gamma=0$-sampling}, eliminating the error accumulation, resulting in $\mathcal{O}(\sqrt{T})$ error, see Appendix~\ref{sec:connect_sde}. In summary, CTM addresses challenges associated with large NFE in distillation models with $\gamma=0$ and removes the discretization error in score-based models. 


\section{Experiments}

\begin{table}[t]
\begin{minipage}[t]{.56\linewidth}
	\scriptsize
 \caption{Performance comparisons on CIFAR-10.}
 \resizebox{.95\linewidth}{!}{
	\centering
	\begin{tabular}{lcccc}
		\toprule
		\multirow{2}{*}{Model} & \multirow{2}{*}{NFE} & \multicolumn{2}{c}{Unconditional} & Conditional \\\cmidrule(lr){3-4}\cmidrule{5-5}
  & & FID$\downarrow$ & NLL$\downarrow$ & FID$\downarrow$ \\\midrule
            \multicolumn{5}{l}{\textbf{GAN Models}}\\
            BigGAN~\citep{brock2018large} & 1 & 8.51 & \xmark & - \\
            StyleGAN-Ada~\citep{karras2020training} & 1 & 2.92 & \xmark & 2.42 \\
            StyleGAN-D2D~\citep{kang2021rebooting} & 1 & - & \xmark & 2.26 \\
            StyleGAN-XL~\citep{sauer2022stylegan} & 1 & - & \xmark & 1.85 \\
            \midrule
            \multicolumn{5}{l}{\textbf{Diffusion Models -- Score-based Sampling}}\\
            DDPM~\citep{ho2020denoising} & 1000 & 3.17 & 3.75 & - \\
            \multirow{2}{*}{DDIM~\citep{song2020denoising}} & 100 & 4.16 & - & - \\
            & 10 & 13.36 & - & - \\
            Score SDE~\citep{song2020denoising} & 2000 & 2.20 & 3.45 & - \\
            VDM~\citep{kingma2021variational} & 1000 & 7.41 & \underline{2.49} & - \\
            LSGM~\citep{vahdat2021score} & 138 & 2.10 & 3.43 & - \\
            EDM~\citep{karras2022elucidating} & 35 & 2.01 & 2.56 & 1.82 \\\midrule
            \multicolumn{5}{l}{\textbf{Diffusion Models -- Distillation Sampling}}\\KD~\citep{luhman2021knowledge} & 1 & 9.36 & \xmark & - \\
            DFNO~\citep{zheng2023fast} & 1 & 5.92 & \xmark & - \\
            Rectified Flow~\citep{liu2022flow} & 1 & 4.85 & \xmark & - \\
            PD~\citep{salimans2021progressive} & 1 & 9.12 & \xmark & - \\
            CD (official report)~\citep{song2023consistency} & 1 & 3.55 & \xmark & - \\CD (retrained) & 1 & 10.53 & \xmark & - \\
            CD + GAN~\citep{lu2023cm} & 1 & 2.65 & \xmark & - \\
            \cc{15}CTM~(ours) & \cc{15}1 & \cc{15}\underline{1.98} & \cc{15}\textbf{2.43} & \cc{15}\underline{1.73} \\\cdashlinelr{1-5}
            PD~\citep{salimans2021progressive} & 2 & 4.51 & - & - \\
            CD~\citep{song2023consistency} & 2 & 2.93 & - & - \\
            \cc{15}CTM~(ours) & \cc{15}2 & \cc{15}\textbf{1.87} & \cc{15}\textbf{2.43} & \cc{15}\textbf{1.63} \\
            \bottomrule
	\end{tabular}
 \label{tab:cifar10_baseline}
 }
    \end{minipage}\hfill
    \begin{minipage}[t]{.44\linewidth}
	\caption{Performance comparisons on ImageNet $64\times64$.}
	\label{tab:ImageNet64_baseline}
	\scriptsize
 \resizebox{.95\linewidth}{!}{
	\centering
	\begin{tabular}{lccc}
		\toprule
		Model & NFE & FID$\downarrow$ & IS$\uparrow$ \\\midrule
            ADM~\citep{dhariwal2021diffusion} & 250 & 2.07 & - \\
            EDM~\citep{karras2022elucidating} & 79 & 2.44 & 48.88 \\
            BigGAN-deep~\citep{brock2018large} & 1 & 4.06 & - \\
            StyleGAN-XL~\citep{sauer2022stylegan} & 1 & 2.09 & \textbf{82.35} \\\midrule
            \multicolumn{4}{l}{\textbf{Diffusion Models -- Distillation Sampling}}\\PD~\citep{salimans2021progressive} & 1 & 15.39 & - \\
            BOOT~\citep{gu2023boot} & 1 & 16.3 & -  \\
            CD~\citep{song2023consistency} & 1 & 6.20 & 40.08 \\
            \cc{15}CTM (ours) & \cc{15}1 & \cc{15}\underline{2.06} & \cc{15}\underline{69.83} \\\cdashlinelr{1-4}
            PD~\citep{salimans2021progressive} & 2 & 8.95 & - \\
            CD~\citep{song2023consistency} & 2 & 4.70 & - \\
            \cc{15}CTM (ours) & \cc{15}2 & \cc{15}\textbf{1.90} & \cc{15}63.90 \\
\bottomrule
	\end{tabular}}
 \centering
 \includegraphics[width=\linewidth]{fid_is_curve.pdf}
 \vskip -0.15in
 \captionof{figure}{FID-IS curve on ImageNet.}\label{fig:fid_is}
\end{minipage} 
\vskip 0.15in
\begin{minipage}[t]{.99\linewidth}
     \centering
\begin{subfigure}{0.32\linewidth}
		\centering
		\includegraphics[width=\linewidth]{edm_NFE_79_v3.png}
		\subcaption{EDM ($79$ NFE)}
	\end{subfigure}
	\begin{subfigure}{0.32\linewidth}
		\centering
		\includegraphics[width=\linewidth]{ctm_NFE_1_v3.png}
		\subcaption{CTM w/o GAN ($1$ NFE)}
	\end{subfigure}	
 	\begin{subfigure}{0.32\linewidth}
		\centering
		\includegraphics[width=\linewidth]{ctm_gan_NFE_1_v3.png}
		\subcaption{CTM w/ GAN ($1$ NFE)}
	\end{subfigure}
 \vskip -0.05in
 \captionof{figure}{Samples generated by (a) EDM, (b) CTM without GAN ($\lambda_{\text{GAN}}= 0$), and (c) CTM with GAN ($\lambda_{\text{GAN}}= 1$). CTM distills knowledge from EDM (teacher) and employs adversarial training for further refining fine-grained details. More generated samples are demonstrated in Appendix~\ref{sec:generated_samples}.}
	\label{fig:sampling_imagenet}
 \end{minipage}
 \vskip 0.1in
 \begin{minipage}[t]{.99\linewidth}
     \centering
	\centering
	\begin{subfigure}{0.48\linewidth}
		\centering
		\includegraphics[width=\linewidth]{avg_NFE_1.png}
		\subcaption{Without classifier-rejection sampling (NFE 1)}
	\end{subfigure}
	\begin{subfigure}{0.48\linewidth}
		\centering
		\includegraphics[width=\linewidth]{avg_NFE_2.png}
		\subcaption{With classifier-rejection sampling (avg. NFE 2)}
	\end{subfigure}	
 \vskip -0.05in	
  \captionof{figure}{Random samples (Siberian Husky) (d) with and (e) without classifier-free sampling.}
	\label{fig:classifier_rejection}
\end{minipage}
\vskip -0.1in
\end{table}

\subsection{Student (CTM) beats teacher (DM) -- Quantitative Analysis}

We evaluate CTM on CIFAR-10 and ImageNet $64\times 64$, using the pre-trained diffusion checkpoints from EDM for CIFAR-10 and CM for ImageNet as the teacher models. We adopt EDM's training configuration for $\mathcal{L}_{\text{DSM}}(\bm{\theta})$ and employ StyleGAN-XL's~\citep{sauer2022stylegan} discriminator for $\mathcal{L}_{\text{GAN}}(\bm{\theta},\bm{\eta})$. During training, we employ adaptive weights $\lambda_{\text{DSM}}$ and $\lambda_{\text{GAN}}$, inspired by VQGAN~\citep{esser2021taming} to balance DSM and GAN losses with the CTM loss. For both datasets, we utilize the DDPM architecture. For CIFAR-10, we take EDM's implementation; and for ImageNet, CM's implementation is used.
On top of these architectures, we incorporate $s$-information via auxiliary temporal embedding with positional embedding~\citep{vaswani2017attention}, and add this embedding to the $t$-embedding. This training setup (Appendix \ref{sec:implementation}), along with the deterministic sampling ($\gamma=0$), allows CTM's generation to outperform teacher models with NFE $1$ and achieve SOTA FIDs with NFE $2$. 

\textbf{CIFAR-10 } CTM's NFE $1$ generation excels both EDM and StyleGAN-XL with FID of $1.73$ on conditional CIFAR-10, and CTM achieves the SOTA FID of $1.63$ with $2$ NFEs, surpassing all generative models. These results are obtained with the implementation based on the official PyTorch code of CM. However, retraining CM with this official PyTorch code yields FID of $10.53$ (unconditional), higher than the reported FID of $3.55$. Additionally, CTM's ability to approximate scores using $g_{\bm{\theta}}(\mathbf{x}_{t},t,t)$ enables evaluating Negative Log-Likelihood (NLL)~\citep{song2021maximum,kim2022maximum}, establishing a new SOTA NLL. This improvement can be attributed, in part, to CTM's reconstruction loss when $u=s$, and improved alignment with the oracle process~\citep{lai2023fp}.

\textbf{ImageNet } CTM's generation surpasses both teacher EDM and StyleGAN-XL with NFE 1, outperforming previous models with no guidance~\citep{dhariwal2021diffusion}, see Figure~\ref{fig:sampling_imagenet} for the comparison of CTM with the teacher model. Notably, all results in Tables~\ref{tab:cifar10_baseline} and \ref{tab:ImageNet64_baseline} are achieved within $30$K-$100$K training iterations, requiring only $10\%$ of the iterations compared to CM and EDM. 



\textbf{Classifier-Rejection Sampling } CTM's fast sampling enables classifier-rejection sampling. In the evaluation, for each class, we select the top 50 samples out of $\frac{50}{1-r}$ samples based on predicted class probability, where $r$ is the rejection ratio. This sampler, combined with NFE $1$ sampling, consumes an average of NFE $\frac{1}{1-r}$. In Figure~\ref{fig:fid_is}, CTM, employing cost-effective classifier-rejection sampling, shows a FID-IS trade-off comparable to classifier-guided results~\citep{ho2021classifier} achieved with high NFEs of 250. Additionally, Figure~\ref{fig:classifier_rejection} confirms that samples rejected by the classifier exhibit superior quality and maintain class consistency, in agreement with the findings of \citet{ho2021classifier}. We employ the classifier at resolution of $64\times64$ provided by \citet{dhariwal2021diffusion}.

\subsection{Qualitative Analysis}

\begin{wrapfigure}{r}{0.6\textwidth}
\vskip-0.36in
\begin{subfigure}{0.48\linewidth}
		\centering
		\includegraphics[width=\linewidth]{FID_by_loss_NFE_1_final.pdf}
		\subcaption{NFE $1$}
	\end{subfigure}	
	\begin{subfigure}{0.48\linewidth}
		\centering
		\includegraphics[width=\linewidth]{FID_by_loss_NFE_18_final.pdf}
		\subcaption{NFE $18$}
	\end{subfigure}	
 \vskip -0.05in
 \caption{Comparison of local, global, and the proposed soft consistency matching.}
	\label{fig:CTM}
 \vskip-0.1in
\end{wrapfigure}




\textbf{CTM Loss} Figure~\ref{fig:CTM} highlights the advantages of employing the proposed soft consistency matching in Eq.~\eqref{eq:soft} during CTM training. It outperforms the local consistency matching (Eq.~\eqref{eq:local}). Additionally, it demonstrates comparable performance to the global consistency matching (Eq.~\ref{eq:global}) with NFE $1$, superior performance with large NFE. Furthermore, soft matching is computationally efficient, enhancing the scalability of CTM.
\begin{wrapfigure}{r}{0.6\textwidth}
\centering
 \vskip -0.35in
	\begin{subfigure}{0.48\linewidth}
		\centering
		\includegraphics[width=\linewidth]{FID_by_DSM_NFE_1_final.pdf}
		\subcaption{NFE $1$}
	\end{subfigure}	
        \begin{subfigure}{0.48\linewidth}
		\centering
		\includegraphics[width=\linewidth]{FID_by_DSM_NFE_18_final.pdf}
		\subcaption{NFE $18$}
	\end{subfigure}	
        \vskip -0.05in
	\caption{The effect of DSM loss.}
	\label{fig:DSM}
 \vskip -0.25in
\end{wrapfigure}


 
\textbf{DSM Loss } Figure~\ref{fig:DSM} illustrates two benefits of incorporating $\mathcal{L}_{\text{DSM}}$ with $\mathcal{L}_{\text{CTM}}$. It preserves sample quality for small NFE unless DSM scale outweighs CTM. For large NFE sampling, it significantly improves sample quality due to accurate score estimation. Throughout the paper, we maintain $\lambda_{\text{DSM}}=1$ based on insights from Figure~\ref{fig:DSM}, unless otherwise specified.


\begin{wrapfigure}{r}{0.6\textwidth}
\vskip -0.2in
\centering
\begin{subfigure}{0.48\linewidth}
\centering
		\includegraphics[width=\linewidth]{FID_ctm_dsm_gan_NFE_1_final.pdf}
		\subcaption{NFE $1$}
	\end{subfigure}	
	\begin{subfigure}{0.48\linewidth}
		\centering
		\includegraphics[width=\linewidth]{FID_ctm_dsm_gan_NFE_18_final.pdf}
		\subcaption{NFE $18$}
	\end{subfigure}	
\vskip -0.05in
 \caption{The effect of GAN loss.}
	\label{fig:GAN}
  \vskip -0.2in
 \end{wrapfigure}
\textbf{GAN Loss } Analogous to the DSM loss, Figure~\ref{fig:GAN} illustrates the advantages of incorporating the GAN loss for both small and large NFE sample quality. Figure~\ref{fig:sampling_imagenet} demonstrates that CTM can produce samples resembling those of EDM (teacher), with GAN refining local details. Throughout the paper, we adopt the warm-up strategy for GAN training: deactivate GAN training with $\lambda_{\text{GAN}}=0$ for warm-up iterations and then activate GAN training with $\lambda_{\text{GAN}}=1$, in line with the recommendation from VQGAN~\citep{esser2021taming}. This warm-up strategy is applied by default unless otherwise specified.



\textbf{Training Without Pre-trained DM } Leveraging our score learning capability, we replace the pre-trained score approximation, $D_{\bm{\phi}}(\mathbf{x}_{t},t)$, with CTM's approximation, $g_{\bm{\theta}}(\mathbf{x}_{t},t,t)$, allowing us to obtain the corresponding empirical PF ODE $\diff\mathbf{x}_{t}=\frac{\mathbf{x}_{t}-g_{\bm{\theta}}(\mathbf{x}_{t},t,t)}{t}$. Consequently, we can construct a pretrained-free target, $\hat{\mathbf{x}}_{\text{target}}:=G_{\texttt{sg}(\bm{\theta})}(G_{\texttt{sg}(\bm{\theta})}(\texttt{Solver}(\mathbf{x}_{t},t,u;\texttt{sg}(\bm{\theta}))),u,s),s,0)$, to replace $\mathbf{x}_{\text{target}}$ in computing the CTM loss $\mathcal{L}_{\text{CTM}}$. In contrast to $\mathbf{x}_{\text{target}}$ (Eq.~\eqref{eq:target}), $\hat{\mathbf{x}}_{\text{target}}$ eliminates the need for pre-trained DMs. When incorporated with DSM and GAN losses, it achieves a NFE $1$ FID of $2.39$ on unconditional CIFAR-10, a performance on par with pre-trained DMs. We highlight that the CTM loss can be used with or without the pre-trained DM, which is contrastive to CM with the Consistency Training loss for pretrained-free training that uses an ad-hoc noise injection technique.



\section{Conclusion}

CTM, a novel generative model, addresses issues in established models. With a unique training approach accessing intermediate PF ODE solutions, it enables unrestricted time traversal and seamless integration with prior models' training advantages. A universal framework for Consistency and Diffusion Models, CTM excels in both training and sampling. Remarkably, it surpasses its teacher model, achieving SOTA results in FID and likelihood for few-steps diffusion model sampling on CIFAR-10 and ImageNet $64\times64$, highlighting its versatility and process.



\section*{Acknowledgement}
We sincerely acknowledge the support of everyone who made this research possible. Our heartfelt thanks go to Koichi Saito, Woosung Choi, Kin Wai Cheuk, and Yukara Ikemiya for their assistance. 


\clearpage
\newpage









\bibliography{dgm}
\bibliographystyle{iclr2024_coNFErence}
\clearpage
\newpage
\appendix

\tableofcontents
	\newpage
	\parttoc

\section{Related Works}\label{sec:related_work}
\paragraph{Diffusion Models} DMs excel in high-fidelity synthetic image and audio generation~\citep{dhariwal2021diffusion,saharia2022photorealistic,rombach2022high}, as well as in applications like media editing, restoration~\citep{meng2021sdedit,cheuk2023diffroll,kawar2022denoising,saito2023unsupervised,hernandez2023vrdmg,murata2023gibbsddrm}. Recent research aims to enhance DMs in sample quality~\citep{kim2022maximum,kim2022refining}, density estimation~\citep{song2021maximum,lu2022maximum}, and especially, sampling speed~\citep{song2020denoising}. 


\paragraph{Fast Sampling of DMs} The SDE framework underlying DMs~\citep{song2020score} has driven research into various numerical methods for accelerating DM sampling, exemplified by works such as \citep{song2020denoising,zhang2022fast,lu2022dpm}. Notably, \citep{lu2022dpm} reduced the ODE solver steps to as few as $10$-$15$. Other approaches involve learning the solution operator of ODEs~\citep{zheng2023fast}, discovering optimal transport paths for sampling~\citep{liu2022flow}, or employing distillation techniques~\citep{luhman2021knowledge,salimans2021progressive,berthelot2023tract,shao2023catch}. However, previous distillation models may experience slow convergence or extended runtime.
\citet{gu2023boot} introduced a bootstrapping approach for data-free distillation. Furthermore, \citet{song2023consistency} introduced CM which extracts DMs' PF ODE to establish a direct mapping from noise to clean predictions, achieving one-step sampling while maintaining good sample quality. CM has been adapted to enhance the training stability of GANs, as \citep{lu2023cm}. However, it's important to note that their focus does not revolve around achieving sampling acceleration for DMs, nor are the results restricted to simple datasets.


\paragraph{Consistency of DMs} Score-based generative models rely on a differential equation framework, employing neural networks trained on data to model the conversion between data and noise. These networks must satisfy specific consistency requirements due to the mathematical nature of the underlying equation. Early investigations, such as \citep{kim2022soft}, identified discrepancies between learned scores and ground truth scores. Recent developments have introduced various consistency concepts, showing their ability to enhance sample quality~\citep{daras2023consistent,li2023diffusion}, accelerate sampling speed~\citep{song2023consistency}, and improve density estimation in diffusion modeling~\citep{lai2023fp}. Notably, \citet{lai2023equivalence} established the theoretical equivalence of these consistency concepts, suggesting the potential for a unified framework that can empirically leverage their advantages. CTM can be viewed as the first framework which achieves all the desired properties.


\section{Theoretical Insights on CTM}\label{appendix:general_theory}
In this section, we explore several theoretical aspects of CTM, encompassing convergence analysis (Section~\ref{sec:convergence_analysis}), properties of well-trained CTM, variance bounds for $\gamma$-sampling, and a more general form of accumulated errors induced by $\gamma$-sampling (cf. Theorem~\ref{th:sampling_agg_error_2_steps}).

We first introduce and review some notions. Starting at time $t$ with an initial value of $\mathbf{x}_t$ and ending at time $s$, recall that $G(\mathbf{x}_t, t, s)$ represents the true solution of the PF ODE, and $G(\mathbf{x}_t, t, s; \bm{\phi})$ is the solution function of the following empirical PF ODE.
\begin{align}\label{eq:emp_pf_ode}
    \frac{\diff \mathbf{x}_{u}}{\diff {u}} =\frac{\mathbf{x}_{{u}}-D_{\bm{\phi}}(\mathbf{x}_{u},{u}) }{{u}}, \quad u\in[0,T].
\end{align}
Here $\bm{\phi}$ denotes the teacher model's weights learned from DSM. Thus, $G(\mathbf{x}_t, t, s; \bm{\phi})$ can be expressed as
\begin{align*}
    G(\mathbf{x}_t, t, s; \bm{\phi})=\frac{s}{t}\mathbf{x}_t + (1-\frac{s}{t})g(\mathbf{x}_t, t, s;\bm{\phi}),
\end{align*}
where $g(\mathbf{x}_{t},t,s;\bm{\phi})=\mathbf{x}_{t}+\frac{t}{t-s}\int_{t}^{s}\frac{\mathbf{x}_{{u}}-D_{\bm{\phi}}(\mathbf{x}_{u},{u}) }{{u}}\diff u$.



\subsection{Convergence Analysis -- Distillation from Teacher Models}\label{sec:convergence_analysis}

\paragraph{Convergence along Trajectory in a Time Discretization Setup.}

CTM's practical implementation follows CM's one, utilizing discrete timesteps $t_0=0<t_1<\cdots<t_N=T$ for training. Initially, we assume local consistency matching for simplicity, but this can be extended to soft matching. This transforms the CTM loss in Eq.~\eqref{eq:ctm_loss} to the discrete time counterpart:
\begin{align*}
    \mathcal{L}^{N}_{\text{CTM}}(\bm{\theta};\bm{\phi}):=\mathbb{E}_{n\in[\![ 1,N ]\!]}\mathbb{E}_{m\in[\![ 0,n ]\!]}\mathbb{E}_{\mathbf{x}_{0}, p_{0t_{n}}(\mathbf{x}\vert\mathbf{x}_{0})}\Big[d\big(\mathbf{x}_{\text{target}}(\mathbf{x}_{t_n},t_n,t_m),\mathbf{x}_{\text{est}}(\mathbf{x}_{t_n},t_n,t_m)\big)\Big],
\end{align*}
where $d(\cdot, \cdot)$ is a metric, and
\begin{align*}
    \mathbf{x}_{\text{est}}(\mathbf{x}_{t_n},t_n,t_m)&:=G_{\bm{\theta}}\Big(G_{\bm{\theta}}(\mathbf{x}_{t_n},t_n,t_m),t_m,0\Big)\nonumber
    \\ \mathbf{x}_{\text{target}}(\mathbf{x}_{t_n},t_n,t_{n-1},t_m)&:=G_{\bm{\theta}}\Big(G_{\bm{\theta}}\big(\texttt{Solver}(\mathbf{x}_{t_n}, t_n,t_{n-1};\bm{\phi}),t_{n-1},t_m\big),t_m,0\Big).
\end{align*}



In the following theorem, we demonstrate that irrespective of the initial time $t_n$ and end time $t_m$, CTM $G_{\bm{\theta}}(\cdot, t_n, t_m; \bm{\phi})$, will eventually converge to its teacher model, $G(\cdot, t_n, t_m; \bm{\phi})$.



\begin{proposition}\label{th:ptw_distill} Define $\Delta_N t:=\underset{n\in[\![ 1,N ]\!]}{\max}\left\{\abs{t_{n+1}-t_n}\right\}$.  Assume
that $G_{\bm{\theta}}$ is uniform Lipschitz in $\bm{x}$ and that the ODE solver admits local truncation error bounded uniformly by $\mathcal{O}((\Delta_N t)^{p+1})$ with $p\geq 1$. If there is a $\bm{\theta}_N$ so that $\mathcal{L}_{\text{CTM}}^{N}(\bm{\theta}_N;\bm{\phi})=0$, then for any $n\in[\![ 1,N ]\!]$ and $m\in[\![ 1,n ]\!]$  
\begin{align*}
    \sup_{\mathbf{x}\in\mathbb{R}^D} d\big(G_{\bm{\theta}_N}(G_{\bm{\theta}_N}(\mathbf{x}, t_n, t_m), t_m, 0) ,G_{\bm{\theta}_N}(G(\mathbf{x}, t_n, t_m; \bm{\phi}), t_m, 0)\big) = \mathcal{O}((\Delta_N t)^{p})(t_n - t_m).
\end{align*}

\end{proposition}


Similar argument applies, confirming convergence along the PF ODE trajectory, ensuring Eq.~\eqref{eq:local} with $\bm{\theta}$ replacing $\texttt{sg}(\bm{\theta})$:
\begin{align*}G_{\bm{\theta}}(\mathbf{x}_{t},t,s)\approx G_{\bm{\theta}}(\texttt{Solver}(\mathbf{x}_{t},t,t-\Delta t;\bm{\phi}),t-\Delta t,s)
\end{align*}
by enforcing the following loss
\begin{align*}
    \tilde{\mathcal{L}}^{N}_{\text{CTM}}(\bm{\theta};\bm{\phi}):=\mathbb{E}_{n\in[\![ 1,N ]\!]}\mathbb{E}_{m\in[\![ 0,n ]\!]}\mathbb{E}_{\mathbf{x}_{0}, p_{0t_{n}}(\mathbf{x}\vert\mathbf{x}_{0})}\Big[d\big(\tilde{\mathbf{x}}_{\text{target}}(\mathbf{x}_{t_n},t_n,t_m),\tilde{\mathbf{x}}_{\text{est}}(\mathbf{x}_{t_n},t_n,t_m)\big)\Big],
\end{align*}
where
\begin{align*}
    \tilde{\mathbf{x}}_{\text{est}}(\mathbf{x}_{t_n},t_n,t_m)&:=G_{\bm{\theta}}(\mathbf{x}_{t_n},t_n,t_m)\nonumber
    \\ \tilde{\mathbf{x}}_{\text{target}}(\mathbf{x}_{t_n},t_n,t_{n-1},t_m)&:=G_{\bm{\theta}}\big(\texttt{Solver}(\mathbf{x}_{t_n}, t_n,t_{n-1};\bm{\phi}),t_{n-1},t_m\big).
\end{align*}




\begin{proposition}\label{th:ptw_traj_distill}  If there is a $\bm{\theta}_N$ so that $\tilde{\mathcal{L}}_{\text{CTM}}^{N}(\bm{\theta}_N;\bm{\phi})=0$, then for any $n\in[\![ 1,N ]\!]$ and $m\in[\![ 1,n ]\!]$  
\begin{align*}
    \sup_{\mathbf{x}\in\mathbb{R}^D} d\big(G_{\bm{\theta}_N}(\mathbf{x}, t_n, t_m),G(\mathbf{x}, t_n, t_m; \bm{\phi})\big) = \mathcal{O}((\Delta_N t)^{p})(t_n - t_m).
\end{align*}

\end{proposition}



\paragraph{Convergence of Densities.} In Proposition~\ref{th:ptw_distill}, we demonstrated point-wise trajectory convergence, from which we infer that CTM may converge to its training target in terms of density. More precisely, in Proposition~\ref{th:density_match}, we establish that if CTM's target $\mathbf{x}_{\text{target}}$ is derived from the teacher model (as defined above), then the data density induced by CTM will converge to that of the teacher model. Specifically, if the target $\mathbf{x}_{\text{target}}$ perfectly approximates the true $G$-function: 
\begin{align}\label{eq:tar_perfect_match}
    \mathbf{x}_{\text{target}}(\mathbf{x}_{t_n},t_n,t_{n-1},t_m)\equiv G(\mathbf{x}_{t_n},t_n,t_m), \quad \text{for all } n\in[\![ 1,N ]\!], m\in[\![ 0,n ]\!], N\in\mathbb{N}.   
\end{align}
Then the data density generated by CTM will ultimately learn the data distribution $p_{\text{data}}$.

Simplifying, we use the $\ell_2$ for the distance metric $d$ and consider the prior distribution $\pi$ to be $p_T$, which is the marginal distribution at time $t=T$ defined by the diffusion process in Eq.~\eqref{eq:sde_forward}.



\begin{proposition}\label{th:density_match}  Suppose that 
\begin{enumerate}[(i)]
        \item 
    The uniform Lipschitzness of $G_{\bm{\theta}}$ (and $G$),
    \begin{align*}
        \sup_{\bm{\theta}}\norm{G_{\bm{\theta}}(\mathbf{x}, t, s) - G_{\bm{\theta}}(\mathbf{x}', t, s)}_2 \leq L \norm{\mathbf{x} - \mathbf{x}'}_2, \quad \text{for all } \mathbf{x}, \mathbf{x}'\in \mathbb{R}^D, t, s\in[0,T], 
    \end{align*}
    \item The uniform boundedness in $\bm{\theta}$ of $G_{\bm{\theta}}$: there is a $L(\mathbf{x}
    )\geq0$ so that
    \begin{align*}
   \sup_{\bm{\theta}} \norm{G_{\bm{\theta}}(\mathbf{x}, t, s) }_2 \leq L(\mathbf{x}
    )<\infty, \quad \text{for all } \mathbf{x} \in \mathbb{R}^D, t, s\in[0,T]
    \end{align*}
\end{enumerate}
If for any $N$, there is a $\bm{\theta}_N$ such that $\mathcal{L}_{\text{CTM}}^{N}(\bm{\theta}_N;\bm{\phi})=0$. Let $p_{ \bm{\theta}_N}(\cdot)$ denote the pushforward distribution of $p_T$ induced by $G_{\bm{\theta}_N}(\cdot, T, 0)$. Then, as $N\rightarrow\infty$, $\norm{p_{ \bm{\theta}_N}(\cdot)- p_{\bm{\phi}}(\cdot)}_{\infty}\rightarrow 0$. Particularly, if the condition in Eq.~\eqref{eq:tar_perfect_match} is satisfied, then $\norm{p_{\bm{\theta}_N}(\cdot)- p_{\text{data}}(\cdot)}_{{\infty}}\rightarrow 0$ as $N\rightarrow\infty$.
\end{proposition}


\subsection{Non-Intersecting Trajectory of the Optimal CTM}\label{sec:non_intersect}
CTM learns distinct trajectories originating from various initial points $\mathbf{x}t$ and times $t$. In the following proposition, we demonstrate that the distinct trajectories derived by the optimal CTM, which effectively distills information from its teacher model ($G_{\bm{\theta}^*}(\cdot,t,s)\equiv G(\cdot,t,s;\bm{\phi})$ for any $t, s\in[0,T]$), do not intersect.


\begin{proposition}\label{th:gt_injective}
Suppose that a well-trained $\bm{\theta}^*$ such that $G_{\bm{\theta}^*}(\cdot,t,s)\equiv G(\cdot,t,s;\bm{\phi})$ for any $t, s\in[0,T]$, and that $D_{\bm{\phi}}(\cdot,t)$ is Lipschitz, i.e., there is a constant $L_{\bm{\phi}}>0$
so that for any $\mathbf{x},\mathbf{y}\in\mathbb{R}^D$ and $t\in[0,T]$
\begin{align*}
    \norm{D_{\bm{\phi}}(\mathbf{x},t) - D_{\bm{\phi}}(\mathbf{y},t)}_2 \leq L_{\bm{\phi}}\norm{\mathbf{x}-\mathbf{y}}_2.
\end{align*}

Then for any $s\in[0,t]$, the mapping $G_{\bm{\theta}^*}(\cdot,t,s)\colon\mathbb{R}^D\rightarrow\mathbb{R}^D$ is bi-Lipschitz. Namely, for any $\mathbf{x}_t, \mathbf{y}_t\in\mathbb{R}^D$
    \begin{align}
        e^{-L_{\bm{\phi}}(t-s)}\norm{\mathbf{x}_t- \mathbf{y}_t}_2\leq \norm{G_{\bm{\theta}^*}(\mathbf{x}_t,t,s) -G_{\bm{\theta}^*}(\mathbf{y}_t,t,s)}_2 \leq e^{L_{\bm{\phi}}(t-s)}\norm{\mathbf{x}_t- \mathbf{y}_t}_2.
    \end{align}
    This implies that $\mathbf{x}_t\neq\mathbf{y}_t$, $G_{\bm{\theta}^*}(\mathbf{x}_t; t, s)\neq G_{\bm{\theta}^*}(\mathbf{y}_t; t, s)$ for all $s\in[0,t]$. 
\end{proposition}

Specifically, the mapping from an initial value to its corresponding solution trajectory, denoted as $\mathbf{x}_t\mapsto G_{\bm{\theta}^*}(\mathbf{x}_t, t, \cdot)$, is injective. Conceptually, this ensures that if we use guidance at intermediate times to shift a point to another guided-target trajectory, the guidance will continue to affect the outcome at $t=0$.

\subsection{Variance Bounds of $\gamma$-sampling}\label{sec:var_bound}

Suppose the sampling timesteps are $T=t_0>t_{1}>\cdots>t_N=0$. In Proposition~\ref{th:gamma_sampling}, we analyze the variance of 
\begin{align*}
    X_{n+1}:= G_{\bm{\theta}}(X_{n}, t_n, \sqrt{1-\gamma^2} t_{n+1}) + Z_n,
\end{align*}
 resulting from $n$-step $\gamma$-sampling, initiated at 
\begin{align*}
     X_1 := G_{\bm{\theta}}(\mathbf{x}_{t_0}, t_0, \sqrt{1-\gamma^2} t_1) + \gamma Z_0, \quad \text{where } Z_n \iid \mathcal{N}(\mathbf{0},\gamma^2t_{n+1}^2)\mathbf{I}).
 \end{align*}
Here, we assume an optimal CTM which precisely distills information from the teacher model $G_{\bm{\theta}^*}(\cdot)=G(\cdot, t, s; \bm{\phi})$ for all $t, s\in[0,T]$, for simplicity.
\begin{proposition}\label{th:gamma_sampling}
We have
    \begin{align*}
        \zeta^{-1}(t_n, t_{n+1}, \gamma)\text{Var}\left(X_n\right)  + \gamma^2t_{n+1}^2 \leq \text{Var}\left(X_{n+1}\right)\leq \zeta(t_n, t_{n+1}, \gamma) \text{Var}\left(X_{n}\right) + \gamma^2t_{n+1}^2,
    \end{align*}
    where $\zeta(t_n, t_{n+1}, \gamma)=\exp{\left(2L_{\bm{\phi}}(t_n-\sqrt{1-\gamma^2}t_{n+1})\right)}$ and $L_{\bm{\phi}}$ is a Lipschitz constant of $D_{\bm{\phi}}(\cdot, t)$.
\end{proposition}

In line with our intuition, CM's multistep sampling ($\gamma=1$) yields a broader range of $\text{Var}\left(X_{n+1}\right)$ compared to $\gamma=0$, resulting in diverging semantic meaning with increasing sampling NFE. 


\subsection{Accumulated Errors in the General Form of $\gamma$-sampling.}\label{sec:acc_error}

We can extend Theorem~\ref{th:sampling_agg_error_2_steps} for two steps $\gamma$-sampling for the case of multisteps. 


We begin by clarifying the concept of ``density transition by a function''. For a measurable mapping $\mathcal{T}: \Omega \rightarrow \Omega$ and a measure $\nu$ on the measurable space $\Omega$, the notation $\mathcal{T}\sharp \nu$ denotes the pushforward measure, indicating that if a random vector $X$ follows the distribution $\nu$, then $\mathcal{T}(X)$ follows the distribution $\mathcal{T}\sharp \nu$.


Given a sampling timestep  $T=t_0>t_1>\cdots>t_N=0$. Let $p_{\bm{\theta}^*, N}$ represent the density resulting from N-steps of $\gamma$-sampling initiated at $p_T$. That is, 
\begin{align*}
    p_{\bm{\theta}^*, N}:=\comp{n=0}{N-1}\left(\mathcal{T}_{\sqrt{1-\gamma^2}t_{n+1}\rightarrow t_{n+1}}^{\bm{\theta}^* }\circ\mathcal{T}_{t_n \rightarrow\sqrt{1-\gamma^2}t_{n+1}}^{\bm{\theta}^* }\right) \sharp p_T.    
\end{align*}
Here, $\comp{n=0}{N-1}$ denotes the sequential composition. We assume an optimal CTM which precisely distills information from the teacher model $G_{\bm{\theta}^*}(\cdot)=G(\cdot, t, s; \bm{\phi})$ for all $t, s\in[0,T]$.



\begin{theorem}[Accumulated errors of N-steps $\gamma$-sampling]\label{th:sampling_agg_error_N_steps}
Let $\gamma \in [0,1]$.
\begin{align*}
    D_{TV}\left(p_{\text{data}}, p_{\bm{\theta}^*, N} 
     \right)
     = \mathcal{O}\left(\sum_{n=0}^{N-1}\sqrt{t_n -\sqrt{1-\gamma^2}t_{n+1}}\right).
\end{align*}
Here, $\mathcal{T}_{t\rightarrow s}\colon\mathbb{R}^D\rightarrow\mathbb{R}^D$ denotes the oracle transition mapping from $t$ to $s$, determined by Eq.~\eqref{eq:sde_forward}. The pushforward density via $\mathcal{T}_{t\rightarrow s}$ is denoted as $\mathcal{T}_{t\rightarrow s}\sharp p_t$, with similar notation applied to $\mathcal{T}_{t\rightarrow s}^{\bm{\theta}^*}\sharp p_t$, where $\mathcal{T}_{t\rightarrow s}^{\bm{\theta}^*}$ denotes the transition mapping associated with the optimal CTM trained from Eq.~\eqref{eq:ultimate_loss}.

    
\end{theorem}










\subsection{Transition Densities with the Optimal CTM}
In this section, for simplicity, we assume the optimal CTM, $G_{\bm{\theta}^*}\equiv G$ with a well-learned $\bm{\theta}^*$, which recovers the true $G$-function. We establish that the density propagated by this optimal CTM from any time $t$ to a subsequent time $s$ aligns with the predefined density determined by the fixed forward process. 



We now present the proposition ensuring alignment of the transited density.
\begin{proposition}\label{th:transition}
    Let $\{p_t\}_{t=0}^{T}$ be densities defined by the diffusion process Eq.~\eqref{eq:sde_forward}, where $p_0:=p_{\text{data}}$. Denote $\mathcal{T}_{t\rightarrow s}(\cdot):=G(\cdot, t, s)\colon\mathbb{R}^D\rightarrow\mathbb{R}^D$ for any $ t\geq s$.  Suppose that the score $\nabla\log p_t$ satisfies that there is a function $L(t)\geq 0$ so that $\int_{0}^{T}\abs{L(t)}\diff t <\infty$ and 
    \begin{enumerate}[(i)]
        \item Linear growth: $\norm{\nabla\log p_t(\mathbf{x})}_2\leq L(t) (1+\norm{\mathbf{x}}_2)$, for all $\mathbf{x}\in\mathbb{R}^D$
        \item Lipschitz: $\norm{\nabla\log p_t(\mathbf{x})- \nabla\log p_t(\mathbf{y})}_2\leq L(t) \norm{\mathbf{x}-\mathbf{y}}_2$, for all $\mathbf{x},\mathbf{y}\in\mathbb{R}^D$.
    \end{enumerate}
    Then for any $t\in[0,T]$ and $s\in[0,t]$, $p_s =\mathcal{T}_{t\rightarrow s} \sharp p_t$.
\end{proposition}

This theorem guarantees that by learning the optimal CTM, which possesses complete trajectory information, we can retrieve all true densities at any time using CTM.








\section{Algorithmic Details}

\subsection{Motivation of Parametrization}\label{sec:parametrization}

Our parametrization of $G_{\bm{\theta}}$ is affected from the discretized ODE solvers. For instance, the one-step Euler solver has the solution of
\begin{align*}
    \mathbf{x}_{s}^{\text{Euler}}=\mathbf{x}_{t}-(t-s)\frac{\mathbf{x}_{t}-\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{t}]}{t}=\frac{s}{t}\mathbf{x}_{t}+\bigg(1-\frac{s}{t}\bigg)\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{t}].
\end{align*}
The one-step Heun solver is
\begin{align*}
    \mathbf{x}_{s}^{\text{Heun}}&=\mathbf{x}_{t}-\frac{t-s}{2}\bigg( 
\frac{\mathbf{x}_{t}-\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{t}]}{t} + \frac{\mathbf{x}_{s}^{\text{Euler}}-\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{s}^{\text{Euler}}]}{s} \bigg)\\
&=\mathbf{x}_{t}-\frac{t-s}{2}\bigg(\frac{\mathbf{x}_{t}}{t}+\frac{\mathbf{x}_{s}^{\text{Euler}}}{s}\bigg)+\frac{t-s}{2}\bigg(\frac{\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{t}]}{t}+\frac{\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{s}^{\text{Euler}}]}{s}\bigg)\\
&=\frac{s}{t}\mathbf{x}_{t}+\bigg(1-\frac{s}{t}\bigg)\bigg(\Big(1-\frac{t}{2s}\Big)\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{t}]+\frac{t}{2s}\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{s}^{\text{Euler}}]\bigg).
\end{align*}
Again, the solver scales $\mathbf{x}_{t}$ with $\frac{s}{t}$ and multiply $1-\frac{s}{t}$ to the second term. Therefore, our $G(\mathbf{x}_{t},t,s)=\frac{s}{t}\mathbf{x}_{t}+(1-\frac{s}{t})g(\mathbf{x}_{t},t,s)$ is a natural way to \djk{represent} the ODE solution.

For future research, we establish conditions enabling access to both integral and integrand expressions. Consider a continuous real-valued function $a(t, s)$. We aim to identify necessary conditions on $a(t, s)$ for the expression of $G$ as:
\begin{align*}
    G(\mathbf{x}_{t},t,s) = a(t,s)\mathbf{x}_t + \big(1-a(t,s)\big)h(\mathbf{x}_t, t, s),
\end{align*}
for a vector-value function $h(\mathbf{x}_t, t, s)$ and that $h$ satisfies:
\begin{itemize}
    \item $\lim_{s\rightarrow t }h(\mathbf{x}_t, t, s)$ exists;
    \item it can be expressed algebraically with $\mathbb{E}.[\mathbf{x}\vert\mathbf{x}_{t}]$.
\end{itemize}
Starting with the definition of $G$, we can obtain
\begin{align*}
G(\mathbf{x}_{t},t,s)&=\mathbf{x}_{t}+\int_{t}^{s}\frac{\mathbf{x}_{u}-\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{u}]}{u}\diff u
\\&=a(t,s)\mathbf{x}_t + \big(1-a(t,s)\big)\underset{h(\mathbf{x}_t , t, s)}{\underbrace{\Big[\mathbf{x}_t + \frac{1}{1-a(t,s)} \int_{t}^{s}\frac{\mathbf{x}_{u}-\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{u}]}{u}\diff u\Big]}}.
\end{align*}


Suppose that there is a continuous function $c(t)$ so that 
\begin{align*}
    \lim_{s\rightarrow t} \frac{s-t}{1-a(t,s)} = c(t),
\end{align*}
then 
\begin{align*}
    \lim_{s\rightarrow t }h(\mathbf{x}_t, t, s) &= \mathbf{x}_t +  \lim_{s\rightarrow t } \Big[ \frac{1}{1-a(t,s)} \int_{t}^{s}\frac{\mathbf{x}_{u}-\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{u}]}{u}\diff u \Big] 
    \\ &= \mathbf{x}_t + \lim_{s\rightarrow t } \Big[ \frac{s-t}{1-a(t,s)} \frac{\mathbf{x}_{t^*}-\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{t^*}]}{t^*} \Big],\quad \text{for some } t^*\in[s, t]
    \\ & = \mathbf{x}_t + c(t) \Big( \frac{\mathbf{x}_t -\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{t}] }{t} \Big)
    \\ & = \Big(\frac{1+c(t)}{t} \Big)\mathbf{x}_t - \frac{c(t)}{t} \mathbb{E}[\mathbf{x}\vert\mathbf{x}_{t}].
\end{align*}
The second equality follows from the mean value theorem (We omit the continuity argument details for Markov filtrations). Therefore, we obtain the desired property 2). We summarize the necessary conditions on $a(s,t)$ as:
\begin{align}\label{eq:cond}
    \text{There is some continuous function } c(t) \text{ in } t \text{ so that } \lim_{s\rightarrow t} \frac{s-t}{1-a(t,s)} = c(t).
\end{align}


We now explain the above observation with an example by considering EDM-type parametrization. Consider $c_{\text{skip}}=c_{\text{skip}}(t,s):=\sqrt{\frac{(s-\sigma_{\text{min}})^{2}+\sigma_{\text{data}}^{2}}{(t-\sigma_{\text{min}})^{2}+\sigma_{\text{data}}^{2}}}$ and $c_{\text{out}}=c_{\text{out}}(t,s):=\Big(1-\frac{s}{t}\Big)$. Then $G(\mathbf{x}_{t},t,s)$ can be expressed as 
\begin{align*}
    G(\mathbf{x}_{t},t,s)=c_{\text{skip}}(t,s)\mathbf{x}_{t}+c_{\text{out}}(t,s)h(\mathbf{x}_{t},t,s),
\end{align*}
where $h$ is defined as 
\begin{align*}
    h(\mathbf{x}_t, t,s ) = \frac{1}{c_{\text{out}}}\Big[(1-c_{\text{skip}})\mathbf{x}_t + \int_{t}^{s}\frac{\mathbf{x}_{u}-\mathbb{E}[\mathbf{x}\vert\mathbf{x}_{u}]}{u}\diff u  \Big].
\end{align*}
Then, we can verify that $c_{\text{skip}}$ satisfies the condition in Eq.~\eqref{eq:cond} and that
\begin{align*}
    \mathbb{E}[\mathbf{x}\vert\mathbf{x}_{t}]=g(\mathbf{x}_{t},t,t)+\frac{\sigma_{\text{min}}^{2}+\sigma_{\text{data}}^{2}-\sigma_{\text{min}}t}{(t-\sigma_{\text{min}})^{2}+\sigma_{\text{data}}^{2}}\mathbf{x}_{t}.
\end{align*}



The DSM loss with this $c_{\text{skip}}$ becomes
\begin{align*}
    \mathcal{L}_{\text{DM}}(\bm{\theta})=\mathbb{E}\bigg[\bigg\Vert\mathbf{x}_{0}-\bigg(g_{\bm{\theta}}(\mathbf{x}_{t},t,t)+\frac{\sigma_{\text{min}}^{2}+\sigma_{\text{data}}^{2}-\sigma_{\text{min}}t}{(t-\sigma_{\text{min}})^{2}+\sigma_{\text{data}}^{2}}\mathbf{x}_{t}\bigg)\bigg\Vert_{2}^{2}\bigg]
\end{align*}
However, empirically, we find that the parametrization of $c_{\text{skip}}(t,s)$ and $c_{\text{out}}(t,s)$ other than the ODE solver-oriented one, i.e., $c_{\text{skip}}(t,s)=\frac{s}{t}$ and $c_{\text{skip}}(t,s)=1-\frac{s}{t}$, faces training instability. Therefore, we set $G(\mathbf{x}_{t},t,s)=\frac{s}{t}\mathbf{x}_{t}+(1-\frac{s}{t})g(\mathbf{x}_{t},t,s)$ as our default design and estimate $g$-function with the neural network.


\subsection{Characteristics of $\gamma$-sampling}\label{sec:connect_sde}
 
 \textbf{Connection with SDE} When $G_{\bm{\theta}}=G$, a single step of $\gamma$-sampling is expressed as:
\begin{align*}
    \mathbf{x}_{t_{n+1}}^{\gamma}&=\mathbf{x}_{t_{n}} +G(\mathbf{x}_{t_{n}},t_{n},\sqrt{1-\gamma^{2}}t_{n+1})+\gamma t_{n+1}\bm{\epsilon}\\
    &=\mathbf{x}_{t_{n}}- \bigg( \underset{\text{past information}}{\underbrace{\int_{t_{n}}^{t_{n+1}}u\nabla\log{p_{u}(\mathbf{x}_{u})}\diff u}} + \underset{\text{future information}}{\underbrace{\int_{t_{n+1}}^{\sqrt{1-\gamma^{2}}t_{n+1}}u\nabla\log{p_{u}(\mathbf{x}_{u})}\diff u}} \bigg)+\gamma t_{n+1}\bm{\epsilon},
\end{align*}
where $\bm{\epsilon}\sim\mathcal{N}(0,\mathbf{I})$. This formulation cannot be interpreted as a differential form~\citep{oksendal2003stochastic} because it look-ahead future information (from $t_{n+1}$ to $\sqrt{1-\gamma^{2}}t_{n+1}$) to generate the sample $\mathbf{x}_{t_{n+1}}^{\gamma}$ at time $t_{n+1}$. This suggests that there is no It\^o's SDE that corresponds to our $\gamma$-sampler pathwisely, opening up new possibilities for the development of a new family of diffusion samplers.

\textbf{Connection with EDM's stochastic sampler}\label{sec:edm_stochastic}
We conduct a direct comparison between EDM's stochastic sampler and CTM's $\gamma$-sampling. We denote $\texttt{Heun}(\mathbf{x}_t, t, s)$ as Heun's solver initiated at time $t$ and point $\mathbf{x}_t$ and ending at time $s$. It's worth noting that EDM's sampler inherently experiences discretization errors stemming from the use of Heun's solver, while CTM is immune to such errors.

The primary distinction between EDM's stochastic sampling in Algorithm~\ref{alg:EDM} and CTM's $\gamma$-sampling in Algorithm~\ref{alg:gamma} is the order of the forward (diffuse) and backward (denoise) steps. However, through the iterative process of forward-backward time traveling, these two distinct samplers become indistinguishable. Aside from the order of forward-backward steps, the two algorithms essentially align if we opt to synchronize the CTM's time $(t_{n}^{\text{CTM}},\tilde{t}_{n}^{\text{CTM}})$ to with the EDM's time $(\hat{t}_{n}^{\text{EDM}},t_{n+1}^{\text{EDM}})$, respectively, and their $\gamma$s accordingly. 

\begin{minipage}{0.48\textwidth}
\begin{algorithm}[H]
    \centering
    \caption{EDM's sampler}\label{alg:EDM}
    \begin{algorithmic}[1]
    \State Start from $\mathbf{x}_{t_{0}}\sim\pi$
        \For{$n=0$ to $N-1$}
        \State $\hat{t}_{n}\leftarrow (1+\gamma)t_{n}$
        \State Diffuse $\mathbf{x}_{\hat{t}_{n}}\leftarrow\mathbf{x}_{t_{n}}+\sqrt{\hat{t}_{n}^{2}-t_{n}^{2}}\bm{\epsilon}$
        \State Denoise $\mathbf{x}_{t_{n+1}}\leftarrow\texttt{Heun}(\mathbf{x}_{\hat{t}_{n}},\hat{t}_{n},t_{n+1})$
        \EndFor
        \State \textbf{Return}  $\mathbf{x}_{t_{N}}$
    \end{algorithmic}
\end{algorithm}
\end{minipage}
\hfill
\begin{minipage}{0.48\textwidth}
\begin{algorithm}[H]
    \centering
    \caption{CTM's $\gamma$-sampling}\label{alg:gamma}
    \begin{algorithmic}[1]
    \State Start from $\mathbf{x}_{t_{0}}\sim\pi$
        \For{$n=0$ to $N-1$}
        \State $\tilde{t}_{n+1}\leftarrow \sqrt{1-\gamma^{2}}t_{n+1}$
        \State Denoise $\mathbf{x}_{\tilde{t}_{n+1}}\leftarrow G_{\bm{\theta}}(\mathbf{x}_{t_{n}},t_{n},\tilde{t}_{n+1})$
        \State Diffuse $\mathbf{x}_{t_{n+1}}\leftarrow\mathbf{x}_{\hat{t}_{n+1}}+\gamma t_{n+1}\bm{\epsilon}$
        \EndFor
        \State \textbf{Return}  $\mathbf{x}_{t_{N}}$
    \end{algorithmic}
\end{algorithm}
\end{minipage}


\begin{algorithm}[H]
    \centering
    \caption{Loss-based Trajectory Optimization}\label{alg:application}
    \begin{algorithmic}[1]
    \State $\mathbf{x}_{ref}$ is given
    \State Diffuse $\mathbf{x}_{t_{0}}\leftarrow\mathbf{x}_{ref}+t_{0}\bm{\epsilon}$
        \For{$n=1$ to $N$}
        \State $\tilde{t}_{n}\leftarrow\sqrt{1-\gamma^{2}}t_{n}$
        \State Denoise $\mathbf{x}_{\tilde{t}_{n}}\leftarrow G_{\bm{\theta}}(\mathbf{x}_{t_{n-1}},t_{n-1},\tilde{t}_{n})$
        \For{$m=1$ to $M$}
        \State Sample $\bm{\epsilon},\bm{\epsilon}'\sim\mathcal{N}(0,\mathbf{I})$
        \State Apply corrector $\mathbf{x}_{\tilde{t}_{n}}\leftarrow \mathbf{x}_{\tilde{t}_{n}}+\frac{\zeta}{2}\Big(\nabla\log{p_{\tilde{t}_{n}}(\mathbf{x}_{\tilde{t}_{n}})}-c_{\tilde{t}_{n}}\nabla_{\mathbf{x}_{\tilde{t}_{n}}}L(\mathbf{x}_{\tilde{t}_{n}},\mathbf{x}_{ref}+\tilde{t}_{n}\bm{\epsilon})\Big)+\sqrt{\zeta}\bm{\epsilon}'$
        \EndFor
        \State Sample $\bm{\epsilon}\sim\mathcal{N}(0,\mathbf{I})$
        \State Diffuse $\mathbf{x}_{t_{n}}\leftarrow\mathbf{x}_{\hat{t}_{n}}+\gamma t_{n}\bm{\epsilon}$
        \EndFor
    \end{algorithmic}
\end{algorithm}

\subsection{Trajectory Control with Guidance}\label{subsec:traj_control}


We could apply $\gamma$-sampling for application tasks, such as image inpainting or colorization, using the (straightforwardly) generalized algorithm suggested in CM. In this section, however, we propose a loss-based trajectory optimization algorithm in Algorithm~\ref{alg:application} for potential application downstream tasks.

Algorithm~\ref{alg:application} uses the time traversal from $t_{n-1}$ to $\tilde{t}_{n}$, and apply the loss-embedded corrector~\citep{song2020score} algorithm to explore $\tilde{t}_{n}$-manifold. For instance, the loss could be a feature loss between $\mathbf{x}_{\tilde{t}_{n}}$ and $\mathbf{x}_{\text{ref}}+\tilde{t}_{n}\bm{\epsilon}$. With this corrector-based guidance, we could control the sample variance. This loss-embedded corrector could also be interpreted as sampling from a posterior distribution. For Figure~\ref{fig:cat_stroke}, we choose $N=2$ with $(t_{0},t_{1})=\big((\sigma_{\text{max}}^{1/\rho}+(\sigma_{\text{min}}^{1/\rho}-\sigma_{\text{max}}^{1/\rho})0.45)^{\rho}, (\sigma_{\text{max}}^{1/\rho}+(\sigma_{\text{min}}^{1/\rho}-\sigma_{\text{max}}^{1/\rho})0.35)^{\rho}\big)$, $c_{\tilde{t}_{n}}\equiv 1$, and $M=10$.

\section{Implementation Details}\label{sec:implementation}

\begin{table}[t]
	\caption{Implementation details.}
	\label{tab:implementation}
	\scriptsize
	\centering
	\begin{tabular}{lcccc}
		\toprule
		Hyperparameter & \multicolumn{3}{c}{CIFAR-10} & ImageNet 64x64 \\\cmidrule(lr){2-4}\cmidrule(lr){5-5}
        & \multicolumn{2}{c}{Unconditional} & Conditional & Conditional \\\cmidrule(lr){2-3}\cmidrule(lr){4-4}\cmidrule(lr){5-5}
        & Training with $\bm{\phi}$ & Training from Scratch & Training with $\bm{\phi}$ & Training with $\bm{\phi}$ \\\cmidrule(lr){1-1}\cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(lr){4-4}\cmidrule(lr){5-5}
        Learning rate & 0.0004 & 0.0004 & 0.0004 & 0.000008 \\
        Discriminator learning rate & 0.002 & 0.002 & 0.002 & 0.002 \\
        $\mu$ & 0.9999 & 0.999 & 0.999 & 0.999 \\
        $N$ & 18 & 18 & 18 & 40 \\
        ODE solver & Heun & Self & Heun & Heun \\
        Max. ODE steps & 17 & 17 & 17 & 20 \\
        EMA decay rate & 0.999 & 0.999 & 0.999 & 0.999 \\
        Training iterations & 100K & 100K & 100K & 30K \\
        Mixed-Precision (FP16) & True & True & True & True \\
        Batch size & 256 & 128 & 512 & 2048 \\
        Number of GPUs & 4 & 4 & 4 & 8 \\
            \bottomrule
	\end{tabular}
\end{table}

\subsection{Training Details}\label{appendix:training_details}

Following \citet{karras2022elucidating}, we utilize the EDM's skip scale and output scale for $g_{\bm{\theta}}$ modeling as
\begin{align*}
    g_{\bm{\theta}}(\mathbf{x}_{t},t,s)=\frac{\sigma_{\text{data}}^{2}}{t^{2}+\sigma_{\text{data}}^{2}}\mathbf{x}_{t}+\frac{t\sigma_{\text{data}}}{\sqrt{t^{2}+\sigma_{\text{data}}^{2}}}\text{NN}_{\bm{\theta}}(\mathbf{x}_{t},t,s),
\end{align*}
where $\text{NN}_{\bm{\theta}}$ refers to a neural network that takes the same input arguments as $g_{\bm{\theta}}$.
The advantage of this EDM-style skip and output scaling is that if we copy the teacher model's parameters to the student model's parameters, except student model's $s$-embedding structure, $g_{\bm{\theta}}(\mathbf{x}_{t},t,t)$ initialized with $\bm{\phi}$ would be close to the teacher denoiser $D_{\bm{\phi}}(\mathbf{x}_{t},t)$. This good initialization partially explains the fast convergence speed.

We use 4$\times$V100 (16G) GPUs for CIFAR-10 experiments and 8$\times$A100 (40G) GPUs for ImageNet experiments. We use the warm-up for $\lambda_{\text{GAN}}$ hyperparameter. On CIFAR-10, we deactivate GAN training with $\lambda_{\text{GAN}}=0$ until 50k training iterations and activate the generator training with the adversarial loss (added to CTM and DSM losses) by increasing $\lambda_{\text{GAN}}$ to one. The minibatch per GPU is 16 in the CTM+DSM training phase, and 11 in the CTM+DSM+GAN training phase. On ImageNet, due to the excessive training budget, we deactivate GAN only for 10k iterations and activate GAN training afterwards. We fix the minibatch to be 11 throughout the CTM+DSM or the CTM+DSM+GAN training in ImageNet.

We follow the training configuration mainly from CM, but for the discriminator training, we follow that of StyleGAN-XL~\citep{sauer2022stylegan}. For $\mathcal{L}_{\text{CTM}}$ calculation, we use LPIPS~\citep{zhang2018unreasonable} as a feature extractor. We choose $t$ and $s$ from the $N$-discretized timesteps to calculate $\mathcal{L}_{\text{CTM}}$, following CM. Across the training, we choose the maximum number of ODE steps to prevent a single iteration takes too long time. For CIFAR-10, we choose $N=18$ and the maximum number of ODE steps to be 17. For ImageNet, we choose $N=40$ and the maximum number of ODE steps to be 20. We find the tendency that the training performance is improved by the number of ODE steps, so one could possibly improve our ImageNet result by choosing larger maximum ODE steps.

For $\mathcal{L}_{\text{DSM}}$ calculation, we select $50\%$ of time sampling from EDM's original scheme of $t\sim\mathcal{N}(-1.2, 1.2^{2})$. For the other half time, we first draw sample from $\xi\sim[0,0.7]$ and transform it using $(\sigma_{\text{max}}^{1/\rho}+\xi(\sigma_{\text{min}}^{1/\rho}-\sigma_{\text{max}}^{1/\rho}))^{\rho}$. This specific time sampling blocks the neural network to forget the denoiser information for large time. For $\mathcal{L}_{\text{GAN}}$ calculation, we use two feature extractors to transform GAN input to the feature space: the EfficientNet~\citep{tan2019efficientnet} and DeiT-base~\citep{touvron2021training}. Before obtaining an input's feature, we upscale the image to 224x224 resolution with bilinear interpolation. After transforming to the feature space, we apply the cross-channel mixing and cross-scale mixing to represent the input with abundant and non-overlapping features. The output of the cross-scale mixing is a feature pyramid consisting of four feature maps at different resolutions~\citep{sauer2022stylegan}. In total, we use eight discriminators (four for EfficientNet features and the other four for DeiT-base features) for GAN training.

Following CM, we apply Exponential Moving Average (EMA) to update $\texttt{sg}(\bm{\theta})$ by
\begin{align*}
    \texttt{sg}(\bm{\theta})\leftarrow \texttt{stopgrad}(\mu\texttt{sg}(\bm{\theta})+(1-\mu)\bm{\theta}).
\end{align*}
However, unlike CM, we find that our model bestly works with $\mu=0.999$ or $\mu=0.9999$, which largely remedy the subtle instability arise from GAN training. Except for the unconditional CIFAR-10 training with $\bm{\phi}$, we set $\mu$ to be 0.999 as default. Throughout the experiments, we use $\sigma_{\text{min}}=0.002$, $\sigma_{\text{max}}=80$, $\rho=7$, and $\sigma_{\text{data}}=0.5$.

\subsection{Evaluation Details}\label{appendix:sampling_details}

For likelihood evaluation, we solve the PF ODE, following the practice suggested in \citet{kim2022maximum} with the RK45~\citep{dormand1980family} ODE solver of $\texttt{tol}=1e-3$ and $t_{\text{min}}=0.002$. 

Throughout the paper, we choose $\gamma=0$ otherwise stated. In particular, for Tables~\ref{tab:cifar10_baseline} and \ref{tab:ImageNet64_baseline}, we report the sample quality metrics based on either the one-step sampling of CM or the $\gamma=0$ sampling for NFE 2 case. For CIFAR-10, we calculate the FID score based on \citet{karras2022elucidating} statistics. For ImageNet, we compute the metrics following \citet{dhariwal2021diffusion} and their pre-calculated statistics. For the StyleGAN-XL ImageNet result, we recalculated the metrics based on the statistics released by \citet{dhariwal2021diffusion}, using StyleGAN-XL's official checkpoint.

For large-NFE sampling, we follow the EDM's time discretization. Namely, if we draw $n$-NFE samples, we equi-divide $[0,1]$ with $n$ points and transform it (say $\xi$) to the time scale by $(\sigma_{\text{max}}^{1/\rho}+(\sigma_{\text{min}}^{1/\rho}-\sigma_{\text{max}}^{1/\rho})\xi)^{\rho}$. However, we emphasize the time discretization for both training and sampling is a modeler's choice.

\section{Additional Generated Samples}\label{sec:generated_samples}
\begin{figure}[t]\centering
	\begin{subfigure}{0.24\linewidth}
		\centering
		\includegraphics[width=\linewidth]{image_1.pdf}
		\subcaption{Tench}
	\end{subfigure}
	\begin{subfigure}{0.24\linewidth}
		\centering
		\includegraphics[width=\linewidth]{image_2.pdf}
		\subcaption{Tree frog}
	\end{subfigure}	
 	\begin{subfigure}{0.24\linewidth}
		\centering
		\includegraphics[width=\linewidth]{image_3.pdf}
		\subcaption{Elephant}
	\end{subfigure}
  	\begin{subfigure}{0.24\linewidth}
		\centering
		\includegraphics[width=\linewidth]{image_4.pdf}
		\subcaption{Kimono}
	\end{subfigure}
	\caption{Uncurated sample comparisons with identical starting points, generated by EDM (FID 2.44) with NFE 79, CTM (FID 2.06) with NFE 1, CTM (FID 1.90) with NFE 2, and CM (FID 6.20) with NFE 1, on (a) tench (class id: 0), (b) tree frog (class id: 31), (c) elephant (class id: 386), and (d) kimono (class id: 614).}
    \label{fig:image_results}
	 \vskip -0.1in
\end{figure}
\newpage
\clearpage
\section{Theoretical Supports and Proofs}\label{sec:proof}

\subsection{Proof of Lemma~\ref{th:unification}}
\begin{myproof}{Lemma}{\ref{th:unification}}
As the score, $\nabla\log p_t(\mathbf{x})$, is integrable, the Fundamental Theorem of Calculus applies, leading to
\begin{align*}
    \lim_{s\rightarrow t}g(\mathbf{x}_{t},t,s)&=\mathbf{x}_{t}+t\lim_{s\rightarrow t}\frac{1}{t-s}\int_{t}^{s}\frac{\mathbf{x}_{u}-\mathbb{E}[\mathbf{x}_{0}\vert\mathbf{x}_{u}]}{u}\diff u
    \\&=\mathbf{x}_{t}-t\frac{\mathbf{x}_{t}-\mathbb{E}[\mathbf{x}_{0}\vert\mathbf{x}_{t}]}{t}\\
    &=\mathbb{E}[\mathbf{x}_{0}\vert\mathbf{x}_{t}].
\end{align*}
\end{myproof}

\subsection{Proof of Theorem~\ref{th:sampling_agg_error_2_steps}}



\begin{myproof}{Theorem}{\ref{th:sampling_agg_error_2_steps}}
Define $\mathcal{T}_{t\rightarrow s}$ as the oracle transition mapping from $t$ to $s$ via the diffusion process Eq.~\eqref{eq:sde_forward}. Let $\mathcal{T}_{t\rightarrow s}^{\bm{\theta}^*}(\cdot)$ represent the transition mapping from the optimal CTM, and $\mathcal{T}_{t\rightarrow s}^{\bm{\phi}}(\cdot)$ represent the transition mapping from the empirical probability flow ODE. 
Since all processes start at point $T$ with initial probability distribution $p_T$ and $\mathcal{T}_{t\rightarrow s}^{\bm{\theta}^*}(\cdot)=\mathcal{T}_{t\rightarrow s}^{\bm{\phi}}(\cdot)$, Theorem 2~in \citep{chen2022sampling} and $\mathcal{T}_{T\rightarrow t}\sharp p_T=p_t$ from Proposition~\ref{th:transition} tell us that for $t>s$

\begin{align}\label{eq:tv_error_1_step}
    D_{TV}\left(\mathcal{T}_{t\rightarrow s}\sharp p_t, \mathcal{T}_{t\rightarrow s}^{\bm{\theta}^*}\sharp p_t\right) 
    = D_{TV}\left(\mathcal{T}_{t\rightarrow s}\sharp p_t, \mathcal{T}_{t\rightarrow s}^{\bm{\phi}}\sharp p_t\right)=\mathcal{O}(t-s).
\end{align}

\begin{align*}
    &D_{TV}\left(\mathcal{T}_{t\rightarrow 0}\mathcal{T}_{\sqrt{1-\gamma^2}t\rightarrow t}\mathcal{T}_{T\rightarrow\sqrt{1-\gamma^2}t}\sharp p_T, \mathcal{T}_{t\rightarrow 0}^{\bm{\theta}^* }\mathcal{T}_{\sqrt{1-\gamma^2}t\rightarrow t}\mathcal{T}_{T\rightarrow\sqrt{1-\gamma^2}t}^{\bm{\theta}^* }\sharp p_T\right)
    \\  \overset{(a)}{\leq} &D_{TV}\left(\mathcal{T}_{t\rightarrow 0}\mathcal{T}_{\sqrt{1-\gamma^2}t\rightarrow t}\mathcal{T}_{T\rightarrow\sqrt{1-\gamma^2}t}\sharp p_T, \mathcal{T}_{t\rightarrow 0}^{\bm{\theta}^* }\mathcal{T}_{\sqrt{1-\gamma^2}t\rightarrow t}\mathcal{T}_{T\rightarrow\sqrt{1-\gamma^2}t}\sharp p_T\right)
    \\  + &D_{TV}\left(\mathcal{T}_{t\rightarrow 0}^{\bm{\theta}^* }\mathcal{T}_{\sqrt{1-\gamma^2}t\rightarrow t}\mathcal{T}_{T\rightarrow\sqrt{1-\gamma^2}t}\sharp p_T,\mathcal{T}_{t\rightarrow 0}^{\bm{\theta}^* }\mathcal{T}_{\sqrt{1-\gamma^2}t\rightarrow t}\mathcal{T}_{T\rightarrow\sqrt{1-\gamma^2}t}^{\bm{\theta}^* }\sharp p_T\right)
    \\  \overset{(b)}{=}&D_{TV}\left(\mathcal{T}_{t\rightarrow 0}\mathcal{T}_{T\rightarrow t}\sharp p_T, \mathcal{T}_{t\rightarrow 0}^{\bm{\theta}^* }\mathcal{T}_{T\rightarrow t}\sharp p_T\right) + D_{TV}\left(\mathcal{T}_{T\rightarrow\sqrt{1-\gamma^2}t}\sharp p_T,\mathcal{T}_{T\rightarrow\sqrt{1-\gamma^2}t}^{\bm{\theta}^* }\sharp p_T\right)
    \\ \overset{(c)}{=}&D_{TV}\left(\mathcal{T}_{t\rightarrow 0}\sharp p_t, \mathcal{T}_{t\rightarrow 0}^{\bm{\theta}^* }\sharp p_t\right) + D_{TV}\left(\mathcal{T}_{T\rightarrow\sqrt{1-\gamma^2}t}\sharp p_T,\mathcal{T}_{T\rightarrow\sqrt{1-\gamma^2}t}^{\bm{\theta}^* }\sharp p_T\right)
    \\ \overset{(d)}{=}& \mathcal{O}(\sqrt{t}) + \mathcal{O}(\sqrt{T-\sqrt{1-\gamma^2}t}).
 \end{align*}

Here (a) is obtained from the triangular inequality, (b) and (c) are due to $\mathcal{T}_{\sqrt{1-\gamma^2}t\rightarrow t}\mathcal{T}_{T\rightarrow\sqrt{1-\gamma^2}t}=\mathcal{T}_{T\rightarrow t}$ and $\mathcal{T}_{T\rightarrow t}\sharp p_T=p_t$ from Proposition~\ref{th:transition}, and (d) comes from Eq.~\eqref{eq:tv_error_1_step}.  
    
    

\end{myproof}





\subsection{Proof of Proposition~\ref{th:ptw_distill}}


\begin{myproof}{Proposition}{\ref{th:ptw_distill}} Consider a LPIPS-like metric, denoted as $d(\cdot, \cdot)$, determined by a feature extractor $\mathcal{F}$ of $p_{\text{data}}$. That is, $d(\mathbf{x}, \mathbf{y})=\norm{\mathcal{F}(\mathbf{x})-\mathcal{F}(\mathbf{y})}_{q}$ for $q\geq1$. For simplicity of notation, we denote $\bm{\theta}_N$ as $\bm{\theta}$.
    Since $\mathcal{L}_{\text{CTM}}^{N}(\bm{\theta};\bm{\phi})=0$, it implies that for any $\mathbf{x}_{t_n}$, $n\in[\![ 1,N ]\!]$, and $m\in[\![ 1,n ]\!]$  
\begin{align}\label{eq:ctm_zero}
    \mathcal{F}\big( G_{\bm{\theta}}(G_{\bm{\theta}}(\mathbf{x}_{t_{n+1}},t_{n+1},t_m),t_m,0)\big) = \mathcal{F}\big( G_{\bm{\theta}}(G_{\bm{\theta}}(\mathbf{x}_{t_{n}}^{\bm{\phi}},t_{n},t_m),t_m,0)  \big)
\end{align}

Denote 
\begin{align*}
    \mathbf{e}_{n,m}:= \mathcal{F}\big( G_{\bm{\theta}}(G_{\bm{\theta}}(\mathbf{x}_{t_n},t_n,t_m),t_m,0)\big) - \mathcal{F}\big( G_{\bm{\theta}}(G(\mathbf{x}_{t_{n}},t_{n},t_m; \bm{\phi}),t_m,0)  \big).
\end{align*}
Then due to Eq.~\eqref{eq:ctm_zero} and $G$ is an ODE-trajectory function that $G(\mathbf{x}_{t_{n+1}},t_{n+1},t_m; \bm{\phi})=G(\mathbf{x}_{t_{n}},t_{n},t_m; \bm{\phi})$, we have
\begin{align*}
    \mathbf{e}_{n+1,m} &= \mathcal{F}\big( G_{\bm{\theta}}(G_{\bm{\theta}}(\mathbf{x}_{t_{n+1}},t_{n+1},t_m),t_m,0)\big) - \mathcal{F}\big( G_{\bm{\theta}}(G(\mathbf{x}_{t_{n+1}},t_{n+1},t_m; \bm{\phi}),t_m,0)  \big)
    \\ &= \mathcal{F}\big( G_{\bm{\theta}}(G_{\bm{\theta}}(\mathbf{x}_{t_{n}}^{\bm{\phi}},t_{n},t_m),t_m,0)  \big) - \mathcal{F}\big( G_{\bm{\theta}}(G(\mathbf{x}_{t_{n}},t_{n},t_m; \bm{\phi}),t_m,0)  \big)
    \\ &= \mathcal{F}\big( G_{\bm{\theta}}(G_{\bm{\theta}}(\mathbf{x}_{t_{n}}^{\bm{\phi}},t_{n},t_m),t_m,0)  \big) - \mathcal{F}\big( G_{\bm{\theta}}(G_{\bm{\theta}}(\mathbf{x}_{t_n},t_n,t_m),t_m,0)\big) \\ &+ \mathcal{F}\big( G_{\bm{\theta}}(G_{\bm{\theta}}(\mathbf{x}_{t_n},t_n,t_m),t_m,0)\big) - \mathcal{F}\big( G_{\bm{\theta}}(G(\mathbf{x}_{t_{n}},t_{n},t_m; \bm{\phi}),t_m,0)  \big)
    \\ &= \mathcal{F}\big( G_{\bm{\theta}}(G_{\bm{\theta}}(\mathbf{x}_{t_{n}}^{\bm{\phi}},t_{n},t_m),t_m,0)  \big) - \mathcal{F}\big( G_{\bm{\theta}}(G_{\bm{\theta}}(\mathbf{x}_{t_n},t_n,t_m),t_m,0)\big) + \mathbf{e}_{n,m}. 
\end{align*}
Therefore, 
\begin{align*}
    \norm{\mathbf{e}_{n+1,m}}_q &\leq  \norm{\mathcal{F}\big( G_{\bm{\theta}}(G_{\bm{\theta}}(\mathbf{x}_{t_{n}}^{\bm{\phi}},t_{n},t_m),t_m,0)  \big) - \mathcal{F}\big( G_{\bm{\theta}}(G_{\bm{\theta}}(\mathbf{x}_{t_n},t_n,t_m),t_m,0)\big)}_q + \norm{\mathbf{e}_{n,m}}_q
    \\ &\leq L_1 L_2^2 \norm{\mathbf{x}_{t_{n}}^{\bm{\phi}} - \mathbf{x}_{t_n}}_q + \norm{\mathbf{e}_{n,m}}_q
    \\ &=\mathcal{O}((t_{n+1} - t_n)^{p+1})+ \norm{\mathbf{e}_{n,m}}_q. 
\end{align*}

Notice that since $G_{\bm{\theta}}(\mathbf{x}_{t_m},t_m,t_m) = \mathbf{x}_{t_m} = G(\mathbf{x}_{t_{m}},t_{m},t_m; \bm{\phi})$, $\mathbf{e}_{m,m}=\mathbf{0}$.

So we can obtain via induction that 
\begin{align*}
    \norm{\mathbf{e}_{n+1,m}}_q &\leq \norm{\mathbf{e}_{m,m}}_q + \sum_{k=m}^{n-1} \mathcal{O}((t_{k+1} - t_k)^{p+1})
    \\ &= \sum_{k=m}^{n-1} \mathcal{O}((t_{k+1} - t_k)^{p+1})
    \\ &\leq \mathcal{O}((\Delta_N t)^{p}) (t_n - t_m).
\end{align*}
\end{myproof}

Indeed, an analogue of Proposition~\ref{th:ptw_distill} holds for time-conditional feature extractors.

Let $d_{t}(\cdot, \cdot)$ be a LPIPS-like metric determined by a time-conditional feature extractor $\mathcal{F}_{t}$. That is, $d_{t}(\mathbf{x}, \mathbf{y})=\norm{\mathcal{F}_{t}(\mathbf{x})-\mathcal{F}_{t}(\mathbf{y})}_{q}$ for $q\geq1$. We can similarly derive

\begin{align*}
    \sup_{\mathbf{x}\in\mathbb{R}^D} d_{t_m}\big(G_{\bm{\theta}}(\mathbf{x}, t_n, t_m) ,G(\mathbf{x}, t_n, t_m; \bm{\phi})\big) = \mathcal{O}((\Delta_N t)^{p})(t_n - t_m).
\end{align*}





\subsection{Proof of Proposition~\ref{th:density_match}}



\begin{myproof}{Proposition}{\ref{th:density_match}}
    We first prove that for any $t\in[0,T]$ and $s\leq t$, as $N\rightarrow\infty$,
    \begin{align}\label{eq:conti_time_distill}
    \sup_{\mathbf{x}\in\mathbb{R}^D} \norm{G_{\bm{\theta}_N}(G_{\bm{\theta}_N}(\mathbf{x}, t, s), s, 0) ,G_{\bm{\theta}_N}(G(\mathbf{x}, t, s; \bm{\phi}), s, 0)}_2 \rightarrow 0.
\end{align}
      We may assume $\{t_n \}_{n=1}^N$ so that $t_m = s$, $t_n=t$, and $t_{m+1} \rightarrow s$, $t_{n+1} \rightarrow t$ as $\Delta_N t \rightarrow \infty$.
    \begin{align*}
        &\sup_{\mathbf{x}}\norm{G_{\bm{\theta}_N}(G_{\bm{\theta}_N}(\mathbf{x}, t, s), s, 0) ,G_{\bm{\theta}_N}(G(\mathbf{x}, t, s; \bm{\phi}), s, 0)}_2  
        \\ \leq &\sup_{\mathbf{x}} \norm{G_{\bm{\theta}_N}(G_{\bm{\theta}_N}(\mathbf{x}, t, s), s, 0) ,G_{\bm{\theta}_N}(G_{\bm{\theta}_N}(\mathbf{x}, t_{n+1}, t_{m+1}; \bm{\phi}), t_{m+1}, 0)}_2 
        \\ + &\sup_{\mathbf{x}} \norm{G_{\bm{\theta}_N}(G_{\bm{\theta}_N}(\mathbf{x}, t_{n+1}, t_{m+1}; \bm{\phi}), t_{m+1}, 0) ,G_{\bm{\theta}_N}(G(\mathbf{x}, t_{n+1}, t_{m+1}; \bm{\phi}), t_{m+1}, 0)}_2 
        \\ + & \sup_{\mathbf{x}} \norm{G_{\bm{\theta}_N}(G(\mathbf{x}, t_{n+1}, t_{m+1}; \bm{\phi}), t_{m+1}, 0) ,G_{\bm{\theta}_N}(G(\mathbf{x}, t, s; \bm{\phi}), s, 0)}_2
    \end{align*}
Since both $G$ and $G_{\bm{\theta}_N}$ are uniform continuous on $\mathbb{R}^D\times[0, T]\times[0, T]$, together with Proposition~\ref{th:ptw_distill}, we obtain Eq.~\eqref{eq:conti_time_distill} as $\Delta_N t \rightarrow \infty$.

     In particular, Eq.~\eqref{eq:conti_time_distill} implies that when $N\rightarrow\infty$
    \begin{align*}
    &\sup_{\mathbf{x}}\norm{G_{\bm{\theta}_N}
    (G_{\bm{\theta}_N}(\mathbf{x}, T, 0), 0, 0) - G_{\bm{\theta}_N}(G(\mathbf{x}, T, 0; \bm{\phi}), 0, 0)}_2 
    \\= &\sup_{\mathbf{x}}\norm{G_{\bm{\theta}_N}(\mathbf{x}, T, 0) - G(\mathbf{x}, T, 0; \bm{\phi})}_2\rightarrow 0.
    \end{align*}
    
    This implies that $p_{\bm{\theta}_N}(\cdot)$, the pushforward distribution of $p_T$ induced by $G_{\bm{\theta}_N}(\cdot, T, 0)$, converges in distribution to $p_{\phi}(\cdot)$. Note that since $\{G_{\bm{\theta}_N} \}_{N}$ is uniform Lipschitz
    \begin{align*}
        \norm{G_{\bm{\theta}}(\mathbf{x}, t, s) - G_{\bm{\theta}}(\mathbf{x}', t, s)}_2 \leq L \norm{\mathbf{x} - \mathbf{x}'}_2, \quad \text{for all } \mathbf{x}, \mathbf{x}'\in \mathbb{R}^D, t, s\in[0,T], \text{ and } \bm{\theta},
    \end{align*}
    $\{G_{\bm{\theta}_N} \}_{N}$ is asymptotically uniformly equicontinuous.  Moreover, $\{G_{\bm{\theta}_N} \}_{N}$ is uniform bounded in $\bm{\theta}_N$. Therefore, the converse of Scheff\'e's theorem
    \citep{boos1985converse,sweeting1986converse} implies that $\norm{p_{ \bm{\theta}_N}(\cdot)- p_{\bm{\phi}}(\cdot)}_{\infty}\rightarrow 0 $ as $N\rightarrow\infty$. Similar argument can be adapted to prove $\norm{p_{\bm{\theta}_N}(\cdot)- p_{\text{data}}(\cdot)}_{{\infty}}\rightarrow 0$ as $N\rightarrow\infty$ if the regression target $p_{\bm{\phi}}(\cdot)$ is replaced with $p_{ \text{data}}(\cdot)$.
\end{myproof}



\subsection{Proof of Proposition~\ref{th:gt_injective}}


\begin{lemma}\label{th:injective_sol_op}
    Let $f\colon\mathbb{R}^D\times[0,T]\rightarrow\mathbb{R}^D$ be a function which satisfies the following conditions:
    \begin{enumerate}[(a)]
        \item $f(\cdot, t)$ is Lipschitz for any $t\in[0,T]$: there is a function $L(t)\geq0$ so that for any $t\in[0,T]$ and $\mathbf{x},\mathbf{y}\in\mathbb{R}^D$
        \begin{align*}
            \norm{f(\mathbf{x}, t)-f(\mathbf{y}, t)}\leq L(t)\norm{\mathbf{x}-\mathbf{y}}, 
        \end{align*}
        \item Linear growth in $\mathbf{x}$: there is a $L^1$- integrable function $M(t)$ so that for any $t\in[0,T]$ and $\mathbf{x}\in\mathbb{R}^D$
        \begin{align*}
            \norm{f(\mathbf{x}, t)}\leq M(t)(1+\norm{\mathbf{x}}).
        \end{align*}        
    \end{enumerate}
    Consider the following ODE 
    \begin{align}\label{eq:lemma_ode}
        \mathbf{x}'(\tau)=f(\mathbf{x}(\tau), \tau)\quad\text{on }[0,T].
    \end{align}
   Fix a $t\in[0,T]$, the solution operator $\mathcal{T}$ of Eq.~\eqref{eq:lemma_ode} with an initial condition $\mathbf{x}_t$ is defined as
   \begin{align}\label{eq:sol_op}
       \mathcal{T}[\mathbf{x}_t](s):=\mathbf{x}_t+\int_{t}^{s}f(\mathbf{x}(\tau;\mathbf{x}_t), \tau)\diff\tau, \quad s\in[t,T].
   \end{align}
   Here $\mathbf{x}(\tau;\mathbf{x}_t)$ denotes the solution at time $\tau$ starting from the initial value $\mathbf{x}_t$.
   Then $\mathcal{T}$ is an injective operator. Moreover, $\mathcal{T}[\cdot](s)\colon\mathbb{R}^D\rightarrow\mathbb{R}^D$ is bi-Lipschitz; that is, for any $\mathbf{x}_t, \hat{\mathbf{x}}_t\in\mathbb{R}^D$
   \begin{align}
       e^{-L(s-t)}\norm{\mathbf{x}_t- \hat{\mathbf{x}}_t}_2\leq \norm{\mathcal{T}[\mathbf{x}_t](s) -\mathcal{T}[\hat{\mathbf{x}}_t](s)}_2 \leq e^{L(t-s)}\norm{\mathbf{x}_t- \hat{\mathbf{x}}_t}_2.
   \end{align}
   Here $L:=\sup_{t\in[0,T]} L(t)<\infty$.
   In particular, if $\mathbf{x}_t\neq\hat{\mathbf{x}}_t$, $\mathcal{T}[\mathbf{x}_t](s)\neq\mathcal{T}[\hat{\mathbf{x}}_t](s)$ for all $s\in[t, T]$.
\end{lemma}
\begin{myproof}{Lemma}{\ref{th:injective_sol_op}}

    Assumptions (a) and (b) ensure the solution operator in Eq.~\eqref{eq:sol_op} is well-defined by applying Carath\'eodory-type global existence theorem~\citep{reid1971ordinary}. We denote $\mathcal{T}[\mathbf{x}_t](s)$ as $\mathbf{x}(s; \mathbf{x}_t)$.
    We need to prove that for any distinct initial values $\mathbf{x}_t$ and $\hat{\mathbf{x}}_t$ starting from $t$,  $\mathcal{T}[\mathbf{x}_t]\not\equiv \mathcal{T}[\hat{\mathbf{x}}_t]$. Suppose on the contrary that there is an $s_0\in[t, T]$ so that $\mathcal{T}[\mathbf{x}_t](s_0) = \mathcal{T}[\hat{\mathbf{x}}_t](s_0)$. For $s\in[t_0,s_0]$, consider 
    $\mathbf{y}(s; \mathbf{x}_t) :=\mathbf{x}(t + s_0-s; \mathbf{x}_t)$ and $\mathbf{y}(s; \hat{\mathbf{x}}_t) :=\mathbf{x}(t_0 + s_0-s; \hat{\mathbf{x}}_t)$.
    Then both $\mathbf{y}(s; \mathbf{x}_t)$ and $\mathbf{y}(s; \hat{\mathbf{x}}_t)$ satisfy the following ODE
    \begin{align}\label{eq:lemma_ode_reverse}
    \begin{cases}
        \mathbf{y}'(s)=-f(\mathbf{y}(s), s), \quad s\in[t,s_0]\\
        \mathbf{y}(t)=\mathcal{T}[\mathbf{x}_t](s_0) = \mathcal{T}[\hat{\mathbf{x}}_t](s_0) 
    \end{cases}
    \end{align}
    Thus, the uniqueness theorem of solution to Eq.~\eqref{eq:lemma_ode_reverse} leads to $\mathbf{y}(s_0; \mathbf{x}_t) = \mathbf{y}(s_0; \hat{\mathbf{x}}_t)$, which means $\mathbf{x}_t=\hat{\mathbf{x}}_t$. This contradicts to the assumption. Hence, $\mathcal{T}$ is injective. 

    
    Now we show that $\mathcal{T}[\cdot](s)\colon\mathbb{R}^D\rightarrow\mathbb{R}^D$ is bi-Lipschitz for any $s\in[t,T]$. For any $\mathbf{x}_t, \hat{\mathbf{x}}_t\in\mathbb{R}^D$,
    \begin{align*}
       \norm{\mathcal{T}[\mathbf{x}_t](s) -\mathcal{T}[\hat{\mathbf{x}}_t](s)}_2 \nonumber
       &=\norm{\mathbf{x}(s;\mathbf{x}_t)-\hat{\mathbf{x}}(s;\hat{\mathbf{x}}_t)}_2
       \\& \leq \norm{\mathbf{x}_t-\hat{\mathbf{x}}_t}_2+ \int_{t}^{s}\norm{f(\mathbf{x}(\tau;\mathbf{x}_t),\tau)-f(\hat{\mathbf{x}}(\tau;\hat{\mathbf{x}}_t),\tau)}_2\diff \tau \nonumber
       \\& \leq \norm{\mathbf{x}_t-\hat{\mathbf{x}}_t}_2+ L\int_{t}^{s}\norm{\mathbf{x}(\tau;\mathbf{x}_t)-\hat{\mathbf{x}}(\tau;\hat{\mathbf{x}}_t)}_2\diff \tau. \nonumber
   \end{align*}
    By applying Gr\"ownwall's lemma, we obtain 
\begin{align}\label{eq:one_side_lip}
       \norm{\mathcal{T}[\mathbf{x}_t](s) -\mathcal{T}[\hat{\mathbf{x}}_t](s)}_2 
       =\norm{\mathbf{x}(s;\mathbf{x}_t)-\hat{\mathbf{x}}(s;\hat{\mathbf{x}}_t)}_2 \leq e^{L(s-t)}\norm{\mathbf{x}_t-\hat{\mathbf{x}}_t}_2. 
   \end{align}    
    On the other hand, consider the reverse time ODE of Eq.~\eqref{eq:lemma_ode} by setting $\tau=\tau(u):=t+s-u$, 
    $\mathbf{y}(u):=\mathbf{x}(t+s-u)$, and $h(\mathbf{y}(u), u):=-f(\mathbf{y}(u), t+s-u)$, then $\mathbf{y}$ satisfies the following equation
    \begin{align}\label{eq:lemma_ode_reverse_general}
        \mathbf{y}'(u)=h(\mathbf{y}(u), u), \quad u\in[t,s].
    \end{align}
    Similarly, we define the solution operator to Eq.~\eqref{eq:lemma_ode_reverse_general} as 
   \begin{align}\label{eq:sol_op_reverse}
       \mathcal{S}[\mathbf{y}_t](s):=\mathbf{y}_t+\int_{t}^{s}h(\mathbf{y}(u;\mathbf{y}_t), u)\diff u. 
   \end{align}    
    Here $\mathbf{y}_t$ denotes the initial value of Eq.~\eqref{eq:lemma_ode_reverse_general} and $\mathbf{y}(u;\mathbf{y}_t)$ is the solution starting from $\mathbf{y}_t$. Due to the Carath\'eodory-type global existence theorem, the operator $\mathcal{S}[\cdot](s)$ is well-defined and 
    \begin{align*}
        \mathcal{S}[\mathbf{x}(s;\mathbf{x}_t)](s)=\mathbf{x}_t,\quad \mathcal{S}[\hat{\mathbf{x}}(s;\mathbf{x}_t)](s)=\hat{\mathbf{x}}_t. 
    \end{align*}
    For simplicity, let $\mathbf{y}_t := \mathbf{x}(s; \mathbf{x}_t)$ and $\hat{\mathbf{y}}_t := \hat{\mathbf{x}}(s; \mathbf{x}_t)$. Also, denote the solutions starting from initial values $\mathbf{y}_t$ and $\hat{\mathbf{y}}_t$ as $\mathbf{y}(u;\mathbf{y}_t)$ and  $\hat{\mathbf{y}}(u;\hat{\mathbf{y}}_t)$, respectively.
    Therefore, using a similar argument, we obtain
    \begin{align*}
       \norm{\mathbf{x}_t-\hat{\mathbf{x}}_t}_2 
       &=\norm{\mathcal{S}[\mathbf{y}_t](s) -\mathcal{S}[\hat{\mathbf{y}}_t](s)}_2 \nonumber
       \\& \leq \norm{\mathbf{x}(s;\mathbf{x}_t)-\hat{\mathbf{x}}(s;\mathbf{x}_t)}_2+ \int_{t}^{s}\norm{h(\mathbf{y}(u;\mathbf{y}_t),u)-h(\hat{\mathbf{y}}(u;\hat{\mathbf{y}}_t),u)}_2\diff u \nonumber
       \\& \leq \norm{\mathbf{x}(s;\mathbf{x}_t)-\hat{\mathbf{x}}(s;\mathbf{x}_t)}_2 + L\int_{t}^{s}\norm{\mathbf{y}(u;\mathbf{y}_t)-\hat{\mathbf{y}}(u;\hat{\mathbf{y}}_t)}_2\diff u. \nonumber
       \\& = \norm{\mathcal{T}[\mathbf{x}_t](s) -\mathcal{T}[\hat{\mathbf{x}}_t](s)}_2 + L\int_{t}^{s}\norm{\mathbf{y}(u;\mathbf{y}_t)-\hat{\mathbf{y}}(u;\hat{\mathbf{y}}_t)}_2\diff u. \nonumber
   \end{align*}    
    By applying Gr\"ownwall's lemma, we obtain 
    \begin{align*}
       \norm{\mathbf{x}_t-\hat{\mathbf{x}}_t}_2 \leq e^{L(s-t)}\norm{\mathcal{T}[\mathbf{x}_t](s) -\mathcal{T}[\hat{\mathbf{x}}_t](s)}_2. 
   \end{align*}        
    Therefore, 
    \begin{align*} 
       e^{-L(s-t)}\norm{\mathbf{x}_t-\hat{\mathbf{x}}_t}_2 \leq \norm{\mathcal{T}[\mathbf{x}_t](s) -\mathcal{T}[\hat{\mathbf{x}}_t](s)}_2. 
   \end{align*}   
\end{myproof}

\begin{myproof}{Proposition}{\ref{th:gt_injective}} With the definition of $G(\mathbf{x}_t, t, s; \bm{\phi})$, we obtain
\begin{align*}
    G(\mathbf{x}_t, t, s; \bm{\phi})
    &=\frac{s}{t}\mathbf{x}_t + (1-\frac{s}{t})g(\mathbf{x}_t, t, s;\bm{\phi})
    \\&=\mathbf{x}_{t}+ \int_{t}^{s}\frac{\mathbf{x}_{{u}}-D_{\bm{\phi}}(\mathbf{x}_{u},{u}) }{{u}}\diff u.
\end{align*}
Here, $g(\mathbf{x}_{t},t,s;\bm{\phi})=\mathbf{x}_{t}+\frac{t}{t-s}\int_{t}^{s}\frac{\mathbf{x}_{{u}}-D_{\bm{\phi}}(\mathbf{x}_{u},{u}) }{{u}}\diff u$. Thus, the result follows by applying Lemma~\ref{th:injective_sol_op} to the integral form of $G(\mathbf{x}_t, t, s; \bm{\phi})$.

\end{myproof}






\subsection{Proof of Proposition~\ref{th:gamma_sampling}}




\begin{lemma}\label{th:Lip_var}
    Let $X$ be a random vector on $\mathbb{R}^D$ and $h\colon\mathbb{R}^D\rightarrow\mathbb{R}^D$ be a bi-Lipschitz mapping with Lipschitz constant $L>0$; namely, for any $\mathbf{x}, \mathbf{y}\in\mathbb{R}^D$
    \begin{align*}
        L^{-1}\norm{\mathbf{x}-\mathbf{y}}_2 \leq \norm{h(\mathbf{x})-h(\mathbf{y})}_2\leq L \norm{\mathbf{x}-\mathbf{y}}_2.
    \end{align*}
    Then 
    \begin{align*}
         L^{-2}\text{Var}(X)\leq\text{Var}(h(X))\leq L^2\text{Var}(X).
    \end{align*}
\end{lemma}

\begin{myproof}{Lemma}{\ref{th:Lip_var}}
    Let $Y$ be an i.i.d. copy of $X$. Then $h(X)$ and $h(Y)$ are also independent. Thus, $\text{cov}(X,Y)=0$ and $\text{cov}(h(X),h(Y))=0$.
    \begin{align}\label{eq:h_var}
        2\text{Var}\left(h(X)\right) 
        &=  \text{Var}\left(h(X)-h(Y)\right) \nonumber
        \\&=\mathbb{E}\left[\left(h(X)-h(Y)\right)^2 \right] - \left(\mathbb{E}\left[h(X)-h(Y) \right]\right)^2.
    \end{align}
    Since $h(X)$ and $h(Y)$ are identically distributed, $\mathbb{E}\left[h(X)-h(Y) \right]=\mathbb{E}\left[h(X)\right]-\mathbb{E}\left[h(Y)\right]=0$.
    Thus, by Lipschitzness of $h$
    \begin{align}\label{eq:h_var_lip}
        2\text{Var}\left(h(X)\right) 
        &=\mathbb{E}\left[\left(h(X)-h(Y)\right)^2 \right] 
        \\&\leq L^2 \mathbb{E}\left[\left(X-Y\right)^2 \right] \nonumber
        \\&= 2 L^2 \text{Var}\left(X\right). \nonumber
    \end{align}    
    The final equality follows the same reasoning as in Eq.~\eqref{eq:h_var}. Likewise, we can apply the argument from Eq.~\eqref{eq:h_var_lip} to show that
    \begin{align*}
        2\text{Var}\left(h(X)\right) 
        &=\mathbb{E}\left[\left(h(X)-h(Y)\right)^2 \right] 
       \\ &\geq L^{-2} \mathbb{E}\left[\left(X-Y\right)^2 \right] 
        \\&= 2 L^{-2} \text{Var}\left(X\right). \nonumber
    \end{align*}
    Therefore, $L^{-2} \text{Var}\left(X\right) \leq \text{Var}\left(X\right) \leq L^2 \text{Var}\left(X\right)$.
\end{myproof}


\begin{myproof}{Proposition}{\ref{th:gamma_sampling}}
For any $n\in\mathbb{N}$, since $G_{\bm{\theta}^*}(X_{n}, t_n,  \sqrt{1-\gamma^2} t_{n+1})$ and $Z_{n+1}$ are independent,
\begin{align}\label{eq:recursive_var}
    \text{Var}\left(X_{n+1}\right) 
    &= \text{Var}\left(G_{\bm{\theta}^*}(X_{n}, t_n,  \sqrt{1-\gamma^2} t_{n+1})\right) + \text{Var}\left( Z_{n+1}\right) \nonumber
    \\&= \text{Var}\left(G_{\bm{\theta}^*}(X_{n}, t_n,  \sqrt{1-\gamma^2} t_{n+1})\right) + \gamma^2\sigma^2(t_{n+1}).
\end{align}
Proposition~\ref{th:gt_injective} implies that $G_{\bm{\theta}^*}(\cdot, t_n, \sqrt{1-\gamma^2}t_{n+1})$ is bi-Lipschitz and that for any $\mathbf{x}, \mathbf{y}$
\begin{align}\label{eq:bi_lip_G}
    \zeta^{-1}(t_n, t_{n+1}, \gamma)\norm{\mathbf{x}-\mathbf{y}}_2 
    &\leq \norm{G_{\bm{\theta}^*}(\mathbf{x}, t_n, \sqrt{1-\gamma^2}t_{n+1}) - G_{\bm{\theta}^*}(\mathbf{y}, t_n, \sqrt{1-\gamma^2}t_{n+1})}_2 \nonumber
    \\&\leq \zeta(t_n, t_{n+1}, \gamma)\norm{\mathbf{x}-\mathbf{y}}_2,
\end{align}
where $\zeta(t_n, t_{n+1}, \gamma)=\exp{\left(2L_{\bm{\phi}}(t_n-\sqrt{1-\gamma^2}t_{n+1})\right)}$. Proposition~\ref{th:gamma_sampling} follows immediately from the inequalities \eqref{eq:recursive_var} and \eqref{eq:bi_lip_G}.
\end{myproof}


\subsection{Proof of Proposition~\ref{th:transition}}

\begin{myproof}{Proposition}{\ref{th:transition}}
    $\{p_t\}_{t=0}^{T}$ is known to satisfy the Fokker-Planck equation~\citep{oksendal2003stochastic} (under some technical regularity conditions). In addition, we can rewrite the Fokker-Planck equation of $\{p_t\}_{t=0}^{T}$ as the following equation (see Eq.~(37) in \citep{song2020score})
    \begin{align}
        \frac{\partial p_t}{\partial t} = -\text{div} \left( \mathbf{W}_t p_t \right), \quad\text{in } (0,T)\times\mathbb{R}^D
    \end{align}
    where $\mathbf{W}_t:=-t\nabla\log p_t$. 

    Now consider the continuity equation for $\mu_t$ defined by $\mathbf{W}_t$ 
    \begin{align}\label{eq:conti_eq}
        \frac{\partial \mu_t}{\partial t} = -\text{div} \left( \mathbf{W}_t \mu_t \right) \quad\text{in } (0,T)\times\mathbb{R}^D.
    \end{align}
    Since the score $\nabla\log p_t$ is of linear growth in $\mathbf{x}$ and upper bounded by a summable function in $t$, the vector field $\mathbf{W}_t:=-t\nabla \log p_t\colon[0,T]\times\mathbb{R}^D\rightarrow\mathbb{R}^D$ satisfies that 
        \begin{align*}
            \int_{0}^{T}\left( \sup_{\mathbf{x}\in K}\norm{\mathbf{W}_t(\mathbf{x})}_2+ \text{Lip}(\mathbf{W}_t,K)~\diff t \right) < \infty,
        \end{align*}
    for any compact set $K\subset\mathbb{R}^D$. Here $\text{Lip}(\mathbf{W}_t,K)$ denotes the Lipschitz constant of $\mathbf{W}_t$ on $K$.

    Thus, Proposition 8.1.8 of \citep{ambrosio2005gradient} implies that for $p_T$-a.e. $\mathbf{x}$, the following reverse time ODE (which is the Eq.~\eqref{eq:sde_forward}) admits a unique solution on $[0,T]$
    \begin{align}
        \begin{cases}\label{eq:ode_charac_conti}
        \frac{\diff }{\diff t} X_t(\mathbf{x})=  \mathbf{W}_t\left( X_t(\hat{\mathbf{x}}) \right)
        \\ X_T(\hat{\mathbf{x}})=\mathbf{x}.
        \end{cases}
    \end{align}
    Moreover, $\mu_t = X_t \sharp p_T$, for $t\in[0,T]$. By applying the uniqueness for the continuity equation (Proposition 8.1.7 of \citep{ambrosio2005gradient}) and the uniqueness of Eq.~\eqref{eq:ode_charac_conti}, we have $p_t = \mu_t = X_t \sharp p_T=\mathcal{T}_{T\rightarrow t} \sharp p_T$ for $t\in[0,T]$. Again, since the uniqueness theorem with the given $p_T$, we obtain $p_s =\mathcal{T}_{t\rightarrow s} \sharp p_t$ for any $t\in[0,T]$ and $s\in[0,t]$.
    
\end{myproof}










\end{document}
