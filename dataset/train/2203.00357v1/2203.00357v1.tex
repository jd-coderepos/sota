




In this paper, we study the problem of logical reasoning on the task of multiple choice question answering (MCQA). 
Specifically, given a passage , a question  and a set of  options , the goal is to select the correct option , where .
Notably, to tackle this task, we devise a novel pre-training method equipped with contrastive learning, where the abundant knowledge contained in the large-scale Wikipedia documents is explored.
We then transfer the learned knowledge to the downstream logical reasoning task.


\subsection{From Logical Reasoning to Meta-Path}



In a sense, in MCQA for logical reasoning, both the given context (i.e., passage and question) and options express certain relations between different logical variables (Figure~\ref{fig:example}). 
Go a step further, following Equation~\ref{eqn:logic-rule}, the relation triplet contained in the correct option should be deduced from the given context through a reasoning path,
while that in the wrong options should not. 
In other words, the context is logically consistent with the correct option only.








In light of this, the training instances for our contrastive learning based pre-training should be in the form of a context-option pair, where the context consists of multiple sentences and expresses the relations between the included constituents, while the option should illustrate the potential relations between parts of the constituents.  
Nevertheless, it is non-trivial to derive such instance pairs from large-scale unlabeled corpus like Wikipedia due to the redundant constituents, e.g., nouns and predicates.
In order to address it, we propose to take the entities contained in unlabeled text as logical variables, and Equation~\ref{eqn:logic-rule} can be transformed as:

As can be seen, the right part above is indeed a meta-path connecting \entpair{i}{j} as formulated in Equation~\ref{eqn:path}, indicating an indirect relation between \entpair{i}{j} through intermediary entities and relations.
In order to aid the logical consistency conditioned on entities to be established, we posit an  assumption that
\textit{under the same context (in the same passage), the definite relation between a  pair of entities can be inferred from the contextual indirect one, or at least not logically contradict to it}.
Taking the passage in Figure~\ref{fig:model-framework} as an example, 
it can be concluded from the sentences  and  that, the director \textit{McKean} has cooperated with \textit{Stephanie Leonidas}. 
Therefore, the logic is consistent between  and .
This can be viewed as a weaker constraint than the original one in Equation~\ref{eqn:logic-rule} for logical consistency, yet it can be further enhanced by constructing negative candidates violating logics.



Motivated by this, given an arbitrary document , where  is the -th sentence,
we can first build an entity-level graph, denoted as , where  is the set of entities contained in  and  denotes the set of relations between entities. 
Notably, to comprehensively capture the relations among entities, we take into account both the external relation from the knowledge graph and the intra-sentence relation. As illustrated in Figure~\ref{fig:model-framework} (a), there will be an intra-sentence relation between two entities if they are mentioned in a common sentence.
Thereafter, we can derive the pre-training instance pairs according to the meta-paths extracted from the graph, which will be detailed in the following subsections.




















\subsection{Meta-Path Guided Positive Instance Construction}
\label{sec:method:meta-path}



























As defined in Equation~\ref{eqn:ent-logic-rule}, in the positive instances, the answer should contain a relation triplet that is logically consistent with the given context. 
Since we take the intra-sentence relationship into consideration, given a pair of entities contained in the document,
we first collect the sentences mentioning both of them as the set of answer candidates.
Accordingly, we then try to find a meta-path connecting the entity pair and hence derive the corresponding logically consistent context. 


In particular, as shown in Figure~\ref{fig:model-framework} (b), given an entity pair \entpair{i}{j}, we denote the collected answer candidates as ,
and then we use Depth-First Search~\citep{dfs-Tarjan72} to find a meta-path linking them on , following Equation~\ref{eqn:path}.
Thereafter, the context sentences  corresponding to the answer candidates in  are derived by retrieving those sentences undertaking the intra-sentence relations during the search algorithm.
Finally, for each answer candidate , the pair  is treated as a positive context-answer pair to facilitate our contrastive learning.
The details of positive instance generation algorithm are described in Appendix~\ref{sec:appendix:dfs-alg}.


\subsection{Negative Instance Generation}
\label{sec:method:data-construction}



In order to obtain the negative instances (i.e., negative context-option pairs) where the option is not logically consistent with the context,
the most straightforward way is to randomly sample the sentences from different documents.
However, this approach could lead to trivial solutions by simply checking whether the entities involved in each option are the same as those in the given context.
In the light of this, we resort to directly breaking the logical consistency of the positive instance pair by modifying the relation rather than the entities in the context or the option, to derive the negative instance pair. 


In particular, given a positive instance pair , we devise two negative instance generation methods: the context-oriented and the option-oriented method, focusing on generating negative pairs by modifying the relations involved in the context  and answer  of the positive pair, respectively.
Considering that the relation is difficult to be extracted, especially the intra-sentence relation,
we propose to implement this reversely via the entity replacement.
In particular, for the option-oriented method, suppose that \entpair{i}{j} is the \ntgtentp~ for retrieving the answer , we first randomly sample a sentence  that contains at least one different entity pair \entpair{a}{b} from \entpair{i}{j} as the relation provider. 
We then obtain the negative option by replacing the entities  and  in  with  and , respectively.
The operation is equivalent to replacing the relation contained in  with that in . Formally, we denote the operation as 


Pertaining to the context-oriented negative instance generation method, we first 
randomly sample a sentence , and then conduct the modification process as follows,

where the entity pair to be replaced in  should be contained in the meta-path corresponding to the \ntgtentp~\entpair{i}{j}.
Accordingly, the negative context can be written as .
Figure~\ref{fig:model-framework}~(c) illustrates the above operations on both the answer and context sentence.


















\subsection{Counterfactual Data Augmentation}
\label{sec:method:counterfactual}

According to~\citet{position-bias-2020-ko,sigir-bias,shortcut-mrc-2021-lai,tip-bias}, the neural models are adept at finding a trivial solution through the illusory statistical information in datasets to make correct predictions,
which often leads to inferior generalization.
In fact, this issue can also occur in our scenario.
In particular, since the correct answer is from a natural sentence and describes a real world fact, while the negative option is synthesized by entity replacement, which may conflict with the commonsense knowledge.
As a result, the pre-trained language model tends to identify the correct option directly by judging its factuality rather than the logical consistency with the given context.
For example, as shown in Figure~\ref{fig:model-framework} (d) (left), 
the language model deems  as correct, simply due to that the other synthetic option  conflicts with the world knowledge.


To overcome this problem, we develop a simple yet effective counterfactual data augmentation method to further improve the capability of logical reasoning~\citep{counterfactual-ner}. 
Specifically, given the entities  that are involved in the meta-path, we randomly select some entities from  and replace their occurrences in the context and the answer of the positive instance pair  with the entities extracted from other documents. In this manner, the positive instance also contradicts to the world knowledge.
Notably, considering that the positive and negative instance pairs should keep the same set of entities, we also conduct the same replacement for  or , if they mention the selected entities.
As illustrated in Figure~\ref{fig:model-framework} (d) (right), a counterfactual instance can be generated by replacing \textit{Mirror Mask} and \textit{Stephanie Leonidas} in  and  with \textbf{[ENT A]} and \textbf{[ENT B]}, where \textbf{[ENT A]} and \textbf{[ENT B]} are arbitrary entities.
Ultimately, the key to infer the correct answer lies in the accurate inference of the logical relation between entities \textbf{[ENT A]} and \textbf{[ENT B]} implied in each context-option pair.
We provide more cases of the constructed data and their corresponding counterfactual samples in Appendix~\ref{sec:appendix:data-case}.



\subsection{Contrastive Learning based Pre-training}
\label{sec:method:cl}

As discussed in previous subsection, there are 
two contrastive learning schemes: option-oriented CL and context-oriented CL. 
Let  be the set of all constructed negative options with respect to the correct option . The option-oriented CL can be formulated as:

In addition, given  as the set of all generated negative contexts corresponding to , the objective of context-oriented CL can be written as:

To avoid the catastrophic forgetting problem, we also add the MLM objective during pre-training and the final loss is:


\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{img/training_frame_v1.1.pdf}
    \caption{The overall training scheme of our method.}
    \label{fig:training_frame}
    \vspace{-0.5cm}
\end{figure}


\begin{table*}[t]
\centering
\setlength{\tabcolsep}{7.0mm}{
\scalebox{0.75}{
\begin{tabular}{lcccccc}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{Model / Dataset}} & \multicolumn{4}{c}{\textbf{ReClor}}                                                                                    & \multicolumn{2}{c}{\textbf{LogiQA}}                        \\
\multicolumn{1}{c}{}                                 & \multicolumn{1}{c}{Dev} & \multicolumn{1}{c}{Test} & \multicolumn{1}{c}{Test-E} & \multicolumn{1}{c}{Test-H} & \multicolumn{1}{c}{Dev} & \multicolumn{1}{c}{Test} \\ \hline
RoBERTa                                         & 62.6                     & 55.6                     & 75.5                       & 40.0                        & 35.0                    & 35.3                        \\
DAGN                                                  & 65.2                     & 58.2                     & 76.1                       & 44.1                        & 35.5                    & 38.7                    \\ 
DAGN (Aug)                                            & 65.8                     & 58.3                     & 75.9                       & 44.5                        & 36.9                    & 39.3                     \\ 
LReasoner (RoBERTa)                     & 64.7                     & 58.3                     & 77.6                       & 43.1                        & ---                     & ---                      \\
Focal Reasoner                                        & 66.8                     & 58.9                     & 77.1                       & 44.6                        & \textbf{41.0}           & 40.3        \\ 
\hline
\modelname                                        & 66.8                     & 59.6                     & 78.1                       & 45.2                        & 40.0                  & 38.9                 \\
\modelname~+ LReasoner                            & 67.4                     & 60.4                     & 78.5                       & 46.2                        & ---                   & ---                  \\
\modelname~+ Prompt                             & \textbf{69.4}            & \textbf{61.6}            & 79.3              & \textbf{47.8}               & 39.9                  & \textbf{40.7}         \\
\modelname~+ Prompt + LReasoner                       & 67.3                     & 61.4                      & \textbf{79.8}      & 46.9                        & ---                      & --- \\
\hline
ALBERT                                        & 69.1 & 66.5 & 76.7 & 58.4 & 38.9 & 37.6 \\
\modelname~(ALBERT)                           & 74.2 & 70.1 & 81.6 & 61.0 & 43.7 & \textbf{42.5} \\
\modelname~(ALBERT) + Prompt                  & \textbf{74.7} & \textbf{70.5} & \textbf{82.5} & \textbf{61.1} & \textbf{46.1} & 41.7 \\
\hline
\textit{max} \\ \hline
LReasoner (RoBERTa)                         & 66.2                     & 62.4                     & 81.4                       & 47.5                        & 38.1               & 40.6                      \\ 
\modelname                                       & 67.8 & 60.7 & 79.6 & 45.9 & \textbf{42.4} & 41.5  \\
\modelname~+ Prompt                             & \textbf{70.2}            & \textbf{62.6}            & 80.5                       & \textbf{48.5}               & 39.5      & \textbf{42.4}            \\
\hline
LReasoner (ALBERT)                            & 73.2 & 70.7 & 81.1 & 62.5 & 41.6 & 41.2 \\
\modelname~(ALBERT)                           & 73.2 & 71.1 & 83.6 & 61.3 & 43.9 & \textbf{45.3} \\
\modelname~(ALBERT) + Prompt                  & \textbf{75.0} & \textbf{72.2} & \textbf{82.5} & \textbf{64.1} & \textbf{45.8} & 43.8 \\
\bottomrule
\end{tabular}
}}
\caption{The overall results on ReClor and LogiQA. We adopt the \textbf{accuracy} as the evaluation metric and all the baselines are based on RoBERTa except specific statement. For each model we repeated training for 5 times using different random seeds and reported the average results. 
: The results are reproduced by ourselves.
\textit{max}: The results of the model achieving the best accuracy on the test set.}
\label{tab:overall-results}
\vspace{-0.5cm}
\end{table*}


\vspace{-0.2cm}
\subsection{Fine-tuning}
\label{sec:method:fine-tuning}

During the fine-tuning stage, to approach the task of MCQA, we adopt the following loss function:

where  is the ground-truth option for the question , given the passage .






Figure~\ref{fig:training_frame} shows the overall training scheme of our method.  is the model to be optimized, , ,  and  are parameters of different modules. 
During pre-training, we use a 2-layer MLP as the output layer. The parameters of the output layer are denoted as , and  represents the pre-trained Transformer parameters.
As for the fine-tuning stage, we employ two schemes. 
For simple fine-tuning, we follow~\citet{bert} to add another 2-layer MLP with randomly initialized parameters  on the top of the pre-trained Transformer.
In addition, to fully take advantage the knowledge acquired during pre-training stage, we choose to directly fine-tune the pre-trained output layer with optimizing both  and .
In order to address the discrepancy that the question is absent during pre-training, the prompt-tuning technique~\citep{prompt-tuning} is employed.
Specifically, some learnable embeddings with randomly initialized parameters  are appended to the input to transform the question in downstream tasks into declarative constraint.