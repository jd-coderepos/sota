
\section{Experiments}
In this section, we provide evaluation of denoising and super-resolution performance of our models against a few existing state-of-the-art methods. Denoising experiments are performed on two datasets: 14 common benchmark images~\cite{DBLP:conf/iccv/XuZZZF15,DBLP:conf/iccv/ChenZY15,DBLP:conf/cvpr/LiuXZG15,DBLP:conf/cvpr/GuZZF14} and the BSD200 dataset. We test additive Gaussian noises with zero mean and standard deviation $\sigma=$ 10, 30, 50 and 70 respectively. BM3D~\cite{DBLP:journals/tip/DabovFKE07}, NCSR~\cite{DBLP:journals/tip/DongZSL13}, EPLL~\cite{DBLP:conf/iccv/ZoranW11}, PCLR~\cite{DBLP:conf/iccv/ChenZY15}, PDPD~\cite{DBLP:conf/iccv/XuZZZF15} and WMMN~\cite{DBLP:conf/cvpr/GuZZF14} are compared with our method. For super-resolution, we compare our network with SRCNN~\cite{DBLP:journals/pami/DongLHT16}, NBSRF~\cite{DBLP:conf/iccv/SalvadorP15}, CSCN~\cite{DBLP:conf/iccv/WangLYHH15}, CSC~\cite{DBLP:conf/iccv/GuZXMFZ15}, TSE~\cite{DBLP:conf/cvpr/HuangSA15} and ARFL+~\cite{DBLP:conf/cvpr/SchulterLB15} on three dataset: Set5, Set14 and BSD100. The scaling parameter are tested with 2, 3 and 4.

Peak Signal-to-Noise Ratio (PSNR) and Structural SIMilarity (SSIM) index are calculated for evaluation. For our method, which is denoted as RED-Net, we implement three versions: RED10 contains 5 convolutional and deconvolutional layers without shortcuts, RED20 contains 10 convolutional and deconvolutional layers with shortcuts, and RED30 contains 15 convolutional and deconvolutional layers with shortcuts.

\subsection{Image Denoising}
{\bf Evaluation on the 14 images} Table \ref{table2} presents the PSNR and SSIM results of $\sigma$ 10, 30, 50, and 70. We can make some observations from the results. First of all, the 10 layer convolutional and deconvolutional network has already achieved better results than the state-of-the-art methods, which demonstrates that combining convolution and deconvolution for denoising works well, even without any skip connections. Moreover, when the network goes deeper, the skip connections proposed in this paper help to achieve even better denoising performance, which exceeds the existing best method WNNM~\cite{DBLP:conf/cvpr/GuZZF14} by 0.32dB, 0.43dB, 0.49dB and 0.51dB on noise levels of $\sigma$ being 10, 30, 50 and 70 respectively. While WNNM is only slightly better than the second best existing method PCLR~\cite{DBLP:conf/iccv/ChenZY15} by 0.01dB, 0.06dB, 0.03dB and 0.01dB respectively, which shows the large improvement of our model. Last, we can observe that the more complex the noise is, the more improvement our model achieves than other methods. Similar observations can be made on the evaluation of SSIM.

\begin{table*}
\small
\centering
\caption{Average PSNR and SSIM results of $\sigma$ 10, 30, 50, 70 for the 14 images.}
\begin{tabular}{c|c c c c c c c c c} \hline
              &\multicolumn{9}{c}{PSNR}            \\ \hline
              &BM3D   &EPLL   &NCSR   &PCLR   &PGPD   &WNNM   &RED10  &RED20  &RED30          \\ \hline
  $\sigma=10$ &34.18  &33.98  &34.27  &34.48  &34.22  &34.49  &34.62  &34.74  &\textbf{34.81} \\ \hline
  $\sigma=30$ &28.49  &28.35  &28.44  &28.68  &28.55  &28.74  &28.95  &29.10  &\textbf{29.17} \\ \hline
  $\sigma=50$ &26.08  &25.97  &25.93  &26.29  &26.19  &26.32  &26.51  &26.72  &\textbf{26.81} \\ \hline
  $\sigma=70$ &24.65  &24.47  &24.36  &24.79  &24.71  &24.80  &24.97  &25.23  &\textbf{25.31} \\ \hline
              &\multicolumn{9}{c }{SSIM}            \\ \hline
  $\sigma=10$ &0.9339 &0.9332 &0.9342 &0.9366 &0.9309 &0.9363 &0.9374 &0.9392 &\textbf{0.9402} \\ \hline
  $\sigma=30$ &0.8204 &0.8200 &0.8203 &0.8263 &0.8199 &0.8273 &0.8327 &0.8396 &\textbf{0.8423} \\ \hline
  $\sigma=50$ &0.7427 &0.7354 &0.7415 &0.7538 &0.7442 &0.7517 &0.7571 &0.7689 &\textbf{0.7733} \\ \hline
  $\sigma=70$ &0.6882 &0.6712 &0.6871 &0.6997 &0.6913 &0.6975 &0.7012 &0.7177 &\textbf{0.7206} \\ \hline
\end{tabular}
\label{table2}
\end{table*}


{\bf Evaluation on BSD200}
For testing efficiency, we convert the images to gray-scale and resize them to smaller ones on BSD-200. Then all the methods are run on these images to get average PSNR and SSIM results of $\sigma$ 10, 30, 50, and 70, as shown in Table \ref{table3}. For existing methods, their denoising performance does not differ much, while our model achieves 0.38dB, 0.47dB, 0.49dB and 0.42dB higher of PSNR over WNNM.

\begin{table*}
\small
\centering
\caption{Average PSNR and SSIM results of $\sigma$ 10, 30, 50, 70 on 200 images from BSD.}
\begin{tabular}{c|c c c c c c c c c } \hline
              &\multicolumn{9}{c}{PSNR}            \\ \hline
              &BM3D   &EPLL   &NCSR   &PCLR   &PGPD   &WNNM   &RED10  &RED20  &RED30 \\ \hline
  $\sigma=10$ &33.01  &33.01  &33.09  &33.30  &33.02  &33.25  &33.49  &33.59  &\textbf{33.63} \\ \hline
  $\sigma=30$ &27.31  &27.38  &27.23  &27.54  &27.33  &27.48  &27.79  &27.90  &\textbf{27.95} \\ \hline
  $\sigma=50$ &25.06  &25.17  &24.95  &25.30  &25.18  &25.26  &25.54  &25.67  &\textbf{25.75} \\ \hline
  $\sigma=70$ &23.82  &23.81  &23.58  &23.94  &23.89  &23.95  &24.13  &24.33  &\textbf{24.37} \\ \hline
              &\multicolumn{9}{c }{SSIM}            \\ \hline
  $\sigma=10$ &0.9218 &0.9255 &0.9226 &0.9261 &0.9176 &0.9244 &0.9290 &0.9310 &\textbf{0.9319} \\ \hline
  $\sigma=30$ &0.7755 &0.7825 &0.7738 &0.7827 &0.7717 &0.7807 &0.7918 &0.7993 &\textbf{0.8019} \\ \hline
  $\sigma=50$ &0.6831 &0.6870 &0.6777 &0.6947 &0.6841 &0.6928 &0.7032 &0.7117 &\textbf{0.7167} \\ \hline
  $\sigma=70$ &0.6240 &0.6168 &0.6166 &0.6336 &0.6245 &0.6346 &0.6367 &0.6521 &\textbf{0.6551} \\ \hline
\end{tabular}
\label{table3}
\end{table*}

\subsection{Image super-resolution}
The evaluation on Set5 is shown in Table \ref{table4}.
Our 10-layer network outperforms the compared methods already, and we achieve better performance with deeper networks.
The 30-layer network exceeds the second best method CSCN for 0.52dB, 0.56dB and 0.47dB on scale 2, 3 and 4 respectively.
The evaluation on Set14 is shown in Table \ref{table5}. The improvement on Set14 in not as significant as that on Set5,
but we can still observe that the 30 layer network achieves higher PSNR than the second best CSCN for 0.23dB, 0.06dB and 0.1dB. The results on BSD100, as shown in Table \ref{table6}, is similar than that on Set5. The second best method is still CSCN, the performance of which is not as good as our 10 layer network. Our deeper network obtains much more performance gain than the others.

\begin{table*}
\small
\centering
\caption{Average PSNR and SSIM results on Set5.}
\begin{tabular}{c|c c c c c c c c c}  \hline
              &\multicolumn{9}{c}{PSNR}            \\ \hline
           &SRCNN  &NBSRF  &CSCN   &CSC    &TSE    &ARFL+   &RED10    &RED20   &RED30           \\ \hline
  $s = 2$  &36.66  &36.76  &37.14  &36.62  &36.50  &36.89   &37.43    &37.62   &\textbf{37.66}  \\ \hline
  $s = 3$  &32.75  &32.75  &33.26  &32.66  &32.62  &32.72   &33.43    &33.80   &\textbf{33.82}  \\ \hline
  $s = 4$  &30.49  &30.44  &31.04  &30.36  &30.33  &30.35   &31.12    &31.40   &\textbf{31.51}  \\ \hline
              &\multicolumn{9}{c }{SSIM}            \\ \hline
  $s = 2$  &0.9542 &0.9552 &0.9567 &0.9549 &0.9537 &0.9559  &0.9590   &0.9597  &\textbf{0.9599} \\ \hline
  $s = 3$  &0.9090 &0.9104 &0.9167 &0.9098 &0.9094 &0.9094  &0.9197   &0.9229  &\textbf{0.9230} \\ \hline
  $s = 4$  &0.8628 &0.8632 &0.8775 &0.8607 &0.8623 &0.8583  &0.8794   &0.8847  &\textbf{0.8869} \\ \hline
\end{tabular}
\label{table4}
\end{table*}

\begin{table*}
\small
\centering
\caption{Average PSNR and SSIM results on Set14.}
\begin{tabular}{c|c c c c c c c c c}  \hline
              &\multicolumn{9}{c}{PSNR}            \\ \hline
           &SRCNN  &NBSRF  &CSCN   &CSC    &TSE    &ARFL+   &RED10    &RED20   &RED30           \\ \hline
  $s = 2$  &32.45  &32.45  &32.71  &32.31  &32.23  &32.52   &32.77    &32.87   &\textbf{32.94}  \\ \hline
  $s = 3$  &29.30  &29.25  &29.55  &29.15  &29.16  &29.23   &29.42    &29.61   &\textbf{29.61}  \\ \hline
  $s = 4$  &27.50  &27.42  &27.76  &27.30  &27.40  &27.41   &27.58    &27.80   &\textbf{27.86}  \\ \hline
              &\multicolumn{9}{c }{SSIM}            \\ \hline
  $s = 2$  &0.9067 &0.9071 &0.9095 &0.9070 &0.9036 &0.9074 &0.9125    &0.9138  &\textbf{0.9144} \\ \hline
  $s = 3$  &0.8215 &0.8212 &0.8271 &0.8208 &0.8197 &0.8201 &0.8318    &0.8343  &\textbf{0.8341} \\ \hline
  $s = 4$  &0.7513 &0.7511 &0.7620 &0.7499 &0.7518 &0.7483 &0.7654    &0.7697  &\textbf{0.7718} \\ \hline
\end{tabular}
\label{table5}
\end{table*}

\begin{table*}
\small
\centering
\caption{Average PSNR and SSIM results on BSD100 for super-resolution.}
\begin{tabular}{c|c c c c c c c c c}  \hline
              &\multicolumn{9}{c}{PSNR}            \\ \hline
           &SRCNN  &NBSRF  &CSCN   &CSC    &TSE    &ARFL+  &RED10  &RED20   &RED30           \\ \hline
  $s = 2$  &31.36  &31.30  &31.54  &31.27  &31.18  &31.35  &31.85  &31.95   &\textbf{31.99}  \\ \hline
  $s = 3$  &28.41  &28.36  &28.58  &28.31  &28.30  &28.36  &28.79  &28.90   &\textbf{28.93}  \\ \hline
  $s = 4$  &26.90  &26.88  &27.11  &26.83  &26.85  &26.86  &27.25  &27.35   &\textbf{27.40}  \\ \hline
              &\multicolumn{9}{c }{SSIM}            \\ \hline
  $s = 2$  &0.8879 &0.8876 &0.8908 &0.8876 &0.8855 &0.8885 &0.8953 &0.8969  &\textbf{0.8974} \\ \hline
  $s = 3$  &0.7863 &0.7856 &0.7910 &0.7853 &0.7843 &0.7851 &0.7975 &0.7993  &\textbf{0.7994} \\ \hline
  $s = 4$  &0.7103 &0.7110 &0.7191 &0.7101 &0.7108 &0.7091 &0.7238 &0.7268  &\textbf{0.7290} \\ \hline
\end{tabular}
\label{table6}
\end{table*}

\subsection{Evaluation with a single model}
To construct the training set, we extract image patches with different noise levels and scaling parameters
for denoising and super-resolution. Then a 30-layer network is trained for the two tasks respectively.
The evaluation results are shown in Table \ref{table7} and Table \ref{table8}. Although training with different levels
of corruption, we can observe that the performance of our network only slightly degrades comparing
to the case
in which using separate models for denoising and super-resolution. This may be due the fact that
 the network has to fit much more complex mappings. Except that CSCN works slightly better on super-resolution
 with scales 3 and 4, our network still beats the existing methods,
 showing that our network works much better in image denoising and super-resolution
 even  using only one  single model to deal with complex corruption.

\begin{table*}
\small
\centering
\caption{Average PSNR and SSIM results for image denoising using a single 30-layer network.}
\begin{tabular}{c|c c c c|c c c c} \hline
       &\multicolumn{4}{c|}{14 images}                      &\multicolumn{4}{c}{BSD200}                        \\ \hline
       &$\sigma=10$ &$\sigma=30$ &$\sigma=50$ &$\sigma=70$ &$\sigma=10$ &$\sigma=30$ &$\sigma=50$ &$\sigma=70$ \\ \hline
  PSNR &34.49       &29.09       &26.75       &25.20       &33.38       &27.88       &25.69       &24.36       \\ \hline
  SSIM &0.9368      &0.8414      &0.7716      &0.7157      &0.9280      &0.7980      &0.7119      &0.6544      \\ \hline
\end{tabular}
\label{table7}
\end{table*}

\begin{table*}
\small
\centering
\caption{Average PSNR and SSIM results for image super-resolution using a single 30 layer network.}
\begin{tabular}{c|c c c|c c c|c c c} \hline
       &\multicolumn{3}{c|}{Set5}    &\multicolumn{3}{c|}{Set14}   &\multicolumn{3}{c}{BSD100}   \\ \hline
       &$s = 2$  &$s = 3$  &$s = 4$  &$s = 2$  &$s = 3$  &$s = 4$  &$s = 2$  &$s = 3$  &$s = 4$  \\ \hline
  PSNR &37.56    &33.70    &31.33    &32.81    &29.50    &27.72    &31.96    &28.88    &27.35    \\ \hline
  SSIM &0.9595   &0.9222   &0.8847   &0.9135   &0.8334   &0.7698   &0.8972   &0.7993   &0.7276   \\ \hline
\end{tabular}
\label{table8}
\end{table*}





