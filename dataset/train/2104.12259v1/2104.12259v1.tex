\documentclass[sigconf]{acmart}
\AtBeginDocument{\providecommand\BibTeX{{\normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

\copyrightyear{2021}
\acmYear{2021}
\setcopyright{acmcopyright}
\acmConference[SIGIR '21] {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval}{July 11--15, 2021}{Virtual Event, Canada.}
\acmBooktitle{Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '21), July 11--15, 2021, Virtual Event, Canada}
\acmPrice{15.00}
\acmISBN{978-1-4503-8037-9/21/07}
\acmDOI{10.1145/XXXXXX.XXXXXX}


\settopmatter{printacmref=true}







\PassOptionsToPackage{usenames,dvipsnames}{xcolor}

\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{caption}
\usepackage{textcomp}

\usepackage{url}
\usepackage{booktabs}
\usepackage{epstopdf}
\usepackage{multirow}
\usepackage{array}
\usepackage{enumitem}
\usepackage{wrapfig}
\usepackage[many]{tcolorbox}
\usepackage{mathtools}
\usepackage{dsfont}
\usepackage{esvect}
\usepackage{hyperref}
\usepackage{multicol}
\usepackage{xpatch}
\usepackage[noend]{algpseudocode}
\usepackage{comment}
\usepackage{todonotes}
\DeclareMathOperator*{\argmin}{\arg\!\min}
\DeclareMathOperator*{\argmax}{\arg\!\max}
\newcommand{\INDSTATE}[1][1]{\STATE\hspace{#1\algorithmicindent}}
\newcommand{\kai}[1]{\textcolor{blue}{{#1}}}
\newcommand{\sun}[1]{\textcolor{red}{{#1}}}

\makeatletter
\xpatchcmd{\algorithmic}{\itemsep\z@}{\itemsep=0.1ex plus0.5pt}{}{}
\makeatother

\newcommand{\footremember}[2]{\footnote{#2}
    \newcounter{#1}
    \setcounter{#1}{\value{footnote}}}
\newcommand{\footrecall}[1]{\footnotemark[\value{#1}]} 

\usepackage{xspace}
\newcommand\UPFD{$\mathsf{UPFD}$\xspace}




\begin{document}
\title{User Preference-aware Fake News Detection}



\author{Yingtong Dou$^{1}$, Kai Shu$^{2}$, Congying Xia$^{1}$, Philip S. Yu$^{1}$, Lichao Sun$^{3}$}
\affiliation{
\institution{
$^1$Department of Computer Science, University of Illinois at Chicago, Chicago, IL, USA\\
$^2$Department of Computer Science, Illinois Institute of Technology, Chicago, IL, USA\\
$^3$Department of Computer Science and Engineering, Lehigh University, Bethlehem, PA, USA\\
}
\country{}
}
\email{{ydou5, cxia8, psyu}@uic.edu, kshu@iit.edu, james.lichao.sun@gmail.com}









\begin{abstract}


Disinformation and fake news have posed detrimental effects on individuals and society in recent years, attracting broad attention to fake news detection. 
The majority of existing fake news detection algorithms focus on mining news content and/or the surrounding exogenous context for discovering deceptive signals;
while the endogenous preference of a user when he/she decides to spread a piece of fake news or not is ignored.
The \textit{confirmation bias} theory has indicated that a user is more likely to spread a piece of fake news when it confirms his/her existing beliefs/preferences.
Users' historical, social engagements such as posts provide rich information about users' preferences toward news and have great potentials to advance fake news detection.
However, the work on exploring user preference for fake news detection is somewhat limited.
Therefore, in this paper, we study the novel problem of exploiting user preference for fake news detection.
We propose a new framework, \UPFD, which simultaneously captures various signals from user preferences by joint content and graph modeling.
Experimental results on real-world datasets demonstrate the effectiveness of the proposed framework.
We release our code and data as a benchmark for GNN-based fake news detection: \url{https://github.com/safe-graph/GNN-FakeNews}.
\end{abstract}


\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010147.10010257</concept_id>
       <concept_desc>Computing methodologies~Machine learning</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
   <concept>
       <concept_id>10002951.10003260.10003282.10003292</concept_id>
       <concept_desc>Information systems~Social networks</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[300]{Computing methodologies~Machine learning}
\ccsdesc[500]{Information systems~Social networks}

\keywords{Data Mining; Social Media Analysis; Fake News Detection}





\maketitle


\section{Introduction}
\label{sec01:intro}



In recent years, social media has enabled the wide dissemination of disinformation and fake news-- false or misleading information disguised in news articles to mislead consumers~
\cite{zhou2020survey, shu2017fake}.
Disinformation has resulted in deleterious effects and raised serious concerns, demanding novel approaches for fake news detection.



Among various fake news detection techniques, fact-checking is the most straightforward approach; however, it is usually labor-intensive to acquire evidence from domain experts~\cite{hassan2017claimbuster}.
In addition, computational approaches using feature engineering or deep learning have shown many promising results~\cite{wang2018eann, karimi2018multi, ruchansky2017csi, chandra2020graph}.
For example, SAFE~\cite{zhou2020mathsf} and FakeBERT~\cite{kaliyarfakebert} used the TextCNN~\cite{zhang2015sensitivity} and BERT~\cite{devlin2018bert,sun2020mixup,sun2020adv} to encode the news textual information, respectively; GCNFN~\cite{monti2019fake} and GNN-CL~\cite{han2020graph} leveraged the GCN~\cite{kipf2016semi} to encode the news propagation patterns on social media (e.g., news sharing cascading among social media accounts).
However, these methods focus on modeling news content and its user exogenous context and ignore the user endogenous preferences. 





Sociological and psychological studies on journalism have theorized the correlation between user preferences and their online news consumption behaviors~\cite{shu2019studying}.
For example, \textit{Na\'ive Realism}~\cite{ross1995naive} indicates that consumers tend to believe that their perceptions of reality are the only accurate views, while others who disagree are regarded as uninformed, irrational, or biased;
and \textit{Confirmation Bias} theory~\cite{nickerson1998confirmation} reveals that consumers prefer to receive information that confirms their existing views.
For instance, a user believes the election fraud would probably share similar news with a supportive stance, and the news asserting election is stolen would attract users with similar beliefs~\cite{abilov2021voterfraud2020}.
To model user endogenous preferences, existing works have attempted to utilize historical posts as a proxy and have shown promising performance to detect sarcasm~\cite{khattri2015your}, hate speech~\cite{qian2018leveraging}, and fake news spreaders~\cite{rangel2020overview} on social media.


\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{overall.pdf}
    \caption{\small The proposed \UPFD framework for user preference-aware fake news detection. Given the news piece and its engaged users on social media, we extract the exogenous context as a news propagation graph and encode the endogenous information based on user historical posts and news texts. The endogenous and exogenous information are fused using a GNN encoder. The final news embedding, composed of user engagement embedding and news textual embedding, is fed into the neural classifier to predict the news' credibility.}
    \label{fig:overall}
\end{figure*}


In this paper, we consider the historical posts of social media users as their endogenous preference in news consumption.
We propose an end-to-end fake news detection framework named \underline{U}ser \underline{P}reference-aware \underline{F}ake \underline{D}etection (\UPFD) to model endogenous preference and exogenous context jointly (as shown in Figure~\ref{fig:overall}).
Specifically, \UPFD consists of the following major components: 
(1) To model the user endogenous preference, we encode news content and user historical posts using various text representation learning approaches.
(2) To obtain the user exogenous context, we build a tree-structured propagation graph for each news based on its sharing cascading on social media.
The news post is regarded as the root node, and other nodes represent the users who shared the same news posts.
(3) To integrate the endogenous and exogenous information, we take the vector representations of news and users as their node features and employ Graph Neural Networks (GNNs)~\cite{hamilton2017inductive, monti2019fake} to learn a joint user engagement embedding.
The user engagement embedding and news textual embedding are used to train a neural classifier to detect fake news.
Our major contributions can be summarized as follows:
\begin{itemize}[leftmargin=*]
    \item We study a novel problem of user preference-aware fake news detection on social media;
    \item We propose a principled way to exploit both endogenous preference and exogenous context jointly to detect fake news; and
    \item We conduct extensive experiments on real-world datasets to demonstrate the effectiveness of \UPFD for detecting fake news.
\end{itemize}














 \section{Our Approach}
\label{sec02:method}
In this section, we present the details of the proposed framework for fake news detection named \UPFD (\underline{U}ser \underline{P}reference-aware \underline{F}ake News \underline{D}etection).
As shown in Figure~\ref{fig:overall}, our framework has three major components.
First, given a news piece, we crawl the historical posts of the users engaged in the news to learn user endogenous preference.
We implicitly extract the preferences of engaged users by encoding historical posts using text representation learning techniques (e.g., word2vec~\cite{mikolov2013efficient}, BERT~\cite{devlin2018bert}).
The news textual data is encoded using the same approach.
Second, to leverage user exogenous context, we build the news propagation graph according to its engagement information on social media platforms (e.g., retweets on Twitter).
Third, we devise a hierarchical information fusion process to fuse the user endogenous preference and exogenous context.
Specifically, we obtain the user engagement embedding using GNN as the graph encoder, where the news and user embeddings encoded by the text encoder are used as their corresponding node features in the news propagation graph.
The final news embeddings are composed by the concatenation of user engagement embedding and news textual embedding.

Next, we will introduce how we encode endogenous preference, extract the exogenous context, and fuse both information.

\subsection{Endogenous Preference Encoding}
\label{sec:text_encoding}

It is non-trivial to explicitly model the endogenous preference of a user only using his/her social network information.
Similar to~\cite{ahmad2017personality, khattri2015your, qian2018leveraging} which model the users' personality, sentiment and stance using their historical posts, we leverage the historical posts of a user to encode his/her preference implicitly.
However, none of the previous fake news datasets contain such information.
In this paper, we select the FakeNewsNet dataset~\cite{shu2018fakenewsnet} which contains news content and its social engagement information on Twitter.
Then we use the Twitter Developer API~\cite{twitterapi} to crawl historical tweets of all accounts that retweeted the news in FakeNewsNet.

To obtain rich historical information for user preference modeling, we crawl the recent two hundred tweets for each account, so as to near 20 million tweets being crawled in total.
For inaccessible users whose accounts are suspended or deleted, we use randomly sampled tweets from accessible users engaging the same news as its corresponding historical posts.
Because deleting the inaccessible users will break the intact news propagation cascading and results in a less effective exogenous context encoder. 
We also remove the special characters, e.g., ``@'' characters and URLs, before applying text representation learning methods.


To encode the news textual information and user preferences, we employ two types of text representation learning approaches based on language pretraining.
Instead of training on the local corpus, the word embeddings pretrained on a large corpus are supposed to encode more semantic similarities between different words and sentences.
For pretrained word2vec vectors, we choose the 680k 300-dimensional vectors pretrained by spaCy~\cite{honnibal2017spacy}.  
We also employ pretrained BERT embeddings to encode the historical tweets and news content as a sequence~\cite{devlin2018bert} using bert-as-a-service~\cite{xiao2018bertservice}.


Next, we elaborate the details of applying the above text representation learning models. 
spaCy includes pretrained vectors for 680k words, and we average the vectors of existing words in combined recent 200 tweets to get user preference representation.
The news textual embedding is obtained similarly.
For the BERT model, we use the cased BERT-Large model to encode the news and user information.   
The news content is encoded using BERT with maximum input sequence length (i.e., 512 tokens).
Due to BERT's input sequence length limitation, we could not use BERT to encode 200 tweets as one sequence, so we resort to encode each tweet separately and average them afterward to obtain a user's preference representation.
Generally, the tweet text is way shorter than the news text, we empirically set the max input sequence length of BERT as 16 tokens to accelerate the tweets encoding time. 


\subsection{Exogenous Context Extraction}
\label{sec:build_graph}

Given a news piece on social media, the user exogenous context is composed of all users that engaged with the news. We utilize the retweet information of news pieces to build a news propagation graph.
As the toy example of the news propagation graph shown in Figure~\ref{fig:overall}, it is a tree-structured graph where the root node represents the news piece, and other nodes represent users who share the root news.
In this paper, we investigate the fake news propagation on Twitter as a proof-of-concept use case.
To build propagation networks in Twitter, we follow a similar strategy used in~\cite{shu2020hierarchical, monti2019fake, han2020graph}.
Specifically, we define a new piece as $v_{1}$, and $\{v_2, \dotsc, v_n\}$ as a list of users that retweeted $v_{1}$ ordered by time. We define two following rules to determine the news propagation path:

\begin{itemize}[leftmargin=*]
    \item For any account $v_i$, if $v_i$ retweets the same news later than at least one following accounts in $\{v_1, \dotsc, v_n\}$, we estimate the news spreads from the account with the latest timestamp to account $v_i$.
    Since the latest tweets are first presented in the timeline of the Twitter app, and thus have higher probabilities to be retweeted.
    
    \item If account $v_i$ does not follow any accounts in the retweet sequences including the source account, we conservatively estimate the news spreads from the accounts with the most number of followers.
    Because tweets from accounts with more followers have a higher chance to be viewed/retweeted by other users according to the Twitter content distributing rules. 
\end{itemize}
Based on the above rules, we can build the news propagation graphs on Twitter.
Note that this approach can be applied to other social media platforms like Facebook as well.


\subsection{Information Fusion}
\label{sec03:fusion}

Previous works~\cite{lu2020gcan, monti2019fake, han2020graph} have demonstrated that fusing the user features with a news propagation graph could boost the fake news detection performance.
Since the GNN can encode both node feature and graph structure in an end-to-end manner, it is a good fit for our task.
Specifically, we propose a hierarchical information fusion approach.
We first fuse the endogenous and exogenous information using the GNN.
With a GNN, the news textual embedding and user preference embedding can be taken as node features.
Given the news propagation graph, most GNNs aggregate the features of its adjacent nodes to learn the embedding of a node.
Like previous GNN-based graph classification models~\cite{xu2018powerful, ying2018hierarchical}, we apply a readout function over all node embeddings to obtain the embedding of a news propagation graph.
The readout function makes the mean pooling operation over all node embeddings to get the graph embedding (i.e., user engagement embedding).
Second, since the news content usually contains more explicit signals regarding the news' credibility~\cite{chandra2020graph}.
We fuse the news textual embedding and user engagement embedding by concatenation as the ultimate news embedding to enrich the news embedding information.

The fused news embedding is finally fed into a two-layer Multi-layer Perceptron (MLP) with two output neurons representing the predicted probabilities for fake and real news.
The model is trained using a binary cross-entropy loss function and is updated with SGD.

 \begin{table}[t]
\small
\centering
\caption{Dataset and graph statistics.}
\resizebox{0.98\linewidth}{!}{\begin{tabular}{l|ccccc}  
\hline
\textbf{Dataset}  &\begin{tabular}[c]{@{}c@{}}\textbf{\#Graphs} \\ (\textbf{\#Fake})\end{tabular} &\begin{tabular}[c]{@{}c@{}}\textbf{\#Total} \\ \textbf{Nodes}\end{tabular}  & \begin{tabular}[c]{@{}c@{}}\textbf{\#Total} \\ \textbf{Edges}\end{tabular}  & \begin{tabular}[c]{@{}c@{}}\textbf{\#Avg. Nodes} \\ \textbf{per Graph}\end{tabular}   \\ 

\hline
 Politifact (POL) & \begin{tabular}[c]{@{}c@{}} 314 \\ (157)\end{tabular}  & 41,054 & 40,740   & 131 \\
\hline
 Gossipcop (GOS)& \begin{tabular}[c]{@{}c@{}} 5464 \\ (2732)\end{tabular}  & 314,262 & 308,798   & 58 \\
\hline

\end{tabular}}
\label{tab:stat}
\end{table}

\section{Experiments}
\label{sec03:exp}

In the experiments, we want to address two following questions: 
\textbf{RQ1:} How are the performances of the proposed \UPFD framework compared to previous works?
\textbf{RQ2:} What are the contributions of endogenous/exogenous information and other variants of the proposed framework?

\subsection{Experimental Setup}

\subsubsection{Dataset.}
Previous works have proposed a couple of fake news datasets with news pieces from different websites and their fact-checking information~\cite{wang2017liar, potthast_martin_2018_1239675}. 
To investigate both the user preference and propagation pattern of fake news, we choose the FakeNewsNet dataset~\cite{shu2018fakenewsnet}.
It contains fake and real news information from two fact-checking websites and the related social engagement from Twitter.
The dataset statistics are shown in Table~\ref{tab:stat}.



\subsubsection{Baselines}

We compare the \UPFD with fake news detection models that utilize different information.
Many baseline methods leverage extra information like image information which is not included in the FakeNewsNet~\cite{shu2018fakenewsnet}.
To ensure a fair comparison, we implement the baselines only with the parts for encoding the news content, user comments, and news propagation graph. 
CSI~\cite{ruchansky2017csi} employs an LSTM to encode the news content information to detect fake news.
SAFE~\cite{zhou2020mathsf} uses the TextCNN~\cite{zhang2015sensitivity} to encode the news textual information.
GCNFN~\cite{monti2019fake} is the first fake news detection framework to encode the news propagation graph using GCN~\cite{kipf2016semi}.
It takes the profile information and comment textual embeddings as the user feature.
GNN-CL~\cite{han2020graph} encodes the news propagation graph using DiffPool~\cite{ying2018hierarchical}, a GNN designed for graph classification.
The node features are extracted from user profile attributes on Twitter.
The list of ten profile feature names can be found in~\cite{han2020graph, lu2020gcan}
We also add two baselines that apply MLP directly on news textual embeddings encoded by word2vec and BERT.



\subsubsection{Experimental Settings}
\label{sec:exp_settings}
We implement all models using PyTorch, and all GNN models are implemented with PyTorch-Geometric package~\cite{Fey2019fast}.
We use unified graph embedding size (128), batch size (128), optimizer (Adam), and L2 regularization weight (0.001), train-val-test split (20\%-10\%-70\%) for all models.
The experimental results are averaged over five different runnings. 
Other hyper-parameters for each model are reported with the code.



\subsection{RQ1: Performance Evaluation}
\label{sec:rqone}

\begin{table}[h]
\small
\centering
\caption{The fake news detection performance of baselines and our model. Stars denote statistically significant under the t-test ($\ast \; p\leq0.05, \ast\ast\; p\leq0.01$, $\ast\ast\ast\; p\leq0.001$).}
\resizebox{0.98\linewidth}{!}{\begin{tabular}{l|l|ll|ll}  
\hline
 \multirow{2}{*}{} & \multirow{2}{*}{\textbf{Model}}  & \multicolumn{2}{c|}{\textbf{POL}}  &  \multicolumn{2}{c}{\textbf{GOS}}  \\ 
\cline{3-6}
 &  & ACC & F1 & ACC & F1 \\
\hline

\multirow{4}{*}{ \begin{tabular}[l]{@{}l@{}} News \\ Only \end{tabular}} & SAFE~\cite{zhou2020mathsf}  & 73.30 & 72.87   & 77.37 &  77.19 \\
 & CSI~\cite{ruchansky2017csi}  & 76.02 &  75.99   & 75.20 &  75.01 \\
 & BERT+MLP & 71.04 &  71.03   & 85.76 &  85.75  \\
 & word2vec+MLP  & 76.47 &  76.36   & 84.61 &  84.59  \\
\hline
 \multirow{3}{*}{ \begin{tabular}[l]{@{}l@{}} News + \\ User \end{tabular}} & GNN-CL~\cite{han2020graph}  & 62.90 &  62.25   & 95.11 &  95.09 \\
 
 & GCNFN~\cite{monti2019fake} & 83.16 &  83.56   & 96.38 &  96.36  \\
 
 
 & \UPFD (ours) & $\mathbf{84.62^{\ast}}$ &  $\mathbf{84.65^{\ast}}$   & $\mathbf{97.23^{\ast\ast}}$ &  $\mathbf{97.22^{\ast\ast\ast}}$  \\

\hline
\end{tabular}}
\label{tab:previous}
\end{table}

Table~\ref{tab:previous} shows the fake news detection performance of \UPFD and six baselines.
First, we can observe that \UPFD has the best performance comparing to all baselines.
\UPFD outperforms the best baseline GCNFN around 1\% on both datasets with statistical significance.
The experimental results of \UPFD and GCNFN demonstrate that the user comments (used by GCNFN) are also beneficial to fake news detection; and the user endogenous preference could impose additional information when user comment information is limited.
Second, since all baselines either encode the news content or user comments without considering the historical posts,
we can tell that leveraging the historical posts as user endogenous preferences could improve the fake news detection performance.
Note that the \UPFD with the best performance on the both datasets uses BERT as the text encoder and GraphSAGE as the graph encoder.



\begin{table}[h]
\centering
\caption{Fake news detection performance on two datasets with different node feature types and models. The bold (underlined) text indicates the best (second best) performances on each dataset.}
\resizebox{0.99\linewidth}{!}{\begin{tabular}{l|cc|cc||cc|cc}  
\hline
   \multirow{3}{*}{\textbf{Feature}} & \multicolumn{4}{c||}{\textbf{POL}} & \multicolumn{4}{c}{\textbf{GOS}}\\
  \cline{2-9}
   &  \multicolumn{2}{c|}{GraphSAGE}   & \multicolumn{2}{c||}{GCNFN} &  \multicolumn{2}{c|}{GraphSAGE}   & \multicolumn{2}{c}{GCNFN}\\
\cline{2-9}
  & ACC & F1 &  ACC & F1  & ACC & F1 & ACC & F1 \\
\hline
  Profile   & 77.38  & 77.12  &  76.94  & 76.72 & 92.19 & 92.16  & 89.00   & 88.96\\
   word2vec    & 80.54  & 80.41  &  80.54  & 80.41 & \underline{96.81} & \underline{96.80}  & 94.97   & 94.95 \\
  BERT  & \textbf{84.62}  & \textbf{84.53}  &   \underline{83.26}  & \underline{83.14} &  \textbf{97.23} & \textbf{97.22}  & 96.18   & 96.17\\
  \hline

\end{tabular}}
\label{tab:overall}
\end{table} 




\subsection{RQ2: Ablation Study}



\subsubsection{Encoder Variants}
As we mentioned in Section~\ref{sec03:fusion}, we employ different text encoders and GNNs to encode the endogenous and exogenous information.
In Table~\ref{tab:overall}, we show the fake news detection performance of two GNN variants using three different node features.
Note that ``word2vec'' and ``BERT'' represent features encoding the user endogenous preferences while the ``Profile'' feature is regarded as a baseline.
GraphSAGE~\cite{hamilton2017inductive} is a GNN to learn node embeddings via aggregating neighbor nodes information and
GCNFN~\cite{monti2019fake} is a GNN-based fake news detection model which leverages two GCN layers to encode the news propagation graph.

Table~\ref{tab:overall} shows that the endogenous features (word2vec and BERT) are consistently better than the profile feature, which only encodes the user profile information.
We also observe that GraphSAGE and BERT have the average best performance among other model and feature variants.
It suggests that BERT is better than word2vec for encoding textual features which has been verified on other NLP tasks~\cite{devlin2018bert}.
Note that the BERT performance could be further improved via fine-tuning, and we leave it as future work.


\begin{figure}[h]
    \centering
    \includegraphics[width=0.48\textwidth]{ablation.pdf}
    \caption{The fake news detection performance of different variants of \UPFD framework. -END/-EXO represents the \UPFD variant without endogenous/exogenous information.}
    \label{fig:ablation}
\end{figure}


\subsubsection{Framework Variants}
To verify the effectiveness of endogenous preference and exogenous context, we fix the text and graph encoder and design three \UPFD variants that remove the endogenous information, exogenous information or both of them.

Specifically, we employ the GCNFN (word2vec) as the graph (text) encoder for both datasets, and remove news concatenation to ensure a fair comparison.
The \UPFD variant without exogenous information (-EXO) is implemented by removing all edges in the news propagation graph.
Thus, -EXO encodes the news embedding solely based on node features without exchanging information between nodes.
The \UPFD variant without endogenous information (-END) takes the user profile as node features and does not contain user endogenous preference information.
The \UPFD variant without both endogenous and exogenous information (-END \& -EXO) replaces the node features of the -EXO with user profile features.

Figure~\ref{fig:ablation} shows the fake news detection performance for different \UPFD variants on two datasets.
We can find that removing either component from the \UPFD will reduce its performance.
Moreover, jointly encoding the endogenous and exogenous information attains the best performance.
The accuracy of \UPFD/-EXO is 85.61\%/81.63\%, and the F1 score of \UPFD/-EXO is 85.97\%/81.15\% on Politifact.
The accuracy of \UPFD/-EXO is 95.47\%/93.92\%, and the F1 score of \UPFD/-EXO is 95.46\%/93.81\% on Politifact.
All the experimental results are statistically significant under the t-test ($p\leq0.01$).
This indicates that exogenous information (i.e., news propagation graph) is more informative on Politifact since removing it results in a larger performance drop.
It is obvious that endogenous information contributes more to performance gain than exogenous information.
This observation further verifies the necessity of modeling user endogenous preferences. \section{Conclusion}


In this paper, we argues that user endogenous news consumption preference plays a vital role in the fake news detection problem.
To verify this argument, we collect the user historical posts to implicitly model the user endogenous preference and leverage the news propagation graph on social media as the exogenous social context of users.
An end-to-end fake news detection framework named \UPFD is proposed to fuse the endogenous and exogenous information and predict the news' credibility on social media.
Experimental results demonstrate the advantage of modeling the user endogenous preference.


 


\begin{acks}
This work is supported in part by NSF under grants III-1763325, III-1909323, and SaTC-1930941. Kai Shu is supported by the John S. and James L. Knight Foundation through a grant to the Institute for Data, Democracy \& Politics at The George Washington University.
\end{acks}





\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}




\end{document}
