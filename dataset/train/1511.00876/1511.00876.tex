\begin{filecontents*}{example.eps}
gsave
newpath
  20 20 moveto
  20 220 lineto
  220 220 lineto
  220 20 lineto
closepath
2 setlinewidth
gsave
  .4 setgray fill
grestore
stroke
grestore
\end{filecontents*}
\RequirePackage{fix-cm}
\documentclass[a4,12pt]{article}
\usepackage{graphicx}


\usepackage{times,longtable,color}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{paralist}
\usepackage{verbatim}
\usepackage{subfig}
\usepackage{calc}
\usepackage{varwidth}
\usepackage{url}
\usepackage{fullpage}
\usepackage{hyperref}





\newcommand{\eps}{\varepsilon}
\newcommand{\smallestred}{\mathfrak{r}}
\newcommand{\p}{\mathfrak{p}}
\newcommand{\e}{\mathfrak{e}}
\newcommand{\f}{\mathfrak{f}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\B}{\mathcal{B}}
\renewcommand{\O}{{\cal O}}
\newcommand{\Q}{\mathcal{Q}}
\newcommand{\R}{\mathcal{R}}
\newcommand{\D}{\mbox{\textsc{Redspace}}}
\newcommand{\U}{\mathcal{U}}
\newcommand{\gammaBound}{\Gamma_0}
\newcommand{\opt}{\mbox{\textsc{opt}}}
\newcommand{\alg}{\mbox{\textsc{alg}}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\SonofH}{\mbox{\textsc{Son Of Harmonic}}}
\newcommand{\SuperH}{\mbox{\textsc{Super Harmonic}}}
\newcommand{\MarkItems}{\mbox{\textsc{Mark}} \mbox{\textsc{and}} \mbox{\textsc{Color}}}
\newcommand{\EHarm}{\mbox{\textsc{Extreme}} \mbox{\textsc{Harmonic}}}
\newcommand{\Pack}{\mbox{\textsc{Pack}}}
\newcommand{\PackS}{\mbox{\textsc{PackSimple}}}
\newcommand{\Hpp}{\mbox{\textsc{Harmonic++}}}
\newcommand{\af}{{\sc Any Fit}}
\newcommand{\nf}{{\sc Next Fit}}
\newcommand{\nfd}{{\sc Next Fit Decreasing}}
\newcommand{\ff}{{\sc First Fit}}
\newcommand{\bfit}{{\sc Best Fit}}
\newcommand{\harm}{{\sc Harmonic}}
\newcommand{\rharm}{{\sc Refined Harmonic}}
\newcommand{\mharm}{{\sc Modified Harmonic}}
\newcommand{\iharm}{{\sc Improved Harmonic}}
\newcommand{\vharm}{{\sc Variable Harmonic}}
\newcommand{\mmharm}{{\sc Strange Harmonic}}
\newcommand{\medium}{\mathrm{medium}}
\newcommand{\size}{\mathrm{s}}

\newcommand{\rTypes}{N}
\newcommand{\rItems}{n}

\newcommand{\blueitems}{n_\mathrm{blue}^i}
\newcommand{\reditems}{n_{\mathrm{red}}^i}
\newcommand{\allitems}{n^i}
\newcommand{\bonus}{n_{\mathrm{bonus}}}

\newcommand{\leaves}{\mathrm{leaves}}
\newcommand{\needs}{\mathrm{needs}}
\newcommand{\redfit}{\mathrm{redfit}}
\newcommand{\bluefit}{\mathrm{bluefit}}
\newcommand{\blue}{x}

\newcommand{\redspace}{\mathrm{redspace}}
\newcommand{\redfrac}{\mathrm{red}}
\newcommand{\Tiny}{\textsc{Tiny}}
\newcommand{\UnmixedRed}{\textsc{UnmixedRed}}

\newcommand{\finalratio}{1.5813}	
\newcommand{\finallb}{1.5762}
\newcommand{\superhratio}{1.58880}
\newcommand{\newsuperhratio}{1.5884}
\newcommand{\sO}{
\setlength{\itemsep}{0pt}
}

\algrenewcomment[1]{\hfill // \emph{#1}}
\algnewcommand{\LineComment}[1]{\State // \emph{#1}}
\algnewcommand\algorithmicforeach{\textbf{for each}}
\algdef{S}[FOR]{ForEach}[1]{\algorithmicforeach\ #1\ \algorithmicdo}



\newcommand{\qed}{}\newtheorem{invariant}{Invariant}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{aproperty}{Property}
\newtheorem{pproperty}{Packing Property}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{theorem}{Theorem}
\newenvironment{proof}{\noindent\textbf{Proof\ \ }}{\hfill}
\newenvironment{acknowledgements}{Acknowledgements}{}
\newlength{\LPlhbox}
\newcommand{\LPblocktag}[2]{\settowidth{\LPlhbox}{(#1)}\parbox{\LPlhbox}{}\hspace*{\fill}}



\begin{document}

\title{Beating the Harmonic lower bound for online bin packing\thanks{A preliminary version of this paper appeared in 43rd Int. Coll. on Automata, Languages and Programming (ICALP 2016), p. 41:1-41:14.}}




\author{Sandy Heydrich\footnote{Fraunhofer-Institut f\"ur Techno- und Wirtschaftsmathematik ITWM, Kaiserslautern, Germany. \url{heydrich@mpi-inf.mpg.de} Work performed at Max Planck Institute for Informatics and Graduate School of Computer Science, Saarland Informatics Campus, Germany, and supported by the Google Europe PhD Fellowship. }         \and
        Rob van Stee\footnote{Department of Mathematics, University of Siegen, 57068 Siegen, Germany, \url{rob.vanstee@uni-siegen.de}.
        Work done at the University of Leicester, LE1 7RH University Road, Leicester, UK.} }

\iffalse 
\institute{S. Heydrich \at
              Max Planck Institute for Informatics and Graduate School of Computer Science, Saarland Informatics Campus, Germany\\
              Tel.: +49681-9325-1028\\
              \email{heydrich@mpi-inf.mpg.de}           \and
           R. van Stee \at
              Department of Mathematics, University of Siegen, 57068 Siegen, Germany\\
              \email{rob.vanstee@uni-siegen.de}.
              Work done at the University of Leicester, LE1 7RH Universitz Road, Leicester, UK.
}
\fi 
\date{Received: date / Accepted: date}



\maketitle

\begin{abstract}
In the online bin packing problem, items of sizes in  arrive online to
be packed into bins of size 1. The goal is to minimize the number of used bins.
In this paper, we present an online bin packing algorithm with asymptotic 
competitive ratio of \finalratio. This is the first improvement in fifteen years and reduces the gap to the lower bound by 15\%. 
Within the well-known {\SuperH} framework, no competitive ratio below 1.58333 can be achieved.

We make two crucial changes to that framework. First, 
some of our algorithm's decisions depend on \emph{exact sizes} of items, instead of only their types.
In particular, for each item with size in , we use its exact size to determine if it can be packed together with an item of size greater than . Second, we add constraints to the linear programs considered by Seiden, in order to better lower bound the optimal solution. These extra constraints are based on marks that we give to items based on how they are packed by our algorithm.
We show that for each input, there exists a single weighting function that can upper bound the competitive ratio on it.

We use this idea to simplify the analysis of {\SuperH}, and show that the algorithm {\Hpp} is in fact \superhratio-competitive (Seiden proved 1.58889), and that {\newsuperhratio} can be achieved within the {\SuperH} framework.
Finally, we give a lower bound of {\finallb} for our new framework.
\end{abstract}






\section{Introduction}
In the online bin packing problem, a sequence of \emph{items} with sizes in the
interval  arrive one by one and need to be packed into \emph{bins}, so that
each bin contains items of total size at most 1. Each item must be irrevocably
assigned to a bin before
the next item becomes available. The algorithm has no knowledge about future items.
There is an unlimited supply of bins available, and the goal is to minimize the 
total number of used bins (bins that receive at least one item).

Bin packing is a classical and well-studied problem in combinatorial optimization. 
Extensive research has gone into developing approximation
algorithms for this problem, e.g. ~\cite{CoGaJo97,GaGrUl72,FerLue81,KarKar82,Rothvoss13,GoeRot14}. Such algorithms have provably good competitive ratio for any possible
input and work in polynomial time. In fact, the bin packing problem was one 
of the first for which approximation algorithms were designed \cite{Johnso73}. 

For bin packing, we are typically interested in the long-term behavior of
algorithms: how good is the algorithm for large inputs, relative to the optimal solution? 
This ratio is often determined by very small inputs. 
To avoid such pathological
instances, the {\em asymptotic competitive ratio} was introduced,
which we now define. For a given input sequence ,
let  be the number of bins used by algorithm~ on .
The {\em asymptotic competitive ratio} for an algorithm~ is defined to be

From now on, we only consider the asymptotic competitive ratio unless otherwise stated. 
For a given input, we typically consider a fixed optimal solution for the analysis.

Lee and Lee~\cite{LeeLee85} presented an algorithm called \harm, 
which partitions the interval
 into  intervals .
The type of an item is defined as the index of the interval which contains its size.
Each type of items is packed into separate bins ( items per bin for type ; type  items are packed
using {\nf} in dedicated bins).
For any , there is a number  such that the \harm\ algorithm
that uses  types has a competitive ratio of at most
~\cite{LeeLee85}, where  for .

\iffalse 
{\SuperH} algorithms classify items based on an interval partition of  and give each item a color as it arrives, red or blue.
For each type , the fraction of red items is some constant denoted by . 
Blue items are packed as in \harm, i.e., for each item type , every bin with blue
items contains a maximal number of blue items. (This may leave some space for
smaller red items of different types.) Red items are packed in bins which
are only partially filled. The idea is that hopefully, later blue items
of other types will arrive that can be placed into the bins with red items. \fi 

\begin{definition}
\label{def:1}
We use the following adjectives for ranges of item sizes.
\emph{Huge} means , \emph{large} means , \emph{medium} means , and \emph{small} means .
\end{definition}

If we consider the bins packed by \harm, then
it is apparent that in bins with large items, nearly half the space can remain
unused. It is better to use this space for items of other types.
After a sequence of papers which used this idea to develop ever better algorithms~\cite{LeeLee85,RaBrLL89,Richey91},
Seiden~\cite{Seiden02} presented a general framework called {\SuperH} which captures all of these algorithms. We describe it in some detail, since we reuse many concepts,
and in order to describe our modifications in a clear way.

\paragraph{The {\SuperH} framework~\cite{Seiden02}}

The fundamental idea of all \SuperH{} algorithms is to first classify items by
size, and then pack an item according to its type (as opposed to
letting the exact size influence packing decisions).
For the classification of items, we use numbers  to 
partition the interval
 into subintervals .
( is a parameter of the algorithm.)
 We define 
for  and .
We denote the type of an item  by , and its size by .
An item  has type  if . 
A type  item has size at most . 

Each item receives a color when it arrives, red or blue; an algorithm in the {\SuperH} framework defines parameters  for each type , which denotes the fraction of items of type  that are colored red.\footnote{This parameter was called  by Seiden; we have made many changes to the (somewhat ad hoc) notation.}
Blue items of type  are packed using \nf{}. We use each bin until 
exactly  items are packed into it.
For each bin, smaller red items may be packed into the space 
of size  that remains unused. 
Red items are also packed using \nf{}, using a fixed amount of the available space in a bin. 
This space is chosen in advance from a fixed set  of spaces, where . 
If red items of type  are packed into a space of size , we pack  red items into each bin.
In the space not used by red items, the algorithm may pack blue items.
There may be several types that the algorithm can pack into a bin together with red items of type .
Each bin will contain items of at most two different types.
If a bin contains items of two types, it is called mixed. If it contains items of only one type, but items of another type may be packed into this bin later, it is called unmixed. 
A bin that will always contain items of one type is called pure blue. A {\SuperH} algorithm tries to minimize the number of unmixed bins,
and to place red and blue items in mixed bins whenever possible. 
Seiden~\cite{Seiden02} showed that the {\SuperH} algorithm {\Hpp}, which uses 70
intervals for its classification and has about 40 manually set
parameters, achieves a competitive ratio of at most 1.58889.

The algorithm {\Hpp} always packs only one red item in a bin, and Seiden exploits this fact in his analysis. However, a very minor technical change is sufficient to make his analysis more general. Since Seiden does mention the possibility of packing more than one red item in a bin, only deciding against it because he could not find good settings for the parameters, we do not see this as a new idea of our algorithm. By allowing more than one red item in a bin in the {\SuperH} framework, a competitive ratio of 1.5884 can be achieved.

Ramanan et al.~\cite{RaBrLL89} gave a lower bound of 
for all {\SuperH} algorithms.
It is based on \emph{critical bins} (formally defined later) like the one shown in
Fig. \ref{fig:ramanan}, which contain a \emph{medium} item (size in ) and
a \emph{large} item (size in ). 
Both of these items arrive many times, and although they fit pairwise
into bins, the algorithm does not combine them like this. 
In contrast, the optimal solution consists exclusively of critical bins.


\paragraph{Our contribution}
We avoid the lower bound construction of Ramanan et al.~\cite{RaBrLL89} by defining
the algorithm so that it combines medium and large items \emph{whenever} they 
fit together in a single bin. 
Essentially, we use {\af} to combine such items into bins (under certain
conditions specified below). This is a generalization of the well-known
algorithms {\ff} and {\bfit}~\cite{Ullman71,GaGrUl72}, which have been used in similar 
contexts before~\cite{babdss15,BaChKK04}. 
For all other items, we essentially leave the structure of {\SuperH} intact, although a number of technical changes are made, as we describe next.
Each bin will still contain items from at most two types, and if there are two types in a bin, then the items of one type are colored blue and the others are colored red.

\begin{figure}\begin{center}
		\includegraphics[width=0.85\textwidth]{image0}
		\caption{\label{fig:ramanan}A critical bin.
			The item sizes are chosen such that a given interval classification algorithm 
			(in this case, {\Hpp}) does not pack these items together. For any \SuperH{} algorithm, such sizes can be found.
			The central idea of our new algorithm is that we limit the number of times that these critical bins can occur in the optimal solution.
			This is how we beat the ratio of 1.58333.
		}
	\end{center}
\end{figure}

We extend the definitions of huge, large, medium and small items (Definition \ref{def:1}) to types in the natural way.\footnote{There will not be any types that contain ,  or  as an inner point in their interval.}
In order to benefit from using \af, we need to ensure that for each medium type, as much as possible, the \emph{smallest} items are colored red.
Otherwise, we run into the same problems as {\SuperH}, see Fig.~\ref{fig:red-too-large} for an example.
Our plan is therefore to initially give each medium item \emph{no color} and pack it alone in a bin.
After several items of some type  have arrived, we color the smallest one red and the others blue.
The next arriving blue items of this type (so-called \emph{late} items) will be packed into the bins with single blue items.
(See Fig. \ref{illus}.) In this way, at least the blue items which are \emph{first} in their bins (the \emph{early} items) are
not smaller than the smallest red item. We thus have a lower bound on the size of half of the blue items (the early ones).

However, postponing coloring decisions like this is not always possible or even desirable. In fact there are exactly two cases where this will not be done upon
arrival of a new medium item .
\begin{enumerate}
	\item 
	If a bin with suitable small red items (say, of some type )
	is available, and it is time to color  blue,
	we will pack  into that bin and color it blue, regardless of the precise size of .
	In this case, in our analysis we will carefully consider how many small
	items of type  the input contains; knowing that there must be some.
	This implies that in the optimal solution, not \emph{all} the bins can be critical.
	Moreover, our algorithm packs these small items very well, using almost the entire space in the bin.
	\item
	If a bin with a large item is available, and  fits into such a bin, we will
	pack  in one such bin as a red item regardless of which color it was supposed to get. 
	This is the best case overall, since finding combinations like this was exactly our goal! 
	This helps to avoid the worst case instances for {\SuperH} (Fig.~\ref{fig:all-medium-red}).
	However, there is a technical problem with this, which we discuss below.
\end{enumerate}

Overall, we have three different cases: medium items are packed alone initially (in which case we have a guarantee about the sizes of some of the blue items), medium items are combined with smaller red items (in which case these small items exist and must be packed in the optimal solution), or medium items are combined with larger blue items (which is exactly our goal).

The main technical challenge is to quantify these different advantages into one overall analysis. 
In order to do this, we introduce---in addition to and separate from the coloring---a marking of the medium items. The marking indicates whether the blue or red items of a given mark are in mixed or unmixed bins. This will bound the number of critical bins (Fig.~\ref{fig:ramanan}) that can exist in the optimal solution, leading to better lower bounds for the optimal solution value than Seiden~\cite{Seiden02} used.

\begin{figure}
	\begin{center}
		\subfloat
		[Packing produced by \SuperH{}.]
		{\includegraphics[width=0.45\textwidth]{image14}}
		\hspace{7mm}
		\subfloat
		[Optimal packing.]
		{\includegraphics[width=0.45\textwidth]{image15}}
	\end{center}
	\caption{Packing of a sequence of medium items (all of the same type ) followed by one large item. The items arrive in the order indicated by the numbers. \SuperH{} needs more bins than the optimal solution, as the red medium item is too large to be combined with the large item. 
		(We assume  here.) \label{fig:red-too-large}}
\end{figure}

\begin{figure}
	\begin{center}
		\subfloat
		[Pack items one per bin without coloring them.]
		{\includegraphics[width=0.45\textwidth]{image1}}
		\hspace{7mm}
		\subfloat
		[The fifth item arrives: time to fix the colors.]
		{\includegraphics[width=0.45\textwidth]{image2}}
		\\
		\subfloat
		[The smallest item becomes red.]
		{\includegraphics[width=0.45\textwidth]{image3}}
		\hspace{7mm}
		\subfloat
		[Additional blue items of the same type are added.]
		{\includegraphics[width=0.45\textwidth]{image4}}
	\end{center}
	\caption{\label{illus}Illustration of the coloring in \EHarm{}. Hatched items are uncolored. In this example, , where  is the type of all items depicted in this example.
		Note that the ratio of  does not hold (for the bins shown)
		at the time that the colors are fixed:  of the items are red at this point.
		The ratio  is achieved when all bins with blue items contain two blue items.
		The blue items which arrive in step (d) are called \emph{late} items.}
\end{figure}

\begin{figure}
	\centering
	\subfloat
	[Packing produced by \SuperH{}.]
	{\includegraphics[width=0.45\textwidth]{image16}}
	\hspace{7mm}
	\subfloat
	[Optimal packing and packing produced by \EHarm{}.]
	{\includegraphics[width=0.45\textwidth]{image17}}
	\caption{An example illustrating why it helps to occasionally color more than a -fraction of the items of a medium type  red. First, five large items arrive (numbered 1-5), then five medium items (numbered 6-10) of type . We assume that  here. \label{fig:all-medium-red}}
\end{figure}


Maintaining the fraction  of red items for all marks separately is necessary for the analysis. 
As we have seen however, if many large items arrive first, we must pack medium items with them whenever possible,
even if this violates the ratio . 
If there are more than  medium items of some type  when the input ends,
we call those items \emph{bonus items}. Each bonus item is packed in a bin with a large item.
After the input ends, we will (virtually) make some of those large items \emph{smaller} so that they get 
type  as well (see Fig.~\ref{fig:post-processing}(a)).
We then change the colors of the bonus items to ensure the proper fraction
 of red medium items.
Hence we \emph{modify the input}, but we only do this for the analysis and only once all the items have been packed.
Clearly the number of bins in the optimal solution can only decrease as a result of making some items smaller.

However,
there could be small red items (say, of type ) in separate bins that could have been packed in bins with two medium type  items, 
had such bins been available at the time when the small red items arrived. Creating such bins after the input ends generates a packing that 
is not covered by our analysis (as this analysis assumes that such compatible items are packed together in one bin, not two; see Fig.~\ref{subfig:postproc-b}).
To avoid this, we \emph{do not allow} small items to be packed into new bins as red items as long as bins with large and medium items exist that may later be modified. Instead, in such a case, we \textbf{count} a single medium item in such a bin as a number of red small items of type , and pack the incoming item of type  as a blue item (Fig.~\ref{fig:post-processing}(c)).
This ensures (as we will show) that if suitable bins with blue items are available,
red items of type  are always packed in them, rather than in new bins.

At this point, we stress that our algorithm does not actually modify the input while it is packing it in any way. The only thing that changes is the internal accounting of the algorithm (in such a way that it thinks it has packed less total size than it actually has). We will show a number of properties of the packing that the algorithm produces, and we crucially show that all of these properties are maintained whenever a bonus item is counted as several small items, which is the only point in which the accounting of the algorithm is changed relative to the actual input. Thus we do not follow the perhaps more common approach of showing that the algorithm would have performed the same on the modified input; we believe that approach cannot be applied here, as we do not see how to define arrival times for the small items that are created.


\begin{figure}[t]
	\begin{center}
	\subfloat
		[If bonus items remain after the algorithm terminates, we transform some large items to medium items, re-establishing the correct ratio of red items for the medium items (in this example, this ratio is ).]
		{\includegraphics[width=\textwidth]{image13c}\label{subfig:postproc-a}}
	\end{center}
	\subfloat
		[This situation \textbf{must not occur} in our algorithm: We shrink a large item packed with a bonus item but there are uncombined red small items compatible with the bonus item. ]
		{\includegraphics[width=\textwidth]{image13a}\label{subfig:postproc-b}}
	\\
	\subfloat
		[In order to prevent the situation in Fig. \ref{subfig:postproc-b}, we (virtually) resize and split the bonus item into small items when other small red items arrive. The new item becomes blue instead. Later, more small blue items can be packed with it.]
		{\includegraphics[width=\textwidth]{image13b}\label{subfig:postproc-c}}
	\\
	\caption{Post-processing and change of the input for the analysis. Gray items denote bonus items.
	\label{fig:post-processing}}
\end{figure}

Like Seiden~\cite{Seiden02} and many other authors~\cite{Ullman71,LeeLee85,RaBrLL89}, we use weighting functions to analyze the competitive ratio of our algorithm. 
A weighting function defines a weight for each item, depending on its type (and mark, in our case). 
By analyzing these, 
Seiden ended up with a set of mathematical programs that upper bounded
the competitive ratio of {\SuperH} algorithms. These
represented a kind of knapsack problems where each item has two
different weights.
Seiden used heuristics to solve these problems in reasonable time.

We instead split each mathematical program into two standard linear programs, and we add new constraints limiting how many critical bins there can be in the optimal solution, which can be deduced from the marks of the items. We solve the linear programs by creating a separation oracle for the dual, which solves a standard knapsack problem (with just one weight per item), making the results much easier to verify. The final weighting function we find depends on the input but does not depend on the marks anymore.
The two dual programs of each pair of linear programs are symmetric, so it is sufficient to give a solution for one of them.


We implemented a computer program which quickly solves the knapsack problems and also does the other necessary work, including the automated setting of many parameters like item sizes and values . As a result, our algorithm  {\SonofH} requires far less manual settings than \Hpp. We also provide a verifier program that checks the feasibility of these solutions; this verifier program should be easy to check by a reader. In addition, we also output the set of knapsack problems directly to allow independent verification.

This approach can also be applied to the original {\SuperH} framework. Surprisingly, we find that the algorithm {\Hpp} is in fact \superhratio-competitive,
using only one weighting function per input. 
A benefit of using our approach is that this result becomes more easily verifiable as well. 
Furthermore, we were able to improve and simplify the parameters of {\Hpp} to achieve a competitive ratio of {\newsuperhratio} within the {\SuperH} framework.

Our second main contribution is a new lower bound for all algorithms of this kind.
The fundamental property of all these algorithms is that they color a fixed fraction
of all items red (for each type). 
We show that no such algorithm can be better
than {\finallb}-competitive. Thus fundamentally different ideas will be needed to
get much closer to the lower bound of 1.54037, which we believe is closer to the
true competitive ratio of this problem.


\paragraph{Related Results}
The online bin packing problem was first investigated by
Ullman~\cite{Ullman71}.
He showed that the \ff\ algorithm has competitive ratio
. This result was then published in~\cite{GaGrUl72}.
Johnson~\cite{Johnso74} showed that the \nf\ algorithm has competitive ratio 2.
Yao showed that {\sc Revised First Fit} has competitive ratio ,
and further showed that no online algorithm has competitive ratio less
than ~\cite{Yao80A}.
Brown and Liang independently improved this lower bound to
1.53635~\cite{Brown79,Liang80}.
The lower bound stood for a long time at ,
due to van Vliet~\cite{Vliet92},
until it was improved to  by Balogh et al.~\cite{BBG12}.

An improved upper bound of 1.5873 by Balogh et al.~\cite{arxiv} partially builds on our ideas but uses a different analysis. The comments about our paper in the arxiv version refer to a previous version and are outdated, as the issue it mentions has long been fixed.

The \emph{offline} version, where all the items are given in advance, 
is well-known to be NP-hard~\cite{GarJoh79}. 
This version has also received a great deal of attention,
for a survey see~\cite{CoGaJo97}.





\section{The {\EHarm} framework}
First of all, to facilitate the comparison to the new framework, we give a formal definition of
the {\SuperH} framework in Algorithm \ref{alg:sh} and \ref{alg:pack1}. It uses the following definitions.
Let  count the total number of items of type , and  count the number of red items of type .

\begin{algorithm}
	\caption{\label{alg:sh}How the \SuperH{} framework packs a single item  of type .
		At the beginning, we set  and  for .}
	\label{SuperH}
	\begin{algorithmic}[1]
		\State{}
		\If{ \label{sh:centralif}}\Comment{pack a red item}
		\State{red}
		\State{}
		\Else\Comment{pack a blue item}
		\State{blue}
		\EndIf
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}
	\caption{The algorithm  for packing an item  of type  with color blue, red.\label{alg:pack1}}
	\begin{algorithmic}[1]
		\State{Try the following types of bins to place  with color  in this order:}
		\State{ \hspace{3mm} \textbullet\ 
			a pure blue, mixed, or unmixed -open bin with items of type  and 
			color  \label{pack:open1}}
		\State{ \hspace{3mm} \textbullet\ 
			an unmixed bin that is \emph{compatible} with  (the bin becomes mixed) \label{pack:compatible1}}
		\State{ \hspace{3mm} \textbullet\ 
			a new unmixed bin (or pure blue bin, if  and  blue)
			\label{pack:c11}}
	\end{algorithmic}
\end{algorithm}


A {\SuperH} algorithm uses a function   to map each item type to an index of a space in , indicating
how much space for red items it leaves unused in bins with blue items of this type. Here  means that no space is left for red items.
The algorithm also uses a function  to map
how much space (given by an index of ) red items of each type require.
We define  if and only if  (i.e., there are no red items of this type).

For each type  such that , 
the items of this type are packed in pure blue bins, that contain only blue items (only one type per bin).
An unmixed bin is called unmixed blue or unmixed red depending on the color of the items in it.

A mixed bin with blue items of type  and red items of type  satisfies the following properties:
.
Note that the last inequality holds if and only if .
The blue items will use space at most  and the red items will use
space at most .
An unmixed blue bin with blue items of type  is \emph{compatible} with a red item of type 
	if .
	An unmixed red bin with red items of type  is {compatible} with a blue item of type  if .


\begin{definition}
	A bin is \emph{red-open} if it contains some red items but can still receive additional red items. 
	We define \emph{blue-open} analogously. 
	A bin is \emph{open} if it is red-open or blue-open. 
\end{definition}

Red-open bins with red items of type  contain at least one and at most  red items.
Blue-open bins can be pure blue.
Red-open and blue-open bins can be mixed or unmixed.
Mixed bins can be red-open and blue-open at the same time.
A bin with  items of type  but no red items is not considered open, 
even though red items might still be packed into it later.


For {\EHarm}, we extend the definition of compatible bins.
As noted in the Introduction, some items will not receive a color when they arrive, but only later.
The goal of having uncolored items is to try and make sure that relatively small items of each medium type become red in the end
(to make it easier to combine them with large items).

\begin{definition}
\label{def:comp}
An unmixed bin is \emph{red-compatible} with a newly arriving item  if
\begin{enumerate}
\item
the bin contains blue or uncolored items\footnote{\label{fn4}We will see later that if an item has no color, it is the only item in its bin (Property \ref{prop:nocolor}).} of type ,  is small
and , \emph{or}
\item
the bin contains a (blue) large item of size ,  is medium and .
\end{enumerate}
An unmixed bin is \emph{blue-compatible} with a newly arriving item  if
\begin{enumerate}
\item
the bin contains red items\footnotemark[\value{footnote}] of type ,  is medium or small
and , \emph{or}
\item
the bin contains one red or uncolored medium item of size ,  is large and .
\end{enumerate}
\end{definition}

It follows that for checking whether a large item and a medium item can be combined in a bin, we ignore the values  and  and use only the relevant parts 2 of
Definition \ref{def:comp}. 


Like {\SuperH} algorithms, an {\EHarm} algorithm first tries to pack a red (blue) 
item into a red-open (blue-open) bin with items of the same type and color; then it tries to find an unmixed compatible bin; if all else fails, it opens a new bin. 
Note that the definition of compatible has been extended compared to {\SuperH},
but we still pack blue items with red items of another type and vice versa;
there will be no bins with blue (or red) items of two different types.
The new framework is formally described in Algorithms \ref{alg:eh} and \ref{alg:pack}.
Items of type  are packed using \nf{} as before.
We discuss the changes from {\SuperH} one by one. 
All the changes stem from our much more careful packing of medium items.
The algorithm {\MarkItems} called in line \ref{callmark} of {\EHarm} will be presented in Section \ref{sec:mark-and-color}.
This algorithm will take care of assigning marks and colors to the items. In particular, this will take care of fixing the color of medium items as described in Figure \ref{illus}.


As can be seen in {\Pack} (lines \ref{pack:open}, \ref{pack:c1} and \ref{pack:color}), medium items that are packed into new bins are initially packed \textbf{one} per bin and not given a color.
We wait until enough of these items have arrived, and then color the smallest one red using
{\MarkItems} (Fig. \ref{illus}). 
Note that  is increased in line \ref{eh:fixbonus4} even though the item might not receive a color at this time.
This means that the value  does not alway accurately reflect how many red items there currently are.
We will show that this is not an issue for the analysis (it will be accurate up to a constant).

\begin{algorithm}
	\caption{\label{alg:eh}How the \EHarm{} framework packs a single item  of type .
		At the beginning, we set , 
		and  for .}
	\label{ExtremeH}
	\begin{algorithmic}[1]
		\State{\label{eh:ni+1}}
		\If{ \label{eh:centralif}}\Comment{pack a red item}
		\If{ or 
			\label{eh:fixbonus} }
		\LineComment{special case: replace bonus item instead and pack the new item as blue; see Fig. \ref{subfig:postproc-c}}
		\If{}
		\State{Let  be a bonus item of type }\Comment{in this case, }
		\Else
		\State{Let  be a bonus item of some type  with }\Comment{here  is a small type}
\EndIf
		\State{}
		\State{Label  as type } \Comment{count  as type  item(s) and color it/them red}\label{eh:fixbonus1}
		\State{}\Comment{ might have been of type  already, then }\label{eh:countasi} 
		\State{
			\label{eh:fixbonus2}}
		\State{blue\label{eh:fixbonus3}} \Comment{since we now have  again}
		\Else
		\State red
		\State{ \label{eh:fixbonus4}} \Comment{The item is red or uncolored}
		\EndIf
		\Else \Comment{pack a blue item}
		\If { is medium, , and there exists a bin  that is red-compatible with   	\label{eh:early1}}
		\State{Place  in  and label it as bonus item. \Comment{special case: bonus item}\label{eh:bonus}}
		\State{\label{eh:ni-1}\Comment{we do not count this item for type }}
		\State{\label{eh:early2}} \Comment{Note that  contains a large item}
		
		\Else	\State{blue} \Comment{The item is blue or uncolored}
		\EndIf
		\EndIf
		\State{Update the marks and colors using {\MarkItems} (Section \ref{sec:mark-and-color}).\label{callmark}}
	\end{algorithmic}
\end{algorithm}





\begin{algorithm}
	\caption{The algorithm  for packing an item  of type  with color blue, red.\label{alg:pack}}
	\begin{algorithmic}[1]
		\State{Try the following types of bins to place  with (planned) color  in this order:}
		\State{ \hspace{3mm} \textbullet\ 
			a pure blue, mixed, or unmixed -open bin with items of type  and 
			color  \label{pack:open}}
		\State{ \hspace{3mm} \textbullet\ 
			a -compatible unmixed bin
			(the bin becomes mixed, with fixed colors of its items) \label{pack:compatible}}
		\State{ \hspace{3mm} \textbullet\ 
			a new unmixed bin (or pure blue bin, if  and  blue)
			\label{pack:c1}}
		\State{If  was packed into a new bin,  is medium and , give  \textbf{no} color, else give it the color . 	\label{pack:color}}
	\end{algorithmic}
\end{algorithm}


When an item arrives, in many cases, we cannot postpone assigning it a color, since a -open or -compatible bin is already available (see
lines \ref{pack:open}--\ref{pack:compatible} of ).
Additionally, if we are about to color an item blue because currently , we check whether a suitable large item has
arrived earlier. We deal with this case in lines \ref{eh:early1}--\ref{eh:early2}
of {\EHarm}.
In this special case, we \emph{ignore} the value .
We pack the medium item with the large item as if it were red (no further item will be packed into this bin), but we \emph{do not count} it towards the total number of existing medium items of its type; instead we label it a \textbf{bonus item}. Bonus items do not have a mark or color,
but this can change later during processing in the following two cases.


\begin{enumerate}
\item
Additional items of type  arrive which are packed as blue items. If enough of them arrive (so that it is time to color an item red again), we first check in line \ref{eh:fixbonus} of {\EHarm} if there is a bonus item of type  that we could color red instead. If there is, we will do so, and pack the new item as a blue item.
\item
An item of some type  and size at most  arrives, that should be colored red.
In this case, for our accounting, we view the bonus item as  red items of type , and adjust the counts accordingly in lines \ref{eh:fixbonus1}--\ref{eh:fixbonus2}
of \EHarm.\footnote{Note that the meanings of 
and  are switched in the description of the algorithm for reasons of presentation.}
The new item of type  is packed as a blue item in line \ref{eh:fixbonus3} of 
\EHarm.\footnote{Strictly speaking, we only need this whole procedure if type  is compatible with the bonus item, to avoid the case in Figure \ref{subfig:postproc-b}.
Instead, we do it for all small items for simplicity.}
\end{enumerate} 



It can be seen that blue items of size at most  are packed as in {\SuperH}.
For red items of size at most , we deal with existing bonus items in lines \ref{eh:fixbonus1}--\ref{eh:fixbonus2} of \EHarm, and in line \ref{pack:compatible} of , an existing medium item may be colored red or blue (the opposite of the parameter ).
Otherwise, the packing proceeds as in {\SuperH} for these items as well.


\subsection{Properties of {\EHarm} algorithms}

All {\EHarm} algorithms are required to satisfy the following properties.
The first two easy properties also hold for {\SuperH} and the third and fourth property hold for \Hpp{} (but not necessarily for all \SuperH{} algorithms).
Let .
\begin{aproperty}[Lemma 2.1 in Seiden~\cite{Seiden02}]
	\label{prop:nextfit}
	Each bin containing items of type , apart from possibly the last one, contains items of total size at least .
\end{aproperty}
\begin{aproperty}\label{prop:leaves-needs}
	For any type , if , then 
	. \end{aproperty}
\begin{proof}
If , then .
If , an additional item of type  could be placed in the space
, which means we could fit  blue items of type  into one bin,
contradicting the definition of .
\end{proof}

\begin{aproperty}
	\label{prop:redspace}
	If  is a small type with , .
	If  is a medium type, then
	. If  is a large or huge type, then , so  at all times.
\end{aproperty}
\begin{aproperty}
	\label{prop:tidelta}
	For , we have  if and only if .
\end{aproperty}


\begin{aproperty}
	\label{prop:redfrac}
	We have  for all types .
\end{aproperty}


\begin{aproperty}
	\label{prop:type12N}
	We have  and .
	All type 1 items (i.e., huge items) and type  items are packed in pure blue bins.
	We have .
\end{aproperty}

This property implies that  and .
This means that an unmixed bin with a large item is never red-compatible
with a medium item via Condition 1 of Definition \ref{def:comp}
(so only Condition 2 is relevant for this combination).
This furthermore implies that for a medium item of type , the precise value
 is irrelevant for the algorithm (only the fact that  is relevant).
It will nevertheless be useful for the analysis to have 
as required by Property \ref{prop:tidelta}.

\begin{aproperty}\label{prop:q1unique}
	Let  be two consecutive medium type thresholds of the algorithm. Then .
\end{aproperty}

\begin{aproperty}
	For each type  and color , at any time, there is at most one -open bin that contains items of type  and no other type.
	For each pair of types and color , at any time, there is at most one -open bin with items of those types.
\end{aproperty}
\begin{proof}
	All bonus items are in mixed bins; such a bin remains mixed if its bonus item gets labeled with a different type.
	Consider an item of type  and color .
By the order in which {\Pack} tries to place items into bins, we only open a new unmixed or pure blue bin of type  if no -open bin is available, so the first claim holds. 

Now consider a pair of types. Say the blue items are of type  and the red items are of type . 
The only cases in which a mixed bin with such items is created are the following:
\begin{itemize}
\item A red item of type  is placed into an unmixed bin  with blue items of type . In this case, there was no existing 
red-open mixed or unmixed bin with red items of type .
\item A blue item of type  is placed into an unmixed bin  with red items of type .
In this case, there was no existing blue-open mixed, unmixed or pure blue bin with blue items of type .
\item A bin receives a bonus item in line \ref{eh:bonus} of {\EHarm} and is now considered mixed.
\item A bonus item gets counted as items of type  in lines \ref{eh:fixbonus1}-\ref{eh:fixbonus2}.
\end{itemize}

At the beginning, there are zero open bins with items of type  and type .
Such bins are only created via one of the cases listed above. 
In the last two cases, no open bins are created (note that only one medium and one large item can be packed together in a bin).
In the second case,  is the only red-open bin with these types (if , that is), and no
red items of type  are packed into unmixed bins with blue items until  contains  type 
items by line \ref{pack:open} of Algorithm \ref{alg:pack}. In the first case, similarly, no new blue item of type  will be packed into unmixed bins with red items
as long as  remains blue-open.
\qed\end{proof}

\begin{aproperty}
\label{prop:redok}
At all times, for each type , .
For each medium type , .
For each small type , .
\end{aproperty}
\begin{proof}
The first bound follows from the condition in line \ref{eh:centralif} of {\EHarm} and because  increases by at most  in between two consecutive times that this condition is tested, unless a bonus item is labeled in lines \ref{eh:fixbonus1}--\ref{eh:fixbonus2} of {\EHarm}; but in that case, the fraction of red items of type  only increases, because
 and  increase by the same amount.

The upper bounds follow because for each medium type ,  increases by at most 1 when  and a new item of this type arrives: either in line \ref{eh:fixbonus2} ( for medium items) or in
line \ref{eh:fixbonus4}. Furthermore, if ,  is not increased anymore.
If a bonus item is created,  and  are unchanged (lines \ref{eh:ni+1} and \ref{eh:ni-1}).
For small items,  increases by at most  in one iteration (line \ref{eh:fixbonus2}), and this only happens if the ratio is too low (line \ref{eh:centralif}).
\qed\end{proof}

Recall that  is not always the true number of medium red items of type , as some of these may not have a color yet.
For a small type , the value  may also not be accurate, because it may include some bonus items. We will fix this in postprocessing, where we replace the bonus items by items of type  to facilitate the analysis.

\begin{aproperty}
At all times, for each type  that is not medium, .
\end{aproperty}

\begin{aproperty}
\label{prop:nocolor}
Each bin with an uncolored item contains only that item.
\end{aproperty}
\begin{proof}
By line \ref{pack:compatible} of the {\Pack} method, as soon as a bin becomes mixed, the colors of its items are fixed. 
By line \ref{pack:open} of the {\Pack} method, an unmixed bin with an uncolored item does not receive a second item of the same type.
\qed
\end{proof}

In particular, no bin which contains an uncolored item is a mixed bin.
The following important invariant generalizes a result for {\SuperH}
(which is easy to see for that algorithm).

\begin{invariant}
\label{inv:unmixed}
If there exists an unmixed bin with red items of type ,
then for any type  such that , 
there is no bin with a bonus item of type   
and no unmixed bin with blue items of type .
\end{invariant}
\begin{proof}
As long as an unmixed red bin
with items of some type  exists, no unmixed blue bin with items of type  for which
 can be opened and vice versa (line \ref{pack:compatible} of \Pack).

Now assume for a contradiction that there is an unmixed red bin with red items of type  (denote the first item in this bin by ) and a bin with a bonus item  of type .
Assume  arrived before . Consider the point in time where  arrived. After deciding that  should be colored red in line \ref{eh:centralif} of \EHarm, we would have found that the second part of the condition in line \ref{eh:fixbonus}  of {\EHarm} is true, and as a consequence would have made  no longer be bonus, a contradiction to our assumption.

Now assume that  arrived before . In this case, either  or the large item  that is packed with  arrived first. (Note that  definitely arrived after , or it would not have been made bonus.)
Now  since  was packed with the medium item . But 
by Property \ref{prop:redspace} and the assumption of the lemma.
Hence, regardless of which item among  and  arrived first, the algorithm does not pack them in different unmixed bins; the second arriving item would be packed at the latest by line \ref{pack:compatible} of {\Pack}.
\qed\end{proof}




















\subsection{Marking the items}
\label{sec:mark-and-color}

\begin{definition}
A \emph{critical bin} for an {\EHarm} algorithm is a bin used in the optimal solution that contains a pair of items,  one of a medium type  () and one of a large type  () such that  but .
\end{definition}
An example was given in Fig.~\ref{fig:ramanan}.
By marking the medium items, we keep track of how many red and blue items of a given type  are in mixed bins.
Blue medium items in mixed bins imply the existence of compatible small items in the input
(which need to be packed somewhere in the optimal solution).
Red medium items in mixed bins means that the algorithm managed to combine at least some pairs of medium and large items
together into bins. In both cases, we have avoided the situation where the offline packing consists \emph{only} of
critical bins, whereas the online algorithm did not create \emph{any} bins which contain a large and a medium item.
\begin{figure}[t]
	\begin{center}
	\subfloat
		[Items get mark : uncolored items and a red item in a mixed bin. The bins with blue -items will receive an additional blue item of the same type before any new bin is opened for this type.]
		{\includegraphics[width=\textwidth]{image5}}
	\\
	\subfloat
		[Items get mark : a single uncolored item and blue items (in pairs) in mixed bins.]
		{\includegraphics[width=\textwidth]{image6}}
	\\
	\subfloat
		[Items get mark : a set of uncolored items. The bins with blue -items will receive an additional blue item of the same type before any new bin is opened for this type. See Fig. \ref{illus}.]
		{\includegraphics[width=\textwidth]{image7}}
	\end{center}
	\caption{Marking the items.
	For simplicity, we have taken  here (where  is the type of the medium items).
	\label{fig:marking}}
\end{figure}
We use three different marks, which together cover all the cases. Our marking is illustrated in Fig. \ref{fig:marking}. 
\begin{description}
\item[] For any medium type , a fraction  of the items marked 
are red, and all of these
\textbf{red} items are packed into mixed bins (i.e., together with a large item).
\item[] For any medium type , a fraction  of the items marked 
are red, and the \textbf{blue} items are packed into mixed bins (i.e., together with small red items).
\item[] For any medium type , a fraction  of the items marked 
are red, and \textbf{none} of the red and blue items marked  are packed into mixed bins.
\end{description}

The algorithm {\MarkItems} is defined in Algorithm \ref{alg:mark}. 
For a given type  and set ,
denote the number of red items by ,
and the total number of items by . 
Algorithm \ref{alg:mark} is run every time after an item has been packed, 
and for every medium type  for which  separately.
It divides the medium items into three sets  and  (see Fig. \ref{fig:marking}). 
Once assigned, an item remains in a set
until the end of the input (after which it may be reassigned, see Section \ref{sec:final}). In many cases, the algorithm will have nothing to do, as none of the conditions hold.
Therefore, some items will remain temporarily unmarked, in a set . 
The set  does not contain the bonus items (in fact none of the sets does).

\begin{algorithm}[!t]
\caption{\label{alg:mark}
The algorithm {\MarkItems} as applied to \emph{medium} items of type  for which .}
\begin{algorithmic}[1]
\If {there is an unmarked blue item  in a bin with a marked blue item }
\State Give  the same mark  as . \label{mark:1}
\State  \label{mark:2}
\EndIf
\State{Let  be the minimum integer value such that
}
\If{there exist  uncolored non-bonus items and one unmarked
 red or bonus item in a mixed bin\label{mark:newr1}}
\State{Mark these  items . If there is a choice of items in mixed bins, use a bonus item\par if possible
	and color it red. Color the (other) uncolored items blue.\par
	If a bonus item is used, .
\label{mark:newr2}}
\State{ 
 \label{mark:newr3}}
\EndIf
\State{Let  be the minimum integer value such that
.}
\If
{there exists an uncolored non-bonus item and a set of mixed bins with 
two unmarked blue items each, which contains a number
 of blue items in total, \label{mark:newblue1}} 
\State{Mark these  items  and color the uncolored item red. \label{mark:newblue2}}
\State{,  }
\EndIf
\State{Let  be the minimum integer value such that 
.}
\If
{there exist  uncolored non-bonus items
\label{mark:check}}
\State{Mark the  largest uncolored items and the single smallest uncolored item \par with the mark . Color  red and the other  items blue.\label{mark:newind1}}
\State{, \label{mark:newind5}}
\EndIf
\end{algorithmic}
\end{algorithm}































Line \ref{mark:newind1} of {\MarkItems} ensures the following property, which was the point of postponing the coloring.
Recall that early items are blue -items which did not get their color immediately and were
packed one per bin (each late item is packed in a bin that already contains an early item).

\begin{aproperty}
	\label{prop:first}
	Each early -item is at least as large as the red -item that
	received its mark in the same iteration of \MarkItems.
\end{aproperty}

After all items have arrived and after some post-processing, we will have 
Each item will be marked according to the set to which it (initially) belongs.
We will see that the values  and  in {\MarkItems} are calculated in such a way that
 holds just before any assignment
to .
The proof is straightforward. 

Note that {\MarkItems} never changes the values  and .
As we saw, the value  may be inaccurate for some types in any event.
This will be fixed for small types in post-processing, whereas for medium types we will prove (\ref{eq:rightfraction}).
Of course, {\MarkItems} does change values
 and  for  in order to record how many
items with each mark there are (and these values \emph{will} be accurate).  





\begin{lemma}
\label{lem:marksNR}
Let .
Just before assignments of new items to  in lines \ref{mark:newr2}-\ref{mark:newr3} or lines \ref{mark:newind1}-\ref{mark:newind5},
for each medium type  such that ,
we have 
and . Generally, we have 
 . 
\end{lemma}
\begin{proof}
Call the assignment of new items to  due to lines \ref{mark:newr2}-\ref{mark:newr3} or lines \ref{mark:newind1}-\ref{mark:newind5} \emph{early assignments}. 


At the beginning, we have .
Thus the lemma holds at this time.
When an early assignment takes place, 
 increases by , and  by 1.
By minimality of , just before any early assignment we have

where we have used Property \ref{prop:redfrac} and integrality in the penultimate line and
the definition of  in the last line.
This immediately implies that right after an early assignment to ,

There are then  bins with one early blue medium item of type . 
{\EHarm} will put
the next arriving blue items of this type into these  bins (one additional item per bin) before opening any new bins.
All of these late blue items are assigned to  and  is increased accordingly in lines \ref{mark:1}--\ref{mark:2},
so eventually .

After that,  and  remain unchanged until the next early assignment of items to . Hence before an early assignment of items to , the first claimed equality holds.

This equality together with (\ref{xbound1}) 
gives 
which implies  and thus  since .
This, together with (\ref{eq:mark-after-assign}), implies  (note that  is largest relative to  right after an early assignment to , i.e., when (\ref{eq:mark-after-assign}) holds).
\iffalse
It furthermore follows from (\ref{xbound2}) that after any early assignment
has taken place and the  bins with one blue item have received their
second blue item, we have 

since by this time  has increased by  and
 has increased by 1 compared to the situation in (\ref{xbound2}).
This also holds before the first early assignment takes place.
By definition of , we have . This, together with (\ref{lem1:before-assignment}), implies
 and thus .
\fi 
\qed\end{proof}

\iffalse 
\begin{corollary}
	\label{cor}
	For a medium type  with , let 
	Then  in all iterations of Algorithm \ref{alg:mark} for type .
\end{corollary}
\begin{proof}
	By Lemma \ref{lem:marksNR},  is strictly contained in an open interval of length 2.
\end{proof}
\fi 

\begin{corollary}
	\label{cor:uncolored}
	After each execution of \MarkItems{} and for each medium type   such that , .
\end{corollary}
\begin{proof}
	We have  and  by Lemma \ref{lem:marksNR}  since , so at the latest when
	 uncolored non-bonus items exist, they are marked and colored.
\qed\end{proof}




\begin{lemma}
\label{lem:markB}
At all times and for each medium type  such that , 
and . 
\end{lemma}
\begin{proof}
We use similar calculations to the proof of Lemma \ref{lem:marksNR}.
At the beginning, all counters are zero. When {\MarkItems} is about to assign items to , 
we have 
by definition of  and Property \ref{prop:redfrac}.
This immediately implies that after each assignment,
we have . 
By minimality of , we also conclude , so  .
\qed\end{proof}





















\section{Post-processing}
\label{sec:post}
Since we consider only the asymptotic competitive ratio in this paper, 
it is sufficient to prove that a certain ratio holds for 
all but a constant number of bins: such bins are counted in the additive constant.
We will perform a sequence (of constant length) of removals of bins in this section.
We will also change the marks of some items to better reflect the actual output, 
fix the type and color of any remaining bonus items and reduce the sizes of some items
to match the values used by {\EHarm} in its accounting (see line \ref{eh:countasi} of Algorithm \ref{alg:eh}).






To begin with, we remove the at most  bins with unmarked medium items
(Corollary \ref{cor:uncolored}), but not the bonus items.
We also remove (at most ) blue-open pure blue bins,
as well as the single bin with items of type  of total size at most , if it exists (see Property \ref{prop:nextfit}).
Additionally, we remove any bins with a \emph{single} blue - or -item, as well as all bins that were assigned to  and  at the same
time as such bins (i.e., during one execution of lines \ref{mark:newblue2} or \ref{mark:newind1} of {\MarkItems}).
This is at most  bins
by Lemma \ref{lem:marksNR}.
Overall we have removed at most a constant number of bins so far.
The packing now has the following property.
This and subsequent Packing Properties will continue to hold during post-processing and will be the basis of our proof of the competitive ratio.

\begin{pproperty}
\label{pp:twoblue}
All medium non-bonus items are marked.
Each blue item in  and  is packed in a bin that contains two blue items,
and  and 
each medium type .
All bins with blue -items or red -items are mixed. 
All bins with items of type  are at least  full.
\end{pproperty}
\begin{proof}
Lines \ref{mark:newblue2} or \ref{mark:newind1} of {\MarkItems} are only executed if all blue items that were
assigned to  or  in a previous run of {\MarkItems}
are already packed into bins with two blue items, since 
Algorithm {\Pack} prefers to pack a new blue item into an existing blue-open bin.
Thus, when we remove all bins with single - or -items, this is only constantly many bins.
The blue -items are packed two per bin by the rules of \MarkItems.
The equality then follows from Lemmas \ref{lem:marksNR} and \ref{lem:markB}. 
The penultimate line follows from the way {\MarkItems} selects the items to mark. The last line follows from Property \ref{prop:nextfit}.
\qed\end{proof}


\paragraph{Final marking}
\label{sec:final}

\begin{figure}[t!]
	\begin{center}
		\includegraphics[width=0.8\textwidth]{image8}
		\caption{\label{fig:final}Reassigning marks after the input is complete and changing some items to get rid of bonus items.
		Items are sorted into their correct sets whenever possible, updating the marks
		that they received while the algorithm was running. Some item sizes are reduced (!).
		The bins next to the arrows indicate what sets of bins are being reassigned.
		}
	\end{center}
\end{figure}

An overview of our changes of marks and sizes
is given in Fig. \ref{fig:final}. 
We will change marks of some items to  or  if
such marks are appropriate. To do this, we run Algorithm \ref{alg:final}
for every medium type  separately.
Note that seemingly wrongly marked items like the ones we look for in
Algorithm \ref{alg:final} can indeed exist because while the algorithm is
running we only mark
each item once, when it is assigned to a set; other items could arrive later
and be packed with it, invalidating its mark.
Packing Property \ref{pp:twoblue} is not affected by Algorithm \ref{alg:final},
since we change marks in the correct proportions, and we only add items to  and 
that satisfy Packing Property \ref{pp:twoblue}. 

Instead of the process described in Algorithm \ref{alg:final}, an easier approach might seem to be
the following. For changing marks from  to , we could simply take the group of bins containing 
the -items that received their mark at the same time as the red -item in the mixed bin.
The problem with this approach is that not all these groups have the same size in general, since  may vary. This means the ratio  would possibly not
be maintained for  (and then also not for ).


\begin{algorithm}[t]
\caption{\label{alg:final}
Final marking for items of type  in {\EHarm} algorithms. Again we only
consider items of medium type .}
\begin{algorithmic}[1]
\State{Sort the bins with two blue -items in order of increasing size of the early -items in these bins.}\label{final:sort}
\For{}
\State{Let  be the largest integer value such that there exist}
	\begin{itemize}
		\item  red -items in mixed bins (one per bin) and
		\item  bins with (two) blue -items (so )
	\end{itemize}
\State{Assign the  largest red -items in mixed bins and the blue -items in the first\par
	 bins in the sorted order to  \label{final:assign-to-r}}
\EndFor
\State{Let  be the largest integer value such that there exist}
	\begin{itemize}
		\item  red -items 
		\item  mixed bins with (two) blue -items
	\end{itemize}
	\State{Assign the  largest red -items and the blue -items in the first
		 mixed bins in the sorted order
	 that were not yet reassigned to , to }
\end{algorithmic}
\end{algorithm}


\begin{pproperty}
\label{pp:allesOK}
No bins with items in  are mixed. 
No bins with \emph{red} items in  are mixed.
\end{pproperty}

\begin{lemma}
	\label{lem:pp12}
	After running Algorithm \ref{alg:final}, only constantly many bins need to be removed in order to ensure that Packing Property \ref{pp:allesOK} holds.
	Packing Property (\ref{pp:twoblue}) is maintained.
\end{lemma}

\begin{proof}
Let us fix a medium type .
After the first loop is finished, there can be at most constantly many red -items and -items in mixed bins, 
since these sets of items are both colored with the correct proportion of
red items by Packing Property \ref{pp:twoblue} and we move a maximal subset of items with the correct proportion to . 
After Algorithm \ref{alg:final} completes, there are at most constantly many blue -items in mixed bins
for the same reason.
We can remove all of these bins at the end if needed. This does not affect Packing Property \ref{pp:twoblue}.
\qed\end{proof}

The following lemma helps us to bound the optimal solution later.

\begin{lemma}
\label{lem:smallestred1}
Let the smallest medium red item of type  in  be . 
It is packed alone in a bin.
At most 
items in  have size less than .
\end{lemma}
\begin{proof}
Item  is packed alone by Packing Property \ref{pp:allesOK}.
Each red -item of type  has size at least  by definition of .
Furthermore, each \emph{early} blue -item of type  has size at least , where
 is the red -item that got its mark at the same time (Property \ref{prop:first}).
However, it is possible that the bin containing  received an additional (large, blue) item later.
In that case, after post-processing, the item  does not have mark  anymore,
so it is not considered when determining , and may in fact be smaller than .
In Algorithm \ref{alg:final}, we therefore take care to always select the bins with
the smallest early blue -items (line \ref{final:sort}). 

We now give an upper bound for the number of early blue -items that can be smaller than  but still have mark  after Algorithm \ref{alg:final} completes.
Let  be the number of red -items in mixed bins
that receive the mark  in line \ref{final:assign-to-r} of Algorithm \ref{alg:final}.
Then the total number of early items that got their mark  at the same time as these
 items is upper bounded by  by Lemma \ref{lem:marksNR}.
We transfer in total  early items from  to .
The number of early items that do not get transferred and are potentially smaller than 
is therefore at most   since .
Clearly, since we move  red -items to ,
 is at most  afterwards.

Finally, we give an upper bound for the number of late blue -items.
There are  blue items in  (using Lemma \ref{lem:marksNR}).
Half of them are packed into existing bins (i.e., as late items).
We have .

Since  by Property \ref{prop:redfrac}, the lemma follows.
\qed\end{proof}



\paragraph{A modification of the input}
\label{sec:mod}
In line \ref{eh:bonus} of {\EHarm}, bonus items are created. These are medium items which are packed as red items (each such item is in a bin with a large blue item) but violate the ratio . 
Some of them may still be bonus when the algorithm has finished. 
Also, some of them may be
labeled with a different type than the type they belong to according to their size. 
We call such items \emph{reduced} items. Note that {\EHarm} treated each reduced item as small red items in its accounting (but had in fact packed the larger bonus item).
All reduced items are in mixed bins. They are not counted as bonus items.

\begin{algorithm}[ht]
\caption{\label{alg:mod}
Modifying the input after packing all items}
\begin{algorithmic}[1]
\State{Let the number of bonus items of type  be . \Comment{These are not reduced items}}
	\State{Color  of these items red and the others blue. Mark them all .}\label{mod:doit-next}
	\State{Reduce the size of blue large items in the bins with (now) blue medium items of type  to .}\label{mod:shrink-large}
	\State{Mark all of these items  as well.\label{mod:mark-r}}
	\State{.}
	\State{}\label{mod:13}
\ForEach{reduced item }
	\State{Let  be the type with which  is labeled.\label{mod:reduced1}}
	\State{Split up  into  red items of size .\label{mod:split}}
	\State{Reduce the size of the newly created items until they belong to type .\label{mod:reduced2}}
\EndFor
\end{algorithmic}
\end{algorithm}

After {\EHarm} has finished, and the steps previously described in this sections have been applied,
we modify the packing that it outputs as described in Algorithm \ref{alg:mod}. 
Again we run this algorithm for every medium type .
The post-processing is illustrated in Fig. \ref{fig:post-processing}; the process in lines \ref{mod:doit-next}--\ref{mod:13} is illustrated in Fig. \ref{subfig:postproc-a}, the process in lines \ref{mod:reduced1}--\ref{mod:reduced2} in Fig. \ref{subfig:postproc-c}.
\begin{lemma}
\label{lem:noincrease}
Denote the set of items in a given packing  by .
Denote the set of items after applying Algorithm \ref{alg:mod} to the packing  by . Then  induces a valid packing for , and

\end{lemma}
\begin{proof}
In line \ref{mod:shrink-large} of Algorithm \ref{alg:mod}, items are only made smaller. In line \ref{mod:split}, a medium item of type  is split into  items of some type . 
The condition for an item to be labeled with type  in line \ref{eh:fixbonus} of 
{\EHarm} is that  is a small type.

By definition of  and , 
we have that  items of type  have
total size at most . Since  is a small type, this value is less than  by Property \ref{prop:redspace}.
This means the newly created items occupy less space than the medium item that they replace. Hence, in both cases we do not increase the amount of occupied space in any bin.

The inequality follows by choosing  to be an optimal packing for .
\qed\end{proof}

\begin{lemma}
Lemma \ref{lem:smallestred1} still holds after executing Algorithm \ref{alg:mod}.
\end{lemma}
\begin{proof}
Algorithm \ref{alg:mod} only creates new -items. Therefore, the number of ``problematic items'' that we want to upper bound, that is, the number of -items of size less than , does not increase. As we only increase  in Algorithm \ref{alg:mod}, the upper bound in Lemma \ref{lem:smallestred1} is not decreased.
\end{proof}

\begin{theorem}
	\label{thm:red-alpha}
	For a given input , denote the result of all the post-processing done in this section by . 
	Packing Properties \ref{pp:twoblue} and \ref{pp:allesOK} as well as Invariant \ref{inv:unmixed}
	still hold after post-processing.
	For any type , at the end we have ,
	where  counts the (correct) total number of red items of type  after postprocessing.
	There are no bonus items, and  the optimal cost to pack the input did not increase in post-processing.
\end{theorem}
\begin{proof}
	Let  be the packing of  that is output by .
	Let  be the packing after running Algorithm \ref{alg:final}, and let the items packed into  be .
	Packing Properties  \ref{pp:twoblue} and \ref{pp:allesOK} hold for   by Lemma \ref{lem:pp12}. Since in Algorithm \ref{alg:mod} we colored the bonus items in the right proportions,
	the ratio  of red items holds for each medium type  up to a constant number of items by Packing Property \ref{pp:twoblue}.
	For a small type , we have  by Property \ref{prop:redok}.
	The only effect of post-processing is that afterwards,  counts the actual number of red items of type  in .
	(Some of these red items replace bonus items in , but the algorithm already counted them in the value .)
All bonus items were removed, and Packing Properties  \ref{pp:twoblue} and \ref{pp:allesOK} remain unaffected.
	
	Consider some medium type . Invariant \ref{inv:unmixed} is not affected by any change of marks or removal of bins.
	The effect of lines \ref{mod:doit-next}--\ref{mod:13} of Algorithm \ref{alg:mod} is that some bins with bonus items
	of type  are replaced with unmixed bins with blue type  items.
	This does not affect the validity of Invariant \ref{inv:unmixed}.	
	
	To get from  to , we only removed some bins (and changed marks, which are irrelevant for the optimal solution).
	Hence . We can now apply Lemma \ref{lem:noincrease} to the optimal packing for  to get the final claim.
\end{proof}













\section{Weights}
Let  be an {\EHarm} algorithm.
For analyzing the competitive ratio of , we will use the well-known technique of weighting functions. The idea of this technique is the following. We assign weights to each item such that the number of bins that our algorithm uses in order to pack a specific input is equal (up to an additive constant) to the sum of the weights of all items in this input. Then, we determine the average weight that can be packed in a bin in the optimal solution. This average weight for a single bin gives us an upper bound on the competitive ratio. In order to use this technique, we now define a set of weighting functions.

Fix an input sequence 
Denote the result of post-processing  by . 
Let  be the packing of  that is output by .
Let  be the packing of  induced by  (Lemma \ref{lem:noincrease}).

From this point on, our analysis is purely based on the structural properties of the packing  that we established in Theorem \ref{thm:red-alpha}. We view  only as a set of items and not as a list. We prove in Theorem \ref{thm:ub-eh} below that this is justified. In particular, we do \emph{not} make any statement about , since the post-processing done in Algorithm \ref{alg:final} means that some items (e.g., the ones introduced in lines \ref{mod:reduced1}-\ref{mod:reduced2}) do not have clearly defined arrival times, and it is not obvious how to define arrival times for them in order to ensure that .

The \emph{class}
of an item of type  is , if it is blue, and  if it is 
red.
The class of an item  indicates how much space is reserved for red items in the bin containing 
(both if  is red and if  is blue), namely  space if the class is .

\begin{lemma}
	\label{lem:allthesame}
	For , red items of class  are either all medium or all small.
	If they are medium, they are of the unique type  such that .
\end{lemma}
\begin{proof}
	By Property \ref{prop:redspace}, if for a red item of type  we have
	, then it is a medium item; in this case, 
	type  is the only type such that
	 since each medium type is in a different class by Property \ref{prop:tidelta}
	and for each small item  we have .
\end{proof}

The class of a bin with red items is the class of those red items.
This is well-defined, as each bin contains red items of only one type.

\begin{definition}
	\label{def:6}
	Let  be the minimum class of any unmixed red bin.
Let  be a smallest item in the unmixed red bins of class . If all red items are in mixed bins, we define  (and  is left undefined).
\end{definition}

If , then by this definition we have . 
If , there may be several red items in one bin,
as in {\SuperH} (in {\Hpp}, there is always at most one red item per bin).
Also, there can be several types  such that .
If , there is only one type  such that , and this is a medium type; it is only in this case that we need to consider the item  and in particular its exact size.

We follow Seiden's proof, adapting it to take the marks into account.
In order to define the weight functions, it is convenient to introduce some additional types.
Note that the algorithm does not depend on the weight functions in any way.
It is also unaware of the added type thresholds.
First of all, for each  such that ,
we add a threshold  between  and 
(see Property \ref{prop:type12N}).
For a type  with upper bound  we define
. We furthermore add a threshold  in case
 is medium.
This splits an existing type into two types.
For the new type  with upper bound , we define
, where .
For the new type  with lower bound , we define
.
To maintain consistency with the rest of the paper, 
we add negative indices for the types to maintain .
That is, if there are  values in  in the range ,
the corresponding values  and the threshold  
(if  is medium)
are stored in ascending order in the values , and , .



For large items, the value of  is only used by the algorithm to check whether \emph{small} items can be combined with them.
Moreover, for small items, the only relevant piece of information is that at least  of space is left by large items.
An {\EHarm} algorithm defines  such that  (and then ignores this value when considering to pack a medium item with a large item). The additional types simply make the function  more accurate, in particular with the threshold , which the algorithm does not know.
It can be seen that the definition of  (and ) is not affected by these new types, as only types of large (i.e., blue) items are changed, and  and  are defined based on unmixed red bins.

The weights of an item  will depend on ,
the class of the red and blue items of type  relative to , and the mark of .
This means we essentially define them for every possible input sequence separately.
The value of  and  (and the marks) become clear by running the algorithm.
We do not write the dependence on  explicitly since we have fixed  in this section.

The two weight functions of an item of size , type  and mark  are given by Table \ref{tab:weights}. 
Recall that .
Regarding , non-medium items have no mark  and are handled under the case .
(Unmarked \emph{medium} items were removed in the previous section). 
Note that  does not depend on  or the added types, as  and  for all items larger than . In contrast,  depends on , as the value of  changes at the threshold
 if  is medium as described above.


\begin{table}[h]
	\caption{Weighting functions of class  for an item  of size , type  and mark .}
	\label{tab:weights}
	\centering
	\begin{tabular}{ll|rl}
		\multicolumn{2}{c|} {
			} & 
		\multicolumn{2}{c} {
			}\\
		\hline
		 & if  , 
		&  & if , \\
		& or &&\\
		 & if , 
		&      & if , 		\\
		   & if ,		             
		&                 & if  \\
		    & if , \\
		 & if  &
	\end{tabular}
\end{table}

Note that  counts all blue items, and  counts all red items. By definition of  and Packing Property \ref{pp:allesOK}, we have  for all items with type  such that .
For simplicity, we ignore the markings for any 
type  with , essentially assuming that there are no items of
such types that are marked . It is clear that this assumption can
only increase the weight of any item. 

Define . Note that for any item , we have  since
, and this is the point at which the  function drops below .


\begin{theorem}
	\label{thm:ub-eh}
	For any input  and {\EHarm} algorithm , defining  as above we have
	
\end{theorem}
\begin{proof}
	Our goal is to upper bound  by the weights of the items , which
	are the items in . 
	We will show that the number of bins in the packing  is upper bounded by the first term in 
	(\ref{eq:ub-eh}), with the additive constant  corresponding to the bins removed in post-processing.
	We follow the line of the corresponding proof in Seiden~\cite{Seiden02}.
	
	Let  be the total size of the items of type  in .
	Let  be the number of unmixed red bins in .
	Let  and  be the number of bins in 
	containing blue items of class  and type less than , and red items of class , respectively. 
	Note that this means that mixed bins are counted twice.
	
	If , every red item is placed in a bin with one or more blue items, and . In this case,
	the total number of bins in  is exactly the total number of bins containing blue items.
	Each bin containing items of type  contains at least a total size of 
	due to Packing Property \ref{pp:twoblue}.
	The bins used to pack  are pure blue and . 
For each item  	of type , we have
	. We see that  counts all the bins with blue items, and
	
	(since  does not include bins with items of type ).




	If , then , and there is an unmixed red bin of class .
	By Invariant \ref{inv:unmixed}, all bins with a blue item of class  must be \emph{mixed} bins.
	These are the bins which contain blue items of any type  such that ;
	if  is medium, this means exactly the large items with size at most .
	We conclude
	
	Let  be the number of bins in  containing 
	red items of class  that are not marked .
	If items of class  are not medium, then .
	This is a well-defined condition by Lemma \ref{lem:allthesame}.
	Let  be the number of \emph{unmixed} bins in  containing red items of class .
	Since every red item with class less than  (that is, red items of any type  such that )
	is placed in a mixed bin by definition of , we have
	
	The first inequality holds because the red items marked  are in {mixed} bins by Packing Property \ref{pp:twoblue}.	
	(If  is not medium, , so it also holds.)
	By combining (\ref{eq:1}) and (\ref{eq:2}), we have
So if ,	the total number of bins in  is at most
	
	Let  be the set of types whose blue items are packed in pure blue bins, including type 1 and type . 
	For each item  of type , , we have , 
	so . Furthermore, for all  we have .
	We conclude
	
	
	In the first term of the minimum in (\ref{eq:min}), we count all bins with blue items
	except the pure blue bins, all bins with red items of classes
	above , and the bins with red items of class  that are not marked .
	(If red items of class  are small, this means all red items of this class.)
This term is therefore upper bounded by 
	
In the second term of the minimum in (\ref{eq:min}), we count all bins with red items, as well
	as bins with blue items of class at least 1 and at most .
The second term is therefore  upper bounded by  
	
	As noted above Theorem \ref{thm:ub-eh}, this is at most 
	\qed\end{proof}

\paragraph{Note} In his proof, Seiden~\cite{Seiden02} defines an item  as the smallest red item in an indeterminate red group bin, and proceeds to argue using the class of . This only works because there is one red item in each bin, so there could not be a larger red item of a smaller class that is in an indeterminate group bin. The proof structure above (defining first  and then ) allows {\SuperH} algorithms to pack multiple red items in one bin as well.

Seiden expresses the upper bound as a maximum over , even though for 
a fixed input sequence, the value of  is of course fixed. 
While the resulting expression is correct, we prefer the easier and more direct formulation in Theorem \ref{thm:ub-eh} above.
\iffalse However, this may have been introduced 
to properly cover the case : the inequalities proved for  do not hold if ,
as can be seen for an output consisting mostly of blue items (the first inequality requires that
there are more bins with red items than with blue items in this case, which does not have to hold)
\fi 













\section{The offline solution} \label{sec:offline-solution}
Having derived an upper bound for the total cost of an \EHarm{} algorithm
in Theorem \ref{thm:ub-eh}, in order to calculate the asymptotic competitive
ratio (\ref{eq:apr}), we now need to lower bound the optimal cost of a given input
after post-processing. This will again depend on what the value of  is.
There are two main cases if : { is medium and  is small}.
The case  is much easier, because  for each item ,
so 
upper bounds the cost of  by Theorem \ref{thm:ub-eh}, 
and this sum does not depend on any marks of items.
We can therefore use a standard knapsack search
as in Seiden~\cite{Seiden02} (for this case) and other papers.

For , we will be interested in the weights of items for a fixed value of .
It can be seen that in the range , the function  changes at most once
(viewed as a function of the size of ), namely at the threshold ,
where  drops below  if  is medium.
On the other hand  in the entire range .
For a fixed value of , we therefore reduce the number of types again as follows. 
Recall that , and  is determined by .

\paragraph{Case 1:  is medium}
We set ,  and . We set , 
 such that , and .

\paragraph{Case 2:  is small}
We set  and  as in {\EHarm} itself (Property \ref{prop:type12N}).
We have , and .

\vspace{10pt}
After these changes, Theorem \ref{thm:ub-eh} remains valid for any fixed , as  and  remain
unchanged (given ).
This holds even though if  is medium, the types do not match the types used by {\EHarm};
the important property is that they match the behavior of {\EHarm} for any fixed value of .


We now define patterns for the two main cases.
Intuitively, a pattern describes the contents of a bin in the optimal offline solution. 
If  is medium, a \emph{pattern of class k} is an integer tuple  where  for , 
and

The values  describe how many items of type  are present in the bin.
The value  counts the number of items of type  and mark . 
It can be seen that any feasible packing of a bin can be described by a pattern: the only quantity that is not 
fixed by a pattern is the total size of the items of type , which we will call sand.
However, by (\ref{eq:fits}), there can be at most  of sand in a bin
packed according to pattern . Conversely, for each pattern, a set of items matching the pattern
that fit into a bin can be found by choosing the size of each item close enough (from above) to the
lower bound  for its type; then (\ref{eq:fits}) guarantees the items will fit.

If  is small, we define a pattern of class  as an integer tuple
 where  and (\ref{eq:fits}) holds
using 
(note that the values  and  depend on whether  is medium or small,
but the definition of  is consistent across these two cases).

There are only finitely many patterns for each value of . 
Denote this set by  for .
If  is small or ,  is a fixed set, denoted by .

For a given weight function  of class , 
we define  for some pattern  as the sum of the weights of the non-sand items in it plus
. As noted, 
is an upper bound for the amount of sand in a bin packed according to pattern ; this 
value is not necessarily in the range . If  is medium, .
Pattern  specifies all the information we need to
calculate , as  does not depend on the precise size of non-sand items, and for class 
we know exactly how many items there are (if any) for each mark.

\iffalse 
following terms.
\begin{itemize}
	\item
	For , we have a term  (the mark is irrelevant here:
	either  is medium and then  is the unique type such that ,
	or  is not medium and then items of class  have no mark).
	\item 
	For , if , we have a term , else we have a term
	 (these items are not marked in this case)
	\item 
	For , there is a term  (these items are not marked; the first argument is an upper bound for the volume left for sand. This 
\end{itemize}
\fi 

We can describe the solution of an offline algorithm for a given post-processed input  by a distribution  over
the patterns, where  indicates which fraction of the bins 
in the optimal solution are packed using pattern . 
Theorem \ref{thm:red-alpha} shows that , where  refers to the original input and  refers to the input after post-processing.

To show that \EHarm{} has competitive ratio at most  for an input sequence
 with
{a particular value } , by Theorem \ref{thm:ub-eh} it is sufficient to show that

for all such inputs , using that
 for ,
as  uses an upper bound for the amount of sand but is otherwise exactly the sum of the weights
of the items in it.


As can be seen from this bound, the question now becomes: what is the distribution  (the mix of patterns) that maximizes the minimum in (\ref{eq:compratio})? We begin by deriving some crucial constraints on  for the important case that  is medium.
This is the point where we start using the marks.
The notation  refers to entry  in pattern .
We use  as shorthand for .

We define three important patterns .
For , let  where the second 1 is at position , and
 is the -th three-dimensional unit vector. 
These are the three possible patterns with an item of type  and an item larger than .
By Property \ref{prop:q1unique}, 
no non-sand item can be added to any of these patterns while maintaining .


\begin{lemma}
	\label{lem:q1fv}
	If { is medium},
	then 
\end{lemma}
\begin{proof}
	We ignore additive constants in this proof, as we will divide by 
	 at the end to achieve our result.	
	The pattern  contains an -item that is strictly smaller than
	. 
	We apply Lemma \ref{lem:smallestred1} for  (ignoring the additive constant) to get
	
	and the bound in the lemma follows.
	\qed\end{proof}



\begin{lemma}
	\label{lem:itsblue}
	In , the -item  of type  is blue.
\end{lemma}
\begin{proof}
	{\EHarm} did not pack  alone in a bin as a red item, since it is smaller than .
	But by Packing Property \ref{pp:allesOK},  also was not packed in a mixed bin as a red -item.
\end{proof}

\begin{lemma}
	\label{lem:q2fv}
	If  is medium, then
	 
\end{lemma}
\begin{proof}
	Again, we ignore additive constants.
	There are  bins packed with pattern , meaning that
 	 contains at least  blue -items of type 
	by Lemma \ref{lem:itsblue}. So in the packing , there exist
	at least  bins with two blue -items of type 
	and red items. The red items are red-compatible with those -items.
	That is, each such red item is of a type  such that 
	
	The number of items of type  in  is given by
	.
	By Theorem \ref{thm:red-alpha}, the number of red items of type  is .
We place  red items together in each bin.
	This means that the number of bins in  with red items of type 
	is .
Summing over all types  with , we find that
	
	\qed\end{proof}

\subsection{Linear program}

Maximizing the minimum in (\ref{eq:compratio}) is the same as maximizing the first
term under the condition that it is not larger than the second term---except that
this condition might not be satisfiable, in which case we need to maximize the
second term. For each value of , we will therefore consider two linear programs, and furthermore these linear programs will differ depending on whether  is medium or small, so that in total we get four different LPs which we will call
,,  and  (we will use the notation  () whenever we want to refer to both  and  ( and )). Let 
and let . 
If  is medium,  is the following linear program.

\LPblocktag{}{\label{linprog:lp1}}\begin{minipage}{\linewidth-2cm}
	~
\end{minipage}
 has a very large number of variables
but only four constraints (apart from the nonnegativity constraints).
Constraint (\ref{c1:q1fv}) is based on Lemma \ref{lem:q1fv}, where we have used that
 does not contain any item marked  or , implying . Constraint
(\ref{c1:q2fv}) is based on Lemma \ref{lem:q2fv}, using that  and  do not
contain non-sand items of size less than , so  and  for all  for which
.\footnote{We also have , but we keep the term for  in (\ref{c1:q2fv}) to make the dual easier to write down.} Constraint (\ref{c1:wvfv}) says
simply that the objective function must be at most  (using that  for , which we will prove in Lemma \ref{lem:10}):
if this does not hold, we should be solving the linear program , which has
objective function , instead. The final constraints (\ref{c1:chifv}) 
and (\ref{c1:chi0fv}) say that  is a distribution.

\begin{lemma}
	\label{lem:10}
	.
\end{lemma}
\begin{proof}
	Recall that  contains one -item of type , i.e. the same type as , and one item larger than . Call the -item  and the large one ; note that . We have that , where  is an upper bound for the weight of the sand, and  (the maximum possible amount of sand and hence also its weight is equal in the two cases). As   ( is larger than 1/2 and such items are never red), and  is too large to be combined with , 
	we have . 
	
	For , consider that  and  have the same type, and as the mark of  is , we get .
	For type , we have that  (Property \ref{prop:leaves-needs}). Therefore, .
	This shows that .
	
	The pattern  contains one -item of type  (denoted by ) and one item larger than  (again denoted by ). 
	We have  since the weight  is the same for - and -items of the same class. As above, we find   and 
	.
	This shows  and .
	\qed\end{proof}

For the case {when  is small}, we do not have conditions
(\ref{c1:q1fv}) and (\ref{c1:q2fv}), and
the linear program  looks as follows.
Here we denote the set of patterns simply by  since it is the same for all values of 
for which . In this setting,  do not have a special meaning.

\LPblocktag{}{\label{linprog:lp2}}\begin{minipage}{\linewidth-2cm}
	~
\end{minipage}
\vspace{-20pt}
\paragraph{Intermezzo}
It is useful to consider the value of  (etc.).
We have not discussed the values of the parameters yet. However, as an example, 
for the algorithm {\Hpp}, two of the types are  and  (types 1 and 18).
Let us consider the case where at the end of the input, an item of type
18 is alone in a bin, and no smaller items are alone in bins.
For this case, for {\Hpp}, the two weighting functions for the pattern which contains types 1 and 18 both evaluate to

In other words, a distribution  consisting only of this one pattern immediately gives a lower bound of 1.58879 on the competitive ratio of {\Hpp}. 

Our improved packing of the medium items and our marking of them ensures that this distribution, where the optimal solution uses critical bins exclusively, can no longer be used, since it is not a feasible solution to . This is the key to our improvement over \Hpp.

\subsection{Dual program}
\label{sec:dual}

Our general idea is as follows: We consider the duals of the linear programs given above. These dual LPs have variables  or , respectively. Any feasible solution for the dual (which is a minimization problem) is an upper bound on the competitive ratio of our algorithm by duality and by (\ref{eq:compratio}). We are interested in feasible dual solutions with objective value , where  is our target competitive ratio. 

\paragraph{Case 1:   is small}
The dual of \ref{linprog:lp2} is the following. 

\LPblocktag{}{\label{linprog:dp2}}\begin{minipage}{\linewidth-2cm}
	~
\end{minipage}
If the constraint (\ref{sh:d3fv}) does not hold for pattern  and a given
dual solution , we have

We need to determine if there is a pattern such that (\ref{eq:heavy}) holds.
For , the left hand side of (\ref{eq:heavy}) represents a weighted average of the weights  and .
We add the condition  to .
A feasible solution with objective value  and  exists for  if and only if
a feasible solution with objective value  and  exists for , as (\ref{eq:heavy}) is
now symmetric in  and .
This means that feasibility of  and  with   can be checked at the same time.
Again, note that it is sufficient for our purposes to find a feasible solution.

We define  for each item . 
Since  is small, there are no marked items of type , so  depends only on the type
and size of .
The problem of determining  for a given value of  is a simple knapsack problem, which is straightforward to solve using dynamic programming. 

All that remains to be done is to determine a value for  for given  such that .
{In order to do this, we use a binary search in the interval .}
We start by setting  and compute . If ,  and  have objective value at most  and we are done. Else, the dynamic program returns a pattern  such that . For this pattern , we compare its weights according to  and .
If , we increase , else we decrease it (halving
the size of the interval we are considering).
If after 20 iterations we still have no feasible solution, we return
infeasible. This may be incorrect (it depends on how long we search), 
but our claimed competitive ratio depends only on the correctness of 
\emph{feasible} solutions.

Summarizing the above discussion, if {  is small},
proving that an \EHarm{} algorithm is -competitive can be done by 
running the binary search for  using .
If  is a feasible solution for , then  is a feasible solution for .


\paragraph{Case 2:   is medium}

For the more interesting case {when   is medium}, the dual  of the program  is the following.

\LPblocktag{}{\label{linprog:dp1}}\begin{minipage}{\linewidth-2cm}
	~
\end{minipage}


{Again we restrict ourselves to solutions with .}
If the value , the conditions (\ref{c:d1fv}) and (\ref{c:d2fv}) are automatically satisfied by (\ref{c:d4fv}). In this case we can set  and . In effect, this reduces  to \ref{linprog:dp2}, for which we already know how to {find a feasible value for }. We therefore ignore the entire marking done by the algorithm and set the weight for each item to be the weight for the case that its mark is not . Then weights again do not depend on marks and we apply the method from Case 1. 


Let us now consider the case 
 For given  we need to determine if  and  are feasible; this requires finding suitable values for  and . If a solution vector  is feasible for  (or ), 
, and constraint (\ref{c:d1fv}) or (\ref{c:d2fv}) is not tight, then we can decrease  and/or  and still have a feasible solution.
We therefore restrict our search to
solutions for which (\ref{c:d1fv}) and (\ref{c:d2fv}) are tight, and .
Then 


This means that given , we know the values of  and . 
We can therefore prove  is a feasible objective value for  {by giving -values that make the linear program feasible.} 
If constraint (\ref{c:d3fv}) does not hold for pattern  () and a given dual solution , we have the
following by some simple rewriting:

If this holds for some pattern  that contains an -item, then it obviously also holds 
if we replace that -item by an -item of the same type.
This gives a pattern with the same values  and  but a higher value for .
It is therefore sufficient to check the patterns with -items.
The only exception to this is if replacing the -item by an -item would give pattern , which does have weight
larger than  and therefore violates (\ref{eq:y3}) (but constraint (\ref{c:d3fv}) does not involve pattern ).
We therefore check pattern  separately.

We have , 
,
,  for all .
Hence the left hand side of (\ref{eq:y3}) is at most  for , and 
using Property \ref{prop:q1unique}.
All our solutions will satisfy these constraints and thus we can ignore -items in the knapsack problem.
(For completeness, we check pattern  separately in our program.)



We define a new weighting function  for the items as given in Table \ref{tab:weights_knapsack},
which depends only on types and sizes (and not on marks).


\begin{table}[h]
	\caption{Weighting function .}
	\label{tab:weights_knapsack}
	\centering
	\begin{tabular}{l|l}
		 & \\
		\hline
		 &
		\\
		 & 
		
		\\
		else & 
	\end{tabular}
\end{table}



In order to prove that an \EHarm{} algorithm is -competitive if {  is medium} and ,
it is sufficient to verify that there exists a value
 such that . {Values for  that satisfy this can again be found in Appendix \ref{sec:sh-all-params}. Finding these values was done again }
by a binary search for each value of  for which , each time setting  and using (\ref{eq:y1}) and (\ref{eq:y2}). 


\paragraph{Summary}
{
	Overall, our approach is as follows: We first fix a target competitive ratio . We do the following for every value of  Consider the value for  (for our algorithm \SonofH{}, these values are specified in Table \ref{tab:sonofharm-y3}). If   is small, we check that \ref{linprog:dp2} is feasible for  and this . If   is medium, we compute  and check whether  or . In the latter case, we again check that \ref{linprog:dp2} is feasible for  and the given value of . In the former case, we check that \ref{linprog:dp1} is feasible for  and the given value of .} Finally, for , it is sufficient to count blue bins, and we solve a single knapsack problem based on  alone, {checking that the heaviest pattern is not heavier than .
}



\subsection{Solving the knapsack problems}\label{sec:implementation-knapsack}

In order to prove our competitive ratio , we prove feasibility of the discussed dual linear programs, which amounts to solving knapsack problems and comparing the maximum weight of a pattern to our target competitive ratio. We will now describe how our implementation of this knapsack solving works, given a set of item types as described at the beginning of Section \ref{sec:offline-solution} and a corresponding weight function  (one weight per type).

We use two main heuristics to speed up the computation.
First, for each type , we define the expansion  of type  as the weight according to function  divided by . Now we sort the types in decreasing order of expansion; call this permutation of types .
When constructing a pattern with high weight, we try to add items in the order of this permutation. Note that  will not contain types that have expansion below that of sand: Such types will not be part of a maximum weight pattern, as the pattern with sand instead of these items has no smaller weight.

Second, we use branch and bound. We use a variable  that will store the maximum weight of a pattern found so far,
and give this the initial value . Whenever the current pattern cannot be extended to a pattern with weight more than
 (based on the expansion of the next item in the ordering  that still fits), we stop the calculation for
this branch. Initializing  with a value close to  immediately eliminates many patterns.

The process works as follows.
We start with type  (i.e., the type with the largest expansion) and an empty pattern.
For current type  and current pattern  that contains items of total size  and total weight  (counting only the non-sand items in the calculation of the weight), we compute an upper bound on the weight that this pattern  can at most get by adding items of types , as follows. We find the first type  in this order that still fits with the items of  and compute . This is an upper bound for the weight of any bin which contains the items from . If this upper bound is already smaller than , we immediately cancel the further exploration of this pattern .

Otherwise, if we have no more types to add (i.e. we reached the end of list of types in ), set  to the weight of  (now including the sand) and store  as the heaviest pattern so far. If we still have more types to explore, find out how many items of the next type can fit maximally into ; call this number  (if adding an item of the next type would create pattern  or  and we are considering the dual program , we set  as we do not need to consider these patterns). Now recursively call this procedure with type  and patterns  where  is obtained from  by adding  items of type .

The heuristics described in this section are still not enough to be able to examine all possible patterns in reasonable time. We explain in the next section how to reduce the set of patterns further (by reducing the number of small types) and how to ensure that larger items are more important than smaller items (by making sure the expansion of small items is monotonically nondecreasing in the size, that is, larger (but still small) items do not have smaller expansions than smaller items).

\section{The algorithm \SonofH}

For our algorithm {\SonofH} we have set initial values as follows.
The right part of Table \ref{tab:sonofharm} below contains item sizes and corresponding 
values that were set manually.
Some numbers of the form  until the value  are added automatically
by our program if they are not listed below (see below for details on how these are selected).

\begin{table}[h]
	\caption{Parameters and item types used for \SonofH{}.}
	\label{tab:sonofharm}
	\centering
	\subfloat[Parameters]{
		\begin{tabular}{|r|l|}\hline
			Parameter & Value\\ \hline
			 & \\
			 & \\
			 &  (starting from )\\
			 & \\\hline
		\end{tabular}
	}
	\subfloat[Size lower bounds and values ]{
		\begin{tabular}{|r|l|}\hline
			Item size & \\ \hline
			33345/100000 & 0\\
			33340/100000&0\\
			33336/100000&0\\
			33334/100000&0\\
			5/18&2/100\\
			7/27&105/1000\\
			1/4&1061/10000\\
			\hline
		\end{tabular}
		\begin{tabular}{|r|l|}\hline
			Item size & \\ \hline
			8/39&8/100\\
			1/5&93/1000\\ 
			3/17&3/100\\
			1/6&8/100\\
			3/20&0\\
			29/200&0\\
			1/7&16/100\\ 
			\hline
		\end{tabular}
	}
\end{table}

The remaining values  are set automatically  
using heuristics designed to speed up the search and minimize the
resulting upper bound. In the range , we automatically
generate item sizes (with corresponding values  and ) that are less than  apart to ensure uniqueness of 
and : no non-sand item can be packed into any bin of pattern  or . 
The value  specifies an upper bound on how much room is used by
red items of size at most ; larger items () use at most  room.
Since we have this bound , we also add size thresholds of the form  for , to ensure that items just below this threshold can be packed without leaving much space unused.

The last parameter is some item size .
Above this size, 
we generate all item sizes of the form  for . 
Below this size, we skip some item sizes as described below.


Our program uses an exact representation of fractions, with numerators and denominators of potentially unbounded size, in order to avoid rounding errors. 
The source code and the full list of all types and parameters as determined by the program can be found at  \url{https://sheydrich.github.io/ExtremeHarmonic/}. 
In Appendix \ref{sec:sh-all-params}, we provide an alternative set of parameters, which give a competitive ratio of 1.583 with a much smaller set of knapsack problems to check.

Additionally, in Table \ref{tab:sonofharm-y3} we provide the -values that certify the competitive ratio of our algorithm. Note that only two different values for  were used.

\begin{table}[h]
	\caption{-values used to certify that \SonofH{} is -competitive.}
	\label{tab:sonofharm-y3}
	\centering
		\begin{tabular}{|r|l||r|l|}\hline
			 & range of  &  & range of  \\\hline
			 &  &  & \\
			&  && \\
			&  && \\\hline
\end{tabular}
\end{table}




\paragraph{Automatic generation of item sizes}\label{sec:automatic-size-generation}
We start by generating all item sizes of the form  for  between 2 and  (if they are not already present in the parameter file). After that, we generate types above  in steps of size . By choosing this step size, we make sure that no non-sand items can be added to the patterns . 
The value  for such a type  is chosen such that the pattern containing an item  of type  and a large item  of type  (i.e., ) has as weight exactly our target competitive ratio if .
That is, we consider the weighting function . We have , , and an upper bound for the amount of sand that fits with these items is 
. Therefore,  is defined as the solution of the equation

as long as this value is positive. We stop generating types as soon as it becomes negative.
To be precise, our highest value  is defined by taking  in (\ref{eq:calcred}).

We have now generated all item sizes above . 
We generate large types as described in Section \ref{sec:implementation-knapsack}.
In the range , we do not generate all  types, but we skip some (to speed up the knapsack search) if this can be done without a deterioriation in the competitive ratio. We do this by considering the expansion of such items, that is, the weight divided by the infimum size. We will ensure that the expansion of smaller items is smaller than that of larger items, so that they are irrelevant (or less relevant) for the knapsack problem.

Let us consider how we test whether a certain type  is required (where  is the next larger type, i.e. either the last type generated before we started this last phase or the last type generated in this phase), and which  we should choose. Denote by  the value we want to check. We compute a lower and upper bound  for the -value of this type as follows: We can compute  and  only depending on the upper bound of the size of items of this type, i.e. depending on , the lower bound of the next larger item size. First, we require , which gives . Second, we want to make sure that the maximum expansion of the current type is not larger than the expansion of the previous (next larger) type (since that might slow down the search), : . If , we continue to test ; if not, we know that the \textit{previously tested} type is necessary to ensure the two constraints. Hence, we add this previous type to the list of types, together with the value  computed in the previous iteration.

\paragraph{Computation of -values}
The -values are completely auto-generated, in contrast to Seiden's paper, where these values are given by hand. For every type  such that ,  is added as a -value and for every type  such that ,  is added as a -value.
Additionally, we make sure that for each medium type we have a -value equal to  and one equal to  where  is the lower bound of the size of items of this type.

After computing the functions  and , we then eliminate -values that are unused and less than , i.e., if there is no pair of types
 such that , then  is removed from the
list. This reduces the number of knapsack problems that need to be solved.

\paragraph{Computation and adjustment of values }
\label{sec:alpha-computation}

For each item type  that has size at most  and at least , 
we adjust the value  such that 

where  if  and  and  otherwise.
To be precise, we set . The reason for this is that it ensures that the
``small expansion'' of these items, where we count only the blue items of this type, is at least .
This is a heuristic; it does not seem to help to make  larger than this.

\section{Super Harmonic revisited}
\label{sec:sh}



Seiden used the following weighting functions, but presented them in a different way.
Define  and  as in Definition \ref{def:6}.
The two weight functions of an item of type  are given by Table \ref{tab:weights_seiden}.

\begin{table}[h]
	\caption{Weighting functions used by Seiden for \SuperH{}.}
	\label{tab:weights_seiden}
	\centering
	\begin{tabular}{ll|rl}
		\multicolumn{2}{c|} {
			} & 
		\multicolumn{2}{c} {
			}\\
		\hline
		 & if
		 or 
		&  & if
		\\
		 & if
		
		&  & if
		\\
	\end{tabular}
\end{table}

Using these weight functions, he shows that (\ref{eq:compratio}) with  holds for
\SuperH{} algorithms. Instead of the mathematical program that Seiden considers,
we use  and its dual .
We use the method described in Section \ref{sec:dual} (a binary search for a weighted average of weights)
to check for feasibility of the dual linear programs for all values of , including the cases where {  is medium}.
This is a significantly easier method than the one Seiden used, since it is based on solving standard knapsack problems.

A small modification of our computer program can be used to verify Seiden's result. Surprisingly, it shows that {\Hpp} is in fact \superhratio-competitive. In contrast to Seiden's heuristic program, which took 36 hours to prove {\Hpp}'s competitive ratio, our program terminates in a few seconds. Of course, this was over fifteen years ago, but we believe the algorithmic improvement explains a significant part of the speedup.
The fast running time of our approach also allowed us to improve upon {\Hpp} within the {\SuperH} framework (at least as long as we allow multiple red items per bin): Using improved  values, we can show a \newsuperhratio-competitive {\SuperH}-algorithm. Our values are also simpler than the ones Seiden used (which were optimized up to precision ); they can be found in the appendix.

\section{Lower bound}
We prove a lower bound for any \EHarm{} algorithm.
We will consider inputs consisting of essentially four different item sizes: , , , and  (we also speak of types 1 through 4). Here  is a very small number. However, there will be many different item sizes in the range
.
The value of  is chosen small enough that the algorithm puts all these sizes in the same type.
Note that the algorithm has not much choice about how many red items of types 2 and 3 can be packed in one bin: only one such item can be packed, else larger blue items could not be added anymore. For type 4, between 1 and 3 red items could be packed in one bin, and we will give lower bound constructions for each of these three cases.

Consider the case that the algorithm packs red type 4 items pairwise into bins. In Table \ref{tab:lb_redfit2}, we give four different inputs that together will prove a lower bound of \finallb{} for this case. A pattern  denotes a set of items containing  items of type 1,  items of type 2 and so on. 
Note that our types defined here do not necessarily correspond to size thresholds used by the algorithm; nevertheless, each item gets a single type assigned by the algorithm, and if we use notation such as  for type  as defined here, we mean the -value of the item type the algorithm assigns to such an item.
The other two columns of the table are explained below.

\begin{table}[t]
	\caption{Inputs for lower bound  in case .}
	\label{tab:lb_redfit2}
	\centering
	\subfloat{
		\begin{tabular}{ccc}
			Pattern & Space for  & Distribution \\ \hline
			 &  & \\
			\hline
			 &  & \\
			\hline
			 &  & \\
			\hline
			 & 
			&  (scaled) \\
			 &  & \\
			 &  & \\
		\end{tabular}
	}
\end{table}

The first three lines of the table represent three different inputs to the algorithm, and the last three lines together represent the final input used in the lower bound.
We construct the first three inputs as follows. For each pattern in the table, 
items arrive in order from small to large. Each item in the pattern arrives  times. In addition, we get  times some amount of sand per bin, that fills up the bin completely. 
Based on each pattern and the values  and , we can calculate exactly how much space (represented as fractions of bins) the online algorithm needs to pack each item in the pattern \emph{on average}. 
To do this, we assume that if red small items can be packed with larger 
blue ones, the algorithm will always do this (this is a worst-case assumption).
The result of this calculation is shown in the column Space.



To illustrate this approach, let us consider an input based on the pattern  in the manner described above. As we assumed that , we know that items of types  and  will not be 
combined by the algorithm, as . Thus, the algorithm will not be able to combine the red items 
of both types with any other items. 
The number of bins used for blue type  items is at least , 
the number of bins for red type  items is at least . 
Analogously, we need at least  bins for blue type  items and at least 
 bins for red type  items. Finally, sand of total volume arbitrarily close to  
arrives, which is packed in at least as many bins by the online algorithm. 
Thus, on average the items in this pattern need  bins to be packed.
The space needed for the second and third patterns can be calculated in the same way. 


\begin{figure}[h]
	\includegraphics[width=\textwidth]{image12}
	\caption{Fourth input for our lower bound construction. The three patterns used in the optimal solution are depicted on the left. The shaded area in the first pattern denotes sand. The algorithm produces the five types of bins depicted on the right, plus bins that only contain sand (not depicted here).}
	\label{fig:lower-bound}
\end{figure}

The fourth input (based on pattern (0,2,1,0)) requires more explanation; see also Fig. \ref{fig:lower-bound}.
For this input, we consider a combination of three patterns that arrive in the distribution given in the last column of the table.
Items of type 2 have size  (according to the
table above) and some of them end up
alone in bins. We extend the input in this case by a number of items of size
almost , where this number is 
calculated as explained below.
All these large items will be placed in new bins by the online algorithm.
In order for this to hold, the items of type 2 must have slightly different
sizes - not all exactly .
We therefore pick  small enough so that the interval
 is contained in a single type according to the classification
done by the algorithm. The first item of this type
will have size . The sizes of later items depend on how it is packed:
\begin{itemize}
	\item If the item is packed in a new bin, all future items
	will be smaller (in the interval )
	\item If the item is packed into a bin with an existing item of type 2 or 3,
	all future items will be larger (in the interval )
\end{itemize}
We use the same method for all later items of the same type, each time dividing the
remaining interval in two equal halves. 
By induction, it follows that whenever an item is placed in a new bin,
all previous items that were packed first into their bins are larger, and
all previous items that were packed into existing bins are smaller.
Therefore,
after all items of this type have arrived, let  be the size of the last item
that was placed into a new bin. 
(Since the algorithm maintains a fixed fraction of red items of type 2,
there can be only constantly many items that arrived after this item; we ignore such
items.)
We have the following.
\begin{itemize}
	\item All items of size more than  are packed either alone into bins or are the first item in a bin with two medium but no small red items; and 
	\item All items of size less than  are in bins with items of type 3 or were
	packed as the second item of their type in an existing bin.
\end{itemize}
We now let items of size exactly  arrive. 
For every bin with red type 3 items and blue type 2 items, two such items arrive, which will be packed in -bins.
Assume that we have  bins with pattern , then we create exactly  such bins, i.e., we let  large items arrive for these.
For every bin with a pair of blue medium items but no red items, one such  item arrives.
The number of these bins is harder to calculate. Let  be the total number of medium items in the input. 
Then the number of such bins is . Now, we want to express  in terms of : Observe that  is half the number of medium items larger than  (as only these end up in -bins). The number of those items is equal to the number of bins with red medium items (which is ) plus the number of bins with two blue medium but no red items (which is ). Thus,  is equal to . This shows that . Finally, we conclude that we can send   many large items and thus get this many -bins. 

To pack  copies of a given pattern, the online algorithm needs 
times the space calculated in Table \ref{tab:lb_redfit2}, while the optimal solution needs exactly  bins. 
In order to calculate the final lower bound, for each of the four inputs, we simply calculate the space of the pattern(s), in the last case the weighted (in proportion to the distribution) sum of the three patterns' spaces. All four cases yield a lower bound of at least {\finallb}, which is achieved if .
Whenever an algorithm has a smaller or larger value for some  value, the space needed by one of the patterns (or the weighted sum of the spaces needed by the three patterns of the last case) increases and thus gives a lower bound above \finallb{}.

Constructions for the other two cases  and  can be found below in Tables \ref{tab:lb_redfit3} and \ref{tab:lb_redfit1}.
The analysis is completely analogous to the first case.
For the case , the best values the online algorithm can use are .
The analysis for the case  is particularly simple, as the given distribution requires
 bins on average (independent of  and ), implying a lower bound of .

\begin{table}[h]
	\caption{Inputs for lower bound  in case .}
	\label{tab:lb_redfit1}
	\centering
	\subfloat{
		\begin{tabular}{ccc}
			Pattern & Space for  & Distribution \\
			\hline 
			 &  & \\
			\hline
			 &  & \\
			\hline
			 & 
			&  (scaled) \\
			 &  & \\
			 &  & 
		\end{tabular}
	}
\end{table}
\vspace{-20pt}
\begin{table}[h]
	\caption{Inputs for lower bound  in case .}
	\label{tab:lb_redfit3}
	\centering
	\subfloat{
		\begin{tabular}{ccc}
			Pattern & Space for  & Distribution \\
			\hline 
			 &  & \\
			 &  & 
		\end{tabular}
	}
\end{table}

\vspace{-30pt}
\paragraph{Acknowledgements}
	We thank the anonymous referees for their useful comments, and Leah Epstein
	for interesting discussions.












\bibliographystyle{plain}
\bibliography{bibliography}

\appendix

\section{Alternative parameters for a competitive ratio of 1.583}\label{sec:sh-all-params}


\begin{table}\centering
	\subfloat[Parameters]{
		\begin{tabular}{|r|l|}\hline
			Parameter & Value\\ \hline
			 & \\
			 & \\
			 &  (starting from )\\
			 & \\\hline
		\end{tabular}
	}
	\subfloat[Size lower bounds and initial values ]{
		\begin{tabular}{|r|l|}\hline
			Item size & \\ \hline
			335/1000 & 0\\
			334/1000&0\\
			5/18&2/100\\
			7/27&105/1000\\
			1/4&106/1000\\
			8/39&8/100\\
			1/5&93/1000\\ \hline
		\end{tabular}
		\begin{tabular}{|r|l|}\hline
			Item size & \\ \hline
			3/17&3/100\\
			1/6&8/100\\
			3/20&0\\
			29/200&0\\
			1/7&135/1000\\
			1/13&1/10\\
			1/14&1/13 \\ \hline
		\end{tabular}
	}
	\caption{Parameters and item types.}
\label{tab:sonofharm2}
\end{table}

We give a list of item types together with their parameters in Table \ref{tab:sonofh_all_parameters}. 
Please note that type 2 is only defined for the definition of the knapsack problem in case {  is medium}.
{\EHarm} algorithms, in contrast to {\SuperH} algorithms, treat all items larger than  as a single type
(thus it sees types 1 and 2 as a single type).
Between type 6 and type 12, the values  are  apart. Between type 39 and type 101, the types are of the form  for some values  (below , we skip some values). The values  for these types are computed as described in Sections \ref{sec:automatic-size-generation}. The paramters are auto-generated from the input in Table \ref{tab:sonofharm2}.

We give a list of all -values that are at most  in Table \ref{tab:sh-deltas}. The -values above  are equal to the -values above .
\begin{table}
	\centering
\begin{tabular}{|c|c||c|c||c|c|}\hline
	index  &  & index  &  & index  &  \\ \hline
	 &  &  &  &  &  \\ \hline
	 &  &  &  &  &  \\ \hline
	 &  &  &  &  &  \\ \hline
	 &  &  &  &  &  \\ \hline
\end{tabular}
	\caption{-values below  in the 1.583-competitive algorithm.\label{tab:sh-deltas}}
\end{table}
Finally, there were only two different -values used to establish the feasibility of the dual LPs:  for the cases  and  in all other cases.

{\small
	\newpage
	\begin{longtable}{|c|c|c|c|c|c|c|}
		\hline
		Type  &  &  &  &  &  &  \\ 
		\hline \endhead 
		 &  &  &  &  &  &  \\ 
		\hline
		 &  &  &  &  &  &  \\  \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\  \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\  \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  & \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\ \hline
		 &  &  &  &  &  &  \\ \hline
		 &  &  &  &  &  &  \\ \hline
		\caption{Parameters used by 1.583-algorithm. The values  to  are in .}
		\label{tab:sonofh_all_parameters}
	\end{longtable}
}


\section{Parameters for an improved {\SuperH} algorithm}

With the parameters listed below in Table \ref{tab:improved_superh}, using the same item types used by Seiden, we are able to achieve a {\SuperH} algorithm (with more than one red item per bin) with competitive ratio \newsuperhratio.

Note that the -values are computed differently than in \Hpp{}. For types  such that  or , we have . Otherwise, we have . The value  in this expression is related to the item threshold . By using this bound, two items of size slightly larger than  can be packed together in one bin.

\iffalse 
\begin{table}[h]
	\caption{Redspace values used for our improvement of \Hpp{}.}
	\label{tab:improved_superh_2}
	\centering
	\subfloat{
	\begin{tabular}{|c|c|c|c|c|c|c|c|}
		\hline 
		 &  &  &  &  &  &  & \\
		\hline 
		1 & 6 / 83 &  6 & 1 / 4   & 11 & 127 / 384 & 16 & 65 / 192\\
		2 & 11 / 83 & 7 & 7 / 24  & 12 & 85 / 256  & 17 & 11 / 32\\
		3 & 13 / 88 & 8 & 5 / 16  & 13 & 171 / 512 & 18 & 17 / 48\\
		4 & 1 / 6 &   9 & 31 / 96 & 14 & 257 / 768 & 19 &  3 / 8\\
 		5 & 11 / 63 &10 & 21 / 64 & 15 & 43 / 128  & 20 &  5 / 12\\ \hline 
	\end{tabular}
	}
\end{table}
\fi 
\begin{table}[h]
\caption{Parameters used for our improvement of \Hpp{}.}
	\label{tab:improved_superh}
	\centering
	\subfloat{
		\begin{tabular}{|c|c|c|c|}
			\hline 
			 &  &  &  \\ 
			\hline 
			1 &  & 0 & 0 \\ 
			\hline 
			2 &  & 0 & 0 \\ 
			\hline 
			3 &  & 0 & 0 \\ 
			\hline 
			4 &  & 0 & 0 \\ 
			\hline 
			5 &  & 0 & 0 \\ 
			\hline 
			6 &  & 0 & 0 \\ 
			\hline 
			7 &  & 0 & 0 \\ 
			\hline 
			8 &  & 0 & 0 \\ 
			\hline 
			9 &  & 0 & 0 \\ 
			\hline 
			10 &  & 0 & 0 \\ 
			\hline 
			11 & &  & 1 \\ 
			\hline 
			12 &  &  & 1 \\ 
			\hline 
			13 &  &  & 1 \\ 
			\hline 
			14 &  &  & 1 \\ 
			\hline 
			15 &  &  & 1 \\ 
			\hline 
			16 &  &  & 1 \\ 
			\hline 
			17 &  &  & 1 \\ 
			\hline 
			18 &  &  & 1 \\ 
			\hline 
			19 &  & 0 & 0\\ 
			\hline 
			20 &  &  & 1 \\ 
			\hline 
			21 &  &  & 1 \\ 
			\hline 
		\end{tabular}
	}
	\subfloat{
		\begin{tabular}{|c|c|c|c|}
			\hline 
			 &  &  &  \\ 
			\hline 
			22 &  &  & 1 \\ 
			\hline 
			23 &  &  & 1 \\ 
			\hline 
			24 &  &  & 1 \\ 
			\hline 
			25 &  &  & 1 \\ 
			\hline 
			26 &  &  & 2 \\ 
			\hline 
			27 &  &  & 2 \\ 
			\hline 
			28 &  &  & 2 \\ 
			\hline 
			29 &  &  & 2 \\ 
			\hline 
			30 &  &  & 2 \\ 
			\hline 
			31 &  &  & 2 \\ 
			\hline 
			32 &  &  & 3 \\ 
			\hline 
			33 &  &  & 3 \\ 
			\hline 
			34 &  &  & 3 \\ 
			\hline 
			35 &  &  & 4 \\ 
			\hline 
			36 &  &  & 4 \\ 
			\hline 
			37 &  &  & 4 \\ 
			\hline 
			38 &  &  & 4 \\ 
			\hline 
			39 &  &  & 0 \\ 
			\hline 
			\vdots & \vdots & \vdots & \vdots \\ 
			\hline
			70 &  & 0 & 0 \\
			\hline 
		\end{tabular}
	}
\end{table} 



\end{document}
