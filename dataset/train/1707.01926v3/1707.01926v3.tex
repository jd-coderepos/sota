We conduct experiments on two real-world large-scale datasets: (1) \textbf{METR-LA} This traffic dataset contains traffic information collected from loop detectors in the highway of Los Angeles County~\citep{Jagadish2014}.  We select 207 sensors and collect 4 months of data ranging from Mar 1st 2012 to Jun 30th 2012 for the experiment.
(2) \textbf{PEMS-BAY} This traffic dataset is collected by California Transportation Agencies (CalTrans) Performance Measurement System (PeMS). 
We select 325 sensors in the Bay Area and collect 6 months of data ranging from Jan 1st 2017 to May 31th 2017 for the experiment.
The sensor distributions of both datasets are visualized in~ Figure~\ref{fig:sensor_distribution} in the Appendix. 

In both of those datasets, we aggregate traffic speed readings into 5 minutes windows, and apply Z-Score normalization. 70\% of data is used for training, 20\% are used for testing while the remaining 10\% for validation. 
To construct the sensor graph, we compute the pairwise road network distances between sensors and build the adjacency matrix using thresholded Gaussian kernel~\citep{shuman2013emerging}. 

where  represents the edge weight between sensor  and sensor ,  denotes the road network distance from sensor  to sensor .  is the standard deviation of distances and  is the threshold.
\vspace{-0.15in}
\subsection{Experimental Settings}
\vspace{-0.1in}
\paragraph{Baselines}

\begin{table}[tbp]
\centering
\caption{Performance comparison of different approaches for traffic speed forecasting. \gcrnn{} achieves the best performance with all three metrics for all forecasting horizons, and the advantage becomes more evident with the increase of the forecasting horizon.}
\label{tab:la_comparison}
\resizebox{\columnwidth}{!}{
\begin{tabular}{c||c|c|cccccccc}

\toprule
&  & Metric & HA     & ARIMA  & VAR    & SVR    & FNN    & FC-LSTM  & \emph{\gcrnn{}}  \\ \hline
\midrule
\multirow{9}{*}{\rotatebox[origin=c]{90}{METR-LA}}&\multirow{3}{*}{15 min}& MAE  & 4.16       & 3.99   & 4.42   & 3.99   &  3.99  &  3.44 &  \bestval{2.77}  \\ 
& & RMSE & 7.80      & 8.21  & 7.89   & 8.45   &  7.94   & 6.30  &  \bestval{5.38}   \\ 
& & MAPE & 13.0\%  & 9.6\% & 10.2\% & 9.3\% &9.9\% & 9.6\%  & \bestval{7.3}\% \\ 
\cline{2-10}
& \multirow{3}{*}{30 min}& MAE  & 4.16     & 5.15   & 5.41   & 5.05   &4.23& 3.77 & \bestval{3.15}  \\ 
& & RMSE & 7.80     & 10.45   & 9.13   & 10.87   & 8.17   & 7.23    & \bestval{6.45}   \\ 
& & MAPE & 13.0\%  & 12.7\% & 12.7\% & 12.1\% & 12.9\% & 10.9\% &  \bestval{8.8}\% \\ 
\cline{2-10}
& \multirow{3}{*}{1 hour}& MAE  & 4.16    &  6.90  &  6.52 &  6.72  &   4.49 &  4.37 & \bestval{3.60}   \\ 
& & RMSE & 7.80     &  13.23  & 10.11  &  13.76  &  8.69  &  8.69  &  \bestval{7.59}   \\ 
& & MAPE & 13.0\%  &  17.4\% & 15.8\% & 16.7\%   &  14.0\%  &  13.2\% &   \bestval{10.5\%}   \\ 
\midrule
\midrule
\multirow{9}{*}{\rotatebox[origin=c]{90}{PEMS-BAY}}&\multirow{3}{*}{15 min}
& MAE  & 2.88   & 1.62   & 1.74   & 1.85   &  2.20  &  2.05 &  \bestval{1.38}  \\ 
& & RMSE & 5.59 & 3.30  & 3.16   &  3.59  &   4.42  &  4.19 &  \bestval{2.95}   \\ 
& & MAPE & 6.8\%  & 3.5\% & 3.6\% & 3.8\% & 5.19\% & 4.8\%  & \bestval{2.9}\% \\ 
\cline{2-10}
& \multirow{3}{*}{30 min}
  & MAE  & 2.88     & 2.33   & 2.32   & 2.48  &  2.30 & 2.20 & \bestval{1.74}  \\ 
& & RMSE & 5.59     & 4.76   & 4.25   &  5.18  &  4.63 &  4.55 & \bestval{3.97}   \\ 
& & MAPE & 6.8\%  & 5.4\% & 5.0\% & 5.5\% & 5.43\% & 5.2\% &  \bestval{3.9}\% \\ 
\cline{2-10}
& \multirow{3}{*}{1 hour}
  & MAE  & 2.88  & 3.38  &  2.93 & 3.28  &  2.46 & 2.37 & \bestval{2.07}   \\ 
& & RMSE & 5.59  & 6.50  & 5.44  & 7.08  &   4.98 &  4.96 & \bestval{4.74}   \\ 
& & MAPE & 6.8\%  & 8.3\% & 6.5\% & 8.0\%   &  5.89\%  &  5.7\% &   \bestval{4.9\%}   \\ 

\bottomrule

\end{tabular}
}
\end{table}

We compare \gcrnn{}\footnote{The source code is available at \url{https://github.com/liyaguang/DCRNN}.} with widely used time series regression models, including
(1) HA: Historical Average, which models the traffic flow as a seasonal process, and uses weighted average of previous seasons as the prediction;
(2) ARIMA: Auto-Regressive Integrated Moving Average model with Kalman filter which is widely used in time series prediction; 
(3) VAR: Vector Auto-Regression~\citep{hamilton1994time}.
(4) SVR: Support Vector Regression which uses linear support vector machine for the regression task; 
The following deep neural network based approaches are also included:
(5) Feed forward Neural network (FNN): Feed forward neural network with two hidden layers and L2 regularization.
(6) Recurrent Neural Network with fully connected LSTM hidden units (FC-LSTM)~\citep{sutskever2014sequence}.

All neural network based approaches are implemented using Tensorflow~\citep{abadi2016tensorflow}, and trained using the Adam optimizer with learning rate annealing.
The best hyperparameters are chosen using the Tree-structured Parzen Estimator (TPE)~\citep{bergstra2011algorithms} on the validation dataset. 
Detailed parameter settings for \gcrnn{} as well as baselines are available in Appendix~\ref{sec:detailed_exp_settings}.


\vspace{-0.1in}
\subsection{Traffic Forecasting Performance Comparison}
Table~\ref{tab:la_comparison} shows the comparison of different approaches for 15 minutes, 30 minutes and 1 hour ahead forecasting on both datasets.
These methods are evaluated based on three commonly used metrics in traffic forecasting, including
(1)  Mean Absolute Error (MAE), (2) Mean Absolute Percentage Error (MAPE),  and (3) Root Mean Squared Error (RMSE).
Missing values are excluded in calculating these metrics. Detailed formulations of these metrics are provided in Appendix~\ref{sec:metrics}.
We observe the following phenomenon in both of these datasets.
(1) RNN-based methods, including FC-LSTM and \gcrnn{}, generally outperform other baselines which emphasizes the importance of modeling the temporal dependency.  
(2) \gcrnn{} achieves the best performance regarding all the metrics for all forecasting horizons, which suggests the effectiveness of spatiotemporal dependency modeling.
(3) Deep neural network based methods including FNN, FC-LSTM and \gcrnn{}, tend to have better performance than linear baselines for long-term forecasting, e.g., 1 hour ahead.  This is because the temporal dependency becomes increasingly non-linear with the growth of the horizon. 
Besides, as the historical average method does not depend on short-term data, its performance is invariant to the small increases in the forecasting horizon.

Note that, traffic forecasting on the METR-LA (Los Angeles, which is known for its complicated traffic conditions) dataset is more challenging than that in the PEMS-BAY (Bay Area) dataset.
Thus we use METR-LA as the default dataset for following experiments.


\vspace{-0.1in}
\subsection{Effect of spatial dependency modeling}
\vspace{-0.1in}
\begin{figure*}[tp]
    \centering
	\begin{minipage}{.48\textwidth}
	\centering
\includegraphics[width=0.9\linewidth]{figures/spatial_dependency}
	\caption{Learning curve for \gcrnn{} and \gcrnn{} without diffusion convolution. Removing diffusion convolution results in much higher validation error. Moreover, \gcrnn{} with bi-directional random walk achieves the lowest validation error.}
	\label{fig:spatial_dependency}
	\end{minipage}
\hspace{0.01\textwidth}
	\begin{minipage}{.48\textwidth}
	\centering
    \includegraphics[width=0.9\linewidth]{figures/k_unit_effect.pdf}
	\caption{Effects of K and the number of units in each layer of \gcrnn{}. K corresponds to the reception field width of the filter, and the number of units corresponds to the number of filters.}
	\label{fig:k_effect}
	\end{minipage} 
\end{figure*}


\begin{table}[tp]
\centering
\caption{Performance comparison for \gcrnn{} and GCRNN on the METRA-LA dataset.}
\label{tab:dcrnn_vs_gcrnn}
\resizebox{0.85\columnwidth}{!}{
\begin{tabular}{c|ccc|ccc|ccc}
\toprule
      & \multicolumn{3}{c}{15 min} & \multicolumn{3}{c}{30 min} & \multicolumn{3}{c}{1 hour} \\ 
      \midrule
      & MAE     & RMSE   & MAPE    & MAE     & RMSE   & MAPE     & MAE    & RMSE   & MAPE     \\
      \hline
DCRNN & \bestval{2.77}    & \bestval{5.38}   & \bestval{7.3\%}   & \bestval{3.15}    & \bestval{6.45}   & \bestval{8.8\%}   & \bestval{3.60}   & \bestval{7.60}   & \bestval{10.5\%}   \\
GCRNN & 2.80    & 5.51   & 7.5\%   & 3.24    & 6.74   & 9.0\%   & 3.81   & 8.16   & 10.9\%  \\
\bottomrule
\end{tabular}
}
\end{table}

To further investigate the effect of spatial dependency modeling, we compare \gcrnn{} with the following variants:
(1) \gcrnn{}-NoConv, which ignores spatial dependency by replacing the transition matrices in the diffusion convolution (Equation~\ref{eq:gconv}) with identity matrices. This essentially means the forecasting of a sensor can be only be inferred from its own historical readings;
(2) \gcrnn{}-UniConv, which only uses the forward random walk transition matrix for diffusion convolution;
Figure~\ref{fig:spatial_dependency} shows the learning curves of these three models with roughly the same number of parameters.
Without diffusion convolution, \gcrnn{}-NoConv has much higher validation error. Moreover, \gcrnn{} achieves the lowest validation error which shows the effectiveness of using bidirectional random walk.
The intuition is that the bidirectional random walk gives the model the ability and flexibility to capture the influence from both the upstream and the downstream traffic.

To investigate the effect of graph construction, we construct a undirected graph by setting , where  is the new symmetric weight matrix.
Then we develop a variant of \gcrnn{} denotes GCRNN, which uses the sequence to sequence learning with \emph{ChebNet graph convolution} (Equation~\ref{eq:chebnet}) with roughly the same amount of parameters.
Table~\ref{tab:dcrnn_vs_gcrnn} shows the comparison between \gcrnn{} and GCRNN in the METR-LA dataset.
\gcrnn{} consistently outperforms GCRNN. The intuition is that directed graph better captures the asymmetric correlation between traffic sensors.  
\begin{figure*}[tp]
    \centering
	\begin{minipage}{.43\textwidth}
	\centering
\includegraphics[width=\linewidth]{figures/temporal_dependency}
    \caption{Performance comparison for different \gcrnn{} variants. \gcrnn{}, with the sequence to sequence framework and scheduled sampling, achieves the lowest MAE on the validation dataset. The advantage becomes more clear with the increase of the forecasting horizon.}
    \label{fig:seq2seq_comparison}
	\end{minipage}
\hspace{0.01\textwidth}
	\begin{minipage}{.52\textwidth}
	\centering
\includegraphics[width=\linewidth]{figures/traffic_visualization}
\caption{Traffic time series forecasting visualization. \gcrnn{} generates smooth prediction and is usually better at predict the start and end of peak hours.}
	\label{fig:traffic_visualization}
	\end{minipage} 
\end{figure*}
Figure~\ref{fig:k_effect} shows the effects of different parameters. 
 roughly corresponds to the size of filters' reception fields while the number of units corresponds to the number of filters. 
Larger  enables the model to capture broader spatial dependency at the cost of increasing learning complexity. We observe that with the increase of , the error on the validation dataset first quickly decrease, and then slightly increase.
Similar behavior is observed for varying the number of units.
\vspace{-0.1in}
\subsection{Effect of temporal dependency modeling}

To evaluate the effect of temporal modeling including the sequence to sequence framework as well as the scheduled sampling mechanism, we further design three variants of \gcrnn{}: 
(1) DCNN: in which we concatenate the historical observations as a fixed length vector and feed it into stacked diffusion convolutional layers to predict the future time series.
We train a single model for one step ahead prediction, and feed the previous prediction into the model as input to perform multiple steps ahead prediction.
(2) \gcrnn{}-SEQ: which uses the encoder-decoder sequence to sequence learning framework to perform multiple steps ahead forecasting.
(3) \gcrnn{}: similar to \gcrnn{}-SEQ except for adding scheduled sampling.

Figure~\ref{fig:seq2seq_comparison} shows the comparison of those four methods with regards to MAE for different forecasting horizons. We observe that:
(1) \gcrnn{}-SEQ outperforms DCNN by a large margin which conforms the importance of modeling temporal dependency.
(2) \gcrnn{} achieves the best result, and its superiority becomes more evident with the increase of the forecasting horizon. 
This is mainly because the model is trained to deal with its mistakes during multiple steps ahead prediction and thus suffers less from the problem of error propagation. 
We also train a model that always been fed its output as input for multiple steps ahead prediction. However, its performance is much worse than all the three variants which emphasizes the importance of scheduled sampling.

\vspace{-0.1in}
\subsection{Model Interpretation}
\vspace{-0.1in}
\begin{figure*}[tp]
    \centering
	\includegraphics[width=\linewidth]{figures/filter_visualization2}
\caption{Visualization of learned localized filters centered at different nodes with  on the METR-LA dataset. The star denotes the center, and the colors represent the weights. We observe that weights are localized around the center, and diffuse alongside the road network.}
	\label{fig:filter_visualization}
\end{figure*}

To better understand the model, we visualize forecasting results as well as learned filters. 
Figure~\ref{fig:traffic_visualization} shows the visualization of 1 hour ahead forecasting. We have the following observations:
(1) \gcrnn{} generates smooth prediction of the mean when small oscillation exists in the traffic speeds (Figure~\ref{fig:traffic_visualization}(a)). 
This reflects the robustness of the model.
(2) \gcrnn{} is more likely to accurately predict abrupt changes in the traffic speed than baseline methods (e.g., FC-LSTM).
As shown in Figure~\ref{fig:traffic_visualization}(b), \gcrnn{} predicts the start and the end of the peak hours. This is because \gcrnn{} captures the spatial dependency, and is able to utilize the speed changes in neighborhood sensors for more accurate forecasting. 
Figure~\ref{fig:filter_visualization} visualizes examples of learned filters centered at different nodes. The star denotes the center, and colors denote the weights. We can observe that (1) weights are well localized around the center, and (2) the weights diffuse based on road network distance. 
More visualizations are provided in Appendix~\ref{sec:model_visualization}.