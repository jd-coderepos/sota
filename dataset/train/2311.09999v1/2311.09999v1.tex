

\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage[pagenumbers]{cvpr} \usepackage{graphicx}\usepackage{multirow}\usepackage{amsmath,amssymb,amsfonts}\usepackage{amsthm}\usepackage{mathrsfs}\usepackage[title]{appendix}\usepackage{xcolor}\usepackage{textcomp}\usepackage{manyfoot}\usepackage{booktabs}\usepackage{algorithm}\usepackage{algorithmicx}\usepackage{algpseudocode}\usepackage{listings}\usepackage{tikz}
\usepackage{multirow}
\usepackage{multicol}
\definecolor{gold}{HTML}{FBF2D2}
\definecolor{silver}{HTML}{DDDDDD}
\definecolor{bronze}{HTML}{EED2B8}

\definecolor{goldD}{HTML}{D9AE13}
\definecolor{silverD}{HTML}{909090}
\definecolor{bronzeD}{HTML}{9A5F26}


\definecolor{catGreen}{HTML}{238763}
\definecolor{catBlue}{HTML}{1F70AE}

\newcommand{\medal}[3]{\tikz[baseline=(char.base)]{\node[rounded corners=2pt,fill=#1,draw=#2,inner sep=1.5pt] (char) {#3};}}

\newcommand{\bm}[2]{
    \ifcase#1\or {\medal{gold}{goldD}{\textbf{#2}}}
    \or {\medal{silver}{silverD}{#2}}
    \or {\medal{bronze}{bronzeD}{#2}}
    \else #2
    \fi\ignorespaces
}


\definecolor{trainorange}{HTML}{F7B059}\definecolor{inferblue}{HTML}{5ADAFA}


\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,citecolor=cvprblue]{hyperref}

\def\paperID{5565} \def\confName{CVPR}
\def\confYear{2024}

\title{TransFusion -- A Transparency-Based Diffusion Model for Anomaly Detection}


\author{Matic Fučka, Vitjan Zavrtanik, Danijel Skočaj\\
University of Ljubljana, Faculty of Computer and Information Science\\
{\tt\small \{matic.fucka, vitjan.zavrtanik, danijel.skocaj\}@fri.uni-lj.si}
}

\begin{document}
\maketitle
\begin{abstract}
Surface anomaly detection is a vital component in manufacturing inspection. Reconstructive anomaly detection methods restore the normal appearance of an object, ideally modifying only the anomalous regions. Due to the limitations of commonly used reconstruction architectures, the produced reconstructions are often poor and either still contain anomalies or lack details in anomaly-free regions. Recent reconstructive methods adopt diffusion models, however with the standard diffusion process the problems are not adequately addressed. We propose a novel transparency-based diffusion process, where the transparency of anomalous regions is progressively increased, restoring their normal appearance accurately and maintaining the appearance of anomaly-free regions without loss of detail. We propose TRANSparency DifFUSION (TransFusion), a discriminative anomaly detection method that implements the proposed diffusion process, enabling accurate downstream anomaly detection. TransFusion achieves state-of-the-art performance on both the VisA and the MVTec AD datasets, with an image-level AUROC of 98.5\% and 99.2\%, respectively. 
\end{abstract}


 \section{Introduction}
\label{sec:intro}


\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{imgs_pdf/transfusion-cvpr-idea-same-classes.pdf}
\caption{The reformulated diffusion model iteratively erases the anomalous regions during the backwards diffusion process. Training on synthetic anomalies (top) generalizes well to real anomalies (marked with \textcolor{red}{red circles}) seen at inference (bottom), leading to accurate output masks  that closely match the ground truth .
}
\label{fig:transfusion-idea}
\end{figure}

The primary objective of surface anomaly detection is the identification and localization of anomalies in images. In the standard problem setup only anomaly-free (normal) images are used to learn a normal appearance model and any deviations from the learned model are classified as anomalies. Surface anomaly detection is commonly used in various industrial domains~\cite{mvtec, visa, mvtec-loco} where the limited availability of abnormal images along with their considerable diversity makes training supervised models impractical.

Many of the recent surface anomaly detection methods follow the reconstructive~\cite{ZavrtanikInpainting,AnnoDDPM, fanogan, ganomaly} or the discriminative~\cite{dsr, draem} paradigms. Reconstructive methods train an autoencoder-like network on anomaly-free images and assume that the autoencoder will not generalize well to anomalous regions, since they were not seen during training, making them distinguishable by reconstruction error. Discriminative methods are trained to segment synthetic anomalies~\cite{draem, memseg,zhang2023destseg} and learn a normal-appearance model to generalize to real-world cases. A reconstructive network is commonly used as the normal-appearance model in discriminative methods.

Discriminative and reconstructive methods exhibit two core issues. First, reconstructive methods may \textit{overgeneralize} which causes them to reconstruct even anomalous regions leading to false negative detections. Second, due to the limited image generation capabilities of the commonly used reconstructive architectures, finegrained details in normal regions tend to be erased leading to \textit{loss of detail} in normal regions, causing false positive detections. Both issues contribute to a poor downstream anomaly detection performance. Recently, standard diffusion models~\cite{ddpm, ddim, diffusion-vit} have been used in place of reconstruction models in anomaly detection~\cite{AnnoDDPM,ddpm-noise-anomaly, ldm_draem}. Due to their addition of the standard Gaussian noise to images all these methods suffer from the \textit{loss of detail} in the normal regions. 
Additionally, most diffusion-based methods perform only partial image reconstruction, retaining some anomalous region information, leading to \textit{overgeneralization}.

To simultaneously address both problems of reconstructive methods, we propose a novel \textit{transparency-based diffusion process} reformulated explicitly for surface anomaly detection. Through the proposed diffusion process, the transparency of anomalies is iteratively increased so that they are gradually replaced with the corresponding normal appearance (Figure~\ref{fig:transfusion-idea}), effectively erasing the anomalies. Increasing the transparency as the objective of the diffusion process enables a precise anomaly-free reconstruction of the anomalous regions -- addressing \textit{overgeneralization}, whilst leaving the normal regions intact -- addressing the \textit{loss of detail} problem. 
To implement the transparency-based diffusion process, we propose \textit{TransFusion (TRANSparency DifFUSION)}, a surface anomaly detection method that integrates the powerful appearance modelling capabilities of diffusion models in the discriminative anomaly detection paradigm. Compared to the previously used reconstructive networks that attempted to implicitly detect and restore the anomaly-free appearance of anomalous regions in a single step~\cite{draem,dsr,zhang2023destseg}, TransFusion can maintain more accurate restorations of anomalous regions without the overgeneralization problem and without loss-of-detail in the anomaly-free regions. Due to the iterative nature of the reformulated diffusion process, TransFusion is able to focus on various visual characteristics of anomalies at various time-steps, even potentially addressing the regions previous iterations may have missed. This enables high-fidelity anomaly-free reconstructions, improving the downstream anomaly detection performance.

The main contributions of our work are as follows:
\begin{itemize}
    \item We propose a novel transparency-based diffusion process reformulated explicitly for the problem of surface anomaly detection. It directly addresses the overgeneralization and loss-of-detail problems of recent reconstructive anomaly detection methods.
    \item We propose TransFusion - A strong discriminative anomaly detection model that implements the transparency-based diffusion process. TransFusion iteratively increases the transparency of anomalies and simultaneously provides their explicit localization, leading to a strong anomaly detection performance even in difficult near-in-distribution scenarios.
    \item We perform extensive experiments on two challenging datasets and show that TransFusion achieves state-of-the-art results in anomaly detection on two standard challenging datasets -- VisA~\cite{visa} and MVTec AD~\cite{mvtec}, with an AUROC of 98.5\% and 99.2\%, respectively. TransFusion sets a new state-of-the-art in anomaly detection in terms of the mean across both datasets, achieving a 98.9\% AUROC, surpassing the previous state-of-the-art by a significant margin of 1.6 percentage points, thus demonstrating its versatility across various scenarios.
\end{itemize}


\section{Related Work}

\noindent\textbf{Surface anomaly detection} has been a subject of intense research in recent years, and various approaches have been proposed to address this task. Methods can be divided into three main paradigms: reconstructive, embedding-based, and discriminative.

\textit{Reconstructive methods} train an autoencoder-like network~\cite{ae-ssim, ae-2014, ZavrtanikInpainting} or a generative model~\cite{ganomaly, fanogan, AnnoDDPM, ddpm-noise-anomaly} and assume that anomalies will be poorly reconstructed compared to the normal regions making them distinguishable by reconstruction error. A solution proposed by Zavrtanik~\cite{ZavrtanikInpainting} involved masking parts of the image and reconstructing it using information from neighboring patches. The poor reconstruction assumption does not always hold, leading to poor performance.


\textit{Embedding-based methods} use feature maps~\cite{simplenet, NPad} extracted with a pretrained network to learn normality on these maps. Patchcore~\cite{patchcore} creates a coreset memory bank out of the extracted normal features. Several normalizing-flow-based~\cite{cflow-ad, cs-flow, fastflow, u-flow} approaches have been proposed as well. Some methods utilize a student-teacher~\cite{uninformed, reverse_dist, ast} network and assume that the student will not be able to produce meaningful features for the anomalies as it had not seen them during training. All these methods assume that the distribution of normal regions will be well represented in the training data and fail on rare normal regions unseen during training, producing false positives. 

\textit{Discriminative methods} use synthetically generated defects~\cite{draem,dsr,cutpaste,zhang2023destseg,memseg,simplenet} to train their model with the idea that the model can then generalize on real anomalies. In seminal works of this paradigm such as DR{\AE}M~\cite{draem}, a reconstructive module is trained to restore the normal appearance and a discriminative network is trained to segment synthetic anomalies. The normal appearance can also be modelled using pretrained features~\cite{zhang2023destseg,memseg,simplenet}. DSR~\cite{dsr} uses a vector-quantized autoencoder for normal appearance reconstruction, however it still suffers from loss of detail of normal regions.


\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{imgs_pdf/transfusion-cvpr_9.pdf}
    \caption{
    TransFusion's \textcolor{trainorange}{training} and \textcolor{inferblue}{inference} pipelines. \textcolor{trainorange}{Training} examples are created from normal images  by generating the anomaly mask  and the anomaly appearance  and imposing them on  according to the transparency schedule . The resulting image  contains synthetic anomalies. TransFusion is guided by an augmented mask . TransFusion outputs the estimated anomaly mask , the anomaly appearance , and the normal appearance . At \textcolor{inferblue}{inference}, TransFusion infers , , and  from the input image and constructs the next step image according to Eq. \ref{eq:next_step_eq}. The predicted mask  and the constructed  are used as the input in the next step.}

    \label{fig:transfusion}
\end{figure*}

\noindent\textbf{Diffusion models} recently emerged as state-of-the-art in image generation~\cite{ddpm}. They have been extended to various domains, such as audio~\cite{diffusion-audio, diffusion-speech} and text generation~\cite{diffusion-text, diffusion-multinomial-text}. Methods have also been proposed that tackle problems such as semantic segmentation~\cite{segdiff, medsegdiff} and object detection~\cite{diffusiondet}. It has also been shown that the Gaussian noise-based diffusion process is not necessary for all problems~\cite{cold-diffusion, diffusiondet}.


\noindent\textbf{Diffusion-based anomaly detection} Wyatt \textit{et. al.}~\cite{AnnoDDPM} proposed AnoDDPM which is based on a standard diffusion architecture~\cite{ddpm}. AnoDDPM was applied to a medical image dataset and achieved state-of-the-art results. Lu \textit{et. al.}~\cite{ddpm-noise-anomaly} proposed using a DDPM to simultaneously predict the noise and to generate features that mimic the features extracted from a pretrained convolutional neural network. DiffAD~\cite{ldm_draem} uses a DR{\AE}M-like~\cite{draem} network but exchanges the autoencoder with a latent diffusion model. All recent diffusion approaches face problems with loss of detail in the normal regions. As a result, they exhibit a high rate of false positives. This suggests that naively applying the standard diffusion process is not sufficient for surface anomaly detection.


\section{TransFusion}

Reconstructive modules of discriminative anomaly detection approaches are tasked with implicitly localizing anomalies and restoring their normal visual appearance. To achieve a better detection robustness and reconstruction capability of such a process, an appropriate diffusion model is defined. Previous work~\cite{cold-diffusion} has established that a variety of iterative processes can be used to achieve the desired diffusion effect. In the proposed transparency-based diffusion process reformulation, images are thought of as a composition of anomalous and normal components, partitioned by the anomaly mask . To frame the anomaly localization and restoration as an iterative process, the anomalous regions are expressed as a linear interpolation between the anomalous and the normal appearance at each step. This equates to the transparency of the anomalous regions increasing throughout the diffusion process (Figure~\ref{fig:transfusion-idea}). In this section, we describe TransFusion in detail.

\subsection{Transparency-based diffusion model}
\label{ch:diff_proc}

In the transparency-based diffusion process reformulation, each image  is expressed as a composition of the normal appearance , the anomaly appearance , the anomaly mask , and the blending factor between the anomalous and the normal appearance , i.e., the transparency level of the anomaly:

where  is a binary mask where the anomalous pixels are set to  and  is the inverse of . The anomalous region is an interpolation between the anomaly appearance  and the normal appearance  in the region specified by the anomaly mask . The transparency of the anomalous region is defined by . The restoration of the normal appearance from an anomalous image  can be modelled as an iterative process of gradually increasing the anomaly transparency until only the normal appearance remains. This is not a trivial task, since the accurate localization , normal appearance  and anomaly appearance  must be inferred from the input image .

\textit{During training}, images containing synthetic anomalies and their corresponding anomaly masks are used.
For each step in the \textit{forward process}, the value of  is gradually increased, thus decreasing the transparency of anomalies, and increasing their prominence. Let  denote the anomalous image  at time step . The transparency schedule is denoted as , where  and . Eq.~(\ref{eq:anom_img}) is rewritten to correspond to timestep  by substituting the variables  with ,  with , and  with : 
  
The image with more transparent anomalies  at iteration  is then computed:

 decreases between steps  and , while the correct values of ,  and  are predefined and remain constant throughout the forward process. We can thus write ,  and . After substituting  for ,  for  and  for  in Eq.~(\ref{eq:t-1}), subtracting it from Eq.~(\ref{eq:t}) and then rearranging it, the transition between steps  and  is computed:

At each time step in the \textit{reverse process}, the value of  moves towards the anomaly-free  by an amount influenced by . The anomaly's transparency is therefore gradually increased, reconstructing the normal appearance until the final anomaly-free restoration  is reached. This requires an accurate estimation of the anomaly mask , the normal appearance  and the anomaly appearance  at each time step.


\subsection{Architecture}
\label{ch:multihead}


The architecture of TransFusion, depicted in Figure~\ref{fig:transfusion}, is based on ResUNet~\cite{resunet} which is commonly used in diffusion models. TransFusion has three prediction heads, which output the anomaly appearance , anomaly mask  and the normal appearance , enabling the generation of the image in the next reverse step according to Eq.~(\ref{eq:next_step_eq}). The anomaly and normal appearance heads consist of a single convolutional layer, while the anomaly mask head consists of a BatchNorm, SiLU and a convolutional layer. 

The input to the diffusion model at each timestep consists of four elements: the current reconstruction estimate , the mask estimate , the 2D sinusoidal positional encoding ~\cite{positional_encoding}, and the timestep . All the elements are channel-wise concatenated except for the timestep embedding which is added to the features. During training, images containing synthetic anomalies are generated from an anomaly-free image , the anomaly mask , and the anomaly appearance . The input image  is generated according to Eq.~\ref{eq:t}, where ,  and , and the  schedule for the sampled timestep . Losses for the prediction head outputs ,  and  are calculated using ,  and  as ground truth values, respectively. 


Separate loss functions are used for each prediction head. The \textit{normal appearance prediction head} uses the structural similarity (SSIM) loss~\cite{ssim} and the  loss:

The \textit{anomaly mask} head uses the focal loss~\cite{focal} and the Smooth  loss, commonly used in discriminative anomaly detection~\cite{memseg,draem}:

The weighting parameter  is set to 5 in all experiments.
The \textit{anomaly appearance prediction head} employs the standard  reconstruction loss:


To ensure the consistency between difusion steps, where  is computed from the estimated , ,  and the previous step  using Eq.~(\ref{eq:next_step_eq}), an additional \textit{consistency loss} function  is employed.  compares the predicted  with the ground truth  computed using the ground truth , , and :

The complete TransFusion loss is then given as:




\subsection{Synthetic anomaly generation}
\label{ch:synt_anom}

Following commonly used procedures~\cite{draem,memseg}, synthetic anomalies are generated by pasting out-of-distribution regions on the anomaly-free inputs, outputting the image containing synthetic anomalies  and the anomaly mask .  is generated using \textit{Perlin noise}~\cite{perlin1985image}. Synthetic anomalous examples are shown in the top part of Figure~\ref{fig:transfusion-idea}. Depending on the timestep used, anomalies are generated at different transparency levels. 


At inference, the current mask estimate  used as input may be inaccurate as it is output by the network at the previous timestep. To address this uncertainty and improve robustness,  is \textit{augmented} so that its anomalous regions become larger or smaller, thus not perfectly fitting the synthetic anomalies in . The augmented mask  is obtained by thresholding the Perlin noise map used for generating  therefore reducing or expanding the size of anomalies in .  is also dropped during training in  of training samples.


\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{imgs_pdf/inference_example.pdf}
    \caption{TransFusion inference. For every fourth timestep, the input image  and the predictions for the mask , anomaly appearance  and normal appearance  are shown. As seen in the top row TransFusion first reconstructs larger anomalies and inpaints the details near the end of the reconstruction process.}
    \label{fig:inference-example}
\end{figure}



\subsection{Inference}
\label{ch:final_mask}


At \textit{inference}, Figure~\ref{fig:transfusion}, the starting mask estimate is initialized to all zero values.
Then, the reverse process of T time steps is performed. T is set to 20 in all experiments unless stated otherwise. At each time step  the current approximation of the reconstructed image  is channel-wise concatenated with the binarized previous mask estimate  and positional encoding . This composite input and the current timestep  are fed into the diffusion model. The model's output consists of the current mask estimate , an anomaly appearance estimation , and a normal appearance estimation  (Figure~\ref{fig:transfusion}, bottom middle). Based on these outputs, the next step   is predicted using Eq.~(\ref{eq:next_step_eq}) (Figure~\ref{fig:transfusion}, bottom right). Anomaly mask  is binarized by thresholding and used in the next step. An example of the inference process is visualized in Figure~\ref{fig:inference-example}. The reverse process iteratively reduces the transparency of the anomalous regions, progressively restoring the anomaly-free appearance of the image. At time step 0, the result is a fully reconstructed anomaly-free image .


The \textit{final anomaly mask}  is derived from , the pixel-wise mean of anomaly masks , with  going from  to , produced throughout the reverse process and from , the reconstruction error between the initial image  and the diffusion model output .

To obtain the final mask , a weighted combination of  and  is performed:

where the influence of  and  is weighted by  (=0.95 in all experiments),  is a mean filter of size  (in our case ) and  is the convolution operator. The mean filter smoothing is performed to aggregate the local anomaly map responses for a robust image-level score estimation. The image-level anomaly score  is obtained by the maximum value of :


Including both  and  gives the final mask  a balanced anomaly representation allowing it to benefit from both discriminative and reconstructive cues.


\begin{table*}[th]
\centering
\setlength{\tabcolsep}{3pt}
\resizebox{\textwidth}{!}{
\begin{tabular}{lccccccccccc}
                  \toprule \textbf{Method} & AnoDDPM~\cite{AnnoDDPM} & AnomDiff~\cite{ddpm-noise-anomaly} & DiffAD~\cite{ldm_draem} & DR{\AE}M~\cite{draem} & DSR~\cite{dsr} & FastFlow~\cite{fastflow} & PatchCore~\cite{patchcore} & RD4AD~\cite{reverse_dist} & AST~\cite{ast} & SimpleNet\cite{simplenet} & \textit{TransFusion}\\
\midrule Candle & 64.9 & 81.0 & 90.4 & 94.4 & \bm2{98.8} & 96.4 & 98.1 & 92.2 & \bm1{99.4} & 95.6 &  \bm3{98.3}\\
Capsules & 76.5 & 80.0 & 87.6 & 76.3 & \bm2{99.1 } & 89.2 & 85.7 & \bm3{90.1 } & 85.4 & 76.7 & \bm1{99.6 }\\
Cashew & 94.4 & 90.9 & 81.4 & 90.7 & \bm3{97.6 } & 95.2 & \bm2{98.5 } & \bm1{99.6 } & 95.1 & 91.7 & 93.7\\
Chewing gum & 91.3 & 98.1 & 94.0 & 94.2 & 93.8 & 99.4 & 99.0 & \bm2{99.7 } & \bm1{100 } & 99.1 & \bm3{99.6 }\\
Fryum & 81.5 & 89.2 & 87.1 & 97.4 & 82.9 & \bm2{98.8 } & 97.2 & 96.6 & \bm1{99.1 } & 95.3 & \bm3{98.3 }\\
Macaroni1 & 58.8 & 77.8 & 87.6 & 95.0 & 87.3 & 94.5 & \bm3{95.7 } & \bm1{98.4 } & 93.9 & 90.8 & \bm1{98.4 }\\
Macaroni2 & 74.5 & 61.0 & 90.7 & \bm3{96.2 } & 83.4 & 81.7 & 78.1 & \bm1{97.6 } & 72.1 & 65.2 & \bm2{96.5 }\\
PCB1 & 42.1 & 86.7 & 75.0 & 54.8 & 90.5 & 94.7 & 98.3 & \bm3{97.6 } & \bm1{99.2 } & 60.1 & \bm2{98.9 }\\
PCB2 & 90.7 & 76.5 & 94.6 & 77.8 & 96.6 & 96.0 & \bm3{97.2 } & 91.1 & \bm2{98.4 } & 93.3 & \bm1{99.7 }\\
PCB3 & 92.3 & 80.4 & 94.7 & 94.5 & 94.8 & 93.3 & \bm3{96.2 } & 95.5 & \bm2{97.4 } & 94.9 & \bm1{99.2 }\\
PCB4 & 98.3 & 93.8 & 97.7 & 93.4 & 93.5 & 97.8 & \bm3{99.0 } & 96.5 & \bm1{99.6 } & 98.2 & \bm1{99.6 }\\
Pipe fryum & 72.5 & 89.4 & 92.7 & \bm2{99.4 } & 97.5 & 99.2 & 99.4 & 97.0 & \bm2{99.4 } & 93.3 & \bm1{99.6 }\\
            \midrule   \textit{Average} & 78.2 & 83.7 & 89.5 & 88.7 & 91.6 & 93.9 & 94.3 & \bm2{96.0 } & \bm3{94.9 } & 87.9 & \bm1{98.5 }\\ \bottomrule
\end{tabular}
}
\caption{Comparison of TransFusion in anomaly detection (AUROC) with SOTA on VisA. \textcolor{goldD}{First}, \textcolor{silverD}{second} and \textcolor{bronzeD}{third} place are marked.}
\label{tb:visa_det_results}
\end{table*}



\section{Experiments}

\begin{table*}
\setlength{\tabcolsep}{3pt}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{lccccccccccc}
                  \toprule \textbf{Method} & AnoDDPM~\cite{AnnoDDPM} & AnomDiff~\cite{ddpm-noise-anomaly} & DiffAD~\cite{ldm_draem} & DR{\AE}M~\cite{draem} & DSR~\cite{dsr} & FastFlow~\cite{fastflow} & PatchCore~\cite{patchcore} & RD4AD~\cite{reverse_dist} & AST~\cite{ast} & SimpleNet\cite{simplenet} & \textit{TransFusion}\\

\midrule Carpet & 93.5 & \bm3{99.9} & 98.3 & 97.0 & \bm1{100 } & \bm1{100 } & 98.7 & 95.3 & 99.1 & 97.5 & 99.2\\
Grid & 93.8 & 99.7 & \bm1{100 } & 99.9 & \bm1{100 } & 99.7 & 98.2 & \bm1{100 } & 98.7 & 99.1 & \bm1{100 }\\
Leather & 99.5 & \bm1{100} & \bm1{100 } & \bm1{100 } & \bm1{100 } & \bm1{100 } & \bm1{100 } & 97.1 & \bm1{100 } & \bm1{100 } & \bm1{100 }\\
Tile & 99.4 & 98.0 & \bm1{100 } & 99.6 & \bm1{100 } & \bm1{100 } & 98.7 & 99.3 & 99.1 & \bm1{100 } & 99.8\\
Wood & 99.0 & 98.1 & \bm1{100 } & 99.1 & 96.3 & \bm1{100 } & 99.2 & 99.2 & 99.2 & \bm1{100 } &  99.4\\

\midrule  
Bottle & 98.4 & 99.3 & \bm1{100 } & 99.2 & \bm1{100 } & \bm1{100 } & \bm1{100 } & \bm1{100 } & \bm1{100 } & \bm1{100 } & \bm1{100 }\\
Cable & 52.7 & 91.2 & 94.6 & 91.8 & 93.8 & \bm1{100 } & \bm3{99.5 } & 95.0 & 98.5 & \bm2{99.9 } & 97.9\\
Capsule & 89.0 & 84.1 & 97.5 & \bm3{98.5 } & 98.1 & \bm1{100 }  & 98.1 & 96.3 & \bm2{99.7 } & 97.7 & \bm3{98.5 }\\
Hazelnut & 84.5 & 97.9 & \bm1{100 }  & \bm1{100 }  & 95.6 & \bm1{100 }  & 99.9 & \bm1{100 }  & \bm1{100 }  & \bm1{100 }  & \bm1{100 } \\
Metal nut & 92.8 & 99.2 & 99.5 & 98.7 & 98.5 & \bm1{100 }  & \bm1{100 } & \bm1{100 }  & 98.5 & \bm1{100 }  & \bm1{100 } \\
Pill & 80.9 & 64.7 & 97.7 & \bm3{98.9 } & 97.5 & \bm1{99.6 } & 96.6 & \bm2{96.6 } & 99.1 & 99.0 & 98.3\\
Screw & 20.3 & 89.9 & 97.2 & 93.9 & 96.2 & 97.8 & \bm3{98.1 } & 97.0 & \bm1{99.7 } & \bm2{98.2 } & 97.2\\
Toothbrush & 86.4 & 96.9 & \bm1{100 }  & \bm1{100 }  & 99.7 & 94.4 & \bm1{100 } & 90.8 & 96.6 & 99.7 & \bm1{100 } \\
Transistor & 65.0 & 92.3 & 96.1 & 93.1 & 97.8 & 98.8 & \bm1{100 }  & 96.7 & \bm3{99.3 } & \bm1{100 }  & 98.3\\
Zipper & 98.2 & 85.5 & \bm1{100 }  & \bm1{100 }  & \bm1{100 }  & 99.5 & 99.4 & 98.5 & 99.1 & 99.5 & \bm1{100 } \\

\midrule    \textit{Average} & 83.5 & 93.1 & 98.7 & 98.0 & 98.2 & \bm2{99.4 } & 99.1 & 98.5 & \bm3{99.2 } & \bm1{99.6 } & \bm3{99.2 }\\ \bottomrule
\end{tabular}
}
\caption{Comparison of TransFusion in anomaly detection (AUROC) with SOTA on MVTec AD. \textcolor{goldD}{First}, \textcolor{silverD}{second} and \textcolor{bronzeD}{third} place are marked.}
\label{tb:mvtec_det_results}
\end{table*}


\begin{table}
\setlength{\tabcolsep}{3pt}
\centering
{\footnotesize
\begin{tabular}{l|c|ll|ll|ll}
\hline \multirow{2}{*}{\textbf{Method}} & \multirow{2}{*}{\textbf{Venue}} & \multicolumn{2}{|c|}{VisA} & \multicolumn{2}{|c|}{MVTec AD} & \multicolumn{2}{|c}{\textit{Average}} \\
& & Det. & Loc. & Det. & Loc. & Det. & Loc.\\  \hline
AnoDDPM & CVPRW'22 & 78.2 & 60.5 & 83.5 & 50.7 & 80.9 & 55.6\\
DR{\AE}M & ICCV'21 & 88.7 & 73.1 & 98.0 & 92.8 & 93.3 & 83.0\\
SimpleNet & CVPR'23 & 87.9 & 68.9 & \bm1{99.6 } & 89.6 & 93.8 & 79.3 \\
DiffAD & ICCV'23 & 89.5 & 71.2 & 98.7 & 84.8 & 94.1 & 78.0\\
DSR & ECCV'22 & 91.6 & 68.1 & 98.2 & 90.8 & 94.9 & 79.5\\
FastFlow & ArXiv'21 & 93.9 & \bm2{86.9 } & \bm2{99.4 } & 92.5 & 96.7 & \bm2{89.7 }\\
Patchcore & CVPR'22 & 94.3 & 79.7 & 99.1 & 92.7 & 97.0 & \bm3{86.2}\\
AST & WACV'23 & \bm3{94.9 } & \bm3{81.5} & \bm3{99.2 } & 81.2 & \bm3{97.1 } & 81.4\\ 
RD4AD & CVPR'22 & \bm2{96.0 } & 70.9 & 98.5 & \bm2{93.9 } & \bm2{97.3 } & 82.4 \\
\textit{TransFusion} & - & \bm1{98.5 } & \bm1{88.8 } &  \bm3{99.2 } & \bm1{94.3 } & \bm1{98.9 } & \bm1{91.6 } \\ \hline
\end{tabular}
}
\caption{Results in anomaly detection (AUROC) and anomaly localization (AUPRO) on both VisA and MVTec AD. \textcolor{goldD}{First}, \textcolor{silverD}{second} and \textcolor{bronzeD}{third} place are marked.}
\label{tb:both_det_results}
\end{table}

\begin{figure*}[h]
    \centering
    \includegraphics[width=\textwidth]{imgs_pdf/mask_comp_bigger.pdf}
    \caption{Qualitative comparison of the masks produced by TransFusion and three other state-of-the-art methods. The anomalous images are shown in the first row. The middle four rows show the anomaly mask generated by RD4AD~\cite{reverse_dist}, DR{\AE}M~\cite{draem}, Patchcore~\cite{patchcore} and TransFusion respectively. The last row shows the ground truth anomaly mask.}
    \label{fig:mask-comp}
\end{figure*}

\begin{figure}[h]
    \centering
    \includegraphics[width=\columnwidth]{imgs_pdf/reconstruction_examples.pdf}
    \caption{Qualitative reconstruction results. TransFusion better restores anomalies to their normal appearance and better preserves the details in the normal regions than competing methods DR{\AE}M~\cite{draem} and DiffAD~\cite{ldm_draem}. A few of the larger differences are highlighted in red.}
    \label{fig:recon-comp}
\end{figure}


\subsection{Datasets}

Experiments are performed on two standard anomaly detection datasets: the VisA dataset~\cite{visa} and the MVTec AD dataset~\cite{mvtec}. The VisA dataset is comprised of 10,821 images distributed across 12 object categories, while the MVTec AD dataset contains 5,354 images encompassing 5 texture categories and 10 object categories. Notably, both datasets provide pixel-level annotations for the test images, enabling accurate evaluation and analysis. Compared to MVTec AD, the VisA dataset has more near-in-distribution anomalies that have proven challenging for recent anomaly detection methods. Consequently, this leads to poorer results by recent methods on the VisA dataset compared to MVTec AD.


\subsection{Evaluation metrics}

Standard anomaly detection evaluation metrics are used. The image-level anomaly detection performance is evaluated by the Area Under the Receiver Operator Curve (AUROC), while for the pixel-level anomaly localization the Area Under the Per Region Overlap (AUPRO) is utilized. 


\subsection{Implementation details}
During both training and inference 20 steps () are used in the diffusion process with a linear transparency () schedule ranging from 0 to 1. 
The model was trained for 1500 epochs using the AdamW optimizer with a batch size of 8. The learning rate was set to  and was multiplied by  after 800 epochs. Synthetic anomalies were added to half of the training batch. Rotation augmentation was used following DR{\AE}M~\cite{draem}. To ensure experimental consistency, a standard preprocessing approach is employed. Each image is resized to dimensions of  and subsequently center-cropped to  following recent literature~\cite{patchcore, memseg, simplenet}. The image is then linearly scaled between -1 and 1 following recent diffusion model literature~\cite{ddpm,ddim}. Following the standard protocol, a separate model was trained for each category and the same hyperparameters were set across both datasets and all categories.

\subsection{Experimental results}




\textit{Anomaly detection} results on VisA are shown in Table~\ref{tb:visa_det_results}. TransFusion achieves the best results on 6 out of the 12 categories and outperforms the previous best state-of-the-art method by  percentage points in terms of the mean AUROC performance, reducing the error by .
 
On the MVTec AD dataset, TransFusion achieves state-of-the-art results with a mean anomaly detection AUROC of 99.2\%. Results are shown in Table~\ref{tb:mvtec_det_results}. While two alternative approaches outperform TransFusion on the MVTec AD dataset, it is noteworthy that the dataset has reached a high level of saturation, rendering it challenging to display superior methodological improvements based solely on performance on this dataset.

Due to the significant differences in anomaly types between the VisA and MVTec AD datasets, very few recent methods exhibit the generalization capability necessary to achieve top results for both datasets. Table~\ref{tb:both_det_results} shows results on both VisA and MVTec AD. Additionally, the average scores across both datasets are shown. TransFusion outperforms all recent methods in terms of the average anomaly detection AUROC by a significant margin of  percentage points, reducing the error by .

TransFusion also achieves the highest score in \textit{anomaly localization} when averaged across both datasets, outperforming competing methods by  percentage points. 
In terms of anomaly detection, TransFusion outpeforms competing methods significantly on the VisA dataset and achieves state-of-the-art performance on MVTec AD. TransFusion also outperforms other diffusion-based methods AnoDDPM~\cite{AnnoDDPM}, DiffAD~\cite{ldm_draem} and AnomDiff~\cite{ddpm-noise-anomaly} by a significant margin, which suggests that simply relying on a standard diffusion process for reconstruction may not be sufficient for anomaly detection. 

\begin{table}[t]
\setlength{\tabcolsep}{3pt}
\centering
{\footnotesize
\begin{tabular}{llcccc} \hline
                 \multirow{2}{*}{\textbf{Group}} & \multirow{2}{*}{\textbf{Condition}}  & \multicolumn{2}{c}{VisA} & \multicolumn{2}{c}{MVTec AD} \\
                  &   & Det. & Loc. & Det. & Loc. \\ \hline
&  w/o PE & \textcolor{blue}{-1.4} & \textcolor{gray}{-0.1} & \textcolor{blue}{-1.9} & \textcolor{gray}{-3.2} \\
\multirow{-2}{*}{\textit{Input strategies}}& w/o Prev. Mask & \textcolor{gray}{-1.2} & \textcolor{blue}{-8.6} & \textcolor{gray}{-2.4} & \textcolor{blue}{-6.2} \\ \hline
& w/o  & \textcolor{blue}{-31.8} & \textcolor{blue}{-45.3} & \textcolor{blue}{-26.0} & \textcolor{blue}{-43.2}\\
& w/o  & \textcolor{gray}{-1.5} & \textcolor{gray}{-3.2} & \textcolor{gray}{-2.2} & \textcolor{gray}{-2.7}\\
 & w/o  & \textcolor{gray}{-1.1} & \textcolor{gray}{-1.5} & \textcolor{gray}{-1.0} & \textcolor{gray}{-1.0}\\ 
 \multirow{-4}{*}{\textit{Loss Function}} &  w/o  & \textcolor{gray}{-0.9} & \textcolor{gray}{-0.3} & \textcolor{gray}{-0.7} & \textcolor{gray}{-0.8}\\ \hline
&  Only  & \textcolor{blue}{-1.5} & \textcolor{gray}{-0.3} & \textcolor{blue}{-1.4} & \textcolor{gray}{-2.6}\\
&  Only  & \textcolor{gray}{-0.1}  & \textcolor{gray}{+0.1} & \textcolor{gray}{-0.2} & \textcolor{gray}{+0.1}\-1pt] \hline
 &  5 steps & \textcolor{blue}{-1.0} & \textcolor{blue}{-4.3} & \textcolor{blue}{-0.7} & \textcolor{blue}{-1.2}\\
 &  10 steps & \textcolor{gray}{-0.5} & \textcolor{gray}{-1.1} & \textcolor{gray}{-0.7} & \textcolor{gray}{-1.0}\\
\multirow{-3}{*}{\textit{Diffusion step num.}} & 50 steps & \textcolor{gray}{-0.3}  & \textcolor{gray}{+0.7} & \textcolor{gray}{-0.5} & \textcolor{gray}{-0.8}\-1pt]
\multirow{-2}{*}{\textit{Transparency sched.}}&  Root & \textcolor{gray}{-1.7}  & \textcolor{blue}{-2.7} & \textcolor{gray}{-0.7} & \textcolor{blue}{-1.6}\\ \hline

\textit{TransFusion} & Linear, 20 steps & 98.5 & 88.8 & 99.2 & 94.3\\ \hline   
\end{tabular}
}
\caption{Ablation study results. Detection results are reported in AUROC and localization results are reported in AUPRO. In each row the difference to the actual model is shown. The highest discrepancy for each experiment group is marked in \textcolor{blue}{blue}.}
\label{tb:ablation}
\end{table}





\subsection{Qualitative comparisons}

A qualitative comparison with the state-of-the-art methods DR{\AE}M~\cite{draem}, RD4AD~\cite{reverse_dist} and Patchcore~\cite{patchcore} can be seen in Figure~\ref{fig:mask-comp}. Note that TransFusion outputs very precise anomaly masks and does not produce significant false positives in the background opposed to other state-of-the-art methods (Columns 5, 13, 14). Due to being a discriminative network, TransFusion outputs masks (Columns 1-14) that are much sharper than those of Patchcore and RD4AD which output a feature-based distance function and the feature reconstruction error, respectively. DR{\AE}M is unable to accurately detect small near-in-distribution anomalies (Columns 3, 5, 6, 14) mostly present in the VisA~\cite{visa} Dataset. We hypothesize that this is due to the subpar reconstructive model of DR{\AE}M.

TranFusion exhibits a strong reconstructive ability. A qualitative comparison can be seen in Figure~\ref{fig:recon-comp}. Compared to DR{\AE}M~\cite{draem}, TransFusion outputs higher-quality reconstructions and even produces realistic results in difficult reconstruction cases such as strong deformations, while maintaining fine-grained details in normal regions. TransFusion better addresses the loss of detail problem compared to previously proposed method DiffAD~\cite{ldm_draem}.





\subsection{Ablation study}
The results of the evaluation of individual components of TransFusion and it's training process are shown in Table~\ref{tb:ablation}.

\noindent\textbf{Input strategies.} In addition to the image , the Positional Encoding (PE) and the previous mask estimate are input during training. The impact of PE and the mask estimate is evaluated by excluding each individually from the architecture. \textit{Excluding PE} leads to a  percentage points (p.\ p.) drop on VisA and a  p.\ p.\ drop on MVTec AD. \textit{Excluding the mask estimate} leads to a  p.\ p. drop on VisA and a  p. p. drop on MVTec AD, showing the benefit of an approximate mask guidance. There is also a significant drop ( p.\ p.\ on VisA and  p.\ p.\ on MVTec AD) in localization when excluding the approximate mask highlighting its importance for precise localization.

\noindent\textbf{Importance of loss functions.} The importance of each loss function was evaluated by excluding one loss function at a time and training the model. Removing ,  or  reduces the overall anomaly detection performance by approximately  p.\ p.\ on VisA and MVTec AD, demonstrating their usefulness. Notably, removing   leads to a major drop in performance ( p.\ p.\ AUROC on VisA,  p.\ p.\ AUROC on MVTec AD), showing the necessity of learning a strong normal appearance model of the object. Without , TransFusion may focus on learning the synthetic anomaly appearance, leading to poor generalization. 

\noindent\textbf{Final mask calculation.} The anomaly mask calculation methods using either only the last mask estimate , the discriminative mask , or the reconstruction mask  are evaluated. Using only  leads to a  p.\ p.\ drop on VisA and a  p.\ p.\ MVTec AD in terms of AUROC.  can accurately localize the anomalies even without , leading to only a  and  p.\ p.\ drop on VisA and MVTec AD, respectively. The impact of mask averaging throughout the diffusion process is significant, since using only the last estimated mask (Last Mask Est.) causes a  and  p.\ p.\ drop in anomaly detection performance on the VisA and MVTec AD, respectively.

\noindent\textbf{Number of diffusion steps.} The impact of the number of diffusion steps on the anomaly detection performance is evaluated. Although a lower number of steps leads to a poorer normal appearance restoration, TransFusion remains robust across various time-step settings achieving similar results across both VisA and MVTec AD, even achieving state-of-the-art results on VisA at only 5 timesteps. A higher number of diffusion steps also increases the result in localization on VisA.


\noindent\textbf{Transparency schedule.} The impact of replacing the linear  schedule with alternative schedules is evaluated. The Root and the Quadratic schedule are examined, where the  values change from  to  using a quadratic or a square-root function, respectively. Using a Quadratic schedule causes a  p.\ p.\ drop in performance on both VisA and MVTec AD. The Root schedule leads to a  and a  p.\ p.\ drop on the VisA and the MVTec AD, respectively. Interestingly, using a quadratic schedule improves anomaly localization by a  p.\ p.\ on VisA and a  p.\ p.\ on MVTec AD. 



\noindent\textbf{Inference efficiency.} Inference times of various methods can be seen in Table~\ref{tb:inf_speed}. Due to the complexity of diffusion models TransFusion is slower than some competing methods, however it is faster than other diffusion-based methods. Additionally, reducing the number of inference steps does not drastically reduce performance (Table~\ref{tb:ablation}). Diffusion distillation is an active field~\cite{diff_distillation, progressive_diffusion_distillation, consistency_model} and may be helpful for speeding up diffusion-based anomaly detection models.

\begin{table}[t]
\centering
\resizebox{\columnwidth}{!}{
\begin{tabular}{lcccc} \toprule
\textbf{Method} & DR{\AE}M~\cite{draem} & Patchcore~\cite{patchcore} & DiffAD~\cite{ldm_draem} & \textit{TransFusion} \\ \midrule
Inference [s] & \bm1{0.05 } & \bm2{0.22 } & 1.00 & \bm3{0.34 } \\ \bottomrule
\end{tabular}
}
\caption{Results for average inference time of a single sample with NVIDIA A100 GPU. Inference times are reported in seconds.}
\label{tb:inf_speed}
\end{table}


\section{Conclusion}
A novel, transparency-based diffusion process is proposed, where the transparency of the anomalous regions is gradually increased, effectively removing them, and restoring their normal appearance. TransFusion, a novel discriminative anomaly detection method that implements the transparency-based diffusion process is proposed. TransFusion is able to produce accurate anomaly-free reconstructions of anomalies, while maintaining the appearance of normal regions, thus addressing both the overgeneralization and loss-of-detail problems of commonly used reconstructive methods. TransFusion achieves state-of-the-art results in anomaly detection on the standard VisA and MVTec AD datasets, achieving an AUROC of 98.5\% and 99.2\% for both datasets, respectively. The versatility of TransFusion and its robustness to near-in-distribution anomalies are further validated by the state-of-the-art performance across both datasets, where TransFusion achieves 98.9\% mean AUROC, surpassing the previous state-of-the-art by a significant margin of 1.6 percentage points. The results indicate that custom diffusion processes crafted specifically for surface anomaly detection are a promising direction for future research.

{
    \small
    \bibliographystyle{ieeenat_fullname}
    \bibliography{egbib}
}



\end{document}
