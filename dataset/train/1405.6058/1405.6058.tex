

\label{sec:tpm}
While \HelloRootkitty{} significantly elevates the security of the overall system, it is not able to guarantee complete isolation of applications. Malware could still successfully exploit subtle bugs in the kernel by trying to restore invariants before they are checked or avoiding breaking invariants altogether. For at least a certain period of time, the malware may be able to access sensitive information of applications running on behalf of other parties.

An alternative research track attempts to protect sensitive information even in the presence of kernel-level malware. Security measures have been developed\citep{garfinkel2003terra,singaravelu2006ReducingTCB,mccune2008Flicker,mccune2010TrustVisor,strackx2010trustedSubsystemsInEmbeddedSystems,azab2011sice} to offer such strong security guarantees by splitting applications in a security sensitive and a security insensitive part. The former part is executed in complete isolation from the rest of the system. This minimizes the size of the trusted computing base (TCB), the sum of all software that is relied upon to isolate sensitive information and calculate the correct result, up-to a point that it becomes feasible to formally verify\citep{jacobs2008verifast} the correctness of code. This proves with mathematical certainty that sensitive information will never leak to another party. While these security measures are able to provide very strong security guarantees, they are no longer binary-compatible with legacy applications. A significant effort is required to partition these applications in an security sensitive and insensitive part. Moreover, it does not provide any availability guarantees. While malware is unable to access or modify sensitive information, it still can, for example, cause the system to freeze, preventing all parties to execute any application.

\subsubsection{Root of trust}


Accepting the presence of kernel-level malware causes significant problems to establish a root of trust. Malware may already have infected the system before the security measure is applied. Hence, the malware could influence the security measure's behavior or disable it altogether. For example, the kernel image stored on the hard drive, could have been modified to include the malicious code. To mitigate this problem, a low-cost security chip, called the Trusted Platform Module (TPM)\citep{TCG2004TPMdesign} has been developed and is already shipped with most modern computers. Equipped with a slow but cheap processor and its own memory, it can be used to execute a fixed set of security-related tasks. To protect the chip itself from software attacks, it is shipped with all required software that under no circumstance can be modified.

The TPM chip is designed for a few specific tasks. First, it is able to record all software that is loaded on the system. Starting at power up, a measurement of the software is calculated and stored on the chip. Every time a new process is loaded, this measurement is extended with a measurement of the loaded software including the used configuration files. This is called a {\em Static Root of Trust Measurement} (SRTM). Similarly, a new measurement can be started after the system has already booted, called a {\em Dynamic Root of Trust Measurement} (DRTM).
Second, the TPM chip is able to store a very limited amount of data, called {\em sealed storage}. On storage, the data is supplied together with a measurement. Only when software with this specific measurement is loaded, can the data be retrieved again.
Finally, the chip is able to attest to a third party that a specific version of software has executed and outputted the specified results. Using cryptographic functions, it can prevent malware from making false claims such as specifying a different output.







Using a combination of the features directly provided by the TPM chip, strong security guarantees can be provided. Flicker\citep{mccune2008Flicker}, takes this approach. Applications are divided into security sensitive modules. Upon invocation, a new dynamic root of trust measurement is started, measuring the loaded module. This will also place the machine in an isolated state. During that time, only the module itself has control over the machine. Malware, possibly already present on the system, will not be executed. Hence, it is unable to access any sensitive information used by the module. After the module finished its execution, it will clear all sensitive information from memory and resume normal operation of the system. When information needs to be stored for other invocations of the same or other modules, it uses the sealed storage feature of the TPM chip.

While malware is not able to modify the binary image of the module, the module must still be trusted. Subtle bugs in the module itself, may be exploited by an attacker by providing unexpected parameters. As a result, sensitive information may not be completely overwritten after the module finished its execution or an incorrect result may be provided. Hence, there is still a need to formally verify that modules behave correctly \citep{jacobs2008verifast}. Given the very limited code size, contrary to entire monolithic kernels such as Windows and Linux, this approach is feasible.

While offering strong security guarantees, the Flicker security measure still has significant drawbacks. First, isolating security-sensitive parts of an application in modules can be difficult. {\em All} accesses to sensitive information must be encapsulated in the module in such a way that the result does not reveal any information unknown to an attacker. This could be achieved by, for example, encrypting the provided result. Another difficulty is that security-sensitive functionality provided by the operating system can no longer be used by the module. 
Second, to reduce the cost of the TPM chip, it is equipped with a low-budget processor that is much slower than the main processor of the system. As a result, executing a module incurs a significant overhead. Moreover, to isolate the module, other code is prevented from being executed and the user can experience a momentarily freeze of the system.

\subsubsection{Increasing flexibility}


Recent security measures\citep{mccune2010TrustVisor,sahita2009criticalAppsOnMobile} are able to significantly reduce Flicker's drawbacks while offering the same strong security guarantees. Using virtualization techniques, an additional protection layer can be added. This hypervisor layer is even more privileged than kernel layer and can be used to protect against kernel-level malware. As usual, formal verification is required to avoid malware infecting this most privileged level.

TrustVisor is an example of a security architecture that uses virtualization techniques to offer strong isolation of code and data of sensitive parts of an application. When the system is booted, a hypervisor is installed. This code executing at the highest privilege level, has two purposes. First, it is responsible to maintain binary compatibility with legacy code. Given the number and diversity of operating systems and legacy applications, any security measure that requires even minor changes to legacy software are infeasible in practice. Only applications that require use of the newly offered security guarantees should require minimal modification.

Second, the hypervisor must protect memory regions used by itself or protected modules. To be able to guarantee isolation of modules, TrustVisor must prevent read and write access from malware to these memory regions from the legacy operating system or applications. Similarly, protected modules that are possibly specially crafted by an attacker must not be able access other protected modules or the implementation of the security measure itself.

Using these properties, TrustVisor implements and protects software-based TPM's, called $\mu$TPMs, to significantly increase performance. When the system is booted, the hardware TPM chip measures all loaded software. At the first execution of the security measure, a long term secret is created for the $\mu$TPMs and sealed by the TPM. For subsequent boots, only when the security measure is loaded correctly, access to the long-term secrets is granted. The $\mu$TPMs use this long-term secret to safely provide secure storage and attestation functionality without accessing the slow hardware TPM. When a security-sensitive part of an application request TPM functionality, a $\mu$TPM is accessed instead. This reduces the overhead of accessing the hardware TPM chip to the cost of crossing the kernel-hypervisor border. Since $\mu$TPMs are executed on the main processor which is significantly more performant than the low-cost hardware TPM, performance evaluation of TrustVisor shows a significant speedup compared to Flicker.





