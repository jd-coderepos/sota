[{'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'UniProtQA', 'Metric': 'BLEU-2', 'Score': '0.571'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'UniProtQA', 'Metric': 'BLEU-4', 'Score': '0.535'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'UniProtQA', 'Metric': 'ROUGE-1', 'Score': '0.743'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'UniProtQA', 'Metric': 'ROUGE-2', 'Score': '0.759'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'UniProtQA', 'Metric': 'ROUGE-L', 'Score': '0.622'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'UniProtQA', 'Metric': 'MEATOR', 'Score': '0.754'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'PubMedQA', 'Metric': 'Accuracy', 'Score': '76.1'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'MedQA-USMLE', 'Metric': 'Accuracy', 'Score': '50.4'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'PubChemQA', 'Metric': 'BLEU-2', 'Score': '0.234'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'PubChemQA', 'Metric': 'BLEU-4', 'Score': '0.141'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'PubChemQA', 'Metric': 'ROUGE-1', 'Score': '0.386'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'PubChemQA', 'Metric': 'ROUGE-2', 'Score': '0.206'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'PubChemQA', 'Metric': 'ROUGE-L', 'Score': '0.332'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'PubChemQA', 'Metric': 'MEATOR', 'Score': '0.308'}}, {'LEADERBOARD': {'Task': 'Multiple Choice Question Answering (MCQA)', 'Dataset': 'MedMCQA', 'Metric': 'Test Set (Acc-%)', 'Score': '0.514'}}, {'LEADERBOARD': {'Task': 'Multiple Choice Question Answering (MCQA)', 'Dataset': 'MMLU (Professional medicine)', 'Metric': 'Accuracy', 'Score': '51.1'}}]
