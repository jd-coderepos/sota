\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts


\RequirePackage[absolute]{textpos}
\setlength{\TPHorizModule}{1mm}
\setlength{\TPVertModule}{1mm}

\DeclareRobustCommand*{\copyrightnote}{\begin{textblock}{85}(17.5,259.5)
      \scriptsize{\noindent \copyright 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted
component of this work in other works.}\end{textblock}}


\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
 \usepackage{hyperref}


\usepackage[pdftex]{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{float}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage[noend]{algcompatible}
\algnewcommand\algorithmicreturn{\textbf{return} }
\algnewcommand\RETURN{\State \algorithmicreturn}\algnewcommand\algorithmicto{\textbf{to} }
\algnewcommand\TO{\algorithmicto}


\usepackage{varwidth}





\usepackage{booktabs}  \usepackage{tablefootnote}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
  T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
  
  
  

\title{Training Classifiers that are Universally Robust to All Label Noise Levels
\thanks{This research is supported by the National Research Foundation, Singapore under its AI Singapore Programme (AISG Award No: AISG-RP-2019-015), and under its NRFF Programme (Award No: NRFFAI1-2019-0005).}
}

\author{\IEEEauthorblockN{Jingyi Xu}
\IEEEauthorblockA{\textit{Singapore University} \\ \textit{of Technology and Design}\\
Singapore \\
jingyi\_xu@mymail.sutd.edu.sg}
\and
\IEEEauthorblockN{Tony Q. S. Quek,~\IEEEmembership{Fellow,~IEEE}}
\IEEEauthorblockA{\textit{Singapore University} \\ \textit{of Technology and Design}\\
Singapore \\
tonyquek@sutd.edu.sg}
\and
\IEEEauthorblockN{Kai Fong Ernest Chong}
\IEEEauthorblockA{\textit{Singapore University} \\ \textit{of Technology and Design}\\
Singapore \\
ernest\_chong@sutd.edu.sg}
}

\begin{document}
\maketitle
\copyrightnote

\begin{IEEEkeywords}
label noise, clean data augmentation, Clothing1M, positive-unlabeled learning, distillation
\end{IEEEkeywords}


\begin{abstract}
For classification tasks, deep neural networks are prone to overfitting in the presence of label noise. Although existing methods are able to alleviate this problem at low noise levels, they encounter significant performance reduction at high noise levels, or even at medium noise levels when the label noise is asymmetric. To train classifiers that are universally robust to all noise levels, and that are not sensitive to any variation in the noise model, we propose a distillation-based framework that incorporates a new subcategory of Positive-Unlabeled learning. In particular, we shall assume that a small subset of any given noisy dataset is known to have correct labels, which we treat as ``positive", while the remaining noisy subset is treated as ``unlabeled". Our framework consists of the following two components: (1) We shall generate, via iterative updates, an augmented clean subset with additional reliable ``positive" samples filtered from ``unlabeled" samples; (2) We shall train a teacher model on this larger augmented clean set. With the guidance of the teacher model, we then train a student model on the whole dataset. Experiments were conducted on the CIFAR-10 dataset with synthetic label noise at multiple noise levels for both symmetric and asymmetric noise. The results show that our framework generally outperforms at medium to high noise levels. We also evaluated our framework on Clothing1M, a real-world noisy dataset, and we achieved 2.94\% improvement in accuracy over existing state-of-the-art methods.
\end{abstract}


\section{Introduction}
For classification tasks, deep neural networks (DNNs) are able to achieve zero training error when trained on datasets with label noise, even in the extreme scenario of totally randomized labels \cite{zhang2016understanding}.
This poses a challenge when training on real-world datasets. Manual data labeling 
is both inefficient and expensive, while automated annotation methods inherently introduce label noise. 
In either case, we typically have access to a small clean subset of the dataset.
For such datasets with label noise, how then do we train DNNs that generalize well, regardless of the actual (unknown) noise levels?

Label noise in real-world datasets is inevitably asymmetric. This asymmetry naturally arises because the performance of any data annotation method that is based on the output labels of a prediction model, is necessarily both class-dependent and instance-dependent \cite{Cheng2018:SurveyAutoImageAnnotation}. Although there are numerous existing methods for tackling label noise~\cite{reed2014training, ghosh2017robust, patrini2017making, hendrycks2018using, tanaka2018joint, zhang2018generalized, arazo2019unsupervised, shu2019meta, wang2019symmetric, xu2019l_dmi, zhang2019metacleaner,li2020dividemix,ma2020normalized}, all of which perform well in the idealized case of symmetric label noise (provided the noise level is not too high), these existing methods are not as robust to asymmetric label noise, and they exhibit a sharp performance drop at medium-to-high noise levels.

Despite much progress on tackling label noise, there are two seemingly opposing challenges that have not been tackled jointly: How do we train a model that is (i) robust to all noise levels, and (ii) whose performance at any given noise level is not sensitive to any variation in the noise model?


To solve both challenges via a unified approach, we propose a distillation-based framework that incorporates a new method of Positive-Unlabeled (PU) learning. 
In general, we have a trade-off between increasing accuracies across all noise levels for a given noise model, and increasing accuracies across all noise models for a given noise level. 
Our motivation to use PU learning is based on the observation that samples of any dataset with label noise can naturally be partitioned into ``correct" and ``incorrect" classes.
Clean data is correct by definition, while the remaining noisy dataset contains both correct and incorrect instances.
This is precisely the scenario of PU learning, where instances in the noisy dataset are treated as ``unlabeled".

Our framework comprises two components: clean data augmentation and knowledge distillation.
Starting with our given clean subset, we initially treat all instances with noisy labels (henceforth called ``noisy samples'') as being unlabeled, and we gradually augment the original clean subset, iteratively, via PU learning; those (unlabeled) noisy samples inserted into our augmented clean set would be assigned new labels. 
Crucially, this new label assignment does not require the originally given labels of the noisy samples. 
In other words, we \emph{do not require any assumptions on the underlying noise model.} Hence, this clean data augmentation component is automatically robust to all noise models. 
As for our distillation component, we train a teacher model solely on the augmented clean set, thus we are able to suppress the influence of label noise when training the student model, especially at high noise levels.

Our major contributions are summarized as follows:
\begin{itemize}
\item We propose a versatile distillation-based framework for tackling label noise.
In contrast to existing work, our framework is robust to all noise levels, and is not sensitive to noise model variation. To the best of our knowledge, this is the first ever solution that overcomes both major challenges we described earlier.

\item We introduce a new type of PU learning.
We then use this new technique to design a clean data augmentation algorithm, which also allows us to correct noisy samples with high confidence.
The effectiveness of our augmentation algorithm is demonstrated by the high precision scores of reliably clean samples extracted from the validation set.

\item In experiments on CIFAR-10 \cite{krizhevsky2009learning} with asymmetric semantic label noise, our proposed framework outperformed outperforms state-of-the-art (SOTA) methods at noise levels --. When evaluated on the real-world noisy dataset Clothing1M~\cite{xiao2015learning}, we achieved a new SOTA accuracy of 77.70\% (2.94\% higher than previous SOTA).
\end{itemize}

\section{Related Work}
\label{sec: related work}
\subsection{Existing Approaches for Tackling Label Noise}
\noindent\textbf{Data cleaning methods.} 
These are methods applied to identified noisy labels, and they include 
label correction~\cite{tanaka2018joint}, sample re-weighting~\cite{shu2019meta, jiang2018mentornet, zhang2019metacleaner}, 
label distribution estimation~\cite{yi2019probabilistic}, re-sampling of a relabeled dataset~\cite{wu2018light}, and treating ambiguous samples as unlabeled data and applying a semi-supervised method~\cite{Ding2018AST}.
The efficacy of such methods depends heavily on the identification of noisy labels, which is inherently a difficult problem as DNNs easily overfit noisy labels.

\noindent\textbf{Methods with robust loss functions.} There are numerous loss functions proposed to alleviate the influence of label noise. These include symmetric loss~\cite{ghosh2017robust}, variants of cross-entropy (CE) loss (generalized CE loss~\cite{wang2019symmetric}, symmetric CE loss~\cite{wang2019symmetric}, Taylor CE loss~\cite{feng2020can}), bootstrap loss~\cite{arazo2019unsupervised, reed2014training}, bilevel-optimization-based loss~\cite{jenni2018deep}, information-theoretic loss~\cite{xu2019l_dmi}, SIGUA loss~\cite{han2020sigua}. See also \cite{ma2020normalized} for a general framework for combining loss functions to enhance robustness to label noise.


\noindent\textbf{Noise model estimation methods.}
Label noise is modeled either explicitly by a noise transition matrix \cite{hendrycks2018using, patrini2017making}; or implicitly via graphical models \cite{xiao2015learning}, knowledge graphs \cite{li2017learning}, conditional random fields \cite{Vahdat2017toward}, residual nets \cite{hu2019weakly}, or joint embedding networks \cite{lee2018cleannet}. 
Once an underlying noise model has been well-estimated, the true labels can then be inferred with high confidence. 
For example, a good estimation of the noise transition matrix can be achieved by adding an extra noise model over the base model and simultaneously training both models \cite{jindal2016learning, sukhbaatar2014training}, 
albeit with certain strong assumptions.


\subsection{Preliminaries}
\label{preliminaries}
\textbf{Knowledge distillation} was first proposed by Hinton \textit{et al.} \cite{hinton2015distilling} for model compression,  
whereby the knowledge learned by a large teacher model , is transferred to another smaller student model , by applying a weighted average of two objective functions as follows:
\vspace*{-0.1em}

\vspace*{-1.1em}

\noindent where  is the traditional loss function, and  is a parameter to balance the effect of the given labels and the outputs of the teacher model.

Assuming that a subset  of a given dataset is known to have correct labels, Li \textit{et al.} \cite{li2017learning} proposed a distillation-based method, where the teacher model  is trained on  and the student model  is subsequently trained using the loss function in \eqref{distillation_loss_function}. 
Hence, the student model would have a higher accuracy compared to the same model trained directly on the noisy dataset, as long as the error rate of the teacher model is less than the noise rate of the dataset.

A key merit of this distillation-based method is that it can be flexibly built on top of any algorithm for training the teacher and student models.
However, their method has two drawbacks: (i) The noisy labels remain invariant in the objective function, which affects the performance of the student model;
(ii) It requires a large clean set (e.g. the values  and  were used in their experiments) to train a sufficiently accurate teacher model. 

\textbf{PU learning} is a special type of semi-supervised learning that involves training a binary classifier on a set of positive data  and a set of unlabeled data ~\cite{li2005learning}. 
Existing PU learning algorithms are classified into four approaches: (i) bias-based, (ii) heuristic-based, (iii) bagging-based, and (iv) risk-based. 

\begin{itemize}
\item A bias-based approach treats  as learnable weighted combinations of ``positive" and ``negative" classes \cite{elkan2008learning}.

\item A heuristic-based approach iteratively selects reliable negative samples from the unlabeled data via a two-step algorithm: (i) identify new reliable negative samples  from ; (ii) train a binary classifier on  and  \cite{liu2002partially}.

\item A bagging-based approach uses an ensemble of classifiers trained on bootstrap subsets \cite{mordelet2014bagging}.

\item A risk-based approach estimates the misclassification risk by replacing the risk of negative samples with risk in terms of  and  given class prior \cite{du2014analysis}.
\end{itemize}

\textbf{Mixup} \cite{zhang2017mixup} is a data augmentation method proposed to favor linear relations on the samples, which involves augmenting the training dataset with convex combinations of pairs of examples and their labels. Specifically, given a pair of samples, (, ) and (, ), the augmented sample is generated via
\vspace*{-0.1em}

\vspace*{-1.1em}

\noindent where  follows a beta distribution for some parameter . We used  in our experiments.

\textbf{Entropy regularization} \cite{tanaka2018joint} is introduced to concentrate the distribution of each prediction vector to one peak:

where  is the number of instances,  is the number of classes, and  is the -th entry of the output vector.
\section{Proposed Framework}
\label{sec: proposed method}

Consider a -class noisy dataset with a small portion of clean set known to have correct labels. We denote the dataset by , where  and  represent this small clean set and the remaining noisy set, respectively.

\begin{algorithm}[H]
\caption{Proposed Method}\label{alg:algorithm}
\textbf{Inputs}: Number of classes , clean set , noisy set , number of iterations , number of ensemble models , positive threshold , reliability criterion , number of teacher models . \\
\textbf{Intermediate teacher models}:  ().\\
\textbf{Output}: Student classifier .\
\hat{\mathcal{P}}^{(i)}=\left\{x\in\mathcal{D}_n
\,\middle\vert\, 
 \vert \{n \mid f^{(i)}_n(x)\geq\alpha \} \vert \geq \theta \right\},

\label{soft bootstrap label formulation}
\hat{y}_j=\lambda(x_j)f_t(x_j)+(1-\lambda(x_j))y_j,

\label{casewise parameter}
\lambda(x_j) =
\begin{cases}
\lambda, &\mbox{if } \max(f_t(x_j))\geq\eta; \\
0, & \mbox{if } \eta > \max(f_t(x_j));
\end{cases}

\label{hard label formulation}
\hat{y}_j =
\begin{cases}
\operatorname{argmax} \ \ f_t(x_j), &\mbox{if } \max(f_t(x_j))\geq\eta; \\
\operatorname{argmax} \ \ y_j, & \mbox{if } \eta > \max(f_t(x_j)).
\end{cases}
-1.5em]}
\label{teacher model}
\centering
\begin{tabular}{lrr|rr}
\toprule
\multirow{2}{*}{} & \multicolumn{2}{c|}{CIFAR10} & \multicolumn{2}{c}{Clothing1M} \\ \cmidrule{2-5}
 & Accuracy (\%) & Size   & Accuracy (\%)   & Size \\ \midrule
0.9 & 99.3   & 1,313  & 94.6  & 5,635   \\
0.8 & 98.0   & 4,845  & 91.3  & 8,219   \\
0.7 & 95.6   & 6,492  & 88.1  & 9,950   \\
0.6 & 93.0   & 7,561  & 85.1  & 11,407  \\
0.5 & 89.8   & 8,487  & 82.0  & 12,808  \\
0.0 & 82.5   & 10,000 & 77.7  & 14,313  \\ \bottomrule
\end{tabular}
\end{table}



\subsection{Comparison between Different Ratios of Clean Set}
\begin{figure}[tb]
\centering
\includegraphics[width=80mm]{comparison_clean_ratio.png}
\caption{Comparison of the best test accuracies (average of 5 trials) corresponding to different clean ratios  on  CIFAR-10 with symmetric noise (upper) and asymmetric noise (lower). All experiments were implemented using soft-bootstrap pseudo-labels.}
\label{Comparison clean ratio}
\end{figure}







We applied bootstrapping when training the teacher model on the augmented clean set to (i) mitigate the problem of imbalance, and (ii) reduce the training time. Specificically, we sampled a balanced subset of the augmented clean set in each epoch, and trained the teacher model on the bootstrap subset, instead of the entire augmented clean set. In order to improve robustness, we also used mixup data augmentation and entropy regularization (cf. Section \ref{preliminaries}) to train the teacher models and student model. The detailed ablation study and elaboration of the effectiveness of each technique is given in Section \ref{ablation study}.

\begin{figure}[htb!]
\centering
\includegraphics[width=80mm]{comparison_label_type.png}
\caption{Comparison of the best test accuracies (average of 5 trials) corresponding to different types of pseudo-labels on CIFAR-10 with symmetric noise (upper) and asymmetric noise (lower). We fixed  and  in the experiments.}
\label{Comparison types of label}
\end{figure}

\subsection{Evaluation of Augmented Clean Set}
To show the effectiveness of our clean data augmentation algorithm, we reported the precision and number of augmented clean samples in TABLE \ref{Table of augmented clean set}, where the results were evaluated on test set for CIFAR-10 and validation set for Clothing1M. As described in Section \ref{clean data augmentation}, we introduced a threshold  to filter ``positive" samples, and a hyperparameter  to control the size of augmented clean set. In our experiment, we fixed ,  (out of 20) for CIFAR-10, and ,  (out of 10) for Clothing1M. Our method extracted more than 40\% samples while achieved overall precision 0.94 and 0.85 for CIFAR-10 and Clothing1M, respectively. 





\subsection{Evaluation of Teacher Model}
As given in \eqref{soft bootstrap label formulation}--\eqref{hard label formulation}, 
the teacher model is used to generate pseudo-labels for the training of the student model.
In order to guarantee the accuracy of the pseudo-labels, we only modified the labels of samples in , while the pseudo-labels of the remaining samples were kept as the given labels.
Here  is the average output vector of 5 models, and  is the threshold to control the confidence level of the ensemble teacher model.
We evaluated the ensemble teacher model for different values of ; see TABLE \ref{teacher model}.



\begin{table}[!tb]
\caption{Best test accuracies of different methods on the Clothing1M dataset. For all baselines, we use the reported results in the respective papers.\-1.5em]}
\label{ablation teacher}
\centering
\begin{tabular}{lrr}
\toprule
Methods  & CIFAR-10 & Clothing1M \\\midrule
Standard & 76.881.82   & 77.270.11  \\\midrule
+ mixup  & 80.682.48   & 77.570.05  \\\midrule
+ bootstrap    & 77.311.16   & 76.970.47 \\\midrule
+ entropy reg. + bootstrap & 77.121.30   & 77.680.04  \\\midrule
+ mixup + bootstrap    & 81.051.70   & 77.750.10 \\\midrule
+ mixup + bootstrap + entropy reg. & 81.451.45   &  77.180.05  \\
\bottomrule
\end{tabular}
\end{table}



\subsection{Comparison between Different Types of Pseudo-labels}
To show the difference between three types of pseudo-labels introduced in \eqref{soft bootstrap label formulation}--\eqref{hard label formulation}, we compared the best test accuracies on CIFAR-10 with different levels of symmetric noise and asymmetric noise in Fig. \ref{Comparison types of label}.
For both symmetric and asymmetric noise, hard label performed worse than two bootstrap labels at low noise levels, and hard bootstrap label had a similar performance compared with soft bootstrap label.
Intuitively, hard label resulted in lower accuracies because it failed to take the given label into consideration for those samples with high confidence, i.e. . However, this problem was mitigated by the case-wise pattern of pseudo-labels, where the pseudo-label was only assigned to those samples that teacher model was confident on, and the labels of the remaining samples remained the given labels. Hence this case-wise pattern can avoid introducing additional noise because of inaccurate teacher model, and it happened to shorten the gap between hard labels and the other two bootstrap labels.



As described previously, our method uses an initial small clean set , with proportion . To study the effect of  on the test accuracy, we applied our algorithm to CIFAR-10 with different noise levels for both symmetric and asymmetric noise. \mbox{Fig. \ref{Comparison clean ratio}} shows that the gap between curves of different clean ratios is not large under low noise levels, and our method performs well even with only a  clean set. However, at high noise levels, the curves for low clean ratios dramatically dropped, especially for asymmetric noise, while the curve for  clean ratio was relatively flat. 



\subsection{Comparison with State-of-the-art}
\subsubsection{Experiments on CIFAR-10}
\begin{table*}[!tb]
\caption{Average (5 trials) and standard deviation of the best test accuracies  of different methods on the CIFAR-10 dataset with semantic asymmetric noise. The highest accuracy for each noise level is boldfaced.}
\label{cifar_asyn}
\centering
\begin{tabular}{lrrrrrrr}
\toprule
\multirow{2}{*}{Method} & \multicolumn{7}{c}{Noise Level (\%)} \\ \cmidrule{2-8} 
  & 30  & 40  & 50  & 60  & 70  & 80  & 90  \\ \midrule
Cross Entropy   & 88.300.42 & 84.280.65 & 77.401.52 & 67.541.21 & 61.720.30 & 57.240.31 & 52.700.21   \\ \midrule
Mixup\cite{zhang2017mixup}  & 90.530.70 & 86.591.13 & 78.670.93 & 69.191.16 & 62.521.32 & 57.902.1 & 53.300.80    \\ \midrule
Joint Optimization\cite{tanaka2018joint}  & 92.010.21 & \textbf{89.560.78} & 84.560.94 & 78.210.32 & 76.700.11 & 76.440.21 & 76.000.14  \\ \midrule
Co-teaching\cite{han2018co}  & 84.500.41 &	70.693.53 &	54.291.30 &	48.760.92 &	46.400.89 &	45.661.77 &	44.391.53 \\\midrule
Loss Correction\cite{arazo2019unsupervised}  & 90.870.23 & 87.210.22 & 74.631.08 & 58.821.08 & 58.060.09 & 53.723.32 & 53.043.59    \\ \midrule
JoCoR\cite{wei2020combating}  &76.572.67 &	67.744.23 	& 56.541.22 &	48.521.84 &	46.220.80 & 43.740.81 & 43.061.89 \\ \midrule
DivideMix\cite{li2020dividemix}  & \textbf{93.950.06} & 84.430.94 & 73.731.07 & 60.132.40 & 53.183.99 & 50.600.546 & 49.420.33 \\ \midrule
Our Method &  90.000.22 & 88.220.26 & \textbf{85.980.45} & \textbf{84.410.15} & \textbf{83.770.12} & \textbf{83.000.10} & \textbf{82.630.25} \\ 
 \bottomrule
\end{tabular}
\end{table*}


\begin{figure*}[tb]
\centering
\includegraphics[width=180mm]{Comparison_sym_asym.png}
\caption{Comparison of the performance of different methods under symmetric noise and asymmetric noise. The noise level here refers to overall noise level within the dataset, e.g.  asymmetric noise would correspond to  overall noise level. }
\label{cifar_fig}
\end{figure*}





We reproduced the results of the baselines \cite{tanaka2018joint,arazo2019unsupervised,zhang2017mixup,han2018co,wei2020combating, li2020dividemix} using the same configuration that we used to evaluate our proposed method: 
(i) We used the same architecture, Pre-Activation ResNet-18 \cite{he2016identity}; 
(ii) We multiplied the noise level in \cite{han2018co, wei2020combating} by a factor 0.9, and multiplied the noise level in our method with a factor  to keep the expected proportion of incorrect labels equal across all methods. 
The comparison results between our method and all the baselines on the CIFAR-10 dataset with asymmetric noise are reported in TABLE \ref{cifar_asyn}.

To evaluate the robustness of each method against different noise models, we compared the accuracies of each mothod with different noise levels for symmetric and asymmetric noise in \mbox{Fig. \ref{cifar_fig}}. As claimed in Section \ref{dataset}, the noise level of asymmetric defined in \cite{patrini2017making} is the class noise level within the corrupted classes, hence the overall noise level of the dataset is actually . In order to compare the performance of each method between symmetric model and asymmetric model, we need to modify the noise level of asymmetric noise by a factor . The curves corresponding to symmetric and asymmetric noise model of our method were very close and flat across all of the noise levels. However, the gap between two lines for other 7 baselines became larger as the noise level increased, and the curves of some methods dramatically dropped, especially under asymmetric case. Our method is robust not only over all noise levels but also against different noise models because of the effectiveness of the clean data augmentation step. By treating all the noisy samples as unlabeled samples and applying a tired PU learning method, our augmentation process is totally independent of the given noisy labels, thereby explaining this robustness. 




\subsubsection{Experiments on Clothing1M}


We directly compared our experiment result with accuracies reported in papers that used the same model architecture, i.e. a ResNet-50 \cite{he2016identity} pre-trained on ImageNet; see TABLE \ref{clothing reuslt}. 
We trained the student model over 5 epochs and achieved a highest test accuracy 77.70\%; this is the highest accuracy among all methods in TABLE \ref{clothing reuslt}.


\subsection{Ablation Study}
\label{ablation study}
To study the effect of mixup data augmentation, bootstrapping, and entropy regularization on our method, we conducted an ablation study on the teacher model (see TABLE \ref{ablation teacher}) and student model (see TABLE \ref{ablation student}), where the ``standard" method means our method without any of these three techniques. Below, we consolidate some insights obtained.

\begin{itemize}
\item All three techniques helped to improve the accuracies slightly. Mixup data augmentation has the largest effect.
\item The effect of mixup is more significant under symmetric noise than under asymmetric noise. Intuitively, mixup improves the robustness to label noise because the combination of a pair of samples might partially correct the wrong labels when one sample accidentally contains the true label of the other noisy sample. For asymmetric noise, the label flips occur only between similar classes, so ``accidental label correction" is less likely.
\end{itemize}
  







\section{Conclusion and Further Remarks}
Our proposed framework is robust to all noise levels. This robustness is universal since the performance at any given noise level is not sensitive to variations in the noise model. 
We achieved state-of-the-art accuracy on Clothing1M, a dataset with real-world label noise, and our experiments on CIFAR-10 with asymmetric semantic label noise show superior outperformance over all baselines. 
Crucially, we achieve universal robustness because our clean data augmentation process does not use the labels of noisy samples; we only require a small clean subset. 
Our framework can be built on top of any classification algorithm (not necessarily using DNNs). Therefore, our framework is versatile, robust, and widely applicable to any classification tasks for datasets with arbitrary label noise.



\begin{table*}[!tb]
\caption{Ablation study results in terms of student model's test accuracy (\%) on CIFAR-10. We set the ratio of original clean set=0.1, , and .\-1.5em]}

\label{ablation student}
\centering
\begin{tabular}{lrrrrrrrr}
\toprule
Noise type           & \multicolumn{4}{c}{Symmetric} & \multicolumn{4}{c}{Asymmetric} \\ \midrule
Method/Noise level   & 30\%  & 50\%  & 70\%  & 90\%  & 30\%   & 50\%  & 70\%  & 90\%  \\\midrule
Standard & 84.740.32 &  81.060.33 & 77.390.37 & 73.290.66  & 87.320.47 & 82.910.46 & 76.340.84 & 70.321.76  \\ \midrule
+Mixup & 88.900.23 &  85.340.34 & 81.820.19 & 76.940.45 & 89.300.27 & 84.930.32 & 77.721.50 & 71.252.51 \\\midrule
+Entropy reg. & 86.520.21 &  83.260.36 & 79.680.38 & 74.580.40 & 87.410.23 & 82.980.44 & 76.161.14 & 70.331.93  \\\midrule
+Mixup +Entropy reg. & 90.100.17 &  87.120.26 & 83.520.10 & 78.880.49 & 90.000.22 & 85.660.26 & 77.201.61 & 70.522.73 
 \\\midrule
\bottomrule
\end{tabular}
\end{table*}


\bibliographystyle{IEEEtran}

\bibliography{bibliography}

\end{document}
