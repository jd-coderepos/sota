\subsection{Speech Classification}
Table \ref{main_result} shows the result of SpeechPrompt v2 (GSLM+ and pGSLM+) on a wide variety of speech processing tasks. 
We show that when using either GSLM or pGSLM as the backbone spoken LMs, SpeechPrompt v2 achieves competitive performance on all content-related speech classification tasks. 
On the other hand, SpeechPrompt v2 can also generalize well across different languages, as we achieve new state-of-the-art results on low-resource Lithuanian SC and Arabic SC~\cite{DBLP:journals/corr/abs-2110-03894}.
Our framework falls slightly behind the prior works for prosody-related tasks but is still competitive. We find that with prosody informed, pGSLM outperforms GSLM in most prosody-related tasks, demonstrating the necessity of diverse spoken LMs for downstream tasks with different properties.
However, we can observe that the prompting method does not perform well for more challenging tasks (FSD and ER), where both content and prosody information must be considered simultaneously.
Moreover, our framework fails to perform well on the audio classification task (AuC) but achieves a comparable result on VAD. We argue that the spoken LMs cannot properly model the non-speech information but are still capable of separating the speech and non-speech patterns.
The result also shows that, empirically, using a learnable verbalizer in our framework steadily improves the performance, which indicates alleviating the information loss problem in the unit-to-class mapping process.
Overall, SpeechPrompt v2 demonstrates competitive results on various speech classification tasks, and the learnable verbalizer improves performance in most cases. Following, we further analyze the behavior of the verbalizer to get more insight into the label mapping process in prompting for speech processing.

\

\begin{figure}[t]
    \centering
    \subfloat[Class ``YES'']{
        \includegraphics[width=\linewidth]{assets/analyzing_verbalizer_class_yes.pdf}
    }
    
    \subfloat[Class ``LEFT'']{
        \includegraphics[width=\linewidth]{assets/analyzing_verbalizer_class_left.pdf}
    }
    \caption{The SHAP analysis of the learnable verbalizer on the Google Speech Command dataset~\cite{vygon2021learning}. Each point refers to one datapoint.} \label{fig:analyzing_verbalizer}
    \vspace{-15pt}
\end{figure}

\vspace{-0.5em}
\subsection{Learnable Verbalizer Analysis}
In this section, we further inspect the behavior of the learnable verbalizer to see how it maps the discrete units to meaningful task labels. Specifically, we adopt Shapley Additive exPlanation~\cite{lundberg2017unified} (SHAP), a popular method to interpret model predictions. In SHAP, the \textbf{SHAP value} is calculated to measure the importance of each input feature, here referring to the discrete unit, to a single prediction made by the model. 

Fig.\ref{fig:analyzing_verbalizer} shows the result of SCR on Google SC dataset for three different runs. We list the top 10 units contributing to the class ``YES'' and the class ``LEFT'' 
\footnote{Please refer to our project website for more demonstration. \url{https://ga642381.github.io/SpeechPrompt}}.
In each chart, the horizontal axis is the SHAP value, while the vertical axis indicates the order of importance of each unit from top to bottom. 
Each point refers to the interpretation of a single datapoint. The color of a point reflects the magnitude of the value for each input unit.
First, we observe that even in the same class, the importance of each unit varies from prediction to prediction. And the learnable verbalizer relies on multiple units to determine the output, indicating a many-to-many mapping behavior from units to labels. This verifies the possible information loss in the previous work, as described in sec\ref{sec:learnable_verbalizer}.
Moreover, the relationship between units and labels does not remain consistent in different runs. 
However, there are units in common and their contribution pattern is similar in different runs (e.g. unit 98 has the same pattern for class ``YES'').
Last, the learnable verbalizer might use one unit to separate different classes. For example, when unit 98 has a lower value, the verbalizer is more likely to predict class ``LEFT'' instead of class ``YES''.
Overall, the analysis suggests that using a learnable verbalizer offers benefits over naive random mapping and frequency-based mapping and is more ideal for our framework. 




























