\pdfoutput=1
\documentclass[runningheads]{llncs}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{color}
\usepackage{ae}
\usepackage[ruled]{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage[breaklinks,bookmarks=false]{hyperref}

\usepackage{thmtools,thm-restate}

\DeclareMathOperator{\bord}{border}
\DeclareMathOperator{\period}{period}
\DeclareMathOperator{\prefix}{prefix}
\DeclareMathOperator{\suffix}{suffix}
\DeclareMathOperator{\nr}{nr}
\DeclareMathOperator{\rank}{rank}

\newcommand{\twodots}{\mathinner{\ldotp\ldotp}}
\newcommand{\id}[1]{\ensuremath{\mathit{#1}}}
\newcommand{\proc}[1]{\textnormal{\scshape#1}}

\begin{document}

\title{Pattern matching in Lempel-Ziv compressed strings: fast, simple, and deterministic\thanks{Supported by MNiSW grant number N~N206 492638, 2010--2012}}
\titlerunning{Pattern matching in Lempel-Ziv compressed strings}

\author{Pawe\l{} Gawrychowski}
\institute{Institute of Computer Science,\\
	University of Wroc{\l}aw,\\
	ul. Joliot-Curie 15, 50--383 Wroclaw,
	Poland \\
	\email{gawry@cs.uni.wroc.pl}
	}

\maketitle
\begin{abstract}
Countless variants of the Lempel-Ziv compression are widely used in many real-life applications. This paper is concerned with a natural modification of the classical pattern matching problem inspired by the popularity of such compression methods: given an uncompressed pattern  and a Lempel-Ziv representation of a string , does  occur in ? Farach and Thorup~\cite{Farach} gave a randomized  time solution for this problem, where  is the size of the compressed representation of . Building on the methods of~\cite{CharikarApproximation} and~\cite{GawrychowskiLZW}, we improve their result by developing a faster and fully deterministic  time algorithm with the same space complexity. Note that for highly compressible texts,  might be of order , so for such inputs the improvement is very significant. A (tiny) fragment of our method can be used to give an asymptotically optimal solution for the substring hashing problem considered by Farach and Muthukrishnan~\cite{FarachHashing}.

\textbf{Key-words}: pattern matching, compression, Lempel-Ziv
\end{abstract}

\section{Introduction}

Effective compression methods allow us to decrease the space requirements which is clearly worth pursuing on its own. On the other hand, we do not want to store the data just for the sake of having it: we want to process it efficiently on demand. This suggest an interesting direction: can we process the data without actually decompressing it? Or, in other words, can we speed up processing if the compression ratio is high? Answer to such questions clearly depends on the particular compression and processing method chosen. In this paper we focus on Lempel-Ziv (also known as LZ77, or simply LZ for the sake of brevity), one of the most commonly used compression methods being the basis of the widely popular \texttt{zip} and \texttt{gz} archive file formats, and on pattern matching, one of the most natural text processing problem we might encounter. More specifically, we deal with the compressed pattern matching problem: given an uncompressed pattern  and a LZ representation of a string , does  occur in ? This line of research has been addressed before quite a few times already. Amir, Benson, and Farach~\cite{Amir} considered the problem with LZ replaced by Lempel-Ziv-Welch (a simpler and easier to implement specialization of LZ), giving two solutions with complexities  and , where  is the size of the compressed representation. The latter has been soon improved~\cite{Kosaraju} to . Then Farach and Thorup~\cite{Farach} considered the problem in its full generality and gave a (randomized)  time algorithm for the LZ case. Their solution consists of two phases, called {\it winding} and {\it unwinding}, the first one uses a cleverly chosen potential function, and the second one adds fingerprinting in the spirit of string hashing of Karp and Rabin~\cite{KarpRabin}. While a recent result of~\cite{Iacono} shows that the winding can be performed in just , it is not clear how to use it to improve the whole running time (or remove randomization).  In this paper we take a completely different approach, and manage to develop a  time algorithm. This complements our recent result from SODA'11~\cite{GawrychowskiLZW} showing that in case of Lempel-Ziv-Welch, the compressed pattern matching can be solved in optimal linear time. The space usage of the improved algorithm is the same as in the solution of Farach and Thorup, .

Besides the algorithm of Farach and Throup, the only other result that can be applied to the LZ case we are aware of is the work of Kida \emph{et al.}~\cite{Kida}. They considered the so-called \emph{collage systems} allowing to capture many existing compression schemes, and developed an efficient pattern matching algorithm for them. While it does not apply directly to the LZ compression, we can transform a LZ parse into a non-truncating collage system with a slight increase in the size, see section~\ref{section:constructing}. The running time (and space usage) of the resulting algorithm is . While  might be acceptable from a practical point of view, removing the quadratic dependency on the pattern length seems to be a nontrivial and fascinating challenge from a more theoretical angle, especially given that for some highly compressible texts  might be much smaller than . Citing~\cite{Kida}, even decreasing the dependency to  (the best preprocessing complexity known for the LZW case~\cite{Kosaraju} at the time) ``is a challenging problem''.

While we were not able to achieve linear time for the general LZ case, the algorithm developed in this paper not only significantly improves the previously known time bounds, but also is fully deterministic and (relatively) simple. Moreover, LZ compression allows for an exponential decrease in the size of the compressed text, while in LZW  is at least . In order to deal with such highly compressible texts efficiently we need to combine quite a few different ideas, and the nonlinear time of our (and the previously known) solution might be viewed as an evidence that LZ is substantially more difficult to deal with than LZW. While most of those ideas are simple, they are very carefully chosen and composed in order to guarantee the  running time. We believe the simplicity of those basic building blocks should not be viewed as a drawback. On the contrary, it seems to us that improving a previously known result (which used fairly complicated techniques) by a careful combination of simple tools should be seen as an advantage. We also argue that in a certain sense, our result is the best possible: if integer division is not allowed, our algorithm can be implemented in  time, and this is the best time possible.

\section{Overview of the algorithm}

Our goal is to detect an occurrence of  in a given Lempel-Ziv compressed text . The Lempel-Ziv representation is quite difficult to work with efficiently, even for a such simple task as extracting a single letter. The starting point of our algorithm is thus transforming the input into a {\it straight-line program}, which is a context-free grammar with each nonterminal generating exactly one string. For that we use the method of Charikar {\it et al.}~\cite{CharikarApproximation} to construct a SLP of size  with additional property that all productions are {\it balanced}, meaning that the right sides are of the form  with  for some constant , where  is the length of the (unique) string generated by . Note that Rytter gave a much simpler algorithm~\cite{RytterApproximation} with the same size guarantee, using the so-called AVL grammars but we need the grammar to be balanced. We also need to add a small modification to allow self-referential LZ.

After transforming the text into a balanced SLP, for each nonterminal we try to check if the string it represents occurs inside , and if so, compute the position of (any) its occurrence. Otherwise we would like to compute the longest prefix (suffix) of this string which is a suffix (prefix) of . At first glance this might seem like a different problem that the one promised to solve: instead of locating an occurrence of the pattern in the text, we retrieve the positions of fragments of the text in the pattern. Nevertheless, solving it efficiently gives us enough information to answer the original question due to a constant time procedure which detects an occurrence of  in a concatenation of two its substrings. 

The first (simple) algorithm for processing a balanced SLP we develop requires as much as  time per query, which results in  total complexity. This is clearly not enough to beat~\cite{Farach} on all possible inputs. Hence instead of performing the computation for each nonterminal separately, we try to process them in  groups corresponding to the (truncated) logarithm of their length. Using the fact that the grammar is balanced, we are then able to achieve  time.  Because of some technical difficulties, in order to decrease this complexity we cannot really afford to check if the represented string occurs in  for each nonterminal exactly, though. Nevertheless, we can compute some approximation of this information, and by using a tailored variant of binary search applied to all nonterminals in a single group at once, we manage to process the whole grammar in time proportional to its size while adding just  to the running time. 



\section{Preliminaries}

The computational model we are going to use is the standard RAM allowing direct and indirect addressing, addition, subtraction, integer division and conditional jump with word size . One usually allows multiplication as well in this model but we do not need it, and the only place where we use integer division (which in some cases is known to significantly increase the computational power), is the proof of Lemma~\ref{lemma:balanced construction}.

We do not assume that any other operation (like, for example, taking logarithms) can be performed in constant time on arbitrary words of size . Nevertheless, because of the  addend in the final running time, we can afford to preprocess the results on words of size  and hence assume that some additional (reasonable) operations can be performed in constant time on such inputs.

As usually,  stands for the length of ,  refers to its fragment of length  beginning at the -th character, where characters are numbered starting from . All strings are over an alphabet  of polynomial cardinality, namely .  A border of  is a fragment which is both a prefix and a suffix of , i.e., . We identify such fragment with its length and say that  is the set of all borders of . A period of a string  is an integer  such that  for all . Note that  is a period of iff  is a border. The following lemma is a well-known property of periods.

\begin{lemma}[Periodicity lemma]\label{lemma:periodicity}
If  and  are both periods of , and , then  is a period as well.
\end{lemma}

The Lempel-Ziv representation of a string  is a sequence of triples  for , where  is the size of the representation.  and  are nonnegative integers, and . Such triple refers to a fragment of the text  and defines . We require that  if . The representation is not self-referential if all fragments we are referring to are already defined, i.e.,  for all . The sequence of triples is often called the {\it LZ parse} of text.

{\it Straight-line program} is a context-free grammar in the Chomsky normal form such that the nonterminals  can be ordered in such a way that each  occurs exactly once as a left side, and whenever  it holds that . We identify each nonterminal with the unique string it derives, so  stands for the length of the string derived from . We call a straight-line program (SLP) {\it balanced} if for each production  both  and  are bounded by a constant fraction of .

We preprocess the pattern  using standard tools (suffix trees~\cite{Ukkonen} built for  and reversed , and LCA queries~\cite{BenderLCA}) to get the following primitives.

\begin{lemma}\label{lemma:equality}
Pattern  can be preprocessed in linear time so that given  representing any two fragments  and  we can find their longest common prefix (suffix) in constant time.
\end{lemma}

\begin{restatable}{lemma}{lemmalongestsuffix}
\label{lemma:longest suffix}
Pattern  can be preprocessed in linear time so that given any fragment  we can find its longest suffix (prefix) which is a prefix (suffix) of the whole pattern in constant time, assuming we know the (explicit or implicit) vertex corresponding to  in the suffix tree built for  (reversed ).
\end{restatable}

\begin{proof}
We assume that the suffix tree is built for  concatenated with a special terminating character, say ssSAssSA\{1,2,\ldots,|s|\}wiSAws[SA[i]\twodots |s|]SAwws[i\twodots j]i=1j=m|s|s(i,j)tb\geq\frac{|t|}{2}\frac{|t|}{2}\bord(t)\cap\left\{\frac{|t|}{2},\ldots,|t|\right\}=\left\{|t|-\alpha p: 0\leq\alpha\leq\frac{|t|}{2p} \right\}p=|t|-bttss^rsss[1\twodots i]s[j\twodots m]x\in border(s[1\twodots i])y\in border(s[j\twodots m])x+y=mx\geq\frac{|s[1\twodots i]|}{2}y\geq\frac{|s[j\twodots m]|}{2}xx=i-\alpha pp\leq\frac{i}{2}s[1\twodots i]ss[1\twodots i]s[j\twodots m]\alpha p0\leq\alpha\leq\frac{i}{p}s[1\twodots i]s[j\twodots m]k\geq ispks[p+1\twodots m]ss[1\twodots k]\left\lfloor \frac{\min(i,i-j+1)}{p}\right\rfloor p\alpha ps[1\twodots k]ss[j\twodots m]s[1\twodots k]s[j\twodots m]k=ms[k+1]\neq s[k+1-p]aba\alpha ps[1\twodots k]\alpha ps[1\twodots k](\alpha + 1) ps[1\twodots k]\alpha ps[k+1]\neq s[k+1-p]s[k+1-p]s[j\twodots m]s[1\twodots k]s\alpha ps[i-\alpha p\twodots m]s[j\twodots m]|s[i-\alpha p\twodots m]||s_1||s_2|s_1s_2ss_1 s_2\mathcal{O}\left(\max\left(1,\log\frac{|s_1|}{|s_2|}\right)\right)s_1=s[1\twodots i]s_2s_2s_1\log |s_1||s_2||s_1||s_2|2|s_1|s_1s_1ss_1[\frac{|s_1|}{2}\twodots |s_1|]s|s_2|2|s_1|s_2s|s_1|+|s_2|s_1s_1s_2sps_1p\leq \frac{|s_1|}{2}\alpha p\alpha \geq 0ss_2\alpha\alphas_2ss_1|s_2|\geq 2|s_1|s_2s|s_1|s_2s_1ss_2(start_i,len_i,next_i)i=1,2,\ldots,nstart_i+len_i-1\leq\sum_{j<i}len_jn\alpha\mathcal{O}(n\log\frac{N}{n})N0<\alpha\leq 1-\frac{\sqrt{2}}{2}(start_i,len_i,next_i)\alphat[start_i\twodots start_i+len_i-1]t[start_i\twodots start_i+len_i-1]t[1\twodots \sum_{j=1}^{i-1}len_j]L=\sum_{j=1}^{i-1}len_jt[start_i\twodots L]t[start_i\twodots len_i\bmod (L-start_i+1)]next_it[start_i\twodots L]2\log len_it[start_i\twodots len_i\bmod (L-start_i+1)] next_i\sum_{i=1}^{n} \log len_i\log\mathcal{O}(n\log\frac{N}{n})\mathcal{O}(n\log n)\mathcal{O}(n\log N)\mathcal{O}(n\log N)\mathcal{O}(n\log\frac{N}{n})n2eXY\frac{\alpha}{1-\alpha}\leq\frac{|X|}{|Y|}\leq\frac{1-\alpha}{\alpha}\alpha\frac{|X|}{|Y|}\frac{|Y|}{|X|}\alpha=0.25|X|X\log nX\rightarrow YZ\log_b|X|\leq\beta+\max\left(\log_b|Y|,\log_b|Z|\right)\beta\alphab\mathcal{O}(n\log\frac{N}{n}+m)\mathcal{O}(n\log\frac{N}{n}\log m+m)\mathcal{O}(n\log\frac{N}{n}+m\log m)\mathcal{O}(n\log\frac{N}{n}+m)Xs\prefix(X)\suffix(X)ssX\rightarrow YZs\suffix(Y)\prefix(Z)sX=SX\rightarrow YZYZXYZYZs[1\twodots i]Ys[i+1\twodots m]Z\left|\suffix(Y)\right|\geq i\left|\prefix(Z)\right|\geq m-is\suffix(Y)\prefix(Z)nt[1\twodots N]s[1\twodots m]st\mathcal{O}(n\log\frac{N}{n}\log m+m)X\prefix(X)\suffix(X)YZX\rightarrow YZYZs\mathcal{O}(\log m)s\prefix(X)\suffix(X)\mathcal{O}(\log m)\mathcal{O}(\log m)\mathcal{O}(m\log m)\mathcal{O}(m\log m)\log m\frac{m}{\log m}\frac{m}{\log m}vduv\log Mvud\mathcal{O}(\log m)\log mu\log mssXs[i\twodots i+2^k-1]s[j\twodots j+2^k-1]2^k<|X|\leq 2^{k+1}s[i\twodots i+2^k-1]Xs[j\twodots j+2^k-1]XkXXs\prefix(X)\suffix(X)XsXs\prefix(X)\suffix(X)X\prefix(X)\suffix(X)Xk\mathcal{G}_\ell = \left\{X_1,X_2,\ldots X_s \right\}(\frac{4}{3})^\ell<|X_i|\leq(\frac{4}{3})^{\ell+1}\sum_\ell\left|\mathcal{G}_\ell\right|=\mathcal{O}(n\log\frac{N}{n})\mathcal{G}_1\mathcal{G}_{\ell-1}\mathcal{G}_\ell0.25X_i\rightarrow Y_i Z_i|Y_i|,|Z_i|\leq\frac{3}{4}|X_i|Y_i, Z_i\mathcal{G}_{\ell'}\ell-5 \leq\ell'<\ellY_iZ_iX_i\prefix(X_i)\suffix(X_i)X_i\mathcal{G}_\ellX_iY_iZ_iX_iskk_{min}=\left\lfloor\ell\log\frac{4}{3}\right\rfloor-3\leq k\leq\left\lceil\ell\log\frac{4}{3}\right\rceil=k_{max}s[i\twodots i+2^{k_1}-1]s[j\twodots j+2^{k_2}-1]s\ellk_{min}\leq k_1,k_2\leq k_{max}\mathcal{O}(|\mathcal{G}_\ell|)\mathcal{G}_\ell\left|\mathcal{G}_\ell\right|\{k,k+1,\ldots,k+4\}a,bc,dbc\text{merge}(b,c)ad\text{merge}(b,c)2^k\text{extend}(a)\text{extend}(d)adwa\text{merge}(b,c)\text{extend}(d)2^k\text{merge}(b,c)d2^k\text{extend}(d)sw|w|-|w|\bmod 2^k2^{k'}2^{k'}<|w|\leq 2^{k'+1}k\leq k'ss[i\twodots i+2^{k_1}-1] s[j\twodots j+2^{k_2}-1]s\mathcal{O}(\log m)\mathcal{O}(\left|\mathcal{G}_\ell\right|)s[i\twodots i+2^{k_1}-1]s[j\twodots j+2^{k_2}-1]k_{min}\leq k_1,k_2\leq k_{max}\mathcal{O}(\left|\mathcal{G}_\ell\right|+m^\epsilon)|k_{max}-k_{min}|\in\mathcal{O}(1)2^{k_{min}}\nr(s[i\twodots i+2^{k_{min}}-1])<\nr(s[j\twodots j+2^{k_{min}}-1])s[i\twodots i+2^{k_{min}}-1]) <_{lex} s[j\twodots j+2^{k_{min}}-1])\nr(s[i\twodots i+2^{k_{min}}-1])s[i\twodots m]\mathcal{O}(\left|\mathcal{G}_\ell\right|)\frac{1}{\epsilon}\mathcal{O}(m^\epsilon)2^{k_{min}}m\mathcal{G}_\ell(\frac{4}{3})^\ell > m\mathcal{G}_\ell\mathcal{O}(m^\epsilon\log m+\sum_\ell\left|\mathcal{G}_\ell\right|)=\mathcal{O}(m+n\log\frac{N}{n})\mathcal{O}(|\mathcal{G}_{\ell}|+m)\ellnt[1\twodots N]s[1\twodots m]st\mathcal{O}(n\log\frac{N}{n}+m\log m)m\log mms[i\twodots i+2^k-1]ss[i\twodots i+2^k-1]sTs22^kv2^kTeke2^k2v\Theta(\log |s|)v\text{marked}(v)kv2^kT'=\text{compress}(T)TTT'kikvs[i\twodots |s|]T\text{marked}(v)t=\left\{k' > k : k'\in\text{marked}(v)\right\}tvT'Ts[i\twodots i+2^k-1]2^kT'\log m\frac{m}{\log m}\log m1\log mkvvvkvk1sh_s(s[i\twodots j])h_s(s[i\twodots j])\in[1,\mathcal{O}(|s|^2)]h_s(s[i\twodots j])=h_s(s[k\twodots l])s[i\twodots j]=s[k\twodots l]h_s\mathcal{O}(|s|^3)\mathcal{O}(|s|^3)s\left\lfloor\log x\right\rfloor1\leq x\leq |s|s[i\twodots j]k=\left\lfloor\log(j-i+1) \right\rfloors[i\twodots i+2^k-1]s[j-2^k+1\twodots j]h_s(s[i\twodots j])j-i+1w_{1},w_{2},\ldots,w_{\left|\mathcal{G}_\ell\right|}w=s[i\twodots i+2^{k_1}-1] s[j\twodots j+2^{k_2}-1]s[i\twodots i+2^{k_{min}}-1][a,b]r\mathcal{O}(\log\min(r-a+1,b-r+1))\mathcal{O}(\log(b-a+1))(a,b,w)x \gets ay \gets bk \gets 12^k \leq b-aw <_{lex} s[SA[a + 2^k]]y \gets a + 2^ks[SA[b - 2^k]] <_{lex} wx \gets b - 2^kk \gets k + 1r \gets \text{binary search for } w \text{ in } s[SA[x]\twodots |s|],s[SA[x+1]\twodots |s|],\ldots,s[SA[y]\twodots |s|]r[1,|s|]k_{min}k_{min}\ellk_{min}I_{k_{min}}w_{i}I_{k_{min}}I_{k_{min}}I_{k_{min}}(w_1,w_2,\ldots,w_{\left|\mathcal{G}_\ell\right|})w_iI_{k_{min}}w_iL \gets \emptysetr_0 \gets 1i \gets 1\left|\mathcal{G}_\ell\right|[a,b] \gets \text{the interval corresponding to } w_i[1\twodots 2^{k_{min}}] \text{ in } SA[c,d]\in I_{k_{min}}w_i[c,d]a \gets \max(a,c)b \gets \min(b,d)a \gets \max(r_{i-1}, a)r_i \gets \proc{Two-way-binary-search}(a,b,w_i)[a,r_i][r_i,b]LLI_{k_{min}}r_i\mathcal{O}(\log m)\mathcal{O}(m+\sum_\ell\left|\mathcal{G}_\ell\right|)\mathcal{O}(m^\epsilon+\left|I_{k_{min}} \right|+\left|\mathcal{G}_\ell\right|)\mathcal{O}(m^\epsilon+\left|\mathcal{G}_\ell\right|)\mathcal{O}(\left|I_{k_{min}}\right|+\left|\mathcal{G}_\ell\right|)\mathcal{O}(\left|I_{k_{min}}\right|)w_i\mathcal{O}(\sum_i m^\epsilon + \left|I^{(i)}_{k_{min}} \right|+\left|\mathcal{G}_\ell\right|)\left|I^{(i)}_{k_{min}}\right|I_{k_{min}}i1\leq\ell\leq mk_{min}\ell\mathcal{O}(m+\sum_\ell\left|\mathcal{G}_\ell\right|)v\rank(v)v\mathcal{O}(1+\min(\rank(\text{left}(v)),\rank(\text{right}(v))))\text{left}(v)\text{right}(v)v\sum_{v} \min(\rank(\text{left}(v)),\rank(\text{right}(v)))v\frac{m}{2^k}kuvuvkvvv\frac{m}{2^k}2^kmX\rightarrow YZYZXX\prefix(X), \suffix(X)YZYZ\prefix(X)\suffix(X)\frac{|Y|}{|Z|}\frac{|Z|}{|Y|}\prefix(X)\prefix(Z)Z\suffix(X)\suffix(Y)Y\prefix(X)a,bc,dYZd|d|=2^k\prefix(d)Z\prefix(Z)c\prefix(d)|c|+|d|-|Z|\prefix_1b\prefix_1\prefix_2a\prefix_2|a|+|b|-|Y|\prefix_3uv|v|2|u|\geq\frac{\min(|Y|,|Z|)}{2}|v|\leq |Y|+|Z|\mathcal{O}(1)\prefix(X)YZ\mathcal{O}(n\log\frac{N}{n})s[1\twodots m]s\mathcal{O}(n\log\frac{N}{n}+m)s\mathcal{O}(n\log\frac{N}{n}+m)X\prefix(X)\suffix(X)s\prefix(Y)\suffix(Z)X\rightarrow YZX\prefix(Y)\suffix(Z)nt[1\twodots N]s[1\twodots m]st\mathcal{O}(n\log\frac{N}{n}+m)\mathcal{O}(n\log\frac{N}{n}+m)start_i,len_i0\mathcal{O}(n\log N+m)t,x_1,x_2,\ldots,x_nix_i=(2\alpha_i+1)t+\beta_i0\leq\beta_i<t0\leq \alpha_i< N\Omega(n\log N)(1^t0^t)^N\mathcal{O}(n)(1^t0^t)^N b_1 1 \ldots b_n 1b_i= \left\lfloor\frac{x_i}{t}\right\rfloor\bmod 211x_ix_i=(2\alpha_i+1)t+\beta_i$ and the lower bound follows.





\bibliographystyle{abbrv}
\bibliography{biblio}

\end{document}
