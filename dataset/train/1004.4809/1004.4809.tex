\documentclass[a4paper]{article}

\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{subfigure}
\usepackage{fancyhdr}

\newcommand{\keywords}[1]{\par\addvspace\baselineskip
    \noindent\keywordname\enspace\ignorespaces#1}

\usepackage[left=3cm,right=3cm,top=1.5cm,foot=1cm]{geometry}
 
\pagestyle{fancy}
\fancyhf{}
\fancyfoot[RO]{\thepage}
\fancyfoot[CO]{ - Univsersit\'e de Strasbourg /  [April 23, 2010]}
\renewcommand{\headrulewidth}{0pt} \renewcommand{\footrulewidth}{0pt} 


\usepackage{hyperref}
\hypersetup{
    unicode=true,
        pdfborder={0 0 0},
        pdftitle={
            Efficient multicast data transfer with congestion control using
                dynamic source channels
        },
        pdfsubject={
            Efficient multicast data transfer with congestion control using
                dynamic source channels
        },
        pdfauthor={
            Vincent Lucas,
            Jean-Jacques Pansiot,
            Dominique Grad and
            Benoit Hilt
        },
        pdfcreator={Vincent Lucas},
        pdfproducer={Vincent Lucas},
        pdfkeywords={multicast, congestion control, FEC}
}

\begin{document}
    \begin{center}
        {\large
             - Universit\'e de Strasbourg / 
            \\
            \vspace{4cm}
            {\huge
                Efficient multicast data transfer\\
                    with congestion control\\
                    using dynamic source channels
            }
            \\
            \vspace{2cm}
            {\Large
                Vincent Lucas,
                Jean-Jacques Pansiot,
                Dominique Grad
                and Beno\^it Hilt
            }
            \\
            \vspace{1cm}
            () LSIIT - Universit\'e de Strasbourg - CNRS, France\\
            \textit{\{lucas, pansiot, dominique.grad\}@unistra.fr}\\
            () Laboratoire MIPS - Universit\'e de Haute Alsace\\
            \textit{benoit.hilt@uha.fr}
            \\
            \vspace{5cm}
            {\Large
                Research report -  april 2010
            }
        }
    \end{center}
    \newpage

\title{
    Efficient multicast data transfer with congestion control using dynamic
        source channels
}

\author{Vincent Lucas,
    Jean-Jacques Pansiot,
    Dominique Grad
    and Beno\^it Hilt
    \\
    \\
    () LSIIT - Universit\'e de Strasbourg - CNRS, France\\
    \textit{\{lucas, pansiot, dominique.grad\}@unistra.fr}\\
    () Laboratoire MIPS - Universit\'e de Haute Alsace\\
    \textit{benoit.hilt@uha.fr}
}

\maketitle

\begin{abstract}
    The most efficient receiver-driven multicast congestion control protocols
    use dynamic channels. This means that each group has a cyclic rate variation
    with a continuously decreasing phase.  Despite promising results in terms of
    fairness, using efficiently these dynamic groups could be a challenging task
    for application programmers.  This paper presents a sequencer which maps out
    application data to dynamic groups in an optimal way.  Multiple applications
    such as file transfer or video streaming, can use this sequencer, thanks to
    a simple  usable with any buffer containing the most important data
    first. To evaluate this solution, we designed a file transfer software using
    a  encoding.  Results show the sequencer optimal behavior and the file
    transfer efficiency, as a single download generates only little more
    overhead than .  Moreover, download time is almost independent of the
    number of receivers, and is already faster than  with  competing
    downloads.
    \\
    \textit{Keywords}: Multicast, Congestion control, FEC
\end{abstract}




\section{Introduction}
    Most multicast flows such as IPTV are streamed at a constant rate using
    .  To fairly share the bandwidth with  streams, several multicast
    congestion controls have been proposed. Highly scalable ones are layered and
    receiver-driven, thus each receiver can adapt its reception rate to the
    network capacity.  In the first propositions, such as
    ~\cite{mccanne_receiver-driven_1996},
    ~\cite{vicisano_tcp-like_1998} or
    \textit{FLID-SL}~\cite{byers_flid-dl:_2002} , the layers correspond to
    multicast groups sent at a constant rate.  Each receiver joins or leaves new
    multicast groups to respectively increase or decrease its reception rate.
    But, to avoid the multicast leave time latency problem, a new approach using
    dynamic rate groups has been proposed, such as
    \textit{FLID-DL}~\cite{byers_flid-dl:_2002}, ~\cite{luby_wave_2002}
    or ~\cite{lucas_fair_2009}.  Each group begins to send at a high rate
    and slows down progressively until becoming quiescent. Thereby, a receiver
    has only to wait in order to reduce its reception rate. This solves the
    leave latency problem as a receiver only leaves a multicast group when it
    becomes quiescent.  Despite promising results in terms of fairness, using
    efficiently these dynamic groups is a challenging task and as far as we
    know, no solution to this problem has been proposed yet.
This paper presents a sequencer which maps out application data to dynamic
    groups in an optimal way.  Multiple applications such as file transfer or
    video streaming, can use this sequencer, thanks to a simple  usable
    with any buffer containing the most important data first. Indeed, the
    application does not need to know anything of the dynamic layering
    mechanism and the sequencer is independent of the application as it works
    without knowing the data encoding scheme.
To evaluate this solution, we designed a file transfer software using the
    sequencer and a  encoding.  Results show the sequencer optimal behavior
    and the file transfer efficiency, as a single download generates barely more
    overhead than .  Moreover, download time is almost independent of the
    number of receivers, and is already faster than  with  competing
    downloads.

\section{Addressed issues}
    An efficient massively scalable multicast congestion control uses several
    multicast groups with dynamic layering.  Despite promising results in terms
    of fairness, using efficiently these dynamic groups is a challenging task
    and no solution to this problem has been proposed yet.
The main purpose of this paper is to design a simple , which enables to
    use dynamic multicast congestion control in an optimal way, and takes as
    parameter a buffer containing the most important data first. Therefore, a
    receiver which receives only \% of the source rate, obtains the first
     of the application buffer.  Moreover, various applications can use
    this  without knowing anything about the dynamic layering used.

\section{Multicast congestion control}
    This section gives the background on multicast congestion control, necessary
    to understand the design of an efficient sequencer.  This description
    is based on the receiver-driven \textit{Multicast Congestion Control}
    ()~\cite{lucas_fair_2009} protocol, but the sequencer is also
    compatible with \textit{FLID-DL}~\cite{byers_flid-dl:_2002} and
    ~\cite{luby_wave_2002}.

    \subsection{The source part}
        The source part is quite similar to  and sends data using dynamic
        multicast groups (cf.  figure~\ref{fig:mcc_recv_rate}). Each group
        begins to send at a high rate and then continuously decreases its rate.
        Once a group reaches a low rate threshold, it stops sending data and
        becomes quiescent.  Therefore, a receiver just waits to decrease its
        reception rate and leaves only quiescent groups.  Only the base group,
        which cumulative rate\footnote{
            The cumulative rate for the group of level  corresponds to
                .
        }
        is  in figure~\ref{fig:mcc_recv_rate}, never becomes quiescent.
The source uses a time division named \textit{Time Slot Index} (),
        which changes each \textit{Time Slot Duration} () seconds. For
        each change of ,  groups become quiescent and  new groups
        start at the  highest rates. Let us define  the subdivision
        of the  corresponding to a duration of . This notion of
         will be used by the sequencer.

    \subsection{The receiver part}
        This is the complex part of the multicast congestion control, see
        ~\cite{lucas_fair_2009} for details.  First, the receiver computes
        the fair rate corresponding to its experienced network conditions. Then,
        the receiver joins multicast groups to receive a rate close to the
        computed fair rate.
Since  uses hierarchical cumulative groups, a receiver can join
        group  only after joining all groups from  to .  Thereby,
        data sent to the lowest groups in the hierarchy are received by most
        receivers.
Receivers of a static source design can only obtain a set of rates with
        a coarse granularity corresponding to the inter-groups rate granularity.
        Whereas, with dynamic source design a receiver can obtain almost any
        desired rate by joining groups more or less quickly, independently of
        the inter-group rate granularity.  Indeed,
        figure~\ref{fig:mcc_recv_rate} shows that if a receiver can get rate 
        by joining group at the shown time, another one can get rate  just by
        delaying its joins, and this with a smaller gap between rates  and
         than between cumulative rates  and .
        \begin{figure}[!t]
            \centering
            \includegraphics[width=.95\textwidth]
{mcc_recv_rate.eps}
            \caption{Fine rate granularity due to source dynamic design}
            \label{fig:mcc_recv_rate}
        \end{figure}

\section{Principle of the sequencer}
    To illustrate the principle of the proposed sequencer, assume that we wish
    to send a video using a dynamic layering congestion control, such as each
    receiver obtains a video resolution corresponding to its reception rate.
    For each video frame, the video software generates a buffer containing the
    different resolutions.  As explained before, the goal is to send the most
    important data to the lowest groups since most of receivers receives it. In
    these conditions, the source application has to map out its data in function
    of the continuously changing rate of each multicast group.
This computation is too specific and too complex for the application level.
    The basic idea presented in this paper proposes to move this mapping
    complexity to a dedicated sequencer easily usable by various applications
    such as file transfer or video streaming.  It provides a simple , which
    only needs a hierarchically encoded buffer, without knowing the buffering
    scheme used by the application. The buffer has just to contain the most
    important bytes at the beginning and the less important at the end.
Then, the sequencer computes the amount of data that each multicast group
    can send, classifies and sequences the application buffer to send the most
    important data at the lowest groups.  Thus, a receiver which receives \%
    of the source rate, obtains the first  of the application buffer.

\section{Proposition details}
    This section details how the sequencer splits incoming buffers into
    packets, orders and gives them to the multicast congestion control protocol,
    which schedules them.

    \subsection{Algorithm parameters}
        The sequencer provides a simple  easy to use, which only needs 
        parameters:
        \begin{itemize}
            \item{
                The hierarchically encoded  to send. It is important to
                    note that the sequencer does not need to know the 
                    encoding scheme used.
            }
            \item{
                The time allowed to send the buffer (). For
                    example, if the buffer is a video frame,  is
                    the duration of the frame.
Concerning file transfer or any other application where the
                     value is not obvious, it can be inferred by
                    the application thanks to the hierarchy used.  Since each
                    receiver must at least receive the first level of the
                    hierarchy, the  must correspond to the time
                    needed to send the amount of data of the first level at the
                    minimal congestion control rate\footnote{
                        The minimal and maximal rates of the congestion control,
                            are fixed when the multicast congestion control
                                session is initiated.
                    }.
Also, the  is independent of any parameter of
                    the congestion control like .
            }
            \item{
                The length of the buffer ().  For a video codec,
                     depends on each image compression.  For a
                        file transfer, the ideal  is the amount
                        of data sent in  at the maximal
                        rate\footnotemark[\value{footnote}].
            }
        \end{itemize}
        The sequencer must query some parameters from the congestion control
        too, such as the amount of data that can be sent for each group during a
        given time slot.
Once all these parameters acquired, the sequencer computes the optimal
        distribution to send the most significant data to the lowest groups
        available.

    \subsection{Packet classifier}
        \begin{figure}
            \centering
            \subfigure[Source dynamic group design]
            {
                \includegraphics[width=0.4\textwidth]
{algo_scheduler.eps}
                \label{fig:algo_scheduler}
            }
            \subfigure[Tile division example]
            {
                \includegraphics[width=0.4\textwidth]
{advanced_scheduler.eps}
                \label{fig:advanced_scheduler}
            }
            \subfigure[Algorithm example]
            {
                \includegraphics[width=0.4\textwidth]
{advanced_scheduler_example.eps}
                \label{fig:advanced_scheduler_example}
            }
            \caption{Sequencer algorithm}
        \end{figure}
        To send the most important data at the lowest group available, the
        sequencer creates a packet hierarchy dependent on time and on the group
        used. The packet hierarchy is subdivided in:
        \begin{itemize}
            \item{
                A coarse grain hierarchy, which splits each group into 
                    and sorts all tiles in function of their minimal rate. A
                     corresponds to a group during a .  It takes
                     seconds for the minimal cumulative rate of group
                     to become lower than the maximal cumulative rate of
                    group  during the same period. For example,
                          figure~\ref{fig:algo_scheduler} shows:
                    \begin{itemize}
                        \item{
                             maximal cumulative rate \textcircled{a} is
                                equal to  minimal cumulative rate
                                \textcircled{b}. This way,  cumulative
                                rate is lower or equal to .
                        }
                        \item{
                             minimal cumulative rate \textcircled{c} is
                                equal to  maximal cumulative rate
                                \textcircled{d}. This way,  cumulative
                                rate is greater or equal to .
                        }
                    \end{itemize}
                    The  order of this example is: . Meaning that the most important data must be
                        send first in , then , then in .
            }
            \item{
                A fine grain hierarchy to sort intra- packets.  Depending
                    on the join time, a receiver may get only the end of a
                    , hence the hierarchy must be sorted in function of
                    decreasing time: i.e. most important packet sent last.
            }
        \end{itemize}

    \subsection{Sequencer algorithm}
        The algorithm goal is to split the buffer into packets and to order
        these packets, sending the most important data at the lowest group
        available (i.e.  figure~\ref{fig:advanced_scheduler_example}).
        \\
        The first thing to do is to split the buffer into \textit{Packet Data
            Units} ().   will be identified by the triplet  where:
        \begin{itemize}
            \item{
                 is the  number\footnote{
                        In practice,  is an offset relatively to the
                            . But for readability purposes, in this
                            paper we use a  number corresponding to:
                            \\
                            .
                    }.
                    With  and  the number of 
                        contained in the application buffer. All  have
                        the same size, except the last one if the
                         is not a multiple of the default 
                        size.
            }
            \item{
                 is the group number to which  will be send. With  and  the number of groups.
            }
            \item{
                 is the packet sequence number relative to .  With  and  the number of packets that
                    the group  can send in .
            }
        \end{itemize}
        During  the same group can be partitioned into several
        tiles.  Indeed, the algorithm splits the  into intervals
        defined by , as illustrated by
        figure~\ref{fig:advanced_scheduler}.  Then, it requests the
        corresponding number of packets  that the group  can send
        during interval .  All tiles are sorted by their minimal cumulative
        rates, in order to send most important  to the tile having the
        minimal cumulative rate possible. For example in
        figure~\ref{fig:advanced_scheduler_example}:
        \begin{itemize}
            \item{
                Tile 0 will send  where .
            }
            \item{
                Tile 8 will send  where .
            }
            \item{
                etc.
            }
        \end{itemize}
        For a given group, the tiles are sent following their chronological
        order: i.e. group  sends first tile , tile  and then tile .
        Finally, the packets of a  are ordered following the fine grain
        hierarchy.  Inside the same tile, a group continuously decreases its
        send rate, meaning that each tile must send less important  first,
        in order to send the most important data at the lowest rate available.

    \subsection{Sequencer header and receiver part}
        The sequencer header is composed of a buffer identifier and an offset
        relative to the application buffer. The receiver stores in a reception
        buffer all the datagrams until one arrives with a new buffer identifier.
        Then, the  provides to the application an access function to
        get a list of all buffer parts received or only the contiguous
        segment starting at offset .

\section{File transfer software design}
    \begin{figure}
        \centering
        \subfigure[Software data flow diagram]
        {\includegraphics[width=0.4\textwidth]
{software_state_transition.eps}
            \label{fig:soft_data_flow}
        }
        \subfigure[Application scheduler algorithm]
        {\includegraphics[width=0.55\textwidth]
{application_orderer.eps}
            \label{fig:application_scheduler}
        }
        \subfigure[Blocks sent before sending a duplicate]
        {\includegraphics[width=0.3\textwidth]
{duplicated_blocks.eps}
            \label{table:blocks_sent}
        }
        \subfigure[4000 blocks scheduled]
        {\includegraphics[width=0.3\textwidth]
{sched_time_nb_blocks_4000.eps}
                \label{fig:theorical_res_sched}
        }
        \subfigure[4000 blocks scheduled with  (, ,
                )]
        {\includegraphics[width=0.3\textwidth]
{sched_time_nb_blocks_8000.eps}
                \label{fig:theorical_res_sched_fec}
        }
        \caption{Application flow diagram and scheduler performances}
    \end{figure}
    The sequencer can be used by various applications. To this end we implement
    an efficient file transfer with a fine grained rate tuning. Our goal is to
    show the performances and the ease of using a dynamic multicast congestion
    control thanks to the sequencer. This software uses a cyclic data
    transmission scheme named \textit{carousel}
    loop~\cite{peltotalo_performance_2007} and sends data following the flow
    diagram from figure~\ref{fig:soft_data_flow}:
    \begin{itemize}
        \item{
            The file reader splits a file into blocks and give them to the 
                encoder.
        }
        \item{
            The  encoder generates repair symbols from the file blocks also
                named source symbols. The source and repair symbols form
                the  symbols.
        }
        \item{
            The application scheduler orders the  symbols into hierarchical
                buffers and pass them to the API.
        }
        \item{
            The sequencer orders the hierarchical buffers into packets assigned
                to groups.
        }
        \item{
            The network scheduler is a part of the multicast congestion control.
                It schedules packets for each multicast group.
                ~\cite{lucas_fair_2009} is used for this evaluation.
        }
    \end{itemize}
    The sequencer coupled with the network scheduler can be reused for other
    applications and provides functionalities similar to , except
    reliability which is managed by the  encoder and the \textit{carousel}.

    \subsection{Application scheduler}
        The application scheduler, derived from~\cite{birk_multicast_2003},
        orders  blocks into buffers of  hierarchical levels (cf.
                figure~\ref{fig:application_scheduler}), such as the distance
        between two occurrences of a block is maximized and the number of
        redundant blocks received is reduced:
\begin{itemize}
           \item{
               The level  chooses block  for buffer , with .
           } 
           \item{
               The level  chooses block  for buffer . With  and  the block at the middle of the longest
                   interval between two blocks of all lower levels.  For example
                   in figure~\ref{fig:application_scheduler}, level  chooses
                   block  since it is the block at the middle between block
                    and  distant of  apart.
} 
        \end{itemize}
        Thus, download time is halved each time the receiver doubles the
        number of levels received (cf.  figure~\ref{fig:theorical_res_sched}).
        Moreover, this property is valid whatever the first buffer  received.
Fine rate granularity is provided by using a block size corresponding to
        the payload of a packet.
Note that the levels used in the application scheduler are independent
        of network scheduler layers.

    \subsection{ encoder}
        A  code generates  symbols from  source symbols.  The main
        advantage is that only  (with  small) distinct
        symbols suffice to recover the  source symbols.
\textit{Maximum Distance Separation} () codes (),
        such as Reed Solomon~\cite{rizzo_effective_1997} codes, have a low
        encoding/decoding rate which limits the
        number of usable symbols.
Whereas \textit{Low-Density Parity-Check} () codes () release the limitation on the number of usable symbols and
        thus have an high encoding/decoding rate. Our file transfer software
        uses a  code~\cite{roca_design_2003} provided by the
        project "Planete-bcast"~\cite{_planete-bcast:_2006} library.
Besides correcting packet losses, having numerous repair symbols can
        reduce the download time.  The application scheduler analysis (cf.
                table~\ref{table:blocks_sent}) shows that the number of unsent
        blocks before sending the first duplicated block is .  Thus,
        having  symbols improves the application scheduler and ables
        to reduce the downloading time for each new level received (cf.
                figure~\ref{fig:theorical_res_sched_fec}).

\section{File transfer evaluation}
    This section describes the testbed and the evaluation criteria used. Then,
    we analyze the application behavior for two different scenarii:
     file transfer with  long competing stream and several file transfers
    with background traffic.

    \subsection{Testbed}
        \begin{figure}[t]
            \centering
\includegraphics[width=0.4\textwidth]{maquette.eps}
            \caption{An example of the testbed with 2 senders and 2 receivers}
            \label{fig:testbed}
        \end{figure}
        The file transfer software has been implemented~\cite{_mutual:_2009} and
        evaluated on a testbed (cf.  figure~\ref{fig:testbed}) composed of Linux
        routers running the  routing daemon (\textit{PIM-SM},
                \textit{IGMPv3}) coupled with the \textit{Token Bucket Filter}
        () module to set the bottleneck rate ( or  Mb/s) and the
        buffer size (queues of  packets).
As multicast congestion control has a slow rate adaptation, it is best
        suited to manage long lived streams. Then, the size of the files
        transferred must not be too small and we have chosen three files whose
        sizes are:
        \begin{itemize}
            \item{
                 MBytes for a transfer lasting at least respectively  and
                     seconds at  and  Mb/s.  This does not able 
                    to converge to the fair rate and shows the behavior of the
                    file transfer with important reception rate variations.
            }
            \item{
                 MBytes for a transfer lasting at least respectively 
                    and  seconds at  and  Mb/s. This ables  to
                    reach the fair rate.
            }
            \item{
                 MBytes for a transfer lasting at least respectively 
                    and  seconds at  and  Mb/s.  This file is the
                    maximal sized manageable by our source and receiver s,
                            due to memory limits.
            }
        \end{itemize}
        The comparison is done between an unicast download client using 
        \textit{\mbox{new-RENO}} congestion control algorithm with 
        option, and a multicast file transfer using our
        implementation~\cite{_mutual:_2009}.

     \subsection{Criteria}
        The file transfer performances evaluation criteria are based on:
\begin{itemize}
            \item{
                : The number of seconds () used to download and recover
                    the file.
            }
            \item{
                : The goodput corresponding to the application download
                    rate ().
            }
            \item{
                : The throughput corresponding to the link download rate
                    ().
            }
            \item{
                : The loss rate ().
            }
            \item{
                : The duplicated symbols overhead () between the total
                    number of  symbols received () and
                    the number of symbols needed by the  code to recover
                    the file (): .  The sequencer behaves
                                                well, if  is close to .
            }
            \item{
                : The  symbols overhead () needed by the 
                    code. It is the ratio between the number of source
                    symbols () and the number of symbols needed
                    by the  code to recover the file ():
                        .
            }
            \item{
                : The header overhead () between
                    the datagram or packet length () and the
                    applicative data () contained by the same
                    packet:
                    \\
                    .
                    \\
                    Since  is  and that unicast
                    and multicast carry respectively  and  bytes of
                    ,  is a constant overhead:
                    \begin{itemize}
                        \item{
                             for unicast streams, or  with
                                ethernet and IP headers.
                        }
                        \item{
                             for multicast streams, or  with
                                ethernet and IP headers.
                        }
                    \end{itemize}
            }
            \item{
                : The total network overhead (). It is the ratio
                    between the length of the file () and the
                    amount of data received at the link level
                    ():
                    \\
                    .
                     \\
                     This criterion represents a general estimation of the
                     total overhead generated in the network and include
                     overhead of ,  and .
            }
            \item{
                : The computation time to recover the file after the last
                     symbol is received (). It is the ratio
                    between the  criterion and the time needed by the
                    network to receive the file ():
                    .  This criterion
                     represents the time needed to restore the file once all the
                     needed symbols are already received.
            }
        \end{itemize}
        In the following results all these criteria are given with a confidence
        interval of  with a series of  tests for each experiment
        setup.

    \subsection{One file transfer with one long competing stream.}
        These tests show the file transfer () behavior with a long competing
        stream:
        \begin{itemize}
            \item{
                 \textit{ file transfer} () competing with
                      stream.
            }
            \item{
                 \textit{ file transfer} () competing with
                      stream.
            }
            \item{
                 \textit{ file transfer} () competing with
                      stream.
            }
        \end{itemize}
        \begin{figure}
            \centering
            \subfigure[ file transfer versus  long stream]
            {
                \includegraphics[width=12cm]
{res_tests_1vs1.eps}
                \label{tab:m1t1}
            }
            \subfigure[ and  file transfers with background traffic]
            {
                \includegraphics[width=12cm]
{res_tests_multi.eps}
                \label{tab:multi_1_and_2}
            }
            \subfigure[ file transfers with background traffic for the
                 file]
            {
\label{tab:multi_5_48}
            \begin{tabular}{|c|c|c|c|c|}
                \hline
                & 
                    & 
                    & 
                    & 
                    \\
                \hline
                & \multicolumn{2}{|c|}{1Mb/s bottleneck}
                    & \multicolumn{2}{|c|}{4Mb/s bottleneck} \\
                \hline
				
					& 2055 (30)
					& 495 (65)
					& 512 (8)
					& 146 (28)
					\\
				
					& 192 (3)
					& 801 (97)
					& 770 (13)
					& 2733 (467)
					\\
				
					& 199 (3)
					& 921 (129)
					& 799 (13)
					& 3360 (754)
					\\
				
					& 5.86 (1.85)
					& 9.86 (9.5)
					& 4.03 (0.11)
					& 8.17 (3.36)
					\\
				\hline
				
					& 3.71 (0.06)
					& 11.64 (7.27)
					& 3.68 (0.26)
					& 11.38 (1.41)
					\\
				
                    & N.A.
					& 0.51 (1.29)
                    & N.A.
					& 0.21 (1.08)
					\\
				
                    & N.A.
					& 6.49 (1.79)
                    & N.A.
					& 6.06 (0.93)
					\\
				\hline
				
                    & N.A.
					& 3.04 (2.67)
                    & N.A.
					& 10.17 (7.61)
					\\
                \hline
            \end{tabular}
}
            \caption{Experiments results}
        \end{figure}
        In all these tests,   is less than , mainly composed of
        the  of header overhead.
Table~\ref{tab:m1t1} shows for  MBytes files that   is
        about , mainly composed of at least  of  and 
        of header overhead.  Concerning the  MBytes file,   is
        between  and .  The increase of  is linked to a
        growth of additional  symbols required (). This can be
        explained as the  extra symbols varies in function of the
        symbols received: all symbols have not the same importance.  Moreover
        with small files, the  variation is due to  slow
        convergence to the fair rate, which confirms that  is not
        suited for too short files.
The small  values prove the sequencer good behavior.
 and  streams use an \textit{Additive Increase and
            Multiplicative Decrease} ()~\cite{yang_general_2000} mechanism
            producing cyclic losses.  But,  losses are more bursty, due to
            sudden rate variations when joining a new group.  Regardless of the
            obtained throughput, the file transfer is not sensitive to the loss
            distribution and is quite as efficient with  of independent
            losses, as with  of bursty losses.  Finally, download time
            differences are due to  loose fairness when competing with
            another  stream.
The file transfer provides a fine grain rate as its behavior is not
        sensitive to the different bottleneck limitations and adapts itself to
        various .

    \subsection{File transfer with background traffic and multiple receivers.}
        These tests show the benefits of using  when several receivers
        download the same file in a more realistic environment:  or 
        simultaneous downloads compete with background traffic composed of many
        short  connections such as those used for web browsing. These
        streams start times follow a Poisson process with an average of 10
        streams per minute. Each stream sends an amount of data defined by
        an exponential distribution, such that  of the connections carry
        less than KB.
Table~\ref{tab:multi_1_and_2} shows that for both  and
        ,  is similar with  or  receivers.  However,
         download time almost doubles when  receivers are involved,
        whereas  download time remains stable. Thus,  is able
        to take advantage of the multicast scalability, while unicast streams
        are forced to share the bandwidth with each other. Then, only 
        receivers are enough to make  more advantageous than .
To show that the benefit of using  increases with the
        number of receivers of the same file, we have done another series of
        tests with  receivers downloading the same  file competing
        with background traffic. Results shown in table~\ref{tab:multi_5_48}
        confirm  performances. Indeed, these results point out that
         is almost independent of the number of receivers, while for
         the download time increases linearly with the number of receivers.



\section{Conclusion}
    This paper presents a new sequencer and  in order to ease the use of
    multicast congestion control with dynamic layering. Indeed, despite
    promising results in terms of fairness, using efficiently these dynamic
    groups is a challenging task for application programmers and no solution has
    been proposed yet.
The sequencer maps out application data to dynamic groups in an optimal way.
    Multiple applications such as file transfer or video streaming, can use this
    sequencer, thanks to a simple  which takes as parameter a
    hierarchically encoded buffer, without knowing the hierarchy application
    scheme.  Thereby, receivers get all the most important data they can afford,
    since they join groups from bottom-up due to the cumulative hierarchy used
    by the multicast congestion control. 
To evaluate our proposition, we designed a file transfer using
    this sequencer, a multicast congestion control, an application scheduler and
    a  coder.
The evaluation on a testbed shows the optimal behavior of the sequencer and
    the file transfer efficiency.  Indeed, it only produces a slightly larger
    overhead than  for a single download.  Furthermore, the multicast file
    transfer is highly scalable, almost independent of the number of receivers,
    and is more advantageous than  starting at only  receivers.
Finally, this file transfer receives a fine rate granularity, which
    is totally independent of the group hierarchy used by the multicast
    congestion control. Moreover, each receiver can start downloading at any
    time independently of the source or other receivers.
Currently, the transferred file size is limited by the  memory.
    Future work will focus on the use of an interleaver to release this
    limitation.
Lastly, the sequencer  is usable by various applications and is already
    integrated in a video streaming software using a
    ~\cite{mccanne_low-complexity_1997} codec with dynamic source channels.

\bibliographystyle{splncs}
\bibliography{lucas_pansiot_grad_hilt_scheduler}

\end{document}
