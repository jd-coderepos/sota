\documentclass{LMCS}

\def\dOi{9(4:22)2013}
\lmcsheading {\dOi}
{1--39}
{}
{}
{Jan.~13, 2013}
{Dec.~17, 2013}
{}

\ACMCCS{[{\bf Security and privacy}]: Formal methods and theory of
  security---Logic and verification; [{\bf Theory of computation}]:
  Formal languages and automata theory---Automata
  extensions---Transducers\,/\,Quantitative automata;
  Logic---Verification by model checking}

\keywords{Pushdown Systems; Reachability with Annotations;
  Quantitative Automata and Logics}

\pdfoutput=1
\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{bbm}
\usepackage{xspace}
\usepackage{mathrsfs}
\usepackage[ruled,commentsnumbered,linesnumbered,norelsize]{algorithm2e}
\usepackage{mathtools}
\usepackage{hyperref}



\widowpenalty=9999
\clubpenalty=9999

\usepackage{tikz}
\usetikzlibrary{calc,matrix,chains,positioning,arrows,fit,automata,backgrounds}
\usetikzlibrary{shapes,shapes.multipart,decorations,decorations.pathmorphing,decorations.pathreplacing}
\tikzstyle{dotstyle}=[fill=black,circle,minimum size=3pt,inner sep=0pt]
\tikzstyle{automatapath}=[->,decorate,decoration={snake,segment length=5mm}]
\tikzstyle{curlybracket}=[decorate,decoration={brace,amplitude=7pt}]

\allowdisplaybreaks[1]


\newcommand{\apath}[2][]{\xrightarrow[#1]{#2}}
\newcommand{\apathS}[2][]{\xrightarrow[#1]{#2}\!\!{}^*\,}
\newcommand{\nat}{\mathbbm{N}}
\newcommand{\eps}{\varepsilon}

\newcommand{\DeltaR}{\Delta_{\mathfrak R}}
\DeclareMathOperator{\dotcup}{\mathaccent\cdot\cup}
\DeclareMathOperator{\bigdotcup}{\bigcup \hspace{-0.35cm} \cdot}
\newcommand{\wedgespace}{\;\wedge\;}
\newcommand{\projectV}{\,\upharpoonright_{\tiny V}\!}
\newcommand{\restrictTo}[1]{\big|_{#1}}
\newcommand{\Gr}{\mathcal G_{\mathfrak R}}
\DeclareMathOperator{\Def}{Def}
\DeclareMathOperator*{\argmin}{argmin}
\newcommand{\FO}{\ensuremath{\mathsf{FO}}}
\newcommand{\Ldoln}{L_{\}^n}}
\newcommand{\Sigdoln}{(\Sigma \cup \{ \\})^{n+1}}


\newcommand{\A}{\mathsf{A}}
\newcommand{\pad}{\square}



\newcommand{\nextElem}[1][]{\xrightarrow{#1}}
\newcommand{\pathTo}[1][]{\xrightarrow{#1}^*}
\newcommand{\reach}[2]{\mathsf{reach}\left(#1,#2\right)}
\newcommand{\preStar}[1]{\mathsf{pre}^*\!\!\left(#1\right)}
\newcommand{\postStar}[1]{\mathsf{post}^*\!\!\left(#1\right)}
\newcommand{\defEquiv}{:\Leftrightarrow}
\newcommand{\Equiv}{\Leftrightarrow}
\newcommand{\Implies}{\Rightarrow}

\newcommand{\configstep}[1][]{\vdash_{#1}}
\newcommand{\configsteps}[1][]{\vdash_{#1}^{*}}
\newcommand{\configstepn}[2][]{\vdash_{#1}^{#2}}


\newcommand{\Pot}{\mathcal{P}ow}
\newcommand{\potset}[1]{\Pot\left(#1\right)}
\newcommand{\natInf}{\nat \cup \{ \infty \}}

\newcommand{\automatonA}{\mathfrak A}
\newcommand{\automatonB}{\mathfrak B}
\newcommand{\automatonC}{\mathfrak C}
\newcommand{\automatonD}{\mathfrak D}
\newcommand{\automatonT}{\mathfrak T}
\newcommand{\tmm}{\mathcal M}

\newcommand{\In}{\mathsf{In}}
\newcommand{\Fin}{\mathsf{Fin}}
\newcommand{\counterSet}{\Gamma}
\newcommand{\counterOperationFunction}{\mathsf{CountOp}}
\newcommand{\semantics}[1]{\llbracket#1\rrbracket}

\newcommand{\costle}{\preceq}
\newcommand{\costlea}[1][\alpha]{\preceq_{#1}}
\newcommand{\costEquiv}[1][\alpha]{\approx_{#1}}

\newcommand{\infProjection}[1]{_{\inf,#1}}
\newcommand{\supProjection}[1]{_{\sup,#1}}

\newcommand{\afterFunction}{\circ}

\newcommand{\partialTo}{\dashrightarrow}
\newcommand{\dom}[1]{\domF\left(#1\right)}
\DeclareMathOperator{\domF}{\mathsf{dom}}

\newcommand{\treeT}{\mathcal T}
\newcommand{\childFunction}[1][\treeT]{s_{#1}}
\newcommand{\parentFunction}[1][\treeT]{\pi_{#1}}
\newcommand{\distanceFunction}[1][\treeT]{d_{#1}}
\newcommand{\treeLeafs}[1][\treeT]{\mathsf{Leafs}_{#1}}
\newcommand{\subTree}[1][\treeT]{\mathsf{Sub}_{#1}}
\newcommand{\RTo}[1]{\vec{\mathrm{R}}_{#1}}
\DeclareMathOperator{\RunCost}{R}
\newcommand{\RuntreeConcat}{\mathsf{RuntreeConcat}}


\newcommand{\defeq}{\stackrel{\scriptstyle{\mathclap{\mathrm{def}}}}{=}}
\newcommand{\defle}{\stackrel{\scriptstyle{\mathclap{\mathrm{def}}}}{\le}}
\newcommand{\defge}{\stackrel{\scriptstyle{\mathclap{\mathrm{def}}}}{\ge}}
\newcommand{\iheq}{\stackrel{\scriptstyle{\mathclap{\mathrm{i.h.}}}}{=}}
\newcommand{\ihge}{\stackrel{\scriptstyle{\mathclap{\mathrm{i.h.}}}}{\ge}}
\newcommand{\ihle}{\stackrel{\scriptstyle{\mathclap{\mathrm{i.h.}}}}{\le}}
\newcommand{\ihEquiv}{\stackrel{\scriptstyle{\mathclap{\mathrm{i.h.}}}}{\Equiv}}
\newcommand{\asle}{\stackrel{\scriptstyle{\mathclap{\mathrm{ass.}}}}{\le}}
\newcommand{\asge}{\stackrel{\scriptstyle{\mathclap{\mathrm{ass.}}}}{\ge}}
\newcommand{\asEquiv}{\stackrel{\scriptstyle{\mathclap{\mathrm{ass.}}}}{\Equiv}}

\makeatletter
\newcommand{\commentLe}{\@ifstar
  \commentLeStar \commentLeNoStar}
\newcommand{\commentGe}{\@ifstar
  \commentGeStar \commentGeNoStar}
\newcommand{\commentEq}{\@ifstar
  \commentEqStar \commentEqNoStar}
\newcommand{\commentEquiv}{\@ifstar
  \commentEquivStar \commentEquivNoStar}
\newcommand{\commentOp}{\@ifstar
  \commentOpStar \commentOpNoStar}

\newcommand{\commentLeNoStar}[1]{\stackrel{\scriptstyle{\mathclap{#1}}}{\le}}
\newcommand{\commentGeNoStar}[1]{\stackrel{\scriptstyle{\mathclap{#1}}}{\ge}}
\newcommand{\commentEqNoStar}[1]{\stackrel{\scriptstyle{\mathclap{#1}}}{=}}
\newcommand{\commentEquivNoStar}[1]{\stackrel{\scriptstyle{\mathclap{#1}}}{\Equiv}}
\newcommand{\commentLeStar}[1]{\stackrel{\scriptstyle{#1}}{\le}}
\newcommand{\commentGeStar}[1]{\stackrel{\scriptstyle{#1}}{\ge}}
\newcommand{\commentEqStar}[1]{\stackrel{\scriptstyle{#1}}{=}}
\newcommand{\commentEquivStar}[1]{\stackrel{\scriptstyle{#1}}{\Equiv}}

\newcommand{\commentOpStar}[2]{\stackrel{\scriptstyle{#1}}{#2}}
\newcommand{\commentOpNoStar}[2]{\stackrel{\scriptstyle{\mathclap{#1}}}{#2}}

\makeatother

\newcommand{\checkReset}{\crOp}
\newcommand{\CounterOperationsSet}{\{\nOp,\iOp,\rOp,\checkReset\}}
\newcommand{\counterProfile}[1]{\bar #1}
\newcommand{\cprofile}{\mathsf{Profile}}
\newcommand{\reCOp}{\mathrm{RE}_{\mathsf{CntOp}}}
\newcommand{\counterProfiles}{\mathcal{CP}}
\newcommand{\counterProfilesD}{\overline{\mathcal{CP}}}
\newcommand{\cple}{\le_{\mathrm{cw}}}
\newcommand{\cpge}{\ge_{\mathrm{cw}}}
\newcommand{\cpl}{<_{\mathrm{cw}}}
\newcommand{\cpg}{>_{\mathrm{cw}}}

\newcommand{\counterProfileSequence}[1]{\mathfrak c_{\counterProfile{#1}}}
\newcommand{\counterProfileSequenceInf}[1]{\mathfrak c^{\infty}_{\counterProfile{#1}}}
\DeclareMathOperator{\supcw}{supcw}

\newcommand{\concatProfile}{\circ}
\newcommand{\maxp}{\mathsf{MaxProfiles}}

\newcommand{\frontpart}{\leftarrow}
\newcommand{\backpart}{\rightarrow}

\newcommand{\Pre}{\mathsf{Pre}}
\newcommand{\Post}{\mathsf{Post}}

\newcommand{\ipc}{i_c^{+}}
\newcommand{\ip}{i^{+}}
\newcommand{\ipl}{i^{+}_{\leftarrow}}
\newcommand{\ipr}{i^{+}_{\rightarrow}}
\newcommand{\cmin}{c_{\mathit{min}}}
\newcommand{\cmax}{c_{\mathit{max}}}
\newcommand{\cend}{c_{\mathit{end}}}
\newcommand{\ipcg}[1][\gamma]{i_{c,#1}^+}
\newcommand{\ipg}[1][\gamma]{i_{#1}^+}
\newcommand{\cming}[1][\gamma]{c_{\mathit{min},#1}}
\newcommand{\cendg}[1][\gamma]{c_{\mathit{end},#1}}
\newcommand{\hipcg}[1][\gamma]{\hat{i_{c,#1}^+}}
\newcommand{\hipg}[1][\gamma]{\hat{i_{#1}^+}}
\newcommand{\hcming}[1][\gamma]{\hat{c_{\mathit{min},#1}}}
\newcommand{\hcendg}[1][\gamma]{\hat{c_{\mathit{end},#1}}}
\newcommand{\na}{\diagup}
\newcommand{\Inf}{\mathsf{Inf}}
\newcommand{\cntr}{\gamma}

\newcommand{\checkMin}[1][]{\mathsf{c}_{#1}\!\!\downarrow}
\newcommand{\checkMinP}[1][]{\mathsf{c}'_{#1}\!\!\downarrow}
\newenvironment{indt}{\begin{quote}}{\end{quote}}
\newcommand{\countOp}{c_{\mathsf{Op}}}


\newcommand{\configstepAlph}[2][]{\stackrel{#2}{\vdash_{#1}}}
\newcommand{\configstepsAlph}[2][]{\stackrel{#2}{\vdash_{#1}^{*}}}

\newcommand{\pdsP}{\mathcal P}
\newcommand{\prsR}{\mathfrak R}
\newcommand{\configstepCost}[1]{\vdash_{#1}}
\newcommand{\configstepsCost}[2][*]{\vdash^{#1}_{#2}}
\newcommand{\configstepsLesserCost}[2][*]{\vdash^{#1}_{\le #2}}
\newcommand{\configstepsLesserCostLangRestrict}[2]{\vdash^{#1}_{\le
#2}}
\newcommand{\pdscntrOperations}{\{\nOp,\iOp,\rOp\}}

\newcommand{\boundedReach}{\rightslice}

\newcommand{\DeltaP}{\Delta_{\mathcal P}}
\newcommand{\DeltaA}{\Delta_{\automatonA}}

\newcommand{\pdsrule}[3]{#1 \xrightarrow[#2]{} #3}

\newcommand{\padprodL}{\otimes_{\mathsf{L}}}
\newcommand{\padprodR}{\otimes_{\mathsf{R}}}
\newcommand{\alphVector}[2]{#1^{\otimes #2}}
\newcommand{\alphVectorS}[2]{\left(#1^{\otimes #2}\right)^*}
\newcommand{\alphVectorL}[2]{#1^{{\padprodL #2}^*}}
\newcommand{\alphVectorR}[2]{#1^{{\padprodR #2}^*}}
\newcommand{\NalphVectorL}[2]{\overline{#1^{{\padprodL #2}^*}}}
\newcommand{\NalphVectorR}[2]{\overline{#1^{{\padprodR #2}^*}}}

\newcommand{\rl}{m_{\leftarrow}}
\newcommand{\rr}{m_{\rightarrow}}
\newcommand{\hrl}{\hat m_{\leftarrow}}
\newcommand{\hrr}{\hat m_{\rightarrow}}
\newcommand{\rev}{\mathsf{rev}}

\newcommand{\befR}{\mathsf{bef}_{\rOp}}
\newcommand{\aftR}{\mathsf{aft}_{\rOp}}
\newcommand{\hasR}{\mathsf{has}_{\rOp}}

\newcommand{\structureS}{\mathfrak S}

\newcommand{\embed}{\hookrightarrow}

\newcommand{\VAR}{\mathrm{VAR}}
\newcommand{\free}{\mathsf{free}}
\newcommand{\FORR}{\ensuremath{\mathsf{FO\!\!+\!\!RR}}}
\newcommand{\FORREO}{\ensuremath{\mathsf{FO\!\!+\!\!RR\!+\!\exists^\omega}}}
\newcommand{\valfunc}{\mathfrak I}
\newcommand{\costRestrict}[2][k]{\big|_{#1}^{#2}}

\newcommand{\bindL}{\mathsf{conv}}
\newcommand{\bindR}{\mathsf{conv}_{\padprodR}}
\newcommand{\unbind}{\mathsf{unconv}}

\newcommand{\ft}{f_{\automatonT}}
\newcommand{\ftp}{f_{\automatonT_{\sup}'}}
\newcommand{\cs}{\mathsf{c}}

\newcommand{\MSO}{\ensuremath{\mathrm{MSO}}}
\newcommand{\wMSO}{\ensuremath{\mathrm{WMSO}}}
\newcommand{\MSOTh}{\mathrm{MSO}-\mathrm{Th}}

\newcommand{\shorter}{\sqsubseteq}

\newcommand{\tsnextElem}{\rightarrowtail}
\newcommand{\tspathTo}{\rightarrowtail^*}
\newcommand{\resCost}{\mathsf{resCost}}

\DeclareMathOperator{\resources}{\mathsf{resources}}
\DeclareMathOperator{\pre}{pre}
\DeclareMathOperator{\Attr}{Attr}

\newcommand{\iOp}{\ensuremath{\mathtt{i}}}
\newcommand{\rOp}{\ensuremath{\mathtt{r}}}
\newcommand{\nOp}{\ensuremath{\mathtt{n}}}
\newcommand{\cOp}{\ensuremath{\mathtt{c}}}
\newcommand{\icOp}{\ensuremath{\mathtt{i\! c}}}
\newcommand{\crOp}{\ensuremath{\mathtt{c\! r}}}

\newcommand{\winregEve}[2][k]{W^{(#1)}_0\left(#2\right)}
\newcommand{\winregAdam}[2][k]{W^{(#1)}_1\left(#2\right)}

\newcommand{\fle}{\le_{\mathrm{cw}}}
\newcommand{\fge}{\ge_{\mathrm{cw}}}
\newcommand{\fl}{<_{\mathrm{cw}}}
\newcommand{\fg}{>_{\mathrm{cw}}}

\newcommand{\undef}{\perp}

\newcommand{\twosm}[2]{\begin{smallmatrix} #1 \\ #2 \end{smallmatrix}}

\newcommand{\squaresCost}{\mathsf{squaresCost}}

\newcommand{\partialFunction}[2]{#2^{#1}_{\mathfrak p}}

\newcommand{\op}{\mathsf{op}}
\newcommand{\inductionstart}[1]{\begin{description}\item[\textbf{(base
case)}]#1 \\}
\newcommand{\inductionstep}[1]{\item[\textbf{(induction step)}]
#1 \\}
\newcommand{\inductionend}{\end{description}}

\newcommand{\profileToOp}{\mathsf{PrToOp}}

\newcommand{\fraku}{\mathfrak u}
 
\newcommand{\RPRS}{\textsf{RPRS}}
\newcommand{\resRep}[1]{\mathcal C_{#1}}
\newcommand{\annotationMonoidM}{\mathcal M}
\newcommand{\neutralM}[1][]{e_{\annotationMonoidM_{#1}}}
\newcommand{\neutralP}{e_{P}}

\newcommand{\wsel}{\mathsf{wsel}}
\newcommand{\strip}{\mathsf{strip}}

\renewcommand{\theta}{\vartheta}
\newcommand{\twovec}[2]{\begin{pmatrix}#1 \\ #2\end{pmatrix}}





\begin{document}
\title{Modeling and Verification of Infinite Systems with Resources}

\author[M.~Lang]{Martin Lang}
\address{Chair of Computer Science 7, RWTH Aachen, 52056 Aachen (Germany)}
\email{\{lang,loeding\}@automata.rwth-aachen.de}


\author[C.~Löding]{Christof L{\"o}ding}


 
\begin{abstract}
  We consider formal verification of recursive programs with resource
consumption. We introduce prefix replacement systems with non-negative integer
counters which can be incremented and reset to zero as a formal model for such
programs. In these systems, we investigate bounds on the resource consumption
for reachability questions. Motivated by this question, we introduce relational
structures with resources and a quantitative first-order logic over these
structures. We define resource automatic structures as a subclass of these
structures and provide an effective method to compute the semantics of the logic
on this subclass. Subsequently, we use this framework to solve the bounded
reachability problem for resource prefix replacement systems. We achieve this 
result by extending the well-known saturation method to annotated prefix replacement
systems. Finally, we provide a connection to the study of the logic cost-WMSO.
\end{abstract}

\maketitle


\section{Introduction}

Transition systems induced by the configuration graph of pushdown automata have
become an important tool in automatic program verification. Starting with the
introduction of the concept of pushdown automata by A.G.\ Oettinger in 1961 and
M.-P.\ Sch\"{u}tzenberger in 1963, these systems have been extensively studied
and are well understood today. Already in 1985, Muller and Schupp were able to
prove the decidability of MSO-logic over these systems (see
\cite{theoryOfPushdownAutomata}), which are mostly called pushdown systems
nowadays. Until now, methods and algorithms have been developed that provide
automatic verification procedures for recursive programs. For example, the model-checker
jMoped, introduced in \cite{jMoped}, uses symbolic pushdown systems to verify
programs given in Java bytecode. 

Recently, quantitative aspects in formal verification came into the focus.
Although there is a long history of automata models with quantitative aspects
such as weighted automata (see \cite{Schutzenberger-WeightedAutomata}) or
distance automata (see \cite{distanceAutomata}), their use in the area of formal
verification was limited. More recently, timed automata (see
\cite{Alur-timedAutomata}) were introduced as model for systems with
quantitative timing constraints. Additionally, there is currently some effort to
extend this line of research to the area of pushdown systems. In
\cite{timed-pushdown}, a model that combines dense-timed automata with pushdown
automata is introduced in order to model real-time recursive systems. Furthermore,
finite automata and games with resource constraints instead of timing
constraints were introduced and studied (see
\cite{infinite-runs-in-weighted-timed-automata}). Additionally, a combined
concept of weighted automata and pushdown systems is used for program
verification with data flow analysis (see \cite{Lal-TACAS08}). However, the
authors do not know of research considering infinite systems with resource
constraints. 


We contribute in our work to the theory of quantitative systems by defining and
analyzing a model for recursive programs with discrete resource consumption. We
introduce resource prefix replacement systems as a combination of prefix
replacement systems and non-negative integer counters similar to those used in B-automata (see
\cite{regularcostfunctions}). These counters support three kinds of operations:
increment, reset to zero, or skip. The operations annotate the
transitions of the prefix replacement system. Thereby, the model is able to
simulate usage and refreshment of resources during program execution. We
consider the resource usage of a run through the system to be the highest
occurring counter value. 


One central aspect in systems with resource consumption is boundedness.
Generally, this means checking whether there is a finite bound such that the
system can complete a given task while keeping the resource consumption within
the bound. We formalize this idea by the concept of bounded reachability. This
means checking whether there is a finite bound such that it is possible to reach
from all initial configurations of the system some configuration in a given goal
set with less resource usage than the bound. An algorithmic solution to this
problem can be used as a building block in the realizability checking of systems
with resources. For example, consider a battery powered mobile measuring device
which should be able to complete certain tasks without recharging the battery.
This is only possible if there is a finite bound on the energy consumption
independent of the selected task. The realizability question of this requirement
can be stated in the form of a bounded reachability problem.


Motivated by this question, we develop a framework to formalize and
solve the bounded reachability problem and related questions for recursive
programs with resource consumption. We introduce resource structures as
a quantitative variant of relational structures based on the idea that being in
relation may cost a certain amount of resources. For these structures, we
develop the quantitative logic first-order+resource relations (for short
\FORR{}) in order to express combined constraints on the resource
consumption and the behavior of the system. Intuitively, the semantics of this
logic is designed to describe the amount of resources necessary to satisfy a
first-order constraint. We define resource automatic structures as a subclass of
resource structures. This definition extends automatic structures as introduced
in \cite{automatic-structures} with a quantitative aspect. Based on the closure
properties of B-automata and ideas from the theory of automatic structures, we
provide an effective way to compute the semantics of the logic over resource
automatic structures.

Subsequently, we demonstrate the usage of this general theory to
solve the bounded reachability problem on resource prefix replacement systems
for regular initial and goal sets. This is achieved by showing that resource
prefix replacement systems are resource automatic structures and thus bounded
reachability can be solved by computing the semantics of an \FORR{} formula. In
order to obtain this decidability result, we analyze prefix replacement systems with a
general form of annotation. Based on the well-known saturation principle, we
devise a method to compute an annotation aware transitive closure of the
successor relation in the form of synchronized transducers. 

This saturation procedure is based on a saturation for ground-tree
transducers presented in \cite{gtt-saturation} and constructed with
the goal of obtaining a synchronous transducer. Although the idea of saturation
in annotated systems is not entirely new, the existing methods do not quite fit
our needs. In \cite{RepsSchwoon-WeightedPushdown}, saturation is used to compute
predecessor and successor configurations of regular configuration sets for
pushdown systems with weights from a semi-ring. This result
was extended in \cite{Lal-TACAS08} to compute an asynchronous transducer for
the reachability relation of (semi-ring) weighted pushdown systems. However,
these methods cannot be applied directly to our problem since we need a 
synchronous transducer for the decision procedure of \FORR{} and additionally
encoding the resource counters into a semi-ring structure is very complex. 
Moreover, we believe that this different two-sided-saturation approach
offers an interesting new viewpoint  on the problem of transitive closure in
annotated pushdown- and prefix replacement systems.

Finally, we provide a connection between our problems and the logic cost-WMSO,
which was also introduced in connection to B-automata. We show that the
decidability results for the boundedness problem of cost-WMSO presented by M.
Vanden Boom in \cite{costwMSO} can also be used to obtain a decision procedure
for a restricted version of bounded reachability. Although this part does not
contain any new results, it shows that this logic, which was designed 
as equivalent formalism to B-automata, is also capable of expressing
a very natural problem for quantitative systems. This motivates further studies
on the expressive power of cost-(W)MSO and other quantitative logics that emerged
around cost-automata. 


In the following section, we first introduce and formalize our model for
recursive programs with resource consumption. In
Section~\ref{sec:Preliminaries}, we present the known results for counter
automata as introduced by T. Colcombet and briefly repeat the important
results. Subsequently, we define and investigate the model of resource
structures and the logic \FORR{} in
Section~\ref{sec:ResourceStructuresAndLogic}. Next, we exhibit an extended
saturation approach which enables us to compute the transitive closure
for prefix replacement systems with annotations in
Section~\ref{sec:ReachabilityWithAnnotations}. At the end of this section, we
use the previously developed framework to prove our main statement on the
bounded reachability problem. Section~\ref{sec:BoundedReachabilityAndCostWMSO}
connects our results to the logic cost-WMSO. Finally, we conclude in
Section~\ref{sec:Conclusion}.

We would like to thank T.~Colcombet and M.~Bojańczyk for the fruitful and
enlightening discussions. Moreover, we want to thank the anonymous reviewers 
for their very constructive and detailed comments. They helped us to 
significantly improve the quality of this article. Additionally, we thank the 
Deutsche Forschungsgemeinschaft, which supports the first author in 
the project ``Automatentheoretische Verifikationsprobleme mit Ressourcenschranken''.

\section{Resource Prefix Replacement Systems}
\label{sec:ResourcePRS}

We define \emph{resource prefix replacement systems} (for short \RPRS{}) to be a
suitable model for recursive programs with resource consumption. This is
achieved by combining prefix replacement systems, which are a well-known model
for recursive programs, with discrete non-negative counters. These counters
support three kinds of operations, which annotate the transitions of the
prefix replacement system. First, the counter can be incremented (\texttt{i}).
This models the use of one unit of one resource. Second, the counter can be
reset to zero (\texttt{r}). This models the complete refresh/refill of this
kind of resources. Third, it is possible to leave the counter unchanged, what we
call no operation (\texttt{n}). This counter model is similar to B-automata,
which are presented in the subsequent section. We formalize the model of
\RPRS{} by the following definition.

\begin{defi}
  A resource prefix replacement system is a triple  consisting of a finite  alphabet , a finite set
of counters  and a finite transition relation . A configuration is a finite
word over . A transition  enables a change from the
configuration  to  for all  and triggers the counter
operation  for each counter . If there is only one counter
in the system, we also write  for a rule
 where  for the unique counter .
\end{defi}

We are mainly interested in the configuration graph induced by the system. A
path in this graph represents a (partial) run of the modeled recursive program.
The resource usage of such a run is calculated by simulating all counter
operations along the path according to the annotated operations at the
transitions.  We identify the resource usage (or resource-cost) of the path with
the maximal counter value (of all counters) in the sequence. Furthermore, we
write  if  is reachable from  with resource
usage of at most . We remark that we do not distinguish between the different
counters when calculating the overall resource usage because we focus on
boundedness questions. 



For example, consider a simple \RPRS{} with only one counter  over the
alphabet . The system contains four replacement rules: . Figure~\ref{fig:RPRSExample} shows a part of the resulting configuration
graph. In this example, it can be seen that for all , we obtain . However, this is not possible with simple paths
without loops because detours using the replacement rules annotated with reset
are needed. In detail, we obtain, e.g.,  by
.

\begin{figure}[t]
  \begin{center}
	\begin{tikzpicture}
	\begin{scope}[level distance=2.2cm,
				level 1/.style={sibling distance=3cm},
				level 2/.style={sibling distance=1.5cm},
				level 3/.style={sibling distance=0.8cm},
				level 4/.style={level distance=0.7cm},
				edge from parent/.style={draw=none},
				font={\large},
				scale=0.7,
				transform shape]

	\tikzstyle{littleN}=[midway,right,font={\small}]
	\tikzstyle{nodehighlight}=[color=blue!70!white]
	\tikzstyle{pathhighlight}=[color=red!70!white,dashed]
	\tikzstyle{counterAnnotation}=[above left=1mm,font={\small},color=red!80]

	\node (eps) at (0,0) {} [grow'=right]
		child {
		node (a) {}
		child {
			node (aa) {}
			child {node (aaa) {}
			child {node {}}}
			child {node (baa) {}
			child {node {}}}
		}
		child {
			node (ba) {}
			child {node (aba) {}
			child {node {}}}
			child {node (bba) {}
			child {node {}}}
		}
		}
		child {
		node (b) {}
		child {
			node (ab) {}
			child {node (aab) {}
			child {node {}}}
			child {node (bab) {}
			child {node {}}}
		}
		child {
			node (bb) {}
			child {node (abb) {}
			child {node {}}}
			child {node (bbb) {}
			child {node {}}}
		}
		};
	
	
	\draw[->] (aaa) -- (aa) node[midway,above] {};
	\draw[->] (aba) -- (ba) node[midway,above] {};
	\draw[->] (aab) -- (ab) node[midway,above] {};
	\draw[->] (abb) -- (bb) node[midway,above] {};
	\draw[->] (aa) -- (a) node[midway,above] {};
	\draw[->] (ab) -- (b) node[midway,above] {};
	\draw[->] (a) -- (eps) node[midway,above] {};
	

	
	\draw[<-] (bbb) -- (bb) node[midway,below] {};
	\draw[<-] (bba) -- (ba) node[midway,below] {};
	\draw[<-] (bab) -- (ab) node[midway,below] {};
	\draw[<-] (baa) -- (aa) node[midway,below] {};
	\draw[<-] (bb) -- (b) node[midway,below] {};
	\draw[<-] (ba) -- (a) node[midway,below] {};




	\draw[<-] (aaa) -- (baa) node[littleN] {};
	\draw[<-] (aba) -- (bba) node[littleN] {};
	\draw[<-] (abb) -- (bbb) node[littleN] {};
	\draw[<-] (aab) -- (bab) node[littleN] {};
	\draw[<-] (aa) -- (ba) node[midway,right] {};
	\draw[<-] (ab) -- (bb) node[midway,right] {};
	\draw[<-] (a) -- (b) node[midway,right] {};
	\end{scope}
\end{tikzpicture}   \end{center}
  \caption{Configuration graph induced by the example \RPRS{}}
  \label{fig:RPRSExample}
\end{figure}


\subsection{The Bounded Reachability Problem}
\label{subsec:BoundedReachability}

Reachability checking is a fundamental building block of many formal
verification procedures. For example, it can be applied as a decision procedure
for the termination problem of a program. The general reachability problem 
on prefix replacement systems can be formulated as follows. Let  (starting 
configurations) and  (final configurations) be two sets of
configurations. We say  is reachable from  if for all elements
in  there is a path to some element of . This resembles the termination
idea that independent of the starting configuration of the program a final
configuration should be reached after finitely many steps.


However, in the context of systems with resources mere reachability is
often not enough to ensure the realizability of the system. 
We therefore extend the question by asking whether bounded
resources are enough to achieve reachability.

\begin{defi}[Bounded Reachability]
  Let  be two sets of configurations. We say  is boundedly reachable
  from  if there is a bound  such that for all  there
  is a  satisfying .
\end{defi}

Reconsider the example depicted in Figure \ref{fig:RPRSExample}. We already
observed
that . Consequently, the set  is
boundedly reachable from . However, if we remove one
of the rules  , this does not
hold anymore although it is still possible to reach  but with increasing
resource usage.

The rest of this work is dedicated to developing tools with the goal of better
understanding and solving the bounded reachability problem. First, we
introduce the basic concepts and known results on cost automata in
Section~\ref{sec:Preliminaries}. These results form the basis for most of our
following work. In Section~\ref{sec:ResourceStructuresAndLogic}, we define
resource structures as a specialized concept to represent systems with resource
consumption. On these structures we define the logic \FORR{} to describe
the behavior of the system in combination with its resource consumption. This
framework allows amongst other things a simple formulation of the bounded reachability problem. To
achieve the desired goal and solve the bounded reachability problem in a
restricted scenario, we provide a method to effectively compute the
semantics of \FORR{} on a restricted class of structures which we call resource
automatic. In Section~\ref{sec:ReachabilityWithAnnotations}, we develop a method
to compute an annotation aware transitive closure of annotated prefix
replacement systems. With this method we are able to prove that \RPRS{} are
resource automatic. Thus, we solve the bounded reachability problem for regular
sets of configurations. 


\section{Cost Automata}
\label{sec:Preliminaries}



To study boundedness questions, M.~Bojańczyk and T.~Colcombet
presented general automata with (non-readable) counters called B- and
S-automata in \cite{bounds-in-omega-regularity}. T.~Colcombet compared these
models with an algebraic and a logical approach in \cite{regularcostfunctions}.
All these concepts define functions from  to . In 
\cite{regularcostfunctions} it is shown that all the models are capable of 
expressing the same functions up to some equivalence relation . 
The equivalence classes resulting from this relation are called 
\emph{cost functions}. We additionally call a cost function \emph{regular} if
it contains a function that is definable by some B-automaton. Correspondingly,
we call the two automata models \emph{cost automata}.

The definition of the equivalence relation   uses so called
\emph{correction functions} to measure the difference between a pair of cost
functions. A correction function  is a non-decreasing mapping from
 to  which maps  and only  always to ,
i.e.,  and .
\begin{defi}
	Let  be two values and  a correction function. We say that  is -dominated
	by  and write  if . If  
	and , we say that  and  are -equivalent and
	write .

	We extend this naturally  to functions. Let  be 
	two functions. We say  is -dominated by  and write 
	 if 
	
	Analogously, if  and  we say  and  are
	-equivalent and write . The two functions are just
	called equivalent (written ) if there exists some
	correction function  such that .
\end{defi}
Note that for a fixed , the relation  is not transitive.
From the inequality it becomes clear that for three functions , we only obtain  and . However, one can easily check that for , we obtain . 

An equivalent characterization of the relation  can be given by
comparing the subsets of the domain with bounded image. 

\begin{lem}[see \cite{regularcostfunctions}]
\label{lem:SecondCostFunctionDefinition}
	Let ,  be two cost functions and . We write
 if  is bounded on , i.e., if . 

We have  iff for all sets : . 
\end{lem}

The definition of  with correction function has the
advantage that it is also applicable to single values instead of functions.
Thus, it enables us to prove the equivalence of two functions by comparing all
of their values instead of all subsets of the domain. The second
characterization helps to understand the flexibility of the relation
 and the expressiveness of regular cost functions. 

In order to
reduce the technical overhead and make full use of the expressiveness of 
B-/S-automata as long as possible, we usually work with concrete cost functions 
defined by automata. We view these functions as representatives of their 
-equivalence class. As a consequence, we will also consider
concrete values of the functions for a single word although this is not
well defined for the equivalence class of functions. We explicitly mention the
situations in which it is important that functions have to be considered
only up to the equivalence .

In the following, we introduce the models of B- and S-automata as well as some
known results for these models. The structures of B- and S-automata are identical.
They only differ in their semantics. We first provide the structure and
introduce the semantics later.

\begin{defi}[see \cite{regularcostfunctions}]
A B/S-automaton is a nondeterministic finite automaton (NFA) extended with a
finite set of counters. Formally, we have .
Similar to standard NFAs,  is a finite set of states,  the set of
initial states,  the set of final states and  a finite input
alphabet.  is the finite set of counters and the counter operations 
are annotated to the transitions. The finite transition relation has the 
form .
\end{defi}

The counter operations in B-/S-automata are similar to \RPRS{}. However,
we don't have the operation  but an operation  which is explained 
below. Additionally, we call B-automata \emph{simple} if
their transition relation contains only counter operations of the form 
 and . Similarly, we call S-automata \emph{simple} if their transition
relation contains only counter operations of the form  and .

The semantics of cost automata is based on the notion of a run. A run is 
a sequence  of transitions that is
compatible with the input word, i.e., for a word 
with , we have .
Similar to \RPRS{}, we
assign a value to each run of a B- or S-automaton based on the annotated counter
operations. However, the counters of cost automata support the additional 
counter operation which means \emph{check}. For the value of the run, only the
counter values of checked positions are considered. The need for this additional
action will become clear after the definition of S-automaton semantics. 
For a run  we denote the set of all counter values at checked positions 
with . A run is called \emph{accepting} if its first transition
starts in a state of  and its last transition ends in a state of .
We formally define the B- and S-semantics for a cost automaton 
as follows:

We remind the reader that  and . We see that the value of an S-run would always be  if we had no check 
operation and considered all occurring values because the counters are 
initialized with . 

Figure~\ref{fig:CounterAutomataExaple} gives an example for this definition. The
shown automata have only one counter  and both count the maximal number of
subsequent -letters in a word. On the left-hand side of the figure there is
an automaton with B-semantics which defines this function. The automaton on the
right-hand side uses S-semantics. A large class of examples is formed by the
characteristic functions of regular languages. For a language , we define the characteristic function 
to assume the value  if the word is in the language  and  
otherwise. An NFA  for  can be transformed into a B-automaton
 which defines  by taking , adding one 
counter and setting all counter operations of the transitions to . Thus,
 is  for every run . So, the value of 
every word in  is  and the value of all other words is  since 
there is no accepting run and consequently we have .
It is easy to see that the automaton  equipped with S-semantics 
defines the characteristic function  of the complement of
. 

Conversely, it is also possible to obtain regular languages from functions
defined by B- or S-automata. We remark that the language of all words which
have a value less than a fixed  in the given function is regular.
Since the bound  is fixed, a usual finite automaton can simulate the counter
values up to  and thus decide whether a given word is below or above the
threshold. 

\begin{figure}
	\begin{tikzpicture}[initial text=,>=stealth]
	\begin{scope}
		\node[state,initial,accepting] (q_0) {};
		\node[above left=1cm] at (1,1) {B-semantics:};
		\path 	(q_0) edge[loop above] node {} ()
				(q_0) edge[loop below] node {} ();
	\end{scope}

	\begin{scope}[node distance=2.5cm,on grid,auto,xshift=4cm]
		\node[state,initial] (q_0) {};
		\node[above left=1cm] at (1,1) {S-semantics:};
		\node[state,accepting,right=of q_0] (q_1) {};
		\node[state,accepting,right=of q_1] (q_2) {};
		\draw[->] 	(q_0) edge[loop above] node {} ()
				(q_0) edge[bend right] node[swap] {} (q_2)
				(q_0) edge node {} (q_1)
				(q_1) edge[loop above] node {} ()
				(q_1) edge node {} (q_2)
				(q_2) edge[loop above] node {} ();
	\end{scope}
\end{tikzpicture} 	\caption{B- and S-automaton which count the maximal subsequent occurrences
of the letter  in a word.}
	\label{fig:CounterAutomataExaple}
\end{figure}

In his work \cite{regularcostfunctions}, T. Colcombet showed several properties
of the models and the functions defined by these models. First, he was able to
prove that the two automata models define, up to the equivalence 
, the same cost functions and concluded that boundedness 
properties are decidable. Second, he showed extensive closure properties for 
regular cost functions under standard operations such as ,  or 
special kinds of projections. 

The results in the framework of regular cost functions form the basis for the
applications on the verification of infinite state systems with resources
investigated here. Therefore, we briefly repeat the major results.

\begin{thm}[Equal expressiveness, see
\cite{regularcostfunctions}]\label{thm:EqualExpressivenessOfSandB}
	Let  be some B-automaton or S-automaton. The following four
    automata are effectively computable and define a function which is
    equivalent () to the one defined by :
	\begin{itemize}
		\item a B-automaton 
		\item a simple B-automaton 
		\item an S-automaton 
		\item a simple S-automaton 
	\end{itemize}
\end{thm}

Boundedness questions have been studied for cost automata since their first
introduction. These questions exist in slightly different formulations. In
our application we reduce the boundedness question for \RPRS{} over several
steps to boundedness questions for regular cost functions.

\begin{thm}[Boundedness, see
\cite{regularcostfunctions}]\label{thm:BoundednessOfCounterautomataIsDecidable}
 Let  be a B- or S-automaton. The following problem is decidable:
 
\end{thm}

The class of regular languages possesses many closure properties. It is
known that it is closed under boolean operations as well as under projection.
This result was generalized and extended to regular cost functions.
In the context of cost functions, the boolean connectives conjunction and
disjunction correspond to  and . Furthermore, two variants of
projection for cost functions have been introduced: 
\emph{inf-projection} and \emph{sup-projection}. Consider an alphabet projection
 and let  be the
canonical extension of  to words. For a cost function 
, the -projection 
 of  is given by  

The -projection is defined analogously. 

\begin{thm}[Closure properties, see \cite{regularcostfunctions}]\
\label{thm:ClosureOfRegularCostFunctions}
	\begin{enumerate}[label=(\roman*)]
		\item Let  and  be B/S-automata. There are
effectively computable B-automata  and
 such that  and
.
	Moreover, the automata  and  can 
	be computed exactly (without ) if the input automata are 
	both B-automata.
		\item Let  be a B/S-automaton over the alphabet 
and  be an alphabet projection function. There are
effectively computable B-automata  and 
such that  and
.
	\end{enumerate}
\end{thm}


\noindent We remark that ,  and - as well as
-projection preserve the equivalence property  on
cost functions in the following sense: for  and , we have ,
 and for all projections  we
also have  and .


A first, simple consequence of the previous theorem is that we can easily
modify the values of a (concrete) cost function on a regular set of its domain. For
example, we can implement a case distinction between two cost functions.
Let  be two regular cost functions (given in form of B-automata) 
and  a regular set. 
The function 

can be defined using the above result by  where  denotes the
complement of . 


\begin{rem}\label{rem:ClosureUnderReversing}
	Similar to regular languages, the functions defined by B- or S-automata are
	closed under reversing the words. 
	Let  be an B-/S-automaton and  denote
    the letter-wise reversed word of  for 
    and . There is a correction function  and 
    a B-/S-automaton  such that 

	If no change between B- and S- automata is made, this is even possible for
	. 
\end{rem}
\begin{proof}
	By Theorem~\ref{thm:EqualExpressivenessOfSandB} there is a simple
B-automaton equivalent to . In simple B-automata the value of a
run is the same when reading the run forward or backward. Consequently
reversing all transitions and exchanging the sets  and  in this 
automaton yields the desired result automaton . 
The additional statement follows from the idea that one can simulate the 
reversed runs of cost automata by reversing all transitions and additionally 
storing whether the counters have been checked and then applying the check at
the other end of the respective increment block. This preserves exact values.
\end{proof}  





\section{Resource Structures and the Logic FO+RR}
\label{sec:ResourceStructuresAndLogic}

In the following section, we introduce resource structures and the logic
\FORR{} as a formal tool to represent systems with resource consumption and
specify combined properties on the behavior and resource consumption
of the system. First, we define a general framework of structures and logic.
Subsequently, we show that this framework is able to express our question
about bounded reachability. Finally, we establish a connection between a
subclass of resource structures and special forms of cost automata. This
connection allows us to effectively evaluate the logic on this subclass of resource
structures.

\subsection{Resource Structures}
\label{subsec:ResourceStructures}

A \emph{resource structure} is a relational structure whose relations
incorporate a notion of resource-cost. In contrast to standard structures, the
relations are not evaluated as a set of tuples but in the form of a function that
maps every tuple to a natural number or infinity. Intuitively, the assigned
value represents the amount of resources which is needed for this tuple to be in the
given relation. A value of infinity means that a tuple is not in the relation 
at all. 

\begin{defi}
 A relational signature  is a set of -ary
relational symbols. A resource structure over some signature  is a tuple
 consisting
of a universe  and  valuations  for
the relations in . The valuation of each relational symbol is a function
 mapping every tuple to its resource-cost
value or infinity.
\end{defi}

Resource structures can be considered an extension of ordinary
relational structures. A standard relation can be represented in the form
of the characteristic resource function which maps tuples in relation to
0 and others to . Conversely, we define the restriction of a
resource structure  to some allowed resource bound . This restricted structure is the ordinary relational structure
given by  with valuations defined by
.

As an example, we can represent an \RPRS{} as a resource structure in the form of
the configuration graph with a quantitative reachability relation. So, for a
given \RPRS{}  let . The
resource-cost for a pair of configurations  is defined to be the
minimal cost of all possible paths from  to . If there is no such path,
the resource-cost is set to , i.e., .


\subsection{The Logic FO+RR}
\label{subsec:LogicFORR}

Specifications for systems with resource consumption should not only be able to
express properties on the behavior of the system but also be capable of modeling
constraints on the resources. A natural question in the context of resource
structures is how many resources are needed in order to satisfy some first-order
property. We define the logic \emph{first-order+resource relations} (for short
\FORR{}) to formalize this question. Its syntax is very similar to ordinary
first-order logic but does not contain negation.

\begin{defi}[Syntax of \FORR{}]
  Let  be a  relational signature. \FORR{} formulas
  over  are:
  
  We denote the set of possible \FORR{} formulas over the signature  by
.
\end{defi}

The semantics assigns to each formula a finite number or infinity instead of a
truth value. Intuitively, this number is the amount of resources which are
necessary to satisfy the formula. More precisely, it is the minimal number 
such that  satisfies the formula when interpreted as normal
first-order formula. This idea also explains the lack of negation in the logic.
The intuitive formulation of the semantics implies that a higher amount of
allowed resources leads to more satisfiable formulas. However, this monotonicity
is incompatible with negation. In the following, we define the formal semantics
in a way to calculate this value directly. It is easy to verify that the above
described intuition and the formal semantics below coincide. 


\begin{defi}[Semantics of \FORR{}]
  Let ,  a signature with
-ary relational symbols and  a resource structure.

  The semantics  of the formula  is a function which takes a valuation for the
free variables of the formula and maps it to a finite number or infinity. It is
defined inductively by:
  
  Note that  is a constant when
. For a formula
 with , we 
also write  and set  for
. In general, we use the letters  to indicate
variables of the logic and  to indicate elements of the structure. 
\end{defi}


The formalism of \FORR{} can be used to express the bounded reachability
problem. By formalizing the definition of bounded reachability and 
simple equivalences using the formal definition of \FORR{}, we obtain:

\begin{prop}\label{prop:BoundedReachabilityIsFORRExpressible}
  Let  be an extended
resource structure representation of an \RPRS{} where  and  are two 
sets of configurations. Let the relation  be valuated by the 
characteristic function of the complement of the set , and the relation  by the 
characteristic function of .
The set  is boundedly reachable in the \RPRS{} from  if and only if
  .
\end{prop}


\subsection{Resource Automatic Structures}
\label{subsec:ResourceAutomaticStructures}

B. Khoussainov and A. Nerode introduced the concept of automatic structures in
\cite{automatic-structures}. Automatic structures are relational structures
which are representable by automata in two aspects. First, they must have a
representation of the universe in the form of a regular language. Second, their
relations must be representable with synchronous transducers which operate over
the language representation of the universe. In \cite{automatic-structures},
automata theoretic methods are used to prove that the FO-theory of every 
automatic structures is decidable. 

We extend this concept of automatic structures to the area of resource
structures. First, we define synchronous resource transducers as a
straight-forward extension of usual synchronous transducers (see
\cite{khoussainov-automata-theory-and-app} for a comprehensive introduction on
synchronous transducers). Based on this model, we define
resource automatic structures as resource structures whose relations are
representable by these transducers. Finally, we prove that the semantics of
\FORR{} is effectively computable over resource automatic structures. 


A synchronous resource transducer can be seen as a cost automaton operating
over an alphabet  consisting of vectors of elements from some original
alphabet . Additionally, the vector can contain special padding symbols
(we use \Sigma\Sigma'\Sigmannn\Sigma \cup \{\ is denoted by 
and the words of length  still by . Vectors with arbitrary words
as entries are denoted by . The symbol  (read ``pad'') is 
used for the vector consisting only of padding symbols (\bindL\}, (w,i) \mapsto
\begin{cases}
	a_i & \text{if  and  for } \\
	\\strip: (\Sigma \cup \{\ to be
the function which just removes all occurrences of \unbindn\alphVectorL{\Sigma}{n} := \bindL((\Sigma^*)^n)\NalphVectorL{\Sigma}{n}\pad\ 
occurs. Moreover, the correctly padded words  form
a regular set.

To simplify the notation in the constructions we write  to
combine two correctly padded words from vector alphabets
,  to a new correctly
padded word from  which combines the two vectors.
Formally, this can also be written in the form .
\end{defi}

\begin{defi}[Synchronous Resource
Transducer]\label{def:SynchronousResourceTransducer}
  A synchronous resource transducer for an -ary relation  over a finite alphabet  is a B-automaton 
operating over the alphabet .

  The semantics is given by:
  

  We also define  which is identical
to the above definition but uses S-automaton semantics instead of B-automaton
semantics on the automaton . We remark that in addition to this
relational semantics, we sometimes view these automata as plain cost automata
over . This point of view is mainly used in
constructions.
\end{defi}

We remark that we could repeat all the definitions with index  for
right-aligned relations. These relations are essentially the (word-wise) reversed 
relations of left-aligned ones. For a quantiative relation , let . By 
Remark~\ref{rem:ClosureUnderReversing}, it is easy to see that  can be 
defined by a left-aligned B-automaton iff  can be defined by a 
right-aligned B-automaton. 
We follow the notation in most of the literature
regarding automatic structures and present the definitions and ideas around 
resource automatic structures with left-aligned relations. However, we show 
that there is no conceptual difference to right-alignment and use right-aligned 
relations in the context of prefix replacement systems because we consider 
it to be more natural.

\begin{figure}[t]
	\begin{center}
			\begin{tikzpicture}[initial text=,>=stealth]
	\tikzstyle{ln}=[auto,font={\scriptsize}]

	
	\node[state,initial,accepting] (q1) at (2,1.5) {};
	\node[state] (q2) at (6,1.5) {};
	\node[state,initial] (q3) at (2,-1.5) {};
	\node[state,initial,accepting] (qId) at (8,0) {};
	
	\draw[->] 	(q1) edge[loop above] node[ln] {} : \icOp\rOp\nOp\icOp, \twovec{b}{\} (q1)
				(q1) edge node[ln] {} (q2)
				(q2) edge[loop above] node[ln,right=3mm,yshift=3mm] {} ()
				(q2) edge node[ln] {} (qId);
				
				
	\draw[->]	(q3) edge[bend right] node[ln,pos=0.7,below right=-2mm] {} (qId)
				(q3) edge[in=110,out=140,loop] node[ln,above left=-4mm] {}{a} : \rOp\nOp, \twovec{\} ()
				(q3) edge[bend left] node[ln,below right=-2mm,pos=0.45] {} (q2);
	
	\draw[->] (qId) edge[loop right] node[ln] {} ();
\end{tikzpicture}
 	\end{center}
	\caption{Synchronous resource transducer for the reachability-cost of the
\RPRS{} in Figure~\ref{fig:RPRSExample}}
	\label{fig:ExampleSyncResTransducer}
\end{figure}


To illustrate and motivate the previous definition, we give an example
transducer in Figure~\ref{fig:ExampleSyncResTransducer}. In order to simplify
the presentation of the automaton, we use the usual concept of -transitions 
although they are not originally part of the definition 
of B-automata. An -transition changes the state and executes the associated counter
operation but does not consume symbols from the input word. It is known that 
-transitions do not change the expressive power of the model and that it
is possible to algorithmically obtain an equivalent B-automaton. The idea behind 
this -elimination procedure is similar to the one for normal -NFAs. The 
transducer in Figure~\ref{fig:ExampleSyncResTransducer} computes the 
reachability-cost relation of the example \RPRS{} 
whose configuration graph is shown in Figure~\ref{fig:RPRSExample}. It 
operates on right-aligned words since this is more common for prefix
replacement systems. This behavior resembles the replacement 
operation which allows to replace some prefix followed by a common postfix. 
We remarked earlier, that it is possible to remove an arbitrary number of 
s or s in front of a word with a resource-cost of at most 2. This is 
reflected in the loops of  which are labeled with the counter operations 
. This sequence of counter operations corresponds 
to one removal step with detour. We remark that we left the s in the counter
sequence although they are not part of B-automaton counter operations. 
This way, the counter operations in the automaton  
resemble more closely the accumulated operations of all replacement steps. In a similar 
way we can also replace one letter by another. However, this requires first to 
pop the stack until the letter which should be changed and afterwards to push the old 
contents again. We saw that only the pop operations influence the 
resource-cost. This is handled in the state  which calculates the cost of
the pop operations, the push operations match the number of pop operations but
do not cost anything and thus do not occur explicitly in the transitions.
The state  covers the ``free'' addition at the 
beginning of a word. Nevertheless, in all cases we have to ensure that the 
last  in the word is not replaced by an  since this is not possible in 
the \RPRS{}. This is ensured by the transitions to the state 
. This state finally recognizes the identity with no more 
resource-cost after the replaced front was completely read. Although this 
particular transducer was constructed manually, we see in 
Section~\ref{sec:ReachabilityWithAnnotations} how to derive such a 
transducer algorithmically. We remark that the algorithmic construction
works in a completely different way. 

We define \emph{resource automatic structures} as a combination of the
ideas of resource- and automatic structures. Similar to automatic structures,
we require a representation of the universe in the form of a regular language.
Additionally, the resource relations are required to have a synchronous
resource transducer which computes their semantics. 

\begin{defi}[Resource Automatic Structure]
A resource structure 
is called resource automatic if it satisfies two conditions. First, there is a
finite alphabet  such that  is a regular language.
Second, for all relations  there exists a synchronous resource
transducer  such that .

Additionally, we also call a structure resource automatic if it is isomorphic to
a resource automatic structure as defined above.
This way, we also allow for resource automatic structures with a universe 
which is not a word-language.
\end{defi}

We first remark that for every resource automatic structure  and
every  the structure  is automatic. As
remarked earlier, it is possible to simulate the behavior of cost automata
up to a fixed bound  with normal finite automata by extending their state
space. Thus, one can easily obtain synchronous transducers for the relations in
 from the resource transducers. 


\begin{rem}\label{rem:ResourceAutomaticRightAligned}
	One can also consider resource automatic structures given by right-aligned
	synchronized resource transducers. These structures are equally expressive
	as resource automatic structures given by left-aligned transducers.
\end{rem}
\begin{proof}
	As remarked earlier, if there is a right-aligned (B-)resource transducer for 
	some relation , there is a left-aligned resource transducer for 
	. Consequently, one directly obtains an isomorphic structure
	given by left-aligned resource transducers (with the isomorphism ). 
\end{proof} 

The rest of this section is dedicated to show how we can compute the semantics
of \FORR{} formulas in a given resource automatic structure. The proof is
divided into a lemma followed by the main result. The proof of the main
result is quite similar to the decidability proof of \FO{} over automatic
structures. We inductively construct synchronous resource transducers which
(approximately) compute the semantics of \FORR{} formulas with free variables.
In Section~\ref{sec:Preliminaries}, we saw that the  and  of two
cost automata is again representable by a cost automaton. This directly
enables a simulation of  and  in \FORR{} formulas on the level of
automata. Although we also saw that  and -projection can be realized
by cost automata, these operations do not directly correspond to the
semantics of  and  in \FORR{}. The reason for this is that
alphabet projection does not preserve the encoding of convoluted words. If one
projects away the longest word in a convolution of words, the result contains
a sequence of  symbols at the end. Hence, the result is not correctly
padded. In the following lemma we show how to solve this problem.
The main idea
is to divide the calculation of the semantics of  and  into
two  or  operations by the following idea. We use
- and -projection in a first step and add an additional step to
cover sequences of  symbols at the end. In this second step, we use that
computing the  and  over all runs is part of B- and S-automaton
semantics. Thus, we can implement such a computation by adding new transitions
to an automaton.

\begin{lem}\label{lem:InfAndSupLikeFORRAreComutable}
	Let  be a finite alphabet,  a synchronous resource
transducer operating over . There are effectively 
computable synchronous resource transducers , 
 operating over  and a correction
function  such that for all :
\begin{enumerate}[label=(\roman*)]
	 \item 
	\item 
\end{enumerate}
\end{lem}
\begin{proof}
The proof of both parts of the lemma is divided into two similar parts. First,
we show how to transform the single  or  operation into two
operations of which the first is the - or -projection as defined in
\cite{regularcostfunctions}. In the second part, we exploit the definition of
cost automata to compute the remaining ``'' and
``''.

We start with part (i) of the statement in the lemma. So, let  be the function defined by 
when interpreted as normal B-automaton. Since  is a
regular set, we can assume w.l.o.g. that  for all . This ensures that the value of the -projection
is determined only by correctly encoded (vector-)words. Let furthermore  be the projection function
removing the last component. With the above explained argument, we can divide
the  in the following way. We obtain that for
all :

 
By Theorem~\ref{thm:ClosureOfRegularCostFunctions}, we obtain a
B-automaton  and by Theorem~\ref{thm:EqualExpressivenessOfSandB}
an S-automaton  operating over  such
that for some correction functions  and :

We now show how to construct an S-automaton  which computes
the last . The idea of this construction exploits the special semantics
of S-automata. For S-automata, the value of a word is the  of the values
of all accepting runs. Thus, we can construct an automaton computing  by making all runs of
 on some  also accepting for . We
implement this by introducing -transitions in positions with
-transitions.  Formally, let . We define
 with:
	
	Let  be an accepting run of  on .
We construct the run  of  on  out of the run
. First, copy the  part of the run  into the first
component of the state vector and set the second component to . Subsequently,
take the -transition to change the second component to . Then, copy the
 part of the run  into the first component and set the second
component to . This is possible because of the -transitions which are
inserted at the positions of the -transitions. By the construction of the
transition relation, this is a valid accepting run of  on
 which induces the same counter sequence as  and thus has the
same cost-value. Consequently, .

	Conversely, let  be an accepting run of  on . Since all final states have a  in their second component and the run 
can only change the second component from  to  (and not back), the run
 can be split into a part which uses states with a  in the second
component and part which uses states with a  there. By construction, the
first part consumes  and the second part uses -transitions at
positions with -transitions in . Consequently, it is
possible to construct a run  of  on  for
some  which induces the same counter sequence as . Therefore,
.


We use a rather lengthy procedure to eliminate -transitions in S-automata,
which is described in more detail in \cite{la11}. The main problem in 
-elimination for S-automata arises from the fact that loops of 
-transitions with  counter operations are meaningful for the 
semantics of S-automata since the supremum over all runs is built. Consequently,
one could loop more and more often through the -increment-loop in order
to obtain large counter values before the next check. The -elimination 
procedure systematically searches for these loops and adds a control component 
to the automaton indicating that a certain counter may have an arbitrarily 
large value (due to looping in -increment-loops). 
If a counter that is marked to have such an arbitrary large value hits a 
 operation, it just gets reset but not checked. 

First note that for every run  of the -automaton, there is a similar 
run  of the -free automaton with at least the same value because
skipping a check can only increase the value of the run. 

For the converse, consider a run  of the automaton with eliminated 
-transitions that skips a check because the counter was indicated to be 
arbitrarily large. We distinguish two cases. First, if no counter is checked,
the value of  is . However, if we construct
a run  similar to  on the -automaton, the counter is checked
at the position where the check is skipped in . In order to obtain the
value  on the -automaton, we construct a sequence  of
runs such that each run loops  
times through the -increment-loop before the check. All these runs are valid
for the input word and yield a value of at least . Since the value of a word on an
S-automaton is determined by the supremum over all runs, the value is 
as the value of  in this case. Second, if there is some counter checked
in , the value of  is some finite . When transferring the run
 to a similar run  of the -automaton, all the counters 
checked in  are also checked in  with the same values. 
Consequently, we just have to ensure that the
additional check, which is skipped in  but occurs in ,
does not decrease the value of the run. To achieve this, we construct the run
 such that it loops  times through the -increment-loop before 
the check. Thereby, the counter has at least value  before
the additional check occurs and the value of  stays  because the
value of a run is determined by the minimal checked counter value in S-automata.

By Theorem~\ref{thm:EqualExpressivenessOfSandB}, we obtain an equivalent
B-automaton  and thus obtain for appropriate correction 
functions  and  in total:

 
We now prove part (ii) of the lemma with similar techniques. However, we now
exploit the semantics of B-automata to implement the additional
-computation.  So, let  and  be like in the previous case but now
assume w.l.o.g. that all words  have
. For the same reasons as above, we obtain


Again by Theorem~\ref{thm:ClosureOfRegularCostFunctions} and
Theorem~\ref{thm:EqualExpressivenessOfSandB}, we obtain a simple B-automaton
 which computes the -projection:

We now create the automaton  by taking  and
making all states final from which one can reach a final state with only
-transitions. This yields an automaton which computes a function which is
slightly different from the real  but still correct w.r.t. a
correction function . Let  be the number of states in
 and . We show that

For the first inequality note that  is well-ordered. Thus, there
is a  such that 
assumes the value of the infimum. W.l.o.g. this infimum is smaller than 
(otherwise there is nothing to show in the first inequality). By the definition
of the model, there is an accepting run  of  on  such that the cost-value of this run is . Let  the front part
of  which reads ,  the state after reading  and 
the maximal checked counter value at this point in the run. By the definition of
the semantics of B-automata, the maximal checked counter value can only increase
in the course of a run. Moreover, the run  shows that the state  can
reach a final state with only -transitions. Therefore,  is an
accepting run of  with the value  and

Conversely, let now  be an accepting run of  on  with cost-value . If there is
no such run, we have  and there is nothing to show. By construction,
there is a final state  of  which is
reachable from  with  -transitions. Since there is a loop-free
path, we have . We look at the run  which is created by
appending these -transitions to . The run  is accepting for
 on . Since every transition has at most one
-operation ( is simple), the cost-value of  is
limited by . Altogether:

Alternatively, it also would have been possible to use the same approach as for
part (i). However, the presented way has the advantage that a costly
-elimination procedure is not necessary. The major reason why such an
approach is not possible for the first part of the lemma is the semantics of
loops consisting only of -transitions in cost automata. In S-automata,
paths with high values are preferred. Consequently, it would change the value
of a run to loop through some increment again and again. In the case of
B-automata it is sufficient to take it once or twice in order to obtain a low
counter value with a reset located on the loop. 
\end{proof}

We now have all prerequisites for a concise formulation of the main theorem on
resource automatic structures. We first inductively translate a formula
 with free variables into a synchronous resource transducer which
calculates a function that is -equivalent to the function defined by the
semantics of . Finally, we
explain why the equivalence relation  is no real restriction and
how to calculate precise values of the semantics.

\begin{thm}\label{thm:FORRisEffectivelyComputableOnRAStructures}
 There is an algorithm which takes as input a resource automatic structure 
 in form of resource
transducers and an \FORR{} formula with at least one free variable over 
the signature of  and outputs a synchronous resource transducer 
that defines an equivalent function to . 
\end{thm}
\begin{proof}
Let  be the formula with  free variables.

We show by induction on the structure of the formula how to construct a
synchronous resource transducer  such that for some
correction function :


\inductionstart{Let }
  The following transducer obviously captures the semantics of :

\inductionend\inductionstart{Let }
  The following transducer captures the semantics of :

where  is given as follows with  s.t. 


\inductionend\inductionstart{Let }
  By the definition of a resource automatic structure, there is a transducer
   such that  


\inductionstep{Let }
By the induction hypothesis, there are transducers ,
 such that  and . The
free variables of  consist of the free variables of 
combined with the free variables of . Let  be the free variables of . In a
first step, the two automata  and
 have to be adapted such that they take all free
variables of  as input. This can easily be achieved by adding new
components to the input vector which are not taken into account by the
automaton. Furthermore, we possibly have to reorder the components in the input
of the automaton. This can be achieved by reordering them in the transition
relation accordingly. As a result, we obtain automata 
and  operating over the input alphabet
 such that:

By Theorem~\ref{thm:ClosureOfRegularCostFunctions}, we can construct an
automaton  such that the equation
 holds. For this automaton, we have


\inductionstep{Let }
	This step is analog to the previous one when replacing  by . 
\inductionstep{Let }
	By the induction hypothesis, there is an automaton 
such that . We assume w.l.o.g that the free variable
 is represented by the last component of the input vector of
. By Lemma~\ref{lem:InfAndSupLikeFORRAreComutable}, there
is an automaton  such that
 for all
. Altogether, we have:


\inductionstep{Let }
	This step is again analog to the previous one. We just use the second part
of Lemma~\ref{lem:InfAndSupLikeFORRAreComutable} instead of the first part.\qedhere
\inductionend
\end{proof}

\noindent It remains to explain how to cover \FORR{} sentences. We remind the reader of 
the fact that the value of an \FORR{} sentence is a constant. 
Calculating this constant value of a sentence up to the equivalence relation 
 means just checking whether the value is infinite or not.
We present this separately from the case with free variables in order to 
emphasize the computational steps necessary to decide whether a formula 
has a finite value.  

\begin{cor}
	Let  be a resource automatic structure like in the previous 
	theorem and  an \FORR{} sentence over the signature of .
	It is decidable whether . 
\end{cor}
\begin{proof}
First, we remove the outermost quantifier from the sentence. Now we can
apply Theorem~\ref{thm:FORRisEffectivelyComputableOnRAStructures} and get 
a synchronized resource transducer  operating over . 
If the outermost quantifier is existential, the formula has a finite value 
if and only if there is some accepting run on . 
If the outermost quantifier is universal, the automaton is accepting if and 
only if the automaton is bounded. This can be checked by 
Theorem~\ref{thm:BoundednessOfCounterautomataIsDecidable}.
\end{proof}

The decision procedure described above paves the way for computing precise
values of \FORR{} formulas. First, one can check whether the value of a
formula  (for some possible valuation) is infinite by the presented
decision procedure. If it is infinite, we are done because 
preserves boundedness and thus the precise value of this formula is also
. Otherwise, it is known that the formula is bounded and there is some
 with . We remarked earlier
that this  is exactly the smallest  such that  when  is interpreted as normal \FO{}-formula. Since the
structures  are (standard) automatic structures for all
fixed , this can be checked algorithmically. Thus, one can check the above
conditions for all possible  and it will terminate because we already know
that the value is finite.


We remark that the previous theorem only covered resource automatic
structures whose universe contains all words in . However, this is no real
restriction. By definition, the universe  is a regular
language. Consequently, we can extend the universe to full  and
set the value of all relations for elements outside of  to . 
Moreover, we introduce two new relations  and  valuated
with the characteristic functions of  and its complement language. 
Similar to standard first-order logic, it is then possible to adapt 
formulas by restricting the quantifications to elements of  by 
transforming  into  
and  into . 
With the standard arguments, one can show that this provides a reduction
of arbitrary resource automatic structures to those with universe . 


\section{Computing Reachability with Annotations}
\label{sec:ReachabilityWithAnnotations}

The bounded reachability problem can be seen as a reachability problem with
annotations at the transitions. The value associated with a path can be computed from the
sequence of annotations -- in our scenario the counter operations. When
computing the transitive closure, we not only have to calculate basic 
reachability but also the (combined) annotations of the paths among the nodes.

In the following, we introduce a general algorithm to compute reachability with
annotations on prefix replacement systems. This procedure is based on the
widely known saturation principle. It creates an output which can directly be
transformed into a synchronous transducer calculating the annotations for paths
between a pair of system configurations. First, we formally describe the
requirements for an annotation domain. Subsequently, we explain the actual
saturation procedure and show how the reachability-cost problem for \RPRS{} can
be represented in the developed framework.

\subsection{Annotation Domains}

An annotation domain which is compatible with saturation has to satisfy certain
requirements. First, the concatenation operation on the annotations has to be
associative because the order in which paths in the pushdown system are
combined during saturation must not be important. Second, the termination of
saturation normally results from the fact that there are only finitely many
possible transitions in a finite automaton which can be added. However, this
argument does not suffice anymore if additional annotations from a potentially
infinitely large domain are considered. Since there may exist infinitely many
paths which are all annotated differently, this problem is inherent to the
considered question. Motivated by the search for \emph{good} or \emph{cheap}
paths in the context of the bounded reachability problem, we equip the
annotations with a partial order. This order has to be well-founded and must
not contain infinite anti-chains. Such an order is often called well-partial
order or partial well-order in the literature. Finally, we need to be able to
reverse paths because the saturation procedure we adapt operates in both directions
(predecessors and successors) simultaneously. Consequently, we require a
compatible reverse operation on the annotations. We formalize these requirements in the
form of \emph{well-partially ordered monoids with involution}.

\begin{defi}[Well-Partially Ordered Monoid with Involution]
	A well-partially ordered monoid with involution 
    is a 5-tuple   where:
	\begin{enumerate}[label=(\roman*)]
		\item  is a monoid
		\item  is a well-partial order. The order is compatible with the
           monoid operation, i.e., .
		\item  is the so called \emph{reverse} function. It is
an involution, i.e., . Moreover, it satisfies the functional
equation .
		\item Order and the reverse function are compatible, i.e.,  
	\end{enumerate}
\end{defi}

\noindent We present a concrete example for such a structure later. In
Section~\ref{subsec:CostReachability}, we show how we can use this
formalism to obtain a quite natural and concise representation of sequences of B-counter operations. 

Before constructing specific instances of well-partially ordered monoids with involution,
we exhibit some general properties. Direct products are a useful tool
in many automaton constructions. Hence, we verify that the direct product of two
well-partially ordered monoids with involution is well-defined. This is
mostly formal checking that the properties are satisfied. 

\begin{lem}\label{lem:ProductOfRIOrderedMisRIOrderedM}
	Let  and
 be two
well-partially ordered monoids with involution. We define the
\emph{direct product}  of these monoids in the usual way 

  with component-wise application of the operation , the
involution  and the compo\-nent-wise order , i.e., .


  The monoid  is a well-partially-ordered monoid with
involution.
\end{lem}
\begin{proof}
  It is clear that  is a monoid. The compatibility of the
reverse function and the order are easy to check.
  In \cite{Higman52}, G. Higman showed that the component-wise order on the
product of two well-partial orders is also a well-partial order.
\end{proof}

We now define a general form of prefix replacement systems whose replacement
rules are annotated with elements from a well-partially ordered monoid with
involution. With the above remark that we can encode sequences of 
B-counter operations in a well-partially ordered monoid, the following 
definition can be seen as a generalization of counter automata.

\begin{defi}[Monoid Annotated Prefix Replacement System]\label{def:ResourcePRS}\ 

Let  be a well-partially ordered
  monoid with involution.
  A monoid annotated prefix replacement system is a triple  consisting of a finite alphabet , a
finite transition relation  and a well-partially ordered monoid with
involution .
  The prefix replacement rules in the transition relation  are annotated with elements from the monoid.
We also write  for a prefix replacement rule .

 Let  be two configurations. We say  is an -successor of 
and write  if . Let  be a sequence
of configurations such that  for all
. We write  with .
\end{defi}


\subsection{Annotation Aware Saturation}
\label{subsec:AnnotationAwareSat}

It is already known for quite some time that saturation methods can be used to
calculate the point-to-point reachability relation of pushdown- or prefix
replacement systems. In addition, it is also known that it is possible to
construct a synchronous transducer which computes this reachability relation.
This shows that the configuration space of a prefix replacement system with the
reachability relation is an automatic structure. One approach for such a
construction can be found in \cite{gtt-saturation}. Although this 
algorithm is for ground term replacement systems, it is easy to see that a
prefix replacement system is just a special case. We adapt the algorithm for
this special case and extend it to fit our needs.

The algorithm performs a two-sided saturation. Our adapted variant operates
over two -NFAs that share some of their states. These two automata read
the changed prefixes of the two configurations. The common suffix is
ignored\footnote{This definition comes from the algorithm's origin as ground
tree replacement algorithm. There, the two subtrees which are framed by the
common (tree-)context are read by the automata.}. A pair  of
configurations with common suffix  is accepted by the pair of automata if
there is a run of the first automaton on  and a run of the second automaton
on  such that both end in the same (shared) state. The saturation algorithm
starts with two NFAs that recognize one rewrite step of a given prefix
replacement system. Then, subsequently, new -transitions which each
simulate one or more prefix replacement steps are added in both automata. The
major reason for this two-sided construction is the possibility of very
different word lengths on both sides of a prefix replacement rule. In contrary
to usual pushdown systems, the left-hand side of a rule in prefix replacement
systems may be much longer than the right-hand side. 

Our adaptation extends the original algorithm to keep track of the annotations. We
implement this by annotating the transitions of the -NFAs with elements
from the annotation domain of the prefix replacement system. Formally, we
define those NFAs by:
\begin{defi}[Monoid annotated -NFA]
A monoid annotated -NFA is a tuple . The components
 are as in usual NFAs.  is a
well-partially ordered monoid with reverse-function. The finite transition
relation  is annotated with elements from . It 
has the form . 
  
Each run of the automaton on a word  naturally defines a
monoid element. The value  of a run is defined by the concatenation of the
values of the used transitions along the run. Consequently, the (finite) set of all possible
accepting runs of the automaton on the word  induces a set of monoid elements
. Additionally, we write  to
indicate that there exists a run from  to  on the word  with
accumulated annotation .
\end{defi}

\begin{algorithm}[t]
 \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
 \SetKw{Continue}{continue}
 \SetKwFor{Find}{Find}{}{}
 \SetKwIF{If}{ElseIf}{Else}{if}{then}{else if}{else}{endif}
 \Input{monoid annotated prefix replacement system }
 \Output{monoid annotated automata  and }

   
  
    and
 with
	,
	
	 
	
	
	
  
  
  
  \While{automata can be updated}{
	
	
	\Find{ and states  s.t.
,
}{
	  
	  
	  \uIf{ with }{
		  
		}
	  \ElseIf{}{
		  
		}
	  , 
	  
	  \Continue{}}\Find{ and states  s.t.
, }{
	  
	  
	  \uIf{ with }{
		  
		}
	  \ElseIf{}{
		  
		}
	  , 
	  
	  \Continue{}}}\KwResult{, }
  \caption{Two-sided saturation procedure\label{algo:GTTSaturation}}
\end{algorithm}

\begin{figure}[t]
	\begin{center}
		\begin{tikzpicture}
  \begin{scope}[shift={(0,0)}]
	\node[anchor=base] (reprule) at (0,1.5) {};
	\node (reprelation) at (0,0) {};
	\draw[-implies,double equal sign distance,double,thick] (reprule) -- (reprelation);
  \end{scope}
  
  \begin{scope}[shift={(4,0)}]
	\node[dotstyle] (WBegin) at (1,1.5) {};
	\node[left=0.7cm] at (WBegin) {};
	\node[left] at (WBegin) {};
	\node[dotstyle] (WEnd) at (3.5,1.5) {};
	\node[right] at (WEnd) {};
	
	\draw[automatapath] (WBegin) -- (WEnd) 
		node[midway,above=1mm] {} 
		node[midway,below=1mm] (w2Annot) {}
		coordinate[midway] (pathmid);
	
	\path let \p1 = (pathmid) in node (autrelation) at (\x1,0) {};
	
	\draw[-implies,double equal sign distance,double,thick] (w2Annot) -- (autrelation);
  \end{scope}
  
  \begin{scope}[shift={(1 ,-4)}]
	\node[dotstyle] (AnonBegin) at (0,2) {};
	\node[left=0.7cm] at (AnonBegin) {};
	\node[left] at (AnonBegin) {};
	\node[dotstyle] (AnonEnd) at (3,2) {};
	\node[above] at (AnonEnd) {};
	
	\draw[automatapath] (AnonBegin) -- (AnonEnd) node[midway,above=1mm] {};
	
	\node[dotstyle] (WA1Begin) at (0,1) {};
	\node[left=0.7cm] at (WA1Begin) {};
	\node[left] at (WA1Begin) {};
	\node[dotstyle] (WA1End) at (3.5,1) {};
	\node (WA1Ext) at (4.5,1) {};
	\node[below] at (WA1End) {};
	
	\draw[automatapath,>=] (WA1Begin) -- (WA1End) node[midway,above=1mm] {} node[midway,below=1mm] (w1Annot) {};
	\draw[automatapath,dotted] (WA1End) -- (WA1Ext);
	
	\draw[->,red] (AnonEnd) -- (WA1End) node[midway,right=2mm,anchor=base] {} 
		node[midway,right=6mm,anchor=base] (epsAnnotM) {} 
		node[midway,right=15mm,anchor=base] (epsAnnotMR) {} 
		node[midway,right=26mm,anchor=base] (epsAnnotML) {};
  \end{scope}

	\draw[->] (reprelation.south) .. controls +(-90:2cm) and +(90:2.3cm) .. (epsAnnotM);
	\draw[->] (autrelation.south) to[out=-90,in=90] (epsAnnotMR);
	\draw[->] (w1Annot.east) to[out=-20,in=-90] (epsAnnotML);

 \end{tikzpicture} 	\end{center}
	\caption{Illustration of the idea of Algorithm~\ref{algo:GTTSaturation}}
	\label{fig:SaturationIdea}
\end{figure}


We describe the intuitive idea of Algorithm~\ref{algo:GTTSaturation} by first
explaining the goal of the algorithm followed by the explanation of one
saturation step in the first of the two automata. We remarked already that the
two automata start with recognizing the successor relation of prefix
replacement. Formally, this means that for every prefix replacement rule
, there is a (shared) final state
 in  and . Moreover, there
are runs 
and . During
the saturation procedure, we want to add -transitions which enable the
automata to simulate one or more prefix replacement steps on their own, such
that there is a run  iff  and symmetrically (but reversed) also that there is a run
 iff . Note that this especially means that both runs
imply . 

In order to enable  to simulate one more application of the
replacement rule , the algorithm uses the following
strategy, which is illustrated in Figure~\ref{fig:SaturationIdea}. First, it
finds a word  and a fitting run  (notice that  is always possible). By
our intuition this means . Subsequently, the
algorithm searches for a run  and
adds a transition from  to  in . After reading , the
automaton can use the new -transition and is now in a state as if it would
have read  in the first place. This captures the sequence of replacement
operations , which is 
possible because  for  by construction.
Thereby, the automaton  can now simulate one execution of this replacement sequence on its own. 

In addition to the correct operation of the replacement rules, the algorithm
also keeps track of the annotation. We saw that the -transition simulates
replacement rules with accumulated annotation . Additionally, it
skips the part of reading  on , which also contains some
annotation . Since  would have read this annotation after
the replacements were made,  we also have to include  into the
-transition. For this reason, the complete annotation of the
-transition to add is . However, we only add this
transition if there is not already a transition with the same source and
destination and a better (-smaller) annotation. This ensures that we only
have finitely many transitions in the automaton although there might be
replacement paths with arbitrarily many different annotations for a pair of
configurations. Additionally, we remove all similar -transitions with a
larger annotation for the same reason. 

The saturation in  is symmetric with the roles of
 and  exchanged. However, the computation of
the annotation is a mirror-image of the computation in 
because  simulates the replacement steps backwards. 

The result of the algorithm is a pair of automata which recognizes the
reachability relation and also contains all minimal annotations for paths from
the first to the second configuration. In the following, we provide formal
arguments for termination and correctness of the algorithm. This includes a
detailed analysis of the saturation steps and the book-keeping of the
annotations.

\begin{rem}
	Algorithm~\ref{algo:GTTSaturation} terminates for every input.
\end{rem}
\begin{proof}
	There are only finitely many pairs of states in  and .
Moreover, there are only two possibilities where a pair of states is considered
several times in the algorithm. First, the transitions can be updated because a pair of runs
leading to a smaller annotation was found. However, this can occur only finitely
many times since the order on the annotation domain is well-founded. Second,
several transitions can be added because the annotations are incomparable. This
can occur only finitely often, too. Otherwise this yields a (size)
increasing sequence of anti-chains. The union of all sets in the sequence would
be an infinite anti-chain in contradiction to the definition of the annotation
domain. Hence, the algorithm terminates after a finite number of steps.
\end{proof}

\begin{lem}\label{lem:CorrectnessOfGTTSaturation}
  Let  be a monoid annotated prefix replacement system, 
and  the result of Algorithm~\ref{algo:GTTSaturation}. For two
configurations  with  the following holds:
  \begin{enumerate}[label=(\roman*)]
   \item If , then there are runs  and  for some  and  such that ,   and .
	\item If there is a run  for some , 
	then  for all .
	\item If there is a run  for some , 
	then  for all .
  \end{enumerate}
\end{lem}
\begin{proof} \ 
	\begin{figure}[t]
		\begin{center}
			\begin{tikzpicture}
  \begin{scope}[shift={(0,4)}]
	\draw (0,0) -- (6,0);
	\node[left] (u) at (0,0) {};
	\draw (2,-0.25) -- (2,0.25);
	\node[above] (uBar) at (1,0) {};
	\node[above] (xBarU) at (4,0) {};

	\node[dotstyle] (A1StartU) at (0,0.8) {};
	\draw[dotted] (A1StartU) -- (0,0);
	\node[left] at (A1StartU) {};
	\node[left=0.7cm] at (A1StartU) {};
  

	\node[dotstyle] (A1EndU) at (2,0.8) {};
	\node[below] at (A1EndU) {};
	\draw[dotted] (A1EndU) -- (2,0);

	\draw[automatapath] (A1StartU) -- (A1EndU) node[midway,above,color=red] {};

	\node[dotstyle] (A1ExtStartU) at (2,1.3) {};
	\node[above] at (A1ExtStartU) {};
	
	\draw[->] (A1EndU) -- (A1ExtStartU) node[midway,left,color=black] {} node[midway,right=1mm,dotstyle,color=red] (EpsTransitionResources) {};

	\node[dotstyle] (A1ExtEndU) at (3,1.3) {};
	\node[above] at (A1ExtEndU) {};
	\draw[dotted] (A1ExtEndU) -- (3,0);

	\draw[automatapath] (A1ExtStartU) -- (A1ExtEndU) coordinate[midway,below=0.3cm] (A1ExtMid) node[midway,above,color=red] {};

	
  \end{scope}

  \begin{scope}[shift={(0,2)}]
	\draw (0,0) -- (6,0);
	\node[left] (v) at (0,0) {};
	\draw (2,0) -- (2,0.25);
	\draw (3,-0.25) -- (3,0);
	\node[above] (vBar) at (1,0) {};
	\node[below] (vHat) at (1.5,0) {};
	\node[above] (xBarV) at (4,0) {};
	\node[below] (xHatV) at (4.5,0) {};

	\node[dotstyle] (A2StartV) at (0,0.8) {};
	\draw[dotted] (A2StartV) -- (0,0);
	\node[left] at (A2StartV) {};
	\node[left=0.7cm] at (A2StartV) {};
  
	\node[dotstyle] (A1StartV) at (0,-0.8) {};
	\draw[dotted] (A1StartV) -- (0,0);
	\node[left] at (A1StartV) {};
	\node[left=0.7cm] at (A1StartV) {};

	\node[dotstyle] (A2EndV) at (2,0.8) {};
	\node[right] at (A2EndV) {};
	\draw[dotted] (A2EndV) -- (2,0);
	\node[dotstyle] (A1EndV) at (3,-0.8) {};
	\draw[dotted] (A1EndV) -- (3,0);
	\node[right] at (A1EndV) {};
	\node[dotstyle] (A1MidV) at (2,-0.8) {};
	\draw[dotted] (A1MidV) -- (2,0);
	\node[above] at (A1MidV) {};

	\draw[automatapath] (A2StartV) -- (A2EndV) node[midway,above,color=red] (Ruv) {};
	\draw[automatapath] (A1StartV) -- (A1MidV) node[midway,above,color=red] (Rwv) {};
	\draw[automatapath] (A1MidV) -- (A1EndV) coordinate[midway,above=0.3cm] (A1RegMid) node[midway,above,color=red] {};
	
	\node[anchor=west,minimum width=0.99cm,fill=black!20,fill opacity=0.5,text opacity=1] (vHatPrime) at (2,0) {};
  \end{scope}

  \draw[->,dashed] () -- ();

  \begin{scope}[shift={(0,0)}]
	\draw (0,0) -- (6,0);
	\node[left] (w) at (0,0) {};
	\draw (3,-0.25) -- (3,0.25);
	\node[above] (wHat) at (1.5,0) {};
	\node[above] (xHatW) at (4.5,0) {};

	\node[dotstyle] (A2StartW) at (0,-0.8) {};
	\draw[dotted] (A2StartW) -- (0,0);
	\node[left] at (A2StartW) {};
	\node[left=0.7cm] at (A2StartW) {};


	\node[dotstyle] (A2EndW) at (3,-0.8) {};
	\draw[dotted] (A2EndW) -- (3,0);
	\node[right] at (A2EndW) {};

	\draw[automatapath] (A2StartW) -- (A2EndW) node[midway,above,color=red] {};
  \end{scope}

  \draw[decorate,decoration={brace,amplitude=5pt}] (6.5,4.8) -- (6.5,2.8) node[midway,right=5pt,color=red] (Rbar) {};
  \draw[decorate,decoration={brace,amplitude=5pt}] (6.5,1.2) -- (6.5,-0.8) node[midway,right=5pt,color=red] {};

  \draw[decorate,decoration={brace,amplitude=5pt}] (8,5.3) -- (8,-0.8) node[midway,right=5pt,color=red] {};

  \draw[->,color=red] (Rbar) .. controls +(90:2cm) and +(0:2cm) .. (EpsTransitionResources);
  \draw[->,color=red] (Ruv) .. controls +(20:1.5cm) and +(-70:1cm) .. (EpsTransitionResources);
  \draw[->,color=red] (Rwv) .. controls +(60:1cm) .. +(1cm,1cm) 
							.. controls +(35:3cm) and +(-50:1cm) .. (EpsTransitionResources);
 \end{tikzpicture} 		\end{center}
		\caption{Illustration of the 1st case of part (i) of Lemma
	\ref{lem:CorrectnessOfGTTSaturation}}\label{fig:PartOneGTTSaturationProof}
  \end{figure}
  We first show (i) by induction on the number of replacement steps. Let 
   be as in the algorithm.
  
  \inductionstart{Let :}
	By definition of the successor relation, there is a replacement rule
 and a common suffix  such that ,  and . By definition of the automata
 and , which are included in 
and , there are runs  and . Additionally, .
  \inductionstep{Let :}
	By the definition of , there is a  such that  with . By the
induction hypothesis, there is a common suffix  such that ,  and there are runs  and  for some state 
such that .
Additionally, there is a common suffix  such that  ,
 and . Now, distinguish
two cases depending on the length of  and .

\textbf{1st case:} :
	\begin{indt}
	  The used words and runs in this case are shown in Figure
\ref{fig:PartOneGTTSaturationProof}.

	  One can write  in the form . With this
notation, we can also write .

	  By construction of the automata  and ,
there are two runs  and  with . 
Additionally, we have  and thus 
.

	  By the saturation algorithm, there is a transition  in  such that . Using this -transition, one can create the
following run:
	  
	  So, this run and the run  satisfy the first condition of the lemma. By
the induction hypothesis,  we have . By the
monotonicity of the monoid operator, we have 


	\end{indt}
	\textbf{2nd case:} :
	\begin{indt}
		This case is mostly analogous to the first one. The roles of
 and  are exchanged. One can write  in the
form  and  in the form .

		By construction of the automata  and ,
there are runs 
and  with . Furthermore, the inductively given run
 can be divided into
two parts .

		Since , the the saturation algorithm guarantees that 
		there is a transition  in 
		 such that . 
		Using this -transition, one can create the following run:
		
		So, this run and the run  satisfy the first condition of the lemma. 
		Consequently, we obtain by the application of the functional equation of
 and the compatibility with the order:
		
	\end{indt}
  \inductionend
  
\noindent	Now we show the parts (ii) and (iii) by induction on the number of
steps of the algorithm. Depending on the automaton in which the saturation step was
executed either the statement of part (ii) or of part (iii) needs to be proven.
Nevertheless, we need to prove both statements together because of the
interplay of both automata in the saturation procedure.

	\begin{figure}[t]
		\begin{center}
			\begin{tikzpicture}
	\tikzstyle{graybox}=[fill=black!10]
	\tikzstyle{grayboxtext}=[anchor=base west,text width=3.75cm,align=left]
	\tikzstyle{highlightrun}=[color=blue!80]
  \begin{scope}[shift={(0,4)}]
	  \draw (0,0) -- (6,0);
	  \node[left] (u) at (0,0) {};
	  
	  \draw (3,-0.25) -- +(0,0.25);
	  \draw (4,-0.25) -- +(0,0.5);
		
	  \node[above] at (5,0) {};
	  \node[above] at (2,0) {};
	  \node[below] at (1.5,0) {};
	  \node[below] at (3.5,0) {};

	  \node[dotstyle] (UBegin) at (0,0.8) {};
	  \draw[dotted] (UBegin) -- (0,0);
	  \node[left=0.7cm] at (UBegin) {};
	  \node[below left] at (UBegin) {};

	  \node[dotstyle] (UMid) at (3,0.8) {} edge [out=130,in=50,loop] node[pos=0.3,left] {} node[midway,above=-1mm,color=red] {} ();
	  \draw[dotted] (UMid) -- (3,0);
	  \node[below left] at (UMid) {};
	  \node[below right] at (UMid) {};
	  
	  \node[dotstyle] (UEnd) at (4,0.8) {};
	  \draw[dotted] (UEnd) -- (4,0);
	  \node[below right] at (UEnd) {};

	  \draw[automatapath] (UBegin) -- (UMid) node[midway,above,color=red] {};
	  \draw[automatapath,highlightrun] (UMid) -- (UEnd) coordinate[midway,below=3mm] (UMidMarker) node[midway,above,color=red] {};
	  
	  \begin{pgfonlayer}{background}
		\fill[graybox] () rectangle ();
	  \end{pgfonlayer}

	  \node[graybox,grayboxtext] at (6.5,0.8) {i.h.: }; 
	  
	  \node[grayboxtext] at (6.5,-0.3) {\hphantom{i.h.: }};

	  \draw[curlybracket] ()--() node[midway,above=3mm,font={\small}] {};
	  \draw[curlybracket] ()--() node[midway,above=3mm,font={\small}] {only };
	  
  \end{scope}

  \begin{scope}[shift={(0,2)}]
	  \draw (1,0) -- (6,0);
	  \node[left] (v) at (1,0) {};

	  \draw (3,-0.25) -- +(0,0.5);
	  \draw (4,-0.25) -- +(0,0.5);

	  \node[above] at (5,0) {};
	  \node[above] at (2,0) {};
	  \node[above] at (3.5,0) {};

	  \node[dotstyle] (V2Begin) at (1,0.8) {};
	  \draw[dotted] (V2Begin) -- (1,0);
	  \node[dotstyle] (V2End) at (3,0.8) {};
	  \draw[dotted] (V2End) -- (3,0);
	  \node[left=0.7cm] at (V2Begin) {};
	  \node[below left] at (V2Begin) {};
	  \node[above right] at (V2End) {};

	  \draw[automatapath] (V2Begin) -- (V2End) node[midway,above,color=red] {};
	   \begin{pgfonlayer}{background}
		\fill[graybox] () rectangle ();
	  \end{pgfonlayer}
	  
	  \node[graybox,grayboxtext] at (6.5,0.8) {i.h.: }; 

	  \node[dotstyle] (V1Begin) at (1,-0.8) {};
	  \draw[dotted] (V1Begin) -- (1,0);
	  \node[dotstyle] (V1Mid) at (3,-0.8) {};
	  \draw[dotted] (V1Mid) -- (3,0);
	  \node[dotstyle] (V1End) at (4,-0.8) {};
	  \draw[dotted] (V1End) -- (4,0);
	  \node[left=0.7cm] at (V1Begin) {};
	  \node[below left] at (V1Begin) {};
	  \node[below] at (V1Mid) {};
	  \node[below right] at (V1End) {};

	  \draw[automatapath] (V1Begin) -- (V1Mid) node[midway,above,color=red] {};
	  \draw[automatapath,highlightrun] (V1Mid) -- (V1End) coordinate[midway,above=3mm] (V1MidMarker) node[pos=0.45,above,color=red] {};
	   \begin{pgfonlayer}{background}
		\fill[graybox] () rectangle ();
	  \end{pgfonlayer}
	  
	  \node[graybox,grayboxtext] at (6.5,-0.8) {i.h.: }; 
  \end{scope}

\draw[->,dashed,highlightrun,>=stealth] () -- ();




\end{tikzpicture} 		\end{center}
		\caption{Illustration of part (ii) of Lemma
	\ref{lem:CorrectnessOfGTTSaturation}}\label{fig:PartTwoGTTSaturationProof}
	\end{figure}
	
	
	\inductionstart{Let  or 
for some  and :}
	By the construction of the automata  and ,
we have , , ,  and thus obtain
 and  as desired.

  \inductionstep{Let  for some  and :}
	We assume that the new/updated transition  is in  (otherwise there is nothing to show here).
	Let  be the number of occurrences of the new transition in
.

	\inductionstart{Let :}
	If the run 
does not contain the new transition, the claim follows directly by the induction
hypothesis of the outer induction. 
	\inductionstep{Let :}
	The used words and runs of the construction are shown in Figure
\ref{fig:PartTwoGTTSaturationProof}.

	The run on  can be represented by:
	
	By the saturation algorithm, there is a word  and a pair
of runs  and
 with  such that  which led
to the construction of the new transition.

	Since  uses
the new transition only  times we have  by the inner induction hypothesis.
Furthermore, we obtain from the outer induction hypothesis (part (iii) of the
lemma) that .

	Additionally, it is possible to construct the following run with the
given run of  on  and the run of 
which led to the construction of the new transition:
	

	This run does not use the new transition. Consequently, the outer
induction hypothesis yields . In total:
	
	with 
	
	\inductionend
	  \inductionstep{Let  for some  and :}
	  This step is mostly analogous to the previous case -- just the roles of the
two automata are exchanged. Thus, we now assume that the new/updated
transition  is in .
	Let  be the number of occurrences of the new transition in
.

	\inductionstart{Let :}
	If the run 
does not contain the new transition, the claim follows directly by the induction
hypothesis of the outer induction. 
	\inductionstep{Let :}
	The run on  can be represented by:
	
	By the saturation algorithm, there is a word  and a pair
of runs  and
 with  such that  which led to the construction of the new transition.

	Since  uses
the new transition only  times, the inner induction hypothesis yields .
Furthermore, we obtain from the outer induction hypothesis (part (ii) of the
lemma) that .

	Additionally, it is possible to construct the following run with the
given run of  on  and the run of 
which led to the construction of the new transition:
	

	This run does not use the new transition. Consequently, the outer
induction hypothesis yields . In
total:
	
	with 
	
	\inductionend
	\inductionend\vspace{-\baselineskip}
\end{proof}


\subsection{Cost-Reachability in \RPRS{}}
\label{subsec:CostReachability}

Although the previously presented algorithm shows that we are able to compute
the reachability relation of prefix replacement systems with annotations, there
are still two problems to settle in order to solve the problem stated in our
motivating question. First, we have to encode the counter operations in the form
of a well-partially ordered monoid with involution. The main problem here
is that evaluating (mapping partial sequences to maximal counter values)
sequences of counter operations is inherently not associative. Thus, we need to
capture the essential information contained in a sequence of counter
operations but in a more accessible representation. Second, we have to
construct a synchronous resource transducer from the result of the algorithm. 

We define \emph{counter profiles} to capture the behavior of counter sequences
and provide a way to store a sequence of counter operations such that an
associative concatenation can be defined. A counter profile is a triple whose
elements are either natural numbers or  (read ``n/a'') meaning \emph{not applicable}. 
We map a sequence of counter operations to a counter profile based on the following
ideas. If there is no reset in the sequence, we just store the number of
increments in the first component. All other components are set to .
If it contains a reset, we store the number of increments before the first reset 
in the first component and the number of increments after the last reset in the 
third component. The second component contains the maximal number of
increments between two subsequent resets. If there are less than two resets in
the sequence, this component remains . It is easy to see that such a
profile contains sufficient information to define an associative concatenation
operator and that the profile  is neutral for this operator. We
denote the set of all valid counter profiles, i.e., those profiles resulting
from some counter sequence, by  and the above described 
mapping from counter sequences to counter profiles by 
.

\begin{prop}\label{prop:CounterProfilesFormAnnotationMonoid}
	The structure  is a
	well-partially ordered mon\-oid with involution where  is the
	concatenation operator induced by the concatenation of counter sequences,
	 is the component-wise order on the profiles. In each component the
	natural numbers are ordered canonically, the element  is incomparable
	to all numbers. The function  is defined by:

Note that the first case corresponds to counter sequences without reset, which
are reverse-invariant.
\end{prop}
\begin{proof}
	By construction the structure  is a
monoid. Furthermore, one can verify by checking all cases that the order 
is compatible with  and the reverse function. We show that the order
 is well-founded and has only finite anti-chains by showing that it is
the product of three orders satisfying these conditions. This argumentation is
analogous to Lemma~\ref{lem:ProductOfRIOrderedMisRIOrderedM}. The canonical
order on  with one additional element  which is incomparable to all
numbers is well-founded and has only finite anti-chains since every set of more
than one natural number forms a chain. Thus only two element sets containing one
number and  can be anti-chains. The order on counter profiles is the
product of three times this order.
\end{proof}


We remark that the framework of well-partially ordered monoids with involution
can be used to capture sequences of counters with S-automaton semantics as well.
The idea to construct S-counter profiles is very similar to B-counter profiles.
Analogously, they store the number of increments before the first and after
the last reset. They additionally store whether these resets were  or
. Following the semantics of S-automata, the profiles do not store the
maximal counter value between subsequent (check-)resets but the minimal ones. 
Due to the fact that there are  and  in S-semantics, they have 
to store this for both directions: when reading the counter sequence from 
left to right and when reading from right to left.


(B-)Counter profiles allow the translation of \RPRS{} into monoid annotated prefix
replacement systems with a direct relation between their semantics. This
translation transforms  into ,  into
 and  into the neutral element . In this
translated system we define  iff  for some 
with . We already explained that  is a
\mbox{(monoid-)}homomorphism. Consequently, the relation
 is preserved under the transformation of the \RPRS{}
to the annotated prefix replacement system. Additionally, this also holds the
other way around. For a pair  in the profile
annotated prefix replacement system one can directly construct a path also
satisfying  in the corresponding \RPRS{}.
Moreover, we remark that if  holds for a pair of
configurations in the profile annotated prefix replacement system, then there is
a -minimal profile which witnesses that. Formally, let  be the set of
all those elements  s.t. . There is a
 s.t.\  because -smaller elements can only have a smaller  than the
 of all components. 

Analogously, we can transform counter profiles back into equivalent counter
sequences. We define the mapping , where the parts in square
brackets are only needed if  or  are not , to convert a 
profile back into an equivalent sequence of counter operations. This 
transformation allows us to obtain normal B-automata in the end.

Even though the above description did not consider \RPRS{} with several
counters, we are not restricted to the single counter scenario. By Lemma
\ref{lem:ProductOfRIOrderedMisRIOrderedM} the direct product of two monoids as
presented in Proposition \ref{prop:CounterProfilesFormAnnotationMonoid} is
again a well-partially ordered monoid with reverse-function. Since all counters
are handled independently from each other in an \RPRS{}, the direct product of
 copies of the counter profiles exactly corresponds to the behavior of an 
counter \RPRS{} for the same reasons as explained in the previous paragraph.
Accordingly, we have  if the maximum of all
entries in all profiles is less than or equal to . 

\begin{figure}[t]
  \begin{center}
  \begin{tikzpicture}
  \node[dotstyle] (A2Start) at (0,-0.5) {};
  \node[dotstyle] (A2Start2) at (0,0) {};
  \node[dotstyle] (A1Start) at (0,2.5) {};
  \node[dotstyle] (A1WaitEnd) at (1,2.5) {};
  \node[dotstyle] (A1WaitEnd2) at (1,2) {};
  \node[dotstyle] (A1NormEnd) at (5,2) {};
  \node[dotstyle] (A2NormEnd) at (5,0) {};


  \node[dotstyle] (CommonStart) at (5,1.5) {};
  \node[dotstyle] (CommonEnd) at (6,1.5) {};


  \node[above] at (A1NormEnd) {};
  \node[below] at (A2NormEnd) {};
  
  \node[below right] at (CommonEnd) {};
\node[left] at (CommonStart) {};

  \draw[automatapath] (A1Start) -- (A1WaitEnd);
  \draw[curlybracket] () -- () node[midway,above=2mm,font={\small}] {wait}; 
  \draw[automatapath] (A1WaitEnd2) -- (A1NormEnd);
  \draw[curlybracket] () -- () node[midway,above=2mm,font={\small}] {run of }; 
 
  \draw[curlybracket] () -- () node[midway,above=2mm,font={\small}] {identity check};


  \draw[automatapath] (A2Start2) -- (A2NormEnd);
  \draw[curlybracket] () -- () node[midway,below=2mm,font={\small}] {run of }; 

  \draw[automatapath] (CommonStart) -- (CommonEnd);

  \draw[->] (A2NormEnd) to[out=110,in=-110] node [midway,left=-1mm] {}
(CommonStart);
  \draw[->] (A1NormEnd) -- node [midway,left=-1mm] {} (CommonStart);


  \draw[-] (0,1) -- (6,1);
  \draw[-] (5,0.7) -- (5,1.3);
  \node[above] at (5.5,1) {};
  \node[below] at (5.5,1) {};

  \draw[-] (1,1) -- (1,1.3);
  \node[above] at (0.5,1) { \ldots \
\semantics{\automatonT}_{\padprodR}((w_1,w_2)) \costEquiv 
\inf \{ j \in \nat \mid  w_1 \configstepsLesserCost{j} w_2 \}

	\automatonT = (Q, \alphVector{\Sigma}{2}, \Delta, \In, \Fin, \Gamma')

	\Delta &= \{ ((p_1,p_2),\twovec{a_1}{a_2},(p_1',p_2'),\fraku) \mid (p_l,a_l,p'_l,m_l) \in \Delta_l, l \in \{1,2\},\fraku(\gamma^j_i) := \profileToOp((m_j)_i) \} \\
	      &\cup \{((p,q_{\mathrm{wait}}),\twovec{a}{\}{b},(q_{\mathrm{wait}},q'),\fraku) \mid (q,b,q',m_2) \in \Delta_2, \fraku(\gamma^1_i) := \eps, \fraku(\gamma^2_i) := \profileToOp((m_2)_i)\} \\
	      &\cup \{((q_{\mathrm{wait}},p_2),\eps,(q_{1,\eps},p_2),\fraku_{\nOp}),((p_1,q_{\mathrm{wait}}),\eps,(p_1,q_{2,\eps}),\fraku_{\nOp}) \mid p_i \in Q_i \cup \{q_{\mathrm{wait}}\} \} \\
	      &\cup \{ ((p,p),\eps,q_{\mathrm{id}},\fraku_{\nOp}), (q_{\mathrm{id}},\twovec{a}{a},q_{\mathrm{id}},\fraku_{\nOp}) \mid p \in Q_1 \cap Q_2, a \in \Sigma\}
};
  \node[above] at (2.5,0.9) {};
  \node[below] at (2,1.11) {};
  
  \begin{scope}[>=latex,anchor=base]
	\node[color=red,inner sep=1pt] (i11) at (1.8,2.3) {};
	\node[color=red,below=4mm,inner sep=0pt] (g11) at (i11)  {};
	\draw[->,color=red] (i11) -- (g11);
	
	\node[color=red,inner sep=1pt] (i12) at (2.2,2.3) {};
	\node[color=red,below=4mm,inner sep=0pt] (g12) at (i12)  {};
	\draw[->,color=red] (i12) -- (g12);
	
	\node[color=red,inner sep=1pt] (r13) at (3,2.3) {};
	\draw[-,color=blue!75] (r13) to[out=150,in=-110] (lastReset1Label.south west);
	


	\node[color=red,inner sep=1pt] (i14) at (3.4,2.3) {};
	\node[color=blue!75,below=4mm,inner sep=0pt] (g14) at (i14)  {};
	\draw[->,color=red] (i14) -- (g14);
	
	
	\node[color=red,inner sep=1pt] (i21) at (1,-0.3) {};
	\node[color=red,above=4mm,inner sep=0pt] (g21) at (i21)  {};
	\draw[->,color=red] (i21) -- (g21);
	\node[color=red,inner sep=1pt] (r22) at (1.4,-0.3) {};
	\node[color=red,above=4mm,inner sep=0pt] (g22) at (r22)  {};
	\draw[->,color=red] (r22) -- (g22);
	\node[color=red,inner sep=1pt] (i23) at (1.8,-0.3) {};
	\node[color=red,above=4mm,inner sep=0pt] (g23) at (i23)  {};
	\draw[->,color=red] (i23) -- (g23);
	
	\node[color=red,inner sep=1pt] (r24) at (2.4,-0.3) {};
	\node[color=red,above=4mm,inner sep=0pt] (g24) at (r24)  {};
	\draw[->,color=red] (r24) -- (g24);
	\draw[-,color=blue!75] (r24) to[out=-50,in=110] (lastReset2Label.north west);
	
	\node[color=red,inner sep=1pt] (i25) at (2.8,-0.3) {};
	\node[color=red,above=4mm,inner sep=0pt] (g25) at (i25)  {};
	\draw[->,color=red] (i25) -- (g25);
	
	\node[color=red,inner sep=1pt] (i26) at (3.5,-0.3) {};
	\node[color=red,above=4mm,inner sep=0pt] (g26) at (i26)  {};
	\draw[->,color=red] (i26) -- (g26);
  \end{scope}
  
  \node[left=0.7cm] (A1) at (0,2) {};
  \node[left=0.7cm] (A2) at (0,0) {};
  \coordinate[left=1.4cm] (Upper) at (A1Start);
  \coordinate[left=1.4cm] (Lower) at (A2Start);
  
  \node[below left=-2mm] at (A1Start) {};
  \node[above left=-0.5mm] at (A1WaitEnd) {};
  \node[below left=-2mm] at (A2Start) {};
  
  \draw[->] (A2Start) -- (A2Start2) node[midway,left] {};
  \node[above left=-1mm] at (A2Start2) {};
  
  \draw[->] (A1WaitEnd) -- (A1WaitEnd2) node[midway,left] {};
  \node[below left=-2mm] at (A1WaitEnd2) {};

  \draw[curlybracket] (Lower) -- (Upper) node[midway,left=2mm] {};

  
\end{tikzpicture}   \end{center}
  \caption{Construction of the synchronous transducer for the exact value}
  \label{fig:r1Rr2ReverseRecognitionExact}
\end{figure}

We remark that it is also possible to use the result of the saturation procedure to construct a transducer which calculates the exact values. However, this requires a slightly more complex construction. The basic construction is analogous to the construction presented in the previous lemma. However, we additionally have to solve the problem of the connection point in the middle of the two sequences. This can be done by nondeterministically guessing the position of the last reset for each counter in both components of the state space. This is illustrated in Figure~\ref{fig:r1Rr2ReverseRecognitionExact}. At some point in the run, the transducer  decides that this is the last reset for some counter in this component of the state space. It checks whether the corresponding counter in the other state-component is already in this \emph{after last reset} mode. If this is the case, the current component uses from this time onwards in the run the counter of the other component to store increments. In any case the automaton validates that there are no more resets for the respective counter in the run. That includes the counter operation associated with the shared synchronization state before switching to . This way, the transducer accumulates all increments contained in the middle part connecting both counter sequences in one counter. Hence, the transducer calculates exactly the maximal counter value of . 

With the previous lemma, we can directly obtain the following theorem.

\begin{thm}\label{thm:RPRSareResourceAutomatic}
	Let  be an \RPRS{} and  its resource structure representation.
   The structure  is resource automatic.
\end{thm}

We are now ready to prove the main result about the bounded reachability
problem of \RPRS{}.  We already saw in the previous section that we can express bounded
reachability with \FORR{} and that we are able to compute the value of this
logic on resource automatic structures. The previous result completes the
puzzle and enables a concise proof for a positive result in a restricted case of
bounded reachability.

\begin{thm}\label{thm:BoundedReachabilityIsDecidable}
	The bounded reachability problem for resource prefix replacement systems 
    and regular sets  and  of configurations is decidable.
\end{thm}
\begin{proof}
	By Theorem~\ref{thm:RPRSareResourceAutomatic} the structure
 is resource automatic for a given resource
prefix replacement system . For regular sets
 the extended resource representation  is also resource automatic since the
valuations of  and  are characteristic functions of a
regular language. 
	By Proposition \ref{prop:BoundedReachabilityIsFORRExpressible} the bounded
reachability problem is expressible in the logic \FORR{} over the structure
 and by
Theorem~\ref{thm:FORRisEffectivelyComputableOnRAStructures} the semantics of
\FORR{} formula is effectively computable on resource automatic structures.
Consequently, computing the semantics yields a decision procedure for the
bounded reachability problem.
\end{proof}

We remark that the complete saturation process can be (computationally) accelerated
if one is only interested in boundedness. In this case it is sufficient to have counter
profiles with entries from  and ignore higher counter values. 
If larger values are created with concatenation, we just reset them to . 
One can easily verify that such profiles also form a well-partially ordered 
monoid with involution and that the usage of the restricted profiles only 
results in smaller values for the calculated resource-cost. 
However, since there are only finitely many profiles
in the saturated automata, there is a largest value  occurring in the 
profiles. A run on the original automata can, compared to a run on the 
automata only using the entries , only have larger 
resource-cost by the factor . Hence, the computed functions of both 
automata are -equivalent and this equivalence is known to 
preserve boundedness. Moreover, with this restriction the runtime of the 
saturation procedure is polynomial in the number and maximal length of the 
prefix replacement rules  and exponential in the number of counters 
(since there are still exponentially
many incomparable counter profile vectors with the restricted profile entries). 

We additionally remark that Theorem~\ref{thm:BoundedReachabilityIsDecidable}
can be generalized to prefix replacement systems with labeled replacement rules and regular constraints on
the labeling of paths. One can extend (resource) prefix replacement systems by
labeling all replacement rules with symbols from a finite alphabet . A
configuration sequence in such a system generates a word . In
these systems, one can study the reachability relation with respect to some
language . A pair of configurations ,  satisfies
this relation  if  is reachable
from  with a sequence of configurations which yields a word  and
needs at most  resources. One can easily see that boundedness
questions on such systems can be solved with the above framework if  is
regular. One can either simulate an automaton recognizing  on top of the
stack of the prefix replacement system or (if one does not want to change the
stack alphabet) include a finite monoid recognizing  (see, e.g.,
\cite{Sakarovitch}) in the annotation monoid. 

\section{The Bounded Reachability Problem and
cost-WMSO}\label{sec:BoundedReachabilityAndCostWMSO}

Together with the model of B-automata different forms of quantitative logics
have been introduced. The logic \FORR{} presented in this work can also be seen as such a logic. However, directly in connection
with the introduction of B-automata (see \cite{regularcostfunctions}) T.\
Colcombet already considered two dual forms of \emph{cost monadic second-order} logic
(for short cost-MSO) over finite words. Recently, M.\ Vanden Boom showed in
\cite{costwMSO} that the boundedness problem for cost-weakMSO is decidable over
the infinite tree (in weak MSO set quantification only ranges over finite
sets). In this section, we show how the bounded reachability problem for systems 
with one counter can be encoded to cost-weakMSO. This reduction yields,
together with the decidability result by M.\ Vanden Boom, an alternative decision
procedure for a restricted version of bounded reachability problem as solved
with our framework in Theorem~\ref{thm:BoundedReachabilityIsDecidable}. 
Although this reduction does not provide any new decidability result, we 
present it to demonstrate that the logic cost-(weak)MSO, which was initially designed
with the goal of creating an equivalent formalism to B-automata, is capable 
of expressing a natural problem on quantitative systems. Moreover, we think that
it motivates research in comparing the expressive power of the different 
recently introduced quantitative logics.

The logic cost-(weak)MSO extends standard monadic second-order logic with
a bounded existential quantifier  (or 
in the dual form) which is only allowed to appear positively in the
formula. The semantics of this logic is quantitative. For a given
structure each formula is mapped to the minimal (or maximal in the dual form)
 such
that the formula is satisfied as normal (weak)MSO formula with a
cardinality restriction of  in all bounded existential
quantifications.

For example, let  be the proposition indicating all positions at which
there is an  in the word. The formula  counts the number of s in a word. The formula
enforces that all positions with an  also have to be in . Consequently,
the set  must have at least the number of s as size in order to satisfy the formula.

The translation of the bounded reachability problem into a cost-weakMSO
formula over the infinite binary tree is conducted in four steps. We
present the approach for a single counter. First, we shift the counter operation
annotation from the prefix replacement rules to the configurations by
considering the incidence graph. In the incidence graph, every transition is
replaced by an additional node. This additional node is then connected to the 
nodes incident to the edge. This graph is still the configuration graph of
a prefix replacement system. Moreover, we can assume without loss of
generality that this replacement system works over the alphabet .
Second, we embed the graph into the binary tree. As usual, we identify every
node in the tree with the -word induced by the path from the root to
the node. In this encoding, the root is labeled with , the left child
with  and the right child with . This can be extended to the complete
tree. Hence, every node can represent one configuration of the prefix
replacement system. Furthermore, we can obtain FO-formulas
, representing the successor
relation (see \cite{thomas03a}), ,
identifying the configurations with increment or reset counter actions, and
, marking the tree representation of the
sets  and  of the bounded reachability problem. Third, we
construct a formula that expresses reachability with a bounded number
of increments. Finally, we use this previous formula to construct a
formula for bounded reachability. This formula checks bounded
reachability by guessing positions with resets and checking for a
bounded number of increments between those positions.

\begin{lem}\label{lem:WMSOReachability}
  Let  be a formula representing a binary relation. The weakMSO
formula  defined as follows is true iff the finite set 
contains a sequence from  to  connected via .
  
  The following cost-WMSO formula  has a value of at most  iff
there is a
path with at most  increments from  to 

  
\end{lem}

\begin{proof}
 We start with the claim on the formula .  Fix
a set  and two elements .

First, assume that  contains a -path  with
.  Then  and  are satisfied. Now, let  be an arbitrary subset of  which contains  but does not
contain  (otherwise the second part of the formula is trivially satisfied).
There is a maximal index  such that . Since , we get
 and thus . By construction,
 is satisfied. Thus,  is
satisfied.

Conversely, assume that  is satisfied. Let  be the
set of elements which are -reachable from  using only elements of
. Note that  is finite and thus occurs in the universal quantification of
the second part of the formula. Furthermore, we have  because  is 
trivially reachable from . If , we get the desired -path from  to .
Otherwise, by the second part of the formula, there are two elements  and  such that . By
assumption,  is reachable from  using only elements of . Consequently,
 is also reachable from  using only elements of .
This is a contradiction to the choice of .

We can now prove the claim on the second formula . Assume there is a
path with at most  increments from  to . Let  be the set of the
nodes on this path. By the previous proof, we know that
 is satisfied. Furthermore, we set . By construction, we have . Consequently, the formula  has a value of at most .

Assume the formula  has a value of at most . Let  and  be
sets witnessing the satisfiability of  with a value of at most .
Furthermore, let .
By definition, we have . By the second part of the formula, we obtain
that  and thus . Since
 guarantees that  is reachable from 
through only configurations in , we obtain that there is a path from  to
 with at most  increment configurations.
\end{proof}


\begin{thm}\label{thm:WMSOBoundedReachability}
  The set  is boundedly reachable (in a one counter setting) from  iff the following cost-weakMSO
formula, which uses the previously defined reachability formula  with 
respect to the bounded-cost reachability formula , has a finite value
  
\end{thm}

\begin{proof}
Let the value of the formula in the theorem be less than . This means that
for all  the second part of the formula (after the implication) has a
value less than . Let  and  be witnesses for this. From the last
part of the formula, we obtain that  is true for all elements in
. Since  must have a value of less
than , there is a sequence  such that
 has value less than . By the previous lemma, we obtain
that there is a path from  to  with less than  increments.
Since the positions  are reset positions (except  and ), this
path is a witness that  reaches an element  with cost less than
. Hence,  is boundedly reachable from .
  
Conversely, let  be boundedly reachable from  with a resource bound of
. We show that the value of the formula is at most . So, let . By
assumption, there is a  and a path  with
resource-cost of at most . We set . Since the value of the path is at most ,
the segments of the path between two subsequent reset positions have at most 
increments. Hence,  has a value of at most . In total,
the whole formula has a value of at most  because  was chosen arbitrarily.
\end{proof}


The previously presented approach is specially tailored for the 
bounded reachability problem on resource prefix replacement systems with 
only one counter. Although it exemplary shows that one can express 
bounded reachability in a quite straightforward way with cost-(W)MSO,
the approach lacks the flexibility and generality of the previously studied
framework. One can see this already when trying to cover the case of
multiple counters. Although it might be possible to extend the shown approach
to multiple counters, some significant new ideas are required.

\section{Conclusion}
\label{sec:Conclusion}

We introduced \RPRS{} as a model for recursive programs with resource
consumption. This model can represent recursive programs that use discrete
resources in a consume-and-refresh manner. We represented these operations with
non-negative integer counters. These counters can be incremented to represent
the consumption of a single resource and reset to zero to simulate a complete
refreshment. 

We developed resource structures and the logic \FORR{} to analyze systems with
resources and specify combined properties on the systems' behavior and their
resource consumption. We identified the subclass of resource automatic
structures and provided an algorithm to compute the semantics of \FORR{}
formulas. This logic is able to express the bounded reachability
problem on a presentation of an \RPRS{} as resource structure. Thereby, we
reduced bounded reachability to an evaluation problem of the quantitative logic
\FORR{}. 

We devised a method to compute a synchronous transducer recognizing an
annotation aware transitive closure of an annotated prefix replacement system.
We used this method to prove that the resource structure representation of an
\RPRS{} is resource automatic. This completed the decidability proof of the
bounded reachability problem. 

Although we gave a self-contained presentation on a formalization of recursive
programs with resource consumption and the bounded reachability problem,
several open questions remain. First, the choice of prefix replacement systems
as underlying computational model induces certain restrictions on the systems
which can be modeled. It excludes important classes such as systems with
parallelism or reactive systems. It remains open whether and how the presented
results can be extended to such classes of system models. Second, the positive
computability results for \FORR{} on resource automatic structures motivate
further research in the area of specification logics for systems with resource
consumption. Moreover, in the area of automatic program verification usually
temporal logics are used. However, it remains unclear how temporal logics for
systems with resource consumption look and whether there will be
algorithmic solution methods. Nevertheless, we saw in the previous section that
there are other quantitative logics which are related to verification problems
of systems with resources. Especially, there are several logics which emerged
around the models of B- and S-automata. In addition to cost-(weak)MSO, there is the
logic (weak)MSO+U introduced by M. Bojańczyk in \cite{wmsoPu}. It extends normal
MSO by a quantifier stating that there are sets of unbounded size such that the
following part of the formula holds. An investigation of the relations between
all these logics would help to identify the boundaries of decidability.

\nocite{regularcostfunctions}
\bibliographystyle{alpha}
\bibliography{literature}
\end{document}
