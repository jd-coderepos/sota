

\documentclass[11pt,a4paper]{article}
\usepackage[nohyperref]{emnlp2018}
\usepackage{times}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{url}
\usepackage{footmisc}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{paralist}
\usepackage{colortbl}
\newcommand{\TODO}[1]{\textcolor{red}{#1}}
\newcommand{\binny}[1]{\textcolor{blue}{[Binny: #1]}}



\usepackage{todonotes}
\usepackage{booktabs} \usepackage{soul}


\aclfinalcopy 



\newcommand\BibTeX{B{\sc ib}\TeX}


\title{Thou shalt not hate: Countering Online Hate Speech}

\author{Binny Mathew, Hardik Tharad, Subham Rajgaria,  Prajwal Singhania,\\
\textbf{Suman Kalyan Maity\textsuperscript{}, Pawan Goyal and Animesh Mukherjee}\\
IIT Kharagpur, India\\
\textsuperscript{}Kellogg School of Management, Northwestern University\\
Email: binnymathew@iitkgp.ac.in, hardik.tharad@gmail.com, subham.rajgaria@gmail.com, \\
prajwal1210@gmail.com, 
suman.maity@kellogg.northwestern.edu, \\
pawang@cse.iitkgp.ernet.in, 
animeshm@cse.iitkgp.ac.in
}

\date{}

\begin{document}
\maketitle
\begin{abstract}
Hate content in social media is ever increasing. While Facebook, Twitter, Google have attempted to take several steps to tackle this hate content, they most often risk the violation of freedom of speech. Counterspeech, on the other hand, provides an effective way of tackling the online hate without the loss of freedom of speech. Thus, an alternative strategy for these platforms could be to promote counterspeech as a defense against hate content. However, in order to have a successful promotion of such counterspeech, one has to have a deep understanding of its dynamics in the online world. Lack of carefully curated data largely inhibits such understanding. In this paper, we create and release the first ever dataset for counterspeech using comments from YouTube. The data contains 9438 manually annotated comments where the labels indicate whether a comment is a counterspeech or not. This data allows us to perform a rigorous measurement study characterizing the linguistic structure of counterspeech for the first time. This analysis results in various interesting insights such as: the counterspeech comments receive double the likes received by the non-counterspeech comments, for certain communities majority of the non-counterspeech comments tend to be hate speech, the different types of counterspeech are not all equally effective and the language choice of users posting counterspeech is largely different from those posting non-counterspeech as revealed by a detailed psycholinguistic analysis. Finally, we build a set of machine learning models that are able to automatically detect counterspeech in YouTube videos with an F1-score of 0.73. 
\end{abstract}


\section{Introduction}

\begin{quote}
``If there be time to expose through discussion the falsehood and fallacies, to avert the evil by the processes of education, the remedy to be applied is more speech, not enforced silence.'' -- Louis Brandeis  
\end{quote}

\vspace{-5mm}
The advent of social media has brought several changes to our society. It allowed people to share their knowledge and opinions to a huge mass in a very short amount of time. While the social media sites have been very helpful, they have some unintended negative consequences as well. One such major issue is the proliferation of hate speech~\cite{massaro1990equality}. To tackle this problem, several countries have created laws against hate speech\footnote{https://goo.gl/tALXsH}. Organizations such as Facebook, Twitter, and YouTube have come together and agreed to fight hate speech as well\footnote{https://goo.gl/sH87W2}.

\subsection{Current protocols to combat hatespeech and their limitations} 
One of the main tools that these organizations use to combat online hate speech is blocking or suspending the message or the user account itself. Although, several social media sites have taken strict actions to prohibit hate speech on websites they own and operate, they have not been very effective in this enterprise\footnote{https://goo.gl/G7hNtS, https://goo.gl/zEu4aX, https://goo.gl/CFmsqM}. At the same time, one should not block/suspend free speech because selective free speech is a dangerous precedent. 



While blocking of hateful speech may reduce its impact on the society, one always has the risk of violation of free speech. Therefore, the preferred remedy to hate speech would be to add more speech ~\cite{richards2000counterspeech}.
\subsection{Can countering hate speech be an effective solution?}
This requirement led countries and organizations to consider countering of hate speech as an alternative to blocking~\cite{gagliardone2015countering}. The idea that `more speech' is a remedy for harmful speech has been familiar in liberal democratic thought at least since the U.S. Supreme Court Justice Louis Brandeis declared it in 1927. There are several initiatives with the aim of using counterspeech to tackle hate speech. For example, the Council of Europe supports an initiative called `No hate speech Movement'\footnote{\label{nohatespeechmovement}http://www.nohatespeechmovement.org/} with the aim to reduce the levels of acceptance of hate speech and develop online youth participation and citizenship, including in Internet governance processes. UNESCO released a study~\cite{gagliardone2015countering} titled `Countering Online Hate Speech', to help countries deal with this problem. Social platforms like Facebook have started counterspeech programs to tackle hate speech\footnote{\label{counterfb}https://counterspeech.fb.com/en/}. Facebook has even publicly stated that it believes counterspeech is not only potentially more effective, but also more likely to succeed in the long run ~\cite{bartlett2015counter}. Combating hate speech in this way has some advantages: it is faster, more flexible and responsive, capable of dealing with extremism from anywhere and in any language and it does not form a barrier against the principle of free and open public space for debate. 

\subsection{Working definition of counterspeech} 
In this paper, we define counterspeech as a direct response/comment (not reply to a comment) that \textit{counters} the hateful or harmful speech. Taking the YouTube videos that contain hateful content toward three target communities: {\sl Jews}, {\sl African-American (Blacks)} and {\sl LGBT}, we collect user comments to create a dataset which contains counterspeech. To annotate this dataset, we use the different classes of counterspeeh described in Benesch et. al. ~\shortcite{susan2016counterspeech} \iffalse \TODO{PG: Previous sentence not clear. Developed on? Did you just tag the dataset using the classes mentioned in this paper?}\binny{We used all the classes defined in the Benesh paper\fi with a slight modification to the `Tone' Category. While the paper includes all kinds of tones in this category, we split this class further into two categories: `Positive Tone' and `Hostile Language'. 

\subsection{Our contributions and observations}
We annotate and release the first ever dataset\footnote{\label{dataset_link}https://goo.gl/uGXSEk} on counterspeech. The dataset is based on counterspeech targeted to three different communities: {\sl Jews}, {\sl Black}, and {\sl LGBT}. It consists of 4111 comments annotated as counterspeech and an additional 5327 comments tagged as non-counterspeech. The counterspeech comments are further labeled into one or more of the categories listed in Table~\ref{tab:dataset_statistics}.

While developing the dataset, we had several interesting observations. We find that overall counterspeech comments receive more (twice) likes than non-counterspeech comments. \iffalse \TODO{If you need to mention the first line, more observations should come here.}\fi Psycholinguistic analysis reveals striking differences between the language used by the users posting counter and non-counterspeech. We also observe that the different communities attract different proportions of counterspeech. `Humor' as a counterspeech seems to be more prevalent when {\sl LGBT} is the target community, while in case of the {\sl Jews} community, `Positive tone' of speech seems to be more widely used.

As an additional contribution, \iffalse we develop machine learning models to classify a comment as counterspeech or non-counterspeech. \TODO{PG: let's be more specific, what model, accuracy etc?}\binny{\fi we define three classification tasks for the dataset and develop machine learning models: (a) counterspeech vs non-counterspeech classification, in which Logistic Regression performs the best with an F1-score of 0.73, (b) multi-label classification of the types of counterspeech present in a give counterspeech text, in which multi-layer perceptron performs the best, \if{0}with a Hamming score of 0.283\binny{I think we should remove hamming loss. I asked rijula and they are also not reporting this. Just precision, recall, fscore, accuracy and exact match}\fi (c) cross-community classification in which SVM performs the best with an F1-score of 0.61.

















\iffalse To the best of our knowledge, this is the first attempt ever to automatically detect counterspeech in online platform. Apart from this, the dataset that we will release will be the first dataset available for researchers to work upon the problem of counterspeech.\fi

\iffalse The main contributions of this paper can be summarized as follows. \iffalse \TODO{PG: My comments below, but seems repetitive, so may be merged with the points earlier, emphasizing on the contributions.}\fi

\begin{itemize}[leftmargin=*,itemsep=0.05em]
\item We annotate and release the first ever dataset on counterspeech. The dataset is based on three target communities: Jews, Black, and LGBT. It consists of \binny{4111} counterspeech comments, which are further labeled with \TODO{XX} counterspeech categories, and  non-counterspeech comments.
	
\item We perform several analysis on this dataset and obtain interesting observations. \iffalse\TODO{Not a contribution as such, need to be more succinct for a contribution.}\binny{\fi We observe that different communities seem to be applying different strategies to counter online hate. Also, we find striking differences in the psycholinguistic nature of the counter and non-counter speakers.
		
\item We provide models for the automatic detection of counterspeech as well as models for fine-grained detection of different types of counterspeech. \end{itemize}
\fi
\section{Related work}

In this section, we review some of the related literature. \if{0}
\subsection{Hateful or harmful speech}

Hate speech lies in a complex nexus with freedom of expression, group rights, as well as concepts of dignity, liberty, and equality ~\cite{gagliardone2015countering}. Owing to this, there can be several issues in defining what constitutes as hate speech ~\cite{benesch2014defining}. The authors usually adopt a definition that fits a general description of hate speech. There is substantial literature on the analysis of hate speech. 
~\citet{silva2016analyzing} studies the targets of hate speech on Twitter and Whisper and observes that `Blacks' are among the most frequent targets of hate speech. ~\citet{mondal2017} studies the effects of anonymity on hate speech. There are works where the authors study the perceptions and experience of people regarding the hate speech~\cite{leets2002experiencing, gelber2016evidencing}. In~\cite{van2015good}, the authors study the impact of hate speech prosecution of a politician on electoral support for his party and find an immediate increase in the support for the party.  

Another line of research corresponds to detection of hate speech in various social media platforms like Twitter~\cite{waseem2016hateful, Chatzakou:2017:MGT:3041021.3053890,davidsonautomated, Badjatiya:2017:DLH:3041021.3054223}, Facebook ~\cite{del2017hate}, Yahoo! Finance and News~\cite{Warner:2012:DHS:2390374.2390377, Djuric:2015:HSD:2740908.2742760, Nobata:2016:ALD:2872427.2883062}, and Whisper~\cite{mondal2017}.

In another online effort, a Canadian NGO, the Sentinel Project~\footnote{https://thesentinelproject.org/}, launched a site in 2013 called HateBase\footnote{https://www.hatebase.org/}, which invites Internet users to add to a list of slurs and insulting words in many languages.
\fi
``Counter-speech is a common, crowd-sourced response to extremism or hateful content. Extreme
posts are often met with disagreement, derision, and counter campaigns''~\cite{bartlett2015counter}. ~\citet{citron2011intermediaries} categorizes four ways in which one can respond to hateful messages -- (i) \textbf{Inaction:} By not responding to the hate speech, we might be actually causing more harm. It sends a message that people do not care about the target community. (ii) \textbf{Deletion/Suspension:} The removal of hate speech is the most powerful option available in response to hate speech. Removal of the hateful content is sometimes accompanied by the removal or suspension of the user account as well. This strategy is used by most of the social networks such as Facebook, Twitter, Quora, etc. (iii) \textbf{Education:} Institutions can help in educating the public about hate speech and its implications, consequences and how to respond. Programmes such as `NO HATE SPEECH' movement\footref{nohatespeechmovement} and Facebooks Counterspeech program\footref{counterfb} help in raising awareness, providing support and seeking creative solutions. (iv) \textbf{Counterspeech:} Counterspeech is considered as the preferred remedy to hate speech as it does not violate the normative of free speech. While government or organizations rarely take part in counterspeech, a large proportion of the counterspeech is actually generated by the online users.



Silence in response to digital hate carries significant expressive costs as well. When powerful intermediaries rebut demeaning
stereotypes (like the Michelle Obama image) and invidious falsehoods (such as holocaust denial), they send a powerful message to readers. Because intermediaries often enjoy respect and a sense of legitimacy, using counterspeech, they can demonstrate what it means to treat others with respect and dignity~\cite{citron2011intermediaries}.

While blocking might work as a counter at the individual scale, it might actually be detrimental for the community as a whole. Deletion of comments that seem hateful might affect a person's freedom of speech. \if{0}\binny{One of the counterspeech strategy is to designate comments as hateful/wrong. I think we should just write: Deletion of comments that seem hateful can affect a person's freedom of speech.}.\fi Also, with blocking, it is not possible to recover from the damage that the message has already caused. Counterspeech can therefore be regarded as the most important remedy which is constitutionally preferred~\cite{benesch2014countering}.

Counterspeech has been studied on social media sites like Twitter~\cite{wright2017vectors, susan2016counterspeech}, YouTube~\cite{ernst2017hate} and Facebook~\cite{schieb2016governing}. ~\citet{wright2017vectors} study the conversations on Twitter, and find that some arguments between strangers lead to favorable change in discourse and even in attitudes.~\citet{ernst2017hate} study the comments in YouTube counterspeech videos related to Islam and find that they are dominated by messages that deal with devaluating prejudices and stereotypes corresponding to Muslims and/or Islam.~\citet{schieb2016governing} study counterspeech on Facebook and through simulation, find that the defining factors for the success of counter speech are the proportion of the hate speech and the type of influence the counter speakers can exert on the undecided.~\citet{Stroud2018feminist} perform case studies on feminist counterspeech. Another line of research considers ascertaining the success of the counterspeech.~\citet{susan2016successfullcounter} describes strategies that have favorable impact or are counterproductive on users who tweet hateful or inflammatory content. 

Most of these studies are not conducted at large scale. Computational approaches are required in order to study and engage counterspeech efforts at scale, automatic detection being the key component~\cite{wright2017vectors}. This paper is the first to release a considerably large annotated counterspeech data and propose an automatic counterspeech detection model.

\section{Dataset}

YouTube is one of the key online platforms on the Internet with 1.5 billion logged-in users visiting the site every month\footnote{http://goo.gl/eEqWAt}. Many of these videos contain hate speech targeted toward various communities. In this paper, we focus on such hateful videos and scrape their comment section.

\subsection{Data collection from YouTube}
In order to gather a diverse dataset, we focus on three target communities: {\sl Jews}, {\sl Blacks}, and {\sl LGBT}. First, we manually select videos\footref{dataset_link} that contain some act of hate against one of these communities. \iffalse{}These videos include acts of hatespeech, violence against target community, etc.\fi Next, we use the YouTube comment scraper\footnote{http://ytcomments.klostermann.ca/} to collect all the comments from the selected videos. Each comment had fields such as the comment text, username, date, number of likes, etc. 


 
\subsection{Dataset annotation}

There are different types of counterspeech that have different effects on the user. In order to understand the differences between them, we annotate the dataset at two levels. 

\noindent\textbf{First level annotation:} In the first level, we select comments from the hate speech video and ask the annotators to annotate each of these comments as a counter/non-counter to the hate message/action in the video. We define a comment as counterspeech if it opposes the hatred expressed in the video. We only consider those comments which are direct response to the video and ignore all the replies to these comments as we observe that they usually tend to drift off-topic and the discussion becomes more personal and noisy. Each comment has been annotated by two users and the conflicting cases have been resolved by a third annotator. We achieve 95.9\% agreement between the two annotators with a Cohen's  of 0.917. As a result of this step, we arrive at 4111 counterspeech comments and 5327 non-counterspeech comments. To our surprise, we find that 43.5\%  of the direct responses to the selected hate videos are counterspeech.

\noindent\textbf{Second level annotation:} In order to obtain a deeper understanding of the types of counterspeech, we perform a second level annotation. We give the annotators a counterspeech text and ask them to label all the types of counterspeech that are present in it. \if{0}\binny{Shouldn't it be: we give the annotators a counterspeech text and ask them to label all the types of counterspeech that are present in it.}.\fi We use the taxonomy of counterspeech described in~\citet{susan2016counterspeech} for this purpose. For ease of readability we describe these categories in the subsequent section. 

Two independent annotators tagged each comment annotated as counterspeech in the first level into appropriate types. We obtain a loose  score of 0.956 and a strict  score of 0.872 for this task~\cite{ravenscroft2016multi}. We employ a third annotator for deciding on the conflicting cases. The final distribution of the different types of counterspeech is noted in Table~\ref{tab:dataset_statistics}.
 








\subsection{Types of counterspeech}

There are numerous strategies that could be used to counter the hateful messages in the online social media.~\citet{susan2016counterspeech} distinguishes eight such strategies that are used by counterspeakers.
We decided on using these eight types of counterspeech with a slight modification to the category `Tone'. While the authors define multiple sub-categories, we only use `Positive Tone' and `Hostile' as categories for the dataset. \iffalse } \TODO{PG: not a good argument}.\fi A single comment can consist of multiple types of counterspeech as shown in Figure~\ref{fig:counter_multi_response}. Below, we discuss these various categories.

\begin{figure}[h!]
	\centering
	\includegraphics[width=.45\textwidth]{Figures/Multiple_Response}
	\caption{An example comment containing two types of counterspeech: \textit{affiliation} and \textit{empathy}.}
	\label{fig:counter_multi_response}
\vspace{-4mm}
\end{figure}




\noindent\textbf{Presenting facts to correct misstatements or mis-perceptions:} In this strategy, the counterspeaker tries to persuade by correcting misstatements. An example of this type of counterspeech toward the {\sl LGBT} community \iffalse\TODO{PG: towards? -- mention this in all the examples.}\binny{Done.}\fi from our dataset is as follows:~\textquotedblleft \textit{Actually homosexuality is natural. Nearly all known species of animal have their gay communities. Whether it be a lion or a whale, they have or had (if they are endangered) a gay community. Also marriage is an unnatural act. Although there are some species that do have longer relationships with a partner most known do not.}\textquotedblright

\noindent\textbf{Pointing out hypocrisy or contradictions:}
In this strategy, the counterspeaker points out the hypocrisy or contradiction in the user's (hate) statements. In order to discredit the accusation, the 
individual may explain and rationalize their previous behavior, or if they are persuadable, resolve to avoid the dissonant behavior in the future~\cite{beauvois1993cognitive}. An example of this type of counterspeech toward {\sl LGBT} community from our dataset is as follows: \textquotedblleft \textit{You don't love homosexuals. You hate them. To say you want homosexuals to go to hell is pure hate. Whether they are worthy of death or not doesn't even matter because once you say you ``hate" someone you automatically contradict Jesus Christ Himself.} \textquotedblright

\iffalse \TODO{PG: what are these 2 statements, which of these is a counterspeech?}\binny{Done.}\fi

\noindent\textbf{Warning of offline or online consequences:}
In this strategy, counterspeaker warns the user of possible consequences of his/her actions. This can sometimes cause the original speaker of the hatespeech to retract from his/her original opinion. An example of this type of counterspeech toward the {\sl African-American} community from our dataset is as follows: \textquotedblleft \textit{I strongly suggest a local lawyer take this case pro bono and get the cops fired or at least disciplined and the man receive a public apology from the mayor, or, the city be sued too.} \textquotedblright

\noindent\textbf{Affiliation:}
Affiliation is \textquotedblleft...establishing, maintaining, or restoring a positive affective relationship with another person or group of persons\textquotedblright ~\cite{byrne1961anxiety}. People are more likely to credit the counterspeech of those with whom they affiliate, since they tend to ``evaluate ingroup members as more trustworthy, honest, loyal, cooperative, and valuable to the group than outgroup members'' ~\cite{kane2005knowledge}. In our dataset, couterspeakers who use {\sl Affiliation} receive the highest number of likes for their comments among all the counterspeech types. An example of this type of counterspeech toward the {\sl African-American} community from our dataset is as follows:~\textquotedblleft \textit{As a black man I feel for this guy because I think he truly believed he would get fairly by the police if he spoke in an eloquent nonthreatening manner. My brother this is America shit don't go that way.} \textquotedblright

\noindent\textbf{Denouncing hateful or dangerous speech:}
In this strategy, the counterspeakers denounce the message as being hateful. This strategy can help the counterspeakers in reducing the impact of the hate message. An example of this type of counterspeech toward {\sl LGBT} community from our dataset is as follows: \textquotedblleft \textit{This is not Christianity. This is a man preaching hate, bullying, and violence, and saying it's what God wants. Not my God.} \textquotedblright

\noindent\textbf{Humor and sarcasm:}
Humor is one of the most powerful tools used by the counterspeakers to combat hate speech. It can de-escalate conflicts and can be used to garner more attention toward the topic. Humor in online settings also eases hostility, offers support to other online speakers, and encourages social cohesion~\cite{marone2015online}. Often, the humor is sarcastic, like the following counterspeech comment subscribing the {\sl LGBT} community from our dataset:~\textquotedblleft \textit{Yeah because using force to change someone's sexuality or thought process is going to work just fine and they will start to love you. Can't see this plan going wrong at all. What a genius!}\textquotedblright

\noindent\textbf{Positive Tone:}
The counterspeaker uses a wide variety of tones to respond to hate speech. In this strategy, we consider different forms of speech such as empathic, kind, polite, or civil. Increasing empathy with members of opposite groups counteracts
incitement~\cite{benesch2014countering}. We would like to point out that the original authors actually defined Tone to contain hostile counterspeech as well. Instead, we decide to make `Hostile Language' as a separate type of counterspeech. An example of this type of counterspeech toward {\sl African-American} community from our dataset is as follows:~\textquotedblleft \textit{it was actually sad to watch i cried because the man wanted to get his child.  breaks my heart honestly and when he said  help me i was just devastated i would sue these cops}\textquotedblright

\noindent\textbf{Hostile language:}
In this strategy, the counterspeaker uses abusive, hostile, or obscene comments in response to the original hate message. Such a response can persuade an original speaker to delete his message or even a whole account, but is unlikely to either de-escalate the conversation or persuade the original speaker to recant or apologize. An example of this type of counterspeech toward {\sl Jews} from our dataset is as follows:~\textquotedblleft \textit{do you muslims want an award from jews Christians and white people for not having a problem with jews? its called basic human decency you f*****g filthy c***s how about you get out of europe and stop ruining germany}\textquotedblright

\iffalse \TODO{PG: we are using names here!!, also language..}\binny{Done.}

\TODO{PG: Earlier, you mentioned that you had 2 new classes to account for the dataset, what are those?}\binny{We removed one of the categories: 'Opinion'. Initially, we put those comments in this category which were talking about their opinion. While tagging, we realized that this was very ambiguous. We have the data tagged but we dropped in from the paper. The second category was the 'Hostile Language'. I have modified the earlier lines now.}\fi






\begin{table}[!htbp]
	\resizebox{\linewidth}{!}{\begin{tabular}{| p{6.4cm} | p{0.8cm} |p{1.0cm}| p{1.0cm}| p {1.0cm}|p {0.7cm}|} 
			\hline
			&\multicolumn{3}{|c|}{Target community}& Total\\
			\hline
			Type of counterspeech & {\sl Jews} & {\sl Blacks}  & {\sl LGBT} & \\
			\hline 
			Presenting facts & 202 & 34 & 255 & 491\\
			Pointing out hypocrisy or contradictions & 147 & 100 & 245 & 492\\
			Warning of offline or online consequences & 77 & 50 & 99 & 226\\
			Affiliation & 166 & 66 & 110 & 342\\
			Denouncing hateful or dangerous speech & 253 & 212 & 221 & 686\\
			Humor & 141 & 115 & 355 & 611\\
			Positive Tone & 287 & 121 & 114 & 522\\
			Hostile & 531 & 510 & 635 & 1676\\ \hline
            Total & 1804 & 1208 & 2034 & 5046 \\
			
			\hline
		\end{tabular}}
		\caption{Statistics of the counterspeech dataset. Numbers corresponding to each of the target community, grouped as per the type of counterspeech are shown.}
		~\label{tab:dataset_statistics}
	\end{table}



	

	
\vspace{-8mm}
\section{Detailed analysis}

In this section, we perform a detailed analysis over the dataset. We observe that 78.2\% of the counterspeech comments belong to exactly one counterspeech category. Thus, majority of the counterspeakers rely on a single strategy for counterspeech. As noted in Table ~\ref{tab:dataset_statistics}, different communities attract different types of counterspeech. We observe that `Hostile Language' is the major category for all the classes. Other than that, the counterspeakers for the {\sl Jews} community seem to be using `Positive Tone' strategy in their counterspeech more often, while the counterspeakers of the {\sl LGBT} community more often use `Humor' to tackle the hatespeech. 


\subsection{Likes and comments}
We first analyze the comments as per the likes and comments received. We consider two groups - counterspeech comments and non-counterspeech comments. For our analysis, we also perform Mann–Whitney U test~\cite{mann1947test} to compare the two distributions. 




On average, we find counterspeech comments in our data receiving 3.26 likes, in contrast to non-counterspeech comments receiving 1.68 likes, which is almost half of counterspeech (). Similarly, we investigate into the number of replies received and find that counterspeech comments received more replies (average: ) than non-counterspeech comments (average: ). However, the differences were not as significant (). \if{0}To get a better understanding, we further perform this analysis considering the different types of counterspeech. Figure~\ref{fig:sfig1} shows the average number of likes received by each type of counterspeech. We can observe that `Affiliation' receives more likes than all other categories. \iffalse\TODO{PG: but figure mentions identification}\binny{Corrected.}\fi In fact, there have been previous research~\citet{susan2016successfullcounter} recommending use of affiliation messages as a successful counter strategy.
Figure~\ref{fig:sfig5} shows the average number of replies received across the different types of counterspeech. Here we can observe that the `Contradictions' category receives the highest number of replies. Moreover, `Humor', `Facts', and `Affiliation' also seem to get more replies. Overall, we see that `Facts' receives the least average likes and `Consequences' receives the least average replies.\fi
\iffalse
\begin{figure*}[h]

	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{Figures/Counter_Number_of_Likes_Mean}
		\caption{Average number of likes received by each type of counterspeech.}
		\label{fig:counter_num_likes}
	\end{subfigure}
	\qquad
	\centering	
	\begin{subfigure}[b]{0.45\textwidth}
		\includegraphics[width=\textwidth]{Figures/Counter_Number_of_Likes_Mean}
		\caption{Average number of replies received by each type of counterspeech.}
		\label{fig:counter_num_replies}
	\end{subfigure}

	\caption{Differences in the number of likes and number of replies received by different types of counterspeech.} 

\end{figure*}
\fi



\begin{figure*}
\if{0}\begin{subfigure}{.24\textwidth}
  \centering
  \includegraphics[width=\linewidth]{Figures/Counter_Number_of_Likes_Mean}
  \caption{All community likes}
  \label{fig:sfig1}
\end{subfigure}\fi
\begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=\linewidth]{Figures/Blacks_Counter_Number_of_Likes_Mean}
  \caption{{\sl Blacks} community likes}
  \label{fig:sfig2}
\end{subfigure}\begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=\linewidth]{Figures/Jews_Counter_Number_of_Likes_Mean}
  \caption{{\sl Jews} community likes}
  \label{fig:sfig3}
\end{subfigure}\begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=\linewidth]{Figures/LGBT_Counter_Number_of_Likes_Mean}
  \caption{{\sl LGBT} community likes}
  \label{fig:sfig4}
\end{subfigure}

\if{0}\begin{subfigure}{.24\textwidth}
  \centering
  \includegraphics[width=\linewidth]{Figures/Counter_Number_of_Replies_Mean}
  \caption{All community replies}
  \label{fig:sfig5}
\end{subfigure}\fi
\begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=\linewidth]{Figures/Blacks_Counter_Number_of_Replies_Mean}
  \caption{{\sl Blacks} community replies}
  \label{fig:sfig6}
\end{subfigure}\begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=\linewidth]{Figures/Jews_Counter_Number_of_Replies_Mean}
  \caption{{\sl Jews} community replies}
  \label{fig:sfig7}
\end{subfigure}\begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=\linewidth]{Figures/LGBT_Counter_Number_of_Replies_Mean}
  \caption{{\sl LGBT} community replies}
  \label{fig:sfig8}
\end{subfigure}\caption{Plots showing average number of likes and replies received by different types of counterspeech in the three communities.}
\label{fig:fig}
\vspace{-5mm}
\end{figure*}









We further look into the comments and likes received by each of the community for each type of counterspeech. Figures~\ref{fig:sfig2} and~\ref{fig:sfig6} show the average number of likes and replies received by the {\sl Blacks} community, respectively. Here, we observe that the comments that talk about online/offline consequences get more likes. Also, strategies such as `Consequences' and `Humor' seem to garner more replies than other strategies. For the {\sl Jews} community, Figures~\ref{fig:sfig3} and~\ref{fig:sfig7} plots the average number of likes and replies received, respectively. `Affiliation' here receives more likes than other types. `Affiliation' and `Contradiction' receive the majority of replies. Figures~\ref{fig:sfig4} and~\ref{fig:sfig8} plot the average number of likes and replies received by the {\sl LGBT} community, respectively. `Humor' and `Contradictions' receives more likes than other types. `Contradiction', `Humor', and `Positive Tone' receives more replies than other types. 







\subsection{Psycholinguistic analysis}
The language that online users choose, provide important psychological cues to their thought processes, emotional states, intentions, and motivations~\cite{tausczik2010psychological}. The LIWC tool\footnote{http://liwc.wpengine.com/} helps in understanding several psycholinguistic properties using the text. In order to understand the psycholinguistic differences, we apply LIWC (i.e., the fraction of words in different linguistic and cognitive dimensions identified by the LIWC tool) on both counter and non-counter comments. Finally, we look for statistically significant differences between these two groups with respect to the above analysis. We run Mann–Whitney U test~\cite{mann1947test} and report the significantly different categories in Table~\ref{tab:liwc_analysis}.

We observe several LIWC categories that show significant differences between counter and non-counter comments. The `spoken' category of LIWC (`assent' and `non-fluencies') is more pronounced in non-counterspeech, whereas `affective processes' (`anxiety', `anger', `sadness', `negative emotion' and `affect') are more strong in counterspeech. `Personal concern' (`religion' and `leisure') is more pronounced in non-counter comments. The `biological processes' (`body', `health', `sexual'), on the other hand, seems to be more dominant in the language of the counterspeakers.

\begin{table}[!t]
	\centering
	\resizebox{\linewidth}{!}{\begin{tabular}{| p{4.5cm} | p{2.2cm} | p{2cm} |p{2.2cm}|} 
			\hline
			Dimension &Category & Counter (mean) & Non-counter (mean) \\ \hline
            
\multirow{ 2}{*}{Personal concerns}&Leisure*** & \cellcolor{red!20}0.184 & \cellcolor{green}\textbf{0.298} \\
									&Relig*** & \cellcolor{red!20}1.341 & \cellcolor{green}\textbf{1.615} \\ \hline

\multirow{ 2}{*}{Spoken categories}&Assent*** & \cellcolor{red!20}0.197 & \cellcolor{green}\textbf{0.275} \\
                        &Nonflu*** & \cellcolor{red!20}0.034 & \cellcolor{green}\textbf{0.051} \\ 
						                  
\hline

\multirow{ 3}{*}{Biological processes}&Body*** & \cellcolor{green}\textbf{0.314} & \cellcolor{red!20}0.248 \\
									 &Health*** & \cellcolor{green}\textbf{0.19} & \cellcolor{red!20}0.154 \\
									 &Sexual*** & \cellcolor{green}\textbf{0.525} & \cellcolor{red!20}0.439 \\
                         
\hline     

\multirow{ 1}{*}{Perceptual processes}&Hear*** & \cellcolor{red!20}0.243 & \cellcolor{green}\textbf{0.305} \\

\hline

\multirow{ 3}{*}{Cognitive processes}&Insight*** & \cellcolor{red!20}0.706 & \cellcolor{green}\textbf{0.867} \\
									&Discrep** & \cellcolor{green}\textbf{0.713} & \cellcolor{red!20}0.699 \\
                                    &Certain*** & \cellcolor{red!20}0.569 & \cellcolor{green}\textbf{0.674} \\	
                                    
\hline

\multirow{ 6}{*}{Affective processes}&Anx*** & \cellcolor{green}\textbf{0.141} & \cellcolor{red!20}0.106 \\
									&Negemo*** & \cellcolor{green}\textbf{1.546} & \cellcolor{red!20}1.31 \\
                                    &Posemo*** & \cellcolor{red!20}1.164 & \cellcolor{green}\textbf{1.306} \\
                                    &Affect*** & \cellcolor{green}\textbf{2.699} & \cellcolor{red!20}2.596 \\
                                    &Anger*** & \cellcolor{green}\textbf{0.929} & \cellcolor{red!20}0.752 \\
                                    &Sad** & \cellcolor{green}\textbf{0.191} & \cellcolor{red!20}0.178 \\



\hline


\multirow{ 1}{*}{Social processes}&Humans*** & \cellcolor{green}\textbf{0.758} & \cellcolor{red!20}0.648 \\

\hline


\multirow{13}{*}{Linguistic processes}&Funct* & \cellcolor{red!20}17.136 & \cellcolor{green}\textbf{18.479} \\
									&Swear*** & \cellcolor{green}\textbf{0.3} & \cellcolor{red!20}0.184 \\
                                    &I*** & \cellcolor{green}\textbf{0.645} & \cellcolor{red!20}0.545 \\
                                    &Article* & \cellcolor{red!20}2.077 & \cellcolor{green}\textbf{2.475} \\
                                    &Ipron*** & \cellcolor{green}\textbf{2.089} & \cellcolor{red!20}2.083 \\
                                    &Negate* & \cellcolor{red!20}0.811 & \cellcolor{green}\textbf{0.881} \\
                                    &Past*** & \cellcolor{red!20}0.745 & \cellcolor{green}\textbf{1.011} \\
                                    &Present*** & \cellcolor{green}\textbf{3.415} & \cellcolor{red!20}3.346 \\
                                    &Pronoun** & \cellcolor{red!20}4.24 & \cellcolor{green}\textbf{4.303} \\
                                    &They*** & \cellcolor{red!20}0.43 & \cellcolor{green}\textbf{0.59} \\
                                  	&Verbs* & \cellcolor{red!20}4.884 & \cellcolor{green}\textbf{5.092} \\
                                  	&You* & \cellcolor{red!20}0.498 & \cellcolor{green}\textbf{0.541} \\
                                    &SheHe*** & \cellcolor{green}\textbf{0.62} & \cellcolor{red!20}0.594 \\

			\hline
\end{tabular}}
\caption{LIWC analysis of the counter and non-counter comments. Only those LIWC categories are shown which are statistically significant:  (*),  (**),  (***). Note that each LIWC category is either dense in green cells (red cells) for the counter (non-counter) comments or for the non-counter (counter) comments.}
~\label{tab:liwc_analysis}
\end{table}


\section{Classification model}
We consider three classification tasks that naturally manifest in this problem context. The first task is a binary classification problem in which we present the system with a comment and the task is to predict whether the comment is a counterspeech or non-counterspeech. The second one is a multi-label classification task in which we present the system with a known counterspeech comment and the task is to predict all the types of counterspeech present in the comment. The third task is similar to first, except that it is cross-community, i.e., while the training data is drawn from two of the three communities, the test data is drawn from the remaining community. 

\noindent\textbf{Preprocessing:} Before the classification, we preprocess all the data by eliminating URLs, numerals and punctuations. The text is then lower cased, tokenized and used as input for the classification pipeline. We observe that the stop words provide important cues to the classifier and therefore retain them through the preprocessing stage.

\noindent\textbf{Training, validation and test split:} The data is split into a training, validation and test set, where the validation and test set are randomly sampled while respecting their overall type distribution in the dataset. \iffalse \TODO{PG: What do you mean by the last sentence? Each type is not equally distributed in general.}\binny{I wanted the train, test and validation set to have the same percentage of each class. The validation set(5\%of data) will have at least 5\%( as comments can have more than one category) of each category of comments. Then Test set will have at least 20\% of each category. The rest is used as Training Data.}\fi As there are more non-counter comments in the training data, we randomly select a subset of these to make the dataset balanced. 



\noindent\textbf{Features:} For the task of classification we use \textit{tf-idf} vectors and \textit{bag of words} vectors (BoWV). The BoWV approach uses the average of the GloVe~\cite{pennington2014glove} word embeddings to represent a sentence. We set the size of the vector embeddings to 200.

\noindent\textbf{Choice of classifiers:}
We experiment with multiple classifiers such as Random Forest (RF), Logistic Regression (LR), SVMs, XGBoost (XGB), Decision Tree (DT), and neural models such as Multi-layer Perceptron(MLP), fastText, LSTM, CNN. 


\subsection{Counterspeech classification}
In this task, a binary classifier is built to predict if the given input text is a counterspeech or non-counterspeech. We consider balanced test data and report results in   Table~\ref{tab:prediction_task1_results}. As the table shows, logistic regression with TF-IDF performs the best. Classifier such as fastText with random embeddings also perform well.





\begin{table}[!htbp]
	
\resizebox{\linewidth}{!}{\begin{tabular}{| p{5cm} | p{1.5cm} |p{1.5cm}| p{1.5cm}| p{1.5cm}|} 
		\hline
		Model & Precision & Recall & F1-Score \\
		\hline
        Random Embedding + LSTM & 0.64 & 0.64 & 0.64  \\
        BoWV + SVM & 0.65 & 0.65 & 0.65 \\
        Random Embedding + CNN & 0.66 & 0.66 & 0.66 \\
        TF-IDF + XGBoost & 0.67 & 0.67 & 0.67  \\
		BoWV + RF & 0.67 & 0.67 & 0.67  \\
        \rowcolor{green!20}Random Embedding + Fasttext & 0.70 & 0.70 & 0.70 \\
		\rowcolor{green}TF-IDF + LR & 0.73 & 0.73 & 0.73  \\
        
		\hline
		
	\end{tabular}}
	\caption{Classification scores for the task of predicting if the given comment is counterspeech or non-counterspeech.}
	~\label{tab:prediction_task1_results}
\vspace{-5mm}
\end{table}

\vspace{-1mm}
\subsection{Counterspeech type classification}
Here, we build models for a multi-label classification task in which the input to the classifier is a counter comment and the output are the types of counterspeech present in the comment. Table~\ref{tab:prediction_task2_results} shows the results of this task.
For evaluation purpose, we report the strict metric \textit{exact match ratio} ~\cite{sorower2010literature}. In addition, to account for partial correctness, we report the variants of accuracy, precision, recall and F1-score proposed by~\citet{godbole2004discriminative}. \if{0}We also report Hamming loss~\cite{schapire2000boostexter} which measures how many times on average, the relevance of an example to a class label is incorrectly predicted.\fi As the table shows, MLP gives the best performance in all the metrics.


\begin{table}[!htbp]
	
\resizebox{\linewidth}{!}{\begin{tabular}{| p{3cm} | p{2cm} | p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|} 
		\hline
		Model & Exact match ratio & Accuracy & Precision & Recall & F1-score \\
		\hline
		Random Forest & 0.17 & 0.19 & 0.21 & 0.19 & 0.20 \\
		Decision Tree & 0.21 & 0.30 & 0.33 & 0.36 & 0.33 \\
		MLP & \cellcolor{green}0.32 & \cellcolor{green}0.39 & \cellcolor{green}0.42 &  \cellcolor{green}0.42 &  \cellcolor{green}0.41 \\
		
		\hline
		
	\end{tabular}}
	\caption{Classification scores for the task of multi-label classification of the types of counterspeech.}
	~\label{tab:prediction_task2_results}
\vspace{-8mm}
\end{table}



\subsection{Cross-community classification}
In this section, we build models that draw the training data points from two communities to predict the labels for the test data drawn from the third community. Note that this application is motivated by the fact that in the context of the current problem there might exist communities for which in-community training instances are scarce and therefore the only way to perform the classification is to resort to the training instances available for other communities (see~\cite{Rudra:2015} for a similar approach). For evaluation, we report weighted precision, recall and F1-Score. Table ~\ref{tab:prediction_task3_results} shows the results of this task. The models are able to produce comparable results even while they are trained using instances from a different community. This is an extremely desirable feature to avoid requirement of fresh annotations every time the model is used for a new  (and so far unseen) community.



\begin{table}[!htbp]
	
\resizebox{\linewidth}{!}{\begin{tabular}{| p{2.5cm} | p{1.7cm}| p{2cm} | p{1.5cm} |p{1.5cm}| p{1.5cm}|} 
		\hline
		Train instances & Test instances & Model & Precision & Recall & F1-Score\\
		\hline
		Blacks + Jews & LGBT & XGB & 0.65 & 0.58 & 0.58 \\
		Jews + LGBT & Blacks & SVM & 0.62 & 0.62 & 0.61  \\
		LGBT + Blacks & Jews &LR & 0.62 & 0.58 & 0.58  \\
		
		\hline
		
	\end{tabular}}
	\caption{Classification scores for the task of predicting if the given comment is counterspeech or non-counterspeech in one community using the training instances from the other two communities.}
	~\label{tab:prediction_task3_results}
\vspace{-8mm}
\end{table}


\section{Discussion}

We observe that the non-counterspeech consist mainly of comments that agree with the main content in the video or hatespeech toward the target community itself. These vary depending on the community involved. In case of {\sl Jews}, we find that majority of the comments claimed that the Jews are controlling the economy and are responsible for the destruction of their society. Many of the non-counterspeech also included holocaust denial~\cite{gerstenfeld2003hate}. In case of {\sl Blacks}, we find that the majority of non-counterspeech were hatespeech in the form of racist remarks such as ni**ers, slavery etc. In case of {\sl LGBT}, we observe that the majority of non-counterspeech are linked to religious groups claiming that it is unnatural and forbidden in their religion.

\iffalse
Analysis of counterspeech content shows that the strategy of using `Hostile Language' is very prevalent (see Table~\ref{tab:dataset_statistics}). We observe that these type of counterspeech are not welcomed by even the target community in whose favor these are posted. In many instances, the target community users tend to oppose this form of counterspeech and request the counterspeakers to refrain from using such language of hate.
\fi


Not all types of counterspeech are equally effective~\cite{susan2016successfullcounter}. \if{0}\TODO{PG: But is this an insight from your dataset? Can we say anything about effectiveness?}\fi To understand the nature of replies received by each type of counterspeech comments, we randomly select some comments corresponding to each type and analyze the nature of the responses received. This would tell us how the community views these statements provided by the counterspeakers. In specific, we check if the reply is agreeing with the statement provided by the counterspeaker. \if{0}\TODO{Not clear. What do you mean by agree/disagree? Whether the response is agreeable to other counterspeakers in the community?}.\fi We observe that strategies like `Warning of Consequences', `Denouncing Hate' and `Humor' receive more acceptance in the replies \if{0}\TODO{What do you mean by acceptance?}\fi than other strategies. Strategies like `Pointing out Hypocrisy' and `Hostile Language' receive least acceptance from the community. Although, using `Hostile Language' seems to be very prevalent (see Table~\ref{tab:dataset_statistics}), we observe that this strategy is not welcomed by even the target community in whose favor these are posted. In many instances, the target community users tend to oppose this form of counterspeech and request the counterspeakers to refrain from using such language of hate.









\iffalse{0}
While counterspeech may seem like a good solution, it also suffers from several problems. Most of the times, the number of people countering the hate speech is very small. \TODO{PG: but in your dataset, 42\% comments are counterspeech. So, are these made by very few people?}\binny{No sir. 1.13 comments per counterspeakers. What i intended to say was about minority likes(LGBT, Fat People, Rohingyas...)} 
\fi



\section{Conclusion and future works}

The proliferation of hateful content in online social media is a growing concern. Currently used methods such as blocking or suspension of messages/accounts cause problems to the freedom of speech. Counterspeech is emerging as a very promising option backed by several organizations and NGOs. With no dataset and model available for counterspeech detection, no large scale study can be conducted. In this paper, we took the first step toward creating a dataset of counterspeech against hateful videos in YouTube. We found that counter comments receive more likes than non-counter comments. Further, the psycholinguistic analysis of the comments reveal striking differences between the language choice of counter and non-counter speakers. We found that different communities seem to have different preferences for the selection of counterspeech type. Our models and dataset are placed in the public domain.

There are several directions, which can be taken up as future research. One immediate step is to develop automatic counterspeech detection models for other social media sites like Facebook and Twitter. Another direction could be to study the effectiveness of different types of counterspeech for different communities. A connected research objective could be to investigate how effective the counterspeakers are in changing the mindset of the hate users. 





\bibliography{emnlp2018}
\bibliographystyle{acl_natbib_nourl}

\end{document}
