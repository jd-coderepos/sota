\documentclass[final]{svjour3}

\smartqed
\usepackage{graphicx}
\usepackage{mathptmx}



\usepackage{latexsym}
\usepackage{xspace}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{wasysym}
\usepackage{color}
\usepackage{cite}
\usepackage{url}

\usepackage{prooftree}
\usepackage{abbrevs}
\usepackage{macros}
\usepackage{ammacros}




\journalname{Journal of Automated Reasoning}
\begin{document}
\title{\hybrid\thanks{Felty was supported in part by the Natural
  Sciences and Engineering Research Council of Canada Discovery program.
  Momigliano was
  supported by EPSRC grant GR/M98555 
and partially by the MRG project (IST-2001-33149),
  funded by the EC under the FET proactive initiative on Global
  Computing.}} \subtitle{A Definitional Two-Level Approach to Reasoning
  with Higher-Order Abstract Syntax}

\titlerunning{\hybrid: reasoning with HOAS}  
\author{Amy Felty \and Alberto Momigliano}
         

\institute{Amy Felty \at School of Information Technology and
Engineering, University of Ottawa, Ottawa, Ontario K1N 6N5, Canada \\
\email{afelty@site.uottawa.ca}
\and 
Alberto Momigliano \at Laboratory for the Foundations of
  Computer Science, School of Informatics, University of Edinburgh,
  Edinburgh EH9 3JZ, Scotland\\
\email{amomigl1@inf.ed.ac.uk}
}

\date{\today. Received:?? / Accepted:??}





\maketitle

\begin{abstract}
  Combining higher-order abstract syntax and (co)-induction in a
  logical framework is well known to be problematic.  We describe the
  theory and the practice of a tool called \hybrid, within \HOL and
  Coq, which aims to address many of these difficulties.  It allows
  object logics to be represented using higher-order abstract syntax,
  and reasoned about using tactical theorem proving and principles of
  (co)induction.  Moreover, it is definitional, which guarantees
  consistency within a classical type theory.  The idea is to have a
  de Bruijn representation of -terms providing a definitional
  layer that allows the user to represent object languages using
  higher-order abstract syntax, while offering tools for reasoning
  about them at the higher level.  In this paper we describe how
  to use \hybrid in a multi-level reasoning fashion, similar in spirit
  to other systems such as \emph{Twelf} and \emph{Abella}. By
  explicitly referencing provability in a middle layer called a
  specification logic, we solve the problem of reasoning by
  (co)induction in the presence of non-stratifiable hypothetical
  judgments, which allow very elegant and succinct specifications of
  object logic inference rules.  We first demonstrate the method on a
  simple example, formally proving type soundness (subject reduction)
  for a fragment of a pure functional language, using a minimal
  intuitionistic logic as the specification logic.  We then prove an
  analogous result for a continuation-machine presentation of the
  operational semantics of the same language, encoded this time in an
  ordered linear logic that serves as the specification layer.  This
  example demonstrates the ease with which we can incorporate new
  specification logics, and also illustrates a significantly more
  complex object logic whose encoding is elegantly expressed using
  features of the new specification logic.
  \keywords{logical frameworks\and higher-order abstract syntax\and
    interactive theorem proving\and induction\and variable binding\and
    Isabelle/HOL\and Coq}
\end{abstract}

\section{Introduction}
\label{sec:intro}




\emph{Logical frameworks} provide general languages in which it is
possible to represent a wide variety of logics, programming languages,
and other formal systems.  They are designed to capture uniformities
of the deductive systems of these object logics and to provide
support for implementing and reasoning about them.  One application of
particular interest of such frameworks is the specification of
programming languages and the formalization of their semantics in view
of formal reasoning about important properties of these languages,
such as their soundness.  Programming languages that enjoy such
properties provide a solid basis for building software systems that
avoid a variety of harmful  defects, leading to 
systems that are significantly more reliable and trustworthy.

The mechanism by which object-logics are represented in a logical
framework has a paramount importance on the success of a
formalization. A naive choice of representation can seriously endanger
a project almost from the start, making it almost impossible to move
beyond the very first step of the developments of a case study (see
\cite{Melham94}, which barely goes beyond encoding the syntax of the
-calculus).

\renewcommand{\gr}{\ensuremath{\mathit expr}}

Higher-Order Abstract Syntax (HOAS) is a representation technique used
in some logical frameworks.  Using HOAS, whose idea dates back to
Church~\cite{Church40}, binding constructs in an object logic are
encoded within the function space provided by a meta-language based on
a -calculus.  For example, consider encoding a simple
functional programming language such as Mini-ML \cite{Clement86} in a
typed meta-language, where object-level programs are represented as
meta-level terms of type .  We can introduce a constant
 of type 
to represent functions of one argument.  Using such a representation
allows us to delegate to the meta-language -conversion and
capture-avoiding substitution.  Further, object logic substitution can
be rendered as meta-level -conversion.  However, experiments
such as the one reported in~\cite{Momigliano02lfm} suggest that the
full benefits of HOAS can be enjoyed only when the latter is paired
with support for \emph{hypothetical} and \emph{parametric}
judgments~\cite{MartinLof85,Harper93jacm,Pfenning99handbook}.  Such
judgments are used, for example, in the well-known encoding of
inference rules assigning simple types to Mini-ML programs.  Both the
encoding of programs and the encoding of the typing predicate
typically contain \emph{negative} occurrences of the type or predicate
being defined (\eg, the underlined occurrence of  in the type of
 above).  
This rules out any naive approach to view those set-theoretically as
least fixed points~\cite{GunterwhyMLnot,Paulson94cade}  or
type-theoretically as inductive types, which employ {strict
  positivity} \cite{PaulinMohring93} to enforce strong
normalization.  As much as HOAS sounds appealing, it raises the
question(s): how are we going to reason about such encodings, in
particular are there induction and case analysis principles available?

Among the many proposals---that we will survey in
Section~\ref{sec:rel}---one solution that has emerged in the last
decade stands out: \emph{specification} and (inductive)
\emph{meta-reasoning} should be handled within a single system but at different \emph{levels}. The first
example of such a meta-logic was ~\cite{McDowell01}, soon to
be followed by its successor, ~\cite{Tiu04phd}.\footnote{This
  is by no way the end of the story; on the contrary, the development
  of these ambient logics is very much a work in progress: Tiu
  \cite{Tiu07} introduced the system LG to get rid of the
  local signatures required by Linc's  quantifier. Even more recently Gacek,
  Miller \& Nadathur presented the logic  to ease reasoning
  on open terms and implemented it in the \emph{Abella system}
  \cite{gacek08lics,Abella,AbellaSOS}. However, as this overdue report
  of our approach describes with an undeniable tardiness a system that
  was developed before the aforementioned new contributions,
  we will take the liberty to refer to  as the ``canonical''
  two-level system. We will discuss new developments in more depth in
  Section~\ref{ssec:2lr}.}  They are both based on intuitionistic logic augmented with introduction and elimination rules
for \emph{defined} atoms (partial inductive definitions,
PIDs~\cite{Halnass91}), in particular \emph{definitional reflection}
(\emph{defL}), which provides support for case analysis. While
 has only induction on natural numbers as the primitive form
of inductive reasoning, the latter generalizes that to standard forms
of induction and co-induction \cite{MomiglianoT03};  also
introduces the so-called ``nabla'' quantifier
~\cite{miller05tocl} to deal with parametric judgments.  This
quantifier accounts for the dual properties of eigenvariables, namely
\emph{freshness} (when viewed as constants introduced by the
quantifier right rule) and \emph{instantiability} as a consequence of
the left rule and case analysis. Consistency and viability of proof search are ensured by
cut-elimination~\cite{mcdowell00tcs,Tiu04phd}. Inside the
meta-language, a \emph{specification logic} (SL) is developed that is
in turn used to specify and (inductively) reason about the
\emph{object logic/language} (OL) under study.
This partition avoids the issue of inductive meta-reasoning in
the presence of negative occurrences in OL judgments, since
hypothetical judgments are intensionally read in terms of object-level
provability. The price to pay is coping with this additional layer where we
explicitly reference the latter.  Were we to work with only a bare
proof-checker, this price could be indeed deemed too high; however, if
we could rely on some form of automation such as tactical theorem
proving, the picture would be significantly different.

The first author has proposed in~\cite{Felty02} that, rather than
implementing an interactive theorem prover for such meta-logics from
scratch, they can be simulated within a modern proof assistant.
(Coq~\cite{bertot/casteran:2004} in that case.)  The correspondence is
roughly as follows: the ambient logic of the proof assistant in place
of the basic (logical) inference rules of , introduction and
elimination (inversion) rules of inductive types (definitions) in
place of the \emph{defR} and \emph{defL} rules of PIDs.\footnote{The
  \emph{defL} rule for PIDs may use full higher-order unification,
  while inversion in an inductive proof assistant typically generates
  equations that may or may not be further simplified, especially at
  higher-order types.}  Both approaches introduce a minimal sequent calculus
\cite{JoMinLog} as a SL, and a Prolog-like set of clauses for the
OL\@.  Nevertheless, in a traditional inductive setting, this is not
quite enough, as reasoning by inversion crucially depends on
simplifying in the presence of constructors. When such constructors
are non-inductive, which is typically the case with variable-binding
operators, this presents a serious problem.  The approach used in that
work was axiomatic: encode the HOAS signature with  a set of constants
and add a set of axioms stating the freeness and extensionality
properties of the constants.  With the critical use of those axioms,
it was shown that it is possible to replicate, in the well-understood
and interactive setting of Coq, the style of proofs typical of
.  In particular, subject reduction for Mini-ML is formalized
in~\cite{Felty02} following this style very closely; this means that
the theorem is proved immediately without any ``technical'' lemmas
required by the choice of encoding technique or results that may be
trivial but are intrinsically foreign to the mathematics of the
problem. Moreover, HOAS proofs of subject reduction typically do not
require weakening or substitutions lemmas, as they are implicit in the
higher-order nature of the encoding. However, this approach did not
offer any formal justification to the axiomatic approach and it is
better seen as a proof-of-concept more than foundational work.

The \hybrid tool~\cite{Ambler02} was developed around the same time:
it implements a higher-order meta-language within
\HOL~\cite{Nipkow-Paulson-Wenzel:2002} that provides a form of HOAS
for the user to represent OLs.  The user level is separated from the
infrastructure, in which HOAS is implemented \emph{definitionally} via
a de Bruijn style encoding.  Lemmas stating properties such as
freeness and extensionality of constructors are \emph{proved} and no
additional axioms are required.

\begin{figure}    \setlength{\unitlength}{4144sp}  \begingroup\makeatletter\ifx\SetFigFont\undefined
    \def\x#1#2#3#4#5#6#7\relax{\def\x{#1#2#3#4#5#6}}  \expandafter\x\fmtname xxxxxx\relax \def\y{splain}  \ifx\x\y   \gdef\SetFigFont#1#2#3{    \ifnum #1<17\tiny\else \ifnum #1<20\small\else \ifnum
    #1<24\normalsize\else \ifnum #1<29\large\else \ifnum
    #1<34\Large\else \ifnum #1<41\LARGE\else \huge\fi\fi\fi\fi\fi\fi
    \csname #3\endcsname}  \else \gdef\SetFigFont#1#2#3{\begingroup \count@#1\relax \ifnum
    25<\count@\count@25\fi
    \def\x{\endgroup\@setsize\SetFigFont{#2pt}}    \expandafter\x \csname \romannumeral\the\count@
    pt\expandafter\endcsname \csname @\romannumeral\the\count@
    pt\endcsname \csname #3\endcsname}  \fi \fi\endgroup
  \begin{picture}(4692,2010)(34,-1198) \thinlines
    {\color[rgb]{0,0,0}\put(1456,269){\oval(210,210)[bl]}
      \put(1456,509){\oval(210,210)[tl]}
      \put(2821,269){\oval(210,210)[br]}
      \put(2821,509){\oval(210,210)[tr]} \put(1456,164){\line( 1,
        0){1365}} \put(1456,614){\line( 1, 0){1365}}
      \put(1351,269){\line( 0, 1){240}} \put(2926,269){\line( 0,
        1){240}} }    {\color[rgb]{0,0,0}\put(1006,-181){\oval(210,210)[bl]} \put(1006,
      59){\oval(210,210)[tl]} \put(3271,-181){\oval(210,210)[br]}
      \put(3271, 59){\oval(210,210)[tr]} \put(1006,-286){\line( 1,
        0){2265}} \put(1006,164){\line( 1, 0){2265}}
      \put(901,-181){\line( 0, 1){240}} \put(3376,-181){\line( 0,
        1){240}} }    {\color[rgb]{0,0,0}\put(556,-631){\oval(210,210)[bl]}
      \put(556,-391){\oval(210,210)[tl]}
      \put(3721,-631){\oval(210,210)[br]}
      \put(3721,-391){\oval(210,210)[tr]} \put(556,-736){\line( 1,
        0){3165}} \put(556,-286){\line( 1, 0){3165}}
      \put(451,-631){\line( 0, 1){240}} \put(3826,-631){\line( 0,
        1){240}} }    {\color[rgb]{0,0,0}\put(151,-1081){\oval(210,210)[bl]}
      \put(151,-841){\oval(210,210)[tl]}
      \put(4216,-1081){\oval(210,210)[br]}
      \put(4216,-841){\oval(210,210)[tr]} \put(151,-1186){\line( 1,
        0){4065}} \put(151,-736){\line( 1, 0){4065}} \put(
      46,-1081){\line( 0, 1){240}} \put(4321,-1081){\line( 0, 1){240}}
    }    \put(1936,-556){\makebox(0,0)[lb]{\smash{\SetFigFont{10}{12.0}{rm}{\color[rgb]{0,0,0}\hybrid}        }}}
    \put(1601,-1006){\makebox(0,0)[lb]{\smash{\SetFigFont{10}{12.0}{rm}{\color[rgb]{0,0,0}Isabelle/HOL, Coq}        }}}
    \put(3376,504){\makebox(0,0)[lb]{\smash{\SetFigFont{10}{12.0}{rm}{\color[rgb]{0,0,0}Syntax:
             }        }}}
    \put(3376,279){\makebox(0,0)[lb]{\smash{\SetFigFont{10}{12.0}{rm}{\color[rgb]{0,0,0}Semantics:
            typing ,\dots}        }}}

    \put(3601,299){\makebox(0,0)[lb]{\smash{\SetFigFont{10}{12.0}{rm}{\color[rgb]{0,0,0}          } }}} 

\put(3626,
    10){\makebox(0,0)[lb]{\smash{\SetFigFont{10}{12.0}{rm}{\color[rgb]{0,0,0}Sequent
            calculus: }        }}}
    \put(4051,-151){\makebox(0,0)[lb]{\smash{\SetFigFont{10}{12.0}{rm}{\color[rgb]{0,0,0}}        }}}
    \put(4000,-421){\makebox(0,0)[lb]{\smash{\SetFigFont{10}{12.0}{rm}{\color[rgb]{0,0,0}Meta-language:
            quasi}        }}}
    \put(4000,-601){\makebox(0,0)[lb]{\smash{\SetFigFont{10}{12.0}{rm}{\color[rgb]{0,0,0}
            datatype for
            a -calculus}        }}}
    \put(4500,-871){\makebox(0,0)[lb]{\smash{\SetFigFont{10}{12.0}{rm}{\color[rgb]{0,0,0}Ambient
            logic:}        }}}
  \put(4500,-1071){\makebox(0,0)[lb]{\smash{\SetFigFont{10}{12.0}{rm}{\color[rgb]{0,0,0}
            tactics/simplifier}        }}}
    \put(4500,-1271){\makebox(0,0)[lb]{\smash{\SetFigFont{10}{12.0}{rm}{\color[rgb]{0,0,0}
            (co)induction}        }}}
    \put(1800,344){\makebox(0,0)[lb]{\smash{\SetFigFont{10}{12.0}{rm}{\color[rgb]{0,0,0}Object
            logic}        }}}
    \put(1800,-106){\makebox(0,0)[lb]{\smash{\SetFigFont{10}{12.0}{rm}{\color[rgb]{0,0,0}Specification
            logic}        }}}
  \end{picture}
  \caption{Architecture of the \hybrid system}
  \label{fig:arch}
\end{figure}


It was therefore natural to  combine the HOAS meta-language 
provided by \hybrid with Miller \& McDowell's two-level approach,
modified for inductive proof assistants.  We implement this combined
architecture in both \HOL and Coq, but we speculate that the approach
also works for other tactic-based inductive proof assistants,
such as PVS~\cite{cade92-pvs},  LEGO~\cite{LEGO} \etc.  We describe
mainly the \HOL version here,
though we compare it in some detail with the Coq
implementation.\footnote{We also compare it with a constructive version
  implemented in Coq~\cite{CapFel07}, which we describe in
  Section~\ref{ssec:h-v}.}  A graphical depiction of the architecture
is shown in Figure~\ref{fig:arch}.  We often refer to the \hybrid and
\HOL levels together as the meta-logic.  When we need to distinguish
the \HOL level on its own, we call it the meta-meta-logic.  When we
say \emph{two-level} reasoning, we are referring to the object and
specification levels, to emphasize that there are two separate
reasoning levels in addition to the meta-level.



Moreover, we suggest a further departure in design
(Section~\ref{ssec:variation}) from the original two-level
approach~\cite{McDowell01}: when possible, \ie, when the
structural properties of the meta-logic are coherent with the style of
encoding of the OL, we may reserve for the specification level only those
judgments that cannot be {adequately} encoded inductively and
leave the rest at the \HOL level.  We claim that this framework with
or without this variation has several advantages:

\begin{itemize}
\item The system is more trustworthy: freeness of constructors and,
  more importantly, extensionality properties at higher-order types are not
  assumed, but proved via the related properties of the
  infrastructure, as we show in Section~\ref{using} 
  (MC-Theorem~\ref{thm:clash}).
\item The mixing of meta-level and specification-level judgments makes proofs more
  easily mechanizable; more generally, there is a fruitful
  interaction between (co)-induction principles, meta-logic
  datatypes, classical reasoning, and hypothetical judgments, which
  lends itself to a good deal of automation.

\item We are not committed to a single monolithic SL,
  but we may adopt different ones (linear, relevant, bunched, \etc.)
  according to the properties of the OL we are encoding. The only
  requirement is consistency, to be established with a formalized
  cut-elimination argument.  We exemplify this methodology using
  non-commutative linear logic to reason about continuation machines
  (Section~\ref{sec:olli}).
\end{itemize}
 
Our architecture could also be seen as an approximation
of \emph{Twelf}~\cite{TwelfSP},
but it has a much lower mathematical overhead, simply consisting of a
small set of theories (modules) on top of a proof assistant. In a
sense, we could look at \hybrid\ as a way to ``represent'' Twelf's
meta-proofs in the well-understood setting of higher-order logic as
implemented in \HOL (or the calculus of (co)inductive constructions as
implemented in Coq). Note that by using a well-understood logic and
system, and working in a purely definitional way, we avoid the need to
justify \emph{consistency} by syntactic or semantic means.  For
example, we do not need to show a cut-elimination theorem for a new
logic as in~\cite{gacek08lics}, nor prove results such as strong
normalization of calculi of the  family \cite{S00} or
about the correctness of the totality checker behind
Twelf~\cite{SchurmannP03}. Hence our proofs are easier to trust, as
far as one trusts Isabelle/HOL and Coq.

Additionally, we can view our realization of the two-level approach as
a way of ``fast prototyping'' HOAS logical frameworks. We can quickly
implement and experiment with a potentially interesting SL; in
particular we can do meta-reasoning in the style of tactical theorem
proving in a way compatible with induction. For example, as we will
see in Section~\ref{sec:olli}, when experimenting with a different
logic, such as a sub-structural one, we do not need to develop all the
building blocks of a usable new framework, such as unification
algorithms, type inference or proof search, but we can rely on the ones
provided by the proof assistant.  The price to pay is, again, the
additional layer where we explicitly reference provability, requiring
a sort of meta-interpreter (the SL logic) to drive it.  This
indirectness can be alleviated, as we shall see, by defining
appropriate tactics, but this is intrinsic to the design choice of
relying on a general ambient logic (here \HOL or Coq,
in~\cite{McDowell01,Tiu04phd} some variation of ). This
contrasts with the architecture proposed in~\cite{McCreight03}, where
the meta-meta-logic is itself sub-structural (linear in this case)
and, as such, explicitly tailored to the automation of a specific
framework.

We demonstrate the methodology by first formally verifying the
subject reduction property for the standard simply-typed call-by-value
-calculus, enriched with a recursion operator.  While this
property (and the calculus as well) has been criticized as too trivial to
be meaningful~\cite{poplmark2005}---and, to a degree, we  agree
with that---we feel that the familiarity of the set-up will ease the
understanding of the several layers of our architecture. Secondly we
tackle a more complex form of subject reduction, that of a
continuation machine, whose operational semantics is encoded
sub-structurally, namely in non-commutative linear logic.

\paragraph{Outline}

The paper is organized as follows: Section~\ref{sec:introh} recalls some
basic notions of \hybrid\ and its implementation in \HOL and Coq.
Section~\ref{using} shows how it can be used as a logical framework.  In
Section~\ref{sec:2lev} we introduce a two-level architecture and present the
first example SL and subject reduction proof,
while Section~\ref{sec:olli} introduces a sub-structural SL and uses it
for encoding continuation machines. We follow that up with an
extensive review and comparison of related work in Section~\ref{sec:rel},
and conclude in Section~\ref{sec:future}.
This paper is an archival documentation of \hybrid 0.1 (see
Section~\ref{ssec:h-v} for the terminology), extending previous joint
work with Simon Ambler and Roy
Crole~\cite{MomTP01,Ambler02,Momigliano02lfm,ACM03prim,Momigliano03fos},
Jeff Polakow~\cite{MomiglianoP03} and Venanzio
Capretta~\cite{CapFel07}.

 \begin{notation}[\HOL]  
   We use a pretty-printed version of \HOL concrete syntax. A type
   declaration has the form \mbox{}.  We stick to the usual logical symbols for \HOL
   connectives and quantifiers (, , , ,
   , ).  Free variables (upper-case) are implicitly
   universally quantified (from the outside) as in logic programming.
   The sign  (Isabelle meta-equality) is used for
   \emph{equality by definition}, and  for Isabelle universal
   meta-quantification.  A rule (a sequent) of the schematic form:  is represented as . A rule with discharged assumptions such as conjunction
   elimination is represented as .  The keyword \textbf{MC-Theorem (Lemma)}
   denotes a machine-checked theorem (lemma), while \emph{Inductive}
   introduces an inductive relation in \HOL, and
   \emph{datatype} introduces a new datatype.
   We freely use infix notations, without explicit declarations.  We
   have tried to use the same notation for mathematical and formalized
   judgments. The proof scripts underlying this paper are written in
   the so-called ``Isabelle old style'', \ie, they are exclusively in
   the tactical-style, \eg, sequences of
   commands. This was still fashionable and supported by \HOL 2005, as
   opposed to the now required ISAR \cite{ISAR} idioms of the new \HOL
   versions.  However, in the interest of time, intellectual honesty
   (and also consistency with Coq), we have decided to base the paper
   on the original code of the project, which had as a fundamental
   goal the \emph{automation} of two-level reasoning.  Naturally, some
   of the comments that we make about concrete features of the system,
   (as well as interactions with it) are by now relevant only to that
   version. When those happen to be obsolete, we will try to make this
   clear to the reader. We expect, however (and indeed we already are
   in the process, see Section~\ref{ssec:h-v}) to carry over this work
   to the current version of \HOL, possibly enhanced by the new
   features of the system.
 \end{notation}

\begin{notation}[Coq]
  We keep Coq's notation similar to \HOL's where possible.  We use the
  same syntax for type declarations, though of course the allowable
  types are different in the two languages.  We also use  for
  equality by definition and  for equality.  There is no
  distinction between a functional type arrow and logical implication
  in Coq, though we use both  and  depending on the
  context.  In \HOL, there is a distinction between notation at the
  Isabelle meta-level and the HOL object-level, which we do not have
  in Coq. Whenever an \HOL formula has the form , and we say that the Coq version is the same, we
  mean that the Coq version has the form , or equivalently , where
  implication is right-associative as usual.
\end{notation}
Source files for the \HOL and Coq code can be found at
\url{hybrid.dsi.unimi.it/jar}~\cite{Hybrid}.


\section{Introducing \hybrid}
\label{sec:introh}



The description of the \hybrid layer of our architecture is taken fairly
directly from previous work, \viz \cite{Ambler02}.  Central to our
approach is the introduction of a binding operator that (1) allows a
direct expression of -abstraction, and (2) is \emph{defined}
in such a way that expanding its definition results in the conversion
of a term to its de Bruijn representation.  The basic idea is inspired
by the work of Gordon~\cite{Gor93}, and also appears in collaborative
work with Melham~\cite{Gordon96}.  Gordon introduces a
-calculus with constants where free and bound variables are
named by \emph{strings}; in particular, in a term of the form
,  is a string
representing a variable bound in , and  is a function
of two arguments, which when applied, converts free occurrences of
 in  to the appropriate de Bruijn indices and includes an
outer de Bruijn abstraction operator.  Not only does this approach
provide a good mechanism through which one may work with \emph{named}
bound variables under -renaming, but it can be used as a
meta-logic by building it into an \HOL type, say of \emph{proper
  terms}, from which other binding signatures can be defined, as
exemplified by Gillard's encoding of the object calculus~\cite{Gillard00}. As
in the logical framework tradition, every OL binding operator is
reduced to the -abstraction provided by the type of proper
terms.


Our approach
takes this a step further and exploits the built in \hoas\ which is
available in systems such as \HOL and Coq.
\hybrid's  constructor is similar to Gordon's 
except that  is a \emph{binding} operator.  The syntax
 is actually notation for
, which makes explicit the use of {bound
variables in the meta-language} to represent {bound variables in the
OL}.  Thus the  in  is
a meta-variable (and not a string as in Gordon's approach).  

At the base level, we start with an inductive definition of de Bruijn
expressions, as Gordon does.

In our setting,  and  are defined to be the natural
numbers, and  provides names for constants.  The latter type is
used to represent the constants of an OL, as each
OL introduces its own set of constants.

To illustrate the central ideas, we start with the -calculus
as an OL\@.  To avoid confusion with the meta-language
(\ie, -abstraction at the level of \HOL or Coq), we use
upper case letters for variables and a capital  for
abstraction.  For example, consider the object-level term 
.
The terms  and  below illustrate how this term is
represented using Gordon's approach and \hybrid, respectively.

In \hybrid we also choose to denote object-level free variables by terms
of the form , though this is not essential.
In either case, the abstraction operator ( or ) is
defined, and expanding definitions in both  and 
results in the same term, shown below using our de Bruijn notation.

In the above term all the variable occurrences bound by the first
, which corresponds to the bound variable  in the
object-level term, are underlined.  The  operator is
central to this approach and its definition includes determining
correct indices.  We return to its definition in
Section~\ref{defh}.

\smallskip
In summary, \hybrid provides a form of HOAS where object-level:
\begin{itemize}
\item free variables correspond to \hybrid expressions of the
form ;
\item bound variables correspond to (bound) meta-variables;
\item abstractions  correspond to
  expressions , defined as ;
\item  applications 
  correspond to expressions .
\end{itemize}


\subsection{Definition of \hybrid in \HOL}
\label{defh}

\hybrid consists of a small number of \HOL theories (actually two, for
a total of about 130 lines of definitions and 80 lemmas and theorems), which 
introduce the basic definition for de Bruijn expressions ()
given above and provide operations and lemmas on them, building up to
those that hide the details of de Bruijn syntax and permit reasoning
on HOAS representations of OLs.  In this
section we outline the remaining definitions, and give some examples.
Note that our \HOL theories do not contain any axioms which
require external justification,\footnote{We will keep emphasizing this point: the
    package is a definitional extension of \HOL and could be brought
    back to HOL primitives, if one so wishes.} as in some
other approaches such as the Theory of Contexts~\cite{HonsellMS01}.

As mentioned, the operator  is central to our approach, and we begin by
considering what is required to fill in its definition.  Clearly
 must expand to a term with \ikw{ABS} at the head.
Furthermore, we must define a function  such that 
is  where  replaces occurrences of the bound
variable in  with de Bruijn index , taking care to increment the
index as it descends through inner abstractions.  In particular, we
will define a function \ikw{lbind} of two arguments such that
formally:

and  replaces occurrences of the bound variable in 
with de Bruijn index , where recursive calls on inner abstractions
will increase the index.  As an example, consider the function
.  In this
case, application of \ikw{lbind} with argument index  should result
in a level 1 expression:

and thus:


We define \ikw{lbind} as a total function operating on all functions
of type , even \emph{exotic} ones
that do not encode -terms.  For example, we could have  where  counts the total
number of variables and constants occurring in .  Only functions
that behave \emph{uniformly} or \emph{parametrically} on their
arguments represent -terms.  We refer the reader to the
careful analysis of this phenomenon (in the context of Coq) given
in~\cite{DFHtlca95} and to Section~\ref{sec:rel} for more background.
We will return to this idea shortly and discuss how to rule out
non-uniform functions in our setting.  For now, we define \ikw{lbind}
so that it maps non-uniform subterms to a default value.  The subterms
we aim to rule out are those that do not satisfy the predicate
, defined as
follows:\footnote{This definition is one of the points where the \HOL
  and Coq implementations of \hybrid diverge.  See
  Section~\ref{ssec:hcoq}.  }
 
\begin{sloppypar}
We do not define \ikw{lbind} directly, but instead define a relation
\mbox{} and
prove that this relation defines a function mapping the first two
arguments to the third.
\end{sloppypar}

In showing that this relation is a function, uniqueness is an easy
structural induction. Existence is proved using the following
abstraction induction principle.
\begin{goal}[abstraction\_induct]
 
\label{thm:abstractioninduct}
\end{goal}
\sloppy{
The proof of this induction principle is by measure induction 
(), where we instantiate  with \ikw{rank} and
set .
}

We now define  as follows, thus completing the definition of \ikw{lambda}:

where  is Isabelle's notation for the
definite description operator .
From these definitions, it is easy to prove a ``rewrite rule'' for
every de Bruijn constructor.  For example, the rule for
\ikw{ABS} is:
\begin{mclemma}[lbind\_ABS]
  
\end{mclemma}
These rules are collected under the name \ikw{lbind\_simps}, and thus
can be used directly in simplification.

Ruling out non-uniform functions, which was mentioned before, will
turn out to be important for a variety of reasons.  For example, it is
necessary for proving that our encoding adequately represents the
-calculus.  To prove adequacy, we identify a subset of the
terms of type  such that there is a bijection between this
subset and the -terms that we are encoding.  There are two
aspects we must consider in defining a predicate to identify this
subset.  First, recall that  corresponds to a bound variable
in the \lcalc, and  to a free variable; we refer to
\emph{bound} and \emph{free} \emph{indices} respectively. We call a
bound index  \emph{dangling} if  or less  labels
occur between the index  and the root of the expression tree.  We
must rule out terms with dangling indices.  Second, in the presence of
the \ikw{LAM} constructor, we may have functions of type
 that do not behave uniformly on their arguments.  We
must rule out such functions.  We define a predicate \ikw{proper},
which rules out dangling indices from terms of type , and a
predicate \ikw{abstr}, which rules out dangling indices and exotic
terms in functions of type .

To define \ikw{proper} we first define \ikw{level}.  Expression
 is said to be at \emph{level} , if enclosing 
inside   nodes ensures that the resulting expression
has no dangling indices.
 
Then,  is defined simply as:


To define \ikw{abstr}, we first define   as follows:
 
Given  , 
we set:

When an expression  of type  satisfies this
predicate, we say it is an \emph{abstraction}.\footnote{This is akin
to the \ikw{valid} and \ikw{valid1} predicates present in weak
HOAS formalizations such as \cite{DFHtlca95} (discussed further in
Section~\ref{ssec:oth}), although this formalization has,
in our notation, the ``weaker'' type
.}  In addition to being
important for adequacy, the notion of an abstraction is central to the
formulation of induction principles at the meta-level.\footnote{And
so much more for the purpose of this paper: it allows inversion on
inductive second-order predicates, simplification in presence of
higher-order functions, and, roughly said, it ensures the consistency of
those relations with the ambient logic.}

It's easy to prove the analogue of  introduction rules in
terms of , for example:
 A simple, yet
important lemma is:
\begin{mclemma}[proper\_abst]
  
\label{mclem:proper_abst}
\end{mclemma}
So any function is a legal abstraction if its body is a proper
expression. This strongly suggests that were we to turn the predicate
 into a \emph{type} , then any function with source type
 would be de facto a legal
abstraction\footnote{This is indeed the case as we have shown in
  \cite{MMF07} and briefly comment on at the end of
  Section~\ref{sec:rel}.}.

It follows directly from the inductive definition of de Bruijn
expressions that the functions , , , and
 are injective, with disjoint images.  With the introduction
of \ikw{abstr}, we can now also prove the following fundamental
theorem:
\begin{goal}[abstr\_lam\_simp]
  
\label{thm:inj}
\end{goal}
which says that  is injective on the set of abstractions.
This follows directly from an analogous property of :
\begin{mclemma}[abst\_lbind\_simp\_lemma]
  
\end{mclemma}
This is proved by structural induction on the  predicate
using simplification with  \ikw{lbind\_simps}.


Finally, it is possible to perform induction over the quasi-datatype
of proper terms.
\begin{goal}[proper\_VAR\_induct]
\label{thm:proper-induct}
 
\end{goal}
The proof is by induction on the size of , and follows from the
following two lemmas.
\begin{mclemma}

\end{mclemma}
\begin{mclemma}[abstr\_size\_lbind]

\end{mclemma}
Note that MC-Theorem~\ref{thm:proper-induct} does not play
any active role in the two-level architecture, as induction will be
performed on the derivability of judgments.



\subsection{Remarks on \hybrid in Coq}
\label{ssec:hcoq}


In this section we comment briefly on the differences between the \HOL
and Coq implementations of \hybrid, which arise mainly from the
differences in the meta-languages.  \HOL implements a
polymorphic version of Church's higher-order (classical) logic plus
facilities for axiomatic classes and local reasoning in the form of
\emph{locales} \cite{Ballarin03}.  Coq
implements a constructive higher-order type theory,
but includes
libraries for reasoning classically, which we used in order to keep
the implementations as similar as possible.

Note that the definition of  uses \HOL's definite
description operator, which is not available in Coq.  The use of this
operator is the main reason for the differences in the two libraries.
In Coq, we instead use the description axiom available in Coq's
classical libraries:\footnote{In the Coq libraries, a dependent-type
version of this axiom is stated, from which the  version  here
follows directly.}

with  as relation .
The Coq version of \hybrid is larger than the \HOL version,
mainly due to showing uniqueness for the  relation.
We then eliminate the
existential quantifier in the description theorem to get a function
that serves as the Coq version of .\footnote{Although this
elimination is not always justified, it is in our case since we define
the type  to be a Coq .}

\newcommand{\Prop}{\textit{Prop}\xspace}
\newcommand{\Set}{\textit{Set}\xspace}

In more detail, if we consider the \HOL theory just described, the
operations and predicates , ,
, , , and 
are defined nearly the same as in the \HOL version.
For predicates such as , we have a choice that we did not
have in \HOL\@.  In Coq, \Prop is the type of logical propositions,
whereas \Set is the type of datatypes.
 \Prop and \Set allow us to distinguish \emph{logical} aspects from
\emph{computational} ones \wrt our libraries.  The datatype  for
example, distinct from \Prop, is defined inductively in the Coq
standard library as a member of \Set.  One option in defining
 is to define it as a function with target type ,
which evaluates via conversion to  or .  The other is to
define it as an inductive predicate (in \Prop), and then we will need
to provide proofs of  subgoals instead of reducing them to
.  We chose the latter option, using \Prop in the definition of
 and all other predicates.
This allowed us to define inductive predicates in Coq that have the
same structure as the \HOL definitions, keeping the two versions as
close as possible.  For our purposes, however, the other option
should have worked equally well.

For predicates , , ,
and , which each have an argument of functional type,
there is one further difference in the Coq definitions.  Equality in
\HOL is extensional, while in Coq, it is not.  Thus, it was necessary
to define extensional equality on type 
\emph{explicitly} and use that equality whenever it is expressed on
this type, \viz

Formally, .  For example,
this new equality appears in the definition of .  In the Coq
version, we first define an auxiliary predicate 
defined exactly as  in \HOL, and then define 
as:
 
The predicate  has the same definition as in \HOL, via this
new version of .  The definition of  parallels
the one for , in this case using .  For
the  predicate, we obtain the Coq version from the \HOL
definition simply by replacing  with .

The proof that  is a total relation is by induction on
 and
the induction case uses a proof by cases on whether or not a term of
type  is ordinary.  Note that the 
property is not decidable, and thus this proof requires classical
reasoning, which is a second reason for using Coq's classical
libraries.

Coq provides a module which helps to automate proofs using
user-defined equalities that are declared as \emph{setoids}.  A setoid
is a pair consisting of a type and an equivalence relation on that
type.  To use this module, we first show that  is reflexive,
symmetric, and transitive.  We then declare certain predicates as
morphisms.  A morphism is a predicate in which it is allowable to
replace an argument by one that is equivalent according to the user-defined
equality.  Such replacement is possible as long as the corresponding
compatibility lemma is proved.  For example, we declare
, , , and  as
morphisms.  In particular, the lemma for  proves that if
, then for all terms  that are extensionally
equal to , we also have .  Setoid rewriting then
allows us to replace the second argument of  by
extensionally equal terms, and is especially useful in the proof that
every  is related to a unique  by .

As stated above, we obtain  by eliminating the existential
quantifier in the description theorem.  Once we have this function, we
can define  as in \HOL and prove the Coq version of the
\textit{abstr\_lam\_simp} theorem
\mbox{(MC-Theorem~\ref{thm:inj})}:  
 
Note the use of logical equivalence () between
elements of \Prop.  Extensional equality is used between elements of
type  and Coq equality is used between other terms
whose types are in \Set.  Similarly, extensional equality replaces
equality in other theorems involving expressions of type .  For example \textit{abstraction\_induct}
(MC-Theorem~\ref{thm:abstractioninduct}) is stated as follows:
 



\section{\hybrid as a Logical Framework}
\label{using}

  


In this section we show how to use \hybrid as a logical framework,
first by introducing our first OL (Section~\ref{ssec:coding}) and
discussing the adequacy of the encoding of its syntax
(Section~\ref{ssec:adeq}).  Representation and adequacy of syntax are
aspects of encoding OLs that are independent of the two-level
architecture.  We then show that some object-level judgments can be
represented directly as inductive definitions
(Section~\ref{ssec:oljudg}).  We also discuss the limitations of
encoding OL judgments in this way, motivating the need for the
two-level architecture of Section~\ref{sec:2lev}.


The system at this level provides:
\begin{itemize}
\item A suite of theorems: roughly three or four dozens propositions,
  most of which are only intermediate lemmas leading to the few that are
  relevant to our present purpose: namely, injectivity and
  distinctness properties of \hybrid constants.

\item Definitions \ikw{proper} and \ikw{abstr}, which are important for
\hybrid's adequate representation of OLs.

\item A very small number of automatic tactics: for example \ikw{proper\_tac}
  (resp.\ \ikw{abstr\_tac}) automatically recognizes whether a given
  term is indeed proper (resp.~an abstraction).

\end{itemize}

We report here the (slightly simplified) code for \ikw{abstr\_tac},
to give an idea of how lightweight such tactics are:

\begin{verbatim}
fun abstr_tac defs =
       simp_tac (simpset()
                 addsimps defs @ [abstr_def,lambda_def] @ lbind_simps)
        THEN'
        fast_tac(claset()
                addDs [abst_level_lbind]
                addIs abstSet.intrs
                addEs [abstr_abst, proper_abst]);
\end{verbatim}
First
the goal is simplified (\texttt{simp\_tac}) using the definition of
\ikw{abstr}, \ikw{lambda}, other user-provided lemmas (\texttt{defs}),
and more importantly the \ikw{lbind} ``rewrite rules''
(\ikw{lbind\_simps}). At this point, it is merely a question of
resolution with the introduction rules for \ikw{abst}
(\texttt{abstSet.intrs}) and a few key lemmas, such as
MC-Lemma~\ref{mclem:proper_abst}, possibly as elimination rules. In
\HOL 2005, a tactic, even a user 
defined one, could also be ``packaged'' into a \emph{solver}. In this
way, it can be combined with the other automatic tools, such as the
simplifier or user defined tactics, \viz  \ikw{2lprolog\_tac}.  (See
Section~\ref{ssec:tac}.)


\subsection{Coding the Syntax of an OL in \hybrid}
\label{ssec:coding}

The OL we consider here is a fragment of
a pure functional language known as Mini-ML\@.  As mentioned, we
concentrate on a -calculus augmented with a fixed point operator,
although this OL could be easily generalized as in~\cite{Pfenning01book}.
This fragment is sufficient to illustrate the main ideas without
cluttering the presentation with too many details.


The types and terms of the source language are given respectively by:

We begin by showing how to represent the syntax in HOAS format using
\hybrid. Since  types for this language have no
bindings, they are represented with a standard datatype, named
\textit{tp} and defined in the obvious way;
more interestingly, as far as terms are
concerned, we need constants for
abstraction,   application and fixed point, say ,
, and .
Recall that in the meta-language, application is denoted by infix
\mathsf{LAM}\con\ikw{fun}\ikw{fix}(\llrec{E\ x})(\ikw{fix} (\lambda x.\ E
\ x))(\llrec{\llFun{y}{\llApp x y}})\lambda\lambda\lambda\lambda\encode{\Gamma}
{\cdot}\Gamma\decode{\Gamma} \cdott\Gamma\encode{\Gamma}{t}\alpha\GammaE\Gamma\decode{\Gamma}{E}t\encode\Gamma{\decode \Gamma E} = E\decode\Gamma{\encode \Gamma t} = t\encode{\cdot}{\cdot}\decode{\cdot}{\cdot}\encode \Gamma {[t_1/x] {t_2}} = {[\encode
    \Gamma {t_1}/x]} \; \encode \Gamma {t_2}\decode \Gamma
  {[E_1/x] {E_2}} = {[\decode \Gamma {E_1}/x]} \; \decode \Gamma
  {E_2}\App {\LAM{x}{\arg{x}}} {(\Var 0)}\expr\llrec {\llFun y {\ikw{if} \ x = y\ \ikw{then} \ x\
  \ikw{else}\ y}}\Gamma,x\Gamma\cup \{x\}\Gamma\uexp{\isterm{\_}{\_}}\fsprems{\uexp\ \mathit{set},\uexp} \fs \bool\uexp\Gamma\vdash t\isterm{\Gamma}{\encode \Gamma t}t\lambda x y.\, \encode{\Gamma,x,y}{t}(\expr\fs\expr\fs\expr)\fs\expr\abst{}{} \Gamma=\{x_1,\ldots, x_n\}(\proper \Gamma\prems{\proper{x_1};\ldots;\proper{x_n}}\Gamma\vdash t(\proper\Gamma\Implies\isterm{\Gamma}{\encode \Gamma  t})\Gamma\vdash t\Gamma \{x_1: \uexp,\dots,x_n:uexp\}(\proper\Gamma\Implies\isterm\Gamma E)\decode\Gamma Et\Gamma\vdash t\encode\Gamma{\decode
  \Gamma E} = E\decode\Gamma{\encode \Gamma t} = t\proper\Gamma\Implies\isterm\Gamma E\proper\Gamma\Implies\isterm{\Gamma}{(\llrec{E\ x})}\isterm{\Gamma,x}{(E~x)}x\proper {(\Gamma, x)}\decode{\Gamma} {\llrec{(E\ x)}} = \rec{\decode{\Gamma,x} {E\ x}}\decode{\Gamma,x} {E\ x}tt=\decode{\Gamma,x} {E\ x}\Gamma,x\vdash t\mathbf{fix}\Gamma
  \vdash \rec t\encode{\Gamma}{\decode{\Gamma} {\llrec{E\ x}}}={\llrec{E\ x}}\decode\Gamma{\encode \Gamma t} = tt\encode \Gamma {[t_1/x] {t_2}} = {[\encode \Gamma {t_1}/x]} \
  \encode \Gamma {t_2}x\Gamma\decode\Gamma{E_1}\decode\Gamma{E_2}\decode \Gamma {[E_1/x] {E_2}} = {[\decode \Gamma {E_1}/x]} \
  \decode \Gamma {E_2}t_2E_2 \begin{array}{c}
 \ianc{\eval{e_1}{\Lx e_1'}\qquad \eval{e_2}{v_2}
   \qquad\eval{[v_2/x]e_1'} {v}}{\eval{e_1\ \at \
     e_2}{v}}{\mathbf{ev\_app}}\vsk  
 \ianc{}{ \eval{\Lx  e}{\Lx  e} }{\mathbf{ev\_fun}} \qquad
\ianc{\eval{[\rec{e}/x]e}{v}}{\eval{\rec{e}}{v}}{\mathbf{ev\_fix}}\vsk
\dotfill\vsk
\ianc{\Gamma, x\oftp \tau \vd e \hastype \tau'}{\gvd \Lx e \hastype \tau \fsp
\tau'}{\mathbf{tp\_fun}} \qquad
 \ianc{\Gamma, x\oftp \tau \vd e \hastype \tau}{\gvd \rec{e} \hastype
   \tau }{\mathbf{tp\_fix}}\vsk 
 \ianc{\Gamma(x) = \tau}{\gvd x \hastype \tau}{\mathbf{tp\_var}}  \qquad
 \ibnc{\gvd e_1 \hastype \tau' \arrow \tau}{\gvd e_2 \hastype
   \tau'}{\gvd e_1\ \at \  e_2 \hastype \tau} 
{\mathbf{tp\_app}}
\end{array}\eval{e}{v}\Gamma \vd e \hastype
\tau\beta\exists t.\ \eval {\llrec{\llFun y
    {\llApp x y }}}{ t}\foldna\mathtt{(p\ \vec t)}\_\_\_\eval {\llFun x E}{V}
\llambda {E} = \llambda {F}\lambda\eval E F \Implies  \forall G.\ \eval E G \limp  F = G\eval E F\eval E Gev\eval e v\eeval {\encode \emptyset e} {\encode
    \emptyset v}\eval e v\isterm
  \emptyset {\encode{\emptyset}{\lFun x e}}\isterm \emptyset {(\llFun x
    {\encode{x}{e}} )}\abstr (\lambda x.\ \encode{x}{e})\eeval {\llFun x {\encode{x}{e}}}{\llFun x
    {\encode{x}{e}}}\eeval
  {\encode{\emptyset} {\lFun x e}} {\encode{\emptyset} {\lFun x
      e}}\eeval E V\decode\emptyset E\decode\emptyset Vev\eval{e}{v}\isterm\emptyset{E}\isterm\emptyset{V}\decode\emptyset E\decode\emptyset V\eval{e}{v}\eeval E V\alpha\lambda\beta\alphabooltype\mathbf{tp\_app}\mathbf{tp\_fun}\mathbf{tp\_fix}x\hastype\tau\Gammax\hastype T\mathbf{tp\_var}\lambda\tauA\tau\expr\conE\expr\fs\expr\llFun{x}{E\ x}\expr\atm\slAt{ \_ }\atmn\geq 0i=1,\ldots,n\sigma_i\tau_1\arrow\tau_2\tau_1\tau_2A \If
G\forall\Sigma(A \If G)\Sigma=\{x_1,\ldots,x_n\iseqp{\Sigma;\G}{G}\Sigma\Pi\Gamma\ir{bc}[\Pi]\Pi\begin{array}{l}
 \ian{}{\iseqp{\Sigma;(\G,A)}{A}}{\ir{init}} 
\qquad\qquad\qquad
 \ian{\iseqp{\Sigma;(\G, A)}{G}}
     {\iseqp{\Sigma;\G}{A\Imp G}}
     {\Imp_R} \1em]
  \ian{}{\iseqp{\Sigma;\G}{\top}}{\top_R}
\qquad\qquad\qquad
  \ian{\iseqp{(\Sigma, a : \tau);\G}{G[a/x]}}{\iseqp{\Sigma;\G}{\forall^\tau x  \ldot G}} {\forall_R} \
  \caption{A minimal sequent calculus with backchaining}
  \label{fig:minlogbc}
\end{figure}


This inference system is equivalent to the standard presentation of
minimal logic \cite{JoMinLog}, where the right rules are the same and
the left rules (given below) for conjunction, implication and universal
quantification replace the \textbf{bc} rule.

1em]
\ibn{\Sigma;\iseqp{\G}{G}}{\Sigma;\iseqp {\G,B}{A}}
       {\Sigma;\iseqp{\G, (G \Imp B)}{A}}
       {\ir{\Imp_L}}
\end{array}\ir{\Imp_L}=_{\alpha\beta\eta}\ir{init}\ir{bc}\Pi\slvd{}{}(\Forall
  n.\ \forall m<n.\ P~m\Implies P~n) \Implies P~x\slvd{\Gamma}{G}n\slvdn{\Gamma}{n}{G}\slvde{G}\slvd{\emptyset}{G}R\forall_R\expr\ikw{proper}(\abstr{E})E ::\expr\fs\expr\ikw{proper}\expr\propert\ikw{proper}\propert\fsprems{\atm, \oo}\fs \bool\sbc{A}{G}\slvdn{\Gamma}{n}{G}\mathtt{demo}\mathtt{prog}\mathtt{clause}\mathtt{mk\_cases}\mathtt{mk\_cases}
"\slvdn{}{j}{\slAt{A}}"\expr\expr\fs\expr\decode{\Sigma}{\ilam{x}{E\ x}} = \ilam{x}{\decode{\Sigma,x}{E\ x}}\SigmaG\oo\Sigma\decode{\Sigma}{G}\Gamma\atm\
\mathit{set}\decode{\Sigma}{\Gamma}\SigmaE_1,\ldots,E_n\expr\fs\exprn\geq 0\forall
\Sigma(\decode{\Sigma}{G}\to\decode{\Sigma}{A})E ::\expr\fs\expr(\abstr{E})E ::\expr\fs\expr(\abstr{E})\PiG\oo\Gamma\Sigma\expr\GammaG\proper\Sigma\Implies\slvd {\Gamma}{G}\iseqp{\Sigma;\decode{\Sigma}{\Gamma}}{\decode{\Sigma}{G}}\proper\Sigma\Implies\slvd {\Gamma}{G}\slvd {\Gamma}{G}\iseqp{\Sigma;\decode{\Sigma}{\Gamma}}{\decode{\Sigma}{G}}\ir{bc} \prems{\slvdn{\Gamma}{n}{G};\; n < m}
  \Implies \slvdn{\Gamma}{m}{G} \land_R \prems{\slvdn{\Gamma}{n}{G};\; \Gamma\subseteq
    \Gamma'} \Implies \slvdn{\Gamma'}{n}{G}  \prems{\slvd{A,\Gamma}{G};\;
    \slvd{\Gamma}{\slAt{A}}} \Implies \slvd{\Gamma}{G}\slvdn{A,\Gamma}{i}{G}\eval{e}{v}\Gamma \vd e \hastype \tau\eval{e}{v}\vd e\hastype\tau\vd
v\hastype\tau\con\atm\atm \_ \If \_\Gamma \{x_1: \uexp,\dots,x_n:uexp\}\overline{\Gamma}\{\istermtwo{x_1},\ldots,\istermtwo{x_n}\}\Gamma\vdash e\proper \Gamma \Implies
\slvd{\overline{\Gamma}}{\slAt{\istermtwo{E}}}\decode\Gamma Et\Gamma\vdash t\encode\Gamma{\decode \Gamma E} =
E\decode\Gamma{\encode \Gamma t} = t\exists T.\slvde{\slAt{\llFun{x}{\llFun{y}{x\ \oat\ y}}\hastype T}}\exists T.\exists
  n.\slvdn{\emptyset}{n}{\slAt{\llFun{x}{\llFun{y}{x\ \oat\
          y}}\hastype T}}Tn\mathbf{tp\_fun}\mathbf{tp\_fun}(\abstr{\lambda x.\llFun{y}{x\ \oat\ y}})(\abstr{\lambda y.x\ \oat\ y})(\proper{x})\mathbf{tp\_app}\with_R\ir{init}\mathtt{fast\_tac}\lambdanIHIH[i+1/n]IHni+1\ikw{fun}\ikw{\oat}\ikw{fix}E_1E_2\ikw{fun}\mathsf{all}\_E=E'_1\mathbf{fix}(\proper{V_2})\slvde{\slAt{(E\ V_2)\hastype T}}\slvdn{}{i}{\slAt{\eval{(E\ V_2)}{V}}}\eval{E}{V}\slvdn{}{n}{\slAt{\eval{E}{V}}}\mathtt{demo}IH_1IH_2IH_3IH\llambda{E}=\llambda{F}EF\begin{array}{c}
 \ian{}{\seq{\G}{A}{A}}{\ir{init}_{\O}}
 \qquad\qquad
 \ian{}{\seq{\G, A }{\cdot}{A}}{\ir{init}_\G}
 \1em]
 \ibn{\seq{\G}{\O}{G_1}}{\seq{\G}{\O}{G_2}} 
    {\seq{\G}{\O}{G_1\with G_2}}{\with_R}\1em] 
\ian{
  \begin{array}{l}
(\sbc{A}{[G_1,\ldots,G_m]}{  [G'_1,\ldots,G'_n]}) \in [\Pi]\\
 \seq{\G}{\cdot}{G_1} \:\ldots\: \seq{\G}{\cdot}{G_m}\\
  {\seq{\G}{{\O}_1}{G'_1} \:\ldots\: \seq{\G}{{\O}_n}{G'_n}}
  \end{array}}
      {\seq{\G}{{\O}_n\ldots{\O}_1}{A}}
      {\ir{bc}}
\end{array}\roimp\forall(\sbc{A}{[G_1,\ldots,G_m]}{
  [G'_1,\ldots,G'_n]})\forall(G_m\to\ldots\to G_1 \to
G'_n \roimp\ldots\roimp G'_1 \roimp A){\Pi}\G{\O}G\roimp_RA\O(A,\G)\top_R\ir{init}_\O\O\ir{init}_\G(\ir{bc})\sbc{A}{[G_1 \ldots G_m]}{[G'_1
  \ldots G'_n]}\Pi\roimp{\O}_i\GG\G\OnGs\GGs\G\O\forall_R\sbc{A}{O_L}{I_L}\fsprems{\atm,
  \ilist{\oo}, \ilist{\oo}}\fs \bool\Omega\Omega_G\Omega_R\mathit{append}(\O_R,\O_G,\O)\mathit{append}(-,-,+)\slvd{\Gamma\coln\Omega}{G}n\slvdn{\Gamma\coln\Omega}{n}{G}\slvde{G}\slvd{\elist\coln\elist}{G} \prems{\slvdn{\Gamma\coln\Omega}{n}{G};\; n < m} \Implies
    \slvdn{\Gamma\coln\Omega}{m}{G} \prems{\oslvdn{\Gamma}{\Omega}{n}{Gs};\; n < m} \Implies
    \oslvdn{\Gamma}{\Omega}{m}{Gs}\prems{\islvdn{\Gamma}{n}{Gs};\; n < m} \Implies
    \islvdn{\Gamma}{m}{Gs}(set\ \Gamma)\G \prems{\slvd{\Gamma\coln\Omega}{G};\; set\
       \Gamma\subseteq set\ \Gamma'} \Implies
     \slvd{\Gamma'\coln\Omega}{G}  \prems{\oslvd{\Gamma}{\Omega}{Gs};\; set\
       \Gamma\subseteq set\ \Gamma' } \Implies \oslvd{\Gamma'}{
       \Omega}{Gs}  \prems{\islvd{\Gamma}{Gs};\; set\
       \Gamma\subseteq set\ \Gamma'}
     \Implies \islvd{\Gamma'}{Gs}  \prems{\slvdn{\Gamma\coln\Omega} i {G} ;\; set\ \Gamma
         = set\ (A, \Gamma');\; \slvdn{\Gamma'\coln\elist} j {\slAt A}}
       \Implies \slvdn {\Gamma'\coln\Omega} {i + j} G  \prems{\oslvdn{\Gamma}{\Omega} i {Gs} ;\; set\ \Gamma
         = set\ (A, \Gamma');\; \slvdn{\Gamma'\coln\elist} j {\slAt A}}
       \Implies \oslvdn {\Gamma'}{\Omega} {i + j} Gs  \prems{\islvdn{\Gamma} i {Gs} ;\; set\ \Gamma
         = set\ (A, \Gamma');\; \slvdn{\Gamma'\coln\elist} j {\slAt A}}
       \Implies \islvdn {\Gamma'} {i + j} Gs s\hra s's'K K;\ilam{x}{i}\begin{array}{rl}
\ir{st\_init} \;\;::\;\; & \ir{init}\:\diamond\:\ir{return}\,v \;\hra\;\ir{answer}\,v
\1em]
\ir{st\_fun} \;\;::\;\; & K\:\diamond\:\ir{ev}\,(\ir{fun}\,x\ldot e) \;\hra\; 
K\:\diamond\: \ir{return}\,(\ir{fun}\, x\ldot e)
\1em]
\ir{st\_app} \;\;::\;\; & K\:\diamond\:\ir{ev}\,(e_1\ \at\ e_2) \;\hra\; 
K;\ilam{x_1}{\ir{app}_1\,x_1\,e_2} \:\diamond\: \ir{ev}\,e_1
\1em]
\end{array}
 \begin{array}{c}
      \ianc{}{s \hra^* s}{\ir {stop}}\qquad\qquad
      \ibnc{s_1 \hra s_2}{s_2 \hra^* s_3}{s_1 \hra^* s_3}{\ir {step}}\
  \caption{Top level transition rules}
  \label{fig:cev}
\end{figure}

The formulation of the subject reduction property of this machine
follows the statement in~\cite{CervesatoP02}, although we consider
sequences of transitions by taking the reflexive-transitive closure
 of the small-step relation, and a top level initialization
rule \textbf{cev} (Figure~\ref{fig:cev}).  Of course, we need to add
typing judgments for the new syntactic categories, namely
instructions, continuations and states. These can be found in
Figure~\ref{fig:tp}, whereas we refer the reader to
Figure~\ref{fig:dyn-st} as far as typing of expressions goes.



\begin{thm}    and  and  implies
  .
\end{thm}
\begin{proof}
  By induction on the length of the execution path using inversion
  properties of the typing judgments.
\qed\end{proof}
\begin{cor}[Subject Reduction]
   and  entails .
\end{cor}

As a matter of fact we could have obtained the same result by showing
the \emph{soundness} of the operational semantics of the continuation
machine \wrt big step evaluation, \viz that  entails  (see Theorem 6.25 in \cite{Pfenning01book}) and then appealing to
type preservation of the latter. That would be another interesting
case study: the equivalence of the two operational semantics
(thoroughly investigated by Pfenning in Chapter 6 \opcit but in the
intuitionistic setting of LF), to gauge what the ``Olli'' approach
would buy us.


\begin{figure}[b]
1em]
  \hspace*{-6em}
 \ibn{\G\vd_e e_1\hastype \tau'\Imp\tau}
      {\G\vd_e e_2\hastype\tau'}
      {\G \vd _i\ir{app}_1\,e_1\,e_2 \hastype \tau }
      {ofI\_\ir{app}_1} 
\mbox{}\1em]
\prooftree
\mbox{}\justifies {\vd_K\ir{init} \hastype \tau\Imp\tau}
\using{ofK\_\ir{init}}\endprooftree
 \qquad\qquad
\qquad
\prooftree
{x\oftp\tau_1\vd_i i\hastype \tau}\qquad
    {\vd_K K\hastype\tau\Imp\tau_2}
\justifies
    {\vd_K K;\ilam{x}{i} \hastype \tau_1\Imp\tau_2 }
\using    {ofK\_\ir{cont}}
\endprooftree    \1em]
\ibnc{\vd_i i \hastype \tau_1} {\vd_K K \hastype \tau_1\ \fsp \ \tau_2}{\vd_s K\:\diamond\: i \hastype  \tau_2}{ofs\_\diamond}
 \qquad\qquad
\ianc{\vd_e v\hastype \tau }{\vd_s \ir{answer}\, v\hastype
  \tau}{ofs\_\ir{answer}}
\end{array}K\leadsto\rep{K}K\rep{i}\encode \cdot \cdot\rep \cdot3.4\init{}\Val\fs\atmK\cont K(\Val\fs\instr)\fs\atm\ceval{\rep e}{\rep v}\init{\rep v} \roimp \exec{(\EV {\rep e)}}\rep e\rep ve\exec{(\ret {\rep v})} v\exec{(\appone{\rep
    {v_1}}{\rep {e_2}})}\leadstoW\leadsto\exec{(\ret{\rep{v}})}\exists V.\ \slvde{\slAt{\ceval{(\llFun{x}{x})} \ V}} ?V Og{ Or} Og_1\exists A.\ \osplit {[A]}{[A]}{\elist}2\mathbf{init}_\Omega?V\llFun{x}{x}s_is_{i+1}\rep{s_i}s_i\rep
{s_{i+1}}
K\:\diamond\: i \;\hra\;s's'\slvd {\elist\coln\rep K}{\slAt{\rep i}}\rep K\mathbf{init}_\Omega\slvd{\elist\coln(\init V, \O)}{\slAt{\exec I}}\oslvd{\elist}{\init V,  \O}{[\slAt{\exec (K\ V')},\slAt{\cont K}]}\Forall L.\ \bprems\osplit \O{L} {[\cont K]} ;\,\,  
Og = (\init{V},  L) \eprems \Implies P\cont K = \init V\O{L}[\cont K](L,\cont K)\slAll v {\ofV
  v {T_1}} \ \mathsf{imp}\ \slAt{\ofI{(K' \ v)}{T}}{v}V' \oslvd{\elist}{(\init V, L, \cont
  K)}{[\slAt{\ofK {T\arrow T_2}},\slAt{\cont K'}]} \osplit {(\init V, L,\cont K)}{Og}{[\cont K']}{(\init V, L) = Og}{K = K'}i    \prems{\slvde{\ceval{E}{V}} ;\;\slvde{\of{E}{T}}} \Implies
    \slvde{\of{V}{T}}\foldn\foldn\foldn\lambda\foldn\foldn\nabla\nabla\cal G\nabla\nabla\pi\cal G^\Omega\cal G\Momega\Momega\mathrm{ATS^{LF}}\lambdaA\Box AAA\fs BA \to B \equiv \Box A \fs B\ikw{fun}(\underline{\var} \fs uexp)\fs uexp\var\var\var\nablaxxx\alpha\piexprexpr'expr'expr(\Con{cAPP} \app E_1 \app E_2)(\Con{cABS} \app \LAM{x}{E\ x})(\Con{cFIX} \app \LAM{x}{E\ x})\lapp\ikw{fun}\ikw{fix}exprexpr'(e_1 \overline{\lapp} e_2)\lappe_1e_2e_1e_2(\ikw{lbind}~e)e0e\expr\fs\expr1(\Var{x})(e(\Bnd{0}))(\Bnd{0})e(\Var{n})(e(\Var{n}))(\Bnd{0})eexpr'\to expr'expr'expr't\ikw{f}expr'\to t\lapp\ikw{fun}\ikw{f}\mathsf{Happ}\mathsf{Hfun}\ikw{f}\mathsf{Happ}\mathsf{Hfun}expr\ikw{fun}0(\ikw{lbind}~(\lambda x.\ f\,x))x0.20.2\propert\propert\expr(\propert\fs\oo)\fs\oo\ikw{LAM}ef\ikw{VAR}\alpha\foldna0.2\pi\lambda\lambda\alpha\alpha\alpha\lambda\mu\pi\mu\bigtriangledown\lambda$-calculus
  using one-sorted variable names.
\newblock {\em Inf. Comput.}, 183(2):212--244, 2003.

\bibitem{WashburnWeirichJFP08}
Geoffrey Washburn and Stephanie Weirich.
\newblock Boxes go bananas: Encoding higher-order abstract syntax with
  parametric polymorphism.
\newblock {\em Journal of Functional Programming}, 18(1):87--140, January 2008.

\bibitem{clf}
Kevin Watkins, Iliano Cervesato, Frank Pfenning, and David Walker.
\newblock A concurrent logical framework: The propositional fragment.
\newblock In Berardi et~al. \cite{DBLP:conf/types/2003}, pages 355--377.

\end{thebibliography}


\end{document}
