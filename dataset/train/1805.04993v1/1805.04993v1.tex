

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2018}
\usepackage{times}
\usepackage{latexsym}
\usepackage{booktabs}
\usepackage{lscape}
\usepackage{url}
\usepackage{xspace}
\usepackage[colorinlistoftodos,prependcaption,textsize=small]{todonotes}
\newcommand{\AL}[1]{\todo[linecolor=green,backgroundcolor=green!25,bordercolor=green]{#1}}
\newcommand{\JRT}[1]{\todo[linecolor=black,backgroundcolor=orange!25,bordercolor=black]{#1}}
\usepackage{array,multirow,graphicx}
\newcommand \egrid{\textsc{EGrid}\xspace}
\newcommand \egraph{\textsc{EGraph}\xspace}
\newcommand \lexgraph{\textsc{LexGraph}\xspace}
\newcommand \parseq{\textsc{ParSeq}\xspace}
\newcommand \sentseq{\textsc{SentSeq}\xspace}
\newcommand \clique{\textsc{Clique}\xspace}
\newcommand \sentavg{\textsc{SentAvg}\xspace}
\newcommand \egridconv{\textsc{EGridConv}\xspace}
\newcommand \dataset{\textsc{GCDC}\xspace}

\aclfinalcopy \def\aclpaperid{1077} 



\newcommand\BibTeX{B{\sc ib}\TeX}

\title{Discourse Coherence in the Wild: A Dataset, Evaluation and Methods}

\author{Alice Lai\\
University of Illinois at Urbana-Champaign\thanks{\ \ Research performed while at Grammarly.}\\
 {\tt aylai2@illinois.edu} \\\And
Joel Tetreault \\
  Grammarly  \\
{\tt joel.tetreault@grammarly.com} \\}

\date{}

\begin{document}
\maketitle

\begin{abstract}
To date there has been very little work on assessing discourse coherence methods on real-world data.  To address this, we present a new corpus of real-world texts (\dataset) as well as the first large-scale evaluation of leading discourse coherence algorithms. We show that neural models, including two that we introduce here (\sentavg and \parseq), tend to perform best.  
We analyze these performance differences and discuss patterns we observed in low coherence texts in four domains.


\end{abstract}


\section{Introduction}

Discourse coherence is an important aspect of text quality. It encompasses how  sentences are connected as well as how the entire document is organized to convey information to the reader.
Developing discourse coherence models to distinguish coherent writing from incoherent writing is useful to a range of applications.  An automated coherence scoring model could provide writing feedback, e.g. identifying a missing transition between topics or highlighting a poorly organized paragraph.  Such a model could also improve the quality of natural language generation systems.

One approach to modeling coherence is to model the distribution of entities over sentences. The entity grid \cite{barzilay-lapata:2005:ACL}, based on Centering Theory \cite{Grosz:1995}, was the first of these models. Extensions to the entity grid include additional features \cite{elsner-charniak:2008:ACLShort,elsner-charniak:2011:ACL,feng-lin-hirst:2014:Coling}, a graph representation \cite{guinaudeau-strube:2013:ACL2013,mesgar-strube:2015:*SEM2015}, and neural convolutions \cite{nguyen-joty:2017:ACL}. 
Other approaches have used lexical cohesion \cite{Morris:1991,somasundaran-burstein-chodorow:2014:Coling}, discourse relations \cite{lin-ng-kan:2011:ACL-HLT2011,feng-lin-hirst:2014:Coling}, and syntactic features \cite{louis-nenkova:2012:EMNLP-CoNLL}. Neural networks have also been successfully applied to coherence \cite{li-hovy:2014:EMNLP,nguyen-joty:2017:ACL,li-jurafsky:2017:EMNLP}.
However, until now, these approaches have not been benchmarked on a common dataset.

Past work has focused on the discourse coherence of well-formed texts in domains like newswire \cite{barzilay-lapata:2005:ACL,elsner-charniak:2008:ACLShort} via tasks like sentence ordering that use artificially constructed data. It was unknown how well the best methods would fare on {\em real-world data} that most people generate.






In this work, we seek to address the above deficiencies via four main contributions.  First, we present a new corpus, the Grammarly Corpus of Discourse Coherence (\dataset), for real-world discourse coherence. The corpus contains texts the average person might write, e.g. emails and online reviews, each with a coherence rating from expert annotators (see examples in Table~\ref{tab:examples} and supplementary material). Second, we introduce two simple yet effective neural network models to score coherence.  Third, we perform the first large-scale benchmarking of 7 leading coherence algorithms.  We show that prior models, which performed at a very high level on well-formed and artificially generated data, have markedly lower performance in these new domains.  
Finally, the data, annotation guidelines, and code have all been made public.\footnote{\url{https://github.com/aylai/GCDC-corpus}}

 











\begin{table*}[htb]
\begin{center}
\begin{footnotesize}
\begin{tabular}{@{}l@{\hspace{1em}}p{14.8cm}@{}}
\toprule
Score & Text \\
\midrule
Low & Should I be flattered? Even a little bit? And, as for my alibi, well, let's just say it depends on the snow and the secret service. So, subject to cross for sure. Do you think there could be copycats? Do you think the guy chose that mask or just picked up the nearest one? Please keep me informed as the case unfolds--
\newline
On another matter, can you believe Dan Burton will be the chair of one of the House subcommittees we'll have to deal w? Irony and satire are the only sane responses.
\newline\
Happy New Year--and here's hoping for many more stories that make us laugh!\\
High & Cheryl,
\newline
I just spoke with Vidal Jorgensen. They expect to be on the ground in about 8 months. They have not yet raised enough money to get the project started -- the total needed is \2M to get started. Vidal said they process has been delayed because their work in Colombia and China is consuming all their resources at the moment. Once on the ground, they will target the poorest of the poor and go to the toughest areas of Haiti. They anticipate an average loan size of \\leq 1.8 <\leq 2.2 <\kappa\pm\pm\pm\pm\pm\pm\pm\pm\pm\pm\pm\pm\pm\pm\pm\pm\kappakkkAB\dagp < 0.05p^{\dag}^{\dag}^{\dag}^{\dag}+\rho-0.008^{\dag}^{\dag}^{\dag}^{\dag}^{\dag}^{\dag}^{\dag}^{\dag}^{\dag}F_{0.5}F_{0.5}$4pt]

You should assign a coherence rating to the text based on whether it is a coherent example of text \textit{in that domain}. A reader has different expectations about how a business email should be written compared to a post on an online forum, and the coherence rating should reflect this difference. A business email with a score of 1 is not necessarily incoherent in the same way that a very incoherent Yahoo Answers post is, but it is not very coherent \textit{for a business email}. 
\end{tabular}
\end{small}
\caption{The annotation instructions we provided to expert annotators.}
\label{tab:expert_instructions}
\end{table*}

\subsection{Model Details}

\begin{figure}[h]
    \centering
    \includegraphics[width=.45\textwidth]{diagram2}
\caption{Structure of \parseq model. The sentence vectors are the output from the first LSTM (not pictured), which takes GloVe word embeddings as input.}
    \label{fig:model_diagram}
\end{figure}

Figure~\ref{fig:model_diagram} shows the structure of \parseq. The sentence vectors pictured are the output at the final timestep from the first LSTM (not pictured), which takes GloVe word embeddings as input. A second LSTM takes these sentence vectors as input and produces paragraph vectors, and a third LSTM takes a sequence of paragraph vectors and produces a single document vector.


\begin{table}
\begin{center}
 \begin{small}
\begin{tabular}{lrrrr}
	\toprule
    & \multicolumn{4}{c}{Accuracy} \\
	System & Yahoo & Clinton & Enron & Yelp \\	
	\midrule
    Majority class & 39.5 & 40.5 & 44.0 & 40.5 \\
    Baseline & 35.0 & 43.5 & 45.0 & 41.5 \\ 
    \midrule
	\egrid & 43.0 & 41.0 & 45.5 & 43.0 \\
    \egraph & 39.5 & 41.5 & 44.5 & 40.5 \\
	\egridconv & 41.0 & 43.5 & 44.5 & 54.0 \\
    \lexgraph & 38.0 & 36.0 & 48.0 & 45.5 \\
    \clique & 48.0 & 45.0 & 52.5 & 51.0 \\
    \sentavg & \textbf{52.0} & 48.5 & 55.5 & 49.0 \\	
    \parseq & 47.5 & \textbf{51.0} & \textbf{56.5} & \textbf{57.5} \\
	\bottomrule
\end{tabular}
 \end{small}
\caption{Three-way classification results on test data. Untrained rater judgments.}
\label{tab:3class_test_mturk}
\end{center}
\end{table}

\subsection{Additional Results}

Table~\ref{tab:3class_test_mturk} contains the classification test results of all systems when the consensus labels come from the Mechanical Turk judgments rather than the expert judgments. 

\begin{table}
\begin{center}
\begin{footnotesize}
\begin{tabular}{@{}lrrrrrrrr@{}}
	\toprule
System & \multicolumn{2}{c}{Yahoo} & \multicolumn{2}{c}{Clinton} & \multicolumn{2}{c}{Enron}  & \multicolumn{2}{c}{Yelp} \\	
    & p & r & p & r & p & r & p & r \\
    \midrule
    Baseline & 25 & 61 & 26 & 24 & 33 & 38 & 17 & 42  \\ 
    \midrule
    \egrid & 31 & 16 & 36 & 12 & 57 & 10 & 33 & 5 \\
    \egraph & 26 & 94 & 35 & 58 & 25 & 45 & 10 & 68  \\
	\egridconv & 31 & 41 & 16 & 24 & 22 & 40 & 50 & 05 \\ 
    \midrule
    \lexgraph & 26 & 29 & 20 & 3 & 55 & 15 & 0 & 0  \\ 
    \midrule
    \clique & 7 & 3 & 0 & 0 & 17 & 3 & 100 & 05 \\
    \sentavg & 38 & 73 & 39 & 36 & 42 & 33 & 36 & 21 \\	
    \parseq & 43 & 51 & 21 & 39 & 57 & 20 & 13 & 11  \\	
	\bottomrule
\end{tabular}
\end{footnotesize}
\caption{Minority class predictions, precision/recall results on test data.}
\label{tab:minority_test}
\end{center}
\end{table}

Table~\ref{tab:minority_test} contains the precision and recall results for the minority class classification test. For neural models, we report precision and recall for one run on test (F0.5 scores in Section 4.4 were averaged over 10 runs).

\begin{table}
\begin{center}
 \begin{small}
\begin{tabular}{lr}
	\toprule
System & Accuracy \\	
	\midrule
    Random baseline & 50.0 \\
    \midrule
	\egrid & 83.0 \\
    \egraph & 65.7 \\
    \egridconv & 82.2\\
    \lexgraph & 72.7 \\
    \clique & 60.9 \\
    \sentseq & 74.1 \\
	\bottomrule
\end{tabular}
\end{small}
\caption{Sentence ordering results on WSJ test data.}
\label{tab:wsj_perm_test}
\end{center}
\end{table}

To compare all models on an established dataset, we report results on the sentence ordering task using the Wall Street Journal (WSJ) portion of the Penn Treebank. Following previous work, we use 20 random permutations of each article and the train/test split defined by Tien Nguyen and Joty (2017) (train = Section 00-13, test = 14-24). Table~\ref{tab:wsj_perm_test} contains the results of all models on WSJ. These results verify our re-implementation of the \egrid model, as well as establishing the reasonable performance of our neural sequence model on news text.





\subsection{Model Parameters}

We specify the parameters for all models and experiments in Tables \ref{tab:param_vals1} and \ref{tab:param_vals2}. Additionally, for the combined training data experiment (Table 10 in the paper), we train parseq with LSTM dimensionality = 100, hidden layer = 200, dropout = 0.5. 

\paragraph{\egrid} \textit{Sequence length} is the length of the transition sequences used to compute the feature vector from the entity grid. For salience, we follow Barzilay and Lapata (2008) and split entities into two salience classes (doubling the number of features) based on whether their frequency is greater than the \textit{salience threshold}. (Salience = off means that there is only one salience class containing all entities.) \textit{Syntax} indicates whether we consider grammatical roles (subject, object, other) in building the entity grid.

\paragraph{\egraph} The \textit{graph type} specifies whether we use an unweighted graph (u), a graph weighted by the number of entities shared between sentences (w), or a graph weighted by syntactic role information (syn). \textit{Distance} indicates whether edge weights are decreased according to the distance between sentences. 

\paragraph{\egridconv} We specify dropout rate, batch size, and entity role embedding size. For the convolution layer, we specify filter number, window size, and pooling length.

\paragraph{\lexgraph} We define the similarity \textit{threshold} used to filter out edge weights between sentences, and \textit{k} as the size of the subgraphs we consider when extracting features from the document graph.

\paragraph{\clique} We define the dropout rate, the LSTM dimensionality, and the hidden layer dimensionality. \textit{Window size} is the number of sentences in a clique.

\paragraph{\sentavg, \parseq} For both models, we specify the dropout rate, the LSTM dimensionality, and the hidden layer dimensionality. For \parseq, the LSTM dimensionality applies to all 3 LSTMs.


\begin{table*}
\begin{center}
\begin{footnotesize}
\begin{tabular}{llrrrrrrrr}
\toprule
 & & \multicolumn{4}{c}{\textbf{Classification}} & \multicolumn{4}{c}{\textbf{Score Prediction}} \\
Model & Parameter & Yahoo & Clinton & Enron & Yelp & Yahoo & Clinton & Enron & Yelp \\
\midrule
Baseline & threshold1 & 6.5 & 6.5 & 6.0 & 2.5 & -- & -- & -- & --  \\
			& threshold2 & 7.0 & 7.0 & 6.5 & 3.0 & -- & -- & -- & -- \\
\midrule
\egrid	& sequence length & 4 & 3 & 4 & 2 & 2 & 2 & 4 & 3 \\
		& salience threshold & off & 2 & 4 & 4 & 2 & off & 3 & 2 \\
        & syntax & on & off & on & on & off & off & on & on \\
        \midrule
\egraph 	& graph type & syn & syn & syn & syn & u & w & w & syn \\
		& distance & no & no & no & no & yes & yes & yes & no \\
        & threshold1 & 15.0 & 0.1 & 0.1 & 0.5 & -- & -- & -- & -- \\
        & threshold2 & 16.0 & 1.1 & 1.1 & 1.6 & -- & -- & -- & -- \\
        \midrule
\egridconv 	& dropout & 0.2 & 0.2 & 0.5 & 0.2  & 0.2 & 0.5 & 0.5 & 0.2 \\
			& filter & 100 & 100 & 100 & 200 & 200 & 200 & 200 & 100 \\
            & window & 4 & 2 & 2 & 6 & 2 & 2 & 2 & 4  \\
            & pool & 3 & 7 & 3 & 5 & 5 & 3 & 3 & 3 \\
            & batch & 128 & 128 & 32 & 128 & 32 & 32 & 32 & 32 \\
            & embedding size & 100 & 100 & 100 & 200 & 100 & 200 & 200 & 100 \\
            \midrule
\lexgraph	& threshold & 0.7 & 0.5 & 0.7 & 0.9 & 0.5 & 0.3 & 0.7 & 0.9  \\
	& k & 6 & 6 & 6 & 5 & 6 & 6 & 4 & 5 \\
    \midrule
\clique	& dropout & 0.5 & 0.5 & 0.5 & 0.5 & 0.5 & 0.5 & 0.5 & 0.5 \\
		& LSTM dim & 100 & 100 & 200 & 100 & 100 & 100 & 200 & 100 \\
        & hidden dim & 200 & 200 & 200 & 200 & 200 & 200 & 200 & 100  \\
        & window size & 3 & 3 & 3 & 7 & 7 & 7 & 7 & 4 \\
\midrule
\sentavg 	& dropout & 0.5 & 0.5 & 0.5 & 0.2 & 0.2 & 0.5 & 0.5 & 0.2  \\
			& LSTM dim & 200 & 50 & 200 & 50 & 300 & 300 & 300 & 300 \\
           	& hidden dim & 200 & 50 & 100 & 300 & 100 & 100 & 50 & 50 \\
            \midrule
\parseq	& dropout & 0.5 & 0.5 & 0.5 & 0.5 & 0.5 & 0.2 & 0.5 & 0.2 \\
		& LSTM dim & 200 & 300 & 50 & 50 & 300 & 200 & 100 & 300  \\
        & hidden dim & 100 & 100 & 100 & 200 & 100 & 50 & 100 & 100 \\
\bottomrule
\end{tabular}
\end{footnotesize}
\caption{Best parameter values for classification and score prediction experiments.}
\label{tab:param_vals1}
\end{center}
\end{table*} 

\begin{table*}[htb]
\begin{center}
\begin{footnotesize}
\begin{tabular}{llrrrrrrrrr}
\toprule
 & & \multicolumn{5}{c}{\textbf{Sentence Ordering}} & \multicolumn{4}{c}{\textbf{Minority Class}} \\
Model & Parameter & Yahoo & Clinton & Enron & Yelp & WSJ & Yahoo & Clinton & Enron & Yelp \\
\midrule
Baseline & threshold1  & -- & -- & -- & -- & -- & 8.0 & 6.5 & 6.0 & 5.0 \\
			& threshold2 & -- & -- & -- & -- & -- & -- & -- & -- & -- \\
\midrule
\egrid	& sequence length &  4 & 4 & 4 & 4 & 3 & 2 & 2 & 2 & 3 \\
		& salience threshold & 4 & off & 4 & off & 4 & off & off & 2 & 2 \\
        & syntax & on & on & off & on & on & off & off & on & off \\
        \midrule
\egraph 	& graph type &  syn & w & w & w & w & u & w & w & w \\
		& distance & yes & yes & yes & yes & yes & yes & yes & yes & no \\
        & threshold1 & -- & -- & -- & -- & -- & 1.2 & 0.5 & 0.9 & 2.2 \\
        & threshold2 & -- & -- & -- & -- & -- & -- & -- & -- & --\\
        \midrule
\egridconv 	& dropout & 0.2 & 0.2 & 0.2 & 0.2 & 0.5 & 0.2 & 0.5 & 0.5 & 0.5 \\
			& filter & 100 & 100 & 100 & 100 & 150 & 100 & 200 & 200 & 200 \\
            & window & 6 & 6 & 4 & 6 & 6 & 2 & 4 & 6 & 6 \\
            & pool & 7 & 7 & 7 & 7 & 6 & 3 & 3 & 5 & 7 \\
            & batch & 32 & 32 & 32 & 128 & 128 & 128 & 32 & 32 & 32 \\
            & embedding size & 200 & 100 & 200 & 100 & 100 & 100 & 200 & 100 & 200 \\
            \midrule
\lexgraph	& threshold & 0.9 & 0.9 & 0.9 & 0.9 & 0.3 & 0.5 & 0.7 & 0.5 & 0.9 \\
	& k &  4 & 3 & 4 & 4 & 4 & 4 & 3 & 3 & 3 \\
    \midrule
\clique	& dropout & 0.5 & 0.2 & 0.2 & 0.2 & 0.2 & 0.2 & 0.2 & 0.5 & 0.2 \\
		& LSTM dim & 100 & 100 & 100 & 300 & 300 & 50 & 50 & 50 & 50 \\
        & hidden dim & 100 & 100 & 50 & 50 & 50 & 50 & 300 & 50 & 200 \\
        & window size &  7 & 5 & 5 & 5 & 7 & 5 & 7 & 5 & 7 \\
\midrule
\sentavg 	& dropout & -- & -- & -- & -- & -- & 0.2 & 0.5 & 0.2 & 0.2 \\
			& LSTM dim & -- & -- & -- & -- & -- & 200 & 200 & 50 & 200 \\
           	& hidden dim & -- & -- & -- & -- & -- & 300 & 200 & 50 & 50 \\
            \midrule
\parseq	& dropout & 0.5 & 0.2 & 0.2 & 0.2 & 0.5 & 0.5 & 0.2 & 0.5 & 0.2 \\
		& LSTM dim & 50 & 300 & 300 & 300 & 300 & 100 & 50 & 200 & 300 \\
        & hidden dim & 200 & 300 & 200 & 100 & 200 & 50 & 300 & 50 & 100 \\
\bottomrule
\end{tabular}
\end{footnotesize}
\caption{Best parameter values for sentence ordering and minority class classification experiments.}
\label{tab:param_vals2}
\end{center}
\end{table*} 



















































\end{document}
