



\vspace{-1mm}
In order to evaluate the performance of the proposed gait biometrics as
an authentication scheme, we utilized the machine learning approach based on
the underlying readings of the motion sensors, and the position sensors from both of the phone and the watch. 

\vspace{-4mm}
\subsection{Preliminaries}
\vspace{-2mm}
\noindent\textbf{Classifier:} In our analysis, we utilized the Random Forest classifier. Random Forest is an ensemble approach based on the generation of many
classification trees, where each tree is constructed using a separate bootstrap
sample of the data. To classify a new input, the new input is run down on
all the trees and the result is determined based on majority voting. Random Forest is efficient, can estimate the
importance of the features, and is robust against noise \cite{maxion2010keystroke}. 
Random Forest outperforms other classifiers including support vector machines which are considered to be the best classifier currently available \cite{caruana2006empirical,liu2013comparison,maxion2010keystroke}.
 
\smallskip
\noindent\textbf{Features:} For each of the used sensor
instances, we calculated the mean, the standard deviation and the range of each of the axis ($X, Y, Z$), the square of each axis ($X^2$, $Y^2$, $Z^2$) and the square root of the sum of squares for that
instance's axes components ($X, Y, Z$) of
all the instances in the sample that corresponds to a single walk instance. Twenty one features are extracted from each of the used sensors, which give us a total of 336 features.


The 336 features or subset of them were used as input to train the classifier to
differentiate a user from other users.  
In the classification task, the positive class corresponds to the gait
of the legitimate user and the negative class corresponds to impersonator (other user).
Therefore, true positive (TP) represents the number of times the legitimate
user is granted access, true negative (TN) represents the number of times
the impersonator is rejected, false positive (FP) represents the number of
times the impersonator is granted access and false negative (FN) represents the
number of times the correct user is rejected.

As performance measures for our classifiers, we used false positive, false negative, precision, recall and
F-measure (F1 score), as shown in  Equation \ref{eqn:precision_recall}.
FP/precision measures the security of the proposed system, i.e., the accuracy of
the system in rejecting impersonators. FN/recall measures the usability of the
proposed system as high FN leads to high rejection rate of the legitimate
users.  F-measure considers both the usability and the security of the system.
To make our system both usable and secure, ideally, we would like to have FP and FN
as close as 0 and recall, precision and F-measure as close as 1. 

\vspace{-1mm}
{\scriptsize{

\begin{equation}
\vspace{-3mm}
\label{eqn:precision_recall}
precision = \frac{TP}{TP+FP}; \hspace{5mm} recall = \frac{TP}{TP+FN}; \hspace{5mm} F\mbox{-}measure = 2* \frac{precision*recall}{precision+recall}\\
\end{equation}
\vspace{-3mm}
}}




\begin{table}[t]
\centering
\vspace{-6mm}
\scriptsize
\caption{Performance for the classifier for three different 
categories. The first three rows show the performance of the classifier using all the sensors. The next three rows show the results of using the sensors subset that provides the best average results. The last three rows show the result
of using the best sensors subset for each user.  Highlighted cells emphasize the most interesting results.}
\label{table:ResultsGeneral}
\def\arraystretch{1.7}
\begin{tabular}{ll|c|c||c|c|c|}
\cline{3-7}
                                                           &                     & \textbf{FNR}    & \textbf{FPR}    & \textbf{F-Measure} & \textbf{recall} & \textbf{precision} \\ \cline{3-7} 
                                                           &                     & \multicolumn{5}{c|}{\textbf{Avg (std. dev.)}}                                          \\ \hline \hline
\multicolumn{1}{|l|}{\multirow{3}{*}{\rotatebox[origin=c]{90}{\textbf{Overall}}}} & \textbf{Phone Only}  & 0.058 (0.037)   & 0.068 (0.034)   & 0.937 (0.026)      & 0.942 (0.037)   & 0.934 (0.031)       \\ \cline{2-7} 
\multicolumn{1}{|l|}{}                                     & \textbf{Watch Only} & 0.085 (0.050)   & 0.105 (0.045)   & 0.906 (0.036)      & 0.915 (0.050)   & 0.899 (0.040)  \\ \cline{2-7} 
\multicolumn{1}{|l|}{}                                     & \textbf{Both}       & 0.038 (0.047)   & 0.042 (0.031)   & 0.960 (0.030)      & 0.962 (0.047)   & 0.960 (0.029)      \\ \hline\hline
\multicolumn{1}{|l|}{\multirow{3}{*}{\rotatebox[origin=c]{90}{\textbf{General}}}}    & \textbf{Phone Only} & 0.040 (0.035)   & 0.051 (0.033)   & 0.954 (0.025)      & 0.960 (0.035)   & 0.950 (0.031)      \\ \cline{2-7} 
\multicolumn{1}{|l|}{}                                     & \textbf{Watch Only} & 0.080 (0.049)   & 0.095 (0.043)   & 0.913 (0.030)      & 0.920 (0.049)   & 0.909 (0.038)        \\ \cline{2-7} 
\multicolumn{1}{|l|}{}                                     & \textbf{Both}       & 0.022 (0.027)   & 0.030 (0.027)   & 0.974 (0.021)      & 0.978 (0.027)   & 0.971 (0.025)       \\ \hline\hline
\multicolumn{1}{|l|}{\multirow{3}{*}{\rotatebox[origin=c]{90}{\textbf{\hspace{-3mm} Individual \hspace{-5mm} }}}} & \textbf{Phone Only} 
																				 & 0.018 (0.023)   & 0.036 (0.020)   & 0.973 (0.013)      & 0.982 (0.023)   & 0.965 (0.019)        \\ \cline{2-7} 
\multicolumn{1}{|l|}{}                                     & \textbf{Watch Only} & 0.046 (0.034)   & 0.063 (0.044)   & 0.947 (0.024)      & 0.954 (0.034)   & 0.941 (0.039)      \\ \cline{2-7} 
 
\multicolumn{1}{|l|}{}                                     & \textbf{Both}       & \cellcolor[HTML]{C0C0C0}{0.002 (0.006) }  & \cellcolor[HTML]{C0C0C0} {0.003 (0.008) }  & \cellcolor[HTML]{C0C0C0} 0.997 (0.005)      & \cellcolor[HTML]{C0C0C0} 0.998 (0.006)   & \cellcolor[HTML]{C0C0C0} 0.997 (0.008)       \\ \hline
\end{tabular}
\vspace{-4mm}
\end{table}



\vspace{-3mm}
\subsection{Classification Results}

As mentioned in Section \ref{sec:dataCollection}, we collected data from 18
users. From each user, we collected 50 samples of walking data. We divided the collected data
into 18 sets based on the users' identities (ids).  In order to build a classifier to
authenticate a user based on her gait biometrics, we defined two classes.
The first class contains the walking data from a specific user, and the other class
contains randomly selected walking data from other users.   

The classification results are obtained after running a 10-fold cross validation, and are summarized in Table
\ref{table:ResultsGeneral}. 
The first part of Table \ref{table:ResultsGeneral} shows the results of using all the features 
extracted using sensors from the phone, the watch and both devices. 
We found combining the features from the phone and the watch sensors decreases the false 
negative from 5.8\% in case of only phone, 8.5\% in case of using only watch to 3.8\% and decreases 
the false positive from 6.8\% in case of only phone, 10.5\% in case of using only watch to 4.2\%.

The second part of Table \ref{table:ResultsGeneral} shows the results obtained by finding the 
sensor subset that provides the best overall average. We found that utilizing only  
accelerometer, gyroscope, magnetometer and orientation sensors from phone rather than using 
all phone sensors decreases the false negative and the false positive by around 2\%.
Similarly, using only  accelerometer, gravity, gyroscope, linear acceleration and magnetometer 
sensors from watch instead of using all watch sensors decreases the false positive rate from 
10.5\% to 9.5\% and the false negative rate from 8.5\% to 8.0\%.
Furthermore, we found utilizing only phone accelerometer, phone gyroscope, phone magnetometer, 
phone orientation, watch accelerometer, watch magnetometer, and watch orientation sensors 
improves the classification accuracy (i.e., decrease both the false positive and the false 
negative rate by 1.2\% and 1.6\%, respectively).
These features subset also contained the subset of features which were not correlated to each other. 
We leverage these uncorrelated features to prevent our \wuzia system against a sophisticated 
form of active impersonation attack \cite{kumar2015treadmill}, as we will describe in Section \ref{sec:treadmill}.

Finally, we checked the classification accuracy by selecting for each user the subset of 
sensors that provides the best results. The results of this model are shown in the last three 
rows of Table \ref{table:ResultsGeneral}. 
We found out that the classifier performance improved over 
the previous two models. Moreover, both the average false positive and the average false 
negative rates dropped to around 0\% when we used the best subset from both of the devices.




In summary, the results obtained from the classification models show that the gait biometrics can be detected in a robust manner and thus will serve as an effective method for authenticating the users.
The results show that the fusion of the phone and the watch sensors significantly enhances the performance of detecting the gait biometrics.
This is reflected in very low false positives and false negatives. 
 













