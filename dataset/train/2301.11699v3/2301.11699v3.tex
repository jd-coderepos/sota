

\documentclass{article}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} 

\usepackage{xcolor}
\usepackage{bm}
\usepackage{multirow}

\newcommand{\R}{\mathbb{R}}
\newcommand{\diff}{\mathop{}\!\mathrm{d}}
\newcommand{\expp}{\mathrm{e}}
\newcommand{\cond}{{\;|\;}}
\newcommand{\condbig}{{\;\big|\;}}
\newcommand{\condBig}{{\;\Big|\;}}
\newcommand{\condbigg}{{\;\bigg|\;}}
\newcommand{\condBigg}{{\;\Bigg|\;}}



\usepackage{xcolor, soul}
\sethlcolor{pink}
\newcommand{\Fredrik}[1]{{\color{purple}\textbf{[Fredrik:} \textit{#1}\textbf{]}}}
\newcommand{\parsection}[1]{\textbf{#1 }}



\makeatletter
\def\changegreek{\@for\next:={alpha,beta,gamma,delta,epsilon,zeta,eta,theta,kappa,lambda,mu,nu,xi,pi,rho,sigma,tau,upsilon,phi,chi,psi,omega,varepsilon,vartheta,varpi,varrho,varsigma,varphi}\do{\expandafter\let\csname\next\expandafter\endcsname\csname\next up\endcsname}}
\def\changegreekbf{\@for\next:={alpha,beta,gamma,delta,epsilon,zeta,eta,theta,kappa,lambda,mu,nu,xi,pi,rho,sigma,tau,upsilon,phi,chi,psi,omega,varepsilon,vartheta,varpi,varrho,varsigma,varphi}\do{\expandafter\def\csname\next\expandafter\endcsname\expandafter{\expandafter\bm\expandafter{\csname\next up\endcsname}}}}
\makeatother

\usepackage{hyperref}


\newcommand{\theHalgorithm}{\arabic{algorithm}}

\DeclareRobustCommand{\mathup}[1]{\begingroup\changegreek\mathrm{#1}\endgroup}
\DeclareRobustCommand{\mathbfup}[1]{\begingroup\changegreekbf\mathbf{#1}\endgroup}



\usepackage[accepted]{icml2023}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

\usepackage[capitalize,noabbrev]{cleveref}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\newtheorem{prop}{Proposition}

\usepackage[textsize=tiny]{todonotes}


\icmltitlerunning{Image Restoration with Mean-Reverting Stochastic Differential Equations}

\begin{document}

\twocolumn[

\icmltitle{Image Restoration with Mean-Reverting Stochastic Differential Equations}








\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Ziwei Luo}{uu}
\icmlauthor{Fredrik K. Gustafsson}{uu}
\icmlauthor{Zheng Zhao}{uu}
\icmlauthor{Jens Sj{\"o}lund}{uu}
\icmlauthor{Thomas B. Sch{\"o}n}{uu}
\end{icmlauthorlist}

\icmlaffiliation{uu}{Department of Information Technology, Uppsala University, Sweden}


\icmlcorrespondingauthor{Ziwei Luo}{ziwei.luo@it.uu.se}


\icmlkeywords{Image Restoration, Stochastic Differential Equations, Diffusion model}

\vskip 0.3in
]





\printAffiliationsAndNotice{}  


\begin{abstract}
    This paper presents a stochastic differential equation (SDE) approach for general-purpose image restoration. The key construction consists in a mean-reverting SDE that transforms a high-quality image into a degraded counterpart as a mean state with fixed Gaussian noise. Then, by simulating the corresponding reverse-time SDE, we are able to restore the origin of the low-quality image without relying on any task-specific prior knowledge. Crucially, the proposed mean-reverting SDE has a closed-form solution, allowing us to compute the ground truth time-dependent score and learn it with a neural network. Moreover, we propose a maximum likelihood objective to learn an optimal reverse trajectory that stabilizes the training and improves the restoration results. The experiments show that our proposed method achieves highly competitive performance in quantitative comparisons on image deraining, deblurring, and denoising, setting a new state-of-the-art on two deraining datasets. Finally, the general applicability of our approach is further demonstrated via qualitative results on image super-resolution, inpainting, and dehazing. Code is available at \url{https://github.com/Algolzw/image-restoration-sde}.
 \end{abstract}

\section{Introduction}
\label{section:introduction}

Diffusion models have shown impressive performance in various image generation tasks, based on modeling a diffusion process and then learning its reverse~\citep{sohl2015deep, ho2020denoising, song2019generative, song2020improved, song2021denoising, song2021maximum, song2021score, rombach2022high,rissanen2022generative}. Among the commonly used formulations \citep{yang2022diffusion}, we adopt that of using the diffusion models defined via stochastic differential equations~\citep[SDEs,][]{song2021maximum,song2021score}. This entails gradually diffusing images towards a pure noise distribution using an SDE, and then generating samples by learning and simulating the corresponding reverse-time SDE \citep{anderson1982reverse}. The essence is training a neural network to estimate the score function of the noisy data distributions \citep{song2019generative}.
\looseness=-1

Image restoration is the general task of restoring a high-quality image from a degraded low-quality version. Common specific examples include image deraining \citep{li2019single, ren2019progressive}, deblurring \citep{nah2017deep, zhang2020deblurring}, denoising \citep{zhang2017beyond, zhang2018ffdnet}, and super-resolution \citep{dong2015image, lugmayr2020srflow,luo2022deep}, just to mention a few.
Image restoration has a rich history \citep{hunt1973application, andrews1974digital, sezan1990survey, banham1997digital} and remains an active topic within computer vision where learning-based approaches have a prominent role \citep{zhang2017image, zhang2017learning, wang2022uformer, xiao2022stochastic}. 

\begin{figure*}[t]
    \begin{center}
    \centerline{\includegraphics[width=1.\textwidth]{figs/overview.pdf}}\vspace{-2.0mm}
    \caption{An overview of our proposed construction, where a mean-reverting SDE (\ref{equ:ou}) is used for image restoration. The SDE models the degradation process from a high-quality image  to its low-quality counterpart , by diffusing  towards a noisy version  of the low-quality image. By simulating the corresponding reverse-time SDE, high-quality images can then be restored.}
    \label{fig:overview}
    \end{center}
    \vskip -0.2in
\end{figure*}

Diffusion models have recently been applied to different image restoration tasks. \citet{saharia2022image, saharia2022palette} train diffusion models which are conditioned on the low-quality images, while \citet{lugmayr2022repaint} utilize a pretrained unconditional model together with a modified generative process. Others explicitly treat image restoration as an inverse problem, assuming that the degradation and its parameters are known at test-time \citep{kawar2021snips, chung2022diffusion, kawar2022denoising}. These methods all employ the standard forward process, which diffuses images to pure noise. The reverse (generative) processes are thus initialized with sampled noise of high variance, which can result in poor restoration of the ground truth high-quality image. A number of experiments have shown that diffusion models can produce better perceptual scores, but often perform unsatisfactory in terms of some pixel/structure based distortion criteria~\citep{saharia2022image, li2022srdiff, kawar2021snips}.
\looseness=-1

To address this issue, we propose to solve the image restoration problem using a \emph{mean-reverting} SDE. As illustrated in Figure~\ref{fig:overview}, this adapts the forward process such that it models the image degradation itself, from a high-quality image to its low-quality counterpart. By simulating the corresponding reverse-time SDE, high-quality images can be restored. Importantly, no task-specific prior knowledge is required to model the image degradation at test time, just a set of image pairs for training. Our main contributions are as follows:
\begin{itemize}
    \item We propose a general-purpose image restoration approach using a mean-reverting SDE that directly models the image degradation process. Our formulation has a closed-form solution that enables us to compute the ground truth time-dependent score function and train a neural network to estimate it.

    \item We propose a simple alternative loss function for training the neural network, based on maximizing the likelihood of the reverse-time trajectory. The loss is demonstrated to stabilize training and consistently improve the image restoration performance compared to the common score matching objective.

    \item We demonstrate the general applicability of our proposed approach by applying it to six diverse image restoration tasks: image deraining, deblurring, denoising, super-resolution, inpainting and dehazing.

    \item Our approach achieves highly competitive restoration performance in quantitative comparisons on image deraining, deblurring and denoising, setting a new state-of-the-art on two deraining datasets.
\end{itemize}









































%
 \section{Background}
\label{section:background}

In this section, we briefly review the key concepts underlying SDE-based diffusion models and show the process of generating samples with reverse-time SDEs.
Let  denote the initial distribution that represents the data, and  denote the continuous time variable. We consider a diffusion process  defined by an SDE of the form,

where  and  are the drift and dispersion functions, respectively,  is a standard Wiener process, and  is an initial condition. Typically, the terminal state  follows a Gaussian distribution with fixed mean and variance. The general idea is to design such an SDE that gradually transforms the data distribution into fixed Gaussian noise~\citep{song2021score,lu2022dpm,de2022riemannian}.


We can then reverse the process to sample data from noise by simulating the SDE backward in time~\citep{song2021score}. \citet{anderson1982reverse} shows that a reverse-time representation of the SDE~\eqref{equ:sde} is given by

where . Here,  is a reverse-time Wiener process and  stands for the marginal probability density function of  at time~. The score function  is in general intractable and thus SDE-based diffusion models approximate it by training a time-dependent neural network  under a so-called score matching objective~\citep{hyvarinen2005estimation,song2021score}.

 \section{Method}
\label{section:method}

The key idea of our proposed image restoration approach is to combine a mean-reverting SDE with a maximum likelihood objective for neural network training. We thus refer to it as an \emph{Image Restoration Stochastic Differential Equation} (IR-SDE). We begin by describing the forward and reverse processes of the mean-reverting SDE, and adapt previously described, score-based, training methods to estimate this SDE. Then, we describe and contrast this with our proposed loss function based on a maximum likelihood objective.




\subsection{Forward SDE for Image Degradation}


We construct a special case of the SDE~\eqref{equ:sde} whose score function is analytically tractable, as follows:

where  is the state mean, and  are time-dependent positive parameters that characterize the speed of the mean-reversion and the stochastic volatility, respectively. There is a lot of freedom when it comes to choosing~ and~ and, as we will see in Section~\ref{section:discussion:theta}, the choice can have a significant impact on the resulting restoration performance. 

In general,  and the starting state  can be set to any pair of different images. The forward SDE (\ref{equ:ou}) then transfers one image to the other as a kind of noisy interpolation. To carry out image degradation, we let  and  be the ground truth high-quality (HQ) image and its degraded low-quality (LQ) counterpart, respectively (see Figure~\ref{fig:overview}). It is worth noting that while  thus depends on  (as they are paired HQ-LQ images of the same object or scene),  is independent of the Brownian motion and the SDE is therefore still valid in the It\^{o} sense.

For our SDE \eqref{equ:ou} to have a closed-form solution, we set , where  is the stationary variance. With this, we have the following:

\begin{proposition}
    Suppose that the SDE coefficients in \eqref{equ:ou} satisfy  for all times . Then, given any starting state  at time , the solution to the SDE is

where  is known and the transition kernel  is a Gaussian with mean  and variance  given by:
    
\label{prop:forward_sde_solution}
\end{proposition}

The proof is provided in Appendix~\ref{prf:SDE_solution}. To simplify the notation when the starting state is , we substitute  with , respectively. 
Then we have the distribution of  at any time  conditioned on the initial state, given by

Note that as , the mean  converges to the low-quality image  and the variance  converges to the stationary variance  (hence the qualifier ``mean-reverting''). In other words, the forward SDE~\eqref{equ:ou} diffuses the high-quality image into a low-quality image with fixed Gaussian noise.
\looseness=-1

 

\subsection{Reverse-Time SDE for Image Restoration}

To recover the high-quality image from the terminal state , we reverse the SDE~\eqref{equ:ou} according to \eqref{equ:reverse-sde} to derive an image restoration SDE (IR-SDE), given by

At test time, the only unknown part is the score  of the marginal distribution at time . But during training, the ground truth, high-quality image  is available and thus we can train a neural network to estimate the conditional score . Specifically, we can use \eqref{eq:sde_gauss_mean_var} to compute the ground truth score as

This is analogous to the standard denoising score-matching which also computes the ground truth score based on a clean image and its noisy counterpart~\cite{hyvarinen2005estimation}. Moreover, if we reparameterize , where  is a standard Gaussian noise , we can obtain the score directly in terms of the noise by

Then, we follow the common practice of approximating the noise using a noise network~\cite{ho2020denoising}, i.e. a conditional time-dependent neural network  which takes both state , condition , and time  as input and outputs pure noise. Such a network can be trained with the following objective similar to that used in DDPM~\cite{ho2020denoising}:

where  are positive weights and  denotes the discretization of the diffusion process. Once trained, we can use the network  to generate high-quality images by sampling a noisy state  and iteratively solving the IR-SDE~\eqref{eq:reverse-irsde} with a numerical scheme, such as Euler--Maruyama or Milstein's method~\cite{mil1975approximate}.


\subsection{Maximum Likelihood Learning}

Despite the fact that the objective in~\eqref{eq:noise_objective} offers a simple way to learn the score, we empirically found that the training  often becomes unstable when applied to the complicated degradations encountered in image restoration. We conjecture that this difficulty stems from trying to learn the instantaneous noise at a given time. We therefore propose an alternative maximum likelihood objective, based on the idea of trying to find the optimal trajectory  given the high-quality image . Note that this objective is not proposed to learn a more accurate score function. Instead, it is used to stabilize training and recover more accurate images. 

Specifically, we want to maximize the likelihood  which can be factorized according to

where  is the low-quality image distribution. Then the reverse transition can be derived from Bayes' rule~\cite{lindholm2022machine}:

Since all distributions are Gaussians that can be computed from Proposition \ref{prop:forward_sde_solution}, it is natural to directly find an optimal reverse state that minimizes the negative log-likelihood:

where we let  represent the ideal state reversed from . To simplify the notation, we let . By solving for the above objective, we have the following:


\begin{proposition}
    Given an initial state , for any state  at discrete time , the optimum reversing solution  in (\ref{eq:cond_prob_nll}) for IR-SDE is given by:
.6em]
        &\quad+ \frac{1 - \expp^{-2 \, \theta_i^{'}}}{1 - \expp^{-2 \, \bar{\theta}_i}} \expp^{-\bar{\theta}_{i-1}} ({x}_0 - \mu) + \mu.
    \end{split}
    
    {J}_{\gamma}(\phi) \coloneqq \sum_{i=1}^T \gamma_{i} \, \mathbb{E} \Bigl[ \bigl\lVert \underbrace{{x}_{i} - (\diff {x}_{i})_{\tilde{\epsilon}_\phi}}_{\mathrm{reversed} \, {x}_{i-1}} - \, {x}_{i-1}^{*} \bigr\rVert \Bigr],
    \label{eq:nll_objective}

    \diff {x} = \Bigl[\theta_t \, (\mu - {x}) - \frac{1}{2} \, \sigma_t^2 \, \nabla_{{x}}\log p_t({x}) \Bigr]\diff t.
    \label{eq:reverse-irode}

        {x}(t) = \mu + \bigl({x}(s) - \mu \bigr) \, \expp^{-\bar{\theta}_{s:t}} + \int^t_s \sigma_z \, \expp^{-\bar{\theta}_{z:t}} \diff w(z),
    
        \begin{split}
        m_{s:t}(x_s) &\coloneqq \mu + ({x}(s) - \mu) \, \expp^{-\bar{\theta}_{s:t}}, \\
        v_{s:t} &\coloneqq \int^t_s \sigma_z^2 \, \expp^{-2\bar{\theta}_{z:t}} \diff z \\
        & \ = \lambda^2 \, \Bigl(1 - \expp^{-2 \, \bar{\theta}_{s:t}}\Bigr).
        \end{split}
    
   \diff {x} = \theta_t \, (\mu - {x}) \diff t + \sigma_t \diff w,
\label{app-equ:ou}

    \psi({x}, t) = {x}\, \expp^{{\bar{{\theta}}_t}},
    \label{app-eq:function_phi}

\begin{split}
    \diff \psi({x}, t) 
    &= \frac{\partial \psi}{\partial t}({x}, t)\diff t + \frac{\partial \psi}{\partial {x}}({x}, t) {\mathbf f}({x}, t)\diff t   \\
    &\quad+ \frac{1}{2}\frac{\partial^2 \psi}{\partial {x}^2}({x}, t) g(t)^2 \diff t \\
    &\quad+ \frac{\partial \psi}{\partial {x}}({x}, t) g(t) \, \mathrm{dw}_t.
\end{split}
\label{app-eq:Ito_formula}

    \diff \psi({x}, t) = \mu {\theta}_t \expp^{\bar{{\theta}}_t}\diff t + \bm{\sigma}_t \expp^{\bar{{\theta}}_t} \, \mathrm{dw}_t 
    \label{eq:solution_phi}

\begin{split}
    \psi({x}, t) &- \psi({x}, s) = \int_{s}^t \mu {\theta}_z \expp^{\bar{{\theta}}_z}\diff z + \underbrace{\int_{s}^t\bm{\sigma}_z \expp^{\bar{{\theta}}_z}{\mathrm{dw}(z)}}_{\sim \mathcal{N}\left(0, \ \int_{s}^t\bm{\sigma}_z^2 \expp^{2\bar{{\theta}}_z}{\mathrm{d}z}\right)}.
    \label{eq:integral_xt_x0}
\end{split}

\begin{split}
    {x}(t) \expp^{{\bar{{\theta}}_t}} - {x}(s) \expp^{{\bar{{\theta}}_s}} = \mu (\expp^{\bar{{\theta}}_t} - \expp^{\bar{{\theta}}_s}) + \int_{s}^t\bm{\sigma}_z \expp^{\bar{{\theta}}_z}{\mathrm{dw}(z)},
    \label{eq:solve_integral_xt_x0}
\end{split}

    {x}(t) = \mu + \bigl({x}(s) - \mu \bigr) \, \expp^{-\bar{\theta}_{s:t}} + \int^t_s \sigma_z \, \expp^{-\bar{\theta}_{z:t}} \diff w_z,
    \label{app-eqn:sde_solution}

\begin{split}
    \int_{s}^t\bm{\sigma}_z^2 \expp^{-2\bar{{\theta}}_{z:t}}{\mathrm{d}z} = \frac{\sigma_t^2}{2\theta_t}\expp^0 - \frac{\sigma_s^2}{2\theta_s} \expp^{-2\bar{{\theta}}_{s:t}} = \lambda^2 \, \Bigl(1 - \expp^{-2 \, \bar{\theta}_{s:t}}\Bigr),
    \label{app_eqm:solve_variance}
\end{split}

    p({x}(t) \cond {x}(s)) = \mathcal{N}\bigl({x}(t) \cond m_{s:t}({x}(s)), v_{s:t}\bigr),

    \begin{split}
    m_{s:t}(x_s) &\coloneqq \mu + ({x}(s) - \mu) \, \expp^{-\bar{\theta}_{s:t}}, \\
    v_{s:t} &\coloneqq \int^t_s \sigma_z^2 \, \expp^{-2\bar{\theta}_{z:t}} \diff z = \lambda^2 \, \Bigl(1 - \expp^{-2 \, \bar{\theta}_{s:t}}\Bigr).
    \end{split}

    \begin{split}
        {x}_{i-1}^{*} &= \frac{1 - \expp^{-2 \, \bar{\theta}_{i-1}}}{1 - \expp^{-2 \, \bar{\theta}_i}} \expp^{-\theta_i^{'}} ({x}_i - \mu) + \frac{1 - \expp^{-2 \, \theta_i^{'}}}{1 - \expp^{-2 \, \bar{\theta}_i}} \expp^{-\bar{\theta}_{i-1}} ({x}_0 - \mu) + \mu.
    \end{split}
    
\begin{split}
    {x}_{i-1}^{*} = \arg\min_{{x}_{i-1}} \Bigl[ -\log p \bigl({x}_{i-1} \mid {x}_i, {x}_0 \bigr) \Bigr].
    \label{app-eq:cond_prob_nll}
\end{split}

\begin{split}
    -\log p \bigl({x}_{i-1} \mid {x}_i, {x}_0 \bigr) &= -\log \frac{p({x}_{i} \mid {x}_{i-1}, {x}_0) p({x}_{i-1} \mid {x}_0)}{p({x}_i \mid {x}_0)} \
where all transitions are tractable. Then we can directly solve the NLL in \eqref{app-eq:cond_prob_nll} by computing its gradient and setting it to be zero:
.6em]
     & = - \frac{\expp^{-{\theta}_i^{'}} ({x}_i - \mu - ({x}_{i-1}^{*} - \mu)\expp^{-{\theta}_i^{'}})}{1 - \expp^{-2 \, {\theta}_i^{'}}} + \frac{{x}_{i-1}^{*} - \mu - ({x}_0 - \mu)\expp^{-\bar{\theta}_{i-1}}}{1 - \expp^{-2 \, \bar{\theta}_{i-1}}} \.6em]
     & = \frac{({x}_{i-1}^{*} - \mu)(1 - \expp^{-2 \, \bar{\theta}_{i}})}{(1 - \expp^{-2 \, {\theta}_i^{'}})(1 - \expp^{-2 \, \bar{\theta}_{i-1}})} - \frac{({x}_{i} - \mu)\expp^{-{\theta}_i^{'}}}{1 - \expp^{-2 \, {\theta}_i^{'}}} - \frac{({x}_{0} - \mu)\expp^{-\bar{\theta}_{i-1}}}{1 - \expp^{-2 \, \bar{\theta}_{i-1}}} = 0,
    \label{app-eq:solve_nll}
\end{split}

    \begin{split}
        {x}_{i-1}^{*} = \frac{1 - \expp^{-2 \, \bar{\theta}_{i-1}}}{1 - \expp^{-2 \, \bar{\theta}_i}} \expp^{-\theta_i^{'}} ({x}_i - \mu) + \frac{1 - \expp^{-2 \, \theta_i^{'}}}{1 - \expp^{-2 \, \bar{\theta}_i}} \expp^{-\bar{\theta}_{i-1}} ({x}_0 - \mu) + \mu,
    \end{split}
    
    \mu \coloneqq {x}_0.
    \label{app-eq:denoise_mu}

    p_{noise}({x}_i|{x}_0) = \mathcal{N}(m_i({x}_0), v_i),
    \label{app-eq:denoise_transition}

    m_i := {x}_0, \quad v_i = \lambda^2 \, \Bigl(1 - \expp^{-2 \, \bar{\theta}_{i}}\Bigr).

    \begin{split}
        {x}_{i-1}^{*} &= \frac{1 - \mathrm{e}^{-2\bar{{\theta}}_{i-1}}}{1 - \mathrm{e}^{-2\bar{{\theta}}_{i}}} \mathrm{e}^{-{{\theta}}_{i}} ({x}_i - {x}_0) + {x}_0.
    \end{split}
    \label{app-eq:optimal_denoising_trajectory}

    \diff {x} = \big[ \theta_t \, (\mu - {x}) - \sigma_t^2 \, \nabla_{{x}} \log p_t({x}) \big] \diff t + \sigma_t \diff \hat{w},
    \label{app-eq:reverse-irsde}

    {x}_i = m_{i} + \sqrt{v_{i}} \, \epsilon_t, \quad  \epsilon_t \sim \mathcal{N}(0, I).
\label{app_eq:sampling_xt}

    {\mathrm d}{x} = -\frac{1}{2}\bm{\sigma}(t)^2 (1 + \mathrm{e}^{-2\bar{{\theta}}_t}) \nabla_{{x}_t}\log p_t({x}_t){\mathrm d}t + \bm{\sigma}(t){\mathrm d}\bar{\mathbf w}.
    \label{app-eq:denoising-sde-simple}

    \diff {x} = \Bigl[\theta_t \, (\mu - {x}) - \frac{1}{2} \, \sigma_t^2 \, \nabla_{{x}}\log p_t({x}) \Bigr]\diff t.
    \label{app-eq:reverse-irode}

    {\mathrm d}{x} = -\frac{1}{2}\bm{\sigma}_t^2 \mathrm{e}^{-2\bar{{\theta}}_t} \nabla_{{x}}\log p_t({x}){\mathrm d}t.
    \label{app-eq:denoising-ode-simple}

    \sigma_{\mathrm{real}}^2 = v_t = \lambda^2 \, \Bigl(1 - \expp^{-2 \, \bar{\theta}_{t}}\Bigr).

    t^* = \arg\min_{t} \| \bar{{\theta}}_t - \frac{1}{2\Delta t} \log (1 - \frac{\sigma_{\mathrm{real}}^2}{\lambda^2}) \|. 

    \begin{split}
        q(x_t \mid x_{t-1}) &= \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t I), \\
        q(x_t \mid x_0) &= \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) I),
    \end{split}

    \begin{split}
        q(x_{i-1} \mid x_i, x_0) \propto q(x_{i} \mid x_{i-1}, {x}_0) q(x_{{i-1}} \mid { x}_0). \\
    \end{split}

    \begin{split}
        & \nabla_{x_{t-1}^{*}} \left\{-\log q \bigl(x_{i-1}^{*} \mid x_i, x_0 \bigr)\right\} \\
        & = \frac{1 - \bar{\alpha}_t}{\beta_t (1 - \bar{\alpha}_{t-1})} x_{t-1}^{*} - (\frac{\sqrt{\alpha_t}}{\beta_t} x_t + \frac{\sqrt{\bar{\alpha}_{t-1}}}{1 - \bar{\alpha}_{t-1}} x_0) = 0.
    \end{split}

    x_{t-1}^{*} = \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} x_t + \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t}{1 - \bar{\alpha}_t} x_0,

    \theta_t = 1 - \frac{f(t)}{f(0)}, \quad f(t) = \cos \left( \frac{t/T + s}{1 + s} \cdot \frac{\pi}{2} \right)^2,

where  as the same as in ~\cite{nichol2021improved}. This cosine  schedule is also visually shown in Figure~\ref{fig:cosine_variance}. Once the  function is determined, we can compute the corresponding diffusion coefficient  by the following stationary condition .
Practically, we approximate  using a discrete form as . To alleviate the over-smooth problem as mentioned in Section~\ref{sec:limitations}, we let the exponential term  to be a smaller value  instead of zero and then  can also be computed by . 


\section{Additional Experimental Results}
\label{app-sec:results}

Here we show more detailed results for each task. Note that all reported results of the comparison methods are obtained from using their official codes and pretrained models.

\textbf{Comparison of losses.}
We first give the final quantitative results of learning deraining task with the proposed maximum likelihood loss~\eqref{eq:nll_objective} and with the noise matching loss~\eqref{eq:noise_objective} in Table~\ref{table:cmp_loss1}. The results show that the maximum likelihood significantly improves the performance over all criteria, which is consistent to Section \ref{sec:discuss_objective} and the result in Figure~\ref{fig:loss_curves}. 

\textbf{Additional quantitative results.}
Here we give the quantitative results of dehazing in Table~\ref{app-table:dehaze}. Here we only compare with the CNN-baseline since DDRM~\cite{kawar2022denoising} requires the degradation parameters to be known, which limits its application on image dehazing.
The comprehensive results of image denoising on three different test sets over different noise levels are given by Tables~\ref{app-table:denoising_mcmaster}, \ref{app-table:denoising_kodak24}, and~\ref{app-table:denoising_cbsd68}. Note we add a SOTA denoising method KBNet~\cite{zhang2023kbnet} on the CBSD68 dataset. The proposed Denoising-ODE has the best perceptual performance for all scenes. 

\textbf{Model complexities.}
We also provide the comparison of computational efficiency and model complexity in Table~\ref{app-table:complexity}. our model only slightly increases the parameters and flops of CNN-baseline, while other SOTA methods have to rely on huge computation operations (MAXIM) or complex network structures (KBNet) to improve their performances. We also need to mention that the reverse process involves repeated network evaluations that increases the inference time and computational cost, which is a common limitation of diffusion models. But for training, we only need to sample noises and learn them, which usually converges quickly. 

\textbf{Additional qualitative results.}
We provide additional results on each task. Specifically, Figure~\ref{app-fig:denosing_results},
Figure~\ref{app-fig:deraining_results}, Figure~\ref{app-fig:deblurring_results}, Figure~\ref{app-fig:sr_results}, Figure~\ref{app-fig:inpainting_results}, and Figure~\ref{app-fig:dehazing_results} illustrate visual results on denosing, deraining, deblurring, super-resolution, inpainting, and dehazing, respectively. In most tasks, the results produced by our method are sharper and more realistic. Please zoom in for the best view.


\vskip 1.0in



\begin{table}[ht]

\begin{minipage}[h]{1.\linewidth}
\caption{Analysis of different losses on deraining task.}
\label{table:cmp_loss1}
\begin{center}
\begin{small}
\begin{sc}
\resizebox{.85\linewidth}{!}{
\begin{tabular}{lcccccccc}
\toprule
\multirow{2}{*}{Method} &  \multicolumn{4}{c}{Rain100H dataset} & \multicolumn{4}{c}{Rain100L dataset}  \\ \cmidrule(lr){2-5} \cmidrule(lr){6-9}
& PSNR & SSIM & LPIPS & FID & PSNR & SSIM & LPIPS & FID    \\
\midrule
Maximum Likelihood Loss  & \textbf{30.75} & \textbf{0.9027} & \textbf{0.048} & \textbf{19.76} & \textbf{38.30} & \textbf{0.9805} & \textbf{0.014} & \textbf{7.94} \\
Noise Matching Loss  & 23.59 & 0.7373 & 0.221 & 91.49 & 31.81 & 0.9313 & 0.107 & 52.64 \\
\bottomrule
\end{tabular}
}
\end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{minipage}


\begin{minipage}[h]{1.\linewidth}
\caption{Quantitative results of dehazing on the SOTS indoor dataset.}
\label{app-table:dehaze}
\vskip 0.05in
\begin{center}
\begin{small}
\begin{sc}
\resizebox{.45\linewidth}{!}{
\begin{tabular}{lcccc}
\toprule
\multirow{2}{*}{Method} &  \multicolumn{2}{c}{Distortion} & \multicolumn{2}{c}{Perceptual}  \\ \cmidrule(lr){2-3} \cmidrule(lr){4-5}
&  PSNR & SSIM & LPIPS & FID \\
\midrule
CNN-baseline  & 29.78 & 0.9683 & 0.037 & 34.77  \\
Our Method  & \textbf{34.14} & \textbf{0.9886} & \textbf{0.012} & \textbf{6.06}  \\

\bottomrule
\end{tabular}
}
\end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{minipage}

\begin{minipage}[h]{1.\linewidth}
\caption{Comparison of the number of parameters and model computational efficiency.}
\label{app-table:complexity}
\vskip 0.05in
\begin{center}
\begin{small}
\begin{sc}
\resizebox{.55\linewidth}{!}{
\begin{tabular}{lcccc}
\toprule
Method &  MAXIM & KBNet & CNN-baseline & Ours  \\
\midrule
\#Parameters  & 14.1M & 118.5M & 33.8M & 34.2M  \\
Flops  & 216G & 68.7G & 98.0G & 98.3G  \\

\bottomrule
\end{tabular}
}
\end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{minipage}

\end{table}


\begin{table}[ht]

\begin{minipage}[h]{1.\linewidth}
\caption{Quantitative results of image denoising on McMaster~\cite{zhang2011color} test set.}
\label{app-table:denoising_mcmaster}
\begin{center}
\begin{small}
\begin{sc}
\resizebox{1.\linewidth}{!}{
\begin{tabular}{lcccccccccccc}
\toprule
\multirow{2}{*}{Method} &  \multicolumn{4}{c}{} & \multicolumn{4}{c}{} & \multicolumn{4}{c}{} \\ \cmidrule(lr){2-5} \cmidrule(lr){6-9} \cmidrule(lr){10-13}
&  PSNR & SSIM & LPIPS & FID &  PSNR & SSIM & LPIPS & FID &  PSNR & SSIM & LPIPS & FID  \\
\midrule
DnCNN  & 33.45 & 0.9035 & 0.068 & 37.14 & 31.52 & 0.8692 & 0.101 & 59.16 & 28.62 & 0.7986 & 0.173 & 107.31 \\
FFDNet  & 34.66 & \textbf{0.9216} & 0.065 & 39.37 & 32.36 & \textbf{0.8861} & 0.103 & 63.84 & \textbf{29.19} & \textbf{0.8149} & 0.183 & 118.38 \\

CNN-baseline  & 33.51 & 0.8978 & 0.089 & 43.90 & 31.79 & 0.8697 & 0.122 & 66.47 & 29.15 & 0.8122 & 0.160 & 93.68 \\

IR-SDE & 31.95 & 0.8600 & 0.038 & 23.97 & 29.48 & 0.8052 & 0.071 & 44.77 & 27.14 & 0.7549 & 0.151 & 97.53 \\

Denoising-ODE  & \textbf{34.80} & 0.9188 & \textbf{0.036} & \textbf{22.03} & \textbf{32.39} & 0.8791 & \textbf{0.055} & \textbf{34.66} & 29.03 & 0.7911 & \textbf{0.091} & \textbf{63.84} \\
Denoising-SDE  & 31.18 & 0.8195 & 0.049 & 29.21 & 28.98 & 0.7512 & 0.088 & 45.84 & 25.85 & 0.6272 & 0.173 & 92.19 \\


\bottomrule
\end{tabular}
}
\end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{minipage}

\begin{minipage}[h]{1.\linewidth}
\caption{Quantitative results of image denoising on Kodak24~\cite{franzen1999kodak} test set.}
\label{app-table:denoising_kodak24}
\begin{center}
\begin{small}
\begin{sc}
\resizebox{1.\linewidth}{!}{

\begin{tabular}{lcccccccccccc}
\toprule
\multirow{2}{*}{Method} &  \multicolumn{4}{c}{} & \multicolumn{4}{c}{} & \multicolumn{4}{c}{} \\ \cmidrule(lr){2-5} \cmidrule(lr){6-9} \cmidrule(lr){10-13}
&  PSNR & SSIM & LPIPS & FID &  PSNR & SSIM & LPIPS & FID &  PSNR & SSIM & LPIPS & FID  \\
\midrule
DnCNN  & 34.48 & 0.9189 & 0.083 & 21.71 & 32.02 & 0.8763 & 0.129 & 41.96 & 28.83 & 0.7908 & 0.229 & 83.27 \\
FFDNet  & 34.63 & \textbf{0.9215} & 0.085 & 21.57 & 32.13 & \textbf{0.8779} & 0.140 & 44.57 & \textbf{28.98} & \textbf{0.7942} & 0.255 & 89.69 \\

CNN-baseline  & 33.92 & 0.9090 & 0.110 & 24.52 & 32.73 & 0.8666 & 0.161 & 45.81 & 28.89 & 0.7904 & 0.223 & 66.01 \\

IR-SDE & 31.85 & 0.8603 & 0.057 & 15.25 & 28.99 & 0.7772 & 0.106 & 35.19 & 26.83 & 0.7190 & 0.208 & 70.96 \\


Denoising-ODE  & \textbf{34.64} & 0.9184 & \textbf{0.050} & \textbf{13.74} & \textbf{32.14} & 0.8739 & \textbf{0.078} & \textbf{21.47} & 28.75 & 0.7746 & \textbf{0.134} & \textbf{45.96} \\

Denoising-SDE  & 30.89 & 0.8099 & 0.074 & 21.09 & 28.55 & 0.7247 & 0.130 & 36.18 & 25.46 & 0.5788 & 0.249 & 75.33 \\

\bottomrule
\end{tabular}
}
\end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{minipage}

\begin{minipage}[h]{1.\linewidth}
\caption{Quantitative results of image denoising on CBSD68~\cite{martin2001database} test set.}
\label{app-table:denoising_cbsd68}
\begin{center}
\begin{small}
\begin{sc}
\resizebox{1.\linewidth}{!}{
\begin{tabular}{lcccccccccccc}
\toprule
\multirow{2}{*}{Method} &  \multicolumn{4}{c}{} & \multicolumn{4}{c}{} & \multicolumn{4}{c}{} \\ \cmidrule(lr){2-5} \cmidrule(lr){6-9} \cmidrule(lr){10-13}
&  PSNR & SSIM & LPIPS & FID &  PSNR & SSIM & LPIPS & FID &  PSNR & SSIM & LPIPS & FID  \\
\midrule
DnCNN  & \textbf{33.90} & 0.9289 & 0.063 & 25.59 & 31.24 & 0.8830 & 0.109 & 43.51 & 27.95 & \textbf{0.7896} & 0.210 & 84.56 \\
FFDNet  & 33.88 & \textbf{0.9290} & 0.065 & 27.24 & 31.22 & 0.8821 & 0.121 & 49.64 & \textbf{27.97} & 0.7887 & 0.244 & 98.76 \\

KBNet & - & - & - & - & \textbf{31.71} & \textbf{0.8923} & 0.098 & 37.86 & - & - & - & - \\

CNN-baseline  & 33.02 & 0.9139 & 0.098 & 31.99 & 30.74 & 0.8661 & 0.162 & 56.64 & 27.84 & 0.7827 & 0.232 & 78.51 \\

IR-SDE & 31.04 & 0.8708 & 0.055 & 21.56 & 28.09 & 0.7866 & 0.101 & 36.49 & 25.54 & 0.6894 & 0.219 & 97.95 \\


Denoising-ODE  & 33.80 & 0.9251 & \textbf{0.042} & \textbf{16.71} & 31.14 & 0.8777 & \textbf{0.074} & \textbf{28.71} & 27.59 & 0.7733 & \textbf{0.138} & \textbf{50.46} \\
Denoising-SDE  & 30.15 & 0.8270 & 0.078 & 25.32 & 27.65 & 0.457 & 0.131 & 39.25 & 24.37 & 0.5875 & 0.243 & 84.87 \\

\bottomrule
\end{tabular}
}
\end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{minipage}

\end{table}




\begin{figure}[ht]
\begin{center}
\centerline{\includegraphics[width=.9\columnwidth]{appendices/appendix_figs/app_denoising.pdf}}\vspace{-2.0mm}
\caption{Visual results of our methods with other denosing approaches on Denoising dataset. The noise level .}
\label{app-fig:denosing_results}
\end{center}
\vskip -0.2in
\end{figure}

\begin{figure}[ht]
\begin{center}
\centerline{\includegraphics[width=.9\columnwidth]{appendices/appendix_figs/app_deraining.pdf}}\vspace{-2.0mm}
\caption{Visual results of our methods with other deraining approaches on Rain100H dataset.}
\label{app-fig:deraining_results}
\end{center}
\vskip -0.2in
\end{figure}

\begin{figure}[ht]
\begin{center}
\centerline{\includegraphics[width=.9\columnwidth]{appendices/appendix_figs/app_deblurring.pdf}}\vspace{-2.0mm}
\caption{Visual results of on Deblurring task.}
\label{app-fig:deblurring_results}
\end{center}
\vskip -0.2in
\end{figure}

\begin{figure}[ht]
\begin{center}
\centerline{\includegraphics[width=.75\columnwidth]{appendices/appendix_figs/app_sr.pdf}}\vspace{-2.0mm}
\caption{Visual results of our methods on super-resolution task.}
\label{app-fig:sr_results}
\end{center}
\vskip -0.2in
\end{figure}

\begin{figure}[ht]
\begin{center}
\centerline{\includegraphics[width=.75\columnwidth]{appendices/appendix_figs/app_inpainting.pdf}}\vspace{-2.0mm}
\caption{Visual results of our method on inpainting task.}
\label{app-fig:inpainting_results}
\end{center}
\vskip -0.2in
\end{figure}

\begin{figure}[ht]
\begin{center}
\centerline{\includegraphics[width=.8\columnwidth]{appendices/appendix_figs/app_dehazing.pdf}}\vspace{-2.0mm}
\caption{Visual results of our method on dehazing task.}
\label{app-fig:dehazing_results}
\end{center}
\vskip -0.2in
\end{figure}




 



\end{document}
