\subsection{Reliable and Secure Data Gathering}
\label{sec:secure}

In this section we describe the communication protocol that handles the communication between gathering units and main servers.
It was designed to be efficient but secure, to protect the possibly sensitive data gathered from a users' devices.
The protocol guarantees confidentiality through encryption, integrity and reliability through compression and feedback, and an access control mechanism is responsible for authentication.

Our protocol encrypts every transmission using standard mechanisms, more precisely 4096-bits RSA public key cryptography to exchange per-session random 128-bits AES symmetric keys.



We implemented reliability through encrypted application layer feedback after successful storage of the data on the database.
Also, to minimize the resources utilization and damage done by lost packets, our server implementation works in a stateless mode, without keeping record of an internal communication state and treating every arriving packet the same way.
These features allow a gathering unit to transmit data in real-time or on-demand at arbitrary times, using any kind of network connection.
A unit can opt for the utilization of network friendly protocols (such as TCP) with a high-quality connection, while using other more efficient or packet oriented protocols (UDP) in other network environments, such as vehicular networks.


For authentication and access control we avoid account creation and password handling by using OpenID, an open and secure authentication method.
To access the data, a user has to login in the front-end server via OpenID, with the same e-mail configured and verified in the gathering unit.
To this end, the only user identification automatically stored on our servers is a normalized and hashed version of the user e-mail, which is not directly identifiable.
Furthermore, the table relating an user's hash to the internal user ID is protected, only accessible by the authentication mechanism and the DB Administrator.



The gathering unit is responsible for authenticating the user's OpenID when gathering or uploading data, but for efficiency we perform no user authentication on the server when storing the data.
This may allow a malicious user to replicate the data-gathering protocol or to fake the OpenID validation.
However, in this situation the attacker can only upload data under a fake user ID, and is not able to access any existing data from another user.
Other data forgery attacks are also impossible to prevent, e.g. almost every smartphone can be configured to return fake data from the integrated sensors.
A user can also alter gathered data just by changing the date and time of the mobile device's internal clock.





















We decided not to use available cryptographic protocols such as TLS or DTLS for simplicity reasons.
Even though those protocols are standard and with proven security, they offer many capabilities that are not required for applications like ours, such as Certificate or Cipher Specification Exchange.
By designing a custom protocol based on the same security standards, we were able to integrate our authentication phase in the first transmitted packet responsible for handshake and key exchange, reducing the number of overhead messages to zero (Fig.~\ref{figure:protocol}).
We also did not use any existing web-service standards or frameworks for the same reasons: complexity and overhead.
They typically bring architectural and design constraints like required Resource Identification, fixed message formats, or specific allowed communication protocol.
A data gathering platform should be able to deal with massive amounts of messages and data, making it very important to reduce required processing and bandwidth.
On the other hand, it only needs to support session authentication and data upload.

\begin{figure}[tb]
 \centering
 \includegraphics[width=0.7\linewidth]{Protocol.eps}
 \caption{Protocol description, with session authentication and data transmission with feedback}
 \label{figure:protocol}
\end{figure}



The protocol is divided in two parts (Fig.~\ref{figure:protocol}): a 2-way handshake and a data transmission phase with feedback.
The \textbf{2-way handshake} phase is responsible for session authentication and symmetric key exchange.
The gathering units should authenticate every sensing session by sending a packet.



\begin{itemize}
\item seq: a sequence number defined by the gathering unit.
Identifies the response packet, allowing the unit to send multiple authentication packets in parallel.

\item hash: this is the md5-hash of the user e-mail.


\item time: the unix timestamp of the start of the session.
This timestamp together with the user\_id make the session's primary key.

\item key: a per-session randomly-generated AES-128 symmetric key that should be used for the remainder of the session.


\item version: the application's version, to allow for future format upgrades with backwards compatibility.

\item identifiers: reserved for optional extra session information, such as identifiers of the gathering unit, sensors or vehicles.
\end{itemize}

Both the key and the identifiers of a session can be changed by the gathering unit at any time, by re-sending an authentication packet with the same hash (user ID) and time.
This allows the gathering unit to not store the aes\_key of each session and to update any identifier that may be unavailable at the start.

On receiving this packet, the server should initialize the session on the database and return the time and unique session identifier (session\_id) now reserved for that session's data.
Both fields are compressed and encrypted before transmission using the received symmetric key.



In the \textbf{data transmission phase}, the gathering unit creates a packet where the first 4 bytes correspond to the received session's unique ID, followed by the compressed and encrypted packet with the data to be transmitted.
The ID and the used encryption key must be the ones exchanged during the handshake, otherwise the server will discard the packet.

The sequence number is used to identify the feedback packets, allowing the unit to transmit the next data packets before receiving feedback from the previous one.
This asynchronous transmission can substantially increase the throughput in high latency connections.
The gathering unit is responsible for sequence number generations, tracking, and any necessary re-transmissions.

The feedback packet is only generated after the storage and flushing of the received data, and contains the number of rows received and successfully written to the DB.
This serves as guarantee of receipt and storage, making it safe to the gathering unit to delete the local data after receiving a positive feedback.



In our implementation we used JSON and zlib to serialize and compress the data before transmission, since they completely serves our purpose while being simple and lightweight. 
