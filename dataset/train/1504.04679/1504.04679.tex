\documentclass[11pt,english,onecolumn,draftcls]{IEEEtran}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage[active]{srcltx}
\usepackage{color}
\usepackage{float}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{epstopdf}

\makeatletter

\providecommand{\tabularnewline}{\\}
\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}
\providecommand{\algorithmname}{Algorithm}
\floatname{algorithm}{\protect\algorithmname}

\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}
\theoremstyle{plain}
\newtheorem{prop}[thm]{\protect\propositionname}
\theoremstyle{plain}
\newtheorem{lem}[thm]{\protect\lemmaname}
\theoremstyle{plain}
\newtheorem{cor}[thm]{\protect\corollaryname}

\renewcommand{\baselinestretch}{1.43}

\@ifundefined{showcaptionsetup}{}{\PassOptionsToPackage{caption=false}{subfig}}
\usepackage{subfig}
\makeatother

\usepackage{babel}
\providecommand{\corollaryname}{Corollary}
\providecommand{\lemmaname}{Lemma}
\providecommand{\propositionname}{Proposition}
\providecommand{\theoremname}{Theorem}

\begin{document}

\title{Efficient Approximation Algorithms for Multi-Antennae Largest Weight
Data Retrieval\thanks{The paper has been accepted by IEEE Transactions on Mobile Computing.
Citation information: DOI 10.1109/TMC.2017.2696009. }}


\author{\textcolor{black}{Longkun Guo, Hong Shen, Wenxing
Zhu}\linebreak{}
\textcolor{black}{{} College of Mathematics and Computer Science,
Fuzhou University, China}\\
\textcolor{black}{{} School of Computer Science, University of
Adelaide, Australia }\\
\textcolor{black}{School of Information Science and Technology,
Sun Yat-Sen University, China}\\
}
\maketitle
\begin{abstract}
In a mobile network, wireless data broadcast over  channels (frequencies)
is a powerful means for distributed dissemination of data to clients
who access the channels through multi-antennae equipped on their mobile
devices. The -antennae largest weight data retrieval (ALWDR)
problem is to compute a schedule for downloading a subset of data
items that has a maximum total weight using  antennae in
a given time interval. In this paper, we first give a linear programming
(LP) relaxation for ALWDR and show that it is polynomial-time
solvable when every data item appears at most once. We also show that
when there exist data items with multiple occurrences, the integrality
gap of this LP formula is .

We then present an approximation algorithm of ratio 
for the -antennae -separated largest weight data
retrieval (ALWDR) problem, a weaker version of ALWDR
where each block of up to  data (time) slots is separated
by a vacant slot on all channels, applying the techniques called collectively
randomized LP rounding and layered DAG construction. We show that
ALWDR is -complete even for the simple
case of , , and equal-weight data items each appearing
up to 3 times. Our algorithm runs in time ,
where  is the number of time slots, and  is the maximum length
of the input. Then, from the simple observation that a ratio 
approximation solution to ALWDR implies a ratio
 approximation solution to ALWDR for any
fixed , we immediately have an approximation algorithm
of ratio  for ALWDR. Our algorithm
has the same approximation ratio as the known result in \cite{lu2014data}
which holds only for  , with a significantly lower time
complexity of 
(improved from 
of \cite{lu2014data}). As a by-product, we also give a fixed-parameter
tractable (fpt-)algorithm of time complexity 
for ALWDR, where  is the number of time slots that contain
data items with multiple occurrences. \end{abstract}

\begin{IEEEkeywords}
Distributed data dissemination, multi-antennae data retrieval, scheduling,
approximation algorithm, linear programming.
\end{IEEEkeywords}


\section{Introductions}

In recent years, wireless data broadcast has been gradually considered
as an attractive data propagation scheme for transferring public information
to a large number of specified mobile devices, in applications ranging
from satellite communications to wireless mobile ad hoc networks.
Most wireless broadcast is between base stations and battery-limited
mobile devices, where a base station emits public information (such
as stock marketing, weather, and traffic) via a number of parallel
channels, and mobile devices within a limited area, using an antenna
(or multiple antennae), listen to the channels and obtain required
data packages. The base stations can coordinate information propagation
to cover a larger scope; Within the covered scope, the mobile client
can move freely among different areas while keeping listening to the
channels for downloading the required data packages; An antenna, equipped
in the mobile client, can only listen to a channel at one time, but
it can switch between the channels by adjusting its frequency.

Wireless data broadcast has already shown its advantages in wireless
networks: Possible power saving, throughput improvement, the communication
efficiency that every transmission by a base station can be received
by all nodes which lie within its communication range, and so on.
At the same time, it brings a number of challenges for data propagation
technologies, which have become popular research topics in recent
years, such as indexing technique, data scheduling, and data retrieval.
Indexing technique and data scheduling are mainly based on the server
side. The former topic investigates the structure of the indexing
information that is emitted by the server to boost clients on finding
the locations of requested data items among the channels. The latter
investigates how the server allocates the data items in proper channels
and at proper time slots, such that clients can quickly accomplish
download tasks. Differently, data retrieval is based on the client
side. The goal is to find a data retrieval sequence retrieving all
requested data items among the channels such that the total access
latency is minimized, where the access latency is the length of the
period from the starting time when the client knows the offset of
each requested data item (by index techniques) to the ending time
when the client downloads all the requested data items.


\subsection{Problem Statement}

Let  be a set of data items
broadcast in channels  in a given
time interval, which is separated into time slots .
Let the data items  be with weights
, respectively. The largest weight data retrieval
(LWDR) problem is to schedule to download the data items of ,
such that the weight of the downloaded items will be maximized \cite{Infocom12LuEfficient}.
When the items are with the same weight, LWDR reduces to the Largest
Number Data Retrieval (LNDR) problem, which is to maximize the number
of the downloaded items in the given time interval. This paper considers
ALWDR, i.e., LWDR for mobile devices with  antennae.
We say there exist conflicts between two data items iff it is impossible
to retrieve both of them in the same broadcast cycle using a same
antenna. There exist two well-known conflicts for data retrieval problems
(including ALWDR): (1) two requested data items at two same
time slots; (2) two adjacent time slots of different channels. The
first conflict is because one antenna can retrieve one channel in
one time slot, while the second is because that the antenna switching
between different channels takes time, typically one time slot.

This paper develops a ratio  approximation
algorithm for ALWDR with both of the two conflicts for any
fixed . To do this, we propose the A-separated
LWDR (ALWDR) problem, a weaker version of ALWDR
which has a vacant time slot in every  time slots. A \textbf{vacant}
\textbf{time slot} is a time slot in which no data item is broadcast.
The reason of developing approximation algorithms for ALWDR
instead of ALWDR is because any approximation algorithm for
ALWDR can be immediately adopted to solve ALWDR
with only a small loss in the approximation ratio, as the simple observation
in the following (proof in appendix):
\begin{prop}
\label{prop:simpobsbetw-gamma}If ALWDR admits a
ratio  approximation algorithm with runtime ,
then for any , ALWDR admits a ratio 
approximation algorithm with runtime .
\end{prop}
A \textbf{segment} of ALWDR is the set of time slots
between two neighbor vacant time slots. Through this paper, we assume
that the number of the segments is . This paper also investigates
ALWDR under the \textbf{occurrence assumption} to
better develop the approximation algorithm. The \textbf{occurrence
assumption} is: Each item is broadcast at most once in each segment
in ALWDR.


\subsection{Related Works}

For LWDR, i.e. ALWDR with , existing literature
has discussed data retrieval in depth in the client side of wireless
data broadcast. The problem is firstly studied under the assumption
that each client is equipped with one antenna, and is to download
multiple requested data items for one single request. Three heuristic
schemes have been proposed in \cite{hurson2006power} to compute a
data retrieval schedule with minimum times of switching between the
channels. Later, two algorithms have been proposed in \cite{Shi2010efficient}
to extend data retrieval technique to the case that clients are equipped
with multiple antennae. Considering neither of the two conflicts,
paper \cite{Gao2011} gives an algorithm to find a data retrieval
schedule with minimum access latency and with the times of switching
between the channels bounded by a given number. A parameterized heuristic
scheme has been proposed in \cite{Infocom12LuEfficient}, attempting
to solve the minimum cost data retrieval problem and to find a data
retrieval schedule with minimized energy consumption. A factor
approximation algorithm for LWDR also has been presented in the same
paper. The key idea of the approximation is first to convert the relationship
between the broadcast data items and the time slots to a bipartite
graph, and then obtain an approximation solution for LWDR via maximum
matching in the bipartite graph. The time complexity is 
if employing the Hungarian algorithm \cite{korte2002combinatorial}.
The ratio is then improved to  for any
constant , based on a combination of both linear and
nonlinear programming technique in the algorithm of \cite{lu2014data},
with a significantly increased time complexity of ,
where  is the number of time slots, and  is the maximum length
of the input. Although the combination of linear programming (LP)
and non-linear programming seems interesting, the algorithm is not
applicable to the general case of  due to the prohibitively
high cost of the so-called pipage rounding for the general 
\cite{lu2014data}. Different to \cite{Infocom12LuEfficient} and
\cite{lu2014data}, the work \cite{He2013Efficient} converts the
relationship between data items and time slots to a directed acyclic
graph (DAG), and presents heuristic algorithms to compute a nearly
optimal access pattern for both one antenna and multiple antennae
scenarios. To the best of our knowledge, no approximation algorithm
is known for ALWDR in the general case of .

Since our algorithms have roots in the existing randomized algorithms
for the covering problem, the important results for the maximum coverage
problem (or namely, max cover), the minimum set cover (SC) problem,
etc. will be addressed. Essentially, LWDR can be considered as a maximum
coverage problem with restricts on the elements. The maximum coverage
problem is known to admit a ratio of  that can be
achieved by a greedy algorithm \cite{hochbaum1996approximating}.
The key idea of the algorithm is always to select the set with maximum
uncovered weight, until all elements are covered. The ratio is best
possible, since this problem admits no ratio 
approximation even when all elements are with equal weight, under
the assumption that  \cite{feige1998threshold}.
It is interesting that, unlike the case for the maximum coverage problem,
applying similar idea as the greedy algorithm for ALWDR
can only result in an approximation algorithm with a tight ratio .
For a given collection  of subsets of ,
the minimum set cover (SC) problem is to compute a subset ,
such that every element in  belongs to at least one member of
. It has been shown that SC can be approximated within
a factor of  \cite{johnson1973approximation}
and is not approximable within  unless ,
for some  \cite{feige1998threshold}. When the cardinality of
all sets in  are bounded by a given constant , SC remains
-complete and is approximable within 
\cite{duh1997approximation}. Moreover, if the number of occurrences
of any element in  is also bounded by a constant ,
SC remains -complete \cite{papadimitriou1988optimization}
and approximable within a factor  for both weighted and unweighted
SC \cite{bar1981linear,hochbaum1982approximation}.

In general, LWDR is to optimize a submodular function subject to a
number of constraints. For optimization of a submodular function subject
to candidate constraints, matroid constraints, or knapsack constraints,
the very recent results are approximation algorithms with ratio ,
for any fixed  \cite{DBLP:conf/soda/BadanidiyuruV14}.
Their algorithms can not be applied to LWDR, since the constraints
therein are neither candidate constraints nor matroid constraints.


\subsection{Our Technique and Main Results}

In the paper, ALWDR is first investigated and transferred
to the -disjoint maximum weight longest path (with restricts)
problem in a layered DAG, and then a novel linear programming (LP)
formula for its relaxation is given accordingly. By the formula, we
show that ALWDR is polynomial solvable when every data item
appears at most once. Contrastingly, general ALWDR is -hard
even when . Thus, the difficulty of solving ALWDR
mainly comes from the items with multiple occurrences. Further, the
LP formula is shown to be with an integrality gap 2. That means, immediately
based on the LP formula, it is impossible to develop approximation
with ratio better than . Then a simple idea is first
to divide an instance of ALWDR into a number of subinstances
in which every item appears at most once; then to solve the subinstances
individually, and to combine the computed subsolutions to a whole
solution. Following this idea, this paper develops three algorithms
approximating ALWDR within a factor of .
Based on the simple observation as in Proposition \ref{prop:simpobsbetw-gamma},
the algorithms can be extended for approximating ALWDR within
a ratio .

The first algorithm for ALWDR is based on the randomized
LP rounding technique. The idea is inspired by the famous randomized
algorithms for set cover \cite{korte2002combinatorial}. Provided
that Karmarkar's algorithm is used to solve the LP formula \cite{korte2002combinatorial},
the algorithm is with a time complexity of ,
where  is the number of channels,  is the factor of ALWDR,
 is the number of time slots, and  is the maximum length of
the input. The algorithm can be extended to ALWDR immediately,
within a runtime \textbf{}
for any fixed , which is the same as the result of \cite{lu2014data}
when , but works for arbitrary . We note that
the time complexity is high, e.g. it is  when
setting .

Observe that the high runtime comes from the large number of all possible
paths involved in the first algorithm, we develop the second algorithm
via collectively randomized LP rounding technique for ALWDR.
This is one of the main results of the paper. The algorithm is first
given and analyzed under the \textbf{occurrence assumption} (each
data item appears at most once in every segment of ALWDR).
By collectively randomized LP rounding, our algorithm still randomly
rounds edges according to an optimum solution against the LP formula,
but simultaneously rounds up a collection of edges (a computed flow)
at one time instead of rounding the edges one by one individually.
The improved runtime of the algorithm is  using
Karmarkar's algorithm.\textbf{ }

Further, it is shown the second algorithm can be improved to solve
ALWDR without the occurrence assumption, resulting
in the third algorithm of the same ratio . The algorithm
can also be extended to approximate ALWDR immediately, at
the cost of increasing runtime to .
This presents a significant improvement from the previous result 
for  in \cite{lu2014data}. Although the improved time
complexity still looks high, we argue that it is efficient for two
reasons: (1)  is not large in most cases (typically 2-20); (2)
for practical applications we may use the simplex method instead to
solve the LP formula. It is known that Karmarkar's algorithm (or other
interior-point method) has better worst case time complexity, but
the simplex method has a much better practical performance. As a by-product,
we also give a fixed-parameter tractable (fpt-)algorithm with a time
complexity  for ALWDR, where 
is the number of time slots that contain data items with multiple
occurrences.

In addition, we also prove the -completeness of the restricted
version of ALWDR with  and ,
by giving a reduction from the 3-dimensional perfect matching (3DM)
problem. We note that the -completeness proof of LWDR
in \cite{Infocom12LuEfficient} can not be easily extended to show
the -completeness of ALWDR for 
and .

The remainder of this paper is organized as follows: Section II gives
first the construction of the DAG corresponding to ALWDR,
then an LP-formula for the relaxation of the problem, as well as some
interesting properties; Section III presents a ratio 
randomized approximation algorithm with a time complexity 
for ALWDR for , as well as its ratio
proof and its extension to general ; Section IV gives a randomized
approximation algorithm with ratio  and an improved
runtime  for ALWDR under the
occurrence assumption, and then its derandomization; Section V shows
that the approximation algorithm can be improved such that it works
for ALWDR with the same ratio  but
without the occurrence assumption, and in addition that ALWDR
is fixed-parameter tractable; Section VI gives the -completeness
proof for A-LWDR with  and ;
Section VII evaluates our algorithms by experiments; Section VIII
concludes this paper.


\section{DAG and LP Formula for ALWDR}

This section will first transform an instance of ALWDR into
a layered DAG  with distinct vertices  and , such that
there exists a retrieve sequence for ALWDR if and only if
there exist  (edge) disjoint -paths in . Then an
LP formula is proposed for computing  disjoint -paths
in the constructed DAG, and hence for ALWDR. Based on the
formula, ALWDR is shown polynomial solvable when each data
item appears at most once in the time interval. Later, the LP formula
is shown with an integrality gap 2, so it is hard to approximate ALWDR
within a factor better than 2 using the LP formula.


\subsection{Construction of the Auxiliary DAG }

The construction of DAG  is as in Algorithm \ref{alg:1Construction-of-Auxiliary}.

\begin{algorithm}
\textbf{Input: }An instance of ALWDR;

\textbf{Output:} .
\begin{enumerate}
\item ;
\item For every item :

\begin{enumerate}
\item Add an edge set 
to , where ;
\end{enumerate}
\item For the relationship between the items, add weight-0 edges to 
as below:

\begin{enumerate}
\item Edge  to 
for every  and every , ;
\item Edge  to  for any ;
/{*} For two items which are broadcast both in the th channel.{*}/
\end{enumerate}
\item Add two vertices  and  with weight-0 edges to  as below:

\begin{enumerate}
\item Edge  for every   and ;
\item Edge  for every ,  and .
\end{enumerate}
\end{enumerate}
\protect\caption{\label{alg:1Construction-of-Auxiliary}Construction of DAG for ALWDR. }
\end{algorithm}


Note that  according to the
above construction. Since  equals the number of
the occurrences of all the items,  holds,
where  is the number of channels and  is the number of time
slots. So . However, it will be shown
later that  can be improved to .
Figure \ref{fig:Construction-of-an} depicts an example of constructing
a layered DAG for a given ALWDR instance by Algorithm \ref{alg:1Construction-of-Auxiliary}.
For briefness, we say an instance of ALWDR is feasible, if
and only if there exists a retrieve sequence according to which all
data items can be retrieved.
\begin{lem}
\label{lem:lwdtokpath}An instance of ALWDR is feasible if
and only if there exist at most  disjoint -paths containing
at least one edge of each  for each  in the corresponding
DAG .\end{lem}
\begin{IEEEproof}
We shall only show the lemma holds for the case , since
the case for general  is similar. Assume that ,
 for any , is a retrieve sequence for an instance
of LWDR, where  is the occurrence of
data item  in channel  and time slot .
If  can be retrieved after ,
then the two data items must be conflict-free. That is, 
and  are either (1) in the same channel,
i.e. , and ; or (2) in different channels
and . According to the construction of ,
there must be an edge leaving , the
head of the edge corresponding to ,
and entering , the tail of the
edge corresponding to item . Therefore,

is an  path in .

Conversely, assume that there exists in  a path  ,
, sharing at least one edge with each .
According to the construction as Algorithm \ref{alg:1Construction-of-Auxiliary},
there exists an edge 
only if  or  and .
That is, the items corresponding to 
and ,
say  and ,
are conflict-free. That is, 
is a valid retrieve sequence. Then since  contains at least one
edge of each , the retrieve sequence retrieves all data
items.
\end{IEEEproof}
While no confusion arises, an edge is said in the th time slot,
if the edge is corresponding to an item broadcast in the th time
slot.

\begin{figure*}
\includegraphics{fig1.eps}

\protect\caption{\label{fig:Construction-of-an}Construction of an auxiliary DAG for
an instance of LWDR: (a) An instance of LWDR; (b) The corresponding
auxiliary DAG. }
\end{figure*}



\subsection{An Linear Programming Relaxation for ALWDR }

By Lemma \ref{lem:lwdtokpath}, to compute an optimum solution to
ALWDR, we need only to compute -disjoint maximum
weight -paths (with some additional restricts) in . The following
formula is an LP relaxation for ALWDR (an LP relaxation for
ALNDR if  for all ):




If Inequality (\ref{eq:keyconstr}) is removed, then the above formula
is exactly an LP formula for the relaxation of -disjoint
-paths in . Because graph  is acyclic, any integral optimum
solution (i.e. a solution with all ) to LP (\ref{eq:theoriginalLP})
contains no cycle. Thus, the solution is a set of (edge) disjoint
paths with maximum weight, and hence an optimum solution to ALWDR.
Note that the condition that graph  is acyclic is essential. Otherwise,
a solution to LP (\ref{eq:theoriginalLP}) can contain both cycles
and paths, and is not a solution to ALWDR.

Further, since when  holds for each ,
the constraint matrix of LP (\ref{eq:theoriginalLP}) is known totally
unimodular \cite{schrijver1998theory}, we have the following property
that indicates ALWDR is polynomial solvable when each data
item broadcast at most once:
\begin{thm}
\label{Thr:LWDR-is-polynomial-1} When  holds
for each , any basic optimum solution to LP (\ref{eq:theoriginalLP})
is integral, i.e., each edge  is with  or .
\end{thm}


Therefore, according to the theorem above, to solve an instance of
ALWDR in which each item appears at most once, we need only
to compute a basic optimum solution to LP (\ref{eq:theoriginalLP})
with  . Moreover, it is known
that a basic optimum solution to LP (\ref{eq:theoriginalLP}) can
be computed in polynomial time \cite{korte2002combinatorial}. Hence,
we have:
\begin{cor}
\label{cor:LWDRpolynomial}ALWDR is polynomial solvable when
each data item is broadcast at most once.
\end{cor}
However, it is known the general case of ALWDR is -hard
even when . Worse still, it is hard to approximate ALWDR
within a factor better than  via LP (\ref{eq:theoriginalLP}),
as stated in the following observation:
\begin{prop}
\label{prop:The-integrality-gap}The integrality gap of LP(\ref{eq:theoriginalLP})
is , even for LNDR with only two channels and each data
item is broadcast at most twice.
\end{prop}
To show the integrality gap as above, we give an instance of LWDR
as depicted in Figure \ref{fig:Integrality-Gap-of}, where there are
only two channels, one antenna, and every item in the instance has
the same weight and is broadcast at most twice. Then apparently, an
optimal solution is to retrieve data items , for
which the antenna only needs to keep listening to the upper channel.
That is, the weight of the retrieved data items of an optimal solution
is . On the other hand, 
is an optimal solution to LP (\ref{eq:theoriginalLP}) against the
instance, resulting a weight of 2.

Then following the definition of integrality gap, it is impossible
to design an approximation algorithm with ratio better than 2 based
on LP (\ref{eq:theoriginalLP}) (using LP-rounding, primal-dual method,
etc). However, it is worth noting that the integrality gap of LP (\ref{eq:theoriginalLP})
is better than 2 if the occurrence assumption holds. In fact, that
is why we propose the occurrence assumption.

\begin{figure}
\includegraphics{fig2inteGAP.eps}

\protect\caption{\label{fig:Integrality-Gap-of}Integrality gap of LP (\ref{eq:theoriginalLP}). }
\end{figure}



\section{A Factor Approximation Algorithm for ALWDR}

Instead of approximating ALWDR directly, this section will
first give an approximation algorithm with ratio 
for ALWDR for , and then show that it
can be extended to general . The key idea of the algorithm
comes from the following simple observation that can be easily extended
from a lemma in\cite{lu2014data}.
\begin{prop}
All possible  retrieval sequences can be computed in 
time for ALWDR, where  is the number of the time slots.
\end{prop}
From the above proposition, a simple idea is first to solve each segment
of ALWDR individually (since a segment is an instance
of ALWDR with  time slots), and then to combine
the computed subsolutions to a whole solution. However, the difficulty
is how to guarantee that the subsolutions could compose a good solution.
To overcome the difficulty, we first compute all possible paths for
each segment of ALWDR, then give a LP formula for
ALWDR based on the set of paths. Based on the formula,
an approximation algorithm is developed by employing randomized rounding
technique. The approximation achieves the same ratio of  as
in \cite{lu2014data}, but is simpler and can be easily extended to
solve ALWDR (and ALWDR) for general .


\subsection{The LP Formula for Relaxation of ALWDR}

Let  be the auxiliary graph output by Algorithm \ref{alg:1Construction-of-Auxiliary}.
Let  be the vacant
time slots in ALWDR. Assume that  is the
part of  between  and , i.e. it corresponds
to the th segment of ALWDR. Let ,
where 
is the set of all the possible paths of  that correspond to
retrieve sequences. Each  is assigned with a weight .
Formally, our LP relaxation for ALWDR is as below:




In the above formula,  indicates  is selected,
and  otherwise. Inequality (\ref{eq:edl}) is to guarantee
that a feasible solution of LP (\ref{eq:LP}) contains at most one
edge of each , i.e. at most one edge for item .
If  , the above formula becomes an integral
programming (IP) formula for ALWDR.


\subsection{The Randomized Algorithm for ALWDR }

Let  be an optimal
solution to LP (\ref{eq:LP}), and  be its weight. The key
idea of our algorithm is to interpret the fractional value 
as the probability of selecting  for .
Then the algorithm is formally as in Algorithm \ref{alg:SCbased-randomized-algorithm}.

\begin{algorithm}
\textbf{Input: }, ,
where  is a
collection of paths of , with a weight ;

\textbf{Output:} , a solution to ALWDR
for .
\begin{enumerate}
\item ;
\item Solve LP (\ref{eq:LP}) against  for  by Karmarkar's
algorithm \cite{schrijver1998theory}, and obtain an optimal solution
;
\item \textbf{For}  to  \textbf{do }

\begin{enumerate}
\item Set  with probability ; /{*} 
is the element selected in . {*}/
\item ;
\end{enumerate}
\item Return .
\end{enumerate}
\protect\caption{\label{alg:SCbased-randomized-algorithm}A randomized algorithm for
ALWDR.}
\end{algorithm}

\begin{lem}
\label{lem:SCratioproof}Algorithm \ref{alg:SCbased-randomized-algorithm}
is a randomized -approximation algorithm
with a time complexity of 
for ALWDR for , where  is the maximum
length of input and  is the maximum occurrence times of  in
all . \end{lem}
\begin{IEEEproof}
The runtime of Algorithm \ref{alg:SCbased-randomized-algorithm}
is easy to calculate: Step 2 of the algorithm takes 
time to run Karmarkar's algorithm, where .
Then because other steps take trivial time compared to Step 2, the
total time is .

For the ratio, let  and  be the output of the algorithm
and its weight respectively. To calculate the expected value of the
output of the algorithm, it remains only to compute the probability
that none of the edges of  is in any .
Below is the probability that  for
every :




Then since 
is fixed, we assume that .
It is easy to see  attains maximum when




That is, when all elements of 
are the same, 
attains maximum , where  is the number of
the occurrence times of any edge of  appearing in all
. So edges of  have a probability of at most
 to be all absent from every . Now
we have all the ingredients for computing , the expectation
of :

Since  is the weight of an optimal solution to LP (\ref{eq:LP}),
 is not less than , the weight of an optimal solution
to ALWDR. Therefore, .
This completes the proof.
\end{IEEEproof}
By simple arithmetical calculation, it is easy to see the ratio will
be  when , be  when , and be  when
. Further, following the inequality as in Proposition \ref{prop:calK}
below, the ratio of our algorithm would be not less than .
\begin{prop}
\label{prop:calK} is a monotone increasing
function for .\end{prop}
\begin{IEEEproof}
The derivative of  is as in the following:


Because for , we have both 
and its derivative ,
 holds for any . That is, for any , 
is monotone increasing.
\end{IEEEproof}
The derandomization of Algorithm \ref{alg:SCbased-randomized-algorithm}
to ALWDR follows a similar line as the derandomization
of Section 4 (although it is a little more complicated). So we omit
it here.


\subsection{Extension to ALWDR}

In this subsection, Algorithm \ref{alg:SCbased-randomized-algorithm}
is extended to solve ALWDR for general . To do this,
two changes are needed for the algorithm: the first is to change the
formula of LP (\ref{eq:LP}), by setting the right part of the constraint
of Equality (\ref{eq:unimoforSC}) from 1 to  accordingly;
the second is to select  disjoint paths to round up simultaneously
for each , while Algorithm \ref{alg:SCbased-randomized-algorithm}
round up only one path for each . More precisely,
the second is to modify Step 3 of Algorithm \ref{alg:SCbased-randomized-algorithm}
as below:

\textbf{For} each 
with  for \textbf{
do }

\quad{}(a) Set 
with probability ,
where  is a set of 
disjoint paths in  and  is
the set of  paths selected from .

\quad{}(b) .
\begin{lem}
\label{lem:aArLWDRratioandtime}ALWDR admits an
approximation algorithm with ratio  and runtime .\end{lem}
\begin{IEEEproof}
The ratio can be obtained following exactly the same line of Lemma
\ref{lem:SCratioproof}.

For the time complexity, Step 2 takes 
time to solve LP (\ref{eq:LP}). Step 3 takes  time to select a  to round up, since it has to select
 paths among  paths which are all possible paths
in . Therefore, the total runtime is .
This completes the proof.
\end{IEEEproof}

\section{Approximation Algorithms for ALWDR under Occurrence
Assumption}

The section will give an algorithm to approximate ALWDR
within a factor of  for general , under the
\textbf{occurrence assumption} that every item is broadcast at most
once in each segment. To do this, an approximation algorithm is first
given for ALWDR for , with the key idea
of collectively and randomly rounding fractional edges according to
an optimum solution to LP (\ref{eq:theoriginalLP}). Later, the algorithm
is derandomized using an interesting method based on conditional expectation.

For all the algorithms in this section, the key observation is that
the high time complexity of Algorithm \ref{alg:SCbased-randomized-algorithm}
mainly comes from the large size of , ,
where  is the number of the channels and  the length
of a segment. The basic idea of the algorithms is to compute the necessary
paths only, instead of computing all possible paths. To do this, we
release paths (or more precisely subflows) from the fractional flow
of an optimum solution to LP (\ref{eq:theoriginalLP}). Those released
paths compose the set of necessary paths for each .
An integral solution to ALWDR can then be obtained
by rounding such fractional paths.


\subsection{A Randomized Algorithm for ALWDR under Occurrence
Assumption}

Our algorithm is mainly composed by the following steps: first to
compute an optimum solution against LP (\ref{eq:theoriginalLP}) for
the constructed graph , output by Algorithm \ref{alg:1Construction-of-Auxiliary}
for an given ALWDR instance; then for each -separated
segment, the algorithm releases a set of subflows with fractional
value from the computed solution; later, the value of each subflow
is randomly rounded to 1 with probability proportional to the original
value. Eventually, the combination of the rounded subflows of each
-separated segment will collectively compose an integral
solution to ALWDR. The full layout of the algorithm
is as in Algorithm \ref{alg:theflows-randomized-algorithm}.

\begin{algorithm}
\textbf{Input: }Auxiliary graph  corresponding to an instance
of ALWDR with occurrence assumption and ,
in which  is corresponding for the th segment of ALWDR;

\textbf{Output:} A solution to ALWDR.
\begin{enumerate}
\item Solve LP (\ref{eq:theoriginalLP}) against  by Karmarkar's algorithm
\cite{schrijver1998theory}, and obtain an optimal solution ;
\item \textbf{For}  to  \textbf{do}

\begin{enumerate}
\item For the flow corresponding to , divide the part in 
into a set of subflows, say 
where  is with value ,  by
using Algorithm \ref{alg:Comp_Fh} (given later);
\item Round the value of  to 1 with probability ;
\end{enumerate}
\item Return the set of the subflows with value 1 as a solution to ALWDR.
\end{enumerate}
\protect\caption{\label{alg:theflows-randomized-algorithm}A collective randomized
rounding algorithm for ALWDR.}
\end{algorithm}

\begin{lem}
\label{lem:flowOAtime}Algorithm \ref{alg:theflows-randomized-algorithm}
outputs a solution for ALWDR within runtime ,
where  is the maximum length of the input.\end{lem}
\begin{IEEEproof}
Step 1 of the algorithm runs Karmarkar's algorithm and takes 
time to solve LP(\ref{eq:LP}) wrt the auxiliary graph , since
the number of the constraints of LP (\ref{eq:LP}) is .
According to Lemma \ref{lem:ratioOAflowLPadmits} (which is given
later), Step 2 takes  time to compute
each , and the rounding time for each 
is . So the
total time of Step 2 is . Therefore,
the total time complexity of Algorithm \ref{alg:theflows-randomized-algorithm}
is .
\end{IEEEproof}
Let  be the number of channels and  be the number of time
slots. Recall that  equals to the number of all
the occurrences of the data items , and 
according to the construction of  as Algorithm \ref{alg:1Construction-of-Auxiliary}.
However, as will be shown in Section V,  can be
decreased to . So the runtime
of Algorithm \ref{alg:theflows-randomized-algorithm} is actually
.
\begin{lem}
\label{lem:ratioOAflowLPadmits}Algorithm \ref{alg:theflows-randomized-algorithm}
is a randomized -approximation algorithm
for ALWDR, where  is the maximum occurrence
times of  in the subflows in the time interval. \end{lem}
\begin{IEEEproof}
Let  and  be the output of the algorithm and the optimum
solution of ALWDR, respectively. We shall show ,
where  is the expectation of . Let 
be the weight of an optimum solution to LP (\ref{eq:theoriginalLP})
against . Since , it remains only to show
. Thus, we will
calculate how much weight is expected to lose during the rounding
procession. For item , assume that

where  is the value of flow  which contains .
Then the probability that the algorithm does not pick  is:




Then since 
is fixed, we assume that .
Similar to the proof of Lemma \ref{lem:SCratioproof}, it is easy
to see  attains maximum when




That is,  attains maximum when every 
is with the same value. Then the probability that the algorithm does
not pick any edge corresponding to  is at most:




where  is the number of the occurrences of , ,
in all subflows, i.e. , . So the expectation
of item  being picked is .
Therefore the expectation of  is:

This completes the proof.
\end{IEEEproof}
It remains to give the division of the subflows for Algorithm \ref{alg:theflows-randomized-algorithm}.
Let  be
an optimal solution to LP (\ref{eq:LP}). W.l.o.g., assume that we
are processing the edges of , and ,
i.e.  is the set of edges with  in .
The key idea of the computation is to repeatedly select an edge 
with minimum , and then construct in  a flow (which
is also a single path) of value  going through , until
every edge  in  is with . The detailed algorithm
is shown in Algorithm \ref{alg:Comp_Fh}.

\begin{algorithm}
\textbf{Input}: ,  and ,
an optimum solution to LP (\ref{eq:theoriginalLP});

\textbf{Output}: .
\begin{enumerate}
\item Set , ;
\item Set , , ;
\item \textbf{For }each  \textbf{do}

\begin{enumerate}
\item \textbf{If}  \textbf{then}


;

\end{enumerate}

/{*}Find an edge  with  for
any . {*}/

\item ;
\item Set ;
\item \textbf{While}  has preceding edges \textbf{do}

\begin{enumerate}
\item Select one of the preceding edges, say ;
\item Set , , and ;
\end{enumerate}

\textbf{EndWhile}


/{*}Add the part of  before  to .{*}/

\item \textbf{While}  has successor edges \textbf{do}

\begin{enumerate}
\item Select one of the successor edges, say ;
\item Set , , and ;
\end{enumerate}

\textbf{EndWhile}


/{*}Add the part of  after  to .{*}/

\item Set  and ;
/{*}Add  to .{*}/
\item \textbf{For} each  \textbf{do}


If  \textbf{then} ;

\item \textbf{If}  \textbf{then}


Set  and go to Step 2;


\textbf{Else} return .

\end{enumerate}
\protect\caption{\label{alg:Comp_Fh}Computation of .}
\end{algorithm}

\begin{lem}
\label{lem:timeofcompFh}Algorithm \ref{alg:Comp_Fh} runs in 
time, and correctly computes a set of flows 
for , such that 
and  holds for each .\end{lem}
\begin{IEEEproof}
Algorithm \ref{alg:Comp_Fh} iterates Step 2-10 at most 
times, since each iteration removes at least one edge from .
In each iteration, Step 6 and 7 need to verify all edges of 
in the worst case, which is at most . So Algorithm \ref{alg:Comp_Fh}
runs in  time.

For , according to Algorithm \ref{alg:Comp_Fh},
the size of  decreases at least one when a new flow is added
to , since at least an edge  with its 
set to 0 is removed from . So .
For the latter part,  clearly
holds since Algorithm \ref{alg:Comp_Fh} decreases  from
 if and only if .
\end{IEEEproof}
Similar to the extension of Algorithm \ref{alg:SCbased-randomized-algorithm}
to ALWDR, and the analysis of Lemma \ref{lem:aArLWDRratioandtime},
it is easy to extend Algorithm \ref{alg:theflows-randomized-algorithm}
to ALWDR for general . Hence, the extension
is omitted.


\subsection{Derandomization}

The main idea of our derandomization is inspired by the derandomization
technique using conditional expectations as implicitly given in \cite{erdos1973combinatorial}
and formally given in the book \cite{spencer1987ten}. That is, to
pick  for  in a greedy and sequential way:
the flow for  is first to select, then ,
, , and so on. Assume that the selection
of the flow for  is complete,
and the algorithm is currently selecting flow for 
against ,
where  is the flow already selected (i.e., 
is rounded to 1) for , and  contains only
the edges corresponding to data items to be covered in future. Our
algorithm selects for  for the flow 
with  maximized. The detailed
algorithm is shown in Algorithm \ref{alg:the1stderandomization}.
Why the algorithm removes the edges of 
from  is that, if the edge corresponding to item 
is already in , the weight of the retrieve
sequence will not increase by covering any edge corresponding to the
same item  for later processing.

\begin{algorithm}
\textbf{Input: },
where  is a collection of flows for
the th segment of ALWDR;

\textbf{Output:} , a solution to ALWDR.
\begin{enumerate}
\item ;
\item Solve LP (\ref{eq:theoriginalLP}) by Karmarkar's algorithm \cite{schrijver1998theory},
and obtain an optimum solution ;
\item \textbf{For}  to  \textbf{do }

\begin{enumerate}
\item \textbf{For} each  \textbf{do}


\quad{}Set ;


\quad{}/{*}  is the weight of  plus the expected
weight sum of edge  selected at probability
. {*}/

\item Select , such that  for
every ;
\item 
\end{enumerate}
\item Return .
\end{enumerate}
\protect\caption{\label{alg:the1stderandomization}Derandomization of Algorithm \ref{alg:theflows-randomized-algorithm}.}
\end{algorithm}

\begin{lem}
The ratio of Algorithm \ref{alg:the1stderandomization} is .\end{lem}
\begin{IEEEproof}
Let  denote the expectation weight sum of
edges  picked at probability , i.e.




Then  is equal to , the expectation
of the weight of the output of Algorithm \ref{alg:theflows-randomized-algorithm}.
So we need only to show ,
provided that  holds according
to Lemma \ref{lem:ratioOAflowLPadmits}.

First, for the last iteration, the algorithm picks 
with maximum  among all s in , so
the following inequality obviously holds:




Consider that we are selecting for , then since  is
chosen to attain maximum , we have:




Then, combining Inequality (\ref{eq:defofEX}) and (\ref{eq:main-2})
yields




Summing up Inequality (\ref{eq:deranfori}) for every ,
and combining with Inequality (\ref{eq:N}), we have:




That is, .
This completes the proof.
\end{IEEEproof}

\section{An Improved Approximation Algorithm for General ALWDR}

In this section, we shall show that Algorithm \ref{alg:theflows-randomized-algorithm}
can be extended to approximate general ALWDR within
the same factor of , without the occurrence assumption.
The key observation is that Algorithm \ref{alg:theflows-randomized-algorithm}
cannot produce a good approximation ratio for ALWDR
since a fractional flow can contain two edges corresponding to an
identical data item. So the idea of the extension is to construct
an improved auxiliary graph in which different edges of an identical flow
is corresponding to distinct data items. Then, the algorithm is to
employ the collectively flow rounding method based on LP (\ref{eq:thedualLP})
given in this section against the improved auxiliary graph, and obtain
an approximation solution with the same ratio .


\subsection{A Refined Construction and a Dual LP Formula}

Before giving the auxiliary graph where our algorithm can work correctly,
we would like first to give a refined construction of , which
significantly decreases the number of edges of , from 
to , where  is the number of the channels.
The key observation of the refined construction is that for a valid
retrieve sequence of LWDR, the constructed graph need only to contain
an -path with all the edges, but not necessarily exactly the
same edges corresponding to the data items in the retrieve sequence.
Hence, we need only to construct a DAG satisfying Lemma \ref{lem:refinedconst}.
The key idea of the construction is to connect the head of an edge
to only one edge in every channel.

However, as analyzed later, LP (\ref{eq:theoriginalLP}) is not suitable
for ALWDR with respect to the construction. Besides
the main part of , it requires an additional virtual part to collaborate
a new LP relaxation. The full layout of the construction is in Algorithm
\ref{alg:RefinedConstruction}.

\begin{algorithm}
\textbf{Input: }An instance of ALWDR;

\textbf{Output:} .
\begin{enumerate}
\item Set , , ; /{*}Initialization.
 is for the main part that corresponding to ALWDR;
 the additional virtual part for a new LP relaxation.{*}/
\item For every item :


\textbf{\quad{}}Add an edge set 
to , where ;

\item Add two vertices  and  with weight-0 edges to  as
below:

\begin{enumerate}
\item Edge  with minimum  for every ;
\item Edge  with maximum  for every ;;
\end{enumerate}
\item \textbf{For}  to  \textbf{do}


\textbf{\quad{}For}  to  \textbf{do \quad{}}/{*} Add edges
for the relationship between the items. {*}/


\textbf{\quad{}\quad{}If} edge  exists
\textbf{then}


\textbf{\quad{}\quad{}\quad{}}Add weight-0 edge 
to  with minimum ;


\textbf{\quad{}\quad{}\quad{}}Add weight-0 edge 
to  with minimum  for every ;


\textbf{\quad{}\quad{}EndIf}


/{*}For each item add an edge from  to the tail of the
edge corresponding to the nearest item that could be retrieved conflict-freely
afterward.{*}/

\item \textbf{For} every item  \textbf{do}


\textbf{\quad{}}Add edges  and ,
as well as the edges  and ,
to  where  and , other edges
are all with cost 0.


/{*} The construction of . Note that ,
, and .{*}/

\item Add edges  and  to ;


/{*} Add the connection between  and . {*}/

\item Return .
\end{enumerate}
\protect\caption{\label{alg:RefinedConstruction}Construction of Auxiliary Graph for
ALWDR. }
\end{algorithm}

\begin{lem}
\label{lem:refinedconst} is a valid retrieve sequence for ALWDR
if and only if in the constructed graph of Algorithm \ref{alg:RefinedConstruction}
there exist  disjoint \textbf{-}paths whose corresponding
retrieve sequences contain every item of .  \end{lem}
\begin{IEEEproof}
We shall only show the lemma holds for the case , since
the case for general  is similar.

For the ``only if'' direction, let ,
 for any , be a retrieve sequence for an instance
LWDR, where  is data item  retrieved
in channel  and time slot . If 
can be retrieved after , then the two data
items must be conflict-free. That is, 
and  are either (1) in the same channel, i.e.
; or (2) in different channels and .
According to the construction of , there will be an edge leaving
, the head of the edge corresponding to item
, and entering ,
the tail of the edge corresponding to a conflict-free data item 
for the minimum . Then according to the construction again,
there exists a path from  to .
That is, every  is reachable from .
Therefore, 
is an  path in .

For the ``if'' direction, assume that there exists a path 
,
, in . According to the construction, for any
edge , 
holds or  and  both hold. That is,
the items retrieved in time slot  and , say 
and  can be retrieved conflict-freely.
So  is a valid
retrieve sequence. These completes the proof.
\end{IEEEproof}
It is easy to see that the DAG  resulting from Algorithm \ref{alg:RefinedConstruction}
has a much smaller size compared to the previous construction as in
Algorithm \ref{alg:1Construction-of-Auxiliary}, as stated below:
\begin{lem}
\label{lem:sizeofrefined}In the constructed graph , there exist
at most  vertices, and at most  edges.\end{lem}
\begin{IEEEproof}
Clearly, we have . That is because we
add an edge for each occurrence of the data items in the construction,
and the number of the occurrences is at most . Then
since there exist at most  edges leaving a vertex, .
\end{IEEEproof}
We now argue that LP (\ref{eq:theoriginalLP}) is no longer a relaxation
for ALWDR with respect to the above refined construction.
Because for a solution of ALWDR, there might exist
no -path with exactly the edges corresponding to the retrieved
sequence, i.e. because a path in  might contain two edges that
corresponding to an identical data item (See figure \ref{fig:A-Refined-Construction}
for an example: The path, corresponding to the retrieve sequence containing
, is forced to go through both edges 
and , which are corresponding to the an identical
item). But according to Inequality (\ref{eq:keyconstr}), 
should hold. Therefore, it remains to give a new LP formula for ALWDR
with respect to  resulted from the refined construction. To do
so, we first add a virtual part to , and then give an LP formula,
which allows a path in  to contain multiple edges corresponding
to an identical item. Then the LP formula is as below:


where  iff  is selected and  otherwise. If
, then from Lemma \ref{lem:refinedconst}, the
above formula becomes an integral programming (IP) formula for ALWDR.
The intuitive explanation of the above LP is as below: Let ,
let  be the minimum of the objective function of the IP corresponding
to LP (\ref{eq:LP}), and let  be the weight of an optimal
solution to the corresponding ALWDR instance. Then,
we have

Because  is fixed, it is identical either to maximize 
or to minimize .

Then based on the new LP formula, Algorithm \ref{alg:theflows-randomized-algorithm}
can be immediately adopted to solve ALWDR. Following
the same line of Lemma \ref{lem:ratioOAflowLPadmits} and \ref{lem:flowOAtime},
and then Lemma \ref{lem:sizeofrefined} on the sized of , we have
the following Theorem:
\begin{thm}
Under the occurrence assumption, ALWDR admits an
algorithm with ratio  and a time complexity .
\end{thm}
\begin{figure}
\includegraphics{fig3refinedconstr.eps}

\protect\caption{\label{fig:A-Refined-Construction}A refined construction of DAG:
(a) An instance of LWDR; (b) The refined corresponding graph. }
\end{figure}



\subsection{Construction of the Improved Auxiliary Graph}

This subsection will further improve the auxiliary graph output by
Algorithm \ref{alg:RefinedConstruction}, such that in the improved
auxiliary graph any path in a segment will not go through two edges
corresponding to an identical data item. Thus, the improved auxiliary
graph can be considered as a graph satisfying the occurrence assumption,
and hence Algorithm \ref{alg:theflows-randomized-algorithm} can be
employed to solve the ALWDR problem accordingly.
The key idea of the improved construction is to find and eliminate
every pair of edges which correspond to an identical data item and
appear in a common path within a segment. The detailed construction
of the improved auxiliary graph is in Algorithm \ref{alg:enhanced-construction},
where w.l.o.g. we assume the ALWDR instance has
only one segment, since the case for multiple segments is similar.
An example of execution of the algorithm is depicted in Figure \ref{fig:oneoccuranceitem}.

\begin{algorithm}
\textbf{Input: }A refined auxiliary graph  (for ALWDR
with one segment) output by Algorithm \ref{alg:RefinedConstruction};

\textbf{Output: }A graph , in which no flow exists containing
two edges corresponding to an identical data item.
\begin{enumerate}
\item ;
\item \textbf{For}  to  \textbf{do}

\begin{enumerate}
\item \textbf{For} each edge  \textbf{do
}/{*}\textbf{ }is the subgraph of  from time
slot  to .{*}/


\quad{}Add a corresponding edge duplicating , say ,
to , assuming it is the th time duplicating ;


\quad{}/{*}Duplicate  by duplicating every edge
therein. {*}/

\item \textbf{For}  to  \textbf{do}


\quad{}\textbf{while} there exist both edge 
and edge  with , such that 
is reachable from  \textbf{do}


\quad{}/{*}There exist a path containing 2 edges both corresponding
to item .{*}/


\quad{}\quad{}(i) Replace each edge ended at , say ,
with  in ;


\quad{}\quad{}(ii) Replace each edge ended at ,
say , with  in
;

\end{enumerate}

\textbf{Endfor}

\item Return .
\end{enumerate}
\protect\caption{\label{alg:enhanced-construction}The construction of an improved
auxiliary graph.}
\end{algorithm}

\begin{lem}
\label{lem:timeofalgf}In runtime ,
Algorithm \ref{alg:enhanced-construction} outputs a graph  with
at most  edges, where  is
the maximum length of a segment of ALWDR. 
has a size, i.e. , not larger than ,
and every path therein contains at most one edge of  for
each item  within a segment. \end{lem}
\begin{IEEEproof}
For the time complexity, Step 2 of Algorithm \ref{alg:enhanced-construction}
repeats at most  times, each of which at most doubles
the size of . Since  is initially , 
holds at the beginning of the th iteration. In this iteration,
it takes  time to duplicate the edges (in Step 2(a)) and
takes  time to check for  for every
 that whether there exists a path containing 2 edges both corresponding
to an identical item (in Step 2(c)). So the total runtime of the algorithm
is .
In addition, we also have .

According to Algorithm \ref{alg:enhanced-construction}, the th
iteration guarantees that no path can contain both edge 
and another edge corresponding to . Therefore, when Algorithm
\ref{alg:enhanced-construction} terminates, all paths containing
2 edges corresponding to an identical item are eliminated. This completes
the proof.
\end{IEEEproof}
\begin{figure}
\includegraphics{fig4FPTimpr.eps}

\protect\caption{\label{fig:oneoccuranceitem}An construction of the improved DAG.}
\end{figure}


\begin{figure}
\includegraphics[scale=0.8]{fig5finalAUXI.eps}

\protect\caption{\label{fig:oneoccuranceitem-1}An construction of the improved DAG
(continued)}
\end{figure}


The correctness of Algorithm \ref{alg:enhanced-construction} can
be immediately obtained from the following lemma:
\begin{lem}
\label{lem:finalgra}There exists -disjoint -path 
in  if and only if there exists in   disjoint \textbf{-}paths
, such that their corresponding retrieve
sequences\textbf{ }contain identical data items.\end{lem}
\begin{IEEEproof}
Let  and  be two edges in  output by
Algorithm \ref{alg:RefinedConstruction}, where  means
that data item  appears in channel  at time slot .
According to the construction of  as in Algorithm \ref{alg:enhanced-construction},
if  and  connected in , then any duplication
of  and that of  are connected in 
when . Let  containing edges ,
, be a path in , where e  is the minimum
time slot where 's corresponding edges appear on the path
. Then there must exist a path  containing 
in , where  means any duplication
of . Therefore, there exists  in 
which retrieves the same data items 
as  does. Similarly and conversely, we can construct a path 
in  from Q in , such that  and  contain identical
data items. This completes the proof. \end{IEEEproof}
\begin{thm}
\label{thr:kagammaLWDR} ALWDR admits an approximation
algorithm with a ratio  and a time complexity ,
where  is the number of channels,  is the number of time slots,
and  is the maximum length of the input.\end{thm}
\begin{IEEEproof}
The ratio can be easily obtained by combining Lemma \ref{lem:finalgra}
and \ref{lem:ratioOAflowLPadmits}. For the time complexity, it takes
 time to solve LP (\ref{eq:thedualLP}),
since the number of the constraints is  \cite{korte2002combinatorial}.
Then by Lemma \ref{lem:timeofalgf}, the runtime 
follows.
\end{IEEEproof}
For any given , by setting 
when transforming from ALWDR to ALWDR,
and then combining Theorem \ref{thr:kagammaLWDR} and Proposition
\ref{prop:simpobsbetw-gamma}, we have:
\begin{thm}
\label{thm:finalratioforkLWDR}For any fixed , ALWDR
admits an approximation algorithm with a ratio 
and a runtime .
\end{thm}
As a by-production, it can be shown that ALWDR is fixed parameter
tractable with respect to the parameter ``'':
\begin{cor}
ALWDR admits an exact algorithm with a time complexity ,
where  is the number of time slots containing data items which
has occurrences in subsequent time slots.\end{cor}
\begin{IEEEproof}
For any instance of ALWDR, the exact algorithm is first to
run Algorithm \ref{alg:enhanced-construction} against the instance,
and then to solve the according LP \ref{eq:thedualLP} to get a basic
optimum solution. Then since 
from Lemma \ref{lem:timeofalgf}, the time complexity of the exact
algorithm would be  in worst case. For the
correctness, from Lemma \ref{lem:timeofalgf}, in  there exists
no path containing two edges corresponding to one identical item.
That is, the task remains only to compute a set of -disjoint
longest paths in , which is corresponding to an optimum solution
for ALWDR. Following the same line of the proof of Theorem
\ref{Thr:LWDR-is-polynomial-1}, the task can be done in polynomial
time .
\end{IEEEproof}

\section{-Completeness of ALWDR }

In this section, we show that ALWDR remains -complete
for , by giving a reduction from the 3-dimensional perfect
matching (3DM) problem, which is known -complete \cite{garey1979computer}.
Moreover, the -completeness remains true even when there
are only three channels, every item is with the same weight and appears
at most 3 times.

For a given positive integer  and a set 
where ,  and  are disjoint and , 3DM is
to decide whether there exists a perfect matching for , i.e.,
a subset  with , such that no elements in
 agree in any coordinate.
\begin{thm}
\label{thm:kagammaLWDR-is-NP-complete,} ALWDR is
-complete even when .
\end{thm}
Since ALWDR is evidently in , we need
only to give the reduction from 3DM to the decision form of ALWDR:
Given a positive integer  and , a set of items of equal weight
1 broadcast in the channels in a time interval, does there exist a
retrieve sequence of  with total weight not less than ?

For an instance of decision 3DM, the construction of the corresponding
ALWDR instance is simply as below (An example of
the construction is depicted in Figure \ref{fig:nproof}):
\begin{enumerate}
\item For each element of , say , add 3 time slots ,
,  to the time interval, which are initially
empty time slots;
\item For each element of , say 
where  is the
th occurrence of , broadcast two items  and  in
time slots  and  of channel , respectively.
\end{enumerate}
\begin{figure}
\includegraphics{Fig6NPproof.eps}

\protect\caption{\label{fig:nproof}An instance of ALWDR corresponding
to the following instance of 3DM: .}
\end{figure}

\begin{IEEEproof}
Note that in the instance of ALWDR constructed as
above, clearly . We need only to show that an instance
of 3DM is feasible if and only the corresponding ALWDR
is feasible for .

Firstly, assume that for the given 3DM instance there exists a perfect
matching, say ,
such that no elements in  agree in any coordinate, i.e. for any
, 
holds. Then for the constructed ALWDR instance,
clearly 
is a feasible solution with .

Conversely, assume that 
is a feasible solution with  to ALWDR.
Then each data item in  is distinct, because for every ,
 and  must contribute weight 2 to the total weight.
That is, for any , .
Therefore, 
is a perfect matching for the given 3DM instance. This completes the
proof.
\end{IEEEproof}
Further, the -completeness remains true even for a very
special case of ALWDR :
\begin{cor}
ALWDR is -complete, even when ,
only three channels exist, and every item is with equal weight and
appears at most 3 times in the time interval.\end{cor}
\begin{IEEEproof}
It is known that 3DM is -complete even if the number of
occurrences of any element in ,  or  is bounded by ``3''
\cite{kann1991maximum}. According to the transformation, because
of the bound ``3'' on element occurrences of 3DM, both the number
of channels and the occurrences of any data item can be bounded by
3.
\end{IEEEproof}

\section{Performance Evaluation}

In this section, we show performance evaluation of our algorithms
(RFA, Algorithm \ref{alg:theflows-randomized-algorithm}) by experiments,
and compare our algorithms with the approximation algorithm adopting
maximum weight matching (MM, as in \cite{Infocom12LuEfficient}) when
. Experimental results comparing our algorithm with an
exactly algorithm (EA, based on integral linear programming (ILP))
for  is also given in the appendix. We implement the algorithms
using python 2.7, on a PC with Mac OS X Yosemite, 1.4 GHz Intel Core
i5 processor, and 8GB 1600MHz DDR3 memory. Other than our proposed
algorithm, we also implement the maximum matching heuristic, and the
exact algorithm (EA). Our implementation uses the \emph{networkx}
library to construct both the auxiliary graphs of RFA and MM, the
interior-point method of the \emph{GLPK} library to solve LPs and
the simplex method of \emph{GLPK }to\emph{ }solve ILPs.


\subsection{Methodology}

To evaluate our algorithms, we simulate push-based broadcast programs.
We denote the number of down-link channels by , the total number
of time slots by , the total number of broadcasting data items
by , and the number of the packets in a request by . In our
experiments,  is set in the range of ,  in ,
 in , and  in . We assume that
all the channels are with uniform bandwidth, and all broadcast data
items are with the same size. Besides, for RFA, we set the value of
 in . In our experiments, for a given the skewed
parameter , we also assume the access probability of a data
item  for a request follows the Zipf distribution :




We use average download percentage (ADP) as the performance metric,
and simulate 10,000 requests to get ADP for each experiment.


\subsection{Experimental Results }

The simulation results comparing RFA and MM are depicted in Figure
\ref{fig:gamma}. In all the experiments, the ADP of RFA always achieves
better performance than that of MM: by about 20-32 percent in Figure
\ref{fig:gamma} (a), and by about 9-20 percents in Figure \ref{fig:gamma}
(b). These results are actually better than our analysis. This phenomenon
is reasonable, because our algorithm is based on rounding a fractional
solution of the LP relaxation of the problem. In many cases, rounding
such an LP optimal solution could result in actually a much better
ADP than the worst case as analyzed. Comparing Figure \ref{fig:gamma}
(a) and Figure \ref{fig:gamma} (b), we find the ADP of RFA decreases
when  increases. That is because the problem becomes more complicated
when  grows, and hence the quality of the solution decreases accordingly.
However, RFA still significantly outperforms MM when , although
the gap between them decreases. For the relationship between ADP and
, as shown in Figure \ref{fig:gamma} (a) and (b), the ADP
of RFA increases when  increases. This is consistent with
our analysis of Algorithm \ref{alg:theflows-randomized-algorithm}:
as  increases,  then decreases,
and hence the approximation ratio  increases.
In particular, as we could see in Figure \ref{fig:gamma}(a), ADP
increases significantly from roughly 78 to 86 percents, when 
increases significantly from 4 to 12; when , the impact
of  over ADP grows inefficiently, i.e. ADP barely increases
when  increases. Then ADP attains the maximum at about 88
percents at , and then ADP decreases when 
grows. While  is 8 instead of 2 in Figure \ref{fig:gamma}(b),
the weight increasing upon 's increment remains efficient
until . Thus, for a more complicated instance, the increment
of  benefits for a larger range.

\begin{figure}
\subfloat[, n=400, .]{\includegraphics[width=0.5\columnwidth]{m2mm}

} \subfloat[, n=1600, .]{\includegraphics[width=0.5\columnwidth]{m8_gamma.eps}

}

\protect\caption{\label{fig:gamma}LWDR, , . }
\end{figure}


The simulation results on the runtime of the algorithms are as given
in Table \ref{tab:Runtime-analysis.}, in which three parameters are
considered: ,  and , since according to our theoretical
analysis in the previous section, these parameters are the factors
that affect the runtime of the algorithm. In all the runtime experiments,
the parameters are set ,  and , where
 is set, since most of the mobile devices in not-long future
is likely to have two antennae, provided that the current mobile devices
are mostly with only one antenna. Then  is a reasonable number
of channels for , while  is likely the value
of  with best performance time ratio. Comparing the runtime
of RFA and EA, we can see that the runtime of RFA is significantly
lower than EA, particularly when the problem size is large, i.e. the
involved  is with size 500. Better still, the gap between them
grows when the size of the problem increases. It is worth to note
that, the time of EA is mostly the time of solving ILP, while the
solver of ILP used in EA is the \emph{GLPK} ILP solver, a mature package
that is almost perfectly implemented. That is, with better implementation
of RFA, RFA could have a runtime over EA even better than as in the
table. On the other hand, we note that the runtime of RFA is higher
than MM when the problem size is large. The high runtime mainly comes
from the cost of solving the LP formula. When ,  and
, the algorithm is to solve an LP of size about 20,000.
However, we argue the algorithm has practical values. Firstly, the
algorithm can be implemented in a better way. The current implementation
is based on Python, so the runtime could be better if the algorithm
is implemented in other languages such as C or C++ that is known with
a better performance. Besides, the open source library \emph{GLPK}
that we used to solve LP, takes almost 500s to solve an LP of size
20, 000. Note that this runtime could be improved if using some other
commercial libraries such as \emph{Gurobi optimizer} which as claimed
is more efficient than \emph{GLPK} and can solve LP with up to millions
of variables in a reasonable time. Last but not least, there are a
lot of efficient approximation algorithms that solve LP even faster,
adopting which could further improve the runtime of our algorithms.
Secondly, even with our simple implementation, the average runtime
of our algorithm is 500ms for LWDR with the number of request data
items of 100 and a channel number of 8. Therefore, Algorithm \ref{alg:theflows-randomized-algorithm}
has the potential to be applied in real networks.

\begin{table*}
\protect\caption{\label{tab:Runtime-analysis.}Runtime analysis.}


\subfloat{\centering{}\begin{tabular}{|c|l|l|l|}
\hline
Problem size of ()  & RFA(s) & MM & EA(s)\tabularnewline
\hline
\hline
(100, 5, 10) & 0.68 & 0.115 & 1.54\tabularnewline
\hline
(150, 5, 10) & 2.22 & 0.245 & 3.07\tabularnewline
\hline
(200, 5, 10) & 4.27 & 0.434 & 6.56\tabularnewline
\hline
(250, 5, 10) & 8.03 & 0.655 & 13.10\tabularnewline
\hline
(300, 5, 10) & 13.08 & 0.950 & 19.54\tabularnewline
\hline
(350, 5, 10) & 18.54 & 1.27 & 28.08\tabularnewline
\hline
(400, 5, 10) & 25.17 & 1.70 & 38.92\tabularnewline
\hline
(450, 5, 10) & 32.48 & 2.09 & 58.56\tabularnewline
\hline
\end{tabular}}\subfloat{\centering{}\begin{tabular}{|c|l|l|l|}
\hline
Problem size of ()  & RFA(s) & MM & EA(s)\tabularnewline
\hline
\hline
(500, 5, 10) & 41.34 & 2.60 & 83.79\tabularnewline
\hline
(550, 5, 10) & 54.53 & 3.19 & 117.23\tabularnewline
\hline
(600, 5, 10) & 71.46 & 3.75 & 153.37\tabularnewline
\hline
(650, 5, 10) & 89.84 & 4.38 & 214.28\tabularnewline
\hline
(700, 5, 10) & 110.67 & 5.07 & -\tabularnewline
\hline
(750, 5, 10) & 132.80 & 6.60 & -\tabularnewline
\hline
(800, 5, 10) & 158.78 & 7.42 & -\tabularnewline
\hline
(900, 5, 10) & 217.22 & 8.35 & -\tabularnewline
\hline
\end{tabular}}
\end{table*}



\section{Conclusion }

We proposed a ratio  approximation algorithm
for the -antennae largest weight data retrieval (ALWDR)
problem that has the same ratio as the known result but a significantly
improved time complexity of 
from  when 
\cite{lu2014data}. To our knowledge, our algorithm is the first ratio
 approximation to ALWDR for the
general case of arbitrary . To achieve this, we first gave
a ratio  algorithm for the -separated ALWDR
(ALWDR) with runtime , under
the assumption that every data item appears at most once in each segment
of ALWDR, for any input of maximum length  on
 channels in  time slots. Then, we show that we can retain
the same ratio for ALWDR without this assumption
at the cost of increased time complexity to .
This result immediately yields an approximation solution of similar
ratio and time complexity for ALWDR, presenting a significant
improvement of the known time complexity of ratio 
approximation to the problem.


\section*{Acknowledgment}

This work is supported by Australian Research Council Discovery Project
DP150104871, \textcolor{black}{Natural Science Foundation of China
\#61300025 and} Research Initiative Grant of Sun Yat-Sen University
under Project 985. The corresponding author is Hong Shen.

\bibliographystyle{plain}
\bibliography{disjointQoS}



\section*{Appendix}


\subsection*{A Transformation from an Approximation for ALWDR
to an Approximation for ALWDR }

Let  be a ratio  approximation with a runtime
 for ALWDR. Then a simple
approximation for ALWDR with runtime 
and ratio  is as in Algorithm \ref{alg:Transformation-1}.

\begin{algorithm}
\textbf{Input: }A fixed , and an instance of ALWDR
(i.e., a set of data items to download 
with weights , together with their occurrences
in channels and time slots );

\textbf{Output:} A retrieval sequence.
\begin{enumerate}
\item \textbf{For}  to 
\textbf{do}


\textbf{For}  to 
\textbf{do}


\textbf{}Set 
as a vacant time slot, i.e., remove any item broadcast in 
;


\textbf{EndFor}


\textbf{}Run  against the instance and obtain a
retrieval sequence ;


\textbf{EndFor}

\item Return  with  .
\end{enumerate}
\protect\caption{\label{alg:Transformation-1}An approximation algorithm for ALWDR
by transformation.}
\end{algorithm}



\subsubsection*{Proof of Proposition \ref{prop:simpobsbetw-gamma}}
\begin{IEEEproof}
Let  be an optimum solution to the original ALWDR.
Let ALWDR be ALWDR but with 
vacant for each .
Assume that  is the set of items in  being set vacant.
Then  is an optimum solution to ALWDR.
Let  be the best solution among all s. It
suffices to show .

From definition of , we have

Then

Then

This completes the proof.
\end{IEEEproof}
Following the above proof, we immediately have an approximation algorithm
for ALWDR by the transformation as in Algorithm \ref{alg:Transformation-1}.


\subsection*{Performance Evaluation for \textmd{\normalsize{}ALWDR} with
}

For , the experimental results comparing the performance
of RFA and EA are depicted in Figure \ref{fig:lpvsilp}, where ,
n=100 for Figure \ref{fig:lpvsilp} (a), , n=200 for Figure
\ref{fig:lpvsilp} (b), and  grows from 2 to 22 in both figures.
The exact algorithm is to solve the integer linear programming (ILP)
formula which is LP (\ref{eq:theoriginalLP}) but with integral .
Figure \ref{fig:lpvsilp} shows that EA performs roughly 17-30 percents
better than RFA when , and 20-35 percents when . Since
EA always produces an optimum solution, this indicates the practical
ratio between the output solution of RFA and EA is better than our
analysis, similar to the case in Figure \ref{fig:gamma}. Besides,
also like the case in Figure \ref{fig:gamma}, when  grows
the performance of RFA also gets better. The increment of 
benefits efficiently until  in Figure \ref{fig:lpvsilp}
(a) and until  in Figure \ref{fig:lpvsilp} (b).

\begin{figure}
\subfloat[, n=100, .]{\begin{centering}
\includegraphics[width=0.5\columnwidth]{m2.eps}
\par\end{centering}

} \subfloat[, n=200, .]{\includegraphics[width=0.5\columnwidth]{m8.eps}

}

\protect\caption{\label{fig:lpvsilp}ALWDR, , . }
\end{figure}

\end{document}
