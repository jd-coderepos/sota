\documentclass{article}

\usepackage[english]{babel}
\usepackage{kotex}
\usepackage[unicode, colorlinks, urlcolor=cyan]{hyperref}
\urlstyle{rm}

\usepackage{txfonts}
\usepackage{CJKutf8}
\newenvironment{Japanese}{\CJKfamily{min}\CJKtilde
\CJKnospace}{}

\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

\usepackage{graphicx}
\usepackage{pgfplots}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{subfiles}
\usepackage{xcolor, colortbl}
\usepackage[toc,page]{appendix}

\usepackage[T1]{fontenc}
\usepackage{CJKutf8}

\makeatletter

\newcommand{\printfnsymbol}[1]{\textsuperscript{\@fnsymbol{#1}}}
\newcommand{\jcomma}{\hspace{-.5em}\hspace{.8em}}
\newcommand{\jperiod}{\hspace{-.5em}\hspace{.5em}}

\title{JaQuAD: Japanese Question Answering Dataset \\ for Machine Reading Comprehension}
\author{
    ByungHoon So\thanks{Equal contribution}\qquad
    Kyuhong Byun\printfnsymbol{1}\qquad
    Kyungwon Kang\qquad
    Seongjin Cho\\
    \texttt{\{byunghoon, khbyun, kangnak, sjcho\}@skelterlabs.com}
}
\date{}

\pgfplotsset{compat=1.17}
\begin{document}

\maketitle

\begin{abstract}
Question Answering (QA) is a task in which a machine understands a given document and a question to find an answer.
Despite impressive progress in the NLP area, QA is still a challenging problem, especially for non-English languages due to the lack of annotated datasets.
In this paper, we present the \textbf{Ja}panese \textbf{Qu}estion \textbf{A}nswering \textbf{D}ataset, JaQuAD, which is annotated by humans.
JaQuAD consists of 39,696 extractive question-answer pairs on Japanese Wikipedia articles.
We finetuned a baseline model which achieves 78.92\% for F1 score and 63.38\% for EM on test set.
The dataset and our experiments are available at \texttt{https://github.com/SkelterLabsInc/JaQuAD}.
\end{abstract}

\subfile{sections/1_introduction}
\subfile{sections/2_related_work}
\subfile{sections/3_dataset_collection}
\subfile{sections/4_dataset_analysis}
\subfile{sections/5_dataset_evaluation}
\subfile{sections/6_experiments}
\subfile{sections/7_conclusion}

\section{Acknowledgements}
This work was supported by TPU Research Cloud (TRC) program.
For training models, we used cloud TPUs provided by TRC.
We also thanks to anotators who geernated and labeled JaQuAD.


\bibliographystyle{abbrv}
\bibliography{reference}

\subfile{sections/appendix}

\end{document}