

\documentclass[preprint,12pt]{elsarticle}



\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{latexsym}
\usepackage{epsfig}
\usepackage{xspace}
\usepackage{color}
\usepackage{epic}
\usepackage{eepic}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{subfigure}


\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}

\newenvironment{program}
{\tt\begin{tabbing}}{\end{tabbing}}

\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\def\Xrv{X_{r_v}} 
\def\Xru{X_{r_u}} 

\newenvironment{proof}{\begin{trivlist}\item[]\textbf{Proof.}}{\end{trivlist}}
\def\punto{\hspace*{\fill}\Box}
\def\dpunto{\hspace*{\fill}\Diamond}



\newcommand{\nop}[1]{}

\newcommand{\stset}{\mathcal{ST}}

\begin{document}
\begin{frontmatter}

\title{Tree Decomposition based Steiner Tree Computation over Large Graphs}


\author[label1]{Fang Wei-Kleiner}
 \address[label1]{Lin\"oping University, Sweden}









\begin{abstract}
In this paper, we present an exact algorithm  for the Steiner tree problem.
The algorithm
is based on certain pre-computed index structures.
Our algorithm offers a practical solution
for the Steiner tree problems on graphs of large size and bounded number of terminals.
\end{abstract}

\begin{keyword}
Steiner tree, Graph algorithms, Treewidth, Tree decomposition
\end{keyword}

\end{frontmatter}

\section{Introduction}




The Steiner tree  problem is a well-studied NP-hard problem,
where we have a  graph  with costs on the edges given
and a set of terminals . The goal is to find a minimum-cost tree in  that connects/contains the terminals. 
The well-known exact algorithm (parameterized algorithm)  is the 
\emph{Dreyfus-Wagner algorithm} \cite{DW}, which follows the dynamic programming paradigm by computing 
Steiner trees  from its minimum subtrees.
The exact complexity of the algorithm
is .
Hence if  is considered as a constant, the algorithm is tractable.

Recently, new applications over Web information systems such as keyword search and social network analysis 
emerge and Steiner tree computation is at the core of the algorithms solving these problems \cite{Li2001WWW}.
One prominent feature in this scenario is that the graph size is large: the size of social networks
or other graph data in the format of XML/RDF  can easily reach hundreds of million of vertices.
As a consequence, for the Web-scale graph data, the parameter  is dominant and
the computation takes prohibitively long time even  is considered as a constant.
Although efforts have been made, algorithms yielding exact results
can only be applied to small size graphs\cite{DPBF}.



In this paper, we present an exact algorithm STEIN I  by first constructing 
certain index structures based on the so-called tree decomposition methodology,
and then conducting  the Steiner tree computation 
over the index structure.
We show that our algorithm achieves the run time of
 where  is the treewidth of the graph (see Definition \ref{def:treewidth}),
 and  is the height of the tree decomposition
of  with an upper bound of .


Chimani et al. \cite{ChimaniMZ12} recently proposed an algorithm for Steiner tree computation
with the time complexity  
, where 
 is the \emph{Bell number} with the upper bound of . 
Clearly this algorithm is only applicable to the graphs with bounded treewidth.
Notice that finding the optimal treewidth of a graph is an intractable problem \cite{Bodlaender93atourist}.
Thus
this algorithm has limitations in practice.



\section{Preliminaries}
\label{sec:pre}
An undirected weighted graph is defined as  plus the weight function , where  is the vertex set and  is the edge set.  is the weight function. 
Let  be a graph.  and  be subgraphs
of . The union of  and , denoted as ,
is the graph  where  and .



\begin{definition} [Steiner tree]
Let   be an undirected graph with the weight function .  
is a set of terminals. The Steiner tree with respect to ,
denoted as , is a tree 
spanning the terminals, where  is minimal.
\end{definition}

If the context is clear, we will  sometimes use the statement  " has the value of" by meaning that "the weight of  has the value of".
As a running example, consider the graphs illustrated in  Figure \ref{fig:subfig1},
where two graphs are illustrated in the same figure and they distinguish from each other on the 
weight of the edge , where graph 1 has the weight 1 and graph 2 has the value  9.
Assume  .
Steiner tree for Graph 1 has the weight 5 including  while the Steiner tree for Graph 2 does not include .



\begin{figure*}[ht]
 \centering
 \subfigure[Graph]{
\includegraphics [scale=0.45]{graph3}
   \label{fig:subfig1}
   }
\subfigure[Tree decomposition]{
  \includegraphics [scale=0.26]{td1}
  \label{fig:decomposition}
}
\label{fig:subfigureExample}
\caption{Example graphs with  as terminals and the tree decomposition.
}
 \label{fig:running}      
\end{figure*}

\subsection{Algorithm STVS}
\label{sec:stvs}

In this section, we introduce the first Steiner tree algorithm STVS.


\begin{definition} [Vertex Separator]
Let  be a graph, .  is a 
-vertex separator, denoted as -VS, if for every path  from  to ,
there exists a vertex  such that  and .
\end{definition}

\begin{theorem}
Let  be a graph, ,  and .
 is a -VS. Then 

where minimum is taken over all  and all  bipartitions
.
\label{the:stvs}
\end{theorem}


\begin{figure}[ht]
 \centering
\subfigure[Illustration of Theorem \ref{the:stvs}]{
  \includegraphics [scale=0.36]{stein1}
  \label{fig:stein1}
}
\subfigure[Nice tree decomposition]{
	\includegraphics [scale=0.20]{nicetd}
\label{fig:nicedecomposition}
}
\end{figure}





\begin{proof}
Consider the Steiner tree .
There must exist a path  from  to .
Given the fact that  is a -VS, 
we know that there exists one vertex , such that  as shown in Figure \ref{fig:stein1}.
No matter where  is located, we can split 
into two subtrees. One is the subtree rooted at , which contains .
The other subtree contains
the rest of the terminals in , together with  and . 
Each of the subtree is a Steiner tree regarding the terminals. 
It is trivial to show the minimum of both trees, due to the fact that
the entire tree is a Steiner tree. \qed
\end{proof}


\begin{algorithm}
\begin{algorithmic}
\REQUIRE{, , ,
 is a -VS. }
\ENSURE{}

\bf{for all} {vertex   }

~~\bf{for all} {,  where  }

~~~~~~ {}
\RETURN {}
\end{algorithmic}
\caption{STVS()}
\label{alg:stvs}
\end{algorithm}

Algorithm \ref{alg:stvs} shows the pseudo code for computing the Steiner tree according 
to Theorem \ref{the:stein1}. The complexity of the algorithm is .
One important observation about STVS   is that
the number of terminals of the sub-Steiner trees is not necessarily less than
that of the final Steiner tree . 
For instance, take the case of  and ,
the number of terminals of  is equal to 
 (both are ). Therefore, the dynamic programming
paradigm is not applicable in this regard.
Moreover, given only the graph, it is unknown how to compute the vertex separator set .
If  is not confined in any form (i.e. ), then  STVS becomes
an algorithm \'a la Dreyfus-Wagner.
Therefore, in order to make the STVS algorithm useful, it has to be guaranteed that all 
the sub-Steiner trees be pre-computed, and  be relatively small comparing to .
In the following section, we will explain in detail how these conditions 
are fulfilled with the tree decomposition techniques. 

\subsection{Tree Decomposition and Treewidth}


\begin{definition} [Tree Decomposition]
A tree decomposition  of a graph , denoted as , is a pair , where  is a finite set of integers with the form  and  is a collection of subsets of  and  is a tree such that:
\begin{enumerate}
	\item  .
	\item for every , there is , s.t. .
	\item for every , the set   v  forms a connected subtree of  .
\end{enumerate}
\label{def:TD}
\end{definition}

A tree decomposition consists of a set of tree nodes, where each node contains a set of vertices in . We call the sets  \emph {bags}. It is required that every vertex in  should occur in at least one bag (condition 1), and for every edge in , both vertices of the edge should occur together in at least one bag (condition 2). The third condition is usually referred to as the connectedness condition, which requires that given a vertex  in the graph, all the bags which contain  should be connected.

Note that from now on, the node in the graph  is referred to as vertex, and the node in the tree decomposition is referred to as tree node or simply node. For each tree node , there is a bag  consisting of vertices. To simplify the representation, we will sometimes use the term node and its corresponding bag interchangeably. 






Figure \ref{fig:decomposition} illustrates a tree decomposition of the graph from the running example.
In most of the tree decomposition related literature, the so-called \emph{nice tree decomposition}
 is used. In short, a nice tree decomposition is a tree decomposition, with 
 the following additional conditions:
(1) Every internal node  has either 1 or 2 child nodes.
(2) If a node  has one child node , then the bag  is obtained from  either
by removing one element or by introducing a new element. (3) If a node  has two
child nodes then these child nodes have identical bags as .
Given a tree decomposition ,  the size of the  nice tree decomposition of 
 is linear to it. Moreover, the transformation can be done in linear time
w.r.t. the size of . 
Figure \ref{fig:nicedecomposition} shows the nice tree decomposition of the running example graph. 








\begin{definition} [Induced Subtree]
Let  be a graph and  its tree decomposition. . 
The induced subtree of  on ,
denoted as , is a subtree of  such that
for every bag ,  
 if and only if .
\end{definition}

Intuitively, the induced subtree of a given vertex  consists of precisely those bags that contain .
Due to the connectedness condition,  is a tree.
With the definition of induced subtree, any vertex  in the graph  can be uniquely
identified with the root of its induced subtree in .
Therefore, from now on we will use the expression of "the vertex  in " with the intended meaning
that "the root of the induced subtree of  in ", if the context is clear.


The following theorem reveals the the relationship between a tree decomposition structure 
and the vertex separator.

\begin{theorem} \cite{TEDI}
Let  be a graph and  its tree decomposition. 
.
Every bag  on the path between  and  in   
is a -vertex separator.
\label{the:vsintd}
\end{theorem}








\begin{definition} [Width, Treewidth] 
Let  be a graph.
The \emph{width} of a tree decomposition  is defined as .
The \emph{treewidth} of  is the minimal width of all tree decompositions of . It is denoted as  or simply .
\label{def:treewidth}
\end{definition}





\section{STEIN I}


\nop{
\begin{example}
Consider the nice tree decomposition in Figure \ref{fig:nicedecomposition}.
The root of the induced subtree of vertices  and 
is  and  respectively.
Then according to Theorem \ref{the:vsintd}, every one from the bags along the path
between  and , namely , , ,
, , ,  and , is a -vertex separator.
\end{example}
}


\begin{definition}[Steiner Tree Set]
Given a set of vertices ,
the Steiner tree Set  is the set of the Steiner trees
of the form  where   
and .
\end{definition}


Now we  are ready to present the algorithm STEIN I,
which consists of mainly two parts:
(1) Index construction, and  (2) Steiner tree query processing.
In step (1), we first generate the tree decomposition  for a given graph .
Then for each bag  on ,
we compute   , where  is the number 
of terminals of the Steiner tree computation.
In another word, for computing a Steiner tree with  terminals, 
we need to pre-compute in each bag all the Steiner trees with 2, 3,.,  terminals.


\begin{theorem}[STEIN I]
\label{the:stein1}
Let  and  is the tree decomposition of  with treewidth .
 is the terminal set. For every bag  in ,
 is pre-computed. Then  can be computed
in time , where  is the height of .
\end{theorem}




\begin{proof}
Assume that  is a nice tree decomposition.
First, for each terminal  we  identify the root of the induced subtree  in .
Then we retrieve the lowest common ancestor (LCA) of all .
We start from the s, conduct the bottom up traversal from the children nodes to the parent node
over , till LCA is reached.

Given a bag  in , we denote all the terminals located in the subtree rooted at  as .
In the following we prove the theorem by induction.

\noindent
{\bf Claim:} Given a bag  in , if for all its child bags ,
 are computed, then 
 can be computed with the time .

\noindent
{\bf Basis:} Bag  is the root of the induced subtree of a terminal , and there is no other terminal below .
(That is,  is the one of the bags where we start with.) 
In this case,  =  and  = .
This is exactly what was pre-computed in bag .

\noindent
{\bf Induction:} 
In a nice tree decomposition, there are three traversal patterns from the child nodes
to the parent node:


\noindent (*) Vertex removal:
parent node  has one child node  where .


\noindent (*) Vertex insertion: 
parent node  has one child node  where .



\noindent (*) Merge: 
parent node  has two child nodes  and ,
where =  = 


\noindent
{\bf Vertex removal}. Assume the current parent bag  has the child bag
, such that  .
We observe that  = . That is, the terminal set below  
remains the same as with . This is because from  to , no new vertex
is introduced. There are two cases:
\begin{itemize}
\item
 is a terminal. Then we need to remember  in .
Therefore, we have  = 
 =
.
That is, the Steiner tree set in  remains exactly the same as .
\item
 is not a terminal. 
In this case, we remove simply all the Steiner trees
from  where  occurrs as a terminal.
This operation costs constant time.
\end{itemize}

\noindent
{\bf Vertex insertion}. Assume the current parent bag  has the child bag
, such that . 
First let us consider the inserted vertex  in . Note that  does not occur
in , so according to the connectedness condition,  does not occur
in any bag below . Now consider any terminal   below . 
According to the definition, the root of the induced subtree of  is also below .
In the following we first prove that  is a -vertex separator.


As stated above,  occurs in  and does not occur in , so
we can conclude that the root of the induced subtree of   () is an ancestor 
of . Moreover, we know that the root of the induced subtree of   () is below
. As a result,  is in the path between  and .
Then according to Theorem \ref{the:vsintd},  is a -vertex separator.

Next we generate all the Steiner trees , where
 . 
We execute the generation of all the Steiner trees in an incremental manner, 
by inserting the vertices in  one by one to , starting from
the vertices in , which is then followed by .
We distinguish the following cases:
\begin{itemize}
\item
. That is, all vertices in  occurs in . Obviously 
 holds. Then the Steiner tree  is pre-computed
for bag  and we can directly retrieve it.
\item 
. According to the order of the Steiner trees generation above, we assign the newly inserted terminal as . 
Let .
It is known that  is already generated.
We call the function STVS as follows: 
STVS. Since  is the -vertex separator as we shown above,
the function will correctly compute the results, as long as all the sub-Steiner trees are available.
Let . The first sub-Steiner tree  (where )
can be retrieved from the Steiner tree set in , because there is no  involved.
The second sub-Steiner tree has the form  (where ).
It can be retrieved from , because  and 
. The later is true due to the fact that the current step by inserting terminals,
all the vertices in  have already been inserted, according the order of Steiner tree generation we assign.
This complete the proof of the correctness.
\end{itemize}

As far as the complexity is concerned, at each step of vertex insertion, 
we need to generate  new Steiner trees. Each call of the function of STVS
takes time  in worst case. Thus the total time cost 
is  = .

\noindent 
{\bf Merge}: Merge operation occurs as bag  has two child nodes  and ,
and both children consist of the same set of vertices as .
Since each of the child nodes induces a distinct subtree, the terminals below the child nodes
are disjunctive. 


Basically the step is to merge the Steiner tree sets of both children nodes.
Assume the Steiner tree set of both child nodes are 
and  respectively, we shall generate the Steiner tree
set   at the parent node.

The merge operation is analogously to the vertex insertion traversal we introduced above.
We start from one child node, say . The task is to insert the terminals 
in  into  one by one.
The vertex separator between any terminal in  and 
is obviously the bag .
The time complexity for the traversal is   as well.

To conclude, in the bottom up traversal, at each step the Steiner tree set can be computed
with the time complexity of . 
Since the number of steps is of ,
the overall time complexity 
is . This completes the proof. \qed
\end{proof}


\section{Conclusion}

In this paper we presented the algorithm STEIN I, solving the Steiner tree problem over tree decomposed-based index structures.
One requirement for the algorithm is that the sub-Steiner trees in the bags have to be pre-computed. 
However, the computation can be conducted offline. Note that the space for the index storage is . 

If the number of terminals is considered as a constant, the algorithm is polynomial to the treewidth of the graph ,
thus the algorithm can also be applied to the graphs whose treewidth is not bounded, but the relationship  holds.
As stated in Introduction, finding  is an intractable problem. Thus even the treewidth of a graph is bounded, 
it is unlikely  can be obtained from a graph of large size. So in practice we can only find certain width , s. t. ,
which can be achieved for the graphs from Web information systems.
There is no obvious correlation between the time complexity and the graph size. In theory, the height of the  tree decomposition ()
is  for balanced tree and  in worst case. However in practice this value is much smaller than the graph size.

\bibliographystyle{plain}
\bibliography{steiner}


\end{document}
