\section{Results}\label{sec:resultsMain}
Visualization: 
Figure \ref{fig:qualitativeresults} (i)-(v) shows five sample images (three daytime and two nighttime images) from the SWINySEG dataset. It also compares the ground truth masks (b) with the output masks produced by ACLNet (c), U-Net (d) and DeepLabv3+ (e). 
We can see that the output density map generated by ACLNet is quite similar to the ground-truth density estimation map.
ACLNet preserves the cloud boundaries, and by virtue of using the clustering, it preserves the pixel information for generating a binary mask. For all these images, ACLNet leads to more accurate pixel-count than U-Net and DeepLabv3+. In (v), none of the models give good predicted pixel count, still ACLNet performs much better than the other models.

\begin{figure}[ht]  \centering
\includegraphics [scale=0.50] {figure_2-crop.pdf}
\caption{Segmentation results for three daytime (i), (ii),(v) and two nighttime (iii)-(iv) images. The number of pixels in the cloud mask is shown below each figure. The red-color text in parenthesis shows the difference in pixel-count between the ground-truth and the prediction made by a model (ACLNet/U-Net/DeepLabV3+). }
 \label{fig:qualitativeresults}
  \end{figure} 

Quantitative results:  We compare ACLNet with five other baseline networks, viz., FCN, CloudU-Net, DeepLabv3+, U-Net and CloudSegNet. Note that we have ourselves trained these networks and performed experiments to obtain the results.  Table \ref{tab:mainResults} shows the experimental results. Evidently, ACLNet provides the best value of metrics for all cases, except for precision metric on nighttime images. 
 

\begin{table}[htbp]\footnotesize
\centering
\caption{ Results  on daytime, nighttime and day+night time images  (Best values are shown in \textbf{bold font}) }\label{tab:mainResults}
\begin{tabu}{|l|c|c|c|c|c|c|}
\hline
Method               & \multicolumn{1}{|c|}{Precision} & \multicolumn{1}{c|}{Recall} & \multicolumn{1}{c|}{F1-Score} & \multicolumn{1}{c|}{Error Rate} &  \multicolumn{1}{c|}{MIoU} &  \multicolumn{1}{l|}{MCC} \\\hline
\multicolumn{7}{|c|}{Daytime (SWIMSEG)}  \\\hline 
 FCN            &  	0.532		&	0.466		&	0.456		&	0.502			&	0.651		&		0.724     \\\hline
 CloudU-Net            &		0.951		&		0.971	&	0.952	&	0.042		&	0.963		&		0.853     \\\hline
 DeepLabv3+            & 	0.889	&	0.913	&	0.888	&	0.082			&	0.971	&		0.93              \\\hline
 U-Net               & 	0.771	&	0.772	&	0.754	&	0.191			
&	0.870		&	0.812        \\\hline
 CloudSegNet        & 	0.921	&	0.897	&	0.892	&	0.078				&	0.944		&	0.826  	    \\\hline
 CloudSegNet (with clustering)					& 	0.941		&	0.914	&	0.912	&	0.061			&	0.955			&	0.885  \\\hline
ACLNet (proposed)        & \textbf{0.964}                         & \textbf{0.979}   & \textbf{0.971}                        & \textbf{0.022}     & \textbf{0.992} 					&  \textbf{0.956}                   \\\hline
\multicolumn{7}{|c|}{Nighttime (SWINSEG)} \\\hline 
 FCN               &	 0.423		&	0.492	&	0.431	&	0.567	
&	0.591	&	0.681          \\\hline
 CloudU-Net        &   \textbf{0.943}	&	0.951	&	0.941	&	0.049	
&	0.931	&	0.816           \\\hline
 DeepLabv3+               & 	0.864	&	0.962	&	0.891	&	0.084			&	0.961	&	0.901        \\\hline
 U-Net               & 	0.693		&	0.673		&	0.701	&	0.240	
&	0.842	&	0.782	       \\\hline
 CloudSegNet       & 	0.891		&	0.924		&	0.881	&	0.083		&	0.915	&	0.824	        \\\hline
 CloudSegNet (with clustering)					&	0.932		&	0.934		&	0.901	&	0.075		&	0.931	&	0.861			\\\hline
ACLNet (proposed)        & 0.917                          & \textbf{0.982}                       & \textbf{0.947}                        &  \textbf{0.037}        & \textbf{0.985}    & \textbf{0.930}             \\\hline
\multicolumn{7}{|c|}{Day + Night Time (SWINySEG)} \\\hline 
 FCN                &   0.500		&		0.511		&		0.441	&	0.555		&	0.591			&		0.713   		\\\hline
 CloudU-Net           & 0.956		&	0.967		&	0.952	&	0.044	
&	0.941			&		0.945     		\\\hline
 DeepLabv3+                & 	0.861	&	0.906	&	0.852	&	0.084			&	0.973			&		0.93             \\\hline
 U-Net          & 	0.714		&	0.764	&	0.741	 &	0.216				&	0.855						&		0.8        						\\\hline
 CloudSegNet       & 	0.930	&	0.883	&	0.891	&	0.079				&	0.926			&		0.812     \\\hline
 CloudSegNet (with clustering)					&	0.931	& 	0.943	&	0.922	&	0.071				&	0.932			&	0.873		\\\hline
ACLNet (proposed)        &  \textbf{0.959 }                         & \textbf{0.979}               			& \textbf{0.968}     & \textbf{0.024} & \textbf{0.993} & \textbf{0.960} \\\hline                     
\end{tabu}
\end{table}

The error rate quantifies the rate of pixel-wise misclassification between ground truth and predicted output over the whole set of instances. Error rate measures the inaccuracy of predicted output values for target values. ACLNet achieves the lowest error-rate for all three categories. These results confirm the superiority of our model. 

Based on the histogram peak of daytime and nighttime images, the difference between the color of sky and cloud regions is better in daytime images than in nighttime images. Hence, ACLNet performs well on daytime images but produces slightly inferior results on nighttime images. Although ACLNet's precision on the nighttime images is slightly less, the cloud features are efficiently segmented. 

 In this paper, our key idea is that since machine-learning (ML) and deep-learning  (DL) networks extract complementary features, combining them can provide higher performance. Our ACLNet network validates this idea and for further validation, we evaluate combining \textit{k}-means clustering with CloudSegNet network. On comparing ``CloudSegNet'' results with ``CloudSegNet (with clustering)'' in Table \ref{tab:mainResults}, it is clear that \textit{k}-means clustering helps in improving the predictive performance of CloudSegNet also. This confirms our design-choice and the importance of our innovation.   
  
 
ROC curve: Figure \ref{fig:roccurve} compares the ROC curves of ACLNet with the other baseline networks shown in Table \ref{tab:mainResults}. The area under the curve (AUC) of ROC for CloudU-Net is the least while the AUC-ROC curve for ACLNet is the highest. The higher the true positive rate and lower the false positive rate, the higher is the AUC. This shows that ACLNet has the highest true positive rate while having the lowest false positive rate.


  
\begin{figure}[htbp]  \centering
\includegraphics [scale=0.50] {roc_curve_cloudseg_revised-crop.pdf}
\caption{ROC curve comparison of different segmentation models.}
 \label{fig:roccurve}
  \end{figure} 

Model size and throughput:   
From Table \ref{tab:modelsize}, we can see that the model size of ACLNet is lower than all techniques, except CloudSegNet. While  CloudSegNet has a small model size,  but its predictive performance is much inferior compared to ACLNet. CloudU-Net has a very high model size (138MB).  Overall, ACLNet achieves the best balance of model size and performance.
Also, ACLNet requires only 7.57 million FLOPs. 
 ACLNet has a throughput of 5.7 and  13.1 frames-per-second on 2080Ti GPU and  P100 GPU, respectively.  
 
\begin{table}[htbp]\footnotesize
  \centering
  \caption{Model size (MB) of different cloud segmentation models}
    \begin{tabular}{|c|c||c|c|}
    \hline
    Model &  Size  & Model &  Size \\
    \hline
    CloudU-Net & 138.6 & CloudSegNet & 0.11\\
    \hline
    DeepLabv3+ & 61.3  & ACLNet with EfficientNet-B1 backbone & 36.7\\
    \hline
    U-Net & 94.3  & ACLNet with EfficientNet-B2 backbone & 43.1\\
    \hline
    FCN \citep{long2015fully}  & 53.6  & ACLNet with ViT backbone & 325\\
    \hline
    ACLNet with ResNet50 backbone & 47.1  & ACLNet & 30.79\\
    \hline
    \end{tabular}\label{tab:modelsize}\end{table}

