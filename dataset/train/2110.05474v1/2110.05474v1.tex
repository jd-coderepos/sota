\section{Experiments}

\subsection{Setup}
\noindent\textbf{Datasets. } Cityscapes~\cite{CordtsORREBFRS16} dataset is designed for urban scene understanding. It contains  classes and only  classes of them are used for scene parsing evaluation. The dataset contains  finely annotated images and  coarsely annotated images. The finely annotated  images are split into ,  and  images for training, validation and testing respectively.

PASCAL VOC 2012~\cite{EveringhamGWWZ10} dataset is a standard object-centric semantic segmentation dataset. It contains  foreground object classes and a background class. The strand training, validation and testing sets consist of ,  and  images, respectively. Following common practice, we use the augmented set~\cite{HariharanABMM11} which contains  images as the training set.

ADE20K dataset \cite{zhouade} is a large scale scene parsing benchmark which contains dense labels of 150 stuff/object categories. The dataset includes 20K/2K/3K images for training, validation and testing.

For both Cityscapes and PASCAL VOC 2012 datasets, 1/2, 1/4, 1/8, 1/16 and 1/32 training images are randomly sampled as the labeled training data, and the remaining images are used as the unlabeled data. For each protocol, AEL provides 5 different data folds and the final performance is the average of 5 folds. In addition, we also evaluate our method on the setting where the full Cityscapes \texttt{train} set is used as the labeled data and ,  and  images and randomly selected from the Cityscapes \texttt{coarse} set as the unlabeled data.



\noindent\textbf{Evaluation.}
We use single scale testing and adopt mean of Intersection over Union (mIoU) as the metric to evaluate the performance. We report the results on the Cityscapes \texttt{val} set and PASCAL VOC 2012 \texttt{val} set in comparisons with state-of-the-art methods. All ablation studies are conducted on the Cityscapes \texttt{val} set under 1/16 and 1/32 partition protocols.

\noindent\textbf{Implementation Details. }
We use ResNet-101 pretrained on ImageNet~\cite{krizhevsky2012imagenet} as our backbone, remove the last two down-sampling operations and employ dilated convolutions in the subsequent convolution layers, making the output stride equal to 8. We use DeepLabv3+~\cite{chen2018encoder} as the segmentation head. For Cityscapes dataset, we use stochastic gradient descent (SGD) optimizer with initial learning rate 0.01, weight decay 0.0005 and momentum 0.9. Moreover, we adopt the `poly' learning rate policy, where the initial learning rate is multiplied by . We adopt the crop size as , batch size as 16 and training iterations as 18k. For PASCAL VOC 2012 dataset, we set the initial learning rate as 0.001, weight decay as 0.0001, crop size as , batch size as 16 and training iterations as 30k. We use random horizontal flip and random resize as the default data augmentation if not specified. All the supervised baselines are trained on the labeled data. 


\begin{table*}[t]
\renewcommand\arraystretch{1.1}
\begin{center}
\caption{Comparison with state-of-the-art methods on the \textbf{Cityscapes} \texttt{val} set under different partition protocols. All the methods are based on DeepLabv3+ with ResNet-101 backbone.}
\label{citysota}
\begin{tabularx}{14cm}{p{2.5cm}|X<{\centering}| X<{\centering}| X<{\centering} | X<{\centering}| X<{\centering}}
\toprule
Method  & 1/32 (93) & 1/16 (186) & 1/8 (372) & 1/4 (744) & 1/2 (1488) \\
\midrule
Supervised  & 57.89 & 62.96 & 69.81 & 74.23 & 77.46 \\
\midrule
MT~\cite{TarvainenV17}    &  64.07 & 68.05 & 73.56 & 76.66 & 78.39\\
CCT~\cite{OualiHT20}   & 66.35 & 69.32 & 74.12 & 75.99 & 78.10 \\
Cutmix-Seg~\cite{FrenchLAMF20}    & 69.11 & 72.13 & 75.83 & 77.24  & 78.95 \\
GCT~\cite{KeQLYL20}     & 63.21  & 66.75 & 72.66 & 76.11 & 78.34\\
\midrule
AEL (Ours)    & \textbf{74.28} & \textbf{75.83} & \textbf{77.90} & \textbf{79.01}  & \textbf{80.28}\\
\bottomrule
\end{tabularx}
\end{center}
\end{table*}

\begin{table*}[t]
\renewcommand\arraystretch{1.1}
\begin{center}
\caption{Comparison with state-of-the-art methods on the \textbf{PASCAL VOC 2012} \texttt{val} set under different partition protocols. All the methods are based on DeepLabv3+ with ResNet-101 backbone.}
\label{vocsota}
\begin{tabularx}{14cm}{p{2.5cm}|X<{\centering}| X<{\centering}| X<{\centering} | X<{\centering}|X<{\centering}}
\toprule
Method & 1/32 (331) & 1/16 (662) & 1/8 (1323) & 1/4 (2646) & 1/2 (5291)  \\
\midrule
Supervised  & 70.14 & 70.60 & 73.12 & 76.35 & 77.21\\
\midrule
MT~\cite{TarvainenV17}    & 70.56 & 71.29 & 73.33 & 76.61 & 78.08 \\
CCT~\cite{OualiHT20}    & 71.22 & 71.86 & 73.68 & 76.51 & 77.40 \\
Cutmix-Seg~\cite{FrenchLAMF20}   & 73.39 & 73.56 & 73.96 & 77.58 & 78.12 \\
GCT~\cite{KeQLYL20}      & 70.32 & 70.90 & 73.29 & 76.66 & 77.98 \\
\midrule
AEL (Ours)     & \textbf{76.97} & \textbf{77.20} & \textbf{77.57} &\textbf{78.06} & \textbf{80.29}\\
\bottomrule
\end{tabularx}
\end{center}
\end{table*}

\subsection{Comparison with State-of-the-Art Methods}
We compare our method with recent semi-supervised semantic segmentation methods, including Mean Teacher (MT)~\cite{TarvainenV17}, Cross-Consistency Training (CCT)~\cite{OualiHT20}, Guided Collaborative Training (GCT)~\cite{KeQLYL20} and Cutmix-Seg~\cite{FrenchLAMF20}.
For a fair comparison, we re-implement all above methods and adopt the same network architecture (DeepLabv3+ with ResNet-101 backbone). 

\textbf{Results on Cityscapes Dataset.}
Table~\ref{citysota} compares AEL with state-of-the-art methods on the Cityscapes \texttt{val} set. Without leveraging any unlabeled data, the performance of the supervised baseline is unsatisfactory under various data partition protocols, especially for the fewer data settings, e.g., 1/32 and 1/16 protocols. Our method consistently promotes the baseline, achieving the improvements of +16.4\%, +12.9\%, +8.1\%, +4.8\% and +2.8\% under 1/32, 1/16, 1/8, 1/4 and 1/2 partition protocols respectively. Our method also significantly outperforms the existing state-of-the-art methods by a large margin under all data partition protocols. In particular, AEL outperforms the existing best method Cutmix-Seg by +5.2\% under extremely few data setting (1/32 protocol), and surpasses Cutmix-Seg by +1.3\% under the 1/2 protocol. 


\textbf{Results on PASCAL VOC 2012 Dataset.}
Table~\ref{vocsota} shows comparison with state-of-the-art methods on the PASCAL VOC 2012 \texttt{val} dataset. AEL achieves consistent performance gains over the supervised baseline, obtaining an improvements of +6.8\%, +7.0\%, +4.1\%, +1.7\% and +3.1\% under 1/32, 1/16, 1/8, 1/4 and 1/2 partition protocols respectively. We can see that over all protocols, AEL outperforms the state-of-the-art methods. For example, our method outperforms the previous best method by +3.6\% and +2.2\% under the 1/32 and 1/2 partition protocols. 


\subsection{Ablation Study}
\label{sec:ablation}
To further understand the advantages of AEL, we conduct a series of ablation studies that examine the effectiveness of different components and different hyper-parameters. All experiments are conducted on the validation set of Cityscapes dataset.

\begin{table*}[t]
\renewcommand\arraystretch{1.1}
\begin{center}
\caption{Ablation study on the effectiveness of different components: Dynamic Re-weighting (DR), Adaptive Equalization Sampling(AES), Adaptive CutMix (ACM), Adaptive Copy-Paste (ACP).}
\label{ablation}
\begin{tabularx}{12cm}{X<{\centering}| X<{\centering}|X<{\centering}|X<{\centering}| p{1.8cm}<{\centering}|p{1.8cm}<{\centering} }
\toprule
\centering{DR} & \centering{AES} & ACM & ACP &  1/32 (93) & 1/16 (186)   \\
\midrule
   &  &  &  & 69.11 & 72.13\\
 \checkmark  &  &  &  &  70.27  & 73.85\\
 & \checkmark &  &  & 71.65 & 74.12 \\
 &  & \checkmark &  & 70.49 & 73.89 \\
 &  &  & \checkmark & 69.69 & 72.64\\
\checkmark & \checkmark &  &  & 72.51 & 74.39 \\
\checkmark & \checkmark & \checkmark &  & 73.43 & 75.12 \\
\checkmark & \checkmark & \checkmark & \checkmark & \textbf{74.28} & \textbf{75.83} \\
\bottomrule
\end{tabularx}
\end{center}

\end{table*}

\textbf{The Effectiveness of Different Components.} 
We ablate each component of AEL step by step. Table~\ref{ablation} reports the studies. We use the basic framework described in Section~\ref{base} as our baseline, which achieves 69.11\% and 72.13\% under 1/32 and 1/16 protocols respectively. We first evaluate the effectiveness of each single component. As shown in the table, Dynamic Re-weighting (DR) improves the baseline by +1.1\% and +1.7\% under 1/32 and 1/16 partition protocols. Adaptive Equalization Sampling (AES) alleviates the biased training issue, achieving the improvements of +2.5\% and +2.0\% over the baseline. Adaptive CutMix (ACM) and Adaptive Copy-Paste (ACP) data augmentation approaches give more chance for under-performing categories to be sampled, and bring the improvements of +1.3\% / +1.7\% and +0.5\% / +0.5\% respectively.
Furthermore, we present the performance gains in a progressive manner. On top of the DR, by leveraging AES strategy on the unsupervised loss, our method obtains improvements of +2.3\% and +0.5\% under 1/32 and 1/16 protocols. The two proposed data augmentation approaches further boost the performance to 74.28\% and 75.83\%, demonstrating the effectiveness of our adaptive learning.


\textbf{Ablation Study on Hyper-Parameters.} Table~\ref{factor} ablates the tunable parameter  in dynamic re-weighting (in Eq~\ref{eq:gamma}), where  yields slightly better performance. Dynamic re-weighting is found to be insensitive to . 

\noindent Table~\ref{sample} ablates the influence of different indicators, including Confidence (in Eq~\ref{confidence}), Margin (in Eq~\ref{margin}), and Entropy (in Eq~\ref{entropy}). We use the Confidence as the default indicator to assess the category-wise performance during training due to its best performance. 


\noindent Adaptive CutMix requires a criteria to identify whether an unlabeled image contains a certain class. We use the ratio between pseudo labels of a certain category and total pixels of the input image as the criteria. Table~\ref{dcutmix} ablates different ratios.



\noindent Table~\ref{dcp} studies the number of sampled categories  in the Adaptive Copy-Paste. We find that  achieves the best performance. One potential reason is that a smaller  provides less training samples from the under-performing categories while a larger  may increase the difficulty for training.



\noindent Table~\ref{weight} ablates the loss weight  which is used to balance the supervised loss and unsupervised loss as shown in Eq~\ref{loss}. As illustrated in the table,  achieves the best performance. We use  in our approach for all the experiments. 

\subsection{Per-class Results}
\begin{table*}[t]
\renewcommand\arraystretch{1.7}
 \setlength{\tabcolsep}{4pt}
    \begin{center}
    \caption{Per-class results on \textbf{Cityscapes} \texttt{val} set under 1/32 data partition protocol. All the methods are based on DeepLabv3+ with ResNet-101 backbone.  }
    \label{per-class}
    \begin{adjustbox}{max width=\linewidth}
        \begin{tabular}{ l | c |c |c c c c c c c c c c | c c c c c c c c c  c}
\toprule[1pt]
       & & & \multicolumn{10}{c|}{Head Classes} & \multicolumn{9}{c}{Tail Classes} \\
       \midrule
       Methods &  \rotatebox{90}{mIoU}&  \rotatebox{90}{mIoU\_tail} &  \rotatebox{90}{road} &  \rotatebox{90}{sidewalk} &  \rotatebox{90}{building} & \rotatebox{90}{ fence} &  \rotatebox{90}{pole} &  \rotatebox{90}{vegetation} & \rotatebox{90}{terrain} &  \rotatebox{90}{sky}&  \rotatebox{90}{person} &  \rotatebox{90}{car} &  \rotatebox{90}{wall} & \rotatebox{90}{traffic light} &  \rotatebox{90}{traffic sign} & \rotatebox{90}{rider} &  \rotatebox{90}{truck}& \rotatebox{90}{ bus}& \rotatebox{90}{ train}& \rotatebox{90}{ motorcycle}&  \rotatebox{90}{bicycle}\\
      \midrule
      Supervised & 57.9 & 39.8 & 94.6 & 72.5 & 87.4 & 42.4 & 51.6 & 88.3 & 49.8 & 91.1 & 74.5 & 89.4 & 21.7 & 47.7 & 59.1 & 33.7 & 43.3 & 37.2 & 11.4 & 42.1 & 62.2 \\
      \midrule
      GCT~\cite{KeQLYL20} & 63.2 & 48.1 & 96.9 & 75.8 & 89.8 & 40.3 & 57.5 & 91.1 & 53.5 & 93.1 & 78.1 & 91.6 & 23.6 & 58.9 & 70.1 & 43.4 & 25.8 & 45.7 & 49.2 & 45.0 & 71.4 \\
       MT~\cite{TarvainenV17}  & 64.1 & 50.4 & 96.7 & 75.6 & 89.5 & 40.0 & 57.3 & 91.0 & 53.2 & 92.80 & 77.9 & 91.3 & 26.2 & 61.1  & 72.3 & 45.8 & 28.0 & 48.1 & 51.6 & 47.1 & 73.8 \\
       CCT~\cite{OualiHT20} & 66.4 & 54.2 & 95.7 & 77.2 & 88.6 & 46.5 & 58.5 & 90.1 & 55.5 & 91.5 & 77.9 & 91.8 & 27.9 & 60.5 & 71.8 & 48.0 & 44.5 & 61.4 & 50.7 & 52.0 & 70.5 \\
       Cutmix-Seg~\cite{FrenchLAMF20} & 69.1 & 58.7 & \textbf{97.2} & 78.6 & 90.1 & 48.1 & 60.1 & 91.5 & 57.2 & 93.0 & 79.6 & 93.3 & 32.4 & 64.8 & 76.5 & 52.3 & 49.4 & 66.0 & 54.8 & 56.7 & 75.1 \\
       
       \midrule
       AEL (Ours) & \textbf{74.3} & \textbf{67.9} & 97.1 & \textbf{78.7} & \textbf{90.3} & \textbf{52.3} & \textbf{62.0} & \textbf{91.7} & \textbf{59.2} & \textbf{93.8} & \textbf{81.6} & \textbf{94.0} & \textbf{37.3} & \textbf{67.9} & \textbf{77.6} & \textbf{60.5} & \textbf{65.6} & \textbf{83.8} & \textbf{74.3} & \textbf{66.9} & \textbf{77.0}\\     
        \bottomrule[1pt]
        \end{tabular}
    \end{adjustbox}
    \end{center}
\end{table*}
Since the class imbalance problem is severe in the Cityscapes dataset, we provide per-class results under 1/32 data partition protocol in Table~\ref{per-class}. We choose 9 classes with the least training samples in the Cityscapes dataset as tail classes, i.e. wall, traffic light, traffic sign, rider, truck, bus, train, motorcycle and bicycle. As shown in the table, our method not only achieves the best overall mIoU, but also obtains significant improvements on tail classes. In particular, Our method outperforms the existing best method Cutmix-Seg by +5.2\% in overall mIoU and +9.2\% in mIoU for tail classes under 1/32 partition protocol. 

\subsection{Performance on the Full Labeled Set}
We conduct experiments where the full Cityscapes \texttt{train} set is used as the labeled dataset and the Cityscapes \texttt{coarse} set is used as the unlabeled dataset. We do not leverage any annotations from the \texttt{coarse} set though it provides coarsely annotated ground-truth. We randomly sample 1000, 3000 and 5000 images from the \texttt{coarse} set to verify the proposed method. As shown in Table ~\ref{full}, the proposed AEL can still improve the supervised baselines by leveraging the unlabeled data though a large amount of labeled data is provided.




\begin{table*}[t]
\centering
\begin{minipage}[t]{0.3\linewidth}
\renewcommand\arraystretch{1.0}
\begin{center}
\caption{Study on  of dynamic re-weighting.}
\begin{tabularx}{0.99\linewidth}{X<{\centering}|X<{\centering}|X<{\centering}}
\toprule
 & 1/32  & 1/16  \\
\midrule
 0    & 69.11 &  72.13 \\
 0.5  & 69.74 & 73.28\\
 1 & 69.35 & 73.67 \\
 \textbf{2} & \textbf{70.27} & \textbf{73.85}\\
 3 &  70.26 &  73.40\\
\bottomrule
\end{tabularx}
\label{factor}
\end{center}
\end{minipage}
\hfill
\begin{minipage}[t]{0.3\linewidth}
\renewcommand\arraystretch{1.0}
\begin{center}
\caption{Study on different indicators for AES.}
\begin{tabularx}{0.99\linewidth}{p{1.3cm}<{\centering}|X<{\centering}|X<{\centering}}
\toprule
Indicator &  1/32 &  1/16 \\
\midrule
 None & 70.27  & 73.85 \\
 Ent & 71.38 & 73.21\\
 \textbf{Conf} & \textbf{72.51} & \textbf{74.39}\\
 Margin & 70.86  & 73.05\\
\bottomrule
\end{tabularx}
\label{sample}
\end{center}
\end{minipage}
\hfill
\begin{minipage}[t]{0.3\linewidth}
\renewcommand\arraystretch{1.0}
\begin{center}
\caption{Study on different ratios in ACM.}
\begin{tabularx}{0.99\linewidth}{X<{\centering}|X<{\centering}|X<{\centering}}
\toprule
Ratio & 1/32  & 1/16  \\
\midrule
  0.001 & 73.27 & 74.28\\
  0.003 & 73.29 & 74.36 \\
  \textbf{0.005} & \textbf{73.43} & \textbf{75.12} \\
  0.01 & 72.78 & 73.66\\
\bottomrule
\end{tabularx}
\label{dcutmix}
\end{center}
\end{minipage}
\end{table*}


\begin{table*}[t]
\centering
\begin{minipage}[t]{0.3\linewidth}
\renewcommand\arraystretch{1.0}
\begin{center}
\caption{Study on number of sampled categories  in ACP.}
\begin{tabularx}{0.99\linewidth}{p{1.2cm}<{\centering}|X<{\centering}|X<{\centering}}
\toprule
 & 1/32& 1/16\\
\midrule
  1 & 72.18 & 74.85\\
  2 & 72.84 & 74.95\\
  \textbf{3} & \textbf{74.28} & \textbf{75.83}\\
  4 & 73.43 & 74.10\\
\bottomrule
\end{tabularx}
\label{dcp}
\end{center}
\end{minipage}
\hfill
\begin{minipage}[t]{0.3\linewidth}
\renewcommand\arraystretch{1.0}
\begin{center}
\caption{Study on loss weight .}
\begin{tabularx}{0.99\linewidth}{X<{\centering}|X<{\centering}|X<{\centering}}
\toprule
 & 1/32 & 1/16 \\
\midrule
  0.5 & 71.85 & 74.61\\
  \textbf{1.0} & \textbf{74.28}& \textbf{75.83}\\
  1.5 & 74.10 & 73.44\\
  2.0 & 73.79 & 72.86\\
\bottomrule
\end{tabularx}
\label{weight}
\end{center}
\end{minipage}
\hfill
\begin{minipage}[t]{0.3\linewidth}
\renewcommand\arraystretch{1.0}
\begin{center}
\caption{Performance on the full Cityscapes \texttt{train} set.} \begin{tabularx}{0.99\linewidth}{p{1.1cm}<{\centering}|p{1.1cm}<{\centering}|X<{\centering}}
\toprule
Number & Baseline  & AEL  \\
\midrule
 0    & 80.16 &  - \\
 1000  & 80.22 & \textbf{80.28}\\
 3000 & 80.55 & \textbf{81.36} \\
 5000 & 80.92 & \textbf{81.95}\\
\bottomrule
\end{tabularx}
\label{full}
\end{center}
\end{minipage}
\end{table*}

\subsection{Results on ADE20K Dataset}
We further provide results on the ADE20K dataset~\cite{zhouade}. Since no previous methods in semi-supervised segmentation conducted experiments on ADE20K dataset, we compare our method with supervised baseline and existing best method Cutmix-Seg on the dataset. As shown in Table~\ref{adesota}, our method consistently promotes the supervised baseline by 6.36\%, 5.70\%, 5.67\%, 3.18\% and 1.45\%, and outperforms the Cutmix-Seg by 2.25\%, 3.38\%, 2.48\%, 1.31\% and 1.26\% under 1/32, 1/16, 1/8, 1/4 and 1/2 partition protocols, respectively.

\begin{table*}[t]
\renewcommand\arraystretch{1.1}
\begin{center}
\caption{Comparison with supervised baseline and Cutmix-Seg on the \textbf{ADE20K} \texttt{val} set under different partition protocols. All the methods are based on DeepLabv3+ with ResNet-101 backbone.}
\label{adesota}
\begin{tabularx}{14cm}{p{2.5cm}|X<{\centering}| X<{\centering}| X<{\centering} | X<{\centering}| X<{\centering}}
\toprule
Method  & 1/32 (631) & 1/16 (1263) & 1/8 (2526) & 1/4 (5052) & 1/2 (10105) \\
\midrule
Supervised  & 22.04 & 27.52 & 32.36 & 36.39 & 41.97 \\
\midrule
Cutmix-Seg~\cite{FrenchLAMF20}  & 26.15 & 29.84 & 35.55 & 38.26 & 42.16 \\
\midrule
AEL (Ours)    & \textbf{28.40} & \textbf{33.22} & \textbf{38.03} & \textbf{39.57}  & \textbf{43.42}\\
\bottomrule
\end{tabularx}
\end{center}
\end{table*}
\begin{figure}[!h]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/vis_city2.pdf}
    \caption{Qualitative results on the Cityscapes \texttt{val} set. From left to right: input image, ground-truth, predictions of the supervised baseline, predictions of our basic framework and predictions of the proposed AEL. Orange rectangles highlight the unsatisfactory segmentation results.}
    \label{vis_city}
\end{figure}
\subsection{Qualitative Results}
Figure~\ref{vis_city} shows the visualization results of different methods evaluated on the Cityscapes \texttt{val} set. We compare the proposed AEL with ground-truth, supervsied baseline and our basic framework described in Section~\ref{base}. Benefiting from a series of technologies designed for the balanced training, AEL achieves great performance on not only head categories (e.g. \textit{Road}), but also tailed categories (e.g. \textit{Rider} and \textit{Bicycle}).

