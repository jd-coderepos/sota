\documentclass[a4paper]{article}

\usepackage{INTERSPEECH2020}
\usepackage{color}
\usepackage{multirow}
\usepackage{makecell}

\title{Conformer: Convolution-augmented Transformer for Speech Recognition}
\name{Anmol Gulati, James Qin, Chung-Cheng Chiu, Niki Parmar, Yu Zhang, Jiahui Yu, Wei Han, Shibo Wang, Zhengdong Zhang, Yonghui Wu, Ruoming Pang}
\address{Google Inc.}
\email{\{anmolgulati, jamesqin, chungchengc, nikip, ngyuzh, jiahuiyu, weihan, shibow, zhangzd, yonghui, rpang\}@google.com}

\newcommand{\netname}{Conformer}
\newcommand{\conv}{\mathrm{Conv}}
\newcommand{\convblock}{\mathrm{ConvBlock}}
\newcommand{\comment}{\textcolor{red}}
\usepackage{hyperref}
\begin{document}

\maketitle
\begin{abstract}
Recently Transformer and Convolution neural network (CNN) based models have shown promising results in Automatic Speech Recognition (ASR), outperforming Recurrent neural networks (RNNs). Transformer models are good at capturing content-based global interactions, while CNNs exploit local features effectively.
In this work, we achieve the best of both worlds by studying how to combine convolution neural networks and transformers to model both local and global dependencies of an audio sequence in a parameter-efficient way. To this regard, we propose the convolution-augmented transformer for speech recognition, named \textit{Conformer}. \textit{Conformer} significantly outperforms the previous Transformer and CNN based models achieving state-of-the-art accuracies. On the widely used LibriSpeech benchmark, our model achieves WER of 2.1\%/4.3\% without using a language model and 1.9\%/3.9\% with an external language model on test/testother. We also observe competitive performance of 2.7\%/6.3\% with a small model of only 10M parameters.

\end{abstract}
\noindent\textbf{Index Terms}: speech recognition, attention, convolutional neural networks, transformer, end-to-end

\input{00_intro.tex}
\input{01_model.tex}
\input{02_exp.tex}

\section{Conclusion}
In this work,
we introduced Conformer, an architecture that integrates components from CNNs and Transformers for end-to-end speech recognition. We studied the importance of each component, and demonstrated that the inclusion of convolution modules is critical to the performance of the Conformer model.
The model exhibits better accuracy with fewer parameters than previous work on the LibriSpeech dataset, and achieves a new state-of-the-art performance at / for test/testother.


\bibliographystyle{IEEEtran}

\bibliography{mybib}

\end{document}
