\documentclass[11pt]{article}
\usepackage{amsmath}
\usepackage{amsmath}
\usepackage{times}
\usepackage{subfigure}
\usepackage{fullpage}
\usepackage{color}
\usepackage{graphicx,amssymb,amsmath}
\usepackage{multirow}
\usepackage{xspace}
\usepackage[linesnumbered,boxed,ruled, vlined]{algorithm2e} \usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{cases} 

\usepackage{url}
\urldef{\mailsa}\path|{huanglx12@mails, lijian83@mail, sqc12@mails}.tsinghua.edu.cn|




\newcommand{\commentout}[1]{}
\newcommand{\eat}[1]{}
\newcommand{\topic}[1]{\vspace{0.2cm}\noindent{\bf #1 :}}
\newcommand{\calX}{{\mathcal X}}
\newcommand{\calH}{{\mathcal H}}
\newcommand{\calJ}{{\mathcal J}}
\newcommand{\calC}{{\mathcal C}}
\newcommand{\calF}{{\mathcal F}}
\newcommand{\calT}{{\mathcal T}}
\newcommand{\calP}{{\mathcal P}}
\newcommand{\calG}{{\mathcal G}}
\newcommand{\calU}{{\mathcal U}}
\newcommand{\calV}{{\mathcal V}}


\newcommand{\calQ}{{\mathcal Q}}
\newcommand{\tcalQ}{{\widetilde{\mathcal Q}}}
\newcommand{\calK}{{\mathcal K}}

\newcommand{\calE}{{\mathcal E}}
\newcommand{\calS}{{\mathcal S}}
\newcommand{\calI}{{\mathcal I}}
\newcommand{\calN}{{\mathcal N}}
\newcommand{\calM}{{\mathcal M}}
\newcommand{\barB}{\overline{B}}


\newcommand{\Prob}{{\operatorname{Pr}}}
\newcommand{\Exp}{{\mathbb{E}}}
\newcommand{\Var}{\operatorname{Var}}
\newcommand{\opt}{\mathsf{Opt}}
\newcommand{\OPT}{\mathsf{OPT}}

\newcommand{\sol}{\mathsf{Sol}}
\newcommand{\LP}{\mathsf{LP}}
\newcommand{\dist}{\mathsf{dist}}


\newcommand{\poly}{\mathsf{poly}}



\newcommand{\B}{\mathsf{B}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}



\newcommand{\hx}{\widehat{x}}
\newcommand{\hy}{\widehat{y}}
\newcommand{\tx}{\widetilde{x}}
\newcommand{\ty}{\widetilde{y}}
\newcommand{\bx}{\overline{x}}
\newcommand{\by}{\overline{y}}
\newcommand{\hz}{\widehat{z}}
\newcommand{\tU}{\widetilde{U}}
\newcommand{\tV}{\widetilde{V}}
\newcommand{\tr}{\widetilde{r}}
\newcommand{\tg}{\widetilde{g}}



\newcommand{\tz}{\widetilde{z}}
\newcommand{\tp}{\tilde{p}}
\newcommand{\tq}{\tilde{q}}
\newcommand{\hg}{\widehat{g}}
\newcommand{\hp}{\widehat{p}}

\newcommand{\tM}{\widetilde{M}}
\newcommand{\tA}{\widetilde{A}}
\newcommand{\bA}{\overline{A}}

\newcommand{\tB}{\widetilde{B}}
\newcommand{\bB}{\overline{B}}
\newcommand{\hM}{\overline{M}}
\newcommand{\bM}{\overline{M}}
\renewcommand{\i}{\mathrm{i}}

\newcommand{\Ray}{\mathcal{R}}

\newcommand{\bg}{\bar{g}}

\renewcommand{\d}{\mathrm{d}}



\newcommand{\true}{}
\newcommand{\false}{}

\newcommand{\jiannote}[1]{\textcolor{red}{#1}}
\newcommand{\rednote}[1]{#1}





\newtheorem{assumption}{Assumption}



\newcommand{\mincsc}{-}
\newcommand{\minwcsc}{-}
\newcommand{\minctc}{-}
\newcommand{\mincds}{-}
\newcommand{\minds}{-}
\newcommand{\minwcds}{-}
\newcommand{\minwds}{-}

\newcommand{\bcsc}{-}


\newcommand{\bsc}{}
\newcommand{\qst}{}
\newcommand{\gst}{}
\newcommand{\hittingset}{}
\newcommand{\lpr}{\mathsf{Lp}\text{-}\mathsf{GST}}
\newcommand{\lpflow}{\mathsf{Lp}\text{-}\mathsf{flow}}
\newcommand{\lphittingset}{\mathsf{Lp}\text{-}\mathsf{HS}}
\newcommand{\lpsteiner}{\mathsf{Lp}\text{-}\mathsf{ST}}
\newcommand{\group}{\mathsf{gp}}
\newcommand{\cell}{\mathsf{cl}}
\newcommand{\setcell}{\mathsf{\Delta}}

\newcommand{\cells}{\mathsf{CG}}
\newcommand{\terminal}{\mathsf{Ter}}
\renewcommand{\mod}{\operatorname{mod}}


\newcommand{\Rc}{R_\mathsf{c}}
\newcommand{\Rs}{R_\mathsf{s}}
\newcommand{\Dc}{D_\mathsf{c}}
\newcommand{\Ds}{D_\mathsf{s}}
\newcommand{\Gc}{\mathcal{G}_\mathsf{c}}

\newenvironment{proof}{\noindent {\em Proof: }\ignorespaces}{}
\newenvironment{proofofthm}[1]{\noindent {\em Proof of Theorem #1: }\ignorespaces}{}
\newenvironment{proofoflm}[1]{\noindent {\em Proof of Lemma #1: }\ignorespaces}{}
\newcommand{\qed}{\hspace*{\fill}\medskip}

\newtheorem{theorem}{Theorem}
\newtheorem{claim}{Claim}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{reduction}{Reduction}
\newtheorem{definition}{Definition}
\newtheorem{property}{Property}
\newtheorem{observation}{Observation}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}

\title{Approximation Algorithms for the Connected Sensor Cover Problem}

\author{Lingxiao Huang \quad\quad\quad\quad Jian Li \thanks{Corresponding author.}
	\quad \quad \quad \quad Qicai Shi  \\
Institute for Interdisciplinary Information Sciences\\
Tsinghua University, China \\
\mailsa
}


\begin{document}

\maketitle

\begin{abstract}
	We study the minimum connected sensor cover problem  (\mincsc) and
	the budgeted connected sensor cover  (\bcsc) problem,
both motivated by important applications (e.g., reduce the communication cost among sensors) in wireless sensor networks.
In both problems, we are given a set of sensors and a set of target points in the Euclidean plane.
In \mincsc, our goal is to find a set of sensors of minimum cardinality,
such that all target points are covered, and all sensors can communicate with each other (i.e., the communication graph is  connected). We obtain a constant factor approximation algorithm, assuming that the ratio between the sensor radius and communication radius is bounded.
In \bcsc\ problem, our goal is to choose a set of  sensors, such that the number of targets covered by the chosen sensors is maximized and the communication graph is connected. We also obtain a constant approximation under the same assumption.
\end{abstract}

\vspace{-0.2cm}
\section{Introduction}
\vspace{-0.2cm}

In many applications, we would like to monitor a region or a collection of targets of interests
by deploying a set of wireless sensor nodes.
A key challenge in such applications is the limited energy supply for each sensor node.
Hence, designing efficient algorithms for minimizing energy consumption and maximizing the lifetime of the network
is an important problem in wireless sensor networks and many variations have been studied extensively. We refer interested readers to the book by Du and Wan~\cite{du2012connected}
for many algorithmic problems in this domain.

In this paper, we consider two important sensor coverage problems.
Now, we introduce some notations and formally define our problem.
We are given a set  of  sensors in .
All sensors in  have the same communication range 
and the same sensing range .
In other words, two sensors  and  can communicate with each other
if , and a target point  can be covered by sensor 
if .
We use  to denote the disk with radius  centered at point .
Let  and .

\begin{assumption}[Funke et al.~\cite{funke2007improved}]
	\label{ass:1}
	In this paper, we assume that  can be upper bounded by a constant 
	(i.e., ). 
Without loss of generality, we can assume that .
	Hence, .
\end{assumption}

Note that this assumption holds for most practical
applications, e.g., it generalizes Funke et al.~\cite{funke2007improved} which assumes that .

The first problem we study is the {\em minimum Connected sensor covering} (\mincsc) problem.
This problem considers the problem of selecting the minimum number of sensors
that form a connected network and detect all the targets.
It is somewhat similar, but different from, the connected dominating set problem.
We will discuss the difference shortly.
The formal problem definition is as follows:

\begin{definition}
	\mincsc: Given a set  of sensors
	and a set  of target points,
	find a subset  of minimum cardinality
	such that all points in  are covered by the union of sensor areas in 
	and the communication links between sensors in  form a connected graph.
\end{definition}
\vspace{-0.1cm}

In some applications, instead of monitoring a set of discrete target points,
we would like to monitor a continuous range , such as a rectangular area.
Such problems can be easily converted into a \mincsc\ with discrete points,
by creating a target point (which we need to cover) in each cell of the arrangement
of the sensing disks  restricted in .


The second problem
studied in this paper is the {\em Budgeted connected sensor cover}  (\bcsc) problem.
The problem setting is the same as \mincsc, except that
we have an upper bound on the number of sensors we can open, and the goal becomes
to maximize the number of covered targets.

\vspace{-0.1cm}
\begin{definition}
	\bcsc: Given a set  of sensors , a set  of target points and a positive integer ,
	find a subset 
	such that  and the number of points in  covered by the union of sensor areas in  is maximum and the communication links between sensors in  form a connected graph.
\end{definition}

\rednote{Note that in this paper we only consider the unweighted versions for both problems. 
	We leave the weighted versions as an interesting future direction.}

\vspace{-0.3cm}
\subsection{Previous Results and Our Contributions}


\subsubsection{\mincsc}
The \mincsc\ problem was first proposed by Gupta et al.~\cite{gupta2006connected}.
They gave an -approximation
( is an upper bound of the hop-distance between any two sensors
having nonempty sensing intersections).
Wu et al.~\cite{wu2013approximations} give an -approximation algorithm.
\rednote{Then, Wu et al.~\cite{wu2016connected} improved the approximation factor to , which is best approximation ratio known so far (in terms of ).}
If ,  and the above result implies a constant approximation.
However, even
 is slightly larger than ,  may still be  arbitrarily large.
We also notice that if , we must have .
So Assumption~\ref{ass:1} is a weaker assumption than the assumption that .
\rednote{Funke et al.~\cite{funke2007improved} showed that the greedy algorithm that provides complete coverage has an approximation factor no better than .}

\mincsc\ is in fact a special case of the {\em group Steiner tree} problem
(as also observed in Wu et al~\cite{wu2013approximations,wu2016minimum}).
In fact, this can be seen as follows:
consider the communication graph (the edges are the communication links).
For each target, we create a group which consists for all sensor nodes that can cover the
target. The goal is to find a minimum cost tree spanning all groups.\footnote{
	Notice that the group Steiner tree is edge-weighted but \mincsc\ is node-weighted.
	However, since all nodes have the same (unit) weight, the edge-weight and node-weight of a tree differ by at most 1.
}
Garg et al~\cite{garg1998polylogarithmic}, combined with the optimal
probabilistic tree embedding \cite{fakcharoenphol2003tight}, \rednote{obtained} an  factor approximation algorithm the group Steiner tree problem via LP rounding.  Chekuri et al.~\cite{chekuri2006greedy} \rednote{claimed} nearly the same approximation ratio using pure combinatorial method.


Our first main contribution is a constant factor approximation algorithm for
\mincsc\ under Assumption~\ref{ass:1}, improving on the aforementioned results.
Our improvement heavily rely on the geometry of the problem (which the group Steiner tree approach ignores).


\begin{theorem}
	There is a polynomial time approximation algorithm which can achieve
	an approximation factor  for \mincsc.
	Under Assumption~\ref{ass:1}, the approximation factor is a constant.
\end{theorem}

\begin{remark}
	The weighted version of the connected sensor covering problem (\minwcsc) has also been studied, in which each sensor has a nonnegative weight and the goal is to find a set of minimum weight. 
Elbassioni et al.~\cite{elbassioni2012relation} showed that the problem is also a special case of the group Steiner tree problem and claimed an  factor approximation algorithm.
\end{remark}

\vspace{-0.3cm}
\subsubsection{\bcsc}
Recall in \bcsc, we have a budget , which is the upper bound of the number of sensors we can use and our goal is to maximize the number of covered target points.
Kuo et al.\cite{kuo2013maximizing} study this problem
under the assumption that the communication and the sensing radius of sensors are the same
(i.e., ). They obtained an -approximation by transforming the problem to a more general connected submodular function maximization problem.

Recently, Khuller et al.~\cite{khuller2014analyzing} obtained
a constant approximation for the {\em budgeted generalized connected dominating set problem},
defined as follows: Given an undirected graph  and budget , and a  monotone {\em special submodular function}
\footnote{
	 is a special submodular function if (1)  is submodular:
	 for any ;
	(2)  if 
	for any . Here,  denotes the neighborhood of  (including ).
} , find a subset  such that ,
 induces a connected subgraph
and  is maximized.
If  in \bcsc, the coverage function  (the number of targets covered by sensor set ) is a special submodular function.\footnote{\rednote{Consider  satisfying that . It implies that for any  and , . Since , we have that . Hence, . It implies that  is a special submodular function.}} 
Hence, we have a constant approximation
for \bcsc\ when .
When ,  may not be special submodular and the algorithm and analysis
in \cite{khuller2014analyzing} do not provide any approximation guarantee for \bcsc.

We note that it is also possible to adapt the greedy approach developed by group Steiner tree~\cite{chekuri2006greedy} and
polymatroid Steiner tree~\cite{calinescu2005polymatroid} to get polylogarithmic approximation
for \bcsc. However, it is unlikely that the approach can be made to achieve constant approximation
factors, and we omit the details.

In this paper, we improve the above results by presenting the first constant
factor approximation algorithm under the more general Assumption~\ref{ass:1}.

\begin{theorem}
	There is a polynomial time approximation algorithm which can achieve
	approximation factor of  for \bcsc.
	Under Assumption~\ref{ass:1}, the approximation factor is .
	\label{th_bcsc}
\end{theorem}

Our algorithm is inspired by \cite{khuller2014analyzing}.
In particular, we make crucial use of the geometry of the problem
to get around the issue required by \cite{khuller2014analyzing}
(i.e., the coverage function is required to be special submodular in their work).

\vspace{-0.2cm}
\subsection{Other Related Work}
\vspace{-0.1cm}


\mincsc\ is closely related to
the {\em minimum dominating set} (\minds) problem
and the {\em minimum connected dominating set} (\mincds) problem.
In fact, if the communication radius  is equal to the sensing radius  and the collection  of sensors is equal to the collection  of target points,
\mincsc\ is equivalent to \mincds.
In general graphs, \mincds\ inherits the inapproximability of set cover, so it is NP-hard to approximation \mincds\ within a factor of  for any  \cite{feige1998threshold,dinur2014analytical}.
Improving upon Klein and Ravi~\cite{klein1995nearly}, Guha and Khuller~\cite{guha1999improved} obtained a
-approximation, which is the best result known for general graphs.

Lichtenstein~\cite{lichtenstein1982planar} proved that \mincds\ in unit disk graphs (UDG) is NP-hard (which also implies that \mincsc\ is NP-hard).
The first constant approximation algorithm for the unweighted \mincds\ problem in UDG
was \rednote{obtained} by Wan et al.\cite{wan2002distributed}.
This was later improved by Cheng et al.\cite{cheng2003polynomial}, who gave the first PTAS.
Many variants of \minds\ and \mincds, motivated by various applications in wireless sensor network, 
have been studied extensively. See \cite{du2012connected} for a comprehensive treatment.

For the weighted (connected) dominating set problem (\minwds\ and \minwcds), Amb{\"u}hl et al.~\cite{ambuhl2006constant} \rednote{provided} the first constant ratio approximation algorithms for both problems (the constants are 72 and 94 for \minwds\ and \minwcds\ respectively).
The constants were improved in a series of subsequent
papers~\cite{huang2009better,dai20095+,zou2011new,willsonbetter}. Recently, Li and Jin~\cite{li2015ptas} 
\rednote{obtained} the first PTAS
for \minwds\ and an improved constant approximation for \minwcds\ in UDG.

\bcsc\ is a special case of the submodular function maximization problem subject to a
cardinality constraint and a connectivity constraint.
Submodular maximization under cardinality constraint,
which generalizes the maximum coverage problem, is a classical combinatorial optimization problem and it is known the optimal approximation is ~\cite{nemhauser1978analysis,feige1998threshold}.
Submodular maximization under various more general combinatorial constraints (in particular, downward monotone set systems)
is a vibrant research area in theoretical computer science
and there have been a number of exciting new developments in the past few years
(see e.g., \cite{calinescu2011maximizing,vondrak2011submodular} and the references therein).
The connectivity constraint has also been considered in some previous work \cite{zhang2012complexity,kuo2013maximizing,khuller2014analyzing}, some of which we mentioned before.


\section{Preliminaries}
\label{sec:prel}

We need the following \emph{maximum coverage} (\bsc) in our algorithms.
\begin{definition}
	\bsc: Given a universe  of elements and a family  of subsets of , and a positive integer ,
	find a subset 
	such that  and the number of elements covered by
	 is maximized.
\end{definition}
We need to following well known result, by \cite{nemhauser1978analysis,hochbaum1998analysis}.
\begin{lemma}[Corollary 1.1 of  Hochbaum and Pathria \cite{hochbaum1998analysis}]
	The greedy algorithm is a -approximation for \bsc .
	\label{lm_bsc}
\end{lemma}

A closely related problem is the {\em hitting set} problem.
\begin{definition}
	\hittingset: Given a universe  of weighted elements (with weight function )
	and a family  of subsets of 
	find a subset 
	such that  for all  (i.e.,  hits every subset in ) and
	 is minimized.
\end{definition}

The \hittingset\ problem is equivalent to the set cover problem (where the elements and subsets switch roles).
It is well known that a simple greedy algorithm
can achieve an approximation factor of  for \hittingset\
and the factor is essentially optimal \cite{feige1998threshold,dinur2014analytical}.
In this paper, we use a geometric version of \hittingset\ in which
the set of given elements are points in  and the subsets are
induced by given disks (i.e., each  is the subset of points that can be covered by
a given disk). Geometric hitting set admits constant factor approximation algorithms (even PTAS)
for many geometric objects (including disks) \cite{bronnimann1995almost,Clarkson,mustafa2009ptas,varadarajan2010weighted,Chan2012}.
As mentioned in the introduction, \mincsc\ is a special case of
the following {\em group Steiner tree} (\gst) problem.

\begin{definition}
	\gst: We are given an undirected graph 
	where  is the edge cost function,
	and  is a collection of subsets of .
	Each subset in  is called a group.
The goal is to find a subtree , such that
	 for all  (i.e.,  spans all groups)
	and the cost of the tree  is minimized.
\end{definition}

Our algorithm for \bcsc\ also needs the following {\em quota Steiner tree} (\qst) problem.

\begin{definition}
	\qst: Given an undirected graph 
	( is the edge cost function,
	 is the vertex profit function) and an integer ,
find a subtree  of the graph 
	( tries to collect as much profit as possible subject to the quota constraint).
\end{definition}


Johnson et al.~\cite{johnson2000prize} proposed the \qst\ problem and proved that any -approximation for the - problem yields an -approximation for the \qst\ problem.
Combining with the -approximation for  developed by Garg \cite{garg2005saving},
we can get a -approximation for the \qst\ problem.
\begin{lemma}
	\label{lm:qst}
	These is an  approximation algorithm with approximation factor 
	for \qst.
\end{lemma}



\section{Minimum Connected Sensor Cover}
\label{sec:mscs}

We first construct an edge-weighted graph  as follows:
If , we add an edge between  and 
(It is easy to see that  is in fact a unit disk graph).
 is called {\em  the communication graph}.
Recall that \mincsc\ requires us to find a set of vertices
that induces a connected subgraph in the communication graph .

First, we note that  may have several connected components.
We can see any feasible solution must be contained in a single connected component
(otherwise, the solution can not induce a connected graph).
Our algorithm tries to find a solution in every connected component.
Our final solution will be the one with the minimum cost among all connected component.
Note that for some connected component, there may not be a feasible solution
in that component (some target point can not be covered by any point in that component),
and our algorithm ignores such component.


\eat{
	\begin{algorithm}
		\caption{ Find the minimum connected dominating set }
		\textbf{Input:} The sensor collection , the target collection , communicate radius and sensing radius of sensors , \\
		\textbf{Output:}  such that,  is a connected subgraph of  and for each target , there exists a sensor , such that ;\\
		
		\begin{enumerate}
			\item Use  to calculate the graph .  \\
			\item Use  to calculate   \\
			\item 
			\item \textbf{for} every component  in  \textbf{do}   \\
\item \textbf{if} for each target , there exists a sensor , such that 
			\begin{enumerate}
				\item \textbf{for} each  \textbf{do}
				\begin{enumerate}
					\item  Solving  with root 
					\item Place a grid with grid size  in the plane
					
					\item \textbf{for} , 
					\item  Solve  with parameters  and round the result of  to an integral solution 
					\item  Solve  with parameters   and round the result of  to an integral solution 
					\item 
					\item \textbf{if} , 
				\end{enumerate}
				\item \textbf{end for}
			\end{enumerate}
			\item \textbf{end if}
			\item \textbf{end for}
			\item return 
		\end{enumerate}
		\label{alg_mcds}
	\end{algorithm}
	
}






From now on, we fix a connected component  in . Let  be the collection of all edges in the connected component .
Similar with Wu et al.~\cite{wu2013approximations},
we formulate the \mincsc\ problem as a group Steiner tree (\gst) problem.
Each edge  is associated with a cost .
For each target , we create a group

The goal is to find a tree  (in ) such that
 for all 
and the cost is minimized.
We can easily see the \gst\ instance constructed above is equivalent to
the original \mincsc\ problem
(the cost of the tree  is the number of nodes in  minus 1).
The \gst\ problem can be formulated as the following linear integral program:
We pick a root  for the tree  and remove all target points that are covered by  from \footnote{We can do this since the final solution always contain ; see Equation~\eqref{eq:terminal}.}
(we need to enumerate all possible roots).
For each edge , we use Boolean variable 
to denote whether we choose edge .



The second constraint says that for any cut  that separates the root
 from any group, there must be at least one chosen edge.
By replacing  with , we obtain the linear programming relaxation of \ref{eq:lpgst1} (denoted as ).
By the duality between flow and cut, we can see that
the second constraint is equivalent to dictating that
we can send at least 1 unit of flow from the root  to nodes in , for each .
This flow viewpoint (also observed in the original \gst\ paper~\cite{garg1998polylogarithmic})
will be particularly useful to us later.
So we write down the flow LP explicitly as follows.
We first replace every undirected edge 
by two directed arcs  and .
Let  denote the collection of all directed arcs.
For each  and
each directed arc , we have a variable  indicating the flow of commodity  on arc .
We use  to denote the net flow
(also called {\em flow excess}) of commodity  into node .
Then we develop the following linear program:



We first have the following lemma that connects two programs \ref{eq:lpgst} and \ref{eq:lpgst1}.


\begin{lemma}
	\label{lm:optimal}
	The optimal value of \ref{eq:lpgst} is at most the optimal value of \ref{eq:lpgst1}.
\end{lemma}

\begin{proof}
	Given a feasible solution , we construct a feasible solution of  as follows: 
	\begin{enumerate}
		\item By definition,  form a tree  rooted at .
Denote  to be the collection of directed arcs satisfying that  is the father point of  on tree . 
\item For each directed arc , let .
Otherwise, let .
\item For each , there must exist a sensor  belonging to tree  by the constraints of \ref{eq:lpgst1}.
Denote  to be the collection of directed arcs satisfying that both  and  lie on the unique path from root  to  on tree . 
\item For each  and each directed arc , let .
Otherwise, let .
\item For each  and , let .
\end{enumerate} 
	By construction, we can check that all constraints of  are satisfied.
Moreover, .
This completes the proof.
\qed
\end{proof}

Denote  to be the optimal fractional value of .
Now, we describe our algorithm.
Our algorithm mainly consists of two steps.
In the first step, we extract a {\em geometric hitting set} instance from the optimal fractional solution of .
We can find an integral solution  for the hitting set problem and we can show its cost is at most .
Then by Lemma~\ref{lm:optimal}, the size of  is at most  times the optimal value of \ref{eq:lpgst1}.
Moreover all sensors in  can cover all target points .
In the second step, we extract a Steiner tree instance, again from the optimal fractional solution of .
We show it is possible to round the Steiner tree LP to get a constant approximation integral Steiner tree,
which can connect all points in .

\topic{Step 1: Constructing the Hitting Set Instance}




We first solve the linear program  and obtain the fractional optimal solution
.
Let  to denote the optimal value of .
We place a grid with grid size  in the plane (i.e., each cell is a  square).
W.l.o.g., we assume that grid lines are parallel to either the -axis or the -axis.
For each , consider the set of sensors , that is the set of sensors which can cover .
Since  is contained in a disk  of radius , the diameter of  that is parallel to the -axis is fully covered by at most  grid cells.
Similarly, the diameter of  that is parallel to the -axis is also covered by at most  grid cells.
Thus, we conclude that there are at most
\rednote{} grid cells that may contain some points in .
Since  , there must be a cell (say ) such that

We call  the {\em significant cell} for point . 
\footnote{
	If there are multiple such cells, we pick one arbitrarily.
}


Now, we construct a geometric hitting set (\hittingset) instance  as follows:
Let the set of points be

and  the family of subsets be

The goal is to choose a subset  of  such that
 for all  (i.e., we want to hit every set in ).
Write the linear program relaxation for the \hittingset\ problem (denoted as ):


Let  to denote the optimal value of .
We need the following simple lemma.

\begin{lemma}
	\label{lm:hittingset}
	.
\end{lemma}
\begin{proof}
	Suppose  is the optimal fractional solution for .
	Now, we want to construct a feasible fractional solution  for 
	such that .
	We simply let
	
	From \eqref{eq:cellsum}, we can easily see  is a feasible solution for the \hittingset\ problem:
	
	It remains to see that
	
	This finishes the proof.
	\qed
\end{proof}




\rednote{C{\u{a}}linescu et al.~\cite{calinescu2004selecting} showed that we can round the above linear program  to obtain an integral solution (i.e., an actual hitting set)  such that .}\footnote{Note that  is equivalent to a minimum disk cover problem if we regard each  as a unit disk of radius  centered at . Hence, we can apply the rounding scheme for the minimum disk cover problem in~\cite{calinescu2004selecting}.}
In another work, Br{\"o}nnimann and Goodrich \cite{bronnimann1995almost},
combined with the existence of -net of size  for disks (see e.g.,~\cite{pyrga2008new}), also showed that we can round 
to an actual hitting set
 such that 
(the connection to -net was made simpler and more explicit in Even et al.~\cite{even2005hitting}).
Hence, by Lemma~\ref{lm:hittingset}, 
we have that .

\topic{Step 2: Constructing the Steiner Tree Instance}
We now have a hitting set . 
Consider a node .
Since  is a node (a sensor) in the hitting set, 
we know there is some point  such that . In other words,  can cover  and is in the significant
cell of .
From \eqref{eq:cellsum}, we know that 
.

Consider the set of cells 
\footnote{
	If a cell is the significant cell for more than one target point ,
	 only has one copy of the cell. In other words,
	it is indeed a {\em set} of cells.
}
If there is a cell which contains the root , we exclude it from .
From each cell , we pick an arbitrary node (i.e., sensor)  in it, 
called the {\em representative node} of .
By \ref{eq:cellsum} (i.e., ), at least  
flow of commodity  that enters .

Consider the Steiner tree problem in  
in which the set of terminals is defined to be

In another word, the goal of this Steiner tree problems
is to connect  and all representative nodes.
We write down the following linear program relaxation for the
Steiner tree problem (denoted as ):


Now, we construct a feasible fractional solution for 
as follows.
Consider the optimal fractional solution  of .
We would like to construct another feasible fractional solution  for .
First, we construct an intermediate solution  by
{\em rerouting} some flow. 
Then, we scale the flow to construct .
The details are as follows:

\begin{itemize}
	\item (Flow Rerouting)
	Consider a cell .
	For each node , let , and let  for any node . In other words, we route
	the flow excess at node  to node .
	After such updates, for each  we can see the flow excess is zero, or
	equivalently .
	The flow excess at node  is
	
	We repeat the above process for all .
	\item
	We next increase the flow excess at node  to 1 for all , and construct another feasible solution . For each , we define  as follows: 
	\begin{enumerate}
		\item For each edge , let .
		Note that such scaling increases the flow excess at node  by a  factor. 
		\item For each node , let . 
	\end{enumerate}
	After the scaling,  unit flow (thinking  as the flow value on ) enters  and . On the other hand, we have that  for each edge  following from the fact that . \end{itemize}


Let , where  is the undirected edge corresponding to directed edges  and  (Notice that  is formulated on directed graphs and Steiner tree is formulated on undirected graphs.
).
For each , since at least 1 unit flow (thinking  as flow value on ) enters  and ,  is a feasible solution for 
.

Next, we show the optimal value of 
is not much larger than that of .

\begin{lemma}
	\label{lm:steiner}
	.
\end{lemma}
\begin{proof}
	Recall  is a feasible solution for  and  is the optimal solution for . Also recall that  is a hitting set instance satisfying that .
	We only need to show that 
	
	This can be seen as follows:
	
	
	
	The second equality follows from the construction of . The first inequality follows from the definition of  (we only reroute the flow for commodity  such that , hence the second term). The second inequality follows from the fact that  and Equation~\eqref{eq:flowbound}.
	This finishes the proof of the lemma.
	\qed
\end{proof}


It is well known that the integrality gap of the Steiner tree problem is a constant \cite{williamson2011design}.
In particular, it is known that using the primal-dual method (based on ) in~\cite{goemans1995general}
(see also \cite[Chapter 7.2]{williamson2011design}),
we can obtain an integral solution  such that

Let  be the set of vertices spanned by the integral Steiner tree .
The above discussion shows that .
Our final solution (the set of sensors we choose) is

The feasibility of  is proved in the following simple lemma.
\begin{lemma}
	 is a feasible solution.
	\label{lm:final1}
\end{lemma}
\begin{proof}
	We only need to show that 
	induces a connected graph and covers all the target points.
	Obviously,  covers all target points, so does .
	Since  is a Steiner tree, thus connected. Moreover,  connects
	all representatives  for all . On the other hand,
	 only contains those sensors in .
	So every sensor in  (say ) is connected to the representative .
	So  induces a connected subgraph.
	\qed
\end{proof}

Lastly, we need to show the performance guarantee.
This is easy since we have shown that
both  and .
So  since  is assumed to be a constant.

\section{Budgeted Connected Sensor Cover}
\label{sec:bcsc}

Again we assume that  and .
Recall that our goal is to find a subset 
of sensors with cardinality  which induces a connected subgraph and
covers as many targets as possible.
We first construct the communication graph  as in Section~\ref{sec:mscs}.
Again, we only need to focus on a connected component of .
Then we find a square  in the Euclidean plane large enough such that all of the  sensors are inside .
Similar to \cite{marathe1995simple,hunt1998nc}, we partition  into small square cells of equal size.
Let the side length of each cell be .
Denote the cell in the ith row and jth column of the partition as .
Let  be the collection of sensors in .
We then partition these cells into  different cell groups
,
where .
In particular, we let

and
 be the collection of sensors in ; see Figure~\ref{fig:grid} as an example.
\begin{figure}
	\label{fig:grid}
	\caption{Partition cells into  different cell groups .}
	\centering
	\includegraphics[height=130pt]{grid.jpg}
\end{figure}

With the above value , we make a simple but useful observation as follows.
\begin{observation}
	\label{ob:nodoublecover}
	There is no target covered by two different sensors contained in two different cells of .
\end{observation}
Denote the optimal solution of \bcsc\ problem as .
In this section, we present an  factor approximation algorithm
for the \bcsc\ problem.

\subsection{The Algorithm}
For , we repeat the following two steps,
and output a tree  with  vertices (sensors) which covers the maximum number of targets.
Then based on , we find a subtree  with exactly  vertices as our final output.


\begin{algorithm}[t]
	\label{alg_GSC}
	\caption{Reassign profits via the greedy algorithm}
	\textbf{Input:} The sensor collection , the target collection , the cell collection . \\
	\textbf{Output:} Profit function \begin{enumerate}
		\item \textbf{for all}  \textbf{do}
		{\setlength\itemindent{15pt} \item  ~~~~~~ // is the set of uncovered targets}
		{\setlength\itemindent{15pt} \item   ~~~~~~ // is the set of available sensors\\
			{\setlength\itemindent{15pt} \item \textbf{for all}  \textbf{do} }
			\begin{enumerate}
				{\setlength\itemindent{15pt} \item   ~~~~~
					// is the set of uncovered targets that can be covered by . 		}
				{\setlength\itemindent{15pt} \item ,
					,
					 }		
			\end{enumerate}
		}
		{\setlength\itemindent{15pt} \item \textbf{end for} }
		\item \textbf{end for}
		\item return 
	\end{enumerate}
\end{algorithm}


\topic{Step 1: Reassign profit}
The profit  of a subset  is the number of targets covered by .
 is a submodular function.
In this step,
we design a new profit function (called {\em modified profit function})  for the set of sensors.
To some extent,  is a linearized version of  (module a constant approximation factor).


Now, we explain in details how  is defined.
Fix a cell group .
\footnote{
	For each , we define a modified profit function .
	For ease of notation, we omit the subscripts.
}
For the vertices in , we use the greedy algorithm Algorithm \ref{alg_GSC}
to reassign profits of the vertices in . Generally speaking, we greedily pick a vertex which covers the most number of targets each time, and use this number as the modified profit. The details are as follows.
Among all vertices in ,
we pick a vertex  which can cover the most number of targets,
and use this number as its modified profit .
Remove the chosen vertex and targets covered by it.
We continue to pick the vertex  in  which can cover the most number of uncovered targets.
Set the modified profit  to be the number of newly covered targets.
Repeat the above steps until all the sensors in  have been picked out.
For other vertices  which are not in , we simply set their modified profit  as 0.

Let us first make some simple observations about  and .
We use  to denote .
First, it is not difficult to see that  for any subset .
Second, we can see that it is equivalent to run the greedy algorithm for
each cell in  separately (due to Observation~\ref{ob:nodoublecover}).
Suppose ,
 where  and  are two different cells in ,
then  due to Observation~\ref{ob:nodoublecover}.


Consider a cell .
Let ,
where the vertices are indexed by the order
in which they were selected by the greedy algorithm.
Let  be the first  vertices in .
By the following lemma, we can see that the modified profit function  is a constant approximation to
true profit function  over any vertex subset .


\begin{lemma}
	For a set of vertices  in the same cell , such that ,
	we have that
	.
	\label{lm_1/e}
\end{lemma}
\begin{proof}
	\eat{
		Suppose in Algorithm~\ref{alg_GSC}, we select
		the vertices in  in the order of .
		Let  be the first  vertices selected by the greedy algorithm in .
		By the construction of , we have
		
		Note that . Since  is a submodule function and  for . So we have .
	}
	By the greedy rule, we can see .
	By Lemma \ref{lm_bsc}, we know that .
	\qed
\end{proof}

\topic{Step 2: Guess the optimal profit and calculate a tree } Although the actual profit of  is unknown, we can guess the profit of  (by enumerating all possibilities).
For each , we calculate in this step
a tree  of size at most , using the \qst\ algorithm (see Lemma~\ref{lm:qst}).
We can show that among these trees (for different  values),
there must be one tree of profit no less than .

After choosing the best tree  with the highest profit,
we construct a subtree  of size  based on  as our final solution of \bcsc.



\begin{algorithm}
	\label{alg_gppafb}
	\caption{Algorithm for \bcsc\ with greedy profit assignment}
	\textbf{Input:} The sensor collection , the target collection , budget B. \\
	\textbf{Output:} a tree  with .
	\begin{enumerate}
		\item Construct the communication graph 	
		\item \textbf{for}  \textbf{from}  to ,  \textbf{from}  to 
		\begin{enumerate}
			\item Reassign every vertex's profit with Algorithm \ref{alg_GSC} \rednote{and obtain a profit function }.
			\item Set every edge's cost as 1
			\item 
			\item \textbf{Do}
			\begin{enumerate}
				\item  Run the -approximation algorithm of \qst\ on  \rednote{with the profit function } and quota 
				\item \textbf{if}  \textbf{then} 
				\item 
			\end{enumerate}
			\item \textbf{While}		
		\end{enumerate}			
		\item \textbf{end for}
		\item  use the dynamic programming algorithm described in Section 5.2.2 in \cite{khuller2014analyzing} to find the best profit subtree of size  from .
		\item return 	
	\end{enumerate}
\end{algorithm}

We first show that there exists , such that based on the modified profit  on ,
there exists a tree with at most  vertices of total modified profit at least
.
We use  to denote the set of vertices of the optimal solution.

\begin{lemma}
	There exists a tree  in ,
	 such that 
	\label{lm_1/k^2}
\end{lemma}
\begin{proof}
	We first notice that
	
	Hence, there exists , such that
	
	For any cell , suppose .
	 is obtained from
	 by appending all vertices in  (recall that  consists of
	the first  vertices selected in  by the greedy algorithm).
	Note that we append at most  vertices in total, and all vertices are still connected
	(
	since all vertices in the same cell are connected
	).
	Thus,  is connected and has at most  vertices.
	
	By Lemma \ref{lm_1/e}, we can see that . Thus, we have 
	Both equalities hold due to Observation~\ref{ob:nodoublecover}.
	\qed
\end{proof}


Then, by Lemma~\ref{lm:qst} and Lemma~\ref{lm_1/k^2},
if we run the \qst\ algorithm (with  as the profit function),
we can obtain the suitable tree  with at most  vertices of profit at least .
The pseudocode of the algorithm can be found in Algorithm~\ref{alg_gppafb}.


\begin{lemma}
	Let  be the tree obtained in Algorithm~\ref{alg_gppafb}, then
	
	\label{lm_treeAppro}
\end{lemma}
\begin{proof}
	By Lemma~\ref{lm_1/k^2}, we can obtain a tree  with at most  nodes. We also have .
	Since  for any , we have that
	
	\qed
\end{proof}



Then we show how to construct a subtree  of  vertices based on tree . Our technique is the same as Khuller et al. \cite{khuller2014analyzing}.
Firstly, they use the following theorem by Jordan \cite{jordan1869assemblages} to prove Lemma \ref{lm_khuller}. Then by a carefully partition, they obtain a subtree with  vertices of profit at least  of original tree with  vertices. Our construction is almost the same except that the original tree  in our setting has at most  vertices.

\begin{lemma}[Jordan \cite{jordan1869assemblages}]
	Given any tree on n vertices, we can decompose it into two trees (by replicating a single vertex) such that the smaller tree has at most  nodes and the larger tree has at most  nodes.
	\label{lm_jordan}
\end{lemma}
\begin{lemma}[Khuller et al. \cite{khuller2014analyzing}]
	Let  be greater than a sufficiently large constant. Given a tree  with  nodes, we can \rednote{partition the vertex set of } it into 13 trees of size at most  nodes each.
	\label{lm_khuller}
\end{lemma}

Denote the subtree with highest total profit as . 
By the above lemma,  has at most  nodes.
Then we show the following lemma.
\begin{lemma}
	Assume . 
	\label{th_treeDecompose}
\end{lemma}
\begin{proof} By Lemma \ref{lm_jordan}, we decompose the tree  into two trees  and  such that  and  and continue decomposing until the tree has at most  vertices (as shown in the figure. Note that each subtree in the white square in the figure has at most  vertices).
	Thus we can decompose a tree of size  to at most 8 subtrees of size at most .
	See the figure.
	Suppose the subtrees are ,,...,. Then we have,
	
	So there is a subtree of size at most  and profit at least .
	\qed
\end{proof}
\includegraphics[height=130pt]{treedecomposition1.png}


Use the same dynamic programming algorithm in Khuller et al.~\cite{khuller2014analyzing},
we can find  from tree .
Combining Lemma \ref{lm_treeAppro} and Lemma \ref{th_treeDecompose},
 (if ).

Thus, we have obtained Theorem \ref{th_bcsc}.



\section{Conclusion and Future Work}
There are several interesting future directions.
The first obvious open question is that whether we
can get constant approximations for \mincsc\ and \bcsc\ without Assumption~\ref{ass:1}
(it would be also interesting to obtain approximation ratios that have better dependency on ).
Generalizing the problem further, an interesting future direction is the case where
different sensors have different transmission ranges and sensing ranges.
Whether the problems admit better approximation ratios than the (more general) graph theoretic
counterparts is still wide open.
Another interesting future direction is to obtain constant approximations for the weighted versions of  \mincsc\ and \bcsc.

\section{Acknowledgments}

We would like to thank anonymous reviewers for their constructive comments,
and pointing out a problematic argument in a previous version of the paper.
We also would like thank Dingzhu Du and Zhao Zhang for helpful discussions.
The research is supported in part by the National Basic Research Program of China Grant 2015CB358700, 
the National Natural Science Foundation of China Grant 61822203, 61772297, 61632016, 61761146003,
and a grant from Microsoft Research Asia.



\bibliographystyle{plain}\bibliography{sensor}

\end{document}
