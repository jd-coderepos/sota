\documentclass[11pt]{paper}
\usepackage{fullpage}


\usepackage {amssymb}
\usepackage {amsmath}
\usepackage {amsthm}
\usepackage [usenames] {color}

\usepackage {enumerate}
\usepackage {plaatjes}
\usepackage {cite}
\usepackage{float}
\usepackage [left,pagewise] {lineno}
\usepackage {xspace}
\usepackage {wrapfig}


\definecolor {infocolor} {rgb} {0.6,0.6,0.6}
\linenumbers

\definecolor {sepia} {rgb} {0.75,0.30,0.15}
\everymath{\color{sepia}}

\floatstyle{ruled}
\newfloat{algorithm}{thp}{alg}
\floatname{algorithm}{Algorithm}


\setlength{\fboxsep}{.5pt}
\renewcommand\thefootnote{\tiny\protect\framebox{\arabic{footnote}}}


\newcommand {\mathset} [1] {\ensuremath {\mathbb {#1}}}
\newcommand {\R} {\mathset {R}}
\newcommand {\Q} {\mathset {Q}}
\newcommand {\Z} {\mathset {Z}}
\newcommand {\script} [1] {\ensuremath {\mathcal {#1}}}
\newcommand {\etal} {\textit {et al.}}
\newcommand {\eps} {\varepsilon}
\newcommand {\eqdef} {:=}
\newcommand {\boruvka}{Bor\r{u}vka}
\DeclareMathOperator {\wspd}{\texttt{wspd}}
\DeclareMathOperator {\as}{as}
\DeclareMathOperator {\emst}{emst}
\DeclareMathOperator {\argmin}{argmin}
\DeclareMathOperator {\DT}{DT}
\DeclareMathOperator {\UC}{UC}
\DeclareMathOperator {\LC}{LC}
\newcommand {\parent} {\overline}
\newcommand {\child} {\underline}

\newcommand{\marrow}{\marginpar[\hfill]{}}
\newcommand{\remark}[3]{\textcolor{blue}{\textsc{#1 #2:}}
\textcolor{red}{\marrow\textsf{#3}}}



\newtheorem {theorem} {Theorem}[section]
\newtheorem {problem}[theorem] {Problem}
\newtheorem {lem}[theorem] {Lemma}
\newtheorem {observation}[theorem] {Observation}
\newtheorem {cor}[theorem] {Corollary}
\newtheorem {claim}[theorem] {Claim}
\newtheorem {invariant}[theorem] {Invariant}

\newenvironment {repeatobservation} [1]
{\noindent {\sc Observation~\ref{#1}.}\ \slshape} {\normalfont}
\newenvironment {repeatclaim} [1]
{\noindent {\sc Claim~\ref{#1}.}\ \slshape} {\normalfont}
\newenvironment {repeatlemma} [1]
{\noindent {\sc Lemma~\ref{#1}.}\ \slshape} {\normalfont}
\newenvironment {repeattheorem} [1]
{\noindent {\sc Theorem~\ref{#1}.}\ \slshape} {\normalfont}
\newenvironment {repeatcorollary} [1]
{\noindent {\sc Corollary~\ref{#1}.}\ \slshape} {\normalfont}

\title{\Large Triangulating the Square and Squaring the Triangle:\\ 
Quadtrees and Delaunay 
Triangulations are Equivalent\footnote{A preliminary version 
appeared in Proc.~22nd SODA, pp.~1759--1777, 2011}}

\author{Maarten L\"offler\thanks{Department of Information and Computing Sciences,
   Universiteit Utrecht;
   3584 CC Utrecht,
   The Netherlands;
   \textsl{m.loffler@uu.nl}.
  }
\and
Wolfgang Mulzer\thanks{Institut f{\"u}r Informatik,
  Freie Universit{\"a}t Berlin; 14195 Berlin, Germany;
  \textsl{mulzer@inf.fu-berlin.de}.
      }
}
\date{}
\begin{document}

\maketitle



\begin{abstract}
  We show that Delaunay triangulations and compressed quadtrees are equivalent
  structures. More precisely, we give two algorithms: the first computes
  a compressed quadtree for a planar point set, given the Delaunay
  triangulation; the second finds the Delaunay triangulation, given a
  compressed quadtree. Both algorithms run in deterministic linear time on
  a pointer machine.
  Our work builds on and extends previous
  results by Krznaric and Levcopolous~\cite{KrznaricLe98} and
  Buchin and Mulzer~\cite{BuchinMu11}. Our main tool for the second 
  algorithm is the
  well-separated pair decomposition (WSPD)~\cite{CallahanKo95},
  a structure that has been used previously to find Euclidean minimum
  spanning trees in higher dimensions~\cite{Eppstein00}. We show that knowing
  the WSPD (and a quadtree) suffices to compute
  a planar Euclidean minimum spanning tree (EMST) in \emph{linear} time. 
  With the EMST
  at hand, we can find the Delaunay triangulation in
  linear time~\cite{ChinWa99}.

  As a corollary, we obtain
  deterministic versions of many previous algorithms related
  to Delaunay triangulations, such as
  splitting planar Delaunay
  triangulations~\cite{ChazelleDeHuMoSaTe02,ChazelleMu11},
  preprocessing imprecise points for faster Delaunay
  computation~\cite{BuchinLoMoMuXX,LoefflerSn10}, and transdichotomous
  Delaunay triangulations~\cite{BuchinMu11,ChanPa09,ChanPa10}.
\end{abstract}

\section {Introduction}

  \tweeplaatjes [scale=0.95] {intro-qt} {intro-dt} {A planar point set , and a quadtree (a) and a Delaunay triangulation (b) on it.}

  Delaunay triangulations and quadtrees are among the oldest and
  best-studied notions in computational
  geometry~\cite{deBergChvKrOv08,BoissonnatYv98,d-slsv-34,FinkelBe74,m-pdt-97,Samet90,ShamosHo75,PreparataSh85}, captivating the attention of researchers
  for almost four decades. 
  Both are proximity structures on planar point sets;
  Figure~\ref {fig:intro-qt+intro-dt} shows a simple example of these structures.
  Here, we will demonstrate that
  they are, in fact, equivalent in a very strong sense.
Specifically, we describe two algorithms. The first computes a suitable 
  quadtree for , given the Delaunay triangulation . 
  This algorithm closely follows
  a previous result by Krznaric and
  Levcopolous~\cite{KrznaricLe98}, who solve this problem in a stronger
  model of computation. Our contribution lies in adapting
  their algorithm to the real RAM/pointer machine model.\footnote{Refer
  to Appendix~\ref{app:models} for a description of different computational
  models.}
  The second algorithm, which is the main focus of this paper,
  goes in the other direction and computes
  , assuming that a suitable quadtree for  is at hand.
  
  The connection between quadtrees and Delaunay triangulations was first
  discovered and fruitfully applied by Buchin and
  Mulzer~\cite{BuchinMu11} (see also~\cite{BuchinLoMoMuXX}).
  While their approach is to use a hierarchy of quadtrees
  for faster conflict location in a randomized incremental
  construction of ,
  we pursue a strategy similar to the one by
  L{\"o}ffler and Snoeyink~\cite{LoefflerSn10}:
  we use the additional information
  to find a connected subgraph of ,
  from which  can be computed in linear deterministic 
  time~\cite{ChinWa99}.
  As in L{\"o}ffler and Snoeyink~\cite{LoefflerSn10},
  our subgraph of choice is the
  \emph{Euclidean minimum spanning tree} (EMST) for ,
  ~\cite{Eppstein00}.
  The connection between quadtrees and EMSTs is well known:
  initially, quadtrees were used to obtain fast approximations
  to  in high dimensions~\cite{CallahanKo93,Vaidya88}.
  Developing these ideas further, several algorithms  were found that
  use the \emph{well-separated pair decomposition}
  (WSPD)~\cite{CallahanKo95},
  or a variant thereof, to reduce EMST computation to
  solving the \emph{bichromatic closest pair} problem. In that
  problem, we are given
  two point sets  and , and we look for a
  pair  that minimizes the distance
  ~\cite{AgarwalEdScWe91,CallahanKo93,KrznaricLeNi99,Yao82}.
  Given a quadtree for , a WSPD for  can be found in
  linear time~\cite{BuchinLoMoMuXX,CallahanKo95,Chan08,HarPeled11}. 
  EMST algorithms based
  on bichromatic closest pairs constitute the fastest
  known solutions in higher dimensions. 
  Our approach is quite similar, but we focus exclusively
  on the plane. We use the quadtree and WSPDs to
  obtain a sequence of bichromatic closest pair problems,
  which then yield a sparse supergraph of the EMST. 
  There are several issues:  we need
  to ensure that the bichromatic closest pair problems
  have total linear size and can be solved in linear time,
  and we also need to extract the EMST from the supergraph
  in linear time.
  In this paper we show how to do this using
  the structure of the quadtree, combined with a partition of the
  point set according to angular segments similar to 
  Yao's technique~\cite{Yao82}.

  \subsection {Applications}

    Our two algorithms have several implications for derandomizing recent
    algorithms related to DTs. First,
    we mention \emph{hereditary} computation of DTs.
    Chazelle \etal~\cite {ChazelleDeHuMoSaTe02} show how to \emph{split} a Delaunay
    triangulation in linear expected time (see also~\cite{ChazelleMu11}).
    That is, given ,
    they describe a randomized algorithm to find  and
     in expected time . Knowing that DTs
    and quadtrees are equivalent, this result becomes almost obvious, as quadtrees
    are easily split in linear time. More importantly, our
    new algorithm achieves linear \emph{worst-case} running time.
Ailon \etal~\cite{AilonChClLiMuSe11} use hereditary
    DTs for 
    \emph{self-improving algorithms}~\cite{AilonChClLiMuSe11}.
    Together with the -net construction by Pyrga and Ray~\cite{PyrgaRa08}
    (see~\cite[Appendix~A]{AilonChClLiMuSe11}),
    our result yields a deterministic version of their algorithm for
    point sets generated by a random source (the inputs are probabilistic,
    but not the algorithm).

    Eppstein \etal~\cite {EppsteinGoSu08} introduce the skip-quadtree and show
    how to turn a (compressed) quadtree into a skip-quadtree in linear
    time.  Buchin and Mulzer~\cite{BuchinMu11} use a
    (randomized) skip-quadtree to find the DT in linear
    expected time.
    This yields several improved results
    about computing DTs. Most notably, they show
    that in the \emph{transdichotomous} 
    setting~\cite{ChanPa09,ChanPa10,FredmanWi94}, computing DTs
    is no harder than sorting the points (according to some special order).
    Here, we show how to go directly from a quadtree
    to a DT, without skip-quadtrees or randomness.
    This gives the first \emph{deterministic} transdichotomous reduction from
    DTs to sorting.

    Buchin \etal~\cite {BuchinLoMoMuXX} use both hereditary
    DTs and the connection between skip-quadtrees and DTs
    to simplify and generalize
    an algorithm by L{\"o}ffler and Snoeyink~\cite{LoefflerSn10}
    to preprocess imprecise points for Delaunay triangulation
    in linear expected time (see also Devillers~\cite{Devillers11} for another
    simplified, but not worst-case optimal, solution). L{\"o}ffler and Snoeyink's
    original algorithm is deterministic, and the derandomized version of the
    Buchin~\etal~algorithm proceeds in a very similar spirit. However, we
    now have an optimal deterministic solution for the generalized 
    problem as well.


    \eenplaatje [scale=0.9] {diagram}
    { We show which can be computed from which in linear time. The black
      arrows depict known linear time deterministic algorithms that work
      in the pointer machine/real RAM model. The red arrows depict our
      new results. Furthermore, for reference, we also show known 
      randomized linear time algorithms (in green) and known deterministic
      linear time algorithms that work in a weaker model of computation 
      (in blue).
    }

    In Figure~\ref {fig:diagram}, we show a graphical representation of 
    different proximity structures on planar point sets.
    The arrows show which structures can be computed from which in
    linear deterministic time on a pointer machine, before and after
    this paper.
    Please realize that there are several subtleties of different 
    algorithms and their interactions that are hard to show in a
    diagram, it is included purely as illustration of the impact of 
    our results.


  \subsection {Organization of this paper}
  
    The main result of our paper is an algorithm to compute a minimum spanning
    tree of a set of points from a given compressed quadtree. However, before
    we can describe this result in Section~\ref {sec:qt->dt}, we need to
    establish the necessary tools; to this end we review several known
    concepts in Section~\ref {sec:prelim} and prove some related technical
    lemmas in Section~\ref {sec:qt}.
    In Section~\ref {sec:dt->qt}, we describe the algorithm to compute a
    quadtree when given the Delaunay triangulation; this is an adaptation
    of the algorithm by Krznaric and Levcopoulos~\cite {KrznaricLe98} to the
    real RAM model.
    Finally, we detail some important implications of our two new algorithms
    in Section~\ref {sec:applications}.
  
  






















\section {Preliminaries} \label {sec:prelim}

  We review some known definitions, structures, 
  algorithms, and their relationships.


  \subsection {Delaunay Triangulations and Euclidean Minimum Spanning Trees}

    Given a set  of  points in the plane, an important and extensively
    studied structure is the \emph {Delaunay triangulation} of ~\cite
    {deBergChvKrOv08,BoissonnatYv98,d-slsv-34,PreparataSh85,ShamosHo75}, 
    denoted .  It can be defined as the dual graph of the
    Voronoi diagram, the triangulation that optimizes the smallest angle in any
    triangle, or in many other equivalent ways, and it has been proven to
    optimize many other different criteria~\cite {m-pdt-97}.

    The \emph {Euclidean minimum spanning tree} of , denoted , 
    is the tree of smallest total edge length that has the
    points of  as its vertices, and it is well known that the EMST is a
    subgraph of the DT~\cite[Theorem~7]{ShamosHo75}.
    In the following, we will assume that all the pairwise distances in
     are distinct (a general position assumption), which implies that
     is uniquely determined. Finally, we remind the reader that
    , like every minimum spanning tree, has 
    the following \emph{cut property}: let 
    a partition of , and let  and  be the two points with  and
     that minimize  the distance . Then  is an edge
    of . Note that this is very similar to the bichromatic closest 
    pair reduction mentioned in the introduction, but the cut property
    holds for any partition of , whereas the bichromatic closest
    pair reduction requires a very specific decomposition of  into pairs
    of subsets (which is usually not a partition).

 \subsection {Quadtrees---Compressed and -Cluster}
  \label {sec:cqt&cqt}

    Let  be a planar point set.
    The \emph{spread} of  is defined as the
    ratio between the largest and the smallst distance between
    any two distinct points in .
    A \emph{quad\-tree} for  is a hi\-erarchical
    decomposition of an axis-aligned bounding square for  into smaller
    axis-aligned
    \emph{squares}~\cite{deBergChvKrOv08,FinkelBe74,HarPeled11,Samet90}.
    A \emph{regular} quadtree is constructed by
    successively subdividing every square with at least two points
    into four congruent child squares. A node  of a quadtree
    is associated with
    (i) , the square corresponding to ;
    (ii) , the points contained in ; 
    and (iii) , the axis-aligned bounding square for
    .
     and  are stored explicitly at the node.
    We write  and   for the diameter of
     and , and  for the center of .
    We will also use the shorthand 
    to denote the shortest distance between any point in  and
    any point in .
    Furthermore, we denote the parent of  by .
    Regular quadtrees can have unbounded depth (if  has unbounded 
    spread
    so in order to give any theoretical guarantees the concept is
    usually refined.
    In the sequel, we use two such variants of quadtrees, namely
    \emph{compressed} and \emph{-cluster} quadtrees,
    which we show are in fact equivalent.

    A \emph {compressed} quadtree is a quadtree in which we replace
    long paths of nodes with only one child by a single 
    edge~\cite{BernEpGi94,BernEpTe99,BuchinLoMoMuXX,Clarkson83}.
    It has size .  Formally,
    given a large constant , an -compressed quadtree
    is a regular quadtree with additional \emph{compressed} nodes.\footnote
    {Such nodes are often called \emph {cluster}-nodes in the
    literature~\cite{BernEpGi94,BernEpTe99,BuchinLoMoMuXX},
    but we prefer the term \emph {compressed} to avoid confusion with
    -cluster quadtrees defined below.}
    A compressed
    node  has only one child  with
     and such that 
    has no points from . 
    Figure~\ref {fig:ex-compquad-notaligned} shows an example.
     Note that in our definition
     need not be aligned with , which would
    happen if we literally ``compressed'' a regular quadtree.
    This relaxed definition is necessary because existing algorithms for 
    computing
    aligned compressed quadtrees use a more powerful model of
    computation than our real RAM/pointer machine
    (see Appendix~\ref{app:models}).  In the usual applications of quadtrees,
    this is acceptable. In fact, Har-Peled~\cite[Chapter~2]{HarPeled11}
    pointed out that some non-standard operation is
    \emph{inevitable} if we require that the squares of the compressed quadtree
    are perfectly aligned. However, here we intend to derandomize algorithms
    that work on a traditional real RAM/pointer machine, so we
    prefer to stay in this model. This keeps our results comparable with the
    previous work.
    
  
    \drieplaatjes {ex-compquad-notaligned} {ex-ccluster} {ex-cclusquad} 
    { (a) A compressed quadtree on a set of  points.
      (b) A -cluster tree on the same point set.
      (c) In a -cluster quadtree, the internal nodes of the -cluster tree are replaced by quadtrees.      
    }    

    Now let  be a large enough constant.
    A subset  is a \emph{-cluster} if  or
    , where  denotes the
    smallest axis-aligned bounding square
    for , and  is the minimum distance between a point in 
    and a point in ~\cite{KrznaricLe95,KrznaricLe98}. In other words, 
     is a -cluster precisely if  is a
    -\emph{semi}-separated pair~\cite{HarPeled11,Varadarajan98}.
    It is easily seen that the -clusters for  form a laminar
    family, i.e., a set system in which any two sets  and   satisfy either
    ; ; or .
    Thus, the -clusters define a \emph{-cluster tree} .
    Figure~\ref {fig:ex-ccluster} shows an example.
    These trees are a very natural way to tackle
    point sets of unbounded spread, and they have linear size. However,
    they also may have high degree. To avoid this, a -cluster tree
     can be augmented by additional nodes, adding more structure
    to the parts of the point set that are not strongly clustered.
    This is done as follows. First, recall that a 
      quadtree is called \emph {balanced} if for every node 
       that is either a leaf or a compressed node,
     the square  is adjacent only to squares that are within a factor 
     of the size of .\footnote{We remind the reader that in our 
     terminology,
     a \emph{compressed node} is the node whose square contains a much
     smaller quadtree, and not the root node of the smaller quadtree.}
    For each
    internal node  of  with set of children , we
    build a balanced regular quadtree on a set of points
    containing one representative point from each node in 
    (the intuition being that such a cluster is so small and far from its
    neighbors, that we might as well treat it as a point). This
    quadtree has size  (Lemma~\ref{lem:c-cluster-QT}), so
    we obtain a tree of constant degree and linear size,
    the \emph {-cluster quadtree}.
    Figure~\ref {fig:ex-cclusquad} shows an example.
    The sets ,  and 
    for the -cluster quadtree are just as for regular and compressed
    quadtrees, where in  we expand the representative points
    appropriately.
    Note that it is possible that , but the points 
    of  can never be too far from .
    In Section~\ref {sec:ccqt} we elaborate more on -cluster quadtrees 
    and their properties, and in Section~\ref{sec:compressed-c-cluster}, 
    we prove that -cluster quadtrees and compressed quadtrees
    are equivalent (Theorem~\ref{thm:cluster-compressed-equiv}). 

 \subsection {Well-Separated Pair Decompositions}

    For any two finite sets  and , let
    .
    A \emph {pair decomposition}
     for a planar\footnote
    {Although some of these notions extend naturally to higher dimensions,
    the focus of this paper is on the plane.}
    -point set  is a set of  \emph {pairs}
      , such
    that
    (i) for all , we have  and
       ; and
    (ii) for any , there is exactly one  with
      .
    We call  the \emph{size} of .
    Fix a constant , and let .
    Denote by ,  the smallest axis-aligned squares containing
     and . We say that 
    is \emph{-well-separated} if ,
    where  is the distance between  and  (i.e.,
    the smallest distance
    between a point in  and a point in ).
    If  is not -well-separated, we say it is
    \emph{-ill-separated}.
    We call  an
    \emph {-well-separated pair decomposition} (-WSPD)
    if all its pairs are
    -well-separated~\cite{CallahanKo93,CallahanKo95,Eppstein00,HarPeled11}.



    Now let   be a (compressed or -cluster) quadtree for .
    Given , it is well known that  can be used to
    obtain an -WSPD for  in linear time~\cite{CallahanKo95,HarPeled11}.
    Since we will need some specific properties of such an -WSPD,
    we give pseudo-code for such an  algorithm 
    in Algorithm~\ref{alg:wspd}. We call this algorithm
    , and denote its output on input  by .
    The correctness of the algorithm  is immediate,
    since it only outputs well-separated pairs, and the bounds on the
    running time and the size of  follow from a well-known
    volume argument which we
    omit~\cite{BuchinLoMoMuXX,CallahanKo95,Chan08,HarPeled11}.
   \begin{algorithm}[ht]
    \begin{enumerate}
    \item Call  on the root  of .
    \end{enumerate}
    
    \begin{enumerate}
    \item If  is a leaf, return .
    \item Return the union of  and
       for all children  and
      pairs of distinct children  of .
    \end{enumerate}
    \vskip0.2cm
    \noindent
    
    \begin{enumerate}
    \item If  and  are
    -well-separated, return .
    \item Otherwise, if , return
       the union of  for all children  of .
    \item  Otherwise, return the union of  for all
       children  of .
    \end{enumerate}
    \caption{Finding a well-separated pair decomposition.}
    \label{alg:wspd}
    \end{algorithm}


    \begin{theorem}\label{thm:wspd}
       There is an algorithm \emph{}, that given a 
       (compressed or -cluster) 
       quadtree  for a planar -point set , finds in time 
       a linear-size -WSPD for , denoted \emph{}.
       \qed
    \end{theorem}


    Note that the WSPD is not stored explicitly: we cannot afford to
    store all the pairs , since their total size might be
    quadratic. Instead,  contains pairs , where 
    and  are nodes in , and   is used to represent
    the pair . 



    Note that the algorithm computes the WSPD with respect to the squares
    , instead of the bounding squares . This makes no big difference,
    since for compressed quadtrees , and for
    -cluster quadtrees  can be outside  only for
    -cluster nodes, resulting in a loss of at most a factor 
    in separation. 
    Referring to the pseudo-code in Algorithm~\ref{alg:wspd}, 
    we now prove three observations. The first observation says
    that the size of the squares under consideration strictly 
    decreases throughout the algorithm.

    \begin{observation} \label{obs:parents-bigger}
    Let  be a pair of distinct nodes of . If 
    \emph{}
    is executed by \emph{} run
    on  (in particular, if \emph{}),
    then .
    \end{observation}


    \begin{proof}
    We use induction on the depth of the call stack for
    . Initially,  and  are children 
    of the same node, and the statement holds.
    Furthermore, assuming that  is called by
     (and hence ), we get
    ,
    where the last equation follows by induction.
    \end{proof}

    The next observation states that the wspd-pairs reported by the
    algorithm are, in a sense, as high in the tree as possible.
    \begin{observation}\label{obs:parents-not-ws}
    If \emph{},
    then  and  are ill-separated.
    \end{observation}

    \begin{proof}
    If , the claim is obvious. Otherwise, let us assume
    that  was  called by . This means
    that  is ill-separated and
    .
    Therefore, 
    ,  and  is ill-separated.
    \end{proof}

   The last claim shows that for each wspd-pair, we can find
   well-behaved boxes whose size is comparable to the distance
   between the point sets. In the following, this will be a useful tool
   for making volume arguments that bound the number of wspd-pairs to consider.
\begin{claim}\label{clm:quad-squares}
Let \emph{}.
Then there exist squares  and  such that
(i)  and
    ;
(ii) ;
and (iii) .
\end{claim}

\begin{proof}
Suppose  is called by
, the other case is symmetric.
Let us define .
By Observation~\ref{obs:parents-bigger},
we have .
 Since 
is well-separated, we have .
Hence, ,
and we can pick squares  and  of diameter  that fulfill (i).
Now (ii) holds by construction, and it remains to check (iii).
First, note that , for . This
proves the lower bound.
For the upper bound, observe that
, because 
is ill-separated. Thus, we have ,
and , as desired.
\end{proof}

    

\section{More on Quadtrees} \label {sec:qt}


  In this section, we describe a few more properties of the -cluster
  trees and -cluster quadtrees defined in Section~\ref{sec:cqt&cqt}, 
  and we prove that they are equivalent to the more standard compressed
  quadtrees (Theorem~\ref {thm:cluster-compressed-equiv}).
  Since most of the material is very technical, we encourage 
  the impatient reader to skip ahead to Section~\ref {sec:qt->dt}.

  \subsection {-Cluster Quadtrees} \label {sec:ccqt}

    
    Krznaric and Levcopolous~\cite[Theorem~7]{KrznaricLe95} showed that a
    -cluster tree can be computed in linear time from a Delaunay 
    triangulation.
    \begin{theorem}[Krznaric-Levcopolous]\label{thm:c-cluster-tree}
      Let  be a planar -point set.
      Given a constant  and , we can find a -cluster
      tree  for  in  time and space on a pointer machine.
      \qed
    \end{theorem}

    Here, we will actually use a more relaxed notion of -cluster
    trees: let ,  be two constants with
    , and let  be a planar -point set.
    A \emph{-cluster tree}  is a rooted
    tree in which each inner node has at least two children and
    which has  leaves, one for each point in . 
    Each node  corresponds to a subset 
    in the natural way. Every node  must fulfill
    two properties:
    (i) if  is not the root, then
      ; and
    (ii) if  has a proper subset  with
       , then
       there is a child  of  with .
    In other words, each node of  corresponds to
    a -cluster of , and  must have a node for every
    -cluster of .  Thus, the original -cluster tree is also 
    a -cluster tree. Our relaxed definition allows for some flexibility
    in the construction of  while providing the same
    benefits as the original  -cluster tree. Thus, outside this section
    we will be slightly sloppy and not distinguish between -cluster trees
    and -cluster trees.

      As mentioned above, the tree  is quite similar 
      to a well-separated pair decomposition: any two unrelated nodes
      in  correspond to a -well-separated pair. 
      However,  has the huge drawback that it may contain
      nodes of unbounded degree.  For example, if
      the points in  are arranged in a square grid,
      then  consists of a single root with  children.
      Nonetheless,  is still useful, since it represents
      a decomposition of  into well-behaved pieces. 
      As explained above,  the -cluster quadtree
       is obtained by augmenting 
      with quadtree-like pieces to replace the nodes with many children.

      
      We will now prove some relevant properties of -cluster
      quadtrees. 
      For a node  of , let  be the balanced regular 
      quadtree on the representative points of 's children.
      The \emph{direct neighbors} of a square  in  
      are the  squares of size  that surround .
      First, we recall how the balanced tree  is obtained: we start with
      a regular (uncompressed) quadtree  for the representative points.
      While  is not balanced, we take a leaf square  of  that
      is adjacent to a leaf square of size less than  and
      we split  into four congruent child squares. The following
      theorem is well known.
     \begin {theorem} [Theorem~14.4 of \cite{deBergChvKrOv08}]
    \label {thm:balance}
      Let  be a quadtree with  nodes. 
      The above procedure yields a balanced
      quadtree with  nodes, and it can be implemented
      to run in  time.
      \qed
    \end {theorem}

     
    Let  be a child of  in .
    The properties of the balanced quadtree  and the
    fact that the children of  are mutually well-separated yield 
    the following observation.
    
      \begin {observation} \label {obs:close}
        If  is large enough,
        at most four leaf squares of  contain points from .
      \end {observation}
      
      \begin {proof}
        Let  be the diameter of the bounding square for 
	. By definition,  is a -cluster,
        so the distance from any point in  to any point
        in  is at least .
	Suppose that  is a leaf square of  with
	, and let  be the parent of .

	There are two possible reasons for the creation of :
	either  is part of the original regular quadtree for
	the representative points, or  is generated during the
	balancing procedure.
	 In the former case, 
	 contains at least two representative points.  
	Thus, since in  there is a point from  and 
	a point from ,
	we have . In the latter case, 
	 must be a direct neighbor of a square with
	at least two representative points 
	(see~\cite[Proof of Theorem~14.4]{deBergChvKrOv08}).
	Therefore, since   contains
	a point from  and has a direct neighbor with a point
	from , the diameter of  is at least
	. Either way, we certainly have 
	.

        Now if , then , so the side length
	of every leaf square  that intersects  is strictly larger than
	. Thus,  can be covered by at most  such squares,
	and the claim follows. 
      \end{proof}

      To see that -cluster quadtrees have linear size, we need 
      a property that is (somewhat implicitly)
      shown in~\cite[Section~4.3]{KrznaricLe98}.

      \begin{lem}\label{lem:c-cluster-QT}
      If  has  children , , ,  in , 
      then  has  nodes.
      \end{lem}

      \begin{proof}
      Note that the total number of nodes in  is
      proportional to the number of 
      squares that contain at least two representative points.
      Indeed, the number of squares in a balanced regular quadtree
      is proportional to the number of squares in the corresponding 
      unbalanced regular quadtree (Theorem~\ref{thm:balance}), and in that tree 
      the squares with
      at least two points correspond to the internal nodes, each
      of which has exactly four children.
      Thus, it suffices to 
      show that the number of squares in  with at least two representative 
      points is .

      Call a square  of  \emph{full} if  contains a representative
      point. 
      A full square  is called \emph{merged} if it has
      at least two full children.  There are
       merged squares, so 
      we only need to bound the number of non-merged full squares
      with at least two points. 
      These squares can be charged to the merged squares,
      using the following claim.
     
      \begin{claim}\label{clm:merged_ancestor}
       There exists a constant  (depending on ) such
       that the following holds:
      for any full square  with at least two representative points,
      one of the  closest ancestors of 
      in  (possibly  itself) is either merged or 
      has a merged direct neighbor.
      \end{claim}
      \begin{proof}
      Let  be a non-merged full square with at least two representative points.
      Since  intersects more than one , the definition of
       implies that the set 
       is not a -cluster. Thus, 
       contains a point at distance at most  from .
      Hence,  has an ancestor  in  that is at most
       levels above  and that has a full direct 
      neighbor  (note that  is balanced, so 
       actually belongs to ). 

      We repeat the argument: since
       is not a -cluster, there is a point in
       at distance
      at most  from . Thus, if we go up
       levels in , we either encounter a common ancestor
      of  and , in which case we are done, or we have found
      a set  of
      three full squares of  such that (i) one square in
       is an ancestor of ; (ii) the squares in 
      have equal size;  and (iii) the squares in  
      form a (topologically) connected set.

      We keep repeating the argument while going up the tree. 
      In each step, if we do not encounter a common ancestor of
      at least two squares in ,
      we can add one more full square to .
      However, as soon as we have five squares of equal size
      that form a connected set, at least two of them have a common
      parent. Thus, the process stops after at most two more
      iterations. Furthermore, since  is connected, once at least two 
      squares in  have a common parent, the parents of the other
      squares must be direct neighbors of that parent. Hence, 
      we found an ancestor of  that is
      only a constant number of levels above  and that is merged
      or has a merged direct neighbor, as desired.
      \end{proof}
      
      Now we use Claim~\ref{clm:merged_ancestor} to charge
      each non-merged full node with at least two representative points
      to a merged node.
      Each merged node is charged at most 
       times, and Lemma~\ref{lem:c-cluster-QT} 
      follows.
      \end{proof}

  The proof of Lemma~\ref{lem:c-cluster-QT} implies the following, slightly
  stronger claim: Recall that  was constructed by building
  a regular quadtree for the representative points for 's children,
  followed by a balancing step. Now, suppose that before the balancing
  step we subdivide each leaf that contains a representative
  point for a -cluster  until it has size at 
  most , for some constant  (if the 
  leaf is smaller than , we do nothing).
  Call the tree that results after the balancing step .
  \begin{cor}\label{cor:c-cluster-QT-extended}
      The tree  has  nodes.
  \end{cor}

  \begin{proof}
    We only need to worry about the additional squares created during the
    subdivision of the leaves. If we take such a square and go up
    at most  levels in the tree, we get a square with a direct
    neighbor that contains a point from another cluster. Now the 
    argument from the proof of Lemma~\ref{lem:c-cluster-QT} applies
    and we can charge the additional squares to merged squares, as before.
  \end{proof}
  \subsection{Balancing and Shifting Compressed Quadtrees}
    \label{sec:shiftbalance}

\tweeplaatjes {shift-plain} {shift-comp}
{
  (a) A regular quadtree on a set of  points.
  (b) A slight shift of the base square may cause many new compressed nodes in the quadtree.
}

    In this section, we show that it is possible to ``shift'' a quadtree; that is, given a compressed quadtree on a set of points  with base square , to compute another compressed quadtree on  with a base square that is similar to , in linear time.
    The main difficulty lies in the fact that the clusters in the two quadtrees can be very different, as illustrated in Figure~\ref {fig:shift-plain+shift-comp}.

    \begin {theorem} \label {thm:shiftbalance}
      Suppose  is a sufficiently large constant and
       a planar -point set.
      Furthermore, let  be an -compressed quadtree
      for  with base square , and let  be a square with
       and . 
      Then we can construct in  time a balanced -compressed quadtree 
      for  with base square  and with  nodes.
    \end {theorem}

    The idea is to construct  in the traditional way through
    repeated subdivision of the base square , while using the information
    provided by  in order to speed up the point location. 
    We will use the terms \emph{-square} and \emph{-square} to
    distinguish the squares in the two trees.
    During the subdivision process, we maintain the partial tree , 
    and for each square  of  
    we keep track of the -squares that have similar size
    as  and that intersect  (in an associated set). 
    We call the leaves of the current partial tree the
    \emph{frontier} of . In each step, we
    pick a frontier -square and split it, until we have reached
    a valid quadtree for . 
    We need to be careful in order to keep  
    balanced and in order to deal with compressed nodes. The former problem
    is handled by starting a cascading split operation as soon as 
    a single split makes  unbalanced.
    For the latter problem, we would like to treat the compressed children
      in the same way as the points in , and handle them
      later recursively. However, there is a problem: during the
      balancing procedure, it may happen that a compressed child becomes
      too large for its parent square and should be part of the regular
      tree. In order to deal with this, we must keep track of the compressed
      children in the associated sets of the -squares. When we detect
      that a compressed child has become too large for its parent, we treat
      it like a regular square. Once we are done, we recurse on the 
      remaining compressed children. Through a charging scheme, we can show
      that the overall work is linear in the size of .
      The following paragraphs describe the individual steps of the algorithm 
      in more detail.

   \paragraph{Initialization and Data Structures.}
      We obtain from   a grid with squares of size in
       , either by repeatedly subdividing 
      , if ; or by repeatedly doubling ,
      if . Since , this requires a constant
      number of steps. Then we determine
      the -squares  of that grid that intersect  
      (note that ). Our algorithm maintains the 
      following data structures:
      (i) a list  of \emph{active} -squares; and (ii) for each 
      -square  a list  of \emph{associated} -squares. 
      We will maintain the invariant that  contains the smallest 
      -squares that have size at least   and that intersect , as
      well as any compressed children that are contained in such a
      -square and that intersect . This invariant implies
      that each  has  associated squares. We call
      a -square  \emph{active} if 
       contains a -square
      of size in  or a compressed child of size in 
      . 
      Initially, we set  
      and ,
      fulfilling the invariant.
  
    \paragraph{The Split Operation.}
      The basic operation of our algorithm is the \emph{split}.
      A split takes a -square  and subdivides it into
      four children . Then it computes
      the associated sets  as follows.
      For each , we intersect 
       with all -squares in , and we put those -squares 
      into  that have non-empty intersection with .
      Then we replace each -square in  that is neither a 
      leaf, nor a compressed node, nor a compressed child by those of its
      children that have non-empty intersection with . Finally, we remove
      from  those compressed nodes whose compressed children have
      size at least  and intersect . Having determined
      , we use it to check whether  is active. If so, we add 
      it to . The split operation maintains the invariant
      about the associated sets, and it takes constant time.
      
    \paragraph{Main Body and Point-Location.}
      We now describe the main body of our algorithm. It consists of 
      \emph{phases}. In each phase, we remove a -square 
       from . We perform a split operation on  as
      described above. Then, we start the \emph{balancing procedure}. 
      For this, we check the four -squares in the
      current frontier that are directly above, below, to the left 
      and to the right of  to see whether any of 
      them have size .
      We put each such -square into a queue . Then, while 
      is not empty, we remove a square  from  and perform a
      split operation on it (note that this may create new active
      squares). Furthermore, if  is in , 
      we remove it from .  Finally, we consider the
      -squares of the current frontier directly above, below, to 
      the left and to the right
      of . If any of them have size  and are not in  yet, we 
      append them to  and continue. The balancing procedure, and 
      hence the phase, ends once  is empty.

      We continue this process until  is empty. Next, we do
       \emph{point-location}. Let  be a
      -square of the current frontier. Since  is empty, 
       is associated with  -squares, all of 
      which are either leaves or compressed nodes or 
      compressed children in . For each -leaf that intersects 
      , we determine whether it contains a point that lies 
      in . In the end, we have a set of
      at most four points from   or compressed children of 
      that intersect , and we call this set the \emph{secondary} associated
      set for , denoted by . We do this for every -square
      in the
      current frontier. 
      
      \paragraph{The Secondary Stage.}
      Next, the goal is to build a small compressed quadtree for the secondary
      associated set of each square in the current frontier. Of course,
      the tree needs to remain balanced.
      For this, we start an operation that is similar to the main body of the 
      algorithm.  We call a -square  \emph{post-active} if 
       and the smallest bounding
      square for the elements in  has size larger than .
      We put all the post-active squares into a list  and we proceed
      as before: we repeatedly take a post-active square from ,
      split it, and then perform a balancing procedure. Here,
      the splitting operation is as follows: given
      a square , we split it into four children .
      By comparing each child  to each element in the secondary associated
      set , we determine the new secondary associated sets 
      . We use these associated sets to check
      which children  (if any) are post-active and add them to ,
      if necessary. This splitting
      operation takes constant time. Again, it may
      happen that the balancing procedure creates new post-active
      squares. We repeat this procedure until 
       is empty.



      \paragraph{Setting Up the Recursive Calls.}
      After the secondary stage, there are no more post-active squares, so 
      for each square  in the current frontier
      we have (i) ; or (ii) the smallest bounding
      square of  has size at most .
      Below in Lemma~\ref{lem:secondary-bound} 
      we will argue that if  contains a single
      compressed child , then  has size at most
      . Thus, (ii) holds in any case. 
      The goal now is to set up a recursive call of the algorithm to handle
      the remaining compressed children. Unfortunately, a compressed
      child may intersect several leaf -squares,
      so we need to be careful about choosing the base squares for the
      recursion. 

      \tweeplaatjes {shift-rec} {shift-rec2}
      { (a) A frontier square  of  intersects several compressed children of . We identify the list  of  squares that intersect the same children.
        (b) To apply the shifting algorithm recursively, we choose base squares  and  aligned with  and .
      }
      
      Let  be a square of the current frontier, and set .
      While there is a compressed child  in 
       that intersects 
      the boundary of 
      , we add all the -squares 
      of the current frontier
      that are intersected by  to .  Since  is balanced, the 
      -th square  that we add to  has size at most  and
      hence the bounding square of   has size at most 
      . By construction,  contains at least
      one element that intersects a square in the old , so by induction
      we know that after  steps the set
       has a bounding square of size at most
      . It follows that the process stops after at most
      three steps (i.e., when  has four elements), because after
      four steps we would have a bounding square of size at most 
      
      that is intersected by five disjoint squares of size at least 
       (since 
       is balanced), which is impossible (for  large enough).
      Figure~\ref {fig:shift-rec} shows an example.

      Now we put two base squares around : a square 
      that is aligned with , and a square  that is 
      aligned with . For , if  contains 
      only one element, we just use the bounding square of .
      If , then the elements
      of  are separated by an edge or a corner between 
      leaf -squares. Thus,
      we can pick a base square  for  such that 
      (i) ; (ii)  is 
      aligned with ; and (iii) the first split of  
      separates the elements in .
      For , if , we just use the bounding square for
      . If , the squares in  must share a common
      edge or corner, and we can find a base square  such that
      (i)  contains ; (ii) the first split of 
       produces squares that are aligned with this edge or 
      corner of ; and (iii) .
      Figure~\ref {fig:shift-rec2} shows an example.
      We now construct an -compressed quadtree 
      with base square  for the elements of 
      in the obvious way. (If  contains any compressed children, 
      we reuse them as compressed children for . This may 
      lead to a violation of the condition for compressed nodes at the 
      first level of . However, our algorithm automatically 
      treats large compressed children as active squares, so there is no 
      problem.) This takes constant time.  We call the algorithm recursively 
      to shift  to the new base
      square . Note that this leads to a valid -compressed
      quadtree since either  is wholly contained in ;
      or the first split of  produces squares that are wholly
      contained in the -leaf squares and have size at most ,
      while each square that intersects  has size at least
      , as  is  balanced. We repeat the procedure 
      for every leaf -square whose secondary associated set we 
      have not processed yet.
      
      \paragraph{Analysis.}
      The resulting tree  is a balanced -compressed quadtree
      for . It remains to prove that the algorithm runs in linear time.
      The initialization stage needs  steps.
      Next, we consider the main body of the algorithm.
      Since each split takes constant time, the total running time 
      for the main body is proportional to the number of 
      splits. Recall that a -square  is called \emph{active} if 
      it is put into , i.e., if  contains a -square of
      size in  or a compressed child of size
      in . Since each -square can cause only
      a constant number of -squares to be active, the total 
      number of active -squares is . Thus, we can use the following 
      lemma to conclude that the total number of
      splits in the main body of the algorithm is linear.
      
      \begin{lem}\label{lem:main-body}
         Every split in the main body of the algorithm can be charged
	 to an active -square such that each such square
	 is charged a constant number of times.
      \end{lem}

      \begin{proof}
      If we split an active square , we can trivially
      charge the split to .
      Hence, the critical splits
      are the ones during the balancing procedure. 
      By induction on the number of steps of the balancing
      procedure, we see that if a square  is split, there must be 
      a square  in the current partial tree  that is a direct 
      neighbor of  and that has an active descendant whose 
      removal from   triggered the
      balancing procedure.\footnote{Recall that a direct neighbor
      of  is one of the eight squares of size  that surround
      .}

      If  has an active ancestor  that is at 
      most five levels above  in  (possibly ), 
      we charge the split of  to
      , and we are done. Otherwise, we know that
       contains at least one compressed child of
      size less than  (otherwise,  would not
      have an active descendant or would itself be active) 
      and -squares of size at least
       (otherwise, one of the five nodes above  in  
      would have been active). Now, before  is split, there
      must have been a split on : otherwise the
      active descendant of  that triggers
      the split on  would not exist. Thus, we repeat the argument to show
      that  has a direct neighbor  with an
      active descendant that triggers the split of . 
      Note that , because the split on  happens before
      the split on .
      If  has an active ancestor that is at most five levels higher up in
       (possibly  itself), we are done again. 
      Otherwise, we repeat the argument again. 
      
      We claim that this process finishes after at most  steps. 
      Indeed, suppose we find  squares 
       without stopping. 
      We know that each  is a direct neighbor of  and that
      each  is associated with a compressed child of size
      at most  and with -squares of size at least
      . Since the set  has
      diameter at most , the set 
      contains at most four -squares of size at least .
      Now each compressed child in an associated set
       is the only child of one of these four large -squares,
      so there are at most four of them.
      Furthermore, each such compressed child is intersected by at
      most four disjoint -squares of size , so 
      there can be at most  squares , a contradiction.
      Hence, we can charge each split to an active square in the
      desired fashion, and the lemma follows.
      \end{proof}
       
      Next, we analyze the running time of the secondary stage. Again,
      the running time is proportional to the number of splits, which
      is bounded by the following lemma.

      \begin{lem}\label{lem:secondary-bound}
         Let  be a frontier -square at the beginning of the
	 secondary stage. Then after the secondary stage, the subtree
	 rooted at  has height at most .
      \end{lem}
      \begin{proof}
      Below, we will argue that for every descendant  of ,
      if  contains a compressed child , then
      . For now, suppose that this holds.

      First, we claim that there are  splits
      to post-active descendants of . 
      The secondary associated set  contains at most four 
      elements, so  has at most  subsets with
      two or more elements. Fix such a subset .
      Then  has at most  post-active
      descendants with secondary associated set .
      This is because each level of  has at most two squares
      with secondary associated set , and 
      the post-active squares with secondary associated set 
      must have size between  and 
      , where  denotes the
      smallest bounding square for the elements in . 
      (Here we use our claim that the compressed children in
      the secondary associated set of each frontier -square 
       are much smaller
      than .) There are only  such levels, so
      adding over all , we see that  has 
      at most  post-active descendants, implying the
      claim.

      Each split creates at most one new level below ,
      so there are only  new levels 
      due to splits to post-active descendants of .
      Next, we bound the number of new levels that are created by
      splits during the balancing phases. Each balancing phase
      creates at most one new level below .
      Furthermore, by induction on the number of steps in the 
      balancing phase, we see that the balancing phase was
      triggered by the split of a post-active square
      that is a descendant either of  or of a direct neighbor
      of .
      At the beginning of the secondary stage, there
      are   -squares that are descendants of direct 
      neighbors of  (as  is balanced). As we argued above, each 
      of them has at most  post-active descendants.
      Thus, the balancing phases add at most  new levels below
      .
      
      Finally, we need to justify the assumption that for any descendant 
      with a compressed child , we have .
      By construction, we have . Suppose that 
      has a descendant  that violates this assumption. The square  was
      created through a split in the secondary stage, and suppose that 
      is the first such square during the whole secondary stage. This means
      that during all previous splits, the assumption holds, so by the
      argument above, there are at most  levels below . 
      This means that , so we would get
      ,
      a contradiction (for  large enough). Thus, no  can violate the
      assumption, as desired.
      \end{proof}
       
      The time to set up the recursion is constant for each square of the
      current frontier. From Lemmas~\ref{lem:main-body} and 
      \ref{lem:secondary-bound}, we can conclude that the total time of
      the algorithm is , which also implies that  has 
      squares. This concludes the proof of Theorem~\ref{thm:shiftbalance}.

    \paragraph{Special Cases.}
    We note two useful special cases of Theorem~\ref{thm:shiftbalance}.
    The first one gives an analog of Theorem~\ref{thm:balance} for compressed
    quadtrees.
    \begin {cor} \label {cor:balance-'n-thread}
      Let  be a -compressed quadtree with  nodes. 
      There exists a balanced -compressed quadtree that contains ,
      has  nodes and can be constructed in  time.
    \end {cor}

   \begin{proof}
      Let  be the base square of . We apply 
      Theorem~\ref{thm:shiftbalance} with . 
   \end{proof}

    The second special case says that we can realign an uncompressed 
    quadtree locally in any way we want, as long as we are willing
    to relax the definition of quadtree slightly.\footnote
    {We cannot get a non-relaxed (-relaxed) uncompressed quadtree, since two points could be arbitrarily close to each other if they were separated by a boundary. However, we can always turn a -relaxed quadtree into a non-relaxed compressed quadtree in linear time again.}
    Let  be a planar point set.
    We call a quadtree for  \emph {-relaxed} if it has at most
     points of  in each leaf, and is otherwise a regular quadtree.
    \begin {cor} \label {cor:qt-shift}
      Let  be a planar point set and  a regular quadtree for , 
      with base square .
      Let  be another square with  and 
      .
      Then we can build a -relaxed quadtree  for  
      with base square  in  time such that
       has  nodes.      
    \end {cor}

   \begin{proof}
      We apply Theorem~\ref{thm:shiftbalance} to , but we stop the
      algorithm before the beginning of the secondary stage.
      Since each secondary associated set for a leaf square has
      at most four elements, and since  contains no compressed
      nodes, the resulting tree  has the desired properties.
   \end{proof}


\subsection{Equivalence of Compressed and -Cluster Quadtrees}
\label{sec:compressed-c-cluster}

    The goal of this section is to prove the following theorem.
    \begin{theorem}\label{thm:cluster-compressed-equiv}
      Let  be a planar -point set.  Given a
      -cluster quadtree on , we can compute in  time an
      -compressed quadtree on ; and given an -compressed
      quadtree on , we can compute in  time an
      -cluster quadtree on .
    \end{theorem}
   
    We present the proof of Theorem~\ref{thm:cluster-compressed-equiv}
    in two lemmas.

    \begin{lem} \label{lem:c-cluster->compressed}
    Let  be a planar -point set. Given a
    -cluster quadtree  for , we can compute in linear time an
    -compressed quadtree  on .
    \end{lem}

    \begin{proof} 
      We construct the compressed quadtree in a top-down fashion, 
      beginning from the root. Suppose that we have constructed a
      partial compressed quadtree , and let  be the representative
      point for a node  in the -cluster tree 
       that corresponds
      to . We show how to expand  in  to the corresponding
      quadtree . 

      First, we add to  a new root that is aligned with the
      old base square and larger by a constant factor, such that
      the old base square does not touch any boundary of the
      new one. Next, we determine by a search from 
      which leaf squares of  intersect
      . By Observation~\ref{obs:close}, there are at most
      four such leaves, so this step takes constant time.
      (Note that since we grow the base square of each quadtree that we
      expand, it cannot happen that  intersects the boundary of
      its parent quadtree.) Next, we repeatedly split
      each leaf that intersects  and that contains some other point
      or compressed child until there are no more such leaves.

      The proof of Observation~\ref{obs:close} shows that
      every leaf square of  that intersects
       has size at least , where 
      is the size of 's base square.
      If  lies completely inside a
      leaf of , we add  as a compressed child to . 
      If  intersects more than one leaf square,  we
      identify a square at most twice the size of 's base square that is
      aligned appropriately with the relevant edges of , 
       and apply Corollary~\ref{cor:qt-shift} to shift  
       to this new base square.  
      This results in a valid  compressed quadtree in which
       has been expanded. We repeat this process until all the quadtree
      pieces of  have been integrated into a large compressed quadtree.

      The total time for the top-down traversal and for the realignment
      procedures is linear. Furthermore, 
      Corollary~\ref{cor:c-cluster-QT-extended} shows that the 
      total work for splitting
      the leaves of  is also linear, since the points in the different
      clusters are -semi-separated. Hence, the total running time
      is linear.
    \end{proof}

    \begin{lem}\label{lem:compressed->c-cluster}
      Let  be a planar -point set, and  be an -compressed
      quadtree for . Then we can compute in linear time a
      -cluster quadtree for .
    \end{lem}

    \begin{proof} 
      We use 
      Corollary~\ref{cor:balance-'n-thread} to balance , 
      but without the recursive calls for the remaining cluster
      nodes. This gives a balanced top-level quadtree  
      (possibly with some compressed children of  now 
      integrated in the tree), in which each leaf square is  
      associated with at most four points from  or compressed
      children of . Furthermore, for each leaf square  of ,
      we have a bounding square for the associated elements
      that is aligned with  and has size at most 
      . 

      We use  to identify a partial 
      cluster quadtree, and we then recurse on the 
      compressed children.
      We say a square  is \emph{full} if 
      there is a leaf below  with a non-empty associated set.
      Otherwise,  is \emph{empty}.
      First, we consider the squares of  in top-down
      fashion and check for each
      full square  which direct neighbors of  
      are empty  (this can
      be done in constant time since  is balanced). If  has
      at most three full direct neighbors, and if all these
      full squares share a common corner,
      we let  be a square that
      is aligned with  and contains the full squares (i.e., either
       or  is a square of size  that contains  and
      its full neighbors). Next, we 
      consider the squares of size  in
      the  grid centered at 
      and check whether they are all empty (again, since  is balanced,
      this takes constant time).
      If so, the points associated with 
      define a -cluster. We put a representative
      point for the cluster into , make a new quadtree with root ,
      and remove 's children from .
      We continue until all the squares of  have been traversed,
      and then we process all the new trees in a similar way, iterating
      if necessary. After we are done, a part of the cluster quadtree has
      been created, and we need to consider the compressed children
      to set up a recursion.

      For this, we consider each non-empty leaf square  of the partial tree.
      Let  be the bounding square of the associated elements of .
      We know that , so the disc  of radius  
      centered at  intersects at most three other leaf squares. 
      We check for each of these leaf squares whether  intersects
      the bounding square of its associated elements.
      If so, we make a new bounding square for the union of these elements and
      repeat. This can happen at most twice more, because in each step
      the size of the bounding square increases by a factor of at most .
      Hence, after three steps we have a disk  of 
      radius  that 
      intersects four disjoint squares of size  that share a
      corner. Thus,  must be completely contained in those squares. 
      This also implies that this procedure yields a
      -cluster.  For each such cluster, we 
      create a representative point and
      an appropriate base square for the child quadtree. 
      Then, we process the cluster
      recursively. In the end, we can prune the resulting compressed
      trees to remove unnecessary nodes.

      By the proof of Corollary~\ref{cor:balance-'n-thread},
      and since be spend only constant additional time for each square,
      this procedure takes linear time. Furthermore, as we argued
      above, we create only -clusters. If 
      is a -cluster, then  is either contained in
      at most four leaf squares of  that share a corner or
      the bounding square  intersects at most four squares of 
       of size  such that the
      surrounding  grid contains only  empty
      squares. In either case,  (or a superset) is discovered.
      It follows that the result is a valid -cluster 
      quadtree.
    \end{proof}






















\section {From a -Cluster Quadtree to the Delaunay Triangulation}
\label{sec:qt->dt}

We now come to the heart of the matter and show how to construct a DT from
a WSPD. Let  be a set of points, and  a
compressed quadtree for . Throughout this section,  is a
small enough constant (say, ), and  is
a large enough constant (e.g., ).
Let  and  be two \emph{unrelated} nodes of , i.e.,
neither node is an ancestor of the other. Let  be the 
set of directed lines that stab  before . 
The set  of directions for 
is an interval modulo 
whose extreme points correspond to
the two diagonal bitangents of  and , i.e., the two lines that
meet  and  in exactly one point each and have  and
 to different sides. 
Figure~\ref {fig:angle-int} illustrates this.

\tweeplaatjes {angle-int} {angle-sep} {(a) The set of possible directions 
between two unrelated nodes  and . (b) The set of possible directions 
between well-separated pairs is small.}

\begin {observation} \label {obs:directions-contained}
Let  and  be two unrelated nodes of , and let  be a
descendant of  and  be a descendant of .
Then .
\end {observation}

\begin{proof}
This is immediate, because  and
.
\end{proof}

\begin{observation}\label{obs:small-Phi}
If  and  are two  nodes of  such that  is
-well-separated, then
.
\end{observation}

\begin{proof}
  Let ,  be the disk around  with radius
  , and  the disk around  with the same radius.\footnote
  {Recall,  is the center point of .}
  By well-separation,  and . Let 
  be the angle between the 
  diagonal bitangents of  and . Then
  , and 
   
  as claimed. 
  Figure~\ref {fig:angle-sep} illustrates this.
\end{proof}


For a number   we define
, i.e., the set
of all directions that differ from  by at most
. We say
that an ordered pair   of nodes has direction  if
.
We also say that a pair of points 
has direction
 if the corresponding pair in the WSPD has
direction . The same definition also applies to an edge.
For a given point  in the plane, we define the
-cone  as the cone with apex  and
opening angle  centered around the direction .

\subsection {Constructing a Supergraph of the EMST}\label{sec:emstsup}

In the following, we abbreviate .
The goal of this section is to construct a graph 
with vertex set  and  edges, such that
. 
It is well known that if we take the graph  on  with edge set
, where
each  connects the bichromatic closest pair for  and , 
then  contains  and has  edges~\cite{Eppstein00}.
However, as defined, it is not clear how to find  in linear time.
There are several major obstacles. Firstly, even though the tree 
has  nodes, it could be that .
Secondly, even if the total size of all 's was , we still need
to find bichromatic closest pairs for all \emph{pairs} in .
Thus, a large set  might appear in many pairs of
, making the total problem size superlinear. Thirdly,
we need to actually solve the bichromatic closest pair problems. A 
straightforward solution to find the bichromatic closest pair for
sets  and  with sizes  and  would take time 
, by computing the Voronoi diagram
for the smaller set and locating all points from the other set in it.
We need to find a way to do it in linear time.

To address these problems, we actually construct a slightly larger graph
, by partitioning the pairs in  according to their
direction. More precisely,
let  be a set of
 numbers, where we assume 
that  is an integer.
For every  , we  construct a graph 
with  edges and then let .
Given , the graph  is constructed in three steps:
\begin{enumerate}
\item 
  For every node
  , select a subset , such that
  ,
  and such that 
   still
  contains all edges of  with orientation . This addresses
  the first problem by making the total set size linear.
\item 
  Find a subset ,
  such that
  each  appears in  pairs of
  , and the set 
  
  contains all edges of  with orientation .
In particular, we choose
  for every node  a subset
   such that
  ,
  each  pair in  contains , and
  . This addresses the second problem
  by ensuring that every set appears in  pairs.
\item 
  For every pair , we
  include in  the edge  such that
   is the closest pair in  (i.e.,
  ).
  Here we actually solve all the bichromatic closest pair problems.
\end{enumerate}
Clearly,  has  edges, and we will show that  is indeed a
supergraph of . Our strategy of subdividing the edges
according to their orientation goes back to Yao, who
used a similar scheme to find EMSTs in higher dimensions~\cite{Yao82}. 

\paragraph{Step 1: Finding the 's.}
Recall that we fixed a direction .  Take the set
 of pairs with direction
. For a pair , we write 
 for the tuple such that  and  comes before
 in direction , it is a \emph{directed} pair in . 
Call a node  of  \emph{full} if either 
(i)  is the
root; (ii)  is a non-empty leaf; or (iii)  has a
directed pair . 
Let  be the tree 
obtained from  by
connecting every full node to its closest full ancestor, and by
removing the other nodes. We can compute  in linear time
through a post-order traversal.  Now, for every leaf  of , put
the point  into the sets , where  is one the \footnote
{Recall,  is a sufficiently large constant.}
closest ancestors of  in . Repeat this procedure, while changing
property (iii) above so that  has a directed pair
. 
This takes
linear time, and . Intuitively, 
contains those points of  that are sufficiently on the outside
of the point set in direction .
Figure~\ref {fig:qt-example+qt-wspd+qt-zu} shows an example.
\drieplaatjesbreed {qt-example} {qt-wspd} {qt-zu}
{(a) A node  in the quadtree, with .
 (b) The relevant wspd-pairs (in green) for the points in 
     with direction  (up). There are also wspd-pairs between  and
     other nodes above and below it.
 (c) For ,  contains those  for which the 
     lowest wspd-pair in the tree  that involves  
     contains .
     In other words,   has the points that do not have a green edge in
     both directions in (b).
}
Variants of the following claim
have appeared several times before~\cite{AgarwalEdScWe91,Yao82}.

\begin{claim}\label{clm:lune_nn}
Let , and let  denote the cone with
apex  and opening angle  centered around .
Suppose that  is an edge of  and
.  Then  is the nearest neighbor of 
in .
\end{claim}

\begin{proof}
If  is an edge of , then the \emph{lune}  defined by
 and  contains no point of ~\cite{deBergChvKrOv08}.\footnote{
is the intersection
of two disks with radius , one centered at , the other centered
at .}
Since the opening angle of  is at most  ,
for  small enough,
the intersection of  with  equals
the intersection of  with the disk around 
 of radius . Hence,  must be the nearest neighbor of
 in .
\end{proof}


\begin{lem}\label{lem:constant-levels}
Let  be an edge of  with direction , and let
 be the corresponding wspd-pair.
Then .
\end{lem}

\begin{proof}
Let  be the leaf for , and suppose for contradiction
that , i.e.,  is not among the   closest
ancestors of  in .
This means there exists a
sequence
 of  distinct ancestors of ,
such that each node is an ancestor of all previous nodes and such
there are well-separated
pairs .


Let  be the cone with apex  and opening angle
 centered around .  By Observation~\ref{obs:small-Phi},
we have .
Furthermore, since  is well-separated, 
.
Now Claim~\ref{clm:quad-squares} implies that there are
squares ,  such that
(i) 
and  ;
(ii) ; and
(iii) .
This means that 

where in the first inequality we bounded the distance between
any point in  and any point in  by the distance between the
squares plus their diameter (since we do not know where
the points lie inside the squares). The second inequality
comes from  and 
the third inequality is due to the fact that  lies
at least  levels below  in .

Since  for  and  since
,
this contradicts the fact that  is the nearest neighbor
of  inside  (Claim~\ref{clm:lune_nn}). 
Thus,  must lie in .
A symmetric argument shows .
\end{proof}

\paragraph{Step 2: Finding the 's.}
For every node , we include in  the  shortest
pairs in direction , i.e., the
pairs  such that
(i)  is contained
in the -cone  with apex 
centered around direction ;
and (ii) there are less than  pairs 
that fulfill (i) and have
.
Since  is constant,
the 's can be constructed in total linear
time.
Even though each  contains a constant number of
elements, a node might still appear in many such sets, so
we further prune the pairs:
by examining the 's, determine for each  the
set .
For each , find the  closest neighbors
(measured by the distance between their center points) of  in
, and for all other 's remove the
corresponding pairs .
Now each node appears in only a constant number of pairs of
.

\begin {lem}\label{lem:constant-neighbors}
Let  be an edge of  with orientation , and
let  be the corresponding wspd-pair.
Then .
\end {lem}

\begin {proof}
We show that  is among the  closest neighbors
of  in direction , a symmetric argument shows that 
is among the  closest neighbors of  in direction .
We may assume that  .
Suppose that  is not among the  shortest pairs
in direction .
Then there is a set  of  nodes
of  such that for all  we have
(i) ;
(ii) ; and
(iii) .
By Claim~\ref{clm:quad-squares}, there exists for every
 a pair of squares  such that
,  and
.

\eenplaatje[scale=0.9]{lune} {All squares  intersect the region .}


Let  be the cone with apex  and opening angle
 centered around . By Observation~\ref{obs:small-Phi},
 for all .
Furthermore, every  contains a point at distance at most  from
, because .
Also, by Claim~\ref{clm:lune_nn}, every  contains a point
at distance at least 
from . Thus, since  
by Claim~\ref {clm:quad-squares} and
, we get ,
for  small enough. However, this implies that
 has only a constant number of squares:
all  (and hence all )
intersect the annular segment   inside
 with inner radius  and outer radius
 (see Figure~\ref{fig:lune}).
All  are unrelated, since they are paired with
 in . Furthermore, the set  has diameter .
If  is a compressed child, then  is contained in the
parent of  and intersects no
other , for . Otherwise, 
. Thus, if we assign to each compressed child
 the square  and to each other node  the square
, we get a collection of  disjoint squares that
meet  and each have diameter . 
Since  has diameter , 
there can be only a constant number of such
squares, so
choosing  large enough leads to a contradiction.
\end{proof}

\paragraph{Step 3: Finding the Nearest Neighbors.}
Unlike in the previous steps, the algorithm for Step 3 is a bit
involved, so we switch the order and begin by
showing correctness.

\begin{lem}\label{lem:emst_nn}
Let  be an edge of  with direction
 and let  be the corresponding wspd-pair.
Then  is the closest pair in .
\end{lem}

\begin{proof}
By Lemma~\ref{lem:constant-levels}, we have .
Furthermore, the cut property of minimum spanning trees implies that
.
Since  is well-separated, we have

Now consider an execution of Kruskal's MST algorithm on
~\cite[Chapter~23.2]{CormenLeRiSt09}.
Let  be the closest pair
in . By , the algorithm
considers  only after processing all edges in
. Hence, at that point
the sets  and  are each contained in a connected component
of the partial spanning tree, and  can have at most one
edge from . Hence, it follows that
, as claimed.
\end{proof}


We now describe the algorithm.
For ease of exposition, we take  (i.e.,
we assume that  is rotated so that  points in the positive
-direction).
Note that now the squares are not generally axis-aligned anymore, but this
will be no problem.
Given a point , we define the four
\emph{directional cones}
,,
, and 
as the leftward, upward, rightward and downward cones with apex  and
opening angle . The directional cones subdivide the plane into
four disjoint sectors. We will also need the \emph{extended} rightward
cone  with apex  and opening
angle .



\begin{claim}\label{clm:emptycone}
Let  be a directed pair in  , 
and suppose that  with  and 
is the closest pair for . 
Then  and
.\footnote{Recall 
that we set ,
so  and  mean ``in direction ''
and ``in direction ''.}
\end{claim}

\eenplaatje {closest-cone} {The intersection points of  and the boundary of
 lie outside , so
.}

\begin{proof}
We prove the claim for , the argument for
 is symmetric. We may assume that .
By assumption, the unit disk  centered at  contains no points of ,
so it suffices to show that
.
Since 
and by Observation~\ref{obs:small-Phi}, the direction of the
line  differs from  by at most .
Therefore, the intersections of the boundaries of
 and 
have distance at least  from . However, the
pair  is well-separated, so all points in  have distance at
most  from , which implies the claim;
see Figure~\ref{fig:closest-cone}.
\end{proof}

Given a  set  for a node  of , we define the \emph{upper chain}
of ,  as follows:
remove from  all points  such that
 contains a point from 
in its interior. Then sort  by -coordinate and connect consecutive
points by 
line segments.
All segments of  have slopes in .
Similarly, we define the \emph{lower chain} of , , by requiring
the cones   for the points in  to be
empty. The goal now is to compute  and  for all
nodes .

\tweeplaatjesbreed {chain-care} {chain-graph}
{(a) A node  with , 
     and the relevant part of the quadtree. 
 (b) The graph . 
 Tree edges are black (going right). To avoid clutter, we just show
 two wspd edges (green, going left).
}

Define a directed graph  as follows:
we create two copies
of each vertex  in , called  and
, and we add a directed edge from
 to  for each
such vertex.
Furthermore,
we replace every edge  of  ( being the parent of )
by two edges: one from  to ,
and one from  to  . We
call these edges the \emph{tree}-edges.
Finally, for every pair , where
 is wholly contained in the extended rightward cone
, we create a directed
edge from  to . These
edges are called \emph{wspd}-edges.
Figure~\ref {fig:chain-care+chain-graph} shows a small example.



\begin{claim}\label{clm:acyclic}
The graph  is acyclic.
\end {claim}

\begin{proof}
Suppose  is a cycle in .
The tree-edges form an acyclic subgraph, so 
has at least one wspd-edge. Let  be
the sequence of wspd-edges along ,
and let  be
such that the endpoint of 
is of the form .
Finally, write
, where  is the sequence of
tree-edges between two consecutive wspd-edges.
Each  consists of a (possibly empty) sequence of

edges, followed by one 
edge and a (possibly empty) sequence of  edges.
Thus, the origin of the next wspd-edge  is
an -node for an ancestor or a
descendant of  in . In either case, by the definition of wspd-edges,
it follows that the leftmost point of  lies
strictly to the right of the leftmost point of . 
Indeed, write . Then 
lies strictly to the right of , because 

and because  is well-separated.
If  is a descendant of , then 
 and the leftmost
point of  cannot lie to the left of the leftmost
point of , which implies the claim. 
If  is an ancestor of , then all of  is
strictly to the right of , and the claim follows again.
Thus,
the leftmost point of  lies strictly to the right of the leftmost
point of  and the leftmost point of
 lies strictly to the right of the leftmost point in
, which is absurd.
\end {proof}

Let  be a topological ordering
of the nodes of .

\begin{claim} \label {clm:order}
Any pair  of points in  with  satisfies
.
\end {claim}

\begin {proof}\label{clm:respecting_order}
Suppose for the sake of contradiction that .
Let ,  be the descendants of  such that
, , 
and .
By Observation~\ref{obs:small-Phi},  lies completely
in the extended rightward cone , so
 has an edge from  to .
Now the tree edges in 
require that the leaf with 
comes before  and the leaf with  comes after
, and the claim follows.
\end{proof}

\tweeplaatjes {topo-order} {topo-chain}
{(a) A set of points, and all edges with a slope in .
     By Claim~\ref {clm:order}, these edges are all (possibly implicitly)
     present in .
 (b) A possible ordering  of the points that respects .
}

Since all edges on  have slopes in , we immediately
have the following corollary.

\begin{cor}
The ordering  respects the orders of  and .

\end{cor}

For every node , let  be the order 
that  induces on the leaf nodes corresponding to . 

\begin{claim}\label{clm:topo_sort}
All the orderings  can be found in total time .
\end{claim}

\begin {proof}
To find the orderings , perform a topological sort on
, in linear time\footnote{Note that
 has  edges, as
.}~\cite[Chapter~22.4]{CormenLeRiSt09}.
With each node  of  store a list , initially empty.
We scan the nodes of  in order. Whenever we see 
a leaf for a point , we append  to the
at most  
lists  for the nodes  with .
The total running time is 
, and 
is sorted according to  for each .
\end{proof}

\begin{claim}\label{clm:findUCLC}
For any node , if  is sorted according to ,
we can find  and
 in
time .
\end{claim}


\begin{proof}
We can find  by a Graham-type pass through .
An example of such a list is shown in Figure~\ref {fig:topo-chain}.
That is, we scan  from left to right, 
maintaining
a tentative upper chain , stored as a stack. 
Let  be the rightmost point of .
On scanning a new point , we distinguish cases depending
in which of the four quadrants
, , 
, or 
it lies in.
By Claim~\ref {clm:respecting_order}, we know that 
. 
If , we discard  and continue to
the next point in . 
If , we
pop  from  and reassess  from the point of view of the
new rightmost point of .
If , we push  onto .

The algorithm takes  time, because every point is pushed
or popped from the stack at most once and because it takes constant
time to decide which point to push or pop.
Now we argue correctness. For this, we use induction in order to
prove that after  steps, we have correctly computed the
upper chain for the first  points in , . This clearly
holds for the first point. Now consider the cases for the -th
point . 
\begin{itemize}
\item
If , then  is certainly
not on the upper chain. Furthermore, 
,
so  cannot conflict with any other point on ,
so in this case .
\item
If , then 
 and 
must be on . Furthermore, every point that we remove
from  has  in its upper cone and cannot be on
. Now let  be the first point of  that
is not popped. Since 
 and since
the remainder of  lies inside of 
, there are no conflicts between  and the
points we have not popped. Thus  is computed correctly.
\item If , then 
, and  is on , because
 contains no points from .
Futhermore,  is contained in ,
so  conflicts with no point on  and the result is correct.
\end{itemize}
This finished the inductive step and the correctness proof.
The lower chain is computed in an analogous manner.
\end{proof}

\begin{claim}\label{clm:find_closest}
For any node  and any pair  in , given
 and , we can find the closest pair in 
in time .
\end{claim}

\begin{proof}
Connect the endpoints of  and  to obtain a simple
polygon (note that the two new edges cannot intersect the chains,
because  has direction ,
so by Observation~\ref {obs:small-Phi}

and all edges of the chains have
slopes in ). Then use the algorithm of Chin and
Wang~\cite{ChinWa99} to find the constrained DT of
the polygon in time . The closest pair will appear
as an edge in this DT, and hence can be found in
the claimed time.\footnote{Actually, the resulting polygon is -monotone,
so the most difficult part of the algorithm by Chin and
Wang~\cite{ChinWa99}, finding the visibility map of the
polygon~\cite{Chazelle91}, becomes much easier~\cite{GareyJoPrTa78}.
The problem may allow a much more direct solution, but since
we will later require Chin and Wang's algorithm in full
generality, we do not pursue this direction.}
\end{proof}

\begin{lem}\label{lem:findNN}
In total linear time, we can find for every  and for
every pair  the closest pair in .
\end{lem}

\begin{proof}
By Claims~\ref{clm:topo_sort}, \ref{clm:findUCLC}, \ref{clm:find_closest},
the time to find all the closest pairs is  proportional to

because every  appears in only a constant number of 's.
\end{proof}

\paragraph{Putting it together.}
We thus obtain the main result of this section.

\begin{theorem}\label{thm:qtree->h}
Given a compressed quadtree  for  and \emph{}, we can 
find a graph
 with  edges such that  contains all edges of .
It takes  time to construct .
\end{theorem}

\begin{proof}
The fact that  contains the EMST follows
from Lemmas~\ref{lem:constant-levels}, \ref{lem:constant-neighbors} and
\ref{lem:emst_nn}. The running time follows from the discussion at the
beginning of Steps 1 and 2 
and from Lemma~\ref{lem:findNN}.
\end{proof}

\subsection {Extracting the EMST}
  We want to extract , but no general-purpose deterministic linear 
  time pointer machine algorithm for this problem is known:
  the fastest such algorithm whose running time can be analyzed
  needs  steps~\cite {Chazelle00}.
  However, the special structure of the graph  and the -cluster quadtree
   make it possible to achieve linear time.

  We know that   contains all EMST edges.
  Furthermore, by construction each edge of  corresponds
  to a wspd-pair. Thus, we can associate each edge 
  of  with two nodes  and  such that  is
  the wspd-pair for the endpoints of . The pruning operation in
  Step~2 of Section~\ref{sec:emstsup} ensures that each
  node is associated with  edges of , and we store
  a list of these edges at each node of .
  Now we use Theorem~\ref{thm:cluster-compressed-equiv}
  to convert our quadtree into a -cluster quadtree .
  During this conversion, we can preserve the information
  about which edges of  are associated with which 
  nodes of , because each old square overlaps with 
  only a constant number of new squares of similar
  size. A special case are those edges that have an
  endpoint associated with a compressed child.
  During the conversion of Theorem~\ref{thm:cluster-compressed-equiv},
  compressed children either become regular squares (during the balancing
  operation), or they correspond to -clusters and are replaced
  by representative points in the parent tree. In the former case,
  we handle the compressed child just like any regular square, in the latter
  case, we associate  with the square that contains the representative
  point for the -cluster.
  
  Next, we would like ensure for each edge  of  that the associated
  squares in  have size between  and , where
   denotes the length of . 
  For the endpoints that were associated with regular squares in the
  original quadtree, such a square can be found by considering a constant 
  number of ancestors and descendants in , by 
  Claim~\ref{clm:quad-squares}.  If the associated square was a compressed
  child that has become a regular square, we may need to consider more than
  a constant number of ancestors, but each such ancestor is considered only
  a constant number of times, since the compressed child has a 
  constant number of associated edges. If  has an endpoint 
  that is now associated with a representative point, we may need to subdivide
  the square containing the representative point, but by 
  Corollary~\ref{cor:c-cluster-QT-extended} the total work is linear.
  Thus, in total linear time we can obtain a -cluster
  tree  such that each square of  is associated with 
  edges of  and such that the two associated square of each 
  edge  of   contain the endpoints of  and have size
  . 

  By the cut property of minimum spanning trees,
   is connected within each -cluster. Thus, we can process
  the clusters bottom-up, and we
  only need to find the EMST within a -cluster given
  that the points in each child are already connected. 
  Within this cluster,  is a regular uncompressed quadtree,
  and we can use the structure of  to perform an appropriate
  variant of \boruvka's MST algorithm~\cite{Boruvka26,Tarjan83} in linear time.

  \begin{lem}\label{lem:extract-emst}
    Let  be a subtree of  corresponding to a -cluster, and
    let  be the edges in  associated with .
    Then  can be computed in time .
  \end{lem}

\begin{proof}
  Let  be the size of the root square of .
  Through a level order traversal of  we group the
  squares in  by height into layers , , , 
  (where  is the bottommost layer, and  contains
  only the root). The squares in  have size .
  As stated above, each square  has a constant number of
  associated edges in  that have one endpoint in  and length
  length  between  and .
  To find the EMST, we subdivide the edges into
  sets , where  contains all edges with length
  in . Given the
  , we can determine the sets  in total time
  , as the edges for  are
  associated only with squares in , ,
  , ,
  for some constant . 
  Note that every edge
  in  is crossed by  other edges in , because all
   have roughly the same length and because every pair of squares in
   has only a constant number of associated edges in .

  Now we compute the EMST by processing the sets ,
  ,  in order. Here is how to
  process . We consider the squares in .
  Assume that we know for each square of  the connected
  component in the current partial EMST it meets (initially
  each -cluster is its own component). By the cut property, every
  square  meets
  only one connected component, as  is much smaller than the
  edges in .
  Eliminate all edges in  between squares in the same component,
  and 
  remove duplicate edges between
  each two components, keeping only the shortest of these edges
  (this takes  time with appropriate pointer manipulation).
  Then find the shortest edge out of each component
  and add these edges to the partial EMST. Determine the new components
  and merge their associated edge sets.
  This sequence of steps is called
  a \emph{\boruvka-phase}.
  Perform \boruvka-phases until  has no edges left.

  By the crossing-number inequality~\cite[Theorem~4.3.1]{Matousek02}, the 
  number of edges considered in
  each phase is proportional to the number  of components with an outgoing
  edge in that phase. Indeed, viewing each component as a supervertex,
  we have an embedding of a graph with  vertices and  edges such
  that there are  crossings (since every edge  is crossed
  by  other edges in ). Thus, the crossing number
  inequality yields , 
  for some
  constant , so .  Since the number of
  components at least halves in each phase, and since initially there
  are at most  components, the total time
  for  is . Finally, label each
  square in  with the component  it meets and proceed
  with round .
  In total, processing  takes time , as desired.
\end{proof}

\subsection{Finishing Up}
We conclude:
\begin {theorem} \label {thm:wspd->dt}
Let  be a planar point set and  be a compressed quadtree 
or a -cluster quadtree 
for .  Then  can be computed in time .
\end {theorem}

\begin{proof}
If  is a -cluster quadtree, invoke 
Theorem~\ref{thm:cluster-compressed-equiv} to convert it
to a compressed quadtree.
Then use Theorem~\ref{thm:wspd} to obtain .
Next, apply Theorem~\ref{thm:qtree->h} to compute the
supergraph  of . After that, if necessary, convert  to a 
-cluster quadtree for  via Theorem~\ref{thm:cluster-compressed-equiv},
and apply Lemma~\ref{lem:extract-emst} to each -cluster, in a bottom-up
manner, to extract . Finally, apply the algorithm
by Chin and Wang~\cite{ChinWa99} to find .
All this takes time , as claimed.
\end{proof}



















\section {From Delaunay Triangulations to -Cluster Quadtrees}
\label {sec:dt->qt}


    For the second direction of our equivalence we need to show
    how to compute a -cluster quadtree for  when given
    . This was already done
    by Krznaric and Levcopolous~\cite{KrznaricLe95,KrznaricLe98},
    but their algorithm works in a stronger model of
    computation which includes the floor function and allows access to data
    at the bit level.
    As argued in the introduction, we prefer the real RAM/pointer machine,
    so we need to do some work to adapt their
    algorithm to our computational model.
    In this section we describe how Krznaric and Levcopolous's
    algorithm can be modified to avoid bucketing and bit-twiddling techniques.
    The only difference is that in the resulting -cluster
    quadtree the squares for the -clusters are not perfectly
    aligned with the squares of the parent quadtree. In our setting,
    this does not matter. The goal of this section is to prove the following
    theorem.

\begin{theorem}\label{thm:dt->c-cluster-qt}
Given , we can compute a -cluster quadtree
for  in linear deterministic time on a pointer machine.
\end{theorem}

In the following, we will refer to the paper by Krznaric and
Levcopolous~\cite{KrznaricLe98} as KL.
Our description is meant to be self-contained; however, we refer the reader to KL for more intuition and a more elaborate description of the main ideas.

\subsection{Terminology}
We begin by recalling some terminology from KL.

\begin{itemize}
\item \textbf{neighborhood.}
The \emph{neighborhood} of a square  of a quadtree
consists of the 25 squares of size  concentric around
 (including ); see Figure~\ref{fig:neighbors}.
\item \textbf{direct neighborhood.}
The \emph{direct neighborhood} of a square
 consists of the 9 squares of size  directly adjacent to 
(including ); see Figure~\ref{fig:neighbors}.
\item \textbf{star of a square.}
Let  be a planar point set, and let  be a square. The \emph{star}
of , denoted by , is the set of all edges  in 
such that (i)  has one endpoint inside  and one endpoint outside the
neighborhood of ; and (ii) , where  is
the length of .
\item \textbf{dilation.}
Let  be a planar point set, and  a connected plane graph with
vertex set . The \emph{dilation} of  is the distortion between
the shortest path metric in  and the Euclidean distance, i.e.,
the maximum ratio, over all pairs of distinct points , between
the length of the shortest path in  from  to , and . There
are many families of planar graphs whose dilation is bounded by a
constant~\cite{DasJo89}.
In particular, for any planar point set , the
dilation of  is bounded
by ~\cite{KeilGu92}.
\item \textbf{orientation.}
The \emph{orientation} of a line segment  is the angle
the line through  makes with the -axis.
\end{itemize}

\eenplaatje {neighbors} {The neighborhood of a square . The direct neighbors
are shown in dark blue, the others in light blue.}

\subsection{Preprocessing}
\label{sec:dt->c-cluster-preprocess}

By Theorem~\ref{thm:c-cluster-tree}, we can obtain a -cluster
tree  for  in linear time, given . Thus, we only
need to construct the regular quadtrees  for each node 
 in . This is done by processing each node of 
individually. First, however, we need to perform a preprocessing step
in order to find  for each edge  of  the node of  
that is the least common ancestor of 's endpoints.
For every node , we define  as the
set of edges in  that have exactly one endpoint in
 and both endpoints in . Clearly, every edge is
contained in exactly two sets  and ,
where  and  are siblings in .
The following is a simple variant of a lemma from
KL~\cite[Lemma~3]{KrznaricLe98}.

\begin{lem}[Krznaric-Levcopolous]\label{lem:out}
Let  be a planar -point set.
Given  and a -cluster tree  for , the sets
\emph{} for every node  can be found in overall
 time and space on a pointer machine.
\end{lem}

\begin{proof}
KL show how to reduce the problem of determining the sets
 to  off-line least-common ancestor (lca) queries 
in two appropriate trees. For the lca-queries,
they invoke an algorithm by Harel and Tarjan~\cite{HarelTa84} that requires
the word RAM. However, since all lca-queries are known in
advance (i.e., the queries are \emph{off-line}), we  
may instead use an algorithm by
Buchsbaum \etal~\cite[Theorem~6.1]{BuchsbaumGeKaRoTaWe08} which 
requires  time and space on a pointer machine.
\end{proof}

\subsection{Processing a Single Node of }
\label{sec:one-node}
We now describe the preprocessing that is necessary on a single
node  of  before the quadtree  can be constructed.
Let 
be the children of . For each child , let
.

\begin{claim}\label{clm:delta_i}
For , \emph{} contains an edge of
length .
\end{claim}

\begin{proof}
If  contains an edge  with an endpoint in  and
with length , then  must
be in , by the definition of a -cluster.
Since  is a subgraph of , it thus suffices to show that
 contains such an edge.
Consider running Kruskal's MST algorithm on . According to the
definition of a -cluster, by the time the algorithm considers the edge 
that achieves , the partially constructed EMST contains exactly
one connected component that has precisely the points in .
Therefore, , and the claim follows.
\end{proof}

\paragraph{Initialization.}
By scanning the sets , we determine a child 
with minimum  (by Claim~\ref{clm:delta_i} a shortest edge in
 has length ).
We may assume that . Let  be a square that contains
 and that has side-length . Let  be
the smallest integer such
that four squares of size  cover all of .
Lemma~\ref {lem:c-cluster-QT} implies that .

The goal is to compute , the balanced regular quadtree aligned at 
 such that each  is contained in squares of size .
To begin, we use  to initialize  as the partial 
balanced quadtree  shown in Figure~\ref{fig:initialqt}.
\eenplaatje [scale=0.8] {initialqt} {The initial quadtree.}
Every square  of  stores the following fields:
\begin{itemize}
\item : a pointer to the parent square,  for
       the root;
\item : pointers for the four children of ,
      for a leaf;
\item : links to the four orthogonal neighbors of 
      in the quadtree  with size 
      (or size , if no smaller neighbor exists);
\end{itemize}

The fields , , and 
are initialized for all the nodes in .

\begin{lem}\label{lem:node-init}
The total time for the initialization phase is
\emph{}.
\end{lem}

\begin{proof}
By Lemma~\ref{lem:c-cluster-QT}, the initial size of  is .
All other operations consist of scanning the \texttt{out}-lists
or are linear in the size of .
\end{proof}

\subsection {Building the Tree }

\begin{algorithm}
  
  \begin{enumerate}
    \item\label{step:activeS} Set .
    \item Set .
    \item\label{step:loop}
          Until the squares in  have size greater than
          :
    \begin{enumerate}
      \item\label{step:activeLoop} For every square  in 
             call the function  
      to determine .  Append  to 
      , if it is not present yet.
      \item\label{step:starLoop} For every
            edge ,
            if  has an endpoint in an undiscovered cluster,
      call the function , and append
      all the squares returned by this call to .
      \item \label{step:newActive} Set .
    \end{enumerate}
  \end{enumerate}
 
  \begin{enumerate}
    \item   Walk along   through the current  to find the
            square  of  that contains the other endpoint
            of .
            This tracing is done by following the appropriate
             pointers from .
     \item \label{step:refine} Refine  for the new cluster, and
            let  be the set of leaf squares containing the newly
            discovered cluster.
      \item Call 
            .
      Afterwards, return the  squares from the recursive call.
  \end{enumerate}
  \caption{Computing a -cluster quadtree for the children of
    a -cluster.}
  \label{alg:explore}
\end{algorithm}

Now we build the tree  by a traversing  in
a way reminiscent of Dijkstra's algorithm~\cite{CormenLeRiSt09}.
In their algorithm, KL make extensive use of the floor function 
in order to locate points inside their quadtree squares. The 
purpose of this section is to argue that this point location work 
can be done through local traversal of the quadtree, without 
the floor function.
Refer to Algorithm~\ref{alg:explore}.
The heart of the algorithm is the procedure , 
which is initially called as
.
The procedure  builds the tree  level
by level, beginning with the level of .
At each point, it maintains
a set  of all squares at the current level that contain 
a cluster that has already been processed. For each such square ,
it calls a function . This function
returns all edges of the Delaunay triangulation that have one endpoint in
 and have length , for a constant . Using 

we can  new clusters whose distance from the active clusters
is comparable to the size of the squares in the current level.
We will say more about the implementation  below.
For each new cluster, we call the procedure  
which adds more squares to  to accommodate the new cluster and 
recursively explores the short edges out of this new cluster. After
the recursive call has finished, we can continue the exploration of the
tree at the current level. 

We now give the details
for the refinement in Step~\ref{step:refine} of :
Let  be
the cluster that contains the other endpoint  of  (we can find 
in constant time, since , and
since for each edge we store the two clusters whose -lists
contain it). Subdivide the current leaf square containing  (and 
possibly also its neighbors if they contain points from ) 
in quadtree-fashion until  is contained in squares of 
size .  Then balance the quadtree and update the 
 pointers
accordingly. 

The algorithm is recursive, and at each point there exists
a sequence , , , 
of instantiations (i.e., stack frames) 
of , where 
was invoked by . Each  has a set
 of active
squares, such that all squares in each 
have the same size, and such that the squares in 
are not larger than the squares in .
We say that a square is active if it is contained in
.
The neighborhood of 
is the union of the neighborhoods of all boxes in .
We maintain the following invariant:

\begin{invariant}\label{inv:neighborhood}
At all times during the execution of \emph{},
all undiscovered -clusters lie outside the neighborhood of
\emph{}.
\end{invariant}

\begin{claim}\label{clm:invariant}
Invariant~\ref{inv:neighborhood} is maintained by \emph{}.
\end{claim}

\begin{proof}
The set  only changes in Steps~\ref{step:activeS} and
\ref{step:newActive}. The invariant is maintained in
Step~\ref{step:activeS}, since the size of the squares in  
(i.e.,  is chosen such that their neighborhoods 
can contain no point from any other cluster. 

Let us now consider Step~\ref{step:newActive}. The
set  contains two kinds of squares:
(i) the parents of squares processed in the current iteration
of the main loop; and (ii) squares that were added to
 after a recursive call. We only need
to focus on squares of type (i), since squares of type (ii)
are already added to  during the recursive
call.
Suppose that  contains a square  whose neighborhood
has a point  in an undiscovered cluster. Since ,
there is a point , and by the definition
of neighborhood, we have .
However, since the dilation of  is at most
~\cite{KeilGu92},  contains a path  of length at most
 from  to . Let
 be the last discovered point along . The point  lies
in an active square  with , and the edge  leaving
 on  has length at most . Therefore,
  for a descendant  of , which
contradicts the fact that  is the last discovered point along
.
\end{proof}

\begin{lem}\label{lem:node-explore}
The total running time of \emph{}, excluding the
calls to \emph{}, is 
\emph{}.
\end{lem}

\begin{proof}
All squares appearing in  are ancestors of non-empty
leaf squares in the final tree . Therefore, by
Lemma~\ref{lem:c-cluster-QT},
the total number of iterations for the loop in
Step~\ref{step:activeLoop} is . Furthermore, 
 contains only edges of length , so every
edge appears in only a constant number of stars. It follows that the
total size of the -lists, and hence the total number of
iterations of the loop in Step~\ref{step:starLoop} is
.

It remains to bound the time for tracing the edges and balancing the
tree.  Since  is balanced and since  contains
only edges of length , the tracing along the 
pointers of an edge takes constant time (since we traverse a constant number
of boxes of size ). By Invariant~\ref{inv:neighborhood},
the other endpoint of the edge  is contained in a leaf square
of the current  of size . (This is because the quadtree
is balanced and because the other endpoint of the edge lies outside
the neighborhood of the active squares.) Therefore, the time to build
the balanced
quadtree for the new leaf squares containing the newly discovered cluster
can be charged to the corresponding nodes in the final , of which
there are . Furthermore, note that by
Invariant~\ref{inv:neighborhood}, balancing the quadtree for the newly
discovered leaf squares does not affect any descendants of the active
squares.
\end{proof}

\subsection {Implementing }

KL show how to exploit the geometric properties of the Delaunay triangulation
in order to implement the function ,
quickly. For this, they store two additional fields with each
active square, called  and
~\cite[Section~6]{KrznaricLe98}, and they explain how to
maintain these lists throughout the procedure. This part of the algorithm works 
on a real RAM/pointer machine without any further modification, so we 
just state their result.
\begin{lem}\label{lem:findStar}
The total time for all calls to \emph{} and the
maintenance of the required data structures is
\emph{}.
\qed
\end{lem}

\subsection {Putting Everything Together}
We can now finally prove Theorem~\ref{thm:dt->c-cluster-qt}.

\begin{proof}[Proof of Theorem~\ref{thm:dt->c-cluster-qt}]
First, we use Theorem~\ref{thm:c-cluster-tree} to find a -cluster
tree  for  in  time. Next, we use the algorithm from
Section~\ref{sec:dt->c-cluster-preprocess} to preprocess the tree.
By Lemma~\ref{lem:out}, this also takes  time. Finally,
we process each node of  using the algorithm from 
Section~\ref{sec:one-node}. 
By Lemmas~\ref{lem:node-init}, \ref{lem:node-explore},
and \ref{lem:findStar}, this takes total time
, where the sum ranges over
all the nodes of . This sum is  because there are
 nodes in , and because every edge of 
appears in exactly two -lists. Hence, the total running
time is linear, as claimed.
\end{proof}





















\section {Applications}
\label {sec:applications}

  As mentioned in the introduction, 
  our result yields
  deterministic versions of several recent randomized algorithms
  related to DTs. 
  Firstly, we can immediately derandomize
  an algorithm for hereditary DTs by
  Chazelle~\etal~\cite{ChazelleDeHuMoSaTe02,ChazelleMu11}:


  \begin {cor}\label{cor:split}
     Let  a planar -point set, and let .
     Given , we can find 
     in deterministic time  on a pointer machine.
  \end {cor}

  \begin{proof}
     Use Theorem~\ref{thm:dt->c-cluster-qt}  to find a -cluster
     quadtree  for ,
     remove the leaves for  from  and trim it
     appropriately.\footnote{Deleting  might
     create new -clusters. However, since we are aiming
     for running time , we can  apply Theorem~\ref{thm:wspd->dt}
     to a partly compressed quadtree that may contain
     long paths where every node has only one child.}
     Finally, apply Theorem~\ref{thm:wspd->dt} to extract  from ,
     in time .
  \end{proof}

  Secondly, we obtain deterministic analogues of the algorithms by
  Buchin~\etal~\cite {BuchinLoMoMuXX} to preprocess imprecise point sets
  for faster DTs. For example, we can prove the following:
  \begin {cor}\label{cor:IDT}
    Let  be
    a sequence of 
     -fat
    planar regions so that 
    no point in  
    meets more than  of them. 
    We can preprocess  in 
    deterministic time into an -size data structure
    so that given a sequence of   points 
     
    with  for all , we can find 
    in deterministic time  on a pointer
    machine.
  \end {cor}

\begin{proof}
    The method of
    Buchin~\etal~\cite[Theorem~4.3 and Corollary~5.6]{BuchinLoMoMuXX}
    proceeds by computing a
    representative quadtree  for .
    Given , the algorithm finds for every point in 
    the leaf square of  that contains it, and then uses this
    information to obtain a compressed quadtree  for  in time
    . However,  is \emph{skewed}
    in the sense that not all its squares need to be perfectly
    aligned and that some squares can be cut off.
    However, the authors argue
    that even in this case  takes  time and
    yields a linear-size WSPD~\cite[Appendix~B]{BuchinLoMoMuXX}.
    The main observation~\cite[Observation~B.1]{BuchinLoMoMuXX}
    is that any (truncated) square  in  is adjacent to at least
    one square whose area is at least a constant fraction of the
    area  would have without clipping.
    Since in skewed quadtrees the size of a node is at most half
    the size of its parent, the argument of Lemma~\ref{lem:constant-levels}
    still applies.
    To see that Lemma~\ref{lem:constant-neighbors} holds,
    we need to check that the volume argument goes through.
    For this, note that by the main observation of Buchin~\etal, we
    can assign every square  (the notation is as in the proof of
    Lemma~\ref{lem:constant-neighbors}) to an adjacent square of
    comparable size at distance  from . Since every such
    square is charged by disjoint descendants from a constant number of
    neighbors, the volume argument still applies, and
    Lemma~\ref{lem:constant-neighbors} holds. Lemma~\ref{lem:findNN}
    only relies on well-separation and the combinatorial structure of
    , and hence remains valid.
    Finally, in order to apply Lemma~\ref{lem:extract-emst},
    we need to turn  into a -cluster quadtree,
    which takes linear time by Theorem~\ref{thm:cluster-compressed-equiv}.
    Thus, the total running time is , as claimed.
\end{proof}

  Finally, Buchin and Mulzer~\cite{BuchinMu11} 
  showed that for word RAMs, DTs are no harder than sorting. 
  We can now do it deterministically.
  Let  be the time to sort  integers
  on a -bit word RAM. The best deterministic bound
  for  is 
  ~\cite{Han04}.\footnote{For specific ranges of , 
  we can do better.
  For example, if ,  radix sort shows
  that ~\cite{CormenLeRiSt09}.}
  \begin {cor}\label{cor:wramDT}
     Let  be a planar -point set given by -bit integers, for some 
     word-size . 
     We can find  in deterministic time  on
     a word RAM supporting the 
     -operation.\footnote{For two -bit words,
      and , we define
      as the -bit word
     .}
  \end {cor}

\begin{proof}
      Buchin and Mulzer~\cite{BuchinMu11} show how to find a
      compressed quadtree   for  in time ,
      using the -operation. They actually do not
      find the squares of the quadtree, only the combinatorial
      structure of  and the bounding boxes .  It is
      easily seen that the algorithm  also works
      in this case.

      To apply Lemma~\ref{lem:constant-levels}, we need to check that
      the sizes of the bounding boxes decrease geometrically down the
      tree. For this, consider a node  with associated point
      set  and the quadtree square  (i.e., the smallest aligned
      square of size  such that the coordinates of all points
      in  share the first  bits). Let  be the bounding box
      of , and let  be such that .
      Clearly,  meets at most nine aligned squares of size ,
      arranged in a  grid. Hence, any descendant  of
       that is at least five levels below  must have
      , since after at most
      four (compressed) quadtree divisions the  squares for  have
      been separated. Thus, the proof of Lemma~\ref{lem:constant-levels}
      goes through as before, if we choose  larger and
      consider every fifth node along the chain .

      Lemma~\ref{lem:constant-neighbors} still holds, because
      every bounding box  is contained in a (possibly much
      larger) square , so the volume argument applies.
      Also, Lemma~\ref{lem:findNN} only relies on well-separatedness
      and the combinatorial structure of , so we can find
      the graph  in linear time. After that, it takes 
      time to compute , using the transdichotomous minimum
      spanning tree algorithm by Fredman and Willard~\cite{FredmanWi94}.
\end{proof}

\section{Conclusions}

We strengthen the connections between proximity structures
in the plane and sharpen several known results between them.
Even though our results are optimal, the underlying algorithms are 
still quite subtle, and it may be of interest to see whether some of
them can be simplified. It is also interesting to see whether systematic
derandomization techniques, like -nets, can be useful to yield 
alternative deterministic algorithms for some of the problems considered
here. Finally, some of the previous results also apply to higher dimensions,
whereas we focus exclusively on the plane. Can we obtain analogous 
derandomizations for ?

\section*{Acknowledgments}

This work was initiated while the authors were visiting the Computational
Geometry Lab at Carleton University. We would like to thank the group
at Carleton and especially our hosts Jit Bose and Pat Morin for their
wonderful hospitality and for creating a great research environment.
We also would like to thank Kevin Buchin and Martin N\"ollenburg for
sharing their thoughts on this problem with us.
Work on this paper by M. L\"offler has been supported by the Office of
Naval Research under MURI grant N00014-08-1-1015.
Work by W. Mulzer has been supported in part by NSF grant CCF-0634958,
NSF CCF 083279, and a Wallace Memorial Fellowship in Engineering.

\small

\bibliographystyle {abbrv}
\newcommand{\SortNoop}[1]{}
\begin{thebibliography}{10}

\bibitem{AgarwalEdScWe91}
P.~K. Agarwal, H.~Edelsbrunner, O.~Schwarzkopf, and E.~Welzl.
\newblock Euclidean minimum spanning trees and bichromatic closest pairs.
\newblock {\em Discrete Comput. Geom.}, 6(5):407--422, 1991.

\bibitem{AilonChClLiMuSe11}
N.~Ailon, B.~Chazelle, K.~L. Clarkson, D.~Liu, W.~Mulzer, and C.~Seshadhri.
\newblock Self-improving algorithms.
\newblock {\em SIAM J. Comput.}, 40(2):350--375, 2011.

\bibitem{deBergChvKrOv08}
M.~{\SortNoop{Berg}}de~Berg, O.~Cheong, M.~van Kreveld, and M.~Overmars.
\newblock {\em Computational geometry: algorithms and applications}.
\newblock Springer-Verlag, Berlin, third edition, 2008.

\bibitem{BernEpGi94}
M.~Bern, D.~Eppstein, and J.~Gilbert.
\newblock Provably good mesh generation.
\newblock {\em J. Comput. System Sci.}, 48(3):384--409, 1994.

\bibitem{BernEpTe99}
M.~Bern, D.~Eppstein, and S.-H. Teng.
\newblock Parallel construction of quadtrees and quality triangulations.
\newblock {\em Internat. J. Comput. Geom. Appl.}, 9(6):517--532, 1999.

\bibitem{BoissonnatYv98}
J.-D. Boissonnat and M.~Yvinec.
\newblock {\em Algorithmic geometry}.
\newblock Cambridge University Press, Cambridge, 1998.

\bibitem{Boruvka26}
O.~Bor\r{u}vka.
\newblock O jist\'em probl\'emu minim\'aln\'{\i}m.
\newblock {\em Pr\'ace Moravsk\'e P\u{r}\'{\i}rodov\u{e}deck\'e
  Spole\u{c}nosti}, 3:37--58, 1926.

\bibitem{BuchinLoMoMuXX}
K.~Buchin, M.~L{\"o}ffler, P.~Morin, and W.~Mulzer.
\newblock Delaunay triangulation of imprecise points simplified and extended.
\newblock {\em Algorithmica}, 2010.
\newblock published online, doi:10.1007/s00453-010-9430-0.

\bibitem{BuchinMu11}
K.~Buchin and W.~Mulzer.
\newblock {D}elaunay triangulations in  time and more.
\newblock {\em J. ACM}, 58(2):Art.~6, 2011.

\bibitem{BuchsbaumGeKaRoTaWe08}
A.~L. Buchsbaum, L.~Georgiadis, H.~Kaplan, A.~Rogers, R.~E. Tarjan, and J.~R.
  Westbrook.
\newblock Linear-time algorithms for dominators and other path-evaluation
  problems.
\newblock {\em SIAM J. Comput.}, 38(4):1533--1573, 2008.

\bibitem{CallahanKo93}
P.~B. Callahan and S.~R. Kosaraju.
\newblock Faster algorithms for some geometric graph problems in higher
  dimensions.
\newblock In {\em Proc. 4th Annu. ACM-SIAM Sympos. Discrete Algorithms (SODA)},
  pages 291--300, 1993.

\bibitem{CallahanKo95}
P.~B. Callahan and S.~R. Kosaraju.
\newblock A decomposition of multidimensional point sets with applications to
  {}-nearest-neighbors and {}-body potential fields.
\newblock {\em J. ACM}, 42(1):67--90, 1995.

\bibitem{Chan08}
T.~M. Chan.
\newblock Well-separated pair decomposition in linear time?
\newblock {\em Inform. Process. Lett.}, 107(5):138--141, 2008.

\bibitem{ChanPa10}
T.~M. Chan and M.~P{\v a}tra{\c s}cu.
\newblock Transdichotomous results in computational geometry, {II}: {O}ffline
  search.
\newblock \texttt{arXiv:1010.1948} (see also STOC 2007).

\bibitem{ChanPa09}
T.~M. Chan and M.~P{\v{a}}tra{\c{s}}cu.
\newblock Transdichotomous results in computational geometry. {I}. {P}oint
  location in sublogarithmic time.
\newblock {\em SIAM J. Comput.}, 39(2):703--729, 2009.

\bibitem{Chazelle91}
B.~Chazelle.
\newblock Triangulating a simple polygon in linear time.
\newblock {\em Discrete Comput. Geom.}, 6(5):485--524, 1991.

\bibitem{Chazelle00}
B.~Chazelle.
\newblock A minimum spanning tree algorithm with inverse-{A}ckermann type
  complexity.
\newblock {\em J. ACM}, 47(6):1028--1047, 2000.

\bibitem{ChazelleDeHuMoSaTe02}
B.~Chazelle, O.~Devillers, F.~Hurtado, M.~Mora, V.~Sacrist{\'a}n, and
  M.~Teillaud.
\newblock Splitting a {D}elaunay triangulation in linear time.
\newblock {\em Algorithmica}, 34(1):39--46, 2002.

\bibitem{ChazelleMu11}
B.~Chazelle and W.~Mulzer.
\newblock Computing hereditary convex structures.
\newblock {\em Discrete Comput. Geom.}, 45(2):796--823, 2011.

\bibitem{ChinWa99}
F.~Chin and C.~A. Wang.
\newblock Finding the constrained {D}elaunay triangulation and constrained
  {V}oronoi diagram of a simple polygon in linear time.
\newblock {\em SIAM J. Comput.}, 28(2):471--486, 1999.

\bibitem{Clarkson83}
K.~L. Clarkson.
\newblock Fast algorithms for the all nearest neighbors problem.
\newblock In {\em Proc. 24th Annu. IEEE Sympos. Found. Comput. Sci. (FOCS)},
  pages 226--232, 1983.

\bibitem{CormenLeRiSt09}
T.~H. Cormen, C.~E. Leiserson, R.~L. Rivest, and C.~Stein.
\newblock {\em Introduction to Algorithms}.
\newblock MIT Press, third edition, 2009.

\bibitem{DasJo89}
G.~Das and D.~Joseph.
\newblock Which triangulations approximate the complete graph?
\newblock In {\em Proceedings of the international symposium on Optimal
  algorithms}, pages 168--192, 1989.

\bibitem{d-slsv-34}
B.~Delaunay.
\newblock Sur la sph{\`e}re vide. {A} la memoire de {Georges} {Voronoi}.
\newblock {\em Izv. Akad. Nauk SSSR, Otdelenie Matematicheskih i Estestvennyh
  Nauk}, 7:793--800, 1934.

\bibitem{Devillers11}
O.~Devillers.
\newblock Delaunay triangulation of imprecise points: Preprocess and actually
  get a fast query time.
\newblock {\em J. Comput. Geom. (JoCG)}, 2(1):30--45, 2011.

\bibitem{Eppstein00}
D.~Eppstein.
\newblock Spanning trees and spanners.
\newblock In {\em Handbook of computational geometry}, pages 425--461.
  North-Holland, Amsterdam, 2000.

\bibitem{EppsteinGoSu08}
D.~Eppstein, M.~Goodrich, and J.~Sun.
\newblock The skip quadtree: a simple dynamic data structure for
  multidimensional data.
\newblock {\em Internat. J. Comput. Geom. Appl.}, 18(1--2):131--160, 2008.

\bibitem{FinkelBe74}
R.~A. Finkel and J.~L. Bentley.
\newblock Quad trees: A data structure for retrieval on composite keys.
\newblock {\em Acta Inform.}, 4:1--9, 1974.

\bibitem{FredmanWi94}
M.~L. Fredman and D.~E. Willard.
\newblock Trans-dichotomous algorithms for minimum spanning trees and shortest
  paths.
\newblock {\em J. Comput. System Sci.}, 48(3):533--551, 1994.

\bibitem{FurstSaSi84}
M.~Furst, J.~B. Saxe, and M.~Sipser.
\newblock Parity, circuits, and the polynomial-time hierarchy.
\newblock {\em Math. Systems Theory}, 17(1):13--27, 1984.

\bibitem{GareyJoPrTa78}
M.~R. Garey, D.~S. Johnson, F.~P. Preparata, and R.~E. Tarjan.
\newblock Triangulating a simple polygon.
\newblock {\em Inform. Process. Lett.}, 7(4):175--179, 1978.

\bibitem{Han04}
Y.~Han.
\newblock Deterministic sorting in {} time and linear space.
\newblock {\em J. Algorithms}, 50(1):96--105, 2004.

\bibitem{HarPeled11}
S.~Har-Peled.
\newblock {\em Geometric Approximation Algorithms}, volume 173 of {\em
  Mathematical Surveys and Monographs}.
\newblock AMS Press, 2011.

\bibitem{HarelTa84}
D.~Harel and R.~E. Tarjan.
\newblock Fast algorithms for finding nearest common ancestors.
\newblock {\em SIAM J. Comput.}, 13(2):338--355, 1984.

\bibitem{KeilGu92}
J.~M. Keil and C.~A. Gutwin.
\newblock Classes of graphs which approximate the complete {E}uclidean graph.
\newblock {\em Discrete Comput. Geom.}, 7(1):13--28, 1992.

\bibitem{Knuth97}
D.~E. Knuth.
\newblock {\em The Art of Computer Programming: Fundamental Algorithms},
  volume~1.
\newblock Addison-Wesley, 3rd edition, 1997.

\bibitem{KrznaricLe95}
D.~Krznaric and C.~Levcopoulos.
\newblock Computing hierarchies of clusters from the {E}uclidean minimum
  spanning tree in linear time.
\newblock In {\em Proc. 15th Found. Software Technology and Theoret. Comput.
  Sci. (FSTTCS)}, pages 443--455, 1995.

\bibitem{KrznaricLe98}
D.~Krznaric and C.~Levcopoulos.
\newblock Computing a threaded quadtree from the {D}elaunay triangulation in
  linear time.
\newblock {\em Nordic J. Comput.}, 5(1):1--18, 1998.

\bibitem{KrznaricLeNi99}
D.~Krznaric, C.~Levcopoulos, and B.~J. Nilsson.
\newblock Minimum spanning trees in  dimensions.
\newblock {\em Nordic J. Comput.}, 6(4):446--461, 1999.

\bibitem{LoefflerSn10}
M.~L{\"o}ffler and J.~Snoeyink.
\newblock {D}elaunay triangulation of imprecise points in linear time after
  preprocessing.
\newblock {\em Comput. Geom. Theory Appl.}, 43(3):234--242, 2010.

\bibitem{Matousek02}
J.~Matou{\v{s}}ek.
\newblock {\em Lectures on discrete geometry}.
\newblock Springer-Verlag, New York, 2002.

\bibitem{m-pdt-97}
O.~Musin.
\newblock Properties of the {Delaunay} triangulation.
\newblock In {\em Proc. 13th Annu. ACM Sympos. Comput. Geom. (SoCG)}, pages
  424--426, 1997.

\bibitem{PreparataSh85}
F.~P. Preparata and M.~I. Shamos.
\newblock {\em Computational geometry. An Introduction}.
\newblock Springer-Verlag, New York, 1985.

\bibitem{PyrgaRa08}
E.~Pyrga and S.~Ray.
\newblock New existence proofs for {}-nets.
\newblock In {\em Proc. 24th Annu. ACM Sympos. Comput. Geom. (SoCG)}, pages
  199--207, 2008.

\bibitem{Samet90}
H.~Samet.
\newblock {\em The design and analysis of spatial data structures}.
\newblock Addison-Wesley, Boston, MA, USA, 1990.

\bibitem{Schoenhage79}
A.~Sch{\"o}nhage.
\newblock On the power of random access machines.
\newblock In {\em Proc. 6th Internat. Colloq. Automata Lang. Program. (ICALP)},
  pages 520--529, 1979.

\bibitem{ShamosHo75}
M.~I. Shamos and D.~Hoey.
\newblock Closest-point problems.
\newblock In {\em Proc. 16th Annu. IEEE Sympos. Found. Comput. Sci. (FOCS)},
  pages 151--162, 1975.

\bibitem{Tarjan83}
R.~E. Tarjan.
\newblock {\em Data structures and network algorithms}.
\newblock SIAM, Philadelphia, 1983.

\bibitem{Vaidya88}
P.~M. Vaidya.
\newblock Minimum spanning trees in {}-dimensional space.
\newblock {\em SIAM J. Comput.}, 17(3):572--582, 1988.

\bibitem{Varadarajan98}
K.~R. Varadarajan.
\newblock A divide-and-conquer algorithm for min-cost perfect matching in the
  plane.
\newblock In {\em Proc. 39th Annu. IEEE Sympos. Found. Comput. Sci. (FOCS)},
  pages 320--331, 1998.

\bibitem{Yao82}
A.~C.~C. Yao.
\newblock On constructing minimum spanning trees in {}-dimensional spaces
  and related problems.
\newblock {\em SIAM J. Comput.}, 11(4):721--736, 1982.

\end{thebibliography}
\normalsize























\appendix
  \section {Computational Models}
  \label{app:models}

Since our results concern different computational models, 
we use this appendix to describe them in more detail. 
Our two models are the real RAM/pointer machine and 
the word RAM.
\paragraph{The Real RAM/Pointer Machine.}
The standard model in computational geometry
is the \emph{real RAM}. Here, data is represented
as an infinite sequence of storage cells. These cells
can be of two different types: they can store real numbers
or integers. The model supports standard operations on
these numbers in constant time, including addition, 
multiplication, and elementary functions
like square-root.
The \emph{floor} function can be used to truncate a 
real number to an integer, but if we were allowed to 
use it arbitrarily, the real RAM could solve PSPACE-complete
problems in polynomial time~\cite{Schoenhage79}.
Therefore, we usually have only a restricted floor function 
at our disposal,
and in this paper it will be banned altogether. 

The  \emph{pointer machine}~\cite{Knuth97} models 
the list processing capabilities
of a computer and
disallows the use of constant time table lookup.
The data structure is modeled as a directed
graph  with bounded out-degree. Each node in
 represents a \emph{record}, with a bounded
number of pointers to other records and a bounded number
of (real or integer) data items.  
The algorithm can access data only by following pointers
from the inputs  (and a bounded number of global entry
records); random access is not possible. The data can be 
manipulated through the usual real RAM operations (again, 
we disallow the floor function). 


\paragraph{Word RAM.}
The \emph{word RAM} is essentially a real RAM without
support for real numbers. However, on a real RAM,
the integers are usually treated as atomic, whereas
the word RAM allows for powerful bit-manipulation tricks.
More precisely, the word RAM represents the 
data as a sequence of
-bit words, where  ( being the
problem size).
Data can be accessed arbitrarily, and standard
operations, such as Boolean operations 
(\texttt{and}, \texttt{xor}, \texttt{shl}, ), addition, or
multiplication take constant time. There are many variants of
the word RAM, depending on precisely which instructions are 
supported in constant time. The general consensus seems
to be that any function in 
is acceptable.\footnote{ is the 
class of all functions  that
can be computed by a family of circuits  with the 
following properties: (i) each  has  inputs; (ii) there exist constants
, such that  has at most  gates, for ; 
(iii) there is a constant  such that for all  the length of the longest
path from an input to an output in  is at most  (i.e., the
circuit family has bounded depth); (iv) each gate
has an arbitrary number of incoming edges (i.e., the \emph{fan-in} is 
unbounded).} However, it is always preferable to rely on a set of operations
as small, and as non-exotic, as possible.
Note that multiplication is not in ~\cite{FurstSaSi84}. 
Nevertheless, it is usually
included in the word RAM instruction set~\cite{FredmanWi94}.



\end{document}
