\documentclass{llncs}

\usepackage{paralist}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[sort]{cite}

\usepackage{listings}
\lstset{language=C,basicstyle={\fontfamily{ppl}\selectfont}}

\usepackage{algorithm,algorithmic}

\usepackage{tikz}
\usetikzlibrary{automata,shapes}
\tikzstyle{edge} = [draw,->]

\usepackage{hyperref}

\renewcommand{\floatpagefraction}{0.85}
\spnewtheorem*{example*}{Example}{\itshape}{\rmfamily}

\newcommand{\pponly}[1]{}
\newcommand{\rronly}[1]{#1}

\newcommand{\BB}{\mathbb{B}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\instance}[1]{\hat{#1}}
\newcommand{\eqvclass}[2]{\bar{#1}^{#2}}

\newcommand{\calM}{\mathcal{M}}
\newcommand{\calP}{\mathcal{P}}

\newcommand{\sleq}{\!\leq\!}

\newcommand{\defn}{\stackrel{\triangle}{=}}
\newcommand{\abstr}[1]{#1^\sharp}
\newcommand{\vecv}[2]{\left(\begin{array}{@{}c@{}}#1\\#2\end{array}\right)}
\newcommand{\ie}{\textit{i.e.}}
\newcommand{\eg}{\textit{e.g.}}
\newcommand{\mat}[1]{{\boldsymbol #1}}
\renewcommand{\vec}[1]{{\boldsymbol #1}}

\newcommand{\verr}{\mathit{e}} \newcommand{\vheat}{\mathit{h}} \newcommand{\vfan}{\mathit{f}}

\author{David Monniaux\inst{1} \and Peter Schrammel\inst{2}}
\institute{CNRS / VERIMAG \and University of Oxford}
\title{Speeding Up \\ Logico-Numerical Strategy
  Iteration\rronly{\0.5ex]
{\footnotesize
\textbf{while}(...) \{\\
\hspace*{1em}... \\
\hspace*{1em}\textbf{if} (abs(x) = 10) \{ \textbf{assert}(x != 0); ... \} \\
\} \-3ex]}\rronly{\footnote{This conjunction corresponds to a \emph{merge-simple
    statement} of \cite{Gawlitza_Monniaux_LMCS12} or to a \emph{path}
  of \cite{Henry_Monniaux_Moy_SAS2012,Monniaux_Gonnord_SAS11}.}}

\paragraph*{Algorithm.}
Let us now see how the algorithm iterates until the least inductive
invariant is reached.
The algorithm maintains, at iteration number , a current strategy
.  Initially, the abstract value  is 
everywhere save at the initial Boolean state , where
;  and  are 
everywhere. For , the strategy yields  as the
least fixed point  greater than
,  being an order-continuous operator on the
lattice  defined as: \\label{equ:transformer}
\Psi_{\pi}(\rho) \defn (i',\vec{b}') \mapsto
  \sup \left\{ \mat{A}_i \vec{x}' \mid \exists \vec{x},\vec{y}.~T_{\pi(i',\vec{b}')}
          \land (\mat{A}\vec{x} \leq \rho(\sigma(i',\vec{b}'))) \right\}
-3ex]}
\begin{enumerate}
\item construct formula
  , that
  is,  where variables  and  have been replaced
  by Boolean values  and ;
\item conjoin it with constraints  and ,
thus obtaining\pponly{\\label{for:invariant_violation}
  T[\instance{\vec{b}}/\vec{b},\instance{\vec{b}'}/\vec{b}'] \land \mat{A}\vec{x} \leq \rho_k(\instance{\vec{b}}) \land \mat{A}_i\vec{x}' > \rho_k(i,\instance{\vec{b}'})
0.6ex]
\centerline{\small
}\0.6ex]
\centerline{\small  }

After having checked all ,
we can compute the strategy value, \ie, 
the fixed point of , which updates
 to
 in this case.\footnote{By maximizing  for any , we get
  .}  The way this is
computed is explained in the next section.
\end{example*}


\subsection{Computing the Strategy Value}
\label{sec:original_value}
We recall now how to compute the strategy fixed point ~\cite[\S6.4]{Gawlitza_Monniaux_LMCS12}, under the
condition that  (which is always the case,
because of the way  is chosen).

The first step is to identify the Boolean states 
``abstractly unreachable'': such  form the least set 
containing all  such that
 and stable by: if  is
such that  then ; for all
, set .

Construct a system of linear inequalities in the unknowns
 for  and , plus
fresh variables: for all , for all  such that , add the inequalities\\
\hspace*{1em}\\
where variables  and  have been replaced
by fresh variables (each different  has its own set of
fresh replacements).   is obtained by linear
programming as the maximum of  satisfying this
system.  This linear program has solutions, otherwise the strategy
 would not have been chosen; if it has no \emph{optimal} solution
it means that .

Note that these  linear programs have \pponly{}\rronly{} variables and a system of inequalities of size
 where  is the size of formula . It is in fact
possible to replace these  linear programs by two linear
programs of size \pponly{}\rronly{}: first,
one using the -abstraction (see
\cite[\S8,9]{Gawlitza:2011:SSR:1961204.1961207}) to obtain which of
the  go to , then another for maximizing
 restricted to the  found not
to be  by the -abstraction.

\section{Our Algorithm}
\label{sec:our_algorithm}
Notice three difficulties in the preceding algorithm: there are,
\emph{a priori},  SMT-solving tests to be performed at each
iteration; the linear programs have exponential size; and there are at
most  strategies, thus a doubly exponential bound on the
number of iterations.
In intuitive terms, the first two difficulties stem from the explicit
expansion of the exponential set of Boolean states, despite the
implicit representation of the exponential set of execution paths
between any two control (Boolean) states  and , a
weakness that we shall now remedy.

\subsection{Strategy Improvement Step}
\label{sec:new_strategy_improvement}

The first difficulty is the easiest to solve: the  SMT-tests,
one for each pair  of control states, can be
folded into one single test where the  and  also
are unknowns to be solved for.

Note that the structure of 
, ,
can be viewed as 
.
Hence, we need not store a  array of rationals (or
infinities), but we can implement it efficiently as an array (of size
) of \textsc{Mtbdd}s \cite{DBLP:journals/tc/Bryant86} with the bounds  in the leaves.
Assume for a given template row , we have  different bounds
, and denote  the propositional formula
describing the set of Boolean states that map to bound .
Then, observe that  for  form a
partition of \rronly{ (that is,  is a tautology and each , , is unsatisfiable)}.
We use the notation  to represent an
\textsc{Mtbdd}, and  to obtain the bound
 for state  for template row .\pponly{\
\psi_1 \defn \bigwedge_i \bigvee_{j=1}^{s_i} \phi_{i,j}(\vec{b})
 \land \mat{A}_i\vec{x} \leq c_{i,j} \label{for:invariant_violation2a}\
\pponly{\vspace*{-3ex}}

Remark that  is satisfiable iff
there is a transition from  inside the
invariant defined by  to  outside of it.
\rronly{
The same applies if we replace  in  by a \emph{slicing} or
\emph{cone of influence}  of  with respect to the value of
, that is, a formula  such that  and  are equivalent (w.r.t ).  When  is
compiled from a program, such a  may be obtained using program
slicing.}
The strategy iteration algorithm progresses regardless of  as
long as . 
\rronly{It is however likely that maximizing 
leads to faster convergence \cite[p.~26]{Gawlitza_Monniaux_LMCS12},
because there is no backtracking in max-strategy iteration and hence a
\emph{locally optimal}, \ie, greedy, strategy cannot be
disadvantageous.  Maximizing  may be performed by
\emph{optimization modulo theory}
techniques~\cite{DBLP:conf/sat/NieuwenhuisO06,DBLP:conf/cade/SebastianiT12,LAK+14}.}

Obtaining a solution

enables us to improve the strategy by setting
 and , as in
\S\ref{sec:original_strategy_iteration}.

\begin{example*}
Let us assume the following current abstract value in the analysis of
our running example:\0.6ex]
\centerline{\small }

\noindent This formula is satisfied, \eg, by the model
 .
Hence, we update
 and
.  We have to repeat this
check excluding the above solution to find other models, \eg,
.
\end{example*}


Improving the strategy this way would however be costly, since we
would have to do it one  at a time (by naive model
enumeration). 

\paragraph{Model generalization.}
There is however a better way by \emph{generalizing} from an obtained
model to a set of  that can be updated at once:
Notice now that, fixing  and 
arising from a solution,
 becomes
a purely propositional formula, whose models also yield suitable
solutions for .
Fix 
and  from a solution, then the free variables are
now only the ; then for any solution 
of
,
we can set  and
.
We can thus improve strategies for whole sets of  at once in nondeterministic systems.

\begin{algorithm}[tb]
\caption{\textsc{Improve}: Selecting the strategy improvement
\label{algo:improve}}
\begin{algorithmic}[1]
\STATE{}
\FOR{}
  \STATE{  \hspace{2em} //  defines the set of  such that  has
been updated.}
  \WHILE{\hfill is satisfiable}
    \STATE{ a model of the above formula \rronly{(optionally of max. )}}
    \STATE{}
    \STATE{}
    \WHILE{ is satisfiable}
      \STATE{ a model of }
      \STATE{}
      \STATE{}
      \STATE{ \hspace{2em} //  means ``in the mapping ,}
      \STATE{ \hspace{2.04em} // \; replace all images of  satisfying
formula  }
      \STATE{ \hspace{2.08em} // \; by '' (respectively for~).}
    \ENDWHILE
  \ENDWHILE
\ENDFOR
\end{algorithmic}
\end{algorithm}
\begin{algorithm}[tb]
\caption{\textsc{Iterate}: Main strategy iteration algorithm
\label{algo:iterate}}
\begin{algorithmic}
\FOR{}
  \STATE{;\quad
         ;\quad 
         ;\quad
         }
\ENDFOR
\STATE{}
\WHILE{}
  \STATE{\textsc{Improve}}
  \IF{}
     \STATE{\textsc{Compute-Strategy-Value}  (see \S\ref{sec:new_strategy_value})}
  \ENDIF
\ENDWHILE
\end{algorithmic}
\end{algorithm}


Our strategy improvement algorithm (procedure \textsc{Improve},
Alg.~\ref{algo:improve}) thus proceeds as follows: it maintains a set
 of ``already improved'' values of , and requests
 by SMT-solving as described above, with
the additional constraint that ; if no such
solution is found, it terminates, having done all improvements,
otherwise it generalizes  to a whole set of solutions as
described above, and improves the strategy for all
these~. The strategy  and the set  are stored
in \textsc{Bdd}s.

\begin{example*}
Let us assume we have the current abstract value\\
\centerline{}
Moreover, assume that we have obtained the model of
: 
 .
Substituting the values of this solution for  and  in formula
, we get 
.  
Now, we substitute the above values for  and  in ,
which gives us . We update the strategy
 for
the whole set of states satisfying , \ie,

at once, and we add  to .
Then we ask the SAT solver again for a model of the formula
, which is unsatisfiable in this example.
We continue enumerating the solutions of , but this time 
excluding , \ie, we call the SMT solver with , 
which is unsatisfiable in our example. Hence, we have completed 
strategy improvement for the first template row.
For row 2, we proceed similarly and obtain the same strategy update.
The associated strategy value computation yields the abstract value
:\0.6ex]
\centerline{}
Moreover, assume that we have computed the following strategy for the
first template row:
 and
. 
Then the states  and  will
be in the same equivalence class, because both bounds will have the same
value in the strategy fixed point. Hence, we have to generate only one
set of constraints for both states when solving the LP problem that
characterizes the strategy fixed point . 

\noindent We finally obtain\footnote{By maximizing  for any 
  in , 
we get .} 

This is actually the strongest inductive abstract
invariant of our program: .
\end{example*}


\begin{theorem}
  Let  be the result of the modified strategy evaluation
  and  be the result
  of the original strategy evaluation. Then for all ,
  .
\end{theorem}
\rronly{
\begin{proof}
  The original strategy evaluation computes . Remark that  is thus the limit of the ascending sequence , ; furthermore, from the definition of  and the form of the equivalence classes, for any ,  does not depend on the choice of  in an equivalence class of~. It follows that the same limit is obtained by keeping for each  only one  per equivalence class. This corresponds to iterating\
\hspace*{-1em}\abstr{\Psi}_{\pi}(\rho) \defn (i',\eqvclass{\vec{b}'}{i'}) \mapsto
  \sup \left\{ \mat{A}_i \vec{x}' \mid \exists \vec{x},\vec{y}.~ T_{\pi(i',\vec{b}')}
          \land (\mat{A}\vec{x} \leq \rho(i',\sigma(\eqvclass{\vec{b}'}{i'}))) \right\}
2ex]
 \caption{\label{tab:exp2}
Comparison of max-strategy iteration with standard analysis approaches
(dom: domain used (boxes (B), zones (Z), octagons (O)); number of
variables: Boolean (b), numerical (n), Boolean and numerical inputs
(bi, ni); number of locations (lc) and edges (ed) of the control flow
graph (CFG); analysis time in seconds; property proved (p); fastest in
bold). (* computed with octagons, because zones are not available)
}
\end{table}



\pponly{\vspace*{-2ex}}
\section{Related Work}
\pponly{\vspace*{-1ex}}
It has long been recognized that it is a good idea to distinguish
states according to Boolean variables or arbitrary predicates
(as in \emph{predicate abstraction}). Yet, taking all Boolean
variables into account tends to be unbearably expensive\rronly{: checking the
reachability of a state for a purely Boolean program is
\textsc{pspace}-complete, in practice often solved by constructing a
\textsc{Bdd} describing reachable states as the result of a least
fixed point computation, which may have exponential size}.
\rronly{

While it is possible to encode finite-precision arithmetic into a
Boolean program, the large number of Boolean variables and the
complicated transition structure generally result in poor performance,
thus the incentive to separate arithmetic from ``true'' Booleans and
other small enumerated types.  Note that this may not be so obvious
for languages such as C or intermediate representations such as LLVM
bitcode, where such types may be encoded as integers; a pre-analysis
may be necessary~\cite{DBLP:journals/entcs/JeannetS12}.

Even if the number  of Boolean variables has been suitably
reduced, distinguishing all combinations may be too costly.} Various
heuristics have therefore been proposed so as to partition 
into a reasonably small number of subsets
\cite{DBLP:conf/sas/SchrammelJ11}. Relations between the Boolean and
numerical states are only kept w.r.t. these equivalence
classes~\cite{DBLP:conf/vmcai/SchrammelS13}.
Combining the latter technique with the method presented in this paper
to limit partitioning would certainly improve efficiency, however, to
the detriment of precision of the obtained invariant which strongly
depends on the choice of a clever partitioning heuristics.

Early work in compilation and verification of reactive systems
\cite{DBLP:journals/scp/BouajjaniFHR92} advocated quotienting the
Boolean state space according to some form of \emph{concrete}
bisimulation. In contrast, we compute coarser equivalences according
to per-constraint \emph{abstract} semantics.
In the \rronly{industrial-strength analyzer }\textsc{Astr\'ee}\pponly{
  analyzer}, static heuristics determine reasonably small packs of
``related'' Booleans and numerical variables, such that the values of
the numerical variables are analyzed separately for each Boolean
valuation~\cite[\S6.2.4]{BlanchetCousotEtAl_PLDI03}. In contrast, our
equivalence classes are computed dynamically and per-constraint.

\rronly{
\emph{Disjunctive invariants} are related to the partitioning
approach; in both cases the invariant is a disjunction  where  are simpler invariants (typically, conjunctions
of certain types of literals), but in the disjunctive invariant
approach the  may overlap (that is, not have pairwise empty
intersection). In such a system, union (as at control merge points)
may be implemented by simple concatenation of the disjunctions, but
this quickly leads to a blowup; instead a criterion could be used to
merge those , \eg, of which the abstract union is actually exact;
a similar problem occurs with widening
operators~\cite{DBLP:journals/sttt/BagnaraHZ06}. An alternative, which
bears some limited resemblance to our strategy-based approach, is to
build a map  meaning that disjunct  flows through path
 into disjunct
~\cite{Henry_Monniaux_Moy_SAS2012}.
}

The strategy iteration we have applied proceeds ``upward'', by
successive under-approximations of the least inductive invariant\rronly{ inside the domain converging to it in a finite number of
  iterations}; strategies correspond to \rronly{paths inside the
  program, which map }to ``max'' operators in a high-level vision of
the problem. There also exists ``downward'' strategy iteration, where
strategies correspond to ``min'' operators\rronly{ (tests inside the
  programs and internal reductions of the abstract domain)}:
iterations produce successive \emph{over}-approximations of the least
inductive
invariant~\cite{DBLP:conf/esop/GaubertGTZ07,DBLP:conf/atva/SotinJVG11},
to which convergence is ensured in some cases. A bonus of such an
approach is that each iteration produces an over-approximation of the
least inductive invariant\rronly{ inside the domain}, which may be
used to prove safety properties without having to wait for
convergence. Sadly, it does not seem to be easily adapted to
approaches based on SMT solving, since the SMT formulas would contain
universal quantifiers\rronly{, which greatly complicates their solving}.

\pponly{For a more comprehensive discussion of related work, we refer to 
the extended version \cite{MS14a}.}
\rronly{
Recently, a tool for \emph{optimization modulo theory}
was presented \cite{LAK+14}. We plan to test the
variant of our algorithm maximizing  (see
\S\ref{sec:new_strategy_improvement}) with the help of this tool.
}

\pponly{\vspace*{-1.5ex}}
\section{Conclusion}
\pponly{\vspace*{-0.5ex}}
We propose a method for computing strongest invariants in
linear template domains when the control states are
partitioned according to  Booleans or arbitrary predicates, thereby
producing a combination of predicate abstraction and template
polyhedral abstraction.  \rronly{In accordance with preceding works
\cite{Henry_Monniaux_Moy_SAS2012,Gawlitza_Monniaux_LMCS12,Monniaux_Gonnord_SAS11},
it traverses loop-free parts of the control graph without need for
intermediate abstraction, thus improving the precision.} Our method
performs strategy iteration, and dynamically partitions 
the states according to an equivalence relation depending on the
current abstraction at each step. The final result is optimal in
the sense that it is the strongest invariant in the abstract domain{\rronly,
which a naive algorithm would obtain in at least exponential time and
space}. \rronly{While an upper bound on the number of equivalence classes in
our algorithm is also exponential , it can be limited arbitrarily,
with some loss of precision. The upper bound on the number of
iterations is doubly exponential in~.}
Our experimental results demonstrate the significant
performance impact of various optimizations and
the ability to compute more precise invariants in comparison to
widening-based techniques.

\pponly{
In preceding work without partitioning
\cite{GM11,Gawlitza_Monniaux_LMCS12}, the single-exponential upper
bound was shown to be reached by a contrived example
program, and the decision problem associated with the least invariant
computation (``given a template, a transition relation, an initial
state and a bad state, is there an inductive invariant that excludes
the bad state'') was shown to be -complete. In contrast,
although we have an \textsc{nexptime}
upper bound and proved \textsc{exptime}-hardness
(see \cite{MS14a} for a proof)
for the problem with partitioning,
we have not yet been able to \rronly{narrow the
interval despite repeated attempts at proving}\pponly{prove}
\textsc{nexptime}-completeness\rronly{. It is thus possible
  that }\pponly{---thus} the worst-case
complexity \pponly{could}\rronly{is} possibly \pponly{be }better.
}

\bibliographystyle{splncs03}
\bibliography{powerset_policies}
\end{document}
