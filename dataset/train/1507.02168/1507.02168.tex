In this section we assume we have a maximal instance $\inst = (G,\terms,(\Az,\Bz),k)$ for which none of the previously defined reduction rules is applicable.
Our goal is to find a {\em{branching step}} that fulfils a good vector,
or a set of vertices to merge (a {\em{reduction step}}). Recall that when we consider a branching into terminal separations $(A_1,B_1)$ and $(A_2,B_2)$ that extend $(\Az,\Bz)$, then $t_i,\nu_i,k_i$ for $i=1,2$ measure respectively the number of terminals resolved in branch $i$, two times the growth of the cost of the separation in branch $i$ (i.e., $2(c(A_i,B_i)-c(\Az,\Bz))$), and the decrease in the budget $k$ after applying all the reduction rules when recursing into branch $i$.

Assume that we have identified a branching step into separations
$(A_1,B_1)$ and $(A_2,B_2)$ that both extend, but are different than
$(\Az,\Bz)$. Then, from the maximality of $(\Az,\Bz)$ we infer than
$\nu_1,\nu_2 \geq 1$.
Since $[1,1,0;2,1,0]$ is a good vector, any branching step
in which in both cases we resolve or reduce at least one terminal pair,
while in at least one case we resolve or reduce at least \emph{two} terminal
pairs, is fine for our purposes. 

\subsection{Basic branching and reductions}

Let $\terms' \subseteq \terms$ be the set of unresolved terminal pairs (not in $\Az\cup \Bz$). For every terminal pair $\{s,t\}\in \terms'$, we apply the algorithm of Theorem~\ref{thm:ptime} twice: once for terminal separation $(\Az\cup \{s\},\Bz\cup \{t\})$, and the second time for terminal separation $(\Az\cup \{t\},\Bz\cup \{s\})$. In this manner we obtain two maximal terminal separations $(A_s,B_t)$ and $(A_t,B_s)$ that extend $(\Az\cup \{s\},\Bz\cup \{t\})$ and $(\Az\cup \{t\},\Bz\cup \{s\})$ respectively. Of course, the number of unresolved pairs decreases by at least one in both $(A_s,B_t)$ and $(A_t,B_s)$, due to resolving $\{s,t\}$. If the number of unresolved pairs either in $(A_s,B_t)$ or in $(A_t,B_s)$ decreases by more than one, then, as we argued, performing a branching step $(A_1,B_1)=(A_s,B_t)$ and $(A_2,B_2)=(A_t,B_s)$ leads to the branching vector $[1,1,0;2,1,0]$ or a better one, which is good. We can test in $\Oh(k^{\Oh(1)} m)$ time whether this holds for any pair $\{s,t\}\in \terms'$, and if so then we pursue the branching step. 

\begin{branching}\label{br:twopairs}
If in either $(A_s,B_t)$ or in $(A_t,B_s)$, more than one terminal pair gets resolved, then perform branching into $(A_1,B_1)=(A_s,B_t)$ and $(A_2,B_2)=(A_t,B_s)$.
\end{branching}

Hence, if this branching step cannot be performed, then we assume the following:

\begin{assumption}\label{ass:one-pair}
For every pair $\{s,t\}\in \terms'$ in both $(A_s,B_t)$ and $(A_t,B_s)$ only the pair $\{s,t\}$ gets resolved.
\end{assumption}

We now proceed with some structural observations about the instance at hand.

\begin{lemma}\label{lem:AsConn}
$G[A_s\setminus \Az]$, $G[A_t\setminus \Az]$, $G[B_s\setminus \Bz]$, $G[B_t\setminus \Bz]$ are connected.
\end{lemma}
\begin{proof}
We prove the statement for $G[A_s\setminus \Az]$, since the other statements are symmetric. Suppose $G[A_s\setminus \Az]$ is disconnected, and let $C$ be any of its connected component that does not contain $s$. Then $C$ is terminal-free, so by the maximality of $(\Az,\Bz)$ we infer that $d(C\cup \Az)>d(\Az)$. But then $d(A_s\setminus C)<d(A_s)$, which contradicts the optimality of $(A_s,B_s)$.
\end{proof}

\begin{lemma}\label{lem:lb}
Let $\{s,t\}\in \terms'$, and let $(A_s,B_t)$ and $(A_t,B_s)$ be any optimum-cost terminal separations extending $(\Az\cup\{s\},\Bz\cup \{t\})$ and $(\Az\cup\{t\},\Bz\cup \{s\})$, respectively. Suppose that $(A_s,B_t)$ and $(A_t,B_s)$ do not resolve any terminal pair apart from $\{s,t\}$. Then for any set $A$ with $\Az\cup\{s\}\subseteq A\subseteq V(G)\setminus \Bz$ that has only $s$ among the terminals of $\terms'$, it holds that $\Delta(A)\geq \Delta(A_s)$. Symmetrically, for any set $B$ with $\Bz\cup\{s\}\subseteq B\subseteq V(G)\setminus \Az$ that has only $s$ among the terminals of $\terms'$, it holds that $\Delta(B)\geq \Delta(B_s)$.
\end{lemma}
\begin{proof}
We prove only the first claim for the second one is symmetric. Let $A$ be such a set, and for the sake of contradiction suppose $\Delta(A)<\Delta(A_s)$. Then $d(A)+d(B_t)<2c(A_s,B_t)$. However, from posimodularity of cuts it follows that either $d(B_t\setminus A)+d(A)\leq d(B_t)+d(A)$ or $d(B_t)+d(A\setminus B_t)\leq d(B_t)+d(A)$. Both $(A,B_t\setminus A)$ and $(A\setminus B_t,B_t)$ are terminal separations that extend $(\Az\cup\{s\},\Bz\cup \{t\})$, and one of them has strictly smaller cost than $(A_s,B_t)$. This is a contradiction with the optimality of $(A_s,B_t)$.
\end{proof}

\subsubsection{Pushing $A_s$ and $B_s$}

The problem that we will soon face is that separations $(A_s,B_t)$ and $(A_t,B_s)$ are not uniquely defined. For instance, there can be some set of vertices $Z\subseteq A_s\setminus \Az$ that could be moved from $A_s$ to $B_t$ without changing the cost of the separation. We now make an adjustment of these separations so that we can assume that $A_s$, resp. $B_s$, is maximal. For this, we need the following technical results.

\begin{lemma}\label{lem:patch}
Suppose that $(A_s,B_t)$ and $(A_s',B_t')$ are maximal terminal separations of minimum cost among separations that extend $(\Az\cup \{s\},\Bz\cup \{t\})$. Suppose further that they do not resolve any other terminal pair from $\terms'$. Then
\begin{itemize}
\item[(a)] $d(A_s)=d(A_s')$ and $d(B_t)=d(B_t')$;
\item[(b)] $(A_s\cap A_s',B_t\cup B_t')$ and $(A_s\cup A_s',B_t\cap B_t')$ are also terminal separations of minimum cost among separations that extend $(\Az\cup \{s\},\Bz\cup \{t\})$;
\item[(c)] $A_s\cup B_t=A_s'\cup B_t'$.
\end{itemize}
\end{lemma}
\begin{proof}
\noindent (a) Let $C=c(A_s,B_t)=c(A_s',B_t')$ be the minimum cost of a terminal separation extending $(\Az\cup \{s\},\Bz\cup \{t\})$. Suppose w.l.o.g. that $d(A_s)<d(A_s')$, then we have that $d(B_t)>d(B_t')$. By posimodularity, we have that
\begin{equation}\label{eq1}
d(A_s\setminus B_t')+d(B_t'\setminus A_s)\leq d(A_s)+d(B_t')<2C.
\end{equation}
Observe that $(A_s\setminus B_t',B_t')$ is a terminal separation that extends $(\Az\cup \{s\},\Bz\cup \{t\})$, and hence 
\begin{equation}\label{eq2}
d(A_s\setminus B_t')+d(B_t')=2c(A_s\setminus B_t',B_t')\geq 2C.
\end{equation}
Symmetrically, by considering terminal separation $(A_s,B_t'\setminus A_s)$ we obtain that
\begin{equation}\label{eq3}
d(A_s)+d(B_t'\setminus A_s)=2c(A_s,B_t'\setminus A_s)\geq 2C.
\end{equation}
Thus, from~\eqref{eq1},~\eqref{eq2}, and~\eqref{eq3} we obtain that
$$4C\leq d(A_s)+d(B_t')+d(A_s\setminus B_t')+d(B_t'\setminus A_s)<4C,$$
which is a contradiction.

\smallskip

\noindent (b) Observe that $d(A_s\cap A_s')\geq d(A_s)$, because otherwise $A_s$ could have been replaced with $A_s\cap A_s'$ in separation $(A_s,B_t)$. By submodularity of cuts we have that $d(A_s\cap A_s')+d(A_s\cup A_s')\leq d(A_s)+d(A_s')$, and hence $d(A_s\cup A_s')\leq d(A_s')=d(A_s)$. By posimodularity, we have that
\begin{equation}\label{eq21}
d((A_s\cup A_s') \setminus B_t)+d(B_t\setminus (A_s\cup A_s'))\leq d(A_s\cup A_s')+d(B_t)\leq d(A_s)+d(B_t)=2C
\end{equation}
On the other hand, for terminal separation $((A_s\cup A_s') \setminus B_t,B_t)$ we have that
\begin{equation}\label{eq22}
d((A_s\cup A_s') \setminus B_t)+d(B_t) = 2c((A_s\cup A_s') \setminus B_t,B_t) \geq 2C,
\end{equation}
and for terminal separation $(A_s\cup A_s',B_t\setminus (A_s\cup A_s'))$ we have that
\begin{equation}\label{eq23}
d(A_s\cup A_s')+d(B_t\setminus (A_s\cup A_s')) = 2c((A_s\cup A_s',B_t\setminus (A_s\cup A_s')) \geq 2C.
\end{equation}
Thus, from~\eqref{eq21},~\eqref{eq22}, and~\eqref{eq23}
$$4C\geq d((A_s\cup A_s') \setminus B_t)+d(B_t)+d(A_s\cup A_s')+d(B_t\setminus (A_s\cup A_s'))\geqÂ 4C,$$
which means that all the inequalities above are in fact equalities. In particular:
\begin{itemize}
\item $d(A_s\cap A_s')=d(A_s)=d(A_s\cup A_s')$, and 
\item $c((A_s\cup A_s') \setminus B_t,B_t)=C$.
\end{itemize} 
Symmetric arguments can be used to show that:
\begin{itemize}
\item $d(B_t\cap B_t') = d(B_t)=d(B_t\cup B_t')$, 
\item $c((A_s\cup A_s') \setminus B_t',B_t')=C$, 
\item $c(A_s,(B_t\cup B_t')\setminus A_s)=C$, and
\item $c(A_s',(B_t\cup B_t')\setminus A_s')=C$.
\end{itemize}
Therefore, both $(A_s\cap A_s',B_t\cup B_t')$ and $(A_s\cup A_s',B_t\cap B_t')$ have cost $C$.

\smallskip

\noindent (c) For the sake of contradiction, assume that $A_s\cup B_t\neq A_s'\cup B_t'$. Suppose first that there is an element $u\in A_s$ such that $u\notin A_s'\cup B_t'$. In the proof of (b) we have showed that $c((A_s\cup A_s') \setminus B_t',B_t')=C$. Note that $((A_s\cup A_s') \setminus B_t',B_t')$ is a terminal separation that extends $(A_s',B_t')$, and moreover its left side is has at least one additional element $u$. Since its cost is the same as the cost of $(A_s',B_t')$, we obtain a contradiction with the maximality of $(A_s',B_t')$.
\end{proof}

\begin{lemma}\label{lem:pushing}
Let $\mathcal{F}$ be the family of all maximal terminal separations $(A_s,B_t)$ of minimum cost among separations that extend $(\Az\cup \{s\},\Bz\cup \{t\})$. Suppose that all separations from $\mathcal{F}$ resolve only the pair $\{s,t\}$ among the pairs from $\terms'$. Then there exists a unique maximal terminal separation $(A_s^{\max},B_t^{\min})$ such that $A_s^{\max}\supseteq A_s$ and $B_t^{\min}\subseteq B_t$ for each $(A_s,B_t)\in \mathcal{F}$. Moreover, if $A$ is such that $\Az\cup \{s\}\subseteq A$, $A\cap \Bz=\emptyset$, $A \cap \bigcup \terms' \subseteq \{s\}$, but $A\setminus A_s^{\max}\neq \emptyset$, then $d(A)>d(A_s^{\max})$.
\end{lemma}
\begin{proof}
We set 
$$(A_s^{\max},B_t^{\min})=\left(\bigcup_{(A_s,B_t)\in \mathcal{F}} A_s,\bigcap_{(A_s,B_t)\in \mathcal{F}} B_t\right).$$
From Lemma~\ref{lem:patch} it follows that $(A_s^{\max},B_t^{\min})\in \mathcal{F}$. 

\newcommand{\oA}{\overline{A}}
\newcommand{\oB}{\overline{B}}

We are left with proving the last statement. Take any such $A$, and suppose for the sake of contradiction that $d(A)\leq d(A_s^{\max})$. Let $\oA=A_s^{\max}\cup A$ and $\oB=B_t^{\min}\setminus A$. Observe that $(\oA,\oB)$ is a terminal separation that extends $(\Az\cup \{s\},\Bz\cup \{t\})$. Since $\oA$ has at least one more element than $A_s^{\max}$, from the properties of $(A_s^{\max},B_t^{\min})$ we infer that $c(\oA,\oB)>C$, where $C$ is the cost of every separation from $\mathcal{F}$. Observe that $d(A_s^{\max}\cap A)\geq d(A_s^{\max})$, because otherwise we would substitute $A_s^{\max}$ with $A_s^{\max}\cap A$ in separation $(A_s^{\max},B_t^{\min})$ and obtain a separation of smaller cost that extends $(\Az\cup \{s\},\Bz\cup \{t\})$. Hence, from the submodularity of cuts we infer that $d(\oA)\leq d(A)$, so in particular $d(\oA)\leq d(A_s^{\max})$.

Now, by posimodularity we obtain that
$$d(\oA\setminus B_t^{\min})+d(B_t^{\min}\setminus \oA)\leq d(\oA)+d(B_t^{\min})\leq d(A_s^{\max})+d(B_t^{\min}).$$
On the other hand, observe that $d(\oA\setminus B_t^{\min})\geq d(A_s^{\max})$, because otherwise we could substitute $A_s^{\max}$ with $\oA\setminus B_t^{\min}$ in the terminal separation $(A_s^{\max},B_t^{\min})$ and obtain a terminal separation that extends $(\Az\cup \{s\},\Bz\cup \{t\})$ and has strictly smaller cost. Thus we infer that $d(B_t^{\min}\setminus \oA)\leq d(B_t^{\min})$. As $B_t^{\min}\setminus \oA=B_t^{\min}\setminus A=\oB$, we conclude that $d(\oA)\leq d(A_s^{\max})$, $d(\oB)\leq d(B_t^{\min})$, and hence $c(\oA,\oB)\leq C$. This is a contradiction.
\end{proof}

We modify now separation $(A_s,B_t)$ as follows. For every terminal pair $\{s',t'\}\in \terms'$ that is different from $\{s,t\}$, we verify using Theorem~\ref{thm:ptime} whether $(A_s,B_t)$ can be chosen so that it has a minimum possible cost among the separations that extend $(\Az\cup \{s\},\Bz\cup \{t\})$, but it also resolves $\{s',t'\}$. If this is possible, then we pursue Branching Step~\ref{br:twopairs} with appropriate $(A_s,B_t)$. Otherwise, every minimum-cost separation extending $(\Az\cup \{s\},\Bz\cup \{t\})$ resolves only $\{s,t\}$, and the assumptions of Lemma~\ref{lem:pushing} are satisfied.
Let $(A_s^{\max},B_t^{\min})$ be the terminal extension whose existence is asserted by Lemma~\ref{lem:pushing}.
Observe that we can construct $(A_s^{\max},B_t^{\min})$ in time $\Oh(k^{\Oh(1)} m)$:
we start with any $(A_s,B_t)$ given by Theorem~\ref{thm:ptime},
and observe that Lemma~\ref{lem:pushing} implies that $A_s^{\max}$ is the unique inclusion-wise maximal set
containing $A_s$ such that $E(A_s^{\max},V(G) \setminus A_s^{\max})$ is a minimum cut between $A_s$ and $\Bz \cup (\terms \setminus A_s)$;
such a set can be computed using $\Oh(k)$ rounds of the Ford-Fulkerson algorithm.
  
Hence, we proceed further with the assumption that we have chosen $(A_s,B_t)$ to be $(A_s^{\max},B_t^{\min})$. We do symmetrically in the second branch, assuming that $(A_t,B_s)$ is chosen to be $(A_t^{\min},B_s^{\max})$, that is, the extension of $B$ that contains terminal $s$ is chosen to be maximum possible. Hence, by Lemma~\ref{lem:pushing}, we can from now on use the following assumption.

\begin{assumption}\label{ass:pushing}
For any set $A$ with $\Az\subseteq A\subseteq V(G)\setminus \Bz$ that contains only $s$ from the terminals of $\terms'$ and has at least one vertex outside $A_s$, it holds that $\Delta(A)>\Delta(A_s)$. Symmetrically, for any set $B$ with $\Bz\subseteq B\subseteq V(G)\setminus \Az$ that contains only $s$ from the terminals of $\terms'$ and has at least one vertex outside $B_s$, it holds that $\Delta(B)>\Delta(B_s)$. 
\end{assumption}

\subsubsection{Analyzing $A_s\cap B_s$, $A_s\setminus B_s$, and $B_s\setminus A_s$}

Suppose now that for some pair $\{s,t\}\in \terms'$, we have that $|(A_s\cap B_s)\setminus \{s\}|\geq 2$. Then, by Assumption~\ref{ass:one-pair} $Z=(A_s\cap B_s)\setminus \{s\}$ is a terminal-free set. Since pair $\{s,t\}$ has to be resolved one way or the other, then by persistence (Theorem~\ref{thm:persistence}) we infer that there is some minimum integral terminal separation $(\Aopt,\Bopt)$ such that $Z\subseteq \Aopt$ or $Z\subseteq \Bopt$. Therefore, it is a safe reduction to merge $Z$ into a single vertex.

\begin{reductionstep}
For every $\{s,t\}\in \terms'$, compute $Z_s=(A_s\cap B_s)\setminus \{s\}$ and $Z_t=(A_t\cap B_t)\setminus \{t\}$. Provided $Z_s$ ($Z_t$) contains more than one vertex, merge it.
\end{reductionstep}

We apply this reduction to all terminal pairs from $\terms'$, which takes time $\Oh(k^{\Oh(1)} m)$. Hence, using Lemma~\ref{lem:AsConn} from now on we can assume the following:

\begin{assumption}\label{ass:small-intersections}
For every pair $\{s,t\}\in \terms'$, either $A_s\cap B_s=\{s\}$ or $A_s\cap B_s=\{s,s'\}$, where $s'$ is the only neighbor of $s$. Moreover, either $A_t\cap B_t=\{t\}$ or $A_t\cap B_t=\{t,t'\}$, where $t'$ is the only neighbor of $t$.
\end{assumption}

As every terminal has degree one, for a pair $\{s,t\}\in \terms'$ we have that $d(A_s)\leq d(\Az\cup \{s\})\leq d(\Az)+1$, since otherwise replacing $A_s$ with $\Az\cup \{s\}$ would decrease the cost of $(A_s,B_s)$. On the other hand, we have that $d(A_s)\geq d(\Az)$, since otherwise $(A_s,\Bz\cup \{t\})$ would be a terminal separation extending $(\Az,\Bz)$ of not larger cost, which would contradict the maximality of $(\Az,\Bz)$. Then, we have three possible cases for $(\Delta(A_s),\Delta(B_s))$: $(0,0)$, $(1,0)$ and $(1,1)$; the omitted case $(0,1)$ is symmetric to $(1,0)$. The algorithm behaves differently in each of these cases. Before we proceed to the description of handling each case separately, we prove some useful observations first.

\newcommand{\Atr}{\tilde{A}}
\newcommand{\Btr}{\tilde{B}}

Let us now fix one pair $\{s,t\}$, and let $\Atr=A_s\setminus B_s$ and $\Btr = B_s\setminus A_s$. Observe that since branching on $\{s,t\}$ did not resolve any additional terminal pair, then both $\Atr \setminus \Az$ and $\Btr \setminus \Bz$ are terminal-free. Hence, by the maximality of $(\Az,\Bz)$ we have that
\begin{equation}\label{eq:truncs}
d(\Atr)\geq d(\Az) \qquad \text{and}\qquad d(\Btr)\geq d(\Bz),
\end{equation}
and the equality holds if and only if $\Atr=\Az$ or $\Btr=\Bz$, respectively. Let $R=V(G)\setminus (A_s\cup B_s)$.

\begin{lemma}\label{lem:posi}
One of the following two cases holds:
\begin{itemize}
\item $|E(A_s\cap B_s,R)|=1$, $\Atr=\Az$, $\Btr=\Bz$, and $(\Delta(A_s),\Delta(B_s))=(1,1)$; or
\item $|E(A_s\cap B_s,R)|=0$, and $2\geq \Delta(A_s)+\Delta(B_s)=\Delta(\Atr)+\Delta(\Btr)\geq 0$.
\end{itemize}
\end{lemma}
\begin{proof}
By applying posimodularity of cuts to the sets $A_s$ and $B_s$, we obtain:
\begin{equation}\label{eq:posi}
d(A_s)+d(B_s)=d(\Atr)+d(\Btr)+2|E(A_s\cap B_s,R)|\geq d(\Az)+d(\Bz)+2|E(A_s\cap B_s,R)|.
\end{equation}
On the other hand, we have that $d(A_s)\leq d(\Az)+1$ and $d(B_s)\leq d(\Bz)+1$. Hence we have that $|E(A_s\cap B_s,R)| \leq 1$ and the claimed case distinction follows from~\eqref{eq:truncs} and~\eqref{eq:posi}.
\end{proof}

\subsubsection{Decomposing sets of excess $2$}

Finally, we make a useful observation that will show a generic setting when Lemma~\ref{lem:ex2-red} can be applied.

\begin{lemma}\label{lem:cool}
Suppose $\Delta(A_s)=1$ and $A_s \neq \Az \cup \{s\}$. Then $A_s\setminus \{s\}\supsetneq \Az$ is a terminal-free excess-2 set, and $(A_s\setminus \Az)\setminus \{s\}$ has a decomposition $\{d,c_1,c_2,\ldots,c_r\}$ given by Lemma~\ref{lem:ex2-red}.
Moreover, $d=s'$ is the unique neighbor of $s$ in $G$.
\end{lemma}
\begin{proof}
The fact that $A_s\setminus \{s\}$ is an excess-2 set follows from the assumption that $s$ has degree exactly $1$ (due to the inapplicability of the Lonely Terminal Reduction), and its unique neighbor $s'$ does not belong to $\Az\cup \Bz$
and does belong to $A_s$ (because $G[A_s\setminus \Az]$ is connected by Lemma~\ref{lem:AsConn}).
Since $(A_s\setminus \Az)\setminus \{s\}$ is nonempty and terminal-free (by Assumption~\ref{ass:one-pair}),
it follows from Lemma~\ref{lem:ex2-red} that it has a decomposition of the form $\{c_1,c_2\}$ or $\{d,c_1,c_2,\ldots,c_r\}$, where $c_i$-s are pairwise nonadjacent and $\Az\cup \{c_i\}$ are excess-1 sets. Suppose $s'=c_i$ for some $i$. Then since $\Az\cup \{c_i\}$ is an excess-1 set, we would have that $\Az\cup \{c_i,s\}$ is an excess-0 set, and hence $(\Az\cup \{c_i,s\},B_t)$ would be an extension of $(\Az\cup \{s\},\Bz\cup \{t\})$ of strictly smaller cost than $(A_s,B_t)$, contradicting the definition of $(A_s,B_t)$. Hence $(A_s\setminus \Az)\setminus \{s\}$ has a decomposition of the form $\{d,c_1,c_2,\ldots,c_r\}$ and $s'=d$.
\end{proof}

We will need one more lemma that resolves corner cases when we apply Lemma~\ref{lem:cool}.

\begin{lemma}\label{lem:no-overlap}
Suppose $s$ satisfies the conditions of Lemma~\ref{lem:cool}, and let $\{d=s',c_1,c_2,\ldots,c_r\}$ be the obtained decomposition of $(A_s\setminus \Az)\setminus \{s\}$. Let $t'$ be the unique neighbor of $t$. Then $s'\neq t'$, and if $t'=c_i$ for some $i\in \{1,2,\ldots,r\}$, then there exists an optimum integral terminal separation $(\Aopt,\Bopt)$ that extends $(\Az,\Bz)$ and has $s\in \Bopt$ and $t\in \Aopt$.
\end{lemma}
\begin{proof}
The fact that $s'\neq t'$ follows from the inapplicability of the Common Neighbour Reduction. Suppose then that $t'=c_i$. From Lemma~\ref{lem:ex2-red} it follows that for some $p_i\geq 1$ and $x_i\geq 0$, there are $p_i$ edges between $s'$ and $c_i$, $p_i+x_i$ edges between $c_i$ and $\Az$, and $x_i+1$ edges between $c_i$ and $V(G)\setminus A_s$; one of these $x_i+1$ edges connects $c_i=t'$ with $t$.

Take any optimum integral separation $(\Aopt,\Bopt)$ extending $(\Az,\Bz)$ and suppose that $s\in \Aopt$ and $t\in \Bopt$. We can further assume that $s'\in \Aopt$ and $t'=c_i\in \Bopt$, because otherwise switching the sides of $s$ and $t$ would result in an integral separation of not larger cost that already fulfills the property we aim for. Recall that $c_i$ has $p_i$ edges to $s'$ (which is assigned to $\Aopt$), $p_i+x_i$ edges to $\Az$, and $x_i+1$ edges to other vertices of the graph. Since $p_i\geq 1$, we see that a strict majority of neighbors of $c_i$ are in $\Aopt$. Hence switching the side of $c_i$ from $\Aopt$ to $\Bopt$ strictly decreases the cost of the separation, a contradiction.
\end{proof}

Lemma~\ref{lem:no-overlap} enables us to perform a reduction step whenever a corner case appears in the analysis of vertices close to $s$ and $t$. We choose not to perform this reduction exhaustively, but rather to execute it on demand when such a case appears during branching.



\subsubsection{Fixing an edge $ss'$ or $tt'$}

In a few cases, we consider an improved branching set,
when in one branch we fix $\{s',s\}$ to belong to the left part and $t$ to belong to the right part, whereas in the second branch we fix vice versa. More precisely, we consider branches $(A_{ss'\to A},B_{ss'\to A})$ and $(A_{ss'\to B},B_{ss'\to B})$ that are minimum-cost terminal separations extending $(\Az\cup \{s,s'\},\Bz\cup \{t\})$ and $(\Az\cup \{t\},\Bz\cup \{s,s'\})$, computed using Theorem~\ref{thm:ptime}. Observe that there is some optimum solution that extends one of these branches: If in some optimum solution the vertices $s'$ and $s$ were assigned to different sides, then we could modify this solution by swapping the sides of $s$ and $t$. After this modification then solution has no larger cost due to $t$ having degree one, whereas the edge $ss'$ ceases to be cut by the solution. This justifies the correctness of this branching step; we shall henceforth call it {\em{branching on $\{s,t\}$ with fixing the edge $ss'$}}.
Symmetrically, we can define branching on $\{s,t\}$ with fixing the edge $tt'$.

\subsection{Case $(\Delta(A_s),\Delta(B_s))=(0,0)$}

We show that this case in fact never happens. From Lemma~\ref{lem:posi} we infer that $E(A_s \cap B_s, R) = \emptyset$, $\Atr=\Az$, and $\Btr=\Bz$. Hence, $A_s\setminus \Az=B_s\setminus \Bz=A_s\cap B_s$. As we argued earlier, we can assume that $A_s\cap B_s=\{s\}$ or $A_s\cap B_s=\{s,s'\}$ for $s'$ being the only neighbor of $s'$. 

In the first case, since the degree of $s$ is at most one, from $E(A_s \cap B_s, R) = \emptyset$ and $\Delta(A_s)=\Delta(B_s)=0$ we can infer that $s$ is an isolated terminal, which should have been removed by the Lonely Terminal Reduction. This contradicts the assumptions that no reduction rule is applicable.

In the second case, by $E(A_s \cap B_s, R) = \emptyset$ and $\Delta(A_s)=\Delta(B_s)=0$, we infer that $|E(s',\Az)|=|E(s',\Bz)|=x$ for some $x\geq 0$. If $x=0$, then $s'$ should have been reduced by the Pendant Reduction. On the other hand, if $x>0$ then the Boundary Reduction would have been triggered on $s'$. In both cases this is a contradiction.

\begin{figure}[H]
	\centering
	\clearpage{}\begin{tikzpicture}

\draw[Bs] plot [smooth,tension=1.3] coordinates {(-2,2)  (0,0.4) (2,2)} to (-2,2);
\draw[As] plot [smooth,tension=1.3] coordinates {(-2,0)  (0,1.6) (2,0)} to (-2,0);

\Azero;
\begin{scope}[shift={(0,2)}] \Bzero; \node at (1,0.17) {$\Bz$}; \end{scope}
\node at (1,-0.2) {$\Az$};
\node[ABT,label=30:$\mathbf{s}$] (s) at (0.1,1) {};
\node[T, label=10:$\mathbf{t}$] (t) at (2.4,1) {};
\draw[term] (s) to[term,bend right=10] (t);


\begin{scope}[shift={(7,0)}]

\draw[Bs] plot [smooth,tension=1.9] coordinates {(-2,2)  (0,0.2) (2,2)} to (-2,2);
\draw[As] plot [smooth,tension=1.9] coordinates {(-2,0)  (0,1.8) (2,0)} to (-2,0);

\Azero;
\begin{scope}[shift={(0,2)}] \Bzero; \node at (1,0.17) {$\Bz$}; \end{scope}
\node at (1,-0.2) {$\Az$};
\node[ABT,label=30:$\mathbf{s}$] (s) at (0.6,1) {};
\node[AB, label=180:$\mathbf{s'}$] (sp) at (-0.6,1) {};
\node[T, label=10:$\mathbf{t}$] (t) at (2.4,0.9) {};
\draw[term] (s) to[term,bend right=10] (t);
\draw (s) to (sp);
\draw (sp) to (-0.33,2.15);
\draw (sp) to (-0.55,2.2);
\draw (sp) to (-0.77,2.15);
\node at (-0.23,1.6) {$p$};
\draw (sp) to (-0.33,-0.15);
\draw (sp) to (-0.55,-0.2);
\draw (sp) to (-0.77,-0.15);
\node at (-0.2,0.4) {$p$};

\end{scope}
\end{tikzpicture}
\figspace
\clearpage{}
	\caption{Case  $(\Delta(A_s),\Delta(B_s))=(0,0)$: a reduction is always immediately applicable. Terminal nodes are squares, paired with zig-zags. Extensions $A_s$ and $B_s$ are highlighted with light blue and red, respectively.}
\label{fig:case-00}
\end{figure}



\subsection{Case $(\Delta(A_s),\Delta(B_s))=(1,0)$}

From Lemma~\ref{lem:posi} we infer that $E(A_s \cap B_s, R) = \emptyset$ and $\Delta(\Atr)+\Delta(\Btr)=1$. We have two subcases: either (a) $(\Delta(\Atr),\Delta(\Btr))=(1,0)$, or (b) $(\Delta(\Atr),\Delta(\Btr))=(0,1)$.

\subsubsection{Subcase (a): $(\Delta(\Atr),\Delta(\Btr))=(1,0)$}

By the equality condition in~\eqref{eq:truncs} we have that $\Btr=\Bz$, while $\Atr\supsetneq \Az$ is a terminal-free set of excess $1$. By the inapplicability of the Excess-1 Reduction, we infer that $\Atr=\Az\cup \{a\}$ for some nonterminal vertex $a$.





Set $A_s$ satisfies the conditions of Lemma~\ref{lem:cool}, so we can decompose $(A_s\setminus \Az)\setminus \{s\}$ into $\{d,c_1,c_2,\ldots,c_r\}$, where $d=s'$ is the unique neighbor of $s$. Since $\Delta(\Atr)=1$, we have that $B_s\supsetneq \Bz\cup \{s\}$ and hence by Lemma~\ref{lem:AsConn} it follows that $s'\in B_s$. By Assumption~\ref{ass:small-intersections} we infer that $A_s\cap B_s=\{s,s'\}$ and thus $\{a\}=\Atr\setminus \Az=\{c_1,c_2,\ldots,c_r\}$. Therefore $r=1$ and $c_1=a$.

Since $\Btr=\Bz$, $B_s\setminus \Bz = B_s \cap A_s = \{s,s'\}$.

By Lemma~\ref{lem:ex2-red} we have that $a$ has: $p$ edges to $s'$, $x+1$ edges to $V(G)\setminus (A_s \cup \Bz)$, $p+x$ edges to $\Az$ and no other edges, for some $p\geq 1, x\geq 0$. 
Since $B_s=\Bz\cup \{s',s\}$ is an excess-0 set and $E(s',R)=\emptyset$, we have that $|E(s',\Bz)|=p+|E(s',\Az)|$. In particular $|E(s',\Bz)|>0$, so since Boundary Reductions do not apply to $s'$, we have $E(s',\Az)=\emptyset$ and hence $|E(s',\Bz)|=p$.

\begin{figure}[H]
	\centering
	\clearpage{}\begin{tikzpicture}[scale=1.1]

\draw[Bs] plot [smooth,tension=1.4] coordinates {(-2,2.2) (-0.1,1.05) (2,2.2)} to (-2,2.2);
\draw[As] plot [smooth,tension=0.5] coordinates {(-2,0) (-1.5,0.4) (-1.3,1.4) (-0.8,2) (0.8,2) (1.3,1.4) (1.5,0.4) (2,0)} to (-2,0);

\Azero;
\begin{scope}[shift={(0,2.2)}] \Bzero; \node at (1,0.17) {$\Bz$}; \end{scope}
\node at (1,-0.2) {$\Az$};
\node[ABT,label=30:$\mathbf{s}$] (s) at (0.6,1.4) {};
\node[AB, label=170:$\mathbf{s'}$] (sp) at (-0.6,1.4) {};
\node[A, label=0:$\mathbf{a}$] (a) at (-0.6,0.6) {};
\node (t) at (2,1.4) {};
\draw[term] (s) to[term] (t);
\draw (s) to (sp);
\draw (sp) to [bend left=15] (a);
\draw (sp) to [bend right=15] (a);
\node at (-0.37,1) {$p$};

\draw (sp) to (-0.33,2.3);
\draw (sp) to (-0.55,2.3);
\node at (-0.28,1.8) {$p$};
\draw (a) to (-0.11,-0.1);
\draw (a) to (-0.33,-0.15);
\draw (a) to (-0.55,-0.15);
\draw (a) to (-0.77,-0.1);
\node at (-0.44,-0.25) {$p+x$};

\draw (a) to (-1.7,0.5);
\draw (a) to (-1.7,0.65);
\draw (a) to (-1.6,0.8);
\node at (-1.85,0.95) {$x+1$};

\end{tikzpicture}
\figspace
\clearpage{}
	\caption{Case (1,0)(a): $(\Delta(A_s),\Delta(B_s))=(\Delta(\Atr),\Delta(\Btr))=(1,0)$. Extensions $A_s, B_s$ are highlighted.}
\label{fig:case-10-a}
\end{figure}

Consider now case $x=0$. Then $a$ has a unique edge $aa'$ with $a'\in R$. Consider first the case when $a'$ is a terminal, so in particular $aa'$ is the only edge incident to $a'$. If $a'=t$, then it is easy to see that $(\Az\cup \{a,t\},\Bz\cup \{s',s\})$ would be an extension of $(\Az,\Bz)$ of the same cost, which contradicts the maximality of $(\Az,\Bz)$. However, if $a'$ belonged to some other pair $\{a',a''\}\in \terms'$, then terminal separation $(A_s\cup \{a'\},B_t\cup \{a''\})$ would have the same cost as $(A_s,B_t)$, which contradicts the maximality of $(A_s,B_t)$. In either case we obtain a contradiction, which means that $a'$ is a nonterminal.

We claim that it is a safe reduction to contract the edge $aa'$; to prove this claim, it suffices to show that there exists an optimum integral terminal separation extending $(\Az,\Bz)$ where $a$ and $a'$ belong to the same side. Take any such integral terminal separation $(\Aopt,\Bopt)$, and assume that $a$ and $a'$ are on opposite sides. Clearly it cannot happen that $a\in \Bopt$ and $a'\in \Aopt$, because then moving $a$ from $\Bopt$ to $\Aopt$ would decrease the cost of the separation. Hence $a\in \Aopt$ and $a'\in \Bopt$. If $s'\in \Bopt$, then moving $a$ from $\Aopt$ to $\Bopt$ would decrease the cost of the separation, so also $s'\in \Aopt$. Construct a new integral separation $(\Aopt_m,\Bopt_m)$ from $(\Aopt,\Bopt)$ by moving $\{a,s'\}$ from $\Aopt$ to $\Bopt$. Then the cost of $(\Aopt_m,\Bopt_m)$ is not larger than that of $(\Aopt,\Bopt)$ (we could have broken the edge $s's$ instead of $aa'$), while both endpoints of $aa'$ belong to $\Aopt_m$.

This reasoning proves the correctness of the following step.
\begin{reductionstep}
Suppose $x=0$ and let $a'$ be the unique neighbor of $a$ in $R$; then $a'$ is a non-terminal. Merge $a$ with $a'$ and restart.
\end{reductionstep}











Henceforth we assume that $x>0$. We claim that now branching on the membership of $a$ leads to a good branch. More precisely, we perform the following branching.

\begin{branching}
If $x\geq 1$, recurse into two branches $(A_{a\to A},B_{a\to A})$ and $(A_{a\to B},B_{a\to B})$ that are minimum-cost maximal terminal separations extending $(\Az\cup \{a\},\Bz)$ and $(\Az,\Bz\cup \{a\})$, respectively.
\end{branching}

Of course, $(A_{a\to A},B_{a\to A})$ and $(A_{a\to B},B_{a\to B})$ are computed using the algorithm of Theorem~\ref{thm:ptime} in time $\Oh(k^{\Oh(1)} m)$. We are left with proving that after applying all the immediate reductions in each branch, we arrive at a good branching vector. For $X\in \{A,B\}$, let $t_{a\to X},\nu_{a\to X},k_{a\to X}$ be the changes of the components of the potential in respective branches, as we denote them in branching vectors.

Consider first the branch $(A_{a\to A},B_{a\to A})$. Then $p$ Boundary Reductions are triggered on vertex $s'$ (regardless of whether it is added or not to one of the sets $A_{a\to A},B_{a\to A}$). Hence $k_{a\to A}\geq p$. Moreover, the terminal pair $\{s,t\}$ either is already resolved by $(A_{a\to A},B_{a\to A})$ or gets reduced by the Lonely Terminal Reduction after applying the Boundary Reductions. Hence $t_{a\to A}\geq 1$. Finally, since $(\Az,\Bz)$ was maximal, we have that $\nu_{a\to A}\geq 1$. So the part of the branching vector corresponding to the branch $(A_{a\to A},B_{a\to A})$ is $[1,1,p]$, or better.

Consider now the second branch $(A_{a\to B},B_{a\to B})$. Then at least $|E(a,\Az)|=p+x$ Boundary Reductions are triggered, hence $k_{a\to B}\geq p+x$. Since $p\geq 1$ and $t$ is of degree $1$, $s'\in B_{a\to B}$ and without loss of generality we can assume $s\in B_{a\to B}$ and $t\in A_{a\to B}$. Hence $t_{a\to B}\geq 1$. If actually $t_{a\to A}\geq 2$ or $t_{a\to B}\geq 2$, then we arrive at a branching vector $[1,1,p;2,1,p]$ or better, which is good, so assume that $t_{a\to A}=t_{a\to B}=1$, that is, only the pair $\{s,t\}$ gets resolved.

We now claim that $\Delta(A_{a\to B})\geq 1$ and $\Delta(B_{a\to B})\geq 1$. The latter claim follows from Assumption~\ref{ass:pushing}, since then $B_{a\to B}$ contains only $s$ among the terminals (due to $t_{a\to B}=1$) and $a\in B_{a\to B}\setminus B_s$. For the former claim, suppose for the sake of contradiction that $d(A_{a\to B})=d(\Az)$. Recall that also $d(B_s)=d(\Bz)$, which means that $d(A_{a\to B})+d(B_s)=c(\Az,\Bz)$. From the posimodularity of cuts it now follows that one of the terminal separations $(A_{a\to B}\setminus B_s,B_s)$ and $(A_{a\to B},B_s \setminus A_{a\to B})$ has cost not larger than $(\Az,\Bz)$, while both of them resolve the terminal pair $\{s,t\}$. This is a contradiction with the maximality of $(\Az,\Bz)$. Hence we infer that $\Delta(A_{a\to B})\geq 1$ and $\Delta(B_{a\to B})\geq 1$, and so $\nu_{a\to B}\geq 2$.

Thus, branching into separations $(A_{a\to A},B_{a\to A})$ and $(A_{a\to B},B_{a\to B})$ leads to a branching vector $[1,1,p;1,2,p+x]$ or better. Recalling that $p,x>0$, observe that this branching vector can be not good only if $p=x=1$ and $\Delta(B_{a\to B})=1$. Hence, from now on let us analyze this case.

Since $\Delta(B_{a\to B})=1$, we have that $B_{a\to B}\setminus \{s\}$ is a terminal-free set of excess $2$, and hence we can apply Lemma~\ref{lem:ex2-red} to it: We have that $B_{a\to B}\setminus \{s\}$ has a decomposition of the form $\{c_1,c_2\}$ or $\{d,c_1,\ldots,c_r\}$. Note that $\Bz\cup \{s'\}$ is an excess-1 set, so $s'=c_i$ for some $i$. As $a\in B_{a\to B}$, $a$ is adjacent to $s'$, and $c_i$-s are pairwise non-adjacent, we must have that $a=d$ and we are dealing with a decomposition of the form $\{d,c_1,\ldots,c_r\}$. Observe that $\Bz\cup \{a,s'\}$ is a $\Bz$-extension of excess at least $1+x+1=3$; hence $B_{a\to B}\supsetneq \Bz \cup \{a,s',s\}$, and in particular $r>1$. Hence there exists some vertex $c_j\neq c_i=s'$. By Lemma~\ref{lem:ex2-red} we have that $c_j$ is adjacent both to $\Bz$ and to $a$. Hence, in the branch $(A_{a\to A},B_{a\to A})$ at least one Boundary Reduction is applied to $c_j$, regardless whether $c_j$ is assigned to $A_{a\to A}$, or $B_{a\to A}$, or neither of these sets. We did not include this Boundary Reduction in the previous calculations; this shows that we in fact pursue a branch with a branching vector $[1,1,2;1,2,2]$ or better, which is a good branching vector.









\subsubsection{Subcase (b): $(\Delta(\Atr),\Delta(\Btr))=(0,1)$}

By the equality condition in~\eqref{eq:truncs} we have that $\Atr=\Az$, while $\Btr\supsetneq \Bz$ is a terminal-free set of excess $1$. By the inapplicability of the Excess-1 Reduction, we infer that $\Btr=\Bz\cup \{b\}$ for some nonterminal vertex $b$. In particular $B_s\supsetneq\Bz\cup \{s\}$, so by Lemma~\ref{lem:AsConn} the unique neighbor $s'$ of $s$ belongs to $B_s$. Since $\Delta(B_s)=0$, we have that $B_s\setminus \{s\}$ is a terminal-free set of excess $1$, so it consists of a single vertex. However, this set already contains $b$. Hence we infer that $b=s'$ is the unique neighbor of $s$, $\Btr=\{s'\}\cup \Bz$, $B_s=\{s,s'\}\cup \Bz$. In particular $s'\notin A_s$, so by Lemma~\ref{lem:AsConn} it follows that $A_s=\Az \cup \{s\}$.

Let $x=|E(s',\Bz)|$. Since $\Delta(B_s)=0$, we also have $x=|E(s',V(G)\setminus B_s)|$. If $x=0$ then $s'$ would be only adjacent to $s$ and thus reducible by the Pendant Reduction. Hence, $x>0$. In particular, we infer that $E(s',\Az)=\emptyset$, since otherwise the Boundary Reduction could be applied to $s'$.














Let us now examine two possible branching steps. Firstly, consider just branching into two branches $(A_s,B_t)$ and $(A_t,B_s)$. In both cases, only one terminal pair $\{s,t\}$ gets resolved. In branch $(A_t,B_s)$, when $s$ is assigned to $B$, we pessimistically have no Boundary Reduction and no increase in the cost of the separation. In branch $(A_s,B_t)$, however, when $s$ is assigned to $A$, we have that $\Delta(A_s)=1$ and one Boundary Reduction is triggered on vertex $s'$ due to having both an edge to $s$ and to $\Bz$.

We now investigate the components of the branching vector when branching on $\{s,t\}$ with fixing $ss'$. If in one of the branches at least one more terminal pair gets resolved, then as argued in the beginning of this section we can just pursue the branching step, because it leads to a good branching vector. Hence, assume from now on that in both branches only the pair $\{s,t\}$ gets resolved. Since $A_s=\{s\}\cup \Az$ and $A_{ss'\to A}$ contains only $s$ among the terminals of $\terms'$, by Assumption~\ref{ass:pushing} we have that $\Delta(A_{ss'\to A})\geq 2$. Also, at least one Boundary Reduction is triggered on an edge between $s'$ and $\Bz$. In branch $(A_{ss'\to B},B_{ss'\to B})$, again we pessimistically have no Boundary Reduction and no increase in the cost of the separation.

\begin{figure}[H]
	\centering
	\clearpage{}\begin{tikzpicture}

\draw[Bs] plot [smooth,tension=0.6] coordinates {(-2,2) (-1.5,1.6) (-1.1,0.7) (-0.5,0.2) (0.5,0.2) (1.2,0.7) (1.5,1.6) (2,2)} to (-2,2);
\draw[As] plot [smooth,tension=1.3] coordinates {(-2,0) (-0.1,0.95) (2,0)} to (-2,0);

\Azero;
\node at (1,-0.2) {$\Az$};
\begin{scope}[shift={(0,2)}] \Bzero; \node at (1,0.17) {$\Bz$}; \end{scope}

\node[ABT,label=180:$\mathbf{s}$] (s) at (0.6,0.5) {};
\node[B, label=0:$\mathbf{s'=b}$] (sp) at (-0.6,1.3) {};
\node (t) at (2,0.6) {};
\draw[term] (s) to[term] (t);
\draw (s) to (sp);
\draw (sp) to (-0.33,2.1);
\draw (sp) to (-0.55,2.1);
\draw (sp) to (-0.77,2.1);
\node at (-0.45,2.2) {$x$};

\draw (sp) to (-1.7,0.65);
\draw (sp) to (-1.75,0.8);
\draw (sp) to (-1.7,0.99);
\node at (-1.9,0.8) {$x$};



\begin{scope}[shift={(6,0)}]

\Azero;
\node at (1,-0.2) {$\Az$};

\node[T,label=180:$\mathbf{s}$] (s) at (0.6,1.5) {};
\node[V, label=0:$\mathbf{s'}$] (sp) at (-0.6,0.7) {};
\node (t) at (2,1.4) {};
\draw[term] (s) to[term] (t);
\draw (s) to (sp);

\draw (sp) to (-0.3,-0.1);
\draw (sp) to (-0.66,-0.1);
\node at (-0.45,-0.25) {$x$};

\draw (sp) to (-1.7,0.65);
\draw (sp) to (-1.7,0.99);
\node at (-1.9,0.8) {$x$};

\end{scope}

\end{tikzpicture}
\figspace
\clearpage{}
	\caption{Case (1,0)(b): $(\Delta(\Atr),\Delta(\Btr))=(0,1)$. This gives rise to an \emph{antenna}, which has to be analyzed together with the other terminal.
	The right side shows an antenna with natural side $\Az$; note the definition does not mention $A_s, B_s$, it only relies on the behaviour of extensions containing $s$ or $s'$.}
\label{fig:case-10-b-antenna}
\end{figure}

A terminal $s$ with the behaviour as described above will be actually the most problematic case for our branching algorithm. Let us define this setting formally.
\begin{definition}
A terminal $s$ is called an {\em{antenna}} if the following conditions hold:
\begin{itemize}
\item The only neighbor $s'$ of $s$ is a nonterminal, has $x>0$ edges to one of the sets $\Az$ or $\Bz$, no edge to the second one, and $x$ edges to $V(G)\setminus (\Az\cup\Bz\cup \{s\})$. The side $S\in \{\Az,\Bz\}$ to which $s'$ is adjacent is called the {\em{natural}} side of $s$, and the second one is called the {\em{unnatural}} side of $s$.
\item Let $S$ and $\overline{S}$ be the natural and unnatural side of $s$, respectively. Then 
\begin{itemize}
\item For any $X$ with $S\cup \{s,s'\} \subsetneq X \subseteq V(G)\setminus \overline{S}$ that contains only $s$ among the terminals from $\terms'$, it holds that $\Delta(X)\geq 1$.
\item For any $Y$ with $\overline{S}\cup \{s\}\subseteq Y\subseteq V(G)\setminus S$ that contains only $s$ among the terminals from $\terms'$, it holds that $\Delta(Y)\geq 1$. If moreover $Y$ contains at least one more vertex than $\overline{S}\cup \{s\}$, then $\Delta(Y)\geq 2$.
\end{itemize}
\end{itemize}
\end{definition}

The discussion above together with Lemmas~\ref{lem:lb} and Assumption~\ref{ass:pushing} shows that in this case $s$ is an antenna with natural side $\Bz$. Obviously, in the symmetric subcase when $(\Delta(A_s),\Delta(B_s))=(0,1)$ and $(\Delta(\Atr),\Delta(\Btr))=(1,0)$ we obtain that $s$ is an antenna with natural side $\Az$. 

The idea now is {\em{not}} to perform any branching step on an antenna, but rather to branch on the situation around the second terminal $t$, i.e., swap the roles of $t$ and $s$ and restart the analysis.
In other words, we will show that if the analysis of the second terminal $t$ does not reveal that it is an antenna (it conforms to cases $(0,0)$, $(1,0)a$, or $(1,1)$), then a branching step leading to a good branching vector can be found on that side. We will be thus left with the case when both $s$ and $t$ are antennas, which we aim to resolve now by exposing a branching strategy leading to a good branching vector.

Therefore, assume that $s$ and $t$ are both antennas, and let $s'$ and $t'$ be their unique neighbors, respectively. By the inapplicability of the Common Neighbor Reduction, $s' \neq t'$. First, suppose that $s$ and $t$ have different natural sides, say $s$ has natural side $\Az$ and $t$ has natural side $\Bz$. However, then $(\Az\cup \{s,s'\},\Bz\cup \{t,t'\})$ would be a terminal separation that has the same cost as $(\Az,\Bz)$, which contradicts the maximality of $(\Az,\Bz)$.

Hence, assume that $s$ and $t$ have the same natural side. W.l.o.g. suppose that it is $\Bz$. Let $x=|E(s',\Bz)|$ and $y=|E(t',\Bz)|$; recall that $x,y\geq 1$. Consider two possible branching steps: we can branch on $\{s,t\}$ with fixing $ss'$ or with fixing $tt'$. Consider first fixing edge $ss'$, and let $(A_{ss'\to A},B_{ss'\to A})$ and $(A_{ss'\to B},B_{ss'\to B})$ be the branches. By the definition of the antenna we have that $\Delta(A_{ss'\to A})\geq 2$ and $\Delta(A_{ss'\to B})\geq 1$. Also, in branch $(A_{ss'\to A},B_{ss'\to A})$ we have at least $x$ Boundary Reductions triggered on edges incident to $s'$, whereas in branch $(A_{ss'\to B},B_{ss'\to B})$ we have at least one Boundary Reduction triggered edges incident to $t'$. Thus we obtain a branching vector $[1,2,x;1,1,1]$ or better, and a symmetric reasoning for fixing $tt'$ leads to branching vector $[1,1,1;1,2,y]$, or better. Note that one of these vectors is good if $\max(x,y)\geq 3$.
Furthermore, such a branching also leads to a good vector if $s'$ or $t'$ is adjacent to some terminal other than $s$ or $t$, respectively,
  as then in at least one branch a second terminal pair would be resolved.
Hence, if this is the case, we pursue the respective branching step.

\begin{branching}
If $\max(x,y)\geq 3$, or there is a terminal in $\terms'$ different than $s$ or $t$ adjacent to $s'$ or $t'$,
then pursue branching on $\{s,t\}$ with fixing the respective edge $ss'$ or $tt'$.
\end{branching}

From now on we assume that $x,y\leq 2$ and that no other terminal than $s$ and $t$ is adjacent to $s'$ nor $t'$.

\begin{figure}[H]
	\centering
	\clearpage{}\begin{tikzpicture}

\begin{scope}[xscale=1.3]
	\Azero; \node at (1,-0.2) {$\Az$};
	\begin{scope}[shift={(0,2)}]
		\Bzero; 
	\end{scope}
\end{scope}

\node[T,label=90:$\mathbf{s}$] (s) at (-0.6,0.5) {};
\node[V, label=0:$\mathbf{s'}$] (sp) at (-1.6,1.3) {};
\node[T,label=90:$\mathbf{t}$] (t) at (0.6,0.5) {};
\node[V, label=180:$\mathbf{t'}$] (tp) at (1.6,1.3) {};

\draw[term] (s) to[term] (t);
\draw (s) to (sp);
\draw (t) to (tp);

\draw (sp) to (-1.4,2.1);
\draw (sp) to (-1.8,2.1);
\node at (-1.6,2.15) {$x$};
\draw (sp) to (-2.3,0.9);
\draw (sp) to (-2.3,1.2);
\node at (-2.4,1) {$x$};

\draw (tp) to (1.3,2.1);
\draw (tp) to (1.5,2.1);
\node at (1.2,2.15) {$y$};
\draw (tp) to (2.3,1.1);
\draw (tp) to (2.3,0.9);
\node at (2.45,1) {$y$};

\end{tikzpicture}
\figspace
\clearpage{}
	\caption{Case (1,0)(b) on both $s$ and $t$, where furthermore the antennas have the same natural side.}
\label{fig:case-10-b-two-antennas}
\end{figure}


Consider now the case when there is a vertex $a$ such that all edges of $E(s',V(G)\setminus (\Bz\cup \{s\}))$ have $a$ as the endpoint different than $s'$. This encompasses the cases when $x=1$ and when $x=2$ but the considered edges connecting $s'$ with $V(G)\setminus (\Az\cup \{s\})$ have the same second endpoint. We claim that then it is a safe reduction to merge $a$ and $s'$. To prove this claim, we need to show that there exists an optimum integral terminal separation $(\Aopt,\Bopt)$ extending $(\Az,\Bz)$ where $a$ and $s'$ are on the same side. Take any such integral terminal separation $(\Aopt,\Bopt)$, and assume that $a$ and $s'$ are on opposite sides. Clearly it cannot happen that $a\in \Bopt$ and $s'\in \Aopt$, because then moving $s'$ from $\Aopt$ to $\Bopt$ would decrease the cost of the separation. Hence $a\in \Aopt$ and $s'\in \Bopt$. This implies that $s\in\Bopt$, since otherwise we could improve the cost of the separation by moving $s'$ from $\Bopt$ to $\Aopt$. Therefore $t\in \Aopt$. Consider modifying $(\Aopt,\Bopt)$ into $(\Aopt_m,\Bopt_m)$ by 
\begin{itemize}
\item moving $s'$ and $s$ from $\Bopt$ to $\Aopt$, and
\item moving $t$ and $t'$ from $\Aopt$ to $\Bopt$, provided $t'$ was not already included in $\Bopt$.
\end{itemize}
It is easy to see that $(\Aopt_m,\Bopt_m)$ is still an integral terminal separation extending $(\Az,\Bz)$ and its cost is no larger than that of $(\Aopt,\Bopt)$. Hence, it is optimum as well. However, in $(\Aopt_m,\Bopt_m)$ it holds that $s'$ and $a$ are on the same side.

This reasoning and its symmetric version for $t'$ imply the correctness of the following reduction step.
Note that $a$ is not a terminal, as we have already excluded this case in the previous branching step.

\begin{reductionstep}
If $|N(s')\setminus (\Bz\cup \{s\})|=1$, then merge $s'$ with its unique neighbor in $V(G)\setminus (\Bz\cup \{s\})$ and restart. If $|N(t')\setminus (\Bz\cup \{t\})|=1$, then merge $t'$ with its unique neighbor in $V(G)\setminus (\Bz\cup \{t\})$ and restart.
\end{reductionstep}

We are left with the case when $x=y=2$ and both $s'$ and $t'$ have two neighbors outside $\Bz\cup \{s,t\}$; these neighbors will be called {\em{external}}. We claim that then just pursuing branching on $\{s,t\}$ with fixed $ss'$ leads to a good branching vector.

\begin{branching}
If $x=y=2$ and $|N(s')\setminus (\Bz\cup \{s\})|=|N(t')\setminus (\Bz\cup \{t\})|=2$, then pursue branching on $\{s,t\}$ with fixing $ss'$.
\end{branching}

Let the branches be $(A_{ss'\to A},B_{ss'\to A})$ and $(A_{ss'\to B},B_{ss'\to B})$. Recall that $\Delta(A_{ss'\to A})\geq 2$. If actually $\Delta(A_{ss'\to A})\geq 3$, then we would already have a good branching vector $[1,3,2;1,1,1]$ or better, so assume henceforth that $\Delta(A_{ss'\to A})=2$. Consider now set $A'=A_{ss'\to A}\setminus \{s,s'\}$. If $A'$ did not contain both external neighbors of $s'$, then a simple edge count shows that $A'$ would be a terminal-free set of excess at most $-2$ (if it contains no external neighbor of $s'$) or $0$ (if it contains one external neighbor of $s'$). In both cases this is a contradiction with the maximality of $(\Az,\Bz)$. Hence, $A'$ contains both external neighbors of $s'$, and $A'$ is a terminal-free set of excess $2$. By Lemma~\ref{lem:ex2-red}, we can decompose $A'$ as $\{c_1,c_2\}$ or $\{d,c_1,\ldots,c_r\}$. Since $s'$ has two different neighbors in $A'$, at least one of them is $c_i$ for some $i$. However, by Lemma~\ref{lem:ex2-red} each $c_i$ is adjacent to $\Az$, and hence in branch $(A_{ss'\to B},B_{ss'\to B})$ at least one Boundary Reduction is triggered on vertex $c_i$ (regardless whether this vertex is assigned to $A_{ss'\to B}$, or to $B_{ss'\to B}$, or to neither of these sets). In our earlier calculations we did not account for this Boundary Reduction, so in fact we obtain branching vector $[1,2,2;1,1,2]$ or better, which is a good branching vector.











\subsection{Case $(\Delta(A_s),\Delta(B_s))=(1,1)$}

By Lemma~\ref{lem:posi}, we have three non-symmetric subcases:
\begin{itemize}
\item[(a)] $|E(A_s \cap B_s, R)|=1$, $\Atr=\Az$, $\Btr=\Bz$;
\item[(b)] $E(A_s \cap B_s, R) = \emptyset$, $\Delta(\Atr)=\Delta(\Btr)=1$;
\item[(c)] $E(A_s \cap B_s, R) = \emptyset$, $\Delta(\Atr)=0$, $\Delta(\Btr)=2$.
\end{itemize}
The case when $E(A_s \cap B_s, R) = \emptyset$, $\Delta(\Atr)=2$, $\Delta(\Btr)=0$, is symmetric to case (c).

The algorithm proceeds as follows: It investigates every terminal pair $\{s,t\}\in \terms'$, and investigates the case given by this terminal pair when considered as $\{s,t\}$ (i.e., looking from the side of $s$), and when considered as $\{t,s\}$ (i.e., looking from the side of $t$). If in any of these checks, for any terminal pair, case $(0,0)$ or $(1,0)(a)$ is discovered, the algorithm pursues the respective Reduction Step or Branching Step, as described in the previous sections. Otherwise, we can assume the following:
\begin{assumption}\label{ass:cases-left}
Every terminal of $\terms'$ is either an antenna, or investigating the basic branch of the respective terminal pair from its side yields case $(1,1)$ (has {\em{type (1,1)}}).
\end{assumption}
In the following we will use this property heavily in order to be able to reason about the total increase in the cost of the separation, also on the side of the second terminal from the pair we are currently investigating. 

\subsubsection{Case (a): $|E(A_s \cap B_s, R)|=1$, $\Atr=\Az$, $\Btr=\Bz$}



Let $Z=A_s\cap B_s=A_s\setminus \Az=B_s\setminus \Bz$. By Assumption~\ref{ass:small-intersections}, we have that $Z=\{s\}$ or $Z=\{s,s'\}$, where $s'$ is the unique neighbor of $s$. 

Suppose first that $Z=\{s,s'\}$. Let $x=|E(s',\Az)|$ and $y=|E(s',\Bz)|$. Since $|E(s',R)|=|E(Z,R)|=1$ and both $A_s$ and $B_s$ are excess-1 sets, we infer that $x=y$. Consequently it must hold that $x=y=0$, because otherwise the Boundary Reduction would apply to $s'$. Thus, $s'$ is a vertex of degree $2$ with one neighbor $r$ in $R$ and the second being $s$. Then the Pendant Reduction would apply to $X = \{s'\}$, a contradiction.

Therefore, we have that $Z=\{s\}$. Let $s'$ be the unique neighbor of $s$. We pursue branching on the pair $\{s,t\}$ with fixing edge $ss'$, i.e., branch into two subcases $(A_{ss'\to A},B_{ss'\to A})$ and $(A_{ss'\to B},B_{ss'\to B})$ that are minimum-cost terminal separations extending $(\Az\cup \{s,s'\},\Bz\cup \{t\})$ and $(\Az\cup \{t\},\Bz\cup \{s,s'\})$, respectively.

\begin{branching}
Pursue branching on $\{s,t\}$ with fixing $ss'$.
\end{branching}

Obviously, as explained in the beginning of this section, if any of the resulting branches resolves one more terminal pair, then the branching vector is good. Therefore, suppose that in both branches only the pair $\{s,t\}$ gets resolved. By Assumption~\ref{ass:pushing}, we have that $\Delta(A_{ss'\to A})\geq 2$ and $\Delta(B_{ss'\to B})\geq 2$. By Assumption~\ref{ass:cases-left}, terminal $t$ is either of type $(1,1)$ or is an antenna. In the former case, by Lemma~\ref{lem:lb} we have that $\Delta(B_{ss'\to A})\geq 1$ and $\Delta(A_{ss'\to B})\geq 1$. Hence we arrive at branching vector $[1,3,0;1,3,0]$ or better, which is a good branching vector. In the latter case, by the definition of an antenna we have that $\Delta(B_{ss'\to A})\geq 1$ or $\Delta(A_{ss'\to B})\geq 1$, depending on whether $\Az$ or $\Bz$ is natural for $s$. Also, in the same branch where respective inequality holds, one Boundary Reduction gets applied on the unique neighbor of $t$. Thus we arrive at branching vector $[1,2,0;1,3,1]$, or $[1,3,1;1,2,0]$ or better (depending on which side is natural for $t$), which is a good branching vector.





\subsubsection{Case (b): $E(A_s \cap B_s, R) = \emptyset$, $\Delta(\Atr)=\Delta(\Btr)=1$}



Since $\Atr$ and $\Btr$ are terminal-free sets of excess $1$, by the inapplicability of the Excess-1 Reduction we infer that $\Atr = \Az \cup \{a\}$ and $\Btr = \Bz \cup \{b\}$ for some distinct nonterminal vertices $a,b$. In particular, both $A_s\setminus \Az$ and $B_s\setminus \Bz$ contain at least one more vertex than $s$. Hence, by Lemma~\ref{lem:AsConn} we infer that if $s'$ is the unique neighbor of $s$, then $s'\in A_s$ and $s'\in B_s$. From Assumption~\ref{ass:small-intersections} it follows that $A_s\cap B_s=\{s,s'\}$. Hence $A_s \setminus \Az=\{a,s,s'\}$ and $B_s \setminus \Bz=\{b,s,s'\}$.

Since $\Delta(A_s)=1$ and $A_s\neq \Az\cup \{s\}$, we can apply Lemma~\ref{lem:cool} to it and infer that $A_s\setminus \{s\}$ has a decomposition $\{d,c_1\}$ with $s'=d$ and $c_1=a$. Consequently, by Lemma~\ref{lem:ex2-red} we infer that for some $p\geq 1$ and $x\geq 0$, we have $|E(s',a)|=p$, $|E(a,\Az)|=p+x$, and $|E(a,V(G)\setminus A_s)|=x+1$. Also, there is no edge between $a$ and $\Bz$, because then the Boundary Reduction would be applicable to $a$. A symmetric reasoning shows that for some $q\geq 1$ and $y\geq 0$, we have $|E(s',b)|=q$, $|E(b,\Bz)|=q+y$, $|E(b,V(G)\setminus B_s)|=y+1$, and there is no edge between $b$ and $\Az$.

Vertex $s'$ cannot be connected both to $\Az$ and to $\Bz$, because then the Boundary Reduction would be applicable to it. Hence, w.l.o.g. assume that $E(s',\Az)=\emptyset$.
Let $q'=|E(s',\Bz)|$. Since $E(A_s \cap B_s, R) = \emptyset$ and both $A_s$ and $\Az\cup \{a\}$ are sets of excess $1$, we infer that $p=q+q'$.

\begin{figure}[H]
	\centering
	\clearpage{}\begin{tikzpicture}[scale=1.1]

\draw[As] plot [smooth,tension=0.5] coordinates {(-2,0) (-1.5,0.4) (-1.3,1.4) (-0.8,1.7) (0.8,1.7) (1.3,1.4) (1.5,0.4) (2,0)} to (-2,0);
\draw[Bs] plot [smooth,tension=0.5] coordinates {(-2,2.4) (-1.5,2) (-1,0.9) (1,0.9) (1.5,2) (2,2.4)} to (-2,2.4);

\Azero;
\begin{scope}[shift={(0,2.4)}] \Bzero; \node at (1.2,0.15) {$\Bz$}; \end{scope}
\node at (1.2,-0.16) {$\Az$};
\node[ABT,label=30:$\mathbf{s}$] (s) at (0.6,1.2) {};
\node[AB, label=180:$\mathbf{s'}$] (sp) at (-0.6,1.2) {};
\node[A, label=0:$\mathbf{a}$] (a) at (-0.6,0.45) {};
\node[B, label=0:$\mathbf{b}$] (b) at (-0.6,1.95) {};
\node[T, label=10:$\mathbf{t}$] (t) at (2,1.2) {};
\draw[term] (s) to[term] (t);
\draw (s) to (sp);
\draw (t) to[bend left=20] (2.6,1.1) {};
\draw (sp) to [bend left=2] (a);
\draw (sp) to [bend right=20] (a);
\draw (sp) to [bend left=25] (a);
\node at (-0.35,0.8) {$p$};

\draw (sp) to[bend left=15] (b);
\draw (sp) to[bend right=15] (b);
\node at (-0.37,1.52) {$q$};
\draw (sp) to[out=130,in=-90] (-1,2.5);
\node at (-0.85,2.57) {$q'$};

\draw (a) to (-0.11,-0.1);
\draw (a) to (-0.33,-0.15);
\draw (a) to (-0.55,-0.15);
\draw (a) to (-0.77,-0.1);
\node at (-0.44,-0.25) {$p+x$};

\draw (a) to (-1.7,0.55);
\draw (a) to[in=-60,out=160] (-1.9,1);
\node at (-2.1,0.6) {$x+1$};
\draw (b) to (-0.44,2.5);
\draw (b) to (-0.22,2.55);
\draw (b) to (-0.00,2.5);
\node at (-0.1,2.63) {$q+y$};

\draw (b) to (-1.7,1.8);
\draw (b) to[in=60,out=-160] (-1.9,1.3);
\node at (-2.1,1.6) {$y+1$};
\end{tikzpicture}
\figspace
\clearpage{}
	\caption{Case (1,1)(b): $\Delta(B_s)=\Delta(A_s)=\Delta(\Atr)=\Delta(\Btr)=1$. Note the edges counted in $x+1$ and $y+1$ may both include a common edge between $a$ and $b$.}
\label{fig:case-11-b}
\end{figure}

For the sake of further argumentation, we now resolve the case when $t'=a$ or $t'=b$, where $t'$ is the unique neighbor of $t$. Then, Lemma~\ref{lem:no-overlap} and its symmetric variant imply that the pair $\{s,t\}$ can be assigned greedily. More precisely, the following reduction step is correct.

\begin{reductionstep}\label{red:(1,1)b-corner}
If $t'=a$ then assign $s$ to the $B$-side and $t$ to the $A$-side, i.e., proceed with instance $(A_t,B_s)$. If $t'=b$ then assign $s$ to the $A$-side and $t$ to the $B$-side, i.e., proceed with instance $(A_s,B_t)$.
\end{reductionstep}








Henceforth we assume that $t'\neq a$ and $t'\neq b$. Since $A_s=\{a,s,s'\}$ and $B_s=\{b,s,s'\}$, by the inpplicability of Common Neighbor Reduction we infer that $t'\notin A_s$ and $t'\notin B_s$.

The crucial observation now is that we can fix both edges $ss'$ and $tt'$ at the same time.

\begin{lemma}\label{lem:double-fixing}
There exists an optimum integral terminal separation $(\Aopt,\Bopt)$ where either $\{s,s'\}\subseteq \Aopt$ and $\{t,t'\}\subseteq \Bopt$, or $\{s,s'\}\subseteq \Bopt$ and $\{t,t'\}\subseteq \Aopt$.
\end{lemma}
\begin{proof}
Let us take any optimum integral terminal separation $(\Aopt,\Bopt)$. If the condition of the lemma is not satisfied, then swapping the sides of $s$ and $t$ does not change the cost of the separation. Let us then assume that the edge $tt'$ is not cut in the solution. Hence, without loss of generality we assume that $s',t,t'\in \Bopt$ and $s\in \Aopt$; the rest of the reasoning will be independent of the choice we made earlier that there are no edges between $s$ and $\Az$, so we are indeed not losing generality here.

Consider $A=\Aopt\cup A_s$. By the submodularity of cuts we have that
$$d(\Aopt\cap A_s)+d(A)\leq d(\Aopt)+d(A_s).$$
However, we have that $d(A_s)\leq d(\Aopt\cap A_s)$ because otherwise we would be able to replace $A_s$ with $\Aopt\cap A_s$ in separation $(A_s,B_t)$ thus decreasing its cost while preserving the fact that it extends $(\Az\cup \{s\},\Bz\cup \{t\})$. Hence, we infer that $d(\Aopt)\geq d(A)$. Observe that since $A_s\setminus (\Az\cup \{s\})$ is terminal-free, then $(A,V(G)\setminus A)$ is also an integral terminal separation, and its cost is $d(A)\leq d(\Aopt)=c(\Aopt,\Bopt)$. Hence, $(A,V(G)\setminus A)$ is also an optimum integral terminal separation. Since $s'\in A_s$ and $t'\notin A_s$, we infer that edges $ss'$ and $tt'$ are not cut in $(A,V(G)\setminus A)$, as was requested.
\end{proof}

Lemma~\ref{lem:double-fixing} justifies the correctness of branching on $\{s,t\}$ with both $ss'$ and $tt'$ fixed. More precisely, we branch into separations $(A_{ss'\to A},B_{ss'\to A})$ and $(A_{ss'\to B},B_{ss'\to B})$ that are minimum-cost terminal separations extending $(\Az\cup \{s,s'\},\Bz\cup \{t,t\})$ and $(\Az\cup \{t,t'\},\Bz\cup \{s,s'\})$, computed using Theorem~\ref{thm:ptime}. 

\begin{branching}
Pursue branching on $\{s,t\}$ with fixing both $ss'$ and $tt'$.
\end{branching}

As we argued at the beginning of this section, if in any of these branches at least one more terminal pair gets resolved, then we arrive at a good branching vector; hence assume that this is not the case.

By Lemma~\ref{lem:lb} we have that $\Delta(A_{ss'\to A})\geq 1$ and $\Delta(B_{ss'\to B})\geq 1$. Also, in both branches the Boundary Reduction will be applied at least $p$ times: either $p$ times on $a$ (provided $s'$ is assigned to the $B$-side), or $q$ times on $b$ and $q'$ times on edges between $s'$ and $\Bz$ (provided $s'$ is assigned to the $A$-side).

We now calculate the branching vectors when performing this branching.

Suppose first that $t$ is an antenna, then by the definition of the antenna we have that $\Delta(A_{ss'\to B})\geq 2$ or $\Delta(B_{ss'\to A})\geq 2$, depending whether $\Bz$ or $\Az$ is the natural side of $t$. Moreover, in the same branch, one Boundary Reduction is triggered on an edge between $t'$ and the natural side of $t$ in the branch. By $t'\notin A_s\cup B_s$, we know that this Boundary Reduction was not accounted for in the previous calculations. Hence, we obtain branching vector $[1,1,p;1,3,p+1]$, or $[1,3,p+1;1,1,p]$, or better, depending on the natural side of $t$. Since $p\geq 1$, these branching vectors are good.

Suppose now that $t$ is of type $(1,1)$, and moreover that investigation of its situation also leads to the same case (b). Then we have that $\Delta(B_{ss'\to A})\geq 1$ and $\Delta(A_{ss'\to B})\geq 1$ by Lemma~\ref{lem:lb}. Moreover, in both of the branches, at least one Boundary Reduction is triggered that reduces some edge incident to $t'$. It is easy to see that the applicability of this Boundary Reduction could not be spoiled by the application of the $p$ Boundary Reductions on the side of $s$, because $t'\notin A_s\cup B_s$ and $s'$ and $t'$ are assigned to different sides. Thus, we arrive at branching vector $[1,2,p+1;1,2,p+1]$, which is $[1,2,2;1,2,2]$ or better, and hence good.

Finally, we are left with the case when $t$ is of type $(1,1)$, and the investigation of its situation also leads to case (c). Similarly as in the previous paragraph, we have that $\Delta(B_{ss'\to A})\geq 1$ and $\Delta(A_{ss'\to B})\geq 1$. Moreover, as we shall see in the next section, in at least one branch, one additional Boundary Reduction will be triggered that will reduce an edge incident to $t'$. Moreover, the applicability of this Boundary Reduction will not be spoiled by the application of the previous $p$ Boundary Reductions on the side of $s$, for the same reason as in the previous paragraph; that is, $t'\notin A_s\cup B_s$ and $s'$ and $t'$ are assigned to different sides. Hence we arrive at branching vector $[1,2,p+1;1,2,p]$, or $[1,2,p;1,2,p+1]$, or better. All these vectors are good for $p>0$.












\begin{comment}

Now the crucial observation is that even though in our branch we fix edge $tt'$, we can prove that the nonterminal $s'$ will also be assigned to one of the sides.

\begin{lemma}\label{lem:sp-colored}
$s'\in A_{tt'\to A}\cup B_{tt'\to A}$ and $s'\in A_{tt'\to B}\cup B_{tt'\to B}$.
\end{lemma}
\begin{proof}
We prove the second statement, for the first one is symmetric. Suppose, for the sake of contradiction, that $s'\notin A_{tt'\to B}\cup B_{tt'\to B}$. Let $A=A_{tt'\to B}\cup (A_s\setminus B_{tt'\to B})$.

We first prove that $d(A_s\setminus B_{tt'\to B})=d(A_s)$. On one hand, we have that 
\begin{equation}\label{l1}
d(A_s)\leq d(A_s\setminus B_{tt'\to B}),
\end{equation}
because otherwise we could replace $A_s$ with $A_s\setminus B_{tt'\to B}$ in separation $(A_s,B_t)$, which would reduce the cost of the separation, a contradiction with the optimality of $(A_s,B_t)$. Similarly, the optimality of $(A_{tt'\to B},B_{tt'\to B})$ implies that 
\begin{equation}\label{l2}
d(B_{tt'\to B})\leq d(B_{tt'\to B}\setminus A_s).
\end{equation}
This is because otherwise we could replace $B_{tt'\to B}$ with $B_{tt'\to B}\setminus A_s$ in separation $(A_{tt'\to B},B_{tt'\to B})$ and obtain a separation that still extends $(\Az\cup \{s\},\Bz\cup \{t,t'\})$ (due to $t'\notin A_s$) and has strictly smaller cost. However, the posimodularity of cuts implies that
\begin{equation}\label{l3}
d(A_s)+d(B_{tt'\to B})\geq d(A_s\setminus B_{tt'\to B})+d(B_{tt'\to B}\setminus A_s).
\end{equation}
Hence, from \eqref{l1},~\eqref{l2}, and~\eqref{l3} we infer that all the inequalities above are in fact equalities, so in particular $d(A_s\setminus B_{tt'\to B})=d(A_s)$.

Observe that $d(A_{tt'\to B}\cap (A_s\setminus B_{tt'\to B}))\geq d(A_{tt'\to B})$, because otherwise we could replace $A_{tt'\to B}$ with $A_{tt'\to B}\cap (A_s\setminus B_{tt'\to B})$ in the terminal separation $(A_{tt'\to B},B_{tt'\to B})$, thus obtaining a separation of smaller cost, a contradiction with the optimality of $(A_{tt'\to B},B_{tt'\to B})$. From the submodularity of cuts we have that
$$d(A_{tt'\to B}\cap (A_s\setminus B_{tt'\to B}))+d(A)\leq d(A_{tt'\to B})+d(A_s\setminus B_{tt'\to B}),$$
which means that $d(A)\leq d(A_s\setminus B_{tt'\to B})=d(A_s)$. From Lemma~\ref{lem:lb} it follows that $d(A_s)\leq d(A_{tt'\to B})$, so we infer that $d(A)\leq d(A_{tt'\to B})$.

Consider now terminal separation $(A,B_{tt'\to B})$. From its definition it follows that it is indeed a terminal separation, it extends $(A_{tt'\to B},B_{tt'\to B})$, and it has no larger cost because $d(A)\leq d(A_{tt'\to B})$. However, due to $s'\in A_s$ we see that $(A,B_{tt'\to B})$ assigns at least one more nonterminal to one of the sides than $(A_{tt'\to B},B_{tt'\to B})$. This is a contradiction with the maximality of $(A_{tt'\to B},B_{tt'\to B})$.
\end{proof}

From Lemma~\ref{lem:sp-colored} we infer that in both of the branches, the Boundary Reduction will be applied at least $p$ times: either $p$ times on $a$ (provided $s'$ is assigned to the $B$-side), or $q$ times on $b$ and $q'$ times on edges between $s'$ and $\Bz$ (provided $s'$ is assigned to the $A$-side). 

We now calculate the branching vectors when branching on $\{s,t\}$ with $ss'$ fixed. By Lemma~\ref{lem:lb}, we have that $\Delta(B_{tt'\to A})\geq 1$ and $\Delta(A_{tt'\to B})\geq 1$, and $p$ Boundary Reductions are triggered on the side of $s$. 

Suppose first that $t$ is an antenna, then by the definition of the antenna we have that $\Delta(A_{tt'\to A})\geq 2$ or $\Delta(B_{tt'\to B})\geq 2$, depending whether $\Bz$ or $\Az$ is the natural side of $t$. Moreover, one Boundary Reduction is triggered on $t'$, and by $t'\notin A_s\cup B_s$ we know that this Boundary Reduction was not accounted for in the previous calculations. Hence, we obtain branching vector $[1,1,p;1,3,p+1]$, or $[1,3,p+1;1,1,p]$, or better, depending on the natural side of $t$. Since $p\geq 1$, these branching vectors are good.

Suppose now that $t$ is of type $(1,1)$, and moreover that investigation of its situation also leads to the same case (b). Then we have that $\Delta(A_{tt'\to A})\geq 1$ and $\Delta(A_{tt'\to A})\geq 1$ by Lemma~\ref{lem:lb}, and at least one Boundary Reduction is applied in both of the branches on 
\end{comment}

\subsubsection{Case (c): $E(A_s \cap B_s, R) = \emptyset$, $\Atr=\Az$, $\Delta(\Btr)=2$}



Since $\Delta(B_s)=1$, we have that $B_s\setminus \{s\}$ is a terminal-free extension of $\Bz$ of excess $2$ and we can apply Lemma~\ref{lem:cool} to decompose it as $\{d,c_1,c_2,\ldots,c_r\}$, where $d=s'$ is the unique neighbor of $s$. Let $p_i=|E(c_i,s')|$, for $i=1,2,\ldots,r$. Recalling Lemma~\ref{lem:ex2-Bside}, let $\sigma=|E(s',\Bz)|+\sum_{i=1}^r p_i=|E(s',\{c_1,\ldots,c_r\}\cup \Bz)|$ be the number of Boundary Reductions that are immediately triggered within $B_s\setminus \{s\}$ in any branch when $s'$ is assigned to the $A$-side. By Lemma~\ref{lem:ex2-Bside} we have that $\sigma>0$. This justifies the claim that was left in our analysis of Case $(1,1)b$, where we argued for the applicability of one additional Boundary Reduction.

Before we proceed, let us exclude the corner case when $t'=c_i$ for some $i\in \{1,2,\ldots,r\}$, where $t'$ is the unique neighbor of $t$. Lemma~\ref{lem:no-overlap} justifies the correctness of the following reduction step.

\begin{reductionstep}
If $t'=c_i$ for some $i\in \{1,2,\ldots,r\}$, then assign $s$ to the $A$-side and $t$ to the $B$-side, i.e., proceed with instance $(A_s,B_t)$.
\end{reductionstep}

Since $t'\neq s'$ by the inapplicability of the Common Neighbor Reduction, henceforth we can assume that $t'\notin B_s$. 

Since $\Atr=\Az$, by Assumption~\ref{ass:small-intersections} we have two cases: either $A_s \setminus \Az=\{s,s'\}$ or $A_s \setminus \Az=\{s\}$.

\paragraph*{Subcase (c.i): $A_s\setminus \Az=\{s,s'\}$.} 

Let $p=|E(s',\Az)|$. Since $E(A_s \cap B_s, R) = \emptyset$ and $A_s$ has excess $1$, we infer that there are $p+1$ edges from $s'$ to $\Btr=\{c_1,c_2,\ldots,c_r\}\cup \Bz$, and hence $\sigma=p+1$. Observe that $p\geq 1$, because if $p=0$ the $s'$ would be adjacent only to $s$ and to a vertex in $\Btr$, and hence the Pendant Reduction would be applicable to $\{s'\}$. Hence in this case $\sigma\geq 2$.


\begin{figure}[H]
	\centering
	\clearpage{}\begin{tikzpicture}

\draw[Bs] plot [smooth,tension=0.6] coordinates {(-2,2) (-1.5,1.6) (-1.1,0.7) (-0.5,0.2) (0.5,0.2) (1.2,0.7) (1.5,1.6) (2,2)} to (-2,2);
\draw[As] plot [smooth,tension=1.3] coordinates {(-2,0) (-0.1,0.95) (2,0)} to (-2,0);

\Azero;
\node at (1,-0.2) {$\Az$};
\begin{scope}[shift={(0,2)}] \Bzero; \end{scope}

\node[ABT,label=30:$\mathbf{s}$] (s) at (0.6,0.5) {};
\node[AB, label=180:$\mathbf{s'}$] (sp) at (-0.6,0.5) {};
\node[B, label={right:$\mathbf{c_1}$}] (c1) at (-0.8,1.5) {};
\node[B, label=0:$\mathbf{c_2}$] (c3) at (0.5,1.5) {};
\node (t) at (2,0.6) {};
\draw[term] (s) to[term] (t);
\draw (s) to (sp);
\draw (sp) to[bend right=2] (c1);
\draw (sp) to[bend left=15] (c1);
\draw (sp) to[bend right=18] (c1);
\draw (sp) to (c3);


\draw (sp) to (-0.33,-0.1);
\draw (sp) to (-0.55,-0.1);
\draw (sp) to (-0.77,-0.1);
\node at (-0.55,-0.25) {$p$};

\draw (c1) to (-1.0,2.1);
\draw (c1) to (-0.8,2.1);
\draw (c1) to (-0.6,2.1);
\draw (c1) to[bend left] (-2,1);



\draw (c3) to (0.6,2.1);
\draw (c3) to (0.8,2.1);

\draw (c3) to[out=-40,in=180] (1.9,1.2);
\draw (c3) to[out=-30,in=180] (1.9,1.3);



\end{tikzpicture}
\figspace
\clearpage{}
	\caption{Case (1,1)(c.i): $\Atr=\Az, \Delta(\Btr)=1, A_s\cap B_s = \{s,s'\}$. A careful reader might notice that since the excess of $B_s$ is 1, an edge count implies $r=2$.}
\label{fig:case-11-ci}
\end{figure}

Having this structure, it is natural to make the following branching.

\begin{branching}
If $A_s\setminus \Az=\{s,s'\}$, then pursue branching on $\{s,t\}$ with fixing $ss'$.
\end{branching}

Let $(A_{ss'\to A},B_{ss'\to A})$ and $(A_{ss'\to B},B_{ss'\to B})$ be the respective branches, i.e., minimum-cost maximal terminal separations extending $(\Az\cup \{s,s'\},\Bz\cup \{t\})$ and $(\Az\cup \{t\},\Bz\cup \{s,s'\})$, respectively. Of course, if in any of these branches one more terminal pair got resolved, then we have a good branching vector. Assume therefore that this is not the case. In branch $(A_{ss'\to A},B_{ss'\to A})$ from Lemma~\ref{lem:lb} we have that $\Delta(\Az\cup \{s,s'\})\geq 1$ and $\sigma\geq 2$ Boundary Reductions are triggered within $B_s\setminus \{s\}$. In branch $(A_{ss'\to B},B_{ss'\to B})$ we again have that $\Delta(\Bz\cup \{s,s'\})\geq 1$, and $p\geq 1$ Boundary Reduction are triggered for edges between $s'$ and $\Az$.

We now calculate the obtained branching vector depending on whether $t$ is an antenna or is of type $(1,1)$.

If $t$ is an antenna with natural side $\Az$, then in branch $(A_{ss'\to A},B_{ss'\to A})$ we have $\Delta(B_{ss'\to A})\geq 1$ and one Boundary Reduction is triggered on edges incident to $t'$. Since $t'\notin B_s$, it is easy to see that the execution of the $\sigma$ previous Boundary Reductions on the side of $s$ could not spoil the applicability of this Boundary Reduction. In branch $(A_{ss'\to B},B_{ss'\to B})$, we do not account for any gain on the side of $t$. Thus we arrive at branching vector $[1,2,1+\sigma;1,1,p]$, which is $[1,2,3;1,1,1]$ or better, and hence good.

If $t$ is an antenna with natural side $\Bz$, then in branch $(A_{ss'\to A},B_{ss'\to A})$ we do not account for any gain on the side of $t$. However, in branch $(A_{ss'\to B},B_{ss'\to B})$ we have that $\Delta(A_{ss'\to B})\geq 1$ and one Boundary Reduction is triggered on edges incident to $t'$. Since $t'\neq s'$, again it is easy to see that the execution of the $p$ previous Boundary Reductions on the side of $s$ could not spoil the applicability of this Boundary Reduction. Thus we arrive at branching vector $[1,2,\sigma;1,1,1+p]$, which is $[1,2,2;1,1,2]$ or better, and hence good.

Finally, suppose $t$ is of type $(1,1)$. Then by Lemma~\ref{lem:lb} we infer that $\Delta(B_{ss'\to A})\geq 1$ and $\Delta(A_{ss'\to B})\geq 1$. Hence we have a branching vector $[1,2,\sigma;1,2,p]$ or better, which is good because $\sigma\geq 2$ and $p\geq 1$.











\paragraph*{Subcase (c.ii): $A_s\setminus\Az=\{s\}$.}



We again investigate the branch on $\{s,t\}$ with fixing $ss'$; for now we do not state that we indeed perform it, because its execution will take place only if the progress will be large enough. Let $(A_{ss'\to A},B_{ss'\to A})$ and $(A_{ss'\to B},B_{ss'\to B})$ be the respective branches, i.e., minimum-cost maximal terminal separations extending $(\Az\cup \{s,s'\},\Bz\cup \{t\})$ and $(\Az\cup \{t\},\Bz\cup \{s,s'\})$, respectively. Of course, if in any of these branches an additional terminal pair gets resolved, then we already have a good branching vector, so assume henceforth that this is not the case. Since $A_s=\Az\cup \{s\}$, by Assumption~\ref{ass:pushing} we infer that $\Delta(A_{ss'\to A})>\Delta(A_s)=1$, because in $A_{ss'\to A}$ at least one more vertex (namely $s'$) is assigned to the $A$-side. As before, in branch $(A_{ss'\to A},B_{ss'\to A})$ we have that $\sigma\geq 1$ Boundary Reductions are triggered inside $B_s$. In branch $(A_{ss'\to B},B_{ss'\to B})$, by Lemma~\ref{lem:lb} we have that $\Delta(B_{ss'\to B})\geq 1$, and we do not account for any Boundary Reductions.

\begin{figure}[H]
	\centering
	\clearpage{}\begin{tikzpicture}

\draw[Bs] plot [smooth,tension=0.6] coordinates {(-2,2) (-1.5,1.6) (-1.1,0.7) (-0.5,0.2) (0.5,0.2) (1.2,0.7) (1.5,1.6) (2,2)} to (-2,2);
\draw[As] plot [smooth,tension=1.3] coordinates {(-2,0) (-0.1,0.7) (2,0)} to (-2,0);

\Azero;
\node at (1,-0.2) {$\Az$};
\begin{scope}[shift={(0,2)}] \Bzero; \end{scope}

\node[ABT,label=30:$\mathbf{s}$] (s) at (0.3,0.4) {};
\node[B, label=180:$\mathbf{s'}$] (sp) at (-0.3,1) {};
\node[B, label={[label distance=3]left:$\mathbf{c_1}$}] (c1) at (-1.05,1.5) {};
\node[B, label={[label distance=-3]left:$\mathbf{c_2}$}] (c2) at (-0.1,1.5) {};
\node[B, label=0:$\mathbf{c_3}$] (c3) at (0.7,1.5) {};
\node (t) at (2,0.6) {};
\draw[term] (s) to[term] (t);
\draw (s) to (sp);
\draw (sp) to[bend left=10] (c1);
\draw (sp) to[bend right=10] (c1);
\draw (sp) to (c2);
\draw (sp) to[bend left=10] (c3);
\draw (sp) to[bend right=10] (c3);

\draw (sp) to[out=-155,in=0] (-1.8,0.6);

\draw (sp) to (-0.33,-0.1);
\draw (sp) to (-0.55,-0.1);


\draw (c1) to (-1.2,2.1);
\draw (c1) to (-1.0,2.1);
\draw (c1) to[bend left] (-2,1);

\draw (c2) to (-0.1,2.1);
\draw (c2) to[out=-30,in=180] (2,1);

\draw (c3) to (0.55,2.1);
\draw (c3) to (0.77,2.1);
\draw (c3) to (0.99,2.1);

\draw (c3) to[out=-40,in=180] (1.9,1.2);
\draw (c3) to[out=-30,in=180] (1.9,1.3);



\end{tikzpicture}
\figspace
\clearpage{}
	\caption{Case (1,1)(c.ii): $\Atr=\Az, \Delta(\Btr)=1, A_s\cap B_s = \{s\}$.}
\label{fig:case-11-cii}
\end{figure}

Let us now investigate what happens in respective branches on the side of terminal $t$, depending on the type of $t$. Suppose first that $t$ is of type $(1,1)$. Then, by Lemma~\ref{lem:lb} it follows that $\Delta(B_{ss'\to A})\geq 1$ and $\Delta(A_{ss'\to B})\geq 1$, and hence together with the account of the progress on the side of $s$, we obtain a branching vector $[1,3,\sigma;1,2,0]$ or better, which is good because $\sigma\geq 1$.

We are left with the case when $t$ is an antenna, where it can be easily verified that the reasoning as above does not lead to a good branching vector without any deeper analysis. We distinguish two subsubcases, depending on the natural side of $t$.





\paragraph*{Subsubcase (c.ii.A): the natural side of $t$ is $\Az$}

Let $t'$ be the unique neighbor of $t$. Since $t$ is an antenna, there are $x$ edges from $t'$ to $\Az$ and $x$ edges from $t'$ to $V(G)$, for some $x\geq 1$.

\newcommand{\Ant}{A_{\text{nt}}}
\newcommand{\Bnt}{B_{\text{nt}}}
\newcommand{\Aunt}{A_{\text{unt}}}
\newcommand{\Bunt}{B_{\text{unt}}}
\newcommand{\Auntext}{A_{\text{unt}}^{\text{ext}}}
\newcommand{\Buntext}{B_{\text{unt}}^{\text{ext}}}

We now introduce a new type of a branching step that we shall call {\em{skewed branching}}. Namely, we will branch into separations $(\Ant,\Bnt)$ and $(\Aunt,\Bunt)$ that are minimum-cost terminal separations extending $(\Az\cup \{t\},\Bz\cup \{s\})$ and $(\Az\cup \{s,s'\},\Bz\cup \{t,t'\})$, respectively. It is easy to see that this branching step is correct, because there is always an optimum integral separation $(\Aopt,\Bopt)$ extending $(\Az,\Bz)$ where (1) $s\in \Bopt$ and $t\in \Aopt$, or (2) $\{s,s'\}\in \Aopt$ and $\{t,t'\}\in \Bopt$. Namely, if neither the first nor the second property is satisfied, then swapping the sides of $s$ and $t$ does not increase the cost of the separation (because the second property is not satisfied), but it makes the first property satisfied.

The reader should think of the skewed branching in the following way. For terminal $t$, the side $\Az$ is the natural side to be assigned to, whereas for $s$ it is $\Bz$ that is more natural. More precisely, in the branch where we have such assignment, we are not able to reason about any Boundary Reductions being triggered. We do, however, hope for a large decrease in the potential in the opposite branch, where both terminals are assigned to their unnatural sides. Therefore, in this unnatural branch we fix both edges $ss'$ and $tt'$ to maximize the progress measured in the potential function, while in the natural branch we do not fix anything, because this would not lead to any profit in the analysis.

Let us now calculate the branching vector that we obtain when we perform the described skewed branching; of course we assume that no other terminal pair gets resolved in either of the branches, because then we immediately obtain a good branching vector. In branch $(\Ant,\Bnt)$, by Lemma~\ref{lem:lb} we have that $\Delta(\Ant)\geq 0$ and $\Delta(\Bnt)\geq 1$, and we do not account for any applications of the Boundary Reduction. In branch $(\Aunt,\Bunt)$, however, we have $\Delta(\Aunt)\geq 2$ by Assumption~\ref{ass:pushing}, because $A_s=\Az\cup \{s\}$, and $\Delta(\Bunt)\geq 2$, by the definition of an antenna and the fact that $\Bz$ is the unnatural side of $t$. Moreover, in this branch $x\geq 1$ Boundary Reductions are applicable to the edges between $t'$ and $\Az$ and $\sigma\geq 1$ Boundary Reductions are applicable within $B_s$. Since $t'\notin B_s$, these applications do not interfere with each other. Thus, we arrive at a branching vector $[1,1,0;1,4,x+\sigma]$, or better. This branching vector is good unless $x=\sigma=1$. Also, even if $x=\sigma=1$ but $\Delta(\Bunt)\geq 3$, then this leads to branching vector $[1,1,0;1,5,2]$ or better, which is good. Thus, we can state the following branching step.

\begin{branching}
Unless $x=\sigma=1$ and $\Delta(\Bunt)=2$, pursue skewed branching into separations $(\Ant,\Bnt)$ and $(\Aunt,\Bunt)$.
\end{branching}









Henceforth we assume that $x=\sigma=1$ and $\Delta(\Bunt)=2$. Therefore, the degree of $t'$ in $G$ is equal to $3$, and it is adjacent to $t$, one vertex in $\Az$, and one vertex in $V(G)\setminus (\Az\cup \Bz)$ that shall be whence called $v$.

Consider now the branch $(\Aunt,\Bunt)$, and suppose there is some optimum terminal separation $(\Aopt,\Bopt)$ extending $(\Az,\Bz)$ that conforms to this branch, i.e., it also extends $(\Aunt,\Bunt)$. Suppose that $v\in \Aopt$. Then this is clearly a contradiction with the optimality of $(\Aopt,\Bopt)$, because $t'$ has $2$ neighbors in $\Aopt$ and $1$ in $\Bopt$, so moving it from $\Bopt$ to $\Aopt$ would decrease the cost of the separation. Hence we can assign $v$ greedily to the $B$-side. More precisely, instead of $(\Aunt,\Bunt)$ we will from now on consider terminal separation $(\Auntext,\Buntext)$ defined as the minimum-cost terminal separation extending $(\Az\cup \{s,s'\},\Bz\cup \{t,t',v\})$. In case $s'=v$, the reasoning above shows that the branch where $\{s,s'\}$ is assigned to the $A$-side and $\{t,t'\}$ is assigned to the $B$-side cannot lead to an optimum solution, so we can greedily pursue the branch where $s$ and $t$ are assigned to respective natural sides.

\begin{reductionstep}
If $v=s'$, then recurse into terminal separation $(A_t,B_s)$.
\end{reductionstep}

Hence, from now on we assume that $v\neq s'$ and we branch into $(\Ant,\Bnt)$ and $(\Auntext,\Buntext)$, where the latter is defined as above. As usual, we assume that $(\Auntext,\Buntext)$ does not resolve any new terminal pair, because then we would have a good branching vector. The same reasoning as for $(\Aunt,\Bunt)$ shows that $\Delta(\Auntext)\geq 2$ and $\Delta(\Buntext)\geq 2$. As before, if we had that $\Delta(\Buntext)\geq 3$, then branching into $(\Ant,\Bnt)$ and $(\Auntext,\Buntext)$ would lead to a branching vector $[1,1,0;1,5,2]$ or better. Hence, we can again assume that $\Delta(\Buntext)=2$.

Therefore, a straightforward edge count shows that $B_q=\Buntext\setminus \{t,t'\}$ is a terminal-free $\Bz$-extension of excess $2$. Hence, we can apply Lemma~\ref{lem:ex2-red} to decompose it. By the inapplicability of the Excess-2 Reduction, we have that $B_q\setminus \Bz$ has a decomposition of the form $\{c_1,c_2\}$ or $\{d,c_1,\ldots,c_r\}$ (from now on we drop the earlier notation for the decomposition of $B_s\setminus (\Bz\cup \{s\})$, and use the notation $d,c_1,\ldots,c_r$ for the decomposition of $B_q\setminus \Bz$). Suppose first that $v=c_i$ for some $i$. Then this is a contradiction with the optimality of $(\Auntext,\Buntext)$, because then $\{t,t',c_i\}$ would be a set of excess $1$, so replacing $\Buntext$ with it would decrease the cost of separation $(\Auntext,\Buntext)$. Therefore, $B_q$ has a decomposition of the form $\{d,c_1,\ldots,c_r\}$ where $v=d$. 

By Lemma~\ref{lem:ex2-red}, we have that $|E(v,c_i)|=p_i$, $|E(c_i,\Bz)|=p_i+x_i$ and $|E(c_i,V(G)\setminus B_q)|=x_i+1$, for some integers $p_i\geq 1$ and $x_i\geq 0$. Let $\sigma_2=|E(v,\Bz)|+\sum_{i=1}^r p_i$ be the number of Boundary Reductions triggered within $B_q$ when the vertex $v$ is assigned to the $A$-side. By Lemma~\ref{lem:ex2-Bside}, $\sigma_2\geq 1$.

Before we proceed, we need to resolve a corner case when $s'\in B_q$. We claim that then it is safe to greedily assign $t$ to the $A$-side and $s$ to the $B$-side.

\begin{reductionstep}\label{rdstep:corner2}
If $s'\in B_q$, then recurse with terminal separation $(A_t,B_s)$.
\end{reductionstep}

To argue the correctness of this reduction step, we need to prove that there exists an optimum terminal separation extending $(\Az,\Bz)$ where $s$ is assigned to the $B$-side and $t$ is assigned to the $A$-side. Let us take any optimum terminal separation $(\Aopt,\Bopt)$
that satisfies point 1 of Lemma~\ref{lem:ex2}.
Assume $s\in \Aopt$ and $t\in \Bopt$, as otherwise we are done.
We can further assume that $s'\in \Aopt$ and $t'\in \Bopt$, because otherwise switching the sides of $s$ and $t$ would not increase the cost of the separation, however it would make it satisfy the condition we seek.
Suppose first that $s'=v$; then we have an immediate contradiction, because moving $t'$ from $\Aopt$ to $\Bopt$ would decrease the cost.
Suppose then that $s'=c_i$ for some $i=\{1,2,\ldots,r\}$.
Since $(\Aopt,\Bopt)$ satisfies point 1 of Lemma~\ref{lem:ex2},
we infer that $\Bopt\cap B_q=\Bz$ or $\Bopt\cap B_q=\Bz\cup \{c_j\}$ for some $j\neq i$. In particular, $v\in \Aopt$. This is, however, a contradiction, because moving $t'$ from $\Bopt$ to $\Aopt$ would decrease the cost of the separation. This justifies the correctness of Reduction Step~\ref{rdstep:corner2}.

Whence we assume that $s'\notin B_q$.

\begin{figure}[H]
	\centering
	\clearpage{}\begin{tikzpicture}[yscale=1.1]

\draw[Bs] plot [smooth,tension=0.6] coordinates {(-2.6,2) (-1.1,1.7) (-0,1) (0.5,0.7) (1.1,0.5) (1.7,0.9) (2.3,1.6) (2.6,2)} to (-2.6,2);

\begin{scope}[xscale=1.3]
	\Azero;
	\node at (1,-0.2) {$\Az$};
	\begin{scope}[shift={(0,2)}] \Bzero; \end{scope}
\end{scope}

\node[T,label=-170:$\mathbf{s}$] (s) at (-1.3,0.6) {};
\node[V, label=left:$\mathbf{s'}$] (sp) at (-1.7,1) {};
\node[V] (oldc1) at (-1.7,1.5) {};
\node[T, label=above:$\mathbf{t}$] (t) at (-0.4,0.6) {};
\node[V, label=0:$\mathbf{t'}$] (tp) at (0.2,0.4) {};
\node[B, label=-20:$\mathbf{v}$] (v) at (0.8,0.9) {};
\node[B, label=left:$\mathbf{c_1}$] (c1) at (0.1,1.5) {};
\node[B, label={[label distance=-3]right:$\mathbf{c_2}$}] (c2) at (0.7,1.5) {};
\node[B, label=right:$\mathbf{c_3}$] (c3) at (1.5,1.5) {};

\draw (s) to (sp);
\draw (sp) to (oldc1);
\draw (sp) to[out=-130,in=0] (-2.5,0.6);

\draw (oldc1) to (-1.55,2.1);
\draw (oldc1) to (-1.77,2.1);
\draw (oldc1) to (-1.99,2.1);

\draw (oldc1) to (-2.4,1.6);
\draw (oldc1) to (-2.4,1.5);
\draw (oldc1) to (-2.4,1.4);

\draw[term] (s) to (t);
\draw (t) to (tp);
\draw (tp) to (0.2,-0.1);
\draw (tp) to (v);

\draw (v) to (c1);
\draw (v) to[bend left=15] (c2);
\draw (v) to[bend right=15] (c2);
\draw (v) to (c3);
\draw (v) to[out=170,in=-100] (-0.2,2.1);

\draw (v) to (2.2,0.8);
\draw (v) to (2.2,0.7);
\draw (v) to (2.2,0.6);

\draw (c1) to (0.1,2.1);
\draw (c2) to (0.6,2.1);
\draw (c2) to (0.8,2.1);
\draw (c3) to (1.4,2.1);
\draw (c3) to (1.6,2.1);

\draw (c1) to[out=-25,in=175] (2.4, 1);
\draw (c2) to[out=-25,in=180] (2.4, 1.1);
\draw (c3) to[out=-25,in=180] (2.4, 1.2);
\draw (c3) to[out=-20,in=180] (2.4, 1.3);


\end{tikzpicture}
\figspace
\clearpage{}
	\caption{Case (1,1)(c.ii.A), where furthermore $x=\sigma=1$ and $\Delta(\Bunt)=2$. The set $B_q=\Buntext \setminus\{t,t'\}$ of excess 2 is highlighted in red.}
\label{fig:case-11-ciiA}
\end{figure}

We will now branch on vertex $v$. More precisely, we recurse into branches $(A_{v\to A},B_{v\to A})$ and $(A_{v\to B},B_{v\to B})$, defined as minimum-cost terminal separations extending $(\Az\cup \{v\},\Bz)$ and $(\Az,\Bz\cup \{v\})$, respectively.

\begin{branching}
Pursue branching on $v$, that is, recurse into branches $(A_{v\to A},B_{v\to A})$ and $(A_{v\to B},B_{v\to B})$.
\end{branching}

The remainder of the description of this subcase is devoted to proving that the execution of this branching step leads to a good branching vector.

Consider first branch $(A_{v\to A},B_{v\to A})$. By the optimality of $(A_{v\to A},B_{v\to A})$ we infer that $t'\in A_{v\to A}$, because otherwise assigning it to $A_{v\to A}$, or moving from $B_{v\to A}$ to $A_{v\to A}$, would decrease the cost of the separation. Also, we can assume that $t\in A_{v\to A}$ and $s\in B_{v\to A}$ for the following reason. If this terminal pair was not resolved in $(A_{v\to A},B_{v\to A})$, then assigning $t$ to the $A$-side and $s$ to the $B$-side would not increase the cost of the separation while extending $(A_{v\to A},B_{v\to A})$, a contradiction with the maximality of $(A_{v\to A},B_{v\to A})$. However, if $t\in B_{v\to A}$ and $s\in A_{v\to A}$, then we can modify separation $(A_{v\to A},B_{v\to A})$ by switching the sides of $s$ and $t$, and because $t'\in A_{v\to A}$, then this modification does not increase the cost. 

Hence, in branch $(A_{v\to A},B_{v\to A})$ the terminal pair $\{s,t\}$ gets resolved. Since $\{v,t,t'\}\subseteq A_{v\to A}$ and $\{s\}\subseteq B_{v\to A}$, by Lemma~\ref{lem:lb} and the definition of an antenna we obtain that $\Delta(A_{v\to A})\geq 1$ and $\Delta(B_{v\to A})\geq 1$. Notice also that at least $\sigma_2\geq 1$ Boundary Reductions are triggered within $B_q$.

Consider the second branch $(A_{v\to B},B_{v\to B})$. In it, one Boundary Reduction is triggered on the edges incident to $t'$, and the terminal pair $\{s,t\}$ is either resolved by this branch or is immediately removed by the Lonely Terminal Reduction (possibly preceded by the Pendant Reduction that removes $t'$). Hence, $\{s,t\}$ also gets resolved in this branch.

From now on, we assume that neither of the considered branches resolves any terminal pair other than $\{s,t\}$, because then, as argued at the beginning of this section, we would immediately achieve a good branching vector. With this assumption in mind, we now claim that $\Delta(B_{v\to B})\geq 2$. 

\begin{myclaim}\label{cl:even-if-terminal1}
$\Delta(B_{v\to B})\geq 2$.
\end{myclaim}
\begin{proof}
If $B_{v\to B}$ is a terminal-free extension of $\Bz$, then this follows from Lemma~\ref{lem:ex2-Aside}. We have two cases left to investigate: either $t\in B_{v\to B}$ or $s\in B_{v\to B}$.

In the first case, since $v\in B_{v\to B}$ by the optimality of $(A_{v\to B},B_{v\to B})$ it follows that also $t'\in B_{v\to B}$. But then if $B_{v\to B}$ was an extension of excess at most $1$, then $B_{v\to B}\setminus \{t,t'\}$ would be a terminal-free extension of excess at most $1$, a contradiction with Lemma~\ref{lem:ex2-Aside}.

In the second case, assume for the sake of contradiction that $\Delta(B_{v\to B})=1$ (it cannot happen that $\Delta(B_{v\to B})=0$, because then $(\Az\cup \{t,t'\},B_{v\to B})$ would be an extension of $(\Az,\Bz)$ of the same cost, a contradiction with the maximality of $(\Az,\Bz)$). Then $B_{v\to B}\setminus \{s\}$ is a terminal-free set of excess $2$. Since $v\in B_{v\to B}$, by the optimality of $(A_{v\to B},B_{v\to B})$ we obtain that $c_i\in B_{v\to B}$ for each $i\in \{1,2,\ldots,r\}$, so $B_q\subseteq B_{v\to B}\setminus \{s\}$. 

On the other hand, $s'\in B_{v\to B}$ because $G[B_{v\to B}\setminus \Bz]$ is connected by the same reasoning as in Lemma~\ref{lem:AsConn}. But we are currently working with the assumption that $s'\notin B_q$, so $B_q$ is a strict subset of $B_{v\to B}\setminus \{s\}$. 

Thus, we obtain a contradiction with Lemma~\ref{lem:ex2-nested}. Indeed, from this lemma it follows that $B_q$ consists of two vertices that are adjacent to $\Bz$ and each of them forms an excess-1 extension of $\Bz$, but we know that $v\in B_q$ is the vertex $d$ of the decomposition of $B_q$ and by Lemma~\ref{lem:ex2-red}, $\Delta(\Bz\cup \{v\})>1$.
\end{proof}

We conclude that the considered branching leads to branching vector $[1,2,\sigma_2;1,2,1]$, or better. This vector is good unless $\sigma_2=1$. Also, if in fact $\Delta(A_{v\to A})\geq 3$, then we also arrive at a good branching vector $[1,3,1;1,2,1]$, or better. Hence, from now on assume that $\sigma_2=1$ and $\Delta(A_{v\to A})=2$.

If $\Delta(A_{v\to A})=2$, then $A_{v\to A}\setminus \{t,t'\}$ is a terminal-free extension of $\Az$ of excess $2$. Let us apply Lemma~\ref{lem:ex2-red} to it. Regardless of the form of the decomposition, from Lemma~\ref{lem:ex2-Bside} we infer that in the branch $(A_{v\to B},B_{v\to B})$ at least one Boundary Reduction will be triggered within $A_{v\to A}\setminus \{t,t'\}$. This Boundary Reduction is applied independently of the Boundary Reduction triggered on edges incident to $t'$ that we previously counted in branch $(A_{v\to B},B_{v\to B})$. This gives one additional Boundary Reduction that we did not account for previously, which leads to a good branching vector $[1,2,1;1,2,2]$, or better.









\paragraph*{Subsubcase (c.ii.B): the natural side of $t$ is $\Bz$}

Recall that we investigated the branch $(A_{ss'\to A},B_{ss'\to A})$ and $(A_{ss'\to B},B_{ss'\to B})$, and we concluded that $\Delta(A_{ss'\to A})\geq 2$, $\Delta(B_{ss'\to B})\geq 1$, and $\sigma\geq 1$ Boundary Reductions are triggered inside $B_s$ in branch $(A_{ss'\to A},B_{ss'\to A})$. From the definition of an antenna we have that $\Delta(A_{ss'\to B})\geq 1$ and one Boundary Reduction is triggered on edges incident to $t'$ in branch $(A_{ss'\to B},B_{ss'\to B})$, when $t$ is assigned to the $A$-side. This gives us branching vector $[1,2,\sigma;1,2,1]$ or better, which is good unless $\sigma=1$. 
Also, note that this branching is good if $s'$ is adjacent to a second terminal different than $s$: due to inapplicability
of the Common Neighbor Reduction, this terminal would belong to a second terminal pair that would get resolved
in the branching.
This justifies the execution of the following branching step.

\begin{branching}
If $\sigma > 1$ or $s'$ is adjacent to a second terminal different than $s$,
then recurse into branches $(A_{ss'\to A},B_{ss'\to A})$ and $(A_{ss'\to B},B_{ss'\to B})$.
\end{branching}



Recall that from Lemma~\ref{lem:cool} we obtained a decomposition $\{d,c_1,c_2,\ldots,c_r\}$ of $(B_{s}\setminus \{s\})\setminus \Bz$, where $d=s'$ is the unique neighbor of $s$. By Lemma~\ref{lem:ex2-Bside}, if $\sigma=1$ then we have two cases:
\begin{itemize}
\item either $r=0$ and $s'$ has degree $4$: one edge to $\Bz$, one edge to $s$, and two edges to $V(G)\setminus (\Bz\cup \{s\})$;
\item or $r=1$ and $s'$ has degree $3$: one edge to $c_1$, one edge to $s$, and one edge to $V(G)\setminus (\Bz\cup \{s,c_1\})$. Moreover, $c_1$ is incident exactly on the following edges: $1$ edge to $s'$, $x$ edges to $\Bz$ and $x$ edges to $V(G)\setminus \Bz\cup (\{s,s'\})$, for some $x\geq 1$.
\end{itemize}
Let $y=|E(t',\Bz)|$; then $y\geq 1$. We now investigate the cases separately.






\paragraph*{Subsubsubcase (c.ii.B.1): $r=0$}

We first investigate the possibility of branching on $\{s,t\}$ with fixing $tt'$. That is, we examine branches $(A_{tt'\to B},B_{tt'\to B})$ and $(A_{tt'\to A},B_{tt'\to A})$ that are minimum-cost maximal extensions of $(\Az\cup \{s\},\Bz\cup \{t,t'\})$ and $(\Az\cup \{t,t'\},\Bz\cup \{s\})$, respectively. Of course if any of these branches resolves some terminal pair other than $\{s,t\}$, then we obtain a good branching vector. Hence, assume this is not the case. 

Consider the first branch $(A_{tt'\to B},B_{tt'\to B})$. By Lemma~\ref{lem:lb} we have that $\Delta(A_{tt'\to B})\geq 1$. Also, one Boundary Reduction is triggered on edges incident to $s'$. 

Consider the second branch $(A_{tt'\to A},B_{tt'\to A})$. By the definition of an antenna, we have that $\Delta(A_{tt'\to A})\geq 2$ and by Lemma~\ref{lem:lb} we have that $\Delta(B_{tt'\to A})\geq 1$. Also, $y$ Boundary Reductions are triggered on edges between $t'$ and $\Bz$ in this branch.

This leads to a branching vector $[1,1,1;1,3,y]$ or better, which is good unless $y=1$.
This justifies executing the following step.

\begin{branching}
If $y>1$, then recurse into branches $(A_{tt'\to B},B_{tt'\to B})$ and $(A_{tt'\to A},B_{tt'\to A})$.
\end{branching}

From now on we assume that $y=1$, and, consequently, we have that $t'$ has degree $3$: it neighbors $t$, one vertex in $\Bz$, and one vertex $w$ outside $\Bz\cup \{t\}$. 

We now resolve the corner case when $w=s'$. Then $t'$ is adjacent to $t$, $s'$ and one vertex in $\Bz$, whereas $s'$ is adjacent to $s$, $t'$, one vertex in $\Bz$, and one vertex outside $\Bz\cup \{s,s',t,t'\}$. We claim that we can assign greedily $s$ to the $A$-side and $t$ to the $B$-side. To argue this, take any minimum-cost integral terminal separation $(\Aopt,\Bopt)$ extending $(\Az,\Bz)$, and assume that $s\in \Bopt$ and $t\in \Aopt$. We can further assume that $s'\in \Bopt$ and $t'\in \Aopt$, because otherwise switching the sides of $s$ and $t$ produces an integral terminal separation of no larger cost where $s$ and $t$ are on the sides we aimed for. But then $t'$ has two neighbors in $\Bopt$ and one in $\Aopt$, which is a contradiction with the optimality of $(\Aopt,\Bopt)$ --- moving $t'$ from $\Aopt$ to $\Bopt$ would decrease the cost. This justifies the correctness of the following step.

\begin{figure}[H]
	\centering
	\clearpage{}\begin{tikzpicture}[yscale=0.8,xscale=0.9]



\begin{scope}
	\Azero;
	\node at (1,-0.2) {$\Az$};
	\begin{scope}[shift={(0,2)}] \Bzero; \end{scope}
\end{scope}

\node[T,label=-170:$\mathbf{s}$] (s) at (-0.7,0.6) {};
\node[V, label=left:$\mathbf{w=s'}$] (sp) at (-1.2,1.4) {};
\node[T, label=-0:$\mathbf{t}$] (t) at (0.7,0.6) {};
\node[V, label=0:$\mathbf{t'}$] (tp) at (1.2,1.4) {};

\draw (s) to (sp);
\draw (sp) to (-1.2,2.1);
\draw (sp) to (-2,0.8);

\draw[term] (s) to (t);
\draw (t) to (tp);
\draw (tp) to (1.2,2.1);
\draw (tp) to (sp);


\end{tikzpicture}
\figspace
\clearpage{}
	\caption{Case (1,1)(c.ii.B.1), where furthermore $s'$ is a neighbor of $t'$.}
\label{fig:case-11-ciiB1corner}
\end{figure}

\begin{reductionstep}
If $w=s'$, then recurse into branch $(A_s,B_t)$.
\end{reductionstep}

From now on, we assume that $w\neq s'$.

Suppose now that $|E(w,\Az)|>0$. Then in branch $(A_{tt'\to B},B_{tt'\to B})$ one additional Boundary Reduction is triggered on edges incident to $w$. Since $w\neq s'$, the application of this Boundary Reduction cannot spoil the applicability of the Boundary Reduction on edges incident to $s'$ that we counted in the same branch. This results in branching vector $[1,1,2;1,3,1]$ or better, which is good, so we can do the following.

\begin{branching}
If $|E(w,\Az)|>0$, then recurse into branches $(A_{tt'\to B},B_{tt'\to B})$ and $(A_{tt'\to A},B_{tt'\to A})$.
\end{branching}

Henceforth we assume that $E(w,\Az)=\emptyset$.


\newcommand{\Aext}{A^{\textrm{ext}}_{tt'\to A}}
\newcommand{\Bext}{B^{\textrm{ext}}_{tt'\to A}}

As in Case~(c.ii.A), we argue that in branch $(A_{tt'\to A},B_{tt'\to A})$ we can greedily assign $w$ to the $A$-side. More precisely, instead of $(A_{tt'\to A},B_{tt'\to A})$ we will from now on consider terminal separation $(\Aext,\Bext)$ defined as the minimum-cost terminal separation extending $(\Az\cup \{t,t',w\},\Bz\cup \{s\})$. The argumentation for the correctness of this step is as before: Suppose there is some optimum terminal separation $(\Aopt,\Bopt)$ extending $(\Az,\Bz)$ that conforms to this branch, i.e., it also extends $(A_{tt'\to A},B_{tt'\to A})$. Suppose that $w\in \Bopt$. Then this is clearly a contradiction with the optimality of $(\Aopt,\Bopt)$, because $t'$ has $2$ neighbors in $\Bopt$ and $1$ in $\Aopt$, so moving it from $\Aopt$ to $\Bopt$ would decrease the cost of the separation. 

As usual, $(\Aext,\Bext)$ resolving an additional terminal pair would immediately lead to a good branching vector when branching into $(A_{tt'\to B},B_{tt'\to B})$ and $(\Aext,\Bext)$, so assume this is not the case.

In branch $(\Aext,\Bext)$, by the definition of an antenna, we have that $\Delta(\Aext)\geq 2$ and by Lemma~\ref{lem:lb} we have that $\Delta(\Bext)\geq 1$. Also, a Boundary Reduction is triggered on the edge between $t'$ and $\Bz$ in this branch. Observe that if we in fact had that $\Delta(\Aext)\geq 3$, then branching into $(A_{tt'\to B},B_{tt'\to B})$ and $(\Aext,\Bext)$ results in branching vector $[1,1,1;1,4,1]$ or better, which is good. This justifies the execution of the following.

\begin{branching}
If $\Delta(\Aext)\geq 3$, then recurse into branches $(A_{tt'\to B},B_{tt'\to B})$ and $(\Aext,\Bext)$.
\end{branching}

\begin{figure}[H]
	\centering
	\clearpage{}\begin{tikzpicture}[yscale=-1.1]

\draw[As] plot [smooth,tension=0.5] coordinates {(-2.6,2) (-1.1,1.7) (-0.2,1) (0.3,0.7) (1.1,0.5) (1.6,0.7) (2.3,1.6) (2.6,2)} to (-2.6,2);

\begin{scope}[xscale=1.3,yscale=-1,shift={(0,-2)}]
	\Azero;
	\begin{scope}[shift={(0,2)}] \Bzero; \node at (1,0.2) {$\Bz$}; \end{scope}
\end{scope}

\node[T,label=-100:$\mathbf{s}$] (s) at (-1.3,0.6) {};
\node[V, label=left:$\mathbf{s'}$] (sp) at (-1.7,0.4) {};
\node[T, label=above:$\mathbf{t}$] (t) at (-0.4,0.6) {};
\node[V, label=0:$\mathbf{t'}$] (tp) at (0.2,0.4) {};
\node[A, label=left:$\mathbf{w}$] (v) at (0.8,0.9) {};
\node[A, label=left:$\mathbf{c_1}$] (c1) at (0.1,1.5) {};
\node[A, label={[label distance=-3]-10:$\mathbf{c_2}$}] (c2) at (0.7,1.5) {};
\node[A, label=-10:$\mathbf{c_3}$] (c3) at (1.5,1.5) {};

\draw (s) to (sp);
\draw (sp) to (-1.7,-0.1);
\draw (sp) to (-2.4,0.8);
\draw (sp) to (-2.3,1.1);

\draw[term] (s) to (t);
\draw (t) to (tp);
\draw (tp) to (0.2,-0.1);
\draw (tp) to (v);

\draw (v) to (c1);
\draw (v) to[bend left=15] (c2);
\draw (v) to[bend right=15] (c2);
\draw (v) to (c3);

\draw (v) to (2.2,0.5);
\draw (v) to (2.2,0.7);

\draw (c1) to (0.1,2.1);
\draw (c2) to (0.6,2.1);
\draw (c2) to (0.8,2.1);
\draw (c3) to (1.4,2.1);
\draw (c3) to (1.6,2.1);

\draw (c1) to[out=-25,in=175] (2.4, 1);
\draw (c2) to[out=-25,in=180] (2.4, 1.1);
\draw (c3) to[out=-25,in=180] (2.4, 1.2);
\draw (c3) to[out=-20,in=180] (2.4, 1.3);


\end{tikzpicture}
\figspace
\clearpage{}
	\caption{Case (1,1)(c.ii.B.1), where furthermore $w\neq s'$ and $\Delta(\Aext)=2$. The set $A_q=\Aext\setminus \{t,t'\}$ of excess 2 is highlighted in blue.}
\label{fig:case-11-ciiB1}
\end{figure}

From now on we assume that $\Delta(\Aext)=2$. This means that $A_q=\Aext\setminus \{t,t'\}$ is a terminal-free extension of $\Az$ of excess $2$, and moreover $w\in A_q$. Hence, we can apply Lemma~\ref{lem:ex2-red} to $A_q$ and obtain a decomposition of the form $\{c_1,c_2,\}$ or $\{d,c_1,\ldots,c_r\}$ (we now drop the notation for the decomposition of $B_s$, and use it for the decomposition of $A_q$ instead). By Lemma~\ref{lem:ex2-red}, each $c_i$ is connected with $\Az$ via at least one edge, but we assumed that there is no edge between $w$ and $\Az$. Hence the decomposition has the form $\{d,c_1,\ldots,c_r\}$ and $d=w$. By Lemma~\ref{lem:ex2-Bside}, at least one Boundary Reduction is triggered within $A_q$ in any branch where $w$ is assigned to $B$.

We will pursue branching on vertex $w$.  More precisely, we consider recursing into branches $(A_{w\to A},B_{w\to A})$ and $(A_{w\to B},B_{w\to B})$, defined as minimum-cost terminal separations extending $(\Az\cup \{w\},\Bz)$ and $(\Az,\Bz\cup \{w\})$, respectively.

\begin{branching}
Pursue branching on $w$, that is, recurse into branches $(A_{w\to A},B_{w\to A})$ and $(A_{w\to B},B_{w\to B})$.
\end{branching}

The remainder of this case is devoted to arguing that this branching step leads to a good branching vector.

Consider branch $(A_{w\to A},B_{w\to A})$. Then a Boundary Reduction is triggered on edges incident to $t'$, and consequently the pair $\{s,t\}$ either gets resolved in this branch, or is removed by an application of the Lonely Terminal Reduction (possibly preceded by the Pendant Reduction that removes $t'$). Hence, at least the terminal pair $\{s,t\}$ gets resolved or removed in this branch. 

In branch $(A_{w\to B},B_{w\to B})$ we have that $t'\in B_{w\to B}$ due to the optimality of $(A_{w\to B},B_{w\to B})$. Moreover, we can assume that $t\in B_{w\to B}$ and $s\in A_{w\to B}$ for the following reason. If this terminal pair was not resolved in $(A_{w\to B},B_{w\to B})$, then assigning $t$ to the $B$-side and $s$ to the $A$-side would not increase the cost of the separation while extending $(A_{w\to B},B_{w\to B})$, a contradiction with the maximality of $(A_{w\to B},B_{w\to B})$. However, if $t\in A_{w\to B}$ and $s\in B_{w\to B}$, then we can modify separation $(A_{w\to B},B_{w\to B})$ by switching the sides of $s$ and $t$, and because $t'\in B_{w\to B}$, then this modification does not increase the cost. 

Hence, in both branches, the terminal pair $\{s,t\}$ gets eventually removed. Suppose then that neither $(A_{w\to A},B_{w\to A})$ nor $(A_{w\to B},B_{w\to B})$ resolves another terminal pair, because otherwise we would immediately have a good branching vector. We continue the calculation of the obtained branching vector with this assumption. First, we need an analogue of Claim~\ref{cl:even-if-terminal1}, whose proof is very similar.

\begin{myclaim}\label{cl:even-if-terminal2}
$\Delta(A_{w\to A})\geq 2$.
\end{myclaim}
\begin{proof}
If $A_{w\to A}$ is a terminal-free extension of $\Az$, then this follows from Lemma~\ref{lem:ex2-Aside}. We have two cases left to investigate: either $t\in A_{w\to A}$ or $s\in A_{w\to A}$.

In the first case, since $w\in A_{w\to A}$ by the optimality of $(A_{w\to A},B_{w\to A})$ it follows that also $t'\in A_{w\to A}$. But then if $A_{w\to A}$ was an extension of excess at most $1$, then $A_{w\to A}\setminus \{t,t'\}$ would be a terminal-free extension of excess at most $1$, a contradiction with Lemma~\ref{lem:ex2-Aside}.

In the second case, assume for the sake of contradiction that $\Delta(A_{w\to A})=1$ (it cannot happen that $\Delta(A_{w\to A})=0$, because then $(A_{w\to A},\Bz\cup \{t,t'\},)$ would be an extension of $(\Az,\Bz)$ of the same cost, a contradiction with the maximality of $(\Az,\Bz)$). Then $A_{w\to A}\setminus \{s\}$ is a terminal-free set of excess $2$ that contains $w$. Since $w\in A_{w\to A}$, by the optimality of $(A_{w\to A},B_{w\to A})$ we obtain that $c_i\in A_{w\to A}$ for each $i\in \{1,2,\ldots,r\}$, so $A_q\subseteq A_{w\to A}\setminus \{s\}$. 

On the other hand, $s'\in A_{w\to A}$ because $G[A_{w\to A}\setminus \Az]$ is connected by the same reasoning as in the proof of Lemma~\ref{lem:AsConn}. However, observe that $s'\notin A_q$. Indeed, we are working with the assumption that $s'\neq w$, and moreover $s'\neq c_i$ for each $i=1,2,\ldots,r$ because otherwise the Boundary Reduction would apply to $s'$. Hence $A_q$ is a strict subset of $A_{w\to A}\setminus \{s\}$. 

Thus, we obtain a contradiction with Lemma~\ref{lem:ex2-nested}. Indeed, from this lemma it follows that $A_q$ consists of two vertices that are adjacent to $\Az$, but we know that $w\in A_q$ and $E(w,\Az)=\emptyset$.
\end{proof}

Observe that in branch $(A_{w\to A},B_{w\to A})$ we also have one Boundary Reduction triggered on the edges incident to $t'$.

On the other hand, in branch $(A_{w\to B},B_{w\to B})$ we have $\Delta(A_{w\to B})\geq 1$ by Lemma~\ref{lem:lb} because $s\in A_{w\to B}$. Also, $\Delta(B_{w\to B})\geq 1$ by the definition of an antenna and the fact that $\{w,t,t'\}\subseteq B_{w\to B}$. Finally, one Boundary Reduction is triggered on edges incident to $s'$ and one Boundary Reduction is triggered within $A_q$. Since $s'\neq w$, the application of one of these reductions cannot spoil the applicability of the other.

Thus we obtain branching vector $[1,2,1;1,2,2]$ or better, which is a good branching vector.









\paragraph*{Subsubsubcase (c.ii.B.2): $r=1$.}

Recall that $s'$ has degree $3$ and has one edge to $c_1$, one edge to $s$, and one edge to $V(G)\setminus (\Bz\cup \{s,c_1\})$, whereas $c_1$ has $x$ edges to $\Bz$ and $x$ edges to $V(G)\setminus (\Bz\cup \{s,c_1\})$, for some $x\geq 1$. Let $v$ be the neighbor of $s'$ other than $c_1$ and $s$.

First, note that $v$ is not a terminal, as we have already excluded the case 
when $s'$ is adjacent to a second terminal different than $s$.

We claim that there is an optimum integral terminal separation $(\Aopt,\Bopt)$ extending $(\Az,\Bz)$ where vertices $s'$ and $v$ are assigned to the same side. Take any optimum integral separation $(\Aopt,\Bopt)$ and suppose that $s'$ and $v$ are assigned to different sides.

Assume first that $s'\in \Aopt$ and $v\in \Bopt$. Then $s\in \Aopt$ and $c_1\in \Aopt$ because otherwise moving $s'$ from $\Aopt$ to $\Bopt$ would decrease the cost of the separation. Hence $t\in \Bopt$, and again by the optimality of $(\Aopt,\Bopt)$ we have $t'\in \Bopt$. Consider a modified integral terminal separation $(\Aopt_m,\Bopt_m)$ obtained from $(\Aopt,\Bopt)$ by moving $\{c_1,s'\}$ from the $A$-side to the $B$-side. Recall that $c_1$ has $x$ edges to $\Bz$ and $x$ edges going outside of $\Bz\cup \{c_1,s'\}$. Then it is easy to see that the cost of $(\Aopt_m,\Bopt_m)$ is not larger than the cost of $(\Aopt,\Bopt)$, whereas $s'$ and $v$ are both assigned to the $B$-side.

Assume second that $s'\in \Bopt$ and $v\in \Aopt$. Similarly as before, by the optimality of $(\Aopt,\Bopt)$ we have that $s\in \Bopt$ and $c_1\in \Bopt$. Consequently, $t\in \Aopt$. If we had that $t'\in \Bopt$, then moving $t$ from $\Aopt$ to $\Bopt$ and $\{s,s'\}$ from $\Bopt$ to $\Aopt$ would strictly decrease the cost of the separation, a contradiction with the optimality of $(\Aopt,\Bopt)$. Hence we have that $t'\in \Aopt$. Consider a modified integral terminal separation $(\Aopt_m,\Bopt_m)$ obtained from $(\Aopt,\Bopt)$ by moving $\{s,s'\}$ from the $B$-side to the $A$-side, and moving $\{t,t'\}$ from the $A$-side to the $B$-side. Recall that $t'$ has $y$ edges going to $\Bz$ and $y$ edges going outside of $\Bz\cup \{t,t'\}$. Hence it is easy to see that the cost of $(\Aopt_m,\Bopt_m)$ is not larger than the cost of $(\Aopt,\Bopt)$, whereas $s'$ and $v$ are both assigned to the $A$-side.

This justifies the execution of the following reduction in this case.

\begin{reductionstep}
Merge $s'$ and $v$.
\end{reductionstep}

As the case study is exhaustive, this finishes the description of the branching algorithm. We hope that the reader shares the joy of the writer after getting to this line.




