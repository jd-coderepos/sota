In this section we assume we have a maximal instance  for which none of the previously defined reduction rules is applicable.
Our goal is to find a {\em{branching step}} that fulfils a good vector,
or a set of vertices to merge (a {\em{reduction step}}). Recall that when we consider a branching into terminal separations  and  that extend , then  for  measure respectively the number of terminals resolved in branch , two times the growth of the cost of the separation in branch  (i.e., ), and the decrease in the budget  after applying all the reduction rules when recursing into branch .

Assume that we have identified a branching step into separations
 and  that both extend, but are different than
. Then, from the maximality of  we infer than
.
Since  is a good vector, any branching step
in which in both cases we resolve or reduce at least one terminal pair,
while in at least one case we resolve or reduce at least \emph{two} terminal
pairs, is fine for our purposes. 

\subsection{Basic branching and reductions}

Let  be the set of unresolved terminal pairs (not in ). For every terminal pair , we apply the algorithm of Theorem~\ref{thm:ptime} twice: once for terminal separation , and the second time for terminal separation . In this manner we obtain two maximal terminal separations  and  that extend  and  respectively. Of course, the number of unresolved pairs decreases by at least one in both  and , due to resolving . If the number of unresolved pairs either in  or in  decreases by more than one, then, as we argued, performing a branching step  and  leads to the branching vector  or a better one, which is good. We can test in  time whether this holds for any pair , and if so then we pursue the branching step. 

\begin{branching}\label{br:twopairs}
If in either  or in , more than one terminal pair gets resolved, then perform branching into  and .
\end{branching}

Hence, if this branching step cannot be performed, then we assume the following:

\begin{assumption}\label{ass:one-pair}
For every pair  in both  and  only the pair  gets resolved.
\end{assumption}

We now proceed with some structural observations about the instance at hand.

\begin{lemma}\label{lem:AsConn}
, , ,  are connected.
\end{lemma}
\begin{proof}
We prove the statement for , since the other statements are symmetric. Suppose  is disconnected, and let  be any of its connected component that does not contain . Then  is terminal-free, so by the maximality of  we infer that . But then , which contradicts the optimality of .
\end{proof}

\begin{lemma}\label{lem:lb}
Let , and let  and  be any optimum-cost terminal separations extending  and , respectively. Suppose that  and  do not resolve any terminal pair apart from . Then for any set  with  that has only  among the terminals of , it holds that . Symmetrically, for any set  with  that has only  among the terminals of , it holds that .
\end{lemma}
\begin{proof}
We prove only the first claim for the second one is symmetric. Let  be such a set, and for the sake of contradiction suppose . Then . However, from posimodularity of cuts it follows that either  or . Both  and  are terminal separations that extend , and one of them has strictly smaller cost than . This is a contradiction with the optimality of .
\end{proof}

\subsubsection{Pushing  and }

The problem that we will soon face is that separations  and  are not uniquely defined. For instance, there can be some set of vertices  that could be moved from  to  without changing the cost of the separation. We now make an adjustment of these separations so that we can assume that , resp. , is maximal. For this, we need the following technical results.

\begin{lemma}\label{lem:patch}
Suppose that  and  are maximal terminal separations of minimum cost among separations that extend . Suppose further that they do not resolve any other terminal pair from . Then
\begin{itemize}
\item[(a)]  and ;
\item[(b)]  and  are also terminal separations of minimum cost among separations that extend ;
\item[(c)] .
\end{itemize}
\end{lemma}
\begin{proof}
\noindent (a) Let  be the minimum cost of a terminal separation extending . Suppose w.l.o.g. that , then we have that . By posimodularity, we have that

Observe that  is a terminal separation that extends , and hence 

Symmetrically, by considering terminal separation  we obtain that

Thus, from~\eqref{eq1},~\eqref{eq2}, and~\eqref{eq3} we obtain that

which is a contradiction.

\smallskip

\noindent (b) Observe that , because otherwise  could have been replaced with  in separation . By submodularity of cuts we have that , and hence . By posimodularity, we have that

On the other hand, for terminal separation  we have that

and for terminal separation  we have that

Thus, from~\eqref{eq21},~\eqref{eq22}, and~\eqref{eq23}

which means that all the inequalities above are in fact equalities. In particular:
\begin{itemize}
\item , and 
\item .
\end{itemize} 
Symmetric arguments can be used to show that:
\begin{itemize}
\item , 
\item , 
\item , and
\item .
\end{itemize}
Therefore, both  and  have cost .

\smallskip

\noindent (c) For the sake of contradiction, assume that . Suppose first that there is an element  such that . In the proof of (b) we have showed that . Note that  is a terminal separation that extends , and moreover its left side is has at least one additional element . Since its cost is the same as the cost of , we obtain a contradiction with the maximality of .
\end{proof}

\begin{lemma}\label{lem:pushing}
Let  be the family of all maximal terminal separations  of minimum cost among separations that extend . Suppose that all separations from  resolve only the pair  among the pairs from . Then there exists a unique maximal terminal separation  such that  and  for each . Moreover, if  is such that , , , but , then .
\end{lemma}
\begin{proof}
We set 

From Lemma~\ref{lem:patch} it follows that . 

\newcommand{\oA}{\overline{A}}
\newcommand{\oB}{\overline{B}}

We are left with proving the last statement. Take any such , and suppose for the sake of contradiction that . Let  and . Observe that  is a terminal separation that extends . Since  has at least one more element than , from the properties of  we infer that , where  is the cost of every separation from . Observe that , because otherwise we would substitute  with  in separation  and obtain a separation of smaller cost that extends . Hence, from the submodularity of cuts we infer that , so in particular .

Now, by posimodularity we obtain that

On the other hand, observe that , because otherwise we could substitute  with  in the terminal separation  and obtain a terminal separation that extends  and has strictly smaller cost. Thus we infer that . As , we conclude that , , and hence . This is a contradiction.
\end{proof}

We modify now separation  as follows. For every terminal pair  that is different from , we verify using Theorem~\ref{thm:ptime} whether  can be chosen so that it has a minimum possible cost among the separations that extend , but it also resolves . If this is possible, then we pursue Branching Step~\ref{br:twopairs} with appropriate . Otherwise, every minimum-cost separation extending  resolves only , and the assumptions of Lemma~\ref{lem:pushing} are satisfied.
Let  be the terminal extension whose existence is asserted by Lemma~\ref{lem:pushing}.
Observe that we can construct  in time :
we start with any  given by Theorem~\ref{thm:ptime},
and observe that Lemma~\ref{lem:pushing} implies that  is the unique inclusion-wise maximal set
containing  such that  is a minimum cut between  and ;
such a set can be computed using  rounds of the Ford-Fulkerson algorithm.
  
Hence, we proceed further with the assumption that we have chosen  to be . We do symmetrically in the second branch, assuming that  is chosen to be , that is, the extension of  that contains terminal  is chosen to be maximum possible. Hence, by Lemma~\ref{lem:pushing}, we can from now on use the following assumption.

\begin{assumption}\label{ass:pushing}
For any set  with  that contains only  from the terminals of  and has at least one vertex outside , it holds that . Symmetrically, for any set  with  that contains only  from the terminals of  and has at least one vertex outside , it holds that . 
\end{assumption}

\subsubsection{Analyzing , , and }

Suppose now that for some pair , we have that . Then, by Assumption~\ref{ass:one-pair}  is a terminal-free set. Since pair  has to be resolved one way or the other, then by persistence (Theorem~\ref{thm:persistence}) we infer that there is some minimum integral terminal separation  such that  or . Therefore, it is a safe reduction to merge  into a single vertex.

\begin{reductionstep}
For every , compute  and . Provided  () contains more than one vertex, merge it.
\end{reductionstep}

We apply this reduction to all terminal pairs from , which takes time . Hence, using Lemma~\ref{lem:AsConn} from now on we can assume the following:

\begin{assumption}\label{ass:small-intersections}
For every pair , either  or , where  is the only neighbor of . Moreover, either  or , where  is the only neighbor of .
\end{assumption}

As every terminal has degree one, for a pair  we have that , since otherwise replacing  with  would decrease the cost of . On the other hand, we have that , since otherwise  would be a terminal separation extending  of not larger cost, which would contradict the maximality of . Then, we have three possible cases for : ,  and ; the omitted case  is symmetric to . The algorithm behaves differently in each of these cases. Before we proceed to the description of handling each case separately, we prove some useful observations first.

\newcommand{\Atr}{\tilde{A}}
\newcommand{\Btr}{\tilde{B}}

Let us now fix one pair , and let  and . Observe that since branching on  did not resolve any additional terminal pair, then both  and  are terminal-free. Hence, by the maximality of  we have that

and the equality holds if and only if  or , respectively. Let .

\begin{lemma}\label{lem:posi}
One of the following two cases holds:
\begin{itemize}
\item , , , and ; or
\item , and .
\end{itemize}
\end{lemma}
\begin{proof}
By applying posimodularity of cuts to the sets  and , we obtain:

On the other hand, we have that  and . Hence we have that  and the claimed case distinction follows from~\eqref{eq:truncs} and~\eqref{eq:posi}.
\end{proof}

\subsubsection{Decomposing sets of excess }

Finally, we make a useful observation that will show a generic setting when Lemma~\ref{lem:ex2-red} can be applied.

\begin{lemma}\label{lem:cool}
Suppose  and . Then  is a terminal-free excess-2 set, and  has a decomposition  given by Lemma~\ref{lem:ex2-red}.
Moreover,  is the unique neighbor of  in .
\end{lemma}
\begin{proof}
The fact that  is an excess-2 set follows from the assumption that  has degree exactly  (due to the inapplicability of the Lonely Terminal Reduction), and its unique neighbor  does not belong to 
and does belong to  (because  is connected by Lemma~\ref{lem:AsConn}).
Since  is nonempty and terminal-free (by Assumption~\ref{ass:one-pair}),
it follows from Lemma~\ref{lem:ex2-red} that it has a decomposition of the form  or , where -s are pairwise nonadjacent and  are excess-1 sets. Suppose  for some . Then since  is an excess-1 set, we would have that  is an excess-0 set, and hence  would be an extension of  of strictly smaller cost than , contradicting the definition of . Hence  has a decomposition of the form  and .
\end{proof}

We will need one more lemma that resolves corner cases when we apply Lemma~\ref{lem:cool}.

\begin{lemma}\label{lem:no-overlap}
Suppose  satisfies the conditions of Lemma~\ref{lem:cool}, and let  be the obtained decomposition of . Let  be the unique neighbor of . Then , and if  for some , then there exists an optimum integral terminal separation  that extends  and has  and .
\end{lemma}
\begin{proof}
The fact that  follows from the inapplicability of the Common Neighbour Reduction. Suppose then that . From Lemma~\ref{lem:ex2-red} it follows that for some  and , there are  edges between  and ,  edges between  and , and  edges between  and ; one of these  edges connects  with .

Take any optimum integral separation  extending  and suppose that  and . We can further assume that  and , because otherwise switching the sides of  and  would result in an integral separation of not larger cost that already fulfills the property we aim for. Recall that  has  edges to  (which is assigned to ),  edges to , and  edges to other vertices of the graph. Since , we see that a strict majority of neighbors of  are in . Hence switching the side of  from  to  strictly decreases the cost of the separation, a contradiction.
\end{proof}

Lemma~\ref{lem:no-overlap} enables us to perform a reduction step whenever a corner case appears in the analysis of vertices close to  and . We choose not to perform this reduction exhaustively, but rather to execute it on demand when such a case appears during branching.



\subsubsection{Fixing an edge  or }

In a few cases, we consider an improved branching set,
when in one branch we fix  to belong to the left part and  to belong to the right part, whereas in the second branch we fix vice versa. More precisely, we consider branches  and  that are minimum-cost terminal separations extending  and , computed using Theorem~\ref{thm:ptime}. Observe that there is some optimum solution that extends one of these branches: If in some optimum solution the vertices  and  were assigned to different sides, then we could modify this solution by swapping the sides of  and . After this modification then solution has no larger cost due to  having degree one, whereas the edge  ceases to be cut by the solution. This justifies the correctness of this branching step; we shall henceforth call it {\em{branching on  with fixing the edge }}.
Symmetrically, we can define branching on  with fixing the edge .

\subsection{Case }

We show that this case in fact never happens. From Lemma~\ref{lem:posi} we infer that , , and . Hence, . As we argued earlier, we can assume that  or  for  being the only neighbor of . 

In the first case, since the degree of  is at most one, from  and  we can infer that  is an isolated terminal, which should have been removed by the Lonely Terminal Reduction. This contradicts the assumptions that no reduction rule is applicable.

In the second case, by  and , we infer that  for some . If , then  should have been reduced by the Pendant Reduction. On the other hand, if  then the Boundary Reduction would have been triggered on . In both cases this is a contradiction.

\begin{figure}[H]
	\centering
	\clearpage{}\begin{tikzpicture}

\draw[Bs] plot [smooth,tension=1.3] coordinates {(-2,2)  (0,0.4) (2,2)} to (-2,2);
\draw[As] plot [smooth,tension=1.3] coordinates {(-2,0)  (0,1.6) (2,0)} to (-2,0);

\Azero;
\begin{scope}[shift={(0,2)}] \Bzero; \node at (1,0.17) {}; \end{scope}
\node at (1,-0.2) {};
\node[ABT,label=30:] (s) at (0.1,1) {};
\node[T, label=10:] (t) at (2.4,1) {};
\draw[term] (s) to[term,bend right=10] (t);


\begin{scope}[shift={(7,0)}]

\draw[Bs] plot [smooth,tension=1.9] coordinates {(-2,2)  (0,0.2) (2,2)} to (-2,2);
\draw[As] plot [smooth,tension=1.9] coordinates {(-2,0)  (0,1.8) (2,0)} to (-2,0);

\Azero;
\begin{scope}[shift={(0,2)}] \Bzero; \node at (1,0.17) {}; \end{scope}
\node at (1,-0.2) {};
\node[ABT,label=30:] (s) at (0.6,1) {};
\node[AB, label=180:] (sp) at (-0.6,1) {};
\node[T, label=10:] (t) at (2.4,0.9) {};
\draw[term] (s) to[term,bend right=10] (t);
\draw (s) to (sp);
\draw (sp) to (-0.33,2.15);
\draw (sp) to (-0.55,2.2);
\draw (sp) to (-0.77,2.15);
\node at (-0.23,1.6) {};
\draw (sp) to (-0.33,-0.15);
\draw (sp) to (-0.55,-0.2);
\draw (sp) to (-0.77,-0.15);
\node at (-0.2,0.4) {};

\end{scope}
\end{tikzpicture}
\figspace
\clearpage{}
	\caption{Case  : a reduction is always immediately applicable. Terminal nodes are squares, paired with zig-zags. Extensions  and  are highlighted with light blue and red, respectively.}
\label{fig:case-00}
\end{figure}



\subsection{Case }

From Lemma~\ref{lem:posi} we infer that  and . We have two subcases: either (a) , or (b) .

\subsubsection{Subcase (a): }

By the equality condition in~\eqref{eq:truncs} we have that , while  is a terminal-free set of excess . By the inapplicability of the Excess-1 Reduction, we infer that  for some nonterminal vertex .





Set  satisfies the conditions of Lemma~\ref{lem:cool}, so we can decompose  into , where  is the unique neighbor of . Since , we have that  and hence by Lemma~\ref{lem:AsConn} it follows that . By Assumption~\ref{ass:small-intersections} we infer that  and thus . Therefore  and .

Since , .

By Lemma~\ref{lem:ex2-red} we have that  has:  edges to ,  edges to ,  edges to  and no other edges, for some . 
Since  is an excess-0 set and , we have that . In particular , so since Boundary Reductions do not apply to , we have  and hence .

\begin{figure}[H]
	\centering
	\clearpage{}\begin{tikzpicture}[scale=1.1]

\draw[Bs] plot [smooth,tension=1.4] coordinates {(-2,2.2) (-0.1,1.05) (2,2.2)} to (-2,2.2);
\draw[As] plot [smooth,tension=0.5] coordinates {(-2,0) (-1.5,0.4) (-1.3,1.4) (-0.8,2) (0.8,2) (1.3,1.4) (1.5,0.4) (2,0)} to (-2,0);

\Azero;
\begin{scope}[shift={(0,2.2)}] \Bzero; \node at (1,0.17) {}; \end{scope}
\node at (1,-0.2) {};
\node[ABT,label=30:] (s) at (0.6,1.4) {};
\node[AB, label=170:] (sp) at (-0.6,1.4) {};
\node[A, label=0:] (a) at (-0.6,0.6) {};
\node (t) at (2,1.4) {};
\draw[term] (s) to[term] (t);
\draw (s) to (sp);
\draw (sp) to [bend left=15] (a);
\draw (sp) to [bend right=15] (a);
\node at (-0.37,1) {};

\draw (sp) to (-0.33,2.3);
\draw (sp) to (-0.55,2.3);
\node at (-0.28,1.8) {};
\draw (a) to (-0.11,-0.1);
\draw (a) to (-0.33,-0.15);
\draw (a) to (-0.55,-0.15);
\draw (a) to (-0.77,-0.1);
\node at (-0.44,-0.25) {};

\draw (a) to (-1.7,0.5);
\draw (a) to (-1.7,0.65);
\draw (a) to (-1.6,0.8);
\node at (-1.85,0.95) {};

\end{tikzpicture}
\figspace
\clearpage{}
	\caption{Case (1,0)(a): . Extensions  are highlighted.}
\label{fig:case-10-a}
\end{figure}

Consider now case . Then  has a unique edge  with . Consider first the case when  is a terminal, so in particular  is the only edge incident to . If , then it is easy to see that  would be an extension of  of the same cost, which contradicts the maximality of . However, if  belonged to some other pair , then terminal separation  would have the same cost as , which contradicts the maximality of . In either case we obtain a contradiction, which means that  is a nonterminal.

We claim that it is a safe reduction to contract the edge ; to prove this claim, it suffices to show that there exists an optimum integral terminal separation extending  where  and  belong to the same side. Take any such integral terminal separation , and assume that  and  are on opposite sides. Clearly it cannot happen that  and , because then moving  from  to  would decrease the cost of the separation. Hence  and . If , then moving  from  to  would decrease the cost of the separation, so also . Construct a new integral separation  from  by moving  from  to . Then the cost of  is not larger than that of  (we could have broken the edge  instead of ), while both endpoints of  belong to .

This reasoning proves the correctness of the following step.
\begin{reductionstep}
Suppose  and let  be the unique neighbor of  in ; then  is a non-terminal. Merge  with  and restart.
\end{reductionstep}











Henceforth we assume that . We claim that now branching on the membership of  leads to a good branch. More precisely, we perform the following branching.

\begin{branching}
If , recurse into two branches  and  that are minimum-cost maximal terminal separations extending  and , respectively.
\end{branching}

Of course,  and  are computed using the algorithm of Theorem~\ref{thm:ptime} in time . We are left with proving that after applying all the immediate reductions in each branch, we arrive at a good branching vector. For , let  be the changes of the components of the potential in respective branches, as we denote them in branching vectors.

Consider first the branch . Then  Boundary Reductions are triggered on vertex  (regardless of whether it is added or not to one of the sets ). Hence . Moreover, the terminal pair  either is already resolved by  or gets reduced by the Lonely Terminal Reduction after applying the Boundary Reductions. Hence . Finally, since  was maximal, we have that . So the part of the branching vector corresponding to the branch  is , or better.

Consider now the second branch . Then at least  Boundary Reductions are triggered, hence . Since  and  is of degree ,  and without loss of generality we can assume  and . Hence . If actually  or , then we arrive at a branching vector  or better, which is good, so assume that , that is, only the pair  gets resolved.

We now claim that  and . The latter claim follows from Assumption~\ref{ass:pushing}, since then  contains only  among the terminals (due to ) and . For the former claim, suppose for the sake of contradiction that . Recall that also , which means that . From the posimodularity of cuts it now follows that one of the terminal separations  and  has cost not larger than , while both of them resolve the terminal pair . This is a contradiction with the maximality of . Hence we infer that  and , and so .

Thus, branching into separations  and  leads to a branching vector  or better. Recalling that , observe that this branching vector can be not good only if  and . Hence, from now on let us analyze this case.

Since , we have that  is a terminal-free set of excess , and hence we can apply Lemma~\ref{lem:ex2-red} to it: We have that  has a decomposition of the form  or . Note that  is an excess-1 set, so  for some . As ,  is adjacent to , and -s are pairwise non-adjacent, we must have that  and we are dealing with a decomposition of the form . Observe that  is a -extension of excess at least ; hence , and in particular . Hence there exists some vertex . By Lemma~\ref{lem:ex2-red} we have that  is adjacent both to  and to . Hence, in the branch  at least one Boundary Reduction is applied to , regardless whether  is assigned to , or , or neither of these sets. We did not include this Boundary Reduction in the previous calculations; this shows that we in fact pursue a branch with a branching vector  or better, which is a good branching vector.









\subsubsection{Subcase (b): }

By the equality condition in~\eqref{eq:truncs} we have that , while  is a terminal-free set of excess . By the inapplicability of the Excess-1 Reduction, we infer that  for some nonterminal vertex . In particular , so by Lemma~\ref{lem:AsConn} the unique neighbor  of  belongs to . Since , we have that  is a terminal-free set of excess , so it consists of a single vertex. However, this set already contains . Hence we infer that  is the unique neighbor of , , . In particular , so by Lemma~\ref{lem:AsConn} it follows that .

Let . Since , we also have . If  then  would be only adjacent to  and thus reducible by the Pendant Reduction. Hence, . In particular, we infer that , since otherwise the Boundary Reduction could be applied to .














Let us now examine two possible branching steps. Firstly, consider just branching into two branches  and . In both cases, only one terminal pair  gets resolved. In branch , when  is assigned to , we pessimistically have no Boundary Reduction and no increase in the cost of the separation. In branch , however, when  is assigned to , we have that  and one Boundary Reduction is triggered on vertex  due to having both an edge to  and to .

We now investigate the components of the branching vector when branching on  with fixing . If in one of the branches at least one more terminal pair gets resolved, then as argued in the beginning of this section we can just pursue the branching step, because it leads to a good branching vector. Hence, assume from now on that in both branches only the pair  gets resolved. Since  and  contains only  among the terminals of , by Assumption~\ref{ass:pushing} we have that . Also, at least one Boundary Reduction is triggered on an edge between  and . In branch , again we pessimistically have no Boundary Reduction and no increase in the cost of the separation.

\begin{figure}[H]
	\centering
	\clearpage{}\begin{tikzpicture}

\draw[Bs] plot [smooth,tension=0.6] coordinates {(-2,2) (-1.5,1.6) (-1.1,0.7) (-0.5,0.2) (0.5,0.2) (1.2,0.7) (1.5,1.6) (2,2)} to (-2,2);
\draw[As] plot [smooth,tension=1.3] coordinates {(-2,0) (-0.1,0.95) (2,0)} to (-2,0);

\Azero;
\node at (1,-0.2) {};
\begin{scope}[shift={(0,2)}] \Bzero; \node at (1,0.17) {}; \end{scope}

\node[ABT,label=180:] (s) at (0.6,0.5) {};
\node[B, label=0:] (sp) at (-0.6,1.3) {};
\node (t) at (2,0.6) {};
\draw[term] (s) to[term] (t);
\draw (s) to (sp);
\draw (sp) to (-0.33,2.1);
\draw (sp) to (-0.55,2.1);
\draw (sp) to (-0.77,2.1);
\node at (-0.45,2.2) {};

\draw (sp) to (-1.7,0.65);
\draw (sp) to (-1.75,0.8);
\draw (sp) to (-1.7,0.99);
\node at (-1.9,0.8) {};



\begin{scope}[shift={(6,0)}]

\Azero;
\node at (1,-0.2) {};

\node[T,label=180:] (s) at (0.6,1.5) {};
\node[V, label=0:] (sp) at (-0.6,0.7) {};
\node (t) at (2,1.4) {};
\draw[term] (s) to[term] (t);
\draw (s) to (sp);

\draw (sp) to (-0.3,-0.1);
\draw (sp) to (-0.66,-0.1);
\node at (-0.45,-0.25) {};

\draw (sp) to (-1.7,0.65);
\draw (sp) to (-1.7,0.99);
\node at (-1.9,0.8) {};

\end{scope}

\end{tikzpicture}
\figspace
\clearpage{}
	\caption{Case (1,0)(b): . This gives rise to an \emph{antenna}, which has to be analyzed together with the other terminal.
	The right side shows an antenna with natural side ; note the definition does not mention , it only relies on the behaviour of extensions containing  or .}
\label{fig:case-10-b-antenna}
\end{figure}

A terminal  with the behaviour as described above will be actually the most problematic case for our branching algorithm. Let us define this setting formally.
\begin{definition}
A terminal  is called an {\em{antenna}} if the following conditions hold:
\begin{itemize}
\item The only neighbor  of  is a nonterminal, has  edges to one of the sets  or , no edge to the second one, and  edges to . The side  to which  is adjacent is called the {\em{natural}} side of , and the second one is called the {\em{unnatural}} side of .
\item Let  and  be the natural and unnatural side of , respectively. Then 
\begin{itemize}
\item For any  with  that contains only  among the terminals from , it holds that .
\item For any  with  that contains only  among the terminals from , it holds that . If moreover  contains at least one more vertex than , then .
\end{itemize}
\end{itemize}
\end{definition}

The discussion above together with Lemmas~\ref{lem:lb} and Assumption~\ref{ass:pushing} shows that in this case  is an antenna with natural side . Obviously, in the symmetric subcase when  and  we obtain that  is an antenna with natural side . 

The idea now is {\em{not}} to perform any branching step on an antenna, but rather to branch on the situation around the second terminal , i.e., swap the roles of  and  and restart the analysis.
In other words, we will show that if the analysis of the second terminal  does not reveal that it is an antenna (it conforms to cases , , or ), then a branching step leading to a good branching vector can be found on that side. We will be thus left with the case when both  and  are antennas, which we aim to resolve now by exposing a branching strategy leading to a good branching vector.

Therefore, assume that  and  are both antennas, and let  and  be their unique neighbors, respectively. By the inapplicability of the Common Neighbor Reduction, . First, suppose that  and  have different natural sides, say  has natural side  and  has natural side . However, then  would be a terminal separation that has the same cost as , which contradicts the maximality of .

Hence, assume that  and  have the same natural side. W.l.o.g. suppose that it is . Let  and ; recall that . Consider two possible branching steps: we can branch on  with fixing  or with fixing . Consider first fixing edge , and let  and  be the branches. By the definition of the antenna we have that  and . Also, in branch  we have at least  Boundary Reductions triggered on edges incident to , whereas in branch  we have at least one Boundary Reduction triggered edges incident to . Thus we obtain a branching vector  or better, and a symmetric reasoning for fixing  leads to branching vector , or better. Note that one of these vectors is good if .
Furthermore, such a branching also leads to a good vector if  or  is adjacent to some terminal other than  or , respectively,
  as then in at least one branch a second terminal pair would be resolved.
Hence, if this is the case, we pursue the respective branching step.

\begin{branching}
If , or there is a terminal in  different than  or  adjacent to  or ,
then pursue branching on  with fixing the respective edge  or .
\end{branching}

From now on we assume that  and that no other terminal than  and  is adjacent to  nor .

\begin{figure}[H]
	\centering
	\clearpage{}\begin{tikzpicture}

\begin{scope}[xscale=1.3]
	\Azero; \node at (1,-0.2) {};
	\begin{scope}[shift={(0,2)}]
		\Bzero; 
	\end{scope}
\end{scope}

\node[T,label=90:] (s) at (-0.6,0.5) {};
\node[V, label=0:] (sp) at (-1.6,1.3) {};
\node[T,label=90:] (t) at (0.6,0.5) {};
\node[V, label=180:] (tp) at (1.6,1.3) {};

\draw[term] (s) to[term] (t);
\draw (s) to (sp);
\draw (t) to (tp);

\draw (sp) to (-1.4,2.1);
\draw (sp) to (-1.8,2.1);
\node at (-1.6,2.15) {};
\draw (sp) to (-2.3,0.9);
\draw (sp) to (-2.3,1.2);
\node at (-2.4,1) {};

\draw (tp) to (1.3,2.1);
\draw (tp) to (1.5,2.1);
\node at (1.2,2.15) {};
\draw (tp) to (2.3,1.1);
\draw (tp) to (2.3,0.9);
\node at (2.45,1) {};

\end{tikzpicture}
\figspace
\clearpage{}
	\caption{Case (1,0)(b) on both  and , where furthermore the antennas have the same natural side.}
\label{fig:case-10-b-two-antennas}
\end{figure}


Consider now the case when there is a vertex  such that all edges of  have  as the endpoint different than . This encompasses the cases when  and when  but the considered edges connecting  with  have the same second endpoint. We claim that then it is a safe reduction to merge  and . To prove this claim, we need to show that there exists an optimum integral terminal separation  extending  where  and  are on the same side. Take any such integral terminal separation , and assume that  and  are on opposite sides. Clearly it cannot happen that  and , because then moving  from  to  would decrease the cost of the separation. Hence  and . This implies that , since otherwise we could improve the cost of the separation by moving  from  to . Therefore . Consider modifying  into  by 
\begin{itemize}
\item moving  and  from  to , and
\item moving  and  from  to , provided  was not already included in .
\end{itemize}
It is easy to see that  is still an integral terminal separation extending  and its cost is no larger than that of . Hence, it is optimum as well. However, in  it holds that  and  are on the same side.

This reasoning and its symmetric version for  imply the correctness of the following reduction step.
Note that  is not a terminal, as we have already excluded this case in the previous branching step.

\begin{reductionstep}
If , then merge  with its unique neighbor in  and restart. If , then merge  with its unique neighbor in  and restart.
\end{reductionstep}

We are left with the case when  and both  and  have two neighbors outside ; these neighbors will be called {\em{external}}. We claim that then just pursuing branching on  with fixed  leads to a good branching vector.

\begin{branching}
If  and , then pursue branching on  with fixing .
\end{branching}

Let the branches be  and . Recall that . If actually , then we would already have a good branching vector  or better, so assume henceforth that . Consider now set . If  did not contain both external neighbors of , then a simple edge count shows that  would be a terminal-free set of excess at most  (if it contains no external neighbor of ) or  (if it contains one external neighbor of ). In both cases this is a contradiction with the maximality of . Hence,  contains both external neighbors of , and  is a terminal-free set of excess . By Lemma~\ref{lem:ex2-red}, we can decompose  as  or . Since  has two different neighbors in , at least one of them is  for some . However, by Lemma~\ref{lem:ex2-red} each  is adjacent to , and hence in branch  at least one Boundary Reduction is triggered on vertex  (regardless whether this vertex is assigned to , or to , or to neither of these sets). In our earlier calculations we did not account for this Boundary Reduction, so in fact we obtain branching vector  or better, which is a good branching vector.











\subsection{Case }

By Lemma~\ref{lem:posi}, we have three non-symmetric subcases:
\begin{itemize}
\item[(a)] , , ;
\item[(b)] , ;
\item[(c)] , , .
\end{itemize}
The case when , , , is symmetric to case (c).

The algorithm proceeds as follows: It investigates every terminal pair , and investigates the case given by this terminal pair when considered as  (i.e., looking from the side of ), and when considered as  (i.e., looking from the side of ). If in any of these checks, for any terminal pair, case  or  is discovered, the algorithm pursues the respective Reduction Step or Branching Step, as described in the previous sections. Otherwise, we can assume the following:
\begin{assumption}\label{ass:cases-left}
Every terminal of  is either an antenna, or investigating the basic branch of the respective terminal pair from its side yields case  (has {\em{type (1,1)}}).
\end{assumption}
In the following we will use this property heavily in order to be able to reason about the total increase in the cost of the separation, also on the side of the second terminal from the pair we are currently investigating. 

\subsubsection{Case (a): , , }



Let . By Assumption~\ref{ass:small-intersections}, we have that  or , where  is the unique neighbor of . 

Suppose first that . Let  and . Since  and both  and  are excess-1 sets, we infer that . Consequently it must hold that , because otherwise the Boundary Reduction would apply to . Thus,  is a vertex of degree  with one neighbor  in  and the second being . Then the Pendant Reduction would apply to , a contradiction.

Therefore, we have that . Let  be the unique neighbor of . We pursue branching on the pair  with fixing edge , i.e., branch into two subcases  and  that are minimum-cost terminal separations extending  and , respectively.

\begin{branching}
Pursue branching on  with fixing .
\end{branching}

Obviously, as explained in the beginning of this section, if any of the resulting branches resolves one more terminal pair, then the branching vector is good. Therefore, suppose that in both branches only the pair  gets resolved. By Assumption~\ref{ass:pushing}, we have that  and . By Assumption~\ref{ass:cases-left}, terminal  is either of type  or is an antenna. In the former case, by Lemma~\ref{lem:lb} we have that  and . Hence we arrive at branching vector  or better, which is a good branching vector. In the latter case, by the definition of an antenna we have that  or , depending on whether  or  is natural for . Also, in the same branch where respective inequality holds, one Boundary Reduction gets applied on the unique neighbor of . Thus we arrive at branching vector , or  or better (depending on which side is natural for ), which is a good branching vector.





\subsubsection{Case (b): , }



Since  and  are terminal-free sets of excess , by the inapplicability of the Excess-1 Reduction we infer that  and  for some distinct nonterminal vertices . In particular, both  and  contain at least one more vertex than . Hence, by Lemma~\ref{lem:AsConn} we infer that if  is the unique neighbor of , then  and . From Assumption~\ref{ass:small-intersections} it follows that . Hence  and .

Since  and , we can apply Lemma~\ref{lem:cool} to it and infer that  has a decomposition  with  and . Consequently, by Lemma~\ref{lem:ex2-red} we infer that for some  and , we have , , and . Also, there is no edge between  and , because then the Boundary Reduction would be applicable to . A symmetric reasoning shows that for some  and , we have , , , and there is no edge between  and .

Vertex  cannot be connected both to  and to , because then the Boundary Reduction would be applicable to it. Hence, w.l.o.g. assume that .
Let . Since  and both  and  are sets of excess , we infer that .

\begin{figure}[H]
	\centering
	\clearpage{}\begin{tikzpicture}[scale=1.1]

\draw[As] plot [smooth,tension=0.5] coordinates {(-2,0) (-1.5,0.4) (-1.3,1.4) (-0.8,1.7) (0.8,1.7) (1.3,1.4) (1.5,0.4) (2,0)} to (-2,0);
\draw[Bs] plot [smooth,tension=0.5] coordinates {(-2,2.4) (-1.5,2) (-1,0.9) (1,0.9) (1.5,2) (2,2.4)} to (-2,2.4);

\Azero;
\begin{scope}[shift={(0,2.4)}] \Bzero; \node at (1.2,0.15) {}; \end{scope}
\node at (1.2,-0.16) {};
\node[ABT,label=30:] (s) at (0.6,1.2) {};
\node[AB, label=180:] (sp) at (-0.6,1.2) {};
\node[A, label=0:] (a) at (-0.6,0.45) {};
\node[B, label=0:] (b) at (-0.6,1.95) {};
\node[T, label=10:] (t) at (2,1.2) {};
\draw[term] (s) to[term] (t);
\draw (s) to (sp);
\draw (t) to[bend left=20] (2.6,1.1) {};
\draw (sp) to [bend left=2] (a);
\draw (sp) to [bend right=20] (a);
\draw (sp) to [bend left=25] (a);
\node at (-0.35,0.8) {};

\draw (sp) to[bend left=15] (b);
\draw (sp) to[bend right=15] (b);
\node at (-0.37,1.52) {};
\draw (sp) to[out=130,in=-90] (-1,2.5);
\node at (-0.85,2.57) {};

\draw (a) to (-0.11,-0.1);
\draw (a) to (-0.33,-0.15);
\draw (a) to (-0.55,-0.15);
\draw (a) to (-0.77,-0.1);
\node at (-0.44,-0.25) {};

\draw (a) to (-1.7,0.55);
\draw (a) to[in=-60,out=160] (-1.9,1);
\node at (-2.1,0.6) {};
\draw (b) to (-0.44,2.5);
\draw (b) to (-0.22,2.55);
\draw (b) to (-0.00,2.5);
\node at (-0.1,2.63) {};

\draw (b) to (-1.7,1.8);
\draw (b) to[in=60,out=-160] (-1.9,1.3);
\node at (-2.1,1.6) {};
\end{tikzpicture}
\figspace
\clearpage{}
	\caption{Case (1,1)(b): . Note the edges counted in  and  may both include a common edge between  and .}
\label{fig:case-11-b}
\end{figure}

For the sake of further argumentation, we now resolve the case when  or , where  is the unique neighbor of . Then, Lemma~\ref{lem:no-overlap} and its symmetric variant imply that the pair  can be assigned greedily. More precisely, the following reduction step is correct.

\begin{reductionstep}\label{red:(1,1)b-corner}
If  then assign  to the -side and  to the -side, i.e., proceed with instance . If  then assign  to the -side and  to the -side, i.e., proceed with instance .
\end{reductionstep}








Henceforth we assume that  and . Since  and , by the inpplicability of Common Neighbor Reduction we infer that  and .

The crucial observation now is that we can fix both edges  and  at the same time.

\begin{lemma}\label{lem:double-fixing}
There exists an optimum integral terminal separation  where either  and , or  and .
\end{lemma}
\begin{proof}
Let us take any optimum integral terminal separation . If the condition of the lemma is not satisfied, then swapping the sides of  and  does not change the cost of the separation. Let us then assume that the edge  is not cut in the solution. Hence, without loss of generality we assume that  and ; the rest of the reasoning will be independent of the choice we made earlier that there are no edges between  and , so we are indeed not losing generality here.

Consider . By the submodularity of cuts we have that

However, we have that  because otherwise we would be able to replace  with  in separation  thus decreasing its cost while preserving the fact that it extends . Hence, we infer that . Observe that since  is terminal-free, then  is also an integral terminal separation, and its cost is . Hence,  is also an optimum integral terminal separation. Since  and , we infer that edges  and  are not cut in , as was requested.
\end{proof}

Lemma~\ref{lem:double-fixing} justifies the correctness of branching on  with both  and  fixed. More precisely, we branch into separations  and  that are minimum-cost terminal separations extending  and , computed using Theorem~\ref{thm:ptime}. 

\begin{branching}
Pursue branching on  with fixing both  and .
\end{branching}

As we argued at the beginning of this section, if in any of these branches at least one more terminal pair gets resolved, then we arrive at a good branching vector; hence assume that this is not the case.

By Lemma~\ref{lem:lb} we have that  and . Also, in both branches the Boundary Reduction will be applied at least  times: either  times on  (provided  is assigned to the -side), or  times on  and  times on edges between  and  (provided  is assigned to the -side).

We now calculate the branching vectors when performing this branching.

Suppose first that  is an antenna, then by the definition of the antenna we have that  or , depending whether  or  is the natural side of . Moreover, in the same branch, one Boundary Reduction is triggered on an edge between  and the natural side of  in the branch. By , we know that this Boundary Reduction was not accounted for in the previous calculations. Hence, we obtain branching vector , or , or better, depending on the natural side of . Since , these branching vectors are good.

Suppose now that  is of type , and moreover that investigation of its situation also leads to the same case (b). Then we have that  and  by Lemma~\ref{lem:lb}. Moreover, in both of the branches, at least one Boundary Reduction is triggered that reduces some edge incident to . It is easy to see that the applicability of this Boundary Reduction could not be spoiled by the application of the  Boundary Reductions on the side of , because  and  and  are assigned to different sides. Thus, we arrive at branching vector , which is  or better, and hence good.

Finally, we are left with the case when  is of type , and the investigation of its situation also leads to case (c). Similarly as in the previous paragraph, we have that  and . Moreover, as we shall see in the next section, in at least one branch, one additional Boundary Reduction will be triggered that will reduce an edge incident to . Moreover, the applicability of this Boundary Reduction will not be spoiled by the application of the previous  Boundary Reductions on the side of , for the same reason as in the previous paragraph; that is,  and  and  are assigned to different sides. Hence we arrive at branching vector , or , or better. All these vectors are good for .












\begin{comment}

Now the crucial observation is that even though in our branch we fix edge , we can prove that the nonterminal  will also be assigned to one of the sides.

\begin{lemma}\label{lem:sp-colored}
 and .
\end{lemma}
\begin{proof}
We prove the second statement, for the first one is symmetric. Suppose, for the sake of contradiction, that . Let .

We first prove that . On one hand, we have that 

because otherwise we could replace  with  in separation , which would reduce the cost of the separation, a contradiction with the optimality of . Similarly, the optimality of  implies that 

This is because otherwise we could replace  with  in separation  and obtain a separation that still extends  (due to ) and has strictly smaller cost. However, the posimodularity of cuts implies that

Hence, from \eqref{l1},~\eqref{l2}, and~\eqref{l3} we infer that all the inequalities above are in fact equalities, so in particular .

Observe that , because otherwise we could replace  with  in the terminal separation , thus obtaining a separation of smaller cost, a contradiction with the optimality of . From the submodularity of cuts we have that

which means that . From Lemma~\ref{lem:lb} it follows that , so we infer that .

Consider now terminal separation . From its definition it follows that it is indeed a terminal separation, it extends , and it has no larger cost because . However, due to  we see that  assigns at least one more nonterminal to one of the sides than . This is a contradiction with the maximality of .
\end{proof}

From Lemma~\ref{lem:sp-colored} we infer that in both of the branches, the Boundary Reduction will be applied at least  times: either  times on  (provided  is assigned to the -side), or  times on  and  times on edges between  and  (provided  is assigned to the -side). 

We now calculate the branching vectors when branching on  with  fixed. By Lemma~\ref{lem:lb}, we have that  and , and  Boundary Reductions are triggered on the side of . 

Suppose first that  is an antenna, then by the definition of the antenna we have that  or , depending whether  or  is the natural side of . Moreover, one Boundary Reduction is triggered on , and by  we know that this Boundary Reduction was not accounted for in the previous calculations. Hence, we obtain branching vector , or , or better, depending on the natural side of . Since , these branching vectors are good.

Suppose now that  is of type , and moreover that investigation of its situation also leads to the same case (b). Then we have that  and  by Lemma~\ref{lem:lb}, and at least one Boundary Reduction is applied in both of the branches on 
\end{comment}

\subsubsection{Case (c): , , }



Since , we have that  is a terminal-free extension of  of excess  and we can apply Lemma~\ref{lem:cool} to decompose it as , where  is the unique neighbor of . Let , for . Recalling Lemma~\ref{lem:ex2-Bside}, let  be the number of Boundary Reductions that are immediately triggered within  in any branch when  is assigned to the -side. By Lemma~\ref{lem:ex2-Bside} we have that . This justifies the claim that was left in our analysis of Case , where we argued for the applicability of one additional Boundary Reduction.

Before we proceed, let us exclude the corner case when  for some , where  is the unique neighbor of . Lemma~\ref{lem:no-overlap} justifies the correctness of the following reduction step.

\begin{reductionstep}
If  for some , then assign  to the -side and  to the -side, i.e., proceed with instance .
\end{reductionstep}

Since  by the inapplicability of the Common Neighbor Reduction, henceforth we can assume that . 

Since , by Assumption~\ref{ass:small-intersections} we have two cases: either  or .

\paragraph*{Subcase (c.i): .} 

Let . Since  and  has excess , we infer that there are  edges from  to , and hence . Observe that , because if  the  would be adjacent only to  and to a vertex in , and hence the Pendant Reduction would be applicable to . Hence in this case .


\begin{figure}[H]
	\centering
	\clearpage{}\begin{tikzpicture}

\draw[Bs] plot [smooth,tension=0.6] coordinates {(-2,2) (-1.5,1.6) (-1.1,0.7) (-0.5,0.2) (0.5,0.2) (1.2,0.7) (1.5,1.6) (2,2)} to (-2,2);
\draw[As] plot [smooth,tension=1.3] coordinates {(-2,0) (-0.1,0.95) (2,0)} to (-2,0);

\Azero;
\node at (1,-0.2) {};
\begin{scope}[shift={(0,2)}] \Bzero; \end{scope}

\node[ABT,label=30:] (s) at (0.6,0.5) {};
\node[AB, label=180:] (sp) at (-0.6,0.5) {};
\node[B, label={right:}] (c1) at (-0.8,1.5) {};
\node[B, label=0:] (c3) at (0.5,1.5) {};
\node (t) at (2,0.6) {};
\draw[term] (s) to[term] (t);
\draw (s) to (sp);
\draw (sp) to[bend right=2] (c1);
\draw (sp) to[bend left=15] (c1);
\draw (sp) to[bend right=18] (c1);
\draw (sp) to (c3);


\draw (sp) to (-0.33,-0.1);
\draw (sp) to (-0.55,-0.1);
\draw (sp) to (-0.77,-0.1);
\node at (-0.55,-0.25) {};

\draw (c1) to (-1.0,2.1);
\draw (c1) to (-0.8,2.1);
\draw (c1) to (-0.6,2.1);
\draw (c1) to[bend left] (-2,1);



\draw (c3) to (0.6,2.1);
\draw (c3) to (0.8,2.1);

\draw (c3) to[out=-40,in=180] (1.9,1.2);
\draw (c3) to[out=-30,in=180] (1.9,1.3);



\end{tikzpicture}
\figspace
\clearpage{}
	\caption{Case (1,1)(c.i): . A careful reader might notice that since the excess of  is 1, an edge count implies .}
\label{fig:case-11-ci}
\end{figure}

Having this structure, it is natural to make the following branching.

\begin{branching}
If , then pursue branching on  with fixing .
\end{branching}

Let  and  be the respective branches, i.e., minimum-cost maximal terminal separations extending  and , respectively. Of course, if in any of these branches one more terminal pair got resolved, then we have a good branching vector. Assume therefore that this is not the case. In branch  from Lemma~\ref{lem:lb} we have that  and  Boundary Reductions are triggered within . In branch  we again have that , and  Boundary Reduction are triggered for edges between  and .

We now calculate the obtained branching vector depending on whether  is an antenna or is of type .

If  is an antenna with natural side , then in branch  we have  and one Boundary Reduction is triggered on edges incident to . Since , it is easy to see that the execution of the  previous Boundary Reductions on the side of  could not spoil the applicability of this Boundary Reduction. In branch , we do not account for any gain on the side of . Thus we arrive at branching vector , which is  or better, and hence good.

If  is an antenna with natural side , then in branch  we do not account for any gain on the side of . However, in branch  we have that  and one Boundary Reduction is triggered on edges incident to . Since , again it is easy to see that the execution of the  previous Boundary Reductions on the side of  could not spoil the applicability of this Boundary Reduction. Thus we arrive at branching vector , which is  or better, and hence good.

Finally, suppose  is of type . Then by Lemma~\ref{lem:lb} we infer that  and . Hence we have a branching vector  or better, which is good because  and .











\paragraph*{Subcase (c.ii): .}



We again investigate the branch on  with fixing ; for now we do not state that we indeed perform it, because its execution will take place only if the progress will be large enough. Let  and  be the respective branches, i.e., minimum-cost maximal terminal separations extending  and , respectively. Of course, if in any of these branches an additional terminal pair gets resolved, then we already have a good branching vector, so assume henceforth that this is not the case. Since , by Assumption~\ref{ass:pushing} we infer that , because in  at least one more vertex (namely ) is assigned to the -side. As before, in branch  we have that  Boundary Reductions are triggered inside . In branch , by Lemma~\ref{lem:lb} we have that , and we do not account for any Boundary Reductions.

\begin{figure}[H]
	\centering
	\clearpage{}\begin{tikzpicture}

\draw[Bs] plot [smooth,tension=0.6] coordinates {(-2,2) (-1.5,1.6) (-1.1,0.7) (-0.5,0.2) (0.5,0.2) (1.2,0.7) (1.5,1.6) (2,2)} to (-2,2);
\draw[As] plot [smooth,tension=1.3] coordinates {(-2,0) (-0.1,0.7) (2,0)} to (-2,0);

\Azero;
\node at (1,-0.2) {};
\begin{scope}[shift={(0,2)}] \Bzero; \end{scope}

\node[ABT,label=30:] (s) at (0.3,0.4) {};
\node[B, label=180:] (sp) at (-0.3,1) {};
\node[B, label={[label distance=3]left:}] (c1) at (-1.05,1.5) {};
\node[B, label={[label distance=-3]left:}] (c2) at (-0.1,1.5) {};
\node[B, label=0:] (c3) at (0.7,1.5) {};
\node (t) at (2,0.6) {};
\draw[term] (s) to[term] (t);
\draw (s) to (sp);
\draw (sp) to[bend left=10] (c1);
\draw (sp) to[bend right=10] (c1);
\draw (sp) to (c2);
\draw (sp) to[bend left=10] (c3);
\draw (sp) to[bend right=10] (c3);

\draw (sp) to[out=-155,in=0] (-1.8,0.6);

\draw (sp) to (-0.33,-0.1);
\draw (sp) to (-0.55,-0.1);


\draw (c1) to (-1.2,2.1);
\draw (c1) to (-1.0,2.1);
\draw (c1) to[bend left] (-2,1);

\draw (c2) to (-0.1,2.1);
\draw (c2) to[out=-30,in=180] (2,1);

\draw (c3) to (0.55,2.1);
\draw (c3) to (0.77,2.1);
\draw (c3) to (0.99,2.1);

\draw (c3) to[out=-40,in=180] (1.9,1.2);
\draw (c3) to[out=-30,in=180] (1.9,1.3);



\end{tikzpicture}
\figspace
\clearpage{}
	\caption{Case (1,1)(c.ii): .}
\label{fig:case-11-cii}
\end{figure}

Let us now investigate what happens in respective branches on the side of terminal , depending on the type of . Suppose first that  is of type . Then, by Lemma~\ref{lem:lb} it follows that  and , and hence together with the account of the progress on the side of , we obtain a branching vector  or better, which is good because .

We are left with the case when  is an antenna, where it can be easily verified that the reasoning as above does not lead to a good branching vector without any deeper analysis. We distinguish two subsubcases, depending on the natural side of .





\paragraph*{Subsubcase (c.ii.A): the natural side of  is }

Let  be the unique neighbor of . Since  is an antenna, there are  edges from  to  and  edges from  to , for some .

\newcommand{\Ant}{A_{\text{nt}}}
\newcommand{\Bnt}{B_{\text{nt}}}
\newcommand{\Aunt}{A_{\text{unt}}}
\newcommand{\Bunt}{B_{\text{unt}}}
\newcommand{\Auntext}{A_{\text{unt}}^{\text{ext}}}
\newcommand{\Buntext}{B_{\text{unt}}^{\text{ext}}}

We now introduce a new type of a branching step that we shall call {\em{skewed branching}}. Namely, we will branch into separations  and  that are minimum-cost terminal separations extending  and , respectively. It is easy to see that this branching step is correct, because there is always an optimum integral separation  extending  where (1)  and , or (2)  and . Namely, if neither the first nor the second property is satisfied, then swapping the sides of  and  does not increase the cost of the separation (because the second property is not satisfied), but it makes the first property satisfied.

The reader should think of the skewed branching in the following way. For terminal , the side  is the natural side to be assigned to, whereas for  it is  that is more natural. More precisely, in the branch where we have such assignment, we are not able to reason about any Boundary Reductions being triggered. We do, however, hope for a large decrease in the potential in the opposite branch, where both terminals are assigned to their unnatural sides. Therefore, in this unnatural branch we fix both edges  and  to maximize the progress measured in the potential function, while in the natural branch we do not fix anything, because this would not lead to any profit in the analysis.

Let us now calculate the branching vector that we obtain when we perform the described skewed branching; of course we assume that no other terminal pair gets resolved in either of the branches, because then we immediately obtain a good branching vector. In branch , by Lemma~\ref{lem:lb} we have that  and , and we do not account for any applications of the Boundary Reduction. In branch , however, we have  by Assumption~\ref{ass:pushing}, because , and , by the definition of an antenna and the fact that  is the unnatural side of . Moreover, in this branch  Boundary Reductions are applicable to the edges between  and  and  Boundary Reductions are applicable within . Since , these applications do not interfere with each other. Thus, we arrive at a branching vector , or better. This branching vector is good unless . Also, even if  but , then this leads to branching vector  or better, which is good. Thus, we can state the following branching step.

\begin{branching}
Unless  and , pursue skewed branching into separations  and .
\end{branching}









Henceforth we assume that  and . Therefore, the degree of  in  is equal to , and it is adjacent to , one vertex in , and one vertex in  that shall be whence called .

Consider now the branch , and suppose there is some optimum terminal separation  extending  that conforms to this branch, i.e., it also extends . Suppose that . Then this is clearly a contradiction with the optimality of , because  has  neighbors in  and  in , so moving it from  to  would decrease the cost of the separation. Hence we can assign  greedily to the -side. More precisely, instead of  we will from now on consider terminal separation  defined as the minimum-cost terminal separation extending . In case , the reasoning above shows that the branch where  is assigned to the -side and  is assigned to the -side cannot lead to an optimum solution, so we can greedily pursue the branch where  and  are assigned to respective natural sides.

\begin{reductionstep}
If , then recurse into terminal separation .
\end{reductionstep}

Hence, from now on we assume that  and we branch into  and , where the latter is defined as above. As usual, we assume that  does not resolve any new terminal pair, because then we would have a good branching vector. The same reasoning as for  shows that  and . As before, if we had that , then branching into  and  would lead to a branching vector  or better. Hence, we can again assume that .

Therefore, a straightforward edge count shows that  is a terminal-free -extension of excess . Hence, we can apply Lemma~\ref{lem:ex2-red} to decompose it. By the inapplicability of the Excess-2 Reduction, we have that  has a decomposition of the form  or  (from now on we drop the earlier notation for the decomposition of , and use the notation  for the decomposition of ). Suppose first that  for some . Then this is a contradiction with the optimality of , because then  would be a set of excess , so replacing  with it would decrease the cost of separation . Therefore,  has a decomposition of the form  where . 

By Lemma~\ref{lem:ex2-red}, we have that ,  and , for some integers  and . Let  be the number of Boundary Reductions triggered within  when the vertex  is assigned to the -side. By Lemma~\ref{lem:ex2-Bside}, .

Before we proceed, we need to resolve a corner case when . We claim that then it is safe to greedily assign  to the -side and  to the -side.

\begin{reductionstep}\label{rdstep:corner2}
If , then recurse with terminal separation .
\end{reductionstep}

To argue the correctness of this reduction step, we need to prove that there exists an optimum terminal separation extending  where  is assigned to the -side and  is assigned to the -side. Let us take any optimum terminal separation 
that satisfies point 1 of Lemma~\ref{lem:ex2}.
Assume  and , as otherwise we are done.
We can further assume that  and , because otherwise switching the sides of  and  would not increase the cost of the separation, however it would make it satisfy the condition we seek.
Suppose first that ; then we have an immediate contradiction, because moving  from  to  would decrease the cost.
Suppose then that  for some .
Since  satisfies point 1 of Lemma~\ref{lem:ex2},
we infer that  or  for some . In particular, . This is, however, a contradiction, because moving  from  to  would decrease the cost of the separation. This justifies the correctness of Reduction Step~\ref{rdstep:corner2}.

Whence we assume that .

\begin{figure}[H]
	\centering
	\clearpage{}\begin{tikzpicture}[yscale=1.1]

\draw[Bs] plot [smooth,tension=0.6] coordinates {(-2.6,2) (-1.1,1.7) (-0,1) (0.5,0.7) (1.1,0.5) (1.7,0.9) (2.3,1.6) (2.6,2)} to (-2.6,2);

\begin{scope}[xscale=1.3]
	\Azero;
	\node at (1,-0.2) {};
	\begin{scope}[shift={(0,2)}] \Bzero; \end{scope}
\end{scope}

\node[T,label=-170:] (s) at (-1.3,0.6) {};
\node[V, label=left:] (sp) at (-1.7,1) {};
\node[V] (oldc1) at (-1.7,1.5) {};
\node[T, label=above:] (t) at (-0.4,0.6) {};
\node[V, label=0:] (tp) at (0.2,0.4) {};
\node[B, label=-20:] (v) at (0.8,0.9) {};
\node[B, label=left:] (c1) at (0.1,1.5) {};
\node[B, label={[label distance=-3]right:}] (c2) at (0.7,1.5) {};
\node[B, label=right:] (c3) at (1.5,1.5) {};

\draw (s) to (sp);
\draw (sp) to (oldc1);
\draw (sp) to[out=-130,in=0] (-2.5,0.6);

\draw (oldc1) to (-1.55,2.1);
\draw (oldc1) to (-1.77,2.1);
\draw (oldc1) to (-1.99,2.1);

\draw (oldc1) to (-2.4,1.6);
\draw (oldc1) to (-2.4,1.5);
\draw (oldc1) to (-2.4,1.4);

\draw[term] (s) to (t);
\draw (t) to (tp);
\draw (tp) to (0.2,-0.1);
\draw (tp) to (v);

\draw (v) to (c1);
\draw (v) to[bend left=15] (c2);
\draw (v) to[bend right=15] (c2);
\draw (v) to (c3);
\draw (v) to[out=170,in=-100] (-0.2,2.1);

\draw (v) to (2.2,0.8);
\draw (v) to (2.2,0.7);
\draw (v) to (2.2,0.6);

\draw (c1) to (0.1,2.1);
\draw (c2) to (0.6,2.1);
\draw (c2) to (0.8,2.1);
\draw (c3) to (1.4,2.1);
\draw (c3) to (1.6,2.1);

\draw (c1) to[out=-25,in=175] (2.4, 1);
\draw (c2) to[out=-25,in=180] (2.4, 1.1);
\draw (c3) to[out=-25,in=180] (2.4, 1.2);
\draw (c3) to[out=-20,in=180] (2.4, 1.3);


\end{tikzpicture}
\figspace
\clearpage{}
	\caption{Case (1,1)(c.ii.A), where furthermore  and . The set  of excess 2 is highlighted in red.}
\label{fig:case-11-ciiA}
\end{figure}

We will now branch on vertex . More precisely, we recurse into branches  and , defined as minimum-cost terminal separations extending  and , respectively.

\begin{branching}
Pursue branching on , that is, recurse into branches  and .
\end{branching}

The remainder of the description of this subcase is devoted to proving that the execution of this branching step leads to a good branching vector.

Consider first branch . By the optimality of  we infer that , because otherwise assigning it to , or moving from  to , would decrease the cost of the separation. Also, we can assume that  and  for the following reason. If this terminal pair was not resolved in , then assigning  to the -side and  to the -side would not increase the cost of the separation while extending , a contradiction with the maximality of . However, if  and , then we can modify separation  by switching the sides of  and , and because , then this modification does not increase the cost. 

Hence, in branch  the terminal pair  gets resolved. Since  and , by Lemma~\ref{lem:lb} and the definition of an antenna we obtain that  and . Notice also that at least  Boundary Reductions are triggered within .

Consider the second branch . In it, one Boundary Reduction is triggered on the edges incident to , and the terminal pair  is either resolved by this branch or is immediately removed by the Lonely Terminal Reduction (possibly preceded by the Pendant Reduction that removes ). Hence,  also gets resolved in this branch.

From now on, we assume that neither of the considered branches resolves any terminal pair other than , because then, as argued at the beginning of this section, we would immediately achieve a good branching vector. With this assumption in mind, we now claim that . 

\begin{myclaim}\label{cl:even-if-terminal1}
.
\end{myclaim}
\begin{proof}
If  is a terminal-free extension of , then this follows from Lemma~\ref{lem:ex2-Aside}. We have two cases left to investigate: either  or .

In the first case, since  by the optimality of  it follows that also . But then if  was an extension of excess at most , then  would be a terminal-free extension of excess at most , a contradiction with Lemma~\ref{lem:ex2-Aside}.

In the second case, assume for the sake of contradiction that  (it cannot happen that , because then  would be an extension of  of the same cost, a contradiction with the maximality of ). Then  is a terminal-free set of excess . Since , by the optimality of  we obtain that  for each , so . 

On the other hand,  because  is connected by the same reasoning as in Lemma~\ref{lem:AsConn}. But we are currently working with the assumption that , so  is a strict subset of . 

Thus, we obtain a contradiction with Lemma~\ref{lem:ex2-nested}. Indeed, from this lemma it follows that  consists of two vertices that are adjacent to  and each of them forms an excess-1 extension of , but we know that  is the vertex  of the decomposition of  and by Lemma~\ref{lem:ex2-red}, .
\end{proof}

We conclude that the considered branching leads to branching vector , or better. This vector is good unless . Also, if in fact , then we also arrive at a good branching vector , or better. Hence, from now on assume that  and .

If , then  is a terminal-free extension of  of excess . Let us apply Lemma~\ref{lem:ex2-red} to it. Regardless of the form of the decomposition, from Lemma~\ref{lem:ex2-Bside} we infer that in the branch  at least one Boundary Reduction will be triggered within . This Boundary Reduction is applied independently of the Boundary Reduction triggered on edges incident to  that we previously counted in branch . This gives one additional Boundary Reduction that we did not account for previously, which leads to a good branching vector , or better.









\paragraph*{Subsubcase (c.ii.B): the natural side of  is }

Recall that we investigated the branch  and , and we concluded that , , and  Boundary Reductions are triggered inside  in branch . From the definition of an antenna we have that  and one Boundary Reduction is triggered on edges incident to  in branch , when  is assigned to the -side. This gives us branching vector  or better, which is good unless . 
Also, note that this branching is good if  is adjacent to a second terminal different than : due to inapplicability
of the Common Neighbor Reduction, this terminal would belong to a second terminal pair that would get resolved
in the branching.
This justifies the execution of the following branching step.

\begin{branching}
If  or  is adjacent to a second terminal different than ,
then recurse into branches  and .
\end{branching}



Recall that from Lemma~\ref{lem:cool} we obtained a decomposition  of , where  is the unique neighbor of . By Lemma~\ref{lem:ex2-Bside}, if  then we have two cases:
\begin{itemize}
\item either  and  has degree : one edge to , one edge to , and two edges to ;
\item or  and  has degree : one edge to , one edge to , and one edge to . Moreover,  is incident exactly on the following edges:  edge to ,  edges to  and  edges to , for some .
\end{itemize}
Let ; then . We now investigate the cases separately.






\paragraph*{Subsubsubcase (c.ii.B.1): }

We first investigate the possibility of branching on  with fixing . That is, we examine branches  and  that are minimum-cost maximal extensions of  and , respectively. Of course if any of these branches resolves some terminal pair other than , then we obtain a good branching vector. Hence, assume this is not the case. 

Consider the first branch . By Lemma~\ref{lem:lb} we have that . Also, one Boundary Reduction is triggered on edges incident to . 

Consider the second branch . By the definition of an antenna, we have that  and by Lemma~\ref{lem:lb} we have that . Also,  Boundary Reductions are triggered on edges between  and  in this branch.

This leads to a branching vector  or better, which is good unless .
This justifies executing the following step.

\begin{branching}
If , then recurse into branches  and .
\end{branching}

From now on we assume that , and, consequently, we have that  has degree : it neighbors , one vertex in , and one vertex  outside . 

We now resolve the corner case when . Then  is adjacent to ,  and one vertex in , whereas  is adjacent to , , one vertex in , and one vertex outside . We claim that we can assign greedily  to the -side and  to the -side. To argue this, take any minimum-cost integral terminal separation  extending , and assume that  and . We can further assume that  and , because otherwise switching the sides of  and  produces an integral terminal separation of no larger cost where  and  are on the sides we aimed for. But then  has two neighbors in  and one in , which is a contradiction with the optimality of  --- moving  from  to  would decrease the cost. This justifies the correctness of the following step.

\begin{figure}[H]
	\centering
	\clearpage{}\begin{tikzpicture}[yscale=0.8,xscale=0.9]



\begin{scope}
	\Azero;
	\node at (1,-0.2) {};
	\begin{scope}[shift={(0,2)}] \Bzero; \end{scope}
\end{scope}

\node[T,label=-170:] (s) at (-0.7,0.6) {};
\node[V, label=left:] (sp) at (-1.2,1.4) {};
\node[T, label=-0:] (t) at (0.7,0.6) {};
\node[V, label=0:] (tp) at (1.2,1.4) {};

\draw (s) to (sp);
\draw (sp) to (-1.2,2.1);
\draw (sp) to (-2,0.8);

\draw[term] (s) to (t);
\draw (t) to (tp);
\draw (tp) to (1.2,2.1);
\draw (tp) to (sp);


\end{tikzpicture}
\figspace
\clearpage{}
	\caption{Case (1,1)(c.ii.B.1), where furthermore  is a neighbor of .}
\label{fig:case-11-ciiB1corner}
\end{figure}

\begin{reductionstep}
If , then recurse into branch .
\end{reductionstep}

From now on, we assume that .

Suppose now that . Then in branch  one additional Boundary Reduction is triggered on edges incident to . Since , the application of this Boundary Reduction cannot spoil the applicability of the Boundary Reduction on edges incident to  that we counted in the same branch. This results in branching vector  or better, which is good, so we can do the following.

\begin{branching}
If , then recurse into branches  and .
\end{branching}

Henceforth we assume that .


\newcommand{\Aext}{A^{\textrm{ext}}_{tt'\to A}}
\newcommand{\Bext}{B^{\textrm{ext}}_{tt'\to A}}

As in Case~(c.ii.A), we argue that in branch  we can greedily assign  to the -side. More precisely, instead of  we will from now on consider terminal separation  defined as the minimum-cost terminal separation extending . The argumentation for the correctness of this step is as before: Suppose there is some optimum terminal separation  extending  that conforms to this branch, i.e., it also extends . Suppose that . Then this is clearly a contradiction with the optimality of , because  has  neighbors in  and  in , so moving it from  to  would decrease the cost of the separation. 

As usual,  resolving an additional terminal pair would immediately lead to a good branching vector when branching into  and , so assume this is not the case.

In branch , by the definition of an antenna, we have that  and by Lemma~\ref{lem:lb} we have that . Also, a Boundary Reduction is triggered on the edge between  and  in this branch. Observe that if we in fact had that , then branching into  and  results in branching vector  or better, which is good. This justifies the execution of the following.

\begin{branching}
If , then recurse into branches  and .
\end{branching}

\begin{figure}[H]
	\centering
	\clearpage{}\begin{tikzpicture}[yscale=-1.1]

\draw[As] plot [smooth,tension=0.5] coordinates {(-2.6,2) (-1.1,1.7) (-0.2,1) (0.3,0.7) (1.1,0.5) (1.6,0.7) (2.3,1.6) (2.6,2)} to (-2.6,2);

\begin{scope}[xscale=1.3,yscale=-1,shift={(0,-2)}]
	\Azero;
	\begin{scope}[shift={(0,2)}] \Bzero; \node at (1,0.2) {}; \end{scope}
\end{scope}

\node[T,label=-100:] (s) at (-1.3,0.6) {};
\node[V, label=left:] (sp) at (-1.7,0.4) {};
\node[T, label=above:] (t) at (-0.4,0.6) {};
\node[V, label=0:] (tp) at (0.2,0.4) {};
\node[A, label=left:] (v) at (0.8,0.9) {};
\node[A, label=left:] (c1) at (0.1,1.5) {};
\node[A, label={[label distance=-3]-10:}] (c2) at (0.7,1.5) {};
\node[A, label=-10:] (c3) at (1.5,1.5) {};

\draw (s) to (sp);
\draw (sp) to (-1.7,-0.1);
\draw (sp) to (-2.4,0.8);
\draw (sp) to (-2.3,1.1);

\draw[term] (s) to (t);
\draw (t) to (tp);
\draw (tp) to (0.2,-0.1);
\draw (tp) to (v);

\draw (v) to (c1);
\draw (v) to[bend left=15] (c2);
\draw (v) to[bend right=15] (c2);
\draw (v) to (c3);

\draw (v) to (2.2,0.5);
\draw (v) to (2.2,0.7);

\draw (c1) to (0.1,2.1);
\draw (c2) to (0.6,2.1);
\draw (c2) to (0.8,2.1);
\draw (c3) to (1.4,2.1);
\draw (c3) to (1.6,2.1);

\draw (c1) to[out=-25,in=175] (2.4, 1);
\draw (c2) to[out=-25,in=180] (2.4, 1.1);
\draw (c3) to[out=-25,in=180] (2.4, 1.2);
\draw (c3) to[out=-20,in=180] (2.4, 1.3);


\end{tikzpicture}
\figspace
\clearpage{}
	\caption{Case (1,1)(c.ii.B.1), where furthermore  and . The set  of excess 2 is highlighted in blue.}
\label{fig:case-11-ciiB1}
\end{figure}

From now on we assume that . This means that  is a terminal-free extension of  of excess , and moreover . Hence, we can apply Lemma~\ref{lem:ex2-red} to  and obtain a decomposition of the form  or  (we now drop the notation for the decomposition of , and use it for the decomposition of  instead). By Lemma~\ref{lem:ex2-red}, each  is connected with  via at least one edge, but we assumed that there is no edge between  and . Hence the decomposition has the form  and . By Lemma~\ref{lem:ex2-Bside}, at least one Boundary Reduction is triggered within  in any branch where  is assigned to .

We will pursue branching on vertex .  More precisely, we consider recursing into branches  and , defined as minimum-cost terminal separations extending  and , respectively.

\begin{branching}
Pursue branching on , that is, recurse into branches  and .
\end{branching}

The remainder of this case is devoted to arguing that this branching step leads to a good branching vector.

Consider branch . Then a Boundary Reduction is triggered on edges incident to , and consequently the pair  either gets resolved in this branch, or is removed by an application of the Lonely Terminal Reduction (possibly preceded by the Pendant Reduction that removes ). Hence, at least the terminal pair  gets resolved or removed in this branch. 

In branch  we have that  due to the optimality of . Moreover, we can assume that  and  for the following reason. If this terminal pair was not resolved in , then assigning  to the -side and  to the -side would not increase the cost of the separation while extending , a contradiction with the maximality of . However, if  and , then we can modify separation  by switching the sides of  and , and because , then this modification does not increase the cost. 

Hence, in both branches, the terminal pair  gets eventually removed. Suppose then that neither  nor  resolves another terminal pair, because otherwise we would immediately have a good branching vector. We continue the calculation of the obtained branching vector with this assumption. First, we need an analogue of Claim~\ref{cl:even-if-terminal1}, whose proof is very similar.

\begin{myclaim}\label{cl:even-if-terminal2}
.
\end{myclaim}
\begin{proof}
If  is a terminal-free extension of , then this follows from Lemma~\ref{lem:ex2-Aside}. We have two cases left to investigate: either  or .

In the first case, since  by the optimality of  it follows that also . But then if  was an extension of excess at most , then  would be a terminal-free extension of excess at most , a contradiction with Lemma~\ref{lem:ex2-Aside}.

In the second case, assume for the sake of contradiction that  (it cannot happen that , because then  would be an extension of  of the same cost, a contradiction with the maximality of ). Then  is a terminal-free set of excess  that contains . Since , by the optimality of  we obtain that  for each , so . 

On the other hand,  because  is connected by the same reasoning as in the proof of Lemma~\ref{lem:AsConn}. However, observe that . Indeed, we are working with the assumption that , and moreover  for each  because otherwise the Boundary Reduction would apply to . Hence  is a strict subset of . 

Thus, we obtain a contradiction with Lemma~\ref{lem:ex2-nested}. Indeed, from this lemma it follows that  consists of two vertices that are adjacent to , but we know that  and .
\end{proof}

Observe that in branch  we also have one Boundary Reduction triggered on the edges incident to .

On the other hand, in branch  we have  by Lemma~\ref{lem:lb} because . Also,  by the definition of an antenna and the fact that . Finally, one Boundary Reduction is triggered on edges incident to  and one Boundary Reduction is triggered within . Since , the application of one of these reductions cannot spoil the applicability of the other.

Thus we obtain branching vector  or better, which is a good branching vector.









\paragraph*{Subsubsubcase (c.ii.B.2): .}

Recall that  has degree  and has one edge to , one edge to , and one edge to , whereas  has  edges to  and  edges to , for some . Let  be the neighbor of  other than  and .

First, note that  is not a terminal, as we have already excluded the case 
when  is adjacent to a second terminal different than .

We claim that there is an optimum integral terminal separation  extending  where vertices  and  are assigned to the same side. Take any optimum integral separation  and suppose that  and  are assigned to different sides.

Assume first that  and . Then  and  because otherwise moving  from  to  would decrease the cost of the separation. Hence , and again by the optimality of  we have . Consider a modified integral terminal separation  obtained from  by moving  from the -side to the -side. Recall that  has  edges to  and  edges going outside of . Then it is easy to see that the cost of  is not larger than the cost of , whereas  and  are both assigned to the -side.

Assume second that  and . Similarly as before, by the optimality of  we have that  and . Consequently, . If we had that , then moving  from  to  and  from  to  would strictly decrease the cost of the separation, a contradiction with the optimality of . Hence we have that . Consider a modified integral terminal separation  obtained from  by moving  from the -side to the -side, and moving  from the -side to the -side. Recall that  has  edges going to  and  edges going outside of . Hence it is easy to see that the cost of  is not larger than the cost of , whereas  and  are both assigned to the -side.

This justifies the execution of the following reduction in this case.

\begin{reductionstep}
Merge  and .
\end{reductionstep}

As the case study is exhaustive, this finishes the description of the branching algorithm. We hope that the reader shares the joy of the writer after getting to this line.




