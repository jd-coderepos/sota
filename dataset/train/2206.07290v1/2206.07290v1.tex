\documentclass{article}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} 

\usepackage[pdfa]{hyperref}
\hypersetup{
    pdftitle = {Differentiable Top-k Classification Learning},
    pdflang = {en-US},
}
\usepackage{url}

\usepackage{wrapfig}

\usepackage{amsmath}
\usepackage{xcolor}


\usepackage{amsmath,amsfonts,bm}

\newcommand{\figleft}{{\em (Left)}}
\newcommand{\figcenter}{{\em (Center)}}
\newcommand{\figright}{{\em (Right)}}
\newcommand{\figtop}{{\em (Top)}}
\newcommand{\figbottom}{{\em (Bottom)}}
\newcommand{\captiona}{{\em (a)}}
\newcommand{\captionb}{{\em (b)}}
\newcommand{\captionc}{{\em (c)}}
\newcommand{\captiond}{{\em (d)}}

\newcommand{\newterm}[1]{{\bf #1}}


\def\figref#1{figure~\ref{#1}}
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
\def\secref#1{section~\ref{#1}}
\def\Secref#1{Section~\ref{#1}}
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
\def\eqref#1{equation~\ref{#1}}
\def\Eqref#1{Equation~\ref{#1}}
\def\plaineqref#1{\ref{#1}}
\def\chapref#1{chapter~\ref{#1}}
\def\Chapref#1{Chapter~\ref{#1}}
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
\def\algref#1{algorithm~\ref{#1}}
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
\def\partref#1{part~\ref{#1}}
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}

\def\eps{{\epsilon}}


\def\reta{{\textnormal{}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}

\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

\newcommand{\pdata}{p_{\rm{data}}}
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}

\newcommand{\laplace}{\mathrm{Laplace}} 

\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}

\newcommand{\parents}{Pa} 

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Tr}{Tr}
\let\ab\allowbreak
 
\usepackage{pgf}

\usepackage{amssymb}\usepackage{pifont}\newcommand{\cmark}{\ding{51}}\newcommand{\xmark}{\ding{55}}

\setcounter{topnumber}{3}
\setcounter{bottomnumber}{2}
\setcounter{totalnumber}{4}
\renewcommand{\topfraction}{1}
\renewcommand{\bottomfraction}{1}
\renewcommand{\textfraction}{0.0}
\renewcommand{\floatpagefraction}{0.9}

\newcommand{\fpc}[1]{{\color{cyan}\textbf{FP:} #1}}
\newcommand{\odc}[1]{{\color{orange}\textbf{OD:} #1}}
\newcommand{\cbc}[1]{{\color{yellow!50!black}\textbf{CB:} #1}}
\newcommand{\hkc}[1]{{\color{purple}\textbf{HK:} #1}}
\newcommand{\tsc}[1]{{\color{green!70!black}\textbf{TS:} #1}}

\newcommand{\fp}[1]{{\color{cyan}#1}}
\newcommand{\od}[1]{{\color{orange}#1}}
\newcommand{\ods}[1]{{\color{orange}\st{#1}}}
\newcommand{\cb}[1]{{\color{magenta!70!black}#1}}


\newcommand{\revA}[1]{{#1}}
\newcommand{\revB}[1]{{#1}}
\newcommand{\revC}[1]{{#1}}
\newcommand{\revD}[1]{{#1}}


\newcommand{\theHalgorithm}{\arabic{algorithm}}
\usepackage[accepted]{icml2022}

\usepackage{printlen}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{model}[theorem]{Model}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}

\icmltitlerunning{Differentiable Top- Classification Learning}

\begin{document}

\twocolumn[
\icmltitle{Differentiable Top- Classification Learning}



\begin{icmlauthorlist}
\icmlauthor{Felix Petersen}{kn}
\icmlauthor{Hilde Kuehne}{f,m}
\icmlauthor{Christian Borgelt}{s}
\icmlauthor{Oliver Deussen}{kn}
\end{icmlauthorlist}

\icmlaffiliation{kn}{University of Konstanz}
\icmlaffiliation{s}{University of Salzburg}
\icmlaffiliation{f}{University of Frankfurt}
\icmlaffiliation{m}{MIT-IBM Watson AI Lab}

\icmlcorrespondingauthor{Felix Petersen}{felix.petersen@uni.kn}

\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]



\printAffiliationsAndNotice{}  



\begin{abstract}


The top- classification accuracy is one of the core metrics in machine learning.
Here,  is conventionally a positive integer, such as  or , leading to top- or top- training objectives.
In this work, we relax this assumption and optimize the model for multiple  simultaneously instead of using a single .
Leveraging recent advances in differentiable sorting and ranking, we propose a differentiable top- cross-entropy classification loss.
This allows training the network while not only considering the top- prediction, but also, e.g., the top- and top- predictions.  
We evaluate the proposed loss function for fine-tuning on state-of-the-art architectures, as well as for training from scratch.
We find that relaxing  does not only produce better top- accuracies, but also leads to top- accuracy improvements.
When fine-tuning publicly available ImageNet models, we achieve a new state-of-the-art for these models.





\end{abstract}














\section{Introduction}

Classification is one of the core disciplines in machine learning and computer vision.
The advent of classification problems with hundreds or even thousands of classes let the top- classification accuracy establish as an important metric, i.e., one of the top- classes has to be the correct class.
Usually, models are trained to optimize the top- accuracy; and top- etc.~are used for evaluation only.
Some works \citep{lapin2016loss,berrada2018smooth} have challenged this idea and proposed top- losses, such as a smooth top- margin loss.
These methods have demonstrated superior robustness over the established top- softmax cross-entropy in the presence of additional label noise \citep{berrada2018smooth}.
In standard classification settings, however, these methods have so far not shown improvements over the established top- softmax cross-entropy.

In this work, instead of selecting a single top- metric such as top- or top- for defining the loss,
we propose to specify  to be drawn from a distribution , which may or may not depend on the confidence of specific data points or on the class label.
Examples for distributions  are  ( top- and  top-),  ( top- and  top-), and  ( top- for each  from  to ).
\revC{Note that, when  is drawn from a distribution, this is done sampling-free as we can compute the expectation value in closed form.} 

Conventionally, given scores returned by a neural network, softmax produces a probability distribution over the top- rank.
Recent advances in differentiable sorting and ranking \citep{Grover2019-NeuralSort, prillo2020softsort, Cuturi2019-SortingOT, Petersen2021-diffsort} provide methods for generalizing this to  probability distributions over all ranks represented by a matrix .
Based on differentiable ranking, multiple differentiable top- operators have recently been proposed.
They found applications in differentiable -nearest neighbor algorithms, differentiable beam search, attention mechanisms, and differentiable image patch selection \citep{cordonnier2021differentiable}.
In these areas, integrating differentiable top- improved results considerably by creating a more natural end-to-end learning setting.
However, to date, none of the differentiable top- operators have been employed as neural network losses for top- classification learning with .

Building on differentiable sorting and ranking methods, we propose a new family of differentiable top- classification losses where  is drawn from a probability distribution.
We find that our top- losses improve not only top- accuracies, but 
also top- accuracy on multiple learning tasks.

We empirically evaluate our method using four differentiable sorting and ranking methods on the CIFAR-100 \citep{Krizhevsky2009_cifar10}, the ImageNet-1K \citep{deng2009imagenet}, and the ImageNet-21K-P \citep{ridnik2021imagenet} data sets.
Using CIFAR-100, we demonstrate the capabilities of our losses to train models from scratch.
On ImageNet-1K, we demonstrate that our losses are capable of fine-tuning existing models and achieve a new state-of-the-art for publicly available models on both top- and top- accuracy.
We benchmark our method on multiple recent models and demonstrate that our proposed method consistently outperforms the baselines for the best two differentiable sorting and ranking methods.
With ImageNet-21K-P, where many classes overlap (but only one is the ground truth), we demonstrate that our losses are scalable to more than  classes and achieve improvements of over  with only last layer fine-tuning.

Overall, while the performance improvements on fine-tuning are rather limited (because we retrain only the classification head), they are consistent and can be achieved without the large costs of training from scratch.
The absolute  improvement that we achieve on the ResNeXt-101 32x48d WSL top- accuracy corresponds to an error reduction by approximately , and can be achieved at much less than 
the computational cost of (re-)training the full model in the first place.  





We summarize our contributions as follows:
\vspace*{-.45em}
\begin{itemize}
\setlength{\itemindent}{-1.em}
\itemsep0pt
    \item We derive a novel family of top- cross-entropy losses and relax the assumption of a fixed .
    \item We find that they improve both top- and top- accuracy.
    \item We demonstrate that our losses are scalable to more than  classes.
    \item We propose splitter selection nets, which require fewer layers than existing selection nets.
    \item We achieve new state-of-the-art results (for publicly available models) on ImageNet1K.
\end{itemize}
\vspace*{-.5em}











\begin{figure*}[h]
    \centering
    \includegraphics[width=.975\linewidth]{fig/pipeline.pdf}
    \caption{
        Overview of the proposed architecture:
        A CNN predicts scores for an image, which are then ranked by a differentiable ranking algorithm returning the probability distribution for each rank in matrix .
        The rows of this distribution correspond to ranks, and the columns correspond to the respective classes.
        In the example, we use a  top- and  top- loss\revA{, i.e., . Here, the th value refers to the top- component, which is satisfied if the prediction is at \textit{any} of \hbox{rank-} to rank-.
        Thus, the weights for the different ranks can be computed via a cumulative sum and are .}
        The correspondingly weighted sum of rows of  yields the probability distribution~, which can then be used in a cross-entropy loss.  
        Photo by Chris Curry on Unsplash.
    }
    \label{fig:panda-overview}
\end{figure*}

\section[Background: Differentiable Sorting and Ranking]{Background: Differentiable Sorting and Ranking}

\label{sec:background-diff-sort-and-rank}

We briefly review NeuralSort, SoftSort, Optimal Transport Sort, and Differentiable Sorting Networks.
We omit the fast differentiable sorting and ranking method~\citep{Blondel2020-FastSorting} and the relaxed Bubble sort algorithm~\cite{petersen2021learning} as they do not provide relaxed permutation matrices / probability scores, but rather only sorted / ranked vectors.

\subsection{NeuralSort \& SoftSort}
\vspace*{-.25em}
To make the sorting operation differentiable, \citet{Grover2019-NeuralSort} proposed relaxing permutation matrices to unimodal row-stochastic matrices. 
For this, they use the softmax of pairwise differences of (cumulative) sums of the top elements.
They prove that this, for the temperature parameter approaching , is the correct permutation matrix, and propose a variety of deep learning differentiable sorting benchmark tasks.
They propose a deterministic softmax-based variant, as well as a Gumbel-Softmax variant of their algorithm. 
\revD{Note that NeuralSort is not based on sorting networks.}

\citet{prillo2020softsort} build on this idea but simplify the formulation and provide SoftSort, a faster alternative to NeuralSort.
They show that it is sufficient to build on pairwise differences of elements of the vectors to be sorted instead of the cumulative sums.
They find that SoftSort performs approximately equivalent in their experiments to NeuralSort.


\subsection{Optimal Transport / Sinkhorn Sort}
\citet{Cuturi2019-SortingOT} propose an entropy regularized optimal transport formulation of the sorting operation.
They solve this by applying the Sinkhorn algorithm~\citep{Cuturi13Sinkhorn} and produce gradients via automatic differentiation rather than the implicit function theorem, which resolves the need of solving a linear equation system.
As the Sinkhorn algorithm produces a relaxed permutation matrix, we can also apply Sinkhorn sort to top- classification learning.

\subsection{Differentiable Sorting Networks}
\citet{Petersen2021-diffsort} propose differentiable sorting networks, a continuous relaxation of sorting networks.
\revA{Sorting networks are a kind of sorting algorithm that consist of wires carrying the values and comparators, which swap the values on two wires if they are not in the desired order. 
Sorting networks can be made differentiable by perturbing the values on the wires in each layer of the sorting network by a logistic distribution, i.e., instead of  and  they use  and .}
Similar to the methods above, this method produces a relaxed permutation matrix, which allows us to apply it to top- classification learning.
The method has also been improved by enforcing monotonicity and bounding the approximation error~\cite{petersen2022monotonic}.
\revA{Note that sorting networks are a classic algorithmic concept~\citep{Knuth1998-3-SortingSearching}, are not neural networks nor refer to differentiable sorting.
Differentiable sorting networks are one of multiple differentiable sorting and ranking methods.
}







\section{Top- Learning}

In this section, we start by introducing our objective, elaborate its exact formulation, and then build on differentiable sorting principles to efficiently approximate the objective.
A visual overview over the loss architecture is also given in Figure~\ref{fig:panda-overview}.

The goal of top- learning is to extend the learning criterion from only accepting exact (top-) predictions to accepting  predictions among which the correct class has to be.
In its general form, for top- learning,  may differ for each application, class, data point, or a combination thereof. 
For example, in one case one may want to rank  predictions and assign a score that depends on the rank of the true class among these ranked predictions, while, in another case, one may want to obtain  predictions but does not care about their order.
In yet another case, such as image classification, one may want to enforce a top- accuracy on images from the ``person'' super-class, but resign to a top- accuracy for the ``animal'' super-class, as it may have more ambiguities in class-labels.
(For example, as recently shown by \citet{northcutt2021pervasive}, there is noise in the labels of ImageNet-1K. 
As ImageNet21K is a superset of ImageNet1K, it also holds in this case, with the addition that labeling in case of 21K classes would be more challenging and therefore more error-prone.)
We model this by a random variable~, following a distribution  that describes the relative importance of different values~. 
The discrete distribution  is either a marginalized distribution for a given setting (such as the uniform distribution), or a conditional distribution for each class, data point, etc. 
This allows specifying a marginalized or conditional distribution . 
This generalizes the ideas of conventional top- supervision (usually softmax cross-entropy) and top- supervision for a  like  (usually based on surrogate top- margin/hinge losses like \citep{lapin2016loss, berrada2018smooth}) and unifies them.

The objective of top- learning is maximizing the probability of accepted predictions of the model  on data  given marginal distribution  (or conditional  if it depends on the class  and/or data point ). In the following,  is the predicted probability of  being the th-best prediction for data point .

To evaluate the probability of  to be the top- prediction, we can simply use .
However,  requires more consideration. 
Here, we require probability scores  for the th prediction over classes , where  (i.e.,  is row stochastic) and ideally additionally  (i.e.,  is also column stochastic and thus doubly stochastic.)
With this, we can optimize our model by minimizing the following loss

which is the cross entropy over the probabilities that the true class is among the top- class for each possible~. 
Note that . 

If  is column stochastic, the inner sum in Equation~\ref{eq:top-k-learning-loss} is . 
As the sum over  is , the outer sum is also .
 being column stochastic is the desirable case. This is given for DiffSortNets and SinkhornSort. However, for SoftSort and NeuralSort, this is only approximately the case.
In the non-column stochastic case of SoftSort and NeuralSort, the inner sum could become greater than ; however, we did not observe this to be a direct problem.


To compute , we require a function mapping from a vector of real-valued scores to an (ideally) doubly stochastic matrix .
The most suitable for this are the differentiable relaxations of the sorting and ranking functions, which produce differentiable permutation matrices , which we introduced in Section~\ref{sec:background-diff-sort-and-rank}.
We build on these approximations to propose instances of top- learning losses and extend differentiable sorting networks to differentiable top- networks, as just finding the top- scores is computationally cheaper than sorting all elements and reduces the approximation error.



\subsection{Top- Probability Matrices}

The discussed differentiable sorting algorithms produce relaxed permutation matrices of size .
However, for top- classification learning, we require only the top  rows for the number  of top-ranked classes to consider.
\revC{Here,  is the largest  that is considered for the objective, i.e., where .}
As , producing a  matrix instead of a  matrix is much faster.


For \textit{NeuralSort and SoftSort}, it is possible to simply compute only the top rows, as the algorithm is defined row-wise. 

For the \textit{differentiable Sinkhorn sorting algorithm}, it is not directly possible to improve the runtime, as in each Sinkhorn iteration the full matrix is required. 
\citet{xie2020differentiable} proposed a Sinkhorn-based differentiable top- operator, which
computes a  matrix where the first row corresponds to the top- elements and the second row correspond to the remaining elements. However, this formulation does not produce  and does not distinguish between the placements
of the top- elements among each other, and thus we use the SinkhornSort algorithm by \citet{Cuturi2019-SortingOT}.

For \textit{differentiable sorting networks}, it is (via a bi-directional evaluation) possible to reduce the cost from  to . 
Here, it is important to note the shape and order of multiplications for obtaining . 
As we only need those elements, which are (after the last layer of the sorting network) at the top  ranks that we want to consider, we can omit all remaining rows of the permutation matrix of the last layer (layer ) and thus it is only of size .

Note that during execution of the sorting network,  is conventionally computed from layer  to layer , i.e., from right to left.
If we computed it in this order, we would only save a tiny fraction of the computational cost and only during the last layer.
Thus, we propose to execute the differentiable sorting network, save the values that populate the (sparse)  layer-wise permutation matrices, and compute  in a second pass from the back to the front, i.e., from layer  to layer , or from left to right in Equation~\ref{eq:shapes-diffsort-topk}.
This allows executing  dense-sparse matrix multiplications with dense  matrices and sparse  matrices instead of dense  and sparse  matrices. 
With this, we reduce the asymptotic complexity from  to .
 




\subsection{Differentiable Top- Networks}

As only the top- rows of a relaxed permutation matrix are required for top- classification learning, it is possible to improve the efficiency of computing the top- probability distribution via differentiable sorting networks by reducing the number of differentiable layers and comparators.
Thus, we propose differentiable top- networks, which relax selection networks in analogy to how differentiable sorting networks relax sorting networks.
Selection networks are networks that select only the top- out of  elements \citep{Knuth1998-3-SortingSearching}.
We propose splitter selection networks (SSN), a novel class of selection networks that requires only  layers (instead of the  layers for sorting networks) which makes top- supervision with differentiable top- networks more efficient and reduces the error (which is introduced in each layer.)
SSNs follow the idea that the input is split into locally sorted sublists and then all wires that are not candidates to be among the global top- can be eliminated.
For example, for , SSNs require only  layers, while the best previous selection network requires  layers and full sorting (with a bitonic network) requires even  layers. 
For  (i.e., for ImageNet-21K-P), SNNs require  layers, the best previous requires  layers, and full sorting requires  layers.
In addition, the layers of SSNs are less computationally expensive than those of the bitonic sorting network.
Details on SSNs, as well as their full construction, can be found in Supplementary Material~\ref{apx:ssn}.
Concluding, the contribution of differentiable top- networks is two-fold: first, we propose a novel kind of selection networks that needs fewer layers, and second, we relax those similarly to differentiable sorting networks.


\subsection{Implementation Details}
\label{sec:implementation_details}

Despite those performance improvements, evaluating the differentiable ranking operators still requires a considerable amount of computational effort for large numbers of classes. 
Especially if the number  of elements to be ranked is  (ImageNet-1K) or even  (ImageNet-21K-P), the differentiable ranking operators can dominate the overall computational costs.
In addition, for large numbers  of elements to be ranked, the performance of differentiable ranking operators decreases as differentially ranking more elements naturally introduces larger errors \citep{Grover2019-NeuralSort,prillo2020softsort,Cuturi2019-SortingOT,Petersen2021-diffsort}.
Thus, we reduce the number of outputs to be ranked differentially by only considering those classes (for each input) that have a score among the top- scores.
For this, we make sure that the ground truth class is among those top- scores, by replacing the lowest of the top- scores by the ground truth class, if necessary.
For , we choose , and for , we choose .
We find that this greatly improves training performance.

Because the differentiable ranking operators are (by their nature of being differentiable) only approximations to the hard ranking operator, they each have their characteristics and inconsistencies.
Thus, for training models from scratch, we replace the top- component of the loss by the regular softmax, which has a better and more consistent behavior.
This guides the other loss if the differentiable ranking operator behaves inconsistently.
To avoid the top- components affecting the guiding softmax component and avoid probabilities greater than  in , we can separate the cross-entropy into a mixture of the softmax cross-entropy (, for the top- component) and the top- cross-entropy (, for the top- components) as follows: 

-0.7ex]
    &{-} (1-P_K(1)) \cdot \log\!\left( \sum_{k=2}^n P_K(k) \left(\sum_{m=1}^k \mP_{m, y}(f_\Theta (X)) \right)\!\!\right) \notag .2em]
Smooth\,top- loss   &      &  \\
Top- NeuralSort          &      &  \\
Top- SoftSort            &      &    \\
Top- SinkhornSort        &      &  \\
Top- DiffSortNets        &      &  \\
\midrule
\underline{\textit{Ours}}\\
Top- NeuralSort          &    & \\   Top- SoftSort            &    & \\   Top- SinkhornSort        &    & \\   Top- DiffSortNets        &    & \\   \bottomrule
    \end{tabular}
    }
    \addtolength{\tabcolsep}{4pt}  
    \vspace*{-.25em}
    \caption{
        CIFAR-100 results for training a ResNet18 from scratch.
        The metrics are Top-Top- accuracy averaged over 2 seeds.
        :~\citet{berrada2018smooth}.
    }
    \label{tab:cifar100-main}
    \vspace*{-2em}
\end{table}





\subsection{Training from Scratch}

We start by demonstrating that the proposed loss can be used to train a network from scratch. 
As a reference baseline, we train a ResNet18 from scratch on CIFAR-100.
In Table~\ref{tab:cifar100-main}, we compare the baselines (i.e., top- softmax, the smooth top- loss \citep{berrada2018smooth}, as well as ``pure'' top- losses using four differentiable sorting and ranking methods) with our top- loss with .

We find that training with top- alone|in some cases|slightly improves the top- but has a substantially worse top- accuracy.
Here, we note that the smooth top- loss \citep{berrada2018smooth}, top- Sinkhorn \citep{Cuturi2019-SortingOT}, and top- DiffSort \citep{Petersen2021-diffsort} are able to achieve good performance.
Notably, Sinkhorn \citep{Cuturi2019-SortingOT} outperforms the softmax baseline on the top- metric, while NeuralSort and SoftSort are less stable and yield worse results especially on top- accuracy. 

By using our loss that corresponds to drawing  from , we can achieve substantially improved results, especially also on the top- accuracy metric.
Using the DiffSortNets yields the best results on the top- accuracy and Sinkhorn yields the best results on the top- accuracy.
Note that, here, also NeuralSort and SoftSort achieve good results in this setting, which can be attributed to our loss with  being more robust to inconsistencies and outliers in the used differentiable sorting method.
Interestingly, top- SinkhornSort achieves the best performance on the top- metric, which suggests that SinkhornSort is a very robust differentiable sorting method as it does not require additional top- components.
Nevertheless, it is advisable to include other top- components as the model trained purely on top- exhibits poor top- performance.

\begin{table}[t]
    \centering
    \addtolength{\tabcolsep}{-4pt}  
    \resizebox{\linewidth}{!}{
    \begin{tabular}{lccc}
\toprule
Method &   &  {ImgNet-1K} & \kern-.25emImgNet-21K-P\\
\midrule
\underline{\textit{Baselines}}\\
Softmax                     &      &  &  \\displaystyle {0.0}\displaystyle {0.2}\displaystyle {0.4}\displaystyle {0.6}\displaystyle {0.8}\displaystyle {1.0}\displaystyle \alpha\displaystyle P_K=[1-\alpha, 0, 0, 0, \alpha]\displaystyle {0.857}\displaystyle {0.858}\displaystyle {0.859}\displaystyle {0.860}\displaystyle {0.861}\displaystyle {0.862}\displaystyle {0.863}\displaystyle 1\displaystyle 1\displaystyle 5\displaystyle {0.9786}\displaystyle {0.9788}\displaystyle {0.9790}\displaystyle {0.9792}\displaystyle {0.9794}\displaystyle {0.9796}\displaystyle {0.9798}\displaystyle {0.9800}\displaystyle 5\displaystyle {10}\displaystyle {15}\displaystyle {20}\displaystyle {25}\displaystyle {30}\displaystyle {35}\displaystyle {40}\displaystyle m\displaystyle {0.858}\displaystyle {0.859}\displaystyle {0.860}\displaystyle {0.861}\displaystyle {0.862}\displaystyle 1\displaystyle 1\displaystyle 5\displaystyle {0.9775}\displaystyle {0.9780}\displaystyle {0.9785}\displaystyle {0.9790}\displaystyle {0.9795}\displaystyle {0.9800}\displaystyle 5\displaystyle {250}\displaystyle {500}\displaystyle {750}\displaystyle {84.0}\displaystyle {84.5}\displaystyle {85.0}\displaystyle {85.5}\displaystyle {86.0}\displaystyle {250}\displaystyle {500}\displaystyle {750}\displaystyle {97.2}\displaystyle {97.4}\displaystyle {97.6}\displaystyle {97.8}\displaystyle {98.0}}\end{pgfscope}\begin{pgfscope}\definecolor{textcolor}{rgb}{0.000000,0.000000,0.000000}\pgfsetstrokecolor{textcolor}\pgfsetfillcolor{textcolor}\pgftext[x=4.726543in,y=1.957562in,,top,rotate=90.000000]{\color{textcolor}\rmfamily\fontsize{10.000000}{12.000000}\selectfont Top-5 acc.}\end{pgfscope}\begin{pgfscope}\pgfpathrectangle{\pgfqpoint{2.575000in}{0.565123in}}{\pgfqpoint{1.751851in}{2.784877in}}\pgfusepath{clip}\pgfsetrectcap \pgfsetroundjoin \pgfsetlinewidth{1.505625pt}\definecolor{currentstroke}{rgb}{0.415686,0.705882,0.176471}\pgfsetstrokecolor{currentstroke}\pgfsetdash{}{0pt}\pgfpathmoveto{\pgfqpoint{4.247222in}{2.648733in}}\pgfpathlineto{\pgfqpoint{3.467045in}{2.533353in}}\pgfpathlineto{\pgfqpoint{2.880301in}{1.756756in}}\pgfpathlineto{\pgfqpoint{2.654630in}{0.691709in}}\pgfusepath{stroke}\end{pgfscope}\begin{pgfscope}\pgfpathrectangle{\pgfqpoint{2.575000in}{0.565123in}}{\pgfqpoint{1.751851in}{2.784877in}}\pgfusepath{clip}\pgfsetbuttcap \pgfsetroundjoin \definecolor{currentfill}{rgb}{0.415686,0.705882,0.176471}\pgfsetfillcolor{currentfill}\pgfsetlinewidth{1.003750pt}\definecolor{currentstroke}{rgb}{0.415686,0.705882,0.176471}\pgfsetstrokecolor{currentstroke}\pgfsetdash{}{0pt}\pgfsys@defobject{currentmarker}{\pgfqpoint{-0.041667in}{-0.041667in}}{\pgfqpoint{0.041667in}{0.041667in}}{\pgfpathmoveto{\pgfqpoint{0.000000in}{-0.041667in}}\pgfpathcurveto{\pgfqpoint{0.011050in}{-0.041667in}}{\pgfqpoint{0.021649in}{-0.037276in}}{\pgfqpoint{0.029463in}{-0.029463in}}\pgfpathcurveto{\pgfqpoint{0.037276in}{-0.021649in}}{\pgfqpoint{0.041667in}{-0.011050in}}{\pgfqpoint{0.041667in}{0.000000in}}\pgfpathcurveto{\pgfqpoint{0.041667in}{0.011050in}}{\pgfqpoint{0.037276in}{0.021649in}}{\pgfqpoint{0.029463in}{0.029463in}}\pgfpathcurveto{\pgfqpoint{0.021649in}{0.037276in}}{\pgfqpoint{0.011050in}{0.041667in}}{\pgfqpoint{0.000000in}{0.041667in}}\pgfpathcurveto{\pgfqpoint{-0.011050in}{0.041667in}}{\pgfqpoint{-0.021649in}{0.037276in}}{\pgfqpoint{-0.029463in}{0.029463in}}\pgfpathcurveto{\pgfqpoint{-0.037276in}{0.021649in}}{\pgfqpoint{-0.041667in}{0.011050in}}{\pgfqpoint{-0.041667in}{0.000000in}}\pgfpathcurveto{\pgfqpoint{-0.041667in}{-0.011050in}}{\pgfqpoint{-0.037276in}{-0.021649in}}{\pgfqpoint{-0.029463in}{-0.029463in}}\pgfpathcurveto{\pgfqpoint{-0.021649in}{-0.037276in}}{\pgfqpoint{-0.011050in}{-0.041667in}}{\pgfqpoint{0.000000in}{-0.041667in}}\pgfpathclose \pgfusepath{stroke,fill}}\begin{pgfscope}\pgfsys@transformshift{4.247222in}{2.648733in}\pgfsys@useobject{currentmarker}{}\end{pgfscope}\begin{pgfscope}\pgfsys@transformshift{3.467045in}{2.533353in}\pgfsys@useobject{currentmarker}{}\end{pgfscope}\begin{pgfscope}\pgfsys@transformshift{2.880301in}{1.756756in}\pgfsys@useobject{currentmarker}{}\end{pgfscope}\begin{pgfscope}\pgfsys@transformshift{2.654630in}{0.691709in}\pgfsys@useobject{currentmarker}{}\end{pgfscope}\end{pgfscope}\begin{pgfscope}\pgfpathrectangle{\pgfqpoint{2.575000in}{0.565123in}}{\pgfqpoint{1.751851in}{2.784877in}}\pgfusepath{clip}\pgfsetrectcap \pgfsetroundjoin \pgfsetlinewidth{1.505625pt}\definecolor{currentstroke}{rgb}{0.901961,0.188235,0.098039}\pgfsetstrokecolor{currentstroke}\pgfsetdash{}{0pt}\pgfpathmoveto{\pgfqpoint{4.247222in}{3.223415in}}\pgfpathlineto{\pgfqpoint{3.467045in}{3.027047in}}\pgfpathlineto{\pgfqpoint{2.880301in}{2.467897in}}\pgfpathlineto{\pgfqpoint{2.654630in}{1.441679in}}\pgfusepath{stroke}\end{pgfscope}\begin{pgfscope}\pgfpathrectangle{\pgfqpoint{2.575000in}{0.565123in}}{\pgfqpoint{1.751851in}{2.784877in}}\pgfusepath{clip}\pgfsetbuttcap \pgfsetmiterjoin \definecolor{currentfill}{rgb}{0.901961,0.188235,0.098039}\pgfsetfillcolor{currentfill}\pgfsetlinewidth{1.003750pt}\definecolor{currentstroke}{rgb}{0.901961,0.188235,0.098039}\pgfsetstrokecolor{currentstroke}\pgfsetdash{}{0pt}\pgfsys@defobject{currentmarker}{\pgfqpoint{-0.041667in}{-0.041667in}}{\pgfqpoint{0.041667in}{0.041667in}}{\pgfpathmoveto{\pgfqpoint{0.000000in}{0.041667in}}\pgfpathlineto{\pgfqpoint{-0.041667in}{-0.041667in}}\pgfpathlineto{\pgfqpoint{0.041667in}{-0.041667in}}\pgfpathclose \pgfusepath{stroke,fill}}\begin{pgfscope}\pgfsys@transformshift{4.247222in}{3.223415in}\pgfsys@useobject{currentmarker}{}\end{pgfscope}\begin{pgfscope}\pgfsys@transformshift{3.467045in}{3.027047in}\pgfsys@useobject{currentmarker}{}\end{pgfscope}\begin{pgfscope}\pgfsys@transformshift{2.880301in}{2.467897in}\pgfsys@useobject{currentmarker}{}\end{pgfscope}\begin{pgfscope}\pgfsys@transformshift{2.654630in}{1.441679in}\pgfsys@useobject{currentmarker}{}\end{pgfscope}\end{pgfscope}\begin{pgfscope}\pgfsetrectcap \pgfsetmiterjoin \pgfsetlinewidth{0.803000pt}\definecolor{currentstroke}{rgb}{0.000000,0.000000,0.000000}\pgfsetstrokecolor{currentstroke}\pgfsetdash{}{0pt}\pgfpathmoveto{\pgfqpoint{2.575000in}{0.565123in}}\pgfpathlineto{\pgfqpoint{2.575000in}{3.350000in}}\pgfusepath{stroke}\end{pgfscope}\begin{pgfscope}\pgfsetrectcap \pgfsetmiterjoin \pgfsetlinewidth{0.803000pt}\definecolor{currentstroke}{rgb}{0.000000,0.000000,0.000000}\pgfsetstrokecolor{currentstroke}\pgfsetdash{}{0pt}\pgfpathmoveto{\pgfqpoint{4.326851in}{0.565123in}}\pgfpathlineto{\pgfqpoint{4.326851in}{3.350000in}}\pgfusepath{stroke}\end{pgfscope}\begin{pgfscope}\pgfsetrectcap \pgfsetmiterjoin \pgfsetlinewidth{0.803000pt}\definecolor{currentstroke}{rgb}{0.000000,0.000000,0.000000}\pgfsetstrokecolor{currentstroke}\pgfsetdash{}{0pt}\pgfpathmoveto{\pgfqpoint{2.575000in}{0.565123in}}\pgfpathlineto{\pgfqpoint{4.326851in}{0.565123in}}\pgfusepath{stroke}\end{pgfscope}\begin{pgfscope}\pgfsetrectcap \pgfsetmiterjoin \pgfsetlinewidth{0.803000pt}\definecolor{currentstroke}{rgb}{0.000000,0.000000,0.000000}\pgfsetstrokecolor{currentstroke}\pgfsetdash{}{0pt}\pgfpathmoveto{\pgfqpoint{2.575000in}{3.350000in}}\pgfpathlineto{\pgfqpoint{4.326851in}{3.350000in}}\pgfusepath{stroke}\end{pgfscope}\end{pgfpicture}\makeatother \endgroup  }
    \vspace{-2em}
    \caption{
        ImageNet-1K accuracy improvements for all ResNeXt-101 WSL model sizes (32x8d, 32x16d, 32x32d, 32x48d). Green () is the original model and red () is with top- fine-tuning.
        }
    \label{fig:resnext-wsl-different-model-sizes-improvements-plot}
    \vspace*{-1em}
\end{figure}

\subsection{Fine-Tuning}

In this section, we discuss the results for fine-tuning on ImageNet-1K and ImageNet-21K-P.
In Table~\ref{tab:imagenet-main}, we find a very similar behavior to training from scratch on CIFAR-100.
Specifically, we find that training accuracies improve by drawing  from a distribution. 
An exception is (again) SinkhornSort, where focussing only on top- yields the best top- accuracy on ImageNet-1K, but the respective model exhibits poor top- accuracy.
Overall, we find that drawing  from a distribution improves performance in all cases.

To demonstrate that the improvements also translate to different backbones, we show the improvements on all four model sizes of ResNeXt-101 WSL (32x8d, 32x16d, 32x32d, 32x48d) in Figure~\ref{fig:resnext-wsl-different-model-sizes-improvements-plot}.
Also, here, our method improves the model in all settings.





\subsection{Impact of the Distribution  and Differentiable Sorting Methods}

We start by demonstrating the impact of , which is the distribution from which we draw .
Let us first consider the case where  is  with probability  and  with probability , i.e., .
In Figure~\ref{fig:top1-vs-top5-loss-plot} (left), we demonstrate the impact that changing , i.e., transitioning from a pure top- loss to a pure top- loss, has on fine-tuning ResNeXt-101 WSL with our loss using the SinkhornSort algorithm.
Increasing the weight of the top- component does not only increase the top- accuracy but also improves the top- accuracy up to around  top-; when using only , the top- accuracy drastically decays as the incentive for the true class to be at the top- position vanishes (or is only indirectly given by being among the top-.)
While the top- accuracy in this plot is best for a pure top- loss, this generally only applies to the Sinkhorn algorithm and overall training is more stable if a pure top- is avoided. 
This can also be seen in Tables~\ref{tab:cifar100-main} and~\ref{tab:imagenet-main}.

In Tables~\ref{tab:imagenet-different-PK} and \ref{tab:cifar100-different-PK}, we consider more additional settings with all differentiable ranking methods.
Specifically, we compare four notable settings:
, i.e., equally weighted top- and top-;  and , i.e., top- has larger weights; , i.e., the case of having an equal weight of  for top- to top-.
The  setting is a rather canonical setting which usually performs well on both metrics, while the others tend to favor top-.
In the  setting, all sorting methods improve upon the softmax baseline on both top- and top- accuracy.
When increasing the weight of the top- component, the top- generally improves while top- decays.

Here we find a core insight of this paper: the best performance cannot be achieved by optimizing top- for only a single , but instead, drawing  from a distribution improves performance on all metrics.

Comparing the differentiable ranking methods, we can find the overall trend that SoftSort outperforms NeuralSort, and that SinkhornSort as well as DiffSortNets perform best.
We can see that some sorting algorithms are more sensitive to the overall  than others:
Whereas SinkhornSort \citep{Cuturi2019-SortingOT} and DiffSortNets \citep{Petersen2021-diffsort} continuously outperform the softmax baseline, NeuralSort \citep{Grover2019-NeuralSort} and SoftSort \citep{prillo2020softsort} tend to collapse when over-weighting the top- components.




Comparing the performance on the medium-scale ImageNet-1K to the larger ImageNet-21K-P in Table~\ref{tab:imagenet-main}, we observe a similar pattern. 
Here, again, using the top- component alone is not enough to significantly increase accuracy, but combining top- and top- components helps to improve accuracy on both reported metrics. 
While NeuralSort struggles in this large-scale ranking problem and stays below the softmax baseline, DiffSortNets~\citep{Petersen2021-diffsort} provide the best top- and top- accuracy with  and , respectively.

In Supplementary Material~\ref{apx:extension-10-20}, an extension to learning with top- and top- components can be found. 

We note that we do not claim that all settings (especially all differentiable sorting methods) improve the classification performance on all metrics. 
Instead, we include all methods and also additional settings to demonstrate the capabilities and limitations of each differentiable sorting method.

Overall, it is notable that SinkhornSort achieves the overall most robust training behavior, while also being by far the slowest sorting method and thus potentially slowing down training drastically, especially when the task is only fine-tuning.
SinkhornSort tends to require more Sinkhorn iterations towards the end of training.
DiffSortNets are considerably faster, especially, it is possible to only compute the top- probability matrices and because of our advances for more efficient selection networks.







\begin{table}[t]
    \centering
    \addtolength{\tabcolsep}{-4pt}  
    \resizebox{\linewidth}{!}{
    \begin{tabular}{lcccc}
\toprule
Method~/~    & {\small} & {\small} & {\small} & {\small}\\
\midrule
\textit{ImageNet-1K}\\
NeuralSort          &   &    &    &  \\
SoftSort            &   &    &    &  \\
SinkhornSort        &   &    &    &  \\  DiffSortNets        &   &    &    &  \\  \midrule
\textit{ImageNet-21K-P}\kern-5em\\
NeuralSort          &   &    &    &  \\
SoftSort            &   &    &    &  \\
SinkhornSort        &   &    &    &  \\
DiffSortNets        & \pmb{}  &    &    &  \\  \bottomrule
    \end{tabular}
    }
    \addtolength{\tabcolsep}{4pt}  
    \vspace*{-.5em}
    \caption{
        ImageNet-1K and ImageNet-21K-P results for different distributions  for fine-tuning the head of ResNeXt-101 32x48d WSL \citep{mahajan2018exploring}.
        The metrics are Top-Top- accuracy averaged over 10 seeds for ImageNet-1K and 2 seeds for ImageNet-21K-P.
    }
    \label{tab:imagenet-different-PK}
    \vspace*{-1em}
\end{table}








\subsection{Differentiable Ranking Set Size }
We consider how accuracy is affected by varying the number of scores  to be differentially ranked. 
Generally, the runtime of differentiable top- operators depends between linearly and cubic on ; thus it is important to choose an adequate value for .
The choice of  between  and  has only a moderate impact on the accuracy as can be seen in Figure~\ref{fig:different-ms-plot} (right).
However, when setting  to large values such as  or larger, we observe that the differentiable sorting methods tend to become unstable.
We note that we did not specifically tune , and that better performance can be achieved by fine-tuning , as displayed in the plot.



\begin{table}[t]
    \centering
    \addtolength{\tabcolsep}{-4pt}  
    \resizebox{\linewidth}{!}{
    \begin{tabular}{lcccc}
\toprule
Method~/~    & {\small} & {\small} & {\small} & {\small}\\
\midrule
\textit{CIFAR-100}\kern-5em\\
NeuralSort          &    &    &    &  \\   SoftSort            &    &    &    &  \\   SinkhornSort        &    &    &    &  \\   DiffSortNets        &    &    &    &  \\   \bottomrule
    \end{tabular}
    }
    \addtolength{\tabcolsep}{4pt}  
    \vspace*{-.5em}
    \caption{
        CIFAR-100 results for different distributions  for training a ResNet18 from scratch.
        The metrics are Top-Top- accuracy averaged over 2 seeds.
    }
    \label{tab:cifar100-different-PK}
    \vspace*{-.25em}
\end{table}


\begin{table}[t]
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{llrcc}
    \toprule
        Method & & \kern-1.5em Public & Top- & Top-  \\
    \midrule
        ResNet50 &                                      & \cmark &    &  \\
        ResNet152 &                                     & \cmark &    &  \\
        ResNeXt-101 32x48d WSL &              & \cmark & 	 &  \\
        ViT-L/16 &                            & \cmark &   & ---   \\
        Noisy Student EfficientNet-L2 &                & \cmark & \pmb{}   & \pmb{} \\ 
        \midrule
        BiT-L   &                                & \xmark &   &   \\
        CLIP (w/ Noisy Student EffNet-L2) &    & \xmark &     & --- \\ 
        ViT-H/14 &                            & \xmark &   & ---   \\
        ALIGN (EfficientNet-L2) &                   & \xmark &    & \pmb{} \\
        Meta Pseudo Labels (EffNet-L2)\kern-.5em &        & \xmark &   &   \\
        ViT-G/14 &                                 & \xmark &   & ---   \\
        CoAtNet-7 &                                 & \xmark & \pmb{}   & --- \\
    \midrule
        ResNeXt-101 32x48d WSL &&&  &  \\ 
        Top- SinkhornSort                                                &&& \pmb{} &  \\ Top- DiffSortNets                                                &&&  & \pmb{} \\
    \midrule
        Noisy Student EfficientNet-L2  &&&  &  \\ 
        Top- SinkhornSort                                                &&&  &  \\
        Top- DiffSortNets                                                &&& \pmb{} & \pmb{} \\
    \bottomrule
    \end{tabular}
    }
    \vspace*{-.5em}
    \caption{
        ImageNet-1K result comparison to state-of-the-art.
        Among the overall best performing differentiable sorting / ranking methods, almost all results in reasonable settings outperform their respective baseline on Top- and Top- accuracy.
        For publicly available models / backbones, we achieve a new state-of-the-art for top- and top- accuracy. Our results are averaged over  runs.
        :~\citet{he2016deep_resnet}, 
        :~\citet{mahajan2018exploring}, 
        :~\citet{dosovitskiy2021image}, 
        :~\citet{xie2020self}, 
        :~\citet{kolesnikov2020big}, 
        :~\citet{radford2021learning}, 
        :~\citet{dosovitskiy2021image}, 
        :~\citet{jia2021scaling}, 
        :~\citet{pham2021meta}, 
        :~\citet{zhai2021scaling}, 
        :~\citet{dai2021coatnet}.
    }
    \label{tab:sota}
\end{table}



\subsection{Comparison to the State-of-the-Art}


We compare the proposed results to current state-of-the-art methods in Table~\ref{tab:sota}. 
We focus on methods that are publicly available and build upon two of the best performing models, namely Noisy Student EfficientNet-L2 \citep{xie2020self}, and ResNeXt-101 32x48d WSL \citep{mahajan2018exploring}.
Using both backbones, we achieve improvements on both metrics, and when fine-tuning on the Noisy Student EfficientNet-L2, we achieve a new state-of-the-art for publicly available models.


\paragraph{Significance Tests.} To evaluate the significance of the results, we perform a -test (with significance level of ).
We find that our model is significantly better than the original model on both top- and top- accuracy metrics. 
Comparing to the observed accuracies of the baseline (), DiffSortNets are significantly better (p=). 
Comparing to the reported accuracies of the baseline (), DiffSortNets are also significantly better (p=).













\section{Conclusion}

We presented a novel loss, which relaxes the assumption of using a fixed  for top- classification learning.
For this, we leveraged recent differentiable sorting and ranking operators.
We performed an array of experiments to explore different top- classification learning settings and achieved a state-of-the-art on ImageNet for publicly available models.

\subsection*{Acknowledgments \& Funding Disclosure}

This work was supported by 
the IBM-MIT Watson AI Lab, 
the DFG in the Cluster of Excellence EXC 2117 ``Centre for the Advanced Study of Collective Behaviour'' (Project-ID 390829875),
and the Land Salzburg within the WISS 2025 project IDA-Lab (20102-F1901166-KZP and 20204-WISS/225/197-2019).























  





















  





















































\bibliography{manual}
\bibliographystyle{icml2022}


\newpage
\appendix




\section{Extension to Top-10 and Top-20}
\label{apx:extension-10-20}

We further extend the training settings, measuring the impact of top- and top- components on the large-scale ImageNet-21K-P dataset. 
The results are diplayed in Table~\ref{tab:imagenet-21k-p-top-10-top-20}, where we report top-, top-, top-, and top- accuracy for all configurations. 
Again, we observe that  top- and  top- produces the overall best performance and that training with top- yields the best top-, top-, and top- accuracy.
We observe that the performance decays for top- components because (even among  classes) there are virtually no top- ambiguities, and artifacts of differentiable sorting methods can cause adverse effects.
Note that top- ambiguities do exist in ImageNet-21K-P, e.g., there are  class hierarchy levels \cite{ridnik2021imagenet}.


\begin{table*}[h]
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{lcccccccccccccccccccc}
\toprule
\textit{IN-21K-P}~~/~~ \kern-1.5em  &    &    &     &   \\
\midrule
Softmax   (baseline)                         &  \kern-4em  &  ---  &  ---  &  ---\\
NeuralSort      &  ---  &    &    &  \\  
SoftSort           &  ---  &    &    &  \\   
SinkhornSort     &  ---  &    &    &  \\
DiffSortNets    &  ---  &    &    &  \\ \bottomrule
\toprule
\textit{IN-21K-P}~~/~~ \kern-1.5em  &    &    &     &   \\
\midrule
Softmax   (baseline)                         &  \kern-4em  &  ---  &  ---  &  ---\\
NeuralSort      &  ---  &    &    &  \\
SoftSort           &  ---  &    &    &  \\
SinkhornSort     &  ---  &    &    &  \\
DiffSortNets    &  ---  &    &    &  \\
\bottomrule
\toprule
\textit{IN-21K-P}~~/~~ \kern-1.5em  &    &    &     &   \\
\midrule
Softmax   (baseline)                         &  \kern-4em  &  ---  &  ---  &  ---\\
NeuralSort      &  ---  &    &    &  \\
SoftSort           &  ---  &    &    &  \\
SinkhornSort     &  ---  &    &    &  \\
DiffSortNets    &  ---  &    &    &  \\
\bottomrule
    \end{tabular}
    }
    \caption{ImageNet 21K with top-, top- and top- components.
    The displayed metrics per column are (Top-Top-Top-Top-).
    }
    \label{tab:imagenet-21k-p-top-10-top-20}
\end{table*}



\section{Splitter Selection Networks}
\label{apx:ssn}

Similar to a sorting network, a \emph{selection network} is generally
a comparator network and hence it consists of wires (or lanes) carrying
values and comparators (or conditional swap devices) connecting pairs
of wires. A comparator swaps the values on the wires it connects if they
are not in a desired order. However, in contrast to a sorting network,
which sorts all the values carried by its wires, a  selection
network, which has  wires, moves the  largest (or, alternatively,
the  smallest) values to a specific set of wires \citep{Knuth1998-3-SortingSearching},
most conveniently consecutive wires on one side of the wire array.
Note that the notion of a selection network usually does not require
that the selected values are sorted. However, in our context it is
preferable that they are, so that  can easily be applied, and
the selection networks discussed below all have this property.

Clearly, any sorting network could be used as a selection network,
namely by focusing only on the top~ (or bottom~) wires. However,
especially if  is small compared to~, it is possible to construct
selection networks with smaller size (i.e.\ fewer comparators) and often
lower depth (i.e.\ a smaller number of layers, where a layer is a set of
comparators that can be executed in parallel).

A core idea of constructing selection networks was proposed in
\citep{Wah_and_Chen_1984}, based on the odd-even merge and bitonic sorting
networks \citep{Batcher_1968}: partition the ~wires into subsets of at
least~ wires (preferably  wires per subset)
and sort each subset with odd-even mergesort. Then merge the (sorted)
top~ elements of each subsets with bitonic merge, thus halving the
number of (sorted) subsets. Repeat merging pairs of (sorted) subsets
until only a single (sorted) subset remains, the top  elements of
which are the desired selection. This approach requires
 layers.

Improvements to this basic scheme were developed in
\citep{Zazon-Ivry_and_Codish_2012,Karpinski_and_Piotrow_2015} and either rely
entirely on odd-even merge \citep{Batcher_1968} or entirely on pairwise
sorting networks \citep{Parberry_1992}. Especially selection networks based on
pairwise sorting networks have advantages in terms of the size of the
resulting network (i.e.\ number of needed comparators). However, these
improvements do not change the depth of the networks, that is, the
number of layers, which is most important in the context considered
here.



\begin{figure*}[t]
\centering
\includegraphics[width=.2\linewidth]{fig/topk-1}\hfill
\includegraphics[width=.2\linewidth]{fig/topk-3}\hfill
\includegraphics[width=.2\linewidth]{fig/topk-5}\hfill
\includegraphics[width=.2\linewidth]{fig/topk-6}
\caption{\label{fig:splitter}Minimum ranks after a splitter cascade
  resulting from the transitive closure of the swaps.}
\end{figure*}


Our own selection network construction draws on this work by focussing
on a specific ingredient of pairwise sorting networks, namely a
so-called splitter (which happens to be identical to a single
bitonic merge layer, but for our purposes it is more comprehensible to
refer to it as a splitter). A~splitter for a list of ~wires having
indices~ has comparators connecting
wires~ and  where 
for .

A pairwise sorting network starts with what we
call a {\em splitter cascade}. That is, an initial splitter
partitions the input wires into subsets of (roughly) equal size.
Each subset is split recursively until wire singletons result
\citep{Zazon-Ivry_and_Codish_2012}. An example of such a splitter cascade is
shown in Figure~\ref{fig:splitter} for 8~wires and in purple color for
16 wires in Figure~\ref{fig:selnet}
(arrows point to where the larger value is desired).


\begin{figure*}[t]
\centering
\includegraphics{fig/topk-0}
\caption{\label{fig:selnet}A  selection network constructed
  with the method described in the text. The numbers on the wires are
  the minimum ranks (starting at 0) that can be occupied by the values
  on these wires. Red crosses mark where wires can be excluded, green
  check marks where a top rank is determined. Swaps in blocks of equal
  color belong to the same splitter cascade. Swaps in gray boxes would
  be needed for full splitter cascades, but are not needed to determine
  the top 5 ranks.}
\end{figure*}


After a splitter cascade, the value carried by wire~ has a
minimum rank of , where  counts the number of
set bits in the binary number representation of~. This minimum rank
results from the transitivity of the swap operations in the splitter
cascade, as is illustrated in Figure~\ref{fig:splitter} for 8~wires:
By following upward paths (in splitters to the left) through the
splitter cascade, one can find for each wire~ exactly
 wires with smaller indices that must carry values
no less than the value carried by wire~. This yields the
minimum ranks shown in Figure~\ref{fig:splitter} on the right.



The core idea of our selection network construction is to use splitter
cascades to increase the minimum ranks of (the values carried by) wires.
If such a minimum rank exceeds~ (or equals~, since we work with
zero-based ranks and hence are interested in ranks
), a wire can be discarded, since its value is
certainly not among the top~. On the other hand, if there is only
one wire with minimum rank~0, the top~1 value has been determined.
More generally, if all minimum ranks no greater than some value~
occur for one wire only, the top~ values have been determined.

We exploit this as follows: Initially all wires are assigned a minimum
rank of~0, since at the beginning we do not know anything about the
values they carry. We then repeat the following construction:
traversing the values  descendingly, we collect
for each~ all wires with minimum rank~ and apply a splitter
cascade to them (provided there are at least two such wires).
Suppose the wires collected for a minimum rank~ have indices
. After the splitter cascade
we can update the minimum rank of wire~ to
\hbox{\vbox to0pt{\vss\hbox{}}}, because
before the splitter cascade there is no known relationship between
wires with the same minimum rank, while the splitter cascade
establishes relationships between them, increasing their ranks by
\hbox{\vbox to0pt{\vss\hbox{}}}. The procedure of
traversing the minimum ranks  descendingly,
collecting wires with the same minimum rank and applying splitter
cascades to them is repeated until all minimum ranks 
occur only once.

As an example, Figure~\ref{fig:selnet} shows a  selection
network constructed is this manner, in which the minimum ranks of the
wires are indicated after certain layers as well as when certain wires
can be discarded (red crosses) and when certain top ranks are determined
(green check marks). Comparators belonging to the same splitter cascade
are shown in the same color.


\begin{table*}[t]
\centering\tabcolsep1.82mm
\begin{tabular}{rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr}
	\toprule
	   & full &
	\multicolumn{8}{c}{odd-even/pairwise/bitonic selection} &
	\multicolumn{8}{c}{splitter selection} \\ 
	\cmidrule(l){2-2} \cmidrule(l){3-10} \cmidrule(l){11-18}
	\multicolumn{1}{l}{\rule{0pt}{2.3ex}}
	& sort &  1 &  2 &  3 &  4 &  5 &  6 &  7 &  8 
	&  1 &  2 &  3 &  4 &  5 &  6 &  7 &  8 \\
	\midrule
	16 &  10  &  4 &  7 &  9 &  9 & 10 & 10 & 10 & 10
	&  4 &  6 &  7 &  8 & 10 & 11 & 12 & 13 \\
	1024 &  55  & 10 & 19 & 27 & 27 & 34 & 34 & 34 & 34
	& 10 & 14 & 16 & 18 & 22 & 25 & 27 & 29 \\
	10450 & 105  & 14 & 27 & 39 & 39 & 50 & 50 & 50 & 50
	& 14 & 18 & 20 & 23 & 27 & 30 & 32 & 34 \\
	65536 & 136  & 16 & 31 & 45 & 45 & 58 & 58 & 58 & 58
	& 16 & 20 & 22 & 25 & 29 & 32 & 34 & 36 \\ 
	\bottomrule
\end{tabular}
\caption{\label{tab:selnetsizes}Depths of sorting networks and
  selection networks (which are equal for odd-even, pairwise,
  or bitonic networks) compared to selection networks
  constructed with our splitter-based approach. Note that for
  small~ and comparatively large~ an odd-even/pairwise/bitonic
  selection network or even a full sorting network may be preferable
  (e.g.\  and
  ), but that for larger~ considerable savings can be
  obtained for small~, even compared to other selection networks.}
\end{table*}


While selection networks resulting from adaptations of sorting networks
(see above) have the advantage that they guarantee that their number
of layers is never greater than that of a full sorting network, our
approach may produce networks with more layers. However, if  is
sufficiently small compared to~ (in particular, if
), our approach can produce selection networks with
considerably fewer layers, as is demonstrated in
Table~\ref{tab:selnetsizes}. Since in the context we consider here
we can expect , splitter-based selection networks
are often superior.









































\end{document}
