\documentclass[11pt,english]{article}


\usepackage{makeidx}  \usepackage{xspace}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[en,nl]{bdalgo}



\newcommand{\Latin}[1]{\textit{#1}}
\newcommand{\eg}{\Latin{e.g.},\xspace}
\newcommand{\ie}{\Latin{i.e.},\xspace}
\newcommand{\via}{\Latin{via}\xspace}
\newcommand{\cf}{\Latin{cf.}\xspace}
\newcommand{\etc}{\Latin{etc.}\@\xspace}
\newcommand{\Anglais}[1]{\textsl{#1}}
\newcommand{\sachant}[1]{\,_{|#1}}

\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}

\newenvironment{proof}[1][0cm]{
  \begin{list}{\bf Proof.~}{
      \setlength{\itemindent}{0cm}
      \setlength{\labelsep}{0cm}
      \setlength{\labelwidth}{#1}
      \setlength{\leftmargin}{#1}
    \item
    }
}{\hfill
  \end{list}
}

\usepackage[USletterpaper,simple]{bdpage}
\TextSize{23.8cm}{16.9cm}

\renewcommand{\vec}[1]{{#1^{\mbox{}\!\!\!\rightarrow}}}
\newcommand{\svs}{\vspace{+.5cm}}
\newcommand{\vs}{\vspace{+3cm}}


\begin{document}



\title{Best-effort Group Service in Dynamic Networks\thanks{Supported by R\'egion Picardie, proj. APREDY.}}

\author{Bertrand Ducourthial \and Sofiane Khalfallah \and Franck Petit\\
\begin{small}
 \begin{tabular}[t]{l}
   (1) Universit\'e de Technologie de Compi\`egne\\
            (2) CNRS Heudiasyc UMR6599\\
                Centre de Recherche de Royallieu\\
                B.P. 20529, Compi\`egne, France\\
              \end{tabular}\hspace{6mm} \begin{tabular}[t]{l}
   (1) Universit\'e PM. Curie\\
            (2) CNRS LIP6 UMR7606\\
            (3) INRIA REGAL\\
	    4, place Jussieu
            75005 Paris, France\\
          \end{tabular}
\end{small}
}

\date{}

\maketitle 

\begin{abstract}
We propose a group membership service for dynamic ad hoc networks.  It maintains
as long as possible the existing groups and ensures that each group diameter is
always smaller than a constant, fixed according to the application using the
groups.
The proposed protocol is self-stabilizing and works in dynamic distributed
systems. Moreover, it ensures a kind of \emph{continuity} in the service offer
to the application while the system is converging, except if too strong topology
changes happen. Such a \emph{best effort} behavior allows applications to rely on
the groups while the stabilization has not been reached, which is very useful in
dynamic ad hoc networks.
\svs

\noindent Keywords: Group maintenance, Best effort, Stabilization, Dynamic network.
\end{abstract}



\section{Introduction}

\paragraph{Self-stabilization in dynamic networks}
A \emph{dynamic} network can be seen as an (\emph{a priori} infinite) sequence
of networks over time. In this paper, we focus on dynamic \emph{mobile}
networks. Examples of such networks are \emph{Mobile Ad hoc} networks (MANETs) or
\emph{Vehicular Ad hoc} networks (VANETs).

Designing applications on top of such networks require dealing with the lack of
infrastructure~\cite{S02,DBLP:conf/icdcit/JhumkaK07}. One idea consists in building virtual structures such as clusters, backbones,
or spanning trees.
However, when the nodes are moving, the maintenance of such structures may
require more control.
The dynamic of the network increases the control overhead.
Thus, distributed algorithms should require less overall organization of the
system in order to remain useful in dynamic networks.

Another paradigm for building distributed protocols in mobile ad hoc networks
consists in designing self-stabilizing algorithms~\cite{BDHY07}. These
algorithms have the ability to recover by themselves (\ie automatically) from an 
inconsistent state caused by transient failures that may affect a memory or a message. 
In this context, the topology changes can be considered as transient failures because 
they lead to an inconsistency in some memories. Indeed, when a node appears or disappears in the
network, all its neighbors should update their neighborhood knowledge.

Self-stabilizing algorithms have been intensively studied the two last decades
for their ability to tolerate transient faults~\cite{D00}.
However, it is important to notice that such algorithms do not ensure all the time
the desirable behavior of the distributed system,
especially when faults occur and during a certain period of time following them. 
In dynamic systems, it becomes illusory to expect an application that continuously 
ensures the service for which it has been designed.
In other words, what we can only expect from the distributed algorithms is to
behave as ``the best'' as possible, the result depending on the dynamic of the
network.

In this paper, we propose a new approach in the design of distributed solutions
for dynamic environments.  
We borrow the term ``{\em best-effort}'' from the networking community to qualify
the algorithms resulting of our approach. 
Roughly speaking, a best-effort algorithm is a self-stabilizing algorithm 
that also maintains an extra property, called {\em continuity}, 
conditioned by the topology changes.  

Continuity aims to improve the output of the distributed protocol during the
convergence phase of the algorithm, provided that a topological property is
preserved.
This means that there is a progression in the successive outputs of the
distributed protocols, except if the network dynamic is too high. This is
important in a distributed system where the
dynamic (that is, the frequent topology changes) can prevent the system to 
converge to the desirable behavior.
Since the output of the protocol will certainly be used before the
stabilization, the continuity ensures that third party applications can rely on
it instead of waiting. The output will certainly be modified in the future, but
without challenging previous ones.

In some aspects, our approach is close to the ones introduced in~\cite{KM06c}
and in \cite{PODC95}.  In~\cite{KM06c}, the authors introduce the notion of
\emph{safe-convergence} which guarantees that the system quickly converges to a
safe configuration, and then, it gracefully moves to an optimal configuration
without breaking safety.  However, the solution in~\cite{KM06c} works on a
static network.  In~\cite{PODC95}, the authors use the notion of \emph{passage
  predicate} to define a {\em superstabilizing} system, \ie a system which is
stabilizing and when it is started from a legitimate state and a single topology
change occurs, the passage predicate holds and continues to hold until the
protocol reaches a legitimate state.
By contrast, the continuity property is intended to be satisfied {\em before} a legitimate
configuration has been reached. It must be satisfied during the stabilization
phase, and between two consecutive stabilization phases (convergence phase
followed by stability phase). 

We illustrate our approach by specifying a new problem, called \emph{Dynamic
  Group Service} inspired from vehicular ad hoc networks (VANET), an emblematic
case of dynamic ad hoc networks. We then design a best effort distributed
protocol called \texttt{GRP} for solving this problem: we prove that it is
self-stabilizing and fulfills a continuity property, allowing applications to
use the groups while the convergence may be delayed because of the dynamic of
the network.

\paragraph{Dynamic group service}
Vehicular ad hoc networks currently attract a lot of attention \cite{BEH04}.
Many VANET applications require cooperation among close vehicles during a given
period: collaborative driving, distributed perception, chats and other
infotainment applications.
Vehicles that collaborate form a \emph{group}. A group is intended to grow
until a limit depending on the application. For instance, the distributed
perception should not involve too far vehicles, a chat should be responsive
enough, that limits the number of hops, etc.
When the group diameter is larger than the bound given by the application, it
should be split into several smaller groups.
However, a group should not be split if this is not mandatory by the diameter
constraint in order to ensure the best duration of service to the application
relying on it.
Even if another partitioning of the network would have been better (\eg less
groups, no isolated vehicle), it is preferable to maintain the composition of
existing groups. It is expected that, thanks to the mobility of the nodes, small
groups will eventually succeed in merging. It is then more important to 
maintain existing groups as long as possible.

\paragraph{Best-effort \texttt{GRP} algorithm}
To solve the \emph{Dynamic Group Service}, we propose a best-effort distributed
algorithm called \texttt{GRP} (for \texttt{GRouP}) designed for unreliable
message passing systems.
This algorithm stabilizes the views (the local knowledge of the group to which
belongs the node) in such a way that all the members of a group will eventually
share the same view (in which only the members appear). The groups' diameters
are smaller than a fixed applicative constant \texttt{Dmax} and neighbor groups
merge while the diameter constraint is fulfilled. Moreover, our algorithm admits
the following continuity property: no node disappears from a group except if a
topology change leads to the violation of the diameter constraint.
This allows to the applications requiring the groups (\eg chat) to run before
the convergence of \texttt{GRP}, that may be delayed because of the dynamic of
the network.

To the best of our knowledge, only a few number of papers address the problem
of group membership maintenance in the context of self-stabilization.  Recently,
in~\cite{DLV08}, the authors propose a self-stabilizing -clustering algorithm
for static networks.  In~\cite{TMC06}, the authors propose a self-stabilizing
group communication protocol.  It relies on a mobile agent that collects and
distributes information during a random walk.  This protocol does not allow 
building groups that strech over at most  hops.

Group communication structures have been proposed in the literature to achieve
fault-tolerance in distributed systems~\cite{ACM93}, by providing for instance
replication, virtual synchrony, reliable broadcast, or atomic broadcast
(\emph{e.g.},~\cite{S90,GS97}).
Other works deal with the -clustering or -dominating set problem, \eg
\cite{APHV00,CKV01,Demirbas06,Johnen09,KM06c,KP98,PB04}, where nodes in a group are at
most at distance  from a \emph{cluster-head} or \emph{dominant node}. The aim
of these algorithms is to optimize the partitioning of the network.
The group service we propose in this paper is different in the sense that its aim is neither to
optimize any partitioning nor to build group centered to some nodes. Instead, it
tries to maintain existing groups as long as possible while satisfying a
constraint on the diameter, without relying on a specific node (that may move or
leave).


\paragraph{Organization}
In Section~\ref{s:model}, we describe the distributed system we consider in this
paper. We also state what it means for a protocol to be self-stabilizing and
best effort regarding a continuity property conditioned by topology changes.
Next, in Section~\ref{s:spec}, we specify the Dynamic Group Service problem and
in Section~\ref{s:algo}, we describe our \texttt{GRP} algorithm solving it\footnote{\label{refonline}.  Note that the algorithm has been successfully implemented using the
  Airplug software suite. The detailed algorithm used for the implementation is
  available on our website (as long as the software):\newline \noindent
{\tt http://www.hds.utc.fr/ducourth/airplug/doku.php?id=en:dwl:grp:accueil}.
Some screenshot movies are also available here:\newline \noindent
{\tt http://www.hds.utc.fr/ducourth/airplug/doku.php?id=en:doc}
}.
The proofs are given in Section~\ref{s:proof}. Finally, we make some
concluding remarks in Section~\ref{s:conclu}.
By lack of place, some proofs are in appendix.





\section{Model}\label{s:model}

We define the distributed system  as follows.

\paragraph{System}
Let  be the set of nodes, spread out in an Euclidean space.  The total number
of nodes in  is finite but unknown.  Each node is equipped with a processor
unit (including local memory) and a communication device. A node can move in the
Euclidean space.  It is either \emph{active} or \emph{inactive}. When it is active, it can
compute, send and receive messages by executing a local algorithm.  The
\emph{distributed protocol}  is composed of all the local
algorithms.

We define the \emph{vicinity} of a node  as the part of the Euclidean space
from where a node  can send a message that can be received by  (the
vicinity depends on the communication devices, the obstacles, etc.).  A node 
can receive a message from  if () both  and  are active, () 
is in the vicinity of , ()  is sending a message, () no other
node in the vicinity of  is currently sending a message, and ()  is not
sending a message itself (any active node that is not sending is able to
receive).

We assume that on each node the message sending is driven by a {\em timer}.
We admit the following \emph{fair channel} hypothesis: there exists two time
constants  and  with  such that, starting from
a date , any node  is able to receive before the date  a message
from each node , providing that  is in the vicinity of  between  and
 and attempts to send a message every  units of time.
At any time instant , there is a \emph{communication link} from  to  if
both  and  have the state active (at ), and if  is into the vicinity
of  (at ).  A communication link is oriented because  could be in the
vicinity of  while the converse is false.

We assume the following hypotheses, close to the IEEE~802.11 protocol.  
() The communication channel contains at most one message---{\em one-message channel}.
() If a node  keeps continuously sending a message , then  
eventually sends ---{\em fair sending}. 
() If a node  keeps continuously receiving a message, then  
eventually receives a message---{\em fair reception}. 
() If a node  has continuously an action  to execute, then  executes
 in finite time---{\em fair activation}.


A \emph{configuration}  of  is the union of states of memories
of all the processors and the contents of all the communication links. An empty
communication link is denoted in the configuration by a link that contains an
empty set of messages. By the way, there is a single topology per configuration.
Let  be the set of configurations.
An \emph{execution} of a distributed protocol  over 
is a sequence of configurations  of  so that
,  moves to  by changing the memory of at least one process, including its message
buffers (\ie by sending or receiving messages).  

We denote by  the topology of  during the configuration
.
In a \emph{static} system , we have  in every
execution .  Otherwise, the system  is said to
be \emph{dynamic}.

\paragraph{Self-Stabilization}
Let  be a set. Then  means that an element  satisfies the predicate  defined on the set  and
 with  means that any  satisfies
.
We define a special predicate  as follows:
, .
Let  and  be two predicates defined on the set of configurations
 of the system .   is an {\em attractor} for
 if and only if the following condition is true: for any configuration
 and for any execution , there exists  such that for any , .

Define a \emph{specification} of a task as the predicate  on the set
 of configurations of system .
A protocol  is self-stabilizing
for  if and only if
there exists a predicate  (called the legitimacy predicate)
defined on  such that the following conditions hold:\newline
\noindent 1. For any configuration , and for any execution , we have  (correctness).
\newline
\noindent 2.  is an attractor for \textsf{true} (closure and convergence).

\paragraph{Best effort requirement}
We denote by  a \emph{topological} predicate defined on the pairs of
successive configurations in an execution. Such a predicate is intended to be
false when an ``important topology'' change happens.
We denote by  a \emph{continuity} predicate defined on the pairs of
successive configurations in an execution. Such a predicate is intended to be
false when the quality of the outputs produced by protocol
 in the two successive configurations decreases.

The protocol  offers a best effort continuity of services if .




\section{Dynamic Group Service Problem}\label{s:spec}

The Dynamic Group Service protocol is inspired from applications requirements in
Vehicular Ad Hoc networks (VANET), such as collaborative perception or
infotainment applications.

\paragraph{Informal specification} On each node , a variable
 gives the composition of the group to which  belongs. This
will be used by the applications. The agreement property says that all nodes in
group of  agree on the composition of the group. The safety property says
that the diameter of each group is smaller than a constant . The
maximality property says that small groups merge to form larger groups.

To deal with the dynamic of the network, the algorithm should be able to satisfy
these three properties in finite time after the last failure or topology change
(self-stabilization). To allow the applications to run while the convergence has
not been reached, the algorithm should ensure a best effort requirement: if the
distance between the members of a group remains smaller than 
(topological property), then no node will leave the group (continuity
property). This is important because the convergence may be delayed because of
the dynamic of the network.

\paragraph{Formal specification}
Let  be a graph.  Let  be the \emph{distance} between  and
 (length of the shortest path from  to  in ).
A \emph{subgraph}  is defined as follows:  and
.
Two subgraphs  and  of a graph  are said
\emph{distinct} if .
Let  be a set of nodes. We denote by  the distance
between  and  in the subgraph , that is, the length of the
shortest path from  to  with only edges of . If such a path does not
exists, then .

Given a graph , the problem considered in this paper consists in designing a
distributed protocol that provides a partition of  into disjoint subgraphs
called {\em groups} that satisfies constraints described
below.  Denote by  the knowledge of  about its group in
configuration  (output on node ).

Let  be the predicate defined on the configurations and called
\emph{agreement property}:  holds if and only if there exists a
partition of disjoint subgraphs ,  , 
 of  such that for every nodes , .


Let  be the \emph{group} of  in configuration , defined by:
()  if  and , ()  otherwise.  Note that given any configuration , if  holds,
 defines a partition of  into disjoint subgraphs of
, {\it i.e.}, there exists a partition of disjoint subgraphs ,
, ,  such that  for every subgraph . 

Let  be an integer representing the maximal admissible distance between two nodes belonging to
the same group.  Let  be the predicate defined on the configurations and called \emph{safety
property}:  holds if each group is connected and its diameter is
smaller than .
More formally , .

Let  be the predicate defined on the configurations and called
\emph{maximality property}:  holds if by merging two existing groups,
we cannot obtain a partition satisfying the safety property. More formally
 with , , .

The problem considered in this paper is to design a self-stabilizing protocol
regarding predicates : after the last failure
or topology change, the algorithm converges in finite time to a behavior where
, , and  are fulfilled.

Note that the above requirement is suitable for fixed topologies only.  The
following predicate deals with dynamic system, {\it i.e.}, with topological
changes.
Let  be the graph modeling the topology of the system at
configuration . We introduce the following notation:  refers to the
distance in the graph , and  denotes the
distance between  and  in  by considering only edges of the
subgraph  of .
Define the {\em topological property} as the predicate  defined on any
couple of two successive configurations  of an execution  as
follows:  holds if, for any pair of nodes belonging to the
same group in , the distance between them will still be smaller than
\texttt{Dmax} in . In other words, if a topology change occurred
between  and , it has preserved the maximal distance condition.
More formally, , .

Finally, we are looking for protocols attempting to preserve a group partition when a topology change occurs. 
Let  be the predicate defined on the couples of successive configurations
and called \emph{continuity property}:  holds if in any
group, no node disappears. In other words, an application can work with the
given view because it defines a group in which no node will disappear. More
formally, , .
Obviously, if the dynamic of the network is too large, such a property cannot be
satisfied.  We then introduce the best effort requirement: .




\section{\texttt{GRP} distributed protocol}\label{s:algo}

The GRP distributed protocol is designed for solving the Distributed Group
Service problem in an unreliable message passing system.

\subsection{Principle of the \texttt{GRP} distributed protocol} 
For each node , the candidates to form a group are neighbors up to distance
.  Each node  periodically echanges messages with its neighbors and 
maintains a list of nodes being at distance at most . 
Each sent message sent by  contains the list of .  The list of  contains nodes at 
distance at most  that are in the group or candidates to join the group. 

Our mechenism needs to take in account symmetric links only, \ie links between pairs of nodes
 and  so that if  is considered by  as a neighbor, then  
(resp. ) is considered as a neighbor by . 
In order to implement this, we use marks.  Each node proceeds as follows:
if  receives a
list from  that does not contain itself, then it adds  in its
list (which will be sent to the neighbors at the next timer expiration). To the
converse, when  receives a list from  that contains either  or
, then it adds  in its list. Marked nodes are not propagated
farther than the neighborhood.

Malformed lists are rejected (such as lists larger than ).
Moreover, when a node  receives a list from  which is too long compared to
its current list, it rejects it to avoid any split of its current group. In this
case,  adds  in its list, meaning that  and 
cannot belong to the same group. To the converse, if the received list is not
too long, it is merged with the current list, meaning that  enters to the
group of . Symmetrically,  will accept  in its group.

Several nodes may be accepted concurrently by distant members of a given
group. In some cases, a too large group may be obtained. Then one of the new
members must leave the group (instead of splitting the existing group).  To
avoid any inopportune change in the views (which are used by the applications),
a new member enters in the view of a node only after the end of its
\emph{quarantine} period. This allows guaranteeing that its arrival has been
approved by all the members (no conflicts). A node arrival is propagated to the
group's members in ; this defines the quarantine period
duration.

When it is necessary to chose which node has to leave the group (to fulfill the
diameter constraint), the choice is done using a \emph{priority} computed by Function~. 
Priorities are
totally ordered; if , then  has the
priority. 
A powerful implementation of priorities is the oldness of nodes in the groups:
the priority of a node is incremented  by a logical clock~\cite{L78}, except if it belongs to a
group (of more than one node) in which case the priority remains stable. The
last entered nodes in a group have then less priority than the nodes entered
before them.

Priorities on the nodes allow to easily define priorities on the groups by
taking the smallest priority of the members.  Priorities on the groups allows to
ensure the merging of neighbor groups (and the maximality property ) in
particular cases (loop of groups willing to merge).



\subsection{Building the lists}\label{s:ant}
In the sequel, a node  is an {\em ancestor} of node  if a path exists from  to . 
The messages sent to the neighbors contain \emph{ordered list of ancestors'
  sets}.  The \emph{ordered list of ancestors' sets} of a node  is defined
by:
    where any node
 satisfies  () and  is the distance
of the farthest ancestor of .

Computations are done using the -operator 
\cite{JACIC06,DT03,SSS07}.
Let  be the set of lists of vertices' sets. For instance, if
 are vertices,  and  belong to .
Let  be the operator defined on  that merges two lists while
deleting needless or repetitive information (a node appears only one time in a
list of ancestors' sets).  For instance: \newline
\noindent

\newline \noindent
.

Finally, let  be the endomorphism of  that inserts an empty set at
the beginning of a list. For instance: \newline \noindent
.

We then define the operator  by: , where  and  are lists belonging to . This
is a strictly idempotent -operator \cite{SSS07} inducing a partial order
relation. It leads to self-stabilizing static tasks (building the complete
ordered lists of ancestor sets) in the register model \cite{DT03}.
Since our wireless communication model admits bounded links, these results can
be extended to this model. (Refer to the discussion related to -operators in
wireless networks in \cite{JACIC06}.)


\subsection{\texttt{GRP} algorithm}
 

Each node  computes its output (\texttt{list}, \texttt{view} and the
priorities) when its timer  expires. It broadcasts its output in the
neighborhood when the timer  expires ().
All messages received from the neighborhood are collected on  in
\texttt{msgSet}. If a neighbor sends more than one message before the timer
expiration, only the last received is kept.
After computation, the variable \texttt{msgSet} is reset in order to detect
when a neighbor leaves.


\begin{footnotesize}
\begin{algorithm*}{\texttt{GRP}, node \texttt{v}}
\ACTION{Upon reception of a message \texttt{msg} sent by a node \texttt{u}}
  \I update message of  in \texttt{msgSet}
\ENDACTION
\ACTION{Upon  timer expiration}
  \I compute()
  \I reset \texttt{msgSet}
  \I restart timer  with duration 
\ENDACTION
\ACTION{Upon  timer expiration}
  \SEND{ with priorities} to the neighbors \label{l:send}
  \I restart timer  with duration 
\end{algorithm*}
\end{footnotesize}

A computation (in procedure \texttt{compute}, below) consists in building the
ordered list of ancestor' sets as well as the view. The list is sent to the
neighbors to be used in their  computation. The view is the output
of the protocol used by the applications (\eg chat, collaborative perception...)
which requested the \texttt{GRP} algorithm, and which determined the diameter
constraint \texttt{Dmax} (fixed during all the execution).

First, the incoming lists are checked.  Line~\ref{l:good}, when the list sent by
 and received by  does not contain , is malformed or is too
long\footnote{ returns the number of elements in
\texttt{list};  returns the th element of \texttt{list},
starting from 0.}, it is replaced by .  When  receives the
list of  containing , it accepts the list of  and sends a
list containing . Thanks to this triple handshake, the link has been detected
as symmetric (by the way, asymmetric link information are not propagated).

Line~\ref{l:cond}, if the received list is too long, the sender  is marked as
incompatible ().  Roughly speaking, a list received
by a node  from another node  is compatible if, by combining its list with
the one of ,  does not increase the diameter of its group beyond
\texttt{Dmax}.
In order to reach this goal, it is enough to test if the sum of the lengths of
both lists is less than or equal to .  But, such simple test
would avoid merging two groups by taking advantage of short cuts between both
groups.  In other words, this would ignore the knowledge that nodes of a group
have on nodes belonging to the other group.  The technical condition used in
Function~\texttt{compatibleList()} deals with such an optimization.

Then a first computation is performed using the  operator. Thanks
to the \texttt{goodList} test, the sizes of the incoming lists are smaller than
.  However, the computed list could reach the size of
 while the maximum is  (the 
operation increases by one the list sizes).
In this case, a choice has to be done between either the local node  or the
farthest nodes in the received lists. This choice is done by using priorities,
Line~\ref{l:order}. If nodes belong to the same group, node priorities are
compared. If nodes are not in the same group, this is a group merging and group
priorities are compared (to avoid loops of groups willing to merge).
If the local node  has not the priority on the too far node 
the lists in which  appears are ignored (Line~\ref{l:order-dbm}).
At the opposite side of the group, node  keeps the list containing  but
the end of its ordered list of ancestor's sets will be truncated (meaning that
 and  will not belong to the same group).
Indeed, after the too far nodes have been all examined, the list of ancestors is
computed again (Lines~\ref{l:compute2b}-\ref{l:compute2e}) and is truncated
(Line~\ref{l:truncate}) in order to delete the too far nodes (these remaining
too fare nodes have less priority than ).

In order to not include a node in a view while it could be rejected later, a
\emph{quarantine mechanism} is used. The quarantine period of a node willing to
enter in a group is equal to \texttt{Dmax} timers. Each time a computation is
done (and then the new node progresses in the group), its quarantine period
decreases. Since the group diameter is less than or equal to \texttt{Dmax}, any
conflict would have been detected before the new node enters into a
view. Moreover, if a member of the group accepts the new node, then all the
members will accept it.

Finally, the priority is updated. When using oldness in the group, the priority
is increased if the node is not in a group. If the node is in a group, the
priority remains stable. The group priority is the smallest priority of its members.

The procedure \texttt{compute()} is given below (a complete implementation with
the detailed algorithm is available on-line, see reference in
Footnote~\pageref{refonline} page~\pageref{refonline}).

\begin{footnotesize}
\renewcommand{\AlgTextName}{{\AlgStyName Procedure}}
\begin{algorithm*}{compute() on node }
\AlgSetWidthCom{0.45\linewidth}
  \C{Checking the received lists}
  \FORALL{  in  }
    \I delete marked nodes except  in \label{l:mn}\CL{Marked nodes are only useful between neighbors.}
 	  \IF{  goodList() }\label{l:good}
       \CL{List of  cannot be used;}
   		 \I replace  by  in \texttt{msgSet} \label{l:badlist}\label{l:sm} \CL{this
  list is ignored but the sender is kept.}
		\ENDIF\label{l:size} \CL{Now, incoming lists cannot be larger than .}
		\IF{  \AND  compatibleList() }  \label{l:cond}
	  \CL{ is new, but its list cannot be accepted;}
   		\I replace  by  in
  \texttt{msgSet} \CL{ is denoted as an incompatible neighbor} 
    \label{l:cond-dbm} \label{l:dbm1}
		\ENDIF
	\ENDFOR
\C{Computing the list of ancestors' sets of .}
	\I \texttt{list} \=   \label{l:compute1b}
  \FORALL{  }
	  \I  \= 
       \CL{Computation using the  -operator.}
  \ENDFOR \label{l:compute1e}
\C{Removal of incoming lists containing too far nodes (after 
  computation, \emph{} cannot be larger than \emph{})}
  \IF{  } 	  \CL{The list is too long.}
    \FORALL{  at position  in  } \CL{Scanning too far nodes.}
      \IF{  has the priority compared to } \label{l:order} \CL{Far node  has the priority.}
        \FORALL{} \CL{Looking for lists that provided ;}
          \IF{  is at position  } \CL{they contain  in their last place.}
 					  \I replace  by  in
            \texttt{msgSet} \label{l:dbm2}
						\label{l:order-dbm}\CL{The neighbor that provided  is ignored.}
				  \ENDIF
        \ENDFOR
      \ENDIF
    \ENDFOR
\C{Computing  again, without the incoming lists that contained too far
    nodes with priority.} 
    \I  \=  \label{l:compute2b}
    \FORALL{  in \texttt{msgSet} }
	    \I  \= 
    \ENDFOR \label{l:compute2e}
	  \I keeping up to  first elements in 
    \label{l:truncate}
    \CL{Deleted too far nodes have not the priority.}
  \ENDIF
  \I Update quarantines: quarantine of new nodes is \texttt{Dmax}, non null quarantine of
  others decreases by 1
	\I  \= non marked nodes in  with null quarantine \label{l:view}
	\I Update priorities: priority of nodes increase only when they are not in a group
\end{algorithm*}
\renewcommand{\AlgTextName}{{\AlgStyName Function}}
\begin{algorithm*}{goodList(\texttt{list})}
\IF{  or  are in  \AND
	   \AND  }
  \RETURN true
\ELSE
\RETURN false
\end{algorithm*}
\begin{algorithm*}{compatibleList(\texttt{list})}
\I\AlgTextIF  \OR \\
	\noindent\mbox{}\hspace{\AlgInd}
  ,
  
	    \RETURN true \CL{Refer to Proposition~\ref{p:compatible}.}
\ELSE
\RETURN false
\end{algorithm*}


\end{footnotesize}



\section{Proofs}\label{s:proof}


We first focus on the self-stabilizing property of our algorithm. We show that
assuming a fixed topology, the system converges in finite time to an execution
satisfying the statements in Section~\ref{s:spec}, \ie  is an attractor.  Next, we prove that, assuming topological
changes preserving the maximal distance condition over the groups, then
continuity is preserved, \ie .

\subsection{Stabilization}

In this section, we prove that our protocol is self-stabilizing by showing that
 and  and  are attractors---Propo\-sitions~\ref{p:safe}, \ref{p:agree} and \ref{p:max}, respectively.



We begin by showing that eventually lists will become correct
(Propositions~\ref{p:dmax} and \ref{p:exist}).
We first prove that any execution cannot remain infinitely with configurations
having lists larger than \texttt{Dmax}. We denote by  the
suffix of an execution  such that, for any configuration , for any node , the size of \texttt{list} is
smaller than or equal to .

\begin{proposition}[Dmax]\label{p:dmax}
On a fixed topology, any execution  reaches in finite time a suffix
.
\end{proposition}

\begin{proof}
Starting from configuration , the system will reach in finite time a
configuration in which every node has computed its list after expiration of its
timer. After such a computation, the size of the lists is bounded by
 (because it is truncated at the  position,
Line~\ref{l:truncate}).
\end{proof}


Starting from this proposition, we now prove that any execution cannot remain
infinitely with configurations having a non existing node in a list. We denote
by  the suffix of an execution  such that, for any
configuration , for any node , every node  satisfies .

\begin{proposition}[Exist]\label{p:exist}
On a fixed topology, any execution  reaches in finite time a suffix
.
\end{proposition}

\begin{proof}
Let  be a configuration (Proposition~\ref{p:dmax}).
Let  be a node label such that  and denote by  the set of
nodes having  in their list at position  in configuration .  Consider
the function  defined by  and  if . We prove that  is continuously growing along the execution to
be eventually equal to infinity forever.

Consider a node  in :  contains  at position
 in its computed list and no node in configuration  contains 
at a smaller position in its computed list. Until the next expiration of its
timer,  cannot receive a list containing  in a smaller position than
.
Hence, the system will reach in finite time a configuration in which the node
 has computed a new list that does not contain  at a position smaller than
. After a timer (fair channel Hypothesis), the system reaches in
finite time a configuration in which the neighbors of  have received this
list.

After finite time, any node  will do the same. The system
then reaches in finite time after configuration  a configuration  in
which  is empty, meaning that .

By iteration,  is growing along the execution.  Since the size of the
lists is bounded by  (Proposition~\ref{p:dmax}), there exists a
configuration  reached in finite time after  in which , meaning that  does not appear anymore in the computed lists of the
nodes forever.
\end{proof}




Next, we establish the connection between marked nodes in the algorithms and
subgraphs (Propositions~\ref{p:nopropagation}, \ref{p:propagation}, \ref{p:dme}
and \ref{p:subgraphs}).
We call \emph{double-marked edge} an edge  such that either 
double-marks  or  double-marks  (denoted by 
in the algorithm).  The following proposition is a consequence of the
double-marked edge technique. A node  double-marks its neighbor  only if
the list sent by  cannot be accepted by  (Lines~\ref{l:dbm1} and
\ref{l:dbm2}). In this case, node  will ignore the list sent by
. Reciprocally, if  has been double-marked by ,  will detect an
asymmetric link ( does not appear in the list it received after
Line~\ref{l:mn}) and only the identity of  will be kept by , the rest of
the list of  will be ignored (Line~\ref{l:sm}).

\begin{proposition}[No Propagation]\label{p:nopropagation}
  Let  and  be two vertices of  and suppose that, in any execution ,
  there exists a configuration  from which any path from  to  in 
  contains a double-marked edge. Then  will eventually disappear from
   and  will eventually disappear from .
\end{proposition}

The following proposition is a consequence of the \emph{ant} computation (see
Section~\ref{s:ant}). It propagates nodes identities (providing there is no
edge-marking technique for limiting it) \cite{DT03,JACIC06}.

\begin{proposition}[Propagation]\label{p:propagation}
  Let  and  be two vertices of  and suppose that, in any execution ,
  there exists a configuration  from which there exists a path from  to 
  in  without double-marked edge. Then  will eventually
  contain  and  will eventually contain .
\end{proposition}


\begin{proposition}[Double-marked edge]\label{p:dme}
  Suppose that . Then any execution admits a suffix
   such that, for any configuration ,
  there is a double-marked edge on any path from  to .
\end{proposition}

\begin{proof}
  Let  and  two nodes of  such that . Without loss
  of generality, we suppose that . Suppose that there exists a
  path from  to  that does not contain any double-marked edge. By
  Proposition~\ref{p:propagation}, there exists a neighbor  of  such that
   sends to  a list containing . The size of this list is larger than
  \texttt{Dmax}. There are two cases:
\newline \noindent 
  () . In this case,  is
    replaced by .
\newline \noindent 
  () . In this case,  computes a list using the
  one sent by . Since , the resulting list is too
  long. Since , the computation will be done again without the
  list provided by , which will be replaced by
  .

  In the two cases,  is double-marked by . Hence, any path from  to 
  will eventually contains a double-marked edge.
\end{proof}

Let denote by  the subgraph of  defined in the
configuration  by: for any node  in , .
Such a subgraph is composed of vertices containing  in their list. We prove
that eventually  and  are distinct when .

\begin{proposition}[Subgraphs]\label{p:subgraphs}
  Suppose that . Then any execution admits a suffix
   such that, for any configuration ,
   and  are distinct subgraphs.
\end{proposition}

\begin{proof}
  By Proposition~\ref{p:dme}, there exists a suffix  such that any path
  from  to  contains a double-marked edge. By
  Proposition~\ref{p:nopropagation}, there exists a suffix  included in
   such that for any configuration  in this suffix,  and . Then  and
  .

  Let consider a node  such that  and . Then there
  exists at least one path from  to  containing . The length of such a
  path is larger than \texttt{Dmax}. Then, by Proposition~\ref{p:dme}, it
  admits a double-marked edge, either on the subpath from  to  or from the
  subpath from  to .

  Now, let consider all the paths from  to  containing ; they all
  contain a double-marked edge. Suppose that for one path , this double-marked edge is between  and  and for a second path , it is between
   and . Then, by considering edges of  from  to  and edges of
   from  to , we obtain a path from  to  without any double-marked edge, which is a contradiction. Then, all paths from  to 
  containing  admit a double-marked edge, and this edge is always between 
  and  or always between  and . Thus,  cannot belong to both 
  and , meaning that there is no node  such that  and .

  Hence, any execution reaches a suffix such that, for any configuration  in
  this suffix,  and  are distinct.
\end{proof} 



The preceding propositions give the Agreement.  Consider any execution
.  Denote by  the suffix of an execution
 such that  holds for any configuration ,
that is  for any .
The following proposition is given by Propositions~\ref{p:subgraphs},
\ref{p:propagation} and \ref{p:nopropagation}.

\begin{proposition}[Agreement]\label{p:agree}
  On a fixed topology, any execution  reaches in finite time a suffix
  .
\end{proposition}

\begin{proof}
  By Proposition~\ref{p:subgraphs}, for any execution, there exists a suffix
  such that, for any nodes  and  in , if ,
  then the subgraphs  and  are distinct. Consider now two nodes 
  and  such that  belongs to 

  By Proposition~\ref{p:propagation}, for any execution, there exists a suffix
  such that, for any configuration  in this suffix, the identities of 
  will be in .

  By Proposition~\ref{p:nopropagation}, for any execution, there exists a suffix
  such that, for any configuration  in this suffix, the 
  contains only vertices of .

  After the end of the quarantine period, all the nodes in 
  belong to .  Then the system reaches a suffix in which all
  the nodes of  and only these nodes appear in , for any
  vertex . Hence, . This gives .
\end{proof}


Now we have the agreement, there is a connection between subgraphs and
groups. We then prove the Safety.
Consider any execution . Denote by  the suffix of an execution  such that 
holds for any configuration . The following proposition is
a consequence of Prop.~\ref{p:subgraphs}.


\begin{proposition}[Safety]\label{p:safe}
On a fixed topology, any execution  reaches in finite time a suffix .
\end{proposition}

\begin{proof}
  By Proposition~\ref{p:subgraphs}, for any execution and any nodes  and 
  in  satisfying , the subgraphs  and  will
  eventually be distinct. Hence, for any execution, there exists a suffix
   such that, for any configuration ,
  for any vertex  in , .

  Then, by Proposition~\ref{p:agree}, we have . This gives .
\end{proof}




We consider any execution .  In order to prove the maximality
property, we introduce the following definitions.  An edge  is
\emph{internal} in a given configuration  if .  In
the converse case (), it is \emph{external}.
An external edge involves double-marked nodes and it is then not propagated by
the algorithm (marked nodes are deleted, see line~\ref{l:mn} in Procedure
\texttt{compute()}).
We denote by  (resp. ) the function defined on  that
returns the \underline{n}umber of \underline{e}xternal \underline{e}dges in a
given configuration (resp. the \underline{n}umber of \underline{d}istinct
\underline{g}roups in configuration : .


\begin{proposition}[Nee]\label{p:nee}
  If  is decreasing along a suffix  of an execution ,  is also
  decreasing along .
\end{proposition}

\begin{proof}
  Let  be an external edge in a configuration  and assume that it is
  an internal edge in configuration . This means that  and . Hence
  .
\end{proof}

We prove that any execution reaches in finite time a suffix in which the
function  does not increase. We denote by  such a
suffix: , .

\begin{proposition}[Not incr.]\label{p:notincr}
  On a fixed topology, any execution  reaches in finite time a suffix
  \emph{}.
\end{proposition}

\begin{proof}
  Let  be a configuration (Proposition~\ref{p:agree}).
  Let  be an internal edge in configuration . Then we have  and  is in .
In order  becomes an external edge, one of its extremity (say )
  would have double-marked the other (in Procedure \texttt{compute()}). But this
  cannot happen after the \texttt{goodList} test (line~\ref{l:good}) because . This cannot happen after the \texttt{compatibleList}
  test (line~\ref{l:cond}) because  is in already in \texttt{view}.
\end{proof}

Now, we prove that any execution reaches in finite time a suffix in which the
function  is decreasing while  is not true. We denote by
 such a suffix: , ,  and .

 \begin{proposition}[Decreasing]\label{p:decr}
 On a fixed topology, any execution  reaches in finite time a suffix .
 \end{proposition}

\begin{proof}
  Let  be a configuration
  (Proposition~\ref{p:notincr}). Starting from such a configuration, the 
  function cannot increase.
Suppose that  is not true in . Then, by definition of , there
  exists two neighbors nodes  and  with different views that could merge
  their groups without breaking . By fair channel hypothesis, a timer
  later the system reaches a configuration  in which  (resp. ) has
  received the list sent by  (resp. ).

  Without loss of generality, suppose that  has the smallest priority
  among all the subgraphs that can merge, and  has the smallest priority
  among all the groups that can merge with .

  During the \texttt{compute()} Procedure on  and , the \texttt{goodList}
  tests are true because  and then . The \texttt{compatibleList} test is true on both  and 
  because they cannot have change their list since configuration . Hence we
  obtain:  and .

  Since  has the smallest priority among the neighbors of , no member
  of  can receive a message from a group with a smallest
  priority. Therefore  will never receive and then will never send to  a
  list with a too far node with a smallest priority than  one's. Hence 
  will never double-mark  and  will remain in the list of .

  Similarly, since  has the smallest priority among the groups that can
  merge, no member of  can receive a message from a group with a smallest
  priority. Therefore  will never receive and then will never send to  a
  list with a too far node with a smallest priority than  one's. Hence 
  will never double-mark  and  will remain in the list of .

  After \texttt{Dmax} timer, the list of  (resp. ) has reached any  (resp. ) thanks to the fair channel Hypothesis. Moreover the
  quarantine of these new members reaches  and they are now included in
  . Thus, the edge  becomes an internal edge.

  Hence, starting from configuration  with , the system reaches
  in finite time a configuration  with .
\end{proof}

The following proposition is given by Propositions~\ref{p:nee}, \ref{p:notincr}
and ~\ref{p:decr}; it shows that any execution reaches in finite time a suffix
in which  is true. We denote by  such a suffix.

\begin{proposition}[Maximality]\label{p:max}
  On a fixed topology, any execution  reaches in finite time a suffix
  .
\end{proposition}

\begin{proof}
  By Prop.~\ref{p:notincr}, the execution reaches a suffix 
  such that the  function will no more increase.  By Prop.~\ref{p:decr},
  the execution reaches a suffix  such that the  function
  decreases while  is not true.  Hence, while  is false, the
  number of external edges will eventually decrease. By Prop.~\ref{p:nee}, this
  means that the number of subgraphs will eventually decrease while  is
  false. Since the graph is finite, the number of subgraphs cannot decrease
  infinitely and  will eventually become true.
\end{proof}


\subsection{Best-effort requirement}

We now consider the dynamic of the network.  We show that if the continuity
property is violated into a group, then there exists a pair of nodes belonging
to that group such that the distance between them is larger that
\texttt{Dmax}. The following technical proposition justifies the compatibleList
test.

\begin{proposition}[Compatible lists]\label{p:compatible}
Let  be a node having the list    and assume
that its neighbor  sends the list .
Then, the diameter of the group of  after  accepts  remains smaller than or equal to
\texttt{Dmax} if and only if there exists  such that  is neighbor of all the nodes belonging to 
and either  or .
\end{proposition}

\begin{proof}
  Let  be a configuration (Proposition~\ref{p:safe}).
  Let  be the first node of  for which the list of ancestor's sets is
  received by . Then, the only external edges between  and 
  known by  are those joining  (external edges are not propagated). Hence,
  without loss of generality, assume that only these external edges exist
  between the groups.

  \noindent () Assume that the conditions are fulfilled.
Let  and  be two nodes in the lists of  and 
  respectively. There exists at most two families of shortest paths from  to
  , depending on the external edge used to reach .
Let  be a path that includes the edge . It starts from  and
  joins  by  edges in the group of , joins  by the edge  and
  then reaches  by  edges in the group of .
Let  be a path from the second family. It starts from  and joins a
  node  by  internal edges in the group of , then joins
   by the edge  and then reaches  by  internal edges in the
  group of .

  The length of  is bounded by .  But since  is a shortest
  path, it is shorter to reach  from  by joining a node of  (\ie
  ) than by joining a node of  (such as ). Hence we have  and the length of  is bounded , which is smaller than
   by hypothesis.
The length of  is bounded by , which is also smaller than
   by assumption.

  Hence, for any node  and  belonging to the group of  and 
  respectively, there exists a path from  to  with less than
   edges. The list of  is then compatible with the list of
  , and can then be accepted by .

  \noindent () Assume by contradiction that the conditions are not
  fulfilled and that  accepts the list of , \ie  includes the list of
   by computing its new list with \texttt{ant}---refer to Lines~ of
  Procedure \texttt{compute()}.  That means that the list of  is
  compatible---refer to Lines~---, which contradicts the assumption.  Then
  the nodes of  will be propagated in the lists of nodes of
   and reciprocally. But at least one node  will see that a node  is too
  far from it and reciprocally. Either  or  will reject the lists of its
  neighbors that contain the too far node (depending on the priority between 
  and ) and either the group of  or the group of  splits (when a
  neighbor is rejected by , it disappears from , and then
  from ; it is then no more in ).
\end{proof}

\begin{proposition}
  For any execution , for any configuration  in , .
\end{proposition}

\begin{proof}
  Suppose that there exists a configuration  and a node  such that
  . Then there
  exists a node  such that  and .
This cannot happen after  or  has added a new node in its view, thanks
  to the quarantine mechanism. This can only happen because either  or 
  removed a node from their views.

  Without loss of generality, suppose that  removed a node :  and .
If , then () the quarantine of  is
  not null or ()  is not in  or ()  is
  marked in  (Line~\ref{l:view} in Procedure
  \texttt{compute()}).

\noindent 
  () The first case is exclude because  was already in
  .

\noindent 
  () In the second case, if  has not received the message of  while it
  received it before, then  left the neighborhood of .
  Then, in configuration , there is not path from  to
   with only nodes of  and . Thus  (\emph{a neighbor left}).

\noindent 
  () In the third case, if  is simple marked, its list is not good while
  it was in configuration , which is exclude (Line~\ref{l:good}). If  is
  double-marked, this cannot happen after the compatibleList test
  (Line~\ref{l:cond-dbm}) because  was in . If this
  happened after Line~\ref{l:order-dbm}, then  sent a list with a too far
  node  having priority on . If , then . Then the quarantine of  is not null and no node
  of  has admitted  in its view. Therefore, thanks to
  Prop.~\ref{p:compatible},  would have never been propagated inside
   until , because of the compatibleList test
  (Line~\ref{l:cond}). Finally, if , then the distance
  from  to  in configuration  is larger than \texttt{Dmax}:
   and . \end{proof}



\section{Conclusion}
\label{s:conclu}



This paper introduces the best effort requirement to complete the
self-stabilization for designing algorithm in dynamic networks.
To illustrate this approach, a new problem inspired from VANET has been
specified: the \emph{Dynamic Group Service}.  A best effort distributed protocol
called \texttt{GRP} has been designed and proved for solving this problem in
message passing. The algorithm is self-stabilizing and fulfills a continuity
property whenever the dynamic allows it.
The protocol has been implemented and its performances studied by simulation
(see reference in Footnote~\ref{refonline} page~\pageref{refonline}). We believe
that the best effort requirement is promising for building useful services in
dynamic networks.

\begin{thebibliography}{10}

\bibitem{APHV00}
A.D. Amis, R.~Prakash, and D.H.T. Vuaong.
\newblock Max-min -cluster formation in wireless ad hoc networks.
\newblock In {\em IEEE INFOCOM}, pages 32--41, 2000.

\bibitem{ACM93}
Kenneth~P. Birman.
\newblock The process group approach to reliable distributed computing.
\newblock {\em Commun. ACM}, 36(12):37--53, 1993.

\bibitem{BEH04}
J.~Blum, A.~Eskandarian, and L.~Hoffman.
\newblock Challenges of intervehicle ad hoc networks.
\newblock {\em IEEE Transaction on Intelligent Transportation Systems,},
  5:347--351, 2004.

\bibitem{BDHY07}
O.~Brukman, S.~Dolev, Y.~Haviv, and R.~Yagel.
\newblock Self-stabilization as a foundation for autonomic computing.
\newblock In {\em The Second International Conference on Availability,
  Reliability and Security ({ARES})}, pages 991--998, Vienna, April 2007.

\bibitem{CKV01}
G.V. Chockler, I.~Keidar, and R.~Vitenberg.
\newblock Group communication specifications: a comprehensive study.
\newblock {\em ACM Computing Surveys}, 4(33):1--43, 2001.

\bibitem{DLV08}
A.~K. Datta, L.~L. Larmore, and P.~Vemula.
\newblock A self-stabilizing {O(k)}-time k-clustering algorithm.
\newblock {\em Computer Journal}, 2009.

\bibitem{JACIC06}
S.~Dela{\"e}t, B.~Ducourthial, and S.~Tixeuil.
\newblock Self-stabilization with r-operators revisited.
\newblock In {\em Journal of Aerospace Computing, Information, and
  Communication}, 2006.

\bibitem{Demirbas06}
Murat Demirbas, Anish Arora, Vineet Mittal, and Vinodkrishnan Kulathumani.
\newblock A fault-local self-stabilizing clustering service for wireless ad hoc
  networks.
\newblock {\em IEEE Trans. Parallel Distrib. Syst.}, 17(9):912--922, 2006.

\bibitem{D00}
S.~Dolev.
\newblock {\em Self-Stabilization}.
\newblock The MIT Press, 2000.

\bibitem{PODC95}
S.~Dolev and T.~Herman.
\newblock Superstabilizing protocols for dynamic distributed systems.
\newblock In {\em Proceedings of the fourteenth annual ACM symposium on
  Principles of distributed computing (PODC)}, page 255, New York, NY, USA,
  1995. ACM.

\bibitem{TMC06}
S.~Dolev, E.~Schiller, and J.L Welch.
\newblock Random walk for self-stabilizing group communication in ad hoc
  networks.
\newblock {\em IEEE Transactions on Mobile Computing}, 5(7):893--905, 2006.

\bibitem{SSS07}
B.~Ducourthial.
\newblock r-semi-groups: A generic approach for designing stabilizing silent
  tasks.
\newblock In {\em 9 Stabilization, Safety, and Security of Distributed
  Systems (SSS'2007)}, pages 281--295, Paris, novembre 2007.

\bibitem{DT03}
B.~Ducourthial and S.~Tixeuil.
\newblock Self-stabilization with path algebra.
\newblock {\em Theor. Comput. Sci.}, 293(1):219--236, 2003.

\bibitem{GS97}
R.~Guerraoui and A.~Schiper.
\newblock Software-based replication for fault-tolerance.
\newblock {\em IEEE Transaction on Computers}, 30(4):68--74, 1997.

\bibitem{DBLP:conf/icdcit/JhumkaK07}
Arshad Jhumka and Sandeep~S. Kulkarni.
\newblock On the design of mobility-tolerant tdma-based media access control
  (mac) protocol for mobile sensor networks.
\newblock In Tomasz Janowski and Hrushikesha Mohanty, editors, {\em ICDCIT},
  volume 4882 of {\em Lecture Notes in Computer Science}, pages 42--53.
  Springer, 2007.

\bibitem{Johnen09}
Colette Johnen and Le~Huy Nguyen.
\newblock Robust self-stabilizing weight-based clustering algorithm.
\newblock {\em Theor. Comput. Sci.}, 410(6-7):581--594, 2009.

\bibitem{KM06c}
Hirotsugu Kakugawa and Toshimitsu Masuzawa.
\newblock A self-stabilizing minimal dominating set algorithm with safe
  convergence.
\newblock In {\em 20th International Parallel and Distributed Processing
  Symposium (IPDPS 2006)}, 2006.

\bibitem{KP98}
S.~Kutten and D.~Peleg.
\newblock Fast distributed construction of small-dominating sets and
  applications.
\newblock {\em Journal of Algorithms}, 28(1):40--66, 1998.

\bibitem{L78}
L.~Lamport.
\newblock Time, clocks and the ordering of events in a distributed system.
\newblock {\em Communications of the ACM}, 21(7):558--565, 1978.

\bibitem{PB04}
L.~D. Penso and V.~C Barbosa.
\newblock A distributed algorithm to find  -dominating sets.
\newblock {\em Discrete Applied Mathematics}, 141(1-3):243--253, 2004.

\bibitem{S90}
F.B. Schneider.
\newblock Impliementing fault tolerant services using the state machine
  approach: a tutorial.
\newblock {\em Computing Surveys}, 22(4):299--319, 2990.

\bibitem{S02}
I.~Stojmenovic.
\newblock {\em Handbook of Wireless Networks and Mobile Computings}.
\newblock John Wiley \& Sons, 2002.

\end{thebibliography}

\label{sec:biblio}

\newpage


\mbox{}
\vspace{1cm}
\appendix


\section{Omitted proofs}

\subsection{Proof of Proposition~\ref{p:dmax} (Dmax)}
\begin{proof}
 Starting from configuration , the system will reach in finite time a
 configuration in which every node has computed its list after expiration of its
 timer. After such a computation, the size of the lists is bounded by
  (because it is truncated at the  position,
 Line~\ref{l:truncate}).
 \end{proof}


\subsection{Proof of  Proposition~\ref{p:exist} (Exist)}

\begin{proof}
Let  be a configuration (Proposition~\ref{p:dmax}).
Let  be a node label such that  and denote by  the set of
nodes having  in their list at position  in configuration .  Consider
the function  defined by  and  if . We prove that  is continuously growing along the execution to
be eventually equal to infinity forever.

Consider a node  in :  contains  at position
 in its computed list and no node in configuration  contains 
at a smaller position in its computed list. Until the next expiration of its
timer,  cannot receive a list containing  in a smaller position than
.
Hence, the system will reach in finite time a configuration in which the node
 has computed a new list that does not contain  at a position smaller than
. After a timer (fair channel Hypothesis), the system reaches in
finite time a configuration in which the neighbors of  have received this
list.

After finite time, any node  will do the same. The system
then reaches in finite time after configuration  a configuration  in
which  is empty, meaning that .

By iteration,  is growing along the execution.  Since the size of the
lists is bounded by  (Proposition~\ref{p:dmax}), there exists a
configuration  reached in finite time after  in which , meaning that  does not appear anymore in the computed lists of the
nodes forever.
\end{proof}

\subsection{Proof of Proposition~\ref{p:dme} (Double-marked edge)}

\begin{proof}
  Let  and  two nodes of  such that . Without loss
  of generality, we suppose that . Suppose that there exists a
  path from  to  that does not contain any double-marked edge. By
  Proposition~\ref{p:propagation}, there exists a neighbor  of  such that
   sends to  a list containing . The size of this list is larger than
  \texttt{Dmax}. There is two cases.
(i) . In this case,  is
    replaced by .
(ii) . In this case,  computes a list using the
    one sent by . Since , the resulting list is too
    long. Since , the computation will be done again without the
    list provided by , which will be replaced by
    .
In the two cases,  is double-marked by . Hence, any path from  to 
  will eventually contains a double-marked edge.
\end{proof}

\subsection{Proof of Proposition~\ref{p:subgraphs} (Subgraphs)}

\begin{proof}
  By Proposition~\ref{p:dme}, there exists a suffix  such that any path
  from  to  contains a double-marked edge. By
  Proposition~\ref{p:nopropagation}, there exists a suffix  included in
   such that for any configuration  in this suffix,  and . Then  and
  .

  Let consider a node  such that  and . Then there
  exists at least one path from  to  containing . The length of such a
  path is larger than \texttt{Dmax}. Then, by Proposition~\ref{p:dme}, it
  admits a double-marked edge, either on the subpath from  to  or from the
  subpath from  to .

  Now, let consider all the paths from  to  containing ; they all
  contain a double-marked edge. Suppose that for one path , this double-marked edge is between  and  and for a second path , it is between
   and . Then, by considering edges of  from  to  and edges of
   from  to , we obtain a path from  to  without any double-marked edge, which is a contradiction. Then, all paths from  to 
  containing  admit a double-marked edge, and this edge is always between 
  and  or always between  and . Thus,  cannot belong to both 
  and , meaning that there is no node  such that  and .

  Hence, any execution reaches a suffix such that, for any configuration  in
  this suffix,  and  are distinct.
\end{proof} 



\subsection{Proof of Proposition~\ref{p:agree} (Agreement)}

\begin{proof}
  By Proposition~\ref{p:subgraphs}, for any execution, there exists a suffix
  such that, for any nodes  and  in , if ,
  then the subgraphs  and  are distinct. Consider now two nodes 
  and  such that  belongs to 

  By Proposition~\ref{p:propagation}, for any execution, there exists a suffix
  such that, for any configuration  in this suffix, the identities of 
  will be in .

  By Proposition~\ref{p:nopropagation}, for any execution, there exists a suffix
  such that, for any configuration  in this suffix, the 
  contains only vertices of .

  After the end of the quarantine period, all the nodes in 
  belong to .  Then the system reaches a suffix in which all
  the nodes of  and only these nodes appear in , for any
  vertex . Hence, . This gives .
\end{proof}

\subsection{Proof of Proposition~\ref{p:safe} (Safety)}

\begin{proof}
  By Proposition~\ref{p:subgraphs}, for any execution and any nodes  and 
  in  satisfying , the subgraphs  and  will
  eventually be distinct. Hence, for any execution, there exists a suffix
   such that, for any configuration ,
  for any vertex  in , .

  Then, by Proposition~\ref{p:agree}, we have . This gives .
\end{proof}

\subsection{Proof of Proposition~\ref{p:nee} (Nee)}

 \begin{proof}
   Let  be an external edge in a configuration  and assume that it is
   an internal edge in configuration . This means that  and . Hence
   .
 \end{proof}

\subsection{Proof of proposition~\ref{p:notincr} (Not incr.)}

\begin{proof}
  Let  be a configuration (Proposition~\ref{p:agree}).
  Let  be an internal edge in configuration . Then we have  and  is in .
In order  becomes an external edge, one of its extremity (say )
  would have double-marked the other (in Procedure \texttt{compute()}). But this
  cannot happen after the \texttt{goodList} test (line~\ref{l:good}) because . This cannot happen after the \texttt{compatibleList}
  test (line~\ref{l:cond}) because  is in already in \texttt{view}.
\end{proof}

\subsection{Proof of Proposition~\ref{p:decr} (Decreasing)}

\begin{proof}
  Let  be a configuration
  (Proposition~\ref{p:notincr}). Starting from such a configuration, the 
  function cannot increase.
Suppose that  is not true in . Then, by definition of , there
  exists two neighbors nodes  and  with different views that could merge
  their groups without breaking . By fair channel hypothesis, a timer
  later the system reaches a configuration  in which  (resp. ) has
  received the list sent by  (resp. ).

  Without loss of generality, suppose that  has the smallest priority
  among all the subgraphs that can merge, and  has the smallest priority
  among all the groups that can merge with .

  During the \texttt{compute()} Procedure on  and , the \texttt{goodList}
  tests are true because  and then . The \texttt{compatibleList} test is true on both  and 
  because they cannot have change their list since configuration . Hence we
  obtain:  and .

  Since  has the smallest priority among the neighbors of , no member
  of  can receive a message from a group with a smallest
  priority. Therefore  will never receive and then will never send to  a
  list with a too far node with a smallest priority than  one's. Hence 
  will never double-mark  and  will remain in the list of .

  Similarly, since  has the smallest priority among the groups that can
  merge, no member of  can receive a message from a group with a smallest
  priority. Therefore  will never receive and then will never send to  a
  list with a too far node with a smallest priority than  one's. Hence 
  will never double-mark  and  will remain in the list of .

  After \texttt{Dmax} timer, the list of  (resp. ) has reached any  (resp. ) thanks to the fair channel Hypothesis. Moreover the
  quarantine of these new members reaches  and they are now included in
  . Thus, the edge  becomes an internal edge.

  Hence, starting from configuration  with , the system reaches
  in finite time a configuration  with .
\end{proof}

\subsection{Proof of Proposition~\ref{p:compatible} (Compatible lists)}
\begin{proof}
  Let  be a configuration (Proposition~\ref{p:safe}).
  Let  be the first node of  for which the list of ancestor's sets is
  received by . Then, the only external edges between  and 
  known by  are those joining  (external edges are not propagated). Hence,
  without loss of generality, assume that only these external edges exist
  between the groups.

  \noindent () Assume that the conditions are fulfilled.
Let  and  be two nodes in the lists of  and 
  respectively. There exists at most two families of shortest paths from  to
  , depending on the external edge used to reach .
Let  be a path that includes the edge . It starts from  and
  joins  by  edges in the group of , joins  by the edge  and
  then reaches  by  edges in the group of .
Let  be a path from the second family. It starts from  and joins a
  node  by  internal edges in the group of , then joins
   by the edge  and then reaches  by  internal edges in the
  group of .

  The length of  is bounded by .  But since  is a shortest
  path, it is shorter to reach  from  by joining a node of  (\ie
  ) than by joining a node of  (such as ). Hence we have  and the length of  is bounded , which is smaller than
   by hypothesis.
The length of  is bounded by , which is also smaller than
   by assumption.

  Hence, for any node  and  belonging to the group of  and 
  respectively, there exists a path from  to  with less than
   edges. The list of  is then compatible with the list of
  , and can then be accepted by .

  \noindent () Assume by contradiction that the conditions are not
  fulfilled and that  accepts the list of , \ie  includes the list of
   by computing its new list with \texttt{ant}---refer to Lines~ of
  Procedure \texttt{compute()}.  That means that the list of  is
  compatible---refer to Lines~---, which contradicts the assumption.  Then
  the nodes of  will be propagated in the lists of nodes of
   and reciprocally. But at least one node  will see that a node  is too
  far from it and reciprocally. Either  or  will reject the lists of its
  neighbors that contain the too far node (depending on the priority between 
  and ) and either the group of  or the group of  splits (when a
  neighbor is rejected by , it disappears from , and then
  from ; it is then no more in ).
\end{proof}





\end{document}
