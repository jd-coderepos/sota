Since the \basic\ model is too weak for the task of position discovery (when  is even),
we considered the \lazy\ model. Although one can solve position discovery in this model, the
overhead cost for this problem is .
In \cite{FriedetzkyGGM12}, it is shown that position discovery
can be solved in the {\perceptive} model (i.e., when the position
of the first collision in a round can be detected while each
agent has to start the round moving to the {\rright} or {\lleft}).
In this section, we inspect efficiency of coordination problems as well as position discovery in this model.
First, we show that the {\perceptive} model gives an opportunity to exchange information between neighbors
on a ring (Section~\ref{sub:sec:comm}). Then, we use this feature to build algorithms for the nontrivial move problem 
which brake the lower bounds working in the {\basic} model and the {\lazy} model (Section~\ref{sub:sec:move:perc}).
Finally, using these solutions as tools, we provide a solution for the positions discovery problem
in time  provided  which is optimal up to the  term (Section~\ref{sub:sec:disc:perc}).

\subsection{Communication on a ring}\labell{sub:sec:comm}
First, we discuss the following {\em neighbors discovery} task in which
each agent  should:
\begin{itemize}
\item
\vspace{-5pt}
learn (relative) location of its left neighbor  and its right neighbor ;
\item
\vspace{-5pt}
determine whether  and  have the same sense of direction as  has.
\end{itemize}
\vspace{-5pt}
Algorithm~\ref{alg:neighbor} solves this problem based on the fact that each two
IDs differ on at least one bit. (Some calculations performed by agents are not
explicitly described in the algorithm, they are discussed later.)
In Algorithm~\ref{alg:neighbor}, each execution of {\SingleRound} is followed by {\ReversedRound} in which
each agent starts a round with the direction opposite to its local direction {\dir}. We omit this detail in the pseudocode. However, let us stress here that this gives a guarantee that each agent starts each application of {\SingleRound} at exactly the same position as its position before the execution of the
algorithm (so, its distances to neighbours are the same as well). 

\begin{algorithm}[]
	\caption{NeighborDiscovery()}
	\label{alg:neighbor}
	\begin{algorithmic}[1]
    \State ;  \Comment{distances to collisions}
    \For{}
        \For{}
            \For{}
                \If{} 
                \Else   \  direction opposite to  \EndIf
                \State \SingleRound
                \State After a round:  \EndFor
        \EndFor
    \EndFor
    \State  \Comment{All agents choose direction {\rright}}
    \State \SingleRound;  \State 
    \State \SingleRound;  \State Location of 
    \State Location of 
    \end{algorithmic}
\end{algorithm}

\begin{proposition}\label{p:alg1}
Algorithm~\ref{alg:neighbor} gives solution to neighbors discovery in  rounds.
\end{proposition}
\iffull
\begin{proof}
Consider  and . First, we show that, in some round,
they start moving towards each other (which gives the distance to collision
equal to halve of their distance, the smallest possible). If they have {\em opposite} sense of direction,
then this happens in line 10 of the algorithm. Otherwise (i.e., they have the
same sense of direction), they start moving towards every other for such 
that ,  and .

When  already knows its distance to , the distance to collision
in line 10 gives information whether  and  have the same sense of direction.
(Namely, their senses of directions are opposite iff the result of  is equal to halve of
the distance between them.)
\end{proof}
\else
\fi

\comment{
\begin{proposition}\label{p:alg1}
One can modify Algorithm~\ref{alg1} such that each agent learns ID of its left neighbor
and ID of its right neighbor in  rounds.
\end{proposition}
\begin{proof}
Recall that, after Algorithm~\ref{alg1}, each agent knows sense of direction of its neighbors
and distances  to them.
Let  be an agent, and .
Observe that, in Algorithm~\ref{alg1},  and  start moving towards
each other in line 7 for particular  iff:
\begin{itemize}
\item
 and  have the same sense of direction, , , ; OR
\item
 and  have opposite sense of direction, , , .
\end{itemize}
\end{proof}
}


\begin{proposition}\label{prop:communication}
If each agent knows:
\begin{itemize}
\item
\vspace{-5pt}
locations of its neighbors (relative to its initial location); AND
\item
\vspace{-5pt}
sense of direction of its neighbors (with respect to its own sense of direction);
\end{itemize}
then each agent can transmit one bit of information
to its neighbors in time .
\end{proposition}
\iffull
\begin{proof}
Assume that each agent  is going to transmit bit . Consider a {\em phase}
which consists of four rounds:
\begin{itemize}
\item Round : if  then  else ;

\SingleRound, \ReversedRound

\item Round : if  then  else ;

\SingleRound, \ReversedRound
\end{itemize}
Consider an agent  and its right neighbor . We show that  is able
to determine  (the bit transmitted by ) based on results of Rounds  and  (i.e., on moments of first
collisions). We say that a round is {\em clear} if  and  collide in the middle point
between their original locations, which means that they start a round moving towards
each other.
We have two cases:

\noindent Case 1: the sense of direction of  and  agree:
 \begin{enumerate}
 \item[(a)]
 : if Round 1 is clear, then , otherwise .
 \item[(b)]
 : if Round 3 is clear, then , otherwise .
 \end{enumerate}

\noindent Case 2: the sense of direction of  and  do {\em not} agree:
 \begin{enumerate}
 \item[(a)]
 : if Round 1 is clear, then , otherwise .
 \item[(b)]
 : if Round 3 is clear, then , otherwise .
 \end{enumerate}

Communication with  can be performed in an analogous way.

\end{proof}
\else
\tj{\vspace{-5pt}
The statement of Prop.~\ref{prop:communication} can be obtained such that each
agent starts  round 1 (2, resp.) moving left/right depending on the transferred  bit. Then, the distances to the first collision in both rounds give information about the bits of  neighbors.}
\fi
Since agents can learn location of their neighbors and their sense(s) of direction
in  rounds (see Proposition~\ref{p:alg1}), Proposition~\ref{prop:communication}
leads to the following corollary.

\begin{corollary}\labell{c:sim}
There exists a possibility to exchange one bit of information
between each two neighbors in the {\perceptive} model  in time , after a  preprocessing.
\end{corollary}

The above corollary gives opportunity to simulate any distributed algorithm on a ring
in message passing model (i.e., when each pair of neighbors can exchange a message in
one round of computation).
However, the time efficiency of such simulations is limited by the fact that only one bit
of information is exchanged between neighbors in a round.


Let {\em information dissemination task} with parameters  and  be to disseminate
a message  with  bits by each agent  to all agents in ring distance 
from .
\begin{corollary}\labell{cor:disseminate}
Information dissemination task in which agents are supposed
to transmit messages of length  on the ring distance  can be accomplished in time .
\end{corollary}
A solution claimed in the above corollary might we designed such that
first all agents transmit own messages, then messages arriving from their left neighbors and finally messages arriving from their right
neighbors.

Assume that  is a set of {\em marked} agents such that each agent
knows whether it is marked or not and the ring distance between any different 
is at least . Moreover, each  has a message  of size .
The {\em sparsed information dissemination task} with parameters  and 
is to deliver the message of each  to all agents in the ring distance
 from . 
For an agent in , we denote this task by Diss().
Using the procedure exchanging a bit of information between
each pair of neighbors in time , we obtain the following result.
\begin{corollary}\labell{cor:sdisseminate}
Sparsed information dissemination task in which agents in distances  are supposed
to transmit messages of length  on the ring distance  can be accomplished in time .
\end{corollary}
In a solution to the sparsed information dissemination we have to tackle
the fact that an agent has no direct way to convey a message of the type ``I have nothing to transmit (yet)''. One can solve this issue by a simple encoding, e.g.,  encodes , while  encodes ``no bit to transmit''.

\subsection{Nontrivial Move}\labell{sub:sec:move:perc}
As we know, the nontrivial move problem is intuitively to break balance between the number
of agents moving clockwise and anticlockwise.
In our solution we use -selective families from \cite{ClementiMS03}.
\begin{definition}
Let . A family  of subsets of  is 
-selective if, for every non empty subset  of  such that , there is a
set  in  such that .
\end{definition}
Clementi et al.\ \cite{ClementiMS03} showed that 
for any  and , there exists an -selective family of size
.

Let a {\em local leader} for some fixed number  be an agent  with the largest ID among agents
in the ring distance  from .
In Algorithm~\ref{alg:move:perceptive} we present a solution to the nontrivial move
problem by establishing local leaders for exponentially growing distances  and trying
to execute -selective family on those leaders. As the number of local leaders is
, it becomes smaller than  for  and gives a nontrivial
move after  rounds.

\begin{algorithm}[]
	\caption{NMoveS()}
	\label{alg:move:perceptive}
	\begin{algorithmic}[1]
    \State ; set the status of  as a local leader;
		\State \SingleRound
    \State If the current directions give a nontrivial move: return
\State Establish -bit communication\Comment{Cor.~\ref{c:sim}}
    \For{}
        \State Sparsed dissemination of ID of local leaders on distance \Comment{Corollary~\ref{cor:sdisseminate}}
        \If{}
            \State set the status of  as the {\em local leader}
\Else
            \State set the status of  as {\em not leader}
\EndIf
\State Execute a -selective family  on the local leaders
        \State \textbf{if} a nontrivial move appears during execution of  \textbf{then} return
    \EndFor
\end{algorithmic}
\end{algorithm}



\begin{lemma}\labell{lem:ntmp}
The algorithm NMoveS solves the nontrivial move problem in  rounds
in the {\perceptive} model.
\end{lemma}
\iffull
\begin{proof}
As for correctness, the number of local leaders in the th iteration of the
for-loop is . Thus, for , the number of local leaders
is not larger than  and therefore the -selective family breaks symmetry
between them which gives a nontrivial move. 



Below, we present the above intuition in more detail.
Let us fix some ``objective correct'' sense of direction.
Let  be the subsets of agents with correct and 
incorrect sense of direction, respectively.
If the algorithm does not finish its execution in line 3,
the rotation index is in  for a round with all  equal to
{\lleft}. If exactly one agent changes its initial direction in
a round, the rotation index will increase by  or .
That is, it will not be in  since ,
and a nontrivial move will be obtained.
Let  be the set of local leaders in the th iteration of the for-loop.
If , the selective family in line 11 will select in some
round exactly one element from the set of local leaders. This follows
from the fact that the set of local leaders is not larger than 
in such case thus the -selective family is sufficient to select
exactly one element from .

Regarding time complexity, the th iteration of the for-loop requires
 rounds, which gives

rounds. \comment{
Regarding time complexity, the th iteration of the for-loop requires
 rounds, which gives

rounds. }
\end{proof}
\else
\fi

\comment{
\begin{corollary}
The leader election problem can be solved in time .
\end{corollary}
\begin{proof}
\tj{BEDZIE WYNIKAC Z REDUKCJI I TU NIEPOTRZEBNE}
First, we solve the nontrivial move problem (Lemma~\ref{lem:ntmp}). Using a nontrivial round, the common
sense of direction can be established in  rounds. Finally, the leader can
be elected in  rounds by Lemma~\ref{lem:emptiness:leader}.
\end{proof}
}

\subsection{Position Discovery in the {\perceptive} model}\labell{sub:sec:disc:perc}

In this section we design an efficient solution for the position
discovery in the {\perceptive} model. Using results from the previous
section and Theorem~\ref{ABC},
we can assume that the leader is elected and the common sense of direction is established
in  rounds.
Throughout this section, we use a labeling of agents such that  is the label of the leader and  is the
label of the th agent on the ring in the clockwise direction from the leader.


We solve the position discovery problem in two stages. First, each agent determines
its right ring distance to the leader (i.e., its {\em label}; note that a label denotes
the distance to the leader, not ID).  
In order to achieve this goal in the standard message passing model on a ring, linear
time is necessary. In order to perform this task faster, we use arithmetic relationships
between distances to collisions (\coll()) and  distances traversed in consecutive rounds (\pos()).
For appropriately designed protocol, an agent in ring distance  from the leader will
be able to learn its ring distance in  rounds.
Then, using the knowledge about ring distances of agents to the leader, the position discovery
will be finally solved in the following way. Let  be the original distances between agents.
Here, we plan movements of agents in such a way that, for each agent and each round,
the distance to collision in the round and the distance traversed in the round gives a linear equation
over  which is linearly independent from equations
derived before. In this way each round provides two new equations and  rounds are sufficient
to determine the actual values of ,
since they give a system of  independent linear equations over
 variables.




\subsubsection{Ring distances}
Now, we design the RingDist protocol in which each agent learns
its right ring distance to the leader. Throughout this section, ring distance denotes the right ring distance from
the leader. We call it a {\em label} of an agent and denote the agent in ring
distance  by .


Let Shift() for  be a round in which
 for each  and
 for .
Moreover, Shift() is a round with directions of agents
opposite to their direction in Shift().
Observe that the rotation index of Shift() is equal to 


RingDist works under assumption that (exactly) one distinguished
agent has the status leader (it is denoted ).
Each agent but the leader starts an execution of a protocol with unspecified
ring distance. The idea of Algorithm~\ref{alg:move:perceptive} is that the
agents gradually learn their ring distances in the following way:
\begin{itemize}
\item
The agents in ring distance  learn their distances in step 1
(the same applies to the agents , although they learn merely their
relative values, without knowing ).
\item
In the th iteration of the for-loop, the agents  for 
learn their ring distances in the following way (see Fig.~\ref{fig:ring:dist}).
\begin{figure}[h]
\begin{center}
  \includegraphics[scale=0.45]{ring-dist.pdf}
  \caption{An illustration for Algorithm~\ref{alg:move:perceptive}. The agent's
	label is not  for any  iff  is not equal to any of the sums
	.}
\label{fig:ring:dist}
\end{center}
\end{figure}
For each , the value of  in Shift() is equal to 
(see Prop.~\ref{prop:bounce} for ,  and thus
).
On the other hand, if one applies Shift() several times,
the values of  in the th executions of Shift() is equal to
, since the rotation index of Shift() is equal to .
Using these relationships, we see that there exists  such that 
iff .
This observation is exploited in RingDist in order to determine ring distances of 
in the th iteration of the main for-loop for .

\item
The remaining agents  for  learn their distances
in the execution of line 8, as each agent knowing
its ring distance propagates it in the distance .
\end{itemize}
Then, it remains to guarantee that the for-loop is finished when all agents
know their ring distances and .
To this aim, we execute CheckCompleteness.
Note that the agent  knows
that it is the last one already at the beginning (without knowing ), as it is
the left neighbour of the leader.
CheckCompleteness is a round in which all agents different from  move
{\lleft}, while  moves {\rright} iff it already knows its own
right ring distance (which in turn implies that every other agent knows its ring distance
as well).
Thus, the rotation index of this round is not zero iff each agent knows its ring distance.
\begin{algorithm}[]
	\caption{RingDist()}
	\label{alg:move:perceptive}
	\begin{algorithmic}[1]
\State \textbf{if} : Diss(''leader'',4)\iffull\Comment{The leader  broadcasts its message on ring distance }\else\tj{\Comment{ broadcasts on dist.\ }}\fi
    \For{}
        \State 
        \State For : Shift(); 
        \State Repeat  times: Shift() \iffull\Comment{Reverse the result of  Shift()}\else\tj{\Comment{Reverse res. of l.\ 4}}\fi
        \State Shift(); ; Shift()
        \State \textbf{if}  for some 
				and : 
				\State\phantom{abc}Set the ring distance of  to ; mark \iffull\Comment{i.e., }\else\tj{\State\phantom{abc} (i.e.,  is  and  is marked)}\fi
        \If{ for  and  marked}
					\State Diss()
					\iffull\Comment{Marked agents broadcast their ring dist.\ on distance }\else\tj{ (i.e., marked agents \State broadcast their ring dist.\ on distance )}\fi
				\EndIf
\State If CheckCompleteness: return\iffull\Comment{See description of the alg. for details}\fi
    \EndFor
\end{algorithmic}
\end{algorithm}
In the following, we show more formally that the above described idea works. First, we make
an observation following from the definition of Shift (the rotation index of Shift() is )
and Proposition~\ref{prop:bounce}.
\begin{proposition}\label{prop:shift}
Let  for .
Assume that agents  know their labels before the th
iteration of the for-loop (and other agents know that they do not belong
to ).
Then, for  the values of ,  recorded by the agent  satisfy the following
conditions in the iteration  of the for-loop:
\begin{itemize}
\item ;
\item .
\end{itemize}
\end{proposition}


\iffull
The following corollary is an immediate consequence of Proposition~\ref{prop:shift}.
\fi
\begin{corollary}\labell{cor:shift}
The condition  is satisfied for an agent  iff  is in the right ring distance
 from the leader (i.e., ).
\end{corollary}

\begin{lemma}\labell{lem:ring}
Assume that the leader is elected and all agents share common sense of direction.
Then, each agent  determines its ring distance during the algorithm RingDist and the
algorithm lasts  rounds.
\end{lemma}
\iffull
\begin{proof}
Before the for-loop, the agents in ring distance  are aware of their ring distance,
while the agent  knows that it is ``the last one''. 
We show by induction that, after the th iteration of the main for-loop, the agents
 know their labels for .
As the base step is obvious, assume inductively that before the th iteration,
the agents  know their labels. Thus, in particular
 know their labels for  since .
This assures that agents are able to perform all steps in the  iteration
of the main for-loop.
Then, Proposition~\ref{prop:shift}
and Corollary~\ref{cor:shift} imply that each agent
 for  and  becomes aware of its ring distance
before dissemination of distances in line 10.
In line 10 agents 
\tj{broadcast} information about their ring distances to agents in their ring distance
.
Thus, the remaining agents  for  learn their ring distances
from the agents .
Finally, for the smallest  such that , the for-loop
is finished and all agents know their ring distances.
In order to execute the th iteration,  rounds are sufficient
(by Corollary~\ref{cor:sdisseminate}, dissemination of distances by marked agents
can be done in  rounds).
Time complexity of the whole procedure is

\end{proof}
\else
\fi

\subsubsection{Position discovery}
In this section we describe a solution for the position discovery
problem based on protocols presented before.
Recall that, given  the common sense of direction and the leader, one can obtain a round
with rotation index  by assigning the direction  to all agents but the leader.
If  is odd, this gives a solution to the position discovery problem in  rounds.
The goal of this section is to get advantage of information provided by positions of 
the first collision in a round, in order to decrease time from  to  and manage
the case that  is even.

Here, we assume that the leader  is elected, the agent(s) in the right ring distance
 from the leader is  and each agent  knows  (see Corollary~\ref{cor:shift}). Moreover, we assume that
 is even (one can easily build a similar solution for odd ).
Let  denote the distance on the ring between the agent  and the agent 
(or  if ). (Note that this is the geometric distance on the ring, not the ring distance!)


Let Convolution() be a round in which the agents' directions are as 
\iffull
follows (see Figure~\ref{fig:red:strong}):
\else
follows:
\fi
\begin{itemize}
\item[]
,  for each , with an
exception: .
\end{itemize}
\iffull
\begin{figure}[H]
\begin{center}
\includegraphics[scale=0.45]{conv.pdf}
  \caption{An illustration of Convolution and Pivot. In Convolution(), the blue agents are the only one which do not collide with a neighbor in the middle of the distance between them. In Pivot, blue agents are the only one which collide with a neighbor in the middle of distance between them.}
\label{fig:red:strong}
\end{center}
\end{figure}
\else
\fi

Let Pivot() be a round in which the agents' directions are as follows:
 and
.
(Here, the subscript indices are calculated modulo  and  is identified
with .)
Observe that the rotation index of Convolution() is equal to  and the rotation
index of Pivot() is equal to  for each .
\begin{algorithm}[]
	\caption{Distances()}
	\label{alg:disc:perc}
	\begin{algorithmic}[1]
    \For{}
        \State Convolution
    \EndFor
    \State Pivot(); Pivot(); Pivot();
    \end{algorithmic}
\end{algorithm}
In the following, we show that information collected during an
execution of Algorithm~\ref{alg:disc:perc} can determine original
positions of all other agents. 
\begin{proposition}\label{prop:linear}
After the for-loop of Algorithm~\ref{alg:disc:perc}, the following
conditions hold:
\begin{enumerate}
\item[(a)]
the agent  can
determine the values of
 and .
\item[(b)]
the agent  can determine the values of
, , and 
\end{enumerate}
for each .
\end{proposition}
\iffull
\begin{proof}
First, observe that
the agent  stays at the original position
of  before the th execution of line 2, since the rotation index
of Convolution is equal to . Therefore, the only agent with ``swapped'' direction
stays in each round of the for loop at the original position of 
for .
As a result, the agent  learns in the st execution of line 2 exactly the same values as 
in the first execution of line 2.
Consider this first round. As  and  start
the round moving towards each other for each  (i.e., ),
they collide after traversing the distance  and therefore learn .
On the other hand, the rotation index of Convolution with any
parameter is  and thus each agent  learns .
All these observations lead to the following conclusion:
\begin{itemize}
\item
Each agent with odd label learns the values of
 for each  (registered as  in consecutive rounds)
and  (corresponding to ) for each .
\item
Each even agent learns the values of
 for each 
and  for each .
\end{itemize}
Given, the above, each agent can deduce the values enumerated
in the proposition.
E.g., each agent with add label solves the 
system of equations  for 
and  for , where  and  are
the values observed as  and  in various rounds.
\end{proof}
\else
\tj{The above proposition uses the fact that each execution of 
Convolution gives information about the sum of two consecutive
's (as the distance between an agent's position at the beginning and the end of a round) and about a particular  (the distance to the first collision is equal to halve of  for some ).}
\fi
Now, observe that
\begin{itemize}
\item
The agent  has the first collision during Pivot() in distance
 for each .
As  knows  and  by Proposition~\ref{prop:linear}(a), it can determine  from Pivot and 
therefore also .
\item
The agent  has the first collision during Pivot() in distance
 for each .
As it knows  and , it can
determine  from Pivot and then  as well.


A similar reasoning works for  as well.
\end{itemize}
By combining the above with Prop.~\ref{prop:linear}(a), one can conclude that each 
agent  with odd label  knows original positions of all agents. A similar argument
applies for even agents and executions of Pivot() and Pivot(),
since Prop.~\ref{prop:linear}(b) can be seen as Prop.~\ref{prop:linear}(a) ``shifted'' by .

\iffull
Thus, we obtain the following conclusion.
\else
\fi
\begin{lemma}\labell{lem:distances}
The protocol Distances (Alg.~\ref{alg:disc:perc}) solves the position discovery problem, provided
the leader () is elected, agents share common sense of direction
and each agent knows its ring distance.
\end{lemma}

\iffull
By combining the subroutines described before, we get the following result.
\fi
\begin{theorem}
The position discovery problem can be solved in the perceptive model
in  rounds.
\end{theorem}

