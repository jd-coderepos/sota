\documentclass{article}

\usepackage{lineno,hyperref}
\modulolinenumbers[5]

\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{tablefootnote}
\usepackage{xspace}
\usepackage{lettrine,color}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{latexsym}
\usepackage{paralist}
\newcommand{\prob}[1]{\mathbf{Pr}[#1]}
\newcommand{\Prob}[1]{\mathbf{Pr}\bigg[#1\bigg]}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage[T1]{fontenc}
\usepackage{lmodern}

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{claim}[theorem]{Claim}

\newcommand{\NATURAL}{\ensuremath{\mathbb{N}}}  \newcommand{\nat}{\ensuremath{\mathbb{N}}} 
\newcommand{\net}{\ensuremath{\mathfrak{N}}\xspace}	
\newcommand{\Exp}[1]{\mathbf{E}\left[#1\right]}	
\newcommand{\ecc}{\ensuremath{D}\xspace}
\newcommand{\comment}[1]{\text{\phantom{(#1)}} \tag{#1}
}
\newcommand{\cj}{\ensuremath{c}\xspace}
\newcommand{\ci}{\ensuremath{c_1}\xspace}
\newcommand{\cii}{\ensuremath{c_2}\xspace}
\newcommand{\ciii}{\ensuremath{c_3}\xspace}
\newcommand{\civ}{\ensuremath{c_4}\xspace}
\newcommand{\cv}{\ensuremath{c_5}\xspace}

\newcommand{\Artur}[1]{\footnote{{\sc\small \textcolor[rgb]{1.00,0.00,0.00}{\textbf{Artur:}}} \textcolor[rgb]{1.00,0.00,0.00}{#1}}}



\title{Communicating with Beeps\footnote{Research partially supported by the Centre for Discrete Mathematics and its Applications (DIMAP).}}

\bibliographystyle{plain}

\begin{document}
	



\author{\textbf{Artur Czumaj} \hspace{4mm} \textbf{Peter Davies} \
	\sum_{i=1}^{\log D} \frac{2^i \log M}{i}
	&\le
	\log M \left(\sum_{i=1}^{\frac{\log D}{2}} \frac{2^i}{i} +
	\sum_{i=\frac{\log D}{2}}^{\log D} \frac{2^i}{i}\right)
	\\
	&\le
	\log M \left(\sum_{i=1}^{\frac{\log D}{2}} 2^i +
	2\sum_{i=\frac{\log D}{2}}^{\log D} \frac{2^i}{\log D}\right)
	\\
	&\le
	\log M \left(2\sqrt D + \frac{4D}{\log D}\right)
	=
	O\left(\frac{D\log M}{\log D}\right)
	\enspace.
	\qedhere
	
	\sum_{i=1}^{\log L} c (D + k_i)
	& =
	c D \log L + c \left(\sum_{i=1}^{\log k} k_i + \sum_{i=\log k+1}^{\log L} k_i\right)\\
	&\le
	c D \log L + c \left(\sum_{i=1}^{\log k} 2^{i-1} + \sum_{i=\log k+1}^{\log L} k\right)
	\\
	& \le
	c D \log L + c(k + k(\log L - \log k))
	=
	O(D \log L + k \log \frac{L}{k})
	\enspace.
	
		c D \log L + \sum_{i=1}^{t} c (D+ k_i)
		&\le
		c D \log L + \sum_{i=1}^{t} 2cD
		\\
		&\le
		c D \log L + \sum_{i=1}^{\log L} 2cD
		\\
		&=
		3 c D \log L
		=
		O(D \log L)
		\enspace,
		
		\sum_{i=1}^{\log M} c (D + \tilde{k}_i)
		& =
		c D \log M + c \left(\sum_{i=1}^{\log k} \tilde{k}_i + \sum_{i=\log k+1}^{\log M} \tilde{k}_i\right)
		\\
		&\le
		c D \log M + c \left(\sum_{i=1}^{\log k} 2^{i-1} + \sum_{i=\log k+1}^{\log M} k\right)
		\\
		& \le
		c D \log M + c(k + k(\log M - \log k))
		\\
		&=
		O(D \log M + k \log \frac{M}{k})
		\enspace.
		
		O(D \log L + D \log M + k \log \frac{M}{k})
		&=
		O(D \log L + D \log \frac{M}{k} + D \log k + k \log \frac{M}{k})
		\\
		&=
		O(k \log \frac{M}{k} + D \log L)
		\enspace,
		
		\sum_{i=1}^{\log M} c (D + \tilde{k}_i)
		& =
		c D \log M + c \sum_{i=1}^{\log M} \tilde{k}_i
		\le
		c D \log M + c \sum_{i=1}^{\log M} 2^{i-1}\\
		&\le
		cD \log M + cM
		=
		O(D \log M + M)
		\enspace.
		\prod_{v\in K} \Prob{C(v)_i = \textbf 0} \geq \prod_{v\in K} (1-\frac{1}{2k})\geq \prod_{v\in K} 4^{-\frac{1}{2k}} = 4^{-\frac{k}{2k}}= \frac 12\enspace.
	\prod_{i\in [\ell]} \Prob{\lnot \left(C(u)_i = \textbf 1\land \bigvee_{v\in K}C(v)_i = \textbf 0\right)} &\leq \prod_{i\in [\ell]} (1-(\frac {1}{2k}\cdot \frac 12))\\
	&\leq \prod_{i\in [\ell]} e^{\frac {-1}{4k}} = e^{\frac{-\ell}{4k}}
	\binom{X}{8k}  (e^{\frac{-\ell}{4k}})^{8k} \leq \left(\frac{ex}{8k}\right)^{8k}e^{-2\ell}\leq e^{8k\ln \frac xk - 2\ell}\leq e^{-4k\ln\frac xk}
		\cj\sum\limits_{q=\log j'}^{\log k}&\left(D+2^q\log \frac {M}{2^q}\right)
		\leq \cj(D\log\frac{k}{j'} +\sum\limits_{q=1}^{\log k}(2^q\log M-q2^q))\\
		&\leq \cj(j'\log \frac {M}{j'}\log\frac{k}{j'} + 2^{\log k + 1}\log M - (\log k -1) 2^{\log k + 1})\\
		&\leq \cj(k\log \frac {M}{k} + \log\frac{2M}{k}2^{\log k + 1})\\
		&\leq 5\cj k \log \frac Mk\enspace,
		
		\cj\sum\limits_{q=\log j'}^{\log \frac M2}&\left(D+2^q\log \frac {M}{2^q}\right)
		\leq \cj(D\log\frac{M}{2j'} +\sum\limits_{q=1}^{\log \frac M2}(2^q\log M-q2^q))\\
		&\leq \cj(j'\log \frac {M}{j'}\log\frac{M}{2j'} + 2^{\log M}\log M - (\log M -2) 2^{\log M})\\
		&\leq \cj(\frac M2 + 2M)\\
		&\leq 3\cj M\enspace,
		
	&\Prob{OUTPUT_v \text{ is correct}} = \binom{M}{k}^{-1} \sum\limits_{\textbf m\in\binom{[M]}{k}} \Prob{OUTPUT_v =\textbf m | m = \textbf m}\\
	&\hspace{1cm}\leq \binom{M}{k}^{-1} \sum\limits_{\textbf{m}\in\binom{[M]}{k}} \Prob{OUTPUT_v =\textbf{m} | m =\textbf{m}, Q_{\leq T} = q_\textbf{m}}\\
	&\hspace{1cm}\leq \binom{M}{k}^{-1}\left(\frac{M}{k}\right)^\frac k2\leq  \left(\frac{M}{k}\right)^{-k}\left(\frac{M}{k}\right)^\frac k2 = \left(\frac{M}{k}\right)^{-\frac k2} \enspace.
	\prob{OUTPUT_v=\textbf m|X^{i}_{T-1}=Xmax^{i}_\textbf m, m=\textbf m}\sum_{x^i =1}^{\frac{\log M}{\cj\log D}}\binom{T}{x^i}
	\leq \frac{\log M}{\cj\log D} \left(\frac{Te}{\frac{\log M}{\cj\log D}}\right)^\frac{\log M}{\cj\log D} =
	\frac{\log M}{\cj\log D} \left(\frac{eD}{\cj}\right)^\frac{\log M}{\cj\log D}
	\leq 2^\frac{\log M}{\cj}
	= M^\frac 1\cj
	\sum_{\textbf m\in [M]}\prob{OUTPUT_v=\textbf m|X^{i}_{T-1}=Xmax^{i}_\textbf m, m=\textbf m, x^i\leq \frac{\log M}{\cj\log D}} \leq M^\frac 1\cj\enspace,
	&\prob{OUTPUT_v\text{ is correct}|x^i\leq \frac{\log M}{\cj\log D}}\\ &\hspace{5mm}\leq \frac 1M \sum_{\textbf m\in [M]}\prob{OUTPUT_v=\textbf m|m=\textbf m, x^i\leq \frac{\log M}{\cj\log D}}\\
	&\hspace{5mm}\leq \frac 1M \sum_{\textbf m\in [M]}\prob{OUTPUT_v=\textbf m|X^{i}_{T-1}=Xmax^{i}_\textbf m,m=\textbf m, x^i\leq \frac{\log M}{\cj\log D}}\\
	&\hspace{5mm}\leq \frac{M^\frac 1\cj}{M} = M^{\frac 1\cj-1}\enspace.
	\Exp{T} > \frac{pD\log M}{2\cj\log D}=\frac{D\log M}{\cj^2\log D}\enspace.
	
	This is a contradiction, and so it must be the case that . Since  is arbitrarily large, we have shown that any algorithm with  success probability must take  expected time, and conversely, any algorithm taking   expected time has  success probability.
\end{proof}

\section{Discussion and Open Problems}
Models for networks of very weak devices, such as the beep model, are growing in popularity as such devices become cheaper and more commercially viable; examples of their use include sensor networks and RFID tagging. Our aim here is to provide the first systematic study of algorithms for global tasks in such a model. Our running times are mostly optimal, with the only major grounds for improvement being an optimal \emph{explicit} multi-broadcast algorithm. However, there are several other interesting aspects of the beep model which could merit further research.

One crucial concern in networks of this type is that \emph{energy} is often highly constrained: we may wish to minimize the amount of times nodes transmit (and possibly even listen; we could introduce a third option of `do nothing' in a time-step). A study of how little energy is required to complete communication tasks in the beep model would be interesting.

Another research direction is further weaken the assumptions of the model, in order to make it as widely applicable as possible. The major assumption remaining is that time-steps are \emph{synchronous}, i.e. that nodes local clocks all `tick' at the same rate and beeps are heard immediately. There are several possible ways of modeling \emph{asynchronicity}, and exploring what can be done in asynchronous beeping networks. One work in this direction is \cite{-HP16}.

\newcommand{\Proc}{Proceedings of the\xspace}
\newcommand{\SODA}{Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)}
\newcommand{\PODC}{Annual ACM Symposium on Principles of Distributed Computing (PODC)}
\newcommand{\DISC}{International Symposium on Distributed Computing (DISC)}
\newcommand{\JALGORITHMS}{Journal of Algorithms}

\bibliography{beep}{}

\end{document}
