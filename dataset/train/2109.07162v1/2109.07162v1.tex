\def\year{2022}\relax
\documentclass[letterpaper]{article} \usepackage{aaai22}  \usepackage{times}  \usepackage{helvet}  \usepackage{courier}  \usepackage[hyphens]{url}  \usepackage{graphicx} \urlstyle{rm} \def\UrlFont{\rm}  \usepackage{natbib}  \usepackage{caption} \DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} \frenchspacing  \setlength{\pdfpagewidth}{8.5in}  \setlength{\pdfpageheight}{11in}  \usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{newfloat}
\usepackage{listings}
\lstset{basicstyle={\footnotesize\ttfamily},numbers=left,numberstyle=\footnotesize,xleftmargin=2em,aboveskip=0pt,belowskip=0pt,showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
\pdfinfo{
/Title (AAAI Press Formatting Instructions for Authors Using LaTeX -- A Guide)
/Author (AAAI Press Staff, Pater Patel Schneider, Sunil Issar, J. Scott Penberthy, George Ferguson, Hans Guesgen, Francisco Cruz, Marc Pujol-Gonzalez)
/TemplateVersion (2022.1)
}



\setcounter{secnumdepth}{2} 





\title{MISSFormer: An Effective Medical Image Segmentation Transformer}
\author{
Xiaohong Huang,\textsuperscript{\rm 1}
	Zhifang Deng,\textsuperscript{\rm 1}
	Dandan Li,\textsuperscript{\rm 1}\thanks{Corresponding author}
	Xueguang Yuan\textsuperscript{\rm 1}
}
\affiliations{
\textsuperscript{\rm 1} Beijing University of Posts and Telecommunications\\




huangxh@bupt.edu.cn, dengzfong@bupt.edu.cn, dandl@bupt.edu.cn, yuanxg@bupt.edu.cn
}


\iffalse
\title{My Publication Title --- Single Author}
\author {
    Author Name
}
\affiliations{
    Affiliation\\
    Affiliation Line 2\\
    name@example.com
}
\fi

\iffalse
\title{My Publication Title --- Multiple Authors}
\author {
First Author Name,\textsuperscript{\rm 1}
    Second Author Name, \textsuperscript{\rm 2}
    Third Author Name \textsuperscript{\rm 1}
}
\affiliations {
\textsuperscript{\rm 1} Affiliation 1\\
    \textsuperscript{\rm 2} Affiliation 2\\
    firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com
}
\fi


\usepackage{bibentry}


\begin{document}

\maketitle

\begin{abstract}
The CNN-based methods have achieved impressive results in medical image segmentation, but it failed to capture the long-range dependencies due to the inherent locality of convolution operation. Transformer-based methods are popular in vision tasks recently because of its capacity of long-range dependencies and get a promising performance. However, it lacks in modeling local context, although some works attempted to embed convolutional layer to overcome this problem and achieved some improvement, but it makes the feature inconsistent and fails to leverage the natural multi-scale features of hierarchical transformer, which limit the performance of models. In this paper, taking medical image segmentation as an example, we present MISSFormer, an effective and powerful Medical Image Segmentation tranSFormer. MISSFormer is a hierarchical encoder-decoder network and has two appealing designs: 1) A feed forward network is redesigned with the proposed Enhanced Transformer Block, which makes features aligned adaptively and enhances the long-range dependencies and local context. 2) We proposed Enhanced Transformer Context Bridge, a context bridge with the enhanced transformer block to model the long-range dependencies and local context of multi-scale features generated by our hierarchical transformer encoder. Driven by these two designs, the MISSFormer shows strong capacity to capture more valuable dependencies and context in medical image segmentation. The experiments on multi-organ and cardiac segmentation tasks demonstrate the superiority, effectiveness and robustness of our MISSFormer, the exprimental results of MISSFormer trained from scratch even outperforms state-of-the-art methods pretrained on ImageNet, and the core designs can be generalized to other visual segmentation tasks. The code will be released in Github.
\end{abstract}

\section{Introduction}
\noindent With the improvement of medical treatment and the people's health awareness, the requirements of highly accurate medical image analysis (such as preoperative evaluation, auxiliary diagnosis) have become more prominent, and the medical image segmentation, as a crucial step of them, the precise and robust segmenation results will provide a good foundation for subsequent analysis and treatment.

Since the fully convolutional networks (FCNs)\cite{Long2015} opened a door for semantic segmentation, one of its variants, the U-shaped networks\cite{2015U,iek20163D} got a promising performance in medical image segmentation by the improvement of skip connection, which provided more detailed information. According to this elegant architecture, the variants of U-Net\cite{Isensee2021,Zhou2018,huang2020unet} have been achieved excellent performance and impressive results. Although their awesome performance and prevalence, the CNN-based methods suffer from a limitation in modeling the long-range dependencies because of the locality of convolution operation\cite{Cao2021,Xie2021}, and they failed to achieve the goal of precise medical image analysis. To overcome the limitation, some works proposed dilated convolution\cite{Gu2019,Feng2020} and pyramid pooling\cite{zhao2017pyramid} to enlarge the receptive field as much as possible. And some recent works\cite{Xie2021,mou2019cs,Chen2021,Sinha2020} tried to employ few self-attention layers or transformer layers\cite{vaswani2017attention} in high-level semantic feature maps due to the quadratic relationship between self-attention computational complexity and feature map size, which makes these methods insufficient to capture the abundant long-range dependencies.

Recently, the success of transformers that capture long-range dependencies makes it possible to solve the above problems. Especially, the researches on visual transformer\cite{Liu2021,Dosovitskiy2020,Wang2021,Graham2021,Chu2021,Xie2021a,zheng2021rethinking} are in full swing and have got a promising performance in vision tasks, encouraged by the great success of transformer in natural language processing (NLP). Corresponding to the transformer in NLP, vision transformer\cite{Dosovitskiy2020} fed the image into standard transformer with positional embeddings by dividing an image into non-overlapping patches and achieved comparable performance with CNN-based methods. Pyramid vision transformer (PVT)\cite{Wang2021} and Swin transformer\cite{Liu2021} proposed hierarchical transformer to explore the vision transformer with spatial reduction attention (SRA) and window-based attention respectively, which are responsible for reducing computational complexity. Besides, the attempts of SETR\cite{zheng2021rethinking} in semantic segmentation proved the potential of transformer in visual tasks once again. 

However, some recent works\cite{Islam2020,Chu2021a,Li2021} showed the limitation of self-attention on local context, inspired by this, Uformer\cite{Wang2021a}, SegFormer\cite{Xie2021a} and PVTv2\cite{Wang2021b} tried to embed convolutional layer between fully-connected layers of feed forward network in transformer block to overcome this problem. Despite it captured local context to some extent, but there are some limitations: 1) the convolutional layer is embeded between fully-connected layers of feed forward network directly, which destroys the consistency and delivery between features, although supplement some local context and get better performance. 2) it did not consider the integration of multi-scale information generated by hierarchical encoder. Both limitations lead to the inferior learning of networks. 

In this paper, MISSFormer, an effective and powerful Medical Image Segmentation tranSFormer, is proposed to leverage the powerful long-ranged dependencies capability of self-attention to produce accurate medical image segmentation. MISSFormer is based on the U-shaped architecture, whose redesigned transfomer block, named Enhanced Transformer Block, makes feature consistent and enhance the feature representations. The MISSFormer consists of encoder, bridge, decoder and skip connection, these components are all builded from the enhanced tansformer block. The encoder extracts hierarchical features through the overlapped image patches, dependencies between different scale features are modeled via bridge, and decoder is responsible for pixel-wise segmentation prediction with skip connection. The main contributions of this paper can be summarized as follows:
\begin{itemize}
	\item We propose MISSFormer, a position-free and hierarchical U-shaped transformer for medical image segmentation.
	\item We redesign a powerful feed forward network, Enhanced Mix-FFN, with better feature consistensy, long-range dependencies and local context, based on this, we expand it and get an Enhanced Transformer Block to make a strong representation.
	\item We propose an Enhanced Transformer Context Bridge based on the Enhanced Transformer Block to capture the correlations of hierarchical multi-scale features.
	\item The superior experimental results on medical image segmentation datasets demonstrate the effectiveness, superiority and robustness of the proposed MISSFormer.
\end{itemize}

\section{Related Work}
\textbf{Medical image segmentation.} Medical image segmentation is a pixel level task of seperating the lesions or organs pixels in a given medical image. U-shaped network\cite{2015U} played a cornerstone role in medical image segmentation tasks because of its superior performance and elegant structure. Benefiting from the rapid development of computer vision tasks\cite{he2016deep,Chen2017}, the medical image segmentation drew lessons from its key insight, for example, resnet architecture became a general encoder backbone for medical image segmentation network, the dilated convolution and pyramid pooling were utilized to enlarge the receptive field for lesion and organ segmentation\cite{Gu2019,Feng2020}. Besides, various attention mechanisms were effective to promote segmentation performance, reverse attention\cite{chen2018reverse} was applied to accurate polyp segmentation\cite{fan2020pranet}, squeeze-and-excitation attention\cite{hu2018squeeze} was integrated into module to refine the channel information to segment vessel in retinal images\cite{zhang2019net}, and some works\cite{mou2019cs,Sinha2020} employed self-attention mechanism to supplement the long-range dependencies for segmentation tasks.

\textbf{Vision transformers.} ViT\cite{Dosovitskiy2020} introduced transformer\cite{vaswani2017attention} into visual tasks for the first time and achieved impressive performance because of the capacity for global dependencies of transformer. Vision tasks developed a new stage inspired by ViT, for example, DeiT\cite{touvron2021training} explored the efficient training strategies for ViT, PVT\cite{Wang2021} proposed a pyramid transformer with SRA to reduce the computational complexity, and Swin transformer\cite{Liu2021} was an efficient and effective hierarchical vision transformer, whose window-based mechanism enhances the locality of features, which was also the improvement of some excellent transformer works\cite{Islam2020,Chu2021a,Li2021}. For other specific tasks, SETR\cite{Zheng2021} was a semantic segmentation network based on transformer and made ViT as backbone, SegFormer\cite{Xie2021a} introduced a simple and efficient design for semantic segmentation powered by transformer, DETR\cite{Carion2020} proposed an end-to-end object detection framework with transformer, Uformer\cite{Wang2021a} builded a general U-shaped transformer for image restoration.

\textbf{Transformers for medical image segmentation.} Researchers borrowed the transformer to medical image segmentation inspired by the rapid development of vision transformers. Transunet\cite{Chen2021} employed some transformer layers into the low resolution encoder feature maps to capture the long-range dependencies, UNETR\cite{Hatamizadeh2021} applied transformer to make a powerful encoder for 3d medical image segmentation with CNN decoder, CoTr\cite{Xie2021} and TransBTS\cite{Wang2021c} bridged the CNN-based encoder and decoder with the transformer to improve the segmentation performance in low resolution stage. Besides these methods which are the combination of CNN and transformer, \cite{Cao2021} proposed Swin-Unet, based on Swin transformer\cite{Liu2021}, to demonstrate the application potential of pure transformer in medical image segmentations. However, Swin-Unet, whose encoder backbone is Swin transformer pretrained on ImageNet, requires pre-training on large-scale datasets, different from it, the proposed MISSFormer is trained on the medical image datasets from scratch, and achieves better performance because of the discriminative feature representations by Enhanced Transformer Block. 
\begin{figure*}[t]
	\centering
	\includegraphics[width=2\columnwidth]{overall.pdf} \caption{The overall structure of proposed MISSFormer. (a) The proposed MISSFormer framework. (b) The structure of Enhanced Transformer Block.}.
	\label{fig1}
\end{figure*}
\section{Method}
This section describes the overall pipeline and the specific structure of MISSFormer first, and then we show the details of the improved transformer block, Enhanced Transformer Block, which is the basic unit of MISSFormer. After that, we introduce the proposed Enhanced Transformer Context Bridge, which models the correlations of hierarchical multi-scale information.
\subsection{Overall Pipline}
The proposed MISSFormer is shown in Fig.1(a), which is a hierarchical encoder-decoder architecture, with enhanced transformer context bridge module appended between encoder and decoder. Specifically, given an input image, MISSFormer first divides it into overlapping patches of size 4*4 to preserve its local continuity with convolutional layers. Then, the overlapping patches are fed into encoder to produce the multi-scale features. Here, the encoder is hierarchical and each stage includes enhanced transformer blocks and patch merging layer, enhanced transformer block learns the long-range dependencies and local context with limited computational complexity, patch merging layer is applied to generate the downsampling features.

After that, MISSFormer makes the generated multi-scale features pass through the Enhanced Transformer Context Bridge to caputure the correlations of different scale features. In practical, different level features is flattened in spatial dimension and reshape them to make consistent in channel dimension, then concatenate them in flattened spatial dimention and feed into the enhanced transformer context bridge with \textit{d-}depth. After that, we split and restore them to their original shape and obtain the discriminative hierarchical multi-scale fetures. 

For the segmentation prediction, MISSFormer takes the descriminative features and skip connections as inputs of decoder. Each decoder stage includes Enhanced Transformer Blocks and patch expanding layer\cite{Cao2021}. Contrary to patch merging layer, the patch expanding layer upsample the adjacent feature maps to twice the original resolution except that the last one is four times, and last, the pixel-wise segmentation prediction is output by a linear projection.

\begin{figure*}[t]
	\centering
	\includegraphics[width=2\columnwidth]{enhanced_mix-ffn.pdf} \caption{The various exploration of locality in feed forward nerual network, from left to right: (a) LeFF in Uformer, (b) Mix-FFN in SegFormer and PVTv2, (c) proposed Simple Enhanced Mix-FFN, (d) proposed Enhanced Mix-FFN}
	\label{fig2}
\end{figure*}
\subsection{Enhanced Transformer Block}
Long-range dependencies and local context are effective for accurate medical image segmentation, transformer and convolution are better for long-range dependencies and locality in present, respectively. While computational complexity the original transformer block is quadratic with the feature map resolution, which makes it unsuitable for high resolution feature maps. Second, transformer lacks the ability to extract the local context\cite{Islam2020,Chu2021a,Li2021}, although Uformer, SegFormer and PVTv2 tried to overcome the limitation by embedding a convolutional layer in feed forward netwok directly, we argue that this approach makes the feature consistency broken and and hinder the feature delivery, even some improved performance is achieved by them. 

In order to solve the above problems, we proposed Enhanced Transformer Block. As is shown in Fig.1(b), the Enhanced Transformer Block is composed of LayerNorm, Efficient Self-Attention and Enhanced Mix-FFN.

\textbf{Efficient Self-Attention.} Efficient self-attention is a spatial reduction self-attention\cite{Wang2021}, which can be applied to high resolution feature map. Given a feature map F, and H,W,C is the height, width and channel depth respectively. For the original standard multi-head self-attention, it makes Q,K,V have same shape N \times C, where N = H \times W, which can be formulated as:

and its computational complexity is . While for the efficient self-attention, it applied a spatial reducation ratio  to  reduce the spatial resolution as follows:

it first reshapes  and  to , and then a linear projection  is used to make channel depth restore to . After that, the computational complexity of self-attention reduces to , and can be applied to high resolution feature maps. The spatial reduction operation is convolution or pooling in common.

\textbf{Enhanced Mix-FFN.} Different from previous methods in Fig.2(a) and (b), we redesigned the structure of Mix-FFN to align feature and make discriminative representations. As shown in Fig.2(c), First we add a skip connection before the depth-wise convolution for the feature diversity and delivery, we will show that the skip connection is essential for Mix-FFN in Section 4.2. Then, we applied layer norm after the skip connection for aligning features and better consistensy and convergency, which can be formulated as:

where,  is the output of efficient self-attention,  is convolution with kernel , we applied depth-wise convolution for efficiency in this paper actually. 

Inspired by\cite{liu2020rethinking}, we extend our design to a general form with the help of layer norm, which facilitate the optimization of skip connection\cite{vaswani2017attention}. As shown in Fig.2(d), we make a Enhanced Mix block embeded in the original feed-forward network. We introduced recursive skip connection in Enhanced Mix block, given an input feature map , a depth-wise convolution layer is applied to capture the local context, and then a recursive skip connection follwed, and it can be defined as:

where .
After that, the model makes more expressive power due to the construction of different feature distribution and consistensy by each recursive step.

\subsection{Enhanced Transformer Context Bridge}

\begin{table}[t]
	\centering
	\begin{tabular}{l|c|c}	
		\hline
		Architecture &DSC & HD \\
		\hline
		\hline
		SegFormer (Xie et al. 2021) &75.24 & \textbf{25.07}\\
		U-SegFormer& \textbf{76.10}& 26.97\\
		\hline
	\end{tabular}
	\caption{Accuracy on Synapse dataset of SegFormer and U-SegFormer}
	\label{table1}
\end{table}
\begin{table}[t]
	\centering
	\begin{tabular}{l|c|c|c|c}
		\hline
		Architecture & skip&  LN&DSC & HD \\
		\hline
		\hline
		U-SegFormer& --& --& 76.10 & 26.97\\
		U-SegFormer w/skip& cat& --& 78.14& 28.77\\
		U-SegFormer w/skip& add& --& 78.74& 20.20\\
		Simple\_MISSFormer& \checkmark& \checkmark& \textbf{79.73}& \textbf{20.14}\\
		\hline			
	\end{tabular}
\caption{Effectiveness of feature consistensy and delivery in Simple Enhanced Mix-FFN, cat indicates concatenation operation for skip connection, add means summation. }
	\label{table2}
\end{table}
\begin{table}[!h]
	\centering
	\begin{tabular}{l|c|c|c}
		\hline
		Achitecture & step &DSC & HD \\
		\hline
		\hline
\multirow{3}{*}{MISSFormer\_S}
		& 1& 79.73& 20.14	\\
		& 2& 79.91& 21.33	\\
		& 3& \textbf{80.74}& \textbf{19.65}	\\
		\hline	
	\end{tabular}
	\caption{Impact of recursive skip connection in Enhanced Mix-FFN, step means recursive step. }
	\label{table3}
\end{table}

Multi-scale information fusion has been proved to be crucial for accurate semantic segmentation in CNN-based method\cite{Sinha2020,Chen2017}. In this part, we explore the multi-scale feature fusion for the Transformer-based method by the aid of hierarchical structure of MISSFormer. The multiple stage feature maps are obtained after feeding the patches into encoder, whose settings of patch merging and channel depth in every stage keep same with SegFormer. Given multi-level features , which are generated by hierarchical encoder, we flatten them in spatial dimension and reshape them to keep the channel depth same with each other, then we concatenate them in flattened spatial dimension, after that, the concatenated token is fed into enhanced transformer block to construct the long-range dependencies and local context correlation. The process can be summarized as formula (5).


After the feature passed through  enhanced transformer block, we split tokens and restore them to original shape of features in every stage, and feed them into transformer-based decoder with corresponding skip connection to predict the pixel-wise segmentation map. The depth of Context Bridge is set to 4 in this paper.
\section{Experiments}
In this section, we first conduct the experiment of ablation studies to validate the effectiveness of each component in MISSFormer, and then the comparation results with previous state-of-the-art methods are reported to demonstrate the superiority of the proposed MISSFormer.
\subsection{Experiments Settings}
\textbf{Datasets.} We perform experiments on two different formats of datasets: Synapse multi-organ segmentation dataset (Synapse) and Automated cardiac diagnosis challenge dataset (ACDC). The Synapse dataset includes 30 abdominal CT scans with 3779 axial abdominal clinical CT images, and the dataset is divided into 18 scans for training and 12 for testing randomly, follow the \cite{Cao2021,Chen2021}. We evaluate our method with the average Dice-SÃ¸rensen Coefficient (DSC) and average Hausdorff Distance (HD) on 8 abdominal organs (aorta, gallbladder, spleen, left kidney, right kidney, liver, pancreas, spleen, stomach). The ACDC dataset includes 100 MRI scans collected from different patients, and each scan labeled three organs, left ventricle (LV), right ventricle (RV) and myocardium (MYO). Consistent with the previous method\cite{Cao2021,Chen2021}, 70 cases are used for training, 10 for validation and 20 for testing, and the average DSC is applied to evaluate the method. It should be noted that we split the dataset randomly because we can not get the divided ACDC data used in the previous method, so we reimplement the TransUnet\cite{Chen2021} and SwinUnet\cite{Cao2021} on our divided dataset and keep same settings with original methods.

\textbf{Implementation details.} The MISSFormer is implemented based on PyTorch and trained on Nvidia GeForce RTX 3090 GPU with 24 GB memory. Different from previous work\cite{Cao2021,Chen2021}, whose model is initialized by the pretrained model on ImageNet, the MISSFormer is initialized randomly and trained from scratch, so, the moderate data augmentation is conducted for all datasets, the initial learning rate is 0.05 and poly learning rate policy is used, the max training epoch is 400 with batchsize of 24. SGD optimizer with momentum 0.9 and weight decay 1e-4 is adopted for MISSFormer. 
\begin{table}[t]
	\centering
	\begin{tabular}{l|c|c|c|c}
		\hline
		Achitecture & step& bridge\_4 & DSC & HD \\
		\hline
		\hline
\multirow{3}{*}{MISSFormer\_S}
		& 1&--& 79.73& 20.14	\\
		& 2&--& 79.91& 21.33	\\
		& 3&--& 80.74&19.65	\\	
		\hline
		\multirow{3}{*}{MISSFormer}
		& 1&\checkmark& \textbf{81.96}& \textbf{18.20}	\\
		& 2&\checkmark& 80.91& 19.48	\\
		& 3&\checkmark& 80.72& 23.43	\\	
		\hline
	\end{tabular}
	\caption{Impact of Enhance Transformer Context Bridge on recursive skip connection of MISSFormer. }
	\label{table4}
\end{table}
\begin{table}[t]
	\centering
	\begin{tabular}{l|c|c|c|c}
		\hline
		Achitecture & depth & stage & DSC & HD \\
		\hline
		\hline
\multirow{6}{*}{MISSFormer    }
		& 2&4321& 80.19& 18.88	\\
		& 4&4321& \textbf{81.96}& \textbf{18.20}	\\
		& 6&4321&81.03&21.36	\\	\cline{2-5} 
& 4&432& 80.65&18.39\\
		& 4&43& 79.86& 20.33	\\
		& 4&4& 79.56 &20.95	\\	
		\hline
	\end{tabular}
\caption{Exploration of bridge depth and multi-scale information in MISSFormer. }
	\label{table5}
\end{table}


\begin{table*}[t]
	\centering
	\begin{tabular}{l|c|c|c|c|c|c|c|c|c|c}
		\hline
		Methods & DSC & HD  & Aorta & Gallbladdr&Kidney(L)&Kidney(R)&Liver&Pancreas&Spleen&Stomach \\
		\hline
		\hline
V-Net&68.81&-&75.34&51.87&77.10&80.75&87.84&40.05&80.56&56.98\\
		DARR &69.77&-&74.74&53.77&72.31&73.24&94.08&54.18&89.90&45.96\\
		R50 U-Net&74.68&36.87&87.74&63.66&80.60&78.19&93.74&56.90&85.87&74.16\\
		U-Net&76.85&39.70&89.07&\textbf{69.72}&77.77&68.60&93.43&53.98&86.67&75.58\\
		R50 Att-Unet&75.57&36.97&55.92&63.91&79.20&72.71&93.56&49.37&87.19&74.95\\
		Att-UNet&77.77&36.02&\textbf{89.55}&68.88&77.98&71.11&93.57&58.04&87.30&75.75\\
		R50 ViT&71.29&32.87&73.73&55.13&75.80&72.20&91.51&45.99&81.99&73.95\\
		Transunet&77.48&31.69&87.23&63.13&81.87&77.02&94.08&55.86&85.08&75.62\\
		Swin-Unet&79.12&21.55&85.47&66.53&83.28&79.61&94.29&56.58&90.66&76.60\\
		\hline
		MISSFormer\_S&80.74&19.65&85.31&66.47&83.37&81.65&\textbf{94.52}&63.49&91.51&79.63\\
		MISSFormer&\textbf{81.96}&\textbf{18.20}&86.99&68.65&\textbf{85.21}&\textbf{82.00}&94.41&\textbf{65.67}&\textbf{91.92}&\textbf{80.81}\\
		\hline
	\end{tabular}
	\caption{Comparison to state-of-the-art methods on Synapse dataset.}
	\label{table6}
\end{table*}

\subsection{Ablation Studies}
We conduct ablation studies on Synapse dataset to varify the effectiveness of the essential component in our approach. We set the SegFormer\_B1 as baseline method, and the number of transformer block in every stage of encoder and decoder is set to 2 to keep the same with other methods for fair comparison. All experiments are performed with the same super parameter settings and trained from scratch. 

\textbf{Architecture selection.} We replace the SegFormer\_B1 MLP decoder with its transformer block and patch expanding to make it U-shaped SegFormer, called ``U-SegFormer", and the results are shown in table 1. As we can see, the U-SegFormer achieved better performance than SegFormer due to the U-shaped model can fuse more corresponding details information with skip connection in each stage, although the SegFormer integrate multi-level information. The skip-connection is applicable for U-shaped network based transformer as before.

\textbf{Effectiveness of feature consistensy and delivery.} Based on U-shaped transformer, we further perform the experiments to validate the impact of feature consistensy and delivery. Table 2 reports the comparison results. We first design different skip connections: concatenation and summation. Table 2 shows that both skip connections boost the model performance greately, and the summation skip connection even improved more than 2.6\%, which provide strong support for our above analysis, and prove that effectiveness of skip connection and importance of enhancing feature delievery. Then, we explore the gap caused by the direct embedding of convolution, a layer norm is applied to align the feature and distribution, we integrate it after the skip connection, which is called Simple  MISSFormer, and it has even 1\% improvements based on U-SegFormer w/skip. Finally, with the help of redesigned feed-forward network, we improved feature distributions and enhanced feature representations to generate an increasing promotion of 3.63 DSC, compared with U-SegFormer baseline.
\begin{figure*}[t]
	\centering
	\includegraphics[width=2\columnwidth]{result.pdf} \caption{The visual comparison with previous state-of-the-art methods on Synapse dataset. Above the red line is good cases, and below it is a failed case, Our MISSFormer shows a better performance than other method}.
	\label{fig3}
\end{figure*}

\textbf{Impact of further feature consistensy in Enhanced Mix Block.} Inspired by above exploration and \cite{liu2020rethinking}, we extend redesigned FFN of Simple\_MISSFormer to make it more general, we call it MISSFormer\_S due to the absence of multi-scale integration. We design experiments to assess the influence of further consistensy and distribution caused by different recursive steps, and its results are recoreded in table 3. The results become better with the increasement of recursive step, which further improved the necessity and effectiveness of feature consistensy and distribution when convolution is embedded in FFN.

\textbf{Influence of Enhanced Transformer Context Bridge.} We conducted experiments to explore the role of multi-scale information in transformer-based methods on acount of the hierarchical features generated by MISSFormer encoder. As table 4 shows, we list the results of MISSFormer\_S for intuitionistic comparison, and the performance of the model has been improved to varying degrees except step equals 3 after embedding the Enhanced Transformer Context Bridge into MISSFormer\_S, we call it as MISSFormer. We observe that the model achieved best performance to have a 2.26\% DSC improvement when step is 1 and the growth rate is gradually decreasing with the increasement of recrsive step, even negative. We guess that there is a balance between the recursive step and Enhanced Transformer Context Bridge or between the number of layernorm and model capacity, which will be discussed in our future work. Besides, we also investigated how bridge depth and multi-scale information integration affect model performance, and the results are saved to table 5. For the exploration of bridge depth, 4 is a suitable depth in MISSFormer beacause of the limited medical data. For transformer-based hierarchical features, the more scale features are fed into the enhanced transformer context bridge, the more comprehensive the model can be learned for long-range dependencies and local context.
\begin{table}[t]
	\centering
	\begin{tabular}{l|c|c|c|c}
		\hline
		Methods & DSC & RV & Myo & LV \\
		\hline
		\hline
R50 U-Net&87.55&87.10& 80.63& 94.92	\\
		R50 Att-UNet& 86.75&87.58& 79.20& 93.47	\\
		R50 ViT& 87.57&86.07&81.88&94.75	\\
		TranUnet&89.71&88.86& 84.53&95.73\\
		SwinUnet& 90.00&88.55& 85.62& 95.83	\\
		\hline
		TranUnet &87.82&86.12& 85.63&\textbf{91.71}\\
		SwinUnet & 87.21 &85.52&84.52 & 91.58	\\
		\hline
		MISSFormer& \textbf{87.90} & \textbf{86.36}  &\textbf{85.75}   &91.59\\
		\hline	
	\end{tabular}
	\caption{Comparison to state-of-the-art methods on ACDC dataset.  means that we keep the original settings and reimplement the method on our divided ACDC dataset }
	\label{table7}
\end{table}
\subsection{Comparison with state-of-the-art methods }
This section reports the comparision results of MISSFormer and previous state-of-the-art methods on Synapse dataset and ACDC dataset. 

\textbf{Experiment results on Synapse dataset.} Table 6 presents the comparision results of proposed MISSFormer and previous state-of-the-art methods. As shown, the proposed method achieved state-of-the-art performance in almost all measures, and it is worth mentioning that the encoder of Transunet and Swin-Unet is pretrained on ImageNet, while the MISSFormer trained on Synapse dataset from scratch, which indicates that MISSFormer capture the better long-range dependencies and local context to make strong feature representations. It can be seen from Fig.3 that our MISSFormer achieve better edge predictions and hard example segmentations compared to Tranunet and Swin-Unet, even in bad case. Compared MISSFormer and MISSFormer\_S, MISSFormer has precise result and less missegmentation because of the integration of multi-scale information. 

\textbf{Experiment results on ACDC dataset.} We evaluate our method on ACDC dataset, which is in the form of MRI. Table 7 presents the segmentation accuracy on our divided ACDC dataset, MISSFormer maintain the first position because of the powerful feature extraction, which indicates the outstanding generalization and robustness of MISSFormer. 

\section{Conclusion}
In this paper, we presented MISSFormer, a postion-free and hierarchical U-shaped medical image segmentation transformer, which explored the global dependencies and local context capture. The proposed Enhanced Mix Block can overcome the problem of feature inconsistency caused by the direct embedding of convolution in feed forward neural network effectively and make discriminative feature representations. Based on these core designs, we further investigated the integration of muti-scale features generated by our hierarchical transformer encoder, which is essential for accurate sementation. We evaluated our method on two different forms of datasets, the superior results demonstrated the effectiveness and robustness of MISSFormer.

\bibliography{000.bib}



\end{document}
