\documentclass{llncs}


\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{cite}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{url}

\newcommand\tstrut{\rule{0pt}{2.4ex}}
\newcommand\bstrut{\rule[-1.0ex]{0pt}{0pt}}

\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.95}
\renewcommand{\bottomfraction}{0.95}
\renewcommand{\floatpagefraction}{0.8}

\makeatletter
\spn@wtheorem{observation}{Observation}{\bfseries}{\itshape}
\makeatother

\title{Efficient Representation for \penalty-1 Online Suffix Tree Construction}
\author{N.\,Jesper Larsson \and Kasper Fuglsang \and Kenneth Karlsson}

\institute{IT University of Copenhagen, Denmark,\\
\email{\{jesl,kfug,kkar\}@itu.dk}}

\newcommand\pred{{\mathit{pred}}}
\newcommand\pos{{\mathit{pos}}}
\newcommand\ppos{{\mathit{ppos}}}
\newcommand\length{{\mathit{length}}}
\newcommand\down{{\mathit{down}}}
\newcommand\suf{{\mathit{suf}}}
\newcommand\rsuf{{\mathit{rsuf}}}
\newcommand\repr{{\mathit{repr}}}
\newcommand\nil{{\mathit{nil}}}
\newcommand\emptystring{{\epsilon}}
\newcommand\ST{{\mathcal{ST}}}
\newcommand\STi[1]{{\mathcal{ST}_{\kern-.222em #1}}}
\newcommand\LT{{\mathcal{LT}}}
\newcommand\TT{{\mathcal{T}}}
\newcommand\alphabet{{\mathrm{\Sigma}}}
\newcommand\reprupd{{\mathbf{repr\kern-.1em\textit{-}update}}}
\newcommand\mrmfind{{\mathbf{mrm\kern-.1em\textit{-}find}}}
\newcommand\ltdepth{{\mathit{depth}_\LT}}
\let\bibtla\textsc

\newcommand\notd{\textsc{notd}\xspace}
\newcommand\nobu{\textsc{nobu}\xspace}
\newcommand\eotd{\textsc{eotd}\xspace}
\newcommand\eov{\textsc{eov}\xspace}
\newcommand\lili{\textsc{ll}\xspace}
\newcommand\hata{\textsc{ht}\xspace}
\newcommand\cpu{\textsc{cpu}\xspace}

\DeclareMathSymbol{\topnode}{\mathord}{symbols}{"3F}
\DeclareMathSymbol{\topedge}{\mathord}{symbols}{"60}

\addtolength\topmargin{-.25cm}

\pagestyle{plain}

\begin{document}

\maketitle

\begin{abstract}
Suffix tree construction algorithms based on \emph{suffix links} are popular because
  they are simple to implement, can operate \emph{online} in linear time, and because the suffix links are
  often convenient for pattern matching. We present an approach using
  \emph{edge-oriented} suffix links, which reduces the number of branch
  lookup operations (known to be a bottleneck in construction time) with some
  additional techniques to reduce construction cost. We discuss various effects of our approach and
  compare it to previous techniques.  An experimental evaluation shows that we
  are able to reduce construction time to around half that of the original algorithm, and
  about two thirds that of previously known branch-reduced construction.
\end{abstract}


\section{Introduction}\label{sec-intro}


The \emph{suffix tree} is arguably the most important data structure in string
processing, with a wide variety of
applications~\cite{Apostolico85,gusfield,SufComp}, and with a number of
available construction
algorithms~\cite{Weiner73,McR,UkkoOnli,FarFOCS,giegkurtzstoyetopdown,canovas2010practical},
each with its benefits. Improvements in its efficiency of construction and
representation continues to be a lively area of research, despite the fact that
from a classical asymptotic time complexity perspective, optimal solutions have
been known for decades. Pushing the edge of efficiency is critical for indexing
large inputs, and make large amounts of experiments feasible, e.g., in
genetics, where lengths of available genomes increase. Much work has been
dedicated to reducing the memory footprint with representations that are
compact~\cite{kurtzsuftree} or compressed (see C{\'a}novas and
Navarro~\cite{canovas2010practical} for a practical view, with references to
theoretical work), and to alternatives requiring less space, such as suffix
arrays~\cite{Manber93}.  Other work adresses the growing performance-gap
between cache and main memory, frequently using algorithms originally designed
for secondary
storage~\cite{ClarkMunro,ferraginaHierarchxs,TsirogiannisModernSuffix,TianSuffixVLDB}.

While memory-reduction is important, it typically requires elaborate operations
to access individual fields, with time overhead that can be deterring for some
applications. Furthermore, compaction by a reduced number of pointers per node
is ineffective in applications that use those pointers for pattern matching. Our
work ties in with the more direct approach to improving performance of the
conventional primary storage suffix tree representation, taken by Senft and
Dvořák~\cite{SenftBranching}. Classical representations required in Ukkonen's
algorithm~\cite{UkkoOnli} and the closely related predecessor of
McCreight~\cite{McR} remain important in application areas such as genetics,
data compression and data mining, since they allow online construction as well
as provide \emph{suffix links}, a feature useful not only in construction,
but also for string matching tasks~\cite{gusfield,kielbasa2011adaptive}. In
these algorithms, a critically time-consuming operation is \emph{branch}:
identifying the correct outgoing edge of a given node for a given
character~\cite{SenftBranching}. This work introduces and evaluates several
representation techniques to help reduce both the number of branch operations
and the cost of each such operation, focusing on running time, and taking an
overall liberal view on space usage.

Our experimental evaluation of runtime, memory locality, and the counts for
critical operations, shows that a well chosen combination of our presented
techniques consistently produce a significant advantage over the original
Ukkonen scheme as well as the branch-reduction technique of Senft and Dvořák.


\section{Suffix Trees and Ukkonen's Algorithm}\label{sec-defs}

We denote the \emph{suffix tree} (illustrated in fig.~\ref{fig-st}) over a
string  of length  by \!. Each edge in
\!, directed downwards from the root, is labeled with a substring of
\!, represented in constant space by reference to position and length in
\!. We define a \emph{point} on an  edge as the position between two
characters of its label, or -- when the point coincides with a node -- after
the whole edge label. Each point in the tree corresponds to precisely one
nonempty substring , , obtained by reading edge
labels on the path from the root to that point. A consequence is that the first
character of an edge label uniquely identifies it among the outgoing edges of a
node. The point corresponding to an arbitrary pattern can be located (or found
non-existent) by scanning characters left to right, matching edge labels from
the root down.  For convenience, we add an auxiliary node  above the
root (following Ukkonen), with a single edge to the root. We denote this edge
 and label it with the empty string, which is denoted by
. (Although  is the topmost node of the augmented tree,
we consistently refer to the root of the unaugmented tree as the root of
\!.) Each leaf corresponds to some suffix~, . Hence, the label endpoint of a leaf edge can be defined implicitly,
rather than updated during construction. Note, however, that any suffix that is
not a unique substring of~ corresponds to a point higher up in the tree. (We
do not, as is otherwise common, require that  is a unique character,
since this clashes with online construction.)

Except for , all edges are labeled with nonempty strings,
and the tree represents exactly the substrings of  in the minimum number of
nodes. This implies that each node is either , the root, a leaf, or a
non-root node with at least two outgoing edges. Since the number of leaves is
at most  (one for each suffix), the total number of nodes cannot exceed
 (with equality for ).



We generalize the definition to  over string , where . An \emph{online} construction algorithm
constructs  in  updates, where update  reshapes
 into , without looking ahead any further than .


We describe suffix tree construction based on Ukkonen's algorithm~\cite{UkkoOnli}. Please refer to Ukkonen's original,
closer to an actual implementation, for details such as
correctness arguments.

 Define the
\emph{active point} before update  as the point corresponding to the
longest suffix of  that is not a unique substring of
. Thanks to the implicit label endpoint of leaf edges, this is the point
of the longest string where update  might alter the tree. The active
point is moved once or more in update , to reach the corresponding start
position for update . (This diverges
slightly from Ukkonen's use, where the active point is only defined as the
start point of the update.)  Since any leaf corresponds to a
suffix, the label end position of any point coinciding with a leaf in 
is . The tree is augmented with \emph{suffix links},
pointing upwards in the tree: Let  be a non-leaf node that coincides with
the string  for some character  and string . Then the suffix link of
 points to the node coinciding with the point of . The suffix link of the
root leads to , which has no suffix link. Before the first update,
the tree is initialized to  consisting only of  and the
root, joined by , and the active point is set to the endpoint of
 (i.e.\@ the root). Update  then procedes as
follows:

\begin{enumerate}
\item If the active point coincides with , move it down one step to
  the root, and finish the update.
\item Otherwise, attempt to move the active point one step down, by scanning
  over character . If the active point is at the end of an edge, this
  requires a \emph{branch} operation, where we choose among the outgoing
  edges of the node. Otherwise,
  simply try matching the character following the point with . If the move down
  succeeds, i.e.,  is present just below the active point, the update
  is finished. Otherwise, keep the current active point for now, and continue with
  the next step.
\item\label{step-ukksplit} Unless the active point is at the end of an edge,
  split the edge at the active point and introduce a new node. If there is a
  saved node  (from step~\ref{step-ukksavevp}), let 's suffix link
  point to the new node. The active point now coincides with a node, which we
  denote .
\item Create a new leaf  and make it a child of . Set the start pointer
  of the label on the edge from  to  to  (the end pointer of leaf
  labels being implicit).
\item If the active point corresponds to the root, move it to
  . Otherwise, we should move the active point to correspond
  to the string , where  is the string corresponding to  for some character
  . There are two cases:
  \begin{enumerate}
  \item Unless  was just created, it has a suffix link, which
    we can simply follow to directly arrive at a node that coincides with the
    point we seek.
  \item\label{step-ukkrescan} Otherwise, i.e. if 's suffix link is not yet set, let  be
    the parent of , and follow the suffix link of  to . Then locate
    the edge below  containing the point that corresponds to . Set this
    as the active point. Moving down from  requires one or more branch
    operations, a process referred to as \emph{rescanning} (see fig.~\ref{fig-linkstyles}). If
    the active point now coincides with a node , set the suffix link of 
    to point to . Otherwise, save  as  to have its suffix link set
    to the node created next.\label{step-ukksavevp}
  \end{enumerate}
\item Continue from step~1.
\end{enumerate}


\section{Reduced Branching Schemes}\label{sec-redbranch}

Senft and Dvořák~\cite{SenftBranching} observe that the \emph{branch} operation,
searching for the right outgoing edge of a node, typically dominates execution
time in Ukkonen's algorithm. Reducing the cost of branch can significantly improve
construction efficiency. Two paths are possible: attacking the cost of the
branch operation itself, through the data structures that support it, which
we consider in section~\ref{sec-hashvsll}, and reducing the \emph{number}
of branch operations in step~\ref{step-ukkrescan} of
the update algorithm.

We refer to Ukkonen's original method of maintaining and using suffix links as
\emph{node-oriented top-down} (\notd). Section~\ref{sec-nobu} discusses the
\emph{bottom-up} approach (\nobu) of Senft and Dvořák, and
sections~\ref{sec-eotd}--\ref{sec-eov} present our novel approach of
\emph{edge-oriented} suffix links, in two variants \emph{top-down} (\eotd) and
\emph{variable} (\eov).

\subsection{Node-Oriented Bottom-Up}\label{sec-nobu}

A branch operation comprises the rather expensive task of locating, given a
node  and character , 's outgoing
edge whose edge label begins with , if one exists. By contrast, following an
edge in the opposite direction can be made much cheaper, through a parent pointer. Senft and Dvořák~\cite{SenftBranching}
suggests the following simple modification to suffix tree representation and
construction:
\begin{itemize}
\item Maintain parents of nodes, and suffix links for
  leaves as well as non-leaves.
\item In step~\ref{step-ukkrescan} of
update, follow the suffix link of  to  rather than that of its
parent  to , and locate the point corresponding to  moving up,
\emph{climbing} from 
rather than rescanning from  (see fig.~\ref{fig-linkstyles}).
\end{itemize}

Senft and Dvořák experimentally demonstrate a runtime improvement across a
range of typical inputs. A drawback is that worst case time complexity is
not linear: a class of inputs with time complexity  is
easily constructed, and it is unknown whether actual worst case
complexity is even higher. To circumvent degenerate cases, Senft and Dvořák
suggest a hybrid scheme where climbing stops after  steps, for constant , falling back to rescan. (As an alternative, we
suggest bounding the number of edges to climb to by using rescan iff the remaining edge label length below the active point
exceeds constant .) Some of the space overhead can be avoided in a representation using clever
leaf numbering.

\subsection{Edge-Oriented Top-Down}\label{sec-eotd}

We consider an alternative branch-saving strategy, slightly modifying
suffix links.

For each split edge, the \notd update algorithm follows a suffix link from
 to , and immediately obtains the outgoing edge  of
 whose edge label starts with the same character as the edge just
visited. We can avoid this
\emph{first} branch operation in rescan (which constitutes a large part of
rescan work)
, by having  available from  directly, without taking the detour via
 and .

Define the string that \emph{marks} an edge as the shortest string represented
by the edge
(corresponding to the point after one character in its label). For edge ,
let , for character  and string , be the shortest string represented
 such that  marks some other edge . (The same as saying that 
marks , except when  is an outgoing edge of the root and , in
which case  marks .) Let the \emph{edge oriented suffix link} of 
point to  (illustrated i fig.~\ref{fig-st}).

\begin{figure}[t]
\begin{center}
\includegraphics[scale=.9]{st1-nodesuflinks.pdf}
\hfil
\includegraphics[scale=.9]{st1-suflinks.pdf}
\end{center}
\caption{\label{fig-st}Suffix tree over the string , with dotted lines
  showing node-oriented suffix links for internal nodes only, as in Ukkonen's
  original scheme (left), and
  edge-oriented suffix links (right).}
\end{figure}
 
\label{sec-siblinglookup}Modifying the update algorithm for this variant of suffix links, we obtain an
\emph{edge-oriented top-down} (\eotd) variant. The update algorithm is
analogous to the original, except that edge suffix links are set and followed
rather than node suffix links, and the first branch operation of each rescan
avoided as a result. The following points deserve special attention:
\begin{itemize}
\item When an edge is split, the top part should remain the destination of
  incoming suffix links, i.e., the new edge is the bottom part.
\item After splitting one or more edges in an update, finding the correct
  destination for the suffix link of the last new edge (the bottom part of the
  last edge split) requires a \emph{sibling lookup} branch operation, not
  necessary in \notd.
\item Following a suffix link from the endpoint of an edge occasionally
  requires one or more extra rescan operation, in relation to following the
  node-oriented suffix link of the endpoint.
\end{itemize}

The first point raises some implementation issues. Efficient representations
(see e.g.\@ Kurtz's~\cite{kurtzsuftree}) do not implement nodes and edges as
separate records in memory. Instead, they use a single record for a node and
its incoming edge. Not only does this reduce the memory overhead, it cuts down
the number of pointers followed on traversing a path roughly by half. The
effect of our splitting rule is that while the top part of the split edge
should retain incoming suffix links, the new record, tied to the bottom part
should inherit the children. We solve this by adding a level of indirection,
allowing all children to be moved in a single assignment. In some settings
(e.g., if parent pointers are needed), this induces a one
pointer per node overhead, but it also has two potential efficiency
benefits. First, new node/edge pairs become siblings, which makes for a natural
memory-locality among siblings (cf.\@ \emph{child inlining} in
section~\ref{sec-inlining}).\label{sec-notechildcache} Second, the original bottom node stays where it was
in the branching data structure, saving one replace operation. These properties
are important for the efficiency of the \eotd representation.

The latter two points go against the reduction of branch operations that
motivated edge-oriented suffix links, but does not cancel it out. (Cf.\@
table~\ref{tab-opcounts}.)

These assertions are supported by experimental data in
section~\ref{sec-experiments}.

Furthermore, \eotd retains the  total construction time of \notd. To see this, note
first that the modification to edge-oriented suffix links clearly adds at most
constant-time operation to each operation, except possibly with regards to the
extra rescan operations after following a suffix link from the endpoint of an
edge. But Ukkonen's proof of total  rescan time still applies: Consider
the string , whose end corresponds to the active point, and
whose beginning is the beginning of the currently scanned edge. Each downward
move in rescanning deletes a nonempty string from the left of this string, and
characters are only added to the right as  is incremented, once for each
online suffix tree update. Hence the number of downward moves are bounded by
, the total number of characters added.


\newcommand\stylescale{.635}

\begin{figure}[t]
\begin{center}
\begin{tabular}{@{\hspace{0pt}}c@{\hspace{0pt}}c@{\hspace{0pt}}c@{\hspace{0pt}}c@{\hspace{0pt}}}
\includegraphics[scale=\stylescale]{notd.pdf}&
\includegraphics[scale=\stylescale]{nobu.pdf}&
\includegraphics[scale=\stylescale]{eotd.pdf}&
\includegraphics[scale=\stylescale]{eov.pdf}\.5ex] \hline
		chr22&	34.55&	29\,569\,178&	18\,927\,812&
                318\,499&	33\,064\,133&	33\,669\,019&	35\,053\,371 \tstrut \\
		dna&		104.86&	87\,681\,116&	58\,585\,203&	236\,634&	100\,172\,270&	100\,736\,053&	111\,372\,537 \\
		dblp&		104.86&	54\,757\,925&	14\,743\,305&	32\,980&	55\,418\,573&	55\,594\,399&	73\,784\,654 \\
		rctail96&	114.71&	74\,993\,651&	20\,777\,946&	86\,190&	71\,863\,312&	72\,128\,546&	70\,211\,436 \\
		jdk13c&	69.73&	50\,659\,938&	6\,678\,647&	54\,174&	49\,300\,828&	49\,413\,385&	28\,044\,490 \\
		sources&	104.86&	80\,270\,528&	30\,753\,392&	191\,755&	75\,419\,031&	75\,953\,764&	70\,537\,447 \\
		w3c2&		104.20&	80\,056\,887&	12\,933\,438&	57\,108&	75\,773\,161&	75\,904\,742&	41\,111\,077 \\
		english&	104.86&	86\,528\,338&	43\,803\,204&	109\,151&	78\,451\,578&	78\,998\,269&	85\,577\,767 \\
		etext&	105.28&	73\,446\,539&	40\,782\,335&	106\,811&	73\,482\,182&	74\,097\,636&	99\,131\,563 \\
		howto&	39.42&	28\,590\,381&	13\,523\,660&	89\,650&	27\,703\,460&	27\,944\,722&	32\,676\,237 \\
		rfc&		116.42&	88\,716\,588&	32\,739\,584&	452\,280&	83\,618\,480&	84\,486\,767&	77\,334\,572 \\
		pitches&	55.83&	47\,744\,716&	21\,303\,582&	279\,505&	42\,615\,067&	43\,081\,419&	46\,777\,918 \\
		proteins&	104.86&	74\,912\,821&	39\,662\,469&	31\,075&	70\,942\,644&	71\,016\,405&	111\,979\,688 \\
		sprot34&	109.62&	70\,190\,029&	20\,737\,274&	45\,034&	69\,274\,605&	69\,425\,197&	78\,927\,702 \\
		adversary&	25.00&	41\,662\,928&	16\,323&	8\,313\,003&	41\,654\,774&	68033\,898\,010&	12\,249 \\	
      \end{tabular}
      \end{center}

      \caption{\label{tab-opcounts} Operation counts.  \emph{rs}: rescan branch
        operations, \emph{sl}: extra
        sibling lookup (see section~\ref{sec-siblinglookup}), \emph{move down}:
        branch operations outside of rescan. Files from the
        \emph{Pizza and Chili Corpus} () and \emph{Lightweight
          Corpus} (). File categories are \textsc{dna}~(),
        \textsc{xml}~(), source code~(), text~(),
        \textsc{midi}~(), proteins~(),
        database~(), and \nobu
        adversary~().}
\end{table}


Fig.~\ref{fig-maidiagram} shows performance across seven implementations and
five performance measures (explained in section~\ref{sec-expmodel}), which we
deem to be relevant for comparison. It summarizes the runtimes (also in
table~\ref{tab-runtimes}) and memory access measures by taking averages across
all files except \emph{adversary}, with equal weight per file. The bars are
scaled to show percentages of the measures for the basic \notd implementation,
which is used as the benchmark. The order of the implementations when ranked by
performance is fairly consistent across the different measures, with some
deviation in particular for the hardware cache measure and smaller-cache
models. The hardware cache measurement comes out as a relatively poor predictor
of performance; by the numbers reported by Perf, the hardware cache even appears
to be outperformed by our simplistic theoretical cache model.

We detect only a minor improvement of \eotd \lili implementations in relation to
\nobu \lili, while inline \eotd \hata provides a more significant
improvement. Note, however that for \nobu, the \hata implementation is much
worse than the \lili implementation, while the reverse is true for \eotd. This
can be attributed to the different hash table use and the particular
significance of inlining, noted in section~\ref{sec-inlining}. The fact that
\eotd \hata without inlining (not in the diagram) is not clearly better than
\nobu \hata stands to confirm this. Although table~\ref{tab-runtimes} shows that
\eotd \lili beats its \hata counterpart for files producing a low average
out-degree in  (because of a small alphabet and/or high repetitiveness), the
robustness of hashing (cf.\@ fig~\ref{fig-hashvsll}) has the greater impact on
average. We have included results to show the impact of the \emph{add to back}
heuristic in \eotd \lili, which also produced a slight improvement for \nobu (not
shown in diagram), as expected.



The operation counts shown in table~\ref{tab-opcounts} generally confirm our
expectations.  (Branch counts include moves down from  to the
root, in order to match Senft and Dvořák's corresponding
counts~\cite{SenftBranching}.) \eov yields a large rescan reduction, even for the adversary
file, which makes it an attractive alternative to \nobu when branching is very
expensive.  We found the exact choice of the  parameter of \eov not to be
overly delicate. All values shown were obtained with .




\section{Conclusion}\label{sec-concl}

It is possible to significantly improve online suffix tree construction time  
through modifications that target reducing branch operations and cache  
utilization, while maintaining linear worst-case time complexity. In many  
applications, our representation variants should be directly applicable for
runtime reduction. Interesting topics remaining to explore are how our
techniques for, e.g., suffix link orientation, fit into the compromise game of
time versus space in succinct representations such as compressed suffix trees,
and comparison to off-line construction.


\begin{table}[t]
\begin{center}
    \scriptsize
     \addtolength{\tabcolsep}{.3ex}
    \begin{tabular}{lrrrrrrrrrrr}
		&             \notd	&	\notd&	\nobu&	\nobu&	\nobu&
                \eov  &	\eov &	\eotd&	\eotd &	\eotd&	\eotd\\
	File&	     &	\hata&	             &    back & \hata  &	\lili &	        \hata &	\lili&	         \hata&	 back&	     inl. \hata \\ \hline
	chr22&	11.43&	16.73&	8.66& 9.00 &	13.72&	9.08&	14.26&	8.96&	14.40&	8.80&	8.91 \\
	dblp&	29.31&	35.56&	22.41& 21.90 &	30.60&	23.60&	32.15&	20.35&	26.55&	17.67&	16.91 \\
	dna&	40.37&	60.76&	30.65& 32.12 &	51.66&	32.70&	53.77&	31.60&	53.37&	30.97&	32.89 \\
	english&	64.26&	50.99&	45.65& 46.36 &	42.11&	47.47&	43.34&	42.70&	42.77&	36.64&	26.21 \\
	etext&	64.96&	50.15&	47.68& 46.44 &	42.43&	50.37&	44.30&	45.56&	43.38&	39.06&	27.67 \\
	howto&	21.74&	15.43&	16.12& 15.09 &	12.64&	16.48&	12.92&	15.33&	12.50&	12.56&	7.61 \\
	jdk13c&	7.97&	23.24&	6.39& 6.53 &	19.29&	6.97&	20.24&	5.72&	14.46&	5.27&	6.76 \\
	pitches&	46.65&	21.34&	34.66& 28.98 &	18.40&	35.38&	19.07&	34.08&	17.26&	26.34&	10.55 \\
	proteins&	104.49&	49.60&	74.30& 74.46 &	41.95&	76.49&	44.27&	75.73&	46.18&	70.55&	31.97 \\
	rctail96&	35.67&	44.76&	26.72& 26.54 &	37.44&	27.61&	38.35&	24.59&	31.32&	21.18&	18.35 \\
	rfc&	52.58&	50.81&	38.78& 37.22 &	42.96&	40.55&	44.14&	37.18&	39.99&	29.45&	21.82 \\
	sources&	44.21&	44.23&	32.71& 30.12 &	37.24&	34.27&	38.63&	31.49&	34.28&	24.70&	17.76 \\
	sprot34&	50.19&	42.65&	38.40& 37.92 &	37.37&	39.82&	38.50&	36.71&	33.66&	33.24&	21.24 \\
	w3c2&	18.98&	39.84&	14.38& 15.19 &	33.13&	14.89&	33.73&	12.91&	24.98&	11.41&	10.47 \\
	adversary&	1.30&	7.89&	267.50&	266.16&	296.42&	1.64&	8.07&	1.40&	5.10&	1.39&	1.34 \\
    \end{tabular}
    \end{center}
    \caption{\label{tab-runtimes}Running times in seconds for the same files as
    table~\ref{tab-opcounts}}
      \vspace{-2mm}
\end{table}

\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }

\bibitem{Apostolico85}
Apostolico, A.: The myriad virtues of subword trees. In: Apostolico, A., Galil,
  Z. (eds.) Combinatorial Algorithms on Words, {\bibtla{nato}} {\bibtla{asi}}
  Series, vol. F\,12, pp. 85--96. Springer-Verlag (1985)

\bibitem{arbitman2010backyard}
Arbitman, Y., Naor, M., Segev, G.: Backyard cuckoo hashing: Constant worst-case
  operations with a succinct representation. In: Proc. 51st Ann.
  {\bibtla{ieee}} Symp. Foundations of {Comput. Sci.} pp. 787--796 (2010)

\bibitem{canovas2010practical}
C{\'a}novas, R., Navarro, G.: Practical compressed suffix trees. In: Proc. 9th
  International Symposium on Experimental Algorithms. pp. 94--105 (2010)

\bibitem{ClarkMunro}
Clark, D.R., Munro, J.I.: Efficient suffix trees on secondary storage. In:
  Proc. seventh Ann. {\bibtla{acm}}--{\bibtla{siam}} Symp. Discrete Algorithms.
  pp. 383--391 (1996)

\bibitem{FarFOCS}
Farach, M.: Optimal suffix tree construction with large alphabets. In: Proc.
  38th Ann. {\bibtla{ieee}} Symp. Foundations of {Comput. Sci.} pp. 137--143
  (Oct 1997)

\bibitem{ferraginaHierarchxs}
Ferragina, P.: Suffix tree construction in hierarchical memory. In:
  Encyclopedia of Algorithms, pp. 922--925. Springer (2008)

\bibitem{PizzaChiliCorpus}
Ferragina, P., Navarro, G.: Pizza \& chili corpus (2005),
  \url{http://pizzachili.dcc.uchile.cl/}

\bibitem{FrigoCacheObliv}
Frigo, M., Leiserson, C., Prokop, H., Ramachandran, S.: Cache-oblivious
  algorithms. In: Proc. 40th Ann. {\bibtla{ieee}} Symp. Foundations of {Comput.
  Sci.} pp. 285--297 (1999)

\bibitem{giegkurtzstoyetopdown}
Giegerich, R., Kurtz, S., Stoye, J.: Efficient implementation of lazy suffix
  trees. Software -- Practice and Experience  33(11),  1035--1049 (2001)

\bibitem{gusfield}
Gusfield, D.: Algorithms on Strings, Trees, and Sequences. Cambridge University
  Press (1997)

\bibitem{hagerup2001deterministic}
Hagerup, T., Miltersen, P.B., Pagh, R.: Deterministic dictionaries. Journal of
  Algorithms  41(1),  69--85 (2001)

\bibitem{kielbasa2011adaptive}
Kie{\l}basa, S.M., Wan, R., Sato, K., Horton, P., Frith, M.C.: Adaptive seeds
  tame genomic sequence comparison. Genome research  21(3),  487--493 (2011)

\bibitem{kurtzsuftree}
Kurtz, S.: Reducing the space requirement of suffix trees. Software -- Practice
  and Experience  29(13),  1149--71 (1999)

\bibitem{SufComp}
Larsson, N.J.: Extended application of suffix trees to data compression. In:
  Proc. {\bibtla{ieee}} Data Compression Conf. pp. 190--199 (Mar--Apr 1996)

\bibitem{Manber93}
Manber, U., Myers, G.: Suffix arrays: A new method for on-line string searches.
  {\bibtla{siam}} J. Comput.  22(5),  935--948 (Oct 1993)

\bibitem{LightweightCorpus}
Manzini, G., Ferragina, P.: Lightweight corpus (2004),
  \url{http://people.unipmn.it/manzini/lightweight/corpus/}

\bibitem{McR}
McCreight, E.M.: A space-economical suffix tree construction algorithm. J.
  {\bibtla{acm}}  23(2),  262--272 (Apr 1976)

\bibitem{PerfSystem}
Perf: Linux profiling with performance counters,
  https://\nolinebreak[1]perf.wiki.kernel.org/

\bibitem{SenftBranching}
Senft, M., Dvořák, T.: On-line suffix tree construction with reduced
  branching. Journal of Discrete Algorithms  12(0),  48--60 (2012)

\bibitem{TianSuffixVLDB}
Tian, Y., Tata, S., Hankins, R.A., Patel, J.M.: Practical methods for
  constructing suffix trees. The \bibtla{vldb} Journal  14(3),  281--289 (2005)

\bibitem{TsirogiannisModernSuffix}
Tsirogiannis, D., Koudas, N.: Suffix tree construction algorithms on modern
  hardware. In: Proc. 13th International Conference on Extending Database
  Technology. pp. 263--274 (2010)

\bibitem{UkkoOnli}
Ukkonen, E.: On-line construction of suffix trees. Algorithmica  14(3),
  249--260 (Sep 1995)

\bibitem{Weiner73}
Weiner, P.: Linear pattern matching algorithms. In: Proc. 14th Ann.
  {\bibtla{ieee}} Symp. Switching and Automata Theory. pp. 1--11 (1973)

\end{thebibliography}


\end{document}
