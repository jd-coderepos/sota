\documentclass{eptcs}
\providecommand{\event}{LFMTP 2010}
\usepackage{breakurl}

\usepackage[latin1]{inputenc}
\usepackage{url}

\usepackage{amsmath,amssymb,amsthm}
\usepackage[english]{babel}
\usepackage{cdsty}


\title{Pattern Unification for the Lambda Calculus with Linear and
Affine Types\thanks {\footnotesize This work was
   in part supported by NABIIT grant 2106-07-0019 of the Danish Strategic Research
   Council.}}

\author{Anders Schack-Nielsen
   \qquad\qquad
   Carsten Sch\"urmann
\institute{ 
  IT University of Copenhagen\\
  Copenhagen, Denmark \\
  \texttt{anderssn|carsten@itu.dk}}
  }
\def\titlerunning{Pattern Unification for the Lambda Calculus with Linear and
Affine Types}
\def\authorrunning{A. Schack-Nielsen \& C. Sch\"urmann}

\newcommand{\aand}{\;\&\;}
\newcommand{\lhat}[1]{\widehat{\;#1\;}}
\newcommand\affarr{\mathrel{-}\joinrel\mathrel{@}}
\newcommand\afflam{\mathring{\lambda}}
\newcommand\affapp{{@}}
\newcommand\affext{\mathring{;}\,}
\newcommand\fI{\textup{}}
\newcommand\fA{\textup{}}
\newcommand\fL{\textup{}}
\newcommand\fUA{{\textup{\textbf{U}}_\textup{\textbf{A}}}}
\newcommand\fUL{{\textup{\textbf{U}}_\textup{\textbf{L}}}}
\newcommand{\affweak}{\succ_\mathrm{aff}}

\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\theoremstyle{definition}
\newtheorem{defin}[thm]{Definition}

\begin{document}
\maketitle
\begin{abstract}
  We define the pattern fragment for higher-order unification problems
  in linear and affine type theory and give a deterministic
  unification algorithm  that computes most general
  unifiers.
\end{abstract}


\section{Introduction}
Logic programming languages, type inference algorithms, and automated
theorem provers are all examples of systems that rely on unification.
If the unification problem has to deal with logic variables at higher
type (functional type), we speak of higher-order
unification~\cite{Huet75}.  Higher-order unification is in general
undecidable, but it can be turned decidable, if appropriately
restricted to a fragment.  For example, Miller's pattern fragment
characterizes a first-order fragment, for which unification is
decidable~\cite{Miller91jlc}. 

As substructural type theories are becoming more prevalent, for
example, in systems that need to represent consumable resources,
higher-order unification algorithms need to deal with logic variables
at linear or affine type.  Linear and affine type theories, for
example, refine intuitionistic type theory in the following way:
Besides intuitionistic assumptions, which can be referred to an
arbitrary number of times, linear and affine assumptions are treated
as resources that must be referred to \emph{exactly once} and \emph{at
  most once}, respectively.

As substructural type theories are mere refinements, one might erroneously suspect that the standard
intuitionistic pattern unification algorithm can be applied to this setting directly.
This, unfortunately, is not the case.  Consider the following two linear unification problems, where we write, as usual,~ for linear application and
juxtaposition for intuitionistic application.

These examples take place in a context in which  is an intuitionistic
variable.  However, the linear application on the left-hand side implies
that the variable must occur \emph{exactly} once in any valid
instantiation of , but in~\eqref{eq:split2} we cannot know whether
 should occur in  or .  This additional problem over normal
intuitionistic higher-order unification is caused exactly by the
interaction of linear and intuitionistic variables.
We solve this issue by imposing a separation of linear, affine, and
intuitionistic variables.



In this paper, we refine the intuitionistic pattern fragment into a
pattern fragment for linear and affine type theory.
We describe a unification algorithm for this fragment 
and prove and prove it correct. Furthermore, we show that in this fragment most general unifiers
exist. Finally, we extend the algorithm with a procedure we call
\emph{linearity pruning}.  This procedure goes beyond the pattern
fragment and treats equations such as~\eqref{eq:split2}
and~\eqref{eq:split1} where variables may have to change their status,
for example from being affine to linear.  Unification problems in this
extended fragment continue to be decidable.  For example,
for~\eqref{eq:split1} the algorithm finds the most general unifier, which is  and .
Our focus in this paper is finding unique most general unifiers, and
since~\eqref{eq:split2} has a set of most general unifiers of size two,
we are not going to try to solve it.  However, one could easily extend
linearity pruning to these cases by considering the finite number of context
splits.

Previous approaches to higher-order linear unification have been
restricted to highly non-deterministic algorithms, such as the
preunification by Cervesato and
Pfenning~\cite{Cervesato97linearhigher-order}.  In contrast, our
algorithm is completely deterministic, and very well suited for
implementation.  It is the core algorithm of the Celf proof
assistant~\cite{SchackNielsen08ijcar}.



\section{Language}
In~\cite{SchackNielsen10ijcar} we introduced a calculus of explicit substitutions
for the -calculus with linear, affine, and intuitionistic
variables and logic variables.  Along with the calculus we introduced a
type system and a reduction semantics, which was proven to be
type-preserving, confluent, and terminating.

We tag each variable  with a flag signifying whether
the variable is intuitionistic, affine, or linear.
We 
use  where  as a short-hand for  compositions of shift,
i.e.\ ,
where  means .  Additionally, de Bruijn indices
 with  are short-hand for .
The context linearity flags and the corresponding assumptions in
contexts are denoted \emph{intuitionistic} (),
\emph{affine} (), \emph{used affine} (),
\emph{linear} (), and \emph{used linear} ().

\begin{figure}[t]



\caption{Context splitting\label{fig:ctx-join}}
\end{figure} 

\begin{figure}[t]





\caption{Bidirectional typing of terms in canonical form\label{fig:typ-term}}
\end{figure} 

\begin{figure}[t]



\caption{Typing of substitutions\label{fig:typ-sub}}
\end{figure} 

In this paper we will work exclusively with the corresponding calculus of canonical
forms and hereditary substitutions.  This can be obtained simply by
viewing each term as a short-hand for its unique normal form and
assuming that everything is fully -expanded.  The resulting type
system is shown in Figures~\ref{fig:ctx-join}--\ref{fig:typ-sub}.
We write  as a shorthand for either 
or .

The intuitionistic part of a context  is formed by
rendering all linear and affine variables unavailable, which corresponds to updating
the context linearity flags from
 to  and  to .
Similarly, the largest context that can split to a given context is
denoted  and constructed by changing every
 to  and  to .
The predicate  specifies that no linear
assumptions occur in , i.e.\ no flag in  is equal to
.  The relaxed typing judgment  is
similar to  except that it makes all variables
available everywhere disregarding linearity and affineness.
The typing judgments could be augmented with an additional kind of
context for looking up logic variables, but we will keep this lookup
implicit and simply write  and  for the context and type
of a logic variable .

\begin{figure}

\caption{Equalities\label{fig:equalities}}
\end{figure} 

Restricting ourselves to canonical forms while retaining the syntax of
redices and closures as short-hands for their corresponding normal forms
induces equalities corresponding to the rewrite rules of the original
system.  The induced equalities are shown in Figure~\ref{fig:equalities}.
Additionally, the two typing rules for  and  from~\cite{SchackNielsen10ijcar},
which are left out, are now simply admissible rules proving type
preservation of hereditary substitution:





We use \emph{spine notation}~\cite{Cervesato03jlc} as a convenient short-hand for series of
applications and projections:

The term  is short-hand for the term where all the terms and
projections in  are applied to  as follows:

We write  for the argumentwise application of  in  and observe
that .

We write  for the \emph{instantiation of the logic variable}  with term  in
term .  This instantiation is type preserving, which follows 
by induction on  and the subject reduction property of hereditary substitutions.
\begin{thm}\label{thm:modalcut}
If  and  then
.
\end{thm}
Theorem~\ref{thm:modalcut} is also called the contextual modal cut
admissibility theorem for linear and affine contextual modal logic.


\section{Patterns}\label{sec:inversion}
The hallmark characteristic of the intuitionistic pattern fragment is
the invertibility of substitutions~\cite{Dowek98tr}.  Our pattern
fragment for the linear and affine calculus that we are going to
introduce next continues to guarantee this important property.  


Consider a substitution
.
Assume that  is a variable .  We say the
substitution extension
 is
\emph{linear} if
, it is \emph{affine} if 
, it is \emph{intuitionistic} if 
, and it is \emph{linear-changing} if 
, , or .
Notice that the possibilities , , and 
cannot occur in well-typed substitutions since this would imply
referencing a linear or affine assumption in an intuitionistic context or
a linear assumption in an affine context.


\begin{defin} \label{def:patsub}
A substitution 
is said to be a \emph{pattern substitution} if all the terms  for
 are distinct de Bruijn indices and none of them
are linear-changing extensions in the substitution.
A pattern substitution is called a \emph{weakening substitution} if the
indices  form an increasing sequence.
\end{defin}

Note that in a pattern substitution all de Bruijn indices are less than or equal to  since  is
equal to the length of .   To understand pattern
substitutions in the presence of logic variables during
lowering (discussed in Section~\ref{sec:unification}), we define the
\emph{extension of pattern substitution  by spine }, written as :





\begin{defin}
A term  is said to be a \emph{pattern} or within the
\emph{pattern fragment} if all
occurrences of logic variables  satisfy the property that
the substitution  is a pattern substitution.
\end{defin}

Recall example~\eqref{eq:split2} from the introduction.  In our system,
the equation is written as
.
We observe that it is not a pattern since there is a linear-changing substitution
extension on the left-hand side in .

It can be proven that the pattern fragment is stable under hereditary
substitution, logic variable instantiation, and inversion of
substitutions.  In particular, the following two theorems hold:

\begin{thm}
The pattern fragment is stable under logic variable instantiation.
I.e.\ for any patterns  and ,  is a pattern.
\end{thm}

\begin{thm}
If  is a pattern substitution and  is a
pattern then  is a pattern.
\end{thm}

The proofs are relatively straight-forward extensions of the proofs given
in~\cite{Dowek98tr} for the intuitionistic pattern fragment.

Next, we define the inverse of a pattern substitution. The name is
justified by Theorem~\ref{thm:inverse} below.
\begin{defin}
Let  be a pattern substitution.
We define its inverse to be
 where

when  and  is undefined otherwise.
The undefined extensions  are flagged  intuitionistic,
affine, or linear depending on the th assumption in the codomain
of .
\end{defin}
Intuitively, this definition is well defined: the s are
distinct and less than or equal to .  For the undefined  one can think
of an arbitrary term of the right type, e.g.\ a freshly created logic variable.




In the following we will refer to affine weakening on contexts , which is defined as

Notice that affine weakening is reflexive and transitive, as it merely
amounts to changing some number of s into s.

\begin{lem}
For a pattern substitution  there exists a
 with  such that
 and the inverse is well-typed with
.
\end{lem}
\begin{proof}
Let .
Then 
and .  Intuitively we are
going to take  to be the smallest possible such that  is
still well-typed, i.e.\ we are going to make all the affine assumptions
that are not used in  unavailable.  More formally we are going to set
 where 
when .  When  the  will
be defined below.

Consider each variable  in .
Note that we have .
If  where  is either  or  then we have
 and .
In the case where  then  and 
are either equal to  or , but since all the variables in 
are distinct it has to be .
If  then  and , and in this case we set
.
Finally, if  then  and  is either  or
.  If  then  is also equal to , and if
 then we can set  since  does not occur
anywhere else in .  This means that for all defined extensions
 in  we have .

The remaining s for which there are no  are
all shifted away by the  part of .  Therefore none of them
can be linear, and if any of them are affine, i.e.\ have ,
we set .
This means that all the undefined extensions in  correspond to
intuitionistic, used linear, or used affine assumptions in ,
and we see that 
 indeed is well-typed with .
\end{proof}
\begin{thm}\label{thm:inverse}
Given a pattern substitution , we have
 and
.
\end{thm}
\begin{proof}
Let .
Since  then the th extension in  is equal to
, and thus  for all .
\end{proof}

We have the usual definition of occurrence, rigid occurrence, and flexible
occurrence written as , , and 
respectively.  These relations are only defined for canonical forms in
which all logic variables are of base type (lowering will achieve this).
Occurrence is defined as
.  Rigid and flexible
occurrence are defined as follows, where we write  for either
rigid or flexible occurrence.


If  then the definition implies that there is
some logic variable \mbox{} in
 beneath  lambdas such that
.  In this case we say that
 occurs in the th argument of .

\begin{lem}\label{lem:linoccur}
Linearity implies occurrence.
\begin{enumerate}
\item
Let  be a pattern substitution and the th
assumption in  be linear.  Then  occurs in .
\item
Let  be a pattern and let the th
assumption in  be linear.  Then  occurs in .
\end{enumerate}
\end{lem}
\begin{proof}
If  then we must have
 for some  since a linear assumption cannot be shifted away.
The second case is by induction on .
\end{proof}

\begin{defin}
Given the typing of a substitution  we will
call it \emph{strong} if there exists no  such
that  and .
\end{defin}
For a pattern substitution

we see that it is strong if and only if
for each affine variable  we have  implies
.

Consider the split of a strong pattern substitution
 over a context split
 into  and
 with .
For any used affine assumption in  the assumption is either
affine or used affine in  and .  If it is used affine then the
corresponding assumption is also used affine in  and thereby
.  If it is affine then the corresponding assumption has to be
affine in  and is thereby used affine in .  This
means that  is strong and by symmetry so is
.

\begin{thm}\label{thm:occurrence}
Let  be a pattern substitution and
 be a term in which all logic variables
are of base type.
\begin{enumerate}
\item
If there exists a term  such that 
then every variable occurring in  also occurs in .
\item
If the typing  is strong and every variable
occurring in  also occurs in  then there exists a term
 such that .
\end{enumerate}
\end{thm}
\begin{proof}
1.\ follows by induction on  and 2.\ by induction on   using the
fact that context splits preserve a strong typing of .  It is easy to see
that a strong typing of  implies a strong typing of
 when going beneath a lambda-binder.

For the base case
 we get that  implies that the th assumption in
 corresponds to an assumption, say the th, in .
Now, we can take , and since  is strong, availability of the
th assumption in  implies availability of the th
assumption in  and thus that  is well-typed.
The base case  is similar, when noting that the shift at the end
of  is equal to the shift at the end of , since they
are both equal to the length of .
\end{proof}

Theorem~\ref{thm:occurrence} states that occurrence is a
conservative approximation of the set of
variables occurring in any instantiation of a term,
i.e.\ if  then .  The opposite is
not necessarily true.


\section{Pattern unification}
A unification problem  is a conjunction of unification
equations, and a solution to a unification problem is an instantiation
of the logic variables such that all equations are satisfied.  Such a
collection of logic variable instantiations will be written as 
and we say that  solves .  In this section we describe an
algorithm that returns ``no'' if no such solution exists or a
most general unifier otherwise, i.e.\ a solution that all other solutions are
refinements of.


More formally, we write  for a unification equation 
or simply  with the implicit understanding that both
terms have the same type in the same context.
Unification equations are symmetric and we will implicitly
switch from  to  when needed.  Unification
problems are given by the following grammar, where  is the
solved unification problem and  is the unification problem
with no solutions.

For convenience we generalize unification equations to spines
and write  as a
short-hand for the argumentwise conjunction of unification equations
(see below).


\subsection{Unification algorithm}\label{sec:unification}
The unification algorithm consists of a set of
transformation rules of the form .   We will see 
that the repeated application of these rule to any unification problem 
will eventually terminate resulting in  either , which indicates that the original problem has
no solution, or , which indicates that all equations have been
solved and that a most general unifier has been found.  In this case the
most general unifier is a mapping from logic variables to their
instantiations as computed during the execution of the
algorithm.  The unification algorithm is given in
Figure~\ref{fig:pat-unif} and each rule is explained in detail below.
For convenience we write the decomposition of a term  into one of
its subterms  and the surrounding term with a hole  as .



\begin{figure}

\caption{Pattern unification rules\label{fig:pat-unif}}
\end{figure} 


\medskip \noindent\textbf{Decomposition.}
Consider a unification equation  and
assume that  is not a base type.

If  then we
must have  and .
In this case  is equal to  under some 
if and only if  is equal to  under  and we therefore
apply \textbf{dec-lam-l}.  The other non-base type cases for  are
similar and give rise to \textbf{dec-lam-a}, \textbf{dec-lam-i}, and
\textbf{dec-pair}.

If  is a base type then  and 
where  and  are either variables or logic variables.  The case
of logic variables is handled below.  We therefore have
.  If  then no 
can make the two equal and we can therefore apply
\textbf{dec-atomic-neq}.  If  then the
spines must unify and we apply \textbf{dec-atomic-eq} where
 is defined as:

No other cases can occur because  trivially imply that
they have the same type.

\medskip \noindent\textbf{Lowering.}
When a logic variable occurs in a unification problem in the form
 with a non-empty spine, we know that  cannot be a
base type.  And since canonical forms of non-base type have unique head
constructors, we can safely instantiate  to that particular
constructor.  This is accomplished by the rules \textbf{lower-*}.
Therefore we can assume that all logic variables are of base type.

\medskip \noindent\textbf{Occurs check.}
Consider a unification equation of the form .  If 
also occurs in the right-hand side then either  or
.  The latter case is handled below in \textbf{Intersection}.
In the former case we have the equation .
Since a pattern substitution  applied to any term can never alter the
shape of the term but only rename variables this equation has no
solutions, and we can apply \textbf{occurs-check}.

\medskip \noindent\textbf{Pruning.}
When we have  then Theorem~\ref{thm:occurrence} tells us
that under some  solving the equation,
variables that do not occur in  cannot occur in .  Assume
that  and .  If  then no
instantiation of logic variables can get rid of the occurrence and
we apply \textbf{pruning-fail}.  If on the other hand
 then the occurrence is in the th argument
of some logic variable .  This means, however, that no instantiation
of  in a solution can contain~.
By Lemma~\ref{lem:linoccur} we know that
 cannot refer to a linear assumption in the context in which 
and  are typed and therefore the th assumption in 
cannot be linear.\footnote{Notice that this argument relies on the fact
that  is under a pattern substitution and thus has no linear-changing
variables.}
Let  be the weakening substitution 
where \textsf{weaken} is defined as:

Define  to be the context  with the th assumption removed.
We see that .
Furthermore, this is a strong typing.
Since the th assumption in  is not linear then
 does indeed exist.
Theorem~\ref{thm:occurrence} tells us that  has to be
instantiated to something on the form  and we can therefore apply
\textbf{pruning}.

\medskip \noindent\textbf{Context pruning.}
If a logic variable  is declared in context
 with ,
we know that  cannot occur in a well-typed instantiation of .
Therefore, by Theorem~\ref{thm:occurrence},  has to be
instantiated to something on the form 
and we can therefore apply \textbf{ctx-pruning}.

Note that pruning the context of  in this way in the case of
 may allow further pruning in .  Additionally, repeated
applications of this step will ensure that no used affine assumptions
occur in the context of logic variables.  Therefore all
typings of the associated substitutions are strong.


\medskip \noindent\textbf{Instantiation.}
Consider the unification equation  where all used affine assumptions have been
pruned from  and the typing of  therefore is strong.
If all  also occur in  then
Theorem~\ref{thm:occurrence} tells us that  is equal to
 for some .  By Theorem~\ref{thm:inverse} we know that
 is equal to  and we can therefore
instantiate  by the rule \textbf{instantiation} provided that 
does not occur in .

\medskip \noindent\textbf{Intersection.}
The final case is when we have .  If  then the
equation will be trivially satisfied no matter what term  might be
instantiated to, so we can simply remove the equation by the rule
\textbf{intersection-eq}.  

Consider an instantiation of  to some .  If for all
 we have  then the equation is
clearly satisfied.  If on the other hand there is some  such
that  then the two sides of the equation
will not be equal.  Therefore any variable  for which
 cannot occur in an instantiation of .
If such an  is linear then Lemma~\ref{lem:linoccur} tells us that
 has to occur in all instantiations and we can conclude that there is
no solution and apply \textbf{intersection-fail}.
Otherwise, any instantiation of  has to be on the form  for some
 where  is defined as the following weakening substitution:

Note that  exists exactly when 
for all linear .  The domain of
 is seen to be  with those assumptions removed for which
.
This step is summarized by the rule \textbf{intersection}.

\subsection{Correctness}
Correctness of the unification algorithm has three parts: preservation,
progress, and termination.
\begin{thm}\label{thm:unif-correct}
The unification algorithm solves all pattern unification problems
correctly.
\begin{enumerate}
\item
If  then the set of solutions to  is equal to the set of
solutions to .
\item
If  has unsolved equations (i.e.\  is not equal to  or
) then there exists a  such that .
\item
The unification algorithm terminates.
\end{enumerate}
\end{thm}
\begin{proof}
The discussion above in section~\ref{sec:unification}
proves preservation of solutions~(1) and progress~(2).
For termination~(3) we will consider the lexicographic ordering of
\begin{enumerate}
\item
The total size of all types of all logic variables occurring in the
unification problem.
\item
The total size of all contexts of the logic variables occurring in the
unification problem.
\item
The total size of all terms in the unification problem.
\end{enumerate}
We see that the decomposition rules \textbf{dec-*} decrease (3) while
keeping (1) and (2) constant.  The lowering rules \textbf{lower-*} and
\textbf{instantiation} decrease (1).  The \textbf{intersection-eq} rule decreases
(3) while keeping (1) and (2) constant.  The \textbf{pruning},
\textbf{ctx-pruning}, and
\textbf{intersection} rules decrease (2) while keeping (1) constant.
\end{proof}

\section{Linearity  pruning}
Within the pattern fragment we know that most general unifiers exist
and we have a decidable algorithm for finding them.  For practical
applications, however, it is often necessary to relax the pattern
restriction and accept that the algorithm sometimes returns left-over
unification problems.  Reed~\cite{Reed09lfmtp}, for example, describes
the dynamic intuitionistic pattern fragment that postpones any
unification equation as constraints that cannot be solved immediately.

In this section we will relax the restriction of pattern substitutions
from Definition~\ref{def:patsub} to \emph{linear-changing pattern substitutions}
permitting linear-changing extensions, greatly
expanding the applicability of our unification algorithm. If a
unification equation involving linear-changing pattern
substitutions cannot be resolved, it is simply postponed as a
constraint.  Instead of just returning  or ,
the unification algorithm using linearity pruning may fail with 
leftover constraints.



In order to handle linear-changing extensions in substitutions we
first need to revisit the notion of variable occurrence that was defined in
section~\ref{sec:inversion}.  So far, occurrences have been
divided into two categories; rigid and flexible.  We will need to make
further distinctions into a total of 12 categories.

We say that an occurrence is in an \emph{intuitionistic position}
in a term if the term can be written as  such
that the occurrence is within .  If an occurrence is not in an
intuitionistic position and the term can be written as
 such that the occurrence is within
 we say that it is in an \emph{affine position}.
If an occurrence is neither in an intuitionistic position nor in an
affine position we say that it is in a \emph{linear position}.
This means that intuitionistic positions are precisely those
in which top-level affine and linear assumptions are
not available. Similarly,  affine positions are those in which top-level affine
assumptions are available but the linear are not.  Finally,  linear
positions are those where all top-level assumptions are available.

If   occurs flexibly in a term , i.e.\ it occurs in the th
argument of some logic variable , there are five possibilities for
the th assumption in ; it can be intuitionistic, affine,
used affine, linear, or used linear.  We say that  occurs in an
\emph{intuitionistic argument} if the th assumption in  is
intuitionistic, we say that it occurs in an \emph{affine argument} if
the th assumption in  is affine, and we say that it occurs
in a \emph{linear argument} if the th assumption in  is
linear.  We will write this as ,
, and , respectively.
Occurrences where the th assumption in  is either
used affine or used linear are not relevant, since context pruning
will have removed them
(see rule \textbf{ctx-pruning} in Figure~\ref{fig:pat-unif}).

This gives a total of 12 categories of occurrence, since any occurrence
is either in an intuitionistic, affine, or linear position and it is
either a rigid occurrence or a flexible occurrence in an intuitionistic,
affine, or linear argument.


\begin{figure}

\caption{Modified pruning rules\label{fig:pat-unif-pruning}}
\end{figure} 

If we are at any time forced to prune a variable occurring in a
linear argument we can simply fail, since the reason for pruning implies
that the variable cannot occur in the given place but
the linear typing tells us that it will.
Consider the case  with  and .  Since
we have widened the fragment we are considering to include
linear-changing pattern substitutions it is now possible that
.  This was previously impossible since if
every substitution is a pattern then  implies
that  is linear which in turn implies .
The \textbf{pruning} and \textbf{pruning-fail}
rules therefore has to be modified slightly in this case as shown in
Figure~\ref{fig:pat-unif-pruning}.

\subsection{Linear-changing pattern substitutions}
\begin{defin}
A linear-changing pattern substitution  is called a
\emph{linear-changing identity} substitution if it is on the form:

or equivalently that it is -equivalent to \textsf{id} except for
some number of linear-changing extensions.
\end{defin}

\begin{thm}\label{thm:injective}
Linear-changing identity substitutions are injective.
Given , , and a linear-changing identity substitution ,
then  implies .
\end{thm}
\begin{proof}
The substitution  simply changes the linearity flags in  and  from
\fL{} to \fA{} or \fI{} or from \fA{} to \fI{} on
those variables that are linear-changing in
 and it is therefore trivially injective.
\end{proof}

\begin{thm}\label{thm:decompose}
A linear-changing pattern substitution can be decomposed into a pattern
substitution and a linear-changing identity substitution.
If  is a linear-changing pattern substitution then there exists a
pattern substitution  and a linear-changing identity substitution
 such that .
\end{thm}
\begin{proof}
Take  to be  with all linear-changing extensions  and
 changed to
linear extensions and all linear-changing extensions  changed to
affine extensions and  to be a linear-changing identity substitution
with the corresponding linear-changing extensions.
\end{proof}

\begin{thm}\label{thm:linprune}
Let  be a linear-changing identity substitution with exactly one
linear-changing extension  and  be some term.
\begin{enumerate}
\item
If the linear-changing extension is 
then there exists an  such that  if
and only if the following five properties hold:
\begin{enumerate}
\item
 occurs in .
\item
There are no occurrences of  in intuitionistic or affine positions in .
\item
For all subterms  of  under  lambdas
 occurs in  if and only if it occurs in .
\item
For all subterms  of  under  lambdas
 occurs in at most one of  and .
\item
All flexible occurrences of  in  are in linear arguments.
\end{enumerate}
\item
If the linear-changing extension is 
then there exists an  such that  if
and only if the following three properties hold:
\begin{enumerate}
\item
There are no occurrences of  in intuitionistic positions in .
\item
For all subterms  and 
of  under  lambdas
 occurs in at most one of  and .
\item
All flexible occurrences of  in  are in linear or affine arguments.
\end{enumerate}
\item
If the linear-changing extension is 
then there exists an  such that  if
and only if the following four properties hold:
\begin{enumerate}
\item
 occurs in .
\item
There are no occurrences of  in affine positions in .
\item
For all subterms  of  under  lambdas
 occurs in  if and only if it occurs in .
\item
All flexible occurrences of  in  are in linear arguments.
\end{enumerate}
\end{enumerate}
\end{thm}
\begin{proof}
By induction on  noting that each of the three sets of
properties are precisely the occurrence requirements for, respectively,
linear variables, affine variables, and linear variables known to adhere
to the affine occurrence requirements.
\end{proof}

Theorem~\ref{thm:linprune} tells us when there exists an  such that
 for a linear-changing identity substitution  with a
single linear-changing extension.  As a corollary we get the conditions
when  is a general linear-changing identity substitution.  The
existence of  is equivalent to the
conjunction of the requirements for each linear-changing extension,
since we can decompose any linear-changing identity substitution 
with  linear-changing extensions into
 where each  is a
linear-changing identity substitution with exactly one linear-changing
extension.

\subsection{Linearity pruning}
Consider the following unification equation where  is a
linear-changing pattern substitution:

We cannot invert  directly but we can decompose it by
Theorem~\ref{thm:decompose} into a pattern
substitution  and a linear-changing identity substitution 
changing the problem to:

In this case we perform a number of pruning steps on the right-hand side
since in any solution the  must adhere to the requirements in
Theorem~\ref{thm:linprune}.  We will consider each linear-changing
extension  in  individually.
The entire algorithm is given in Figure~\ref{fig:lin-prun1}
and each rule is explained below.

\begin{figure}

\caption{Linearity pruning\label{fig:lin-prun1}}
\end{figure} 




Since many of the rules rely on pruning, we extend our language of
unification problems with the constraint  to
simplify the presentation.  This
constraint states that  cannot occur in  in a solution.  If this is
already the case then the rule \textbf{prune-finish} removes it.  If  occurs either rigidly or
flexibly in a linear argument in  then no instantiation of logic
variables can remove the occurrence, and therefore there are no
solutions.  The rule \textbf{prune-fail} covers this case.  If there are
flexible occurrences in either intuitionistic or affine arguments then
we can safely prune them away with the rule \textbf{prune}.

\medskip \noindent\textbf{Position-based pruning.}
The variable  cannot occur in any intuitionistic position.  
Furthermore, if  then  also cannot occur in affine positions.
These occurrences can therefore be pruned away with the rules
\textbf{int-pos} and \textbf{aff-pos}.

\medskip \noindent\textbf{Pruning at multiplicative context splits.}
We will now consider all linear applications  and all affine
applications 
in the term  and compare occurrences in  and ,
as these positions are where the context is split
multiplicatively.

For any multiplicative context split the variable should only occur in one
of the branches by Theorem~\ref{thm:linprune}.  A multiplicative split
with rigid or linear argument
occurrences in one of the branches therefore allows us to prune any
occurrences in the other branch with the rule \textbf{multiplicative},
and if this is impossible due to rigid
or linear argument occurrences in both branches, we conclude that
there is no solution by following up with \textbf{prune-fail}.
We can restrict the \textbf{multiplicative} rule to the case where
, since  implies that  already occurs in at most
one of the branches at each multiplicative split.

\medskip \noindent\textbf{Pruning at additive context splits.}
Similarly, we consider all pairs  in the term
, i.e.\ the places where the context is split additively.
If  then the variable  must occur in either both
branches of the additive split or in none of them.  An additive split without occurrences in
one of the branches therefore allows us to prune any occurrences in the
other branch using the \textbf{additive} rule.

\medskip \noindent\textbf{Strengthening intuitionistic variables.}
Consider the case when , i.e.\  is intuitionistic, and
consider some flexible occurrence of  in an intuitionistic argument,
say the th, of some logic variable  in .  If  then we
do not necessarily know whether this particular occurrence should be
pruned away or strengthened to a linear occurrence, but in either case,
and also if , we can safely
strengthen the th assumption of  from intuitionistic to affine.
Let  and  be a fresh logic variable
with  and ,
where  and  are defined as
follows:
1.5ex]
\textsf{strengthen}(\Gamma,A^f;1;ff') &=& \Gamma,A^{f'} \\
\textsf{strengthen}(\Gamma,A^l;i+1;ff') &=& \textsf{strengthen}(\Gamma;i;ff'),A^l \\
\end{array}

Note that  when the th assumption in 
is  and  is either , , or .  When
referring to  we will sometimes leave out the context
and simply write  as  can be
inferred from the codomain of the substitution.

We can now instantiate  to  as shown in the
\textbf{int-strengthen} rule.
When we cannot apply this rule anymore, and we furthermore cannot apply
any of the pruning steps described above, then either  satisfies the
three conditions of part~2 of Theorem~\ref{thm:linprune} or else there
is some subterm  or  with flexible
occurrences in both  and .  In the latter case there is really
nothing else to do.\footnote{If we instead of a most general unifier
  were looking for the set of most general unifiers then we could
  easily enumerate the different possible solutions by introducing a
  disjunction and then either prune the variable from  or .}
In the former case, we can write the equation  as
 where
.  Since  is injective this equation
simplifies to , which corresponds to changing
every occurrence of  to .  This is
summarized by the rule \textbf{int-aff-invert}.


\medskip \noindent\textbf{Strengthening affine variables.}
Consider now the case when , i.e.\  is affine.  Since we
know that  occurs affinely but should occur linearly,
no more pruning will be necessary.  This means that any
flexible occurrence of  in an affine argument,
say the th, of some logic variable  in  can be strengthened to
a linear occurrence.  Thus, as is summarized in the
\textbf{aff-strengthen} rule we instantiate  to , where  is
a fresh logic variable with ,
, and
.
Since we know that  is supposed to be linear then it should also occur.
If it does not, we can fail with the rule \textbf{no-occur}.

If none of the rules \textbf{no-occur}, \textbf{aff-pos},
\textbf{additive}, or \textbf{aff-strengthen} apply then 
satisfies the four properties of part~3 of Theorem~\ref{thm:linprune}
and can be strengthened from affine to linear using
\textbf{aff-lin-invert}.

\bigskip

As an example we sketch how the algorithm solves
equation~\eqref{eq:split1} supposing that it has already been lowered.
.  The
last equation is a pattern, which can be solved directly.

\subsection{Correctness}
The discussion above relies heavily on
Theorem~\ref{thm:linprune} and proves that the algorithm preserves
solutions.   It is therefore easily possible to generalize part~1 of the Correctness
Theorem~\ref{thm:unif-correct} to the version of the unification
algorithm including linearity pruning.
Termination (part~3) also holds for the extended algorithm with a slight
elaboration of the termination ordering.  When calculating the size of
a term we will order the linearity flags  because with
this ordering,
the strengthening rules \textbf{int-strengthen},
\textbf{aff-strengthen}, \textbf{int-aff-invert}, and
\textbf{aff-lin-invert} decrease unification problems in size.
Furthermore, we require
that every introduction of the  constraint is followed by
a sequence of \textbf{prune} steps followed by a \textbf{prune-fail} or
\textbf{prune-finish} step.  When the introduction and elimination of
the  constraint are seen together as one step then the
combined result  always reduces the termination measure.
However, since the extended algorithm can get
stuck on certain equations with a ``don't know'', we have to
accept that progress, as stated in part~2 of the theorem, no
longer holds.  In these cases we can simply report a set of leftover
constraints, each of which require strengthening of some intuitionistic
variable that occurs flexibly in multiple parts of the right-hand side.



\section{Conclusion}
We have defined the pattern fragment for higher-order unification problems
in linear and affine type theory.  We have proved that all higher-order
unification equations within this fragment have no solutions or a most
general unifier, and given an algorithm to construct it.  Furthermore,
we have extended the unification algorithm beyond the pattern fragment
to those non-pattern equations that arise due to the additional
constraints from the linear and affine type system.


\bibliographystyle{eptcs}
\bibliography{lin-uni}

\end{document}
