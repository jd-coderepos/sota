\documentclass{article}
\usepackage{fullpage}
  \usepackage{verbatim}
  \usepackage{authblk}
  \usepackage{stfloats}
  \usepackage{graphicx}
  \usepackage{bold-extra}
  \usepackage{enumerate}
  \usepackage{amsfonts,amsmath,amsthm}
  \usepackage{tikz}
  \usetikzlibrary{shapes, calc}
  \usepackage{rotating}
\def\dd{\mathinner{.\,.}}
  \usepackage[algo2e, noend, noline, boxed]{algorithm2e}
  \renewcommand{\CommentSty}[1]{\textnormal{#1}\unskip}\SetKwComment{tcm}{\{}{\}}
   \newenvironment{myfunction}[2][htbp]
  {\setlength{\algomargin}{.2cm}
    \begin{center}
    \begin{minipage}{#2}
    \begin{function}[#1]
    \small
     \let\Par=\par
       \def\par{\endgraf\vspace{.1cm}}
           \SetKw{To}{to}\SetKw{Downto}{downto}\SetKw{Or}{or}\SetKwFor{Algo}{Function}{}{}\vspace{.15cm}}
   {\let\par=\Par\end{function}\end{minipage}\end{center}}
  \newenvironment{myalgorithm}[2][htbp]
  {\setlength{\algomargin}{.2cm}
    \begin{center}
    \begin{minipage}{#2}
    \begin{algorithm2e}[#1]
    \small
     \let\Par=\par
       \def\par{\endgraf\vspace{.1cm}}
           \SetKw{To}{to}\SetKw{Downto}{downto}\SetKw{Or}{or}\SetKwFor{Algo}{Algorithm}{}{}\vspace{.15cm}}
   {\let\par=\Par\end{algorithm2e}\end{minipage}\end{center}}

  \theoremstyle{theorem}
   \newtheorem{theorem}{Theorem}
   \newtheorem{observation}{Observation}
   \newtheorem{lemma}{Lemma}
  \newtheorem{fact}[theorem]{Fact}
  \newtheorem{claim}[theorem]{Claim}
  \theoremstyle{definition}
  \newtheorem{example}{Example}


  \newcommand{\ChangeList}{\mathit{ChangeList}}
  \newcommand{\Covered}{\mathit{Covered}}
  \newcommand{\CST}{\mathit{CST}}
  \newcommand{\sCST}{\mathit{sCST}}
  \newcommand{\children}{\mathit{children}}
  \renewcommand{\next}{\mathit{next}}
  \newcommand{\tree}{\mathit{tree}}
  \newcommand{\extend}{\Delta}
  \newcommand{\firstocc}{\mbox{\textit{first}}}
  \newcommand{\lastocc}{\mbox{\textit{last}}}
  \newcommand{\Occ}{\mathit{Occ}}
  \renewcommand{\c}{\mathit{cv}}
  \newcommand{\Oh}{\mathcal{O}}
  \newcommand{\PeakAncestor}{\mathit{PeakAncestor}}
  \newcommand{\Lift}{\mathit{Lift}}
  \newcommand{\LocalCorrect}{\mathit{LocalCorrect}}
  \newcommand{\Dist}{\mathit{Dist}}
  \newcommand{\List}{\mathit{List}}
  \newcommand{\MultiInsert}{\mathit{MultiInsert}}
  \newcommand{\MultiPred}{\mathit{MultiPred}}
  \newcommand{\MultiSucc}{\mathit{MultiSucc}}
  \newcommand{\PP}{\mathcal{P}}
  \newcommand{\union}{\mathit{Union}}
  \newcommand{\find}{\mathit{Find}}  
  \newcommand{\EE}{\mathcal{E}}
  \newcommand{\PC}{{\textsc{PartialCovers}}}
  \newcommand{\APC}{{\textsc{AllPartialCovers}}}
  
  \newcommand{\Leaves}{\mathit{Leaves}}  

  \title{
    Fast Algorithm for Partial Covers in Words\footnote{
      A preliminary version of this work appeared in the Proceedings of
      the Twenty-Fourth Annual Symposium on Combinatorial Pattern Matching, pp. 177--188, 2013.
    }
  }
  
  \date{}
  \author[1]{Tomasz Kociumaka\thanks{
    Supported by Polish budget funds for science in 2013-2017 as a research project under the `Diamond Grant' program.
    }}
\author[1]{Jakub Radoszewski\thanks{The author receives financial support of Foundation for Polish Science.}}
\author[1,2]{Wojciech Rytter\thanks{Supported by grant no.\ N206 566740 of the National Science Centre.}}
\author[3]{Solon P. Pissis\thanks{Supported by the NSF--funded iPlant Collaborative (NSF grant \#DBI-0735191).}}
\author[1]{Tomasz Wale\'n\thanks{Supported by Iuventus Plus grant (IP2011 058671) of the Polish Ministry of Science and Higher Education.}}

\affil[1]{Faculty of Mathematics, Informatics and Mechanics, University of Warsaw, Poland, \texttt{[kociumaka, jrad, rytter, walen]@mimuw.edu.pl}}
\affil[2]{Faculty of Mathematics and Computer Science, Copernicus University, Toru\'n, Poland}
\affil[3]{Department of Informatics, King's College London, UK, \texttt{solon.pissis@h-its.org}}


\begin{document}
\maketitle
  \begin{abstract}
    A factor  of a word  is a \emph{cover} of  if every position in  lies within some occurrence of  in .
    A word  covered by  thus generalizes the
    idea of a \emph{repetition}, that is, a word composed of exact concatenations of .
    In this article we introduce a new notion of
    -\emph{partial cover}, which can be viewed as a relaxed variant
    of cover, that is, a factor covering at least  positions in .
    We develop a data structure of  size (where ) that can be constructed in  time
    which we apply to compute all shortest -partial covers for a given .
    We also employ it for an -time algorithm computing a shortest -partial cover
    for each .
  \end{abstract}



    \section{Introduction}
    The notion of periodicity in words and its many variants have been well-studied in numerous
    fields like combinatorics on words, pattern matching, data compression, automata theory,
    formal language theory, and molecular biology (see \cite{DBLP:journals/tcs/CrochemoreIR09}).
    However the classic notion of
    periodicity is too restrictive to provide a description of a word such as
    , which is covered by copies of , yet not exactly periodic.
    To fill this gap, the idea of \emph{quasiperiodicity} was introduced~\cite{Apo93}.
    In a periodic word, the occurrences of the period do not overlap. In contrast,
    the occurrences of a quasiperiod in a quasiperiodic word may overlap.
    Quasiperiodicity thus enables the
    detection of repetitive structures that would be ignored by the classic characterization
    of periods.

    The most well-known formalization of quasiperiodicity is the cover of word.
    A factor  of a word  is said to be
    a \emph{cover} of  if , and every position in  lies within
    some occurrence of  in .
    Equivalently, we say that  \emph{covers} . Note that a cover of  must also be
    a \emph{border} --- both prefix and suffix --- of .
    Thus, in the above example,  is the shortest cover of .

    A linear-time algorithm for computing the shortest cover of a word was proposed
    by Apostolico et al.~\cite{DBLP:journals/ipl/ApostolicoFI91}, and a linear-time
    algorithm for computing all the covers of a word was proposed by
    Moore \& Smyth~\cite{DBLP:journals/ipl/MooreS94}. Breslauer~\cite{DBLP:journals/ipl/Breslauer92}
    gave an online linear-time algorithm computing the {\em minimal cover array} of a word --- a data 
    structure specifying the shortest cover of every prefix of the word.
    Li \& Smyth~\cite{DBLP:journals/algorithmica/LiS02} provided a linear-time algorithm
    for computing the {\em maximal cover array} of a word, and showed that, analogous to
    the border array~\cite{AlgorithmsOnStrings}, it actually determines the structure of {\em all} the covers of every prefix of the word.

    A known extension of the notion of cover is the notion of \emph{seed}.
    A seed is not necessarily aligned with the ends of the word being covered,
    but is allowed to overflow on either side.
    More formally, a word  is a seed of  if  is a factor of  and  is a factor of some
    word  covered by .
    Seeds were first introduced by Iliopoulos, Moore, and Park~\cite{DBLP:journals/algorithmica/IliopoulosMP96}.
    A linear algorithm for computing the shortest seed of a word was given
    by Kociumaka et al.~\cite{DBLP:conf/soda/KociumakaKRRW12}.

    Still it remains unlikely that an arbitrary word, even over the binary alphabet,
    has a cover (or even a seed).
    For example,  is a word that not only has no cover, 
    but whose every prefix also has no cover.    
    In this article we provide a natural form of quasiperiodicity.
    We introduce the notion of \emph{partial covers}, that is, factors covering at least a given number of positions in .
    Recently, Flouri et al.~\cite{Flouri2013102} suggested a related notion of \emph{enhanced covers}
    which are additionally required to be borders of the word.
    
    Partial covers can be viewed as a relaxed variant of covers
    alternative to approximate covers~\cite{SimParkKimLee}.
    The approximate covers require each position to lie within an
    approximate occurrence of the cover. This allows for small irregularities
    within each fragment of a word.
    On the other hand partial covers require exact occurrences but drop
    the condition that all positions need to be covered. This allows some
    fragments to be completely irregular as long as the total length of such
    fragments is small.
    The significant advantage of partial covers is that they enjoy more
    combinatorial properties, and consequently the algorithms solving the most
    natural problems are much more efficient than those concerning approximate
    covers, where the time complexity rarely drops below quadratic and
    some problems are even NP-hard. 
    
    Let  denote the number of positions in  covered by occurrences of the word  in ; 
    we call this value the \emph{cover index} of  within .
    For example, . We primarily
    focus on the following two problems, but the tools we develop can be
    used to answer a number of questions concerning partial covers,
    some of which are discussed in the Conclusions.
    \vskip 0.3cm \noindent {\PC\ \bf problem}

    \noindent \hspace*{0.2cm}
    {\bf Input:} a word  of length  and a positive integer .

    \noindent \hspace*{0.2cm}
    {\bf Output:} all shortest factors  such that .
    \vskip 0.3cm \noindent
    Each factor given in the output is represented by the first and the last starting position
    of its occurrence in .

    \begin{example}
      Let  and .
      Then the only shortest -partial covers are  and .
    \end{example}
  
  
\noindent {\APC\ \bf problem}

    \noindent \hspace*{0.2cm}
    {\bf Input:} a word  of length .

    \noindent \hspace*{0.2cm}
    {\bf Output:} for all , a shortest factor 
    such that .

    \vskip 0.3cm
    \noindent{\bf Our contribution.} The following summarizes our main result.
    \begin{theorem}\label{thm:main}
      The \PC\ and \APC\ problems can be solved
      in  time and  space.
    \end{theorem}

    We extensively use suffix trees, for an exposition see \cite{AlgorithmsOnStrings,Jewels}.
    A suffix tree of a word is a compact trie of its suffixes, the nodes of the trie which become
    nodes of the suffix tree are called {\em explicit} nodes, while the other
    nodes are called {\em implicit}. 
    Each edge of the suffix tree can be viewed as an {\em upward}
    maximal path of implicit nodes starting with an explicit node.
    Moreover, each node belongs to a unique path of that kind.
    Then, each node of the trie can be represented in the suffix tree
    by the edge it belongs to and an index within the corresponding path.
    Each factor of the word corresponds to an explicit or implicit
    node of the suffix tree.
    A representation of this node is called the \emph{locus} of the factor.
    Our algorithm finds the loci of the shortest partial covers, it is then straightforward
    to locate an occurrence for each of them.

    \paragraph{\bf A Sketch of the Algorithm}
    The algorithm first augments the suffix tree of , that is, a linear number of implicit
    extra nodes become explicit.
    Then, each node of the augmented tree is annotated with two integer values.
    They allow for determining the size of the covered area 
    for each implicit node by a simple formula, since limited to a single edge of the augmented suffix tree,
    these values form an arithmetic progression.
    This yields a solution to the \PC.
    For an efficient solution to the \APC\ problem, we additionally
    find the upper envelope of a number of line segments constructed from the arithmetic progressions.
    
    \paragraph{\bf Structure of the Paper}
    In Section~\ref{sec:CST} we formally introduce the augmented and annotated suffix tree
    that we call \emph{Cover Suffix Tree}.
    We show its basic properties and present its application for \PC\
    and \APC\ problems.
    Section~\ref{sec:CST_construction} is dedicated to the construction
    of the Cover Suffix Tree.
    Before that, Section~\ref{sec:fu} presents an auxiliary data structure being an extension
    of the classical Union/Find data structure; its implementation is given later, in Section~\ref{sec:details}.
    Additional applications of the Cover Suffix Tree are given in Sections~\ref{sec:by-products}
    and~\ref{sec:conclusions}.
    The former presents how the data structure can be used to compute all primitively rooted squares
    in a word and a linear-sized representation of all the seeds in a word.
    The latter contains a short discussion of variants of the \PC\ problem
    that can be solved in a similar way.


  \section{Augmented and Annotated Suffix Trees}\label{sec:CST}
  Let  be a word of length  over a totally ordered alphabet .
  The suffix tree  of  can be constructed in  time
  \cite{DBLP:conf/focs/Farach97,DBLP:journals/algorithmica/Ukkonen95}.
  For an explicit or implicit node  of , we denote by  the word obtained by spelling
  the characters on a path from the root to .
  We also denote .
  As in most applications of the suffix tree,
  the leaves of  play an auxiliary role and do not correspond to factors
  (actually they are suffixes of , where ).
  They are labeled with the starting positions of the suffixes of .

  We introduce the \emph{Cover Suffix Tree} of , denoted by ,
  as an \emph{augmented} --- new nodes are added --- suffix tree in which the
  nodes are \emph{annotated} with information relevant to covers.  is similar to the data structure named \emph{Minimal Augmented Suffix Tree}
  (see \cite{DBLP:journals/algorithmica/ApostolicoP96,DBLP:conf/icalp/BrodalLOP02}).

  For a set  of integers and , we define
  
  and we assume  if .
  By  we denote the set of starting positions of occurrences of  in .
  For any , we define:
  
  Note that  if  is the last occurrence of .
  Additionally, we define:
   see, for example,
  Fig.~\ref{fig:c_Delta}.

    \begin{figure}[htb]
      \centering
      \begin{tikzpicture}
\def\unitX{3mm}
\def\unitY{3mm}


\foreach \x/\c in {1/b,2/c,3/c,4/c,5/a,6/c,7/c,8/c,9/a,10/c,11/c,12/a,13/c,14/c,15/b} {
    \draw node [above] at (\x*\unitX, 0) {\tt \c}; 
    \draw node [below] at (\x*\unitX, 0) {\tiny \tt \x}; 
}

\foreach \x/\y/\label in {4/1/,8/1/,11/2/} {
    \draw (\x*\unitX-0.3*\unitX,\y*\unitY*0.8+0.4*\unitY) -- (\x*\unitX-0.3*\unitX,\y*\unitY*0.8+0.7*\unitY)--+(3.6*\unitX,0)--+(3.6*\unitX,-0.3*\unitY);
}
\end{tikzpicture}
       \caption{\label{fig:c_Delta}
        Let  and let  be the node corresponding to .
        We have , , .
      }
    \end{figure}

  A word  is called \emph{primitive} if  for a word  and an integer  implies that , and
  non-primitive otherwise.
  A square  is called \emph{primitively rooted} if  is primitive.

  \begin{observation}\label{obs:primitively_rooted_square}
    Let  be a node in the suffix trie of .
    Then  is a primitively rooted square in 
    if and only if there exists  such that .
  \end{observation}
  \begin{proof}
    Recall that, by the synchronization property of primitive words (see~\cite{AlgorithmsOnStrings}),
     is primitive if and only if it occurs exactly twice in .

    
    If  occurs in  at position  then .

     If  then obviously  occurs in  at position .
    Additionally, if  was not primitive then  would hold.
  \end{proof}

  In , we introduce additional explicit nodes called \emph{extra nodes}, 
  which correspond to halves of primitively rooted square factors of .
  Moreover we annotate all explicit nodes (including extra nodes) with the values
  ; see, for example, Fig.~\ref{fig:CST_example}.
  The number of extra nodes is bounded by the number of distinct squares, which is linear \cite{DBLP:journals/jct/FraenkelS98},
  so  takes  space.
 
  \begin{lemma}\label{lem:formula}
    Let  be the consecutive implicit nodes on the edge from an explicit node  of 
    to its explicit parent.
    Then for  we have
    
    in particular  forms an arithmetic progression.
  \end{lemma}
  \begin{proof}
    Note that , since otherwise  would be an explicit node of .
    Also note that if any two occurrences of  in  overlap, then the corresponding
    occurrences of  overlap.
    Otherwise, by Observation~\ref{obs:primitively_rooted_square},
    the path from  to  (excluding ) would contain an extra node.
    Hence, when we go up from  (before reaching its parent) the size of the covered area
    decreases at each step by .
  \end{proof}
   \begin{figure}[htb]
      \centering
      \clearpage{}  \begin{tikzpicture}[scale=.85]
\filldraw (0,-.5) circle (0.07cm);

      \draw (0,-.5) -- node[above=0.15cm,sloped] {\begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}} (-4.4,-5);
    \begin{scope}[yshift=-2cm,xshift=-1cm]
      \filldraw (-3.4,-3) node[above left=-0.05cm] {9, 3} circle (0.07cm);
      \filldraw (-5.4,-5.5) node[below=0.05cm] {7, 1} circle (0.07cm);
      \filldraw (-3.8,-5) node[below=0.05cm] {4, 1} circle (0.07cm);
      \filldraw (-2.6,-6.5) node[below=0.05cm] {11, 1} circle (0.07cm);
      \draw (-3.4,-3) -- node[above=0.15cm,sloped] {\begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}} (-5.4,-5.5);
      \draw (-3.4,-3) -- node[above=0.15cm,sloped,near end] {\begin{rotate}{270}\end{rotate}} (-3.8,-5);
      \draw (-3.4,-3) -- node[above,sloped] {\begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}} (-2.6,-6.5);
    \end{scope}

\draw (0,-.5) -- node[above=0.15cm,sloped,near end] {\begin{rotate}{270}\end{rotate}} (-0.2,-1.5);
    \draw (-0.2,-1.5) -- node[above=0.15cm,sloped] {\begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}} (-2.5,-7.5);
    \filldraw (-0.2,-1.5) node[right] {2, 2} circle (0.07cm);
    \filldraw (-2.5,-7.5) node[below=0.05cm] {15, 1} circle (0.07cm);

\draw (0,-.5) -- node[above,sloped] {\begin{rotate}{90}\end{rotate}} (1.5,-1.5);
    \begin{scope}[xshift=1.5cm,yshift=-1.5cm]
      \filldraw (0,0) node[above right=-0.05cm] {10, 10} circle (0.07cm);
      \filldraw (-1,-3) node[left] {11, 2} circle (0.07cm);
      \filldraw (-3,-5.5) node[below=0.05cm] {8, 1} circle (0.07cm);
      \filldraw (-1.4,-5) node[below=0.05cm] {5, 1} circle (0.07cm);
      \filldraw (-0.2,-6.5) node[below left=-0.05cm] {12, 1} circle (0.07cm);
      \draw (0,0) -- node[above=0.15cm,sloped] {\begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}} (-0.6,-1.8);
\filldraw (-0.67,-1.87) rectangle (-0.53,-1.73);
      \draw (-0.6,-1.8) node[left=0.05cm] {9, 3};
      \draw (-0.6,-1.8) -- node[above=0.15cm,sloped] {\begin{rotate}{270}\end{rotate}} (-1,-3);
      \draw (-1,-3) -- node[above=0.15cm,sloped] {\begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}} (-3,-5.5);
      \draw (-1,-3) -- node[above=0.15cm,sloped,near end] {\begin{rotate}{270}\end{rotate}} (-1.4,-5);
      \draw (-1,-3) -- node[above,sloped] {\begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}} (-0.2,-6.5);
    \end{scope}
    \draw (1.5,-1.5) -- node[above,sloped,near end] {\begin{rotate}{90}\end{rotate}} (2,-3.5);
    \draw (1.5,-1.5) -- node[above,sloped] {\begin{rotate}{90}\end{rotate}} (3.5,-3);
    \filldraw (2,-3.5) node[below=0.05cm] {2, 1} circle (0.07cm);

      \begin{scope}[xshift=3.5cm,yshift=-3cm]
        \filldraw (0,0) node[above right=-0.05cm] {10, 4} circle (0.07cm);
\filldraw (-0.1,-0.9) rectangle (0.04,-0.76);
        \draw (-0.03,-0.83) node[left=0.05cm] {9, 3};
\filldraw (-0.13,-1.73) rectangle (0.01,-1.59);
        \draw (-0.06,-1.66) node[left=0.05cm] {11, 2};
        \filldraw (-0.09,-2.5) node[left] {12, 1} circle (0.07cm);
        \filldraw (-1.7,-5) node[below right=-0.05cm] {9, 1} circle (0.07cm);
        \filldraw (-0.2,-4.5) node[below=0.05cm] {6, 1} circle (0.07cm);
        \filldraw (1.1,-5.5) node[below=0.05cm] {13, 1} circle (0.07cm);
        \draw (0,0) -- node[above=0.15cm,sloped] {\begin{rotate}{270}\end{rotate}} (-0.03,-0.83);
        \draw (-0.03,-0.83) -- node[above=0.15cm,sloped] {\begin{rotate}{270}\end{rotate}} (-0.06,-1.66);
        \draw (-0.06,-1.66) -- node[above=0.15cm,sloped] {\begin{rotate}{270}\end{rotate}} (-0.09,-2.5);
        \draw (-0.09,-2.5) -- node[above=0.15cm,sloped] {\begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}} (-1.7,-5);
        \draw (-0.09,-2.5) -- node[above=0.15cm,sloped,near end] {\begin{rotate}{270}\end{rotate}} (-0.2,-4.5);
        \draw (-0.09,-2.5) -- node[above,sloped] {\begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}} (1.1,-5.5);
      \end{scope}
      
      \draw (3.5,-3) -- node[above,sloped,near end] {\begin{rotate}{90}\end{rotate}} (4.3,-5);
      \filldraw (4.3,-5) node[below=0.05cm] {3, 1} circle (0.07cm);
      \draw (3.5,-3) -- node[above,sloped] {\begin{rotate}{90}\end{rotate} \ \ \begin{rotate}{90}\end{rotate}} (4.75,-4);
\filldraw (4.68,-4.07) rectangle (4.82,-3.93);
      \draw (4.75,-4) node[above right=-0.05cm] {8, 2};
      \draw (4.75,-4) -- node[above,sloped] {\begin{rotate}{90}\end{rotate} \ \ \begin{rotate}{90}\end{rotate}} (6,-5);
      \filldraw (6,-5) node[above right=-0.05cm] {10, 1} circle (0.07cm);
      \draw (6,-5) -- node[above=0.15cm,sloped] {\begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}\ \ \ \begin{rotate}{270}\end{rotate}} (5.4,-8);
      \draw (6,-5) -- node[above,sloped] {\begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}\ \ \ \begin{rotate}{90}\end{rotate}} (6.6,-8);
      \filldraw (5.4,-8) node[below=0.05cm] {10, 1} circle (0.07cm);
      \filldraw (6.6,-8) node[below=0.05cm] {14, 1} circle (0.07cm);

  \end{tikzpicture}
\clearpage{}
      \caption{
         for .
        It contains four extra nodes that are denoted by squares in the figure.
        Each node is annotated with . Leaves are omitted for clarity.
      }\label{fig:CST_example}
    \end{figure}
  \begin{example}
    Consider the word  from Fig.~\ref{fig:CST_example}.
    The word  corresponds to an explicit node of ; we denote it by .
    We have  and  since the two occurrences of the factor  
    in  overlap.
    The word  corresponds to an implicit node  and .
    Now the word  corresponds to an extra node  of .
    Its occurrences are adjacent in  and , .
    The word  corresponds to an implicit node  and .
  \end{example}


  \noindent
  As a consequence of Lemma~\ref{lem:formula} we obtain the following result.
  Recall that the locus of a factor  of , given by its start and end position
  in , can be found in  time \cite{DBLP:conf/cpm/KucherovNS12}.
  \begin{lemma}\label{lem:if_CST}
    Assume we are given .
    Then we can compute:
    \begin{enumerate}[(1)]
      \item\label{one} for any , the loci of the shortest -partial covers in linear time;
      \item\label{two} given the locus of a factor  in the suffix tree
      , the cover index  in  time.
    \end{enumerate}
  \end{lemma}
  \begin{proof}
    Part (\ref{two}) is a direct consequence of Lemma~\ref{lem:formula}.
    As for part (\ref{one}), for each edge of , leading from  to its parent ,
    we need to find minimum  for which
    .
    Such a linear inequality can be solved in constant time.
  \end{proof}
  Due to this fact the efficiency of the \PC\ problem
  relies on the complexity of  construction.
  In turn, the following lemma, also a consequence of Lemma~\ref{lem:formula},
  can be used to solve \APC\ problem
  provided that  is given.
  As a tool a solution to the geometric problem of upper envelope
  \cite{DBLP:journals/ipl/Hershberger89} is applied.
  \begin{lemma}\label{lem:all_if_CST}
    Assume we are given .
    Then we can compute the locus of a shortest -partial cover
    for each  in  time and  space.
  \end{lemma}
  \begin{proof}
    Consider an edge of  from  to its parent  containing  implicit nodes.
    For each such edge, we form a line segment on the plane connecting points
     and 
    (if there are no implicit nodes on the edge, the line segment is a single point).
    Denote all such line segments obtained from  as , we have .
    We consider the upper envelope  of the set of these segments.
    Formally, if each  connecting points  and , ,
    is interpreted as a linear function on a domain ,
     is defined as a function  such that:
    
    Here we are actually interested in an \emph{integer envelope} , that is, 
    limited to integer arguments, see Fig.~\ref{fig:envelope}.
    By Lemma~\ref{lem:formula}, for any ,
     equals the maximum of  over all factors  of 
    such that .
    A piecewise linear representation of  can be computed in  time and  space
    \cite{DBLP:journals/ipl/Hershberger89}, therefore the function  for all its arguments
    can be computed in the same time complexity.

    \begin{figure}[htb]
      \centering
        \begin{tikzpicture}[scale=.35]
    \draw[->,-latex] (0,0) -- (16,0);
    \draw[->,-latex] (0,0) -- (0,16);
    \foreach \i in {1,...,15}
      \draw (\i,-0.2) -- node[below] {\scriptsize \i} (\i,0.2);
    \foreach \i in {1,...,15}
      \draw (-0.2,\i) -- node[left] {\scriptsize \i} (0.2,\i);
    \foreach \pos in {(1,10), (2,10), (3,9), (4,11), (5,12), (6,10), (7,7), (8,8), (9,9), (10,10), (11,11), (12,12), (13,13), (14,14), (15,15)}
      \draw \pos circle (0.15cm);
    \draw[thick,densely dashed]
      (1,10) -- (2,10) -- (2,9) -- (3,9) -- (3,11) -- (4,11) -- (4,12) -- (5,12)
      -- (5,10) -- (6,10) -- (6,7) -- (7,7) -- (7,8) -- (8,8) -- (8,9) -- (9,9)
      -- (9,10) -- (10,10) -- (10,11) -- (11,11) -- (11,12) -- (12,12) -- (12,13)
      -- (13,13) -- (13,14) -- (14,14) -- (14,15) -- (15,15);

    \draw (16,0.5) node[right] {word};
    \draw (16,-0.5) node[right] {length};
    \draw (-4.5,16.8) node[right] {covered};
    \draw (-4.5,15.8) node[right] {positions};

\draw (3,9) -- (1,3);
\filldraw (3,9) circle (0.07cm);
\filldraw (1,3) circle (0.07cm);
\draw (7,7) -- (4,4);
\filldraw (7,7) circle (0.07cm);
\filldraw (4,4) circle (0.07cm);
\draw (4,4) -- (4,4);
\filldraw (4,4) circle (0.07cm);
\draw (11,11) -- (4,4);
\filldraw (11,11) circle (0.07cm);
\filldraw (4,4) circle (0.07cm);
\draw (1,2) -- (1,2);
\filldraw (1,2) circle (0.07cm);
\draw (15,15) -- (2,2);
\filldraw (15,15) circle (0.07cm);
\filldraw (2,2) circle (0.07cm);
\draw (1,10) -- (1,10);
\filldraw (1,10) circle (0.07cm);
\draw (3,9) -- (2,6);
\filldraw (3,9) circle (0.07cm);
\filldraw (2,6) circle (0.07cm);
\draw (4,11) -- (4,11);
\filldraw (4,11) circle (0.07cm);
\draw (8,8) -- (5,5);
\filldraw (8,8) circle (0.07cm);
\filldraw (5,5) circle (0.07cm);
\draw (5,5) -- (5,5);
\filldraw (5,5) circle (0.07cm);
\draw (12,12) -- (5,5);
\filldraw (12,12) circle (0.07cm);
\filldraw (5,5) circle (0.07cm);
\draw (2,2) -- (2,2);
\filldraw (2,2) circle (0.07cm);
\draw (2,10) -- (2,10);
\filldraw (2,10) circle (0.07cm);
\draw (3,9) -- (3,9);
\filldraw (3,9) circle (0.07cm);
\draw (4,11) -- (4,11);
\filldraw (4,11) circle (0.07cm);
\draw (5,12) -- (5,12);
\filldraw (5,12) circle (0.07cm);
\draw (9,9) -- (6,6);
\filldraw (9,9) circle (0.07cm);
\filldraw (6,6) circle (0.07cm);
\draw (6,6) -- (6,6);
\filldraw (6,6) circle (0.07cm);
\draw (13,13) -- (6,6);
\filldraw (13,13) circle (0.07cm);
\filldraw (6,6) circle (0.07cm);
\draw (3,3) -- (3,3);
\filldraw (3,3) circle (0.07cm);
\draw (4,8) -- (3,6);
\filldraw (4,8) circle (0.07cm);
\filldraw (3,6) circle (0.07cm);
\draw (6,10) -- (5,9);
\filldraw (6,10) circle (0.07cm);
\filldraw (5,9) circle (0.07cm);
\draw (10,10) -- (7,7);
\filldraw (10,10) circle (0.07cm);
\filldraw (7,7) circle (0.07cm);
\draw (14,14) -- (7,7);
\filldraw (14,14) circle (0.07cm);
\filldraw (7,7) circle (0.07cm);
  \end{tikzpicture}
       \caption{\label{fig:envelope}
        Line segments constructed as in Lemma~\ref{lem:all_if_CST} for the  from Fig.~\ref{fig:CST_example}.
        The marked points joined with a dashed polyline show the values of the integer upper envelope function .
        We infer from the graph that the lengths of the shortest -partial covers of 
        are as follows:
        1 for , 4 for , 5 for , and  for .
      }
    \end{figure}

    Let us introduce a prefix maxima sequence for : ,
    with .
    Note that  is non-decreasing.
    If  then the shortest -partial cover for all 
    has length .
    An example of such a partial cover can be recovered
    if we explicitly store the initial line segments used in the pieces of the representation of .
    Thus the solution of the \APC\ problem can be obtained
    from the sequence  in  time.
  \end{proof}
  In the following two sections we provide an  time construction
  of .
  Together with Lemmas~\ref{lem:if_CST} and~\ref{lem:all_if_CST}, it
  yields Theorem~\ref{thm:main}.


  \section{Extension of Disjoint-Set Data Structure}\label{sec:fu}
  In this section we extend the classic disjoint-set data structure to compute
  the \emph{change lists} of the sets being merged, as defined below.
 \begin{figure}[ht]
      \centering
      \clearpage{}    \begin{tikzpicture}[scale=.7]
      \def\unitX{1cm}
      \def\unitY{1cm}

      \begin{scope}[xshift=3cm,yshift=2cm]
        \draw[thick,densely dotted,->,-latex] (1.07,0.07) sin (1.5,0.3) cos (1.93,0.07);
        \draw[xshift=1cm,thick,densely dotted,->,-latex] (1.07,0.07) sin (1.5,0.3) cos (1.93,0.07);
        \draw[xshift=3cm,thick,densely dotted,->,-latex] (1.07,0.07) sin (1.5,0.3) cos (1.93,0.07);
        \draw[xshift=6cm,thick,densely dotted,->,-latex] (1.07,0.07) sin (1.5,0.3) cos (1.93,0.07);

        \filldraw (1,0) node[below=0.05cm] {1} circle (0.1cm);
        \draw (2,0) node[below=0.05cm] {2} circle (0.1cm);
        \filldraw (3,0) node[below=0.05cm] {3} circle (0.1cm);
        \filldraw (4,0) node[below=0.05cm] {4} circle (0.1cm);
        \draw (5,0) node[below=0.05cm] {5} circle (0.1cm);
        \draw (6,0) node[below=0.05cm] {6} circle (0.1cm);
        \draw (7,0) node[below=0.05cm] {7} circle (0.1cm);
        \filldraw[white!70!black] (8,0) circle (0.1cm);
        \draw (8,0) node[below=0.05cm] {8} circle (0.1cm);
        \filldraw[white!70!black] (9,0) circle (0.1cm);
        \draw (9,0) node[below=0.05cm] {9} circle (0.1cm);
      \end{scope}

      \begin{scope}[yshift=4.5cm]
        \draw (0,0) node[above] {};
        \draw (-2.5,-2) node[above left] {};
        \draw (0,-1.5) node[above left] {};
        \draw (2.25,-1.3) node[above] {};

        \draw (0,0) -- (0,-1.5) -- (-1,-2.25) -- (-1.5,-3.25);
        \draw (0,-1.5) -- (1,-2.25) -- (1.5,-3.25);
        \draw (-1,-2.25) -- (-0.5,-3.25);
        \draw (1,-2.25) -- (0.5,-3.25);
        \filldraw[white] (-1.5,-3.25) circle (0.1cm);
        \draw (-1.5,-3.25) node[below=0.05cm] {7} circle (0.1cm);
        \filldraw[white] (-0.5,-3.25) circle (0.1cm);
        \draw (-0.5,-3.25) node[below=0.05cm] {5} circle (0.1cm);
        \filldraw[white] (0.5,-3.25) circle (0.1cm);
        \draw (0.5,-3.25) node[below=0.05cm] {2} circle (0.1cm);
        \filldraw[white] (1.5,-3.25) circle (0.1cm);
        \draw (1.5,-3.25) node[below=0.05cm] {6} circle (0.1cm);

        \draw (0,0) -- (-2.5,-2) -- (-3,-3);
        \draw (-2.5,-2) -- (-2,-3);
        \filldraw[white!70!black] (-3,-3) circle (0.1cm);
        \draw (-3,-3) node[below=0.05cm] {9} circle (0.1cm);
        \filldraw[white!70!black] (-2,-3) circle (0.1cm);
        \draw (-2,-3) node[below=0.05cm] {8} circle (0.1cm);

        \draw (0,0) -- (2.25,-1.3) -- (2.75,-2.25) -- (2.25,-3.25);
        \draw (2.25,-1.3) -- (1.75,-2.25);
        \draw (2.75,-2.25) -- (3.25,-3.25);
        \filldraw (1.75,-2.25) node[below=0.05cm] {4} circle (0.1cm);
        \filldraw (2.25,-3.25) node[below=0.05cm] {3} circle (0.1cm);
        \filldraw (3.25,-3.25) node[below=0.05cm] {1} circle (0.1cm);
      \end{scope}

    \end{tikzpicture}
\clearpage{}
      \caption{
        Let  be the partition of  whose classes
        consist of leaves in the subtrees rooted at children of ,
        ,
        and let .
        Then 
        (depicted by dotted arrows).
      }\label{fig:ChangeList}
    \end{figure}
  First, let us extend the  notation.
  For a partition  of , we
  define
  
  Now for two partitions  let us define the \emph{change list} (see also Fig.~\ref{fig:ChangeList}) by
  

 \newcommand{\id}{id}
 We say that  is a partition of  \emph{labeled} by  if  is a partition of  and 
  is a one-to-one (injective) mapping.
 A label  is called \emph{active} if  for some  and \emph{free} otherwise.
 \begin{lemma}\label{lem:main_data_structure}
    Let  be positive integers such that  is of magnitude .
    There exists a data structure of size , which maintains a partition   of 
    labeled by  and supports the following operations:
    \begin{itemize}
      \item  for  gives the label of  containing~.
      \item  for a set  of active labels and a free label
       replaces all  with labels in  by their set-theoretic union with the label .
      The change list of the corresponding modification of  is returned.
    \end{itemize}
    Initially  is a partition into singletons with .
    Any valid sequence of  operations is performed in  time.
    A single  operation takes  time.
  \end{lemma}
 
  Note that these are actually standard disjoint-set data structure operations except for the fact that
  we require  to return the change list.
  The technical proof of Lemma~\ref{lem:main_data_structure} is postponed until Section~\ref{sec:details}.


  \section{-time Construction of }\label{sec:CST_construction}
  The suffix tree of  augmented with extra nodes is called the
  \emph{skeleton} of , which we denote by .
  It could be constructed using the fact that all square factors of a word can be
  computed in linear time~\cite{DBLP:journals/jcss/GusfieldS04,Crochemore2013,DBLP:conf/spire/CrochemoreIKRRW10}.
  However, we do not need such a complicated machinery here.
  We will compute  on the fly, simultaneously annotating the nodes with , .

  We introduce auxiliary notions related to covered area of nodes:
  

  \begin{observation}
    
  \end{observation}

  \noindent
  In the course of the algorithm some nodes will have their values  already computed;
  we call them \emph{processed nodes}.
  Whenever  will be processed, so will its descendants.
    
  The algorithm processes inner nodes  of  in the order of non-increasing height .
  The height is not defined for leaves, so we start with .
  Extra nodes are created on the fly using Observation~\ref{obs:primitively_rooted_square}
  (this takes place in the auxiliary  routine).

  We maintain the partition  of  given by sets of leaves of subtrees
  rooted at \emph{peak nodes}.
  Initially the peak nodes are the leaves of .
  Each time we process  all its children are peak nodes.
  Consequently, after processing  they are no longer peak nodes and  becomes a new peak node.
  The sets in the partition are labeled with identifiers of the
  corresponding peak nodes.
  Recall that leaves are labeled with the starting positions of the corresponding suffixes. 
  We allow any labeling of the remaining nodes as long as each node of
   has a distinct label of magnitude .
  For this set of labels we store the data structure of Lemma~\ref{lem:main_data_structure}
  to compute the change list of the changing partition.

    \begin{figure}[htpb]
      \centering
      \clearpage{}    \begin{tikzpicture}[scale=.8]
      \def\unitX{1cm}
      \def\unitY{1cm}
      
      \newcommand{\subtree}[4]{
        \draw (#1*\unitX,#2*\unitY)--+(0.5*\unitX,-1*\unitY)--+(-0.5*\unitX,-1*\unitY)--cycle;
        \filldraw[black,fill=white] (#1*\unitX,#2*\unitY) circle (\unitX/20);
        \draw node (#4) at (#1*\unitX,#2*\unitY) {};
        \draw node [#3] at (#1*\unitX,#2*\unitY) {};
      }
      
      \subtree{0}{0}{above left}{v_1}
      \subtree{2}{0}{above left}{v_2}
      \subtree{4}{0.2}{above left}{v_3}
      \subtree{6}{0.1}{above right}{v_4}
      \subtree{8}{0.5}{above right}{v_5}

      \draw let \p1=(v_3),\p2=(v_4) in
        () node (v) {};
      \draw node at (v) [above] {};
      \draw [dashed, shorten >= -0.1cm] (v)--(v_3);
      \draw [dashed, shorten >= -0.1cm] (v)--(v_4);
      \draw (v) circle (\unitX/20);

      \draw let \p1=(v_1),\p2=(v_5) in
        () node (root) {};
      \draw node at (root) [above] {};
      \draw [dashed, shorten >= -0.1cm] (root)--(v_1);
      \draw [dashed, shorten >= -0.07cm] (root)--(v_5);

      \draw [dashed,<->] let \p1=(root),\p2=(v),\p3=(1*\unitX,0) in
        (\x3,\y1)--(\x3,\y2) node[midway, left] {};;


      \filldraw [black] let \p1=(v_3) in 
        (\x1-\unitX*0.3,\y1-\unitY) circle (\unitX/20) node [below] {};

    \end{tikzpicture}
\clearpage{}
      \caption{
        One stage of the algorithm, where the peak nodes are  while the
        currently processed node is .
        If  and , then .
        The current partition is  .
        After  is processed, the partition changes to
        .
        The  operation merges 
        and returns the corresponding change list.
      }\label{fig:tree}
    \end{figure}

  \noindent
  We maintain the following technical invariant (see Fig.~\ref{fig:tree}).

  \medskip
  \noindent
	{\bf Invariant:}
  \begin{enumerate}[\bf (A)]
    \item
    For each peak node  we store:
    
    \item
    For each  we store .
    \item
    For each  we store .
  \end{enumerate}

  \noindent
  We use two auxiliary routines.
  The  operation updates  and  values when  decrements.
  It also creates all extra nodes of depth .
  The  operation is used for updating  and  values for children
  of the node .
  The  and  arrays are stored to enable efficient implementation
  of these two routines. 


   
   \newcommand{\algname}{\textsc{ComputeCST}}
  \begin{myalgorithm}[H]{11.8 cm}
    \Algo{\algname(w)}
    {
      \,suffix tree of \;
       := partition of  into singletons\;
\lForEach{ a leaf of }{, }\;
      \For{ \KwSty{downto} }{
        \;
        \{Now part (A) of Invariant() is satisfied\}\\
        \ForEach{ an inner node of , }{
          \;
          \;
           := \\
            \lForEach{}{}\;
            ; \;
        }
      }
      \Return{ together with values of  \;}
    }
  \end{myalgorithm}

      
    \paragraph{\bf Description of the  Operation}
    The procedure  plays an important preparatory role in processing the current node.
    According to part (A) of our invariant, for all peak nodes  we know the values:
    
    Now we have to change  to  and guarantee validity of the invariant:
    
    This is exactly how the following operation updates  and .

    It also creates all extra nodes of depth  that were not explicit nodes of
    the suffix tree.
    By Observation~\ref{obs:primitively_rooted_square}, if 
    then at position  in  there is an occurrence of a primitively rooted square
    of half length .
    Consequently, an extra node corresponding to this occurrence is created
    in the  operation.

    \begin{myfunction}[H]{9 cm}
      \Algo{}{
        \ForEach{ \KwSty{in} }{
          \;
          ; \;
          \If{}{
            Create a node of depth  on the edge from  to 
          }
        }
      }
    \end{myfunction}

    \paragraph{\bf Description of the  Operation}
    Here we assume that  occurs at positions  and that these are consecutive occurrences.
    Moreover, we assume that these occurrences are followed by distinct characters, i.e. . 
   	The  procedure updates  to make part (B) of the invariant hold for  again.
   	The data structure  is updated accordingly so that (C) remains satisfied.
    \begin{myfunction}[H]{9.5 cm}
      \Algo{}{
        ;\ \;
        \lIf{}{
          
          } \lElse{
          }\;
        \lIf{}{
           }
        \lElse{
          }\;
        \;
         ;\ \;
      }
    \end{myfunction}

    \paragraph{\bf Complexity of the Algorithm}
    In the course of the algorithm we compute  for each .
    Due to Lemma~\ref{lem:main_data_structure} we have:
    
    Consequently we perform  operations .
    In each of them at most one element is added to a list  for some .
    Hence the total number of insertions to these lists is also .

    The cost of each operation  is proportional to the total size of
    the list  processed in this operation.
    For each  the list  is processed once and
    the total number of insertions into lists is ,
    therefore the total cost of all operations  is also .
    This proves the following fact which, together with Lemmas~\ref{lem:if_CST} and~\ref{lem:all_if_CST},
    implies our main result (Theorem~\ref{thm:main}).
    

    \begin{lemma}
      Algorithm \algname~constructs  in  time and  space, where .
    \end{lemma}


  \section{Implementation Details}\label{sec:details}
  In this section we give a proof of Lemma~\ref{lem:main_data_structure}.  
  We use an approach similar to Brodal and Pedersen \cite{DBLP:conf/cpm/BrodalP00}
  (who use the results of \cite{DBLP:journals/jacm/BrownT79})
  originally devised for computation of maximal quasiperiodicities.

  Theorem 3 of \cite{DBLP:conf/cpm/BrodalP00} states that
  a subset  of a linearly ordered universe can be stored in a height-balanced
  tree of linear size supporting the following operations:
  \begin{description}
    \item[\quad :] insert all elements of  to ,
    \item[\quad :] return all  for  and ,
    \item[\quad :] return all  for  and ,
  \end{description}
  in  time.

  \smallskip

  In the data structure we store each  as a height-balanced tree.
  Additionally, we store several auxiliary arrays, whose semantics follows.
  For each  we maintain a value 
  and a pointer  to the tree representing  such that .
  For each  (technically for each tree representing ) we
  store  and for each  we store , a pointer to the
  corresponding tree (null for free labels).

  Answering  is trivial as it suffices to follow the 
  pointer and return the  value.
  The  operation is performed according
  to the pseudocode given below (for brevity we write  instead of
  ).

  \begin{claim}
    The  operation correctly computes the change list and updates the
    data structure.
  \end{claim}
  \begin{proof}
    In the  operation for sets , , we find the largest set 
    and  all the elements of the remaining sets to .
    If  is in the change list, then  and  come from
    different sets , in particular at least one of them does not come from
    . Depending on which one it is, the pair  is found by
     or  operation.
    While computing , the table  is not updated yet
    (i.e. corresponds to the state before  operation) while  is already
    updated. Consequently the pairs inserted to  indeed belong to the change
    list. 
    Once  is proved to be the change list, it is clear that  is
    updated correctly.  For the other components of the data structure,
    correctness of updates is evident.
    
  \end{proof}

  \begin{myfunction}[H]{10.8 cm}
  \Algo{}{
      \;
      \;
     \ForEach{}{
      \lForEach{}{}\;
      \;
     }
     \;
     \ForEach{}{\ForEach{}{
      \lIf{}{}\;
     }
     \ForEach{}{
      \lIf{}{}\;
      }
      \;
     }
     \;
     ; \;
     \lForEach{}{}
     \Return{}\;
  }
  \end{myfunction}
  
  \begin{claim}
    Any sequence of  operations takes  time in total.
  \end{claim}
  \begin{proof}
    Let us introduce a potential function .
    We shall prove that the running time of a single  operation
    is proportional to the increase in potential.
    Clearly 
    
    so this suffices to obtain the desired  bound.
    
    Let us consider a  operation that merges partition classes of sizes
     to a single class of size .
    The most time-consuming steps of the algorithm are the operations on
    height-balanced trees, which, for single , run in  time. 
    These operations are not performed
    for the largest set and for the remaining ones we have 
    (i.e. ). This lets us bound the time complexity
    of the  operation as follows:
    
    which is equal to the increase in potential.
  \end{proof}




  \section{By-Products of Cover Suffix Tree}\label{sec:by-products}
  In this section we present two additional applications of the Cover Suffix Tree.
  We show that, given  (or  of a word that can be obtained from 
  in a simple manner), one can compute in linear time all distinct primitively rooted squares
  in  and a linear representation of all the seeds of , in particular, the shortest
  seeds of .
  This shows that constructing this data structure is \emph{at least as hard}
  as computing all primitively rooted squares and seeds. While there are linear-time algorithms
  for these problems \cite{DBLP:journals/jcss/GusfieldS04,DBLP:conf/focs/KolpakovK99,Crochemore2013} and \cite{DBLP:conf/soda/KociumakaKRRW12}, they
  are all complex and rely on the combinatorial properties specific to the repetitive structures they seek for.
  

  \begin{theorem}
    Assume that the Cover Suffix Tree of a word of length  can be computed in  time.
    Then all distinct primitively rooted squares in a word  of length  can be computed in
     time.
  \end{theorem}
  \begin{proof}
    Let  be a special symbol.
    Let  be a morphism such that
     for any .
    We consider the word , that is, the word  with -characters
    inserted at all its inter-positions, e.g.\ if  then .
    
    Let us consider the set of explicit non-branching nodes of 
    and select among them the nodes corresponding to even-length factors of 
    starting with the symbol .
    It suffices to note that there is a one-to-one correspondence between these
    nodes and the halves of primitively rooted squares in .
  \end{proof}


  \begin{figure}[htpb]
  \begin{center}
  \begin{tikzpicture}[scale=0.9]
{\small
 \draw (0,0) node[above] {\texttt{a}};
  \draw (0.5,0) node[above] {\texttt{b}};
  \draw (1,0) node[above] {\texttt{a}};
  \draw (1.5,0) node[above] {\texttt{a}};
  \draw (2,0) node[above] {\texttt{b}};
  \draw (2.5,0) node[above] {\texttt{a}};
  \draw (3,0) node[above] {\texttt{a}};
  \draw (3.5,0) node[above] {\texttt{b}};
  \draw (4,0) node[above] {\texttt{a}};
  \draw (4.5,0) node[above] {\texttt{a}};
  \draw (5,0) node[above] {\texttt{a}};
  \draw (5.5,0) node[above] {\texttt{b}};
  \draw (6,0) node[above] {\texttt{a}};
  \draw (6.5,0) node[above] {\texttt{a}};
  \draw (-1,0) node[above] {\texttt{a}};
  \draw (-0.5,0) node[above] {\texttt{a}};
  \draw (7,0) node[above] {\texttt{b}};
  \draw (7.5,0) node[above] {\texttt{a}};
  \draw[xshift=-2cm] (-0.25,0.4) .. controls (0.5,1.2) and (1,1.2) .. (1.75,0.4);
  \filldraw[white] (-2.25,0) rectangle (-1.25,1.5);
  \draw[xshift=1.5cm] (-0.25,0.4) .. controls (0.5,1.2) and (1,1.2) .. (1.75,0.4);
  \draw[yshift=0.1cm] (-0.25,0) .. controls (0.5,-0.8) and (1,-0.8) .. (1.75,0);
  \draw[xshift=5cm] (-0.25,0.4) .. controls (0.5,1.2) and (1,1.2) .. (1.75,0.4);
  \draw[xshift=3cm,yshift=0.1cm] (-0.25,0) .. controls (0.5,-0.8) and (1,-0.8) .. (1.75,0);
  \draw[xshift=6.5cm,yshift=0.1cm] (-0.25,0) .. controls (0.5,-0.8) and (1,-0.8) .. (1.75,0);
  \filldraw[white,yshift=0.1cm] (7.75,0) rectangle (8.25,-1.5);
}
\end{tikzpicture}

   \caption{Seed of string \texttt{aaabaabaabaaabaaba}.}
  \label{fig:seed}
  \end{center}
  \end{figure}

  Recall that a word  is a seed of  if  is a factor of  and  is a factor of some
  word  covered by , see Fig.~\ref{fig:seed}.
  The following lemma states that the set of all seeds of  has a representation of  size, where .
  This representation enables, e.g., simple computation of all shortest seeds of the word.
  By a range on a edge of a suffix tree we mean a number of consecutive nodes on this edge
  (obviously at most one of these nodes is explicit).
  Let  denote the reverse of the word .
  
  \begin{lemma}[\cite{DBLP:journals/algorithmica/IliopoulosMP96,DBLP:conf/soda/KociumakaKRRW12}]\label{lem:seeds_representation}
    The set of all seeds of  can be split into two disjoint classes.
    The seeds from one class form a single (possibly empty) range on each edge of the suffix tree of ,
    while the seeds from the other class form a range on each edge of the suffix tree of .
  \end{lemma}



  We will show that given  and  we can compute the representation
  of all seeds from Lemma~\ref{lem:seeds_representation} in  time.
  Let us recall auxiliary notions of quasiseed and quasigap, see \cite{DBLP:conf/soda/KociumakaKRRW12}.

  By  and  let us denote  and , respectively.
  We say that  is a \emph{complete cover} in  if  is a cover of
  the word .
  The word  is called a \textit{quasiseed} of  if  is a complete cover in ,
   and .
  Alternatively,  can be decomposed into , where  and  is a cover of .

  All quasiseeds of  lying on the same edge of the suffix tree with lower explicit endpoint 
  form a range with the lower explicit end of the range located at .
  The length of the upper end of the range is denoted as .
  If the range is empty, we set .
  Thus a representation of all quasiseeds of a given word can be provided using only 
  the quasigaps of explicit nodes in the suffix tree.
  It is known that computation of quasiseeds is the hardest part of an algorithm computing seeds:

  \begin{lemma}[\cite{DBLP:journals/algorithmica/IliopoulosMP96,DBLP:conf/soda/KociumakaKRRW12}]\label{lem:quasigaps}
    Assume quasigaps of all explicit nodes of suffix trees of  and  are known.
    Then a representation of all seeds of  from Lemma~\ref{lem:seeds_representation}
    can be found in  time.
  \end{lemma}

  It turns out that the auxiliary data in  and  enable constant-time computation
  of quasigaps of explicit nodes.
  By Lemma~\ref{lem:quasigaps} this yields an  time algorithm for computing a representation
  of all the seeds of .
  This is stated formally in the following theorem.

  \begin{theorem}\label{thm:seeds}
    Assume that the Cover Suffix Tree of a word of length  can be computed in  time.
    Given a word  of length , one can compute a representation of all seeds of 
    from Lemma~\ref{lem:seeds_representation} in  time.
    In particular, all the shortest seeds of  can be computed within the same time complexity.
  \end{theorem}
  \begin{proof}
    We show how to compute quasigaps for all explicit nodes of .
    The computation for  is symmetric.
    Note that  may contain more explicit nodes that the suffix tree of the word.
    In this case, the results from any maximal sequence of edges connected by non-branching explicit nodes
    in  need to be merged into a single range on the corresponding edge of the suffix tree.

    By the definition of , an explicit node  of  is a complete cover in 
    if the following condition holds:
    
    Thus for checking whether an explicit node  of  is a quasiseed of 
    it suffices to check whether this condition and the following equalities hold:
    
    If  is not a quasiseed of , we have , otherwise
    we can assume that .

    \begin{example}
      Consider the word  from Fig.~\ref{fig:CST_example}, .
      The word  corresponds to an explicit node of ; we denote it by .
      We have , , , and .
      Therefore  is a quasiseed of , see also Fig.~\ref{fig:c_Delta}.
    \end{example}

    By Lemma~\ref{lem:formula}, the condition for any node on the edge ending at  to be
    a complete cover in  is very simple:
    
    Assume this condition is satisfied and consider any implicit node  on this edge.
    Then  is a quasiseed if both inequalities:
    
    are satisfied.
    Thus in this case
    
  
    \begin{example}
      Consider the word  from Fig.~\ref{fig:CST_example}.
      The word  corresponds to an explicit node of ; we denote it by .
      We have , , , and .
      Therefore  is a quasiseed of . 
      Since ,  could be smaller than 6.
      However,  and the above formula yields .
    \end{example}

    \noindent
    This concludes a complete set of rules for computing  for explicit nodes of .
  \end{proof}


  \section{Conclusions}\label{sec:conclusions}
  We have presented an algorithm which constructs a data structure, called the
  {\em Cover Suffix Tree}, in  time and  space.
  The Cover Suffix Tree has been developed in order to solve the
  \PC\ and \APC\ problem in  and  time,
  respectively, but it also gives a well-structured description of the cover indices of all factors.
  Consequently, various questions related to partial covers can be answered efficiently.
  For example, with the Cover Suffix Tree one can solve in linear time a
  problem inverse to \PC:
  find a factor of length between  and  that maximizes the number of positions covered.
  Also a similar problem to \APC\ problem,
  to compute for all lengths  the maximum number of positions covered by a factor of length ,
  can be solved in  time.
  This solution was actually given implicitly in the proof of Lemma~\ref{lem:all_if_CST}.

  An interesting open problem is to reduce the construction time to .
  This could be difficult, though, since by the results of Section~\ref{sec:by-products}
  this would yield alternative linear-time algorithms finding primitively rooted squares
  and computing seeds.
  The only known linear-time algorithms for these problems
  (see \cite{DBLP:journals/jcss/GusfieldS04,Crochemore2013,DBLP:conf/spire/CrochemoreIKRRW10} and \cite{DBLP:conf/soda/KociumakaKRRW12})
  are rather complex.

   
  \bibliographystyle{abbrv}
  \bibliography{partial_covers}
\end{document}
