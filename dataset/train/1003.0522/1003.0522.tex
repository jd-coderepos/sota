\documentclass[runningheads,letter]{llncs}
\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{url}
\urldef{\mailsa}\path|yodaiken@fsmlabs.com|
\urldef{\mailsc}\path|@fsmlabs.com|
\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}
\newcommand{\set}[1]{\{#1\}}
\newcommand{\seq}[1]{\langle#1\rangle }
\newcommand{\ess}{\Lambda}
\newcommand{\union}{\bigcup}
\newcommand{\Ma}{\mathcal{M}}
\newcommand{\Aprod}{\mathcal{A}}
\newcommand{\Fprod}{\mathcal{F}}
\newcommand{\st}{\mathit{start}}
\newcommand{\conc}{\circ}
\newcommand{\Bfunc}{\left\{\begin{array}{ll}}
\newcommand{\Efunc}{\end{array}\right.}
\newcommand{\Beq}{}
\newcommand*{\longhookrightarrow}{\ensuremath{\lhook\joinrel\relbar\joinrel\rightarrow}}
\newcommand*{\xLongleftarrow}{\ensuremath{\Leftarrow\joinrel\Relbar\joinrel\Relbar\joinrel\Relbar\joinrel\Relbar\joinrel\Relbar\joinrel\Relbar\joinrel\Relbar\joinrel\Relbar}}

\newtheorem{thm}{Theorem}
\newtheorem{dfn}{Definition}[section]
\newtheorem{lem}{Lemma}[section]
\newcommand{\Sample}{\mathcal{S}}
\newcommand{\Partial}{\mathcal{P}}
\newcommand{\Impli}{\mathcal{I}}
\begin{document}

\mainmatter  

\title{State machine models of timing and circuit design}

\titlerunning{State machine solutions}

\author{Victor Yodaiken\thanks{Reformatted and edited Jan-18-10 }
}
\authorrunning{Yodaiken Jan-19-10}


\institute{FSMLabs Inc. 
\mailsa\\
\url{http://www.yodaiken.com}}



\toctitle{State machine solutions}
\tocauthor{VY}
\maketitle


\begin{abstract}
This paper illustrates a technique for specifying
the detailed timing, logical operation, and compositional circuit design
of digital circuits in terms of ordinary state machines with output
(transducers). The method is illustrated here with specifications
of gates, latches, and other simple circuits and via the construction of
devices starting with a SR latch built
from gates and then moving on to more complex devices.
Circuit timing and transients are
treated in some detail.
The method is based on ``classical" automata and recursive functions on strings.
No formal methods, extended state machines,
or process algebras are involved but a reference is made
to potential applications of the Krohn-Rhodes theorem and other group/monoid
based algebraic techniques. 
\keywords{ transducer, Moore machine, primitive recursion, composition, parallel}
\end{abstract}


\section{Introduction}

Both the time sensitive behavior and circuit architecture of 
digital circuits can be effectively modelled as ordinary state machines using
recursive functions for specifications. This note starts with the example of
logic gates and latches constructed from cross-coupled gates, where timing
and transient signals must be taken into account. Section \ref{sec:back} makes
the case that the methods used in section \ref{sec:example1} actually are
equivalent to ordinary automata. Section \ref{sec:example2} carries us
into proofs and more
examples from simple digital circuit design. The focus in this paper is on the by-hand 
methods of specification and verification, but the methods described here seem
to be well suited to automation. One of the goals of this work is to show that 
automata do not need to be extended or enhanced to capture 
properties of complex circuits. A final section discusses some possible implications involving semigroups.


\section{Basics \label{sec:example1}}
\subsection{Behavior}
Behavior should encompass
the possibility of transient outputs and inputs, conditions that leave
output undetermined, and ``don't care" inputs and outputs.
The basic idea here is to model circuits as state
machines with output, possibly state machines constructed as products of
simpler state machines. The recursive function technique permits convenient specification of
enormous state machines, state machines with parameters, and quite arbitrary
interconnect. 

A state machine with output (a transducer)  can be treated as a map from sequences
of inputs to output values with  corresponding to the output of 
in the state reached by following the sequence  from 's initial state. If we put  where  is the empty sequence, we have defined
the initial state output of  --- something that is usually unspecified
in state machines modelling circuits. If we then put  where
 is the sequence obtained by appending input  to sequence , we have
totally determined the input/output behavior of .

For state machines
modelling circuits, inputs can be ``samples" of the input signals applied to
the input pins during the shortest interval of interest (time units may be
picoseconds or microseconds or femtoseconds, depending on the devices being
studied). A sample assigns signal levels to pins. To
start, we can suppose signal levels are limited to . Samples are then
maps  where the set of input pins depends on the device
in question.  Then  defined by  and
 is a (not finite) state machine that simply counts the
number of time intervals that passed since the initial state. But 
defined by  and  tells us how
long pin  has been kept high in consecutive preceding time intervals.

 Say that
 is an OR gate with input pins  and propagation delay  only if 
 for some  implies that .  
There are an infinite number of state machines that satisfy this constraint --- corresponding
to the process variability of actual gates.

Instead of defining  to correspond to , define a single function to see
how long a pin has been \emph{held} at a level.


Or more compactly .

A NAND gate can be specified as follows.
\begin{dfn}  is a NAND-gate with propagation delay  on pins  only if

\end{dfn}

The idea here is to minimally specify what we can expect from a gate and not constrain 
for example transient behavior unless we have some reason to be able to specify in more detail.

Given a function , let's have  count how long the output of  has been stable.


So it's useful to note that if  meets the requirements for a NAND-gate with delay 
then holding an input pin low for  time units causes output to be kept stable for at least
 time units. This is a pretty obvious fact, but let's prove it just to show a style of recursion based
proof that seems eminently automatable.

Note that  by definition. If  then  so there is
nothing to prove. But if  then 
the NAND gate constraints require that  and the rest follows by induction on .
For  there is nothing to prove since  by definition.
Suppose that . If  then  and there is still
nothing to prove since  by definition.
If  then it must be that  since by construction . Thus
 and  so  and if  as assumed by recursion, the inequality must still
hold in the  state.

I'll postpone multi-output circuits to section \ref{sec:example2}.
\subsection{Composition}



Now consider how two NAND-gates could be cross-coupled to create a latch. In 
this case, the inputs to the composite circuit \emph{induce} inputs for the
two component gates. Suppose that  and  are solutions to constraints
\ref{cons:nand1} and \ref{cons:nand2} with input pins .
We want to construct some  that
contains copies of  and  and that accepts input samples that are maps
. When an input  is applied to  an input  will
be generated for the copy of  and an input  for the copy of . Input 
and input  as the two inputs are connected directly to the input pins of the components.
But  will be set to the output of  in the current state and  to the output of 
in the current state.
\begin{center}
\fbox{\begin{minipage}{5in}

\end{minipage}
}
\end{center}

Define  
where  and  are the induced input sequences that are themselves
functions of  and . We need to define a mapping  and
we do so recursively. Note that when  we must have  so that
the components do not see any input until the composite system sees input.

\begin{dfn}  is a constructed RS-Latch with base propagation delay 
on pins  only if

\end{dfn}

Define  to extract the  output from the latch.

\subsection{Abstraction}
Stepping back from the construction, consider an abstract behavioral specification of an RS-latch.



We want to say  is a SR-latch with delay  if and only if
whenever  we must have .
Without proof, if  is constructed from NAND-gates of delay  as specified above, and  then
 is a RS-latch with delay . The  is an artifact of the model, which imposes a single
time unit delay for a signal to propagate between the output and input of any connected components\footnote{ 
If that requirement is a problem the model can be adjusted. For example, we could require that for any circuit element ,  for any
samples  and  --- that is, there is at least one unit of delay between
the application of a signal and a response. A sensible limitation in any case.
Because the output does not depend on input, we can calculate the output using a dummy input.
So for example make  be any appropriate sample and let,  where 
--- eliminating the interconnect delay.}.
Of course, this is not a surprising fact,
since engineers have been using latches since the 1950s and, by all indications, they work as intended.

Just for fun, consider a NAND-gate constructed from 3 gates. Suppose  and 
 and  are all NAND-gates with delay  on pins  and 
we want to build a NAND gate with input pins  from them.
Put  and let . 
Define  when . Then if
 define the mapping 
where 


The glaring difference between  and the constructed  is that the
mapping from  to the  involves recursive feedback for  but not
for .

\section{Background\label{sec:back}}

\subsection{Representations}
We're representing state machines (transducers) with functions on strings.
\begin{center}
\fbox{
\begin{minipage}{4in}
Correspondence between a transducer  and a string function .

\end{minipage}
}
\end{center}

A Moore machine or transducer is usually given by a 6-tuple

where  is the alphabet,  is a set of outputs,  is a set of states,  is the initial
state,  is the transition function
and is the output function.
While it is usual to limit Moore machines to finite state sets, and such
finite state machines are sufficient to represent any constructable digital
system, it's convenient to have infinite state machines available for specifications. For example, a hypothetical infinite counter may be useful in describing the periodic
behavior of a finite state device. 

Given , use primitive recursion on sequences to 
extend  the transition function  to  by:


So  is
the output of  in the state reached by following  from 's initial
state.
Call  the 
\emph{representing function} of . A representing function is ``finite" if
and only if it represents a finite state machine. 

The transformation from string function to transducer is also simple.
Given  define   where  indicates string
concatenation. Note that it is possible for  but  meaning
that   for all
.  Intuitively  when both lead to the same state. Let .
Say  is finite if and only if  is finite. Define
 and define . Then
with  we have a Moore machine

and, by construction  is the representing function for . See section \ref{sec:conjecture} for a short
discussion of the next step of abstraction: the monoid induced by the state machine.

Any  that has  as a representing function can differ
from  only in names of states and by including unreachable and/or
duplicative states. That is, there may be some   so that
 but since  it must
be the case that the states are identical in output and in the output of any
states reachable from them. If we are using Moore machines to
represent the behavior of digital systems, these differences are not particularly interesting and we can treat  as \emph{the} Moore machine represented
by .

\subsection{Products}

Gecseg\cite{Gecseg}  describes a general automata product suitable to composition of digital circuits that is used in a simplified way here and in a more
general way in \cite{yodaikenprpresent}.

Suppose we have a collection of (not necessarily distinct) Moore machines
 for 
that are to be connected to construct a new machine with alphabet  
using a connection map .
The intuition is that when an input  is applied to the system,
the connection map computes an input for
 from the input  and the outputs of the factors (\emph{feedback}).

\begin{dfn}{\rm
\textbf{General product of automata for digital circuits}\\
Given  and  and 
 where , define the Moore machine:
\\
\begin{itemize}
\item  and 
\item  and .
\item .
\end{itemize} }
\end{dfn}

I'll state without proof a theorem proved elsewhere that should be reasonably
obvious\cite{yodaikenprpresent}.
\begin{thm}\label{thm:main}{\rm
\textbf{If} each  represents 
and \\
and when , \\
and if when , then  where .\\
and 
\textbf{then}  represents 
}\end{thm}

\section{More examples\label{sec:example2}}

Let's step up the complexity of the examples to  multi-output-pin circuits.
In this case, we just add another parameter to select which output pin is
being referenced.
A single bit adder might output have output pins
 and accept
input samples . 


An  bit  adder then has inputs that are maps from 
 to .  The output pins are . In contrast to a gate, there are never
``do not care" inputs. Define . Define 
and 


Let

and 
Given a binary -vector , define projection  and
then  assuming both that the lower indexed bits
are the lower order bits and that the length of the vector is known.
What we want of an -bit adder  is that
when inputs have been stable for long enough .


We can construct a ripple carry adder as follows.



If  is the delay for the component adders, then 
we want to require that  should imply .
I'm just going to present proof sketches since the idea should be clear and
the main claim here is that these proofs should be reasonably easy to 
automate. I want to particularly show how component properties can be pushed
up the composition ladder because if  tells us that  has a 
property  and we can show it for all , then  must be true.
However, there are additional constraints on  because of the definition
of the map from  to .

Proofs are usually by induction: one strings and on the component index.
First, there is a lemma
for how long the output of an adder is stable when the input is held stable.
Recall the definition of  above in equation  and 
consider . 

Ignoring the composite system, say that  delay adder  must have the 
property that:


Note this  ranges over input sequences for single-bit adders - we'll turn to
 for the n-bit adder below.
Proof: Let  and there is nothing to prove since 
and . Suppose the lemma true for  and consider .
Suppose  and
consider  where we extend the  notation to allow for pin arguments.
If  then
all we have to prove is that  which is trivially true. So 
consider  and  for some .
Note that  implies that  for
each input  pin  for some value of .
So by the definition of
an adder the outputs of  are determined when .
From the definition of  we have  only when 
which we know is false (or else .
So  which means 
so  and  so  which means that the
outputs at state  were determined by the inputs which have not changed
by state . QED.

Now switch back to the composite structure.
By construction,   and   and 
 . So by the lemma at \ref{lemma2} and the initial assumption
 since the inputs have been stable for
. Now we note that for , we must have
. The proof is by induction
using the definition of the mapping from  to the .  This tells us that the inputs for . The  gets lost because of the 1 unit delay between output pins and input pins - see the
note above. At this point it's a matter of putting the parts together to complete the proof.

\section{Possible future directions\label{sec:conjecture}}


One of the advantages of working with ``vanilla" state machines is that they are fundamentally related to algebra --- algebra in the sense of groups and monoids, not ``algebra" in the sense of ``process algebra" or even universal algebra. It's
well known that every state machine induces a monoid, and there is a decomposition theory for state machines that parallels
and extends group decomposition via the Jordon-Holder theorem.  The researchers who first looked at algebraic automata
theory were focused on so-called ``cascade" products in which there is no feedback\cite{Arbibabs,Holcombe,ginzburg}.
For example, the composed nand-gate
above has no feedback between the  --- information moves in one direction only. The constructed SR latch, on the
other hand, requires that the output of  be fed back into . The standard digital architecture distinction
between combinational and sequential circuits appears related to this distinction. 

Recall  the state set induced by . Let  be the monoid consisting
of the set of maps
 for  so that  and the operation
. The set of maps will be a superset of  because
 does not imply that  since  which
may be distinct from . But if  is finite then  must be
finite and certainly  is the identity and


The product used here was ignored by the pioneers of algebraic automata theory for a variety of reasons, but
perhaps one of them was that the practitioner interest was in state minimization which leads naturally to
questions of decomposition. The full generality of feedback products also loses the analogy to the
wreath products of the Jordon-Holder theorem that are key to the Krohn-Rhodes decomposition. But
the product used here is quite constrained. Each  or  where  is
a component factor because the 
communication mimics the connection of wires so that no computation can be done in the connection map. There
are additional constraints imposed by fan-out and fan-in limits and we may want more constraints such as
the  constraint mentioned above that prevents instant response to inputs.
We can conjecture that this constrained
product also has structural implications for the construction of monoids. With the caution that
what follows is extremely early conjecture let's look at some possibilities relating combinations versus
sequence circuits to group structure.  What we call
combinatorial circuits in digital circuit engineering seems to produce state systems with only trivial loops - where.  This limits the complexity of subgroups within the underlying monoid. So products
with non-trivial feedback may be the only ways to introduce longer loops into the state structure.

\bibliography{all}
\bibliographystyle{plain}
\end{document}
