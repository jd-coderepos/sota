[{'LEADERBOARD': {'Task': 'Zero-Shot Video Question Answer', 'Dataset': 'MSRVTT-QA', 'Metric': 'Accuracy', 'Score': '43.8'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Video Question Answer', 'Dataset': 'MSRVTT-QA', 'Metric': 'Confidence Score', 'Score': '2.7'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Video Question Answer', 'Dataset': 'ActivityNet-QA', 'Metric': 'Confidence Score', 'Score': '2.7'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Video Question Answer', 'Dataset': 'ActivityNet-QA', 'Metric': 'Accuracy', 'Score': '34.2'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Video Question Answer', 'Dataset': 'MSVD-QA', 'Metric': 'Accuracy', 'Score': '54.9'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Video Question Answer', 'Dataset': 'MSVD-QA', 'Metric': 'Confidence Score', 'Score': '3.1'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'InfiMM-Eval', 'Metric': 'Overall score', 'Score': '30.46'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'InfiMM-Eval', 'Metric': 'Deductive', 'Score': '28.7'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'InfiMM-Eval', 'Metric': 'Abductive', 'Score': '46.12'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'InfiMM-Eval', 'Metric': 'Analogical', 'Score': '22.08'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'InfiMM-Eval', 'Metric': 'Params', 'Score': '7B'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering', 'Dataset': 'MM-Vet', 'Metric': 'GPT-4 score', 'Score': '31.4Â±0.1'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering', 'Dataset': 'MM-Vet', 'Metric': 'Params', 'Score': '7B'}}, {'LEADERBOARD': {'Task': 'Video-based Generative Performance Benchmarking', 'Dataset': 'VideoInstruct', 'Metric': 'Correctness of Information', 'Score': '2.03'}}, {'LEADERBOARD': {'Task': 'Video-based Generative Performance Benchmarking', 'Dataset': 'VideoInstruct', 'Metric': 'Detail Orientation', 'Score': '2.32'}}, {'LEADERBOARD': {'Task': 'Video-based Generative Performance Benchmarking', 'Dataset': 'VideoInstruct', 'Metric': 'Contextual Understanding', 'Score': '2.30'}}, {'LEADERBOARD': {'Task': 'Video-based Generative Performance Benchmarking', 'Dataset': 'VideoInstruct', 'Metric': 'Temporal Understanding', 'Score': '1.98'}}, {'LEADERBOARD': {'Task': 'Video-based Generative Performance Benchmarking', 'Dataset': 'VideoInstruct', 'Metric': 'Consistency', 'Score': '2.15'}}, {'LEADERBOARD': {'Task': 'Video-based Generative Performance Benchmarking', 'Dataset': 'VideoInstruct', 'Metric': 'mean', 'Score': '2.16'}}, {'LEADERBOARD': {'Task': 'Video-based Generative Performance Benchmarking (Correctness of Information)', 'Dataset': 'VideoInstruct', 'Metric': 'gpt-score', 'Score': '2.03'}}, {'LEADERBOARD': {'Task': 'Video-based Generative Performance Benchmarking (Detail Orientation))', 'Dataset': 'VideoInstruct', 'Metric': 'gpt-score', 'Score': '2.32'}}, {'LEADERBOARD': {'Task': 'Video-based Generative Performance Benchmarking (Contextual Understanding)', 'Dataset': 'VideoInstruct', 'Metric': 'gpt-score', 'Score': '2.30'}}, {'LEADERBOARD': {'Task': 'Video-based Generative Performance Benchmarking (Temporal Understanding)', 'Dataset': 'VideoInstruct', 'Metric': 'gpt-score', 'Score': '1.98'}}, {'LEADERBOARD': {'Task': 'Video-based Generative Performance Benchmarking (Consistency)', 'Dataset': 'VideoInstruct', 'Metric': 'gpt-score', 'Score': '2.15'}}]
