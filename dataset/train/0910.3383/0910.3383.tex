


\label{sec:foc_mumall}

In \cite{andreoli92jlc}, Andreoli identified some important structures
in linear logic, which led to the design of his focused proof system.
This complete proof system for (second-order) linear logic structures
proofs in stripes of \emph{asynchronous} and \emph{synchronous} rules.
Choices in the order of application of asynchronous rules do not matter,
so that the real non-determinism lies in the synchronous phase.
However, the focused system tames this non-determinism by forcing
to hereditarily chain these choices: once the focus is set on a
synchronous formula, it remains on its subformulas
as its connectives are introduced, and so on,
to be released only on asynchronous subformulas.
We refer the reader to \cite{andreoli92jlc} for a complete
description of that system,
but note that Figure~\ref{fig:focused}, without the fixed point rules,
can be used as a fairly good reminder:
it follows the exact same structure, only missing the rules for exponentials.

Focusing \mumall\ can be approached simply by reading the
focusing of second-order linear logic through the encoding of fixed points.
But this naive approach yields a poorly
structured system.
Let us recall the second-order encoding of $\mu B \t$:
\[ \forall S.~ \oc(\forall \x.~ B S \x \llimp S \x) \llimp S \t \]
This formula starts with a layer of asynchronous connectives:
$\forall$, $\llimp$ and ${\wn}$, the dual of $\,{\oc}$.
Once the asynchronous layer has been 
processed, the second-order eigenvariable $S$ represents $\mu B$
and one obtains unfoldings of $S$ into $BS$
by focusing on the pre-fixed point hypothesis.
Through that encoding, one would thus obtain a system where several unfoldings
necessarily require several phase alternations.
This is not satisfying:
the game-based reading of focusing identifies fully synchronous (positive)
formulas with data types, which should be built in one step by the player,
\ie\ in one synchronous phase.
In \mumall, least fixed points over fully synchronous operators
should be seen as data types.
That intuition, visible in previous examples, is also justified
by the classification of connectives in Definition~\ref{def:connectives},
and is indeed accounted for in the focused system
presented in Figure~\ref{fig:focused}.

It is commonly believed that asynchrony corresponds to invertibility.
The two notions do coincide in many cases but it should not be taken too
seriously, since this does not explain, for example,
the treatment of exponentials,
or the fact that $init$ has to be synchronous while it is trivially
invertible.
In the particular case of fixed points,
invertibility is of no help in designing a complete focused proof system.
Both $\mu$ and $\nu$ are invertible (in the case of $\nu$, this is
obtained by using the unfolding coinvariant) but
this does not capture the essential aspect of fixed points, that is
their infinite behavior.
As a result, a system requiring that the $\mu$ rule is applied
whenever possible would not be complete, notably failing
on $\;\vdash \top \lltens \llone, \mu p. p$ or $\;\vdash nat~x \llimp nat~x$.
As we shall see, the key to obtaining focused systems is to consider
the permutability of asynchronous rules, rather than their invertibility,
as the fundamental guiding principle.

We first design the $\mu$-focused system in Section~\ref{sec:mufoc},
treating $\mu$ synchronously,
which is satisfying for several reasons starting with its positive nature.
We show in Section~\ref{sec:nufoc} that it is also possible to consider
a focused system for \mumall\ where $\nu$ is treated synchronously.
In Section~\ref{sec:foc_mulj}, we apply the $\mu$-focused system
to a fragment of \muLJ.

\subsection{A complete $\mu$-focused calculus} \label{sec:mufoc}

In this section,
we call \emph{asynchronous} (\resp \emph{synchronous})
the negative (\resp positive) connectives of Definition~\ref{def:connectives}
and the formulas whose top-level connective is asynchronous (\resp 
synchronous).
Moreover, we classify non-negated atoms as synchronous and negated
ones as asynchronous. As with Andreoli's original system, this latter choice
is arbitrary and can easily be changed for a case-by-case 
assignment~\cite{miller07cslb,chaudhuri08jar}.

We present the system in Figure~\ref{fig:focused} as a good
candidate for a focused proof system for \mumall.
In addition to asynchronous and synchronous formulas as defined above,
focused sequents can contain \emph{frozen formulas} $P^*$
where $P$ is an asynchronous atom or fixed point.
Frozen formulas may only be found at toplevel in sequents.
We use explicit annotations of the sequents in the style of Andreoli:
in the synchronous phase, sequents have the form
$\;\vdash \Gamma \Downarrow P$;
in the asynchronous phase, they have the form
$\;\vdash \Gamma \Uparrow \Delta$.
In both cases,
$\Gamma$ and $\Delta$ are sets of formulas of disjoint locations,
and $\Gamma$ is a multiset of synchronous or frozen formulas.
The convention on $\Delta$ is a slight departure from Andreoli's
original proof system where $\Delta$ is a list: we shall emphasize
the irrelevance of the order of asynchronous rules without
forcing a particular, arbitrary ordering.
Although we use an explicit freezing annotation,
our treatment of atoms is really the same one as Andreoli's;
the notion of freezing is introduced here as a technical device for
dealing precisely with fixed points,
and we also use it for atoms for a more uniform presentation.

\begin{figure}[htpb]
\begin{center}
$\begin{array}{c}
\mbox{Asynchronous phase}
\\[6pt]
\infer{\vdash\Gamma\Uparrow P\llpar Q,\Delta}{\vdash\Gamma\Uparrow P,Q,\Delta}
\quad
\infer{\vdash\Gamma\Uparrow P\llwith Q, \Delta}{
  \vdash\Gamma\Uparrow P,\Delta & \vdash\Gamma\Uparrow Q,\Delta
}
\quad
\infer{\vdash\Gamma\Uparrow a^\perp\t, \Delta}{
  \vdash\Gamma,(a^\perp\t)^*\Uparrow\Delta}
\\[6pt]
\infer{\vdash \Gamma \Uparrow \bot, \Delta}{\vdash \Gamma\Uparrow\Delta}
\quad
\infer{\vdash \Gamma \Uparrow \top, \Delta}{}
\quad
\infer{\vdash \Gamma \Uparrow s\neq t, \Delta}{
 \{ \vdash \Gamma\theta \Uparrow \Delta\theta :
      \theta\in csu(s\unif t) \} }
\\[6pt]
\infer{\vdash\Gamma\Uparrow\forall{}x. P x,\Delta}{
  \vdash\Gamma\Uparrow P c,\Delta}
\\[6pt]
\infer{\vdash\Gamma\Uparrow \nu{}B\t,\Delta}{
  \vdash\Gamma\Uparrow S\t,\Delta &
  \vdash\Uparrow BS\x, S\x^\bot
}
\quad
\infer{\vdash\Gamma\Uparrow \nu{}B\t,\Delta}{
  \vdash\Gamma,(\nu{}B\t)^*\Uparrow\Delta}
\end{array}
$

\vspace{10pt}
$
\begin{array}{c}
\mbox{Synchronous phase}
\\[6pt]
\infer{\vdash\Gamma,\Gamma'\Downarrow P\lltens Q}{
  \vdash\Gamma\Downarrow P &
  \vdash \Gamma'\Downarrow Q
}
\quad
\infer{\vdash \Gamma\Downarrow P_0\llplus P_1}{\vdash\Gamma\Downarrow P_i}
\quad
\infer{\vdash (a^\perp\t)^*\Downarrow a\t}{}
\\[6pt]
\infer{\vdash \Downarrow \llone}{} \quad \infer{\vdash \Downarrow t=t}{}
\\[6pt]
\infer{\vdash \Gamma\Downarrow\exists{}x. P x}{\vdash\Gamma\Downarrow P t}
\\[6pt]
\infer{\vdash\Gamma\Downarrow \mu{}B\t}{\vdash\Gamma\Downarrow B(\mu{}B)\t}
\quad
\infer{\vdash (\nu{}\B\t)^*\Downarrow \mu{}B\t}{}
\end{array}$

\vspace{10pt}
Switching rules (where $P$ is synchronous, $Q$ asynchronous)
\[
\infer{\vdash\Gamma\Uparrow P,\Delta}{\vdash\Gamma,P\Uparrow\Delta}
\quad
\infer{\vdash \Gamma, P \Uparrow}{\vdash \Gamma \Downarrow P}
\quad
\infer{\vdash \Gamma \Downarrow Q}{\vdash \Gamma \Uparrow Q}
\]
\end{center}
\caption{The $\mu$-focused proof-system for \mumall}
\label{fig:focused}
\end{figure}

The $\mu$-focused system extends the usual focused system for MALL.
The rules for equality are not surprising,
the main novelty here is the treatment of fixed points.
Each of the fixed point connectives has two rules in the focused 
system:  one treats it ``as an atom'' and the other one as an expression with
internal logical structure.
In accordance with Definition~\ref{def:connectives},
$\mu$ is treated during the synchronous phase
and $\nu$ during the asynchronous phase.

Roughly, what the focused system implies is that
if a proof involving a $\nu$-expression
proceeds by coinduction on it, then this coinduction can be done at the 
beginning;
otherwise that formula can be ignored in the whole derivation,
except for the $init$ rule.
The latter case is expressed by the rule which moves the greatest fixed
point to the left zone, freezing it.
Focusing on a $\mu$-expression yields two choices: unfolding or applying the 
initial rule for fixed points.
If the considered operator is fully synchronous, the focus will never be lost.
For example, if $nat$ is the (fully synchronous) expression
$\mu N. \lambda{}x.~ x=0 \llplus \exists{}y.~ x=s~y \lltens N~y$,
then focusing puts a lot of structure on a proof of
$\vdash \Gamma\Downarrow nat~t$: 
either $t$ is a closed term representing a natural number and $\Gamma$ is empty,
or $t = s^n t'$ for some $n\geq 0$ and $\Gamma$ only contains $(nat~t')^\bot$.

We shall now establish the completeness of our focused proof system:
If the unfocused sequent $\;\vdash\Gamma$ is provable then so is
$\;\vdash\Uparrow\Gamma$, and the order of application of asynchronous
rules does not affect provability.
From the perspective of proofs rather than provability,
we are actually going to provide transformations from unfocused to focused
derivations (and back) which can reorder asynchronous rules arbitrarily.
However, this result cannot hold without a simple condition
avoiding pathological uses of infinite branching, as illustrated with
the following counter-example.
The unification problem $s~(f~0)\unif f~(s~0)$, where $s$ and $0$ are constants,
has infinitely many solutions $[(\lambda x.~ s^n x) / f]$.
Using this, we build a derivation $\Pi_\omega$
with infinitely many branches, each $\Pi_n$
unfolding a greatest fixed point $n$ times:
\[
 \Pi_0 \eqdef \infer[\top]{\vdash \nu p. p, \top}{} \quad\quad
 \Pi_{n+1} \eqdef \infer[\nu]{\vdash \nu p. p, \top}{
                  \infer{\vdash \nu p. p, \top}{\Pi_n} &
                  \infer[init]{\vdash \mu p. p, \nu p. p}{}} \]
 \[ \Pi_\omega \eqdef \infer[\neq]{
                     f; \vdash s~(f~0) \neq f~(s~0), \nu p. p, \top}{
                     \Pi_0 & \Pi_1 & \ldots & \Pi_n & \ldots} \]
Although this proof happens to be already in a focused form,
in the sense that focusing annotations can be added in a straightforward
way,
the focused transformation must also provide a way to change the order
of application of asynchronous rules.
In particular it must allow to permute down the introduction of
the first $\nu p. p$. The only reasonable way to do so is as follows,
expanding $\Pi_0$ into $\Pi_1$ and then pulling down the $\nu$ rule
from each subderivation, changing $\Pi_{n+1}$ into $\Pi_n$:
\[ \Pi_\omega \quad\rightsquigarrow\quad
      \infer[\nu]{f; \vdash s~(f~0) \neq f~(s~0), \nu p. p, \top}{
         \infer{f; \vdash s~(f~0) \neq f~(s~0), \nu p. p, \top}{\Pi_\omega} &
         \infer[init]{\vdash \mu p. p, \nu p. p}{}} \]
This leads to a focusing transformation that may not terminate.
The fundamental problem here is that although each additive
branch only finitely explores the asynchronous formula $\nu p.p$,
the overall use is infinite.
A solution would be to admit infinitely deep derivations,
with which such infinite balancing process may have a limit.
But our goal here is to develop finite proof representations
(this is the whole point of (co)induction rules)
so we take an opposite approach and require a minimum amount
of finiteness in our proofs.

\begin{definition}[Quasi-finite derivation]
A derivation is said to be quasi-finite if
it is cut-free,
has a finite height
and only uses a finite number of different coinvariants.
\end{definition}

This condition may seem unfortunate, but it appears to be essential
when dealing with transfinite proof systems involving fixed points. More
precisely, it is related to the choice regarding the introduction of
asynchronous fixed points, be they greatest fixed points in $\mu$-focusing
or least fixed points in $\nu$-focusing.
Note that quasi-finiteness is trivially satisfied
for any cut-free derivation that is finitely branching,
and that any derivation which does not involve the $\neq$ rule
can be normalized into a quasi-finite one.
Moreover,
quasi-finiteness is a natural condition from a practical perspective,
for example in the context of automated or interactive theorem proving,
where $\neq$ is restricted to finitely branching instances anyway.
However, it would be desirable to refine the notion of quasi-finite
derivation in a way that allows cuts and is preserved by cut elimination,
so that quasi-finite proofs could be considered a proper proof fragment.
Indeed, the essential idea behind quasi-finiteness is that
only a finite number of locations are explored in a proof,
and the cut-free condition is only added because cut reductions
do not obviously preserve this.
We conjecture that a proper, self-contained notion of quasi-finite
derivation can be attained,
but leave this technical development to further work.



The core of the completeness proof follows~\cite{miller07cslb}.
This proof technique proceeds by transforming standard derivations
into a form where focused annotations can be added to obtain a focused
derivation. Conceptually, focused proofs are simply special cases
of standard proofs, the annotated sequents of the focused proof system
being a concise way of describing their shape.
The proof transformation proceeds by iterating two lemmas which
perform rule permutations: the first lemma expresses that 
asynchronous rules can always be applied first, while the second one
expresses that synchronous rules can be applied in a hereditary fashion
once the focus has been chosen.
The key ingredient of \cite{miller07cslb} is the notion of focalization
graph, analyzing dependencies in a proof and showing that there is always
at least one possible focus.

In order to ease the proof, we shall consider an intermediate
proof system whose rules enjoy a one-to-one correspondence with
the focused rules.
This involves getting rid of the cut, non-atomic axioms,
and also explicitly performing freezing.

\begin{definition}[Freezing-annotated derivation]
The freezing-annotated variant of \mumall\ is obtained by
removing the cut rule,
enriching the sequent structure with an annotation for frozen fixed points
or atoms,
restricting the initial rule to be applied only on frozen asynchronous
formulas,
and adding explicit annotation rules:
\[
   \infer{\vdash \freeze{a^\perp\t}, a\t}{}
\quad\quad
   \infer{\vdash \freeze{\nu\B\t}, \mu B \t}{}
\quad\quad
   \infer{\vdash \Gamma, \nu B \t}{\vdash \Gamma, \freeze{\nu B \t}}
\quad\quad
   \infer{\vdash \Gamma, a^\perp\t}{\vdash \Gamma, \freeze{a^\perp\t}}
\]

Atomic instances of $init$ can be translated into freezing-annotated
derivations:
\[ \infer{\vdash \nu B\t, \mu \B\t}{}
\quad \longrightarrow \quad
   \infer{\vdash \nu B\t , \mu \B\t }{
   \infer{\vdash \freeze{\nu B\t}, \mu \B\t }{}}
\quad\quad\quad\quad
   \infer{\vdash a^\perp\t, a\t}{}
\quad \longrightarrow \quad
   \infer{\vdash a^\perp\t , a\t }{
   \infer{\vdash \freeze{a^\perp\t}, a\t }{}} \]
Arbitrary instances of $init$ can also be obtained by first expanding them
to rely only on atomic $init$, using Proposition~\ref{def:atomicinit},
and then translating atomic $init$ as shown above.
We shall denote by $init*$ this derived generalized axiom.
Any \mumall\ derivation can be transformed into a freezing-annotated one
by normalizing it and translating $init$ into $init*$.
\end{definition}

The asynchronous freezing-annotated rules (that is,
those whose principal formula is asynchronous) correspond naturally
to asynchronous rules of the $\mu$-focused system.
Similarly, synchronous freezing-annotated rules correspond to
synchronous focused rules, which includes the axiom rule.
The switching rules of the $\mu$-focused system
do not have a freezing-annotated equivalent:
they are just book-keeping devices marking phase transitions.

From now on we shall work on freezing-annotated derivations,
simply calling them derivations.


\subsubsection{Balanced derivations}

In order to ensure that the focalization process terminates, we have to 
guarantee that the permutation steps preserve some measure over derivations.
The main problem here comes from the treatment of fixed points,
and more precisely from the fact that there is a choice in the asynchronous
phase regarding greatest fixed points.
We must ensure that a given greatest fixed point formula is always used in 
the same way in all additive branches of a proof:
if a greatest fixed point is copied by an additive conjunction or $\neq$,
then it should either be used for coinduction in all branches,
or frozen and used for axiom in all branches.
Otherwise it would not be possible to permute the treatment of the 
$\nu$ under that of the $\llwith$ or $\neq$ while controlling the size of
the transformed derivation.

\begin{definition}[Balanced derivation]
A greatest fixed point occurrence is \emph{used in a balanced way}
if all of its principal occurrences are used consistently:
either they are all frozen or they are all used for coinduction, 
with the same coinvariant.
We say that a derivation is \emph{balanced} if it is quasi-finite
and all greatest fixed points occurring in it are used in a balanced way.
\end{definition}

\begin{lemma}\label{lem:invwith}
If $S_0$ and $S_1$ are both coinvariants for $B$
then so is $S_0\llplus S_1$.
\end{lemma}

\begin{proof}
Let $\Pi_i$ be the derivation of coinvariance for $S_i$.
The proof of coinvariance of $S_0\llplus S_1$ is as follows:
\[ \infer[\llwith]{\vdash S_0^\perp\x \llwith S_1^\perp\x,
                          B (S_0\llplus S_1) \x}{
   \infer{\vdash S_0^\perp\x, B (S_0\llplus S_1)\x}{
   \phi_0(\Pi_0)}
   &
   \infer{\vdash S_1^\perp\x, B (S_0\llplus S_1)\x}{
   \phi_1(\Pi_1)}
} \]
The transformed derivations $\phi_i(\Pi_i)$ are obtained by functoriality:
\[ \phi_i(\Pi_i) = \infer[cut]{\vdash S_i^\perp\x, B (S_0\llplus S_1)\x}{
                  \infer{\vdash S_i^\perp\x, B S_i \x}{\Pi_i} &
                  \infer[B]{\vdash \B S_i^\perp \x,
                                   B (S_0\llplus S_1) \x}{
                  \infer[\llplus]{\vdash S_i^\perp \y, S_0\y\llplus S_1\y}{
                  \infer[init]{\vdash S_i^\perp\y, S_i\y}{}}}} \]
Notice that after the elimination of cuts, the proof of coinvariance
that we built can be larger than the original ones:
this is why this transformation cannot be done as part of
the rule permutation process.
\end{proof}

\begin{lemma} \label{lem:balance}
Any quasi-finite derivation of $\;\vdash\Gamma$
can be transformed into a balanced
derivation of $\;\vdash\Gamma$.
\end{lemma}

\begin{proof}
We first ensure that all coinvariants used for the same (locatively identical)
greatest fixed point are the same.
For each $\nu B$ on which at least one coinduction is performed
in the proof, this is achieved by taking the union of all coinvariants
used in the derivation,
thanks to Lemma~\ref{lem:invwith},
adding to this union the unfolding coinvariant $B (\nu B)$.
Note that quasi-finiteness is needed here to
ensure that we are only combining finitely many coinvariants.
Let $S_{\nu B}$ be the resulting coinvariant,
of the form $S_0 \llplus \ldots \llplus S_n \llplus B (\nu B)$,
and $\Theta_{\nu B}$ be the proof of its coinvariance.
We adapt our derivation by
changing every instance of the $\nu$ rule as follows:
\[ \infer{\vdash \Gamma, \nu B \t}{
      \vdash \Gamma, S_i \t &
      \infer{\vdash S_i^\perp \x, B S_i \x}{\Theta_i}}
   \quad\longrightarrow\quad
   \infer{\vdash \Gamma, \nu B \t}{
     \infer=[\llplus]{\vdash
       \Gamma, S_{\nu B}\t}{
       \vdash \Gamma, S_i\t}
     &
     \infer{\vdash S_{\nu B}^\perp\x, BS_{\nu B}\x}{\Theta_{\nu B}}
  } \]

It remains to ensure that a given fixed point is either always coinducted on
or always frozen in the derivation.
We shall balance greatest fixed points,
starting with unbalanced fixed points closest to the root,
and potentially unbalancing deeper fixed points in that process,
but without ever introducing unbalanced fixed points that were not initially
occurring in the proof.

Let $\Pi_0$ be the derivation obtained at this point.
We define the degree of a greatest fixed point
to be the maximum distance in the sublocation ordering
to a greatest fixed point sublocation occurring in $\Pi_0$,
$0$ if there is none.
Quasi-finiteness ensures that degrees are finite,
since there are only finitely many locations occurring at toplevel
in the sequents of a quasi-finite derivation.
We shall only consider derivations in which greatest fixed points that
are coinducted on are also coinducted on with the same coinvariant
in $\Pi_0$, and maintain this condition
while transforming any such derivation into a balanced one.
We proceed by induction on
the multiset of the degrees of unbalanced fixed points in the derivation,
ordered using the standard multiset ordering |
note that degrees are well defined for all unbalanced fixed points since they
must also occur in $\Pi_0$.
If there is no unbalanced fixed point, we have a balanced proof.
Otherwise, pick an unbalanced fixed point of maximal degree.
It is frozen in some branches and coinducted on in others.
We remove all applications of freezing on that fixed point,
which requires to adapt axioms\footnote{
  Note that instead of the unfolding coinvariant $B(\nu B)$ we could have
  used the coinvariant $\nu B$. This would yield a simpler proof,
  but that would not be so easy to adapt for $\nu$-focusing in
  Section~\ref{sec:nufoc}.
}:
\[ \infer{\vdash \freeze{\nu B \t}, \mu \B \t}{}
\quad\longrightarrow\quad
   \infer[\nu]{\vdash \nu B \t, \mu\B\t}{
   \infer=[\llplus]{\vdash S_{\nu B}\t,\mu\B\t}{
   \infer[\mu]{\vdash B (\nu B) \t, \mu\B\t}{
   \infer[init*]{\vdash B (\nu B) \t, \B(\mu\B)\t}{}}}
   & \infer{\vdash S^\perp_{\nu B}\x, BS_{\nu B}\x}{\Theta_{\nu B}}} \]
The fixed point $\nu B$ is used in a balanced way in the resulting derivation.
Our use of the derived rule $init*$ might have introduced
some new freezing rules on greatest fixed point
sublocations of $B(\nu B)$ or $\B (\mu \B)$.
Such sublocations, if already present in the proof,
may become unbalanced, but have a smaller degree.
Some new sublocations may also be introduced,
but they are only frozen as required.
The new derivation has a smaller multiset
of unbalanced fixed points, and we can conclude by induction hypothesis.
\end{proof}

Balancing is the most novel part of our focalization process.
This preprocessing is a technical device ensuring
termination in the proof of completeness,
whatever rule permutations are performed.
It should be noted that balancing is often too strong,
and that many focused proofs are indeed not balanced.
For example,
it is possible to obtain unbalanced focused proofs
by introducing an additive conjunction before treating a greatest 
fixed point differently in each branch.

\subsubsection{Focalization graph}

We shall now present the notion of focalization graph
and its main properties~\cite{miller07cslb}.
As we shall see, their adaptation to \mumall{}
is trivial\footnote{
  Note that we do not use the same notations:
  in \cite{miller07cslb}, ${\prec}$ denotes the subformula relation
  while it represents accessibility in the focalization graph in our case.
}.

\begin{definition}
The \emph{synchronous trunk} of a derivation is its largest prefix
containing only applications of synchronous rules.
It is a potentially open subderivation having the same conclusion sequent.
The open sequents of the synchronous trunk (which are conclusions
of asynchronous rules in the full derivation) and its initial sequents
(which are conclusions of $init$, $\llone$ or ${=}$)
are called \emph{leaf sequents} of the trunk.
\end{definition}

\begin{definition}
We define the relation $\prec$ on the formulas of
the base sequent of a derivation $\Pi$:
$P\prec Q$ if and only if
there exists $P'$, asynchronous subformula\footnote{
  This does mean subformula in the locative sense,
  in particular with (co)invariants being subformulas of
  the associated fixed points.
} of $P$,
and $Q'$, synchronous subformula of $Q$,
such that $P'$ and $Q'$ occur in the same
leaf sequent of the synchronous trunk of $\Pi$.
\end{definition}

The intended meaning of $P\prec Q$ is that we must focus on $P$ before $Q$.
Therefore, the natural question is the existence of minimal elements for that 
relation, equivalent to its acyclicity.

\begin{proposition} \label{prop:mini_subform}
If $\Pi$ starts with a synchronous rule,
and $P$ is minimal for $\prec$ in $\Pi$,
then so are its subformulas in their respective subderivations.
\end{proposition}

\begin{proof}
There is nothing to do
if $\Pi$ simply consists of an initial rule.
In all other cases
($\lltens$, $\llplus$, $\exists$ and $\mu$)
let us consider any subderivation $\Pi'$ in which
the minimal element $P$ or one of its subformulas $P'$ occurs
| there will be exactly one such $\Pi'$, except in the case of a tensor
applied on $P$.
The other formulas occurring in the conclusion of $\Pi'$
either occur in the conclusion of $\Pi$ or are subformulas
of the principal formula occurring in it.
This implies that a $Q\prec P$ or $Q\prec P'$ in $\Pi'$
would yield a $Q'\prec P$ in $\Pi$,
which contradicts the minimality hypothesis.
\end{proof}

\begin{lemma}\label{lem:mini}
The relation $\prec$ is acyclic.
\end{lemma}

\begin{proof}
We proceed by induction on the derivation $\Pi$.
If it starts with an asynchronous rule or an initial synchronous rule,
\ie\ its conclusion sequent is a leaf of its synchronous trunk,
acyclicity is obvious since $P\prec Q$ iff $P$ is asynchronous
and $Q$ is synchronous.
If $\Pi$ starts with $\llplus$, $\exists$ or $\mu$,
the relations $\prec$ in $\Pi$ and its subderivation
are isomorphic (only the principal formula changes)
and we conclude by induction hypothesis.
In the case of $\lltens$,
say $\Pi$ derives $\,\vdash\Gamma,\Gamma',P\lltens P'$,
only the principal formula $P\lltens P'$ has subformulas in both premises
$\,\vdash\Gamma,P$ and $\,\vdash\Gamma',P'$.
Hence there cannot be any $\prec$ relation between a formula of $\Gamma$
and one of $\Gamma'$.
In fact, the graph of $\prec$ in the conclusion is obtained by taking
the union of the graphs in the premises
and merging $P$ and $P'$ into $P\lltens P'$.
Suppose, \emph{ab absurdo}, that $\prec$ has cycles in $\Pi$,
and consider a cycle of minimal length.
It cannot involve nodes from both $\Gamma$ and $\Gamma'$:
since only $P\lltens P'$ connects those two components,
the cycle would have to go twice through it,
which contradicts the minimality of the cycle's length.
Hence the cycle must lie within
$(\Gamma,P\lltens P')$ or $(\Gamma',P\lltens P')$
but then there would also be a cycle in the corresponding premise
(obtained by replacing $P\lltens P'$ by its subformula)
which is absurd by induction hypothesis.
\end{proof}

\subsubsection{Permutation lemmas and completeness} 

We are now ready to describe the transformation of a balanced derivation
into a $\mu$-focused derivation.

\begin{definition}
We define the \emph{reachable locations} of a balanced
derivation $\Pi$, denoted by $|\Pi|$, by taking
the finitely many locations occurring at toplevel in sequents of $\Pi$,
ignoring coinvariance subderivations,
and saturating this set by adding the sublocations of
locations that do not correspond to fixed point expressions.
\end{definition}

It is easy to see that $|\Pi|$ is a finite set.
Hence $|\Pi|$, ordered by strict inclusion, is a well-founded measure
on balanced derivations.

Let us illustrate the role of reachable locations with the following
derivations:
\[ \infer[\nu]{\vdash \nu B \t, a \llpar b, \top}{
   \infer[\top]{\vdash S \t, a\llpar b, \top}{} &
   \infer{\vdash S^\perp\x, BS\x}{\vdots}}
\quad\quad\quad
   \infer[\llpar]{\vdash \nu B \t, a \llpar b, \top}{
   \infer[\top]{\vdash \nu B \t, a, b, \top}{}} \]
For the first derivation, the set of reachable locations is
$\{ \nu B \t, a \llpar b, \top, S\t, a, b \}$.
For the second one, it is $\{ \nu B \t, a\llpar b, \top, a, b \}$.
As we shall see, the focalization process may involve transforming
the first derivation into the second one, thus loosing reachable locations,
but it will never introduce new ones.
In that process, the asynchronous rule $\llpar$ is ``permuted'' under
the $\top$, \ie\ the application of $\top$ is delayed by the insertion
of a new $\llpar$ rule.
This limited kind of proof expansion does not affect reachable locations.
A more subtle case is that of ``permuting'' a fixed point rule under $\top$.
This will never happen for $\mu$. For $\nu$, the permutation
will be guided by the existing reachable locations:
if $\nu$ currently has no reachable sublocation it will be frozen,
otherwise it will be coinducted on,
leaving reachable sublocations unchanged in both cases.
The set of reachable locations is therefore
a skeleton that guides the focusing process,
and a measure which ensures its termination.

\begin{lemma} \label{lem:inst}
For any balanced derivation $\Pi$,
$|\Pi\theta|$ is balanced and $|\Pi\theta|\subseteq|\Pi|$.
\end{lemma}

\begin{proof}
By induction on $\Pi$, following the definition of $\Pi\theta$.
The preservation of balancing and reachable locations is obvious since
the rule applications in $\Pi\theta$ are the same as in $\Pi$,
except for branches that are erased by $\theta$
(which can lead to a strict inclusion of reachable locations).
\end{proof}

\begin{lemma}[Asynchronous permutability] \label{lem:async}
Let $P$ be an asynchronous formula.
If $\;\vdash \Gamma, P$ has a balanced derivation $\Pi$,
then it also has a balanced derivation $\Pi'$ where $P$ is principal in the
conclusion sequent, and such that $|\Pi'|\subseteq|\Pi|$.
\end{lemma}

\begin{proof}
Let $\Pi_0$ be the initial derivation.
We proceed by induction on its subderivations,
transforming them while respecting the balanced use of fixed points
in $\Pi_0$.
If $P$ is already principal in the conclusion, there is nothing to do.
Otherwise, by induction hypothesis
we make $P$ principal in the immediate subderivations where it occurs,
and we shall then permute the first two rules.

If the first rule ${\cal R}$
is $\top$ or a non-unifiable instance of $\neq$, there is no subderivation,
and \emph{a fortiori} no subderivation where $P$ occurs.
In that case we apply an introduction rule for $P$,
followed by ${\cal R}$ in each subderivation.
This is obvious in the case of $\llpar$, $\llwith$, $\forall$, $\bot$,
$\neq$ and $\top$ (note that there may not be any subderivation in the last
two cases, in which case the introduction of $P$ replaces ${\cal R}$).
If $P$ is a greatest fixed point that is coinducted on in $\Pi_0$,
we apply the coinduction rule with the coinvariance premise taken in $\Pi_0$,
followed by ${\cal R}$.
Otherwise, we freeze $P$ and apply ${\cal R}$.
By construction, the resulting derivation is balanced in the same way as
$\Pi_0$, and its reachable locations are contained in $|\Pi_0|$.

In all other cases we permute the introduction of $P$ under the first rule.
The permutations of MALL rules are simple. We shall not detail them, but
note that if $P$ is $\top$ or a non-unifiable $u\neq v$, permuting
its introduction under the first rule erases that rule.
The permutations involving freezing rules are obvious,
and most of the ones involving fixed points, such as ${\lltens}/\nu$,
are not surprising:
\[\infer{\vdash \Gamma,\Gamma', P\lltens P', \nu{}B\t}{
  \infer{\vdash\Gamma,P,\nu{}B\t}{
    \vdash\Gamma,P,S\t &
    \vdash BS\x ,S\x^\bot
  } &
  \vdash\Gamma',P'
  }
\quad \longrightarrow \quad
  \infer{\vdash \Gamma,\Gamma',P\lltens P', \nu{}B\t}{
  \infer{\vdash \Gamma,\Gamma',P\lltens P', S\t}{
    \vdash \Gamma,P,S\t &
    \vdash \Gamma',P'}
  &
    \vdash BS\x, S~\x^\bot
  }
\]
The ${\llwith}/\nu$ and ${\neq}/\nu$ permutations
rely on the fact that the subderivations obtained by induction hypothesis
are balanced in the same way,
with one case for freezing in all additive branches
and one case for coinduction in all branches:
\disp{
\infer{\vdash\Gamma,P\llwith P', \nu{}B\t}{
  \infer{\vdash\Gamma,P,\nu{}B\t}{
    \infer{\vdash\Gamma,P,S\t}{\Pi} &
    \infer{\vdash BS\x, S\x^\bot\vphantom{\t}}{\Theta}
  } &
  \infer{\vdash\Gamma,P',\nu{}B\t}{
    \infer{\vdash\Gamma,P',S\t}{\Pi'} &
    \infer{\vdash BS\x, S\x^\bot\vphantom{\t}}{\Theta}
  }
}
}{
\infer{\vdash\Gamma,P\llwith P', \nu{}B\t}{
  \infer{\vdash\Gamma,P\llwith P', S\t}{
    \infer{\vdash \Gamma, P, S\t}{\Pi} &
    \infer{\vdash \Gamma, P', S\t}{\Pi'}}
  &
  \infer{\vdash BS\x, (S\x)^\bot\vphantom{\t}}{\Theta}}
}
Another non-trivial case is ${\lltens}/{\neq}$ which makes use of
Lemma~\ref{lem:inst}: \disp{
  \infer{\vdash \Gamma,\Gamma',P\lltens Q, u\neq v}{
  \infer{\vdash \Gamma,P,u\neq v}{
  \Set{\infer{\vdash (\Gamma,P)\sigma}{\Pi_\sigma}}{\sigma\in csu(u\unif v)}} &
  \infer{\vdash \Gamma',Q}{\Pi'}}
}{
  \infer{\vdash \Gamma,\Gamma',P\lltens Q, u\neq v}{
    \Set{
      \infer{\vdash (\Gamma,\Gamma',P\lltens Q)\sigma}{
          \infer{\vdash (\Gamma,P)\sigma}{\Pi_\sigma} &
          \infer{\vdash (\Gamma',Q)\sigma}{\Pi'\sigma}}
      }{\sigma\in csu(u\unif v)}
  }
} A simple inspection shows that in each case,
the resulting derivation is balanced in the same way as $\Pi_0$,
and does not have any new reachable location |
the set of reachable locations may strictly decrease only
upon proof instantiation in ${\lltens}/{\neq}$,
or when permuting $\top$ and trivial instances of $\neq$ under
other rules.
\end{proof}

\begin{lemma}[Synchronous permutability] \label{lem:sync}
Let $\Gamma$ be a sequent of synchronous and frozen formulas.
If $\;\vdash\Gamma$
has a balanced derivation $\Pi$ in which $P$ is minimal for $\prec$
then it also has a balanced derivation $\Pi'$ such that
$P$ is minimal and principal in the conclusion sequent of $\Pi'$,
and $|\Pi'|=|\Pi|$.
\end{lemma}

\begin{proof}
We proceed by induction on the derivation.
If $P$ is already principal, there is nothing to do.
Otherwise, since the first rule must be synchronous,
$P$ occurs in a single subderivation.
We can apply our induction hypothesis on that subderivation:
its conclusion sequent still cannot contain any asynchronous formula by
minimality of $P$ and,
by Proposition~\ref{prop:mini_subform}, $P$ is still minimal in it.
We shall now permute the first two rules, which are both synchronous.
The permutations of synchronous MALL rules are simple.
As for $\llone$, there is no permutation involving $=$.
The permutations for $\mu$ follow the same geometry as those for $\exists$
or $\llplus$. For instance, ${\lltens}/{\mu}$ is as follows:
\disp{
  \infer[\lltens]{\vdash \Gamma, \Gamma', P\lltens P', \mu B \t}{
    \vdash \Gamma,P &
    \infer[\mu]{\vdash \Gamma',P',\mu B\t}{\vdash \Gamma',P', B(\mu B)\t}}
}{
  \infer[\mu]{\vdash \Gamma, \Gamma', P\lltens P', \mu B \t}{
  \infer[\lltens]{\vdash \Gamma, \Gamma', P\lltens P', B(\mu B) \t}{
    \vdash \Gamma,P &
    \vdash \Gamma',P', B(\mu B)\t}}
}
All those permutations preserve $|\Pi|$.
Balancing and minimality are obviously preserved, respectively
because asynchronous rule applications and
the leaf sequents of the synchronous trunk are left unchanged.
\end{proof}

\begin{theorem}
The $\mu$-focused system is sound and complete with respect to \mumall:
If $\;\vdash\Uparrow\Gamma$ is provable, then $\;\vdash\Gamma$
  is provable in \mumall.
If $\;\vdash\Gamma$ has a quasi-finite \mumall\ derivation,
  then $\;\vdash\Uparrow\Gamma$ has a (focused) derivation.
\end{theorem}

\begin{proof}
For soundness, we observe that an unfocused derivation can be obtained
simply from a focused one by erasing focusing annotations
and removing switching rules
($\;\vdash\Delta\Uparrow\Gamma$ gives $\;\vdash\Delta,\Gamma$ and
 $\;\vdash\Gamma\Downarrow P$ gives $\;\vdash \Gamma,P$).
To prove completeness, we first obtain a balanced derivation using
Lemma~\ref{lem:balance}. Then, we use permutation lemmas to reorder rules
in the freezing-annotated derivation so that we
can translate it to a $\mu$-focused derivation.
Formally, we first use an induction on the height of the derivation.
This allows us to assume that coinvariance proofs can be focused,
which will be preserved since those subderivations are left untouched
by the following transformations.
Then, we prove simultaneously the following two statements:
\begin{enumerate}
\item
  If $\;\vdash\Gamma,\Delta$ has a balanced derivation $\Pi$,
  where $\Gamma$ contains only synchronous and frozen formulas,
  then $\;\vdash\Gamma\Uparrow\Delta$ has a derivation.
\item
  If $\vdash\Gamma,P$ has a balanced derivation $\Pi$
  in which $P$ is minimal for ${\prec}$,
  and there is no asynchronous formula in its conclusion,
  then there is a focused derivation of $\vdash\Gamma\Downarrow P$.
\end{enumerate}
We proceed by well-founded induction on $|\Pi|$
with a sub-induction on the number of non-frozen formulas in the
conclusion of $\Pi$.
Note that (1) can rely on (2) for the same $|\Pi|$ but
(2) only relies on strictly smaller instances of (1) and (2).
\begin{enumerate}
\item
If there is any, pick \emph{arbitrarily} an asynchronous formula $P$,
and apply Lemma \ref{lem:async} to make it principal in the first rule.
The subderivations of the obtained proof can be focused,
either by the outer induction in the case of coinvariance proofs,
or by induction hypothesis (1) for the other subderivations:
if the first rule is a freezing, then the reachable locations of the
subderivation and the full derivation are the same, but there is one
less non-frozen formula;
with all other rules, the principal location is consumed
and reachable locations strictly decrease.
Finally, we obtain the full focused derivation by composing those
subderivations using the focused equivalent of the rule applied on $P$.

When there is no asynchronous formula left, we have shown
in Lemma~\ref{lem:mini} that there is a minimal synchronous formula $P$
in $\Gamma,\Delta$.
Let $\Gamma'$ denote $\Gamma,\Delta$ without $P$.
Using switching rules,
we build the derivation of $\vdash\Gamma\Uparrow\Delta$
from $\vdash\Gamma'\Downarrow P$,
the latter derivation being obtained by (2) with $\Pi$ unchanged.

\item
Given such a derivation,
we apply Lemma~\ref{lem:sync} to make the formula $P$ principal.
Each of its subderivations has strictly less reachable locations,
and a conclusion of the form $\;\vdash\Gamma'', P'$
where $P'$ is a subformula of $P$
that is still minimal by Proposition~\ref{prop:mini_subform}.
For each of those we build a focused derivation of
$\;\vdash\Gamma''\Downarrow P'$:
if the subderivation still has no asynchronous formula in its conclusion,
we can apply induction hypothesis (2);
otherwise $P'$ is asynchronous by minimality
and we use the switching rule releasing focus on $P'$,
followed by a derivation of $\vdash\Gamma''\Uparrow P'$
obtained by induction hypothesis (1).
Finally, we build the expected focused derivation from those
subderivations by using the focused equivalent of the
synchronous freezing-annotated rule applied on $P$.
\end{enumerate}
\vspace{-0.6cm}\end{proof}

In addition to a proof of completeness, we have actually defined
a transformation that turns any unfocused proof into a focused one.
This process is in three parts:
first, balancing a quasi-finite unfocused derivation;
then, applying rule permutations on unfocused balanced derivations;
finally, adding focusing annotations to obtain a focused proof.
The core permutation process allows to reorder asynchronous rules
arbitrarily, establishing that, from the proof search viewpoint,
this phase consists of inessential non-determinism as usual,
except for the choice concerning greatest fixed points.

In the absence of fixed points, balancing disappears,
and the core permutation process is known to preserve the essence of
proofs, \ie\ the resulting derivation behaves the same as the original
one with respect to cut elimination.
A natural question is whether our process enjoys the same property.
This is not a trivial question,
because of the merging of coinvariants which is performed during balancing,
and to a smaller extent the unfoldings also performed in that process.
We conjecture that those new transformations, which are essentially
loop fusions and unrolling, do also preserve the
cut elimination behavior of proofs.

A different proof technique for establishing completeness
consists in focusing a proof by cutting it against focused 
identities~\cite{laurent04unp,chaudhuri08jar}.
The preservation of the essence of proofs is thus an immediate
corollary of that method.
However, the merging of coinvariants cannot be performed through
cut elimination, so this proof technique (alone) cannot be used
in our case.



\subsection{The $\nu$-focused system}
\label{sec:nufoc}

While the classification of $\mu$ as synchronous and $\nu$ as
asynchronous is rather satisfying and coincides with several other observations,
that choice does not seem to be forced from the focusing point of view alone.
After all, the $\mu$ rule also commutes with all other rules.
It turns out that one can design a $\nu$-focused system
treating $\mu$ as asynchronous and $\nu$ as synchronous,
and still obtain completeness.
That system is obtained from the previous one by changing only
the rules working on fixed points:
\[ \renewcommand\arraystretch{2}\begin{array}{cp{0.3cm}c}
\infer{\vdash\Gamma\Uparrow\mu{}B\t,\Delta}{
       \vdash\Gamma\Uparrow B(\mu{}B)\t,\Delta}
& &
\infer{\vdash\Gamma\Uparrow\mu{}B\t,\Delta}{
   \vdash\Gamma,(\mu{}B\t)^*\Uparrow\Delta}
\\
\infer{\vdash\Gamma\Downarrow\nu{}B\t}{
       \vdash\Gamma\Downarrow S\t & \vdash\Uparrow BS\x, (S\x)^\bot}
& &
\infer{\vdash(\mu\B\t)^*\Downarrow\nu{}B\t}{}
\end{array} \]

Note that a new asynchronous phase must start in the coinvariance premise:
asynchronous connectives in $BS\x$ or $(S\x)^\perp$ might have to be
introduced before a focus can be picked.
For example, if $B$ is $(\lambda p.~ a^\perp \llpar \bot)$ and
$S$ is $a^\perp$, one cannot focus on $S^\perp$ immediately
since $a^\perp$ is not yet available for applying the $init$;
conversely, if $B$ is $(\lambda p.~ a)$ and $S$ is
$a\lltens\llone$, one cannot focus on $BS$ immediately.

\begin{theorem}
The $\nu$-focused system is sound and complete with respect to \mumall:
If $\;\vdash\Uparrow\Gamma$ is provable, then $\;\vdash\Gamma$
  is provable in \mumall.
If $\;\vdash\Gamma$ has a quasi-finite \mumall\ derivation,
  then $\;\vdash\Uparrow\Gamma$ has a (focused) derivation.
\end{theorem}

\begin{proof}[sketch]
The proof follows the same argument as for the $\mu$-focused system.
We place ourselves in a logic with explicit freezing annotations
for atoms and least fixed points,
and define balanced annotated derivations, requiring
that any instance of a least fixed point is used consistently throughout
a derivation, either always frozen or always unfolded;
together with the constraint on its sublocations, this means that
a least fixed point has to be unfolded the same number of times in
all (additive) branches of a derivation.
We then show that any quasi-finite annotated derivation can be balanced;
the proof of Lemma~\ref{lem:balance} can be adapted easily.
Finally, balanced derivations can be transformed into focused
derivations using permutations: the focalization graph technique
extends trivially, the new asynchronous permutations involving the
$\mu$ rule are simple thanks to balancing, and the new synchronous
permutations involving the $\nu$ rule are trivial.
\end{proof}

This flexibility in the design of a focusing system is unusual.
It is not of the same nature as the arbitrary bias assignment that
can be used in Andreoli's system: atoms are non-canonical, and the bias
can be seen as a way to indicate what is the synchrony of the formula
that a given atom might be instantiated with. But our fixed points
have a fully defined logical meaning, they are canonical.
The flexibility highlights the fact that focusing is a somewhat shallow
property, accounting for local rule permutability
independently of deeper properties such as positivity.
Although we do not see any practical use of such flexibility,
it is not excluded that one is discovered in the future,
like with the arbitrary bias assignment on atoms in Andreoli's original 
system.

It is not possible to treat both least and greatest fixed points
as asynchronous. Besides creating an unclear situation regarding $init$,
this would require to balance both kinds of fixed points, which is
impossible. In $\mu$-focusing, balancing greatest fixed points unfolds
least fixed points as a side effect, which is harmless since there is
no balancing constraint on those. The situation is symmetric in
$\nu$-focusing. But if both least and greatest fixed points
have to be balanced, the two unfolding processes interfere
and may not terminate anymore.
It is nevertheless possible to consider mixed bias assignments
for fixed point formulas, if the $init$ rule is restricted accordingly.
We would consider two logically identical variants
of each fixed point: $\mu^+$ and $\nu^+$ being treated synchronously,
$\mu^-$ and $\nu^-$ asynchronously, and the axiom rule would be
restricted to dual fixed points of opposite bias:
\[ \infer{\vdash (\mu B\t)^+, (\nu \B \t)^-}{} \quad
   \infer{\vdash (\nu B\t)^+, (\mu \B \t)^-}{} \]
This restriction allows to perform simultaneously the balancing of
$\nu^-$ and $\mu^-$ without interferences. Further, we conjecture
that a sound and complete focused proof system for that logic would be
obtained by superposing
the $\mu$-focused system for $\mu^+$, $\nu^-$ and the $\nu$-focused
system for $\mu^-$, $\nu^+$.

\subsection{Application to \muLJL} \label{sec:foc_mulj}

The examples of Section~\ref{sec:mumall_examples} showed that despite
its simplicity and linearity, \mumall\ can be related to a more
conventional logic.
In particular we are interested in drawing some connections with
\muLJ~\cite{baelde08phd},
the extension of LJ with least and greatest fixed points.
In the following, we show a simple first step to this program,
in which we capture a rich fragment of \muLJ{}
even though \mumall\ does not have exponentials.
In this section, we make use of the properties of negative formulas
(Definition~\ref{def:connectives}), which has two important consequences:
we shall use the $\mu$-focused system, and could not use the
alternative $\nu$-focused one, since it does not agree with the 
classification;
moreover, we shall work in a fragment of \mumall\ without atoms,
since atoms do not have any polarity.

We have observed (Proposition~\ref{prop:struct}) that structural rules are 
admissible for negative formulas of \mumall.
This property allows us to obtain a 
faithful encoding of a fragment of \muLJ\ in \mumall{}
despite the absence of exponentials.
The encoding must be organized so that formulas appearing on
the left-hand side of intuitionistic sequents can be encoded positively
in \mumall.
The only connectives allowed to appear negatively shall thus be
$\wedge$, $\vee$, $=$, $\mu{}$ and $\exists$.
Moreover, the encoding must commute with negation,
in order to translate the (co)induction rules correctly.
This leaves no choice in the following design.

\begin{definition}[$\H$, $\G$, \muLJL]
The fragments $\H$ and $\G$ are given by the following grammar:
{\allowdisplaybreaks\begin{eqnarray*}
\G &::=& \G\wedge \G \| \G \vee \G \| s=t \| \exists x. \G x \|
         \mu{}(\lambda{}p\lambda\x.\G p \x)\t \| p \t
        \\
  &\|& \forall{}x. \G x \| \H \supset \G \|
       \nu{}(\lambda{}p\lambda\x.\G p \x)\t \\
\H &::=& \H\wedge \H \| \H \vee \H \| s=t \|
         \exists{}x. \H x \|
         \mu{}(\lambda{}p\lambda\x.\H p \x)\t \| p \t
\end{eqnarray*}}
The logic \muLJL\ is the restriction of \muLJ\ to sequents
where all hypotheses are in the fragment $\H$,
and the goal is in the fragment $\G$.
This implies a restriction of induction and coinduction rules to
(co)invariants in $\H$.

Formulas in $\H$ and $\G$ are translated in \mumall\ as follows:
\[  \begin{array}{rcl}
 \enc{P\wedge Q} &\stackrel{def}{=}& \enc{P}\lltens\enc{Q} \\
 \enc{P\vee Q}   &\stackrel{def}{=}& \enc{P}\llplus\enc{Q} \\
 \enc{s=t} &\stackrel{def}{=}& s=t \\
 \enc{\exists x.Px} &\stackrel{def}{=}& \exists x. \enc{Px} \\
 \enc{\mu{}B\t} &\stackrel{def}{=}& \mu\enc{B}\t \\
\end{array} \qquad
\begin{array}{rcl}
 \enc{\forall x.Px} &\stackrel{def}{=}& \forall x. \enc{Px} \\
 \enc{\nu{}B\t} &\stackrel{def}{=}& \nu\enc{B}\t \\
 \enc{P\supset Q} &\stackrel{def}{=}& \enc{P} \llimp \enc{Q} \\
 \enc{\lambda p\lambda\x. B p \x} &\stackrel{def}{=}&
         \lambda p\lambda\x.\enc{B p \x} \\
 \enc{p\t} &\eqdef& p\t
\end{array} \]
\end{definition}



For reference, the rules of \muLJL\ can be obtained simply from
the rules of the focused system presented in Figure~\ref{fig:muLJL},
by translating $\Gamma;\Gamma'\vdash P$ into $\Gamma,\Gamma'\vdash P$,
allowing both contexts to contain any $\H$ formula
and reading them as sets to allow contraction and weakening.

\begin{proposition} \label{prop:01}
Let $P$ be a $\G$ formula, and $\Gamma$ a context of $\H$ formulas.
Then $\Gamma\vdash P$ has a quasi-finite \muLJL\ derivation if and only if
$\;\vdash [\Gamma]^\perp, [P]$ has a quasi-finite \mumall\ derivation,
under the restrictions that (co)invariants
in \mumall\ are of the form $\lambda\x.~ [S\x]$ for $S\x\in\enc{\H}$.
\end{proposition}

\begin{proof}
The proof transformations are simple and compositional.
The induction rule corresponds to the $\nu$ rule for $(\mu{}[B]\t)^\bot$,
the proviso on invariants allowing the translations:
\[ \infer{\Gamma, \mu B \t \vdash G}{
          \Gamma,S\t\vdash G &
          B S \x \vdash S\x}
    \quad \longleftrightarrow \quad
   \infer{\vdash [\Gamma]^\perp, \nu \overline{[B]} \t, [G]}{
          \vdash [\Gamma]^\perp, [S]^\perp\t, [G] &
          \vdash \overline{[B]}[S]^\perp \x, [S]\x}
\]
Here, $[S]$ stands for $\lambda\x.~ [S\x]$,
and the validity of the translation relies on the fact that
$\overline{[B]}[S]^\perp\x$ is the same as $[BS\x]^\perp$.
Note that $BS$ belongs to $\H$ whenever both $S$ and $B$ are in $\H$,
meaning that for any $p$ and $\x$, $Bp\x \in \H$.
The coinduction rule is treated symmetrically,
except that in this case $B$ can be in $\G$:
\[ \infer{\Gamma \vdash \nu B \t}{\Gamma \vdash S \t &
          S\x\vdash BS\x}
   \quad\longleftrightarrow\quad
   \infer{\vdash \enc{\Gamma}^\perp, \nu\enc{B}\t}{
          \vdash \enc{\Gamma}^\perp, \enc{S}\t &
          \vdash \enc{S}^\perp\x, \enc{B}\enc{S}\x} \]
In order to restore the additive behavior of some intuitionistic
rules (\emph{e.g.}, $\wedge{}R$) and translate the structural rules,
we can contract and weaken the negative \mumall\ formulas corresponding
to encodings of $\H$ formulas.
\end{proof}

Linear logic provides an appealing proof theoretic setting because of
its emphasis on dualities and of its clear separation of concepts
(additive \vs{}multiplicative, asynchronous \vs{}synchronous).  Our experience
is that \mumall{} is a good place to study focusing in the presence of
least and greatest fixed point connectives.  To get similar results for
\muLJ, one can either work from scratch entirely
within the intuitionistic framework or use an encoding into linear logic.
Given a mapping from intuitionistic to linear logic, and a complete focused
proof system for linear logic, one can often build a complete
focused proof-system for intuitionistic logic.
\[
\xymatrix
{
 \vdash F \ar@{.>}[d]\ar[r] & \ar[d] \vdash [F] \\
 \vdash \Uparrow F  & \ar[l]\vdash \Uparrow [F] \\
}
\]
The usual encoding of intuitionistic logic into linear logic involves
exponentials, which can damage focusing structures by causing both
synchronous and asynchronous phases to end.
Hence, a careful study of the polarity of linear connectives must
be done (cf. \cite{danos93kgc,liang07csl}) in order to minimize the
role played by the exponentials in such encodings. Here, as a result of
Proposition~\ref{prop:01}, it is possible to get a complete focused
system for \muLJL\ that inherits exactly the strong structure of linear
$\mu$-focused derivations.

This system is presented in Figure~\ref{fig:muLJL}.
Its sequents have the form $\Gamma;\Gamma'\vdash P$ where
$\Gamma'$ is a multiset of synchronous formulas (fragment $\H$)
and the set $\Gamma$ contains frozen least fixed points
in $\H$.
First, notice that accordingly with the absence of exponentials
in the encoding into linear logic, there is no structural rule.
The asynchronous phase takes place on sequents where $\Gamma'$ is not empty.
The synchronous phase processes sequents of the form
$\Gamma ; \vdash P$, where the focus is without any ambiguity on $P$.
It is impossible to introduce any connective on the right when 
$\Gamma'$ is not empty.
As will be visible in the following proof of completeness,
the synchronous phase in \muLJL\ does not correspond exactly to
a synchronous phase in \mumall: it contains rules that are translated
into asynchronous \mumall\ rules, namely implication, universal
quantification and coinduction.
We introduced this simplification in order to simplify the presentation,
which is harmless since there is no choice in refocusing afterwards.

\begin{figure}[htpb]
\begin{center}
\[
\begin{array}{c}
\mbox{Asynchronous phase}
\\[6pt]
\infer{\Gamma;\Gamma', P\wedge Q \vdash R}{
       \Gamma;\Gamma', P, Q \vdash R}
\quad
\infer{\Gamma;\Gamma', P\vee Q \vdash R}{
       \Gamma;\Gamma', P\vdash R &
       \Gamma;\Gamma', Q\vdash R}
\\[6pt]
\infer{
  \Gamma;\Gamma', \exists{}x. P x \vdash Q}{
  \Gamma;\Gamma', P x \vdash Q}
\\[6pt]
\infer{\Gamma;\Gamma',  s = t \vdash P}{
    \{ (\Gamma;\Gamma' \vdash P)\theta :
      \theta\in csu(s\unif t) \} }
\\[6pt]
\infer{\Gamma;\Gamma',\mu{}B\t \vdash P}{
       \Gamma, \mu{}B\t;\Gamma'\vdash P}
\quad
\infer{\Gamma;\Gamma',\mu{}B\t \vdash P}{
  S \in \H &
  \Gamma;\Gamma', S\t \vdash P &
  ;BS\x \vdash S\x
}
\\ ~
\\
\mbox{Synchronous phase}
\\[6pt]
\infer{\Gamma;\vdash A\wedge B}{\Gamma;\vdash A & \Gamma;\vdash B}
\quad
\infer{\Gamma;\vdash A_0\vee A_1}{\Gamma;\vdash A_i}
\quad
\infer{\Gamma;\vdash A\supset B}{\Gamma; A \vdash B}
\\[6pt]
\infer{\Gamma;\vdash t=t}{}
\quad
\infer{\Gamma;\vdash \exists{}x. P x}{\Gamma;\vdash P t}
\quad
\infer{\Gamma;\vdash \forall{}x. P x}{\Gamma;\vdash P x}
\\[6pt]
\infer{\Gamma, \mu{}B\t;\vdash \mu{}B\t}{}
\quad
\infer{\Gamma;\vdash \mu{}B\t}{\Gamma;\vdash B(\mu{}B)\t}
\\[6pt]
\infer{\Gamma;\vdash \nu{}B\t}{
  S \in \H &
  \Gamma;\vdash S\t &
  ;S\x \vdash BS\x
}
\end{array}
\]
\end{center}

\caption{Focused proof system for \muLJL} \label{fig:muLJL}
\end{figure}

\begin{proposition}[Soundness and completeness]
The focused proof system for \muLJL\ is sound and complete
with respect to \muLJL:
any focused \muLJL\ derivation of $\Gamma';\Gamma\vdash P$
can be transformed into a \muLJL\ derivation of $\,\Gamma',\Gamma\vdash P$;
any quasi-finite \muLJL\ derivation of $\,\Gamma\vdash P$
can be transformed into a \muLJL\ derivation of $\cdot\;;\Gamma\vdash P$.
\end{proposition}

\begin{proof}
The soundness part is trivial: unfocused \muLJL\ derivations can be
obtained from focused derivations by removing focusing annotations.
Completeness is established using the translation to linear logic
as outlined above.
Given a \muLJL\ derivation of $\Gamma\vdash P$,
we obtain a \mumall\ derivation of $[\Gamma]\vdash [P]$ using
Proposition~\ref{prop:01}.
This derivation inherits quasi-finiteness,
so we can obtain a $\mu$-focused \mumall\ derivation
of $\vdash \Uparrow [\Gamma]^\perp, [P]$.
All sequents of this derivation correspond to encodings of \muLJL\ sequents,
always containing a formula that corresponds to the right-hand side
of \muLJL\ sequents.
By permutability of asynchronous rules,
we can require that asynchronous rules are applied on right-hand side
formulas only after any other asynchronous rule in our $\mu$-focused derivation.
Finally, we translate that focused derivation into a focused
\muLJL\ derivation.
Let $\Gamma$ be a multiset of least fixed points in $\H$,
$\Gamma'$ be a multiset of $\H$ formulas,
and $P$ be a formula in $\G$.
\begin{enumerate}
\item
  If there is a $\mu$-focused derivation of
  $\vdash ([\Gamma]^\perp)^* \Uparrow [\Gamma']^\perp, [P]$
  or $\vdash ([\Gamma]^\perp)^*,  [P] \Uparrow [\Gamma']^\perp$
  then there is a focused \muLJL\ derivation of
  $\Gamma;\Gamma'\vdash P$.
\item
  If there is a $\mu$-focused derivation of
  $\vdash ([\Gamma]^\perp)^* \Downarrow [P]$
  then there is a focused \muLJL\ derivation of $\Gamma;\vdash P$.
\end{enumerate}
We proceed by a simultaneous induction on the $\mu$-focused derivation.
\begin{enumerate}
\item
  Since $[P]$ is the only formula that may be synchronous,
  the $\mu$-focused derivation can only start with two switching rules:
  either $[P]$ is moved to the left of the arrow, in which case
  we conclude by induction hypothesis (1),
  or $\Gamma'$ is empty and $[P]$ is focused on, in which case
  we conclude by induction hypothesis (2).

  If the $\mu$-focused derivation starts with a logical rule,
  we translate it into a \muLJL\ focused rule before concluding by
  induction hypothesis.
  For instance, the $\llwith$ or $\neq$ rule, which can only be
  applied to a formula in $[\Gamma']^\perp$, respectively correspond
  to a left disjunction or equality rule.
  Other asynchronous \mumall\ rules translate differently depending
  on whether they are applied on $[\Gamma]^\perp$ or $[P]$:
  $\llpar$ can correspond to left conjunction or right implication;
  $\nu$ to left $\mu$ (induction) or right $\nu$ (coinduction);
  $\forall$ to left $\exists$ or right $\forall$.
  Note that in the case where $[P]$ is principal, the constraint on
  the order of asynchronous rules means that $\Gamma$ is empty,
  which is required by synchronous \muLJL\ rule.
  Finally, freezing is translated by the \muLJL\ rule
  moving a least fixed point from $\Gamma'$ to $\Gamma$.

\item
  If the $\mu$-focused derivation starts with the switching rule releasing
  focus from $[P]$ we conclude by induction hypothesis (1).
  Otherwise it is straightforward to translate the first rule and
  conclude by induction hypothesis (2):
  $\lltens$, $\llplus$, ${=}$, $\exists$ and $\mu$
  respectively map to the right rules for
  $\wedge$, $\vee$, ${=}$, $\exists$ and $\mu$.

  Note, however, that the tensor rule splits frozen formulas
  in $([\Gamma]^\perp)^*$, while the right conjunction rule of \muLJL{}
  does not. This is harmless because weakening is obviously admissible
  for the frozen context of \muLJL\ focused derivations.
  This slight mismatch means that we would still have a complete
  focused proof system for \muLJL\ if we enforced a linear use of
  the frozen context. We chose to relax this constraint as it does not
  make a better system for proof search.
\end{enumerate}
\vspace{-0.5cm}\end{proof}

Although \muLJL\ is only a small fragment of \muLJ,
it catches many interesting and useful problems.  For example, 
any Horn-clause specification can be expressed in $\H$ as a least
fixed point, and theorems that state properties such as totality or
functionality of predicates defined in this manner are in $\G$.
Theorems that state more model-checking properties, of the form
$\forall x.~ P~x\supset Q~x$, are in $\G$ provided
that $P$ and $Q$ are in $\H$.
Further, implications can be chained through a greatest fixed point
construction, which allows to specify various relations on
process behaviors.
For example, provided that one-step transitions $u\ra v$ are specified
in $\H$, simulation is naturally expressed in $\G$ as follows:
\[ \nu S \lambda x \lambda y.~
     \forall x'.~ x \ra x' \supset \exists y'.~ y \ra y' \wedge S~x'~y' \]
Finally, the theorems about natural numbers presented in
Section~\ref{sec:mumall_examples} are also in $\G$.
Although a formula in $\G$ can \emph{a priori} be a theorem in \muLJ{}
but not in \muLJL,
we have shown~\cite{baelde09tableaux} that \muLJL{}
is complete for inclusions of non-deterministic finite automata |
${\cal A}\subseteq {\cal B}$ being expressed naturally as
$\forall w.~ [{\cal A}]w \supset [{\cal B}]w$.


Interestingly, the \muLJL\ fragment has already been identified in
LINC~\cite{tiu05eshol} and the Bedwyr system~\cite{baelde07cade}
implements a proof-search strategy for it that is complete for finite
behaviors, \ie\ proofs without (co)induction nor axiom rules,
where a fixed point has to be treated in a finite number of unfoldings.
This strategy coincides with the focused
system for \muLJL, where the finite behavior restriction corresponds
to dropping the freezing rule,
obtaining a system where proof search consists in
eagerly eliminating any left-hand side (asynchronous) formula
before working on the goal (right-hand side),
without ever performing any contraction or weakening.
The logic \muLJ\ is closely related to LINC, the main difference being
the generic quantifier $\nabla$, which allows to specify and reason about
systems involving variable binding,
such as the $\pi$-calculus~\cite{tiu05concur}.
But we have shown~\cite{baelde08lfmtp} that $\nabla$ can be added
in an orthogonal fashion in \muLJ\ (or \mumall)
without affecting focusing results.
