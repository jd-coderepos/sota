\documentclass[submission,copyright,creativecommons]{eptcs}
\providecommand{\event}{Festschrift Symposium for Dave Schmidt} 

\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{yfonts}
\usepackage{galois}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{stmaryrd}

\lstset{
language={Java},
mathescape=true,
flexiblecolumns=true,
morekeywords={call,method,var,assert,share,unshare,acquire,release,fork,join,free,invariant,requires,ensures,acc,rd,old},
basicstyle=\sffamily,
moredelim=[is][\itshape]{@}{@},
stepnumber=1,
numbersep=2pt}


\newcommand{\Sample}{\ensuremath{\mathsf{Sample}}}

\newcommand{\goodgap}{\hspace{1.536pt}}


\newcommand{\Java}{\ensuremath{\mathsf{Java}}}
\newcommand{\real}{\ensuremath{\mathbb{R}}}
\newcommand{\integer}{\ensuremath{\mathbb{Z}}}
\newcommand{\naturals}{\ensuremath{\mathbb{N}}}
\newcommand{\Scala}{\ensuremath{\mathsf{Scala}}}
\newcommand{\IVSF}{\ensuremath{\mathsf{IVSF}}}
\newcommand{\TSF}{\ensuremath{\mathsf{TSF}}}
\newcommand{\CSharp}{\ensuremath{\mathsf{C\#}}}
\newcommand{\FSharp}{\ensuremath{\mathsf{F\#}}}

\newcommand{\variables}{\ensuremath{\mathsf{Vars}}}

\newcommand{\lfp}[2]{\ensuremath{\mathit{lfp}^{#1}_{#2} \hspace{2pt}}}
\newcommand{\parts}[1]{\ensuremath{\wp(#1)}}
\newcommand{\dom}[1]{\ensuremath{\cfunction{dom}(#1)}}
\newcommand{\statement}[1]{\ensuremath{\mathsf{#1}}}
\newcommand{\funzione}[2]{\ensuremath{#1 \rightarrow#2}}
\newcommand{\pair}[2]{\ensuremath{#1 \times #2}}
\newcommand{\cartesianproduct}[2]{\ensuremath{#1 \times #2}}
\newcommand{\reducedproduct}[2]{\ensuremath{#1 \varotimes #2}}
\newcommand{\true}{\cel{true}}
\newcommand{\false}{\cel{false}}
\newcommand{\booltop}{\cel{\top_B}}
\newcommand{\reducefunction}{\afunction{red}}
\newcommand{\gettype}{\afunction{getType}}
\newcommand{\getstatictype}[1]{\cfunction{\sttype}(#1)}
\newcommand{\sttype}{statictype}
\newcommand{\abstractn}{abstract}
\newcommand{\abstractfunction}[1]{\afunction{\abstractn}(#1)}


\newcommand{\sequence}[1]{\ensuremath{#1^*}}
\newcommand{\sem}[1]{\ensuremath{\llbracket \mathtt{#1} \rrbracket}}
\newcommand{\semanticanome}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\semantica}[2]{\ensuremath{\semanticanome{#1}\sem{#2}}}



\newcommand{\cset}[1]{\ensuremath{\mathsf{#1}}}
\newcommand{\ctrace}[1]{\ensuremath{\trace{{\cset{#1}}}}}
\newcommand{\cel}[1]{\ensuremath{\mathsf{#1}}}
\newcommand{\cjoin}{\ensuremath{\cup}}
\newcommand{\cmeet}{\ensuremath{\cap}}
\newcommand{\corder}{\ensuremath{\subseteq}}
\newcommand{\cbot}{\ensuremath{\emptyset}}
\newcommand{\ctop}[1]{\cset{#1}}
\newcommand{\cfunction}[1]{\ensuremath{\mathit{#1}}}
\newcommand{\csemantics}[2]{\ensuremath{\semantica{#1}{#2}}}



\newcommand{\adomain}{\ensuremath{\mathcal{H}}} \newcommand{\aset}[1]{\cset{\overline{#1}}}
\newcommand{\ael}[1]{\cel{\overline{#1}}}
\newcommand{\alub}{\ensuremath{\cup^\mathcal{H} }} \newcommand{\aglb}{\ensuremath{\cap^\mathcal{H} }} \newcommand{\awidening}{\ensuremath{\nabla_{\mathcal{H} }}} \newcommand{\aorder}{\ensuremath{\subseteq^\mathcal{H}}} \newcommand{\abot}{\ensuremath{\bot^\mathcal{H} }} \newcommand{\abtop}{\ensuremath{\top^\mathcal{H} }} \newcommand{\asemantics}[2]{\semantica{\afunction{\semanticanome{#1}}}{#2}}
\newcommand{\atrace}[1]{\ensuremath{\trace{#1}}}
\newcommand{\afunction}[1]{\ensuremath{\overline{\mathit{#1}}}}



\newcommand{\gas}{\ensuremath{\cset{\mathcal{REMOVE}}}}



\newcommand{\avaluename}{\ensuremath{\afunction{value}}}
\newcommand{\avalue}[1]{\ensuremath{\avaluename(#1)}}

\newcommand{\avariableindexname}{\ensuremath{\afunction{varIndex}}}
\newcommand{\avariableindex}[1]{\ensuremath{\avariableindexname(#1)}}
\newcommand{\aval}{\ensuremath{\aset{Val}}}

\newcommand{\firstdomain}{\aset{A}}
\newcommand{\seconddomain}{\aset{B}}
\newcommand{\concretedomain}{\cset{C}}
\newcommand{\cartesiandomain}{\textswab{C}}
\newcommand{\powerdomain}{\textswab{P}}

\newcommand{\firstsemantics}{\semanticanome{S}_\firstdomain}
\newcommand{\secondsemantics}{\semanticanome{S}_\seconddomain}
\newcommand{\concretesemantics}{\semanticanome{S}_\concretedomain}
\newcommand{\cartesiansemantics}{\semanticanome{S}_\cartesiandomain}

\newcommand{\firstsemanticsapplication}[1]{\firstsemantics\sem{#1}}
\newcommand{\secondsemanticsapplication}[1]{\secondsemantics\sem{#1}}
\newcommand{\concretesemanticsapplication}[1]{\concretesemantics\sem{#1}}
\newcommand{\cartesiansemanticsapplication}[1]{\cartesiansemantics\sem{#1}}
 
\title{A Survey on Product Operators in Abstract Interpretation}
\author{Agostino Cortesi
\institute{Ca' Foscari University\\ Venice, Italy}
\email{cortesi@dsi.unive.it}
\and
Giulia Costantini
\institute{Ca' Foscari University\\ Venice, Italy}
\email{costantini@dsi.unive.it}
\and
Pietro Ferrara
\institute{ETH \\Zurich, Switzerland}
\email{pietro.ferrara@inf.ethz.ch}
}
\def\titlerunning{Product Operators in Abstract Interpretation}
\def\authorrunning{A. Cortesi, G. Costantini \& P. Ferrara}
\begin{document}
\maketitle

\begin{abstract}
The aim of this paper is to provide a general overview of the product operators introduced in the literature as a tool to enhance the analysis accuracy in the Abstract Interpretation framework.  In particular we focus on the Cartesian and reduced products, as well as on the reduced cardinal power, an under-used technique whose features deserve to be stressed for their potential impact in practical applications. 
\end{abstract}

\section{Introduction}
Abstract interpretation \cite{CC79} has been widely applied as a general technique for the sound approximation of the semantics of computer programs. In particular, abstract domains (to represent data) and semantics (to represent data operations) approximate the concrete computation. When analyzing a program and trying to prove some property on it, the quality of the result is determined by the abstract domain choice. There is always a trade-off between accuracy and efficiency of the analysis. During the years, various abstract domains have been developed. An interesting feature of the abstract interpretation theory is the possibility to combine different domains in the same analysis. In fact, the abstract interpretation framework offers some standard ways to compose abstract domains, ensuring the preservation of the theoretical properties needed to guarantee the soundness of the analysis. These compositional methods are called \emph{domain refinements}. A systematic treatment of abstract domain refinements has been given in \cite{FGR96, GR97}, where a generic refinement is defined to be a lower closure operator on the lattice of abstract interpretations of a given concrete domain. These kinds of operators on abstract domains provide high-level facilities to tune a program analysis in terms of accuracy and cost. Two of the most well-known domain refinements are the \emph{disjunctive completion} \cite{CC79, CC94, FR99, GR98, J97} and the \emph{reduced product} \cite{CC79}, but they are not the only ones. The reduced product can be seen as the most precise refinement of the simple Cartesian product. Moreover, the reduced cardinal power is introduced by \cite{CC79}. While the other domain refinements have been, since their introduction, widely used and explored, the reduced cardinal power has seen definitely less further developments since 1979, with the exception of \cite{GR99}. To verify our assertion, we looked for the number of scientific citations (in the abstract interpretation context) to some domain refinements in Google Scholar. We depicted the results of this search in Figure \ref{fig:citations}. In particular, we focused on the Cartesian product, the reduced product and the reduced cardinal power. Throughout the years, the number of citations increases in all three cases, but the absolute numbers are very different: just consider that the total citations of \textquotedblleft Cartesian product\textquotedblright\ are 964, while the ones to \textquotedblleft reduced cardinal power\textquotedblright\ are only 38. 

\begin{center}
\begin{figure}
\includegraphics[scale=0.8]{citations.png}
\label{fig:citations}
\caption{Number of annual citations since 1979, for the searches "reduced cardinal power", "reduced product" and "cartesian product" (in the abstract interpretation field)}
\end{figure}
\end{center}

However, we think that the reduced cardinal power refinement has a potential which has not been completely exploited yet. Consider, for example, that such refinement is used by ASTR\'EE\cite{CCFMMMR05}, the well-known static program analyzer that proves the absence of run-time errors in safety-critical embedded applications written or automatically generated in C. This paper aims at giving a survey of the different product operators introduced in the literature by providing a uniform terminology, an analysis of their complexity, and of the implementation effort they require.


\section{Formal definitions, complexity, and implementation}
\label{sect:formaldef}
In this Section, we introduce the three main ways of combining various abstract domains in the abstract interpretation theory (namely, the Cartesian product, the reduced product, and the reduced cardinal power). For the sake of simplicity, we will focus on the combination of \emph{two} abstract domains. Therefore, we suppose that two abstract domains  and  are given, and that they are equipped with lattice operators:  and .

In addition, let  be the concrete domain. We suppose that this domain is equipped with lattice operators as well: . We suppose that both  and  are sound abstractions of , that is, they form a Galois connection:  and , where  and  are the abstraction and concretization functions of  and , respectively. \footnote{There exist other approaches which can be used as well (e.g., when the best abstraction function does not exist \cite{CH78}). However, the Galois connection-based approach is definitely the most commonly used \cite{CC92a}.}

Finally, abstract domains provide abstract semantic transformers. Formally, we suppose that  provides , and  provides . These are sound approximation of the concrete semantics . Formally,  and .



\subsection{Cartesian product}
The elements of this domain are elements in the Cartesian product of the two domains, and the operators are defined as the component-wise application of the operators of the two domains. 

Formally, let  be the Cartesian product. The partial order is defined as the conjunction of the partial orders of the two domains (). Similarly, the least upper bound and the greatest lower bound operators are defined as the component-wise application of the operators of the two domains ( and , respectively). This way, we obtain that the Cartesian product  forms a lattice. The pairwise approach to combine operators holds also in the case of widening. In fact, given  the widening operators  and  on the domains  and , respectively, the operator  is a widening operator on  \cite{ZanioliCortesi}.

In addition, the abstraction function  consists in the component-wise application of the abstraction functions of the two domains (), while the concretization function  consists in the intersection of the results obtained by the concretization functions of the two domains on the corresponding component (). Then, the Cartesian product forms a Galois connection with the concrete domain (formally, ).

Finally, also the semantic operator  is defined as the component-wise application of the abstract semantics of the two domains (formally, ). This way, the semantics of the Cartesian product is a sound over-approximation of the concrete semantics ().


As pointed out by Patrick Cousot \cite{MIT}, \textquotedblleft the Cartesian product discovers in one shot the information found separately by the component analyses\textquotedblright, but \textquotedblleft we do not learn more by performing all analyses simultaneously than by performing them one after another and finally taking their conjunctions\textquotedblright.

In addition, the Cartesian product may contain several abstract elements that represent the same information. For instance, consider the Cartesian product of the Interval and the Parity domains, and in particular the elements , , , and , where  represents the odd element of the Parity domain. All these elements concretize to the singleton , but some of them are not minimal\footnote{An abstract element  is minimal w.r.t. a property  if and only if (i)  and (ii) .}.






\subsubsection{Complexity}
When applying lattice or semantic operators, the complexity of the operator defined on  is exactly the sum of the complexity of the corresponding operators on  and . Instead, the height of the lattice of  (that is important to estimate the complexity of computing a fixpoint using this domain) is the multiplication of the heights of  and .

\subsubsection{Implementation}
Given the implementations of  and , the implementation of  is completely straightforward, and it could be used to combine any existing abstract domain in a completely generic way. In fact, the implementation only requires the existence of the operators, and there is no need to develop anything specific on such domains.

\subsection{Reduced product}
Even if the Cartesian product is a quite effective way to cheaply combine two domains in terms of both formalization and implementation, it is clear that one may want to let the information flow among the two domains to mutually refine them. Already in one of the foundative papers of abstract interpretation \cite{CC79}, Patrick and Radhia Cousot introduced the reduced product exactly with the purpose of refining the information tracked by  and . In particular, when we have an abstract state that is non-minimal, we can take the smallest element which represents the same information by \emph{reducing} it. A reduction improves the precision of the abstract representation
with respect to the order in the Cartesian product without affecting its concrete meaning. Intuitively, a reduction exploits the information tracked by one of the two domains involved in the product to refine the information tracked by the other one (and viceversa). Let  be an element of a reduced product (where  and  belong respectively to the two domains combined in the product: , ). Let  be the set of concrete values associated to  and  be the set of concrete values associated to . Then, the element  represents the set of concrete elements . The reduction tries to find the smallest element  such that the concretizations of  and  are subsets of those of  (respectively), but their intersection remains the same as the original one ().

The lattice and semantic structures of the reduced product are exactly the same as those of the Cartesian product. In addition, a reduction operator aimed at refining the information tracked by the two domains is introduced, and it is used after each lattice or semantic operator application. Formally, the reduction operator  is defined by . Nevertheless, such definition is not computable in general, and often one wants to have a relaxed version of this operator that is not expensive to compute. In general, a reduction operator has to satisfy the following two properties: (i)  (the result of its application is a more precise abstract element); (ii)  (an abstract element and its reduction represent the same property).

Consider again the example of the product of the Interval and Parity domains. A simple reduction operator may increase by one the lower bound (or decrease by one the upper bound) of the interval if the bound does not respect the information tracked by the Parity domain (e.g., it is odd while the parity tracks that the value is even). This way, the reduction of , , and  yields in all cases the abstract value . Note that the reduction operator does not always obtain the minimal information. For instance, if we reduce  (where  represents the even element of the Parity domain), we would obtain  (where  is the bottom element of the Intervals domain), that could be further reduced to  (where  is the bottom element of the Parity domain). Therefore, the reduction operator usually requires to compute a fixpoint \cite{MIT}. 
As two other examples, consider the reduced product of Interval and Congruences domains. Firstly, the reduction of the abstract value  produces the abstract value  which is not a minimal element. We need to iterate the reduction to obtain . Secondly, the reduction of  produces the abstract value  which can be reduced again to .

Observe that the widening operator on the reduced product cannot be derived \textquotedblleft for free\textquotedblright\ as refinement on the the widening operators of the components. As proved in \cite{ZanioliCortesi}, this is true only under the (quite strict) condition that , where  represents the elements of the reduced product.
This property does not often hold in practice. A far simpler (and naive) solution consists in applying the widening component-wise and refraining from reducing the result before feeding it back as left argument of the next iteration' s widening. This subsumes the above condition (as the reduction becomes idempotent on the iterates), but it also allows converging when the condition does not hold.



\subsubsection{Complexity}
In addition to the complexity of the Cartesian product, the reduced product requires to compute the reduction operator. Therefore, the complexity of an operator of the reduced product is the sum of the complexity of the operators defined on  and  and of the reduction operator. Since this operator may require computing a fixpoint, the final cost of a generic operator could be rather expensive. Therefore, usually it is more convenient to define a reduction operator that refines only partially the information tracked by the two domains \cite{LOG08}.


\subsubsection{Implementation}
The implementation of the reduction operator has to be specific for the domains we are refining. Therefore, while the Cartesian product was completely generic and automatic, the reduced product requires one to define and implement how two domains let the information flow among them. This means that each time we want to combine two domains in a reduced product we have to implement such operator. On the other hand, all the other lattice and semantic operators are defined exactly as in the Cartesian product, except that they have to call the reduction operator at the end, but this can be implemented generically w.r.t. the combined domains.

\subsubsection{Granger product}
Granger \cite{G92} proposed an elegant solution to compute an approximation of the reduction operator. Granger based his new product on the definition of two operators  and . The idea is that each operator refines one of the two domains involved in the product. The final reduction is obtained by iteratively applying  and . In order to have a sound reduction operator,  and  have to satisfy the following conditions:
\begin{itemize}
\item 
\item 

\end{itemize}
The intuition behind Granger's product is that dealing with only one flow of information at a time is simpler. Each of the two operators  tries to descend in one of the lattices: given the abstract element made by the pair , the  operator uses the information from  to go down the lattice of 	, while the  operator uses the information from  to go down the lattice of . After each application of  or  we get a smaller element. The descent is iteratively repeated until the operators cannot recover any more precision: the reduction operator  is then defined as the fixpoint of the decreasing iteration sequence obtained by applying  and . This is defined by the sequence  as follows:


The Granger product has exactly the same complexity we discussed for the reduced product. The main practical advantage of the Granger product is that one only needs to define and implement  and , that is, how the information flows from one domain to the other in one step. Then the reduction operator relying on the fixpoint computation comes for free. 



\subsubsection{Open product}

Cortesi et al. \cite{CCH00} proposed a further refinement of the Cartesian product. Its purpose is to let the domains interact with each other during \emph{and} after operations by making explicit the domains' interaction through (abstract) queries. The open product is orthogonal to Granger's product and the two proposals can be combined, by incorporating Granger's idea of refinement inside the open product. The open product is orthogonal also to other methods such as down-set completion, and tensor product.





\subsection{Reduced cardinal power}
The reduced cardinal power was introduced by Cousot and Cousot in \cite{CC79}, but the literature concerning it has been relatively poor on both the theoretical and the practical level. The main feature of the cardinal power is that it allows one to track disjunctive information over the abstract values of the analysis. For instance, given the Interval and the Parity domain, one could track information like \textquotedblleft when \statement{x} is odd, \statement{y} is in [0..10]\textquotedblright. Some examples of the application of the cardinal power are the example 10.2.0.2 of \cite{CC79}, and examples 3 and 4 of \cite{CCL11}. In addition, a detailed explanation with various examples has been proposed by Giacobazzi and Ranzato \cite{GR99}. Let us look at the example in \cite{CCL11}, where the following slice of
code is analyzed (typical of data transfer protocols where even and odd numbered packets contain data of different types):
\lstset{numbers=none}
\begin{lstlisting}
1: n := 10; i := 0; A := new int[n];
2: while (i < n) do {
3:  A[i] := 0;
4:  i := i + 1;
5:  A[i] := -16;
6:  i := i + 1;
7: }
\end{lstlisting}
To analyze it, the authors combine \textit{Parity} (where the lattice is made by the abstract elements ) and \textit{Intervals}. The reduced cardinal power of Intervals by Parity tracks abstract properties of the form , which means that the interval associated to some variable is  (resp. ) when the parity associated to another variable (which could be the same) is  (resp. ). First of all, the authors show a non-relational analysis of the listing above, where they use:
\begin{itemize}
\item the reduced product of Parity and Intervals for simple variables;
\item the reduced cardinal power of Parity by Interval for array elements (hence ignoring their relationship to indexes)
\end{itemize}
For example  means that the indexed array elements must be even with value included between  and . The result of this analysis is:  (variable \statement{i} is even and has value ),  (variable  is even and has value ), and , which represents that array elements are abstracted by  (i.e., they are even and with values in ). The precision of this analysis can be greatly improved by using again the reduced cardinal power of Intervals by Parity, but this time relating the parity of an \textit{index} of the array to the interval of the \textit{elements} of the array at that index. The new result is , which means that the array elements at odd indexes are equal to  while those at even indexes are .

The reduced cardinal power has been formalized as follows in \cite{CC79}. Given two abstract domains  and , the cardinal power  with base  and exponent  is the set of all isotone maps . Roughly, the combination of two abstract domains in  means that a state in  implies the abstract state of  it is in relation with. The partial ordering  is defined by . Similarly, the least upper bound and greatest lower bound operators are defined as the pointwise application of the operators of . This way,  forms a lattice.

Let  be two abstract elements in . Then, the widening operator  on  can be defined as:

Observe that the operator above can be effectively applied only if  is finite.

By defining  and  consequently, we have that . We refer the interested reader to \cite{GR99} (and in particular to Theorem 3.6 and Proposition 3.7, where  corresponds to ) for more details and formal proofs.



A correctness result was presented in \cite{CC79} as well (Theorem 10.2.0.1). In this work, the authors focused on a collecting semantics defined by a lattice of assertions which is a Boolean algebra. Afterwards, Cousot and Cousot did not broaden their theoretical definition to a more general setting.

Let us recall the example used in \cite{CC79} to show the expressiveness of this domain.

\lstset{numbers=none}
\begin{lstlisting}
1: x := 100; b := true;
2: while b do {
3: 	x := x - 1;
4: 	b := (x > 0);
5: }
\end{lstlisting} 

The exponent of the cardinal power we use to analyze this example is the Boolean domain for variable , while the base is the Sign domain for variable  tracking values  as well as  (meaning that the values are ),  (meaning that the values are ),  (meaning that the values are different from 0). This way, we track that when variable \statement{b} has a particular Boolean value, then the sign of variable \statement{x} has a particular sign. Before entering the \statement{while} loop, we know that , while . After the application of the semantics of statement 3, we will have that , and , because the value of \statement{b} is unchanged (it is certainly true) while the value of \statement{x} has been decreased by one (so it could become equal to zero or remain greater than zero). After line 4, we obtain that , and , since the new condition \statement{x>0} is assigned to \statement{b}. In fact, \statement{b} equals to \statement{true} implies that \statement{x} must be greater than zero. In addition, we knew that the value of \statement{x} was . Then, if \statement{b} is now \statement{false}, we are sure that \statement{x} will be equal to zero (but not less than zero). The fixpoint computation over the while loop stabilizes immediately (because, if we enter the loop again, we know that \statement{b} is true and, as a consequence, \statement{x} is positive, thus returning to the same conditions of the first iteration), and so we obtain that at the end of the program we have that , and , since we have to assume the negation of \statement{b} to terminate the execution of the \statement{while} loop. 





The cardinal power effectiveness is compromised when  is infinite (i.e., intervals in ), and can become costly when  is finite but non-trivial (i.e., intervals of machine integers). For this reason, some restricted forms of cardinal power can be used, where only a finite subset of  is represented.

Summarizing, the main difficulties in constructing a reduced cardinal power domain are: (i) the choice of elements in  to use; and (ii) the efficient design of abstract operators.

\subsubsection{Complexity}
Each time a lattice or semantic operator has to be applied to the abstract state, the cardinal power requires to apply it to all the elements of the base. Consider the cardinal power . In a state of our domain, we will track a state of  for each possible state of . Let  be the number of states of ,  the cost of an operator on  and  the cost on . Then the overall cost over  is , since, for any element in  we have to apply the operator both on  and .

Let  and  be the height of the lattice of  and , respectively. Then the height of  is .

It is then clear that the cardinal power causes a significant increase in the complexity of the analysis w.r.t. the complexity of the two original analyses. If there is already practical evidence that the reduction operator in the reduced product may induce an analysis that is too complex \cite{LOG08}, it is even more important to carefully choose the two domains combined in a cardinal power. Nevertheless, particular instances of the cardinal power are already used to analyze industrial software, and in particular in ASTR\'EE \cite{BCC03}. ASTR\'EE exploits the Boolean relation domain, which applies the cardinal power using the values of some particular Boolean program variables as exponent. In this way, the analysis tracks precise disjunctive information w.r.t. these variables. In addition, ASTR\'EE contains trace partitioning \cite{MR05}. This can be seen as a cardinal power in which the exponent is a set of manually provided tokens on which the analysis tracks disjunctive information. There are various types of tokens the user can provide: particular abstract values of a variable, the begin of an \statement{if} statement, etc. It is proved that, in practice, if an expert user provides the \emph{right} tokens, the resulting analysis can be quite precise preserving its performances at the same time.

\subsubsection{Implementation}
The implementation can be rather simple when using a programming language providing functional constructs. In fact, the most part of the cardinal power (namely, elements of the domain, and lattice and semantic operators) can be defined as the functional point-wise application of the operators on the base and the exponent. Instead, the implementation of the cardinal power may be more verbose using an imperative programming language, but we do not expect it represents a significant challenge.


\subsubsection{Reduced relative power}
Giacobazzi and Ranzato generalized the reduced cardinal power \cite{GR99}. For this purpose, the authors introduce the operation of \emph{reduced relative power} on abstract domains. As it happened with the cardinal power, the reduced relative power is based on two domains  and  (respectively, the exponent and the base) and is defined in a general and standard abstract interpretation setting. Its formal definition is , where  is a generic operator used to combine concrete denotations. It is called \textquotedblleft reduced \emph{relative} power\textquotedblright\ because it is parametric with respect to . The operator  should be thought of as a kind of combinator of concrete denotations: the glb is a typical example, but another less restrictive combinator could be needed for some non-trivial applications. An example comes from the field of logic program semantics. The reduced relative power can be used to systematically derive new declarative semantics for logic programs by composing the domains of interpretation of some well-known semantics. In this case a concrete domain of sets of program execution traces is endowed with an operator of trace-unfolding that does not behave like a meet-operation (in particular, it is not even commutative). For more details, see Section 7 of \cite{GR99}. The definition of the reduced relative power is as follows.  consists of all the monotone functions from  to  having the shape , where: (i)  ranges over concrete values, (ii)  is the concretization function of  and (iii)  is the abstraction function of . These monotone functions establish a dependency between the values of  and , and for this reason are called \emph{dependencies}. Intuitively, a dependency encodes how the abstract domain  is able to represent the \textquotedblleft reaction\textquotedblright\ of the concrete value  whenever it is combined via  with an object described by .





\section{Examples}
\label{sect:motivatingexamples}
In this Section, we discuss the application of the Cartesian product, the reduced product, and the cardinal power to some examples dealing with arrays. This way, we show the main features and limits of each combination of domains. The two abstract domains we will combine are Intervals \cite{CC77} and a relational domain that tracks constraints of the form .

\subsection{Cartesian product}
As a first example, we consider a quite standard program that initializes to 0 all the elements of a given array. 
	\lstset{numbers=none}
\begin{lstlisting}
for(i=0; i < arr.length; i++)
	arr[i] = 0;
\end{lstlisting}

We want to prove that the array accesses are safe, that is,  and , in particular when we perform \statement{arr[i]=0}. 

If we run the analysis using only Intervals, we obtain that . In fact, this domain cannot infer any information from the loop guard \statement{i<arr.length} since it does not have any upper bound for \statement{arr.length}. This result suffices to prove the first part of our property () but not the second part ().
If we run the analysis using only a relational domain, we obtain that  when we analyze the statement \statement{arr[i]=0} thanks to the loop guard. In this way, we can prove the second part of the property, but not the first part.

Therefore, the two domains alone cannot prove the property of interest, while the Cartesian product can. In fact, it runs the two analyses in parallel, and at the end it takes from both domains the most precise result they get regarding the property to verify. Combining the two results, the entire property is proved to hold.

\subsection{Reduced product}
Let us introduce a more complex example. It receives as input an integer variable \statement{l}, and it creates an array with one element if , and of \statement{l} elements otherwise. Then it initializes the first \statement{l} elements to zero.

\begin{lstlisting}
if(l<=0)
	arr = new Int[1];
else 
	arr = new Int[l];
for(i=0; i < l; i++)
	arr[i] = 0;
\end{lstlisting}

As before, we want to prove that when we perform \statement{arr[i]=0} we have that  and . In particular, the critical property is the second one, since the first one is already proved by Intervals as explained before.

If we analyze this example with the Cartesian product defined before, we obtain that (i)  in the \statement{then} branch, and (ii)  in the \statement{else} branch. Then, when we compute the upper bound of these two states, we obtain only . This leads to infer that  inside the loop, but this cannot prove that .

We now define a specific reduction operator that refines the information tracked by the relational domain with Intervals. In particular, if Intervals track that  and we have that , then in the relational domain we introduce the constraint  where . Thanks to this reduction operator, we infer that, in the \statement{then} branch, . Thank to this reduction, when we join the two abstract states after the \statement{if} statement we obtain that . This leads to infer (when we analyze \statement{arr[i]=0}) that , and the information tracked by the relational domain proves that .


\subsection{Reduced cardinal power}
We slightly modify the previous example. In particular, we create an array of one element if , and we initialize all the elements in the array from the third to the -th element.

\begin{lstlisting}
if(l <= 2)
  arr = new Int[1];
else 
  arr = new Int[l];
for(i = 3; i < l; i++)
  arr[i] = 0;
\end{lstlisting}

As in the previous example, the main challenge is to prove the second part of the property (that is, ) when executing \statement{arr[i]=0}.

First of all, we show that the reduced product of Intervals and our relational domain is not in position to prove this property.
In the \statement{then} branch, the Interval domain tracks that  and . This information yields the strict lower bound relationship  through the reduction operator we previously introduced. The abstract state associated to the \statement{then} branch is , while in the \statement{else} branch we obtain . When we compute the join between these two states, we obtain . In fact, the join of the constraints  and  results in . Finally, inside the \statement{for} loop we know (from the Interval domain and its widening operator) that . Moreover, the loop guard implies that, when we perform \statement{arr[i]=0},  holds. From  and , we obtain that , that is weaker than the property of interest .

Now consider the reduced cardinal power of Intervals on \statement{l} as exponent and our relational domain as base. The \statement{then} branch is associated to the abstract state , and the \statement{else} branch to . The join between these two states simply creates a new abstract state which contains both informations, that is,  and . When we enter the while loop, we have to consider the two cases separately:
\begin{itemize}
\item in the first case, . Then, the loop guard  is surely evaluated to false: the loop is not executed, so we do not need to verify the property about array accesses. Therefore, when  holds, we have that . This way, when we analyze \statement{arr[i]=0}, we can discard this case;
\item in the second case, we have that  and . Then, from the abstract state obtained after the \statement{if} statements and assuming the loop guard, we know that . By combining  and , we obtain , which is exactly the property we wanted to prove. 
\end{itemize}


\section{Conclusion}
In this survey, we presented various product operators in the abstract interpretation theory. 
For each product, we formalized its main components, we discussed its complexity and the implementation efforts required to implement it. We pointed out that, while the complexity of the Cartesian product does not cause any practical problem, the reduced product may affect the performances of the analysis if the reduction operator is too precise. In addition, the cardinal power leads to a lattice whose height is exponential w.r.t. the heights of the combined domains, and therefore this product requires the user to carefully and manually choose how to combine the two domains.
Finally we presented some examples that underline the expressiveness and the limit of the different products, showing in which scenarios a product is satisfactory or when we have to choose a more complex product.

\subsection*{Acknowledgments}
We are very indebted to Dave Schmidt. Both in his articles and especially in his presentations and discussions he has transmitted to us the passion in discovering new problems and solutions, the attention to clarity and understandability, and the strength of humility.

Work partially supported by the PRIN-Miur Project \textquotedblleft Security Horizons\textquotedblright .

\bibliographystyle{eptcs}
\bibliography{bibliografia}

\end{document}