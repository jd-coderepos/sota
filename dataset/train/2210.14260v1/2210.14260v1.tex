\pdfoutput=1


\documentclass[11pt]{article}

\usepackage[]{acl}

\usepackage{times}
\usepackage{latexsym}

\usepackage[T1]{fontenc}


\usepackage[utf8]{inputenc}

\usepackage{microtype}

\usepackage{graphicx}
\usepackage{subcaption}

\usepackage{tabularx, colortbl, xcolor}
\definecolor{mygray}{gray}{0.95}
\definecolor{mycyan}{HTML}{005397}
\definecolor{myred}{HTML}{E13333}

\definecolor{mygreen}{HTML}{C7C6C4}
\definecolor{mymagenta}{HTML}{BF3E87}
\definecolor{mypurple}{HTML}{1B2278}

\usepackage{amsfonts}
\usepackage{amsmath}


\usepackage{braket}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}

\usepackage[english]{babel}
\usepackage{amsthm}
\usepackage{amssymb}

\theoremstyle{remark}
\newtheorem{case}{Case}[section]


\usepackage{easyReview}
\renewcommand{\alertColor}{\textcolor{myred}}
\renewcommand{\addColor}{\textcolor{mycyan}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}


\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage{textcomp}

\usepackage{multirow}
\usepackage{lscape}

\title{Universal Evasion Attacks on Summarization Scoring}



\author{\textbf{Wenchuan Mu}\quad \textbf{Kwan Hui Lim}\\
Singapore University of Technology and Design \\
\texttt{\{wenchuan\_mu,kwanhui\_lim\}@sutd.edu.sg}\\
}

\begin{document}
\maketitle
\begin{abstract}
The automatic scoring of summaries is important as it guides the development of summarizers. Scoring is also complex, as it involves multiple aspects such as fluency, grammar, and even textual entailment with the source text. However, summary scoring has not been considered a machine learning task to study its accuracy and robustness. In this study, we place automatic scoring in the context of regression machine learning tasks and perform evasion attacks to explore its robustness. Attack systems predict a non-summary string from each input, and these non-summary strings achieve competitive scores with good summarizers on the most popular metrics: ROUGE, METEOR, and BERTScore. Attack systems also "outperform" state-of-the-art summarization methods on ROUGE-1 and ROUGE-L, and score the second-highest on METEOR. Furthermore, a BERTScore backdoor is observed: a simple trigger can score higher than any automatic summarization method. The evasion attacks in this work indicate the low robustness of current scoring systems at the system level. We hope that our highlighting of these proposed attacks will facilitate the development of summary scores.
\end{abstract}

\section{Introduction}

A long-standing paradox has plagued the task of automatic summarization. On the one hand, for about 20 years, there has not been any automatic scoring available as a sufficient or necessary condition to demonstrate summary quality, such as adequacy, grammaticality, cohesion, fidelity, etc. On the other hand, contemporaneous research more often uses one or several automatic scores to endorse a summarizer as state-of-the-art. More than 90\% of works on language generation neural models choose automatic scoring as the main basis, and about half of them rely on automatic scoring only~\cite{van2021human}. However, these scoring methods have been found to be insufficient~\cite{novikova-etal-2017-need}, oversimplified~\cite{van2021human}, difficult to interpret~\cite{sai2022survey}, inconsistent with the way humans assess summaries~\cite{rankel-etal-2013-decade,bohm-etal-2019-better}, or even contradict each other~\cite{gehrmann-etal-2021-gem,bhandari-etal-2020-metrics}.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.45\textwidth]{bifurcated.pdf}
    \caption{Automatic summarization (left) and automatic scoring (right) should be considered as two systems of the same rank, representing conditional language generation and natural language understanding, respectively. As a stand-alone system, the accuracy and robustness of automatic scoring are also important. In this study, we create systems that use bad summaries to fool existing scoring systems. This work shows that optimizing towards a flawed scoring does more harm than good, and flawed scoring methods are \emph{not} able to indicate the true performance of summarizers, even at a system level.}
    \label{fig:robots}
\end{figure}

Why do we have to deal with this paradox? The current work may not have suggested that summarizers assessed by automatic scoring are de facto ineffective. However, optimizing for flawed evaluations~\cite{gehrmann-etal-2021-gem,peyrard-etal-2017-learning}, directly or indirectly, ultimately harms the development of automatic summarization~\cite{narayan-etal-2018-ranking,kryscinski-etal-2019-neural,paulus2018a}. One of the most likely drawbacks is shortcut learning (surface learning, \citealp{geirhos2020shortcut}), where summarizing models may fail to generate text with more widely accepted qualities such as adequacy and authenticity, but instead pleasing scores. Here, we quote and adapt\footnote{We underline adaptations.} this hypothetical story by \citeauthor{geirhos2020shortcut}.

\textit{"Alice loves \underline{literature}. Always has, probably always will. At this very moment, however, she is cursing the subject: After spending weeks immersing herself in the world of \underline{Shakespeare's The Tempest}, she is now faced with a number of exam questions that are (in her opinion) to equal parts dull and difficult. 'How many \underline{times is Duke of Milan addressed}'... Alice notices that Bob, sitting in front of her, seems to be doing very well. Bob of all people, who had just boasted how he had learned the whole book chapter by rote last night ..."}

\begin{table*}[!t]
\scriptsize
\begin{tabularx}{\textwidth}{p{0.065\textwidth}Xp{0.28\textwidth}}
\hline
System &
  Summary &
  Document \\
\hline
Gold &
  Kevin Pietersen was sacked by   England 14 months ago after Ashes defeat. Batsman scored 170 on his county   cricket return for Surrey last week. Pietersen wants to make a sensational   return to the England side this year. But Andrew Flintoff thinks time is running   out for him to resurrect career. \hfill (ROUGE-1, ROUGE-2, ROUGE-L, METEOR, BERTScore)&
  \multirow{6}{16\baselineskip }{Andrew Flintoff fears   Kevin Pietersen is 'running out of time' to resurrect his England career. The   dual Ashes-winning all-rounder is less convinced, however, about Pietersen's   prospects of forcing his way back into Test contention. Kevin Pietersen scored   170 for Surrey in The Parks as he bids to earn a recall to the England   squad... ... Flintoff senses he no longer has age on his side. Pietersen has   not featured for England since he was unceremoniously sacked 14 months ago.   ... ... Flintoff said ... 'If he'd started the season last year with Surrey, and   scored run after run and put himself in the position... whereas now I think   he's looking at the Ashes ... ... you get the sense everyone within the England   set-up wants him as captain,' he said.' ... The former England star is hoping   to win back his Test place with a return to red ball cricket. ... ...  'this stands up as a competition.'} \\
\cellcolor{mygray}
Good \cite{liu-liu-2021-simcls}&
\cellcolor{mygray}
  Kevin   pietersen scored 170 for surrey against mccu oxford. Former england star   andrew flintoff fears pietersen is 'running out of time' to resurrect his   england career. Pietersen has been surplus to requirements since being sacked   14 months ago. Flintoff sees a bright future for 'probably the premier   tournament' in this country. \hfill(55.45, 18.18, 41.58, 40.03, 85.56) &
   \\
Broken&
  \textcolor{mypurple}{Andrew Flintoff fears Kevin Pietersen is running out of time to resurrect his England career Flintoff. Pietersen scored 170 for   Surrey in The.  Former England star   Andrew.  batsman has been .  since being sacked 14 months ago   after.  three in the.  the Ashes and he s.}  \hspace{100pt}\textcolor{white}{>}\,\hfill (\textbf{56.84}, \textbf{21.51}, \textbf{44.21}, \textbf{47.26}, 85.95) &
   \\
\cellcolor{mygray}
A dot&
\cellcolor{mygray}
  \textbf{\color{mymagenta}.} \hfill(0, 0, 0, 0, \textbf{88.47}) &
   \\
Scrambled code&
\texttt{\color{mymagenta}\textbackslash{}x03\textbackslash{}x18\$\textbackslash{}x18...\textbackslash{}x03\$\textbackslash{}x03|...\textbackslash{}x0f\textbackslash{}x01\textless{}\textless{}\$\$\textbackslash{}x04...\textbackslash{}x0e \textbackslash{}x04\# \$...\textbackslash{}x0f\textbackslash{}x0f\textbackslash{}x0f...\textbackslash{}x0e...\textbackslash{}x0f...\textbackslash{}x0f\textbackslash{}x0f\$\textbackslash{}x0f \textbackslash{}x04\textbackslash{}x0f\textbackslash{}x0f} (many tokens omitted) \hfill(0, 0, 0, 0, 87.00) &
   \\
\cellcolor{mygray}
Scrambled code + broken&
\cellcolor{mygray}
  \texttt{\color{mymagenta}\textbackslash{}x03\textbackslash{}x18\$\textbackslash{}x18...\textbackslash{}x03\$\textbackslash{}x03|...\textbackslash{}x0f\textbackslash{}x01\textless{}\textless{}\$\$\textbackslash{}x04...\textbackslash{}x0e \textbackslash{}x04\# \$...\textbackslash{}x0f\textbackslash{}x0f\textbackslash{}x0f...\textbackslash{}x0e...\textbackslash{}x0f...\textbackslash{}x0f\textbackslash{}x0f\$\textbackslash{}x0f \textbackslash{}x04\textbackslash{}x0f\textbackslash{}x0f}...    \textcolor{mypurple}{Andrew Flintoff fears Kevin Pietersen is running out of time to   resurrect his England career Flintoff.    Pietersen scored 170 for Surrey in The.  Former England star Andrew.  batsman has been .  since being sacked 14 months ago   after.  three in the.  the Ashes and he s.} (many tokens omitted)\hspace{100pt} \hfill(\textbf{56.84}, \textbf{21.51}, \textbf{44.21}, \textbf{47.26}, 87.00) &\\
\hline
  
\end{tabularx}

\caption{We created non-summarizing systems, each of which produces bad text when processing any document. Broken sentences get higher lexical scores; non-alphanumeric characters outperform good summaries on BERTScore. Concatenating two strings produces equally bad text, but scores high on both. The example is from CNN/DailyMail (for
visualization, document is abridged to keep content most consistent with the corresponding gold summary).
}
\label{tab:example}
\end{table*} 
According to \citeauthor{geirhos2020shortcut}, Bob might get better grades and consequently be considered a better student than Alice, which is an example of surface learning. The same could be the case with automatic summarization, where we might end up with significant differences between expected and actual learning outcomes~\cite{paulus2018a}. To avoid going astray, it is important to ensure that the objective is correct.

In addition to understanding the importance of correct justification, we also need to know what caused the fallacy of the justification process for these potentially useful summarizers. There are three mainstream speculations that are not mutually exclusive. (1) The transition from extractive summarization to abstractive summarization~\cite{kryscinski-etal-2019-neural} could have been underestimated. For example, the popular score ROUGE~\cite{lin-2004-rouge} was originally used to judge the ranking of sentences selected from documents. Due to constraints on sentence integrity, the generated summaries can always be fluent and undistorted, except sometimes when anaphora is involved. However, when it comes to free-form language generation, sentence integrity is no longer guaranteed, but the metric continues to be used. (2) Many metrics, while flawed in judging individual summaries, often make sense at the system level~\cite{reiter-2018-structured,gehrmann-etal-2021-gem,bohm-etal-2019-better}. In other words, it might have been believed that few summarization systems can \emph{consistently} output poor-quality but high-scoring strings. (3) Researchers have not figured out how humans interpret or understand texts~\cite{van2021human,gehrmann-etal-2021-gem,schluter-2017-limits}, thus the decision about how good a summary really is varies from person to person, let alone automated scoring. In fact, automatic scoring is more of a natural language understanding (NLU) task, a task that is far from solved. From this viewpoint, automatic scoring itself is fairly challenging.

Nevertheless, the current work is not to advocate (and certainly does not disparage) human evaluation. Instead, we argue that automatic scoring itself is not just a sub-module of automatic summarization, and that automatic scoring is a stand-alone system that needs to be studied for its \emph{own} accuracy and robustness. The primary reason is that NLU is clearly required to characterize summary quality, \emph{e.g.}, semantic similarity to determine adequacy~\cite{morris-2020-second}, or textual entailment~\cite{dagan2005pascal} to determine fidelity. Besides, summary scoring is similar to automated essay scoring (AES), which is a 50-year-old task measuring grammaticality, cohesion, relevance etc. of written texts~\cite{ke2019automated}. Moreover, recent advances in automatic scoring also support this argument well. Automatic scoring is gradually transitioning from well-established metrics measuring N-gram overlap (BLEU~\cite{papineni-etal-2002-bleu}, ROUGE~\cite{lin-2004-rouge}, METEOR~\cite{banerjee-lavie-2005-meteor}, etc.) to emerging metrics aimed at computing semantic similarity through pre-trained neural models (BERTScore~\cite{zhang2019bertscore}, MoverScore~\cite{zhao-etal-2019-moverscore}, BLEURT~\cite{sellam-etal-2020-bleurt}, etc.) These emerging scores exhibit two characteristics that stand-alone machine learning systems typically have: one is that some \emph{can be fine-tuned} for human cognition; the other is that they \emph{still have room to improve} and still have to learn how to match human ratings. 


Machine learning systems can be attacked. Attacks can help improve their generality, robustness, and interpretability. In particular, evasion attacks are an intuitive way to further expose the weaknesses of current automatic scoring systems. Evasion attack is the parent task of adversarial attack, which aims to make the system fail to correctly identify the input, and thus requires defence against certain exposed vulnerabilities.

In this work, we try to answer the question: do current representative automatic scoring systems really work well at the system level? How hard is it to say they do not work well at the system level? In summary, we make the following major contributions in this study:
\begin{itemize}
    \item We are the first to treat automatic summarization scoring as an NLU regression task and perform evasion attacks.
    \item We are the first to perform a \emph{universal}, \emph{targeted} attack on NLP \emph{regression} models.
    \item Our evasion attacks support that it is not difficult to deceive the three most popular automatic scoring systems simultaneously.
    \item The proposed attacks can be directly applied to test emerging scoring systems.

\end{itemize}


\section{Related Work}\label{sec:related}
\subsection{Evasion Attacks in NLP}
In an evasion attack, the attacker modifies the input data so that the NLP model incorrectly identifies the input. The most widely studied evasion attack is the adversarial attack, in which insignificant changes are made to the input to make "adversarial examples" that greatly affect the model's output~\cite{szegedy2013intriguing}. There are other types of evasion attacks, and evasion attacks can be classified from at least three perspectives. (1) Targeted evasion attacks and untargeted evasion attacks~\cite{cao2017mitigating}. The former is intended for the model to predict a specific wrong output for that example. The latter is designed to mislead the model to predict any incorrect output. (2) Universal attacks and input-dependent attacks~\cite{wallace-etal-2019-universal,song-etal-2021-universal}. The former, also known as an "input-agnostic" attack, is a "unique model analysis tool". They are more threatening and expose more general input-output patterns learned by the model. The opposite is often referred to as an input-dependent attack, and is sometimes referred to as a local or typical attack. (3) Black-box attacks and white-box attacks. The difference is whether the attacker has access to the detailed computation of the victim model. The former does not, and the latter does. Often, targeted, universal, black-box attacks are more challenging. Evasion attacks have been used to expose vulnerabilities in sentiment analysis, natural language inference (NLI), automatic short answer grading (ASAG), and natural language generation (NLG)~\cite{alzantot-etal-2018-generating,wallace-etal-2019-universal,song-etal-2021-universal,filighera2020fooling,filighera2022cheating,zang-etal-2020-word,behjati2019universal}.


\subsection{Universal Triggers in Attacks on Classification}
A prefix can be a universal trigger. When a prefix is added to any input, it can cause the classifier to misclassify sentiment, textual entailment~\cite{wallace-etal-2019-universal}, or if a short answer is correct~\cite{filighera2020fooling}. These are usually untargeted attacks in a white-box setting\footnote{When the number of categories is small, the line between targeted and non-targeted attacks is blurred, especially when there are only two categories.}, where the gradients of neural models are computed during the trigger search phase.

\citeauthor{wallace-etal-2019-universal} also used prefixes to trigger a reading comprehension model to specifically choose an odd answer or an NLG model to generate something similar to an egregious set of targets. These two are universal, targeted attacks, but are mainly for classification tasks. Given that automatic scoring is a regression task, more research is needed.

\subsection{Adversarial Examples Search for Regression Models}
Compared with classification tasks in NLP, regression tasks (such as determining text similarity) are fewer and less frequently attacked. For example, the Universal Sentence Encoder (USE, \citealp{cer-etal-2018-universal}) and BERTScore~\cite{zhang2019bertscore} are often taken as two constraints when searching adversarial examples for other tasks~\cite{alzantot-etal-2018-generating}. However, these regression models may also be flawed, vulnerable or not robust, which may invalidate the constraints~\cite{morris-2020-second}.

\citet{morris-2020-second} shows that adversarial attacks could also threaten these regression models. For example, \citet{maheshwary2021generating} adopt a black-box setting to maximize the semantic similarity between the altered input text sequence and the original text. Similar attacks are mostly input-dependent, probably because these regression models are mostly used as constraints. In contrast, universal attacks may better reveal the vulnerabilities of these regression models.





\subsection{Victim Scoring Systems}
Every (existing) automatic summary scoring is a monotonic regression model. Most scoring requires at least one gold-standard text to be compared to the output from summarizers. One can opt to combine multiple available systems in one super system~\cite{lamontagne2006combining}. We will focus on the three most frequently used systems, including rule-based systems and neural systems. ROUGE (Recall-Oriented Understudy for Gisting Evaluation \citealp{lin-2004-rouge}) measures the number of overlapping N-grams or the longest common subsequence (LCS) between the generated summary and a set of gold reference summaries. Particularly, ROUGE-1 corresponds to unigrams, ROUGE-2 to bigrams, and ROUGE-L to LCS. F-measures of ROUGE are often used~\cite{see-etal-2017-get}. METEOR~\cite{banerjee-lavie-2005-meteor} measures overlapping unigrams, equating a unigram with its stemmed form, synonyms, and paraphrases. BERTScore~\cite{zhang2019bertscore} measures soft overlap between two token-aligned texts, by selecting alignments, BERTScore returns the maximum cosine similarity between contextual BERT~\cite{devlin-etal-2019-bert} embeddings.


\subsection{Targeted Threshold for Attacks}
We use a threshold to determine whether a targeted attack on the regression model was successful. Intuitively, the threshold is given by the scores of the top summarizers, and we consider our attack to be successful if an attacker obtains a score higher than the threshold using clearly inferior summaries. We use representative systems that once achieved the state-of-the-art in the past five years: Pointer Generator~\cite{see-etal-2017-get}, Bottom-Up~\cite{gehrmann-etal-2018-bottom}, PNBERT~\cite{zhong-etal-2019-searching}, T5~\cite{raffel2019exploring},
BART~\cite{lewis-etal-2020-bart}, and SimCLS~\cite{liu-liu-2021-simcls}.


\section{Universal Evasion Attacks}\label{sec:methods}
We develop universal evasion attacks for individual scoring system, and make sure that the combined attacker can fool ROUGE, METEOR, and BERTScore at the same time. It incorporates two parts, a white-box attacker on ROUGE, and a black-box universal trigger search algorithm for BERTScore, based on genetic algorithms. METEOR can be attacked directly by the one designed for ROUGE. Concatenating output strings from black-box and white-box attackers leads to a sole universal evasion attacking string.

\subsection{Problem Formulation}

Summarization is conditional generation. A system $\sigma$ that performs this conditional generation takes an input text ($\mathbf{a}$) and outputs a text ($\hat{\mathbf{s}}$), \emph{i.e.}, $\hat{\mathbf{s}} = \sigma(\mathbf{a})$. In single-reference scenario, there is a gold reference sequence $\mathbf{s}_\text{ref}$. A summary scoring system $\gamma$ calculates the "closeness" between sequence $\hat{\mathbf{s}}$ and $\mathbf{s}_\text{ref}$. In order for a scoring system to be sufficient to justify a good summarizer, the following condition should always be avoided:
\begin{equation}\label{eq:cond}
    \gamma(\sigma_\text{far worse}(\mathbf{a}), \mathbf{s}_\text{ref}) > \gamma(\sigma_\text{better}(\mathbf{a}), \mathbf{s}_\text{ref}).
\end{equation}

Indeed, to satisfy the condition above is our attacking task. In this section, we detail how we find a suitable $\sigma_\text{far worse}$.

\subsection{White-box Input-agnostic Attack on ROUGE and METEOR}
In general, attacking ROUGE or METEOR can only be done with a white-box setup, since even the most novice attacker (developer) will understand how these two formulae calculate the overlap between two strings. We choose to game ROUGE with the most obvious bad system output (broken sentences) such that no additional human evaluation is required. In contrast, for other gaming methods, such as reinforcement learning~\cite{paulus2018a}, even if a high score is achieved, human evaluation is still needed to measure how bad the quality of the text is.

We utilize a hybrid approach (we refer to it as $\sigma_\text{ROUGE}$) of token classification neural models and simple rule-based ordering, since we know that ROUGE compares each pair of sequences ($\mathbf{s}_1, \mathbf{s}_2$) via hard N-gram overlapping. In bag algebra, extended from set algebra~\cite{bertossi2018datalog}, two trendy variants of ROUGE: ROUGE-N ($R_{\text{N}}(n, \mathbf{s}_1, \mathbf{s}_2), n \in\mathbb{Z}^+$) and ROUGE-L($R_{\text{L}}(\mathbf{s}_1, \mathbf{s}_2)$) calculate as follows:

\begin{align} 
    R_{\text{N}}(n, \mathbf{s}_1, \mathbf{s}_2) &= \frac{2\cdot\abs{b(n, \mathbf{s}_1) \cap b(n, \mathbf{s}_2)}}{\abs{b(n, \mathbf{s}_1)} + \abs{b(n, \mathbf{s}_2)}}, \\
    R_{\text{L}}(\mathbf{s}_1, \mathbf{s}_2) &=
    \frac{2\cdot \abs{b(1, \text{LCS}(\mathbf{s}_1, \mathbf{s}_1))}}{\abs{b(1, \mathbf{s}_1)} + \abs{b(1, \mathbf{s}_2)}},
\end{align}

where $\abs{\cdot}$ denotes the size of a bag, $\cap$ denotes  \emph{bag} intersection, and bag of N-grams is calculated as follows:
\begin{equation}\label{eq:bag}
    b(n, \mathbf{s}) = \set{x\mid x \text{ is an } n\text{-gram in } \mathbf{s}}_{\text{bag}}.
\end{equation}


In our hybrid approach, the first step is that the neural model tries to predict the target's bag of words $b(1, \mathbf{s}_\text{ref})$, given any input $\mathbf{a}$ and corresponding target $\mathbf{s}_\text{ref}$. Then, words in the predicted bag are ordered according to their occurrence in the input $\mathbf{a}$. Formally, training of the neural model ($\phi$) is:

\begin{equation}\label{eq:train}
\min_\phi \frac{1}{\abs{\mathcal{A}}}\sum _{\mathbf{a}\in \mathcal{A}} \sum _{w\in  \mathbf{a}} H(P_\text{ref}(\cdot\mid w), P(\cdot\mid w, \phi)),
\end{equation}


where $H$ is the cross-entropy between the probability distribution of the reference word count and the predicted word count. An approximation is that the model tries to predict $b(1, \mathbf{s}_\text{ref})\cap b(1, \mathbf{a})$. Empirically, three-quarters of words in reference summaries can be found in their corresponding input texts.

Referencing the input text ($\mathbf{a}$) and predicted bag of words ($\hat{W}$) to construct a sequence is straightforward, as seen in Algorithm~\ref{alg:b2s}.


\begin{algorithm}
\caption{From bag of words to sequence}\label{alg:b2s}
\small
\begin{algorithmic}
\Require $\mathbf{a}, \hat{W}$
\Return $\hat{\mathbf{s}}$
\State $\hat{\mathbf{s}} \gets ()$
\While{$\abs{\hat{W}} > 0$}
\State Salient Sequence $\mathbf{l} \gets (x \mid $ for $x \in \mathbf{a}$ if $[x \in \hat{W}])$
\State $\mathbf{c} \gets$ Longest Consecutive Salient Subsequence of $l$
\If{$\abs{\mathbf{c}} < C$} \Comment{Constant about 3}
\State break 
\EndIf
\State $\hat{\mathbf{s}} \gets \hat{\mathbf{s}} + \mathbf{c}$ \Comment{Concatenate $\mathbf{c}$ to $\hat{\mathbf{s}}$}
\State $\hat{W} \gets \hat{W} - \mathbf{c}$ \Comment{Remove used words}

\EndWhile
\end{algorithmic}
\end{algorithm}

Algorithm~\ref{alg:b2s} uses salient words to highlight the longest consecutive salient subsequences in $\mathbf{a}$, until the words in $\hat{W}$ are exhausted, or when each consecutive salient sequence is less than three words ($C=3$). 


\subsection{Black-box Universal Trigger Search on BERTScore}
Finding a $\sigma_\text{far worse}$ for BERTScore alone to satisfy condition\ref{eq:cond} is easy. A single dot (\emph{"."}) is an imitator of \emph{all} strings, as if it is a "backdoor" left by developers. We notice that, on default setting of BERTScore\footnote{\url{https://huggingface.co/metrics/bertscore}}, using a single dot can achieve around 0.892 on average when compared with any natural sentences. This figure "outperforms" all existing summarizers, making \textit{outputing a dot} a good enough $\sigma_\text{far worse}$ instance.

This example is very intriguing because it highlights the extent to which many vulnerabilities go unnoticed, although it cannot be combined directly with the attacker for ROUGE. Intuitively, there could be various clever methods to attack BERTScore as well, such as adding a prefix to each string~\cite{wallace-etal-2019-universal,song-etal-2021-universal}. However, we here opt to develop a system that could output (one of) the most obviously bad strings (scrambled codes) to score high.

BERTScore is generally classified as a neural, untrained score~\cite{sai2022survey}. In other words, part of its forward computation (\emph{e.g.}, greedy matching) is rule-based, while the rest (\emph{e.g.}, getting every token embedded in the sequence) is not. Therefore, it is difficult to "design" an attack rationally. Gradient methods (white-box) or discrete optimization (black-box) are preferable. Likewise, while letting BERTScore generate soft predictions~\cite{jauregi-unanue-etal-2021-berttune} may allow attacks in a white-box setting, we found that black-box optimization is sufficient.

Inspired by the single-dot backdoor in BERTScore, we hypothesize that we can form longer catch-all emulators by using only non-alphanumeric tokens. Such an emulator has two benefits: first, it requires a small fitting set, which is important in targeted attacks on regression models. We will see that once an emulator is optimized to fit one natural sentence, it can also emulate almost any other natural sentence. The total number of natural sentences that need to be fitted before it can imitate decently is usually less than ten. Another benefit is that using non-alphanumeric tokens does not affect ROUGE.



Genetic Algorithm (GA, \citealp{holland1992genetic}) was used to discretely optimize the proposed non-alphanumeric strings. Genetic algorithm is a search-based optimization technique inspired by the natural selection process. GA starts by initializing a population of candidate solutions and iteratively making them progress towards better solutions. In each iteration, GA uses a fitness function to evaluate the quality of each candidate. High-quality candidates are likely to be selected and crossover-ed to produce the next set of candidates. New candidates are mutated to ensure search space diversity and better exploration. Applying GA to attacks has shown effectiveness and efficiency in maximizing the probability of a certain classification label~\cite{alzantot-etal-2018-generating} or the semantic similarity between two text sequences~\cite{maheshwary2021generating}. Our single fitness function is as follows,
\begin{equation}
    \mathbf{\hat{s}}_\text{emu} = \argmin_\mathbf{\hat{s}} -B(\hat{\mathbf{s}}, \mathbf{s}_\text{ref}),
\end{equation}
where $B$ stands for BERTScore. As for termination, we either use a threshold of -0.88, or maximum of 2000 iterations.

To fit $\mathbf{\hat{s}}_\text{emu}$ to a set of natural sentences, we calculate BERTScore for each sentence in the set after each termination. We then select a proper $\mathbf{s}_\text{ref}$ to fit for the next round. We always select the natural sentence (in a finite set) that has the lowest BERTScore with the optimized $\mathbf{\hat{s}}_\text{emu}$ at the current stage. We then repeat this process till the average BERTScore achieved by this string is higher than many reputable summarizers.

Finally, to simultaneously game ROUGE and BERTScore, we concatenate $\mathbf{\hat{s}}_\text{emu}$ and the input-agnostic $\sigma_\text{ROUGE}(\mathbf{a})$. If we set the number of tokens in $\mathbf{\hat{s}}_\text{emu}$ greater than 512 (the max sequence length for BERT), $\sigma_\text{ROUGE}(\mathbf{a})$ would then not affect the effectiveness of $\mathbf{\hat{s}}_\text{emu}$, and we technically game them both. Additionally, this concatenated string games METEOR, too.

\section{Experiments}
We instantiate our evasion attack by conducting experiments on non-anonymized CNN/DailyMail (CNNDM, \citealp{nallapati2016abstractive,see-etal-2017-get}), a dataset that contains news articles and associated highlights as summaries. CNNDM includes 287,226 training pairs, 13,368 validation pairs and 11,490 test pairs. 


For $\sigma_\text{ROUGE}$ we use RoBERTa (base model, \citealp{liu2019roberta}) to instantiate $\phi$, which is an optimized pretrained encoding with a randomly initialized linear layer on top of the hidden states. Number of classes is set to three because we assume that each word appears at most twice in a summary. All 124,058,116 parameters are trained as a whole on CNNDM train split for one epoch. When the batch size is eight, the training time on an NVIDIA Tesla K80 graphics processing unit (GPU) is less than 14 hours. It then takes about 20 minutes to predict (including word ordering) all 11,490 samples in the CNNDM test split. Scripts and results are available at
\url{https://github.com} (URL will be made publicly available after paper acceptance).

For the universal trigger to BERTScore, we use the library from \citet{pymoo} for discrete optimizing, set population size at 10, and terminate at 2000 generations. $\mathbf{\hat{s}}_\text{emu}$ is a sequence of independent randomly initialized non-alphanumeric characters. For a reference $\mathbf{s}_\text{ref}$ from CNNDM, we start from randomly pick a summary text from train split and optimize for $\mathbf{\hat{s}}_{\text{emu}, i=0}$. We then pick the $\mathbf{s}_\text{ref}$ that is farthest away from $\mathbf{\hat{s}}_{\text{emu}, i=0}$ to optimize for $\mathbf{\hat{s}}_{\text{emu}, i=1}$, with $\mathbf{\hat{s}}_{\text{emu}, i=1}$ as initial population. Practically, we found that we can stop iterating when $i = 5$. Each iteration takes less than two hours on a 2vCPU (Intel Xeon @ 2.30GHz).

\begin{table*}[t]
\scriptsize
\begin{tabular}{llllllll}
\hline
System                                        & ROUGE-1 & ROUGE-2 & ROUGE-L & ROUGE-A.M. & ROUGE-G.M. & METEOR & BERTScore \\
\hline
Pointer-generator(coverage)~\cite{see-etal-2017-get} & 39.53   & 17.28   & 36.38   & 31.06    & 29.18    & 33.1  & 86.44    \\
Bottom-Up~\cite{gehrmann-etal-2018-bottom}           & 41.22   & 18.68   & 38.34   & 32.75    & 30.91    & 34.2  & 87.71    \\
PNBERT~\cite{zhong-etal-2019-searching}             & 42.69   & 19.60   & 38.85   & 33.71    & 31.91    & \textbf{41.2}  & 87.73    \\
T5~\cite{raffel2019exploring}                 & 43.52   & 21.55   & 40.69   & 35.25    & 33.67    & 38.6  & \underline{88.66}    \\
BART~\cite{lewis-etal-2020-bart}                     & 44.16   & 21.28   & 40.90   & 35.45    & 33.75    & 40.5  & 88.62    \\
SimCLS~\cite{liu-liu-2021-simcls}                   & 46.67   & \textbf{22.15}   & 43.54   & \underline{37.45}    & \textbf{35.57}    & 40.5  & \textbf{88.85}    \\
\hline
Scrambled code + broken                       & \underline{46.71}   & 20.39   & \underline{43.56}   & 36.89    & 34.62    & 39.6  & 87.80     \\
Scrambled code + broken   (alter)             & \textbf{48.18}   & 19.84   & \textbf{45.35}   & \textbf{37.79}    & \underline{35.13}    & \underline{40.6}  & 87.80    \\
\hline
\end{tabular}
\caption{Results on CNNDM. Besides ROUGE-1/2/L, METEOR, and BERTScore, we also compute the arithmetic mean (A.M.) and geometric mean (G.M.) of ROUGE-1/2/L, which is commonly adopted~\cite{zhang-etal-2019-pretraining,bae-etal-2019-summary,chowdhery2022palm}. The best score in each column is in bold, the runner-up underlined. Our attack system is compared with well-known summarizers from the past five years. The alternative version (last row) of our system changes $C$ in Algorithm~\ref{alg:b2s} from 3 to 2.}
\label{tab:result}
\end{table*}
\section{Results}
We compare ROUGE-1/2/L, METEOR, and BERTScore of our threat model with that achieved by the top summarizers in Table~\ref{tab:result}. We present two versions of threat models with a minor difference. As the results indicate, each version alone can exceed state-of-the-art summarizing algorithms on both ROUGE-1 and ROUGE-L. For METEOR, the threat model ranks second. As for ROUGE-2 and BERTScore, the threat model can score higher than other BERT-based summarizing algorithms\footnote{except MatchSum~\cite{zhong-etal-2020-extractive} and DiscoBERT~\cite{xu-etal-2020-discourse}, where our method is about 0.5 lower in ROUGE-2. We present the same results in tables with additional target thresholds in Appendix~\ref{sec:additional}}. Overall, we rank the systems by averaging their three relative ranking on ROUGE\footnote{Conservatively, We take geometric mean~\cite{chowdhery2022palm}. Combining metrics in other ways shows similar trends.}, METEOR, and BERTScore; our threat model gets runner-up (2.7), right behind SimCLS (1.7) and ahead of BART (3.3). This suggests that at the system level, even a combination of mainstream metrics is questionable in justifying the excellence of the summarizer.


These results reveal low robustness of popular metrics and how certain models can obtain high scores with inferior summaries. For example, our threat model is able to grasp the essence of ROUGE-1/2/L using a general but lightweight model, which requires less running time than summarizing algorithms. The training strategies for the model and word order are trivial. Not surprisingly, its output texts do not resemble human understandable "summaries" (Table~\ref{tab:example}).


\section{Discussion}

\subsection{How does Shortcut Learning Come about?}
As suggested in the hypothetical story by \citeauthor{geirhos2020shortcut}, scoring draws students’ attention~\cite{filighera2022cheating} and Bob is thus considered a better student. Similarly, in automatic summarization, there are already works that are explicitly optimized for various scoring systems~\cite{jauregi-unanue-etal-2021-berttune,pasunuru-bansal-2018-multi}. Even in some cases, people subscribe more to automatic scoring than "aspects of good summarization". For example, \citet{pasunuru-bansal-2018-multi} employ reinforcement learning where entailment is one of the rewards, but in the end, ROUGE, not textual entailment, is the only justification for this summarizer.

We use a threat model to show that optimizing toward a flawed indicator does more harm than good. This is consistent with the findings by \citeauthor{paulus2018a} but more often, not everyone scrutinizes the output like \citeauthor{paulus2018a} do, and these damages can be overshadowed by a staggering increase in metrics, or made less visible by optimizing with other objectives. This is also because human evaluations are usually only used as a supplement, and it is only one per cent of the scale of automatic scoring, and how human evaluations are done also varies from group to group~\cite{van2021human}. 


\subsection{Simple defence}
For score robustness, we believe that simply taking more scores as benchmark~\cite{gehrmann-etal-2021-gem} may not be enough. Instead, fixing the existing scoring system might be a better option. A well-defined attack leads to a well-defined defence. Our attacks can be detected, or neutralised through a few defences such as adversarial example detection~\cite{xu2017feature,metzen2017detecting,carlini2017adversarial}. During the model inference phase, detectors, determining if the sample is fluent/grammatical, can be applied before the input samples are scored. An even easier defence is to check whether there is a series of non-alphanumeric characters. Practically, grammar-based measures, like grammatical error correction (GEC\footnote{\url{https://github.com/PrithivirajDamodaran/Gramformer}}), could be promising~\cite{napoles-etal-2016-theres,novikova-etal-2017-need}, although they are also under development. To account for grammar in text, one can also try to parse predictions and references, and calculate F1-score of dependency triple overlap~\cite{riezler-etal-2003-statistical,clarke-lapata-2006-models}. Dependency triples compare grammatical relations of two texts. We found both useful to ensure input sanitization (Table~\ref{tab:defence}).


\begin{table}[t]
\centering
\scriptsize
\begin{tabularx}{0.5\textwidth}{Xll}
\hline
System                                           & Parse & GEC \\
\hline
Pointer-generator(coverage)~\cite{see-etal-2017-get}           & 0.131          & \underline{1.73}         \\ 
Bottom-Up~\cite{gehrmann-etal-2018-bottom}                     & 0.145          & 1.88        \\
PNBERT~\cite{zhong-etal-2020-extractive}                     & 0.179          & 2.15            \\
T5~\cite{raffel2019exploring}                        & \underline{0.198}          & \textbf{1.59} \\
BART~\cite{lewis-etal-2020-bart}                         & 0.170          & 2.07          \\
SimCLS~\cite{liu-liu-2021-simcls}                         & \textbf{0.202} & 2.17        \\
\hline
Scrambled code + broken                         & 0.168          & 2.64      \\
\hline

\end{tabularx}
\caption{\label{tab:defence}
Input sanitization checks, Parse and GEC, on the 100-sample CNNDM test split given by \citet{graham-2015-evaluating}. They penalize non-summary texts, but may introduce more disagreement with human evaluation, \emph{e.g.}, high-scoring Pointer-generator on GEC. Thus, their actual summary-evaluating capabilities on linguistic features (grammar, dependencies, or co-reference) require further investigation.
}
\end{table}

\subsection{Potential Objections on the Proposed Attacks}
\paragraph{The Flaw was Known.}
That many summarization scoring can be gamed is well known. For example, ROUGE grows when prediction length increases~\cite{sun-etal-2019-compare}. ROUGE-L is not reliable when output space is relatively large~\cite{krishna-etal-2021-hurdles}. That ROUGE correlates badly with human judgments at a system level has been revealed by findings of \citeauthor{paulus2018a}. And, BERTScore does not improve upon the correlation of ROUGE~\cite{fabbri-etal-2021-summeval,gehrmann-etal-2021-gem}.

The current work goes beyond most conventional arguments and analyses against the metrics, and actually constructs a system that sets out to game ROUGE, METEOR, and BERTScore together. We believe that clearly showing the vulnerability is beneficial for scoring remediation efforts. From a behavioural viewpoint, each step of defence against an attack makes the scoring more robust. Compared with findings by \citeauthor{paulus2018a}, we cover more metrics, and provide a more thorough overthrow of the monotonicity of the scoring systems, \emph{i.e.}, outputs from our threat model are significantly worse.

\paragraph{Shoddy Attack?}
The proposed attack is easy to detect, so its effectiveness may be questioned. In fact, since we are the first to see automatic scoring as a decent NLU task and attack the most widely used systems, evasion attacks are relatively easy. This just goes to show that even the crudest attack can work on these scoring systems. Certainly, as the scoring system becomes more robust, the attack has to be more crafted. For example, if the minimum accepted input to the scoring system is a "grammatically correct" sentence, an attacker may have to search for fluent but factually incorrect sentences. With a contest like this, we may end up with a robust scoring system.

As for attack scope, we believe it is more urgent to explore popular metrics, as they currently have the greatest impact on summarization. Nonetheless, we will expand to a wider range of scoring and catch up with emerging ratings such as BLEURT~\cite{sellam-etal-2020-bleurt}.

\subsection{Potential Difficulties}
Performing evasion attacks with bad texts is easy, when texts are as bad as broken sentences or scrambled codes in Table~\ref{tab:example}. In this case, the output of the threat system does not need to be scrutinized by human evaluators. However, human evaluation of attack examples may be required to identify more complex flaws, such as untrue statements or those that the document does not entail. Therefore, more effort may be required when performing evasion attacks on more robust scoring systems.


\section{Conclusion}
We hereby answer the question: it is easy to create a threat system that simultaneously scores high on ROUGE, METEOR, and BERTScore using worse text. In this work, we treat automatic scoring as a regression machine learning task and conduct evasion attacks to probe its robustness or reliability. Our attacker, whose score competes with top-level summarizers, actually outputs non-summary strings. This further suggests that current mainstream scoring systems are not a sufficient condition to support the plausibility of summarizers, as they ignore the linguistic information required to compute sentence proximity. Intentionally or not, optimizing for flawed scores can prevent algorithms from summarizing well. The practical effectiveness of existing summarizing algorithms is not affected by this, since most of them optimize maximum likelihood estimation. Based on the exposed vulnerabilities, careful fixes to scoring systems that measure summary quality and sentence similarity are necessary.

\section*{Ethical considerations}
The techniques developed in this study can be recognized by programs or humans, and we also provide defences. Our intention is not to harm, but to publish such attacks publicly so that better scores can be developed in the future and to better guide the development of summaries. This is similar to how hackers publicly expose bugs/vulnerabilities in software. This shows that our work has long-term benefits for the community. Our attacks are not against real-world machine learning systems.

\section*{Limitations}
We have only attacked the three most widely adopted scoring schemes that have already in summarization literature. However, there are emerging scoring schemes like BLEURT~\cite{sellam-etal-2020-bleurt}, which will be studied in our future work.





\bibliography{anthology,custom}
\bibliographystyle{acl_natbib}

\appendix
\section{Packages}
For evaluation metrics, we used the following packages:
\begin{itemize}
    \item For ROUGE metrics~\cite{lin-hovy-2003-automatic}, we used the public \emph{rouge-score} package from Google Research: \\ \url{https://github.com/google-research/google-research/tree/master/rouge}
    \item For METEOR~\cite{lavie-agarwal-2007-meteor}, we used the public Natural Language Toolkit:\\
    \url{https://www.nltk.org/_modules/nltk/translate/meteor_score.html}
    \item For BERTScore~\cite{zhang2019bertscore}, we used the public \emph{datasets} package from Huggingface:\\
    \url{https://huggingface.co/metrics/bertscore}
\end{itemize}


\section{Additional Comparison with More Summarization Systems}
\label{sec:additional}
We present the same results in Table~\ref{tab:result} with additional systems in Table~\ref{tab:additional}. Table~\ref{tab:additional} also shows that about half of the listed works employ human evaluation to support the effectiveness of summarization systems.


\begin{landscape}
\begin{table}[t]
\scriptsize
\centering
\begin{tabularx}{\linewidth}{Xllllllllll}
\hline
System          & ROUGE-1    & ROUGE-2   & ROUGE-L   & Average R-Rank & ROUGE-A.M. & ROUGE-G.M. & METEOR   & BERTScore   & Average Rank & Human Eval \\
\hline
Pointer-generator   + coverage ~\citealp{see-etal-2017-get} & 39.53 (34) & 17.28 (33) & 36.38 (33) & 33.33 & 31.06 & 29.18 & 33.1 (16) & 86.44 (15) & 26.20 &     \\
SummaRuNNer                    ~\citealp{nallapati2017summarunner} & 39.6  (33) & 16.2  (34) & 35.3  (34) & 33.67 & 30.37 & 28.29 &          &           & 33.67 &     \\
Pointer + EntailmentGen        ~\citealp{guo-etal-2018-soft} & 39.81 (32) & 17.64 (31) & 36.54 (31) & 31.33 & 31.33 & 29.50 &          &           & 31.33 & yes \\
REFRESH                        ~\citealp{narayan-etal-2018-ranking} & 40.00 (31) & 18.20 (25) & 36.60 (30) & 28.67 & 31.60 & 29.87 & \textbf{43.2} (1) & 87.15 (14) & 20.20 & yes \\
ML+RL ROUGE                    ~\citealp{kryscinski-etal-2018-improving} & 40.19 (30) & 17.38 (32) & 37.52 (25) & 29.00 & 31.70 & 29.70 &          &           & 29.00 & yes \\
                               ~\citealp{li-etal-2018-improving-neural} & 40.30 (29) & 18.02 (27) & 37.36 (26) & 27.33 & 31.89 & 30.05 &          &           & 27.33 & yes \\
ROUGESal+Ent RL                ~\citealp{pasunuru-bansal-2018-multi} & 40.43 (28) & 18.00 (28) & 37.10 (28) & 28.00 & 31.84 & 30.00 &          &           & 28.00 &     \\
RL + pg + cbdec                ~\citealp{jiang-bansal-2018-closed} & 40.66 (27) & 17.87 (30) & 37.06 (29) & 28.67 & 31.86 & 29.97 &          &           & 28.67 & yes \\
end2end w/ inconsistency loss  ~\citealp{hsu-etal-2018-unified} & 40.68 (26) & 17.97 (29) & 37.13 (27) & 27.33 & 31.93 & 30.05 &          &           & 27.33 & yes \\
Latent                         ~\citealp{zhang-etal-2018-neural} & 41.05 (25) & 18.77 (21) & 37.54 (24) & 23.33 & 32.45 & 30.70 &          &           & 23.33 &     \\
Bottom-Up Summarization        ~\citealp{gehrmann-etal-2018-bottom} & 41.22 (24) & 18.68 (24) & 38.34 (19) & 22.33 & 32.75 & 30.91 & 34.2 (15) & 87.71 (11) & 18.60 &     \\
EditNet                        ~\citealp{moroshko-etal-2019-editorial} & 41.42 (23) & 19.03 (19) & 38.36 (18) & 20.00 & 32.94 & 31.15 &          &           & 20.00 &     \\
rnn-ext + RL                   ~\citealp{chen-bansal-2018-fast} & 41.47 (22) & 18.72 (22) & 37.76 (22) & 22.00 & 32.65 & 30.83 & 36.7 (13) & 87.37 (13) & 18.40 & yes \\
BanditSum                      ~\citealp{dong-etal-2018-banditsum} & 41.50 (21) & 18.70 (23) & 37.60 (23) & 22.33 & 32.60 & 30.79 & 39.2 (9) & 87.41 (12) & 17.60 & yes \\
                               ~\citealp{li-etal-2018-improving} & 41.54 (20) & 18.18 (26) & 36.47 (32) & 26.00 & 32.06 & 30.20 &          &           & 26.00 & yes \\
NeuSUM                         ~\citealp{zhou-etal-2018-neural-document} & 41.59 (19) & 19.01 (20) & 37.98 (20) & 19.67 & 32.86 & 31.08 & 39.9 (7) & 88.18 (5) & 14.20 & yes \\
DCA                            ~\citealp{celikyilmaz-etal-2018-deep} & 41.69 (18) & 19.47 (18) & 37.92 (21) & 19.00 & 33.03 & 31.34 &          &           & 19.00 & yes \\
Two-Stage + RL                 ~\citealp{zhang-etal-2019-pretraining} & 41.71 (17) & 19.49 (17) & 38.79 (17) & 17.00 & 33.33 & 31.59 & 35.3 (14) & 87.97 (6) & 14.20 &     \\
HIBERT                         ~\citealp{zhang-etal-2019-hibert} & 42.37 (16) & 19.95 (12) & 38.83 (16) & 14.67 & 33.72 & 32.02 &          &           & 14.67 & yes \\
PNBERT                         ~\citealp{zhong-etal-2019-searching} & 42.69 (15) & 19.60 (16) & 38.85 (15) & 15.33 & 33.71 & 31.91 & 40.3 (6) & 87.73 (9) & 12.20 &     \\
BERT-ext + RL                  ~\citealp{bae-etal-2019-summary} & 42.76 (14) & 19.87 (13) & 39.11 (14) & 13.67 & 33.91 & 32.15 &          &           & 13.67 & yes \\
UniLM                          ~\citealp{dong2019unified} & 43.33 (12) & 20.21 (11) & 40.51 (11) & 11.33 & 34.68 & 32.86 & 38.6 (10) & 88.51 (4) & 9.60  &     \\
T5                             ~\citealp{raffel2019exploring} & 43.52 (11) & \underline{\underline{21.55}} (3) & 40.69 (8) & 7.33  & 35.25 & 33.67 & 38.6 (10) & \underline{88.66} (2) & 6.80  &     \\
DiscoBERT                      ~\citealp{xu-etal-2020-discourse} & 43.77 (10) & 20.85 (8) & 40.67 (9) & 9.00  & 35.10 & 33.36 &          &           & 9.00  & yes \\
BertSum                        ~\citealp{liu-lapata-2019-text} & 43.85 (9) & 20.34 (10) & 39.90 (12) & 10.33 & 34.70 & 32.89 &          &           & 10.33 &     \\
BART                           ~\citealp{lewis-etal-2020-bart} & 44.16 (8) & 21.28 (5) & 40.90 (7) & 6.67  & 35.45 & 33.75 & 40.5 (4) & \underline{\underline{88.62}} (3) & 5.40  & yes \\
PEGASUS                        ~\citealp{zhang2020pegasus} & 44.17 (7) & 21.47 (4) & 41.11 (6) & 5.67  & 35.58 & 33.91 &          &           & 5.67  &     \\
HeterGraph                     ~\citealp{wang-etal-2020-heterogeneous} & 42.95 (13) & 19.76 (15) & 39.23 (13) & 13.67 & 33.98 & 32.17 & 39.7 (8) &           & 12.25 &     \\
ProphetNet                     ~\citealp{qi-etal-2020-prophetnet} & 44.20 (6) & 21.17 (6) & 41.30 (5) & 5.67  & 35.56 & 33.81 &          &           & 5.67  &     \\
MatchSum                       ~\citealp{zhong-etal-2020-extractive} & 44.41 (5) & 20.86 (7) & 40.55 (10) & 7.33  & 35.27 & 33.49 & \underline{41.4} (2) & 87.72 (10) & 6.80  &     \\
Gsum                           ~\citealp{dou-etal-2021-gsum} & 45.94 (4) & \textbf{22.32} (1) & 42.48 (4) & \underline{3.00}  & \underline{\underline{36.91}} & \underline{35.18} &          &           & \underline{3.00}  & yes \\
SimCLS                         ~\citealp{liu-liu-2021-simcls} & \underline{\underline{46.67}} (3) & \underline{22.15} (2) & \underline{\underline{43.54}} (3) & \textbf{2.67}  & \underline{37.45} & \textbf{35.57} & 40.5 (4) & \textbf{88.85} (1) & \textbf{2.60}  &     \\
\hline
Scrambled code + broken                        & \underline{46.71} (2) & 20.39 (9) & \underline{43.56} (2) & \underline{\underline{4.33}}  & 36.89 & 34.62 & 37.5 (12) & 87.8  (7) & 6.40  &     \\
Scrambled code + broken (alter)                     & \textbf{48.18} (1) & 19.84 (14) & \textbf{45.35} (1) & 5.33  & \textbf{37.79} & \underline{\underline{35.13}} & \underline{\underline{40.6}} (3) & 87.8  (7) & \underline{\underline{5.20}}  &    
           \\
\hline
\end{tabularx}
\caption{ROUGE, METEOR, and BERTScore of various summarizers on the CNNDM test set. Ranking of each number in each column is indicated in parentheses. We calculate the average of the ranking, and the smaller the number, the better the ranking. The arithmetic mean (A.M.) and geometric mean (G.M.) of ROUGE-1/2/L obtained by each system (each row) are computed. The \textbf{best score} in each column is in bold, the \underline{runner-up} is underlined, and the \underline{\underline{second runner-up}} is underlined with two lines. Our attack system is compared with well-known summarizers from the past five years. The alternative version (last row) of our system changes $C$ in Algorithm~\ref{alg:b2s} from 3 to 2.}
\label{tab:additional}
\end{table}
\end{landscape}
 

\end{document}
