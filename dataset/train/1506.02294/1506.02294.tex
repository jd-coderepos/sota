\documentclass{sig-alternate-05-2015}
\usepackage{graphicx,color,url,footmisc}
\usepackage{booktabs}
\usepackage{synttree}
\usepackage{multirow}
\usepackage{amsmath} 
\usepackage{caption}
\newcounter{copyrightbox}
\usepackage{subfig}
\usepackage{balance}


\newcommand{\mf}[1]{{\small\color{red}[Mario: #1]}}
\newcommand{\neil}[1]{{\small\color{green}[Neil: #1]}}
\newcommand{\mat}[1]{{\small\color{blue}[Mathias: #1]}}

\newcommand{\ie}{{\em i.e.}}
\newcommand{\eg}{{\em e.g.}}

 \newcommand{\myparatight}[1]{\smallskip\noindent{\bf {#1}:}~}

\newenvironment{packeditemize}{\begin{list}{}{\setlength{\itemsep}{2pt}\addtolength{\labelwidth}{4pt}\setlength{\leftmargin}{20pt}\setlength{\listparindent}{\parindent}\setlength{\parsep}{0pt}\setlength{\topsep}{0pt}}}{\end{list}}


\begin{document}

 \CopyrightYear{2016} 
\setcopyright{acmcopyright}
\conferenceinfo{ASIA CCS '16,}{May 30-June 03, 2016, Xi'an, China}
\isbn{978-1-4503-4233-9/16/05}\acmPrice{\sst_ix_iy_ip_ia_it_ix_iy_ip_ia_iissss_as_byyyyyssunumnS(u)s\in S(u)tT(u, s, t)uss\in S(u)tsT(u, s, t)tT(u,s', t)s'\in S(u)-\{s\}tc(u,s,t)2nsS(u)stc(u, s, t)S(u)s_as_bs_cs_ds_es_as_bs_cs_ds_es_as_bs_cs_ds_es_as_bs_cs_ds_exs_xx\in \{a,b,c,d,e\}xs_xx\in \{a,b,c,d,e\}xxs_xx\in \{a,b,c,d,e\}xx\in \{a,b,c,d,e\}uuxs_xx\in\{a, b, c,d,e\}uxus_xux\in\{a, b, c,d,e\}xs_xx\in\{a, b, c,d,e\}xx\{s_a,s_b,s_c,s_d,s_e\}s_xxx\in\{a,b,c,d,e\}s_as_bs_cs_ds_es_as_bs_cs_ds_eU_dF=\{1,2,3,4,5\}f(u,s,i)iusi\in Fs\in \{s_a,s_b,s_c,s_d,s_e\}uiixus_x\cup_{j\in
F-\{i\}}f(u,s_x,j)s_x\cup_{v\in U_d-\{u\}}\cup_{j\in F-\{i\}}f(u,s_x,j)x\in\{a,b,c,d,e\}xus_x\cup_{j\in
F-\{i\}}f(u,s_x,j)u\cup_{j\in F-\{i\}}f(u,s_y,j)y\in \{a,b,c,d,e\}/\{x\}\cup_{v\in U_d-\{u\}}\cup_{j\in
F-\{i\}}f(u,s_z,j)z\in\{a,b,c,d,e\}x\in\{a,b,c,d,e\}uf(u,s_x,i)xxx\in
\{a,b,c,d,e\}\cup_{v\in U_d-\{u\}} f(v,s_z,i)z\in\{a,b,c,d,e\}f(u,s_z,i)z\in\{a,b,c,d,e\}TT_s^{-1}T_ss_as_bs_as_axyxys_ys_xx,y\in\{a,b,c,d,e\}s_as_bs_cs_ds_es_as_bs_cs_ds_ea\max\{\text{RA-}ay\}y\in \{a,b,c,d,e\}aab\max\{\text{RA-}by\}y\in \{a,b,c,d,e\}bbc\max\{\text{RA-}cy\}y\in \{a,b,c,d,e\}ccd\max\{\text{RA-}dy\}y\in \{a,b,c,d,e\}dde\max\{\text{RA-}ey\}y\in \{a,b,c,d,e\}eexyx,y\in \{a,b,c,d,e\}xyx,y\in \{a,b,c,d,e\}xyx,y\in \{a,b,c,d,e\}xyx,y\in \{a,b,c,d,e\}eabaeaeeaeeeaeeaeesss\{s_a,s_b, s_c,s_d,s_e\}xyxys_ys_xx,y\in\{a,b,c,d,e\}s_xx\max\{\text{RA}\text{-}xy\}y\in\{a,b,c,d,e\}xxx\in\{a,b,c,d,e\}xyx,y\in \{a,b,c,d,e\}\frac{1}{25}xyx,y\in \{a,b,c,d,e\}\frac{1}{25}s_e\{s_a,s_b\}\{s_a,s_b,s_c\}\{s_a,s_b,s_c,s_d\}\{s_a,s_b,s_c,s_d,s_e\}\{s_a,s_e\}\{s_a,s_c,s_e\}\{s_a,s_b,s_c,s_e\}\{s_a,s_c,s_d,
s_e\}\{s_a,s_b,s_c,s_d,s_e\}\frac{1}{n}ns_es_e$') are all close to 50\%, and thus are ignored to better contrast the
differences of other EERs. 

We find that EERs converge very fast. In particular, after 2 minutes (around 30
strokes),  EERs are stable or slightly fluctuate. Moreover, after collecting
 strokes, training a classifier is finished within 1
second.





 


  



\subsection{Summary}
Our observations can be summarized as follows:
\begin{packeditemize}
\item Users can subconsciously adapt their behavior to different screen settings, 
i.e., transitions between settings do  not affect user experiences.
\item Our authentication mechanism achieves 
much smaller EERs than previous work for both random attacks and targeted attacks.  
\item Our authentication system achieves smaller EERs with more screen settings.  
\item Learning our classifiers is fast, i.e., strokes collected within two minutes are enough to stabilize  EERs.
\end{packeditemize}







\section{Discussion}
\label{discussion}
\myparatight{Training human attackers} To mimic the targeted user's touch
behavior, a human attacker needs to be trained to produce touch strokes whose
features are close to those of the targeted user. We note that Meng et
al.~\cite{tey2013can} proposed an interactive system to train a human attacker
to reproduce  \emph{keystroke dynamics} of the targeted user for a \emph{given
short password}. Specifically, they consider  features of keystroke dynamics are
constructed from 2-grams, and thus changing the keystroke timing of a character
only influences features of the local two 2-grams. For instance, suppose we have
a password with three characters ABC, changing the keystroke timing of B only
influences the features of AB and BC. Thus,  it is possible to train a human
attacker to reproduce the keystroke dynamics of a given short password via
greedily changing the keystroke timings of characters one by one. 

However,  reproducing touch strokes could be much harder than reproducing
keystroke dynamics. This is because 1) we have around 30 touch features, 2)
changing one touch point could result in changes of a few features, and 3) the
human attacker needs to learn how the targeted user would adapt to different
screen settings. Nevertheless, it is an interesting future work to explore the
possibility/impossibility of training human attackers to mimic a targeted user.

\myparatight{Fixing one screen setting to perform targeted attacks} A robot can
keep replaying touch data collected in a fixed screen setting to attack our
authentication system. The expected number of tries until the robot is using the
correct screen setting would then be  the total number of
screen settings. Once the robot gets the correct setting, the robot can use the
mobile device for a time interval during which the setting is unchanged. 

However, this attack can be blocked with a high probability by combing our
touch-based authentication with PINs. Specifically, once we detect suspicious
touch data, we ask the user to type in the backup PIN. 


\myparatight{Detecting screen settings with specialized intelligent robots} An
intelligent robot that is equipped with specialized sensors could potentially
detect the screen settings using some Artificial Intelligence (AI) algorithms,
and detecting the screen settings could enable the attacker (e.g., a friend or
spouse of the targeted user) to perform better targeted attacks.  For instance,
a robot with a camera could possibly detect the screen settings by using
computer vision algorithms to compare its raw touch data (collected via the
camera) on the screen and the movements (again, collected via the camera) of the
running application. However, the robot still needs to generate a few touch
strokes (these strokes may be from a screen setting that is different from the
one used by our authentication system) before the screen setting is detected,
during which our authentication scheme might already successfully reject the
attacker. Moreover,  it might not be easy for the attacker to get such a
specialized robot, which is true at least for now, given the current state of
AI. Therefore, we focus on robots that are commercialized and easy to get.  


\myparatight{Leveraging sloppiness and jitter} Screen settings could also adjust
sloppiness and jitter other than the distortions along the X axis and the Y axis
studied in this paper.  Sloppiness controls how far the user has to move the
finger on the screen to send a movement to the applications and jitter controls
what distortions from a straight line on the screen are still considered as a
movement by the applications. It is an interesting future work to explore the
impact of sloppiness and jitter on the performance of defending against forgery
attacks in our authentication system.



\section{Conclusion and Future Work}\label{sec:conclusion}



In this work, we design a new touch-based continuous authentication system
 to defend against forgery attacks by leveraging the impact of screen 
settings on a user's touch behaviors.  First, we find that, when screen settings are discretized properly, a user's
touch behaviors in two different settings are both \emph{stable} and
\emph{sensitive}.  Second, based on these findings, we design a new authentication system called
\emph{adaptive touch-based continuous authentication}. The key idea is to randomly sample a predefined screen setting  in each time interval. The attacker cannot know the screen setting at the time of attacks. 
Third, we evaluate our system by collecting
data from 25 subjects in five screen settings. We find that  users can subconsciously 
adapt their touch behavior to different screen settings, 
i.e., transitions between settings do not interrupt users nor affect user experiences. 
 Moreover, we observe that our system
significantly outperforms previous work at defending against both random forgery
attacks and targeted forgery attacks, the registration phase of our system takes a short
period of time,  and our system can better defend  against forgery attacks with more 
screen settings.

Future work includes performing a large-scale study about our authentication system in the wild, investigating more types of screen settings,  and 
exploring more advanced attacks to touch-based authentication systems.

\balance
{
\bibliographystyle{abbrv}
\begin{thebibliography}{10}

\bibitem{AttackingAndroidFaceAuthentication}
{Attacking Android Face Authentication}.
\newblock \url{https://www.youtube.com/watch?v=BwfYSR7HttA}.

\bibitem{AttackingAndroidFaceAuthenticationLiveness}
{Attacking Android Liveness Check}.
\newblock \url{https://www.youtube.com/watch?v=zYxphDK6s3I}.

\bibitem{Bee}
{Bee}.
\newblock \url{http://www.usvigilant.com/bee/}.

\bibitem{bo2013silentsense}
C.~Bo, L.~Zhang, X.-Y. Li, Q.~Huang, and Y.~Wang.
\newblock Silentsense: silent user identification via touch and movement
  behavioral biometrics.
\newblock In {\em MobiCom}, 2013.

\bibitem{NolockSOUPS13}
D.~V. Bruggen, S.~Liu, M.~Kajzer, A.~Striegel, C.~R. Crowell, and J.~D'Arcy.
\newblock Modifying smartphone user locking behavior.
\newblock In {\em SOUPS}, 2013.

\bibitem{chang2011libsvm}
C.-C. Chang and C.-J. Lin.
\newblock Libsvm: a library for support vector machines.
\newblock {\em ACM TIST}, 2(3), 2011.

\bibitem{svm2}
C.~Cortes and V.~Vapnik.
\newblock Support-vector networks.
\newblock In {\em Machine Learning}, volume~20, pages 273--297, 1995.

\bibitem{CSDN}
{CSDN passwork leak}.
\newblock \url{goo.gl/hn0Cr6}.

\bibitem{munichGuys}
A.~De~Luca, A.~Hang, F.~Brudy, C.~Lindner, and H.~Hussmann.
\newblock Touch me once and i know it's you!: Implicit authentication based on
  touch screen patterns.
\newblock In {\em CHI}, 2012.

\bibitem{whylockCCS14}
S.~Egelman, S.~Jain, R.~S. Portnoff, K.~Liao, S.~Consolvo, and D.~Wagner.
\newblock Are you ready to lock? understanding user motivations for smartphone
  locking behaviors.
\newblock In {\em CCS}, 2014.

\bibitem{fingerprintForgeryAttack}
{Fogery Attacks to Fingerprint}.
\newblock \url{http://www.ccc.de/en/updates/2013/ccc-breaks-apple-touchid}.

\bibitem{frank2013touchalytics}
M.~Frank, R.~Biedert, E.~Ma, I.~Martinovic, and D.~Song.
\newblock Touchalytics: On the applicability of touchscreen input as a
  behavioral biometric for continuous authentication.
\newblock {\em IEEE Transactions on Information Forensics and Security},
  8(1):136--148, 2013.

\bibitem{li2013unobservable}
L.~Li, X.~Zhao, and G.~Xue.
\newblock Unobservable reauthentication for smart phones.
\newblock In {\em NDSS}, 2013.

\bibitem{Nest}
{Nest Thermostat}.
\newblock \url{https://nest.com/}.

\bibitem{rockyou}
{Rockyou password leak}.
\newblock \url{goo.gl/hGwU5k}.

\bibitem{Sae-Bae:2012:BGN:2207676.2208543}
N.~Sae-Bae, K.~Ahmed, K.~Isbister, and N.~Memon.
\newblock Biometric-rich gestures: a novel approach to authentication on
  multi-touch devices.
\newblock In {\em CHI}, 2012.

\bibitem{sae2012investigating}
N.~Sae-Bae, N.~Memon, and K.~Isbister.
\newblock Investigating multi-touch gestures as a novel biometric modality.
\newblock In {\em IEEE BTAS}, 2012.

\bibitem{sae2014multitouch}
N.~Sae-Bae, N.~Memon, K.~Isbister, and K.~Ahmed.
\newblock Multitouch gesture-based authentication.
\newblock {\em IEEE transactions on information forensics and security},
  9(3-4):568--582, 2014.

\bibitem{attack-CCS13}
A.~Serwadda and V.~V. Phoha.
\newblock When kids' toys breach mobile phone security.
\newblock In {\em CCS}, 2013.

\bibitem{sherman2014user}
M.~Sherman, G.~Clark, Y.~Yang, S.~Sugrim, A.~Modig, J.~Lindqvist,
  A.~Oulasvirta, and T.~Roos.
\newblock User-generated free-form gestures for authentication: security and
  memorability.
\newblock In {\em MobiSys}, 2014.

\bibitem{sophos}
{Sophos Naked Security blog}.
\newblock Survey says 70\% don't password-protect mobiles: download free
  {M}obile {T}oolkit.
\newblock
  \url{http://nakedsecurity.sophos.com/2011/08/09/free-sophos-mobile-security-toolkit/}.
\newblock Published Aug 9, 2011.

\bibitem{tey2013can}
C.~M. Tey, P.~Gupta, and D.~Gao.
\newblock I can be you: Questioning the use of keystroke dynamics as
  biometrics.
\newblock In {\em NDSS}, 2013.

\bibitem{smartphoneMorethanPC}
{The Smartphone Market is Bigger Than the PC Market}.
\newblock
  \url{http://www.businessinsider.com/smartphone-bigger-than-pc-market-2011-2}.

\bibitem{Xu2014soups}
H.~Xu, Y.~Zhou, and M.~R. Lyu.
\newblock Towards continuous and passive authentication via touch biometrics:
  An experimental study on smartphones.
\newblock In {\em SOUPS}, 2014.

\end{thebibliography}

}




\end{document}
