\subsection{Basic Tests}  \label{sec:basic-tests}

\subsubsection{Null Replies}

The first question asked for each database is "How many NULL replies
are returned for IP address queries?". There are four flavors for
this question. First it is asked only on IPs which are in the core
of the PoPs and then it is asked for all IP addresses, including
singletons addresses. As some databases may have better information
on end users or access interfaces than on core routers and main
PoPs, this can be meaningful. The next observation regards NULL
replies that apply to all the IP addresses within a certain PoP:
does the database fail to cover a range of addresses or a physical
location range, or are the NULL replies a matter of a single IP
address lack of information? This too is considered both with and
without singletons. Table \ref{tab:nulldata} shows for each of the
databases the percentage of IP addresses which returned a NULL reply
for each of these questions.

\begin{table}
\begin{minipage}[b]{\linewidth}
\begin{center}
\small\addtolength{\tabcolsep}{-3pt}

\begin{tabular}{|l|c|c|c|c|}
 \hline   \bf{} & \multicolumn{2}{c|}{\bf{Core PoP IP }} & \multicolumn{2}{c|}{\bf{With Singletons
   }}\\
 \hline
    \bf{Database} & {\bf{Null IP }} & {\bf{Null PoP }} & {\bf{Null IP }} & {\bf{Null PoP}}\\
 \hline
     IPligence & 3.9\%&  1.5\% & 2.9\% & 1.4\% \\
\hline
     IP2Location & 0\%&  0\% & 0\% & 0\% \\
\hline
     MaxMind & 36\%&  10.6\% & 30.1\% & 6\% \\
\hline
     HostIP.Info & 64\%&  38.6\% & 64\% & 29\% \\
\hline
     GeoBytes & 20.7\%&  4.3\% & 17.8\% & 2.7\% \\
\hline
     NetAcuity & 0\%&  0\% & 0\% & 0\% \\
\hline
     Spotter & 37\%&  18.1\% &   &   \\
\hline
     DNS & 14.3\%& 12.2\% & 28.4\% &  2\%\\
\hline

\end{tabular}
\caption{Null IP Address Information } \label{tab:nulldata}
\end{center}
\end{minipage}
\end{table}
 
NetAcuity and IP2Location where the only databases to return a reply
for all the queried IP addresses. For IP2Location database there are
a few hundreds of NULL entries in the entire database (for IP
addresses not in this study). This alone does not come to indicate
that the returned addresses are correct, only that an entry exists.
The location correctness is discussed later on in this section. On
the other end of the scale, HostIP.info failed to locate most of the
IP addresses, however on the PoP level this percentage drops by
half. It can be assumed that HostIP.info nature of the failure is
lack of information on specific IP addresses and not IP ranges.
Further more, in most cases HostIP.info does return a reply with
country information, but without longitude and latitude. Spotter did
not locate about a third of the IP addresses. The reason for such a
failure can be either that the IP did not respond to ping or the IP
responded to ping, but the roundtrip-times were too high to provide
approximations for the algorithm. Only core PoP IP addresses,
without singletons, where tested here. For MaxMind, the percentage
of Null replies refers to events where no specific location
information was available. In most of these cases, MaxMind does
return longitude and latitude information, which are the center of
the country where the IP is located. A list of these coordinates is
available to the users, and though we choose in this work to refer
to this information as a NULL reply, a general notion of location is
provided by the database. DNS NULL replies are less than 15\% for
core PoP IP adresses, and almost 29\% when taking into account
singletons. As there is a probability that singletons represent end
users and not router interfaces, this is expected. The effect of
grouping to PoPs when looking at DNS is significant: when taking
into account singletons, only 2\% of the PoPs have no location by
DNS.


\subsubsection{Agreement within database}
By nature, IP addresses belonging to the same PoP reside in the same
area. One can leverage this information to evaluate the accuracy of
a geolocation database: if IP addresses that belong to the same PoP
are assigned different geographical location, then the accuracy of
this information should be questioned. This statement is based on
the assumption that the PoP algorithm is correct and does not assign
IP addresses from different locations to the same PoP. We
already discussed why it is true based on design and previous
limited evaluation.  Our experiments here further support the assumption:
in all the PoPs evaluated, with no
exception, there are always databases that support the PoP vicinity
requirement.


Figure \ref{fig:cdf_range} presents a CDF of the convergence range
within databases without singletons. The X-axis is the range of
convergence in kilometers, logarithmic scale, with 500km being the
limit where the algorithm was stopped. The algorithm progressed its
testing in steps of 1km.
\begin{figure}
\begin{minipage}[b]{\linewidth}
\centering
\includegraphics[width=8cm, height=5.5cm]{cdf_range}
\caption{Range of Convergence Within Databases}
\label{fig:cdf_range}
\end{minipage}
\end{figure}


IPligence and IP2Location clearly have a range of convergence far
better than other databases: over  of the PoPs located using
these databases have the minimal range of convergence - one
kilometer, which is in practice the exact same location. MaxMind,
GeoBytes and NetAcuity have  to  of their PoPs converge
within one kilometer. For HostIP.Info, a bit less than  of the
PoPs converge within the minimal range, and almost all the rest fail
to converge. This is caused mostly due to lack of information on IP
addresses, as many PoPs do not have even a single IP with location
information inside a PoP. The case of Spotter here is different. As
this information is acquired by measurements, having almost a third
of the PoPs converge within one kilometer is an indication of good
performance. In addition, over  of the PoPs converge within
, and close to 98\% within , which is similar or
better than most of the other databases. The slow accumulation is
expected due to measurements errors. Maybe the most important graph
here is the  graph, showing the range of convergence when
combining the information from all databases. Though all databases,
have most of their PoPs located within the minimal range, less than
 of the  PoPs converge within this range, meaning that
between the databases there is disagreement, though as the range
grows so does the percentage of converged PoPs. This does not
necessarily mean that all the databases have agreed on the same
location, as databases which reply with a location for every IP have
more influence that databases with some NULL replies. We further
explore this question in section \ref{subsec:compare}. An important
observation is that even if a certain database indicates that the
range of convergence of a PoP is minimal, i.e., 1km, it does not
necessarily imply accuracy, or in our case that all other databases
will agree with this location.



Figures \ref{fig:cdf_agreement_100k} and \ref{fig:cdf_agreement}
present a CDF of the agreement within databases without singletons.
The X axis marks the percentage of IP addresses in PoPs that
represent the majority, and the Y axis presents the probability for
this majority vote. For Figure \ref{fig:cdf_agreement_100k} we set a
radius of 100km and in Figure \ref{fig:cdf_agreement} the used
radius is 500km, within which a majority is required. In some cases
no majority is found, i.e., less than 50\% of the IP addresses are
within any circle with the given radius. Remember that the algorithm
selects in such a case the location based on the largest group of
votes.

\begin{figure}
\begin{minipage}[b]{\linewidth}
\centering
\includegraphics[width=8cm, height=5.5cm]{cdf_agreement_100km}
\caption{CDF of Agreement Within Databases, 100km Radius}
\label{fig:cdf_agreement_100k}
\end{minipage}
\end{figure}

\begin{figure}
\begin{minipage}[b]{\linewidth}
\centering
\includegraphics[width=8cm, height=5.5cm]{cdf_agreement}
\caption{CDF of Agreement Within Databases, 500km Radius}
\label{fig:cdf_agreement}
\end{minipage}
\end{figure}



Note that for all databases there are PoPs that had no majority
vote, meaning the locations diverged by more than 100km or 500km.
IPLigence and IP2Location have the highest probability to reach an
agreement within a PoP, while HostIP.Info, and Geobytes grow at the
slowest pace. For a radius of , Spotter does not reach full
agreement for almost 60\% of the PoPs, probably due to measurement
accuracy limitations. Interestingly, for less than 4\% of the PoPs
there is  agreement by all databases, which once again does
not correlate with single-database observations and points to a
mismatch between databases.



\subsection{Comparison Between Databases} \label{subsec:compare}
\subsubsection{Accuracy}
So far, we have discussed results that depend only on the database
itself. Next we compare the databases based on the data collected
from all databases. First, we asses the accuracy of a database by
comparing an IP location in every database to the location of its
PoP as voted by all databases.


\begin{figure}
\begin{minipage}[b]{\linewidth}
\centering
\includegraphics[width=8cm, height=5.5cm]{cdf_deviation_zoom}
\caption{CDF of database location deviation from PoP majority -
500km range} \label{fig:cdf_deviation_zoom}
\end{minipage}
\end{figure}

\begin{figure}
\begin{minipage}[b]{\linewidth}
\centering
\includegraphics[width=8cm, height=5.5cm]{cdf_deviation_region}
\caption{Breakdown of deviation from PoP majority CDF By region -
500km Range} \label{fig:cdf_deviation_region}
\end{minipage}
\end{figure}



\begin{figure}
\begin{minipage}[b]{\linewidth}
\centering
\includegraphics[width=8cm, height=5.5cm]{cdf_deviation}
\caption{CDF of Database location deviation from PoP majority}
\label{fig:cdf_deviation}
\end{minipage}
\end{figure}


Figure \ref{fig:cdf_deviation_zoom} depicts for each database the
CDF of the deviation of each IP from the PoP majority vote. The
interesting observations here consider  range, which is a city
range, and  range, which can be referred to as a region.
IPligence, MaxMind and IP2Location have a probability of 62\% to
73\% to place a IP within  from the PoP majority vote, with
IPligence and MaxMind placing over 80\% of the IP addresses within
 radius. Geobytes, HostIP.Info and Netacuity place 33\% to
47\% of the IP addresses within a city range, and 48\% to almost
60\% within  from the majority. Spotter places only 10\%
within  range and 30\% within the same region.

Some of the databases, like HostIP.Info, Netacuity, Geobytes and
Spotter, deviate less in Europe than in the USA and the rest of the
world, as depicted in Figure \ref{fig:cdf_deviation_region}. Other
databases, as IP2Location, have greater deviation in Europe than the
rest of the world. For clarity, only two of the databases are shown
in Figure \ref{fig:cdf_deviation_region}. A drawback of all
databases is that there is a long tail of IP addresses locations
which are placed  or more from the majority of the vote.
Figure \ref{fig:cdf_deviation} shows that in some databases this
tail can hold 15\% of the IP addresses. Although the majority vote
may be incorrect, this points that at least one of the databases is
very far off from the real IP address location.

Figure~\ref{fig:range2deviation} depicts for each database a scatter
plot of the range of convergence (X axis) versus the deviation of
the IP location from its PoP location based on all databases (Y
axis). The figure demonstrates that in many cases the range of
convergence is small , yet the deviation from the PoP majority vote
may be thousands of kilometers. Further more, a large range of
convergence does not imply that that the PoP center is necessarily
wrong, as again in all databases we see cases where the range is
large, yet the selected IP address location is the same as the
majority location from all databases. IPligence and IP2Location
demonstrate an interesting phenomenon: though their range of
convergence is very low, the variation from the PoP majority
location is very large. This can indicate, as is demonstrated next,
that large groups of IP addresses are assigned a single false
location.


For MaxMind and HostIP there are many PoPs at the far end of the
graph, with a large range of convergence. This is caused by lack of
information on specific IP addresses which does not allow them to
reach a majority vote. Netacuity and Spotter demonstrate a scattered
behavior, meaning the range of convergence and the deviation from
the PoPs majority both change. For Netacuity this means that IP
addresses are assigned distinct locations within the same area, as
with different users in the same city. Spotter suffers from large
range of convergence for some PoPs due to NULL replies, however
there is an obvious trend that places most PoPs IP addresses within
 range from each other, with a small number scattered at
larger range of convergance, as can be expected in a triangulation
based method.

\begin{figure}
\begin{minipage}[b]{\linewidth}
\centering
\includegraphics[width=8cm,height=9cm]{range2deviation}
\caption{Database location deviation from PoP majority vs. Range of
Convergance} \label{fig:range2deviation}
\end{minipage}
\end{figure}

\subsubsection{Correlation Between Databases}

While some of the databases have proprietary means to gather
location information, a large portion of geolocation databases is
likely to come from the same source, such as getting country
information from ARIN. To examine this theory we calculate the cross
correlation between every pair of databases, on the entire IP
address location vector, and display it as a heatmap, shown in
Figure \ref{fig:heatmap}.

\begin{figure}
\begin{minipage}[b]{\linewidth}
\centering
\includegraphics[width=8.5cm]{heatmap}
\caption{Cross Correlation Between Databases - Heatmap}
\label{fig:heatmap}
\end{minipage}
\end{figure}


The strongest correlation is between IPligence and IP2Location. As
was shown in previous results, the trends of these two databases
look very similar. The correlation between these two databases is
over . Maxmind and HostIP.Info also have very high correlation
with IP2Location and IPligence as well as between themselves. The
correlation figures above do not take into account NULL replies.
Considering those, IPligence's and IP2Location's correlation with
Maxmind drops to  and with HostIP.Info below . Comparing
all the databases, Netacuity and Geobytes correlate the least:
. Spotter has over  correlation with most databases,
expect Geobytes, with  correlation to Netacuity. Considering
that the location given by Spotter is never a landmark, rather a
result of delay measurement, this is a high figure. The high
correlation between the databases indicates that in most cases the
location addresses returned by all the databases will be very much
alike. In cases where it is difficult to obtain the location
address, the answers may vary significantly between services.

\subsection{Database Anomalies}
Though the results above may indicate that some databases have
superb location information, this is not the case. In many cases the
returned data is deceiving, and actually may represent lack of
information in the database. For example, we identified 266 IP
addresses in the PoPs that belong to Qwest Communications. Out of
those, 253 IP addresses are located by IPligence in Denver,
Colorado. Looking at the raw IPligence database, there are 20291
entries that belong to Qwest communications. Out of those, 
are located in Denver, which is the location of Qwest's
headquarters. The phenomenon was first detected by our algorithm
last year, in July/2009: 70 Qwest PoPs where detected. Maxmind
assigned them to 55 different locations, HostIP.info to 46
locations, IP2locations to 35 locations and IPligence located them
all in Denver. In response to a query back then, IPligence have
replied that "In some occasions you could find records belonging to
RIPE or any other registrar, these are most likely not used IP
addresses but registered under their name, anything else should be
empty or null".

Quite a similar case exists with IP2Location. For Cogent, 2365 out
of 2879 IP addresses were located in Washington DC, which is
Cogent's headquarters location. Out of 57 PoPs belonging to Cogent,
only one was not placed by IP2Location in these exact same
coordinates. For IPligence, all the PoPs were located in the same
place, too. However, Maxmind placed the PoPs in 13 locations,
Geobytes in 23 locations and Netacuity in 31 locations (only a
handful in Washington's area).
In the Akamai audit by Gomez~\cite{akamai_audit} a similar case
is described: A node in Vancouver, Canada was reported to be in
Tornto, and a node in Bangalore, India was reported to be in Mumbai.
In both cases those were ISP headquarters known locations.

Sometimes differences between databases may be very acute, with a
reported node location being far off by thousands of kilometers and
even countries far apart. In Figure \ref{fig:uunet_mismatch} one
such example is shown. We take a 4-nodes PoP in ASN 703 (Verizon/
UUNET / MCI Communications) and display on a map the location of the
PoP based on each of the geolocation database. IPligence,
IP2Location, Geobytes, Netacuity and DNS all internally have the PoP
four IP addresses at the same location, however each of the
databases locate it differently: IPligence and IP2Location in
Australia, Netacuity and DNS in Singapore and Geobytes in
Afghanistan. MaxMind and Spotter lack information on these nodes and
HostIP.Info places the PoP with 66\% certainty in China. Extending
our PoP view to include singletons, thus including 10 nodes, the
picture does not change.  MaxMind and Spotter have location on one
of the IPs and they place it in Singapore. IPligence and IP2location
place 9 out of 10 IPs in Australia, and one in Singapore. Geobytes
places this last IP address in Singapore too, yet 6 out of 10 IP
locations still point to Kabul. The rest three nodes are located in
Australia. Geobytes does give low certainty rate to the location,
being 50 or less to both country and region. Netacuity places 8 out
of 10 IPs in Singpore and 2 in Australia. HostIP.Info has location
information on 6 IPs, 3 of them are placed in China and 3 in
Australia, but in Melbourne, far from IPligence and IP2location
designated location. Notably, all the edges in this PoP have less
than 3.5mS delay and are measured five to 173 times each.


\begin{figure}
\begin{minipage}[b]{\linewidth}
\centering
\includegraphics[width=8cm,height=5cm]{uunet_mismatch}
\caption{Mismatch Between Databases - UUNET }
\label{fig:uunet_mismatch}
\end{minipage}
\end{figure}


The mismatch between databases is not uncommon. Some examples exist
inside the United States, too: in Figure
\ref{fig:gcrossing_mismatch} we show one PoP in ASN 3549, Global
Crossing, as it is placed by the different geolocation databases all
across the country. This PoP has over 160 IP addresses, counting
singletons, and as such a majority in each database has more
substance. IPligence places the PoP with more than 90\% majority in
Springfield, Missouri. MaxMind and IP2Location point to Saint Louis,
Missouri with 92\% and 82\% accordingly. NetAcuity indicates that
the PoP is in  San-Jose, California with 100\% certainty, while DNS
and Spotter place the PoP in this vicinity, in a radius of a few
tens of kilometers. GeoBytes has somewhat above 59\% of the
locations pointing to New York, with other common answers being
spread across California (25\%). Geobytes country certainty here was
100\% with 42\% region certainty for the IP addresses it located in
New York. HostIP.Info placed the PoP in Chicago with 65\% majority
(28\% of the locations had pointed to Santa Clara, California).

\begin{figure}
\begin{minipage}[b]{\linewidth}
\centering
\includegraphics[width=8cm]{gcrossing_mismatch}
\caption{Mismatch Between Databases - Global Crossing}
\label{fig:gcrossing_mismatch}
\end{minipage}
\end{figure}


The above are not single incidents. Similar cases have been found in
other AS as well, such as REACH (AS 4637), where IPligence,
IP2location and Maxmind located a PoP in China, Geobytes located it
in Australia, while Netacuity and Spotter put it in the silicon
valley, USA. Other cases range from AS16735 (CTBC/Algar Telecom)
where PoP locations in Brazil were set thousands of kilometers
apart, to Savvis (AS3561) which is another case of locations spread
across the USA.

\subsection{Database Changes}
One of the motivations to update geolocation databases is the claim
that they change significantly over time. Maxmind\cite{maxmind}
claim that it looses accuracy at a rate of approximately 1.5\% per
month. IP2Location~\cite{ip2location} state that on average, there
are 5\%-10\% of the records being updated in the databases every
month due to IP address range relocation and new range available.
Based on the PoPs dataset, we compare this information versus the
databases at our disposal. For IPligence, an average of
approximately one percent of the addresses changes every month, with
some minimal changes in some consecutive months, such as 0.6\%
between November and December 2009. In HostIP.Info, 18\% of the IP
addresses changed their location within nine months, meaning an
average of 2\% a month. IP2Location changed only 1\% of the
locations over 4 months, meaning 0.25\% per month, however the
reference set here included only 10K IP addresses. For Netacuity,
running only on our dataset of 104K IP addresses, we observe that
2.4\% of the IP addresses have changed in less than a month.
