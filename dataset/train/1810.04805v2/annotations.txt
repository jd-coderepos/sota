[{'LEADERBOARD': {'Task': 'Multimodal Intent Recognition', 'Dataset': 'PhotoChat', 'Metric': 'F1', 'Score': '53.2'}}, {'LEADERBOARD': {'Task': 'Multimodal Intent Recognition', 'Dataset': 'PhotoChat', 'Metric': 'Precision', 'Score': '56.1'}}, {'LEADERBOARD': {'Task': 'Multimodal Intent Recognition', 'Dataset': 'PhotoChat', 'Metric': 'Recall', 'Score': '50.6'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'MultiRC', 'Metric': 'F1', 'Score': '70.0'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'MultiRC', 'Metric': 'EM', 'Score': '24.1'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD1.1 dev', 'Metric': 'EM', 'Score': '86.2'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD1.1 dev', 'Metric': 'F1', 'Score': '92.2'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD1.1 dev', 'Metric': 'EM', 'Score': '84.2'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD1.1 dev', 'Metric': 'F1', 'Score': '91.1'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'MRQA', 'Metric': 'Average F1', 'Score': '78.5'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD1.1', 'Metric': 'EM', 'Score': '87.433'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD1.1', 'Metric': 'F1', 'Score': '93.160'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD1.1', 'Metric': 'EM', 'Score': '87.4'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD1.1', 'Metric': 'F1', 'Score': '93.2'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD1.1', 'Metric': 'EM', 'Score': '85.083'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD1.1', 'Metric': 'F1', 'Score': '91.835'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD1.1', 'Metric': 'F1', 'Score': '91.8'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'CoQA', 'Metric': 'In-domain', 'Score': '82.5'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'CoQA', 'Metric': 'Out-of-domain', 'Score': '77.6'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'CoQA', 'Metric': 'Overall', 'Score': '81.1'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'CoQA', 'Metric': 'In-domain', 'Score': '79.8'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'CoQA', 'Metric': 'Out-of-domain', 'Score': '74.1'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'CoQA', 'Metric': 'Overall', 'Score': '78.1'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'SWAG', 'Metric': 'Dev', 'Score': '86.6'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'SWAG', 'Metric': 'Test', 'Score': '86.3'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'ReCoRD', 'Metric': 'F1', 'Score': '56.065'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'ReCoRD', 'Metric': 'EM', 'Score': '54.040'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'QNLI', 'Metric': 'Accuracy', 'Score': '92.7%'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'RTE', 'Metric': 'Accuracy', 'Score': '70.1%'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MultiNLI', 'Metric': 'Matched', 'Score': '86.7'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MultiNLI', 'Metric': 'Mismatched', 'Score': '85.9'}}, {'LEADERBOARD': {'Task': 'Emotion Recognition in Conversation', 'Dataset': 'CPED', 'Metric': 'Accuracy of Sentiment', 'Score': '48.96'}}, {'LEADERBOARD': {'Task': 'Emotion Recognition in Conversation', 'Dataset': 'CPED', 'Metric': 'Macro-F1 of Sentiment', 'Score': '45.18'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'MRPC', 'Metric': 'F1', 'Score': '89.3'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'STS Benchmark', 'Metric': 'Spearman Correlation', 'Score': '0.865'}}, {'LEADERBOARD': {'Task': 'Sentiment Analysis', 'Dataset': 'SST-2 Binary classification', 'Metric': 'Accuracy', 'Score': '94.9'}}, {'LEADERBOARD': {'Task': 'Named Entity Recognition (NER)', 'Dataset': 'CoNLL 2003 (English)', 'Metric': 'F1', 'Score': '92.8'}}, {'LEADERBOARD': {'Task': 'Named Entity Recognition (NER)', 'Dataset': 'CoNLL 2003 (English)', 'Metric': 'F1', 'Score': '92.4'}}, {'LEADERBOARD': {'Task': 'Named Entity Recognition (NER)', 'Dataset': 'SciERC', 'Metric': 'F1', 'Score': '65.24'}}, {'LEADERBOARD': {'Task': 'Named Entity Recognition (NER)', 'Dataset': 'NCBI-disease', 'Metric': 'F1', 'Score': '86.37'}}, {'LEADERBOARD': {'Task': 'Type prediction', 'Dataset': 'ManyTypes4TypeScript', 'Metric': 'Average Accuracy', 'Score': '57.52'}}, {'LEADERBOARD': {'Task': 'Type prediction', 'Dataset': 'ManyTypes4TypeScript', 'Metric': 'Average Precision', 'Score': '54.18'}}, {'LEADERBOARD': {'Task': 'Type prediction', 'Dataset': 'ManyTypes4TypeScript', 'Metric': 'Average Recall', 'Score': '54.02'}}, {'LEADERBOARD': {'Task': 'Type prediction', 'Dataset': 'ManyTypes4TypeScript', 'Metric': 'Average F1', 'Score': '54.10'}}, {'LEADERBOARD': {'Task': 'Text Classification', 'Dataset': 'DBpedia', 'Metric': 'Error', 'Score': '0.64'}}, {'LEADERBOARD': {'Task': 'Linguistic Acceptability', 'Dataset': 'CoLA', 'Metric': 'Accuracy', 'Score': '60.5%'}}, {'LEADERBOARD': {'Task': 'Natural Language Understanding', 'Dataset': 'PDP60', 'Metric': 'Accuracy', 'Score': '78.3'}}]
