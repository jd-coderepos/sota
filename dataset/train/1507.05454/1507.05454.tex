\documentclass[fleqn]{tlp}



\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[all]{xy}

\newtheorem{definition}{Definition} \newtheorem{example}{Example} \newtheorem{lemma}{Lemma} \newtheorem{proposition}{Proposition} \newtheorem{theorem}{Theorem} \newtheorem{corollary}{Corollary} 

\usepackage{color}

\newcommand{\red}[1]{{\color{red} #1}}
\newcommand{\green}[1]{{\color{green} #1}}
\newcommand{\blue}[1]{{\color{blue} #1}}
\newcommand{\brown}[1]{{\color{brown} #1}}
\newcommand{\purple}[1]{{\color{purple} #1}}
\newcommand{\gray}[1]{{\color{gray} #1}}

\makeatletter
\newenvironment{prog}{\vspace{0.7ex}\par
\setlength{\parindent}{0.7cm}
\obeylines\@vobeyspaces\tt}{\vspace{0.7ex}\noindent
}
\makeatother
\newcommand{\startprog}{\begin{prog}}
\newcommand{\stopprog}{\end{prog}\noindent}
\newcommand{\fpr}[1]{\mbox{\footnotesize\tt #1}} \newcommand{\conc}{\mathsf{conc}} 
\newcommand{\symb}{\mathsf{symb}} 
\newcommand{\alt}{\mathsf{alt}} 
\newcommand{\traces}{\mathit{Traces}} 
\newcommand{\depth}{\mathit{depth}} 
\newcommand{\rt}{\mathit{root}} 
\newcommand{\inp}{\mathsf{input}} 
\newcommand{\trace}{\mathit{trace}} 
\newcommand{\matches}{\mathit{matches}} 
\newcommand{\ground}{\mathit{ground}} 

\newcommand{\envpat}{\mathit{env2pat}}
\newcommand{\patenv}{\mathit{pat2env}}
\newcommand{\memo}{\mathit{memo}}
\newcommand{\pat}{\mathit{pat}}
\newcommand{\asub}{\mathit{asub}}
\newcommand{\get}{\mathit{get}}
\newcommand{\addentry}{\mathit{addentry}}

\newcommand{\id}{{\mathit{id}}} 

\newcommand{\sgeq}{\geqslant}
\newcommand{\sleq}{\leqslant}
\newcommand{\snorm}{||\cdot||}
\newcommand{\ri}{{<\!\!\!<}}

\newcommand{\alttrace}{\mathsf{alt\_trace}}
\newcommand{\true}{\mathsf{true}}
\newcommand{\mgu}{\mathsf{mgu}}
\newcommand{\error}{\mathsf{error}}
\newcommand{\defined}{\mathsf{defined}}
\newcommand{\call}{\mathsf{call}}
\newcommand{\fail}{\mathsf{fail}}
\newcommand{\eval}{\mathsf{eval}}
\newcommand{\clauses}{\mathsf{clauses}}
\newcommand{\midd}{\!\mid\!}
\newcommand{\sep}{\mathit{\;]\![\;}}
\newcommand{\success}{\mbox{\footnotesize \textsc{success}}}
\newcommand{\failsc}{\mbox{\footnotesize \textsc{fail}}}
\newcommand{\errorsc}{\mbox{\footnotesize \textsc{error}}}

\newcommand{\pend}{\mathit{pending}}
\newcommand{\done}{\mathit{qs}}
\newcommand{\res}{\mathit{R}}
\newcommand{\resultants}{\mathit{res}}
\newcommand{\anc}{\mathit{as}}
\newcommand{\safe}{\mathit{safe}}
\newcommand{\unsafe}{\mathit{unsafe}}
\newcommand{\ren}{\mathit{ren}}
\newcommand{\isplit}{\mbox{\sf i-split}}
\newcommand{\rsplit}{\mbox{\sf r-split}}
\newcommand{\sel}{\mathit{selected}}
\newcommand{\tab}{\mathit{ren}}
\newcommand{\unfolds}{\hookrightarrow}
\newcommand{\unfold}{\mbox{\sf unfold}}
\newcommand{\gen}{\mathit{gen}}
\newcommand{\gpos}{\mathit{gpos}}
\newcommand{\concat}{\mbox{\scriptsize ++}}
\newcommand{\freevars}{\mathit{fvars}}
\newcommand{\query}{\mathit{query}}



\def\defemb#1#2{\expandafter\def\csname #1\endcsname
                              {\relax\ifmmode #2\else\hbox{}\fi}}
\defemb{cA}{{\cal A}}
\defemb{cB}{{\cal B}}
\defemb{cC}{{\cal C}}
\defemb{cD}{{\cal D}}
\defemb{cE}{{\cal E}}
\defemb{cF}{{\cal F}}
\defemb{cG}{{\cal G}}
\defemb{cH}{{\cal H}}
\defemb{cI}{{\cal I}}
\defemb{cJ}{{\cal J}}
\defemb{cL}{{\cal L}}
\defemb{cM}{{\cal M}}
\defemb{cN}{{\cal N}}
\defemb{cO}{{\cal O}}
\defemb{cP}{{\cal P}}
\defemb{cQ}{{\cal Q}}
\defemb{cR}{{\cal R}}
\defemb{cS}{{\cal S}}
\defemb{cT}{{\cal T}}
\defemb{cU}{{\cal U}}
\defemb{cV}{{\cal V}}
\defemb{cX}{{\cal X}}
\defemb{cZ}{{\cal Z}}



\newcommand{\pos}{{\cP}os}
\newcommand{\fpos}{{\cN}{\cV}{\cP}os}
\newcommand{\var}{{\cV}ar}
\newcommand{\head}{{\cH}ead}
\newcommand{\nat}{\mbox{}}
\newcommand{\mas}{+}
\newcommand{\nil}{[\:]}

\newcommand{\Cc}{{\cal{C}}} \newcommand{\Fc}{{\cal{F}}} \newcommand{\Var}{{\cal V}ar} \newcommand{\Rc}{{\cal{R}}} \newcommand{\Tc}{{\cal{T}}} \newcommand{\Xc}{{\cal{X}}} \renewcommand{\emptyset}{\{\}} \renewcommand{\phi}{\varphi}
\newcommand{\equ}{\approx}
\newcommand{\dt}{{\cal P}} \newcommand{\nns}{{\lambda_{needed}}} \newcommand{\lns}{\lambda_{lazy}} \newcommand{\toppos}{\epsilon} \newcommand{\ol}[1]{\overline{#1}}  \newcommand{\pr}[1]{\mbox{}}   \newcommand{\prm}[1]{\mbox{\tt #1}}   \newcommand{\todo}[1]{\fbox{\sc To do: #1}}
\newcommand{\To}{\Rightarrow}
\newcommand{\foo}[1]{\tt #1}


\newcommand{\pred}{\mathit{pred}}
\newcommand{\opred}{\textsc{pred}}
\newcommand{\cfg}{\textsc{cfg}}
\newcommand{\srg}{\textsc{srg}}
\newcommand{\start}{\textsc{start}}
\newcommand{\terminals}{\textsc{t}}

\newcommand{\acalls}{Ancestors}
\newcommand{\unfq}{{Unf}}

\def\ri{<\!\!\!<}   



\newcommand{\lto}{\longrightarrow}
\newcommand{\hto}{\hookrightarrow}
\newcommand{\gn}{\rightsquigarrow}

\let\l=\langle
\let\r=\rangle
\def \tuple#1{\langle #1 \rangle}


\newcommand{\Dom}{\mathit{Dom}}
\newcommand{\Ran}{\mathit{Ran}}
\newcommand{\Range}{\mathit{Range}}
\newcommand{\Hpos}{\mathcal{H}_{\mathit{pos}}}
\newcommand{\Hneg}{\mathcal{H}_{\mathit{neg}}}
\newcommand{\seq}{\mathit{Seq}}
\newcommand{\msa}{\mathit{msa}}
\newcommand{\false}{\mathit{false}}
\newcommand*{\eg}{\textit{e.g.}, }



\begin{document}

\title[Concolic Testing in Logic Programming]{Concolic Testing in Logic Programming\thanks{This work has been partially supported by the EU (FEDER) and
    the Spanish \emph{Ministerio de Econom\'{\i}a y Competitividad}
    under grant TIN2013-44742-C4-1-R and by the \emph{Generalitat
      Valenciana} under grant PROMETEOII/2015/013. 
Part of this research was done while the third author was visiting
    the University of Reunion; G.\ Vidal gratefully acknowledges their
    hospitality.}  }

\author[F.~Mesnard and \'E.~Payet and G.~Vidal]
{FRED MESNARD, \'ETIENNE PAYET \\
  LIM - Universit\'e de la R\'eunion, France\\
  \email{\{fred,epayet\}@univ-reunion.fr} 
\and
GERM\'AN VIDAL \\
MiST, DSIC, Universitat Polit\`ecnica de Val\`encia\\
\email{gvidal@dsic.upv.es}
}



\maketitle

\label{firstpage}

\begin{abstract}
  Software testing is one of the most popular validation techniques in
  the software industry. Surprisingly, we can only find a few
  approaches to testing in the context of logic programming.
In this paper, we introduce a systematic approach for dynamic
  testing that combines both concrete and symbolic execution. Our
  approach is fully automatic and guarantees full path coverage when
  it terminates.
We prove some basic properties of our technique and illustrate its
  practical usefulness through a prototype implementation.\\
  
  \noindent
  \emph{To appear in Theory and Practice of Logic Programming (TPLP),
  Proc.\ of ICLP 2015.}\\
\end{abstract}

\begin{keywords}
 Symbolic execution, logic programming, testing.
\end{keywords}

\section{Introduction} \label{intro}

Essentially, software validation aims at ensuring that the developed
software complies with the original requirements. One of the most
popular validation approaches is \emph{software testing}, a process
that involves producing a test suite and then executing the system
with these test cases. The main drawback of this approach is that
designing a test suite with a high code coverage |i.e., covering as
many execution paths as possible| is a complex and time-consuming
task. As an alternative, one can use a tool for the random generation
of test cases, but then we are often faced with a poor code coverage.
Some hybrid approaches exist where random generation is
driven by the user, as in QuickCheck \cite{CH00}, but then again the
process may become complex and time-consuming.

Another popular, fully automatic approach to test case generation is
based on \emph{symbolic execution} \cite{Kin76,Cla76}. Basically,
symbolic execution considers unknown (symbolic) values for the input
parameters and, then, explores all feasible execution paths in a
non-deterministic way. Symbolic states include now a \emph{path
  condition} that stores the current constraints on symbolic values,
i.e., the conditions that must hold to reach a particular execution
point. For each final state, a test case is produced by solving
the constraints in the associated path condition.

A drawback of the previous approach, though, is that the constraints
in the path condition may become very complex. When these constraints
are not solvable, the only sound way to proceed is to stop the
execution path, often giving rise to a poor coverage.  Recently, a new
variant called \emph{concolic execution} \cite{GKS05,SMA05} that
combines both \emph{conc}rete and symb\emph{olic} execution has been
proposed as a basis for both model checking and test case
generation. The main advantage is that, now, when the constraints in
the symbolic execution become too complex, one can still take some
values from the concrete execution to simplify them. This is sound and
often allows one to explore a larger execution space.  Some successful
tools that are based on concolic execution are, e.g., SAGE
\cite{GLM12} and Java Pathfinder \cite{PR10}.

In the context of the logic programming paradigm, one can find a
flurry of \emph{static}, complete techniques for software analysis and
verification. However, only a few dynamic techniques for program
validation have been proposed. Dynamic, typically incomplete,
techniques have proven very useful for software validation in other
paradigms. In general, these techniques are sound so that they avoid
\emph{false positives}. This contrasts with typical static
verification methods which may produce some false positives due to the
abstraction techniques introduced to ensure completeness. Therefore,
we expect concolic execution to complement 
existing analysis and verification techniques for logic programs.

In this paper, we introduce a new, fully automatic scheme for
\emph{concolic testing} in logic programming. As in other paradigms,
concolic testing may help the programmer to systematically find
program bugs and generate test cases with a good code coverage. As it
is common, our approach is always sound but usually incomplete.  In
the context of logic programming, we consider that ``full path
coverage'' involves calling each predicate in all possible
ways. Consider, e.g., the logic program . Here,
one could assume that the execution of the goals in  is
enough for achieving a full path coverage. However, in this paper we
consider that full path coverage requires, e.g., the set
 so that we have a goal that matches both
clauses, one that only matches the first clause, one that only matches
the second clause, and one that matches no clause. We call this notion
\emph{choice} coverage, and it is specific of logic programming. To
the best of our knowledge, such a notion of coverage has not been
considered before. Typically, only a form of \emph{statement} coverage
has been considered, where only the clauses used in the considered
executions are taken into account. For guaranteeing choice coverage, a
new type of unification problems must be solved:
we have to produce goals in which the selected atom  matches
the heads of some clauses, say , but does not match
the heads of some other clauses, say .
We provide a constructive algorithm for solving such unifiability
problems.

A prototype implementation of the concolic testing scheme for pure
Prolog, called \textsf{contest}, is publicly available from
\texttt{http://kaz.dsic.upv.es/contest.html}. The results from an
experimental evaluation point out the usefulness of the
approach. Besides logic programming and Prolog, our technique might
also be useful for other programming languages since there exist
several transformational approaches that ``compile in'' programs to
Prolog, like, e.g., \cite{GZAP10}.

Omitted proofs as well as some extensions can be found in the
online appendix.

\section{Concrete Semantics} \label{concrete}

The semantics of a logic program is usually given in terms of the SLD
relation on goals \cite{Llo87}. In this section, we present instead a
\emph{local} semantics which is similar to that of
\citeN{SESGF11}. Basically, this semantics deals with states that
contain all the necessary information to perform the next step (in
contrast to the usual semantics, where the SLD tree built so far is
also needed, e.g., for dealing with the cut).
In contrast to \cite{SESGF11}, for simplicity, in this paper we only
consider definite logic programs.
However, the main difference w.r.t.\ \cite{SESGF11} comes from the
fact that our concrete semantics only considers the computation of the
first solution for the initial goal. This is the way most Prolog
applications are used and, thus, our semantics should consider this
behaviour in order to measure the coverage in a realistic way.

Before presenting the transition rules of the concrete semantics, let
us introduce some auxiliary notions and notations. We refer
  the reader to \cite{Apt97} for the standard definitions and
  notations for logic programs.
The semantics is defined by means of a transition system on
\emph{states} of the form
, where
 is a sequence of
goals labeled with substitutions (the answer computed so far, when
restricted to the variables of the initial goal).  We denote sequences
with , where  denotes the empty sequence.  In
some cases, we label a goal  both with a substitution and a
program clause, e.g., , which is used to
determine the next clause to be used for an SLD resolution step (see
rules \textsf{choice} and \textsf{unfold} in Fig.~\ref{fig:concrete2}).
Note that the clauses of the program are not included in the state but
considered a global parameter since they are static.
In the following, given an atom 
and a logic program , 
returns the sequence of renamed apart program clauses  
from  whose head unifies with .
A syntactic object  is \emph{more general} than a syntactic object
, denoted , if there exists a substitution
 such that .
 denotes the set of variables of the syntactic object . 
For a substitution ,  is defined as .


\begin{figure}[t]
  \rule{\linewidth}{1pt}
  2ex]

     \mathsf{(failure)} & {\displaystyle 
      \frac{~} 
        {\tuple{(\fail,\cB)_\delta} \to \tuple{\failsc_\delta}}
        }
        \hspace{24ex}
    \mathsf{(backtrack)} ~ {\displaystyle 
      \frac{S\neq\epsilon} 
        {\tuple{(\fail,\cB)_\delta\midd S} \to \tuple{S}}
        }\3ex]

    \mathsf{(unfold)} & {\displaystyle 
      \frac{\mgu(A,H_1)=\sigma} 
        {\tuple{(A,\cB)_\delta^{H_1\leftarrow\cB_1}\midd S}
          \to \tuple{(\cB_1\sigma,\cB\sigma)_{\delta\sigma}\midd S}}
        } \\ 

    \end{array}
    
  \begin{array}{l@{~~~~~~}l@{~~~~~~}l}
    p(s(a)). &
    q(a).   &
    r(a).  \\
  
    p(s(X)) \leftarrow q(X). & q(b). & r(c). \\
    
    p(f(X)) \leftarrow r(X). & \\
    \end{array}
    
    \begin{array}{llllll}
      \tuple{p(f(X))_\id} & \to^\mathsf{choice} &
      \tuple{p(f(X))_\id^{p(f(Y)) \leftarrow r(Y)}} & \to^\mathsf{unfold}
      & \tuple{r(X)_\id} \\
      & \to^\mathsf{choice} & \tuple{r(X)_\id^{r(a)}\midd r(X)_\id^{r(c)}}
      & \to^\mathsf{unfold}
      & \tuple{\mathsf{true}_{\{X/a\}}\midd r(X)_\id^{r(c)}} \\
      & \to^\mathsf{success} & \tuple{\success_{\{X/a\}}} 
    \end{array}
    -1ex]
  4ex]

    \mathsf{(failure)} & {\displaystyle 
      \frac{~} 
        {\tuple{(\mathsf{fail},\cB)_\delta
          \sep (\mathsf{fail},\cB')_\theta} \leadsto_\diamond 
        \tuple{\failsc_\delta \sep \failsc_\theta}}
        }\4ex]

     \mathsf{(choice)} &  {\displaystyle 
      \frac{\clauses(A,\cP) = \ol{c_n}\wedge n>0 \wedge \clauses(A',\cP)=\ol{d_k}} 
        {\begin{array}{l@{~}l}
            \tuple{(A,\cB)_\delta\midd S \sep (A',\cB')_\theta\midd S'} 
            \leadsto_{\!c(\ell(\ol{c_n}),\ell(\ol{d_k}))} 
          \tuple{(A,\cB)_\delta^{c_1} \midd \ldots\midd
          (A,\cB)_\delta^{c_n}\midd  S\8ex]


    \mathsf{(choice\_fail)} & {\displaystyle 
      \frac{ 
        \clauses(A,\cP)=\emptyset
      \wedge \clauses(A',\cP)=\ol{c_k}} 
        {\tuple{(A,\cB)_\delta\midd S \sep (A',\cB')_\theta\midd S'} 
          \leadsto_{c(\emptyset,\ell(\ol{c_k}))}
          \tuple{(\fail,\cB)_\delta\midd S\sep (\fail,\cB')_\theta\midd S'}}
        }\
  \rule{\linewidth}{1pt}
  \caption{Concolic execution semantics} \label{fig:concolic}
\end{figure}

In the concolic execution semantics, we perform both concrete and
symbolic execution steps in parallel. However, the symbolic execution
does not explore all possible execution paths but only mimics the
steps of the concrete execution; observe, e.g., rule \textsf{choice}
in Figure~\ref{fig:concolic}, where the clauses labeling the copies of
the symbolic goal are the same clauses  matching the
concrete goal, rather than the set of clauses  (a superset
of ).

\begin{example} \label{ex2} 
  Consider again the logic program of Example~\ref{ex1}, now with
  clause labels:
  
    Given the initial goal , we have the following concolic
    execution:
    
    where , , and
    .
\end{example}
In this paper, we only consider finite concolic executions for initial
goals.  This is a reasonable assumption since one can expect concrete
goals to compute the first answer finitely (unless the program is
erroneous).
We associate a \emph{trace} to each concolic execution as follows:

\begin{definition}[trace]
  Let  be a program and  an initial concolic state. Let , , be a
  concolic execution for  in . Let
  , , be the
  sequence of labels in  which are different from
  . Then, the trace associated to the concolic execution 
  is .
\end{definition}
Roughly speaking, a trace is just a sequence with the sets of labels
of the matching clauses in each choice step.
For instance, the trace associated to the concolic execution of
Example~\ref{ex2} is , i.e., we have
two unfolding steps with matching clauses  and
, respectively.
Note that traces ending with  represent failing derivations.

The following result states an essential invariant for concolic execution:

\begin{theorem} \label{th:invariant} Let  be a program and  be an initial
  concolic state. Let , ,
  be a finite (possibly incomplete) concolic execution for  in
  . Then, for all concolic states , , the following
  invariant holds: , ,  (if any), and
  .
\end{theorem}

\section{Concolic Testing} \label{testing}

In this section, we introduce a concolic testing procedure for logic
programs based on the concolic execution semantics of the previous
section.

\subsection{The Procedure}

As we have seen in Section~\ref{concolic}, the concolic execution
steps labeled with  give us a hint of (potential)
alternative execution paths. Consider, for instance, the concolic
execution of Example~\ref{ex2}. The first step is labeled with
. This means that the selected
atom in the concrete goal only matched clause , while the
selected atom in the symbolic goal matched clauses , 
and . In principle, there are as many alternative execution
paths as elements in
; e.g.,
 denotes an execution path where the selected atom matches no
clause,  another path in which the selected atom
\emph{only} matches clause , 
another path where the selected atom matches all three clauses
,  and , and so forth.

When aiming at full choice coverage, we need to
solve both unification and disunification problems. Consider, e.g.,
that  is the selected atom in a goal, and that we want it to unify
with the head of clause  but not with the heads of clauses
 and . For this purpose, we introduce the following
auxiliary function , which also includes some groundness
requirements (see below). In the following, we let  denote
the unifiability relation, i.e., given atoms ,  holds
if ; correspondingly,  holds if
.

\begin{definition}[] \label{def:alt}
  Let  be an atom and  be sets of clause labels. Let
   be a set of variables.  The function 
  returns a substitution  such that the following holds:
  
  where  are the heads of the (renamed apart) clauses
  labeled by  and  are the heads of the
  (renamed apart) clauses labeled by ,
  respectively. 
If such a substitution does not exist, then function  returns
  .
\end{definition}
When the considered signature is finite,\!\footnote{Full Prolog and
  infinite signatures like integers or real numbers are left as future
  work.}  the following semi-algorithm is trivially sound and complete
for solving the above unifiability problem: first, bind  with terms
of depth .\footnote{The depth  of a term  is defined
  as usual:  if  is a variable or a constant symbol,
  and , otherwise.} If the
condition above does not hold, then we try with terms of depth ,
and check it again. We keep increasing the considered term depth until
a solution is found. If a solution exists, this naive semi-algorithm will
find it (otherwise, it may run forever). 
In practice, however, it may be very inefficient.

Observe that, in general, there might be several most general solutions to
the above problem. Consider, e.g., ,
 and . Then, both 
and  are most general solutions.  In principle, any of them is
equally good in our context.
We postpone to the next section the introduction of a constructive
algorithm for function .  Here, we present an algorithm to
systematically produce concrete initial goals so that all
\emph{feasible} choices in the execution paths are covered (unless the
process runs forever).
First, we introduce the following auxiliary definitions:

\begin{definition}[, ]
\label{defn:conc:symb}
  Let  be a concolic
  state. Then, we let  denote the
  first concrete goal and  the
  first symbolic goal.
\end{definition}

\begin{definition}[] \label{def:alttrace}
  Let  be a program,  an initial concolic state, and  be a (possibly incomplete)
  concolic execution for  in .  Then, the function
   denotes the following set of (potentially) alternative
  traces:
  
\end{definition}
For instance, given the following (partial) concolic execution 
from Example~\ref{ex2}:

where , ,
, we have ,
, and
.

Now, we introduce our concolic testing procedure. It takes as input a
program and a random |e.g., provided by the user| initial atomic goal
rooted by the distinguished predicate . In the following, we assume
that each concrete initial goal  is existentially
terminating w.r.t.\ Prolog's leftmost computation rule, i.e., either
computes the \emph{first} answer in a finite number of steps or
finitely fails \cite{Vasak86a}.
For this purpose, we assume that  has some associated
\emph{input} arguments, determined by a function , so that an
initial goal  existentially terminates if the terms
 are ground. One could also consider that there
are several combinations of input arguments that guarantee existential
termination |this is similar to the modes of a predicate| but we only
consider one set of input arguments for simplicity (extending the
concolic testing algorithm would be straightforward).
As mentioned before, assuming that concrete initial goals are
existentially terminating is a reasonable assumption in practice.

\begin{definition}[concolic testing] \label{def:concolic}
  \begin{description}
  \item[\textbf{Input:}] a logic program  and an atom
     with  ground.

  \item[\textbf{Output:}] a set  of test cases.
    
  \end{description}

  \begin{enumerate}
  \item Let , ,
    .

  \item While  do
    \begin{enumerate}
    \item Take , , .

    \item 
      Let  and 
      compute a successful or finitely failing derivation
      . 
      
    \item Let . 

    \item We update  as follows:
      \begin{itemize}
      \item for each prefix  of
         and
      \item for each (possibly partial) trace 
         which is not the prefix of
        any trace in , 
      \item add 
         to  if , where
         and
        .\!\footnote{I.e.,  is
          the first atom of the symbolic goal  of the
          concolic state , see Definition
          \ref{defn:conc:symb}. }
      \end{itemize}
    \end{enumerate}
  \item Return the set  of test cases
  \end{enumerate}
\end{definition}
The soundness of concolic testing is immediate, since 
each atom from  is indeed a test case 
of the form  with  ground. 
Completeness and termination are more subtle properties though.

In principle, one could argue that the concolic testing algorithm is
a complete semi-algorithm in the sense that, if it terminates, the
generated test cases cover all feasible paths. Our assumptions
trivially guarantee that every considered concrete execution is finite
(i.e., step (2b) in the loop of the concolic testing
algorithm). Unfortunately, the algorithm will often run forever by
producing infinitely many test cases. Consider, e.g., the following
simple program:

Even if every goal  with  ground is terminating, our
algorithm will still produce infinitely many test cases, e.g.,
, , , \ldots, since each goal will
explore a different path (i.e., will produce a different execution
trace: , ,
, etc). In practice, though, the
quality of the generated test cases should be experimentally evaluated
using a coverage tool.

Therefore, in general, we will sacrifice completeness in order to
guarantee the termination of concolic testing. For this purpose, one
can use a time limit, a bound for the length of concolic executions,
or a maximum term depth for the arguments of the generated test
cases. In this paper, we consider the last approach.
Then, one can replace the use of a particular function  in step
(2d) of Definition~\ref{def:concolic} by a function  with
 if 
for all , and  otherwise.
This is the solution we implemented in the concolic testing tool
described in Section~\ref{tool}.

For instance, by requiring a maximum term depth of , the
generated test cases for the program  above would be ,
,  and , where  is a fresh constant
symbol, with associated traces , ,
, and , respectively.

Termination of the algorithm in Definition~\ref{def:concolic} is then
guaranteed since only a finite number of new atoms can be added in
step (2d) |up to variable renaming| and, moreover, only those (possibly
partial) traces which are not a prefix of any trace already in the set
 are considered. Observe that these facts suffice to
ensure termination of the algorithm since one cannot have infinitely
many traces with a finite number of atoms.

\subsection{Solving Unifiability Problems} \label{sec:unif}

In this section, we present a constructive algorithm for function .
Let us first reformulate our unification problem in slightly more
general terms than in Definition~\ref{def:alt}. Let  be an atom and
,  be two sets of atoms the elements of which are
variable disjoint with  and unify with , and a set of variables
. The problem consists in finding a substitution  such that

We introduce a stepwise method that, roughly speaking, proceeds as
follows:
\begin{itemize}
\item First, we produce some ``maximal'' substitutions 
  (called \emph{maximal unifying substitution} below) for  such
  that  still unifies with the atoms in . Here, we use
  a special set  of fresh variables with
  . The elements of
   are denoted by , , \dots{} Then, in , the
  variables from  (if any) denote positions where further binding
  will prevent  from unifying with some atom in . In
  contrast,  still unifies with all the atoms in
   as long as  does not bind any variable from .
Roughly speaking, we apply some (minimal) generalizations to the
  atoms in  so that they unify, and then return their most
  general unifier.

  For this stage, we use well known techniques like \emph{variable
    elimination} \cite{MM82}
  and \emph{generalization} (from the algorithm for most specific
  generalization \cite{Plo70}); see Definition~\ref{alg1} below.

\item In a second stage, we look for another substitution 
  such that  is a solution for . Here, we
  basically follow a generate and test algorithm (as in the naive
  algorithm above), but it is now much more restricted thanks to
  .
\end{itemize}

\subsubsection{The Positive Atoms}
\label{section-algo-all-pos}


Here, we will use the variables from the special set  to
replace \emph{disagreement pairs}
(see~\cite{Apt97} p.~27).
Roughly speaking, given terms  and , a subterm  of  and a
subterm  of  form a disagreement pair if the root symbols of
 and  are different, but the symbols from  up to the root of
 and from  up to the root of  are the same. For instance,
 and  are disagreement pairs of the terms 
and .
A disagreement pair  is called \emph{simple}
if one of the terms is a variable that does not occur in the other
term and no variable of  occurs in .  We say that
the substitution  is determined by  if
.

Basically, given an atom  and a set of atoms , the following
algorithm nondeterministically computes a substitution  such
that  still unifies with all the atoms in  as
long as  does not bind any variable from .

\begin{definition}[maximal unifying substitution] \label{alg1}
\begin{description}
\item[\textbf{Input:}] 
  an atom  and a set of atoms  such that
   and  for all .
\item[\textbf{Output:}] a substitution .
\end{description}

\begin{enumerate}
\item \label{algo-msa-init}
  Let .
\item \label{algo-msa-while-simple}
  While simple disagreement pairs occur in  do
  \begin{enumerate}
  \item nondeterministically choose a simple disagreement pair 
    (resp.\ ) in  such that there is no other simple
    disagreement pair of the form  (or ) with 
    (i.e., a strict instance);
  \item \label{algo-msa-simple-pair}
    set  to  where .
  \end{enumerate}
\item \label{algo-msa-while-not-simple}
  While  do
  \begin{enumerate}
  \item nondeterministically choose a 
    disagreement pair  in ;
  \item \label{algo-msa-not-simple-pair} replace all disagrement
    pairs  in  by a fresh variable of .
  \end{enumerate}
\item \label{algo-msa-return} 
  Return , where , , and .
\end{enumerate}
\end{definition}
We note that the algorithm assumes that the input atom  is always more
general than the final atom  so that the last step is well defined. 
An invariant proving that this is indeed the case can be found in the
online appendix (Appendix B).

Observe that the step (2a) is nondeterministic since there may exist
several disagreement pairs  (or ) for the same variable .
Consider the atom  and the set
. Then, both  and 
are maximal unifying substitutions, as the following example
illustrates:

\begin{example}\label{ex-1-g}
  Let  and , with
  . 
  The algorithm then considers
  the simple disagreement pairs in . From , we get
   and the
  action~(\ref{algo-msa-simple-pair}) sets  to
    .
   The substitution  is determined by  and the
     action~(\ref{algo-msa-simple-pair}) sets  to
     .
   Now, we have two non-deterministic possibilities:
   \begin{itemize}
   \item If we consider the disagreement pair , we have a
     substitution  and
     Action~(\ref{algo-msa-simple-pair}) then sets  to
     . Now, no simple disagreement pair
     occurs in , hence the algorithm jumps to the loop at
     line~\ref{algo-msa-while-not-simple}.
     Action~(\ref{algo-msa-not-simple-pair}) replaces the disagreement
     pair  with a fresh variable , hence  is set
     to .  As  the loop at
     line~\ref{algo-msa-while-not-simple} stops and the algorithm
     returns the substitution .
   \item If we consider the disagreement pair  instead, we have  a
     substitution , and
     Action~(\ref{algo-msa-simple-pair}) sets  to
     . Now, by proceeding as in the
     previous case, the algorithm returns .
   \end{itemize}
\end{example}

\subsubsection{The Negative Atoms}
\label{section-algo-all-pos-neg}


Now we deal with the negative atoms 
by means of the following
algorithm which is the basis of our implementation of function
:

\begin{definition}[PosNeg] \label{alg2}
\begin{description}
\item[\textbf{Input:}] an atom  and two sets of atoms
  , , the elements of which are variable
  disjoint with  and unify with , and
  a set of variables . 
\item[\textbf{Output:}]  or a substitution 
  (restricted to the variables of ).
\end{description}

\begin{enumerate}\itemsep2pt
\item Let  be the substitution returned by the algorithm
  of Definition~\ref{alg1}
  with input  and .
\item Let   be an idempotent substitution such that
   is ground.
\item Check that 
   and
  ,
  otherwise return .
\item Check that for each , 
  ,
  otherwise return .
\item Return 
  (restricted to the variables of ). 
\end{enumerate}
\end{definition}
The correctness of this algorithm is stated as follows:

\begin{theorem}\label{theorem:correction-algo-posneg}
  Let  be an atom and  be two sets of atoms such that
   and 
  for all , 
  and a set of variables .
  The algorithm in Definition~\ref{alg2} always terminates and, if it
  returns a substitution , then  holds and  is ground.
\end{theorem}

\begin{example}
  Let , , ,  
  and .
  The algorithm of Definition~\ref{alg1} 
  returns . 
  We take , it is idempotent and  
   is ground.
   
  and  does not intersect with .
  Finally,  does not unify with .
  The algorithm thus returns 
  restricted to the variables of , i.e., 
  .
\end{example}

\begin{example}
  Let , , 
  , and . 
  The algorithm of Definition~\ref{alg1}
  applied to  and  
  returns . 
  However, we cannot find  such that  does not
  unify with  without binding . 
  The algorithm thus returns .  
\end{example}
Theorem~\ref{theorem:correction-algo-posneg} states the soundness of our
procedure for computing function .
As for completeness, we claim that binding an atom  with all
possible maximal unifying substitutions for  and  does not
affect to the existence of a solution to the unification problem (*)
above
(see the online appendix (Appendix B) for more details).


\subsection{A Tool for Concolic Testing} \label{tool}

In this section, we present a prototype implementation of the
concolic testing scheme. The tool, called \textsf{contest}, is
publicly available from the following URL
\begin{quote}
  \texttt{http://kaz.dsic.upv.es/contest.html}
\end{quote}
It consists of approx.\ 1000 lines of Prolog code and implements the
concolic testing algorithm of Definition~\ref{def:concolic} with
function  as described in Section~\ref{sec:unif} and a maximum
term depth that can be fixed by the user in order to guarantee the
termination of the process. 
Moreover, we also introduced a bound for the number of alternatives
when computing function  (see
Definition~\ref{def:alttrace}). Roughly speaking, when the number of
alternatives is too high, we give up aiming at full \emph{choice}
coverage and return sets with only one clause label (which suffice for
clause coverage).

\begin{table}[t]
  \caption{Clause coverage analysis results (SICStus Prolog)}   \label{table:coverage}
  \centering
  \footnotesize
  
\end{table}

Table~\ref{table:coverage} shows a summary of the coverage achieved by
the test cases automatically generated using \textsf{contest}. The
complete benchmarks --including the source code, initial goal, input
arguments and maximum term depth-- 
can be found in the above URL.
We used the coverage analysis tool of SICStus Prolog 4.3.1, which
basically measures the number of times each clause is used. The
results are very satisfactory, achieving a full coverage in most of
the examples.

The current version is a proof-of-concept implementation and only
deals with pure Prolog without negation. We plan to extend it to cope
with full Prolog. The concrete semantics can be extended following
\cite{SESGF11}, and concolic execution is in general a natural
extension of the semantics in Figure~\ref{fig:concolic}. 
For relational built-in's or
equalities, we should label the execution step with an associated
constraint, which can then be used to produce alternative execution
paths by solving its negation. In this context, our tool will be
useful not only for test case generation, but also to detect program
errors during concolic testing (e.g., negated atoms which are not
instantiated enough, incorrect calls to arithmetic built-in's, etc).
See the online appendix (Appendix A) for more details on extending
concolic execution to full Prolog.

\section{Related Work and Concluding Remarks} \label{relwork}

\citeN{DBLP:conf/iclp/MeraLH09} 
present a framework unifying unit testing and 
run-time verification for the 
Ciao system~\cite{DBLP:journals/tplp/HermenegildoBCLMMP12}.
The  constraint programming 
system~\cite{DBLP:journals/tplp/SchimpfS12}
and SICStus Prolog~\cite{DBLP:journals/tplp/CarlssonM12}
both provide  tools which run a given goal and compute
how often program points in the code were executed.
SWI-Prolog~\cite{wielemaker:2011:tplp} offers a unit testing tool
associated to an optional interactive generation of test cases.
It also includes an experimental coverage analysis which runs a given goal
and computes the percentage of the used clauses and failing clauses.
\citeN{DBLP:conf/issta/BelliJ93} and \citeN{DBLP:conf/lopstr/DegraveSV08}
consider automatic generation of test inputs for  strongly typed and moded logic
programming languages like the Mercury programming 
language~\cite{Somogyi96a}, whereas we only require moding the top-level predicate of the program.

One of the closest approaches to our work is the test case generation
technique by \cite{AAGR14}. The main difference, though, is that their
technique is based solely on traditional symbolic execution. As
mentioned before, concolic testing may scale better since one can deal
with more complex constraints by using data from the concrete
component of the concolic state.  
Another difference is that we aim at full path coverage (i.e., choice
coverage), and not only a form of statement coverage.

Another close approach is \cite{Vid15}, where a concolic execution
semantics for logic programs is presented. However, this approach only
considers a simpler statement coverage and, thus, it can be seen as a
particular instance of the technique in the present paper. Another
significant difference is that, in \cite{Vid15}, concolic execution
proceeds in a stepwise manner: first, concrete execution produces an
execution \emph{trace}, which is then used to drive concolic
execution. Although this scheme is conceptually simpler, it may give
rise to poorer results in practice since one cannot use concrete
values in symbolic executions, one of the main advantages of concolic
execution over traditional symbolic execution.  Moreover,
\citeN{Vid15} presents no formal results nor an implementation of the
concolic execution technique.

Summarizing the paper, we have introduced a novel scheme for concolic testing in logic
programming. It offers a sound and fully automatic technique for
test case generation with a good code coverage. 
We have stated 
the particular type of unification problems that should be solved to produce new test cases. 
We have proposed a correct algorithm for such unification problems.
Furthermore, we have developed a publicly available
proof-of-concept implementation of the concolic testing scheme,
\textsf{contest}, that shows the usefulness of our approach.
To the best of our knowledge, this is the first fully automatic
testing tool for Prolog that aims at full path coverage (here called choice coverage).

As future work, we plan to extend the scheme to full Prolog (see the
remarks in Section~\ref{tool}).
Another interesting subject for further research is the definition of
appropriate heuristics to drive concolic testing w.r.t.\ a given
coverage criterion. This might have a significant impact on the
quality of the test cases when the process is incomplete.
Finally, from the experimental evaluation, we observed that the
results could be improved by introducing type information, so that the
generated values are restricted to the right type. Hence, improving concolic
testing with type annotations is also a promising line of future work.





\begin{thebibliography}{}

\bibitem[\protect\citeauthoryear{Albert, Arenas, G{\'{o}}mez{-}Zamalloa, and
  Rojas}{Albert et~al\mbox{.}}{2014}]{AAGR14}
{\sc Albert, E.}, {\sc Arenas, P.}, {\sc G{\'{o}}mez{-}Zamalloa, M.}, {\sc and}
  {\sc Rojas, J.} 2014.
\newblock {Test Case Generation by Symbolic Execution: Basic Concepts, a
  CLP-Based Instance, and Actor-Based Concurrency}.
\newblock In {\em {SFM} 2014}. Springer LNCS 8483, 263--309.

\bibitem[\protect\citeauthoryear{Apt}{Apt}{1997}]{Apt97}
{\sc Apt, K.} 1997.
\newblock {\em {From Logic Programming to Prolog}}.
\newblock Prentice Hall.

\bibitem[\protect\citeauthoryear{Belli and Jack}{Belli and
  Jack}{1993}]{DBLP:conf/issta/BelliJ93}
{\sc Belli, F.} {\sc and} {\sc Jack, O.} 1993.
\newblock Implementation-based analysis and testing of {P}rolog programs.
\newblock In {\em {ISSTA}}. 70--80.

\bibitem[\protect\citeauthoryear{Carlsson and Mildner}{Carlsson and
  Mildner}{2012}]{DBLP:journals/tplp/CarlssonM12}
{\sc Carlsson, M.} {\sc and} {\sc Mildner, P.} 2012.
\newblock {SICStus Prolog} - the first 25 years.
\newblock {\em Theory and Practice of Logic Programming\/}~{\em 12,\/}~1-2,
  35--66.

\bibitem[\protect\citeauthoryear{Claessen and Hughes}{Claessen and
  Hughes}{2000}]{CH00}
{\sc Claessen, K.} {\sc and} {\sc Hughes, J.} 2000.
\newblock {QuickCheck: a lightweight tool for random testing of Haskell
  programs}.
\newblock In {\em Proc.\ of {(ICFP} 2000)}. {ACM}, 268--279.

\bibitem[\protect\citeauthoryear{Clarke}{Clarke}{1976}]{Cla76}
{\sc Clarke, L.} 1976.
\newblock A program testing system.
\newblock In {\em Proceedings of the 1976 Annual Conference (ACM'76)}.
  488--491.

\bibitem[\protect\citeauthoryear{Degrave, Schrijvers, and Vanhoof}{Degrave
  et~al\mbox{.}}{2008}]{DBLP:conf/lopstr/DegraveSV08}
{\sc Degrave, F.}, {\sc Schrijvers, T.}, {\sc and} {\sc Vanhoof, W.} 2008.
\newblock Automatic generation of test inputs for {M}ercury.
\newblock In {\em Logic-Based Program Synthesis and Transformation, 18th
  International Symposium, {LOPSTR} 2008}. 71--86.

\bibitem[\protect\citeauthoryear{Godefroid, Klarlund, and Sen}{Godefroid
  et~al\mbox{.}}{2005}]{GKS05}
{\sc Godefroid, P.}, {\sc Klarlund, N.}, {\sc and} {\sc Sen, K.} 2005.
\newblock {DART: directed automated random testing}.
\newblock In {\em Proc.\ of PLDI'05}. ACM, 213--223.

\bibitem[\protect\citeauthoryear{Godefroid, Levin, and Molnar}{Godefroid
  et~al\mbox{.}}{2012}]{GLM12}
{\sc Godefroid, P.}, {\sc Levin, M.}, {\sc and} {\sc Molnar, D.} 2012.
\newblock Sage: whitebox fuzzing for security testing.
\newblock {\em CACM\/}~{\em 55,\/}~3, 40--44.

\bibitem[\protect\citeauthoryear{G{\'o}mez-Zamalloa, Albert, and
  Puebla}{G{\'o}mez-Zamalloa et~al\mbox{.}}{2010}]{GZAP10}
{\sc G{\'o}mez-Zamalloa, M.}, {\sc Albert, E.}, {\sc and} {\sc Puebla, G.}
  2010.
\newblock {Test case generation for object-oriented imperative languages in
  CLP}.
\newblock {\em TPLP\/}~{\em 10,\/}~4-6, 659--674.

\bibitem[\protect\citeauthoryear{Hermenegildo, Bueno, Carro,
  L{\'{o}}pez{-}Garc{\'{\i}}a, Mera, Morales, and Puebla}{Hermenegildo
  et~al\mbox{.}}{2012}]{DBLP:journals/tplp/HermenegildoBCLMMP12}
{\sc Hermenegildo, M.~V.}, {\sc Bueno, F.}, {\sc Carro, M.}, {\sc
  L{\'{o}}pez{-}Garc{\'{\i}}a, P.}, {\sc Mera, E.}, {\sc Morales, J.~F.}, {\sc
  and} {\sc Puebla, G.} 2012.
\newblock An overview of {C}iao and its design philosophy.
\newblock {\em {TPLP}\/}~{\em 12,\/}~1-2, 219--252.

\bibitem[\protect\citeauthoryear{King}{King}{1976}]{Kin76}
{\sc King, J.~C.} 1976.
\newblock Symbolic execution and program testing.
\newblock {\em CACM\/}~{\em 19,\/}~7, 385--394.

\bibitem[\protect\citeauthoryear{Lloyd}{Lloyd}{1987}]{Llo87}
{\sc Lloyd, J.} 1987.
\newblock {\em Foundations of {L}ogic {P}rogramming}.
\newblock Springer-Verlag, Berlin.
\newblock 2nd Ed.

\bibitem[\protect\citeauthoryear{Martelli and Montanari}{Martelli and
  Montanari}{1982}]{MM82}
{\sc Martelli, A.} {\sc and} {\sc Montanari, U.} 1982.
\newblock An {E}fficient {U}nification {A}lgorithm.
\newblock {\em ACM Transactions on Programming Languages and Systems\/}~{\em
  4}, 258--282.

\bibitem[\protect\citeauthoryear{Mera, L{\'{o}}pez{-}Garc{\'{\i}}a, and
  Hermenegildo}{Mera et~al\mbox{.}}{2009}]{DBLP:conf/iclp/MeraLH09}
{\sc Mera, E.}, {\sc L{\'{o}}pez{-}Garc{\'{\i}}a, P.}, {\sc and} {\sc
  Hermenegildo, M.~V.} 2009.
\newblock Integrating software testing and run-time checking in an assertion
  verification framework.
\newblock In {\em 25th International Conference on Logic Programming, {ICLP}
  2009, Pasadena}. 281--295.

\bibitem[\protect\citeauthoryear{Pasareanu and Rungta}{Pasareanu and
  Rungta}{2010}]{PR10}
{\sc Pasareanu, C.} {\sc and} {\sc Rungta, N.} 2010.
\newblock {Symbolic PathFinder: symbolic execution of Java bytecode}.
\newblock In {\em ASE}, {C.~Pecheur}, {J.~Andrews}, {and} {E.~D. Nitto}, Eds.
  ACM, 179--180.

\bibitem[\protect\citeauthoryear{Plotkin}{Plotkin}{1970}]{Plo70}
{\sc Plotkin, G.} 1970.
\newblock A note on inductive generalization.
\newblock {\em Machine intelligence\/}~{\em 5}, 153--163.

\bibitem[\protect\citeauthoryear{Schimpf and Shen}{Schimpf and
  Shen}{2012}]{DBLP:journals/tplp/SchimpfS12}
{\sc Schimpf, J.} {\sc and} {\sc Shen, K.} 2012.
\newblock {ECL}{PS} - from {LP} to {CLP}.
\newblock {\em Theory and Practice of Logic Programming\/}~{\em 12,\/}~1-2,
  127--156.

\bibitem[\protect\citeauthoryear{Sen, Marinov, and Agha}{Sen
  et~al\mbox{.}}{2005}]{SMA05}
{\sc Sen, K.}, {\sc Marinov, D.}, {\sc and} {\sc Agha, G.} 2005.
\newblock {CUTE: a concolic unit testing engine for C}.
\newblock In {\em Proc.\ of ESEC/SIGSOFT FSE 2005}. ACM, 263--272.

\bibitem[\protect\citeauthoryear{Somogyi, Henderson, and Conway}{Somogyi
  et~al\mbox{.}}{1996}]{Somogyi96a}
{\sc Somogyi, Z.}, {\sc Henderson, F.}, {\sc and} {\sc Conway, T.} 1996.
\newblock The execution algorithm of {Mercury}, an efficient purely declarative
  {Logic Programming} language.
\newblock {\em The {Journal of Logic Programming}\/}~{\em 29,\/}~1--3, 17--64.

\bibitem[\protect\citeauthoryear{Str{\"o}der, Emmes, Schneider-Kamp, Giesl, and
  Fuhs}{Str{\"o}der et~al\mbox{.}}{2011}]{SESGF11}
{\sc Str{\"o}der, T.}, {\sc Emmes, F.}, {\sc Schneider-Kamp, P.}, {\sc Giesl,
  J.}, {\sc and} {\sc Fuhs, C.} 2011.
\newblock {A Linear Operational Semantics for Termination and Complexity
  Analysis of ISO Prolog}.
\newblock In {\em LOPSTR'11}. Springer LNCS 7225, 237--252.

\bibitem[\protect\citeauthoryear{Vasak and Potter}{Vasak and
  Potter}{1986}]{Vasak86a}
{\sc Vasak, T.} {\sc and} {\sc Potter, J.} 1986.
\newblock Characterization of terminating logic programs.
\newblock In {\em Proc. of the 1986 Intl. Symp. on {Logic Programming}}. IEEE,
  140--147.

\bibitem[\protect\citeauthoryear{Vidal}{Vidal}{2015}]{Vid15}
{\sc Vidal, G.} 2015.
\newblock {Concolic Execution and Test Case Generation in Prolog}.
\newblock In {\em Proc.\ of the 24th International Symposium on Logic-Based
  Program Synthesis and Transformation (LOPSTR'14)}, {M.~Proietti} {and}
  {H.~Seki}, Eds. Springer LNCS 8981, 167--181.

\bibitem[\protect\citeauthoryear{Wielemaker, Schrijvers, Triska, and
  Lager}{Wielemaker et~al\mbox{.}}{2012}]{wielemaker:2011:tplp}
{\sc Wielemaker, J.}, {\sc Schrijvers, T.}, {\sc Triska, M.}, {\sc and} {\sc
  Lager, T.} 2012.
\newblock {SWI-Prolog}.
\newblock {\em Theory and Practice of Logic Programming\/}~{\em 12,\/}~1-2,
  67--96.

\end{thebibliography}




\clearpage

\begin{appendix}

\pagestyle{plain}

\mbox{}\1ex]
GERM\'AN VIDAL \\
\em MiST, DSIC, Universitat Polit\`ecnica de Val\`encia\\
\email{gvidal@dsic.upv.es}
  \end{center}

\vspace{.5ex}

  \begin{center}
    \emph{ submitted 29 April 2015; revised 3rd July 2015; accepted 14
      July 2015 } 
  \end{center}

\vspace{1.5ex}

In this appendix we report, for the sake of completeness, some
auxiliary contents that, for space limitations, we could not include
in the paper. 

\section{Towards Extending Concolic Testing to Full Prolog} \label{fullsemantics}


\begin{figure}[b]
  \rule{\linewidth}{1pt}
  2ex]

     \mathsf{(failure)} & {\displaystyle 
      \frac{~} 
        {\tuple{(\fail,\cB)_\delta} \to \tuple{\failsc_\delta}}
        }
        \hfill\hspace{5ex}
    \mathsf{(backtrack)} ~ {\displaystyle 
      \frac{S\neq\epsilon} 
        {\tuple{(\fail,\cB)\midd S} \to \tuple{S}}
        }\3ex]

    \mathsf{(choice\_fail)} & {\displaystyle 
      \frac{\defined(A,\cP)\wedge \clauses(A,\cP)=\emptyset} 
        {\tuple{(A,\cB)_\delta\midd S} \to \tuple{(\fail,\cB)_\delta\midd S}}
        }\3ex]

    \mathsf{(cut)} & {\displaystyle 
      \frac{~} 
        {\tuple{(!^m,\cB)_\delta\midd S'\midd ~?^m_{\delta'}\midd S}
          \to \tuple{\cB_{\delta}\midd~?^m_{\delta'}\midd S}}
        } \hfill\hspace{5ex}
    \mathsf{(cut\_fail)} ~ {\displaystyle 
      \frac{~} 
        {\tuple{?^m_\delta \midd S}
          \to \tuple{\fail_\delta \midd S}}
        } \3ex]

    \mathsf{(call\_error)} & {\displaystyle 
      \frac{A\in\cV} 
        {\tuple{(call(A),\cB)_\delta\midd S}
          \to
          \tuple{\errorsc_{\delta}}}
        } \3ex]

    \mathsf{(unify)} & {\displaystyle 
      \frac{\mgu(t_1,t_2)=\sigma\neq\fail} 
        {\tuple{(t_1=t_2,\cB)_\delta\midd S}
          \to
          \tuple{\cB\sigma_{\delta\sigma}\midd S}}
        } \hfill\hspace{3ex}
    \mathsf{(unify\_fail)} ~ {\displaystyle 
      \frac{\mgu(t_1,t_2)=\fail} 
        {\tuple{(t_1=t_2,\cB)_\delta\midd S}
          \to
          \tuple{\fail_{\delta}\midd S}}
        } \3ex]

    \mathsf{(rel)} & {\displaystyle 
      \frac{\mathsf{eval}(t_1\oplus t_2) = A \in\{\mathsf{true},\mathsf{fail}\}} 
        {\tuple{(t_1~{\oplus}~t_2,\cB)_\delta\midd S}
          \to
          \tuple{(A,\cB)_\delta\midd ~ S}}
        } \hfill\hspace{1ex}
    \mathsf{(rel\_error)} ~ {\displaystyle 
      \frac{\mathsf{eval}(t_1\oplus t_2) = \error} 
        {\tuple{(t_1\oplus t_2,\cB)_\delta\midd S}
          \to
          \tuple{\errorsc_\delta}}
        }
    \end{array}
    
  \hspace{-3ex}\begin{array}{r@{~}l}
    \mathsf{(success)} & {\displaystyle 
      \frac{~} 
        {\tuple{\mathsf{true}_\delta\mid S
            \sep\mathsf{true}_{\theta}\mid S'} 
          \leadsto_\diamond
          \tuple{\success_\delta \sep \success_\theta}}
        } \3ex]

    \mathsf{(backtrack)} & {\displaystyle 
      \frac{S\neq\epsilon} 
        {\tuple{(\mathsf{fail},\cB)\mid S \sep
          (\mathsf{fail},\cB')\mid S'} \leadsto_\diamond \tuple{S\sep S'}}
        }\11ex]

    \mathsf{(choice\_fail)} & {\displaystyle 
      \frac{\mathsf{defined}(A,\cP)\wedge \clauses(A,\cP)=\emptyset
      \wedge \clauses(A',\cP)=\ol{c_k}} 
        {\tuple{(A,\cB)_\delta\mid S \sep (A',\cB')_\theta\mid S'} 
          \leadsto_{c(\emptyset,\ell(\ol{c_k}))} 
          \tuple{(\fail,\cB)_\delta\mid S\sep (\fail,\cB')_\theta\mid S'}}
        }\3ex]

    \mathsf{(cut)} & {\displaystyle 
      \frac{~} 
        {\tuple{(!^m,\cB)_\delta\mid S_1\mid ~?^m_{\delta'}\mid S
          \sep (!^m,\cB')_\theta\mid S'_1\mid ~?^m_{\theta'}\mid S'}
          \leadsto_\diamond \tuple{\cB_{\delta}\mid~?^m_{\delta'}\mid S
          \sep \cB'_{\theta}\mid~?^m_{\theta'}\mid S'}}
        } \3ex]

    \mathsf{(call)} & {\displaystyle 
      \frac{A\not\in\cV\wedge m~\mbox{is fresh}} 
      {\begin{array}{l}
          \tuple{(call(A),\cB)_\delta\mid S
        \sep (call(A'),\cB')_\theta\mid S'} \\
          \hspace{10ex}\leadsto_\diamond
          \tuple{(A[\cV/\mathsf{call}(\cV),!/!^m],\cB)_{\delta}\mid ~?^m_{\delta}\mid S
          \sep (A'[\cV/\mathsf{call}(\cV),!/!^m],\cB')_{\theta}\mid ~?^m_{\theta}\mid S'}
      \end{array}}
        } \3ex]

    \mathsf{(not)} & {\displaystyle 
      \frac{m~\mbox{is fresh}} 
        {\begin{array}{l}
            \tuple{(\backslash\!\!+\!\!(A),\cB)_\delta\mid S
          \sep (\backslash\!\!+\!\!(A'),\cB')_\theta\mid S'} \\
          \hspace{10ex}\leadsto_\diamond
          \tuple{(\mathsf{call}(A),!^m,\mathsf{fail})_{\delta}\mid \cB_\delta\mid ~?^m_\delta\mid S
          \sep (\mathsf{call}(A'),!^m,\mathsf{fail})_{\theta}\mid \cB'_\theta\mid ~?^m_\theta\mid S'}
      \end{array}}
        } \3ex]

    \mathsf{(unify\_fail)} & {\displaystyle 
      \frac{\mgu(t_1,t_2)=\mathsf{fail}} 
        {\tuple{(t_1=t_2,\cB)_\delta\mid S\sep (t'_1=t'_2,\cB')_\theta\mid S'}
          \leadsto_{d(t'_1,t'_2)}
          \tuple{\mathsf{fail}_{\delta}\mid S\sep \mathsf{fail}_{\theta}\mid S'
          }}
        } \3ex]

    \mathsf{(is\_error)} & {\displaystyle 
      \frac{\mathsf{eval}(e_2) = \mathsf{error}} 
        {\tuple{(t_1~\mathsf{is}~e_2,\cB)_\delta\mid S
          \sep (t'_1~\mathsf{is}~e'_2,\cB')_\theta\mid S'}
          \leadsto_\diamond
          \tuple{\error_\delta\sep \error_\theta}}
        } \3ex]

    \mathsf{(rel\_error)} & {\displaystyle 
      \frac{\mathsf{eval}(t_1\oplus t_2) = \mathsf{error}} 
        {\tuple{(t_1\oplus t_2,\cB)_\delta\mid S\sep (t'_1\oplus t'_2,\cB')_\theta\mid S'}
          \leadsto_\diamond
          \tuple{\error_\delta\sep \error_\theta}}
        } \
  \rule{\linewidth}{1pt}
  \caption{Extended concolic execution semantics} \label{fig:concolic3}
\end{figure}

\noindent
Regarding the concolic execution semantics, we follow a similar
approach to that of Section~\ref{concolic}. The labeled transition
rules can be seen in Figure~\ref{fig:concolic3}. Now, we consider six
kinds of labels for :
\begin{itemize}
\item The labels  and  with the same meaning
  as in the concolic semantics of Section~\ref{concolic}.

\item The label , which is used to denote a unification
  step, i.e., the step implies that  and  should unify.

\item In contrast, the label  denotes a disunification,
  i.e., the step implies that  and  should not unify.

\item The label  denotes a step where  is
  evaluated (see below). 

\item Finally, the label  denotes that the relational
  expression  should be equal to .
\end{itemize}
In particular, in rules \textsf{unify} and \textsf{unify\_fail}, the
labels store the unification that must hold in the step. Note that the
fact that  does not imply 
since  and  might be less instantiated than  and
.

In rule \textsf{is}, we label the step with  which means
that the fresh variable  should be bound to the evaluation of
 after grounding it. Note that introducing such a fresh variable
is required to avoid a failure in the subsequent step with rule
\textsf{unify} because of, e.g., a non-ground arithmetic expression
that could not be evaluated yet to a value using function
.
Note that rule \textsf{is\_error} does not include any label since we
assume that an error in the concrete computation just aborts the
execution and also the test case generation process.

Finally, in rule \textsf{rel} we label the step with  where
 is the value  of the relational expression in the
concrete goal, and  is a (possibly nonground) corresponding
expression in the symbolic goal. Here, we use the auxiliary function
 to simplify the relational expression as much as
possible. E.g.,  but
.

These labels can be used for extending the concolic testing algorithm
of Section~\ref{testing}. For instance, given a concolic execution
step labeled with , we have that solving 
will produce a binding for  (e.g., ) that will follow an
alternative path. Here, the concolic testing procedure will integrate
a constraint solver for producing solutions to negated constraints. We
find this extension of the concolic testing procedure an interesting
topic for future work.

\section{Proofs of Technical Results} \label{appendix:proofs}

\subsection{Concolic Execution Semantics}

\begin{proof}[Proof of Theorem~\ref{th:invariant}]
  Since the base case  trivially holds, in the following we only
  consider the inductive case . Let . By the
  inductive hypothesis, we have , ,  (if
  any), and . Now, we
  consider the step  and distinguish the
  following cases, depending on the applied rule:
  \begin{itemize}
  \item If the rule applied is , ,
     or , the claim follows
    trivially by induction.

  \item If the rule applied is , let us assume that
    we have ,  and , . Therefore, we have , and the claim follows straightforwardly by the induction
    hypothesis.

  \item Finally, if the applied rule is , then we
    have that ,  for some clause . Therefore, we have , where
     and . First, 
    holds by vacuity since the goals are not labeled with a
    clause. Also, the number of concrete and symbolic goals is
    trivially the same since  by the inductive hypothesis.
    Now, by the inductive hypothesis, we have  and thus
     and . Then, since ,
    , , and , it is easy to see that
     (and thus )
    and  when restricted to the variables of  
    (and thus ). Therefore, we can conclude
    .
    Finally, using a similar argument, we have
    .
  \end{itemize}
\end{proof}

\subsection{Solving Unifiability Problems}

First, we prove the following invariant which justifies that the
algorithm in Definition~\ref{alg1} is well defined.

\begin{proposition}
  The following statement is an invariant of the loops at
  lines~\ref{algo-msa-while-simple} and
  \ref{algo-msa-while-not-simple} of the algorithm in
  Definition~\ref{alg1}:
  \begin{description}
  \item[] (a)  for all 
    and (b)  for some .
  \end{description}
\end{proposition}

\begin{proof}
  Let us first consider the loop at line
  \ref{algo-msa-while-simple}. Clearly, the invariant holds upon
  initialization. Therefore, let us assume that it holds for some
  arbitrary set  and we prove it also holds for 
  with  for some simple disagreement pair  (or
  ).  
Let us consider part (a).  Since  for all ,
  there exist a substitution  such that  for
  all . Consider such an arbitrary . If
  , then part (a) of the invariant holds trivially in
  . Otherwise,  is clearly a unifier  and ,
  and it also holds. 
Consider now part (b). Since  for some , there
  exists a substitution  such that . Using a
  similar argument as before, either  with  or
   with , and part (b) of
  the invariant also holds in .

  Let us now consider the loop at line
  \ref{algo-msa-while-not-simple}. Clearly, the invariant holds when
  the previous loop terminates. 
Let  be the selected disagreement pair.
  Then  is replaced in  by a fresh variable
  , thus obtainining a new set .
  Let  and . Both  and 
  are idempotent substitutions because  and  since  is fresh.
  Let  be the atoms of  where  come from
  and  be the atoms obtained by replacing
   in  by . Then  and
  . 
Now, we want to prove that the invariant also holds in . Part (a) is trivial, since
  we only generalize some atoms: if  unify with  and , it
  will also unify with  and . Regarding part (b), we have
  that  for some . Clearly, part (b) also holds in
   if  is different from  and . Otherwise,
  w.l.o.g., assume that  and . Since 
  and , and  is a disagreement pair for ,
  we have that the subterm of  that corresponds to the position of
   should be more general than  (otherwise, it would not
  unify with both terms). Therefore, replacing  by a fresh variable
   will not change that, and we have  for some
  .
\end{proof}
The following auxiliary results are useful to prove the correctness of
the algorithms in Definitions~\ref{alg1} and \ref{alg2}. 

\begin{lemma}\label{lemma:technical-1}
  Suppose that  for some atoms  and 
  and some substitution .
  Then we have  for any
  substitution  with
  
  and
  .
\end{lemma}
\begin{proof}
  For any , 
  \begin{itemize}
  \item either  and then 
    
  \item or  and then
    
    because .
    Moreover,  because
    ,
    so .
    Finally, .
  \end{itemize}
  Consequently, .
  As , we have 
  i.e. .
\end{proof}

\begin{proposition}\label{proposition:invariant-correction-algo-pos-1}
  The loop at line~\ref{algo-msa-while-simple} always terminates
  and the following statement is an invariant of this loop.
  \begin{description}
  \item[] For each  there exists 
     and a substitution  such that
     and
    . 
  \end{description}
\end{proposition}
\begin{proof}
  Action~(\ref{algo-msa-simple-pair})
  reduces the number of simple disagreement pairs in
   which implies termination of the 
  loop at line~\ref{algo-msa-while-simple}.

  Let us prove that  is an invariant.
  First,  clearly holds upon initialization
  of . Suppose it holds prior to an execution of
  action~(\ref{algo-msa-simple-pair}).
  Therefore, for each  there exists 
     and a substitution  such that
     and
    .
Let  be the selected simple disagreement pair.
  Then, we consider a substitution 
  determined by . For any ,
  we have . 
  Thus  by .
Hence
  .
  Moreover, as  is a simple pair we have
  . Hence,
  
Since , we have .
  Consequently, by~(\ref{eq:ran-eta}) and
  Lemma~\ref{lemma:technical-1} we have
  
Now, we want to prove that  holds for ,
  i.e., that for each  there exists 
     and a substitution  such that
     and
    .
We let , so  holds.
Now, suppose by contradiction that
  , and let  be one of its elements.
  We have  because
  , so
  .
  Moreover,  by~(\ref{eq:ran-eta}) so
  . Therefore,
  
  which by  gives a contradiction.
  Consequently, 
  
  and the claim follows.
\end{proof}

\begin{proposition}\label{proposition:invariant-correction-algo-pos-2}
  The loop at line~\ref{algo-msa-while-not-simple} always terminates
  and the following statement is an invariant of this loop.
  \begin{description}
  \item[] For each  there exists 
     and a substitution  such that
     and
    .
  \end{description}
\end{proposition}
\begin{proof}
  Action~(\ref{algo-msa-not-simple-pair})
  reduces the number of disagreement pairs in
   which implies termination of the 
  loop at line~\ref{algo-msa-while-not-simple}.

  Let us prove that  is an invariant.
  By Proposition~\ref{proposition:invariant-correction-algo-pos-1},
   holds upon termination of the loop at
  line~\ref{algo-msa-while-simple}, hence  holds
  just before execution of the loop at
  line~\ref{algo-msa-while-not-simple}.
  Suppose it holds prior to an execution of
  action~(\ref{algo-msa-not-simple-pair}), so we have that, 
  for each  there exists 
     and a substitution  such that
     and
    .
Let  be the selected disagreement pair.
  Then  is replaced in  by a fresh variable
  , thus obtainining a new set .
  Let  and . Both  and 
  are idempotent substitutions because  and  since  is fresh.
  Let  be the atoms of  where  come from
  and  be the atoms obtained by replacing
   in  by . Then  and
  . 
Now, we want to prove that  holds in , i.e., that for each
   there exists  and a substitution
   such that  and
  .
  
  Since  holds in , we have .
  Moreover,  because  does not occur in .
  So if  then  and
  if  then .
  Consequently, let us set
  \begin{itemize}
  \item  and  if 
  \item  and  if 
  \item  and  if .
  \end{itemize}
  Then we have
  
  Moreover,
  
  i.e.
  
  As  then
  
  because 
  
  by  and 
   and
  .
  Moreover, by  we have
   so by~(\ref{eq:dom-theta-prime})
  
  Hence, .
With~(\ref{eq:A-unifies}) this implies that upon termination of
  action~(\ref{algo-msa-not-simple-pair}) the invariant
   holds
  because  is set to  and  to .
\end{proof}
The correctness of the algorithm in Definition~\ref{alg1} is then
stated as follows.

\begin{theorem}\label{theorem:correction-algo-pos}
  Let  be an atom and  be a set of atoms such that
   and  for all
  . 
  The algorithm in Definition~\ref{alg1} with input  and 
  always terminates and returns a substitution  such that
   unifies with all the atoms of  for any
  idempotent substitution  with
   and
  .
\end{theorem}

\begin{proof} 
  Proposition~\ref{proposition:invariant-correction-algo-pos-1}
  and Proposition~\ref{proposition:invariant-correction-algo-pos-2}
  imply termination of the algorithm.
Upon termination of the loop at line~\ref{algo-msa-while-not-simple}
  we have .
Let  be the element of  with . 
Now, we want to prove that  unifies with all the
  atoms in  for any idempotent substitution  (i.e.,
  ) such that
  
  and .
By Proposition~\ref{proposition:invariant-correction-algo-pos-2}, we
  have that, for all , there exists a substitution
   such that  and
  . 
From all the previous conditions, it follows that
   and
  . Therefore, by
  Lemma~\ref{lemma:technical-1}, we have
  .  Finally, since
  , we have 
  and, thus,  unifies with .
\end{proof}

\begin{proof}[Proof of Theorem~\ref{theorem:correction-algo-posneg}]
  Each step of the algorithm terminates, hence the algorithm terminates.
  Assume that the algorithm returns a substitution .
  The set  is ground by construction.
By Theorem~\ref{theorem:correction-algo-pos}, we have that  unifies with all the atoms in  as long as
   is idempotent,  and
  . Finally, the last check ensures that
   does not unify with any atom of .
\end{proof}

\subsubsection{Completeness} \label{sec:completeness}

For simplicity, we ignore the groundness constraint in this
section. Therefore, we now focus on the completeness of the following
unification problem: Let  be an atom and  be sets of
atoms such that  for all . Then, we
want to find a substitution  such that

We further assume that all atoms are renamed apart. 

Let us first formalize the notion of unifying substitution:

\begin{definition}[unifying substitution]
  Let  be an atom and let  be a set of atoms such that
   and  for all
  . We say that  is a unifying substitution for 
  w.r.t.\  if  for all .
\end{definition}
In particular, we are interested in \emph{maximal} unifying
substitutions computed by the algorithm in Definition~\ref{alg1}.
The relevance of maximal unifying substitutions is that variables from
 identify where further instantiation would result in a
substitution which is not a unifying substitution anymore.
For the remaining positions, we basically return their most general
unifier.

Now, we prove that binding an atom  with a maximal unifying
substitution for  w.r.t.\  does not affect to the existence
of a solution to our unification problem (**) above.
Here, for simplicity, we assume that only \emph{most specific}
solutions are considered, where a solution  is called a
\emph{most specific} solution for  and  if there
exists no other solution which is strictly less general than .
Furthermore, we also assume that the atom  has the form
.

\begin{lemma}
  Let  be an atom and  be sets of atoms such that
   for all . If there exists a
  substitution  such that  for all
   and  for all , then
  there exists a maximal unifying substitution  and a
  substitution  such that  for all
   and  for all .
\end{lemma}

\begin{proof} (\emph{sketch})
  Let us consider the stages of the algorithm in Definition~\ref{alg1}
  with input  (atom  is not needed since it has the form
   and, thus, imposes no constraint).  The first
  stage just propagates simple disagreement pairs of the form  or
  . When  only occurs once, it is easy to see that  is
  also a (most specific) unifying substitution for  w.r.t.\
  . Consider, e.g., that  contains a binding of
  the form  for some  and context
   and such that  corresponds to the same position of 
  and  in . Depending on the terms in the corresponding
  position of the remaining atoms, we might have  or . Either case, replacing  by  will not change the fact that
   is still a most specific unifying substitution for
  .

  The step is more subtle when there are several simple disagreement
  pairs for a given variable, e.g.,  and  (we could
  generalize it to an arbitrary number of pairs, but two are enough to
  illustrate how to proceed). In this case, if , we
  choose  and the reasoning is analogous to the previous case.
  However, when neither  not , the algorithm
  in Definition~\ref{alg1} is non-deterministic and allows us to
  choose any of them. As before, let us consider that 
  contains bindings of the form  and  for
  some  and contexts  and such that
   and  correspond to the same positions of  and
   in , respectively. Here, assuming there are no further
  constraints from the remaining atoms, a most specific unifying
  substitution might either bind  to  and leave 
  unconstrained (e.g., bound to a fresh variable) or the other way
  around: bind  to  and leave  unconstrained. Here,
  we choose the same alternative as in the considered solution
  , say  is bound to . Therefore,  is
  still a unifying substitution for  w.r.t.\ . Note
  that the new (non-simple) disagreement pair  introduced in
   will be generalized away in the next stage (and
  replaced by a fresh variable from ).
  
  Therefore, when the first stage is completed (i.e., step 2 in
  Definition~\ref{alg1}), we have propagated some terms from one atom to
  the remaining ones --as in the computation of a most general
  unifier-- thus producing a new set  such that  is
  still a (most specific) unifying substitution for  w.r.t.\
  .

  By definition, after this stage, there are no simple disagreement
  pairs in . 
  Then, in the second stage (step 3 in Definition~\ref{alg1}), we replace
  every (non-simple) disagreement pair  by a fresh variable
   from . Since  was a unifying substitution for
  , it should have a binding  for some
   and context  and such that 
  corresponds to the same position of  and  in ,
  where  is a variable.  Therefore, replacing  by a fresh
  variable  will not change the fact that  is still a
  unifying substitution for the resulting set (up to variable
  renaming).

  Hence, when the second stage is finished, we have a new set
   without any disagreement pair at all, i.e.,
   with . Moreover, since  is a most
  specific uniyfing substitution for  w.r.t.\ , we have
  . Therefore, there exists a substitution
   such that  such that  is
  a solution for  and , which concludes the
  proof.
\end{proof}

\section{Some More Examples on Solving Unifiability Problems}

\begin{example}[maximal unifying substitution]
  Let  and .
  First the algorithm of Definition~\ref{alg1} sets
  ,
  then it considers the simple disagreement pairs
  in . The substitution 
  is determined by . Action~(\ref{algo-msa-simple-pair})
  sets  to  i.e. to
  
  The substitution 
  is determined by . Action~(\ref{algo-msa-simple-pair})
  sets  to .
  The substitution  is determined by
  . Action~(\ref{algo-msa-simple-pair}) sets  to
   i.e. to
  
  Now no simple disagreement pair occurs in  hence the algorithm
  skips to the loop at line~\ref{algo-msa-while-not-simple}.
  \begin{itemize}
  \item Action~(\ref{algo-msa-not-simple-pair}) replaces 
    the disagreement pair  with a
    fresh variable , hence  is set to
    .
  \item Action~(\ref{algo-msa-not-simple-pair}) replaces 
    the disagreement pair 
    with a fresh variable , hence  is set to
    .
  \end{itemize}
  As  the loop at line~\ref{algo-msa-while-not-simple}
  stops and the algorithm returns the substitution .

  Note that there are several non-deterministic possibilities
  for ,  and . For instance, if we
  consider , which is determined by ,
  then  is set to .
  The loop at line~\ref{algo-msa-while-not-simple} finally sets 
   to , so the algorithm returns the substitution
  .
\end{example}
We note that the set  used by the algorithm
of Definition~\ref{alg1} may contain several occurrences
of a same, non-simple, disagreement pair.

\begin{example}[maximal unifying substitution]
  Let  and .
  First the algorithm sets .
  Then the loop at line~\ref{algo-msa-while-simple}
  considers the simple disagreement pairs in  and,
  for instance, it sets  to 
  (it may also set  to 
  or to ).
  As no simple disagreement pair now occurs in , the
  algorithm jumps at line~\ref{algo-msa-while-not-simple}.
  The pair  occurs twice in .
  Action~(\ref{algo-msa-not-simple-pair}) replaces each occurrence
  with the same variable , so the loop at
  line~\ref{algo-msa-while-not-simple} sets
   to  and the algorithm returns .
\end{example}

\begin{example}[maximal unifying substitution]
  Let  and .
  First the algorithm sets .
  Then the loop at line~\ref{algo-msa-while-simple}
  considers the simple disagreement pairs in  and,
  for instance, it sets  to 
  (it may also set  to 
  or to ).
  As no simple disagreement pair now occurs in , the
  algorithm jumps at line~\ref{algo-msa-while-not-simple}.
  The pairs  and  occur once in  and
  Action~(\ref{algo-msa-not-simple-pair}) replaces them with
  two different variables .
  So the loop at line~\ref{algo-msa-while-not-simple} sets
   to  and the algorithm returns .
\end{example}

\end{appendix}



\end{document}
