\documentclass{LMCS}

\def\doi{7 (3:21) 2011}
\lmcsheading {\doi}
{1--42}
{}
{}
{Mar.~\phantom08, 2011}
{Sep.~28, 2011}
{}   

\usepackage{enumerate}
\usepackage{amsmath,amssymb,xspace}
\usepackage{caption}
\usepackage{stmaryrd}
\usepackage{mathpartir}
\usepackage{hyperref}

 








\newcommand{\myskip}[1]{}

\newcommand{\lb}[1]{
\begin{center}
\fbox{
\begin{minipage}{4.5in}
{\bf Lars' comment:} {\rm #1}
\end{minipage}
}
\end{center}
}

\newcommand{\js}[1]{
\begin{center}
\fbox{
\begin{minipage}{4.5in}
{\bf Jan's comment:} {\rm #1}
\end{minipage}
}
\end{center}
}

\newcommand{\br}[1]{
\begin{center}
\fbox{
\begin{minipage}{4.5in}
{\bf Bernhard's comment:} {\rm #1}
\end{minipage}
}
\end{center}
}

\newcommand{\hy}[1]{
\begin{center}
\fbox{
\begin{minipage}{4.5in}
{\bf Hongseok's comment:} {\rm #1}
\end{minipage}
}
\end{center}
}

\newcommand{\comment}[1]{\marginpar{{\footnotesize #1 }}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
 
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}

\newenvironment{rcases}
{\left.\begin{aligned}}
{\end{aligned}\right\rbrace}

\newcommand{\ALMOSTPURE}{\text{pseudo pure}\xspace}
\newcommand{\boring}{canonical\xspace} \newcommand{\boringly}{canonically\xspace} \newcommand{\Heap}{\ensuremath{\mathit{Heap}}\xspace}
\newcommand{\NIL}{\ensuremath{\mathit{nil}}\xspace}
\newcommand{\Ref}{\ensuremath{\mathit{Ref}}\xspace}
\newcommand{\Val}{\ensuremath{\mathit{Val}}\xspace}
\newcommand{\BVal}{\ensuremath{\mathit{BVal}}\xspace}
\newcommand{\Com}{\ensuremath{\mathit{Com}}\xspace}
\newcommand{\NORMAL}{\ensuremath{\mbox{\it ok}}\xspace}
\newcommand{\ERR}{\ensuremath{\mbox{\it error}}\xspace}
\renewcommand{\O}{\ensuremath{O}}
\newcommand{\SVAR}{{\textsc{Var}}\xspace}
\newcommand{\Label}{{\textsc{Label}}\xspace}
\newcommand{\SEXP}{{\mathit{Exp}}\xspace}
\newcommand{\SBEXP}{{\mathit{BExp}}\xspace}
\newcommand{\SIEXP}{{\mathit{IExp}}\xspace}
\newcommand{\SCOM}{{\mathit{Com}}\xspace}
\newcommand{\QUOTE}[1]{\textnormal{`\ensuremath{#1}'}}
\newcommand{\UNQUOTE}[1]{\SYN{eval}\,{#1}}
\newcommand{\SYN}[1]{\ensuremath{\texttt{#1}}}
\newcommand{\upd}{\ensuremath{\mathop{:=}}}
\renewcommand{\l}{\ensuremath{\ell}\xspace}
\newcommand{\strue}{\ensuremath{\mathit{true}}\xspace}
\newcommand{\sfalse}{\ensuremath{\mathit{false}}\xspace}

\newcommand{\powerset}[1]{\ensuremath{\wp(#1)}}
\newcommand{\fvar}{\ensuremath{\mathsf{fv}}}
\newcommand{\fv}[1]{\ensuremath{\mathit{fv}(#1)}}
\newcommand{\bv}[1]{\ensuremath{\mathit{bv}(#1)}}
\newcommand{\lam}[2]{\ensuremath{\lambda#1.\,#2}}
\newcommand{\bnfeq}{\ensuremath{::=}}
\newcommand{\hmid}{\ensuremath{\;|\;}}
\newcommand{\defiff}{\ensuremath{\stackrel{\mbox{\tiny \it def}}{\Leftrightarrow}}}
\newcommand{\defeq}{\ensuremath{\stackrel{\mbox{\tiny \it def}}{=}}}
\newcommand{\ignore}[1]{}
\newcommand{\Rec}[1]{\ensuremath{\mathit{Rec}(#1)}}
\newcommand{\recselect}[2]{\ensuremath{{#1}({#2})}}  \newcommand{\PROJ}[2]{\ensuremath{\pi_{#1}(#2)}}
\newcommand{\record}[1]{\ensuremath{\left.\!\{\!|{#1}|\!\}\right.\!}}
\newcommand{\dom}[1]{\ensuremath{\mathsf{dom}({#1})}}
\newcommand{\inj}[1]{\ensuremath{{#1}}}
\newcommand{\pair}[2]{\ensuremath{\left\langle{#1},{#2}\right\rangle}}
\newcommand{\tuple}[1]{\ensuremath{\left\langle{#1}\right\rangle}}
\newcommand{\supp}[1]{\ensuremath{\mathit{supp}(#1)}}
\newcommand{\id}{\ensuremath{\mathit{id}}}
\newcommand{\Cont}[1]{\ensuremath{#1^{\perp}}}
\newcommand{\CPS}[1]{\ensuremath{#1^{\perp\!\!\perp}}}
\newcommand{\ContRel}[1]{\ensuremath{\mathrel{#1^{\perp}}}}
\newcommand{\CPSRel}[1]{\ensuremath{\mathrel{#1^{\perp\!\!\perp}}}}
\newcommand{\FORALL}[1]{\ensuremath{\forall#1.\,}}
\newcommand{\EXISTS}[1]{\ensuremath{\exists#1.\,}}
\newcommand{\inCom}{\ensuremath{\iota_\textit{Com}}}
\newcommand{\unlift}[1]{\ensuremath{#1_\downarrow}}
\newcommand{\lift}[1]{\ensuremath{#1_\bot}}
\newcommand{\COMB}{\ensuremath{\cdot}}
\newcommand{\DISJ}{\ensuremath{\mathop{\#}}}


\newcommand{\TERR}{\ensuremath{T_\textit{err}}\xspace}
\newcommand{\SET}{\ensuremath{\textbf{Set}}\xspace}
\newcommand{\POSET}{\ensuremath{\textbf{PoSet}}\xspace}
\newcommand{\FMCpo}{\ensuremath{\textbf{FM-Cpo}}\xspace}
\newcommand{\FMCppo}{\ensuremath{\textbf{FM-Cppo}}\xspace}
\newcommand{\Cppo}{\ensuremath{\textbf{Cppo}}\xspace}
\newcommand{\N}{\ensuremath{\mathbb{N}}\xspace}
\newcommand{\D}{\ensuremath{\mathbb{D}}\xspace}
\newcommand{\Env}{\ensuremath{\textit{Env}}\xspace}
\newcommand{\Var}{\ensuremath{\mathit{Var}}\xspace}
\newcommand{\Loc}{\ensuremath{\mathit{Loc}}\xspace}
\newcommand{\Nats}{\ensuremath{\mathit{Nats}^{\scriptsize +}}\xspace}
\newcommand{\Ints}{\ensuremath{\mathit{Integers}}\xspace}
\newcommand{\Perm}{\ensuremath{\mathit{perm}}\xspace}
\newcommand{\act}{\ensuremath{\cdot}}
\newcommand{\IMPLIES}{\ensuremath{\Rightarrow}}
\newcommand{\IFF}{\ensuremath{\Leftrightarrow}}
\newcommand{\lub}{\ensuremath{\sqcup}}
\newcommand{\trans}[2]{\ensuremath{(#1\,#2)}}
\newcommand{\sto}{\ensuremath{\multimap}}
\newcommand{\key}[1]{\ensuremath{\mathrm{#1}}\xspace}
\newcommand{\kw}[1]{\textnormal{\sf\textbf{#1}}\xspace}
\newcommand{\triple}[3]{{\ensuremath{\!\left.\{ #1 \}\, #2\, \{  #3 \}\!\right.}}}
\newcommand{\VALID}[1]{\ensuremath{\models{#1}}}
\newcommand{\K}{\ensuremath{\mathcal P}}
\newcommand{\C}{\ensuremath{\mathcal C}}
\newcommand{\access}{\ensuremath{\sqsubseteq}}
\newcommand{\A}{\ensuremath{\mathcal A}}
\newcommand{\R}{\ensuremath{\mathcal R}}
\newcommand{\EQ}[1]{\ensuremath{\textnormal{\textsf{Eq}}(#1)}}
\newcommand{\True}{\ensuremath{\mathit{true}}}
\newcommand{\False}{\ensuremath{\mathit{false}}}
\newcommand{\pointsto}{\ensuremath{\mapsto}}
\newcommand{\pASR}{{\mathit{pAssn}}\xspace}
\newcommand{\ASR}{{\mathit{Assn}}\xspace}
\newcommand{\EMP}{\ensuremath{\textit{emp}}}
\newcommand{\wemp}{\textnormal{\textit{emp}}}
\newcommand{\fresh}{\kw{newloc}}
\newcommand{\rnk}[1]{\textit{rnk}(#1)}

\newcommand{\SPEC}{{\mathit{Spec}}\xspace}
\newcommand{\TRUE}{{\mathbf{T}}}
\newcommand{\FALSE}{{\mathbf{F}}}


\newcommand{\den}[1]{\left\llbracket #1
  \right\rrbracket}                            
\newcommand{\ASSden}[1]{\ensuremath{\den{#1}}}
\newcommand{\EXPden}[1]{\ensuremath{\den{#1}}}
\newcommand{\COMden}[1]{\ensuremath{\den{#1}}}
\newcommand{\rec}[1]{\left.\{#1\}\right.}
\newcommand{\recty}[1]{\left\langle#1\right\rangle}

\newcommand{\RN}[1]{\textsc{\scriptsize(#1)}\xspace}
\newcommand{\textRN}[1]{\textsc{(#1)}\xspace}

\newcommand{\mimp}{\,{-\!\!*}\,}

\newcommand{\ntri}[3]{{{#1}\,{\mapsto}\,{{\{{#2}\}}\, \_\, {\{{#3}\}}}}\xspace}
\newcommand{\ntria}[4]{{{#1}\,{\mapsto}\,{{\{{#2}\}}{\, #3\, }{\{{#4}\}}}}\xspace}

\newcommand{\commentout}[1]{}

\newcommand{\hkey}[1]{{\bf #1}}

\newcommand{\letin}[2]{\hkey{let}\; #1 \;\hkey{in}\; #2}
\newcommand{\letrec}[2]{\hkey{letrec}\; #1 \;\hkey{in}\; #2}
\newcommand{\letdyn}[2]{\hkey{letdyn}\; #1 \;\hkey{in}\; #2}
\newcommand{\Letin}[2]{\begin{array}[t]{@{}l}
                        \hkey{let}\; #1 \\
                        \hkey{in}\; #2
                       \end{array}}
\newcommand{\letbe}[3]{\hkey{let}\; #1 \; \hkey{be}\; #2 \;\hkey{in}\; #3}
\newcommand{\Letbe}[3]{\begin{array}[t]{@{}l}
                        \hkey{let}\; #1 \; \hkey{be}\; #2 \\
                        \hkey{in}\; #3
                       \end{array}}
\newcommand{\Letbec}[3]{\begin{array}{@{}l}
                        \hkey{let}\; #1 \; \hkey{be}\; #2 \\
                        \hkey{in}\; #3
                       \end{array}}

\newcommand{\Ifthen}[2]{\begin{array}[t]{@{}l}
                        \hkey{if}\; #1 \\
                        \hkey{then}\; #2
                        \end{array}}
\newcommand{\mifthenelse}[3]{\hkey{if}\; #1 \;\hkey{then}\; #2 \;\hkey{else}\; #3}
\newcommand{\Ifthenelse}[3]{\begin{array}[t]{@{}l}
                                \hkey{if}\; #1 \\
                                \hspace{0em} \hkey{then}\; #2 \\
                                \hspace{0em} \hkey{else}\; #3
                            \end{array}}
\newcommand{\Ifthenandelse}[3]{\begin{array}[t]{@{}l}
                                \hkey{if}\; #1 \; \hkey{then}\; #2 \\
                                \hkey{else}\; #3
                            \end{array}}

\renewcommand{\P}{\ensuremath{\mathcal{P}}\xspace}
\newcommand{\Pred}{\ensuremath{\mathrm{Pred}}\xspace}

\newcommand{\Ad}{\mathrm{Ad}}  \newcommand{\DCl}{\Ad}  \newcommand{\UAdm}{\mathit{UAdm}\xspace}
\newcommand{\CBUlt}{\mathit{CBUlt}\xspace}
\newcommand{\RANK}[2]{\ensuremath{{#1}_{[#2]}}}
\newcommand{\RR}{\ensuremath{\mathbb R}}
\newcommand{\W}{\ensuremath{W}}
\newcommand{\FOLD}{\ensuremath{\iota}}
\newcommand{\UNFOLD}{\ensuremath{\iota^{-1}}}
\newcommand{\nequiv}[1]{\ensuremath{\mathrel{\stackrel{#1}{=}}}}
\newcommand{\PHI}[1]{\ensuremath{\mathop{\overline{#1}}}}

\newcommand{\HOLE}{\ensuremath{\cdot}}
\newcommand{\INT}{\textsf{int}\xspace}
\newcommand{\BOOL}{\textsf{bool}\xspace}
\newcommand{\sdash}{\ensuremath{\vdash_s}} \newcommand{\adash}{\ensuremath{\vdash}} \newcommand{\tdash}{\ensuremath{\vdash}} 

\renewcommand{\clubsuit}{\boxempty}
\newcommand{\wapp}{\ensuremath{{\mathop{@}}}}
\newcommand{\X}{\ensuremath{\Xi}}



\title[Nested Hoare Triples and Frame Rules for Higher-order Store]{Nested Hoare Triples and Frame Rules for Higher-order Store\rsuper*} 
  
\author[J.~Schwinghammer]{Jan Schwinghammer\rsuper a}
\address{{\lsuper a}Programming Systems Lab, Saarland University, 66123 Saarbr\"ucken, Germany}
\email{jan@ps.uni-saarland.de}


\author[L.~Birkedal]{Lars Birkedal\rsuper b} 
\address{{\lsuper b}IT University of Copenhagen, Rued Langgaards Vej 7, 2300 K{\o}benhavn S., Denmark}
\email{birkedal@itu.dk}


\author[B.~Reus]{Bernhard Reus\rsuper c}
\address{{\lsuper c}School of Informatics, University of Sussex, Brighton BN1 9QH, U.K.}
\email{bernhard@sussex.ac.uk}


\author[H.~Yang]{Hongseok Yan\rsuper dg} 
\address{{\lsuper d}Department of Computer Science, University of Oxford, Oxford OX1 3QD, U.K.}
\email{Hongseok.Yang@cs.ox.ac.uk}


 \keywords{Higher-order store, Hoare logic, separation logic, semantics.}
\subjclass{F.3.1, F.3.2}
\titlecomment{{\lsuper*}A preliminary version of this work was presented at the 18th EACSL Annual Conference on Computer Science Logic (CSL'09), 7--11 September 2009, Coimbra, Portugal \cite{schwinghammerBRY09}.}

 
\begin{document}

\begin{abstract}
\noindent
Separation logic is a Hoare-style logic for reasoning about programs with heap-allocated mutable data structures.  
As a step toward extending separation logic to high-level languages with ML-style general (higher-order) storage, we investigate the compatibility of nested Hoare triples with several variations of higher-order frame rules. 

The interaction of nested triples and frame rules can be subtle, and the inclusion of certain  frame rules is in fact unsound. 
A particular combination of rules can be shown consistent by means of a Kripke model where worlds live in a recursively defined ultrametric space. 
The resulting logic allows us to elegantly prove programs involving stored code. In particular, using recursively defined assertions, it leads to natural specifications and proofs of invariants  required for dealing with recursion through the store.
\end{abstract}


\maketitle


\section{Introduction}
\label{sec:intro}

Many programming languages permit not only the storage of first-order data, but also forms of higher-order store. Examples are code pointers in C, and ML-like general references. 
It is therefore important to have modular reasoning principles for these language features. 
Separation logic is  an effective formalism for modular reasoning about pointer programs, in low-level C-like programming languages and, more recently, also in higher-level languages 
\cite{Krishnaswami:ML-SL07,Nanevski:Morrisett:Shinnar:Govereau:Birkedal:08,Parkinson:Biermann:08,Reynolds:02a}.
However, its assertions are usually limited to talk about first-order data. 

In previous work, we have begun the study of separation logic for languages with higher-order store \cite{Birkedal:Reus:Schwinghammer:Yang:08,Reus:Schwinghammer:06}. A challenge in this research is the combination of proof rules from separation logic for  modular reasoning, and proof rules for code stored on the heap. 
 Ideally, a program logic for higher-order store provides sufficiently expressive proof rules that, e.g., can deal with recursion through the store, and at the same time interact well with (higher-order) frame rules, which enable modular program verification. 

Our earlier work \cite{Birkedal:Reus:Schwinghammer:Yang:08,Reus:Schwinghammer:06} shows that separation logic is consistent with higher-order store. However, the formulation in this earlier work has a shortcoming: code is treated like any other data in that  assertions can only mention concrete commands. In order to obtain modular, open and reusable reasoning principles,  it is clearly desirable to abstract from particular code and instead (partially) specify its behaviour. For example, when verifying mutually recursive procedures on the heap, one would like to consider each  procedure in  isolation, relying on properties but not the implementations of the others. The recursion rule given by Birkedal et al.\ \cite{Birkedal:Reus:Schwinghammer:Yang:08} and Reus and Schwinghammer  \cite{Reus:Schwinghammer:06} does not achieve this. 
A second, and less obvious consequence of  lacking  behavioural specifications for code in assertions is that one cannot take full advantage of the frame rules of separation logic. For instance, 
the programming language in \cite{Birkedal:Reus:Schwinghammer:Yang:08} 
can simulate higher-order procedures by passing arguments through the heap, but the available (higher-order) frame rules are not useful here because an appropriate specification for this encoding is missing. 

In this article, we address these shortcomings by investigating a program logic in which stored code can be specified using Hoare triples, i.e., an assertion language with \emph{nested triples}. 
This is an obvious idea, but the combination of nested triples and frame rules turns out to be tricky: the most natural combination is in fact unsound. 

The main technical contributions of this article are therefore: 
\begin{enumerate}[(1)]
\item the observation that certain ``deep'' frame rules can be unsound, 
\item the suggestion of a ``good'' combination of nested Hoare triples and frame rules,  and 
\item the verification of those  rules  by means of   an elegant Kripke model, based on a denotational semantics of the programming language, where the worlds are themselves world-dependent sets of heaps. 
\end{enumerate}
The worlds form a complete metric space and  (the denotation of) the operation , needed to generically express higher-order  frame rules, is contractive; as a consequence, our logic permits recursively defined assertions. 

\paragraph{Outline} After introducing the syntax of programming language and assertions in Section~\ref{sec:syntax} we discuss some unsound combinations of rules in Section~\ref{sec:ProgramLogic}. This section also contains the suggested set of rules for our logic.   The soundness of the logic is then shown  in Section~\ref{sec:Semantics}.
Section~\ref{sec:discussion-of-proof-rules} discusses further proof rules for nested triples. Finally the conclusion  addresses  related work and   the differences between the model presented here and a step-indexed model.


\section{Syntax of Programs and Assertions}
\label{sec:syntax}
 
This section presents the syntax of the programming language and that of assertions.

\subsection{Programming language}
We consider a simple imperative programming language extended with operations for 
stored code and heap manipulation. The syntax of the language is shown in 
Figure~\ref{fig:LanguageSyntax-alt}. The expressions in the language are
integer expressions, variables, and the quote expression
 for representing an unevaluated command . The integer
or code value denoted by expression  can be stored in a heap cell
 using , and this stored value can later be looked up
and bound to the (immutable) variable  by .
In case the value stored in cell  is code , we can
run (or ``evaluate'') this code by executing . Our language also
provides constructs for allocating and disposing heap cells such as 
above. 

We point out that, as in ML, all variables  in
our language are \emph{immutable}, so that once they are bound to a value, their values do not change. 
This property of the language lets us avoid side conditions on variables when studying frame rules.
Finally, we do not include while loops in our language; these could be added easily, and they can also be expressed by stored code (using Landin's knot).\footnote{To obtain the original while rule of Hoare logic one needs to be able to hide the additional pointer storing the body of the while loop. This can be achieved  using anti-frame rules as discussed e.g.\ in \cite{schwinghammerYBPR10}.}
 
\begin{example}[Iterate procedure] 
An iterator that calls its parameter function as well as itself through the store can be programmed as follows. 
 
Here we assume that cells \emph{it},  and  are some fixed global constants, and that the iterator code is stored in the cell \emph{it}.
Command  then calls the code in  as many times as the value of counter cell  prescribes.
\end{example}


\begin{figure*}[t]
\hrule
1ex]
C\in\SCOM 
& \bnfeq &
   [e_1]\SYN{:=}e_2 \hmid
  \SYN{let}~y\SYN{=}[e]~\SYN{in}~C \hmid
  \UNQUOTE [e] 
  & \mbox{assignment, lookup, unquote}
\\
& \hmid &
  \SYN{let}~x{=}\SYN{new}~(e_1,\ldots,e_n)~\SYN{in}~C\hmid\SYN{free}~e
  & \mbox{allocation, disposal}
\\
& \hmid &
  \SYN{skip}\! \hmid \!
  C_1\SYN{;}C_2 
  & \mbox{no op, sequencing } 
\\
& \hmid &
  \SYN{if}\,(e_1{=}e_2)\,\SYN{then}\,C_1\,\SYN{else}\,C_2   
  & \mbox{conditional} 
\
\hrule
\caption{\label{fig:LanguageSyntax-alt}Syntax of expressions, commands and assertions}
\end{figure*}



\subsection{Assertions and distribution axioms}

Our assertion language is standard first-order intuitionistic logic,
extended with
separating connectives  and , the points-to predicate 
~\cite{Reynolds:02a},
and recursively defined assertions . 
The syntax of assertions appears in Figure~\ref{fig:LanguageSyntax-alt}.
Each assertion describes a property of states, which consist of an immutable stack and 
a mutable heap. Formula  means that the heap component of the state is
empty, and  means that the heap component can be split
into two, one satisfying   and the other satisfying , both evaluated with respect to the same
stack. The spatial implication operator (``magic wand'') is omitted here for reasons explained
later in Remark~\ref{remark:wand}. The points-to predicate 
states that the heap component consists of only one cell  whose 
content is   or, in case  is a command, an approximation   of  which is defined (terminates) 
for less heaps than . This is in line with the fact that we consider \emph{partial correctness} only.

One interesting aspect of our assertion language is that it includes Hoare triples 
 and invariant extensions ; previous work
\cite{BirkedalL:semslt-lmcs,Birkedal:Reus:Schwinghammer:Yang:08} does not treat them as assertions 
but as so-called \emph{specifications}, which form a different syntactic category. 
A consequence of having these new constructs as assertions
is that they allow us to study proof rules for exploiting locality of stored code
systematically, as we will describe shortly.

Intuitively,  means that  denotes code 
satisfying , and  denotes a modification of  where 
all the pre- and post-conditions of triples inside  are -extended with . In other words,
all code specified by pre- and postconditions inside  must preserve  invariant . For instance,
the assertion

is equivalent to
.
This assertion says that cell  is the only cell in the heap
and it stores code  that satisfies the triple .
This intuition about the  operator is made precise in the set of
axioms in Figure~\ref{fig:DistRules}, which let us distribute  through
  the constructs of the assertion language. 


\begin{figure*}[t]
\hrule
1ex]
  \triple{P}{e}{Q} {\otimes} R
&
  \;\Leftrightarrow\;
&
  \triple{P \,{\circ}\, R}{e}{Q \,{\circ}\, R}
\\
  (P\,{\otimes}\,R')\,{\otimes}\, R
&
  \;\Leftrightarrow\;
&
  P\,{\otimes}\,(R'\,{\circ}\, R)
\\
  (\kappa x. P)\,{\otimes}\, R
&
  \;\Leftrightarrow\;
&
  \kappa x. (P \,{\otimes}\, R)
& (\kappa \,{\in}\, \{\forall,\exists\}, x\notin\fv{R})
\\
  (P \,{\oplus}\, Q)\,{\otimes}\, R
&
  \;\Leftrightarrow\;
&
  (P \,{\otimes}\, R) \,{\oplus}\, (Q \,{\otimes}\, R)
&
  (\oplus \,{\in}\, \{\Rightarrow, \wedge, \vee, *\})
\\
  P \otimes R
&
  \;\Leftrightarrow\;
&
  P
&
(\mbox{ is one of , , , , })
\end{array}

\label{eqn:unfolding-axiom}
(\mu X(\vec x).P)(\vec e) \Leftrightarrow P[X:=\mu X(\vec x).P,\, \vec x:=\vec e]\ .
\begin{array}{lcl}
C_{\mathit{it},f,c} & \equiv & \SYN{let}\ n\, \SYN{=}\, [c]\ \SYN{in} \\
&& \SYN{if}\ n\,\SYN{=0}\ \SYN{then}\ \SYN{skip}\  \SYN{else}\  (\,  \UNQUOTE{[f]} \SYN{;}\ [c]\, \SYN{:=}\, n \SYN{-1} \SYN{;}\ \UNQUOTE{[\emph{it}]} \, ) 
\end{array}
\triple{c\, {\pointsto}\_ * f\,{\pointsto}\triple{\EMP}{\_}{\EMP} * R_{\mathit{it}}}
{\QUOTE{C_{\mathit{it},f,c}}}
{c\,{\pointsto}0  * f\,{\pointsto}\triple{\EMP}{\_}{\EMP} * R_{\mathit{it}}}\ .R_{\mathit{it}} \equiv \mu X.\, \mathit{it} \, {\pointsto}\,
 \triple{c\,{\pointsto}\_ * f\,{\pointsto}\triple{\EMP}{\_}{\EMP} * X}
 {\_}
{c\,{\pointsto}0 * f\,{\pointsto}\triple{\EMP}{\_}{\EMP} * X}\ .
\begin{array}{l}
\{\, c\,{\pointsto}\_ * f\,{\pointsto}\triple{\EMP}{\_}{\EMP} * \mathit{it}\,{\pointsto}\_ \, \}
\\
\, [\mathit{it}]  \SYN{:=}\,  \QUOTE{C_{\, \mathit{it},f,c}}  \SYN{;}\, \SYN{\UNQUOTE{[]}}\\
\{\, c\, {\pointsto}0 * f\,{\pointsto} \triple{\EMP}{\_}{\EMP} * R_{\mathit{it}} \}\ .
\end{array}

\inferrule[Conj]{ }  { \X;\Gamma \;\adash\; \triple{P_2}{e}{Q_2} \wedge  \triple{P_1}{e}{Q_1} \Rightarrow
  \triple{P_1{\wedge} P_2}{e}{Q_1{\wedge} Q_2} 
}

\inferrule[Deref]{
  \X;\Gamma,x\,{\adash}\,\triple{P\,{*}\,e\,{\mapsto}\,x}{\QUOTE{C}}{Q}
}{
  \X;\Gamma\,{\adash}\, \triple{\exists x.P\,{*}\,e\,{\mapsto}\,x}{\QUOTE{\SYN{let}\,{x{=}[e]}\,\SYN{in}\,{C}}}{Q}
}(x \not\in \fvar(e,Q))
\2ex] 
\inferrule[UpdateInv]{
}{
  \X;\Gamma\,{\adash}\,\triple{e\,{\mapsto}\,\_ \,{*}\, (e_1{\mapsto}e_0 \wedge  \triple{A}{e_0}{B})}{\QUOTE{[e] \,{:=}\, e_0}}{(e\,{\mapsto}\,e_0\wedge  \triple{A}{e_0}{B}) \,{*}\, (e_1{\mapsto}e_0 \wedge \triple{A}{e_0}{B}) }
}
\2ex]
\inferrule[If]{
  \X;\Gamma\adash \triple{P \,{\wedge}\, e_0{=}e_1}{\QUOTE{C}}{Q} \quad \X;\Gamma\adash \triple{P \,{\wedge}\, e_0{\not=}e_1}{\QUOTE{D}}{Q}
}{
  \X;\Gamma\adash \triple{P}{\QUOTE{\SYN{if}\;(e_0{=}e_1)\;\SYN{then}\;C\;\SYN{else}\;D}}{Q}
}
\
\hrule
\caption{Proof rules from separation logic}
\label{fig:SLRules}
\end{figure*}

\begin{figure*}[!t]
\hrule
2ex]
\inferrule[ExistAux]{
}{
  \X;\Gamma \;\adash\; (\forall x.\triple{P}{e}{Q})\Rightarrow\triple{\exists x.P}{e}{\exists x.Q}
}(x \not\in \fvar(e))
\
\hrule
\caption{Non-syntax driven proof rules}
\label{fig:Nonsyntax:SLRules}
\end{figure*}


\subsection{Proof rule for recursive assertions}\label{subsubsec:runique}
Besides the axiom \eqref{eqn:unfolding-axiom} which lets us unfold recursive assertions, we include a proof rule that expresses the uniqueness of recursive assertions, 

for any  formally contractive in . 
Using this rule, the equivalence of (possibly recursively defined) assertions  and  can be proved by finding a suitable assertion  that has both  and  as fixed points. 


\subsection{Frame rule for higher-order store} 


The frame rule is the most important rule in separation logic, and it formalizes the intuition of local reasoning, where proofs focus on the footprints of the programs we verify. 
For instance, in Example~\ref{example:spec}, we have said we can prove

But if we wanted now to prove a similar result for an  that had some side effect like

then setting  we can prove  but now we need to  show

The so-called ``deep frame rule'' will allow us to  do just that, to prove triple \eqref{IIexDFR_eq} from triple \eqref{example_dfr} in one reasoning step, such that we can re-use our original proof. This rule will be discussed below and details of its concrete usage can be seen in  Example~\ref{example:DFR}.
Note also that the first-order (or shallow) frame rule does not achieve this, it would only give us

which is   not useful here.



Establishing  ``deep'' frame rules in our setting is challenging, because nested triples allow for several choices regarding the shape of the rule.  Moreover, the recursive nature of the higher-order store complicates matters and it is difficult to see which choices actually make sense (i.e., do not lead to inconsistency).

To see this problem more clearly, consider
the rules below:

Note that we have four choices, depending on whether
we use  or  and on whether
we have an inference rule or an axiom. If we choose the separating conjunction  for ,
we obtain \emph{shallow} frame rules that  add  to 
the outermost triple  only; 
they do not add  in nested triples
appearing in pre-condition  and post-condition . On the other hand,
if we choose  for , since ,
we obtain \emph{deep} frame rules that add
the invariant  not just 
to the outermost triple but also to all the nested triples in  and . 

The distinction between inference rule and axiom has  
some bearing on where the frame rule can be applied. With
the axiom version, we can apply the frame rule not just to valid triples,
but also to nested triples appearing in pre- or post-conditions
which is not possible with the inference rule

Ideally, we would like to have the axiom versions of the frame rules
for both the  and  connectives. Unfortunately, this is not possible for : 
adding the axiom version for   makes our logic unsound.
The source of the problem is that with the axiom 
version for , one can add invariants selectively to some, but not necessarily all,
nested triples. This flexibility can be abused to derive 
incorrect conclusions. 

Concretely, with the axiom version for  (\textsc{DeepFrameAxiom}) we can make the following derivation:


Here we use the monotonicity of  in the form of rule (\textsc{-Mono}), cf.~Figure~\ref{fig:proofrulesummary} in the Appendix.
The steps annotated  \textsc{-Dist} use the first equivalence    
of the distribution axioms for  in Fig.~\ref{fig:DistRules} 
(in  and  direction, respectively).
We annotate the application of an axiom between triples with  to indicate that we apply  it actually as a rule via the application of (\textsc{ModusPonens}). So, for instance,   (\textsc{Conseq}), used frequently below,   denotes   a sub-derivation of the following form:


where we  will usually omit the implications   and  when they are obvious from the context.

The fact we could derive  means that
when adding  to nested triples, we can skip the triples in the  part of
the pre- and post-conditions of . 
This flexibility leads to the unsoundness:
\begin{prop}
\label{prop:DeepFrameUnsound}
Adding the axiom version (\textsc{DeepFrameAxiom}) of the frame rule for  renders our logic
unsound.
\end{prop}
\proof
Let  be the recursive assertion , and note  that this means   
 holds.
Then, we can derive the triple:
 
 
Here the first step uses the derivation above for adding invariants 
selectively, and the last step uses the consequence rule with
the following two implications:


where the second equivalence follows from  the fact that  (use axioms (-\textsc{Overlap}), (-\textsc{Zero}), and (\textsc{-Mono}) of   Separation Logic from  Figure~\ref{fig:proofrulesummary})       with (\textsc{Conseq})\footnote{Note that it is important here that (\textsc{Conseq})  derives an implication between triples.}, and
 
in which the distribution axioms of  Figure~\ref{fig:DistRules} are used, again in concert with (\textsc{Conseq}) and Separation Logic rules like (\textsc{-Mono}).
 
Consider , i.e., the program that copies the contents from cell  to cell .
When  such that  holds,

 
Now we instantiate  in  with ,
discharge the premise of the resulting derivation
with the above derivation for , and obtain
 
But the post-condition of the conclusion here is equivalent to
 by the definition of  and 
the distribution axioms for . Thus, as our rule for 
will show later, we should be able to conclude that

However, since  is not even an address, the program  which executes the code \SYN{free}(-1)   now stored in cell 3 always faults, contradicting the requirement of separation logic that proved programs
run without faulting.
\qed



\begin{remark}[Counterexample for the Deep Frame Axiom]
Notice that in the derivation above  it is essential that  is a recursively defined assertion, otherwise we would not obtain that the locations  and  point to code satisfying the same  assertion .

While the above counterexample has been the first such counterexample historically, there is also another   form of counterexample discovered later which  uses the same ideas as the above but works ``through the store.'' More precisely,  in this alternative counterexample the copying code  resides on the heap where the frame axiom  can  be applied directly on a nested triple, and not through the derivation 

This rather follows the style of  \cite{Pottier09}\footnote{However, the antiframe rule is used there.} and \cite{CharltonReusLola10}\footnote{This uses a version where the copied code accesses a cell that is then disposed of before the code itself is executed later.}. For this counterexample, let  be as above and let
 
  First, observe that the following triple can be derived with  a rule for eval (this rule  \textsc{(Eval)} will be explained in detail in Section~\ref{subsec:eval-rule}):
 

 But the  (\textsc{DeepFrameAxiom}) (the axiom version for )  can be used to derive

 which then  by applying distribution axioms unfolding the definition of  yields:
  
 Applying this to triple \eqref{eval_dagger} with the help of an appropriate (\textsc{Conseq}) step we can therefore derive

and thus by the shallow frame rule again

This  triple   should not hold for all heaps since actually now the code in  has been laundered to work with its caller code in  although  the code in , to function properly, might depend on the code in  meeting the specification .  Using the above derivation, we can now construct a program that is provably safe but crashes, showing that (\textsc{DeepFrameAxiom}) cannot be correct (as the other used rules and axioms clearly are). First, with the rule version for  (\textsc{DeepFrameRule}) to add  one   gets


so that by definition of  , , and  we obtain

where  is the assertion 

(also used in the proof of Proposition~\ref{prop:DeepFrameUnsound}).
From that  one can easily derive with the rules  \textsc{(Seq)}, \textsc{(Eval)} and \textsc{(Conseq)}  that
  
Yet, if 
and , then the above program crashes. 
Although the code in  does not call the crashing code 
 in , it copies  
into , which is possible due to the ``laundered'' specification of  in the triple for . 


Again, this shows how essential it is that  is equivalent to  which forces  to be recursively defined to actually allow the copying to be performed. This version of the counterexample uses the (\textsc{DeepFrameRule}) rather than (\textsc{ModusPonens}) and (\textsc{-Mono}), and its pattern  is more likely to appear in ``naturally occurring'' examples.
 \end{remark}
 
As Proposition~\ref{prop:DeepFrameUnsound} shows, we cannot include (\textsc{DeepFrameAxiom}) in the proof system. 
Fortunately, 
the second best choice of frame axioms leads to a consistent proof system:
\begin{prop}
Both the inference rule version of the frame rule for  and the axiom version for 
are sound.
In fact, the  following more general version (\textsc{-Frame}) of the rule for  holds:

\end{prop}
We will prove this proposition in Section~\ref{sec:Semantics} by a model construction. 

\begin{example}[Application of (\textsc{-Frame})]
\label{example:DFR} 
Recall our specification

of the iteration command in Example~\ref{example:spec}, 
where  is a recursive specification for the iterator itself:

Assume this triple has been already proven (cf.\ Example~\ref{example:eval} below).
If the code  is to be used  on a procedure  that 
 needs some state , e.g.\ , then we need to show

This triple could be established by a proof similar to the one for the triple \ref{exDFR_eq} above, just carrying around the extra assumption . If we want to \emph{reuse} this proof though, or even more importantly, if we do not have the proof of the above triple because it is part of a module for which we do not have the actual code, then we can use rule (\textsc{-Frame}) on triple \eqref{exDFR_eq} to derive:

A \textsc{Conseq} step  using the equivalence of the first axiom in  Figure~\ref{fig:DistRules}  in both directions for the pre- and postcondition, respectively,  thus gives us the triple:

which by another four applications of distribution axioms yields the required triple.
Note that the rule~\textsc{(RUnique)}   would be needed to show   that  is equivalent to the recursive assertion

\end{example}




\subsection{Rule for executing stored code}
\label{subsec:eval-rule}
An important and challenging 
part of the design of a program logic for higher-order store is the
design of a proof rule for , the command
that executes code stored at .
Indeed, the rule should overcome two challenges directly
related to the recursive nature of higher-order store: (1)
implicit recursion through the store (i.e., Landin's knot), and (2)
extensional specifications of stored code.

These two challenges are addressed, using the expressiveness of our
assertion language, by the following rule for :

This rule states that in order to prove  for executing stored code in  under the assumption that  points to arbitrary code  (expressed by the  which is an abbreviation for ), it suffices to show that the specification  implies  that  itself fulfils triple 
. 

In the above rule we do not make any assumptions about what code  actually
points to, as long as it fulfils the specification . It may even be updated between recursive calls.  However, for recursion through the store,  must be recursively defined as it needs to maintain itself as an invariant of the code in .

\begin{example}[Recursion through the store with the iterator]\label{example:eval}
As seen in the iterator Example~\ref{example:spec} one would like to prove

with the help of \textsc{(Eval)}. First we set 

such that  is the same as . We are now in a position to  apply \textsc{(Eval)} obtaining the following proof obligation 

which can be seen to be identical to  which holds trivially.
\end{example}

The ({\sc Eval}) rule crucially relies on the expressiveness of
our assertion language, especially the presence of nested triples
and recursive assertions. In our previous work, we did not consider nested 
triples. As a result, we had to reason explicitly with stored code,
rather than properties of the code, as illustrated by one of our previous rules
for  \cite{Birkedal:Reus:Schwinghammer:Yang:08}:

Here the actual code  is specified explicitly in the pre- and post-conditions of the triple.
In both rules the intuition is that the premise states
that the body of the recursive procedure fulfils the triple, under the assumption that the recursive call already does so. 
In the ({\sc Eval}) rule this is done without direct reference to the code itself, using the variable  to stand for arbitrary code satisfying .
The soundness proof of ({\sc OldEval}) proceeded along the lines of Pitts' method for establishing relational properties of domains~\cite{Pitts:96}.
On the other hand, as we will show in Section~\ref{sec:Semantics}, ({\sc Eval}) relies on the availability of recursive assertions,
the existence of which is guaranteed by Banach's fixpoint theorem.

From the ({\sc Eval}) rule one can easily derive the axioms of Figure~\ref{fig:DerivedRulesHO}. The first two axioms are for non-recursive calls. This can be seen from the fact that in the pre-condition of the nested triples    does not appear at all or does not have a specification, respectively. Only the third axiom  ({\sc EvalRec}) allows for recursive calls. 
The idea of this axiom is that one  assumes that  the code in  fulfils the required triple   provided the code that  points to  at call-time fulfils the triple as well.
\begin{figure*}[t]
\hrule
2ex]
\inferrule[EvalNonRecUpd]{
}{
 \X;\Gamma\adash \triple{P*e\pointsto \forall \vec{y}.\, \triple{P* e\pointsto \_}{\_}{Q}}{\QUOTE{\UNQUOTE{[e]}}}{Q} 
} 
\
\hrule
\caption{Derived rules from {\sc Eval}}
\label{fig:DerivedRulesHO}
\end{figure*}
Let us look at the actual derivation of ({\sc EvalRec}) to make this evident.  We write 

 such that for the original 
 
  of the rule  ({\sc EvalRec}) we obtain with the help of Axiom~\eqref{eqn:unfolding-axiom}:

 Note that  in the derivation below  contains the variables  which may appear freely in  and .

In the derivation tree above, the axiom used at the top is simply a first-order axiom for  elimination. The quantified variables  are substituted by the variables  with the same name from the context.
After an application of rule ({\sc EvalRec}), those variables  can then be substituted further.
Step \textsc{Csub} abbreviates the following derivation where contexts have been omitted for clarity:
 

In the above derivation, (\textsc{R}) and (\textsc{T}) denote reflexivity and transitivity of implication, respectively, and step \textsc{unfold} denotes the following sub-derivation:


 The use of recursive specification 
 
  is essential here as it allows us to unroll the definition (see equivalence \eqref{eq:unfold_rec}) so that the ({\sc Eval}) rule can be applied. Note that in the logic of \cite{Honda:Yoshida:Berger:05}, which also uses nested triples  
 but  features neither a specification logic nor  any  frame rules or axioms,  recursive specifications do not exist. 
Avoiding them, one loses an elegant specification mechanism to allow for code updates during   recursion. Such updates are indeed possible as   \SYN{eval} uses a pointer to call code from the (obviously changeable) heap. In the logic of  \cite{Honda:Yoshida:Berger:05}   specifications would have to refer to other means to deal with such code updates, like e.g.\ families of code with uniform specifications. But  it is unclear to what extent such a formulation would allow for modular extensions. For modular reasoning one must not rely on concrete families of code in proofs,  otherwise these proofs are not reusable when the family has to be changed to allow for additional code.   Assuming the code in  does \emph{not} change, the  recursively defined  above can be expressed without recursion (we can omit the  now, as this is only needed for mutually recursively defined triples) as follows: 
 
 The question however remains how the assertion  can be proved for some concrete    that is stored in . In  \cite{Honda:Yoshida:Berger:05}  this is done by an induction on some appropriate argument, which is possible since only  total correctness  is considered there.    
In our logic,    ({\sc OldEval}) is strikingly  similar to a fixpoint induction  rule in ``de~Bakker and Scott'' style and ({\sc Eval}) even allows one to    abstract away from concrete code. These rules are elegant and simple  to use. Not only do they allow for recursion through the store, (\textsc{Eval}) also disentangles the reasoning from the concrete code stored in the heap, supporting modularity and extensibility.
  
  
 Figure~\ref{fig:RulesHigherOrder}  summarizes a particular choice of
  proof-rule set from the current and previous subsections.  
Soundness is proved  in Section~\ref{sec:Semantics}.

\begin{figure*}[!t]
\hrule

\hrule
\caption{Proof rules specific to higher-order store}
\label{fig:RulesHigherOrder}
\end{figure*}


\subsection{Nested triples and classical assertion logic}
\label{subsec:ClassicalAssertionLogic}
One may wonder why we insist on an intuitionistic program logic. 
Unfortunately, as the following proposition shows, it is not possible to use a classical version of our logic; more precisely, the combination of a classical specification logic and   rule (\textsc{-Frame}) is not sound. Thus, by our identification of assertion and specification language, we cannot have a classical assertion logic either. 

\begin{prop}
\label{prop:classicalUnsound}
Adding rule  (\textsc{-Frame})  to a classical specification logic is not sound.
\end{prop}
\proof
Assuming the rule for the elimination of double negation, 
we can derive the   problematic triple 
Assume ,
using the abbreviation  for . With   rule (\textsc{-Frame}) to frame in  we can derive the triple 
 from . 
Since  and , rule (\textsc{Conseq}) and the distribution axioms then let us derive  . On the other hand, rule (\textsc{Skip}) derives  the triple .
 Thus, we have shown that from the assumption   we can derive , i.e.\ we have shown  
. 
By eliminating the double negation we can now derive the triple . \qed


Note that this derivation does not use nested triples, and also applies to the specification logics used in \cite{BirkedalL:semslt-lmcs,Birkedal:Reus:Schwinghammer:Yang:08}.

 
\section{Semantics of Nested Triples}
\label{sec:Semantics}


This section develops a model for the programming language and logic we have presented. 
The semantics of programs, given in Subsection~\ref{subsec:semantics_exp_com} using an untyped domain-theoretic model, is standard. 
The following semantics of the logic is, however, unusual; it
is a possible world semantics where the worlds live in a  recursively defined {\em metric\/} space. 
Before we begin with the technical devlopment proper we give a brief overview of the main ideas employed.

\subsection{Overview of the technical development}
\label{sec:overview-of-technical-development}

In earlier work, Birkedal, Torp-Smith, and
Yang~\cite{BirkedalL:semslt-lmcs,Birkedal:Yang:parsepl-journal} showed
how to model a specification logic with higher-order frame rules but
for a language with first-order store. There, the assertion and specification 
logic were kept distinct. Assertions were modelled as semantic predicates
, with  the set of heaps,
and specifications as world-indexed truth values . (These latter maps were
restricted to be monotone in a certain sense, but that does not matter for the present
explanation.)
The informal idea was that the set of worlds would consist of invariants that 
had been framed in and thus worlds consisted of semantic predicates, . Here, with 
higher-order store and nested triples and the collapse of assertion and
specification logic, assertions will be modelled as world-indexed predicates.
So we get . Worlds will still consist of semantic predicates,
so . Thus we see that the set of worlds  should be recursively
defined.  This captures the idea that any assertion can serve as an invariant to 
be framed in via a frame rule.

The idea of using such a Kripke model over a recursively defined set
of worlds comes from~\cite{Birkedal:Stovring:Thamsborg:09}, where this
idea was used to define a model of a type system with general ML-like
references (hence higher-order store). Following~\cite{Birkedal:Stovring:Thamsborg:09} we show how to
find a solution to the recursive world equation in a category of
complete bounded ultra-metric spaces (the definition of which we
recall below). This is possible by restricting the subsets of  that
we use to so-called uniform admissible subsets of . The set 
of all such forms a complete bounded ultra-metric space and thence we
can solve the recursive world equation.  Having solved that, we show how
to define a world extension operator  (which will be used to model
the syntactic  operator used earlier), as a fixed point of a suitable contractive
operator. 
Moreover, we show that the subset  of  is a complete Heyting algebra with a commutative and monotone monoid structure, 
as needed for the interpretation of separation logic. 

Having defined semantic predicates in certain metric spaces allows us
to interpret recursively defined assertions via application of
Banach's fixed point theorem.

The final core idea in the development is the interpretation of
triples. Here we bake in the frame rules to the model by including
suitable quantifications over future worlds, following ideas from
earlier work~\cite{Birkedal:Reus:Schwinghammer:Yang:08}. To ensure
that nested triples are modelled as semantic predicates, we also force
the interpretation of triples to be metrically non-expansive in the worlds
argument. In particular,    predicates involving nested triples can be used
in recursive definitions of assertions. 


\subsection{Semantics of expressions and commands}
\label{subsec:semantics_exp_com}

\begin{figure*}[t]
\hrule
\vspace{-2mm}
-1.5mm]
\den{C_1\SYN{;}C_2}_\eta h &
\defeq \key{if}\;\den{C_1}_\eta h\,{\in}\,\{\bot,\ERR\}\;\key{then}\,\den{C_1}_\eta h\;\key{else}\,\den{C_2}_\eta\! (\den{C_1}_\eta h)
\-1.5mm]
&\quad\;\;\key{else}~\key{if}~(\EXPden{e_1}_\eta{=}\EXPden{e_2}_\eta)~\key{then}~\den{C_1}_\eta h~\key{else}~\den{C_2}_\eta h
\-1.5mm]
&\quad\;\; \key{in}~\den{C}_{\eta[x\mapsto\l]}
(h\COMB\record{\l{=}\EXPden{e_1}_\eta, \ldots, \l{+}n{-}1{=}\EXPden{e_n}_\eta})
\-1.5mm]
&\quad\;\; \key{else}~(\key{let}~h'~\text{s.t.}~h=h'\COMB\record{\EXPden{e}_\eta{=}h(\EXPden{e}_\eta)}~\key{in}~h')
\-1.5mm]
\den{\SYN{let}~x\SYN{=}[e]~\SYN{in}~C}_\eta h &
\defeq
\key{if}~\EXPden{e}_\eta\notin\dom h~\key{then}~\ERR~\key{else}~\den{C}_{\eta[x\mapsto \recselect{h}{\EXPden{e}_\eta}]}h
\-1.5mm]
&\quad\;\;\key{else}~
(h(\EXPden{e}_\eta))(h)

\label{eqn:domain-eqn}
\Heap &= \Rec\Val 
&
\Val &= \lift{\Ints} \,{\oplus}\, \lift\Com 
&
\Com &= \Heap\,{\sto}\,\TERR(\Heap) 

r\COMB r' &\;\;\defeq\;\; 
\text{if  then  else  }.

d(p,q) &= 
\begin{cases}
2^{-\max\{i\in\omega\;|\;\RANK{p}i = \RANK{q}i\}} &\text{if }\\
0 &\text{otherwise} 
\end{cases}

h \in p*q\ \defiff\ \ 
\exists h_1,h_2.\  \ h = h_1\COMB h_2\ \wedge\ h_1 \in p\ \wedge\ h_2\in q.
\pi_n(h_1\COMB h_2) = \pi_n(h_1)\COMB \pi_n(h_2)\in p(w')*q(w') = (p*q)(w').
r\circ r' = \FOLD(\UNFOLD(r)\otimes r' *\UNFOLD(r'))
\quad \text{and}\quad
(p\otimes r)(w) =  p(r\circ w)
r \PHI{\circ} r' &= \FOLD((\lambda w.\UNFOLD(r)(r'\circ w)) * \UNFOLD(r'))\ .

(\lambda w.\UNFOLD(r)(r'\circ w)) * \UNFOLD(r')
\nequiv{n-1}
(\lambda w.\UNFOLD(s)(s'\circ w)) * \UNFOLD(s')

(\lambda w.\UNFOLD(r)(r'\circ_1 w)) * \UNFOLD(r')
\nequiv{n}
(\lambda w.\UNFOLD(r)(r'\circ_2 w)) * \UNFOLD(r')

r\circ r'\  =\ r\PHI\circ r'
\ =\ \FOLD(\lambda w.\UNFOLD(r)(r'\circ w) * \UNFOLD(r'))
\ =\ \FOLD(\UNFOLD(r)\otimes r'\, * \UNFOLD(r'))

\wemp\circ r 
\ =\ \FOLD((\lambda w.\UNFOLD(\wemp)(r\circ w)) * \UNFOLD (r))
\ =\ \FOLD(\UNFOLD(r)) 
\ =\ r\ .

r\circ\wemp 
\ =\ \FOLD(\lambda w.\UNFOLD(r)(\wemp\circ w) * \UNFOLD(\wemp))
\ =\ \FOLD(\lambda w.\UNFOLD(r)(w) * \EMP)
\ =\ r\ .

\UNFOLD((r\circ s)\circ t)(w)
&= \UNFOLD(r\circ s)(t\circ w) * \UNFOLD(t)(w)\\
&= \UNFOLD(r)(s\circ(t\circ w)) * \UNFOLD(s)(t\circ w) * \UNFOLD(t)(w)\\
&=  \UNFOLD(r)(s\circ(t\circ w)) * \UNFOLD(s\circ t)(w)\\
&\nequiv{n-1}   \UNFOLD(r)((s\circ t)\circ w) * \UNFOLD(s\circ t)(w)\\
&= \UNFOLD(r\circ(s\circ t))(w)\ .

(p\otimes r)\otimes s 
= \lambda w.p(r\circ(s\circ w))
=\lambda w.p((r\circ s)\circ w) 
= p\otimes(r\circ s)

h\in p(w) * \UNFOLD(w)(\wemp) *r\ \IMPLIES\ 
c(h)\in \DCl(q(w) * \UNFOLD(w)(\wemp) * r) ,  

p\mimp q = \{h\;|\;\forall n\in\omega.\forall h'\in \Heap.\ \text{if  then }\}\ ,

\den{X(\vec e)}_{\eta,\rho} w & =   \rho(X)(\den{\vec e}_\eta)w\\
\den{\False}_{\eta,\rho} w & =   \{\bot\}\\
\den{\True}_{\eta,\rho} w & =  \Heap\\
\den{P\vee Q}_{\eta,\rho} w & =   \den{P}_{\eta,\rho} w\cup\den{Q}_{\eta,\rho} w\\
\den{P\wedge Q}_{\eta,\rho} w & =  \den{P}_{\eta,\rho} w\cap\den{Q}_{\eta,\rho} w\\
\den{P \Rightarrow Q}_{\eta,\rho} w & = \{h\;|\;\forall n\in\omega.\ \pi_n(h)\in\den{P}_{\eta,\rho} w\ \text{implies}\ \pi_n(h)\in\den{Q}_{\eta,\rho} w\}\\
\den{\forall x.P}_{\eta,\rho} w & = \textstyle{\bigcap_{d\in\Val}} \den{P}_{\eta[x:=d],\rho}w\\
\den{\exists x.P}_{\eta,\rho} w & =  \{h\;|\; \forall n\in\omega.\ \pi_n(h)\in \textstyle{\bigcup_{d\in\Val}} \den{P}_{\eta[x:=d],\rho}w\}\\
\den{e_1=e_2}_{\eta,\rho} w & =\{h\;|\;h\neq\bot\Rightarrow\,\den{e_1}_\eta = \den{e_2}_\eta\}\\
\den{e_1\,{\mapsto}\, e_2}_{\eta,\rho} w & = \{h\;|\;h\sqsubseteq  \record{\den{e_1}_\eta  = \den{e_2}_{\eta}}\}\\
\den{\EMP}_{\eta,\rho} w & = \{\record{},\bot\}\\
\den{P*Q}_{\eta,\rho} w & =  \den{P}_{\eta,\rho} w * \den{Q}_{\eta,\rho} w\\
\den{\triple{P}{e}{Q}}_{\eta,\rho} w & = \DCl \{ h \in \Heap \ |\ rnk(h)>0 \Rightarrow  w\models_{rnk(h)-1} \triple{\den{P}_{\eta,\rho}}{\den{e}_\eta}{\den{Q}_{\eta,\rho}} \}\\
\den{P\otimes Q}_{\eta,\rho} w & =  ( \den{P}_{\eta,\rho}\otimes\FOLD(\den{Q}_{\eta,\rho}) ) w\\
\den{(\mu X(\vec x).P)(\vec e)}_{\eta,\rho} w & =  \textit{fix}(\lambda q,\vec d. \den{P}_{\eta[\vec x:=\vec d],\rho[X:=q]}) (\den{\vec e}_\eta)w

\frac{\triple{A}{e}{B} \Rightarrow \triple{P}{e'}{Q}} {\triple{\triple{A}{e}{B} \wedge P}{e'}{Q}}

\forall p.\ (p\otimes\FOLD(r) * r)(w) * \UNFOLD(w)(\wemp) 
&= p(\FOLD(r)\circ w) * \UNFOLD(\FOLD(r)\circ w)(\wemp) \ .

(p\otimes\FOLD(r) * r)(w) * \UNFOLD(w)(\wemp) 
&= (p\otimes\FOLD(r))(w) * r(w) * \UNFOLD(w)(\wemp) \\
&= p(\FOLD(r)\circ w) * r(w\circ\wemp) * \UNFOLD(w)(\wemp)\\
&= p(\FOLD(r)\circ w) * (r\otimes w)(\wemp) * \UNFOLD(w)(\wemp)\\
&= p(\FOLD(r)\circ w) * (r\otimes w * \UNFOLD(w))(\wemp)\\
&= p(\FOLD(r)\circ w) * \UNFOLD(\FOLD(r)\circ w)(\wemp)\ .

h\in (p \,{*}\, r)(w) \,{*}\,\UNFOLD(w)(\wemp) \,{*}\, r' 
= p(w)\,{*}\,\UNFOLD(w)(\wemp) \,{*}\, (r(w)\,{*}\,r')\ .

c(h)\,{\in}\, \DCl(q(w)\,{*}\,\UNFOLD(w)(\wemp) \,{*}\, (r(w)\,{*}\,r')) 
= \DCl((q\,{*}\,r)(w)\,{*}\,\UNFOLD(w)(\wemp) \,{*}\, r')\ ,

\label{eqn:eval-1}
h'\in\den{e\pointsto R[\_]}_{\eta,\rho} w\ \text{ and }\ h''\in\den{P}_{\eta,\rho} w*\UNFOLD(w)(\wemp) *r . 

\label{eqn:eval-2}
\den{e}_\eta\in\dom{\pi_n(h')} = \dom{h'} \subseteq\dom{h}\\
\label{eqn:eval-3}
\exists d_n.\  \pi_n(h)(\den{e}_\eta) = \pi_n(h')(\den{e}_\eta) \sqsubseteq d_n\ \text{ and }\ \pi_n(h')\in\den{R[k]}_{\eta[k:=d_n],\rho} w

\pi_n(h')\in \den{R[k]}_{\eta_n,\rho}w\ \text{ implies }\ \pi_n(h')\in\den{\triple{P*e\,{\pointsto}\,R[\_]}{k}{Q}}_{\eta_n,\rho}w

\forall n.\ w\models\triple{\den{P*e\,{\pointsto}\,R[\_]}_{\eta_n,\rho}}{\pi_{r_n-1};d_n;\pi_{r_n-1}}{\den{Q}_{\eta_n,\rho}}\ .

\label{eqn:eval-key-equation}
\pi_n(h')(\den{e}_\eta)= \pi_{r_n}(\pi_n(h'))(\den{e}_\eta) \sqsubseteq \pi_{r_n-1};d_n;\pi_{r_n-1}\ , 

\forall n.\ w\models\triple{\den{P*e\,{\pointsto}\,R[\_]}_{\eta_n,\rho}}{\pi_n(h')(\den{e}_\eta)}{\den{Q}_{\eta_n,\rho}}\ .

\label{eqn:eval-4}
\forall n.\ w\models\triple{\den{P*e\,{\pointsto}\,R[\_]}_{\eta,\rho}}{h'(\den{e}_\eta)}{\den{Q}_{\eta,\rho}}\ .

\inferrule[Out-T]{ 
\X;\Gamma \adash \triple{ \triple{A}{d}{B} \wedge P}{e}{Q}}
{ \X;\Gamma \adash \triple{A}{d}{B} \Rightarrow \triple{ P} {e} {Q}
}
\qquad 
 \inferrule[In-T]{ 
 \X;\Gamma \adash \triple{A}{d}{B} \Rightarrow \triple{P} {e} {Q}
}
{\X;\Gamma \adash \triple{ \triple{A}{d}{B} \wedge P}{e}{Q}}
 
\pi_n(h)\in p(w) * \UNFOLD(w)(\wemp) *r\ \IMPLIES\ 
\pi_n(c(\pi_n(h)))\in \DCl(q(w) * \UNFOLD(w)(\wemp) * r). 

\inferrule[Out]{ 
\X;\Gamma \adash \triple{ \phi \wedge P}{e}{Q}}
{ \X;\Gamma \adash \phi \Rightarrow \triple{ P} {e} {Q}
} \mbox{( \ALMOSTPURE)}
\qquad 
 \inferrule[In]{ 
 \X;\Gamma \adash \phi \Rightarrow \triple{P} {e} {Q}
}
{\X;\Gamma \adash \triple{ \phi \wedge P}{e}{Q}}
\mbox{( \ALMOSTPURE)}
 \label{eq:assumption_out_rule}
\pi_n(h)\in \den{\phi}_{\eta,\rho}\, w

\label{eqn:InUnsound}
\adash \triple{ R}{\QUOTE{\SYN{skip}}}{\False}
 
\inferrule[Out]{ 
\X;\Gamma \adash \triple{ \phi \wedge P}{e}{Q}}
{ \X;\Gamma \adash \phi \Rightarrow \Diamond \triple{ P} {e} {Q}
}
\qquad 
\inferrule[In]{ 
 \X;\Gamma \adash \phi \Rightarrow \Diamond \triple{P} {e} {Q}
}
{\X;\Gamma \adash \triple{ \phi \wedge P}{e}{Q}}
\qquad
\inferrule[E]{\ignore{x} }
{ \X;\Gamma \adash \Diamond P \Rightarrow P}
 
\inferrule[Invariance]{ 
\X;\Gamma \adash \triple{P}{e}{Q}}
{ \X;\Gamma \adash \triple{P\wedge \triple{A}{k}{B}}{e}{Q\wedge \triple{A}{k}{B}}
}
\triple{\EMP}{\QUOTE{\SYN{let}\, x = \SYN{new}\, 0 \ \SYN{in}\ [x]\SYN{:=} \QUOTE{\SYN{skip}}\ }}{\exists x.\, x{\mapsto}\triple{\EMP}{\_}{\EMP}} 
\inferrule[InvarianceR]{ 
\X;\Gamma \adash \triple{P*e_1\mapsto e_2}{e}{Q * e_1\mapsto e_2}}
{ \X;\Gamma \adash \triple{P* (e_1\mapsto e_2 \wedge \phi)}{e}{Q * (e_1\mapsto e_2 \wedge \phi)} }(\mbox{ \ALMOSTPURE})
 \inferrule[UpdateInv]{ 
}{
  \X;\Gamma\,{\adash}\,\triple{e\,{\mapsto}\,\_ \,{*}\, (e_1{\mapsto}e_0 \wedge \phi)}{\QUOTE{[e] \,{:=}\, e_0}}{(e\,{\mapsto}\,e_0\wedge  \phi) \,{*}\, (e_1{\mapsto}e_0 \wedge \phi) }
}(\mbox{ \ALMOSTPURE})

{e\,{\mapsto}\,e_0 \,{*}\, (e_1{\mapsto}e_0 \wedge \phi)} \Rightarrow
{(e\,{\mapsto}\,e_0 \wedge \phi) \,{*}\, (e_1{\mapsto}e_0 \wedge \phi)}  
&\textsc{-Assoc}&&
\inferrule{}{\X;\Gamma\vdash P*(Q *R) \IFF (P*Q)*R}
\.5ex]
&\textsc{-Unit}&&
\inferrule{}{\X;\Gamma\vdash P * \EMP\IFF P}
\.5ex]
&\textsc{-Overlap}&&
\inferrule{}{\X;\Gamma\vdash (e\mathop{\mapsto} e_1 \,\mathop*\, e\mathop{\mapsto} e_2)\IFF \False}
\.5ex]
&\textsc{-Mono}&&
\inferrule{\X;\Gamma\vdash P\IMPLIES P' }{\X;\Gamma\vdash P \otimes R\IMPLIES P' \otimes R}
\.5ex]
& \textsc{Update} &&
\inferrule{}{
  \X;\Gamma\,{\adash}\,\triple{e\,{\mapsto}\,\_ \,{*}\, P}{\QUOTE{[e] \, \SYN{:=}\, e_0}}{e\,{\mapsto}\,e_0 \,{*}\, P}
}
\.5ex]
&\textsc{New} &&
\inferrule{
  \X;\Gamma,x \,{\adash}\, \triple{P*x\,{\mapsto}\,e}{\QUOTE{C}}{Q}
}{
  \X;\Gamma \,{\adash}\, \triple{P}{\QUOTE{\SYN{let}\,{x {=} \SYN{new}\,e}\,\SYN{in}\,{C}}}{Q}
}\ (x \not\in \fvar(P,e,Q))
\.5ex]
&\textsc{If} &&
\inferrule{
  \X;\Gamma\adash \triple{P \,{\wedge}\, e_0{=}e_1}{\QUOTE{C}}{Q} \quad \X;\Gamma\adash \triple{P \,{\wedge}\, e_0{\not=}e_1}{\QUOTE{D}}{Q}
}{
  \X;\Gamma\adash \triple{P}{\QUOTE{\SYN{if}\;(e_0{=}e_1)\;\SYN{then}\;C\;\SYN{else}\;D}}{Q}
}
\.5ex]
&\textsc{Seq} &&
\inferrule{
  \X;\Gamma\adash \triple{P}{\QUOTE{C}}{R} \quad \Gamma\adash \triple{R}{\QUOTE{D}}{Q}
}{
  \X;\Gamma\adash \triple{P}{\QUOTE{C;D}}{Q}
}
\2ex]
&\textsc{Conseq} &&
\inferrule{
  \X;\Gamma \,\adash\, P'{\Rightarrow}\,P 
  \quad \X;\Gamma \,\adash\, Q\,{\Rightarrow}\,Q'
}{
  \X;\Gamma \,\adash\, {\triple{P}{e}{Q}} \Rightarrow {\triple{P'}{e}{Q'}}
}
\
\hrule
\caption{\label{fig:proofrulesummary} Axioms and proof rules. Rule \textsc{-Mono} is in fact a derived rule.}
\end{figure}

\begin{figure}
\ContinuedFloat
\hrule
.5ex]
&\textsc{Invariance}&&
\inferrule{}{
 \X;\Gamma \;\adash\; \triple{P}{e}{Q}
\Rightarrow
\triple{P\wedge \psi}{e}{Q \wedge \psi}
  } \mbox{\quad ( is pure)}
  \.5ex]
&\textsc{-Frame} &&
\inferrule{}{
  \X;\Gamma \adash \triple{P}{e}{Q} \Rightarrow \triple{P\,{*}\,R}{e}{Q\,{*}\,R}
}
\
\hrule
\caption{ Axioms and proof rules (cont.). }
\end{figure}


\section{Proofs}

This section contains the proofs omitted from the main part of the paper. 

\subsection{Heyting algebra structure of uniform admissible subsets}
\label{app:subsec:assertions}

\begin{lemma}[Heyting algebra]
\label{lem:UAdm-Heyting}
Let . 
Then  is a complete Heyting algebra
with a (monotone) commutative monoid structure .
All the algebra operations are non-expansive with respect to the metric defined in Section~\ref{subsec:Assertion-Domain}. 
\end{lemma}


\begin{proof}
Since admissibility and uniformity are preserved by taking arbitrary intersections,  is a complete lattice, with meets given by set-theoretic intersection, least element  and greatest element . Binary joins are given by set-theoretic union, and arbitrary joins by .

The join is described more explicitly  as . 
First, note that the  right hand side  is an element of : 
 is uniform, i.e.,  implies  for all , since . To  show that  is also admissible suppose  is a chain in , and let  be the lub of this chain. We must show that  for all . By compactness,  for some , and hence  using the idempotency of  and the fact that . 
To see the inclusion , 
note that for all , if  for all  and some arbitrary , 
then also  by admissibility, and hence  follows. 
For the other inclusion, we claim that the right hand side  is one of the elements appearing in the intersection; from this claim it is immediate that .  
The claim follows since  by the uniformity of the 's.  

The implication  of this complete lattice  is described by  \pi_n(h)\in p\pi_n(h)\in q: 
Using  it is easy to see that  is uniform. Admissibility follows analogously to the case of joins: if  is a chain in  with lub , and if  is such that  then we must show that . Since  is compact, there is some  such that , and thus the required  follows from . 
Next, to see that  is indeed the implication in , first note that we have , using the uniformity of  and the admissibility of . If  for some , and  and  for some , then the uniformity of  yields . Thus we obtain . 

That  is an operation on  is established in the proof of Lemma~\ref{lem:separation:non-expansiveness}. It is easy to check that  is  commutative and associative and  that it is monotone, i.e., if  and  then . Moreover, we have , and the fact that  follows from the definition of the heap combination . 


For the non-expansiveness of the algebra operations, we  only consider the case of meets  as an example. Assume  and , then whenever  we have  and  by assumption. Thus also .
\end{proof}


\begin{lemma}[Heyting   algebra, II]
\label{lem:UAdm-Heyting-II}
The set of non-expansive functions ,  ordered pointwise, forms a complete Heyting algebra with a (monotone) commutative monoid structure. 
The operations are given by the pointwise extension of the corresponding ones on , and  they are non-expansive with respect to the -metric on .
\end{lemma}
\begin{proof}
We begin by showing that all the claimed algebra operations on  are well-defined, i.e., that the pointwise definitions give rise to non-expansive functions from  to . 
The cases of the various units are given by constant functions and thus non-expansive:

Next, consider the case of meets. Let  be a family of functions  in  and  such that , we have

by the non-expansiveness of each . Well-definedness for the other operations is shown analogously. 

We now show that the operations are non-expansive. Again, we consider the case of meets only, as the remaining cases are similar. 
Let  and  be two families of non-expansive functions such that  holds for all . 
To see that  holds,  by definition of the -metric it suffices to prove 
 for all . 
This follows from the pointwise definition since  holds for every  by assumption.
\end{proof}



\subsection{Interpretation of assertions}
\label{subsec:app:interpretation-assertions}

\begin{lemma}[Non-expansiveness of fix, \cite{Birkedal:Stovring:Thamsborg:09}]
\label{lem:fix-non-expansiveness}
Let  be an object in , and let  be contractive functions on . 
Then . 
\end{lemma}

\begin{lemma}[Well-definedness]
The interpretation in Fig.~\ref{fig:assertion-semantics} is well-defined. More precisely, let  be an assertion with free relation variables in , where the arity of  is . Then:
\begin{enumerate}
\item for every  and ,  is an element of , i.e., a non-expansive function ; 
\item  denotes a non-expansive function from  to ; 
\item   If  is formally contractive in  then the functional   is a contractive map from  to , where  is an -ary relation variable. 
\end{enumerate}
\end{lemma}

\begin{proof}
The claims are proved simultaneously by induction on the structure of . 
Note that the composition of non-expansive functions is again a non-expansive function, and that the composition of a contractive function with a non-expansive function is again a contractive function. 
\begin{iteMize}{}
\item For the logical connectives, the claims follow from the inductive hypothesis and Lemmas~\ref{lem:UAdm-Heyting} and \ref{lem:UAdm-Heyting-II} respectively.
 
\item The case of invariant extension, , follows from Lemma~\ref{lem:existence-tensor-and-circ}. In particular,  is  a contractive function whenever  is formally contractive in . 

\item The case of a relation variable, , follows from the assumption that  is a non-expansive function from  to . 

\item In the case of recursive assertions, , the well-formedness requirement that  be formally contractive in  means that 
 is contractive, by part (3) of the induction hypothesis. Hence,  is a contractive endofunction on . 
In particular,  the fixed point in the definition of 
 
 is well-defined, and by Lemma~\ref{lem:fix-non-expansiveness}, 

 is a non-expansive function. 

Similarly, if  is formally contractive in , then 
 is contractive by Lemma~\ref{lem:fix-non-expansiveness} and the inductive hypothesis that 
 is contractive for any . 

\item It remains to consider the case of (nested) triples. Note that the interpretation of triples is defined in terms of the admissible downward closure, so it is clear that  is uniform and admissible. 
We first prove claim (1), i.e., the non-expansiveness of .  
To this end, assume that , and let . We must show that . 
By the downward closure, we also know that . 
Since , we also have . Without loss of generality we can assume that , and thus must have 
. 
By Lemma~\ref{lem:semantic-triples-key} this implies  
, and thus also 
.

We now prove the following claim which implies the non-expansiveness and contractiveness properties stated in conditions (2) and (3):

For the proof of this claim, assume  and  for some . 
We must show that . 
Let . Without loss of generality we can assume  (and hence ), and thus obtain 
. 
By induction hypothesis,  and  are non-expansive, and thus
 and 
. 
By Lemma~\ref{lem:semantic-triples-key} we obtain 
. 
This yields .
\end{iteMize}
\end{proof}













\subsection{Soundness of standard rules from separation logic}
\label{app:subsec:HoareLogicRules}

The following lemmas show that the usual rules of separation logic, 
expressed using triples containing quoted commands as shown in Figure~\ref{fig:SLRules}, are sound. 

\begin{lemma}[Skip] 
The axiom  is valid. 
\end{lemma}

\begin{proof}
This follows from the fact that  for all , and that  is a closure operation. 
\end{proof}

\begin{lemma}[Conditional]
If  
and  are both valid, 
then so is . 
\end{lemma}

\begin{proof}
Let  and  and suppose . From the semantics of 
the conditional, we can assume without loss of generality that  and  
are not both in . We must show that 

where .
Depending on whether the statement  hold, we have  or . Therefore, the claim follows from either the first or the second assumed triple. 
\end{proof}

\begin{lemma}[Update]
The axiom  is valid. 
\end{lemma}

\begin{proof}
By Lemma~\ref{lem:star-frame}, it suffices to prove the validity of

Let , , ,  and . 
We will show that  holds for all . 

Let  and , and suppose . 
We may assume that , for otherwise  is immediate. 
Thus,  such that  and . 
In particular, since , we obtain that . 
Therefore, from the semantics of the assignment command,  
. 
But this heap is the same as , 
and therefore . The latter set is contained in  since  is a closure operation.
\end{proof}



\begin{lemma}[UpdateInv]
The axiom
 
 is valid. 
\end{lemma}

\begin{proof} 
Consider  , , ,  and .  We
will show that  holds for all .

Let  and , and suppose . 
We may assume that , for otherwise  is immediate. 
Thus,  such that  and . 
In particular, since , we obtain that
 such that 
  and 
  and
 .
Therefore, from the semantics of the assignment command,  
. 
But this heap is the same as .
Now the rank of heap  is obviously identical to the rank of
 and thus  as  is \ALMOSTPURE and .
Therefore . The latter set is contained in  since  is a closure operation.
\end{proof}





\begin{lemma}[Free] 
The axiom  is valid. 
\end{lemma}

\begin{proof}
By Lemma~\ref{lem:star-frame}, it suffices to prove the validity of

Let , , ,  and . 
We will prove that  holds for all . 

Let , let  and suppose . 
Since  is the unit for  and  is a closure operation, we must only show . 
We may assume that , for otherwise  is immediate. 
Thus,  such that  and . 
In particular, since , we obtain that . 
Therefore, from the semantics of the deallocation command, 
. It follows that . 
\end{proof}


\begin{lemma}[Deref] 
If  is valid and  is not free in  and , 
then  is also valid. 
\end{lemma}

\begin{proof}
Assume that  is valid, and pick  and . 
Let . 
We will show that  for all .

Let ,  and .  
We must show that . 
By definition there are heaps  such that  and 
 
and 
.  
By definition this means that

Let us write  for . In the remainder of the proof,
we will prove that

because then, by admissibility and the continuity of , we obtain 
the required
.

Without loss of generality we can assume that , so that 
as well.
Then, since , we have in particular  and . 
Using the monotonicity of commands with respect to the environment, this gives 

By uniformity of , we have 
, so that the assumption gives us 

Since  is a downward-closed set for every predicate , the above
formula implies that  belongs to the set on the right hand side.
Furthermore, since , we have . The combination
of these two facts
gives the desired .
\end{proof}


\begin{lemma}[New] 
If\  is valid and  is not free in ,  and , then 
 is valid. 
\end{lemma}

\begin{proof}
Let , ,  and . Suppose .  
We must show that . 
Consider the following environment  and heap :

where  is the least natural number not contained in . 
Since  is not free in  and , we have  and . Thus by the assumption on  we obtain:

Then the 
assumption that  is valid implies:

Using the fact that 
 and 
since , this proves the statement. 
\end{proof}


\begin{lemma}[Auxiliary variable]
Assume that  is not free in . Then the  axiom 

is valid. 
\end{lemma}

\begin{proof}
Let , , and fix . 
For each , let ,   
and .
Since  is not free in , we have 
. Thus, a similar reasoning
with rank as that in the proof of Consequence implies that it is
sufficient to prove the following claim:

Assume , let  and . 
We must show that . 
By definition,  where  and . 
Thus, for each  there exists  such that , and therefore 
 by the uniformity of . 
From the assumption  we then obtain 
that for each , 
 
Using the admissibility of  and the continuity of , it follows that . 
\end{proof}

\begin{lemma}[Invariance]
Then the  axiom 
is valid. 
\end{lemma}

\begin{proof} 
Let , , and fix . 
For each ,let  
and  and .
A similar reasoning
with rank as that in the proof of (\textsc{Conseq}) implies that it is
sufficient to prove the following claim:

But since   is pure, either  for all  or  for all .  In the former case, the above implication reduces to the identity axiom, in the latter case  
  always holds.
 \end{proof}


\begin{lemma}[Disjunction]
For all  and , the axiom 
 
is valid.
\end{lemma}

\begin{proof}
Let , , and fix . 
Let , ,  and . 
As in the  preceding proofs, it suffices to show that 

For this, suppose that  and let . 
We must show that . 
Note that  entails that 
 or 
. 
Therefore, by the assumption we know that 
 or 
, from which 
it follows that  by the monotonicity of  and of the closure operation. 
\end{proof}







 


\end{document}
