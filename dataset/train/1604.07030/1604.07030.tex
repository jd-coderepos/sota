\documentclass[
submission
]{dmtcs-episciences-tampered}




\usepackage[utf8]{inputenc}
\usepackage{subfigure}



\usepackage[square,numbers]{natbib}


\author{Clemens Grabmayer\affiliationmark{1}}

\title{{Linear Depth Increase of Lambda Terms
        along Leftmost-Outermost Beta-Reduction}}   

\affiliation{
Gran Sasso Science Institute, Viale F. Crispi, 7, 67100 L'Aquila AQ, Italy}
\received{2019-09-30}


\usepackage{amsmath,amsthm,amssymb}
\usepackage[english]{babel}
\usepackage{stmaryrd}
\usepackage{authblk}
\usepackage{color,graphicx}
\usepackage{hyperref,url}
\usepackage{tikz}
\usepackage[normalem]{ulem}
\usepackage{calc}


\usepackage{tikz}
\usetikzlibrary{arrows,shapes,calc,positioning}



\newcommand{\funin}{\mathrel{:}}
\newcommand{\fap}[2]{#1({#2})}
\newcommand{\bfap}[3]{{#1}({#2},\hspace*{0.05pt}{#3})}
\newcommand{\tfap}[4]{{#1}({#2},\hspace*{0.05pt}{#3},\hspace*{0.05pt}{#4})}
\newcommand{\iap}[2]{#1 _{#2}}
\newcommand{\indap}[2]{#1 _{#2}}
\newcommand{\subap}[2]{#1 _{#2}}
\newcommand{\supap}[2]{#1 ^{#2}}
\newcommand{\bap}{\subap}
\newcommand{\pap}{\supap}
\newcommand{\bpap}[3]{#1 _{#2}^{#3}}
\newcommand{\pbap}[3]{#1 _{#3}^{#2}}



\newcommand{\nb}{\nobreakdash}

\newcommand{\nf}{\normalfont}

\newcommand{\sdefdby}{{:=}}
\newcommand{\defdby}{\mathrel{\sdefdby}}

\newcommand{\punc}[1]{\ensuremath{\hspace*{3pt}{#1}}}



\newenvironment{dedication}
               {\hspace*{0ex}\begin{flushright}\em}
               {\end{flushright}}


\definecolor{azure}{rgb}{0.94,1.00,1.00}
\definecolor{brown}{rgb}{.75,.25,.25}
\definecolor{cyan}{rgb}{0.25,0.88,0.82}
\definecolor{chocolate}{rgb}{0.82,0.41,0.12}
\definecolor{darkcyan}{rgb}{0.5,0,1}
\definecolor{darkgreen}{rgb}{0,0.39,0}
\definecolor{darkmagenta}{rgb}{0.5,0,0.5}
\definecolor{darkgoldenrod}{RGB}{184,134,11}
\definecolor{firebrick}{RGB}{175,25,25}
\definecolor{forestgreen}{rgb}{0.13,0.55,0.13}
\definecolor{goldenrod}{RGB}{218,165,32}
\definecolor{lightcyan}{rgb}{0.88,1.00,1.00}
\definecolor{lightpink}{rgb}{1.00,0.71,0.76}
\definecolor{myyellow}{RGB}{235,235,0}
\definecolor{lightyellow}{rgb}{1.00,1.00,0.88}
\definecolor{lightgoldenrod}{rgb}{0.83,0.97,0.51}
\definecolor{lightgoldenrodyellow}{rgb}{0.98,0.98,0.82}
\definecolor{lightskyblue}{rgb}{0.53,0.81,0.98}
\definecolor{moccasin}{rgb}{1.00,0.89,0.71}
\definecolor{magenta}{rgb}{1,0,1}
\definecolor{navyblue}{rgb}{0,0,0.5}
\definecolor{orange}{rgb}{1.0,0.65,0.0}
\definecolor{orangered}{rgb}{1.0,0.27,0.0}
\definecolor{palegreen}{rgb}{0.60,0.98,0.60}
\definecolor{powderblue}{rgb}{0.69,0.88,0.90}
\definecolor{purple}{rgb}{1,0.5,1}
\definecolor{royalblue}{RGB}{65,105,225}
\definecolor{mediumblue}{RGB}{0,0,205}
\definecolor{cornflowerblue}{RGB}{100,149,237}
\definecolor{springgreen}{rgb}{0.0,1.0,0.5}
\definecolor{turquoise}{rgb}{0.25,0.88,0.82}
\definecolor{snow}{rgb}{1.00,0.98,0.98}
\definecolor{tan}{rgb}{0.82,0.71,0.55}
\definecolor{red}{rgb}{1,0,0}
\definecolor{violetred}{RGB}{208,32,144}

\newcommand{\colorin}[1]{\textcolor{#1}}

\newcommand{\black}{\colorin{black}} 
\newcommand{\blue}{\colorin{blue}} 
\newcommand{\brown}{\colorin{brown}} 
\newcommand{\chocolate}{\colorin{chocolate}}
\newcommand{\colorred}{\colorin{red}}
\newcommand{\colortan}{\colorin{tan}}
\newcommand{\cyan}{\colorin{cyan}}           
\newcommand{\darkcyan}{\colorin{darkcyan}}
\newcommand{\darkgoldenrod}[1]{\textcolor{darkgoldenrod}{#1}}
\newcommand{\darkgreen}{\colorin{darkgreen}}
\newcommand{\darkmagenta}{\colorin{darkmagenta}}
\newcommand{\dm}{\colorin{darkmagenta}}
\newcommand{\forestgreen}{\colorin{forestgreen}}
\newcommand{\firebrick}{\colorin{firebrick}}
\newcommand{\fb}{\firebrick}
\newcommand{\goldenrod}[1]{\textcolor{goldenrod}{#1}}
\newcommand{\green}{\colorin{green}}
\newcommand{\grey}{\colorin{grey}}
\newcommand{\magenta}{\colorin{magenta}}
\newcommand{\mediumblue}{\colorin{mediumblue}}
\newcommand{\mb}{\mediumblue}
\newcommand{\moccasin}{\colorin{moccasin}}
\newcommand{\navyblue}{\colorin{navyblue}}
\newcommand{\orangered}{\colorin{orangered}}
\newcommand{\orange}{\colorin{orange}}
\newcommand{\palegreen}{\colorin{palegreen}}
\newcommand{\purple}{\colorin{purple}}
\newcommand{\royalblue}{\colorin{royalblue}}
\newcommand{\springgreen}{\colorin{springgreen}}
\newcommand{\turquoise}{\colorin{turquoise}}
\newcommand{\violetred}{\colorin{violetred}}



\newcommand{\tuple}[1]{\langle #1 \rangle}
\newcommand{\tuplespace}{\hspace*{0.5pt}}
\newcommand{\pair}[2]{\tuple{#1, \tuplespace #2}}

\newcommand{\descsetexpmid}{\mathrel{\vert}}
\newcommand{\descsetexp}[2]{\left\{{#1}\descsetexpmid{#2}\right\}}
\newcommand{\descsetexpbigmid}{\mathrel{\bigvert}}
\newcommand{\descsetexpbig}[2]{\bigl\{{#1}\descsetexpmid{#2}\bigr\}}
\newcommand{\setexp}[1]{\left\{{#1}\right\}}
\newcommand{\setexpbig}[1]{\bigl\{{#1}\bigr\}}
\newcommand{\setexpBig}[1]{\Bigl\{{#1}\Bigr\}}
\renewcommand{\emptyset}{\varnothing}

\newcommand{\cardinality}[1]{\left|{#1}\right|}

\newcommand{\family}[2]{\setexp{#1}_{#2}}
\newcommand{\familybig}[2]{\setexpbig{#1}_{#2}}
\newcommand{\familyBig}[2]{\setexpBig{#1}_{#2}}

\newcommand{\nat}{\mathbb{N}}
\newcommand{\natplus}{\pap{\nat}{+}}

\newcommand{\todo}[1]{\framebox{\textcolor{mediumblue}{todo: {#1}}}}


\newcommand{\slogand}{\wedge}
\newcommand{\slogor}{\vee}
\newcommand{\logand}{\mathrel{\slogand}}
\newcommand{\logor}{\mathrel{\slogor}} 
\newcommand{\slognot}{\neg}
\newcommand{\lognot}[1]{\slognot{#1}}

\newcommand{\existsst}[2]{\exists{\hspace*{1pt}#1}{#2}}
\newcommand{\uniqueexistsst}[2]{\exists{!}{\hspace*{1pt}#1}{#2}}
\newcommand{\forallst}[2]{\forall{\hspace*{0.5pt}#1}{#2}}
\newcommand{\existsstzero}[1]{\exists{\hspace*{1pt}#1}}
\newcommand{\uniqueexistsstzero}[1]{\exists{!}{\hspace*{1pt}#1}}
\newcommand{\forallstzero}[1]{\forall{\hspace*{0.5pt}#1}}


\newcommand{\sbigOmicron}{O}
\newcommand{\bigOmicron}{\fap{\sbigOmicron}}
\newcommand{\sbigTheta}{\Theta}
\newcommand{\bigTheta}{\fap{\sbigTheta}}
\newcommand{\sbigOmega}{\Omega}
\newcommand{\bigOmega}{\fap{\sbigOmega}}




\newcommand{\avar}{x}
\newcommand{\bvar}{y}
\newcommand{\cvar}{z}
\newcommand{\avari}{\indap{\avar}}
\newcommand{\bvari}{\indap{\bvar}}
\newcommand{\cvari}{\indap{\cvar}}

\newcommand{\ater}{s}
\newcommand{\bter}{t}
\newcommand{\cter}{u}
\newcommand{\ateracc}{\ater'}
\newcommand{\bteracc}{\bter'}
\newcommand{\cteracc}{\cter'}
\newcommand{\ateri}{\indap{\ater}}
\newcommand{\bteri}{\indap{\bter}}
\newcommand{\cteri}{\indap{\cter}}
\newcommand{\ateracci}{\indap{\ateracc}}
\newcommand{\bteracci}{\indap{\bteracc}}
\newcommand{\cteracci}{\indap{\cteracc}}

\newcommand{\snlvar}{0}
\newcommand{\snlvarsucc}{S}

\newcommand{\asig}{\Sigma}
\newcommand{\asigi}{\indap{\asig}}
\newcommand{\asigmin}{\supap{\asig}{-}}
\newcommand{\asiglo}{\indap{\asig}{\scriptlo}}
\newcommand{\asiglosim}{\indap{\asig}{\scriptlosim}}
\newcommand{\asiglored}{\indap{\asig}{\scriptlored}}
\newcommand{\asiglop}{\indap{\asig}{\scriptlop}}
\newcommand{\asiglopsim}{\indap{\asig}{\scriptlopsim}}
\newcommand{\asiglopred}{\indap{\asig}{\scriptlopred}}
\newcommand{\asiglambda}{\indap{\asig}{\lambda}}
\newcommand{\asigexpand}{\indap{\asig}{\scriptexpand}}
\newcommand{\asigexp}{\indap{\asig}{\scriptexp}}

\newcommand{\arules}{R}

\newcommand{\ruleslopsim}{\indap{\arules}{\scriptlopsim}}
\newcommand{\ruleslop}{\indap{\arules}{\scriptlop}}
\newcommand{\rulesexpand}{\indap{\arules}{\scriptexpand}}
\newcommand{\rulesexp}{\indap{\arules}{\scriptexp}}
\newcommand{\rulesexpprime}{\indap{\arules}{\scriptexp'}}

\newcommand{\aTRS}{{\cal R}}
\newcommand{\alTRS}{{\cal L}}
\newcommand{\lTRSof}{\fap{\alTRS}}

\newcommand{\TRS}{TRS}
\newcommand{\TRSs}{TRSs}
\newcommand{\CRS}{CRS}

\newcommand{\stermsover}{\text{\nf Ter}}
\newcommand{\termsover}{\fap{\stermsover}}
\newcommand{\termslosimover}{\fap{\stermsover_{\scriptlosim}}}
\newcommand{\sinftermsover}{\text{\nf Ter}^{\infty}}
\newcommand{\inftermsover}{\fap{\sinftermsover}}

\newcommand{\scontextsover}{\textit{Cxt}}
\newcommand{\contextsover}{\fap{\scontextsover}}
\newcommand{\scontextsnover}{\bap{\scontextsover}}
\newcommand{\contextsnover}[1]{\fap{\scontextsnover{#1}}}

\newcommand{\sloredsimtermsover}{\text{\nf Ter}_{\text{lo-red}}}
\newcommand{\loredsimtermsover}{\fap{\sloredsimtermsover}}

\newcommand{\sarity}{\textit{ar}}
\newcommand{\arityof}{\fap{\sarity}}

\newcommand{\vars}{\textit{Var}}


\newcommand{\sfolapp}{@}
\newcommand{\sfonlabs}{\lambda}
\newcommand{\sfolabs}[1]{(\lambda{#1})}
\newcommand{\sfonlvarsucc}{\snlvarsucc}
\newcommand{\folapp}{\bfap{\sfolapp}}
\newcommand{\fonlabs}{\fap{\sfonlabs}}
\newcommand{\fonlvarsucc}{\fap{\sfonlvarsucc}}
\newcommand{\folabs}[1]{\fap{\sfolabs{#1}}}

\newcommand{\afovar}{\mathsf{v}}
\newcommand{\afovari}[1]{\indap{\afovar}{\hspace*{-0.25pt}#1}}

\newcommand{\dBi}[1]{\underline{#1}}


\newcommand{\afoscopesym}{f}
\newcommand{\bfoscopesym}{g}
\newcommand{\cfoscopesym}{h}
\newcommand{\dfoscopesym}{i}
\newcommand{\afoscopesymi}{\indap{\afoscopesym}}
\newcommand{\afoscope}{\fap{\afoscopesym}}
\newcommand{\bfoscope}{\fap{\bfoscopesym}}
\newcommand{\cfoscope}{\fap{\cfoscopesym}}
\newcommand{\dfoscope}{\fap{\dfoscopesym}}

\newcommand{\cxtap}[2]{{#1}[#2]}
\newcommand{\cxtapbig}[2]{{#1}\bigl[#2\bigr]}
\newcommand{\acxt}{C}
\newcommand{\bcxt}{D}
\newcommand{\ccxt}{E}
\newcommand{\acxtap}{\cxtap{\acxt}}
\newcommand{\bcxtap}{\cxtap{\bcxt}}
\newcommand{\ccxtap}{\cxtap{\ccxt}}
\newcommand{\acxti}{\bap{\acxt}}
\newcommand{\bcxti}{\bap{\bcxt}}
\newcommand{\ccxti}{\bap{\ccxt}}

\newcommand{\bcxtfromi}[1]{\pap{\bcxt}{(#1)}}
\newcommand{\bcxtfromiap}[1]{\cxtap{\bcxtfromi{#1}}}


\newcommand{\afoscopecxt}{F}
\newcommand{\afoscopecxtap}{\cxtap{\afoscopecxt}}
\newcommand{\hole}{\Box}
\newcommand{\holei}{\iap{\hole}}
\newcommand{\holes}{\pmb{\hole}}



\newcommand{\nary}[1]{{}\nb-ary}


\newcommand{\ruleof}[1]{\indap{\rho}{\hspace*{-0.3pt}#1}}

\newcommand{\smyleftspoon}{\hbox{}}
\newcommand{\smyrightspoon}{\hbox{}}
\newcommand{\sdependson}{\smyleftspoon}
\newcommand{\dependson}{\mathrel{\sdependson}}
\newcommand{\sisnestedinto}{\smyrightspoon}
\newcommand{\isnestedinto}{\mathrel{\sisnestedinto}}

\newcommand{\sdepth}{\text{\nf d}}
\newcommand{\depth}[1]{\lvert{#1}\rvert} \newcommand{\depthbig}[1]{\big\lvert{#1}\big\rvert} \newcommand{\sudepth}{\indap{\sdepth}{\text{\nf u}}}
\newcommand{\udepth}[1]{\lVert{#1}\rVert_{\text{\nf u}}} 

\newcommand{\holedepth}[1]{\lvert{#1}\rvert_{\hole}}
\newcommand{\holedepthbig}[1]{\big\lvert{#1}\big\rvert_{\hole}}

\newcommand{\expdepth}[1]{\lvert{#1}\rvert_{\scriptexp}}
\newcommand{\expdepthbig}[1]{\bigl\lvert{#1}\bigr\rvert_{\scriptexp}}

\newcommand{\expholedepth}[1]{\lvert{#1}\rvert_{\scriptexp,\hole}}
\newcommand{\expholedepthbig}[1]{\bigl\lvert{#1}\bigr\rvert_{\scriptexp,\hole}}

\newcommand{\holedepthnotexp}[1]{\lvert{#1}\rvert_{\hole}^{\scriptnotexp}}
\newcommand{\holedepthnotexpbig}[1]{\big\lvert{#1}\big\rvert_{\hole}^{\scriptnotexp}}

\newcommand{\scriptnotexp}{\text{\sout{\nf\hspace*{1pt}exp\hspace*{1pt}}}}
\newcommand{\depthnotexp}[1]{\lvert{#1}\rvert^{(\scriptnotexp)}}
\newcommand{\depthnotexpbig}[1]{\big\lvert{#1}\big\rvert^{(\scriptnotexp)}} 


\newcommand{\snestdepth}{\textit{d}_{\text{\nf nest}}}
\newcommand{\nestdepth}{\fap{\snestdepth}}
\newcommand{\smaxnestdepth}{\textit{D}_{\text{\nf nest}}}
\newcommand{\maxnestdepth}{\fap{\smaxnestdepth}}




\newcommand{\ssize}{\text{\normalfont sz}}
\newcommand{\size}[1]{\left\lVert{#1}\right\rVert} 



\newcommand{\expsize}[1]{\left\lVert{#1}\right\rVert\bap{}{\scriptexp}}





\newcommand{\slcns}{{:}{:}}
\newcommand{\lcns}[2]{{#1}\mathrel{\slcns}{#2}}
\newcommand{\emptylist}{{[\hspace*{0.5pt}]}}
\newcommand{\avarlist}{\avar s}
\newcommand{\bvarlist}{\bvar s}



\newcommand{\slop}{\textit{lop}}\newcommand{\slopstar}{\pap{\slop}{*}}
\newcommand{\slopn}{\subap{\slop}}
\newcommand{\slopstart}{\slop}
\newcommand{\lopstart}{\fap{\slop}}
\newcommand{\lopn}[1]{\fap{\slopn{#1}}}
\newcommand{\slopni}[2]{\slop_{#1,\hspace*{1pt}#2}}
\newcommand{\lopni}[2]{\fap{\slopni{#1}{#2}}}  
\newcommand{\sappsfromseq}{\subap{\textit{app}}{\hspace*{-0.7pt}\textit{s}}}
\newcommand{\appsfromseq}{\bfap{\sappsfromseq}}
\newcommand{\ssubst}{\textit{subst}}
\newcommand{\subst}{\tfap{\ssubst}}

\newcommand{\slopsimTRS}{{\cal L\hspace*{-0.75pt}O}} \newcommand{\lopsimTRSwrt}{\fap{\slopsimTRS}}
\newcommand{\sLOTRSprime}{{\cal L\hspace*{-1.5pt}O}'}
\newcommand{\LOTRSprimewrt}{\fap{\sLOTRSprime}}
\newcommand{\sLOCRS}{{\cal L\hspace*{-1.5pt}O}_{\textit{CRS}}}
\newcommand{\LOCRSwrt}{\fap{\sLOCRS}}

\newcommand{\sexpandTRS}{{\cal E}}
\newcommand{\sexpandTRSlosim}{\indap{\sexpandTRS}{\scriptlosim}}
\newcommand{\sexpandTRSlopsim}{\indap{\sexpandTRS}{\scriptlopsim}}
\newcommand{\expandTRSwrt}{\fap{\sexpandTRS}}
\newcommand{\expandTRSlosimwrt}{\fap{\sexpandTRSlosim}}
\newcommand{\expandTRSlopsimwrt}{\fap{\sexpandTRSlopsim}}

\newcommand{\denlterrepwrt}[2]{\llbracket{#2}\rrbracket^{#1}}
\newcommand{\denlterrep}[1]{\llbracket{#1}\rrbracket}
\newcommand{\denlterwrt}[2]{\llbracket{#2}\rrbracket^{#1}_{\sslabs}}
\newcommand{\denlter}[1]{\llbracket{#1}\rrbracket_{\sslabs}}

\newcommand{\denlterrepnlop}[1]{\llbracket{#1}\rrbracket^{\text{\st{\slop}}}}


\newcommand{\losimTRS}{losim-TRS}
\newcommand{\lopsimTRS}{lopsim-TRS}
\newcommand{\loredTRS}{lo-red-TRS}
\newcommand{\omredTRS}{om-red-TRS}
\newcommand{\loredCRS}{lo-red-CRS}









\newcommand{\alter}{M}
\newcommand{\blter}{N}
\newcommand{\clter}{L}
\newcommand{\dlter}{P}
\newcommand{\elter}{Q}
\newcommand{\alteracc}{\alter'}
\newcommand{\blteracc}{\blter'}
\newcommand{\clteracc}{\clter'}
\newcommand{\dlteracc}{\dlter'}
\newcommand{\elteracc}{\elter'}
\newcommand{\alteri}{\indap{\alter}}
\newcommand{\blteri}{\indap{\blter}}
\newcommand{\clteri}{\indap{\clter}}
\newcommand{\dlteri}{\indap{\dlter}}
\newcommand{\alteracci}{\indap{\alteracc}}
\newcommand{\blteracci}{\indap{\blteracc}}
\newcommand{\clteracci}{\indap{\clteracc}}
\newcommand{\dlteracci}{\indap{\dlteracc}}

\newcommand{\twochurch}{\textit{two}}

\newcommand{\sslabs}{\lambda}
\newcommand{\slabs}[1]{\sslabs{#1}.}
\newcommand{\labs}[2]{\slabs{#1}{#2}}
\newcommand{\lapp}[2]{{#1}{#2}}


\newcommand{\substin}[2]{{#1}[{#2}]}
\newcommand{\substinfor}[3]{\substin{#1}{{#2}\defdby{#3}}}


\newcommand{\sred}{\to}
\newcommand{\red}{\mathrel{\sred}}
\newcommand{\sredi}{\indap{\sred}}
\newcommand{\redi}[1]{\mathrel{\sredi{#1}}}
\newcommand{\sredij}{\bpap{\sred}}
\newcommand{\redij}[2]{\mathrel{\sredij{#1}{#2}}}
\newcommand{\smred}{\twoheadrightarrow}
\newcommand{\mred}{\mathrel{\smred}}
\newcommand{\smredi}{\indap{\smred}}
\newcommand{\mredi}[1]{\mathrel{\smredi{#1}}}
\newcommand{\sredn}{\supap{\sred}}
\newcommand{\redn}[1]{\mathrel{\sredn{#1}}}
\newcommand{\sredin}[2]{\bpap{\sred}{#1}{#2}}
\newcommand{\redin}[2]{\mathrel{\sredin{#1}{#2}}}


\newcommand{\snfred}{{\downarrow}}
\newcommand{\nfred}{\mathrel{\snfred}}
\newcommand{\nfof}[1]{{#1}\snfred}

\newcommand{\ssyntequal}{{\equiv}}
\newcommand{\syntequal}{\mathrel{\ssyntequal}}
\newcommand{\snotsyntequal}{{\not\equiv}}
\newcommand{\notsyntequal}{\mathrel{\snotsyntequal}}

\newcommand{\scriptlo}{\text{\nf lo}}
\newcommand{\scriptlop}{\text{\nf lop}}
\newcommand{\scriptlosim}{\text{\nf losim}}
\newcommand{\scriptlored}{\text{\nf lored}}
\newcommand{\scriptlopsim}{\text{\nf lopsim}}
\newcommand{\scriptlopred}{\text{\nf lopred}}
\newcommand{\scriptexpand}{\text{\nf expand}}
\newcommand{\scriptexp}{\text{\nf exp}}
\newcommand{\scriptsearch}{\text{\nf search}}
\newcommand{\scriptcontract}{\text{\nf contr}}
\newcommand{\scriptstart}{\text{\nf start}} 
\newcommand{\scriptsubst}{\text{\nf subst}}


\newcommand{\scriptinit}{\text{\nf init}}
\newcommand{\scriptdescendinfolapp}{\iap{\text{\nf desc}}{\sfolapp}}
\newcommand{\scriptdescendinfolabs}{\iap{\text{\nf desc}}{\sfonlabs}}
\newcommand{\scriptcontractn}[1]{\iap{\text{\nf contr}}{{#1}}}
\newcommand{\scriptcontractbeta}{\iap{\text{\nf contr}}{\beta}}
\newcommand{\scriptcontractbetan}[1]{\iap{\text{\nf contr}}{\beta,{#1}}}
\newcommand{\scriptvar}{\text{\nf var}}
\newcommand{\scriptvardistribute}{\text{\nf var-distr}}


\newcommand{\ssearchred}{\sredi{\scriptsearch}}
\newcommand{\searchred}{\mathrel{\ssearchred}}
\newcommand{\ssearchmred}{\smredi{\scriptsearch}}
\newcommand{\searchmred}{\mathrel{\ssearchmred}}
\newcommand{\ssubstred}{\sredi{\scriptsubst}}
\newcommand{\substred}{\mathrel{\ssubstred}}
\newcommand{\ssubstmred}{\smredi{\scriptsubst}}
\newcommand{\substmred}{\mathrel{\ssubstmred}}
\newcommand{\scontractred}{\sredi{\scriptcontract}}
\newcommand{\contractred}{\mathrel{\scontractred}}
\newcommand{\slored}{\sredi{\text{\nf lo}}}
\newcommand{\lored}{\mathrel{\slored}}
\newcommand{\scriptlobeta}{\text{\nf lo}\beta}
\newcommand{\slobetared}{\sredi{\scriptlobeta}}
\newcommand{\lobetared}{\mathrel{\slobetared}}
\newcommand{\slobetaredn}{\sredin{\scriptlobeta}}
\newcommand{\lobetaredn}[1]{\mathrel{\slobetaredn{#1}}}
\newcommand{\slobetamred}{\smredi{\scriptlobeta}}
\newcommand{\lobetamred}{\mathrel{\slobetamred}}
\newcommand{\slosim}{\supap{\text{\nf lo}}{*}}
\newcommand{\slosimred}{\sredi{\slosim}}
\newcommand{\losimred}{\mathrel{\slosimred}}
\newcommand{\slosimmred}{\smredi{\slosim}}
\newcommand{\losimmred}{\mathrel{\slosimmred}}
\newcommand{\slopsimred}{\sredi{\slop}}
\newcommand{\lopsimred}{\mathrel{\slopsimred}}
\newcommand{\slopsimmred}{\smredi{\slop}}
\newcommand{\lopsimmred}{\mathrel{\slopsimmred}}



\newcommand{\somred}{\sredi{\text{\nf om}}}
\newcommand{\omred}{\mathrel{\somred}}
\newcommand{\sommred}{\smredi{\text{\nf om}}}
\newcommand{\ommred}{\mathrel{\sommred}}

\newcommand{\sexpand}{\textit{exp}}
\newcommand{\expand}{\fap{\sexpand}}
\newcommand{\sexpandi}{\indap{\sexpand}}
\newcommand{\expandi}[1]{\fap{\sexpandi{#1}}}

\newcommand{\sexpred}{\sredi{\scriptexp}}
\newcommand{\expred}{\redi{\scriptexp}}
\newcommand{\sexpmred}{\smredi{\scriptexp}}
\newcommand{\expmred}{\mredi{\scriptexp}}

\newcommand{\sbetared}{\sred_{\beta}}
\newcommand{\betared}{\mathrel{\sbetared}}
\newcommand{\sbetaredn}{\sredin{\beta}}
\newcommand{\betaredn}[1]{\mathrel{\sbetaredn{#1}}}

\newcommand{\sexprednf}{{\downarrow_{\scriptexp}}}
\newcommand{\exprednf}[1]{{#1}\sexprednf}
\newcommand{\sexprednfi}[1]{{\bpap{\downarrow}{\scriptexp}{\hspace*{-1pt}(#1)}}}
\newcommand{\exprednfi}[2]{{\langle#2\rangle}\sexprednfi{#1}}
\newcommand{\sexprednfbig}{{\big\downarrow_{\scriptexp}}}
\newcommand{\exprednfbig}[1]{{#1}\sexprednfbig}
\newcommand{\sexprednfbigi}[1]{{\bpap{\smash{\big\downarrow}}{\scriptexp}{\hspace*{-1.5pt}(#1)}}}
\newcommand{\exprednfbigi}[2]{{#2}\sexprednfbigi{#1}}

\newcommand{\exprednfiof}[1]{\fap{\sexprednfi{#1}}}




\newcommand{\sinitred}{\sredi{\scriptinit}}
\newcommand{\initred}{\mathrel{\sinitred}}
\newcommand{\sdescendinfolappred}{\sredi{\scriptdescendinfolapp}}
\newcommand{\descendinfolappred}{\mathrel{\sdescendinfolappred}}
\newcommand{\sdescendinfolabsred}{\sredi{\scriptdescendinfolabs}}
\newcommand{\descendinfolabsred}{\mathrel{\sdescendinfolabsred}}
\newcommand{\scontractbetared}{\sredi{\scriptcontractbeta}}
\newcommand{\contractbetared}{\mathrel{\scontractbetared}}
\newcommand{\svarred}{\sredi{\scriptvar}}
\newcommand{\varred}{\mathrel{\svarred}}
\newcommand{\svarnred}[1]{\sredi{\scriptvar_{#1}}}
\newcommand{\varnred}[1]{\mathrel{\svarnred{#1}}}


\newcommand{\arewseq}{\sigma}
\newcommand{\brewseq}{\tau}
\newcommand{\arewstep}{\rho}


\newcommand{\scomprewrels}[2]{{#1}\cdot{#2}}
\newcommand{\comprewrels}[2]{\mathrel{\scomprewrels{#1}{#2}}}




\newcommand{\casedistinction}{case-dis\-tinc\-tion}
\newcommand{\lambdaabstraction}{\nb-ab\-strac\-tion}
\newcommand{\LambdaCalculus}{Lambda Calculus}
\newcommand{\lambdacalculus}{\nb-cal\-cu\-lus}
\newcommand{\lambdabinding}{\nb-bin\-ding}
\newcommand{\lambdaterm}{\nb-term}
\newcommand{\lambdaterms}{\lambdaterm{s}}
\newcommand{\lambdadepth}{\nb-depth}
\newcommand{\lambdalifting}{lambda-lif\-ting}
\newcommand{\Lambdalifting}{Lambda-lif\-ting}
\newcommand{\betareduction}{\nb-re\-duc\-tion}
\newcommand{\betacontraction}{\nb-con\-trac\-tion}
\newcommand{\betaredex}{\nb-re\-dex}
\newcommand{\alphaconversion}{\nb-con\-ver\-sion}
\newcommand{\alphaequivalent}{\nb-equi\-va\-lent}
\newcommand{\lo}{left\-most-outer\-most}
\newcommand{\loabb}{l.o.}
\newcommand{\om}{outermost}
\newcommand{\loreduction}{\lo~re\-duc\-tion}
\newcommand{\lopreduction}{\lo-par\-al\-lel~re\-duc\-tion}
\newcommand{\lopbetareduction}{\lo-par\-al\-lel~\betareduction}
\newcommand{\loredex}{\lo\ re\-dex}
\newcommand{\nondeterministic}{non-de\-ter\-min\-istic}
\newcommand{\nontrivial}{non-triv\-i\-al}
\newcommand{\omreduction}{\om\nb-re\-duc\-tion}
\newcommand{\omredex}{\om\nb-redex}

\newcommand{\oTRS}{oTRS}

\newcommand{\TRSrepresentation}{\TRS\nb-re\-pre\-sen\-ta\-tion}
\newcommand{\CRSrepresentation}{\CRS\nb-re\-pre\-sen\-ta\-tion}
\newcommand{\lTRSrepresentation}{\lTRS\nb-re\-pre\-sen\-ta\-tion}
\newcommand{\lTRS}{\hspace*{-0.5pt}\nb-\hspace*{-0.5pt}\TRS}
\newcommand{\lTRSs}{\lTRS{s}}

\newcommand{\welldefined}{well-de\-fined}
\newcommand{\wellfounded}{well-found\-ed}


\newcommand{\sseared}{\sredi{\text{\nf s}}}
\newcommand{\sseamred}{\smredi{\text{\nf s}}}
\newcommand{\sconred}{\sredi{\text{\nf c}}}

\newcommand{\lambdacal}{\lambda}
\newcommand{\graphcal}{\mathcal{G}}
\newcommand{\graphcalwrt}{\fap{\graphcal}}
\newcommand{\agraph}{G}
\newcommand{\agraphi}{\iap{\agraph}}
\newcommand{\sgraphred}{{\Longrightarrow}}
\newcommand{\graphred}{\mathrel{\sgraphred}}
\newcommand{\sgraphredrtc}{{\Longrightarrow^*}}
\newcommand{\graphredrtc}{\mathrel{\sgraphredrtc}}
\newcommand{\sgraphredn}[1]{{\pap{\sgraphred}{#1}}}
\newcommand{\graphredn}[1]{\mathrel{\sgraphredn{#1}}}



\newcommand{\stime}{\text{\nf Time}}
\newcommand{\timei}{\bap{\stime}}







 

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem*{corollary*}{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem*{fact}{Fact}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{question}[theorem]{Question}
\newtheorem{claim}{Claim}
\newtheorem{case}{Case} 
 
 
\begin{document}
\publicationdetails{VOL}{2015}{ISS}{NUM}{SUBM}
\maketitle
\begin{abstract}
  Performing  steps of \betareduction\ to a given term in the \lambdacalculus\ 
  can lead to an increase in the size of the resulting term that is exponential in . 
  The same is true for the possible depth increase of terms along a \betareduction\ sequence. 
  We explain that the situation is different for the \lo\ strategy for \betareduction:
  while exponential size increase is still possible, depth increase is bounded linearly in the number of steps. 
  For every \lambdaterm~ with depth , 
  in every step of a \lo\ \betareduction\ rewrite sequence starting from  
  the term depth increases by at most .
  Hence the depth of the \nb-th reduct of  in such a rewrite sequence~is~bounded~by~.
  
  We prove the lifting of this result to \lambdaterm\ representations as orthogonal first-order term rewriting systems,
  which can be obtained by the \lambdalifting\ transformation.
  For the transfer to \lambdacalculus, we rely on correspondence statements via \lambdalifting. 
  We argue that the linear-depth-increase property can be a stepping stone for an alternative proof of, and so can shed new light on,
  a result by Accattoli and Dal~Lago (2015) that states: 
  leftmost-outermost \betareduction\ rewrite sequences of length  in the \lambdacalculus\ can be implemented on a reasonable machine with an overhead
  that is polynomial in  and the size of the initial term. 
  
  \keywords{lambda calculus, beta reduction, leftmost-outermost strategy, complexity}
\end{abstract}



\section{Introduction}
Accattoli and Dal~Lago \cite{acca:lago:2014:beta-reduction-invariant:LICS,acca:lago:2016}
proved that the number of steps in a
\lo\ rewrite sequence to normal form provides an invariant cost model for the \lambdacalculus, in the following sense.\ 
There is an implementation  on a reasonable machine (e.g., a Turing machine, or a random access machine)
of the partial function that maps a \lambdaterm\ to its normal form, whenever that exists,
such that  has the following property: 
there are integer polynomials  and 
such that if a \lambdaterm~ is the result of  successive \lo\ \betareduction\ steps performed to a \lambdaterm~ of size~,
then  obtains a compact representation~ of  from 
in time bounded by , 
and  can be obtained from  in time bounded by  where  is the symbol size of 
the represented \lambdaterm~.\footnote{That the represented \lambdaterm~ must be computable from its compact representation~
            in time bounded by the size of ,
            which is implicit in the result of \cite{acca:lago:2014:beta-reduction-invariant:LICS,acca:lago:2016},
            is crucial to prevent `hiding' of reduction work in the computation of `pretty printing'  as .} 


To achieve this result, Accattoli and Dal~Lago describe how to simulate \lo\ \betareduction\ rewrite sequences in the \lambdacalculus\ by
`\lo\ useful' rewrite sequences in the linear explicit substitution calculus.
They employ substitution steps only insofar as those are needed to 
create the \lo\ \betaredex\ (representation), or to make it visible. 
In this way they work with shared representations of \lambdaterms\ in order to avoid size explosion. 
Then they show that `\lo\ useful' rewrite sequences in the linear explicit substitution calculus can be implemented on a reasonable machine
with a polynomial overhead dependent on the length of the sequence, and the size of the initial~term.\pagebreak[4]   

My goal is to connect this result with  graph reduction techniques that are widely used for the compilation and runtime-evaluation of functional programs.
In particular, I would like to obtain a graph rewriting implementation for \lo\ \betareduction\ in the \lambdacalculus\
that demonstrates this result, but that is close in spirit to graph reduction as it is used in runtime evaluators for functional programming languages.  
My idea is to describe a port graph grammar \cite{stew:2002} implementation that is based on 
\TRS\ (term rewrite system) representation{s} of \lambdaterm{s}.
These \lambdaterm\ representations correspond closely to supercombinator systems that are obtained by \lambdalifting, as first described by Hughes~\cite{hugh:1982:report}.

That such an implementation is conceivable by employing subterm-sharing 
is suggested by a property of (plain, unshared) \lo\ \betareduction\ rewrite sequences in the \lambdacalculus\
that we will show.
The depth increase in each step of an arbitrarily long \lo\ \betareduction\ rewrite sequence from a \lambdaterm~
is uniformly bounded by , the depth of .
As a consequence, for the depth of the \nb-th reduct~ of a \lambdaterm~ 
in a \lo\ \betareduction\ rewrite sequence  
it holds that: ,
and hence . 

In the terminology of \cite{acca:lago:2014:beta-reduction-invariant:LICS,acca:lago:2016}
this property shows that \lo\ rewrite sequences do not cause `depth explosion' in \lambdaterms. 
This contrasts with general  rewrite sequences,
along which the depth of terms may increase exponentially.
The example below provides an illustration. 

\begin{example}[`depth-exploding' family under \betareduction, from Asperti and L\'{e}vy \cite{aspe:levy:2013}] 
  Consider the following families  and  of \lambdaterms: 
  \begin{center}
    n\in\natn\in\nat
  \end{center}
where 
  
  is the Church numeral for .
  By induction on  it can be verified that it holds:
  \begin{center}
    
  \end{center}
  and that the syntax tree of  is the complete binary application tree 
  with  occurrences of  at depth .
  The induction step for the statement on the rewrite sequence can be performed as follows:
  
  This  rewrite sequence is not \lo, but it proceeds mainly in inside-out direction. 
  
  Let . Then for  and 
  it follows that  reduces to its normal form  in precisely  \betareduction\ steps
  ,
  for with reducts~,
  that the depth of the initial term is
  ,
  and the depth of the final term is
  .
  From this it follows
  . 
  
  This argument shows that for the relative depth increase of \betareduction\ rewrite sequences  of length 
  is exponential, because it holds in any case that
   for every .
\end{example}


\smallskip
Such an exponential depth increase with respect to general \betareduction\
contrasts sharply with the linear-depth-increase property of \lo\ \betareduction\ that we will show here.
We now lay out the basic insight that is at the basis of this result.

\paragraph{Underlying property, leading to the linear-depth-increase result.}
  For every leftmost-outermost \betareduction\ rewrite sequence 
  
  in the \lambdacalculus\ the following property can be shown:
  if  is the \lo\ \betaredex\ in the \nb-th reduct ,
  its abstraction part has a representation
    
  with `scope part'  and `free subexpressions' ,
  where  are distinct variables that are free in , 
  such that an abstraction of the form
  
  with the same scope part , but possibly with different free subexpressions ,   
  occurs already in  (perhaps as an \alphaconversion\ equivalent variant).
  This implies 
  for the depth of  in relation to the depth of the initial term  of the sequence.
  Now if  for some unary context 
  with the \lo\ \betaredex\ highlighted, then the \nb-th step is of the form:
  
  In order to move the substitutions for  inside of the abstraction ,
  we have assumed here, for simplicity, that  does not occur free in one of 
  (otherwise \alphaconversion\ would be needed to rename  in  first).
  This justifies taking up the substitution of  for  into the simultaneous substitution expression 
  after the  step. 
  Now from the form of the step 
  we see that any depth increase can only stem from the substitution of  for one of the occurrences of  in .
  This can move the argument  of the \betaredex\ deeper by at most .
  So by using , see above, we obtain 
    .
  In this way we recognize that the depth increase in the \nb-th \lo\ \betareduction\ step is always bounded by the depth  of the initial term  of the sequence.


\paragraph{Concepts for showing the underlying property.}
  For showing that scope parts of abstractions in \lo\ redexes of \lo\ \betareduction\ rewrite sequences trace back to the initial term of the sequence,
  we will use representations of \lambdaterms\ as orthogonal first-order term rewrite systems.
  We call these TRS representations \lTRSs.
  They are closely connected to systems of supercombinators \cite{hugh:1982:report,hugh:1982},
  which are widely used for the compilation of functional programs. 
Supercombinator translations are obtained by `\lambdalifting' \cite{peyt:1987}.
  This transformation rewrites higher-order terms with bindings (such as named abstractions in \lambdaterms)
  into applicative first-order terms, and a finite number of combinator definitions.
  For functional programs \lambdalifting\ is applied by construeing them as 
  generalized \lambdaterms\ with \textsf{case} and \textsf{letrec} constructs.
  A program is compiled into a finite number of combinator definitions 
  of the form  where  is an applicative combinator context.
  
  Supercombinator representations are well-suited for the evaluation via \lo\ evaluation. This is because evaluation can proceed by repeatedly applying a combinator definition
  to occurrences of combinators with their sufficient number of arguments.
  In the example as above these are occurrences of applicative terms of the form . 
  In this way evaluation becomes a process of applying combinator definitions locally 
  without having to carry out the substitutions of arguments for variable occurrences that are needed for \betareduction\ on \lambdaterms.
  Moreover, \lo\ \betareduction\ can be simulated by evaluating combinator terms in a \lo\ manner. 
  In the \lTRS\ formulation,
  supercombinator definitions are modeled by rewrite rules 
   where  is a scope symbol,
  and  an applicative context that may contain other scope symbols.
  \lTRSs\ correspond to systems of supercombinators that are obtained by `fully-lazy \lambdalifting' \cite{hugh:1982:report,peyt:1987}. 
  
  This construction of first-order term representations of \lambdaterms\ 
  guarantees that every redex of a term in the representing \lTRS\
  corresponds to a \betaredex\ via the translation to \lambdaterms. 
  Indeed, the \lo\ redex on a \lTRS\ term representation of a \lambdaterm\ corresponds to the \lo\ \betaredex\ on the represented \lambdaterm. 
  But conversely, typically not all \betaredex{es} in a \lambdaterm\ will correspond directly to a redex on the \lTRSrepresentation.
  Crucially, after a number of (typically \lo) \betareduction\ steps  
    have been simulated from a \lTRS\nb-term  that represents a \lambdaterm~,
  every redex  in  will involve a scope symbol  that, 
  under the translation to \lambdacalculus,
  represents the scope of  in a a subterm~ that already occurred (modulo \alphaconversion) in . 
  
  \smallskip





While the linear-depth-increase statement will be shown for rewrite sequences in a \TRS\
for simulating \lo\ \betareduction, its transfer to \lambdaterms\ via a lifting theorem along \lambdalifting\
will only be sketched. The lifting and projection statements needed for this part are similar
to proofs for the correctness of fully-lazy \lambdalifting\ as described by Balabonski~\cite{bala:2012}.   

Notwithstanding the linear-depth-increase property for \lo\ rewrite sequences that we show here,
it is important to realize that `size explosion' (exponential size increase) can in fact take place.
There are infinitely many \lambdaterms~ of size  (linear size in )
such that  reduces in  \lo\ \betareduction\ steps
to a term of size  (properly exponential size in ). 

\begin{example}[`size-exploding' family under \lo\ -red., from Accattoli and \mbox{Dal~Lago~\cite{acca:lago:2014:beta-reduction-invariant:LICS,acca:lago:2016}}] 
    \label{expl:lo:size:exploding:family}
  Consider the following two families  and  of \lambdaterms:  
  \begin{center}
    n\in\natn\in\nat
  \end{center}
  Every term , for  is a normal form, and it holds that:
  
  This can be shown by induction.
  Furthermore the term  is the normal form of , for ,
  because there is a \lo\ \betareduction\ rewrite sequence of length~ from  to :
  \begin{center}
    n\in\nat  
  \end{center}
  The induction step in a proof of this statement can be verified as follows:
  \begin{center}
    \alteri{n} \lobetaredn{n} \blteri{n}\alteri{n} \lobetaredn{n} \blteri{n}\alteri{0}\blteri{0}\alteri{0}
  \end{center}
  Finally, the size of terms in  grows linearly,
  and the size of terms  exponentially: 
  \begin{center}
    
  \end{center}
  where by the size of the \lambdaterm\ we understand the size of its syntax tree plus the number of symbols in variable occurrences.   
\end{example}


Therefore naive implementations of \lo\ \betareduction\ that operate
directly on \lambdaterms\ cannot avoid exponential runtime cost, simply because the result
of  \lo\ \betareduction\ steps can be exponentially larger than the initial term.
However, Accattoli and Dal Lago recognized that a \lo\ \betareduction\ sequence 
can also be implemented in the linear substitution calculus
by carrying out explicit-substitution steps of \betaredex\ contractions in a lazy manner
that only guarantees that the pattern of the next \lo\ \betaredex\ is always visibly created. 
They show that, in this way, the size of intermediate \lambdaterm\ representations stays 
polynomially bounded by the length of the sequence. 

The linear-depth-increase property along \lo\ rewrite sequences suggests 
an alternative proof, which is based on graph rewriting, of the result by Accattoli and Dal~Lago.
The crucial idea is to use directed acyclic graph representations of terms in a \lTRS\
with the property that the depth of a graph (which is defined due to acyclicity) corresponds closely to the depth of the represented term. 
Then the power of sharing is deployed to avoid size explosion of the graph representations.
In Section~\ref{sec:idea:graph:implementation} we sketch the basic idea for 
such a graph implementation, and estimate its complexity.




\paragraph{Overview.}
  In Section~\ref{sec:lo-simulation}
    we introduce representations of \lambdaterms\ as first-order terms,
    and define a TRS that simulates the \lo\ strategy 
    (and a \nondeterministic\ generalization) for \betareduction\ 
on \lambdaterm\ representations. 
  In Section~\ref{sec:lTRSs} 
    we define \lTRSs, that is, representations of \lambdaterms\ as orthogonal term write systems
    that are closely related to supercombinator representations.
    We also define the expansion of \lTRS\ representations into first-order term represenations of \lambdaterms.
  In Section~\ref{sec:lo-simulation:lTRSs}
    we adapt the \lo\ \betareduction\ simulation TRS from Section~\ref{sec:lo-simulation} 
    to \lTRS\ representations of \lambdaterms.  
  In Section~\ref{sec:depth:increase}
    we show the linear-depth-increase result for simulated \lo\ \betareduction\ sequences:
    we prove it for all rewrite sequences in the simulation TRS on \lTRS\ respresentations.
  In Section~\ref{sec:transfer:lambda-calculus}
    we sketch how the linear-depth-increase result can be transferred from \lTRS\ representations to \lambdaterms.
  In Section~\ref{sec:idea:graph:implementation}
    we briefly lay out our idea of using the linear-depth-increase result 
    for developing an efficient graph rewriting system
    for simulating \lo\ \betareduction\ on \lTRS\ representations.


\section{Preliminaries}
  \label{prelims}


By  we denote the natural numbers including .
For first-order term rewriting systems, terminology and notation from the standard text \cite{terese:2003} will be used.
Below we summarize the most important concepts and the notation that we will use. 

\paragraph{First-order signatures, variables, and context holes.}
  A \emph{(first-order) signature}  is a set of function symbols that is equipped with an arity function . 
  Such a signature may contain \emph{constants} by which we mean function symbols of arity~. 
  When referring to signatures, we will mostly keep the arity function implicit, and write  for . 
  
  In addition to first-order signatures we will use
  countably infinite sets  of \emph{variables},
  and a countably infinite set  of \emph{context hole symbols}
  each of which carries an index.
  We will always tacitly assume that the set~, the set~, 
  and the union of the set of function symbols in signature , , \ldots, under consideration
  are disjoint.
  
  
  
\paragraph{Terms and contexts over first-order signatures.}   
  By  we denote the set of \emph{terms over signature  and set  of variables} 
  that are formed with function symbols in  and variables in .
  By  (with an empty set of variables) we define 
  the set of \emph{ground terms} over ,
  that is, the set of terms that are formed from only the function symbols in .
  We use  to indicate syntactic equality of terms.
  
  For , ,  we denote by  the set of \emph{contexts} 
  that are formed with function symbols in  and variables in ,
  and with  kinds of holes .
  Note that an \nary{n} context may contain zero, one or more occurrences of each of the  holes;
  so it does not need to have any hole occurrence at all, in which case it is a term.
  As a consequence also  holds for all , .
  We also use  to indicate syntactic equality of contexts.
For , , we define by   
  the set of \nary{n} \emph{ground contexts} over ,
  that is, the set of \nary{n} contexts that are formed from the function symbols in .
By 
  we define the set of contexts over  and  and with some of the holes in .
  Note again that  holds.
  By  we denote the set of ground contexts over . 
  
  For unary (\nary{1}) contexts  we permit to drop the subscript `1'
  from the context hole , which then is the single context hole  that may occur in ,
  and thus we permit to write  for . 
  
  By  we denote the subset of  that is formed
  by the \emph{\underline{\smash{linear}}} \nary{n} contexts in which every context hole , for 
  is only permitted to occur once. By  we denote the set of linear, \nary{n}, ground contexts over .
  
  Let  be an \nary{n} context.
  Then for terms 
  we denote by  the term in  
  that results from  by replacing each hole  in  by , for all .
  Similarly, for contexts  
  we denote by  the context in  
  that results from  by replacing each hole  in  by , for all .
    
  
\paragraph{Depth and size of terms. Depth, hole depth, and size of contexts.} 
  For a term  we denote by  the \emph{depth of }
  by which we mean the length of the longest (cycle-free) path in the syntax tree of  from the root to a leaf. 
  For a context  the \emph{depth  of } is defined analogously.  
  By the \emph{size } of a term , and the \emph{size } of a context 
  we mean the size of the syntax tree of , and , respectively. 
  
  By the \emph{hole depth } of a context 
    we mean the length of the longest (cycle-free) path in the syntax tree of  from the root to a leaf at which some hole occurs.
  We will use the following two lemmas that express easy properties concerning the connection between depth and hole depth in
  filled contexts.   

  \begin{lemma}\label{lem:holedepth:vs:depth}
    
    for all terms , where ,
    and all contexts  in which there is at least one occurrence of . 
  \end{lemma}
  
  
  \begin{lemma}\label{lem:depth:cxtap:vs:depth:holedepth}
      
    for contexts , and terms .
  \end{lemma}  


\paragraph{Term rewriting systems.}
  A \emph{term rewriting system} (\TRS) is a pair  that consists of a signature~,
  and a set  of pairs of terms over  that are called \emph{rules}.
  The rules are subject to two conditions: the left-hand side of a rule is not a variable,
  and the variables that occur on the right-hand side of a rule are a subset of the variables that occur on the left-hand side.
  
  A term  is a \emph{normal form of} a TRS~ if no rule of  is applicable to .
    
    
  
    
    
    

\paragraph{Notation for rewrite relations.}
  Let  be a \TRS\ with rewrite relation . 
  Then we denote the many-step (zero, one or more step) rewrite relation of  by ,
  and the  step rewrite relation of  by , for . 
  By  we mean the many-step relation of  to a normal form. 
  We will use the same notation convention for rewrite relations that are indexed by name abbreviations.
  

\paragraph{-calculus.}
  Contrasting with terms in a \TRS\ (first-order terms), 
  \lambdaterms\ are viewed as \nb-equivalence classes of pseudo-term representations with names for bound variables.
  For \lambdaterms,  denotes \betareduction, and  \lo\ \betareduction.

  A \betareduction\ redex in a \lambdaterm~ is called \emph{\lo} if it is to the left, or outside of any other redex in .
  The \emph{\lo\ reduction strategy} for the \lambdacalculus\ is a 1-step strategy that,
  for a given \lambdaterm~ contracts the \lo\ \betaredex\ in .



\paragraph{Termination/strong normalization of rewrite relations.} 
  Let  be the rewrite relation (of a TRS or of \lambdacalculus), and let  be a term.  
  We say that  \emph{terminates from }, 
     and also that \emph{ is strongly normalizing from }
  if there is no infinite rewrite sequence from 
  (and consequently all sufficiently long rewrite sequences from  lead to a normal form with respect to ). 
  We say that  \emph{terminates}, and also that \emph{is strongly normalizing}, if  does not enable infinite rewrite sequences.
    




\section{Simulation of leftmost-outermost rewrite sequences}
  \label{sec:lo-simulation}


We start with the formal definition of first-order representations of \lambdaterms,
called \lambdaterm\ representations,
before describing a \TRS\ for simulating \lo\ \betareduction\ on \lambdaterm\ representations.

\begin{definition}[\lambdaterm\ representations, denoted \lambdaterms]\label{def:ltermrep}
  Let

be the signature that
  consists of the \emph{variable} symbols , with , which are constants (nullary function symbols),
  the binary \emph{application symbol}~,
  and the unary \emph{named abstraction} symbols , for .
  
  Now by a \emph{\lambdaterm\ representation} (a \emph{(first-order) representation of a \lambdaterm})
  we mean a ground term in . 
  A \lambdaterm\ representation  denotes, by reading its symbols in the obvious way,
  and interpreting occurrences of variable symbols  that are not bound,
  as the variable names , a unique \lambdaterm\ .
  
  
  
  
  
  
\end{definition}

\begin{example}
  ,
  , and
  
  are \lambdaterm\ representations that denote the \lambdaterms\
  ,
  ,
  and 
  ,
  respectively.
\end{example}
    
Below we formulate a \TRS\ that facilitates the simulation, on \lambdaterm\ representations,
of the evaluation of \lambdaterms\ according to the \lo\ strategy.
We introduce this TRS as a motivation for a similar simulation \TRS\ on super\-com\-bi\-na\-tor-based \lambdaterm\ representations
that is introduced later in Definition~\ref{def:losimTRS}, and that will be crucial for obtaining the linear depth-increase result. 
While the \TRS\ is designed to reason about \lo\ rewrite sequences, it actually permits the simulation of generalizations of the \lo\ rewrite sequences:
\betaredex{es} may also be contracted if they are \lo\ in right subterms immediately below stable parts of the term. 
This is because the search process for \lo\ redexes will be initiated again in parallel positions just below stable spines. 
We will therefore use the abbreviation `lop' in symbol names to hint at 
the \nondeterministic\ evaluation strategy `\underline{l}eftmost-\underline{o}utermost, iterated in \underline{p}arallel positions below stable parts of the term'. 

The idea behind the simulation \TRS\ is as follows.
The process is started on a term , where  is a \lambdaterm\ representation that is to be evaluated.
First  is initialized to  (via the rule ()), 
where the index (which here is ) will be used as a lower bound for yet unused variable indices. 
Then a term  with an outermost applications in an expression 
is uncurried into a representing expression with a stack of applications
(by steps of the rule ())
when descending over applications along the spine of the term 
until a variable or an abstraction is encountered 
(detected by one of the rules (), (), or ()).
If an abstraction occurs, and the expression contains an argument for this abstraction,
the representation of a \lo\ \betaredex\ has been detected, 
which is then contracted by a step corresponding to a \betacontraction\
(applying the rule ()); the evaluation continues similarly from there on.
If there is no argument for such an abstraction, 
then it is part of a head normal form context,
and the evaluation descends into the abstraction (applying the rule ()) 
to proceed recursively on the subterm.
If a variable occurs on the left end of the spine (detected by one of the rules () or ()), 
then a head normal form context has been detected,
which consists of a single variable (in case the applicable rule is ()),
or of the variable together with the recently uncurried applications (in case the applicable rule is ()).
In the first case evaluation stops in the present subterm,
whereas in the second case the simulating evaluation can continue (after applying ()), 
possibly in parallel, from any immediate subterm of one of the recently uncurried applications.
The rules:\label{def:losim:TRS:ltermreps}
have to be extended with appropriate rules for  that implement capture-avoiding substitution,
which induce a rewrite relation . 
We do not provide those rules here, because the rewrite system above only serves us as a stepping stone
for a similar rewrite system in Section~\ref{sec:lo-simulation:lTRSs}
that operates on supercombinator representations of \lambdaterms\ (\lTRSs)
where substitution can be organized as context-filling.



Based on the simulation \TRS, we denote by  the rewrite relation that is induced by the rule scheme () for .
It defines steps that initiate the simulation of a \betareduction\ step which then proceeds with  steps 
  that carry out the substitution in the contraction of the \betaredex.
By , , , and 
we designate the rewrite relations that are induced by the rules
, , , and  for some , respectively.
By  we denote the union of , , , and ,
because they organize the search 
for the next \loredex\ or of an outermost redex. Finally, we denote by  the rewrite relation that is induced by the entire TRS.



The labels for  and  are motivated as follows:
In a  step the representation of a \loredex\ is contracted,
or the representation of a `stacked' outermost redex that is \lo\ below a stable
part of the term (and  that is bound to become
a \loredex\ at some later stage, at least if the term has a normal form). 
And a  step is part of the search in the term 
for the representation of the next \loredex\ or of an outermost redex
that is bound to become a \loredex\ later.
 


  
  
  
  
\begin{example}\label{ex:lopsimred:ltermrep}
  We consider the \lambdaterm\
  .
  Evaluating  with the \lo\ rewrite strategy, symbolized by the rewrite relation , gives rise to the rewrite sequence:

where the underlinings symbolize the \betaredex{es} that are contracted in the next step. 
The term:
                           
  denotes , that is, ; other variable names are possible modulo `\alphaconversion'.                    
  Simulating this \lo\ rewrite sequence by means of the simulation TRS above
        
Note that the  steps indeed initiate, and the  steps complete,
  the simulation of corresponding \betareduction\ steps in the  rewrite sequence on \lambdaterms\ above,
  while the other steps organize the search for the next (\lambdaterm\ representation of a) \lo\ \betaredex.
  The  rewrite sequence \eqref{rewseq1:ex:lopsimred:ltermrep}
  can be viewed as the projection of the  rewrite sequence above
  under an extension of the denotation operation  on \lambdaterm\ representations yielding \lambdaterms\
  (which works out substitutions, and interprets uncurried application expressions  appropriately).
  Hereby  steps project to  steps,
  but all other steps vanish under the projection.
\end{example}

While the \TRS\ above facilitates the faithful representation of \lo\ rewrite sequences on \lambdaterms\
(which can be formulated formally analogous to Proposition~\ref{prop:lifting:lobeta:lo-losim:rewseqs}, see page~\pageref{lem:lifting}),
it does not lend itself well to the purpose of proving the linear-depth-increase result.
This is because it is not readily clear which invariant for reducts  of a term  
in rewrite sequences 
could make it possible to prove that the depth increase in the final step of  is bounded by a constant  that only depends on the initial term  of the sequence (but not on ).
In the next section, however, we develop a concept that can overcome this problem.
We define extensions of first-order \lambdaterm\ representations
in which the abstraction parts of representations of \lo\ \betaredex{es} 
are built up from contexts that trace back to contexts in the initial term of the rewrite sequence.
This will guarantee that after a \lo\ \betareduction\ rewrite sequence 
a scope part of the abstraction part  of the next \lo\ \betaredex\  in  
does already occur in . 










\section{\protect\lTRS\ representations of lambda terms}
  \label{sec:lTRSs}


We now introduce \lTRS{s} as orthogonal \TRSs\ that are able to represent \lambdaterms.
The basic idea is that, for a \lambdaterm~, function symbols that are called `scope symbols'
are used to represent abstraction scopes.
Hereby the scope of an abstraction  in  
includes the abstraction  and all occurrences of the bound variable , but may leave room
for subterms in  without occurrences of  bound by the abstraction.
For example, the \lambdaterm~
may be denoted as the term 
where the binary scope symbol  represents the scope context .
In our formalization of \lambdaterm\ representations the free variables  and 
will be replaced by variable constants, yielding for example the term  .
Furthermore, scopes are assumed to be strictly nested.
Every scope symbol defines a rewrite rule that governs the behavior of the application of the scope to an argument.
In the case of the \lambdaterm~
this leads to the first-order rewrite rule 

for the scope symbol  that corresponds to the \lambdaterm\ scope context .
Such a translation facilitates a correspondence between \betareduction\ steps in the \lambdacalculus,
and first-order term rewriting steps on terms with adequately defined scope symbols. In the example here the correspondence is between the steps: 

provided that the \lTRS\nb-term  represents the \lambdaterm~.

\lTRSs\ are \TRSrepresentation{s} of systems of supercombinators that are obtained by the \lambdalifting\ transformation.
I have been introduced to these \lambdaterm\ representations by orthogonal \TRSs\ by Vincent van Oostrom
(personal communication, in the framework of the NWO-research project `Realising Optimal Sharing',
 and our collaboration on `nested term graphs'~\cite{grab:oost:2015}). 
He strongly shaped my understanding of them, and pointed me to the studies of optimal reduction for weak \betareduction\ 
(\betareduction\ outside of abstractions or in `maximal free' subexpressions)
by Blanc, L\'{e}vy, and Maranget \cite{blan:levy:mara:2005}.
Also, he encouraged work by Balabonski~\cite{bala:2012} on characterizations of optimal-sharing implementations for weak \betareduction\ 
by term labelings.
Later I discovered the direct connection with `fully-lazy \lambdalifting',
which was introduced in the early 1980-ies by Hughes \cite{hugh:1982:report,hugh:1982}. 


\begin{definition}[\lTRS{s}]\label{def:lTRS}
  A \emph{\lTRS}  
  is a pair~, 
  where  is a signature containing the binary application symbol~,
  and the \emph{scope symbols} in ,
  and where 
  consists of the \emph{defining rules}  for scope symbols  with arity~
  that are of the form: 
  
  with  a \nb-ary context of  
  that is called the \emph{scope context} for .
  For scope symbols  
  we say that  \emph{depends on} the scope symbol ,
  denoted by ,
if  occurs in the scope context  for .
We say that  is \emph{finitely nested} 
  if the converse relation of , the \emph{nested-into} relation , is well-founded,
  or equivalently (using the axiom of dependent choice),
  if there is no infinite chain of the form
  
  on scope symbols .  
\end{definition}

\begin{example}\label{ex:lTRS}
  Let  be the \lTRS\ 
  with ,
  where , , and ,
and the following set  of rules:
  \begin{center}
    
  \end{center}  
This finite \lTRS\
  is also finitely nested, as the depends-on relation consists only of a single link: .  
  It facilitates to denote the \lambdaterm~ in Example~\ref{ex:lopsimred:ltermrep},
  see the expansion of  in Example~\ref{ex:lTRS:expred} below. 
\end{example}  


In order to explain how \lTRS\ terms denote \lambdaterm\ representations, we introduce, for every \lTRS~, 
an expansion \TRS\ that makes use of the defining rules for the scope symbols in . 
Then `denoted \lambdaterm\ representations' will be defined as normal forms of terms in the expansion \TRS.
It uses function symbols~ with parameters  
for expanding a \lTRS\ term in a top--down manner.
Thereby the indices  are used to guarantee that when an abstraction  is created 
the indexed variable name  is different from that of all abstractions  that have been created above it. 
In this way the arising \lambdaterm\ representation will be uniquely named at vertical positions. 


\begin{definition}[expansion \TRS\ for a \lTRS]\label{def:expandTRS}
  Let  be a \lTRS. 
  The \emph{expansion \TRS~ for }
  has the signature 
  with 
  where  is unary for , and ,
  and its set of rules  consists of the rules:
  \begin{center}
  \afoscopecxt\afoscopesym
  \end{center}
  By  we denote the rewrite relation of .
\end{definition}


\begin{lemma}\label{lem:expTRS:orthogonal:UN}
  The expansion \TRS~ 
  of a \lTRS~  
  is an orthogonal TRS.
  Hence its rewrite relation  is confluent,
  and normal forms of terms, whenever they exist, are unique.
\end{lemma}



Since expansion~\TRSs\ are orthogonal \TRSs, finite or infinite normal forms are unique.
Furthermore they are constructor~\TRSs, i.e.\ they have rules whose right-hand sides are guarded by constructors.
This can be used to show that all terms in an expansion~\TRS\ rewrite to a unique finite or infinite normal form.  






\begin{definition}[\lambdaterm\ representations denoted by \protect\lTRS\nb-terms]
  Let  be a \lTRS. 
  For a term  we denote by  
  the finite or infinite \nb-normal form of the term  in .
  If it is a \lambdaterm\ representation, we say that
   is the \emph{denoted \lambdaterm\ representation} of ,
  and write  for the \lambdaterm~.
\end{definition}

\begin{example}\label{ex:lTRS:expred}
  With the \lTRS~ from Example~\ref{ex:lTRS}
  the \lambdaterm~ in Example~\ref{ex:lopsimred:ltermrep} can be denoted
  as the term  expands 
  to a \lambdaterm\ representation of 
  (the final  step consists of two parallel  steps):

Hence
    .                         
  This \lambdaterm\ representation coincides with the term  in Example~\ref{ex:lopsimred:ltermrep}
  `modulo \alphaconversion',
  and furthermore, for the denoted \lambdaterm\ it holds that
  .
\end{example}


\begin{proposition}\label{prop:lTRS-term:fin:nested:defines:lterrep}
  Let  be a finitely nested \lTRS. 
  Then for every ground term  of , 
   is a finite ground term over , hence a \lambdaterm\ representation
  of the \lambdaterm\ .
\end{proposition}
 

For proving termination and finiteness of the expansion process for terms and contexts in finitely nested \lTRSs,
we now define two measures: the `nesting depth' of scope symbols, and the `expansion size' of terms and of contexts.

\begin{definition}[nesting depth of a scope symbol, maximal nesting depth of contexts and terms]
  Let  be a finitely nested \lTRS.   
  
  We define \emph{the nesting depth } of a scope symbol 
  by means of \wellfounded\ induction on , the converse of the nested-into relation , as follows:
  
  Note that  is well-founded, since  is finitely nested. 
  Furthermore the maximum in this clause is always taken over a finite set,
  because  
  means that  occurs in the scope context  of , which is finite. 
 
  By the \emph{maximal nesting depth } of an \nary{n} context ,  
  we mean the maximal nesting depth of a scope symbol that occurs in .
  Similarly, by the \emph{maximal nesting depth } of a term   
  we mean the maximal nesting depth of a scope symbol that occurs in .
\end{definition}





Next we introduce the `expansion size' of ground contexts (and thereby also of ground terms) over the signatures of an \lTRS~, and the \lambdaterm\ representations.
We define it in such a way that the expansion size of a context  can later be recognized as the size of a normal form of 
in the expansion TRS~ when context holes, and remaining symbols  are not counted.
First, however,
we will need this measure to show that every term  has a normal form in  at all.


\begin{definition}[expansion size]
  Let  be a finitely nested \lTRS.
We define the \emph{expansion size~} of contexts 
  by induction on the structure of , thereby distinguishing the five possible cases of outermost symbols:  
  -0.5ex]
    \expsize{ \afoscope{\acxti{1},\ldots,\acxti{k}} } 
      & \;\defdby\;
        1 + \expsize{ \afoscopecxtap{\holei{1},\ldots,\holei{k},\afovari{0}} }  
          + \sum_{i=1}^{k} 
              \expsize{\acxti{i}}
        & & \parbox{\widthof{(scope context for  in ,)}}
                   {(where  is the
                    \-0.5ex]
    \expsize{ \folabs{\afovari{j}}{\acxti{0}} }   
      & \;\defdby\;
        1 + \expsize{ \acxti{0} } 
    \\
    \expsize{ \afovari{j} }
      & \;\defdby\;
        1 
        & & \text{(for all )}  
    \\
    \expsize{\holei{j}}
      & \;\defdby\;
        0
        & & \text{(for all )} \punc{.}
  
    \exprednfi{i}{\acxt} \: & \defdby\: \exprednf{\expandi{i}{\acxt}} \punc{,}
      &
    \exprednfi{i}{\ater} & \:\defdby\: \exprednf{\expandi{i}{\ater}} \punc{,}
  \label{eq:lem:expanded:form:cxts}
    \begin{split}
      \exprednfi{i}{\acxt}
        \: & \syntequal\:
      \bcxtap{\expandi{i_1}{\holei{j_1}},\ldots,\expandi{i_m}{\holei{j_m}}}  
      \\
        \: & \syntequal\:
      \bcxtap{\exprednfi{i_1}{\holei{j_1}},\ldots,\exprednfi{i_m}{\holei{j_m}}}  
    \end{split}
  \label{eq:lem:expanded:form:cxtap}
    \exprednfi{i}{ \acxtap{ \acxti{1},\ldots,\acxti{n} } }
      \:\syntequal\:
    \bcxtap{ \exprednfi{i_1}{\acxti{j_1}}, \ldots, \exprednfi{i_m}{\acxti{j_m}} } 
  \expandi{i}{\acxt}
      \:\expmred\;
    \bcxtap{\expandi{i_1}{\holei{j_1}},\ldots,\expandi{i_m}{\holei{j_m}}} \punc{.}
  
    \expandi{i}{\acxtap{\acxti{1},\ldots,\acxti{n}}}
      \: & \expmred\;
    \bcxtap{\expandi{i_1}{\acxti{j_1}},\ldots,\expandi{i_m}{\acxti{j_m}}}
    \\
      \: & \expmred\;
    \bcxtap{\exprednfi{i_1}{\acxti{j_1}},\ldots,\exprednfi{i_m}{\acxti{j_m}}} \punc{,}
  {3}
    \lopstart{\avar}
      \; & \sred \;
    \lopni{0}{0}{\avar}    
      \tag*{}
    \\
    \lopni{n}{i}{\folapp{\avari{1}}{\avari{2}},\bvari{1},\ldots,\bvari{n}}
      \; & \sred \;
    \lopni{n+1}{i}{\avari{1},\avari{2},\bvari{1},\ldots,\bvari{n}}  
      \tag*{}
    \displaybreak[0]\\
    \lopni{0}{i}{\afoscope{\avari{1},\ldots,\avari{k}}}
      \; & \sred \;
    \folabs{\afovari{i}}{\lopni{0}{i+1}{\afoscopecxtap{\avari{1},\ldots,\avari{k},\afovari{i}}}}
      \tag*{}
    \displaybreak[0]\\
    \lopni{n+1}{i}{\afoscope{\avari{1},\ldots,\avari{k}},\bvari{1},\bvari{2},\ldots,\bvari{n+1}}
      \; & \sred \;              
    \lopni{n}{i}{\afoscopecxtap{\avari{1},\ldots,\avari{k},\bvari{1}},\bvari{2},\ldots,\bvari{n+1}} 
     \tag*{}
    \displaybreak[0]\\  
\lopni{0}{i}{\afovari{j}}
      \; & \sred \;
    \afovari{j}
      \tag*{}
    \displaybreak[0]\\
    \lopni{n+1}{i}{\afovari{j},\bvari{1},\ldots,\bvari{n+1}}
      \; & \sred \;
    \folapp{\ldots{\folapp{\afovari{j}}{\lopni{0}{i}{\bvari{1}}}}\ldots}
           {\lopni{0}{i}{\bvari{n+1}}}
      \tag*{}
{2}
    \lopstart{\afoscope{\bfoscopesym,\cfoscopesym}}
     & \;\,\initred\;\;\: & & 
       \lopni{0}{0}{\afoscope{\bfoscopesym,\cfoscopesym}}
     \\
     & \;\,\descendinfolabsred\;\;\: & &
       \folabs{\afovari{0}}{\lopni{0}{1}{\folapp{\bfoscopesym}{\folapp{\cfoscopesym}{\afovari{0}}}}}
     \displaybreak[0]\\
     & \;\,\descendinfolappred\;\;\: & &
       \folabs{\afovari{0}}{\lopni{1}{1}{\bfoscopesym,\folapp{\cfoscopesym}{\afovari{0}}}}
     \displaybreak[0]\\
     & \;\,\contractred\;\;\: & &
       \folabs{\afovari{0}}{\lopni{0}{1}{\folapp{\cfoscopesym}{\afovari{0}}}}
     \displaybreak[0]\\
     & \;\,\descendinfolappred\;\;\: & &
       \folabs{\afovari{0}}{\lopni{1}{1}{\cfoscopesym,\afovari{0}}}
     \displaybreak[0]\\
     & \;\,\contractred\;\;\: & &
       \folabs{\afovari{0}}{\lopni{0}{1}{\dfoscope{\afovari{0}}}}
     \displaybreak[0]\\
     & \;\,\descendinfolabsred\;\;\: & &
       \folabs{\afovari{0}}{\folabs{\afovari{1}}{\lopni{0}{1}{\folapp{\afovari{1}}{\afovari{0}}}}}
     \displaybreak[0]\\
     & \;\,\descendinfolappred\;\;\: & &
       \folabs{\afovari{0}}{\folabs{\afovari{1}}{\lopni{1}{2}{\afovari{1},\afovari{0}}}}
     \displaybreak[0]\\
     & \;\,\varnred{1}\;\;\: & &
       \folabs{\afovari{0}}{\folabs{\afovari{1}}{\folapp{\afovari{1}}{\lopni{0}{2}{\afovari{0}}}}}
     \displaybreak[0]\\
     & \;\,\varnred{0}\;\;\: & &
       \folabs{\afovari{0}}{\folabs{\afovari{1}}{\folapp{\afovari{1}}{\afovari{0}}}}
      
\expandi{i}{\lopstart{\avar}}
      & \;\red\;
    \expandi{i}{\avar}
    \\
    \expandi{i}{\lopni{0}{j}{\avar}}
      & \;\red\;  
\expandi{i'}{\avar}
    & & \text{for } 
    \\
    \expandi{i}{\lopni{n+1}{j}{\avar,\bvari{1},\ldots\bvari{n+1}}} 
    & \;\red\;
    \expandi{i'}{\folapp{\cdots\folapp{\avar}{\bvari{1}}\ldots}{\bvari{n+1}}}
& & \text{for } 
  
    \expdepth{\bter} 
      & {} \,\defdby\,
    \depthnotexp{ \exprednfi{0}{\bter} } \in\nat\cup\setexp{\infty} \punc{,}
    & 
    \expdepth{\acxt} 
      & {} \,\defdby\,
    \depthnotexp{ \exprednfi{0}{\acxt} } \in\nat\cup\setexp{\infty} \punc{,}
    \\
    & & 
    \expholedepth{\acxt} 
      & {} \,\defdby\,
    \holedepthnotexp{ \exprednfi{0}{\acxt} } \in\nat\cup\setexp{\infty} \punc{,}
  {2}
    \expdepth{\avar} & = 0 
      & & (\avar\text{\nf\ variable in })
    \\  
\expdepth{\holei{i}} & = 0
      & & (i\in\nat)
    \\
\expdepth{\folapp{\acxti{1}}{\acxti{2}}} 
      & = 
    1 + \max \setexp{ \expdepth{\acxti{1}}, \expdepth{\acxti{2}} }
    \displaybreak[0]\\
\expdepth{\afoscope{\acxti{1},\ldots,\acxti{k}}}
      & = 
    1 + \expdepth{ \afoscopecxtap{\acxti{1},\ldots,\acxti{k},\afovari{0}} }
    \displaybreak[0]\\
\expdepth{\afovari{j}} 
      & = 
    0
      & & (j\in\nat)
    \displaybreak[0]\\
\expdepth{\folabs{\afovari{j}}{\bter}}
      & = 
    1 + \expdepth{\bter}
    \displaybreak[0]\\
\expdepth{\lopstart{\acxt}}
      & = 
    \expdepth{\acxt}  
    \displaybreak[0]\\
\expdepth{\lopni{n}{i}{\acxti{0},\acxti{1},\ldots,\acxti{n}}}
& =   
    \expdepth{\folapp{\cdots\folapp{\acxti{0}}{\acxti{1}}\ldots}{\acxti{n}}}   
  
    \expdepth{ \folapp{\acxti{1}}{\acxti{2}} }
      & {} =
    \depthnotexp{ \exprednfi{0}{ \folapp{\acxti{1}}{\acxti{2}} } }
      =
    \depthnotexp{ \exprednf{(\expandi{0}{ \folapp{\acxti{1}}{\acxti{2}} })} }
    \\
      & {} =
    \depthnotexp{ \exprednf{(\folapp{ \expandi{0}{\acxti{1}} }{ \expandi{0}{\acxti{2}} })} }
    \displaybreak[0]\\
      & {} =
    \depthnotexp{ \folapp{ \exprednf{\expandi{0}{\acxti{1}}} }{ \exprednf{\expandi{0}{\acxti{2}}} }}
           =
    \depthnotexp{ \folapp{ \exprednfi{0}{\acxti{1}} }{ \exprednfi{0}{\acxti{2}} } }
    \\
      & {} =
    1 + \max \bigl\{ \depthnotexp{\exprednfi{0}{\acxti{1}}}, \depthnotexp{\exprednfi{0}{\acxti{1}}} \bigr\}
      =
    1 + \max \bigl\{ \expdepth{\acxti{1}}, \expdepth{\acxti{2}} \bigr\} \punc{.} 
  
    \expdepth{ \afoscope{\acxti{1},\ldots,\acxti{k}} }
      & {} =
    \depthnotexpbig{ \exprednfbigi{0}{ \afoscope{\acxti{1},\ldots,\acxti{k}} } }
      =
    \depthnotexpbig{ \exprednf{(\expandi{0}{ \afoscope{\acxti{1},\ldots,\acxti{k}} })} }
    \\ 
      & {} =
    \depthnotexpbig{ \exprednf{(\folabs{\afovari{0}}{ \expandi{1}{ (\afoscopecxtap{\acxti{1},\ldots,\acxti{k},\afovari{0}}) } })} } 
      & & \hspace*{-20ex} \text{(using the step here)}
    \displaybreak[0]\\
      & {} =
    \depthnotexpbig{ \folabs{\afovari{0}}{ \exprednf{( \expandi{1}{ (\afoscopecxtap{\acxti{1},\ldots,\acxti{k},\afovari{0}}) } )} } } 
    \displaybreak[0]\\
      & {} = 
    \depthnotexpbig{ \folabs{\afovari{0}}{ \exprednfbigi{1}{ (\afoscopecxtap{\acxti{1},\ldots,\acxti{k},\afovari{0}}) } } }  
    \displaybreak[0]\\
      & {} =
    \depthnotexpbig{ \folabs{\afovari{0}}{ \exprednfbigi{0}{ (\afoscopecxtap{\acxti{1},\ldots,\acxti{k},\afovari{0}}) } } }   
      & & \hspace*{-20ex} \text{(by using Lemma~\ref{lem:expanded:form:terms:cxts:difference})}
    \\
      & {} =
    1 + \depthnotexpbig{ \exprednfbigi{0}{ (\afoscopecxtap{\acxti{1},\ldots,\acxti{k},\afovari{0}}) } } 
      = 
    1 + \expdepth{ \afoscopecxtap{\acxti{1},\ldots,\acxti{k},\afovari{0}} }  \punc{,}
  
    \exprednfi{0}{ \acxt }
      & \:\syntequal\:
    \bcxtap{ \exprednfi{i_1}{\holei{j_1}}, \ldots, \exprednfi{i_m}{\holei{j_m} } } \punc{,}
      \label{eq:1:prf:lem:expholedepth:vs:expdepth}
    \\
    \exprednfi{0}{ \acxtap{\ateri{1},\ldots,\ateri{n},\hole} }
      & \:\syntequal\:
    \bcxtap{ \exprednfi{i_1}{\ccxti{j_1}}, \ldots, \exprednfi{i_m}{\ccxti{j_m} } } \punc{,}
      \label{eq:2:prf:lem:expholedepth:vs:expdepth}
    \\
    \text{where }
      & 
      \ccxti{i} \defdby \begin{cases}
                          \ateri{i} & \text{ if } 
                          \\
                          \hole    & \text{ if } 
                        \end{cases}
                        \hspace*{1ex} \in\contextsnover{1}{\asig\cup\asiglambda}\punc{,}\text{ for .}
      \notag
  
    \expholedepthbig{ \acxtap{\ateri{1},\ldots,\ateri{n},\hole}}
      \: & = \:
    \holedepthnotexpbig{ \exprednfi{0}{ \acxtap{\ateri{1},\ldots,\ateri{n},\hole} } }
      & & \text{(by def.\ of )}
    \\
      & = \:
    \holedepthnotexpbig{ \bcxtap{ \exprednfi{i_1}{\ccxti{j_1}}, \ldots, \exprednfi{i_m}{\ccxti{j_m} } } }      
      & & \text{(by \eqref{eq:2:prf:lem:expholedepth:vs:expdepth})} 
    \displaybreak[0]\-0.35ex]
      & =
    \depthnotexpbig{ \bcxtap{ \expandi{i_1}{\holei{j_1}}, \ldots, \expandi{i_m}{\holei{j_m} } } }
      & & \text{(by def. of )}      
    \displaybreak[0]\\
      & =
    \depthnotexpbig{ \bcxtap{ \exprednfi{i_1}{\holei{j_1}}, \ldots, \exprednfi{i_m}{\holei{j_m} } } }
      & & \text{(by def.\ of )}
    \displaybreak[0]\\
      & =
    \depthnotexpbig{ \exprednfi{0}{\acxt} }
      & & \text{(by \eqref{eq:1:prf:lem:expholedepth:vs:expdepth})} 
    \\
      & =
    \expdepth{ \acxt } 
      & & \text{(by def.\ of )} \punc{.}
  
    \exprednfi{0}{ \acxt }
      & \:\syntequal\:
    \bcxtap{ \exprednfi{i_1}{\holei{j_1}}, \ldots, \exprednfi{i_m}{\holei{j_m} } } \punc{,}
      \label{eq:1:lem:expdepth:cxtap:vs:expdepth:expholedepth}
    \\
    \exprednfi{0}{ \acxtap{\ater} }
      & \:\syntequal\:
    \bcxtap{ \exprednfi{i_1}{\ater}, \ldots, \exprednfi{i_m}{\ater} } \punc{.}
      \label{eq:2:lem:expdepth:cxtap:vs:expdepth:expholedepth}
  
    \expdepth{\acxt}
      =
    \depthnotexp{\exprednfi{0}{\acxt}}
      =
\depthnotexp{\bcxtap{ \expandi{i_1}{\holei{j_1}}, \ldots, \expandi{i_m}{\holei{j_m} } }}    
      =
    \depth{\bcxt} 
      =
    \depthnotexp{\bcxt} \punc{,}
      \label{eq:3:lem:expdepth:cxtap:vs:expdepth:expholedepth}
    \\
    \expholedepth{\acxt}
      =
    \holedepthnotexp{\exprednfi{0}{\acxt}}
      =
\holedepthnotexp{\bcxtap{ \expandi{i_1}{\holei{j_1}}, \ldots, \expandi{i_m}{\holei{j_m} } }}    
      =
    \holedepth{\bcxt} 
      =
    \holedepthnotexp{\bcxt} \punc{.}
      \label{eq:4:lem:expdepth:cxtap:vs:expdepth:expholedepth}  
  
    \expdepth{ \acxtap{\ater} }
       \: & = \:
     \depthnotexp{ \exprednfi{0}{\acxtap{\ater}} }
       & & \text{(by def.\ of )}
     \\
       & = \:
     \depthnotexp{ \bcxtap{ \exprednfi{i_1}{\ater}, \ldots, \exprednfi{i_m}{\ater}  } } 
       & & \text{(by \eqref{eq:2:lem:expdepth:cxtap:vs:expdepth:expholedepth})}   
     \displaybreak[0]\\
       & = \:
     \max \descsetexpbig{ \depthnotexp{\bcxt},\, \holedepthnotexp{\bcxt} + \depthnotexp{ \exprednfi{i_j}{\ater} } }   
                        { j\in\setexp{1,\ldots,n} }
       & & \parbox{\widthof{(by using a \nb-version}}
                 {(by using a \nb-version\\\phantom{(by} of Lemma~\ref{lem:depth:cxtap:vs:depth:holedepth})}        
     \displaybreak[0]\\
       & = \:
     \max \setexpbig{ \depthnotexp{\bcxt},\, \holedepthnotexp{\bcxt} + \expdepth{\ater} }
       & & \text{(by appeal to Lemma~\ref{lem:expanded:form:terms:cxts:difference})} 
     \displaybreak[0]\\
      & = \:
     \max \setexpbig{ \expdepth{\acxt},\, \expholedepth{\acxt} + \expdepth{\ater} }
       & & \text{(by \eqref{eq:3:lem:expdepth:cxtap:vs:expdepth:expholedepth}, and \eqref{eq:4:lem:expdepth:cxtap:vs:expdepth:expholedepth})} \punc{.}
  
    \expdepth{\ater} \;\le\; \expdepth{\bter} + d
      \;\; & \Longrightarrow\;\;
    \expdepthbig{\acxtap{\ater}}
      \;\le\;
    \expdepthbig{\acxtap{\bter}} + d \punc{,}
      \label{eq:1:lem:lifting:expdepth:le:in:cxt}
    \\
    \expdepth{\ater} \;=\; \expdepth{\bter}
      \;\; & \Longrightarrow\;\;
    \expdepthbig{\acxtap{\ater}}
      \;=\;
    \expdepthbig{\acxtap{\bter}} \punc{.}
      \label{eq:2:lem:lifting:expdepth:le:in:cxt}
  {2}
    \expdepth{\acxtap{\ater}}
      & \:=\: 
    \max \setexp{ \expdepth{\acxt},\, \expholedepth{\acxt} + \expdepth{\ater} } 
      & \qquad & \text{(by Lemma~\ref{lem:expdepth:cxtap:vs:expdepth:expholedepth})} 
    \\
      & \:\le\: 
    \max \setexp{ \expdepth{\acxt},\, \expholedepth{\acxt} + \expdepth{\bter} + d }
      & \qquad & \text{(using the assumption)}   
    \displaybreak[0]\\
      & \:\le\: 
    \max \setexp{ \expdepth{\acxt} + d,\, \expholedepth{\acxt} + \expdepth{\bter} + d }
      & \qquad & \text{(possibly increasing the maximum)}  
    \displaybreak[0]\\
      & \: = \: 
    \max \setexp{ \expdepth{\acxt},\, \expholedepth{\acxt} + \expdepth{\bter} } + d
      & \qquad & \text{(simplifying the maximum expression)}  
    \\ 
      & \:=\: 
    \expdepth{\acxtap{\bter}} + d 
      & & \text{(by Lemma~\ref{lem:expdepth:cxtap:vs:expdepth:expholedepth})} \punc{.}  
  \label{eq:lem:cxt:contract-step}
    \expdepth{ \acxtap{\ateri{1},\ldots,\ateri{k},\cter} }  
      \:\le\: 
    \max \setexp{ \expdepth{ \acxtap{\ateri{1},\ldots,\ateri{k},\hole} },\, 
                  \expdepth{\acxt} + \expdepth{\cter} }  \punc{.}   
  {2}
    &
    \expdepth{ \acxtap{\ateri{1},\ldots,\ateri{k},\cter} } 
    \  
  and have established the statement \eqref{eq:lem:cxt:contract-step}.
  If, on the other hand,  does not occurs in , then we argue:
      
  and have obtained \eqref{eq:lem:cxt:contract-step} again.
\end{proof}\pagebreak[4]




Now we can formulate, and prove, a crucial lemma (Lemma~\ref{lem:depth-increase:contract-step}). 
Its central statement is that the depth increase in a  step   
(with respect to a \lopsimTRS) at the root of a term
is bounded by the depth of the scope context of the scope symbol that is involved in the step.
See Figure~\ref{fig:depth:increase} for an illustration of the underlying intuition 
for the analogous case of a step according to the defining rule of a scope symbol.  
Then
we obtain a lemma (Lemma~\ref{lem:expdepth:lopsimred:steps}) concerning the depth increase in general  and  steps.

\begin{lemma}\label{lem:depth-increase:contract-step}
  Let  be a finitely nested \lTRS.
  Then for every scope symbol  with arity  and scope context ,
  and for all terms , and all , it holds:
  \begin{enumerate}[(i)]\setlength{\itemsep}{0ex}
    \item{}\label{it:1:lem:depth-increase:contract-step}
      
    \item{}\label{it:2:lem:depth-increase:contract-step}
      
  \end{enumerate}
\end{lemma}

\begin{proof}
  We let , , , and  be as assumed 
  in the lemma.
We establish statement~\eqref{it:1:lem:depth-increase:contract-step} as follows:
  
  
  For showing statement~\eqref{it:2:lem:depth-increase:contract-step} 
  we proceed by lifting the inequality in statement~\eqref{it:1:lem:depth-increase:contract-step} into a context
  by means of Lemma~\ref{lem:lifting:expdepth:le:in:cxt}.
  More precisely, we argue as follows by means of the inductive clauses in Lemma~\ref{lem:expdepth},
  and by appealing to Lemma~\ref{lem:lifting:expdepth:le:in:cxt} 
  for the context :
  
  In this way we have now also justified the inequality in statement~\eqref{it:2:lem:depth-increase:contract-step}.
\end{proof}





\begin{lemma}\label{lem:expdepth:lopsimred:steps}
  Let  be the \lopsimTRS\ 
  for a finitely nested \lTRS~.
  
  Then every  step in  preserves the expansion depth,
  and every  step increases the expansion depth by less that the expansion depth
  of the scope symbol  involved in the contraction. 
  More precisely, the following statements hold for all :
  \begin{enumerate}[(i)]\setlength{\itemsep}{0.5ex} \item{}\label{it:1:lem:expdepth:lopsimred:steps}
      If , then .
    \item{}\label{it:2:lem:expdepth:lopsimred:steps}
      If , then ,
      where  is the scope symbol involved in the step.   
\end{enumerate}
\end{lemma}

\begin{proof}
  We first reduce the proof obligation for both items of the lemma
  to statements that pertain to rewrite steps that take place at the root of the term . 
  This is because for non-root  and  steps  
  the corresponding property can be lifted into a rewriting context by using Lemma~\ref{lem:lifting:expdepth:le:in:cxt}.
For instance, consider a step  that does not take place at the root of . 
  As such it is of the form 
  for some \nontrivial\ unary context  and subterms  and  of  and , respectively,
  such that  is a root step. 
  Now under the assumption that \eqref{it:2:lem:expdepth:lopsimred:steps} holds for root  steps,
  we have . 
  Then by using equation \eqref{eq:1:lem:lifting:expdepth:le:in:cxt} in Lemma~\ref{lem:lifting:expdepth:le:in:cxt}
  we obtain the desired inequality as follows:
  
  For non-root  steps, preservation of expansion depth can be argued analogously
  by using equation \eqref{eq:2:lem:lifting:expdepth:le:in:cxt} in Lemma~\ref{lem:lifting:expdepth:le:in:cxt},
  under the assumption that root   steps preserve expansion depth.


  It remains to show that the statements in \eqref{it:1:lem:depth-increase:contract-step} and \eqref{it:2:lem:depth-increase:contract-step} 
  hold for root steps. 
  We start with showing this for item~\eqref{it:1:lem:depth-increase:contract-step},
  by inspecting the rules of the \lopsimTRS,
  and by using the clauses of expansion depth in Lemma~\ref{lem:expdepth}.
  The case of a root  step is straightforward. 
  Now we consider the case of a root  step, which is of the form: 
  
  for some .
  Here we easily conclude with the clauses for the expansion depth in Lemma~\ref{lem:expdepth}: 
  
  Next we consider a root  step. With some  it is of the form:
  
  Here we argue as follows by using clauses for the expansion depth in Lemma~\ref{lem:expdepth}:
  
  The case of a root  step is again easy,
  both according to the rule ,
  also according to the rule ,
  by using the clauses for , and for , respectively. 
  
  For showing the restriction of item~\eqref{it:2:lem:depth-increase:contract-step}
  to root steps, we consider a  steps at the root.
  Such a step is of the form:
  
  Then the desired expansion depth inequality 
  
  follows from Lemma~\ref{lem:depth-increase:contract-step},~\eqref{it:2:lem:depth-increase:contract-step}.
\end{proof}

By a direct application of this lemma we obtain our main result concerning
the depth increase of terms in  rewrite sequences.
 

\begin{theorem}\label{thm:main:lTRS}
  Let  be a finite, and finitely nested \lTRS,
  and let . Let  be a finite or infinite  rewrite sequence~ with initial term .
  Then  can be construed as a sequence of  and  steps: 
  \begin{center}
       
  \end{center}
and then the following statements hold for all  with  where  is the length of :
\begin{enumerate}[(i)]\setlength{\itemsep}{0ex}
    \item{}\label{it:1:thm:main:lTRS}
      ,
      and 
      
       if ,
      that is more verbally, the expansion depth remains the same in the  steps, and
      it increases by at most  in the  steps. 
    \item{}\label{it:2:thm:main:lTRS}  
      ,
      that is,
      the increase of the expansion depth along  is linear
      in the number of  steps performed, with  as multiplicative constant. 
  \end{enumerate}  
\end{theorem}





\begin{proof}
  Statement~\eqref{it:1:thm:main:lTRS} 
  follows directly from Lemma~\ref{lem:expdepth:lopsimred:steps},~\eqref{it:1:lem:expdepth:lopsimred:steps}, and \eqref{it:2:lem:expdepth:lopsimred:steps}. 
  Statement~\eqref{it:2:thm:main:lTRS} follows by adding up the uniform bound  
  on the expansion depth increase in the   steps of the rewrite sequence .    
\end{proof}



 
  





\section{Transfer to \lo\ 
         \nb-reduction in the \lambdacalculus}
  \label{sec:transfer:lambda-calculus}


In this section we sketch how the linear-depth-increase result can be transferred from simulating rewrite sequences on terms of the \lopsimTRS~
for a \lTRS~ to \lo\ \betareduction\ rewrite sequences on terms of the \lambdacalculus. 
We formulate correspondence statements via projection and lifting. In particular, we formulate statements about the projections of  steps to \betareduction\ steps on \lambdaterms,
where the projection takes place via expansion to expanded-form \lambdaterm\ representations,
and about the lifting of \lo\ \betareduction\ rewrite sequences to \lo\ rewrite sequences in \lopsimTRS{s},
where the lifting has to be defined via fully-lazy \lambdalifting. 
We do not prove these statements here, but we illustrate them by means of our running example. 
On the basis of such correspondences between rewrite sequences, the linear-depth-increase result for \lo\ \betareduction\ in the \lambdacalculus\
follows from the linear-depth-increase result for \lopsimTRS\ in Section~\ref{sec:depth:increase}. 



The first correspondence statement concerns the projection of  steps to  steps or empty steps on \lambdaterms\
with the property that \lo\  steps project to \lo\  steps. 


\begin{proposition}[Projection of  steps via ]
    \label{prop:projection}
  Let  be the \lopsimTRS\ for 
  a \lTRS~.
  Let 
  be a term in  such that  for a \lambdaterm~.
  
  Then the following statements hold concerning the projection of  steps via  
  to steps on \lambdaterms, for all :
  \begin{enumerate}[(i)]\setlength{\itemsep}{0ex} 
    \item
      If , then .
      That is, the projection of a  step via  is a trivial step.
    \item  
      If , then .
      That is, the projection of a  step via  is a  step.
    \item  
      If  is a \lo\ step, then  holds.
      That is, the projection of a \lo\  step via  is  steps.
  \end{enumerate}
\end{proposition}

A \emph{proof} of this statement can be obtained by defining the projection via the expansion rewrite relation ,
and in particular, via the reduction  to expanded forms, which yields \lambdaterm\ representations.
Then it can be shown that  steps do not change the expanded form, and that  steps
correspond to the contraction of \betaredex{es} on the represented \lambdaterms. 

\begin{example}
  We illustrate the projection of  rewrite sequences in a \lopsimTRS\ to  sequences in the \lambdacalculus\
  at our standard example.
  For this, we consider the \lambdaterm~
  from Example~\ref{ex:lopsimred:ltermrep}, and the \lTRS~
  with 
  as defined in Example~\ref{ex:lTRS}, for which  holds, 
  that is, the \lTRS\nb-term  represents the \lambdaterm~.  
  
  Then the leftmost (and \lo)  rewrite sequence in  from Example~\ref{ex:lopsimred} 
  projects to the \lo\  rewrite sequence in the \lambdacalculus\ from Example~\ref{ex:lopsimred:ltermrep}
  as follows, where we indicate the projection by writing the denoted \lambdaterms\ beneath 
  the corresponding \lambdaterm\ representations:
  \begin{center}
  
  \end{center}
  As in Example~\ref{ex:lopsimred:ltermrep} we have underlined redexes that are contracted in  steps.
  This parallelization of steps can help to recognize, for the latter ones quite directly,
  that projection takes place by taking the expanded form of the \lopsimTRS\ term, and interpreting that as a \lambdaterm\
  (modulo \alphaconversion).\label{ex:prop:projection}
\end{example}






The next lemma states that every \lo\ \betareduction\ step 
can be lifted to a sequence  of leftmost steps in a \lopsimTRS,
provided that  denotes , and  has been obtained by the simulation of a  rewrite sequence. 


\begin{lemma}[Lifting of  steps to  steps w.r.t.\ ]\label{lem:lifting}
  Let  be a \lTRS.
  Let  be a ground term 
  such that  for a \lambdaterm~.
  Furthermore let  
  with  for a \lambdaterm~
  be the final term of a \lo\ rewrite sequence .
  
  Then for a  step  
  with \lambdaterm~ as target
  there are terms  
  and a \lo\  rewrite sequence 
  
  whose projection via  amounts to the step ,
  and hence, , and .
\end{lemma}

We note that in the lemma `\lo' in `\lo\ rewrite sequence '
and `\lo\  rewrite sequence '
could both be replaced by `leftmost'. The reason is as follows. 
In a \lopsimTRS~ for a \lTRS~ 
it holds for all rewrite sequences  for a ground term  over the signature of 
and of \lambdaterm\ representations that  does not have occurrences of operation symbols  in nested positions
(but only at identical or parallel positions). 
From this it follows that all redexes of the \lopsimTRS\ in  are outermost,
and hence that all \lo\ steps from  in  arise by contracting leftmost redexes. 

We expect that Lemma~\ref{lem:lifting} can be proved in close analogy to the correctness statement for fully-lazy \lambdalifting.
In particular, it is possible to use the correspondence between weak \betareduction\ steps on \lambdaterms\
and combinator reduction steps on supercombinator representations obtained by fully-lazy \lambdalifting. 
The latter result was formulated and proved by Balabonski in \cite{bala:2012}.

Now by using Lemma~\ref{lem:lifting} in a proof by induction on the length of a  rewrite sequence 
the theorem below can be obtained. It justifies the use of \lopsimTRS{s} for the simulation of 
 rewrite sequences.

\begin{proposition}[Lifting of  to \lo\  rewrite sequences]\label{prop:lifting:lobeta:lo-losim:rewseqs}
  Let  be a \lTRS.
  Let  be a ground term with  for a \lambdaterm~.
  Then every  rewrite sequence:
  \begin{center}
     
  \end{center}
  of finite or infinite length  lifts via  to a \lo\  rewrite sequence: 

  with precisely   steps
  such that furthermore
   holds for all .
\end{proposition}

For the same reason as argued above for Lemma~\ref{lem:lifting}, the formulation
`\lo\  rewrite sequence' in this proposition could be replaced by `leftmost  rewrite sequence'.

Now by using the lifting of  rewrite sequences to  rewrite sequences
(Proposition~\ref{prop:lifting:lobeta:lo-losim:rewseqs}),
that \lambdaterm\ and \lambdaterm\ representation depths coincide (Proposition~\ref{prop:expdepth:lterrep:lter}),
and that the depth of an \lTRS\ that can represent a \lambdaterm~ is bounded by the depth of  (Lemma~\ref{lem:depth:losimTRS}),
the theorem above entails our main theorem,
the linear-depth-increase result for \lo\ \betareduction\ rewrite sequences.




\begin{theorem}[Linear depth increase in -rewrite sequences]\label{thm:main}
  Let  be a \lambdaterm.
  Then for every finite or infinite \lo\ rewrite sequence 
   
  from   with length 
  it holds:
  \begin{enumerate}[(i)]\setlength{\itemsep}{0ex}
    \item
      
      for all  with ,
      that is,
      the depth increase in each step of  is uniformly bounded by . 
    \item  
      ,
      and hence ,
      for all  with ,
      that is,
      the depth increase along  to the \nb-th reduct is linear in ,
      with  as multiplicative constant.
  \end{enumerate}
\end{theorem}





\section{Idea for a graph rewriting implementation}
  \label{sec:idea:graph:implementation}


The linear-depth-increase result suggests a directed-acyclic-graph implementation of \lo\ \betareduction\
that is based on the following idea.
It keeps subterms shared as much as possible, particularly in the search for the
representation of the next \lo\ redex.
Steps that are used in the search for the next \lo\ redex
do not perform any unsharing, but only use markers to organize the search, and to keep track of its progress.
All search steps together increase the size of the graph only by at most a constant multiple.
Then the number of search steps that are necessary for finding the next \lo\ redex is linear in the size of the current graph. 
Unsharing of the graph only takes place once the next (representation of the) \lo\ redex is found:
then the part of the graph between this redex and the root is unshared (copied),
and subsequently the (represented) redex is contracted. 

The idea is to develop a graph rewriting calculus  
such that its rewrite relation  implements
\lo\  rewrite sequences in the corresponding \lopsimTRS~.
We know from Proposition~\ref{prop:projection}
that those \lo\  rewrite sequences in turn implement
 rewrite sequences in the \lambdacalculus.
Starting from a \lambdaterm~,
a \lo\ \betareduction\ rewrite sequence from 
is thus first lifted to a  rewrite sequence 
from a \lambdaterm\ representation  of 
in an \lopsimTRS~ 
for a \lTRS~ with ,
and then to a  rewrite sequence from a directed-acyclic graph  that represents~:\vspace*{-1.5ex}
\begin{center}
  
\end{center}
(here we have shortened the subscripts in  steps)
where it holds for all :
\begin{center}
  
\end{center}
Here we have used the linear-depth-increase results Theorem~\ref{thm:main} for \lambdaterms, 
and Theorem~\ref{thm:main:lTRS} for \lambdaterm\ respresentations.  
Now it seems feasible to develop the graph rewrite calculus  in such a way
that the depth  of the (acyclic) graph representations  of the \lopsimTRS\ terms  
are bounded by a constant  multiplied with the depth of ,
and consequently also bounded by  multiplied with the \lambdadepth\ of , or the depth of :
\begin{center}
  i\in\setexp{0,1,\ldots,n}
\end{center}
The reason for the possible depth increase in the graph representations 
consists in the use of additional controle nodes for keeping track of the progress of \lo\ evaluation: 
links will be used in order to indicate positions to which the \lo\ evaluation needs to backtrack
after having reduced a subexpression to a normal form, or having detected that a subexpression is a normal form. 
The depth of the graphs  are well-defined because they are acylic. 

The idea for simulating a step 
consists in unsharing the graph representation  of  only 
between the graph's root and the representation of the \betaredex\ in the  step,
and then carrying out the representation of the  step that involves   
replacing the symbol  by a graph version of its scope context ,
together with adapting links accordingly. 
We can expect the size increase in the graph rewrite step  
to be bounded linearly in the depth  of , for the first part,
and to be bounded by linearly the size , and hence the size  of ,
for the contraction part.   
That is, we want to guarantee that for all  it holds:
\begin{center}
  
\end{center}  
We may also assume that  is at the same time a multiplicative constant for bounding
the size of  by the sizes of  and :
\begin{center}
  
\end{center}  
On the basis of these assumptions a bound for the size of the \nb-th graph 
of the graph rewrite sequence can be calculated as follows:
\begin{center}
  
\end{center}
Now the time for computing the \nb-th rewrite step 
will consist of two parts: 
the time  for searching the occurrence of the representation of the \lo\ redex in ,
and the time  for performing the graph representation of the  step.
The search part  can be organized as a graph traversal of ,
and therefore can be expected to be performed in time that depends linearly on the size of .
The contraction part  consists of the necessary unsharing of the  between its root
and the represented \lo\ redex, and by performing the  step on the shared representation . 
The first subpart necessitates copying work of time that is linearly dependent on the depth  of .
The second subpart involves the addition of a graph context from  that corresponds to the scope context 
of the scope symbol  that is part of the  redex that is contracted; 
it therefore requires copying , and since  occurs already in ,
this can be expected to be work that depends linearly on the size of .
Together we obtain that for some  it holds: 
\begin{center}
  
\end{center}
From this we now obtain the following rough estimate of the time needed to implement 
the \lo\ rewrite sequence  
by the graph rewrite sequence , for some :
\begin{center}
  
\end{center}
This can yield a polynomial cost function for the work that is needed
to faithfully implement a \lo\ \betareduction\ rewrite sequence of length 
by `atomic' graph manipulation steps. 

An implementation of such graph rewriting representations of \lo\ \betareduction\ sequences,
broken down into the atomic steps of a port graph rewrite system \cite{stew:2002}, on a reasonable machine
could lead to an alternative proof of the invariance result of Accattoli and Dal Lago. 



\enlargethispage{6ex}
\paragraph{Acknowledgment.}
  This article is an extension of my not reviewed contribution~\cite{grab:2016:lindepthincrease:liber:alberti}
  to the Liber Alberti Festschrift on the occasion of the retirement of Albert Visser from Utrecht University in 2016. 
  I want to thank: 
  Vincent van Oostrom, for familiarizing me with \TRSrepresentation{s} of \lambdaterms,
  and with the simulation of weak- reduction by orthogonal \TRSs;
  Dimitri Hendriks, for comments on my drafts of \cite{grab:2016:lindepthincrease:liber:alberti},
  and for his questions about it that helped me;
  J\"{o}rg Endrullis, for help with typsetting Figure~\ref{fig:depth:increase} with TikZ;
  and Luca Aceto for detailed comments about the present version.


\bibliographystyle{plainnat}\bibliography{ldi-lobr}
\label{sec:biblio}


\end{document}