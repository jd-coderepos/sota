\documentclass{llncs}

\synctex=1

\usepackage{todonotes}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{wrapfig}


\usepackage[pdftex]{hyperref}

\usepackage[amsfonts]{logic-thm}


\pagestyle{plain}

\newcommand{\Sync}{\mathit{Sync}}
\newcommand{\CG}{\Cc\Gg}
\newcommand{\Aunc}{A_\mathit{unc}}
\newcommand{\rlp}{r_{l+1}}
\newcommand{\brlp}{\bar{\rlp}}
\newcommand{\cc}{\mathfrak{c}}
\newcommand{\ttest}{\mathit{test}}
\newcommand{\sskip}{\mathit{skip}}
\newcommand{\inctest}{\searrow}
\newcommand{\eqtest}{\downarrow}
\newcommand{\Tower}{\mathit{Tower}}
\newcommand{\state}{\mathit{state}}
\newcommand{\bd}{\bar{\d}}
\newcommand{\Spec}{\mathit{Spec}}
\newcommand{\loc}{\mathit{dom}}
\newcommand{\Plays}{\mathit{Plays}}
\newcommand{\view}{\mathit{view}}
\newcommand{\upa}{\uparrow}
\newcommand{\dar}{\downarrow}
\newcommand{\proj}[1]{_{|#1}}
\newcommand{\da}{\!\!\dar}
\newcommand{\Ssys}{\S^{sys}}
\newcommand{\Senv}{\S^{env}}
\newcommand{\bSsys}{{\bar{\S}^{sys}}}
\newcommand{\bSenv}{{\bar{\S}^{env}}}
\newcommand{\Qsys}{Q^{sys}}
\newcommand{\ES}{\mathit{ES}}
\newcommand{\st}{\mathit{state}}
\newcommand{\dom}{\mathit{dom}}
\newcommand{\bin}{\mathit{bin}}
\newcommand{\test}{\mathit{test}}
\newcommand{\edge}{-\!\!\!-\!\!\!-\!\!\!-\!\!\!-}
\newcommand{\ch}{\mathop{ch}}





\newenvironment{ignore}[1]{}

\renewenvironment{comment}[1]{}









 
\newcommand{\igw}[1]{}\newcommand{\anca}[1]{}\newcommand{\hugo}[1]{}

\renewenvironment{proof}{{\em Proof. }}{\nopagebreak
  \hspace*{\fill}}

\newenvironment{sproof}{{\em Sketch of Proof. }}{\nopagebreak
  \hspace*{\fill}}

\newcommand{\addbeg}{\color{blue}}
\newcommand{\addend}{\color{black}}
\newcommand{\added}[1]{\addbeg #1 \addend}

\begin{document}


\title{Asynchronous Games over Tree Architectures}


\author{Blaise Genest, Hugo Gimbert, Anca Muscholl,
  Igor Walukiewicz}

 \institute{ IRISA, CNRS, Rennes, France\\
 LaBRI, CNRS/Universit√© Bordeaux, France \\
   }

\maketitle

\begin{abstract}
 We consider the distributed control problem in the setting of
  Zielonka asynchronous automata. 
  Such automata are compositions of finite processes
  communicating via shared actions and evolving asynchronously. Most
  importantly, processes participating in a shared action can exchange
  complete information about their causal past. This gives more power
  to controllers, and avoids simple pathological undecidable cases as
  in the setting of Pnueli
  and Rosner.
  We show the decidability of the control problem for
  Zielonka automata over acyclic communication architectures.  We
  provide also a matching lower bound, which is -fold exponential,
   being the height of the architecture tree.
\end{abstract}


\section{Introduction}\label{sec:intro}
Synthesis is by now well understood in the case of sequential systems.
It is useful for constructing small, yet safe, critical modules.
Initially, the {\em synthesis problem} was stated by Church, who asked
for an algorithm to construct devices transforming sequences of input
bits into sequences of output bits in a way required by a
specification~\cite{church62}. Later Ramadge and Wonham proposed the
{\em supervisory control} formulation, where a plant and a
specification are given, and a controller should be designed such that
its product with the plant satisfies the specification~\cite{RW89}. So
control means restricting the behavior of the plant. Synthesis is the
particular case of control where the plant allows for every possible
behavior.

For synthesis of {\em distributed} systems, a common belief is that the
problem is in general undecidable, referring to work by Pnueli and
Rosner~\cite{PR90}. They extended Church's 
formulation to an architecture of {\em synchronously} communicating
processes, that exchange messages through one slot communication
channels. Undecidability in this setting comes mainly from~\emph{partial
information}: specifications permit to control the flow of information about the global state of the system. The only
decidable type of architectures is that of pipelines.




The setting we consider here is based on a by
now well-established model of distributed computation using
shared actions: \emph{Zielonka's asynchronous
  automata}~\cite{zie87}. Such a device is an asynchronous product of
finite-state processes synchronizing on common actions.  
Asynchronicity means that processes can progress at different speed. 
Similarly to~\cite{GLZ04,MTY05} 
we consider the control problem for such automata. 
Given a Zielonka automaton (plant), find another Zielonka automaton
(controller) such that the product of the two satisfies a given
specification. In particular, the controller does
not restrict the parallelism of the system.
Moreover, during synchronization the individual processes of the controller
can exchange all their 
information about the global state of the system. This gives more
power to the controller than in the Pnueli and Rosner model, thus
avoiding simple pathological scenarios leading to undecidability. 
It is still open whether the control problem for Zielonka automata is
decidable.  

In this paper we prove decidability of the control problem  for
reachability objectives on tree architectures. 
In such architectures every process can communicate with its parent,
its children, and with the environment. 
If a controller exists, our algorithm yields a controller that is a
finite state Zielonka automaton exchanging information of
\emph{bounded} size.  We also provide the first non-trivial lower bound for
asynchronous distributed control. It matches the -fold exponential
complexity of our algorithm ( being the height of the
architecture). 


As an example, our decidability result covers client-server
architectures where a server communicates with clients, and server and
clients have their own interactions with the environment
(cf. Figure~\ref{fig:server-client}). Our algorithm providing a
controller for this architecture runs in exponential time. Moreover,
each controller adds polynomially many bits to the state space of the
process.  Note also that this architecture is undecidable
for~\cite{PR90} (each process has inputs), and is not covered
by~\cite{GLZ04} (the action alphabet is not a co-graph), nor
by~\cite{MTY05} (there is no bound on the number of actions performed
concurrently).
\begin{figure}[b]
\centering
  \vspace{-0.7cm}
  \includegraphics[scale=.6]{server-client2.pdf}
\caption{Server/client architecture}
  \label{fig:server-client}
\end{figure}
\medskip

\noindent\textit{Related work.}
The setting proposed by Pnueli and Rosner~\cite{PR90} has been
thoroughly investigated in past years. 
By now we understand that, suitably using
the interplay 
between specifications and an architecture, one can get undecidability
results for most architectures rather easily. While
specifications leading to undecidability are very artificial, no
elegant solution to eliminate them exists at present.


The paper~\cite{kv01} gives an automata-theoretic approach to
solving pipeline architectures and at the same time extends the
decidability results to CTL specifications and variations of the
pipeline architecture, like one-way ring architectures. The synthesis
setting is investigated in~\cite{MadThiag01} for local
specifications, meaning that each process has its own, linear-time
specification. For such specifications, it is shown that an
architecture has a decidable synthesis problem if and only if it is a
sub-architecture of a pipeline with inputs at both endpoints.
The paper~\cite{FinSch05} proposes information forks as an uniform
notion explaining the (un)decidability results in distributed
synthesis. 
In~\cite{MeyWil05} the authors consider distributed synthesis for
knowledge-based 
specifications. The paper~\cite{GasSznZei09} studies an interesting case
of external specifications and well-connected architectures.

Synthesis for asynchronous systems has been strongly advocated by Pnueli
and Rosner in \cite{PR89icalp}. Their notion of asynchronicity
is not exactly the same as ours: it means roughly that system/environment
interaction is not
turn-based, and processes observe the system only when
scheduled.
 This notion of asynchronicity appears in
several subsequent works, such as~\cite{sf06,KatSchPel11} for distributed
synthesis.


 
As mentioned above, we do not know whether the control problem in our setting is
decidable in general. Two related decidability results are known, both
of different flavor that ours. The first one~\cite{GLZ04} restricts the alphabet of actions: control with reachability
condition is decidable for co-graph alphabets.  This restriction 
excludes among others client-server architectures.
The second result~\cite{MTY05} shows decidability by restricting the
plant: roughly speaking, the restriction says that every process
can have only bounded missing knowledge about the other processes (unless
they diverge). The proof
of~\cite{MTY05} goes beyond the controller synthesis problem, by
coding it into monadic second-order theory of event structures and
showing that this theory is decidable when the criterion on the plant
holds. Unfortunately, very simple plants have a  decidable control problem but
undecidable MSO-theory of the associated event structure.
Melli\`es~\cite{mel06} relates game semantics and asynchronous games, played
on event structures.
More recent 
work~\cite{cgw12} considers finite games on event structures
and shows a determinacy result for such games under some restrictions.


\medskip

 \noindent\textit{Organization of the paper.} 
 The next section presents basic definitions. 
 The two consecutive sections present the algorithm and the matching
 lower bound. 




\section{Basic definitions and observations}
Our control problem can be formulated in the same way as the Ramadge
and Wonham control problem but using Zielonka automata instead of
standard finite automata. We start by presenting Zielonka automata and
an associated notion of concurrency. Then we briefly recall the
Ramadge and Wonham formulation and our variant of it. Finally, we give
a more convenient game-based formulation of the problem.


\subsection{Zielonka automata}

Zielonka automata are simple parallel devices. Such an
automaton is a parallel
composition of several finite automata, denoted as~\emph{processes},
synchronizing on common actions. There is no global clock, so between
two synchronizations, two processes can do a different number of
actions. Because of this Zielonka automata are also called
asynchronous automata.

A \emph{distributed action alphabet} on a finite set  of processes is a
pair , where  is a finite set of \emph{actions} and
 is a \emph{location
  function}. The location  of action  comprises all
processes  that need to synchronize in order to perform this
action. 
A (deterministic) \emph{Zielonka automaton}
 is
given by 
\begin{itemize}
\item for every process  a finite set  of (local) states,
\item the initial state , 
\item for every action   a partial transition function
 on tuples of states of processes in
  . 
\end{itemize}

For convenience, we abbreviate a tuple  of local
states by  ,  where . We also talk about 
as the set of \emph{-states} and of  as
\emph{global states}. Actions from  are denoted as \emph{-actions}.

A Zielonka automaton can be seen as a sequential automaton with the
state set  and transitions  if
, and . By  we denote the set of
words labeling runs of this sequential automaton that start from the
initial state.


This definition has an important consequence. The location mapping
 defines in a natural way an independence relation : two
actions  are independent (written as ) if they
involve different processes, that is, if . Notice that the order of execution of two independent
actions  in a Zielonka automaton is irrelevant, they can
be executed as , or  - or even concurrently. More generally,
we can consider the congruence  on  generated by ,
and observe that whenever , the global state reached from
the initial state on  and , respectively, is the same. Hence,  if and only if . Notice also that if  and  involves no -action, then the -state
reached on  and , respectively, is the same.



The idea of describing concurrency by an independence relation on
actions goes back to the late seventies, to Mazurkiewicz~\cite{maz77}
and Keller~\cite{kel73} (see also ~\cite{DieRoz95}). An equivalence
class  of  is called a Mazurkiewicz \emph{trace}, it can be
also viewed as labeled pomset of a special kind. Here, we will often
refer to a trace using just a word  instead of writing .  As
we have observed  is a sum of such equivalence classes. In
other words it is \emph{trace-closed}.



\begin{example}
  Consider the following, very simple, example with processes
  . Process 1 has local actions  and synchronization
  actions  () shared with process 2. Similarly,
  process 3 has local actions  and synchronization actions
   () shared with process 2
(cf.~Figure~\ref{f:async} where the symbol  denotes any 
value 0 or 1).
Each process is a finite automaton and the Zielonka
automaton is the product of the three components synchronizing on
common actions. 
We have for instance  and . The final states are the rightmost states of each automaton. The
automaton accepts traces of the form  with
 or .
\begin{figure}[htbp]
\centering
\includegraphics[scale=.6]{example-aa-bis.pdf}
  \caption{A Zielonka automaton}
  \label{f:async}
\end{figure}
\end{example} 








Since the notion of a trace can be formulated without a reference to an
accepting device, it is natural to ask if the model of Zielonka
automata is powerful enough. Zielonka's theorem says that this is
indeed the case, hence these automata are a right model for
the simple view of concurrency captured by Mazurkiewicz traces. 



\begin{theorem}\cite{zie87}
  Let  be a distribution of
  letters. If a language  is regular and trace-closed then there is a
  deterministic Zielonka automaton accepting  (of size exponential
  in the number of processes and polynomial in the size of the minimal
  automaton for , see~\cite{ggmw10}). 
\end{theorem}

\medskip

One could try to use Zielonka's theorem directly to solve a
distributed control problem. For example, one can start with the
Ramadge and Wonham control problem, solve it, and if a solution happened to
respect the required independence, then distribute
it. Unfortunately, there is no reason for the solution to respect the
independence. Even worse, the following, relatively simple, result
says that it is algorithmically impossible to approximate a
regular language by a language respecting a given independence
relation.

\medskip

\begin{theorem}\cite{SEM03}
  It is not decidable if, given a distributed alphabet and a
  regular language , there is a trace-closed language
   such that every letter from  appears in some
  word of .
\end{theorem}

\medskip

The condition on appearance of letters above is not crucial for the
above undecidability result. Observe
that we need some condition in order to make the problem nontrivial,
since by definition the empty language is trace-closed.





\subsection{The control problem}

We can now formulate our control problem as a variant of the 
Ramadge and Wonham formulation. We will then provide an equivalent
description of the problem in terms of games. While more complicated
to state, this description is easier to work with. 

Recall that in Ramadge and Wonham's control problem~\cite{RW89} we are
given an alphabet  of actions partitioned into system and
environment actions: . Given a plant  we
are asked to find a controller  such that the product 
satisfies a given specification. Here both the plant and the
controller are finite deterministic automata over . Additionally,
the controller is required not to block environment actions, which in
technical terms means that from every state of the controller there
should be a transition on every action from . 


Our control problem can be formulated as follows: Given a distributed
alphabet  as above and a Zielonka automaton ,
find a Zielonka automaton  over the same distributed alphabet such
that  satisfies a given specification. Additionally
the controller is required not to block uncontrollable actions: from
every state of  every uncontrollable action  should be possible.
 The important point is
that the controller should have the same distributed structure as the
plant. The product of the two automata, that is just the standard
product, means that plant and controller are totally synchronized, in
particular communications between processes happen at the same
 time. 
Hence concurrency in the controlled system is the same as in
the plant. The major difference between the controlled system and the
plant is that the states carry the additional information computed by
the controller.

\begin{example}
  Reconsider the automaton in Figure~\ref{f:async} and assume that
   are uncontrollable. So the controller needs to
  propose controllable actions  and , resp., in such a way that all
  processes reach their final state. In particular, process 2 should
  not block. At first sight this may seem impossible to guarantee, as it
  looks like process  needs to know what  process  has
  received, or process  needs to know about the  received by
  process . Nevertheless, a controller exists. It consists of
   proposing  at state , process  proposing
   at state  and process  proposing all
  actions. If  then  reaches the final state by the
  transition , else by the transition .
\end{example}



It will be more convenient to work with a game formulation of this
problem. Instead of talking about controller we will talk about
distributed strategy in a game between \emph{system} and
\emph{environment}. A plant defines a game arena, with plays
corresponding to initial runs of . Since  is deterministic,
we can view a play as a word from  - or a trace, since
 is trace-closed.  Let
 denote the set of traces associated with words from
.

A strategy for the system will be a collection of individual
strategies for each process. The important notion here is the view 
each process has about the global state of the system. Intuitively this is
the part of the current play that the process could see or  learn
about from other processes during a communication with them. Formally,
the -view of a play , denoted , is the smallest
trace  such that  and  contains no action from
. We write  for the set of plays that are
-views:


A \emph{strategy for a process}  is a function
, where .  We require in addition, for every , that  is a subset of the actions that are
possible in the -state reached on . A \emph{strategy} is a
family of strategies , one for each process.

The set of plays respecting a strategy , denoted ,  is the smallest set  
containing the empty play , and such that for every :
\begin{enumerate}
\item if  and  then  is in
  ;
\item if  and  then  provided that  \emph{for all}
  .
\end{enumerate}
Intuitively, the definition says that actions of the environment are
always possible, whereas actions of the system are possible only if
they are allowed by the strategies of all involved processes.
As in \cite{MTY05} (and unlike \cite{GLZ04}) our strategies
are process-based. That is, a controllable action  with
 is allowed from  if it is proposed by
process  in state  and by process  in state .
Before
defining winning strategies, we need to introduce infinite plays that
are consistent with a given strategy . Such plays can be seen as
(infinite) traces associated with infinite, initial runs of 
satisfying the two conditions of the definition of
. We write  for the set of
finite or infinite such plays.  A play from  is
also denoted as~\emph{-play}.


A play  is called
\emph{maximal}, if there is no action  such that
.  In particular,  is maximal if
 is infinite for every process . Otherwise, if
 is finite then  cannot have enabled local actions
(either controllable or uncontrollable). Moreover there should be no
communication possible between any two processes with finite views in
.


In this paper we consider \emph{local reachability} winning
conditions. For this, every process has a set of target states . We assume that states in  are \emph{blocking},
that is they have no outgoing transitions. This means that if
 then  for all . 

\begin{definition}
The \emph{control problem} for a plant  and a local reachability
condition  is to determine if there is a strategy
 such that every maximal trace  ends 
in  (and is thus finite).  Such traces and
strategies are called \emph{winning}.
\end{definition}


As already mentioned, we do not know if this control problem is
decidable in general. In this paper we put one restriction on possible
communications between processes. First, we impose two
simplifying assumptions on the distributed alphabet . The 
first one is that all actions are at most binary: ,
for every . The second requires that all uncontrollable
actions are local: , for every . So the first restriction says that we allow only
binary synchronizations. It makes the technical reasoning much
simpler. The second restriction reflects the fact that each process is
modeled with its own, local environment.



\begin{definition}\label{df:com graph}
A distributed alphabet  with unary and binary actions
defines an undirected graph  with node set  and edges 
if there exists  with , . Such a
graph is called \emph{communication graph}. 
\end{definition}












\section{The upper bound for acyclic communication graphs}

We fix in this section a distributed alphabet
. According to Definition~\ref{df:com graph} the alphabet
determines a communication graph . We assume that  is
acyclic and has at least one edge. This allows us to choose a leaf  in , with  an edge in . Throughout this
section,  denotes this fixed leaf process and  its parent
process. Starting from a
control problem with input ,  we define below a
control problem over the smaller (acyclic) graph . The construction will be an exponential-time
reduction from the control problem over  to a control problem
over . If we represent  as a tree of depth  then
applying this construction iteratively we will get an -fold
exponential algorithm to solve the control problem for 
architecture.

The main idea of the reduction is simple: process  simulates
the behavior of process . The reason why a simulation can work is
that after each synchronization between  and , the views of both
processes are identical, and between two such synchronizations 
evolves locally. But the construction is more delicate than this
simple description suggests, and needs some preliminary considerations
about winning strategies.

We start with a lemma showing how to
restrict the winning strategies. 
For  let . So  is the set of
synchronization actions between  and . Moreover  is
just the set of local actions of . We write  instead of
 and . Recall that in
the lemma below  is the fixed leaf process, and  its
parent. 


 \begin{lemma}\label{l:separation}
  If there exists some winning strategy for , then there is one, say
  ,  such that for every   the
  following hold:
  \begin{enumerate}
  \item If an uncontrolable action is possible from a state  of
    process  then for every play  with  we have
    .
  \item For every process  and , we have either
     for some  or .
  \item Let  with . Then either
     or 
    holds.
  \end{enumerate}
\end{lemma}

\begin{proof}
  The first item is immediate, since uncontrollable actions are alwyas
  possible. For the second item we modify  into  as
  follows. If  contains some local action, then we choose
  one, say , and put . We do this for every
  process  and show that the resulting strategy  is
  winning. Suppose that  is maximal, but not
  winning. Clearly  is a -play, but not a maximal one, since
   is winning.  Thus, there is  for some
  processes  and some . By definition of
   it means that either  or
   contains some local action, say  and . But then  is
  a -play, a contradiction with the maximality of .

For the last item we can assume that  and  always
  propose either a local action or a set of communication actions. Now
  given a winning strategy  we will produce a winning strategy
   satisfying the condition of the lemma, by modifying only .

 Assume that  with , and
 , where  and 
 with both   non-empty.
 We define  by cases:
 
The idea behind the definition above is simple: if there is a possible
local future for  that makes synchronization with  impossible (first
case), then 's strategy can as well propose only communication with
other processes than  -- since such communication leads to winning
as well. If not, 's strategy can  offer only communication with ,
since this choice will never block.

We show now that  is winning.  Assume by contradiction that 
is a maximal -play, but not winning.  It is then a -play, but
not a maximal one. So there must be some  such that
.  In particular, 's state after  is not
final.  Let , , and 
with  and . We
have two cases.

Suppose , so we are in the first case of the above
above. Thus there exists  such that . By definition of  we find
 such that  is a -play and
. Since , we have
. This means that no communication between
 and  is possible after . No local action of  is possible
after  since , and we have assumed that  is a
maximal -play. Finally, by the choice of , no local action of
process  is possible from . To obtain a contradiction it
suffices to show that  can be extended to a maximal -play by
adding a sequence of actions  of processes other than  and
. This will do as  is not accepting by assumption,
and we will get a maximal -play that is not winning.  To find the
desired  observe that  where
 and . So 
represents the actions of  after the last action of   in ,
and  represents the actions of other processes.  Taking  we
observe that  and 
that  is a maximal -play. So we have found the desired .



The second case is when . This means that for all 
, we have 
. Since  is a maximal -play,
 no local action of  is possible. This means that
 . But then
 . Since  there is
 some  possible communication between
  and  after , so  is not maximal
 w.r.t.~.
\end{proof}

The following definition associates with a strategy  and the leaf
process  all the outcomes of local plays of  such that  is
either waiting for a synchronization with  or is in a final (hence
blocking) state.  For an initial run  of  we denote by
 the -state reached by  on .


 \begin{definition}\label{d:outcome}
Given a strategy  and a
-play , let  be the set:
   
 \end{definition}
Observe that if  allows  to reach a final state  from 
without communication, then . This is so,
since final states are assumed to be blocking.



For the game reduction we need to precalculate all possible sets
. These sets will be actually of the special form
described below. 


\begin{definition}
  Let  be a state of .  We say that  is an \emph{admissible plan in } if
  there is a play  with , and a strategy  such
  that (i) , (ii) every -play of  from 
  reaches a final state or a state where  proposes some communication
  action, and (iii) one of the following holds:
  \begin{itemize}
  \item  for every , or
    \item  and  for every .
  \end{itemize}
  In the second case  is called a \emph{final plan}.
\end{definition}


It is not difficult to see that we can compute the set of all
admissible plans. In the above definition we do not ask that  is
winning in the global game, but just that it can locally bring  to one
of the situations described by . So verifying if  is an
admisible plan simply amounts  to solve a 2-players reachability game on process
 against the (local) environment.

Lemma~\ref{l:rfuture} below allows to deduce that the sets 
are admissible plans whenever  is winning. For  with ,  let . So  contains all actions belonging to both  and ,
that are enabled in the state .



\begin{lemma}\label{l:rfuture}
  If  is a winning strategy 
  satisfying Lemma~\ref{l:separation} then for every -play  in  we have:
  \begin{enumerate}
  \item if there is some -play  with  and
      then  is a final plan;
  \item if there is some -play  with , , , and
     then for every  we have
    .
  \end{enumerate}
 In particular,   is always an admissible plan.
\end{lemma}

\begin{proof}
  Take  as in the statement of the lemma and suppose . Take . By definition this means
  that there is  such that  is a -play,
  , and  with . Observe that  is also a -play. Hence  should
  be final because after  process  can do at most
  communication with , but this is impossible since  is in a
  final state. Since  is final, it cannot propose an action,
  hence . This shows the first item of the lemma.

  For the second item of the lemma take , , , and  as in
  the assumption. Once again we get  such that
   is a -play, , and 
  with . Once again  is a -play. We have
  that  is not final since . As
   is winning, the play  can be extended by an action of
  . But the only such action that is possible is a communication
  between  and . Since  and  are the communication sets
  proposed by  and , respectively, we must
  have .
\end{proof}


\medskip
\textit{The new plant }.  We are now ready to define the reduced
plant  that is the result of eliminating process .  Let
.  We have  where the components will be
defined below.

The states of process  in  are of one of the following types:

where ,  is
an admissible plan, . The new initial state for  is
.


For every , we let  and . The local
winning condition for  becomes 
T.



The set of actions  is , plus
additional local -actions that we introduce below.
All transitions  with  are as in .
Regarding  we have the following transitions:
\begin{enumerate}
\item If not in a final state then process  chooses an admissible
  plan:
  
where  is an admissible plan in , and
  .

\item Local action of :

\item Synchronization between  and :

\item Synchronization between  and . Process  declares the
  communication actions with :
  
  when  is not final,   is not a final plan, and for every
   we have .




  Then the environment can choose the target state of  and a
  synchronization action :
  
  for every  such that  for some , and . Notice that the
complicated name of the action  is needed to ensure
that the transition is deterministic.

\end{enumerate}

To summarize the new actions of process  in plant  are:
\begin{itemize}
\item , for every admissible plan  ,
\item , for each ,
\item  for each
  .
\end{itemize}


The proof showing that this construction is correct provides a
translation from winning strategies in  to winning strategies in
, and back. To this purpose we rely on a
translation from plays in  to plays in . A (finite or
infinite) play  in  is a trace that will be convenient
to view as a word of the form

where for  we have that:  is communication between  and ;  is a sequence of local actions of ; and  is a sequence of actions of other processes than . Note that  are
concurrent, for each . We will write  for the prefix of
 ending in . Similarly  for the prefix ending with 
; analogously for .

Fix a strategy  in . With a word  as above we will associate the word

where for every :
\begin{itemize}
\item  and ;
\item ;
\item .
\end{itemize}
We then construct a strategy that plays  in  instead of
 in . In Figure~\ref{fig:chi} we have pictorially represented
which parts of  determine which parts of .

\begin{figure*}[tbhf]
  \centering
\begin{tikzpicture}[xscale=1.5]
  \draw (0,1)node{}
  ++(1.3,0)node(y0){} ++(1.2,0)node(x0){}
  ++(.5,0)node(a1){} ++(1.8,0)node(y1){}
  ++(1.3,0)node(x1){} ++(.6,0)node(a2){};
  \draw (0,0)node{} 
  ++(.8,0)node(T0){}
  ++(.5,0)node(y0p){} ++(.7,0)node(A0){}
  ++(1,0)node(a1t){} ++(.8,0)node(T1){}
  ++(1,0)node(y1p){}
  ++(.7,0)node(A1){}
   ++(1.2,0)node(a2t){}
   ++(1,0)node(T2){};
    \draw(y0)--(y0p);
    \draw(y0)--(A0);
    \draw(x0)--(a1t);
    \draw(a1)--(a1t);
    \draw(a1)--(T1);
   \draw(y1)--(y1p);
   \draw(y1)--(A1);
   \draw(x1)--(a2t);
   \draw(a2)--(a2t);
    \draw(a2)--(T2);
\end{tikzpicture}
  \caption{Definition of }
  \label{fig:chi}
\end{figure*}


The next lemma follows directly from the definition of the reduction
from  to .

\medskip

\begin{lemma}\label{lemma:states}
  If  ends in a letter from  then we have the following
  \begin{itemize}
  \item .
  \item  for every  and
    .
  \item  for every .
  \item  for every .
  \end{itemize}
\end{lemma}


\medskip
\noindent\textit{From  in  to  in .}
We are now ready to define  from a winning strategy . We
assume that  satisfies the property stated in
Lemma~\ref{l:separation}. We will define  only for certain plays and
then show that this is sufficient. 

Consider  such that  for some -play  ending in
a letter from . We have:
\begin{itemize}
\item If  then 
  where .
\item For every process  we put
   for .
\item For  and  we define
  
\item .
\end{itemize}
Observe that in the last case the strategy proposes no move as there
are only moves of the environment from a position reached on a play of
this form.

The next lemma states the correctness of the construction. 



 \begin{lemma}\label{lemma:sigma to sigma prim}
  If  is a winning strategy for  then 
  is a winning strategy for .
\end{lemma}



\begin{proof}
  We will show inductively that for every -play  ending 
  in a letter of the form  there is a -play
   such that . Then we will show that
  every maximal -play is winning.
  
  We start with the induction step, later we will explain how to
  do the induction base. Let us take  as in the induction
  hypothesis. By Lemma~\ref{lemma:states} we have
  .   

  Consider a possible, -compatible, extension of  till the next letter
  . It is of the form  where .  We will show that it is of the form
   for some ,
  and that  is a -play.
  \begin{itemize}
  \item By definition of the automaton  and the strategy 
    we have  with .
  \item Since  is the same as  on actions from , we get that  is a -play.

  \item Concerning , by the definition of  we have that
    . Then by the definition of  we get
    some  such that , and 
    with . As  we can find  such that  is a -play, 
    and . We get that  is a -play with
    , and we are done.
  \end{itemize}
The induction base is exactly the same as the induction step 
taking  and  to be the empty sequence. 

To finish the lemma we need to show that every maximal -play 
is winning. For this we examine all possible situations where
such a play can end. We consider plays  and  as at the
beginning of the lemma.

If  itself is maximal then  is final because
otherwise  would be possible. Hence, by
Lemma~\ref{lemma:states}  and  are
final. Since  and  are the same on processes other than 
and , no action  with  is possible
from . It follows that  is a maximal -play. Since  is
winning,  is final for every process . By
Lemma~\ref{lemma:states},  is winning too.

Suppose now that  is maximal for some
. By the same reasoning as above there is no
-play extending  by an action from . We have two cases
\begin{itemize}
\item If  is final then  is a final plan by
  Lemma~\ref{l:rfuture}. So there is  such that
   is final. Then  is a maximal -play. Since
   is winning, after  all processes are in the final state. By
  Lemma~\ref{lemma:states},  is winning too.
\item If  is not final then  since  is assumed to satisfy
  Lemma~\ref{l:separation}, and communication with other processes
  than  is not possible. By Lemma~\ref{l:rfuture}  cannot be
  final and action  for  is possible according to
  . A contradiction.
\end{itemize}

A play of the form  cannot be maximal since some local
actions of the form  are always possible. This covers all the
cases and completes the proof.
\end{proof}




\medskip
\noindent\textit{From  in  to  in .}
From a strategy  for  we define a
strategy  for . We assume that 
satisfies Lemma~\ref{l:separation}. We consider  ending in an
action from  such that  is a -play. First, for
every  and every  we set

If  is not final then 
for some admissible plan  in state . This means
that  for some strategy . In this case:
\begin{itemize}
\item for every  we set ;

\item for every  we consider
   and set
  
\end{itemize}

\medskip

\begin{lemma}\label{lemma:sigma prim to sigma}
  If  is a winning strategy for  then 
  is a winning strategy for .
\end{lemma}

\medskip

\begin{proof}
  Suppose that  is -play ending in an action from
   and such that  is a -play. We first show
  that for every extension of  to a -play  with , , and , its image
   is a -play. Then we will show that
  every maximal -play is winning.

  Take . By Lemma~\ref{lemma:states}  is not
  final, so we have . Then
   by the definition of . Again directly from the
  definition we have that  is a -play. By
  definition of  we have then that  is a
  -play for . Finally, we need to see why
   with  is possible. Since
   we get that . Then
  , and in consequence
   is possible by
  Lemma~\ref{lemma:states} and the definition of .

  It remains to verify that every maximal -play is winning. Consider a
  maximal -play  where  ends in an action from ,
  , and  (this includes the cases
  when , or  are empty). We look at  and consider two
  situations:

  \begin{itemize}
  \item If no  is possible from  then
     is final. This means that  is empty and
     and  are both final. It is then clear
    that  is a maximal -play. Since  is winning,
    every process is in a final state. So  is a winning play in
    .
  \item If  is a -play for some  then again we
    have two cases:
    \begin{itemize}
    \item If  is final then  by
      the definition of . As  is an admissible plan,  is
      final. After  no action other than  is
      possible. But  is not possible either since  is
      final. Hence  is a maximal -play. So all the
      states reached on  are final. By
      Lemma~\ref{lemma:states} we deduce the same for , hence
       is winning.
    \item If  is not final then  for
       (local actions of  are not possible, since 
      is maximal). Hence , and  is not final. This
      means that  is not final. So it is
      possible to extend the -play with an action of the form . But
      by the definition of  we have . Hence 
       can be extended by a communication between  and  on
      a letter from ; a contradiction.
    \end{itemize}
  \end{itemize}
\end{proof}

\medskip

Together, Lemmas~\ref{lemma:sigma to sigma prim} and~\ref{lemma:sigma prim to
  sigma} show Theorem~\ref{th:reduction}.


\begin{theorem}\label{th:reduction}
  Let  be the fixed leaf process with 
  and  its parent.  Then the system has a winning strategy for  iff it
  has one for . All the components of 
  are identical to those of , apart that for the process . The
  size of  in  is , where  and
   are the sizes of processes  and  in , respectively.
\end{theorem}

\begin{remark} Note that the bound on  is better than  obtained by simply counting all
possible states in the description above. 
The reason is that we can restrict admissible plans to be (partial)
functions from  into . 
That is, we do not need to consider different
sets of communication actions for the same state in .
\end{remark}

Let us reconsider the example from Figure~\ref{fig:server-client} of a
server with  clients. Applying our reduction  times we reduce
out all the clients and obtain the single process plant whose size is
 where 
is the size of the server,  is the size of client , and  is
the maximal number of communication actions between a client and the
server.



\begin{theorem}\label{th:main}
  The control problem for distributed alphabets with acyclic communication
  graph is decidable. There is an algorithm for solving
  the problem (and computing a finite-state controller, if it exists) whose
  working time is bounded by a tower of exponentials of height equal
  to half of the diameter of the graph. 
\end{theorem}






Our reduction algorithm  can be actually used to compute a (finite-state)
distributed controller:

\begin{corollary}
  There is an algorithm which solves the control problem for
  distributed alphabets whose communication graph is acyclic and if
  the answer is positive, the algorithm outputs a controller
  satisfying the following property: For every process  and every
  state  of the controller , the set of actions allowed for
  process  in state  is the set of all uncontrollable local
  actions plus:
\begin{itemize}
  \item either a unique controllable local action,
  \item or a set of controllable actions shared with a unique neighbour 
  of .
\end{itemize} 
\end{corollary}





\section{The lower bound}

We show in this section that in the simplest non-trivial case of
acyclic communication graphs, consisting of a line of three processes,
the control problem is already \EXPTIME-complete. In the general case
the complexity of the control problem grows as a tower of exponentials
function with respect to the size of the diameter of the communication
graph. 


\subsection{Height one}
\begin{proposition} \label{p:3} 
  The control problem for the communication graph  is
  \EXPTIME-complete.
\end{proposition}

\medskip

\begin{proof}
The EXPTIME upper bound follows from Theorem~\ref{th:reduction}, as
  the height of the tree is 1.
So the reduction is applied twice
from process , first simulating process , then simulating
process . Finally, a reachability game is solved on an exponential
size arena.  

  For the lower bound we simulate an alternating polynomial space
  Turing machine  on input . We assume that  has a unique
  accepting, blocking configuration (say with blank tape, head
  leftmost). The goal now is to let processes  guess an accepting
  computation tree of  on . The environment will be able to
  choose a branch in this tree and challenge each proposed
  configuration. Process  will be used to validate tests initiated
  by the environment. If a test reveals an inconsistency, process 2
  blocks and the environment wins. To summarize the idea of the construction: \anca{added}
  processes  and 
  generate sequences of configurations (encoded by local actions),
  separated by action \bar{\, respectively, shared with
  process . Both start with the initial configuration of  on
  . Transitions from existential states are chosen by the plant,
  and those from universal ones by the environment. 
At a given time, process  has generated the same number of
configurations is process , or process  is about generating one
configuration more. In the first case, the environment can check
that it is the
same configuration; and in the second, it can check that it is the successor
configuration. In this way,  and  need to generate the same branch of the
run tree.

  A computation of  with space bound  is a sequence , where each configuration  is
  encoded as a word from  of length
  . Since  is alternating, its acceptance is expressed by the existence
  of a tree of accepting computations. 

  Processes 1 starts by generating the initial configuration on , followed by a synchronization
  symbol \ process 1 goes into a state where the outgoing
  transitions are labeled by 's transitions on  (if the
  configuration was not blocking). These transitions are controllable
  if  is existential, and uncontrollable if  is
  universal. The transition chosen, either by the plant or the
  environment, is  stored in the state up to the next synchronization symbol.  Finally, if the current
  configuration is final then process 1 synchronizes with 2 on _F\}
(4,.25) node (jp) {}\\label{eq:ctr}
  x_0u_0  x_1u_1\cdots  x_{k-1} u_{k-1}\#_{l+1}

where  and for every , letter  and
 is an -counter with value . The value of the above
-counter is .  The end marker
 will be convenient in the construction that follows.
An \emph{iterated -counter} is a nonempty sequence of
-counters.

\medskip For every  we will define a plant  such that the winning
strategy for the system in  will need to produce an iterated
-counter. 

\medskip For  this is very easy, we have only one
process in  and all transitions are controllable. 

\noindent\centerline{\includegraphics[scale=.62]{one-counter.pdf}}

This automaton can repeatedly produce a -counter and eventually go
to the accepting state. The letter on which it goes to accepting state
will be not important, so we put . Recall that our acceptance
condition is that all processes reach a final state from which no
actions are possible.

Suppose that we have already constructed . We want now to
define , a plant producing an iterated -counter,
i.e., a sequence of -counters with values . We assume that the
communication graph of  has the distinguished root process . Process
 is in charge of generating an iterated -counter. From  we
will construct two plants  and , over disjoint sets
of processes. The plant  is obtained by adding a new root
process  that communicates with , similarly for the 
plant  with root process .  The plant
 will be the composition of  and  with a new
\emph{verifier process} that we name . The root process of the communication graph
of  will be . The schema of the
construction is presented in Figure~\ref{fig:architecture}. Process
, as well as , are in charge of generating an
iterated -counter. That they behave indeed this way is
guaranteed by a construction similar to the one of
Proposition~\ref{p:3}, with the help of the verifier :
\anca{added} the
environment gets a chance of challenging each -counter of the
sequence of  (and similarly for ). These
challenges correspond to two types of tests, equality and
successor. If there is an error in one of these sequences then 
the environment can place a challenge and win. Conversely, if there is
no error no challenge of the environment can be successful; this means
then that the sequences of -counters have
correct values .

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=.7]{architecture.pdf}
  \caption{Architecture of the plant }
  \label{fig:architecture}
\end{figure}



\medskip\noindent\textit{Construction of .}
The construction of the automaton  of the new root
 is presented in Figure~\ref{fig:main automaton}.

\begin{figure*}[htbp]
  \centering
  \includegraphics[scale=.7]{Ar.pdf}
  \caption{Automaton for process }
  \label{fig:main automaton}
\end{figure*}


We start by modifying the automaton for process , given by .
Actions of  from , that were previously local for
, become shared actions with .  Process  has new local actions 
 and an action _l\Vv_{l+1}\ is executed after each -counter, that is, after each .

The automaton for  has two main tasks: it ``copies'' the
sequence of -counters generated by  (actually only the
projection onto ) and it interacts with  towards the
verification of this sequence. This automaton is composed of three parts that synchronize
with , forcing it to behave in  some specific way. The first part called
``zero'' enforces that  starts with an -counter with value 0
(otherwise  would block). When we read  we know that
the first -counter has ended and the control is passed to the
second, main part of .

The main part of  gives a possibility for the environment
to enter into a test part. That is, after each transition on 
(that is  or ) the environment chooses between action
 (that continues the main part) or a test action from
  that leads into the test
part. The main part also outputs a local action  when
needed, i.e., whenever the last seen -counter was
maximal. (Technically it means that there has been no  since the
last .) The transition on  gives a possibility to go
to the accepting state.

The test part of  simply receives the -actions of
 and sends them to process  (cf.~loop  and ). It does so until it receives
 signaling the end of the counter. Then it sends _l\Vv_{l+1}r_{l+1}\top_{l+1}\bar\Dd^l\Dd^l\bar\Dd^l\Dd^l\bar a\bar\Dd^la\Dd^l\Dd^l\bar\Dd^l\bar{(\inctest,c)}\bar{(\inctest,1-c)}\ there have been only
. This is done to accommodate for the carry needed for the successor test. Recall that
 stands for  if  is   and vice versa.



\noindent\textit{Process .}
This process will have two main states  and , the first one
being initial. From  there is a transition on _l\mathit{succ}\mathit{succ}\ back to
. Moreover from  it is possible to go to the accepting state.

\begin{figure}
  \centering
  \includegraphics[scale=.62]{process0.pdf}
  \caption{Process .}
  \label{fig:verifier}
\end{figure}


Additionally, from  there is a transition on 
to the state  for every . Similar to the
construction of Proposition~\ref{p:3}, process  should
accept if either the two bits from  challenged by the
environment are compatible with the test, or their positions
are unequal. So, from state  on letter
 there is a transition to a state called
; on all other letters there is a transition to a
looping state (see also Figure~\ref{fig:verifier}). Similarly from , but now with 
letters, and the order of reading from the components reversed.

From state  process  verifies that the sequence of
actions  initiated by  has not the same \emph{length} as the
sequence over  initiated by  (up to the
moment where ^0_l\bar\ are executed). This is done
simply by interleaving the two sequences of actions , shared with
 and , respectively\anca{deja la}. Notice that
the symbols  by themselves are not important, one could as well replace
them by a single symbol. If this is the
case, then process  gets to an accepting state, otherwise it
rejects. In state  process  can perform any 
controllable action and then enter the
accepting state.



\medskip\noindent\textit{Putting together .}
The plant  is the composition of ,  and the
new process . The actions of  are the ones of ,
plus  where  consists of:
\begin{itemize}
\item  with domain ,
\item   with domain ,
\item  and  with domain  (),
\item , _l(\eqtest,c)^0(\inctest,c)^0\Ssys\set{r_{l+1},\Vv_{l+1}}c\in \S_l\bar Xc\bar cr_l,r_{l+1}\bar{r_l},\bar{r_{l+1}}\Cc^llll\cc\s\Cc^l\s\bigcup_{i=1,\ldots,l} \S^\#_i\ccll=11l+1\Cc^{l+1}\Cc^l\bar{\Cc}^l\rlp\brlp\Vv_{l+1}(l+1)\cc\ccl\bigcup_{i=1,\dots,l} \S^\#_il\Cc^l\Cc^l\bar\Cc^l\Cc^{l+1}r_{l+1}\ccr_l\ccl\Cc^l\rlp\S_{l+1}r_{l+1}\cc\#_{l+1}\top_{l+1}\bar{r_{l+1}}\Vv_{l+1}\mathit{eq}\ symbols he has received.

  Let us suppose now that the environment chooses a question action in
   or . Let  be the index of an -counter 
  within  at which the first question is asked. We will consider
  two cases: (i) the question is asked in , (ii) the
  question is asked in  but not in .

  If a question is asked in  then the play has the
  following form:
  \begin{center}
  \begin{tikzpicture}[yscale=.7]
    \draw (0,2)node{:}++(1.5,0)node{}++(1.2,0)node(dol){_lud\Vv_{l+1}\brlp\dots\bar{u_{i-1}}\bar
      \}++(1,0)node{}++(1,0)node(e){};
    \draw (dol)--+(0,-1);
    \draw (dolb)--+(0,1);
    \draw (d)--+(0,-1);
    \draw (e)--+(0,1);
  \end{tikzpicture}
  \end{center}
  \noindent with  being prefixes of ;  being a
  question, and  a synchronization action of  with . So
   can be a question or _l\bar{\_l\Vv_{l+1}\mathit{eq}\bar e d\bar{(\dar,c)}(\dar,1-c)c\in\S_l\Vv_{l+1}\mathit{loop}r_{l+1}\bar{r_{l+1}}\bar e d\bar{(\dar,c)}(\dar,1-c)\Vv_{l+1}\mathit{neqtest}\rlp\brlp\Vv_{l+1}\S_l\brlpl\Vv_{l+1}\bar{\. Then it enters into the loop state of the
  test copy and can continue to generate  since it can do any
  transition in this state. As for process , if  is a
  question, then it does the same thing as .  If  is _l\rlp\cc\Vv_{l+1}\brlp\rlp\cc\rlp\brlp\rlp\dots u_{i-1}\}
    ++(1,0)node{}++(1,0)node(d){};
    \draw (0,1)node{:};
    \draw
    (0,0)node{:}++(1.5,0)node{}++(1,0)node(dolb){_l\bar u_i\bar\}++(1,0)
    node{}++(1,0)node(e){}; 
    \draw (dol)--+(0,-1);
    \draw (dolb)--+(0,1);
    \draw (dolbp)--+(0,1);
    \draw (d)--+(0,-1);
    \draw (e)--+(0,1);
  \end{tikzpicture}
  \end{center}
  where  is a prefix of ,  a prefix of , 
  is a question, and  a synchronization of  with
  . Observe that after reading _l\bar{\ process  is in
  state . As before our first goal is to show that 
  gets to an accepting state. If the sequence  is not
   then we reason as in the
  previous case. Otherwise  gets to state . As before we
  can deduce that the two questions are asked at different positions of
  the respective counters. Which means that  will receive a
  different number of  letters from  and  so it
  will get to state . The rest of the argument is exactly
  the same as in the previous case.
\end{proof}


We will show that in order to win in  the system  has no
other choice than to generate an iterated -counter. Before this we
present a  general useful lemma:

\medskip

\begin{lemma}\label{l:sub}
  Consider a plant  consisting of two plants  and 
  over process set  and , respectively. We assume that
  there exist  and  such that each
  action  in  is such that either  or
  , or . Then every winning strategy in  gives a winning
  strategy in .
\end{lemma}

\medskip

\begin{proof}
  Just fix the behaviour of the environment in  and play the
  strategy in .
\end{proof}

With this at hand we can now prove the main lemma.

\medskip

\begin{lemma}\label{lemma:strategy-long}
  If  is a winning strategy in  and  is a
  -play with no question then the projection of  on
   is an iterated -counter.
\end{lemma}

\medskip

\begin{proof}
  By the construction of , if
  there is no question during a -play, then the play is uniquely
  determined by the strategy. We will show that this unique play is an
  iterated -counter. 

  By applying Lemma~\ref{l:sub} twice we obtain from 
  a winning strategy in
  . By induction assumption the projection of  on
    is an iterated
  -counter. 
  Thus, between every two  consecutive
  _l\S_{l+1}l\#_l\bar{r_{l+1}}u_0,u_1,\ldotsl0,1,\ldots\Tower(2,l)\bar{u_0},\bar{u_1},\ldotsi\bar{u_i}u_iku_iku_ir_{l+1}(\eqtest,c)\bar{r_{l+1}}k\bar{(\eqtest,1-c)}\Vv_{l+1}\mathit{neqtest}(\eqtest,c)\bar{(\eqtest,1-c)}r_l\bar{r_l}l\Cc^l\bar{\Cc^l}k\Vv_{l+1}r_{l+1}\bar{r_{l+1}}\Cc^{l+1}u_ii
  \pmod{\Tower(2,l)}\bar{u_{i+1}}(i+1) \pmod{\Tower(2,l)}k\bar{(\inctest,c)}(\inctest,c)(\inctest,1-c)a_lku_i\Vv_{l+1}\bar{r_{l+1}}r_{l+1}\sl\Cc^l\s\s\bigcup_{i=1,\ldots,l} \S^\#_ill>02l+1(2^{l+3}-3)\Omega(\Tower(n,l))\Cc^l(2^{l+2}-3)2l-1l\Tower(n,l)\Tower(2,l)1n2MwnwM\Cc(M,w)Mw\Tower(n,l)(l+1)(l+1)\Cc(M,w)\Cc^{l+1}0\Tower(n,l)Mw\Cc(M,w)\Cc(M,w)lM,w,n$. The game can be
  constructed in the time proportional to its size.
\end{proof}







\section{Conclusions}

Distributed synthesis is a difficult and at the same time
promising problem, since distributed systems are intrinsically complex
to construct. We have considered  a simple, yet powerful model based on synchronization using shared memory --
as used in multithreaded programs or by  hardware primitives
such as compare-and-swap. 
Under some restrictions we have shown that the resulting control
problem is decidable. Since every process is allowed to interact with
the environment, our tree architectures are quite rich and allow to
model hierarchical situations, like server/clients. Such cases
are undecidable in the setting of Pnueli and Rosner. 





Already Pnueli and Rosner in~\cite{PR89icalp} strongly argue in
favour of asynchronous distributed synthesis.  
The choice of transmitting additional information while synchronizing
is a consequence of the model we have adopted. We think that it is
interesting from a practical point of view. It is also interesting
theoretically, since it allows to avoid simple (and unrealistic)
reasons for undecidability. Our lower bound result is somehow
surprising. Since we have full information sharing, all the
complexity must be hidden in the uncertainty about other processes
peforming in parallel. 

Important problems remain open, in particular the decidability 
without the acyclic restriction. A more immediate task is to consider
non-blocking winning conditions and B\"uchi specifications. A further
interesting research venue is synthesis of open,
concurrent recursive programs, as considered e.g.~in~\cite{bgh09}.



\bibliographystyle{abbrv}
\bibliography{bibliography-new}

 

\end{document}
