[{'LEADERBOARD': {'Task': 'Zero-Shot Video Question Answer', 'Dataset': 'STAR: Situated Reasoning', 'Metric': 'Accuracy', 'Score': '39.7'}}, {'LEADERBOARD': {'Task': 'Temporal/Casual QA', 'Dataset': 'NExT-QA', 'Metric': 'WUPS', 'Score': '33.5'}}, {'LEADERBOARD': {'Task': 'Temporal/Casual QA', 'Dataset': 'NExT-QA', 'Metric': 'WUPS', 'Score': '26.7'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'PMC-VQA', 'Metric': 'Accuracy', 'Score': '26.4'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'MSRVTT-QA', 'Metric': 'Accuracy', 'Score': '0.474'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'MSRVTT-QA', 'Metric': 'Accuracy', 'Score': '0.310'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'MSRVTT-QA', 'Metric': 'Accuracy', 'Score': '0.174'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-dev', 'Metric': 'Accuracy', 'Score': '56.3'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-dev', 'Metric': 'Accuracy', 'Score': '51.8'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-dev', 'Metric': 'Accuracy', 'Score': '49.2'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'OK-VQA', 'Metric': 'Accuracy', 'Score': '50.6'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'OK-VQA', 'Metric': 'Accuracy', 'Score': '44.7'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'OK-VQA', 'Metric': 'Accuracy', 'Score': '41.2'}}, {'LEADERBOARD': {'Task': 'Generative Visual Question Answering', 'Dataset': 'PMC-VQA', 'Metric': 'BLEU-1', 'Score': '4.1'}}, {'LEADERBOARD': {'Task': 'Video Question Answering', 'Dataset': 'STAR: Situated Reasoning', 'Metric': 'Average Accuracy', 'Score': '42.8'}}, {'LEADERBOARD': {'Task': 'Video Question Answering', 'Dataset': 'STAR: Situated Reasoning', 'Metric': 'Average Accuracy', 'Score': '42.4'}}, {'LEADERBOARD': {'Task': 'Video Question Answering', 'Dataset': 'STAR: Situated Reasoning', 'Metric': 'Average Accuracy', 'Score': '41.8'}}, {'LEADERBOARD': {'Task': 'Video Question Answering', 'Dataset': 'STAR: Situated Reasoning', 'Metric': 'Average Accuracy', 'Score': '39.7'}}, {'LEADERBOARD': {'Task': 'Action Recognition', 'Dataset': 'RareAct', 'Metric': 'mWAP', 'Score': '60.8'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Cross-Modal Retrieval', 'Dataset': 'Flickr30k', 'Metric': 'Image-to-text R@1', 'Score': '89.3'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Cross-Modal Retrieval', 'Dataset': 'Flickr30k', 'Metric': 'Image-to-text R@5', 'Score': '98.8'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Cross-Modal Retrieval', 'Dataset': 'Flickr30k', 'Metric': 'Image-to-text R@10', 'Score': '99.7'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Cross-Modal Retrieval', 'Dataset': 'Flickr30k', 'Metric': 'Text-to-image R@1', 'Score': '79.5'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Cross-Modal Retrieval', 'Dataset': 'Flickr30k', 'Metric': 'Text-to-image R@5', 'Score': '95.3'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Cross-Modal Retrieval', 'Dataset': 'Flickr30k', 'Metric': 'Text-to-image R@10', 'Score': '97.9'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Cross-Modal Retrieval', 'Dataset': 'COCO 2014', 'Metric': 'Image-to-text R@1', 'Score': '65.9'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Cross-Modal Retrieval', 'Dataset': 'COCO 2014', 'Metric': 'Image-to-text R@5', 'Score': '87.3'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Cross-Modal Retrieval', 'Dataset': 'COCO 2014', 'Metric': 'Image-to-text R@10', 'Score': '92.9'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Cross-Modal Retrieval', 'Dataset': 'COCO 2014', 'Metric': 'Text-to-image R@1', 'Score': '48.0'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Cross-Modal Retrieval', 'Dataset': 'COCO 2014', 'Metric': 'Text-to-image R@5', 'Score': '73.3'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Cross-Modal Retrieval', 'Dataset': 'COCO 2014', 'Metric': 'Text-to-image R@10', 'Score': '82.1'}}, {'LEADERBOARD': {'Task': 'Meme Classification', 'Dataset': 'Hateful Memes', 'Metric': 'ROC-AUC', 'Score': '0.700'}}]
