\documentclass[envcountsame,oribibl]{llncs}



\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{natbib}


\usepackage[dvips]{hyperref} 


\usepackage{algorithmic} \usepackage{algorithm} 




\newcommand{\oneone}{1\!\!1}
\newcommand{\one}[1]{\oneone\left(#1\right)}
\newcommand{\stacktwo}[2]{\begin{array}{c}#1 \\#2\end{array}}
\newcommand{\mat}[2]{\left(\begin{array}{#1}#2\end{array}\right)}
\newcommand{\piecewise}[1]{\left\{\begin{array}{@{\;}ll}#1\end{array}\right.}
\newcommand{\set}[1]{\{#1\}}                        \newcommand{\setof}[2]{\{\,{#1}\::\:{#2}\,\}}        \newcommand{\groupFrac}[2]{\left(\frac{#1}{#2}\right)}

\newcommand{\sm}{\setminus} \newcommand{\compl}[1]{\overline{#1}}                \newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\argmax}{\arg\max}

\newcommand{\C}{\mathbb{C}}                        \newcommand{\N}{\mathbb{N}}                     \newcommand{\Q}{\mathbb{Q}}                     \newcommand{\R}{\mathbb{R}}                     \newcommand{\Z}{\mathbb{Z}}                     

\newcommand{\pr}[1]{\mathrm{Pr}\left(#1\right)}
\newcommand{\var}[1]{\mathbf{Var}\left[#1\right]}
\newcommand{\E}[1]{\mathbf{E}\left[#1\right]}
\newcommand{\Esub}[2]{\mathbf{E}_{#1}\left[#2\right]}
\newcommand{\cpr}[2]{\mathrm{Pr}\left(#1|#2\right)}

\newcommand{\tand}{\textrm{ and }} \newcommand{\tif}{\textrm{if }} \newcommand{\mapstor}{\textrm{ or }} \newcommand{\ow}{\textrm{otherwise}}
\newcommand{\tow}{\textrm{otherwise}}

\newcommand{\bigO}[1]{O\left(#1\right)}
\newcommand{\bigOTilde}[1]{\tilde O\left(#1\right)}
\newcommand{\bigOmega}[1]{\Omega\left(#1\right)}

\newcommand{\tab}{\hspace*{1em}} 






\addtolength{\marginparwidth}{-10pt}
\newcommand{\footcomment}[1]{} \newcommand{\margincomment}[1]{} \newcommand{\commentw}[1]{\margincomment{WS: #1}}
\newcommand{\commentc}[1]{\margincomment{CM: #1}}
\newcommand{\footcommentw}[1]{\footcomment{WS: #1}}
\newcommand{\footcommentc}[1]{\footcomment{CM: #1}}



\newcommand{\bp}{\,\rule[-0.22em]{0.08em}{1em}\,} 

\newcommand{\betTour}{\textsc{BetweennessTour}}
\newcommand{\fast}{\textsc{FAST}}
\newcommand{\kra}{\textsc{KRA}}

\begin{document}

\title{Faster Algorithms for Feedback Arc Set Tournament, Kemeny Rank Aggregation and Betweenness Tournament\thanks{A preliminary version of this work appeared in version 1 of the arXiv preprint \cite{Karpinski09betweenness}.}}
\titlerunning{Exact algs}  \author{Marek Karpinski\inst{1}\thanks{Parts of this work done while visiting Microsoft Research.} \and Warren Schudy\inst{2}\thanks{Parts of this work done while visiting University of Bonn.}}
\authorrunning{Marek Karpinski and Warren Schudy} \tocauthor{Marek Karpinski and Warren Schudy}
\institute{University of Bonn,\\
\email{marek@cs.uni-bonn.de}
\and
Brown University,\\
\email{ws@cs.brown.edu}}

\maketitle              

\begin{abstract}
We study fixed parameter algorithms for three problems: Kemeny rank aggregation, feedback arc set tournament, and betweenness tournament. For Kemeny rank aggregation we give an algorithm with runtime , where  is the number of candidates,  is the cost of the optimal ranking, and  hides polynomial factors. This is a dramatic improvement on the previously best known runtime of . For feedback arc set tournament we give an algorithm with runtime , an improvement on the previously best known  \cite{Alon09}. For betweenness tournament we give an algorithm with runtime , where  is the number of vertices and  is the optimal cost. This improves on the previously known  \cite{Saurabh09}), especially when  is small. Unusually we can solve instances with  as large as  in polynomial time!

\keywords{Kemeny rank aggregation, Feedback arc set tournament, Fixed parameter tractability, Betweenness tournament}
\end{abstract}

\section{Introduction}

Suppose you ran a chess tournament, everybody played everybody (a.k.a.\ round robin) and you wanted to use the results to rank everybody.  Unless you were really lucky, the results would not be acyclic, so you could not just sort the players by who beat whom. A natural objective is to find a ranking that minimizes the number of upsets, where an upset is a pair of players where the player ranked lower in the ranking beat the player ranked higher. Minimizing the number of upsets is called \emph{feedback arc set problem} on tournaments (\fast). The complementary problem of \emph{maximizing} the number of pairs that are \emph{not upsets} is called the \emph{maximum acyclic subgraph problem} on tournaments. These problems are NP-hard~\citep{Ailon08aggregating,Alon06,Charbit07} (see also \citep{Conitzer06a}), but a polynomial-time approximation scheme (PTAS) \cite{Mathieu09fast} is known.

In statistics and psychology, one motivation is \emph{ranking by paired comparisons} \citep{Slater61}: here, you wish to sort some set by some objective but you do not have access to the objective, only a way to compare a pair and see which is greater; for example, determining people's preferences for types of food. This problem attracted computational attention as early as 1961 \citep{Slater61} (for comparison Hoare published quicksort the same year). Feedback arc set tournament and closely related problems have also been used in machine learning~\citep{Cohen99,Ailon08aggregating}.

The \fast{} problem can be generalized to a problem we call \emph{weighted \fast{}}, sometimes known as \emph{feedback arc set with probability constraints}.
The input is a complete directed graph with arc weights  with  for every pair of vertices . In other words a weighted \fast{} instance is a convex combination of unweighted \fast{} instances.

We study the \emph{parameterized complexity} of this problem, in particular the parameter , the cost of an optimal ranking.  We use the notation  to hide factors that are polynomial in the input size, that is  iff  for some  and all sufficiently large inputs . The first fixed-parameter algorithms for feedback arc set tournament had runtime  and later algorithms made a dramatic improvement to  \cite{Alon09}. We improve this to .

\begin{theorem} \label{thm:exactFAST}
There exists a deterministic parameterized subexponential
   algorithm for weighted \fast{} with runtime . A variant of the algorithm uses  time and  space.
\end{theorem}

The \emph{Exponential time hypothesis} (ETH) \cite{Impagliazzo01} is that 3-SAT cannot be solved in time . We also give a matching lower bound assuming the ETH:

\begin{theorem} \label{thm:exactLB}
There does not exist a parameterized algorithm for weighted \fast{} with runtime  unless the exponential time hypothesis \cite{Impagliazzo01} is false.
\end{theorem}

We leave open the possibility that \emph{unweighted} \fast{} may admit an exact algorithm with runtime .

We note that independently of this work Uri Feige \cite{Feige09} gave an unrelated algorithm for \emph{unweighted} \fast{} matching Theorem \ref{thm:exactFAST}.

\medskip

An important application of weighted feedback arc set tournament is {\em rank aggregation}. Frequently, one has access to several rankings of objects of some sort, such as search engine outputs~\citep{Dwork01}, and desires to aggregate the input rankings into a single output ranking that is similar to all of the input rankings: it should have minimum {average distance} from the input rankings, for some notion of distance. This ancient problem was already studied in the context of voting by \citep{Borda} and \citep{Condorcet} in the 18 century, and has aroused renewed interest recently~\citep{Dwork01,Conitzer06b}.  A natural notion of distance is the number of pairs of vertices that are in different orders, which is known as the Kendall-Tau distance. This defines the {\em Kemeny rank aggregation} problem (KRA) \citep{Kemeny59,Kemeny62}. This choice yields a maximum likelihood estimator for a certain na\"\i{}ve Bayes model~\citep{Young95}. This problem is NP-hard~\citep{Bartholdi89}, even with only four voters \citep{Dwork01}, and has a PTAS \cite{Mathieu09fast}.

We denote the \emph{average} distance between the optimal ranking and the input rankings by . Two parameters have attacted the bulk of the study:  and the average Kendall-Tau distance between the input rankings. It is easy to see (triangle inequality) that these two parameters are within a constant factor of each other, so these parameters give equivalent runtimes up to constants in the exponent. All previous work give algorithms with runtime  \cite{Betzler09}. There is a standard reduction from Kemeny rank aggregation to weighted \fast{} \cite{Ailon08aggregating,Coppersmith06,Mathieu09fast}, so we improve the best known parameterized algorithm for KRA dramatically to  as a corollary of our Theorem \ref{thm:exactFAST}.

\begin{corollary} \label{thm:exactKRA}
Let  be the number of candidates and  the optimum value. There exists a deterministic parameterized subexponential algorithm for Kemeny Rank Aggregation with runtime and space . A variant uses  time and  space.
\end{corollary}

Some other paramters have attracted attention. The parameter of maximum Kendall-Tau distance has been studied but yield bounds no tighter (up to constants in the exponent) than is known for the average Kendall-Tau distance \cite{Betzler09}. Another parameter is the maximum , over candidates  and pairs of voters , of the absolute difference between the rank of  in  and . The best runtime known is  \cite{Betzler09}.

\bigskip

In the Betweenness problem we are given a ground set of \emph{vertices} and a set of \emph{betweenness constraints}
involving  vertices and a \emph{designated} vertex among them.
The objective function of a ranking of the elements is the number of betweenness constraints
for which the designated vertex is not between the other two vertices. The goal is to
\emph{minimize} the objective function. 
For the status of the general Betweenness
problem, see e.g.\ \cite{Opatrny79,Chor98,Ailon07hardness,Charikar09}.
We refer to the Betweenness problem in tournaments, that is in instances with a constraint for every triple of vertices,
as the \betTour{} problem (see \cite{Ailon07hardness}). This problem is NP-hard \cite{Ailon07hardness} and has a recently discovered polynomial-time approximation scheme \cite{Karpinski09betweenness}. We study its parameterized complexity.

\begin{theorem} \label{thm:exactGen}
There exists a randomized parameterized subexponential
   algorithm for \betTour{} with runtime and space , where  is the number of vertices and  is the cost of the optimal ranking. It succeeds with constant probability.
\end{theorem}

The previously best known runtime was  \cite{Saurabh09}. Our result is better by a logarithmic factor in the exponent for the largest possible  and even better for smaller . Interestingly we can solve all instances with  in polynomial time!

Our results easily generalize to all fully dense ranking CSPs of arity three with \emph{fragile} constraints as introduced by \cite{Karpinski09betweenness}. For simplicity we limit ourselves to the well-known problems discussed above.

\medskip

We now outline the organization of our paper. Section \ref{sec:fast} discusses weighted feedback arc set tournament, including our algorithm (Section \ref{sec:fastAlg}), analysis (\ref{sec:fastAnalysis}), and lower bound (\ref{sec:lb}). Section \ref{sec:bet} discusses our results for betweenness tournament, including our algorithm (Section \ref{sec:betAlg}) and analysis (\ref{sec:betAnalysis}).

\section{Feedback arc set tournament} \label{sec:fast}

\subsection{Algorithm} \label{sec:fastAlg}

We now outline some of our key techniques. Firstly any two low-cost rankings for a FAST problem are nearby in Kendall-Tau distance. Secondly two rankings that are Kendall-Tau distance  apart are equivalent to within additive  in how good each position for each a vertex is (Lemma \ref{lem:fastSVMlandscape}). Thirdly most vertices (in a low-cost instance) have a vee-shaped cost versus position curve and optimal rankings are locally optimal so we know that each vertex belongs at the bottom of its curve. The uncertainty in this curve by  causes an uncertainty in the optimal position also around  (Lemmas \ref{lem:feClose} and \ref{lem:psiSmallFAST}). Our algorithm simply computes uncertainties  in the positions of all of the vertices  and solves a dynamic program for the optimal ranking that is near a particular constant-factor approximate ranking. We remark that Braverman and Mossel \cite{Braverman08} and Betzler et al.~\cite{Betzler08,Betzler09} previously applied dynamic programming to \fast{} and KRA.

First we state some core notation. Throughout this paper let  refer to the set of objects (vertices) being ranked and  denote . Our  hides absolute constants only. Our  hides a polynomial in . A \emph{ranking} is a bijective mapping from a set  to . We call  the position of  in the ranking . We let  denote the Kendall-Tau distance between rankings  and , i.e. the number of pairs of vertices in different orders in the two rankings.
An \emph{ordering} is an injection from  into . We use  and  (with superscripts) to denote rankings  and orderings respectively.

The input to weighted \fast{} is a set  of vertices and arc weights  such that  for all . 
The \fast{} objective function is the weight of the backwards arcs . For ranking , vertex  and  (with  for all ) we define , i.e.\ the cost of the arcs incident to  in the ordering formed by moving  to position  in .
Let  denote an optimal ranking and  its cost.

\begin{algorithm}[t]
Input: Vertex set , arc weights .
\begin{algorithmic}[1]
\STATE Sort by weighted indegree \cite{Coppersmith06}, yielding ranking  of .
\STATE Set  for all .
\STATE Use dynamic programming or divide-and-conquer (Details: Lemma \ref{lem:DP}) to find the optimal ranking  with  for all .
\end{algorithmic}
\caption{Exact algorithm for FAST. If dynamic programming is used in the last line the runtime and space are both . If divide-and-conquer is used the runtime is  and the space is .}
\label{alg:exactFAST}
\end{algorithm}


\medskip

Before running our main Algorithm \ref{alg:exactFAST} we compute a small \emph{kernel}, that is a smaller instance with the same optimal cost as the input instance (up to a known shift). This preliminary step allows us to separate the dependence on  and  in the runtime, yielding the runtime stated in Theorem \ref{thm:exactFAST}.

Dom et al.\ \cite{Dom06} give an algorithm for computing kernels of \emph{unweighted} FAST instances with  vertices. This was later improved to  vertices by Bessy et al. \cite{Bessy09}. There is a kernelization algorithm for Kemeny rank aggregation in \cite{Betzler09}, but it produces an instance of size , not the desired . To get the desired kernel for general weighted \fast{} we consider a slight variant of the algorithm from \cite{Dom06}.

\begin{lemma}\label{lem:kernel}
There is polynomial-time computable -vertex kernel for weighted FAST. 
\end{lemma}
\begin{proof}[sketch]
Let  be the cost of a 5-approximate ranking \cite{Coppersmith06}.

We say that an arc is a \emph{majority arc} if it has greater weight than its reverse, with ties broken arbitrarily. A majority arc clearly has weight at least 1/2. The \emph{majority tournament} \cite{Ailon08aggregating} is the unweighted directed graph with vertex set  and arc set equal to the majority arcs.

Our kernelization algorithm is simple: we apply the following two reduction rules, which are extensions of two reduction rules in \cite{Dom06}, as often as possible.

The first reduction rule is eliminating a vertex that is part of no cycles of three arcs in the majority tournament. Consider some such vertex . It is easy to see that there exists an optimal ranking that puts every predecessor of  (in the majority tournament) before  and every successor of  after , while implies the validity of this rule.

The second reduction rule concerns an arc  of the majority tournament that is in more than  cycles of three arcs in the majority graph. Any feedback arc set not not paying for such an arc must pay for more than  other arcs of the majority tournament, each of cost at least 1/2, and hence cannot be optimal. Therefore we record that we must pay , then set weight  to zero and  to one.

Now we argue that the resulting instance after these two rules are exhaustively applied has  vertices.
An optimal feedback arc set, which necessarily has cost , can include at most  majority arcs. 
Each such majority arc is in at most  triangles by the second rule, so there are at most  triangles.
Finally by the first rule every vertex is in a triangle, so there are at most  vertices.
\end{proof}

We have not investigated whether or not the  vertex kernel for unweighted FAST \cite{Bessy09} can be extended to weighted FAST.

\subsection{Analysis}  \label{sec:fastAnalysis}

Variants of the following Lemma are given in \cite{Mathieu09fast} and \cite{Karpinski09betweenness}. We give a simplified proof here for completeness.

\begin{lemma}[\cite{Mathieu09fast,Karpinski09betweenness}]\label{lem:fastSVMlandscape}
Let  and  be rankings over . It follows that  for all  and .
\end{lemma}

\begin{proof}
Fix ,  and rankings ,. 
Consider the sets of vertices  and . Intuitively these are the vertices that cross  from left to right (resp. right to left) when going from  to . It follows easily from the definition of  that , so we now proceed to bound  and .

The bijective nature of  and  implies that . Observe that all vertices in  are before all vertices in  in , and vice versa for , hence . Putting these facts together proves the Lemma.
\end{proof}

\begin{lemma}\label{lem:feClose}
In Algorithm~\ref{alg:exactFAST} we have   for all  and any optimal ranking  of .
\end{lemma}
\begin{proof}
The weight of an arc and its reverse sum to one so . By Lemma \ref{lem:fastSVMlandscape} therefore 

for any .

Fix . We conclude

\end{proof}

\begin{lemma}\label{lem:psiSmallFAST}
In Algorithm~\ref{alg:exactFAST} we have .
\end{lemma}
\begin{proof}
Fix . Let , the cardinality of which we are trying to bound. We say  is \emph{pricey} if . Clearly  hence the number of pricey vertices is at most . All non-pricey vertices in  have , so at most  non-pricey vertices are in . We conclude  since  is a 5-approximation \cite{Coppersmith06}.
\end{proof}

\begin{lemma}\label{lem:DP}
There is a dynamic program for \fast{} that finds the optimal ranking  with  for all  using space and runtime , where . A divide and conquer variant uses  time and  space.
\end{lemma}

\begin{proof}
Say that a set  is \emph{valid} if it contains all vertices  with  and no vertex  with . Observe that for any  all valid sets of size  agree except for the presence or absence of  vertices.  Therefore there are at most  valid sets.

We say that a ranking  of valid set  is \emph{valid} if  is a valid set for all . It is easy to see that a ranking  is valid if and only if satisfies  for all .

One can easily see the following optimal substructure property: prefixes of an optimal  valid ranking are optimal valid rankings themselves.

For any valid set  let  denote the cost of the optimal valid ranking of . The recurrence relation is


The space-efficient variant evaluates  using divide and conquer instead of dynamic programming, similar to \cite{Dom06}. Details deferred.
\end{proof}

Now we put the pieces together and prove Theorem~\ref{thm:exactFAST}.
\begin{proof}[of Theorem~\ref{thm:exactFAST}]
The kernelization algorithm of Lemma \ref{lem:kernel} allows us to assume without loss of generality that . Algorithm \ref{alg:exactFAST} returns an optimal ranking by Lemmas  \ref{lem:feClose} and \ref{lem:DP}. Lemmas \ref{lem:psiSmallFAST} and \ref{lem:DP} allow us to bound the runtime and space requirements of the dynamic program.
\end{proof}

\subsection{Lower bound}  \label{sec:lb}



\begin{proof}[of Theorem \ref{thm:exactLB}]
For sake of contradiction suppose we have an algorithm for weighted FAST with runtime . We present a series of reductions which converts such an algorithm into a subexpontial-time algorithm for vertex cover, the existence of which is known to contradict the ETH \cite{Flum06}.

Let an instance of vertex cover with  vertices be given. Applying Karp's reduction from vertex cover to feedback arc set \cite{Karp72} produces a feedback arc set instance with  vertices. Finally one can reduce this to a weighted FAST instance with the same number of vertices by representing incomparable pairs of vertices by opposite arcs of weight 1/2. The result is an weighted FAST instance with  vertices that is equivalent to the original vertex cover instance. The optimal cost for this instance is at most its number of arcs, which is , so the hypothesized algorithm has runtime . This runtime is subexponential, contradicting the ETH.
\end{proof}


\section{Betweenness tournament}  \label{sec:bet}

\subsection{Algorithm}  \label{sec:betAlg}

We now introduce some new notation for the betweenness problem. We let  (for example) denote the standard binomial coefficient and  denote the set of subsets of set  of size . For any ordering  let  denote the ranking naturally associated with .

Let  denote the ordering over  which maps  to .
For set  of vertices and ordering  with domain including  let  denote the ordering over  which maps  to , i.e.\ the restriction of  to . For orderings  and  with disjoint domains let   denote the natural combined ordering over . For example of our notations,  denotes the ordering over  that maps  to  and  to .

A ranking 3-CSP consists of a ground set  of \emph{vertices} and a \emph{constraint system} , where  is a function from rankings of 3 vertices to . For brevity we henceforth abuse notation and and write  by . The objective of a ranking CSP is to find an ordering  (w.l.o.g.\ a ranking) minimizing . We will only ever deal with one constraint system  at a time, so we leave the dependence of  on  implicit in our notations. Abusing notation we sometimes refer to  as a \emph{constraint}, when we really are referring to .
Clearly one can model \betTour{} as a ranking 3-CSP.

Let , where the sum is over sets  of size 2. Note that this definition is valid regardless of whether or not  is in . The only requirement is that the range of  excluding  must not contain . This ensures that the argument to  is an ordering (injective). 

Our algorithm and analysis for \betTour{} are analogous to our results for \fast{} with two major differences. Firstly no kernel for betweenness tournament is known, which hurts the runtime somewhat. Secondly we use a more complicated approach to get the preliminary constant-factor approximation ranking .
We use the known PTAS \cite{Karpinski09betweenness} with an appropriate error parameter to get a 2-approximation. Our analysis requires not only that  be of \emph{cost} comparable to  but also that it be close in \emph{Kendall-Tau distance}. Fortunately the analysis of the PTAS from \cite{Karpinski09betweenness} supports the following theorem.

\begin{theorem}[\cite{Karpinski09betweenness}] \label{thm:nearby}
There exists a polynomial-time algorithm for \betTour{} that produces a set  of  rankings. With constant probability one of the rankings  satisfies   and has cost at most , where  is some optimal ranking.
\end{theorem}

\begin{algorithm}[t]
Input: Vertex set 
\begin{algorithmic}[1]
 \STATE Use the Algorithm from Theorem \ref{thm:nearby} to construct a set of rankings 
 \STATE Let  be the ranking from  with lowest cost
 \FOR{each }
 \IF{}
  \STATE Set  for all , where  and  are absolute constants.
  \STATE Use dynamic programming (see Lemma \ref{lem:DP}) to find the optimal ranking  with  for all .
 \ENDIF
\ENDFOR
\STATE Return the best of the  rankings.
\end{algorithmic}

\caption{Our algorithm for \betTour. The runtime is . }
\label{alg:exactGen}
\end{algorithm}



\subsection{Analysis}  \label{sec:betAnalysis}

The following two lemmas are given in \cite{Karpinski09betweenness} in more generality. We give simplified proofs here for readability.

\begin{lemma}[\cite{Karpinski09betweenness}]\label{lem:bChangeFirst}
For any rankings  and  over vertex set , vertex  and  we have

\end{lemma}

\begin{proof}
Fix , , ,  and . 
As in the proof of Lemma \ref{lem:fastSVMlandscape}, consider the sets of vertices  and .
From the definition of  we see that a constraint  contributes identically to  and  unless either:
\begin{enumerate}
\item  and  have a non-empty intersection (or)
\item .
\end{enumerate}

In the proof of Lemma \ref{lem:fastSVMlandscape} we showed that .
We can therefore bound

Clearly , hence  for sufficiently large .  Substituting this inequality into the second term of (\ref{eq:hello}) proves the Lemma.
\end{proof}


\begin{lemma}[\cite{Karpinski09betweenness}]\label{lem:fragile} Let  be a ranking of , ,  be a vertex and .
Let  be the set of vertices (excluding ) between  and  in . 
Then
. 
\end{lemma}

\begin{proof}
By definition

where the sum is over sets  of  vertices. Observe that betweenness tournament has a special property: the quantity in brackets in (\ref{eqn:pen2}) is at least 1 for every  that has at least one vertex between  and  in . There are at least  such sets.
\end{proof}

\begin{lemma}\label{lem:feCloseGen}
During the iteration of Algorithm~\ref{alg:exactGen} that considers the ranking with  and  guaranteed by Theorem \ref{thm:nearby} we have   for all .
\end{lemma}
\begin{proof}
By Lemma \ref{lem:bChangeFirst} and Theorem \ref{thm:nearby} we have 

for any .

Fix . We conclude

\end{proof}

\begin{lemma}\label{lem:psiSmallGen}
In Algorithm \ref{alg:exactGen} we have  .
\end{lemma}
\begin{proof}
We proceed analogously to the proof of Lemma \ref{lem:psiSmallFAST}.
Fix . Let , whose cardinality we are trying to bound. We say  is \emph{pricey} if . Clearly  hence the number of pricey vertices is at most . All non-pricey vertices in  have , so  non-pricey vertices are in . We conclude .
\end{proof}

\begin{lemma}\label{lem:DPGen}
There is a dynamic program for betweenness that finds the optimal ranking  with  for all , with space and runtime  where . A divide and conquer variant uses  time and  space.
\end{lemma}

\begin{proof}
As in the proof of Lemma \ref{lem:DP} we say that a set  is \emph{valid} if it contains all vertices  with  and no vertex  with . Observe that for any  the valid sets of size  are identical except for the presence or absence of at most  vertices. Therefore there are at most  valid sets. 

We say that a ranking  of valid set  is \emph{valid} if  is a valid set for all . It is easy to see that a ranking  is valid if and only if satisfies  for all .

The dynamic program based on  that worked for \fast{} does not appear to directly generalize to \betTour. We consider an alternate approach.
For any ranking  over  let  denote the portion of the cost shared by all orderings with prefix . That is, the cost of all constraints with at most 1 vertex outside . One can easily see the following optimal substructure property: prefixes of an optimal (w.r.t. ) valid ranking are optimal (w.r.t. ) valid rankings themselves.

For any valid set  let  denote the  cost of the optimal (w.r.t. ) valid ranking of . The recurrence relation is

\end{proof}

\begin{proof}[of Theorem~\ref{thm:exactGen}]
Lemmas \ref{lem:DPGen} and \ref{lem:psiSmallGen}, plus the test of the ``if'' in Algorithm  \ref{alg:exactGen}, allow us to bound the runtime and space requirements of the dynamic program used by Algorithm \ref{alg:exactGen} by , which is of the correct order since . The ``for'' loop is over a constant number of options and hence does not impact the runtime.

For correctness we focus on the iteration of Algorithm~\ref{alg:exactGen} that considers the  with  and  as guaranteed by Theorem \ref{thm:nearby}. Theorem \ref{thm:nearby} ensures  and hence the ``if'' is passed. By Lemma \ref{lem:feCloseGen}  is among the orders the dynamic program considers.
\end{proof}


\section*{Acknowledgements}
We would like to thank Venkat Guruswami, Claire Mathieu, Prasad Raghavendra and Alex Samorodnitsky for interesting remarks and discussions.

\nocite{Bredereck09}
\bibliographystyle{abbrvnat}
\bibliography{big_bib}  



\end{document}
