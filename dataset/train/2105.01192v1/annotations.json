[{'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'MuSeRC', 'Metric': 'Average F1', 'Score': '0.671'}}, {'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'MuSeRC', 'Metric': 'EM', 'Score': '0.237'}}, {'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'MuSeRC', 'Metric': 'Average F1', 'Score': '0.45'}}, {'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'MuSeRC', 'Metric': 'EM', 'Score': '0.071'}}, {'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'MuSeRC', 'Metric': 'Average F1', 'Score': '0.0'}}, {'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'MuSeRC', 'Metric': 'EM', 'Score': '0.0'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'DaNetQA', 'Metric': 'Accuracy', 'Score': '0.642'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'DaNetQA', 'Metric': 'Accuracy', 'Score': '0.52'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'DaNetQA', 'Metric': 'Accuracy', 'Score': '0.503'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'PARus', 'Metric': 'Accuracy', 'Score': '0.498'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'PARus', 'Metric': 'Accuracy', 'Score': '0.48'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'PARus', 'Metric': 'Accuracy', 'Score': '0.478'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'RuCoS', 'Metric': 'Average F1', 'Score': '0.26'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'RuCoS', 'Metric': 'EM', 'Score': '0.257'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'RuCoS', 'Metric': 'Average F1', 'Score': '0.25'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'RuCoS', 'Metric': 'EM', 'Score': '0.247'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'RWSD', 'Metric': 'Accuracy', 'Score': '0.597'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'RWSD', 'Metric': 'Accuracy', 'Score': '0.669'}}, {'LEADERBOARD': {'Task': 'Word Sense Disambiguation', 'Dataset': 'RUSSE', 'Metric': 'Accuracy', 'Score': '0.595'}}, {'LEADERBOARD': {'Task': 'Word Sense Disambiguation', 'Dataset': 'RUSSE', 'Metric': 'Accuracy', 'Score': '0.587'}}, {'LEADERBOARD': {'Task': 'Word Sense Disambiguation', 'Dataset': 'RUSSE', 'Metric': 'Accuracy', 'Score': '0.528'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'TERRa', 'Metric': 'Accuracy', 'Score': '0.549'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'TERRa', 'Metric': 'Accuracy', 'Score': '0.513'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'TERRa', 'Metric': 'Accuracy', 'Score': '0.483'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'RCB', 'Metric': 'Average F1', 'Score': '0.4'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'RCB', 'Metric': 'Accuracy', 'Score': '0.438'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'RCB', 'Metric': 'Average F1', 'Score': '0.319'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'RCB', 'Metric': 'Accuracy', 'Score': '0.374'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'RCB', 'Metric': 'Average F1', 'Score': '0.217'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'RCB', 'Metric': 'Accuracy', 'Score': '0.484'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'LiDiRus', 'Metric': 'MCC', 'Score': '0.147'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'LiDiRus', 'Metric': 'MCC', 'Score': '0'}}]
