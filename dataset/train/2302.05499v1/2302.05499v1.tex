\documentclass{article}

\usepackage{microtype}
\usepackage{geometry}
\usepackage{booktabs} 
\usepackage{bbm}
\usepackage{mathtools}
\usepackage{nccmath}
\usepackage{setspace}

\usepackage{caption}
\usepackage{subcaption}

\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\SetKwInput{KwInput}{Input}                \SetKwInput{KwOutput}{Output}              \newcommand\mycommfont[1]{\footnotesize\ttfamily\textcolor{blue}{#1}}
\SetCommentSty{mycommfont}
\newcommand{\algcapsty}[1]{\small\sffamily\bfseries{#1}}
\SetAlCapSty{algcapsty}

\usepackage[T1]{fontenc}
\usepackage{wrapfig,lipsum,booktabs}

\usepackage{soul}
\usepackage{dsfont}
\usepackage{enumerate}
\usepackage{enumitem}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{arabtex}
\usepackage{bbm}
\usepackage{dsfont}
\usepackage[Symbol]{upgreek}
\usepackage{lscape}
\usepackage{caption}
\usepackage{balance}
\usepackage{xspace}
\usepackage{float}



\usepackage{wasysym}
\usepackage[table,xcdraw,dvipsnames]{xcolor}
\usepackage{multirow}
\usepackage{array, boldline, rotating}

\usepackage{amssymb}\usepackage{pifont}\newcommand{\cmark}{\ding{51}}\newcommand{\xmark}{\ding{55}}

\newcommand{\ds}[1]{\mathds{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\bb}[1]{\mathbbm{#1}}









\let\oldeqref\eqref
\renewcommand*\eqref[1]{(\ref{#1})}

\newcommand{\smnote}[1]{\textbf{\textcolor{Cyan}{SM: #1}}}
\newcommand{\jwnote}[1]{\textbf{\textcolor{Orange}{JW: #1}}}
\newcommand{\eg}{\emph{e.g.,~}}
\newcommand{\ie}{\emph{i.e.,~}}


\newcommand{\myparagraph}[1]{\vspace{0.07cm}\noindent\textbf{#1}~}



\def\code#1{\texttt{#1}}
\DeclarePairedDelimiter\norm{\lVert}{\rVert}






\newcommand{\thickhline}{\hlineB{4}}
\newcommand{\bfcode}[1]{\code{\textbf{#1}}}


\definecolor{LightCyan}{rgb}{0.88,1,1} 

\usepackage{amsmath,amsfonts,bm}

\newcommand{\figleft}{{\em (Left)}}
\newcommand{\figcenter}{{\em (Center)}}
\newcommand{\figright}{{\em (Right)}}
\newcommand{\figtop}{{\em (Top)}}
\newcommand{\figbottom}{{\em (Bottom)}}
\newcommand{\captiona}{{\em (a)}}
\newcommand{\captionb}{{\em (b)}}
\newcommand{\captionc}{{\em (c)}}
\newcommand{\captiond}{{\em (d)}}

\newcommand{\newterm}[1]{{\bf #1}}


\def\figref#1{figure~\ref{#1}}
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
\def\secref#1{section~\ref{#1}}
\def\Secref#1{Section~\ref{#1}}
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
\def\eqref#1{equation~\ref{#1}}
\def\Eqref#1{Equation~\ref{#1}}
\def\plaineqref#1{\ref{#1}}
\def\chapref#1{chapter~\ref{#1}}
\def\Chapref#1{Chapter~\ref{#1}}
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
\def\algref#1{algorithm~\ref{#1}}
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
\def\partref#1{part~\ref{#1}}
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}

\def\eps{{\epsilon}}


\def\reta{{\textnormal{}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}

\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

\newcommand{\pdata}{p_{\rm{data}}}
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}

\newcommand{\laplace}{\mathrm{Laplace}} 

\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}

\newcommand{\parents}{Pa} 


\DeclareMathOperator{\Tr}{Tr}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\sign}{sign}
\let\ab\allowbreak

\newcommand{\trace}{\Tr}
 
\newcommand{\alg}{\code{CUDA}\xspace}
\usepackage{iclr2023_conference,times}
\iclrfinalcopy
\usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}    \usepackage{hyperref}       \usepackage{url}            \usepackage{booktabs}       \usepackage{amsfonts}       \usepackage{nicefrac}       \usepackage{microtype}      \usepackage{xcolor}         \usepackage{kotex}


\renewcommand*\cite[1]{\citep{#1}}
\newcommand{\rebut}[1]{\textcolor{black}{#1}}

\title{CUDA: Curriculum of Data Augmentation for Long-tailed Recognition}



\author{Sumyeong Ahn\thanks{Two authors contribute equally}\,\,\,, Jongwoo Ko, Se-Young Yun \\
  KAIST AI \\
  Seoul, Korea \\
  \texttt{\{sumyeongahn, jongwoo.ko,  yunseyoung\}@kaist.ac.kr} \\
}

\begin{document}

\maketitle

\begin{abstract}
Class imbalance problems frequently occur in real-world tasks, and conventional deep learning algorithms are well known for performance degradation on imbalanced training datasets. 
To mitigate this problem, many approaches have aimed to balance among given classes by \emph{re-weighting} or \emph{re-sampling} training samples. 
These re-balancing methods increase the impact of minority classes and reduce the influence of majority classes on the output of models. 
However, the extracted representations may be of poor quality owing to the limited number of minority samples.
To handle this restriction, several methods have been developed that increase the representations of minority samples by leveraging the features of the majority samples.  
Despite extensive recent studies, no deep analysis has been conducted on determination of classes to be augmented and strength of augmentation has been conducted.
In this study, we first investigate the correlation between the degree of augmentation and class-wise performance, and find that the proper degree of augmentation must be allocated for each class to mitigate class imbalance problems. Motivated by this finding, we propose a simple and efficient novel curriculum, which is designed to find the appropriate per-class strength of data augmentation, called \alg: \textbf{\code{CU}}rriculum of \textbf{\code{D}}ata \textbf{\code{A}}ugmentation for long-tailed recognition.
\alg can simply be integrated into existing long-tailed recognition methods. We present the results of experiments showing that \alg~effectively achieves better generalization performance compared to the state-of-the-art method on various imbalanced datasets such as CIFAR-100-LT, ImageNet-LT, and iNaturalist 2018.  
\footnote{Code is available at \href{https://github.com/sumyeongahn/CUDA_LTR}{Link}}
\vspace{-10pt}
 \end{abstract}
\section{Introduction}
\label{sec:intro}

Deep neural networks (DNNs) have significantly improved over the past few decades on a wide range of tasks~\cite{he2017mask, redmon2017yolo9000, qi2017pointnet}. This effective performance is made possible by come from well-organized datasets such as MNIST~\cite{lecun1998gradient}, CIFAR-10/100~\cite{krizhevsky2009learning}, and ImageNet~\cite{russakovsky2015imagenet}. However, as \citet{van2018inaturalist} indicated, gathering such balanced datasets is notoriously difficult in real-world applications. In addition, the models perform poorly when trained on an improperly organized dataset, \eg in cases with class imbalance, because minority samples can be ignored due to their small portion.

The simplest solution to the class imbalance problem is to prevent the model from ignoring minority classes. To improve generalization performance, many studies have aimed to emphasize minority classes or reduce the influence of the majority samples. Reweighting~\cite{cao2019learning, menon2021longtail} or resampling~\cite{buda2018systematic, van2007experimental} are two representative methods that have been frequently applied to achieve this goal. (i) \emph{Reweighting} techniques increase the weight of the training loss of the samples in the minority classes. (ii) \emph{Resampling} techniques reconstruct a class-balanced training dataset by upsampling minority classes or downsampling majority classes. 

Although these elaborate rebalancing approaches have been adopted in some applications, limited information on minority classes due to fewer samples remains problematic. To address this issue, some works have attempted to spawn minority samples by leveraging the information of the minority samples themselves. For example,~\citet{chawla2002smote, ando2017deep} proposed a method to generate interpolated minority samples. Recently~\cite{kim2020m2m, chu2020feature, park2022majority} suggested enriching the information of minority classes by transferring information gathered from majority classes to the minority ones. For example, \citet{kim2020m2m} generated a balanced training dataset by creating adversarial examples from the majority class to consider them as minority.

Although many approaches have been proposed to utilize data augmentation methods to generate various information about minority samples, relatively few works have considered the influence of the degree of augmentation of different classes on class imbalance problems. In particular, few detailed observations have been conducted as to which classes should be augmented and how intensively.

\begin{figure*}[t]
    \centering
    \vspace{-10pt}
\includegraphics[width=.9\textwidth]{fig/intuition_revise.pdf}
    \vspace{-5pt}
    \caption{Motivation of \alg.
    If one half of the classes (\eg class indices in -) are strongly augmented, the \rebut{averaged accuracy} of the other half of the classes (\ie in -) increases. \rebut{The heatmaps in the first and the second rows present the accuracy for class indices in - and -, respectively. Also, each point in the plots means the accuracy under corresponding augmentation strength.} This phenomenon is also observed in the imbalanced case in which the top first half (major\rebut{; the first row}) have more samples than the second half classes (minor\rebut{; the second row}). Setup and further analysis are described in~\autoref{app:figure_1}.}
    \vspace{-20pt}
    \label{fig:intuition}
\end{figure*}

To this end, we first consider that controlling the strength of class-wise augmentation can provide another dimension to mitigate the class imbalance problem. In this paper, we use the number of augmentation operations and their magnitude to control the extent of the augmentation, which we refer to herein as its strength, \eg a strength parameter of  means that two randomly sampled operations with a pre-defined magnitude index of  are used.

Our key finding is that class-wise augmentation improves performance in the non-augmented classes while that for the augmented classes may not be significantly improved, and in some cases, performances may even decrease. As described in~\autoref{fig:intuition}, regardless of whether a given dataset is class imbalanced, conventional class imbalance methods show similar trends: when only the major classes are strongly augmented (\eg  strength ), the performance of majority classes decreases, whereas that for the minority classes have better results. \rebut{To explain this finding, we further} find that \rebut{strongly augmented classes get diversified feature representation,} preventing the growth of the norm of a linear classifier for corresponding classes. \rebut{As a result, the softmax outputs of the strongly augmented classes are reduced, and thus the accuracy of those classes decreases.}
It is described in~\autoref{app:figure_1}. 
This result motivates us to find the proper augmentation strength for each class to improve the performance for other classes while maintaining its own performance.

\myparagraph{Contribution.}
We propose a simple algorithm called \textbf{\code{CU}}rriculum of \textbf{\code{D}}ata \textbf{\code{A}}ugmentation (\alg) to find the proper class-wise augmentation strength for long-tailed recognition. Based on our motivation, we have to increase the augmentation strength of majorities for the performance of minorities when the model successfully predicts the majorities. On the other hand, we have to lower the strength of majorities when the model makes wrong predictions about majorities. 
The proposed method consists of two modules, which compute a level-of-learning score for each class and leverage the score to determine the augmentation. 
Therefore, \alg increases and decreases the augmentation strength of the class that was successfully and wrongly predicted by the trained model. 
To the best of our knowledge, this work is the first to suggest a class-wise augmentation method to find a proper augmentation strength for class imbalance problem.

We empirically examine performance of \alg on synthetically imbalanced datasets such as CIFAR-100-LT~\cite{cao2019learning}, ImageNet-LT~\cite{liu2019large}, and a real-world benchmark, iNaturalist 2018~\cite{van2018inaturalist}. With the high compatibility of \alg, we apply our framework to various long-tailed recognition methods and achieve better performance compared to the existing long-tailed recognition methods. Furthermore, we conduct an extensive exploratory analysis to obtain a better understanding of \alg. The results of these analyses verify that \alg exhibits two effects that mitigate class imbalance, including its balanced classifier and improved feature extractor.
 \vspace{-10pt}
\section{Related works}
\label{sec:related}
\vspace{-10pt}

\myparagraph{Long-tailed Recognition (LTR).} The datasets with class imbalances can lead DNNs to learn biases toward training data, and their performance may decrease significantly on the balanced test data. To improve the robustness of such models to imbalance, LTR methods have been evolving in two main directions: (1) reweighting~\citep{cui2019class, cao2019learning, park2021influence} methods that reweight the loss for each class by a factor inversely proportional to the number of data points, and (2) resampling methods~\citep{kubat1997addressing, chawla2002smote, ando2017deep} that balance the number of training samples for each class in the training set. However, studies along these lines commonly sacrifice performance on majority classes to enhance that on minority classes, because the overfitting problem occurs with limited information on minority classes as a result of increasing the weight of a small number of minority samples.

Several methods have recently been developed to alleviate the overfitting issues in various categories: (1) two-stage training~\cite{cao2019learning, kang2019decoupling, liu2019large}, (2) ensemble methods~\cite{zhou2020bbn, xiang2020learning, wang2021longtailed, cai2021ace}, and (3) contrastive learning approach~\cite{kang2021exploring, cui2021parametric, zhu2022balanced, li2022nested, li2022targeted}. To re-balance the classifier layers after achieving a good representation on the imbalanced training dataset in an early phase, \citet{cao2019learning} proposed deferred resampling (DRS) and reweighting (DRW) approaches. \citet{kang2019decoupling} decoupled the learning procedure into representation learning and training linear classifier, achieved higher performance than previous balancing methods. \citet{wang2021longtailed} and \citet{cai2021ace} suggested efficient ensemble methods using multiple experts with a routing module and a shared architecture for experts to capture various representations. \citet{liu2022selfsupervised} found that self-supervised representations are more robust to class imbalance than supervised representations, and some works have developed supervised contrastive learning methods~\citep{khosla2020supervised} for imbalanced datasets~\citep{cui2021parametric, zhu2022balanced, li2022targeted}.

Another line of research has considered augmentation methods in terms of both input and feature spaces \cite{kim2020m2m, chu2020feature, li2021metasaug}. Recently, \citet{park2022majority} mixed minority and majority images by using CutMix with different sampling strategies to enhance balancing and robustness simultaneously. These methods commonly focus on utilizing the rich context of majority samples to improve the diversity of minority samples. Moreover, these augmentation-based methods are relatively in easy to apply orthogonally with other LTR methods.


\myparagraph{Data Augmentation (DA).} DA has been studied to mitigate overfitting which may occur due to a lack of data samples. 
Some works have been proposed to erase random parts of images to enhance the generalization performance of neural networks~\cite{devries2017improved, zhong2020random, kumar2017hide, choe2019attention}. Recently, variants of MixUp~\citep{zhang2017mixup} have been proposed; this method combines two images with specific weights~\citep{tokozume2018between, guo2019mixup, takahashi2018ricap, devries2017improved, verma2019manifold}. By aggregating two approaches, CutMix~\citep{yun2019cutmix} was proposed to erase and replace a small rectangular part of an image into another image.
In another line of research, methods have been proposed to automatically configure augmentation operations~\cite{cubuk2019autoaugment, lim2019fast, li2020dada, hataya2020faster, gudovskiy2021autodo}. In addition, \citet{cubuk2020randaugment} randomly selected augmentation operations using the given hyperparameters of the number of sampling augmentation and their magnitudes. Recently, class-wise or per-sample auto-augmentation methods have also been proposed~\cite{cheung2021adaaug, rommel2021cadda}. \section{\textbf{\underline{CU}}rriculum of \textbf{\underline{D}}ata \textbf{\underline{A}}ugmentation for Long-Tailed Recognition}
\label{sec:method}
\vspace{-10pt}


The core philosophy of \alg is to \emph{``generate an augmented sample that becomes the most difficult sample without losing its original information.''} In this section, we describe design of \alg in terms of two parts: (1) a method to generate the augmented samples based on the given strength parameter, and (2) a method to measure a Level-of-Learning (LoL) score for each class.


\subsection{Problem Formulation of Long-tailed Recognition}


Suppose that the training dataset  is composed of images with size , , and their corresponding labels .  is a set of class , \ie . Without loss of generality, we assume , where  denotes the cardinality of the set . We denote the  and . LTR algorithms, , mainly focus on training the model  with parameter  when the class distribution of training dataset  and test dataset  are not identical. More precisely,  is highly imbalanced while  is balanced, \ie uniform distribution.


\subsection{Curriculum of Data Augmentation}

In this section, we describe our proposed DA with strength parameter, and the methods used to measured the LoL score. Then, we integrate the two methods in a single framework to propose \alg.

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.85\textwidth]{fig/algorithm.pdf}
    \caption{Algorithm overview. \alg is composed of two main parts: (1) strength-based augmentation and (2) Level-of-Learning (LoL) score. To control the difficulty of augmented images, strength-based augmentation utilizes two values, the number of augmentations and their magnitudes. We use the strength-based augmentation module to score the LoL. Based on the measured LoL score, \alg generates adequately augmented images for LTR algorithms.}
    \label{fig:algorithm}
    \vspace{-10pt}
\end{figure*}


\myparagraph{DA with a strength parameter.}
Let us assume that there exist pre-defined  augmentation operations. We utilize visual augmentation operations which is indexed as , \eg Gaussian blur, Rotation, Horizontal flip. Each augmentation operation  has its own pre-defined augmentation magnitude function  where the strength parameter . These operations are described in detail along with each magnitude functions in~\autoref{app:augmentation}.

Given an augmentation strength parameter  and an input image , we model a sequence of augmentation operations   as follows:


where,  and  denote categorical and discrete uniform distributions, respectively. 
The sequential augmentation operation  samples  operations from the categorical distribution when the probability of seeing the operations follows uniform distribution. 
As depicted on the left side~\autoref{fig:algorithm}, suppose that the random sampled augmentations , , and  are brightness, X-shift, and Y-shift, respectively. Then,  outputs an image in which bright is raised by  and moved by  on the x-axis and shifted by  on the y-axis.


\scalebox{0.8}{
\begin{minipage}{0.75\textwidth}
\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetAlgoLined
    \SetNoFillComment
    \LinesNotNumbered 
    \caption{\textbf{CU}rriculum of \textbf{D}ata \textbf{A}ugmentation}
    \label{alg:cuda}
    \KwInput{LTR algorithm , training dataset , train epochs , aug. probability , threshold , number of sample coefficient . }
    \KwOutput{trained model }
\textbf{Initialize:}  \\
    \For{} 
    {   
        Update  \quad \tcp*{Alg.~\ref{alg:LoL}} 
        Generate   where   
         \\
        Run LTR algorithm using , \ie .
    }
\end{algorithm}
\end{minipage}}
\hfill
\scalebox{0.75}{
\begin{minipage}{0.52\textwidth}
\begin{algorithm}[H]
    \setstretch{1.177}
    \DontPrintSemicolon
    \SetAlgoLined
    \SetNoFillComment
    \LinesNotNumbered 
    \caption{: Update LoL score}
    \label{alg:LoL}
    \KwInput{, , , , }
    \KwOutput{updated }
    \textbf{Initialize:} check  \\
    \For{}   
    {   
        \textcolor{blue}{/*   */} \\
        Sample   s.t.  \\
        Compute  \\
        \If{ }
{check ; \textbf{break}}
}
    \textbf{if} check  \textbf{then}  \\
    \textbf{else} 
\end{algorithm}
\end{minipage}}

\myparagraph{Level-of-Learning (LoL).} To control the strength of augmentation properly, we check whether the model can correctly predict augmented versions without losing the original information. To enable this, we define the LoL for each class  at epoch , \ie , which is adaptively updated as the training continues as follows:






where 


Here,  is threshold hyperparameter,  is coefficient of the number of samples used to updating LoL.  is a function which outputs the number of correctly predicted examples by the model  among  randomly augmented samples with strength .  is defined as: 

Note that  is a randomly sampled subset of  with replacement and its size is .





The key philosophy of this criterion is two fold. (1) If samples in the class  are trained sufficiently with an augmentation strength of , the model is ready to learn a more difficult version with augmentation strength of . In contrast, if the model predicts incorrectly, it should re-learn the easier sample with an augmentation strength of . (2) As the strength parameter increases, the number of candidates for the sequential augmentation operation  increases exponentially. For example, the amount of increment is  when  is increases to . To control the LoL in a large sequential augmentation operation space, we take more random samples to check as the strength parameter gets bigger. In our experiments, linearly increasing the number of samples to evaluate corresponding to the strength with a small additional computation time was sufficient.  is described in  \autoref{fig:algorithm} and Algorithm~\ref{alg:LoL}.





\myparagraph{Curriculum of DA.} By combining two components, including DA with a strength parameter and LoL, our \alg provides class-wise adaptive augmentation to enhance the performance of the others without losing its own information. As shown in~\autoref{fig:algorithm} and Algorithm~\ref{alg:cuda}, we measure the LoL score  for all classes in the training dataset to determine the augmentation strength for every epoch. Based on , we generate the augmented version  for  and train the model with the augmented samples. Additionally, we randomly use the original sample instead of the augmented sample with probability  so that the trained models do not forget the original information. In our experiments, this operation improved performance robustly on a wide range of  values. The results are provided in Section~\ref{exp:analysis}.

\myparagraph{Advantage of \alg design.}
Our proposed approach mainly has three advantages. (1) \alg adaptively finds proper augmentation strengths for each class without need for a validation set. 
(2) Following the spirits of existing curriculum learning methods~\cite{hacohen2019power, zhou2020curriculum, wu2021when}, \alg enables modeling by first presenting easier examples earlier during training to improve generalization. This encourages the model to learn difficult samples (\ie within high augmentation strength) better. (3) Moreover, owing to the universality of data augmentation, \alg is easily compatible with other LTR algorithms, such as~\cite{cao2019learning, ren2020balanced, wang2021longtailed}.





















 \section{Experiments}
\label{sec:exp}
In this section, we present empirical evaluation, the results of which demonstrate the superior performance of our proposed algorithm for class imbalance. We first describe the long-tailed classification benchmarks and implementations in detail (Section~\ref{exp:set}). Then, we describe the experimental results on several synthetic (CIFAR-100-LT, ImageNet-LT) and real-world (iNaturalist 2018) long-tailed benchmark datasets in Section~\ref{exp:result}. Moreover, we conduct additional experiments to obtain a better understanding of \alg, and this analysis is provided in Section~\ref{exp:analysis}.





\begin{table}[t!]
\begin{minipage}[b]{1.0\linewidth}
\caption{Validation accuracy on CIFAR-100-LT dataset.  are from \citet{park2022majority} and ,  are from the original papers~\cite{kim2020m2m, zhu2022balanced}. Other results are from our implementation. We format the first and second best results as \textbf{bold} and \underline{underline }. We report the average results of three random trials.}
\label{tab:cifar_200ep}
\centering
\resizebox{0.85\columnwidth}{!}{
\begin{tabular}{p{0.43\textwidth}||>
{\centering}p{0.09\textwidth}>
{\centering}p{0.09\textwidth}>
{\centering}p{0.09\textwidth}|>
{\centering}p{0.09\textwidth}>
{\centering}p{0.09\textwidth}>
{\centering\arraybackslash}p{0.09\textwidth}}
\thickhline
\multirow{2}{*}{Algorithm} 
& \multicolumn{3}{c|}{Imbalance Ratio (IR)} 
& \multicolumn{3}{c}{Statistics (IR 100)} \\
\cline{2-4} \cline{5-7}


                            & 100 & 50 & 10 
                            & Many & Med & Few \\ \hline
CE                          &     &     &  
                            &     &     &    \\ 
CE + CMO~\cite{park2022majority}
                            &           &          &  
                            &           &          &   \\
\rowcolor{LightCyan} 
CE + CUDA                   &     &     &  
                            &     &     &   \\
\rowcolor{LightCyan} 
CE + CMO + CUDA
                            &      &     &  
                            &      &     &   \\\hline
CE-DRW~\citep{cao2019learning}
                            &     &     &  
                            &     &     &   \\
CE-DRW + Remix~\citep{chou2020remix}
                            &      &     &  
                            & -         & -         & -  \\ 
\rowcolor{LightCyan} 
CE-DRW + CUDA               &  &     &  
                            &     &     &   \\ \hline

LDAM-DRW~\citep{cao2019learning}
                            &     &     &  
                            &     &     &   \\ 
LDAM + M2m~\cite{kim2020m2m}
                            &      & -         &  
                            & -          & -         & -  \\ 

\rowcolor{LightCyan} 
LDAM-DRW + CUDA
                            &     &     &  
                            &     &     &  \\ \hline
BS~\citep{ren2020balanced}
                            &      &    &  
                            &      &    &   \\
\rowcolor{LightCyan} 
BS + CUDA                   &     &     &  
                            &     &     &   \\ \hline
RIDE (3 experts)~\citep{wang2021longtailed}
                            &     &     &  
                            & -         & -         & -  \\
RIDE (3 experts)
                            &     &     &  
                            &     &     &    \\  
RIDE + CMO~\citep{park2022majority}
                            &     &     &  
                            & -         & -         & -  \\
RIDE + CMO
                            &     &     &  
                            &     &     &   \\ 
\rowcolor{LightCyan} 
RIDE (3 experts) + CUDA     &     &     &   
                            &     &     &   \\  \hline
BCL~\cite{zhu2022balanced}
                            &     &     &  
                            &     &     &   \\
\rowcolor{LightCyan} 
BCL + CUDA     
                            &     &     & 
                            &     &     &  \\
\thickhline
\end{tabular}}
\end{minipage}
\vspace{-7pt}
\end{table}





 
\subsection{Experimental setup}\label{exp:set}
\vspace{-10pt}
\myparagraph{Datasets.}
We evaluate \alg on the most commonly used long-tailed image classification tasks: CIFAR-100-LT~\cite{cao2019learning}, ImageNet-LT~\cite{liu2019large}, and iNaturalist 2018~\cite{van2018inaturalist}. CIFAR-100-LT and ImageNet-LT are provided with imbalanced classes by synthetically sampling the training samples. CIFAR-100-LT is examined with various imbalance ratios , where an imbalance ratio is defined as . iNaturalist 2018 is a large-scale real-world dataset includes natural long-tailed imbalance. We utilize the officially provided datasets.

\myparagraph{Baselines.} We compare \alg with previous long-tailed learning algorithms , including cross-entropy loss (CE), two-stage approaches: CE-DRW~\cite{cao2019learning} and cRT~\cite{kang2019decoupling}, balanced loss approaches: LDAM-DRW~\cite{cao2019learning} and Balanced Softmax (BS; \citealt{ren2020balanced}), the ensemble method: RIDE with three experts~\cite{wang2021longtailed}, resampling algorithms: Remix~\cite{chou2020remix} and CMO~\cite{park2022majority}, and contrastive learning-based approach: BCL~\cite{zhu2022balanced}. We integrate \alg with CE, CE-DRW, LDAM-DRW, BS, RIDE, and BCL algorithms. For longer epochs, we compare \alg with PaCo~\cite{cui2021parametric}, BCL, and NCL~\cite{li2022nested}, by combining \alg with BCL and NCL. For a fair comparison of the computational cost, we train the network with the official one-stage implementation of RIDE (\ie without distillation and routing).

\myparagraph{Implementation.} For CIFAR-100-LT dataset, almost all implementations follow the general setting from~\citet{cao2019learning}, whereas cRT~\cite{kang2019decoupling}, BCL, NCL and RIDE follow the settings used in their original implementation. Following \citet{cao2019learning}, we use ResNet-32~\cite{he2016deep} as a backbone network for CIFAR-100-LT. The network is trained on SGD with a momentum of  and a weight decay of . The initial learning rate is  and a linear learning rate warm-up is used in the first  epochs to reach the initial learning rate. During training over  epochs, the learning rate is decayed at the th and th epochs by . 
For the ImageNet-LT and iNaturalist, the ResNet-50 is used as a backbone network and is trained for  epochs. The learning rate is decayed at the th and th epochs by . As with CIFAR, for cRT, RIDE, and BCL, we follow the original experimental settings of the official released code. For the hyperparameter values of \alg, we apply a  of  and  of  for all experiments. For , we set the values as  for CIFAR-100-LT and  for ImageNet-LT and iNaturalist 2018. The detailed implementation for baselines are in \autoref{app:implementation}.

\subsection{Experimental Results}
\label{exp:result}
In this section, we report the performances of the methods compared on the CIFAR-100-LT, ImageNet-LT, and iNaturalist 2018. We include four different categories of accuracy: all, many, med(ium), and few. Each represents the average accuracy of all samples, classes containing more than  samples,  to  samples, and under  samples, respectively.


\begin{table}[t!]
\begin{minipage}[b]{1.0\linewidth}
\caption{Validation accuracy on ImageNet-LT and iNaturalist 2018 datasets.  indicates reported results from the \citet{park2022majority} and  indicates those from the original paper~\cite{kang2019decoupling}.  means we train the network with the official code in an one-stage RIDE.}
\centering
\resizebox{0.9\columnwidth}{!}{
\begin{tabular}{p{0.4\textwidth}||>
{\centering}p{0.09\textwidth}>
{\centering}p{0.09\textwidth}>
{\centering}p{0.09\textwidth}|>
{\centering}p{0.09\textwidth}|>
{\centering}p{0.09\textwidth}>
{\centering}p{0.09\textwidth}>
{\centering}p{0.09\textwidth}|>
{\centering\arraybackslash}p{0.09\textwidth}}
\thickhline
\multirow{2}{*}{Algorithm} 
&  \multicolumn{4}{c|}{ImageNet-LT}  
& \multicolumn{4}{c}{iNaturalist 2018} \\
\cline{2-5} \cline{6-9}
                            & Many & Med & Few & All
                            & Many & Med & Few & All\\ \hline
CE                          
                            &     &     &     &  
                            &     &     &     &   \\
\rowcolor{LightCyan} 
CE + CUDA                   
                            &     &     &     &  
                            &     &     &  &  \\ \hline
CE-DRW~\cite{cao2019learning}
                            &     &     &     &  
                            &     &     &     &  \\
\rowcolor{LightCyan} 
CE-DRW + CUDA               
                            &     &     &     &  
                            &     &     &     &  \\ \hline
LWS~\cite{kang2019decoupling}
                            &     &     &     &  
                            &     &     &     &  \\
cRT~\cite{kang2019decoupling}
                            &     &     &     &  
                            &     &     &     &  \\
\rowcolor{LightCyan}
cRT + CUDA
                            &     &     &     & 
                            &     &     &     &  \\ \hline
LDAM-DRW~\cite{cao2019learning}
                            &     &     &     &  
                            & -         & -         & -         &  \\
\rowcolor{LightCyan} 
LDAM-DRW + CUDA             
                            &     &     &     &  
                            &     &     &     &  \\ \hline
BS~\cite{ren2020balanced}
                            &     &     &     &  
                            &     &     &     &  \\
\rowcolor{LightCyan} 
BS + CUDA                   
                            &     &     &     &  
                            &     &     &     &  \\ \hline
RIDE (3 experts)~\cite{wang2021longtailed}
                            &     &     &     &  
                            &     &     &     &  \\
RIDE + CMO~\cite{park2022majority}
                            &     &     &     &  
                            &     &     &     &  \\
\rowcolor{LightCyan} 
RIDE (3 experts) + CUDA     
                            &     &     &     &  
                            &     &  &     &  \\ \hline
BCL~\cite{zhu2022balanced}
                            &     &     &     & 
                            &     &     &     &  \\
\rowcolor{LightCyan}
BCL + CUDA     
                            &     &     &     &  
                            &     &     &     &  \\
\thickhline
\end{tabular}
}\label{tab:in_inat}
\end{minipage}
\end{table} \begin{center}
\begin{table}[t!]
\begin{minipage}{0.252\linewidth}
\caption{Comparison for CIFAR-LT-100 performance on ResNet-32 with 400 epochs. }
\label{tab:cifar_other}
\centering
\resizebox{1.0\columnwidth}{!}{


\begin{tabular}{l||cc}
\thickhline
\multirow{2}{*}{Algorithm} 
& \multicolumn{2}{c}{Imbalance Ratio} \\
\cline{2-3} 

                            & 100 & 50 \\ \hline
PaCo
                            &      &       \\
BCL
                            &  &   \\
NCL
                            &  &    \\ \hline
\rowcolor{LightCyan} 
BCL + CUDA     
                            &      &    \\
\rowcolor{LightCyan} 
NCL + CUDA     
                            &      &    \\ \thickhline

\end{tabular}
}
\end{minipage}
\hspace{0.15in}
\begin{minipage}{0.695\linewidth}
\caption{Augmentation analysis on CIFAR-100-LT with IR 100. AA~\cite{cubuk2019autoaugment}, FAA~\cite{lim2019fast}, DADA~\cite{li2020dada}, and RA~\cite{cubuk2020randaugment} with  policies are used. C, S, I represent CIFAR, SVHN, and ImageNet policy.}
\resizebox{1.0\columnwidth}{!}{
\begin{tabular}{lccccccccccccc>{\columncolor{LightCyan}}c}
\thickhline
& \multirow{2}{*}{Vanilla} &&  \multicolumn{3}{c}{AA} &&  \multicolumn{2}{c}{FAA} &&  \multicolumn{2}{c}{DADA} &&  \multirow{2}{*}{RA}  &  \\ 


                            & && C & S & I && C & I && C & I &&&\multirow{-2}{*}{\cellcolor{LightCyan}CUDA} \\ \hline
CE                          
                            &  &&     &     &     &&  &     &&     &     &&  &  \\
CE-DRW                          
                            &  &&     &     &     &&  &     &&     &     &&  &  \\
LDAM-DRW                          
                            &  &&     &     &     &&  &     &&     &     &&  &  \\
BS                          
                            &  &&     &     &     &&  &     &&     &     &&  &  \\
RIDE (3 experts)                           
                            &  &&     &     &     &&  &     &&     &     &&  &  \\

\thickhline
\end{tabular}
\label{tab:dataug}}
\end{minipage}
\end{table}
\vspace{-30pt}
\end{center}


































 
\myparagraph{CIFAR-100-LT.} In \autoref{tab:cifar_200ep}, we report the performance when \alg~is applied to the various algorithms: CE, CE-DRW~\cite{cao2019learning}, LDAM-DRW~\cite{cao2019learning}, BS~\cite{ren2020balanced}, RIDE~\cite{wang2021longtailed} with 3 experts, RIDE+CMO~\cite{park2022majority}, and BCL~\cite{zhu2022balanced}.
Compared to the cases without \alg, balanced validation performance is increased when we apply the proposed approach. 

Recently, some works \cite{cui2021parametric, alshammari2022long, zhu2022balanced, li2022nested} have shown impressive performances with diverse augmentation strategies and longer training epochs. For a fair comparison with these methods, we examine \alg using the same experimental setups from PaCo (\citealt{cui2021parametric}; 400 epochs with batch size of 64). Table~\ref{tab:cifar_other} shows that augmented images using \alg can enhance LTR performance compared to the other baselines. In particular, \alg with NCL obtains the best performance over  epochs. As noted by~\citet{li2022nested}, the NCL algorithm utilizes six times as much memory compared to the vanilla architecture with three experts. Hereinafter in large-scale benchmarks, we focus on the cases with similar network size. 

\myparagraph{ImageNet-LT and iNaturalist 2018.} To evaluate the performance of \alg on larger datasets, we conduct experiments on ImageNet-LT~\cite{liu2019large} and iNaturalist 2018~\cite{van2018inaturalist}. Table~\ref{tab:in_inat} summarizes the performance of various LTR methods and the performance gain when integrated with \alg. Our proposed method consistently improves performance regardless of the LTR method and target dataset by simply adding class-wise data augmentation without complicated methodological modification. Additionally, to evaluate the performance gain of \alg on other architectures, we experiment with \alg on ImageNet-LT with ResNet-10~\cite{liu2019large} and ResNeXt-50~\cite{xie2017aggregated}, as reported in \autoref{app:analysis}.

\vspace{-3pt}
\begin{figure}[!t]
  \centering
  \begin{subfigure}{0.195\linewidth}
\includegraphics[width=\linewidth]{fig/CE_stdev.pdf}\\
            \includegraphics[width=\linewidth]{fig/ce_align.pdf}
            \vspace{-15pt}
          \caption{CE}
  \end{subfigure}
  \begin{subfigure}{0.195\linewidth}
\includegraphics[width=\linewidth]{fig/CE-DRW_stdev.pdf}\\
            \includegraphics[width=\linewidth]{fig/ce-drw_align.pdf}
            \vspace{-15pt}
          \caption{CE-DRW}
  \end{subfigure}
  \begin{subfigure}{0.195\linewidth}
\includegraphics[width=\linewidth]{fig/LDAM_stdev.pdf}\\
            \includegraphics[width=\linewidth]{fig/ldam-drw_align.pdf}
            \vspace{-15pt}
          \caption{LDAM-DRW}
  \end{subfigure}
  \begin{subfigure}{0.195\linewidth}
\includegraphics[width=\linewidth]{fig/BS_stdev.pdf}\\
            \includegraphics[width=\linewidth]{fig/bs_align.pdf}
            \vspace{-15pt}
          \caption{BS}
  \end{subfigure}
  \begin{subfigure}{0.195\linewidth}
\includegraphics[width=\linewidth]{fig/RIDE_stdev.pdf}\\
            \includegraphics[width=\linewidth]{fig/ride_align.pdf}
            \vspace{-15pt}
          \caption{RIDE}
  \end{subfigure}
  \vspace{-7pt}
  \caption{Analysis of how \alg improves long-tailed recognition performance, classifier weight norm (top row) and feature alignment \rebut{gain} (bottom row) of the CIFAR-100-LT validation set. Notably that weight norm and feature alignment represent class-wise weight magnitude of classifier and ability of feature extractor, respectively. The detailed analysis is described in Section~\ref{exp:analysis}.}
  \vspace{-7pt}
  \label{fig:output_analysis}
\end{figure}



%
 
\begin{figure}[!t]
  \centering
  \begin{subfigure}{0.195\linewidth}
          \includegraphics[width=\linewidth]{fig/CE_Heat.pdf}
          \vspace{-16pt}
          \caption{CE}
  \end{subfigure}
\begin{subfigure}{0.195\linewidth}
          \includegraphics[width=\linewidth]{fig/CE-DRW_Heat.pdf}
          \vspace{-16pt}
          \caption{CE-DRW}
  \end{subfigure}
  \begin{subfigure}{0.195\linewidth}
          \includegraphics[width=\linewidth]{fig/LDAM_Heat.pdf}
          \vspace{-16pt}
          \caption{LDAM-DRW}
  \end{subfigure}
\begin{subfigure}{0.195\linewidth}
          \includegraphics[width=\linewidth]{fig/BS_Heat.pdf}
          \vspace{-16pt}
          \caption{BS}
  \end{subfigure}
\begin{subfigure}{0.195\linewidth}
          \includegraphics[width=\linewidth]{fig/RIDE_Heat.pdf}
          \vspace{-16pt}
          \caption{RIDE}
  \end{subfigure}
  \vspace{-7pt}
  \caption{Evolution of LoL score on various algorithms, CE, CE-DRW, LDAM-DRW, BS, and RIDE.  }
  \label{fig:curriculum}
  \vspace{-15pt}
\end{figure}
 
\vspace{-2pt}
\subsection{Analysis}\label{exp:analysis}
\vspace{-2pt}
We design our analyses to answer the following questions. (1) How does \alg perform? (2) Does \alg perform better than other augmentation methods? (3) How does LoL score change over training epochs when combined with various LTR methods? (4) Which part of \alg is important to improved performance? These analyses provide additional explanations to understand \alg. All experiments are conducted on CIFAR-100-LT with imbalance ratio of .

\myparagraph{How does \alg mitigate the class imbalance problem?}
To deeply understand \alg, we observe two types of metrics: 
(1) variance of weight L1-Norm of linear classifier between each class
(2) feature alignment gain for each class (\ie cosine similarity with and without \alg) on validation dataset.
The classifier weight norm is usually used to measure how balanced the model consider the input from a class-wise perspective~\cite{kang2019decoupling, alshammari2022long}. Feature alignment, especially feature cosine similarity amongst samples belonging to the same class, is a measure of the extent to which the extracted features are aligned~\cite{oh2021boil}. As shown in~\autoref{fig:output_analysis}, \alg has two forces for alleviating imbalance. For all cases, \alg reduces the variance of the weight norm (\ie balance the weight norm), and thus the trained model consider the minority classes in a balanced manner. Note that because LDAM-DRW and RIDE utilize a cosine classifier (\ie utilizing L2 normalized linear weight), their standard deviation scale is quite different from those other methods. Because LDAM-DRW, BS, and RIDE include balancing logic in their loss function, they exhibit lower variance reduction compared to the CE and CE-DRW. Second, as shown in the bottom row in~\autoref{fig:output_analysis}, \alg obtains feature alignment gains for almost all classes. This shows that \alg facilitates a network to learn to extract meaningful features.

\myparagraph{Compared with other augmentations.} To verify the impact of \alg, we examine the other augmentation methods as follows. We compare five augmentation methods, including AutoAugment (AA, \citealt{cubuk2019autoaugment}), Fast AutoAugment (FAA, \citealt{lim2019fast}), DADA~\cite{li2020dada}, RandAugment (RA, \citealt{cubuk2020randaugment}), and the proposed method \alg. Because AA, FAA, and DADA provide their policies searched by using CIFAR, SVHN (for AA), and ImageNet, we leverage their results. Furthermore, RA suggests using their parameter  for CIFAR, and we follow their guidelines. As shown in~\autoref{tab:dataug}, even though the \rebut{automated augmentation methods} use additional computation resources to search, \alg outperforms the other pre-searched augmentations. This shows that \alg is computationally efficient.



\myparagraph{Dynamics of LoL score.}
We evaluate how LoL scores vary with algorithms: CE, CE-DRW, LDAM-DRW, BS, and RIDE. Note that we set a lower class index (\ie ) as the most common class (\ie the number of samples is ), while an index of  represents the rarest class (\ie with five samples). As described in~\autoref{fig:curriculum}, as training progressed, the LoL score of all algorithms increase. After learning rate decay (\ie 160 epoch) all algorithms are able to learn to classify minority classes more easily than before. In particular, except for BS, the majority classes of most algorithms show a steep increment. The reason that BS exhibit a similar increasing speed for majority and minority classes is that it includes a module to balance the impact of majority and minority samples. \rebut{Furthermore, we found that CE-DRW and BS have similar end average accuracy in the case of applying \alg but different LoL score dynamics. We can conclude that LoL score on one category of classes has a high correlation with the performance of opposite classes from the observation that CE-DRW has higher and lower performance gain for many and few, respectively, than BS.} 


\begin{figure}[!t]
    \begin{subfigure}{0.24\linewidth}
            \includegraphics[width=1.\linewidth]{fig/aug_prob.pdf}
            \vspace{-15pt}
            \caption{Aug prob. .}
            \label{fig:aug_prob}
    \end{subfigure}
    \begin{subfigure}{0.24\linewidth}
            \includegraphics[width=1.\linewidth]{fig/num_test.pdf}
            \vspace{-15pt}
            \caption{Num test .}
            \label{fig:num_test}
    \end{subfigure}
    \begin{subfigure}{0.24\linewidth}
          \includegraphics[width=1.\linewidth]{fig/acc_rate.pdf}
          \vspace{-15pt}
            \caption{Accept rate .}
          \label{fig:acc_rate}
    \end{subfigure}
    \begin{subfigure}{0.24\linewidth}
          \includegraphics[width=1.\linewidth]{fig/hyperopt_revise.pdf}
          \vspace{-15pt}
            \caption{Curriculum.}
          \label{fig:hyper_opt}
    \end{subfigure}
    \vspace{-5pt}
    \caption{Additional analysis of \alg. (a) sensitivity of augmentation probability , (b) sensitivity analysis of number of sample coefficient , (c) sensitivity of acceptance threshold , and (d) impact of curriculum. The dotted lines in (a), (b) and (c) represents the performance of CE.}
    \label{fig:analysis}
    \vspace{-13.5pt}
\end{figure}

\myparagraph{Parameter sensitivity.} For further analysis, we conduct a sensitivity analysis of hyperparameters in \alg. More precisely, we study three kinds of parameters, including augmentation probability ~(\autoref{fig:aug_prob}), number of tests ~(\autoref{fig:num_test}), and LoL update threshold ~(\autoref{fig:acc_rate}). We examine each hyperparameter sensitivity on a \alg case with RIDE and the remainder of the hyperparameters are fixed to the default values in Section~\ref{exp:set}. All results show that the performance gains of \alg decreases if the parameters are adjusted to make the augmentation too strong or weak. For example, the augmentation strength of all classes steeply increases when  becomes small. The strength cannot increase when  becomes large, and thus it cannot improve the performance of the model. Moreover, as shown in~\autoref{fig:num_test}, the performance of \alg increases as  increases. However, larger  spends computational overhead, we set  as  and obtained cost-effective performance gain.

\myparagraph{Impact of curriculum.} In addition to studying the impact of \alg, we examine its performance component-wise. In particular, we test the case where class-wise augmentation strength is searched based on the hyperparameter optimization algorithm. We check five cases overall: \rebut{baseline} algorithm, hyperparameter optimization (HO), re-searched DADA for CIFAR-100-LT, \alg without curriculum, (\ie re-training utilizing the final augmentation strength of \alg), and \alg. \rebut{We provide detailed description for each method in \autoref{app:hyperopt}.} As described in~\autoref{fig:hyper_opt}, \alg finds better augmentation strengths compare to the hyperparameter search case. This means that \alg exhibits not only a lower searching time but also obtains better augmentation strength. Moreover, by comparing the performance of with or without curriculum, the curriculum also can provide additional advance to the model to achieve better generalization. Additionally, as \autoref{fig:curriculum}, lower augmentation strength at the beginning of training is more effective than static higher augmentation strength. These results are consistent with the results of previous studies on curriculum learning methods~\cite{ zhou2020curriculum}. \section{Conclusion}
\label{sec:conclusion}
In this study, we proposed \alg to address the class imbalance problem. The proposed approach is also compatible with existing methods. To design a proper augmentation for LTR, we first studied the impact of augmentation strength for LTR. We found that the strength of augmentation for a specific type of class (\eg major class) could affect the performance of the other type (\eg minor class). From this finding, we designed \alg to adaptively find an appropriate augmentation strength without any further searching phase by measuring the LoL score for each epoch and determining the augmentation accordingly. To verify the superior performance of proposed approach, we examined each performance with various methods and obtained the best performance among the methods compared, including synthetically generated and real-world benchmarks. Furthermore, from our analyses, we validated that our \alg enhanced balance and feature extraction ability, which can consistently improve performance for majority and minority classes.

\section*{Acknowledgement}
This work was supported by Institute of Information \& communications Technology Planning \& Evaluation (IITP) grant funded by the Korea government (MSIT) (No.2019-0-00075, Artificial Intelligence Graduate School Program (KAIST), 10\%) and the Institute of Information \& communications Technology Planning \& Evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2022-0-00871, Development of AI Autonomy and Knowledge Enhancement for AI Agent Collaboration, 90\%) 
\bibliographystyle{iclr2023_conference}
\bibliography{ref}

\appendix
\newpage

\begin{center}
    \textbf{\Large{Appendix\\}}
    \textbf{\large{CUDA: Curriculum of Data Augmentation for Long-tailed Recognition}}
\end{center}

Owing to the page limitation of the main manuscript, we provide detailed information in this supplementary as follows. (1) In \autoref{app:figure_1}, we summarize the experimental setup of~\autoref{fig:intuition}, and further explain why augmentation on one side causes performance degradation on the opposite side. (2) In \autoref{app:implementation}, we describe in detail our experimental setting, including dataset configuration, data preprocessing, and training implementation. (3) In \autoref{app:analysis}, we show ImageNet-LT performance on different size and architecture networks, training time analysis, and accuracy on the balanced dataset case. (4) In \autoref{app:augmentation}, we present in detail the augmentation operations that \alg utilizes. (5) In~\autoref{app:hyperopt}, we describe the experimental setting of~\autoref{fig:hyper_opt}.

\section{Detail for \autoref{fig:intuition}}
\label{app:figure_1}
\subsection{Experimental Settings}
\myparagraph{Major and minor group decomposition.}
To check the impact of augmentation on majority and minority classes, we split the training dataset into two clusters. The majority cluster is the top  classes by sorting through the number of samples for each class. The bottom  classes are in the minority cluster. For simplicity, we utilize class indices of  to  as the majority and  to  as the minority, respectively. For the balanced case, we utilize  to  classes as cluster 1, and the others as cluster 2.

\myparagraph{Controlling augmentation strength.}
We set the augmentation strength as the number of augmentation and its augmentation magnitude by following the augmentation rule of \alg. For example, the samples in the majority classes with magnitude parameter  represents that they are augmented with randomly sampled  augmentations with their own pre-defined augmentation magnitude.

\myparagraph{Training setting.}
For heatmaps in~\autoref{fig:intuition}, we follow the training recipe of CIFAR-100-LT for CE case, \eg ResNet-32, learning rate of , and so on. Further details, hyperparameters, and datasets are described in~\autoref{sec:exp} and~\autoref{app:implementation}.

\begin{figure}[th]
  \centering
  \begin{minipage}{.49\textwidth}
    \centering
        \includegraphics[width=1\linewidth]{fig/balanced.pdf}
        \caption{Analysis on Balanced CIFAR-100.}
        \label{fig:balance_analysis}
    \end{minipage}
    \begin{minipage}{.49\textwidth}
    \centering
        \includegraphics[width=1\linewidth]{fig/imbalanced.pdf}
        \caption{Analysis on CIFAR-100-LT (IR ).}
        \label{fig:imbalance_analysis}
    \end{minipage}
\end{figure}

\subsection{Analysis}
\myparagraph{Analysis for \autoref{fig:intuition}.} To figure out the reason for the phenomena in \autoref{fig:intuition}, we conduct further analysis as shown in \autoref{fig:balance_analysis} and \autoref{fig:imbalance_analysis}. Our experimental setups are as follows:
\begin{itemize}
    \item Train the networks with three augmentation strategies, respectively (without, partial, and all), then measure the class-wise feature alignment and linear classifier weight norm for all networks. (Experiment 1)
    \item From a trained network without augmentation in Experiment 1, we freeze the feature extractor and train the linear classifier layer with augmenting partial classes. Then, we measure the class-wise L1-norm for all linear classifiers. (Experiment 2)
\end{itemize}
From the \autoref{fig:balance_analysis} and \autoref{fig:imbalance_analysis}, we have three observations from Experiment 1: 
\begin{enumerate}
    \item When we conduct augmentation only for partial classes (0-49 classes), the feature alignment for augmented classes of the training dataset is degraded compared to the non-augmented classes. This is because the augmentation classes have more diversified training data than non-augmentation classes, which leads to more diversification in feature space. We observe the balance between alignment between classes in the cases of without augmentation and with all augmentation since all classes have similar diversity. (See the first rows in Figure~\ref{fig:balance_analysis},~\ref{fig:imbalance_analysis})
    \item However, all three augmentation strategies have balanced class-wise feature alignment for the same test dataset. This tendency can be observed in both balanced and imbalanced datasets. This result is consistent with \citet{kang2019decoupling}. Furthermore, the values for feature alignment are increased when we conduct augmentation partially or all, compared to without augmentation. This result shows that augmentation enhances the feature extraction ability, which is consistent with conventional studies. (See the second rows in Figure~\ref{fig:balance_analysis},~\ref{fig:imbalance_analysis})
    \item When we conduct augmentation only for partial classes on a balanced dataset, the class-wise weight norm of the linear classifier is larger for non-augmentation classes. This result incurs performance improvement for non-augmentation classes and reduction for augmentation classes since this linear classifier has a tendency to classify non-augmented classes with larger weight values. However, we observe that class-wise weight norms are balanced in ``without augmentation'' and ``all augmentation'' cases. (See the third row in \autoref{fig:balance_analysis})
    \item We observe that the class-wise weight norm of the linear classifier is larger for majorities for all classes that have the same augmentation strength. These results are consistent with previous works~\cite{kang2019decoupling, alshammari2022long}. However, when we conduct augmentation only for majorities, the class-wise weight norm is more balanced. This phenomenon is similar to the balanced case in that partial augmentation incurs a reduction in the norm of the linear classifier for augmented classes. (See the third row in \autoref{fig:imbalance_analysis})
\end{enumerate}

\begin{figure}[th]
  \centering
  \begin{minipage}{.49\textwidth}
    \centering
        \includegraphics[width=1\linewidth]{fig/analysis_concept.pdf}
        \vspace{1pt}
        \caption{Concept of the impact of lower feature alignment on linear classifier.}
        \label{fig:analysis_concept}
    \end{minipage}\hfill
    \begin{minipage}{.49\textwidth}
    \centering
        \includegraphics[width=1\linewidth]{fig/Theta_distance.pdf}
        \caption{The difference of linear classifier norm  along training epoch.}
        \label{fig:theta_distance}
    \end{minipage}
\end{figure}

Our observations from Experiment 1 are highly consistent in both balanced and imbalanced datasets. The results in \autoref{fig:intuition}, \autoref{fig:balance_analysis} and \autoref{fig:imbalance_analysis} highly motivate the design of \alg. Moreover, our results for Experiment 2 can explain these observations as shown in \autoref{fig:analysis_concept} and \autoref{fig:theta_distance}.

We observe that in the presence of feature alignment degradation from augmentation, the corresponding norm is relatively small, as shown in \autoref{fig:analysis_concept}. This is because in the class that has lower feature alignment, the variation of the gradient for the linear classifier is larger than in the class with high feature alignment. As shown in \autoref{fig:theta_distance}, from Experiment 2, we observe that , the norm of class-wise difference of between current and initialize linear classifier parameters  , have smaller value in augmented classes than non-augmented classes. From our experimental analysis in~\autoref{fig:balance_analysis},~\ref{fig:imbalance_analysis}, and~\ref{fig:theta_distance}, we can conclude that augmentation breaks the consistency of feature alignment and it makes the weight norm of the linear classifier decreases.









%
 
\section{Implementation detail in \autoref{sec:exp}}
\label{app:implementation}
\subsection{Dataset Description}

\myparagraph{CIFAR-100-LT.} CIFAR-100-LT is a subset of CIFAR-100. Following \citet{wang2021longtailed, park2022majority, zhu2022balanced}, we use the same long-tailed version for a fair comparison. The number of samples of th class is determined as follows: (1) Compute the imbalanced factor , which reflects the degree of imbalance in the data. (2)  between  and  follows an exponential decay (\ie ). The imbalance factors used in the experiment are set to 100, 50, and 10.

\myparagraph{ImageNet-LT.} ImageNet-LT~\cite{liu2019large} is a modified version of the large-scale real-world dataset~\cite{russakovsky2015imagenet}. Subsampling is conducted by following the Pareto distribution with power value . It consists of K images of  classes in total. The most common or rare class has  or  images, respectively.



\myparagraph{iNaturalist 2018.} iNaturalist~\cite{van2018inaturalist} is a large-scale real-world dataset which consists of K images from  classes. It has long-tailed property by nature, with an extremely class imbalanced. In addition to long-tailed recognition, this dataset is also used for evaluating the fine-grained classification task.




\subsection{Data Preprocessing}
For data preprocessing, we follow the default settings of \citet{cao2019learning}. For CIFAR-100-LT, each side of the image is padded with 4 pixels, and a  crop is randomly selected from the padded image or its horizontal flip. For ImageNet-LT and iNaturalist 2018, after resizing each image by setting the shorter side to 256 pixels, a  crop is randomly sampled from an image or its horizontal flip. 

For BCL and NCL, which use AutoAugment~\cite{cubuk2019autoaugment} or RandAugment~\cite{cubuk2020randaugment} as default data augmentation, we apply them after random cropping by following their original papers~\cite{zhu2022balanced, li2022nested}. Then, we finally conduct \alg after all default augmentation operations, and then normalize the image with following mean and standard deviation values sequentially: CIFAR-100-LT ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), ImageNet-LT~((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), and iNaturalist 2019~((0.466, 0.471, 0.380), (0.195, 0.194, 0.192)).

\subsection{Detailed Implementation}\label{app:implementation_issues}
Because some official codes do not open their entire implementations, we re-implement by following the rules. For re-implementation, we reproduce the code based on their partial code and the authors' responses.

\myparagraph{RIDE.} We follow the officially offered code\footnote{https://github.com/frank-xwang/RIDE-LongTailRecognition}. Among various experimental configurations of official code~(\eg one-stage RIDE, RIDE-EA, Distill-RIDE), for fair comparison (to leverage similar computation resources), we utilize one-stage training (\ie one-stage RIDE) for all cases. We confirm that CMO~\cite{park2022majority} also utilizes this setup for RIDE + CMO from the response of the authors.

\myparagraph{CMO.} We re-implement all CMO results from their official code\footnote{https://github.com/naver-ai/cmo} in our work. However, the official code of CMO does not contain code for RIDE + CMO. Therefore, we re-implement by injecting the CMO part for BS in the official code (weighted sampler and mixup part) into the RIDE code. Furthermore, for iNaturalist 2018, we train the model for 100 epochs for a fair comparison with other methods (whereas the original RIDE + CMO is trained for 200 epochs on iNaturalist 2018).

\myparagraph{BCL.} The officially released code\footnote{https://github.com/FlamieZhu/Balanced-Contrastive-Learning} of BCL only contains ImageNet-LT and iNaturalist 2018. Whereas the official code applies a cosine classifier for ImageNet-LT and iNaturalist 2018, we apply an ordinary linear classifier for CIFAR-100-LT from the author's response. All hyperparameters are the same as the experiment settings of the original work~\cite{zhu2022balanced}.

\subsection{\rebut{Guideline for Hyper-parameter Tuning}}
\rebut{Although we did not tune the hyper-parameters extensively. However, we give a guideline to select the hyper-parameters.}

\rebut{
\myparagraph{The number of samples for updating LoL ().} We can set this value according to the given computing resources (\ie the largest  under computing resource constraint). This is because the performance improves as  increases from obtaining a definite LoL score by testing many samples. 
}

\rebut{
\myparagraph{The acceptance threshold ().} Our strategy for tuning gamma is to select the largest value in which at least one of LoL scores among all classes increases within 20 epochs. This is because for large-scale datasets, the network fail to infer even the easier-to-learn majority classes. Here is the detailed tuning strategy for .
\begin{itemize}
    \item We initially set  as 0.6.
    \item We decrease the threshold  by 0.1 points whenever it fails to raise any of LoL score for the first 20 training epochs.
\end{itemize}
We condcut this search on CE with CIFAR-100-LT with IR 100 and using the same  value of the other algorithms with remaining IR settings. Also, we conduct this search rule on ImageNet-LT with CE and use the same value to the other large-scale dataset, \ie iNaturalist 2018 with remaining algorithms.
}

\rebut{
\myparagraph{The augmentation probability ().} While we did not tune this hyper-parameter, we offer the guideline how to tune this value based on \autoref{fig:aug_prob}. As shown in \autoref{fig:aug_prob}, the shape of graph between  and performance is concave. Thanks to concavity, we think that it is easy to find the optimal value for this hyper-parameter. Note that the reason for the concavity is because the decision of  value has a trade-off between preserving the information of the original image and exploring diversified images. 
}

\rebut{
\myparagraph{Further sensitivity analysis on ImageNet-LT}
In Section~\ref{sec:exp}, we apply different values of  in CIFAR-100-LT (0.6) and large-scale datasets (0.4; ImageNet-LT and iNaturalist 2018). In addition to \autoref{fig:analysis}, we further conduct the sensitivity analysis for  on the ImageNet-LT to verify \alg works well robustly with different values of  on large-scale datasets. As shown in \autoref{tab:sensitivity_in}, our proposed method \alg is also robust to hyper-parameter selection for  not only the small datasets such as CIFAR-100-LT but also large-scale datasets.
\begin{table}[ht]
\centering
\caption{\rebut{Sensitivity analysis of  with BS on ImageNet-LT dataset}}\label{tab:sensitivity_in}
\resizebox{0.5\columnwidth}{!}{
\rebut{
\begin{tabular}{l|cccc}
\thickhline
  &    &    &    &    \\ \midrule
Acc. (\%) & 51.42 & 51.59 & 51.38 & 51.24 \\
\thickhline
\end{tabular}}}
\end{table} }





%
 
\section{Further analyses}
\label{app:analysis}
\begin{figure}[t]
    \centering
    \begin{minipage}{0.45\linewidth}
            \includegraphics[width=1.\linewidth]{fig/other_net.pdf}
            \caption{Network architecture.}
            \label{fig:resnext}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\linewidth}
        \vspace{5pt}
          \includegraphics[width=0.9\linewidth]{fig/time.pdf}
          \vspace{4pt}
          \caption{Training time.}
          \label{fig:time}
    \end{minipage}
\end{figure}

\myparagraph{Training Time Analysis.} \alg requires additional computation for computing LoL score. We measure the additional training time for adding \alg on various algorithms. As shown in~\autoref{fig:time}, when utilizing \alg additional training time is spent. However, the additional operation for searching the LoL score does not require a large value. For example, BS with \alg spends  time to obtain adequate augmentation strength. 

\myparagraph{Network Architecture Analysis.} We also present our ResNet-10~\cite{liu2019large} and ResNeXt-50~\cite{xie2017aggregated} experiments on the ImageNet-LT dataset in \autoref{fig:resnext}, respectively. These results show that \alg consistently improves performance regardless of network sizes and corresponding LTR methods.

\myparagraph{What if \alg is ran on the balanced dataset.}
We examine that if \alg is applied to the balanced case, \ie imbalance ratio is . As described in the Table~\ref{tab:balance} \alg obtains  accuracy gain, which is lower than the other auto augmentation methods. However, other autoaugmentation methods spend more computation time searching a good augmentation than \alg. Furthermore, as described in~\autoref{fig:curriculum}, \alg has higher performance than the others when the class imbalance dataset is given. 

\begin{table}[h]
    \centering
    \caption{Balanced case.  mark represents the reported value in~\cite{li2020dada}}
    \resizebox{0.4\textwidth}{!}{
    \begin{tabular}{c|cc}
            \thickhline
            Augmentation & Acc. & Searching time (Overhead) \\ \hline
            CE & 68.5 & - \\
            AutoAug & 70.7 &  GPU hours\\
            RandAug & 69.4 & - \\
            FAA & 70.7 &  GPU hours\\
            DADA & 70.9 &  GPU hours\\
            CUDA & 70.4 &  GPU hours \\
            \thickhline
    \end{tabular}}
    \label{tab:balance}
\end{table}

 
\section{Augmentation Preset}
\label{app:augmentation}
\begin{figure}[!t]
  \centering
  \begin{subfigure}[b]{0.16\linewidth}
      \includegraphics[width=\linewidth]{fig/aug_ex/raw.png}
      \caption{Raw}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/Flip.png}
          \caption{Flip}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/Mirror.png}
          \caption{Mirror}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/EdgeEnhance.png}
          \caption{Edge Enhance}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/Detail.png}
          \caption{Detail}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/Smooth.png}
          \caption{Smooth}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/AutoContrast.png}
          \caption{AutoContrast}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/Equalize.png}
          \caption{Equalize}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/Invert.png}
          \caption{Invert}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/GaussianBlur.png}
          \caption{Gaussian Blur}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/ResizeCrop.png}
          \caption{Resize Crop}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/Rotate.png}
          \caption{Rotate}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/Posterize.png}
          \caption{Posterize}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/Solarize.png}
          \caption{Solarize}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/SolarizeAdd.png}
          \caption{SolarizeAdd}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/Color.png}
          \caption{Color}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/Contrast.png}
          \caption{Contrast}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/Brightness.png}
          \caption{Brightness}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/Sharpness.png}
          \caption{Sharpness}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/ShearX.png}
          \caption{ShearX}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/ShearY.png}
          \caption{ShearY}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/TranslateXabs.png}
          \caption{Translate X}
  \end{subfigure}
  \begin{subfigure}[b]{0.16\linewidth}
          \includegraphics[width=\linewidth]{fig/aug_ex/TranslateYabs.png}
          \caption{Translate Y}
  \end{subfigure}
\end{figure}


\begin{table}[t!]
\caption{Description of augmentation operations utilized in \alg. We show the examples of each augmentation with maximum augmentation parameters.}
\centering
\resizebox{1.0\columnwidth}{!}{
\begin{tabular}{c|c|c}
\thickhline
Operation &  Parameter &  Description \\ \hline
\code{Flip} 
& On/Off
& Flip top and bottom \\ \hline


\code{Mirror} 
& On/Off
& Flip left and right \\ \hline


\code{Edge Enhancement} 
& On/Off
& Increasing the contrast of the pixels around the targeted edges \\ \hline


\code{Detail} 
& On/Off   
& Utilize convolutional kernel  \\ \hline


\code{Smooth} 
& On/Off   
& Utilize convolutional kernel \\ \hline


\code{AutoContrast} 
& On/Off
& Remove a specific percent of the lightest and darkest pixels\\ \hline


\code{Equalize} 
& On/Off   
& apply non-linear mapping to make uniform distribution\\ \hline


\code{Invert} 
& On/Off   
& Negate the image\\ \hline


\code{Gaussian Blur} 
& [0,2]
& Blurring an image using Gaussian function\\ \hline


\code{Resize Crop} 
& [1,1.3]  
& Resizing and center random cropping\\ \hline


\code{Rotate} 
& [0,30]
& Rotate the image\\ \hline


\code{Posterize} 
& [0,4]
& Reduce the number of bits for each channel\\ \hline


\code{Solarize} 
& [0,256]
& Invert all pixel values above a threshold\\ \hline


\code{SolarizeAdd} 
& [0,110]
& Adding value and run solarize\\ \hline


\code{Color} 
& [0.1, 1.9]
& Colorize gray scale values\\ \hline


\code{Contrast} 
& [0.1,1.9]
& Distance between the colors\\ \hline


\code{Brightness} 
& [0.1,1.9]
& Adjust image brightness\\ \hline


\code{Sharpness} 
& [0.1,1.9]
& Adjust image sharp\\ \hline


\code{Shear X} 
& [0,0.3]
& Shearing X-axis\\ \hline


\code{Shear Y} 
& [0,0.3]
& Shearing Y-axis\\ \hline


\code{Translate X} 
& [0,100]
& Shift X-axis\\ \hline


\code{Translate Y} 
& [0,100]
& Shifting Y-axis\\ \hline


\thickhline
\end{tabular}
}\label{tab:aug_description}
\end{table}
 \subsection{Data augmentation operations used in \alg.}
There have been numerous data augmentation operations in vision tasks. We used totally  augmentations for \alg with their own parameter set. Details of the operation set and parameters are described in Table~\ref{tab:aug_description}.  For augmentation magnitude parameter , we divide parameters into thirty values linearly. For example of, ShearX case, its max and min values are  and , respectively. Therefore, , thus .

\subsection{\rebut{Further analysis on augmentation preset}}
\rebut{To get further intuition on the effect of number of predefined augmentation operations, we conduct several exploratory experiments.}

\rebut{
\myparagraph{Validity of our main finding (\autoref{fig:intuition}) under a few predefined augmentation.}
The observation in \autoref{fig:intuition} is caused by minorities becoming relatively easy to learn since majorities have become difficult. Therefore, if the sample of majorities becomes difficult enough to learn, the same phenomenon as \autoref{fig:intuition} occurs regardless of the number of augmentation presets. To verify that our main finding is valid regardless of the number of predefined augmentations, we conduct the experimental with ten augmentation operations (Mirror, ShearX, Invert, Smooth, ResizeCrop, Color, Brightness, Sharpness, Rotate, AutoContrast). \autoref{tab:findings} describes the performance of (0,0), (0,4), (4,0), and (4,4) that each configuration denotes the augmentation strength of (majority; top 50 class, minor; bottom 50 class). Through the results, we verify that the finding in \autoref{fig:intuition} is valid even in a small number of predefined augmentation operations.
\begin{table}[ht]
\centering
\caption{\rebut{The performance comparison between different augmentation strength on major (class indices 0-49) and minor (class indices 50-99) categories. }}\label{tab:findings}
\resizebox{1.0\columnwidth}{!}{
\rebut{
\begin{tabular}{l|c|cccc|l|c|cccc}
\thickhline
                          & (major, minor) & Many & Med & Few & All &   & (major, minor) & Many & Med & Few & All \\ \midrule
\multirow{4}{*}{CE}       & 0,0            & 66.2                     & 37.3                    & 8.2                     & 38.7                    & \multirow{4}{*}{CE-DRW} & 0,0                  & 62.8                     & 41.7                    & 16.2                    & 41.4                    \\
                          & 0,4            & 69.7                     & 30.4                    & 2.3                     & 35.7                    &                         & 0,4                  & 65.9                     & 37.2                    & 10.6                    & 39.3                    \\
                          & 4,0            & 60.9                     & 39.3                    & 12.8                    & 38.9                    &                         & 4,0                  & 49.3                     & 45.2                    & 28.3                    & 41.6                    \\
                          & 4,4            & 67.0                     & 34.5                    & 4.7                     & 37.0                    &                         & 4,4                  & 56.6                     & 46.6                    & 24.6                    & 43.5                    \\ \midrule
\multirow{4}{*}{LDAM-DRW} & 0,0            & 62.8                     & 42.3                    & 19.0                    & 42.5                    & \multirow{4}{*}{BS}     & 0,0                  & 61.6                     & 42.3                    & 23.0                    & 43.3                    \\
                          & 0,4            & 70.1                     & 34.3                    & 6.4                     & 38.5                    &                         & 0,4                  & 66.9                     & 37.9                    & 10.8                    & 39.9                    \\
                          & 4,0            & 52.3                     & 42.0                    & 27.7                    & 41.3                    &                         & 4,0                  & 48.7                     & 42.5                    & 28.7                    & 40.5                    \\
                          & 4,4            & 61.1                     & 43.4                    & 17.3                    & 41.8                    &                         & 4,4                  & 56.3                     & 44.2                    & 23.0                    & 42.1                    \\ \midrule
\multirow{4}{*}{RIDE}     & 0,0            & 67.7                     & 51.5                    & 26.7                    & 49.7                    &  \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{}     & \multicolumn{1}{l}{}    & \multicolumn{1}{l}{}    & \multicolumn{1}{l}{}    \\
                          & 0,4            & 70.5                     & 36.8                    & 7.7                     & 39.9                    & \multicolumn{1}{r}{}    & \multicolumn{1}{r}{} & \multicolumn{1}{l}{}     & \multicolumn{1}{l}{}    & \multicolumn{1}{l}{}    & \multicolumn{1}{l}{}    \\
                          & 4,0            & 56.6                     & 44.5                    & 27.2                    & 43.6                    & \multicolumn{1}{r}{}    & \multicolumn{1}{r}{} & \multicolumn{1}{l}{}     & \multicolumn{1}{l}{}    & \multicolumn{1}{l}{}    & \multicolumn{1}{l}{}    \\
                          & 4,4            & 62.3                     & 44.5                    & 21.6                    & 43.9                    & \multicolumn{1}{r}{}    & \multicolumn{1}{r}{} & \multicolumn{1}{l}{}     & \multicolumn{1}{l}{}    & \multicolumn{1}{l}{}    & \multicolumn{1}{l}{}   \\
\thickhline
\end{tabular}}}
\end{table} }

\rebut{
\myparagraph{Effect of number of predefined augmentation.}
We further analyze the impact of predefined augmentation operations ( in \autoref{fig:algorithm}); we additionally experiment by replacing the augmentation preset in \autoref{app:augmentation} with the following two augmentation presets: (1) 10 randomly sampled augmentations (Mirror, ShearX, Invert, Smooth, ResizeCrop, Color, Brightness, Sharpness, Rotate, AutoContrast) and (2) RandAugment\,\cite{cubuk2020randaugment} preset that consists of (AutoContrast, Equalize, Invert, Rotate, Posterize, Solarize, SolarizeAdd, Color, Contrast, Brightness, Sharpness, ShearX, ShearY, CutoutAbs, TranslateXabs, TranslateYabs). \autoref{tab:augment_number} demonstrates that the accuracy slightly increases when the size of the augmentation preset increases. However, the gap between the RandAugment preset (14 operations) and our original preset (22 operations) is small compared to the gap between the vanilla (without \alg case) and the RandAugment case. These results verify our belief that the impact of the number of predefined augmentations is small.
\begin{table}[ht]
\centering
\caption{\rebut{The performance comparison of \alg with different number () of predefined augmentation operations.}}\label{tab:augment_number}
\resizebox{0.8\columnwidth}{!}{
\rebut{
\begin{tabular}{l|c|ccccc}
\thickhline
                                                & Category & CE & CE-DRW & LDAM-DRW & BS & RIDE \\ \midrule
\multirow{4}{*}{Vanilla (w/o augmentation)} & Many                         & 66.2                   & 62.8                       & 62.8                         & 61.6                   & 67.7                     \\
                                                & Med                          & 37.3                   & 41.7                       & 42.3                         & 42.3                   & 51.5                     \\
                                                & Few                          & 8.2                    & 16.2                       & 19.0                         & 23.0                   & 26.7                     \\
                                                & All                          & 38.7                   & 41.4                       & 42.5                         & 43.3                   & 49.7                     \\  \midrule
\multirow{4}{*}{Random Selection (K=10)}                      & Many                         & 70.8                   & 62.3                       & 65.2                         & 62.6                   & 68.5                     \\
                                                & Med                          & 40.4                   & 49.0                       & 49.2                         & 46.9                   & 52.0                     \\
                                                & Few                          & 9.0                    & 26.7                       & 21.6                         & 27.3                   & 27.1                     \\
                                                & All                          & 41.6                   & 47.0                       & 46.5                         & 46.5                   & 50.3                     \\  \midrule
\multirow{4}{*}{RandAugment (K=14)}                    & Many                         & 70.3                   & 63.5                       & 65.4                         & 62.9                   & 68.5                     \\
                                                & Med                          & 40.7                   & 49.1                       & 50.6                         & 48.1                   & 52.3                     \\
                                                & Few                          & 9.6                    & 26.0                       & 21.6                         & 28.7                   & 27.0                     \\
                                                & All                          & 41.8                   & 47.2                       & 47.1                         & 47.5                   & 50.4                     \\  \midrule
\multirow{4}{*}{Ours (K=22)}                    & Many                         & 71.6                   & 64.3                       & 67.3                         & 63.3                   & 69.2                     \\
                                                & Med                          & 42.3                   & 49.2                       & 50.4                         & 48.4                   & 52.8                     \\
                                                & Few                          & 9.4                    & 26.7                       & 21.4                         & 28.7                   & 27.3                     \\
                                                & All                          & 42.7                   & 47.7                       & 47.6                         & 47.7                   & 50.7   \\
\thickhline
\end{tabular}}}
\end{table} }

\rebut{
\myparagraph{Effect of randomly ordered data augmentation.}
Our proposed \alg operates randomly sequential of the selected augmentations based on the strength of DA. To study the impact of these randomly ordered augmentations, we compare \alg and \alg with fixed order augmentations. For examples, when the operation indices  among 22 augmentations are samples, it is applied with . \autoref{tab:fix_order} shows small performance differences between the two methods. Thus, we believe that the effect of the augmentation order on the difficulty is negligible. This is because the effectiveness of \alg is expected to be sufficiently high even in a given order of augmentations since the goal is to make it harder to learn, regardless of the ordered (determined or random) order.
\begin{table}[ht]
\centering
\caption{\rebut{The performance comparison of \alg with random order (Ours) and fixed order of augmentation operations. Note that the values in parentheses are differences between \alg and \alg with fixed augmentation order (Random order  Fixed order).}}\label{tab:fix_order}
\resizebox{1.0\columnwidth}{!}{
\rebut{
\begin{tabular}{l|c|ccccc}
\thickhline
                             & Category & CE & CE-DRW & LDAM-DRW & BS & RIDE \\ \midrule
\multirow{4}{*}{Random order (Ours)} & Many     & 71.6                   & 64.3                       & 67.3                         & 63.3                   & 69.2                     \\
                             & Med      & 42.3                   & 49.2                       & 50.4                         & 48.4                   & 52.8                     \\
                             & Few      & 9.4                    & 26.7                       & 21.4                         & 28.7                   & 27.3                     \\
                             & All      & 42.7                   & 47.7                       & 47.6                         & 47.7                   & 50.7                     \\ \midrule
\multirow{4}{*}{Fixed order}   & Many     & 70.5 (-1.1)            & 62.8 (-1.5)                & 66.9 (-0.4)                  & 62.5 (-0.8)            & 68.2 (-1.0)              \\
                             & Med      & 43.0 (+0.7)            & 50.2 (+1.0)                & 49.7 (-0.7)                  & 48.3 (-0.1)            & 53.5 (+0.7)              \\
                             & Few      & 9.0 (-0.4)             & 27 (+0.3)                  & 21.9 (+0.5)                  & 29.6 (+0.9)            & 26.9 (-0.4)              \\
                             & All      & 42.4 (-0.3)            & 47.7 (+0.0)                & 47.4 (-0.2)                  & 47.7 (+0.0)            & 50.5 (-0.2)   \\
\thickhline
\end{tabular}}}
\end{table} }

\rebut{
\myparagraph{Comparison with random augmentation.}
To verify that the success of \alg is not simply from a richer dataset made by DA, we compare our proposed method \alg to randomly sampled augmentation for every iteration. Our comparison methods are Random 5 and Random 10, which denote the conduct of five and ten randomly sampled augmentations for every iteration. As shown in \autoref{tab:random_augment}, while Random 10 generates the most diversifying images, the network trained with this showed the worst performance, even lower than vanilla. Our \alg achieves the best performance among all methods.
\begin{table}[ht]
\centering
\caption{\rebut{The performance comparison between train network with randomly selected five and ten augmentation operations for every iteration and our proposed \alg.}}\label{tab:random_augment}
\resizebox{0.8\columnwidth}{!}{
\rebut{
\begin{tabular}{l|c|ccccc}
\thickhline
                           & Category & CE & CE-DRW & LDAM-DRW & BS & RIDE \\ \midrule
\multirow{4}{*}{Vanilla}   & Many                 & 66.2                   & 62.8                       & 62.8                         & 61.6                   & 67.7                     \\
                           & Med                  & 37.3                   & 41.7                       & 42.3                         & 42.3                   & 51.5                     \\
                           & Few                  & 8.2                    & 16.2                       & 19                           & 23                     & 26.7                     \\
                           & All                  & 38.7                   & 41.4                       & 42.5                         & 43.3                   & 49.7                     \\ \midrule
\multirow{4}{*}{Randomly selected 5 augmentations}  & Many                 & 68.9                   & 56.9                       & 64.2                         & 59.5                   & 64                       \\
                           & Med                  & 35                     & 48.2                       & 42.7                         & 48.2                   & 44.8                     \\
                           & Few                  & 3.7                    & 25.6                       & 16.3                         & 23                     & 20                       \\
                           & All                  & 37.5                   & 44.5                       & 42.3                         & 44.6                   & 44.1                     \\ \midrule
\multirow{4}{*}{Randomly selected 10 augmentations} & Many                 & 61.7                   & 51.2                       & 57.9                         & 54                     & 57.7                     \\
                           & Med                  & 25.7                   & 43.2                       & 34.7                         & 41.2                   & 38.3                     \\
                           & Few                  & 1.3                    & 20.6                       & 12.7                         & 16.8                   & 16.6                     \\
                           & All                  & 31.0                     & 39.2                       & 36.2                         & 38.4                   & 38.6                     \\ \midrule
\multirow{4}{*}{\alg}      & Many                 & 71.6                   & 64.3                       & 67.3                         & 63.3                   & 69.2                     \\
                           & Med                  & 42.3                   & 49.2                       & 50.4                         & 48.4                   & 52.8                     \\
                           & Few                  & 9.4                    & 26.7                       & 21.4                         & 28.7                   & 27.3                     \\
                           & All                  & 42.7                   & 47.7                       & 47.6                         & 47.7                   & 50.7                    \\
\thickhline
\end{tabular}}}
\end{table} } 
\section{Experimental setting of \autoref{fig:hyper_opt}}
\label{app:hyperopt}
To further analyze the impact of curriculum, we compare \alg with the performance of previous hyper-parameter search algorithms and auto-augmentation methods, especially DADA~\cite{li2020dada}. We describe each setting in detail as follows.

\rebut{
\myparagraph{Baseline.}
This is the case of training with standard data augmentation that consists of random cropping and probabilistic horizontal flip.
}

\myparagraph{Hyper-parameter search.} We utilize the strength score-based augmentation module in \alg to verify the hyper-parameter search. In other words, samples in each class utilize  augmentation operations. Therefore, we search the class-wise augmentation on the search space  where  is the number of classes. We leverage the hyper-parameter searching open-source library, Ray~\cite{liaw2018tune}, for search  space efficiently. Among various search modules, we utilize the HyperOptSearch module, which is the implementation of the Tree-structured Parzen Estimator~\cite{bergstra2013making}. Moreover, for fast search, we use the Asynchronous Successive Halving Algorithm (ASHA)~\cite{li2020system}. We run  trials for each algorithms which spends almost  GPU hours (\ie  overhead compare to CUDA).

\myparagraph{Researched DADA operation on imbalanced CIFAR.}
Because the officially offered policies on CIFAR by~\citet{li2020dada} are searched for a balanced CIFAR dataset, we have to re-search the augmentation policy for the imbalanced dataset. We utilize the official code of DADA and replace the dataloader to re-search the operations. It spends  minutes for searching the augmentation policy ( than the overhead of CUDA). Despite this additional overhead, DADA outputs worse performance than \alg (even \alg without curriculum case). This is because (1) DADA does not consider class-wise augmentation and (2) it does not consider the impact of class imbalance.

\rebut{
\myparagraph{\alg without curriculum}
To verify the impact of curriculum itself, we ran the following steps. (1) We conduct experiments with \alg and get the strength of data augmentation for each class at the final epoch. (2) We re-train the network from scratch by using the strength parameter obtained from (1).
} 
\section{\rebut{Further Analyses}}
\label{app: rebuttal}
\rebut{
To get better understanding, we conduct several analyses for our proposed method, \alg.
}

\subsection{\rebut{Further analysis on LoL score}}
\rebut{
In this section, we conduct experimental ablation studies to understand the performance gain of our proposed method, \alg.}

\rebut{
\myparagraph{Suitability of LoL score as metric for class-wise difficulty.}
The superiority of LoL score is to measure the difficulty metric based on the augmentation strength for each class, which is motivated by our main findings. To verify the suitability of LoL score as a metric for class-wise difficulty, we compared \alg and the case where LoL score is replaced by the score in \citet{sinha2022class}. As same with our proposed method, we increase the strength parameter when the score in \citet{sinha2022class} is larger than the same threshold . \autoref{tab:lol_score} summarizes the results that our LoL score showed performance improvement compared to the case of \citet{sinha2022class}. From the results, we can conclude that this improvement comes from the characteristic of LoL score that is directly related to augmentation strength.
\begin{table}[ht]
\centering
\caption{\rebut{The performance comparison between the scores for determining strength parameter, \citet{sinha2022class} and LoL score (ours). }}\label{tab:lol_score}
\resizebox{0.85\columnwidth}{!}{
\rebut{
\begin{tabular}{l|c|ccccc}
\thickhline
                                  & Category & CE & CE-DRW & LDAM-DRW & BS & RIDE \\ \midrule
\multirow{4}{*}{\citet{sinha2022class}}          & Many     & 68.4                   & 59.7                       & 62.0                         & 59.7                   & 67                       \\
                                  & Med      & 42.5                   & 48.8                       & 48.7                         & 47.0                   & 52.1                     \\
                                  & Few      & 11.6                   & 27.3                       & 25.4                         & 32.0                   & 26.7                     \\
                                  & All      & 42.3                   & 46.1                       & 46.4                         & 46.9                   & 49.6                     \\ \midrule
\multirow{4}{*}{LoL score} & Many     & 71.6                   & 64.3                       & 67.3                         & 63.3                   & 69.2                     \\
                                  & Med      & 42.3                   & 49.2                       & 50.4                         & 48.4                   & 52.8                     \\
                                  & Few      & 9.4                    & 26.7                       & 21.4                         & 28.7                   & 27.3                     \\
                                  & All      & 42.7                   & 47.7                       & 47.6                         & 47.7                   & 50.7    \\
\thickhline
\end{tabular}}}
\end{table} }

\rebut{
\myparagraph{Effect of random sampling for computing LoL score}
To implement the computation of LoL score efficiently, we randomly selected the instances for each class. The reason for using random sampling to compute  is that we want to measure how much the model learns entire information for each class. To understand the effect of random sampling, we compare our random sampling method to sampling instances with larger (or smaller) losses. \autoref{tab:random_sample} describes the comparison of performance between various sampling strategies. As shown in the results, if \alg measures the degree of learning with only easy samples (the samples with small losses), \alg increases the strength of augmentation too quickly and generates performance degradation. Therefore, it is a better way to grasp the degree of learning for each class without prejudice through uniform random sampling. Furthermore, computing loss for all samples for sorting them at the beginning of each epoch requires  times of computation overhead than our method.
\begin{table}[ht]
\centering
\caption{\rebut{The performance comparison between the large loss sample selection, small loss sample selection, and random selection (ours).} }\label{tab:random_sample}
\resizebox{0.65\columnwidth}{!}{
\rebut{
\begin{tabular}{l|c|ccccc}
\thickhline
                                        & Category & CE & CE-DRW & LDAM-DRW & BS & RIDE \\ \midrule
\multirow{4}{*}{Larger Loss}            & Many                 & 67.0                     & 61.6                       & 63.1                         & 59.9                   & 67.9                     \\
                                        & Med                  & 37.1                   & 45.2                       & 45.7                         & 42.4                   & 51.2                     \\
                                        & Few                  & 7.3                    & 20.3                       & 20.3                         & 23.3                   & 25.8                     \\
                                        & All                  & 38.6                   & 43.5                       & 44.2                         & 42.8                   & 49.4                     \\ \midrule
\multirow{4}{*}{Smaller Loss}             & Many                 & 53.0                     & 53.4                       & 54.5                         & 51.2                   & 59.3                     \\
                                        & Med                  & 24.7                   & 33.0                         & 33.9                         & 36.1                   & 38.4                     \\
                                        & Few                  & 24.2                   & 32.9                       & 33.7                         & 35.4                   & 38.2                     \\
                                        & All                  & 41.6                   & 44 .0                        & 45.5                         & 45.7                   & 49.8                     \\ \midrule
\multirow{4}{*}{Random (Ours)} & Many                 & 71.6                   & 64.3                       & 67.3                         & 63.3                   & 69.2                     \\
                                        & Med                  & 42.3                   & 49.2                       & 50.4                         & 48.4                   & 52.8                     \\
                                        & Few                  & 9.4                    & 26.7                       & 21.4                         & 28.7                   & 27.3                     \\
                                        & All                  & 42.7                   & 47.7                       & 47.6                         & 47.7                   & 50.7          \\
\thickhline
\end{tabular}}}
\end{table} }

\rebut{
\myparagraph{Numerical values of LoL score dynamics.}
We provide the numerical values for \autoref{fig:curriculum} that is, the average values (for every 20 epochs) of LoL score for the classes with indices 1-10 and the classes with indices 91-100. From the numerical values, we can easily understand the explanation which is discussed in Section~\ref{sec:exp}.
\begin{table}[ht]
\centering
\caption{\rebut{The averaged LoL score of top 10 classes (class indices with 1-10) and bottom classes (class indices with 91-100) for every 20 epochs.}}\label{tab:lol_dynamics}
\resizebox{0.75\columnwidth}{!}{
\rebut{
\begin{tabular}{l|c|cccccccccc}
\thickhline
                          & Class / Epoch & 20 & 40 & 60 & 80 & 100 & 120 & 140 & 160 & 180 & 200 \\ \midrule
\multirow{2}{*}{CE}       & Top 10    & 0.5                    & 0.8                    & 1.7                    & 2                      & 2.6                     & 2.7                     & 3.2                     & 3.2                     & 3.4                     & 3.7                     \\
                          & Bottom 10 & 0.0                    & 0.0                    & 0.0                    & 0.0                    & 0.0                     & 0.1                     & 0.0                     & 0.1                     & 0.0                     & 0.1                     \\ \midrule
\multirow{2}{*}{CE-DRW}   & Top 10    & 0.8                    & 1.3                    & 2                      & 2.5                    & 1.6                     & 2.6                     & 1.8                     & 2.6                     & 2.5                     & 2.6                     \\
                          & Bottom 10 & 0.0                    & 0.0                    & 0.0                    & 0.0                    & 0.0                     & 0.1                     & 0.0                     & 0.0                     & 1.2                     & 1.4                     \\ \midrule
\multirow{2}{*}{LDAM-DRW} & Top 10    & 1.8                    & 3.4                    & 3.3                    & 3                      & 3.4                     & 3.2                     & 3.1                     & 3.6                     & 4.1                     & 4.3                     \\
                          & Bottom 10 & 0.0                    & 0.0                    & 0.1                    & 0.0                    & 0.0                     & 0.1                     & 0.0                     & 0.0                     & 1.8                     & 1.4                     \\ \midrule
\multirow{2}{*}{BS}       & Top 10    & 1.1                    & 1.1                    & 1.6                    & 2.4                    & 2.1                     & 2.5                     & 2.5                     & 2.8                     & 3.9                     & 4.0                     \\
                          & Bottom 10 & 0.1                    & 0.1                    & 0.0                    & 0.1                    & 0.6                     & 1.1                     & 1.0                     & 0.7                     & 1.7                     & 1.4                     \\ \midrule
\multirow{2}{*}{RIDE}     & Top 10    & 0.8                    & 1.2                    & 1.6                    & 1.7                    & 2.1                     & 1.8                     & 1.3                     & 1.1                     & 2.5                     & 2.6                     \\
                          & Bottom 10 & 0.0                    & 0.0                    & 0.0                    & 0.0                    & 0.0                     & 0.0                     & 0.0                     & 0.0                     & 0.7                     & 0.8   \\
\thickhline
\end{tabular}}}
\end{table} }

\subsection{\rebut{Analysis the case of without class-wise}}
\rebut{
To examine the validity of class-wise augmentation of \alg, we apply the \alg with the same strength of DA for all classes. Instead of computing LoL score class-wisely, we computed only one LoL score for the entire dataset by uniformly random sampling instances in the training dataset regardless of class. \autoref{tab:class-wise} shows the significant performance degradation of \alg without class-wise augmentation compared to \alg. This is because, without class-wise augmentation, we cannot allocate the appropriate strength of augmentation to each class.
\begin{table}[ht]
\centering
\caption{\rebut{The performance comparison between different augmentation strategy on CIFAR-100-LT with imbalance ratio 100. Note that values in parentheses are differences of \alg w/o class-wise with vanilla (vanilla - \alg w/o class-wise) or \alg (\alg - \alg w/o class-wise).}}\label{tab:class-wise}
\resizebox{0.8\columnwidth}{!}{
\rebut{
\begin{tabular}{l|c|ccccc}
\thickhline
                                     & Category & CE & CE-DRW &  LDAM-DRW & BS & RIDE \\ \midrule
\multirow{4}{*}{\alg w/o class-wise} & Many     & 69.0                   & 62.7                       & 65.2                         & 62.2                   & 67.7                     \\
                                     & Med      & 38.7                   & 47.3                       & 47.6                         & 44.7                   & 52.2                     \\
                                     & Few      & 6.7                    & 23.5                       & 20.7                         & 25.5                   & 26.4                     \\
                                     & All      & 39.7                   & 45.5                       & 45.7                         & 44.9                   & 49.9                     \\ \midrule
\multirow{4}{*}{Vanilla}             & Many     & 66.2 (-2.8)            & 62.8 (+0.1)                & 62.8 (-2.4)                  & 61.6 (-0.6)            & 67.7 (+0.0)              \\
                                     & Med      & 37.3 (-1.4)            & 41.7 (-5.6)                & 42.3 (-5.3)                  & 42.3 (-2.4)            & 51.5 (-0.7)              \\
                                     & Few      & 8.2 (+1.5)             & 16.2 (-7.3)                & 19.0 (-1.7)                  & 23.0 (-2.5)            & 26.7 (+0.3)              \\
                                     & All      & 38.7 (-1.0)            & 41.4 (-4.1)                 & 42.5 (-3.2)                  & 43.3 (-1.6)            & 49.7 (-0.2)              \\ \midrule
\multirow{4}{*}{\alg (Ours)}         & Many     & 71.6 (+2.6)            & 64.3 (+1.6)                & 67.3 (+2.1)                  & 63.3 (+1.1)            & 69.2 (+1.5)              \\
                                     & Med      & 42.3 (+3.6)            & 49.2 (+1.9)                & 50.4 (+2.8)                  & 48.4 (+3.7)            & 52.8 (+0.6)              \\
                                     & Few      & 9.4 (+2.7)             & 26.7 (+3.2)                & 21.4 (+0.7)                  & 28.7 (+3.2)            & 27.3 (+0.9)              \\
                                     & All      & 42.7 (+3.0)            & 47.7 (+2.2)                & 47.6 (+1.9)                  & 47.7 (+2.8)            & 50.7 (+0.8)             \\
\thickhline
\end{tabular}}}
\end{table} }



  
\end{document}
