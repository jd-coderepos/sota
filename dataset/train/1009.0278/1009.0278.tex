

\documentclass[a4paper]{article}
\newenvironment{IEEEproof}{\begin{proof}}{\end{proof}}
\newcommand \techreport[1]{#1}
\newcommand \ieeetrans[1]{}

\makeatletter
\usepackage{paralist}
\usepackage{cite}
\usepackage[cmex10]{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{psfrag}
\usepackage{dsfont}
\usepackage{subfigure}


\newcommand{\prottitle}[1]{
\begin{minipage}[t]{\columnwidth}
\begin{center}\emph{#1}\end{center}
\vspace{0.5ex}
\end{minipage}
}


\newcommand{\protheader}[5]{\vspace{1.5ex} \begin{minipage}[t]{0.125\columnwidth}{}\end{minipage} \hfill
\begin{minipage}[t]{0.3\columnwidth}{\fbox{#1}} \1.5ex] #3 \end{center}}\end{minipage} \hfill
\begin{minipage}[t]{0.3\columnwidth}{\begin{flushright} \fbox{#4} \1.5ex]
}

\newcommand{\protbottom}[3]{
\begin{minipage}[t]{\columnwidth}
\setlength{\unitlength}{\columnwidth}
\begin{picture}(1,0.03)
\put(0,0){\line(1,0){1}} \put(0.08,0.02){\vector(0,-1){0.04}} \put(0.92,0.02){\vector(0,-1){0.04}} \end{picture}
\end{minipage}
\begin{minipage}[t]{\columnwidth}
\setlength{\unitlength}{\columnwidth}
\begin{picture}(1,0.03)
\end{picture}
\end{minipage}
\begin{minipage}[t]{0.03\columnwidth}{\vspace{1.5ex}}\end{minipage} \hfill
\begin{minipage}[t]{0.325\columnwidth}{#1}\end{minipage} \hfill
\begin{minipage}[t]{0.25\columnwidth}\begin{center}{#2}\end{center}\end{minipage} \hfill
\begin{minipage}[t]{0.325\columnwidth}{\begin{flushright} #3 \end{flushright}} \end{minipage} \hfill
\begin{minipage}[t]{0.03\columnwidth}{}\end{minipage}
}

\newcommand{\protrightarrow}[1]{
\setlength{\unitlength}{\columnwidth}
\begin{picture}(1,0.1)
\put(0,-0.03){\vector(1,0){1}} \put(0,0){\begin{minipage}[t]{\columnwidth}
\begin{center} #1 \end{center}
\end{minipage}}
\end{picture}
}

\newcommand{\protleftarrow}[1]{
\setlength{\unitlength}{\columnwidth}
\begin{picture}(1,0.1)
\put(1,-0.03){\vector(-1,0){1}}
\put(0,0){\begin{minipage}[t]{\columnwidth}
\begin{center} #1 \end{center}
\end{minipage}}
\end{picture}
}

\newcommand{\protlrarrow}[1]{
\setlength{\unitlength}{\columnwidth}
\begin{picture}(1,0.1)
\put(1,-0.03){\vector(-1,0){1}} \put(0,-0.03){\vector(1,0){1}}
\put(0,0){\begin{minipage}[t]{\columnwidth}
\begin{center} #1 \end{center}
\end{minipage}}
\end{picture}
}

\newcommand{\protocol}[1]{\noindent \fbox{\parbox{\columnwidth}{#1}}}

\newcommand{\mytodo}[1]{\noindent \fbox{\parbox{\columnwidth}{\textbf{TODO:} \\ \textit{#1}}}}

\newcommand{\chooserandom}{\ensuremath{\stackrel{R}{\longleftarrow}}\xspace}
\newcommand{\mytestin}{\ensuremath{\stackrel{?}{\in}}\xspace}
\newcommand{\mytesteq}{\ensuremath{\stackrel{?}{=}}\xspace}
\newcommand{\nequiv}{\ensuremath{\equiv \!\!\!\!\!\! / \,\,\,\,}}
\newcommand{\leer}{\hspace{1em}}
\newcommand{\mytrafo}{\ensuremath{\mathcal{T}}\xspace}
\newcommand{\kbytes}{\ensuremath{\mathrm{KBytes}}\xspace}
\newcommand{\mbytes}{\ensuremath{\mathrm{MBytes}}\xspace}

\newcommand{\sigmaprotocol}{\ensuremath{\Sigma}-protocol\xspace}
\newcommand{\sigmaprotocols}{\ensuremath{\Sigma}-protocols\xspace}
\newcommand{\myalgorithm}[2]{\ensuremath{\mathsf{#1} \, (#2)}}

\newcommand{\defobj}{\ensuremath{\stackrel{def}{=}}\xspace}
\newcommand{\intervaloo}[2]{] #1 , \, #2 [}
\newcommand{\intervaloc}[2]{] #1 , \, #2 ]}
\newcommand{\intervalco}[2]{[ #1 , \, #2 [}
\newcommand{\intervalcc}[2]{[ #1 , \, #2 ]}

\newcommand{\damgard}{Damg{\aa}rd\xspace}

\newcommand{\prover}{\ensuremath{\mathcal{P}}\xspace}
\newcommand{\cheatingprover}{\ensuremath{\mathcal{P}^*}\xspace}
\newcommand{\verifier}{\ensuremath{\mathcal{V}}\xspace}
\newcommand{\cheatingverifier}{\ensuremath{\mathcal{V}^*}\xspace}
\newcommand{\secretinput}[1]{\ensuremath{in_{#1}}}
\newcommand{\partyoutput}[1]{\ensuremath{out_{#1}}}
\newcommand{\formprotocol}[2]{\ensuremath{\mathtt{#1} (#2)}}
\newcommand{\protocoltrans}[1]{\ensuremath{[ #1 ]}}
\newcommand{\protocolview}[2]{\ensuremath{< #1 >_{#2}}}
\newcommand{\calccomp}[2]{\ensuremath{\mathsf{Comp}_{#1}^{#2}}\xspace}
\newcommand{\commcomp}[2]{\ensuremath{\mathsf{Comm}_{#1}^{#2}}\xspace}

\newcommand{\committer}{\ensuremath{\mathcal{C}}\xspace}
\newcommand{\cheatingcommitter}{\ensuremath{P_C^*}\xspace}
\newcommand{\recipient}{\ensuremath{\mathcal{R}}\xspace}
\newcommand{\cheatingrecipient}{\ensuremath{P_R^*}\xspace}
\newcommand{\commitmentdescription}{\ensuremath{descr_{com}}\xspace}
\newcommand{\commitment}[1]{\ensuremath{com( #1 )}\xspace}
\newcommand{\commitmentsecretkey}[1]{\ensuremath{sk_{#1}}\xspace}
\newcommand{\commitmentpublickey}[1]{\ensuremath{pk_{#1}}\xspace}
\newcommand{\commitmentspace}{\ensuremath{\mathcal{C}}\xspace}
\newcommand{\commessagespace}{\ensuremath{\mathcal{M}}\xspace}
\newcommand{\groupdescription}[1]{\ensuremath{descr_{#1}}\xspace}

\newcommand{\proofofknowledge}[3]{\ensuremath{\mathtt{PoK} \, \left( \; (\, #1, #2 \,) \;\; | \;\; #3 \, \right)}\xspace}
\newcommand{\proofhowtoopen}[1]{\ensuremath{\mathtt{PoK}_{open}(#1)}\xspace}
\newcommand{\proofmult}[3]{\ensuremath{\mathtt{PoK}_{mult}(#1 ; \; #2 , \; #3)}\xspace}
\newcommand{\proofsquare}[2]{\ensuremath{\mathtt{PoK}_{sq}(#1 , \; #2)}\xspace}
\newcommand{\proofequal}[2]{\ensuremath{\mathtt{PoK}_{eq}(#1 , #2)}\xspace}
\newcommand{\proofgeqzero}[1]{\ensuremath{\mathtt{PoK}_{\geq 0}(#1)}\xspace}
\newcommand{\proofinterval}[3]{\ensuremath{\mathtt{PoK}_{[\cdot, \cdot]}(#1 \in [#2 , #3])}\xspace}
\newcommand{\proofintervalgiven}[1]{\ensuremath{\mathtt{PoK}_{[\cdot, \cdot]}(#1)}\xspace}

\newcommand{\proofhowtoopenempty}{\ensuremath{\mathtt{PoK}_{open}()}\xspace}
\newcommand{\proofmultempty}{\ensuremath{\mathtt{PoK}_{mult}()}\xspace}
\newcommand{\proofsquareempty}{\ensuremath{\mathtt{PoK}_{sq}()}\xspace}
\newcommand{\proofequalempty}{\ensuremath{\mathtt{PoK}_{eq}()}\xspace}
\newcommand{\proofgeqzeroempty}{\ensuremath{\mathtt{PoK}_{\geq 0}()}\xspace}
\newcommand{\proofintervalempty}{\ensuremath{\mathtt{PoK}_{[\cdot]}}\xspace}

\newcommand{\proofmultonly}[1]{\ensuremath{\mathtt{PoK}_{mult}(#1)}\xspace}


\newcommand{\ellmodulus}{\ensuremath{\ell_n}\xspace}
\newcommand{\ellstat}{\ensuremath{\ell_{\varnothing}}\xspace}
\newcommand{\ellestimate}{\ensuremath{\ell_B}\xspace}
\newcommand{\ellsecret}{\ensuremath{\ell_T}\xspace}
\newcommand{\ellchallenge}{\ensuremath{\ell_F}\xspace}

\newcommand{\sigmafirst}[2]{\ensuremath{\mathsf{first}_{#1}(#2)}\xspace}
\newcommand{\sigmaresponse}[2]{\ensuremath{\mathsf{response}_{#1}(#2)}\xspace}
\newcommand{\sigmaverify}[2]{\ensuremath{\mathsf{verify}_{#1}(#2)}\xspace}
\newcommand{\sigmasimulate}[2]{\ensuremath{\mathsf{sim}_{#1}(#2)}\xspace}


\newcommand{\watermark}{\ensuremath{\mathit{WM}}\xspace}
\newcommand{\wwork}{\ensuremath{\mathit{W'}}\xspace}
\newcommand{\allegedstego}{\ensuremath{\mathit{W^{*}}}\xspace}
\newcommand{\originalwork}{\ensuremath{\mathit{W}}\xspace}
\newcommand{\exwatermark}{\ensuremath{\mathit{WM^{*}}}\xspace}
\newcommand{\visualmasking}{\ensuremath{\mathit{W''}}\xspace}

\newcommand{\freqtrafo}[1]{\ensuremath{\hat{#1}}\xspace}
\newcommand{\wmcorr}{\ensuremath{\mathit{corr}}\xspace}
\newcommand{\mvector}[2]{\ensuremath{{#1}^{[#2]}}\xspace}

 
\newcommand \adjwidth {1.0}
\newcommand \narrowline {}
\newcommand \defn {\mathrel{\triangleq}}
\newcommand \ELb {\mathcal{L}}
\renewcommand\Pr{\mathop{\mbox{\ensuremath{\mathbb{P}}}}\nolimits}
\newcommand\E{\mathop{\mbox{\ensuremath{\mathbb{E}}}}\nolimits}
\newcommand {\dd} {\, \mathrm{d}}
\newcommand\argmax{\mathop{\mathrm{argmax}}}
\newcommand\argmin{\mathop{\mathrm{argmin}}}
\newcommand \thr {\tau}
\newcommand \hthr {\hat{\thr}_n^*}
\newcommand \hns {\hat{n}^*}
\newcommand \ns {n^*}
\newcommand \errf {\mathcal{E}}
\newcommand \err {\varepsilon}
\newcommand \noise {\omega}
\newcommand \loss {L}
\newcommand \worst {\mathbb{L}}
\newcommand \pa {p_A}
\newcommand \pu {p_U}
\newcommand \LA {\ell_A}
\newcommand \LAC {\ell_{A_{C}}}
\newcommand \LU {\ell_U}
\newcommand \LUC {\ell_{U_{C}}}
\newcommand \LB {\ell_B}
\newcommand \CX {\mathcal{X}}
\newcommand \decfun {q}
\newcommand \decs {g}
\newcommand \Decs {G}
\newcommand\ind[1]{\mathop{\mbox{\ensuremath{\mathbb{I}}}}\left\{#1\right\}}
\newcommand\set[1] {\left\{#1\right\}}
\newcommand\cset[2] {\left\{#1 \mathrel{:} #2\right\}}
\newcommand \OR {\vee}
\newcommand \AND {\wedge}
\newcommand \auth {\mathcal{P}}
\newcommand \ver {\mathcal{V}}
\newcommand \concat {|}
\newcommand \id {I}
\newcommand \code {\Phi}
\newcommand \metric {\gamma}
\newcommand \minmetric {\gamma_{\min}}
\newcommand \Borel[1] {\mathcal{F}_{#1}}
\newcommand \rr {\hat{r}}
\newcommand \rc {\hat{c}}
\newcommand \rx {\hat{x}}
\newcommand \failure {F}
\newcommand \success {S}

\newcommand \myprotocol {{\sc AdaThres}}

\newcommand\Reals {{\mathds{R}}}
\newcommand\Naturals {{\mathds{N}}} 

\newcommand \Swiss {\textsc{Swiss-Knife}}
\newcommand \Hitomi {\textsc{Hitomi}}
\newcommand \ECMAD {\textsc{ECMAD}}
\newcommand \MAD {\textsc{MAD}}
\newcommand \Hancke {\textsc{HaKu}}

\theoremstyle{plain} \newtheorem{remark}{Remark}
\theoremstyle{plain} \newtheorem{definition}{Definition}
\theoremstyle{plain} \newtheorem{example}{Example}
\theoremstyle{plain} \newtheorem{assumption}{Assumption}
\theoremstyle{plain} \newtheorem{conjecture}{Conjecture}
\theoremstyle{plain} \newtheorem{theorem}{Theorem}
\theoremstyle{plain} \newtheorem{proposition}{Proposition}
\theoremstyle{plain} \newtheorem{lemma}{Lemma}
\theoremstyle{plain} \newtheorem{corollary}{Corollary}


\title{Expected loss analysis of thresholded authentication protocols in noisy conditions}
\ieeetrans{
\author{Christos~Dimitrakakis,~\IEEEmembership{Member,~IEEE,}
  Aikaterini~Mitrokotsa
  and~Serge~Vaudenay,\thanks{C. Dimitrakakis is with FIAS in Frankfurt, Germany}\thanks{A. Mitrokotsa and S. Vaudenay are with EPFL in Lausanne, Switzerland.}}
}
\techreport{
  \author{Christos Dimitrakakis \and Aikaterini Mitrokotsa \and Serge Vaudenay}
}



\begin{document}
\maketitle
\begin{abstract}
  A number of authentication protocols have been proposed recently,
  where at least some part of the authentication is performed during a
  phase, lasting  rounds, with no error correction. This requires
  assigning an acceptable threshold for the number of detected
  errors. This paper describes a framework enabling an
  \textit{expected loss} analysis for all the protocols in this
  family. Furthermore, computationally simple methods to obtain nearly
  optimal value of the threshold, as well as for the number of rounds
  is suggested. Finally, a method to adaptively select both the number
  of rounds and the threshold is proposed.
\end{abstract}


\section{Introduction}

Traditionally~\cite{stallings:cryptography,stinson:cryptography},
authentication is assumed to be taking place on an error-free channel,
and error analysis is performed separately from cryptographic analysis
of protocols.  However, a number of authentication protocols have been
proposed~\cite{brands94, bussard, singelee1,tippenhauer,
  sheddingLight,
  cryptoeprint:2009:310,hancke05,reid2007,KimAKSP-2008-icisc}, where
at least some part of the authentication is performed during a
challenge-response phase lasting  rounds with no error correction,
due to a need to detect relay attacks by timing delays.  The noise
necessitates the use of a tolerance threshold , such that a
party is authenticated if the total error of its responses 
is below the threshold .

This paper introduces a general framework for analysing such
protocols.  We assign a cost  to the event that we authenticate a
malicious party ---which we call the {\em attacker}---a cost (or
loss)  to the event that we fail to authenticate a valid party
---which we call the {\em user}---and a cost  for each round
of the challenge-response phase.  Our goal is to select  so
as to minimise the \textit{expected loss} .

The paper is organised as follows. Section~\ref{sec:relatedwork}
presents related work, while Section~\ref{sec:preliminaries}
introduces notation and thresholded authentication
protocols. Section~\ref{sec:loss-analysis} contains the
\textit{expected loss} analysis under noise. In particular,
Sec.~\ref{sec:threshold-choice} suggests a method to calculate the
threshold accompanied by a finite sample loss bound, while
Sec.~\ref{sec:rounds-choice} provides a further bound by selecting an
appropriate number of rounds. These results only require that the
expected error of the attacker is higher than that of the
user. Section~\ref{sec:specific-protocols} applies the above analysis
to a number of currently used protocols.  Section~\ref{sec:noise}
suggests a high-probability method for estimating the channel noise
and presents the results of simulation experiments that compare our
choice of threshold with thresholds derived using asymptotic
approximations. Finally, Sec.~\ref{sec:conclusion} concludes the
paper. For completeness, the appendix provides some useful auxilliary
results regarding the finite sample and the asymptotic derivations.

\subsection{Related Work}
\label{sec:relatedwork}
In certain authentication protocols part of the communication is
performed in noisy channels without employing error correction.
Specifically, a {\em rapid-bit exchange phase} was introduced
in~\cite{brands94} to compute an upper bound on the distance of the
prover .  This is composed of  challenge-response
\textit{rounds}, used to calculate a round-trip time and thus place a
bound on the distance.  Subsequently, a broad range of
\textit{distance bounding} protocols were proposed, both for
RFID~\cite{hancke05, KimAKSP-2008-icisc, reid2007, singelee1,
  sheddingLight}, as well as other wireless devices~\cite{capkun,
  capkun2, tippenhauer}.

Hancke and Kuhn \cite{hancke05} were the first to indicate that since
the \textit{rapid-bit exchange} phase is taking place in a noisy
channel, challenges and responses may be corrupted.  Thus, a
legitimate user may fail to get authenticated.  Their protocol (henceforth
\Hancke), employed  rounds and authenticated any prover who made a
number of mistakes  less than an acceptance threshold , so
as to reduce the number of false rejections.  Using the binomial
distribution and an assumption on the error rates they give
expressions for the \textit{false accept} and \textit{false reject
  probability} as a function of  and , but they provide no
further analysis.  Nevertheless, they indicate that the number of
challenge-response rounds  in the rapid bit exchange phase should
be chosen according to the expected error rate.  Kim et
al. \cite{KimAKSP-2008-icisc} extend this approach with the {\Swiss}
protocol by considering {\em three} types of errors. 
Finally~\cite{singelee1}, rather than using a threshold ,
proposed a protocol (henceforth {\ECMAD}) using an error correcting
code (ECC).  {\ECMAD}, which extends the {\MAD}
protocol~\cite{capkun}, uses only  of the  total rounds for the
challenges and responses. The remaining  rounds are used to
transmit the  ECC.  This has the effect of achieving better
security (in terms of false acceptance rates) with the same number of
rounds .

All these approaches use  rounds in the noisy authentication phase.
However, they do not define the optimal .  They simply state that
the probability of authenticating a user becomes much higher than the
probability of authenticating an attacker as  increases.  However,
a large value of  is incompatible with the requirements of many
applications and devices (i.e. high value of  leads to high
overhead for resource-constrained devices). This can be modelled by
assigning an {\em explicit cost} to every round, which should take
into account the transmission energy, computation and time overhead.
This cost has so far not been explicitly taken into consideration.


Another work that is closely related to ours is~\cite{singelee2},
which, given a {\em required} false acceptance and false rejection
rate, provides a {\em lower bound} on the number of required
rounds. This analysis is performed for both {\Hancke} and
{\ECMAD}. However, it assumes that the number of rounds  would be
large enough for the binomial distribution of errors to be
approximately normal.  Our analysis is more general, since it uses
finite-sample bounds that hold for any bounded error function.


Recently, Baign\`{e}res et al. \cite{ProvSec2010} have given an
analysis on the related topic of distinguishing between a real and a
fake solver of challenge-response puzzles. More precisely, they study
CAPTCHA-like protocols and provide a threshold which minimizes the
probability of error in these protocols.  The main differences between
the analysis presented in this paper and~\cite{ProvSec2010} can be
summarised below: \begin{inparaenum}[(a)]
\item We perform an expected loss analysis rather than an error
  analysis.
\item Our bounds hold uniformly, while~\cite{ProvSec2010} uses an asymptotically optimal distinguisher.
\item We consider bounded errors rather than  errors for each
  challenge-response.
\item We additionally propose a method to estimate channel noise.
  This is of course not applicable in the context
  of~\cite{ProvSec2010}, due to the different setting.
\end{inparaenum}

A more general work on authentication under noisy conditions was
presented in~\cite{lai}.  This provided tight information-theoretic
upper and lower bounds on the attacker's success in impersonation and
substitution attacks, proving that it decreased with noise.  However,
our analysis shows that, when one considers losses due to
communication overhead and false rejections of users, the expected
loss increases, which is a natural result.

\subsection{Our contribution}
In this paper, we perform a detailed \textit{expected loss} analysis
for a general class of multi-round authentication protocols in a noisy
channel. The analysis is performed by assigning a loss  to each round,
and losses  to false acceptance and false rejection respectively.

We show how a nearly-optimal threshold  for a given number of
rounds  can be chosen and give {\em worst-case} bounds on the
\textit{expected loss} for that choice.  Thus, the bounds hold no
matter if the party that attempts to get authenticated is either a
legitimate user  or an attacker . This extends our previous work
\cite{sheddingLight}, which proposed a new \textit{distance bounding}
protocol ({\Hitomi}) and only calculated a value for the threshold
, without providing any bounds.

We also show how a nearly-optimal number of rounds  can be
chosen and give further bounds on the \textit{expected loss}.  The
bounds hold for {\em any bounded} error function, and not only for
 errors.\footnote{In all previous proposals, there is either
  an error at each round, or there is not.}  Furthermore, they are
valid for any , since they are based on probability inequalities
for a finite number of samples.\footnote{The analysis
  in~\cite{singelee2} only holds for large , so the approximation
  only holds asymptotically.} Thus, they are considerably more general
to the bounds of~\cite{singelee2}.

Finally, we provide high-probability estimates for the current noise
level in the channel by leveraging the coding performed in the initial
and final phases of the protocol, which take place in a coded
channel. This enables us to significantly weaken assumptions on
knowledge of the noise level in the channel and in turn, provide an
authentication algorithm which has low expected loss with high probability.









































\section{Preliminaries}
\label{sec:preliminaries}

We consider sequences  with all  in some
alphabet  and . We write  for the set of all sequences. 
We use  to indicate a definition.   denotes the
probability of event , while  denotes expectations so that
 denotes the
conditional expectation of random variable  when  is
true. The notation  will denote an appropriate
-field on . Finally,  is an indicator
function equal to  when  is true and  otherwise.

We consider shared secret challenge-response authentication protocols
with multi-round exchanges.  In such protocols, a verifier 
grants access to a prover , if the latter can demonstrate its
identity  and possession of a shared secret . The
protocol has three phases:
\begin{inparaenum}[(i)]
\item An initialisation phase.
\item A \textit{rapid-bit exchange} phase, lasting  rounds.
\item A termination phase.
\end{inparaenum}
A frequent assumption is that the authentication takes place in a
noise-free channel. The extension to noisy channels is done by
assuming the existence of an error correcting protocol. Thus, the {\em
  error} analysis is performed separately from the {\em cryptographic}
analysis. Here we shall integrate the two aspects of the problem by
performing an {\em expected loss} analysis of the authentication
protocol directly on the noisy channel. We shall assume that the
initialisation and termination phases are fixed (due to other security
considerations) and focus on the \textit{rapid-bit exchange} phase.

Due to noise in the physical medium, in any exchange between 
and , the former may send a symbol , while the
latter may receive a symbol  such that . We
shall denote the probability of erroneous transmission in the data
layer as: , .
For simplicity, we shall only treat the case of symmetric channel
noise such that: ,
.

\subsection{Thresholded protocols}
\label{sec:thresholded-protocols}
During {\em multi-round challenge response authentication} phase
(e.g. the \textit{rapid-bit exchange} phase in an RFID
distance-bounding protocol) the verifier  sends  challenges
, with , to the prover , which
responds by transmitting  responses , with . We use , and  to
denote the complete challenge and response sequences respectively. The
verifier  can calculate the correct responses  and so
can calculate an error  for the -th round. While the
legitimate user  should also be able to calculate the correct
responses, due to noise, there may be errors in the received
responses. On the other hand, the attacker has to resort to guessing,
so the expected error of the attacker should be higher than that of
the user.  In order to trade off false acceptances with false
rejections, we need a threshold value , such that a prover is
accepted if and only if the total error observed is smaller than
. More precisely, we define:
\begin{definition}
  An additive thresholded multi-round challenge-response
  authentication protocol has the following parameters:
  \begin{enumerate}
  \item A natural number , equal to the number of
    challenge-response rounds.
  \item A threshold .
  \item An error function , where
     represents the error of the -th round.
  \end{enumerate}
  The verifier  rejects the prover (authenticator) ,
  if and only if .
  \label{def:thresholded-auth}
\end{definition}
The relation of  to the challenge and response strings  and
 strongly depends on the protocol.  In order to make our analysis
generally applicable, we define , a lower
bound on the expected per-round error of the attacker and , an upper bound on the error of a legitimate user.
These bounds depend on the noise and on the protocol under
consideration.  We shall return to them in
section~\ref{sec:specific-protocols}.

\section{Expected loss analysis}
\label{sec:loss-analysis}
We now specify our potential losses. For every round of the
\textit{rapid-bit exchange phase}, we suffer loss . In addition,
we suffer a loss of  for each false acceptance and a loss 
for false rejection.\footnote{These losses are subjectively set to
  application-dependent values. Clearly, for cases where falsely
  authenticating an attacker the impact is severe,  must be much
  greater than .} Given that we perform  rounds, the total
loss when the prover  is either the legitimate user  or the
attacker  is given by:

Armed with this information, we can now embark upon an
expected loss analysis.  We wish to devise an algorithm that
guarantees an {\em upper bound} on the expected loss . To
start with, we note that the expected loss when the
communicating party is an attacker  or the user , is given
respectively by:

The \textit{expected loss} is in either case bounded by the {\em worst-case expected loss}:

If we can find an expression that bounds both  and
, we automatically obtain a bound on the expected
loss, .

The remainder of this section is organised as
follows. Section~\ref{sec:threshold-choice} shows how a nearly-optimal
threshold  for a given number of rounds  can be chosen and
gives bounds on the expected loss for that choice.
Section~\ref{sec:rounds-choice} shows how a nearly-optimal number of
rounds  can be chosen and gives further bounds.
\subsection{Choice of threshold}
\label{sec:threshold-choice}
We want to choose a threshold  such that no matter whether the
prover  is the attacker  or the legitimate user  the
expected loss  is as small as possible.  The
problem is that as we \textit{increase} the threshold ,
 \textit{decreases}, while  \textit{increases}. The opposite is happening when we
\textit{decrease} the threshold .  Thus, to minimise the
worst-case expected loss, we can choose a threshold  such that
.  A
particular choice of the threshold  that minimises an upper
bound on the worst-case expected loss is given in
Theorem~\ref{thm:threshold}.  As an intermediate step, we obtain a
bound on the worst-case expected loss for {\em any} given threshold
. Formally, we can show the following:
\begin{lemma}
  Let  be the error of the -th round.  If, for all
  , it holds that 
  and , for some  such that , then:

\end{lemma}
\begin{IEEEproof}
  The expected loss when , is simply:
  
  the last two steps used the fact that  and the
  \textit{Hoeffding inequality}~\eqref{eq:hoeffding}. Specifically, in
  our case, Lemma~\ref{lem:hoeffding} (page~\pageref{lem:hoeffding})
  applies with . Then, it is easy to see that  for all  and , so .  By setting ,
  we obtain , which we can plug into the above
  inequality, thus arriving at the required result.  The user case,
  , is handled similarly and we conclude that .
\end{IEEEproof}
Having bounded the loss suffered when choosing a specific threshold,
we now choose a threshold  that minimises the above bound for
fixed . In fact, we can show that such a threshold results in a
particular loss bound.
\begin{theorem}
  Let  and select
  
  If , then the expected loss  is
  bounded by:
  
  with .
  \label{thm:threshold}
\end{theorem}
\begin{IEEEproof}
  Substitute \eqref{eq:opt-threshold} in
  the first exponential of \eqref{eq:hoeffding-loss-bound} to obtain:
  
  It is easy to see that the exact same result is obtained by
  substituting \eqref{eq:opt-threshold} in the second exponential of \eqref{eq:hoeffding-loss-bound}.
Thus, both
   and  are bounded by the same
  quantity and consequently, so is . Thus,
  
  where we simplified the bound by noting that
  .
\end{IEEEproof}
The intuition behind the algorithm and the analysis is that it is
possible to bound the probability that  makes less errors than
expected, or that  makes more than expected.  For this reason, the
 chosen in the theorem must lie between  and . This
also implies a lower bound on the number of rounds .  

\subsection{Choice of the number of rounds}
\label{sec:rounds-choice}
Using similar techniques to those employed for obtaining a suitable
value for the threshold, we now indicate a good choice for the number
of rounds  and provide a matching bound on the expected loss.
\begin{theorem}
  Assume . If we choose 
  and
  
  where  and , then the expected
  loss  is bounded by:
  
  \label{the:rounds}
\end{theorem}
\begin{IEEEproof}
  We shall bound each one of the summands of \eqref{eq:threshold-loss-bound}
  by .
For the first term we have:
  
  For the second term, by noting that , we have:
  
  Summing the two bounds, we obtain the required result.
\end{IEEEproof}

This theorem proves that our {\em worst-case expected loss} 
grows sublinearly both with increasing round cost (with rate
) and with increasing authentication costs (with
rate . Furthermore, the {\em expected loss} is
bounded symmetrically for both user and attacker access. Finally,
there is a strong dependence on the margin  between the
attacker and the user error rates, which is an expected result.

\section{Analysis of RFID thresholded protocols}
\label{sec:specific-protocols}

Currently, the only known protocols employing an authentication
phase without any error correction that we are aware of are {\em RFID
  distance bounding} protocols. For that reason, we shall examine the
properties of two such protocols, for which it is possible to derive
expressions for  given a symmetric channel noise .

The {\Swiss} protocol~\cite{KimAKSP-2008-icisc} and the
variant {\Hitomi}~\cite{sheddingLight}
are thresholded authentication protocols satisfying
Definition~\ref{def:thresholded-auth}.  It is easy to show (for
details see~\cite{sheddingLight}) that, for those two protocols, under
channel noise , the expected error bounds  are given
by: , , where we note in
passing that  and so .
Finally, by substituting 
in \eqref{eq:threshold-loss-bound}, we obtain the following bound for
{\Swiss} and {\Hitomi}:


We have performed a number of experiments to test the efficacy of
these protocols, when used in conjunction with our suggested, as well
as the optimal values of the threshold and number of rounds.  In all
of the experiments shown here, we chose the following values for the
losses: , , .  

Figure~\ref{fig:ExpectedLossVsN-a} depicts the bound
\eqref{eq:swiss-knife-threshold} on the expected loss, as well as the
actual  calculated via the binomial formula, when the
threshold , calculated from (\ref{eq:opt-threshold}), is used.
We plot both the expected loss and the bound for two different channel
noise levels , where the number of
rounds  varies from  to . Obviously, the bound is greater
than the actual expected loss, while it approaches it exponentially
fast as  increases.  In addition, the losses are higher when the
amount of noise increases.

Furthermore, we can see that there are minimising values of  for
all cases. While they do not coincide for the bound and the actual
\textit{expected loss}, they are within a factor of two of each
other. Finally, , the value of  minimising the bound, is
always greater than , the value of  that minimises the {\em
  worst-case expected loss}.  Since the probability of incorrect
authentication always decreases with increasing , this implies that
any additional losses incurred by using  is due to transmission
costs only.

Figure~\ref{fig:expected-losses-noise-nopt}
examines the effect of noise in more detail.  In particular,
it depicts the \textit{worst-case expected loss} for the optimal number of
rounds , denoted by  in the legend.  This is
of course smaller than , the loss suffered by
choosing , with the gap becoming smaller for larger error
rates. Since when this occurs, the \textit{expected loss} is very close to
, this implies that the bound of the Theorem~1 needs considerable
tightening for small . Finally,  is considerably
looser, and thus it is only of theoretical interest.


Finally, due to the way that the protocols under consideration
generate challenges and responses, the number of rounds  must be
smaller than the length  of the messages in the initialization
phase and also the length of the key .  Thus, in practice we will
always select a number of rounds .  This
condition is necessary since the responses  for both protocols are
calculated using an XOR operation between the secret key  and a
constant value (i.e. either  or ) that has the same
length . Since these protocols are only used as examples, it is
beyond the scope of this paper to propose protocols that do not suffer
from this limitation.

\begin{figure}
\centering
\subfigure[The \textit{Expected Loss}  and the bound on the \textit{Expected Loss}  vs. the number of bits  exchanged during the rapid single bit exchange for various values of channel noise .]
{
  \label{fig:ExpectedLossVsN-a}
  \psfrag{T1, BER=0.01}[r][r][0.75][0]{, }
  \psfrag{EL, BER=0.01}[r][r][0.75][0]{, }
  \psfrag{T1, BER=0.1}[r][r][0.75][0]{, }
  \psfrag{EL, BER=0.1}[r][r][0.75][0]{, }
  \psfrag{hn number of bits}[B][B][0.75][0]{ (number of rounds)}
  \psfrag{Expected Loss}[B][B][0.75][0]{Expected loss}
  \includegraphics[width=0.95\columnwidth]{ExpectedLossVsN.eps}
}
\subfigure[The worst-case expected Loss  and the bounds  and
 from theorems 1 and 2 respectively vs. the channel error rate
.]{
  \label{fig:expected-losses-noise-nopt}
  \psfrag{ns}[r][r][0.75][0]{}
  \psfrag{hns}[r][r][0.75][0]{}
  \psfrag{ELBT1}[r][r][0.75][0]{}
  \psfrag{ELBT2}[r][r][0.75][0]{}
  \psfrag{bit error rate}[B][B][0.75][0]{ (channel noise)}
  \psfrag{Expected Loss}[B][B][0.75][0]{Expected loss}
  \includegraphics[width=0.95\columnwidth]{ExpectedLossOptimalN.eps}
}
\caption{Comparison of all losses.}
\label{fig:losses-rounds}
\end{figure}

\section{Estimating }
\label{sec:noise}
In this section, we discuss how it is possible to calculate the
channel error rate , which is used in the expressions for
. This can be done by leveraging the coding performed during
the initial and final phases of the protocol.  We assume some coding
function , with , and a metric
 on  (where usually  and  is the
Hamming distance) such that:

is the minimum (Hamming) distance between valid codewords.  For a
given , the source transmits  and the
sink receives , with .  As
before, we assume that the physical channel has a symmetric error rate
, where  denotes the
-th bit of .  This is then decoded as . Let  be
the number of errors in the string , or more precisely .  Let  be the distance between the
closest valid codeword  and the received
. If , then .




The crux of our method for estimating  relies on the number of
errors  being less than , in which case, the
estimated number of errors  will equal .  Let
 be our empirical error rate.
In that case, the expected empirical error rate equals the true error
rate. More formally:

If  then the protocol fails in any case, due
to decoding errors in the initial or final phases.  If not, then the
above equation holds and we can obtain high probability bounds for
 via the \textit{Hoeffding inequality} (Appendix,  Lemma \ref{lem:hoeffding}).  In particular, it is easy to
show that, for any :

by substituting the square-root term into (\ref{eq:hoeffding}), and
setting , , , .
Consequently, for the {\Swiss} family of protocols the following
values for  and  hold with probability :

While we were unable to provide bounds on the performance of this
choice, experimental investigations presented in the next section
indicate that it has good performance.


\subsection{Evaluation Experiments}
We have performed some experiments to evaluate our methods in a more
realistic setting, involving an RFID distance bounding protocol with a
\textit{rapid-bit exchange} phase.  We perform simulations for two
cases: Firstly, when a \textit{legitimate user}  is trying to get
authenticated and secondly, when an \textit{adversary}  is trying
to perform a mafia fraud attack.  We have estimated the
\textit{worst-case expected loss} by running  experiments for
each case, obtaining a pair of estimates ,
 by averaging the loss , as defined in
\eqref{eq:loss}, incurred in each experiment and taking the maximum of
the two.  In all of the experiments shown in this section, we chose
the following values for the losses: , , , while we used  for the coded messages in the
initialisation phase.

The actual values  depend on , which is unknown. We
compare three methods for choosing . Firstly, guessing a
value  for the channel noise. Secondly, using the maximum
likelihood noise estimate .  In both
cases, we simply use  as described at the beginning of
Sec.~\ref{sec:specific-protocols} to obtain .  In the third
case, we use the high-probability bounds~\eqref{eq:pa-hp} for , with an arbitrary value of .

In the first experiment, we use the nearly-optimal threshold and
number of rounds that we have derived in our analysis.  In the second
experiment, we replace our choice of threshold with a choice similar
to that of Baign\`{e}res et al.~\cite{ProvSec2010}. Their threshold is
derived via the likelihood ratio test, which is asymptotically optimal
(c.f. ~\cite{Degroot:OptimalStatisticalDecisions,Chernoff:SequentialDesignExperiments})

Since in our case we have unequal losses  and , we
re-derive their threshold via a Bayesian test (to which a Bayesian
formulation of the Neymann-Pearson
lemma~\cite{Degroot:OptimalStatisticalDecisions} applies) to obtain:

Interestingly, for small , the form of  is
similar to : Let  such that 
and . Then (\ref{eq:asymptotic-threshold})
can be approximated by:

More details on the derivation of \eqref{eq:asymptotic-threshold} are
given in Appendix~\ref{app:asymptotics}.

Figure~\ref{fig:loss-comparison} depicts the \textit{worst-case
  expected loss}  as a function of the actual noise .
Figure~\ref{fig:LossComparison-a} shows  using the threshold
 derived from our {\em expected loss}
analysis~\eqref{eq:opt-threshold}, while in
Figure~\ref{fig:LossComparison-b} we use the asymptotically optimal
threshold of \eqref{eq:asymptotic-threshold}. In both cases, we plot
, while the actual noise  is changing, for a number of
different cases. Initially, we investigate the evolution of 
for three arbitrarily chosen values . Additionally, we examine the evolution of the
{\em worst-case expected loss}, when the noise is empirically
estimated  and finally when  and
 are calculated via equation (\ref{eq:pa-hp}) with .




As it can be seen in Figure~\ref{fig:loss-comparison}, in all cases
(using ours Figure~\ref{fig:LossComparison-a} or Baign\`{e}res et
al. \cite{ProvSec2010} threshold Figure~\ref{fig:LossComparison-b})
the \textit{worst-case expected loss} is very low for small values of
the actual noise and increases sharply when the actual noise exceeds
the value of . It is interesting to see that when we use the
optimistic\footnote{Experiments with pessimistic high probability
  estimates for the noise showed a significant increase in the number
  of rounds used, which resulted in a higher expected loss.}
high probability estimates for , we obtain almost always
better performance than simply guessing the noise, or using the plain
empirical estimate  directly. Furthermore, using the
asymptotically optimal threshold \eqref{eq:asymptotic-threshold}, we
observe a deterioration in the results.



As mentioned in the related work (Sec.~\ref{sec:relatedwork}), the
choice of the threshold by Baign\`{e}res et al. \cite{ProvSec2010} is
only asymptotically optimal. Ours, while not optimal, gives a
worst-case expected loss guarantee for any finite sample size. Thus,
it has better performance when the asymptotic approximation is not
sufficiently good, which occurs when both the number of rounds  and
the gap  are small.



\begin{figure}
\centering
\subfigure[Our threshold]{
 \label{fig:LossComparison-a}
 \psfrag{omega}[B][B][1][0]{}
 \psfrag{Expected Loss}[B][B][0.75][0]{Expected loss}
 \psfrag{hw=0.1}[B][B][0.55][0]{}
 \psfrag{hw=0.01}[B][B][0.55][0]{}
 \psfrag{hw=0.001}[B][B][0.55][0]{}
 \psfrag{hw=k/n}[B][B][0.55][0]{}
 \psfrag{d=0.1}[B][B][0.55][0]{}
 \psfrag{d=0.01}[B][B][0.55][0]{}
 \includegraphics[width=0.95\columnwidth]{Figure4PlotLUAd}
}
\subfigure[Asymptotic threshold]{
 \label{fig:LossComparison-b}
 \psfrag{omega}[B][B][1][0]{}
 \psfrag{Expected Loss}[B][B][0.75][0]{Expected loss}
 \psfrag{hw=0.1}[B][B][0.55][0]{}
 \psfrag{hw=0.01}[B][B][0.55][0]{}
 \psfrag{hw=0.001}[B][B][0.55][0]{}
 \psfrag{hw=k/n}[B][B][0.55][0]{}
 \psfrag{d=0.1}[B][B][0.55][0]{}
 \psfrag{d=0.01}[B][B][0.55][0]{}
 \includegraphics[width=0.95\columnwidth]{Figure4PlotLUAdv}
}
\caption{The worst-case expected loss as a function of noise. We plot
 the evolution of the loss as noise changes, for a number of
 different cases. Firstly, for the case where we arbitrarily assume a
 noise value . Secondly, for an empirically estimated , and finally for  calculated via equation
(\ref{eq:pa-hp}) with .}
\label{fig:loss-comparison}
\end{figure}

Finally, note that in the {\Swiss} and {\Hitomi} protocols, the size
of the initialisation messages is fixed, since the number of rounds
 is fixed.  In practice, one would have to modify these protocols
in order for them to work with an arbitrary number of rounds, but this
subject is beyond the scope of this paper. Our focus is mainly the
{\em expected loss} analysis of the noisy authentication phase.


\section{Conclusion}
\label{sec:conclusion} 

We have performed an expected loss analysis for thresholded
authentication protocols under noise.  This is particularly
significant for areas of communications where challenges and responses
are costly and where there exists significant uncertainty about the
correctness of any single response. More precisely, we have shown how
to select a threshold and provided an upper bound on the worst-case
expected loss. Additionally, we have shown how to select the number of
rounds in order to tighten the loss and obtained a loss bound that
holds uniformly and depends only on the error rates of the user and
attacker and the individual losses.  We have applied these choices of
threshold and number of rounds to two representative distance bounding
protocols, the {\Swiss} and the \Hitomi. In addition, we have
presented a high-probability method for estimating the channel noise
for such protocols.  We have examined its performance in further
simulation experiments with {\em unknown channel noise}, and shown
that we obtain uniformly superior results to guessing or direct
empirical noise estimates. Finally, we repeated those experiments with
a asymptotically optimal threshold similar to that used by
Baign\`{e}res et al.\cite{ProvSec2010}. Our results indicate a
significant improvement through the use of a threshold with uniform,
rather than asymptotic, guarantees. Consequently, it is our view that
algorithms motivated by an asymptotic analysis should be avoided in
the finite-sample regime of most challenge-response authentication
protocols.







\section*{Acknowledgements}
This work was partially supported by the Marie Curie IEF project
``PPIDR: Privacy-Preserving Intrusion Detection and Response in
Wireless Communications'', grant number: 252323 and by the IM-CLeVeR
EU FP7 Integrated Project, grant number: 231722.

\appendix
\techreport{\section{Auxilliary results}}
\subsection{Useful formulas}
\label{sec:binomial}
If  are Bernoulli random variables with  and  for all , then

This probability can be bounded via \textit{Hoeffding's inequality} \cite{Hoeffding}:
\label{sec:Hoeffding}
\begin{lemma}[Hoeffding]
  For independent random variables  such that
  , with   and :
  
  \label{lem:hoeffding}
\end{lemma}
\iffalse
Specifically for Bernoulli trials, we can use the Chernoff-Hoeffding
bound~\cite{Hoeffding}:
\begin{lemma}[Chernoff-Hoeffding]
  For independent random variables  such that , with  and :
  
  \label{lem:chernoff-hoeffding}
\end{lemma}
\fi
\subsection{On asymptotic thresholds}
\label{app:asymptotics}
One way to obtain an asymptotically optimal threshold is to employ a
Bayesian hypothesis test~\cite{Degroot:OptimalStatisticalDecisions}.
This requires defining a prior probabilty on the possible
hypotheses. In our case, the hypothesis set is , on
which we define a prior probability . For  errors, the
probability of observing  errors out of  observations is
given by  and  for the attacker
and user respectively and it follows a binomial distribution with
parameters  respectively. Given an observed error , the
{\em posterior} probability of any hypothesis  is:

We then define a decision set , where  means we decide that the prover is
an attacker and  means we decide that the prover is a user
and  means that we are undecided.  Finally, we define
a loss function , such that  is our loss when we decide  and  is the correct
hypothesis.  The expected loss of decision , under
our prior and given  errors out of  is:

where  denotes expectation with respect to the prior .
Now define the decision function :

This decision function minimises  by construction
(c.f. \cite{Degroot:OptimalStatisticalDecisions} ch. 8). 
The following
remark is applicable in our case:
\begin{remark} Assume i.i.d errors with , so that
  we can use a binomial probability for .  Set the
  loss function  to be , 
  and  otherwise.  Then the decision
  function~\eqref{eq:bayes-decision} becomes equivalent to:

where

\end{remark}
\begin{IEEEproof}
  We start by calculating the expected loss for either decision. First:
  
  due to our choice of  and .  Similarly,
  
  Combining the above expressions, the decision
  function~\eqref{eq:bayes-decision} can then be written so that we
  make decision  if and only if:
  
  Finally, replacing \eqref{eq:binomial} with means 
  respectively and taking logarithms we obtain:
  
  as a condition for deciding . With some elementary
  manipulations, we arrive at the required result.
\end{IEEEproof}
Given
the conditions of the previous remark, it is easy to see
(c.f. ~\cite{Degroot:OptimalStatisticalDecisions} ch.~8) that the
decision function  minimises the Bayes risk:

Furthermore, for , we obtain
\eqref{eq:asymptotic-threshold}.  In addition, this choice also
minimises an upper bound on the worst-case expected loss since:

for uniform .

Finally, the asymptotic optimality of Bayesian testing generally
follows from Bayesian {\em consistency}
(c.f. \cite{Degroot:OptimalStatisticalDecisions} ch. 10). More
specifically, \cite{Chernoff:AsymptoticEfficiency} has proved the
asymptotic optimality of Bayes solutions for hypothesis testing of the
type examined here.  

\bibliographystyle{plain}
\bibliography{threshold}

\end{document}
