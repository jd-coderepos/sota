\section{Experiments}




\begin{figure}[tb]
   \begin{minipage}{0.48\textwidth}
      \centering
         \includegraphics[width=0.95\columnwidth]{figures/speed_acc.pdf}
      \caption{
         Speed vs. accuracy trade-off of different inference approaches applied to the MuCon method.
         Using FIFA we can achieve a better speed vs. accuracy trade-off compared to frame sampling or hypothesis pruning in exact inference.}
      \label{fig:speed_acc}
   \end{minipage}\hfill
   \begin{minipage}{0.48\textwidth}
      \centering
         \includegraphics[width=0.95\columnwidth]{figures/len_energy.pdf}
      \caption{Effect of the length energy multiplier for Laplace and Gaussian length energy. Accuracy is calculated on the breakfast dataset using FIFA applied to the MuCon approach trained in the weakly supervised action segmentation setting.}
      \label{fig:len_energy}
   \end{minipage}
\end{figure}


\subsection{Evaluation Protocols and Datasets}
We evaluate FIFA on 3 different tasks: weakly supervised action segmentation, fully supervised action segmentation, and weakly supervised action alignment. Results for action alignment are included in the supplementary material.
We obtain the source code for the state-of-the-art approaches on each of these tasks and train a model using the standard training configuration of each model.
Then we apply FIFA as a replacement for an existing inference stage or as an additional inference stage.

We evaluate our model using the Breakfast~\cite{breakfast} and Hollywood extended~\cite{hollywoodextended} datasets on the 3 different tasks. Details of the datasets are included in the supplementary material.

\begin{comment}
Breakfast is the most popular dataset currently used for action segmentation.
It contains more than 1.7k videos of different cooking activities. The dataset consists of 48 different fine-grained actions. In our experiments, we follow the 4 train/test splits provided with the dataset and report the average.
The main performance metrics used for weakly supervised action segmentation and alignment are the same as the previous approaches.
The input features are also kept the same depending on the approach we use FIFA with.
\end{comment}



\subsection{Results and Discussions}
In this section, we study the speed-accuracy trade-off and the impact of the length model. 
Additional ablation experiments are included in the supplementary material.
\paragraph{Speed vs. Accuracy Trade-off.}
One of the major benefits of FIFA is the flexibility of choosing the number of optimization steps. The number of steps of the optimization can be a tool to trade-off speed vs. accuracy.
In exact inference, we can use frame-sampling i.e. lowering the resolution of the input features, or hypothesis pruning i.e. beam search for speed vs. accuracy trade-off.

Figure~\ref{fig:speed_acc} plots the speed vs. accuracy trade-off of exact inference compared to FIFA.
We observe that FIFA provides a much better speed-accuracy trade-off as compared to frame-sampling for exact inference. The best performance after 50 steps with  improvement on the MoF accuracy compared to not performing any inference.



\begin{comment}
   
\begin{table}[tb]
   \centering
   \resizebox{0.75\columnwidth}{!}{\begin{tabular}{cccccc }
         \toprule
         Num. Steps & MoF & MoF-BG & IoU & IoD & Time (min) \\
         \midrule
         No inference & 45.4 & 44.7 & 37.3 & 51.2 & 1.0\\
         \midrule
         2 steps  & 47.9 & 47.1 & 39.8 & 53.0 & 1.2 \\
         5 steps  & 49.1 & 48.3 & 40.0 & 52.8 & 1.5 \\
         10 steps & 50.1 & 49.4 & 40.2 & 52.9 & 2.0\\
         30 steps & 51.2 & 50.6 & 41.0 & 53.2 & 4.2\\
         50 steps & \textbf{51.3} & \textbf{50.7} & \textbf{41.1} & \textbf{53.3} & 6.5 \\
         60 steps & \textbf{51.3} & \textbf{50.7} & \textbf{41.1} & \textbf{53.3} & 7.7 \\
         \midrule
         Exact Inference & 50.7 & 50.3 & 40.9 & 54.0 & 32.85 \\
         \bottomrule
      \end{tabular}
    }
   \caption{Impact of the number of optimization steps for FIFA+MuCon for weakly supervised action segmentation on the Breakfast dataset.
}
   \label{tab:optimization_steps}
\end{table}

\end{comment}


\paragraph{Impact of the Length Energy.}
For the length energy, we assume that the segment lengths follow a Laplace distribution. Figure~\ref{fig:len_energy} shows the impact of the length energy multiplier on the performance. While the best accuracy is achieved with a multiplier of , our approach is robust to the choice of these hyper-parameters. We further experimented with a Gaussian length energy. However, as shown in the figure, the performance is much worse compared to the Laplace energy. This is due to the quadratic penalty that dominates the total energy, which makes the optimization biased towards the initial estimate and ignores the observation energy.  




\paragraph{Impact of Length Model Initialization.}
Since FIFA starts with an initial estimate for the lengths, the choice of initialization might have an impact on the performance. Table~\ref{tab:initialization} shows the effect of initializing the lengths with equal values compared to using the length model of MuCon~\cite{mucon} for the weakly supervised action segmentation on the Breakfast dataset. As shown in the table, FIFA is more robust to initialization compared to the exact inference as the drop in performance is approximately half of the exact inference.

\begin{table}[tb]
   \centering
   \resizebox{.45\columnwidth}{!}{\begin{tabular}{clc}
         \toprule
         Inference Method & initialization & MoF   \\
         \midrule
           Exact & MuCon~\cite{mucon}    & \textbf{50.7}  \\
                 & Equal  &  48.8 (-1.9) \\
         \midrule
           FIFA   & MuCon~\cite{mucon}   &  \textbf{51.3} \\
                  & Equal &  50.2 (-1.1) \\
         \bottomrule
      \end{tabular}
    }
   \caption{Impact of the Length Model initialization for MuCon using exact inference and FIFA for weakly supervised action segmentation on the Breakfast dataset.}
   \label{tab:initialization}
\end{table}


\begin{comment}

\paragraph{Optimizer and Its Learning Rate}
The choice of the optimizer used to update the length estimates using the calculated gradients is one of the hyper-parameters of our approach.
We have experimented with two optimizers SGD and Adam.
As shown in Figure~\ref{fig:learning_rate_adam_sgd}, the best performing value for the learning rate hyper-parameter depends on the optimizer used.
For SGD a low value of  achieves the best performance with higher values causing major drops in performance.
On the other hand, Adam optimizer works well with a range of learning rate values as it has an internal mechanism to adjust the learning rate. The best performance for Adam is observed at .

\begin{figure}[t]
    \centering
       \includegraphics[width=0.9\columnwidth]{figures/learning_rate.pdf}
    \caption{Effect of the learning rate on the performance of weakly supervised action segmentation using FIFA applied on the MuCon approach. Accuracy is calculated on the Breakfast dataset.}
    \label{fig:learning_rate_adam_sgd}
 \end{figure}

 We further investigate and notice that the reason SGD performs so poorly for large values of the learning rate is that it fluctuates and is not able to optimize the energy effectively. Figure~\ref{fig:energy_adam_vs_sgd} shows the value of the approximate energy during the optimization for Adam and SGD for the same inference.
 We observe that a large learning rate causes SGD to fluctuate while Adam is stable and achieves a lower energy value at the end of the optimization.

 \begin{figure}[t]
    \centering
       \includegraphics[width=\columnwidth]{figures/adam_vs_sgd.pdf}
    \caption{The value of the approximate energy during FIFA optimization for SGD and Adam optimizer for the same inference.}
    \label{fig:energy_adam_vs_sgd}
 \end{figure}




\end{comment}
\begin{figure*}[t]
    \centering
       \includegraphics[width=0.9\linewidth]{figures/mucon_breakfast_2.pdf}
    \caption{Visualization of the FIFA optimization process. On the right the values of the total approximate energy is plotted.
    On the left, negative log probability values, ground truth segmentation, optimization initialization, the masks and the segmentation after inference is ploted.}
    \label{fig:q_res}
 \end{figure*}


\subsection{Comparison to State of the Art}



In this section, we compare FIFA to other state-of-the-art approaches.

\paragraph{Weakly Supervised Action Segmentation.}
We apply FIFA on top of two state-of-the-art approaches for weakly supervised action segmentation namely MuCon~\cite{mucon} and CDFL~\cite{CDFL} on the Breakfast dataset~\cite{breakfast} and report the results in Table\ref{tab:weak_segmentation}. FIFA applied on CDFL achieves a 12 times faster inference speed while obtaining results comparable to exact inference.
FIFA applied to MuCon achieves a 5 times faster inference speed and obtains a new state-of-the-art performance on the Breakfast dataset on most of the metrics.

\begin{table}
   \begin{minipage}{0.48\textwidth}
      \centering
      \resizebox{\columnwidth}{!}{\begin{tabular}{lccccc}
            \toprule
            Method & MoF & MoF-BG & IoU & IoD & Time (min)  \\
            \midrule
            ISBA~\cite{isba} & 38.4 & 38.4 & 24.2 & 40.6 & 0.01 \\
            NNV~\cite{richard2018nnviterbi} & 43.0 & - & - & - & 234 \\
            D3TW~\cite{d3tw} & 45.7 & - & - & - & - \\
            \midrule
            CDFL~\cite{CDFL} & 50.2 & 48.0 & 33.7 & 45.4 & - \\
            CDFL & 49.4 & 47.5 & 35.2 & 46.4 & 260 \\
            FIFA + CDFL  & 47.9  & 
                              46.3  & 
                              34.7  & 
                              48.0  &   
                              20.4 (12.8)\\
            \midrule
            MuCon~\cite{mucon} & 47.1 & - & - & - & - \\
            MuCon & \underline{50.7} & \underline{50.3} & \underline{40.9} & \textbf{54.0} & 4.1 \\FIFA + MuCon  & \textbf{51.3}  & 
                              \textbf{50.7}  & 
                              \textbf{41.1}  & 
                              \underline{53.3}   & 
                              0.8 (5.1)\\\bottomrule
         \end{tabular}
      }
      \caption{Results for weakly supervised action segmentation on the Breakfast dataset.  indicates results obtained by running the code on our machine.} 
      \label{tab:weak_segmentation}
   \end{minipage}\hfill
   \begin{minipage}{0.48\textwidth}
      \centering
      \resizebox{\columnwidth}{!}{\begin{tabular}{lccccc}
            \toprule
            Method & \multicolumn{3}{c}{F1@\{10, 25, 50\}} & Edit & MoF  \\
            \midrule
            BCN~\cite{wang2020boundary} & 68.7 & 65.5 & \underline{55.0} & 66.2 & \textbf{70.4}  \\
ASRF~\cite{ishikawa2020alleviating} & \underline{74.3} & 68.9 & \textbf{56.1} & 72.4 & 67.6  \\
\midrule
            MS-TCN++~\cite{li2020ms} & 64.1 & 58.6 & 45.9 & 65.6 & 67.6  \\
            FIFA + MS-TCN++ & \underline{74.3} & \underline{69.0} & 54.3 & \underline{77.3} & 67.9 \\
            \midrule
            MS-TCN~\cite{MS-TCN} & 52.6 & 48.1 & 37.9 & 61.7 & 66.3  \\
            FIFA + MS-TCN   & \textbf{75.5} & \textbf{70.2} & 54.8 & \textbf{78.5} & \underline{68.6}\\
            \bottomrule
         \end{tabular}
      }
      \caption{Results for fully supervised action segmentation setup on the Breakfast dataset.}
      \label{tab:full_segmentation}
   \end{minipage}
\end{table}



Similarly for the Hollywood extended dataset~\cite{hollywoodextended} we apply FIFA to MuCon~\cite{mucon} and report the results in Table~\ref{tab:weak_hollywood}.
FIFA applied on MuCon achieves a 4 times faster inference speed while obtaining results comparable to exact inference.

\begin{comment}
   
\paragraph{Weakly Supervised Action Alignment}
Similar to weakly supervised action segmentation, we apply FIFA on top of CDFL and MuCon for weakly supervised action alignment task and report the results in Table~\ref{tab:weak_alignment}.
Our experiments show that FIFA applied on top of CDFL achieves state-of-the-art or better than state-of-the-art results on MoF and Mof-BG metrics, whereas FIFA applied on top of MuCon achieves state-of-the-art results for IoD and IoU metrics. 

\begin{table}[tb]
    \centering
    \resizebox{\columnwidth}{!}{\begin{tabular}{lcccc}
          \toprule
          Method & MoF & MoF-BG & IoU & IoD \\
          \midrule
          ISBA~\cite{isba} & 53.5 & 51.7 & 35.3 & 52.3\\
          DTW~\cite{d3tw} & 57.0 & - & - & 56.3\\
          CDFL~\cite{CDFL} & 63.0 & 61.4 & 45.8 & \underline{63.9}\\
          ADP~\cite{ghoddoosian2021action} & \underline{64.1} & \textbf{65.5} & 43.0 & - \\
          \midrule
          FIFA + CDFL  & \textbf{65.3} & \underline{64.3} & \underline{46.3} & 61.3\\
          FIFA + MuCon  & 61.4 & 61.2 & \textbf{48.4} & \textbf{64.1}\\
          \bottomrule
       \end{tabular}
     }
    \caption{Results for weakly supervised action alignment on the Breakfast dataset.}
    \label{tab:weak_alignment}
 \end{table}
\end{comment}



\paragraph{Fully Supervised Action Segmentation.}
In the fully supervised action segmentation we apply FIFA on top of MS-TCN~\cite{MS-TCN} and its variant MS-TCN++~\cite{li2020ms} on the Breakfast dataset~\cite{breakfast} and report the results in Table~\ref{tab:full_segmentation}.
MS-TCN and MS-TCN++ are approaches that do not perform any inference at test time. This usually results in over-segmentation and low F1 and Edit scores.
Applying FIFA on top of these approaches improves the F1 and Edit scores significantly.
FIFA applied on top of MS-TCN achieves state-of-the-art performance and sets new state-of-the-art performance on most metrics.

For the Hollywood extended dataset~\cite{hollywoodextended}, we train MS-TCN~\cite{MS-TCN} and report results comparing exact inference (EI) compared to FIFA in Table~\ref{tab:full_hollywood}. We observe that MS-TCN using an inference algorithm achieves new state-of-the-art results on this dataset. FIFA is comparable or better than exact inference on this dataset.



\begin{table}
   \begin{minipage}{0.48\textwidth}
      \centering
      \resizebox{\columnwidth}{!}{\begin{tabular}{lcccl}
            \toprule
            Method & MoF-BG & IoU & Time (speedup)\\
            \midrule
            ISBA~[6] & 34.5 & 12.6 & -  \\
            D3TW~[x] & 33.6  &   & -  \\
            CDFL~[x] & 40.6  & 19.5 &  - \\
            MuCon~[33]  & 41.6  &   & - \\
            \midrule
            MuCon  & 40.1  & 13.9  & 53 \\
            MuCon + FIFA  & 41.2  & 13.7  & 13 (4.1) \\
            \bottomrule
         \end{tabular}
      }
      \caption{Results for weakly supervised action segmentation on the Hollywood extended dataset. Time is reported in seconds.  indicates results obtained by running the code on our machine.}
      \label{tab:weak_hollywood}
   \end{minipage}\hfill
   \begin{minipage}{0.48\textwidth}
      \centering
      \resizebox{\columnwidth}{!}{\begin{tabular}{lcccc}
            \toprule
            Method & MoF & MoF-BG & IoU & IoD \\
            \midrule
            HTK~[19] & 39.5 &   & 8.4 &  \\
            ED-TCN~[6] & 36.7 & 27.3 & 10.9 & 13.1 \\
            ISBA~[6] & 54.8 & 33.1 & 20.4 & 28.8\\
            \midrule
            MSTCN~[1] (+ EI)  & 64.9 & 35.0 & 22.6 & 33.2 \\
            MSTCN + FIFA  & 66.2 & 34.8 & 23.9 & 35.8 \\
            \bottomrule
         \end{tabular}
      }
      \caption{Results for fully supervised action segmentation on the Hollywood extended dataset. EI stands for Exact Inference.}
      \label{tab:full_hollywood}
   \end{minipage}
\end{table}

\subsection{Qualitative Example}



A qualitative example of the FIFA optimization process is depicted in Figure~\ref{fig:q_res}. For further qualitative examples, failure cases, and details please refer to the supplementary material.




%
