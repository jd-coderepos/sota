[{'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': '% true', 'Score': '29.50'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': '% info', 'Score': '89.84'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': '% true (GPT-judge)', 'Score': '29.87'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': 'BLEURT', 'Score': '-0.25'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': 'ROUGE', 'Score': '-9.41'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': 'BLEU', 'Score': '-4.91'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': 'MC1', 'Score': '0.22'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': 'MC2', 'Score': '0.39'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': '% true', 'Score': '20.44'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': '% info', 'Score': '97.55'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': '% true (GPT-judge)', 'Score': '20.56'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': 'BLEURT', 'Score': '-0.56'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': 'ROUGE', 'Score': '-17.75'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': 'BLEU', 'Score': '-17.38'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': 'MC1', 'Score': '0.21'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': 'MC2', 'Score': '0.33'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': '% true', 'Score': '26.68'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': '% info', 'Score': '89.96'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': '% true (GPT-judge)', 'Score': '27.17'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': 'BLEURT', 'Score': '-0.31'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': 'ROUGE', 'Score': '-11.35'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': 'BLEU', 'Score': '-7.58'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': 'MC1', 'Score': '0.20'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': 'MC2', 'Score': '0.36'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': '% true', 'Score': '53.86'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': '% info', 'Score': '64.50'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': '% true (GPT-judge)', 'Score': '53.24'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': 'BLEURT', 'Score': '0.08'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': 'ROUGE', 'Score': '1.76'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': 'BLEU', 'Score': '-0.16'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': 'MC1', 'Score': '0.19'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'TruthfulQA', 'Metric': 'MC2', 'Score': '0.35'}}]
