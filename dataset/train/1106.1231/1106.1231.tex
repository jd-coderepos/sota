
\documentclass[copyright,creativecommons]{eptcs}
\providecommand{\event}{GANDALF 2011} 


\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,latexsym, booktabs}
\usepackage{graphicx}
\usepackage{pifont}
\usepackage{newalg}

\newcommand{\back}{\!\!\!\!\! \!\!\!\!\!}
\newcommand{\attentionmr}[1]{{\bf MR: #1}\marginpar{\bf MR}}
\newcommand{\attentionmc}[1]{{\bf MC: #1}\marginpar{\bf MC}}
\newcommand{\attentionfb}[1]{{\bf FB: #1}\marginpar{\bf FB}}
\newcommand{\myurl}[2]{\href{#1}{#2}}

\providecommand{\urlalt}[2]{\href{#1}{#2}}
\providecommand{\doi}[1]{doi:\urlalt{http://dx.doi.org/#1}{#1}}

\def\altbox{\hspace{2mm}\nolinebreak\null\nolinebreak\hfill\Box}
\newenvironment{proof}{\noindent {\bf Proof:}}{\bigskip}

\newenvironment{tracex}{\ccspace{0.15}\noindent}{\ccspace{0.2}}
\newcommand{\cspace}{\vspace{0.15cm}}
\newcommand{\ccspace}[1]{\vspace{#1cm}}





\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{example}[theorem]{Example}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{conjecture}[theorem]{Conjecture}

\def\name#1{\mbox{\sc #1}}
\def\sos#1#2{{\def\arraystretch{1.6}\begin{array}{c}#1\\\hline
#2\end{array}}}

\newcommand{\nat}{{\mathbb N}}
\newcommand{\Nil}{{\sf nil}}
\newcommand{\ignore}[1]{}

\newcommand{\gor}{\;\big|\;}
\newcommand{\rec}{{\sf rec} \:}

\newcommand{\nar}[2]{\xrightarrow{#1}_{#2}}
\newcommand{\sar}[1]{\nar{#1}{}}
\newcommand{\notnar}[2]{\not \xrightarrow{#1}_{#2}}
\newcommand{\rnar}[2]{\stackrel{#1}{\rightsquigarrow}_{#2}}
\newcommand{\onar}[2]{\stackrel{#1}{\mapsto}_{#2}}
\newcommand{\timestep}{\nar{1}{}}


\newcommand{\dnar}[2]{\stackrel{#1}{\Rightarrow}_{#2}}

\def\car#1{\stackrel{{#1}}{{\longrightarrow}}_{c}}
\def\iar#1{\stackrel{{#1}}{{\longrightarrow}}_i}
\def\har#1{\stackrel{{#1}}{{\longrightarrow}}_h}

\newcommand{\Act}{{\cal A}}
\newcommand{\ur}{{\cal U}}
\newcommand{\B}{{\mathbb A}} \newcommand{\Bt}{\B_{\tau}} \newcommand{\X}{{\cal X}}
\newcommand{\Pg}{\tilde{\PG}}
\newcommand{\PG}{{\mathbb P}}
\newcommand{\Sg}{\tilde{\SG}}
\newcommand{\SG}{{\mathbb S}}

\newcommand{\clean}{{\sf clean}}
\newcommand{\unlab}{{\sf unmark}}
\newcommand{\urgent}{{\sf urgent}}
\newcommand{\fase}{\texttt{FASE}}
\newcommand{\cwb}{\texttt{CWB}}
\newcommand{\cwbnc}{\texttt{CWB-NC}}


\newcommand{\R}{\widehat{{\mathbb A}}} \newcommand{\Rt}{\widehat{{\mathbb A}}_{\tau}} \newcommand{\uRt}{\widehat{{\underline{\mathbb A}}}_{\tau}} 
\newcommand{\uread}[1]{\widehat{\underline{#1}}} 

\newcommand{\Lab}{{\sf L}}
\newcommand{\lab}{{\sf LAB}}
\newcommand{\subl}{\{\!|}
\newcommand{\subr}{|\!\}}
\newcommand{\Rem}{{\sf R}}
\newcommand{\CS}{{\sf P}}
\newcommand{\LCS}{{\sf LE}}
\newcommand{\up}{{\sf UE}}
\newcommand{\card}{\sharp \,}
\newcommand{\plus}[2]{ (#1)^{+#2}}
\newcommand{\nor}[1]{ (#1)_\varepsilon}
\newcommand{\tuple}{{\cal N}}
\newcommand{\rop}{\triangleright}

\newcommand{\denote}[1]{\llbracket #1\rrbracket}

\newcommand{\bool}{{\mathbb B}}
\newcommand{\ubool}{{\underline{\bool}}}
\newcommand{\kvalues}{{\mathbb K}}
\newcommand{\ukvalues}{{\underline{\kvalues}}}

\newcommand{\fa}{\mathit{f}}
\newcommand{\tr}{\mathit{t}}

\newcommand{\ufa}{\underline{\fa}}
\newcommand{\utr}{\underline{\tr}}

\newcommand{\Bv}{{\sf B}}
\newcommand{\Bvu}{\underline{{\sf B}}}
\newcommand{\Cv}{{\sf C}}
\newcommand{\Cvu}{\underline{{\sf C}}}

\newcommand{\rtb}[1]{{\it b_{{\rm #1}}rt}}
\newcommand{\rfb}[1]{{\it b_{{\rm #1}}rf}}
\newcommand{\wtb}[1]{{\it b_{{\rm #1}}wt}}
\newcommand{\wfb}[1]{{\it b_{{\rm #1}}wf}}
\newcommand{\wtc}[1]{{\it c_{{\rm #1}}wt}}
\newcommand{\wfc}[1]{{\it c_{{\rm #1}}wf}}
\newcommand{\rtc}[1]{{\it c_{{\rm #1}}rt}}
\newcommand{\rfc}[1]{{\it c_{{\rm #1}}rf}}
\newcommand{\rtbu}[1]{\underline{{\it b_{{\rm #1}}rt}}}
\newcommand{\rfbu}[1]{\underline{{\it b_{{\rm #1}}rf}}}
\newcommand{\wtbu}[1]{\underline{{\it b_{{\rm #1}}wt}}}
\newcommand{\wfbu}[1]{\underline{{\it b_{{\rm #1}}wf}}}
\newcommand{\wtcu}[1]{\underline{{\it c_{{\rm #1}}wt}}}
\newcommand{\wfcu}[1]{\underline{{\it c_{{\rm #1}}wf}}}
\newcommand{\rtcu}[1]{\underline{{\it c_{{\rm #1}}rt}}}
\newcommand{\rfcu}[1]{\underline{{\it c_{{\rm #1}}rf}}}

\newcommand{\urtb}[1]{\underline{{\it b_{{\rm #1}}rt}}}
\newcommand{\urfb}[1]{\underline{{\it b_{{\rm #1}}rf}}}
\newcommand{\uwtb}[1]{\underline{{\it b_{{\rm #1}}wt}}}
\newcommand{\uwfb}[1]{\underline{{\it b_{{\rm #1}}wf}}}
\newcommand{\module}{\, \mbox{ mod }\,}

\newcommand{\Kv}{{\sf K}}
\newcommand{\Kvu}{\underline{{\sf K}}}
\newcommand{\rk}[1]{{\it kr #1}}
\newcommand{\wk}[1]{{\it kw #1}}
\newcommand{\rc}[1]{{\it c_{#1}r}}
\newcommand{\wc}[1]{{\it c_{#1}w}}
\newcommand{\rku}[1]{\underline{{\it kr #1}}}
\newcommand{\wku}[1]{\underline{{\it kw #1}}}
\newcommand{\rcu}[1]{\underline{{\it c_{#1}r}}}
\newcommand{\wcu}[1]{\underline{{\it c_{#1}w}}}
\newcommand{\ruk}{\rk{1}}
\newcommand{\rdk}{\rk{2}}
\newcommand{\wuk}{\wk{1}}
\newcommand{\wdk}{\wk{2}}
\newcommand{\uruk}{\underline{\rk{1}}}
\newcommand{\urdk}{\underline{\rk{2}}}
\newcommand{\uwuk}{\underline{\wk{1}}}
\newcommand{\uwdk}{\underline{\wk{2}}}

\newcommand{\hide}[1]{[\Phi_{H(#1)}]}

\newcommand{\checky}{\ding{51}}
\newcommand{\checkn}{\ding{55}}

\newcommand{\vp}{{\sf PV}}
\newcommand{\vpu}{\underline{\vp}}
\newcommand{\req}{{\tt req}}
\newcommand{\enter}{{\tt enter}} \newcommand{\exit}{{\tt exit}}
\newcommand{\cs}{{\sf cs}}
\newcommand{\dekker}{{\it Dekker}}
\newcommand{\dijkstra}{{\it Dijkstra}}
\newcommand{\knuth}{{\it Knuth}}
\newcommand{\peterson}{{\it Peterson}}
\newcommand{\lamport}{{\it Lamport}}
\newcommand{\hyman}{{\it Hyman}}
\newcommand{\ldekker}{\dekker[\vp]}
\newcommand{\BK}{{\sf BK}}

\newcommand{\dekkera}{{\sf Dekker}} \newcommand{\dekkerb}{\dekkera}
\newcommand{\dekkerc}{\dekkera}
\newcommand{\dijkstraa}{{\sf Dijkstra}} \newcommand{\dijkstrab}{\dijkstra}
\newcommand{\knutha}{{\sf Knuth}} \newcommand{\knuthb}{\knutha}
\newcommand{\petersona}{{\sf Peterson}} \newcommand{\petersonb}{\petersona}
\newcommand{\petersonc}{\petersona}
\newcommand{\lamporta}{{\sf Lamport}} \newcommand{\lamportb}{\lamporta}
\newcommand{\proc}{{\tt P}}
\newcommand{\Top}{{\sf T}}

\newcommand{\ppath}[5]{#1 & #2 & #3 & #4 & #5}

\newcommand{\todo}[1]{
\begin{center}
{\bf TO-DO: #1} 
\end{center}
}



\title{Automated Analysis of MUTEX Algorithms with 
\thanks{
This work was supported by the PRIN Project `Paco:Performability-Aware
Computing: Logics, Models, and Languages'.}}
\author{Federico Buti, Massimo Callisto De Donato, Flavio Corradini, Maria Rita Di Berardini
\institute{School of Science and Technology, University of Camerino}
\email{\{federico.buti, massimo.callisto, flavio.corradini,
mariarita.diberardini\}@unicam.it}
\and
Walter Vogler
\institute{Institut f\"ur Informatik, Universit\"at Augsburg}
\email{vogler@informatik.uni-Augsburg.de}}
\def\titlerunning{Automated Analysis of MUTEX Algorithms with }
\def\authorrunning{F.~Buti et al.}
\begin{document}
\maketitle
 
\begin{abstract}
In this paper we study the liveness of several MUTEX solutions by
representing them as processes in PAFAS, a CCS-like process algebra
with a specific operator for modelling non-blocking reading behaviours.
Verification is carried out using the tool \fase, exploiting a
correspondence between violations of the liveness property and a special
kind of cycles (called {\em catastrophic cycles}) in some transition
system. We also compare our approach with others in the literature. The aim
of this paper is twofold: on the one hand, we want to demonstrate the
applicability of \fase\  to some concrete, meaningful examples; on the
other hand, we want to study the impact of introducing non-blocking
behaviours in modelling concurrent systems.
\end{abstract}


\section{Introduction}
MUTEX algorithms can exhibit an intricate behaviour and their correctness
can be hard to establish, because our intuitive notion of the program flow
can be misled by the fact that a shared variable may change from one
statement to the other, even if the process we are tracing does not modify
it. There are two kinds of properties to verify: the {\em safety property}
that two competing processes are never in their critical sections at the
same time, and the {\em liveness property} that a requesting process will
always enter its critical section. The first kind of property can be proven
fairly easily because only the static configuration of the system at any
time must be taken into account. The liveness property is much more
difficult to prove since it usually requires some fairness assumption.


In~\cite{CVJ02}, we have developed the process description language PAFAS,
a CCS-like~\cite{Mil89} process algebra  originally introduced as a tool
for evaluating the worst-case efficiency of asynchronous systems. Processes
are compared via a variant of the testing approach of De~Nicola and
Hennessy~\cite{DH84} where tests are test environments (or user behaviours)
together with a time bound. A process is embedded into the environment (via
parallel composition) and satisfies a (timed) test, if success is reached
before the time bound in {\em every} run of the composed system, i.e.\ even
in the worst case. This gives rise to a {\em faster-than} preorder relation
over processes that is naturally an {\it efficiency preorder}.
In~\cite{CV05} it has been shown that the test-based preorder
in~\cite{CVJ02} can equivalently be defined on the basis of a performance
function that gives the worst-case time needed to satisfy any test
environment. Whenever the above testing scenario is adapted to a setting
where tests belong to a very specific, but often occurring, class of {\em
request-response} user behaviours (processes serving these users receive
requests via an -action and provide responses via an -action) this
performance function is {\em asymptotically linear}. This provides us with
a quantitative measure of systems performance
that measures how fast the system under consideration responds to requests
from the environment. In~\cite{CV05} we have also shown how to determine
this performance measure for finite-state processes. This result only holds
for request-response processes (i.e. processes that can only perform 
and  as visible actions) that pass certain sanity checks: they must
not produce more responses than requests, and they must allow requests and
provide responses in finite time. While the first requirement can easily
be read off from the transition system, violation of the latter one
is characterised as the existence of a special kind of cycles (called
{\em catastrophic cycles}) in a reduced transition system (we remind the reader to \cite{CV05} for the complete description of such a reduction).
Finally, a corresponding tool \fase\ that allows the automated
evaluation of systems performance function has been developed; see
\cite{BCCDV09} for a first informal account. 

The notion of timing in PAFAS is strongly related to (weak) {\em fairness
of actions} which requires that an action must be performed whenever it is
enabled continuously in a run. We have shown that each everlasting (or
non-Zeno) timed process execution is fair and vice versa, where fairness is
defined in an intuitive but complicated way in the spirit
of~\cite{CostaS84,CostaS87}. In fact, we have proven this correspondence
for fairness of actions and, with a modified notion of timing, for fairness
of components. These characterisations have been used in~\cite{CDV06} to
prove that Dekker's algorithm is live under the assumption of fairness of components
but not under the assumption of fairness of actions. This result can be
improved by means of suitable assumptions about the hardware, namely we
must assume that reading a value from a storage cell is non-blocking; to
model this we have introduced specific reading prefixes for PAFAS
in~\cite{CDV08tr}. 

Here, we add reading in the form of a read-set prefix  (the new process description language is called PAFAS) which
behaves as  but, like a variable or a more complex data structure, can
also be read with actions in the set . Since being
read does not change the state, each action  () can be
performed repeatedly until the execution of some ordinary action of  .


A first key property of non-blocking actions is that they have a direct
impact on timed behaviour of concurrent systems (see the examples at the
end of Section~\ref{PAFAS-s}). They are also an important feature for
proving the liveness of MUTEX solutions under the assumption of weak
fairness of actions. Indeed, one result in~\cite{CDV08tr} shows that
Dekker's algorithm is live when assuming fairness of actions, provided we
regard as non-blocking the reading of a variable as well as its writing in
the case that the written value equals the current one. It had long been an
open problem how to achieve such a result in a process algebra (see
e.g.~\cite{Walker89}). In~\cite{CDV08tr} we have also discovered an
interesting connection between liveness of MUTEX algorithms and
catastrophic cycles; we have shown that violations of the liveness property
can be traced back to catastrophic cycles of a suitably modified process
(cf. Section~\ref{algos}). Even though \fase\ was originally developed for
automatically checking whether a process of (original) PAFAS has a
catastrophic cycle, it has been recently adapted to a setting with reading
actions. This has opened the way to check automatically the liveness
property for MUTEX algorithms.

In this paper we use \fase\ to study the liveness of four MUTEX
solutions--Peterson's, Lamport's, Dijkstra's and Knuth's algorithms (see
\cite{Walker89} and references therein)--under the assumption of
fairness of actions. Our aim is twofold: we want to show the applicability
of \fase\ to  concrete, meaningful examples, but also to stress the
impact of introducing non-blocking actions in PAFAS (and in general in
modelling concurrent systems). We prove that Peterson is live provided we
regard the reading of a variable as a non-blocking action. We also show
that the liveness of Dijkstra and Knuth cannot be ensured even if (as
in~\cite{CDV08tr}) we consider as non-blocking the reading of a variable
and its writing in the case the written value equals the current one. With
the same assumption on program variables, we finally prove that Lamport
(which is not symmetric) is live for just one of the two competing
processes, i.e.\ it is not live. 


To even more emphasize the role of non-blocking reading in proving
liveness property, we have implemented some ideas taken
from~\cite{Walker89}
that describe how fairness can be assumed in a CCS setting in order to
enable a proof of liveness. At the time of writing, these ideas could not
be expressed for the use of the Concurrency
Workbench~\cite{CleavelandPS89}, but this is now possible within newer
tools like the Concurrency Workbench of the New Century~\cite{CLS00}. A
comparison of the results provided by the two approaches shows that the
liveness of Dekker's and Peterson's algorithms strongly depends on the
liveness of the hardware. This is exactly the sort of consideration for
which non-blocking actions provide a formal treatment.

We proceed as follows: In Section~\ref{PAFAS-s} we recall PAFAS, its
timed operational semantics and the correspondence between fair traces and
everlasting timed computations. In Section~\ref{algos} we introduce the
four algorithms and provide our results. Finally, in
Section~\ref{sec:walker} we compare our approach with that
in~\cite{Walker89}.
\section{A process algebra for describing reading
behaviours}\label{PAFAS-s}
PAFAS~\cite{CVJ02} is a CCS-like process description language~\cite{Mil89}
(with a {\em TCSP}-like parallel composition), where actions are atomic and
instantaneous, but have associated an upper time bound (either  or ,
for simplicity) as a maximal delay for their execution. As shown
in~\cite{CVJ02}, these upper time bounds can be used to evaluate
efficiency, but they do not influence functionality (which actions are
performed); so compared with CCS also PAFAS treats the full functionality
of asynchronous systems. In~\cite{CDV08tr}, PAFAS has been extended with a
new operator  to represent non-blocking behaviour of processes.
Intuitively,  models a process like a
variable or a more complex data structure that behaves as  but can
additionally be read with : since being read
does not change the state, each action  can be performed
repeatedly without blocking a synchronization partner as described below.
We use the following notation:  is an infinite set of \emph{visible
actions}; the additional action  represents a internal activity,
unobservable for other components, and . Elements of
 are denoted by  and those of  by
. Actions in  can let time  pass before their
execution, i.e.\ 1 is their maximal delay. After that time, they become
\emph{urgent} actions written  or ; these
have maximal delay 0. The set of urgent actions is denoted by
 and is ranged over by
. Elements of  are ranged over by  and . We also assume
that, for any , when time elapses .  (ranged over by ) is the set of
process variables, used for recursive definitions.  is a {\it general relabelling function} if the set  is finite and . Such a function can also be used to
define {\em hiding}: , where the actions in  are made internal, is
the same as , where the relabelling function  is defined
by  if  and  if
. 

Below, initial processes are just processes of a standard process algebra
extended with , while general processes are those reachable from the
initial ones according to the operational semantics.
The set  of {\em initial (timed) process terms}  and  of
(general) {\em (timed) process terms}  are generated by:


\vspace{0.1cm}
\hspace{3cm}


\hspace{3.2cm} 


\vspace{0.1cm}

where   is a constant, , ,   is a
general relabelling function and  possibly infinite;
   and  are (finite
and nonempty) subsets of   and , resp.
We assume that the latter kind of read-sets can only contain a copy (either
lazy or urgent) of each action , i.e.\ 
cannot contain both  {\em and}  for any . By the operational semantics, terms not satisfying this property
are not reachable from initial ones anyway.  
A process term is {\em closed} if every variable  is bound by the
corresponding -operator; the set of closed timed process terms in
 and , simply called {\em processes} and {\em initial
processes} resp., is denoted by  and  resp.


 is the Nil-process: it cannot perform any action but can let time
pass without limits.  and  is
action-prefixing known from CCS. Process  performs 
within time 1; i.e.\ it can perform  immediately and evolve to 
(as usual in CCS), or let one time unit pass and become
. In this latter case,  cannot be further
delayed (i.e.\ it must occur or be deactivated) unless
 has to wait for a synchronisation on . Our processes are {\em patient}: as a stand-alone process
 has no reason to wait, but as a component of a larger
system, e.g.\ , it can wait for a
synchronisation on ; this can take up to time 1 since component 
can idle so long.  can perform actions from
 without changing state (including urgencies and,
hence, the syntax of the term itself), and the actions of  in the same
way as , i.e.\ the read-set is removed after such an action. 
is a non-deterministic choice between two conflicting processes  and
. \  and  run in parallel in  and have to
synchronize on all actions from .  behaves as  but with
actions changed according to  .  models a recursive
definition; we often use equations to define recursive processes. 
\paragraph{Functional and temporal behaviour of PAFAS processes.}
\label{secTimedSem}
We first introduce the transitional semantics describing the functional
behaviour of PAFAS processes, i.e.\ which actions they can perform.
\begin{definition}\label{PACTSOS}\rm({\em functional operational
semantics})
Let  and . The SOS-rules defining the transition
relation   (the {\em action
transitions}) are given in Table~\ref{Behaviour}\footnote{We do here
without  and , used e.g.\ in~\cite{CDV06} to get
a closer relationship between states of untimed fair runs and timed
non-Zeno runs. They do not change the behaviour (up to an injective
bisimulation) and would complicate the setting.}. As usual, we write
 if  and  if
there exists a  such that . Similar
conventions will apply later on. We also define the set of the {\em
activated} or enabled actions to be the set of all  such that
.
\end{definition}

\vspace{-0.8cm}
\begin{table}[tbh]
\small

\caption{Functional behaviour of PAFAS processes}
\label{Behaviour}
\end{table}

Rules in Table~\ref{Behaviour} are quite standard. Timing can be
disregarded in \name{Pref}: when an action is performed, one cannot see
whether it was urgent or not, and thus ; furthermore, component  has to act {\em within} time 1, i.e.\
it can also act immediately, giving . Rules
\name{Read} and \name{Read} say that  can either repeatedly perform one of its non-blocking actions or
evolve as . Other rules are as expected; symmetric rules have been
omitted.
Actually, the above SOS-rules describe reading in a sensible way only under
some syntactic restrictions, cf.~\cite{CDV08tr}. All the example processes
we consider here meet these restrictions.


We now define the refusal traces of a term . Intuitively a
refusal trace records, along a computation, which actions process  can
perform (, ) and which actions  can
refuse to perform when time elapses (, ).
 is called a (partial) {\it time-step}. The actions listed
in  are not urgent; hence  is justified in not performing them, but
performing a time step instead. This time step is partial because it can
occur only in contexts that can refuse the actions not in . If 
then  is fully justified in performing this time-step; i.e.,  can
perform it independently of the environment. In such a case, we say that
 performs a {\it 1-step} written ; moreover we often
write  (the urgent version of ) instead of . To
provide the reader with a better intuition we observe that any  can
perform a 1-step whenever it can refuse to perform, because not urgent, all
its activated actions. In the next definition,  is the set of urgent actions in . 

\begin{definition}\label{PAFASRT}\rm ({\em refusal transitional semantics})
The SOS-rules in Table~\ref{rt-semantics} define  where .
\end{definition}
\begin{table}[tbh]
\small

\caption{Refusal transitional semantics of PAFAS processes}
\label{rt-semantics}
\end{table}
Rule \name{Pref} says that a process  can let time pass
and can refuse to perform any action, while rule \name{Pref} says
that a process , can let time pass but action
 cannot be refused. Process  cannot let time
pass and cannot refuse any action; in any context,  has
to perform  before time can pass further. Rule~\name{Par}
defines which actions a parallel composition can refuse during a time-step.
The intuition is that  can refuse an action  if
either  ( and  can do  independently)
and both  and  can refuse , or  ( and
 are forced to synchronise on ) and at least one of them can
refuse the action, i.e.\ can delay it. Thus, an action in a parallel
composition is urgent (cannot be further delayed) only when all
synchronising \lq local\rq\ actions are urgent. Rule \name{Read}
says that  can refuse the same actions as
 provided these are not urgent in ;
moreover, as for the action-prefixing,  process  cannot let time pass and cannot refuse any action,  whenever one
of the urgent actions in  is a . Other
rules are as expected. Again symmetric rules have been omitted.

In \cite{CVJ02}, it is shown that inclusion of refusal traces characterises
a testing-based faster-than relation that compares processes w.r.t. their
worst-case efficiency. In this sense, e.g.\  is
faster than the functionally equivalent , since
only the latter has the refusal traces .  After , 
returns to itself (recursion unfolding creates fresh  and );
intuitively,  is disabled during the occurrence of , so  and also
 can be delayed again. In contrast, after a 1-step and any number of
's,  turns into  and no
further 1-step is possible; read actions do not block or delay other
activities, they make processes faster. If  models the reading of a
value stored by  or  and two parallel processes want to read it,
this should take at most time 1 in a setting with non-blocking reads. And
indeed, whereas  has
the refusal trace , this behaviour is not possible for  since, when performing
, this evolves into e.g.\ , and
then 1 is not possible.

Another application of refusal traces is the modelling of {\it weak
fairness of actions}. Weak fairness requires that an action must be
performed whenever continuously enabled in a run. Thus, a run from 
above with infinitely many 's is not fair; the read action does not
block  or change the state, so the same  is  always enabled but never
performed. In contrast, if  performs , a fresh  is created; in
conformance to~\cite{CostaS84}, a run from  with infinitely many 's
is fair. In~\cite{CDV08tr}, generalising \cite{CDV06}, fair traces for
PAFAS are first defined in an intuitive, but very complex fashion in
the spirit of~\cite{CostaS84,CostaS87} and then characterised: {\em they
are the sequences of visible actions occurring in transition sequences with
infinitely many 1-steps}. 
Due to lack of space, we cannot properly formulate this as a theorem, but
take it as a {\bf definition} of \emph{fair traces} instead. With this,
infinitely many 's are a fair trace of  since it can repeat 
indefinitely, but the fair traces of finite-state  are those that end
with . We use this definition of fair traces to study liveness property
of MUTEX solutions we consider in the next section. 


For request-response processes the transition system (built according to
Def.~\ref{PACTSOS} and~\ref{PAFASRT}) must be reduced as described
in~\cite{CV05}; a cycle in the resulting system is catastrophic if it
contains (at least) one time step but no - or -transition.

\section{Liveness property of MUTEX algorithms}\label{algos}
In this section we use the approach of~\cite{CDV08tr} to study the liveness
of four different MUTEX solutions: Peterson's, Lamport's, Dijkstra's and 
Knuth's algorithm. We first translate the algorithms into PAFAS and
then use \fase\ to automatically decide whether each of them is live or
not. Negative results are discussed by means of counterexamples, i.e.\ fair
violating traces which are built from catastrophic cycles detected with
\fase. The results of this section are collected in
Table~\ref{tab:comparing2}.

\paragraph{Peterson's algorithm}\label{sec:peterson}
There are two processes  and , two Boolean-valued
variables  and , whose initial value is false, and a variable
, which takes values in  and whose initial value is arbitrary.
The  variables are ``request'' variables and  is a ``turn''
variable:  is true if  is requesting entry to its critical
section and  is  if it is 's turn to enter its critical
section. Only  writes , but both processes read it. Process 
 (with ) is described as follows;   is the index of the
other process:

\vspace{0.2cm}
\small
\begin{algorithm}{Peterson}{}
\begin{WHILE}{}
\langle \mbox{non-critical section} \rangle; \\
b_i \= true; \quad k \= j;\\
{\bf while} \; b_j \mbox{ and } k = j \; {\bf do \; skip};\\
\langle \mbox{critical section} \rangle; \\
b_i \= false;
\end{WHILE}
\end{algorithm}
\normalsize
In our translation of the algorithm into PAFAS, we use essentially
the same coding as Walker in~\cite{Walker89}. Each variable is represented
as a family of processes. For example, the process  denotes the
variable  with value false. The {\em sort} of  (i.e.\ the
set of actions it can ever perform) is  Unlike~\cite{Walker89}, we model the actions that correspond to the reading
of a variable (e.g.\  and ) as non-blocking. Below, we
let  and .
\begin{definition}\label{pet-algo1}\rm({\sl Peterson's algorithm})
Let . Program variables are represented as follows:

\hspace{0.5cm}


\vspace{0.1cm}

\noindent
Given , , we define .
Processes  and  are represented by the following
PAFAS processes: the actions  and  indicate the request
to enter and the execution of the critical section by the process
.

\hspace{3cm}


\noindent
Since no process should be forced to request by the fairness assumption,
 has the alternative of an internal move, i.e.\ staying in its
non-critical section.
Peterson's algorithm is defined to be the PAFAS process ; here (and in
the following)  is the set of all actions except  and 
(). A MUTEX algorithm like Peterson's satisfies {\em liveness} if,
in every fair trace, each  is eventually followed by the respective
.
\end{definition}

We now show how to modify the process \petersona\  such that it is live 
under the assumption of fairness of actions iff the modified process, that
we call , does not have catastrophic cycles. Observe that 
\fase\ only accepts request-response behaviours (having only  and 
as visible actions) as input and, hence, it cannot be applied directly.
Moreover, \petersona\ can perform a 1-step followed by the two internal
actions of  and  (see Def.~\ref{pet-algo1}) giving a catastrophic
cycle which is not relevant for the liveness property. So, we modify
\petersona\ as follows: we first change  and  into 's
and  and  into  and , resp.; we finally  delete the
 summand of . As in~\cite{CDV08tr} (see Theorem 8.2\footnote{The
proof of Theorem 8.2 we provide in~\cite{CDV08tr} is partly independent
from the specific algorithm we were analysing, i.e.\ Dekker's algorithm,
and it can be easily adapted to all the algorithms we consider in this
paper. From now on, we freely use the correspondence between liveness and
catastrophic cycles without explicitly proving it. In the following, if 
is a PAFAS process that models a given MUTEX solution, we write
 to denote the process we obtain by changing  as \petersona.}),
we can prove that  does not have catastrophic cycles iff
each request from process  will eventually be satisfied along fair
traces, i.e.\ iff \petersona\ is live for  process  under the
assumption of fairness of actions. The liveness of \petersona\ follows by
the symmetry of the algorithm. In case of non-symmetric algorithms, as
e.g.\ Lamport, the liveness for processes  and   must be
proven separately. Since \fase\ has shown that \petersona does not
have catastrophic cycles, our first result is:

\begin{proposition}\label{prop:pet-live}
 is live under the assumption of fairness of actions.
\end{proposition}
We now consider , a slightly different specification of
Peterson where all actions -- including the reading of program variables --
are ordinary actions. E.g., in this version, we define . Then,   can be defined as in
Def.~\ref{pet-algo1}.

\begin{proposition}\label{prop:pet-non-live} 
  is not live under the assumption of fairness of actions.
\end{proposition}
\begin{proof}
\fase\  shows that  has  catastrophic cycles as,
e.g., those in the next examples.
\end{proof}

The following example shows a timed computation along which both processes
 and  get stuck after a request. To ease understanding,
we leave the actions on program variables visible, i.e.\ we consider a
timed computation of . Indeed, by the operational semantics, we know that
 behaves as  as long as we rename actions in  with
. We will proceed in this fashion later on in this section.
Furthermore, we write  and
 to abbreviate 
and , resp. In general, we underline a value to
denote the urgent version of the PAFAS process that represents the
corresponding variable. 
\begin{example}\rm\label{ex:pet-1}
Consider the following timed computation from .

\begin{tracex}

\end{tracex}

\noindent Process  can only perform  as a synchronisation
between  and either  or ; after the first  1-step,
this action becomes urgent. Once in , we perform 
and  evolves into  which can delay  .
As a consequence,  can refuse to perform  and, since this is its
only activated action, . The execution sequence
 is fair but not live since no process will
ever enter the critical section;  corresponds to a catastrophic cycle in the
reduced transition system of . 
\end{example}

This example describes a scenario where process  will never move
because process  repeatedly reads variables  and . There
is another fair run where , reading variable , can
repeatedly delay and, thus,  indefinitely block  that wants to
write it. On the contrary, the representation of program variables we use
in Def.~\ref{pet-algo1} ensures the liveness of the hardware under the
assumption of fairness of actions; namely, it ensures that no process can
be indefinitely blocked by infinite reading. 




\paragraph{Lamport's algorithm}
There are  processes and  Boolean-valued variables  (), each with initial value false;  only  writes ,
but all the processes can read it. The -th process is described below:

\vspace{0.15cm}
\small
\begin{algorithm}{Lamport}{}
{\bf var} \; j:integer;\\
\begin{WHILE}{}
\langle \mbox{non-critical section} \rangle; \\
b_i \= true;\\
\begin{FOR}{j \= 1 \TO i-1}
\begin{IF}{b_j}
b_i \= false; \\
{\bf while} \; b_j \; {\bf do \; skip};\\
{\bf goto} \;  4;
\end{IF}
\end{FOR}\\
\begin{FOR}{j \= i+1 \TO n}
{\bf while} \; b_j \; {\bf do \; skip};
\end{FOR}\\
\langle \mbox{critical section} \rangle; \\
b_i \= false;
\end{WHILE}
\end{algorithm}
\normalsize
Now we provide the PAFAS specification in case of  processes.
\begin{definition}\label{lamp-algo1}\rm({\em Lamport's algorithm})
Again we first define the family of PAFAS processes representing the
program variables. Let  and  where .
We also define  where . 

\noindent Processes  and  are represented by:



\noindent
Finally . 
\end{definition}
Note that now we regard as non-blocking not only the reading of a variable
but also its writing in case that the  written value equals the current
one. This kind of re-write does not change the state of the variable and 
can be thought of as a non-destructive or non-consuming operation (allowing
potential concurrent behaviour). This way of accessing a variable is not
new. It has been implemented e.g.\ in area of database. Unlike in 's specification, we make this assumption on the hardware to show that 's algorithm is not live with respect to :


\begin{proposition}\label{prop:lamp-live}
If we assume fairness of actions, \lamporta\ is live for process
 but {\em not} for process . 
\end{proposition}

\begin{proof}
\lamporta\ is not live for  because  has
catastrophic cycles. To prove the other statement, we need symmetric
changes; namely, we rename actions  and  into  and 
resp. and actions  and  into ; we also delete the
-summand of process . Since this modified process does not
have catastrophic cycles, we conclude that \lamporta\ is live for process
.
\end{proof}

Prop.~\ref{prop:lamp-live} still holds if we use the same representation of
program variables as in Def.~\ref{pet-algo1}, while we lose liveness for
 whenever processes representing program variables are those used
for . Then, while reading variable , process 
can forever block the other process that wants to write it. The next
example explains why \lamporta\ is not live for process .
\begin{example}\rm\label{ex:lamp-1}
The following timed computation corresponds to an execution sequence from
 which is fair but not live since process  never
enters its critical section.

\begin{tracex}

\end{tracex} 

\noindent  can do either a - or a -action (due to
a synchronisation between  and ); both actions become
urgent after the first 1-step. Later, we perform   followed by
 (and, hence,  evolves into )
which, in turn, is followed by  and . At this stage,
 becomes  and  can refuse to perform its
activated actions, again  and , and evolve into
.  Finally,  corresponds to a catastrophic
cycle in the reduced transition system of .
A key observation here is that process , along this cycle,
continuously changes the value of  from {\em true} to {\em false} and
vice versa. Consequently, the PAFAS process representing this
variable always offers a new instance of  and  to its
synchronisation partners, and in particular to . So,
any possible move of process  can be arbitrarily delayed (and,
hence, this process can indefinitely be blocked) even in fair traces. No
reasonable assumption about program variables can prevent this unwanted
behaviour under weak fairness.
\end{example}

\vspace{-0.5cm}
\paragraph{Dijkstra's algorithm}
This algorithm considers  processes that share two Boolean-valued
arrays  and  (whose components are initialised to true) and a turn
variable  initially chosen in . The -th process is described below:
\begin{algorithm}{Dijkstra}{}
{\bf var} \; j:integer;\\
\begin{WHILE}{}
\langle \mbox{non-critical section} \rangle; \\
b[i] \= false;\\
\begin{IF}{k \neq i}
c[i] \= true;\\
{\bf if} \; b[k] \; {\bf then} \; k \= i; \\
{\bf goto} \; 5;
\ELSE 
c[i] \= false;\\
\begin{FOR}{j \= 1 \TO n}
{\bf if} \; j \neq i  \mbox{ and } \neg c[j] \;{\bf then \; goto} \; 5;
\end{FOR}
\end{IF}\\
\langle \mbox{critical section} \rangle; \\
c[i] \= true; \\
b[i] \= true;
\end{WHILE}
\end{algorithm}
\noindent Again we provide the PAFAS representation in case of 
processes.
\begin{definition}\rm\label{def:dijkstra1} ({\it Dijkstra's algorithm}) 
Components of the array  are represented by processes 
and  () in Def.~\ref{lamp-algo1}. The other shared
variables are defined similarly.
Let , , and ; as usual, 
 denotes the parallel composition of all
program variables. Its definition is as expected and, hence, omitted.
Processes  and  are instead given below:

\hspace{1cm}


\vspace{0.1cm}

\noindent Dijkstra's algorithm is defined as  where .

As in~\cite{Walker89} we must ensure that whenever, during the execution of
the statement ``{\bf if  then }'', process 
has read variable  but not yet , the other process cannot change
the value of the former variable. Note that  locks the variable  in
writing mode when evaluating . Indeed, after a -action,  can
be written only after a subsequent -action, i.e.\ once  has been
read.
\end{definition}

As other papers in the literature (see e.g.~\cite{Bogunovic03}), we cannot
prove the liveness of the algorithm\footnote{Paper~\cite{Bogunovic03}
studies the liveness of the same algorithms we consider here except for
Lamport. In~\cite{Bogunovic03} it has been proven that Peterson and Knuth
are live, but Dijkstra is not.}. 
In case  is  , process  can immediately enter its critical
section (after setting  to false, both conditions  and
 are false), while process  has to wait until 
becomes true (i.e.\ until  ends its critical section) and, hence,
it can change . If  is fast enough to perform its critical
section, reset variables  and , and submit a further request
(again, by setting  to false) before  can actually read
, the latter process can never enter its critical section. This
scenario is fair and, hence, admissible; see e.g.\ in~\cite{Bogunovic03}
where Dijkstra is analysed by exploiting the model checker SMV
(\cite{Bogunovic03} and references therein). The fairness notion assumed
in~\cite{Bogunovic03} ensures that each process executes infinitely often
and that no process can stay in its critical or non-critical section
forever. The next example shows that the above scenario is also admissible
if one assumes fairness of actions and introduces reasonable non-blocking
behaviours.
\begin{example}\rm\label{ex:dijkstra1}
Let us consider the following timed computation:

\begin{tracex}

\end{tracex}

Along the cycle , the process  repeatedly
changes the value of   from {\em false} to {\em true} and vice versa.
As in Example~\ref{ex:lamp-1}, this means that it can block forever process
.
\end{example}

\begin{proposition}\label{prop:dijkstra} 
\dijkstraa\ is not live under the assumption of fairness of actions.
\end{proposition}


\paragraph{Knuth's algorithm}
There are two processes  and , two variables  and
 that take values in  and whose initial value is 0, and a
turn variable  that takes values in 
and whose initial value is arbitrary.  Process  () is
described as follows, where  is the index of the other process:
\begin{algorithm}{Knuth}{}
\begin{WHILE}{}
\langle \mbox{non-critical section} \rangle; \\
c_i \= 1;\\
{\bf if} \; k = i  \; {\bf then \; goto} \; 6;\\
\; {\bf if} \; c_j  \neq 0  \; {\bf then \; goto} \; 4;\\
c_i \= 2;\\
{\bf if} \; c_j =2  \; {\bf then \; goto} \; 3;\\
k \= i;\\
\langle \mbox{critical section} \rangle; \\
k \= j; \\
c_i \= 0;
\end{WHILE}
\end{algorithm}
\begin{definition}\rm\label{def:knuth1} ({\it 's algorithm}) 
The turn variable  is given in Def.~\ref{pet-algo1} and modelled according to Def.~\ref{def:dijkstra1}. Variables 
and  are represented as follows, where :

\vspace{0.1cm}
\hspace{3.5cm}


\vspace{0.15cm}

\noindent Let    and . We
let  to be the parallel composition of all program
variables. Moreover, processes  and  are defined as
follows: 

\vspace{0.1cm}

\hspace{1.5cm}


\hspace{1.5cm}


\noindent We define . 
\end{definition}
We now provide an example that shows the existence of a catastrophic cycle
in the reduced transition system of the modified \knutha. This example also
implies Prop.~\ref{prop:knuth}.

\begin{example}\rm\label{ex:knuth}
Let us consider the following timed computation:



\vspace{0.15cm}

\noindent Once in , process  cannot enter its critical section
because  is 2; but, the value of this variable will
never change because  is blocked. Moreover, as in
Examples~\ref{ex:lamp-1} and~\ref{ex:dijkstra1}, repeated changes of
variable  (from 2 to 1 and vice versa) allows a further 1-step in
.
The execution sequence  is fair but not live since
process  never enters its critical section. Let us finally notice
that Knuth is live e.g.\ in~\cite{Bogunovic03} since the above execution
sequence is not fair as defined there, and hence not admissible, because
process  does not execute infinitely often. 
\end{example}
\begin{proposition}\label{prop:knuth}
\knutha\ is not live under the assumption of fairness of actions.
\end{proposition}
\section{Related works and Conclusion} \label{sec:walker}
This work partly originates from~\cite{Walker89} where Walker aimed at
verifying six MUTEX algorithms with the Concurrency
Workbench~\cite{CleavelandPS89} (CWB, for short). 
Walker translated the algorithms into CCS and then verified the safety
property that the two competing processes are never in their critical
sections at the same time. Regarding the liveness property, Walker first
considered the following interpretation -- which could be expressed as a
modal mu-calculus formula and then checked with the CWB:
\begin{center}
\begin{minipage}{15.5cm}
\small
\em
An algorithm is live if whenever at some point in a computation the
process  requests the execution of its critical section, then in
any continuation from that point in which between them the processes
execute an infinite number of critical sections,  performs its
critical section at least once. 
\end{minipage}
\end{center}
The fairness (or progress) assumption assumed here is that infinitely often
a critical section is entered. This assumption allows a run where one
process enters its critical section repeatedly, while the other one
requests the execution of its critical section, but then -- for no good
reason at all -- refuses to take the necessary steps to actually enter it.
So, it may be no surprising that four of the six algorithms (Dekker,
Dijkstra, Lamport and Hyman) fail to satisfy this property. Moreover, in
order to economize on computational effort, the six algorithms
in~\cite{Walker89} have been minimized w.r.t. weak bisimulation. This
allowed Walker to ignore some -loops that could invalidate the
liveness property. And, indeed, all of them are not live whenever
the formula expressing the first interpretation of liveness is evaluated
over the transition system that does not abstract from 's. By
examining process , it is clear that these -loops arise,
e.g. in Peterson, from repeated reading and writing of variables by the
same process. This is common to all the algorithms and it is not introduced
by the translation into CCS (or in PAFAS). Rather its presence reflects the
faithfulness of the translation itself. 


Then, Walker considered the same liveness property we study in
Section~\ref{algos}. To establish that any of the algorithms is live under
this second interpretation, Walker added some assumption. Indeed,
one characteristic of the -loops arising from repeated reading and
writing of variables by one process is that the other one is excluded from
an infinite computation of the system. It is natural to ask if {\em
only} the presence of such `unfair' loops prevents any of the
algorithms from being live. So, Walker proposed to use enriched formulas
of the form  where  is the property of interest (i.e.\
liveness) and  is a fairness assumption that assumes as admissible
only those paths to which each process contributes infinitely often. 
Even if at the time of writing no automated analysis was possible, Walker
discussed how fairness could be assumed. The basic idea  is to tag
each action with a unique {\em probe} or label; then, we can say the -th
process  contributes infinitely often to a computation whenever
none of its probes is continuously possible from a certain point on.
Finally, the liveness under this fairness
assumption is expressed by letting  be the set of all probes of
 and defining  
where 
,
and the operators  (always),  (future),  (possibly)
and  (necessarily) are standard modal logics operators.

\begin{table}
\centering
\small
\begin{tabular}{l c c l c c l c c}
 & CWBNC & \fase & &  CWBNC & \fase\  & &  CWBNC & \fase\  \\ \hline
\midrule
 & \checkn\ & \checky\ & \peterson\ & \checkn\ & \checky\
&  & \checkn\ & \checkn\ \\
 & \checkn\ & \checkn\ & \lamport\ & \checkn\ & \checkn\ \\
\midrule
\end{tabular}
\caption{Liveness of MUTEX solutions: CWBNC vs. \fase.}
\label{tab:comparing2}
\end{table}

This fairness induced with probes is closely related to fairness of actions
as it has been defined in~\cite{CostaS84,CostaS87}. W.r.t. our
characterisation (cf.\ Section~\ref{PAFAS-s}),  the  main difference is
that, instead of time and time passing, probes are used to decide whenever
an action is continuously enabled along a computation and, hence, must be
performed eventually. To allow a comparison, we have implemented these
ideas within the {\em Concurrency Workbench of the New
Century}~\cite{CLS00} (CWBNC, for short) that, unlike CWB, can handle modal
formulas with fairness constrains. To be able to attach a probe to each
process action, the algorithms have been translated into {\em Timed CCS}
(this is not possible by using the standard CCS language); probes are
introduced by annotating synchronisation actions or 's. For instance,
the -th processes of Peterson can be defined as follows:

\hspace{2.5cm}


Note that two consecutive actions (as, e.g.,  and  in
) never have the same label. Moreover, since the overall number of
labels impacts on the computational effort (see below), we also try to
reduce the number of labels we use.  For example, we can reuse  to
label the actions of  because none of its actions is adiacent to
 and this action has already been executed once  is
reached. 

Whenever an action is performed, the corresponding label becomes {\it
visible}\footnote{E.g.,\ if  synchronises with  on the
execution of , the label  becomes visible; similarly,
whenever process  executes  we get the label .} and can
be used as a probe in . 
Table~\ref{tab:comparing2} shows that all the algorithms we consider are
not live according to this second liveness interpretation (also in this
setting, Lamport is live for process  but not for ). As
an example, consider a path from Peterson along
which the first process reaches ,  is true and  is 2. Once in such a state,
process  can read  and  and come back to . Along
this cycle, no probe of  is continuously possible (probes
 and  are alternately possible) but  will never be
performed. So,  is false and Peterson is not live. As in
Example~\ref{ex:pet-1}, there is a path along which a
process can be indefinitely blocked by repeated reading. Also in this
setting, the liveness of the algorithm strongly depends on the liveness of
the hardware, i.e.\ on the the possibility of making some behaviours
non-blocking.

As a further counter-check, we again consider Peterson but now we tag its
actions in such a way that the same probe is associated to all the  actions
that appear along consecutive reading (trying to simulate the intuition
behind non-blocking behaviours). So, let us replace  with 
. 
Now, whenever in  and assuming  and  equal to true and 2,
the process  can still repeatedly read variables  and
, but the corresponding path is not fair because probe  is
continuously possible. With these probes, Peterson and Dekker turn out to
be live.
So, probes can be used to somehow simulate non-blocking actions. But they
must be added and (whenever necessary) tuned by the user by hand. This
task is subject to errors and wrong assumptions that would give erroneous
results.  On the contrary, \fase\ can be more easily used by also a
non-expert user that has only to decide whether (and, in case,
which) non-blocking behaviours are necessary. In our opinion, the use of
probes requires a deeper knowledge of the problem and much
more attention in both modelling and analysis phases. 

Another difference between the two approaches deals with {\em performance}
issues. In Table \ref{tab:comparing3} we report the execution time of both  and  to perform the analysis on the algorithms discussed in this paper. 
In particular, in~\cite{BCCDV09} an efficient algorithm for detecting catastrophic
cycles has been proposed and implemented. This works in time 
where  and  are, resp., the number of nodes and edges of the
state space of the process. On the contrary, CWBNC uses an on-the-fly model
checking algorithm whose complexity is exponential in the size of the
formula (see~\cite{CLS00}); in our case, this size strongly depends
on the number of probes.

\begin{table}
\centering
\small
\begin{tabular}{l c c l c c l c c}
 & CWBNC & \fase & &  CWBNC & \fase\  & &  CWBNC & \fase\  \\ \hline
\midrule
 &   &  & \peterson\ & \ & \
&  & \ & \ \\
 & \ & \ & \lamport\ & \ & \ \\
\midrule
\end{tabular}
\caption{Execution time (expressed in milliseconds): CWBNC vs. }
\label{tab:comparing3}
\end{table}

\fase\ is a good first step towards the creation of an integrated
framework for the analysis of concurrent systems. The improvements
introduced by the tool (and, in particular, the possibility to easily
check non-functional properties such as liveness) allows us to derive
results -- as those in this paper -- very hard to prove by hand. Since
these results are very promising, we are currently planning to extend
\fase\ in order to improve the analysis of more complex systems with a
larger state space.

\bibliographystyle{eptcs}
\bibliography{mutex-algs}
\end{document}