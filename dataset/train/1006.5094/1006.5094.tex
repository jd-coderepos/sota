
\documentclass[copyright,creativecommons]{eptcs}
\providecommand{\event}{QAPL 2010} \providecommand{\volume}{}
\providecommand{\anno}{}
\providecommand{\firstpage}{1}
\providecommand{\eid}{}
\usepackage{breakurl}        \usepackage{amsfonts}






\newtheorem{new_theorem}
	{Theorem}[section]

\newtheorem{new_definition}
	[new_theorem]{Definition}

\newtheorem{new_remark}
	[new_theorem]{Remark}

\newtheorem{new_example}
	[new_theorem]{Example}

\newtheorem{new_lemma}
	[new_theorem]{Lemma}

\newtheorem{new_proposition}
	[new_theorem]{Proposition}

\newtheorem{new_corollary}
	[new_theorem]{Corollary}




\newenvironment{definition}
	{\begin{new_definition}\rm}
	{\end{new_definition}}

\newenvironment{remark}
	{\begin{new_remark}\rm}
	{\end{new_remark}}

\newenvironment{example}
	{\begin{new_example}\rm}
	{\end{new_example}}

\newenvironment{lemma}
	{\begin{new_lemma}\rm}
	{\end{new_lemma}}

\newenvironment{proposition}
	{\begin{new_proposition}\rm}
	{\end{new_proposition}}

\newenvironment{theorem}
	{\begin{new_theorem}\rm}
	{\end{new_theorem}}

\newenvironment{corollary}
	{\begin{new_corollary}\rm}
	{\end{new_corollary}}

\newenvironment{proof}
	{\medskip\noindent{\bf Proof}}
	{}
 




\def\ms#1{\null\ifmmode\mathord{\mathcode`-="702D\it #1\mathcode`\-="2200}\else\fi}

\newcommand{\cws}[2]
	{\\ \centerline{} \\begin{array}{l}
P ::= \nil \mid \lap a, \lambda \rap . P \mid P + P \mid A
\end{array}\begin{array}{c}
\langle a, \lambda \rangle . P \arrow{a,\lambda}{} P \8mm]
\infr{A \eqdef P \hspace{5mm} P \arrow{a,\lambda}{} P'}{A \arrow{a,\lambda}{} P'}
\end{array}
\begin{array}{c}
\ms{rate}(P, a, C) \: = \: 
\sum \lmp \lambda \in \realns_{> 0} \mid \exists P' \in C \ldotp P \arrow{a, \lambda}{} P' \rmp 
\end{array}\begin{array}{c}
\ms{trace}(c) \: = \: \left\{ \begin{array}{ll}
\delta &
\hspace{0.5cm} \textrm{if } \\
a \circ \ms{trace}(c') &
\hspace{0.5cm} \textrm{if } \\
\end{array} \right. 
\end{array}\begin{array}{c}
\ms{prob}(c) \: = \: \left\{ \begin{array}{ll}
1 &
\hspace{0.5cm} \textrm{if } \\
{\lambda \over \ms{rate}_{\rm t}(P)} \cdot \ms{prob}(c') &
\hspace{0.5cm} \textrm{if } \\
\end{array} \right. \\
\end{array}\begin{array}{c}
\ms{prob}(C) \: = \: \sum\limits_{c \in C} \ms{prob}(c). 
\end{array}-14mm]
\fullbox
	\end{definition}

	\begin{definition}

Let  and . The stepwise average duration of  is the sequence of average sojourn times 
in the states traversed by , which is defined by induction on the length of  through the -valued 
function:

where  is the empty stepwise average duration. We also define the multiset of computations in
 whose stepwise average duration is not greater than  as:

Moreover, we denote by  the multiset of computations in  whose length
is equal to .
\fullbox
	\end{definition}

The main idea underlying the testing approach is that two process terms are equivalent whenever an external observer 
interacting with them by means of tests cannot infer any distinguishing information from the functional and quantitative 
standpoints. Tests are represented as process terms that interact with the terms to be tested through a parallel composition 
operator enforcing synchronization on all visible action names. A test is passed with success whenever a specific point 
during execution is reached.
In the rest of the paper, we model tests as non-recursive, finite-state process terms.

Intuitively, at each state the process term proposes the execution of a durational action chosen according to the race
policy and then, if such an action is visible, the test decides either to react by enabling the interaction or to block it
(note that tests cannot block the execution of  actions). 
The interaction can occur between actions with the same name only. If the test offers several actions with the same name as 
that of the action chosen by the term, then the selection of one such actions is probabilistic.

Formally, tests consist of nondurational actions each equipped with a weight . 
The set of tests respecting a canonical form is necessary and sufficient to decide whether two process terms are Markovian 
testing equivalent. Each of these canonical tests allows for one computation leading to success, whose intermediate 
states can have alternative computations leading to failure in one step. 

	\begin{definition}

The set  of canonical reactive tests is generated by the syntax:

where 
,  finite, the summation is absent whenever ,
and \textrm{s} (resp.\ \textrm{f}) is a zeroary operator standing for success (resp.\ failure).
\fullbox
	\end{definition}

The following semantic rules define the interaction between a process term and a test:

where  is the weight
of  with respect to  and  denotes the transition relation for tests.

Given  and , the interaction system of  and  is the process term 
, where each state of  is called a configuration. We say that a configuration is 
successful if its test part is s and that a test-driven computation is successful if it traverses a successful 
configuration. 
We denote with  the multiset of successful computations of . It is worth noting that for any 
sequence  of average amounts of time the multiset 
 is finite and all the computations of it have a finite length and are independent 
of each other.

Markovian testing equivalence requires to compare the probabilities of performing successful test-driven computations 
within a given sequence of average amounts of time.

	\begin{definition}\label{mte}

Let . We say that  is Markovian testing equivalent to , written 
, iff for all reactive tests  and sequences 
 of average amounts of time:
\cws{11}{\ms{prob}(\calsc_{\le \theta}^{|\theta|}(P_{1}, T)) \: = \: \ms{prob}(\calsc_{\le
\theta}^{|\theta|}(P_{2}, T)).}
\fullbox
	\end{definition}

The following example justifies why the average duration of a computation has been defined in terms of the sequence of 
average sojourn times in the states traversed by the computation, rather than simply considering the sum of average durations. 

\begin{example}
Consider the two process terms:
\cws{0}{\begin{array}{l}
\lap g, \gamma \rap . \lap a, \lambda \rap . \lap b, \mu \rap . \nil +
\lap g, \gamma \rap . \lap a, \mu \rap . \lap d, \lambda \rap . \nil \\
\lap g, \gamma \rap . \lap a, \lambda \rap . \lap d, \mu \rap . \nil +
\lap g, \gamma \rap . \lap a, \mu \rap . \lap b, \lambda \rap . \nil 
\end{array}}
Under the assumption  and , both terms have a computation with concrete trace , 
probability , average duration , but 
different average sojourn times. We can argue similarly for the computation with concrete trace . 
Intuitively, an external observer distinguishes between them by observing the names of the actions that are performed and 
the instants at which they are performed. This is captured by  as the two process terms are not Markovian 
testing equivalent.
\fullbox

\end{example}

\section{Approximate Markovian Testing Equivalence}\label{sect:approx}


In this section, we show three levels of approximation for .
The goal is to estimate from different perspectives how much a process term  is similar to a given process term . 
Here we assume that  represents the original model to be approximated through an alternative model .
Since similarity cannot be transitive, as usual when relaxing equivalence relations we will also investigate what can be 
``transitively'' inferred about the distance between two process terms  and  whenever there exists a process term 
 that is similar to both of them.

The three considered dimensions of the similarity problem are: time taken to pass a test (Sect.~\ref{subsect:time}), expressed 
as the sequence of average sojourn times in the states traversed by successful computations; probability with which tests are 
passed (Sect.~\ref{subsect:prob}); syntactical form of the passed test (Sect.~\ref{subsect:test}). 
For every dimension, we will provide a measure of the distance between process terms that do not satisfy ,
by stepwise refining the notion of similarity in terms of flexibility and usability. 
In each case, we will discuss the interpretation of the measure and the complexity of the algorithm measuring the distance 
between process terms. Finally, we will present a unifying notion of approximate Markovian testing equivalence -- resulting 
in Def.~\ref{beh-mte-prob-time} -- which joins all the ingredients mentioned before. Indeed, a unifying framework is useful 
to study the trade-off existing among the three orthogonal aspects and the related impact upon the inequalities of the process 
terms under comparison. 

\subsection{Approximating Time}\label{subsect:time}

The first dimension under consideration is time. In the setting of , the time needed to pass a test with
success is described as the sequence of average sojourn times in the states traversed by successful computations. 
Approximation at this level consists in relaxing the condition concerning the average sojourn times. 
We will introduce such an approximation through several steps in an incremental way. First, we will show how a process 
term  can be approximated by a process term  that is either ``slightly slower'' or ``slightly faster'' 
than . Then, we join both interpretations of similarity in order to obtain the most general definition of Markovian 
testing similarity with respect to time.

We start by introducing the idea of slow approximation. Whenever  approximates successful computations of  with 
respect to a test  and temporal threshold , stepwise average sojourn times slightly greater 
than those imposed by  may be tolerated. In this case, we obtain a slow approximation, in the sense that  simulates 
 -- the same tests are passed with the same probabilities -- but the successful computations of  can be slower than 
the corresponding ones of .

As a first attempt in formalizing this intuition, we define the multiset of computations in 
 whose stepwise average duration is not greater than  plus 
, which acts as a tolerance threshold:

Based on this definition, we have the following relaxation of .

	\begin{definition}\label{def1:sMts}

Let  and . 
We say that  is slow Markovian testing -similar to  
iff for all reactive tests  and sequences  of average 
amounts of time:
\cws{11}{\ms{prob}(\calsc_{\le \theta}^{|\theta|}(P_{1}, T)) \: = \: 
\ms{prob}(\calsc_{\le \theta+\epsilon}^{|\theta|}(P_{2}, T)).}
\fullbox
	\end{definition}

\begin{example}
Consider the process terms  and 
. Then,  approximates 
(is slow Markovian testing -similar to) , where  
expresses exactly the difference between the stepwise average amounts of time of the computations of  and . 
\fullbox
\end{example}

\noindent Note that  if and only if  (resp.\ ) is slow Markovian testing -similar 
to  (resp.\ ). Moreover, we have the following transitivity result.

\begin{proposition}\label{time:transitivity}

Let  and . 
If  is slow Markovian testing -similar to  and  is slow Markovian testing 
-similar to , then  is slow Markovian testing -similar to .
\fullbox

\end{proposition}

\noindent In favor of this approximation of , we observe that it can be decided through a trivial variant of the 
algorithm for  -- which will be outlined later in this section -- and with the same time complexity, which is , 
where  is the total number of states of  and ~\cite{ABC}. 
However, an approximation such as this is too restrictive, as illustrated in the following example.

\begin{example}

Consider the process terms of the previous example. Then,  is not slow Markovian testing -similar 
to , with . In fact, take  
such that . 
With this temporal threshold, any computation of  is discarded, while this is not the case for .
\fullbox
\end{example}

In order to further relax , we need to compare explicitly the sets of computations of  and . 
Formally, given , we now define the multiset of computations in  whose stepwise average 
duration is not greater than  or else is -similar, with , 
to the stepwise average duration of any computation in . Therefore:

Based on this definition, we propose a new approximation of .

	\begin{definition}\label{def2:sMts}

Let  and . 
We say that  is slow Markovian testing -similar to  
iff for all reactive tests  and sequences  of average 
amounts of time:
\cws{11}{\ms{prob}(\calsc_{\le \theta}^{|\theta|}(P_{1}, T)) \: = \: 
\ms{prob}(\calsc_{\le \theta+\epsilon, \calsc^{|\theta|}(P_{1}, T)}^{|\theta|}(P_{2}, T)).}
\fullbox
	\end{definition}

\noindent Intuitively,  is compared with 
augmented with the successful -driven computations of  that are slower (up to ) 
than corresponding computations in .

\begin{example}

Consider two process terms  and  that are defined as follows, respectively:
\cws{0}{\begin{array}{l}
\lap g, \gamma \rap . \lap a, \lambda \rap . \lap b, \lambda \rap . \nil +
\lap g, \gamma \rap . \lap a, \lambda \rap . \lap d, \lambda \rap . \nil \\
\lap g, \gamma \rap . \lap a, \lambda \rap . \lap d, \lambda-\delta \rap . \nil +
\lap g, \gamma \rap . \lap a, \lambda-\delta \rap . \lap b, \lambda \rap . \nil 
\end{array}}
The computation  with concrete trace  of  is slowly -simulated by the 
corresponding computation  of , provided that . 
Given any test , for each  we have that 
 iff
, because from the temporal 
standpoint  is stepwise slower than  and their difference is limited by . We can argue similarly in the 
case of the two computations with concrete trace . Hence,  is slow Markovian testing -similar 
to .
\fullbox
\end{example}

\noindent Note that  if and only if  (resp.\ ) is slow Markovian testing -similar to 
 (resp.\ ). Moreover, we have the following transitivity result.

\begin{proposition}\label{time:transitivity_bis}

Let  and . 
If  is slow Markovian testing -similar to  and  is slow Markovian testing 
-similar to , then  is slow Markovian testing -similar to  for some 
.
\fullbox
\end{proposition}

Alternatively, by a symmetric argument we obtain a fast approximation whenever the successful computations of 
 are approximated by successful computations of  with stepwise average duration that can be 
slightly lower than that of corresponding successful computations of .
Based on this intuition, we have the following approximation of  still preserving the same 
results concerning Def.~\ref{def2:sMts}.

	\begin{definition}\label{def:fMts}

Let  and . 
We say that  is fast Markovian testing -similar to  
iff for all reactive tests  and sequences  of average 
amounts of time:
\cws{11}{\ms{prob}(\calsc_{\le \theta+\epsilon, \calsc^{|\theta|}(P_{2}, T)}^{|\theta|}(P_{1}, T)) \: = \: 
\ms{prob}(\calsc_{\le \theta}^{|\theta|}(P_{2}, T)).}
\fullbox
	\end{definition}

\begin{example}

Consider a variant of the previous example where the second process term is:
\cws{0}{\begin{array}{l}
\lap g, \gamma \rap . \lap a, \lambda \rap . \lap d, \lambda+\delta \rap . \nil +
\lap g, \gamma \rap . \lap a, \lambda+\delta \rap . \lap b, \lambda \rap . \nil
\end{array}}
In this case, it is easy to see that  is fast Markovian testing -similar to , where
.
\fullbox
\end{example}

The definitions of (slow and fast) Markovian testing similarity can be decided in polynomial time by exploiting a simple 
variant of the same algorithm for , because essentially the main objective -- i.e.\ equating the execution 
probability of certain successful computations -- does not change. The unique relaxation concerns the average durations of these 
computations, i.e.\ the criterion according to which the successful computations to compare are chosen.
We now outline the most important steps of this proof by illustrating the differences with respect to the original algorithm for
 of~\cite{ABC}. First, deciding  is reduced to decide the Markovian version 
of ready equivalence, which can be reduced to decide probabilistic ready equivalence if we consider the embedded discrete-time
versions of the CTMCs underlying the two process terms to compare. Then, probabilistic ready equivalence is decided through a 
suitable reworking of the algorithm for probabilistic language equivalence~\cite{Tzeng}. 
In the transformation from continuous time to discrete time, information about the total exit rate of each state is encoded 
within the action names labeling the transitions leaving that state. Note that the use of this additional information provides 
the unique difference between  and (slow and fast) Markovian testing similarity. 
More precisely, when applying the algorithm for probabilistic language equivalence in the case of , a state of 
 is equated to a state of , i.e.\ they are put into the same accepting set, if and only if 
the two sets of augmented action names labeling the transitions departing from the two states coincide. In particular, they must 
exhibit the same total exit rates. 
Hence, the temporal information represents a decoration that is used to decide which states of  and 
 belong to the same accepting set. In our relaxed setting, instead of checking the equality between the total 
exit rates as required by , we check their inequality up to , i.e.\ a state of  is
equated to a state of  if the total exit rate of the second state is greater/lower than the total exit rate of 
the first state and their difference is limited by the threshold . 
Then, once the accepting sets are defined according to this condition, the algorithm of~\cite{Tzeng} proceeds as usual. 
The time complexity of the overall algorithm is .

Markovian testing similarity can be further relaxed. On the one hand, the fast and slow versions can be combined together, thus
obtaining the following definition.

	\begin{definition}\label{def:sfMts}

Let  and . 
We say that  is temporally Markovian testing -similar to  
iff for all reactive tests  and sequences  of average 
amounts of time:
\cws{11}{\ms{prob}(\calsc_{\le \theta+\epsilon, \calsc^{|\theta|}(P_{2}, T)}^{|\theta|}(P_{1}, T)) \: = \: 
\ms{prob}(\calsc_{\le \theta+\epsilon, \calsc^{|\theta|}(P_{1}, T)}^{|\theta|}(P_{2}, T)).}
\fullbox
	\end{definition}

\noindent Hence, a computation  of  can be approximated either by a slower or by a 
faster computation of . However,  cannot be approximated by a computation of  that is stepwise 
either slower or faster than . 
In order to overcome this limitation, we introduce the following relaxation of :

\noindent Based on this notion of approximation, a computation  is similar to a computation  if the difference
between their average sojourn times is limited by . Then, we have the following variant of Def.~\ref{def:sfMts}.

	\begin{definition}\label{def2:sfMts}

Let  and . 
We say that  is temporally Markovian testing -similar to  
iff for all reactive tests  and sequences  of average 
amounts of time:
\cws{11}{\ms{prob}(\calsc_{\le \theta \pm \epsilon, \calsc^{|\theta|}(P_{2}, T)}^{|\theta|}(P_{1}, T)) \: = \: 
\ms{prob}(\calsc_{\le \theta \pm \epsilon, \calsc^{|\theta|}(P_{1}, T)}^{|\theta|}(P_{2}, T)).}
\fullbox
	\end{definition}

\noindent Note that this extension does not alter the decidability results of Markovian testing similarity.

\begin{example}

Consider a variant of the previous example where the second process term is:
\cws{0}{\begin{array}{l}
\lap g, \gamma \rap . \lap a, \lambda-\delta \rap . \lap d, \lambda+\delta \rap . \nil +
\lap g, \gamma \rap . \lap a, \lambda+\delta \rap . \lap b, \lambda-\delta \rap . \nil
\end{array}}
It can be verified that  is temporally Markovian testing -similar to , where
.
\fullbox
\end{example}

On the other hand, when comparing the computations of two process terms we can decide to change at each step the value 
of the threshold expressing the tolerance to different temporal behaviors. This is obtained by assuming 
 and checking, e.g., the inequality:

within the definition of . For instance, this variant can be used to discount the effect 
of far (in the future) steps by assuming that  increases as long as  increases.

\subsection{Approximating Probability}\label{subsect:prob}

The introduction of a relaxation concerning the probabilistic behavior of process terms results into the following extension of 
 where the probabilities of the successful -driven computations of  and  are not imposed to be 
equal anymore.

	\begin{definition}\label{def:pMts}

Let  and . 
We say that  is probabilistically Markovian testing -similar to  
iff for all reactive tests  and sequences  of average 
amounts of time:
\cws{11}{|\ms{prob}(\calsc_{\le \theta}^{|\theta|}(P_{1}, T)) - \ms{prob}(\calsc_{\le \theta}^{|\theta|}(P_{2}, T))|
\le \epsilon.}
\fullbox
	\end{definition}

As we have seen in the previous section, verifying Markovian testing equivalence amounts to decide whether two probabilistic 
automata accept the same words with the same probability. However, as shown in~\cite{dRT}, the relaxation of this equivalence
problem, i.e.\ checking whether for all words the distance between two process models is less than , is an
undecidable problem.

To make it decidable, it is possible to restrict ourselves to more specific notions of probabilistic similarity. 
As an example, \cite{ST} defines a polynomially accurate similarity that can be rephrased in our testing framework as follows: any 
set of successful computations of  with a polynomial number of steps must be matched by  with an error that is bounded 
by any polynomial. In order to measure the distance between process terms even when their difference is not negligible in the sense
of~\cite{ST}, in the next section we will show that decidability is obtained by relaxing the condition over tests in Def.~\ref{def:pMts}.

\subsection{Approximating Tests}\label{subsect:test}

Similarly as done in Sect.~\ref{subsect:time}, in this section we consider in an incremental way a notion of similarity that is based 
on the exemplary behavior of tests. The proposed approach is not completely naive as it is somehow inspired by~\cite{AAW}, where processes 
are compared with respect to an event log describing typical behaviors. In particular, in~\cite{AAW} processes are defined in terms of 
Petri nets and an event log is a multiset of firing sequences. Then, different models are compared by measuring the overlap in (partially) 
fitting these sequences. 
This is done by using a fitness function that takes into account all enabled transitions at any point in each sequence. 
This idea results into two measures, called precision and recall. Precision establishes whether the behavior of the second, 
alternative model is possible from the viewpoint of the behavior of the first, original model. Recall establishes how much of 
the behavior of the first model is covered by the second model. 
In our setting, we resort to a variant of this kind of approach from two different perspectives. 

First, we observe that the notion of typical behavior that is at the base of model evaluation is naturally represented by tests.
While in~\cite{AAW} it is suggested to define the event log through simulation or by explicitly describing by hand some 
typical behavior of interest, in our setting we formally describe an event log as a finite set of tests satisfying properties 
described in terms of logical formulas. Canonical tests do not exhibit any probabilistic and temporal behavior, so that  
we can employ the logical characterization of testing equivalence, which comprises a restricted set of logical 
operators: a modal operator on sequences of visible actions, true, disjunction, and diamond~\cite{ABC}. Then, given a formula 
 representing a property of interest, we use as event log the set of canonical tests satisfying , called 
, provided that such a set is finite. As an example,  could be the formula 
that is satisfied by all the tests in which the unique computation leading to success is made of the concrete trace 
. Thus, this trace represents the property with respect to which it is interesting to compare two 
process terms.
In general, tests satisfying  denote the set of typical behaviors, parameterized by , which guide the estimation of 
the degree of similarity between process terms.

Second, we observe that a test-based notion of the fitness measures of~\cite{AAW} can be used to estimate the similarity between
tests. Approximating tests, as well as relaxing time and probability requirements, is justified by the fact that we intend to
overcome the typical limitations of ``perfect'' equivalence.
In order to relax  by following this intuition, we assume that the process terms to compare are not expected to 
exhibit the same quantitative behavior when interacting with the same test, but they can exhibit such a behavior when 
interacting with two possibly different but similar tests. 
In other words, if a process term satisfies a test with a certain probability and within a given amount of time, then the second 
one can simulate the behavior of the first term by satisfying with the same probability and by the same time another test that 
fits the first test according to a notion of test similarity.

Inspired by the formulas of~\cite{AAW}, we now define the notions of behavioral precision and recall for test similarity. 
Let  be the concrete trace associated with the unique computation of  leading to success,  be 
the length of this trace, and  be the i-th state of it, such that  and  is the state 
that reaches success in one step. Then, we assume that ,  iff 
 and
. 
In practice,  denotes the transition belonging to the successful computation of  that is enabled at the 
-th step, while  denotes the set of transitions leading to failure in one step that are enabled at the 
-th step. Then, we introduce the following definitions of precision and recall for two tests  and :\\
\cws{0}{
\begin{array}{rcl}
\ms{prec}(T,T') & = & {1 \over \mid T' \mid} \sum_{i=1}^{\mid T' \mid} 
{ \mid (\ms{enabled}(T,i,s) \,\cap\, \ms{enabled}(T',i,s)) \;\cup\; (\ms{enabled}(T,i,f) \,\cap\, \ms{enabled}(T',i,f)) \mid
\over 
\mid \ms{enabled}(T',i,f) \mid \,+\, \mid \ms{enabled}(T',i,s) \mid}
\end{array}}
and: \\
\cws{0}{
\begin{array}{rcl}
\ms{rec}(T,T') & = & {1 \over \mid T \mid} \sum_{i=1}^{\mid T \mid} 
{ \mid (\ms{enabled}(T,i,s) \,\cap\, \ms{enabled}(T',i,s)) \;\cup\; (\ms{enabled}(T,i,f) \,\cap\, \ms{enabled}(T',i,f)) \mid
\over 
\mid \ms{enabled}(T,i,f) \mid \,+\, \mid \ms{enabled}(T,i,s) \mid}.\\
\end{array}}

At each step, we compare the set of enabled transitions for the current state of the two tests, by distinguishing 
the transitions leading to failure from the unique one along the computation leading to success. 
Both formulas establish a measure between  and  that estimates the similarity between them. Obviously, it holds that 
.
Similarly as in~\cite{AAW}, it is important to note that tests are not imposed to offer the same behavior, which may differ 
step by step thus originating different computations.

Analogously,  and  are not imposed to have the same length. For instance, if  and 
the behaviors of  and  coincide in the first  steps, then  because each behavior of  is 
possible according to the behavior of , while  because only half of the behavior of  is 
covered by the behavior of . 
On the other hand,  and  coincide iff .

\begin{example}

Consider  and 
. Then, it holds that 
 because we distinguish actions leading to success from those leading 
to failure. Without this distinction, it would result .

Now, consider the two tests 
 and 
. Then,  and .
Recall is higher than precision, because the unique behavior of  that is not covered by  is the first action 
of the successful computation, while from the viewpoint of  we have two impossible behaviors of , i.e.\
the actions  and .
\fullbox
\end{example}

Precision and recall satisfy the same transitivity relations shown in~\cite{AAW}, as reported in 
Table~\ref{prec_rec_transitive} for the sake of completeness.

\begin{table}
\footnotesize

\caption{Transitivity relations for  and : }\label{prec_rec_transitive}
\end{table}

Then, by using a notion of test similarity quantified with respect to the precision and recall defined above, we have the 
following relaxation of , which is based on the observed behavior expressed in terms of test-driven 
computations, where instead of a single test we consider a pair of tests that fit almost the same. 
The first attempt abstracts from the temporal behavior of the process terms to compare.

	\begin{definition}\label{def1:bMts}

Let  and  a finite set of tests. 
We say that  is behaviorally Markovian testing similar to  with precision  and recall 
 iff for each reactive test  there exists a reactive test 
 such that:
\begin{enumerate}
\item  and 
\item 
\fullbox
\end{enumerate}

	\end{definition}

As far as the transitivity properties of Def.~\ref{def1:bMts} are concerned, we now discuss what can be inferred about two 
process terms  and  provided that there exists a process term  such that  is behaviorally 
Markovian testing similar to  with precision  and recall  and  is behaviorally Markovian testing similar 
to  with precision  and recall .
By hypothesis, for each test  applied to  there exists a test  applied to  such that the probabilities 
of the successful -driven computations of  and of the successful -driven computations of  are equal. 
By hypothesis, there exists also a test  applied to  such that the probabilities of the successful -driven  
computations of  and of the successful -driven computations of  are equal. Hence, the probabilities of the 
successful -driven computations of  and of the successful -driven computations of  are equal. 
Afterwards,  and  can be inferred from , , , and , as shown in 
Table~\ref{prec_rec_transitive}.

In order to take into different account behaviors with a very low probability of success in comparison with successful 
behaviors occurring more frequent, in the two inequalities of Def.~\ref{def1:bMts} we can multiply  and  by the 
probability of the successful test-driven computations of .

The next step refines the condition about probabilities of Def.~\ref{def1:bMts} by taking into account the temporal behavior of 
process terms. 
We recall that  is defined with respect to all the sequences  of average amounts 
of time. When considering a canonical test  and a process term  that does not execute invisible actions, we can restrict 
ourselves to the sequences of length , which is the exact number of steps needed to reach success. This is not enough to 
reduce the comparison between  and a similar test  to a finite set of sequences. 
Therefore, we now define a canonical set of sequences for  that is finite and is sufficient to decide whether 
a process term behaviorally simulates another one with respect to .

Such a canonical set is made of a sequence for each subset of the set of successful computations . 
For each  we define the sequence of average amounts of time  such that 
 and the canonical set 
.
Note that  and that we may have 
 for some , so that the minimum number
of sequences to consider could be lower than .

The algorithm that computes these sequences consists of building a tree as follows. The root is at level  and is marked 
with the set of all the successful computations . If the current node of the level  is marked with a 
set  of computations, then create a child node for each  for which there exists  
such that  for each . 
Add to this new node the labels  and . The tree
construction terminates at the level . In this way, the tree contains at most  leafs,
each leaf is associated with a subset , and the path from the root to this leaf contains as labels
the average amounts of time forming the sequence .

\begin{proposition}\label{canonical_sequences}

Let  and . 
If for each sequence  of average amounts of time we have: 
\cws{0}{\ms{prob}(\calsc_{\le \theta}^{|\theta|}(P_{1}, T)) \: = \: 
\ms{prob}(\calsc_{\le \theta}^{|\theta|}(P_{2}, T))}
then, we also have that for each sequence  of average 
amounts of time: 
\cws{11}{\ms{prob}(\calsc_{\le \theta}^{|\theta|}(P_{1}, T)) \: = \: 
\ms{prob}(\calsc_{\le \theta}^{|\theta|}(P_{2}, T)).}
\fullbox

\end{proposition}

\noindent Now, we are ready to define a decidable approximation of  based on observed behavior.

	\begin{definition}\label{def2:bMts}

Let  and  a finite set of tests. 
We say that  is behaviorally Markovian testing similar to  with precision  and recall 
 iff for each reactive test  there exists a reactive test 
 such that for all sequences  
of average amounts of time:
\begin{enumerate}
\item  and 
\item 
\fullbox
\end{enumerate}

	\end{definition}

The same considerations concerning the transitivity of Def.~\ref{def1:bMts} still hold.
With respect to the approximations based on time and probability that have been discussed in the previous sections,
in this setting we deal with finite sets of tests and sequences of average amounts of time. Hence, it is possible to define 
a very intuitive, still decidable, approximation of  based on time, probability, observed behavior, and the 
three corresponding families of quantitative thresholds.

	\begin{definition}\label{beh-mte-prob-time}

Let  and  a finite set of tests. 
We say that  is Markovian testing similar to  with precision , recall 
, temporal threshold , and probability threshold  
iff for each reactive test  there exists a reactive test 
 such that for all sequences  
of average amounts of time:
\begin{enumerate}
\item  and 
\item 
\fullbox
\end{enumerate}

	\end{definition}

\noindent Given a modal logic formula , we observe that  (resp.\ ) is Markovian testing similar to  
(resp.\ ) with precision 1, recall 1, temporal and probability thresholds 0 if and only if  
with respect to the tests defined by .  It is worth noting that a unifying framework merging the three orthogonal 
aspects (time, probability, and observed behavior) puts the basis for the analysis of the trade-off among them.

\begin{example}
Consider two process terms  and  that are defined as follows, respectively:
\cws{0}{\begin{array}{l}
\lap g, \gamma \rap . \lap a, \lambda+\delta \rap . \lap b, \lambda \rap . \nil +
\lap g, \gamma \rap . \lap a, \lambda \rap . \lap d, \lambda \rap . \nil \\
\lap g, \gamma \rap . \lap a, \lambda \rap . \lap d', \lambda \rap . \nil +
\lap g, \gamma \rap . \lap a, \lambda \rap . \lap b, \lambda-\delta \rap . \nil 
\end{array}}
and compare them with respect to tests whose successful computation is described by the concrete trace ,
with  any action. Then,  is Markovian testing similar to  with:
\begin{itemize}
\item both precision and recall equal to , where the difference in the observed behaviors is due to the two concrete 
traces  of  and  of , under the assumption ; 
\item temporal threshold , where the difference in the average 
sojourn times is due to the three rates , ,  labeling corresponding transitions
related to the two concrete traces  of  and ; 
\item probability threshold , since the probabilities of the successful computations to compare are always the same.
\fullbox
\end{itemize}
\end{example}

\section{Related and Future Work}\label{sect:conc}

In the last decade several approaches to the approximation of behavioral equivalences have been proposed (see, e.g., 
\cite{LMMS,DGJP,vBW,DHW,AP,AAW,DLT,DHW2} and the references therein). 

Some of them use a well-established approach based on behavioral pseudometrics~\cite{DGJP,vBW}, which give a 
measure of the similarity between states of a transition system. These pseudometrics provide a conservative extension of 
bisimulation equivalence. Hence, they cannot be compared with the notions of testing similarity, which instead rely on testing 
semantics. With approaches based on pseudometrics it is not easy to establish a clear relation between the measure estimating 
process similarity and its interpretation in a practical, mainly activity oriented, setting. 
As an example elucidating this aspect, \cite{AB} shows the importance of evaluating the impact that the absence of an equivalence 
relating two process terms has upon their difference with respect to performability measures. However, this is done without 
defining explicitly an approximate equivalence relating these measures with the degree of similarity. 

Some other approaches that are not based on pseudometrics, like~\cite{AP,DLT,DHW2}, rely on relations approximating 
bisimulation equivalence. 
These approaches seem promising thanks to the strict relation between bisimulation and lumping for Markov chains~\cite{Buc}. 
Indeed, the characterization of lumpability is extremely useful, because the knowledge of a lumpable partition of the states 
of a Markov chain allows the generation of an aggregated Markov chain that is smaller than the original one, but leads to 
several results for the original Markov chain without an error. In this setting, there exist approximation techniques based 
on relaxed notions of lumping and on perturbation theory which establish bounds on the error made when approximating. This is 
particularly useful because these bounds are in direct relation with the numerical analysis of Markov chains and, therefore, 
provide immediately a clear interpretation of their impact upon the quantitative behavior of the process terms under analysis. 
However, it seems that there still exists a significant gap between the applicability of the approximate bisimulations 
mentioned above and their decidability. Very often, the (strict) assumptions underlying approximate bisimulation that are needed 
to define efficient verification algorithms are such that it becomes hard to find real application domains and, in particular, 
to give a natural interpretation of the degree of similarity. 
On the other hand, the definition of an approximate bisimulation that can be related to approximate lumping and has an efficient 
verification algorithm is still an open problem.

Contrariwise, the approach proposed in~\cite{AAW} does not rely on behavioral equivalences, since it is based on the estimation
of observed behaviors -- quantified through a notion of fitness that does not require any nonfunctional information such as time 
and probability -- whenever log-driven computations are compared. However, this estimation is not related to any notion of
behavioral equivalence.

The main result of this paper is showing that testing equivalence offers an ideal semantic framework for joining ideas
taken from approximate behavioral equivalences with the approach of~\cite{AAW}. In addition, the proposed definitions of 
approximation elucidate the role of each aspect under consideration -- time, probability, and observed behavior -- without 
sacrificing neither decidability nor usability. 

As future work, it would be interesting to investigate the relation between the estimations provided by approximate 
Markovian testing equivalence and -lumpability~\cite{ABC}, which is the version of lumpability corresponding to Markovian 
testing equivalence. One such result would enhance the applicability to domains where the degree of similarity must be 
interpreted in terms of impact upon the performance behavior of systems.

The application to real examples will be the subject of further investigations. For instance, it is well-known that approximate
equivalence checking can be profitably employed in the setting of noninterference analysis. Basically, one user/component 
may affect the behavior of other users/components in a way that compromises system properties like security and safety. 
Such an impact is studied by comparing the two views of the system that are obtained by activating and deactivating, respectively, 
the behavior of the interfering user/component. This approach is illustrated and used in~\cite{ABC} for the evaluation of 
performability aspects of several real-world case studies, like a secure routing system and a power-manageable system.
In this setting, the goal is to use Markovian testing similarity to compare different system views with respect to families of 
properties formalized through modal logic formulas. The comparison is intended to distinguish which observable 
behaviors make these views different from functional, temporal, and probabilistic perspectives, each case accompanied by a 
measure of such a difference.

\medskip
\noindent
 
        {\bf Acknowledgement}
 
\noindent
The author thanks the anonymous referees for their valuable comments. 
This work has been funded by MIUR-PRIN project \textit{PaCo -- Performability-Aware Computing: Logics, Models, and Languages}.

\bibliographystyle{eptcs} \begin{thebibliography}{1}

\bibitem{AABBBL}
A.~Acquaviva, A.~Aldini, M.~Bernardo, A.~Bogliolo, E.~Bont\`a, and E.~Lattanzi (2005):
\newblock \emph{A Formal Method Based Methodology for Predicting the Impact of Dynamic Power Management}.
\newblock {\sl Formal Methods for Mobile Computing, Springer LNCS} 3465, pp.~155--189. 

\bibitem{ABC}
A.~Aldini, M.~Bernardo, and F.~Corradini (2010):
\newblock \emph{A Process Algebraic Approach to Software Architecture Design}.
\newblock {\sl Springer}.

\bibitem{AB}
A.~Aldini and M.~Bernardo (2009):
\newblock \emph{Weak Behavioral Equivalences for Verifying Secure and Performance-Aware Component-Based Systems}.
\newblock {\sl Architecting Dependable Systems~6, Springer LNCS} 5835, pp.~228--254. 

\bibitem{AP}
A.~Aldini and A.~Di~Pierro (2008):
\newblock \emph{Estimating the Maximum Information Leakage}.
\newblock {\sl Journal of Information Security} 7, pp.~219--242. 

\bibitem{AAW}
A.K.~Alves~de~Medeiros, W.M.P.~van~der~Aalst, and A.J.M.M.~Weijters (2008):
\newblock \emph{Quantifying Process Equivalence Based on Observed Behavior}.
\newblock {\sl Data \& Knowledge Engineering} 64, pp.~55--74.

\bibitem{BPW} 
M.~Backes, B.~Pfitzmann, and M.~Waidner (2007):
\newblock \emph{The Reactive Simulatability (RSIM) Framework for Asynchronous Systems}.
\newblock {\sl Information and Computation} 205, pp.~1685--1720.

\bibitem{HPA}
J.A.~Bergstra, A.~Ponse, and S.A.~Smolka, Eds. (2001):
\newblock \emph{Handbook of Process Algebra}.
\newblock {\sl Elsevier}.

\bibitem{Ber07}
M.~Bernardo (2007):
\newblock \emph{Non-Bisimulation-Based Markovian Behavioral Equivalences}.
\newblock {\sl Journal of Logic and Algebraic Programming} 72, pp.~3--49.

\bibitem{Buc} P.~Buchholz (1994):
\newblock \emph{Exact and Ordinary Lumpability in Finite Markov Chains}.
\newblock {\sl Journal of Applied Probability} 31, pp.~59--75.

\bibitem{dRT}
M.~de Rougemont and M.~Tracol (2009):
\newblock \emph{Static Analysis for Probabilistic Processes}.
\newblock {\sl Int.~Symp.~on Logic in Computer Science (LICS'09), IEEE-CS}, pp.~299--308.

\bibitem{DGJP}
J.~Desharnais, V.~Gupta, R.~Jagadeesan, and P.~Panangaden (2004):
\newblock \emph{Metrics for Labelled Markov Processes}.
\newblock {\sl Theoretical Computer Science} 318, pp.~323--354.

\bibitem{DLT}
J.~Desharnais, F.~Laviolette, and M.~Tracol (2008): 
\newblock \emph{Approximate Analysis of Probabilistic Processes: Logic, Simulation and Games}. 
\newblock {\sl Int.~Conf.~on Quantitative Evaluation of Systems (QEST'08), IEEE-CS}, pp.~264--273.

\bibitem{DHW} A.~Di~Pierro, C.~Hankin, and H.~Wiklicky (2005):
\newblock \emph{Measuring the Confinement of Probabilistic Systems}.
\newblock {\sl Theoretical Computer Science} 340, pp.~3--56.

\bibitem{DHW2} A.~Di~Pierro, C.~Hankin, and H.~Wiklicky (2008):
\newblock \emph{Quantifying Timing Leaks and Cost Optimisation}.
\newblock {\sl Conf.\ on Information and Comm.\ Security (ICICS'08), Springer LNCS} 5308, pp.~81--96.

\bibitem{LMMS} P.~Lincoln, J.C.~Mitchell, M.~Mitchell, and A.~Scedrov (1999):
\newblock \emph{Probabilistic Polynomial-time Equivalence and Security Analysis}.
\newblock {\sl World Congress on Formal Methods in the Development of Computing Systems (FM'99), Springer LNCS} 
1708, pp.~776--793.

\bibitem{FUMK} 
H.~Foster, S.~Uchitel, J.~Magee, and J.~Kramer (2003):
\newblock \emph{Model-based Verification of Web Service Compositions}.
\newblock {\sl Int.~Conf.~on Automated Software Engineering (ASE'03), IEEE-CS}, pp.~152--163.

\bibitem{ST}
R.~Segala and A.~Turrini (2007):
\newblock \emph{Approximated Computationally Bounded Simulation Relations for Probabilistic Automata}.
\newblock {\sl Computer Security Foundations Symposium (CSF'07), IEEE-CS}, pp.~140--156.

\bibitem{SWD} A.~Simpson, J.~Woodcock, and J.~Davies (1998):
\newblock \emph{Safety through Security}.
\newblock {\sl Workshop on Software Specification and Design (IWSSD'98), IEEE-CS} pp.~18--24.

\bibitem{Tzeng}
W.G.~Tzeng (1994):
\newblock \emph{A Polynomial-Time Algorithm for the Equivalence of Probabilistic Automata}.
\newblock {\sl SIAM Journal on Computing} 21, pp.~216--227.

\bibitem{vBW}
F.~van~Breugel and J.~Worrell (2005): 
\newblock \emph{A Behavioural Pseudometric for Probabilistic Transition Systems}. 
\newblock {\sl Theoretical Computer Science} 331, pp.~115--142.


\end{thebibliography}

\end{document}
