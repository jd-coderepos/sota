\documentclass[10pt]{article}
\usepackage{amsmath,amssymb}
\setcounter{page}{1}

\newcommand{\ls}{{\it l}} \newcommand{\ZZ}{{\mathbb Z}} \newcommand{\QQ}{{\mathbb Q}} \newcommand{\NN}{{\mathbb N}} \newcommand{\FF}{{\mathbb F}} \newcommand{\Zmod}[1]{{\mathbb Z}/(#1)} \newcommand{\divides}{\mid}
\newcommand{\notdivides}{\nmid}
\newcommand{\Znonneg}{\ZZ_{\ge 0}} \newcommand{\Zpositive}{\ZZ_{>0}} \makeatletter
\def\GCD{\qopname\relax\@empty{GCD}} \def\lc{\qopname\relax o{lc}} \def\res{\qopname\relax o{res}} \def\content{\qopname\relax o{content}} \makeatother
\newcommand{\GF}{\mathrm{GF}}
\newcommand{\QF}{\mathrm{QF}}
\newcommand{\rem}{\mathrm{rem}}

\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}

\newcommand{\Q}{\QQ}
\newcommand{\sQ}{\QQ}
\newcommand{\Z}{\ZZ}
\newcommand{\sZ}{\ZZ}
\newcommand{\Fp}{{\mathbb F}_p}
\newcommand{\degr}{d}
\newcommand{\x}{x}
\newcommand{\minp}{m}
\newcommand{\bad}{lc-bad }
\newcommand{\bbad}{lc-bad}
\newcommand{\EuclAlg}{{\rm GCD}}

\author{
  Michael Monagan\thanks{Supported by NSERC of Canada
  and the MITACS NCE of Canada.}\footnotemark[1] \quad
  Mark van Hoeij\thanks{Supported by NSF grant
  0098034.}\footnotemark[2] \10pt]
 \footnotemark[2]
  Department of Mathematics, Florida State University, \\
  Tallahassee, FL 32306-4510, USA.
}

\title{A Modular Algorithm for Computing
Polynomial GCDs over Number Fields presented with Multiple Extensions.}
\date{November 2005}


\begin{document}
\maketitle
\begin{abstract}
We consider the problem of computing the monic gcd of two
polynomials over a number field .
Langemyr and McCallum have already shown how Brown's modular
GCD algorithm for polynomials over  can be modified to work
for  and subsequently, Langemyr extended the
algorithm to .  Encarnacion also showed how to use
rational number to make the algorithm for  output sensitive,
that is, the number of primes used depends on the size of the integers
in the gcd and not on bounds based on the input polynomials.

Our first contribution is an extension of Encarnacion's modular GCD
algorithm to the case  which, like Encarnacion's algorithm,
is is output sensitive.

Our second contribution is a proof that it is not necessary
to test if  divides the discriminant.
This simplifies the algorithm; it is correct without this test.

Our third contribution is a modification to the algorithm to treat
the case of reducible extensions.  Such cases arise when
solving systems of polynomial equations.



Our fourth contribution is an implementation of the
modular GCD algorithm in Maple and in Magma.
Both implementations use a recursive dense polynomial data structure for
representing polynomials over number fields with multiple field
extensions.

Our fifth contribution is a primitive fraction-free algorithm.
This is the best non-modular approach.
We present timing comparisons of the Maple and Magma implementations 
demonstrating various optimations and comparing them with the monic Euclidan
algorithm and our primitive fraction-free algorithm.

\end{abstract}

\section{Introduction}
We recall the relevant details of the so called {\em modular GCD algorithm}
first developed by Brown in \cite{Brown} for polynomials over  and then
by Langemyr and McCallum in \cite{Langemyr}, Langemyr in \cite{AAECC} and
Encarnacion in \cite{Encarnacion} for polynomials over ,
which we shall generalize to .
First some notation.

We denote the input polynomials by  and , their monic gcd by .
The {\em cofactors} are the polynomials  and .
The {\em denominator}  of  is the
smallest positive integer such that .
See section~\ref{sectionEucl} for the definition of 
if .
The {\em height}  of  is the magnitude of the largest
integer appearing in the rational coefficients of .

The {\em associate}  of  is defined as
 where .
Here  is defined as  where  is
the {\em leading coefficient} of .
Define the {\em semi-associate}  as  where
 is the smallest positive rational for which 

\bigskip
\noindent
{\bf Examples:} If  then
, , and 
If  and  then , ,
 and .


\bigskip
\noindent
Computing the associate  is useful for removing denominators,
but could be expensive if  is a complicated algebraic number.
So we preprocess the input polynomials in our algorithm
by taking the semi-associate instead.
If  then the two notions are the same up to a sign:





\subsection{Motivation for the algorithm}
\label{advantages}
The goal of this paper is to present an efficient
GCD algorithm over a field  that consists of
multiple extensions over  that is practical.
As a motivating application, consider the problem of factoring 
using Trager's algorithm \cite{Trager}.
One sequence of gcd computations in  is required to compute the
square-free factorization of  beginning with .
Then for each square-free factor, a second sequence of gcd computations
in  occurs when the irreducible factors of  are determined.

Let  be a number field of degree  over  and
let  both have degree  and let  be their monic gcd.
For a computer algebra system to be effective at performing computations
in  we require a GCD algorithm for computing  with a complexity
which is comparable to that of multiplication and division in 
It is well known that the size of the integers in the
coefficients of the remainders in the Euclidean algorithm grows
rapidly and consequently, the Euclidean algorithm becomes ineffective
when  is much smaller than  the worst case being when .
This leads us to consider a modular GCD algorithm.

Let  that is,  is is the magnitude of the largest
integer coefficient appearing the rational coefficients of 
If we knew  in advance, we could choose a single prime  from
a table, compute one modular image in  time
and reconstruct the rational coefficients of  in  time.
However we do not know  and accurate bounds are not possible when 
is much smaller than  and .
Thus we compute  modulo a sequence of primes of almost constant bit length
and incrementally reconstruct .
If we want , that is, if we want
the number of primes used to be proportional to the size of
the coefficients in  so that small gcds are recovered quickly,
then we are forced to
\begin{enumerate}

\item Not use a primitive element to convert to a single extension,
which is expensive and can cause a blowup in the size of the coefficients.
This problem is well known, e.g. see \cite{Abbott}.  Note, although the conversion
to a primitive element could be done {\em after} reducing the inputs modulo 
thus, without blowup, it is expensive; it introduces an  factor
into the overall complexity of the algorithm which is  otherwise.
We make some additional remarks about this in the conclusion.

\item Not invert , which can also cause a blowup, and can
also be more expensive than computing .

\item Use rational reconstruction -- see \cite{Collins,MQRR,Pan,Wang}.
Otherwise a denominator bound would be necessary, but such bounds
are generally too large. The defect bound, usually the
(reduced~\cite{Bradford}) discriminant, which is part of the denominator
bound, is usually also too large.

\item Use trial division.  Otherwise we would need bounds for .
Such bounds will be a function of  and will be much too
large when  is small relative to  and , an important
special case.

\end{enumerate}
Encarnacion's paper confirms and deals with these items.
As a result, Encarnacion's algorithm is the fastest algorithm
for a single extension.
As for item 1, his paper deals only with a single extension, but he
does illustrate that modifying that extension (making 
an algebraic integer) is not efficient. But if modifying one
extension  is not efficient, then modifying  extensions
(replacing it by a primitive element) is certainly not efficient.

\subsection{Organization of the paper}
Our first goal is to generalize Encarnacion's algorithm to multiple
extensions without using a primitive element.
We do this in section 2 where we study the Euclidean algorithm in 
modulo a prime .


In section 2 we present our modular GCD algorithm and study its expected
time complexity.  We also describe how to modify the modular GCD algorithm so that it can
be used when one or more of the minimal polynomials defining
the number field  are not irreducible and in section 4 we give
explicit code for how to do this in Magma.


In section 3 we present two implementations of our modular GCD algorithm,
one in Maple and one in Magma.  The data structure that we use for both
implementations, for representing polynomials and field elements, is
a recursive dense data structure.
We give details and explain why it is a good choice.

To demonstrate the effectiveness of the modular GCD algorithm in
 we compare it with several implementations of the Euclidean
algorithm over characteristic 0.  Based on the work of Maza and
Rioboo in \cite{Maza} we give a new primitive -fraction-free
algorithm for  which is the best non-modular algorithm. Timing
comparisons comparing the two implementations of our modular GCD
algorithm with the various non-modular Euclidean algorithm based
implementations are given along with comparisons demonstrating the
effectiveness of the other improvements we have made.


\section{The modular GCD algorithm}

\subsection{lc-bad, fail, unlucky and good primes}
The {\em modular GCD algorithm} computes the {\em monic gcd}\ 
 of  and .
It does this by reducing  modulo one or more primes
and calling the {\em Euclidean algorithm mod } for each of these primes .
The modular GCD algorithm reconstructs  from these modular images.
If the Euclidean algorithm mod  outputs  we say  is a good prime.
Only good primes should be used during the reconstruction for it to
be successful.
However, not all primes are good. We distinguish the following cases:
\begin{definition}
\label{definitionbad}
Let  and  be their monic gcd.
We will distinguish four types of primes.
\begin{itemize}
\item {\em \bad primes}.
Let  be the minimal polynomials of the 
field extensions .
So  is a monic irreducible polynomial in 
 and .
If ,  or
any leading coefficient of 
vanishes mod  then we call  an {\em \bad prime}.

\item {\em Fail primes}.
If  is not an \bad prime, and the Euclidean algorithm
mod  returns ``failed'', then  is called a {\em fail prime}.

\item {\em Unlucky primes}.
If  is not an \bad prime nor a fail prime, and if the
output of the Euclidean algorithm mod  has higher degree than ,
then  is called an {\em unlucky prime}.

\item {\em Good primes}.
A prime  is called a {\em good prime} if the Euclidean algorithm mod 
returns  mod .
Theorem~\ref{theorem1} in section~\ref{sectionEucl} says that all primes
that are not \bad are either fail, unlucky or good.
\end{itemize}
\end{definition}
{\bf Remarks:}
\begin{enumerate}
\item Our definition of \bad prime is not symmetric in .
It could be that  is \bad for  but not \bad for .
In that case, because of how we set up the algorithm,
we should either: not use , or: interchange
 mod  before calling the Euclidean algorithm mod .


\item Our definitions are not the same as the
standard definitions in~\cite{Brown}.
For example, it is possible that the Euclidean algorithm mod  fails
even if the monic gcd of  mod ,  mod  exists
and equals  mod .
We call such  a fail prime and not a good prime.
This distinction is not necessary if 
where there are no fail primes.



\item If 
(in the standard definition these primes are called bad primes)
then  mod  is not defined and so
 can not be a good prime.
According to theorem~\ref{theorem1},  must then be either
\bbad, fail, or unlucky.



\item Minimal polynomials are monic so
the leading coefficients of  are
.
However,  is in general not an integer but
an algebraic number.


\item 
It is very easy to tell if a prime  is \bad or not, but we can
not tell in advance if  is fail, unlucky, or good.
So we will end up calling the Euclidean algorithm mod  with fail, unlucky,
and good primes but never with \bad primes.
\end{enumerate}

\subsubsection{\bad primes}
If ,  and  then  satisfies
our definition of an \bad prime as well as the definition of a good
prime. However, there are good reasons not to use any \bad prime.
Take for example .
Also, the proof of theorem~\ref{theorem1}
requires that  not be \bbad.


Another example is ,  with
gcd ,
, and the minimal polynomial of  is
.
Because of preprocessing, in the algorithm we work with
. Modulo  this becomes
. If we used the prime , it is easy to give an example 
where the Euclidean algorithm mod  returns  mod 
which is . But, viewing  as a variable,
 mod .

For our algorithm, the best solution to the above problems is:
{\em never use  an \bad prime}.

\subsubsection{Fail primes}
Fail primes are primes for which the Euclidean algorithm mod 
tries to divide by a zero divisor, in which case it returns ``failed''.
Take for example ,  where .
Denote  mod  as .
The Euclidean algorithm mod  will first try to make  mod 
monic by multiplying it with .
But if , the norm of , vanishes mod 
then  is zero or a zero-divisor, and the computation of
 fails. In this example 
so the fail primes are  and .

The reason that in our terminology  and  are called fail primes
and not \bad primes in the example (after all, the problem was caused
by  mod )
is to indicate how these primes are discarded:
We do not actively avoid these primes, instead, they
``discard themselves'' when the Euclidean algorithm mod  is called.

One can also construct examples where  is not \bbad,
 is a unit mod ,
but  still divides   (occasionally such 
can be unlucky instead of fail).
Take for example  with minimal polynomial ,
,
.
The monic gcd is .
The denominator is .
In this example, if  then  is not \bad and the leading
coefficient of  (as well as of ) is a unit mod .
Nevertheless,  can not be a good prime because .
In this type of example  must divide the discriminant.
For this reason, Encarnacion~\cite{Encarnacion} tests if the
discriminant is  mod  and avoids such primes.
However, even without the discriminant-test,
the primes  would still have been discarded at some point:
The Euclidean algorithm mod 
will calculate  =  mod , try to make  monic
and fail because the leading coefficient of ,
namely, , is a zero divisor mod .


Although one can generalize the discriminant-test
to , our algorithm does not use it because it makes no difference for
the correctness of the algorithm.
For an intuitive explanation see lemma~\ref{lemmaTestNotNeeded} and for a proof see theorem~\ref{theorem1}.


\subsubsection{Unlucky primes}
Unlucky primes are not trivially detectable like \bad primes
and do not ``discard themselves'' like fail primes do, but
need to be detected and discarded nevertheless.
Fortunately, Brown~\cite{Brown} showed how to do this in
a way that is efficient and easy to
implement: Whenever modular gcd's do not have the
same degree, keep only those of smallest degree
and discard the others.

As an example, take , ,
. Then the Euclidean algorithm mod 
will return , so  is an unlucky prime.
But if ,  and  the same as before,
then  is a fail prime.

\subsubsection{Good primes}
\label{goodprimes}
All but finitely many primes must be good. This is because
if one would run the Euclidean algorithm in characteristic 0,
it would be a finite computation, and so there can only be finitely
many conditions on the primes and each condition only excludes
finitely many primes (see lemma~\ref{finitep}).





Of course we will not run the Euclidean algorithm
in characteristic 0, so this does not tell us which primes to use.
But this is not a problem because
to guarantee correctness of the
algorithm, just as in Brown's algorithm,
all we need to do is to avoid the \bad primes.
Experiments show that random primes are good with high probability. Hence,
even if there was an oracle that quickly provided good primes, it would not
noticeably improve the running time.
 \subsection{The Euclidean algorithm over a ring}
\label{sectionEucl}
Let  be algebraic numbers.
Let  and .
Let  be the degree of  over
.
The dimension of  as a -vector space is .
A basis of  is:

Let  be the set of all -linear combinations of 
and let .
Let  be the minimal polynomial of 
over . The degree of  is ,  is {\em monic} (the leading
coefficient is )
and .
The coefficients of  are in .
Let  be the smallest positive integer such that the coefficients
of  are in .
Denote  and .

In general  is not a ring.
For example, , but  is not
in  unless .
When , to compute the product  we
replace  by variables ,
then multiply ,
as polynomials, and after that
take the remainder modulo the polynomials .
During this computation we only divide a bounded number of times by 
. Hence, if  is a sufficiently large integer, then
 for all .


If  then define the {\em denominator} of  as the smallest
positive integer  such that .
Note that , and hence , depends on the choice of
.
For example, if 
and  then .
For  one has ,
in particular .
Define

If  then  divides 
for some . Hence, if  then  is a ring.
We will {\em always assume that  does not divide } so that  is a ring
(if  then  is an \bad prime).
Denote

Then  is a -module with basis .
Define 
If  then we use the notation , or also  mod ,
for the image of  in . If , then
(primes that divide  are always excluded)

If  is defined we will say that  {\em can be reduced mod} .


Now  is a ring and also an -vector space with
basis  mod . We can do the following identifications:



If  then  is a {\em unit} in  if and only if both  and 
are in   (whenever we write  it is implicitly assumed that ).
This is equivalent to .
If  we will call  a {\em unit} mod  if 
and  is a unit in . The following lemma shows
that these two notions are equivalent.

\begin{lemma}
\label{unitmodp}
Let . Then
 is a unit in 
if and only if  is a unit in .
\end{lemma}
{\bf Proof:}
If  is a unit in  then  and  are in , hence
 and  are defined,
and since  is a ring homomorphism 
one sees that
 is the inverse of . Hence
 is a unit in . \\
Conversely, assume  is a unit. Then 
so we can take . To finish the proof we
need to show that .
Take the smallest integer  for which .
Since  is minimal, we have 
but then  is the product of a unit
and a nonzero element in  and hence nonzero.
But  equals 
so , hence , so  and 
is invertible in .
\\


If  then
{\em the denominator}  is defined as
the smallest positive integer such that
.
Now  if and only if .
The polynomial  is the image of  in , and
is defined if and only if , in which case we 
will say that  {\em can be reduced} mod .
Furthermore, if  and  have the same degree
(when  is nonzero mod )
then we will say that  {\em reduces properly} mod .
If  is not an \bad prime it means
that  can be reduced mod , and that  reduces
properly mod .


Let  and .
Multiplication by  is an -linear map .
The {\em characteristic polynomial}  of  over
the extension  is defined as the characteristic polynomial of
this linear map.
The {\em trace}  of  over  is the trace of 
and the {\em norm}  of  over  is the determinant of .
Whenever we do not mention the extension  it is assumed to
be  (so  and ) in which case we
write , , .
Now the {\em integral closure of  in } is

This is a ring (see \cite{Hecke}), and the elements of 
are called the {\em algebraic integers} in .
We will use the following notation for the integral closure of 
in 

Suppose  and .
Then by definition  if and only if  mod .
The characteristic polynomial of  is in , hence 
and hence


\begin{lemma}
\label{unit}
If  and  then  is a unit
in  if and only if  is a unit in .
In particular,  is a unit if and only if
 is a unit in , in other words,
both numerator and denominator
of  are not divisible by .
The same is also true for .
\end{lemma}
{\bf Remark:} If  then 
and the lemma implies that if  and
 then . \-15pt]
\begin{enumerate}
\item	Set , , .
\vspace*{-2mm}
\item	\label{monic1}
	If  then set  = monic.
	If  = ``failed'' then return ``failed''.\vspace*{-2mm}
\item	If  then return .
\vspace*{-2mm}
\item	\label{monic2}
	Set .
	If  = ``failed'' then return ``failed''. \vspace*{-2mm}
\item	Let  be the remainder of  divided by .
\vspace*{-2mm}
\item	\label{laststep} Set  and go back to Step 3.
\end{enumerate}
{\bf Remark on a shortcut:}
Suppose that  in step~3 is a nonzero constant.
Some implementations of the Euclidean algorithm over a field will then take a
{\em shortcut}: stop the computation, the output is 1.
Over a ring {\em we should not use this shortcut}\ because that would invalidate
lemma~\ref{st_exist} below. This plays a role because our algorithm will
not test if  divides the discriminant.
We may only use the shortcut if  is a unit.
For  we can test that efficiently
by computing  mod  (see lemmas~\ref{unitmodp},\ref{unit}).
\\

Denote  as the output of this algorithm.
If  ``failed'' then
the sequence of polynomials  with , ,
is called the {\em monic polynomial remainder sequence} of .
\begin{lemma}
\label{st_exist}
If 
and  ``failed'' then the ideal

remains the same during each step.
In particular  which implies:
\begin{enumerate}
\item There exist  such
      that .
\item  and  are divisible by .
\item  is the monic gcd of  and .
\end{enumerate}
\end{lemma}
{\bf Proof}: When we make  monic, we divide by a unit, which does not
change the ideal. In step~\ref{laststep} we increase  so we must show
that  which is clear because  is
the remainder of  modulo .
Hence . So 
which is part 1,  which is part 2. Finally, every  that
divides both  and  divides any element of  in particular
it divides . Since  is monic it satisfies precisely the definition
of the monic gcd. \\

\noindent {\bf Remark:} If  ``failed'' then the
{\em extended Euclidean algorithm}, which calculates  and  as well as 
will not fail either. \\

Let  be the output of the Euclidean algorithm.
If all leading coefficients during the computation
are units then the algorithm succeeds, the monic gcd exists and
equals .
If there is no monic gcd in 
then  ``failed''.
If a monic gcd  does exist then it is not necessarily true that
the algorithm will find it; the output  is then either  or ``failed''.
A situation where the output is ``failed'' even when a monic gcd exists
is given in the following lemma.
\begin{lemma}
\label{lemmaTestNotNeeded}
Suppose  and . Then  .
Suppose a monic gcd  exists and that .
Then  ``failed''.
\end{lemma}
{\bf Proof:}
If  then ,
hence  so .
Since  ``failed'', when we run the
Euclidean algorithm over  we will encounter a leading coefficient in 
that is not a unit in . But according to the remark after lemma~\ref{unit},
if  is not a unit in  then it is also not a unit in 
and hence the algorithm fails over  as well.
\\


If the ring  in the Euclidean algorithm is a field ,
then the output is never ``failed'', so  is
always the monic gcd of .
\begin{lemma}
\label{finitep}
Suppose  and 
is the monic polynomial remainder sequence. Let  in 
be the leading coefficients that we divided by in steps~\ref{monic1} 
and~\ref{monic2}.
For all but finitely many primes the following holds:
\begin{enumerate}
\item , and  are units in .
\item  and 
is the monic polynomial remainder sequence of .
\item  is a {\em good prime} which means:
The monic gcd of  exists, will be found
by the Euclidean algorithm, and equals  where  is the monic
gcd of .
\end{enumerate}
\end{lemma}
{\bf Proof:} Part 1 holds for all primes that
do not divide any of the following:
, , , , 
for . Since these are finitely many
integers, all nonzero, we see that part 1 holds for all but finitely
many primes.
The only divisions in the Euclidean algorithm are divisions
by , so if the input is in 
and all  are units in , then all polynomials
in the  computation are in .
Induction shows that

is precisely the monic polynomial remainder sequence of , so part 2 follows from part 1.
Part 3 follows from part 2.
\\

Since we will only run the Euclidean algorithm in
 for various primes , and not in ,
we do not know the values of .
So the lemma does not tell us which primes are good, it only
says that all but finitely many primes are good.
We now investigate the relation between

and  when  is not an \bad prime.
\begin{theorem}
\label{theorem1}
Let  and let  be the monic gcd.
Assume , 
and  mod , so  is not an \bad prime.
Let .
If  ``failed'' then

Furthermore, if  then 
reduces properly mod  and .
\end{theorem}
{\bf Remark:} The theorem says that if  is not \bad
then  is either fail, unlucky, or good.
This implies that if \bad primes are avoided then the modular GCD algorithm
is correct. \  \overline{s_0} \overline{f_1} + \overline{t_0} \overline{f_2} = {\bf d}.  
	s_0 f_1 + t_0 f_2 \equiv {\bf d}_0 {\rm \ mod \ } p.

  h_i =
	(s_{i-1} f_1 + t_{i-1} f_2 - {\bf d}_{i-1} )/p^i \in R_p[x]

	\tilde{s}_i = s_{i-1} - p^i {\bf \rm q}_i s_0, \ \ \ 
	\tilde{t}_i = t_{i-1} - p^i {\bf \rm q}_i t_0, \ \ \
	{\bf d}_i = {\bf d}_{i-1} + p^i {\bf \rm r}_i.

	\tilde{s}_i f_1 + \tilde{t}_i f_2 \equiv {\bf d}_i {\rm \ mod \ } p^{i+1}.

	s_i = s_{i-1} - p^i r, {\rm \ \ and \ \ }
	t_i = t_{i-1} - p^i({\bf \rm q}_i t_0 + q f_{1,d}),

	s_i f_1 + t_i f_2 \equiv {\bf d}_i {\rm \ mod \ } p^{i+1}.

	\label{intersection}
	R_p = \hat{R}_p \bigcap L
 \hat{s}f_1 + \hat{t}f_2 = \hat{\bf d}. 	  {\rm deg}({\bf d})
	= {\rm deg}(\hat{\bf d}) \geq {\rm deg}(g).
-16pt]
\begin{itemize}
\item[1.] Preprocessing: Set ,  and .
\vspace*{-2mm}
\item[2.] Main Loop: Take a new prime  that is not lc-bad.
\vspace*{-2mm}
\item[3.] Let  be the output of the Euclidean algorithm applied
          to  and  mod .
          If ``failed'' then go back to step 2.
\vspace*{-2mm}
\item[4.] If  then return .
\vspace*{-2mm}
\item[5.] If  or  then \\
          set  and go to step 8.
\vspace*{-2mm}
\item[6.] If  then go back to step 2.
\vspace*{-2mm}
\item[7.] Let  be the output of applying Chinese remaindering to  mod  and
           mod .  Set .
\vspace*{-2mm}
\item[8.] Apply rational reconstruction to obtain  from  mod . \\
          If this fails, go back to step 2.
\vspace*{-2mm}
\item[9.] Trial division: If  and  then return , \\
          otherwise, go back to step 2.
\end{itemize}


\medskip
\noindent
Step 1 is a preprocessing step.  We compute  and ,
the semi-associates of  and  respectively, that is,
we cancel any rational scalar from the input polynomials before proceeding.
We do not compute  or , the monic
associates of  and  which can cause a blowup.

Since lc-bad and fail primes are actively discarded in steps 2 and 3,
the primes  remaining after step 6 are
either all unlucky or all good.  Let .
Suppose rational reconstruction succeeds at step 8 with output 
If  and  then  and the modular GCD algorithm terminates.
If either trial division fails then from Theorem 1
either  is not yet large enough to recover the rational
coefficients in  or all primes are unlucky.
Before we state the time complexity of the algorithm
we examine three technical problems.

\subsubsection*{Problem 1: The Trial Divisions}
If  the trial divisions  and  in step 9 may
be very expensive because the rational coefficients in the quotient
 may be much larger in length than those in .
There are many ways to engineer the algorithm so that this
happens with very low probability.

One is to modify the trial division algorithm so it first
tests if  and  for some prime  before
attempting divisions in characteristic 0.  For this test to be of value
the prime  must be different from the primes used thus far
by the modular GCD algorithm.  Magma, for example, reserves
a special prime not used by modular algorithms for this purpose.

A second way is to build into the rational reconstruction algorithm
some redundancy so that if it succeeds with output  then 
with high probability. This is our preferred approach.  To do this
one can either modify Wang's rational reconstruction algorithm in
\cite{Wang81,Wang}, or use the algorithm of Monagan in \cite{MQRR}.

A third possibility is to modify the modular GCD algorithm
so that when rational reconstruction succeeds with output ,
we compute , the GCD modulo an additional prime 
and require that  before we
attempt the trial divisions.  Maple version 8, for example,
uses this approach for a number of modular algorithms.

\subsubsection*{Problem 2: Rational Reconstruction is not Incremental}

When we apply the Chinese remainder theorem to compute the new
value of  in step 7 such that  and
, we can do this incrementally, i.e.,
in  instead of  time per integer coefficient,
using only classical algorithms for integer arithmetic as follows:

\medskip
\noindent
\hspace*{2mm}    Step 9: Chinese remaindering. \\
\hspace*{2mm}    Set .   \\  \hspace*{2mm}    Set . \\
\hspace*{2mm}    Set . \\
\hspace*{2mm}    Set . \\
\hspace*{2mm}    Set  \\

\noindent
However, no incremental version of rational reconstruction is known.
If one uses the Euclidean algorithm (see section 3.2), rational reconstruction will
cost  per coefficient.  Suppose  and .
If rational reconstruction were applied at each step it will
introduce an  component per rational coefficient
into the modular GCD algorithm.
This can be reduced to  without increasing
the asymptotic cost of the other components of the modular GCD
algorithm and without using fast arithmetic
if we perform rational reconstruction periodically.
For example, after   primes.

In practice the cost of rational reconstruction is
usually much less than  per coefficient and the
Fibonacci sequence is much too sparse on most data.
Suppose  has  rational coefficients that need to be
reconstructed. Suppose rational reconstruction is designed so that
it will fail with high probability when the input is the image of a
rational number which cannot be reconstructed because  is not yet
large enough. Suppose also it remembers the monomial in  where it
failed in the previous step so that it always starts with a
coefficient for which it previously failed. Then if rational
reconstruction is applied at every step, the expected total cost of
rational reconstruction, assuming classical integer arithmetic, is
 that is,  per coefficient.

\subsubsection*{Problem 3: Computing Inverses in the Euclidean Algorithm}

In Step 3 the Euclidean algorithm is applied over  modulo  which
is not a field in general; it is a finite ring  with zero divisors
in general.  The (monic) Euclidean algorithm, described in section 2,
needs to invert the leading coefficient of the divisor, an element of .
Units in  can be inverted using linear algebra in  arithmetic
operations in  where  is the degree of  over 
However this would introduce an  factor into the modular GCD algorithm.
Thus we prefer to apply the Euclidean algorithm to compute inverses in 
because it requires only  arithmetic operations in .
However, if  is not a field, the Euclidean algorithm may fail
to compute an inverse even when the inverse exists.
If this happens we will also call  a fail prime.
Thus a prime  is a fail prime if the Euclidean algorithm with
input  and  in  fails modulo  where inverses
are computed in  using the Euclidean algorithm.
Thus there are two sources of failure.  One is elements of  which
are not invertible modulo  and the other is units in  which
are not invertible by the Euclidean algorithm.
It is not hard to see that the number of fail primes is finite.
Run the Euclidean algorithm in characteristic 0 to invert
elements of   The conditions on  for which elements
of  are not invertible when using the Euclidean algorithm
involve integers of finite length and hence the number
of fail primes for any given input  and  is finite.

\subsection{Time Complexity of the Modular GCD Algorithm}
We estimate the average asymptotic time complexity of our
modular GCD algorithm for .  We will not include the cost
of the trial divisions in our complexity estimate and we
will state the expected running time in terms of
,  and .

Let  be the degree of the number field  and let
, that is, 
bounds the size of the largest coefficient appearing in the .
Let , ,

and let  be the number of good primes needed to reconstruct .
In most cases  though it can happen that the coefficients
of  are larger than those of  and .

We will assume that the probability that a prime is good is high
so that  is close to the actual number of primes that were used.
This assumption is true in practice when we use 30 bit primes.
However, for theoretical completeness of the complexity estimate,
we would need to determine some  such that
if  then the probability that  is good is greater
than some constant, say .
Moreover, we require that  is a polynomial function
of the size of , i.e., polynomial in .
We did not determine such  because it appears to be difficult
to obtain a useful result and secondly, this issue would
not have consequences for the algorithm in practice (one hardly ever
encounters primes that are not good).
However, we do claim that such a bound that is
polynomial in  exists.


Because neither of our implementations use asymptotically
fast arithmetic throughout it makes sense for us to first assume
classical arithmetic, i.e., quadratic algorithms for integer
and polynomial arithmetic.  Under the assumptions made we have
\begin{theorem}
\label{theorem2}
The expected running time of our modular GCD algorithm is

arithmetic operations on integers of size  bits.
\end{theorem}
The three contributions are for reducing the minimal polynomials 
and input polynomials  and  modulo  primes (step 3),
applying the Euclidean algorithm  times (step 3),
and reconstruction of  rational coefficients (steps 7 and 8),
respectively.

The hardest gcd problems for our algorithm occur when  and when  is large, that is,   This happens
when the gcd  and cofactors  and  are of
similar size. This is also when dividing  and  by 
using the classical division algorithm is most expensive. Under the
simplifying assumption that , that is the coefficients of
the minimal polynomials are not larger than those in  and
, the expected time complexity for these ``hard'' gcds is 

 
\subsection{When  is not a field}
Until now we have assumed that  is a field, i.e., we assumed
that  is a field and each  is irreducible over 
The algorithm does not verify these assumptions because testing
irreducibility of  with a factorization algorithm could be costly,
and in many applications, it will be known a priori that
each  is a field hence such tests would be redundant.
However, in the context of solving a systems of polynomial equations
over  with finitely many solution, Lazard in \cite{Lazard} presents
an algorithm for decomposing a lex Gr\"obner basis into a union of triangular sets
where univariate gcds are computed in  and  is often not field,
that is, one or more of the  are be reducible over .
Another algorithm of Kalkbrenner in \cite{Kalkbrenner} also computes
gcds in  where  is often not a field.
Kalkbrenner's algorithm decomposes a polynomial system into
a union of triangular sets using pseudo-remainders and gcd computations in 
The problem of computing gcds efficiently in  when one or more of the
 are reducible is studied by Maza and Rioboo in \cite{Maza}.
We will look at their algorithm in more detail in a later section.
As our algorithm is stated, if any  is reducible, and
the leading coefficient of a remainder in the Euclidean algorithm
(when run over ) is not invertible, our modular algorithm
will most likely enter an infinite loop because the
Euclidean algorithm mod  will fail for all but finitely many .
This is a serious flaw which we now address.

Let  be the output of
Euclidean algorithm over  (over characteristic 0).
If  ``failed'', then it is still true that all but
finitely many primes are good. In this case, the modular GCD algorithm
presented thus far will produce .
However, if  ``failed'', then all but finitely many primes
are fail primes. So we can not expect the modular GCD algorithm to terminate.
We want to have a {\em modified} modular GCD algorithm that has
the following specifications:

\begin{enumerate}
\item It must always terminate, whether  is a field or not.
\item If  is a field, the output must be .
\item If  is not a field, then the output must one of the
following: Either the monic gcd in . Or the output
is ``failed'', in which case a second output must
be returned as well, namely a non-trivial factor  of some 
a zero divisor in .
\end{enumerate}

\noindent
{\bf Example:} Let  where .
Let  and   Inverting
 will fail for all primes .
Thus in our example the output of our modified algorithm
should be "failed", .

\medskip
\noindent
{\bf Remark:}
Suppose  is not a field and the Euclidean algorithm if run
in characteristic 0 would encounter a zero divisor.  The modification to
our modular algorithm described below will most probably output this zero
divisor.  It can, however, output a different zero divisor.

\medskip
\noindent
It is well known that the Euclidean algorithm can easily be modified
to meet the above specifications without calling a factoring algorithm:
The Euclidean algorithm  in characteristic 0
will only fail if we divide by a zero divisor, that is, we try to
invert a zero divisor.  Inverses use the extended Euclidean algorithm
applied to  and some other element of  for some .
The inverse only fails when this gcd is not 1, in which case a non-trivial
factor  of  has been found.  The {\em modified} Euclidean
algorithm will then return ``failed'' for the gcd of ,
but will also return  as second output.
Exactly how this is implemented will depend on the system.
In our Maple implementation, when we compute inverses in  using
the extended Euclidean algorithm, if an inverse does not exist,
we generate a run-time error and return the non-trivial gcd
found as part of the error.
The calling routine may ``catch'' this error and process it.
In our Magma implementation, because Magma has no non-local goto
mechanism, we must use a different approach which we describe
in detail in the next section.

For efficiency reasons, we want to turn this into a modular algorithm.
If we run the modified Euclidean algorithm mod ,
using the same arguments as in lemma~\ref{finitep} one sees that for
all but finitely many  the result will be ``failed'' with
 mod  as a second output.
So we make the following modification to the modular GCD algorithm:
In addition to all the steps done before, we will also store the
second outputs of the modified Euclidean algorithm mod .
Each time the number of these second outputs reaches a certain threshold
(for example a Fibonacci number ) we combine them using Chinese remaindering,
apply rational reconstruction, and if rational reconstruction suceeds,
perform a trial division to see if we found a true factor  of .
To prevent that a prime , for which the second output is different
from  mod , can cause an infinite loop, we do not use
all available primes when computing  with Chinese remaindering; instead
we omit the first  primes, thus use only the last  primes.

\section{Implementation}
At the end of this section we describe two implementations of our
modular GCD algorithm, one in Maple 9 \cite{Maple} and one in Magma 2.10 \cite{Magma}.
We give timing comparisons for the two implementations to demonstrate
the effectiveness of our improvements and for comparison with the Euclidean algorithm.

To fix notation, recall that )
where  is algebraic over ,
and  is the minimal polynomial for  over .
To implement the the modular GCD algorithm, we start with input polynomials
over , reduce them modulo  a machine prime so that they are over  modulo ,
run the Euclidean algorithm retract them to be over  for application of the
Chinese remainder theorem, reconstruct the rational coefficients so the output
is over  and finally perform trial divisions over .





\subsection{A Data Structure for  and }
Our Maple and Magma implementations both use a {\em recursive
dense} representation for polynomials. This is the representation
advocated by Stoutemyer in \cite{David} as the best overall
representation for polynomials based on the his system Derive.
We choose this data representation for elements of  and for
polynomials in . That is we regard the inputs  and 
as polynomials in  and . 

In our Magma implementation, we are implicitly using this representation
as we construct  as a tower of univariate polynomial extensions over
. In Magma, univariate polynomials are represented as a vector
of coefficients, that is, a dense one-dimensional array of coefficients.
In our Maple implementation, we have implemented a recursive dense data type.
The datatype, implemented in Maple code, is being implemented in the Maple kernel.

We describe the Maple data type {\tt <poly>} using a BNF notation.
\begin{verbatim}
  <poly> ::= POLYNOMIAL( <ring>, <data> )
  <ring> ::= [ <char>, <vars>, <exts> ]
  <char> ::= <nonnegative integer>
  <vars> ::= vector(<variables>)
  <data> ::= <immediate integer> | <rational number> | vector(<data>)
  <exts> ::= vector(<data>)
\end{verbatim}

\noindent
The characteristic of the ring is encoded by \verb+<char>+
and \verb+<exts>+ is a vector of the minimal polynomials.
Thus the ring to which the polynomial belongs is encoded
explicitly in the data structure.  Since the ring information
is identical for polynomials in the same ring it is stored
once so that the cost of storing the ring information
is one word (a pointer) per polynomial.

The bottom of the data structure is a word of storage which is
either a pointer to a rational number or an immediate integer.
In Maple 9, on a 32 bit computer, immediate integers are signed
integers of 30 bits in length where one bit is used to distinguish
them from pointers.



In a recursive dense representation a zero coefficient at any level
in the data structure, except the bottom level, is represented by
the immediate integer 0 (or the nil pointer). This means that every
algorithm must treat 0 as a special case. This exceptional case does
not bother us because in the implementation of most operations, 0 is
a special case anyway. In the Maple examples below, vectors are
indicated by square brackets.

\medskip
\noindent
{\bf Example 1:} The representation of the polynomial
 in characteristic 0 and characteristic 3 is
\begin{verbatim}
  POLYNOMIAL( [0,[z],[]], [1,0,-10,0,1] )
  POLYNOMIAL( [3,[z],[]], [1,0,2,0,1] )
\end{verbatim}
The empty vector \verb+[]+ indicates that there are no extensions and the
data in both these examples is a vector of machine integers.
Allowing one word as a header word for the POLYNOMIAL structure and for
each vector, the storage requirement for both polynomials is 16 words.
Since the ring information can be shared between polynomials over the same
ring, a more accurate count is that 9 words are required. From
now on we count 1 word (a pointer) for the ring storage.

\medskip
\noindent {\bf Example 2:} The representation for the polynomial
 in  
and  is
\begin{verbatim}
  POLYNOMIAL([0, [x, z], []], [[5], [0, -3], [1]])
  POLYNOMIAL([0, [x, z], [[-2, 0, 1]]], [[5], [0, -3], [1]])
  POLYNOMIAL([3, [x, z], [[1, 0, 1]]], [[2], 0, [1]])
\end{verbatim}
\noindent
The storage requirement is 14, 14 and 11 words respectively.

\medskip
\noindent {\bf Example 3:} Even for moderately sparse polynomials,
the recursive dense data structure is surprisingly compact. Consider
the sparse polynomial  Our data structure for
this polynomial for  is
\begin{verbatim}
  POLYNOMIAL(R, [[[1,0,0,4], 0, 0, [3]], 0, 0, [[2]]]);
\end{verbatim}
\noindent This is 24 words.  In general it is  words. One of
the main sparse representations for polynomials that is used in
AXIOM is a linked list of pairs where each pair is a pointer to a
coefficient and a pointer to a monomial where the monomial  would be stored as an exponent vector .  Thus each
non-zero term of the polynomial requires  words of storage.
On our example this would be 35 words, allowing 3 words for the top
level of the data structure. On this example, the recursive dense
representation uses less storage for .

\medskip
\noindent
{\bf Example 4:} Multiple extensions are handled in the obvious way.
Consider the polynomial 
We show how to input this polynomial in two ways, first,
directly, using the {\tt rpoly} command which
converts from Maple's native sum-of-products
representation for formulae to the POLYNOMIAL data structure,
and secondly, by first creating the number field and
polynomial ring using the {\tt rring} command.
We then reduce the polynomial  modulo .
{
\begin{verbatim}
  > f := rpoly(x^2-u/3*x+v/2, [x,u,v], [u^2-2,v^2-3]);
                  2                          2       2
           f := (x  - 1/3 u x + 1/2 v) mod <u  - 2, v  - 3>
  > lprint(f);
    POLYNOMIAL([0, [x, u, v], [[[-2], 0, [1]], [-3, 0, 1]]],
    [[[0, 1/2]], [0, [-1/3]], [[1]]])
  > L := rring( [u,v], [u^2-2,v^2-3] );
            L := [0, [u, v], [[[-2], 0, [1]], [-3, 0, 1]]]

  > Lx := rring(L,x); # construct L[x] from L
          Lx := [0, [x, u, v], [[[-2], 0, [1]], [-3, 0, 1]]]

  > g := rpoly( x^2-u/3*x+v/2, Lx );
                  2                          2       2
           g := (x  - 1/3 u x + 1/2 v) mod <u  - 2, v  - 3>
  > h := phirpoly(g,5);
                                2            2       2
           h := (3 v + 3 u x + x ) mod <3 + u , 2 + v , 5>
\end{verbatim}
}

\medskip
\noindent An advantage of the recursive dense representation
is the following.  When we reduce mod , using the {\tt
phirpoly} comand above, we obtain a recursive structure where the
bottom level of the structure, representing polynomials in
 in the example, is a vector of machine integers.
This is the most efficient representation for arithmetic in .
This is important because this is where most of the computation will
occur when the Euclidean algorithm is executed modulo 
 \subsection{Trial Division}
Another bottleneck of the modular GCD algorithm is the trial divisions.
If  is the result of rational reconstruction then we must check
that  and  to show that .
Because these trial divisions can be expensive,
we have considered abandoning trial divisions altogether in favor of a
probabilistic result, that is, check that result of rational reconstruction
agrees, say, with the gcd modulo five additional primes instead of one.
However, in many applications where one computes gcd's, for example,
normalizing a rational function, one wants to compute
also the cofactors  and , hence,
the divisions cannot be avoided.

There are also situations where one cofactor is enough. If Trager's
factorization algorithm is used to factor a polynomial 
where , one computes  where  is
an irreducible polynomial over  and  is the norm of a
factor of . Since the degree of  is known to be  in advance, it is not hard to see that if the modular GCD
algorithm constructs a polynomial  of degree  and  then
 must also divide  and hence .
Since it is useful to compute the cofactor  in Trager's
algorithm, but not the cofactor , then the latter trial
division, which is usually the larger in degree, may be avoided.
This simple observation can make a significant improvement.

When dividing  and  by  over  using the classical
division algorithm, a very significant improvement can be obtained
if one avoids fractions as much as possible.  This idea of avoiding
fractions has been used to speed up many computations in computer
algebra. Notice that the leading coefficient of  in the
modular GCD algorithm is an integer.  If also , which is often the case, then the entire division algorithm
can be completed using only integer arithmetic. If  for
some  then the division algorithm can still be modified to avoid
fractions. We show how to do this for univariate polynomials with
one field extension with minimal polynomial .
\\

\noindent
{\bf Algorithm Fraction Free Long Division.} \\
{\bf Input:}  :  , and
       . \\
{\bf Output:}  if ; ``failed'' otherwise.
\begin{itemize}
\item[]    Set   and .
\vspace*{-2mm}
\item[]    Set  and 
\vspace*{-2mm}
\item[]    Set  and 
\vspace*{-2mm}
\item[]    Set  and . Remark: 
\vspace*{-2mm}
\item[]    Set , , and .
\vspace*{-2mm}
\item[]    While  and  do
\vspace*{-2mm}
\begin{itemize}
\item[]        Set .  Remark: .
\vspace*{-1mm}
\item[]        Set 
\vspace*{-1mm}
\item[]        Set .
\vspace*{-1mm}
\item[]        Set 
\vspace*{-1mm}
\item[]        Set .
\vspace*{-1mm}
\item[]        Set .
\vspace*{-1mm}
\item[]        Set .
\vspace*{-1mm}
\item[]        While  and  do
\vspace*{-0mm}
\begin{itemize}
\item[]            Set .  Remark: .
\vspace*{-0mm}
\item[]            Set 
\vspace*{-0mm}
\item[]            Set 
\vspace*{-0mm}
\item[*]            Set .
\vspace*{-0mm}
\item[]            Set  and 
\vspace*{-0mm}
\end{itemize}
\item[]        Set .
\vspace*{-1mm}
\end{itemize}
\item[]    If  then output ``failed''.
\vspace*{-2mm}
\item[]
Set  and output .
\end{itemize}

\noindent
The algorithm first makes the inputs  and  primitive over .
We claim that each time round the outer loop and also each time
round the inner loop the following invariant holds:
 where  and  has
integer coefficients.  From this the correctness of the
algorithm follows easily.
The outer loop reduces the degree of the remainder  in .
In the outer loop we multiply  by the smallest possible integer
so that , a polynomial in , will be exactly
divisible by the integer 
The inner loop then reduces the remainder  modulo .
In the inner loop we multiply  by the smallest integer
so that , a polynomial in , will be divisible by
the integer .
The scalar , an integer, keeps track of the integer factors
of  and , respectively, that  was multiplied
by so that the terms of quotient  may be correctly computed.

\medskip
\noindent
{\bf Remark:} The algorithm works over any integral domain  for which
GCDs exist.  That is, replacing  by  and  by the quotient
field  generalizes the algorithm to work for inputs
 and .  One application of this is
for  which arises when computing a gcd over an algebraic
function field in a single parameter  using a modular GCD algorithm.
There for each prime  used, the algorithm makes trial divisions
in  modulo .

 

\subsection{Maple Implementation}
Program {\tt NGCD}, our Maple implementation of our modular GCD
algorithm uses the recursive dense polynomial data structure
described in section 4.1. Here we demonstrate it's usage on three
problems. The first gcd problem is in  where   We create the field as  create the polynomial ring , convert the two given
polynomials  and  below from Maple's native sum of product
representation for polynomials to the recursive dense representation
described in section 4.1, and then compute and display their gcd
using the command {\tt NGCD.}  This command also prints some
diagnostic information.
{ \small
\begin{verbatim}
> read recden; read NGCD; read PGCD;
> K := rring([a,b],[a^2-2,b^2-3]);
          K := [0, [a, b], [[[-2], 0, [1]], [-3, 0, 1]]]
> Kx := rring(K,x):
> f1 := rpoly(x^2+(a*b-a-1)*x-a*b-2*b,Kx):
> f2 := rpoly(x^2+(a*b-4*a+1)*x+a*b-8*b,Kx):
> NGCD(f1,f2);
  NGCD: GCD in Q[a, b][x] mod <b^2-3, a^2-2>
   NGCD: Prime 1 = 46273
   NGCD: Prime 2 = 46271
  NGCD: Trial divisions over Z starting after 2 primes
                                  2       2
                  (a b + x) mod <b  - 3, a  - 2>
\end{verbatim}
}

\noindent We now demonstrate our implementation on two gcd problems
over  which is not a field. In the
first problem an error is generated. The error message shows the
zero divisor found in characteristic 0, namely,  and the
corresponding extension polynomial  that it divides.


{ \small
\begin{verbatim}
> L := rring(K,c,c^2-6):
> Lx := rring(L,x);
     [0, [x, c, b, a], [[[[-6]], 0, [[1]]], [[-3], 0, [1]], [-2, 0, 1]]]
> f1 := rpoly(x^2+a*b*x+1,Lx):
> f2 := rpoly((c-a*b)*x+1,Lx):
> NGCD(f1,f2);
  NGCD: GCD in Q[c, b, a][x] mod <a^2-2, b^2-3, c^2-6>
   NGCD: Prime 1 = 46273
   NGCD: fail prime 46273
  Error, (in NGCD) zero divisor found, c^2-6, c-a*b
\end{verbatim}
}

\noindent The second example shows a gcd computation of two
polynomials in  succeeding even though  is not a field.
Note that our {\tt NGCD} returns the primitive associate of the
monic gcd, that is, 
{ \small
\begin{verbatim}
> P := rring(L,[x,y,z]): # create L[x,y,z]
> f1 := rpoly((2*x+c*y+a*b+2*z)*(x-a*y*z-c)^2,P):
> f2 := rpoly((2*x+c*y+a*b+2*z)*(y-c*x*z-b)^2,P):
> NGCD(f1,f2);
  NGCD: GCD in Q[c, b, a][x, y, z] mod <-2+a^2, -3+b^2, c^2-6>
   NGCD: Prime 1 = 46273
   NGCD: Prime 2 = 46271
  NGCD: Trial divisions over Q starting after 2 primes
                                         2            2        2
           (a b + 2 z + c y + 2 x) mod <c  - 6, -3 + b , -2 + a >
\end{verbatim}
}



 

\subsection{Magma Implementation}



Here we give details and examples of a Magma implementation of our
modular GCD algorithm for polynomials over a number fields. The
algorithm cannot, in fact, be implemented in Magma 2.9. We will
describe modifications made by Allan Steel to Magma 2.10 that permit
our algorithm to be implemented.

In Magma, before one may compute with ,  a number
field, the user must explicitly construct the number field  and
the polynomial ring . In the following Magma
session\footnote{Lines beginning with the  character are input
lines and other lines are Magma output} we construct  input
the polynomial  compute  construct  using the {\tt NumberField}
constructor, and then compute .

{ \small
\begin{verbatim}
  > Q := RationalField();
  > P<z> := PolynomialRing(Q); // construct Q[z]
  > m := z^2-2;
  > m^2; // compute and display m^2
  z^4 - 4*z^2 + 4
  > K<a> := NumberField(m);
  > a^3;
  2*a
\end{verbatim}
}


\noindent Number fields may also be constructed with the quotient
ring constructor {\tt quo}. Our modular GCD algorithm supports both.
Magma users are more likely to use {\tt NumberField} because the
Magma library for it is extensive. The {\tt NumberField} constructor
requires, naturally, that minimial polynomials are irreducible
whereas the quotient ring constructor does not. As an example we
construct the number field  and the ring
 using both approaches.

{ \small
\begin{verbatim}
  > P<v> := PolynomialRing(K);  K<b> := NumberField(v^2-3);
  > a^3/b^3; // computes sqrt(2)^3/sqrt(3)^3
  2/9*a*b
  > R<w> := PolynomialRing(K);
  > L<c> := NumberField(w^2-6);
                       ^
  Runtime error in 'NumberField': Argument 1 is not irreducible
\end{verbatim}
\begin{verbatim}
  // using the quotient ring constructor ...
  > P<u> := PolynomialRing(Q);  K<a> := quo<P|u^2-2>;
  > P<v> := PolynomialRing(K);  K<b> := quo<P|v^2-3>;
  > R<w> := PolynomialRing(K);  L<c> := quo<R|w^2-6>;
  > c^3*a^3/b^3;
  4/3*a*b*c
\end{verbatim}
}

\noindent
We create two polynomials  and  in  and
compute their gcd.  First we use the built-in {\tt Gcd} command
which uses the ordinary Euclidean algorithm and then we use {\tt modgcdA},
our modular GCD algorithm which prints the primes used (30 bit primes).

{ \small
\begin{verbatim}
  > P<x> := PolynomialRing(K);
  > f1 := x^2+(a*b-a-1)*x-a*b-2*b;
  > f2 := x^2+(a*b-4*a+1)*x+a*b-8*b;
  > Gcd(f1,f2);
  x + a*b
  > modgcdA(f1,f2);
  prime=1073741789
  prime=1073741783
  x + a*b
\end{verbatim}
}

\noindent
To implemement our modular GCD algorithm we need to compute over  modulo
a prime .  In our example this means we need to compute over the
finite ring .
We may construct this ring in Magma as a composition of univariate
quotients using the {\tt quo} constructor.  Below we do this for  and
then attempt to compute the 
using Magma's {\tt Gcd} command.

{ \small
\begin{verbatim}
  > Z7 := GaloisField(7);
  > R7<z> := PolynomialRing(Z7);  K7<a> := quo<R7|z^2-2>;
  > R7<y> := PolynomialRing(K7);  K7<b> := quo<R7|y^2-3>;
  > P7<x> := PolynomialRing(K7);
  > f1 := x^2+(a*b-a-1)*x-a*b-2*b;
  > f2 := x^2+(a*b-4*a+1)*x+a*b-8*b;
  > Gcd(f1,f2);
       ^
  Runtime error in 'Gcd': Algorithm is not available for this kind
  of coefficient ring
\end{verbatim}
}

\noindent
The error arises because Magma refuses to execute the Euclidean
algorithm here because  is not a field.  So we attempt to
implement the (monic) Euclidean algorithm (from section 2) directly.

{ \small
\begin{verbatim}
 > r1 := f1 mod f2; r1; // f2 is already monic
 (3*a + 5)*x + (5*a + 6)*b
 > u := LeadingCoefficient(r1);
 > r1 := u^(-1)*r1; // make r1 monic
          ^
 Runtime error in '^': Argument is not invertible
\end{verbatim}
}

\noindent When a zero divisor is encountered, an error occurs, which
is expected because  is, in fact, a fail prime. For the modular
GCD algorithm we would like to ``catch'' this error, compute the
zero divisor over , and move on to the next prime, which is
what we do in our Maple implementation.  Unfortunately there is no
non-local goto facility in Magma.  A consequence of this is that our
modular GCD algorithm cannot be implemented in Magma 2.9 without
programming our own polynomial arithmetic operations from scratch.
In Magma 2.10, Allan Steel has implemented {\tt
IsInvertible}\footnote{Because the implementation of IsInvertible
uses the extended Euclidean algorithm, it may output false even
though the input is invertible in the ring.} for rings in Magma, in
particular for quotient rings, so that we can detect a zero divisor
before dividing by it. For example:

{ \small
\begin{verbatim}
  > IsInvertible(3*a+5);
  false
  > IsInvertible(3*a+4);
  true 5*a + 5
\end{verbatim}
}

\noindent This enables the following implementation of the Euclidean
algorithm for  where  is a univariate quotient
ring over a field, to detect a zero divisor, and if a zero divisor
occurs, to compute it by calling the same algorithm recursively. Our
implementation outputs a pair of values. The output  means
the algorithm succeeded and  is the GCD() in . The
output  means the algorithm failed and  is the zero
divisor in  that the Euclidean algorithm encountered.

{ \small
\begin{verbatim}
  > forward GetZeroDivisor;
  > EuclideanAlgorithm := function(f1,f2)
  >    // Input f1,f2 in R[x], R a univariate quotient ring
  >    while Degree(f2) ge 0 do
  >       u := LeadingCoefficient(f2);
  >       t,i := IsInvertible(u);
  >       if not t then return false, GetZeroDivisor(u); end if;
  >       f2 := i*f2; // make f2 monic
  >       r := f1 mod f2; f1 := f2; f2 := r;
  >    end while;
  >    u := LeadingCoefficient(f1);
  >    t,i := IsInvertible(u);
  >    if not t then return false, GetZeroDivisor(u); end if;
  >    return true, i*f1;
  > end function;
\end{verbatim}
\begin{verbatim}
  > GetZeroDivisor := function(u)
  >    K := Parent(u);  // K = R[z]/<m>, m in R[z]
  >    m := Modulus(K); // m is in R[z]
  >    P := Parent(m);  // P = R[z]
  >    f := P!u; // this coerces u in K to R[z]
  >    t,g := EuclideanAlgorithm(m,f);
  >    if not t then return g; end if;
  >    return K!g; // coerces g in R[z] back to K
  > end function;
\end{verbatim}
}


\noindent
The example below shows the Euclidean algorithm hitting
the zero divisor  in the subring 
where note .

{ \small
\begin{verbatim}
  > EuclideanAlgorithm(f1,f2);
  false a + 4
\end{verbatim}
}

\noindent
We now demonstrate our implementation on the two gcd problems
from the previous section, namely, over  which
is not a field.  In the Magma session below we construct 
as  where , , and .
The first gcd problem in  is for , 
where the  is not invertible.
Our algorithm correctly computes and outputs  a divisor
of , the minimal polynomial for .

{ \small
\begin{verbatim}
  > P<x> := PolynomialRing(L);
  > f1 := x^2+a*b*x+1;
  > f2 := (c-a*b)*x+1;
  > modgcdA(f1,f2);
  prime=1073741789
  prime failed
  hit zero divisor w - a*b
\end{verbatim}
}

\noindent
The second gcd problem is a multivariate gcd problem in .
Note that we convert the flat multivariate polynomial representation used for input
to a recursive univariate tower  to improve
the efficiency of the modular GCD algorithm.

{ \small
\begin{verbatim}
  > R<x,y,z> := PolynomialRing(L,3);
  > f1 := (2*x+c*y+a*b+2*z)*(x-a*y*z-c)^2;
  > f2 := (2*x+c*y+a*b+2*z)*(y-c*x*z-b)^2;
  > modgcdA(f1,f2);
  prime=1073741789
  prime=1073741783
  x + 1/2*c*y + z + 1/2*a*b
\end{verbatim}
}

 


\subsection{Triangular Sets}

In the following subsection we will make a timing comparison
comparing our modular GCD algorithm with the monic Euclidean
algorithm on polynomials in . The bottleneck of the monic
Euclidean algorithm is the many integer gcds that are computed to
add, subtract and multiply the fractions that appear. Arithmetic
with fractions can be reduced by using -fraction-free
algorithms for arithmetic in  and could be eliminated entirely if
one uses a -fraction-free GCD algorithm for . In order to
properly demonstrate the superiority of the modular GCD algorithm we
want to include in our timing comparison an implementation of the
best possible non-modular GCD algorithm for  The
fraction-free algorithm of Maza and Rioboo \cite{Maza} for computing
a gcd over a triangular set applies to our problem. We modify the
ideas of Maza and Rioboo to construct a {\it primitive}
-fraction-free GCD algorithm for  which, based on our
experiments, is clearly the fastest of the non-modular algorithms
for gcds in .






\subsubsection*{Triangular sets}

For  let   and
  and
let ,  and 
It is clear that  is isomorphic to  and thus a
gcd computation in  is equivalent to a gcd computation in .
The set of generators  for  is called a {\it triangular set}
because  is a polynomial in  only for .
Such sets arise naturally in elimination algorithms and in that context it will
often be the case that one or more of the  are reducible over 
and thus  is not a field in general.



In \cite{Maza}, Maza and Rioboo show how to compute  modulo  by modifying the
subresultant gcd algorithm for  to be fraction-free, that is, to work
inside the ring  Their algorithm outputs either
an associate of the gcd of  or it outputs a non-trivial factor
of some   Their algorithm works if  is replaced by any integral
domain where gcds exist.  In the context of polynomial systems
this would apply if there were parameters in the system.
For simplicity of exposition, let us suppose that for ,
 is monic over , that is, 
so that reduction modulo  does not introduce fractions.
And let us assume for the moment that  is a field.
We recall the notion of pseudo division in 

\begin{definition}
Let  be non-zero, 
 and .
The {\it pseudo-remainder} and {\it pseudo-quotient} of  divided by 
are the polynomials  and , respectively, satisfying
 and  or .
\end{definition}
The key observation about pseudo-division is that if  and  have
no fractions on input, that is,  and the
usual division algorithm is applied to  divided by , no fractions
appear in the division algorithm and .

Maza and Rioboo define the notion of a quasi-inverse for commutative
rings with identity.  We specialize the definition to 
\begin{definition}
Let   Then  is a
{\it quasi-inverse} of  if  and 
for some integer 
\end{definition}
\noindent
{\bf Example:} Let  where  is monic and
irreducible with .  If  then there exist
 such that  where  is the resultant
of  and .  Thus  is a quasi-inverse of  in .
The polynomials  and resultant  can be computed without any fractions
using the extended subresultant algorithm.

\bigskip
\noindent
{\bf Remarks:} The definition for quasi-inverse is unique up to multiplication
by a non-zero integer and an algorithm for computing a quasi-inverse of  may
or may not return the quasi-inverse of  with smallest positive .
Notice that in the case where  if  is a quasi-inverse
for  then  is a quasi-inverse for 

\bigskip
Let us assume for now that we know how to compute a quasi-inverse of .
In the monic Euclidean algorithm for  (see section 2) we make  monic,
that is, we multiply  by  where .  To obtain
a -fraction-free algorithm in , Maza and Rioboo multiply  by a
quasi-inverse of  before pseudo-division by .
Suppose  and let  be a quasi-inverse of .
Then  and  thus
quantity  in the pseudo-division will be an integer.
We obtain the following -fraction-free algorithm for computing an
associate of the monic gcd  of 

\bigskip
\noindent
\hspace*{5mm} 1  Set , . \\
\hspace*{5mm} 2  Compute  s.t.  for  where  and set  \\
\hspace*{5mm} 3  Set  \\
\hspace*{5mm} 4  Compute  s.t.  for  where  and set  \\
\hspace*{5mm} 5  \hspace*{5mm} Let  be the pseudo-remainder of  divided  mod . \\
\hspace*{5mm} 6  \hspace*{5mm} If  then output . \\
\hspace*{5mm} 7  \hspace*{5mm} Set  and  and go to step 4.

\bigskip
\noindent Although this algorithm is -fraction-free the size of
the integer coefficients blows up exponentially.  This is caused by
multiplication by the integer  in pseudo-division and also by
multiplication by  when multiplying by the quasi-inverse 
This blowup can be reduced either by dividing out by known integer
factors, which is the approach that Maza and Riboo take in
\cite{Maza} in modifying the subresultant GCD algorithm, or by
making  and  primitive, that is, dividing out by the
gcd of their integer coefficients. Which approach is better depends
on the relative cost of computing gcds verses multiplication and
division in the base coefficient domain which in our case is .
We recall the notion of integer primitive part and integer content
for .

\begin{definition}
Let  with .
The integer content of  denoted  is the gcd of the
integer coefficients of  when  is viewed as a polynomial in .
The -primitive part of  denoted  is 
Thus we have  and .
\end{definition}
After computing  in step 4 we set  and
also after computing  in step 5 we set .
The resulting GCD algorithm that we obtain is a {\em primitive -fraction-free}
algorithm.

It remains to describe how we compute a quasi-inverse of 
One way to do this would be to compute  using the extended Euclidean algorithm
applied to  and  in  and then clear fractions.
In the same way we have just described how to modify the monic Euclidean algorithm
for computing a gcd in  where 
to be -fraction-free, Maza and Rioboo modify the extended monic Euclidean
algorithm in  to be fraction-free by using pseudo-division
and multiplication by quasi-inverses in .
Again, an eponential blow up occurs which can be reduced by dividing out by
known integer factors or it can be minimized by dividing out by integer contents.
To fix the details of this algorithm we present our Maple code for computing
the quasi-inverse of  and integer  using our Maple data structure
from the previous section.

{ \small
\begin{verbatim}
  quasiInverse := proc(x) local Q,K,P,m,u,r0,r1,t0,t1,i,c,den,g,pr,mu,pq;
  # Input  x in K = K_{n-1}[z]/<m(z)>
  # Output v in K and r in Z^+ s.t.  v x = r and r = den(1/x)
    Q := [0,[],[]];  # field of rational numbers
    K := getring(x);
    if K=Q then u := rpoly(x); RETURN( rpoly(denom(u),Q), numer(u) ) fi;
    m := getalgext(K);    # m is a polynomial in z
    u := liftrpoly(x);    # u is a polynomial in z
    u := ipprpoly(u,'c'); # x = c u and u for u primitive over Z
    P := getring(m);      # P = K[i-1][z]
    r0,r1,t0,t1 := m,u,rpoly(0,P),rpoly(1,P);
    while degrpoly(r1) > 0 do
        (i,den) := quasiInverse(lcrpoly(r1));
        (r1,t1) := mulrpoly(i,r1),mulrpoly(i,t1);
        g := igcd(icontrpoly(r1), icontrpoly(t1));
        (r1,t1) := iquorpoly(r1,g),iquorpoly(t1,g);
        pr := ippremrpoly(r0,r1,'mu','pq');
        if iszerorpoly(pr) then ERROR( "inverse does not exist", [r1,P] ) fi;
        r0,r1,t0,t1 := r1,pr,t1,subrpoly(mulrpoly(mu,t0),mulrpoly(pq,t1));
        g := igcd(icontrpoly(r1), icontrpoly(t1));
        (r1,t1) := iquorpoly(r1,g),iquorpoly(t1,g);
    end while;
    (v,r) := quasiInverse(lcrpoly(r1),args[2..nargs]);
    t1 := mulrpoly(v,t1); g := igcd(icontrpoly(t1),r);
    t1 := scarpoly(denom(c),iquorpoly(t1,g));
    RETURN( subsop(1=K,t1), numer(c)*r/g );
  end;
\end{verbatim}
}
We remark that at the start of the loop we have  for
some  in  (and some  which is not computed).
Thus when the loop exits we have  for a constant
polynomial .
We multiply  by  the quasi-inverse of  so that we
have  for some .
But multplication by  introduces an integer multiplier and since this
algorithm algorithm is recursive it is critical that we clear it here.
Thus we compute  the gcd of  and the coefficients of  and divide
through by .

We can improve the performance of this algorithm further by
modifying pseudo-division as follows; instead of multiplying  by 
and then performing a normal long division, we modify the division algorithm to
multiply the current pseudo remainder  by the smallest integer s.t. the
leading coefficient of the divisor  will divide the leading coefficient of  exactly.
We call this primitive pseudo-division.
This is what the subroutine {\tt ippremrpoly} does.
This improvement gives us typically another 30\% improvement in quasi-inverse computation.

Finally, what if  is not a field?
Suppose we call the algorithm with 
If the algorithm returns normally, it outputs  and 
such that .  Then  is invertible for .
Suppose an error occurs and the algorithm outputs .
Then  for some  is a non-trivial
factor of  and thus we have encountered a zero divisor


Of the two, Maza and Rioboo's algorithm and our primitive
-fraction-free algorithm which is derived from Maza and
Rioboo's algorithm, ours appears to be much faster.  In
\cite{MonvHoeij}, we showed that there is a cubic growth in the size
of the integers in Maza and Rioboo's algorithm whereas the growth in
the primitive -fraction-free algorithm is linear.
 

\subsection{Timing Results}

In this section we compare the Magma and Maple
implementations of our modular GCD algorithm with the default
Maple and Magma system GCD implementations for a sequence of
univariate gcd problems over a number field  of degree 24.
The number field  used in our test
problems is defined by  and
.  The gcd problems are constructed as follows.
Let

\vspace*{-5mm}

\vspace*{-5mm}

For  the input polynomials  and 
are defined as follows:  and 

Thus we consider a sequence of gcd problems over  where the degree of
the input polynomials is fixed at  and the ,
is a polynomial of degree .
The reason for this choice of gcd problems, where
the degree of the gcd is increasing relative to the
degree of the inputs, is that it includes a range of types of gcd problem
that occur in practice.  In comparison with the Euclidean algorithm,
we expect our modular GCD algorithm to perform best for small  and
worst for large .

The following comparison is made between Maple 9 and Magma 2.10 on
an AMD Opteron running at 2.0 GHz for , that is, the degree of
the input polynomials  and  is 20. All timings are in CPU
seconds. The timings in columns 1 and 4 are for our Maple and Magma
implementations of our modular Gcd algorithm where the number of
primes required for reconstruction is indicated in parens. 
The Maple timings in column 2 are for the monic Euclidean algorithm.
The Maple timings in column 3 are for the primitive fraction free GCD algorithm.
The Magma timings in columns 5 and 6 are for the monic Euclidean
algorithm over  where the elements of  are created using
Magma's NumberField constructor (column 5) and Magma's quotient
field constructor (column 6).

\begin{table}[htb]
\begin{center}
\begin{tabular}{r | l r r | r r r |}
   & Maple & Rel 9 &     & Magma & 2.10  & \\
 &  1       &   2         &  3     &    4       &   5   &   6   \\ \hline
 0  & 0.27 (1) &   NA        & NA     &  0.06 (1)  & 200.4 &    NA \\
 1  & 1.3  (3) &   NA        & NA     &  0.09 (2)  & 151.6 &    NA \\
 2  & 1.5  (4) &   NA        & NA     &  0.12 (3)  & 106.1 &    NA \\
 3  & 2.4  (6) & 367.3       & NA     &  0.16 (4)  &  66.1 &    NA \\
 4  & 3.1  (9) & 193.7       & NA     &  0.20 (5)  &  37.8 &    NA \\
 5  & 3.4 (11) &  90.0       & NA     &  0.21 (6)  &  18.3 & 808.5 \\
 6  & 3.4 (13) &  37.7       & NA     &  0.20 (7)  &   7.3 & 282.4 \\
 7  & 3.1 (15) &  13.0       & 176.2  &  0.19 (8)  &   2.1 &  73.7 \\
 8  & 2.4 (17) &   3.5       &  39.5  &  0.19 (10) &   0.4 &  12.4 \\
 9  & 1.6 (19) &   0.8       &   2.0  &  0.14 (11) &   0.1 &   1.1 \\
10  & 1.0 (22) &   0.1       &   0.0  &  0.11 (12) &   0.0 &   0.0 \\ \hline
\end{tabular}
\caption{NA means not attempted}
\end{center}
\end{table}

\subsubsection*{Remarks}
\begin{enumerate}
\item The number of primes (indicated in parens) for
  the modular algorithm is more in Maple than in Magma.
  This is because Maple 9 uses 15.5 bit primes for portability \cite{Disco}
  and Magma 2.10 uses 30 bit primes \cite{Steel}.

\item Even allowing for the fact that Magma uses fewer primes than
  Maple, the Magma implementation is considerably faster.
  The Maple implementation is using compiled code for arithmetic
  in ,  and  but not for rational reconstruction,
  nor arithmetic in  and 
  wheres Magma does.  Thus less time is spent in the Magma interpreter.

\item The times for both implementations increase to a
  maximum at  then decrease even though the number of primes
  increases linearly.  The reason is that the cost of the modular gcds,
  which is  coefficient operations,
  is decreasing {\em quadratically} to  as  increases to ,
  and the cost of the trial divisions, which is 
  coefficient operations in , is also decreasing after 
  {\em quadratically} to .

\item The reason for the huge difference in times between columns
  5 and 6 is because of the different representation of field elements
  being used and the different algorithm for inverting field elements.
  In column 5 we used the {\tt NumberField} constructor to build 
  which represents field elements as as polynomials over 
  {\em with denominators factored out}.  In column 6 we have used
  the quotient ring constructor to build  which doesn't.
  Thus {\tt NumberField} avoids arithmetic with fractions.
  The second reason is that {\tt NumberField} uses a modular
  algorithm to compute inverses in  which is where, by experiment,
  most of the time is spent on this data.

\item The data clearly shows the superiority of the modular GCD algorithm.
  And yet the non-modular timings are still impressive.  This is partly because
  Maple 9 and Magma 2.10 both have asymptotically fast integer arithmetic.
However, the data also shows that the Euclidean algorithm is faster
  than the modular GCD algorithm when  is large.
  The efficiency of the modular GCD algorithm can be improved when  is large
  if we reconstruct also  the smaller cofactor.
  We will show timings for this next.
\end{enumerate}



The second set of data below is for the same gcd problem set but
with  instead of . The four sets of timings, all in CPU
seconds, in columns 0, 1, 3, and 5 are for the primitive
-fraction-free algorithm and for three versions of our Maple
implementation of the modular GCD algorithm. In column 1 we are
using Wang's rational reconstruction algorithm (see \cite{Wang81}).
In column 3 we are instead using Monagan's maximal quotient rational
reconstruction algorithm (MQRR) from \cite{MQRR}. In column 5 we
also reconstruct the smaller cofactor, stopping when rational
recocnstruction succeeds on the cofactor or the gcd. In columns 2, 4
and 6, the first number in parens is the number of (good) primes
that the modular GCD algorithm and second number indicates the time
spent in trial division.

\begin{table}[htb]
\begin{center}
\begin{tabular}{r r | r r | r r | r r}
& 0    &    1  &  2         &    3   &  4         &    5   & 6    \\ \hline
0& -     & 0.659 &(1, 0\%)  &  0.669 &(1, 0\%)   & 0.660 & (1, 0\%)  \\
1& -     & 1.631 &(2, 17\%) &  1.621 &(2, 17\%)  & 1.599 &(2, 16\%)  \\
2& -     & 2.679 &(3, 25\%) &  2.681 &(3, 25\%)  & 2.710 &(3, 26\%)  \\
3& -     & 4.529 &(5, 29\%) &  3.860 &(4, 33\%)  & 3.860 &(4, 34\%)  \\
4& -     & 6.859 &(8, 27\%) &  5.600 &(6, 33\%)  & 5.689 &(6, 34\%)  \\
5& -     & 7.910 &(10, 24\%)&  6.590 &(7, 37\%)  & 7.500 &(7, 33\%)  \\
6& -     & 10.32 &(12, 28\%)&  7.350 &(8, 39\%)  & 8.449 &(8, 33\%)  \\
7& -     & 11.33 &(14, 28\%)&  7.820 &(9, 38\%)  & 9.140 &(9, 33\%)  \\
8& -     & 11.68 &(16, 27\%)&  8.000 &(10, 37\%) & 9.350 &(10, 32\%)  \\
9&  268. & 11.71 &(18, 25\%)&  7.809 &(11, 36\%) & 8.119 &(9*, 34\%)  \\
10& 126. & 11.67 &(21, 23\%)&  7.430 &(12, 33\%) & 6.659 &(8*, 37\%)  \\
11& 53.2 & 10.19 &(22, 21\%)&  6.559 &(13, 30\%) & 4.530 &(6*, 43\%)  \\
12& 19.1.& 8.840 &(25, 17\%)&  5.539 &(14, 25\%) & 3.030 &(5*, 44\%)  \\
13& 5.49.& 9.170 &(27, 8\%) &  4.170 &(15, 17\%) & 1.470 &(3*, 52\%)  \\
14& 1.21 & 4.120 &(29, 6\%) &  3.310 &(17, 8\%)  & 0.580 &(2*, 52\%)  \\
15& 0.14 & 2.030 &(31, 0\%) &  2.259 &(18, 0\%)  & 0.149 &(2*, 34\%)  \\ \hline
\end{tabular}
\caption{(*) means cofactor reconstructed and (-) not attempted.}
\end{center}
\end{table}



 
\section{Conclusion and Remaining Problems}
Let  be a number field of degree  presented with  field extensions.
Let  and let  be the monic gcd of  and .
We have presented a modular GCD algorithm which computes  without
converting to a single field extension and without computing discriminants (Thereom 1).
Our goal was to design an algorithm with a complexity
that is as good as classical polynomial multiplication and
division in  Recall that  denotes the magnitude of the
largest integer appearing in the rational coefficients of 
Let  and 
Our algorithm incrementally reconstructs  from its image modulo  machine
primes such that  is proportional to 
It uses rational reconstruction.
The reason for using an incremental approach with trial division
rather than using a bound is that there are no good bounds for 
in particular, when  is much smaller than .

Our implementations of the algorithm in Maple and Magma demonstrate its
effectiveness compared with non-modular algorithms.
Both implementations use a recursive dense representation
for field elements and for polynomial variables to eliminate data
structure overhead in the algorithm which otherwise may
ruin a modular implementation.

Our Maple implementation was installed in Maple 10 in 2005
as part of the {\tt Algebraic} package by J\"urgen Gerhard of Maplesoft.
It may be accessed using the Maple command
{\tt with(Algebraic:-RecursiveDensePolynomials);}
We made one further optimization that we found useful.
Many applications in practice involve algebraic numbers which are
simple square roots and cube roots such as  and .
In such cases it is advantageous to pick primes for which the 
the minimal polynomial  for  splits into distinct 
linear factors modulo .  For if  in 
then we may compute the gcd of  and 
for each  and interpolate .  
This embeds  in  and eliminates a field extension.
In practice, it eliminates computations with polynomials in  of
low degree which have a relatively high data structure overhead.
In our software we do this if  where
there is a reasonable probability of finding primes that split .



Write  and 
where  is the degree of the minimal polynomial of .
If the degree  of  over  is high then the use of fast
multiplication techniques can speed up the arithmetic in  mod .
In particular, if  we can multiply and divide
in  in 
To multiply polynomials in  where 
rapidly, first multiply them as bivariate polynomials in  then reduce
the coefficients modulo  using asymptotic fast division.
To multiply the bivariate polynomials rapidly, first convert them, in linear
time to univariate polynomials using the subtitution .
This large multiplication in  is in .
Now a fast multiplication in  enables a fast GCD computation
in  in .
Thus for  we have sketched out an asymptotically modular GCD
algorithm which runs in  time
with high probability.

If  asymptotically fast multiplication and division in  will
be less effective than if .  This suggests that we first convert
to a single field extension.  Using a primitive element in characteristic 0
should be avoided because it can cause coefficient growth.
But in characteristic  this is not a concern.
Let 
be a primitive element.  Using linear algebra one can compute the
minimal polynomial  for  and also the
representation for all  power products 
in  in O() arithmetic operations in 
and then make the substitutions for the power products in 
and  in O() arithmetic operations in .
If  the degree of  and  is high enough, the
time saved by the fast multiplication techniques in the Euclidean
algorithm mod  will be larger than the cost of the
conversion to a single extension mod .
However, if we want to do this then we really need also
to think about how to convert to a single field extension faster
than   We do not know how to do this.
 
\subsection*{Acknowledgment}
We acknowledge John Cannon and the Magma group for hosting
in Sydney in 2003 and Allan Steel for helping
us with our Magma implementation.
We also acknowlege Mark Moreno Maza for providing details of his implementation
of the fraction free algorithm in \cite{Maza}.

\begin{thebibliography}{}

\bibitem{Abbott} J.~A. Abbott, R.~J. Bradford, J.~H. Davenport (1986).
The Bath Algebraic Number Package,
{\it Proceedings of SYMSAC '86}, ACM press, pp.~250--253.

\bibitem{Bradford} R.~J. Bradford (1989).
Some Results on the Defect,
{\it Proceedings of ISSAC '89}, ACM press, pp.~129--135.

\bibitem{Brown} W.~S. Brown (1971).
On Euclid's Algorithm and the Computation of
Polynomial Greatest Common Divisors,
{\it J. ACM} {\bf 18}, pp.~476--504.

\bibitem{Magma} J.~J.~Cannon (2003).
{\it Magma Handbook}, \\
http://magma.maths.usyd.edu.au/magma/htmlhelp/MAGMA.htm

\bibitem{Collins} G.~E.~Collins and M.~J.~Encarnacion (1995).
Efficient Rational Number Reconstruction.
{\it J. Symbolic Computation} {\bf 20}, pp.~287--297.

\bibitem{Encarnacion}  M.~J. Encarnacion (1995).
Computing GCDs of Polynomials over Algebraic Number Fields,
{\it J. Symbolic Computation} {\bf 20}, pp.~299--313.

\bibitem{Gathen} J.~von zur Gathen and J.~Gerhard (1999).
{\it Modern Computer Algebra}.  University of Cambridge Press.

\bibitem{GMP}
The GNU Multiple Precision Arithmetic Library.
Copyright, Free Software Foundation, Inc. (2002).
{\tt http://www.gnu.org/software/gmp/gmp.html}

\bibitem{Hecke} E.~Hecke (1981).
Lectures on the Theory of Algebraic Numbers,
{\it Springer Graduate Texts in Mathematics} {\bf 77}.


\bibitem{Knuth} D. E. Knuth (1998).
{\it The Art of Computer Programming: Volume 2 Seminumerical Algorithms
Third Edition}, Addison Wesley, section 4.5.3.

\bibitem{Langemyr}  L.~Langemyr, S. McCallum (1989).
The Computation of Polynomial GCD's over an Algebraic Number Field,
{\it J. Symbolic Computation} {\bf 8}, pp.~429--448.

\bibitem{AAECC} L.~Langemyr (1991).
An Asymptotically Fast Probabilistic Algorithm for Computing
Polynomial GCD's over an Algebraic Number Field.
{\it Proc. of AAECC '90}, Springer-Verlag LNCS {\bf 508}, pp.~222--233.

\bibitem{Lazard} D.~Lazard (1992).
Solving Zero-dimensional Algebraic Systems.
{\it J. Symbolic Comp.} {\bf 13}, 117--131.

\bibitem{Kalkbrenner} M.~Kalkbrenner (1993).
A Generalized Euclidean Algorithm for Computing
Triangular Representations of Algebraic Varieties.
{\it J. Symbolic Comp.} {\bf 15}, 143--167.

\bibitem{Maza} M.~Moreno Maza, R.~Rioboo (1995).
Polynomial Gcd Computations over Towers of Algebraic Extensions,
{\it Proc. of AAECC-11} Springer-Verlag LNCS {\bf 948} (1995), pp.~365--382.

\bibitem{Maple}
{\it Maple 9 Introductory Programming Guide}
M.~B.~Monagan, K.~O.~Geddes, K.~M.~Heal, G.~Labahn,
S.~M.~Vorkoetter, J.~McCarron, P.~DeMarco.
Maplesoft, 2003.  ISBN: 1-894511-43-3.

\bibitem{Disco} M.~B. Monagan (1993).
In-place arithmetic for polynomials over .
{\it Proceedings of DISCO '92}, Springer-Verlag LNCS, {\bf 721}, pp.~22--34.

\bibitem{MQRR} M.~B. Monagan (2004).
Maximal Quotient Rational Reconstruction: An Almost Optimal
Algorithm for Rational Number Reconstruction. 
{\it Proceedings of ISSAC 2004}, ACM Press, pp.~243--249.

\bibitem{MonvHoeij} M.~B. Monagan, M. van Hoeij (2004).
Algorithms for Polynomial GCD Computation over Algebraic Function Fields.
{\it Proceedings of ISSAC 2004}, ACM Press, pp.~297--304.

\bibitem{Monagan}
M.~B. Monagan, A.~D. Wittkopf (2000).
On the Design and Implementation of Brown's
Algorithm over the Integers and Number Fields,
{\it Proceedings of ISSAC 2000}, ACM Press, pp.~225--233.

\bibitem{Montgomery} P~.L~Montgomery (1992).
{\it An FFT Extension of the Elliptic Curve Method of Factorization.}
PhD thesis, University of California, Los Angeles.

\bibitem{Pan} V~.Y~Pan, X.~Wang (2002).
Acceleration of the Euclidean Algorithm and Extensions,
{\it Proceedings of ISSAC '02}, ACM Press, pp.~207--213.

\bibitem{Steel} A.~Steel (2003). Private communication.

\bibitem{David} D.~Stoutemyer (1984).
Which Polynomial Representation is Best?  Surprises Abound!
{\it Proceedings of the 1984 Macsyma User's Conference},
pp.~221--243.

\bibitem{Trager} B.~M.~Trager (1976).
Algebraic Factoring and Rational Function Integration.
{\it Proc. of ISSAC '76}, ACM Press, pp 219--226.

\bibitem{Wang81} P. Wang (1981).
A -adic Algorithm for Univariate Partial Fractions.
{\it Proceedings of SYMSAC '81}, ACM Press, pp 212-217.

\bibitem{Wang} P. Wang, M.~J.~T. Guy, J.~H. Davenport (1982).
{\em -adic Reconstruction of Rational Numbers}.
in SIGSAM Bulletin, {\bf 16}, No 2.

\bibitem{Zippel} R.~Zippel (1979).
Probabilistic algorithms for sparse polynomials.
{\it Proceedings of EUROSAM '79}, Springer-Verlag LNCS, pp.~216--226.

\end{thebibliography}

\end{document}
