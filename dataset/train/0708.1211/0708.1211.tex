\documentclass{article}
\usepackage{latex8}
\usepackage{pxfonts}
\usepackage{times}
\usepackage{bbm}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{clrscode}
\usepackage{fullpage}
\usepackage{amssymb}
 
\begin{document}
\pagestyle{empty}

\title{A Deterministic Sub-linear Time Sparse Fourier Algorithm via Non-adaptive Compressed Sensing Methods}
\author{M. A. Iwen\thanks{Supported in part by NSF DMS-0510203.}\\
University of Michigan\\
markiwen@umich.edu}

\maketitle
\thispagestyle{empty}

\begin{abstract}
We study the problem of estimating the best  term Fourier representation for a given frequency-sparse signal (i.e., vector)  of length .  More explicitly, we investigate how to deterministically identify  of the largest magnitude frequencies of , and estimate their coefficients, in polynomial time.  Randomized sub-linear time algorithms which have a small (controllable) probability of failure for each processed signal exist for solving this problem.  However, for failure intolerant applications such as those involving mission-critical hardware designed to process many signals over a long lifetime, deterministic algorithms with no probability of failure are highly desirable.  In this paper we build on the deterministic Compressed Sensing results of Cormode and Muthukrishnan (CM) \cite{CMDetCS3,CMDetCS1,CMDetCS2} in order to develop the first known deterministic sub-linear time sparse Fourier Transform algorithm suitable for failure intolerant applications.  Furthermore, in the process of developing our new Fourier algorithm, we present a simplified deterministic Compressed Sensing algorithm which improves on CM's algebraic compressibility results while simultaneously maintaining their results concerning exponential decay.
\end{abstract}

\section{Introduction}

In many applications only the top few most energetic terms of a signal's Fourier Transform (FT) are of interest.  In such applications the Fast Fourier Transform (FFT), which computes all FT terms, is computationally wasteful.  To make our point, we next consider a simple application-based example in which the FFT can be replaced by faster approximate Fourier methods:\\

\noindent \textbf{Motivating Example:  sub-Nyquist frequency acquisition}

Imagine a signal/function  of the form

consisting of a single unknown frequency  (e.g., consider a windowed sinusoidal portion of a wideband frequency-hopping signal \cite{SigApp1}).  Sampling at the Nyquist-rate would dictate the need for at least  equally spaced samples from  in order to discover  via the FFT without aliasing \cite{BoydAl}.  Thus, we would have to compute the FFT of the -length vector

However, if we use aliasing to our advantage we can correctly determine  with significantly fewer -samples taken in parallel.

Consider, for example, the two-sample Discrete Fourier Transform of .  It has
 
Clearly  implies that  modulo 2 while  implies that  modulo 2.  In this fashion we may use several potentially aliased Fast Fourier Transforms in parallel to discover  modulo  the  prime.  Once we have collected these moduli we can reconstruct  via the famous \textbf{Chinese Remainder Theorem (CRT)}.  

\newtheorem{Theorem}{Theorem}
\begin{Theorem}
{\sc Chinese Remainder Theorem (CRT):}  Any integer  is uniquely specified mod  by its remainders modulo  relatively prime integers  as long as .
\end{Theorem}

To finish our example, suppose that  and that we have used three FFT's with 100, 101, and 103 samples to determine that  mod ,  mod , and  mod 103, respectively.  Using that 
 mod 103 and we can see that  for some integer .  Thus, 

Therefore,  for some integer .  Substituting for  we get that .  By similar work we can see that  mod  after considering  modulo 100.  Hence,  by the CRT.  As an added bonus we note that our three FFTs will have also provided us with three different estimates of 's coefficient .

The end result is that we have used significantly less than  samples to determine .  Using the CRT we required only  samples from  to determine  since .  In contrast, a million -samples would be gathered during Nyquist-rate sampling.  Besides needing significantly less samples than the FFT, this CRT-based single frequency method dramatically reduces required computational effort.  And, it's deterministic.  There is no chance of failure.  Of course, a single frequency signal is incredibly simple.  Signals involving more than 1 non-zero frequency are much more difficult to handle since frequency moduli may begin to collide modulo various numbers.  Dealing with the potential difficulties caused by such frequency collisions in a deterministic way comprises the majority of this paper.

\subsection{Compressed Sensing and Related Work}

Compressed Sensing (CS) methods \cite{CS1,CS2,CMDetCS3,CMDetCS1,CMDetCS2} provide a robust framework for reducing the number of measurements required to estimate a sparse signal.  For this reason CS methods are useful in areas such as MR imaging \cite{MRI1, MRI2} and analog-to-digital conversion \cite{SigApp1,SigApp2} where measurement costs are high.  The general CS setup is as follows:  Let \textbf{A} be an -length signal/vector with complex valued entries and  be a full rank  change of basis matrix.  Furthermore, suppose that  is sparse (i.e., only  entries of  are significant/large in magnitude).  CS methods deal with generating a  measurement matrix, , with the smallest number of rows possible (i.e.,  minimized) so that the  significant entries of  can be well approximated by the -element vector result of

Note that CS is inherently algorithmic since a procedure for recovering 's largest -entries from the result of Equation~\ref{eqn:matprod} must be specified.  

For the remainder of this paper we will consider the special CS case where  is the  Discrete Fourier Transform matrix.  Hence, we have

Our problem of interest is to find, and estimate the coefficients of, the  significant entries (i.e., frequencies) of  given a frequency-sparse (i.e., smooth) signal \textbf{A}.  In this case the deterministic Fourier CS measurement matrixes, , produced by \cite{CS2,CMDetCS3,CMDetCS1,CMDetCS2} require super-linear -time to multiply by \textbf{A} in Equation~\ref{eqn:matprod}.  Similarly, the energetic frequency recovery procedure of \cite{CS1,DetCS} requires super-linear time in .  Hence, none of \cite{CS1,CS2,DetCS,CMDetCS3,CMDetCS1,CMDetCS2} have both sub-linear measurement and reconstruction time.  

Existing randomized sub-linear time Fourier algorithms \cite{AAFFT1,AAFFT1exp,AAFFT2} not only show great promise for decreasing measurement costs, but also for speeding up the numerical solution of computationally challenging multi-scale problems \cite{SparseSpect, SparseSpectM}.  However, these algorithms are not deterministic and so can produce incorrect results with some small probability on each input signal.  Thus, they aren't appropriate for long-lived failure intolerant applications.

In this paper we build on the deterministic Compressed Sensing methods of Cormode and Muthukrishnan (CM) \cite{CMDetCS3,CMDetCS1,CMDetCS2} in order to construct the first known deterministic sub-linear time sparse Fourier algorithm.  In order to produce our new Fourier algorithm we must modify CM's work in two ways.  First, we alter CM's measurement construction in order to allow sub-linear time computation of Fourier measurements via aliasing.  Thus, our algorithm can deterministically approximate the result of Equation~\ref{eqn:matprod} in time polylog().  Second, CM use a -strongly selective collection of sets \cite{Constructions} to construct their measurements for algebraically compressible signals.  We introduce the generalized notion of a -majority -strongly selective collection of sets which leads us to a new reconstruction algorithm with better algebraic compressibility results than CM's algorithm.  As a result, our deterministic sub-linear time Fourier algorithm has better then previously possible algebraic compressibility behavior.

The main contributions of this paper are:
\begin{enumerate}
\item We present a new deterministic compressed sensing algorithm that both  improves on CM's algebraically compressible signal results, and  has comparable measurement/run time requirements to CM's algorithm for exponentially decaying signals.
\item We present the first known deterministic sub-linear time sparse DFT.  In the process, we explicitly demonstrate the connection between compressed sensing and sub-linear time Fourier transform methods.
\item We introduce -majority -strongly selective collections of sets which have potential applications to streaming algorithms along the lines of \cite{FirstDetCS, Crprecis}.
\end{enumerate}

The remainder of this paper is organized as follows:  In section~\ref{sec:prelim} we introduce relevant definitions and terminology.  Then, in section~\ref{sec:Measurements} we define -majority -strongly selective collections of sets and use them to construct our compressed sensing measurements.  Section~\ref{sec:SigReconstruct} contains our new deterministic compressed sensing algorithm along with analysis of it's accuracy and run time.  Finally, we present our deterministic sub-linear time Fourier algorithm in sections~\ref{sec:fmeasure} and~\ref{sec:inaccessible}.  Section~\ref{sec:conc} contains a short conclusion.

\section{Preliminaries}
\label{sec:prelim}

Throughout the remainder of this paper we will be interested in complex-valued functions  and signals (or arrays) of length  containing  values at various .  We shall denote such signals by , where  is the signal's  complex value for all .  Hereafter we will refer to the process of either calculating, measuring, or retrieving the  value associated any  from machine memory as \textit{sampling} from  and/or .  Given a signal  we define 
its discrete -norm, or Euclidean norm, to be 
  
We will also refer to  as 's energy.

For any signal, , its Discrete Fourier Transform (DFT), denoted , is another signal of length  defined as follows: 

Furthermore, we may recover  from its DFT via the Inverse Discrete Fourier Transform (IDFT) as follows:

We will refer to any index, , of  as a frequency.  Furthermore, we will refer to  as frequency 's 
coefficient for each .  Parseval's equality tells us that  for any signal.  In other words, the DFT 
preserves Euclidean norm and energy.  Note that any non-zero coefficient frequency will contribute to 's energy.  Hence, we will also refer to 
 as frequency 's energy.  If  is relatively large we'll say that  is energetic.

Our algorithm produces output of the form  where each .  We will refer to any such set of  tuples 
 
as a \textbf{sparse Fourier representation} and denote it with a superscript `s'.  Note that if we are given a sparse Fourier representation, , we may consider 
to be a length- signal.  We simply view  as the  length signal

for all .  Using this idea we may, for example, compute  from  via the IDFT.

A  term/tuple sparse Fourier representation is -optimal for a signal  if it contains  of the most energetic frequencies of  along with their coefficients.  More precisely, we'll say that a sparse Fourier representation 
 
is \textbf{-optimal} for  if there exists a valid ordering of 's coefficients by magnitude

so that .  Note that a signal may have several -optimal Fourier 
representations if its frequency coefficient magnitudes are non-unique.  For example, there are two 1-optimal sparse Fourier representations for the signal 

However, all -optimal Fourier representations, , for any signal \textbf{A} will always have both the same unique  and  values.  

We continue with two final definitions:  Let  be a  most energetic frequency as per Equation~\ref{eqn:ordering}.  We will say that a signal  is \textbf{(algebraically) -compressible} for some  if  for all .  If  is a -optimal Fourier representation we can see that

Hence, any -compressible signal  (i.e., any signal with a fixed  so that  for all ) will have  for some .  For any -compressible signal class (i.e., for any choice of  and ) we will refer to the related optimal -size worst case error value (i.e., Equation~\ref{equ:pbound} above) as .  Similarly, we define an \textbf{exponentially compressible} (or \textbf{exponentially decaying}) signal for a fixed  to be one for which
.  The optimal worst case error is then


Fix  small (e.g., ).
Given a compressible input signal, , our deterministic Fourier algorithm will identify  of the most energetic frequencies from  and approximate their coefficients to produce a Fourier representation  with .  These are the same types of compressible signal results proven by CM \cite{CMDetCS1,CMDetCS2}.

\section{Construction of Measurements}
\label{sec:Measurements}

We will use the following types of subset collections to form our measurements:

\newtheorem{Definition}{Definition}
\begin{Definition}
A collection, , of  subsets of  is called \textbf{-majority -strongly selective} if for any  with , and for all , the following are true:    belongs to  subsets in  and,  more than two-thirds of  containing  are such that  (i.e., every member of  occurs separated from all other members of  in more than two-thirds of the  -subsets it belongs to).
\label{def:SepSets}
\end{Definition}

A 1-majority -strongly selective collection of sets is an example of a \textbf{-strongly selective collection of sets} \cite{Constructions,CMDetCS3}.  Note that a -majority -strongly selective collection of subsets contains many -strongly selective collections of subsets (i.e., it has repeated strong selectivity).  Thus, our newly defined -majority -strongly selective collections are help us count how many times each small subset element is isolated.  This added structure allows a new reconstruction algorithm (Algorithm~\ref{alg:reconstruct}) with better algebraic compressibility properties than previous methods.

Next, we will build  -majority -strongly selective collections of subsets.  Each of these  collections will ultimately be used to determine energetic frequencies modulo a small prime .  These moduli will then be used along with the Chinese Remainder Theorem to reconstruct each energetic frequency in a manner akin to the introduction's motivating example.  Our technique is motivated by the method of prime groupings first employed in \cite{FirstDetCS}.  To begin, we will denote each of the  collections of subsets by  where .  We construct each of these -majority -strongly selective collections as follows:  

Define  and let 
 
be the first  primes where  is such that

Hence,  is the  prime natural number and we have

Note that we know  via the Prime Number Theorem, and so .  Each  will correspond to a different -majority -strongly selective collection of subsets of .

Along the same lines we let  through  be the first  (to be specified later) consequitive primes such that
  
We are now ready to build , our first -majority k-strongly selective collection of sets.  We begin by letting  for all  and  be

Next, we progressively define  to be all integer residues mod , i.e., 

and conclude by setting  equal to all  such  residue groups:

More generally, we define  for  as follows:


\newtheorem{Lemma}{Lemma}
\begin{Lemma}
Fix .  If we set  then  will be a -majority -strongly selective collection of sets.  Furthermore, if  then .
\label{lem:S0strong}
\end{Lemma}

\noindent \textit{Proof:}\\

Let  be such that .  Furthermore, let  be such that .  By the Chinese Remainder Theorem we know that  and  may only collide modulo at most  of the  -primes .  Hence,  may collide with all the other elements of  (i.e., with ) modulo at most  -primes.  We can now see that  will be isolated from all other elements of  modulo at least  -primes.  This leads us to the conclusion that  is indeed -majority -strongly selective.

Finally, we have that

Furthermore, given that , the Prime Number Theorem tells us that .  Thus, we can see that  will indeed contain  sets.~~ \\

Note that at least  primes are required in order to create a (-majority) -strongly separating collection of subsets using primes in this fashion.  Given any  a  element subset  can be created via the Chinese Remainder Theorem and  moduli so that every element of  collides with  in any desired  -primes.  We next consider the properties of the other  collections we have defined:  .

\begin{Lemma}
Let ,  have  elements, and .  Furthermore, suppose that . Then, for all , there exists a unique  so that .
\label{lem:S1-m}
\end{Lemma}

\noindent \textit{Proof:}\\

Fix any .   implies that  for some unique integer .  Using 's unique representation modulo  (i.e., ) we get that .  Hence, we can see that .  Furthermore, no other element of  is in  for any  since it's inclusion therein would imply that it was also an element of .~~ \\

Note that Lemma~\ref{lem:S1-m} and Lemma~\ref{lem:S0strong} together imply that each  is also a -majority -strongly separating collection of subsets.  Also, we can see that if  we can find  mod  by simply computing  mod .  Finally, we form our measurement matrix.

Set .  To form our measurement matrix, , we simply create one row for each  by computing the -length characteristic function vector of , denoted .  This leads to  being a  x  measurement matrix.  Here we bound the number of rows in  by noting that:  ,  ,  ,  , and  .

\section{Signal Reconstruction from Measurements}
\label{sec:SigReconstruct}

Let  be an -length signal of complex numbers with it's  entries numbered 0 through .  Our goal is to identify  of the largest magnitude entries of  (i.e., the first  entries in a valid ordering of  as in Equation~\ref{eqn:ordering}) and then estimate their signal values.  Toward this end, set 

where  is a constant to be specified later, and let  be the smallest integer such that 

Note that  is defined to be the last possible significant frequency (i.e., with energy  a fraction of ).
We expect to work with sparse/compressible signals so that .  Later we will give specific values for  and  depending on , the desired approximation error, and 's compressibility characteristics.  For now we show that we can identify/approximate  of 's largest magnitude entries each to within -precision via Algorithm~\ref{alg:reconstruct}.

\begin{algorithm}[tb]
\begin{algorithmic}[1]
\caption{} \label{alg:reconstruct}
\STATE \textbf{Input: Signal , integers } 
\STATE \textbf{Output: , a sparse representation for }
\STATE Initialize 
\STATE Set 
\STATE Form measurement matrix, , via -majority -strongly selective collections (Section~\ref{sec:Measurements})
\STATE Compute  \\
\begin{center}
{\sc Identification}
\end{center}
\FOR { from  to }
	\STATE Sort  by magnitude
	\FOR { from  to }
		\STATE  largest magnitude -measurement
		\STATE  's associated residue mod  (i.e., the  in )
		\FOR { from  to }
			\STATE 
			\STATE  mod 
		\ENDFOR
		\STATE Construct  from  via the Chinese Remainder Theorem
	\ENDFOR
\ENDFOR \\
\STATE Sort 's maintaining duplicates and set  the number of times  was constructed via line 16
\begin{center}
{\sc Estimation}
\end{center}
\FOR { from  to }
	\FOR { from  to }	
		\IF { }
			\STATE  
			\STATE 
			\STATE 
			\STATE 
		\ENDIF
	\ENDFOR
\ENDFOR \\
\STATE Output  largest magnitude entries in 
\end{algorithmic}
\end{algorithm}

Algorithm~\ref{alg:reconstruct} works by using  measurements to separate 's significantly energetic frequencies .  Every measurement which successfully separates an energetic frequency  from all other members of  will both  provide a good (i.e., within ) coefficient estimate for , and  yield information about 's identity.  Frequency separation occurs because our  measurements can't collide any fixed  with any other member of  modulo more then  -primes (see Lemma~\ref{lem:S0strong}).  Therefore, more than  of 's  -primes will isolate any fixed .  This means that our reconstruction algorithm will identify all frequencies at least as energetic as  at least  times.  We can ignore any frequencies that aren't recovered this often.  On the other hand, for any frequency that is identified more then  
times, at most  of the measurements which lead to this identification can be significantly contaminated via collisions with  members.  Therefore, we can take a median of the more than  measurements leading to the recovery of each frequency as that frequency's coefficient estimate.  Since more than half of these measurements must be accurate, the median will be accurate.  The following Theorem is proved in the appendix.

\begin{Theorem}
Let  be a -optimal Fourier representation for our input signal \textbf{A}.  Then, the  term representation  returned from Algorithm~\ref{alg:reconstruct} is such that .  Furthermore, Algorithm~\ref{alg:reconstruct}'s Identification and Estimation (lines 7 - 30) run time is .  The number of measurements used is .
\label{thm:alg1}
\end{Theorem}

Theorem~\ref{thm:alg1} immediately indicates that Algorithm~\ref{alg:reconstruct} gives us a deterministic -measurement, -reconstruction time method for exactly recovering -support vectors.  If  is a -support vector then setting  and  will be sufficient to guarantee that both  and  are true.  Hence, we may apply Theorem~\ref{thm:alg1} with  and  to obtain a perfect reconstruction via Algorithm~\ref{alg:reconstruct}.  However, we are mainly interested in the more realistic cases where  is either algebraically or exponentially compressible.  The following theorem (proved in the appendix) presents itself.

\begin{Theorem}
Let  be -compressible.  Then, Algorithm~\ref{alg:reconstruct} can return a  term sparse representation  with  using  total identification/estimation time and  measurements.  If  decays exponentially, Algorithm~\ref{alg:reconstruct} can return a B term sparse representation, , with  using both  polylog() measurements and identification/estimation time.
\label{thm:compress}
\end{Theorem}

For -compressible signals, , CM's algorithm \cite{CMDetCS1,CMDetCS2} takes - identification/estimation time and -measurements to achieve the same error bound.  As a concrete comparison, CM's algorithm requires - identification/estimation time and -measurements for 3-compressible signals.  Algorithm~\ref{alg:reconstruct}, on the other hand, requires only - identification/estimation time and -measurements.  Hence, we have improved on CM's algebraic compressibility results.  All that's left to do in order to develop a deterministic sub-linear time Fourier algorithm is to compute our CS Fourier measurements (Algorithm~\ref{alg:reconstruct} lines 1 - 6) in sub-linear time.

\section{Sub-linear Time Fourier Measurement Acquisition}
\label{sec:fmeasure}

\begin{algorithm}[tb]
\begin{algorithmic}[1]
\caption{} \label{alg:fmeasure}
\STATE \textbf{Input:  -samples, integers } 
\STATE \textbf{Output:  -measurements}
\STATE Zero a -element array, \textbf{A} 
\FOR { from  to }
	\FOR { from  to }
		\STATE 
		\STATE Calculate  via FFT
		\STATE  for each 
	\ENDFOR
\ENDFOR \\
\STATE Output -measurements
\end{algorithmic}
\end{algorithm}

Our goal in this section is to demonstrate how to use Algorithm~\ref{alg:reconstruct} as means to approximate the Fourier transform of a signal/function , where   has an integrable  derivative, and  .  In this case we know the Fourier coefficients for  to be -compressible \cite{BoydAl,FourierCont}.  Hence, for  sufficiently large, if we can collect the necessary Algorithm~\ref{alg:reconstruct} (line 5 and 6) measurements in sub-linear time we will indeed be able to use Algorithm~\ref{alg:reconstruct} as a sub-linear time Fourier algorithm for .  

Note that in order to validate the use of Algorithm~\ref{alg:reconstruct} (or any other sparse approximate Fourier Transform method \cite{AAFFT1,AAFFT2}) we must assume that  exhibits some multi-scale behavior.  If  contains no unpredictably energetic large (relative to the number of desired Fourier coefficients) frequencies then it is more computationally efficient to simply use standard FFT/USFFT methods \cite{FFT,AUSFFTrev,AUSFFT,USFFT1,USFFT2}.  The responsible user, therefore, is not entirely released from the obligation to consider 's likely characteristics before proceeding with computations.

Choose any Section~\ref{sec:Measurements} -prime , , and any -prime  with .  Furthermore, pick .  Throughout the rest of this discussion we will consider  to be accessible to sampling at any desired predetermined positions .  Given this assumption we may sample  at  in order to perform the following DFT computation:

Via aliasing \cite{BoydAl} this reduces to

Using Sections~\ref{sec:Measurements} and \ref{sec:SigReconstruct} we can see that these measurements are exactly what we need in order to determine  of the most energetic frequencies of  modulo  (i.e.,  of the most energetic frequencies of 's band-limited interpolant's DFT).  

We are now in the position to modify Algorithm~\ref{alg:reconstruct} in order to find a sparse Fourier representation for .  To do so we proceed as follows:  First, remove lines 5 and 6 and replace them with Algorithm~\ref{alg:fmeasure} for computing all the necessary -measurements.  Second, replace each ``" by ``" in Algorithm~\ref{alg:reconstruct}'s {\sc Identification} section.  It remains to show that these Algorithm~\ref{alg:reconstruct} modifications indeed yield a sub-linear time approximate Fourier transform.  The following theorem presents itself (see appendix for proof):

\begin{Theorem}
Let  have  an integrable  derivative, and   for some .  Furthermore, assume that 's  largest magnitude frequencies all belong to .  Then, we may use Algorithm~\ref{alg:reconstruct} to return a  term sparse Fourier representation, , for  such that  using -time and -measurements from .
\label{thm:subfourier}
\end{Theorem}

If  is smooth (i.e., has infinitely many continuous derivatives on the unit circle where 0 is identified with ) it follows from Theorem~\ref{thm:subfourier} that Algorithm~\ref{alg:reconstruct} can be used to find an -accurate, with , sparse -term Fourier representation for  using -time/measurements.  This result differs from previous sub-linear time Fourier algorithms \cite{AAFFT1,AAFFT2} in that both the algorithm and the measurements/samples it requires are deterministic.  Recall that the deterministic nature of the algorithm's required samples is potentially beneficial for failure intolerant hardware.  In signal processing applications the sub-Nyquist sampling required to compute Algorithm~\ref{alg:reconstruct}'s -measurements could be accomplished via  parallel low-rate analog-to-digital converters.

\subsection{DFT from Inaccessible Signal Samples}
\label{sec:inaccessible}

Throughout the remainder of this section we will consider our -length compressible vector  to be the product of the  x  DFT matrix, \textbf{}, and a non-sparse -length vector \textbf{A}.  Thus,

Furthermore, we will assume that \textbf{A} contains equally spaced samples from some unknown smooth function  (e.g., \textbf{A}'s band-limited interpolent).  Hence,

We would like to use our modified Algorithm~\ref{alg:reconstruct} along with Algorithm~\ref{alg:fmeasure} to find a sparse Fourier representation for .  However, unless  for all -pairs (which would imply  had been grossly oversampled), \textbf{A} won't contain all the -samples required by Algorithm~\ref{alg:fmeasure}.  Not having access to  directly, and restricting ourselves to sub-linear time approaches only, we have little recourse but to locally interpolate  around our required samples.

For each required Algorithm~\ref{alg:fmeasure} -sample at  we may approximate  to within -error by constructing 2 local interpolents (one real, one imaginary) around  using \textbf{A}'s nearest  entries \cite{BasicInterp}.  These errors in -samples can lead to errors of size  in our  calculations.  However, as long as the -measurement errors are small enough (i.e., of size  in the -compressible case) Theorem~\ref{thm:subfourier} and all related Section~\ref{sec:SigReconstruct} results and will still hold.  Using the proof of Theorems~\ref{thm:alg1} and \ref{thm:compress} along with some scratch work we can see that using  interpolation points per -sample ensures all our -measurement errors are .  We have the following result:

\begin{Theorem}
Let  be -compressible.  Then, we may use Algorithms~\ref{alg:reconstruct} and \ref{alg:fmeasure} to return a  term sparse representation, , for  such that  using -time and -samples from \textbf{A}.
\label{thm:detDFT}
\end{Theorem}

Notice that Theorem~\ref{thm:detDFT} no longer guarantees an -accurate -time DFT algorithm for smooth data (i.e., \textbf{A}'s containing samples from a smooth function ).  This is because as  we require an increasingly large number of interpolation points per -sample in order to guarantee our -measurements remain -accurate.
However, for , we can still consider smooth data \textbf{A} to be -compressible and so achieve a -time DFT algorithm.  

\section{Conclusion}
\label{sec:conc}

Compressed Sensing (CS) methods provide algorithms for approximating the result of any large matrix multiplication as long as it is known in advance that the result will be sparse/compressible.  Hence, CS is potentially valuable for many numerical applications such as those involving multi-scale aspects \cite{SparseSpect,SparseSpectM}.  In this paper we used CS methods to develop the first known deterministic sub-linear time sparse Fourier transform algorithm.  In the process, we introduced a new deterministic Compressed Sensing algorithm along the lines of Cormode and Muthukrishnan (CM) \cite{CMDetCS1,CMDetCS2}.  
Our new deterministic CS algorithm improves on CM's algebraic compressibility results while simultaneously maintaining their results concerning exponential compressibility.

Compressed Sensing is closely related to hashing methods, combinatorial group testing, and many other algorithmic problems \cite{FirstDetCS,Crprecis}.  Thus, -majority -strongly selective collections of sets and Algorithm~\ref{alg:reconstruct} should help improve results concerning algebraically compressible (at each moment in time) stream hashing/heavy-hitter identification.  Further development of these/other algorithmic applications is left as future work.  It is also worthwhile to note that Monte Carlo Fourier results similar to those of \cite{AAFFT2} may be obtained by altering our measurement construction in Section~\ref{sec:Measurements}.  If we construct our  collections by using only a small subset of randomly chosen 's we will still locate all sufficiently energetic entries of  with high probability.  The entries' coefficients can then be approximated by standard USFFT techniques \cite{AAFFT2,USFFT1,USFFT2,AUSFFTrev}.

\section{Acknowledgments}

We would like to thank Graham Cormode and S. Muthukrishnan for answering questions about their work.  We would also like to thank Martin Strauss, Anna Gilbert, Joel Lepak, and Hualong Feng for helpful discussions, advice, and comments.

\bibliographystyle{abbrv}
\bibliography{CSforSODA}

\appendix

\section{Proof of Theorem~\ref{thm:alg1}}

We begin by proving two lemmas.

\begin{Lemma}
IDENTIFICATION:  Lines 7 through 19 of Algorithm~\ref{alg:reconstruct} are guaranteed to recover all valid  (i.e., all  with  - there may be  such entries) more then  times.  Hence, despite line 22, an entry for all such , will be added to  in line 26.
\label{lem:identification}
\end{Lemma}

\noindent \textit{Proof:}\\

Because of the construction of  (i.e., proof of Lemma~\ref{lem:S0strong}) we know that for each  there exist more then  subsets  such that .  Choose any .  Denote the -primes that isolate  from all of  by

We next show that, for each , we get  as one of the  largest magnitude -measurements identified in line 10.

Choose any .  We know that

We also know that the  largest measurement L-magnitude must be .  Hence, we are guaranteed to execute lines 12-15 with an  mod .

Choose any  and set 
  
Using Lemma~\ref{lem:S1-m} we can see that line 13 inspects all the necessary residues of  mod .  To see that  will be chosen correctly we note first that
 
Furthermore, setting  mod  and
 
we have

Finally we can see that 

Hence, lines 13 and 14 will indeed select the correct residue for  modulo .  Therefore, line 16 will correctly reconstruct  at least  times.~~ \\

\begin{Lemma}
ESTIMATION:  Every  stored in  in line 27 is such that .
\label{lem:estimation}
\end{Lemma}

\noindent \textit{Proof:} \\

Suppose that  is stored in .  This only happens if  has been estimated by  for more then  -primes.  The only way that any such estimate can have  is if  collides with one of  modulo  (this is due to the definition of  in Equation~\ref{def:B'}).  By the proof of Lemma~\ref{lem:S0strong} we know this can happen at most  times.  Hence, more then half of the  estimates, , must be such that .  It follows that taking medians as per lines 24 and 25 will result in the desired -accurate estimate for .
~~ \\

We are now ready to prove Theorem~\ref{thm:alg1}.\\

\noindent \textbf{Theorem~\ref{thm:alg1}}~~\textit{Let  be a -optimal Fourier representation for our input signal .  Then, the  term representation  returned from Algorithm~\ref{alg:reconstruct} is such that .  Furthermore, Algorithm~\ref{alg:reconstruct}'s Identification and Estimation (lines 7 - 30) run time is .  The number of measurements used is }.\\

\noindent \textit{Proof:}\\

Choose any .  Using Lemmas~\ref{lem:identification} and~\ref{lem:estimation} we can see that only way some  is if there exists some associated  so that  and
 
In this case we'll have  so that


Now using Lemma~\ref{lem:estimation} we can see that

Furthermore, we have

Using observation \ref{eqn:proofe} above we can see that this last expression is bounded above by

Substituting for  (see Equation~\ref{eqn:epsilon}) gives us our result.  Mainly,



We next focus on run time.  Algorithm~\ref{alg:reconstruct}'s Identification (i.e., lines 7 through 19) run time is dominated by the  executions of line 13.  And, each execution of line 13 takes time .  Hence, given that , , and , we can see that Identification requires -time.

Continuing, Algorithm~\ref{alg:reconstruct}'s Estimation (i.e., lines 20 through 30) run time is ultimately determined by line 22's {\sc if}-statement.  Although line 22 is executed  times, it can only evaluate to true  times.  Hence, each line 24/25 -time median operation will be evaluated at most  times.  The resulting Estimation runtime is therefore .

To bound the number of measurements we recall that:  the number of measurements is ,  ,  ,  , and  . Hence, the number of measurements is .  Substituting for  gives us the desired bound.
~~ \\

\section{Proof of Theorem~\ref{thm:compress}}

\noindent \textbf{Theorem~\ref{thm:compress}}~~\textit{Let  be -compressible.  Then, Algorithm~\ref{alg:reconstruct} can return a  term sparse representation  with  using  total identification/estimation time and  measurements.  If  decays exponentially, Algorithm~\ref{alg:reconstruct} can return a B term sparse representation, , with  using both  polylog() measurements and identification/estimation time.}\\

\noindent \textit{Proof:} \\

We first deal with the algebraically compressible case.  We have to determine our Algorithm~\ref{alg:reconstruct}'s  and Theorem~\ref{thm:alg1}'s  variables.  Moving toward that goal we note that

After looking at Theorem~\ref{thm:alg1} we can see that we must use  and a  (see Equations~\ref{eqn:epsilon} and~\ref{def:B'}) so that

Continuing,

Hence, we must use .  Applying Theorem~\ref{thm:alg1} gives us Algorithm~\ref{alg:reconstruct}'s runtime and number of required measurements.

We next deal with the exponentially compressible case.  Now, as before, we have to determine our Algorithm~\ref{alg:reconstruct}'s  and Theorem~\ref{thm:alg1}'s  variables.  To do so we note that

After looking at Theorem~\ref{thm:alg1} we can see that we must use  and a  so that

Continuing,

Hence, we must use .  Applying Theorem~\ref{thm:alg1} gives us Algorithm~\ref{alg:reconstruct}'s runtime and number of required measurements.~~ \\

\section{Proof of Theorem~\ref{thm:subfourier}}

\noindent \textbf{Theorem~\ref{thm:subfourier}}~~\textit{Let  have  an integrable  derivative, and   for some .  Furthermore, assume that 's  largest magnitude frequencies all belong to .  Then, we may use Algorithm~\ref{alg:reconstruct} to return a  term sparse Fourier representation, , for  such that  using -time and -measurements from .}\\

\noindent \textit{Proof:} \\

We note that Theorems~\ref{thm:alg1} and~\ref{thm:compress} still hold for -compressible infinite signals/vectors  (i.e., signals with -length).  For the purposes of proof we may consider  to be formed by any bijective mapping  so that both

and

are true.  We then set

In this case we note that 's  largest magnitude frequencies belonging to  implies our that -majority -strongly separating collection of (infinite) subsets, , will still correctly isolate all the  most energetic frequency positions in .

Continuing, we may still consider our infinite length -compressible, with , signal  (i.e., the Fourier coefficient series ) to be sorted by magnitude for the purpose of identifying valid , etc.. Furthermore, we may bound the (now infinite) sums of 's entries' magnitudes by the same integrals as above.  The proofs of the theorems/supporting lemmas will go through exactly as before if we consider all the finite sums in their proofs to be absolutely convergent infinite sums.  The only real difference from our work in Section~\ref{sec:SigReconstruct} is that we are computing our -measurements differently.

Similar to Theorem~\ref{thm:alg1}, the required number of measurements from  will be .  This is exactly because for each -pair we compute all the measurements 
via one FFT requiring  samples.  Hence, the number of samples from  we use is once again bounded above by .  Furthermore, each of the  FFT's will take -time (despite the signal lengths' factorizations \cite{1968-bluestein,rabiner-schafer-rader}).  The result follows.
~~ \\

\end{document}
