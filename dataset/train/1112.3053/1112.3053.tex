\documentclass{article}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}


\usepackage{amsthm}
\usepackage{amssymb,stmaryrd}
\usepackage[all]{xy}
\usepackage{url}
\usepackage{graphicx}
\usepackage{turnstile}


\newcommand{\Inn}{\ensuremath{\mathbf{Inn}}}
\newcommand{\Games}{\ensuremath{\mathbf{Gam}}}
\newcommand{\restrict}{\upharpoonright}
\newcommand{\from}{\leftarrow}
\newcommand{\tto}{\Rightarrow}
\newcommand{\leqa}{\unlhd}
\newcommand{\hhole}{\square}
\newcommand{\game}[1]{\mathcal{#1}}
\newcommand{\names}{\mathcal{X}}
\newcommand{\intr}[1]{\llbracket #1 \rrbracket}
\newcommand{\lpair}[1]{\langle #1 \rangle}
\newcommand{\bigintr}[1]{\left\llbracket#1\right\rrbracket}
\newcommand{\variables}{\mathcal{V}}
\newcommand{\lsum}[1]{[#1]}
\newcommand{\cobang}{\text{ยก}}
\newcommand{\natto}{\stackrel{\bullet}{\to}}
\newcommand{\name}[1]{` #1 '}
\newcommand{\adj}{\dashv} \newcommand{\leg}[1]{\mathcal{L}_{#1}}
\newcommand{\infplays}[1]{\leg{#1}^\omega}
\newcommand{\longplays}[1]{\leg{#1}^\infty}
\newcommand{\infthreads}[1]{Th_{#1}^\omega}
\newcommand{\longthreads}[1]{Th_{#1}^\infty}
\newcommand{\threads}[1]{\llceil #1 \rrceil}
\newcommand{\inter}{\mathop{|\!|}}
\newcommand{\one}{1}
\newcommand{\zero}{0}
\newcommand{\gamezero}{\mathbf{\zero}}
\newcommand{\gameone}{\mathbf{\one}}
\newcommand{\unfold}[1]{\widetilde{A}}
\newcommand{\addr}{\mathcal{A}}
\newcommand{\implies}{\Rightarrow}
\newcommand{\vis}{\mathcal{V}}
\newcommand{\church}[1]{\underline{#1}}
\newcommand{\size}{\mathrm{rsize}}
\newcommand{\cosize}{\mathrm{rcosize}}


\newcommand{\Ext}{\mathcal{E}}
\newcommand{\Set}{\mathbf{Set}}
\newcommand{\Gam}{\mathbf{Win}}



\newcommand{\todo}[1]{\emph{TODO:} #1}



\newtheorem{lemma}{\textsc{Lemma}}
\newtheorem{theorem}{\textsc{Theorem}}
\newtheorem{definition}{\textsc{Definition}}
\newtheorem{proposition}{\textsc{Proposition}}
\newtheorem{corollary}{\textsc{Corollary}}
\newtheorem{remark}{\textsc{Remark}}

\newlength{\viewht}
\newlength{\viewlift}
\newlength{\viewdp}
\newlength{\viewdrop}

\newcommand{\pview}[1]{\settoheight{\viewht}{\makebox{}}\setlength{\viewlift}{\viewht}\addtolength{\viewlift}{-1ex}\raisebox{0.3\viewlift}{\makebox{}}\!#1\!\settoheight{\viewht}{\makebox{}}\setlength{\viewlift}{\viewht}\addtolength{\viewlift}{-1ex}\raisebox{0.3\viewlift}{\makebox{}}}

\newcommand{\oview}[1]{\settodepth{\viewdp}{\makebox{}}\setlength{\viewdrop}{0.3\viewdp}\addtolength{\viewdrop}{0.5ex}\raisebox{-\viewdrop}{\makebox{}}\!#1\!\settodepth{\viewdp}{\makebox{}}\setlength{\viewdrop}{0.3\viewdp}\addtolength{\viewdrop}{0.5ex}\raisebox{-\viewdrop}{\makebox{}}} 

\begin{document}
\title{Estimation of the length of interactions\\ in arena game semantics}
\author{Pierre Clairambault\\
University of Bath\\
\texttt{p.clairambault@bath.ac.uk}}
\date{}
\maketitle
\begin{abstract}
We estimate the maximal length of interactions between strategies in HO/N game semantics, in the spirit of the work by Schwichtenberg and Beckmann for the length of reduction in 
simply typed -calculus.
Because of the operational content of game semantics, the bounds presented here also apply to head linear reduction on -terms and to the execution of
programs by abstract machines (PAM/KAM), including in presence of computational effects such as non-determinism or ground type references. The proof proceeds by extracting from
the games model a combinatorial rewriting rule on trees of natural numbers, which can then be analysed independently of game semantics or -calculus.
\end{abstract}



\section{Introduction}

Among the numerous notions of execution that one can consider on higher-order programming languages (in particular on the -calculus) \emph{head linear reduction} \cite{danos:abstract} plays a particular role. Although
it is not as widespread and specifically studied as, say, -reduction, it is nonetheless implicit to various approaches of higher-order computation, such as geometry of interaction, game semantics, optimal
reduction and ordinary operational semantics. It is also implicit to several abstract machines, including the Krivine Abstract Machine (KAM) \cite{krivine1985interpreteur} and the Pointer Abstract Machine (PAM) \cite{danos:abstract}, 
in the sense that it is the reduction they perform \cite{danos:abstract,phd} and as such is a valuable abstraction of how programs are executed in the implementation of higher order languages. 



Despite being closer to the implementation of programming languages, head linear reduction never drew a lot of attention from the community. Part of the reason for that is that it is not a usual notion of reduction:
defining it properly on -terms requires both to extend the notion of redex and to restrict to linear substitution, leading to rather subtle and tricky definitions which lack the canonicity of 
-reduction\footnote{However, there are syntaxes on which head linear reductions appear more canonical that -reduction, for instance proof nets \cite{DBLP:journals/tcs/MascariP94}.}. 
Moreover, its associated observational equivalence is the same as for the usual head -reduction, which makes it non relevant as long as one is
interested in the equational theory of -calculus.
However, head linear reduction should appear in the foreground as soon as one is interested in quantitative aspects of computation, such as complexity. On the contrary, although very precise bounds are known for the possible length of -reduction chains in simply typed -calculus \cite{schwichtenberg1982complexity,beckmann2001exact}, to the author's knowledge, the situation for head linear reduction remains essentially
unexplored. Even if it is generally expected that the bounds remain hyper-exponential\footnote{Note however that in \cite{de1987generalizing}, De Bruijn gives an upper bound for his local -reduction, akin to head linear
reduction. The bound is an iterate of the diagonal of an Ackermann-like function!}  (and this indeed what we will prove), it does not seem to follow easily from the bounds known for -reduction.


Rather than reasoning directly on head linear reduction, we will instead look at it through game semantics \cite{hyland-ong}. Indeed, there is a close relationship between head linear reduction and interaction in games
model of programming languages \cite{danosregnier}. More precisely, given two -normal and -long -terms  and , there is a step-by-step correspondence between head linear reduction chains of  and 
game-theoretic interactions between the strategies  and . Of course, game semantics are not central to our analysis: as is often the case, our methods and results could be adapted to a purely syntactical
framework. However, games have this considerable advantage of accommodating in a single framework purely functional programming languages such as the -calculus or PCF and a number of computational features such as 
non-determinism \cite{DBLP:conf/lics/HarmerM99}, control operators \cite{DBLP:conf/lics/Laird97} and references \cite{abramsky-mccusker:active-algol}. This will allow us to do our study with an increased generality:
our complexity results will hold for a variety of settings, from simply typed -calculus to richer languages possibly featuring the computational effects mentioned above, as long as there is no
fixed point operator.

\paragraph{Outline.} In Section 2 we will recall some of the basic definitions of Hyland-Ong game semantics, define the central notion of size of a strategy, and introduce our main question as the problem of finding 
the maximal length of an interaction between two strategies of fixed size. Our approach will be then to progressively simplify this problem in order to reach its underlying combinatorial nature. In Section 3
we first introduce the notion of \emph{visible pointer structures}, \emph{i.e.} plays where the identity of moves has been forgotten. This allows a more elementary (strategy-free) equivalent statement of our problem.
Then we show how each position in a visible pointer structure can be characterised by a tree of natural numbers called an \emph{agent}. We then show that the problem can be once again reformulated as the maximal length of
a reduction on these agents. In Section 4 we study the length of this reduction, giving in particular an upper bound. We also give a corresponding lower bound, and finally use our result to estimate
the maximal length of head linear reduction sequences on simply typed -terms.

\paragraph{Related works.} Our results and part of our methods are similar to the works of Schwichtenberg and Beckmann \cite{schwichtenberg1982complexity,beckmann2001exact}, but the reduction we study is in some sense more
challenging, because redexes are not
destroyed as they are reduced. Moreover, the game semantics setting allows for an extra generality. The present work also has common points with work by Dal Lago and Laurent \cite{DBLP:conf/csl/LagoL08}, in the sense that it uses
tools from game semantics to reason on the length of execution. However the approach is very different : their estimate is very precise but uses an information on terms difficult to compute (almost as hard as actually performing
execution). Here, we need little information on terms (gathering this information is linear in the size of the term), but our bounds are, in most cases, very rough.

\section{Arena game semantics}
\label{section_games}

We recall briefly the now usual definitions of arena games, first introduced in \cite{hyland-ong}. More detailed accounts
can be found in \cite{fpc2000,harmer2004innocent}. We are interested in games with two participants: Opponent
(O, the \emph{environment}) and Player (P, the \emph{program}). 


\subsection{Arenas and Plays}

Valid plays are generated by directed graphs called \emph{arenas}, which are semantic versions of \emph{types}. 
Formally, an \textbf{arena} is a structure  where:
\begin{itemize}
\item  is a set of \textbf{moves},
\item  is a polarity function indicating whether
a move is an Opponent or Player move (-move or -move).
\item  is a set of \textbf{initial moves}.
\item  is a relation called \textbf{enabling}, such that
if , then .
\end{itemize}
In other words, an arena is just a directed bipartite graph. We now define plays as \textbf{justified sequences} over : these are
sequences  of moves of , each non-initial move  in  being equipped with a pointer to an earlier move
 in , satisfying . In other words, a justified sequence  over  is such that
each reversed pointer chain  is a path on  (viewed as a graph).
The role of pointers is to allow \emph{reopenings} or \emph{backtracking} in plays. When writing justified sequences, we will often omit the
justification information if this does not cause any ambiguity. The symbol  will denote the prefix ordering on justified
sequences, and  will mean that  is a -ending prefix of .
If  is a justified sequence on ,  will denote its length.

Given a justified sequence  on , it has two subsequences of particular interest: the P-view and O-view.
The view for P (resp. O) may be understood as the subsequence of the play where P (resp. O) only sees his own duplications.
Practically, the P-view  of  is computed by forgetting everything
under Opponent's pointers, in the following recursive way:
\begin{itemize}
\item  if ;
\item  if  and  has no justification pointer;
\item  if  and  points to .
\end{itemize}
The O-view  of  is defined dually, without the special treatment of initial moves\footnote{In the terminology of \cite{harmer2004innocent}, it is the \emph{long} -view.}. 
The \emph{legal plays} over , denoted by , are the
justified sequences  on  satisfying the \textbf{alternation} condition, \emph{i.e.} that 
if , then .

\subsection{Classes of strategies}

In this subsection, we will present several classes of strategies on arena games that are of interest to us in the present paper. 
A \textbf{strategy}  on  is a set of even-length legal plays on , closed under even-length prefix. A strategy from  to 
is a strategy , where  is the usual arrow arena defined by ,  (where
 means  with polarity  reversed),  and .

\paragraph{Composition.} We define composition of strategies by the usual parallel interaction plus hiding mechanism.
If ,  and  are arenas, we define the set of \textbf{interactions}
 as the set of justified sequences  over , 
and  such that ,
 and
. Then, if 
and , we define parallel interaction as ,
composition is then defined as . Composition is associative and admits copycat strategies 
as identities.

\paragraph{-visible strategies.} A strategy  is \textbf{-visible} if each of its moves points to the current -view. Formally, for all ,
 points inside . -visible strategies are stable under composition, as is proved for instance in \cite{harmer2004innocent}. They
correspond loosely to functional programs with ground type references \cite{abramsky-mccusker:active-algol}.

\paragraph{Innocent strategies.}
The class of \emph{innocent} strategies is central in game semantics, because of their correspondence with purely functional programs (or 
-terms) and of their useful definability properties. A strategy  is \textbf{innocent} if 

Intuitively, an innocent strategy only takes its -view into account to determine its next move. Indeed, any innocent strategy is characterized by
a set of -views. This observation is very important since -views can be seen as abstract representations of branches of -expanded Bรถhm trees
(\emph{a.k.a.} Nakajima trees \cite{nakajima1975infinite}) : this is the key to the definability process on innocent strategies \cite{hyland-ong}. It is quite technical to prove that
innocent strategies are stable under composition, proofs can be found for instance in \cite{harmer2004innocent,phd}. Arenas and innocent strategies form a cartesian closed category and
are therefore a model of simply typed -calculus.

\paragraph{Bounded strategies.} A strategy  is \textbf{bounded} if it is -visible and if the length of its -views is bounded: formally, there exists
 such that for all , . Bounded strategies are stable under composition, as is proved in \cite{totality} for the innocent case
and in \cite{phd} for the general case. This result corresponds loosely to the strong normalisation result on simply-typed -calculus.
Syntactically, bounded strategies include the interpretation of all terms of a functional
programming language without a fixed point operator but with \textsc{Algol}-like ground type references (for details about how reference cells get
interpreted as strategies see for instance \cite{abramsky-mccusker:active-algol}, it is obvious that this interpretation yields a bounded strategy) and arbitrary non determinism. This remark
is important since it implies that our results will hold for any program written with these constructs, as long as they do not use recursion or a fixed point
operator. 

\subsection{Size of strategies and interactions}

Since in this paper we will be interested in the length of interactions, it is sensible to make it precise first what we mean by the \emph{size} of strategies. 
Let  be a bounded strategy, its size is defined as

All our analysis on the size of interactions will be based on this notion of size of strategies. Our starting point is the following finiteness result, 
proved in \cite{totality}. We say that an interaction  is \textbf{passive} if the only move by the external Opponent on 
is the initial move on , so that the interaction stops as soon as we need additional input from the external Opponent. 

\begin{proposition}
Let  and  be bounded strategies and let  be a passive interaction, then  is finite.
\label{finiteness}
\end{proposition}

Using this, we can actually deduce the existence of an uniform bound on the length of such , which only depends
on the respective size of  and :

\begin{lemma}
For all  there is a lesser  such that for all arenas  and , for all  and  such that
 and , for all passive  we have .
\label{konig}
\end{lemma}
\begin{proof}
For arenas  and  consider the set  of all passive interactions  such that for all ,
 and for all , . Then, consider the union  of all the , our goal
here is to find a bound on the length of all elements of . Consider now the tree structure on  given by the prefix ordering.
To make this tree finitely branching, consider the relation  on moves, where  is the number of pointers required
to go from  to an initial move. The tree  is now finitely branching, but is also well-founded by Proposition \ref{finiteness}, therefore it is finite by
Kรถnig's lemma\footnote{Or, more adequately, the fan theorem.}. Let  be its maximal depth, it is now obvious that it satisfies the required properties.
\end{proof}

We have proved the existence of the uniform bound , but in a way that provides no feasible means of estimating . The goal of the rest of this
paper is to estimate this bound as precisely as possible. As a matter of fact, we will be mainly interested in the ``typed" variant , defined as the maximum
length of all possible passive interactions between strategies  and  of respective size  and , where  has a finite depth .


\section{Pointer structures and rewriting}
We have seen that to prove Lemma \ref{konig}, we must consider plays up to an equivalence relation  which assimilates all moves at the same depth. Indeed,
general arenas and plays contain information which is useless for us. Following \cite{totality}, we will here reason on
\emph{pointer structures}, which result of considering moves in plays up to .  Pointer structures are also similar to the \emph{parity pointer functions} of
Harmer, Hyland and Melliรจs \cite{hhm} and to the \emph{interaction sequences} of Coquand \cite{coquand}. We will delve here into their combinatorics and extract from them a small rewriting system,
whose study is sufficient to characterize their length.

\subsection{ as a bound for pointer structures}

\paragraph{Visible pointer structures.}
In \cite{totality}, we introduced pointer structures by elementary axioms, independent of the general notions of game semantics. Instead here, we define \textbf{pointer
structures} as usual alternating plays, but on the particular ``pure" arena , where  ( is the singleton
arena with just one Opponent move) and . 
As we are interested in the interaction between -visible strategies, we will only consider \textbf{visible} pointer structures,
where both players point in their corresponding view. Formally,  is visible if for all , 
 points inside  and if for all ,  points inside . The \textbf{depth} of a visible pointer structure  is the smallest 
such that  is a play on . Let us denote by  the set of all visible pointer structures.

\paragraph{Atomic agents.}
After forgetting information on plays, let us forget information on strategies. Instead of considering bounded strategies with all their intentional behaviour,
we will just keep the data of their size. Pointer structures will then be considered as interactions between the corresponding numbers which will be called
\textbf{atomic agents}. If  is such a natural number, we define its \textbf{trace} as follows, along with the dual notion of \textbf{co-trace}:

An \textbf{interaction} at depth  between  and  is a visible pointer structure  of depth at most  such that .
We write . These definitions allow to give the following strategy-free equivalent formulation of .

\begin{lemma}
Let  and  be natural numbers and , then

\end{lemma}
\begin{proof}
Consider the maximal bounded strategies of respective size  and , defined as  
and . Then pointer structures in  are the same as (passive) interactions
in , thus . Reciprocally, if  has size  and  has size
 and if  is passive, then if  denotes  where moves are considered up to  we have 
thus  and .
\end{proof}

\subsection{Agents}

To bound the length of a pointer structure , our idea is to label each of its moves  by an object , expressing the size that the strategies have left. Let us consider
here an analogy between pointer structures and the execution of -terms by the KAM\footnote{The syntax used here seems natural enough, but is for instance described in \cite{phd}.}.
Consider the following three KAM computation steps:

The interaction between two closed terms (with empty environment) leads, after three steps of computation, to the interaction between two \emph{open terms}
 and  (where  is free in ), with an environment. By analogy, if  is labelled by the pair  of interacting ``strategies", each move 
should correspond to an interaction between objects , where  and  have a tree-like structure which is reminiscent of those of closures\footnote{As in the example above, closures
are pairs  where  is an open term and  is an \emph{environment}, \emph{i.e.} a mapping which to each free variable of  associates a closure.}.

We will call a \textbf{pointed visible pointer structure} (pvps) a pair  where  is a visible pointer structure and 
is an arbitrary ``starting" move. We adapt the notions of size and depth for pvps, and introduce a notion of \emph{context}. 


\begin{definition}
Let  be a pointed visible pointer structure. The \textbf{residual size} of  at , written , is defined as follows:
\begin{itemize}
\item If  is an Opponent move, it is 
\item If  is a Player move, it is 
\end{itemize}
where  means that the computation of  reaches\footnote{So starting from  and following Opponent's pointers
eventually reaches .} . Dually, we have the notion of
\textbf{residual co-size} of  at , written , defined as follows:
\begin{itemize}
\item If  is an Opponent move, it is 
\item Otherwise, 
\end{itemize}
The \emph{residual depth} of  at  is the maximal length of a pointer chain in  starting from .
\end{definition}




\begin{definition}
Let  be a visible pointer structure. We define the \textbf{context} of  as:
\begin{itemize}
\item If  is an O-move, the set  of O-moves appearing in ,
\item If  is a P-move, the set  of P-moves appearing in .
\end{itemize}
In other words it is the set of moves to which  can point whilst abiding to the visibility condition, except . We also need the dual notion
of co-context, which contains the moves the other player can point to. The \textbf{co-context} of  is:
\begin{itemize}
\item If  is an O-move, the set  of P-moves appearing in ,
\item If  is a P-move, the set  of O-moves appearing in .
\end{itemize}
\end{definition}

\begin{definition}
A \textbf{general agent} (just called agent for short) is a finite tree, whose nodes and edges are both labelled by natural numbers. If  are agents and  are natural numbers, we write:

\end{definition}

\begin{definition}[Trace, co-trace, interaction]
Let us generalize the notion of trace to general agents. The two notions  and  are defined by mutual recursion, as follows:
let  be an agent. We say that  is a \textbf{trace} (resp. a \textbf{co-trace}) of , denoted  (resp.
) if the following conditions are satisfied:
\begin{itemize}
\item  (resp. ),
\item If  is the context of  (resp. co-context), then for each  we have .
\item If  is the context of  (resp. co-context), then for each  the residual depth of  at  is less than .
\end{itemize}
Then, we define an \textbf{interaction} of two agents  and  at depth  as a pair  where the residual depth of  at  is less than , which we write .
\end{definition}
Notice that we use the same notations ,  and  both for natural numbers and general agents. This should not generate any confusion, since the definitions
just above coincide with the previous ones in the special case of ``atomic", or closed, agents: if  and  are natural numbers, then obviously  if and
only if .
Note also that definitions are adapted here to this particular setting where strategies are replaced by natural numbers, however they could be generalized to the usual notion
of strategies. An agent would be then a tree of strategies, and a trace of this agent would be a possible interaction between all these strategies. This would
be a new approach to the problem of \emph{revealed} or \emph{uncovered} game semantics \cite{greenland2004game,blum2008thesis}, where strategies are not necessarily cut-free.

\subsection{Simulation of visible pointer structures}

We introduce now the main tool of this paper, a reduction on agents which ``simulates" visible pointer structures: if  and  are agents (),
we define the non-deterministic reduction relation  on triples , where  is a depth (a natural number) and  and  are agents, by the following two cases:

where ,  in the first case and  in the second case. We can now state the following central proposition.

\begin{proposition}[Simulation]
Let , then if  is defined, there exists  such that .
\end{proposition}
\begin{proof}
The proof proceeds by a close analysis of where in its -view (resp. -view)  can point. If it points to , then the active strategy
asks for its argument which corresponds to the second reduction case. If it points to some element  of its context, the active strategy calls the -th
element of its context: this is the first reduction case, putting the subtree  in head position. The rest of the proof consists in technical verifications,
to check that the new triple  is such that .
\end{proof}

The result above will be sufficient for our purpose. Let us mention in passing that the connection between visible pointer structures
and agents is in fact tighter: a reduction chain starting from a triple  can also be canonically mapped to a pointed visible pointer structure in ,
and the two translations are inverse of one another. The interested reader is directed to \cite{phd}.

Before going on to the study of the rewriting rules introduced above, let us give a last simplification. If  and  are agents,
then  will denote the agent obtained by appending  as a new son of the root of  with label , \emph{i.e.} .
Consider the following non-deterministic rewriting rule on agents:

Both rewriting rules on triples  are actually instances of this reduction, by the isomorphism . We let the obvious verification
to the reader. This is helpful, as all that remains to study is this reduction on agents illustrated in Figure \ref{rewrite}. To summarize, if  denotes the length of the longest reduction sequence
starting from an agent , we have the following property.

\begin{proposition}
Let , , then .
\label{equiv}
\end{proposition}
\begin{proof}
Obvious from the simulation lemma, adding  for the initial move which is not accounted for by the reduction on agents. In fact this is an equality, as one can prove using the \emph{reverse} simulation
lemma mentioned above. See \cite{phd}.
\end{proof}

\begin{figure}

\caption{Rewriting rule on agents}
\label{rewrite}
\end{figure}

\section{Length of interactions}

The goal of this section is to study the reduction on agents introduced above, and to estimate its maximal length. We will first provide an upper bound for this length, adapting a 
method used by Beckmann \cite{beckmann2001exact} to estimate the maximal length of reductions on simply typed -calculus. We will then discuss the question of lower bounds, and finally
describe an application to head linear reduction.

\subsection{Upper bound}

We define on agents a predicate , which introduction rules are compatible both with syntax and reduction.

\begin{definition}
The predicate  (where  range over natural numbers) is defined on agents in the following inductive way.
\begin{itemize}
\item \textsc{Base.} 
\item \textsc{Red.} Suppose . Then if for all  such that  we have  and if
we also have , then .
\item \textsc{Cut.} If ,  and , then .
\end{itemize}
\end{definition}

By this inductive definition, each proposition  is witnessed by a tree using \textsc{Base}, \textsc{Red} and \textsc{Cut}. \textsc{Red}-free trees look like
syntax trees, are easy to build but give few information on the reduction, whereas \textsc{Cut}-free trees look like reduction trees, are difficult to build but give very accurate information
on the length of reduction. The idea of the proof is then to design an automatic way to turn a \textsc{Red}-free tree to a \textsc{Cut}-free tree, \emph{via} a cut elimination lemma.
Let us now give the statement and sketch the proof of the four important lemmas that underlie our reasoning.

A \textbf{context-agent}  is a finite tree whose edges are labelled by natural numbers, and whose nodes are labelled either by natural numbers, or by the variable , with the constraint that
all edges leading to  must be labelled by the same number ;  is called the \textbf{type} of  in . If
We denote by  the result of substituting of all occurrences of  in  by . We denote by  the agent obtained by deleting in 
all occurrences of , along with the edges leading to them.


\begin{lemma}[Substitution lemma]
If ,  and  (where  is the type of  in ), then 
\label{main_substitution}
\end{lemma}
\begin{proof}
We prove by induction on the tree witness for  that the above property is true for all context-arena  such that . The way
to handle each case is essentially forced by the induction hypothesis.
\end{proof}

\begin{lemma}[Cut elimination lemma]
Suppose . Then if , . Otherwise, .
\end{lemma}
\begin{proof}
By induction on the witness for , using the substitution lemma when the last rule is \textsc{Cut} with a type of .
\end{proof}

\begin{lemma}[Recomposition lemma]
Let  be an agent. Then , where  is the maximal label of an edge in ,  is the maximal label of a node and  is the number of nodes.
\end{lemma}
\begin{proof}
By induction on .
\end{proof}

\begin{lemma}[Bound lemma]
Let  be an agent, then if , .
\end{lemma}
\begin{proof}
The only used rules are \textsc{Base}, \textsc{Red} and \textsc{Cut} with . These \textsc{Cut} rules do not add any possible reduction and are easy to eliminate, then the lemma
is easily proved by induction on .
\end{proof}

These lemmas are sufficient to give a first upper bound, by iterating the cut elimination lemma starting from the witness tree for  generated by the recomposition lemma. However when the
type is small, some of the lemmas above can be improved. For instance if ,  and the type of  in  is , then , 
since once the reduction reaches  it will never enter  again. Using this we get a ``base" cut-elimination lemma, stating that for all , whenever  then we have actually 
 instead of . Using this, we prove the following.

\begin{theorem}[Upper bound]
Let  denote the highest edge label in ,  means the highest node label and  means the number of nodes of . Then if  and  we have:

For the particular case when  and if  we have:

\end{theorem}
\begin{proof}
Both proofs are rather direct. For the first part, by the recomposition lemma we have . It suffices then to apply  times
the cut elimination lemma, then use the ``base" cut-elimination lemma to eliminate the remaining cuts. For the second part we reason likewise, but rely on the substitution lemma instead of the recomposition
lemma to get , which gives . But we have  by Proposition \ref{equiv}, which concludes the proof.
\end{proof}

Note that whereas the bounds in \cite{beckmann2001exact} are asymptotic and give poor quantitative information if instantiated on small types, our bound does provide valuable information on interactions with
small depth. For instance, if  and  such that ,
 and the depth of  is at most , then no interaction between  and  can be longer than . As we will see below, this can not be significantly improved.
In fact, we conjecture that for all  and , we have  : this was found and machine-checked for all  thanks to an implementation of agents and their
reduction, unfortunately we could not prove its correctness, nor generalize it to higher depths.


\subsection{Lower bound}

As argued in the introduction, the upper bound above applies to several programming languages executed by head linear reduction, possibly featuring non determinism and/or ground type references, therefore the fact that
we used game semantics to prove it increases its generality. On the other hand, if we try to give the closest possible lower bound for  using the full power of visible pointer structures, we would get a lower
bound without meaning for most languages concerned by the upper bound, since pointer structures have no innocence or determinism requirements\footnote{Our experiments with pointer structures and agents confirmed indeed that the
possibility to use non-innocent behaviour does allow significantly longer plays.}. Therefore what makes more sense is to describe a lower bound in the more restricted possible framework, \emph{i.e.}
simply typed -calculus.


We won't detail the construction much, as the method is standard and does not bring a lot to our analysis. The idea is to define higher types for church integers by  and . Then, 
denoting by  the church integer for  of type , we define . We apply then  to  to get a term whose head linear
reduction chain has at least  steps. In game semantics,  has size  and all other components have size smaller than , the depth of the ambient arena being . The function  being
monotonically increasing in all its parameters we have the following inequalities for , both bounds making sense for all programming languages containing the simply-typed -calculus and whose 
terms can be interpreted as bounded strategies.

Note that from this we can deduce bounds for , when we have no information on the depth of the ambient arena. Indeed, we always have  and  because a pointer chain in a play
is visible by both players. Thus, .

\subsection{Application to head linear reduction}

Earlier works on game semantics \cite{danosregnier} suggest that in every games model of a programming language lies a hidden notion of linear reduction, head linear reduction
when modelling call-by-name evaluation: this is the foundation for our claim that our game-theoretic result is really about the length of execution in programming languages whose terms can
be described as bounded strategies. Of course it requires some work to interface execution in these programming languages to our game-theoretic results, and part of this work has to be redone in each case. 
To illustrate this, we now describe how to extract from our results a theorem about the length of head linear reduction sequences in simply-typed -calculus. For the formal definition of head linear reduction, the reader
is directed to \cite{danos:abstract}. If  is a -term then the \textbf{spinal height} of  is the quantity  defined by induction as ,  and ; when  is a -normal form,  is nothing but the height of its Bรถhm tree.
The \textbf{height} of  is the subtly different quantity\footnote{One can easily prove that on closed terms, it is always less than the more common notion of height defined as
,  and , for which our upper bound consequently also holds.}  defined by ,  and . Finally, the
\textbf{level} of a type  is defined by  and  and the \textbf{degree}  of a term is the maximal level of the type of all subterms
of .


A \textbf{game situation} \cite{phd} is the data of -terms  and  in -long -normal form, and we are interested
in the term .  Our game-theoretic results
apply immediately to game situations, because of the connection between game-theoretic interaction and head linear reduction \cite{danosregnier}:
if  denotes the length of the head linear reduction chain of , then we have 
 where
 is the depth of the arena corresponding to ,  is the size of  and  is the maximal size of all of the . But since  and  are already in -long
-normal form, we have  and . Thus, we conclude that in the case of a game situation we have:

Outside of game situations, it is less obvious to see how our results apply. The more elegant approach would be probably to extend the connection between head linear reduction
and game semantics to \emph{revealed} game semantics, which would give the adequate theoretical foundations to associate an agent to any -long -term. Without
these tools, we can nonetheless apply the following hack. Suppose we have a -term . The idea is to ``delay" all redexes, replacing each redex  of type  in  with 
, where we add a new symbol  for each pair . We iterate this operation until we reach a -normal -term , which satisfies .
We then expand  to its -long form , which satisfies . We consider now the term , 
where each  binds one of the new symbols , and  is the (-long form of) the corresponding evaluation -term. We recognise here a game situation, whose head linear
reduction chain is necessarily longer than for  (we have only added steps due to the delaying of redexes and -expansion). Using the inequality above for game situations, we conclude:


\section{Conclusion \& future work}

Applied to head linear reduction on simply typed -calculus, our results show that the price of linearity is not as high as one might expect. 
Not only the bounds remain in , but they are only slightly higher than those for usual -reduction: in particular, the height 
of the tower of exponentials is the same.

A strength of our method is that it is not restricted to -calculus; the results should indeed immediately apply as well to similar notions of reduction on other total
programming languages. Beyond ground type references and non determinism, there are also games model of call-by-value languages \cite{abramsky-mccusker:families} generating pointer structures as well, thus this work should also provide
bounds for the corresponding call-by-value linear reduction (\emph{tail} linear reduction?). All the tools used here also can be extended to \emph{non-alternating plays} \cite{DBLP:conf/concur/Laird05}, which suggests that this work could
be used to give bounds to the length of reductions in some restricted concurrent languages.

We also believe \emph{agents} are worth studying further. Their combinatorial nature and their connection to execution of programs may prove interesting for the study of higher order systems with restricted complexity, 
such as \emph{light} linear logics \cite{DBLP:journals/iandc/Girard98}. For instance, proofs typable in light systems may correspond to agents with some restricted behaviours, which would make them a valuable tool for 
the study of programming languages with implicit complexity.

\paragraph{Acknowledgements.} This work was partially supported by the French ANR project CHOCO. The author also would like to thank Fabien Renaud for interesting discussions on related subjects.





\begin{thebibliography}{10}

\bibitem{abramsky-mccusker:active-algol}
Samson Abramsky and Guy McCusker.
\newblock {Linearity, Sharing and State: a Fully Abstract Game Semantics for
  Idealized Algol with active expressions}, 1997.

\bibitem{abramsky-mccusker:families}
Samson Abramsky and Guy McCusker.
\newblock Call-by-value games.
\newblock In Mogens Nielsen and Wolfgang Thomas, editors, {\em 6th Annual
  Conference of the European Association for Computer Science Logic}, volume
  1414 of {\em Lecture Notes in Computer Science}. Springer, 1998.

\bibitem{beckmann2001exact}
A.~Beckmann.
\newblock {Exact bounds for lengths of reductions in typed -calculus}.
\newblock {\em Journal of Symbolic Logic}, 66(3):1277--1285, 2001.

\bibitem{blum2008thesis}
W.~Blum.
\newblock {\em {Thesis fascicle: Local computation of -reduction}}.
\newblock PhD thesis, {University of Oxford}, 2008.

\bibitem{phd}
Pierre Clairambault.
\newblock {\em {Logique et Interaction : une รtude Sรฉmantique de la
  Totalitรฉ}}.
\newblock PhD thesis, {Universitรฉ Paris Diderot}, 2010.

\bibitem{totality}
Pierre Clairambault and Russ Harmer.
\newblock {Totality in arena games}.
\newblock {\em Annals of Pure and Applied Logic}, 2009.

\bibitem{coquand}
Thierry Coquand.
\newblock A semantics of evidence for classical arithmetic.
\newblock {\em Journal of Symbolic Logic}, 60(1):325--337, 1995.

\bibitem{danosregnier}
Vincent Danos, Hugo Herbelin, and Laurent Regnier.
\newblock Game semantics and abstract machines.
\newblock In {\em 11th IEEE Symposium on Logic in Computer Science}, pages
  394--405, 1996.

\bibitem{danos:abstract}
Vincent Danos and Laurent Regnier.
\newblock {How abstract machines implement head linear reduction}.
\newblock Unpublished, 2003.

\bibitem{de1987generalizing}
N.G. de~Bruijn.
\newblock {Generalizing Automath by means of a lambda-typed lambda calculus}.
\newblock {\em Mathematical Logic and Theoretical Computer Science},
  106:71--92, 1987.

\bibitem{DBLP:journals/iandc/Girard98}
Jean-Yves Girard.
\newblock Light linear logic.
\newblock {\em Inf. Comput.}, 143(2):175--204, 1998.

\bibitem{greenland2004game}
W.~Greenland.
\newblock {\em {Game semantics for region analysis}}.
\newblock PhD thesis, {University of Oxford}, 2004.

\bibitem{harmer2004innocent}
Russ Harmer.
\newblock {Innocent game semantics}.
\newblock {\em Lecture notes}, 2004--2007.

\bibitem{hhm}
Russ Harmer, Martin Hyland, and Paul-Andr{\'e} Melli{\`e}s.
\newblock Categorical combinatorics for innocent strategies.
\newblock In {\em IEEE Symposium on Logic in Computer Science}, pages 379--388,
  2007.

\bibitem{DBLP:conf/lics/HarmerM99}
Russ Harmer and Guy McCusker.
\newblock A fully abstract game semantics for finite nondeterminism.
\newblock In {\em IEEE Symposium on Logic in Computer Science}, pages 422--430,
  1999.

\bibitem{hyland-ong}
Martin Hyland and C.-H.~Luke Ong.
\newblock On full abstraction for {PCF}: {I}, {II} and {III}.
\newblock {\em Information and Computation}, 163(2):285--408, December 2000.

\bibitem{krivine1985interpreteur}
Jean-Louis Krivine.
\newblock {Un interpr{\'e}teur du -calcul}.
\newblock {\em Unpublished}, 1985.

\bibitem{DBLP:conf/csl/LagoL08}
Ugo~Dal Lago and Olivier Laurent.
\newblock Quantitative game semantics for linear logic.
\newblock In {\em CSL}, pages 230--245, 2008.

\bibitem{DBLP:conf/lics/Laird97}
James Laird.
\newblock Full abstraction for functional languages with control.
\newblock In {\em IEEE Symposium on Logic in Computer Science}, pages 58--67,
  1997.

\bibitem{DBLP:conf/concur/Laird05}
James Laird.
\newblock A game semantics of the asynchronous -calculus.
\newblock In {\em CONCUR}, pages 51--65, 2005.

\bibitem{DBLP:journals/tcs/MascariP94}
Gianfranco Mascari and Marco Pedicini.
\newblock Head linear reduction and pure proof net extraction.
\newblock {\em Theoretical Computer Science}, 135(1):111--137, 1994.

\bibitem{fpc2000}
Guy McCusker.
\newblock {Games and Full Abstraction for FPC}.
\newblock {\em Information and Computation}, 160(1-2):1--61, 2000.

\bibitem{nakajima1975infinite}
R.~Nakajima.
\newblock {Infinite normal forms for the -calculus}.
\newblock {\em -Calculus and Computer Science Theory}, pages 62--82,
  1975.

\bibitem{schwichtenberg1982complexity}
H.~Schwichtenberg.
\newblock {Complexity of normalization in the pure typed lambda-calculus}.
\newblock {\em Studies in Logic and the Foundations of Mathematics},
  110:453--457, 1982.

\end{thebibliography}

\newpage

\appendix

\section{pointer structures and rewriting}

\begin{lemma}
Let  be a pointed visible pointer structure and  an agent such that . Then
if , .
\label{lem_point}
\end{lemma}
\begin{proof}
Let us suppose without loss of generality that  is an Opponent move; the other case can be obtained just by switching Player/Opponent and -views/-views
everywhere. Then  being a Player move, we have to check first that , \emph{i.e.}

We use that , \emph{i.e.}

But , hence  and the inequality is obvious. We need now to examine
the context of . Since  is a Player move, it is defined as the set  of Player moves appearing in
, which is also the set of Player moves appearing in  and therefore the co-context of . But ,
hence for all  we have  which is exactly what we needed.
\end{proof}

\begin{proposition}[Simulation]
Let , then if  is defined, there exists  such that .
\end{proposition}
\begin{proof}
Suppose .
Let  be the context of . By visibility,  must either point to  or to an element of the context. Let us
distinguish cases.
\begin{itemize}
\item If , then we claim that , \emph{i.e} ,
 and the depth of  relative to  is at most . For the first part, we use
that  : in particular,  and since  this implies by Lemma \ref{lem_point} that .
For the second part, we must first check that . Let us suppose without loss of generality that  is an Opponent move, all the
reasoning below can be adapted by switching Player/Opponent and -views/-views everywhere. We want to prove:

But since , we already know:

Thus we only need to remark that  since  is a Player move.
Now, we must examine the co-context of , but by definition of -view it is  where 
is the context of . Since  we have as required  for each 
and  because . For the third part, we have to prove that the depth of  relative to  is at most , but
it is obvious since the depth relative to  is at most  and .

\item Otherwise, we have  for . Then, we claim
that . We do have
 because , thus  and  by Lemma \ref{lem_point}.
It remains to show that  and that the depth of  relative to  is at most , but
the proofs are exactly the same as in the previous case.
\end{itemize}
\end{proof}



\section{Upper bound}

\begin{lemma}[Monotonicity]
If , then  for all  and .
\label{monotonicity}
\end{lemma}
\begin{proof}
By induction on .
\end{proof}

\begin{lemma}[Null substitution lemma]
If  and the type of  in  is , then for all agent  we still have . Moreover, the witness includes as many \textsc{Cut} rules
as for .
\label{first_substitution}
\end{lemma}
\begin{proof}
We prove by induction on the tree witness for  that the above property is true for all context-arena  such that .
\begin{itemize}
\item \textsc{Base.} The root of  is , hence the result is trivial.
\item \textsc{Red.} Suppose  has the form , where  possibly include occurrences of  (the case where  appears as a son
of the root encompasses the other). The premises of \textsc{Red} are then that for  such that
, 
and . The induction hypothesis on these premises give witnesses for the two following properties:


All the possible reductions are already covered since , thus by \textsc{Red} we have  as required.
\item \textsc{Cut.} Let us suppose  is obtained by \textsc{Cut}, hence  has the form . Let us suppose
that  has the form , since once again the case where  is a child of the root of  encompasses the other. The premises of \textsc{Cut} are then
 and , and . Note now that we also have , therefore
the induction hypothesis on  along with  and  implies that
. But by induction hypothesis we also have , hence by \textsc{Cut}:

Which was what was required for , thus it suffices since trees are considered up to permutation.
\end{itemize}
\end{proof}

\begin{lemma}[Main substitution lemma]
If ,  and  (where  is the type of  in ), then 
\label{main_substitution}
\end{lemma}
\begin{proof}
We prove by induction on the tree witness for  that the above property is true for all context-arena  such that .
\begin{itemize}
\item \textsc{Base.} The root of  is , hence the result is trivial.
\item \textsc{Red.} Suppose  has the form , where  possibly include occurrences of  (the case where  appears as a son
of the root encompasses the other). The premises of \textsc{Red} are then that for  such that
, 
and . The induction hypothesis on these premises give witnesses for the two following properties:


By hypothesis we have , hence by \textsc{Cut} (since ), we have:

Using (\ref{eq1}) for all , (\ref{eq2}) (adjusted to  by Lemma \ref{monotonicity}) and (\ref{eq3}) we deduce by \textsc{Red} that

Which is what was required.
\item \textsc{Cut.} Let us suppose  is obtained by \textsc{Cut}, hence  has the form . Let us suppose
that  has the form , since once again the case where  is a child of the root of  encompasses the other. The premises of \textsc{Cut} are then
 and , and . Note now that we also have , therefore
the induction hypothesis on  along with  and  implies that
. But by induction hypothesis we also have , hence by \textsc{Cut}:

Which was what was required for , thus it suffices since trees are considered up to permutation.
\end{itemize}
\end{proof}



\begin{lemma}[Cut elimination lemma]
Suppose . Then if , . Otherwise, .
\end{lemma}
\begin{proof}
By induction on the tree witness for .
\begin{itemize}
\item \textsc{Base.} Trivial.
\item \textsc{Red.} Suppose , the premises of \textsc{Red} are
 for all  and .
If , then it follows by induction hypothesis that  and
, which implies by \textsc{Red} and Lemma \ref{monotonicity} that . If , then
the premises of \textsc{Red} are  for all  and . By induction
hypothesis this is still true with  instead of , thus by \textsc{Red} we have  which is what we needed to prove.
\item \textsc{Cut.} Suppose , the premises of \textsc{Cut} are ,  and . If 
then by induction hypothesis it follows that  and , in particular if we define a context-agent  we have
, hence by the substitution lemma (since ) we have
, thus  thanks to Lemma \ref{monotonicity} (since it is always true
than ).
If  then by induction hypothesis we have  and . We use then the substitution lemma (since ) to get , which
is stronger that what was required whatever was the value of . The last remaining case is when  and , then by induction hypothesis  and ,
thus by the substitution lemma we have as required .
\end{itemize}
\end{proof}

\begin{lemma}[Recomposition lemma]
Let  be an agent. Then:

Where  is the maximal label of an edge in ,  is the maximal label of a node and  is the number of nodes.
\end{lemma}
\begin{proof}
First, let us show that the following rule \textsc{Base'} is admissible, for any  and .

If  this is exactly \textsc{Base}. Otherwise we apply \textsc{Red}. There is no possible reduction, so the only thing we have to prove is , which
is provided by the induction hypothesis. Then we prove the lemma by immediate induction on , using only \textsc{Base'}, \textsc{Cut} and Lemma \ref{monotonicity}.
\end{proof}

From now on, let  denote the longest reduction sequence of . We also use the notations  and  for iterated exponentials.

\begin{lemma}[Bound lemma]
Let  be an agent, then if , .
\label{bound}
\end{lemma}
\begin{proof}
First of all we prove that if there is a witness for , then it can be supposed \textsc{Cut}-free: this is proved by induction on , eliminating
each use of \textsc{Cut} by Lemma \ref{first_substitution}. Then, by induction on the \textsc{Cut}-free witness tree for :
\begin{itemize}
\item \textsc{Base.} Then, the root of  is , thus ; there is nothing to prove.
\item \textsc{Red.} The premises of  include in particular that for all  such that , we have . By induction hypothesis, this
means that for all such  we have , hence .
\end{itemize}
\end{proof}

From all this, it is possible to give a first upper bound by using the recomposition lemma, then iterating the cut elimination lemma. However, we will first prove here a refined version of the
cut elimination lemma when , which will allow to decrease by one the height of the tower of exponentials. First, we need the following adaptation of the substitution lemma:

\begin{lemma}[Base substitution lemma]
If ,  and the type of  in  is , then .
\label{specialized_substitution}
\end{lemma}
\begin{proof}
We prove by induction on the tree witness for  that the above property is true for all context-arena  such that .
\begin{itemize}
\item \textsc{Base.} The root of  is , hence the result is trivial.
\item \textsc{Red.} Suppose  has the form , where  possibly include occurrences of  (the case where  appears as a son
of the root encompasses the other). The premises of \textsc{Red} are then that for  such that
, 
and . The induction hypothesis on these premises give witnesses for the two following properties:


By hypothesis we have , hence by Lemma \ref{first_substitution} (since ) we have

Hence, using (\ref{eq4}) for all , (\ref{eq5}) and (\ref{eq6}) (adjusted to  by Lemma \ref{monotonicity}) we deduce by \textsc{Red} that

Which is what was required.
\item \textsc{Cut.} Let us suppose  is obtained by \textsc{Cut}, hence  has the form . Let us suppose
that  has the form . The premises of \textsc{Cut} are then
 and . Note now that we also have , therefore
the induction hypothesis on  along with  implies that
 and all that remains is to substitute  in . But since the type of  is , Lemma \ref{first_substitution} proves
that , which concludes since trees are considered up to permutation.
\end{itemize}
\end{proof}

\begin{lemma}[Base cut elimination lemma]
If , then .
\label{specialized_cut_elim}
\end{lemma}
\begin{proof}
By induction on the witness tree for .
\begin{itemize}
\item \textsc{Base.} Trivial.
\item \textsc{Red.} Suppose  has the form . The premises of \textsc{Red} are that for all  we have
 and . The result is then
trivial by induction hypothesis and \textsc{Red}.
\item \textsc{Cut.} Suppose  with , the premises of \textsc{Cut} are that  and . If , then the result
is trivial by the induction hypothesis and \textsc{Cut}. If , we just apply Lemma \ref{specialized_substitution} instead of \textsc{Cut}.
\end{itemize}
\end{proof}

\begin{theorem}[Upper bound]
Let  denote the highest edge label in ,  means the highest node label and  means the number of nodes of . Then if  and  we have:

For the particular case when  and if  we have:

\end{theorem}
\begin{proof}
Let us first prove the first part. By the recomposition lemma, we have . By  iterations of the cut elimination lemma, we have
. But then by Lemma \ref{specialized_cut_elim} we also have . By Lemma \ref{bound}, this
implies as required that . We turn now to the second part. Obviously, we have  and . By the
substitution lemma, this implies that . By  applications of the cut elimination lemma, and one application of Lemma \ref{specialized_cut_elim}, this means
that  hence .
\end{proof}





\end{document}
 
\end{document}
