\documentclass{LMCS}

\def\dOi{11(1:20)2015}
\lmcsheading {\dOi}
{1--33}
{}
{}
{Feb.~28, 2014}
{Mar.~31, 2015}
{}

\ACMCCS{[{\bf Theory of computation}]: Semantics and
  reasoning---Program reasoning---Program verification; [{\bf Software
      and its engineering}]: Software organization and
  properties---Software functional properties---Formal
  methods---Software verification}

\subjclass{D.2.4 [Software/Program Verification]; 
  F.3.1 [Specifying and Verifying and Reasoning about Programs]}

\usepackage{amsmath,amssymb}
\usepackage{color}
\usepackage[noend]{algpseudocode}


\usepackage{tikz}
\usetikzlibrary{shapes.symbols}

\algrenewcommand\algorithmicindent{1.0em}

\newcommand{\TODO}[1]{\textcolor{red}{\textbf{[TODO: #1]}}}
\newcommand{\COMMENT}[1]{}
\newcommand{\defeq}{\;\stackrel{\rm def}{=}\;}

\newcommand{\NULL}{\ensuremath{\mathtt{NULL}}}
\newcommand{\hwqueue}{Herlihy\&Wing queue}
\newcommand{\enq}{\ensuremath{\mathtt{enq}}}
\newcommand{\deq}{\ensuremath{\mathtt{deq}}}
\newcommand{\false}{\mathsf{false}}
\newcommand{\true}{\mathsf{true}}
\newcommand{\assume}{\mathsf{assume}}
\newcommand{\Prg}{\mathit{Prg}}
\newcommand{\ndchoice}{\sqcup}
\newcommand{\bigndchoice}{\bigsqcup}

\newcommand{\remPending}[1]{\ensuremath{\mathit{remPending}({#1})}}
\newcommand{\Match}{\ensuremath{\mathit{Match}}}
\newcommand{\Compl}[1]{\ensuremath{\mathit{Compl}({#1})}}
\newcommand{\Deq}[1]{\ensuremath{\mathit{Deq}({#1})}}
\newcommand{\Enq}[1]{\ensuremath{\mathit{Enq}({#1})}}
\newcommand{\Before}[2]{\ensuremath{\mathit{Before}({#1},{#2})}}
\newcommand{\After}[2]{\ensuremath{\mathit{After}({#1},{#2})}}
\newcommand{\Val}[2]{\ensuremath{\mathit{Val}_{#1}({#2})}}

\newcommand{\uid}{\ensuremath{\mathit{uid}}}
\newcommand{\ltsq}{\ensuremath{{\mathsf{LTS}}_Q}}
\newcommand{\qtrans}[1]{\ensuremath{\xrightarrow{#1}}}
\newcommand{\compl}{\ensuremath{\hat}}
\newcommand{\mus}{\mu_{\rm seq}}
\newcommand{\permeq}{\sim_{\rm perm}}
\newcommand{\seqx}[2]{\ensuremath{#1\langle #2\rangle}}
\newcommand{\enqset}{\ensuremath{\mathtt{Enq}}}
\newcommand{\deqset}{\ensuremath{\mathtt{Deq}}}
\newcommand{\qbehavset}{\ensuremath{\mathcal{Q}}}
\newcommand{\qbehavsetx}[1]{\ensuremath{\qbehavset_{#1}}}
\newcommand{\obsequiv}{\ensuremath{\equiv_{\mathit{obs}}}}

\newcommand{\Bad}[2]{\ensuremath{\mathit{Bad}(#1,#2)}}
\newcommand{\Badx}[3]{\ensuremath{\mathit{Bad}_{#3}(#1,#2)}}
\newcommand{\dhat}{\ensuremath{d_{\bot}}}
\newcommand{\Dhat}{\ensuremath{D_{\dhat}}}
\newcommand{\Ehat}{\ensuremath{E_{\dhat}}}



\newcommand\inpar[1]{\left(\begin{array}{@{}l@{}}#1\end{array}\right)}
\newcommand\inatom[1]{\left\langle\begin{array}{@{}l@{}}#1\end{array}\right\rangle}

\newcommand\mylabel[1]{\label{#1}}


\newcommand{\VFresh}{\ensuremath{\mathsf{VFresh}}}
\newcommand{\VRepet}{\ensuremath{\mathsf{VRepet}}}
\newcommand{\VOrd}{\ensuremath{\mathsf{VOrd}}}
\newcommand{\VWit}{\ensuremath{\mathsf{VWit}}}
\newcommand{\POrd}{\ensuremath{\mathsf{POrd}}}
\newcommand{\PWit}{\ensuremath{\mathsf{PWit}}}

\begin{document}

\title[Aspect-Oriented Linearizability Proofs]{Aspect-Oriented Linearizability Proofs\rsuper*}

\author[S.~Chakraborty]{Soham Chakraborty\rsuper a}
\address{{\lsuper{a,d}}MPI-SWS, Kaiserslautern and Saarbr\"ucken, Germany}
\email{\{sohachak,viktor\}@mpi-sws.org}

\author[T.~A.~Henzinger]{Thomas A. Henzinger\rsuper b}
\address{{\lsuper b}IST Austria, Klosterneuburg, Austria}
\email{tah@ist.ac.at}

\author[A.~Sezgin]{Ali Sezgin\rsuper c}
\address{{\lsuper c}University of Cambridge Computer Laboratory, Cambridge, U.K.}
\email{as2418@cam.ac.uk}

\author[V.~Vafeiadis]{Viktor Vafeiadis\rsuper d}
\address{\vspace{-18 pt}}


\keywords{Linearizability, Queue, Verification, Herlihy-Wing Queue}
\titlecomment{{\lsuper*}A preliminary version of this article appeared at CONCUR'13.}

\begin{abstract}
Linearizability of concurrent data structures is usually proved by monolithic
simulation arguments relying on the identification of the so-called linearization points.
Regrettably, such proofs, whether manual or automatic, are often complicated
and scale poorly to advanced non-blocking concurrency patterns, such as helping
and optimistic updates.

In response, we propose a more modular way of checking linearizability of
concurrent queue algorithms that does not involve identifying linearization
points.  We reduce the task of proving linearizability
with respect to the queue specification to establishing four basic
properties, each of which can be proved independently by simpler
arguments.  As a demonstration of our approach, we verify the Herlihy and Wing
queue, an algorithm that is challenging to verify by a simulation
proof.  

\end{abstract}

\maketitle



\section{Introduction}
\label{sec:introduction}

Linearizability~\cite{HW1990} is widely accepted as the standard correctness
requirement for concurrent data structure implementations.
It amounts to showing that each method provides the illusion that it {\em executes} atomically at some point after its call and before its return.
Typically, what each method is expected to do (atomically) is given in terms of a sequential specification.
For instance, an unbounded queue must support the following two methods: 
\emph{enqueue}, which extends the queue by appending one element to its end, 
and \emph{dequeue}, which removes and returns the first element of the queue.

The standard way to prove that a concurrent queue implementation is linearizable is
to show that it is simulated by the idealised atomic queue implementation, 
which we take to be the specification of the queue.
For example, using forward simulation~\cite{LV1995}, we have to define 
a relation  relating the state of the implementation to the state of the specification,
and to show that 
(1) the initial states of the implementation and the specification are related by , and 
(2) starting from -related implementation and specification states , 
if the implementation takes a step and goes to state , 
the specification can also take a matching step (or stutter) and 
result in some state  that is -related to .
The most important part of these proofs is to decide which of the implementation steps
are matched by actual steps of the specification code and which by stuttering moves.
For each method of the implementation, the step during its execution that in the 
simulation proof is matched by the atomic step of the corresponding method of the 
specification is known as the \emph{linearization point}.
A well-established approach (e.g.~\cite{AHH+2013,ARR+2007,CDG2005,DSW2011,DM2009,LCL+2009,SWD2012,Vaf2009,Vaf2010})
is therefore to identify these linearization points, 
which when performed by the implementation change the state of the specification, 
and to then construct a suitable forward or backward simulation.

While for a number of concurrent algorithms, spotting the
linearization points may be straightforward (and has even been automated to some extent~\cite{Vaf2010}), 
in general specifying the linearization points can be very difficult. 
For instance, in implementations using a helping mechanism, they can lie in code not syntactically belonging to the thread and operation in question, and can even depend on future behavior.
There are numerous examples in the literature, where this is the case;
to mention only a few concurrent queues: 
the Herlihy and Wing queue~\cite{HW1990},
the optimistic queue~\cite{LS2004}, 
the elimination queue~\cite{MNS+2005}, 
the baskets queue~\cite{HSS2007}, 
the flat-combining queue~\cite{HIS+2010}.

\subsection*{The Herlihy and Wing Queue}\hfill
\label{subsec:HWQ}
\begin{figure}[h!]
\centering\begin{tabular}{@{}l@{~~}|@{~~}l@{}}
\begin{minipage}[t]{.37\textwidth}
\begin{algorithmic}[1]
 \State 
 \State 
 \Statex \qquad
 \Statex
 \Procedure{}{}
  \State 
  \hfill 
   \State 
   \hfill 
 \EndProcedure
\algstore{mybreak}
\end{algorithmic}
\end{minipage}
&
\begin{minipage}[t]{.55\textwidth}
\vskip 0em
\begin{algorithmic}[1]
\algrestore{mybreak}
 \Procedure{}{{}} 
  \While{true}
   \State  
   \hfill 
  \For{ \textbf{to} }
    \State 
   \hfill 
   \If{} \Return 
   \EndIf
  \EndFor
 \EndWhile
 \EndProcedure
\end{algorithmic}
\end{minipage}
\end{tabular}
\caption{Herlihy and Wing queue~\cite{HW1990}.}\label{fig:hw-queue}
\end{figure}



In this paper, we focus on the Herlihy and Wing queue~\cite{HW1990} (henceforth, HW queue for short)
that illustrates nicely the difficulties encountered when defining a simulation relation based on linearization points.
We recall the code of the queue as given in \cite{HW1990} in Figure~\ref{fig:hw-queue}.
The queue is represented as a pre-allocated unbounded array, , initially filled with s, 
and a marker, , pointing to the end of the used part of the array.
Enqueuing an element is done in two steps: the marker to the end of the array is incremented (), thereby reserving a slot for storing the element, and then the element is stored at the reserved slot ().
Dequeue is more complex: it reads the marker (), and then searches from the beginning of the array up to the marker to see if it contains a non- element.
It removes and returns the first such element it finds (). 
If no element is found, dequeue starts again afresh.
Each of the four statements surrounded by  brackets and annotated 
by  or  for  is assumed to execute atomically.

We now show that verifying this algorithm by finding its linearization points is difficult.
Consider the following execution fragment, where  denotes context switches between concurrent threads,

which have threads  and  executing enqueue instances,  and  executing dequeue instances. 
At the end of this fragment,  is ready to dequeue the element enqueued by , and  is ready to dequeue the element enqueued by .
In order to define a simulation relation from this interleaving sequence to a valid sequential queue behavior, where operations happen in isolation, we have to choose the linearization points for the two completed enqueue instances. 
The difficulty lies in the fact that no matter which statements are chosen as the linearization points for the two enqueue instances, there is always an extension to the fragment inconsistent with the particular choice of linearization points. 
For instance, if we choose  as the linearization point for , then the extension 

requiring 's element be enqueued before that of 's, will be inconsistent.
If, on the other hand, we choose any statement which makes  linearize before , then the extension

requiring the reverse order of enqueueing will be inconsistent. 
This shows not only that finding the correct linearization points can be challenging,
but also that the simulation proofs will require to reason about the entire state of the
system,
as the local state of one thread can affect the linearization of another.


\subsection*{Our Contribution}

In our experience, this and similar tricks for reducing synchronization among threads so as to achieve better performance, make concurrent algorithms extremely difficult to reason about when one is constrained to establishing a simulation relation.
However, if two methods overlap in time, then the only thing enforced by linearizability is that their effects are observed in {\em some} and same order by all threads.
For instance, in the example given above, the simple answer for the particular ordering between the linearization points of the enqueue instances of  and , is that it does not matter!
As long as enqueue instances overlap, their values can be dequeued in any order.

Building on this observation, our contribution is to simplify linearizability proofs by modularizing them.
We reduce the task of proving linearizability to establishing four relatively
simple properties, each of which may be reasoned about independently.
In (loose) analogy to aspect-oriented programming, 
we are proposing ``aspect-oriented'' linearizability proofs for concurrent queues,
where each of these four properties will be proved independently.

So what are these properties?  A correct (i.e., linearizable)
concurrent queue:
\begin{enumerate}
\item must not allow dequeuing an element that was never enqueued;
\item must not allow the same element to be dequeued twice;
\item must not allow elements to be dequeued out of order; and
\item must correctly report whether the queue is empty or not.\footnote{The HW queue trivially satisfies the fourth property as it never reports
that the queue is empty.}
\end{enumerate}

Although similar properties were already mentioned by Herlihy and Wing~\cite{HW1990}, 
we for the first time prove that suitably formalized versions of these four properties
are not only necessary, but also sufficient, conditions for linearizability 
with respect to the queue specification, at least for what we call 
\emph{purely-blocking} implementations.
This is a rather weak requirement satisfied by all non-blocking implementations,
as well as by possibly blocking implementations, such as HW  method, whose
blocking executions do not modify the global state.


\subsection*{Paper Outline}

The rest of the paper is structured as follows:
Section~\ref{sec:back} recalls the definition of linearizability in terms of execution histories.
Section~\ref{sec:seqwit} develops an alternative characterization of legal queue behaviors, which is useful for our proofs.
Section~\ref{sec:conditions} formalizes the aforementioned four properties, and proves that they are necessary and sufficient conditions for proving linearizability of queues.
Section~\ref{sec:herlihy-wing} returns to the HW queue example and presents a detailed manual proof of its correctness by checking each of the properties separately.
Section~\ref{sec:checking} shows how the checking of these four properties can be automated by reducing them to non-termination of certain parametric programs.
Section~\ref{sec:cave} explains how we adapted \textsc{Cave}~\cite{Vaf2010} to prove these parametric programs non-terminating for the case of the HW queue.
Finally, in Section~\ref{sec:related-work} we discuss related work, and in Section~\ref{sec:conclusion} we conclude.

\subsection*{Differences from the Conference Paper}

This article is an extended version of our CONCUR'13 conference paper~\cite{HSV2013},
containing all the proofs of the lemmas and theorems mentioned in the paper.
Since the conference, we have also implemented a checker for the \VRepet\ property,
and have expanded the discussion of automation in Sections~\ref{sec:checking} 
and~\ref{sec:cave} to cover the verification of \VRepet.



\section{Technical Background}
\label{sec:back}

In this section, we introduce common notations that will be used throughout the paper and recall the definition of linearizability.

For any function  from  to  and , let .
Given two sequences  and , let  denote their concatenation, and let  hold if one is a permutation of the other.
We use  to refer to the  element in sequence ,
and  to refer to the subsequence of  containing all 
elements from position  to  inclusive.
We write  for the subsequence of  containing only
elements in the set .

\subsection*{Behaviors}

A {\em data structure}  is a pair , where  is the {\em data domain} and  is the {\em method alphabet}.
An {\em event} of  is a quadruple , for a unique event identifier, , a method , and data elements .
Intuitively,  denotes the application of method  with input argument  returning the output value .
Throughout the paper, we will assume that the  components of events are globally unique.
A duplicate-free sequence over events of  is called a {\em behavior}.
The {\em semantics} of data structure  is a set of behaviors, called {\em legal} behaviors.

The method alphabet  of a queue is the set .
We will take the data domain to be the set of natural numbers, , and a distinguished symbol {\NULL} not in .
Events are written as , short for , and , short for . For consiceness, we will often also omit the  superscripts.
Events with {\enq} are called {\em enqueue} events, and those with {\deq} are called {\em dequeue} events.
We use  and  to denote all enqueue and dequeue events, respectively.

We will use a labelled transition system, , to define the queue semantics.
The states of {\ltsq} are sequences over , the initial state is the empty sequence . 
There is a transition from  to  with action , written , if
(\textit{i})  and , or 
(\textit{ii})  and , or 
(\textit{iii})  and .

A {\em run} of {\ltsq} is an alternating sequence  of states and queue events such that for all , we have .
The trace of a run is the sequence  of the events occurring on the run.
A queue behavior  is \emph{legal} iff there is a run of {\ltsq} with trace .
In what follows, we will consider only legal queue behaviors, and hence usually omit {\em legal}, unless explicitly stated otherwise.
Let  denote the set of all (legal) queue behaviors.


\subsection*{Histories and Linearizability}

Each event  generates two {\em actions}: the {\em invocation} of , written as , and the {\em response} of , written as .
We will also use  and  to denote the invocation and the response actions, respectively. 
When a particular method  does not have an input (resp., output) parameter, we will write
 (resp., ) for the corresponding invocation (resp., response) action. 
We will also often omit the superscripts, when they are not important.

In this paper, a {\em history} of  is a sequence of invocation and response actions of . 
We will assume the existence of an implicit identifier in each history  that uniquely pairs each invocation with its corresponding response action, if the latter also occurs in .
A history  is {\em well-formed} if every response action occurs after its associated invocation action in .
We will consider only well-formed histories.
An event is {\em completed} in , if both of its invocation and response actions occur in .
An event is {\em pending} in , if only its invocation occurs in .
We define  to be the sub-sequence of  where all pending events have been removed.
An event  precedes another event  in , written , if the response of  occurs before the invocation of  in .
For event ,  denotes the set of all events that precede  in . 
Similarly,  denotes the set of all events that are preceded by  in .
Formally, 

A set of events  is {\em closed under } iff whenever  and , then .

History  is called {\em complete} if it does not have any pending events.
For a possibly incomplete history , a {\em completion} of , written , is a well-formed complete history such that  where  contains only response actions.
Let  denote the set of all completions of .

A history is called {\em sequential} if all invocations in it are immediately followed by their matching responses, with the possible exception of the very last action which can only be the invocation of a pending event.
We identify complete sequential histories with behaviors of  by mapping each consecutive pair of matching actions in the former to its event constructing the latter.
A sequential history  is a {\em linearization} of a history , if there exists  such that  and whenever  we have .

\begin{defi}[Linearizability~\cite{HW1990}]
A history  is linearizable with respect to a data structure  if
there exists a linearization of  that is a legal behavior of .
A set of histories  is linearizable with respect to  if 
every  is linearizable with respect to .
\end{defi}
An {\em execution trace} is a sequence of instruction labels coupled with thread identifiers executing the instruction.
For instance,  denotes the execution of instruction with the unique label  by thread .
An instruction label is the {\em entry} point of method , written , if it is the label of the first instruction of .
Similarly, an instruction label is an {\em exit} point of , written , if it is the label of an instruction that completes the execution of . 
Each execution trace  induces a history  which is obtained by replacing each  with , each  with , and removing the remaining symbols.
We assume that states of an execution trace contain enough information to deduce the values of  and  associated with each entry and exit point. 
To illustrate this definition, consider the following execution trace from the introduction:

The history corresponding to this trace is:

where we have used the thread identifiers without subscripts as unique event identifiers.
After completing the history with responses  and  of the pending enqueues, 
and removing the pending invocation , the history may be linearized as follows:

and corresponds to the (legal) behavior
.
An execution trace is {\em complete} if its induced history is complete.
An implementation is identified with the set of execution traces it generates. 
When clear from the context, we will refer to the induced history of an execution trace as a history of the implementation.

\section{Alternative Characterization of Legal Queue Behaviours}
\label{sec:seqwit}

We start with some terminology.
Let  be a history. 
 denotes the set of all enqueue events invoked (and not necessarily completed) in .
Similarly,  denotes the set of all dequeue events invoked in .
When  is a complete history, we define the value of an event , written , to be
the value enqueued or dequeued by that event.

We find it useful to express the semantics of queues in an alternative formulation.

\begin{defi}\mylabel{def:seqwit}
A queue behavior  has a {\em sequential witness} if there is a total mapping  from  to  such that
\begin{enumerate}[label=(\roman*)]
\item  implies , 
\item  iff ,
\item  implies ,
\item  implies ,
\item  implies ,
\item  implies .
\end{enumerate}
\end{defi}

\noindent To illustrate this definition, consider the following legal queue behavior:

We can pick  such that ,  and .
The constraints of Definition~\ref{def:seqwit} are satisfied because:
\begin{itemize}
\item  implies .
\item 
.
\end{itemize}

To show that a behavior is legal iff it has a sequential witness, we need a number of 
auxiliary definitions and lemmas.

We say that two queue behaviors  and  are {\em observationally equivalent}, written , 
if the sequences of enqueue events and those of dequeue events agree in both behaviors.
Formally,  iff  and .

We define a special subset of queue behaviors, the {\em canonical} subset , in which each enqueue event is immediately followed by its matching dequeue event, in case it exists.
Formally, the canonical queue behaviors are given by the following regular expression:

A run  of {\ltsq} is called {\em canonical} if the trace of  is canonical.

Note that every canonical behavior is legal. Consider a canonical behavior  
and split it into  
such that  does not end with an .
This behavior can be generated by the following run of the .


As the following result shows, canonical queue behaviors represent all legal behaviors, up to observational equivalence.

\begin{lem}\mylabel{lem:canonical-representative}
Let  be a legal queue behavior.
Then there exists a canonical behavior  such that .
\end{lem}

\proof
By induction on the length of .
The base case, where  trivially satisfies the condition since .
Now assume the claim holds for , and we have to prove it for .
By the induction hypothesis, there is a canonical behavior .
We observe that since  and  are legal and , their runs 
end in the same final state. Therefore, the fact that  is legal implies
that  is also legal.
We proceed by a case analysis of .
\begin{itemize}
\item . Then  is trivially also canonical.
\item .
We know that  cannot end in an enqueue event, or else the queue would not
be empty. Therefore  is canonical.
\item , with .
We know that  must be of the form  
where  does not end in a enqueue event and  contains only 
enqueue events.
Then, we take the behavior ,
which is both canonical and observationally equivalent to .
\qed
\end{itemize}

\noindent Moreover, canonical behaviors have a straightforward sequential witness.

\begin{lem}\mylabel{lem:canonical-seqwit}
Every canonical behavior  has a sequential witness .
\end{lem}
\proof
Let  be a canonical behavior.
We construct  by mapping all  to , and each  with  to its immediate predecessor.
By the definition of canonical behavior, each  in  is immediately preceded by .
Thus, the first four conditions are trivially satisfied.
If  and  is in , then by the definition of canonical behavior, we must have

for some sequences .
This implies that condition (v) is satisfied.
Finally, if , consider the sequence  obtained by projecting out all  events from .
That is, 

Then, by the definition of canonical behavior, we have
.
In other words,  has an equal number of  and  symbols, such that by construction .
This implies that condition (vi) is satisfied.
\qed



\begin{lem}\mylabel{lem:deq-after-enq}
If   is a legal queue behavior, then .
\end{lem}
\proof
By the definition of {\ltsq},  can happen at a state  if  for some sequence .
Again by definition, all runs of {\ltsq} reaching  must have a transition with label ; otherwise,  cannot occur in .
Since all legal behaviors have a corresponding run,  must hold.
\qed

Next, we show that observationally equivalent legal queue behaviors cannot reorder their  events.

\begin{lem}\mylabel{lem:obsequiv-deqnull}
If  and  are observationally equivalent legal queue behaviors, then  iff .
\end{lem}
\proof
Since  is a symmetric relation, we prove only one direction.
()
Consider the subsequences , , and their duals  and  for .
Note that each enqueue event increases by one the length of the sequence representing the state, each dequeue event decreases by one the length of the sequence representing the state, and  can only happen when the length of the sequence is zero ().
Then, the number of enqueue events in  and the number of non-{\NULL} dequeue events in  must be equal; let us call it .

Assume first that  is a proper prefix of .
This implies that  is a proper prefix of .
The  symbol in  is  because .
Then, the number of non-{\NULL} dequeue events preceding this  is , but the number of enqueue events preceding it, contained in , which is a proper prefix of , is strictly less than .
This contradicts the assumption that  is a legal queue behavior.
The case where  is a proper prefix of  follows a similar argument.

Now assume that  and .
Further assume  for some .
Because , the next dequeue event in  is necessarily .
This, however, contradicts that the fact that  is legal, 
because in a legal behavior  cannot immediately follow an enqueue event.
Therefore  for some  and because , we have that , as required.
\qed

Next, we show that given two observationally equivalent behaviors 
and a sequential witness for the first behavior, 
we can build a sequential witness for the other.

\begin{lem}\mylabel{lem:obsequiv-witness}
Let  and  be a sequential witness for .
Then, there exists a sequential witness for .
\end{lem}
\proof
Let  denote a permutation from  to  such that  events are not shuffled.
That is,  means that  and whenever , we set  By the definition of obs-equivalence and Lemma~\ref{lem:obsequiv-deqnull}, this permutation is well-defined.
Note that because , the ordering among dequeue events is preserved by .
That is, if  and , then .
The same holds for the ordering among enqueue events.
We now pick the mapping  and show that it is a sequential witness for .
Conditions (i) and (ii) are satisfied by construction.
Condition (iii) is satisfied because  is a bijection.
Condition (iv) is satisfied by Lemma~\ref{lem:deq-after-enq} and by the construction of .
Condition (v) is satisfied by because  is a bijection and preserves the ordering between dequeues and enqueues.
Condition (vi) is satisfied by Lemma~\ref{lem:obsequiv-deqnull}.
\qed

\begin{lem}\mylabel{lem:seqwit-removals}
Let  be a queue behavior with a sequential witness .
\begin{enumerate}
\item Let  and  be dequeue and enqueue events such that , and 
let  be the behavior obtained after removing both  and  from . 
Then, the restriction of  to  is a sequential witness for .
\item Let , and  by obtained by removing  from .
Then, the restriction of  to  is a sequential witness for .
\end{enumerate}
\end{lem}
\proof
In both cases, let us denote the restriction of  on  with ; 
we have to show that  satisfies the six conditions of a sequential witness.

(1)
Since  is a restriction, it satisfies conditions (i), (ii) and (iii).
Observe that for any two events  and  in , we have  iff .
This implies that  satisfies conditions (iv) and (v).
Finally, we have to show that there cannot be a dequeue event  such that .
Assume the contrary, then since the number of non-{\NULL} dequeue events and the number of enqueue events preceding  must be equal, there must be a dequeue event  whose matching  comes after .
This implies that  and , contradicting condition (iii).
Thus, condition (vi) is also satisfied by .

(2)
As in the previous case, conditions (i) to (v) are satisfied by .
The condition (vi) is satisfied because removing  does not affect the cardinality of either set; thus, if  is in , then the number of enqueue events and non-{\NULL} dequeue events that precede  in  is the same as those that precede  in .
\qed

\begin{lem}\mylabel{lem:seqwit-canonical}
Let  be a queue behavior and let  be a sequential witness for .
Then, there exists a canonical behavior  such that  and for all ,  iff .
\end{lem}
\proof
Let  denote the canonical behavior of  whose sequential witness is .
We will prove, by induction on the length of , that  is a well-defined total function.

For the base, consider all sequences  of length 1 or less which have a sequential witness.
\begin{itemize}
\item If , then the empty mapping is the only sequential witness for ; by definition,  is a canonical behavior.
The second condition is vacuously satisfied.
\item If , then  which maps  to  is the only sequential witness for ; by definition,  is a canonical behavior.
Since , the second condition is satisfied.
\item If  for some , then the empty mapping is the only sequential witness for ; by definition,  is a canonical behavior.
Since there is no  event, the second condition is vacuously satisfied.
\end{itemize}
Observe that the sequence  of length 1 cannot have a sequential witness, because any sequential witness has to map  to a matching enqueue which does not exist.

Assume that the claim holds for all sequences of length  or less.
Let  be a sequence of length  and  be a sequential witness for .
Consider the two sub-sequences of ,  and , with lengths  and , respectively.
Observe that  is an interleaving of  and .
In particular,  is either  or .
We will do a case analysis on the possible values for .
\begin{itemize}
\item .
Then, we set , with  obtained by removing the first  from  (note that this is ) and  obtained by restricting  to .
By Lemma~\ref{lem:seqwit-removals},  is a sequential witness for .
By inductive hypothesis,  is a canonical behavior observationally equivalent to .
Since  is a canonical behavior, so is .
Since , we have , .
Thus, .
The second condition is satisfied, because both  and  have  in their first position and  preserves the positions of {\NULL}-dequeue events by inductive hypothesis.
\item  for some .
By the assumption that  is a sequential witness for  implies that there exists  such that  (conditions (i) and (ii)) and  (condition (iv)).
Then,  must hold.
Assume contrary, that is  for some .
As noted above,  is either  or .
If the former, then  cannot hold since  is minimal with respect to , violating condition (iv) which contradicts the assumption that  is a sequential witness for .
If the latter, that is , then , and either there is no  or if it exists, , violating condition (v) which contradicts the assumption that  is a sequential witness for .
Thus, . 
We set , with  obtained by removing  and  from  and  to be the restriction of  on .
By Lemma~\ref{lem:seqwit-removals},  is a sequential witness for .
By inductive hypothesis,  is a canonical behavior obs-equivalent to .
Since  is a canonical behavior, so is .
Finally, since , we have  and . 
Thus, .
By the proof of Lemma~\ref{lem:seqwit-removals}, we know that for any  either both  and  precede it in  or neither does.
Since  is the first event in , the latter cannot happen; i.e.  and .
This implies that the position of  is the same in  and  by the inductive hypothesis.
Thus the second condition is satisfied. 
\qed
\end{itemize}

\begin{lem}\mylabel{lem:canonical-order-legal}
Let  be a canonical queue behavior.
Let  be a queue behavior such that , 
for every  in  there is , and 
for every ,  iff .
Then,  is legal.
\end{lem}
\proof
We prove by induction on the length of  that  has a run in {\ltsq}.
The base case where  is trivial.
Assume that the claim holds for all sequences of length  or less.
Let  be a sequence of length .
By the inductive hypothesis, there is a run  in {\ltsq} with trace .
Let  denote the state reached after this run.
It is enough to show that there is a transition in {\ltsq} of the form , for some .
We do a case analysis on .
\begin{itemize}
\item . 
Then the desired transition is .
\item .
By the assumption on , .
By observational equivalence to , if  for some , then .
Together they imply that there are exactly  many non-{\NULL} dequeue events and at least  many enqueue events that precede  in .
This in turn implies that  must be of the form .
Then the desired transition is .
\item .
By the assumption on  and , we have .
This implies that the number of enqueue events that occur in  is equal to the number of non-{\NULL} dequeue events in .
Since , for any dequeue event  we have  iff .
These in turn imply that for any enqueue event  we have  iff .
Overall, we then have  and  is the desired transition.
\qed
\end{itemize}

\begin{thm}\mylabel{thm:equiv-legal-seqwitness}
A queue behavior  is legal iff  has a sequential witness.
\end{thm}

\proof
()
Let  be a legal queue behavior.
By Lemma~\ref{lem:canonical-representative}, there is a canonical behavior  such that .
By Lemma~\ref{lem:canonical-seqwit},  has a sequential witness.
By Lemma~\ref{lem:obsequiv-witness},  has a sequential witness.

()
Let  be a queue behavior and  be a sequential witness for .
By Lemma~\ref{lem:seqwit-canonical} and Lemma~\ref{lem:canonical-order-legal},  is legal.
\qed

\section{Conditions for Queue Linearizability}
\label{sec:conditions}


\subsection*{Generic Necessary and Sufficient Conditions}

We start by reducing the problem of checking linearizability of a given history, , with respect to the queue specification to finding a mapping from its dequeue events to its enqueue events satisfying certain conditions.
Intuitively, we map each dequeue event to the enqueue event whose value the dequeue removed, or to nothing if the dequeue event returns \NULL.
We say that the mapping is {\em safe} if it pairs each {\deq} event with an {\enq} event such that the value removed by the former is inserted by the latter, 
implying that elements are inserted exactly once and removed at most once.
A safe mapping is {\em ordered} if it additionally respects the ordering of events in .
Finally, an ordered mapping is a {\em linearization witness} if all {\NULL} returning {\deq} events see at least one state where the queue is logically empty.
Below, we formalize these notions.

\begin{defi}[Safe Mapping]\mylabel{def:safe}
A total mapping  from  to  is {\em safe} for complete history  if \\
(1) for all , if , then ;\\
(2) for all ,  iff ; and\\
(3) for all , if , then . 
\end{defi}

\begin{defi}[Ordered Mapping]\mylabel{def:ordered}
A safe mapping  for  is {\em ordered} if \\
(1) for all , we have ; and\\
(2) for all  and , if , 
then there exists \mbox{} such that  and .
\end{defi}
Intuitively, the first condition states that an enqueue event cannot start after the completion of the dequeue event that removed the value inserted by the former.
The second condition states that if two enqueue events  and  are ordered such that  and the value inserted by  is removed by some , then there must exist a dequeue event  removing what  has inserted and  cannot complete before  starts.

Let  be a complete history and  be ordered for .
Let  be a dequeue event returning {\NULL}; that is, . 
Define  as the smallest set consisting of all enqueue events  in  such that either if the matching dequeue  for  exists (i.e. ), then  is after , or there is another  in  which precedes either  or the matching dequeue event  of .
Formally, the definition is given inductively as follows:

with
.

Intuitively, the set  contains all enqueue events after the completion of which  cannot observe an empty queue.
In other words, if  and if  completes before  does, then the state of the queue is guaranteed to be non-empty after  completes until the completion of . 

\COMMENT{
 such that either there does not exist a  such that  or  exists and one of the following holds:
\begin{enumerate}
\item .
\item there exists  such that either  or .
\end{enumerate}
An equivalent definition given inductively is as follows:
}




\begin{defi}[Linearization Witness]\mylabel{def:lin-witness}
An ordered mapping  for  is a {\em linearization witness} if for any  with , we have .
\end{defi}

In the proofs that follow, we sometimes use the following result to prove that a given ordered mapping is a linearization witness.
\begin{lem}\mylabel{lem:alt-lin-witness}
Let  be a complete history,  be an ordered mapping for  and  be such that .
Then,  iff there exist subsets  and  such that ,  is closed under , and .
\end{lem}

\proof\hfill

\noindent {\bf ()}
Assume that . Set

We have to show that  and  satisfy the three constraints.
\begin{itemize}
\item If , then it cannot be in  by construction.
If , then either  belongs to  or it is an event that precedes another event in .
If , then by construction its matching  cannot be in .
This implies that , hence .
If , then it is in  and there is some  such that  and  which imply that , hence .
\item Let  and .
We do case analysis on .
\begin{itemize}
\item If  with , then by the construction of , .
\item If  with , then if there is  such that , then .
Assume that .
This can happen when either  or . 
If  is in , which by the assumption that  is ordered implies that  must complete after  starts ( must hold).
This in turn implies that , beginning after  completes must be in , which contradicts the assumption that .
If  is in , then there must exist  such that either  or .
Because  is ordered, we have .
Together with the assumption that , these imply . 
Now, if , then  which contradicts the assumption that .
If  with , that  and  hold means that  which in turn contradicts the assumption that .
Finally, if  with , then because  there is some  such that  which leads to the same contradiction as the previous case.
\item If ,  is either an enqueue event  or there is a dequeue event  such that  and .
For the latter claim, observe that either  and we take  or  and by definition of  there exists  such that  which by transitivity of  implies .
If , then either  or .
If  and  hold, then  must also be in  contradicting the assumption that .
If  and  hold, then , which exists because  is safe, must be in  which contradicts the assumption that .
If , then  implies that  contradicting the assumption that .
\end{itemize}
Thus, we conclude that  whenever  for some .
\item Let .
By the assumption that , .
Thus, by construction  , establishing .
Since , there exists  such that  and , establishing .
\end{itemize}

\noindent{\bf ()}
Assume that there exist  and  such that all three conditions are satisfied.
We now show that the sets  and  are disjoint.
We show by induction that there is no index  such that .
If ,   implies that there does not exist  such that  and .
By the assumption that  and  are disjoint, we have .
But by the assumption that , we must have .
This contradicts the assumption that .

Assume that for all indices less than or equal to , for some , the claim holds:  implies that  and  are disjoint.
Consider the index .
Assume that there is . 
Then there exists  such that either  or there is  with  and .
The former case, , is not possible since that would imply that  and contradict that .
By the assumption that  is closed under ,  and , we must have .
By the assumption that  and , there must be  such that .
But if  and , then there must be  such that  or .
Applying the same arguments as above, we arrive, after  iterations, to the conclusion that there must be some  which is also in .
But by definition,  with  cannot be in  (if  exists, then ).
This contradicts the assumption that .
\qed


\begin{defi}
Let  be a complete history with a linearization witness .
Call two events  and  in  {\em overlapping} if neither  nor  holds.
We define a relation  over . 
For two enqueue events  and , we have  if  and one of the following holds:
\begin{enumerate}
\item .
\item  and  are overlapping, there exists  such that , but there does not exist  such that .
\item {\sloppy  and  are overlapping, and there exist  and  such that , , and .}
\item  and  are overlapping, there exist ,  such that , , and there exists  such that ,  and .
\end{enumerate}
Let , called the {\em enq-order}, denote the transitive closure of .
We will drop the subscripts when the history  and its linearization witness either are clear from the context or do not matter.
\end{defi}

\begin{lem}\mylabel{ref:enq-order-total}
Let  be a complete history with linearization witness .
Then, the induced enq-order  is a partial order over .
\end{lem}
\proof
We have to show that there does not exist a sequence  of enqueue events such that  for  and .
The proof is done by induction on , the number of enqueue events in the sequence.
In the base case, we note that  is impossible by definition.
Assume that there is no such sequence of length  or less.
Consider the sequence .
For convenience, we will use  to denote the dequeue event in  such that . 
If no such dequeue event exists for , we will say that {\em  does not exist}.
We make the following observations about this sequence:

\begin{enumerate}
\item If  does not exist, then  cannot exist.
Assume the contrary and that for some , we have ,  does not exist and  exists.
By the definition of ,  cannot be due to conditions 2-4, because they all require the existence of .
Then, we must have .
On the other hand, since  is a linearization witness for , by condition 2 of ordered mapping, the existence of  implies the existence of , which contradicts the assumption that  does not exist.
Because the sequence represents a cycle and  is a partial order, all  exist.

\item There cannot be two distinct pairs of events  and  such that  and  for some .
If there were, then we would have  or .
If , then  hold and this sequence does not contain .
If , then  hold and this sequence does not contain .
Thus, both sequences have less than  events, which contradict the inductive hypothesis.
\end{enumerate}

\noindent We first show that none of the orderings in the cycle can be due to condition (4); i.e. there is no  such that  because there is some  such that  and . 
We assume the contrary and, without loss of generality, assume that  is due to condition (4).
Then, there is  such that  and .
Observe that for all other enqueue events  in the sequence,  as otherwise,  which results in a shorter cycle contradicting the inductive hypothesis.
In particular, , but this immediately leads to .
This implies that  is also a cycle.
Thus, if any consecutive events in the cycle are ordered due to condition (4), then .
Clearly  can never hold due to condition (4), leading to the conclusion that if  is due to condition (4), then .

Now, assume by contradiction that  exists and there is  such that  and .
Since ,  exists.
By the first observation above,  also exists.
So,  cannot be due to condition (2).
We do a case analysis on the possible justifications for .
\begin{itemize}
\item Assume that  (condition (1)). 
By the assumption that , we have , which contradicts the assumption that .

\item Assume that  and  are overlapping and  (condition (3)).
Because , either  or  or there is an enqueue event  such that either  or  holds.
If  holds, then by transitivity  also holds.
If  holds, then because  cannot hold ( is ordered),  must hold.
If  holds, then because  holds (due to  being ordered) we must have .
Finally, if  holds, then by transitivity  also holds.
All four cases contradict the assumption that .

\item Assume that there exists  such that ,  and  (condition (4)).
We do a case analysis on the possible justifications of  and  holding:
\begin{itemize}

\item , and . 
Then either  or  holds.

\item , and .
Then either  or  holds.

\item , and there is  such that .
Then either  or  holds.

\item , and there is  such that .
Then either  or  holds.

\item , and .
Then either  or  holds.

\item , and .
Then either  or  holds.

\item , and there is  such that .
Then either  or  holds.

\item , and there is  such that .
Then either  or  holds.

\item There is  such that , and .
Then either  or  holds.

\item There is  such that , and .
Then either  or  holds.

\item There is  such that , and there is  such that .
Then either  or  holds.

\item There is  such that , and there is  such that .
Then either  or .

\item There is  such that , and .
Then either  or  holds.

\item There is  such that , and .
Then either  or  holds.

\item There is  such that , and there is  such that .
Then either  or  holds.

\item There is  such that , and there is  such that .
Then either  or .

\end{itemize}
In all cases the former implication contradicts  and the latter implication contradicts .

\end{itemize}
Thus, if  is a cycle in , none of the pairwise orderings can be due to condition (4).

Now consider the case where all consecutive events are overlapping; that is,  and  are overlapping for all .
Then, by the definition of  and the first observation, we must have .
But this would imply by the transitivity of  that  which is impossible due to  being a partial order.

So, there must be exactly one pair  and  of events ordered by .
Without loss of generality assume that .
By the second observation,  is overlapping with all  for .
In particular,  and  must be overlapping.
That contradicts the assumption that . 
Thus no sequence of length  can have a cycle in the  relation.
\qed


The main result of this section is stated below.
\begin{thm}\mylabel{thm:witness}
A set of histories  is linearizable with respect to queue iff every  has a completion
 that has a linearization witness.
\end{thm}
\newpage

\proof\hfill

\noindent{\bf ()} If  is linearizable with respect to queue, then there is a linearization  of  which is a legal queue behavior.
By Theorem~\ref{thm:equiv-legal-seqwitness},  has a sequential witness .
The mapping  satisfies the conditions of a linearization witness since all  orderings are preserved in .
In particular,  is safe because conditions (i) to (iii) of sequential witness imply conditions (1) to (3) of safe mapping.
It is ordered because
\begin{itemize}
\item By condition (iv) of sequential witness,  implies  and definition of linearizability implies that , which is condition (1) of ordered mapping,
\item Assume that there exist  such that  and .
Then by definition of linearization, .
By condition (v) of sequential witness,  exists and .
By definition of linearization, this in turn implies that , which is condition of (2) of ordered mapping.
\end{itemize}
Assume .
Define the sets , .
Observe that  because for any , by definition we have , which implies , which in turn implies .
Assume there is .
Then by definition of linearization, .
By construction, .
Let  denote the position of  in ; i.e. .
Because  is legal, it has an obs-equivalent canonical behavior, .
By Lemma~\ref{lem:seqwit-canonical} .
By definition of canonical behavior, each enqueue event in  has a matching dequeue event in .
Since  and  are obs-equivalent, then each enqueue event in  has a matching dequeue event in .
Thus, , the inclusion being proper in case  contains a {\NULL}-dequeue event (distinct from  since ).
Thus, .
Since all conditions of linearization witness per Lem.~\ref{lem:alt-lin-witness} are satisfied for  and ,  is a linearization witness.

\noindent{\bf ()}
Let  be a complete history with a linearization witness .
Let  denote a total order extension of .
That is,  is a total order over  such that whenever , we have .
Let  denote the -maximal enqueue event over .
That is, for any , we have  whenever .

In order to prove the if-direction (), we will make use of  to construct a sequence  with sequential witness .
We actually prove a stronger property, which also requires that if  in  then .
By Theorem~\ref{thm:equiv-legal-seqwitness}, the result follows.

The construction is given by induction on the number of (completed) events in .
In the base case, there are no events and  with empty mapping is the desired sequence.
Assume that the claim holds for all complete concurrent histories with  events or less.
Let  be a complete concurrent history with  events and  be a linearization witness for .
We first choose an event.

Call event  {\em maximal} (relative to ), if there is no event  such that  and one of the following holds:
\begin{enumerate}
\item , there is no  such that .
\item  with , there is no  such that .
\item  with , and .
\end{enumerate}
Let  be a non-empty complete history and  be its linearization witness.
We first show that there is at least one event in  that is maximal relative to .
First, observe that if , then any  must return {\NULL}; otherwise,  cannot be safe.
Then, any  such that no  with  exists is maximal.
Since  is a partial-order, such  must exist.
If conversely we assume that  and  is empty, then  is maximal.

Assume that  and  are non-empty.
If  is not maximal, it must be because there is  such that .
Then, by definition of  and the assumption that  is -maximal, there cannot be  such that  if .
So,  is not maximal only if there is ,  and .
Furthermore, the definition of , that  is -maximal and  exists imply that for all , there is   such that .
In particular, this means that for  such that no  with  exists and  with , setting  as a maximal element.
Thus, the set of maximal events in any non-empty history is non-empty. 

Let  denote the set of maximal elements relative to .
If  contains a dequeue event  such that , then we choose .
Otherwise, if  contains a dequeue event  such that , then we choose .
If neither condition holds, we choose .

We now show that if  is a non-empty history with linearization witness , the history  obtained by removing the chosen event from  has , which is  restricted to the remaining events in , as a linearization witness.
Before we do a case analysis on the type of the chosen event, we make two observations. 
If  is obtained from  by removing an event  and a mapping is safe for , then it is also safe for  when restricted to the .
Second, removing  from  does not change the relative ordering among the remaining events.
So  holds iff  holds.
In particular, if  and a mapping is ordered for , then it is ordered for .

We have three cases to consider for the chosen event:
\begin{itemize} 
\item The chosen event is  with .
Let  be such that .
Since , after removing  we have  and thus .
Additionally,  is the same as  when both are restricted to .
Then, we have

establishing that .
Thus,  is a linearization witness for .

\item The chosen event is . 
Observe that  is the -maximal enqueue event  relative to .
By the second observation above,  is ordered for .
We have to show that for any ,  is justified; that is, .
By the assumption that  is a linearization witness for , we have .
If , then  by definition.
If , then  and , so .

Then, the interesting case is when . 
First observe that  iff .
For the only-if () direction, assume that there is some .
By the definition of , if  then  contradicting the -maximality of .
The if () direction is trivial.
This implies that  because .
If there are several such \NULL-returning dequeues, choose  such that for any  with  implies .
Intuitively,  is the -maximal among dequeue events returning \NULL.

Now since  was chosen, we know that there must be at least one  such that , since otherwise  would have been chosen.
By the assumption about ,  with .
If , then  contradicting the assumption that .
So  with .
But then , which must exist because  is safe, is in , again contradicting the assumption that .
So, by contradiction we conclude that there is no such  for which  and  hold.

\item The chosen event is .
By the assumption about the chosen event,  does not exist, so  and  is safe because  is safe.
Because  does not exist, if  is such that , then . 
Then, for every such , , which means that  implies . 
So,  is a linearization witness for .

\end{itemize}

\noindent Now, we know that  is a linearization witness for  which has exactly  events.
By the inductive hypothesis,  is linearizable with respect to queue. 
That is, there is a linearization  of  which is a legal queue behavior.
By Theorem~\ref{thm:equiv-legal-seqwitness},  has a sequential witness .
We claim that , where  is the chosen element in  as described above, is a legal queue behavior.
Additionally, we will also show that for any two enqueue events  and  both in ,  implies .

Assume that the chosen element was  such that .
We set .
Observe that by the assumption that  is a chosen element, we must have .
This implies that for all , there is  such that ; as otherwise,  would be in .
Since all events of  are the same as the events of , the sets  and  have the same cardinality.
These along with the inductive hypothesis that  is a sequential witness for  imply that all six conditions of a sequential witness are satisfied for  and .
Because the relative ordering of events in  in  remains the same in ,  implies , and by induction hypothesis this can happen only when .

Assume that the chosen element was  such that . 
We set .
Because  was safe for ,  exists and  is well-defined.
By the inductive hypothesis,  is in  and hence .
Again by the inductive hypothesis, for any , we have .
Since  is the last event in , no event can follow  in .
In particular, there is no  such that . 
These along with the inductive hypothesis imply that  is a sequential witness for .
Similar to the previous case,  implies  and by inductive hypothesis this can happen only when .

Assume that the chosen element was .
We take .
Because  is chosen,  does not exist in .
Furthermore, since  is the last event in , no other event can follow  in .
These observations along with the inductive hypothesis imply that  is a sequential witness for .
Observe also that , being the last element in , also satisfies the condition that it should not precede any other enqueue event in , satisfying the condition that  implies .
\qed


\subsection*{Necessary and Sufficient Conditions for Complete Histories}

We now focus on complete histories, namely ones with no pending events. 
We observe that whether a history is not linearizable can always be determined by examining the dequeued values. 
Let  be a complete history.
In order to simplify the technical presentation we assume that each value is enqueued at most once.\footnote{In case there are multiple occurring values, this is akin to guessing the mapping {\Match}; it is enough that at least one guess satisfies the criteria (absence of violations).}
The possible violations in  are: 
\begin{description}
\item[(\VFresh)] A dequeue event returns a value not previously inserted by any enqueue event.
Formally, there exists a value  such that  and either  or .
\item[(\VRepet)] Two dequeue events return the value inserted by the same enqueue event.
Formally, there exist two dequeue events  such that .
\item[(\VOrd)]
Two values are enqueued in a certain order, and a dequeue returns the later value before any dequeue of the earlier value starts.
Formally, there exist values ,  such that , , and either  or .
\item[(\VWit)] A dequeue event returning \NULL\ even though the queue is never logically empty during the execution of the dequeue event.
Formally, let , where  represent subsequences of .
Then for any choice of  and  such that , there exists an  completed in  and  does not occur in .
\end{description}\smallskip

\noindent We have the following result which ties the above violation types to linearizable queues.

\begin{prop}\mylabel{prop:compl-viol}
A complete history  is linearizable with respect to queue iff it has none of the \VFresh, \VRepet, \VOrd, \VWit\ violations.
\end{prop}

\begin{proof}\hfill

\noindent{\bf()} If  is linearizable with respect to queue, then by Theorem~\ref{thm:witness},  has a linearization witness .
We show by contradiction that none of the four violations can happen in .

\begin{itemize}
\item Assume that  has \VFresh.
Then there exists a dequeue event  such that  and either  does not exist or .
That  does not exist is impossible because by the second condition of safe mapping,  and by the first condition of safe mapping .
That  holds is impossible because by the first condition of safe mapping, .

\item Assume that  has \VRepet.
Then there exist  with .
This is impossible by the third condition of safe mapping.

\item Assume that  has \VOrd.
Then there exist ,  such that  and either  such that  does not exist or such a  exists and .
Both possibilities contradict the second condition of ordered mapping.

\item Assume that  has \VWit.
Then  is of the form  such that , and for every possible partitioning of , there is an enqueue event  with  such that  is completed in  and there is no dequeue event , pending or completed, in  such that .
First, observe that by choosing  (resulting in ), we conclude that there is at least one enqueue event  whose matching dequeue event  is not in ; that is,  if .
This implies that .
Because  is a linearization witness for , we must have .
In other words, all enqueue events  must not belong to .
This implies that if  then  must happen after .
Let  be chosen such that for any other ,  occurs before  in .
Let  with . 
By the assumption that there is a  violation for , there must be an enqueue event  in  such that if there is  with , then  is neither completed nor pending in .
This implies that  if it exists must occur after .
Because  is not completed in  (it is completed in ), .
These two facts imply that either  or if  then  holds.
But this implies that .
This contradicts the assumption that  is the first enqueue event in  to complete in .
Such an  does not exist implies that there is at least one enqueue event  in  which is completed in , which implies that . 
Finally, this contradicts the assumption that  and  are disjoint.
\end{itemize}




\noindent{\bf()} 
Assume that there exists a complete history  in which none of the violations happen.
We will show that the mapping that pairs events enqueueing and dequeueing the same value is a linearization witness for .

Let  denote the set of all {non-\NULL} returning dequeue events of .
Similarly, let  denote the set of all {\NULL} returning dequeue events of .
Let  be the mapping from  to  such that  iff . 
Let  be such that all  are mapped to .
We claim that  defined as 

is a linearization witness for .

First, observe that  is a total mapping because  does not have {\VFresh}.
Furthermore, because  does not contain {\VRepet},  is a safe mapping by construction.
 satisfies the first condition of an ordered mapping because  does not have {\VFresh}.
 satisfies the second condition of an ordered mapping because  does not have {\VOrd}.
Thus,  is also an ordered mapping.

Let  be a {\NULL}-returning dequeue event in .
We have to show that  and  are disjoint.
Because  has no {\VWit} violation, there must be a prefix  of  such that if  is an enqueue event is completed in  then its matching dequeue event  (i.e. ) is either pending or completed in .
In other words, if  occurs in , then so does .
Let  be such that , for any  we have , and  is completed in .
If there is no such , that is, if  is empty, then we are done.
Otherwise, observe that  because by the absence of {\VWit}, there is  such that  and ; in particular,  occurs in .
But  implies that there is  such that either  or .
Both cases imply that  must be completed in , contradicting the assumption that  was minimal.
Thus, there are no enqueue events in  which are completed in .
Since  is contained in the set of completed events of , we conclude that  and  are disjoint.

This concludes the proof that  is a linearization witness for .
\end{proof}

We remark that none of the violations  mentions the possibility of an
element inserted by an enqueue being lost forever.  This is intentional, as
such histories are ruled out by the following proposition.

\begin{prop}
Given an infinite sequence of complete histories  
not containing any of the violations above, 
where for every ,  is a prefix of
, and the number of dequeue events in  is less than that of ,
if  contains an enqueue event ,
then exists some  containing .
\end{prop}

\begin{proof}
We prove this by contradiction. 
If there is no  event, then  is always in the queue, 
and so, from the absence of \VWit\ violations, none of the dequeue events
following  can return \NULL.
Also, since dequeue events cannot return values that were not previously
enqueued {\VFresh} and cannot return the same value multiple times {\VRepet},
and since the number of dequeue events is increasing, then there must also be
new enqueue events.
However, only finitely many of those are not preceded by  which
completes in . 
This means that eventually one dequeue event has to return an element inserted
by  such that , which is \VOrd.
\end{proof}

For checking purposes, we find it useful to re-state the third violation as the following
equivalent proof obligation.
\begin{description}
\item[(\POrd)]
For any enqueue events  and  with  and \mbox{},
a dequeue event  cannot return  
if  is not removed in  or is removed by  with .
\end{description}
Thus, to check this property, it suffices to come up with an overapproximation of
all those executions satisfying the premise of \POrd, and prove that such executions
cannot end with a dequeue event (in the sense that no other method is preceded 
by that dequeue event) returning the value of .

\subsection*{Necessary and Sufficient Conditions for Purely-Blocking Queues}

There is a subtle complication in the statement of Theorem~\ref{thm:witness}.
The witness mapping is chosen relative to some completion of the concurrent history under
consideration. 
However, because implementations may become blocked, such completions may actually never be reached. 
This means that one cannot reason about the correctness of a queue implementation by considering only the reachable states of the implementation.
What we would ideally like to do is to claim that if the implementation violates linearizability, then there is a finite complete induced history of the implementation which has no witness. 
In other words, if the implementation contains an incomplete execution trace whose induced (incomplete) history has no witness, then that execution trace is the prefix of a complete execution trace of the implementation.

Let  be the set of all induced histories of a library implementation.
We call the library implementation \emph{completable} iff for every history , we have .
For completable implementations, it suffices to consider only complete execution traces.

\begin{thm}\label{thm:no-violations}
A completable queue implementation is linearizable 
iff all its complete histories have none of the \VFresh, \VRepet, \VOrd\ and \VWit\ violations.
\end{thm}

\begin{proof}\hfill

\noindent{\bf()} If some complete history has a violation, by Prop.~\ref{prop:compl-viol}, it has no linearization, contradicting the assumption that the implementation is linearizable.

\noindent{\bf()}
Consider an arbitrary induced history  of the implementation. 
As the implementation is completable, 
there exists a completion  that is a valid induced history of the implementation.
From our assumptions,  cannot have a violation, and so by
Prop.~\ref{prop:compl-viol},  has a linearization, and therefore so does .
\end{proof}

Since it may not be obvious how to easily prove that an implementation is
completable, we introduce the stronger notion of purely-blocking
implementations, that is straightforward to check.
We say that an implementation is \emph{purely-blocking} when at any reachable state,
any pending method, if run in isolation will terminate or its entire execution does
not modify the global state.
Formally, let  be an execution trace of the implementation in which  executed by  is pending, i.e.  does not occur in .
The pending method  is called {\em pure after } if for any sequence  in which no action of  by  occurs and any sequence  in which only actions of  by  occur,  is an execution trace of the implementation iff  is an execution trace of the implementation.
The execution trace  is called {\em obstruction-free for } if there is another execution trace  of the implementation such that all actions in  belong to  executed by .
Then, the implementation is purely-blocking if for each execution trace  of the implementation and pending method  in , either  is obstruction-free for  or  is pure after .

\begin{prop}\label{prop:pb}
Every purely-blocking implementation is completable.
\end{prop}

\begin{proof}
Let  be an execution trace of a purely-blocking implementation.
We fix a total order of pending methods, and consider them in that order. 
For a pending method  executed by , if running it in isolation terminates, then extend  only with actions executed by  until  occurs.
Otherwise, the execution of  does not modify any global state and so all actions executed by  beginning with the last occurrence of  can be removed from the execution trace without affecting its realizability.
\end{proof}

We remark that our new notion of purely-blocking is a strictly weaker
requirement than the standard non-blocking notions:
\emph{obstruction-freedom}, which requires all pending methods to terminate when run in isolation, 
as well as the stronger notions of lock-freedom and wait-freedom.
(See~\cite{HS2008} for an in depth exposition of these three notions.)



\section{Manually Verifying the Herlihy-Wing Queue}
\label{sec:herlihy-wing}

Let us return to the HW queue presented in \S\ref{sec:introduction} and prove
its correctness manually following our aspect-oriented approach.

First, observe that HW queue is purely-blocking:  always terminates,
and  can update the global state only by reading  at ,
in which case it immediately terminates.
So from Prop.~\ref{prop:pb} and Theorem~\ref{thm:no-violations}, it suffices
to show that it does not have any of the four violations.
The last one, \VWit, is trivial as the HW  never returns .
So, we are left with three violations
whose absence we have to verify: \VFresh, \VRepet, and \VOrd. 

Intuitively, there are no \VFresh\ violations because  can return only a value that
has been stored inside the  array.  The only assignments to 
are  and : the former can only happen by an , which puts  into
the array; the latter assigns .

Likewise, there are no \VRepet\ violations because whenever in an arbitrary execution trace two calls to
 return the same , then at least twice there was an element of 
the  array holding the value  and was updated to  by
the  instruction at .
Therefore, at least two assignments of the form  happened; 
i.e.\ there were at least two  events in the induced history.

We move on to the more challenging third condition, \VOrd. 
We actually consider its equivalent reformulation, \POrd.
Fix a value  and consider an execution trace  where every method call enqueuing  
is preceded by some method call enqueuing some different value  and there
are no  calls returning  (there may be arbitrarily many concurrent
 and  calls enqueuing or dequeuing other values). 
The goal is to show that in this execution trace, no  return .

Let us suppose there is a dequeue  returning , and try to derive a contradiction.
For  to return , it must have read  such that
. So,  must have read  at  after
 incremented it at .

Since, , it follows that  will have read a larger
value of  at  than .  So, in particular, once 
finishes, the following assertion will hold:

Note that since, by assumption,  can never be dequeued, and any later
 can only affect the  array at indexes larger than ,
\eqref{eq:POrd-inv} is an invariant.

Given this invariant, however, it is impossible for  to return , as in
its loop it will necessarily first have encountered . Formally, to show this
we use the following loop invariant at the beginning of  loop

and \eqref{eq:POrd-inv} for the while loop. With these invariants, it is immediate
that the swap at line  cannot read .

\section{Checking the Conditions by Proving Program Divergence}
\label{sec:checking}

In this section, we reduce proving the absence of \VFresh, \VRepet\ and \VOrd\
violations to proving that certain programs always diverge.  Towards the end of
the section, we also discuss how the absence of \VWit\ violations might be automatically
checked for queue implementations whose {\deq} method may return \NULL.

Our proof technique relies heavily on instrumenting the  function
with a prophecy variable `guessing' the value that will be returned when
calling it.
That is, we construct a method, , such that the set of execution traces of
 
is equal to the set of execution traces of , where  stands for
(demonic) non-deterministic choice: the set of traces of  is
the union of the sets of traces of  and .
A simple construction is to define  to behave exactly as 
except that when  is about to return a value other than , 
we make  diverge.  That is, we prepend an 
statement to every  statement in .
In Section~\ref{sec:cave}, we describe a better construction.

\subsection*{Proving Absence of \VFresh\ Violations}

Generally, it is completely straightforward to prove the absence of \VFresh\
violations.  For example, it is sufficient for the queue implementation to be
data independent~\cite{WP1986}.

This is because a data independent implementation cannot produce values `out of
thin air.' In other words, if a dequeue returns a value, it must have read that
value from memory, and the only way for a value to get into memory is for an
enqueue to be invoked with that value passed as an argument.  Therefore, no
\VFresh\ violations can occur in data independent implementations.




\subsection*{Proving Absence of \VRepet\ Violations}

To prove the absence of \VRepet\ violations, we use the following theorem. 

\begin{thm}\label{thm:vrepet}
A completable queue implementation has no \VRepet\ violations iff 
for all values  and all  such that , the program

has no execution trace in which more than   threads terminate, where

\end{thm}

\begin{proof}
()
We argue by contradiction.
Consider an execution trace  of  where at least  of the  threads terminate.
The induced history  cannot have a safe matching because to satisfy condition (1) of
Definition~\ref{def:safe}, each  must be matched by some ,
and from the pigeonhole principle multiple  will have to be matched
with the same , 
thereby violating condition (3) of the Definition.

()
Again, we argue by contradiction.
Assume the queue implementation has an execution trace  such that  has a \VRepet\ violation. 
For each value , 
let  be the number of invoked  operations in  
and  be the number of invoked  operations.
Then, since there is a \VRepet\ violation, for some  there are at least 
 completed  operations in .
Finally, observe that  can be generated by a run of the program 
(for some ) in which at least  of the  threads terminate.
\end{proof}

In case the queue implementation is data independent~\cite{WP1986}, we can
simplify the \VRepet\ check further.
We say that a history is \emph{differentiated}, if all the input arguments to invocations
of the library's methods are pairwise different.  Given a renaming function on data
values, , we write  for applying the function
to all the data values in the history .
An implementation is \emph{data independent}, if the set of histories it generates, ,
satisfies two properties: (1) for every , ; and (2) for every ,
there exists a differentiated history  such that .
To ensure data independence, it suffices to check that the implementation
never performs any operations (such as testing for equality) on the value domain.

For data-independent programs, we can reduce reasoning about any number 
(say  and  where ) of  and
 threads to a single  and multiple  threads.
To see why a data independence condition is necessary,
consider the following incorrect  and  implementations:

Observe that for all , the program  never terminates whereas
the program  has a terminating execution: the serial execution where
both enqueues take place before all the dequeues.


\begin{thm}\label{thm:vrepet-di}
A data-independent completable queue implementation has no \VRepet\ violations
iff for all values , all  and all , the program
 (as defined in Theorem~\ref{thm:vrepet})
has no execution in which more than one  threads terminate.
\end{thm}

\begin{proof}
By Theorem~\ref{thm:vrepet}, it suffices to show that if
for all ,  and ,  has no execution trace with more than one
terminating , then
for all , ,  and , no execution trace of the program  can have more
than  terminating  threads.
Now, as  and  do not perform any value-dependent operations, we can
replace the  being enqueued by distinct fresh  values.
Doing so will naturally affect the return values of the dequeue operations that
were returning , but because of data independence, nothing else.
Hence, the program 

must have an execution trace where at least  of the  threads
terminate with  for .
So, by the pigeonhole principle, there exists some value  that gets 
dequeued multiple times, say .  This, however, contradicts our assumption
that  has at most one terminating  thread.
\end{proof}

\subsection*{Proving Absence of \VOrd\ Violations}

We move on to the \POrd\ property, which as we have seen in the manual proof of
the HW queue, is often more complicated to prove.  It turns out that our
automated technique for proving \POrd\ also establishes absence of \VFresh\
violations as a side-effect.
We reduce the problem of proving absence of \VFresh\ and \VOrd\ violations to the
problem of checking non-termination of non-deterministic programs with an
unbounded number of threads.  The reduction exploits the instrumented
 definition:  cannot return a result  in an execution
precisely if  cannot terminate in that same execution. 

\begin{thm}\label{thm:vord}
A completable queue implementation has no \VFresh\ and \VOrd\ violations iff 
for all  and for all  and  such that , the 
thread does not terminate in the program

where

\end{thm}

\begin{proof}
()
We argue by contradiction.
Consider an execution trace  of  in which the  thread terminates.
If  is not invoked in , then as there are no \VFresh\ violations, 
we know that no  in  can return , 
contradicting our assumption that  terminates in .
Otherwise, if  is invoked in , then at some earlier point
 was executed, and since initially  was set to ,
this means that  was executed and therefore .
Consequently, from \POrd, if there is  in  returns , there must
be a  in  that can be completed to return , contradicting
our assumption that  terminates in .

() We have two properties to prove.
For \VFresh, it suffices to consider the restricted parallel context that
never enqueues . In this restricted context,
 does not terminate, and so  cannot return .
For \VOrd, consider an execution trace in which every  happens after
some enqueue of a different value, say , and in which there is no 
.  Such an execution trace can easily be produced by the unbounded parallel
composition of , and so  also does not terminate, as required.
\end{proof}


\subsection*{Showing Absence of \VWit\ Violations}

Here, we have to show that any dequeue event cannot return \texttt{NULL} if it never goes through a state where the queue could be logically empty.
This in turn means that we have to express non-emptiness using only the actions of the history (and not referring to the linearization point or the gluing invariant which relates the concrete states of the implementation to the abstract states of the queue).
For the following let us fix a (complete) concurrent history  and a dequeue of interest  which returns {\NULL} and does not precede any other event in .

Let  be some prefix of  and let  be a completed enqueue event in .
We will call  {\em alive} after  if there is a matching dequeue event  in , i.e. , 
then  is neither pending nor completed in . 
In other words,  is alive after  if its matching dequeue , if it exists, is not invoked in .

For the following, let  denote the dequeue event which removes the element inserted by the enqueue event ; that is, .
A sequence  of enqueue events in  is {\em covering} for  in  if the following holds:
\begin{itemize}
\item  is alive at  where  is the maximal prefix of  in which  does not occur.
\item For all ,  starts before  completes.
\item For all , we have .
\item  is alive at .
\end{itemize}
Note that all  must exist by the third condition, with the only exception of , which does not exist (the last condition).
Then, the sequence is covering for  if  does not start before  starts, and every enqueue event  completes before the dequeue event  starts.
Intuitively, this means that at every state visited during the execution of , the queue contains at least one element. 

The property corresponding to the last violation (\VWit) then becomes the following:
\begin{description}
\item[(\PWit)] A dequeue event  cannot return {\NULL} if there is a covering for .
\end{description}

\begin{lem}\mylabel{lem:vwit-pwit}
A (complete) concurrent history  has {\VWit} iff it does not satisfy {\PWit}.
\end{lem}
\begin{proof}
()
Let  have {\VWit}.
By Prop.~\ref{prop:compl-viol}, there is  such that  and .
We construct a covering sequence  for  such that for all  the response of  occurs before the response of , if  and  are minimal indices for which  and  hold, then , and , and if  with , then .

\begin{description}
\item[(Base)] By the assumption there is an enqueue event in .
Set  an enqueue event in  such that for any other enqueue event , we have .

\item[(Inductive)] Let  be in  with .
Let  be the set of all  such that either  or , where  is the matching dequeue event for .
Observe that  is non-empty.
Choose  to be an enqueue event with minimal index in .
That is, if  is the smallest index for which  holds, then for any ,  implies .
Observe that .
This implies that by construction it cannot be the case that  since it would contradict the assumption that  was chosen as an enqueue event with minimal index among those that precede .
But again by construction we have  which implies that the response event of  occurs after the response event of .
This also means that because , we must have . 

\end{description}
Since the sequence of indices  is strictly decreasing, to show that the construction terminates with , we only have to show that there is  completed before  is completed; i.e. the response of  occurs before the response of  in .
By the definition of {\VWit}, taking , we know that there must be at least one enqueue event  in  such that  is completed in  and its matching dequeue is neither pending nor completed in . 
But this immediately implies that  and  is completed before  is completed.


()
Let  be a covering sequence for .
Then,  because  if it exists is preceded by , i.e. .
Furthermore, for every , since we have , all .
Finally, . 
Thus,  and  are not disjoint if there is a covering for .
By Prop.~\ref{prop:compl-viol} this implies the existence of {\VWit}.
\end{proof}

\noindent
We will actually restate the same property in a simpler way by making the
following observation.
\begin{prop}
There is a covering for  in  iff at every prefix  of  such that
 is pending in , there is at least one alive enqueue event.
\end{prop}

\noindent
Then, we can alternatively state {\PWit} as follows:
\begin{description}
\item[()] A dequeue event  cannot return {\NULL} if for every prefix  at which  is pending there exists an alive enqueue event.
\end{description}
Note that {\POrd} can also be stated in terms of alive enqueue events. 
\begin{description}
\item[()] For any enqueue events  and  with  and \mbox{},
a dequeue event cannot return  if  is alive at .
\end{description}

\section{Automation within Cave}
\label{sec:cave}

\begin{figure}[t]
\begin{algorithmic}
 \Procedure{}{}
  \While{true}
   \State 
  \For{ \textbf{to} }
  \State 

  \EndFor
 \EndWhile
 \EndProcedure
\end{algorithmic}
\caption{The HW dequeue method instrumented with the prophecy variable  guessing
its return value, where  stands for non-deterministic choice.}
\label{fig:instr-deq}
\end{figure}

To automate the linearizability proof of the HW queue, we have mildly adapted
the implementation of \textsc{Cave}~\cite{Vaf2010}, a sound but incomplete
thread-modular concurrent program verifier that can handle dynamically
allocated linked list data structures and fine-grained concurrency.
The tool takes as its input a program consisting of some initialization code
and a number of concurrent methods, which are all executed in parallel an unbounded
number of times each. When successful, it produces a proof in RGSep that the
program has no memory errors and none of its assertions are violated at runtime.
Internally, it performs RGSep action inference~\cite{Vaf2010a} with a rich
shape-value abstract domain~\cite{Vaf2009} that can remember invariants 
indicating that value  is inside a linked list.
\textsc{Cave} also has a way of proving linearizability by a brute-force search
for linearization points (see~\cite{Vaf2010} for details), but this is not
applicable to the HW queue and therefore irrelevant for our purposes.

\subsection*{Overview of Action Inference}

In brief, \textsc{Cave}'s action inference algorithm first determines the part of
the heap-allocated memory that is private to a thread and the part that is shared. 
The main heuristic employed in this decision is that newly allocated memory 
cells are deemed to be private until they become reachable from some global 
variable, from which point onwards they are deemed shared.

Next, the algorithm computes a binary relation  on program states 
overapproximating the effects of all atomic statements of the program 
to the shared part of the heap. 
Syntactically, it represents  as the union of a set of more primitive 
binary relations, which are called \emph{actions}.
Moreover, it remembers which atomic program statements correspond 
to which actions of the set.
Thus, for example, if we want to compute an overapproximation of a 
program  in a parallel context, , we can run action inference
on  and from the total set of actions return only those corresponding
to . 

As part of this overapproximation, any information about the program's 
control flow is lost except when the program explicitly records it in some 
global variable.  This property is common to most thread-modular 
reasoning techniques, and is necessary for scalability.
Thus, for instance, the programs , , and  generate 
the same set of actions.

In the process of computing the set of actions, \textsc{Cave} 
proves that the program is memory safe and does not violate any 
assertions in it. To do so, it constructs a proof in RGSep, which is an
adaptation of Jones' rely-guarantee method suitable for pointer-manipulating 
programs~\cite{Jon1983,VP2007}. 
To construct these proofs, it calculates via abstract interpretation
an invariant that holds after every atomic program statement.
These invariants describe the shapes of the heap allocated data structures
(e.g., that there is a linked list from  to  via the field \texttt{next}),
and some very simple facts about the values stored in them 
(e.g., that the sequences of values stored in two list segments are equal,
or that the sequence of values stored in one list segment is sorted).

Finally, we note that action inference is incremental. Typically, action inference 
is run starting with an initial empty set of actions, to which set it adds any new
actions it generates until a fixpoint is reached. 
When, however, we want to verify  and we already know a sound 
abstraction of  (under the assumption that  can be run in parallel), 
it suffices to perform action inference only on  but starting with the 
set of actions of  as the initial set of actions.
To this set, action inference will add any further actions  produces.





\subsection*{Summary of Changes}

The modifications we had to perform to \textsc{Cave} were:
\begin{enumerate}
\item To add code that instruments  methods with a prophecy argument
guessing its return value, thereby generating ;
\item To add some glue code that constructs the verification conditions of
Theorems~\ref{thm:vrepet-di} and~\ref{thm:vord} and runs the 
underlying prover to verify them;
\item To improve the abstraction function so that it can remember properties of the
form , which are needed to express the \eqref{eq:POrd-inv} invariant
of the proof in Section~\ref{sec:herlihy-wing}; and
\item When checking the absence of  violations, 
to instrument the inferred actions so as to work around the fact 
that action inference abstracts over control flow information.
\end{enumerate}
The first two changes are clearly tool-independent, the third item is 
very \textsc{Cave}-specific, whereas the fourth item is fairly generic. 
The problem that we are working around here is common to almost
all thread-modular verification approaches, and our instrumentation 
should work for other tools as well.  
To use a different tool from \textsc{Cave}, the tool must be able to express 
invariants such as the aforementioned \eqref{eq:POrd-inv} invariant.

As \textsc{Cave} does not support arrays (it only supports linked lists), we
gave the tool a linked-list version of the HW queue, for which it successfully 
verified that there are no \VFresh, \VRepet, and \VOrd\ violations.
(As the HW deques never return , the algorithm also trivially has no
\VWit\ violations.) 


\subsection*{Prophetic Instrumentation of Dequeues}

In order to be able to use the theorems in the previous section, we must first
construct the method  that records the result of the  function
in its arguments which acts like a prophecy variable.
In essence, the  we construct must be such that the set of traces of
 
is equal to the set of traces of , where  stands for
non-deterministic choice.
Figure~\ref{fig:instr-deq} shows the resulting automatically-generated 
instrumented definition of  for the HW queue.

Our implementation of the instrumentation performs a sequence of simple rewrites,
each of which does not affect the set of traces produced:

In general, the goal of applying these rewrite rules is to bring the introduced
 statements as early as possible without unduly duplicating
code.

\subsection*{Instrumentation for Checking Absence of \VRepet\ Violations}

Observe that the HW queue implementation is data independent as the operations 
on the shared locations in the  and  methods do not depend
on the value of argument. 
Therefore, using Theorem~\ref{thm:vrepet-di}, we have to prove that in the
context where only one  can happen in parallel,  cannot
terminate if another  has terminated.

One slight complication is that we cannot use RGSep action
inference~\cite{Vaf2010} directly to prove this property because we have to
keep track of the exact number of occurences of particular shared memory
operation (such as the enqueues of ).
In rely-guarantee, operations on shared variables are abstracted by 
\emph{actions}, which typically do not contain any control flow within them. 
Hence after the initial action generation, 
we have to augment the shared state and the actions with 
auxiliary variables that 
(a) record the termination of parallel  and 
(b) ensure that only one parallel  call is accounted for.
Our implementation therefore proceeds as follows:
\begin{enumerate}
\item It infers an initial set of RGSep actions, , by performing symbolic
execution of the {\enq} and {\deq} methods, and refine this set of actions
to record information about the arguments of  and the result of the
 functions wherever possible.
Let  be the actions generated by  method and  be those
generated by .

\item For each action that is executed at most once by an  invocation,
it generates a fresh auxiliary variable, , and records that  changes
from  to  by performing that action.
Formally, we define:

writing  and  for the freshly generated variables in the
action's pre- and post-states.
(The purpose of this instrumentation is to ensure that the  actions will 
not interfere more than once with  below.)

\item Record each action that must be performed by a completed  event
using a fresh auxiliary variable, .  Formally,

where  are the freshly generated variables in the action's
post-state.
(The purpose of this instrumentation is to be able to detect whether a
 operation has terminated.) 

\item 
Running action inference with the following initial set of actions (the rely condition)

verify the Hoare triple

The postcondition ensures that no other  has terminated, because if it
had, it must have set each .
\end{enumerate}





\section{Related Work}
\label{sec:related-work}

Linearizability was first introduced by Herlihy and Wing~\cite{HW1990}, who
also presented the HW queue as an example whose linearizability cannot be proved
by a simple forward simulation where each method performs its effects
instantaneously at some point during its execution.
The problem is, as we have seen, that neither of  or  can be given
as the (unique) linearization point of  events, because the way in which
two concurrent enqueues are ordered may depend on not-yet-completed concurrent
 events.  In other words, one cannot simply define a mapping from the
concrete HW queue states to the queue specification states. 
Nevertheless, Herlihy and Wing do not dismiss the linearization point technique
completely, as we do, but instead construct a proof where they map concrete
states to non-empty sets of specification states.  

This mapping of concrete states to non-empty sets of abstract states is closely
related to the method of \emph{backward simulations}, employed by a number of
manual proof efforts~\cite{CDG2005,DM2009,SWD2012}, 
and which Schellhorn et al.~\cite{SWD2012} recently showed to be a complete
proof method for verifying linearizability.
Similar to forward simulation proofs, backward simulation proofs, are monolithic 
in the sense that they prove linearizability directly by one big proof.
Sadly, they are also not very intuitive and as a result often difficult to come
up with. For instance, although the definition of their backward simulation
relation for the HW queue is four lines long, Schellhorn et al.~\cite{SWD2012}
devote two full pages to explain it.

As a result, most work on automatically verifying linearizability
(e.g.~\cite{ARR+2007,Vaf2009,Vaf2010,AHH+2013,DGH2013}) and some
manual verification efforts (e.g.,~\cite{DSW2011,CDG2005}) have relied on the simpler
technique of forward simulations, even though it is known to be incomplete.
The programmer is typically required to annotate each method with its
linearization points and then the verifier uses some kind of shape analysis
that automatically constructs the simulation relation. 
This approach seems to work well for simple concurrent algorithms such as the
Treiber stack and the Michael and Scott queues, where finding the linearization
points may be automated by brute-force search~\cite{Vaf2010}.
Most recently, with their technique based on (automatically) rewriting implementations Dragoi et al.~\cite{DGH2013} have succeeded to extend this approach to some implementations with helping.
Similar to their precursors, however, their approach also assumes the existence of static linearization points, i.e.\ instructions in the program code that when executed invariably correspond to the linearization of one or more methods.
Thus, there are many implementations, as mentioned in the Introduction, that cannot be handled by this approach.

Among this line of work, the most closely related one to this paper is the
recent work by Abdulla et al.~\cite{AHH+2013}, 
who verify linearizability of stack and queue algorithms using observer
automata that report specification violations such as our \VOrd. 
Their approach, however, still requires users to annotate methods
with linearization points, because checker automata are synchronized with the
linearization points of the implementation.

To the best of our knowledge, there exist only two earlier published proofs 
of the HW queue: (1) the original pencil-and-paper proof by Herlihy and
Wing~\cite{HW1990}, and (2) a mechanized backward simulation proof by
Schellhorn et al.~\cite{SWD2012}.

Both proofs are manually constructed. In comparison,  our new proof 
is simpler, more modular, and automatically generated.
This is largely due to the fact that we have decomposed the goal of proving
linearizability into proving four simpler properties,
which can be proved independently.
This may allow one to adapt the HW queue algorithm, e.g.\ by checking
emptiness of the queue and allowing  to return \NULL, and affecting
only the proof of absence of \VWit\ violations without affecting the
correctness arguments of the other properties. 

Our violation conditions are arguably closer to what programmers have
in mind when discussing concurrent data structures.  Informal specifications 
written by programmers and bug reports do not mention that some method is 
not linearizable, but rather things like that values were dequeued in the wrong
order.

\section{Conclusion}
\label{sec:conclusion}

We have presented a new method for checking linearizability of concurrent queues.
Instead of searching for the linearization points and doing a monolithic simulation proof, we verify four simple properties whose conjunction is equivalent to linearizability with respect to the atomic queue specification.
By decomposing linearizability proofs in this way, we obtained a simpler correctness proof of the Herlihy and Wing queue~\cite{HW1990}, and one which can be produced automatically.

We believe that our new property-oriented approach to linearizability proofs
will be applicable to other kinds of concurrent shared data structures, such as
stacks, sets, and maps.
The generalization, however, is not entirely straightforward.  In the case of
stacks, the violations are similar to that of queues, but not exactly dual. 
The main difference is that the ordering violation for stacks is similar to
\VWit\ and not to \VOrd\ as one might expect.
Similarly, the violations for set implementations are also not as simple as
dropping the ordering constraint.  Instead, we need to count the number of
successful insertions and deletions to express what can go wrong.  It remains
to be seen, however, whether such counting arguments can yield an automatic
verification technique. 




\section*{Acknowledgments}
We would like to thank the CONCUR'13 reviewers for their feedback. 
The research was supported by the EC FET FP7 project ADVENT, by the Austrian
Science Fund NFN RISE (Rigorous Systems Engineering), by the ERC Advanced
Grant QUAREM (Quantitative Reactive Modeling), and by the EPSRC Grants EP/H005633/1 and EP/K008528/1.

\bibliographystyle{abbrv}
\bibliography{biblio}

\end{document}
