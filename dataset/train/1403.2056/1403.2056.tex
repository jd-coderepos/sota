

\RequirePackage{fix-cm}

\documentclass[a4paper]{myjournal}

\setlength\overfullrule{14pt} 

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage{array}
\usepackage{tabularx}
\usepackage{url}
\usepackage{placeins}

\usepackage[algo2e,ruled,vlined,linesnumbered]{algorithm2e}
\SetCommentSty{textit}
\DontPrintSemicolon
\IncMargin{-\parindent}
\SetAlCapHSkip{0pt}
\SetAlgoLined

\SetKwProg{Function}{Function}{}{}
\SetKwFunction{LCPCompare}{LCP-Compare}

\usepackage{versions}
\excludeversion{FORABSTRACT}
\includeversion{FORREPORT}
\excludeversion{FORJOURNAL}
\def\pFORREPORT#1{\processifversion{FORREPORT}{#1}}
\def\pFORJOURNAL#1{\processifversion{FORJOURNAL}{#1}}

\usepackage{tikz,pgfplots}
\usetikzlibrary{positioning}

\tikzset{
  baseline=(current bounding box.center),
  HTline/.style={black!50,dashed},
}

\usetikzlibrary{external}
\tikzset{
  external/prefix={tikz/},
  external/optimize=true,
  external/mode={list and make},
}


\pgfplotscreateplotcyclelist{mycolor1}{red, every mark/.append style={solid,scale=0.8}, mark=o \\blue, every mark/.append style={solid,scale=0.7}, mark=square \\violet, every mark/.append style={solid,scale=0.95}, mark=x \\green!70!black, every mark/.append style={solid,scale=0.95}, mark=diamond \\orange!40!red, every mark/.append style={solid,scale=0.95}, mark=x, dashed \\teal, every mark/.append style={solid,scale=0.95}, mark=asterisk, dashed \\brown!70!black, every mark/.append style={solid,scale=0.95}, mark=triangle, dashed \\}

\pgfplotscreateplotcyclelist{mycolor2}{red, every mark/.append style={solid,scale=0.8}, mark=o \\blue, every mark/.append style={solid,scale=0.7}, mark=square \\green!70!black, every mark/.append style={solid,scale=0.95}, mark=diamond \\orange!40!red, every mark/.append style={solid,scale=0.95}, mark=x, dashed \\teal, every mark/.append style={solid,scale=0.95}, mark=asterisk, dashed \\brown!70!black, every mark/.append style={solid,scale=0.95}, mark=triangle, dashed \\purple!80!blue, every mark/.append style={solid,scale=0.7}, mark=square, densely dotted \\olive, every mark/.append style={solid,scale=0.8}, mark=o, densely dotted \\gray, every mark/.append style={solid,scale=0.95}, mark=x, densely dotted \\}

\pgfplotsset{
  major grid style={thin,dotted,color=black!50},
  minor grid style={thin,dotted,color=black!50},
  grid,
  every axis/.append style={
    line width=0.5pt,
    tick style={
      line cap=round,
      thin,
      major tick length=4pt,
      minor tick length=2pt,
    },
  },
  legend cell align=left,
  legend style={
    /tikz/every even column/.append style={column sep=3mm,black},
    /tikz/every odd column/.append style={black},
  },
  plotSpeedupMini/.style={
    width=67mm,height=49mm,
    xlabel near ticks,
ylabel absolute=true,
    every axis y label/.append style={yshift=-13pt},
max space between ticks=18pt,
    title style={yshift=-3pt},
  },
  plotSpeedup64/.style={
    plotSpeedupMini,xtick={1,8,16,32,48,64},
    cycle list name={mycolor1},
  },
  plotSpeedup48/.style={
    plotSpeedupMini,xtick={1,6,12,24,36,48},
    cycle list name={mycolor1},
  },
  plotSpeedup16/.style={
    plotSpeedupMini,xtick={1,2,4,6,8,12,16},
    cycle list name={mycolor1},
  },
  plotSpeedup8/.style={
    plotSpeedupMini,xtick={1,...,8},ytick={0,...,5},
    cycle list name={mycolor2},
  },
}

\usepackage{hyperref}
\hypersetup{
  breaklinks=true,
  colorlinks=true,
  citecolor=blue,
  linkcolor=blue,
  urlcolor=blue,
  bookmarksnumbered,
  bookmarksopen,
  pdftitle={Engineering Parallel String Sorting},
  pdfauthor={Timo Bingmann, Andreas Eberle, Peter Sanders},
  pdfsubject={parallel string sorting algorithms, super scalar string sample sort, multiway LCP-mergesort},
  pdfkeywords={parallel string sorting, parallel algorithm, string sorter, sample sort, mergesort, lcp},
}

\hypersetup{pdfpagescrop={10 130 485 830}}

\usepackage{breakurl}




\usepackage{amsfonts}

\newcommand{\ceil}[1]{\left\lceil #1\right\rceil}
\newcommand{\floor}[1]{\left\lfloor #1\right\rfloor}
\newcommand{\abs}[1]{\left| #1\right|}
\newcommand{\seq}[1]{\langle #1\rangle}
\newcommand{\norm}[1]{\left\|#1\right\|}
\newcommand{\enorm}[1]{\norm{#1}_{2}}
\newcommand{\sumnorm}[1]{\norm{#1}_{1}}
\newcommand{\maxnorm}[1]{\norm{#1}_{\infty}}
\newcommand{\xor}{\oplus}
\newcommand{\set}[1]{\left\{ #1\right\}}
\newcommand{\gilt}{:}
\newcommand{\sodass}{\,:\,}
\newcommand{\setGilt}[2]{\left\{ #1\sodass #2\right\}}
\newcommand{\Def}{:=}
\newcommand{\zvektor}[2]{\left(#1,#2\right)}
\newcommand{\vektor}[2]{\left(\begin{smallmatrix}#1\\#2\end{smallmatrix}\right)}
\newcommand{\condition}[1]{\left[#1\right]}
\newcommand{\binomial}[2]{\binom{#1}{#2}}
\newcommand{\even}{\mathrm{even}}
\newcommand{\odd}{\mathrm{odd}}
\newcommand{\mymod}{\,\bmod\,}
\newcommand{\divides}{|}

\newcommand{\blank}{\Box}
\newcommand{\cross}[2]{\langle #1,#2 \rangle}
\newcommand{\defeq}{\mathrel{:=}}
\newcommand{\hash}{\sym{@}}
\newcommand{\hD}[1][D]{^{(#1)}}
\newcommand{\hed}[1][D]{^{1/#1}}
\newcommand{\Lpal}{L_{\mathrm{pal}}}
\newcommand{\Lparity}{L_{\mathrm{parity}}}
\newcommand{\Lvv}{L_{\mathrm{vv}}}
\newcommand{\pD}[1][D]{^{[#1]}}
\newcommand{\pos}[1]{\mathbf{#1}}
\newcommand{\qs}{\mathord{\Box}}
\newcommand{\mSet}[2]{\left\{#1 \mid #2\right\}}
\newcommand{\s}{\mathord{-}}
\newcommand{\CAce}{\hbox{\mdseries\scshape CAce}}
\newcommand{\sCAce}{\s\CAce}
\newcommand{\CAcs}{\hbox{\mdseries\scshape CAcs}}
\newcommand{\sCAcs}{\s\CAcs}
\newcommand{\CAww}{\hbox{\mdseries\scshape CAww}}
\newcommand{\sCAww}{\s\CAww}
\newcommand{\sC}{\s\hbox{\scshape Chng}}
\newcommand{\sD}{\s\hbox{\scshape Diam}}
\newcommand{\sT}{\s\hbox{\scshape Time}}
\newcommand{\CA}{\hbox{\mdseries\scshape CA}}
\newcommand{\sCA}{\s\CA}
\newcommand{\ST}[1]{\langle #1\rangle}
\newcommand{\sym}[1]{\mathord{\hbox{\texttt{\upshape #1}}}}

\newcommand{\nat}{\mathbb{N}}
\newcommand{\natnull}{\mathbb{N}_{0}}
\newcommand{\natless}[1]{\mathbb{N}_{#1}}
\newcommand{\nplus}{\mathbb{N}_+}
\newcommand{\real}{\mathbb{R}}
\newcommand{\rplus}{\mathbb{R}_+}
\newcommand{\rnneg}{\mathbb{R}_*}
\newcommand{\integer}{\mathbb{Z}}
\newcommand{\intint}[2]{{#1}..{#2}}
\newcommand{\realrange}[2]{\left[#1, #2\right]}
\newcommand{\realrangeo}[2]{\left(#1, #2\right)}
\newcommand{\realrangelo}[2]{\left(#1, #2\right]}
\newcommand{\realrangero}[2]{\left[#1, #2\right)}
\newcommand{\unitrange}[2]{\realrange{0}{1}}
\newcommand{\bool}{\set{0,1}}
\newcommand{\mapping}[2]{{#2}^{#1}}
\newcommand{\powerset}[1]{{\cal P}\left(#1\right)}
\newcommand{\NP}{\mathbf{NP}}
\newcommand{\Bild}{\mathbf{Bild}\:}

\newcommand{\withtype}[1]{\in#1}

\newcommand{\prob}[1]{{\mathbf{P}}\left[#1\right]}
\newcommand{\condprob}[2]{{\mathbf{P}}\left[#1\;|\;#2\right]}
\newcommand{\condexpect}[2]{{\mathbf{E}}\left[#1\;|\;#2\right]}
\newcommand{\expect}{{\mathbf{E}}}
\newcommand{\var}{{\mathbf{Var}}}
\newcommand{\quant}[2]{\tilde{#1}_{#2}}

\newcommand{\whpO}[1]{\tilde{\mathrm{O}}\left( #1\right)}
\newcommand{\Oschlange}{}
\newcommand{\Ohh}[1]{\mathcal{O}\!\left( #1\right)}
\newcommand{\Oh}[1]{\mathcal{O}\!\left( #1\right)}
\newcommand{\oh}[1]{\mathrm{o}\!\left( #1\right)}
\newcommand{\Th}[1]{\Theta\!\left( #1\right)}
\newcommand{\Thsmall}[1]{\Theta( #1)}
\newcommand{\Om}[1]{\Omega\!\left( #1\right)}
\newcommand{\om}[1]{\omega\!\left( #1\right)}
\newcommand{\Oleq}{\preceq}

\newcommand{\lref}[1]{\ref{\labelprefix:#1}}
\newcommand{\llabel}[1]{\label{\labelprefix:#1}}
\newcommand{\labelprefix}{} 

\newcommand{\discussionsize}{\small}
\newenvironment{discussion}{\par\discussionsize}{\par}

\marginparpush2mm
\newcommand{\frage}[1]{{\sf[ #1]}\marginpar{?}}


\newcommand{\mysubsubsection}[1]{\vspace{2mm}\noindent{\bf #1 }}

\newcommand{\punkt}{\enspace .}

\newenvironment{code}{\noindent \begin{tabbing}\hspace{2em}\=\hspace{2em}\=\hspace{2em}\=\hspace{2em}\=\hspace{2em}\=\hspace{2em}\=\hspace{2em}\=\hspace{2em}\=\hspace{2em}\=\hspace{2em}\=\kill}{\end{tabbing}}

\newcommand{\labelcommand}{}
\newcommand{\captiontext}{}
\newsavebox{\codeparam}
\newcounter{lineNumber}
\newenvironment{disscodepos}[3]{\renewcommand{\labelcommand}{#2}\renewcommand{\captiontext}{#3}\sbox{\codeparam}{\parbox{\textwidth}{#3}}\begin{figure}[#1]\begin{center}\begin{code}\setcounter{lineNumber}{1}}{\end{code}\end{center}\caption{\llabel{\labelcommand}\captiontext}\end{figure}}

\newenvironment{disscode}[2]{\begin{disscodepos}{htb}{#1}{#2}}{\end{disscodepos}}

\newcommand{\codel}[1]{\mbox{\rm "`#1"'}}
\newcommand{\codem}[1]{\mathrm{#1}}

\iffalse

\newcommand{\id}{\tt}
\newcommand{\Function} {{\bf Function\ }}
\newcommand{\Procedure}{{\bf Procedure\ }}
\newcommand{\Process}{{\bf process\ }}
\newcommand{\While}    {{\bf while\ }}
\newcommand{\Repeat}   {{\bf repeat\ }}
\newcommand{\Until}    {{\bf until\ }}
\newcommand{\Loop}     {{\bf loop\ }}
\newcommand{\Exit}     {{\bf exit\ }}
\newcommand{\Goto}     {{\bf goto\ }}
\newcommand{\Do}       {{\bf do\ }}
\newcommand{\Od}       {{\bf od\ }}
\newcommand{\Dopar}       {{\bf dopar\ }}
\newcommand{\For}      {{\bf for\ }}
\newcommand{\Step}      {{\bf step\ }}
\newcommand{\Foreach}      {{\bf foreach\ }}
\newcommand{\Rof}      {{\bf rof\ }}
\newcommand{\Forall}      {{\bf forall\ }}
\newcommand{\To}       {{\bf to\ }}
\newcommand{\If}       {{\bf if\ }}
\newcommand{\Is}       {:=}
\newcommand{\Endif}    {{\bf endif\ }}
\newcommand{\Fi}       {{\bf fi\ }}
\newcommand{\Then}     {{\bf then\ }}
\newcommand{\Else}     {{\bf else\ }}
\newcommand{\Elsif}    {{\bf elsif\ }}
\newcommand{\Return}   {{\bf return\ }}
\newcommand{\Set}      {{\bf set\ }}
\newcommand{\Boolean}  {{\bf boolean\ }}
\newcommand{\Integer}  {}
\newcommand{\True}     {{\bf true\ }}
\newcommand{\False}    {{\bf false\ }}
\newcommand{\Bitand}   {{\bf bitand\ }}
\newcommand{\Var}      {{\bf var\ }}
\newcommand{\Xor}       {{\bf\ xor\ }}
\newcommand{\Not}       {{\bf\ not\ }}
\newcommand{\Or}       {{\bf\ or\ }}
\newcommand{\Div}       {{\bf\ div\ }}
\newcommand{\Mod}       {{\bf\ mod\ }}
\newcommand{\End}       {{\bf end\ }}
\newcommand{\Endfor}       {{\bf endfor\ }}
\newcommand{\Rem}[1]   {{\bf (*~}{\rm#1}{\bf ~*)}}
\newcommand{\RRem}[1]   {\`{\bf --\hspace{0.5mm}--~}{\rm#1}}
\newcommand{\RRemNL}[1]   {\`{\bf (*~ }{\rm#1}{\bf ~*)}{\tiny\arabic{lineNumber}}\stepcounter{lineNumber}}

\newcommand{\At}[1]{\left\langle#1\right\rangle}
\newcommand{\NL}{\`{\tiny\arabic{lineNumber}}\stepcounter{lineNumber}}
\fi

\newcommand{\iProc}{i_\mathrm{PE}}

\newcommand{\dissepslong}[5]{\begin{figure}[#1]\begin{center}\epsfxsize#2\leavevmode\epsfbox{#3.eps}\end{center}\caption{\llabel{#4}#5}\end{figure}}

\newcommand{\dissepspos}[4]{\dissepslong{#1}{#2}{\labelprefix/#3}{#3}{#4}}
\newcommand{\disseps}[3]{\dissepspos{htb}{#1}{#2}{#3}}

\newdimen\endofsize\endofsize=0.5em
\def\endofbeweis{~\quad\hglue\hsize minus\hsize
                 \hbox{\vrule height \endofsize width
\endofsize}\par}
\newenvironment{myproof}{\begin{proof}}{\endofbeweis\end{proof}}


 \newcommand{\lcp}{\mathrm{lcp}}
\newcommand{\Strings}{\mathcal{S}}

\def\Oh#1{\mathcal{O}(#1)}
\def\oh#1{\mathrm{o}(#1)}
\def\Om#1{\Omega(#1)}
\def\om#1{\omega(#1)}

\newcommand{\TODO}[1]{{\sf TODO}\marginnote{#1}}

\newcommand{\arr}[1]{[\, #1 \,]}

\newcommand{\Inc}{{++}}
\newcommand{\Dec}{{--}}

\newcommand{\Rem}[1]{\tcp*{#1}}
\newcommand{\Remi}[1]{\tcp*[f]{#1}}

\newcommand{\marginnote}[1]{\marginpar{\raggedright\footnotesize \itshape#1\par}}



\begin{document}

\title{Engineering Parallel String Sorting}

\author{Timo Bingmann \and Andreas Eberle \and Peter Sanders}

\institute{
Karlsruhe Institute of Technology, Karlsruhe, Germany\\
\email{\{bingmann,sanders\}@kit.edu}}





\maketitle

\begin{abstract}
  We discuss how string sorting algorithms can be parallelized on modern
  multi-core shared memory machines.  As a synthesis of the best sequential
  string sorting algorithms and successful parallel sorting algorithms for
  atomic objects, we first propose string sample sort. The algorithm makes
  effective use of the memory hierarchy, uses additional word level parallelism,
  and largely avoids branch mispredictions. Then we focus on NUMA architectures,
  and develop parallel multiway LCP-merge and -mergesort to reduce the number of
  random memory accesses to remote nodes.  Additionally, we parallelize variants
  of multikey quicksort and radix sort that are also useful in certain
  situations. Comprehensive experiments on five current multi-core platforms are
  then reported and discussed. The experiments show that our implementations
  scale very well on real-world inputs and modern machines.
\end{abstract}

\section{Introduction}

Sorting is perhaps the most studied algorithmic problem in computer science.
While the most simple model for sorting assumes \emph{atomic} keys, an important
class of keys are strings or vectors to be sorted lexicographically. Here, it is important
to exploit the structure of the keys to avoid costly repeated operations on the
entire string.  String sorting is for example needed in database index
construction, some suffix sorting algorithms, or MapReduce tools. Although there
is a correspondingly large volume of work on sequential string sorting, there is
very little work on parallel string sorting. This is surprising since
parallelism is now the only way to get performance out of Moore's law so that
any performance critical algorithm needs to be parallelized. We therefore
started to look for practical parallel string sorting algorithms for modern
multi-core shared memory machines. Our focus is on large inputs which fit into
RAM.  This means that besides parallelization we have to take the memory
hierarchy, layout, and processor features like the high cost of branch
mispredictions, word parallelism, and super scalar processing into account.
Looking beyond single-socket multi-core architectures, we also consider
many-core machines with multiple sockets and non-uniform memory access (NUMA).

In Section~\ref{sec:basic-sequential} we give an overview of basic sequential
string sorting algorithms, acceleration techniques and more related work. We
then propose our first new string sorting algorithm, super scalar string sample
sort (S), in Section~\ref{sec:s5}. Thereafter, we turn our focus to NUMA
architectures in Section~\ref{sec:para-mergesort}, and develop parallel
LCP-aware multiway merging as a top-level algorithm for combining presorted
sequences. Broadly speaking, we propose both multiway distribution-based string
sorting with S and multiway merge-based string sorting with LCP-aware
mergesort, and parallelize both approaches.

Section~\ref{sec:more-parasort} describes parallelizations of caching multikey
quicksort and radix sort, which are two more competitors. We then compare both
parallel and sequential string sorting algorithms experimentally in
Section~\ref{sec:experiments}.

For all our input instances, except random strings, parallel S achieves
higher speedups on modern single-socket multi-core machines than our own
parallel multikey quicksort and radixsort implementations, which are already
better than any previous ones. For multi-socket NUMA machines, parallel multiway
LCP-merge with node-local parallel S achieves higher speedups for large
real-world inputs than all other implementations in our experiment.

Shorter versions of Section~\ref{sec:s5}, \ref{sec:more-parasort} and
\ref{sec:experiments} have appeared in our conference
paper~\cite{bingmann2013parallel}.  We would like to thank our students Florian
Drews, Michael Hamann, Christian Käser, and Sascha Denis Knöpfle who implemented
prototypes of our ideas.

\section{Preliminaries}\label{sec:prelim}

Our input is a set  of  strings with total
length .  A \emph{string}  is a one-based array of  characters from
the \emph{alphabet} .  We assume the canonical
lexicographic ordering relation `' on strings, and our goal is to sort
 lexicographically.  For the implementation and pseudo-code, we
require that strings are zero-terminated, i.e. , but
this convention can be replaced using other end-of-string indicators, like
string length.

Let  denote the \emph{distinguishing prefix size} of , i.e., the
total number of characters that need to be inspected in order to establish the
lexicographic ordering of .  is a natural lower bound for the
execution time of sequential string sorting. If, moreover, sorting is based on
character comparisons, we get a lower bound of .

Sets of strings are usually represented as arrays of pointers to the beginning
of each string. Note that this indirection means that, in general, every access
to a string incurs a cache fault even if we are scanning an array of strings.
This is a major difference to atomic sorting algorithms where scanning is very
cache efficient.  Our target machine is a shared memory system supporting 
hardware threads or processing elements (PEs), on  cores.

\subsection{Notation and Pseudo-code}

The algorithms in this paper are written in a pseudo-code language, which mixes
Pascal-like control flow with array manipulation and mathematical set notation.
This enables powerful expressions like , which sets  to be the array of pairs . We write ordered sequences like arrays using square brackets
, overload `' to also concatenate arrays, and let  and  be ranges of integers.  To
make array operations more concise, we assume  and  both to be the
-th element in the array . We do not allocate or declare arrays and
variables beforehand, so  also implicitly defines an array . The
unary operators `` and `` increment and decrement integer variables
by one.

To avoid special cases, we use the following sentinels: `' is the
empty string, which is lexicographically smaller than any other string,
`' is a character or string larger than any other character or string,
and `' is an undefined variable.

For two arrays  and , let  denote the length of the
\emph{longest common prefix} (LCP) of  and . This function is symmetric,
and for one-based arrays the LCP value denotes the last index where  and 
match, while position  differs in  and , if it exists.  In a
sequence  let  denote . For a sorted sequence
of strings  the \emph{associated LCP~array}
 is  with . For the empty string , let  for any string .

We will often need the sum over all items in an LCP array  (excluding the
first), and denote this as , or just  if  is
clear from the context. The distinguishing prefix size  and  are related
but not identical. While  includes all characters counted in ,
additionally,  also accounts for the distinguishing characters, some string
terminators and characters of the first string. In general, we have .

\section{Basic Sequential String Sorting Algorithms}\label{sec:basic-sequential}

We begin by giving an overview of most efficient sequential string sorting
algorithms. Nearly all algorithms classify the original string set 
into smaller sets with a distinct common prefix. The smaller sets are then
sorted further recursively, until the sets contain only one item or another
string sorter is called.

\emph{Multikey quicksort} \cite{bentley1997fast} is a simple but effective
adaptation of quicksort to strings (called multi-key data).  When all strings in
 have a common prefix of length , the algorithm uses character
 of a pivot string  (e.g. a pseudo-median) as a
\emph{splitter} character.  is then partitioned into ,
, and  depending on comparisons of the -th
character with . Recursion is done on all three subproblems. The key
observation is that the strings in  have common prefix length
 which means that compared characters found to be equal with  will
never be considered again. Insertion sort is used as a base case for constant
size inputs. This leads to a total execution time of . Multikey
quicksort works well in practice in particular for inputs which fit into the
cache. Since a variant of multikey quicksort was the overall best sequential
algorithm in our experiments, we develop a parallel version in
Section~\ref{sec:para-mkqs}.

\emph{MSD radix sort}
\cite{mcilroy1993engineering,ng2007cache,karkkainen2009engineering} with common
prefix length  looks at the -th character producing 
subproblems which are then sorted recursively with common prefix . This
is a good algorithm for large inputs and small alphabets since it uses the
maximum amount of information within a single character. For input sizes
 MSD radix sort is no longer efficient and one has to switch to a
different algorithm for the base case. The running time is  plus the
time for solving the base cases. Using multikey quicksort for the base case
yields an algorithm with running time . A problem with large
alphabets is that one will get many cache faults if the cache cannot support
 concurrent output streams (see \cite{mehlhorn2003scanning} for
details). We discuss parallel radix sorting in Section~\ref{sec:para-radixsort}.

\emph{Burstsort} dynamically builds a trie data structure for the input
strings. In order to reduce the involved work and to become cache efficient, the
trie is build lazily -- only when the number of strings referenced in a
particular subtree of the trie exceeds a threshold, this part is expanded. Once
all strings are inserted, the relatively small sets of strings stored at the
leaves of the trie are sorted recursively (for more details refer to
\cite{sinha2004cache-conscious,sinha2007cache-efficient,sinha2010engineering}
and the references therein).

\emph{LCP-Mergesort} is an adaptation of mergesort to strings that saves and
reuses the LCPs of consecutive strings in the sorted subproblems
\cite{ng2008merging}. In section~\ref{sec:para-mergesort}, we develop a parallel
multiway variant of LCP-merge, which is used to improve performance on NUMA
machines. Our multiway LCP-merge is also interesting for merging of
string sets stored in external memory.

\emph{Insertion sort} \cite{knuth1998sorting} keeps an ordered array, into which
unsorted items are inserted by linearly scanning for their correct position. If
strings are considered atomic, then full string comparisons are done during the
linear scan. This is particularly cache-efficient and the algorithm is commonly
used as base case sorter.  However, if one keeps additionally the associated LCP
array, the number of character comparisons can be decreased, trading them for
integer comparisons of LCPs. We needed a base case sorter that also calculates
the LCP array and found no reference for LCP-aware insertion sort in the
literature, so we describe the algorithm in Section~\ref{sec:lcp-inssort}.

\subsection{Architecture Specific Enhancements}

To increase the performance of basic sequential string sorting algorithms on
real hardware, we have to take its architecture into consideration.  In the
following list we highlight some of most important optimization principles.

\emph{Memory access time} varies greatly in modern systems.  While the RAM model
considers all memory accesses to take unit time, current architectures have
multiple levels of cache, require additional memory access on TLB misses, and
may have to request data from ``remote'' nodes on NUMA systems.  While there are
few hard guarantees, we can still expect recently used memory to be in cache and
use these assumptions to design cache-efficient algorithms.  Furthermore, on
NUMA systems we can instruct the kernel on how to distribute memory by
specifying allocation policies for memory segments

\emph{Caching of characters} is very important for modern memory hierarchies as
it reduces the number of cache misses due to random access on strings.  When
performing character lookups, a caching algorithm copies successive characters
of the string into a more convenient memory area.  Subsequent sorting steps can
then avoid random access, until the cache needs to be refilled.  This technique
has successfully been applied to radix sort \cite{ng2007cache}, multikey
quicksort \cite{rantala2007web}, and in its extreme to burstsort
\cite{sinha2007cache-efficient}. However, caching comes at the cost of increased
space requirements and memory accesses, hence a good trade-off must be found.

\emph{Super-Alphabets} can be used to accelerate string sorting algorithms which
originally look only at single characters.  Instead, multiple characters are
grouped as one and sorted together.  However, most algorithms are very sensitive
to large alphabets, thus the group size must be chosen carefully.  This approach
results in 16-bit MSD radix sort and fast sorters for DNA strings.  If the
grouping is done to fit many characters into a machine word for processing as a
whole block using arithmetic instructions, then this is also called \emph{word
  parallelism}.

\emph{Unrolling, fission and vectorization of loops} are methods to exploit
out-of-order execution and super scalar parallelism now standard in modern CPUs.
The processor's instruction scheduler automatically analyses the machine code,
detects data dependencies and can dispatch multiple parallel operations.
However, only specific, simple data independencies can be detected and thus
inner loops must be designed with care (e.g. for radix sort
\cite{karkkainen2009engineering}). The performance increase by reorganizing
loops is most difficult to predict.

\subsection{More Related Work}

There is a huge amount of work on parallel sorting of atomic objects so that we
can only discuss the most relevant results. Besides (multiway) mergesort,
perhaps the most practical parallel sorting algorithms are parallelizations of
radix sort (e.g.~\cite{wassenberg2011engineering}) and
quicksort~\cite{tsigas2003simple} as well as sample
sort~\cite{blelloch1991comparison}.

There is some work on PRAM algorithms for string sorting
(e.g. \cite{hagerup94optimal}). By combining pairs of adjacent characters into
single characters, one obtains algorithms with work  and time
. Compared to the sequential algorithms this is
suboptimal unless  and with this approach it is unclear how to
avoid work on characters outside distinguishing prefixes.

We found no publications on practical parallel string sorting, aside from our
conference paper~\cite{bingmann2013parallel}. However, Ta\-kuya Akiba has
implemented a parallel radix sort \cite{akiba2011radixsort}, Tommi Rantala's
library~\cite{rantala2007web} contains multiple parallel mergesorts and a
parallel SIMD variant of multikey quicksort, and Nagaraja
Shamsundar~\cite{shamsundar2009lcpmergesort} also parallelized Waihong Ng's
LCP-mergesort \cite{ng2008merging}. Of all these implementations, only the radix
sort by Akiba scales reasonably well to many-core architectures.  We discuss the
scalability issues of these implementations in Section~\ref{sec:exp-parallel}.

\section{Super Scalar String Sample Sort (\texorpdfstring{S}{S5})}\label{sec:s5}

Already in a sequential setting, theoretical considerations and experiments (see
Section~\ref{sec:exp-sequential}) indicate that \emph{the} best string sorting
algorithm does not exist.  Rather, it depends at least on , , ,
and the hardware.  Therefore we decided to parallelize several algorithms taking
care that components like data distribution, load balancing or base case sorter
can be reused.  Remarkably, most algorithms in
Section~\ref{sec:basic-sequential} can be parallelized rather easily and we will
discuss parallel versions in
Sections~\ref{sec:s5}--\ref{sec:more-parasort}. However, none of these
parallelizations make use of the striking new feature of modern many-core
systems: many multi-core processors with individual cache levels but relatively
few and slow memory channels to shared RAM. Therefore we decided to design a new
string sorting algorithm based on \emph{sample sort}
\cite{frazer1970samplesort}, which exploits these properties.  Preliminary
result on string sample sort have been reported in the bachelor thesis of Sascha
Denis Knöpfle~\cite{knoepfle2012string}.

\subsection{Traditional (Parallel) Atomic Sample Sort}\label{sec:ss-atomic}

Sample sort \cite{frazer1970samplesort,blelloch1991comparison} is a generalization of quicksort working
with  pivots at the same time.  For small inputs, sample sort uses some
sequential base case sorter.  Larger inputs are split into  \emph{buckets}
 by determining  splitter keys 
and then classifying the input elements -- element  goes to bucket  if
 (where  and  are defined as sentinel elements --
 being smaller than all possible input elements and  being larger).
Splitters can be determined by drawing a random sample of size  from
the input, sorting it, and then taking every -th element as a
splitter. Parameter  is the \emph{oversampling} factor. The buckets are
then sorted recursively and concatenated. ``Traditional'' parallel sample sort
chooses  and uses a sample big enough to assure that all buckets have
approximately equal size.  Sample sort is also attractive as a sequential
algorithm since it is more cache efficient than quicksort and since it is
particularly easy to avoid branch mispredictions (super scalar sample sort --
S) \cite{sanders2004super}. In this case,  is chosen in such a way that
classification and data distribution can be done in a cache efficient way.

\subsection{String Sample Sort}\label{sec:ss-string}

In order to adapt the atomic sample sort from the previous section to strings,
we have to devise an efficient classification algorithm.  Most importantly, we
want to avoid comparing whole strings needlessly, and thus focus on character
comparisons.  Also, in order to approach total work , we have to
use the information gained during classification in the recursive calls. This
can be done by observing that strings in buckets have a common prefix depending
on the LCP of the two splitters:

Another issue is that we have to reconcile the parallelization and load
balancing perspective from traditional parallel sample sort with the cache
efficiency perspective of super scalar sample sort, where the splitters are
designed to fit into cache. We do this by using dynamic load balancing which
includes parallel execution of recursive calls as in parallel quicksort. Dynamic
load balancing is very important and probably unavoidable for parallel string
sorting, because any algorithm must adapt to the input string set's
characteristics.

\subsection{Super Scalar String Sample Sort (\texorpdfstring{S}{S5}) -- A Pragmatic Solution}

We adapt the implicit binary search tree approach used in (atomic) super scalar
sample sort (S)~\cite{sanders2004super} to strings.  Algorithm~\ref{alg:s5}
shows pseudo-code of one variant of S as a guideline through the following
discussion, and Figure~\ref{fig:ternary-tree} illustrates the classification
tree with buckets and splitters.

\begin{figure}[t]\centering
\begin{tikzpicture}[
  xscale=0.6,
  bucket/.style={draw,rectangle,inner sep=2pt},
  keynode/.style={draw,circle,inner sep=1pt},
  equall/.style={fill=white,inner sep=2pt,text depth=-1pt},
  ]

\node (k1) [keynode] at (7,3) {\vphantom{0}};

\node (k2) [keynode] at (3,2) {\vphantom{0}};
\node (k3) [keynode] at (11,2) {\vphantom{0}};

\node (k4) [keynode] at (1,1) {\vphantom{0}};
\node (k5) [keynode] at (5,1) {\vphantom{0}};
\node (k6) [keynode] at (9,1) {\vphantom{0}};
\node (k7) [keynode] at (13,1) {\vphantom{0}};

\node (b0)  [bucket] at (0,0) {\vphantom{0}};
\node (b1)  [bucket] at (1,0) {\vphantom{0}};
\node (b2)  [bucket] at (2,0) {\vphantom{0}};
\node (b3)  [bucket] at (3,0) {\vphantom{0}};
\node (b4)  [bucket] at (4,0) {\vphantom{0}};
\node (b5)  [bucket] at (5,0) {\vphantom{0}};
\node (b6)  [bucket] at (6,0) {\vphantom{0}};
\node (b7)  [bucket] at (7,0) {\vphantom{0}};
\node (b8)  [bucket] at (8,0) {\vphantom{0}};
\node (b9)  [bucket] at (9,0) {\vphantom{0}};
\node (b10) [bucket] at (10,0) {\vphantom{0}};
\node (b11) [bucket] at (11,0) {\vphantom{0}};
\node (b12) [bucket] at (12,0) {\vphantom{0}};
\node (b13) [bucket] at (13,0) {\vphantom{0}};
\node (b14) [bucket] at (14,0) {\vphantom{0}};

\draw (k1) -- node[above] {} (k2);
\draw (k1) -- node[equall] {} (b7);
\draw (k1) -- node[above] {} (k3);

\draw (k2) -- node[above] {} (k4);
\draw (k2) -- node[equall] {} (b3);
\draw (k2) -- node[above] {} (k5);

\draw (k3) -- node[above] {} (k6);
\draw (k3) -- node[equall] {} (b11);
\draw (k3) -- node[above] {} (k7);

\draw (k4) -- node[left] {} (b0);
\draw (k4) -- node[equall] {} (b1);
\draw (k4) -- node[right] {} (b2);

\draw (k5) -- node[left] {} (b4);
\draw (k5) -- node[equall] {} (b5);
\draw (k5) -- node[right] {} (b6);

\draw (k6) -- node[left] {} (b8);
\draw (k6) -- node[equall] {} (b9);
\draw (k6) -- node[right] {} (b10);

\draw (k7) -- node[left] {} (b12);
\draw (k7) -- node[equall] {} (b13);
\draw (k7) -- node[right] {} (b14);

\end{tikzpicture}   \caption{Ternary classification tree for  splitters and  buckets.}\label{fig:ternary-tree}
\end{figure}

Rather than using whole strings as arbitrarily long splitters, or all characters
of the alphabet as in radix sort, we design the splitter keys to consist of
\emph{as many characters as fit into a machine word}.  In the following let 
denote the number of characters fitting into one machine word (for 8-bit
characters and 64-bit machine words we would have ).  We choose 
splitters  (for some integer ) from a sorted sample to
construct a \emph{perfect binary search tree}, which is used to classify a set
of strings based on the next  characters at common prefix . The main
disadvantage of this approach is that we may have many input strings whose next
 characters are identical.  For these strings, the classification does not
reveal much information. We make the best out of such inputs by explicitly
defining \emph{equality buckets} for strings whose next  characters exactly
match .  For equality buckets, we can increase the common prefix length by
 in the recursive calls, i.e., these characters will never be inspected
again.  In total, we have  different buckets 
for a ternary search tree (see Figure~\ref{fig:ternary-tree}).


\begin{algorithm2e}[t]
\caption{Sequential Super Scalar String Sample Sort -- a single step}\label{alg:s5}\normalsize

\KwIn{ a set of strings with common prefix .}

 \Rem{Read sample  of ,}
 \Rem{sort it, and select}
 \Rem{equidistant splitters.}\nllabel{alg:s5:sample}
 \KwSty{with}  \Rem{Construct tree,}\nllabel{alg:s5:tree}
 \Rem{and save LCPs of splitters.}\nllabel{alg:s5:slcp}
\For(\Remi{Process strings (interleavable loop).}\nllabel{alg:s5:strloop})
{}
{
  \KwSty{local} ,\quad  \Rem{Start at root, get  chars from ,}
  \For(\Remi{and traverse tree (unrollable loop)}\nllabel{alg:s5:treeloop})
  {}
  {
     \Rem{without branches using ``'' .}\nllabel{alg:s5:chartest}
  }
  ,\quad \KwSty{local}  \Rem{Calculate matching non-equality bucket.}
  \lIf(\Remi{Test for equality with next splitter.})
  {\nllabel{alg:s5:eqtest}}
  {
    
  }
   \Rem{Save final bucket number for string  in an oracle.}\nllabel{alg:s5:end-strloop}
}
 \nllabel{alg:s5:bktzero}\Rem{Inclusive prefix sum}
\lFor(\Remi{over bucket sizes})
{}
{
  \nllabel{alg:s5:count}
}
 \Rem{as fissioned loops.}\nllabel{alg:s5:prefixsum}
\lFor(\Remi{Reorder strings into new subsets.})
{}
{
  \nllabel{alg:s5:redistribute}
}

\KwOut{ are  string subsets with . The subsets have common prefix  for  even, and
  common prefix  for  odd.}

\end{algorithm2e}

Testing for equality can either be implemented by explicit equality tests at
each node of the search tree (which saves time when most elements end up in a
few large equality buckets) or by going down the search tree all the way to a
bucket  ( even) doing only -comparisons, followed by a single
equality test with , unless . This last variant is
shown in Algorithm~\ref{alg:s5}, and the equality test is done in
line~\ref{alg:s5:eqtest}.

Postponing the equality test allows us to completely unroll the loop descending
the search tree (line~\ref{alg:s5:treeloop}), since there is no exit
condition. We can then also unroll the loop over the elements
(line~\ref{alg:s5:strloop}), interleaving independent tree descent
operations. The number of interleaved descents is limited in practice by the
number of registers to hold local variables like  and . As in
\cite{sanders2004super}, this is an important optimization since it allows the
instruction scheduler in a super scalar processor to parallelize the operations
by drawing data dependencies apart.

After reordering, the strings in the ``'' and ``'' buckets
 and  keep common prefix length . For other even buckets
 the common prefix length is increased by .

An analysis similar to the one of multikey quicksort \cite{bentley1997fast} lets
us conjecture the following asymptotic time bound.

\begin{conjecture}\label{thm:s5}
  String sample sort with implicit binary trees, word parallelism and equality
  checking at each splitter node can be implemented to run in expected time
  .
\end{conjecture}

We now argue the correctness of Conjecture~\ref{thm:s5}, without giving a formal
proof\footnote{We are currently working on this for a final version of this
  paper}.  The classification schemes of multikey quicksort and string sample
sort can both be seen as a tree. In this tree, edges are either associated with
characters of a distinguishing prefix, or with string ranges determined by
splitters.

In multikey quicksort each inner node  of the tree has three children: ,
, and . We can associate each character comparison during partitioning at
node  with the thereby determined edge.  By selecting pivots randomly or
using a sample median, the expected number of  and ~edges in all paths
from the root is  \cite{hoare1962quicksort,bentley1997fast}, since
this approach is identical to atomic quicksort. Thus the time spent over all
comparisons accounted by these edges is expected . All
comparisons associated with ~edges correspond to characters from the
distinguishing prefix, and are thus bounded by . In total we have  work in the multikey quicksort tree.

We can view string sample sort as a multikey quicksort using multiple pivots in
the classification tree, as seen in Figure~\ref{fig:ternary-tree}.  In string
sample sort, an ~edge matches  characters, of which at least one is from
the distinguishing prefix  (but usually all are). If any of the 
characters is not counted in , then the ~edge leads to a leaf, which does
not require further sorting. There are at most  such comparisons leading to
leaves, all other ~edges match  characters. Thus we have at most
 comparisons leading to ~edges.  To prove our conjecture, we
need to show that the expected number of  and ~edges on all paths from the
root is .  However, we are not aware of any analysis of sample sort
showing this expected run time for a \emph{fixed sample size}. Furthermore, in
string sample sort we have to deal with the probability of multiple equal
samples and need to resample strings repeatedly at higher depths, thus the known
analysis of a single top-level sampling approach
\cite{blelloch1991comparison,yang1987optimal,frazer1970samplesort} do not
apply. Nevertheless, due to repeated resampling, we can conjecture that the
bucket sizes grow small very fast, just as they do in atomic sample sort.  By
using the additional LCP information gained at  and  edges from
Equation~\ref{eq:lcp} one could decrease the expected path length from the root
further, though probably not asymptotically.

If the ~edges are taken immediately, as done in the variant with explicit
equality checking at each node, then we conjecture expected  time.  However, if we choose to unroll descents of the tree, then the
splitter at the root may match and the  additional steps down the
tree are superfluous.  This happens when many strings are identical, and the
corresponding splitters are high up in the tree. We thus have to attribute
 time to the ~edges. Together with the
expected cost of  and ~edges, we conjecture in total an expected
 bound.

String sample sort is particularly easy to parallelize for , as in
current multi-core architectures, and we can state the following theorem.

\begin{theorem}
  A single step of super scalar string sample sort (Algorithm~\ref{alg:s5}) can
  be implemented to run on a CREW PRAM with ~processors in  time and  work.
\end{theorem}
\begin{proof}
  Sorting the sample requires  time and
   work, where  is the
  sample size. Selecting the sample, picking splitters, constructing the tree
  and saving LCP of splitters is all  time and 
  work. Each processors gets  strings and in worst case runs down
  all  steps in the classification tree, which is  time and  work. Departing from
  lines~\ref{alg:s5:bktzero}--\ref{alg:s5:redistribute}, each processor keeps
  its own bucket array , initializes it in  time, and classifies
  only those strings in its string set. Then, an interleaved global prefix sum
  over the  bucket counters yields the boundaries in which each
  processor can independently redistribute its strings. The prefix sum runs in
   time and  work~\cite{kogge1973parallel}, while
  counting and redistribution runs in  time and 
  work. Summing all time and work yields our result.
\end{proof}

We only consider a single step here, and thus cannot use the distinguishing
prefix  to bound the overall work.

\subsection{Implementation Details}

One goal of S is to have a common classification data structure that fits
into the cache of all cores. Using this data structure, all PEs can
independently classify a subset of the strings into buckets in parallel.  The
process follows the classic distribution-based sorting steps: we first classify
strings (lines~\ref{alg:s5:strloop}--\ref{alg:s5:end-strloop}), counting how
many fall into each bucket (line~\ref{alg:s5:count}), then calculate a prefix
sum (line~\ref{alg:s5:prefixsum}) and redistribute the string pointers
accordingly (line~\ref{alg:s5:redistribute}). To avoid traversing the tree
twice, the bucket index of each string is stored in an oracle
(lines~\ref{alg:s5:end-strloop}, \ref{alg:s5:count},
\ref{alg:s5:redistribute}). Additionally, to make higher use of super scalar
parallelism, we even separate the classification loop
(line~\ref{alg:s5:strloop}) from the counting loop (line~\ref{alg:s5:count}), as
done by \cite{karkkainen2009engineering}.

Like in S, the binary tree of splitters is stored in level-order as an array
 (line~\ref{alg:s5:tree}), allowing efficient traversal using , without branch mispredictions in line~\ref{alg:s5:chartest}. The
pseudo-code ``'', which yields  or , can be implemented
using different machine instructions. One method is to use the instruction
\texttt{SETA}, which sets a register to  or  depending on a preceding
comparison. Alternatively, newer processors have predicated instruction like
\texttt{CMOVA} to conditionally move one register to another, again depending on
a preceding comparison's outcome. We noticed that \texttt{CMOVA} was slightly
faster than flag arithmetic.

While traversing the classification tree, we compare  characters using one
arithmetic comparison. However, we need to make sure that these comparisons
have the desired outcome, e.g., that the most significant bits of the register
hold the first character. For little-endian machines and 8-bit characters, which
are used in all of our experiments, we need to \emph{swap the byte order} when
loading character from a string. In our implementation we do this using the
\texttt{BSWAP} machine instruction. In the pseudo-code (Algorithm~\ref{alg:s5})
this operation is symbolized by , which fetches 
characters from  at depth , and swaps them appropriately.

For performing the equality check, already mentioned in the previous section, we
want to discuss four different alternatives in more technical details here:
\begin{enumerate}
\item One can traverse the tree using only -comparisons and perform the
  equality check afterwards, as shown in Algorithm~\ref{alg:s5}. For this we
  keep the splitters  in an in-order array, in addition to the
  classification tree , which contains them in level-order. Duplicating the
  splitters avoids additional work in line~\ref{alg:s5:eqtest}, where  is an
  in-order index. This variant was our final choice, called S-Unroll, as it
  was overall fastest.

\item The additional in-order array from the previous variant, however, can be
  removed. Instead, a rather simple calculation involving only bit operations
  can be used to transform the in-order index  back to level-order, and reuse
  the classification tree . We tried this variant, but found no performance
  advantage over the first.

\item Another idea is to keep track of the last -branch during tree
  traversal, this however was slower and requires an extra register for each of
  the interleaved descents.

\item The last variant is to check for equality after each comparison in
  line~\ref{alg:s5:chartest}. This requires only an additional \texttt{JE}
  instruction and no extra \texttt{CMP} in the inner-most loop.  The branch
  misprediction cost of the \texttt{JE} is counter-balanced by skipping the rest
  of the tree.  As  is a tree-order index when exiting the inner loop, we
  need to apply the inverse of the transformation mentioned in the second method
  to  to determine the correct equality bucket.  Thus in this fourth variant,
  named S-Equal, no additional in-order splitter array is needed.

\end{enumerate}

The sample is drawn pseudo-randomly with an oversampling factor  to
keep it in cache when sorting with STL's introsort and building the search tree.
Instead of using the straight-forward equidistant method to draw splitters from
the sample, as shown in Algorithm~\ref{alg:s5} (line~\ref{alg:s5:sample}), we
developed a simple recursive scheme that tries to avoid using the same splitter
multiple times: Select the middle sample  of a range  (initially the
whole sample) as the middle splitter . Find new boundaries  and
 by scanning left and right from  \emph{skipping} samples equal to
. Recurse on  and .  The splitter tree selected by this
heuristic was never slower than equidistant selection, but slightly faster for
inputs with many equal common prefixes. It is used in all our experiments.

The LCP of two consecutive splitters in line~\ref{alg:s5:slcp} can be calculated
without a loop using just two machine instructions: \texttt{XOR} and
\texttt{BSR} (to count the number of leading zero bits in the result of
\texttt{XOR}). In our implementation, these calculation are done while selecting
splitters. Similarly, we need to check if splitters contain end-of-string
terminators, and skip the recursion in this case.

For current 64-bit machines with 256\,KiB L2 cache, we use . Note that
the limiting data structure which must fit into L2 cache is not the splitter
tree , which is only 64\,KiB for this , but is the bucket counter array
 containing  counters, each 8 bytes long. We did not look into methods
to reduce this array's size, because the search tree is stored both in
level-order and in in-order, and thus we could not increase the tree size
anyway.

\subsection{Practical Parallelization of \texorpdfstring{S}{S5}}\label{sec:parallel-s5}

Parallel S (pS) is composed of four sub-algorithms for differently sized
subsets of strings. For a string subset  with , a \emph{fully parallel version} of S is run, for large sizes
 a sequential version of S is used, for
sizes  the fastest sequential algorithm for
medium-size inputs (caching multikey quicksort from Section~\ref{sec:para-mkqs})
is called, which internally uses insertion sort when .  We
empirically determined  and  as good thresholds to
switch sub-algorithms.

The fully parallel version of S uses 
threads for a subset . It consists of four stages: selecting samples
and generating a splitter tree, parallel classification and counting, global
prefix sum, and redistribution into buckets. Selecting the sample and
constructing the search tree are done sequentially, as these steps have
negligible run time. Classification is done independently, dividing the string
set evenly among the  threads. The prefix sum is done sequentially once all
threads finish counting.

In both the sequential and parallel versions of S we permute the string
pointer array using out-of-place redistribution into an extra array. In
principle, we could do an in-place permutation in the sequential version by
walking cycles of the permutation \cite{mcilroy1993engineering}. Compared to
out-of-place copying, the in-place algorithm uses fewer input/output streams and
requires no extra space. However, we found that modern processors optimize the
sequential reading and writing pattern of the out-of-place version better than
the random access pattern of the in-place walking. Furthermore, for fully
parallel S, an in-place permutation cannot be done in the same manner.  We
therefore always use \emph{out-of-place redistribution}, with an extra string
pointer array of size . For recursive calls, the role of the extra array and
original array are swapped, which saves superfluous copying work.

All work in parallel S is dynamically load balanced via a central job
queue. We use the lock-free queue implementation from Intel's Thread Building
Blocks (TBB) and threads initiated by OpenMP to create a \emph{light-weight
  thread pool}.

To make work balancing most efficient, we modified all sequential
sub-al\-go\-rithms of parallel S to use an explicit recursion stack. The
traditional way to implement dynamic load balancing would be to use work
stealing among the sequentially working threads. This would require the
operations on the local recursion stacks to be synchronized or atomic. However,
for our application fast stack operations are crucial for performance as they
are very frequent. We therefore choose a different method: \emph{voluntary work
  sharing}. If the global job queue is empty and a thread is idle, then a global
atomic counter is incremented to indicate that other threads should share their
work. These then free the stack level with the \emph{largest subproblems} from
their local recursion stack and enqueue these as separate, independent
jobs. This method avoids costly atomic operations on the local stacks, replacing
it by a faster counter check, which itself \emph{need not be synchronized} or
atomic. The short wait of an idle thread for new work does not occur often,
because the largest recursive subproblems are shared. Furthermore, the global
job queue never gets large because most subproblems are kept on local stacks.

\section{Parallel Multiway LCP-Mergesort}\label{sec:para-mergesort}

When designing pS we considered L2 cache sizes, word parallelism, super
scalar parallelism and other modern features. However, new architectures with
large amounts of RAM are now commonly non-uniform memory access (NUMA) systems,
and the RAM chips are distributed onto different memory banks, called \emph{NUMA
  nodes}. In preliminary synthetic experiments, access to memory on ``remote''
nodes was 2--5 times slower than memory on the local socket, because the
requests must pass over an additional interconnection bus. This latency and
throughput disparity brings algorithms for external and distributed memory to
mind, but the divide is much less pronounced and block sizes are smaller.

In light of this disparity, we propose to use \emph{independent string sorters}
on each NUMA node, and then \emph{merge} the sorted results. During merging, the
amount of information per transmission unit passed via the interconnect (64-byte
cache lines) should be maximized. Thus, besides the sorted string pointers, we
also want to use LCP information to skip over known common prefixes, and cache
the distinguishing characters.

While merging sorted sequences of strings with associated LCP information is a
very intuitive idea, remarkably, only one very recent paper by Ng and
Kakehi~\cite{ng2008merging} fully considers LCP-aware mergesort for
strings. They describe \emph{binary} LCP-merge\-sort and perform an average case
analysis yielding estimates for the number of comparisons needed. For the NUMA
scenario, however, we need a \emph{parallel -way LCP-merge}, where  is
the number of NUMA nodes.  Furthermore, we also need to extend our existing
string sorting algorithms to save the LCP array.

In the next section, we first review binary LCP-aware merging. On this
foundation we then propose and analyze parallel -way LCP-merging in
Sections~\ref{sec:merge-kway}--\ref{sec:merge-details}. For node-local LCP
calculations, we extended pS appropriately, and describe the necessary
LCP-aware base case sorter in Section~\ref{sec:lcp-inssort}. Further information
on the results of this section are available in the bachelor thesis of Andreas
Eberle~\cite{eberle2014parallel}.

\subsection{Binary LCP-Compare and LCP-Mergesort}\label{sec:mergesort-binary}

We reformulate the binary LCP-merge and -mergesort presented by Ng and
Ka\-ke\-hi~\cite{ng2008merging} here in a different way. Our exposition is somewhat
more verbose than necessary, but this is intentional and prepares for a simpler
description of -way LCP-merge in the following section.

Consider the basic comparison of two strings  and . If there is no
additional LCP information, the strings must be compared character-wise until a
mismatch is found. However, if we have additionally the LCP of  and 
to another string , namely  and , then we can first
compare these LCP values. Since both reference , we know that  and 
share a common prefix  and that this common
prefix is maximal (i.e. longest). Thus if , then the
two strings  and  differ at position . If we
now furthermore assume , then we immediately see , from which follows . The argument can be
applied symmetrically if .

There remains the case . Here, the LCP information
only reveals that both have a common prefix , and additional
character comparisons starting at the common prefix are necessary to order the
strings.

\begin{algorithm2e}[t]
\caption{Binary LCP-Compare}\label{alg:LCP-compare}\normalsize
\Function{\LCPCompare{}}
{
  \KwIn{ and  where  and  are two strings
    together with LCPs  and , and  is
    another string with  and .}

  \uIf(\Remi{case 1: LCPs are equal  compare more characters,})
  {}
  {
     \Rem{starting at .}
    \While(\Remi{Compare characters and}\nllabel{alg:LCP-compare:charloop})
    {}
    {
       \Rem{increase total LCP.}
    }
    \lIf(\nllabel{alg:LCP-compare:charcmp2})
    {}
    {
      \Return 
    }
    \lElse
    {
      \Return 
    }
  }
  \lElseIf(\Remi{case 2: .})
  {}
  {
    \Return 
  }
  \lElse(\Remi{case 3: .})
  {
    \Return 
  }
  \KwOut{ with , , and .}
}
\end{algorithm2e}

The pseudo-code in Algorithm~\ref{alg:LCP-compare} implements these three
cases. In preparation for -way LCP-merge, the function \LCPCompare
additionally takes variables  and , which are corresponding indexes and
returns these instead of  or . It also calculates more information
than just the order of  and , since future LCP-aware comparisons also
require .

In the cases , the  is easily
inferred since the character after the smaller LCP differs in  and
. From this follows , as already
stated above. For  each additionally compared equal
character is common to both  and , and the comparison loop in
line~\ref{alg:LCP-compare:charloop} of Algorithm~\ref{alg:LCP-compare} breaks at
the first mismatch or zero termination. Thus afterwards ,
and can be returned as such.

Using \LCPCompare we can now build a binary LCP-aware merging method, which
merges two sorted string sequences with associated LCP arrays. One only needs to
take  and , compare then using \LCPCompare, write the smaller of them,
say , to the output and fetch its successor  from the sorted
sequence. The written string  then plays the role of  in the
discussion above, and the next two candidate strings  and  can be
compared, since  is returned by \LCPCompare and
 is known from the corresponding LCP array. This
procedure is detailed in Algorithm~\ref{alg:LCP-merge}. For binary merging, we
can ignore the  returned by \LCPCompare. Notice that using the indexes 
and , the LCP invariant can be restored using just one assignment in
line~\ref{alg:LCP-merge:lcp-swap}.

\begin{theorem}\label{thm:LCP-mergesort}
  Using Algorithm~\ref{alg:LCP-merge}, one can implement a binary LCP-mergesort
  algorithm, which requires at most  character
  comparisons and runs in  time.
\end{theorem}
\begin{proof}
  We assume the divide step of binary LCP-mergesort to do straight-forward
  halving as in non-LCP mergesort \cite{knuth1998sorting}, which is why we
  omitted its pseudo-code. Likewise, the recursive division steps have at most
  depth  when reaching the base case. If we briefly
  ignore the character comparison loop in \LCPCompare,
  line~\ref{alg:LCP-compare:charloop}, and regard it as a single comparison,
  then the standard divide-and-conquer recurrence  of non-LCP mergesort
  still holds. Regarding the character comparison loop, we can establish that
  each increment of  ultimately increases the overall LCP sum by exactly
  one, since in all other statements LCPs are only moved, swapped or stored, but
  never decreased or discarded.  Another way to see this is that the character
  comparison loop is the only place where characters are compared, thus to be
  able to establish the correctly sorted order, all distinguishing characters
  must be compared here.

  We regard the three different comparison expressions in
  lines~\ref{alg:LCP-compare:charloop}--\ref{alg:LCP-compare:charcmp2} as one
  ternary comparison, as the same values are checked again and zero-terminators
  can be handled using flag tests.  To count the total number of comparisons, we
  can thus account for all \textsl{true}-outcomes of the while loop condition in
  \LCPCompare (line~\ref{alg:LCP-compare:charloop}) using , and all
  \textsl{false}-outcomes using , since this is the
  highest number of times case 1 can occur in the mergesort recursion. This is
  an upper bound, and for most string sets, cases~2 and 3 reduce the number of
  comparisons in the second term.  Since , the time complexity  follows immediately.
\end{proof}

\begin{algorithm2e}[t]
\caption{Binary LCP-Merge}\label{alg:LCP-merge}\normalsize

\KwIn{ and  two sorted sequences of strings with LCP
  arrays  and . Assume sentinels 
  for , and .}

,\quad ,\quad  \Rem{Indexes for ,  and .}
,\quad  \Rem{Invariant:  for .}
\While{}
{
  ,\quad  \Rem{Fetch strings  and ,}
   \Rem{compare them,}
  ,\quad  \Rem{put smaller into output}
  ,\quad  \Rem{and advance to next.}\nllabel{alg:LCP-merge:lcp-swap}
}

\KwOut{ contains sorted  and , and  has the LCP array }

\end{algorithm2e}

Ng and Kakehi \cite{ng2008merging} do not give an explicit worst case
analysis. Their average case analysis shows, that the total number of character
comparisons of binary LCP-mergesort is about , where  is the average length of distinguishing prefixes and
 the probability of a ``breakdown'' (which corresponds to case 1 in
\LCPCompare). Taking  and , their equation
matches our worst-case result, except for the minor difference between  and
.

\subsection{\texorpdfstring{}{K}-way LCP-Merge}\label{sec:merge-kway}

To accelerate LCP-merge for NUMA systems, we extended the binary LCP-merge
approach to -way LCP-merge using tournament
trees~\cite{knuth1998sorting,sanders00fast}, since current NUMA systems have
four or even eight nodes. We could not find any reference to -way LCP-merge
in the literature, even though the idea to store and reuse LCP information
inside the tournament tree is very intuitive. The algorithmic details, however,
require precise elaboration.

\begin{figure}\centering\normalsize
  \begin{tikzpicture}[
  yscale=-1,
  xscale=0.8,yscale=0.8,
  keynode/.style={anchor=base,inner sep=1pt},
  uparrow/.style={->},
  txtnode/.style={anchor=base east},
  ]

  \node (n0) [keynode] at (0,-1) {};

  \node[txtnode] at (-1,-1) {Winner};

  \node (n1) [keynode] at (0,0) {};

  \node (n2) [keynode] at (-2,1) {};
  \node (n3) [keynode] at (2,1) {};

  \node[txtnode,anchor=east] at (-2.7,0.25) {Losers};

  \draw[densely dotted] (-5.8,1.4) -- (4,1.4);

  \node[txtnode] at (-4,2) {Players};

  \node (n4) [keynode] at (-3,2) {};
  \node (n5) [keynode] at (-1,2) {};
  \node (n6) [keynode] at (+1,2) {};
  \node (n7) [keynode] at (+3,2) {};

  \draw[uparrow] (n1) -- (n0);
  \draw[uparrow] (n2) -- (n1);
  \draw[uparrow] (n3) -- (n1);
  \draw[uparrow] (n4) -- (n2);
  \draw[uparrow] (n5) -- (n2);
  \draw[uparrow] (n6) -- (n3);
  \draw[uparrow] (n7) -- (n3);

  \node[txtnode] at (-4,3) {Inputs};

  \node (s1) [keynode] at (-3,3) {};
  \node (s2) [keynode] at (-1,3) {};
  \node (s3) [keynode] at (+1,3) {};
  \node (s4) [keynode] at (+3,3) {};

  \draw[uparrow] (s1) -- (n4);
  \draw[uparrow] (s2) -- (n5);
  \draw[uparrow] (s3) -- (n6);
  \draw[uparrow] (s4) -- (n7);

  \node[txtnode] at (-1,-2) {Output};

  \node (s0) [keynode] at (0,-2) {};

  \draw[uparrow] (n0) -- (s0);

  \draw[densely dotted] (-5.8,-1.6) -- (4,-1.6);

\end{tikzpicture}   \caption{LCP-aware tournament tree with  showing input and output
    streams, their front items as players, the winner node , and loser
    nodes , where  is the index of the losing player of the
    particular game and  is the LCP of  and the winner of the
    comparison at node .}\label{fig:lcp-losertree}
\end{figure}

As commonly done in multiway mergesort, to perform -way merging one regards
selection of the next item as a tournament with  players (see
Figure~\ref{fig:lcp-losertree}). Players compete against each other using binary
comparisons, and these games are organized in a binary tree. Each node in the
tree corresponds to one game, and we label the nodes of the tree with the
``losers'' of that particular game. The ``winner'' continues upward and plays
further games, until the overall winner is determined. The winner is commonly
placed on the top, in an additional node, and with this node, the tournament
tree contains each player exactly once.  Hence the tree has exactly  nodes,
since we do not consider the input, output or players part of the tree.  For
sorting strings into ascending sequences, the ``overall winner'' of the
tournament is the lexicographically smallest string.

The first winner is determined by playing an initial round on all  nodes from
bottom up.  This winner can then be sent to the output, and the next item from
the corresponding input sequence takes its place.  Thereafter, only 
games must be replayed, since the previous winner only took part in those games
along the path from the corresponding input to the root of the tournament
tree. This can be repeated until all streams are empty. By using sentinels for
empty inputs, special cases can be avoided, and we can assume  to be a power
of two, filling up with empty inputs as needed. Thus the tournament tree can be
assumed to be a perfect binary tree, and can be stored implicitly in an
array. Navigating upward in the tree corresponds to division by two:  is the parent of child , unless  (note that we use a
one-based array here). Thus finding the path from input leaf to root when
replaying the game can be implemented very efficiently. Inside the tree nodes,
we save the loser \emph{input index} , or winner index  (renamed from
), instead of storing the string  or a reference thereof.

We now discuss how to make the tournament tree LCP-aware. The binary comparisons
between players are done using \LCPCompare (Algorithm~\ref{alg:LCP-compare}),
which may perform explicit character comparisons in case 1. Since we want to
avoid comparing characters already found equal, we store alongside the loser
input index  an LCP value  in the tree node. The LCP  represents
the LCP of the stored losing string  with the particular game's winner
string, which passes upward to play further comparisons. If we call the
corresponding winner , even though it's not explicitly stored, then .

After the initial overall winner  is determined, we have to check that all
requirements of \LCPCompare are fulfilled when replaying the games on the path
from input  to the root.  The key argument is that the overall winner  was
also the winner of all individual games on the path.  Hence, for all games 
on that path .  Thus after writing  to the output,
and advancing to the next item  from the input ,
we have  as the common, smaller predecessor string.  The previous
discussion about the overall winner  is also valid for the individual winner
 of any node  in the tree, since it is the winner of all games leading
from input  to node .

The function signature 
was designed to be played on two nodes  and  of the LCP-aware
tournament tree. When replaying a path, we can picture a node  moving
``upward'' along the edges. \LCPCompare is called with this moving node and the
loser information  saved in the encountered node .
After performing the comparisons, the returning values  are the winner
node, which passes upwards, and  are the loser information, which is
saved in the node .  Thus \LCPCompare effectively selects the winner of each
game, and computes the loser information for future LCP-aware comparisons.  Due
to the recursive property discussed in the previous paragraph, the requirements
of \LCPCompare remains valid along all paths, and \LCPCompare can switch between
them.

\begin{algorithm2e}[t]
\caption{-way LCP-Merge}\label{alg:kway-LCP-merge}\normalsize

\KwIn{ sorted sequences of strings with LCP arrays
   and common prefix . Assume sentinels
   for , and  a power of
  two.}

,\quad  \Rem{Initialize indexes for  and .}
\For(\Remi{Initialize loser tree, building})
{}
{
   \Rem{perfect subtrees left-to-right.}
  ,\quad  \Rem{Play from input node , upward till the root}
  \While(\Remi{of a perfect odd-based subtree is reached.})
  {}
  {
    , \quad \;
  }
   \Rem{Save intermediate winner in odd node at top.}
}
 \Rem{Initial winner after all games (rename ).}
\While(\Remi{Loop until output is done.})
{}
{
  ,\quad  \Rem{Output winner string  with LCP .}
  ,\quad  \Rem{Replace winner with next item from input.}
  ,\quad  \Rem{Play from input node , all games}
  \While(\Remi{upward to root (unrollable loop).})
  {}
  {
    ,\quad  \;
  }
   \Rem{Save next winner at top.}
}
\KwOut{ contains sorted  and has the LCP array }

\end{algorithm2e}

This LCP-aware -way merging procedure is shown in pseudo-code in
Algorithm~\ref{alg:kway-LCP-merge}.  We build the initial tournament tree
incrementally from left to right, playing all games only on the right-most path
of every odd-based perfect subtree.  This right-most side contains only nodes
with even index.

The following theorem considers only a single execution of -way LCP-merg\-ing,
since this is what we need in our NUMA scenario:

\begin{theorem}\label{thm:kway-LCP-merge}
  Algorithm~\ref{alg:kway-LCP-merge} requires at most  character comparisons, where  is the total number of
  strings and  is the sum of increments
  to LCP array entries.
\end{theorem}
\begin{proof}
  We focus on the character comparisons in the sub-function \LCPCompare, since
  Algorithm~\ref{alg:kway-LCP-merge} itself does not contain any character
  comparisons. As in the proof of Theorem~\ref{thm:LCP-mergesort}, we can
  account for all \textsl{true}-outcomes of the while loop condition in
  \LCPCompare (line~\ref{alg:LCP-compare:charloop}) using , since it
  increments the overall LCP. We can bound the number of \textsl{false}-outcomes
  by bounding the number of calls to \LCPCompare, which occurs exactly  times
  when building the tournament tree, and then  times for each of the
   output string (we actually have one superfluous run in the pseudo-code,
  but we keep it as it makes the code shorter).  As before, this upper bound,
  , is only attained in pathological cases, and for
  most inputs, cases 2 and 3 in \LCPCompare reduce the overall number of
  character comparisons.
\end{proof}

\begin{theorem}
  Using Algorithm~\ref{alg:kway-LCP-merge} one can implement a -way
  LCP-mergesort algorithm, which requires less than  character comparisons and runs in
   time.
\end{theorem}
\begin{proof}
  We assume the divide step of -way LCP-mergesort to split into 
  sub-problems of nearly even size. Using Theorem~\ref{thm:kway-LCP-merge}
  yields the recurrence  with
  , if we ignore the character comparisons loop.  Assuming 
  for some integer , the recurrence can be solved elementary using induction,
  yielding . For , the input cannot be split evenly into recursive subproblems. However, to
  keep this analysis simple, we use -way mergesort even when , and
  thus incur the cost of Theorem~\ref{thm:kway-LCP-merge} also at the base
  level. So, we have  levels of recursion. As in
  previous proofs, we account for all matching character comparisons with ,
  and all others with the highest number of occurrences of case 1 in \LCPCompare
  in the whole recursion, which is . Since , the run time
  follows.
\end{proof}

In the proof we assume -way LCP-merge even in the base level. In an
implementation, one would chose a different merger when . By selecting
-way LCP-merge, the number of comparisons in the lowest recursion is reduced,
and we can get a bound of , which is close to the
one in Theorem~\ref{thm:kway-LCP-merge}.

\subsection{Practical Parallelization of \texorpdfstring{}{K}-way LCP-Merge}\label{sec:merge-kway-parallel}

We now discuss how to parallelize -way LCP-merge when given  sorted input
streams. The problem is that merging itself cannot be parallelized without
significant overhead~\cite{cole1988parallel}, as opposed to the classification
and distribution in pS.  Instead, we want to split the problem into disjoint
areas of independent work, as done commonly in practical parallel
multiway mergesort sorting algorithms and implementations
\cite{akl1987optimal,singler2007mcstl}.

In contrast to atomic merging, a perfect split with respect to the number of
elements in the subproblems by no means guarantees good load balance for string
merging. Rather, the amount of work in each piece depends on the unknown values
of the common prefixes. Therefore, dynamic load balancing is needed anyway and
we can settle for a simple and fast routine for splitting the input into
pieces that are small enough to allow good load balance. We now outline our
current approach\footnote{which we intend to improve for the final version.}.
Since access to string characters
incurs costly cache faults, we want to use the information in the LCP array to
help split the input streams.  In principle, in the following heuristic we merge
the top of the LCP interval trees \cite{abouelhoda2004replacing} of the 
input streams to find independent areas.

If we consider all occurrences of the global minimum in an LCP array, then these
split the input stream into disjoint areas starting with the same distinct
prefix. The only remaining challenge is to match equal prefixes from the 
input streams, and for this matching we need to inspecting the first
distinguishing characters of any string in the area. Matching areas can then be
merged independently.

Depending on the input, considering only the global LCP minima may not yield
enough independent work. However, we can apply the same splitting method again
on matching sub-areas, within which all strings have a longer common prefix, and
the global minimum of the sub-area is larger.

We put these ideas together in a splitting heuristic, which scans the  input
LCP arrays sequentially once, and creates merge jobs while scanning.  We start
by reading  characters from the first string of all  input streams, and
select those inputs with the smallest character block . In each of
these selected inputs, we scan the LCP array forward, skipping over all entries
, and checking entries  for equal character blocks, until either an
entry  or a mismatching character block is found. This forward scan
encompasses all strings with prefix , and an independent merge job
can be started.  The process is then repeated with the next strings on all 
inputs.

We start the heuristic with  (loading a 64-bit register full of
characters), but reduce  depending on how many jobs are started, as otherwise
the heuristic may create too many splits, e.g. for random input strings. We
therefore calculate an expected number of independent jobs, and adapt 
depending on how much input is left and how many jobs were already created. This
adaptive procedure keeps  high for inputs with high average common prefix and
low otherwise.

We use the same load balancing framework as with pS (see
Section~\ref{sec:parallel-s5}).  During merge jobs, we check if other threads
are idle via the global unsynchronized counter variable. To reduce balancing
overhead, we check only every 4\,Ki processed strings. If idle threads are
detected, then a -way merge job is split up into further independent jobs
using the same splitting heuristic, except that a common prefix of all strings
may be known, and is used to offset the character blocks of size .

\subsection{Implementation Details}\label{sec:merge-details}

Our experimental platforms have  NUMA nodes, and we use
parallel -way LCP-merge only as a top-level merger on  input
streams. Thus we assume the  inputs characters to be divided evenly onto the
 memory nodes.  On the individual NUMA memory nodes, we pin about
 threads and run pS on the string subset.

Since -way LCP-merge requires the LCP arrays of the sorted sequences, we
extended pS to optionally save the LCP value while sorting. The string
pointers and LCP arrays are kept separate, as opposed to interleaving them as
``annotated'' strings~\cite{ng2008merging}. This was done, because pS
already requires an additional pointer array during out-of-place
redistribution. The additional string array and the original string array are
alternated between in recursive calls. When a subset is finally sorted, the
correctly ordered pointers are copied back to the original array, if
necessary. This allows us to place the LCP values in the additional array.

The additional work and space needed by pS to save the LCP values is very
small, we basically get LCPs for free. Most LCPs are calculated in the base case
sorter of pS, and hence we describe LCP-aware insertion sort in the next
section. All other LCPs are located at the boundaries of buckets separated by
either multikey quicksort or string sample sort. We calculate these boundary
LCPs after recursive levels are finished, and use the saved splitters or pivot
elements whenever possible.

The splitting heuristic of parallel -way LCP-merge creates jobs with varying
, and we created special implementations for the 1-way (plain copying) and
2-way (binary merging) cases, while all other -way merges are performed using
the LCP-aware tournament tree.

To make parallel -way LCP-merge more cache- and NUMA transfer-efficient, we
devised a \emph{caching variant}. In \LCPCompare the first character needed for
additional character comparisons during the merge can be predicted (if
comparisons occur at all).  This character is the distinguishing character
between two strings, which we label , where . Caching this character while sorting is easy, since it is
loaded in a register when the final, distinguishing character comparison is
made. We extended pS to save  in an additional array and employ
it in a modified variant of \LCPCompare to save random accesses across NUMA
nodes.  Using this caching variant all character comparisons accounted for in
the  term in Theorem~\ref{thm:kway-LCP-merge} can be done using
the cached , thus only  random accesses to strings are
needed for a -way merge.

\subsection{LCP-Insertion Sort}\label{sec:lcp-inssort}

As mentioned in the preceding section, we extended pS to save LCP
values. Thus its base-case string sorter, insertion sort, also needed to be
extended. Again, saving and reusing LCPs during insertion sort is a very
intuitive idea, but we found no reference or analysis in the literature.

Assuming the array  is already sorted and
the associated LCP array  is known, then insertion sort locates a position
 at which a new string  can be inserted, while keeping the array
sorted. After insertion, at most the two LCP values  and  may need
to be updated. While scanning for the correct position , customarily from the
right, values of both  and  can already be shifted to allocate a
free position.

Using the information in the preliminary LCP array, the scan for  can be
accelerated by skipping over certain areas in which the LCP value attests a
mismatch. The scan corresponds to walking down the LCP interval tree, testing
only one item of each child node, and descending down if it matches. In plainer
words, areas of strings with a common prefix can be identified using the LCP
array (as already mentioned in Section~\ref{sec:merge-kway-parallel}), and it
suffices to \emph{check once} if the candidate matches this common prefix. If
not then the whole area can be skipped.

In the pseudo-code of Algorithm~\ref{alg:lcp-inssort}, the common prefix of the
candidate  is kept in , and increased while characters match. When a
mismatch occurs, the scan is continued to the left, and all strings can be
skipped if the LCP reveals that the mismatch position remains unchanged
(case~3). If the LCP does below , then a smaller strings precedes and
therefore the insertion point  is found (case~2). At positions with equal LCP
more characters need to be compared (case~1). In the pseudo-code these three
cases are fused with a copy-loop moving items to right.

\begin{algorithm2e}[t]
\caption{LCP-InsertionSort}\label{alg:lcp-inssort}\normalsize

\KwIn{ is a set of strings with common prefix }

\For(\Remi{Insert  into sorted sequence .}\nllabel{alg:lcp-inssort:for})
{}
{
  ,\quad  \Rem{Start candidate LCP  with common prefix .}
  \While{\nllabel{alg:lcp-inssort:while}}
  {
    \lIf(\Remi{case 1: LCP decreases  insert after .}\nllabel{alg:lcp-inssort:while-begin})
    {}
    {
      \KwSty{break}
    }
    \ElseIf(\Remi{case 2: LCP equal  compare more characters.})
    {}
    {
       \Rem{Save LCP of  and .}
      \While(\Remi{Compare characters.})
      {\nllabel{alg:lcp-inssort:charcmp1}}
      {
        
      }
      \If(\Remi{If  is larger, insert  after ,})
      {\nllabel{alg:lcp-inssort:charcmp2}}
      {
        ,\quad  \Rem{set , the LCP of  and , but}
        \KwSty{break} \Rem{set  after loop in line~\ref{alg:lcp-inssort:final}.}
      }
    }
     \Rem{case 3: LCP is larger  no comparison needed.}
     \nllabel{alg:lcp-inssort:while-end}
  }
   \Rem{Insert  at correct position, update  with LCP.}\nllabel{alg:lcp-inssort:final}\nllabel{alg:lcp-inssort:for-end}
}
  
\KwOut{ is sorted and has the LCP array }

\end{algorithm2e}

\begin{theorem}
  LCP-aware insertion sort (Algorithm~\ref{alg:lcp-inssort}) requires at most  character comparisons and runs in  time.
\end{theorem}
\begin{proof}
  The only lines containing character comparisons in
  Algorithm~\ref{alg:lcp-inssort} are lines~\ref{alg:lcp-inssort:charcmp1} and
  \ref{alg:lcp-inssort:charcmp2}.  If the while loop condition is \textsl{true},
  then  is incremented.  In the remaining algorithm the value of  is
  only shifted around, never discarded or decreased.  Thus we can count the
  number of comparisons yielding a while-loop repetition with .  The while
  loop is encountered at most , as this is the highest number
  of times the inner loop in lines
  \ref{alg:lcp-inssort:while-begin}--\ref{alg:lcp-inssort:while-end} runs.  We
  can regard the exiting comparison of line \ref{alg:lcp-inssort:charcmp1} and
  the following comparison in line \ref{alg:lcp-inssort:charcmp2} as one ternary
  comparison, as the same values are checked again.  This ternary comparison
  occurs at most once each run of the inner loop, thus 
  times.  With , the run time follows from the number of iterations of
  the for loop (line \ref{alg:lcp-inssort:for}--\ref{alg:lcp-inssort:for-end})
  and the while loop (lines
  \ref{alg:lcp-inssort:while}--\ref{alg:lcp-inssort:while-end}).
\end{proof}

We close with the remark that non-LCP insertion sort requires 
steps in the worst case, when all strings are equal except for the last
character.

\section{More Shared Memory Parallel String Sorting}\label{sec:more-parasort}

\subsection{Parallel Radix Sort}\label{sec:para-radixsort}

Radix sort is very similar to sample sort, except that classification is much
faster and easier. Hence, we can use the same parallelization toolkit as with
S. Again, we use three sub-algorithms for differently sized subproblems:
fully parallel radix sort for the original string set and large subsets, a
sequential radix sort for medium-sized subsets and insertion sort for base
cases. Fully parallel radix sort consists of a counting phase, global prefix sum
and a redistribution step. Like in S, the redistribution is done
out-of-place by copying pointers into a shadow array.

We experimented with 8-bit and 16-bit radixes for the fully parallel
step. Smaller recursive subproblems are processed independently by sequential
radix sort with in-place permuting, and here we found 8-bit radixes to be faster
than 16-bit sorting.  Our parallel radix sort implementation uses the same work
balancing method as parallel S, freeing the largest subproblems when other
threads are idle.

\subsection{Parallel Caching Multikey Quicksort}\label{sec:para-mkqs}

\begin{figure}\centering\small
  

\begin{tikzpicture}[scale=0.4,
  yscale=-1,
  line cap=round,
  ]

  \colorlet{dred}{black}
  \colorlet{fred}{teal!40!white}

  \colorlet{dgreen}{black}
  \colorlet{fgreen}{olive!20!white}

  \begin{scope}

    \node[left] at (0,0) {\bf Sequential};

    \begin{scope}[xshift=5mm,yshift=-5mm,
      xscale=0.9,
      ptr/.style={<-,thick},
      move/.style={->,>=stealth},
      ]
      \draw (0,0) rectangle (2,1);
      \draw (2,0) rectangle (5.5,1);
      \draw (5.5,0) rectangle (7.5,1);
      \draw (7.5,0) rectangle (11,1);
      \draw (11,0) rectangle (13,1);
      \node at (1,0.5) {};
      \node at (3.75,0.5) {};
      \node at (6.5,0.5) {};
      \node at (9.25,0.5) {};
      \node at (12,0.5) {};
      \draw[ptr] (2,1) -- +(0,4mm);
      \draw[ptr] (5.5,1) -- +(0,4mm);
      \draw[ptr] (7.5,1) -- +(0,4mm);
      \draw[ptr] (11,1) -- +(0,4mm);

      \draw[move] (18mm,16mm) -- +(6mm,0);
      \draw[move] (53mm,16mm) -- +(6mm,0);
      \draw[move] (77mm,16mm) -- +(-6mm,0);
      \draw[move] (112mm,16mm) -- +(-6mm,0);
    \end{scope}
    
    \node at (13.1,-0.25) {\large};

    \begin{scope}[xshift=14.2cm,yshift=-5mm,
      xscale=0.9,
      ]

      \draw (0,0) rectangle (5,1);
      \draw (5,0) rectangle (7,1);
      \draw (7,0) rectangle (13,1);
      \node at (2.5,0.5) {};
      \node at (6,0.5) {};
      \node at (10,0.5) {};

    \end{scope}

  \end{scope}

  \begin{scope}[yshift=3cm,xscale=1.2,
    blkid/.style={font=\tiny},
    ptr/.style={<-,thick,line cap=round},
    move/.style={->,>=stealth},
    ]

    \node[left] at (0,0) {\bf Parallel};

\begin{scope}[xshift=5mm,yshift=-5mm,xscale=1.1]
      \foreach \x in {0,...,2,6,7,11} {
        \filldraw[fill=fred] (\x,0) rectangle (\x+1,1);
        \node[font=\color{dred}] at (\x+0.5,0.5) {};
        \node[blkid] at (\x+0.5,-0.4) {};
      }
      \foreach \x in {3,...,5,8,9,10} {
        \filldraw[fill=fgreen] (\x,0) rectangle (\x+1,1);
        \node[font=\color{dgreen}] at (\x+0.5,0.5) {};
        \node[blkid] at (\x+0.5,-0.4) {};
      }
      \foreach \x in {12,13} {
        \draw (\x,0) rectangle (\x+1,1);
        \node at (\x+0.5,0.5) {};
        \node[blkid] at (\x+0.5,-0.4) {};
      }
      \foreach \x in {14} {
        \draw (\x,0) rectangle (\x+0.6,1);
        \node at (\x+0.3,0.5) {};
        \node[blkid] at (\x+0.5,-0.4) {};
      }

      \foreach \x/\B in {16/0,17/1,18/2} {
        \draw (\x,0) rectangle (\x+1,1);
        \node at (\x+0.5,0.5) {};
        \node[blkid] at (\x+0.5,-0.4) {};
      }
    \end{scope}

\node[rotate=90, align=center] at (-1.2,4) {Working \\ Blocks};

    \begin{scope}[xshift=1cm,yshift=2cm]

      \node[dred] at (-0.6,0.6) {};

      \filldraw[fill=fred] (0,0) rectangle (1,1);
      \filldraw[fill=fred] (1,0) rectangle (2,1);
      \node[font=\color{dred}] at (0.5,0.5) {};
      \node[font=\color{dred}] at (1.5,0.5) {};
      \draw[ptr] (1,1) -- +(0,4mm);
      \draw[move] (8mm,16mm) -- +(5mm,0);
      \node[blkid] at (1,-0.4) {};

      \filldraw[fill=fred] (2.5,0) rectangle (3.5,1);
      \filldraw[fill=fred] (3.5,0) rectangle (4.5,1);
      \node[font=\color{dred}] at (3,0.5) {};
      \node[font=\color{dred}] at (4,0.5) {};
      \draw[ptr] (3.5,1) -- +(0,4mm);
      \draw[move] (33mm,16mm) -- +(5mm,0);
      \node[blkid] at (3.5,-0.4) {};

      \filldraw[fill=fred] (5,0) rectangle (6.3,1);
      \filldraw[fill=fred] (6.3,0) rectangle (7,1);
      \node[font=\color{dred}] at (5.7,0.5) {};
      \node[font=\color{dred}] at (6.65,0.5) {};
      \draw[ptr] (6.3,1) -- +(0,4mm);
      \draw[move] (61mm,16mm) -- +(5mm,0);
      \node[blkid] at (6,-0.4) {};

    \end{scope}
    \begin{scope}[xshift=1cm,yshift=45mm]

      \node[dgreen] at (-0.6,0.6) {};

      \filldraw[fill=fgreen] (0,0) rectangle (0.8,1);
      \filldraw[fill=fgreen] (0.8,0) rectangle (2,1);
      \node[font=\color{dgreen}] at (0.4,0.5) {};
      \node[font=\color{dgreen}] at (1.4,0.5) {};
      \draw[ptr] (0.8,1) -- +(0,4mm);
      \draw[move] (6mm,16mm) -- +(5mm,0);
      \node[blkid] at (1,-0.4) {};

      \filldraw[fill=fgreen] (2.5,0) rectangle (3.5,1);
      \filldraw[fill=fgreen] (3.5,0) rectangle (4.5,1);
      \node[font=\color{dgreen}] at (3,0.5) {};
      \node[font=\color{dgreen}] at (4,0.5) {};
      \draw[ptr] (3.5,1) -- +(0,4mm);
      \draw[move] (33mm,16mm) -- +(5mm,0);
      \node[blkid] at (3.5,-0.4) {};

      \filldraw[fill=fgreen] (5,0) rectangle (7,1);
      \node[font=\color{dgreen}] at (6,0.5) {};
      \draw[ptr] (7,1) -- +(0,4mm);
      \draw[move] (68mm,16mm) -- +(5mm,0);
      \node[blkid] at (6,-0.4) {};
      \coordinate (moveA) at (7,0.5);

    \end{scope}

    \node[rotate=90] at (11,4) {Output};

    \begin{scope}[xshift=12cm,yshift=17mm]

      \foreach \x/\c/\C/\B in {0/dred/fred/0,2/dgreen/fgreen/3} {
        \filldraw[fill=\C] (\x+0,0) rectangle (\x+2,1);
        \node[font=\color{\c}] at (\x+1,0.5) {};
        \node[blkid] at (\x+1,-0.3) {};
      }

      \node[right] at (4,0.5) {};

      \foreach \x/\c/\C/\B in {0/dgreen/fgreen/5} {
        \filldraw[fill=\C] (\x+0,1.75) rectangle (\x+2,2.75);
        \node[font=\color{\c}] at (\x+1,2.25) {};
        \node[blkid] at (\x+1,1.4) {};
      }

      \node[right] at (2,2.25) {};

      \foreach \x/\c/\C/\B in {0/dred/fred/1,2/dred/fred/2,4/dgreen/fgreen/4} {
        \filldraw[fill=\C] (\x+0,3.5) rectangle (\x+2,4.5);
        \node[font=\color{\c}] at (\x+1,4) {};
        \node[blkid] at (\x+1,3.2) {};
      }

      \node[right] at (6,4) {};

      \coordinate (moveB) at (0,4);

    \end{scope}

    \draw[>=stealth,->] (moveA) to[out=0,in=180] node[below,font=\tiny,rotate=-10] {done} (moveB);

  \end{scope}

\end{tikzpicture}
   \caption{Block schema of sequential and parallel multikey quicksort's ternary
    partitioning process}\label{fig:mkqs-blocks}
\end{figure}

Our preliminary experiments with sequential string sorting algorithms (see
Section~\ref{sec:exp-sequential}) showed a surprise winner: an enhanced variant
of multikey quicksort by Tommi Rantala \cite{rantala2007web} often outperformed
more complex algorithms.

This variant employs both caching of characters and uses a super-alphabet of  characters, exactly as many as fit into a machine word. The string pointer
array is augmented with  cache bytes for each string, and a string subset is
\emph{partitioned by a whole machine word} as splitter. Thereafter, the cached
characters are reused for the recursive subproblems  and
, and access to strings is needed only for sorting ,
unless the pivot contains a zero-terminator.  In this section caching means
\emph{copying} of characters into another array, not necessarily into the
processor's cache. Key to the algorithm's good performance is the following
observation:

\begin{theorem}\label{thm:mkqs-access}
  Caching multikey quicksort needs at most 
  (random) accesses to string characters in total, where  is the number of
  characters cached per access.
\end{theorem}
\begin{proof}
  Per string access  characters are loaded into the cache, and these 
  characters are never fetched again. We can thus account for all accesses to
  distinguishing characters using , since the
  characters are fetched in blocks of size . Beyond these, at most one access
  per string can occur, which accounts for fetching  characters of which not
  all are need for sorting.
\end{proof}

In light of this variant's good performance, we designed a parallelized
version. We use three sub-algorithms: \emph{fully parallel caching multikey
  quicksort}, the original sequential caching variant (with explicit recursion
stack) for medium and small subproblems, and insertion sort as base case. For
the fully parallel sub-algorithm, we generalized a block-wise processing
technique from (two-way) parallel atomic quicksort \cite{tsigas2003simple} to
three-way partitioning.

The input array is viewed as a sequence of blocks containing  string pointers
together with their  cache characters (see
Figure~\ref{fig:mkqs-blocks}). Each thread holds exactly three blocks and
performs ternary partitioning by a globally selected pivot. When all items in a
block are classified as ,  or , then the block is added to the
corresponding output set , , or . This
continues as long as unpartitioned blocks are available. If no more input blocks
are available, an extra empty memory block is allocated and a second phase
starts. The second partitioning phase ends with fully classified blocks, which
might be only partially filled. Per fully parallel partitioning step there can
be at most  partially filled blocks. The output sets ,
, and  are processed recursively with threads divided as
evenly among them as possible. The cached characters are updated only for the
 set.

In our implementation we use atomic compare-and-swap operations for block-wise
processing of the initial string pointer array and Intel TBB's lock-free queue
for sets of blocks, both as output sets and input sets for recursive steps. When
a partition reaches the threshold for sequential processing, then a continuous
array of string pointers plus cache characters is allocated and the block set is
copied into it. On this continuous array, the usual ternary partitioning scheme
of multikey quicksort is applied sequentially. Like in the other parallelized
algorithms, we use dynamic load balancing and free the largest level when
re-balancing is required. We empirically determined  as a
good block size.

\subsection{Burstsort}\label{sec:para-burstsort}

Burstsort is one of the fastest string sorting algorithms and cache-efficient
for many inputs, but it looks difficult to parallelize it. Keeping a common
burst trie would require prohibitively many synchronized operations, while
building independent burst tries on each PE would lead to the question how to
merge multiple tries of different structure.  This problem of merging tries is
related to parallel -way LCP-merge, and future work may find a way to combine
these approaches.

\section{Experimental Results}\label{sec:experiments}

We implemented parallel versions of S, -way LCP-merge, multikey quicksort
and radix sort in C++ and compare them with the few parallel string sorting
implementations we could find online in Section~\ref{sec:exp-parallel}.  We also
integrated many sequential implementations into our test framework, and discuss
their performance in Section~\ref{sec:exp-sequential}. Our implementations, the
test framework and most input sets are available from
\url{http://tbingmann.de/2013/parallel-string-sorting}.

\subsection{Experimental Setup}\label{sec:exp-setup}

We tested our implementations and those by other authors on five different
platforms.  All platforms run Linux and their main properties are listed in
Table~\ref{tab:hardware}.  We compiled all programs using gcc~4.6.3 with
optimizations \texttt{-O3 -march=native}.  The five platforms were chosen to
encompass a wide variety of multi-core systems, which exhibit different
characteristics in their memory system and also cover today's most popular
hardware.  By experimenting on a large number of systems (and inputs), we
demonstrate how robust our implementations and algorithm designs are.

The test framework sets up a separate environment for each run.  To isolate heap
fragmentation, it was very important to fork() a child process for each run.
The string data is loaded before the fork(), allocating exactly the matching
amount of RAM, and shared read-only with the child processes. No precaution to
lock the program's memory into RAM was taken (as opposed to previous experiments
reported in~\cite{bingmann2013parallel}). Turbo-mode was disabled on IntelE5.

Before an algorithm is called, the string pointer array is generated inside the
child process by scanning the string data for zero characters, thus flushing
caches and TLB entries. Time measurement is done with clock\_gettime() and
encompasses only the sorting algorithm. Because many algorithms have a deep
recursion stack for our large inputs, we increased the stack size limit to
64\,MiB. For non-NUMA experiments, we took no special precautions of pinning
threads to specific cores or nodes, and used the default Linux task scheduling
system as is. Memory for NUMA-unaware algorithms was interleaved across all
nodes by setting the default allocation policy.

For our experiments with NUMA-aware string sorting, the characters array is
segmented equally onto the NUMA memory banks before running an algorithm.  The
algorithm then pins its threads to the appropriate node, enabling node-local
memory access. Additional allocations are also taken preferably from the local
memory node.

The output of each string sorting algorithm was verified by first checking that
the resulting pointer list is a permutation of the input set, and then checking
that strings are in non-descending order. The input was shared read-only with
the algorithm's process and thus cannot have been modified.

Methodologically we have to discuss, whether measuring only the algorithm's run
time is a good decision. The issue is that deallocation and defragmentation in
both heap allocators and kernel page tables is done lazily. This was most
notable when running two algorithms consecutively. The fork() process isolation
excludes both variables from the experimental results, however, for use in a
real program context these costs cannot be ignored. We currently do not know
how to invoke the lazy cleanup procedures to regenerate a pristine memory
environment. These issues must be discussed in greater detail in future work for
sound results with big data in RAM.  We briefly considered HugePages, but these
did not yield a performance boost. This is probably due to random accesses being
the main time cost of string sorting, while the number of TLB entries is not a
bottleneck.

\begin{table}\centering\small\def\tabcolsep{3.5pt}
\caption{Hard- and software characteristics of experimental platforms}\label{tab:hardware}
\begin{tabular}{l|l|r|r||r|r|r|r}
Name    & Processor          & Clock & Sockets                      & Cache: L1      & L2              & L3            & RAM   \\
        &                    & [GHz] & Cores  HT                    & [KiB]          & [KiB]           & [MiB]         & [GiB] \\\hline
IntelE5 & Intel Xeon E5-4640 & 2.4   &                 &  &  &  & 512   \\
AMD48   & AMD Opteron 6168   & 1.9   &  &  &  &   & 256   \\
AMD16   & AMD Opteron 8350   & 2.0   &   &  &  &   & 64    \\
Inteli7 & Intel Core i7 920  & 2.67  &                 &   &   &   & 12    \\
IntelX5 & Intel Xeon X5355   & 2.67  &                 &   &  &               & 16    \\ 
\end{tabular}

\bigskip
\def\tabcolsep{2.0pt}
\begin{tabular}{l|l|l|c|l|l}
Name    & Codename     & Memory               & NUMA  & Interconnect            & Linux/Kernel Version \\
        &              & Channels             & Nodes &                         &                      \\ \hline
IntelE5 & Sandy Bridge & 4  DDR3-1600 & 4     & 2  8.0 GT/s QPI & Ubuntu 12.04/3.2.0   \\
AMD48   & Magny-Cours  & 4  DDR3-667  & 8     & 4  3.2 GHz HT   & Ubuntu 12.04/3.2.0   \\
AMD16   & Barcelona    & 2  DDR2-533  & 4     & 3  1.0 GHz HT   & Ubuntu 10.04/2.6.32  \\
Inteli7 & Bloomfield   & 3  DDR3-800  &       & 1  4.8 GT/s QPI & openSUSE 11.3/2.6.34 \\
IntelX5 & Clovertown   & 2  DDR2-667  &       & 1  1.3 GHz FSB  & Ubuntu 12.04/3.2.0   \\
\end{tabular}
\end{table}

\subsection{Inputs}\label{sec:exp-inputs}

We selected the following datasets, all with 8-bit characters. Most important
characteristics of these instances are shown in Table~\ref{tab:data}.

\textbf{URLs} contains all URLs found on a set of web pages which were crawled
breadth-first from the author's institute website. They include the protocol
name.

\textbf{Random} (from \cite{sinha2004cache-conscious}) are strings of length
 over the ASCII alphabet , with both length and characters
chosen uniformly random.

\textbf{GOV2} is a TREC test collection consisting of 25 million HTML pages, PDF
and other documents retrieved from websites under the .gov domain. We
consider the whole corpus for line-based string sorting, concatenated by
document id.

\textbf{Wikipedia} is an XML dump of the most recent version of all pages in the
English Wikipedia, which was obtained from \url{http://dumps.wikimedia.org/};
our dump is dated \texttt{enwiki-20120601}.  Since the XML data is not
line-based, we perform \emph{suffix sorting} on this input.

We also include the three largest inputs Ranjan \textbf{Sinha}
\cite{sinha2004cache-conscious} tested burstsort on: a set of \textbf{URLs}
excluding the protocol name, a sequence of genomic strings of length 9 over a
\textbf{DNA} alphabet, and a list of non-duplicate English words called
\textbf{NoDup}. The ``largest'' among these is NoDup with only 382\,MiB, which
is why we consider these inputs more as reference datasets than as our target.

The inputs were chosen to represent both real-world datasets, and to exhibit
extreme results when sorting. Random has a very low average LCP, while URLs have
a high average LCP. GOV2 is a general text file with all possible ASCII
characters, and Sinha's DNA has a small alphabet size. By taking suffixes of
Wikipedia we have a very large sorting problem instance, which needs little
memory for characters.

Our inputs are very large, one infinite, and most of our platforms did not have
enough RAM to process them. For each platform, we determined a large prefix
, which can be processed with the available RAM and time, and leave
sorting of the remainder to future work.

\begin{table}[tb]\centering\normalsize
\caption{Characteristics of the selected input instances.}\label{tab:data}
\def\tabcolsep{6pt}
\begin{tabular}{l|rrrrrr}
Name        &       &                        &  () &  &  & avg.\              \\ \hline
URLs        & 1.11\,G  & 70.7\,Gi                  & 93.5\,\%            & 62.0          & 84         & 68.4                    \\
Random      &  &                   &                  &            & 94         & 10.5                    \\
GOV2        & 11.3\,G  & 425\,Gi                   & 84.7\,\%            & 32.0          & 255        & 40.3                    \\
Wikipedia   & 83.3\,G  &  & (79.56\,T)          & 954.7         & 213        &  \\
Sinha URLs  & 10\,M    & 304\,Mi                   & 97.5\,\%            & 29.4          & 114        & 31.9                    \\
Sinha DNA   & 31.6\,M  & 302\,Mi                   & 100\,\%             & 9.0           & 4          & 10.0                    \\
Sinha NoDup & 31.6\,M  & 382\,Mi                   & 73.4\,\%            & 7.7           & 62         & 12.7                    \\
\end{tabular}
\end{table}

\subsection{Performance of Parallel Algorithms}\label{sec:exp-parallel}

In this section we report on our experiments on the platforms shown in
Table~\ref{tab:hardware}, which contains a wide variety of multi-core machines
of different age. The results plotted in
Figures~\ref{fig:more-IntelE5}--\ref{fig:more-IntelX5} show the speed up of each
parallel algorithm over the best sequential one, for increasing thread count.
Tables \ref{tab:absrun-IntelE5}--\ref{tab:absrun-IntelX5b} show absolute running
times of our experiments, with the fastest algorithm's time highlighted in bold
text.

Overall, our parallel string sorting implementations yield high speedups, which
are generally much higher than those of all previously existing parallel string
sorters. Each individual parallel algorithm's speedup depends highly on hardware
characteristics like processor speed, RAM and cache performance\footnote{See
  \url{http://tbingmann.de/2013/pmbw/} for parallel memory bandwidth
  experiments}, the interconnection between sockets, and the input's
characteristics. In general, the speedup of string sorting for high thread
counts is bounded by memory bandwidth, not processing power.  On both non-NUMA
platforms (Figures~\ref{fig:more-Inteli7}, \ref{fig:more-IntelX5}), our
implementations of pS are the string sorting algorithm with highest
speedups, except for Random and Sinha's NoDup inputs.  On NUMA many-core
platforms, the picture is more complex and results mostly depend on how well the
inner loops and memory transfers are optimized on each particular system.

The parallel experiments cover all algorithms we describe in this paper:
pS-Unroll is a variant of pS from Section~\ref{sec:s5}, which
interleaves three unrolled descents of the classification tree, while
pS-Equal unrolls only a single descent, but tests equality at each splitter
node. In the NUMA-aware variant called ``pS-Unroll + pLCP-Merge'' we first
run pS-Unroll independently on each NUMA node for separate parts of the
input, and then merge the presorted parts using our parallel -way LCP-merge
algorithm (Section~\ref{sec:para-mergesort}). From the additional parallel
algorithms in Section~\ref{sec:more-parasort}, we draw our parallel multikey
quicksort (pMKQS) implementations, and radix sorts with 8-bit and 16-bit fully
parallel steps.  Furthermore, we included the parallel radix sort implemented by
Ta\-kuya Akiba~\cite{akiba2011radixsort} in the experiments on all platforms.

For the tests on Inteli7 and IntelX5, we added three more parallel
implementations: pMKQS-SIMD is a multikey quicksort implementation from
Rantala's library, which uses SIMD instructions to perform vectorized
classification against a single pivot. We improved the code to use OpenMP tasks
for recursive sorting steps. The second implementation is a parallel 2-way
LCP-mergesort also by Rantala, which we also augmented with OpenMP
tasks. However, only recursive merges are run in parallel, the largest merge is
performed sequentially. The implementation uses insertion sort for , all other sorting is done via merging. N.\ Shamsundar's parallel
LCP-mergesort is the third additional implementation, but it also uses only
2-way merges.  As seen in Figures~\ref{fig:more-Inteli7}--\ref{fig:more-IntelX5},
only Akiba's radix sort scales fairly well, which is why we omitted the other
three algorithms on the platforms with more than eight cores.

\emph{Inteli7} (Figure~\ref{fig:more-Inteli7}, Table~\ref{tab:absrun-Inteli7}--\ref{tab:absrun-Inteli7b}) is a consumer-grade, single
socket machine with fast RAM and cache hierarchy. \emph{IntelX5}
(Figure~\ref{fig:more-IntelX5}, Table~\ref{tab:absrun-IntelX5}--\ref{tab:absrun-IntelX5b}) is our oldest architecture, and shows the
slowest absolute speedups. Both are not NUMA architectures, which is why we did
not run our NUMA-aware algorithm on them. They are more classic architectures,
and exhibit most of the effects we targeted in our algorithms to gain good
speedups. Our pS variants are fastest on all inputs, except very random ones
(Random and NoDup), where radix sorts are slightly faster on Inteli7.
Remarkably, on IntelX5 the speed gain of radix sort is not visible.  We suspect
that some processors can optimize the inner loops of radix sort (counting,
prefix sums and data redistributions with few input/output streams
\cite{karkkainen2009engineering}) better than others.  Our pMKQS also shows good
overall speedups, but is never particularly fast.  This is due to the high
memory bandwidth caching multikey quicksort requires, as it reads and rereads an
array to just partition by one pivot.

For all test instances, except URLs, the fully parallel sub-algorithm of pS
was run only 1--4 times. Thereafter, the input was split up into enough subsets,
and most of the additional speedup is gained by load-balancing the sequential
sub-algorithms well. The pS-Equal variant handles URL instances better, as
many equal matches occur here. However, for all other inputs, pS-Unroll with
interleaved tree descents fares better, even though it has higher theoretical
running time.

Comparing our radix sorts with Akiba's we already see the implementation's main
problems: it does not parallelize recursive sorting steps (only the top-level is
parallelized) and only performs simple load balancing. This can be seen most
pronounced on URLs and GOV2.  All three additional implementations, pMKQS-SIMD,
pMergesort-2way by Rantala, and the same by Shamsundar do not show any good
speedup, partly because they are already pretty slow sequentially, and partly
because they are not fully parallelized.

On the Inteli7 machine, which has four real cores and four Hyper-Threading
cores, pS achieves speedups  on all inputs, except Random where it
gains only . This is remarkable, as the machine has only three memory
channels, and a single core can fully utilize two of them. Thus in pS a lot
of computation work is parallelized. On IntelX5, which has eight real cores,
pS achieves speedups  on all inputs. We attribute this to the early
dual-socket architecture, on which many other parallel implementations also do
not scale well.

\emph{IntelE5} (Figure~\ref{fig:more-IntelE5}, Table~\ref{tab:absrun-IntelE5}) is our newest machine with 32
real cores across four sockets with one NUMA node each. It contains one of
Intel's most recent many-core processors. \emph{AMD48}
(Figure~\ref{fig:more-AMD48}, Table~\ref{tab:absrun-AMD48}) is a somewhat older AMD many-core machine with
high core count, but relatively slow RAM and a slower interconnect.  Compared to
the previous results on Inteli7, we notice that parallel multikey quicksort (pMKQS) is very
fast, and achieves slightly higher speedups than pS on most inputs on
IntelE5 and significantly higher ones on AMD48.  This effect is clearly due to
pS ignoring the NUMA architecture and thus incurring a relatively large
number of expensive inter-node random string accesses. We analyzed the number of
string access of pMKQS in Theorem~\ref{thm:mkqs-access}, after which the
characters are saved and accessed in a scanning pattern. This scanning
apparently works well on the NUMA machines, as it is very cache-efficient, can
be easily predicted by the processor's memory prefetcher, and a costly
inter-node transfered cache line contains saved characters of eight strings.

These expected results were the reason to focus on NUMA-aware string sorting
algorithms, and to develop parallel -way LCP-merge for top-level merging of
presorted sequences. In our experiments we ran ``pS-Unroll + pLCP-Merge''
only when there is at least one thread per NUMA node. We tried to rebalance
threads to other NUMA nodes once work on a node is done, but this did not work
well, since the additional inter-node synchronization was too costly. We thus
have to leave the question of how to balance sorting work on NUMA systems for
highly skewed inputs open to future research.  Plain LCP-merge also contains
costly inter-node random string accesses in case 1 of \LCPCompare. As predicted
in Section~\ref{sec:merge-details}, we saw a huge speed improvement due to
\emph{caching} of just the distinguishing character , and don't
consider the non-caching variant in our results.

On IntelE5, with four NUMA nodes, pS-Unroll + pLCP-Merge reaches the highest
speedups on URLs, GOV2 inputs and Wikipedia suffixes. On the AMD48 machine with
eight NUMA nodes, random access is even more costly and the inter-node
connections are easily congested, which is why pMKQS fairs better against our
NUMA-aware sorting.  In future (possibly the next revision of this
paper), experiments with caching more than just one character may lead to larger
speedups on these NUMA systems. Remarkably, radix sort is still very fast on
both NUMA machines for random inputs.

The lower three plots in Figure~\ref{fig:more-IntelE5} and \ref{fig:more-AMD48}
show that on these large many-core platforms, parallel sorting becomes less
efficient for small inputs (around 300\,MiB). This is expected due to the high
cost of synchronization, but our parallel algorithms still fare well.

\emph{AMD16} (Figure~\ref{fig:more-AMD16}, Table~\ref{tab:absrun-AMD16}) is an earlier NUMA architecture with
four NUMA nodes, and the slowest RAM speed and interconnect in our
experiment. However, on this machine random access, memory bandwidth and
processing power (in cache) seems to be more balanced for pS than on the
newer NUMA machines.

We included the absolute running times of all our speedup experiments in
Tables~\ref{tab:absrun-IntelE5}--\ref{tab:absrun-IntelX5b} for reference and to
show that our parallel implementations scale well both for very large instances
on many-core platforms and also for small inputs on machines with fewer cores.
For a final version of this article, we may need to remove the data
table. In this case, we will reference a technical report instead.

\subsection{Performance of Sequential Algorithms}\label{sec:exp-sequential}

We collected many sequential string sorting algorithms in our test framework. We
believe it to contain virtually every string sorting implementation publicly
available.

The algorithm library by Tommi Rantala \cite{rantala2007web} contains 37~versions
of radix sort (in-place, out-of-place, and one-pass with various dynamic memory
allocation schemes), 26~variants of multikey quicksort (with caching,
block-based, different dynamic memory allocation and SIMD instructions),
10~different funnelsorts, 38~implementations of burstsort (again with different
dynamic memory managements), and 29~mergesorts (with losertree and LCP caching
variants). In total these are 140~original implementation variants, all of high
quality.

The other main source of string sorting implementations are the publications of
Ranjan Sinha. We included the original burstsort implementations (one with
dynamically growing arrays and one with linked lists), and 9~versions of
copy-burstsort. The original copy-burstsort code was written for 32-bit
machines, and we modified it to work with 64-bit pointers.

We also incorporated the implementations of CRadix sort and LCP-Merge\-sort by
Waihong Ng, and the original multikey quicksort code by Bentley and Sedgewick.

\begin{table}[tb]\centering\normalsize
\caption{Description of selected sequential string sorting algorithms}\label{tab:seqalgo}
\begin{tabularx}{\linewidth}{l|X}
Name             & Description and Author                                                                                                                                        \\ \hline
std::sort        & \texttt{gcc}'s standard atomic introsort with full string comparisons.                                                                                        \\
mkqs             & Original multikey quicksort by Bentley and Sedgewick \cite{bentley1997fast}.                                                                                  \\
mkqs\_cache8     & Modified multikey quicksort with caching of eight characters by Tommi Rantala \cite{rantala2007web}, slightly improved.                                       \\
radix8\_CI       & 8-bit in-place radix sort by Tommi Rantala \cite{karkkainen2009engineering}.                                                                                  \\
radix16\_CI      & Adaptive 16-/8-bit in-place radix sort by Tommi Rantala \cite{karkkainen2009engineering}.                                                                     \\
radixR\_CE7      & Adaptive 16-/8-bit out-of-place radix sort by Tommi Rantala~\cite{karkkainen2009engineering}, version CE7 (preallocated swap array, unrolling, sorted-check). \\
CRadix           & Cache efficient radix sort by Waihong Ng \cite{ng2007cache}, unmodified.                                                                                      \\
LCPMergesort     & LCP-mergesort by Waihong Ng \cite{ng2008merging}, unmodified.                                                                                                 \\
Seq-S-Unroll & Sequential super scalar string sample sort with interleaved loop over strings, unrolled tree traversal and radix sort as base sorter.                         \\
Seq-S-Equal  & Sequential super scalar string sample sort with equality check, unrolled tree traversal and radix sort as base sorter.                                        \\
burstsortA       & Burstsort using dynamic arrays by Ranjan Sinha \cite{sinha2004cache-conscious}, from \cite{rantala2007web}.                                                   \\
fbC-burstsort    & Copy-Burstsort with ``free bursts'' by Ranjan Sinha \cite{sinha2007cache-efficient}, heavily repaired and modified to work with 64-bit pointers.              \\
sCPL-burstsort   & Copy-Burstsort with sampling, pointers and only limited copying depth by Ranjan Sinha \cite{sinha2007cache-efficient}, also heavily repaired.                 \\
\end{tabularx}
\end{table}

Of the 203 different sequential string sorting variants, we selected the
thirteen implementations listed in Table~\ref{tab:seqalgo} to represent both the
fastest ones in a preliminary test and each of the basic algorithms from
Section~\ref{sec:basic-sequential}. The thirteen algorithms were run on all our
five test platforms on small portions of the test instances described in
Section~\ref{sec:experiments}. Tables \ref{tab:seqalgo-results1} and
\ref{tab:seqalgo-results2} show the results, with the fastest algorithm's time
highlighted with bold text.

Cells in the tables without value indicate a program error, out-of-memory
exceptions or extremely long runtime. This was always the case for the
copy-burstsort variants on the GOV2 and Wikipedia inputs, because they perform
excessive caching of characters. On Inteli7, some implementations required more
memory than the available 12\,GiB to sort the 4\,GiB prefixes of Random and URLs.

Over all run instances and platforms, multikey quicksort with caching of eight
characters was fastest on 18~pairs, winning the most tests. It was fastest on
all platforms for both URL list and GOV2 prefixes, except URL on IntelX5, and on
all large instances on AMD48 and AMD16. However, for the NoDup input, short
strings with large alphabet, the highly tuned radix sort radixR\_CE7
consistently outperformed mkqs\_cache8 on all platforms by a small margin. The
copy-burstsort variant fbC\_burstsort was most efficient on all platforms for
DNA, which are short strings with small alphabet. For Random strings and
Wikipedia suffixes, mkqs\_cache8 or radixR\_CE7 was fastest, depending on the
platforms memory bandwidth and sequential processing speed.  Our own
\emph{sequential} implementations of S were never the fastest, but they
consistently fall in the middle field, without any outliers.  This is expected,
since S is mainly designed to be used as an efficient top-level parallel
algorithm, and to be conservative with memory bandwidth, since this is the
limiting factor for data-intensive multi-core applications.

We also measured the peak memory usage of the sequential implementations using a
heap and stack profiling
tool\footnote{\url{http://tbingmann.de/2013/malloc_count/}, by one of the
  authors.} for the selected sequential test instances. The bottom of
Table~\ref{tab:seqalgo-results1} shows the results in MiB, excluding the string
data array and the string pointer array (we only have 64-bit systems, so
pointers are eight bytes). We must note that the profiler considers
\emph{allocated virtual memory}, which may not be identical to the amount of
physical memory actually used. From the table we plainly see, that the more
\emph{caching} an implementation does, the higher its peak memory
allocation. However, the memory usage of fbC\_burstsort is extreme, even if one
considers that the implementation can deallocate and recreate the string data
from the burst trie. The lower memory usage of fbC\_burstsort for Random is due
to the high percentage of characters stored implicitly in the trie structure.
The sCPL\_burstsort and burstsortA variants bring the memory requirement down
somewhat, but they are still high. Some radixsort variants and, most notable,
mkqs\_cache8 are also not particularly memory conservative, again due to
caching. Our sequential S implementation fares well in this comparison
because it does no caching and permutes the string pointers in-place (Note that
radixsort is used for small string subsets in sequential S. This is due to
the development history: we finished sequential S before focusing on caching
multikey quicksort). For sorting with little extra memory, plain multikey
quicksort is still a good choice.





\begin{table}[p]\centering\small
\caption{Run time of sequential algorithms on IntelE5 and AMD48 in seconds, and peak memory usage of algorithms on IntelE5. See Table~\ref{tab:seqalgo} for a short description of each.}\label{tab:seqalgo-results1}
\def\tabcolsep{6pt}
\begin{tabular}{l|rrrr*{3}{r}|}
                    & \multicolumn{4}{c|}{Our Datasets} & \multicolumn{3}{c|}{Sinha's} \\
                    & URLs     & Random   & GOV2     & \multicolumn{1}{r|}{Wikipedia} & URLs     & DNA     & NoDup    \\ \hline
                 & 66\,M    & 409\,M   & 80.2\,M  & 256\,Mi   & 10\,M    & 31.5\,M & 31.6\,M  \\
                 & 4\,Gi    & 4\,Gi    & 4\,Gi    & 32\,Pi    & 304\,Mi  & 302\,Mi & 382\,Mi  \\
 ()       & 92.7\,\% & 43.0\,\% & 69.7\,\% & (13.6\,G) & 97.5\,\% & 100\,\% & 73.4\,\% \\
             & 57.9     & 3.3      & 34.1     & 33.0      & 29.4     & 9.0     & 7.7      \\ \hline
& \multicolumn{7}{c|}{IntelE5} \\ \cline{2-8}
std::sort &      122 &      422 &      153 &      287 &     11.6 &     26.9 &     25.4 \\
            mkqs &     37.1 &      228 &     56.7 &      129 &     5.67 &     11.0 &     10.9 \\
    mkqs\_cache8 & \bf 16.6 &     67.1 & \bf 25.7 &     79.5 & \bf 2.03 &     4.62 &     6.02 \\
      radix8\_CI &     48.4 &     64.3 &     54.6 &     90.1 &     6.12 &     6.79 &     6.29 \\
     radixR\_CE7 &     37.5 & \bf 58.6 &     44.6 & \bf 72.4 &     4.77 &     4.66 & \bf 4.73 \\
Seq-S-Unroll &     32.4 &      142 &     39.9 &      103 &     4.90 &     7.05 &     7.78 \\
 Seq-S-Equal &     32.8 &      169 &     45.6 &      120 &     5.11 &     7.68 &     8.38 \\
          CRadix &     54.1 &     65.1 &     61.6 &      113 &     6.82 &     10.2 &     8.63 \\
    LCPMergesort &     25.8 &      316 &     53.9 &      167 &     5.00 &     14.6 &     17.0 \\
      burstsortA &     29.5 &      131 &     43.3 &      120 &     5.64 &     8.48 &     8.46 \\
  fbC\_burstsort &     60.9 &     69.8 &          &          &     11.0 & \bf 3.81 &     15.4 \\
 sCPL\_burstsort &     45.0 &      122 &          &          &     11.1 &     14.3 &     24.8 \\ \hline
& \multicolumn{7}{c|}{AMD48} \\ \cline{2-8}
std::sort &      243 &   1\,071 &      197 &     494 &     21.7 &     55.7 &     44.2 \\
            mkqs &     90.7 &      511 &     78.2 &     226 &     11.0 &     20.8 &     19.8 \\
    mkqs\_cache8 & \bf 37.9 & \bf 96.9 & \bf 31.7 & \bf 114 & \bf 3.44 &     7.08 &     8.75 \\
      radix8\_CI &     83.1 &      127 &     71.2 &     138 &     9.72 &     10.9 &     9.46 \\
     radixR\_CE7 &     73.6 &      125 &     63.6 &     120 &     8.34 &     8.27 & \bf 7.70 \\
Seq-S-Unroll &     59.4 &      283 &     55.6 &     167 &     7.93 &     11.2 &     11.7 \\
 Seq-S-Equal &     56.5 &      292 &     57.7 &     180 &     8.06 &     11.5 &     12.2 \\
          CRadix &     98.2 &      115 &     68.8 &     147 &     8.11 &     12.6 &     11.2 \\
    LCPMergesort &     48.2 &      597 &     68.8 &     232 &     7.35 &     20.7 &     24.4 \\
      burstsortA &     46.0 &      214 &     53.0 &     193 &     8.49 &     13.3 &     13.1 \\
  fbC\_burstsort &     85.8 &      115 &          &         &     17.7 & \bf 5.92 &     22.1 \\
 sCPL\_burstsort &     73.1 &      266 &          &         &     20.1 &     24.6 &     37.9 \\ \hline
& \multicolumn{7}{p{76ex}|}{\centering{}Memory usage of sequential algorithms (on IntelE5) in MiB, excluding input and string pointer array} \\ \cline{2-8}
std::sort &   0.002 &  0.002 &  0.002 &  0.003 &  0.002 &  0.002 &  0.002 \\
            mkqs &   0.134 &  0.003 &   1.66 &  0.141 &  0.015 &  0.003 &  0.004 \\
    mkqs\_cache8 &  1\,002 & 6\,242 & 1\,225 & 4\,096 &    153 &    483 &    483 \\
      radix8\_CI &    62.7 &    390 &   77.2 &    256 &   9.55 &   30.2 &   30.2 \\
     radixR\_CE7 &     669 & 3\,902 &    786 & 2\,567 &    111 &    303 &    303 \\
Seq-S-Unroll &     129 &    781 &    155 &    513 &   20.3 &   60.8 &   60.9 \\
 Seq-S-Equal &     131 &    781 &    156 &    513 &   20.8 &   60.8 &   61.0 \\
          CRadix &     752 & 4\,681 &    919 & 3\,072 &    114 &    362 &    362 \\
    LCPMergesort &  1\,002 & 6\,242 & 1\,225 & 4\,096 &    153 &    483 &    483 \\
      burstsortA &  1\,466 & 7\,384 & 1\,437 & 5\,809 &    200 &    531 &    792 \\
  fbC\_burstsort & 31\,962 & 6\,200 &        &        & 2\,875 &    436 & 4\,182 \\
 sCPL\_burstsort &  9\,971 & 7\,262 &        &        & 1\,578 & 1\,697 & 5\,830 \\ \hline
\end{tabular}
\end{table}

\begin{table}[p]\centering\small
\caption{Run time of sequential algorithms on AMD16, Inteli7, and IntelX5 in seconds. See Table~\ref{tab:seqalgo} for a short description of each.}\label{tab:seqalgo-results2}
\def\tabcolsep{6pt}
\begin{tabular}{l|rrrr rrr|}
                    & \multicolumn{4}{c|}{Our Datasets} & \multicolumn{3}{c|}{Sinha's} \\
                    & URLs     & Random   & GOV2     & \multicolumn{1}{r|}{Wikipedia} & URLs     & DNA     & NoDup    \\ \hline
                 & 66\,M    & 409\,M   & 80.2\,M  & 256\,Mi   & 10\,M        & 31.5\,M & 31.6\,M  \\
                 & 4\,Gi    & 4\,Gi    & 4\,Gi    & 32\,Pi    & 304\,Mi      & 302\,Mi & 382\,Mi  \\
 ()       & 92.6\,\% & 43.0\,\% & 69.7\,\% & (13.6\,G) & 97.5\,\%     & 100\,\% & 73.4\,\% \\
             & 57.9     & 3.3      & 34.1     & 33.0      & 29.4         & 9.0     & 7.7      \\ \hline
& \multicolumn{7}{c|}{AMD16} \\ \cline{2-8}
std::sort &      274 &  1\,088 &      237 &         &     28.1 &     73.5 &     56.8 \\
            mkqs &      138 &     586 &     99.7 &     284 &     15.9 &     29.6 &     26.9 \\
    mkqs\_cache8 & \bf 45.4 & \bf 114 & \bf 40.2 &     142 & \bf 4.77 &     8.99 &     10.7 \\
      radix8\_CI &      112 &     158 &     84.5 &     171 &     11.7 &     13.6 &     11.5 \\
     radixR\_CE7 &     91.4 &     156 &     75.3 & \bf 135 &     10.5 &     10.8 & \bf 9.46 \\
Seq-S-Unroll &     70.6 &     326 &     68.4 &     235 &     9.57 &     14.5 &     14.8 \\
 Seq-S-Equal &     72.9 &     315 &     67.9 &     227 &     9.41 &     12.8 &     13.5 \\
          CRadix &      132 &     128 &     91.8 &     201 &     11.7 &     19.0 &     14.7 \\
    LCPMergesort &     56.8 &     631 &     86.6 &     285 &     9.22 &     25.5 &     30.9 \\
      burstsortA &     52.4 &     284 &     64.4 &     252 &     10.1 &     17.2 &     17.0 \\
  fbC\_burstsort &      109 &     123 &          &         &     25.5 & \bf 6.34 &     29.8 \\
 sCPL\_burstsort &     79.8 &     288 &          &         &     28.8 &     38.9 &     54.9 \\ \hline
& \multicolumn{7}{c|}{Inteli7} \\ \cline{2-8}
std::sort &     94.4 &      360 &     75.6 &      233 &     9.41 &     23.3 &     21.2 \\
            mkqs &     33.2 &      187 &     30.9 &      112 &     5.00 &     9.43 &     9.62 \\
    mkqs\_cache8 & \bf 14.7 &          & \bf 14.5 &     66.1 & \bf 1.81 &     3.91 &     5.10 \\
      radix8\_CI &     38.3 &     49.6 &     32.4 &     73.0 &     4.95 &     5.35 &     5.05 \\
     radixR\_CE7 &     30.7 & \bf 46.6 &     28.8 & \bf 59.7 &     3.85 &     3.71 & \bf 3.84 \\
Seq-S-Unroll &     25.3 &      108 &     26.2 &     86.5 &     3.94 &     5.75 &     6.44 \\
 Seq-S-Equal &     25.9 &      130 &     27.6 &     97.4 &     4.11 &     6.14 &     6.82 \\
          CRadix &     43.2 &          &     33.4 &     84.6 &     5.27 &     7.87 &     6.49 \\
    LCPMergesort &     22.7 &          &     32.3 &      139 &     4.33 &     12.1 &     14.2 \\
      burstsortA &     22.5 &          &     24.9 &      102 &     4.52 &     6.67 &     6.91 \\
  fbC\_burstsort &          &          &          &          &     9.31 & \bf 3.12 &     12.7 \\
 sCPL\_burstsort &     35.3 &          &          &          &     9.82 &     13.0 &     20.0 \\ \hline
& \multicolumn{7}{c|}{IntelX5} \\ \cline{2-8}
std::sort &      140 &      731 &      137 &      401 &     17.4 &     48.9 &     38.6 \\
            mkqs &     74.2 &      333 &     56.6 &      148 &     7.18 &     13.9 &     14.0 \\
    mkqs\_cache8 &     30.1 & \bf 80.1 & \bf 25.5 &     95.5 & \bf 3.35 &     6.48 &     7.51 \\
      radix8\_CI &     69.0 &      109 &     49.7 &     88.9 &     5.84 &     7.47 &     7.06 \\
     radixR\_CE7 &     55.9 &      110 &     44.6 & \bf 83.5 &     4.92 &     6.12 & \bf 5.95 \\
Seq-S-Unroll &     35.9 &      170 &     34.4 &      108 &     4.17 &     5.62 &     6.74 \\
 Seq-S-Equal &     38.7 &      198 &     36.5 &      121 &     4.65 &     6.09 &     7.19 \\
          CRadix &     77.7 &     94.3 &     57.7 &      141 &     8.26 &     13.3 &     11.0 \\
    LCPMergesort &     36.2 &      454 &     55.1 &      208 &     6.61 &     19.3 &     22.8 \\
      burstsortA & \bf 27.0 &      215 &     34.9 &      153 &     4.70 &     9.17 &     10.1 \\
  fbC\_burstsort &          &     86.8 &          &          &     16.4 & \bf 4.31 &     21.1 \\
 sCPL\_burstsort &     46.5 &      212 &          &          &     19.6 &     26.8 &     38.5 \\ \hline
\end{tabular}
\end{table}
 


\def\SpeedupLegend{\legend{
    pS-Unroll,
    pS-Equal,
    pS-Unroll + pLCP-Merge,
    pMultikeyQuicksort,
    pRadixsort 8-bit,
    pRadixsort 16-bit,
    pRadixsort Akiba
  }}

\begin{figure}[p]\centering\small\parskip=\smallskipamount


\begin{tikzpicture}
  \begin{axis}[plotSpeedup64,
    title={URLs, , },
    ylabel={speedup},
    ]

    \draw[HTline] (axis cs:32,\pgfkeysvalueof{/pgfplots/ymax}) -- (axis cs:32,\pgfkeysvalueof{/pgfplots/ymin});

\addplot coordinates { (1,0.974766) (2,1.98825) (4,3.95901) (6,5.28313) (8,6.64958) (12,8.92138) (16,11.7155) (20,12.9521) (24,13.6741) (28,14.0529) (32,14.407) (40,14.4037) (48,15.0139) (56,14.9361) (64,15.4681) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.954859) (2,1.95468) (4,3.92321) (6,5.27983) (8,6.63208) (12,8.90292) (16,11.6942) (20,13.0863) (24,13.4758) (28,14.1596) (32,14.6816) (40,14.3006) (48,14.9839) (56,14.9125) (64,14.9703) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (4,5.33275) (6,5.399) (8,8.2893) (12,10.7001) (16,13.1366) (20,14.8064) (24,16.0844) (28,17.2247) (32,17.9493) (40,17.4956) (48,18.0851) (56,17.4406) (64,17.6045) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,1) (2,2.11398) (4,4.23185) (6,5.66002) (8,7.32955) (12,10.7285) (16,13.1137) (20,14.5771) (24,15.05) (28,15.4622) (32,16.232) (40,15.9185) (48,16.6643) (56,16.1291) (64,16.2509) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.315004) (2,0.632866) (4,1.2514) (6,1.68307) (8,2.20627) (12,3.02951) (16,3.61263) (20,4.05577) (24,4.2885) (28,4.4496) (32,4.33955) (40,4.37397) (48,4.4156) (56,4.41452) (64,4.40274) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.314913) (2,0.699251) (4,1.39003) (6,1.8632) (8,2.37163) (12,3.44864) (16,4.16474) (20,4.62824) (24,4.92126) (28,5.06235) (32,5.17368) (40,5.28956) (48,5.34884) (56,5.33903) (64,5.30958) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.477322) (2,0.490666) (4,0.491655) (6,0.492051) (8,0.494072) (12,0.491459) (16,0.491847) (20,0.491225) (24,0.494187) (28,0.492039) (32,0.489973) (40,0.493851) (48,0.491749) (56,0.493136) (64,0.494044) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \legend{}
  \end{axis}
\end{tikzpicture}
\hfill \begin{tikzpicture}
  \begin{axis}[plotSpeedup64,
    title={Random, , },
    ]

    \draw[HTline] (axis cs:32,\pgfkeysvalueof{/pgfplots/ymax}) -- (axis cs:32,\pgfkeysvalueof{/pgfplots/ymin});

\addplot coordinates { (1,0.601744) (2,1.20909) (4,2.41459) (6,3.45429) (8,4.37921) (12,5.94566) (16,7.21395) (20,8.46732) (24,9.48612) (28,10.2401) (32,10.737) (40,10.8256) (48,11.1393) (56,11.4638) (64,11.4183) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.550267) (2,1.10639) (4,2.22983) (6,3.203) (8,4.07521) (12,5.56963) (16,6.7885) (20,7.93284) (24,8.93044) (28,9.76148) (32,10.2878) (40,10.3719) (48,10.7538) (56,11.1399) (64,11.3193) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (4,1.98166) (6,2.2362) (8,3.71563) (12,5.40183) (16,6.71925) (20,7.97728) (24,9.08606) (28,9.89158) (32,10.2393) (40,10.405) (48,9.99988) (56,9.82272) (64,10.1409) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,0.994161) (2,1.91898) (4,3.66903) (6,5.1472) (8,6.74018) (12,9.12209) (16,10.5319) (20,11.4576) (24,11.4294) (28,11.1948) (32,11.1023) (40,10.6664) (48,10.291) (56,9.98721) (64,9.67053) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.47526) (2,1.02974) (4,2.12304) (6,3.07041) (8,3.96947) (12,5.71535) (16,7.24752) (20,8.58494) (24,10.2527) (28,11.1431) (32,12.2696) (40,11.9588) (48,11.9588) (56,12.0962) (64,12.2908) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.475394) (2,1.10655) (4,2.12282) (6,3.06172) (8,3.93265) (12,5.6226) (16,7.25099) (20,8.8234) (24,10.4783) (28,11.7512) (32,12.9425) (40,13.4635) (48,13.8859) (56,14.0325) (64,13.5702) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.536881) (2,0.968636) (4,1.62642) (6,2.01535) (8,2.26332) (12,2.60085) (16,2.83083) (20,2.99766) (24,3.12951) (28,3.19974) (32,3.26496) (40,3.30265) (48,3.31866) (56,3.3119) (64,3.3687) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \legend{}
  \end{axis}
\end{tikzpicture}

\begin{tikzpicture}
  \begin{axis}[plotSpeedup64,
    title={GOV2, , },
    ylabel={speedup},
    ]

    \draw[HTline] (axis cs:32,\pgfkeysvalueof{/pgfplots/ymax}) -- (axis cs:32,\pgfkeysvalueof{/pgfplots/ymin});

\addplot coordinates { (1,0.956303) (2,1.98911) (4,4.10488) (6,5.56532) (8,6.31589) (12,7.58376) (16,9.21637) (20,10.38) (24,11.8644) (28,13.0622) (32,13.7765) (40,13.9202) (48,14.5244) (56,14.7761) (64,15.027) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.906652) (2,1.89749) (4,3.94115) (6,5.37837) (8,5.98301) (12,7.17722) (16,8.66913) (20,9.71406) (24,11.2824) (28,12.4883) (32,13.1923) (40,13.1858) (48,13.9574) (56,14.1049) (64,14.6656) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (4,4.91771) (6,4.95875) (8,8.0466) (12,10.2089) (16,11.9348) (20,13.5179) (24,14.3435) (28,15.1674) (32,16.619) (40,16.4843) (48,16.584) (56,16.1023) (64,16.2863) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,0.993399) (2,2.02486) (4,3.81834) (6,5.07328) (8,6.47598) (12,8.17344) (16,10.4948) (20,12.1183) (24,13.2557) (28,14.0458) (32,14.5726) (40,14.3957) (48,14.2716) (56,13.9763) (64,14.0727) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.315191) (2,0.671451) (4,1.3871) (6,1.88752) (8,2.2873) (12,2.89646) (16,3.39779) (20,3.98304) (24,4.30447) (28,4.12134) (32,4.47189) (40,4.32621) (48,4.42393) (56,4.52798) (64,4.60219) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.314654) (2,0.699781) (4,1.44127) (6,1.99307) (8,2.34298) (12,2.8408) (16,3.48621) (20,4.05551) (24,4.36594) (28,4.38657) (32,4.79989) (40,4.62405) (48,4.77726) (56,4.86342) (64,5.2019) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.505729) (2,1.02438) (4,1.30179) (6,1.25808) (8,1.26803) (12,1.27677) (16,1.29373) (20,1.29031) (24,1.28956) (28,1.28488) (32,1.2808) (40,1.27168) (48,1.27255) (56,1.27071) (64,1.27173) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \legend{}
  \end{axis}
\end{tikzpicture}
\hfill \begin{tikzpicture}
  \begin{axis}[plotSpeedup64,
    title={Wikipedia, },
    ]

    \draw[HTline] (axis cs:32,\pgfkeysvalueof{/pgfplots/ymax}) -- (axis cs:32,\pgfkeysvalueof{/pgfplots/ymin});

\addplot coordinates { (1,0.936438) (2,1.90512) (4,3.94143) (6,5.67822) (8,7.30245) (12,10.1436) (16,12.555) (20,14.7363) (24,17.3471) (28,19.5849) (32,21.2583) (40,22.0638) (48,23.2722) (56,24.2699) (64,24.7726) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.855381) (2,1.77978) (4,3.68011) (6,5.29784) (8,6.83879) (12,9.53709) (16,11.9048) (20,13.8579) (24,16.2404) (28,18.5146) (32,20.4221) (40,21.0757) (48,22.226) (56,23.2238) (64,24.3311) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (4,4.01997) (6,4.73533) (8,7.55119) (12,10.8681) (16,13.7343) (20,16.59) (24,19.6485) (28,22.1288) (32,23.8444) (40,24.6058) (48,26.1777) (56,27.4274) (64,27.7708) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,1) (2,2.02922) (4,4.12019) (6,5.87725) (8,7.60182) (12,10.7392) (16,13.5267) (20,16.2023) (24,17.9125) (28,19.0394) (32,20.1865) (40,20.9824) (48,20.9509) (56,21.152) (64,21.464) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.628628) (2,1.3598) (4,2.8095) (6,3.98646) (8,5.25227) (12,7.31502) (16,9.43152) (20,11.3385) (24,13.2715) (28,14.8023) (32,16.2874) (40,16.6583) (48,17.0206) (56,17.3722) (64,17.7453) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.627999) (2,1.41498) (4,2.921) (6,4.11868) (8,5.44793) (12,7.51443) (16,9.73236) (20,11.6311) (24,13.6882) (28,15.3943) (32,17.107) (40,17.2774) (48,17.6109) (56,17.8549) (64,18.4218) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.89271) (2,1.76151) (4,3.38789) (6,4.58814) (8,5.63601) (12,7.19565) (16,8.44885) (20,9.46584) (24,10.2391) (28,10.793) (32,11.1766) (40,11.0467) (48,9.62738) (56,9.64556) (64,9.71655) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \legend{}
  \end{axis}
\end{tikzpicture}

\begin{tikzpicture}
  \begin{axis}[plotSpeedup64,
    title={Sinha URLs, , },
    ylabel={speedup},
    ]

    \draw[HTline] (axis cs:32,\pgfkeysvalueof{/pgfplots/ymax}) -- (axis cs:32,\pgfkeysvalueof{/pgfplots/ymin});

\addplot coordinates { (1,0.999466) (2,2.00638) (4,4.02239) (6,5.43295) (8,6.7005) (12,8.05087) (16,8.63124) (20,10.2669) (24,10.9776) (28,11.374) (32,11.2627) (40,10.2958) (48,9.55862) (56,9.50889) (64,9.36358) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.941825) (2,1.90106) (4,3.79258) (6,5.16897) (8,6.30871) (12,7.56403) (16,8.13353) (20,9.8183) (24,10.5412) (28,10.7995) (32,10.9086) (40,9.84256) (48,9.72511) (56,9.32196) (64,8.77594) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (4,4.54621) (6,4.69246) (8,6.92692) (12,7.96417) (16,8.93304) (20,9.15095) (24,9.01576) (28,8.86138) (32,8.15999) (40,7.17744) (48,7.0384) (56,7.05151) (64,5.53302) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,0.931109) (2,1.87243) (4,3.73455) (6,4.92992) (8,6.28246) (12,8.08002) (16,8.89515) (20,9.17353) (24,9.24536) (28,8.27312) (32,8.17236) (40,7.10477) (48,6.83481) (56,5.82832) (64,5.07171) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.441868) (2,0.958087) (4,1.88533) (6,2.71739) (8,3.64026) (12,4.66969) (16,5.78256) (20,5.95009) (24,6.84117) (28,7.14451) (32,7.29914) (40,7.21448) (48,7.17391) (56,6.9797) (64,6.76483) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.442192) (2,1.04423) (4,2.05711) (6,2.90223) (8,3.82245) (12,4.99666) (16,6.02466) (20,6.17041) (24,6.31355) (28,6.48704) (32,6.83831) (40,5.94203) (48,5.50602) (56,5.30653) (64,4.80175) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.530769) (2,0.628281) (4,0.688666) (6,0.709595) (8,0.72257) (12,0.735917) (16,0.737783) (20,0.744833) (24,0.745612) (28,0.750317) (32,0.750141) (40,0.749874) (48,0.752457) (56,0.750924) (64,0.754918) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \legend{}
  \end{axis}
\end{tikzpicture}
\hfill \begin{tikzpicture}
  \begin{axis}[plotSpeedup64,
    title={Sinha DNA, , },
    xlabel={number of threads},
    every axis x label/.append style={overlay},
    ]

    \draw[HTline] (axis cs:32,\pgfkeysvalueof{/pgfplots/ymax}) -- (axis cs:32,\pgfkeysvalueof{/pgfplots/ymin});

\addplot coordinates { (1,0.998493) (2,1.96449) (4,3.82806) (6,5.2978) (8,6.48431) (12,8.37845) (16,9.61843) (20,10.9104) (24,11.7876) (28,12.2747) (32,12.6642) (40,12.7077) (48,12.6539) (56,12.5144) (64,12.9477) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.906346) (2,1.80524) (4,3.52267) (6,4.9104) (8,6.07049) (12,7.87099) (16,9.17477) (20,10.5097) (24,11.3281) (28,11.8731) (32,12.1278) (40,12.2304) (48,12.2554) (56,11.9657) (64,12.7644) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (4,4.29606) (6,4.26321) (8,6.42962) (12,8.07446) (16,8.73182) (20,9.26379) (24,10.0694) (28,10.1085) (32,9.92308) (40,9.61577) (48,9.09804) (56,8.71148) (64,8.43695) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,0.883224) (2,1.7371) (4,3.30741) (6,4.51264) (8,5.76261) (12,7.62804) (16,8.79617) (20,8.84956) (24,8.75796) (28,7.98026) (32,7.60665) (40,6.87231) (48,6.50323) (56,5.96579) (64,5.54318) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.686185) (2,1.31937) (4,2.68049) (6,3.82567) (8,5.02676) (12,6.75552) (16,8.11819) (20,9.22645) (24,10.0395) (28,10.218) (32,10.3915) (40,10.6453) (48,10.7567) (56,11.0403) (64,10.8747) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.686561) (2,1.39951) (4,2.78711) (6,3.94261) (8,5.122) (12,6.93212) (16,8.82577) (20,10.6587) (24,11.4291) (28,11.6277) (32,11.6815) (40,11.305) (48,10.6932) (56,10.3309) (64,9.46857) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.927775) (2,1.70877) (4,2.88629) (6,3.47351) (8,4.11565) (12,4.46737) (16,5.83675) (20,5.72129) (24,5.79189) (28,5.7737) (32,5.72867) (40,5.76998) (48,5.65996) (56,5.86075) (64,5.70168) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \legend{}
  \end{axis}
\end{tikzpicture}

\begin{tikzpicture}
  \begin{axis}[plotSpeedup64,
    title={Sinha NoDup, , },
    legend to name={speedup127},legend columns=1,
    ylabel={speedup},xlabel={number of threads},
    ]

    \draw[HTline] (axis cs:32,\pgfkeysvalueof{/pgfplots/ymax}) -- (axis cs:32,\pgfkeysvalueof{/pgfplots/ymin});

\addplot coordinates { (1,0.915701) (2,1.81457) (4,3.55012) (6,5.00297) (8,6.23176) (12,8.22771) (16,9.58894) (20,10.4273) (24,10.8939) (28,11.3492) (32,11.8037) (40,12.2983) (48,12.7922) (56,13.2688) (64,13.9269) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.856446) (2,1.69872) (4,3.34573) (6,4.7253) (8,5.9378) (12,7.86371) (16,9.17982) (20,10.1458) (24,10.6654) (28,11.1148) (32,11.4501) (40,12.0477) (48,12.6079) (56,12.9168) (64,13.3525) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (4,3.0097) (6,3.48041) (8,5.38567) (12,7.51843) (16,9.29834) (20,10.2897) (24,11.6018) (28,11.5284) (32,12.5311) (40,11.909) (48,10.9631) (56,10.6046) (64,9.71857) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,0.897669) (2,1.76347) (4,3.42247) (6,4.80178) (8,6.03705) (12,8.22937) (16,9.45292) (20,9.84738) (24,10.1758) (28,9.87553) (32,9.49213) (40,8.4568) (48,7.78807) (56,7.53421) (64,6.81024) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.907487) (2,1.86594) (4,3.77616) (6,5.40987) (8,7.00013) (12,9.83809) (16,11.7864) (20,14.2827) (24,15.4843) (28,16.7422) (32,17.8153) (40,17.9959) (48,17.9342) (56,18.0932) (64,17.1807) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.907047) (2,2.1675) (4,4.34344) (6,6.20918) (8,7.9846) (12,11.0978) (16,12.7222) (20,15.8103) (24,17.032) (28,17.0696) (32,17.9582) (40,17.4538) (48,16.2216) (56,15.7323) (64,15.0747) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.998969) (2,1.85303) (4,3.18045) (6,4.10496) (8,4.77027) (12,5.68907) (16,6.2783) (20,6.64474) (24,6.94499) (28,7.11521) (32,7.27884) (40,7.3799) (48,7.2864) (56,7.35096) (64,7.39178) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \SpeedupLegend
  \end{axis}
\end{tikzpicture}
\hfill \parbox{53mm}{\hfill\ref{speedup127}\hfill\null}
\caption{Speedup of parallel algorithm implementations on IntelE5, median of 1--3 runs}\label{fig:more-IntelE5}
\end{figure}



\begin{figure}[p]\centering\small\parskip=\smallskipamount


\begin{tikzpicture}
  \begin{axis}[plotSpeedup48,
    title={URLs, , },
    ylabel={speedup},
    ]

\addplot coordinates { (1,0.750409) (2,1.48314) (3,2.19963) (6,4.26124) (9,6.0729) (12,7.73635) (18,10.3301) (24,12.083) (30,13.2948) (36,14.5854) (42,16.1143) (48,16.5295) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.830498) (2,1.62128) (3,2.33941) (6,4.39276) (9,6.29068) (12,7.95963) (18,10.5542) (24,11.9032) (30,13.0933) (36,14.0586) (42,15.8534) (48,16.2436) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (9,6.33313) (12,6.80523) (18,10.1328) (24,12.8248) (30,14.0239) (36,15.453) (42,15.604) (48,16.5156) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,0.915963) (2,1.8647) (3,2.75885) (6,5.28335) (9,7.58253) (12,9.62174) (18,12.9807) (24,15.4843) (30,16.096) (36,17.486) (42,17.5708) (48,17.1593) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.303046) (2,0.591939) (3,0.862324) (6,1.65281) (9,2.38128) (12,2.90609) (18,3.81917) (24,4.36777) (30,4.53699) (36,4.92823) (42,4.96592) (48,4.9945) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.303207) (2,0.639245) (3,0.939096) (6,1.80557) (9,2.58712) (12,3.3037) (18,4.2192) (24,5.1272) (30,5.38343) (36,6.11976) (42,6.18269) (48,6.159) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.415528) (2,0.420303) (3,0.42203) (6,0.42257) (9,0.424666) (12,0.425158) (18,0.424179) (24,0.424384) (30,0.423229) (36,0.424437) (42,0.423192) (48,0.424519) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \legend{}
  \end{axis}
\end{tikzpicture}
\hfill \begin{tikzpicture}
  \begin{axis}[plotSpeedup48,
    title={Random, , },
    ]

\addplot coordinates { (1,0.570846) (2,1.09916) (3,1.60977) (6,3.02848) (9,4.26565) (12,5.37678) (18,7.22699) (24,8.70327) (30,9.89559) (36,10.8352) (42,11.6577) (48,12.1796) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.613079) (2,1.18455) (3,1.73494) (6,3.24284) (9,4.54827) (12,5.72984) (18,7.63815) (24,9.14645) (30,10.3254) (36,11.1879) (42,12.0843) (48,12.5775) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (9,3.82907) (12,4.05048) (18,6.90141) (24,9.07863) (30,9.08813) (36,10.4999) (42,11.384) (48,12.1404) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,1) (2,1.91806) (3,2.84839) (6,5.25575) (9,7.05368) (12,9.27459) (18,11.5002) (24,13.4129) (30,13.3853) (36,13.7201) (42,13.469) (48,12.2457) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.635266) (2,1.26425) (3,1.86069) (6,3.59573) (9,5.22536) (12,6.74592) (18,9.4309) (24,11.831) (30,13.817) (36,14.3852) (42,15.057) (48,15.9419) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.63209) (2,1.22113) (3,1.77468) (6,3.35962) (9,4.8824) (12,6.2683) (18,8.82308) (24,11.0491) (30,13.0161) (36,14.625) (42,15.8411) (48,16.7459) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.492337) (2,0.871761) (3,1.16841) (6,1.78453) (9,2.15705) (12,2.40393) (18,2.70964) (24,2.89966) (30,3.00408) (36,3.12084) (42,3.15506) (48,3.21375) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \legend{}
  \end{axis}
\end{tikzpicture}

\begin{tikzpicture}
  \begin{axis}[plotSpeedup48,
    title={GOV2, , },
    ylabel={speedup},
    ]

\addplot coordinates { (1,0.85109) (2,1.6707) (3,2.45489) (6,4.63968) (9,5.81513) (12,6.84268) (18,9.01303) (24,10.7245) (30,12.015) (36,12.836) (42,13.7791) (48,14.9359) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.877886) (2,1.72094) (3,2.53219) (6,4.79318) (9,6.11917) (12,7.22835) (18,9.47265) (24,11.1697) (30,12.537) (36,13.4345) (42,14.2904) (48,15.3967) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (9,7.48672) (12,7.63217) (18,12.0999) (24,15.3957) (30,15.6703) (36,17.4637) (42,19.0032) (48,20.0508) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,0.955083) (2,1.88805) (3,2.79903) (6,5.36673) (9,7.45435) (12,8.94757) (18,12.48) (24,14.7902) (30,16.7809) (36,17.0204) (42,17.5035) (48,17.596) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.362086) (2,0.738803) (3,1.1087) (6,2.13675) (9,2.6823) (12,2.98249) (18,4.12748) (24,4.86887) (30,5.54951) (36,5.98381) (42,6.26702) (48,6.6006) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.363845) (2,0.765504) (3,1.14993) (6,2.22099) (9,2.78827) (12,3.09529) (18,4.37611) (24,5.25075) (30,6.0255) (36,6.78135) (42,6.9802) (48,7.36415) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.484672) (2,0.944696) (3,1.21496) (6,1.2615) (9,1.28402) (12,1.28826) (18,1.29011) (24,1.28984) (30,1.27813) (36,1.28393) (42,1.28214) (48,1.2828) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \legend{}
  \end{axis}
\end{tikzpicture}
\hfill \begin{tikzpicture}
  \begin{axis}[plotSpeedup48,
    title={Wikipedia, },
    ]

\addplot coordinates { (1,0.882556) (2,1.71998) (3,2.53557) (6,4.83049) (9,6.92119) (12,8.8039) (18,12.0987) (24,14.8809) (30,17.1828) (36,19.3257) (42,20.9978) (48,22.0894) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.905581) (2,1.74442) (3,2.56918) (6,4.91779) (9,7.03798) (12,8.94713) (18,12.3076) (24,15.1088) (30,17.3869) (36,19.5954) (42,21.1699) (48,22.4315) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (9,5.3929) (12,5.64715) (18,10.1278) (24,13.8861) (30,17.0068) (36,17.2842) (42,19.8065) (48,21.8958) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,0.926464) (2,1.82607) (3,2.69891) (6,5.29061) (9,7.67097) (12,9.95464) (18,14.1067) (24,17.1093) (30,19.6777) (36,21.5269) (42,22.4843) (48,22.5458) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.566076) (2,1.18565) (3,1.7478) (6,3.45542) (9,5.13084) (12,6.69549) (18,9.72818) (24,12.5123) (30,15.0805) (36,16.9289) (42,18.4539) (48,19.8507) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.566167) (2,1.23408) (3,1.81271) (6,3.56089) (9,5.22569) (12,6.82081) (18,9.81465) (24,12.6308) (30,15.1333) (36,17.46) (42,19.433) (48,20.8247) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.73338) (2,1.40049) (3,2.00974) (6,3.58082) (9,4.82945) (12,5.79694) (18,7.26664) (24,7.32181) (30,7.35227) (36,7.36572) (42,7.35122) (48,7.28927) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \legend{}
  \end{axis}
\end{tikzpicture}

\begin{tikzpicture}
  \begin{axis}[plotSpeedup48,
    title={Sinha URLs, , },
    ylabel={speedup},
    ]

\addplot coordinates { (1,0.746262) (2,1.42621) (3,2.07367) (6,3.72194) (9,5.12839) (12,5.92991) (18,7.37552) (24,8.00771) (30,8.33664) (36,8.56887) (42,8.71595) (48,8.23862) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.78937) (2,1.51488) (3,2.20706) (6,3.93381) (9,5.35055) (12,6.17963) (18,7.70061) (24,8.31462) (30,8.71615) (36,9.33603) (42,9.34069) (48,8.80296) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (9,5.49299) (12,5.08945) (18,5.37063) (24,5.71168) (30,5.47754) (36,5.39267) (42,5.45724) (48,5.52419) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,0.837211) (2,1.64211) (3,2.38513) (6,4.49354) (9,6.1922) (12,7.36085) (18,8.59035) (24,9.11918) (30,8.72347) (36,8.48048) (42,8.04802) (48,6.80069) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.372115) (2,0.782165) (3,1.14137) (6,2.17448) (9,3.20048) (12,3.79035) (18,5.09304) (24,5.9577) (30,6.83059) (36,7.29734) (42,7.99392) (48,7.15947) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.371651) (2,0.870226) (3,1.24739) (6,2.186) (9,2.88823) (12,3.32379) (18,3.42719) (24,3.04786) (30,2.70433) (36,2.37545) (42,2.11384) (48,1.82624) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.412732) (2,0.489916) (3,0.520441) (6,0.558182) (9,0.572684) (12,0.580308) (18,0.587247) (24,0.590529) (30,0.590156) (36,0.590825) (42,0.593459) (48,0.594616) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \legend{}
  \end{axis}
\end{tikzpicture}
\hfill \begin{tikzpicture}
  \begin{axis}[plotSpeedup48,
    title={Sinha DNA, , },
    xlabel={number of threads},
    every axis x label/.append style={overlay},
    ]

\addplot coordinates { (1,0.823405) (2,1.54656) (3,2.22591) (6,3.95905) (9,5.33494) (12,6.46385) (18,8.04871) (24,9.09774) (30,9.79855) (36,10.0887) (42,10.2486) (48,10.2964) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.939949) (2,1.74954) (3,2.50913) (6,4.42606) (9,5.88421) (12,7.10393) (18,8.71619) (24,9.68648) (30,10.3383) (36,10.6252) (42,10.8429) (48,10.9384) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (9,5.77963) (12,4.77184) (18,4.52674) (24,5.59509) (30,5.616) (36,5.51509) (42,4.72972) (48,5.27873) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,0.799575) (2,1.53287) (3,2.19657) (6,4.11088) (9,5.61362) (12,6.54585) (18,7.88136) (24,8.24737) (30,7.97703) (36,7.74934) (42,7.39182) (48,6.77749) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.607953) (2,1.16783) (3,1.68972) (6,3.30709) (9,4.61144) (12,6.09417) (18,8.23377) (24,10.1252) (30,11.0911) (36,11.4002) (42,11.9866) (48,12.0241) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.607366) (2,1.24749) (3,1.83889) (6,3.47299) (9,4.68874) (12,5.98975) (18,7.6733) (24,8.61821) (30,8.37219) (36,7.51793) (42,7.01404) (48,6.24702) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.740451) (2,1.31647) (3,1.82294) (6,2.69205) (9,3.41119) (12,3.55153) (18,4.62663) (24,4.60258) (30,4.61943) (36,4.61003) (42,4.60146) (48,4.60157) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \legend{}
  \end{axis}
\end{tikzpicture}

\begin{tikzpicture}
  \begin{axis}[plotSpeedup48,
    title={Sinha NoDup, , },
    legend to name={speedup126},legend columns=1,
    ylabel={speedup},xlabel={number of threads},
    ]

\addplot coordinates { (1,0.641601) (2,1.22533) (3,1.78168) (6,3.26742) (9,4.52919) (12,5.60212) (18,7.27153) (24,8.42793) (30,9.295) (36,9.86301) (42,10.2536) (48,10.3857) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.685016) (2,1.30855) (3,1.89863) (6,3.47467) (9,4.7902) (12,5.91728) (18,7.60819) (24,8.73286) (30,9.58954) (36,10.1558) (42,10.5825) (48,10.6805) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (9,4.36667) (12,4.68296) (18,5.94262) (24,7.50042) (30,7.62508) (36,8.18505) (42,8.29852) (48,8.37507) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,0.733493) (2,1.41819) (3,2.0494) (6,3.84856) (9,5.40554) (12,6.42345) (18,8.24118) (24,8.8184) (30,8.71944) (36,8.33248) (42,7.92753) (48,7.07788) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.764395) (2,1.54564) (3,2.28417) (6,4.41559) (9,6.10572) (12,8.18944) (18,10.6938) (24,13.8353) (30,15.9454) (36,17.1137) (42,17.8285) (48,18.1993) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.764232) (2,1.71079) (3,2.52036) (6,4.78575) (9,6.26734) (12,8.34558) (18,9.45186) (24,10.5858) (30,10.0149) (36,8.92638) (42,8.18708) (48,7.47404) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.719562) (2,1.30203) (3,1.78621) (6,2.84388) (9,3.54031) (12,4.01599) (18,4.5929) (24,4.90949) (30,5.12658) (36,5.2439) (42,5.34533) (48,5.38175) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \SpeedupLegend
  \end{axis}
\end{tikzpicture}
\hfill \parbox{53mm}{\hfill\ref{speedup126}\hfill\null}
\caption{Speedup of parallel algorithm implementations on AMD48, median of 1--3 runs}\label{fig:more-AMD48}
\end{figure}



\begin{figure}[p]\centering\small\parskip=\smallskipamount
\begin{tikzpicture}
  \begin{axis}[plotSpeedup16,
    title={URLs, , },
    ylabel={speedup},
    ]

\addplot coordinates { (1,0.996097) (2,1.93926) (4,3.67931) (6,5.08504) (8,5.99254) (12,7.51112) (16,8.60517) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.928712) (2,1.80911) (4,3.42816) (6,4.61683) (8,5.62082) (12,6.85069) (16,8.17445) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (4,2.77223) (6,2.78177) (8,4.59208) (12,5.76948) (16,7.19596) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,0.925321) (2,1.92224) (4,3.61869) (6,4.78066) (8,5.67209) (12,6.63068) (16,6.86855) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.336167) (2,0.64755) (4,1.16613) (6,1.48682) (8,1.67163) (12,1.77526) (16,1.91586) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.336931) (2,0.702242) (4,1.27452) (6,1.65333) (8,1.87444) (12,1.98994) (16,2.28374) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.397263) (2,0.398102) (4,0.402551) (6,0.399594) (8,0.3803) (12,0.402843) (16,0.381983) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \legend{}
  \end{axis}
\end{tikzpicture}
\hfill \begin{tikzpicture}
  \begin{axis}[plotSpeedup16,
    title={Random, , },
    ]

\addplot coordinates { (1,0.518476) (2,1.00422) (4,1.92791) (6,2.74482) (8,3.48943) (12,4.69581) (16,5.68674) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.563427) (2,1.09211) (4,2.10211) (6,2.94878) (8,3.75565) (12,5.00471) (16,6.01668) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (4,1.69038) (6,1.80128) (8,3.12389) (12,4.36021) (16,5.43858) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,0.911639) (2,1.72276) (4,3.12557) (6,4.13696) (8,4.39836) (12,5.04346) (16,5.61131) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.578411) (2,1.16099) (4,2.17613) (6,3.20074) (8,3.89944) (12,5.17908) (16,6.2901) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.578564) (2,1.18084) (4,2.0923) (6,3.19642) (8,3.66537) (12,4.89052) (16,5.92626) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.434871) (2,0.763547) (4,1.23581) (6,1.53916) (8,1.76674) (12,2.05072) (16,2.23356) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \legend{}
  \end{axis}
\end{tikzpicture}

\begin{tikzpicture}
  \begin{axis}[plotSpeedup16,
    title={GOV2, , },
    ylabel={speedup},
    ]

\addplot coordinates { (1,0.865828) (2,1.6992) (4,3.29041) (6,4.64362) (8,5.23607) (12,6.47657) (16,7.96386) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.890456) (2,1.75408) (4,3.37873) (6,4.76587) (8,5.43494) (12,6.73462) (16,8.23942) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (4,3.56995) (6,3.71742) (8,6.25732) (12,8.44776) (16,10.3912) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,0.982692) (2,1.90927) (4,3.66304) (6,4.79485) (8,6.1991) (12,7.37091) (16,7.80824) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.420062) (2,0.860466) (4,1.65558) (6,2.20277) (8,2.60388) (12,2.7802) (16,3.15731) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.42069) (2,0.890183) (4,1.7064) (6,2.30422) (8,2.53625) (12,3.12764) (16,3.55795) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.526317) (2,1.01865) (4,1.28462) (6,1.29424) (8,1.29111) (12,1.28456) (16,1.27868) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \legend{}
  \end{axis}
\end{tikzpicture}
\hfill \begin{tikzpicture}
  \begin{axis}[plotSpeedup16,
    title={Wikipedia, },
    ]

\addplot coordinates { (1,0.764364) (2,1.51468) (4,3.00143) (6,4.36973) (8,5.71602) (12,8.13859) (16,10.361) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.783771) (2,1.55198) (4,3.07756) (6,4.47278) (8,5.85579) (12,8.32596) (16,10.5931) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (4,3.28753) (6,3.67775) (8,6.14842) (12,8.72225) (16,11.1251) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,0.926774) (2,1.83055) (4,3.51777) (6,4.94621) (8,6.1914) (12,7.93395) (16,8.9441) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.698467) (2,1.51085) (4,2.9694) (6,4.18611) (8,5.4514) (12,7.12493) (16,8.55479) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.700009) (2,1.57604) (4,3.09713) (6,4.29921) (8,5.65721) (12,7.35396) (16,8.99649) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.821593) (2,1.53269) (4,2.69958) (6,3.54309) (8,4.17458) (12,5.03663) (16,5.5399) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \legend{}
  \end{axis}
\end{tikzpicture}

\begin{tikzpicture}
  \begin{axis}[plotSpeedup16,
    title={Sinha URLs, , },
    ylabel={speedup},
    ]

\addplot coordinates { (1,0.944717) (2,1.83646) (4,3.54997) (6,5.02404) (8,6.21254) (12,7.90186) (16,8.73948) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.998915) (2,1.95873) (4,3.73024) (6,5.23945) (8,6.63289) (12,8.45683) (16,9.12872) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (4,2.92974) (6,2.9834) (8,4.72156) (12,5.59877) (16,6.59696) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,0.844915) (2,1.66173) (4,3.18482) (6,4.3279) (8,5.36546) (12,6.68209) (16,6.9158) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.389264) (2,0.808451) (4,1.51748) (6,2.12185) (8,2.75282) (12,3.17103) (16,3.58237) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.389811) (2,0.893564) (4,1.69915) (6,2.32452) (8,2.91721) (12,3.51435) (16,3.91877) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.405984) (2,0.480279) (4,0.531732) (6,0.5489) (8,0.55935) (12,0.571904) (16,0.572433) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \legend{}
  \end{axis}
\end{tikzpicture}
\hfill \begin{tikzpicture}
  \begin{axis}[plotSpeedup16,
    title={Sinha DNA, , },
    xlabel={number of threads},
    every axis x label/.append style={overlay},
    ]

\addplot coordinates { (1,0.86569) (2,1.67179) (4,3.24269) (6,4.77523) (8,6.13113) (12,8.36743) (16,9.96741) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.997658) (2,1.91279) (4,3.68862) (6,5.4082) (8,6.98754) (12,9.38013) (16,10.9577) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (4,3.29104) (6,3.3856) (8,5.42049) (12,6.89719) (16,7.77302) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,0.862717) (2,1.678) (4,3.09888) (6,4.12824) (8,4.89231) (12,5.61019) (16,5.85338) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.616864) (2,1.1879) (4,2.27875) (6,3.10367) (8,3.83405) (12,4.41847) (16,4.85272) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.616556) (2,1.27247) (4,2.44365) (6,3.3504) (8,4.14297) (12,4.7916) (16,5.78033) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.701883) (2,1.2693) (4,2.14323) (6,2.58188) (8,3.11075) (12,3.30566) (16,4.07479) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \legend{}
  \end{axis}
\end{tikzpicture}

\begin{tikzpicture}
  \begin{axis}[plotSpeedup16,
    title={Sinha NoDup, , },
    legend to name={speedup124},legend columns=1,
    ylabel={speedup},xlabel={number of threads},
    ]

\addplot coordinates { (1,0.795714) (2,1.55083) (4,3.01716) (6,4.44272) (8,5.75449) (12,8.00682) (16,9.86921) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.865283) (2,1.68331) (4,3.28162) (6,4.78404) (8,6.25101) (12,8.56386) (16,10.4237) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (4,2.24929) (6,2.60161) (8,4.14022) (12,5.78398) (16,7.20435) };
    \addlegendentry{algo=eberle/ps5-parallel-toplevel-merge};
    \addplot coordinates { (1,0.795421) (2,1.55636) (4,2.93862) (6,4.05978) (8,4.95868) (12,6.07494) (16,6.49496) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.78344) (2,1.59164) (4,3.0765) (6,4.32795) (8,5.45549) (12,6.92904) (16,7.60993) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.783918) (2,1.74726) (4,3.37178) (6,4.80988) (8,6.0842) (12,7.90708) (16,8.46205) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.731133) (2,1.32209) (4,2.218) (6,2.85274) (8,3.31951) (12,3.90085) (16,4.24069) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};

    \SpeedupLegend
  \end{axis}
\end{tikzpicture}
\hfill \parbox{53mm}{\hfill\ref{speedup124}\hfill\null}
\caption{Speedup of parallel algorithm implementations on AMD16, median of 1--3 runs}\label{fig:more-AMD16}
\end{figure}



\def\SpeedupLegend{\legend{
    pS-Unroll,
    pS-Equal,
    pMultikeyQuicksort,
    pRadixsort 8-bit,
    pRadixsort 16-bit,
    pRadixsort Akiba,
    pMKQS-SIMD Rantala,
    pMergesort-2way Rantala,
    pMergesort-2way Shamsundar
  }}

\begin{figure}[p]\centering\small\parskip=\smallskipamount


\begin{tikzpicture}
  \begin{axis}[plotSpeedup8,
    title={URLs, , },
    ylabel={speedup},
    ]

    \draw[HTline] (axis cs:4,\pgfkeysvalueof{/pgfplots/ymax}) -- (axis cs:4,\pgfkeysvalueof{/pgfplots/ymin});

\addplot coordinates { (1,0.972401) (2,1.70879) (3,2.46116) (4,2.99134) (5,3.00577) (6,3.19935) (7,3.28043) (8,3.41052) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.99973) (2,1.74836) (3,2.49284) (4,2.97622) (5,3.13419) (6,3.29324) (7,3.37077) (8,3.46607) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (1,0.9283) (2,1.64679) (3,2.19916) (4,2.58588) (5,2.66811) (6,2.72112) (7,2.77198) (8,2.80602) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.363083) (2,0.658043) (3,0.861096) (4,0.995139) (5,1.01229) (6,1.04143) (7,1.06013) (8,1.07317) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.363065) (2,0.722727) (3,0.969044) (4,1.13361) (5,1.16841) (6,1.19702) (7,1.21907) (8,1.23537) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.452258) (2,0.455251) (3,0.45564) (4,0.455531) (5,0.455536) (6,0.455666) (7,0.455555) (8,0.455482) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};
    \addplot coordinates { (1,0.479541) (2,0.834872) (3,0.834366) (4,1.13387) (5,1.16405) (6,1.38047) (7,1.45146) (8,1.46973) };
    \addlegendentry{algo=rantala/mergesort\_lcp\_2way\_parallel};
    \addplot coordinates { (1,0.460179) (2,0.744088) (3,0.936966) (4,1.06151) (5,1.07856) (6,1.08582) (7,1.08692) (8,1.08899) };
    \addlegendentry{algo=rantala/multikey\_simd\_parallel4};
    \addplot coordinates { (1,0.487199) (2,0.766454) (3,0.983612) (4,1.09668) (5,1.1083) (6,1.09879) (7,1.12205) (8,1.11072) };
    \addlegendentry{algo=shamsundar/lcp-merge-string-sort};

    \legend{}
  \end{axis}
\end{tikzpicture}
\hfill \begin{tikzpicture}
  \begin{axis}[plotSpeedup8,
    title={Random, , },
    ]

    \draw[HTline] (axis cs:4,\pgfkeysvalueof{/pgfplots/ymax}) -- (axis cs:4,\pgfkeysvalueof{/pgfplots/ymin});

\addplot coordinates { (1,0.608294) (2,1.11831) (3,1.62185) (4,2.08281) (5,2.05642) (6,2.15798) (7,2.36101) (8,2.55) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.57169) (2,1.05098) (3,1.52995) (4,1.97083) (5,2.0046) (6,2.11034) (7,2.3139) (8,2.49886) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (1,0.627624) (2,1.15434) (3,1.64564) (4,2.07669) (5,2.26567) (6,2.42465) (7,2.52332) (8,2.60838) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.828673) (2,1.52015) (3,2.1175) (4,2.48091) (5,2.59118) (6,2.71047) (7,2.79322) (8,2.85097) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.828638) (2,1.56854) (3,2.16318) (4,2.34224) (5,2.52118) (6,2.55722) (7,2.73416) (8,2.66588) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.813881) (2,1.2136) (3,1.46592) (4,1.62563) (5,1.66991) (6,1.71105) (7,1.74363) (8,1.77602) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};
    \addplot coordinates { (1,0.203959) (2,0.336518) (3,0.336514) (4,0.373197) (5,0.417058) (6,0.450217) (7,0.486981) (8,0.487086) };
    \addlegendentry{algo=rantala/mergesort\_lcp\_2way\_parallel};
    \addplot coordinates { (1,0.159486) (2,0.268213) (3,0.354062) (4,0.414261) (5,0.417885) (6,0.419778) (7,0.420627) (8,0.423163) };
    \addlegendentry{algo=rantala/multikey\_simd\_parallel4};
    \addplot coordinates { (1,0.105888) (2,0.165005) (3,0.193239) (4,0.199904) (5,0.185464) (6,0.178065) (7,0.170066) (8,0.161867) };
    \addlegendentry{algo=shamsundar/lcp-merge-string-sort};

    \legend{}
  \end{axis}
\end{tikzpicture}

\begin{tikzpicture}
  \begin{axis}[plotSpeedup8,
    title={GOV2, , },
    ylabel={speedup},
    ]

    \draw[HTline] (axis cs:4,\pgfkeysvalueof{/pgfplots/ymax}) -- (axis cs:4,\pgfkeysvalueof{/pgfplots/ymin});

\addplot coordinates { (1,0.999196) (2,1.8256) (3,2.60945) (4,3.3062) (5,3.27222) (6,3.31645) (7,3.49914) (8,3.71618) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.965032) (2,1.76566) (3,2.52746) (4,3.20945) (5,3.31226) (6,3.37419) (7,3.53614) (8,3.73848) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (1,0.843514) (2,1.51291) (3,2.0977) (4,2.57013) (5,2.70407) (6,2.84761) (7,2.94657) (8,3.03291) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.389854) (2,0.733136) (3,1.01223) (4,1.28365) (5,1.32438) (6,1.37023) (7,1.38284) (8,1.34621) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.390101) (2,0.763793) (3,1.07333) (4,1.35592) (5,1.41828) (6,1.49361) (7,1.55333) (8,1.59123) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.476299) (2,0.857464) (3,0.972216) (4,0.983475) (5,0.981728) (6,0.916572) (7,0.904021) (8,0.904372) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};
    \addplot coordinates { (1,0.399586) (2,0.674226) (3,0.677166) (4,0.775457) (5,0.82631) (6,1.01917) (7,1.03333) (8,1.04821) };
    \addlegendentry{algo=rantala/mergesort\_lcp\_2way\_parallel};
    \addplot coordinates { (1,0.40188) (2,0.669081) (3,0.877903) (4,1.01875) (5,1.03212) (6,1.04497) (7,1.0512) (8,1.05416) };
    \addlegendentry{algo=rantala/multikey\_simd\_parallel4};
    \addplot coordinates { (1,0.2974) (2,0.569824) (3,0.82517) (4,1.04613) (5,1.01999) (6,1.13741) (7,1.24125) (8,1.31271) };
    \addlegendentry{algo=shamsundar/lcp-merge-string-sort};

    \legend{}
  \end{axis}
\end{tikzpicture}
\hfill \begin{tikzpicture}
  \begin{axis}[plotSpeedup8,
    title={Wikipedia, },
    ]

    \draw[HTline] (axis cs:4,\pgfkeysvalueof{/pgfplots/ymax}) -- (axis cs:4,\pgfkeysvalueof{/pgfplots/ymin});

\addplot coordinates { (1,0.995627) (2,1.81653) (3,2.6354) (4,3.40262) (5,3.48571) (6,3.70222) (7,4.04757) (8,4.37885) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.941684) (2,1.72386) (3,2.50564) (4,3.24064) (5,3.39956) (6,3.65702) (7,3.96416) (8,4.29128) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (1,0.859935) (2,1.59129) (3,2.2849) (4,2.92271) (5,3.2092) (6,3.44763) (7,3.67017) (8,3.85076) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.800617) (2,1.57359) (3,2.27736) (4,2.99101) (5,3.20794) (6,3.46082) (7,3.69543) (8,3.95773) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.80039) (2,1.64636) (3,2.36387) (4,3.1405) (5,3.33855) (6,3.60636) (7,3.85934) (8,4.1094) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.955796) (2,1.71109) (3,2.39737) (4,2.98559) (5,3.20428) (6,3.41306) (7,3.6005) (8,3.78843) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};
    \addplot coordinates { (1,0.486403) (2,0.825184) (3,0.820258) (4,0.919764) (5,1.01707) (6,1.155) (7,1.24172) (8,1.25014) };
    \addlegendentry{algo=rantala/mergesort\_lcp\_2way\_parallel};
    \addplot coordinates { (1,0.469331) (2,0.801477) (3,1.07406) (4,1.27352) (5,1.30562) (6,1.33221) (7,1.34991) (8,1.37048) };
    \addlegendentry{algo=rantala/multikey\_simd\_parallel4};
    \addplot coordinates { (1,0.270244) (2,0.518629) (3,0.752857) (4,0.960499) (5,0.983053) (6,1.09484) (7,1.15843) (8,1.23077) };
    \addlegendentry{algo=shamsundar/lcp-merge-string-sort};

    \legend{}
  \end{axis}
\end{tikzpicture}

\begin{tikzpicture}
  \begin{axis}[plotSpeedup8,
    title={Sinha URLs, , },
    ylabel={speedup},
    ]

    \draw[HTline] (axis cs:4,\pgfkeysvalueof{/pgfplots/ymax}) -- (axis cs:4,\pgfkeysvalueof{/pgfplots/ymin});

\addplot coordinates { (1,0.999456) (2,1.80878) (3,2.59434) (4,3.2771) (5,3.11342) (6,3.32549) (7,3.47032) (8,3.58117) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.92257) (2,1.66917) (3,2.40662) (4,3.05302) (5,3.05431) (6,3.24926) (7,3.41051) (8,3.5383) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (1,0.79902) (2,1.44494) (3,2.01357) (4,2.49463) (5,2.60012) (6,2.70175) (7,2.79498) (8,2.83635) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.305205) (2,0.621748) (3,0.887946) (4,1.12246) (5,1.16696) (6,1.20952) (7,1.25679) (8,1.28584) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.305158) (2,0.690238) (3,0.988567) (4,1.27081) (5,1.30088) (6,1.34776) (7,1.38714) (8,1.43309) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.384053) (2,0.448526) (3,0.477531) (4,0.492919) (5,0.493939) (6,0.496973) (7,0.497989) (8,0.500591) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};
    \addplot coordinates { (1,0.387513) (2,0.65766) (3,0.657901) (4,0.754267) (5,0.830392) (6,0.940009) (7,1.01895) (8,1.0072) };
    \addlegendentry{algo=rantala/mergesort\_lcp\_2way\_parallel};
    \addplot coordinates { (1,0.392698) (2,0.65017) (3,0.843155) (4,0.969384) (5,0.963535) (6,0.968319) (7,0.960954) (8,0.955928) };
    \addlegendentry{algo=rantala/multikey\_simd\_parallel4};
    \addplot coordinates { (1,0.260012) (2,0.431675) (3,0.533133) (4,0.582222) (5,0.545892) (6,0.548345) (7,0.53898) (8,0.527164) };
    \addlegendentry{algo=shamsundar/lcp-merge-string-sort};

    \legend{}
  \end{axis}
\end{tikzpicture}
\hfill \begin{tikzpicture}
  \begin{axis}[plotSpeedup8,
    title={Sinha DNA, , },
    xlabel={number of threads},
    every axis x label/.append style={overlay},
    ]

    \draw[HTline] (axis cs:4,\pgfkeysvalueof{/pgfplots/ymax}) -- (axis cs:4,\pgfkeysvalueof{/pgfplots/ymin});

\addplot coordinates { (1,0.99892) (2,1.80374) (3,2.57917) (4,3.24537) (5,2.97361) (6,3.26755) (7,3.33132) (8,3.53799) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.873726) (2,1.58994) (3,2.28791) (4,2.89553) (5,2.82289) (6,3.1141) (7,3.19676) (8,3.40387) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (1,0.68729) (2,1.24212) (3,1.7092) (4,2.10566) (5,2.23041) (6,2.34432) (7,2.40405) (8,2.43804) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.537349) (2,0.984869) (3,1.37113) (4,1.75416) (5,1.80751) (6,1.86269) (7,1.90882) (8,1.95066) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.537452) (2,1.05809) (3,1.51244) (4,1.87629) (5,1.91339) (6,1.96581) (7,2.00133) (8,2.06926) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.768171) (2,1.2863) (3,1.68824) (4,1.96086) (5,1.9518) (6,1.91462) (7,1.96107) (8,2.04891) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};
    \addplot coordinates { (1,0.265258) (2,0.462427) (3,0.461996) (4,0.572787) (5,0.576459) (6,0.70563) (7,0.737828) (8,0.739798) };
    \addlegendentry{algo=rantala/mergesort\_lcp\_2way\_parallel};
    \addplot coordinates { (1,0.279211) (2,0.452547) (3,0.576373) (4,0.652529) (5,0.651691) (6,0.648686) (7,0.645622) (8,0.644521) };
    \addlegendentry{algo=rantala/multikey\_simd\_parallel4};
    \addplot coordinates { (1,0.158888) (2,0.265294) (3,0.334327) (4,0.371593) (5,0.350311) (6,0.359217) (7,0.354851) (8,0.35003) };
    \addlegendentry{algo=shamsundar/lcp-merge-string-sort};

    \legend{}
  \end{axis}
\end{tikzpicture}

\begin{tikzpicture}
  \begin{axis}[plotSpeedup8,
    title={Sinha NoDup, , },
    legend to name={speedup113},legend columns=1,
    ylabel={speedup},xlabel={number of threads},
    ]

    \draw[HTline] (axis cs:4,\pgfkeysvalueof{/pgfplots/ymax}) -- (axis cs:4,\pgfkeysvalueof{/pgfplots/ymin});

\addplot coordinates { (1,0.843128) (2,1.5498) (3,2.2609) (4,2.92167) (5,2.88146) (6,3.16792) (7,3.33962) (8,3.58155) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.772935) (2,1.43051) (3,2.08821) (4,2.70474) (5,2.77523) (6,2.97191) (7,3.23925) (8,3.48034) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (1,0.700966) (2,1.28503) (3,1.81623) (4,2.29789) (5,2.51823) (6,2.7052) (7,2.86087) (8,2.97847) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.733786) (2,1.41276) (3,2.04545) (4,2.6041) (5,2.74059) (6,2.91974) (7,3.0644) (8,3.20181) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.733414) (2,1.54795) (3,2.25772) (4,2.89201) (5,2.99533) (6,3.21784) (7,3.4107) (8,3.58816) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.771594) (2,1.34974) (3,1.85659) (4,2.27772) (5,2.41103) (6,2.54968) (7,2.67543) (8,2.80077) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};
    \addplot coordinates { (1,0.301755) (2,0.513879) (3,0.514098) (4,0.615646) (5,0.643015) (6,0.784059) (7,0.78568) (8,0.783031) };
    \addlegendentry{algo=rantala/mergesort\_lcp\_2way\_parallel};
    \addplot coordinates { (1,0.282158) (2,0.474103) (3,0.628564) (4,0.732347) (5,0.743653) (6,0.752681) (7,0.758433) (8,0.762842) };
    \addlegendentry{algo=rantala/multikey\_simd\_parallel4};
    \addplot coordinates { (1,0.193982) (2,0.314972) (3,0.382818) (4,0.408169) (5,0.40646) (6,0.379143) (7,0.368308) (8,0.357651) };
    \addlegendentry{algo=shamsundar/lcp-merge-string-sort};

    \SpeedupLegend
  \end{axis}
\end{tikzpicture}
\hfill \parbox{53mm}{\hfill\ref{speedup113}\hfill\null}
\caption{Speedup of parallel algorithm implementations on Inteli7, median of fifteen runs}\label{fig:more-Inteli7}
\end{figure}



\begin{figure}[p]\centering\small\parskip=\smallskipamount
\begin{tikzpicture}
  \begin{axis}[plotSpeedup8,
    title={URLs, , },
    ylabel={speedup},
    ]

\addplot coordinates { (1,0.9999) (2,1.8233) (3,2.30003) (4,2.715) (5,2.7834) (6,2.925) (7,2.95107) (8,2.95976) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.958927) (2,1.74914) (3,2.22175) (4,2.64318) (5,2.73381) (6,2.84733) (7,2.89255) (8,2.90514) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (1,0.837161) (2,1.5589) (3,1.88237) (4,2.12172) (5,2.14288) (6,2.16397) (7,2.16314) (8,2.17112) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.374131) (2,0.627294) (3,0.705535) (4,0.770699) (5,0.771934) (6,0.783031) (7,0.773114) (8,0.784894) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.374151) (2,0.715279) (3,0.82246) (4,0.896028) (5,0.907074) (6,0.908327) (7,0.899429) (8,0.941041) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.463834) (2,0.470392) (3,0.469601) (4,0.470329) (5,0.469912) (6,0.470313) (7,0.469001) (8,0.470727) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};
    \addplot coordinates { (1,0.653837) (2,1.13822) (3,1.0704) (4,1.33409) (5,1.40046) (6,1.60539) (7,1.59971) (8,1.60719) };
    \addlegendentry{algo=rantala/mergesort\_lcp\_2way\_parallel};
    \addplot coordinates { (1,0.367881) (2,0.610155) (3,0.669326) (4,0.720991) (5,0.724768) (6,0.727782) (7,0.725803) (8,0.724932) };
    \addlegendentry{algo=rantala/multikey\_simd\_parallel4};
    \addplot coordinates { (1,0.519033) (2,0.887236) (3,1.06976) (4,1.12566) (5,0.971145) (6,1.00614) (7,1.03255) (8,0.973544) };
    \addlegendentry{algo=shamsundar/lcp-merge-string-sort};

    \legend{}
  \end{axis}
\end{tikzpicture}
\hfill \begin{tikzpicture}
  \begin{axis}[plotSpeedup8,
    title={Random, , },
    ]

\addplot coordinates { (1,0.750499) (2,1.39654) (3,1.90137) (4,2.3556) (5,2.57483) (6,2.82592) (7,2.98461) (8,3.12177) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.717486) (2,1.33935) (3,1.83443) (4,2.27705) (5,2.4961) (6,2.78747) (7,2.94421) (8,3.0756) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (1,0.895597) (2,1.66191) (3,2.07347) (4,2.41392) (5,2.48164) (6,2.50547) (7,2.51362) (8,2.50966) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.760502) (2,1.33472) (3,1.66384) (4,1.93697) (5,2.07782) (6,2.18745) (7,2.26575) (8,2.31419) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.760415) (2,1.36241) (3,1.68131) (4,2.10862) (5,2.18143) (6,2.31419) (7,2.42069) (8,2.47954) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.7214) (2,1.16437) (3,1.40523) (4,1.58609) (5,1.68643) (6,1.76742) (7,1.80753) (8,1.84844) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};
    \addplot coordinates { (1,0.194263) (2,0.316622) (3,0.294321) (4,0.342492) (5,0.351533) (6,0.378237) (7,0.383385) (8,0.380583) };
    \addlegendentry{algo=rantala/mergesort\_lcp\_2way\_parallel};
    \addplot coordinates { (1,0.12613) (2,0.212535) (3,0.239354) (4,0.257622) (5,0.262098) (6,0.265431) (7,0.267872) (8,0.269156) };
    \addlegendentry{algo=rantala/multikey\_simd\_parallel4};
    \addplot coordinates { (1,0.0943263) (2,0.151745) (3,0.150963) (4,0.156201) (5,0.152621) (6,0.142955) (7,0.124777) (8,0.11621) };
    \addlegendentry{algo=shamsundar/lcp-merge-string-sort};

    \legend{}
  \end{axis}
\end{tikzpicture}

\begin{tikzpicture}
  \begin{axis}[plotSpeedup8,
    title={GOV2, , },
    ylabel={speedup},
    ]

\addplot coordinates { (1,0.999774) (2,1.85245) (3,2.44397) (4,2.95046) (5,3.10226) (6,3.29865) (7,3.21952) (8,3.26321) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.972179) (2,1.80805) (3,2.40696) (4,2.91571) (5,3.08005) (6,3.28325) (7,3.18875) (8,3.22998) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (1,0.814039) (2,1.48325) (3,1.83432) (4,2.11823) (5,2.16963) (6,2.17244) (7,2.15759) (8,2.15199) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.416966) (2,0.774196) (3,0.959289) (4,1.09138) (5,1.06301) (6,1.05661) (7,1.08192) (8,1.08523) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.416992) (2,0.803135) (3,1.01642) (4,1.19533) (5,1.269) (6,1.18249) (7,1.23025) (8,1.23079) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.507369) (2,0.925263) (3,0.969526) (4,0.988834) (5,0.972064) (6,0.944768) (7,0.908467) (8,0.900704) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};
    \addplot coordinates { (1,0.385581) (2,0.639746) (3,0.584819) (4,0.692151) (5,0.72175) (6,0.771044) (7,0.768984) (8,0.762475) };
    \addlegendentry{algo=rantala/mergesort\_lcp\_2way\_parallel};
    \addplot coordinates { (1,0.289402) (2,0.485785) (3,0.544264) (4,0.589299) (5,0.60013) (6,0.603382) (7,0.607746) (8,0.602314) };
    \addlegendentry{algo=rantala/multikey\_simd\_parallel4};
    \addplot coordinates { (1,0.258377) (2,0.508917) (3,0.530522) (4,0.671417) (5,0.71353) (6,0.766202) (7,0.723444) (8,0.731737) };
    \addlegendentry{algo=shamsundar/lcp-merge-string-sort};

    \legend{}
  \end{axis}
\end{tikzpicture}
\hfill \begin{tikzpicture}
  \begin{axis}[plotSpeedup8,
    title={Wikipedia, },
    ]

\addplot coordinates { (1,0.953217) (2,1.78363) (3,2.42464) (4,2.97705) (5,3.25106) (6,3.5207) (7,3.63734) (8,3.74216) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.915313) (2,1.7221) (3,2.34793) (4,2.89583) (5,3.17163) (6,3.44586) (7,3.57013) (8,3.67465) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (1,0.877002) (2,1.64463) (3,2.111) (4,2.48825) (5,2.59075) (6,2.66056) (7,2.68218) (8,2.67951) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.873188) (2,1.65696) (3,2.16424) (4,2.60002) (5,2.7568) (6,2.89685) (7,2.95072) (8,2.99349) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.871335) (2,1.69033) (3,2.19403) (4,2.69712) (5,2.85174) (6,2.9764) (7,3.08939) (8,3.17213) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.959605) (2,1.72032) (3,2.21548) (4,2.61486) (5,2.77828) (6,2.87419) (7,2.93601) (8,2.95505) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};
    \addplot coordinates { (1,0.439717) (2,0.707147) (3,0.656473) (4,0.780054) (5,0.799037) (6,0.802101) (7,0.804788) (8,0.804035) };
    \addlegendentry{algo=rantala/mergesort\_lcp\_2way\_parallel};
    \addplot coordinates { (1,0.316914) (2,0.538889) (3,0.614161) (4,0.666245) (5,0.673717) (6,0.677455) (7,0.676614) (8,0.674767) };
    \addlegendentry{algo=rantala/multikey\_simd\_parallel4};
    \addplot coordinates { (1,0.209457) (2,0.417124) (3,0.535823) (4,0.66661) (5,0.63199) (6,0.654877) (7,0.732874) (8,0.698853) };
    \addlegendentry{algo=shamsundar/lcp-merge-string-sort};

    \legend{}
  \end{axis}
\end{tikzpicture}

\begin{tikzpicture}
  \begin{axis}[plotSpeedup8,
    title={Sinha URLs, , },
    ylabel={speedup},
    ]

\addplot coordinates { (1,0.999116) (2,1.82065) (3,2.37738) (4,2.81738) (5,2.94902) (6,3.0943) (7,3.11714) (8,3.12621) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.959066) (2,1.75599) (3,2.31292) (4,2.75425) (5,2.94697) (6,3.08898) (7,3.12007) (8,3.12733) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (1,0.814119) (2,1.49311) (3,1.85363) (4,2.148) (5,2.18081) (6,2.20993) (7,2.1951) (8,2.16208) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.496591) (2,0.901499) (3,1.10355) (4,1.26436) (5,1.3064) (6,1.33523) (7,1.34728) (8,1.35477) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.496067) (2,1.01527) (3,1.25019) (4,1.45987) (5,1.50493) (6,1.53161) (7,1.55285) (8,1.56339) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.567312) (2,0.662461) (3,0.687989) (4,0.709017) (5,0.710197) (6,0.708669) (7,0.710997) (8,0.712768) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};
    \addplot coordinates { (1,0.45385) (2,0.723138) (3,0.673333) (4,0.792516) (5,0.818357) (6,0.843156) (7,0.81748) (8,0.832144) };
    \addlegendentry{algo=rantala/mergesort\_lcp\_2way\_parallel};
    \addplot coordinates { (1,0.303796) (2,0.494891) (3,0.531101) (4,0.564223) (5,0.563809) (6,0.564978) (7,0.558656) (8,0.558662) };
    \addlegendentry{algo=rantala/multikey\_simd\_parallel4};
    \addplot coordinates { (1,0.286173) (2,0.475861) (3,0.533578) (4,0.56684) (5,0.493436) (6,0.497404) (7,0.485898) (8,0.462927) };
    \addlegendentry{algo=shamsundar/lcp-merge-string-sort};

    \legend{}
  \end{axis}
\end{tikzpicture}
\hfill \begin{tikzpicture}
  \begin{axis}[plotSpeedup8,
    title={Sinha DNA, , },
    xlabel={number of threads},
    every axis x label/.append style={overlay},
    ]

\addplot coordinates { (1,0.99905) (2,1.78543) (3,2.3211) (4,2.78063) (5,2.96105) (6,3.22262) (7,3.32007) (8,3.43184) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.912136) (2,1.65021) (3,2.17619) (4,2.62363) (5,2.82404) (6,3.09781) (7,3.20896) (8,3.33858) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (1,0.718659) (2,1.29376) (3,1.51569) (4,1.72392) (5,1.73832) (6,1.7327) (7,1.73115) (8,1.71999) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.688775) (2,1.17741) (3,1.33465) (4,1.52431) (5,1.52867) (6,1.53956) (7,1.54092) (8,1.52852) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.688688) (2,1.26858) (3,1.48148) (4,1.65575) (5,1.66331) (6,1.67388) (7,1.66643) (8,1.67138) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.855474) (2,1.37842) (3,1.49261) (4,1.64729) (5,1.63897) (6,1.64864) (7,1.64529) (8,1.67481) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};
    \addplot coordinates { (1,0.283608) (2,0.484903) (3,0.452237) (4,0.572926) (5,0.576268) (6,0.647767) (7,0.643427) (8,0.648369) };
    \addlegendentry{algo=rantala/mergesort\_lcp\_2way\_parallel};
    \addplot coordinates { (1,0.189151) (2,0.306189) (3,0.328834) (4,0.348653) (5,0.348329) (6,0.348596) (7,0.347965) (8,0.346764) };
    \addlegendentry{algo=rantala/multikey\_simd\_parallel4};
    \addplot coordinates { (1,0.155098) (2,0.253853) (3,0.288981) (4,0.311731) (5,0.27539) (6,0.279166) (7,0.275856) (8,0.264446) };
    \addlegendentry{algo=shamsundar/lcp-merge-string-sort};

    \legend{}
  \end{axis}
\end{tikzpicture}

\begin{tikzpicture}
  \begin{axis}[plotSpeedup8,
    title={Sinha NoDup, , },
    legend to name={speedup150},legend columns=1,
    ylabel={speedup},xlabel={number of threads},
    ]

\addplot coordinates { (1,0.844615) (2,1.55897) (3,2.12965) (4,2.6514) (5,2.95029) (6,3.16891) (7,3.43721) (8,3.59209) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCU2};
    \addplot coordinates { (1,0.793896) (2,1.47436) (3,2.0303) (4,2.53702) (5,2.862) (6,3.16512) (7,3.36691) (8,3.53341) };
    \addlegendentry{algo=bingmann/parallel\_sample\_sortBTCEU1};
    \addplot coordinates { (1,0.729788) (2,1.35798) (3,1.68608) (4,2.009) (5,2.09019) (6,2.1127) (7,2.16087) (8,2.16166) };
    \addlegendentry{algo=bingmann/parallel\_mkqs};
    \addplot coordinates { (1,0.826332) (2,1.49351) (3,1.8668) (4,2.17438) (5,2.2755) (6,2.39557) (7,2.4228) (8,2.45253) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_8bit};
    \addplot coordinates { (1,0.826251) (2,1.67226) (3,2.14625) (4,2.57548) (5,2.71856) (6,2.84203) (7,2.93172) (8,3.03053) };
    \addlegendentry{algo=bingmann/parallel\_radix\_sort\_16bit};
    \addplot coordinates { (1,0.840289) (2,1.45528) (3,1.82591) (4,2.12) (5,2.24231) (6,2.3399) (7,2.38012) (8,2.40097) };
    \addlegendentry{algo=akiba/parallel\_radix\_sort};
    \addplot coordinates { (1,0.287288) (2,0.471553) (3,0.445113) (4,0.526034) (5,0.529804) (6,0.571926) (7,0.582396) (8,0.593269) };
    \addlegendentry{algo=rantala/mergesort\_lcp\_2way\_parallel};
    \addplot coordinates { (1,0.199131) (2,0.332662) (3,0.373997) (4,0.403212) (5,0.406236) (6,0.408601) (7,0.407206) (8,0.405203) };
    \addlegendentry{algo=rantala/multikey\_simd\_parallel4};
    \addplot coordinates { (1,0.172706) (2,0.279831) (3,0.305399) (4,0.315349) (5,0.275015) (6,0.270678) (7,0.265499) (8,0.243802) };
    \addlegendentry{algo=shamsundar/lcp-merge-string-sort};

    \SpeedupLegend
  \end{axis}
\end{tikzpicture}
\hfill \parbox{53mm}{\hfill\ref{speedup150}\hfill\null}
\caption{Speedup of parallel algorithm implementations on IntelX5, median of fifteen runs}\label{fig:more-IntelX5}
\end{figure}
 


\begin{table}\centering\small
\caption{Absolute run time of parallel and best sequential algorithms on IntelE5 in seconds, median of 1--3 runs. See Table~\ref{tab:paraalgo} for a short description of each.}\label{tab:absrun-IntelE5}
\def\tabcolsep{3.6pt}
\begin{tabular}{l|*{10}{r}|@{}}
PEs & 1   & 2 & 4 & 8 & 12 & 16 & 24 & 32 & 48 & 64 \\ \hline
& \multicolumn{10}{l|}{\textbf{URLs} (complete), , , } \\ \cline{2-11}
mkqs\_cache8 & \bf 467 &  &  &  &  &  &  &  &  &  \\
pS-Unroll &    633 &     310 &     156 &     92.8 &     69.2 &     52.7 &     45.1 &     42.8 &     41.1 &     39.9 \\
 pS-Equal &    646 &     316 &     157 &     93.0 &     69.3 &     52.8 &     45.8 &     42.0 &     41.2 &     41.2 \\
 pS+LCP-M &        &         & \bf 116 & \bf 74.4 &     57.7 & \bf 47.0 & \bf 38.4 & \bf 34.4 & \bf 34.1 & \bf 35.1 \\
        pMKQS &    617 & \bf 292 &     146 &     84.2 & \bf 57.5 &     47.1 &     41.0 &     38.0 &     37.0 &     38.0 \\
     pRS-8bit & 1\,959 &     975 &     493 &      280 &      204 &      171 &      144 &      142 &      140 &      140 \\
    pRS-16bit & 1\,960 &     883 &     444 &      260 &      179 &      148 &      125 &      119 &      115 &      116 \\
    pRS/Akiba & 1\,293 &  1\,258 &  1\,255 &   1\,249 &   1\,256 &   1\,255 &   1\,249 &   1\,259 &   1\,255 &   1\,249 \\ \hline
& \multicolumn{10}{l|}{\textbf{Random}, , , } \\ \cline{2-11}
mkqs\_cache8 & \bf 609 &  &  &  &  &  &  &  &  &  \\
pS-Unroll & 1\,209 &     601 &     301 &     166 &      122 &      101 &     76.7 &     67.7 &     65.3 &     63.7 \\
 pS-Equal & 1\,322 &     657 &     326 &     178 &      131 &      107 &     81.4 &     70.7 &     67.6 &     64.2 \\
 pS+LCP-M &        &         &     367 &     196 &      135 &      108 &     80.0 &     71.0 &     72.7 &     71.7 \\
        pMKQS &    732 & \bf 379 & \bf 198 & \bf 108 & \bf 79.7 & \bf 69.1 & \bf 63.6 &     65.5 &     70.7 &     75.2 \\
     pRS-8bit & 1\,530 &     706 &     343 &     183 &      127 &      100 &     70.9 &     59.3 &     60.8 &     59.2 \\
    pRS-16bit & 1\,530 &     657 &     343 &     185 &      129 &      100 &     69.4 & \bf 56.2 & \bf 52.4 & \bf 53.6 \\
    pRS/Akiba & 1\,355 &     751 &     447 &     321 &      280 &      257 &      232 &      223 &      219 &      216 \\ \hline
& \multicolumn{10}{l|}{\textbf{GOV2}, , , } \\ \cline{2-11}
mkqs\_cache8 & \bf 1\,079 &  &  &  &  &  &  &  &  &  \\
pS-Unroll & 1\,399 &     673 &     326 &     212 &     176 &     145 &      113 &     97.1 &     92.1 &     89.0 \\
 pS-Equal & 1\,476 &     705 &     339 &     224 &     186 &     154 &      119 &      101 &     95.8 &     91.2 \\
 pS+LCP-M &        &         & \bf 272 & \bf 166 & \bf 131 & \bf 112 & \bf 93.3 & \bf 80.5 & \bf 80.7 & \bf 82.1 \\
        pMKQS & 1\,347 & \bf 661 &     350 &     207 &     164 &     127 &      101 &     91.8 &     93.7 &     95.1 \\
     pRS-8bit & 4\,244 &  1\,992 &     964 &     585 &     462 &     394 &      311 &      299 &      302 &      291 \\
    pRS-16bit & 4\,252 &  1\,912 &     928 &     571 &     471 &     384 &      306 &      279 &      280 &      257 \\
    pRS/Akiba & 2\,645 &  1\,306 &  1\,028 &  1\,055 &  1\,048 &  1\,034 &   1\,037 &   1\,045 &   1\,051 &   1\,052 \\ \hline
& \multicolumn{10}{l|}{\textbf{Wikipedia}, , } \\ \cline{2-11}
mkqs\_cache8 & \bf 2\,502 &  &  &  &  &  &  &  &  &  \\
pS-Unroll & 2\,728 &     1\,341 &     648 &     350 &     252 &     203 &     147 &     120 &      110 &      103 \\
 pS-Equal & 2\,986 &     1\,435 &     694 &     374 &     268 &     215 &     157 &     125 &      115 &      105 \\
 pS+LCP-M &        &            &     635 &     338 & \bf 235 & \bf 186 & \bf 130 & \bf 107 & \bf 97.6 & \bf 92.0 \\
        pMKQS & 2\,554 & \bf 1\,259 & \bf 620 & \bf 336 &     238 &     189 &     143 &     127 &      122 &      119 \\
     pRS-8bit & 4\,064 &     1\,879 &     909 &     486 &     349 &     271 &     192 &     157 &      150 &      144 \\
    pRS-16bit & 4\,068 &     1\,805 &     875 &     469 &     340 &     262 &     187 &     149 &      145 &      139 \\
    pRS/Akiba & 2\,862 &     1\,450 &     754 &     453 &     355 &     302 &     249 &     229 &      265 &      263 \\ \hline
& \multicolumn{10}{l|}{\textbf{Sinha NoDup} (complete), , , } \\ \cline{2-11}
radixR\_CE7 & \bf 6.00 &  &  &  &  &  &  &  &  &  \\
pS-Unroll & 8.27 &     4.17 &     2.13 &      1.22 &     0.921 &     0.790 &     0.695 &     0.642 &     0.592 &     0.544 \\
 pS-Equal & 8.84 &     4.46 &     2.26 &      1.28 &     0.963 &     0.825 &     0.710 &     0.661 &     0.601 &     0.567 \\
 pS+LCP-M &      &          &     2.52 &      1.41 &      1.01 &     0.815 &     0.653 &     0.604 &     0.691 &     0.779 \\
        pMKQS & 8.44 &     4.30 &     2.21 &      1.25 &     0.920 &     0.801 &     0.744 &     0.798 &     0.973 &      1.11 \\
     pRS-8bit & 8.35 &     4.06 &     2.01 &      1.08 &     0.770 &     0.643 &     0.489 &     0.425 & \bf 0.422 & \bf 0.441 \\
    pRS-16bit & 8.35 & \bf 3.49 & \bf 1.74 & \bf 0.949 & \bf 0.682 & \bf 0.595 & \bf 0.445 & \bf 0.422 &     0.467 &     0.502 \\
    pRS/Akiba & 7.58 &     4.09 &     2.38 &      1.59 &      1.33 &      1.21 &      1.09 &      1.04 &      1.04 &      1.02 \\ \hline
\end{tabular}
\end{table}



\begin{table}\centering\small
\caption{Absolute run time of parallel and best sequential algorithms on AMD48 in seconds, median of 1--3 runs. See Table~\ref{tab:paraalgo} for a short description of each.}\label{tab:absrun-AMD48}
\def\tabcolsep{2.8pt}
\begin{tabular}{l|*{11}{r}|@{}}
PEs & 1   & 2 & 3 & 6 & 9 & 12 & 18 & 24 & 36 & 42 & 48 \\ \hline
& \multicolumn{11}{l|}{\textbf{URLs} (complete), , , } \\ \cline{2-12}
mkqs\_cache8 & \bf 773 &  &  &  &  &  &  &  &  &  &  \\
pS-Unroll & 1\,030 &     521 &     352 &     181 &     127 &     99.9 &     74.9 &     64.0 &     53.0 &     48.0 &     46.8 \\
 pS-Equal &    931 &     477 &     331 &     176 &     123 &     97.1 &     73.3 &     65.0 &     55.0 &     48.8 &     47.6 \\
 pS+LCP-M &        &         &         &         &     122 &      114 &     76.3 &     60.3 &     50.0 &     49.6 &     46.8 \\
        pMKQS &    844 & \bf 415 & \bf 280 & \bf 146 & \bf 102 & \bf 80.4 & \bf 59.6 & \bf 49.9 & \bf 44.2 & \bf 44.0 & \bf 45.1 \\
     pRS-8bit & 2\,552 &  1\,306 &     897 &     468 &     325 &      266 &      202 &      177 &      157 &      156 &      155 \\
    pRS-16bit & 2\,550 &  1\,210 &     823 &     428 &     299 &      234 &      183 &      151 &      126 &      125 &      126 \\
    pRS/Akiba & 1\,861 &  1\,840 &  1\,832 &  1\,830 &  1\,821 &   1\,819 &   1\,823 &   1\,822 &   1\,822 &   1\,827 &   1\,821 \\ \hline
& \multicolumn{11}{l|}{\textbf{Random}, , , } \\ \cline{2-12}
mkqs\_cache8 & \bf 879 &  &  &  &  &  &  &  &  &  &  \\
pS-Unroll & 1\,315 &     683 &     466 &     248 &     176 &      140 &      104 &     86.3 &     69.3 &     64.4 &     61.7 \\
 pS-Equal & 1\,225 &     634 &     433 &     232 &     165 &      131 &     98.3 &     82.1 &     67.1 &     62.1 &     59.7 \\
 pS+LCP-M &        &         &         &         &     196 &      185 &      109 &     82.7 &     71.5 &     66.0 &     61.9 \\
        pMKQS &    751 & \bf 392 & \bf 264 & \bf 143 & \bf 106 & \bf 81.0 & \bf 65.3 & \bf 56.0 &     54.7 &     55.8 &     61.3 \\
     pRS-8bit & 1\,182 &     594 &     404 &     209 &     144 &      111 &     79.6 &     63.5 &     52.2 &     49.9 &     47.1 \\
    pRS-16bit & 1\,188 &     615 &     423 &     224 &     154 &      120 &     85.1 &     68.0 & \bf 51.3 & \bf 47.4 & \bf 44.8 \\
    pRS/Akiba & 1\,525 &     861 &     643 &     421 &     348 &      312 &      277 &      259 &      241 &      238 &      234 \\ \hline
& \multicolumn{11}{l|}{\textbf{GOV2}, , , } \\ \cline{2-12}
mkqs\_cache8 & \bf 750 &  &  &  &  &  &  &  &  &  &  \\
pS-Unroll &    881 &     449 &     305 &     162 &     129 &      110 &     83.2 &     69.9 &     58.4 &     54.4 &     50.2 \\
 pS-Equal &    854 &     436 &     296 &     156 &     123 &      104 &     79.2 &     67.1 &     55.8 &     52.5 &     48.7 \\
 pS+LCP-M &        &         &         &         & \bf 100 &     98.2 &     62.0 & \bf 48.7 & \bf 42.9 & \bf 39.5 & \bf 37.4 \\
        pMKQS &    785 & \bf 397 & \bf 268 & \bf 140 &     101 & \bf 83.8 & \bf 60.1 &     50.7 &     44.1 &     42.8 &     42.6 \\
     pRS-8bit & 2\,071 &  1\,015 &     676 &     351 &     280 &      251 &      182 &      154 &      125 &      120 &      114 \\
    pRS-16bit & 2\,061 &     980 &     652 &     338 &     269 &      242 &      171 &      143 &      111 &      107 &      102 \\
    pRS/Akiba & 1\,547 &     794 &     617 &     594 &     584 &      582 &      581 &      581 &      584 &      585 &      585 \\ \hline
& \multicolumn{11}{l|}{\textbf{Wikipedia}, , } \\ \cline{2-12}
mkqs\_cache8 & \bf 1\,442 &  &  &  &  &  &  &  &  &  &  \\
pS-Unroll & 1\,634 &     838 &     569 &     299 &     208 &     164 &     119 &     96.9 &     74.6 &     68.7 &     65.3 \\
 pS-Equal & 1\,592 &     827 &     561 &     293 &     205 &     161 &     117 &     95.4 &     73.6 &     68.1 &     64.3 \\
 pS+LCP-M &        &         &         &         &     267 &     255 &     142 &      104 &     83.4 &     72.8 &     65.9 \\
        pMKQS & 1\,556 & \bf 790 & \bf 534 & \bf 273 & \bf 188 & \bf 145 & \bf 102 & \bf 84.3 & \bf 67.0 & \bf 64.1 & \bf 64.0 \\
     pRS-8bit & 2\,547 &  1\,216 &     825 &     417 &     281 &     215 &     148 &      115 &     85.2 &     78.1 &     72.6 \\
    pRS-16bit & 2\,547 &  1\,168 &     795 &     405 &     276 &     211 &     147 &      114 &     82.6 &     74.2 &     69.2 \\
    pRS/Akiba & 1\,966 &  1\,030 &     717 &     403 &     299 &     249 &     198 &      197 &      196 &      196 &      198 \\ \hline
& \multicolumn{11}{l|}{\textbf{Sinha NoDup} (complete), , , } \\ \cline{2-12}
radixR\_CE7 & \bf 8.24 &  &  &  &  &  &  &  &  &  &  \\
pS-Unroll & 12.8 &     6.73 &     4.63 &     2.52 &     1.82 &      1.47 &      1.13 &     0.978 &     0.836 &     0.804 &     0.794 \\
 pS-Equal & 12.0 &     6.30 &     4.34 &     2.37 &     1.72 &      1.39 &      1.08 &     0.944 &     0.812 &     0.779 &     0.772 \\
 pS+LCP-M &      &          &          &          &     1.89 &      1.76 &      1.39 &      1.10 &      1.01 &     0.993 &     0.984 \\
        pMKQS & 11.2 &     5.81 &     4.02 &     2.14 &     1.53 &      1.28 &      1.00 &     0.935 &     0.989 &      1.04 &      1.16 \\
     pRS-8bit & 10.8 &     5.33 &     3.61 &     1.87 &     1.35 &      1.01 & \bf 0.771 & \bf 0.596 & \bf 0.482 & \bf 0.462 & \bf 0.453 \\
    pRS-16bit & 10.8 & \bf 4.82 & \bf 3.27 & \bf 1.72 & \bf 1.32 & \bf 0.988 &     0.872 &     0.779 &     0.924 &      1.01 &      1.10 \\
    pRS/Akiba & 11.5 &     6.33 &     4.62 &     2.90 &     2.33 &      2.05 &      1.80 &      1.68 &      1.57 &      1.54 &      1.53 \\ \hline
\end{tabular}
\end{table}



\begin{table}\centering\small
\caption{Absolute run time of parallel and best sequential algorithms on AMD16 in seconds, median of 1--3 runs. See Table~\ref{tab:paraalgo} for a short description of each.}\label{tab:absrun-AMD16}
\begin{tabularx}{\linewidth}{l|*{7}{>{\hfill}X}|@{}}
PEs & 1   & 2 & 4 & 6 & 8 & 12 & 16 \\ \hline
& \multicolumn{7}{l|}{\textbf{URLs}, , , } \\ \cline{2-8}
mkqs\_cache8 & \bf 422 &  &  &  &  &  &  \\
pS-Unroll &    424 & \bf 218 & \bf 115 & \bf 83.0 & \bf 70.5 & \bf 56.2 & \bf 49.1 \\
 pS-Equal &    455 &     233 &     123 &     91.4 &     75.1 &     61.6 &     51.6 \\
 pS+LCP-M &        &         &     152 &      152 &     91.9 &     73.2 &     58.7 \\
        pMKQS &    456 &     220 &     117 &     88.3 &     74.4 &     63.7 &     61.5 \\
     pRS-8bit & 1\,256 &     652 &     362 &      284 &      253 &      238 &      220 \\
    pRS-16bit & 1\,253 &     601 &     331 &      255 &      225 &      212 &      185 \\
    pRS/Akiba & 1\,063 &  1\,060 &  1\,049 &   1\,057 &   1\,110 &   1\,048 &   1\,105 \\ \hline
& \multicolumn{7}{l|}{\textbf{Random}, , , } \\ \cline{2-8}
mkqs\_cache8 & \bf 350 &  &  &  &  &  &  \\
pS-Unroll & 675 &     349 &     182 &      128 &      100 &     74.6 &     61.6 \\
 pS-Equal & 621 &     321 &     167 &      119 &     93.2 &     70.0 &     58.2 \\
 pS+LCP-M &     &         &     207 &      194 &      112 &     80.3 &     64.4 \\
        pMKQS & 384 & \bf 203 & \bf 112 & \bf 84.6 & \bf 79.6 &     69.4 &     62.4 \\
     pRS-8bit & 605 &     302 &     161 &      109 &     89.8 & \bf 67.6 & \bf 55.7 \\
    pRS-16bit & 605 &     297 &     167 &      110 &     95.5 &     71.6 &     59.1 \\
    pRS/Akiba & 805 &     459 &     283 &      227 &      198 &      171 &      157 \\ \hline
& \multicolumn{7}{l|}{\textbf{GOV2}, , , } \\ \cline{2-8}
mkqs\_cache8 & \bf 291 &  &  &  &  &  &  \\
pS-Unroll & 336 &     171 &     88.3 &     62.6 &     55.5 &     44.9 &     36.5 \\
 pS-Equal & 326 &     166 &     86.0 &     61.0 &     53.5 &     43.2 &     35.3 \\
 pS+LCP-M &     &         &     81.4 &     78.2 & \bf 46.5 & \bf 34.4 & \bf 28.0 \\
        pMKQS & 296 & \bf 152 & \bf 79.4 & \bf 60.6 &     46.9 &     39.4 &     37.2 \\
     pRS-8bit & 692 &     338 &      176 &      132 &      112 &      105 &     92.1 \\
    pRS-16bit & 691 &     327 &      170 &      126 &      115 &     92.9 &     81.7 \\
    pRS/Akiba & 552 &     285 &      226 &      225 &      225 &      226 &      227 \\ \hline
& \multicolumn{7}{l|}{\textbf{Wikipedia}, , } \\ \cline{2-8}
mkqs\_cache8 & \bf 642 &  &  &  &  &  &  \\
pS-Unroll & 840 &     424 &     214 &     147 &     112 &     78.9 &     62.0 \\
 pS-Equal & 819 &     414 &     209 &     144 &     110 &     77.1 &     60.6 \\
 pS+LCP-M &     &         &     195 &     175 &     104 & \bf 73.6 & \bf 57.7 \\
        pMKQS & 693 & \bf 351 & \bf 183 & \bf 130 & \bf 104 &     80.9 &     71.8 \\
     pRS-8bit & 920 &     425 &     216 &     153 &     118 &     90.1 &     75.1 \\
    pRS-16bit & 917 &     408 &     207 &     149 &     114 &     87.3 &     71.4 \\
    pRS/Akiba & 782 &     419 &     238 &     181 &     154 &      128 &      116 \\ \hline
& \multicolumn{7}{l|}{\textbf{Sinha NoDup} (complete), , , } \\ \cline{2-8}
radixR\_CE7 & \bf 9.50 &  &  &  &  &  &  \\
pS-Unroll & 11.9 &     6.13 &     3.15 &     2.14 &     1.65 &     1.19 &     0.963 \\
 pS-Equal & 11.0 &     5.65 &     2.90 &     1.99 & \bf 1.52 & \bf 1.11 & \bf 0.912 \\
 pS+LCP-M &      &          &     4.22 &     3.65 &     2.30 &     1.64 &      1.32 \\
        pMKQS & 11.9 &     6.11 &     3.23 &     2.34 &     1.92 &     1.56 &      1.46 \\
     pRS-8bit & 12.1 &     5.97 &     3.09 &     2.20 &     1.74 &     1.37 &      1.25 \\
    pRS-16bit & 12.1 & \bf 5.44 & \bf 2.82 & \bf 1.98 &     1.56 &     1.20 &      1.12 \\
    pRS/Akiba & 13.0 &     7.19 &     4.28 &     3.33 &     2.86 &     2.44 &      2.24 \\ \hline
\end{tabularx}
\end{table}



\begin{table}\centering\small
\caption{Absolute run time of parallel and best sequential algorithms on Inteli7 in seconds, median of fifteen runs, larger test instances. See Table~\ref{tab:paraalgo} for a short description of each.}\label{tab:absrun-Inteli7}
\begin{tabularx}{\linewidth}{l|*{8}{>{\hfill}X}|@{}}
PEs & 1   & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\ \hline
& \multicolumn{8}{l|}{\textbf{URLs}, , , } \\ \cline{2-9}
mkqs\_cache8 & 14.8 &  &  &  &  &  &  &  \\
pS-Unroll &     14.9 &     8.46 &     5.87 & \bf 4.83 &     4.81 &     4.52 &     4.41 &     4.24 \\
 pS-Equal & \bf 14.5 & \bf 8.27 & \bf 5.80 &     4.86 & \bf 4.61 & \bf 4.39 & \bf 4.29 & \bf 4.17 \\
        pMKQS &     15.6 &     8.78 &     6.57 &     5.59 &     5.42 &     5.31 &     5.21 &     5.15 \\
     pRS-8bit &     39.8 &     22.0 &     16.8 &     14.5 &     14.3 &     13.9 &     13.6 &     13.5 \\
    pRS-16bit &     39.8 &     20.0 &     14.9 &     12.7 &     12.4 &     12.1 &     11.9 &     11.7 \\
    pRS/Akiba &     32.0 &     31.7 &     31.7 &     31.7 &     31.7 &     31.7 &     31.7 &     31.7 \\
     p2w-MS/R &     30.1 &     17.3 &     17.3 &     12.7 &     12.4 &     10.5 &     9.96 &     9.83 \\
 pMKQS-SIMD/R &     31.4 &     19.4 &     15.4 &     13.6 &     13.4 &     13.3 &     13.3 &     13.3 \\
 pLCP-2w-MS/S &     29.7 &     18.9 &     14.7 &     13.2 &     13.0 &     13.2 &     12.9 &     13.0 \\ \hline
& \multicolumn{8}{l|}{\textbf{Random}, , , } \\ \cline{2-9}
radixR\_CE7 & \bf 19.6 &  &  &  &  &  &  &  \\
pS-Unroll & 32.2 &     17.5 &     12.1 &     9.39 &     9.51 &     9.07 &     8.29 &     7.67 \\
 pS-Equal & 34.2 &     18.6 &     12.8 &     9.93 &     9.76 &     9.27 &     8.46 &     7.83 \\
        pMKQS & 31.2 &     16.9 &     11.9 &     9.42 &     8.64 &     8.07 &     7.75 &     7.50 \\
     pRS-8bit & 23.6 &     12.9 &     9.24 & \bf 7.89 & \bf 7.55 & \bf 7.22 & \bf 7.00 & \bf 6.86 \\
    pRS-16bit & 23.6 & \bf 12.5 & \bf 9.04 &     8.35 &     7.76 &     7.65 &     7.16 &     7.34 \\
    pRS/Akiba & 24.0 &     16.1 &     13.3 &     12.0 &     11.7 &     11.4 &     11.2 &     11.0 \\
     p2w-MS/R & 95.9 &     58.1 &     58.1 &     52.4 &     46.9 &     43.5 &     40.2 &     40.2 \\
 pMKQS-SIMD/R &  123 &     72.9 &     55.3 &     47.2 &     46.8 &     46.6 &     46.5 &     46.2 \\
 pLCP-2w-MS/S &  185 &      119 &      101 &     97.9 &      105 &      110 &      115 &      121 \\ \hline
& \multicolumn{8}{l|}{\textbf{GOV2}, , , } \\ \cline{2-9}
mkqs\_cache8 & 14.6 &  &  &  &  &  &  &  \\
pS-Unroll & \bf 13.1 & \bf 7.15 & \bf 5.00 & \bf 3.95 &     3.99 &     3.93 &     3.73 &     3.51 \\
 pS-Equal &     13.5 &     7.39 &     5.16 &     4.06 & \bf 3.94 & \bf 3.87 & \bf 3.69 & \bf 3.49 \\
        pMKQS &     15.5 &     8.62 &     6.22 &     5.08 &     4.82 &     4.58 &     4.43 &     4.30 \\
     pRS-8bit &     33.5 &     17.8 &     12.9 &     10.2 &     9.85 &     9.52 &     9.43 &     9.69 \\
    pRS-16bit &     33.4 &     17.1 &     12.2 &     9.62 &     9.20 &     8.73 &     8.40 &     8.20 \\
    pRS/Akiba &     27.4 &     15.2 &     13.4 &     13.3 &     13.3 &     14.2 &     14.4 &     14.4 \\
     p2w-MS/R &     32.6 &     19.3 &     19.3 &     16.8 &     15.8 &     12.8 &     12.6 &     12.4 \\
 pMKQS-SIMD/R &     32.5 &     19.5 &     14.9 &     12.8 &     12.6 &     12.5 &     12.4 &     12.4 \\
 pLCP-2w-MS/S &     43.9 &     22.9 &     15.8 &     12.5 &     12.8 &     11.5 &     10.5 &     9.94 \\ \hline
& \multicolumn{8}{l|}{\textbf{Wikipedia}, , } \\ \cline{2-9}
radixR\_CE7 & \bf 59.6 &  &  &  &  &  &  &  \\
pS-Unroll & 59.9 & \bf 32.8 & \bf 22.6 & \bf 17.5 & \bf 17.1 & \bf 16.1 & \bf 14.7 & \bf 13.6 \\
 pS-Equal & 63.3 &     34.6 &     23.8 &     18.4 &     17.5 &     16.3 &     15.0 &     13.9 \\
        pMKQS & 69.3 &     37.5 &     26.1 &     20.4 &     18.6 &     17.3 &     16.2 &     15.5 \\
     pRS-8bit & 74.5 &     37.9 &     26.2 &     19.9 &     18.6 &     17.2 &     16.1 &     15.1 \\
    pRS-16bit & 74.5 &     36.2 &     25.2 &     19.0 &     17.9 &     16.5 &     15.4 &     14.5 \\
    pRS/Akiba & 62.4 &     34.8 &     24.9 &     20.0 &     18.6 &     17.5 &     16.6 &     15.7 \\
     p2w-MS/R &  123 &     72.2 &     72.7 &     64.8 &     58.6 &     51.6 &     48.0 &     47.7 \\
 pMKQS-SIMD/R &  127 &     74.4 &     55.5 &     46.8 &     45.7 &     44.7 &     44.2 &     43.5 \\
 pLCP-2w-MS/S &  221 &      115 &     79.2 &     62.1 &     60.6 &     54.4 &     51.5 &     48.4 \\ \hline
\end{tabularx}
\end{table}

\def\tabcolsep{4pt}
\begin{table}\centering\small
\caption{Absolute run time of parallel and best sequential algorithms on Inteli7 in seconds, median of fifteen runs, smaller test instances. See Table~\ref{tab:paraalgo} for a short description of each.}\label{tab:absrun-Inteli7b}
\begin{tabularx}{\linewidth}{l|*{8}{>{\hfill}X}|@{}}
PEs          & 1   & 2 & 3 & 4 & 5 & 6 & 7 & 8                                                                                      \\ \hline
& \multicolumn{8}{l|}{\textbf{Sinha URLs} (complete), , , } \\ \cline{2-9}
mkqs\_cache8 & 1.81 &  &  &  &  &  &  &  \\
pS-Unroll & \bf 1.54 & \bf 0.853 & \bf 0.595 & \bf 0.471 & \bf 0.495 & \bf 0.464 & \bf 0.445 & \bf 0.431 \\
 pS-Equal &     1.67 &     0.924 &     0.641 &     0.505 &     0.505 &     0.475 &     0.452 &     0.436 \\
        pMKQS &     1.93 &      1.07 &     0.766 &     0.618 &     0.593 &     0.571 &     0.552 &     0.544 \\
     pRS-8bit &     5.05 &      2.48 &      1.74 &      1.37 &      1.32 &      1.28 &      1.23 &      1.20 \\
    pRS-16bit &     5.06 &      2.23 &      1.56 &      1.21 &      1.19 &      1.14 &      1.11 &      1.08 \\
    pRS/Akiba &     4.02 &      3.44 &      3.23 &      3.13 &      3.12 &      3.10 &      3.10 &      3.08 \\
     p2w-MS/R &     3.98 &      2.35 &      2.34 &      2.05 &      1.86 &      1.64 &      1.51 &      1.53 \\
 pMKQS-SIMD/R &     3.93 &      2.37 &      1.83 &      1.59 &      1.60 &      1.59 &      1.61 &      1.61 \\
 pLCP-2w-MS/S &     5.93 &      3.57 &      2.89 &      2.65 &      2.83 &      2.81 &      2.86 &      2.93 \\ \hline
& \multicolumn{8}{l|}{\textbf{Sinha DNA} (complete), , , } \\ \cline{2-9}
radixR\_CE6 & 3.69 &  &  &  &  &  &  &  \\
pS-Unroll & \bf 2.94 & \bf 1.63 & \bf 1.14 & \bf 0.906 & \bf 0.989 & \bf 0.900 & \bf 0.883 & \bf 0.831 \\
 pS-Equal &     3.37 &     1.85 &     1.29 &      1.02 &      1.04 &     0.944 &     0.920 &     0.864 \\
        pMKQS &     4.28 &     2.37 &     1.72 &      1.40 &      1.32 &      1.25 &      1.22 &      1.21 \\
     pRS-8bit &     5.47 &     2.99 &     2.14 &      1.68 &      1.63 &      1.58 &      1.54 &      1.51 \\
    pRS-16bit &     5.47 &     2.78 &     1.94 &      1.57 &      1.54 &      1.50 &      1.47 &      1.42 \\
    pRS/Akiba &     3.83 &     2.29 &     1.74 &      1.50 &      1.51 &      1.54 &      1.50 &      1.43 \\
     p2w-MS/R &     11.1 &     6.36 &     6.36 &      5.13 &      5.10 &      4.17 &      3.98 &      3.97 \\
 pMKQS-SIMD/R &     10.5 &     6.50 &     5.10 &      4.51 &      4.51 &      4.53 &      4.55 &      4.56 \\
 pLCP-2w-MS/S &     18.5 &     11.1 &     8.79 &      7.91 &      8.39 &      8.18 &      8.29 &      8.40 \\ \hline
& \multicolumn{8}{l|}{\textbf{Sinha NoDup} (complete), , , } \\ \cline{2-9}
radixR\_CE7 & \bf 3.83 &  &  &  &  &  &  &  \\
pS-Unroll & 4.54 & \bf 2.47 & \bf 1.69 & \bf 1.31 &     1.33 &     1.21 &     1.15 &     1.07 \\
 pS-Equal & 4.96 &     2.68 &     1.83 &     1.42 &     1.38 &     1.29 &     1.18 &     1.10 \\
        pMKQS & 5.47 &     2.98 &     2.11 &     1.67 &     1.52 &     1.42 &     1.34 &     1.29 \\
     pRS-8bit & 5.22 &     2.71 &     1.87 &     1.47 &     1.40 &     1.31 &     1.25 &     1.20 \\
    pRS-16bit & 5.22 &     2.48 &     1.70 &     1.32 & \bf 1.28 & \bf 1.19 & \bf 1.12 & \bf 1.07 \\
    pRS/Akiba & 4.97 &     2.84 &     2.06 &     1.68 &     1.59 &     1.50 &     1.43 &     1.37 \\
     p2w-MS/R & 12.7 &     7.46 &     7.45 &     6.22 &     5.96 &     4.89 &     4.88 &     4.89 \\
 pMKQS-SIMD/R & 13.6 &     8.08 &     6.10 &     5.23 &     5.15 &     5.09 &     5.05 &     5.02 \\
 pLCP-2w-MS/S & 19.8 &     12.2 &     10.0 &     9.39 &     9.43 &     10.1 &     10.4 &     10.7 \\ \hline
\end{tabularx}
\end{table}



\begin{table}\centering\small
\caption{Absolute run time of parallel and best sequential algorithms on IntelX5 in seconds, median of fifteen runs, larger test instances. See Table~\ref{tab:paraalgo} for a short description of each.}\label{tab:absrun-IntelX5}
\begin{tabularx}{\linewidth}{l|*{8}{>{\hfill}X}|@{}}
PEs          & 1   & 2 & 3 & 4 & 5 & 6 & 7 & 8                                                                                      \\ \hline
& \multicolumn{8}{l|}{\textbf{URLs}, , , } \\ \cline{2-9}
mkqs\_cache8 & 64.2 &  &  &  &  &  &  &  \\
pS-Unroll & \bf 56.2 & \bf 30.8 & \bf 24.4 & \bf 20.7 & \bf 20.2 & \bf 19.2 & \bf 19.0 & \bf 19.0 \\
 pS-Equal &     58.6 &     32.1 &     25.3 &     21.2 &     20.5 &     19.7 &     19.4 &     19.3 \\
        pMKQS &     67.1 &     36.0 &     29.8 &     26.5 &     26.2 &     26.0 &     26.0 &     25.9 \\
     pRS-8bit &      150 &     89.5 &     79.6 &     72.9 &     72.8 &     71.7 &     72.6 &     71.6 \\
    pRS-16bit &      150 &     78.5 &     68.3 &     62.7 &     61.9 &     61.8 &     62.4 &     59.7 \\
    pRS/Akiba &      121 &      119 &      120 &      119 &      120 &      119 &      120 &      119 \\
     p2w-MS/R &     85.9 &     49.3 &     52.5 &     42.1 &     40.1 &     35.0 &     35.1 &     34.9 \\
 pMKQS-SIMD/R &      153 &     92.0 &     83.9 &     77.9 &     77.5 &     77.2 &     77.4 &     77.5 \\
 pLCP-2w-MS/S &      108 &     63.3 &     52.5 &     49.9 &     57.8 &     55.8 &     54.4 &     57.7 \\ \hline
& \multicolumn{8}{l|}{\textbf{Random}, , , } \\ \cline{2-9}
mkqs\_cache8 & \bf 58.9 &  &  &  &  &  &  &  \\
pS-Unroll & 78.5 &     42.2 &     31.0 &     25.0 & \bf 22.9 & \bf 20.9 & \bf 19.7 & \bf 18.9 \\
 pS-Equal & 82.1 &     44.0 &     32.1 &     25.9 &     23.6 &     21.1 &     20.0 &     19.2 \\
        pMKQS & 65.8 & \bf 35.5 & \bf 28.4 & \bf 24.4 &     23.7 &     23.5 &     23.4 &     23.5 \\
     pRS-8bit & 77.5 &     44.1 &     35.4 &     30.4 &     28.4 &     26.9 &     26.0 &     25.5 \\
    pRS-16bit & 77.5 &     43.3 &     35.0 &     27.9 &     27.0 &     25.5 &     24.3 &     23.8 \\
    pRS/Akiba & 81.7 &     50.6 &     41.9 &     37.2 &     34.9 &     33.3 &     32.6 &     31.9 \\
     p2w-MS/R &  303 &      186 &      200 &      172 &      168 &      156 &      154 &      155 \\
 pMKQS-SIMD/R &  467 &      277 &      246 &      229 &      225 &      222 &      220 &      219 \\
 pLCP-2w-MS/S &  625 &      388 &      390 &      377 &      386 &      412 &      472 &      507 \\ \hline
& \multicolumn{8}{l|}{\textbf{GOV2}, , , } \\ \cline{2-9}
mkqs\_cache8 & 55.3 &  &  &  &  &  &  &  \\
pS-Unroll & \bf 47.8 & \bf 25.8 & \bf 19.5 & \bf 16.2 & \bf 15.4 & \bf 14.5 & \bf 14.8 & \bf 14.6 \\
 pS-Equal &     49.1 &     26.4 &     19.9 &     16.4 &     15.5 &     14.6 &     15.0 &     14.8 \\
        pMKQS &     58.7 &     32.2 &     26.0 &     22.6 &     22.0 &     22.0 &     22.1 &     22.2 \\
     pRS-8bit &      115 &     61.7 &     49.8 &     43.8 &     44.9 &     45.2 &     44.2 &     44.0 \\
    pRS-16bit &      115 &     59.5 &     47.0 &     40.0 &     37.7 &     40.4 &     38.8 &     38.8 \\
    pRS/Akiba &     94.2 &     51.6 &     49.3 &     48.3 &     49.2 &     50.6 &     52.6 &     53.0 \\
     p2w-MS/R &      124 &     74.7 &     81.7 &     69.0 &     66.2 &     62.0 &     62.1 &     62.7 \\
 pMKQS-SIMD/R &      165 &     98.4 &     87.8 &     81.1 &     79.6 &     79.2 &     78.6 &     79.3 \\
 pLCP-2w-MS/S &      185 &     93.9 &     90.1 &     71.2 &     67.0 &     62.4 &     66.0 &     65.3 \\ \hline
& \multicolumn{8}{l|}{\textbf{Wikipedia}, , } \\ \cline{2-9}
radixR\_CE7 & \bf 185 &  &  &  &  &  &  &  \\
pS-Unroll & 194 & \bf 104 & \bf 76.2 & \bf 62.0 & \bf 56.8 & \bf 52.5 & \bf 50.8 & \bf 49.4 \\
 pS-Equal & 202 &     107 &     78.7 &     63.8 &     58.2 &     53.6 &     51.7 &     50.3 \\
        pMKQS & 211 &     112 &     87.5 &     74.2 &     71.3 &     69.4 &     68.9 &     68.9 \\
     pRS-8bit & 212 &     111 &     85.4 &     71.0 &     67.0 &     63.8 &     62.6 &     61.7 \\
    pRS-16bit & 212 &     109 &     84.2 &     68.5 &     64.8 &     62.1 &     59.8 &     58.2 \\
    pRS/Akiba & 192 &     107 &     83.4 &     70.6 &     66.5 &     64.3 &     62.9 &     62.5 \\
     p2w-MS/R & 420 &     261 &      281 &      237 &      231 &      230 &      230 &      230 \\
 pMKQS-SIMD/R & 583 &     343 &      301 &      277 &      274 &      273 &      273 &      274 \\
 pLCP-2w-MS/S & 882 &     443 &      345 &      277 &      292 &      282 &      252 &      264 \\ \hline
\end{tabularx}
\end{table}

\begin{table}\centering\small
\caption{Absolute run time of parallel and best sequential algorithms on IntelX5 in seconds, median of fifteen runs, smaller test instances. See Table~\ref{tab:paraalgo} for a short description of each.}\label{tab:absrun-IntelX5b}
\begin{tabularx}{\linewidth}{l|*{8}{>{\hfill}X}|@{}}
PEs          & 1   & 2 & 3 & 4 & 5 & 6 & 7 & 8                                                                                      \\ \hline
& \multicolumn{8}{l|}{\textbf{Sinha URLs} (complete), , , } \\ \cline{2-9}
mkqs\_cache8 & 3.35 &  &  &  &  &  &  &  \\
pS-Unroll & \bf 2.91 & \bf 1.60 & \bf 1.22 & \bf 1.03 & \bf 0.985 & \bf 0.939 &     0.932 &     0.929 \\
 pS-Equal &     3.03 &     1.65 &     1.26 &     1.05 &     0.986 &     0.940 & \bf 0.931 & \bf 0.929 \\
        pMKQS &     3.57 &     1.95 &     1.57 &     1.35 &      1.33 &      1.31 &      1.32 &      1.34 \\
     pRS-8bit &     5.85 &     3.22 &     2.63 &     2.30 &      2.22 &      2.18 &      2.16 &      2.14 \\
    pRS-16bit &     5.86 &     2.86 &     2.32 &     1.99 &      1.93 &      1.90 &      1.87 &      1.86 \\
    pRS/Akiba &     5.12 &     4.38 &     4.22 &     4.10 &      4.09 &      4.10 &      4.09 &      4.08 \\
     p2w-MS/R &     6.40 &     4.02 &     4.31 &     3.67 &      3.55 &      3.45 &      3.55 &      3.49 \\
 pMKQS-SIMD/R &     9.56 &     5.87 &     5.47 &     5.15 &      5.15 &      5.14 &      5.20 &      5.20 \\
 pLCP-2w-MS/S &     10.2 &     6.10 &     5.44 &     5.12 &      5.89 &      5.84 &      5.98 &      6.27 \\ \hline
& \multicolumn{8}{l|}{\textbf{Sinha DNA} (complete), , , } \\ \cline{2-9}
radixR\_CE7 & 6.11 &  &  &  &  &  &  &  \\
pS-Unroll & \bf 5.14 & \bf 2.87 & \bf 2.21 & \bf 1.85 & \bf 1.73 & \bf 1.59 & \bf 1.55 & \bf 1.50 \\
 pS-Equal &     5.63 &     3.11 &     2.36 &     1.96 &     1.82 &     1.66 &     1.60 &     1.54 \\
        pMKQS &     7.14 &     3.97 &     3.39 &     2.98 &     2.95 &     2.96 &     2.96 &     2.98 \\
     pRS-8bit &     7.45 &     4.36 &     3.85 &     3.37 &     3.36 &     3.33 &     3.33 &     3.36 \\
    pRS-16bit &     7.45 &     4.05 &     3.46 &     3.10 &     3.09 &     3.07 &     3.08 &     3.07 \\
    pRS/Akiba &     6.00 &     3.72 &     3.44 &     3.12 &     3.13 &     3.11 &     3.12 &     3.06 \\
     p2w-MS/R &     18.1 &     10.6 &     11.3 &     8.96 &     8.91 &     7.92 &     7.98 &     7.92 \\
 pMKQS-SIMD/R &     27.1 &     16.8 &     15.6 &     14.7 &     14.7 &     14.7 &     14.8 &     14.8 \\
 pLCP-2w-MS/S &     33.1 &     20.2 &     17.8 &     16.5 &     18.6 &     18.4 &     18.6 &     19.4 \\ \hline
& \multicolumn{8}{l|}{\textbf{Sinha NoDup} (complete), , , } \\ \cline{2-9}
radixR\_CE7 & \bf 5.96 &  &  &  &  &  &  &  \\
pS-Unroll & 7.06 &     3.83 &     2.80 & \bf 2.25 & \bf 2.02 & \bf 1.88 & \bf 1.74 & \bf 1.66 \\
 pS-Equal & 7.51 &     4.05 &     2.94 &     2.35 &     2.08 &     1.88 &     1.77 &     1.69 \\
        pMKQS & 8.17 &     4.39 &     3.54 &     2.97 &     2.85 &     2.82 &     2.76 &     2.76 \\
     pRS-8bit & 7.22 &     3.99 &     3.20 &     2.74 &     2.62 &     2.49 &     2.46 &     2.43 \\
    pRS-16bit & 7.22 & \bf 3.57 & \bf 2.78 &     2.32 &     2.19 &     2.10 &     2.03 &     1.97 \\
    pRS/Akiba & 7.10 &     4.10 &     3.27 &     2.81 &     2.66 &     2.55 &     2.51 &     2.48 \\
     p2w-MS/R & 20.8 &     12.6 &     13.4 &     11.3 &     11.3 &     10.4 &     10.2 &     10.1 \\
 pMKQS-SIMD/R & 30.0 &     17.9 &     15.9 &     14.8 &     14.7 &     14.6 &     14.6 &     14.7 \\
 pLCP-2w-MS/S & 34.5 &     21.3 &     19.5 &     18.9 &     21.7 &     22.0 &     22.5 &     24.5 \\ \hline
\end{tabularx}
\end{table}

\begin{table}\centering\small
\caption{Description of parallel string sorting algorithms in experiment}\label{tab:paraalgo}
\begin{tabularx}{\linewidth}{l|X}
Name          & Description and Author                                                                                                                                                            \\ \hline
pS-Unroll & Our parallel super scalar string sample sort (see Section~\ref{sec:s5}) with unrolled and interleaved tree descents.                                                              \\
 pS-Equal & Our parallel super scalar string sample sort (see Section~\ref{sec:s5}) with equality checking at each splitter node.                                                             \\
        pMKQS & Our parallel multikey quicksort (see Section~\ref{sec:para-mkqs}) with caching of  characters.                                                                             \\
pS+LCP-M  & Our parallel multiway LCP-merge with pS on each NUMA node.                                                                                                                \\
     pRS-8bit & Our parallel radix sort (see Section~\ref{sec:para-radixsort}) with -bit alphabet                                                                                              \\
    pRS-16bit & Our parallel radix sort (see Section~\ref{sec:para-radixsort}) with -bit alphabet at the fully parallel levels, and -bit alphabets for sequentially processed subproblems. \\
    pRS/Akiba & Ta\-kuya Akiba's~\cite{akiba2011radixsort} radix sort.                                                                                                                            \\
     p2w-MS/R & Parallel 2-way LCP-mergesort from Tommi Rantala's  library~\cite{rantala2007web}.                                                                                                 \\
 pMKQS-SIMD/R & Parallel multikey quicksort with SIMD operations from Tommi Rantala's library~\cite{rantala2007web}.                                                                              \\
 pLCP-2w-MS/S & Parallel 2-way LCP-mergesort by Nagaraja Shamsundar~\cite{shamsundar2009lcpmergesort}, which is based on Waihong Ng's LCP-mergesort~\cite{ng2008merging}.                         \\ \hline
\end{tabularx}
\end{table}
 
\FloatBarrier

\section{Conclusions and Future Work}\label{sec:conclusions}

We have demonstrated that string sorting can be parallelized successfully on
modern multi-core shared memory and NUMA machines. In particular, our new string
sample sort algorithm combines favorable features of some of the best sequential
algorithms -- robust multiway divide-and-conquer from burstsort, efficient data
distribution from radix sort, asymptotic guarantees similar to multikey
quicksort, and word parallelism from caching multikey quicksort.  For NUMA
machines we developed parallel -way LCP-merge to further decrease costly
inter-node random access.

We want to highlight that using our pS (which can save LCPs) and -way
LCP-merge implementations it is straight-forward to construct a fast parallel
external memory string sorter for short strings () using shared memory
parallelism. The sorting throughput of our string sorters is probably higher
than the available I/O bandwidth.

Implementing some of the refinements discussed in the next section are likely to
yield further improvements for string sample sort and -way
LCP-merge.

\subsection{Practical Refinements}\label{app:refinements}

\emph{Memory conservation:} For use of our algorithms in applications like
database systems or MapReduce libraries, it is paramount to give hard guarantees
on the amount of memory required by the implementations. Our experiments show
clearly, that caching of characters accelerates string sorting, but this speed
comes at the cost of memory space. A future challenge is thus to sort fast, but
with limited memory. In this respect, pS is a very promising candidate, as
it can be restricted to use only the classification tree and a recursion stack,
if little additional memory is available. But if more memory is available, then
caching, saving oracle values and out-of-place redistribution can be enabled
adaptively.

\emph{Multipass data distribution:} There are two constraints for the maximum
sensible value for the number of splitters : The cache size needed for the
classification data structure and the resources needed for data
distribution. Already in the plain external memory model these two constraints
differ ( versus ). In practice, things are even more
complicated since multiple cache levels, cache replacement policy, TLBs,
etc. play a role. Anyway, we can increase the value of  to the value required
for classification by doing the data distribution in multiple passes (usually
two).  Note that this fits very well with our approach to compute oracles even
for single pass data distribution. This approach can be viewed as LSD radix sort
using the oracles as keys. Initial experiments indicate that this could indeed
lead to some performance improvements.

\emph{Alphabet compression:} When we know that only  different
values from  appear in the input, we can compress characters into
 bits.  For S, this allows us to pack more characters
into a single machine word.  For example, for DNA input, we might pack 32
characters into a single 64 bit machine word. Note that this compression can be
done on the fly without changing the input/output format and the compression
overhead is amortized over  key comparisons.

\emph{Jump tables:} In S, the  most significant bits of a key are often
already sufficient to define a path in the classification tree of length up to
.  We can exploit this by precomputing a jump table of size  storing a
pointer to the end of this path. During element classification, a lookup in this
jump table can replace the traversal of the path.  This might reduce the gap to
radix sort for easy instances.

\emph{Using tries in practice:} The success of burstsort indicates that
traversing tries can be made efficient. Thus, we might also be able to use a
tuned trie based implementation of S in practice. One ingredient to such an
implementation could be the word parallelism used in the pragmatic solution --
we define the trie over an enlarged alphabet. This reduces the number of
required hash table accesses by a factor of . The tuned van Emde Boas trees
from \cite{dementiev2004sortedlist} suggest that this data structure might work
in practice.

\emph{Adaptivity:} By inspecting the sample, we can adaptively tune the
algorithm.  For example, when noticing that already a lot of information\footnote{The entropy  can be used to
  define the amount of information gained by a set of splitters. The bucket
  sizes  can be estimated using their size within the sample.} can be
gained from a few most significant bits in the sample keys, the algorithm might
decide to switch to radix sort. On the other hand, when even the  most
significant characters do not give a lot of information, then a trie based
implementation can be used.  Again, this trie can be adapted to the input, for
example, using hash tables for low degree trie nodes and arrays for high degree
nodes.



\small
\bibliographystyle{spmpsci}
\bibliography{library}



\end{document}
