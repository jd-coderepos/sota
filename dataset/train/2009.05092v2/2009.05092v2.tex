\def\year{2021}\relax
\documentclass[letterpaper]{article} \usepackage{aaai21}  \usepackage{times}  \usepackage{helvet} \usepackage{courier}  \usepackage[hyphens]{url}  \usepackage{graphicx} \urlstyle{rm} \def\UrlFont{\rm}  \usepackage{natbib}  \usepackage{caption} \frenchspacing  \setlength{\pdfpagewidth}{8.5in}  \setlength{\pdfpageheight}{11in}  

\usepackage{booktabs}
\usepackage{multirow,multicol}
\usepackage{amsmath}
\usepackage{xcolor}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{verbatim}
\usepackage[capitalize]{cleveref}
\usepackage{soul, color}
\DeclareMathOperator*{\ReLU}{\text{ReLU}}
\DeclareMathOperator*{\LeakyReLU}{\text{LeakyReLU}}
\DeclareMathOperator*{\softmax}{\text{softmax}}
\DeclareMathOperator*{\argmax}{\text{argmax}}
\DeclareMathOperator*{\maxpool}{\text{maxpool}}
\DeclareMathOperator*{\GAT}{\text{GAT}}
\DeclareMathOperator*{\FFN}{\text{FFN}}

\newcommand\tocomplete[1]{\textcolor{red}{#1}}

\pdfinfo{
/Title (Dialogue Relation Extraction with Document-level Heterogeneous Graph Attention Networks )
/Author (Hui Chen,
     Pengfei Hong,
     Wei Han,
     Navonil Majumder,
     Soujanya Poria)
/TemplateVersion (2021.1)
} 

\setcounter{secnumdepth}{2} 

\title{Dialogue Relation Extraction with Document-level \\ Heterogeneous Graph Attention Networks
}
 \author{
     Hui Chen,
     Pengfei Hong,
     Wei Han,
     Navonil Majumder,
     Soujanya Poria
     \\
 }
 \affiliations{


     DeCLaRe Lab,
     Singapore University of Technology and Design,
     Singapore\\
hui\_chen@mymail.sutd.edu.sg, \{hongpengfei.emrys, henryhan88888\}@gmail.com, \\
     navo@nlp.cic.ipn.mx, sporia@sutd.edu.sg \\
}


\begin{document}

\maketitle

\begin{abstract}

Dialogue relation extraction (DRE) aims to detect the relation between two entities mentioned in a multi-party dialogue. It plays an important role in constructing knowledge graphs from conversational data increasingly abundant on the internet and facilitating intelligent dialogue system development.
The prior methods of DRE do not meaningfully leverage speaker information---they just prepend the utterances with the respective speaker names. Thus, they fail to model the crucial inter-speaker relations that may give additional context to relevant argument entities through pronouns and triggers. We, however, present a graph attention network-based method for DRE where a graph, that contains meaningfully connected speaker, entity, entity-type, and utterance nodes, is constructed. This graph is fed to a graph attention network for context propagation among relevant nodes, which effectively captures the dialogue context.
We empirically show that this graph-based approach quite effectively captures the relations between different entity pairs in a dialogue as it outperforms the state-of-the-art approaches by a significant margin on the benchmark dataset DialogRE. Our code is released at: \url{https://github.com/declare-lab/dialog-HGAT} 





\end{abstract}


\section{Introduction}
Relation extraction (RE) task aims to recognize relations between two entities present in a document. It plays a pivotal role in understanding unstructured text and constructing knowledge bases~\cite{peng2017cross,quirk2017distant}. Although the task of document-level relation extraction has been studied extensively in the past, the task of relation extraction from dialogues has yet to receive extensive study. 

Conversational text exhibits intra- and inter-utterance relations~\cite{poria2020beneath}, which makes it different from the text
in previous document-level relation extraction. Most previous works focus on professional and formal
literature like biomedical documents~\cite{li2016biocreative,wu2019renet} and Wikipedia articles~\cite{elsahar2018t,yao2019docred,mesquita2019knowledgenet}.
These kinds of datasets are well-formatted and logically coherent with clear referential semantics.
Hence for most NLP tasks analyzing a few continuous sentences are enough to grasp pivotal information.
However, for dialogue relation extraction, conversational text is sampled from daily chat, which is more casual in nature.
Hence its logic is simpler but entangled and referential ambiguity always occurs to an external reader.
Compared with formal literature, it has lower information density~\cite{wang2011pilot} but is more difficult for model to understand. Moreover, compared with other document-level RE dataset such as DocRED, dialogue text has much more cross-sentence relations~\cite{yu2020dialogue}.
\cref{fig1} presents an example of dialogue relation extraction, taken from DialogRE~\cite{yu2020dialogue} dataset. In order to infer the relation between \textit{Speaker1} and \textit{Emma}, we may need to find some triggers to recognize the characteristics of \textit{Emma}. Triggers are evidences that can support the inference. As we can see, the following utterances are talking about \textit{Emma}, and the key word \textit{baby daughter} mentioned by \textit{Speaker1} is a trigger, which provides an evidence that \textit{Emma} is \textit{Speaker1}'s daughter.


\begin{figure}[t]
\centering
\includegraphics[width=0.9\columnwidth]{cover_fancy.pdf} \caption{An example adapted from DialogRE dataset. Words with red and blue background represent subject and object entities. Words with yellow background represent triggers that facilitate the relation inference. Solid and dash lines stand for intra- and inter-utterance relations.}
\label{fig1}
\end{figure}

Prior works show that triggers of arguments facilitate the document-level relation inference. Thus, DocRED dataset~\cite{yao2019docred} provides several supporting evidences for each argument pair. Some efforts utilize the dependency paths of arguments to find possible triggers. For example, LSR model~\cite{nan2020reasoning} constructs meta dependency paths of each argument pair and aggregates all the word representations located in these paths to their model, in order to enhance model's reasoning ability.
\citet{sahu2019inter} uses syntactic parsing and coreference resolution to find intra- and inter-related words of each argument. \citet{christopoulou2019connecting} proposes an edge-oriented graph to synthesize argument-related information.
These models are graph-based and have proven powerful in encoding long-distance information. However, for dialogue relation extraction, interlocutors exist in every utterance of the dialogue, and they are often considered as an argument. Although these previous approaches have utilized entity features of arguments, most of them employ meta dependency paths to find the related words, which results in the missing of necessary information related to speakers, since the speaker references have very little dependency features in each utterance. We think the structure of our graph allows it to model the intra- and inter-speaker relations through paths that involve conversational discourse and word-level semantics. This phenomenon enables the model to outshine the state-of-the-art frameworks int the task of dialogue level relation extraction. 

In this work, we propose a simple yet effective attention-based heterogeneous graph neural network to tackle the dialogue relation extraction task by using multi-type features to create the graph and employing graph attention mechanism to propagate contextual information. Different from most of the previous works, our proposed model is customized for the relation extraction task in dialogue background, as we have specially modeled speaker information and designed a mechanism to propagate massages among different sentences for better inter-sentence representation learning. The remainder of this paper is organized as follows: \cref{method} elaborates on our proposed framework; \cref{experiment} introduces the used dataset and baseline models; \cref{result} lays out the experiment results and analysis; ~\cref{related-work} briefly discusses relevant works of heterogeneous graph neural networks; and \cref{conclusion} concludes the paper.

\section{Background of Graph Attention Networks}






\subsection{Graph Attention Network (GAT)}
The graph attention network is composed of graph attentional layers.
Given a graph  and its node embeddings , GAT layer updates all the embeddings to  using a self-attention mechanism.
In the attention computation part, each node only with its neighbour nodes serves as inputs to generate a set of attention weights, which is called masked attention:

Where  is a weight matrix to linearly transform embeddings to another feature space,  weight matrix in a feed-forward neural network to generate the attention weights. Then these weights will be applied to original node features to generate new features:


\subsection{Heterogeneous Graph Neural Network (HGNN)}
Massive work on graph neural network treats the graph as homogeneous ones, where nodes and edges are of the same type.
However, considering the complexity of the real world, the attributes of things and their relations vary greatly.
As a result, it is difficult to use a homogeneous graph to describe them.
Heterogeneous graphs, which assume multi-type nodes and edges, make mathematical modeling of the real world more approachable.
A heterogeneous graph can be defined by a graph topology  with a node type mapping: :  and an edge type mapping : . Particularly, a graph is a heterogeneous graph when the types of nodes  or the types of edges .
\par
To construct neural networks on heterogeneous graphs, effective information extraction and message passing scheme should be formulated.
Meta-path \cite{sun2011pathsim}, which has been used as a general structure to capture different semantics in heterogeneous graphs, is utilized in HGNNs.
A meta-path is a path defined on the edge and node type set , in the form of . It specifies a composition relation  between objects  and . In our work, we firstly build a heterogeneous graph composed of hierarchical and functional language components from the dataset, then applies heterogeneous graph attention operations on task-specified useful meta-paths to enhance the performance.

\section{Methodology}
\label{method}
\subsection{Task Definition}

Given a dialogue containing  utterances  and argument pairs , where subject  and object  are entities mentioned in the dialogue, the goal is to identify the relation between argument pairs . For document-level relation extraction task, subject entity and object entity are often distributed in various sentences.


\subsection{Model Overview}
In this work, a conversation is represented as a heterogeneous graph for both intra- and inter-sentence relation inferences.
We first utilize Utterance Encoder to encode sentential level utterance information.
These utterance encodings along with word embeddings, speaker embeddings, argument embeddings, and entity-type embeddings are logically connected to form a heterogeneous graph---discussed in detail later in this section. Further, this graph is fed through a graph attention layer~\cite{velivckovic2017graph} that aggregates information from the neighboring nodes.

Lastly, we concatenate the learned argument embeddings and feed them to a classifier. An overview of the proposed framework is shown in~\cref{fig2}.


\begin{figure*}[ht]
\centering
\includegraphics[width=\linewidth]{GAT-RE.pdf} \caption{An overview of the proposed framework.}
\label{fig2}
\end{figure*}


\subsection{Data Preprocessing}
We use spaCy\footnote{\url{https://spacy.io}} to tokenize  utterances and at the same time, we obtain part-of-speech (POS) tags and named-entity types of each token.

\subsection{Utterance Encoder}
Given a dialogue , each GloVe~\cite{pennington2014glove} initialized utterance  is first fed to a contextual encoder to obtain the contextualized representations of each constituent word. Bidirectional long short-term memory network (BiLSTM) is used as our contextual encoder. The operation of BiLSTM in our model can be defined as:

where  and  denote the hidden representations in the -th layer of utterance  from two directions,  is the contextual representation which is the concatenation of  and , and  stands for the embedding of the -th token in utterance . Unlike the previous approaches~\cite{christopoulou2019connecting} that only rely on semantic-contextual features for utterance encoding, we also employ syntactic features. Thereby, we concatenate semantic word-embedding  initialized by GloVe~\cite{pennington2014glove}, syntactic Part of Speech embedding , and entity-type embedding  to form token embedding :


To encode non-local contextual information between each utterances, we max pool the hidden states of each utterance-level BiLSTM (local LSTM), and then feed the sequence  to a conversational-level BiLSTM (global LSTM). The operation of global LSTM is the same as~\cref{lrnn1,lrnn2,lrnn3}.




\subsection{Graph Construction}

\subsubsection{Node Construction}

There are five types of nodes in our proposed heterogeneous graph: utterance nodes, entity-type nodes, word nodes, speaker nodes, and argument nodes. Each type of node is used to encode a type of information in the dialogue.


\paragraph{Utterance and Entity-Type Nodes.}
Utterance nodes are used to represent the utterance-level information in a conversation.
We use the outputs of utterance encoder which contains the utterance level encoding to initialize our utterance nodes.

Entity-type nodes represent the types of words that include a variety of named and numeric entities, such as PERSON or LOCATION.
Naturally, each constituent word of a named entity is connected to its corresponding type node.
Since the different mentions of the same entity may have different types in one conversation, we aim to capture all the type information of each entity via this entity-type node. For example, `Frank' can be a string if it represents an alternative name, and at the same time, it can be a person if it refers to a speaker in the conversation. We believe that entity-type information has a positive influence on the relation-inference process. Each Entity-Type node is initialized with our created Entity-Type embedding according to its entity type.


\paragraph{Word, Speaker, and Argument Nodes.}
Word nodes represent the vocabulary of the conversation. Each word node is connected with the utterance which contains the word and it is also connected with all the possible entity types that the word could have in the conversation. We initialize the states of word nodes with GloVe~\cite{pennington2014glove}.

Speaker node represents each unique speaker in the conversation. Each speaker node is connected with the utterances uttered by the speaker himself/herself. This type of node is initialized with its specific embedding and it is used to gather global information about the utterances made by the speaker.

Argument nodes are two special nodes that used to encode argument's relative positional information about the argument pair. One stands for the subject argument and the other represents the object argument. Similar to speaker nodes, argument nodes are also encoded by a specific embedding.



\subsubsection{Edge Construction}
The proposed graph is undirected but the propagation has directions. There are five types of edges: utterance-word, utterance-argument, utterance-speaker, type-word, and type-argument. `A-B' means there are edges between node A and B. Each edge has its own type. These edges are randomly initialized except utterance-word edge.

For the edge between utterance and word nodes, we adopt POS tags to initialize the edge features, since POS tags can reflect the local information of each word. This kind of edge aggregates not only global semantic features of the conversation but also local syntactic features to the word nodes.







\subsubsection{Graph Attention Layer}
We use graph attention mechanism~\cite{velivckovic2017graph} to aggregate discourse information and entity-type information to basic nodes. Let's take node  as an example. The graph attention mechanism described in the following shows how 's neighborhood  aggregates its information to :


where  and  are representations of node  and , , ,  and  are trainable weight matrices,  is the edge weight matrix that is mapped to the multi-dimensional embedding space,  is the attention weight between  and ,  is an activation function, and  is concatenation operation.

\subsubsection{Message Propagation}
Although graph attention operation can effectively aggregate neighbor features, only one message passing will make the node structure relatively shallow. To make node features more informative, we update all basic nodes multiple times.

Our meta path is as follows:
First, we use utterance nodes to update word nodes, speaker nodes and argument nodes; secondly, the updated word nodes propagate messages to entity-type nodes; then entity-type nodes update word nodes, argument nodes, and entity-type nodes; next we use word nodes, speaker nodes, and argument nodes to update utterance nodes; and lastly the updated utterance nodes update word nodes, speaker nodes and argument nodes. The path can be denoted as , where , , and  refer to utterance nodes, basic nodes, and entity-type nodes.

Following~\citet{wang2020heterogeneous}, we add a residual connection~\cite{he2016deep} to avoid gradient vanishing during updating:


where  is the output learned in the graph attention layer, and  is the original input of the graph attention layer.

In our model, we first aggregate utterance nodes to basic nodes, so that semantic and syntactic features obtained in the utterance graph encoder can be intactly passed to word nodes, speaker nodes, and argument nodes. In message passing, except for graph attention operation, there is also a two-layer feed-forward network which can be denoted as:


Suppose we have the initial embeddings of utterance nodes, basic nodes and entity-type nodes, denoted as embedding matrices , the message propagating process can be written as:





where the GAT operation is the same as~\cref{gat-global1,gat-global2,gat-global3,residual-global,FFN}. The superscripts represent it is the  new value of that matrix and 0 marks the initial value.




\subsection{Relation Classifier}
After the message propagation in the heterogeneous graph, we obtain new representations of all entities. We select the argument nodes  and , as well as the corresponding word nodes  and  from basic nodes, and concatenate them. Finally, they are fed to a linear transformation and a sigmoid function to get the predictions:

where  is the probability of relation type  given argument pair ,  and  are linear transformation weight and bias vector,  is max pooling operation, and  is sigmoid function.

\section{Experiments}
\label{experiment}
\subsection{Dataset Used}
We evaluate the proposed framework on the DialogRE dataset~\cite{yu2020dialogue}, which contains totally 1,788 dialogues and 10,168 relational triples. DialogRE is adapted from the complete transcripts of \textit{Friends}, which is a widely used corpus in dialogue research these years~\cite{chen-etal-2017-robust,zhou2018they,yang2019friendsqa}, and there are 36 possible relation types, most of which focus on biographical attributes of person entities. Each dialogue contains several relational triples , and the task is to predict the relation  between each entity pair . In the experiments, the dataset is partitioned into train, dev, and test set with roughly 60/20/20 ratio. Following the evaluation metrics of DialogRE, we report macro F1 scores of the proposed model and all the baselines in both the standard and conversational settings.



\subsection{Settings and Hyperparameters}
In our experiments, we tune the parameters of batch size, learning rate, and BiLSTM hidden size by testing the performance on the validation set. \cref{tab:param_settings} lists the major parameters used in our experiments.

\begin{table}[ht]
\centering
\begin{tabular}{l|c}
\toprule
 Parameter & Value \\
\midrule
Word Embedding Dimension & 300 \\
NER Embedding Dimension & 30 \\
POS Embedding Dimension & 30 \\
Local BiLSTM Hidden Size & 200 \\
Local BiLSTM Layers & 2 \\
Global BiLSTM Hidden Size & 128 \\
Global BiLSTM Layers & 2 \\
Multihead Attention Number & 10 \\
Learning Rate & 0.0005 \\
Batch Size & 16 \\
Edge Embedding Dimension & 50 \\
\bottomrule
\end{tabular}
\caption{Parameter settings.}
\label{tab:param_settings}
\end{table}



\subsection{Baseline models}
\subsubsection{Sequence-based Models}
We select convolutional neural networks(CNN)~\cite{zeng2014relation}, LSTM, and BiLSTM~\cite{cai2016bidirectional} as the sequence-based baselines. These models take word embeddings, mention embeddings, and type embeddings as features. Concretely, they use GloVe and spaCy to get word embeddings and label named-entity types, and then take an average of all the embeddings of mention names for each entity to get mention embeddings.

\subsubsection{Graph-based Models}
As our proposed model is graph-based, we also select two graph-based models AGGCN~\cite{guo2019attention} and LSR~\cite{nan2020reasoning} as the baselines. AGGCN directly feeds the full dependency tree of each sentence to a graph convolutional network which takes self-attention weights as soft edges. It achieves state-of-the-art results in various relation extraction tasks. LSR adopts an adaptation of Kirchhoffâ€™s Matrix-Tree Theorem~\cite{tutte1984graph,koo2007structured} to induce the latent dependency structure of each document and then feeds the latent structure to a densely connected graph convolutional network to inference the relations. These graph-based models both utilize dependency information to construct the inference graph.



\section{Results and Analysis}
\label{result}
\subsection{Comparision with Baselines}
We present our main results on DialogRE dataset in~\cref{tab:results}. As shown in~\cref{tab:results}, our model surpasses the state-of-the-art method by 9.6\%/7.5\% F1 scores, and 8.4\%/5.7\% F1 scores in both validation and test sets, which demonstrates the effectiveness of the information propagation along task-specific functional meta-paths in the heterogeneous graph.
Whatever purely sequential models or graph-based models that are built from local transformers focus on modeling the sequence within a sentence scope.
As a result, inter-sentence communication usually passes through a long distance, which causes information loss or disruption.
However, this kind of information exchange is critically important for dialog-style text, because logical connections are not locally compact within adjacent sentences,
instead they are spread over the whole conversations.
Our proposed model, on the opposite, constructs a heterogeneous graph with shorter distances between logically closed but syntactically faraway word pairs.
Hence the long-distance issue is mitigated.
\par
We also compare the model sizes as an efficiency indicator.
Although creating numerous nodes and edges inevitably brings overhead, the total number of parameters is still moderate.

\begin{table*}[ht]
\centering
\begin{tabular}{l|c|cccc}
\toprule
\multirow{2}{*}{Model} & &
\multicolumn{2}{c}{Dev} &
\multicolumn{2}{c}{Test} \\
& \#params &  &  &  &  \\
\midrule
Majority~\cite{yu2020dialogue} & - & 38.9 & 38.7 & 35.8 & 35.8 \\
CNN~\cite{yu2020dialogue} & - & 46.1 & 43.7 & 48.0 & 45.0 \\
LSTM~\cite{yu2020dialogue} & - & 46.7 & 44.2 & 47.4 & 44.9 \\
BiLSTM~\cite{yu2020dialogue} & 4.1M & 48.1 & 44.3 & 48.6 & 45.0 \\
\midrule
AGGCN~\cite{guo2019attention} & 3.7M & 46.6 & 40.5 & 46.2 & 39.5 \\
LSR~\cite{nan2020reasoning} & 20.5M & 44.5 & - & 44.4 & - \\
\midrule
DHGAT(Ours) & 4.0M & \textbf{57.7} & \textbf{52.7} & \textbf{56.1} & \textbf{50.7} \\
\bottomrule
\end{tabular}
\caption{Main results on DialogRE dataset. Values in the \#params column refer to parameter sizes of the models.  and  are macro F1 scores under standard setting and conversational setting, respectively. The unit of all the scores is \%.}
\label{tab:results}
\end{table*}

\subsection{Ablation Study}
To understand the impact of the components in our model, we perform ablation study using our proposed model on DialogRE dataset. The ablation results are shown in~\cref{tab:ablation}. First, we remove local LSTM and global LSTM. The results showing drops in all the evaluation metrics prove that the contextual encoder plays an important role in semantic feature extraction. Second, we remove the specific argument nodes and have observed that F1 and F1 scores decrease to 55.0\% and 50.2\% on test set. This proves our design on argument nodes effectively synthesize argument features to the model. Further, we test the performance of the syntactic features we inject by removing POS embedding, NER embedding, and POS edge features. All the scores decrease, and specifically, the removal of POS embedding leads to about 2\% drops in all the evaluation metrics.

\paragraph{Rand init vs. GloVe}
Additionally, we have compared different initialization strategies on word nodes. When we transfer GloVe initialization method to a random but trainable initialization method, we can observe a 3\% to 4\% decrease in all the metrics. This demonstrates our GloVe initialization strategy retains word features which have a positive influence on the performance.

\paragraph{Is our design of meta path optimal?}
We test the performance of our message propagation strategy via changing the update strategies. In our proposed model, those basic nodes composed of word, speaker, and argument nodes are updated totally thrice, i.e., they are first updated by utterance nodes, second updated by entity type nodes, and ultimately updated by utterance again. In our ablation study, we try to update basic nodes once, which means basic nodes are only updated by utterance nodes. Results present a dramatically drop of the evaluation scores, especially the standard F1 scores. However, if we add two more updates, that is to say, after our default updates, entity type nodes update basic nodes again and then utterance nodes update basic again, the results don't have an increase on the evaluation scores but decrease a bit. This proves that our message propagation strategy is the optimum now. If we only update the basic nodes once, node features are not informative enough. But if we update the basic nodes too many times, the features may be overfitted.

\begin{table}[ht]
\centering
\begin{tabular}{l|cccc}
\toprule
\multirow{2}{*}{Model} &
\multicolumn{2}{c}{Dev} &
\multicolumn{2}{c}{Test} \\
&  &  &  &  \\
\midrule
Full model & 57.7 & 52.7 & 56.1 & 50.7 \\
 Local BiLSTM & 54.9 & 50.0 & 55.3 & 50.3 \\
 Global BiLSTM & 54.7 & 50.2  & 53.5 & 48.7 \\
 Argument Nodes & 56.0 & 51.3 & 55.0 & 50.2 \\
 POS Embedding & 54.6 & 50.9 & 53.0 & 48.5   \\
 NER Embedding & 56.8 & 51.5 & 54.2 & 49.2 \\
 POSInitEdge & 56.9 & 52.4 & 54.7 & 50.4 \\
\midrule
 Random Init Word Nodes & 53.6 & 48.3 & 52.8 & 47.5 \\
 Update Basic Nodes(t=1) & 47.5 & 45.3 & 47.6 & 44.6 \\
 Update Basic Nodes(t=5) & 55.2 & 50.6 & 54.6 & 49.2 \\
\bottomrule
\end{tabular}
\caption{Ablation results on DialogRE dataset. `t' means the number of updates for basic nodes. The unit of all the scores is \%.}
\label{tab:ablation}
\end{table}

\subsection{Case Studies}
In the dataset, 95\% of relation pairs have argument pairs that span two sentences. Therefore, it is crucial to model long range inter-sentential relationships. Our model can propagate relational information more effectively. Comparing to the LSTM model, speaker nodes, utterance nodes and unique word nodes shorten the information propagation path between two argument nodes. Considering the following example in \cref{case_study}. subject a - `Mindy' and object b - `Speaker 1' have relationship `per:friends' indicated by the trigger `my best friend' in the first utterance. The entity information is relayed from `Mindy' to `Speaker 1' in the update process: `speaker 1' node aggregate utterance level information from its neighbor nodes that contains a. the relation trigger `best friend'. b. utterance level information that contains the subject `Mindy'. However, for bi-LSTM model, it will need to overcome long range of irrelevant information that will affect the final performance.


\begin{figure}[t]
\centering
\includegraphics[width=0.9\columnwidth]{case_study.pdf} \caption{Case study: an example to show the effective message propagation between argument pairs}
\label{case_study}
\end{figure}

\subsection{Error Analysis}
Entity-type information involves in the information propagation process and thus affect the contents of output embeddings.
The model is prone to make incorrectly biased predictions which highly relies on the entity types of two arguments if it fails to acquire enough certainty from other information sources.
For example, given an entity pair of two human names, both with the named entity type `PERSON'.
Sometimes the model inclines to deem the relationship between the pair to be `per:alternate\_name' instead of correct `per:alumni' or `per:roommate'.
This is because for all of these classes, `PERSON-PERSON' is a preferable entity-type pair.
However, the class `per:alternate\_name' (22.01\%) presents more frequently than `per:alumni' (1.83\%) and `per:roommate' (1.29\%) in the dataset.
When information aggregated from all sources other than entity pair is not evident for judgment, entity bias misguides the model to wrong classification results.




\section{Related Work}
\label{related-work}


Graph-based models have raised popular attention from NLP researchers, as it is demonstrated as a powerful mathematical tool to represent complicated syntactic and semantic relations among structured language data.
Early work applies classic graph processing algorithms onto language graphs. \citet{pang2004sentimental} construct a text graph and adopt the minimum-cut method to cluster the nodes for sentiment analysis. \citet{agirre2009personalizing} leverage PageRank algorithm on personalized subgraphs of a wordnet to disambiguate polysemous words according to connected context words.

Recently, with the achievement of graph neural networks \cite{kipf2016semi}, to incorporate syntactic features, which are easy to be expressed by graphs, into end-to-end learning models becomes a growing trend.
\citet{peng2017cross} firstly try to build a computation graph from syntactic parsing trees and employing graph LSTM to obtain better word embeddings for multi-ary relation extraction.
\citet{zhang2018graph} design a pruning algorithm for syntactic graphs and add a graph convolution layer on top of the sequential LSTM encoder in the learning process.
The combination with typical attention-based language models such as transformer \cite{vaswani2017attention} is also studied.
The work in \cite{cai2020graph,yao2020heterogeneous} use transformer-based graph convolutional networks to explicitly encode relations among distant syntactic nodes, to address the long-distance propagation issue.

Other works introduce heterogeneous graph neural networks into NLP tasks, like text classification~\cite{linmei2019heterogeneous}, text summarization~\cite{wang2020heterogeneous}, user profiling~\cite{chen2019semi}, and event categorization~\cite{peng2019fine}. These works prove that heterogeneous graph neural network is a powerful tool in NLP. For the relation extraction task, \citet{christopoulou2019connecting} construct an edge-oriented heterogeneous graph that contains sentence, mention, and entity information. However, syntactic information is neglected in their model. Different from them, homogeneous nodes in our graph is all independent, and we take syntactic features to initialize sentence information as well as edges features.



\section{Conclusion}
\label{conclusion}
In this work, we present an attention-based heterogeneous graph to deal with the dialogue relation extraction task. This heterogeneous graph attention network has modeled multi-type features of the conversation, like utterance, word, speaker, argument, and entity type information. On the benchmark DialogRE dataset, our proposed framework outperforms the strong baselines and the state-of-the-art approaches by a significant margin, which proves the proposed framework can effectively capture relations between different entities in the conversation. Future works will focus on applying the relation knowledge to assist dialogue generation.

\bibstyle{aaai21.bst}
\bibliography{main.bib}


\end{document}
