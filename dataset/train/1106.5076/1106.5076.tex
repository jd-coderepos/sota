\documentclass{llncs}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithmic}
\usepackage{bigstrut}
\usepackage{fullpage}

\def\id#1{\ensuremath{\mathit{#1}}}
\let\idit=\id
\def\idbf#1{\ensuremath{\mathbf{#1}}}
\def\idrm#1{\ensuremath{\mathrm{#1}}}
\def\idtt#1{\ensuremath{\mathtt{#1}}}
\def\idsf#1{\ensuremath{\mathsf{#1}}}
\def\idcal#1{\ensuremath{\mathcal{#1}}}  


\def\rankop{\idtt{rank}}
\def\selop{\idtt{select}}
\def\accessop{\idtt{access}}
\def\polylog{\idtt{polylog}}
\def\rangesum{\idtt{range\_sum}}
\def\dominancesum{\idtt{dominance\_sum}}
\def\insertop{\idtt{insert}}
\def\deleteop{\idtt{delete}}
\def\updateop{\idtt{modify}}
\def\sumop{\idtt{sum}}
\def\searchop{\idtt{search}}
\def\rangecount{\idtt{range\_count}}
\def\dominancecount{\idtt{dominance\_count}}



\newtheorem{observation}[theorem]{Observation}


\def\etal{{\em et al.}}
\newcommand{\f}[2]{| #2 |_{ #1 }} 

\begin{document}

\title{Dynamic Range Selection in Linear Space\thanks{This work was
    supported by NSERC and the Canada Research Chairs Program.}}

\author{Meng He \and J. Ian Munro \and Patrick K. Nicholson}

\institute{Faculty of Computer Science, Dalhousie University, Canada \and David R. Cheriton School of Computer Science, University of Waterloo, Canada, \\
 \email mhe@cs.dal.ca, \{imunro, p3nichol\}@uwaterloo.ca
}

\maketitle
\begin{abstract}
  Given a set  of  points in the plane, we consider the problem
  of answering range selection queries on : that is, given an
  arbitrary -range  and an integer , return the -th
  smallest -coordinate from the set of points that have
  -coordinates in . We present a linear space data structure
  that maintains a dynamic set of  points in the plane with real
  coordinates, and supports range selection queries in  time, as well as insertions and deletions in  amortized time.  The space usage of this data
  structure is an  factor improvement over
  the previous best result, while maintaining asymptotically matching
  query and update times.  We also present a succinct data structure
  that supports range selection queries on a dynamic array of 
  values drawn from a bounded universe.
\end{abstract}


\section{Introduction}

The problem of finding the \emph{median} value in a data set is a
staple problem in computer science, and is given a thorough treatment
in modern textbooks~\cite{CSRL01}.  In this paper we study a dynamic
data structure variant of this problem in which we are given a set 
of  points in the plane.  The \emph{dynamic range median problem}
is to construct a data structure to represent  such that we can
support \emph{range median queries}: that is, given an arbitrary range , return the median -coordinate from the set of points
that have -coordinates in .  Furthermore, the data structure
must support insertions of points into, as well as deletions from, the
set .  We may also generalize our data structure to support
\emph{range selection queries}: that is, given an arbitrary -range  and an integer , return the -th smallest
-coordinate from the set of points that have -coordinates in
.

In addition to being a challenging theoretical problem, the range
median and selection problems have several practical applications in
the areas of image processing~\cite{GW93}, Internet advertising,
network traffic analysis, and measuring real-estate prices in a
region~\cite{HM08}.

In previous work, the data structures designed for the above problems
that support queries and updates in polylogarithmic time require
superlinear space~\cite{BGJS10}.  In this paper, we focus on designing
linear space dynamic range selection data structures, without
sacrificing query or update time.  We also consider the problem of
designing \emph{succinct data structures} that support range selection
queries on a dynamic array of values, drawn from a bounded universe:
here ``succinct'' means that the space occupied by our data structure
is close to the information-theoretic lower bound of representing the
array of values~\cite{J89}.

\subsection{Previous Work\label{sec:previousresults}}



\paragraph{Static Case:}

The static range median and selection problems have been studied by
many different authors in recent
years~\cite{BKMT05,KMS05,HM08,P08,PG09,GPT09,GS09,BJ09,BGJS10,JL11}.
In these problems we consider the  points to be in an array: that
is, the points have -coordinates .  We now summarize
the upper and lower bounds for the static problem.  In the remainder
of this paper we assume the word-RAM model of computation with word
size  bits.


For exact range medians in constant time, there have been several
iterations of near-quadratic space data
structures~\cite{KMS05,P08,PG09}. For linear space data structures,
Gfeller and Sanders~\cite{GS09} showed that range median queries could
be supported in  time\footnote{In this paper we use 
  to denote .}, and Gagie et al.~\cite{GPT09} showed that
selection queries could be supported in  time using a
wavelet tree, where  is the number of distinct -coordinates
in the set of points.  Optimal upper bounds of 
time for range median queries have since been achieved by Brodal et
al.~\cite{BJ09,BGJS10}, and lower bounds by J{\o}rgensen and
Larsen~\cite{JL11}; the latter proved a cell-probe lower bound of
 time for any static range selection data
structure using  bits of space.  In the case of
range selection when  is fixed for all queries, J{\o}rgensen and
Larsen proved a cell-probe lower bound of 
time for any data structure using 
space~\cite{JL11}.  Furthermore, they presented an adaptive data
structure for range selection, where  is given at query time, that
matches their lower bound, except when ~\cite{JL11}.  Finally, Bose et al.~\cite{BKMT05} studied the
problem of finding \emph{approximate range medians}.  A
-approximate median of range  is a value of rank between
 and , for .

\paragraph{Dynamic Case:}

Gfeller and Sanders~\cite{GS09} presented an  space data
structure for the range median problem that supports queries in
 time and insertions and deletions in 
amortized time. Later, Brodal et al.~\cite{BJ09,BGJS10} presented an
 space data structure for the dynamic range
selection problem that answers range queries in  time and insertion and deletions in 
amortized time.  They also show a reduction from the \emph{marked
  ancestor problem}~\cite{AHR98} to the dynamic range median problem.
This reduction shows that  query time is
required for any data structure with polylogarithmic update time.
Thus, there is still a gap of  time between
the upper and lower bounds for linear and near linear space data
structures. 

In the restricted case where the input is a dynamic array  of 
values drawn from a bounded universe, , it is possible to
answer range selection queries using a dynamic wavelet tree, such as
the succinct dynamic string data structure of He and
Munro~\cite{HM10}.  This data structure uses  bits\footnote{ denotes the 0th-order empirical
  entropy of the multiset of values stored in .  Note that  always holds.} of space, the query time is
, and the update time is
.

\subsection{Our Results\label{sec:ourresults}}

In Section~\ref{sec:lineards}, we present a \emph{linear space} data
structure for the dynamic range selection problem that answers queries
in  time, and performs updates in  amortized time. This data structure can be used to
represent point sets in which the points have \emph{real coordinates}.
In other words, we only assume that the coordinates of the points can
be compared in constant time.  This improves the space usage of the
previous best data structure by a factor of ~\cite{BGJS10}, while maintaining query and update time.

In Section~\ref{sec:dynarray}, we present a succinct data structure
that supports range selection queries on a dynamic array  of values
drawn from a bounded universe, .  The data structure
occupies  bits, and supports
queries in  time, and insertions and deletions in  amortized time.
This is a  improvement\footnote{The
  preliminary version of this paper that appeared in ISAAC 2011
  erroneously stated the bound for our succinct data structure as
  being an  improvement.  We thank Gelin Zhou for
  pointing out this error.} in query time over the dynamic wavelet
tree, and thus closes the space gap between the dynamic wavelet tree
solution and that of Brodal et al.~\cite{BGJS10}.


\section{Linear Space Data Structure\label{sec:lineards}}

In this section we describe a linear space data structure for the
dynamic range selection problem.  Our data structure follows the same
general approach as the dynamic data structure of Brodal et
al.~\cite{BGJS10}.  However, we make several important changes, and
use several other auxiliary data structures, in order to improve the
space by a factor of .

The main data structure is a weight balanced B-tree~\cite{AV03}, ,
with branching parameter , for , and leaf parameter .  The tree  stores the
points in  at its leaves, sorted in non-decreasing order of
-coordinate\footnote{Throughout this paper, whenever we order a
  list based on -coordinate, it is assumed that we break ties using
  the -coordinate, and vice versa.}.  The height of  is  \emph{levels}, and we assign numbers to the
levels starting with level  which contains the root node, down to
level  which contains the leaves of .  Inside each internal
node , we store the smallest and largest -coordinates in
.  Using these values we can acquire the path from the root of
 to the leaf representing an arbitrary point contained in  in
 time; a binary search over the values stored in the
children of an arbitrary internal node requires  time
per level.


Following Brodal et al.~\cite{BGJS10}, we store a \emph{ranking tree}
 inside each internal node .  The purpose of the
ranking tree  is to allow us to efficiently make a branching
decision in the main tree , at node .  Let  denote the
subtree rooted at node .  The ranking tree  represents all of
the points stored in the leaves of , sorted in non-decreasing
order of -coordinate.  The fundamental difference between our
ranking trees, and those of Brodal et al.~\cite{BGJS10}, is that ours
are more space efficient.  Specifically, in order to achieve linear
space, we must ensure that the ranking trees stored in each level of
 occupy no more than  bits in total, since there
are  levels in .  We describe the ranking
trees in detail in Section~\ref{sec:serank}, but first discuss some
auxiliary data structures we require in addition to .


We construct a red-black tree  that stores the points in  at
its leaves, sorted in non-decreasing order of -coordinate.  As
in~\cite{BGJS10}, we augment the red-black tree  to store, in
each node , the count of how many points are stored in  and
, where  and  are the two children of .  Using
these counts,  can be used to map any query  into
, the rank of the successor of  in , and , the rank
of the predecessor of  in .  These ranking queries, as well as
insertions and deletions into , take  time. 



\begin{figure}
\centering
\includegraphics[scale=1.2]{stringfig.pdf}
\caption{\label{fig:stringfig}The top two levels of an example tree
  , and the corresponding strings  and  for these
  levels. Each node at level  has exactly  children.}
\end{figure}


We also store a string  for each node  in .  This string
consists of all of the of the points in  sorted in
non-decreasing order of -coordinate, where each point is
represented by the index of the child of node 's subtree in which
they are contained, i.e., an integer bounded by
.  However, for technical reasons, instead of
storing each string with each node , we concatenate all the
strings  for each node  at level  in  into a string
of length , denoted by .  Each chunk of string 
from left to right represents some node  in level  of 
from left to right within the level.  See Figure~\ref{fig:stringfig}
for an illustration.  We represent each string  using the
dynamic succinct data structure for representing strings of He and
Munro~\cite{HM11}.  Depending on the context, we refer to both the
string, and also the data structure that represents the string, as
.  Consider the following operations on the string :





\begin{itemize}
\item , which returns the -th integer,
  , in ;
\item , which returns the number of
  occurrences of integer  in ;
\item , which returns the
  total number of entries in  whose values are in
  the range ;
\item , which inserts integer 
  between  and ;
\item , which deletes  from . 
\end{itemize} 





Let .  The following lemma summarized the functionality
of these data structures for succinct \emph{dynamic strings} over
small universe:





\begin{lemma}[\cite{HM11}]
\label{lem:smallalphabet}
Under the word RAM model with word size , a string
 of values from a bounded universe , where
 for any constant , can be
represented using  bits to support , ,
,  and  in  time.  Furthermore, we can perform a batch of  update
operations in  time on a substring  in which
the -th update operation changes the value of ,
provided that .
\end{lemma}


The data structure summarized by the previous lemma is, roughly, a
B-tree constructed over the string , in which each leaf
stores a \emph{superblock}, which is a substring of  of
length at most  bits.  We mention this because the ranking tree
stored in each node of  will implicitly reference to these
superblocks instead of storing leaves.  Thus, the leaves of the
dynamic string at level  are \emph{shared} with the ranking
trees stored in nodes at level .

As for their functionality, these dynamic string data structures
 are used to translate the ranks  and  into ranks
within a restricted subset of the points when we navigate a path from
the root of  to a leaf.  The space occupied by these strings is
 bits,
which is  words.  We present the following lemma:

\begin{lemma}
\label{lem:space-1}
Ignoring the ranking trees stored in each node of , the data
structures described in this section occupy  words.
\end{lemma}

In the next section we discuss the technical details of our
space-efficient ranking tree.  The key idea to avoid using linear
space per ranking tree is to \emph{not} actually store the points in
the leaves of the ranking tree, sorted in non-decreasing order of
-coordinate.  Instead, for each point  in ranking tree ,
we implicitly reference the the string , which stores the index
of the child of  that contains .

\subsection{Space Efficient Ranking Trees\label{sec:serank}}

Each ranking tree  is a weight balanced B-tree with branching
parameter , where , and leaf parameter .  Thus,  has height , and each leaf implicitly represents a substring of
, which is actually stored in one of the dynamic strings,
.

\paragraph{Internal Nodes:}
Inside each internal node  in , let  denote the number
of points stored in the subtree rooted at the -th child of , for
, where  is the degree of .  We store a
\emph{searchable partial sums structure}~\cite{RRR02} for the sequence
.  This data structure will allow us to
efficiently navigate from the root of  to the leaf containing
the point of -coordinate rank .  The functionality of this data
structure is summarized in the following lemma:

\begin{lemma}[\cite{RRR02}]\label{lem:RRR}
Suppose the word size is .  A sequence  of
 nonnegative integers of  bits each, for any
constant , can be represented in  bits
and support the following operations in  time:
\begin{itemize}
\item  which returns ,
\item  which returns the smallest  such that
  ,
\item  which sets  to
  , where .
\end{itemize}
This data structure can be constructed in  time, and it
requires a precomputed universal table of size  bits for
any fixed .
\end{lemma}

We also store the \emph{matrix structure} of Brodal et
al.~\cite{BGJS10} in each internal each node  of the ranking tree.
Let  denote the out-degree of node
, and let  denote the subtrees
rooted at the children of  from left to right.  Similarly, recall
that  denotes the out-degree of , and let  be the subtrees rooted
at each child of  from left to right.  These matrix structures are
a kind of partial sums data structure defined as follows; we use
roughly the same notation as~\cite{BGJS10}:

\begin{definition}[Summarizes~\cite{BGJS10}]
  A \emph{matrix structure}  is an ~matrix, where
  entry  stores the number of points from  that are contained in .  The
  matrix structure  is stored in two ways.  The first
  representation is a standard table, where each entry is stored in
   bits.  In the second representation, we divide each
  column into \emph{sections} of  bits
  --- leaving  bits of overlap between the sections
  for technical reasons --- and we number the sections , where .  In the second
  representation, for each column , there is a \emph{packed word}
  , storing section  of each entry in column .
  Again, for technical reasons, the most significant bit of each
  section stored in the packed word  is padded with a zero
  bit.
\end{definition}

We defer the description of how the matrix structures are used to
guide queries until Section~\ref{sec:answering}.  For now, we just
treat these structures as a black box and summarize their properties
with the following lemma:

\begin{lemma}[\cite{BGJS10}]\label{lem:matrix-struct}
  The matrix structure  for node  in the ranking tree 
  occupies  bits, and can be
  constructed in  time.
  Furthermore, consider an update path that goes through node  when
  we insert a value into or delete a value from .  The matrix
  structures in each node along an update path can be updated in
   amortized time per node.
\end{lemma}


\paragraph{Shared Leaves:}

Now that we have described the internal nodes of the ranking tree, we
describe the how the leaves are shared between  and the dynamic
string over .  To be absolutely explicit, we do not actually
store the leaves of : they are only conceptual. We present the
following lemma:

\begin{lemma}
\label{lem:leaf-query}
Let  be a leaf in  and  be the substring of  that
 represents, where each value in  is in the range ,
and .  Using a universal table
of size  bits, for any , an array  can be computed in
 time, where , for .
\end{lemma}

\begin{proof}
Instead of explicitly storing the leaves of , we use the partial
sums structures along the path from the root of  to the parent
of leaf  to produce two ranks,  and , which are the
starting and ending ranks of the substring  represented by  in
.  Based on the leaf parameter of , and the properties
of weight balanced B-trees~\cite{AV03},  can have length
.  Following the analysis of how superblocks are
laid out in the dynamic string , this means that  is stored
in a constant number of consecutive superblocks~\cite[Section
  4]{HM10a}.

Given that we know  and , we can acquire a pointer to the
first superblock that stores part of  in 
time~\cite[Lemma 7]{HM10a}.  Inside each superblock the substring is
further decomposed into a list of \emph{blocks} of length  bits each, in which only the final block has free space.
In order to produce the array , we scan the list of blocks in the
superblock up to position , reading  bits at a time.
Since each value in  occupies 
bits, we can read  values at a time.  As we
read these values, we keep a running total of the ranks of each value
in  up to our current position.  Let \emph{field} 
denote , where  is our current position within .
Clearly,  occupies  bits.  Furthermore, let  be the concatenation of these fields.  Thus, the
running total, , contains at most  bits, and can be stored in a constant number
of words.

In order to efficiently update our running total  after reading a
 bits from the current block, we perform a lookup in a
universal table .  Let  denote the -th lexicographically
smallest string of length  bits, over the bounded universe
.  Also, let  denote the frequency of symbol  in string . In each entry of the table , we
store the value .  Since both  and 
fit in a constant number of words, we can exploit word-level
parallelism to update the running total by summing all the fields in
 and  in  time.

The table  occupies  bits, and allows
us to process  values in  time.  Recall
that the entire superblock contains 
values.  Thus, we can return  in  time.
\end{proof}

We now present the following lemma regarding the space and
construction time of the ranking trees:

\begin{lemma}
\label{lem:space-2}
Each ranking tree  occupies  bits of space if
, and requires  time to construct, assuming that we
have access to the string .
\end{lemma}

\begin{proof}
The space occupied by the internal nodes is  bits, since each internal node occupies
 bits by
Lemmas~\ref{lem:RRR} and~\ref{lem:matrix-struct}, and the number of
internal nodes is .  In order to reduce the cost of the pointers between the
internal nodes in  to  bits per pointer, we make use
of well known memory blocking techniques for dynamic data structures
(e.g., see~\cite[Appendix J]{HM10a}).  The main idea is to allocate a
\emph{fixed memory area} for the entire ranking tree, and perform all
updates to the ranking tree using memory from this area.  After
 updates, we allocate a new area and copy over the entire
ranking tree.  The cost of using this memory blocking will amount to
 amortized time per update. Thus the overall space is  bits, since we must count the
pointer to the root of the ranking tree, stored at the start of the
fixed memory area.

Now we analyze the overall construction time.  Based on
Lemmas~\ref{lem:RRR} and~\ref{lem:matrix-struct}, we can construct all
the internal nodes in  time, since the number of internal nodes
is , and each
requires  time to construct. 
\end{proof}

\begin{remark}
Note that the discussion in this section implies that we need not
store ranking trees for nodes , where .  Instead, we can directly query the dynamic string 
using Lemma~\ref{lem:leaf-query} in  time to
make a branching decision in .  This will be important in
Section~\ref{sec:dynarray}, since it significantly reduces the number
of pointers we need.
\end{remark}

\subsection{Answering Queries\label{sec:answering}}

In this section, we explain how to use our space efficient ranking
tree in order to guide a range selection query in .

We are given a query  as well as a rank , and our goal
is to return the -th smallest -coordinate in the query range.
We begin our search at the root node  of the tree .  In order to
guide the search to the correct child of , we determine the
canonical set of nodes in  that represent the query .
Before we query , we search for  and  in .  Let
 and  denote the ranks of the successor of  and
predecessor of  in , respectively. We query  using
, and use the searchable partial sum data structures
stored in each node of , to identify the canonical set of nodes
in  that represent the interval .  At this point we
outline how to use the matrix structures in order to decide how to
branch in .

\paragraph{Matrix Structures:}
We discuss a straightforward, \emph{slow method} of computing the
branch of the child of  to follow.  We then discuss the details of
a faster method, which can also be found in the original
paper~\cite{BGJS10}.

In order to determine the child of  that contains the -th
smallest -coordinate in the query range, recall that  is sorted
by -coordinate.  Let  denote the degree of , and 
denote the number of points that are contained in the range  in the subtree rooted at the -th child of , for . Determining the child that contains the -th smallest
-coordinate in  is equivalent to computing the value
 such that  and .  In order to compute , we use the matrix structures
in each internal node of the canonical set of nodes, , that
represent .  The set  contains 
internal nodes, as well as at most two leaf nodes.

Consider any internal node , and without loss of generality,
suppose  was on the search path for , but not the search path
for , and that  has degree .  If the search path for
 goes through child  in , then consider the difference
between columns  and  in the first representation of matrix
.  We denote this difference as , where , for .  For each internal
node  we add each  to a running total, and denote the
overall sum as .  Next, for each of the --- at most --- two leaves
on the search path, we query the superblocks of  to get the
relevant portions of the sums, and add them to .  At this point,
, and it is a simple matter to scan each entry in  to
determine the value of .  Since each matrix structure has 
entries in its columns, this overall process takes  time, since
there are  levels in .  Since there are
 levels in , this costs  time.  This time bound can be
reduced by a factor of , using
a slightly faster method which we now describe.

\paragraph{Faster method:} The main idea of the fast method is to use
word-level parallelism and the second representation of each matrix in
order to speed up the query time.  When we begin our search in the
root node  of the tree , consider the sections of , denoted
.  We query , using the first section  to
guide the search.  In order to remove the  factor from the slow
method, in each internal node  we subtract the packed words
, then add them to a running total .
After we have summed the differences between the packed words in all
the internal nodes, we add the relevant sections from the canonical
leaf nodes using Lemma~\ref{lem:leaf-query}.

Since  is only a rough approximation of the first section of
, each value in the packed word might be off by : the number of additions and subtractions we used to compute
.  This means there may be errors, caused by carry bits, in
possibly the  least significant bits in each value
stored in the packed word .  We scan each entry in  to
determine the indices of the first and last entries in  that
match , except for the last  bits~\footnote{This
  can be done in constant time using parallel subtraction as
  in~\cite{BGJS10}, but that is only necessary in the static case,
  where we are not allowed to spend an additive  factor at each level in .}, as well as the first value that
is greater than  in a more significant bit beyond the  least significant bits.  Let  denote
this set of entries in the packed word .

Next, we check the largest and smallest entries,  and , in
 in order to determine if one of these is .  This can be done
in  time. If neither  or  is ,
then there are several cases for how to proceed.  If there are only a
constant number of values in , then we can compute the index,
, of the child of  that we should branch to, by computing the
entries in  for these values in  time each.
We call this the \emph{good case}.  However, if there are a
non-constant number of entries in , then we are in the \emph{bad
  case}, and we must do a binary search over  to determine .
This costs  time in
total.

The key observation, is that after we do the binary search for 
in the bad case, at \emph{no point in the future} will we ever have to
examine the first section of  or the matrix structures.  This is
because when we are in the bad case, the difference between the first
sections of  and  is a value that can be
stored in  bits: which is why the overlap between
sections was set to be .  Moreover, since there are
only  sections, we can spend at most
 time in bad
cases before we have exhausted all of the bits in the matrix
structures; once there are no more bits, we are guaranteed to have
found the -th smallest -coordinate in the query range.  Since
the good case requires  time, and there are
 levels in , our search costs at most  time.



\paragraph{Recursively Searching in :} 
Let  denote the -th child of .  The final detail to
discuss is how we translate the ranks  into ranks in the
tree .  To do this, we query the string  before
recursing to .  We use two cases to describe how to find
 within . In the first case, if  is the root of ,
then .  Otherwise, suppose the range in 
that stores the parent  of node  begins at position , and
 is the -th child of .  Let  for . Then, the range in  that
stores  is . We then query , and
set , , , and recurse to .  We present the following
lemma, summarizing the arguments presented thus far:

\begin{lemma}
\label{lem:query}
The data structures described in this section allow us to answer range
selection queries in  time.
\end{lemma}

\subsection{Handling Updates}

In this section, we describe the algorithm for updating the data
structures.  We start by describing how insertions are performed.
First, we insert  into  and look up the rank, , of 's
-coordinate in .  Next, we use the values stored in each
internal node in  to find 's predecessor by -coordinate,
.  We update the path from  to the root of .  If a node 
on this path splits, we must rebuild the ranking tree in the parent
node  at level , as well as the dynamic string .

Next, we update  in a top-down manner; starting from the root of
 and following the path to the leaf storing .  Suppose that at
some arbitrary node  in this path, the path branches to the -th
child of , which we denote .  We insert the symbol  into
its appropriate position in . After updating  --- its
leaves in particular --- we insert the symbol  into the ranking
tree , at position , where  is the rank of the
-coordinate of  among the points in .  As in , each
time a node splits in , we must rebuild the data structures in
the parent node.  We then update the nodes along the update path in
 in a top-down manner: each update in  must be processed
by all of the auxiliary data structures in each node along the update
path.  Thus, in each internal node, we must update the searchable
partial sums data structures, as well as the matrix structures.

After updating the structures at level , we use  to map
 to its appropriate rank by -coordinate in .  At this
point, we can recurse to .  In the case of deletions, we follow
the convention of Brodal et al.~\cite{BGJS10} and use node marking,
and rebuild the entire data structure after  updates.  We
present the following theorem:

\begin{theorem}\label{thm:main}
Given a set  of points in the plane, there is a linear space
dynamic data structure representing  that supports range selection
queries for any range  in  time,
and supports insertions and deletions in 
amortized time.
\end{theorem}


\begin{proof}
The query time follows from Lemma~\ref{lem:query} and the space from
Lemmas~\ref{lem:space-1} and~\ref{lem:space-2}. All that remains is to
analyze the update time.

We can insert a point  into  in  time.  The node
structure of  can be updated in  amortized
time by the properties of weight balanced B-trees.  Similarly, the
node structure of  for each node  in the update path in 
can be updated in  amortized time, and there
are  ranking trees that are updated.  Thus, the
tree structure of  and the ranking trees in each node can be
updated in  time.

The difficulty arises when a node  in  splits, since the index
of  relative to the other children of  has changed.  In this
case, we are required to not only rebuild , but also the
substring of  that stores .  If  contains 
points, then  is a string of length , and constructing  takes
 time after  updates, by
Lemma~\ref{lem:space-2}.  This is  amortized time in total, since splits can occur in each
level of .

One issue is that this analysis assumes that we have access to the
updated version of , storing the indices of the children of
, sorted by -coordinate, \emph{after the split}.  We now
explain the technical details of how to compute this string; a task
that requires a few more definitions. Let  and  denote the
two nodes into which  splits, and let , where  is the degree of , denote the
left-to-right sequence of children of  before the split.  Suppose
that after the split, children  become the children of
 and  become the children of , where , and .  Also suppose
that  is the -th child of , and denote the degree of 
as .

First, we extract the strings  and  from  and
: this requires  time in total, since we must traverse a root-to-leaf path in
the dynamic strings.  The next step is to scan both strings 
and  together, and at the same time write an updated string
, which will be the sequence of indices of 's children,
after  is split.  When we encounter the index  in , we
append  to  if , and  if .  In the case when , then we check the
corresponding index  in : if , then we
append  to , and a  otherwise.  For example, let
, , and
 be the -rd child of .  Suppose that  is to be split so
that children  and  become the children of  and  and 
become the children of .  Then, following the steps we just
described, .  Overall,
generating  takes  time, since we do one scan through both  and .  The
additive  term is absorbed in all but a constant
number of levels near the bottom of , where .  Thus, the string generation
algorithm described above requires  amortized time, when we consider that each level in
 can split during an insertion.

When a split occurs in , we must also do a batched update on the
dynamic string , where  is the level of .  To do
this, we make use of the batched insertion operation from
Lemma~\ref{lem:smallalphabet}.  When , where  is the value in Lemma~\ref{lem:smallalphabet}, we can
replace the  values representing 
with  in  time.  However, in the
alternative case, when  is small, we just directly insert
and delete values into  in  time per
operation.  As with the string generation algorithm, the case where
 is too small for batched updates only occurs in a constant
number of bottom levels of .  Thus, the overall cost for updating
 for every level in  in which a node is split takes
 amortized time.

Finally, we consider the more common case where  does not split
during the insertion, and how to update .  Consider the update
path in , and an arbitrary node  on this path.  We can update
the searchable partial sums structure in  in  time in the
worst case by Lemma~\ref{lem:RRR}.  If  is split, then the cost of
rebuilding the searchable partial sums structure is absorbed by the
cost of rebuilding .  The matrix structures can be rebuilt in
 amortized time per internal node on the update path by
Lemma~\ref{lem:matrix-struct}, or  amortized
time per ranking tree.  Each conceptual leaf in  takes  time to update by Lemma~\ref{lem:smallalphabet} --- since
we must update the dynamic string --- but there are at most two leaves
updated per ranking tree.  Overall we get that the cost of each update
is  amortized time.  
\end{proof}

\section{Dynamic Arrays\label{sec:dynarray}}

In this section, we show how to adapt Theorem~\ref{thm:main} for
problem of maintaining a dynamic array  of values drawn from a
bounded universe .  A query consists of a range in the
array, , along with an integer , and the output is the
-th smallest value in the subarray .  Inserting a value
into position  shifts the position of the values in positions
 to , and deletions are analogous.  We present
the following theorem:

\begin{theorem}
\label{thm:dynarray}
Given an array  of values drawn from a bounded universe
, there is an  bit
data structure that can support range selection queries on  in
 time,
and insertions into, and deletions from,  in  amortized time.
\end{theorem}


\begin{proof}
  The data structure is roughly the same as the tree  from
  Theorem~\ref{thm:main}, except that now we need a few extra
  techniques to avoid paying for more than a constant number of
  pointers.  The first idea is to use a generalized wavelet tree 
  with fan out  over the universe , instead of the original weight balanced B-tree ,
  (c.f., Ferragina et al.~\cite{FMMN04}).  The tree  has height
  , and, as in the tree , we
  store dynamic strings  at each level in , as well as
  ranking trees for each node of .  The reason we cannot afford to
  increase the branching factor beyond  is that the cost of a search in the ranking tree during a
  \emph{bad case} (see the description of the \emph{faster method}
  from Section~\ref{sec:answering}) would dominate the query cost: if
  the fan out of  is , then the total time in bad cases can be
  .

  Another issue is that the pointers to the ranking trees stored in
  each node of  occupy too much space: the lowest level in  in
  which we store ranking trees has  nodes, and therefore  bits are required for
  pointers to the roots of the ranking trees.  However, since the
  maximum number of bits occupied by ranking trees at any level is at
  most , which is  --- not counting the pointers to their
  roots --- we can use the same technique as in
  Lemma~\ref{lem:space-2} and group all the ranking trees at a given
  level in  into a fixed memory area of size .  Thus, we can
  replace all of the  bit pointers to the roots of the ranking
  trees with  bit pointers, and the space for pointers to
  the ranking trees becomes :
  one pointer to the fixed memory area per level in the tree.  We also
  need  bits to store the pointers
  to the dynamic strings at each level.  At this point, we can use the
  technique of M{\"a}kinen and Navarro~\cite{MN06} to further reduce
  this to  bits.

  Finally, since we are working solely with ranks rather than
  -coordinates, we can discard the red-black tree .  To
  analyze the total space cost we sum the space required by the
  dynamic strings and the ranking trees at each level in .  Thus,
  the total number of bits required is:

\noindent
By the same arguments presented in~\cite{FMMN04}, this simplifies to:

\end{proof}

\section{Concluding Remarks}
In the same manner as Brodal et al.~\cite{BGJS10}, the data structure
we presented can also support orthogonal range counting queries in the
same time bound as range selection queries.  We note that the
cell-probe lower bounds for the static range median and static
orthogonal range counting match~\cite{P07,JL11}, and --- very recently
--- dynamic weighted orthogonal range counting was shown to have a
cell-probe lower bound of  query time
for any data structure with polylogarithmic update time~\cite{L11}.
In light of these bounds, it is likely that 
time for range median queries is optimal for linear space data
structures with polylogarithmic update time.  However, it may be
possible to do better in the case of dynamic range selection, when , for any , using an adaptive data
structure as in the static case~\cite{JL11}.

\paragraph{Acknowledgements:} We would like to thank Gelin Zhou for
pointing out an error in the preliminary version, in the proof of
Theorem 2.

\bibliographystyle{splncs03} \bibliography{median}


\end{document}
