

\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}              

\usepackage[dvipsnames]{xcolor}
\newcommand{\red}[1]{{\color{red}#1}}
\newcommand{\todo}[1]{{\color{red}#1}}
\newcommand{\TODO}[1]{\textbf{\color{red}[TODO: #1]}}


 
\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,citecolor=cvprblue]{hyperref}
\usepackage{multirow}
\DeclareUnicodeCharacter{2212}{-}

\def\paperID{5611} \def\confName{CVPR}
\def\confYear{2024}

\title{On-the-Fly Guidance Training for Medical Image Registration }

\author{Yicheng Chen \thanks{Equal contribution}\\
Tongji University \\
    Shanghai, China\\
    {\tt\small 2053186@tongji.edu.cn} 
    \and
    Shengxiang Ji \footnotemark[1]\\
    Huazhong University of Science and Technology\\
    Wuhan, China\\
    {\tt\small u202015362@hust.edu.cn} 
    \and
    Yuelin Xin \footnotemark[1]\\
    University of Leeds\\
    Leeds, UK\\
    {\tt\small sc20yx2@leeds.ac.uk} 
    \and
    Kun Han\\
    University of California, Irvine\\
    Irvine, CA, USA\\
    {\tt\small  khan7@uci.edu}
    \and
    Xiaohui Xie \thanks{Corresponding author}\\
    University of California, Irvine\\
    Irvine, CA, USA\\
    {\tt\small xhx@ics.uci.edu}
}

\begin{document}
\maketitle
\begin{abstract}



This research explores a novel approach in the realm of learning-based image registration, addressing the limitations inherent in weakly-supervised and unsupervised methods. Weakly-supervised techniques depend heavily on scarce labeled data, while unsupervised strategies rely on indirect measures of accuracy through image similarity. Notably, traditional supervised learning is not utilized due to the lack of precise deformation ground-truth in medical imaging. Our study introduces a unique training framework with \textbf{On-the-Fly Guidance} (OFG) to enhance existing models. This framework, during training, generates pseudo-ground truth a few steps ahead by refining the current deformation prediction with our custom optimizer. This pseudo-ground truth then serves to directly supervise the model in a supervised learning context. The process involves optimizing the predicted deformation with a limited number of steps, ensuring training efficiency and setting achievable goals for each training phase. OFG notably boosts the precision of existing image registration techniques while maintaining the speed of learning-based methods. We assessed our approach using various pseudo-ground truth generation strategies, including predictions and optimized outputs from established registration models. Our experiments spanned three benchmark datasets and three cutting-edge models, with OFG demonstrating significant and consistent enhancements, surpassing previous state-of-the-arts in the field. OFG offers an easily integrable plug-and-play solution to enhance the training effectiveness of learning-based image registration models. Code at \url{https://github.com/miraclefactory/on-the-fly-guidance}.

\end{abstract}
 \section{Introduction}
\label{sec:intro}



\begin{figure}[t]
\begin{center}
   \includegraphics[width=\linewidth]{imgs/hero.png}
\end{center}
   \caption{Loss landscape comparison between TransMorph with OFG and TransMorph without OFG on 2 datasets, (a)-(b), (d)-(e). The vertical axis represents the loss value, and the horizontal axes represent two principle directions in the parameter space. The landscapes illustrate the effect of OFG on the smoothness and convexity of the optimization surface. OFG in (a) and (d) produce much flatter loss landscapes, indicating improved trainability and better training outcomes, clearly shown in (c) and (f).}
   \label{fig:hero}
\end{figure}

Medical image registration plays a crucial role in various aspects of medical image analysis and finds numerous applications in modern medicine. Essentially, it involves the challenge of determining transformations, represented as a deformation field, to align two medical images (such as volumetric MRIs) in a manner that maximizes their visual similarity. Two primary approaches are commonly employed to tackle this challenge: optimization-based methods and learning-based methods. Traditionally, optimization-based methods like \cite{AVANTS200826, BAJCSY19891, 1175091}, iteratively enhance the deformation field by incorporating mathematical constraints. More recently, as learning-based methods, like those presented in \cite{Chen_2022, chen2021vitvnet}, have gained prominence, the field of image registration has swiftly embraced these techniques, which directly predict deformation fields from pairs of fixed and moving images.



Nevertheless, learning-based methods encounter a significant challenge. The two prevailing training approaches for deep learning registration models — namely weakly-supervised and unsupervised learning — each come with distinct advantages and drawbacks. Weakly-supervised learning, leveraging segmentation labels, typically produces superior registration outcomes \cite{Balakrishnan_2019}, but the process of labeling datasets can be resource-intensive. In contrast, unsupervised learning eliminates the need for labeled data but strives to derive an accurate deformation field by comparing image similarities in the absence of pseudo-ground truth. Naturally, a pivotal question emerges: \textit{Can we discover a training framework that avoids manually labeled ground truth while harnessing the advantages of direct supervision?}

In this paper, we introduce a unified framework with on-the-fly guidance (OFG) to incorporate supervised learning and enhance the performance of learning-based image registration methods. OFG employs instance-specific optimization to dynamically generate pseudo-ground truth during the training steps, using these optimized results to supervise image registration models. Our training framework adopts a novel hybrid approach that integrates direct prediction with iterative refinement, specifically tailored for the training phase. The process unfolds in two distinct but interconnected stages. In the prediction stage, the model being trained predicts a deformation field $\phi_{pre}$ during the forward pass. Subsequently, in the optimization stage, $\phi_{pre}$ is input to the optimizer module, which iteratively refines it, yielding an optimized deformation field $\phi_{opt}$. Importantly, this optimized deformation field serves as a pseudo-label for training. The model is supervised through direct supervision between the optimized field and the initially predicted field: $MSE(\phi_{pre}, \phi_{opt})$, guiding the model's training alongside other regularization and loss functions.

Pseudo-supervision is facilitated through proposed on-the-fly guidance, a critical training technique that offers incremental supervision, guiding the model progressively toward convergence. Instead of providing the model with the ultimately optimized solution, we optimize the currently predicted deformation over limited (10) steps to derive a pseudo-ground truth as direct supervision, without adding too much overhead to the existing training paradigm. Importantly, by supplying incremental guidance alongside the training process, OFG mitigates the model's vulnerability to local minima, resulting in enhanced training outcomes. The integration of image registration models with on-the-fly guidance enables a more nuanced and self-improving training regimen. We also compared OFG with other pseudo-supervision approaches, such as self-training, which utilizes the prediction or optimized prediction from pre-trained models. OFG consistently and significantly outperforms these methods, demonstrating the priority of our proposed framework.

The main contributions of our work are summarized as follows:
\begin{itemize}
    \item We introduce OFG, a unified framework designed to enhance the performance of existing image registration methods. This framework incorporates both optimization and supervised learning into the training process while maintaining the efficiency of these methods during inference.
    \item The optimized pseudo-ground truth, generated iteratively during the training process, provides a more direct target for image registration models. Additionally, the on-the-fly guidance establishes a self-improving relationship between the registration model and the optimizer module.
    \item Through comprehensive benchmarking across various models and datasets, our approach consistently outperforms baseline models, achieving superior performance compared to previous state-of-the-art methods.
\end{itemize}

 \begin{figure*}
    \begin{center}
      \includegraphics[width=\linewidth]{imgs/ofg.png}
    \end{center}
    \caption{The overall structure of the proposed framework. The framework is divided into two parts, the prediction stage (any registration model that can predict a deformation field), and the optimization stage. The framework uses the idea of on-the-fly guidance to integrate the optimizer into the training process. The optimizer will iteratively refine the deformation field predicted by the registration model, the derived optimized deformation field will then be used as pseudo ground truth to train the registration model.}
    \label{fig:overall architecture}
\end{figure*}

\section{Related Work}
\label{sec:formatting}

We will primarily be discussing these works in the context of medical image registration. 











\subsection{Weakly-Supervised \& Unsupervised Training}

Recent advancements have demonstrated that learning-based methods are gradually surpassing traditional optimization-based methods \cite{10.1007/978-3-540-30135-6_78, john2000voxel, patch-based, GLOCKER2008731, THIRION1998243, lddmm, Beg2005comp} in terms of performance and efficiency \cite{Lea2022IEEE, Aco2018arX, ale2021CoRR, are2022Fro}. Learning-based registration algorithms \cite{Balakrishnan_2019, dalc2018unsp, amen2018unsu, mok2020large, mok2021fast, mok2022affine, jing2021end, shi2022xmor, shen2019netw, shen2019regi, 10.1007/978-3-319-66182-7_27, yang2017quicksilver, 10.1007/978-3-319-66182-7_31} optimize the energy function in \cref{energy function} for training dataset, aiming to acquire a global representation of the images being registered. 
While traditional supervised approaches \cite{yang2017quicksilver, 10.1007/978-3-319-66182-7_27} rely on ground-trurh deformation fields typically generated through traditional registration methods,
there has been a surge in unsupervised methods \cite{Balakrishnan_2019, de_Vos_2019, shen2019netw, zhang2021lear, chen2021vitvnet, Chen_2022}. A key innovation in this domain is the spatial transformer network (STN) \cite{STN}. For instance,
VoxelMorph \cite{Balakrishnan_2019} utilizes a U-Net architecture to predict the deformation field and can utilize segmentation labels. 
Bob D. de Vos et al. \cite{de_Vos_2019} introduces a coarse-to-fine strategy in medical image registration.
ViT-V-Net \cite{chen2021vitvnet} integrates a Vision Transformer \cite{dosovitskiy2021image} block into the bottleneck of a U-Net architecture \cite{isola2018imagetoimage}. 
Lastly, TransMorph \cite{Chen_2022} combines a Swin Transformer \cite{liu2021swin} as the encoder with a ConvNet as the decoder.
Although most of these methods can leverage auxiliary segmentation information for improved accuracy\cite{Balakrishnan_2019}, such labels typically require costly manual annotations.



















\subsection{Unsupervised Training with Optimization}

Recent advancements in computer vision have seen the growing application of on-the-fly guidance frameworks, leveraging instance-specific optimization for various tasks. These include image registration \cite{uns2023MICCAI,Def2024Spr}, segmentation \cite{ins2022arx}, and human pose estimation \cite{SPIN}. In the realm of image registration, the study in \cite{fas2022Spr} effectively captures large deformations through discretized displacements coupled with a convex optimization process. \cite{uns2023MICCAI} introduces a self-supervised learning paradigm based on cyclical self-training, utilizing a feature-based differentiable optimizer. Meanwhile, \cite{Def2024Spr} presents Neural Instance Optimization (NIO) to correct biases in the deformation field caused by distribution shifts in deep-learning methods, while also incorporating prior knowledge from the training domain.

Most relevant to our work is \cite{uns2023MICCAI}, which leverages a differentiable convex discrete optimisation approach \cite{lea2022SPR} to predict refined deformation fields. This self-training approach utilizes pseudo labels to guide the training across different stages. However, a notable distinction lies in their optimizer, which is used to find a transformation with a input of the fusion of semantic and hand-crafted image features, leading to non-learnable deformation field generation. Such an approach is in contrast with the utilization of existing unsupervised methods \cite{Balakrishnan_2019,chen2021vitvnet,Chen_2022}. Additionally, unlike our OFG strategy, the method presented in \cite{uns2023MICCAI} employs pseudo labels between training stages rather than within a single training iteration. This could potentially lead to higher convergence complexity, a challenge in updating the base network for desired outcomes.
 \section{Method}\label{sec:method}

In this work, we present a two-stage training framework with the proposed on-the-fly guidance (OFG) using pseudo-ground truth, which embeds optimization and supervised learning in the training of image registration models. In the following sections, we will discuss the overall structure of OFG, the key ideas and insights behind our design, alongside the implementation details of our method. In the following sections, $I_{m}$ and $I_{f}$ denote the moving image and fixed image respectively, $\phi_{pre}$ and $\phi_{opt}$ denotes the predicted deformation field and the optimized deformation field.

\subsection{Overall Structure}\label{sec:optron architecture}

\cref{fig:overall architecture} presents the overall structure of the proposed two-stage training framework. 

\textbf{Prediction Stage.} This stage consists of a learning-based registration model. The registration model takes a fixed image $I_{f}$ and a moving image $I_{m}$ and predicts a dense deformation field $\phi$ for each image pair $I_{f}$ and $I_{m}$, i.e.,
\begin{equation}
    F_{\theta}(I_{f}, I_{m}) = \phi
\end{equation}
where $\theta$ denotes the parameters of the registration network. 
Since OFG is a unified training framework, the prediction stage can utilize the desired existing learning-based registration model that predicts a deformation field. In our experiments, we used several popular models, such as VoxelMorph \cite{Balakrishnan_2019}, ViT-V-Net \cite{chen2021vitvnet} and TransMorph \cite{Chen_2022} in the prediction stage.


\textbf{Optimization Stage.} The optimization stage utilizes the proposed optimizer to iteratively refine the deformation field $\phi_{pre}$ predicted from the current training step by several steps (10 in our default setting). Subsequently, the optimized deformation field $\phi_{opt}$ is used as the pseudo-ground truth to provide supervision for the current predicted deformation during the training, forming a feedback loop between the prediction model and the optimizer module. 

















































\subsection{Training with Pseudo Ground Truth}\label{method:Pse}


Diverging from conventional image registration methods that rely on indirect supervision due to the absence of ground truth deformation fields, our approach involves leveraging pseudo labels generated by the optimizer mentioned earlier, providing structured and direct guidance. Within our study, we explore multiple methods for generating pseudo-ground truth. The most straightforward approach involves using the predictions from the pre-trained model as pseudo labels, akin to previous knowledge distillation methods. However, this method has a limitation: the pre-trained model's performance sets an upper bound for the current model. Another option is to iteratively optimize the predicted deformation from the pre-trained models until convergence, using the ultimately optimized deformation field as the pseudo-ground truth. This has the potential for improved performance but faces challenges due to the unique nature of image registration. Unlike tasks such as image segmentation, where predicted results align closely with the input image, the registration model must compare features from both input images to generate a reasonable deformation field. We argue that directly employing the ultimately optimized deformation offers minimal improvement, as evidenced by the substantial discrepancy between predicted deformation and pseudo ground truth during training, as demonstrated in the experiment section. Consequently, we introduce a novel method for pseudo-ground truth generation, incorporating on-the-fly guidance, which will be detailed in the next section.

\begin{figure}[t]
    \begin{center}
\includegraphics[width=0.9\linewidth]{imgs/self-improving-2.png}
    \end{center}
   \caption{An illustration of the self-improving on-the-fly guidance, showing a tight integration between the prediction stage and the optimization stage.}
   \label{fig:self-improving}
\end{figure}

\subsection{On-the-Fly Guidance}\label{method:Tra}
Rather than relying on a fixed pseudo ground truth derived from either the pre-trained model's prediction or an ultimately optimized deformation, our approach introduces on-the-fly guidance. This dynamic supervision evolves alongside the training process to address discrepancies between pseudo labels and current predictions. In each training step, we utilize the current predicted deformation field as input for an online optimizer, subjecting it to optimization for a limited number of steps (typically 10 in the default setting). This approach offers two advantages: firstly, the minimal number of optimizations incurs acceptable overhead during training, and secondly, the optimized deformation serves as an attainable goal for the ongoing training step, providing more direct guidance for optimizing model parameters. In essence, on-the-fly guidance delivers incremental supervision, offering step-by-step and targeted guidance for the model. Moreover, this strategy possesses inherent self-improvement characteristics. A well-estimated deformation field from the registration model provides a superior initialization for the optimizer, leading to a better-optimized deformation field. This improved deformation field, in turn, offers enhanced supervision back to the model, establishing a positive feedback loop between prediction and optimization. (\cref{fig:self-improving}).

\subsection{Online Optimizer}\label{method:Opt}
An efficient and effective optimizer is the key to on-the-fly guidance. We explored three different optimization strategies: network-based optimization, downsampled optimization, and the proposed optimizer as shown in \cref{fig:overall architecture} (b). The proposed design achieves the best performance (see \cref{tab:ins} and \cref{tab:ablation}) due to its instance-specific optimization strategy and high degree of freedom for parameter updating. The detail of the other two optimizers would be introduced in Sec. \ref{sec:ablation_study}. 

The proposed optimizer is simple yet powerful, taking in the deformation field generated by the prediction model as its initial parameters and optimize it as the pseudo labels. Internally, it contains a Spatial Transformer Network (STN) \cite{STN}, which introduces no additional parameter. Consequently, the only updatable parameters in the optimizer is the deformation field. During an optimization iteration, the current deformation field is applied to the moving image through the Spatial Transformer, yielding a warped image. Using the warped and the fixed image, an energy function will evaluate the discrepancy between the warped moving image and the target image, and also the distortion of the deformation field. This discrepancy is backpropagated using methods like Adam \cite{kingma2017adam} or Stochastic Gradient Descent (SGD), this essentially updates the deformation field, i.e.,
\begin{equation}
    \phi_{opt}^{(n+1)} = \phi_{opt}^{(n)} - \eta \nabla E_{opt}
\end{equation}
where $n$ denotes the iteration step, $\eta$ is the learning rate, and $\nabla E_{opt}$ represents the gradient of the optimization energy function, the detail of its implementation will be discussed later.

It is important to note that the optimization stage only serves its propose as the provider of supervision during training. The optimizer will not be used in inference time.







\subsection{Implementation Detail}

\textbf{Overall Loss Function.} The training of the registration model utilizes a composite loss function that combines the principles of supervision by pseudo-ground truth with regularization. The model learns by minimizing the discrepancy between the predicted deformation field $\phi_{pre}$, and the optimized deformation field $\phi_{opt}$, which is quantified using MSE. Simultaneously, a regularization term $L_{reg}$ is incorporated to encourage a smooth deformation field. The overall loss implementation is as follows:
\begin{equation}
    L_{all} = \frac{1}{n} \sum (\phi_{pre} - \phi_{opt})^2 + \lambda L_{reg}
    \label{loss-all}
\end{equation}
In this formula, $L_{all}$ is the overall loss, where the first term is the MSE-based supervision and the second term represents the regularization loss, with $\lambda$ acting as the regularization weight. For our model, $\lambda$ is empirically set to 0.02 to ensure an optimal balance between fidelity of the deformation fields and the regularization constraint. The regularization loss is implemented as follows:

\begin{equation}
    L_{reg}(\phi)=\sum_{p\in\Omega}||\nabla\phi(p)||^2
    \label{loss-reg}
\end{equation}









\textbf{Optimizer Energy Function.} 
The energy function to be minimized in the optimizer module consists of two terms: an image similarity loss term that computes the difference between the warped image $I_{m }\circ \phi$ and fixed image $I_{f}$ and a regularization loss term that imposes smoothness in $\phi$:
\begin{equation}
    E_{opt}(I_{m},I_{f},\phi)=LNCC(I_{f}, I_{m}\circ\phi)+L_{reg}(\phi)
    \label{energy function}
\end{equation}
where $\circ$ represents the transformation function which warps $I_{m}$ using $\phi$. The regularization term we used is the same as \cref{loss-reg} and the similarity metric we used is the local normalized cross-correlation (NCC) between warped image $I_m\circ\phi$ and fixed image $I_f$:
\begin{equation}
\begin{scriptsize}
\begin{aligned}
    &LNCC(I_f,I_m\circ\phi)=\\
    &\sum_{p\in\Omega}\frac{(\sum_{p_i}(f(p_i)-\hat{f}(p))([I_m\circ\phi](p_i)-[\hat{I}_m\circ\phi](p)))^2}{(\sum_{p_i}(f(p_i)-\hat{f}(p))^2)(\sum_{p_i}([I_m\circ\phi](p_i)-[\hat{f}_m\circ\phi](p))^2)}
\end{aligned}
\end{scriptsize}
\label{NCC-function}
\end{equation}
where $\hat{I}_f(p)$ and $\hat{I}_m(p)$ represent the mean voxel value within a local window of size $n^3$ centered at voxel $p$.



 \section{Experiments}\label{sec:exp}

\begin{table*}[t]
    \begin{center}
    {\small{
    \begin{tabular}{llccccc}
\toprule
    Datasets & Methods & Base. DSC $\uparrow$ & \textbf{OFG DSC} $\uparrow$ & Base. $\% |J_{\phi}| < 0$ $\downarrow$ & \textbf{OFG $\mathbf{\% |J_{\phi}| < 0}$} $\downarrow$ & Infer. Time (s)\\
    \midrule
    \multirow{5}{*}{IXI \cite{ixi}} 
    & SyN \cite{AVANTS200826} & 0.647 & N/A & 1.96e-6 & N/A & 277(CPU) \\
    & NiftyReg \cite{niftyreg} & 0.585 & N/A & 0.029 & N/A & 22.4(CPU) \\
    \noalign{\smallskip}
    \cline{2-7}
    \noalign{\smallskip}
    & VoxelMorph \cite{Balakrishnan_2019} & 0.714 & \textbf{0.737}(+2.3\%) & 1.398 & \textbf{0.516}(-0.882) & 0.061(GPU) \\
    & ViT-V-Net \cite{chen2021vitvnet} & 0.716 & \textbf{0.738}(+2.2\%) & 1.543 & \textbf{0.545} (-0.998) & 0.615(GPU) \\
    & TransMorph \cite{Chen_2022} & 0.744 & \textbf{0.760}(+1.6\%) & 1.433 & \textbf{0.794} (-0.639) & 0.114(GPU) \\
    \midrule
    \multirow{5}{*}{OASIS \cite{10.1162/jocn.2007.19.9.1498}} 
    & SyN \cite{AVANTS200826} & 0.769 & N/A & 1.58e-4 & N/A & 258(CPU) \\
    & NiftyReg \cite{niftyreg} & 0.762 & N/A & 0.011 & N/A & 25.0(CPU) \\
    \noalign{\smallskip}
    \cline{2-7}
    \noalign{\smallskip}
    & VoxelMorph \cite{Balakrishnan_2019} & 0.788 & \textbf{0.794}(+0.6\%) & 0.911 & \textbf{0.490} (-0.421) & 0.061(GPU) \\
    & ViT-V-Net \cite{chen2021vitvnet} & 0.794 & \textbf{0.809}(+1.5\%) & 0.887 & \textbf{0.487} (-0.400) & 0.646(GPU) \\
    & TransMorph \cite{Chen_2022} & 0.818 & \textbf{0.818}(=) & 0.765 & \textbf{0.517} (-0.248) & 0.160(GPU) \\
    \midrule
    \multirow{5}{*}{LPBA40 \cite{lpba}} 
    & SyN \cite{AVANTS200826} & 0.703 & N/A & 1.18e-4 & N/A & 172(CPU) \\
    & NiftyReg \cite{niftyreg} & 0.691 & N/A & 1.13e-3 & N/A & 22.8(CPU) \\
    \noalign{\smallskip}
    \cline{2-7}
    \noalign{\smallskip}
    & VoxelMorph \cite{Balakrishnan_2019} & 0.658 & \textbf{0.666}(+0.8\%) & 0.288 & \textbf{0.023} (-0.205) & 0.046(GPU) \\
    & ViT-V-Net \cite{chen2021vitvnet} & 0.663 & \textbf{0.672}(+0.9\%) & 0.390 & \textbf{0.112} (-0.278) & 0.446(GPU) \\
    & TransMorph \cite{Chen_2022} & 0.678 & \textbf{0.684}(+0.6\%) & 0.438 & \textbf{0.150} (-0.288) & 0.327(GPU) \\
    \bottomrule
    \end{tabular}
    }}
    \end{center}
\caption{Evaluation results for different methods on various datasets. The OFG architecture provides significant and substantial improvement on the unsupervised learning-based methods. These results validate OFG's effectiveness and generalizability without compromising on inference efficiency.} \label{tab:results}
\end{table*}


\subsection{Experiment Conditions}


\textbf{Dataset and Preprocessing.} This study employs three public datasets: IXI \cite{ixi}, OASIS \cite{10.1162/jocn.2007.19.9.1498}, and LPBA40 \cite{lpba}. For all datasets, we conduct standard preprocessing procedures on structural brain MRI data using FreeSurfer \cite{freesurfer}, including skull stripping, resampling, and affine transformation. The volume dimension is $160 \times 192 \times 224$ for IXI and OASIS, and $160 \times 192 \times 160$ for LPBA40. Specifically, for IXI, we randomly selected 200 volumes for training and 20 volumes for validation. For OASIS, the selection includes 200 for training and 19 for validation. And for LPBA40, we used 30 volumes for training, 9 volumes for validation, and 1 volume as the atlas.

\textbf{Evaluation Metrics.} When assessing our approach, we employed two widely-used metrics. Firstly, we measured the volume overlap of anatomical segmentations, quantified using Dice score (DSC) \cite{Balakrishnan_2019, mul1989com}. This metric offers insights into the accuracy of registration. Additionally, we evaluate the regularity of the deformation fields through the Jacobian matrix, denoted as $J_{\phi}(p) = \nabla\phi(p)$. Specifically, we calculate the count of non-background voxels for which $\% |J_{\phi}| < 0$, indicating regions where the deformation deviates from being diffeomorphic \cite{afas2007neu}. This helps assessing the deformation's spatial consistency.

\textbf{Baseline Models.} We validated our proposed framework based on various registration models that have previously demonstrated state-of-the-art performance in registration tasks. This comparison included two traditional methods and multiple learning-based methods:
\begin{itemize}
    \item SyN \cite{AVANTS200826}: For all datasets, mean squared error (MSE) was used as the objective function, along with three scales with 160, 80, 40 iterations, respectively.
    \item NiftyReg \cite{niftyreg}: The sum of squared difference (SSD) was used as the objective function. We used three scales with 300 iterations each by default.
    \item VoxelMorph \cite{Balakrishnan_2019}: We adhered to the default parameters outlined for VoxelMorph-1 proposed in \cite{Balakrishnan_2019}.
    \item ViT-V-Net \cite{chen2021vitvnet}: We applied the default network hyperparameter settings suggested in \cite{chen2021vitvnet}.
    \item TransMorph \cite{Chen_2022}: We applied the default hyperparameter settings of TransMorph in \cite{Chen_2022}.
\end{itemize}

\textbf{Experiment Settings.} All models were trained on NVIDIA RTX 4090 for 500 epochs using Adam \cite{adam2014arx}, with an initial learning rate of 1e-4 and a batch size of 1. 
For the optimizer module in our architecture, we used an initial learning rate of $0.1$, coupled with an optimization iteration count of $10$ during training.























\begin{figure*}[t]
    \label{fig:results}
    \begin{center}
       \includegraphics[width=0.9\linewidth]{imgs/results.png}
    \end{center}
    \caption{Visualization of registration results. This is an arbitrary demo extracted from the comparison results between baseline TransMorph, ViT-V-Net (row 2) and their respective model trained with OFG (row 1), demo from the IXI dataset \cite{ixi}}
    \label{fig:vis-results}
\end{figure*}

\begin{figure*}[t]
    \begin{center}
       \includegraphics[width=0.85\linewidth]{imgs/training_lpba_2.png}
    \end{center}
    \caption{Visualization of training process vs. validation DSC for models on LPBA40. The self-training strategy utilizes deformation fields from a pre-trained network as pseudo-ground truth. In contrast, optimized self-training iteratively refines the deformation these fields, and then uses them as pseudo-ground truth. Our proposed method is highlighted for its superior outcomes. Notably, self-training schema underperforms, primarily due to complexities in convergence.}
    \label{fig:training}
\end{figure*}

\subsection{Image Registration Results}

We conducted extensive experiments on the three datasets to showcase the effectiveness of our proposed framework. Moreover, to demonstrate the plug-and-play versatility of our approach, we implemented OFG on three learning-based registration networks: VoxelMorph \cite{Balakrishnan_2019}, ViT-V-Net \cite{chen2021vitvnet}, and TransMorph \cite{Chen_2022}.


\textbf{OFG on IXI.} OFG considerably increased DSC over the original learning-based models, as evidenced in \cref{tab:results}. Notably, it outperformed the previous state-of-the-art, TransMorph \cite{Chen_2022}, on the IXI dataset, achieving a +1.6\% improvement in DSC and halving the percentage of non-diffeomorphic voxels ($|J_{\phi}| < 0$). This suggests OFG's capability to not only elevate model performance but also to prevent the generation of over-sharpened deformation fields, which can be visually observed by comparing the actual registration results as shown in \cref{fig:vis-results}.
Furthermore, OFG substantially improved other learning-based methods, with a +2.3\% increase on DSC for VoxelMorph \cite{Balakrishnan_2019} and a +2.2\% increase on DSC for ViT-V-Net \cite{chen2021vitvnet}, further validating the effectiveness and generalizability of our method.




\textbf{OFG on LPBA40.} LPBA40 \cite{lpba} is another dataset we used to validate our method. Evaluation results are presented in \cref{tab:results}. With only 40 volumes, learning-based models can easily overfit on this dataset. This can be partially observed in the convergence phase in \cref{fig:training}.
On a small dataset, the extra supervision provided by our method can be crucial due to the lack of training data. Supervision that introduces greater challenges into the training process can significantly enhance the model's learning, ultimately yielding superior results.



\textbf{OFG on OASIS.} OASIS \cite{10.1162/jocn.2007.19.9.1498} is another commonly used dataset in medical image registration. According to the results in \cref{tab:results}, although all methods generally achieve higher DSC on this dataset, it's noteworthy that OFG yielded no noticeable improvement when applied to TransMorph on the OASIS dataset. It is likely due to the OASIS dataset presents a less stringent challenge for TransMorph. To validate this hypothesis, we employed image similarity loss as a metric; a lower loss score indicates a dataset is less challenging for a given method. This was substantiated by comparing the convergence loss of all models across various datasets, as detailed in \cref{tab:converg-loss}. Among the diverse combinations of three models and three datasets assessed, TransMorph on the OASIS dataset demonstrated the lowest convergence loss, aligning with our hypothesis.







\begin{table}
\begin{center}
{\small{
    \begin{tabular}{l|ccc}
\toprule
    Converg. Loss & IXI \cite{ixi} & OASIS \cite{10.1162/jocn.2007.19.9.1498} & LPBA40 \cite{lpba} \\
    \midrule
    VoxelMorph \cite{Balakrishnan_2019} & -0.222 & -0.259 & -0.183 \\
    ViT-V-Net \cite{chen2021vitvnet} & -0.242 & -0.266 & -0.215 \\
    TransMorph \cite{Chen_2022} & -0.262 & \textbf{-0.283} & -0.232 \\
    \bottomrule
    \end{tabular}
}}
\end{center}
\caption{Comparison between the 3 models' convergence losses on 3 datasets. Note that the loss function settings were the same. For TransMorph on OASIS, the convergence loss is clearly the lowest.}
\label{tab:converg-loss}
\end{table}



\subsection{Training Guided by Pseudo Ground Truth}
To evaluate the effectiveness of pseudo-ground truth described in \cref{method:Pse}, we compared the loss landscapes of TransMorph and TransMorph w. OFG on the IXI and LPBA40 datasets.
Following the loss landscape visualization method described in \cite{li2018visualizing, goodfellow2015qualitatively, im2017empirical}, we chose a set of pre-trained model's parameters $\theta^{\ast}$ as the center point in the graph, perturbed $\theta^{\ast}$ in two random directions 
and computed the average loss value on five samples from the validation set at each location. 
As shown in \cref{fig:hero}, the loss landscape of TransMorph w. OFG is substantially smoother and convex than that of other strategies. The flatter loss landscape of TransMorph w. OFG suggests better trainability, avoidance of local minima and better performance, which further demonstrates the advantage of our training method guided by pseudo label.

\begin{table}
\begin{center}
{\small{
    \begin{tabular}{lccc}
\toprule
     & DSC & $\% |J_{\phi}| < 0$ & Optimize Time (s) \\
    \midrule
    VoxelMorph-1 & 0.691 & 0.456 & 1.174 \\
    VoxelMorph-2 & 0.690 & 0.383 & 2.314 \\
    VoxelMorph-5 & 0.693 & 0.385 & 5.856 \\
    \midrule
    \textit{Ours} & \textbf{0.731} & 0.503 & 4.697 \\
    \bottomrule
    \end{tabular}
}}
\end{center}
\caption{Comparison between instance-specific optimizer (OFG) and network-based optimizer on IXI dataset\cite{ixi}. The outcomes presented are derived from the initial 200 epochs.}
\label{tab:ins}
\end{table}

\subsection{On-the-fly Guidance Strategy}
To evaluate the effectiveness of our on-the-fly guidance strategy described in \cref{method:Tra}, we conducted a comparative analysis against an alternative approach. This approach utilized deformation fields, initially set by a well-trained network and subsequently refined iteratively by the OFG optimizer module, as pseudo-ground truth to guide training from scratch. The comparative results are detailed in \cref{fig:training} between the green line and the blue line. In contrast to our method, although initial learning occurs in the alternative strategy, it faces challenges in terms of convergence complexity. This comparison effectively demonstrates the superiority and efficiency of on-the-fly guidance strategy.






\subsection{Instance-specific Optimization}
To evaluate the efficacy of instance-specific optimization described in \cref{method:Opt}, we conducted a comparative study on a distinct optimizer design. An in-depth discussion of this optimizer, termed the Network-based optimizer, is provided in \cref{sec:ablation_study} Paragraph 1. VoxelMorph-$n$ means repeating $n$ epochs before providing pseudo-ground truth. The results, presented in \cref{tab:ins}, effectively demonstrate the superiority of instance-specific optimization within the OFG architecture. This optimizer module not only achieves the highest DSC, but also maintains a feasible optimization time.




\begin{figure}[t]
    \begin{center}
       \includegraphics[width=\linewidth]{imgs/ablation_3.png}
    \end{center}
    \caption{Ablation results. This evaluation investigates the impact of integrating unsupervised learning elements into our OFG system on IXI (left) and LPBA40 (right, 30 epochs). It reveals a notable decrease in performance with increased reliance on unsupervised methods, showing a 1.6\% and 1.9\% decline with TransMorph, respectively.}
    \label{fig:mix}
\end{figure}


\subsection{Ablation Study}
\label{sec:ablation_study}
\textbf{Optimizer Design.} We designed a plug-and-play optimizer module to provide a more refined deformation field. Particularly, there are various approaches to optimizer design. \cref{tab:ablation} shows the performance of different optimizer schemes. 
\begin{itemize}
    \item \textbf{Network-based Optimizer.} Network-based optimizer aims to find a general transformation applicable to all instances. In this setup, for each epoch of the baseline network, the optimizer network initially updates its parameters iteratively for all images in the optimization set. Subsequently, the baseline network learns exclusively from the pseudo deformation fields generated by the optimizer network for each image pair in the training set. 
    \item \textbf{DownSample Optimizer.} Optimizing the entire deformation field at once might be challenging \cite{han2022diff}. By downsampling the deformation field, we can decrease the number of parameters being updated in every optimization iteration, which could lead to faster optimization routines. Additionally, downsampled deformation field can provide coarse-resolution information \cite{mok2020large}, which is crucial to the smoothness of the deformation field.
\end{itemize}
We observe that most optimizer designs demonstrate their effectiveness by surpassing the performance of none-optimizer version, except for the Downsample Optimizer. 
Among the evaluated strategies, the proposed OFG optimizer module achieves the highest Dice score while maintaining practical optimization time within a training iteration.
The Downsample Optimizer, despite its acceleration of the optimization process, inadvertently compromises the quality of results. This occurs due to direct downsampling of the deformation field, resulting in a loss of fine-granularity information and higher degrees of freedom, as discussed in \cref{method:Opt}. 
For the Network-based Optimizer, although it contributes to the optimization process, the efficacy is found to be suboptimal. Furthermore, the computational intensity and optimization time is impractical in our proposed architecture. 


\textbf{Importance of Pseudo-Ground Truth.} We propose on-the-fly guidance strategy to circumvent the limitations inherent in the indirect learning mechanisms of unsupervised learning, as outlined in \cref{method:Pse}. To evaluate the effectiveness of this approach, as shown in \cref{fig:mix}, we contrast our method with two optimization strategy. Epoch-interval optimization involves the application of pseudo labels generated by the optimizer at specific epoch intervals, contrary to the continuous optimization present in our original OFG. Threshold-based optimization applies pseudo labels when a random value falls below a predetermined threshold. Moreover, we analyze Loss composition \cref{loss ratio}.
In the aforementioned three experiments, the default configuration of the OFG fully incorporates supervision using pseudo-ground truth. As the parameters diverge from this original setting, there is a proportional increase in the reliance on unsupervised learning methods.
Notably, in our analysis of the IXI dataset, we observe that our approach holds a great performance degradation with the increased incorporation of unsupervised learning elements within our approach.
Furthermore, in our exploration of loss composition, we maintain the values of $\lambda$ and $\beta$ in \cref{loss ratio} consistent with the original OFG settings, while introducing $L_{sim}$ as an auxiliary component. This inclusion, however, results in diminished focus on the superior pseudo-ground truth, thus impairing performance.

\begin{equation}
    L_{all} = \alpha L_{sim} + \lambda L_{reg} + \beta L_{opt}
    \label{loss ratio}
\end{equation}

\begin{table}
  \centering
  \small{
  \begin{tabular}{lccc}
    \toprule
    Optimizer Design &  DSC & Time & VRAM Usage \\
    \midrule
    None & 0.635 & N/A & 12.07 GB \\
    Network-based & 0.642 & 13.604 & 14.35 GB \\
    DownSample & 0.610 & \textbf{0.097} & 12.44 GB \\
    \midrule
    \textit{Ours} & \textbf{0.654} & 3.228 & 13.07 GB \\
    \bottomrule
  \end{tabular}
  }
  \caption{Ablation results of the OFG Optimizer on LPBA40 Dataset. This evaluation focuses over the initial 30 epochs.}
  \label{tab:ablation}
\end{table}



















 \section{Conclusion}







This work introduces On-the-Fly Guidance (OFG), a training framework that successfully unites learning-based methods with optimization techniques to enhance the training of learning-based registration models. Demonstrating significant improvements on benchmark datasets, outperforming existing methods, OFG has proven its effectiveness and generalizability. Future work may focus on optimizing the efficiency of the OFG training process with other optimizer designs to accelerate its adoption in practical applications. {
    \small
    \bibliographystyle{ieeenat_fullname}
    \bibliography{main}
}



\end{document}
