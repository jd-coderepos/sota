\RequirePackage{ifpdf}
\newif\ifpdf
\ifx\pdfoutput\undefined
\pdffalse
\else
\pdfoutput=1
\pdfcompresslevel=9
\pdftrue
\fi

\ifpdf
\documentclass[pdftex]{llncs}
\else
\documentclass[dvips]{llncs}
\fi




\usepackage[T1]{fontenc}
\usepackage{ae, aecompl}
\usepackage{wrapfig}
\usepackage{xspace}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{float}
\newfloat{algorithm}{t}{lop}
\usepackage[vflt]{floatflt}
\usepackage{lineno}
\usepackage[usenames,dvipsnames]{color}
\usepackage{colortbl}

\usepackage{enumitem}
\usepackage{numprint}
\ifpdf
\usepackage[pdftex]{graphicx}
\DeclareGraphicsExtensions{.pdf,.png,.mps}
\DeclareGraphicsRule{.eps}{pdf}{*}{}
\else
\usepackage[dvips]{graphicx}
\usepackage[dvips]{color}
\fi

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{bibspacing}
\usepackage{xspace}

\usepackage{fancyhdr}
\pagestyle{plain}

\setlength{\bibspacing}{1.0\baselineskip}

\renewcommand{\topfraction}{0.9}

\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\eg}{e.\,g.\xspace}
\newcommand{\Eg}{E.\,g.\xspace}
\newcommand{\ie}{i.\,e.\xspace}
\newcommand{\Ie}{I.\,e.\xspace}



\renewcommand{\floatpagefraction}{0.9}
\newtheorem{notation}[example]{Notation}
\newtheorem{app-theorem}{Example}

\newtheorem{consDefinition}[example]{Definition}
\newtheorem{consTheorem}[example]{Theorem}
\newtheorem{consProposition}[example]{Proposition}

\newcommand{\Pro}[1]{\mathbf{Pr} \left[\,#1\,\right]}
\newcommand{\pro}[1]{\mathbf{Pr} [\,#1\,]}
\newcommand{\Ex}[1]{\mathbb{E} \left[\,#1\,\right]}
\newcommand{\ex}[1]{\mathbb{E} [\,#1\,]}
\newcommand{\hit}{- [\pi]_s (H[v,s]-H[u,s])}

\newcommand{\centre}[1]{z_{#1}}
\newcommand{\centres}{Z}
\newcommand{\degree}{\operatorname{deg}}
\newcommand{\maxdeg}{\operatorname{maxdeg}}
\newcommand{\diam}{\operatorname{diam}}
\newcommand{\res}{\operatorname{res}}
\newcommand{\Res}{\operatorname{Res}}
\newcommand{\cond}{\operatorname{cond}}
\newcommand{\Cond}{\operatorname{Cond}}
\newcommand{\proxy}{\operatorname{proxy}}
\newcommand{\excond}{\operatorname{ex\_cond}}
\newcommand{\exres}{\operatorname{ex\_res}}
\newcommand{\exalg}{\operatorname{ex\_alg}}
\newcommand{\dist}{\operatorname{dist}}
\newcommand{\ord}{\operatorname{ord}}
\newcommand{\Vor}{\operatorname{Vor}}
\newcommand{\M}{\mathbf{M}}
\newcommand{\LL}{\mathbf{L}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\f}{\hat{f}}
\newcommand{\e}{\mathbf{e}}
\newcommand{\dhat}{d}
\newcommand{\llminimal}{-minimal\xspace}
\newcommand{\NP}{}
\newcommand{\disjbigcup}{\mathop{\dot{\bigcup}}} 
\newcommand{\disjcup}{\mathop{\dot{\cup}}} 
\newcommand{\bigO}{\mathcal{O}} 
\newcommand{\polylog}{\operatorname{polylog}} 

\DeclareMathOperator{\intraWeight}{\it intraWeight}
\DeclareMathOperator{\interWeight}{\it interWeight}
\DeclareMathOperator{\subtreeVol}{\it subtreeVol}

\newcommand{\iec}{\textit{i.\,e.},\xspace}
\newcommand{\egc}{\textit{e.\,g.},\xspace}
\newcommand{\etal}{\textit{et al.}\xspace}
\newcommand{\Wlog}{w.\,l.\,o.\,g.\xspace}
\newcommand{\wrt}{w.\,r.\,t.\xspace}
\newcommand{\st}{s.\,t.\xspace}
\newcommand{\cf}{cf.\xspace}

\newcommand{\dibap}{\textsc{DibaP}\xspace}
\newcommand{\pdibap}{\textsc{PDibaP}\xspace}
\newcommand{\bubble}{\textsc{Bubble}\xspace}
\newcommand{\smooth}{\textsc{Smooth}}
\newcommand{\bubfosc}{\textsc{Bubble-FOS/C}\xspace}
\newcommand{\bubfost}{\textsc{Bubble-FOS/T}\xspace}
\newcommand{\metis}{\textsc{METIS}\xspace}
\newcommand{\kmetis}{\textsc{kMeTiS}\xspace}
\newcommand{\parmetis}{\textsc{ParMETIS}\xspace}
\newcommand{\kappart}{\textsc{KaPPa}\xspace}
\newcommand{\kahip}{\textsc{KaHIP}\xspace}
\newcommand{\jostle}{\textsc{Jostle}\xspace}
\newcommand{\zoltan}{\textsc{Zoltan}\xspace}
\newcommand{\parkway}{\textsc{Parkway}\xspace}
\newcommand{\graclus}{\textsc{Graclus}\xspace}
\newcommand{\party}{\textsc{Party}\xspace}
\newcommand{\scotch}{\textsc{Scotch}\xspace}
\newcommand{\thrsh}{\xspace}
\newcommand{\trunccons}{\textsc{TruncCons}\xspace}
\newcommand{\consol}{\texttt{Consolidation}\xspace}
\newcommand{\consols}{\texttt{Consolidations}\xspace}
\newcommand{\asspart}{\texttt{AssignPartition}\xspace}
\newcommand{\assclus}{\texttt{AssignCluster}\xspace}
\newcommand{\asssd}{\texttt{AssignSubdomain}\xspace}
\newcommand{\compcen}{\texttt{ComputeCenters}\xspace}
\newcommand{\initcen}{\textsc{LoadBasedInitialCenters}\xspace}
\newcommand{\NN}{\mbox{\rm IN}}
\newcommand{\closu}[1]{\overline{#1}}
\newcommand{\djoko}{Djokovi\'{c} relation\xspace}
\newcommand{\subE}[1]{{#1}_{\mathcal{E}}}




\newcommand{\csch}[1]{\textcolor{blue}{[CS: #1]}\xspace}
\newcommand{\hmey}[1]{\textcolor{red}{[HM: #1]}\xspace}
\newcommand{\rgla}[1]{\textcolor{ForestGreen}{[RG: #1]}\xspace}
\renewcommand{\csch}[1]{}
\renewcommand{\hmey}[1]{}
\renewcommand{\rgla}[1]{}



\numberwithin{equation}{section}
\numberwithin{example}{section}
\numberwithin{table}{section}

\newcount\shortyear\newcount\shorthour\newcount\shortminute
\shorthour=\time\divide\shorthour by 60\shortyear=\shorthour
\multiply\shortyear by 60\shortminute=\time\advance\shortminute by
-\shortyear
\shortyear=\year\advance\shortyear by -1900

\def\zeit{\number\shorthour:\ifnum\shortminute<10 0\number\shortminute
\else\number\shortminute\fi}

\def\rightmark{{\small \today, \zeit{}}}

 \def\rightmark{}    

\begin{document}
\date{}


\title{Tree-based Coarsening and Partitioning \\ of Complex Networks}


\author{Roland Glantz \and Henning Meyerhenke \and Christian Schulz}

\institute{Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany}
\maketitle
\vspace{-4mm}
\begin{abstract}
Many applications produce massive complex networks whose
  analysis would benefit from parallel processing.  Parallel
  algorithms, in turn, often require a suitable network partition.  For solving optimization tasks such as
  graph partitioning on large networks, multilevel methods are
  preferred in practice. Yet, complex networks pose  challenges to
  established multilevel algorithms, in particular to their coarsening
  phase.  

One way to specify a (recursive) coarsening of a graph is to
  rate its edges and then contract the edges as prioritized by the
  rating.  In this paper we (i) define weights for the edges of a
  network that express the edges' importance for connectivity, (ii)
  compute a minimum weight spanning tree  \wrt these weights, and
  (iii) rate the network edges based on the conductance values of
  's fundamental cuts. To this end,  we also (iv) develop the first optimal
  linear-time algorithm to compute the conductance values of
  \emph{all} fundamental cuts of a given spanning tree.


We integrate the new edge rating into a leading multilevel graph
  partitioner and equip the latter with a new greedy postprocessing
  for optimizing the maximum communication volume (MCV).  Experiments
  on bipartitioning frequently used benchmark networks show that the
  postprocessing already reduces MCV by 11.3\%. Our new edge rating
  further reduces MCV by 10.3\% compared to the previously best rating
  with the postprocessing in place for both ratings. In total, with a
  modest increase in running time, our new approach reduces the MCV of
  complex network partitions by 20.4\%.
\end{abstract}
\vspace{-4mm}

\textbf{Keywords:} Graph coarsening, multilevel graph partitioning, complex networks, 
fundamental cuts, spanning trees


\section{Introduction}
\label{sec:intro}
Complex networks such as social networks or web graphs have
become a focus of investigation recently~\cite{costa2011analyzing}.
Such networks are often scale-free, \ie they have a power-law
degree distribution with many low-degree vertices and few high-degree vertices.
They also have a small diameter (small-world property), 
so that the whole network is discovered within a few hops from any vertex.
Complex networks arise in a variety of applications; several of them generate massive data sets.
As an example, the social network Facebook currently contains a billion active 
users (\url{http://newsroom.fb.com/Key-Facts}).
On this scale many algorithmic tasks benefit from parallel processing.
The efficiency of parallel algorithms on huge networks, in turn,
is usually improved by \emph{graph partitioning} (GP).


Given a graph  and a number of blocks , the GP problem asks for a
division of  into  pairwise disjoint subsets 
(\emph{blocks}) such that no block is larger than

where  is the allowed imbalance. When GP is used for parallel processing, each 
processing element (PE) usually receives one block, and edges running between two blocks model communication
between PEs. The most widely used objective function (whose minimization is -hard) is the \emph{edge cut}, the total weight of the edges between different blocks.
However, it has been pointed out more than a decade ago~\cite{Hendrickson_graphpartitioning} that 
the determining factor for modeling the communication cost of parallel iterative graph algorithms is the
\emph{maximum communication volume} (MCV), which has received growing attention 
recently, \eg in a GP challenge~\cite{BaderMSW12dimacs}. 
MCV considers the worst communication volume taken over all blocks 
() and thus penalizes imbalanced communication:

Note that parallel processing is only one of many applications for graph partitioning; more can
be found in recent surveys~\cite{GPOverviewBook,SPPGPOverviewPaper}.

All state-of-the-art tools for partitioning very large graphs in
practice rely on the multilevel approach~\cite{SPPGPOverviewPaper}.
In the first phase a hierarchy of graphs  is built
by recursive coarsening.  is supposed to
 be very small in
size, but similar in structure to the input 
 . In the second
phase a very good initial solution for 
 is computed. In the
final phase, the solution is prolongated to the next-finer
 graph,
where it is improved using a local improvement algorithm. This
process of prolongation and local improvement is repeated up to
.


Partitioning static meshes and similar non-complex networks 
this way is fairly mature. Yet, the structure of complex networks (skewed degree
distribution, small-world property) distinguishes complex networks from traditional
inputs and makes finding small cuts challenging with current tools.

One reason for the difficulties of established multilevel graph
partitioners is the coarsening phase. Most tools rely on edge
contractions for coarsening. Traditionally, only edge weights have
guided the selection of the edges to be
contracted~\cite{karypis1998fast}. Holtgrewe
\etal~\cite{HoltgreweSS10engineering} recently presented a two-phase
approach that makes contraction more systematic by separating two
issues: An \emph{edge rating} and a \emph{matching algorithm}. The
rating of an edge indicates how much sense it makes to contract the
edge. The rating then forms the input to an approximate maximum weight
matching algorithm, and the edges of the resulting matching are
contracted.  As one contribution of this paper, we define a new edge
rating geared towards complex network partitions with low MCV.













\paragraph{Outline and Contribution.}
\label{subsec:contribution}
After the introduction we sketch the state of the art
(Section~\ref{sec:soa}) and settle necessary notation
(Section~\ref{sec:prelim}).
Our first technical contribution, described briefly in Section~\ref{sec:GP},
results from our goal to minimize MCV rather than the edge cut: We equip 
a leading multilevel graph partitioner with  greedy postprocessing that trades in small edge cuts for small MCVs.


Our main contributions follow in Sections~\ref{sec:BI} and~\ref{sec:effCond}.
The first one is a new edge rating, designed for complex networks by
combining local and non-local information. Its rationale is to find moderately
balanced cuts of high quality quickly (by means of the clustering measure
\emph{conductance}~\cite{Kannan04clustering} and its loose connection to MCV via isoperimetric graph partitioning~\cite{GradyS06isoperimetric}) and to use this information to indicate whether
an edge is part of a small cut or not. Finding such cuts is done by evaluating 
conductance for all \emph{fundamental cuts} of a 
minimum spanning tree of the input graph with carefully chosen edge weights. 
(a fundamental cut is induced by the removal of exactly one 
spanning tree edge, cf.\ Section~\ref{sec:prelim}).
The second main contribution facilitates an efficient computation of our new
edge rating. We present the first optimal linear-time algorithm to
compute the conductance values of all fundamental cuts of a spanning
tree. 


We have integrated both MCV postprocessing and our new edge rating
 into \kahip~\cite{kaHIPHomePage,sandersschulz2013}, a
state-of-the-art graph partitioner with a reference implementation of
the edge rating , that yielded the best quality for
complex networks so far (see Section~\ref{sec:soa}).


Experiments in Section~\ref{sec:results} show that greedy MCV
postprocessing improves the partitions of our complex network
benchmark set in terms of MCV by 11.3\% on average with a comparable
running time.


Additional extensive bipartitioning experiments (MCV postprocessing
included) show that, compared to , the fastest variant
of our new edge rating further improves the MCVs by 10.3\%, at the
expense of an increase in running time by a factor of
1.79. Altogether, compared to previous work on partitioning complex
networks with state-of-the-art methods~\cite{Safro2012a}, the total
reduction of MCV by our new techniques amounts to 20.4\%.




\section{State of the Art}
\label{sec:soa}
Multilevel graph partitioners such as \metis~\cite{karypis1998fast} and \kahip~\cite{kaHIPHomePage,sandersschulz2013} (more are described in recent surveys~\cite{GPOverviewBook,SPPGPOverviewPaper}) typically employ recursive
coarsening by contracting edges, which are often computed as those of a matching.
Edge ratings are important in guiding the matching
algorithm; a successful edge rating is



\noindent where the weights of the vertices  and of the edges  are given by  and , respectively~\cite{HoltgreweSS10engineering}.

To broaden the view of the myopic rating above (it does not look beyond its
incident vertices), Safro
\etal~\cite{Safro2012a} precompute the algebraic distance
~\cite{Chen2011a} for the end vertices
of each edge  and use the edge rating



\noindent For graphs with power-law degree distributions,  yields
considerably higher partition quality than ~\cite{Safro2012a}.
This is due to the fact that algebraic distance expresses a semi-local connection
strength of an edge ~\cite{Chen2011a}. Specifically,  is
computed from  randomly initialized vectors that are smoothed by a Jacobi-style
over-relaxation for a few iterations. 
The idea is that the vector entries associated with
well-connected vertices even out more quickly than those of
poorly connected vertices. Thus, a high value of 
indicates that the edge  constitutes a bottleneck and should
not be contracted. 


Another strategy for matching-based multilevel schemes in complex networks 
(\eg for agglomerative clustering~\cite{Fagginger:2013gc}) is to match unconnected
vertices at 2-hop distance in order to eliminate star-like structures.
Also, alternatives to matching-based coarsening exist, \eg
weighted aggregation schemes~\cite{ChevalierS09comparison,MeyerhenkeMS09graph}.






Pritchard and Thurimella~\cite{Pritchard2011a} use a spanning tree to
sample the {\em cycle space} of a graph in a uniform way and thus find
small cuts (consisting of a single edge, two edges or a cut vertex)
with high probability~\cite{Pritchard2011a}. Our method uses a minimum
weight spanning tree on a graph with carefully chosen edge weights. Moreover,
we sample the {\em cut-space}. The aim of the
sampling is to create a collection  of moderately balanced
cuts which form the basis of our new edge rating.



We integrate our new algorithms into \kahip~\cite{kaHIPHomePage,sandersschulz2013}.
\kahip focuses on solution quality and has been shown recently to be
a leading graph partitioner for a wide variety of graphs such as
road networks, meshes, and complex networks~\cite{dissSchulz}.
It implements several advanced multilevel graph partitioning
algorithms, meta-heuristics, and sophisticated local improvement schemes.




\section{Preliminaries}
\label{sec:prelim}
Let  be a finite, undirected, connected, and simple
graph. Its edge weights are given by . We
write  for  and extend  to
subsets of  through .

For subsets ,  of  with , the
set  consists of those edges in  that have one end
vertex in  and the other end vertex in . If, in addition to
, it holds that (i)  and
(ii) , then the pair  is called a
{\em cut} of , and  is called the {\em cut-set} of
. The weight of a cut  is given by
. The \emph{volume} of any subset  of  is
the total weight of the edges incident on  (which equals the sum over the
weighted degrees of the vertices in ):



\begin{consDefinition}[Fundamental cut, cut-set , ]~\\
\label{nota:funda_condu}
\noindent Let  be a spanning tree of , and let . If  and  are the connected components (trees) of the
graph , then  is the
fundamental cut of  with respect to  and , and



\noindent is the fundamental cut-set of  with respect to  and
. Conductance is a common quality measure in graph
clustering~\cite{Kannan04clustering}. Its value for  is



\end{consDefinition}

\section{Greedy MCV Optimization}
\label{sec:GP}
The ultimate applications we target with our graph partitioning algorithm are iterative parallel algorithms executed on complex
networks. As argued in Section~\ref{sec:intro}, the maximum communication volume (MCV)
is a more accurate optimization criterion than the edge cut.
The graph partitioner \kahip has so far solely focused on the edge
cut, though. That is why, as a new feature, we equip \kahip with a
postprocessing that greedily optimizes MCV. This postprocessing is
executed after local improvement on the finest level of the multilevel
hierarchy and works in rounds.
In each round, we iterate over all boundary vertices of the input
partition in a random order and check whether moving the vertex from its
own block to the opposite block reduces or keeps the MCV value.
If this is the case, the current vertex will be moved to the
opposite block.  One round of the algorithm can be implemented in
 time (see Section~\ref{sec:mcv-apx} in the appendix
for more details).  The total number of rounds of the algorithm is a tuning parameter.  After
preliminary experiments we have set it to 20.


\section{A New Conductance-based Edge Rating for Partitioning}
\label{sec:BI}
An edge rating in a multilevel graph partitioner should yield a low
rating for an edge  if  is likely to be contained in the cut-set
of a ``good'' cut, \eg if the cut-set consists of a bridge.

In our approach a good cut is one that (i) has a low conductance and
(ii) is at least moderately balanced. In complex networks (i) does not
always imply (ii) (see below).  A loose connection between conductance
and MCV in bipartitions can be established via isoperimetric graph
partitioning~\cite{GradyS06isoperimetric}.  Our approach to define an
edge rating and use it for partitioning is as follows.


\begin{enumerate}
\item Generate a collection  of moderately balanced
  bipartitions (cuts of ) that contain cuts with a low conductance
  value.
\item Define a measure  such that  is low
  [high] if  is [not] contained in the cut-set of a cut in
   with low conductance.
\item Instead of multiplying the edge rating  with the factor  as in~\cite{Safro2012a},
  we replace one of the two (identical) myopic factors  in  by the more far-sighted factor
  . This yields the new edge rating

  

  The higher , the higher , and thus the higher
  the chances for  to be contracted during coarsening.
\item Run a multilevel graph partitioner capable of handling edge ratings
such as \kahip with .
\end{enumerate}

\noindent To specify , we need to define 
and .

\paragraph{Specifics of .}
For the definition of , we resort to a
basic concept of graph-based clustering, \ie the use of minimum weight
spanning trees (MSTs). We describe this concept in the context of
graph-based image segmentation
(GBIS)~\cite{Felzenszwalb2004a,Wassenberg2009a} for illustration
purposes (see Figure~\ref{fig:arrays}a).

\begin{figure}[tb]
\begin{centering}
\includegraphics[scale=0.12]{figures/MSTseg}
\hspace{12ex}
\includegraphics[scale=0.20]{figures/arrays}
\par\end{centering}
\caption{\label{fig:arrays} (a) Example of MST (red) in GBIS. For the
  green arrow see the text. (b) Vertex attributes  and
  . Tree  is formed by the black edges, and the
  subtree with root  is contained in the shaded area. The weights
  of the blue and green edges contribute to , and the
  weights of the red edges contribute to .}
\vspace{-0.5cm}
\end{figure}
In GBIS one represents an image by a graph  whose vertices [edges]
represent pixels [neighborhood relations of pixels]. The edges are
equipped with weights that reflect the contrast between the gray
values at the edges' end vertices. An MST  of  with respect to
contrast has the following property
(see~\cite[Thm.~4.3.3]{Jungnickel05a}).  The contrast value associated
with any  is minimal compared to the contrast values of
the edges in the fundamental cut-set  (see
Eq.~\ref{eq:funda}). Thus, for any  with a high contrast
value (see the green arrow in Figure~\ref{fig:arrays}a), the
fundamental cut  yields a segmentation into two regions
with a high contrast anywhere on the common border.

Here, we arrive at a collection  of 
moderately balanced bipartitions (cuts) of  by (i) computing
connectivity-based contrast values for the edges of , (ii)
computing an MST  of  \wrt these values, and (iii) letting
 consist of 's fundamental cuts \wrt . The
contrast value of an edge  should be low [high] if the
edge is indispensable for ``many'' connections via shortest
paths. Thus, the higher the contrast, the stronger the negative effect
on 's connectivity if  is cut, and thus the more reasonable it
is to cut .
To define the contrast values, we generate a random collection
 of breadth-first-traversal (BFT) trees. A tree in
 is formed by first choosing a root randomly. As usual,
we let the trees grow out of the roots using a queue, but we process
the edges incident on a vertex in a randomized order. Alternatively,
SSSP trees may be used if edge weights are to be included.

Let  denote the number of trees in
 that contain  and in which  is closer to the
tree's root than  ( and  cannot have the same distance to the
root). We set the {\em contrast} value of an edge  to



Just considering the number of trees in  which contain
, turned out to yield poorer partitions than using
Eq.~\ref{eq:gamma}. We believe that this is due to small subgraphs
which are connected to the graphs' ``main bodies'' via very few
edges. Just considering the number of trees in  which
contain such an edge would result in a high contrast of the edge
although the cut is far from moderately balanced. Even worse, the
conductance of the cut may be small (\eg if the cut-set contains only
one edge). This would protect edges in cut-sets of very unbalanced
cuts from being contracted --- an undesired feature.

\paragraph{Specifics of .}
Our plan is to define a measure  such that  is
low [high] if  is [not] contained in the cut-set of a cut in
 with low conductance. Hence, we set



\noindent where  denotes the cut-set of the cut . Let 
denote the set of edges in the (fundamental) cycle that arises if 
is inserted into . Then, the cuts  with  (see Eq.~\ref{eq:Cond}) are precisely the fundamental cuts
 (see Eq.~\ref{eq:funda}) with  and . Note that  is the only edge in  that is not in
. This suggests to first compute the -values for all
edges  as specified in Section~\ref{sec:effCond}.  For
 the value of  is then obtained by forming
the minimum of the -values of . If , then  is the set of edges on the
unique path in  that connects  to .





\section{An -Algorithm for Computing All
   }
\label{sec:effCond}
In this section we demonstrate how, for a rooted given spanning tree
 of a graph , one can compute all conductance values
, , in time  (the
root can be chosen randomly). This algorithm facilitates an efficient
computation of the edge rating introduced in the previous section.
The key to achieving optimal running time is to aggregate information
on fundamental cuts during a postorder traversal of . The
aggregated information is kept in the three vertex attributes
,  and  defined in
Definition~\ref{def:attributes} below.
Technically, the three vertex attributes take the form
of arrays, where indices represent vertices.

\begin{consDefinition} \label{def:attributes}
Let  be the children of vertex  in .  Moreover, let
 denote the subtree rooted at  (including ), and let 
(\emph{descendants of }) denote the set that contains the vertices
of , \ie . We use the following three vertex
attributes to aggregate information that we need to compute the
conductance values:
\begin{itemize}[noitemsep,nolistsep]
  \item .
  \item  equals twice the total weight of all edges  with (i) , (ii)  and (iii)
    the lowest common ancestor of  and  in  is  ({\color{blue}blue}
    edges in Figure~\ref{fig:arrays}b) plus the total weight of all
    edges not in  with one end vertex being  and the other end
    vertex being contained in  ({\color{ForestGreen}green} edges in
    Figure~\ref{fig:arrays}b).
  \item  equals the total weight of all edges not
    in  with exactly one end vertex in  ({\color{red}red} edges in
    Figure~\ref{fig:arrays}b).
\end{itemize}
\end{consDefinition}
If  has a parent edge , Eq.~\ref{eq:condu} takes the form



When computing ,  and , we
employ two vertex labellings (stored in arrays indexed by the
vertices):  indicates the preorder label of  in , and
 indicates the maximum of  over all
. We also need lowest common ancestors (LCAs). Queries
\textsc{LCA}(, , ), \ie the LCA of  and  on ,
require constant time after an -time
preprocessing~\cite{Bender:2000:LPR:646388.690192}.


We start by initializing labels and vertex attributes to arrays of
length  with all entries set to  (for details see
Algorithm~\ref{algo:BTE} in Section~\ref{sec:pseudocode} in the
appendix). Then we compute the entries of  and
 in a single depth-first traversal of  and
perform the preprocessing for \textsc{LCA}(). Finally, we call a standard postorder traversal in 
starting at the root of . When visiting a vertex, either one of the
subroutines \textsc{Leaf} (see Algorithm~\ref{algo:Leaf} in
Section~\ref{sec:pseudocode} of the appendix) or
\textsc{NonLeaf} (see Algorithm~\ref{algo:NonLeaf}) is called
depending on the vertex type.


\begin{algorithm}[tbp]
\caption{Procedure \textsc{NonLeaf} called during postorder traversal of }
\label{algo:NonLeaf}
\begin{algorithmic}[1]
\State 

\ForAll{}
  \If{}
    \If{label[u] < label[t]}
      \State 
      \State 
    \Else
      \State 
    \EndIf
  \Else
  \If{}\\ 
    \Comment{equivalent to test if }
    \State 
    \State 
    \State 
  \EndIf
\EndIf
\EndFor
\State  \State
;
\If{} \State

\EndIf
\end{algorithmic}
\end{algorithm}

If  is a leaf, Algorithm~\ref{algo:Leaf} sets  to
 and  to the total weight of all edges in
 that are incident on . Likewise, the entry
 is updated for any  with . 

If  is not a leaf (Algorithm~\ref{algo:NonLeaf}), and if  has a parent edge in , 
this edge is found in line 8 and the corresponding conductance value is computed in line 22 using  and
. The entry  is updated
multiple times until the postorder traversal ascends from  towards
the root of  (line 14). The
update of  is justified in the proof of
Theorem~\ref{prop:update} (see Section~\ref{sec:proofs-apx} 
(appendix), it also contains the proof of Proposition~\ref{prop:time}).
Eq.~\ref{eq:inter} in Theorem~\ref{prop:update}
guarantees that the conductance values computed in line 22 are correct. 









\begin{consTheorem}
\label{prop:update}
After having finished processing  in a traversal of , the
equalities given below hold (where in the last one we assume that 
is not the root of  and that  is the parent edge of  in
).


\end{consTheorem}

\begin{consProposition}
\label{prop:time}
Given a rooted spanning tree  of , the computation
of all , , takes  time.
\end{consProposition}

\section{Experimental Results}
\label{sec:results}
\paragraph{Approach and settings.}

\begin{wraptable}[16]{r}{55mm}
\vspace{-8mm}
\scalebox{0.8}{
  \begin{tabular}{ l | r | r }
    Name & \#vertices & \#edges\\ \hline \hline
p2p-Gnutella          & \numprint{6405}   & \numprint{29215}\\\hline
PGPgiantcompo         & \numprint{10680}  & \numprint{24316}\\\hline
email-EuAll           & \numprint{16805}  & \numprint{60260}\\\hline
as-22july06           & \numprint{22963}  & \numprint{48436}\\\hline
soc-Slashdot0902      & \numprint{28550}  & \numprint{379445}\\\hline
loc-brightkite\_edges & \numprint{56739}  & \numprint{212945}\\\hline
loc-gowalla\_edges    & \numprint{196591} & \numprint{950327}\\\hline
coAuthorsCiteseer     & \numprint{227320} & \numprint{814134}\\\hline
wiki-Talk             & \numprint{232314} & \numprint{1458806}\\\hline
citationCiteseer      & \numprint{268495} & \numprint{1156647}\\\hline
coAuthorsDBLP         & \numprint{299067} & \numprint{977676}\\\hline
web-Google            & \numprint{356648} & \numprint{2093324}\\\hline
coPapersCiteseer      & \numprint{434102} & \numprint{16036720}\\\hline
coPapersDBLP          & \numprint{540486} & \numprint{15245729}\\\hline
as-skitter            & \numprint{554930} & \numprint{5797663}\\\hline
  \end{tabular}}
\caption{Complex networks used as benchmark set.}
\label{tab:graphs}
\end{wraptable}

The multilevel partitioner within the \kahip package has three
different algorithm configurations: strong, eco and fast. We use the
eco configuration since this configuration was chosen
in~\cite{Safro2012a}, too. The variable  in the balance
constraint is set to the common value .

We evaluate the postprocessing and compare  with  on
the basis of the 15 complex networks listed in Table~\ref{tab:graphs}
and further described in Table~\ref{tab:graphs_annot} 
(appendix). The networks are from two
popular archives~\cite{BaderMSW12dimacs,Leskovecxxxx}. The same
networks have been used previously in~\cite{Safro2012a} to evaluate
.


All computations are done on a workstation with two 8-core Intel(R)
Xeon(R) E5-2680 processors at 2.70GHz. Our code is implemented in
C/C++ and compiled with GCC 4.7.1.  Note that we do not exploit
parallelism here and run sequential experiments only.  First of all,
we focus in this paper on solution quality, not on speed. Secondly,
the standard of reference, , is also implemented sequentially.

Since the results produced by \kahip depend on many factors including random seeds,
we perform 50 runs with different seeds for each network and compute the following three {\em performance
  indicators}:

\begin{itemize}[noitemsep,nolistsep]
\item  and : minimal and average MCV found by \kahip. 
\item  and : minimal and average cut found by \kahip. 
\item : average time \kahip needs for the complete partitioning process.
\end{itemize}




\paragraph{Postprocessing results.}
For , the average reduction of avgMCV due to
postprocessing amounts to 11.3\% (see Table~\ref{tab:PPgainsMCV} in
Section~\ref{sec:exp-apx} of the appendix). Since the postprocessing
trades in small edge cuts for small MCVs, values for  and
 [ and ] are with [without]
postprocessing. The increase in running time due to postprocessing is
negligible.
\vspace{-1.75ex}
\paragraph{Edge rating results.}
Intriguingly, using an asymptotically optimal Range Minimum Query
(RMQ) code (by Fischer and Heun~\cite{Fischer2006a}) within 
for the algorithms in Section~\ref{sec:effCond} 
does not decrease the running time. The straightforward asymptotically
slower algorithm is slightly faster (1.1\% in total) in our
experiments. To investigate this effect further, we compare the results on a set of 
non-complex networks, Walshaw's graph partitioning
archive~\cite{SoperWC04combined}. Again, the implementation of the (in
theory faster) RMQ algorithm does not play out, running time and
quality remain comparable. Therefore, the running times in all tables
refer to the implementation not using the Fischer/Heun RMQ code.

The edge rating  depends on the number of random spanning
trees, \ie . To make this clear we write
 instead of .

For a given network we measure the quality of the edge rating
 through (three) quotients of the
form (performance indicator using 
divided by the same performance indicator using
). Tables~\ref{tab:MCV_20}, \ref{tab:MCV_100},
and~\ref{tab:MCV_200} in Section~\ref{sec:exp-apx} of the appendix
show the performance quotients of ,  and
. The geometric means of the performance quotients over
all networks are shown in Table~\ref{tab:meansQuot}.

\begin{table}[tb]
  \caption{Geometric means of the performance quotients minMCV, avgMCV
    and avgTime over all networks in
    Table~\ref{tab:graphs}. Number of trees: 20, 100 and 200. Reference is the edge
    rating . A quotient  means that
     yields better results than .}
\begin{center}
\begin{tabular}{ l | c c | c }
                               & minMCV            & avgMCV              & avgTime\\\hline \hline                                 
Ratios  & \textbf{0.892}    & \textbf{0.897}      & \textbf{1.793}\\ \hline
Ratios  & \textbf{0.874}    & \textbf{0.893}      & \textbf{5.278}\\ \hline
Ratios  & \textbf{0.865}    & \textbf{0.890}      & \textbf{9.411}\\ \hline
\end{tabular}
\end{center}
\label{tab:meansQuot}
\vspace{-7mm} 
\end{table}

As the main result we state that buying quality through increasing
 is expensive in terms of running time. The
rating  already yields avgMCV that is 10.3\% lower than
avgMCV from  --- at the expense of a relative increase in
running time by only 1.79. The total reduction of average MCV from
postprocessing {\em and} replacing  by  amounts
to 20.4\% (see Tables~\ref{tab:PPgainsMCV} and~\ref{tab:MCV_100} in
the appendix).


It is further interesting to note that, when we omit the
postprocessing step and compare the average edge cut instead of MCV,
 and  perform comparably well. While  yields
a slightly better minimum cut,  yields a slightly better
average cut (see Table~\ref{tab:cut_100} in Section~\ref{sec:exp-apx}
of the appendix).





\section{Conclusions and Future Work}
\label{sec:conclusions}
Motivated by the deficits of coarsening complex networks during
multilevel graph partitioning, we have devised a new edge rating for
guiding edge contractions. The new rating of an edge indicates whether
it is part of a good moderately balanced conductance-based cut or
not. To compute the necessary conductance values efficiently, we have
developed the first linear-time algorithm to compute the conductance
values of \emph{all} fundamental cuts of a spanning tree.
Our evaluation shows a significant improvement over a previously leading
code for partitioning complex networks. 
The new edge rating and additional greedy postprocessing \emph{combined}
result in a 20.4\% better maximum communication volume.

We would like to stress that good coarsening is not only of interest
for graph partitioning, but can be employed in many other methods and
applications that exploit hierarchical structure in networks. Future
work should investigate the concurrence of the contrast  and
the conductance values  --- possibly replacing  by an
even better contrast yet to be found. Our overall coarsening scheme is
agnostic to such a replacement and would require no further
changes. Moreover, we would like to extend our methods to an arbitrary
number of blocks. While the proposed edge rating should work out of
the box, the greedy MCV minimization has to be adapted to work
effectively for a larger number of blocks.




\paragraph*{Acknowledgments.}
We thank Johannes Fischer for providing an implementation of
the Range Minimum Query method presented in~\cite{Fischer2006a}.


\begin{footnotesize}
\bibliographystyle{abbrv}
\bibliography{roland,refs-parco}
\end{footnotesize}


\newpage
\appendix
\section{Pseudocode of Algorithms in Section~\ref{sec:effCond}}
\label{sec:pseudocode}
\begin{algorithm}[!h]
\caption{Given a spanning tree  of  with root ,
  compute  for all }
\label{algo:BTE}
\begin{algorithmic}[1]
\State Set  to 

\State Compute  and  for all .

\State Perform LCA preprocessing

\State Postorder(, )
\end{algorithmic}
\end{algorithm}


\begin{algorithm}[h!]
\caption{Procedure \textsc{Leaf} called during postorder traversal of }
\label{algo:Leaf}
\begin{algorithmic}[1]
\State 
\State 
\ForAll{}
  \If{}
    \State 
  \Else
    \State \textsc{LCA}
    \State 
    \State 
  \EndIf
\EndFor
\If{} \State

\EndIf
\end{algorithmic}
\end{algorithm}

\section{Proofs of Section~\ref{sec:effCond}}
\label{sec:proofs-apx}
\subsection{Proof of Theorem~\ref{prop:update}}
\begin{proof}
  We prove Eq.s~\ref{eq:vol},~\ref{eq:intra} and~\ref{eq:inter} one
  after the other. Colors correspond to the edge types introduced in
  Definition~\ref{def:attributes}.
\begin{enumerate}
\item Due to line 1 of Algorithm~\ref{algo:Leaf},  for any leaf  of . If  is not a
  leaf of , we proceed by induction. Specifically, we assume inductively
   for all children  of . Due to
  lines 5 and 19 of Algorithm~\ref{algo:NonLeaf}, .
\item Due to line 8 of Algorithm~\ref{algo:Leaf} and line 14 of
  Algorithm~\ref{algo:NonLeaf},



Note that a blue edge contributes twice to  since it
is encountered from both endpoints. A green edge, on the other hand,
contributes only once.
\item Due to line 9 of Algorithm~\ref{algo:Leaf},  for any leaf  of . If  is
  not a leaf of , let  be the edges between 
  and its children . In particular, . By induction
  we may assume . Thus, line 6 of Algorithm~\ref{algo:NonLeaf}, where we
  take the sum over all  values of 's children ,
  yields



Note that this is an intermediate result of . The blue
and green terms make up , which we still have to
subtract. Moreover, the red term does not yet contain the (weights of)
edges in  with one end vertex being  and the other one not being
contained in . In the following, we replace the blue and the
green term by  and rewrite the red term.



Finally, line 15 of Algorithm~\ref{algo:NonLeaf} results in
,
and line 20 of Algorithm~\ref{algo:NonLeaf} yields
Eq.~\ref{eq:inter}.
\end{enumerate}

\end{proof}

\subsection{Proof of Proposition~\ref{prop:time}}
\begin{proof}
All initialization and preprocessing steps can be done in 
time. During the postorder traversal of  each  explores
its direct neighborhood, either in \textsc{Leaf} or in
\textsc{NonLeaf}. Two observations are crucial now. First, all
elementary operations within \textsc{Leaf} and \textsc{NonLeaf} take
constant time, including the LCA queries. Second, for each edge of
 the respective operations are executed at most twice.
\end{proof}

\section{MCV Postprocessing}
\label{sec:mcv-apx}
We now show how one round of the postprocessing algorithm that
optimizes MCV can be implemented in 
time.  The crucial step is to decide if moving a vertex  to the
opposite block reduces MCV in  time. To do so, we need a
few notations.  An \emph{internal vertex} is a vertex of the graph
which is not a boundary vertex, and the external degree of a vertex is
defined as the number of neighbors in the opposite block.  Let  be a bipartition of  and, without loss of generality, let 
be a random boundary vertex from block . During the course of the
algorithm, we keep track of the communication volumes of the
blocks. Let  and  be the initial communication volume of
 and , respectively. We do the following to decide if moving
 to the opposite block reduces MCV.  First, we move  to the
opposite block . Afterwards, the communication volume  is
reduced by the number of boundary vertices in  that are also
neighbors of  and become internal vertices after the movement.
Moreover, the communication volume  is increased by the amount of
internal vertices in  that become boundary vertices after  is
moved to .  Additionally, since we move , the communication
volume  is reduced by one, and if the number of neighbors of 
in  is not zero, then  is increased by one.  Note that we
can check in constant time if a vertex is a boundary vertex or an
internal vertex by storing the external degree of all vertices in an
array and updating the external degree of a vertex and its neighbors
when the vertex is moved.  We move  back to its origin if the
movement did not yield an improvement in MCV.




\section{Test Set of Complex Networks}
\label{sec:test-set}
\begin{table}[h!]
\caption{Complex networks used for comparing  and .}
\begin{center}
\scalebox{0.8}{
  \begin{tabular}{ l | r | r | r }
    Name & \#vertices & \#edges & Network Type\\ \hline \hline
p2p-Gnutella          & \numprint{6405}   & \numprint{29215}    & filesharing network\\\hline
PGPgiantcompo         & \numprint{10680}  & \numprint{24316}    & largest connected component in network of PGP users\\\hline
email-EuAll           & \numprint{16805}  & \numprint{60260}    & network of connections via email\\\hline
as-22july06           & \numprint{22963}  & \numprint{48436}    & network of autonomous systems in the internet\\\hline
soc-Slashdot0902      & \numprint{28550}  & \numprint{379445}   & news network\\\hline
loc-brightkite\_edges & \numprint{56739}  & \numprint{212945}   & location-based friendship network\\\hline
loc-gowalla\_edges    & \numprint{196591} & \numprint{950327}   & location-based friendship network\\\hline
coAuthorsCiteseer     & \numprint{227320} & \numprint{814134}   & citation network\\\hline
wiki-Talk             & \numprint{232314} & \numprint{1458806}  & network of user interactions through edits\\\hline
citationCiteseer      & \numprint{268495} & \numprint{1156647}  & citation network\\\hline
coAuthorsDBLP         & \numprint{299067} & \numprint{977676}   & citation network\\\hline
web-Google            & \numprint{356648} & \numprint{2093324}  & hyperlink network of web pages\\\hline
coPapersCiteseer      & \numprint{434102} & \numprint{16036720} & citation network\\\hline
coPapersDBLP          & \numprint{540486} & \numprint{15245729} & citation network\\\hline
as-skitter            & \numprint{554930} & \numprint{5797663}  & network of internet service providers\\\hline
  \end{tabular}}
\end{center}
\label{tab:graphs_annot}
\end{table}



\section{Details of Experimental Results}
\label{sec:exp-apx}



\begin{table}[tb]
  \caption{Effect of postprocessing on performance of . Numbers are ratios of
    the performance indicators minMCV and avgMCV with and without
    postprocessing. A ratio  means that postprocessing
    reduces MCV by .}
\begin{center}
\begin{tabular}{c | c  c}
                             & minMCV              &  avgMCV               \\\hline \hline
PGPgiantcompo                &  0.951              &   0.924               \\ \hline
as-22july06                  &  0.913              &   0.824               \\ \hline
email-EuAll                  &  0.858              &   0.859               \\ \hline
loc-brightkite\_edges        &  0.765              &   0.753               \\ \hline
p2p-Gnutella04               &  0.866              &   0.862               \\ \hline
soc-Slashdot0902             &  0.921              &   0.912               \\ \hline
citationCiteseer             &  0.939              &   0.919               \\ \hline
coAuthorsCiteseer            &  0.975              &   0.955               \\ \hline 
coAuthorsDBLP                &  0.905              &   0.898               \\ \hline
loc-gowalla\_edges           &  0.887              &   0.870               \\ \hline
web-Google                   &  0.965              &   0.926               \\ \hline
wiki-Talk                    &  0.994              &   0.974               \\ \hline
as-skitter                   &  0.939              &   0.937               \\ \hline
coPapersCiteseer             &  0.892              &   0.877               \\ \hline
coPapersDBLP                 &  0.856              &   0.841               \\ \hline  \hline
\textbf{Geometric mean}	     & \textbf{0.907}      & \textbf{0.887}        \\ \hline
\end{tabular}
\end{center}
\label{tab:PPgainsMCV}
\end{table}

\begin{table}[tb]
  \caption{Performance quotients of  with postprocessing for minMCV, avgMCV
    and avgTime. Reference is  with postprocessing. A quotient  means that
     yields better results than .}
\begin{center}
\begin{tabular}{ c | c  c | c }
& minMCV  & avgMCV & avgTime\\
                        \hline \hline
PGPgiantcompo           &  0.962              &  1.004               &  3.068              \\ \hline
as-22july06             &  0.898              &  0.766               &  1.387              \\ \hline
email-EuAll             &  0.904              &  0.918               &  1.537              \\ \hline
loc-brightkite\_edges   &  0.714              &  0.714               &  1.190              \\ \hline
p2p-Gnutella04          &  1.003              &  1.000               &  2.255              \\ \hline
soc-Slashdot0902        &  0.991              &  0.999               &  3.045              \\ \hline
citationCiteseer        &  1.001              &  0.974               &  1.938              \\ \hline
coAuthorsCiteseer       &  1.090              &  1.053               &  2.842              \\ \hline 
coAuthorsDBLP           &  0.743              &  0.774               &  1.461              \\ \hline
loc-gowalla\_edges      &  0.608              &  0.607               &  0.642              \\ \hline
web-Google              &  0.820              &  0.729               &  3.479              \\ \hline
wiki-Talk               &  0.992              &  1.023               &  1.142              \\ \hline
as-skitter              &  0.769              &  0.760               &  0.924              \\ \hline
coPapersCiteseer        &  1.011              &  1.260               &  2.575              \\ \hline
coPapersDBLP            &  1.035              &  1.135               &  2.448              \\ \hline  \hline
\textbf{Geometric mean} &  \textbf{0.892}     &  \textbf{0.897}      &\textbf{1.793}       \\ \hline
\end{tabular}
\end{center}
\label{tab:MCV_20}
\end{table}

\begin{table}[tb]
  \caption{Performance quotients of  with postprocessing for minMCV, avgMCV
    and avgTime. Reference is  with postprocessing. A quotient  means that
     yields better results than .}
\begin{center}
\begin{tabular}{ c | c  c | c }
& minMCV  & avgMCV & avgTime\\
                        \hline \hline
PGPgiantcompo           &  0.986              &  0.998               &  12.379              \\ \hline
as-22july06             &  0.750              &  0.760               &   2.373              \\ \hline
email-EuAll             &  0.874              &  0.917               &   3.183              \\ \hline
loc-brightkite\_edges   &  0.715              &  0.715               &   3.836              \\ \hline
p2p-Gnutella04          &  0.995              &  0.995               &   6.670              \\ \hline
soc-Slashdot0902        &  0.920              &  0.987               &  10.801              \\ \hline
citationCiteseer        &  1.017              &  0.972               &   7.485              \\ \hline
coAuthorsCiteseer       &  1.068              &  1.035               &  10.567              \\ \hline 
coAuthorsDBLP           &  0.737              &  0.776               &   5.282              \\ \hline
loc-gowalla\_edges      &  0.624              &  0.609               &   1.929              \\ \hline
web-Google              &  0.837              &  0.729               &  13.507              \\ \hline
wiki-Talk               &  0.987              &  1.015               &   1.194              \\ \hline
as-skitter              &  0.793              &  0.769               &   2.986              \\ \hline
coPapersCiteseer        &  0.991              &  1.245               &   8.567              \\ \hline
coPapersDBLP            &  0.970              &  1.118               &   7.951              \\ \hline  \hline
\textbf{Geometric mean} &  \textbf{0.874}     &  \textbf{0.893}      &\textbf{5.278}        \\ \hline
\end{tabular}
\end{center}
\label{tab:MCV_100}
\end{table}

\begin{table}[tb]
  \caption{Performance quotients of  with postprocessing for minMCV, avgMCV
    and avgTime. Reference is  with postprocessing. A quotient  means that
     yields better results than .}
\begin{center}
\begin{tabular}{ c | c  c | c }
& minMCV  & avgMCV & avgTime\\
                        \hline \hline
PGPgiantcompo           &  0.976              &   1.000              &  24.258               \\ \hline
as-22july06             &  0.694              &   0.735              &   3.645               \\ \hline
email-EuAll             &  0.874              &   0.927              &   5.262               \\ \hline
loc-brightkite\_edges   &  0.692              &   0.711              &   7.215               \\ \hline
p2p-Gnutella04          &  0.997              &   0.997              &  12.313               \\ \hline
soc-Slashdot0902        &  0.913              &   0.959              &  20.883               \\ \hline
citationCiteseer        &  1.013              &   0.974              &  14.589               \\ \hline
coAuthorsCiteseer       &  1.026              &   1.035              &  20.412               \\ \hline 
coAuthorsDBLP           &  0.740              &   0.773              &  10.157               \\ \hline
loc-gowalla\_edges      &  0.615              &   0.611              &   3.574               \\ \hline
web-Google              &  0.843              &   0.729              &  26.421               \\ \hline
wiki-Talk               &  0.986              &   1.017              &   1.217               \\ \hline
as-skitter              &  0.775              &   0.760              &   5.588               \\ \hline
coPapersCiteseer        &  1.035              &   1.255              &  16.131               \\ \hline
coPapersDBLP            &  0.958              &   1.122              &  14.881               \\ \hline  \hline
\textbf{Geometric mean} &  \textbf{0.865}     &  \textbf{0.890}      &\textbf{9.411}        \\ \hline
\end{tabular}
\end{center}
\label{tab:MCV_200}
\end{table}

\begin{table}[tb]
  \caption{Performance quotients of  without postprocessing for minCut, avgCut
    and avgTime. Reference is  without postprocessing. A quotient  means that
     yields better results than .}
\begin{center}
\begin{tabular}{ c | c  c | c }
& minMCV  & avgMCV & avgTime\\
                        \hline \hline
PGPgiantcompo           &  1.036              &  1.021               &  13.405               \\ \hline
as-22july06             &  0.858              &  0.904               &   2.387               \\ \hline
email-EuAll             &  0.976              &  0.894               &   3.248               \\ \hline
loc-brightkite\_edges   &  1.026              &  1.032               &   3.964               \\ \hline
p2p-Gnutella04          &  0.951              &  0.959               &   7.554               \\ \hline
soc-Slashdot0902        &  0.943              &  1.258               &  13.083               \\ \hline
citationCiteseer        &  0.986              &  0.941               &   8.000               \\ \hline
coAuthorsCiteseer       &  1.118              &  1.110               &  11.420               \\ \hline 
coAuthorsDBLP           &  0.795              &  0.885               &   5.554               \\ \hline
loc-gowalla\_edges      &  1.100              &  1.093               &   1.948               \\ \hline
web-Google              &  0.826              &  0.699               &  15.660               \\ \hline
wiki-Talk               &  1.032              &  1.033               &   1.194               \\ \hline
as-skitter              &  1.007              &  1.007               &   3.085               \\ \hline
coPapersCiteseer        &  1.150              &  1.391               &  13.578               \\ \hline
coPapersDBLP            &  1.034              &  1.252               &  12.045               \\ \hline  \hline
\textbf{Geometric mean} &  \textbf{0.984}     &  \textbf{1.018}      &\textbf{5.915}         \\ \hline
\end{tabular}
\end{center}
\label{tab:cut_100}
\end{table}







\end{document}
