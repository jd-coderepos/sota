\documentclass[letterpaper,11pt]{article}

\usepackage{xspace}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{typearea}
\paperwidth 8.5in \paperheight 11in
\typearea{13}

\usepackage[compact]{titlesec}

\newcommand{\sketch}[1]{}\newcommand{\myspace}{\vspace{-6pt}}

\newtheorem{thm}{Theorem}[section]
\newtheorem{prop}[thm]{Proposition}
\newtheorem{obs}[thm]{Observation}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{proposition}[thm]{Proposition}
\newtheorem{assumption}[thm]{Assumption}
\newtheorem{claim}[thm]{Claim}
\newtheorem{rem}[thm]{Remark}
\newtheorem{que}[thm]{Question}
\newtheorem{defn}[thm]{Definition}
\def \CC   {{\mathbb C}}
\def \FF   {{\mathbb F}}
\def \SS   {{\mathbb S}}
\def \DD   {{\mathbb D}}
\def \PP   {{\mathbb P}}
\def \RR   {{\mathbb R}}
\def \II   {{\mathbb I}}
\def \EE   {{\cal E}}
\def \TT   {{\mathbb T}}
\def \OPT  {\mbox{\rm OPT}}
\def \ST  {\sigma_t}
\date{}

\newcommand{\ox}{\ensuremath{\overline{x}}\xspace}
\newcommand{\oy}{\ensuremath{\overline{y}}\xspace}
\newcommand{\trans}{\intercal}

\renewcommand{\thefootnote}{\fnsymbol{footnote}}

\newcommand{\withproof}[1]{*** Proof omitted in final *********** \\
   #1 \\ ***\\}

\newcommand{\removefromfile}[1]{}
\newcommand{\ignore}[1]{}


\usepackage{setspace}
\setstretch{1.05}

\makeatletter
 \setlength{\parindent}{0pt}
 \addtolength{\partopsep}{-2mm}
 \setlength{\parskip}{5pt plus 1pt}
\addtolength{\abovedisplayskip}{-3mm}
\allowdisplaybreaks
\makeatother

\newenvironment{proofof}[1]{

\noindent{\bf Proof of {#1}:}}
{\hfill


}

\def\E{\mathbb{E}}
\def\oy{\overline{y}}
\def\ox{\overline{x}}
\def\oF{\overline{F}}
\def\cS{\mathcal{S}}
\def\sse{\subseteq}








\begin{document}
\title{Online Packing and Covering Framework with Convex Objectives}
\date{}
\author{Niv Buchbinder\thanks{Statistics and Operations Research Dept., Tel Aviv University, Research supported in part by ISF grant
954/11 and by BSF grant 2010426.}
\and
Shahar Chen\thanks{Technion - Israel Institute of Technology, Haifa, Israel. Work
supported by ISF grant 954/11 and BSF grant 2010426.}
\and
Anupam Gupta\thanks{Computer Science Department, Carnegie Mellon
    University, Pittsburgh, PA 15213, USA. Research partly supported by
    NSF awards CCF-1016799 and CCF-1319811.}
\and
Viswanath Nagarajan\thanks{Department of Industrial and Operations
  Engineering, University of Michigan, Ann Arbor, MI 48109.}
\and
Joseph (Seffi) Naor}


\maketitle
\begin{abstract}
  We consider online fractional covering problems with a convex
  objective, where the covering constraints arrive over time. Formally,
  we want to solve
   where the
  objective function  is convex, and the
  constraint matrix  is non-negative. The rows of 
  arrive online over time, and we wish to maintain a feasible solution
   at all times while only increasing coordinates of .  We also
  consider packing problems of the form
   where  is a convex function. In the online setting,
  variables  and columns of  arrive over time, and we wish
  to maintain a non-decreasing solution . These problems are dual to each other when  the Fenchel
  dual of .

  \medskip We provide an online primal-dual framework for both classes
  of problems with competitive ratio depending on certain
  ``monotonicity'' and ``smoothness'' parameters of ; our results
  match or improve on guarantees for some special classes of
  functions  considered previously.


  \medskip Using this fractional solver  with problem-dependent
  randomized rounding procedures, we obtain competitive algorithms for
  the following problems: online covering LPs minimizing -norms
  of arbitrary packing constraints, set cover with multiple cost
  functions, capacity constrained facility location, capacitated
  multicast problem, set cover with set requests, and profit maximization with non-separable production costs. Some of these
  results are new and others provide a unified view of previous results,
  with matching or slightly worse competitive ratios.
\end{abstract}

\newpage


\section{Introduction}

We consider the following class of fractional covering problems:

Above,  is a non-decreasing convex function and
 is non-negative. (Observe that we can transform the more
general constraints  with all non-negative entries into this
form by scaling the constraints.) The covering constraints  arrive online over time, and must be satisfied upon arrival. We
want to design an online algorithm that maintains a feasible fractional
solution , where  is required to be non-decreasing over time.

We also consider the Fenchel dual of~\eqref{eq:cnx-cov} which is the
following packing problem:

Here, the variables  along with columns of  (or,
alternatively, rows of ) arrive over time, and the Fenchel dual is
formally defined in~(\ref{eq:fenchel}); see, e.g.,~\cite{Rock} for
background and properties.
Let  denote the {\em row sparsity} of the matrix , i.e., the maximum number of non-zeroes in any row, and let  be the  coordinate of the gradient of  at point .

This paper gives an online primal-dual algorithm for this pair of convex
programs~\eqref{eq:cnx-cov} and~\eqref{eq:cnx-pack}. This extends the
widely-used online primal-dual framework for linear objective functions to the
convex case. The competitive ratio is given as the ratio between the primal and dual objective functions\footnote{However, for clarity of exposition we provide the ratio as
Dual/Primal and not vice versa.}. It depends on certain
``smoothness'' parameters of the function . We provide two general
algorithms:
\begin{itemize}
\item In the first algorithm, the primal variables  and dual variables  are monotonically non-decreasing, while the dual variables  are allowed to both increase and decrease over time. The competitive ratio of this algorithm is:
  



\item In the second algorithm, all variables---primal variables 
  as well as dual variables ---are required to be monotonically non-decreasing. The
  competitive ratio is slightly worse in this case, given by:
  
  Observe that the difference from~(\ref{intro:gen-apx}) is the additional
  parameter , which is defined to be an upper bound on the maximum-to-minimum ratio of positive
  entries in any column of .
\end{itemize}
The above expressions are difficult to parse because of their generality, so
the first special case of interest is that of linear objectives. In this
case , and also , hence the competitive ratios are  for monotone
primals, and  for monotone primals and duals. Both of
these competitive ratios are known to be best
possible~\cite{BN-MOR,GN12-mor}.

\def\b{b}  
The applicability of our framework extends to a number of settings,
most of which have been studied before in different works. We now
outline some of these connections.
\begin{itemize}
\item {\em Mixed Covering and Packing LPs}. In this problem, covering constraints  arrive online. There are also  ``packing constraints'' , for , that are given up-front. The right hand sides  of these packing constraints are themselves variables, and the objective is to minimize the -norm  of the ``load vector'' . All entries  and  are non-negative.
    Clearly, the objective function is a monotonically non-decreasing convex function.


  We obtain an -competitive algorithm for this problem,
  where  is the row-sparsity of matrix . Prior to our work,
  \cite{ABFP13} gave an -competitive algorithm for the special case of 
  (corresponding to , the makespan of the
  loads); here  and  are the maximum-to-minimum ratio of the
  entries in the covering and packing constraints.

\item {\em Set Cover with Multiple Costs}.
Here the offline input is a
  collection of  sets  over a universe , and
   different linear  cost functions  for
  . Elements from  arrive online and must be covered by
  some set upon arrival, where the decision to select a set into the
  solution is irrevocable. The goal is to maintain a set-cover that
  minimizes the  norm of the  cost functions. Combining our
  framework with a simple randomized rounding scheme gives an
  -competitive
  randomized online
  algorithm; here  is the maximum number of sets containing any
  element. The special case of  (when  without loss of generality)
  is the online set-cover problem~\cite{AAABN03}, for which the
  resulting -competitive bound is tight, at least for
  randomized polynomial-time online algorithms~\cite{Korman05}.

\item {\em Capacity Constrained Facility Location} (CCFL). Here we are
  given  potential facility locations, each with an opening cost 
  and a capacity . Now,  clients arrive online, each client  having an assignment cost  and a demand/load  for
  each facility . The online algorithm must open facilities
  (paying the opening costs ) and assign each arriving client 
  to some open facility  (paying the assignment cost , and
  incurring a load  on facility ). The \emph{makespan} of an
  assignment is the maximum load on any facility. The objective in CCFL
  is to minimize the sum of opening costs, assignment costs and the
  makespan. Using our framework, we obtain an -competitive
  fractional solution to a convex relaxation of CCFL. This is then
  rounded online to get an -competitive randomized
  online algorithm. This competitive ratio is worse by a logarithmic
  factor than the best result~\cite{ABFP13}, but it follows easily from
  our general framework.

\item {\em Capacitated Multicast Problem} (CMC).  This is a common
  generalization of CCFL and the \emph{online multicast
    problem}~\cite{AAABN-talg06}. There are  edge-disjoint rooted
  trees  corresponding to multicast trees in some
  network. Each tree  has a {\em capacity} , and each edge
   has an opening cost . A sequence of 
  clients arrive online, and each must be assigned to one of these
  trees. Each client  has a tree-dependent load of  for tree
  , and is connected to exactly one vertex  in tree
  . Thus, if client  is assigned to tree  then the load of
   increases by , and all edges on the path in  from
   to its root must be opened. The objective is to minimize
  the total cost of opening the edges, subject to the capacity
  constraints that the total load on tree  is at most .
  Solving a natural fractional convex relaxation, and then applying a
  suitable randomized rounding to it, we get an -competitive randomized online algorithm that violates each
  capacity by an  factor; here  is the maximum
  depth of the trees . The capacitated multicast
  problem with depth  trees generalizes the CCFL problem, in which
  case we recover the above result for CCFL.

\item {\em Online Set Cover with Set Requests} (SCSR).  We are given a
  universe  of  \emph{resources}, and a collection of 
  \emph{facilities}, where each facility  is specified by (i) a
  subset  of resources (ii) opening cost  and (iii)
  capacity . The resources and facilities are given up-front. Now,
  a sequence of  {\em requests} arrive over time. Each request
   requires some subset  of resources. The request
  has to be served by assigning it to some collection  of
  facilities whose sets collectively cover , i.e., . Note that these facilities have to be open, and
  we incur the cost of these facilities. Moreover, if a facility  is
  used to serve client , this contributes to the load of facility
  , and this total load must be at most the capacity .  This
  problem was considered recently by Bhawalkar et al.~\cite{BGP14}.

  Using an approach identical to that for the CCFL problem, we get an
  -competitive randomized online algorithm that
  violates each capacity by an  factor. Again this
  factor is weaker than the best result by a logarithmic factor, but
  directly follows from our general framework.

\item {\em Profit Maximization with Production Costs} (PMPC).
This is an application of the dual packing problem~\eqref{eq:cnx-pack}, in contrast to the above applications which are all applications of the primal covering problem.

  Consider a seller with  items that can be produced and sold.  The seller has a \emph{production cost function}  which is monotone, convex and satisfies some other technical conditions; the total cost incurred by the seller to produce  units of every item  is given by .\footnote{An important difference from prior work on such problems~\cite{BGMS11,HK15}: in these works, each item  had a separate production cost function , and . We call this the \emph{separable} case. Our techniques allow the production cost to be {\em non-separable} over items---e.g., we can handle .}  There are  buyers who arrive online. Each buyer  is interested in subsets of items (bundles) that belong to a set family . The value of buyer  for subset  is given by , where  is her \emph{valuation function}. If buyer  is allocated a bundle , she pays the seller her valuation . (Observe: this is not an auction setting.) The goal in the PMPC problem is to produce items and allocate subsets to buyers so as to maximize the profit , where  denotes the subset allocated to buyer  and  is the total quantity of all items produced.  As mentioned above, we consider a non-strategic setting, where the valuation of each buyer is known to the seller.

  Our main result here is for the fractional version of the problem where the allocation to each buyer  is allowed to be any point in the convex hull of the set family . We show that for a large class of valuation functions (e.g., supermodular, or weighted rank-functions of matroids) and production cost functions, our framework provides a polynomial time online algorithm: the precise competitive ratio is given by expression ~\eqref{intro:gen-apx-mon} with . As a concrete example, suppose the production cost function is  for some . In this case, we get an -competitive algorithm, where  satisfies , and  is the maximum-to-minimum ratio of the valuation functions .
\end{itemize}

As the above list indicates, the framework to solve fractional convex
programs is fairly versatile and gives good fractional results for a
variety of problems. In some cases, solving the particular relaxation we
consider and then rounding ends up being weaker than the best known
results for that specific problems (by a logarithmic factor); we hope
that further investigation into this problem will help close this gap.

\paragraph{Bibliographic Note:} In independent and concurrent work,
Azar et al.~\cite{ACP14} consider online covering problems with convex
objectives---i.e., problem~\eqref{eq:cnx-cov}. They also obtain a
competitive ratio that depends on properties of the function , but
their parameterization is somewhat different from ours. As an example,
for online covering LPs minimizing the -norm of packing
constraints, they obtain an -competitive
algorithm, whereas we obtain a tighter  ratio.

\subsection{Techniques and Paper Outline}
\label{sec:outline}

In \S\ref{sec:alg-description}, we give the first general algorithm for the
convex covering problem~(\ref{eq:cnx-cov}) maintaining monotone primal
variables (but allowing dual variables to decrease). The main
observation is simple, yet powerful: convex
optimization problems with a function  can be reduced to linear optimization using the
gradient of the convex function . In the process we end up also
giving a cleaner algorithm and proof for linear optimization problems
as well, significantly simplifying the previous algorithm
from~\cite{GN12-mor}.  The resulting algorithm performs multiplicative
increases on the primal variables; for the dual, it does an initial
increase followed by a linear decrease after some point.

In \S\ref{sec:monotone} we give the second general algorithm, which is
simpler. The primal updates are the same as above but we skip the dual
decreases. This results in a worse competitive ratio, but the loss is
necessary for any monotone primal-dual
algorithm~\cite{BN-MOR}.

In \S\ref{sec:applications} and \S~\ref{sec:profit-max} we deal with the
various applications of our framework. The high-level idea in all of these
is to suitably cast each application in the form of either ~\eqref{eq:cnx-cov}
or~\eqref{eq:cnx-pack}. All, but the applications in
\S\ref{sec:applications}, are for the convex covering problem~\eqref{eq:cnx-cov}. Some
comments on the main ideas to watch out for:
\begin{itemize}
\item For applications to combinatorial problems we have to define the
  convex relaxation with some care in order to avoid bad integrality
  gaps. Moreover, some of our convex relaxations are motivated by the
  particular constraints we want to enforce when
  subsequently rounding.

\item For some of the problems our convex relaxations have an
  exponential number of constraints. To get a polynomial running time,
  we use the natural ``separation oracle'' approach. Moreover, we relax
  the constraints by a constant factor, so that each call to the
  separation oracle gives us a ``big'' improvement, and hence there are
  only a few updates per request.

\item For capacity constrained facility location (in \S\ref{sec:CCFL}),
  capacitated multicast problem (in \S\ref{sec:multicast}), and set
  cover with set requests (in \S\ref{sec:sc-set-requests}), na\"{\i}ve
  randomized rounding is bad, and hence the rounding schemes introduces
  correlations between opening facilities and assigning clients. These
  correlations also motivate the specific convex relaxations we consider
  for the problems.
\end{itemize}


In \S\ref{sec:profit-max} we consider the problem of profit maximization
with production costs, which after some simplifications can be cast as a
convex packing program as in~\eqref{eq:cnx-pack}.  We want allocations
to be non-decreasing over time, so we use our second general primal-dual
algorithm, which maintains monotone solutions. We also show how this
problem can be solved efficiently for some special classes of valuation
functions: supermodular and matroid-rank-functions. This convex program
can also be (randomly) rounded online to get integral allocations with the
same multiplicative competitive ratio, but with an extra additive term. The
additive term depends only on the number  of items and the cost
function ; in particular it does not depend on , the number of
buyers. We note that such an additive loss is necessary for our approach
due to an integrality gap of the convex relaxation.

\subsection{Related Work}
\label{sec:related-work}

This paper adds to the body of work in online primal-dual algorithms;
see~\cite{BN-mono} for a survey of this area. This approach has been
applied successfully to a large class of online problems: set
cover~\cite{AAABN03}, graph connectivity and cuts~\cite{AAABN-talg06},
caching~\cite{BBN-focs07-paging}, auctions~\cite{HK15}, scheduling~\cite{DH14},
etc. Below we discuss in more detail only work that is directly
relevant to us.

Online packing and covering {\em linear programs} were first considered by
Buchbinder and Naor~\cite{BN-MOR}, where they obtained an -competitive algorithm for covering and an -competitive algorithm for packing. The competitive ratio for covering linear
programs was improved to  by Gupta and
Nagarajan~\cite{GN12-mor}, where  is the maximum number of
non-zero entries in any row.

Azar, Bhaskar, Fleischer, and Panigrahi~\cite{ABFP13} gave the first
algorithm for online {\em mixed packing and covering} LPs, where the
packing constraints are given upfront and covering constraints arrive
online; the objective is to minimize the maximum violation of the
packing constraints. Their algorithm had a competitive ratio of , where  is the number of packing
constraints and  (resp. ) denotes the maximum-to-minimum
ratio of entries in the covering (resp. packing) constraints. Using our
framework, this bound can be improved to . This
is also best possible as shown in~\cite{ABFP13}.

The capacity constrained facility location problem was also introduced
by Azar, Bhaskar, Fleischer, and Panigrahi~\cite{ABFP13}, who gave an
-competitive algorithm. Our result for this
problem is worse by a log-factor, but has the advantage of following
directly from our general framework. Moreover, our approach can be
extended to the capacitated multicast problem, which is a generalization
of CCFL to multi-level facility costs. The online multicast problem
(without capacities) was considered by Alon et al.~\cite{AAABN-talg06}
where they obtained an -competitive randomized
algorithm.

The online set cover problem with set requests was considered recently
by Bhawalkar, Gollapudi, and Panigrahi~\cite{BGP14} who obtained an
-competitive algorithm where capacities are violated
by an  factor. The competitive ratio obtained
through our approach is worse by a logarithmic factor in the cost
guarantee. Still, we think this is useful, since it follows with almost
no additional effort, given our online fractional framework and the CCFL
rounding scheme. Our approach is also likely to be useful in other such
generalizations.

The class of online maximization problems with production costs was
introduced by Blum, Gupta, Mansour, and Sharma~\cite{BGMS11} and
extended by Huang and Kim~\cite{HK15}. The key differences from our
setting are: (i) these papers deal with an {\em auction} setting where
the seller is not aware of the valuations of the buyers, whereas our
setting is not strategic, and (ii) these papers are restricted to
separable production costs, whereas we can handle much more general
(non-separable) cost functions.


\section{The General Framework}
\label{sec:general}

Let  be a non-negative non-decreasing convex
function. We assume that the function  is continuous and
differentiable, and satisfies the following \emph{monotonicity
  condition}:

 Here,  means  for all .

We consider the online fractional covering problem~\eqref{eq:cnx-cov}
where the constraints in  arrive online. Our algorithm is a
primal-dual algorithm, which works with the following pair of convex
programs:

Here  is the Fenchel dual of , which is defined
as

 (Observe that by
scaling the rows of  appropriately, we can transform any convering LP
of the form  into the form above.) The following duality is
standard.

\begin{lemma}[Weak duality]
Let  be feasible primal and dual solutions to  and  respectively. Then,

\end{lemma}
\begin{proof}

Rearranging we get the desired.
\end{proof}

\subsection{The Algorithm}
\label{sec:alg-description}

The algorithm maintains a feasible primal  and a feasible dual solution  at each time.

\vspace{0.25cm}
\noindent \framebox[1.05\width][l]{
\begin{minipage}{0.94\linewidth}
\vspace{0.1in}
{\bf Fractional Algorithm:} At round :
\begin{itemize}
\item Let  be a continuous variable denoting the current time.
\item While the new constraint is unsatisfied, i.e., , increase  at rate  and:
\item {\bf Change of primal variables:}
\begin{itemize}

\item For each  with , increase each  at rate

Here  is an upper bound on the row sparsity of the matrix.  is the -coordinate of the gradient .
\end{itemize}
\item {\bf Change in dual variables:}
\begin{itemize}
\item Set , where  is determined later.
\item Increase  at rate .
\item  If the dual constraint of variable  is tight, that is, , then,
    \begin{itemize}
    \item Let .
    \item Increase  at rate .
\ \frac{d}{d \tau} \left(\sum_{i=1}^{t}a_{ij}y^{\tau}_i\right) = a_{t j} \cdot r^{\tau} - a_{m^\star_j j} \cdot \frac{a_{t j}}{a_{m^\star_j j}}\cdot r^{\tau}=0
 x^{\tau}_j \geq \frac{1}{\max_{i\in S_j}\{a_{ij}\}\cdot d}\left(\exp\left(\frac{\ln\left(1+2d^2\right)}{\mu_j^{\tau}}\sum_{i\in S_j}a_{ij}y^{\tau}_i\right)-1\right) \label{differential:xy}
\frac{\partial x_j}{\partial y_i}=  \frac{\log\left(1+ 2d^2\right)}{\min_{\ell=1}^{n}\left\{\frac{\nabla_\ell f(\delta x)}{\nabla_\ell f(x)}\right\}}\cdot\frac{a_{i j}\,x_j + \frac{1}{d}}{\nabla_j f(x)} \geq \log\left(1+ 2d^2\right)\cdot\frac{a_{i j}\,x_j + \frac{1}{d}}{\nabla_j f(\delta x)}.

\frac{x_j^{\tau} + \frac{1}{a_{ij}d}}{x_j^{\tau(i)} + \frac{1}{a_{ij}d}} & \geq & \exp\left(\frac{\ln\left(1+2d^2\right)}{\nabla_j f(\delta x^\tau)}\cdot a_{ij}y^{\tau}_i\right) \label{x_lower:ineq1},

\lefteqn{\exp\left(\frac{\ln\left(1+2d^2\right)}{\mu_j^{\tau}} \sum_{i\in S_j} a_{ij}y^{\tau}_i\right) \leq \exp\left( \sum_{i\in S_j} \frac{\ln\left(1+2d^2\right)}{\nabla_j f(\delta x^{\tau(i+1)})} \cdot a_{ij}y^{\tau(i+1)}_i\right)} \label{x_lower:ineq2}\\
& \leq & \prod_{i\in S_j} \frac{x_j^{\tau(i+1)} + \frac{1}{a_{ij}d}}{x_j^{\tau(i)} + \frac{1}{a_{ij}d}}
  \leq   \prod_{i\in S_j} \frac{x_j^{\tau(i+1)} + \frac{1}{\max_{i\in S_j} \{a_{ij}\}\cdot d}}{x_j^{\tau(i)} + \frac{1}{\max_{i\in S_j} \{a_{ij}\}\cdot d}}\label{x_lower:ineq3} \\
& \leq & \prod_{i \in T_j} \frac{x_j^{\tau(i+1)} + \frac{1}{\max_{i\in S} \{a_{ij}\}\cdot d}}{x_j^{\tau(i)} + \frac{1}{\max_{i\in S_j} \{a_{ij}\}\cdot d}} = \frac{x_j^{\tau} + \frac{1}{\max_{i\in S_j} \{a_{ij}\}\cdot d}}{\frac{1}{\max_{i\in S_j} \{a_{ij}\}\cdot d}}\label{x_lower:ineq4} .

\min_{z} \left(\frac{\min_{\ell=1}^{n}\left\{\frac{\nabla_\ell f(\delta z)}{\nabla_\ell f(z)}\right\}}{4\ln(1+2d^2)}\right) -
\max_{z} \left(\frac{(\delta z)^\trans \nabla f(\delta z) - f(\delta z) }{f(z)}\right),
 \frac{1}{a_{t j}} > x_{j}^{\tau} \geq \frac{1}{\max_{i\in S_j}\{a_{ij}\}\cdot d}\left(\exp\left(\ln(1+2d^2)\right)-1\right) ,
\frac{d \left(\sum_{i=1}^{t}y_i\right)}{d \tau} \geq r^{\tau} - \sum_{j \in U(\tau)}\frac{a_{t j}}{a_{m^\star_j j}} \cdot r^{\tau} \geq r^{\tau} \left(1 - \sum_{j \in U(\tau)}\frac{1}{2d}\right) \geq \frac{1}{2}r^{\tau} \label{d_dual},

\frac{d f(x^{\tau})}{d\tau} & = \sum_{j} \nabla_j f(x^{\tau}) \frac{\partial x^{\tau}_j}{\partial \tau}  =  \sum_{j | a_{tj}>0}\nabla_j f(x^{\tau}) \left(\frac{a_{tj}x^{\tau}_j + \frac{1}{d}}{\nabla_j f(x^{\tau})}\right) =  \sum_{j | a_{tj}>0}\left( a_{tj}x^{\tau}_j + \frac{1}{d}\right) \leq 2 \label{d_primal}.

\frac{d \left(\sum_{i=1}^{t}y^{\tau}_i\right)}{d f(x^{\tau})} \geq \frac{r^{\tau}}{4} = \frac{\min_{\ell=1}^{n}\left\{\frac{\nabla_\ell f(\delta x^{\tau})}{\nabla_\ell f(x^{\tau})}\right\}}{4\ln\left(1+ 2d^2\right)} \label{ineq:dy_increase}.

\sum_{i=1}^{m}\oy_i \geq \frac{\min_{x'}\min_{\ell=1}^{n}\left\{\frac{\nabla_\ell f(\delta x')}{\nabla_\ell f(x')}\right\}}{4\ln\left(1+ 2d^2\right)}\cdot f(\ox) \label{ineq:y_increase}.
\nabla_i f(x) \,= \, \nabla_i f(a),\quad \forall i\in[n].
    \mbox{Dual} & = \sum_{i=1}^{m}y_i - f^\star(\mu) \geq  \left(\frac{\min_{x'}\min_{\ell=1}^{n}\left\{\frac{\nabla_\ell f(\delta x')}{\nabla_\ell f(x')}\right\}}{4\ln(1+2d^2)} - \frac{f^\star(\nabla f(\delta\ox)) }{f(\ox)}\right) \cdot f(\ox) \\
\intertext{by Inequality~(\ref{ineq:y_increase}), and using Claim~\ref{clm:dual-fact} (with ), we get}
    &= \left(\frac{\min_{x'}\min_{\ell=1}^{n}\left\{\frac{\nabla_\ell f(\delta x')}{\nabla_\ell f(x')}\right\}}{4\ln(1+2d^2)} - \frac{(\delta\ox)^\trans\nabla f(\delta \ox) - f(\delta \ox) }{f(\ox)}\right) \cdot f(\ox)
\\
    & \geq \left[\min_{z} \left(\frac{\min_{\ell=1}^{n}\left\{\frac{\nabla_\ell f(\delta z)}{\nabla_\ell f(z)}\right\}}{4\ln(1+2d^2)}\right) - \max_{z}\left(\frac{(\delta z)^\trans \nabla f(\delta z) - f(\delta z) }{f(z)}\right)\right] \cdot \mbox{Primal}
  \label{eq:gen-apx}
  \frac{{\rm Dual}}{{\rm Primal}}\,\,\ge \,\, \max_{c > 0} \,\,
  \left(\min_{z} \frac{\min_{\ell=1}^{n}\left\{\frac{\nabla_\ell f(z)}{\nabla_\ell f(cz)}\right\}}{4\ln(1+2d^2)} -
  \max_{z} \frac{z^\trans \nabla f(z) - f(z) }{f(c z)}\right).

  \overline{r} = \frac{\min_{\ell=1}^{n}\left\{\frac{\nabla_\ell
        f(\delta \ox)}{\nabla_\ell f(\ox)}\right\}}{\log\left(1+
      2d^2\right)}.

\max_{c>0} \quad \min_{z} \left(\frac{\min_{\ell=1}^{n}\left\{\frac{\nabla_\ell f( z)}{\nabla_\ell f(cz)}\right\}}{4\ln(1+2d^2)} - \frac{ z^\trans \nabla f( z) - f( z) }{f(cz)}\right)

  r = \frac{\min_{\ell=1}^{n}\left\{\frac{\nabla_\ell f(\delta
        x)}{\nabla_\ell f(x)}\right\}}{\log\left(1+ d\rho\right)},

  \frac{1}{a_{tj}} \quad \geq \quad x^{\tau}_j \quad \geq\quad
  \frac{1}{\max_{i=1}^{t}\{a_{ij}\}\cdot d}
  \left(\exp\left(\frac{\ln\left(1 +
          d\rho\right)}{\mu^{\tau}_j} \sum_{i=1}^{t}a_{ij}y_i\right) -
    1\right),

\max_{c>0}\quad \min_{z} \left(\frac{\min_{\ell=1}^{n}\left\{\frac{\nabla_\ell f( z)}{\nabla_\ell f(cz)}\right\}}{2\ln(1+\rho d)}\right) - \max_{z} \left(\frac{ z^\trans \nabla f( z) - f( z)}{f(cz)}\right) \label{eq:mono-cr}

    f(x) ~~=~~ \frac1p \| Bx \|_p^p \,\,=\,\,\frac{1}{p}\sum_{k=1}^{K}\left(B_k
      x\right)^p \,\,=\,\, \frac{1}{p}\sum_{k=1}^{K}\left( \sum_{j=1}^n
      \b_{kj}\cdot x_j
    \right)^p .
  
    \frac{f(z)}{f(cz)} & = (1/c)^p \\
    \frac{\nabla_j f(z)}{\nabla_j f(c z)} &= (1/c)^{p-1} \\
    \frac{\sum_{j=1}^{n}z_j \cdot \nabla f(z)_j}{f(cz)} &=
    \frac{\sum_{j=1}^{n}z_j\sum_{k=1}^K \b_{kj }\cdot \left(B_k z\right)^{p-1}}{f(cz)}=     \frac{p\cdot f(z)}{f(cz)}  = p(1/c)^{p}.
     
    {\rm Dual} \geq \left(\frac{\delta^{p-1}}{4 \ln(1 + 2d^2)} - p \delta^p +
      \delta^p\right) \cdot {\rm Primal}
  {2}
    \min & \quad g(x) \,\,=\,\, \sum_{k=1}^{K}\bigg( \sum_{j=1}^n
    \b_{kj}\cdot x_j \bigg)^p
    \,+\, \sum_{j=1}^n \bigg(\sum_{k=1}^K \b_{kj}^p\bigg)\cdot x_j \\
    s.t. & \quad \sum_{j : e\in S_j} x_j  \geq 1, \qquad \forall e \in U\\
    &\quad x \geq 0.
  
\overline{C} & =& \sum_{k=1}^K  \left(C_k +\sum_{e\in U} D_{ek}\right)^p \quad \le \quad 2^p \sum_{k=1}^K  C_k^p + 2^p \sum_{k=1}^K  \left(\sum_{e\in U} D_{ek}\right)^p \quad \le \quad  2^p \cdot C + 2^p \sum_{k=1}^K  r^p \sum_{e\in U} D_{ek}^p \notag \\
&=& 2^p \cdot C+ (2r)^p \sum_{e\in U} D_{e}  \label{eq:multSC-1}
\E[C_k^p]  \le  K_p \cdot \bigg( \E[C_k]^p + \sum_{j=1}^n \E[\b_{kj}^p
\cdot X_j^p] \bigg) \le K_p \cdot \bigg( (4p\log r)^p \;
\bigg(\sum_{j=1}^n \b_{kj}\cdot x_j\bigg)^p + 4p\log r \sum_{j=1}^n
\b_{kj}^p \cdot x_j \bigg) .\E[C] = \sum_{k=1}^K \E[C_k^p] \le K_p (4p\log r)^p \sum_{k=1}^K \bigg( \bigg(\sum_{j=1}^n \b_{kj}\cdot x_j\bigg)^p + \sum_{j=1}^n \b_{kj}^p \cdot x_j  \bigg)  = K_p (4p\log r)^p \cdot g(x).{2}
  \min & \sum_{i=1}^{m}c_i x_i + \sum_{i,j}a_{ij}y_{ij} + \max_{i=1}^{m}\sum_{j=1}^{n}p_{ij} \cdot y_{ij}\\
  s.t. & \quad \sum_{i\in S} x_i + \sum_{i\notin S}y_{ij} \geq 1, \qquad
  \forall j \in [n], \forall S \subseteq [m] \\
  &\quad y, x \in \{0,1\}.
 f(x,y) \,\,=\,\, \bigg(\sum_{i=1}^{m}c_i x_i \bigg)^p \,+\, \bigg(
\sum_{i,j}a_{ij}y_{ij}\bigg)^p \, + \,
\sum_{i=1}^{m}\bigg(\sum_{j=1}^{n}p_{ij} \cdot y_{ij}\bigg)^p. g(x,y) \,\,=\,\, \bigg(\sum_{i}^{}c_i \bigg(x_i + \frac{\sum_j p_{ij} \cdot y_{ij}}{M}\bigg)\bigg)^p \,+\, \bigg( \sum_{i,j}a_{ij}y_{ij}\bigg)^p \, + \,  \sum_{i}^{}\bigg(\sum_{j}^{ }p_{ij} \cdot y_{ij}\bigg)^p.
  \min & \quad g(x,y) \label{eq:gLP} \\
  s.t. & \quad \sum_{i\in S} x_i + \sum_{i\notin S}y_{ij} \geq 1, \qquad
  \forall j\in [n], S \subseteq [m] \notag\\
  &\quad y, x \geq 0. \notag

\overline{y}_{ij}=\min\{y_{ij},x_i\}, \quad \forall i,j, \text{ and} \\
\ox_i = \max\left\{ x_i, \frac{\sum_j p_{ij} \cdot y_{ij}}{M} \right\},\quad \forall i.
{2}
  \textstyle \sum_j p_{ij}\cdot \oy_{ij} &\le M\cdot \ox_i & \qquad\qquad &\forall
  i \label{eq:ccfl:1} \\
  \textstyle \sum_{i=1}^m \oy_{ij} &\ge \frac12    &  &\forall j
  \label{eq:ccfl:2} \\
  \oy_{ij} &\le \ox_i &  &\forall i, j
  \label{eq:ccfl:3}
{2}
    \sum_i c_i\cdot \ox_i &\le 4\alpha \cdot M & &
    \label{eq:ccfl:4} \\
    \sum_{i,j}a_{ij}\cdot \oy_{ij}  &\le 4\alpha\cdot M & &
    \label{eq:ccfl:5} \\
    \sum_j p_{ij}\cdot \oy_{ij} &\le 4\alpha \cdot M &\qquad\qquad &\forall i.
    \label{eq:ccfl:6}
   g(x,y)\le \alpha^p\cdot m(3M)^p \leq (4\alpha M)^p, 
    \sum_i c_i\cdot \ox_i \le \sum_{i} c_i \left(x_i + \frac{\sum_j
        p_{ij} \cdot y_{ij}}{M}\right) \le g(x,y)^{1/p} \\
    \sum_{i,j}a_{ij}\cdot \oy_{ij} \le \sum_{i,j}a_{ij}y_{ij} \le
    g(x,y)^{1/p}\\
    \sum_j p_{ij} \cdot \oy_{ij} \le \sum_j p_{ij} \cdot y_{ij} \le
    g(x,y)^{1/p}
  
    \Pr[ Z_{ij}=1] =
      \begin{cases}
        \min\{4\log mn\cdot \oy_{ij}, 1\} & \mbox{ if }i\in F_f, \\
        \frac{\oy_{ij}}{\ox_i} & \mbox{ otherwise.}
      \end{cases}
  
    \Pr[j\mbox{ not assigned}] = \Pr[ \sum_i X_i Z_{ij}=0] = \prod_i (1-E[
    X_i Z_{ij}]) \le \exp\bigg(-4\log n\sum_i \oy_{ij}\bigg)<1/n^2,
  
  g(x) \,\,=\,\, \left(\sum_{i=1}^m \sum_{e\in T_i} c_e \left( x_e +
      \frac{2}{u_i} \sum_{v\in T^e} p_{v} \cdot x_{v,\tau(v)}
    \right)\right)^p \, + \, \sum_{i=1}^{m}\left(\frac{2C}{u_i}\cdot
    \sum_{v\in T_i} p_{v} \cdot x_{v,\tau(v)}\right)^p.

  g(x) \,\,=\,\, g(x,y) \,\,=\,\, \left(\sum_{i=1}^m \sum_{e\in T_i} c_e
    \left( x_e + \frac{2}{u_i} \sum_{j\in T^e} p_{ij} \cdot y_{ij}
    \right)\right)^p \, + \, \sum_{i=1}^{m}\left(\frac{2C}{u_i}\cdot
    \sum_{j\in T^e} p_{ij} \cdot y_{ij}\right)^p.
{2}
  \min & \quad g(x) \\
  s.t. & \quad \textstyle \sum_{e\in \delta(S)} x_e \geq 1, \qquad
  \forall \, \, V_j\subseteq S \subseteq V\setminus \{r\},~~\forall j\in [n]\\
  &\quad x \geq 0.

  \ox_e = \max\bigg\{ f_{e} ~~,~~ \frac{2}{u_i}\sum_{j\in T^e} p_{ij}
  \cdot y_{ij} \bigg\},\quad \forall e\in T_i,~ \forall i\in[m].
{2}
  \oy_{ij} &\leq \ox_i & \qquad\qquad
  & \forall j\in T^e, ~ \forall
  e\in T_i, ~ \forall i\in [m].
  \label{eq:cmp:0} \\
  \sum_{j\in T^e}\, p_{ij}\cdot \oy_{ij}  = \sum_{v\in
    T^e}\, p_{v}\cdot \ox_{v,\tau(v)}  &\le  u_i \cdot \ox_e
  & & \forall e\in T_i,\,\, \forall i\in [m].
  \label{eq:cmp:1} \\
  \ox_e &\le \ox_{\tau(e)} & & \forall \, e \in T.
  \label{eq:cmp:2} \\
  \sum_{i=1}^m \oy_{ij} &\ge 1 && \forall j\in [n].
  \label{eq:cmp:3}
{2}
    \sum_{e\in T} c_e\cdot \ox_e &\le  4\alpha \cdot C
    && \label{eq:cmp:4} \\
    \sum_{j\in T_i}\, p_{ij}\cdot \oy_{ij} = \sum_{v\in
      T_i}\, p_{v}\cdot \ox_{v,\tau(v)} &\le 4\alpha \cdot
    u_i, & \qquad\qquad &\forall i\in[m]. \label{eq:cmp:5}
  
    \sum_{e\in T} c_e\cdot \ox_e \le \sum_{e\in T} c_e \bigg(x_e +
      \frac{2}{u_i}\sum_{j\in T^e} p_{ij} \cdot y_{ij} \bigg) \le
    g(x,y)^{1/p} \\
    \frac{C}{u_i}\sum_{j\in T_i} p_{ij} \cdot \oy_{ij} \le \frac{2C}{u_i}
    \sum_{j\in T_i} p_{ij} \cdot y_{ij} \le g(x,y)^{1/p}
  
    \Pr[j\mbox{ not assigned to any tree in step 1}] = \prod_{i=1}^m
    \left( 1- \min\{\oy_{ij},1\} \right) \le \mathrm{e}^{-\sum_{i=1}^m \oy_{ij}}
    \le_{\eqref{eq:cmp:3}} \frac1{\mathrm{e}}.
  \label{eq:cmp-alteration}
    \Pr[j\mbox{ rejected in step 2 } | \, j \mbox{ assigned to  in step 1}]\quad \le \quad \frac18.
  
    E[\mbox{load from }S_h \mid  j\mbox{ assigned to  in step~1} ]  =
    \sum_{\ell\in S_h} p_{i\ell}\cdot
    \frac{\oy_{i\ell}}{\ox_{e_h}}\quad \le \quad \frac1{\ox_{e_h}} \cdot
    \sum_{\ell\in T^{e_h}} p_{i\ell}\cdot \oy_{i\ell} \quad
    \le_{\eqref{eq:cmp:1}} \quad u_i.
  
    E[\mbox{load from }\cup_{h=1}^k S_h \mid j\mbox{ assigned to
     in step~1}] \quad \le \quad k\cdot u_i \quad \le \quad d\cdot u_i,
  
    \Pr[\ell\mbox{ assigned to }T_i\mid j\mbox{ assigned to
     in step~1} ]=\Pr[\ell\mbox{ assigned to }T_i] = \oy_{i\ell}.
  
    E[\mbox{load from }[n]\setminus j\setminus \cup_{h=1}^k S_h \, | \,
    j\mbox{ assigned to  in step~1}] \quad \le \quad \sum_{\ell\in T_i}
    p_{i\ell}\cdot \oy_{i\ell} \quad \le \quad 4\alpha\cdot u_i
  
  g(x,y) \,\,=\,\, \left(\sum_{i}^{}c_i \left(x_i + \frac{\sum_j
        y_{ij}}{u_i}\right)\right)^p \,+\, C^p \cdot \sum_{i}^{} \left(
    x_i + \frac{1}{u_i} \sum_{j}^{ }y_{ij}\right)^p.
{2}
  \min & \quad g(x,y)\\
  s.t. & \quad \sum_{i\in T} x_i + \sum_{i\in F(\ell)\setminus T}y_{ij}
  \geq 1, \qquad \forall T\sse F(\ell),\,\, \forall \ell\in R_j,\,\,
  \forall j\in [k],\\
  &\quad y, x \geq 0.

  \overline{y}_{ij}=\min\{y_{ij},x_i\}, \quad \forall i,j. \\
\ox_i = \max\left\{ x_i, \frac{\sum_j y_{ij}}{u_i} \right\},\quad \forall i.
{2}
  \sum_j \oy_{ij} &\le u_i\cdot \ox_i & \qquad\qquad & \forall i.
  \label{eq:scsr:1} \\
  \sum_{i\in F(\ell)} \oy_{ij} &\ge \frac12 && \forall \ell\in R_j,\,\,
  \forall j\in [k].
  \label{eq:scsr:2} \\
  \oy_{ij} &\le \ox_i && \forall i, j.
  \label{eq:scsr:3}

    \sum_i c_i\cdot \ox_i \le 4\alpha \cdot C.
    \label{eq:scsr:4}\\
    \ox_{i} \le 4\alpha,\quad \forall i.
    \label{eq:scsr:6}
  
  Pr[ Z_{ij}=1] \,\,=\,\, \left\{
    \begin{array}{ll}
      \min\{4\log (mnk)\cdot \oy_{ij}, 1\} & \mbox{ if }i\in \oF, \\
      \frac{\oy_{ij}}{\ox_i} & \mbox{ otherwise.}
    \end{array}
  \right.
{2}
  \mbox{maximize } \sum_{i=1}^{n} \sum_{T\in \cS_i} &v_i(T)\cdot y_{iT} & \,\,-\,\, g(\mu)   &
  \tag{} \label{lp:prod-D}\\
  \sum_{T\in \cS_i} y_{iT} & \le 1 & & \forall \,
  i \in [n],   \label{lp:prod-D1} \\
\sum_{i=1}^n \sum_{T\in \cS_i} \mathbf{1}_{j\in T}\cdot y_{iT} - \mu_j & \le 0& \quad & \forall j\in [m],  \label{lp:prod-D2}  \\
  y,\mu &\geq 0. & \qquad &
{2}
  \mbox{minimize } \sum_{i=1}^{n} \ou_i \,\,+\,\, & g^\star(x) &  &
  \tag{} \label{lp:prod-P}\\
  \ou_i + \sum_{j\in T} x_j & \ge v_i(T) & & \forall \,
  i \in [n], \,\,\forall T\in \cS_i,  \label{lp:prod-P1} \\
  \ou,x &\geq 0. & \qquad &

  f(\ou,x)\quad :=\quad \sum_{i=1}^{n} \ou_i \,+\, g^\star(x).

\max_{c > 0}\left\{ \min_{z} \left(\frac{\min_{\ell=1}^{n}\left\{\frac{\nabla_\ell g^\star(z)}{\nabla_\ell g^\star(cz)}\right\}}{2\ln(1+\rho d)}\right) - \max_{z}
\left(\frac{ z^\trans \nabla g^\star(z) - g^\star(z)
  }{g^\star(c z)}\right) \right\} \label{eq:prod-comp-ratio}

  \rho \quad \le \quad R\,:=\, \,\, \frac{ \max \left\{ v_i(T) : T\in
      \cS_i,\, i\in [n]\right\}}{\min \left\{v_i(T) : T\in \cS_i,
      v_i(T)>0,\, i\in [n]\right\}}. \label{eq:def-R}

    \textstyle \ou_i + \left(\sum_{j\in T} x_j -
      v_i(T)\right) < 0, \label{eq:sep-oracle-prod}
  
    \min_{T\in \cS_i} \, \bigg(\sum_{j\in T} x_j - v_i(T)\bigg) \quad =
    \quad \min_{T\in \cS_i} \, \sum_{j\in T} (x_j - v_{ij}) \quad =
    \quad -\max_{T\in \cS_i} (v_{ij}-x_j),
  a(1-\frac1m)\cdot \sum_{i=1}^{n} \sum_{T\in \cS_i} v_i(T)\cdot y_{iT} - a \cdot g(\mu) - g(L\cdot \mathbf{1}).
g((1+\epsilon)a\cdot \mu + \ell\cdot \mathbf{1}) & = & g\left(\frac{1}{1+\epsilon}\cdot (1+\epsilon)^2a\cdot \mu + \frac{\epsilon}{1+\epsilon}\cdot (1+\frac1\epsilon) \ell\cdot \mathbf{1}\right)\\
&\le &  g\left((1+\epsilon)^2a\cdot \mu\right) +  g\left( (1+\frac1\epsilon) \ell\cdot \mathbf{1}\right)\\
&\le & ((1+\epsilon)^2a)^\beta\cdot g(\mu) + g\left( L\cdot \mathbf{1}\right)\quad = \quad a \cdot g(\mu) + g\left( L\cdot \mathbf{1}\right).
 \label{eq:prod-cost-eg1} g(\mu) \quad =\quad \min \left\{ \frac{1}{q}\sum_{k=1}^K z_k^q\,\, :\,\, \sum_{k=1}^K p_{kj}\cdot z_k \ge \mu_j,\, \forall j\in[m],\,\, z\ge 0\right\}.
g^\star(x) \quad =\quad \frac{1}{p}\sum_{k=1}^K \left(\sum_{j=1}^m p_{kj}\cdot x_j\right)^p, \qquad \mbox{where }\frac{1}{p}+\frac1q=1.\label{eq:prod-cost-eg2} g (\mu) \quad =\quad \frac{1}{p}\sum_{k=1}^K \left(\sum_{j=1}^m c_{kj}\cdot \mu_j\right)^p.
g^\star(x) \quad =\quad \min \left\{ \frac{1}{q}\sum_{k=1}^K z_k^q\,\, :\,\, \sum_{k=1}^K c_{kj}\cdot z_k \ge x_j,\, \forall j\in[m],\,\, z\ge 0\right\}, \qquad \mbox{where }\frac{1}{p}+\frac1q=1.{2}
  \mbox{minimize } \sum_{i=1}^{n} \ou_i \,\,+\,\, & \frac1q \sum_{k=1}^K z_k^q  \qquad \qquad \qquad \mathbf{(P')}
  \notag & \\ \ou_i + \sum_{j\in T} \sum_{k=1}^K c_{kj}\cdot z_k & \ge v_i(T),\quad  \forall \,
  i \in [n], \,\,\forall T\in \cS_i,  & \notag \\
  \ou,z &\geq 0. & \notag
{2}
  \mbox{maximize } \sum_{i=1}^{n} \sum_{T\in \cS_i} &v_i(T)\cdot y_{iT}  \,\,-\,\, \frac1p \sum_{k=1}^K \lambda_k^p   \qquad \mathbf{(D')} \notag &\\
  \sum_{T\in \cS_i} y_{iT}  \le 1,   & \quad \forall \, i \in [n],   \notag \\
\sum_{i=1}^n \sum_{T\in \cS_i} (\sum_{j\in T} c_{kj} ) & \cdot y_{iT} - \lambda_k  \le 0, \quad  \forall k\in [K],  \notag  \\
  y,\lambda &\geq 0. \notag
c_k^T \mu \quad = \quad \sum_{j=1}^m c_{kj} \cdot \mu_j \quad = \quad \sum_{j=1}^m c_{kj} \sum_{i=1}^n \sum_{T\in \cS_i} \mathbf{1}_{j\in T}\cdot y_{iT} \quad = \quad \sum_{i=1}^n \sum_{T\in \cS_i} y_{iT} \sum_{j\in T} c_{kj} \quad \le \quad \lambda_k.\rho \,\, = \,\, R\cdot \frac{K\cdot \max\{c_{kj} : k\in[K],j\in[m]\} }{\min\{c_{kj}: k\in[K],j\in[m]\}}.
Above  is the maximum-to-minimum ratio of valuations, and recall .

Combined with Theorem~\ref{thm:prod-integral} (), we obtain:
\begin{cor}
There is a randomized online algorithm for PMPC with cost function~\eqref{eq:prod-cost-eg2} for  that achieves expected profit at least .
\end{cor}
Here  where  is the maximum entry in .

\bibliographystyle{alpha}
{\small \bibliography{covering-pd}}

\end{document}
