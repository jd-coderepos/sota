\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage[rebuttal]{cvpr}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage[dvipsnames]{xcolor}
\usepackage{gensymb}
\usepackage{multirow}
\newcommand\mc[1]{\multicolumn{1}{c}{#1}}


\usepackage[pagebackref,breaklinks,colorlinks,bookmarks=false]{hyperref}

\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}






\def\cvprPaperID{6518} \def\confName{CVPR}
\def\confYear{2022}

\newcommand{\rI}[1]{{\color{red}{[R1:#1]}}}
\newcommand{\rII}[1]{{\color{ForestGreen}{[R2:#1]}}}
\newcommand{\rIII}[1]{{\color{blue}{[R3:#1]}}}
\newcommand{\RI}{{\color{red}\textbf{R1}}}
\newcommand{\RII}{{\color{ForestGreen}\textbf{R2}}}
\newcommand{\RIII}{{\color{blue}\textbf{R3}}}


\newcommand{\gb}[1]{{\color{olive}{[GB:#1]}}}  \newcommand{\gbt}[1]{{\color{olive}{#1}}} \newcommand{\cm}[1]{{\color{orange}{[CM:#1]}}}  \newcommand{\cmt}[1]{{\color{orange}{#1}}} 

\newcommand{\remove}[1]{{\color{magenta}{#1}}} 

\newcommand{\myparagraph}[1]{\vspace{-0.5pt}\noindent\textbf{#1}}

\begin{document}

\title{Rethinking Visual Geo-localization for Large-Scale Applications}  

\maketitle
\thispagestyle{empty}
\appendix

\noindent






\myparagraph{[{\RI, \RII}] Dataset.} 
SF-XL was built following our experience with real-world applications of VG, where the test database is collected before deployment of the software and is available at training time. SF-XL \textbf{only} has an overlap between training and test \textbf{database}, but the test queries are \textbf{never} seen at training time.
({\RII}) The dataset was created from Google StreetView following the examples of Tokyo24/7 and Pitts250k, which have been instrumental to the growth of this field of research. As these prior datasest did, we will make ours available on request.
({\RI}) We want to clarify a few points:
\textbf{(i)} at training time GeoClass uses only 4 groups as this is enough to learn a robust representation (\cref{tab:new_ablations} upper half).
Moreover, GeoClass is robust w.r.t. the selection of these 4 groups (\cref{tab:new_ablations} lower half), as each group approximately spans the same area and has the same number of classes.
\textbf{(ii)} while SF-XL v1 contains very challenging queries, SF-XL v2 has simpler queries but they are labeled with 6DOF camera pose, making it also suitable for city-scale pose estimation.
\textbf{(iii)} GeoClass is able to exploit large amounts of data much better than previous methods. Although we do not use all images in SF-XL, we believe its size can foster future works on large-scale VG. 







\myparagraph{[{\RI, \RII}] GeoClass groups and classes.} 
Each group (containing on average 350k images organized in around 18k classes) can be seen as a separate dataset. Training can even be performed on a single group (in this case, the cosPlace collapses to a cosFace) with a little loss in recall (\cref{tab:new_ablations}). \\
Heading labels are crucial to compute groups and classes, as described by eqs. (1)-(2).
Without heading labels (equivalent to using ), all images within a cell would fall into the same class even if they look in different directions.
In practice, the scenario where a building can be seen from two different classes of the same group is avoided by taking  and  big enough: two classes belonging to the same group are by definition at least  meters apart or at least  degrees apart in heading/orientation (i.e. 40m and 90\degree with the used hyperparameters).
Moreover, following eq.~(1), when  then  regardless of the , and using any value of  would not make sense because  would be  regardless of  when  (cf. eq.~(2)).







\myparagraph{[{\RI, \RII}] Training.} 
The sequential training over each group is an approximation of the cosPlace loss that makes training 68\% faster.
We found that training with cosPlace instead of the sequential approximation leads to small improvements on 4 out of 5 datasets.
Given that cosPlace is an ensemble of multiple LMCL losses, each group requires a distinct classification layer.





\myparagraph{[{\RI, \RII}] Hyperparameters.} 
For our preliminary experiments, and to choose the right hyperparameters, we relied on the val set of Pitts30k. Tuning the hyperparameters on the test set would not only be against machine learning ethics but, as stated at \textbf{L326}, it would also require an unfeasibly long time because of the large test database of SF-XL.













\myparagraph{[{\RI, \RII, \RIII}] Results.} 
Previous VG methods require the training set to be split in database and queries, resulting in an intrinsic bias (see in Tab. 2 the difference when using SF-XL* and SF-XL**, i.e. different splits of the same data).
On the other hand, GeoClass uses the dataset as a whole for training.
({\RII}) Images in SF-XL, SF-XL* and SF-XL** are exactly the same, but SF-XL is not split in two sets. \\
({\RI}, {\RIII}) For all methods we carefully followed their authors' instructions (or directly their code), and avoided validating the methods on the test set, whereas the authors of SFRS suggest to "[...] test all the five checkpoints [...] and generally at least one of them would achieve satisfactory performance on tokyo." (\begin{footnotesize}\url{https://github.com/yxgeee/OpenIBL/issues/9}\end{footnotesize}), which explains the gap in results.











\myparagraph{[{\RI}] Backbones.} 
We used a ResNet-18 in our preliminary experiments and ablations, as it is 10x lighter and 4x faster than a VGG-16 with similar results\footnote{\url{https://github.com/jcjohnson/cnn-benchmarks}}.
Note that all VG SOTA methods since 2016 use a VGG-16 with NetVLAD, and that changing the backbone for NetVLAD can be difficult (\begin{footnotesize}\url{https://github.com/yxgeee/OpenIBL/issues/16}\end{footnotesize}).
In contrast, the ablation in Fig. 5 shows that GeoClass is robust to very diverse backbones.



\myparagraph{[{\RI}] Dependency on GeM.} 
We replaced GeM with max and average pooling, and max pooling results in a drop of R@1 of 0.6 (averaged over all datasets), while average pooling in a drop of 0.9. This shows that GeoClass would outperform previous SOTA even with a basic architecture.



\myparagraph{[{\RIII}] Using Google Landmark (GL).} 
Unlike VG datasets such as Pitts30k and Tokyo 24/7, GL does not provide GPS coordinates for each image, and therefore we can't use GeoClass on it (or any other geo-localization training method).
For transparency, we used the most similar model trained on GL
and found that our GeoClass-based VGG outperforms it by 7.8 on R@1 (averaged over all datasets).


\myparagraph{[{\RI, \RII, \RIII}] Changes to the paper.}
Upon acceptance, we pledge to improve the unclear parts of the paper, and to add extensive results in the supplementary (e.g. ablations over all hyperparameters, comparisons with models trained on Google Landmark, replacing GeM with other poolings).




\begin{table}[t!]
\centering
  \resizebox{\columnwidth}{!}{
  \begin{tabular}{ccccc}
    \toprule
    \# groups & 1 & 2 & 4 & 8 \\
    \midrule
    R@1 & 90.1 & 90.3 & 90.6 & 90.5 \\
    \specialrule{.3em}{.2em}{.2em}
    groups &  &  &  &  \\
    \midrule
    R@1 & 90.6 & 90.5 & 90.7 & 90.3 \\    \bottomrule
  \end{tabular}}
   \caption{\textbf{New ablations} to investigate the effect of the number of groups used for training (upper half), and different selections of groups (lower half) to train GeoClass. Results on Pitts30k val set.}
  \label{tab:new_ablations}
  \vspace{-0.4cm}
\end{table}









\end{document}
