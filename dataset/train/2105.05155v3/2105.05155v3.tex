\documentclass{article} \usepackage{collas2022_conference,times}



\usepackage{amsmath,amsfonts,bm}






\def\figref#1{figure~\ref{#1}}
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
\def\secref#1{section~\ref{#1}}
\def\Secref#1{Section~\ref{#1}}
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
\def\eqref#1{equation~\ref{#1}}
\def\Eqref#1{Equation~\ref{#1}}
\def\plaineqref#1{\ref{#1}}
\def\chapref#1{chapter~\ref{#1}}
\def\Chapref#1{Chapter~\ref{#1}}
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
\def\algref#1{algorithm~\ref{#1}}
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
\def\partref#1{part~\ref{#1}}
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}


\def\eps{{\epsilon}}


\def\reta{{\textnormal{$\eta$}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}

\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}











\let\ab\allowbreak






















































 
\usepackage{url}

\usepackage{booktabs}       \usepackage{amsfonts}       \usepackage{nicefrac}       \usepackage{microtype}      \usepackage{xcolor}         \usepackage{geometry}
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{textcomp}
\usepackage{siunitx}
\usepackage{mathtools}
\usepackage{float}
\usepackage{graphicx}
\usepackage{subcaption}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=red,
    filecolor=magenta,      
    urlcolor=blue,
    citecolor=purple,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
    }




\title{TAG: Task-based Accumulated Gradients for Lifelong learning}





\author{Pranshu Malviya \\Department of Computer and Software Engineering\\
Mila - Quebec AI Institute\\
École Polytechnique de Montréal\\
Montréal, Canada \\
\And Balaraman Ravindran \\
Robert Bosch Center for Data Science and Artificial Intelligence \\
Department of Computer Science and Engineering \\
IIT Madras \\ 
Chennai, India \\
\AND Sarath Chandar \\
Department of Computer and Software Engineering\\
Mila - Quebec AI Institute \\
École Polytechnique de Montréal \\
Canada CIFAR AI Chair \\
Montréal, Canada \\
}



\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\collasfinalcopy 

\begin{document}


\maketitle

\begin{abstract}
When an agent encounters a continual stream of new tasks in the lifelong learning setting, it leverages the knowledge it gained from the earlier tasks to help learn the new tasks better. In such a scenario, identifying an efficient knowledge representation becomes a challenging problem. Most research works propose to either store a subset of examples from the past tasks in a replay buffer, dedicate a separate set of parameters to each task or penalize excessive updates over parameters by introducing a regularization term. While existing methods employ the general task-agnostic stochastic gradient descent update rule, we propose a task-aware optimizer that adapts the learning rate based on the relatedness among tasks. We utilize the directions taken by the parameters during the updates by additively accumulating the gradients specific to each task. These task-based accumulated gradients act as a knowledge base that is maintained and updated throughout the stream. We empirically show that our proposed adaptive learning rate not only accounts for catastrophic forgetting but also exhibits knowledge transfer. We also show that our method performs better than several state-of-the-art methods in lifelong learning on complex datasets. Moreover, our method can also be combined with the existing methods and achieve substantial improvement in performance.
\end{abstract}



\section{Introduction}
    


    Lifelong learning (LLL), also known as continual learning, is a setting where an agent continuously learns from data belonging to different tasks \citep{parisi2019continual}. Here, the goal is to maximize performance on all the tasks arriving in a stream without replaying the entire datasets from past tasks \citep{riemer2018learning}. Approaches proposed in this setting involve investigating the stability-plasticity dilemma \citep{mermillod2013stability} in different ways where stability refers to preventing the forgetting of past knowledge and plasticity refers to accumulating new knowledge by learning new tasks \citep{mermillod2013stability, delange2021continual}. 
    
    Unlike human beings, who can efficiently assess the correctness and applicability of the past knowledge \citep{chen2018lifelong}, neural networks and other machine learning models often face various issues in this setting. Whenever data from a new task arrives, these models often tend to forget the previously obtained knowledge due to dependency on the input data distribution, limited capacity, diversity among tasks, etc. This leads to a significant drop in performance on the previous tasks - also known as \textit{catastrophic forgetting}
\citep{MCCLOSKEY1989109,323080,xie2021artificial}.
    
    Recently there has been an ample amount of research proposed in LLL \citep{delange2021continual}. Several methods, categorized as \textit{Parameter Isolation} methods, either freeze or add a set of parameters as their task knowledge when a new task arrives. Another type of methods, known as \textit{Regularization-based} methods, involve an additional regularization term to tackle the stability-plasticity dilemma \citep{kirkpatrick2017overcoming,li2021lifelong}. There are approaches based on approximate Bayesian inference, where parameters are sampled from a distribution, that suggest controlling the updates based on parameter uncertainty \citep{blundell2015weight,adel2019continual,ahn2019uncertainty}. But these approaches are computationally expensive and often depend on the choice of prior \citep{zenke2017continual,nguyen2018variational}. 

   






    Another class of methods, namely \textit{Replay-based} methods, store a subset of examples from each task in a replay buffer. These methods apply gradient-based updates that facilitate a high-level transfer across different tasks through the examples from the past tasks that are simultaneously available while training. As a result, these methods tend to frame LLL as an i.i.d. setting \citep{bang2021rainbow,saha2021gradient}. While replay-based methods are currently state-of-the-art in several LLL tasks, it is important that we explore various ways to tackle the original non-i.i.d. problem \citep{HADSELL20201028}. Hence the focus of this paper is to design efficient replay-free methods for LLL.


    While adaptive gradient descent based optimizers such as Adam \citep{kingma2014adam} have shown superior performance in the classical machine learning setup, many existing works in LLL employ the conventional stochastic gradient descent for parameter update \citep{lopez2017gradient,chaudhry2019tiny,farajtabar2020orthogonal}. Adaptive gradient descent based optimizers accumulate gradients to regulate the magnitude and direction of updates but often struggle when the dataset arrives in a non-i.i.d. manner, from different tasks, etc. These optimizers tend to `over-adapt' on the most recent batch and hence suffer from poor generalization performance \citep{keskar2017improving, chen2018closing, mirzadeh2020understanding}. 

    While exploiting the adaptive nature of the gradient descent based optimizers, we alleviate catastrophic forgetting by introducing Task-based Accumulated Gradients (\textit{TAG}) that is a wrapper around existing optimizers. The key contributions of our work are as follows: (i)
We define a task-aware adaptive learning rate for the parameter update step that is also aware of relatedness among tasks in LLL. 
(ii) As the knowledge base, we propose to additively accumulate the directions (or gradients) that the network took while learning a specific task instead of storing past examples.
(iii) We empirically show that our method prevents catastrophic forgetting and exhibits knowledge transfer if the tasks are related without introducing more parameters.


    Our proposed method, described in Section \ref{tag_sec}, achieves state-of-the-art results and outperforms several Replay-free methods on complex datasets like \textbf{Split-miniImageNet}, \textbf{Split-CUB}, etc. For smaller episodic memory, our method also outperforms the \textit{Replay-based} methods as shown in Section \ref{exp_sec}. Note that we propose a new approach to optimizing based on the past gradients and as such it could potentially be applied along with the existing LLL methods including replay-based methods. We demonstrate the effectiveness of doing the same in the experiments. 
    
\section{Related Work}


    Methods proposed in LLL are broadly categorized into three classes: \textit{Regularization-based}, \textit{Parameter Isolation} and \textit{Replay-based} methods \citep{masana2020class,delange2021continual,mai2022online}. \textit{Regularization-based} methods prevent a drastic change in the network parameters as the new task arrives to mitigate forgetting. These methods further are classified as data-focused \citep{li2017learning,triki2017encoder,li2021lifelong} and prior-focused methods \citep{nguyen2018variational,ebrahimi2019uncertainty}. In particular, Elastic Weight Consolidation (\textit{EWC}) \citep{kirkpatrick2017overcoming}, a prior-focused method, regularizes the loss function to minimize changes in the parameters important for previous tasks. Yet, when the model needs to adapt to a large number of tasks, the interference between task-based knowledge is inevitable with fixed model capacity.
\textit{Parameter Isolation} methods \citep{rusu2016progressive,xu2018reinforced,serra2018overcoming} such as \citep{aljundi2017expert} assign a model copy to every new task that arrives. These methods alleviate catastrophic forgetting in general, but they rely on a strong base network and work on a small number of tasks. Another closely related methods, called Expansion-based methods, handle the LLL problem by expanding the model capacity in order to adapt to new tasks \citep{sodhani2018training,rao2019continual}. \textit{Replay-based} methods maintain an `episodic memory', containing a few examples from past tasks, that is revisited while learning a new task \citep{riemer2018learning,jin2020gradient}. For instance, Averaged Gradient Episodic Memory (\textit{A-GEM}) \citep{chaudhry2018efficient}, alleviating computational inefficiency of GEM \citep{lopez2017gradient}, uses the episodic memory to project the gradients based on hard constraints defined on the episodic memory and the current mini-batch. Experience Replay (\textit{ER}) \citep{chaudhry2019tiny} uses both replay memory and input mini-batches in the optimization step by averaging their gradients to mitigate forgetting. { On the other hand, we propose a replay-free method that maintains a fixed-capacity model during training and test time.} 

    Task-relatedness \citep{li2017learning,jerfel2019reconciling,shaker2020modular} or explicitly learning task representations \citep{yoon2017lifelong} is also an alternative approach studied in LLL. Efficient Lifelong Learning Algorithm (\textit{ELLA}) \citep{ruvolo2013ella} maintains sparsely shared basis vectors for all the tasks and refines them whenever the model sees a new task. \citet{rao2019continual} perform dynamic expansion of the model while learning task-specific representation and task inference within the model. Orthogonal Gradient Descent (\textit{OGD}) \citep{farajtabar2020orthogonal} maintains a space based on a subset of gradients from each task. As a result, \textit{OGD} often faces memory issues during run-time depending upon the size of the model and the subset \citep{bennani2020generalisation}. Unlike \textit{OGD}, we accumulate the gradients and hence alleviate the memory requirements by orders for each task. 
    
    A recent work \citep{mirzadeh2020understanding} argues that tuning the hyper-parameters gives a better result than several state-of-the-art methods including \textit{A-GEM} and \textit{ER}. They introduce \textit{Stable SGD} that involves an adjustment in the hyper-parameters like initial learning rate, learning rate decay, dropout, and batch size. They present this gain in performance on simplistic benchmarks like \textbf{Permuted MNIST} \citep{goodfellow2013empirical}, \textbf{Rotated MNIST} and \textbf{Split-CIFAR100} \citep{mirzadeh2020understanding}. { Another related work \citep{gupta2020maml} discusses a similar technique of using learning rate with episodic memory to reflect the similarities between the old and new tasks. On the other hand, our method explicitly computes the similarities between the tasks to regulate the learning rate.}




\section{Method}\label{tag_sec}
\subsection{Lifelong learning Setup}

In this section, we introduce the notations and the LLL setup used in the paper. We focus on the standard task-incremental learning scenario which is adopted in the numerous state-of-the-art LLL methods. It involves solving new tasks using an artificial neural network with a multi-head output where each head is associated with a unique task and the task identity is known beforehand \citep{lopez2017gradient,van2019three,delange2021continual}. We denote the current task as $t$ and any of the previous tasks by $\tau$. The model receives new data of the form $\{X^{(t)}, D^{(t)}, Y^{(t)}\}$ where $X^{(t)}$ are the input features, $D^{(t)}$ is the task descriptor (that is a natural number in this work) and $Y^{(t)}$ is the target vector specific to the task $t$.
    
We consider the `single-pass per task' setting in this work following \citep{lopez2017gradient,riemer2018learning,chaudhry2019tiny} where the model is trained only for one epoch on the dataset. It is more challenging than the multiple pass setting used in numerous research works \citep{kirkpatrick2017overcoming,rebuffi2017icarl}. The goal is to learn a classification model $f(X^{(t)}; \theta)$, parameterized by $\theta \in \mathbb{R}^P$ to minimize the loss $L(f(X^{(t)}; \theta), Y^{(t)})$ for the current task $t$ while preventing the loss on the past tasks from increasing. We evaluate the model on a held-out set of examples of all the tasks ($\leq t$) seen in the stream. 




\subsection{Task-based accumulated gradients}\label{tag_def_section}
The specific form of our proposed method depends on the underlying adaptive optimizer. For ease of exposition, we describe it as a modification of RMSProp \citep{rmsprop} here and call it \textit{TAG-RMSProp}. The \textit{TAG} versions of other methods such as the Adagrad \citep{duchi2011adaptive} and Adam are available in Appendix \ref{app_tag_opt}. A \textit{Naive RMSProp} update, for a given learning rate $\eta$, looks like the following:
     \begin{align} 
     \begin{split}
       V_n &= \beta V_{n-1} + (1-\beta)g^2_n ;~~1\leq n\leq N\\
        \theta_{n+1} &= \theta_n - \frac{\eta}{\sqrt{V_n + \epsilon}} g_n
    \end{split}\label{rms_eq}
    \end{align}
    where $\theta_n$ is the parameter vector at step $n$ in the epoch, $g_n$ is the gradient of the loss, $N$ is the total number of steps in one epoch, $V_n$ is the moving average of the square of gradients (or the \textit{second moment}), and $\beta$ is the decay rate. We will use \textit{TAG-optimizers} as a generic terminology for the rest of the paper. 
    
    We maintain the second moment $V^{(t)}_n$ for each task $t$ in the stream and store it as the knowledge base. When the model shifts from one task to another, the new loss surface may look significantly different. We argue that by using the task-based second moment to regulate the new task updates, we can reduce the interference with the previously optimized parameters in the model. 
We define the second moment $V^{(t)}_n$ for task $t$ for \textit{TAG-RMSProp} as:
$V^{(t)}_n = \beta_2 V^{(t)}_{n-1} + (1-\beta_2)g^2_n$  where $\beta_2$ is constant throughout the stream. We use $\textbf{V}^{(t)}_n$ to denote a matrix that stores the second moments from all previous tasks, i.e., $\textbf{V}^{(t)}_n = \{V^{(1)}_N, ..., V^{(t-1)}_N, V^{(t)}_n\}$ of size $(t \times P)$. Hence, the memory required to store these task-specific accumulated gradients increases linearly as the number of tasks in the setting. 


    Note that each $V^{(\tau)}_N (\text{where}~\tau<t)$ vector captures the gradient information when the model receives data from a task $\tau$ and does not change after the task $\tau$ is learned. It helps in regulating the magnitude of the update while learning the current task $t$. 
To alleviate the catastrophic forgetting problem occurring in the \textit{Naive RMSProp}, we replace $V_n$ (in Eq. \ref{rms_eq}) to a weighted sum of $\textbf{V}^{(t)}_n$. We propose a way to regulate the weights corresponding to $\textbf{V}^{(t)}_n$ for each task in the next section. 


\subsection{Adaptive Learning Rate}\label{alpha_sec}

    Next, we describe our proposed learning rate that adapts based on the relatedness among tasks. We discuss how task-based accumulated gradients can help regulate the parameter updates to minimize catastrophic forgetting and transfer knowledge.

We first define a representation for each task to enable computing correlation between different tasks. We take inspiration from a recent work \citep{guiroy2019towards} which is based on a popular meta-learning approach called Model-Agnostic Meta-Learning (MAML) \citep{finn2017model}. \citet{guiroy2019towards} suggest that with reference to given parameters $\theta^s$ (where $s$ denotes shared parameters), the similarity between the adaptation trajectories (and also meta-test gradients) among the tasks can act as an indicator of good generalization. This similarity is defined by computing the inner dot product between adaptation trajectories. In the experiments, \citet{guiroy2019towards} show an improvement in the overall target accuracy by adding a regularization term in the outer loop update to enhance the similarity.
    
    In the case of LLL, instead of a fixed point of reference $\theta^s$, the parameters continue to update as the model adapts to a new task. Analogous to the adaptation trajectories, we essentially want to capture those task-specific \textit{gradient directions} in the LLL setting. Momentum serves as a less noisy estimate for the overall gradient direction and hence approximating the adaptation trajectories. The role of momentum has been crucial in the optimization literature for gradient descent updates \citep{ruder2016overview,li2017convergence}. Therefore, we introduce the task-based \textit{first moment} $M^{(t)}_n$ in order to approximate the adaptation trajectories of each task $t$. It is essentially the momentum maintained while learning each task $t$ and would act as the task representation for computing the correlation. 

    The $M^{(t)}_n$ is defined as: 
$M^{(t)}_n = \beta_1 M^{(t)}_{n-1} + (1-\beta_1)g_n$ 
where $\beta_1$ is the constant decay rate. Intuitively, if the current task $t$ is correlated with a previous task $\tau$, the learning rate in the parameter update step should be higher to encourage the transfer of knowledge between task $t$ and $\tau$. In other words, it should allow knowledge transfer. Whereas if the current task $t$ is uncorrelated or negatively correlated to a previous task $\tau$, the new updates over parameters may cause catastrophic forgetting because these updates for task $t$ may point in the opposite direction of the previous task $\tau$'s updates. In such a case, the learning rate should adapt to lessen the effects of the new updates. We introduce a scalar quantity $\alpha_n(t,\tau)$ to capture the correlation that is computed using $M^{(t)}_n$ and $M^{(\tau)}_N$: 
    \begin{align} \label{alpha_eq}
    \alpha_n(t,\tau) &=  exp\left(-b~\frac{{M_n^{(t)}}^TM^{(\tau)}_N}{|M_n^{(t)}||M^{(\tau)}_N|}\right)
    \end{align}
    where $|.|$ is the Euclidean norm. Existing adaptive optimizers, such as Adam, tend to overfit on the most recent dataset from a task, which results in catastrophic forgetting in LLL. By using the exponential term, the resulting $\alpha_n(t,\tau)$ will attain a higher value for uncorrelated tasks and will minimize the new updates (hence prevent forgetting). 
    Here, $b$ is a hyperparameter that tunes the magnitude of $\alpha_n(t,\tau)$. The higher the $b$ is, the greater is the focus on preventing catastrophic forgetting. Its value can vary for different datasets. For the current task $t$ at step $n$ (with $\theta^{(t)}_1 = \theta^{(t-1)}_{N+1}$), we define the \textit{TAG-RMSProp} update as:

    \begin{align} \label{update}
    \theta^{(t)}_{n+1} &= \theta^{(t)}_n - \frac{\eta}{\sqrt{\alpha_n(t,t)~ V^{(t)}_n + \sum\limits_{\tau=1}^{t-1} \alpha_n(t,\tau)~ V^{(\tau)}_N + \epsilon}} g_n
    \end{align}





    Hence, the role of each $\alpha_n(t,\tau)$ is to regulate the influence of corresponding task-based accumulated gradient $V^{(\tau)}_N$ of the previous task $\tau$. Since we propose a new way of looking at the gradients, our update rule (Eq. \ref{update}) can be applied with any kind of task-incremental learning setup. In this way, the overall structure of the algorithm for this setup remains the same.



\section{Experiments}\label{exp_sec}

We describe the experiments performed to evaluate our proposed method.\footnote{Code for the experiments is submitted as supplementary material and will be released publicly upon acceptance.} 
In the first experiment, we show the gain in performance by introducing \textit{TAG} update instead of naive optimizers update. We analyse how our proposed learning rate adapts and achieves a higher accuracy over the tasks in the stream. Next, we compare our proposed replay-free method with other state-of-the-art baselines and also show that \textit{TAG} update (in Eq. \ref{update}) can be used along with other state-of-the-art methods to improve their results. 

    The experiments are performed on four benchmark datasets: \textbf{Split-CIFAR100}, \textbf{Split-miniImageNet}, \textbf{Split-CUB} and \textbf{5-dataset}. \textbf{Split-CIFAR100} and \textbf{Split-miniImageNet} splits the \textbf{CIFAR-100} \citep{krizhevsky2009learning,mirzadeh2020understanding} and \textbf{Mini-imagenet} \citep{vinyals2016matching,chaudhry2019tiny} datasets into 20 disjoint 5-way classification tasks. \textbf{Split-CUB} splits the \textbf{CUB} \citep{wah2011caltech} dataset into 20 disjoint tasks with 10 classes per task. \textbf{5-dataset} is a sequence of five different datasets as five 10-way classification tasks. These datasets are: \textbf{CIFAR-10} \citep{krizhevsky2009learning}, \textbf{MNIST} \citep{mnist}, \textbf{SVHN} \citep{netzer2011reading}, \textbf{notMNIST} \citep{notmnist} and \textbf{Fashion-MNIST} \citep{xiao2017fashion}. More details about the datasets are given in Appendix \ref{exp_details}.
For experiments with \textbf{Split-CIFAR100} and \textbf{Split-miniImageNet}, we use a reduced ResNet18 architecture following \citep{lopez2017gradient,chaudhry2019tiny}. We use the same reduced ResNet18 architecture for \textbf{5-dataset}. For \textbf{Split-CUB}, we use a ResNet18 model which is pretrained on Imagenet dataset \citep{imagenet_cvpr09} as used in \citep{chaudhry2019tiny}. 

    We report the following metrics by evaluating the model on the held-out test set: \textbf{(i)} \textbf{Accuracy} \citep{lopez2017gradient} i.e., average test accuracy when the model has been trained sequentially up to the latest task, \textbf{(ii)} \textbf{Forgetting} \citep{chaudhry2018riemannian} i.e., decrease in performance of each task from their peak accuracy to their accuracy after training on the latest task and \textbf{(iii)} \textbf{Learning Accuracy (LA)} \citep{riemer2018learning} i.e., average accuracy for each task immediately after it is learned.
    The overall goal is to maximise the average test \textbf{Accuracy}. Further, a LLL algorithm should also achieve high \textbf{LA} while maintaining a low value of \textbf{Forgetting} because it should learn the new task better without compromising its performance on the previous tasks (see Appendix \ref{exp_details}).





    
    We report the above metrics on the best hyper-parameter combination obtained from a grid-search. The overall implementation of the above setting is based on the code provided by \citep{mirzadeh2020understanding}. The details of the grid-search and other implementation details corresponding to all experiments described in our paper are given in Appendix \ref{hyper}. For all the experiments described in this section, we train the model for a single epoch per task. Results for multiple epochs per task are given in Appendix \ref{multi_pass}. All the performance results reported are averaged over five runs. 



\subsection{Naive optimizers}\label{naive_opt}



    We validate the improvement by our proposed setting over the gradient descent based methods and demonstrate the impact of using correlation among tasks in the \textit{TAG-optimizers}. Firstly, we train the model on a stream of tasks using \textit{Naive SGD} update without applying any specific LLL method. Similarly, we replace the SGD update with \textit{Naive Adagrad}, \textit{Naive RMSProp}, \textit{Naive Adam} and their respective \textit{TAG-optimizers} to compare their performances. We show the resulting \textbf{Accuracy (\%)} (in Fig. \ref{naive_acc_bar}) and \textbf{Forgetting} (in Fig. \ref{naive_forg_bar}) when the model is trained in with the above-mentioned optimizers. 



   \begin{figure}[h!]
        \centering
        \begin{subfigure}[b]{0.33\textwidth}
            \includegraphics[width=\textwidth]{pics/naive_vs_tag.png}\caption{Accuracy (\%)}\label{naive_acc_bar}
        \end{subfigure}
        \begin{subfigure}[b]{0.33\textwidth}
            \includegraphics[width=\textwidth]{pics/naive_vs_tag_f.png}\caption{Forgetting}\label{naive_forg_bar}
        \end{subfigure}
        \includegraphics[width=0.11\linewidth]{pics/naive_vs_tag_label.png}
        \caption{Final average test \textbf{Accuracy (\%)} (higher is better) and \textbf{Forgetting} (lower is better) obtained after the stream is finished for all four datasets. The vertical bars with hatches are the performance by \textit{TAG-optimizers} while others are \textit{Naive} optimizers. \textit{TAG-optimizers} outperforms the naive optimizers in all datasets in terms of accuracy and also results in a lower forgetting.}
       
    \end{figure}


    It is clear that \textit{TAG-optimizers} outperform their naive counterparts as well as \textit{Naive SGD} for all four datasets by a significant amount. There is a notable decrease in \textbf{Forgetting} by \textit{TAG-optimizers} (in Fig. \ref{naive_forg_bar}) in general that eventually reflects on the gain in final test \textbf{Accuracy} as seen in Fig. \ref{naive_acc_bar}. In \textbf{Split-CUB}, \textit{TAG-Adam} ($57\%$) shows a remarkable improvement in accuracy when compared to \textit{Naive Adam} ($45\%$) such that it even surpasses \textit{Naive SGD} ($55\%$). Interestingly, \textit{TAG-Adam} results in slightly lower accuracy as compared to \textit{TAG-Adagrad} except in \textbf{Split-miniImageNet}. Moreover, \textit{Naive Adagrad} results in a better performance than \textit{Naive RMSProp} and \textit{Naive Adam} for all the datasets. This observation aligns with the results by \citet{hsu2018re}. \textit{Naive SGD} performs almost equivalent to \textit{Naive Adagrad} except in \textbf{5-dataset} where it is outperformed.
    





\begin{figure*}[h!]
        \centering
        \begin{subfigure}[b]{0.28\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-CUB_2_.png}
            \caption{$\tau=2$}\label{t2}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.28\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-CUB_5_.png}
            \caption{$\tau=5$}\label{t5}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.28\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-CUB_6_.png}
            \caption{$\tau=6$}\label{t6}
        \end{subfigure}
\caption{Evolution of (a) $\alpha(t,2)$ and test accuracy $a_{t,2}$ (left), (b) $\alpha(t,5)$ and test accuracy $a_{t,5}$ (middle) and (c) $\alpha(t,6)$ and test accuracy $a_{t,6}$ (right) along the stream of $20$ tasks in the \textbf{Split-CUB} dataset. The grey-coloured lines are $\max_{\tau'} \alpha_n(t,\tau')$ (top, dashed line), $\mathbb{E}_{\tau'} [\alpha(t,\tau')]$ (middle, solid line) and $\min_{\tau'} \alpha(t,\tau')$ (bottom, dashed line) that indicate the range of $\alpha(t,\tau')$. Elliptical regions (black dashed) highlight subtle gain in the accuracy by \textit{TAG-RMSProp} that are maintained throughout the stream. Observing corresponding $\alpha(t,\tau)$ in those regions validates our hypothesis discussed from Section \ref{alpha_sec}.}
        \label{alpha_fig}
    \end{figure*}

    Next, we analyse $\alpha(t,\tau)$ which is the average of $\alpha_n(t,\tau)$ across all steps $n$ for all $t$ and $\tau$ when stream is finished i.e., $\alpha(t,\tau) = \frac{1}{N}\sum_{n=1}^N \alpha_n(t,\tau)$. We show how $\alpha(t,\tau)$ values play role in the gain in \textit{TAG-optimizers} accuracies in case of \textbf{Split-CUB} dataset. Each plot in Fig. \ref{alpha_fig} corresponds to test accuracies $a_{t,\tau}$ (with shaded areas indicating their standard deviations) for \textit{Naive RMSProp} (blue) and \textit{TAG-RMSProp} (red) for a particular $\tau$ for all tasks $t$ in the stream (x-axis). Along with that, the grey-coloured curves are $\max_{\tau'} \alpha_n(t,\tau')$ (top, dashed line), $\mathbb{E}_{\tau'} [\alpha(t,\tau')]$ (middle, solid line) and $\min_{\tau'} \alpha(t,\tau')$ (bottom, dashed line) respectively. { These curves are shown along with the corresponding $\alpha(t,\tau)$ to indicate the rank of $\alpha(t,\tau)$ in the set $\{\alpha(t,\tau');~ \tau'\in[1,t]\}$. This set is computed when the model encounters the task $t$ in the stream.}

    The accuracies of \textit{TAG-RMSProp} and \textit{Naive RMSProp} appear to correlate for most of the stream. We mark the regions (black dashed ellipse) of subtle improvements in the accuracy by \textit{TAG-RMSProp} that is later maintained throughout the stream. While observing $\alpha(t,\tau)$ in those regions particularly, we note that the rank of $\alpha(t,\tau)$ affects the accuracy in \textit{TAG-RMSProp} as following: \textbf{(i)} Lower (or decrease in) rank of $\alpha(t,\tau)$ means that there exists some correlation between the tasks $t$ and $\tau$. So, the model should take advantage of the current task updates and seek (or even amplify) backward transfer. Such observations can be made for the following $(t,\tau)$: $(4,2)$, $(5,2)$, $(14,2)$, $(9,5)$, $(14,6)$, $(19,6)$ etc. Our method also prevents drastic forgetting as well in few cases. For example: $(7, 2)$, $(12, 2)$, $(10,6)$. \textbf{(ii)} Higher (or increase in) rank of $\alpha(t,\tau)$ results in prevention of forgetting as observed in Fig. \ref{alpha_fig}. Such $(t,\tau)$ pairs are $(11,2)$, $(7,5)$, $(12,5)$, $(12,6)$, etc. It also results in backward transfer as observed in $(11,5)$ and $(15,5)$. We report the same analysis for the other three datasets and show the results in Appendix \ref{alpha_app}. 




\subsection{Compared with other baselines}\label{baseline_opt}
    \begin{table*}[t!]
        \caption{Comparing performance in terms of final average test \textbf{Accuracy (\%)} (higher is better), \textbf{Forgetting} (lower is better) and Learning Accuracy (\textbf{LA (\%)}) (higher is better) of the existing baselines with \textit{TAG-RMSProp} on all four datasets. All metrics are averaged across 5 runs. Overall, \textit{TAG-RMSProp} outperforms all other methods in terms of \textbf{Accuracy}. \textit{*MTL} assumes that the whole dataset from all tasks is always available during training, hence it is a different setting and its accuracy acts as an upper bound.}
\centering
        \resizebox{\textwidth}{!}{\begin{tabular}{c c c c c c c}
        \hline
        \multirow{2}{*}{\textbf{Methods}} &  \multicolumn{3}{c}{\textbf{Split-CIFAR100}} & \multicolumn{3}{c}{\textbf{Split-miniImageNet}}\\
                \cmidrule(lr){2-4} \cmidrule(l){5-7}
             & \textbf{Accuracy (\%)} & \textbf{Forgetting} & \textbf{LA (\%)} & \textbf{Accuracy (\%)} & \textbf{Forgetting} & \textbf{LA (\%)} \\
        \midrule
        \textit{Naive SGD} &   $ 51.36 ~(\pm 3.21 )$ & $ 0.18 ~(\pm 0.03 )$ & $ 68.46 ~(\pm 1.93 )$  & $ 48.19 ~(\pm 0.79 )$ & $ 0.13 ~(\pm 0.01 )$ & $ 60.6 ~(\pm 0.95 )$ \\
        \textit{Naive RMSProp} &  $ 48.91 ~(\pm 2.88 )$ & $ 0.2 ~(\pm 0.03 )$ & $ 67.28 ~(\pm 0.43 )$  & $ 45.06 ~(\pm 0.6 )$ & $ 0.21 ~(\pm 0.01 )$ & $ 64.39 ~(\pm 1.02 )$ \\
        \hline
        \textit{EWC} & $ 49.06 ~(\pm 3.44 )$ & $ 0.19 ~(\pm 0.04 )$ & $ 66.82 ~(\pm 1.41 )$ & $ 47.87 ~(\pm 2.08 )$ & $ 0.15 ~(\pm 0.02 )$ & $ 61.66 ~(\pm 1.06 )$
        \\
        \textit{A-GEM} &   $ 54.25 ~(\pm 2.0 )$ & $ 0.16 ~(\pm 0.03 )$ & $ 68.98 ~(\pm 1.19 )$ & $ 50.32 ~(\pm 1.29 )$ & $ 0.11 ~(\pm 0.02 )$ & $ 61.02 ~(\pm 0.64 )$ \\
        \textit{ER} &   $ 59.14 ~(\pm 1.77 )$ & $ 0.12 ~(\pm 0.02 )$ & $ 70.36 ~(\pm 1.23 )$ & $ 54.67 ~(\pm 0.71 )$ & $ 0.1 ~(\pm 0.01 )$ & $ 64.06 ~(\pm 0.41 )$ \\
        \textit{Stable SGD} &   $ 57.04 ~(\pm 1.07 )$ & $ 0.09 ~(\pm 0.0 )$ & $ 64.62 ~(\pm 0.91 )$ & $ 51.81 ~(\pm 1.66 )$ & $ 0.09 ~(\pm 0.01 )$ & $ 59.99 ~(\pm 0.94 )$ \\
        \hline
        \textbf{TAG-RMSProp (Ours)} &  $ \textbf{62.79} ~(\pm 0.29 )$ & $ 0.1 ~(\pm 0.01 )$ & $ 72.06 ~(\pm 1.01 )$  & $ \textbf{57.2} ~(\pm 1.37 )$ & $ 0.06 ~(\pm 0.02 )$ & $ 62.73 ~(\pm 0.61 )$ \\
        \hline
        \textit{MTL*} &  $67.7 ~(\pm 0.58)$ & - & - &$66.14~(\pm1.0)$ & - & - \\
        \hline
        \end{tabular}}\\
        \resizebox{\textwidth}{!}{\begin{tabular}{c c c c c c c}
        \hline
        \multirow{2}{*}{\textbf{Methods}} &   \multicolumn{3}{c}{\textbf{Split-CUB}} & \multicolumn{3}{c}{\textbf{5-dataset}}\\
        \cmidrule(lr){2-4} \cmidrule(l){5-7}
             &  \textbf{Accuracy (\%)} & \textbf{Forgetting} & \textbf{LA (\%)} & \textbf{Accuracy (\%)} & \textbf{Forgetting} & \textbf{LA (\%)} \\
        \midrule
        \textit{Naive SGD} & $ 54.88 ~(\pm 1.83 )$ & $ 0.12 ~(\pm 0.01 )$ & $ 65.97 ~(\pm 0.59 )$  & $ 46.48 ~(\pm 3.62 )$ & $ 0.48 ~(\pm 0.05 )$ & $ 84.55 ~(\pm 1.06 )$\\
        \textit{Naive RMSProp} &  $ 49.4 ~(\pm 1.77 )$ & $ 0.24 ~(\pm 0.01 )$ & $ 71.76 ~(\pm 0.94 )$ & $ 45.49 ~(\pm 1.89 )$ & $ 0.5 ~(\pm 0.03 )$ & $ 85.58 ~(\pm 1.21 )$\\
        \hline
        \textit{EWC} & $ 55.66 ~(\pm 0.97 )$ & $ 0.12 ~(\pm 0.01 )$ & $ 66.36 ~(\pm 0.71 )$ & $ 48.58 ~(\pm 1.47 )$ & $ 0.4 ~(\pm 0.03 )$ & $ 79.56 ~(\pm 3.18 )$\\
        \textit{A-GEM} &  $ 56.91 ~(\pm 1.37 )$ & $ 0.1 ~(\pm 0.01 )$ & $ 65.6 ~(\pm 0.73 )$ & $ 55.9 ~(\pm 2.58 )$ & $ 0.34 ~(\pm 0.04 )$ & $ 82.61 ~(\pm 2.13 )$\\
        \textit{ER} &  $ 59.25 ~(\pm 0.82 )$ & $ 0.1 ~(\pm 0.01 )$ & $ 66.17 ~(\pm 0.42 )$ & $ 61.58 ~(\pm 2.65 )$ & $ 0.28 ~(\pm 0.04 )$ & $ 84.3 ~(\pm 1.08 )$ \\
        \textit{Stable SGD} & $ 53.76 ~(\pm 2.14 )$ & $ 0.11 ~(\pm 0.01 )$ & $ 62.15 ~(\pm 1.12 )$ & $ 46.51 ~(\pm 2.75 )$ & $ 0.46 ~(\pm 0.03 )$ & $ 83.3 ~(\pm 1.44 )$\\
        \hline
        \textbf{TAG-RMSProp (Ours)} & $ \textbf{61.58} ~(\pm 1.24 )$ & $ 0.11 ~(\pm 0.01 )$ & $ 71.56 ~(\pm 0.74 )$ & $ \textbf{62.59} ~(\pm 1.82 )$ & $ 0.29 ~(\pm 0.02 )$ & $ 86.08 ~(\pm 0.55 )$\\
        \hline
        \textit{MTL*} &  $71.65~(\pm0.76)$ &  - & - & $70.0~(\pm4.44)$  &  - & - \\
        \hline
        \end{tabular}}
        \label{main_table}
    \end{table*}


{ In the next experiment, we show that the \textit{TAG-RMSProp} results in a strong performance as compared to other LLL algorithms. In Table \ref{main_table}, we report the performance of \textit{TAG-RMSProp} and the following state-of-the-art baselines: \textit{EWC} \citep{kirkpatrick2017overcoming}, \textit{A-GEM} \citep{chaudhry2018efficient}, \textit{ER} \citep{aljundi2019online} with reservoir sampling and \textit{Stable SGD} \citep{mirzadeh2020understanding}. Additional details about our implementation are given in Appendix \ref{exp_details}.}
Apart from these baselines, we report the performance of \textit{Naive SGD} and \textit{Naive RMSProp} from the previous section. We also report results on multi-task learning (MTL) settings on all four datasets where the dataset from all the tasks is always available throughout the stream. Hence, the resulting accuracies of the MTL setting serve as the upper bounds for the test accuracies in LLL. Following \citet{mirzadeh2020understanding}, the size of the episodic memory for both \textit{A-GEM} and \textit{ER} is set to store $1$ example per class. Since we want to evaluate \textit{TAG} with all other baselines on the original non-i.i.d. problem, we keep the episodic memory size in the replay-based methods small for the comparison. We still report \textit{A-GEM} and \textit{ER} results with bigger memory sizes in Appendix \ref{agem_er_app}. The size of the mini-batch sampled from the episodic memory is set equal to the batch-size to avoid data imbalance while training. 

Other baselines such as \textit{OGD} \citep{farajtabar2020orthogonal} requires storing N (=$200$ in their experiments) number of gradients per task and it is evaluated only on variants of the MNIST dataset by training a small feed-forward network. On the other hand, \textit{TAG} additively accumulates the gradients and hence requires memory equal to two copies of the model as the knowledge base. This enabled us to train a reduced ResNet18 on complex datasets. Due to greater memory requirements, \textit{OGD} faced memory errors in our setting. We would also like to highlight that \textit{OGD} use \textit{Naive-SGD}, whereas \textit{TAG}, being an adaptive learning rate based method, is complementary to this approach.{ Although we utilize a similar amount of memory as Progressive Neural Networks \cite{rusu2016progressive}, an expansion-based method, we do not make any changes to the size of the model during the training and testing process. On the other hand, \cite{rusu2016progressive} require quadratic growth in the number of parameters as the number of tasks increases. Hence, we do not compare our approach with the expansion-based method in our experiments.}
    


	From the results reported in Table \ref{main_table}, we observe that \textit{TAG-RMSProp} achieves the best performance in terms of test \textbf{Accuracy} as compared to other baselines for all datasets. The overall improvement is decent in \textbf{Split-CIFAR100}, \textbf{Split-miniImageNet} and \textbf{Split-CUB} which are $3.65\%$, $2.5\%$ and $2.3\%$ with regard to the next-best baseline. On the other hand, the improvement by \textit{TAG-RMSProp} is relatively minor in \textbf{5-dataset} i.e., $1\%$ as compared to \textit{ER} with the similar amount of \textbf{Forgetting} ($0.29$ and $0.28$) occurring in the stream. In terms of \textbf{LA}, \textit{TAG-RMSProp} achieves almost similar performance as \textit{Naive RMSProp} in \textbf{Split-CUB} and \textbf{5-dataset}. We also note that the \textbf{LA} of \textit{TAG-RMSProp} is higher in \textbf{Split-CIFAR100}, \textbf{Split-CUB} and \textbf{5-dataset} than \textit{ER} and \textit{A-GEM}. 
The higher \textbf{LA} with similar \textbf{Forgetting} as compared to other baselines shows that while \textit{TAG} exploits the adaptive nature of existing optimizers, it also ensures minimal forgetting of the gained knowledge. The existing optimizers tend to aggressively fit the model on the most recent task at an immense cost of forgetting the earlier tasks. Hence, even if a similar (or lower) \textbf{Forgetting} occurs in \textit{TAG}, the higher test \textbf{Accuracy} (with high \textbf{LA}) shows that \textit{TAG} is capable of retaining the gained knowledge from each task. Although \textbf{LA} is lower in \textbf{Split-miniImageNet}, \textit{TAG-RMSProp} manages to prevent catastrophic forgetting better than these methods and hence results in a higher test \textbf{Accuracy}.


    \begin{figure*}[t!]
        \centering
        \begin{subfigure}[b]{0.3\textwidth}
            \includegraphics[width=\textwidth]{pics/cifar_sota.png}
            \caption{\textbf{Split-CIFAR100}}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.3\textwidth}
            \includegraphics[width=\textwidth]{pics/imagenet_sota.png}
            \caption{\textbf{Split-miniImageNet}}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.3\textwidth}
            \includegraphics[width=\textwidth]{pics/cub_sota.png}
            \caption{\textbf{Split-CUB}}
        \end{subfigure}
        \caption{Evolution of average test \textbf{Accuracy (\%)} $A_t$ for different existing methods and \textit{TAG-RMSProp} throughout the stream in \textbf{Split-CIFAR100}, \textbf{Split-miniImageNet} and \textbf{Split-CUB}. All results are averaged across 5 runs and the shaded area represent standard deviation. Performing similar as \textit{ER} for major part of the stream, \textit{TAG-RMSProp} always results in the highest final accuracy as compared to other methods with a low standard deviation.}
        \label{sota_fig}
    \end{figure*}

    Figure \ref{sota_fig} provides a detailed view of the test \textbf{Accuracy} of individual baseline as the model encounters the new tasks throughout the LLL stream in \textbf{Split-CIFAR100}, \textbf{Split-miniImageNet} and \textbf{Split-CUB}. At the starting task $t=1$, \textit{TAG-RMSProp} beats other baselines because of lower initial learning rates (see Appendix \ref{hyper}) and reflects the performance gain by the RMSProp over SGD optimizer. In all three datasets, the performance of \textit{TAG-RMSProp} is very similar to \textit{ER} specially from task $t=5$ to task $t=15$, but ultimately improves as observed at $t=20$. These results show a decent gain in the final test \textbf{Accuracy} by \textit{TAG-RMSProp} as compared to other baselines. To analyze how the presence of similar tasks help the model to perform better, we also perform the experiment with \textbf{Rotated MNIST} \citep{lopez2017gradient} dataset, details of which are given in Appendix \ref{5data_rotated}.




\subsection{Combined with other baselines}\label{tag_base_opt}


    Lastly, we show that the existing baselines can also benefit from our proposed method \textit{TAG-RMSProp}. We replace the conventional SGD update from \textit{EWC}, \textit{A-GEM} and \textit{ER}, and apply RMSProp update (Eq. \ref{rms_eq}) and \textit{TAG-RMSProp} update (Eq. \ref{update}) respectively. We use the same task-incremental learning setup as used in the previous sections in terms of architecture and hyper-parameters. We compare the resulting accuracies of the baselines with their \textit{RMSProp} and \textit{TAGed} versions in Fig. \ref{taged_table}. 
    
    \begin{figure*}[h!]
        \centering
        \includegraphics[width=0.8\linewidth]{pics/taged_acc.png}
        \caption{Comparing performance for different existing methods with their \textit{RMSProp} and \textit{TAGed} versions on all four datasets in terms of final average test \textbf{Accuracy (\%)} along with \textit{A-GEM} and \textit{ER} for different samples per class ($\mathbb{M}$) in the episodic memory. The vertical bars with hatches are the performance by \textit{TAGed} versions of the baselines. All results are averaged across 5 runs. All \textit{TAGed} versions results in a similar gain in the accuracy over baselines with both SGD and RMSProp update.}
        \label{taged_table}
    \end{figure*}

    For a given dataset, we see that gain in the final accuracy in the \textit{TAGed} versions is similar for the baselines described in Section \ref{baseline_opt}. That is, \textit{TAG} improves these baselines with SGD update on \textbf{Split-CIFAR100},  \textbf{Split-miniImageNet}, \textbf{Split-CUB} and \textbf{5-dataset} by at least $8\%$, $4\%$, $4\%$ and $9\%$ respectively. On the other hand, \textit{TAG} improves the baselines with RMSProp update on the datasets by at least $12\%$, $12\%$, $7\%$ and $9\%$ respectively. The improvement is also significant in \textit{A-GEM} with bigger episodic memory (i.e., $10$ samples per class or $\mathbb{M}=10$) but we observe relatively smaller improvement (2\%) by \textit{TAGed ER} ($\mathbb{M}=10$) as compared to \textit{ER} ($\mathbb{M}=10$). These results show that apart from outperforming the baselines independently (with smaller episodic memory in replay-based methods), \textit{TAG} can also be used as an update rule in the existing research works for improving their performances. 

    While \textit{A-GEM} and \textit{ER} are strong baselines for LLL, we would like to highlight that these replay-based methods are not applicable in settings where storing examples is not an option due to privacy concerns. \textit{TAG-RMSProp} would be a more appropriate solution in such settings.
    
\section{Conclusion}
We propose a new task-aware optimizer for the LLL setting that adapts the learning rate based on the relatedness among tasks. We introduce the task-based accumulated gradients that act as the representation for individual tasks for the same. We conduct experiments on complex datasets to compare \textit{TAG-RMSProp} with several state-of-the-art methods. Results show that \textit{TAG-RMSProp} outperforms the existing methods in terms of final accuracy with a commendable margin without storing past examples or using dynamic architectures. We also show that it results in a significant gain in performance when combined with other baselines. To the best of our knowledge, ours is the first work in the LLL literature showing that we can use an adaptive gradient method for LLL and prevent forgetting better than \textit{Naive SGD}. For future work, as the memory required to store the task-specific accumulated gradients increases linearly with the tasks, reducing memory complexity without compromising the performance can be an interesting direction. This can be achieved by \textbf{(i)} computing correlation using a smaller quantity than the task-based first moments, and \textbf{(ii)} clustering the similar tasks together to reduce the number of task-based second moments (in settings with a soft margin between the tasks). Another possible direction from here can be shifting to a class-incremental scenario where the task identity is not known beforehand and is required to be inferred along the stream.



\bibliography{collas2022_conference}
\bibliographystyle{collas2022_conference}

\appendix
\section{Appendix}
In this document, we provide the details and results excluded from the main paper. In \ref{app_tag_opt}, we describe the \textit{TAG} versions of Adagrad and Adam. The implementation details are described in Section \ref{exp_details}. We also report results obtained by performing additional experiments in Section \ref{more_exp}. 

\subsection{TAG-optimizers}\label{app_tag_opt}
Similar to RMSProp (in Section \ref{tag_sec}), with the task-based first moments $M^{(t)}_n$, let $W^{(t)}_n=\{\alpha_n(t,\tau); \tau \in [1,t]\}$ (from Eq. \ref{alpha_eq}) and,
    \begin{align} \label{w_eq}
W^{(t)}_n \textbf{V}^{(t)}_n &= 
    \begin{cases} 
      V^{(1)}_n~; & t=1 \\
      \alpha_n(t,t)~ V^{(t)}_n + \sum\limits_{\tau=1}^{t-1} \alpha_n(t,\tau)~ V^{(\tau)}_N~; & t>1
      \end{cases}
    \end{align}

We define the \textit{TAG} versions of Adagrad and Adam as following: 
    \begin{itemize}
        \item \textit{TAG-Adagrad}:
    \begin{align} 
     \begin{split}
        V^{(t)}_n &= V^{(t)}_{n-1} + g^2_n\\
        \theta^{(t)}_{n+1} &= \theta^{(t)}_n - \frac{\eta}{\sqrt{W^{(t)}_n \textbf{V}_n + \epsilon}} g_n\\
        \end{split}\label{tag_adagrad_update}
    \end{align}
    \item \textit{TAG-Adam}:
     \begin{align} 
     \begin{split}
        V^{(t)}_n &= \beta_2 V^{(t)}_{n-1} + (1-\beta_2)g^2_n \\
        \theta^{(t)}_{n+1} &= \theta^{(t)}_n - \frac{\eta\sqrt{1-\beta_2^{n}}}{(1-\beta_1^{n})\sqrt{W^{(t)}_n \textbf{V}_n + \epsilon}}  M^{(t)}_n\\
        \end{split}\label{tag_adam_update}
    \end{align}
    \end{itemize}
Both \textit{TAG-Adagrad} (Eq. \ref{tag_adagrad_update}) and \textit{TAG-Adam} (Eq. \ref{tag_adam_update}) result in a significant gain in Accuracy and prevent Forgetting as observed in Fig. \ref{naive_acc_bar} and Fig. \ref{naive_forg_bar} respectively in Section \ref{naive_opt}.

\subsection{Implementation details}\label{exp_details}

The summary of the datasets used in the experiments is shown in Table \ref{data_stats} and Table \ref{5data_stats}.
    
\begin{table}[h!]
    \caption{Dataset Statistics}
    \vskip 0.1in
    \centering
    \begin{tabular}{c c c c}
        \hline
        & \textbf{Input size} & \textbf{Training samples per task} & \textbf{Test samples per task} \\
        \hline
        \textbf{Split-CIFAR100} & $3\times32\times32$ & $2500$ & $500$ \\
        \textbf{Split-miniImageNet} & $3\times84\times84$ & $2400$ & $600$ \\
        \textbf{Split-CUB}  & $3\times224\times224$ & $300$ & $290$ \\
        \hline
    \end{tabular}
    \label{data_stats}
\end{table}    
    


In \textbf{5-dataset}, we convert all the monochromatic images to RGB format depending on the task dataset. All images are then resized to $3\times32\times32$. The overall training and test data statistics of \textbf{5-dataset} are described in Table \ref{5data_stats}.

\begin{table}[h!]
    \caption{\textbf{5-dataset} statistics.}
    \vskip 0.1in
    \centering
    \begin{tabular}{c c c}
        \hline
        & \textbf{Training samples} & \textbf{Test samples} \\
        \hline
        \textbf{CIFAR-10}  & $50000$ & $10000$ \\
        \textbf{MNIST}  & $60000$ & $10000$ \\
        \textbf{SVHN}  & $73257$ & $26032$ \\
        \textbf{notMNIST}  & $16853$ & $1873$ \\
        \textbf{Fashion-MNIST} & $60000$ & $10000$ \\
        \hline
    \end{tabular}\label{5data_stats}
\end{table}

Details about the metrics used for evaluating the model: 
    \begin{itemize}
        \item \textbf{Accuracy} \citep{lopez2017gradient}: If $a_{t,\tau}$ is the accuracy on the test set of task $\tau$ when the current task is $t$, it is defined as,  
      $
        A_t = \frac{1}{t}\sum\limits_{\tau=1}^t a_{t,\tau}
        $.
        \item \textbf{Forgetting} \citep{chaudhry2018riemannian}: It is the average forgetting that occurs after the model is trained on all tasks. If the latest task is $t$ and is defined as,
        $
        F_t = \frac{1}{t-1}\sum\limits_{\tau=1}^{t-1} \max_{t' \in \{1,...,t-1\}} (a_{t',\tau} - a_{t,\tau})
        $.
        \item \textbf{Learning Accuracy (LA)} \citep{riemer2018learning}: It is the measure of learning capability when the model sees a new task. For the current task $t$, it is defined as, 
        $
        L_t = \frac{1}{t}\sum\limits_{\tau=1}^{t} a_{\tau,\tau}
        $.
    \end{itemize}

{
We implement the following baselines to compare with our proposed method:
\begin{itemize}
    \item \textit{EWC}: Our implementation of \textit{EWC} is based on the original paper \citep{kirkpatrick2017overcoming}.
    \item \textit{A-GEM}: We implemented \textit{A-GEM} based on the the official implementation provided by \citep{chaudhry2018efficient}.
    \item \textit{ER} \citep{chaudhry2019tiny}: Our implementation is based on the one provided by \citep{aljundi2019online} with reservoir sampling except that the sampled batch does not contain examples from the current task. 
	\item \textit{Stable SGD} \citep{mirzadeh2020understanding}: We obtain the best hyper-parameter set by performing grid-search over different combinations of the learning rate, learning rate decay, and dropout (see Appendix \ref{hyper}). 
\end{itemize}
}


We provide our code as supplementary material that contains the scripts for reproducing the results from experiments described in this paper. In the \textsc{code} folder, we include \textsc{readme.md} file that contains the overall code structure, procedure for installing the required packages, links to download the datasets and steps to execute the scripts. All experiments were executed on an NVIDIA GTX 1080Ti machine with 11 GB GPU memory. 

\subsubsection{Hyper-parameter details}\label{hyper} 
In this section, we report the grid search details for finding the best set of hyper-parameters for all datasets and baselines. We train the model with $90\%$ of the training set and choose the best hyper-parameters based on the highest accuracy on the validation set which consists of remaining $10\%$ for the training set. For existing baselines, we perform the grid search either suggested by the original papers or by \cite{farajtabar2020orthogonal}. For all \textit{TAG-optimizers}, $\beta_1$ is set to $0.9$. For \textit{TAG-RMSProp} and \textit{TAG-Adagrad}, $\beta_2$ is set to $0.99$ and for \textit{TAG-Adam} it is $0.999$. In all the experiments, the mini-batch size is fixed to $10$ for \textbf{Split-CIFAR100}, \textbf{Split-miniImageNet}, \textbf{Split-CUB} similar to \citep{chaudhry2019tiny,mirzadeh2020understanding}. We set mini-batch size to $64$ for \textbf{5-dataset} following \citep{serra2018overcoming}. This is because we wanted to highlight the role of learning rate and to show how \textit{TAG-RMSProp} improves the performance while the other hyper-parameters (including batch-size) were fixed. 


\begin{itemize}
    \item \textit{Naive SGD}
    \begin{itemize}
        \item Learning rate: [0.1 (\textbf{Split-CIFAR100}, \textbf{5-dataset}), 0.05 (\textbf{Split-miniImageNet}), 0.01(\textbf{Split-CUB}), 0.001]
    \end{itemize}
    \item \textit{Naive Adagrad}
    \begin{itemize}
        \item Learning rate: [0.01, 0.005 (\textbf{Split-CIFAR100}, \textbf{Split-miniImageNet}, \textbf{5-dataset}), 0.001, 0.0005 (\textbf{Split-CUB}), 0.0001]
    \end{itemize}
    \item \textit{Naive RMSProp}
    \begin{itemize}
        \item Learning rate: [0.01, 0.005 (\textbf{Split-CIFAR100}), 0.001 (\textbf{Split-miniImageNet}, \textbf{5-dataset}), 0.0005, 0.0001 (\textbf{Split-CUB}), 0.00005, 0.00001]
    \end{itemize}
    \item \textit{Naive Adam}
    \begin{itemize}
        \item Learning rate: [0.01, 0.005 (\textbf{Split-CIFAR100}), 0.001 (\textbf{Split-miniImageNet}, \textbf{5-dataset}), 0.0005, 0.0001 (\textbf{Split-CUB})]
    \end{itemize}
    \item \textit{TAG-Adagrad}
    \begin{itemize}
        \item Learning rate: [0.005 (\textbf{Split-CIFAR100}, \textbf{5-dataset}), 0.001 (\textbf{Split-miniImageNet}), 0.0005  (\textbf{Split-CUB}), 0.00025, 0.0001]
        \item $b$: [1, 3, 5 (\textbf{Split-CIFAR100}, \textbf{Split-miniImageNet}, \textbf{Split-CUB}), 7 (\textbf{5-dataset})] 
    \end{itemize}
    \item \textit{TAG-RMSProp}
    \begin{itemize}
        \item Learning rate: [0.005, 0.001, 0.0005 (\textbf{5-dataset}), 0.00025 (\textbf{Split-CIFAR100}), 0.0001 (\textbf{Split-miniImageNet}), 0.00005, 0.000025 (\textbf{Split-CUB}), 0.00001]
        \item $b$: [1, 3, 5 (\textbf{Split-CIFAR100}, \textbf{Split-miniImageNet}, \textbf{Split-CUB}), 7 (\textbf{5-dataset})] 
    \end{itemize}
    \item \textit{TAG-Adam}
    \begin{itemize}
        \item Learning rate: [0.005, 0.001 (\textbf{5-dataset}), 0.0005 (\textbf{Split-CIFAR100}), 0.00025 (\textbf{Split-miniImageNet}), 0.0001 (\textbf{Split-CUB})]
        \item $b$: [1, 3, 5 (\textbf{Split-CIFAR100}, \textbf{Split-miniImageNet}, \textbf{Split-CUB}), 7 (\textbf{5-dataset})] 
    \end{itemize}
    \item \textit{EWC}
    \begin{itemize}
        \item Learning rate: [0.1 (\textbf{Split-CIFAR100}, \textbf{5-dataset}), 0.05 (\textbf{Split-miniImageNet}), 0.01(\textbf{Split-CUB}), 0.001]
        \item $\lambda$ (regularization): [1 (\textbf{Split-CIFAR100}, \textbf{Split-miniImageNet}, \textbf{Split-CUB}), 10, 100 (\textbf{5-dataset})]
    \end{itemize}
    \item \textit{A-GEM}
    \begin{itemize}
        \item Learning rate: [0.1 (\textbf{Split-CIFAR100}, \textbf{Split-miniImageNet}, \textbf{5-dataset}), 0.05, 0.01(\textbf{Split-CUB}), 0.001]
    \end{itemize}
    \item \textit{ER}
    \begin{itemize}
        \item Learning rate: [0.1 (\textbf{Split-CIFAR100}, \textbf{5-dataset}), 0.05 (\textbf{Split-miniImageNet}), 0.01(\textbf{Split-CUB}), 0.001]
    \end{itemize}
    \item \textit{Stable SGD}
    \begin{itemize}
        \item Initial learning rate: [0.1 (\textbf{Split-CIFAR100}, \textbf{Split-miniImageNet}, \textbf{5-dataset}), 0.05 (\textbf{Split-CUB}), 0.01]
        \item Learning rate decay: [0.9 (\textbf{Split-CIFAR100}, \textbf{Split-miniImageNet}, \textbf{Split-CUB}), 0.8, 0.7 (\textbf{5-dataset})]
        \item Dropout: [0.0 (\textbf{Split-miniImageNet}, \textbf{Split-CUB}, \textbf{5-dataset}), 0.1 (\textbf{Split-CIFAR100}), 0.25, 0.5]
    \end{itemize}

\end{itemize}

In case of \textit{TAG-RMSProp}, we empirically found that the best performance of the all three benchmarks with $20$ tasks occurred when hyper-parameter $b=5$ and for \textbf{5-dataset}, $b=7$. We also found that a lower value of Learning rate in \textit{TAG-RMSProp} results in a better performance. These empirical observations can reduce the search space for hyperparameter setup by a huge amount when applying \textit{TAG-RMSProp} on a LLL setup. 

For the experiments in Section \ref{tag_base_opt} that require a hybrid version of these methods, we use the same hyperparameters from above except for \textit{TAGed ER} in \textbf{Split-CIFAR100} (Learning rate = 0.0005) and \textbf{Split-CUB} (Learning rate = 0.0001). We choose the learning rates of \textit{TAG-RMSProp} and \textit{Naive-RMSProp} over \textit{EWC}, \textit{A-GEM} and \textit{ER}.


\subsection{Additional Experiments}\label{more_exp}
In this section, we describe the additional experiments and analysis done in this work. 

\subsubsection{Backward Transfer Metric}
While we show the occurrence of knowledge transfer in Fig. \ref{alpha_fig}, we can quantify the Backward Transfer (\textbf{BWT}) \citep{chaudhry2019tiny} by computing the difference between the final \textbf{Accuracy} and \textbf{LA}. i.e., \\ $\textbf{BWT} = \frac{1}{t-1}\sum_{\tau=1}^{t-1} a_{t,\tau} - a_{\tau,\tau}$. We report the \textbf{BWT} results for all datasets and baselines in Table \ref{bwt_table}. 

While \textit{TAG-RMSProp} outperforms the other baselines in terms of \textbf{BWT} for \textbf{Split-miniImageNet}, it is overall the second-best method for \textbf{Split-CIFAR100} and \textbf{5-dataset}. In case of \textbf{Split-CUB}, even if \textbf{TAG-RMSProp} achieves the highest \textbf{Accuracy}, it results in a lower \textbf{BWT} because of a significantly higher \textbf{LA} as compared to the other baselines (see Table \ref{main_table}). 

\begin{table*}[h!]
        \caption{Comparing performance in terms of final average test \textbf{Accuracy (\%)} (higher is better) and \textbf{BWT} (higher is better) with the standard deviation values for different existing methods with \textit{TAG-RMSProp} for all four datasets. All metrics are averaged across 5 runs.}
        \vskip 0.1in
        \centering
        \resizebox{\textwidth}{!}{\begin{tabular}{c c c c c}
        \hline
        \multirow{2}{*}{\textbf{Methods}} &  \multicolumn{2}{c}{\textbf{Split-CIFAR100}} & \multicolumn{2}{c}{\textbf{Split-miniImageNet}}\\
                \cmidrule(lr){2-3} \cmidrule(l){4-5}
             & \textbf{Accuracy (\%)} & \textbf{BWT (\%)} & \textbf{Accuracy (\%)} & \textbf{BWT (\%)} \\
        \midrule
        \textit{Naive SGD} &   $ 51.36 ~(\pm 3.21 )$ & $ -17.1 ~(\pm 2.64 )$  & $ 48.19 ~(\pm 0.79 )$ & $ -13.83 ~(\pm 1.97 )$ \\
        \textit{Naive RMSProp} &  $ 48.91 ~(\pm 2.88 )$ & $ -18.37 ~(\pm 2.71 )$  & $ 45.06 ~(\pm 0.6 )$ & $ -19.32 ~(\pm 1.39 )$ \\
        \hline
        \textit{EWC} & $ 49.06 ~(\pm 3.44 )$  & $ -17.76 ~(\pm 3.35 )$ & $ 47.87 ~(\pm 2.08 )$ &  $ -13.79 ~(\pm 2.26 )$
        \\
        \textit{A-GEM} &   $ 54.25 ~(\pm 2.0 )$  & $ -14.73 ~(\pm 2.48 )$ & $ 50.32 ~(\pm 1.29 )$ &  $ -10.69 ~(\pm 1.57 )$ \\
        \textit{ER} &   $ 59.14 ~(\pm 1.77 )$  & $ -11.22 ~(\pm 2.19 )$ & $ 54.67 ~(\pm 0.71 )$ &  $ -9.39 ~(\pm 0.64 )$ \\
        \textit{Stable SGD} &   $ 57.04 ~(\pm 1.07 )$  & $ -7.59 ~(\pm 0.36 )$ & $ 51.81 ~(\pm 1.66 )$ & $ -8.18 ~(\pm 1.18 )$ \\
        \hline
        \textbf{TAG-RMSProp (Ours)} &  $ \textbf{62.79} ~(\pm 0.29 )$ &  $ -9.27 ~(\pm 1.16 )$  & $ \textbf{57.2} ~(\pm 1.37 )$  & $ -5.52 ~(\pm 1.71 )$ \\
        \hline
\end{tabular}}\\
        \resizebox{\textwidth}{!}{\begin{tabular}{c c c c c}
        \hline
        \multirow{2}{*}{\textbf{Methods}} &   \multicolumn{2}{c}{\textbf{Split-CUB}} & \multicolumn{2}{c}{\textbf{5-dataset}}\\
        \cmidrule(lr){2-3} \cmidrule(l){4-5}
             &  \textbf{Accuracy (\%)} & \textbf{BWT (\%)} & \textbf{Accuracy (\%)} &  \textbf{BWT (\%)} \\
        \midrule
        \textit{Naive SGD} & $ 54.88 ~(\pm 1.83 )$  & $ -11.09 ~(\pm 1.43 )$  & $ 46.48 ~(\pm 3.62 )$  & $ -38.06 ~(\pm 3.69 )$\\
        \textit{Naive RMSProp} &  $ 49.4 ~(\pm 1.77 )$ & $ -22.36 ~(\pm 0.95 )$ & $ 45.49 ~(\pm 1.89 )$  & $ -40.09 ~(\pm 2.6 )$\\
        \hline
        \textit{EWC} & $ 55.66 ~(\pm 0.97 )$  & $ -10.7 ~(\pm 0.39 )$ & $ 48.58 ~(\pm 1.47 )$ &  $ -30.98 ~(\pm 3.34 )$\\
        \textit{A-GEM} &  $ 56.91 ~(\pm 1.37 )$  & $ -8.69 ~(\pm 0.93 )$ & $ 55.9 ~(\pm 2.58 )$  & $ -26.71 ~(\pm 3.6 )$\\
        \textit{ER} &  $ 59.25 ~(\pm 0.82 )$  & $ -6.93 ~(\pm 0.92 )$ & $ 61.58 ~(\pm 2.65 )$  & $ -22.72 ~(\pm 3.08 )$ \\
        \textit{Stable SGD} & $ 53.76 ~(\pm 2.14 )$ & $ -8.39 ~(\pm 1.26 )$ & $ 46.51 ~(\pm 2.75 )$ & $ -36.79 ~(\pm 2.19 )$\\
        \hline
        \textbf{TAG-RMSProp (Ours)} & $ \textbf{61.58} ~(\pm 1.24 )$  & $ -9.99 ~(\pm 1.62 )$ & $ \textbf{62.59} ~(\pm 1.82 )$ & $ -23.49 ~(\pm 1.73 )$\\
        \hline
\end{tabular}}
        \label{bwt_table}
    \end{table*}
    
    
\subsubsection{Comparing with other baselines on Rotated-MNIST and 5-dataset}\label{5data_rotated}
We evaluate the performance of \textit{TAG-RMSProp} on \textbf{Rotated MNIST}  and \textbf{5-dataset} and in terms of average test \textbf{Accuracy} on each task in the stream. 

Here, \textbf{Rotated MNIST} \citep{lopez2017gradient} is a version of \textbf{MNIST} dataset \citep{mnist} where the images in a task are basically MNIST images with some fixed degrees of rotation. In our experiment, we consider $10$ tasks where we incrementally rotate the images by $30^{\circ}$ for each task. 

The goal of this experiment to answer two questions: \textbf{(i)} Is the proposed way to find similar tasks by computing correlation between task-based first moments valid? \textbf{(ii)} Can the presence of similar tasks in the stream help model to perform better? 

We plot the \textbf{Accuracy} for \textit{Naive SGD}, \textit{ER} and \textit{TAG-RMSProp} in Figure \ref{sota_5data}. Best performance of \textit{Naive SGD} and \textit{ER} was observed with learning rates $0.1$. For \textit{TAG-RMSProp}, we found the setting with $learning rate=0.00025$ and $b=5$ results in the best final \textbf{Accuracy}.
Details of \textbf{5-dataset} is given in Appendix \ref{exp_details}.

In Figure \ref{sota_rotate_}, we observe that \textit{TAG-RMSProp} not only outperforms \textit{ER} but there is a significant gain in \textbf{Accuracy} at $t=7$ (i.e., images with $180 ^{\circ}$ rotation). Since there are several digits that could look exactly same even with $180 ^{\circ}$ rotation, \textit{TAG} recognizes the similarity between $t=7$ and $t=1$ and is able to transfer the gained knowledge to result it increase in the \textbf{Accuracy}. This observation answers the above two questions since similar tasks in \textbf{Rotated MNIST} are recognized by \textit{TAG} and also help in improving the performance. As observed in Figure \ref{sota_5data_}, although \textit{TAG-RMSProp} is outperformed by \textit{ER} from task $t=2$ (\textbf{MNIST}) to $t=4$ (\textbf{notMNIST}) for \textbf{5-dataset}, it results in the highest final \textbf{Accuracy} as compared to other methods. Moreover, the increase in \textbf{Accuracy} from $t=2$ (MNIST) to $t=3$ (SVHN) also shows the positive transfer exhibited by \textit{TAG} as compared to \textit{ER}.


\begin{figure}[h!]
            \centering
        \begin{subfigure}[b]{0.45\textwidth}
            \includegraphics[width=\textwidth]{pics/rotate_.png}
            \caption{\textbf{Rotated MNIST}}\label{sota_rotate_}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.45\textwidth}
            \includegraphics[width=\textwidth]{pics/5data_.png}
            \caption{\textbf{5-dataset}}\label{sota_5data_}
        \end{subfigure}

\caption{Evolution of average test \textbf{Accuracy (\%)} $A_t$ for different existing methods and \textit{TAG-RMSProp} throughout the stream in \textbf{Rotated MNIST} and \textbf{5-dataset}. All results are averaged across 5 runs and the shaded area represent standard deviation.}
        \label{sota_5data}
    \end{figure}








\subsubsection{Evolution of $\alpha(t,\tau)$ and Test Accuracy $a_{t,\tau}$} \label{alpha_app}
    Next, we continue the analysis done in Section \ref{naive_opt} for \textbf{Split-CIFAR100} (in Fig. \ref{alpha_cifar_app}), \textbf{Split-miniImageNet}  (in Fig. \ref{alpha_imagenet_app}), \textbf{Split-CUB} (in Fig. \ref{alpha_cub_app}) for the first $9$ tasks and \textbf{5-dataset} (in Fig. \ref{alpha_5data_app}) for first $3$ tasks. In \textbf{Split-CIFAR100} and \textbf{Split-miniImageNet}, the model with \textit{Naive RMSProp} tends to forget the task $t$ by significant amount as soon as it receives the new tasks. On the other hand, \textit{TAG-RMSProp} prevents catastrophic forgetting and hence results in a higher accuracy throughout the stream. We can observe that for \textbf{Split-CIFAR100} and \textbf{Split-miniImageNet}, $\alpha(\tau+1,\tau)$ (where $\tau\in[1,9]$) generally have a higher rank in the set $\{\alpha(t,\tau');\tau'\in[1,t]\}$. This is because \textit{TAG-RMSProp} also recognizes an immediate change in the directions when the model receives a new task (from $M^{(t-1)}_N$ to $M^{(t)}_n$). A similar observation is made in case of \textbf{Split-CUB} but the visible gain in the accuracy by \textit{TAG-RMSProp} does not occur instantly. Apart from that, we observe that the lower and higher rank of $\alpha(t,\tau)$ results in backward transfer and prevents catastrophic forgetting respectively in the stream. Overall, in all datasets, we arrive at the same conclusion obtained in Section \ref{naive_opt}. 

    \begin{figure*}[t!]
        \centering
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-CIFAR100_1.png}\caption{$\tau=1$}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-CIFAR100_2.png}\caption{$\tau=2$}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-CIFAR100_3.png}\caption{$\tau=3$}
        \end{subfigure}
        \\
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-CIFAR100_4.png}\caption{$\tau=4$}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-CIFAR100_5.png}\caption{$\tau=5$}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-CIFAR100_6.png}\caption{$\tau=6$}
        \end{subfigure}
        \\
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-CIFAR100_7.png}\caption{$\tau=7$}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-CIFAR100_8.png}\caption{$\tau=8$}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-CIFAR100_9.png}\caption{$\tau=9$}
        \end{subfigure}
        \caption{Evolution of $\alpha(t,\tau)$ and test accuracy $a_{t,\tau}$ where $\tau \in [1,9]$ along the stream of $20$ tasks in the \textbf{Split-CIFAR100} dataset. The grey-coloured lines are $\max_{\tau'} \alpha_n(t,\tau')$  (top, dashed line), $\mathbb{E}_{\tau'} [\alpha(t,\tau')]$  (middle, solid line) and $\min_{\tau'} \alpha(t,\tau')$  (bottom, dashed line) that indicate the range of $\alpha(t,\tau')$. }
        \label{alpha_cifar_app}
    \end{figure*}
    \begin{figure*}[t!]
        \centering
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-miniImageNet_1.png}\caption{$\tau=1$}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-miniImageNet_2.png}\caption{$\tau=2$}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-miniImageNet_3.png}\caption{$\tau=3$}
        \end{subfigure}
        \\
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-miniImageNet_4.png}\caption{$\tau=4$}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-miniImageNet_5.png}\caption{$\tau=5$}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-miniImageNet_6.png}\caption{$\tau=6$}
        \end{subfigure}
        \\
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-miniImageNet_7.png}\caption{$\tau=7$}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-miniImageNet_8.png}\caption{$\tau=8$}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-miniImageNet_9.png}\caption{$\tau=9$}
        \end{subfigure}
        \caption{Evolution of $\alpha(t,\tau)$ and test accuracy $a_{t,\tau}$ where $\tau \in [1,9]$ along the stream of $20$ tasks in the \textbf{Split-miniImageNet} dataset. The grey-coloured lines are $\max_{\tau'} \alpha_n(t,\tau')$  (top, dashed line), $\mathbb{E}_{\tau'} [\alpha(t,\tau')]$  (middle, solid line) and $\min_{\tau'} \alpha(t,\tau')$  (bottom, dashed line) that indicate the range of $\alpha(t,\tau')$. }
        \label{alpha_imagenet_app}
    \end{figure*}
    \begin{figure*}[t!]
        \centering
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-CUB_1.png}\caption{$\tau=1$}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-CUB_3.png}\caption{$\tau=3$}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-CUB_4.png}\caption{$\tau=4$}
        \end{subfigure}
        \\
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-CUB_7.png}\caption{$\tau=7$}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-CUB_8.png}\caption{$\tau=8$}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/Split-CUB_9.png}\caption{$\tau=9$}
        \end{subfigure}
        \caption{Evolution of $\alpha(t,\tau)$ and test accuracy $a_{t,\tau}$ where $\tau \in \{1,3,4,7,8,9\}$ along the stream of $20$ tasks in the \textbf{Split-CUB} dataset. The grey-coloured lines are $\max_{\tau'} \alpha_n(t,\tau')$  (top, dashed line), $\mathbb{E}_{\tau'} [\alpha(t,\tau')]$  (middle, solid line) and $\min_{\tau'} \alpha(t,\tau')$  (bottom, dashed line) that indicate the range of $\alpha(t,\tau')$.}
        \label{alpha_cub_app}
    \end{figure*}
    \begin{figure*}[t!]
        \centering
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/5-dataset_1.png}\caption{$\tau=1$}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/5-dataset_2.png}\caption{$\tau=2$}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.32\textwidth}
            \includegraphics[width=\textwidth]{pics/5-dataset_3.png}\caption{$\tau=3$}
        \end{subfigure}
        \caption{Evolution of $\alpha(t,\tau)$ and test accuracy $a_{t,\tau}$ where $\tau \in \{1,2,3\}$ along the stream of $5$ tasks in the \textbf{5-dataset} dataset. The grey-coloured lines are $\max_{\tau'} \alpha_n(t,\tau')$  (top, dashed line), $\mathbb{E}_{\tau'} [\alpha(t,\tau')]$  (middle, solid line) and $\min_{\tau'} \alpha(t,\tau')$  (bottom, dashed line) that indicate the range of $\alpha(t,\tau')$.}
        \label{alpha_5data_app}
    \end{figure*}
    
    \subsubsection{Multiple-pass per Task}\label{multi_pass}
    In this section, we report the performance of \textit{TAG-RMSProp} and all other baselines discussed in Section \ref{baseline_opt} for 5 epochs per task in Table \ref{main_table_epochs}. Hyper-parameters for this experiment are kept the same as the single-pass per task setting. \textit{TAG-RMSProp} results in high average Accuracy in all the datasets. We also observe less amount of \textbf{Forgetting} in \textit{TAG-RMSProp} as compared to other baselines. In terms of \textbf{Learning Accuracy}, \textit{TAG-RMSProp} is outperformed by the other baselines in \textbf{Split-CIFAR100}, \textbf{Split-miniImageNet} and \textbf{5-dataset} but performs better in \textbf{Split-CUB}.


    \begin{table*}[t!]
        \caption{Comparing performance in terms of Final average test \textbf{Accuracy (\%)} (higher is better), \textbf{Forgetting} (lower is better) and Learning Accuracy (\textbf{LA (\%)}) (higher is better) with the standard deviation values for different existing methods with \textit{TAG-RMSProp} running for \textbf{5 epochs per task} for all four datasets (see Section \ref{exp_sec}). All metrics are averaged across 5 runs. \textit{*MTL} assumes that the dataset from all tasks are always available during training, hence it is a different setting and its accuracy acts as an upper bound.}
        \vskip 0.1in
        \centering
        \resizebox{\textwidth}{!}{\begin{tabular}{c c c c c c c}
        \hline
        \multirow{2}{*}{\textbf{Methods}} &  \multicolumn{3}{c}{\textbf{Split-CIFAR100}} & \multicolumn{3}{c}{\textbf{Split-miniImageNet}}\\
                        \cmidrule(lr){2-4} \cmidrule(l){5-7}
             & \textbf{Accuracy (\%)} & \textbf{Forgetting} & \textbf{LA (\%)} & \textbf{Accuracy (\%)} & \textbf{Forgetting} & \textbf{LA (\%)} \\
        \midrule
        \textit{Naive SGD} &   $ 52.26 ~(\pm 0.65 )$ & $ 0.28 ~(\pm 0.01 )$ & $ 78.45 ~(\pm 0.41 )$  & $ 46.9 ~(\pm 1.18 )$ & $ 0.25 ~(\pm 0.02 )$ & $ 70.82 ~(\pm 0.6 )$ \\
        \textit{Naive RMSProp} &  $ 46.12 ~(\pm 2.33 )$ & $ 0.32 ~(\pm 0.02 )$ & $ 76.29 ~(\pm 0.53 )$  & $ 41.07 ~(\pm 0.66 )$ & $ 0.32 ~(\pm 0.01 )$ & $ 71.43 ~(\pm 0.42 )$\\
        \hline
        \textit{EWC} & $ 51.7 ~(\pm 1.71 )$ & $ 0.27 ~(\pm 0.02 )$ & $ 77.72 ~(\pm 0.84 )$ & $ 48.17 ~(\pm 0.81 )$ & $ 0.25 ~(\pm 0.01 )$ & $ 71.87 ~(\pm 0.26 )$ \\
        \textit{A-GEM} &   $ 54.24 ~(\pm 1.14 )$ & $ 0.25 ~(\pm 0.01 )$ & $ 78.38 ~(\pm 0.39 )$ & $ 49.08 ~(\pm 0.52 )$ & $ 0.23 ~(\pm 0.01 )$ & $ 70.49 ~(\pm 0.4 )$ \\
        \textit{ER} &   $ 60.03 ~(\pm 0.96 )$ & $ 0.19 ~(\pm 0.01 )$ & $ 78.15 ~(\pm 0.7 )$ & $ 54.01 ~(\pm 0.56 )$ & $ 0.19 ~(\pm 0.01 )$ & $ 71.77 ~(\pm 0.58 )$ \\
        \textit{Stable SGD} &  $ 58.92 ~(\pm 0.73 )$ & $ 0.19 ~(\pm 0.01 )$ & $ 76.91 ~(\pm 0.72 )$ & $ 51.23 ~(\pm 0.88 )$ & $ 0.22 ~(\pm 0.01 )$ & $ 71.77 ~(\pm 0.56 )$ \\
        \hline
        \textbf{TAG-RMSProp (Ours)} &  $ 60.64 ~(\pm 1.38 )$ & $ 0.17 ~(\pm 0.01 )$ & $ 77.12 ~(\pm 0.76 )$  & $ \textbf{58.0} ~(\pm 1.11 )$ & $ 0.11 ~(\pm 0.02 )$ & $ 68.14 ~(\pm 0.38 )$ \\
        \hline
        \textit{MTL*} &  $67.7 ~(\pm 0.58)$ & - & - &$66.14~(\pm1.0)$ & - & - \\
        \hline
        \end{tabular}}\\
        \resizebox{\textwidth}{!}{\begin{tabular}{c c c c c c c}
        \hline
        \multirow{2}{*}{\textbf{Methods}} &   \multicolumn{3}{c}{\textbf{Split-CUB}} & \multicolumn{3}{c}{\textbf{5-dataset}}\\
                        \cmidrule(lr){2-4} \cmidrule(l){5-7}
             &  \textbf{Accuracy (\%)} & \textbf{Forgetting} & \textbf{LA (\%)} & \textbf{Accuracy (\%)} & \textbf{Forgetting} & \textbf{LA (\%)} \\
        \midrule
        \textit{Naive SGD} & $ 59.87 ~(\pm 1.48 )$ & $ 0.21 ~(\pm 0.02 )$ & $ 79.77 ~(\pm 0.44 )$  & $ 49.95 ~(\pm 2.42 )$ & $ 0.51 ~(\pm 0.04 )$ & $ 90.86 ~(\pm 0.63 )$\\
        \textit{Naive RMSProp} &  $ 35.87 ~(\pm 1.14 )$ & $ 0.46 ~(\pm 0.01 )$ & $ 79.59 ~(\pm 0.3 )$ & $ 50.47 ~(\pm 0.99 )$ & $ 0.51 ~(\pm 0.01 )$ & $ 90.89 ~(\pm 0.44 )$\\
        \hline
        \textit{EWC}& $ 59.73 ~(\pm 2.4 )$ & $ 0.21 ~(\pm 0.02 )$ & $ 79.8 ~(\pm 0.58 )$& $ 52.51 ~(\pm 7.34 )$ & $ 0.43 ~(\pm 0.09 )$ & $ 86.8 ~(\pm 2.52 )$\\
        \textit{A-GEM} &  $ 62.65 ~(\pm 1.61 )$ & $ 0.17 ~(\pm 0.02 )$ & $ 79.1 ~(\pm 0.4 )$ & $ 62.48 ~(\pm 3.16 )$ & $ 0.35 ~(\pm 0.04 )$ & $ 90.53 ~(\pm 0.73 )$\\
        \textit{ER} &  $ 66.06 ~(\pm 1.28 )$ & $ 0.14 ~(\pm 0.02 )$ & $ 78.79 ~(\pm 0.55 )$ & $ 62.84 ~(\pm 1.58 )$ & $ 0.35 ~(\pm 0.02 )$ & $ 90.52 ~(\pm 0.69 )$\\
        \textit{Stable SGD} & $ 58.75 ~(\pm 0.96 )$ & $ 0.19 ~(\pm 0.01 )$ & $ 76.6 ~(\pm 0.64 )$ & $ 51.95 ~(\pm 3.83 )$ & $ 0.48 ~(\pm 0.05 )$ & $ 90.41 ~(\pm 0.29 )$ \\
        \hline
        \textbf{TAG-RMSProp (Ours)} & $ \textbf{68.0} ~(\pm 1.01 )$ & $ 0.13 ~(\pm 0.01 )$ & $ 80.15 ~(\pm 0.22 )$ & $ 61.13 ~(\pm 3.05 )$ & $ 0.36 ~(\pm 0.04 )$ & $ 89.9 ~(\pm 0.33 )$
\\
        \hline
        \textit{MTL*} &  $71.65~(\pm0.76)$ &  - & - & $70.0 ~(\pm 4.44 )$ &  - & - \\
        \hline
        \end{tabular}}
        \label{main_table_epochs}
    \end{table*}




\subsubsection{Bigger Memory size in replay-based methods}\label{agem_er_app}
    We also compare the performance of \textit{A-GEM} and \textit{ER} with a larger number of samples per class ($\mathbb{M}$) in the episodic memory for all four datasets in Table \ref{main_table_memory}. With $\mathbb{M}=10$, total episodic memory size for \textbf{Split-CIFAR100}, \textbf{Split-miniImageNet}, \textbf{Split-CUB} and \textbf{5-dataset} becomes $1000$, $1000$, $2000$ and $500$ respectively. We observe \textit{ER} results in a significant gain in the performance as the episodic memory size increases. But \textit{TAG-RMSProp} is able to outperform \textit{A-GEM} in \textbf{Split-CIFAR100}, \textbf{Split-miniImageNet} and \textbf{Split-CUB} with a large margin even when $\mathbb{M}$ is set to $10$.  
    \begin{table*}[t!]
        \caption{Comparing performance in terms of Final average test \textbf{Accuracy (\%)} (higher is better), \textbf{Forgetting} (lower is better) and Learning Accuracy (\textbf{LA (\%)}) (higher is better) with the standard deviation values for \textit{A-GEM} and \textit{ER} for different number of samples per class ($\mathbb{M}$) in the episodic memory with \textit{TAG-RMSProp} for all four datasets (see Section \ref{exp_sec}). All metrics are averaged across 5 runs. Overall, \textit{ER} with bigger memory outperforms all other methods in terms of Accuracy. }
        \vskip 0.1in
        \centering
        \resizebox{\textwidth}{!}{\begin{tabular}{c c c c c c c}
        \hline
        \multirow{2}{*}{\textbf{Methods}} &  \multicolumn{3}{c}{\textbf{Split-CIFAR100}} & \multicolumn{3}{c}{\textbf{Split-miniImageNet}}\\
                        \cmidrule(lr){2-4} \cmidrule(l){5-7}
             & \textbf{Accuracy (\%)} & \textbf{Forgetting} & \textbf{LA (\%)} & \textbf{Accuracy (\%)} & \textbf{Forgetting} & \textbf{LA (\%)} \\
        \midrule
        \textit{A-GEM} ($\mathbb{M}=1$) &   $ 54.25 ~(\pm 2.0 )$ & $ 0.16 ~(\pm 0.03 )$ & $ 68.98 ~(\pm 1.19 )$ & $ 50.32 ~(\pm 1.29 )$ & $ 0.11 ~(\pm 0.02 )$ & $ 61.02 ~(\pm 0.64 )$ \\
        \textit{A-GEM} ($\mathbb{M}=5$) & $ 55.74 ~(\pm 1.14 )$ & $ 0.14 ~(\pm 0.01 )$ & $ 68.97 ~(\pm 0.56 )$ & $ 49.52 ~(\pm 2.02 )$ & $ 0.12 ~(\pm 0.02 )$ & $ 60.49 ~(\pm 0.78 )$\\
        \textit{A-GEM} ($\mathbb{M}=10$) & $ 56.68 ~(\pm 1.92 )$ & $ 0.13 ~(\pm 0.02 )$ & $ 68.72 ~(\pm 0.96 )$ & $ 49.77 ~(\pm 2.41 )$ & $ 0.12 ~(\pm 0.02 )$ & $ 60.6 ~(\pm 0.66 )$\\
        \hline
        \textit{ER} ($\mathbb{M}=1$) &   $ 59.14 ~(\pm 1.77 )$ & $ 0.12 ~(\pm 0.02 )$ & $ 70.36 ~(\pm 1.23 )$ & $ 52.76 ~(\pm 1.53 )$ & $ 0.1 ~(\pm 0.01 )$ & $ 61.7 ~(\pm 0.74 )$ \\
        \textit{ER} ($\mathbb{M}=5$) & $ 65.74 ~(\pm 1.47 )$ & $ 0.07 ~(\pm 0.01 )$ & $ 70.91 ~(\pm 1.13 )$ & $ 58.49 ~(\pm 1.21 )$ & $ 0.05 ~(\pm 0.01 )$ & $ 62.24 ~(\pm 0.85 )$\\
        \textit{ER} ($\mathbb{M}=10$) &   $ \textbf{68.94} ~(\pm 0.93 )$ & $ 0.05 ~(\pm 0.01 )$ & $ 71.26 ~(\pm 1.01 )$ & $ \textbf{60.06} ~(\pm 0.63 )$ & $ 0.04 ~(\pm 0.01 )$ & $ 62.21 ~(\pm 1.24 )$ \\
        \hline
        \textbf{TAG-RMSProp (Ours)} &  $ 62.79 ~(\pm 0.29 )$ & $ 0.1 ~(\pm 0.01 )$ & $ 72.06 ~(\pm 1.01 )$  & $ 57.2 ~(\pm 1.37 )$ & $ 0.06 ~(\pm 0.02 )$ & $ 62.73 ~(\pm 0.61 )$ \\
        \hline
        \end{tabular}}\\
        \resizebox{\textwidth}{!}{\begin{tabular}{c c c c c c c}
        \hline
        \multirow{2}{*}{\textbf{Methods}} &   \multicolumn{3}{c}{\textbf{Split-CUB}} & \multicolumn{3}{c}{\textbf{5-dataset}}\\
                        \cmidrule(lr){2-4} \cmidrule(l){5-7}
             &  \textbf{Accuracy (\%)} & \textbf{Forgetting} & \textbf{LA (\%)} & \textbf{Accuracy (\%)} & \textbf{Forgetting} & \textbf{LA (\%)} \\
        \midrule
        \textit{A-GEM} ($\mathbb{M}=1$) &  $ 56.91 ~(\pm 1.37 )$ & $ 0.1 ~(\pm 0.01 )$ & $ 65.6 ~(\pm 0.73 )$ & $ 55.9 ~(\pm 2.58 )$ & $ 0.34 ~(\pm 0.04 )$ & $ 82.61 ~(\pm 2.13 )$\\
        \textit{A-GEM} ($\mathbb{M}=5$) & $ 56.4 ~(\pm 1.5 )$ & $ 0.1 ~(\pm 0.01 )$ & $ 65.63 ~(\pm 0.64 )$ & $ 61.39 ~(\pm 1.0 )$ & $ 0.28 ~(\pm 0.01 )$ & $ 83.48 ~(\pm 1.05 )$ \\
        \textit{A-GEM} ($\mathbb{M}=10$) & $ 56.71 ~(\pm 1.6 )$ & $ 0.1 ~(\pm 0.01 )$ & $ 65.73 ~(\pm 0.9 )$ & $ 62.43 ~(\pm 1.38 )$ & $ 0.26 ~(\pm 0.03 )$ & $ 83.38 ~(\pm 1.79 )$\\
        \hline
        \textit{ER} ($\mathbb{M}=1$) &  $ 59.25 ~(\pm 0.82 )$ & $ 0.1 ~(\pm 0.01 )$ & $ 66.17 ~(\pm 0.42 )$ & $ 61.58 ~(\pm 2.65 )$ & $ 0.28 ~(\pm 0.04 )$ & $ 84.31 ~(\pm 1.08 )$ \\
        \textit{ER} ($\mathbb{M}=5$) & $ 68.89 ~(\pm 0.31 )$ & $ 0.04 ~(\pm 0.0 )$ & $ 66.76 ~(\pm 0.73 )$ & $ 71.56 ~(\pm 1.54 )$ & $ 0.16 ~(\pm 0.02 )$ & $ 84.34 ~(\pm 1.46 )$\\
        \textit{ER} ($\mathbb{M}=10$) &  $ \textbf{70.73} ~(\pm 0.23 )$ & $ 0.03 ~(\pm 0.01 )$ & $ 66.83 ~(\pm 0.86 )$ & $ \textbf{75.44} ~(\pm 1.07 )$ & $ 0.12 ~(\pm 0.02 )$ & $ 84.62 ~(\pm 0.89 )$ \\
        \hline
        \textbf{TAG-RMSProp (Ours)} & $ 61.58 ~(\pm 1.24 )$ & $ 0.11 ~(\pm 0.01 )$ & $ 71.56 ~(\pm 0.74 )$ & $ 62.59 ~(\pm 1.82 )$ & $ 0.3 ~(\pm 0.02 )$ & $ 86.08 ~(\pm 0.55 )$\\
        \hline
        \end{tabular}}
        \label{main_table_memory}
    \end{table*}

{
\subsubsection{Ablation studies}\label{variant_sec}
In the following experiments, we perform ablation studies over \textit{TAG-RMSProp}. 

\begin{itemize}
    \item Instead of Eq. \ref{alpha_eq} in \textit{TAG-RMSProp}, we define \textit{TAG-1} where $\alpha_n(t,\tau) = 1$ i.e., equal importance is given to all task based second moments.
    \item Similarly, we define \textit{TAG-age} by replacing Eq. \ref{alpha_eq} with $\alpha_n(t,\tau) = t - \tau + 1$ i.e., giving importance to the past tasks based on their age. 
    \item There can be different ways to approximate the gradient directions such as averaging the gradients or storing the gradients for each task etc. Therefore, we define a variant \textit{TAG-G}, where we store first $\mathbb{B}$ gradients obtained for each task instead of maintaining task-based first moments. When the model sees a new task $t$, we then obtain the $\alpha_n(t, \tau)$ by computing cosine similarity between these stored gradients. \end{itemize}

We implement \textit{TAG-1}, \textit{TAG-age} and \textit{TAG-G} in our code and run experiments on \textbf{Split-CIFAR100}, \textbf{Split-miniImageNet}, \textbf{Split-CUB} and \textbf{5-dataset}. For \textit{TAG-G}, we run it for different values of $\mathbb{B}$. All results shown is Table \ref{ablation} are averaged across $5$ runs.


 \begin{table*}[t!]
        \caption{Comparing performance in terms of Final average test \textbf{Accuracy (\%)} (higher is better), \textbf{Forgetting} (lower is better) and Learning Accuracy (\textbf{LA (\%)}) (higher is better) with the standard deviation values for different variants of \textit{TAG-RMSProp} (see Appendix \ref{variant_sec}) for all four datasets. All metrics are averaged across 5 runs.}
        \vskip 0.1in
        \centering
        \resizebox{\textwidth}{!}{\begin{tabular}{c c c c c c c}
        \hline
        \multirow{2}{*}{\textbf{Methods}} &  \multicolumn{3}{c}{\textbf{Split-CIFAR100}} & \multicolumn{3}{c}{\textbf{Split-miniImageNet}}\\
                        \cmidrule(lr){2-4} \cmidrule(l){5-7}
             & \textbf{Accuracy (\%)} & \textbf{Forgetting} & \textbf{LA (\%)} & \textbf{Accuracy (\%)} & \textbf{Forgetting} & \textbf{LA (\%)} \\
        \midrule
        \textit{TAG-1} &   $ 48.91 ~(\pm 0.32 )$ & $ 0.22 ~(\pm 0.0 )$ & $ 70.19 ~(\pm 0.47 )$ & $ 48.21 ~(\pm 1.25 )$ & $ 0.11 ~(\pm 0.02 )$ & $ 58.79 ~(\pm 1.41 )$ \\
        \textit{TAG-age} & $ 54.55 ~(\pm 1.37 )$ & $ 0.13 ~(\pm 0.02 )$ & $ 66.59 ~(\pm 2.07 )$ & $ 49.42 ~(\pm 0.78 )$ & $ 0.06 ~(\pm 0.0 )$ & $ 55.0 ~(\pm 0.48 )$\\
        \hline
        \textit{TAG-G} ($\mathbb{B}=1$) &   $ 62.6 ~(\pm 0.38 )$ & $ 0.1 ~(\pm 0.01 )$ & $ 72.37 ~(\pm 0.71 )$ & $ 58.58 ~(\pm 0.66 )$ & $ 0.05 ~(\pm 0.01 )$ & $ 63.24 ~(\pm 0.72 )$ \\
        \textit{TAG-G} ($\mathbb{B}=5$) & $ 62.95 ~(\pm 1.24 )$ & $ 0.1 ~(\pm 0.01 )$ & $ 72.62 ~(\pm 1.35 )$ & $ 58.47 ~(\pm 0.82 )$ & $ 0.05 ~(\pm 0.01 )$ & $ 62.99 ~(\pm 0.66 )$\\
        \textit{TAG-G} ($\mathbb{B}=20$) & $ 62.97 ~(\pm 1.39 )$ & $ 0.1 ~(\pm 0.01 )$ & $ 72.55 ~(\pm 1.06 )$ & $ \textbf{58.62} ~(\pm 0.83 )$ & $ 0.05 ~(\pm 0.01 )$ & $ 63.12 ~(\pm 0.81 )$\\
        \hline
        \textbf{TAG-RMSProp} &  $ 62.79 ~(\pm 0.29 )$ & $ 0.1 ~(\pm 0.01 )$ & $ 72.06 ~(\pm 1.01 )$  & $ 57.2 ~(\pm 1.37 )$ & $ 0.06 ~(\pm 0.02 )$ & $ 62.73 ~(\pm 0.61 )$ \\
        \hline
        \end{tabular}}\\
        \resizebox{\textwidth}{!}{\begin{tabular}{c c c c c c c}
        \hline
        \multirow{2}{*}{\textbf{Methods}} &   \multicolumn{3}{c}{\textbf{Split-CUB}} & \multicolumn{3}{c}{\textbf{5-dataset}}\\
                        \cmidrule(lr){2-4} \cmidrule(l){5-7}
             &  \textbf{Accuracy (\%)} & \textbf{Forgetting} & \textbf{LA (\%)} & \textbf{Accuracy (\%)} & \textbf{Forgetting} & \textbf{LA (\%)} \\
        \midrule
        \textit{TAG-1} &   $ 43.53 ~(\pm 0.61 )$ & $ 0.06 ~(\pm 0.0 )$ & $ 47.86 ~(\pm 0.49 )$ & $ 50.49 ~(\pm 0.95 )$ & $ 0.44 ~(\pm 0.01 )$ & $ 85.58 ~(\pm 1.16 )$ \\
        \textit{TAG-age} & $ 30.8 ~(\pm 1.07 )$ & $ 0.04 ~(\pm 0.01 )$ & $ 33.05 ~(\pm 0.8 )$ & $ 53.28 ~(\pm 1.46 )$ & $ 0.4 ~(\pm 0.02 )$ & $ 85.43 ~(\pm 1.8 )$\\
        \hline
        \textit{TAG-G} ($\mathbb{B}=1$) &   $ 58.7 ~(\pm 1.04 )$ & $ 0.09 ~(\pm 0.01 )$ & $ 66.96 ~(\pm 0.48 )$ & $ \textbf{63.57} ~(\pm 1.24 )$ & $ 0.27 ~(\pm 0.02 )$ & $ 85.37 ~(\pm 1.34 )$ \\
        \textit{TAG-G} ($\mathbb{B}=5$) & $ 58.73 ~(\pm 1.09 )$ & $ 0.09 ~(\pm 0.01 )$ & $ 67.01 ~(\pm 0.54 )$ & $ 62.84 ~(\pm 1.18 )$ & $ 0.28 ~(\pm 0.01 )$ & $ 84.99 ~(\pm 1.18 )$\\
        \textit{TAG-G} ($\mathbb{B}=20$) & $ 58.73 ~(\pm 1.07 )$ & $ 0.09 ~(\pm 0.01 )$ & $ 66.95 ~(\pm 0.58 )$ & $ 62.38 ~(\pm 2.58 )$ & $ 0.29 ~(\pm 0.03 )$ & $ 85.24 ~(\pm 2.72 )$ \\
        \hline        
        \textbf{TAG-RMSProp} & $ \textbf{61.58} ~(\pm 1.24 )$ & $ 0.11 ~(\pm 0.01 )$ & $ 71.56 ~(\pm 0.74 )$ & $ 62.59 ~(\pm 1.82 )$ & $ 0.3 ~(\pm 0.02 )$ & $ 86.08 ~(\pm 0.55 )$\\
        \hline
        \end{tabular}}
        \label{ablation}
    \end{table*}

We observe that that \textit{TAG-1} and \textit{TAG-age} perform better than \textit{Naive RMSProp} and \textit{EWC} (refer Table \ref{main_table}) on all datasets except on \textbf{Split-CUB}. But, they are outperformed by \textit{TAG-RMSProp}. The significantly worse performance on \textbf{Split-CUB} suggests that the model relies heavily on similarity among tasks and even maintaining the importance based on age is not sufficient for the learning process. 

On the other hand, \textit{TAG-RMSProp} and \textit{TAG-G} ($\mathbb{B}=1$) store the same amount of memory, but \textit{TAG-RMSProp} only performs better on two (\textbf{Split-CIFAR100} and \textbf{Split-CUB}) out of four datasets. In particular, even of $\mathbb{B}=20$, \textit{TAG-G} is outperformed by \textit{TAG-RMSProp} on \textbf{Split-CUB}. This could be due to complexity of \textbf{Split-CUB} and the model (ResNet18), more number of iterations were required to solve individual tasks. Hence, storing the first few gradients is not sufficient to represent a task to compute the similarities. On the other hand, momentum is a better choice for computing tasks similarity since it is able to approximate the overall gradient directions when the model converges. We also observe that \textit{TAG-G} tends to forget less catastrophically than \textit{TAG-RMSProp} on all datasets. But, \textbf{TAG-RMSProp} outperforms \textbf{TAG-G} in terms of \textbf{LA} on \textbf{Split-CUB} and \textbf{5-dataset}. Interestingly, lower value of $\mathbb{B}$ for \textit{TAG-G} results in better \textbf{Accuracy} on \textbf{5-dataset} whereas a higher $\mathbb{B}$ is better choice for other three datasets. 

}






























\end{document}
