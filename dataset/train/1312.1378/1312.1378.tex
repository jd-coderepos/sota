

The growing consensus within the network community today is that a semantic
separation of the \emph{identity} and \emph{location} information, currently
overloaded in IP addresses, would solve the limitations of the routing
infrastructure~\cite{huston:potaroo,rfc4984}. Such architectural update
involves network infrastructure upgrades in few, selected, network points like
border routers, where the linking of the two namespaces must be performed.
But, more importantly, it also entails the more challenging implementation of a
\emph{mapping-system} able to distribute dynamic location-identity bindings
(\emph{mappings}) to globally distributed routers.    

In this context, routers generally retrieve mappings on user demand, as
opposed to proactively fetching them. This is done such that the amount of
memory a router requires to participate in the system does not grow with
identifier space, as is the case today, but is instead dependent on the packet
level traffic the router processes. As a result, to diminish retrieval times,
increase packet forwarding speed and to protect the mapping system from floods
of resolution requests, routers are provisioned with mappings caches
(\emph{map-caches}) that temporarily store in use bindings. 



Although caches placed between processor and main memory, in operating systems
or in web proxies are well studied~\cite{agarwal:cmodel, breslau:webcache,
rizzo:proxycache}, route and mappings caches have yet to be thoroughly
analyzed. A considerable number of experiments have empirically evaluated
map-cache performance, however they are mainly focused on providing a
circumstantial description of cache behavior, that is, for particular cache
configurations and network traffic traces, as opposed to a general
one~\cite{iannone:lcache, jkim:lcache, kim:rcaching, jakab:lisp-tree,
zhang:lcache}. Typically, these results yield accurate estimates for cache
performance but unfortunately cannot be extrapolated to provide rough
projections or bounds on cache behavior for workloads with different characteristics; nor can
they provide insight into what traffic properties influence cache performance
and to what degree.
Answering such questions would not only be a first important step towards
understanding the overall performance of the mapping-system, but would also 
provide a quick way of gauging the expected map-cache performance of any
network domain. 








In this paper, we present an analytical model that, to the best of our
knowledge, constitutes the first theoretical framework for map-cache
performance analysis and provisioning. The model relies on coarse traffic
parameters and aims to be applicable to a wide range of scenarios. In
particular, we first show how the working-set theory~\cite{denning:ws_model} may be
used to estimate simple parameters that characterize the intrinsic locality of network
traffic and thereafter explain how they can be leveraged to link cache size and miss rate. 
The underlying assumption that enables the analysis is that traffic can be
approximated as having a stationary generating process. We find
stationarity to hold for real network traffic, and, to facilitate the use of the model,
we propose a simple methodology that tests for it in network traces.
Finally, we validate the result by emulation, using packet traces collected at
the edges of a campus and an academic network. Part of these results have been
previously presented in~\cite{coras:lcache_n}.







Another contribution of this paper is that we exploit the model to $(i)$
perform an in-depth, over time analysis of cache performance for our datasets
and $(ii)$ study the security of the map-cache by evaluating its vulnerability
to scanning attacks. Our findings show that miss rate decreases at an
accelerated pace with cache size and eventually settles to a power-law
decrease. As a result, even for a relative small size, $10\%$ of the
Internet's aggregated routing table, the performance is still acceptable,
below $0.2\%$ packet miss-rate.
On the other hand, we also find that even simple and low
intensity attacks may compromise performance and that increasing
the cache size does not alleviate the problem while the map-cache cannot
accommodate the whole destination address space. Thereby, to achieve acceptable
forwarding speeds, manufacturers should either overprovision router memory or
design efficient cache management algorithms. 



For the sake of clarity, we focus our analysis on the performance of LISP
map-cache (see Section~\ref{sec:background}). Nevertheless, the results are
relevant for other architectures inspired by the location/identity split
paradigm, including those like ILNP~\cite{RFC6740} that use DNS as their
mapping system, since the equations could be used to approximate DNS resolver
caching performance. Moreover, the cache models could be applied to
route-caching and scalability techniques that focus on shrinking routing
tables to extend router lifetimes~\cite{ballani:viaggre}.

The rest of the paper is structured as follows. Section~\ref{sec:background}
provides an overview of the location/identity split paradigm and one of its
most successful implementations, LISP. In Section~\ref{sec:cmodel} we first
introduce the cache model problem and then present our analytical model and
its extension that accommodates for cache pollution attacks.
Section~\ref{sec:evaluation} describes the methodology used and the results
that validate the two models.  Section~\ref{sec:discussion} discusses the
predictions of our results when applied to our datasets and some design
guidelines to improve cache performance. Section~\ref{sec:rw} presents the
related work. Finally, Section~\ref{sec:conclusions} concludes the paper.
