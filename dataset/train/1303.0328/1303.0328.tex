\documentclass{article}

\textwidth=6.5in
\textheight=9in
\topmargin=-0.75in
\oddsidemargin=0in
\evensidemargin=-.5in

\usepackage[margin=10pt,font=small,labelfont=bf, labelsep=endash]{caption}
\usepackage[ruled,boxed]{algorithm2e}
\usepackage{amsmath}			

\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}

\newcommand \p    {\prime}
\newcommand \pp   {{\prime\prime}}
\newcommand \ppp  {{\prime\prime\prime}}
\newcommand \pppp {{\prime\prime\prime\prime}}
\newcommand \del {\delta}
\newcommand \eps {\epsilon}
\newcommand \ra {\rightarrow}
\newcommand \oo {\infty}
\newcommand \half {\frac{1}{2}}
\newcommand \threehalf {\frac{3}{2}}


\def \fns {\footnotesize}
\def \ss {\scriptsize}

\raggedbottom



\begin{document}

\centerline{\bf Efficient long division via Montgomery multiply}

\bigskip

\centerline{Last modified: 20 Aug 2016}
\bigskip
\centerline{Ernst~W.~Mayer}
\centerline{\fns 10190 Parkwood Dr.~\#1, Cupertino, CA 95014}
\centerline{\fns {\em ewmayer@aol.com}}

\bigskip

\begin{abstract}
We present a novel right-to-left long division algorithm based on the Montgomery modular multiply, consisting of separate highly efficient loops with simple carry structure for computing first the remainder  and then the quotient . These loops are ideally suited for the case where  occupies many more machine words than the divide modulus , and are strictly linear time in the ``bitsize ratio" . For the paradigmatic performance test of multiword dividend and single 64-bit-word divisor, exploitation of the inherent data-parallelism of the algorithm effectively mitigates the long latency of hardware integer MUL operations, as a result of which we are able to achieve respective costs for remainder-only and full-DIV (remainder and quotient) of 6 and 12.5 cycles per dividend word on the Intel Core 2 implementation of the x86\_64 architecture, in single-threaded execution mode.  We further describe a simple ``bit-doubling modular inversion" scheme, which allows the entire iterative computation of the mod-inverse required by the Montgomery multiply at arbitrarily large precision to be performed with cost less than that of a single Newtonian iteration performed at the full precision of the final result. We also show how the Montgomery-multiply-based powering can be efficiently used in Mersenne and Fermat-number trial factorization via direct computation of a modular inverse power of 2, without any need for explicit radix-mod scalings.
\end{abstract}








\section{Introduction}
\label{sect:intro}

In an ingenious 1985 work \cite{Mont85}, Montgomery presented an algorithm for division-free modular multiplication (``modmul") which is ideally suited for modern binary compute hardware. For general background we refer the reader to Crandall \& Pomerance \cite{CP05}, who note that the method is a generalization of an old method of Hensel \cite{Hensel} for computing the inverses of 2-adic numbers, and who further give a nice survey of subsequent developments and algorithmic refinements, most of which are also detailed in the more-encyclopedic reference by Menezes {\em et al.} \cite{Mene96}. C\&P make specific note of the ``tough case" when the number  is much larger than the modulus  in the log-ratio sense, that is if  is the smallest integer such that , then we have . They remark on several highly-tuned computer algorithms for this case, all based on variants of the Barrett mod technique \cite{Bar87}. In the present work we show how the Montgomery modmul can be successfully brought to bear on both the general but especially the latter ( large) case. The resulting division method consists of the following three steps, where  is the binary arithmetic radix used for the core Montgomery modmul operations:
\begin{enumerate}
\item 	(Algorithms~A and B) Computes a scaled remainder , related to the true remainder  (mod ) by  (mod ) for Algorithm~A, and  for Algorithm~B;

\item	(Algorithm~C) Efficiently computes the needed modular power of the radix  via a divide-and-conquer scheme, and returns the true remainder ;

\item	(Algorithm~D) Takes  and  and produces the quotient .
\end{enumerate}
Steps 1 and 3 are performed using simple loops which run through the elements of the (presumably multiword) vector  in ascending order, and possess quite-similar loop-body arithmetic structure. Step 1 is all that is needed if a simple binary ``does  divide x?" result is required. Step 2 uses similar core modmul arithmetic to compute the scaling factor needed to transform the Step 1 result out of ``Montgomery space", yielding the remainder , which is used (in addition to ) as an input to Step 3. Steps 1 and 3 each require  size- modmul operations (one per loop execution), whereas Step 2 needs just  modmuls. Thus, the scheme possesses the property that the work required to compute just the remainder  is asymptotically half that needed to obtain both the remainder and quotient.

Let us first introduce some basic arithmetic and computational notation related to the various core multiply operations. Given nonnegative integers  and  whose product is desired with respect to some positive integer modulus  (such that ), the Montgomery method begins with an arithmetic radix (or ``base") , typically chosen for computational convenience.  and  must be coprime, thus the modular inverse  of  exists, such that

The Montgomery multiply does not directly return  (mod ); rather it returns a ``shifted mod" involving the inverse of the radix , thus we include  in the argument list as a parameter:

which needs suitable adjustment if the ``true mod"  (mod ) is required. Often it is not~-- for example in the fast divisibility algorithm we shall give in the next section, we only care if the output is zero or not, obviating any need for postprocessing arithmetic~-- but when it is, the extra effort needed to scale the output in order to produce the true mod may be appreciable. The need to perform this scaling-away of the inverse power of the arithmetic radix is the major reason why the Montgomery multiply has not driven other modmul algorithms from the field in more or less any context requiring a modmul, although it has become ubiquitous in areas such as Diffie-Hellman and RSA-style public-key cryptography and elliptic curve arithmetic, all of which feature repeated multiplications with respect to a fixed modulus and thus in which radix-scalings are few relative to overall modmul count. In this respect long division , where we especially mean ``long" in the literal sense that , appears to be a bit of an anomaly, because although it does feature repeated multiply modulo , the best-known high-performance implementations such as that of the Gnu MP library \cite{GMP} eschew the Montgomery method, at least in any fashion resembling the one described here.

Here we take , a power of 2 typically equal to the an unsigned-integer wordsize  supported by the compute hardware and programming language being used, or some integer power of  if the modulus , requiring a multiword-arithmetic implementation. It is further assumed that twos-complement integer arithmetic is being performed both with respect to  and . The restriction of coprimality of the radix and modulus thus simply reduces to that of the modulus  being odd for the Montgomery modmul to work. The more general case of even moduli can easily be accommodated with simple pre- and postprocessing to take care of any powers of 2 appearing in , which we shall also detail. (We specifically refer the reader to the end of the section describing Algorithm~D).

Assuming one has computed the needed mod-inverse , a typical computational implementation of the Montgomery modmul consists of a three-multiply sequence, followed by a mod-subtraction, which can be expressed in pseudocode as\\
\\
{\bf Algorithm:} \\
\IncMargin{5em} \begin{algorithm}[H]
\SetAlgoLined
\KwData{Unsigned b-bit integers ,  odd and }
\KwResult{The radix  Montgomery product  (mod )}
\vspace{0.1in}
{
	;\\
	;\\
	;\\
	;\\
	\eIf {} {
		\Return \;
	}{
		\Return \;
	}
}
\label{MM}
\end{algorithm}
\vspace{0.1in}
Here  denotes a -bit unsigned integer type (hardware-supported or emulated-multiword), and for the  output pair we mimic the colon-separated register-pair notation used to describe the MUL instruction output in the x86\_64 instruction set architecture (ISA); arithmetically we mean .

\vspace{0.1in}
\noindent The three multiply variants appearing in the function are as follows:
\begin{table}[ht]
\begin{center}
\begin{tabular}{l p{3in}}
	&	Full -bit double-width unsigned multiply which returns the lower and upper halves of  in a pair of variables. For this operation the result depends on whether the inputs are treated as signed or unsigned, so we add a leading `U' to specify that we mean the unsigned version.\\
\\
&	Lower-half multiply, that is, . We label the inputs as unsigned here, but for this operation the result is the same whether the inputs are treated as signed or unsigned.\\
\\
&	Upper-half multiply, returns , the upper -bit half of the unsigned product .
\end{tabular}
\end{center}
\end{table}
\setcounter{table}{0}

\noindent These three multiply operations are related simply as

Since  is a power of 2 we can also express MULL and UMULH in terms of simple binary shifts and masks of a full product:

The three-multiply sequence  is followed by mod- subtraction of a pair of -bit quantities, typically effected an if/else branch (as in our pseudocode), or uaing a conditional-mov-style operation, either of the explicit kind if the hardware supports it, or of the ``hand-rolled" bitwise-mask-and-add variety.



\section{Notes on the Newtonian Iterative mod-Inverse}
\label{sect:modinv}

The multiplication algorithm first requires computation of , the multiplicative inverse of  modulo . This is a modular analog of the inverse over the reals, and in practice one even uses the same Newtonian iterative-inversion algorithm to compute  as is commonly used to effect a fast floating-point inverse computation needing no hardware division, the latter being generally a slow operation in both the floating-point and integer domains. One starts with an initial guess  having one or more low-order ``good bits" in the sense that  with . One advantage of the Newtonian iteration in the modular realm is that as long as even the least-significant bit of  is correct, convergence is guaranteed. So since  odd we can take  to be any odd number, e.g.~1 or even  itself. Montgomery (personal communication) alternatively suggests a kind of low-precision bitwise table-lookup in the form of a simple inline formula, yielding at least 5 correct low bits in the resulting initial iterate:

In a 32 or 64-bit context one can save a further few cycles via use of a precomputed 128-element bytewise lookup table indexed by . The ensuing Newton iteration involves repeated steps of form

Where the asterisk operator is a shorthand for the  operation (that is, multiplication modulo ) on the pairs of operands it separates, either with respect to some fixed arithmetic base , or to some variable power of 2 whose number of bits increases with each iteration to keep pace with the per-iteration doubling of number of converged bits of , and which exceeds  only on the final iteration. The advantage of taking  to be a power of the natural integer wordsize is apparent here, since e.g.~if  we really can use the hardware multiply operation denoted in programming languages such as C and Fortran by `', that is, integer product modulo . For  we replace the literal `' by a software-emulated  operation, which for  not terribly larger than  (say, ) will typically be based on some hardware-optimized implementation of grammar-school multiply. For larger radices, optimized software implementations will transition to a subquadratic algorithm such as Toom-Cook and eventually for very large operands, to some kind of fast transform-based discrete convolution. Similar large-argument optimizations apply to the other forms of multiply required by the Montgomery algorithm.

Returning to the inverse computation, the number of significant bits at the bottom doubles on each iteration, until we reach the bitwidth set by the modulus , which determines the width of the  operation used. Since we only care about the final converged value of  we can do the iteration ``in-place". A typical C implementation of the inversion~(\ref{newt}) for  might look as follows, where  is a typedef for the native unsigned 64-bit integer type on the platform in question:\\
\\
{\bf Algorithm:} {64-bit mod-inverse computation}\\
\begin{algorithm}[H]
\KwData{Unsigned 64-bit odd integer modulus }
\KwResult{Mod-inverse , such that }
\vspace{0.1in}
	{
	;\\
	\For { \KwTo }{
		;\\
		;\\
	}
}
\end{algorithm}
\vspace{0.2in}
Let us crunch the numbers on an actual numerical example, the 64-bit modulus . First note that  (mod 16), which in binary . XOR of this with 2 toggles the set bit in the 2s slot to yield . Since we only care about these 5 bits of the initial inverse seed value, we could simply initialize . In fact, since in this case we are targeting a 64-bit result the high bit of this initial iterate gains us nothing in terms of work savings: We could equally well take , and in either case would still require 4 iterations to obtain a 64-bit-converged result. However, since in practice such bit-masking is superfluous, we illustrate the algorithm exactly as given. We thus have XOR(3q, 2) = 12180204350589856915 (note the multiply by 3 here is also modulo ) which in hexadecimal = A908C752C8936C9\underline{1}, where we have underlined the converged hex digits, which at this point means just the rightmost one (though at least the low bit of the next-higher hex digit is also converged). We note that for this particular choice of  our initial-iterate formula actually yields 6 good bits in . (In general there is a 50\% chance of this ``extra bits for free" behavior occurring, according to the low bits of ). We now iterate 4 times, obtaining the data in Table~\ref{table_iter64}, again with the same underline-highlighting of converged digits. The right-column iterate  is the input (in addition to the fixed ) to the next iteration. The iteration yields the desired 64-bit mod inverse, which in decimal form is . Were we to do one more iteration, we would observe that the product  would have its 64-bit lower half equal to unity, confirming that  has reached its desired fixed point.

\begin{table}[ht]
\begin{center}
\caption{\label{table_iter64}Convergence history of Newtonian iteration for 64-bit mod-inverse of :}
\begin{tabular}{c|c|c|c}
	&		&	 &	\\
\hline
	& {\tt F3D66805FF3D2BC\underline{1}}	& {\tt 4141B6714938A\underline{4D1}}	&		\\
	& {\tt B0955EB99F05F\underline{001}}	& {\tt 656E0C4A27\underline{9FB4D1}}	&		\\
	& {\tt 0A62BFBCBF\underline{000001}}	& {\tt 6EAB\underline{2BE6389FB4D1}}	&		\\
	& {\tt E97F\underline{000000000001}}	& {\tt \underline{81FC2BE6389FB4D1}}	&	
\end{tabular}
\end{center}
\end{table}


\vspace{-0.1in}
An alternative to the XOR-based initialization is to instead use a small precomputed bytewise lookup table yielding 8 bits for the initializer, followed by just 3 iterations to yield 64 bits. 
If the hardware has fast hardware support for 32-bit integers (as is the case on many platforms still running 32-bit operating systems), it makes sense to begin using 32-bit operands, followed by a single 64-bit iteration. Similarly, if a radix larger than 64 bits is used, one can proceed to 64 bits in  using the above loop, then do a single iteration at 128 bits using software-emulated 128-bit integer arithmetic, and so forth. As the operands get large enough to exceed the natural hardware wordsize  it also pays to exploit some simple optimizations resulting from the properties of the mod-inverse. For example, let us say our hardware supports integers of 64 bits, in the sense that the operations  and  (either directly or in emulated form via the upper half of ) are supported by way of hardware instructions. Further assume we have a 64-bit-accurate mod-inverse in hand (that is, bits 0:63 of the inverse), and wish to do one more Newtonian modular inversion iteration modulo  to obtain a 128-bit mod-inverse. We can do so efficiently, by way of direct computation of bits 64:127 of the inverse, using a combination of three of the above 64-bit  primitives. More generally, given a -bit-converged mod-inverse, one can obtain  more bits of precision using just three -bit  primitives. Here the bit count  need not be equal to that of the ensuing Montgomery-mul arithmetic~-- all the analysis holds generally~-- but let us assume it for notational ease.

Define an emulated -bit type (e.g.~in C via a struct) consisting of a pair of -bit ``digits"  and , such that a -bit quantity  expands~-- here again using C-style notation~-- as , where . We then take our -bit-converged mod-inverse  and use it to initialize the low word of such a -bit variable, that is, set  and . Since we presumably are working with a -bit modulus q, we similarly store it in another -bit variable ~-- the -bit inversion will have only used the lower half of this. We also have by construction that the fully (that is, -bit) converged inverse satisfies . We can take advantage of these two facts to speed the -bit inversion iteration. The product  yields a -bit partial multiplicative identity, where by ``partial" we mean having only its lower  bits unity, that is, identity modulo :

where here the `' are shorthand for full-width products of the operands in question. In terms of -bit hardware operations, since our input value  is -bits-good, we know {\em a priori} that the lower half (bits , word ) of the -bit product  is equal to 1, and need not explicitly compute this half. Extracting bits  of , which is the half of interest, we have:

where the addition is simple -bit hardware integer addition modulo . To effect the subtraction of the 2-word result  from the constant 2 we note that this subtraction leaves the low -bit word unchanged so long as , i.e. we have at least a 2-bit-converged mod-inverse. The high word simply requires arithmetic negation, thus . We use that the lower half of this is unity to simplify the ensuing  operation: since  still just has nonzero low word, one has

The low half of this is again guaranteed to be unity, so starting with a -bit accurate approximation to the multiplicative mod-inverse stored in , the entire sequence of operations needed to perform the next Newton iteration and obtain a -bit result can be condensed to the following direct computation of the next-higher  bits of the inverse, needing just three -bit multiply instructions, along with one addition and one arithmetic negation:

where the negation and addition are both twos-complement, i.e. modulo .

In order to compute a work estimate for~(\ref{next_b}), we must address the question of whether the upper-half product here is a true half-multiply (in the sense of needing asymptotically the same computational work as the a MULL operations as  becomes large) or whether the UMULH needs to be computed using a full double-width UMUL\_LOHI (retaining just the upper half of the result) in order to properly capture the carry out of the low half of the product. In general, half-multiply implementations of UMULH for multiword inputs proceed by truncating the multiplication rhombus and approximating the exact carry out of the the lower-half product using a ``carry layer" of thinness similar or equal to the bitwidth of the hardware wordsize . This is effective if the carries occurring in the wordsize computations are local, which is a good assumption if the inputs are quasirandom, in which case the chance of an incorrect carry resulting from the truncated-rhombus approximation is in some rough sense proportional to . In the context of the Newton iteration for the mod-inverse, however, the inputs to the  product yielding our partial multiplicative identity are the very opposite of random in this sense, because the very purpose of the iteration is to produce a product whose low  bits have the specific pattern 000...001. This by definition entails ``maximally nonlocal" carry behavior in the low half of the  product. But that very same property provides a way out of the seeming difficulty, since it guarantees that the discarded low-half product , by construction. In other words, the UMULH in the streamlined iteration~(\ref{next_b}) can truly be performed as a half-multiply, but if one does things this way one must compare the terms summed in the carry-layer approximation (which sum is normally simply discarded after it has been used to generate the carry) to the expected value 0, in order to identify any missed carry resulting from the approximation. We shall enounter a similar application of error-corrected upper-half multiply in our remainder and quotient algorithms.

Thus the cost of~(\ref{next_b}) can be brought down to three -bit half-multiply instructions, which is less than one-half the MUL cost needed for the na\"ive -bit version of the inversion iteration,\ for which the inner  operation forms a -bit result using one double-width  operation and two -bit ``half-multiply" (with respect to the width of the -bit inverse we seek)  instructions:


This then has its high digit negated to produce  prior to being fed to a second such multiply of the . Analogous considerations apply to each additional bit-doubling iteration required, so the work of each successive ``bit-doubling" step using~(\ref{next_b}) is asymptotically equivalent to the summed work of all the preceding iterations, hence the total work needed to obtain the fully converged inverse using this method is indeed less than that needed by a single ``na\"ive" Newtonian iteration performed at the full final precision needed.

By way of example, let us compute the inverse of the 128-bit   Using 64-bit hardware arithmetic we have  and . We compute  with respect to the arithmetic modulus , the smallest power of the hardware wordsize greater than . Starting with the initial guess formula~(\ref{qinv0}), 4 Newton iterations yield a 64-bits-good partial inverse , and it is easily verified that . Now making use of~(\ref{next_b}) with operand bitsize :

Thus , and again , as desired.



\section{A Fast Multiword Divisibility Test}
\label{sect:algo_a}

In this case it is not modmul by another number less than the radix we are interested in, but rather modmul by the radix  itself. In a typical modular reduction of a multiword integer of form

one might start with the most-significant digit , reduce  modulo  and carry the result rightward into the next-lower digit, a ``left-to-right" approach to the reduction if one visualizes the terms of the above expansion written out in decreasing significance from left to right, analogously to the way one writes multi-digit numbers in decimal and other common small bases.

Here we exploit the fact that the Montgomery modmul naturally introduces an inverse power of the radix  every time it is performed. Thus, starting with the least-significant digit , a Montgomery modmul of this with unity yields . But this is exactly the ``modular reduction carry" one needs if proceeding in right-to-left fashion, that is, the carry into the next-higher term. That observation, followed by a bit of carry-related work, leads immediately to the fast multiword divisibility algorithm captured in pseudocode form as Algorithm~A.

\begin{algorithm}\SetAlgoLined
\SetAlgoRefName{A}
\KwData{Unsigned b-bit integer array , b-bit scalars , with  odd and }
\KwResult{True if  divides , false otherwise.}
\vspace{0.1in}
{
	;\\
	\For { \KwTo }{
		;\\
		;\\
		{\em// Add q to loop output if had a borrow:}\\
		;\\
		;\\
	}
	\Return \;
}
\caption{IS\_DIV\_A, fast right-to-left divisibility check}
\label{algo_a}
\end{algorithm}

This algorithm can be trivially generalized to also permit even divisors, by first counting trailing binary zeros in  (call this number ), and one immediately returns FALSE if  has fewer trailing zeros than . Otherwise~-- in pseudocode but with all quantities arbitrarily large here~-- one returns IS\_DIV\_A(, where  ,  and  is the mod- inverse of the right-justified divisor . The number-of-words parameter can be set via  if one wants to account for the length reduction due to the right-shifting of inputs by one or more entire -bit words, without the extra expense of counting leading zeros of  required if one wants to achieve the maximum possible length reduction by counting partial-word shifts; otherwise one can simple take .

We assume nothing about hardware support for carry flags on add and subtract here, thus the explicit check for borrow-on-subtract using unsigned comparison . The one slight subtlety related to the case where the subtraction results in a borrow is that since the underlying remainder accumulation is , such a borrow must be accounted for by re-adding . Since the ensuing low-half multiply of  is by  and , one can simply add 1 to the  result instead of adding  to the computed difference stored in , which is advantageous if  occupies multiple machine words.

We can ignore the possible carry out of the resulting  step, because we are computing a result : If the addition overflows,  ends up being  too small as a result of twos-complement arithmetic. If we restore the dropped  in the next step, instead of

we have

i.e. the result is the same . Thus we are letting the twos-complement arithmetic help with the modding here. (Note that the  operation is doing effectively the same thing).

Because of the multiply-by-unity nature of the processing of each term in the expansion of  we do not need the double-width multiply which opens the three-multiply sequence of the general Montgomery modmul: Here (ignoring the carry-in from the next-lower term for the moment) we have , and instead of explicitly negating the output of the UMULH operation to effect the final  step, we simply subtract the UMULH result from the next-higher term at the start of the next loop execution, thus inlining the negation with the leftward carry propagation. The core loop in the algorithm thus constructs a scaled sequence of modular partial sums (negated Hensel remainders) such that on the th loop iteration,

To obtain the true remainder , we must take the output value, scale it and negate it :

Thus if we desire the true remainder rather than merely knowing whether it is zero on not, we just encapsulate the same computational loop in a slightly different interface, which here further performs the negation prior to returning to reinforce that it is a  negation rather than a twos-complement  one:
\vspace{0.1in}

\begin{algorithm}[H]
\SetAlgoLined
\SetAlgoRefName{A'}
\KwData{As for Algorithm A}
\KwResult{Scaled remainder  (mod ).}
\vspace{0.1in}
{
	{\em [Same as loop body of Algorithm A]}\\
	\eIf {} {
		\Return \;
	}{
		\Return \;
	}
}
\caption{REMAINDER\_A, fast right-to-left scaled remainder computation}
\label{algo_ar}
\end{algorithm}
\vspace{0.1in}

By way of a concrete numerical example which can be easily reproduced either using a tiny program or ``by hand" (using e.g.~the Unix `bc' utility or a freeware package such as Pari/GP), let us consider the problem of finding the remainder of  (which needs  64-bit words to store explicitly) with respect to the 64-bit modulus . The 64-bit mod inverse , and Table~2 lists the successive UMULH outputs at end of each loop execution in the middle column, and the results of applying the above scaling formula (with loop iteration  replacing  in the radix power) to these successive iterates in the third column from left~-- we write the scaled outputs in hexadecimal form to ease comparison with analogous data we shall provide in \S~\ref{sect:algo_b}. The reader can verify that these right-column data equal  (mod ), i.e. that the iterates are indeed the scaled partial sums as given in~(\ref{Asum}). Note that if we desire the Hensel quotient, we simply save the MULL outputs within the loop, but must further account for the possible borrow from the subtraction; these modifications produce the same quotient loop as given in our true-quotient-producing Algorithm~D, but with no true-remainder subtraction step preceding the loop.

\begin{table}
\begin{center}
\label{table_a}
\caption{Per-loop-iteration data for Algorithm A applied to  and , with . Rightmost column: A simple x86\_64 assembly-code implementation of the remaindering loop.}
\begin{tabular}{r|r|c| l l}
		&Result ()\qquad\qquad	& (mod )\qquad\\
\hline
	 0	& 8052108280172618802	&{\tt 1CFD12E467CEDBCE	}	&	\qquad{\tt	MOV	}	&	{\tt [x]\ \ \ ,R10}\\
	 1	&13395404783617144454	&{\tt 4D611EA3809531E7	}	&	\qquad{\tt	MOV	}	&	{\tt [len]\ ,RCX}\\
	 2	&14290423936650903017	&{\tt BD293142B725F2B8	}	&	\qquad{\tt	MOV	}	&	{\tt [q]\ \ \ ,RSI}\\
	 3	&12694450473754035419	&{\tt 6DA6C745723D2042	}	&	\qquad{\tt	MOV	}	&	{\tt [qinv],RBX}\\
	 4	&13022541340536637118	&{\tt 62A5DDA094A31338	}	&	\qquad{\tt	XOR	}	&	{\tt RDX,RDX	// cy = 0}\\
	 5	& 7849884873665013561	&{\tt 32D35CC447414DD0	}	&	\qquad{\tt	XOR	}	&	{\tt RDI,RDI	// bw = 0}\\
	 6	&  139461722106114244	&{\tt C4E358F892AFD7CB	}	&	{\tt loop:		}	&	{\tt // Loop downward}\\
	 7	& 6660703926365324543	&{\tt 841646B12435044D	}	&	\qquad{\tt	MOV	}	&	{\tt (R10),RAX	// x[i]}\\
	 8	&13147792529020392181	&{\tt 953C002AC7E9CA9B	}	&	\qquad{\tt	ADD	}	&	{\tt 8,R10	// \&x[i+1]}\\
	 9	&12940374201018017432	&{\tt 87A198DD565BAE6E	}	&	\qquad{\tt	SUB	}	&	{\tt RDX,RAX	// x[i]-cy}\\
	10	& 9345504322264630629	&{\tt 665B982F2C57CF9F	}	&	\qquad{\tt	SETC}	&	{\tt DIL	// bw = CF}\\
	11	&10439060481633841924	&{\tt C2F464196442F72D	}	&	\qquad{\tt	IMUL}	&	{\tt RBX,RAX 	// tmp*qinv}\\
	12	&11180607432989656657	&{\tt 92AB735A1C3B4927	}	&	\qquad{\tt	ADD	}	&	{\tt RDI,RAX	// tmp+=bw}\\
	13	& 6407570042918850368	&{\tt C2A0BA67701C6754	}	&	\qquad{\tt	MUL	}	&	{\tt RSI	// UMULH(q,tmp)}\\
	14	&12260751538328612790	&{\tt 339D02265F21100D	}	&	{\tt DEC RCX	}	&	{\tt }\\
	15	& 5031209829575536552	&{\tt 77ABEA1607BF1817	}	&	{\tt JNZ loop	}	&	{\tt // loop if RCX != 0}\\
		& 						& 							&	\qquad{\tt	MOV	}	&	{\tt RDX,[cy]	// Output}\\
\end{tabular}
\end{center}
\vspace{-0.4in}
\end{table}
The output of the loop is , which is nonzero and thus indicates that  does not divide , and indeed the properly scaled output  (mod ).

Timing tests of Algorithm~A on a commodity 64-bit PC~-- the author used a 64-bit GCC 4.2 build on a vintage 2009 sub-\xqn/1qqxqqinvx1x_i - cytmpqinvxqqxFFFFx_{n-1}uint_b\ n2 = n/2,\ tmp0,\ tmp1,\ bw0,\ bw1,\ cy0 = 0,\ cy1 = 0i\leftarrow 0n2-1tmp0 = x_i - cy0;						\qquad\qquad\qquad\qquad\ \ \ 	tmp1 = x_{i+n2} - cy1;	bw0 = (cy0 > x_i);						\qquad\qquad\qquad\qquad\ \ 	bw1 = (cy1 > x_{i+n2});	tmp0 = {\rm MULL_b}(tmp0, qinv) + bw0;\ \ tmp1 = {\rm MULL_b}(tmp1, qinv) + bw1;	cy0 = {\rm UMULH_b}(tmp0, q);			\qquad\qquad\ \ \ 	cy1 = {\rm UMULH_b}(tmp1, q);	uint_b\ scale = P\cdot R \equiv R^{n2+1}qcy1 \leftarrow {\rm MONT\_MUL_b}(cy1,\ scale,\ q,\ qinv)cy1 * Pquint_b\ cy = (cy0 + cy1)(cy < cy0)\ or\ (cy \ge q)cy \leftarrow (cy - q)(cy == 0)FxnFP = R^{n/F}\ ({\rm mod}\ q)qPRP\ ({\rm mod}\ q)P\cdot R = R^{n/F+1}\ ({\rm mod}\ q)qFxF=1FxF = 4qtmp \cdot q{\rm UMUL\_LOHI_b}(x, y)nq \cdot qinv \equiv 1\ ({\rm mod}\ R)tmp \cdot qlox_i - cy (+ q)qx_i < cyloqlo = x_i - cy (+ q)ixqxuint_b\ tmp,\ lo,\ cy = 0n == 1x_0 \% qi\leftarrow 0n-2tmp  = x_i - cybw = (cy > x_i)lo = tmp + qlo = tmptmp = {\rm MULL_b}(tmp, qinv) + bwcy = {\rm UMULH_b}(tmp, q [, lo])i = n-1tmp  = x_i - cycy > x_ilo = tmp + qlo = tmp(lo == 0)xqr = xqblolon = 1x_0x_0lox = 2^{977}-1q = 16357897499336320049R=2^{64}ilolo \cdot R^{i}qR^nqR^nqR^{n-1}qMp(j,k)j,kjkR(j+k-1)qRM(x,x){\rm MONT\_SQR_b}x,q,qinvqq \cdot qinv \equiv 1\ ({\rm mod}\ 2^b)R = 2^bx^2 \cdot R^{-1}quint_b\ hi:lo = {\rm USQR\_LOHI_b}(x)lo = {\rm MULL_b}(qinv, lo)lo = {\rm UMULH_b}(   q, lo)hi < lohi - lo + qhi - loM(x,1){\rm MMUL\_ONE_b}x,q,qinvqq \cdot qinv \equiv 1\ ({\rm mod}\ 2^b)R = 2^bx \cdot R^{-1}quint_b\ lo = {\rm MULL_b}(qinv, x)lo = {\rm UMULH_b}(   q, lo)lo \ne 0q - loloqRWW^k > qRqq < W = 2^{64}RqMp(1,1) \ra 1RqR^2qbnR^2q\lfloor R/q \rfloorR/qRqR - q \cdot \lfloor R/q \rfloorq < 2^{64}2^{96} = R^{3/2}q{\rm MONT\_SQR}_{64}2^{128} = R^2qqR^2qR^{n+1}qR^nq{\rm MONT\_SQR_b}{\rm MMUL\_ONE_b}{\rm MMUL\_ONE_b}RqR^nqxqnp = 2{\rm MONT\_SQR_b}n > 3ppjnxn > 2uint_b\ pow \equiv R^2qq,qinvqq \cdot qinv \equiv 1\ ({\rm mod}\ 2^b){\rm n} == 3pow \leftarrow {\rm MONT\_SQR_b}(pow,\ q,\ qinv)R^3\ ({\rm mod}\ q)uint_b\ ptmp \leftarrow {\rm MONT\_SQR_b}(pow,\ q,\ qinv)R^3\ ({\rm mod}\ q)int\ j \leftarrow 0,\ p \leftarrow n, bm \leftarrow 0p > 5{\rm BIT\_SETC}(bm,\ j,\ {\rm IS\_EVEN}(p))p \leftarrow (p/2) + 1j \leftarrow j + 1{\rm p} == 4pow \leftarrow {\rm MONT\_MUL_b}(pow,\ ptmp,\ q,\ qinv){\rm p} == 5pow \leftarrow {\rm MONT\_SQR_b}(ptmp,\ q,\ qinv)n > 5i\leftarrow j-10{\rm BIT\_TEST}(bm,\ i)ptmp \leftarrow {\rm MMUL\_ONE_b}(pow,\ q,\ qinv)pow  \leftarrow {\rm MONT\_MUL_b}(ptmp,\ pow,\ q,\ qinv)pow  \leftarrow {\rm MONT\_SQR_b}(pow,\ q,\ qinv)powR^nq(bitmap\ bm,\ int\ j,\ boolean\ cond)j(cond)p> 5p = 4p = 2p = 3p = 4Mp(3,Mp(3,0))p = 5Mp(3,3)p = 2p = 3p = 2Mp(3,0)n+1nxqr = {\rm MONT\_MUL_b}(tmp,pow,q,qinv).nn+1n(n,n+1)x = 2^{977}-1q = 16357897499336320049n = 16p = 16bm = 01p = 5R^2 = 5575771501247148520qRR^{16}\ ({\rm mod}\ q)R^{16} = 1547775041475743422qtmp = 4097145961007838330r = 8623243291871090711 \equiv 2^{977}-1qn+1p = 17bm = 00p = 5R^{17}\ ({\rm mod}\ q)R^{17} = 8502984233828494641qtmp = 11326687669760783497(n,n+1)n = 6n = 2^{20}n = 2^a + 1n(a-1)n+1(a-1)nO(\lg n)n\ra\ooxqinvxr = (x\ {\rm mod}\ q)(x - r)q(x - r) = k \cdot qk\lfloor x/q \rfloor{\rm MULL_b}(x - r, qinv)bkk < Rx < (q + 1)Rkqqinv_nR^n{\rm MULL}(x - r, qinv)nRcy(x - r)cy(R-1, R-1) = \lfloor (R^2 - 2R + 1)/R \rfloor = R-2cycy + bwbry[n]\lfloor x/q \rflooryxcy=0uint_b\ tmp,\ bw = 0,\ cy = ri \leftarrow 0n-1tmp = x_i - bw - cybw = (tmp > x_i)tmp = {\rm MULL_b}(tmp, qinv)cy = {\rm UMULH_b}(tmp, q)y_i = tmp({\rm mod}\ q)-1tmp \cdot q{\rm UMUL\_LOHI_b}(tmp, q)tmp = x_i - bw - cy+ bwx = 2^{977}-1q = 16357897499336320049y_i\lfloor x/q \rfloor2^{64}x = 2^{977}-1q = 16357897499336320049R=2^{64}y_ixqR = 2^{128}R^2qRq(x - r)(x - r)qinvy = \lfloor x/q \rfloor = (x - r)/q(x - r)(x - r)j(x - r)jyyy(x - r)qinv(x - r)(x - r)(x - r)xy\lceil \lg y \rceil(x - r)xqF=2r_0r_1r_1 = \lfloor x/R^{n/2} \rfloorqy_0-y_7xqqF=2i=n/2-1bw=1xx_{n/2}x_{n/2}i=12i=13n/1qqtz_qtz_qxbsave = x\ \& (2^{tz_q} - 1)qxq' = (q \gg tz_q)x' = (x \gg tz_q)x'q'r'r = (r' \ll tz_q) + bsavex'q'r'qx = 2^p + axqs = 2ppsq= 1s \equiv -aqr \equiv s + aq\lfloor \lg(p) \rfloorRs' = s \cdot RqRR^{-1}q{\rm MMUL\_ONE_b}RRRR = 2^b2^{-p}qp'pshift := {\rm NOT}(p')2^xxp'bpq< Ruint_bbpqq \cdot qinv \equiv 1\ ({\rm mod}\ 2^b)2^{-p}quint_b\ pshift = p + bint\ leadz  = int\ i_1  = b - 1 - leadzint\ i_0 = i_1[i_1:i_0] < bint\ ichunk = (pshift \gg i_0)[i_1:i_0]uint_b\ s = 1 \ll (b - ichunk - 1)pshift = {\rm NOT}(pshift)int\ i \leftarrow i_0-10s = {\rm MONT\_SQR_b}(s,\ q,\ qinv){\rm BIT\_TEST}(pshift,\ i)s = s + s{\rm if}(s \ge q)\ s = s-qs = s + s{\rm if}(s \ge q)\ s = s-qs2^{-p}qx = 2^{977}-1q = 16357897499336320049qinv = 9366409592816252113pshift = 977 + 64 = 1041= 10000010001_2R = 2^{64}leadz = 53i_1 = 64-1-53 = 10p[32, 63]i_0 = i_1-6+1 = 5ichunk = (p \gg 5) = 100000_2 = 32s = (1 \ll (64-32-1)) = (1 \ll 31)2^{31}i_0-1= 4{\rm NOT}(p')pshiftp = 977R=2^{64}ii(p')\ \ \ \ \ {\rm MONT\_SQR}(2^{31})		2^{  31\times2 - 64}			2^{  -2}						2 \times	{\rm MONT\_SQR}(2^{-1})		2^{  -2\times2 - 64}\times2	2^{ -68}\times2 = 2^{ -67}	2 \times	{\rm MONT\_SQR}(2^{-66})	2^{ -67\times2 - 64}\times2	2^{-198}\times2 = 2^{-197}	2 \times	{\rm MONT\_SQR}(2^{-196})	2^{-197\times2 - 64}\times2	2^{-458}\times2 = 2^{-457}	\ \ \ \ \ {\rm MONT\_SQR}(2^{-457})	2^{-457\times2 - 64}			2^{-978}s = 2^{-977}q= 7143819210136784550r = 2^{977}q= 8623243291871090712(2^{977} - 1)\ {\rm mod}\ qs \cdot r \equiv 1qp+bp2^pqp = 977= 1111010001R = 2^{64}= 111101 = 61s = R*2^{61}q= 696971437655893565R^{3/2}qR^2qR^2q2^{61}s2^{1041-64} = 2^{977}qppO(\lg p)2^pqp = 977R=2^{64}iip\ \ \ \ \ {\rm MONT\_SQR}(2^{125})	2^{125\times2 - 64}			2^{ 186}						\ \ \ \ \ {\rm MONT\_SQR}(2^{186})	2^{186\times2 - 64}			2^{ 308}						\ \ \ \ \ {\rm MONT\_SQR}(2^{308})	2^{308\times2 - 64}			2^{ 552}						2 \times	{\rm MONT\_SQR}  (2^{552})	2^{552\times2 - 64}\times2	2^{1040}\times2 = 2^{1041}	a \ne\pm 1s^{-1}qb2^p + aqRa = \pm 1R = 2^{96}q = 178021379228511215367151 = 2 \cdot 41448832329225 \cdot M_{31} + 1$. \cite{WMMM,MM31}



\section{Note Added in Proof}

Knuth~\cite{Knuth} hints at a right-to-left remaindering algorithm (Problem 4.3.1-41), but as this is cast as an exercise, there are scant details. Much more detail is provided in the paper by Eldridge \& Walter~\cite{EldWalt93}, who present both a right-to-left remaindering algorithm and a method for computing the quotient with it in ``on the fly'' fashion. Their quotient computation is not fully one-step deterministic in that it involves an initial estimate and a post hoc conditional error-correction step, but nonetheless allows for both remainder and quotient to be obtained with a single pass through the data. In that light, the main advantages of the present two-pass approach is its parallelizability~-- whether in ``overlapping instruction stream'' fashion as detailed here, or via explicit multithreaded implementation, or a combination of both. That parallelism is a direct result of the separate initial remaindering step, which is easily modified to yield as many ``partial remainders'' as desired, for either standalone recombination or for passing to a similarly parallel quotient-computation step. The author thanks an anonymous reviewer for the reference to the latter paper.



\section{Acknowledgements}

The fast divisibility Algorithm~A was first implemented by the author circa 1998 and used extensively since then in his experimental number theory codes, but was not considered by him to be suitable for publication without accompanying true-remainder and quotient algorithms. The latter came about only recently, thanks to an unexpected bout of free time sufficient to revisit the earlier work, for which the author would like to thank Synopsys Inc.

The author would like to thank Peter Montgomery, at whose metaphorical feet he first learned the basics of the latter's modmul method, and the ``hard code" crew at mersenneforum.com~-- George Woltman, Robert Holmes and Ross Schiff~-- for kindly taking the time to review an early version of this manuscript and providing numerous helpful x86\_64-coding-related insights.

\bibliographystyle{acmsmall}
\bibliography{mont_div_arxiv}



\end{document}
