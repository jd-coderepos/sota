\documentclass[11pt]{article}
\usepackage[pdftex]{graphicx,color}
\usepackage{graphicx,color}
\usepackage{amsmath,amssymb,dsfont,enumerate,fullpage,epsfig,multirow,longtable}
\usepackage{epsfig,epstopdf}
\usepackage{cases}
\usepackage{algorithm, algorithmic}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\usepackage[numbers]{natbib}

\usepackage{authblk}

\newenvironment{proof}{\noindent\emph{Proof\ }}{\hspace*{\fill}\medskip}
\newenvironment{claimproof}{\noindent\emph{Proof of claim\ }}{\hspace*{\fill}\medskip}
\newenvironment{plainproof}{\noindent\emph{Proof\ }}{}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{claim}{Claim}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}
\usepackage{amsmath}
\usepackage{paralist}
\usepackage{framed}


\newcommand{\todo}[1]{{\bf{ \color{red} : {#1}}}}

\newcommand\restr[2]{{\left.\kern-\nulldelimiterspace #1 \vphantom{\big|} \right|_{#2} }}

\newcommand{\one}{\ensuremath{\mathds{1}}}

\title{Lagrangian Duality based Algorithms in Online Scheduling}
\author{Nguyen Kim Thang\thanks{Research supported by FMJH program Gaspard Monge in Optimization and
Operations Research and by EDF.}}
\affil{IBISC, University of Evry Val d'Essonne, France }

\date{}

\begin{document}

\maketitle


\begin{abstract}
We consider Lagrangian duality based approaches to design and analyze 
algorithms for online energy-efficient scheduling. 
First, we present a primal-dual framework. 
Our approach makes use of the Lagrangian weak duality and convexity to derive 
dual programs for problems which could be formulated as convex assignment
problems. The duals have intuitive structures as the ones in linear programming.
The constraints of the duals explicitly indicate the online decisions
and naturally lead to competitive algorithms. 
Second, we use a dual-fitting approach, which also based on the weak duality, 
to study problems which are unlikely to admit convex relaxations. Through the analysis,
we show an interesting feature in which 
primal-dual gives idea for designing algorithms while the analysis 
is done by dual-fitting.

We illustrate the advantages and the flexibility of the approaches through problems 
in different setting: from single machine 
to unrelated machine environments, from typical competitive analysis to the one with
resource augmentation, from convex relaxations to non-convex relaxations.
\end{abstract}

\newpage 
\tableofcontents


\section{Introduction}	\label{sec:intro}

In the online setting, items arrive over time 
and one must determine how to serve items in order to optimize a quality of 
service without the knowledge about future. 
A popular measure for studying the performance of online algorithms is 
\emph{competitive ratio} in the model of the worst-case analysis. 
An algorithm is said to be -\emph{competitive}
if for any instance its objective value is within factor  of the optimal offline algorithm's one.  
Moreover, to remedy the limitation of pathological instances in the worst-case analysis, 
there is other model called \emph{resource augmentation} \cite{KalyanasundaramPruhs00:Speed-is-as-powerful}. 
In the latter, online algorithms are given an extra power and are compared to the optimal 
offline algorithm without that additional resource. This model has successfully provided theoretical evidence for 
heuristics with good performance in practice, especially in online scheduling where 
jobs arrive online and need to be processed on machines. 
We say a scheduling algorithm is \emph{-speed -competitive}
if for any input instance the objective value of the algorithm with machines of 
speed  is at most  times the objective value of the optimal offline scheduler
with unit speed machines. 

The most successful tool until now to analyze online algorithms 
is the potential function method. 
Potential functions have been designed to show that the corresponding algorithms behave
well in an amortized sense. However, designing such potential functions is far from trivial and often
yields little insight about how to design such potential functions and algorithms for related problems. 

Recently, interesting approaches 
\cite{AnandGarg12:Resource-augmentation,GuptaKrishnaswamy12:Online-Primal-Dual,Thang13:Lagrangian-Duality} 
based on mathematical programming have been presented 
in the search for a principled tool to design and analyze online scheduling algorithms. 
The approaches give insight about the nature of many scheduling problems,
hence lead to algorithms which are usually simple and competitive.


\subsection{Approaches and Contribution}	
In this paper, we present approaches based on Lagrangian duality in designing and analyzing 
algorithms for online energy-efficient scheduling problems. 

\paragraph{Primal-Dual Approach.} We first show a primal-dual framework for a general online 
convex assignment problem and its applications to online scheduling. In the framework, the algorithm 
decisions are interactively guided by the dual variables in the primal-dual sense. 

The online convex assignment problem consists of a set of agents and a set of items which arrive over time.
At the arrival of item , the item needs to be (fractionally) assigned to some agents . 
Let  is the amount of  assigned to .
The problem is to minimize   
under some constraints 
and  for every  where functions 's are convex.
In offline setting, the optimal solutions are completely characterized by 
the KKT conditions (see \cite{BoydVandenberghe04:Convex-Optimization} for example).
However, for online setting, the conditions could not be satisfied due to the lack of knowledge
about the future. 

Our approach is the following. We first consider the problem as a primal convex mathematical program. 
Then we derive a Lagrangian dual program by the standard Lagrangian duality. 
Instead of analyzing directly the corresponding Lagrangian functions
where in general one can not disentangle the objective and the constraints
as well as the primal and dual variables,
we exploit the convexity property of given functions and construct 
a dual program. In the latter, dual variables are separated from the primal ones. 
The construction is shown in Section \ref{sec:framework}.
As the price of the separation procedure, the strong duality 
property is not guaranteed. However, the weak duality always holds and that is 
crucial (and sufficient) to deduce a lower bound for the given problem.
The dual construction is not standard in optimization but the goal is to derive 
duals with intuitive structures similar to the ones in linear programming which 
are easier to work with.
An advantage of the approach lies in the dual program
in which the constraints could be maintained online. Moreover, the dual constraints 
explicitly indicate the online decisions and naturally lead to a competitive algorithm
in the primal-dual sense.   

The dual construction is inspired by \cite{DevanurJain12:Online-matching}
which used the primal-dual approach for online
matching with concave return. In fact, Devanur and Jain \cite{DevanurJain12:Online-matching}
considered a matching problem with convex objective function and \emph{linear} constraints.
They linearized the objective function and derived the dual in the sense of linear programming. 
In our framework, we consider problems with convex objective and 
\emph{convex} constraints\footnote{The primal-dual machinery of linear programming cannot be applied anymore.}. 
We then construct our duals from Lagrangian dual programs. 
Informally, the construction could be seen as a linearization of Lagrangian duals. 

\paragraph{Applications.}	 We illustrate the advantages and the flexibility of the approach through 
online scheduling problems related to throughput. In the setting, there are a set of 
unrelated machines. Each job  is released at time , has deadline , a value  and 
a processing volume  if job  is executed in machine . 
Jobs could be executed preemptively but migration is not allowed, 
i.e., no job could be executed in more than one machine. At any time , the scheduler 
has to choose an assignment of jobs to machines and the speed of each machine 
in order to process such jobs. The energy cost of machine  is 
 where  is a given convex energy power and 
is the speed of machine  at time . Typically,  for some constant . 
In the setting, we look for competitive and energy-efficient algorithms. The following objectives 
are natural ones representing the tradeoff between value and energy. 
The first objective is to minimize energy cost plus the \emph{lost value} 
--- which is the total value of uncompleted jobs. The second objective is to maximize 
 the total value of completed jobs minus the energy cost.

\begin{enumerate}
	\item For the objective of minimizing energy plus the lost value 
	we derive a primal-dual algorithm for the single machine setting. 
	The competitive ratio is characterized by a system
	of differential equations. For a specific case where , the competitive
	ratio turns out to be  (and recognize the result in \cite{KlingPietrzyk13:Profitable-Scheduling}. 
	With the primal-dual framework, the result is more general and the analysis is simpler.
\item For the objective of maximizing the total value of completed jobs minus the energy cost,
	it has been shown that without resource augmentation 
	no algorithm has bounded competitive ratio even for a single machine \cite{PruhsStein10:How-to-Schedule-When}.
	We study the problem for unrelated machines in the resource augmentation model. We give a primal-dual 
	algorithm which is -speed and -competitive for 
	every  where  depends on function .
	For typical function , 
	which is closed to 0 for large .
\end{enumerate}

Note that for these problems, we consider relaxations with convex objectives and linear constraints.

\paragraph{Dual-fitting approach.} 
An essential point of the primal-dual approach is a \emph{convex} relaxation 
of the corresponding problems. However, some problems unlikely admit such a relaxation. 
To overcome that difficulty, we follow the dual-fitting approach for \emph{non-convex}
programming presented in \cite{Thang13:Lagrangian-Duality}. A summary of the approach is as 
follows.

Given a problem, formulate a relaxation which is \emph{not} necessarily convex and its Lagrangian dual. 
Next construct dual variables such that the Lagrangian dual has objective value within a desired factor 
of the primal one (due to some algorithm). Then by the standard Lagrangian weak 
duality\footnote{For completeness, the proof of weak duality is given in the appendix} 
for mathematical programming, the competitive ratio follows. Since the Lagrangian weak 
duality also holds in the context of calculus of variations, the approach could be applied 
for the unknowns which are not only variables but also functions.  

Let  be the Lagrangian function with primal and dual variables 
and , respectively. 
Let  and  are feasible sets of  and .
Intuitively, the approach could be seen as a game between an algorithm
and an adversary. The algorithm chooses dual variables  in such a way that whatever 
the choice (strategy) of the adversary, the value 
is always within a desirable factor  of the objective due to the algorithm.
We emphasize that  is taken over  feasible solutions 
of the primal.

An advantage of the approach is the flexibility of the formulation. 
As convexity is not required, we can come up with a direct and natural relaxation for the problem.
The main core of the approach is to determine the dual variables
and to prove the desired competitive ratio. Determining such dual variables is the crucial 
step in the analysis. However, the dual variables usually have intuitive interpretations which are useful  
to figure out appropriate values of such variables. Besides, the dual variables are not interactively 
constructed as in the primal-dual approach --- this is the main difference between two approaches.
Nevertheless, for some problems one could informally separate the convex and non-convex parts. Then 
the dual solution for the original problem may be derived from 
a dual solution for the convex part (constructed using primal-dual) by
adding some correcting terms due to the non-convex part. 



\paragraph{Applications.}
We consider the general energy model: speed scaling with power down. 
There is a machine which can be set either in the sleep state or in the active 
state. Each transition of the machine from the sleep state to the active one has 
cost , which represents the \emph{wake-up} cost. 
In the sleep state, the energy consumption of the machine is 0. 
The machine, in its active state, can choose a speed 
to execute jobs. The power energy consumption of 
the machine at time  in its active state is 
where  and  are characteristic parameters of 
the machine. Hence, the consumed energy (without wake-up cost) of the machine
is  where the integral is taken during the machine's 
active periods. We decompose the latter into \emph{dynamic energy} 
 and \emph{static energy} 
 (where again the integrals are taken during
active periods).
Jobs arrive over time, a job  is released at time , has weight  
and requires  units of processing volume if it is processed 
on machine . A job could be processed preemptively.
At any time, the scheduler has to determine the state and the speed of every machine (it it is active) 
and also a policy to execute jobs.
We consider two problems in the setting.

In the first problem, each job  has additionally a deadline  by which 
the job has to be completed. The objective is to minimize the total consumed
energy.  

In the second problem, jobs do not have deadline. Let  
be the completion time of the job . 
The \emph{flow-time} of a job  is defined as , 
which represented the waiting time of  on the server.
The objective is to minimize the total weighted flow-time of all jobs plus the total 
energy. 

As posed in \cite{Albers10:Energy-efficient-algorithms}, an important direction in energy-efficient scheduling
is to design competitive algorithms for online problems
in the general model of speed scaling with power down. 
Attempting efficient algorithms in the general energy model, one encounters 
the limits of current tools which have been successfully applied 
in previous energy models. That results in a few work on the model
\cite{AlbersAntoniadis12:Race-to-idle:,BampisDurr12:Speed-scaling,HanLam10:Deadline-scheduling},
in contrast to the widely-studied models of speed scaling only or power down only. 
The potential function method, as mentioned earlier, yield little insight
on the construction of new algorithms in this general setting.     
Besides, different proposed approaches based on the duality of 
mathematical programming
\cite{AnandGarg12:Resource-augmentation,GuptaKrishnaswamy12:Online-Primal-Dual,DevanurHuang14:Primal-Dual} 
require that the problems admit linear of convex relaxations. However, it is unlikely to 
formulate problems in the general energy model as convex 
programs.  

Our results in the general energy model are the following.


\begin{enumerate}
	\item For the problem of minimizing the total consumed energy,
	we formulate a natural \emph{non-convex} relaxation using the Dirac delta function. 
	We first revisit a special case with no wake-up cost under the primal-dual view. In this case,
	the relaxation becomes convex and our framework could be applied to show a
	-competitive algorithm (the algorithm is in fact algorithm 
	\textsc{Optimal Available} \cite{YaoDemers95:A-Scheduling-Model}).
	Next we study the general problem with wake-up cost. 
	The special case effectively gives ideas to determine the machine speed in active state. 
	Thus we consider an algorithm in which the procedure maintaining the machine 
	speed in active state follows the ideas in the special case. The algorithm turns out to be algorithm 
	\textsc{Sleep-aware Optimal Available} (SOA) \cite{HanLam10:Deadline-scheduling} with different description 
	(due to the primal-dual view). \citet{HanLam10:Deadline-scheduling} proved that SOA has competitive ratio 
	. We prove that SOA is indeed  
	-competitive by the dual-fitting technique.
	Although the improvement is slight, the analysis is 
	\emph{tight}\footnote{The algorithm has competitive ratio exactly 
	even without wake-up cost \cite{BansalKimbrel07:Speed-scaling}.}
	and it suggests that the duality-based approach is seemingly a right tool for online scheduling. 
	Through the problem, we illustrate an interesting feature in the construction of  
	algorithms for non-convex relaxations. The primal-dual framework
	gives ideas for the design of an algorithm while the analysis is done using dual-fitting technique.     
\item For the problem of minimizing energy plus weighted flow-time, we derive a -competitive
	algorithm using the dual fitting framework; that matches the best known competitive ratio (up to a constant)
	for the same problem in the restricted speed scaling model 
	(where the wake-up cost and the static energy cost are 0). 
	Informally, the dual solutions are constructed as the combination of a solution 
	for the convex part of the problem and a term that represents the lost due to 
	the non-convex part. Building upon the salient ideas of the previous analysis,
	we manage to show the competitiveness of the algorithm. 
\end{enumerate}

\subsection{Related work}



In the search for principled methods to design and analyze online problems,
especially in online scheduling, interesting approaches 
\cite{AnandGarg12:Resource-augmentation,GuptaKrishnaswamy12:Online-Primal-Dual,Thang13:Lagrangian-Duality} 
based on mathematical programming have been presented. 
The approaches give insight about the nature of many scheduling problems,
hence lead to algorithms which are usually simple and competitive
\cite{AnandGarg12:Resource-augmentation,GuptaKrishnaswamy12:Online-Primal-Dual,Thang13:Lagrangian-Duality,DevanurHuang14:Primal-Dual,ImKulkarni14:Competitive-Algorithms,ImKulkarni14:SELFISHMIGRATE:-A-Scalable}.

\citet{AnandGarg12:Resource-augmentation} was the first who proposed 
studying online scheduling by linear (convex) 
programming and dual fitting. By this approach, they gave 
simple algorithms and simple analyses with improved performance
for problems where the analyses based on potential functions are complex or 
it is unclear how to design such functions. Subsequently, 
Nguyen \cite{Thang13:Lagrangian-Duality} generalized the approach
in \cite{AnandGarg12:Resource-augmentation} and proposed to study online scheduling 
by non-convex programming and the weak Lagrangian duality. Using that technique,
\cite{Thang13:Lagrangian-Duality} derive competitive algorithms 
for problems related to weighted flow-time.

\citet{BuchbinderNaor09:The-Design-of-Competitive}
presented the primal-dual method for online packing and covering problems.
Their method unifies several previous
potential function based analyses and is a powerful tool to design and analyze 
algorithms for problems with linear relaxations.
\citet{GuptaKrishnaswamy12:Online-Primal-Dual}
gave a primal-dual algorithm for a general class of scheduling problems with 
cost function . \citet{DevanurJain12:Online-matching}
also used the primal-dual approach to derive optimal competitive ratios for online
matching with concave return. 
The construction of dual programs in \cite{DevanurHuang14:Primal-Dual,DevanurJain12:Online-matching}
is based on convex conjugates and Fenchel duality for primal convex programs
in which the objective is convex and the constraints are \emph{linear}. 



An interesting quality of service in online scheduling is the tradeoff between 
energy and throughput. The online problem to minimize the consumed energy plus lost values 
with the energy power  is first studied by \cite{ChanLam10:Tradeoff-between}
where a -competitive algorithm is given for a single machine.
Subsequently, \citet{KlingPietrzyk13:Profitable-Scheduling} derived an 
improved -competitive for identical machines with migration using the technique in 
\cite{GuptaKrishnaswamy12:Online-Primal-Dual}. 
The online problem to maximize the total value of completed jobs minus the consumed energy
for a single machine has been considered in
\cite{PruhsStein10:How-to-Schedule-When}. \citet{PruhsStein10:How-to-Schedule-When} proved that 
the competitive ratio without resource augmentation is unbounded and gave 
an -speed, -competitive algorithm for a single machine.
 
The objective of minimizing the total flow-time plus energy has been widely studied in speed scaling energy model. 
For a single machine, \citet{BansalChan09:Speed-scaling}
gave a -competitive algorithm. Besides, they also proved a  
-competitive algorithm for minimizing total \emph{fractional} weighted flow-time plus
energy. Their results hold for a general class of convex power functions. Those results also 
imply an -competitive algorithm for weighted flow-time plus energy 
when the energy function is . Again, always based on linear programming and dual-fitting, 
\citet{AnandGarg12:Resource-augmentation} proved an -competitive algorithm 
for unrelated machines. Subsequently, Nguyen \cite{Thang13:Lagrangian-Duality} and
\citet{DevanurHuang14:Primal-Dual} presented an -competitive algorithms 
for unrelated machines by dual fitting and primal dual approaches, respectively. It turns out that the different
approaches lead to the same algorithm. To the best of our knowledge, this objective is not studied 
in the speed scaling with power down energy model.

In the speed scaling with power down energy model, all previous papers
considered the problem of minimizing the energy consumption on a single machine. 
\citet{IraniShukla07:Algorithms-for-power} was the first 
who studied the problem in online setting and derived an algorithm with competitive ratio 
. Subsequently, 
\citet{HanLam10:Deadline-scheduling} presented an algorithm 
which is -competitive.
In offline setting, the problem is recently showed to be NP-hard 
\cite{AlbersAntoniadis12:Race-to-idle:}. Moreover, \citet{AlbersAntoniadis12:Race-to-idle:}
also gave a 1.171-approximation algorithm, which improved
the 2-approximation algorithm in \cite{IraniShukla07:Algorithms-for-power}. 
If the instances are agreeable then the problem is polynomial 
\cite{BampisDurr12:Speed-scaling}.
 
 
 
\subsection{Organization}
The paper is organized as follows. In Section \ref{sec:framework}, we introduce the 
online convex assignment problem and present a primal-dual framework for this problem.
In Section \ref{sec:energy+values} and Section \ref{sec:values-energy}, we apply the framework
to derive primal-dual algorithms for problems related to the tradeoff between energy and value. 
In Section \ref{sec:4S-energy} and Section \ref{sec:4S-energy+flow}, we study problems
in the speed scaling with power down model using the dual-fitting approach.  
In the former, we study the problem of minimizing energy and 
in the latter we consider the problem of minimizing 
the total energy plus weighted flow-time. In the beginning of each section, we 
restate the considered problem in a short description. 


\section{Framework for Online Convex Assignment}		\label{sec:framework}
  
Consider the assignment problem where items  arrive online 
and need to be (fractionally) assigned to some agents  with the following objective and constraints.   

where  indicates the amount of item  assigned to agent  
and functions  are convex, differential for every  and 
. Denote  if item  is released before item . 

Let  be the set of feasible solutions of . 
The Lagrangian dual is
 
where  is the following Lagrangian function 

where the inequalities holds for any  due the convexity of functions 's.
In the first inequality, we use  
(similarly for functions 's) and in the second inequality, 
we use the monotonicity of  (and similarly for ).
Denote 

We have 

Intuitively, one could imagine that  is the solution of an algorithm (or a function 
on the solution of an algorithm). We emphasize that  is \emph{not} a solution of 
an optimal assignment. The goal is to design 
an algorithm, which produces  and derives dual variables , in such
a way that the primal objective is bounded by a desired factor from the dual one.
   
Inequality (\ref{framework-Lagrangian}) naturally leads to the following idea of an algorithm. 
For any item , we maintain the following invariants  

Whenever the invariants hold for every ,
 since  for every . 
Therefore,  and so the dual 
is lower-bounded by , which does not depend anymore
on . The procedure of maintaining the invariants dictate the decision  
of an algorithm and indicates the choice of dual variables. 

Consider the following dual


\begin{lemma}[Weak Duality]
Let  and  be optimal values of primal program
 and dual program , respectively. Then
.
\end{lemma}
\begin{proof}
It holds that

where the inequalities follow the weak Lagrangian duality and the constraints of 
for every feasible solution .
Therefore, the lemma follows.
\end{proof}

Hence, our framework consists of maintaining the invariants for every online item  and
among feasible set of dual variables (constrained by the invariants) choose the ones 
which optimize the ratio between the primal and dual values. If an algorithm with output 
 satisfies  for some factor  then 
the algorithm is -competitive.

\section{Minimizing Total Energy plus Lost Values}	\label{sec:energy+values}

\paragraph{The problem.}
We are given a machine with a convex energy power  and
jobs arrive over time. Each job  is released at time , has deadline , processing volume 
 and a value . Jobs could be executed preemptively and at any time , the scheduler 
has to choose a set of \emph{pending} jobs (i.e., ) and a machine speed  
in order to process such jobs. The \emph{energy cost} of a schedule is 
. Typically,
 for some constant . The objective of the problem
is to minimize energy cost plus the \emph{lost value} --- which is the total value of uncompleted jobs.


\paragraph{Formulation.} Let  and  be variables indicating whether job  is completed or it is not.
We denote variable  as the speed that the machine processes job  at time .  
The problem could be relaxed as the following convex program.
 
  
In the relaxation, the second constraint indicates that either job  is completed or it is not. 
The third constraint guarantees the necessary amount of work done in order to complete job .  

Applying the framework, we have the following dual.

subject to
\begin{enumerate}
	\item For any job , . 
	Moreover,  if  then . 
	\item For any job ,  and  if  then .
	\item For any job  and any , it holds that 
	. 
	Particularly, if  then . 
\end{enumerate}
Note that  is not equal to  (the machine speed on job  according to our algorithm) 
but it is a function depending on . That is the reason we use  instead of .
We will choose 's in order to optimize the competitive ratio. To simplify the notation, we drop out 
the star symbol in the superscript of every variable (if one has that). 

\paragraph{Algorithm.} The dual constraints naturally leads to the following algorithm. We first describe
informally the algorithm. 
In the algorithm, we maintain a variable  representing the 
\emph{virtual} machine speed on job . The virtual speed on job  means 
that job  will be processed with that speed \emph{if} it is accepted; otherwise, 
the real speed on  will be set to 0. 
Consider the arrival of job . Observe that by the third dual constraint, 
we should always increase the machine speed on job 
at  in order to increase .
Hence, at the arrival of a job , increase continuously the \emph{virtual} 
speed  of job  at  for .
Moreover, function  is also simultaneously 
updated as a function of  
according to a system of differential equations
(\ref{eq:PD-throughput+energy}) in order to optimize the competitive ratio.
The iteration on job  terminates whether one of the first two constraints becomes tight. 
If the first one holds, then accept the job and set the real speed equal to 
the virtual one. Otherwise, reject the job.

Define .
Consider the following system of differential equations with 
boundary conditions:  if .

where  is some constant. Let  be a smallest constant such that the system has 
a solution. 

The formal algorithm is given in Algorithm~\ref{algo:energy+values}. 

\begin{algorithm}[htbp]
\begin{algorithmic}[1] 
\STATE Initially, set , ,  and  equal to 0 for every .
\STATE Let  be the smallest constant such that  
	(\ref{eq:PD-throughput+energy}) has a solution. During the algorithm, keep 
	as a solution of (\ref{eq:PD-throughput+energy}) with constant  and 
	for every time .
\FOR{a job  arrives}
	\STATE Initially, .
	\WHILE{ \textbf{and} }
		\STATE Continuously increase  at   for 
		and update  and  (as a function of ) and
		 simultaneously. 
	\ENDWHILE
	\STATE Set .
\IF{ \textbf{and} }
		\STATE Reject job .
		\STATE Set .
	\ELSE
		\STATE Accept job .
		\STATE Set ,  
			     and .
	\ENDIF
\ENDFOR
\end{algorithmic}
\caption{Minimizing the consumed energy plus lost values.}
\label{algo:energy+values}
\end{algorithm}


In the algorithm, machine  processes accepted job  with speed  at time .
As the algorithm completes all accepted jobs, it is equivalent to state that the machine
processes accepted jobs in the earliest deadline first fashion with speed  at time .

By the algorithm, the dual variables are feasible. In the following
we bound the values of the primal and dual objectives.

\begin{lemma}		\label{lem:throughput+energy}
It holds that 

\end{lemma}
\begin{proof}
By the algorithm,  at every time  such that 
for every job . Hence, it is sufficient to show that 

where recall .

We will prove the inequality (\ref{ineq:throughput+energy-1}) 
by induction on the number of jobs in the instance. For the base case where there is 
no job, the inequality holds trivially. Suppose that the inequality holds before the arrival of a job .
In the following, we consider different cases.

\paragraph{Job  is accepted.} 
Consider any moment  in the while loop related to job . We emphasize that  is a moment 
in the execution of the algorithm, not the one in the time axis .
Suppose that at moment , an amount  is increased (allocated) at . Note that 
 as .
As  is accepted,  and 
the increase at  in the left hand-side of (\ref{ineq:throughput+energy-1})
is  

Let  be the value of  at moment  in 
the while loop.  By the algorithm, the dual variable  satisfies

where the inequality is due to the fact that at the end of the while loop, 
 (by the loop condition) and  is increasing. 
Therefore, at moment , 

where the equality follows since .
Hence, the increase in the right hand-side of (\ref{ineq:throughput+energy-1}) is at least 
.

Due to the system of inequations~(\ref{eq:PD-throughput+energy}) and the choice of , 
at any moment in the execution of the 
algorithm, the increase in the left hand-side of (\ref{ineq:throughput+energy-1}) is 
at most that in the right hand-side. Thus, the induction step follows.

\paragraph{Job  is rejected.}
If  is rejected then  and so the increase in the left hand-side of (\ref{ineq:throughput+energy-1}) 
is . Moreover, by the algorithm .
So we need to prove that after the iteration of the for loop 
on job , it holds that 
.
As  is rejected, 

Therefore, it is sufficient to prove that 

Before the iteration of the while loop, the left-hand side of (\ref{ineq:energy+values-2}) 
is . Similar as the analysis of the previous case, during the execution of the algorithm
the increase rate of the left-hand side is 
, which is non-negative by
equation~(\ref{eq:PD-throughput+energy}). Thus, inequality (\ref{ineq:energy+values-2})
holds.

By both cases, the lemma follows. 
\end{proof}

\begin{theorem}
The algorithm is -competitive. Particularly,
if the energy power function  then the algorithm 
is -competitive
\end{theorem}
\begin{proof}
The theorem follows by the framework
and Lemma \ref{lem:throughput+energy}.

If the power energy function  
then  and  satisfy the system 
(\ref{eq:PD-throughput+energy}). Thus, the algorithm is -competitive.
\end{proof}


\section{Maximizing the Total Value minus Energy}		\label{sec:values-energy}

\paragraph{The problem.}
We are given unrelated machines and jobs arrive over time. 
Each job  is released at time , has deadline , a value  
and processing volume  if it is executed on machine . 
Jobs could be executed preemptively but migration is not allowed, i.e., no job 
could be executed in more than one machine. 
At a time , the scheduler has to choose a set of \emph{pending} jobs (i.e., )  
to be processed on each machine, and 
the speeds 's for every machine  to execute such jobs.  
The energy cost is  where  is a given convex power function.
The objective now is to maximize the total value of completed jobs minus the energy cost. 

We first give some idea about the difficulty of the problem even on a single machine. 
Assume that the adversary releases a job with small value but with a high energy 
cost in order to complete the job. One has to execute the job since otherwise the profit would be zero.
However, at the moment an algorithm nearly completes the job, the adversary releases
other job with much higher value and a reasonable energy demand. One need to switch immediately 
to the second job since otherwise either a high value is lost or the energy consumption becomes 
too much. It means that all energy spending on the first job is lost without any gain. 
Based on this idea, \cite{PruhsStein10:How-to-Schedule-When} has shown that 
without resource augmentation, the competitive ratio 
is unbounded. 

In this section, we consider the problem with resource augmentation, meaning that 
with the same speed  the energy power for the algorithm is , 
whereas the one for the adversary is . 
Let  be the smallest constant such that  for 
all . For the typical energy power , 
which is closed to 0 for  large.


\paragraph{Formulation.} Let  be variable indicating whether job  is completed
in machine . 
Let  be the variable representing the speed
that machine  processes job  at time .   
The problem could be formulated as the following convex program.
 
  
Note that in the objective, by resource augmentation the consumed energy 
is . 
Applying the framework, we have the following dual.

subject to
\begin{enumerate}
	\item For any machine  and any job , 
	. 
	\item For any machine , any job  and any , 
	 where the sum is taken over all jobs  released before ,
	i.e., . 
	Particularly, if  then . 
\end{enumerate}


Similar as in the previous section, the constraints naturally lead to Algorithm~\ref{algo:values-energy}.
In the algorithm and the analysis, to simplify the notation we drop out 
the star symbol in the superscript of every variable (if one has that). 


\begin{algorithm}[ht]
\begin{algorithmic}[1] 
\STATE Initially, set  and  equal to 0.
\STATE The algorithm always runs accepted jobs with speed  in the earliest deadline 
	first fashion. 
\FOR{a job  arrives}
	\STATE Initially,  for every  and let  be the set of all machines,
		.
	\WHILE{}
		\STATE For every , 
		increase  at  in the continuous manner for 
		and update  and 
		 simultaneously. 
		\IF{ \textbf{and}  for some machine }
			\STATE .
		\ENDIF
		\IF{ \textbf{and}  for some machine }
			\STATE  and  .
		\ENDIF
	\ENDWHILE
	\IF{}
		\STATE Reject job  and set  (note that ).
	\ELSE
		\STATE Let .
		\STATE Accept and assign job  to machine , i.e., .
		\STATE Set , 
				and .
	\ENDIF
\ENDFOR
\end{algorithmic}
\caption{Minimizing the throughput minus consumed energy.}
\label{algo:values-energy}
\end{algorithm}

\begin{lemma}
Dual variables constructed by Algorithm~\ref{algo:values-energy} are feasible.
\end{lemma}
\begin{proof}
By the algorithm (line 6),  
where the sum is taken over all jobs  released before  () and
if  then . 
Consider the first constraint. If  is rejected then  for every machine .
Otherwise, by the assignment (line 17),
it always holds that  for every .
\end{proof}

In the following we bound the values of the primal and dual objectives 
in the resource augmentation model.

\begin{lemma}		\label{lem:throughput-energy}
For every , it holds that 

\end{lemma}
\begin{proof}
We have 

In the second inequality, recall that 
and by the algorithm, 
for any . 
The last inequality follows by the 
definition of . Therefore, it is sufficient to prove that 

We prove inequality (\ref{eq:throughput-energy-1})
by induction on the number of released jobs in the instance. For the base case where there is 
no job, the inequality holds trivially. Suppose that the inequality holds before the arrival of a job .

If  is rejected then  for every  and . 
Therefore, the increases in both side of inequality (\ref{eq:throughput-energy-1}) are 0.
Hence, the induction step follows. 

In the rest, assume that  is accepted and let  be the machine 
to which  is assigned. 
We have

The first inequality is due to the convexity of 
 
The second inequality holds because  is increasing. 
The first equality follows since
 only at  such that  (by the algorithm).     
The last inequality is due to the loop condition in the algorithm.
Thus, at the end of the iteration (related to job ) in the for loop,
the increase in the left hand side of inequality (\ref{eq:throughput-energy-1}) is
 
Besides, the increase in the right hand-side of inequality (\ref{eq:throughput-energy-1}) is 
.
Hence, the induction step follows; so does the lemma.
\end{proof}


\begin{theorem}
The algorithm is -augmentation, -competitive
for . 
\end{theorem}
\begin{proof}
By resource augmentation, with the same speed  the energy power 
for the algorithm is , 
whereas the one for the adversary is . So by 
Lemma~\ref{lem:throughput-energy}, the theorem follows.
\end{proof}

Note that the result could be generalized for \emph{heterogeneous} machines 
where the energy power functions are different. In this case, one needs to consider 
.

\section{Energy Minimization in Speed Scaling with Power Down Model}		\label{sec:4S-energy}
\paragraph{The problem.} 
We are given a single machine that could be transitioned into 
a sleep state or an active state.  Each transition from the sleep state to 
the active state costs , which is called the \emph{wake-up cost}. 
Jobs arrive online, each job has a released time , a deadline , 
a processing volume  and could be processed preemptively. In the problem,
all jobs have to be completed. In the sleep state, the energy consumption of the machine is 0.
In the active state, the power energy consumption at time  is 
where  and  are constant. Thus, the consumed energy of the machine 
in active state is , that can be decomposed into 
\emph{dynamic energy}  and 
\emph{static energy}  (where the integral is taken over  at which 
the machine is in active state). At any time , 
the scheduler has to decide the state of the machine and the speed if the machine is in active state 
in order to execute and complete all jobs. 
The objective is to minimize the total energy --- the consumed energy in active state plus the 
wake-up energy. 

\paragraph{Formulation.} In a mathematical program for the problem, we need to incorporate an information 
about the machine states and the transition cost from the sleep state to the active one.  
Here we make use of 
the properties of the Heaviside step function and the Dirac delta function to encode 
the machine states and the transition cost. Recall that the Heaviside step 
function  if  and  if . Then 
is the integral of the Dirac delta function  (i.e., ) and it holds that 
. Now let  be a function
indicating whether the machine is in active state at time , i.e.,  if 
the machine is active at  and  if it is in the sleep state. 
Assume that the machine initially is in the sleep state. Then
 equals twice the transition cost
of the machine (a transition from the active state to the sleep state costs 0 while 
in , it costs ).


Let  be variable representing the machine speed on job  at time .   
The problem could be formulated as the following (non-convex) program.
 
  
The first constraint ensures that every job  will be fully processed during .
Moreover, each time a job is executed, the machine has to be in the active state. 
Note that we do not relax the variable . The objective function consists of 
the energy cost during the active periods and the wake-up cost. 

\subsection{Speed Scaling without Wake-Up Cost}
The problem without wake-up cost () has been extensively studied. 
We reconsider the problem throughout our primal-dual approach. In case ,
the machine is put in active state whenever there is some pending job (thus the function
 is useless and could be removed from the formulation).  
In this case, the relaxation above becomes a convex program. Applying the framework and by the same
observation as in previous sections, we derive the following algorithm.

At the arrival of job , increase continuously  at  for 
and update simultaneously  until .

It turns out that the machine speed  of the algorithm equals 
where  is the remaining processing volume of jobs arriving at or before 
with deadline in . So the algorithm is indeed algorithm \textsc{Optimal Available} \cite{YaoDemers95:A-Scheduling-Model}
that is -competitive \cite{BansalKimbrel07:Speed-scaling}.
However, the primal-dual view of the algorithm gives more insight and that is useful 
in the general energy model (see Lemma~\ref{lem:general-energy}). 

\subsection{Speed Scaling with Wake-Up Cost}

\paragraph{The Algorithm.}
Define the \emph{critical} speed .
In the algorithm, the machine speed is always at least  if it executes some job.
 
Initially, set  and  equal 0 for every time  and jobs .
If a job is released then it is marked as \emph{active}. Intuitively, a job is active 
if its speed  has not been settled yet. 
Let  be the current moment. Consider currently active jobs in the earliest deadline 
first (EDF) order. Increase continuously  at  for 
and update simultaneously  until .
Now consider different states of the machine at the current time . We distinguish 
three different states: (1) in \emph{working state} the machine is active and 
is executing some jobs; (2) in \emph{idle state} the machine is active but 
its speed equals 0; and (3) in \emph{sleep state} the machine is inactive.   
\begin{description}
	\item[In working state.] If  then keep 
	process jobs with the earliest deadline by speed . 
	Mark all currently pending jobs as inactive.
	If , switch to the idle state.
\item[In idle state.] If  then switch to the working state. \\
	If . Mark all currently pending jobs as active. 
	Intuitively, we delay such jobs until some moment where the machine has to run
	at speed  in order to complete these jobs (assuming that there is no new job released).\\
	Otherwise, if the total duration of idle state from the last wake-up equals  then switch 
	to the sleep state.
\item[In sleep state.] If  then switch to the working state.
\end{description}

In the rest, we denote  as the machine speed at time 
by the algorithm. Moreover, let  be the speed of the algorithm
on job  at time . 


\paragraph{Analysis.} The Lagrangian dual is
 
where the minimum is taken over   feasible solutions of the primal and 
 is the following Lagrangian function 

where . 

By weak duality, the optimal value of the primal is always larger than the one of the 
corresponding Lagrangian dual. In the following, we bound the Lagrangian dual value
in function of the algorithm cost and derive the competitive 
ratio via the dual-fitting approach.


\paragraph{Dual variables} Let  be 
some constant to be chosen later. For jobs  such that 
 for every ,
define  such that  equals the marginal 
increase of the \emph{dynamic} energy due to the arrival of job . For jobs  such that 
 for some moment ,
define  such that  equals the marginal 
increase of the \emph{dynamic and static} energy due to the arrival of job .

\begin{lemma}		\label{lem:general-energy}
Let  be an arbitrary job. 
\begin{enumerate}
	\item If  for every  then
	 
	for every .
	\item Moreover, if 
	 for some  then .
\end{enumerate}
\end{lemma}
\begin{proof}
We prove the first claim.
For any time , speed  is non-decreasing as long as new jobs arrive. Hence,
it is sufficient to prove the claim assuming that no other job is released after . So
 is the machine speed after the arrival of . The marginal increase in the dynamic energy 
due to the arrival of  could be written as 

where  is taken over  such that .
The inequality is due to the convexity of  and the second equality follows by the algorithm. 
Moreover,  for any ; so the lemma 
follows. 

We are now showing the second claim. 
By the algorithm, the fact that  for some  means that
job  will be processed at speed  in some interval 
(assuming that no new job is released after ).  
The marginal increase in the energy is  while  could be expressed 
as . Therefore, .
\end{proof}


\begin{theorem}
The algorithm has competitive ratio at most .
\end{theorem}
\begin{proof}
Let  be the dynamic energy of the algorithm 
schedule, i.e., 
due to the definition of 's and . 
Moreover, let  be the static energy plus the wake-up energy of the algorithm, i.e.,
.
We will bound the Lagrangian dual objective. 

By Lemma~\ref{lem:general-energy} (second statement), 
for every job  such that  for some , 
. By the definition of the critical speed,
 for any . Therefore,

where in the sum is taken over jobs  such that 
 for some .  Therefore,

where in the second line, the sum is taken over jobs  such that 
 for all .
The first inequality follows (\ref{eq:general-energy}) and Lemma~\ref{lem:general-energy} (first statement).
The second inequality holds since  and . 
The third inequality is due to the first order derivative 
and  is the solution of equation .
In fact  maximizes function .

As the energy power function  where  and , 
. Therefore,

Choose , we have that


In the following, we claim that 

for any feasible solution  of the relaxation.

Consider the algorithm schedule. An \emph{end-time}  is a moment in the schedule such
that the machine switches from the idle state to the sleep state. 
Conventionally, the first end-time in the schedule is 0. 
Partition the time line into phases. A \emph{phase}  is a time interval such that 
are consecutive end-times. Observe that in a phase, the schedule
has transition cost  and there is always a new job released in a phase
(otherwise the machines would not switch to non-sleep state).
We will prove the claim on every phase. In the following, 
we are interested in phase  and whenever we mention , 
it refers to . 

By the algorithm, the static energy of the schedule during 
the idle time is , \linebreak i.e., . 
Let  be an arbitrary feasible of solution of the relaxation. 

If during , the machine following solution  makes a transition from
non-sleep state to sleep state or inversely then 
. Hence



If during , the machine following solution  makes no transition (from
non-sleep static to sleep state or inversely) then  during  in order to 
process jobs released in the phase. Therefore, 

where the second inequality follows the algorithm: as the machine switches to sleep state 
at time , it means that the total idle duration in  incurs a cost .

In conclusion, the dual 
whereas the primal is . Thus, 
the competitive ratio is at most .
\end{proof}


\section{Minimizing Energy plus Weighted Flow-Time in Speed Scaling with 
Power Down Model}		\label{sec:4S-energy+flow}

\paragraph{The problem.} 


We consider the problem of minimizing the total weighted flow-time
plus energy on a single in the general energy model. 
Again, the machine has a transition cost  from sleep state to active state.
The power energy consumption of the machine at time  in its active state is 

where  and  and  is the machine speed at time . 
Recall that the \emph{dynamic energy} is 
 and the \emph{static energy} is
 (where the integrals are taken during
active periods).
Jobs arrive over time, a job  is released at time , has weight  
and requires  units of processing volume if it is processed 
on machine . A job could be processed preemptively, i.e., a job could be interrupted and resumed later. 
The \emph{flow-time} of a job  is  where
 is the completion time of the job.
At any time, the scheduler has to determine the state and the speed of every machine (it it is active) 
and also a policy how to execute jobs.
The objective is to minimize the total weighted flow-time of all jobs plus the total 
energy (including the wake-up cost). 

\paragraph{Formulation.} Similar as the previous section, we 
make use of the properties of Heaviside step function and Dirac delta function to encode 
the machine states and the transition cost. Let  be a function
indicating whether the machine  is in active state at time , i.e.,  if 
the machine is active at  and  if it is in the sleep state. 
Assume that the machine initially is in the sleep state. Then
 equals twice the transition cost
of the machine.
Let  be the variable that represents 
the speed of job  at time . Let  be 
a variable representing the completion time of . 
The problem could be relaxed as the following (non-convex) program.

  
The first constraints ensure that every job  must 
be completed by time . 
In the objective function, the first and second terms represent
twice the consumed energy and the total weighted flow-time, respectively. 
Note that in the second term,  by the constraints. 
The last term stands for twice the transition cost. 





\paragraph{Preliminaries.}
We say that a job  is \emph{pending} at time  if it is not completed, i.e., . 
At time , denote  the \emph{remaining} processing volume of job .
The \emph{total weight} of pending jobs at time  
is denoted as . 
The \emph{density} of a job  is . 
Define the \emph{critical speed}  of the machine 
as . As , by 
the first order condition,  satisfies .


\subsection{The Algorithm.} 

We first describe the algorithm informally. In the speed scaling model, all previous algorithms 
explicitly or implicitly balance the weighted flow-time of jobs and the consumed energy to process such jobs. 
That could be done by setting the machine speed at any time  proportional to 
some function of the total weight of pending jobs (precisely, proportional to 
 where  is the total weight of pending jobs).
Our algorithm follows the same idea of balancing.
However, in the general energy model, the algorithm would not be competitive if 
the speed is always set proportionally to  since the static energy might be large
due to the long active periods of the machine. Hence, even if the total weight of 
pending jobs on the machine is small, in some situation the speed is maintained larger than 
. In fact, it will be set to be the critical 
speed , defined as . 


An issue while dealing with the general model is to determine when a machine is waken up.
Again, if the total weight of pending jobs is small and the machine is active,
then the static energy is large. Otherwise if pending jobs remain for long time then the 
weight flow-time is large. The algorithm also balances the costs by making a plan and 
switching the machine into active state at appropriate moments. 
If new job is released then the plan, together with its starting time, will be changed.  

\paragraph{Description of algorithm.}
At any time , the machine maintains the following policy
in different states: the \emph{working state} (the machine is active and currently processes
some job), the \emph{idle state} (the machine is active but currently processes no job) and 
the \emph{sleep state}.

\begin{description}
\item[In working state.] If 
		then the machine speed is set as .
		Otherwise, the speed is set as .
		At any time, the machine processes the highest  density job
		among the pending ones. 
\item[In idle state.]
		\begin{enumerate}
			\item If 
			then switch to the working state.
\item If 
			then make a plan to process the pending jobs with speed (exactly) 
			in non-increasing order of their  density. So the plan consists of a single 
			block (with no idle time) and the block length could be explicitly computed (given 
			the processing volumes of all jobs and speed ). Hence, the total energy consumed in the plan 
			could also be computed and it is independent of the starting time of the plan. 
		
			Choose the starting time of the plan in such a way that the total energy consumed 
			in the plan equals the total weighted flow-time of all jobs in the plan. 
			There always exists
			such starting time since if the plan begins immediately at , the energy is larger than  
			the weighted flow-time; 
			and inversely if the starting time is large enough, the latter dominates the former.  
		
			At the starting time of a plan, switch to the working state. (Note that the plan together with 
			its starting time could be changed due to the arrival of new jobs.)
\item Otherwise, if the total duration of idle state from the last wake-up equals
				 then switch to sleep state.
		\end{enumerate}
\item[In sleep state.] Use the same policy as
		the first two steps of the idle state.   
\end{description}
  
\subsection{Analysis} 
  
The Lagrangian dual of program (\ref{relaxation}) is  
where  is the corresponding Lagrangian function where the maximum is taken over 
dual variables. The purpose of the section is to choose appropriate dual variables
and prove that for any feasible solution  of the primal, the Lagragian dual
is bounded by a desired factor from the primal. 


\paragraph{Dual variables.} 
Denote the dual variables corresponding to the first constraints of (\ref{relaxation}) 
as 's. Set all dual variables (corresponding to the primal (\ref{relaxation})) 
except 's equal to 0.
The values of dual variables 's is defined as the follows. 

Fix a job . At the arrival of a job , 
rename pending jobs as 
in non-increasing order of their  densities, i.e., 
 
(note that  is the inverse of job 's density).
Denote  for .

Define  such that 

Note that .
If job  is processed with speed larger than  then
the first term stands for the weighted flow-time of  and
the second term represents an upper bound of the increase 
in the weighted flow-time of jobs with density smaller than . 
Observe that due to arrival of , the jobs with higher density than 
are completed earlier and the ones with smaller density than 
may have higher flow-time. 
Informally, the second sum in (\ref{eq:lambda}) captures 
the marginal change in the total weighted flow-time. 
The third term in (\ref{eq:lambda}) is introduced in order to cover energy consumed during the 
execution periods of job  if it is processed by speed . That term is necessary 
since during such periods the 
energy consumption and the weighted flow-time is not balanced. 


\paragraph{}
The Lagrangian function  with the chosen dual variables becomes
 



\paragraph{Notations.}
We denote  the machine speed at time  by the algorithm. 
So by the algorithm, if  then .
Let  and  be the total dynamic and static 
energy consumed by the algorithm schedule, respectively. 
In other words, 
and  where the integral is taken over all moments 
 where the machine is active (either in working or in idle states).
Additionally, let  be the total transition cost of the machine.
Moreover, let  be the total weighted flow-time of all jobs 
in the schedule. 

We relate the cost of the schedule (due to the algorithm) and the chosen values of dual variables by the 
following lemma. Note that by definition of 's, we have that 
.

\begin{lemma}		\label{lem:general-energy-lambda}
It holds that

and
.
\end{lemma}
\begin{proof}
We prove the first inequality.
Consider times  where the machine speed is .   
By the algorithm .
Recall that by the definition of critical speed ,
so . Therefore,
. Hence,


Now consider times  where the machine speed is 
strictly larger than . Thus
the dynamic energy consumed on such periods is


For periods where  while some jobs are still pending
on the machine, by the algorithm plan, the total weighted flow time of jobs in such periods 
is bounded by 
Therefore,



In the rest, we prove the second inequality .
By the definition of 's (particularly the third term in (\ref{eq:lambda})),
 covers the total energy of machine during all intervals where 
the machine processes jobs by speed . Denote  as 
 subtracting the energy incurred during periods where the machine 
speed is . We need to prove that   is enough to cover the total energy 
incurred over all moments where the machine speed is strictly larger than .  
In the following, we are interested only in such moments.

Consider a job  processed at time  with speed larger than . 
By the definition of 's, 
 contributes to time  an amount at least  where
the sum is taken over pending jobs  with smaller density than that of .
The latter is exactly . Thus,  contributes to time 
an amount .

Now consider an arbitrarily small interval  where the machine processes only job 
and the speed is strictly larger than .
Let  be the total weight of pending jobs over .  The processing 
amount of  done over  is  while the 
energy amount consumed in that interval is . Hence, 
in average the machine spends  
(dynamic) energy unit at time .     

Therefore, during periods where the machine speed is larger than ,
 is increase at rate proportionally to the one of the dynamic energy.
The second inequality of the lemma follows.
\end{proof}

\begin{corollary}		\label{cor:general-energy-lambda}
It holds that
.
\end{corollary}
\begin{proof}
By the previous lemma, we deduce that

\end{proof}

In the following, we show the main technical lemma.

\begin{lemma}		\label{lem:energy-general-main}
Let  be an arbitrary job.  
Then, for every 

\end{lemma} 
\begin{proof}
Fix a job . 
We prove by induction on the number of released jobs
after . The base case follows Lemma \ref{lem:base}
and the induction step is done by Lemma \ref{lem:induction}. 
\end{proof}

\begin{lemma}		\label{lem:base}
If no new job is released after  then inequality (\ref{eq:energy-general-main}) holds.
\end{lemma}
\begin{proof}
Denote the instance as .
At , rename jobs in non-increasing order of their densities, i.e., 
 (note that  is the inverse of job 's density).
Denote  for .

By definition of ,


Let  be the completion time of job  for every . Moreover,
let  be the largest job index such that 
.
In other words, job  is processed by speed strictly larger than  and the other jobs
with larger index (if exist) will be processed by speed .
Fix a time , let  be the pending job at  with the smallest index.
We prove first the following claim.

\begin{claim}
It holds that

\end{claim}
\begin{claimproof}
We consider different cases.
\paragraph{Case 1: .} In this case, job  will be processed by speed .
	\begin{description}
		\item[Subcase 1.1: .]
		During interval , the machine has completed jobs  and has processed a part of job .
		Precisely, during  the machine has processed  units of job 
		for every job  and has executed  units of job .   
		Moreover, every job  is processed with speed .  
		Therefore,  

The first inequality is because  for every job .
		The first equality is due to the definition of the density.
		The second inequality follows since  for every job 
		and .
		The third inequality holds since function  is decreasing. 


		\item[Subcase 1.2: .]
		In this case , i.e., during  the machine  has completed 
		jobs . Similarly as the previous subcase, we have 

where the last inequality follows the definition of .
\end{description}

\paragraph{Case 2: .} In this case, job  will be processed with speed strictly larger than .
	\begin{description}
		\item[Subcase 2.1: .] The proof is done in the same manner as in Subcase 1.1.
\item[Subcase 2.2: .] 
		For simplicity, denote .
		Partition time after  as .  
		During an interval , the weight  is unchanged so 
		to show inequality (\ref{eq:energy-general-main}), it is sufficient to prove 
		at . 
		
		We prove again by induction. For the base case , the claim inequality holds
		by the previous case. Assume that the inequality holds at , we will prove that 
		it holds at  for . We are interested only in .
		Let . Informally,  is the fractional
		weight of pending jobs at time . 
		
		During period  assume that the total fractional weight of pending jobs 
		varies by . During the same period ,
		the total processing volume done by algorithm is at least
		 since the speed is either  or 
		 but in the latter, by the algorithm, .
		Moreover, jobs  processed during  have density at most .
		Therefore, . In other words,
		. Taking integral, we get   
		
		Therefore, 
		
		where the first inequality is due to the induction hypothesis and inequality (\ref{eq:weight-a}).	



\end{description}
Combining all the cases, the claim holds.
\end{claimproof}

Using the claim, the lemma follows immediately as shown below.

where the inequality holds since function  is decreasing. (Recall that  is the pending job 
at time  with the smallest index.)
\end{proof}

\begin{lemma}		\label{lem:induction}
Assume that inequality (\ref{eq:energy-general-main}) holds if 
there are  jobs released after . Then the inequality also holds
if  jobs are released after .
\end{lemma}
\begin{proof}
Denote the instance as .
Among such jobs, let  be the last released one (at time ).
By induction hypothesis, it remains to prove the lemma inequality for .

We first show the claim that inequality (\ref{eq:energy-general-main}) holds for any time 
 by a similar argument as in Subcase 2.2 of the previous claim. 
Indeed, we prove the claim by fixing the 
processing volume of job  and varying its weight . Note that 
 depends on  and when  is varied, 
 is also varied. However, with a fixed value of 
,  is fixed and 
we are interested only in . If  then 
the claim follows the induction hypothesis (the instance becomes the one 
with  jobs).  Assume that the claim holds for some value .
Now increase an arbitrarily small amount of  and 
consider a time  (corresponding to the current value of ).
Due to that increase, during period  the total fractional weight of pending jobs 
varies by . During the same period ,
the total processing volume done by algorithm is at least
 since the machine speed is at least .
Moreover, jobs processed during  have density at most .
Therefore, .    
So 

This inequality means that in the lemma inequality (\ref{eq:energy-general-main}), 
the decrease in the left-hand side 
is larger than that in the right-hand side while varying the weight of job . 
Hence, the inequality holds for .



Now we consider instance  with fixed parameters for job .
We will prove the lemma for .
Denote . Again, rename jobs 
in non-increasing order of their  densities at time .
(After , no new job is released and the relative order of jobs is unchanged.)
Let  be the total weight of pending jobs at 
which have  density smaller than . 
Recall that the total weight of pending jobs at time  is .

Let  be the pending job with the smallest index at time  
in the instance . 
During , the machine processes (a part) of job , jobs .
The jobs have density at least .
We deduce

The first inequality follows the previous claim, stating that inequality (\ref{eq:energy-general-main}) 
holds for . The second inequality follows the fact that at any time the speed 
of the machine is at least . The third inequality
holds since 
and function  is decreasing.
The last inequality holds since  and .
\end{proof}



\begin{theorem}
The algorithm has competive ratio at most .
\end{theorem}
\begin{proof}
Recall that the dual has value at least  where the minimum is taken 
over  feasible solution of the primal. The goal is to bound 
the Lagrangian function. 

 Define  as 


\begin{claim}		\label{claim:general-energy-L1}
Let  be an arbitrary feasible solution of the primal. Then,

\end{claim}



\begin{claim}		\label{claim:general-energy-L2}
Let  be an arbitrary feasible solution of the primal. 
Define

Then, .
\end{claim}


We first show how to prove the theorem assuming the claims.
By (\ref{eq:lagrangian}), we have

where the first and second inequalities are due to Claim~\ref{claim:general-energy-L1} and
Claim~\ref{claim:general-energy-L2}, respectively. The third inequality follows
Corollary~\ref{cor:general-energy-lambda} and . 
The last inequality is due to the fact that

for every .

Besides, the primal objective is at most
. 
Hence, the competitive ratio is at most .


In the rest, we prove the claims.

\setcounter{claim}{1}
\begin{claim}		\label{claim:general-energy-L1}
Let  be an arbitrary feasible solution of the primal. Then,

\end{claim}
\begin{claimproof}
We have

where the inequality holds because the integral for each job  is taken over . 

Let  be the set of time  such that 
.
Then by Lemma~\ref{lem:energy-general-main}, for any 

Therefore,

since . Hence, 

The first inequality is due to (\ref{eq:L1-null}) and note that if  then the contribution of the term 
inside the integral is 0. The second inequality follows Lemma~\ref{lem:energy-general-main} and 
recall that  . 
The equality is because 
for  such that  (meaning ).
The third inequality is due to the first order derivative and  is the solution of  
. 
The fourth inequality holds since the term inside the integral is non-negative
and .


Replacing 
(solution of ), 
we get:

\end{claimproof}

\begin{claim}		\label{claim:general-energy-L2}
Let  be an arbitrary feasible solution of the primal. 
Define

Then, .
\end{claim}
\begin{claimproof}
Consider the algorithm schedule. An \emph{end-time}  is a moment in the algorithm schedule such
that the machine switches from the idle state to the sleep state. 
Conventionally, the first end-time in the schedule is 0. 
Partition the time line into phases. A \emph{phase}  is a time interval such that 
are consecutive end-times. Observe that in a phase, the schedule
has transition cost  and some new job is released in a phase
(otherwise the machine would not switch to non-sleep state).
We will prove the claim on every phase. In the following, 
we are only interested in phase  and define 



By the algorithm, the static energy on machine  during 
its idle time is , i.e., . 
If during , the schedule induced by solution  makes a transition from
non-sleep state to sleep state or inversely then 
. Hence



If during , the schedule induced by solution  makes no transition (from
non-sleep static to sleep state or inversely) then either  or  for every 
. Note that by definition of phases, some job is released during .

\paragraph{Case 1: .} 
Hence,

where the second inequality follows since the total idle duration in  incurs a cost 
(so the machine switches to sleep state at time ).

\paragraph{Case 2: .}  As the machine is in the sleep state 
during  in solution , all jobs 
released in  are completed later than . 
By the algorithm, the total weighted flow-time of such jobs is at least the static energy of the algorithm
during . In other words,

where the third inequality is again due to the fact that 
the total idle duration in  incurs a static energy . 
\end{claimproof}

The above proofs of the claims complete the theorem proof.
\end{proof}


\bibliographystyle{plainnat}
\bibliography{scheduling}
\newpage

\appendix

\section*{Appendix}

\setcounter{lemma}{-1}
\begin{lemma}[Weak duality]
Consider a possibly non-convex optimization problem

where  for .
Let  be the feasible set of . 
Let  be the Lagragian function

Define 
where  means . 
Then .
\end{lemma}
\begin{proof}
We observe that, for every feasible , and every ,
 is bounded below by :


Define a function  such that

As  is defined as a point-wise minimum, it is a concave function.  

We have, for any  and , . Combining with 
the previous inequality, we get 

Taking the minimum over , we obtain

Therefore,

\end{proof}

\end{document}