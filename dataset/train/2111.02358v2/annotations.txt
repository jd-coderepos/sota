[{'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-dev', 'Metric': 'Accuracy', 'Score': '82.78'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-std', 'Metric': 'overall', 'Score': '81.30'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-std', 'Metric': 'yes/no', 'Score': '94.68'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-std', 'Metric': 'number', 'Score': '67.26'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'VQA v2 test-std', 'Metric': 'other', 'Score': '72.87'}}, {'LEADERBOARD': {'Task': 'Visual Reasoning', 'Dataset': 'NLVR2 Test', 'Metric': 'Accuracy', 'Score': '86.86'}}, {'LEADERBOARD': {'Task': 'Visual Reasoning', 'Dataset': 'NLVR2 Dev', 'Metric': 'Accuracy', 'Score': '85.64'}}, {'LEADERBOARD': {'Task': 'Image Retrieval', 'Dataset': 'PhotoChat', 'Metric': 'R1', 'Score': '11.5'}}, {'LEADERBOARD': {'Task': 'Image Retrieval', 'Dataset': 'PhotoChat', 'Metric': 'R@5', 'Score': '30.0'}}, {'LEADERBOARD': {'Task': 'Image Retrieval', 'Dataset': 'PhotoChat', 'Metric': 'R@10', 'Score': '39.4'}}, {'LEADERBOARD': {'Task': 'Image Retrieval', 'Dataset': 'PhotoChat', 'Metric': 'Sum(R@1,5,10)', 'Score': '83.2'}}]
