\documentclass[a4paper]{article}

\usepackage{INTERSPEECH2022}

\usepackage{xcolor,soul,framed} \usepackage{amsmath,bm}
\usepackage{url}            

\title{Perceptual Contrast Stretching on Target Feature for Speech Enhancement}
\name{Rong Chao, Cheng Yu, Szu-Wei Fu, Xugang Lu, Yu Tsao}
\address{
CSIE, NCKU, Taiwan \
CITI, Academia Sinica, Taiwan \
  Microsoft Corporation \
  NICT, Japan
  }
\email{f14071075@gs.ncku.edu.tw, yu.tsao@citi.sinica.edu.tw}

\setlength{\textfloatsep}{8pt}

\begin{document}

\maketitle


\begin{abstract}

Speech enhancement (SE) performance has improved considerably owing to the use of deep learning models as a base function. Herein, we propose a perceptual contrast stretching (PCS) approach to further improve SE performance. The PCS is derived based on the critical band importance function and is applied to modify the targets of the SE model. Specifically, the contrast of target features is stretched based on perceptual importance, thereby improving the overall SE performance. Compared with post-processing-based implementations, incorporating PCS into the training phase preserves performance and reduces online computation. Notably, PCS can be combined with different SE model architectures and training criteria. Furthermore, PCS does not affect the causality or convergence of SE model training. Experimental results on the VoiceBank-DEMAND dataset show that the proposed method can achieve state-of-the-art performance on both causal (PESQ score = 3.07) and noncausal (PESQ score = 3.35) SE tasks.


\end{abstract}
\noindent\textbf{Index Terms}: Speech enhancement, contrast stretching, perceptual importance

\section{Introduction}

Speech enhancement (SE) is performed to remove noise components from noisy speech to improve speech quality and intelligibility. SE has been used at an important front-end of many speech-related studies, such as automatic speech recognition \cite{weninger2015speech, zhang2017speech}, speaker recognition \cite{michelsanti2017conditional, taherian2020robust}, and assistive listening devices \cite{wang2017deep, lesica2021harnessing}. Traditionally, SE algorithms are typically designed based on the assumptions of speech and noise signals. Notable approaches include those presented in \cite{boll1979suppression} and \cite{priori1}. These approaches are effective in some stationary noise scenarios, wherein the signals conform to the assumptions introduced. However, in most real-world noisy scenarios, time-varying noise exhibits nonstationary properties, resulting in the suboptimal performance of these conventional SE methods. 


In recent years, deep learning (DL) has been widely used in various research fields, including SE.
Using DL models as a base mapping function has notably improved SE \cite{lu2013speech, xu2014regression,  liu2014experiments, han2015learning}. Although these DL-based methods achieve satisfactory performance under the testing conditions associated with the training data, their performance degrades when they are operated under unexpected conditions, attributed to two factors: first, the network architecture may not adequately consider the sequential nature of the speech signals; second, a regression function optimized by L1/L2 distance-based objective functions may average out important signal patterns, which can result in low precision of enhanced speech.


Numerous approaches have been proposed to further improve DL-based SE systems, including those that aims to determine suitable acoustic features to improve SE, such as waveforms \cite{fu2018end} and complex spectral features \cite{williamson2015complex}. Additionally, advanced networks have been proposed to model sequential signals more accurately, such as recurrent neural networks \cite{huang2015joint}, fully convolutional networks \cite{fu2018end}, long-short term memory \cite{LSTM2}, transformers \cite{kim2020t}, and generative adversarial networks \cite{pascual2017segan, fu2019metricgan}. In another approach, advanced objective functions are derived to provide more accurate training to achieve the desired speech quality or intelligibility. Notable examples include differentiable speech metrics \cite{fu2019metricgan, fu2018end}, and deep feature losses \cite{germain2019speech, hsieh2020improving}, where losses are computed in representative or discriminative feature spaces. Aside from the above-mentioned approaches, this study investigates another direction to improve the SE performance: modifying the target features of the SE model and post-processing (PP).

PP has been derived to further modify enhanced speech to match the statistical properties of clean speech \cite{xu2014regression, valin2020perceptually, chen2020truth}. Experimental results show that such an approach can further sharpen the structure of enhanced speech and suppress residual noise. Moreover, PP is compatible with any system for further improving SE. Accordingly, we propose perceptual contrast stretching (PCS)—a novel method to enhance the contrasts of the target features of an SE model. PCS can be implemented as PP for SE or incorporated into the SE training phase, where the implementation of the latter can avoid an increase computation cost during inference.





Gamma-correction approaches have proven to be effective for image enhancement \cite{rahman2016adaptive}. Based on these approaches, the characteristics of the human auditory system are employed in PCS. In this study, we first examined the effectiveness of PCS by incorporating it into the SE training phase. Next, we implemented it as a PP, and notable improvements were achieved. Specifically, PCS stretches the contrasts of the target features in the training data based on a set of auditory weights. The weights are designed based on the critical band importance \cite{pavlovic2018sii}, which is perceptually correlated with the human auditory system. The proposed PCS offers three major advantages: First, it is compatible with different SE systems (conventional or DL based). Second, it does not require additional parameters in the SE model. Third, it does not affect the causal property of the causal SE models.
\begin{figure*}
 \centering
 \includegraphics[width=\linewidth]{gamma.pdf}
 \caption{Normalized time-frequency feature (spectral magnitude) is stretched by different gamma values. The original clean feature ( = 1) is shown in (c); stretching based on different  values is shown in (a) to (e); (f) shows the proposed PCS.} 
 \label{fig:gammagraph}
\end{figure*}
We compared PCS with several different contrast-stretching strategies in our experiments. The evaluation scores show that PCS outperformed the other feature enhancement approaches. State-of-the-art (SOTA) results (PESQ score = 3.35) were achieved when the best SE model was used.




\section{Related Studies}
In this section, we introduce two primary categories of related studies. Our proposed PCS training strategy for SE was designed based on these previous studies. 

\subsection{Gamma correction}
\label{ssec:gammacorrection}

The proposed PCS was partially inspired by image processing. First, we introduce gamma correction \cite{poynton2012digital}, widely adopted as a contrast-enhancement approach in computer vision research. Based on human vision systems, the brightness perception of the eye from graphical information is affected by the brightest region of the image. Specifically, the relationship between perceived and physical brightness can be derived as a nonlinear transfer function. The gamma correction was designed based on this function and can be derived as a power-law operation, expressed as follows:




where  is the input signal value,  the modulation parameter,  the scaling function (typically a constant), and  the output signal value. For example, the standard red-green-blue (sRGB), widely used in monitors and printers, uses a gamma value of 2.2 () in its transfer function to provide better perception. Another color space, i.e., the Digital Cinema Initiatives - Protocol 3 (DCI-P3), uses a gamma value of 2.6 (). In these operations, the input signals are normalized to a range between 0 and 1 to ensure that the boundary values and the minimal and maximal values of the input signal remain invariant after the operation. In recent SE research, Zhang et al. \cite{zhang2021low} applied a weighting mechanism to the training target, similar to gamma correction using a dynamic scaling function (i.e., based on the ratio of input and target features).  





\subsection{Critical band importance}
\label{ssec:criticalband}
In human auditory systems, the importance of the signal components varies based on the frequency region. More specifically, humans can perceive differences in frequency bands ranging from 400 to 4400 Hz better than in other frequency bands. Consequently, a set of critical band importance weights was measured and defined. Some conventional SE approaches adopted critical bands to perform spectral subtraction \cite{singh1998speech}, whereas some DL-based SE approaches adopted critical band importance to improve their model \cite{liu2018bone}. These approaches demonstrate improvements in perceptual evaluation scores compared with the baseline approaches. In this study, we demonstrate that SE can be further improved to achieve SOTA performance by combining gamma correction with critical band importance.

\section{PCS on target feature for speech enhancement}
In this section, the derivation of the proposed PCS on the target feature for SE based on two related studies is presented.

\subsection{Auditory nonlinearity}
Similar to the human vision system, the human auditory system exhibits a nonlinear relationship with speech signals. The sound pressure level (SPL) is measured in decibels (dB) as follows:



This equation standardizes the relationship between physical loudness and perceived loudness. The notations , , and  denote the dB level, measured signal power, and reference signal power, respectively. The SPL of the human auditory and visual systems
exhibits a similar property because the human eye perceives brightness based on reference to the brightest region of an image, as mentioned in \ref{ssec:gammacorrection}. Thus, we designed a transfer function suitable for the human auditory systems.


\begin{figure}[h]
 \centering
 \includegraphics[width=\linewidth]{gammascale.pdf}
 \caption{Scaling curves of our modified gamma correction using different gamma values, where  and  represent input and output, respectively.}  
 \label{fig:gammascale}
\end{figure}

\begin{figure*}[t]
 \centering
 \includegraphics[width=\linewidth]{system.pdf}
 \caption{High-level system block diagram of proposed perceptual contrast stretching training strategy for SE, where the brown block C.S. represent contrast-stretching step.} 
 \label{fig:system}
 \vspace{-0.3cm}
\end{figure*}

\subsection{Modified gamma correction}
We begin by implementing gamma correction on time-frequency features (spectrogram) of speech signals to enhance the contrast.
Based on Eq. \ref{equation:gamma}, the range of input features must be suitable for our task. In Eq. \ref{equation:gamma}, the range of  is regulated between . However, the range of speech features cannot be regulated within this range. Hence, a new regulation is required, wherein the input values range between  (here,  represents the maximum value of the input features). The processed signal was normalized when it was recovered in the waveform domain. Subsequently, the gamma correction equation for the time-frequency feature of speech signals was modified as follows:

where the value of input feature  ranges from . The notations , , , and  denote the modified feature, scaling function, gamma value, and input feature, respectively.




Furthermore, the training features of our SE models were moved to the  domain ( features) \cite{fu2020boosting}. We can thus derive Eq. \ref{equation:tfgamma} as follows:

where the scaling function  is  in this case, which is dynamic and based on . As shown in Fig \ref{fig:gammascale}, the modified gamma correction attenuates the features (decreases the contrast) when , and increases the value of the features (enhances the contrast) when . This effect is similarly observed on the speech spectrogram shown in Fig. \ref{fig:gammagraph}, where (a) and (b) contain more blurry patterns, whereas (d) and (e) contain more contrastive patterns. This also suggests that feature enhancement can be implemented using different  values to serve specific purposes. 

\subsection{PCS}
Contrast-stretching was applied to perceptually enhance the target features on the training data. The waveform was first processed via short-time Fourier transform (STFT), wherein the phase component was excluded from the input stream for inverse STFT (iSTFT) (see Fig. \ref{fig:system}). Subsequently, we applied contrast stretching to the target stream feature for the enhanced feature . The  feature was then obtained using the feature (here,  and  denote the target and input streams, respectively). Consequently, the loss  can be computed as:

where  denotes the objective functions, and  denotes the transformation by the SE. To determine the best performance afforded using a fixed , we tested several different hyperparameters (–, with a step size of ) in our validation set and evaluated their effectiveness. Experimental results on the VoiceBank-DEMAND dataset show that the best perceptual scores were achieved using . Hence, we adopted  as the fundamental  value. 
\begin{table}[h]
\centering
\caption{Critical band importance and proposed PCS.}
\label{tab:table_PCS}
\begin{tabular}[\linewidth]{|c|c|c|}
\hline
Frequency bands (Hz) & BIF & \boldsymbol{} \\
\hline 
0100           & 0.000 & 1.0000  \\
100200         & 0.010 & 1.0702  \\
200300         & 0.026 & 1.1825  \\
300400         & 0.041 & 1.2877   \\
4004400        & 0.057 & 1.4    \\
44005300       & 0.046 & 1.3228   \\
53006400       & 0.034 & 1.2386   \\
64007700       & 0.023 & 1.1614   \\
77009500       & 0.011 & 1.0772  \\
\hline
\end{tabular}
\end{table}

We reviewed Cochlea's knowledge in Sec. \ref{ssec:criticalband}, its applications, and its importance in perceptual scores when applied to SE tasks. To further improve our contrast stretching for better perceptual performance, we designed feature enhancement based on the critical band importance. As most SE approaches adopt time–frequency features, we designed a feature enhancement that weights the features based on their frequencies. The band importance function (BIF) \cite{ansi1997s3} is listed in Table \ref{tab:table_PCS}. We designed the PCS based on the BIF and rescaled it into the range [1.0, 1.4]. The rescaling function is formulated as follows:

where  denotes the index of the frequency bands,  and  are the  values of PCS and BIF at band , respectively.  and  denote the maximum and minimum values of , respectively. Meanwhile,  was set to , and  was adopted. As shown in Fig. \ref{fig:gammagraph}(f), the proposed PCS\footnote{The actual frequency band regions we used to implement PCS are slightly different from Table \ref{tab:table_PCS} owing to the STFT limitations. Detailed settings can be fount at \url{https://github.com/RoyChao19477/PCS/PCS}.} is effective. We can sharpen the formant peaks by applying PCS, where Fig. \ref{fig:gammagraph}(f) is more contrastive compared with those presented in Figs. \ref{fig:gammagraph}(a) and \ref{fig:gammagraph}(b), but does not indicate severe distortions as in Figs. \ref{fig:gammagraph}(d) and \ref{fig:gammagraph}(e).


\section{Experiments}
\label{sec:exp}


\subsection{Experimental setup}
\label{ssec:network}

We evaluated our method using well-known network architectures, including the transformer \cite{fu2020boosting}, CRNN \cite{zhao2018convolutional}, MetricGAN+ \cite{fu2021metricgan+} (from SpeechBrain \cite{ravanelli2021speechbrain}), and DPT-FSNet \cite{dang2021dpt}. The transformer contains four convolutional encoder layers, eight self-attention heads, and a fully connected decoder layer. The CRNN comprises CNN layers, with one bidirectional long short-term memory (BLSTM) layer and two fully connected layers. The MetricGAN+ comprises a BLSTM-based generator with two bidirectional LSTM layers and a CNN-based discriminator. The dual-path transformer-based full-band and sub-band fusion network (DPT-FSNet) is a dual-path architecture that uses an improved transformer.


To compare the proposed PCS with other methods, we used a publicly available dataset, VoiceBank-DEMAND, to evaluate the SE. The Voice Bank-DEMAND dataset is widely used as a benchmark for monaural SE approaches. The training set with 11572 utterances comprises 28 speakers corrupted with four signal-to-noise ratio (SNR) levels (15, 10, 5, and 0 dB). The test sets set with 824 utterances comprises two speakers corrupted at four SNR levels (17.5, 12.5, 7.5, and 2.5 dB). Details regarding this dataset are available in \cite{valentini2017noisy}. 

\subsection {Comparison of different feature enhancement methods}
\label{ssec:comparison}

As contrast-stretching for image processing can be considered a feature enhancement method for SE, we compared our proposed PCS with a fixed gamma of 1.4 with three typically used contrast enhancement methods—min-max normalization, histogram equalization (HE) \cite{pizer1987adaptive}, and adaptive equalization (AE) \cite{qureshi1985adaptive}. These methods were adopted in the spectrum domain as contrast-stretching methods. HE was implemented along the time axis of each frequency band. A causal transformer SE model was used to evaluate the effectiveness of these methods. 
Feature enhancement was applied to the spectral domain and then transferred to the log1p features space in these experiments.



\begin{table}
\caption{SE models with different feature enhancement methods on VoiceBank-DEMAND.}
\vspace{-0.2cm}
\label{table_1}
\centering
\begin{tabular*}{\linewidth}{l||lllll} 
\hline
                  & PESQ  & STOI  & CSIG  & COVL  \\ 
\hline
Noisy             & 1.97 & 0.92 & 3.34 & 2.63 \\
\hline
Wiener \cite{pascual2017segan} & 2.22 & - & 3.23 & 2.67 \\
Conv-TasNet \cite{koyama2020exploring} & 2.53 & - & 3.95 & 3.23 \\ 
Demucs \cite{defossez2020real} & 2.93  & \textbf{0.95}   & 4.22  & 3.52 \\
T \cite{fu2020boosting} & 2.76 & 0.94 & 4.10 & 3.44 \\
T + min-max       & 2.80 & 0.93 & 4.09 & 3.45 \\
T + HE  & 2.20 & 0.93 & 3.04 & 2.60 & \\
T + AE            & 2.82 & 0.94 & 4.12 & 3.48 \\
\hline
\hline
\textbf{T + =1.4}   & 2.90 & 0.94 & 4.18 & 3.55 \\
\textbf{T + \boldsymbol{}=PCS} & \textbf{3.07} & 0.94 & \textbf{4.26} & \textbf{3.67} \\
\hline
\end{tabular*}
\end{table}
Table \ref{table_1} shows that the causal transformer (T) can be improved notably via PCS method, with a 0.31 PESQ score improvement. Moreover, except for HE, which failed to converge in training, the enhancement results are beneficial when feature enhancement approaches are used. To evaluate the effectiveness of the causal transformer with PCS, we tested performance of several causal models (e.g., causal DEMUCS \cite{defossez2020real} and Conv-TasNet (scores from \cite{koyama2020exploring})).
To the best of our knowledge, the proposed method outperformed other causal SE methods on this dataset in terms of the PESQ, CSIG, and COVL scores.


\begin{table}[h]
\caption{Different models with PCS on VoiceBank-DEMAND.}
\label{table_2}
\centering
\begin{tabular}{l||lllll} 
\hline
                              & PESQ           & STOI  & CSIG    &  COVL  & Cau.  \\
\hline
Noisy             & 1.97 & 0.92 & 3.34 & 2.63 & - \\
\hline
SEGAN \cite{pascual2017segan} & 2.16 & - & 3.48 & 2.80 & No \\
T (c) \cite{fu2020boosting} & 2.76          & 0.94 & 4.10 & 3.44 & Yes     \\
T (c) \textbf{+ PCS}    & \textbf{3.07} & 0.94 & \textbf{4.26} & \textbf{3.67} & \textbf{Yes}     \\
T (nc) \cite{fu2020boosting} & 2.84          & 0.94 & 4.20 & 3.51 & No      \\
T (nc) \textbf{+ PCS}    & \textbf{3.15} & 0.94 & \textbf{4.34} & \textbf{3.75} & No      \\
CRNN \cite{zhao2018convolutional} & 2.83          & 0.94 & 4.18 & 3.51 & No      \\
CRNN \textbf{+ PCS}     & \textbf{3.11} & 0.94 & \textbf{4.31} & \textbf{3.72} & No      \\
MGAN+ \cite{fu2021metricgan+}    & 3.15 & 0.93 & 4.14  & 3.64  & No      \\ 
MGAN+ \textbf{+ PCS}    & \textbf{3.21} & 0.93 & \textbf{4.15} & \textbf{3.67} & No      \\
DPT \cite{dang2021dpt}  & 3.33 & 0.96 & \textbf{4.58} & \textbf{4.00} & No      \\
DPT*                    & {3.11} & 0.95 & 4.30 & 3.72 & No      \\
DPT* \textbf{+ PCS}     & \textbf{3.35} & 0.95 & \textbf{4.43} & \textbf{3.92} & No      \\
\hline
\end{tabular}
\end{table}


\subsection {Effectiveness using different SE models}

Table \ref{table_2} shows that the performance of different SE models, including the causal transformer (T(c)), non-causal transformer (T(nc)), CRNN, MetricGAN+ (MGAN+), and DPT-FSNet\footnote{The contrast-stretched target features are transferred back to the waveform domain as training targets.} (We used a frame size of 64 and a single batch size in all DPT-FSNet reproduction experiments and denote it as DPT*), can be improved by applying PCS. To the best of our knowledge, The DPT* + PCS achieved SOTA performance with a PESQ score of 3.35 and outstanding scores for other evaluation metrics. 
In general, we can infer from the improvements presented in Table \ref{table_2} that PCS is a general and effective contrast stretching training strategy for DL-based SE approaches.

\subsection {Effectiveness of PP}
PCS can be implemented as a PP module, aiming to further improve enhanced speech from an SE model. The results are presented in Table \ref{table_3}. Note that for some CS methods (e.g., HE), information from the entire spectrogram is required, causing the SE system noncausal. The operation of PCS is similar to gamma correction; therefore the causality of the SE model will not be changed when PCS is applied as PP. From Table \ref{table_3}, using PCS as a PP module can also improve the SE performance effectively. 
When comparing the results of Tables. \ref{table_2} and \ref{table_3}, using PCS as a PP and applying PCS to the target feature enhancement yield comparable improvements. Especially, implementing PCS as a PP module allows it to be used alone (Noisy\textbf{+PP-PCS}) and combined with conventional SE methods (e.g., Wiener\textbf{+PP-PCS}); the detailed results and codes can be found at \url{https://github.com/RoyChao19477/PCS}.




\begin{table}[h]
\caption{PP-PCS with different SE models on the VoiceBank-Demand dataset. "Noisy" denotes original speech without SE.}
\label{table_3}
\centering
\begin{tabular}{l||llllll} 
\hline
& PESQ & STOI & CSIG & COVL    \\
\hline
Noisy             & 1.97 & 0.92 & 3.34 & 2.63    \\
Noisy \textbf{+ PP-PCS} & \textbf{2.47} & 0.92 & \textbf{3.63}  & \textbf{3.03}  \\
Wiener             & 2.22 & 0.91 & 3.21  & 2.65        \\
Wiener\textbf{+ PP-PCS}      & \textbf{2.63} & 0.91 & \textbf{3.39}  & \textbf{2.95}        \\
MGAN+ \textbf{+ PP-PCS}    & 3.20 & 0.92 & 4.08 & 3.63    \\
DPT* \textbf{+ PP-PCS}     & \textbf{3.30} & \textbf{0.95} & \textbf{4.35} & \textbf{3.84}    \\
\hline
\end{tabular}
\end{table}

\section{Conclusions}
\label{sec:conclusion}
We proposed a PCS for target features to further boost SE performance. PCS exerts a perceptual emphasis on target features to overcome the average-out problem (not precise) caused by distance-based objective functions. Three major contributions of the proposed PCS are noted: First, PCS is compatible with different SE models (both conventional and DL based). Second, no additional parameters are required in the SE model. Third, it does not affect the causality of causal SE models. We conclude that the proposed PCS can further improve the performance of previous SOTA SE models with an efficient operation of the target features. 
To the best of our knowledge, the causal transformer + PCS (causal) and DPT* + PCS (noncausal) approaches achieved the best PESQ score and competitive scores in other metrics on the Voice Bank-DEMAND dataset.








\newpage



\bibliographystyle{IEEEtran}

\bibliography{mybib}

\end{document}