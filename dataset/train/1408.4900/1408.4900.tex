\documentclass{llncs}
\usepackage{llncsdoc}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{comment}
\usepackage{verbatim}
\usepackage{amssymb}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\begin{document}

\frenchspacing


\title{\Large Speeding up Graph Algorithms\\ via Switching Classes}
\institute{Colorado State University, Fort Collins CO 80521, USA}
\author{Nathan Lindzey~\thanks{lindzey@math.colostate.edu,
Mathematics Department,
Colorado State University,
Fort Collins, CO, 80523-1873
U.S.A.}
}
\date{}
\maketitle


\begin{abstract} \small\baselineskip=9pt 
Given a graph , a \emph{vertex switch} of  results in a new graph where neighbors of  become nonneighbors and vice versa.  This operation gives rise to an equivalence relation over the set of labeled digraphs on  vertices.  The equivalence class of  with respect to the switching operation is commonly referred to as 's \emph{switching class}. The algebraic and combinatorial properties of switching classes have been studied in depth; however, they have not been studied as thoroughly from an algorithmic point of view.  The intent of this work is to further investigate the algorithmic properties of switching classes. In particular, we show that switching classes can be used to asymptotically speed up several super-linear unweighted graph algorithms. The current techniques for speeding up graph algorithms are all somewhat involved insofar that they employ sophisticated pre-processing, data-structures, or use ``word tricks" on the RAM model to achieve at most a  speed up for sufficiently dense graphs.  Our methods are much simpler and can result in super-polylogarithmic speedups. In particular, we achieve better bounds for diameter, transitive closure, bipartite maximum matching, and general maximum matching.
\end{abstract}

\section{Introduction}

The runtime of an algorithm is intimately related to how an instance is represented.  
Recall that the runtimes of the first generation of graph algorithms were expressed solely in terms of , the number of vertices.  This analysis was natural since at this time graphs were represented in  space via their adjacency matrix.  It was soon noticed that if , then a variety of graph algorithms could be sped up by first computing the adjacency list from the adjacency matrix, then running the algorithm on the more efficient adjacency list representation. This motivated the introduction of  to the runtime of graph algorithms and it is now customary in algorithm design to assume that a graph instance is given in the form of its adjacency list. 

We introduce  as a measure of complexity and show many classical graph algorithms can be analyzed in terms of .  This is a significant measure of complexity since  but .  In particular, if , then several graph algorithms can be asymptotically sped up by computing the so-called \emph{partially complemented adjacency list}  (pc-list) from an adjacency list, then running the algorithm on the more efficient partially complemented adjacency list representation.  

The pc-list~\cite{DahlhausGM02} is a natural generalization of the adjacency list  that involves an additional  bits of storage to represent \emph{vertex switches}.  When a vertex is switched, its neighbors become nonneighbors and nonneighbors become neighbors.   A (di)graph afforded such a switching operation is commonly referred to as a \emph{switching class}~\cite{Seidel76}.  Figure 1 of the appendix demonstrates how a pc-list can represent a switching class which can in turn be used to obtain a more compact representation of a graph.  Algebraic and combinatorial properties of switching classes have been studied in depth~\cite{Seidel76,ChengW86}; however, they have not been studied as thoroughly from an algorithmic point of view.  The intent of this work is extend~\cite{DahlhausGM02} by further investigating algorithmic properties of switching classes.

In~\cite{DahlhausGM02} canonical  unweighted graph algorithms were developed for switching classes; however, due to the linear-time solvability of these problems, the pc-list provided no asymptotic speed up in runtime.  We extend this work by developing switching class algorithms for classical unweighted graph problems for which no linear-time algorithm is known.  We show that for sufficiently dense graphs, the pc-list can provide super-polylogarithmic speed ups in runtime. 

This is notable since the current techniques for speeding up algorithms over dense instances are all somewhat involved and achieve at most a  speed up.  A data-structure in~\cite{KaoOT98} is given that allows one to work on the complement of a graph without constructing it; however, the algorithms they consider are linear and do not improve any of the results established in~\cite{DahlhausGM02}.
The techniques in~\cite{CheriyanM96} are notable in that they achieve a  speed-up for several canonical graph problems over arbitrary dense graphs (assuming the RAM model).  Clever but complicated preprocessing in~\cite{FederM95} allows for an asymptotic speedup that is logarithmic in the density of the graph that is at most .  

Our approach is much simpler insofar that it involves only basic preprocessing of the graph and slight modifications to existing algorithms.

\section{Preliminaries}
All graphs are assumed to be finite, labeled, directed, unweighted, and simple unless stated otherwise, and let  denote the class of all such graphs on  vertices. Let  and  denote vertex set and edge set of  respectively.  Let  denote the set of edges that have exactly one endpoint in  and exactly one endpoint in .  Let  denote the subgraph induced by the vertex set .  An \emph{out-switch} (\emph{in-switch}) of a vertex changes out-neighbors (in-neighbors) to non out-neighbors (in-neighbors) and vice versa. A \emph{Seidel-switch} of a vertex in an undirected graph changes neighbors to nonneighbors and nonneighbors to neighbors.  Performing an out-switch and in-switch on the same vertex of an undirected graph is equivalent to Seidel-switching that vertex.  Let , , and  be the graphs obtained by out, in, and Seidel switching on a vertex  respectively.  It is easy to see that the order in which vertices are switched does not matter, so let , , and  be the graph obtained by out, in, and Seidel switching on a set .  If a mixed sequence of in and out switches are permitted, then let  be the graph obtained by \emph{Gale-Berlekamp switching} where  are the subsets of vertices that have been in-switched and out-switched respectively.

\begin{definition}
Let .  Then  iff  such that  with respect to some switching operation .
\end{definition}

\begin{proposition}
 is an equivalence relation over .
\end{proposition}

\begin{definition}
Let .  Then  is the switching class of  with respect to some switching operation .
\end{definition}

\noindent 
In particular, we let , , , and  denote the \emph{in, out, Gale-Berlekamp, and Seidel switching class of}  respectively.  It is worth noting that in-switching classes and out-switching classes have an algebraic structure similar to Gale-Berlekamp switching classes~\cite{RothV08}. It is routine to show that   and  form an equivalence relation over  that gives rise to the Abelian group .



\begin{definition}
The partially complemented adjacency list (pc-list) of a graph  (with respect to some switching operation) is an adjacency list outfitted with a constant number of bitstrings of length  that represent vertex switches.
\end{definition}
If a vertex  is switched, then we let  denote its doubly-linked neighborlist in the pc-list of .  If  is unswitched, then we let  denote the doubly-linked neighbor list of  in the pc-list of .  For any switched vertex , we still refer to  as the neighborlist of  even though its elements are actually non-neighbors in the original graph.

\begin{proposition}
 is the graph obtained by out-switching (in-switching) all of the vertices.
\end{proposition}
\noindent The proposition above is useful due to the fact that some graph classes can be recognized by considering properties of their complements~\cite{McConnellS99}. Unfortunately, constructing the complement graph  is an  operation which precludes any linear-time bound.  The pc-list has proved useful in this context since it represents  implicitly which obviates the  cost of constructing ~\cite{DahlhausGM02,McConnellS99}.

The pc-list was motivated by McConnell's \emph{complement-equivalence classes}~\cite{McConnell97}.  It is straightforward to see that the symmetric complement-equivalence classes of~\cite{DahlhausGM02} coincide with Seidel switching classes and in-out complement-equivalence classes~\cite{DahlhausGM02} coincide with Gale-Berlekamp switching classes.  Due to this correspondence, it seems natural to couch the pc-list in terms of the existing theory of switching classes. 

It is obvious that we should seek out small members of switching classes to obtain a more succinct representation of a given graph.  Ideally, we should seek a member of a switching class with the fewest edges.
\begin{definition}
A minimum representative of a switching class  is a not necessarily unique graph  having minimum edge cardinality .
\end{definition}
If we limit ourselves to strictly out-switches or strictly in-switches, the following lemma shows that we can easily construct a minimum representative using a greedy algorithm.
\begin{lemma}\label{lem:buildOut}
\cite{DahlhausGM02} A minimum representative  () can be constructed in  time.
\end{lemma}
\begin{proof}
Visit each vertex and if switching it reduces the edge count, do so. For out switching, if there are more than  elements in 's neighbor list, switch  and replace the neighbor list with non-neighbors of .  The work for creating the list of non-neighbors can be charged to visiting the neighbors of . For in switching, if  appears more than  times in the adjacency list of , then switch .  The work is clearly .
\end{proof}

\noindent Observe that if both in-switches and out-switches are allowed, then the algorithm in the proof of Lemma~\ref{lem:buildOut} no longer guarantees that the representative is a minimum.  This is because edges can reappear while constructing the representative.  It is known that computing minimum representatives for Gale-Berlekamp and Seidel switching classes is NP-hard and is even hard to approximate within a constant factor of the optimum~\cite{RothV08,JelinkovaSHK11}.  There do however exist randomized linear-time -approximation schemes for computing a minimum representative ~\cite{KarpinskiS09}.  This allows one to obtain a representative  such that  in  time with high probability.



\section{Basic Algorithms for Switching Classes}

\subsection{Traversal}

Traversal algorithms for out-switching classes first appeared in~\cite{DahlhausGM02} where the existence of  algorithms for traversal on Seidel switching classes was left open.  We show that these algorithms can obtained in a straightforward manner through a slight modification of the pc-list data-structure and the traversal algorithms of~\cite{DahlhausGM02,LindzeyO13}.
 We refer the reader to~\cite{DahlhausGM02,LindzeyO13} for a more thorough treatment.  We begin with an intuitive explanation as to why the pc-list is able to provide asymptotic savings in runtime for graph traversal.

Let  be a graph traversal algorithm and assume there exists an oracle  such that for any current vertex , it returns in  time either an undiscovered neighbor  or reports that all of 's neighbors have been discovered.  If  considers a vertex that has already been discovered, then we shall call this a \emph{bad query}. It is clear that the runtime of  with oracle  is  since  can make no bad queries.  This is no longer the case if we run  without  since we might have  bad queries for arbitrary graphs. In this case, the runtime of  is dominated by bad queries since we could have as many as .  However, if the size of 's pc-list is asymptotically smaller than its adjacency list, then we can obtain a tighter upper bound on the number of bad queries that can occur during an execution of algorithm  without use of an oracle.  This is due to the fact that every bad query of BFS or DFS can be charged to an element of the pc-list data-structure~\cite{DahlhausGM02,LindzeyO13}.

\begin{theorem}
\cite{DahlhausGM02} Given , BFS on  can be done  time.
\end{theorem}

\begin{theorem}
\cite{DahlhausGM02,LindzeyO13} Given , DFS on  can be done in  time.
\end{theorem}
\begin{proposition}
Let  be a set of Seidel switched vertices and let .  Then  is isomorphic to the graph  where  is the complement of the cut induced by .
\end{proposition}
Given an adjacency list representation of  and a set of Seidel switched vertices  such that , a pc-list data-structure that represents  can be constructed in  time as follows.  Let  be an arbitrary vertex. If  is switched, set its bit to 1, add all of its neighbors in  and its nonneighbors in  into its neighborlist.  If  is unswitched, set its bit to 0, add all of its neighbors in  and its nonneighbors in  into its neighborlist. Relabel the vertices so that the members of  have a smaller label than members of , then radix-sort the pc-list with respect to this new labeling.  The sort has the effect of making all nonneighbors of  appear consecutively in 's neighborlist.  Finally, insert a dummy vertex between the two elements  and  of 's neighborlist such that  is switched and  is unswitched.

The same algorithms given in~\cite{DahlhausGM02} and~\cite{LindzeyO13} can be used on this pc-list representation with the following modification; once 's dummy vertex is visited during a scan of its neighbor list, flip 's bit in the pc-list.  If  is switched, then the flip has the effect of treating elements after the dummy vertex as actual neighbors of . If  is unswitched, then the flip has the effect of treating elements after the dummy vertex as nonneighbors of .  Accounting for this modification in the traversal algorithms of~\cite{DahlhausGM02,LindzeyO13} is trivial.  The foregoing gives the following result.
\begin{theorem}
Given , BFS and DFS on  can be done in  time.
\end{theorem}

\subsection{Contraction}

\noindent Another basic graph-theoretic operation is contraction of a subset of vertices.  Henceforth we shall assume that all switching operations are out-switches for ease of exposition.  Let  be a minimum representative, let  be the number of vertices of a subset ,  be the number of edges incident to vertices of  in the graph .  The results of this section will be needed for computing maximum matchings of general graphs.  Without loss of generality, we assume that the pc-list of  is sorted by vertex label.

\begin{lemma}\label{lem:contract}
Given , a set  can be contracted to vertex  in  time.
\end{lemma}
\begin{proof}
To build the neighbor list of , we first build two doubly-linked neighbor lists  that correspond to the contraction of all the switched vertices  and unswitched vertices of  respectively.

Initialize  to be  some  and let .  Then contracting  and  together corresponds to taking the intersection .  Since the neighborlists are sorted, taking the intersection  can be computed in  using a routine similar to the merge routine of merge-sort as follows.  Let  denote the th element of a doubly-linked list .

If , then the comparison can be charged to the th edge of 's neighbor list.  If , then the comparison can be charged to the th edge of 's neighbor list.  If , then  is removed from the doubly-linked list .  Removing a vertex from  happens at most  times since each deletion can be charged to an element of .  

Initialize  to be  for some  and let . Suppose that  are unswitched, then contracting  and  together corresponds taking the union .  The union  can clearly be computed in .

To combine  and  it suffices to scan  and remove all elements from  that also exist in . This can be done using a routine similar to the merge routine.  At the end of the routine, define  to be .  Since the sizes of  and  are each , it follows that  can be constructed in  time.
\end{proof}

\begin{lemma}\label{lem:contractG}
Let  be a collection of vertex-disjoint subsets. Then the contracted graph  can be computed in .
\end{lemma}
\begin{proof}
By Lemma~\ref{lem:contract} we can perform all of the contractions in time .  After performing the contractions, the pc-list must be cleaned up so that vertices subsumed by contractions are no longer referenced.  This can be done by radix-sorting and removing duplicates in  time.
\end{proof}


\section{Super-Linear Graph Algorithms}
In this section, we show that given a graph , spending  time to compute an  space pc-list representation of  gives rise to better bounds for several canonical unweighted graph algorithms.  

\subsection{Diameter and Transitive Closure}

At present, the most efficient combinatorial algorithm (ignoring log factors) for computing the diameter and transitive closure of a graph to our knowledge is the naive  algorithm, that is, calling BFS from each vertex.  The following results are straightforward.
\begin{theorem}
The diameter of a graph  can be computed in  time.
\end{theorem}
\begin{theorem}
The transitive closure of a graph  can be computed in  time.
\end{theorem}
\begin{proof}
Compute  in  time,  then run the naive algorithm from each vertex using the BFS algorithm of~\cite{DahlhausGM02}.  The runtime of this algorithm is .
\end{proof}
\noindent Since  is never worse than  and is sometimes better, this is indeed a better bound for both diameter and transitive closure.  

At this point it is natural to ask when a graph \emph{benefits} from its pc-list representation, that is, when its pc-list representation is asymptotically smaller than its adjacency-list representation.  It is easy to see that there are at least twice as many graphs that benefit from pc-lists as there are graphs that benefit from adjacency-lists.  This is because the pc-list is a generalization of the adjacency-list and the complement of any graph whose adjacency-list representation is asymptotically smaller than its adjacency-matrix representation must have a minimum representative  such that .  For instance, the class of graphs whose complement is sparse benefits from its pc-list representation simply by out-switching all of its vertices. 

It would be interesting to give precise conditions for when a graph benefits from its pc-list representation, but for now, our intuition tells us that very dense graphs and ``unbalanced" graphs (graphs with vanishingly few vertices of average valency) appear to benefit most from the pc-list representation.\footnote{Perhaps it is possible to make this intuition well-defined via discrepancy theory.}  On the other hand, since almost all graphs are roughly -regular, the pc-list does not provide an asymptotically smaller representation for most graphs.  The techniques of~\cite{CheriyanM96} and~\cite{FederM95} are notable since they give logarithmic speedups in runtime for almost all graphs.

\subsection{Hopcroft-Karp Bipartite Maximum Matching}

Notice that switching in general does not preserve the bipartite property.  Given a bipartite graph , define the \emph{bipartite switching class} of  (with respect to some switching operator), such that neighbors of  become nonneighbors and nonneighbors of  that lie outside of 's partition class become neighbors.  In this section, all switches are assumed to be bipartite out-switches.  Familiarity with the bipartite maximum matching problem is assumed.

The Hopcroft-Karp algorithm consists of \emph{phases}, each of which strictly increases the size of a current matching.  In~\cite{HopcroftK73} it is shown that a phase consists of a call to a modified BFS routine followed by a call to a modified DFS and that only  phases are needed to compute a maximum matching.  These routines can be implemented to run in  time which gives rise to a  bound for computing a maximum matching of a bipartite graph.  

The purpose of running the modified BFS is to discover a directed acyclic level graph  such that any path connecting two unmatched vertices in  corresponds to a shortest augmenting path in .  A modified DFS is then conducted on  in order to find a maximal set of vertex-disjoint augmenting paths  in . These steps are repeated until a phase is encountered such that , in which case the matching  must be maximum by a theorem of Berge. 

It suffices to show that given , a phase of Hopcroft-Karp can be implemented to run in  time. Let BFS* and DFS* be pc-list implementations of the aforementioned modified BFS and DFS routines.  The BFS* routine is essentially the same as the BFS algorithm of~\cite{DahlhausGM02} except for the following modifications.  Let  denote the BFS level of a vertex .
\begin{enumerate}
\item The undiscovered vertices are divided into two doubly-linked lists  and .  If the current vertex , then BFS only considers vertices in  (similarly for ).
\item The discovered vertices are kept in an array of doubly-linked lists  that represents a partition of the discovered vertices by BFS level.  In particular, a discovered vertex  resides in the doubly-linked list at index  of .  This array represents the levels in the DAG .
\item Let  be the level of the first unmatched vertex in  that has been dequeued. Once all vertices at level  have been dequeued, the routine returns .
\end{enumerate}
 It is clear that the aforementioned modifications to the BFS routine of~\cite{DahlhausGM02} can be accomplished in  time.  Pseudocode of BFS* that achieves this bound is given in the appendix.
 
The vertices of  form the initial set of undiscovered vertices for the modified DFS routine.  Notice that explicitly constructing the level DAG  from  would exceed the  time bound; however, this is unnecessary since  provides an implicit representation of .
A precondition to the DFS algorithm of~\cite{LindzeyO13} is that doubly-linked list of undiscovered vertices is ordered according to the ordering of the vertices of the pc-list. For each , the ordering of  might not respect the ordering of the vertices in the sorted pc-list; however, this can be corrected by performing a radix-sort on  in  time.  The DFS* routine is the same as the DFS algorithm in~\cite{LindzeyO13} except for the following modifications.

\begin{enumerate}
\item If a vertex  is current, then  points to the doubly-linked list  so that  only considers undiscovered neighbors at .
\item When a path  from the designated source vertex  to an unmatched vertex in  has been found, the routine adds  to the set of vertex-disjoint augmenting paths and restarts DFS* from .
\end{enumerate}
The vertices of  cannot be considered in subsequent DFS* searches since they are removed from  once they are discovered.   Since the union of vertex-disjoint paths  has size , it is clear that DFS* can be implemented to run in  time.   Pseudocode of DFS* that achieves this bound is given in the appendix.

Finally, since a set of matched edges  has size , it is clear that the symmetric difference between  and the edges of the paths in  can be computed in  time.  This completes the description of a phase.  Because BFS* and DFS* are  and updating a matching takes  time, we obtain the following result.

\begin{lemma}\label{lem:phase}
A phase of Hopcroft-Karp can be implemented in  time.
\end{lemma}

\noindent By Lemma~\ref{lem:phase} and the fact that only  phases are needed to compute a maximum matching of a bipartite graph,  we obtain the following result.
\begin{theorem}
A maximum matching of a bipartite graph  can be computed in  time.
\end{theorem}


\noindent Pseudocode for Hopcroft-Karp that achieves the bound above is given in the appendix.  In~\cite{BalasN93} it is shown that finding maximum matchings of complement biclique graphs can be used as a heuristic to enumerate large cliques in graphs.  It is possible that the pc-list could make this heuristic more efficient in practice by circumventing the construction of the complement.

\subsection{Gabow-Tarjan Maximum Matching}

A full discussion of the Gabow-Tarjan maximum cardinality matching algorithm~\cite{GabowT91} is beyond the scope of this paper.  The following is only a rough sketch of the algorithm.  Familiarity with the maximum matching problem is assumed.\\

\noindent It is well known that the maximum matching problem for general graphs is complicated by the existence of alternating odd cycles (blossoms)~\cite{Edmonds65}.  
The Gabow-Tarjan maximum matching algorithm consists of  iterations of so-called \emph{phase 1} (not to be confused with Hopcroft-Karp's phases) followed by  calls to \emph{find\_ap\_set}~\cite{GabowT91}.  
Phase 1 consists of running \emph{find\_ap\_set} on a contracted graph  and expanding unweighted blossoms afterwards. 
The \emph{find\_ap\_set} routine is a depth-first based search responsible for discovering augmenting paths and blossoms of the input graph. A pre-condition to \emph{find\_ap\_set} is that the input graph  is contracted with respect to a set of blossoms .  Once \emph{find\_ap\_set} halts, the routine returns a maximal set of vertex-disjoint augment paths in the contracted graph.  These paths in the contracted graph are translated into vertex-disjoint augmenting paths in the original graph in  time and the current matching is updated with respect to those paths.  In addition to finding these paths, an execution discovers a set of new blossoms as well as a set of previously discovered blossoms to be expanded. This gives rise to a new set of blossoms to be contracted before the next call to \emph{find\_ap\_set}.  A blossom is expanded if its dual variable  becomes non-positive, which establishes an invariant that contracted blossoms  always have positive weight after the first execution of \emph{find\_ap\_set}.  Unweighted blossoms are expanded because they might be ``hiding augmenting paths"~\cite{Edmonds65}.  Expanding these blossoms gives \emph{find\_ap\_set} a chance to find these hidden augmenting paths in the next iteration. The maximum cardinality case is treated as a special case of their minimum weight matching algorithm and is shown to run in time  since the algorithm performs  iterations of \emph{find\_ap\_set} which runs in time . 
In~\cite{GabowT91} it is shown that blossom, augmenting path, and dual variable maintenance all take  time and space during an iteration of phase 1.  

Lemma~\ref{lem:contractG} shows that we can build the contracted graph in time proportional to , so it remains to show that \emph{find\_ap\_set} can be conducted in  time.  We shall assume that we have obtained a minimum member  of 's out-switching class.  Recall that a vertex of  is switched if and only if it has  or more neighbors in the original graph.  It follows that we can build an adjacency lookup vector  for each switched vertex  in  time.  This lookup vector will allow us to answer if some vertex  is adjacent to a switched vertex  in the original graph in  time. 

\begin{lemma}
The find\_ap\_set routine can be implemented in  time.
\end{lemma}

\noindent It suffices to show that the subroutine \emph{find\_ap} can be implemented in  time~\cite{GabowT91}.  Let  denote the blossom that  currently belongs to.  It is important to note that \emph{find\_ap} only performs grow steps and blossom steps.  We show how to perform each of these steps when the current vertex is switched.  The following invariants will be needed to simplify the analysis of our modification to \emph{find\_ap}.

\begin{enumerate}
\item Let  be the current vertex. If an edge  is scanned and  became outer after , then a blossom step is performed and every vertex in  has been completely scanned~\cite{GabowT91}.
\item The order in which vertices become outer is given by the ordering of a doubly-linked list .
\item If the current vertex performs a blossom step, then no more grow steps are possible from the current vertex.
\end{enumerate}
The second and third invariants are not part of the specification of their algorithm; however, it can be implemented to maintain these invariants without affecting the correctness or resource bounds of the algorithm. 

It is straightforward to modify the DFS algorithm of~\cite{LindzeyO13} so that when a current outer vertex  is considering an inner undiscovered neighbor , the next outer current vertex becomes  where  is a matched edge.  The details of the blossom step are slightly more involved.  It helps to view the blossom steps as DFS where the ``undiscovered vertices" are those vertices that have an outer label that is greater than the current vertex's outer label.  Once a blossom step is performed, the inner vertices along that blossom become current (and therefore outer) in order of their DFS discovery time and the routine proceeds recursively.



Assume that a current vertex  has no more grow steps, that is, there are no more undiscovered vertices reachable from .
If  is not switched, then proceed as usual in \emph{find\_ap}; otherwise, assume that  is switched.
The invariants guarantee that the blossom steps from  can be conducted by performing DFS where the ``undiscovered vertices" are those vertices to the right of  in .  Let us refer to this ordered set of vertices as .  The main obstacle is that we cannot use the DFS routine of~\cite{LindzeyO13} immediately to solve this problem since the ordering of the pc-list does not respect the ordering of .  For this reason we must use  to determine adjacency in  time.  

Let .  If , then a blossom step is performed. When a blossom step is performed, then  is removed from  since invariant 1 implies that these vertices have already been completely scanned and cannot be further used to discover an augmenting path.  Assuming the blossom data-structures in~\cite{GabowT91}, it follows that blossom steps take  time.  

If , then no blossom step is performed, but we can charge the lookup to 's entry in .  But as in the routines of~\cite{DahlhausGM02} and~\cite{LindzeyO13}, we must guarantee that  considers  only  times throughout the entire DFS execution on .  To ensure this, each time we encounter a  such that , we add it to the end of an auxiliary doubly-linked neighborlist for .  This has the effect of building an ordered neighborlist for  that respects the ordering of .  Using this neighborlist, we can follow the restart step of the DFS algorithm in~\cite{LindzeyO13} to correctly and efficiently resume DFS on  when  returns from a recursive call. As in the bipartite case, keeping track of augmenting paths and updating the current matching can be accomplished in  time.  Since \emph{find\_ap\_set} can be implemented in  time, we obtain the following result.

\begin{theorem}\label{thm:maxmatch}
A maximum matching of a graph  can be computed in  time.
\end{theorem}

\section{Conclusions}


We have demonstrated that switching classes can be used to obtain asymptotically better bounds for several graph algorithms through use of the pc-list data-structure.  These improvements on algorithm resource bounds suggest that the pc-list is a more efficient data-structure than the adjacency list for several unweighted graph problems.  But like any graph representation, it has its trade-offs.  For instance, finding an arbitrary neighbor of a switched vertex  in the original graph takes  time whereas finding an arbitrary neighbor of an unswitched vertex takes  time.

It may be tempting to believe that any unweighted graph algorithm can be implemented to work with a pc-list representation; however, it seems unlikely that the maximum matching algorithm of~\cite{MicaliV80} is amenable to pc-lists.  This is due to the fact that their approach requires a number of edges (so-called bridges) to be queued and processed at a later point in the execution of the algorithm.  When a bridge is processed, it does not always progress the algorithm, that is, it may not lead to a grow step, produce an augmenting path, or discover a blossom.  In light of this, processing a bridge cannot always be charged to a vertex or edge of .  We were unable to obtain a bound tighter than  for the number of bridges queued throughout the algorithm; however, it might be possible to modify the algorithm so that only bridges that lead to an augmenting path or blossom are considered.

In fact, there are classical super-linear graph problems that inherently cannot benefit from the pc-list.  Two such examples are finding an Eulerian tour of  and computing the ear decomposition of .  Any algorithm for these problem must spend  time for arbitrary graphs since the size of the output is proportional to the number of edges.

An obvious line of future work would be towards a more formal characterization of graphs that benefit from pc-list representations as well as the development of more pc-list algorithms.  We conclude by thanking Ross M. McConnell for his insightful comments.





\bibliographystyle{plain}
\bibliography{master}

\section{Appendix}

\begin{figure}[htp]\label{fig:pclist}

\includegraphics[scale=.14]{adjlist.png} \includegraphics[scale=.14]{out.png}
\centering
\includegraphics[scale=.14]{berlekamp.png}
\caption{An illustration of the partially complemented adjacency list.  Setting  as the graph given in the leftmost picture, it is not hard to see that the graph obtained by out switching (the rightmost picture) and Gale-Berlekamp switching (the lower picture) are minimum representatives of  and  respectively.  This demonstrates that  is not necessarily a minimum representative of .}
\end{figure}

\begin{algorithm}
\KwData{A bipartite graph }
\KwResult{A maximum matching  of }
\;
Let  be the pc-list of a minimum representative of \;
\Repeat{}{
Let  be a copy of the pc-list \;
\;
\;
connect  to each unmatched vertex in \;
 BFS\;
 radix-sort()\;
DFS*()\;
\;
}
return \;
\caption{Hopcroft-Karp()}  \label{HK}
\end{algorithm}


\begin{algorithm} \label{alg:BFS}
\KwData{A pc-list , two global ordered doubly-linked lists ,  of the undiscovered vertices of  and  respectively.}
\KwResult{A partition  that represents a level graph.}
Let  be an array of doubly-linked lists\;
Let  be a queue\;
\;
\texttt{enqueue(,)}\;
\Repeat{ is empty}{
 \texttt{dequeue()}\;

\If{}{
 break\;
}  

\ElseIf{}{
Let  point to \;
}
\Else{
\If{ is unmatched}{
\;
}
Let  point to \;
}

\If{ is unswitched}{
  \For{}{
     \If{ is undiscovered}{
     	\texttt{remove(,)}\;
     	\texttt{enqueue(,)}\;
     	\texttt{append(,)}\;
     }
  }
}
\Else{

\For{}{
   \texttt{mark(,)}\;
   }
 \For{}{
     \If{ is unmarked}{
     	\texttt{remove(,)}\;
     	\texttt{enqueue(,)}\;
     	\texttt{append(,)}\;
     }
  }

}
}
return 
\caption{BFS()} 
\end{algorithm}

\begin{algorithm} \label{alg:DFS}
\caption{DFS*()} 
\KwData{A pc-list , a current undiscovered vertex , a global array  of ordered doubly-linked lists of undiscovered vertices, and global set of vertex-disjoint shortest augmenting paths .}
\KwResult{Discovers a maximal set of vertex-disjoint augmenting paths .}
Let \;
\If{}{
\texttt{remove}(,)\;
}
\If{ and  is unmatched}{
Let  be vertices of the DFS stack\;
\;
DFS*()\;
}
\If{ is unswitched}{
	\For{}{
	 	   DFS*()\;
	}
}
\Else{
	 \texttt{head}()\;
	 \texttt{head}()\;
	\While{}{
	\If{}{
		 \texttt{next}()\;
		 \texttt{next}()\;
	}
	\ElseIf{}{
		\;
		 \texttt{next}()\;
		\texttt{remove}()\;
	}
\Else{
	DFS()\;
	\tcp{restarting step ...}
         = prev()\;
	\While{ and }{
		\;
		 \texttt{prev}()\;	
		\texttt{remove}())\;
}
\If{}{
		 \texttt{head}()\;
	}
	\Else{
		 \texttt{next}()\;
	}
}
}
}

\end{algorithm}

\begin{algorithm}\label{alg:contract}

\For{}{
\;
\ForEach{}{
\If{b is switched}{
	\If{}{ \;}
	\Else{\;}
}
\Else{
	\;
 }
}

\;
}
Relabel each vertex  with \;
 radix-sort()\;
 remove-duplicates()\;
\caption{contract()}
\end{algorithm}

\begin{algorithm}
Let  be the pc-list of a minimum representative of \;
Let  be the blossom tree of \;
\;
\;
\;

\Repeat{}{ \tcp{phase 1}
 contract()\;
 \emph{find\_ap\_set}()\;
\tcp{search performs dual adjustments \& expands nonpositve blossoms}
 \emph{search}()\;
\;
\;
}
\Repeat{}{
  \emph{find\_ap\_set}())\;
\;
}
return \;


\caption{Gabow-Tarjan()}
\end{algorithm}

\begin{comment}
\begin{algorithm}
\;
\;
\While{x has a neighbor }{
	\If{ is free}
	{
		exit;
	}
	\Else{
	\;
	\emph{find\_ap(y')}\;
	}
}
\Else{
	\While{ has a neighbor }{
			 inner vertices along  in reverse order\;
			\For{ such that }{
				\;	
			}		
			\For{}{
				\;
				\emph{find\_ap(i)}\;
		}
	}
}
return \;
\caption{\emph{find\_ap}()}
\end{algorithm}
\end{comment}
\end{document}
