\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{subcaption}
\usepackage{sistyle}
\SIthousandsep{,}

\newcommand{\myparagraph}[1]{\vspace{0.1em}\noindent\textbf{#1}}
\newcommand{\todo}[1]{\textcolor{red}{TODO: #1}}




\usepackage[breaklinks=true,bookmarks=false, hidelinks]{hyperref}

\cvprfinalcopy 

\def\cvprPaperID{1022} \def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\setcounter{page}{1}

\newcommand{\posetrack}{PoseTrack\xspace}

\newcommand{\ProTracker}{ProTracker~\cite{ProTracker} \xspace}

\newcommand{\BUTD}{BUTD~\cite{BUDT}\xspace}

\newcommand{\SOPTPT}{SOPT-PT~\cite{SOPT-PT}\xspace}

\newcommand{\MLLab}{ML-LAB~\cite{ML-LAB}\xspace}



\newcommand{\ICG}{ICG~\cite{ICG}\xspace}


\newcommand{\BUTDS}{BUTDS~\cite{BUDT}\xspace}

\newcommand{\FRACTALNET}{FractalNet~\cite{FractalNet}\xspace}

\newcommand{\SSDHG}{SSDHG\xspace}


\newcommand{\MPI}{}
\newcommand{\UBO}{}
\newcommand{\UOA}{}
\newcommand{\AMZ}{}
\newcommand{\GOG}{}



\title{PoseTrack: A Benchmark for Human Pose Estimation and Tracking
\vspace{-3mm}}


\author{
Mykhaylo Andriluka\GOG\quad
Umar Iqbal\UBO \quad
Eldar Insafutdinov\MPI \quad
Leonid Pishchulin\MPI\\
Anton Milan\AMZ \quad
Juergen Gall\UBO \quad
Bernt Schiele\MPI \.25em]
		
		\includegraphics[height=\cwidth\columnwidth]{images/hard_pred/15375_mpii_relpath_5sec_testsub_00000069.jpg} 
		&
		\includegraphics[height=\cwidth\columnwidth]{images/hard_pred/21086_mpii_relpath_5sec_testsub_00000046.jpg} 
		&
		\includegraphics[height=\cwidth\columnwidth]{images/hard_pred/23965_mpii_relpath_5sec_testsub_00000048.jpg} 
		&
		\includegraphics[height=\cwidth\columnwidth]{images/hard_pred/16235_mpii_relpath_5sec_testsub_00000052.jpg} \\
		5 & 6 & 7 & 8 \\
		
	\end{tabular}
\vspace{-0.35cm}
	\caption{Selected frames from sample sequences with negative average MOTA
          score. The predictions of our ArtTrack-baseline are overlaid in each
          frame. Challenges for current methods in such sequences include crowds (images 3 and 8), extreme proximity of
          people to each other (7), rare poses (4 and 6) and strong camera motions (3, 5, 6, and
          8).}
\label{fig:hard_sequences}
\end{figure*}





 
\myparagraph{Dataset difficulty.}  We composed our dataset by including videos
around the keyframes from MPII Human Pose dataset that included several people
and non-static scenes. The rationale was to create a dataset that would be
non-trivial for tracking and require methods to correctly resolve effects such
as person-person occlusions. In Fig.~\ref{fig:mota:all_methods} we visualize
performance of the evaluated approaches on each of the test sequences.  We
observe that test sequences vary greatly with respect to difficulty both for
pose estimation as well as for tracking. \Eg, for the best performing submission
\ProTracker the performance varies from nearly 80 MOTA to a score below zero\footnote{Note that MOTA metric can become negative for example when the number
  of false positives significantly exceeds the number of ground-truth
  targets.}. Note that the approaches mostly agree with respect to the
difficulty of the sequences.  More difficult sequences are likely to require
methods that are beyond simple tracking component based on frame-to-frame
assignment used in the currently best performing approaches. To encourage
submissions that explicitly address challenges in the difficult portions of the
dataset we have defined easy/moderate/hard splits of the data and report results
for each of the splits as well as the full set.

 
\myparagraph{Evaluation metrics.} The MOTA evaluation metric has a deficiency in
that it does not take the confidence score of the predicted tracks into
account. As a result achieving good MOTA score requires tuning of the pose
detector threshold so that only confident track and pose hypothesis are supplied
for evaluation. This in general degrades pose estimation performance as measured
by mAP (\cf performance of submission \ProTracker in
Tab.~\ref{tab:posetrack_mota} and \ref{tab:posetrack_map}).  We 
quantify this in Fig.~\ref{tab:tracking-mota-val} for our ArtTrack
baseline. Note that filtering the detections with score below  as
compared to  improves MOTA from 38.1 to 53.4. One potential
improvement to the evaluation metric would be to require that pose tracking
methods assign confidence score to each predicted track as is common for pose
estimation and object detection.  This would allow one to compute a final score as
an average of MOTA computed for a range of track scores. Current pose
tracking methods typically do not provide such confidence scores. We believe that extending
the evaluation protocol to include confidence scores is an important future direction. 





 












 \section{Dataset Analysis}
\label{sec:baselines}


In order to better understand successes and failures of the current body pose
tracking approaches, we analyze their performance across the range of
sequences in the test set. To that end, for each sequence we compute an average
over MOTA scores obtained by each of the seven evaluated methods. Such average
score serves us as an estimate for the difficulty of the sequence for the
current computer vision approaches. We then rank the sequences by the average
MOTA. The resulting ranking is shown in Fig.~\ref{fig:mota:all_methods} (left) along
with the original MOTA scores of each of the approaches.
First, we observe that all methods
perform similarly well on easy
sequences. Fig.~\ref{fig:easy_sequences} shows a few easy sequences
with an average MOTA above . Visual analysis
reveals that easy sequences typically contain significantly separated
individuals in upright standing poses with minimal changes of body
articulation over time and no camera motion. Tracking accuracy drops
 with the increased complexity of video
sequences. Fig.~\ref{fig:hard_sequences} shows a few hard sequences
with average MOTA accuracy below . 
These sequences typically include strongly overlapping people, and fast motions of
people and camera.







We further analyze how tracking and pose estimation accuracy are affected by
pose complexity. As a measure for the pose
complexity of a sequence we employ an average deviation of each pose in a sequence
from the mean pose. 
The computed complexity score is used to sort video sequences from low to high pose
complexity and average mAP is reported for each
sequence. The result of this evaluation is shown in
Fig.~\ref{fig:mota:all_methods} (middle). For visualization purposes, we partition the sorted video
sequences into bins of size 10 based on pose complexity score and report average
mAP for each bin. We observe that both body pose estimation and tracking
performance significantly decrease with the increased pose complexity.
Fig.~\ref{fig:mota:all_methods} (right) shows a plot that highlights correlation
between mAP and MOTA of the same sequence. We use the mean performance of all methods in this visualization. Note that in most cases more accurate
pose estimation reflected by higher mAP indeed corresponds to higher
MOTA. However, it is instructive to look at sequences where poses are estimated
accurately (mAP is high), yet tracking results are particularly poor (MOTA near
zero). One of such sequences is shown in Fig.~\ref{fig:hard_sequences} (8). This
sequence features a large number of people and fast camera movement that is likely
confusing simple frame-to-frame association tracking of the evaluated
approaches. Please see supplemental material for additional examples and
analyses of challenging sequences.









 \section{Conclusion}
\label{sec:conclusion}
In this paper we proposed a new benchmark for human pose estimation and articulated tracking that is significantly larger and more diverse in terms of data variability and complexity compared to existing pose tracking benchmarks. Our benchmark enables objective comparison of different approaches for articulated people tracking in realistic scenes. We have set up an online evaluation server that permits evaluation on a held-out test set, and have measures in place to limit overfitting on the dataset. Finally, we conducted a rigorous survey of the state of the art. Due to the scale and complexity of the benchmark, most existing methods build on combinations of proven components: people detection, single-person pose estimation, and tracking based on simple association between neighboring frames. Our analysis shows that current methods perform well on easy sequences with well separated upright people, but are severely challenged in the presence of fast camera motions and complex articulations. Addressing these challenges remains an important direction for the future work.



 \myparagraph{Acknowledgements.}
UI and JG have been supported by the DFG project GA 1927/5-1 (FOR 2535) and the ERC Starting Grant ARCA (677650).
 {\small
\bibliographystyle{ieee}
\bibliography{egbib,refs-short,anton-ref,biblio}
}

\end{document}
