\documentclass[letterpaper,11pt]{article}





\usepackage{fullpage}
\usepackage{amsmath,amsthm}
\usepackage{accents}
\usepackage{times}
\usepackage{url}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{cite}
\usepackage{mdwlist}
\usepackage{graphicx,amsmath,amssymb,amsthm,subfigure, amsfonts}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{algorithmic}
\usepackage{tipa}
\usepackage{a4wide}
\usepackage{color}

\usepackage{subfigure}
\usepackage[english]{babel}
\usepackage{subfigure}
\usepackage{nonfloat}
\usepackage{epsfig}
\usepackage{sidecap}
\usepackage{authblk}


\usepackage{algorithm2e}
\DeclareMathOperator*{\argmax}{argmax}

\newcommand{\ignore}[1]{}
               {}
\newcommand{\abs}[1]{\left| #1\right|}
\newcommand{\set}[1]{\left\{ #1\right\}}
\newcommand{\Ad}{}
\newcommand{\A}{}
\newcommand{\rmPi}{\rm {\Pi}}
\newcommand{\nnPi}{{\rm {\Pi}}^{(n,n)}}
\newcommand{\tnPiNaive}{{\rm {\Pi}}^{(t+1,n)}_{naive}}
\newcommand{\tnPi}{{\rm {\Pi}}^{(t+1,n)}}
\newcommand{\view}{\mathrm{VIEW}}
\newcommand{\seed}{\mathit{seed}}
\newcommand{\init}{\mathit{init}}
\newcommand{\curr}{\mathit{curr}}
\newcommand{\next}{\mathit{next}}
\newcommand{\len}{\mathit{len}}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\def\lena#1{\textsc{(Lena says: \marrow\textsf{#1})}}\newcommand{\todo}[1]{{\em{TODO: {#1}}}}


\renewcommand{\Re}{\mathbb{R}}
\newcommand{\R}{\cal{R}}
\renewcommand{\H}{\cal{H}}

\newcommand{\compind}{\ensuremath{\stackrel{\mathsf{c}}{\mathop\approx}}}


\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{notation}{Notation}
\newtheorem{construction}{Construction}

\newtheorem{observation}[theorem]{\textbf{Observation}}


\newtheorem{remark}[theorem]{Remark}

\newenvironment{proofsk}{\begin{proof}[Proof sketch.]}
{\end{proof}}


\newlength{\saveparindent}
\setlength{\saveparindent}{\parindent}
\newlength{\saveparskip}
\setlength{\saveparskip}{\parskip}


\newcounter{ctr}
\newcounter{savectr}
\newcounter{ectr}

\newenvironment{tiret}{\begin{list}{\hspace{1pt}\rule[0.5ex]{6pt}{1pt}\hfill}{\labelwidth=15pt\labelsep=3pt \leftmargin=18pt \topsep=1pt\setlength{\listparindent}{\saveparindent}\setlength{\parsep}{\saveparskip}\setlength{\itemsep}{1pt}}}{\end{list}}


\newenvironment{newenum}{\begin{list}{{\rm \arabic{ctr}.}\hfill}{\usecounter{ctr}\labelwidth=17pt\labelsep=6pt \leftmargin=23pt \topsep=.5pt\setlength{\listparindent}{\saveparindent}\setlength{\parsep}{\saveparskip}\setlength{\itemsep}{5pt} }}{\end{list}}

\begin{document}

\begin{titlepage}

\title{\bf Efficient Private Distributed Computation \\
on Unbounded Input Streams\thanks{This research has been supported by the Israeli Ministry of Science and Technology (MOST), the Institute for Future Defense Technologies Research named for the Medvedi, Shwartzman and Gensler Families, the Israel Internet Association (ISOC-IL), the Lynne and William Frankel Center for Computer Science at Ben-Gurion University, Rita Altura Trust Chair in Computer Science, {\em Israel Science Foundation} (grant number 428/11), Cabarnit Cyber Security MAGNET Consortium, MAFAT and Deutsche Telekom Labs at BGU. Emails: {\tt {dolev,yuditsky}\allowbreak @cs.bgu.ac.il}, {\tt garay@\allowbreak research.\allowbreak att.com}, {\tt niv.gilboa@gmail.com}, {\tt kolesnikov@\allowbreak research.bell-labs.com.} A brief announcement will be presented in DISC 2012.}}

\author[1]{Shlomi Dolev}
\author[2]{Juan Garay}
\author[3]{Niv Gilboa}
\author[4]{Vladimir Kolesnikov}
\author[1]{Yelena Yuditsky}

\affil[1]{Department of Computer Science, Ben Gurion University of the Negev, Israel }
\affil[2]{AT\&T Labs -- Research, Florham Park, NJ }
\affil[3]{Deptartment of Communication Systems Engineering, Ben-Gurion University of the Negev, Beer-Sheva, Israel}
\affil[4]{Bell Laboratories, Murray Hill, NJ}




\date{}


\maketitle
\thispagestyle{empty}
\begin{abstract}
In the problem of swarm computing,  agents wish to securely and
distributively perform a computation on common inputs, in such a way
that even if the entire memory contents of some of them are exposed,
no information is revealed about the state of the computation.
Recently, Dolev, Garay, Gilboa and Kolesnikov [ICS 2011] considered this
problem in the setting of information-theoretic security, showing how to perform such computations on input streams of {\em unbounded length}.  The cost of their solution, however, is exponential in the size of the Finite State Automaton (FSA) computing the function.

In this work we are interested in efficient computation in the above
model, at the expense of {\em minimal} additional assumptions. Relying on the existence of one-way functions, we show how to process {\it a priori} unbounded inputs (but of course, polynomial in the security parameter) at a cost {\em linear} in , the number of FSA states. In particular, our algorithms
achieve the following: 

\begin{tiret}

\item In the case of -reconstruction (i.e. in which all 
agents participate in reconstruction of the distributed computation) and at most  agents are corrupted,
the agent storage, the time required to process each input symbol and the time complexity for reconstruction are all . 

\item In the case of -reconstruction (where only  agents 
take part in the reconstruction) and at most  agents are corrupted,
the agents' storage and time required to process each input symbol are . The complexity of reconstruction is .

\end{tiret}
\end{abstract}


\end{titlepage}
\clearpage
\pagenumbering{arabic} 


\section{Introduction}

Distributed computing has become an integral part of a variety of
systems, including cloud computing and ``swarm'' computing, where 
agents perform a computation
on common inputs.  In these emerging computing paradigms, security
(i.e., privacy and correctness) of the computation is of a primary
concern.  Indeed, in
swarm computing, often considered in military contexts (e.g., unmanned
aerial vehicle (UAV) operation), security 
of the data and program state is of paramount importance;
similarly, one persistent challenge in the field of cloud
computing is ensuring the privacy of users' data, demanded by
government, commercial, and even individual cloud users.

In this work, we revisit the notion of {\em never-ending}
private distributed computation, first considered by Dolev, Garay, Gilboa and
Kolesnikov~\cite{DGGK11}. In such a computation, an unbounded sequence
of commands (or inputs) are interpreted by several machines (agents) in 
a way that no information about the inputs as well as the state of
the computation is revealed to an adversary who is able to ``corrupt''
the agents and examine their internal state, as long as up to a predetermined
threshold of the machines are corrupted.


Dolev {\em et al.}
were able to provide very strong (unconditional, or information-theoretic)
security for computations performed by a finite-state machine (FSA),
at the price however of the computation being efficient only for a small
set of functions, as in general the complexity of the computation
is exponential in the size (number of states) of the FSA computing
the function.


In this work, we {\em minimally}\footnote{Indeed, the existence
of one-way functions is considered a minimal assumption in contemporary
cryptography. In particular, we do not allow the use of public-key 
cryptography.}
weaken the original model by
additionally assuming the existence of one-way functions (and hence
consider polynomial-time adversaries---in the security parameter; more
details below), and in return achieve very high efficiency as a
function of the size of the FSA.  We stress that we still consider
computation on {\em a priori} unbounded number of inputs, and
where the online (input-processing) phase incurs {\em no communication}.
We now describe the model in more detail.


\vspace{-.1in}
\paragraph{The setting.}
As in~\cite{DGGK11}, we consider a distributed computation setting in
which a party, whom we refer to as {\it the dealer}, has a finite
state automaton (FSA)  which accepts an ({\em a priori}
unbounded) stream of inputs  received from an
external source. The dealer delegates the computation to agents
, by furnishing them with an implementation of \A.
The agents receive, in a synchronized manner, all
the inputs for  during the online input-processing phase,
where no communication whatsoever is allowed.  Finally, given a signal
from the dealer, the agents terminate the execution, submit their 
 internal state to the dealer, who computes the  state of   and returns it as output.

We consider an attack model where an entitiy,
called the adversary, \Ad, is able to adaptively ``corrupt'' agents
(i.e., inspect their internal state) during the online execution
phase, up to a threshold\footnote{We note that more general access 
structures may be naturally employed with our constructions.} 
.  We do not aim at maintaining the privacy of the
automaton \A; however, we wish to protect the secrecy of the state of
\A\ and the inputs' history.  We note that \Ad\ may have external
information about the computation, such as partial inputs or length of
the input sequence, state information, etc.  This auxiliary
information, together with the knowledge of \A, may exclude the
protection of certain configurations, or even fully determine \A's
state.  We stress that this cannot be avoided in any implementation,
and we do not consider this an insecurity.  Thus, our goal is to
prevent the leakage or derivation by
\Ad\ of any knowledge from seeing the execution traces which \Ad\ did
not already possess.

As mentioned above, our constructions relying on one-way functions
dictates that the computational power of entities (adversary, agents),
be polynomially bounded (in
, the security parameter).
Similarly, our protocols run on input streams of polynomial length.
At the same time, we do not impose an {\it a priori} bound on its length; 
moreover, the size of the agents' state is independent of it.
This allows  to use agents of the same (small) complexity (storage and 
computational power) in all situations.


\vspace{-.1in}

\paragraph{Our contributions.}
Our work is the first significant extension of the work
of~\cite{DGGK11}.  Towards our goal of making never-ending and private
distributed computation practical, we introduce an additional (minimal)
assumption of existence of one-way functions (and hence pseudo-random
number generators [PRGs]), and propose the following constructions:
\begin{tiret}
\item  A scheme with  reconstruction (where all  agents participate in reconstruction), where
the storage and processing time per input symbol is  for each
agent. The reconstruction complexity is ).
\item A scheme with  reconstruction (where  corrupted agents do not 
take part in the reconstruction), where the above costs are 
.\footnote{For some values of , e.g. , this quantity would be exponential in . This does not contradict our
assumption on the computational power of the participants; it simply
means that, given , for some values of  and  this
protocol cannot be executed in the allowed time.}
\end{tiret} 
Regarding tools and techniques, the carefully orchestrated use of PRGs
and secret-sharing techniques~\cite{Sha79} allows our protocols to hide the state of the computation against an adaptive adversary by using share re-randomization. 
Typically, in the context of secret sharing, this is simply done by the addition of a suitable (i.e., passing through the origin) random polynomial. However, due to the no-communication requirement, share re-randomization is a lot more challenging in our setting. This is particularly so in the more general case of the -reconstruction protocol. We achieve share re-randomization by sharing PRG seeds among the players in a manner which allows players to achieve sufficient synchronization of their randomness, which is resilient to  corruptions.



\vspace{-.1in}

\paragraph{Related work.} 
Reflecting a well-known phenomenon in distributed computing, where
a single point of failure needs to be avoided,
a team of agents (e.g., UAVs)  that collaborate in a mission
is more robust than a single agent trying
to complete a mission by itself (e.g., \cite{Bamberger,BDDS10}). 
Several techniques have been  suggested for this purpose;
another related line of work is that of automaton splitting and
replication, yielding
designs that can tolerate faults and as well as provide
some form of privacy of the computation
(see, e.g.,~\cite{DKS07,DLY07,DGKPS10,DGGK09,DGGK11}).
As mentioned above, 
only~\cite{DGGK11}
addresses the unbounded-input-stream scenario.
\ignore{
Techniques for information-theoretic communication among the participants of 
such systems have been investigated as well~\cite{DO00,BD03,DGGN08,DGKPS10},
some of which might be amenable for enhancement and application to our
scenario as well.\todo{VLAD: which techniques can be amenable? We have unbounded-input non-interactive online phase}
} 



Recall that in {\em secure multi-party
computation}~\cite{DBLP:conf/stoc/GoldreichMW87,BGW88,CCD88}, 
parties, some of which might be corrupted, are to compute an -ary
(public) function on their inputs, in such a way that no information
is revealed about them beyond what is revealed by the function's
output.  At a high level, we similarly aim in our context to ensure
the correctness and privacy of the distributed computation. However,
as explained in~\cite{DGGK11}, our setting is significantly different
from that of MPC, and MPC definitions and solutions cannot be directly
applied here.  The reason is two-fold: MPC protects players {\em
individual} inputs, whereas in our setting the inputs are common to
all player.  Secondly, and more importantly, MPC operates on inputs of
fixed length, which would require an {\it a priori} estimate on the 
maximum input size  and agents' storage linear in .  
While unbounded inputs could be processed, 
by for example processing them ``in blocks,'' this would require
communication during the online phase, which is not allowed
in our setting. Refer to~\cite{DGGK11} for a more detailed discussion
on the unbounded inputs setting {\em vis-\`{a}-vis} MPC's.



Finally, we note that using recently proposed fully-homomorphic encryption
(FHE)~\cite{DBLP:conf/stoc/Gentry09} (and follow-ups) trivially solves
the problem we pose, as under FHE the agents can simply compute arbitrary
functions. In fact, plain additively homomorphic encryption 
(e.g.,~\cite{EC:Paillier98}) can
be used to encrypt the current state of the FSA and non-interactively
update it as computation progresses, in a manner similar to what is
described in our constructions (see the high-level intuition in
Section~\ref{outline}).  We note that, firstly, public-key encryption
and, dramatically so, FHE, suffer from orders-of-magnitude
computational overhead, as compared to the symmetric-key operations that
we rely on.  More importantly, in this work we aim at minimizing
the assumptions needed for efficient unbounded private distributed
computation.

\ignore{
\todo{Move the MPC discussion below to appendix}

\subsection{Inapplicability of MPC to our setting}
\label{app-mpc}
Firstly, MPC aims to solve a different problem, that of protecting the
players' individual inputs from \Ad, who can corrupt some of them,
learn their input and observe the communication they receive.  In
contrast, in our problem the inputs are common to all the players (but
not {\it a priori} known to \Ad, or revealed in case of corruption),
and the goal is to protect the state of, as well as the inputs to, the
computation.  (Therefore, we cannot in particular treat the common
input as public information, and the shares received from the dealer
as MPC input.)

Of course, an adequate representation (circuit-based, for example) of
the MPC computation would be able to evaluate \A, with respect to a
subset of corrupted players, and at least for the basic MPC setting,
where there is a single (tuple of secret) input(s) out of which an
output (tuple) is produced.  But then comes our main feature, of
multiple, possibly unbounded number of input symbols.  This is
reminiscent of secure {\it reactive} systems (e.g.,~\cite{PW00}),
where the computation is not limited to ``one shot'' as above, but
instead processes inputs ``in blocks'' throughout several rounds of
interaction. However, because all MPC solutions (and definitions) are
explicitly tied to the length of the input, being able to handle
unbounded number of inputs without communication does not seem
immediate.  This is what our Krohn-Rhodes-based approach achieves, at
the expense of solving a narrower problem.


\todo{VLAD: end of appendix block}


\paragraph{Private perennial computation without communication from Krohn-Rhodes decomposition.}
Dolev et al.~\cite{DGGK11}
show the feasibility of achieving private  computation  on unbounded inputs
with non-interactive input-processing phase, at the cost of limiting the class of  
functions that can be evaluated---specifically, those carried out by 
finite-state automata (FSA).  Their cost is also in general exponential in the FSA size.

In this work, we aim to achieve much more practical efficiency for distributed FSA evaluation.  We {\em minimally} weaken our model by additionally assuming the existence of one-way functions (and hence consider polytime adversaries), and in exchange achieve efficiency linear in the FSA size.  We stress that we still consider computation on {\em a priori} unbounded inputs, where the online (input-processing) phase incurs not communication.

} 








\vspace{-.1in}

\paragraph{Organization of the paper.} The remainder of the paper is
organized as follows. In Section~\ref{sec-Prelim_and_outline} we present
in more detail the model, definitions and building blocks that we use 
throughout the paper. We dedicate Section~\ref{outline} to a high-level
description of our constructions, while in Section \ref{sec-from-all} we 
present them in detail. The full privacy analysis is presented in Section \ref{sec-priv-ana}. 
\ignore{The first scheme , in which we need all of the agents to reconstruct the current state of the computation is described in section~\ref{sec-from-all-details}. In section \ref{sec-from-t} we present two schemes  and , in which we need only a subset of the agents to reconstruct the current state of the computation. Sections \ref{sec-from-all-details} and \ref{sec-from-t} contain proofs of correctness and security.
} 

 
\section{Model and Definitions}
\label{sec-Prelim_and_outline}


A {\it finite-state automaton} (FSA) \A\ has a finite set of states
, a finite alphabet , and a transition
function . In this work we
do not assume an initial state or a terminal state for the automaton,
i.e., it may begin its execution from any state and does not
necessarily stop.

We already described in the previous section the distributed
computation setting---dealer, agents, adversary, and unbounded input
stream---under which the FSA is to be executed. In more detail, we
assume a {\em global clock} to which all agents are synchronized.  We
will assume that no more than one input symbol arrives during any
clock tick.  By {\em input stream}, 
we mean a sequence of input symbols arriving at a certain schedule of
clock ticks.  Abusing notation, we will sometimes refer to the input
without explicit reference to the schedule.  (We note that the global
clock requirement can in principle be removed if we allow the input
schedule to be leaked to \Ad.)
\ignore{
As in~\cite{DGGK11}, we consider a distributed computation setting in
which a party, which we refer to as {\it the dealer}, has an FSA \A\
which accepts an ({\it a priori} unbounded) stream of inputs  received from an external source. The dealer delegates the 
computation to a set of agents , by 
furnishing them with an implementation of \A.
The agents, each receiving
all the inputs for \A, execute their 
implementation of \A\ without communicating with each other, and,
at a given signal from the dealer, terminate the
execution, compute the current state of \A\ and return it as output. 
We will typically use  to refer to distributed computation 
schemes thus described.

We consider 
an adversarial model where an entity, 
called the adversary \Ad, is allowed to corrupt agents as the
execution of the protocol proceeds. We consider the so-called
{\em passive} or {\em semi-honest} adversary model, where corrupted
agents can combine their views in order to learn protected information,
but are not allowed to deviate from the protocol. Each agent can be
corrupted only once during an execution. \Ad\ can view the entire
contents of a corrupted agent's memory, but does not obtain any of the
global inputs. Incidentally, we consider event processing by an agent
as an {\em atomic operation}.  That is, agents cannot be corrupted
during an execution of  
state update.  This
is a natural and easily achievable assumption, which allows us to not
worry about some tedious details.  The computation is then considered
to be secure, if any two executions (possibly on different inputs and
initial states---defined more formally
below) 
are ``similarly'' distributed.  } 

We also
mentioned that \Ad\ is
allowed to corrupt agents as the execution of the protocol
proceeds. We consider the so-called {\em passive} or {\em semi-honest}
adversary model, where corrupted agents can combine their views in
order to learn protected information, but are not allowed to deviate
from the protocol. Furthermore, each agent can be corrupted only once
during an execution. When it does, \Ad\ can view the entire contents
of a corrupted agent's memory, but does not obtain any of the global
inputs. 

Incidentally, we consider event processing by an agent as an
{\em atomic operation}.  That is, agents cannot be corrupted during an
execution of
state update.  This
is a natural and easily achievable assumption, which allows us to not
worry about some tedious details.  The computation is then considered
to be secure, if any two executions (possibly on different inputs and
initial states---defined more formally
below) 
are ``similarly''
distributed.  

This model of security for distributed computation on unbounded input
streams was introduced by Dolev {\em et al.}~\cite{DGGK11} as the {\it
progressive corruption} model (PCM), allowing \Ad\ to be
computationally unbounded, and in particular requiring that the
distributions of the two executions (again, more formally defined
below) be identical.

In this work we use a variant of PCM, applying the following two
weakenings to the PCM definition:
\begin{newenum}
\item Rather than requiring that the distributions of executions be identical,
we require them to be {\em computationally} indistinguishable.
This means that we guarantee security only against polynomial-time-bounded
adversaries.


\item We 
require indistinguishability of executions for the {\em same} corruption
timeline (and, of course, different input streams).  This means that,
for example, agent IDs are now allowed to be included in the agents'
views. (We use agent IDs in one of our contructions.)
We stress that this is not a significant security weakening,
as essentially we only allow the adversary to differentiate among the
agents' identities;
the inputs and current state of the computation remain computationally
hidden.
\end{newenum}


We now present our amended PCM definition.  We first formalize the
notion of 
{\em corruption timeline} and  the view of the adversary.



\begin{definition}
A {\em corruption timeline}  is a sequence , where  are the
corrupted agents and  ()
 denote the time when the corresponding corruption took place.
The {\em length} of
a corruption timeline is .
\end{definition} 





We denote by  the probability
distribution of the aggregated internal states of corrupted agents at
the time of corruption, when executed on input  and
initial state .




\begin{definition} [\bf Computational Privacy in the Progressive Corruption Model]
\label{defProgressive}
We say that a distributed computation scheme  is {\rm
-private in the Progressive Corruption Model (PCM)} if for every
two states , polynomial-length input streams , and any corruption timeline , ,

\end{definition}
\noindent Here, `' denotes the computational indistinguishability
of two distributions.






\subsection{Tools and Building Blocks}
\label{sec:tools-app}
A pseudo-random generator (PRG) , where  and  are typically of the
form  and , respectively, for some positive
integers . Recall that PRGs are known to exist based on the
existence of one-way functions, and that the security property of a
PRG guarantees that it is computationally infeasible to distinguish
its output on a value chosen uniformly at random from  from a value
chosen uniformly at random from  (see,
e.g.,~\cite{Goldreich2000}). In our setting, we will further assume that
the old values
of the PRG seeds are securely erased by the agents upon use and hence are
not included in the view of the adversary.

The other basic tool that our protocols make use of 
is
{\em secret sharing}~\cite{Sha79}, where
essentially, a secret piece of information is ``split'' into shares
and handed out to a set of players by a distinguished player called
{\em the dealer}, in such a way that up to a threshold  of the
players pulling together their shares are not able to learn anything
about it, while  are able to reconstruct the secret. We
present the specific instantiations of secret sharing as needed
in the 
corresponding sections.
 
\section{Overview of Our Approach}
\label{outline}
Let  be a publicly known automaton with  states. We assume
that we have some ordering of the states of \A, which are denoted
by corresponding labels.  Every agent
stores the description of the automaton. In addition, during the
computation, for every state  of \A, every agent  computes
and stores its current label . 
As mentioned above, all agents receive a global input stream
 and perform computation in
synchronized time steps.

At a high level, the main idea behind our constructions is that the
state labels will be shares ({\em \`{a} la} secret
sharing~\cite{Sha79}) of a secret which identifies the currently
active state of .  More specifically, for each of the 
automaton states, the  state labels (held by the  agents) will
be shares of a  if the state is currently active, and shares of a
 otherwise.  We will show how the players' local computation on
their shares will ensure that this property is maintained throughout
the computation on the entire input stream .  When the input
stream  is fully processed (or a stop signal is issued), the
agents recover the current state by reconstructing the secrets
corresponding to each automaton state.  At the same time, shares of
the secrets (when not taken all together) reveal no information on the
current state of .


We now present additional high-level details on two variants of
the approach above. Recall that we consider the semi-honest adversary model, 
where corrupted players are not allowed to deviate from the protocol, but 
combine their views in order to learn protected information.

\vspace{-.1in}
\paragraph{-reconstruction.}  In this scenario, we require that all 
 agents participate in the reconstruction of the secret (corrupted
players are considered semi-honest and hence honestly provide their computed
shares).

At the onset of computation, the shares are initialized using an 
additive secret-sharing scheme, such that the initial state labels are the
sharing of , and labels of each of the other states are shares of .
When processing a global input symbol , each agent computes a
new label for a state  by summing the previous labels of all states
 such that .  It is easy to see that, due to the
fact that we use additive secret sharing, the newly computed shares
will maintain the desired
secret-sharing property.  Indeed, say that on input symbol
,  states transition into state .  If all of them
were inactive and their labels were shares of 's, then the newly computed 
shares 
will encode a  (as the sum of  zeros).  Similarly, if one of the 
predecessor states was active and and its label shared a , then  
the new active state  will also correspond to a share a .

A technical problem arises in the case of ``empty'' states, i.e.,
those that do not have incoming transitions for symbol , and
hence their labels are undefined. Indeed, to hide the state of the
automaton from the adversary who corrupts agent(s), we need to ensure that
each label is a random share of the appropriate secret.  Hence, we
need to generate a random -share for each empty state without
communication among the agents.








In the  sharing and reconstruction scenario, we will non-interactively
generate these labels pseudo-randomly as follows.  Each pair of
agents  will be assigned a random PRG seed  
Then, at each event (e.g., processing input symbol
), each agent  will pseudo-randomly generate a string
 using each of the seeds , and set the label of the
empty state to be the sum of all strings . 
This is done for each empty state independently.  The PRG
seeds are then (deterministically) ``evolved'' thereby erasing from the
agent's view the knowledge of the labels' provenance, and making them all
indistinguishable from random.  As all agents are synchronized with
respect to the input and the shared seeds, it is easy to see that the
shares generated this way reconstruct a , since each string  will be
included twice in the total sum, and hence will cancel out (we will use an
appropriate [e.g., XOR-based] secret-sharing scheme such that 
this is ensured.).


Finally, and intuitively, we observe that  PCM security
will hold since
the view of each corrupted agent only includes pseudo-randomly
generated labels for each state and the current PRG seed value.  As noted
above, even when combined with the views of other corrupted players, the labels
are still indistinguishable from random.

\vspace{-.1in}
\paragraph{-reconstruction.} In this scenario, up to  corrupted 
agents do not take part in the reconstruction (this is motivated by the
possibility of agents (UAVs) being captured or destroyed by the
adversary).  Agents who submit their inputs are doing so correctly.
Thus, here we require .

We will take our -reconstruction solution as the basis, and
adapt and expand it as follows.  First, in order to enable
reconstruction with  agents, we will use  additive
secret-sharing (such as Shamir's~\cite{Sha79}).  Second, as before,
we will use a PRG to generate labels, but now we will have a
separate seed for each subset of agents of size .  Then, at each
event (e.g., processing of an input symbol),
\ignore{
 
\textcolor{blue}{\todo{Lena: clock cycle with or without input letter}
VLAD: We need to agree on the detail how we schedule inputs. I think
it should be at most one input per clock cycle, right.  We should
write and justify it in the model section above.},
}
each agent ,
for each of the groups he belongs to, will update its shares by
generating a random -secret sharing of a  using the randomness generated by applying 
to the group's seed.  Then, agent  will use the share thus generated for
the -th agent as its own,
and set the label of the empty state to be the sum of all such shares.

Here we note that, since agents are excluded from some of the groups,
and that in this scenario up to  agents might not return their
state during reconstruction, special care must be taken in the
generation of the re-randomizing polynomials so that all agents have
invariantly consistent shares, even for groups they do not belong to,
and that any set of agents of size  enable the reconstruction of
the secrets.  (See Section~\ref{sec-from-t} for details.)
The above is done for each empty state independently.
As before, the PRG seeds are then (deterministically) evolved,
making them all indistinguishable from random.

\ignore{

{\bf -reconstruction using additively homomorphic encryption.}  In our third scenario, we will make use of additively homomorphic public-key encryption, such as Goldwasser-Micali~\cite{C:GolMic88} (for  reconstruction) or Paillier~\cite{EC:Paillier98}.

Our main idea here is to encrypt the state labels with the public key known to the dealer (or reconstructible by a threshold of players).  The output is then obtained by running a secure multiparty computation on the player's current states.   Now, during FSA computation, since the labels are encrypted, they hide the state update history, and empty states can be simply labeled with encryptions of  (for  reconstruction) and with Shamir shares of  derived from a single seed.

} 

\begin{algorithm*} [htb]
\caption{Template algorithm for agent , , for label 
and state update.\label{alg:updating}}
\label{algo:calc}
\begin{algorithmic}[1]
\REQUIRE An input symbol .
\ENSURE New labels for every state.
\IF{ is initialized} 
\STATE  (the sum is calculated over some field , depending on the scheme).
\ENDIF
\FOR {every  s.t. }
\STATE Compute  , where , and , .
\STATE .
\FOR { to }
\STATE , where  is a scheme-specific pseudo-random quantity.
\ENDFOR
\ENDFOR
\end{algorithmic}
\end{algorithm*}

\begin{remark}
{\em This approach reveals the length and schedule of the input
 processed by the players.  Indeed, the stored seeds (or more
precisely, their evolution which is traceable by the adversary simply
by corrupting at different times players who share a seed) do reveal
to the adversary the number of times the update function has been invoked.
We hide this information by
by requiring the agents to run updates at each
clock tick.
} 
\end{remark}



Algorithm~\ref{alg:updating} 
summarizes the update operations performed by agent  () during the -th clock cycle. The key point is the generation of
, the label re-randomizing quantity. Notice also that in every
clock cycle, there may or may not be an input symbol received by the
agent; if the agent did not receive any input, we assume that the
input symbol is not initialized.



\ignore{

\todo{VLAD: I haven't gone through the algorithm. I suspect it needs some care.}

\todo{need to add text explaining that add-randomness does, depending on the instance of the protocol... what does it do?}

\todo{add-randomness is not a good name}

\todo{Juan: I tried to simplify the notation, and made add-randomness explicit. I'll probably change it further once I go over the next section.}

} 

 
\section{The Constructions in Detail}
\label{sec-from-all}

\subsection{The -reconstruction protocol \label{sec-from-all-details}}
We start our formalization of the intuition presented above with the
case where all  out of the  agents participate in the state
reconstruction.  The protocol for this case, which we call , is presented
below.

\vspace{-.1in}
\paragraph{Protocol .} The protocol consists of three phases:

\vspace{.1in}

\noindent {\em Initialization.} The dealer secret-shares among the agents 
a secret value for each state, such that the value for the initial
state is  and for all the other states is . This is done as follows. 
Agent  () is given a a random binary string
, with the constraints that 
 
where  is the index of the initial state of the
computation, and for every , 

 
Each agent then proceeds to assign its state labels as
.


\vspace{.1in}
\noindent {\em Event Processing.}  Each agent runs Algorithm~\ref{algo:calc},
updating its labels and computing the new seeds for the PRG.  
Let  be the set of all possible agents' pairs. For line 8
of Algorithm \ref{algo:calc}, each agent  now computes



\begin{figure*} [ht]
\begin{center}
\includegraphics[width=7cm]{comp_scheme1}
\caption{\sl The internal state of agent  before a transition.}
\end{center}
\label{fig:comp_scheme1}
\end{figure*}

\vspace{.1in}
\noindent {\em Reconstruction.}  All agents submit their internal states to the
dealer, who reconstructs the secrets  corresponding to each state, by 
adding (mod 2) the shares of each state, and determines and outputs 
the currently active state (the one whose reconstructed secret is ).



\begin{figure*} [ht]
\begin{center}
\includegraphics[width=11cm]{comp_scheme2}
\caption{\sl The internal state of agent  after an  transition.}
\end{center}
\label{fig:comp_scheme2}
\end{figure*}

\vspace{.1in}
Before proving the correctness and privacy achieved by the protocol, 
we illustrate the operation of the online (Event Processing) phase
with the following example;
refer to Figures 1
and 2.
The two figures describe the execution of the
protocol
on an automaton with four states and two possible
inputs. 
Figure 1 presents the 
internal state of agent  after the -th clock cycle. 
The agent holds the original automaton and has a label for each of 
the four states, 
, ,  and
.



Figure 2
shows the changes in the agent's internal state compared to Figure 1
after the -th clock cycle. We also assume
that in this clock cycle the agents receive an input symbol
. The new labels for each state are the sum of old labels and
pseudo-random values. The labels in the sum are the old labels of
all the states that transition to the current state given the
input. Thus, the new  includes a sum of the old
 and the old , while the new
 doesn't include any labels in its sum because there is
no state that transitions to  after an  input. The 
pseudo-random addition to each state  is the sum .


We start by proving  the correctness of the construction.


\begin{proposition}
\label{prop-all}
At every Event Processing step of protocol's,
the secret corresponding
to the current state in the computation is  and for all other states 
the secret is .
\end{proposition}
\begin {proof}
The proof is
by induction on the number of steps  that the automaton performs, i.e., 
the number of clock cycles.

For the base case, if we consider the state of the protocol
after the initialization step and before the first clock cycle, i.e.,
at , then the statement is true by our definition of the label
assignments. Let us first consider the case where at the -th step
an input symbol  from  is received.  
Following the protocol,
agent 's new label for state  becomes


Consider now the next state of the computation in the automaton; we
wish to show that the secret corresponding to that state will be 1.
Let  be the index of the current state of the automaton, and
 be the index corresponding to the next state; by definition,
. Then, 
 
 

By the induction hypothesis, we know that 
 
and for , 
 

\noindent Thus, if we will sum over all the agents:



\noindent This is because in , 
every  appears exactly twice in this sum, once for
every 
element in . 
Using similar arguments one can see that all the other
states will resolve to 0.  

In the case that in the -th step no input symbol is received,
due to the fact that we just add the
random strings in the same way as in the case above,
we again get
that the secret corresponding to the current
state of the computation is 1, and for all others is 0.
\end {proof}


\begin{proposition}
\label{prop-pcm-all}
Protocol 
 is -private in the PCM model according to 
Definition~\ref{defProgressive}.
\end{proposition}
\begin {proofsk}
Recall that the underlying observation is that when a corruption takes place
(which cannot happen during the label-update procedure), the agent's state
includes the current labels and PRG seeds which have already been evolved, 
and hence cannot be correlated with the label shares previously
generated.

Without loss of generality, consider the case where \Ad\ corrupts
all but one agent according to an arbitrary corruption timeline,
and assume, say, agent  is not corrupted.  We argue that the 
view of the adversary is indistinguishable from a 
view corresponding to
(randomly) initialized agents  on the given automaton and
any initial state.  In other words, the view of the adversary is
indistinguishable from the view he would obtain if he corrupted the
agents simultaneously and before any input was processed.  Once we
prove that, the proposition follows.

The view of each corrupted agent includes  seeds that he shares
with other agents and the FSA labels which are secret shares of  or
a .  We argue that, from the point of view of the adversary,
these labels are {\em random} shares 
of either  or .  This follows
from the PRG property that an evolved seed cannot be correlated with
a prior output of the PRG, and from the fact that  remains uncorrupted.
Indeed, the newly generated ``empty'' states' labels look random since
the adversary cannot link them to the PRG seeds in his view.  The other
states' labels look random to the adversary since they are XORed
with 's label.

Thus, the total view of the adversary consists of random shares of
 and , and is hence indistinguishable from the one corresponding
to the initial state.
\end{proofsk}




We now calculate time and storage complexity of .
At every step of the
computation, each agent pseudo-randomly generates and XORs  strings.
Further, each agent holds a small constant-length label for each
automaton state, and  PRG seeds, yielding an

memory requirement.



\subsection{The -reconstruction protocol}
\label{sec-from-t}
Recall that in this case, up to  of the agents might not take part
in the reconstruction, and thus .


A straightforward (albeit costly) solution to this scenario would be to execute  independently for every subset of agents of size .  This would involve each agent  holding  copies of the automaton , one copy for each such subset which includes , and updating them all, as in , according to the same input symbol.  
Now, during the reconstruction, the dealer can recover the
output from any subset of  agents. The cost of this approach would be as follows.  Every agent holds  automata (one for every  tuple that includes this agent), and executes , which requires  memory, resulting in a total cost of ,
with the cost of computation per input symbol being proportional to storage's.
 

We now present , an improved  reconstruction scheme,
whose intuition was already presented in Section~\ref{outline}. The protocol
uses Shamir's secret-sharing scheme~\cite{Sha79}, which we now 
briefly review. Let  be a field of
size greater than ,
and  be the secret.
The dealer randomly generates coefficients  from
 and construct the following polynomial of degree ,
. 
The dealer gives each participant , , the value .  It can be easily seen that one can reconstruct the
secret from any subset of at least  points, and no information
about the secret is revealed by 
 points (or less).

\vspace{-.15in}
\paragraph{Protocol .} As before, the protocol consists of
three phases:

\vspace{.05in}
\noindent {\em Initialization.}  Using Shamir's secret sharing as
described above, the dealer shares a secret  for the 
initial state and  for all other states.
In addition, the dealer generates a random seed for every
set of  agents, and gives each agent the seeds for the sets it
belongs to. 
Let  be the set of all possible subsets of
 agents.


\vspace{.06in}
\noindent {\em Event Processing.} Each agent runs Algorithm~\ref{algo:calc} updating its labels, as follows.   
Let  and , , be a 
state of the automaton.  Upon obtaining value  (refer to Algorithm~\ref{algo:calc}),
the agents in  (individually) construct a
degree- polynomial, , by defining its value on the following
 field points: , all the points  such that ,
and  such that  is the minimal agent's index in  (the choice of 
which point in  is arbitrary). Now define , 
, and .

Observe that by this definition, {\em every} agent  can use
polynomial interpolation to compute , since the only required
information is  (and the knowledge of set membership).

Let polynomial  be defined as
. Each agent  now computes 
 (note that this is possible since the values corresponding to
sets the agent does not belong to is set to ), and updates the 
-th label, , in Algorithm \ref{algo:calc} by 
setting  in line .

\vspace{.06in}
\noindent {\em Reconstruction.} At least  agents submit their 
internal state to the dealer, who, for every , views the
-th labels of  agents as shares in a Shamir secret-sharing
scheme. The dealer reconstructs all the  secrets using 
the scheme's reconstruction procedure, and determines and outputs the
currently active state (whose recovered secret is equal to ).



\begin{proposition}
\label{prop-threshold}
At every Event Processing step of protocol , the shared secret
for the current state in the computation is  and for all the other
(inactive) states, the shared secret is . Furthermore,  agents
can jointly reconstruct all secrets.
\end{proposition}

\begin {proof}
We prove the proposition by induction on the number of clock cycles . We show that at each clock cycle , for every state , the  labels  are points on a degree  polynomial  whose free coefficient is  if  is the current state and  otherwise.

At initialization, the 
claim is true by our definition of the label assignments. 

Assume that the induction hypothesis is correct after . We prove
the hypothesis for the -th step. Assume first that in this step the
agents receive an input letter , and denote the current
state by . By our definition, the new label of the state 
of agent  is


\noindent or, equivalently,


For every , define polynomial  as

Therefore,  for every  and every . In
addition, since every  is of degree  and so is , we deduce
that  is also of degree . We finish proving the induction step by
showing that  only for the correct state.

Let . By induction, 
and  for any . Furthermore, by construction
, and therefore . Since  for any
, we have that  for any .

If the agents do not receive any input symbol in the -th clock cycle, 
then 
the claim follows by similar arguments as above.
\end {proof}



\begin{proposition}
\label{prop-pcm-tn}
 is -private in the PCM model according to Definition~\ref{defProgressive}.
\end{proposition}
\noindent At a high level, the proof follows the steps of the proof of 
Proposition~\ref{prop-pcm-all}. The full details of the privacy
analysis are presented in Section \ref{sec-priv-ana}.



We now calculate the costs incurred by the protocol.  The space
complexity of each agent is as follows. An agent holds a label for
every state, i.e. 
bits. Additionally every agent holds  seeds, where every seed is of size . Thus, in total we have 
bits. Each step of the Event Processing phase requires  time for seed manipulation and field
operations. Reconstruction (by the dealer)
is just interpolation of  polynomials of degree .

\newpage
\section*{Supplementary Material:}
\section{Privacy Analysis in Detail \label{sec-priv-ana}}

\ignore{
\todo{I started reading the proofs but got confused a little.  I modified and moved the definitions part to prelims.  I wrote my own proofs in previous sections.  I am not 100\% convinced by my proofs, so please adjust and/or check if they make sense. I think the rest of this section can go.

 Also, you guys pay a lot of attention to the PRG syntax (and other minute details).  Usually in crypto papers it is taken for granted, and people don't write it all out.}

} 
We show that each of our schemes in Sections
\ref{sec-from-all-details} and \ref{sec-from-t} is computationally
private in the PCM in two stages. In the first stage we construct for
each scheme  and every possible corruption timeline  an
intermediate scheme, . We prove that if the corruption
timeline is  then the view of an adversary in  is
independent of the state of the automaton. In other words, the
adversary's view is distributed identically for any initial state and
any sequence of input symbols.

In the second stage we prove that the view of an adversary in 
with {\em any} efficiently constructible corruption timeline 
and any efficiently constructible input stream is computationally
indistinguishable from the adversary's view in . We
deduce that  is computationally private in the PCM.

\subsection{Constructing }

\begin{notation}
Let  denote the scheme of Section \ref{sec-from-all} that
requires all the agents for reconstruction, and let  
and 
denote the threshold schemes of Section \ref{sec-from-t}. We say that
an adversary is {\em appropriate} for the scheme  if it
corrupts at most  agents. We say that an adversary is {\em
appropriate} for the  and  if schemes it corrupts
at most  agents.
\end{notation}


Let  be one of the schemes  or .  defines initial data that an agent  stores: a description of the automaton, a label for each node in the automaton and random seeds that are shared with other agents. For each scheme the domain of seeds is  while the domain of labels is a field . For example, in  the field is . The subsets of agents that share a single seed are specific to each scheme. The description of  follows.

\smallskip
\noindent
{\bf Initialization:} An agent  is initialized with a description of the automaton as in . For every subset of agents  such that , if the agents in  share a seed in  that other agents do not have then  is initialized with  elements, , .  is chosen uniformly at random from , while  are chosen uniformly at random and independently from .  computes the initial label of the -th state (indexed from  to ) over  as 

for fixed coefficients .

The agent stores  but ,, are deleted.

\smallskip
\noindent
{\bf Processing:} Each of the schemes  defines data processing for every clock cycle. This processing includes computing new values for each seed and new values for each node label. 

Computing new labels and seeds in  depends on the corruption timeline , which is defined by a sequence  such that the adversary corrupts agent  at time  for  and . 

An agent  in  begins updating  only after the corruption of the first agent  that holds . Therefore, at any time , , we have that . If  the agent modifies  as  specifies for updating a seed.
 
An agent  in  begins updating a state label  only after  is corrupted at time . Therefore, when the adversary corrupts  it obtains the original label . For every clock cycle after  the agent modifies  as  specifies for updating a label.

\subsection{Privacy of }
We show that if the corruption timeline is fixed to  then  is private in the information-theoretic sense. In order to do so, we introduce the following definition and lemma.
\begin{definition}
Let  be a set of agents, let  be a hypergraph and let  be a finite field. We call  a {\em distribution hypergraph}, if for every , there is an element  chosen uniformly from , such that every  holds  and every  has no information on .
\end{definition}

\begin{lemma} 
\label{prop-privacy}
Let  be a set of agents and let  be a distribution hypergraph over a finite field . Assume that each agent  uses a fixed set of public elements , such that ,  to compute a label 

Assume that an adversary that corrupts an agent  obtains both the agent's label  and its random strings  for all  such that  and its . Then, the label of any uncorrupted agent  is distributed independently of the adversary's view if and only if for any subset of agents  that the adversary corrupts and for any agent , there exists a hyper-edge , such that  and . 
\end{lemma}

\begin {proof}
Let  be an agent such that  and there exists a hyper-edge , such that  and . Since  is chosen uniformly at random from , which is a field, and  we have that  is distributed uniformly at random in  and furthemore  is independent of the adversary's view.  

Conversely, assume that there exists an agent  such that for every , there exists an agent , ,  such that . Then, the adversary obtains  for every  such that  and can therefore compute  without corrupting .
\end {proof} 



\begin{proposition}
\label{prop:priv_intermediate}
For each of the three possible schemes  and every corruption timeline , if the adversary is appropriate for the scheme   then  is private in the following sense. For  every two states  and for any two input streams ,
. Furthermore, all the state labels are random and independent elements in a finite field .
\end{proposition}
\begin{proof}
The view of an adversary  is made up of the description of the automaton, the seeds and the labels. All of these are obtained from an agent at the moment of corruption. The description of the automaton is static. The distribution of the seeds depends only on  and as a consequence is independent of the initial state  and the input stream .

Therefore, the only data elements in the adversary's view that could depend on the initial state and the input stream are the state labels. 

However, just prior to the adversary corrupting an agent , since the adversary is {\em appropriate} there is a subset of uncorrupted agents  such that  and all agents in  share a seed that is not known to any agent outside . In , an appropriate adversary corrupts a total of at most  agents and just prior to corrupting an agent there are at least two uncorrupted agents. By the definition of  this pair of agents, which we denote by , shares a seed. Therefore, by the definition of  the two agents share the elements , which are all random and independent of the adversary's view. Such subsets  of uncorrupted agents also exist in  and . 

By the construction of , before the corruption of , the state labels of  have their initial value  and therefore, by Lemma \ref{prop-privacy} these labels are random and independent of the adversary's view.

Therefore, the adversary's view in  with corruption timeline  is distributed identically for any initial state  and any input stream .
\end{proof}

\subsection{Computational Privacy of  and }

We complete the analysis by proving that  and  are computationally private in the PCM. 

\begin{notation}
Let  be a security parameter, let  be a field and let  be a polynomial. Let  and  be parameters such that  and let  be a pseudo-random generator. Denote the uniform distribution on  by . 

\end{notation}

We regard  as a random variable that represents the whole view of the adversary in  and regard  as a reduction of that view to the first  clock cycles. Similarly,  represents the adversary's view of the first  clock cycles in .

\begin{notation}
Let  be one of the schemes  or . For every  define  to be a hybrid scheme which is identical to  for any clock cycle  such that  and is identical to  for any clock cycle  such that . Define a sequence of random variables  as follows. Select an arbitrary initial state , select an input stream  from  and select a corruption timeline  from .  is the view of an adversary for the scheme  given the choices of ,  and .
\end{notation}

It follows from the definition of the schemes  that  is  and  is . Therefore,  and . 

Note that  is well defined for any  since the memory contents and the inputs of  and  are all in the same domain (although the distribution of the memory contents is not identical). The only difference between  and  is the processing at each clock cycle. 


\begin{proposition}
\label{prop:indis_pi_int}
Let  be one of the schemes  or . If the adversary is appropriate for  then  for  any initial state , any efficiently constructible corruption timeline  and any efficiently constructible input stream . 
\end{proposition}
\begin{proof}
We assume towards a contradiction that the views of an adversary in  and in  are not computationally indistinguishable.
Therefore, there exist a probabilistic, polynomial time algorithm  and a polynomial  such that 

for an infinite number of values .  denotes  and  denotes .


We construct an algorithm  that distinguishes between  independent samples of  and  independent samples of  for a random . Since  is at most a polynomial in , the algorithm  contradicts the assumption that  is a pseudo-random generator, thus proving the proposition. Denote the distribution on  independent samples of  by  and denote the distribution on  independent samples of  by .

\medskip
\noindent
{\bf Description of :} the algorithm receives as input a description of the automaton, ,  and . In addition, the algorithm receives as input a binary string  of length  and decides whether it is chosen from  or  by performing the following steps.
\begin{enumerate}
\item Choose a random initial state , select an input stream  from  and select a corruption timeline  from .
\item Choose a random  in the range .
\item Simulate the operation of the agents  in the scheme  for the first  clock cycles.
\item In the -th clock cycle all the agents that have already been corrupted, i.e. in cycles  to , execute  (which is identical to  for a corrupted agent). For any uncorrupted player, including those that are corrupted in the -th cycle do the following:
\begin{enumerate}
\item Update any seed that is shared with a corrupted player as specified by  (which is identical to the update process of  for such seeds).
\item For any seed that is shared by set of uncorrupted agents , select a fresh string of length  from  and parse it as  for  and . Replace the previous seed with . 
\item Recall that in every  the label of the -th state, , is updated by a linear combination of previous state labels and of elements  derived from expanded seeds.  updates the label in a similar way, except that for every  such that  is shared by uncorrupted agents,  is selected from  as described in the previous step instead of being selected from an expanded seed.  
\end{enumerate}
\item Simulate the operation of the agents  in the scheme  for the last  clock cycles.
\item Throughout the simulation of the agents simulate the actions of an adversary with corruption timeline .
\item Run  on the adversary's view and return the result of .
\end{enumerate}

We argue that if  is chosen from  then the view of the adversary that  simulates is , while if  is chosen from  then the view of that adversary is . Obviously, the view that the adversary obtains in the first  clock cycles is identical to the view in  and the view in the last  clock cycles is identical to the view in . Therefore, we need to prove that the view in the -th clock cycle is identical to  if  is uniformly random and identical to  if  is selected from .

 specifies identical processing to  for corrupted agents and seeds shared by corrupted agents. Therefore, the  differences are in seeds that are shared only by uncorrupted agents and in state labels of uncorrupted agents. 

In the -th clock cycle,  replaces seeds that are shared by uncorrupted agents with strings selected from . If  is uniformly random then these seeds are uniformly random. Therefore, in this case the distribution of the seeds is identical to the distribution if  is executed in the previous clock cycle, . If  is a sequence of elements of the form , where  is random, then the new seed,  is exactly as specified by  after a single clock tick. That is the expected distribution if the agents run  in the previous clock tick, .

The state labels are updated by a linear combination in which the coefficients of each  are non-zero. If  is uniformly random then each  is a random field element in  and therefore each state label is a a random field element in . By Proposition \ref{prop:priv_intermediate} that is identical to the distribution of state lables in . If  is a sequence of elements of the form , where  is random, then the new label is exactly as specified by  after a single clock tick.

The argument above shows that once  is given,  distinguishes between a sequence of uniform elements and a sequence of pseudo-random elements with the same probability that  distinguishes between  and . Since  is chosen randomly in the range  and since  and  we have that 

and


Therefore,


	 
for an infinite number of values . Since  distinguishes between  and  we deduce that  is not a pseudo-random generator and have thus reached a contradiction.
\end{proof}

\begin{theorem}
If the adversary is appropriate then the schemes  and  are all computationally private in the PCM. 
\end{theorem}
\begin{proof}
By proposition \ref{prop:indis_pi_int} if the adversary is appropriate then for every efficiently constructible corruption timeline , , every two initial states  and every two efficiently constructible input streams , such that  we have  and .

By Proposition \ref{prop:priv_intermediate} we know that
. Therefore,

\end{proof}

\ignore{
\subsection{Minimizing the number of the seeds}
\todo{VLAD: this sect. needs to be reworked}
In the first scheme which was described in \ref{sec-from-all}, as the seed distribution we used a clique on  vertices . In total we needed  seeds. 
An interesting question is, are we able to minimize our number of seeds. By proposition \ref{prop-privacy}, in the first scheme, if we know that our adversary can catch at most  agents, then a -regular graph would be enough and will be necessary. Such a graph will have  edges.
What can we say about the second scheme?
}


{\small

\begin{thebibliography}{99}

\bibitem{BDDS10} O.\ Ben-Shahar, S.\ Dolev, A.\ Dolgin, and M.\ Segal,
\newblock ``Direction Election in Flocking Swarms'', 
\newblock \textit{Proc. of the DIALM-POMC Joint Workshop on Foundations of Mobile Computing}, pages 73-80, 2010.


\bibitem{BGW88}
M.\ Ben-Or, S.\ Goldwasser and A.\ Wigderson,
\newblock ``Completeness theorems for non-cryptographic fault-tolerant distributed computation'',
\newblock {\it Proc. of the 20th annual ACM symposium on Theory of computing} (STOC), pages 1-10, 1988.

\bibitem{Bamberger}
R.\ Bamberger Jr., D.\ Watson, D.\ Scheidt, and K.\ Moore,
``Flight Demonstrations of Unmanned Aerial Vehicle Swarming Concepts'',
{\em Johns Hopkins APL Technical Digest}, 27(1):41--55, 2006.

\bibitem{CCD88} D.\ Chaum, C.\ Cr\'{e}peau and I.\ Damg{\aa}rd,
``Multiparty unconditionally secure protocols'', {\it Proc. of the 20th annual ACM symposium on Theory of computing} (STOC), pages 11--19, 1988.

\bibitem{DGKPS10}
S.\ Dolev, N.\ Gilboa, M.\ Kopeetsky, G. Persiano, and P. Spirakis ``Information Security for
Sensors by Overwhelming Random Sequences and Permutations'', \textit{Proc. of the DIALM-POMC Joint Workshop on Foundations of Mobile Computing)}, 2010. Poster in \textit{Proc. of the 17th ACM Conference on Computer and Communications Security}, (CCS), 2010.

\bibitem{DGGK09}
S.\ Dolev, J.\ Garay, N.\ Gilboa, V.\ Kolesnikov,
``Swarming Secrets'',
{\it 47th Annual Allerton Conference on Communication, Control, and Computing,}
2009. Also brief announcment in {\it Proc. of the 29th Annual ACM Symposium on Principles of Distributed Computing} (PODC), 2010.

\bibitem{DGGK11}
S.\ Dolev, J.\ Garay, N.\ Gilboa, V.\ Kolesnikov,
``Secret Sharing Krohn-Rhodes: Private and Perennial Distributed Computation'',
{\it Innovations in Computer Science}, (ICS), pages 32-44, 2011.

\bibitem{DKS07} S.\ Dolev, M.\ Kopeetsky, and A.\ Shamir,
\newblock ``RFID Authentication Efficient Proactive Information Security within Computational Security'',
\newblock  {\it Theory Comput. Syst}, 48(1):132-149, 2011.


\bibitem{DLY07} S.\ Dolev, L.\ Lahiani, M.\ Yung,
\newblock ``Secret Swarm Unit Reactive -Secret Sharing'',
\newblock {\it Ad Hoc Networks}, 10(7):1291-1305, 2012.



\bibitem{DBLP:conf/stoc/Gentry09}
C. Gentry ``Fully homomorphic encryption using ideal lattices'', {\it Proceedings of the 41st Annual ACM Symposium on Theory of Computing} (STOC), pages 169-178, 2009.

\bibitem{DBLP:conf/stoc/GoldreichMW87}
Oded Goldreich, Silvio Micali, and Avi Wigderson.
\newblock ``How to play any mental game or a completeness theorem for protocols
  with honest majority'',
\newblock {\it Proc. of the 19th Annual ACM Symposium on Theory of Computing} (STOC), pages 218--229, 1987.

\bibitem{Goldreich2000} O. Goldreich,
\newblock {\it Foundations of Cryptography: Basic Tools}, Cambridge University Press, 2000.

\bibitem{EC:Paillier98} P. Paillier, ``Public-Key Cryptosystems Based on Composite Degree Residuosity Classes'', \textit{Advances in Cryptology - EUROCRYPT, International Conference on the Theory and Application of Cryptographic Techniques}, pages 223-238, 1999.


\bibitem{PW00}
B.\ Pfitzmann and M.\ Waidner.
\newblock ``Composition and integrity preservation of secure reactive systems'',
\newblock {\it Proc. of the 7th ACM conference on Computer and Communications Security} (CCS), pages 245--254, 2000.


\bibitem{Sha79} A.\ Shamir. 
\newblock ``How to Share a Secret'',
\newblock {\it Communications of the ACM,} vol. 22(11):612-613, 1979.



\end{thebibliography}

} 
\appendix



\end{document}
