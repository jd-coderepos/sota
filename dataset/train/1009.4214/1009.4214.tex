\documentclass{article}
\usepackage{algorithm}
\usepackage[noend]{algorithmic}
\usepackage{amsmath, amssymb}
\usepackage{qtree}
\usepackage{graphicx}
\usepackage{url}
\usepackage{comment}
\usepackage{amsthm}

\title{A Versatile Algorithm to Generate Various Combinatorial Structures}
\author{Pramod Ganapathi\thanks{Associate Software Engineer, IBM, India; pramodghegde@in.ibm.com}, Rama B\thanks{Graduate Student, Department of Computer Science and Automation, Indian Institute of Science, India; ramab@csa.iisc.ernet.in}}

\def\eg{{\it e.g.\ }}
\def\etc{{\it etc}}
\newtheorem{defn}{Definition}
\newtheorem{theorem}[defn]{Theorem}
\newtheorem{lemma}[defn]{Lemma}
\newtheorem{proposition}[defn]{Proposition}
\newtheorem{corollary}[defn]{Corollary}

\begin{document}

\thispagestyle{empty}

\label{firstpage}
\maketitle 
\begin{abstract}
Algorithms to generate various combinatorial structures find tremendous importance in computer science. In this paper, we begin by reviewing an algorithm proposed by Rohl~\cite{rohl1} that generates all unique permutations of a list of elements which possibly contains repetitions, taking some or all of the elements at a time, in any imposed order. The algorithm uses an auxiliary array that maintains the number of occurrences of each unique element in the input list. We provide a proof of correctness of the algorithm. We then show how one can efficiently generate other combinatorial structures like combinations, subsets, -Parenthesizations, derangements and integer partitions \& compositions with minor changes to the same algorithm.
\end{abstract}

\floatname{algorithm}{Procedure}

\section{Introduction}
\label{sec:intro}

Algorithms which generate combinatorial structures like permutations, combinations, etc. come under the broad category of combinatorial algorithms~\cite{book_KrSt}. These algorithms find importance in areas like Cryptography, Molecular Biology, Optimization, Graph Theory, etc. Combinatorial algorithms have had a long and distinguished history. Surveys by Akl~\cite{selim_combsurvey}, Sedgewick~\cite{sedgewick_perm}, Ord Smith~\cite{ordsmith_1,ordsmith_2}, Lehmer~\cite{lehmer_tricks}, and of course Knuth's thorough treatment~\cite{knuth_perm,knuth_fas3}, successfully capture the most important developments over the years. The literature is clearly too large for us to do complete justice. We shall instead focus on those which have directly impacted our work.

The well known algorithms which solve the problem of generating all  permutations of a list of  unique elements are Heap Permute~\cite{heap_permute}, Ives~\cite{ives_perm} and Johnson-Trotter~\cite{trotter_perm}. In addition, interesting variations to the problem are - algorithms which generate only unique permutations of a list of elements with possibly repeated elements, like \cite{bratley_unique, chase_unique, sag_repetitions}, algorithms which generate permutations in lexicographic order, like \cite{smith_lexico1, schrack_lexico, shen_lexico} and algorithms which genenerate permutations taking  elements at a time. With regard to these variations, the most complete algorithm, in our opinion, is the one proposed by Rohl~\cite{rohl1} which possesses the following salient features:
\begin{enumerate}
\item Generates all permutations of a list considering some or all elements at a time
\item Generates only unique permutations
\item Generates permutations in any imposed order
\end{enumerate}
It is of course possible to extend any permutation generating algorithm to exhibit all of the above features. However, when such naive algorithms are given inputs similar to \emph{aaaaaaaaaaaaaaaaaaab}\footnote{There are 20 unique permutations of length 20}, the number of wasteful computations can be unmanageably huge. Clearly, the need for specially tailored algorithms is justified.

We provide a rigorous proof of correctness of Rohl's algorithm. We also show interesting adaptations of the algorithm to generate various other combinatorial structures efficiently.

The paper is organised as follows: we begin by introducing terminologies and notations that will be used in the paper in Section~\ref{sec:prelim}, and presenting Rohl's algorithm in Section~\ref{sec:algo}. Section~\ref{sec:anal} contains a detailed analysis of the algorithm, which also includes the proof of correctness of the algorithm (missing in Rohl's paper). We then present various efficient extensions of Rohl's algorithm in Section~\ref{sec:exten}, to generate many more combinatorial structures.

Rohl's algorithm involves two stages. The first stage builds up an auxiliary array that maintains the number of occurrences of each unique element in the input list. The second stage uses this auxiliary array to effect and generates the required combinatorial structure. We present a recursive representation of the algorithm. It would be quite easy to transform the recursive version to an iterative one~\cite{rec2iter}.

\section{Preliminaries}
\label{sec:prelim}

In this section, we introduce the key terms, concepts and notations that will be used in the paper.

\subsection{Basic Definitions} 

\noindent \textbf{Set:} A collection of elements without repetitions

\noindent \textbf{List:} A collection of elements possibly with repetitions

\noindent \textbf{Permutation:} A permutation of a list is an arrangement of the elements of the list in any order, taking some or all elements at a time \\
E.g: Consider a list ; Various permutations are - , , , , , 

\noindent \textbf{-Permutation Set:} The -permutation set of a list is defined as the set of all possible -permutations of the list, where an -permutation is defined as a permutation taking exactly   elements at a time\\
E.g: Consider a list . We get: ,  and , , , , , \footnote{Each permutation in an -permutation set is actually a list of elements. For compactness, we represent the elements in concatenated form.} as the -permutation set, -permutation set and -permutation set, respectively.

The algorithm takes as input:
\begin{itemize}
 \item A list of  elements to permute, called input list:  containing  unique elements
 \item An integer , , which denotes the number of elements to be taken at a time during permuting
 \item A set of  elements which are actually the  unique elements of  in a particular sequence, called Order Set (or just Order): 
\end{itemize}

It produces as output the -permutation set of , which is a set of  -permutations:  where each  is in turn is a list of  elements:  ). The algorithm works such that  follows the order  (definition and explanation in Section~\ref{sec:order}). Quite obviously, . Note that we use the terms -permutation ({set}) and permutation ({set}) interchangeably, if clear from the context.

\subsection{Order of Permutation Set}
\label{sec:order}

Consider the -permutation set of the list , , , , , . We see that the permutations are in lexicographic order, i.e they follow the order . At the same time, the -permutation set \{, , , , , \} follows the order . We shall now introduce a formal definition of what we mean when we say   follows the order .

\noindent \textbf{Discriminating Index:} The discriminating index between two different -permutations is the first (minimum) index in both permutations at which the elements differ from each other. Given two permutations  and , we denote the discriminating index as 

Also, assume that  denotes the index of the element  in . Thus .

 is said to \emph{follow} an order  if:
\begin{itemize}
\item 
\item  For every pair of permutations in , the elements at the discriminating index have the same positions relative to each other in , as do the pair of permutations in  \\

\end{itemize}

where . It has to be noted that similar definitions hold for both sets of combinations and derangements too.

\subsection{Auxiliary Array}
\label{hashorder}

Central to the algorithm is an auxiliary array denoted as . It is an array of integers built in such a way that [] gives the number of occurrences of element  in the {input list }.  is of size  as it is maintained parallel to .

As an example, consider , ; here  and . We have  (= c) occurring twice,  (= a) occurring thrice and  (= b) occurring once. Thus we must have . Instead, if we had , we would have .

\section{The Algorithm}
\label{sec:algo}

In this section, we introduce the algorithm. The algorithm takes ,  and  as input and produces  as output, while ensuring that  follows . The first stage involves building  while the second stage involves recursive generation of  using .

\subsection{Building }

The first stage involves building  parallel to  in a way that  is an integer which represents the number of occurrences of  in . Procedure~\ref{countarray} is a pseudocode representation of how to build , given  and . We assume the existence of the function  which takes an element of  as a parameter and returns the position of the element in . We can say . A naive implementation of  would be to perform a linear search over , and this would have a worst case runtime of . However, if needed, we can achieve  runtime using hash functions. We leave the implementation details to the reader.

\begin{algorithm}
\caption{: Building }
\label{countarray}
\begin{algorithmic}[1]
 \STATE \textbf{Input:}  and 
 \STATE \textbf{Output:} 
 \medskip
 \STATE 
 \FOR{  to }
	\STATE 
	\STATE 
 \ENDFOR
\end{algorithmic}
\end{algorithm}

\subsection{Generating Permutations}

Procedure~\ref{countarray} builds . The second stage involves using the recursive routine APR to generate , following order , as output. To this end, we use an output array .

Procedure~\ref{permute} is a pseudocode representation of APR. It assumes non-local existence of the following: , , ,  and . Also, it has a local parameter - an integer . Thus the function's header takes the form \textbf{APR()}. It is invoked by the function call APR(1). As APR recursively calls itself (),  is populated using .

\begin{algorithm}
\begin{algorithmic}[1]
\caption{: APR() - Permutations}
\label{permute}
\STATE \textbf{Local:} 
\STATE \textbf{Global:} , , ,  and 
\medskip
\IF{}
	\STATE Print 
	\RETURN
\ELSE
	\FOR{ to }
		\IF{} \label{proc:apr:line:cond}
			\STATE  
			\STATE 
			\STATE APR()
			\STATE 
		\ENDIF
	\ENDFOR
\ENDIF
\end{algorithmic}
\end{algorithm}

\section{Algorithm Analysis}
\label{sec:anal}

In this section, we begin by explaining how APR works and showing the recursion tree for a particular example. We then give a formal proof of its correctness. We conclude by establishing an upper bound on the runtime of APR.

We know that the contents of  are constantly changing. Given a particular index in  we assign to it an element  only if , at that particular time. We call the assignment \emph{minimal} if we choose the  corresponding to the minimum  for which . More formally, we can say that an assignment of  to a particular index in  is minimal iff  such that . Also we say \emph{populates  minimally} to signify that minimal assignment is done at every index from  to  (inclusive).

\subsection{Recursion Tree}
\label{subsec:rectree}

Let us analyse how APR functions by referring to Procedure~\ref{permute}. The function, at any recursion level, begins by searching for the first available element, i.e. the first index  at which  (lines 7-8). Once found, the corresponding element () is assigned at the current index in  (line 9). It then decrements  to reflect the fact that that particular element was assigned (line 10). After that, there is a recursive call and the control moves to the next recursion level and deeper thereafter performing the same set of functions (lines 7-10). Once the control returns to the current recursion level, it de-assigns the element that was assigned to the current index in , by incrementing  (line 10). It then moves to the next available element in  and performs the process of assigning and recursion all over again.

\begin{figure*}[!htp] \centering
{\scriptsize \Tree [.{CA = \{2,2\} \\  \\ \textbf{APR(1)}} 
	[.{index=1 \\ CA = \{1,2\} \\  \\ \textbf{APR(2)}} 
		[.{index=2 \\ CA = \{0,2\} \\  \\ \textbf{APR(3)}}
			 [.{index=3 \\ CA = \{0,1\} \\  \\ \textbf{APR(4)}} 
				[.{index=4 \\ \fbox{}} ] ] ]
		 [.{index=2 \\ CA = \{1,1\} \\  \\ \textbf{APR(3)}}
			 [.{index=3 \\ CA = \{0,1\} \\  \\ \textbf{APR(4)}}
				 [.{index=4 \\ \fbox{}} ] ] 
			[.{index=3 \\ CA = \{1,0\} \\  \\ \textbf{APR(4)}} 
				[.{index =4 \\ \fbox{}} ] ] ] ]
	 [.{index=1 \\ CA = \{2,1\} \\  \\ \textbf{APR(2)}}
		 [.{index=2 \\ CA = \{1,1\} \\  \\ \textbf{APR(3)}}
			 [.{index=3 \\ CA = \{0,1\} \\  \\ \textbf{APR(4)}}
				 [.{index=4 \\ \fbox{}} ] ]
			 [.{index=3 \\ CA = \{1,0\} \\  \\ \textbf{APR(4)}} 
				[.{index=4 \\ \fbox{}} ] ] ]
		 [.{index=2 \\ CA = \{2,0\} \\  \\ \textbf{APR(3)}}
			 [.{index=3 \\ CA = \{1,0\} \\  \\ \textbf{APR(4)}} 
				[.{index =4 \\ \fbox{}} ] ] ] ] ]}
\caption{Recursion Tree of APR for ; ; }
\label{rectree}
\end{figure*}

 We venture an example to better illustrate the process. Assume we have ,  and . When  and  are fed to Procedure~\ref{countarray}, we would obtain [1] = [2] = 2. Procedure~\ref{permute} is then invoked. The recursion tree that would be obtained is shown in Figure~\ref{rectree} ( is abbreviated to CA). The root of the tree represents the initial state, i.e.  and . Every descendant of the root represents a particular recursion depth, indicated by the value of . At every node, we indicate the values in  and  just before going down to the next recursion level followed by the function call that initiates the next recursion level. Once we go four levels deep into the recursion, i.e. , the contents of  would be output because  (lines 3-4 of Procedure~\ref{permute}). The control then returns to the previous recursion level (line 5). We observe that , i.e. the collection of all leaves of the recursion tree from left to right, follows the order .

\subsection{Proof of Correctness}
\label{subsec:proof}

In this section, we shall use  to denote a general -permutation instead of . Also, we shall use , instead of , to denote the  element of the  permutation.

\begin{theorem}
 The algorithm generates only valid permutations of .
\end{theorem}

\begin{proof}
 We assign an element  to any particular index in  only if we have . Also, we decrement or increment  whenever  is assigned or de-assigned, respectively. This process ensures that APR only assigns elements that were actually present in  and no element is assigned more times than it occurs. Hence we can say that every permutation that is output is valid.\end{proof}

\begin{theorem}
\label{thm:unique_order}
The algorithm generates only unique permutations of  following order .
\end{theorem}

Before we prove Theorem~\ref{thm:unique_order}, we must understand how the algorithm generates a permutation subsequent to an already generated one. Once a permutation is output, the program searches backwards from the end of  for an index where it can assign, from the available elements, an element that has a \emph{higher} position in  than the previously assigned element. This means that, if  were assigned at a particular index, the algorithm checks if it can assign any among  at the same index. At the \emph{first instance} (referred to as Property 1) of such an index, the algorithm assigns the \emph{first among} (referred to as Property 2) , whichever is available. Note that this index would be the discriminating index between the previously output permutation and the next permutation that is going to be output. Once this is done, the program \emph{populates the rest of  minimally} (referred to as Property 3).

\begin{proof}[Proof of Theorem~\ref{thm:unique_order}]
This process ensures that, between two consecutive permutations, we will have at least one index where the elements differ. Given that at this index, i.e. discriminating index, we assign one of , we can be sure that the permutation generated subsequent to a particular permutation will occupy a higher position in  (when it follows order ). \end{proof}

\begin{lemma}
\label{lemma:disc}
 Given three consecutive permutations ,  and , we have: \\ .
\end{lemma}

\begin{proof}
 This shall be proved by contradiction. Let us assume we have , ,  such that

where  represent each of , , , respectively. By the definition of discriminating index in Section~\ref{sec:order}, we have the following equations.

and

From equations \ref{eqn:contrad1} and \ref{eqn:eqp2},  we can say . By using this in equation~\ref{eqn:disc1}, we get

Also, from equations \ref{eqn:eqp1} and \ref{eqn:eqp2} and equation \ref{eqn:contrad1}, we get

Equations \ref{eqn:finp1} and \ref{eqn:finp2} imply that  comes before , when order of consideration is , which is a contradiction to the order of the permutations. This in turn implies that the initial assumption is wrong. \end{proof}

\begin{corollary}
\label{corr:disc}
.
\end{corollary}

\begin{proof}
 Equations \ref{eqn:eqp1} and \ref{eqn:eqp2} follow from the definition of discriminating index. From Lemma~\ref{lemma:disc} we have , thus we get

Thus the corollary follows. \end{proof}

\begin{lemma}
\label{lemma:nextperm}
 Given two successive permutations that APR generates, say  and , : such that  occurs between  and .\footnote{ Denotes  excluding  and }
\end{lemma}

\begin{proof}
This shall be proved by contradiction. Assume there exists such a . Let us take ,  and . By the analysis of how APR generates a permutation subsequent to an already generated one

 Also we have  from Lemma~\ref{lemma:disc} and  from Corollary~\ref{corr:disc}. Thus  is the only possibility.

For  to be between  and : . This is a direct contradiction to Property 2. Thus we can have no  in between  and . \end{proof}

\begin{theorem}
 The algorithm generates all -permutations of .
\end{theorem}

\begin{proof}
 We begin by proving that APR correctly generates the first permutation. By Lemma~\ref{lemma:nextperm}, we have proved that the process of generating the next permutation given the current one is accurate in that the immediate next permutation, in accordance with the order , is generated. We then prove that APR terminates once all permutations are generated.

At the beginning of the algorithm, we perform a minimal assignment at the first index, i.e. . The program then moves down a recursion level and once again performs a minimal assignment. This process continues until the last recursion level. In the  recursion level, the program outputs the permutation. Clearly the first permutation that would be output by APR would be formed by populating  minimally.

The program control returns from a level of recursion only after looping in  is complete, i.e. when there are no more available elements that can be allotted at that corresponding index in . We know that the range  is finite because the size of  is finite. Also the maximum recursion depth of the program is finite because  is finite. This would ensure that every recursion level would eventually end which in turn ensures that the program will eventually terminate. \end{proof}

\subsection{Running Times}
\label{sec:anal:subsec:runtime}

To establish an upper bound on the running time of APR, let us analyse the recursion tree shown in Figure~\ref{rectree}. We see that the number of leaves are exactly equal to the number of unique -permutations of , i.e. . Each of the leaves are exactly  levels below the root. The critical operations, i.e. looping and searching for available elements, are done on the first  levels.\footnote{In the  level, the permutations are output.} At each level, we loop in the range . Thus we can say that the running time of APR is bounded by  in the worst case.

It is to be noted that the runtime of Procedure~\ref{countarray} has been ignored in comparison to the runtime of Procedure~\ref{permute}.

\section{Extensions}
\label{sec:exten}

In this section we show how the smallest of changes to Procedure~\ref{permute} helps us generate many more combinatorial structures. Please note that the proof of correctness of each of the following algorithms follows trivially from the rigorous analysis in Section~\ref{subsec:proof}.

\subsection{Derangements}

A derangement of a list is a permutation of the list in which none of the elements appear in their original positions. Some previous work on derangement generating algorithms can be found in \cite{deran2, deran1}.

With just two changes to Procedure~\ref{permute}, we are able to generate derangements - 
\begin{itemize}
 \item Non-local existence of , in addition to the other entities, is required
 \item Before assigning an element at a particular index, we perform an additional check to ensure that the same element does not occur at the exact same index in , i.e., if we were to assign  to , we would need to ensure that 
\end{itemize}

The procedure shall be referred to as APR2 (shown in Procedure~\ref{proc:apr2}). It is invoked by the call APR2(1). All we do is perform an additional check to ensure that the element being assigned at the current position does not appear in  at the same position (Line~\ref{proc:apr2:line:cond}).  is built exactly as was illustrated in Procedure~\ref{countarray}.

Extending the algorithm to generate partial derangements, like in \cite{partialderan}, is easily done. Figure~\ref{fig:rectreederan} shows the recursion tree when we generate derangements of ;  and . It is to be noted that the program can output -derangements, as well all derangements following an imposed order.

\begin{algorithm}
\begin{algorithmic}[1]
\caption{: APR2() - Derangements}
\label{proc:apr2}
\STATE \textbf{Local:} 
\STATE \textbf{Global:} , , ,  and 
\medskip
\IF{}
	\STATE Print 
	\RETURN
\ELSE
	\FOR{ to }
		\IF{ \textbf{and} } \label{proc:apr2:line:cond}
			\STATE  
			\STATE 
			\STATE APR2()
			\STATE 
		\ENDIF
	\ENDFOR
\ENDIF
\end{algorithmic}
\end{algorithm}

\begin{figure}[!htp] \centering
{\scriptsize \Tree [.{CA = \{1,1,1\} \\  \\ \textbf{APR2(1)}} 
	[.{index=1 \\ CA = \{1,0,1\} \\  \\ \textbf{APR2(2)}} 
		[.{index=2 \\ CA = \{0,0,1\} \\  \\ \textbf{APR2(3)}}
			[.{} ] ]
		[.{index=2 \\ CA = \{1,0,0\} \\  \\ \textbf{APR2(3)}}
			[.{index=3 \\ CA = \{0,0,0\} \\  \\ \textbf{APR2(4)}}
				 [.{index=4 \\ \fbox{}} ] ] ] ]
	 [.{index=1 \\ CA = \{1,1,0\} \\  \\ \textbf{APR2(2)}}
		 [.{index=2 \\ CA = \{0,1,0\} \\  \\ \textbf{APR2(3)}}
			 [.{index=3 \\ CA = \{0,0,0\} \\  \\ \textbf{APR2(4)}}
				 [.{index=4 \\ \fbox{}} ] ] ] ] ]}
\caption{Recursion Tree of APR2: ;  and }
\label{fig:rectreederan}
\end{figure}

\subsection{Combinations}
\label{subsec:comb}

\begin{figure*}[!htp] \centering
{\scriptsize \Tree [.{CA = \{1,1,1\} \\  \\ \textbf{APR3(1)}} 
	[.{index = 1 \\ CA = \{0,1,1\} \\  \\ \textbf{APR3(2)}} 
		[.{index = 2 \\ CA = \{0,0,1\} \\  \\ \textbf{APR3(3)}}
			 [.{index = 3 \\ \fbox{}} ] ] 
		[.{index = 2 \\ CA = \{0,1,0\} \\  \\ \textbf{APR3(3)}}
			[.{index = 3 \\ \fbox{}} ] ] ]
	[.{index = 1 \\ CA = \{1,0,1\} \\  \\ \textbf{APR3(2)}} 
		[.{index = 2 \\ CA = \{1,0,0\} \\  \\ \textbf{APR3(3)}}
			[.{index = 3 \\ \fbox{}} ] ] ]
	[.{index = 1 \\ CA = \{1,1,0\} \\  \\ \textbf{APR3(2)}}
		 [.{} ] ] ]}
\caption{Recursion Tree of APR3 for ; }
\label{fig:rectreecomb}
\end{figure*}

A combination of a list of elements is a selection of some or all of the elements. It is a selection where the sequence of elements in the selection is not important. Some combination generating algorithms that have been proposed are Chase~\cite{chase_comb}, Ehrlich~\cite{gideon_perm, gideon_PC} and Lam-Soicher~\cite{clement_Cminchange}. 

We would require to make just one change to Procedure~\ref{permute} to be able to produce all possible -combinations\footnote{Definition analogous to definition of -permutation.} of an input list. The new procedure shall be referred to as APR3 (shown in Procedure~\ref{proc:apr3}). All we do is - before assigning an element at a particular index in , we make sure that the element occupies a position in  that is greater than the position of element at the previous index, in . At the first index however, we may assign any element. The change is in Line~\ref{proc:apr3:line:cond} of Procedure~\ref{proc:apr3}.  is built in exactly as was illustrated in Procedure~\ref{countarray}.

By changing, the condition  to , we can get combinations which contain no repeated elements. The recursion tree obtained when we generate all combinations of  with  and  is shown in Figure~\ref{fig:rectreecomb}.

\begin{algorithm}
\begin{algorithmic}[1]
\caption{: APR3() - Combinations}
\label{proc:apr3}
\STATE \textbf{Local:} 
\STATE \textbf{Global:} , , ,  and 
\medskip
\IF{}
	\STATE Print  \label{proc:apr3:line:print}
	\RETURN
\ELSE
	\FOR{ to } \label{proc:apr3:line:loop}
		\IF{ \textbf{or} } \label{proc:apr3:line:cond}
			\STATE  
			\STATE 
			\STATE APR3()
			\STATE 
		\ENDIF
	\ENDFOR
\ENDIF
\end{algorithmic}
\end{algorithm}

\begin{figure*}[!htp] \centering
{\scriptsize \Tree 
[
	.{CA =  \\  \\ \textbf{APR3(1)}} 
	[
		.{index = 1 \\ CA = \{0,1,\ldots,1\} \\  \\ \textbf{APR3(2)}} 
		[
			.{\vdots}
			[
				.{index = 26 \\ CA = \{0,0,\ldots,0\} \\  \\ \textbf{APR3(27)}} 
				[.{index = 27 \\ \fbox{}} ] 
			]
		]
	]
	[
		.{index = 1 \\ CA = \{1,0,1,\ldots,1\} \\  \\ \textbf{APR3(2)}}
		[
			.{\vdots}
			[
				.{index = 25 \\ CA = \{1,0,\ldots,0\} \\  \\ \textbf{APR3(26)}} 
				[.{} ] 
			]
		]
	]
	[
		.{ \\ }
	]
	[
		.{index = 1 \\ CA = \{1,\ldots,1,0\} \\  \\ \textbf{APR3(2)}}
		[
			.{}
		]
	]
]}
\caption{Recursion Tree of APR3 for ; ; }
\label{fig:rectree_waste}
\end{figure*}

As is evident from Figure~\ref{fig:rectreecomb}, there can be many wasteful branches with certain kinds of input to APR3. For example, if we were to have ,  and , we would have a recursion tree similar to Figure~\ref{fig:rectree_waste}, where branches ending with  denote wasteful branches, i.e. recursion branches that do not produce any output. All unnecessary computations are because we loop from  at every index. However, based on two simple observations, we can completely eliminate all wasteful branches
\begin{enumerate}
 \item Once  is assigned at a particular index, subsequent indices can only contain one of 
 \item In the case where we have already assigned elements to the first  indices of , and , we need not loop if we are sure that there are fewer than  elements left over, i.e., if , we can terminate looping in the current recursion level and return to the previous recursion level
\end{enumerate}

\begin{figure*}[!htp] \centering
{\scriptsize \Tree 
[.{CA = \{1,1,1,1\} \\  \\ \textbf{APR3(1)}} 
	[.{index=1 \\ CA = \{0,1,1,1\} \\  \\ \textbf{APR3(2)}} 
		[.{index=2 \\ CA = \{0,0,1,1\} \\  \\ \textbf{APR3(3)}}
			[.{index=3 \\ CA = \{0,0,0,1\} \\  \\ \textbf{APR3(4)}}
				[.{index=4 \\ \fbox{}} ] ] 
			[.{index=3 \\ CA = \{0,0,1,0\} \\  \\ \textbf{APR3(4)}} 
				[.{index =4 \\ \fbox{}} ] ] ]
		[.{index=2 \\ CA = \{0,1,0,1\} \\  \\ \textbf{APR3(3)}}
			[.{index=3 \\ CA = \{0,1,0,0\} \\  \\ \textbf{APR3(4)}}
				[.{index=4 \\ \fbox{}} ] ] ] ]
	 [.{index=1 \\ CA = \{1,0,1,1\} \\  \\ \textbf{APR3(2)}}
		[.{index=2 \\ CA = \{1,0,0,1\} \\  \\ \textbf{APR3(3)}}
			[.{index=3 \\ CA = \{1,0,0,0\} \\  \\ \textbf{APR3(4)}}
				[.{index=4 \\ \fbox{}} ] ] ] ] ]}
\caption{Recursion Tree of APR3 for ; ; }
\label{fig:combCum}
\end{figure*}

\begin{algorithm}
\begin{algorithmic}[1]
\caption{: Building }
\label{proc:cumarray}
\STATE 
\FOR{ to }
	\STATE 
\ENDFOR
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\begin{algorithmic}[1]
\caption{: APR3() - Combinations \emph{Efficiently}}
\label{proc:apr3'}
\STATE \textbf{Local:} 
\STATE \textbf{Global:} , , , ,  and 
\medskip
\IF{}
	\STATE Print 
	\RETURN
\ELSE
	\STATE 
	\WHILE{}
		\IF{}
			\STATE  
			\STATE 
			\STATE APR3()
			\STATE 
		\ENDIF
		\STATE 
	\ENDWHILE
\ENDIF
\end{algorithmic}
\end{algorithm}

This means that in Line~\ref{proc:apr3:line:loop} of Procedure~\ref{proc:apr3}, the loop limits would need to be made tighter. For simplicity, we modify the definition of  to return 0 if . Also, we assign to  an element that does not exist in . This would mean that . Now, Point 1 indicates that we can begin looping from  instead of 1.

To incorporate Point 2, we build a \emph{Cumulative Array}~\cite{pearls} on . It is called  and is of size . It is built such that . A quick implementation is shown Procedure~\ref{proc:cumarray}.

It is to be noted that  reflects  values at the beginning. We know that  values are constantly changing. Thus we can use  only for indices where  values are known to have not changed. Procedure~\ref{proc:apr3'} is a pseudocode representation of the modified version of APR3. This is denoted by APR3. The effectiveness of APR3 is made apparent in Figure~\ref{fig:combCum}. Analogous to the argument in Section~\ref{sec:anal:subsec:runtime}, the running time of APR3 is in 

\subsection{Catalan Families}

In this section, we show how the algorithm can be modified to output all possible valid parenthesizations of  factors. A valid parenthesization of  factors can be defined as a sequence of  opening brackets and  closing brackets with the condition that at no point in the sequence should the number of closing brackets be greater than the number of opening brackets. We shall refer to the set of all possible valid parenthesizations of  factors as -Parenthesizations. Some previous work can be found in \cite{catalan2, knuth_perm}.

\begin{algorithm}
\caption{: Building }
\label{countCat}
\begin{algorithmic}[1]
\STATE \textbf{Input: }
\STATE \textbf{Output: }
\medskip
 \STATE 
 \STATE 
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\begin{algorithmic}[1]
\caption{: APR4() - -Parenthesizations}
\label{permCat}
\STATE \textbf{Local:} 
\STATE \textbf{Global:} , ,  and 
\medskip

\IF{}
	\STATE Print 
	\RETURN
\ELSE
\FOR{}
	\IF{( \textbf{ or }   ) \textbf{and} }
		\STATE  
		\STATE 
		\STATE APR4()
		\STATE 
	\ENDIF
\ENDFOR
\ENDIF
\end{algorithmic}
\end{algorithm}

The input to the algorithm is . We initialize  such that  =  = . This can be viewed as an input list of  opening brackets and  closing brackets (). We then generate all possible permutations of this input list using  and make sure that at no point in a permutation we assign more closing brackets than opening brackets. We set  and .

Once again, we see that we generate a different combinatorial structure using pretty much the same algorithm. The building of  is shown in Procedure~\ref{countCat} and the recursive generation of parenthesizations is shown in Procedure~\ref{permCat}. The recursive procedure is called APR4.

\subsection{Subsets}

\begin{algorithm}
\begin{algorithmic}[1]
\caption{: APR5() - Subsets}
\label{proc:apr5}
\STATE \textbf{Local:} 
\STATE \textbf{Global:} , , ,  and 
\medskip
\STATE Print  \label{proc:apr5:line:print}
\IF{}
	\RETURN
\ELSE
	\FOR{ to }
		\IF{ \textbf{or} } \label{proc:apr5:line:cond}
			\STATE  
			\STATE 
			\STATE APR5()
			\STATE 
		\ENDIF
	\ENDFOR
\ENDIF
\end{algorithmic}
\end{algorithm}

True to the formula , we know that all subsets of a list can be generated using an algorithm that generates all -combinations. This is achieved by calling the -combinations generating algorithm successively with: . However, the structure of APR allows us to do it more efficiently.

All subsets of a list of  elements can be obtained by calling APR5 (shown in Procedure~\ref{proc:apr5}). It is a modified version of APR3 (shown in Procedure~\ref{proc:apr3}) with  and the \textbf{Print} statement before the \textbf{if} block.  is again built exactly as was shown in Procedure~\ref{countarray}.

\subsection{Integer Compositions and Partitions}

A composition of an integer  is a set of strictly positive integers which sum up to ~\cite{compositions}. For example, 3 has four compositions - . Generally, a composition of  can contain any number from 1 to . However, it is also interesting to study a variation of the problem wherein we are not allowed to use all numbers.

\begin{algorithm}
\begin{algorithmic}[1]
\caption{: APR6() - Integer Compositions}
\label{proc:compo}
\STATE \textbf{Local:} 
\STATE \textbf{Global:} , ,  and 
\medskip
\IF{}
	\STATE Print 
	\RETURN
\ELSE
	\FOR{ to }
		\IF{}
			\STATE  
			\STATE 
			\STATE APR6()
			\STATE 
		\ENDIF
	\ENDFOR
\ENDIF
\end{algorithmic}
\end{algorithm}

We now present an algorithm (APR6), based on the same algorithmic structure used so far, that given an  and , generates all possible compositions of  using elements in . It is shown in Procedure~\ref{proc:compo}. An example recursion tree is shown in Figure~\ref{fig:compositions}. It is easy to modify Procedure~\ref{proc:compo} to generate all integer partitions, instead of integer compositions (analogous to how we generated combinations by using a permutations generating algorithm).

It is possible that when given an , we have a limited number of some or all of the numbers. For example, we could have ;  with the condition that no number can be used more than twice. This can be handled by maintaining an auxilary array  parallel to .

\begin{figure*}[!htp] \centering
{\scriptsize \Tree 
[
	.{n=9 \\  \\ \textbf{APR6(1)}} 
	[
		.{index = 1 \\  \\  \\ \textbf{APR6(2)}} 
		[
			.{index = 2 \\  \\  \\ \textbf{APR6(3)}}
			[
				.{index = 3 \\  \\  \\ \textbf{APR6(4)}} 
				[
					.{index = 4 \\ \fbox{}} 
				] 
			]
		]
		[
			.{index = 2 \\  \\  \\ \textbf{APR6(3)}}
			[
				.{index = 3 \\  \\  \\ \textbf{APR6(4)}} 
				[
					.{index = 4 \\  \\  \\ \textbf{APR6(5)}}
					[
						.{index = 5 \\ \fbox{}}
					]
				] 
			]
		]
	]
	[
		.{index = 1 \\  \\  \\ \textbf{APR6(2)}}
		[
			.{index = 2 \\  \\  \\ \textbf{APR6(3)}}
			[
				.{index = 3 \\  \\  \\ \textbf{APR6(4)}} 
				[
					.{index = 4 \\  \\  \\ \textbf{APR6(5)}}
					[
						.{index = 5 \\ \fbox{}}
					]
				] 
			]
		]
		[
			.{index = 2 \\  \\  \\ \textbf{APR6(3)}}
			[
				.{index = 3 \\  \\  \\ \textbf{APR6(4)}} 
				[
					.{index = 4 \\  \\  \\ \textbf{APR6(5)}}
					[
						.{index = 5 \\ \fbox{}}
					]
				] 
			]
		]
		[
			.{index = 2 \\  \\  \\ \textbf{APR6(3)}}
			[
				.{index = 3 \\  \\  \\ \textbf{APR6(4)}} 
				[
					.{index = 4 \\  \\  \\ \textbf{APR6(5)}}
					[
						.{index = 5 \\ \fbox{}}
					]
				] 
			]
		]
	]
]}
\caption{Recursion Tree of APR6 for ; }
\label{fig:compositions}
\end{figure*}

\section{Conclusion}
\label{sec:conc}

Algorithms to generate combinatorial structures will always be needed, simply because of the fundamental nature of the problem. One could need different kinds of combinatorial structures for different kinds of input. Thus, having one common effective algorithm, as the one proposed in this paper, which solves many problems, would be useful.

One must note that a few other non-trivial adaptations - generating all palindromes of a string, generating all positive solutions to a diophantine equation with positive co-efficients, etc, are also possible.

\section{Future Research}
\label{sec:future}

The proposed algorithm conclusively solves quite a few fundamental problems in combinatorics. Further research directed towards achieving even more combinatorial structures while preserving the essence of the proposed algorithm should assume topmost priority.

One could also perform some probabilistic analysis and derive tighter average case bounds on the runtime of the algorithms.

\section*{Acknowledgement}

We would like to thank Prof. K V Vishwanatha from the CSE Dept. of R V College of Engineering, Bangalore for his comments.

\bibliographystyle{amsplain}
\bibliography{APR}
\label{lastpage}

\end{document}
