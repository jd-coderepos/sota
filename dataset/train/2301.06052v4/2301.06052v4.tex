

\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}              

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{times}
\usepackage{microtype}
\usepackage{epsfig}
\usepackage[table,xcdraw]{xcolor}
\usepackage{caption}
\usepackage{xcolor}
\usepackage{float}
\usepackage{placeins}
\usepackage{color, colortbl}
\usepackage{stfloats}
\usepackage{enumitem}
\usepackage{tabularx}
\usepackage{xstring}
\usepackage{multirow}
\usepackage{xspace}
\usepackage{url}
\usepackage{subcaption}
\usepackage{arydshln}
\usepackage{xcolor}
\usepackage{bbm}
\usepackage[hang,flushmargin]{footmisc}
\usepackage{pifont}\newcommand{\cmark}{\ding{51}}\newcommand{\xmark}{\ding{55}}\usepackage[accsupp]{axessibility}

\newcommand{\todo}[1]{{\textcolor{red}{[TODO: #1]}}}
\newcommand{\xs}[1]{{\textcolor{cyan}{[XS: #1]}}}
\newcommand{\zjr}[1]{{\textcolor{red}{[ZJR: #1]}}}
\newcommand{\xiaodong}[1]{{\textcolor{blue}{[xiaodong: #1]}}}
\newcommand{\yangsong}[1]{{\textcolor{green}{[yangsong: #1]}}}

\newcommand{\et}[2]{}
\newcommand{\etb}[2]{}
\newcommand{\etr}[2]{}
\newcommand{\etbb}[2]{}
\newcommand{\ets}[2]{}


\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


\def\cvprPaperID{**}
\def\confName{****}
\def\confYear{****}


\begin{document}

\title{T2M-GPT: Generating Human Motion from Textual Descriptions with \\ Discrete Representations}

\author{Jianrong Zhang, 
Yangsong Zhang, 
Xiaodong Cun, Shaoli Huang, Yong Zhang \\ Hongwei Zhao, Hongtao Lu, Xi Shen \\
\small Equal contribution \qquad Corresponding author \
\hat{z_i} =  \underset{c_k\in C}\arg\min\|z_i - c_k\|_2
\label{formula:1}

\mathcal{L}_{vq} = \mathcal{L}_{re} + \underbrace{||\mathit{sg}[Z] - \hat{Z}||_2}_{\mathcal{L}_{embed}} + \beta \underbrace{||Z - \mathit{sg}[\hat{Z}]||_2}_{\mathcal{L}_{commit}}
\label{formula:2}

\mathcal{L}_{re} = \mathcal{L}_1^{smooth}(X, X_{re}) + \alpha \mathcal{L}_1^{smooth}(V(X), V(X_{re}))
\label{formula:3}

	\mathcal{L}_{trans} = \mathbb{E}_{S\sim p(S)}[-\log p(S|c)]
	\label{formula:5}

	\text{Attention} = \text{Softmax} \left( \frac{QK^T \times mask}{\sqrt{d_k}} \right)
	\label{formula:causal}

\text{FID} = \lVert \mu_{gt} - \mu_{pred}\rVert^2 - \text{Tr}(\Sigma_{gt} + \Sigma_{pred} - 2(\Sigma_{gt}\Sigma_{pred})^{\frac{1}{2}})
\label{formula:fid}

\text{MM-Dist} = \frac{1}{N}\sum_{i=1}^{N}\lVert f_{pred,i} - f_{text,i}\rVert
\label{formula:mm-dis}

\text{Diversity} = \frac{1}{S_{dis}}\sum_{i=1}^{S_{dis}}||f_{pred,i} - f_{pred,i}'||
\label{formula:diversity}

\text{MModality} = \frac{1}{10N}\sum_{i=1}^{N}\sum_{j=1}^{10}\lVert f_{pred,i,j} - f_{pred,i,j}'\rVert
\label{formula:mmodality}



\subsection{Motion representations}

We use the same motion representations as ~\cite{guo2022generating}. Each pose is represented by , where  is the global root angular velocity;  are the global root velocity in the X-Z plan;  are the local pose positions, velocity and rotation with j the number of joints;  is the foot contact features calculated by the heel and toe joint velocity.



\section{VQ-VAE Architecture}
\label{sec:supp_vq_arch}
We illustrate the detailed architecture of VQ-VAE in Table~\ref{tab:supp_vqarch}. The dimensions of the HumanML3D~\cite{guo2022generating} and KIT-ML~\cite{plappert2016kit} datasets feature are 263 and 259 respectively.

\begin{table}[t]
    \centering\setlength{\tabcolsep}{12pt}
    \resizebox{0.4\textwidth}{!}{
    \begin{tabular}{ccc}
    \toprule
        \multirow{2}{*}{Dilation rate} & 
        \multicolumn{2}{c}{Reconstruction} \\ \cmidrule{2-3}
         &  FID  & Top-1 (\%)  \\ \midrule
        1, 1, 1 & \et{0.145}{.001} & \et{0.500}{.003}  \\
        4, 2, 1 & \et{0.138}{.001} & \etb{0.502}{.002}  \\
        9, 3, 1 & \etb{0.070}{.001} & \et{0.501}{.002}  \\ 
        16, 4, 1 & \et{57.016}{.084} & \et{0.032}{.001} \\\bottomrule
    \end{tabular}
    }
    \caption{\textbf{Ablation study of different dilation rate in VQ-VAE on HumanML3D~\cite{guo2022generating} test set.}}
    \label{tab:supp_dilation}
\end{table}


\paragraph{Dilation rate.}

We investigate the impact of different dilation rates of the convolution layers used in VQ-VAE, and the results are presented in Table~\ref{tab:supp_dilation} for reconstruction. We notice that setting the dilation rate as (9, 3, 1) gives the most effective and stable performance.

\section{Limitations}
\label{sec:supp_limitation}
Our approach has two limitations: \textit{i)} for excessively long texts, the generated motion might miss some details of the textual description. Note that this typical failure case exists for all competitive approaches. \textit{ii)} some generated motion sequences slightly jitter on the legs and hands movement, this can be seen from the visual results provided in the appendix. We think the problem comes from the VQ-VAE architecture, with a better-designed architecture, the problem might be alleviated. For a real application, the jittering problem could be addressed using a temporal smoothing filter as a post-processing step.


\section{Funding Support}
\label{sec:supp_fund}
This work is supported by:
\begin{itemize}
    \item Natural Science Foundation of China (No. 62176155).
    \item Natural Science Foundation of Jilin Province (20200201037JC).
    \item Provincial Science and Technology Innovation Special Fund Project of Jilin Province (20190302026GX)
    \item Shanghai Municipal Science and Technology Major Project (2021SHZDZX0102)
\end{itemize}


\begin{table*}[h]
    \centering\setlength{\tabcolsep}{12pt}
    \begin{tabular}{ll}
    \toprule
        Components & Architecture \\ \midrule
        VQ-VAE Encoder & (0): Conv1D(, 512, kernel\_size=(3,), stride=(1,), padding=(1,)) \\
        ~ & (1): ReLU() \\
        ~ & (2): 2  Sequential( \\
        ~ &   ~~~~(0): Conv1D(512, 512, kernel\_size=(4,), stride=(2,), padding=(1,)) \\
        ~ &   ~~~~(1): Resnet1D( \\
        ~ &   ~~~~~~~~    (0): ResConv1DBlock( \\
        ~ &   ~~~~~~~~~~~~      (activation1): ReLU() \\
        ~ &   ~~~~~~~~~~~~      (conv1): Conv1D(512, 512, kernel\_size=(3,), stride=(1,), padding=(9,), dilation=(9,)) \\
        ~ &   ~~~~~~~~~~~~      (activation2): ReLU() \\
        ~ &   ~~~~~~~~~~~~      (conv2): Conv1D(512, 512, kernel\_size=(1,), stride=(1,))) \\
        ~ &   ~~~~~~~~    (1): ResConv1DBlock( \\
        ~ &   ~~~~~~~~~~~~      (activation1): ReLU() \\
        ~ &    ~~~~~~~~~~~~     (conv1): Conv1D(512, 512, kernel\_size=(3,), stride=(1,), padding=(3,), dilation=(3,)) \\
        ~ &   ~~~~~~~~~~~~      (activation2): ReLU() \\
        ~ &    ~~~~~~~~~~~~     (conv2): Conv1D(512, 512, kernel\_size=(1,), stride=(1,))) \\
        ~ &   ~~~~~~~~    (2): ResConv1DBlock( \\
        ~ &   ~~~~~~~~~~~~      (activation1): ReLU() \\
        ~ &   ~~~~~~~~~~~~      (conv1): Conv1D(512, 512, kernel\_size=(3,), stride=(1,), padding=(1,)) \\
        ~ &   ~~~~~~~~~~~~      (activation2): ReLU() \\
        ~ &   ~~~~~~~~~~~~      (conv2): Conv1D(512, 512, kernel\_size=(1,), stride=(1,))))) \\
        \midrule
        Codebook & nn.Parameter((512, 512), requires\_grad=False) \\
        \midrule
        VQ-VAE Decoder & (0): 2  Sequential( \\
        ~ &   ~~~~(0): Conv1D(512, 512, kernel\_size=(3,), stride=(1,), padding=(1,)) \\
        ~ &   ~~~~(1): Resnet1D( \\
        ~ &   ~~~~~~~~    (0): ResConv1DBlock( \\
        ~ &   ~~~~~~~~~~~~      (activation1): ReLU() \\
        ~ &   ~~~~~~~~~~~~      (conv1): Conv1D(512, 512, kernel\_size=(3,), stride=(1,), padding=(9,), dilation=(9,)) \\
        ~ &   ~~~~~~~~~~~~      (activation2): ReLU() \\
        ~ &   ~~~~~~~~~~~~      (conv2): Conv1D(512, 512, kernel\_size=(1,), stride=(1,))) \\
        ~ &   ~~~~~~~~    (1): ResConv1DBlock( \\
        ~ &   ~~~~~~~~~~~~      (activation1): ReLU() \\
        ~ &    ~~~~~~~~~~~~     (conv1): Conv1D(512, 512, kernel\_size=(3,), stride=(1,), padding=(3,), dilation=(3,)) \\
        ~ &   ~~~~~~~~~~~~      (activation2): ReLU() \\
        ~ &    ~~~~~~~~~~~~     (conv2): Conv1D(512, 512, kernel\_size=(1,), stride=(1,))) \\
        ~ &   ~~~~~~~~    (2): ResConv1DBlock( \\
        ~ &   ~~~~~~~~~~~~      (activation1): ReLU() \\
        ~ &   ~~~~~~~~~~~~      (conv1): Conv1D(512, 512, kernel\_size=(3,), stride=(1,), padding=(1,)) \\
        ~ &   ~~~~~~~~~~~~      (activation2): ReLU() \\
        ~ &   ~~~~~~~~~~~~      (conv2): Conv1D(512, 512, kernel\_size=(1,), stride=(1,))))) \\
        ~ &   ~~~~(2): Upsample(scale\_factor=2.0, mode=nearest) \\
        ~ &   ~~~~(3): Conv1D(512, 512, kernel\_size=(3,), stride=(1,), padding=(1,)) \\
        ~ & (1): ReLU() \\
        ~ & (2): Conv1D(512, , kernel\_size=(3,), stride=(1,), padding=(1,))
 \\
         \bottomrule
    \end{tabular}
    \caption{\textbf{Architecture of our Motion VQ-VAE.}}
    \label{tab:supp_vqarch}
\end{table*} 
\end{document}
