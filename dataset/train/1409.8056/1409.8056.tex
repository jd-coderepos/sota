\documentclass{LMCS}

\def\dOi{10(4:2)2014}
\lmcsheading {\dOi}
{1--80}
{}
{}
{Feb.~20, 2013}
{Oct.~30, 2014}
{}

\ACMCCS{[{\bf Theory of computation}]: Models of
  computation---Concurrency---Process calculi;Semantics and
  reasoning---Program semantics---Denotational semantics/Catgorical semantics} 




\usepackage{lmcs-preamble}
\renewcommand{\with}[1]{\langle #1 \rangle}
\renewcommand{\QFI}{\maji{IQ}}
\renewcommand{\LLL}{\QFI}
\renewcommand{\SSSL}{\SSS^{\LLL}}
\renewcommand{\TTTL}{\TTT^{\LLL}}

\theoremstyle{plain}\newtheorem{satz}[thm]{Satz}
\def\eg{{\em e.g.}}
\def\cf{{\em cf.}}

\renewcommand{\stratglobale}{behaviour\xspace} 
\renewcommand{\astratglobale}{a behaviour\xspace}
\renewcommand{\stratglobales}{behaviours\xspace}
\renewcommand{\Stratglobale}{Behaviour\xspace} 
\renewcommand{\Astratglobale}{A behaviour\xspace}
\renewcommand{\Stratglobales}{Behaviours\xspace}

\renewcommand{\stratlocale}{strategy\xspace}  
\renewcommand{\astratlocale}{a strategy\xspace}
\renewcommand{\stratlocales}{strategies\xspace}
\renewcommand{\Stratlocale}{Strategy\xspace}  
\renewcommand{\Astratlocale}{A strategy\xspace}
\renewcommand{\Stratlocales}{Strategies\xspace}

\renewcommand{\plays}{\E}
\renewcommand{\views}{\EVi}
\renewcommand{\Plays}{\E}
\renewcommand{\Views}{\EVi}



\begin{document}

\author[T.~Hirschowitz]{Tom Hirschowitz}
\address{CNRS, Universit\'e de Savoie}
\email{tom.hirschowitz@univ-savoie.fr}
\thanks{Partially
    funded by the French ANR projets blancs PiCoq ANR-10-BLAN-0305 and
    R\'ecr\'e ANR-11-BS02-0010}


\title[Full abstraction for fair testing in CCS]{Full abstraction for fair testing in CCS \\ {\tiny (expanded version)}\rsuper*}



\keywords{Programming languages; categorical semantics; presheaf
    semantics; game semantics; concurrency; process algebra}

\titlecomment{{\lsuper*}An extended abstract of this paper has appeared in CALCO '13.} 




\begin{abstract}
  \noindent In previous work with Pous, we defined a semantics for CCS
  which may both be viewed as an innocent form of presheaf semantics
  and as a concurrent form of game semantics.  We define in this
  setting an analogue of fair testing equivalence, which we prove
  fully abstract w.r.t.\ standard fair testing equivalence.

  The proof relies on a new algebraic notion called \emph{playground},
  which represents the `rule of the game'. From any playground, we
  derive two languages equipped with labelled transition systems, as
  well as a strong, functional bisimulation between them.
\end{abstract}

\maketitle

\clearpage
\tableofcontents
\clearpage

\section{Introduction}
\begin{wrapfigure}[6]{r}{0pt}
  \begin{minipage}[c]{0.28\linewidth}
    \vspace*{-1em}
    \begin{tabular}[t]{c|c}
      Games & Concurrency \\
      \hline
      position & \configuration \\
      player & \agent \\
      move & \action \\
      play & \trace \end{tabular}
  \end{minipage}
\end{wrapfigure}
This paper is about \emph{game semantics} for CCS~\cite{Milner80}.
Game semantics is originally a very successful approach to
\emph{sequential} denotational
semantics~\cite{DBLP:conf/lfcs/Nickau94,DBLP:journals/iandc/HylandO00,ajm}.
Its basic idea is to interpret programs as strategies for a player in
a game, and the computational environment as an opponent. Composition
of programs is handled by letting the corresponding strategies
interact.  We mostly use game semantical terminology in this paper,
but the above dictionary may help the intuition of concurrency
theorists.

Denotational models of CCS are extremely diverse, and treat various
behavioural equivalences, as surveyed by Winskel and
Nielsen~\cite{WN}. The closest game semantical work seems to be
Laird's model~\cite{DBLP:conf/fsttcs/Laird06}, which achieves full
abstraction w.r.t.\ \emph{trace} (a.k.a.\ \emph{may testing})
equivalence for a fragment of .  The goal of the present paper is
to design the first game semantics for a finer equivalence than trace
equivalence, in the simpler setting of CCS (we plan to address the
full -calculus in future work).  The reason Laird is limited to
trace equivalence is that the standard notion of strategy is a set of
plays (with well-formedness conditions). Hence, e.g., the famous
coffee machines,  and , are identified.  Following
two recent, yet independent lines of work~\cite{RideauW,HP11}, we
generalise strategies by allowing them to accept plays \emph{in
  several ways}, thus reconciling game semantics with presheaf
models~\cite{DBLP:conf/lics/JoyalNW93}. Winskel et al.'s approach is
only starting to be applied to concrete languages, see for example the
work in progress on an affine, concurrent variant of Idealised
Algol~\cite{CCWGalop14}.  The approach
of~\cite{HP11,2011arXiv1109.4356H} (\citetalias{2011arXiv1109.4356H})
was used to give a game semantics for CCS, and define a semantic
analogue of fair testing equivalence, but no adequacy result was
proved. We here prove full abstraction of semantic fair testing
equivalence w.r.t.\ standard fair testing equivalence.  Our model is
compositional, since (1) all syntactic constructs of CCS have natural
interpretations, and (2) global dynamics may be inferred from local
dynamics, as in any game semantics (see the paragraph on innocence
below and Sections~\ref{subsubsec:strategies}
and~\ref{subsubsec:syntax}).

\subsection{Overview of the approach}
\subsubsection*{Truly concurrent plays}
First of all, as in~\cite{RideauW}, our notion of play is truly
concurrent.  Indeed, it does not keep track of the order in which
(atomic) moves occur.  Instead, it only retains causal dependencies
between them (see Section~\ref{subsec:plays}).  Furthermore, our plays
form a proper category, which enables in particular a smooth treatment
of bound variables. Briefly, plays that differ only up to a
permutation of channels are isomorphic, and by construction strategies
handle them correctly.


\subsubsection*{Branching behaviour}
Second, we deal with 
branching behaviour. Standardly, and ignoring momentarily the previous
paragraph, a strategy is essentially a prefix-closed set of `accepted'
plays.  This is equivalent to functors , where
 is the poset of plays ordered by prefix inclusion, and  is
the poset  ( stands for `extension').  A play
 is `accepted' by such a functor  when ,
and if , then functoriality imposes that
, hence : this is
prefix-closedness.  In order to allow plays to be accepted in several
ways, we follow \emph{presheaf models}~\cite{DBLP:conf/lics/JoyalNW93}
and move to functors , where  is the
category of finite ordinals and all functions between
them\footnote{The author learnt this point of view from a talk by Sam
  Staton.}. Thus, to each play , a strategy
associates a \emph{set} of ways to accept it, empty if  is
rejected.  E.g., in the simplistic setting where  denotes the
poset of words over actions, ordered by prefix inclusion, the coffee
machine  is encoded as the presheaf  defined on the left
and pictured on the right:
\begin{center}
    \begin{minipage}[c]{0.26\linewidth}
      \begin{itemize}
      \item ,
      \item ,
      \item ,
      \item ,
      \end{itemize}
    \end{minipage}
      \hfil
    \begin{minipage}[c]{0.44\linewidth}
      \begin{itemize}
      \item  empty otherwise,
      \item ,
      \item ,
      \item ,
      \end{itemize}
    \end{minipage}
      \hfil
      \begin{minipage}[c]{0.28\linewidth}
        \vspace*{-.8em}
        \diag(.15,.8){\& |(root)| \star \& \\
          |(x)| x \& \& |(x')| x' \\
          \\
          |(y)| y \& \& |(y')| y'. }{(root) edge[labelal={a}] (x) edge[labelar={a}] (x') (x) edge[labell={b}] (y) (x') edge[labelr={c}] (y') }
      \end{minipage}
\end{center}
This illustrates what is meant by `accepting a play in several ways':
the play  is here accepted in two ways,  and .  The other
coffee machine is of course obtained by identifying  and . In
our setting, plays are considered relative to their initial position
, hence strategies are presheaves  on the
category of plays over .

\subsubsection*{Innocence}
Finally, defining strategies as presheaves on plays is too naive,
which leads us to reincorporate the game semantical idea of
\emph{innocence}.  Example~\ref{ex:noninnocent} below exhibits such a
presheaf in which two players synchronise on a public channel ,
without letting others interfere. In CCS, this would amount to a
process like  in which, say, the first
two processes could arrange for ruling out the third.  Considering
such presheaves as valid strategies would break our main result.

In the Hyland-Ong approach, innocent strategies may be defined as
prefix-closed sets of \emph{views}, where views are special
plays representing the information that a player may `access' during
a global play. The global strategy  associated to an
innocent strategy  is then recovered by decreeing that
 accepts all plays whose views are accepted by .
This leads us to consider a subcategory  of the category
 of plays, whose objects are called \emph{views}. We thus
have for each position  two categories of strategies: the
naive one, the category  of
\emph{\stratglobales} on , consists of presheaves on plays; the
more relevant one, the category  of
\emph{\stratlocales} on , consists of presheaves on views. 

How, then, do we recover the global \stratglobale associated to
\astratlocale, which is crucial for defining our semantic fair testing
equivalence?  The right answer is given by a standard categorical
construction called right Kan extension (see
Section~\ref{subsubsec:strategies}).  Roughly, for the \stratglobale
 associated to a \stratlocale , a way to accept some play
 is a compatible family of ways for  to
accept all views of .  In the boolean, setting (considering
functors ), this reduces to  accepting
 iff all its views are accepted by . Our definition thus
generalises Hyland and Ong's.

Finally, game semantical \emph{parallel composition} (different from
CCS parallel composition, though inspired from it) intuitively
lets strategies interact together.  We account for it as follows.  If
we partition the players of a play  into two teams, 
we obtain  two subpositions 
\begin{wrapfigure}[4]{r}{0pt}
  \begin{minipage}[c][3em]{0.4\linewidth}
\diag(.6,.6){\op{(\views_{X_1})} \&     \op{(\views_{X})} \&     \op{(\views_{X_2})} \\
    \& \set }{(m-1-1) edge[into] (m-1-2) edge[labelbl={S_1}] (m-2-2) (m-1-3) edge[linto] (m-1-2) edge[labelbr={S_2}] (m-2-2) (m-1-2) edge[labelon={[S_1,S_2]},dashed] (m-2-2) }
\end{minipage}\end{wrapfigure}
\noindent ,  each  player of  belonging to  or  according
to its team. We have that the category  of views on 
is isomorphic to the coproduct category . The parallel composition of any two \stratlocales 
and  on  resp.\  is simply obtained by universal
property of coproduct, as above right.

\subsection{Main result: which behavioural equivalence?}
With our game in place, we easily define a translation of CCS
processes into \stratlocales. It then remains to demonstrate the
adequacy of this translation.  Our \stratlocales are actually rather
intensional, so we cannot hope for adequacy w.r.t.\ equality of
\stratlocales.  Instead, we exploit the rich structure of our model to
define both \anlts{} and an analogue of fair testing equivalence
\emph{on the semantic side}, i.e., for \stratlocales.  We then provide
two results. The most important, in the author's view, is full
abstraction w.r.t.\ standard \emph{fair testing semantics}
(Corollary~\ref{cor:final}). But the second result might be considered
more convincing by many: it establishes that our semantics is fully
abstract w.r.t.\ weak bisimilarity (Corollary~\ref{cor:wbisim}).
A reason why the latter result is here considered less important
originates in the tension between \lts{} semantics and reduction
semantics~\cite{modularLTS}. Briefly, reduction semantics is simple
and intuitive, but it operates on equivalence classes of terms (under
so-called \emph{structural} congruence). On the other hand, designing
\ltss{} is a subtle task, rewarded by easier, more structural
reasoning over reductions. We perceive \lts{} semantics as less
intrinsic than reduction semantics. E.g., for more sophisticated
calculi than CCS, several \ltss{} exist, which yield significantly
different notions of bisimilarity.

\begin{wrapfigure}[3]{r}{0pt}
  \begin{minipage}[c]{0.23\linewidth}
    \vspace*{-1.5em}
    \diag(.3,.3){|(a)| \bullet \& |(b)| \bullet \& |(d)| \bullet
      \& |(f)| \bullet \\
      \& |(c)| \bullet \& |(e)| \bullet \& |(g)| \bullet }{(a) edge[labela={\tau}] (b) edge[labelbl={\tau}] (c) (b) edge[labela={\tau}] (d) edge[labelbl={a}] (e) (d) edge[labela={\tau}] (f) edge[labelbl={b}] (g) }
\end{minipage}
\end{wrapfigure}
Beyond \lts{}-based
equivalences, we see essentially two options: \emph{barbed
  congruence}~\cite{DBLP:books/daglib/0004377} or some \emph{testing
  equivalence}~\cite{DBLP:journals/tcs/NicolaH84}.
Barbed congruence equates processes  and , roughly, when for all
contexts ,  and  are weakly bisimilar w.r.t.\
\emph{reduction} (i.e., only -actions are allowed), and
furthermore they have the same interaction capabilities at all
stages. Barbed congruence is sometimes perceived as too discriminating
w.r.t.\ guarded choice. Consider, e.g., the CCS process  pictured
above, and let  be the same with  and  swapped.  Both
processes may disable both actions  and , the only difference
being that  disables  \emph{before} disabling .  Barbed
congruence distinguishes  from  (take ), which some view as a deficiency.

Another possibility would be \emph{must testing}
equivalence~\cite{DBLP:journals/tcs/NicolaH84}.  Recall that 
\emph{must pass} a test process  iff all maximal executions of
 perform, at some point, a fixed `tick'
action~\cite{DBLP:journals/iandc/Gorla10}, here denoted by .
Then,  and  are must testing equivalent iff they must
pass the same tests.  Must testing equivalence is sometimes perceived
as too discriminating w.r.t.\ divergence.  E.g., consider  and . Perhaps surprisingly,  and 
are \emph{not} must testing equivalent. Indeed,  must pass the
test , but  does not, due to an infinite, silent
reduction sequence.

We eventually go for fair testing equivalence, which was originally
introduced (for CCS-like calculi) to rectify both the deficiency of
barbed congruence w.r.t.\ choice and that of must testing equivalence
w.r.t.\ divergence.  The idea is that two processes are equivalent
when they \emph{should} pass the same tests. A process 
should pass the test  iff their parallel composition 
never loses the ability of performing the special `tick' action, after
any tick-free reduction sequence. Fair testing equivalence thus
equates  and  above, as well as  and .
Cacciagrano et al.~\cite{DBLP:journals/corr/abs-0904-2340} provide an
excellent survey.


\subsection{Plan and overview}\label{subsec:overview}
We now give a bit more detail on the contents.  In
Section~\ref{sec:prelim}, we introduce our notations and some
preliminaries.  Section~\ref{sec:HP} summarises from \citetalias{2011arXiv1109.4356H} the game for
CCS, the notions of strategy and behaviour, the translation
 of CCS processes into strategies, and semantic fair
testing equivalence.  The rest is devoted to proving that
, here decomposed as  (see
below), is such that  iff , where  is standard fair testing
equivalence (Corollary~\ref{cor:final}).

\subsubsection{Playgrounds}
Our proof of this result takes a long detour to introduce a new
algebraic gadget called \emph{playground}, which we now motivate.  Our
first attempts at proving the full abstraction result were obscured by
a tight interleaving of
\begin{itemize}
\item results stating common properties of moves in the game, or of
  plays, and
\item results and constructions on strategies derived from those
  (e.g., the \lts{} for strategies).
\end{itemize}

On the other hand, the reasons why our constructions work are
intuitively simple.  Namely, innocent strategies essentially amount to
describing syntax trees by selecting their branches amongst a set of
all possible branches. This enlarges the universe of terms slightly,
but in game semantics, one studies properties of terms which also make
sense for such generalised terms.  Compositionality and the definition
of our semantic fair testing equivalence are examples where using
strategies instead of terms tends to simplify the constructions. E.g.,
associated behaviours are recovered from innocent strategies through
Kan extension, thanks to an expressive notion of morphism between
plays.  Our results essentially follow from this correspondence
between terms and strategies.

\begin{exa}
  To illustrate what we mean by generalised terms, consider standard,
  unlabelled binary trees as a stripped down example of a term
  language.  Such trees admit a description as prefix-closed sets of
  words over  (their sets of \emph{occurrences}). In order
  to get exactly trees, such sets should be constrained a bit. E.g.,
  the empty set of words, or the set  do not describe
  any tree.
\end{exa}

Playgrounds are a first attempt at a general framework describing
this correspondence between terms and strategies. We develop their theory in
Sections~\ref{sec:playgrounds} and~\ref{sec:strats}, whose main result
is a strong bisimulation between both presentations (i.e., terms vs.\
strategies).  This is then expoited in the next sections to derive the
main results.

The basis for playgrounds are \emph{pseudo double
  categories}~\cite{GrandisPare,GrandisPareAdjoints,LeinsterHC,GarnerPhD},
a weakening of Ehresmann's double
categories~\citep{Ehresmann:double,Ehresmann:double2}.  Playgrounds
are thus pseudo double categories with additional structure.  The
objects of a playground represent positions in the game.  There are
two kinds of morphisms: \emph{vertical} morphisms represent plays,
while \emph{horizontal} ones represent embeddings of positions. E.g.,
there are special objects representing `typical' players; and a player
of a position  is a horizontal morphism  from such a
typical player, in a Yoneda-like way. There are then axioms to model
atomicity (plays may be decomposed into atomic moves) and locality
(plays over a large position may be restricted to any subposition;
each player only sees part of the play). There are finally a few more
technical axioms.

In Section~\ref{sec:playgrounds}, we give the definition and derive a
few basic results and constructions. In particular, we define a naive
notion of strategy, \emph{behaviours}, and a less naive notion,
\emph{strategies}.  Finally, we relate the two by exhibiting a functor
from strategies to behaviours.  In Section~\ref{sec:strats}, we prove
that strategies are in bijective correspondence with infinite terms in
a certain language. We then derive from this \anlts{}  for
strategies.  Furthermore, we define a second language, which is closer
to usual process calculi. And indeed, instantiating this general
language to our game for CCS yields essentially CCS, the only
difference being that channel creation is treated on an equal footing
with input and output. We further equip this language of \emph{process
  terms} with \anlts{} .  Finally, we define a translation
from process terms to strategies , which is proved to be a strong bisimulation
(Theorem~\ref{thm:bisim}).

At this point, it remains 
\begin{enumerate}\enlargethispage{\baselineskip}
\item to show that the pseudo double category  formed by our
  game does satisfy the axioms for playgrounds, and
\item to use the strong bisimulation  to derive our main
  results.
\end{enumerate}

\subsubsection{Graphs with complementarity}
We start with (2), because we feel doing otherwise would disrupt the
flow of the paper. Indeed, it should not be surprising at all that
 forms a playground; and furthermore the methods employed to
show this are in sharp contrast with the rest of the paper.  The plan
for (2), carried out in Section~\ref{sec:graphs}, is as follows.

First, we reduce semantic fair testing equivalence to fair testing
equivalence in the \lts{} , thus bridging the gap
between the game semantical world and \ltss{}. But this is not as
simple as it looks.  Indeed, Hennessy and De Nicola's original setting
for testing equivalences~\citep{DBLP:journals/tcs/NicolaH84} is not
quite expressive enough for our purposes, which leads us to define a
slightly more general one, called \emph{modular graph with
  complementarity}.  First, our setting is `typed', in the sense that
not all tests may be applied to a process , only tests of a type
`compatible' with . Furthermore, in modular graphs with
complementarity, fair testing equivalence relies on a notion of
\emph{complementarity} saying when two transitions may be glued
together to form a \emph{closed-world} transition.  Thus, fair testing
equivalence is `intrinsic', i.e., does not depend on any alphabet.  So
we have a mere \lts{}  over an \emph{ad hoc} alphabet
 derived from , and we need promote it into a modular
graph with complementarity.  This goes by refining the original
alphabet  with `interfaces', yielding a new alphabet . We
then define a morphism , and pull 
 back along , thus obtaining our modular graph with
complementarity  (which is thus also \anlts{} over
). In passing, we do the same for , which yields
: this will be useful later.  We finally prove that
fair testing equivalence in  coincides with semantic
fair testing equivalence (Lemma~\ref{cor:SSSLI}).  Similarly, we
construct a modular graph with complementarity  for CCS, and
show that fair testing equivalence therein coincides with standard
fair testing equivalence (Proposition~\ref{prop:fairccs}).  We are
thus reduced to proving that some composite  is \emph{fair}, i.e.,
preserves and reflects fair testing equivalence.

Our second step is to establish a sufficient condition for a relation
 to be fair and to apply this to the graph of our
translation .  The idea is to define what an
adequate alphabet  should be in our setting, and to prove that,
essentially, if we can find an adequate alphabet  for  and ,
such that  is a relation over , then  is fair as soon as
\begin{itemize}
\item  is included in weak bisimilarity over , and
\item both graphs have enough -\emph{trees}, in a sense
  inspired by the notion of
  \emph{failure}~\cite{DBLP:journals/iandc/RensinkV07}.
\end{itemize}
In order to apply this, we transform  and
 into modular graphs with complementarity over the same
alphabet  (i.e., set of labels) as .  We proceed by
`relabeling' along some morphism of graphs .  We
still have our translation , which is a strong, functional bisimulation over .
It thus remains to check that (a) the map  is included in weak bisimilarity, and (b) both 
and  have enough -trees.  Roughly,  has enough
-trees when, for any  in a certain class of tree-like \ltss{}
over  called -trees, there exists  weakly bisimilar
to .  For (b), all three \ltss{} under consideration clearly have
enough -trees. For (a), our proof is brute force.


\subsubsection{CCS as a playground}
We finally deal in Section~\ref{sec:ccs} with the last missing bit of
our proof: we show that  forms a playground. This rests upon
the following two main ingredients.

First, we design a correctess criterion for plays, in a sense close to
correctness criteria in linear logic.  Namely, plays from some
position  to position  are represented as particular cospans  in some category.  Specifically, they are
obtained by closing a given set of cospans named \emph{moves} under
identities and composition.  We design a combinatorial criterion
for deciding when an arbitrary cospan is indeed a play.

The second main ingredient is a construction of the \emph{restriction}
of a play  from some position  to a subposition .
Briefly, this means computing the part of  which is relevant to
players in . This construction is almost easy: most of  may be
`projected' back onto the initial position , and then a mere
pullback
\begin{center}
  \Diag{\pbk{m-2-1}{m-1-1}{m-1-2} }{\restr{U}{X'} \& U \\
    X' \& X }{(m-1-1) edge[into,labelu={}] (m-1-2) edge[labell={}] (m-2-1) (m-2-1) edge[into,labeld={}] (m-2-2) (m-1-2) edge[labelr={}] (m-2-2) }
\end{center}
of sets gives the needed restriction. The glitch is that in general
some parts of  may not canonically be projected back onto . The
principle for this projection is as simple as: project, e.g., input
moves to the inputting player. The problem arises for
synchronisations. Projecting them to the channel over which the
synchronisation occurs does not yield the desired result, and
similarly projecting to either of the involved players fails.  Our
solution is to ignore synchronisations at first, and later reintroduce
them automatically using a technique from algebraic
topology: factorisation systems~\cite{Joyal:ncatlab:facto}.

With both of these ingredients in place, the proof is relatively
straightforward.

Section~\ref{sec:conc} concludes and provides some perspectives for
future work.

\subsection{Related work}
Our bisimulation result relating terms to strategies for any
playground draws inspiration from \emph{Kleene
  coalgebra}~\cite{DBLP:conf/fossacs/BonsangueRS09,DBLP:conf/concur/BonchiBRS09}. There,
the main idea is that both the syntax and the semantics of various
kinds of automata should be \emph{derived} from more basic data
describing, roughly, the `rule of the game'. Formally, starting from a
well-behaved (\emph{polynomial}) endofunctor on sets, one constructs
both (1) an equational theory and (2) a sound and complete coalgebraic
semantics. This framework has been applied in standard automata
theory, as well as in quantitative settings.  Nevertheless, its
applicability to programming language theory is yet to be
established. E.g., the derived languages do not feature parallel
composition.  Our playgrounds may be seen as a first attempt to convey
such ideas to the area of programming language theory.  Technically,
our framework is rather different though, in that we replace the
equational theory by a transition system, and the coalgebraic
semantics by a game semantics.  To summarise, our approach is close in
spirit to Kleene coalgebra, albeit without quantitative
aspects. Conversely, Kleene coalgebra resembles our approach without
innocence.

Building upon previous
work~\cite{DBLP:conf/lics/AbramskyM99,Mellies04,DBLP:conf/concur/MelliesM07}
on \emph{asynchronous} games, a series of papers by Winskel and
collaborators (see, e.g., \citet{RideauW,DBLP:conf/fossacs/Winskel13})
attempt to define a notion of concurrent strategy encompassing both
innocent game semantics and presheaf models. Ongoing work evoked
above~\cite{CCWGalop14} shows that the model does contain innocent
game semantics, but presheaf models are yet to be investigated.
(Their notion of innocence, borrowed from Faggian and
Piccolo~\cite{DBLP:conf/tlca/FaggianP09}, is not intended to be
related to that of Hyland and Ong.)  In their framework, a game is an
event structure, whose events are thought of as moves, equipped with a
notion of polarity.  In one of the most recent papers in the
series~\cite{DBLP:conf/fossacs/Winskel13}, Winskel establishes a
strong relationship between his concurrent strategies and presheaves.
For a given event structure with polarity , he considers the
so-called \emph{Scott order} on the set  configurations of
.  For two configurations  and , we have 
iff  may be obtained from  by removing some negative moves and
then adding some positive ones, in a valid way.  Strategies are then
shown to coincide with presheaves on .  This
is close in spirit to our use of presheaves, but let us mention a few
differences. First, our games do not directly deal with
polarity. Furthermore, in our setting, for any morphism  of
plays,  is intuitively bigger than  in some way, unlike what
happens with the Scott ordering. Finally, an important point in our
use of (pre)sheaves is that, unlike configuration posets, our plays
form proper \emph{categories}, i.e., homsets may contain more than one
element (intuitively, the same view may have several occurrences in a
given play). Thus, potential links between both approaches remain to
be further investigated.

To conclude this paragraph, let us mention a few, more remotely related
lines of work.  Melli\`es~\cite{DBLP:conf/lics/Mellies12}, although in
a deterministic and linear setting, incorporates some `concurrency'
into plays by presenting them as string diagrams. Our notion of
innocent strategy shares with Harmer et
al.'s~\cite{DBLP:conf/lics/HarmerHM07} presentation of innocence based
on a distributive law the goal of better understanding the original
notion of innocence. Finally, others have studied game semantics in
non-deterministic~\cite{DBLP:conf/lics/HarmerM99} or
concurrent~\cite{DBLP:conf/fossacs/GhicaM04,DBLP:conf/fsttcs/Laird06}
settings, using coarser, trace-based behavioural equivalences.




\section{Prerequisites and preliminaries}\label{sec:prelim}
In this section, we recall some needed material and introduce our
notations.  We attempt to provide intuitive, yet concise explanations,
but these may not suffice to get the non-specialist reader up to
speed, so we also provide references when possible.

For the reader's convenience, we finally provide in
Figure~\ref{fig:cheat} (end of paper) a summary of notations, beyond
those introduced here.

\subsection{Sets, categories, presheaves}\label{subsec:prelim:cats}
We make intensive use of category theory, of which we assume prior
knowledge of categories, functors, natural transformations, limits and
colimits, adjoint functors, presheaves, bicategories, Kan extensions,
and pseudo double categories. All of this except pseudo double
categories is entirely covered in Mac Lane's standard
textbook~\cite{MacLane:cwm} and the beginning of Mac Lane and
Moerdijk~\cite{MM}. For a more leisurely introduction, one may consult
Lawvere and Schanuel~\cite{DBLP:books/daglib/0095291}, or
Leinster~\cite{LeinsterCats}.  The needed material on Kan extensions
roughly amounts to their expression as ends, which is recalled when
used (Section~\ref{subsubsec:strategies}).  The last bit, namely the
notion of \emph{pseudo double category} is briefly recalled below,
after fixing some notation.  Finally, there are very local uses of
locally presentable categories~\cite{Adamek} in the present section,
and of adhesive category theory~\cite{DBLP:conf/fossacs/LackS04} in
the proof of Lemma~\ref{lem:decompleft}.

Throughout the paper, any finite ordinal  is seen as  (rather than ).
In any category, for any object  and set , let 
denote the -fold coproduct of  with itself, i.e., ,  times.

 is the category of sets;  is a skeleton of the category
of finite sets, e.g., the category of finite ordinals and arbitrary
maps between them;  is the category of finite ordinals and
monotone maps between them.  For any category ,  denotes the category of presheaves on , while
 and 
respectively denote the categories of presheaves of finite sets and of
finite ordinals.  One should distinguish, e.g., `presheaf of finite
sets'  from `finite presheaf of sets' . The category  of \emph{finite} presheaves is the
full subcategory of  spanning presheaves  which are
finitely presentable~\cite{Adamek}. In presheaf categories, finitely
presentable objects are the same as finite colimits of
representables. In the only case we will use ( below), because
representables have finite categories of elements, the latter in turn
coincide with presheaves  such that the disjoint union  is finite.  For all presheaves  of any such
kind, , and , let  denote
.
\begin{rem}
  This conflicts with the notation  above, but context
  should disambiguate, as in  a set  acts on an object
  , whereas in , a morphism  acts on an object .
\end{rem}
We denote the Yoneda embedding by
, and often abbreviate  to
just .

For any functor  and object , let 
 denote the comma category on the left below, and 
 denote the pullback category on the right:
  
When  is clear from context, we simply write , resp.\
. Also, as usual, when  is the identity,
we use the standard slice notation .

Finally, we briefly recall pseudo double categories. They are a
weakening of Ehresmann's double
categories~\citep{Ehresmann:double,Ehresmann:double2}, notably studied
by \citet{GrandisPare,GrandisPareAdjoints}, \citet{LeinsterHC}, and
\citet{GarnerPhD}.  The weakening lies in the fact that one dimension
is strict and the other weak (i.e., bicategory-like).  We need to
consider proper pseudo double categories, notably we use cospans in
examples, but we often handle pseudoness a bit sloppily.  Indeed, the
proofs of Section~\ref{sec:playgrounds} quickly become unreadable when
accounting for pseudoness.


A pseudo double category  consists of a set  of
\emph{objects}, shared by a `horizontal' category  and a
`vertical' bicategory . Following ParÃ©~\cite{PareYoneda}, ,
being a mere category, has standard notation (normal arrows, 
for composition,  for identities), while the bicategory 
earns fancier notation ( arrows,  for composition,
 for identities).  is furthermore equipped with a set of
\emph{double cells} , which have vertical, resp.\ horizontal,
domain and codomain, denoted by , ,
, and . 

\begin{wrapfigure}[6]{r}{0pt}
  \begin{minipage}[t][3em]{0.28\linewidth}
    \vspace*{-1.6em}\Diag(.6,.6){}{X \& X' \& X'' \\
    Y \& Y' \& Y'' \\
    Z \& Z' \& Z''}{(m-1-1) edge[labelu={h}] (m-1-2) edge[pro,labell={u},twoleft={ur}{}] (m-2-1) (m-2-1) edge[labelu={h'}] (m-2-2) (m-1-2) edge[pro,labell={u'},twoleft={u'r}{},tworight={u'l}{}] (m-2-2) (m-1-2) edge[labelu={k}] (m-1-3) (m-2-2) edge[labelu={k'}] (m-2-3) (m-1-3) edge[pro,labelr={u''},tworight={u''l}{}] (m-2-3) (m-2-1) 
    edge[pro,labell={v},twoleft={vr}{}] (m-3-1) (m-3-1) edge[labela={h''}] (m-3-2) (m-2-2) edge[pro,labell={v'},twoleft={v'r}{},tworight={v'l}{}] (m-3-2) (m-3-2) edge[labela={k''}] (m-3-3) (m-2-3) edge[pro,labelr={v''},tworight={v''l}{}] (m-3-3) (ur) edge[cell={.2},labela={\alpha}] (u'l) (u'r) edge[cell={.2},labela={\alpha'}] (u''l) (vr) edge[cell={.2},labela={\beta}] (v'l) (v'r) edge[cell={.2},labela={\beta'}] (v''l) }
  \end{minipage}
\end{wrapfigure}
We picture this as, e.g.,  on the right, where , , , and . Finally, there are operations for composing double
cells: \emph{horizontal} composition  composes them along a
common vertical morphism, \emph{vertical} composition 
composes along horizontal morphisms. Both vertical compositions (of
morphisms and of double cells) may be associative only up to coherent
isomorphism. The full axiomatisation is given by
Garner~\cite{GarnerPhD}, and we here only mention the
\emph{interchange law}, which says that the two ways of parsing the
above diagram coincide: .

For any (pseudo) double category , we denote by  the category
with vertical morphisms as objects and double cells as morphisms, and
by  the bicategory with horizontal morphisms as objects and
double cells as morphisms.  Domain and codomain maps arrange into
functors  and . We will refer to  and  simply as 
and , reserving subscripts for  and .

We introduce a bit more notation.
\begin{defi}
  A double cell 
is \emph{special} when its vertical domain and codomain are (horizontal) identities.
\end{defi}
For any object ,  denotes the category with
\begin{itemize}
\item objects all vertical morphisms to , and
\item morphisms  all double cells 
  \doublecellpro{Y}{Y'}{X}{X}{h}{u}{v}{k}{\alpha} with .
\end{itemize}
This complies with noting  for the pullback category~\eqref{eq:pbkcat}, taking 
 for  and  for .

\subsection{Transition systems}\label{subsec:prelim:lts}
Beyond category theory, this paper also makes heavy use of the theory
of \ltss{} and associated techniques, especially bisimulation and
other behavioural equivalences.  The notion of \lts{} that we'll use
here is a little more general than usual. Indeed, usually, the
transitions of \anlts{} are labelled with letters in a given set
called the \emph{alphabet}, or the set of \emph{actions}. Here, we
consider the case where the vertices of \anlts{} may be typed, and
actions may change the type.  Extending the usual theory to this
setting is straightforward, so we only provide a brief overview. For
more on the usual theory, modern references are~\citet{Sangio}
and~\citet{SangioRutten}. Our setting is essentially a baby version of
Fiore's~\cite{DBLP:conf/ifipTCS/Fiore00} (see the references therein
for precursors).

Let  be the category of reflexive graphs, which has as objects
diagrams  in , equipped with a
further arrow  such that . We will as usual denote  by . Morphisms are those
morphisms between underlying graphs which preserve identity arrows.
 is thus the category of presheaves over the category \diaginline{\star
  \& {[1]}}{(m-1-2) edge[labelo={e}] (m-1-1) (m-1-1) edge[bend left,labela={s}] (m-1-2) edge[bend right,labelb={t}] (m-1-2) } with  and .
\begin{defi}
  For any , let the \emph{category of \ltss{} over } be
  just the slice category .
\end{defi}

\subsubsection{Basic notation}\label{subsubsec:notation:lts}  is called the \emph{alphabet}, which goes
slightly beyond the usual notion of an alphabet. The latter would here
come in the form of the graph with one vertex, an identity edge, plus
an edge for each letter.  By convention, and mainly to ease graphical
intuitions in Sections~\ref{sec:playgrounds} and~\ref{sec:strats}, for
any \lts{} , we understand an edge  in  as a transition from  to . Of course, to recover a
more standard notation, one may replace all graphs with their
opposites.  When  does not matter, but  does, we denote such
a transition by , omitting the
subscript  when clear from context.

For any reflexive graph , we denote by  the graph with the
same vertices and arbitrary paths as edges.  is reflexive,
with identity edges given by empty paths. Similarly,  is the morphism induced by .
This defines a functor , which is \emph{not} left
adjoint to the forgetful functor .  There is a
left adjoint, though, which we denote by . It is given by
a quotient of , essentially equating  and , i.e.,
the singleton, identity path and the empty one.
\begin{defi}
  Let  denote the graph with the same vertices as ,
  whose edges  are paths  in , considered
  equivalent modulo removal of identity edges.
\end{defi}
Any path  has a normal form, obtained by removing all identity
edges and denoted by .  We will deem such normal forms
\emph{identity-free}.  We denote by 
any path  in , such that
.  Concretely, if  is an
identity, then  only consists of identity edges;
otherwise,  consists of , possibly surrounded by
identity edges. In the former case, we further abbreviate the notation
to  (observe that  may well be empty).  Similarly,
for any path  in ,  denotes any path
 in  such that .

\subsubsection{Bisimulation and change of base} 
In this section, we revisit the usual notion of (strong and weak) bisimulation in our graph-based setting,
and provide a few stability results under base change and cobase change.
Let us start with strong bisimulations.

\begin{defi} For any , a morphism 
  is a \emph{graph fibration} iff for all , , and
  , there exist  and 
  such that .
\end{defi}


Consider morphisms  and .  
A \emph{relation over } is a subgraph of the pullback
\begin{center}
  \Diag{\pbk{m-2-1}{m-1-1}{m-1-2} }{G \times_A G' \& G' \\
    G \& A. }{(m-1-1) edge[labelu={}] (m-1-2) edge[labell={}] (m-2-1) (m-2-1) edge[labeld={p}] (m-2-2) (m-1-2) edge[labelr={p'}] (m-2-2) }
\end{center}
In particular, if two edges  are related by some , then so are their sources, resp.\ targets.
We denote such relations by .

We will most often deal with \emph{full} relations, i.e., such that
 iff both sources and targets are related. Of course, such
relations need only to be defined on vertices.
\begin{defi}
  A \emph{simulation}  is a relation  over  such that for all , if  then there exist  and  such that .  A \emph{bisimulation} is a
  simulation whose converse also is a simulation.
\end{defi}
When  is full,  is a simulation iff for all , if
 then there exists  and  such that
 and  and  are mapped to the same edge in .

\begin{prop}
   is a simulation iff its first projection  is a  graph fibration.  Accordingly,  is a
  bisimulation iff both projections are  graph fibrations.
\end{prop}
\begin{proof}
  Straightforward.
\end{proof}\enlargethispage{3\baselineskip}
\begin{rem}\label{rem:joyal}
  The characterisation of simulations in terms of  graph fibrations may
  be attributed to Joyal et al.~\cite{DBLP:conf/lics/JoyalNW93}, who first observed
   that a morphism  in  is a functional bisimulation iff
   for any commuting square as the exterior of
   \begin{center}
    \diag{\yoneda(\star) \& G \\
      \yoneda[1] \& G', }{(m-1-1) edge[labelu={}] (m-1-2) edge[labell={\yoneda(t)}] (m-2-1) (m-2-1) edge[labeld={}] (m-2-2) (m-1-2) edge[labelr={f}] (m-2-2) (m-2-1) edge[dashed] (m-1-2) }
  \end{center}
  there exists a dashed arrow making both triangles commute.  Here,
   maps the reflexive
  graph with a single vertex (and its identity edge) to the one with
  two vertices and just one non-identity edge  between them, by
  picking out the target of .
  This precisely says that  is a  graph fibration.

  A peculiar aspect of this characterisation is that it may seem
  independent from . Actually,  is a relation over , and  is a morphism over .
\end{rem}

As usual, fixing  and  over , we have:
\begin{prop}
  Bisimulations are closed under union, and the union of all
  bisimulations, called \emph{bisimilarity}, is again a bisimulation,
  the maximum one. 
\end{prop}
Considering \emph{endo}relations , we talk about
bisimilarity \emph{in} .
\begin{notation}
  Bisimilarity in  over  is denoted by . It may, upon
  a slight abuse of notation, be understood as an equivalence relation
  over all vertices of any two graphs over . Namely, if  and
   are graphs over , we may write  when 
  and  to mean bisimilarity in .
\end{notation}

Before treating weak bisimulations, we consider a first stability result,
which is all we need about strong bisimulations.

Any morphism  induces by pullback a change-of-base
functor , which has a left
adjoint  given by composition with .

\begin{prop}\label{prop:change of base}
  For any morphism of graphs , both functors  and , i.e., pullback along and post-composition with ,
  preserve functional bisimulations.
\end{prop}

\begin{proof}
  The case of  is actually trivial.
  For , we use Remark~\ref{rem:joyal}. By the pullback lemma,
  the square on the right below
is a pullback. We check that  is again a
  bisimulation. Indeed, consider any square as
  on the left below:
\begin{center}
    \Diag{\pbk[10]{m-2-2}{m-1-2}{m-1-3} \path[->,draw] (m-2-1) edge[fore,dashed,bend right=3] (m-1-3) ; }{\yoneda (\star) \& \cob{f}(G) \& G \\
      \yoneda[1] \& \cob{f}(G') \& G'. }{(m-1-1) edge[labelu={}] (m-1-2) edge[labell={\yoneda(t)}] (m-2-1) (m-2-1) edge[labeld={}] (m-2-2) (m-1-2) edge[labelr={}] (m-2-2) (m-2-1) edge[dotted] (m-1-2) (m-1-2) edge (m-1-3) (m-2-2) edge (m-2-3) (m-1-3) edge (m-2-3) }
  \end{center}
  Because  is a bisimulation, we obtain the dashed arrow
  making both triangles commute. But then by universal property of
  pullback, we obtain the dotted arrow, making the corresponding
  bottom triangle commute.  Finally, the top triangle commutes upon
  postcomposition with , and after composition with
  , hence commutes by uniqueness in the
  universal property of pullback.
\end{proof}
\begin{rem}
  This is an instance of the fact that \emph{right maps} are stable
  under pullback in any weak factorisation
  system~\cite{Joyal:ncatlab:facto}, here with the factorisation
  system cofibrantly generated by the sole map .
\end{rem}

Let us now treat weak bisimulations. We start with the functional case.
\begin{defi}
  A morphism  in  is a \emph{functional,
    weak bisimulation} iff  is a graph fibration.
\end{defi}
\begin{prop}
  This equivalent to the fact that, for any edge  in , there exists  in  and a path  such that .
\end{prop}
\begin{proof}
  If  is an identity, then taking the empty path for  will do,
  so the condition really says something about non-identity edges .
\end{proof}
\begin{rem}
  Remark~\ref{rem:joyal} adapts to weak, functional bisimulations,
  using  instead of .
\end{rem}


Let us now handle the relational case.  In the strong case, a relation
between graphs  and  over  was defined to be a subobject of
the pullback , and simulation properties were related
to the projections being graph fibrations. In order to follow this
pattern here, we need to consider  instead of
. However, in general,  differs from . We consider the
former:
\begin{defi}
  A \emph{weak simulation}  is a relation  whose first projection  is a
  graph fibration.
  
   is a \emph{weak bisimulation} iff both projections are graph
  fibrations.
\end{defi}
Explicitly, consider  and , and
 as above a weak simulation. For any edge  in
, i.e., identity-free path ,
and  such that , there should be an identity-free
path  in  such that .  If
 is full, this is equivalent to the existence, for each edge  in  and  such that , of an
identity-free path  such that 
and . We will only consider
full relations in this paper, hence only the last characterisation
will matter to us.

As in the strong case, we have for any fixed  and  over :
\begin{prop}
  Weak bisimulations are closed under union, and the union of all weak
  bisimulations, called \emph{weak bisimilarity}, is again a weak
  bisimulation, the maximum one.
\end{prop}
\begin{notation}
  Weak bisimilarity over  is denoted by . As for strong
  bisimilarity, we will abuse notation and consider  as a
  relation between the vertices of any two graphs over .
\end{notation}


\subsection{CCS}
The main subject of this paper is CCS~\cite{Milner89}, and fair
testing equivalence over it.  We work with a standard version, except
in two respects. First, we work with infinite terms, which spares us
the need for replication, recursion, or other possible mechanisms for
describing infinite processes in a finite way.  Second, we work with a
de Bruijn-like presentation: terms carry their (finite) sets of known
channels, in the form of a finite number. I.e., the number 
indicates that the considered process knows channels 
(which complies with our notation for finite ordinals, introduced in
Section~\ref{subsec:prelim:cats}).

\begin{rem}
  While the de Bruijn-like presentation clearly is a matter of
  convenience, working with infinite terms does have an impact on our
  results.  Restricting ourselves to recursive processes (e.g., by
  introducing some recursion construct), we would still have that
   implies .  The
  converse is less obvious and may be stated in very simple terms:
  suppose you have two recursive CCS processes  and  and a test
  process , possibly non-recursive, distinguishing  from ; is
  there any recursive  also distinguishing  from ?  We leave
  this question open.
\end{rem}



Our (infinite) CCS terms are coinductively generated by the typed grammar
\begin{mathpar}
  \inferrule{\Gam \vdash P \\ \Gam \vdash Q}{\Gam \vdash P|Q} \and \inferrule{\Gam,a \vdash P}{\Gam \vdash \nu a. P} \and \inferrule{\ldots \\ \Gam \vdash P_i \\ \ldots}{\Gam \vdash \sum_{i \in n} \alpha_i.P_i}~(n \in \Nat) \,.\end{mathpar}
Here, as announced,  ranges over , i.e., the free names of
a process always are  for some . Accordingly, 
denotes just  (and then ).  Furthermore,  is
either , , or  (for ).  The latter is a
`tick' move used in the definition of fair testing equivalence.

\begin{defi}\label{def:A}
  Let  be the reflexive graph with vertices given by finite
  ordinals, edges  given by  if , and by  otherwise,   being the identity edge on .
  Elements of the first summand are denoted by , while elements of the second summand are denoted by
  .
\end{defi}

\begin{figure}[t]
  \begin{mathpar}
    \inferrule{ }{(\Gam \vdash P) \xot{\id} (\Gam \vdash P)} \and \inferrule{ }{(\Gam \vdash \sum_{i \in n} \alpha_i.P_i) \xot{\alpha_i} (\Gam \vdash P_i)} \\ \inferrule{(\Gam \vdash P_1) \xot{\alpha} (\Gam \vdash P'_1)}{(\Gam \vdash P_1 \para P_2) \xot{\alpha} (\Gam \vdash P'_1 \para P_2)} \and \inferrule{(\Gam \vdash P_2) \xot{\alpha} (\Gam \vdash P'_2)}{(\Gam \vdash P_1 \para P_2) \xot{\alpha} (\Gam \vdash P_1 \para P'_2)} \and \inferrule{(\Gam,a \vdash P) \xot{\alpha} (\Gam, a \vdash P')}{ (\Gam \vdash \nu a.P) \xot{\alpha} (\Gam \vdash \nu a.P')}~{(\alpha \notin \ens{a, \abar})} \and \inferrule{ (\Gam \vdash P_1) \xot{\alpha} (\Gam \vdash P'_1) \\
      (\Gam \vdash P_2) \xot{\overline{\alpha}} (\Gam \vdash P'_2) }{(\Gam \vdash P_1 \para P_2) \xot{\id} (\Gam \vdash P_1 \para P'_2)
    } \end{mathpar}
  \caption{CCS transitions}
  \label{fig:ccs}
\end{figure}
We view terms as a graph  over  with the usual transition
rules, as recalled in Figure~\ref{fig:ccs} (which is an inductive
definition).  There, we let  denote  when
, or  when .
\begin{rem}
  The graph  only has `endo'-edges, hence only relates terms with
  the same set of free channels. Some \ltss{} below do use more
  general graphs.
\end{rem}

Let us finally recall the definition of fair testing equivalence.
Let  denote the set of processes  such that 
for all paths , there exists a path 
.
\begin{defi}\label{def:ccsfair}
  A \emph{test} for  is any process .  A
  test  is \emph{passed} by  when .  Two processes  and  are
  \emph{fair testing equivalent}, notation , iff  and  and  pass exactly
  the same tests.
\end{defi}



\section{Summary of previous work}\label{sec:HP}
In this section, we recall some material from \citetalias{2011arXiv1109.4356H}. Apart from the
admittedly numerous prerequisites mentioned in the previous section,
the paper should be self-contained, although the material in this
section would usefully be complemented by reading \citetalias{2011arXiv1109.4356H}. 

As sketched in the introduction, we construct a
multi-player game, consisting of positions and plays between
them. Positions are certain graph-like objects, where vertices
represent players and channels.  But what might be surprising is that
moves are not just a binary relation between positions, because we not
only want to say \emph{when} there is a move from one position to
another, but also \emph{how} one moves from one to the other. This
will be implemented by viewing moves from  to  as \emph{cospans}
 in a certain category  of
higher-dimensional graph-like objects, or `string diagrams', where 
and  respectively are the initial and final positions, and 
describes how one goes from  to .  By composing such moves (by
pushout), we get a bicategory  of positions and plays. This is
described in Sections~\ref{subsec:diagrams}--\ref{subsec:plays}.  In
Section~\ref{sec:playgrounds}, we will equip this bicategory with more
structure, namely that of a pseudo double category, where one
direction models dynamics, and the other models space, e.g., the
inclusion of a position into another.  Section~\ref{subsec:strats:old}
further recalls our two notions of strategies derived from the game
(behaviours and innocent strategies, respectively), and
Section~\ref{subsec:fair} recalls our semantic variant of fair testing
equivalence.

\subsection{Diagrams}\label{subsec:diagrams}
In preparation for the definition of our base category , recall
that (directed, multi) graphs may be seen as presheaves over the
category freely generated by the graph with two objects  and
, and two edges . Any presheaf 
represents the graph with vertices in  and edges in ,
the source and target of any  being respectively  and . A way to visualise how such presheaves represent
graphs is to compute their \emph{categories of
  elements}~\cite{MM}. Recall that the category of elements 
for a presheaf  over  has as objects pairs  with  and , and as morphisms  all morphisms
 in  such that . This category
admits a canonical projection functor  to , and  is the colimit of
the composite  with the
Yoneda embedding. E.g., the category of elements for  is
the poset ,
which could be pictured as
\diagramme[stringdiag={0.1}{0.6}]{baseline=(A.south)}{\path[-,draw] (A) edge (E) (B) edge (E) ; \node at () {,} ;}{\joueur{A} \& \node[regular polygon,anchor=center,regular polygon
  sides=3,fill,minimum size=3pt,draw,rotate=-90] (E) {}; \&
  \joueur{B} }{} \hspace*{-.7em} where dots represent vertices, the triangle
represents the edge, and links materialise the graph of  and
, the convention being that  goes from the apex of the
triangle.  We thus recover some graphical intuition.

Our string diagrams will also be defined as (finite) presheaves over
some base category . Let us give the formal definition of  for
reference.  We advise to skip it on first reading, as we then attempt
to provide some graphical intuition.
\begin{figure}[t]
    \begin{mathpar}
      {\begin{minipage}[t]{0.33\textwidth}
        \centering
        {\diag(.4,.4){\&|(v)| v \\
            |(n)| [n] \& \& |(n')| [n'] \\
            \& |(star)| \star }{(star) edge[labelbl={s_i}] (n) edge[labelbr={s_i}] (n') (n) edge[labelal={t}] (v) (n') edge[labelar={s}] (v) }} \\
        ()
\end{minipage}}
  \and
  {\begin{minipage}[t]{0.2\textwidth}
        \centering
        {\diag(.4,.4){\&|(v)| \forkn \\
     |(n)| \forkln \& \& |(n')| \forkrn \\
      \& |(star)| [n] }{(star) edge[labelbl={t}] (n) edge[labelbr={t}] (n') (n) edge[labelal={l}] (v) (n') edge[labelar={r}] (v) }} \\
  ( )
  \end{minipage}}
  \and 
  {  \begin{minipage}[t]{0.33\textwidth}
    \centering
    {\diag(.4,.3){|(n)| [m]   \&  |(sender)| o_{m,c} \\
        |(star)| \star \& |(v)| \tau_{n,a,m,c} \\
        |(n')| [n] \& |(receiver)| \inna \& }{(star) edge[labell={s_c}] (n) edge[labell={s_a}] (n') (n) edge[labela={t}] (sender) (n') edge[labelb={t}] (receiver) (sender) edge[labelr={\epsilon}] (v) (receiver) edge[labelr={\rho}] (v) }} \\
    ( , and )
    \end{minipage}}\end{mathpar}\caption{Equations for }
  \label{fig:equationsC}
\end{figure}

\begin{defi}
Let  be the graph with, for all , , and :
  \begin{itemize}
  \item vertices , , , , ,
    , , , , and ;
  \item edges ;
  \item for all , edges
    ;
  \item edges ;
  \item edges ;
  \item edges .
  \end{itemize}

  Let  be the free category on , modulo the equations in
  Figure~\ref{fig:equationsC}, where, in the left-hand one,  is 
  when , and  otherwise.
\end{defi}
Our category of string diagrams will be the category  of finite
presheaves on .


\begin{wrapfigure}{r}{0pt}
  \begin{minipage}[t]{0.3\linewidth}
    \centering
    \diagramme[stringdiag={.8}{1.3}]{}{}{\node (s_1) {}; \& \node (s_2) {}; \& \node (s_3) {}; \\
      \& \node (id) {}; }{(s_1) edge (id) (s_2) edge (id) (s_3) edge (id) }
    \\
    \diagramme[stringdiag={.8}{1.3}]{}{\path[-,draw] (a) edge (j1) (c) edge (j1) (b) edge (j1) ; }{\canal{a}     \& \canal{b} \&  \canal{c} \\
      \& \joueur{j1} }{}
  \end{minipage}
\end{wrapfigure}
To explain this seemingly arbitrary definition, let us compute a few
categories of elements. Let us start with an easy one, that of  (we implicitly identify any  with ). An
easy computation shows that it is the poset pictured in the top part
on the right. We will think of it as a position with one player
 connected to three channels, and draw it as in the
bottom part on the right, where the bullet represents the player, and
circles represent channels.  The \emph{positions} of our game are
finite presheaves empty except perhaps on  and 's. Other
objects will represent moves.  The graphical representation is
slightly ambiguous, because the ordering of channels known to players
is implicit.  We will disambiguate in the text when necessary.  A
\emph{morphism of positions} is an injective morphism of presheaves.
The intuition for a morphism  between positions is thus that
 embeds into .
\begin{defi}\label{def:Dh}
  Positions and morphisms between them form a category .
\end{defi}


A more difficult category of elements is that of . It is
the poset generated by the graph on the left (omitting base
objects for conciseness):
  \begin{mathpar}
    \diag (.4,.3) {\& \& |(lt)| l s \& \& |(rt)| r s \& \& \\ |(lt1)| l s s_1 \& \& |(l)| l \& |(para)| \id_{\paraof{2}} \& |(r)| r \& \& |(lt2)| l s s_2 \\ 
\& \& \& |(ls)| l t = r t \&  \& \& }{(lt1) edge (ls) (lt2) edge (ls) (ls) edge (l) edge (r) (lt) edge (l) (rt) edge (r) (l) edge (para) (r) edge (para) (lt1) edge[identity] (lt1) edge (lt) edge[fore,bend left=10] (rt) (lt2) edge[identity] (lt2) edge (rt) edge[bend right=10,fore] (lt) }
    \and
          \diagramme[stringdiag={.3}{.6}]{}{
\node[diagnode,at= (t1.south east)] {\ \ \ .} ; }{\& \& \joueur{t_1} \&  \& \joueur{t_2} \\
\& \&   \&  \\
    \& \ \& \\
    \canal{t0} \& \& \& \couppara{para} \& \& \& \canal{t1} \\ \& \ \& \\
    \& \&  \\
\& \& \& \joueur{s} \& \& \& \& }{(para) edge[-] (t_2) (t1) edge[-,bend right=10] (t_2) (t0) edge[-] (s) (t1) edge[-] (s) (s) edge[-] (para) (para) edge[fore={.3}{.3},-] (t_1)
    (t0) edge[fore={.5}{.5},-,bend left=10] (t_2) (t0) edge[-,bend left=15] (t_1) (t1) edge[-,fore={1}{.5},bend right=10] (t_1) }  
\end{mathpar}
We think of it as a binary player () forking into two players
( and ), and draw it as on the right.
\newcommand{\longueurfigun}{.6}\newcommand{\separation}{} The
graphical convention is that a black triangle stands for the
presence of , , and . Below, we represent
just  as a white triangle with only a left-hand branch, and
symmetrically for .  Furthermore, in all our pictures, time flows
`upwards'.

  Another category of elements, characteristic of CCS,
  is the one for synchronisation . The case  is the poset generated by the graph on the left of
  Figure~\ref{fig:tau}, which we will draw as on the right. \begin{figure*}[t]
    \begin{mathpar}
      \diagramme[diag={.4}{.4}]{}{\path[->] (t1) edge (s) (t2) edge (s') (t0) edge (t) (t0) edge[bend right=20] (s) (t3) edge (t) (t3) edge (s) (t2) edge (t') (t1) edge (s') ; \path[->,draw] (t1) edge[fore={.3}{.5}] (iota) (t1) edge[fore={0.3}{.5}] (iota') ; \path[draw,->] (iota) edge[fore={.4}{0}] (tau) (iota') edge[fore={.4}{0}] (tau) ; \path[->] (t1) edge[fore={.6}{.3},bend right=20] (t') ; \path[->] (t1) edge[fore={.6}{.5},bend left=20] (t) ; \foreach \x/\y in {s/iota,t/iota,s'/iota',t'/iota'} \path[->]
        (\x) edge (\y) ; }{\& \&  |(t)| \epsilon s \& \&   \& \&  |(t')| \rho s   \\
        \ \& \\
        |(t0)[anchor=base west]| \epsilon t s_1 \& \&  |(iota)| \epsilon \& \& |(tau)| {\scriptscriptstyle \id_{\tau_{n,a,m,c}}} \& \& |(iota')| \rho  \& |(t2)| \rho t s_2 \\
        \& |(t3)| \epsilon t s_3 \&  \& \& |(t1)| \epsilon t s_2 \\
        \& \& |(s)| \epsilon t \& \& \& \& |(s')| \rho t }{}\hfil
      \diagramme[stringdiag={.8}{.8}]{}{\path[-] (s) edge (t1) (t2) edge (s') (t0) edge (t) (t0) edge[bend right=20] (s) (t3) edge (s) edge (t) (t2) edge (t') (s') edge (t1) ; \moveccsin{t1}{iota'}{t2}{1} \moveccsout{t0}{iota}{t1}{1} \twocell[.4][.4]{iota}{t1}{iota'}{}{
          decorate,decoration={snake,amplitude=.3mm,segment length=1mm},bend left=40}
        \path[-] ; \path[-] (t1) edge[fore={.3}{.3}] (t') ; \path[-] (t) edge[fore={.1}{.5}] (t1) ; \foreach \x/\y in {s/t,s'/t'} \path[-] (\x) edge (\y) ; \node[anchor=north] at (t1.south) {} ; \node[anchor=south] at (t.north) {} ; \node[anchor=north] at (s.south) {} ; \node[anchor=south] at (t'.north) {} ; \node[anchor=north] at (s'.south) {} ; }{\& \& \joueur{t} \& \& \& \& \joueur{t'}   \\
        \ \\
        \canal{t0}\& \&  \coupout{iota}{0} \& \& \canal{t1}  \& \&  \coupin{iota'}{0} \& \canal{t2} \\
        \& \canal{t3} \\
        \& \& \joueur{s} \& \& \& \& \joueur{s'} }{}\end{mathpar}
    \caption{Category of elements for  and graphical representation}
\label{fig:tau}
\end{figure*} The left-hand ternary player  outputs on its nd channel, here
. The right-hand unary player  receives on its st
channel, again . Both players have two occurrences, one before
and one after the move, respectively marked as  and .
Both  and  have arity  here, and both  and  have
arity . There are actually three moves, in the sense that
there are three higher-dimensional objects in the corresponding
category of elements.  The first is the output move from  to ,
graphically represented as the left-hand \raisebox{.25em}{
\diagramme[ampersand replacement=\&,column sep=.5cm,inner sep=0.1pt]{inner sep=0pt}{\path[-] (a) edge[-latex] (b) ; }{\node[coordinate] (a){}; \& \node[coordinate] (b){}; }{}}
(intended to evoke the `ping' sent by  entering channel ).
The second move is the input move from  to , graphically represented
as the right-hand
\raisebox{.25em}{
\diagramme[ampersand replacement=\&,column sep=.5cm,inner sep=1pt]{inner sep=0pt}{\path[-] (b) edge[-latex] (c) ; }{\node[coordinate] (b){}; \& \node[coordinate] (c){}; }{}} (intended to evoke a `ping' exiting channel ).  The
      third and final move is the synchronisation itself, which
      `glues' the other two together, as represented by the squiggly
      line.


  
We leave the computation of other categories of elements as an
exercise to the reader. The remaining diagrams are depicted in the top row of Figure~\ref{fig:stringmoves}, for
. \begin{figure*}[t]
  \centering
  \begin{tabular}{*{8}{c}}
  \diagramme[stringdiag={.2}{.33}]{}{ }{\& \joueur{t_1} \& \& \& \\ \& \&   \&  \\
    \& \ \& \\
    \canal{t0} \& \& \coupparacreux{para} \& \& \canal{t1}
    \\ \& \ \& \\
    \& \&  \\
    \& \& \joueur{s} \& \&
}{(t0) edge[-] (t_1) (t1) edge[-,bend right=20] (t_1) (t0) edge[-] (s) (t1) edge[-] (s) (s) edge[-] (para) (para) edge[-] (t_1) }
&
\diagramme[stringdiag={.2}{.33}]{}{ }{\& \& \& \joueur{t_2} \& \\ \& \&   \\
    \& \ \& \\
    \canal{t0} \& \& \coupparacreux{para} \& \& \canal{t1}
    \\ \& \ \& \\
    \& \&  \\
    \& \& \joueur{s} \& \&
}{(t0) edge[-,bend left=20] (t_2) (t1) edge[-] (t_2) (t0) edge[-] (s) (t1) edge[-] (s) (s) edge[-] (para) (para) edge[-] (t_2) }
&
\diagramme[stringdiag={.3}{.5}]{baseline=()}{\path[-] (t2) edge (s) (t1) edge (t) (t0) edge (t) (t2) edge (t) (t) edge (iota.west) (s) edge (iota.west) (t0) edge[bend right=20] (s) (t1) edge (s) ; \moveccsout[1]{t1}{iota}{t2}{1} \foreach \x/\y in {s/t} \path[-] (\x) edge (\y) ; }{\& \& \joueur{t}  \\
    \&  \\
    \canal{t0} \& \& \coupout{iota}{0}  \& \canal{t2} \\
    \& \canal{t1} \\
    \& \& \joueur{s} }{}&
\diagramme[stringdiag={.6}{\longueurfigun}]{baseline=()}{
    \path[-] (a) edge (p) (in) edge (p) edge (p') (p') edge (a) edge (b) ; \moveccsin[.5]{a}{in}{b}{1} \foreach \x/\y in {p/p',a/a,p/b} \path[-] (\x) edge (\y) ; }{ \& \joueur{p'} \& \\ \canal{a} \& \coupout{in}{0} \& \canal{b} \\ \& \joueur{p} }{} &
\diagramme[stringdiag={.6}{\longueurfigun}]{}{ \path[-] (a) edge
    (a) edge (p) (tick) edge[shorten <=-1pt] (p) edge[shorten <=-1pt] (p') (p') edge (a) edge (b) (b) edge (p) edge (b) ; }{ \& \joueur{p'} \& \\ \canal{a} \& \couptick{tick} \& \canal{b} \\ \& \joueur{p} \& }{} &
\diagramme[stringdiag={.3}{.5}]{baseline=()}{\path[-,draw] (t1) edge (s) (t1) edge (t) (t0) edge (t) (t2) edge (t) (t) edge (nu) (s) edge (nu) (nu) edge[gray,very thin] (t2) (t0) edge[bend right=20] (s) ; }{

    \& \& \joueur{t} \& \&  \& \\
    \&  \&    \\
    \canal{t0} \& \& \coupnu{nu} \& \& \canal{t2}  \\
    \& \canal{t1} \\
    \& \& \joueur{s} \& }{}\\
  \diag(.6,.2){{[n]} \\ {\forkln} \\ {[n]} }{(m-1-1) edge (m-2-1) (m-3-1) edge (m-2-1) }&
  \diag(.6,.2){{[n]} \\ {\forkrn} \\ {[n]} }{(m-1-1) edge (m-2-1) (m-3-1) edge (m-2-1) }&
  \diag(.6,.2){{[m]} \\ {o_{m,c}} \\ {[m]} }{(m-1-1) edge (m-2-1) (m-3-1) edge (m-2-1) }&
  \diag(.6,.2){{[n]} \\ {\inna} \\ {[n]} }{(m-1-1) edge (m-2-1) (m-3-1) edge (m-2-1) }&
  \diag(.6,.2){{[n]} \\ {\tickn} \\ {[n]} }{(m-1-1) edge (m-2-1) (m-3-1) edge (m-2-1) }&
  \diag(.6,.2){{[n+1]} \\ {\nun} \\ {[n]} }{(m-1-1) edge (m-2-1) (m-3-1) edge (m-2-1) }&
\end{tabular}
  \caption{String diagrams and corresponding cospans 
    for , , , , , and }
\label{fig:stringmoves}
\end{figure*}
The first two are \emph{views}, in the game semantical sense, of the
fork move  explained above. The next two,  (for
`output') and  (for `input'), respectively represent what the
sender and receiver can see of the above synchronisation move.  
The last two diagrams are a `tick' move, used for
defining fair testing equivalence, and a channel creation move.

\subsection{From diagrams to moves}\label{subsec:moves}
In the previous section, we have defined our category of diagrams as
, and provided some graphical intuition on its objects.  The
next goal is to construct a bicategory whose objects are positions
(recall: presheaves empty except perhaps on  and 's), and
whose morphisms represent plays in our game. We start in this section
by defining moves as cospans in , and continue in the next one
by explaining how to compose moves to form plays. Moves are defined in
two stages: \emph{seeds}, first, give the local form for moves, which
are then defined by embedding seeds into bigger positions.

To start with, until now, our diagrams contain no information about
the `flow of time' (although it was mentioned informally for
pedagogical purposes). To add this information, for each diagram 
representing a move, we define its initial and final positions, say
 and , and view the whole move as a cospan . We have taken care, in drawing our diagrams before, of placing
initial positions at the bottom, and final positions at the top.  We
leave it to the reader to define, based on the above pictures, the
cospans
\begin{mathpar}
    \diag(.6,.2){{[n] \para [n]} \\ {\forkn} \\ {[n]} }{(m-1-1) edge (m-2-1) (m-3-1) edge (m-2-1) }\and
    \diag(.6,.2){{[m] \paraofij{c}{a} [n] } \\ {\tau_{n,a,m,c}} \\ {
        [m] \paraofij{c}{a} [n] } }{(m-1-1) edge (m-2-1) (m-3-1) edge (m-2-1) }\end{mathpar}
for forking and synchronisation, plus the ones specified in the bottom
row of \figurename~\ref{fig:stringmoves}.  In these cospans, initial
positions are on the bottom row, and we denote by
 the position
consisting of an -ary player  and an -ary player ,
quotiented by the equations  for
all . When both lists are empty, by convention,  and the
players share all channels in order.
\begin{defi}
  These cospans are called \emph{seeds}. 
\end{defi} 
\begin{rem}
  Such cospans will be used below as the morphisms of a bicategory
  , using their lower object as their \emph{target}. Thus, we
  often denote the corresponding leg by  and the other by .  The
  reason for this convention is that it emphasises below that the
  fibration axiom~\axref{fibration} is very close to a universal
  property of pullback~\cite{Jacobs}.
\end{rem}
\begin{rem}
  Both legs of each seed are monic, as will be below both legs of each
  move, and then of each play (because monics are stable under pushout
  in presheaf categories).
\end{rem}

As announced, the moves of our game are obtained by embedding seeds
into bigger positions. This means, e.g., allowing a fork move to occur
in a position with more than one player. We proceed as follows.
\begin{defi}\label{def:interface}
  Let the \emph{interface} of a seed  be , i.e., the position consisting only of the
  channels of the initial position of the seed.  More generally, an
  \emph{interface} is a position consisting only of channels.
\end{defi}

\begin{wrapfigure}[3]{r}{0pt}
  \begin{minipage}[c][3em]{0.22\linewidth}
  \vspace*{-2em}
        \diag(.3,.6){\&|(I)| I_X \\
   |(X)| Y \&|(M)| M \&|(Y)| X }{(I) edge (X) edge (M) edge (Y) (X) edge (M) (Y) edge (M) }
  \end{minipage}
\end{wrapfigure}
Since channels present in the initial position remain in the final
one, we have for each seed a commuting diagram as on the right.  By gluing any
position  to the seed along its interface, we obtain a new cospan,
say .  I.e., for any injective morphism , we push
, , and  along  and use
the universal property of pushout, as in:
  
  \begin{defi}
    Let \emph{moves} be all cospans obtained in this way.
  \end{defi}
  Recall that colimits in presheaf categories are pointwise. So, e.g.,
  taking pushouts along injective maps graphically corresponds to
  gluing diagrams together. 
  \begin{exa}\label{ex:forkmove}
    The cospan  has
    as canonical interface the presheaf ,
    consisting of two channels, say  and .  Consider the
    position  consisting of a player  with two
    channels  and , plus an additional channel . Further
    consider the map  defined by  and . The pushout
    \begin{mathpar}
      \Diag{\pbk{pi}{M'}{star} }{|(I2)| {I_{[2]}} \& |(star)| {[2]+\star} \\
         |(pi)| {\forkof{2}} \&|(M')| {M'} }{(I2) edge (star) edge (pi) (pi) edge (M') (star) edge (M') } \and \mbox{is} \and
                \diagramme[stringdiag={.3}{.6}]{}{
    \node[diagnode,at= (c.south east)] {\ \ \ .} ; \node[anchor=south] at (t_1.north) {} ; \node[anchor=south] at (t_2.north) {} ; \node[anchor=north] at (s.south) {} ; \node[anchor=north] at (y.south) {} ; \node[anchor=north] at (c.south) {} ; \node[anchor=north] at (t0.south) {} ; \node[anchor=north] at (t1.south) {} ; }{\& \& \joueur{t_1} \&  \& \joueur{t_2} \\
    \& \&   \&  \\
    \& \ \& \\
    \canal{t0} \& \& \& \couppara{para} \& \& \& \canal{t1} \& \& \joueur{y} \& \& \canal{c} \\ \& \ \& \\
    \& \&  \\
    \& \& \& \joueur{s} \& \& \& \& }{(para) edge[-] (t_2) (t1) edge[-,bend right=10] (t_2) (t0) edge[-] (s) (t1) edge[-] (s) (s) edge[-] (para) (y) edge[-] (t1) edge[-] (c) (para) edge[fore={.3}{.3},-] (t_1)
    (t0) edge[fore={.5}{.5},-,bend left=10] (t_2) (t0) edge[-,bend left=15] (t_1) (t1) edge[-,fore={1}{.5},bend right=10] (t_1) }  
    \end{mathpar}
\end{exa}
We conclude with a useful classification of moves.
\begin{defi}
  A move is \emph{full} iff it is neither a left nor a right fork.  A
  seed is \emph{basic} iff it is neither a full fork nor a
  synchronisation.  We call  the identity-on-objects subgraph of
   spanning full moves.
\end{defi}
Intuitively, a move is full when its final position contains all
possible avatars of involved players.

\subsection{From moves to plays}\label{subsec:plays}
\begin{wrapfigure}[5]{r}{0pt}
  \begin{minipage}[c]{0.25\linewidth}
    \vspace*{-1.5em}
    \diag(.3,1){\&|(U)| U \\
      |(X)| X \& \&|(Y)| Y \\
      \&|(V)| V }{(X) edge (U) edge (V) (Y) edge (U) edge (V) (U) edge (V) }
  \end{minipage}
\end{wrapfigure}
Having defined moves, we now define their composition to construct our
bicategory  of positions and plays.   will be a
sub-bicategory of , the bicategory which has as
objects all finite presheaves on , as morphisms  all
cospans , and as 2-cells  all commuting
diagrams as on the right.  Composition is given by pushout, and hence
not strictly associative. 



\begin{defi}
  Let  denote the locally full subbicategory of
   with positions as objects, whose morphisms,
  \emph{plays}, are either equivalences or isomorphic to some
  composite of moves. 
\end{defi}
We denote morphisms in  with special arrows ; composition and identities are denoted with  and 
(recalling the notation for vertical morphisms in a pseudo double
category in Section~\ref{subsec:prelim:cats}).


Again, composition by pushout glues diagrams on top of each other.
\begin{exa}\label{ex:forkplay}
Composition features some concurrency.
  Composing the move of Example~\ref{ex:forkmove} with a forking
  move by  yields
    \begin{center}
                \diagramme[stringdiag={.3}{.6}]{}{
    \node[diagnode,at= (c.south east)] {\ \ \ .} ; \node[anchor=south] at (t_1.north) {} ; \node[anchor=south] at (t_2.north) {} ; \node[anchor=south] at (y_1.north) {} ; \node[anchor=south] at (y_2.north) {} ; \node[anchor=north] at (s.south) {} ; \node[anchor=north] at (y.south) {} ; \node[anchor=north] at (c.south) {} ; \node[anchor=north] at (t0.south) {} ; \node[anchor=north] at (t1.south) {} ; }{\& \& \joueur{t_1} \&  \& \joueur{t_2} \& \& \& \& \joueur{y_1} \& \& \joueur{y_2} \\
    \& \&   \&  \\
    \& \ \& \\
    \canal{t0} \& \& \& \couppara{para} \& \& \& \canal{t1} \& \&  \& \couppara{para'} \&  \& \& \canal{c} \\
    \& \ \& \\
    \& \&  \\
    \& \& \& \joueur{s} \& \& \& \& \& \& \joueur{y} }{(t1) edge[-,bend right=10] (t_2) (t0) edge[-] (s) (t1) edge[-] (s) (para) edge[-] (t_2) (s) edge[-] (para) (y) edge[-] (t1) edge[-] (c) (para) edge[fore={.3}{.3},-] (t_1)
    (t0) edge[fore={.5}{.5},-,bend left=10] (t_2) (t0) edge[-,bend left=15] (t_1) (t1) edge[-,fore={1}{.5},bend right=10] (t_1) (c) edge[-,bend right=10] (y_2) (para') edge[-] (y_2) (y) edge[-] (para') (y) edge[-] (t1) edge[-] (c) (para') edge[fore={.3}{.3},-] (y_1) (t1) edge[fore={.5}{.5},-,bend left=10] (y_2) (t1) edge[-,bend left=15] (y_1) (c) edge[-,fore={1}{.5},bend right=10] (y_1) }  
    \end{center}
\end{exa}
\begin{exa}
  Composition retains causal dependencies between moves. To see this,
  consider the following diagram.  In the initial position, there are
  channels  and , plus three players , and
   (we indicate the channels known to each player in
  parentheses). In a first move,  outputs on , while  inputs. In
  a second move,  outputs on , while (the avatar  of) 
  inputs. The fact that  first inputs on  then on  is encoded in 
  the corresponding diagram, which looks like the
  following:
\begin{center}
      \diagramme[stringdiag={.8}{1.3}]{}{\moveccsin{b}{i}{a'}{1} \moveccsout{a}{o}{b}{1} \moveccsout{b}{o'}{a'}{1} \moveccsin[fore={.1}{.1}]{a'}{i'}{y''}{1} \node[diagnode,at= (z.south east)] {\ \ \ \ .} ; \node[below=1pt] at (b.south) {} ; \node[below=1pt] at (a'.south) {} ; \node[below=1pt] at (x.south) {} ; \node[below=1pt] at (y.south) {} ; \node[below=1pt] at (z.south) {} ; \node[above left] at (y') {} ; \twocell{o}{b}{i}{}{
          decorate,decoration={snake,amplitude=.3mm,segment length=1mm},bend left=50}
        \twocell[.4][.25]{o'}{a'}{i'}{}{
          decorate,decoration={snake,amplitude=.3mm,segment length=1mm},bend right=30}
      }{\& \& \joueur{y''} \\
         \& \& \coupin{i'}{0} \& \\ \joueur{x'} \& \& \joueur{y'} \& \& \joueur{z'} \\
         \coupout{o}{0} \& \canal{b} \& \coupin{i}{0} \& \canal{a'} \& \coupout{o'}{0} \\
         \joueur{x} \& \& \joueur{y} \& \& \joueur{z} }{(b) edge[-] (x) edge[-] (x') edge[-] (y) edge[-] (y') edge[-] (y'') (a') edge[-] (y') edge[-] (y) edge[-,bend right=10] (y'') edge[-] (z) edge[-] (z') (i) edge[-] (y) edge[-] (y') (i') edge[-] (y') edge[-] (y'') (o) edge[-] (x) edge[-] (x') (o') edge[-] (z) edge[-] (z') }
\end{center}  
\end{exa}

\subsection{Behaviours and strategies}\label{subsec:strats:old}
\subsubsection{Behaviours}\label{subsubsec:behaviours}
Recall from \citetalias{2011arXiv1109.4356H} the category  
\begin{center}
  \begin{tabular}[t]{p{.77\textwidth}p{.23\textwidth}}
    \vspace*{-2.3em}\begin{itemize}
  \item whose objects are maps  in , such that there
    exists a play , i.e., objects are plays, where we
    forget the final position;
  \item and whose morphisms  are commuting
    diagrams as on the right with all arrows monic.
  \end{itemize}
  &
    \diag|baseline= (m-1-1.base) |{U \& U' \\
      X \& X' }{(m-1-1) edge[labelu={}] (m-1-2) (m-2-1) edge[labell={}] (m-1-1) (m-2-1) edge[labeld={}] (m-2-2) (m-2-2) edge[labelr={}] (m-1-2) }
  \end{tabular}
\end{center}
Morphisms  in  represent extensions of , both
spatially (i.e., embedding into a larger position) and dynamically
(i.e., adding more moves).

We may relativise this category  to a particular position ,
yielding a category  of plays on  as follows. Consider the
functor  mapping any play  to its
initial position , and consider the pullback category  as
defined in Section~\ref{subsec:prelim:cats}. The objects of 
are just plays  on , and morphisms are morphisms of
plays whose lower border is .  This yields the definition of a
category of `naive' strategies, called behaviours.
\begin{defi}\label{def:behccs}
  The category  of \emph{behaviours} on  is the category
   of presheaves of finite sets on .
\end{defi}\enlargethispage{2\baselineskip}
Behaviours suffer from the deficiency of allowing unwanted cooperation
between players. 
\begin{exa}\label{ex:noninnocent}
  Consider a position  with three players  sharing a
  channel , and the following plays on it: in , 
  outputs on , and  inputs; in ,  outputs
  on , and  inputs; in ,  inputs on . One may
  define a \stratglobale  mapping  and  to a
  singleton, and  to . Because  is
  accepted,  accepts to output on ; and because  is
  accepted,  accepts to input on . The problem is that 
  rejecting  roughly amounts to  refusing to synchronise
  with , or conversely.
\end{exa}

\subsubsection{Strategies}\label{subsubsec:strategies}
To rectify this, we consider the following notion of view:
\begin{defi}
  Let  denote the full subcategory of  consisting of \emph{views}, i.e.,
  composites of basic seeds.
\end{defi}
We relativise views to a position  by considering the comma
category  as defined in Section~\ref{subsec:prelim:cats}.  Its
objects are pairs of a view  on a single -ary player,
and an embedding , i.e., a player of .

    \begin{defi}
     The category  of \emph{strategies} on  is the category
      of presheaves of finite ordinals on .
    \end{defi}
   \begin{rem}
     We could here replace finite ordinals with a wider category and
     still get a valid semantics. But then to show the correspondence
     with the syntax below we would work with the subcategory of
     presheaves of finite ordinals.
   \end{rem}
    
   This definition of strategies rules out undesired behaviours. We
   now sketch how to map strategies to behaviours (this is done in
   more detail for arbitrary playgrounds below): let first  be
   the category obtained by taking a comma category instead of a
   pullback in the definition of .  Then, embedding
    into  via ,
   followed by right Kan extension to  followed by
   restriction to  yields a functor . The image of a strategy  may be computed as in
    \begin{center}
      \diag{\op{(\EVi_X)} \& \op{\E_X} \& \op{\E(X)} \\
        \ford \& \set, }{(m-1-1) edge[labell={S}] (m-2-1) edge[into] (m-1-2) (m-2-1) edge[into] (m-2-2) (m-1-2) edge[labell={S'}] (m-2-2) (m-1-3) edge[linto] (m-1-2) edge[labelbr={\exta{X}{S}}] (m-2-2)
      }
    \end{center}
    where  is here obtained by right Kan extension (the embedding
     being full and faithful, we may
    choose the diagram to strictly commute).
    By the standard formula for right Kan extensions as
    ends~\citep{MacLane:cwm} we have, for any : 
     If  is boolean, i.e.,
    takes values in , then the involved end may be
    viewed as a conjunction, saying that  is accepted by 
    whenever all its views are accepted by .  Equivalently,
     is a limit of 



\subsubsection{Decomposition: a syntax for strategies}\label{subsubsec:syntax}
Our definition of strategies is rather semantic in flavour. Indeed,
presheaves are akin to domain theory. However, they also lend
themselves well to a syntactic description (unlike behaviours). Again,
this is treated at length in the abstract setting below, so we here
only sketch the construction.

First, it is shown in \citetalias{2011arXiv1109.4356H} that strategies on an arbitrary position 
are in 1-1 correspondence with families of strategies indexed by the
players of . Recall that  is the position consisting of one
-ary player. A player of  is the same as a morphism 
(for some ) in . Thus, we define the set  of players of .
\begin{prop}
We have  . For any , we denote by  the component corresponding
to  under this isomorphism.
\end{prop}
So, strategies on arbitrary positions may be entirely described by
strategies on `typical' players . As an important particular
case, we may let two strategies interact along an interface (recall
from Definition~\ref{def:interface} that this means a position
consisting only of channels), which will be the basis of our semantic
definition of fair testing equivalence. We proceed as follows.
Consider any pushout  of  where  is an
interface. We have
\begin{cor}
  .
\end{cor}
\begin{proof}
  We have , and conclude by universal
  property of coproduct.
\end{proof}
We denote by  the image of  under
this isomorphism.

Having shown how strategies may be decomposed into strategies on
`typical' players , we now explain that strategies on such
players may be further decomposed. First, we observe that 
is isomorphic to the full subcategory  of 
spanning views.  For any strategy  on  and seed , let the \emph{residual}  of  after  be
the strategy playing like  after , i.e., for all , .  is almost
determined by its residuals. The only information missing from the
's to reconstruct  is the set of initial states and how
they relate to the initial states of each . This may be
taken into account as follows.

\begin{defi}\label{def:restriction}
  For any  and initial state , let ,
   the \emph{restriction} of  to , be determined by

where  denotes the unique morphism .
\end{defi}
 is determined by its set  of initial
states, plus the map  sending any  and isomorphism class 
of seeds to . In other words, we have
for all :
\begin{thm}
   .
\end{thm}
Given an element  of the right-hand side, the
corresponding strategy maps the identity view  to , and any
non-identity view  on  to the sum .

A closely related result is that strategies on a player  are in
bijection with infinite terms in the following typed grammar, with
judgements  and , where  is called a
\emph{definite strategy} and  is a \emph{strategy}:
\begin{mathpar}
\inferrule{\ldots \ n_b \vdash S_b \ \ldots \ {(\forall b \colon [n_b] \proto [n] \in \MMMB_n)}
}{
n \vdashdefinite \langle (S_b)_{b \in \MMMB_n} \rangle
}
\and
\inferrule{\ldots \  n \vdashdefinite D_i \  \ldots \ (\forall i \in m)}{
n \vdash \oplus_{i \in m} D_i}~(m \in \Nat).
\end{mathpar}
Here,  denotes the set of all isomorphism classes of seeds
from .  This achieves the promised syntactic description of
strategies. We may readily define the translation of CCS processes,
coinductively, as follows. For processes with channels in , we
define

For example,  is mapped to



\subsection{Semantic fair testing}\label{subsec:fair}
The tools developed in the previous section yield the following
semantic analogue of fair testing equivalence.
\begin{defi}\label{def:cw:successful}
  \emph{Closed-world} moves are those generated by some seed among
  ,,, and . A play is
  \emph{closed-world} when it is a composite of closed-world moves.
  Let a closed-world play be \emph{successful} when it contains a
   move, and \emph{unsuccessful} otherwise. A state  of a behaviour  over a closed-world play
   is successful when the play  is, and unsuccessful
  otherwise.
\end{defi}

Let then  denote the set of behaviours  such that any unsuccessful, closed-world state admits a
successful extension.  Formally:
\begin{defi}\label{def:bbotccs}
  Let  iff, for any unsuccessful, closed-world play  and , there exists a successful,
  closed-world , a morphism  in , and a state
   such that .
\end{defi}
Finally, let us say
that a triple , for any  (where  is an
interface) and , \emph{passes} the test
consisting of a morphism  of positions and a
strategy  iff , where 
is the pushout of  and .  Let  denote the set of
all such .
\begin{defi}
  For any , , , and
  ,  iff  and
  .
\end{defi}
Obviously,  is an equivalence relation, analogous to standard fair
testing equivalence, which we hence also call (semantic) fair testing
equivalence.

This raises the question of whether the translation 
preserves or reflects fair testing equivalence. The rest of the paper
is devoted to proving that it does both. As announced in the
introduction, this is done by organising the game into a
\emph{playground}, as defined in the next section.

\section{Playgrounds: from behaviours to strategies}\label{sec:playgrounds}

\subsection{Motivation: a pseudo double category}\label{subsec:pseudodouble}
\begin{wrapfigure}[6]{r}{0pt}
  \begin{minipage}[c]{0.25\linewidth}
    \vspace*{-1.5em}
    \diag{Y' \& Y \\
      U' \& U \\
      X' \& X }{(m-1-1) edge[labelu={h}] (m-1-2) (m-2-1) edge[labelo={k}] (m-2-2) (m-3-1) edge[labeld={l}] (m-3-2) (m-1-1) edge[labell={s'}] (m-2-1) (m-1-2) edge[labelr={s}] (m-2-2) (m-3-1) edge[labell={t'}] (m-2-1) (m-3-2) edge[labelr={t}] (m-2-2) }
  \end{minipage}
\end{wrapfigure}
We start by organising the game described above into a (pseudo) double
category.  We have seen that positions are the objects of the category
, whose morphisms are embeddings of positions.  We have also
seen that positions are the objects of the bicategory , whose
morphisms are plays.  It should seem natural to define a pseudo double
category structure with
\begin{itemize}
\item  as horizontal category,
\item  as vertical bicategory,
\item commuting diagrams as on the right as double cells.
\end{itemize}
Here,  is the initial position and  is the final one;
all arrows are mono.
  This forms a pseudo double category , and we have:
\begin{prop}\label{prop:pseudodouble}
  The functor  is a Grothendieck
  fibration~\citep{Jacobs}.
\end{prop}
Intuitively,  being a fibration demands some canonical way of
\emph{restricting} a given play on some position  to some
`subposition' .  More technically, it amounts to the
existence, for all plays  and horizontal morphisms , of a universal ( maximal) way of restricting 
to , as on the left below:
\begin{mathpar}
    \diag(1,1){|(X)| {Y'} \& |(Y)| {Y} \\ |(U)| {X'} \& |(V)| {X} }{(X) edge[dashed,labela={h}] (Y) edge[pro,dashed,twol={u'}] (U) (Y) edge[pro,twor={u}] (V) (U) edge[labela={l}] (V) (l) edge[dashed,cell=.3,labela={\alpha}] (r) }
\and     \Diag(.25,.8){}{|(U'')| E'' \\ \\ 
      \& |(U')| E' \& \& |(U)| E \\ 
      |(Y'')| p(E'') \\ \\ 
      \& |(Y')| p(E') \& \& |(Y)| p(E).  }{(U') edge[labelb={r}] (U) (Y') edge[labelb={p(r)}] (Y) (U) edge[serif cm-to,fore,shorten <=.3cm,shorten >=.3cm] (Y) (U'') edge[bend left=10,labelar={t}] (U) (Y'') edge[bend left=10,labelar={p(t)}] (Y) (U'') edge[serif cm-to,fore,shorten <=.3cm,shorten >=.3cm] (Y'') (U'') edge[dashed,labelbl={s}] (U') (Y'') edge[labelbl={k}] (Y') (U') edge[serif cm-to,fore,shorten <=.3cm,shorten >=.3cm] (Y') (U') edge[serif cm-to,shorten <=.3cm,shorten >=.3cm] (Y') (U'') edge[serif cm-to,shorten <=.3cm,shorten >=.3cm] (Y'') (U) edge[serif cm-to,shorten <=.3cm,shorten >=.3cm] (Y) } \end{mathpar}
Formally, consider any functor . A morphism  in  is \emph{cartesian} when, as on the right
above, for all  and ,
if  then there exists a unique  such that  and .
\begin{defi} 
  A functor  is a \emph{fibration} iff for all , any  has a cartesian lifting, i.e., a 
  cartesian antecedent by . 
\end{defi} 

Proposition~\ref{prop:pseudodouble} is proved among other facts in
Section~\ref{sec:ccs}.  This was the starting point of the
notion of playground: which axioms should we demand of a pseudo double
category in order to enable the constructions of
\citetalias{2011arXiv1109.4356H}?  We follow the constructions in this
section, considering an arbitrary pseudo double category , on
which we impose axioms along the way. Objects and vertical
morphisms will respectively be called \emph{positions} and
\emph{plays}. The pseudo double category  does satisfy the
axioms, albeit in a non-trivial way. This is stated and proved in
Section~\ref{sec:ccs}, but we use the result in advance in examples to
illustrate our constructions. 

Let us record the axioms imposed on  in the next sections to
obtain our bisimulation result (Theorem~\ref{thm:bisim}):
\begin{center}
  \begin{minipage}[t]{0.48\linewidth}
    \begin{itemize}
    \item \axref{fibration}, page \pageref{fibration},
    \item \axref{discreteness}---\axref{fibration:continued}, page
      \pageref{discreteness},
    \item \axref{ax:views}, page \pageref{ax:views},
    \item \axref{leftdecomposition}, page \pageref{leftdecomposition},
    \end{itemize}
  \end{minipage}
  \hfil
  \begin{minipage}[t]{0.48\linewidth}
    \begin{itemize}
    \item \axref{views:decomp}, page \pageref{views:decomp},
    \item \axref{finiteness}, page \pageref{finiteness},
    \item \axref{basic:full}, page \pageref{basic:full}.
    \end{itemize}
  \end{minipage}
\end{center}
\subsection{Behaviours}\label{subsec:beh}
The easiest construction of \citetalias{2011arXiv1109.4356H} to carry over to the abstract setting
of playgrounds is that of behaviours.  First, let us stress that, in
the case of ,  is very different from the category of
plays called  recalled in Section~\ref{subsubsec:behaviours}.
Indeed, any morphism  in  in
particular induces an embedding of the final position  of
 into that of . In , instead, a morphism  may
involve extending  with more moves.
\begin{exa}
  The move of Example~\ref{ex:forkmove} embeds into the
  play of Example~\ref{ex:forkplay} in the sense of , but not in
  the sense of .  Indeed, the passive player  of
  Example~\ref{ex:forkmove} does belong to the final position, but its
  image in Example~\ref{ex:forkplay} does not.
\end{exa}
\begin{wrapfigure}[6]{r}{0pt}
  \begin{minipage}{0.3\linewidth}
    \centering
    \vspace*{-2em}
    
  \end{minipage}
\end{wrapfigure}
So our first step is to construct an analogue of  from any
playground . Intuitively, it should have as objects all plays, and
as morphisms  all pairs  as on the right.
However, this definition is slightly wrong on morphisms, in that
 carries some information about how  embeds into ,
while we are only interested in how  does.  Thus, we instead define
morphisms  to be pairs  as in~\eqref{eq:alpha},
quotiented by the equivalence relation generated by pairs
 such that there exists morphisms  and
 satisfying , as in
   

   In order to define composition in this category, we state the
   following axiom (cf.\ Proposition~\ref{prop:pseudodouble}).
\begin{ax}
  \begin{myaxioms}[series=myaxiomsseries]
  \item (Fibration) The vertical codomain functor  is a fibration.\label{fibration}
  \end{myaxioms}
\end{ax}

Composition may now be defined by pullback (i.e., cartesian lifting in
the fibration ) and pasting:
   \begin{center}
     \Diag{\path (Z') -- node[pos=.5] (mid) {} (X'); \path (Y) edge[cell={.5},labelu={\alpha}] (r) ; \path (mid) edge[cell={.5},labelu={\beta}] (right) ; \pbkk{Z}{Z''}{Z'} }{|(Z'')| Z'' \& |(Z')| Z' \& |(V)| V \\
       |(Z)| Z \& |(Y')| Y' \&  \\
       |(Y)| Y \& \& \\
       |(X)| X  \& |(X')| X' \& |(U)| U.
       }{(Z) edge[pro,labell={w}] (Y) edge (Y') (Y) edge[pro,labell={u}] (X) (X) edge (X') (Y') edge[pro,twor={u'}] (X') (Z') edge[pro,labell={w'}] (Y') edge (V) (X') edge (U) (V) edge[pro,tworight={right}{u''}] (U) (Z'') edge[pro,labell={w''}] (Z) edge (Z') }
   \end{center}
   (We use `double pullback' marks to denote cartesian double cells.)
   Quotienting makes composition functional and associative, and
   furthermore it is compatible with the above equivalence. Identities are obvious.

   \begin{prop}
     This forms a category .
   \end{prop}
   \begin{exa}
     Consider the move  from Example~\ref{ex:forkmove}, and let us
     name its initial and final positions as in .  Let us further call  the play from
     Example~\ref{ex:forkplay}, obtained by composing  with a
     forking move by .  In order to obtain a double cell
     , we need to provide an extension of  with some
     move by , and there are actually three ways of doing this.
     One is with a left forking move, another is with a right forking
     move, and the last is with a full forking move. In this example,
     the last possibility actually yields an identity double cell , and may be obtained using~\axref{fibration} in the
     \begin{minipage}[t]{\linewidth}
       \vspace*{-.7em}
       \begin{wrapfigure}{r}{0pt}
       \begin{minipage}[t]{.18\linewidth}
       \vspace*{-1.5em}
         \Diag(.6,1){\pbkk{Y}{Z}{Z'} \node[at=(c.center),anchor=base west] {} ; }{|(Z)| Z \&|(Z')| Z' \\
           |(Y)| Y \&|(Y')| Y' \\
           |(X)| X \&|(X')| X' }{(Z) edge[pro,twoleft={left}{w}] (Y) edge (Z') (Y) edge[pro,twol={u}] (X) edge (Y') (X) edge (X') (Z') edge[pro,tworight={right}{w'}] (Y') (Y') edge[pro,twor={u'}] (X') (l) edge[cell={.3},labelu={\alpha}] (r) }
       \end{minipage}
       \end{wrapfigure}
       \noindent following general way.  Consider any double cell
        in , and play  such that  is well-defined. Then, letting  be the cartesian lifting of  along , we
       obtain a morphism  in , as in on the
       right.  The universal property of  here amounts to the
       fact that left and right forking moves both embed uniquely into
       full forking, which makes our three candidate morphisms  equal in~.
     \end{minipage}
   \end{exa}

   Recalling notation from Section~\ref{subsec:prelim:cats}, consider
   now the pullback category , where  is any position.
   Following Definition~\ref{def:behccs}, we state: \begin{defi}\label{def:beh}
  The category  of \emph{behaviours} on  is
  , i.e., the category of presheaves of finite sets on
  .
\end{defi}
This construction has a bit of structure. Indeed, the
map  extends to a pseudo functor  by vertical post-composition.  Post-composing the opposite of
this pseudo functor by , we obtain a
pseudo functor , satisfying .


\subsection{More axioms}
We now turn to generalising further constructions
of \citetalias{2011arXiv1109.4356H} to the general setting of
playgrounds.  We mentioned in Section~\ref{sec:HP} that strategies on
a position  should be defined as presheaves on the category of
views on .  We will further want to generalise the decomposition
theorems for strategies of \citetalias{2011arXiv1109.4356H}, which
crucially rely on a property of views stated (in
Section~\ref{subsec:views} below) as Proposition~\ref{prop:decompV}.

In order for this to work, we need to state more axioms for .  In
particular, the axioms equip  with a notion of \emph{player} for a
position .  Each position has a set of players, each player having
a certain `type'.  Furthermore, in Section~\ref{subsec:views},  is
equipped with a notion of view; and views have a type, too.
Proposition~\ref{prop:decompV}, e.g., states that views on a position
 form a coproduct, over all players  in , of views over the
type of .

We first state a series of simple axioms, and then, building on these,
two more complicated axioms.
\newcounter{axiomcounter}
\begin{ax}\label{ax:indivmoves}
   is equipped with
  \begin{itemize}
  \item a full subcategory  of objects called
    \emph{individuals},
  \item a replete class  of vertical morphisms called \emph{moves},
    with replete subclasses  and , respectively called
    \emph{basic} and \emph{full} moves,
  \item a map  called the \emph{length},
  \end{itemize}
  satisfying the following conditions:
  \begin{axioms}
  \item  is discrete. Basic moves have no non-trivial
    automorphisms in .  Vertical identities on individuals have
    no non-trivial endomorphisms.
    \label{discreteness}
  \item (Individuality) Basic moves have individuals as both domain
    and codomain. \label{individuality}
  \item
    \begin{minipage}[t]{.97\linewidth}
      \vspace*{-.82em}
      \begin{wrapfigure}{r}{0pt}
        \begin{minipage}[t]{.18\linewidth}
          \vspace*{-1.5em} \diag{|(X0)| X \&|(X)| X \\
            |(Xi)| X \&|(Y)| Y }{(X0) edge[identity,pro,twol={}] (Xi) edge[identity] (X) (X) edge[pro,twor={u}] (Y) (Xi) edge[labelb={\bar{u}}] (Y) (l) edge[cell=0.3,labelb={\alpha^u}] (r) }
        \end{minipage}
      \end{wrapfigure}
      (Atomicity) For any cell , if  then also .  Up to a special isomorphism in
      , all plays  of length  admit decompositions into
       moves.  For any  of length 0, there is
      an isomorphism  as on the right in .
    \end{minipage}
\label{atomicity}
\item (Fibration, continued) Restrictions of moves (resp.\ full moves)
  to individuals either are moves (resp.\ full moves), or have length
  0. \label{fibration:continued}
  \end{axioms}
\end{ax}
Replete means stable under isomorphism (here in ).  In
\axref{fibration:continued}, \emph{restriction} is w.r.t.\ the
fibration , as explained below
Proposition~\ref{prop:pseudodouble}. 

\begin{defi}
  A \emph{player} in a position (i.e., object) , is a pair ,
  where  and . Let  be the set of players of .
\end{defi}
\begin{exa}
  In , individuals are representable positions , which
  consist for some  of a single -ary player, connected to 
  distinct channels. Importantly, for each isomorphism class of such
  positions we pick one representative: this makes  discrete by
  Yoneda. Furthermore, basic moves are basic seeds.
\end{exa}

Here is a further, crucial axiom.
\begin{defi}\label{def:DB0}
  Let  be the full subcategory of  having as objects
  basic moves and morphisms of length 0 between individuals.
\end{defi}

\begin{ax}
  \begin{axioms}
  \item (Views) For any move  in , the domain
    functor  is an equivalence of categories. \label{ax:views}
  \end{axioms}
\end{ax}
In elementary terms, for any  in  with , there exists a cell
\begin{center}
  \diag{|(d)| d \& |(Y)| Y \\
    |(dMy)| d^{y,M} \& |(X)| X, }{(d) edge[labelu={y}] (Y) edge[pro,dashed,twol={v^{y,M}}] (dMy) (Y) edge[pro,twor={M}] (X) (dMy) edge[dashed,labeld={y^M}] (X) (l) edge[cell=.3,dashed,labelu={\scriptstyle \alpha^{y,M}}] (r) }
\end{center}
with , which is unique up to canonical isomorphism of
such. An isomorphism between two such tuples, say  and 
is a diagram
\begin{center}
  \Diag (.3,.5) {\twocellr{dMy}{d}{Y}{\alpha'} \twocellr{d''}{d}{Y}{\alpha''} \twocellro[.5]{dMy}{d}{d''}{\beta} \path[->,draw] (dMy) edge node[pos=.7,above] {} (X) edge[labelbl={h}] (d'')
    (d'') edge[labelbr={y''}] (X) (d) edge[pro,fore,labelr={v''}] (d'') ; }{\& |(d)| d \& \& \& |(Y)| Y \\
    \& {} \\
    |(dMy)| d' \& \& \& \& |(X)| X \\
    \& \& |(d'')| d'' \& }{(d) edge[labelu={y}] (Y) edge[pro,twol={v'}] (dMy) (Y) edge[pro,twor={M}] (X) }    
\end{center}
such that  (where necessarily
, , and ).





\begin{exa}
  This axiom is obviously satisfied by .
\end{exa}

We then have two decomposition axioms.
\begin{ax}
  \begin{axioms}
  \item (Left decomposition) 
Any double cell
    \begin{center}
      \Diag{\twocellbr{B}{A}{X}{\alpha} }{|(A)| A \& |(X)| X \\
        \& |(Y)| Y \\
        |(B)| B \& |(Z)| Z }{(A) edge[labelu={h}] (X) edge[pro,labell={u}] (B) (X) edge[pro,labelr={w_1}] (Y) (Y) edge[pro,labelr={w_2}] (Z) (B) edge[labeld={k}] (Z) }
      \hfil decomposes as \hfil
      \Diag(1,2){\twocellbr[.3]{C}{A}{X}{\alpha_1} \twocellbr[.3]{B}{C}{Y}{\alpha_2} \twocell[.3]{L}{A}{C}{}{celllr={0}{0},bend
          right,fore,labelbl={\scriptscriptstyle \alpha_3}} }{\& |(A)| A \& |(X)| X \\
        |(L)| \& |(C)| C \& |(Y)| Y \\
        \& |(B)| B \& |(Z)| Z }{(A) edge[labelu={h}] (X) edge[pro] node[pos=.5,anchor=north west] {} (C) edge[pro,bend right=70,labell={u}] (B) (C) edge[pro] node[pos=.5,anchor=north west] {} (B) edge[labelu={l}] (Y) (X) edge[pro,labelr={w_1}] (Y) (Y) edge[pro,labelr={w_2}] (Z) (B) edge[labeld={k}] (Z) }
    \end{center}
    with  an isomorphism, in an essentially unique way.
    \label{leftdecomposition}
  \end{axioms}
\end{ax}


Here is our second decomposition axiom. 

\begin{ax}
  \begin{axioms}
  \item (Right decomposition) Any double cell as in the center below,
    where  is a basic move and  is a move, decomposes in exactly
    one of the forms on the left and right:
  \begin{mathpar}
    \begin{minipage}[t]{0.18\linewidth}
      \centering \Diag {\twocell[.4][.3]{B}{A}{X}{}{celllr={0.0}{0.0},bend
          right=30,labelbr={\alpha_1}} \twocell[.4][.3]{C}{B}{Y}{}{celllr={0.0}{0.0},bend
          right=20,labelbr={\alpha_2}} }{|(A)| A \& |(X)| X \\
     |(B)| B \& |(Y)| Y \\
    |(C)| C \& |(Z)| Z }{(A) edge[pro] (B) edge (X) (B) edge (Y) edge[pro] (C) (C) edge (Z) (X) edge[pro] (Y) (Y) edge[pro] (Z) } 
    \end{minipage}
    \and \leftlsquigarrow \and
    \begin{minipage}[t]{0.18\linewidth}
      \centering      \Diag{\twocellbr{B}{A}{X}{\alpha} }{|(A)| A \& |(X)| X \\
     |(B)| B \& |(Y)| Y \\
    |(C)| C \& |(Z)| Z }{(A) edge[labelu={h}] (X) edge[pro,labell={w}] (B) (B) edge[pro,labell={b}] (C) (X) edge[pro,labelr={u}] (Y) (Y) edge[pro,labelr={M}] (Z) (C) edge[labeld={k}] (Z) }
    \end{minipage}
\and \rightrsquigarrow \and
     \begin{minipage}[t]{0.18\linewidth}
      \centering \Diag {\twocell[.4][.3]{B}{A}{X}{}{celllr={0.0}{0.0},bend
          right=30,labelbr={\alpha_1}} \twocell[.3][.4]{C}{Y}{Z}{}{celllr={0.0}{0.0},bend
          right=20,labeld={\alpha_2}} }{|(A)| A \& |(X)| X \\
     |(B)| B \& |(Y)| Y \\
    |(C)| C \& |(Z)| Z. }{(A) edge[pro] (B) edge (X) (B) edge[pro] (C) (C) edge (Z) edge (Y) (X) edge[pro] (Y) (Y) edge[pro] (Z) } 
    \end{minipage}
  \end{mathpar}
    \label{views:decomp}
  \end{axioms}
\end{ax}

\begin{rem}
  This axiom takes pseudoness rather sloppily. Indeed, the domain of
  the right-hand composite is not really , but rather
  . So we actually mean , where
   cancels identities on the left.
\end{rem}


\begin{exa} \hfill \  \linebreak
\begin{minipage}{\textwidth}
\begin{wrapfigure}[6]{r}{0pt}
  \begin{minipage}[c]{0.18\linewidth}
    \vspace*{-1.5em}
    \Diag{\twocellbr{B}{A}{X}{\alpha} }{|(A)| X \& |(X)| X \\
      |(B)| X \&  |(Y)| X \\
      |(C)| X \& |(Z)| X }{(A) edge[identity] (X) edge[pro,labell={i_y}] (B) (X) edge[identity] (Y) (Y) edge[pro,labelr={S}] (Z) (B) edge[pro,labell={o_x}] (C) (C) edge[identity] (Z) }
  \end{minipage}
\end{wrapfigure}
That this axiom is satisfied by  is not obvious and is proved
in Section~\ref{sec:ccs}. However, let us disprove the more general
version where  is not required to be basic. Let  consist of two
players  and  sharing a channel . Let 
be the play where  inputs on ,  be the
play where  outputs on , and let  be the
play where both players synchronise on .  We obtain a double cell
as on the right, which does not decompose as
in~\axref{views:decomp}. The problem here is that, on the left-hand
side, the upper input by  has to be mapped to , which prevents any
suitable decomposition.
\end{minipage}
\end{exa}

We now define and study views.

\subsection{Views}\label{subsec:views}
\begin{defi}
  A \emph{view} in  is a play which is specially isomorphic in
   to a possibly empty (vertical) composite of basic moves. I.e.,
  if

are all basic moves, then the composite is a view. Let  be the
full subcategory of  consisting of views.
\end{defi}
The definition includes the `identity' view . In ,
this of course coincides with views as defined in
\citetalias{2011arXiv1109.4356H}.

Here is an important consequence of our axioms. It is a bit
complicated to state, but very useful in the (more intelligible)
developments on views below.

\begin{lem}\label{lem:big}
    For all plays  and , 
    views , and double cells ,
    for all special isomorphisms 
    
    and 
    
    decomposing  and  into moves, there exists a unique, strictly monotone map
     with 
    and double cells  and  
     for , where
    
such that ,
as in 
    \begin{mathpar}
  \Diag(.6,4){\path (vdotsi) -- node (hurm) {} (d'n1) ; \deuxcellule{1.5}{1}{dn1}{dn}{l}{}{cell=.3,labelb={\gamma}} \deuxcellule{1.1}{.9}{l}{dn}{r}{}{celllr={0}{.4},labela={\alpha\ \ \ \ }} \path[->] (r) edge[cell={.2},labela={\gamma'}] (hurm) ; }{|(A)| Y \&|(X)| X_p \\
   |(dn)| d_n \&|(d'n)| X_{p-1} \\
   |(dn1)| d_{n-1} \&|(d'n1)|  \\
   |(vdots)| \vdots \&|(vdotsi)| \\
   |(d1)| d_1 \&|(d'1)| X_1 \\
   |(d0)| d_0 \&|(d'0)| X_0 }{(A) edge[labell={w}] (dn) edge (X) (dn) edge[labell={b_n}] (dn1) edge[bend left=60] node[pos=.3,right] (l) {} (d0) (X) edge[labelr={M_{p}}] (d'n) edge[bend right=50,twor={}] node[pos=.3,left] {} (d'0) (d0) edge (d'0) (d1) edge[labell={b_1}] (d0) (d'1) edge[labelr={M_1}] (d'0) }
\and  = \and    
    \diagramme[diag={0.6}{1.5}]{}{\twocellbr{B0}{A0}{Bf1minus1}{} \twocellbr{A0}{A1}{Bf1}{\alpha_{f(1)}} \twocellr{Bf1}{A1}{Bf2minus1}{} \twocellbr{Amminus1}{Am}{Bfm}{\alpha_{f(n)}} \twocellbr{Am}{A}{Bn}{\beta} }{|(A)| Y \&|(Bn)| X_p \\
       |(Am)| d_n \&|(Bfm)| X_{f (n)} \\
       |(Amminus1)| d_{n-1} \&|(Bfmminus1)| X_{f(n)-1} \\
       \&|(Bf2minus1)| X_{f(2)-1} \\
       |(A1)| d_1 \&|(Bf1)| X_{f (1)} \\
       |(A0)| d = d_0 \&|(Bf1minus1)| X_{f (1) - 1} \\
         \&|(B0)| X_{0}. }{(A) edge (Bn) edge[pro,labell={w}] (Am) (Am) edge (Bfm) edge[pro,labell={b_n}] (Amminus1) (Amminus1) edge (Bfmminus1) (A1) edge (Bf2minus1) edge (Bf1) edge[pro,labell={b_1}] (A0) (A0) edge (Bf1minus1) edge (B0) (Bn) edge[pro,labelr={M_{> f (n)}}] (Bfm) (Bfm) edge[pro,labelr={M_{f (n)}}] (Bfmminus1) (Bf2minus1) edge[pro,labelr={M_{] f (1), f (2)[}}] (Bf1) (Bf1) edge[pro,labelr={M_{f (1)}}] (Bf1minus1) (Bf1minus1) edge[pro,labelr={M_{< f (1)}}] (B0) (Bfmminus1) edge[dotted] (Bf2minus1) (Amminus1) edge[dotted] (A1) }
  \end{mathpar}
\end{lem}
In the case , also , and the decomposition of 
  should be understood as  being an
  \emph{identity}, with  being
  . 

\begin{rem}
  Only  is claimed to be unique here.  Furthermore, as
  in~\axref{views:decomp}, we are a bit sloppy regarding pseudoness.
  Also, in the following, we consider only the underlying map , implicitly extended with .  Finally, for
  all , there exist  and
   as in the lemma. This is obvious when  and ;
  we just explained it for the case ; and when  it follows
  from Lemma~\ref{lem:hv} below.
\end{rem}
\begin{proof}
  We proceed by lexicographic induction on the pair .  

  If  then our map  is the unique map , , and we take .  Otherwise, we apply~\axref{views:decomp} with ,
  ,  and
  .
    \begin{itemize}
    \item If we are in the left-hand case,  decomposes as
      , with 
      and .  By induction hypothesis,
      we obtain a map  and a
      corresponding decomposition of .  We then let
       map  to , and  to
       for any .
    \item If we are in the right-hand case, we obtain a map
      , and return the map .
    \end{itemize}
    This shows existence of the desired decomposition. For uniqueness,
    consider any map  and corresponding
    decomposition.  Axiom~\axref{leftdecomposition} entails that at
    each stage,  and
     have the same cardinality. Indeed,
    otherwise, we would find isomorphic decompositions of  with incompatible lengths.  Thus, .
\end{proof}

We continue with a few easy results.  Recall the family of isomorphisms
 from Axiom~\axref{atomicity}, indexed by vertical morphisms
of length .  Furthermore, let us denote by  and  the
coherence isomorphisms from  for cancelling vertical identities.
\begin{lem}\label{lem:alphau}
  For any  of length , there is an isomorphism
  \begin{mathpar}
          \diag{|(X)| X \&|(Y)| Y \\
         |(Y0)| Y \&|(Yi)| Y }{(Y) edge[identity,pro,twor={}] (Yi) (X) edge[labela={\bar{u}}] (Y) edge[pro,twol={u\ \ }] (Y0) (Y0) edge[identity] (Yi) (l) edge[cell=0.3,labela={\alpha_u}] (r) }         
  \end{mathpar}
  in , such that  and .
\end{lem}
\begin{proof}
  Pose .
\end{proof}
\begin{lem}\label{lem:hv}
  If  has length , then , , and  and  are horizontal inverses.
\end{lem}
\begin{proof}
  By~\axref{discreteness}.
\end{proof}

\begin{lem}\label{lem:B0isos}
   (Definition~\ref{def:DB0}) is a groupoid.
\end{lem}
\begin{proof}
  This means that any  in  is an
  isomorphism.  Let  and . Existence of  entails  and , by~\axref{discreteness}.

  If , then  and  are both
  mapped by  to . By~\axref{ax:views}, there is thus a unique
  isomorphism  in  such that , i.e., . This shows that
   is an iso.
  
  If  has length , then by~\axref{atomicity} we furthermore
  have  and . Moreover, the
  composite  (with
   and  as in Lemma~\ref{lem:alphau}
  and~\axref{atomicity}) is an endomorphism of , hence
   by~\axref{discreteness}.  It is thus an
  isomorphism, hence so is , which is equal to 
  by two applications of Lemma~\ref{lem:hv}.
\end{proof}

\begin{lem}\label{lem:auto}
  In any category , for any object  isomorphic to an object  such
  that  has no non-trivial endomorphisms,  does not have any
  non-trivial endomorphisms either.
\end{lem}
\begin{proof}
  By the Yoneda lemma, we have .
\end{proof}

\begin{lem}
   Any groupoid  whose objects have no non-trivial endomorphisms
   is an equivalence relation.
\end{lem}
\begin{proof}
  For any objects  and , we have that if  is non-empty
  then  and  are isomorphic, so by Yoneda .
\end{proof}

\begin{cor}\label{cor:B0eqrel}
 is an equivalence relation.  
\end{cor}
This adds to Lemma~\ref{lem:B0isos} that there is at most one morphism
between any two objects.
  \begin{proof}
    By Lemma~\ref{lem:auto} and~\axref{atomicity}, its objects have no
    non-trivial automorphisms, which in a groupoid is the same as
    having no non-trivial endomorphisms. By the last result, 
    is an equivalence relation.
  \end{proof}

This leads to a better understanding of .
\begin{lem}\label{lem:preorder}
  Consider any morphism of views , with
  isomorphisms 
  and , for
  basic moves  and  for all  and . We have ,
   for all , and there exist unique
  isomorphisms  such that , as in
\begin{mathpar}
  \diag(.6,4){|(dn)| d_n \&|(d'n)| d'_n \\
   |(dn1)| d_{n-1} \&|(d'n1)| d'_{n-1} \\
   |(vdots)| \vdots \&|(vdotsi)| \vdots \\
   |(d1)| d_1 \&|(d'1)| d'_1 \\
   |(d0)| d_0 \&|(d'0)| d'_0 }{(dn) edge[labell={b_n}] (dn1) edge (d'n) edge[bend left=50,twol={}] node[pos=.3,right] {} (d0) (d'n) edge[labelr={b'_n}] (d'n1) edge[bend right=50,twor={}] node[pos=.3,left] {} (d'0) (d0) edge (d'0) (d1) edge[labell={b_1}] (d0) (d'1) edge[labelr={b'_1}] (d'0) (l) edge[cell={.4},labela={\alpha}] (r) (vdots) edge[cell={.2},labela={\gamma}] (l) (r) edge[cell={.2},labela={\gamma'}] (vdotsi) }
\and  = \and
\diag(.6,2){|(dn)| d_n \&|(d'n)| d'_n \\
   |(dn1)| d_{n-1} \&|(d'n1)| d'_{n-1} \\
   |(vdots)| \vdots \&|(vdotsi)| \vdots \\
   |(d1)| d_1 \&|(d'1)| d'_1 \\
   |(d0)| d_0 \&|(d'0)| d'_0. }{(dn) edge[twol={b_n}] (dn1) edge[identity] (d'n) (d'n) edge[twor={b'_n}] (d'n1) (d0) edge[identity] (d'0) (d1) edge[twoleft={b1}{b_1}] (d0) (d'1) edge[tworight={b'1}{b'_1}] (d'0) (dn1) edge[identity] (d'n1) (l) edge[cell={1},labela={\alpha_n}] (r) (b1) edge[cell={1},labela={\alpha_1}] (b'1) (d1) edge[identity] (d'1) }
\end{mathpar}
\end{lem}
\begin{proof}
Applying Lemma~\ref{lem:big} with  yields  which by
Corollary~\ref{cor:B0eqrel} and~\axref{atomicity} has to be a bijection. This yields
the desired 's, which are unique by Corollary~\ref{cor:B0eqrel} again.
\end{proof}

This entails:
\begin{cor}\label{cor:Vpreordergroupoid}
   is an equivalence relation, compatible with length.
\end{cor}

Here is an analogue of~\axref{ax:views} for general plays and views
instead of just moves and basic moves.
\begin{prop}\label{prop:views}
For any  in  with ,
    and any  in , there exists a cell
\begin{center}
  \diag{|(d)| d \& |(Y)| Y \\
    |(dMy)| d^{y,u} \& |(X)| X, }{(d) edge[labelu={y}] (Y) edge[pro,dashed,twol={v^{y,u}}] (dMy) (Y) edge[pro,twor={u}] (X) (dMy) edge[dashed,labeld={y^u}] (X) (l) edge[cell=.3,dashed,labelu={\scriptstyle \alpha^{y,u}}] (r) }
\end{center}
with  a view, which is unique up to canonical isomorphism of
such.   
\end{prop}

\begin{proof}
  We find  by repeated application of~\axref{ax:views}.  For
  essential uniqueness, by repeated application of~\axref{ax:views}, 
  we find an isomorphism between any two such views, which 
  by Corollary~\ref{cor:Vpreordergroupoid} is unique.
\end{proof}


We continue with an analogue of~\axref{views:decomp}:
\begin{prop}\label{prop:views:decomp}
  Any double cell
  \begin{center}
      \Diag{\twocellbr{B}{A}{X}{\alpha} }{|(A)| A \& |(X)| X \\
     |(B)| B \& |(Y)| Y \\
    |(C)| C \& |(Z)| Z, }{(A) edge[labelu={h}] (X) edge[labell={w}] (B) (B) edge[labell={v}] (C) (X) edge[labelr={u}] (Y) (Y) edge[labelr={u'}] (Z) (C) edge[labeld={k}] (Z) }
  \end{center}
where  is a view, decomposes in exactly one of the following forms:
  \begin{center}
    \begin{minipage}[t]{0.35\linewidth}
      \centering \Diag (.5,.25) {\twocell[.4][.2]{A'}{A}{X}{}{celllr={0.0}{0.0},bend
          right=10,labelbr={\alpha_1}} \twocell[.4][.2]{B}{A'}{Y}{}{celllr={0.0}{0.0},bend
          right=20,labelbr={\alpha_2}} \twocell[.2][.2]{C}{B}{Y'}{}{celllr={0.0}{0.0},bend
          right=20,labelbr={\alpha_3}} \twocell[.2][.4]{B}{A}{A'}{}{celllr={0.0}{0.0},bend
          right=10,labeld={\alpha_4}} \twocell[.4][.2]{Y'}{Y}{Z}{}{celllr={0.0}{0.0},bend
          right=10,labeld={\alpha_5}} }{|(A)| A \& \&\&\&\&\&\& \& |(X)| X \\
        \& |(A')| A' \&\&\&\&\&\& \&  \\
        |(B)| B \& \&\&\&\&\&\& \& |(Y)| Y \\
        \& \&\&\&\&\&\& |(Y')| Y' \&  \\
        |(C)| C \& \&\&\&\&\&\& \& |(Z)| Z }{(A) edge[pro] (B) edge[pro] (A') edge (X) (A') edge[pro] node[pos=.5,inner sep=0pt,anchor=south east]
        {} (B) edge (Y) (B) edge (Y') edge[pro] (C) (C) edge (Z) (X) edge[pro] (Y) (Y) edge[pro] node[pos=.5,inner sep=0pt,anchor=south east]
        {} (Y') edge[pro] (Z) (Y') edge[pro] (Z) } 
    \end{minipage}
    \hfil
    \begin{minipage}[t]{0.25\linewidth}
      \centering
      \Diag (1.5,1.5) {\twocellbr{B}{A}{X}{\alpha_1} \twocellbr{C}{B}{Y}{\alpha_2} }{|(A)| A \& |(X)| X \\
        |(B)| B \& |(Y)| Y \\
        |(C)| C \& |(Z)| Z }{(A) edge (X) edge[pro] (B) (B) edge[pro] (C) edge (Y) (X) edge[pro] (Y) (Y) edge[pro] (Z) (C) edge (Z) }
    \end{minipage}
    \hfil
    \begin{minipage}[t]{0.35\linewidth}
      \centering \Diag (.5,.25) {\twocell[.2][.2]{B}{A}{X}{}{celllr={0.0}{0.0},bend
          right=20,labelbr={\alpha_1}} \twocell[.4][.2]{B'}{B}{X'}{}{celllr={0.0}{0.0},bend
          right=20,labelr={\alpha_2}} \twocell[.4][.2]{C}{B'}{Y}{}{celllr={0.0}{0.0},bend
          right=30,labelbr={\alpha_3}} \twocell[.2][.4]{C}{B}{B'}{}{celllr={0.0}{0.0},bend
          right=10,labeld={\alpha_4}} \twocell[.4][.2]{X'}{X}{Y}{}{celllr={0.0}{0.0},bend
          right=10,labeld={\alpha_5}} }{|(A)| A \& \&\&\&\&\&\& \& |(X)| X \\
        \&  \&\&\&\&\&\& |(X')| X' \&  \\
        |(B)| B \& \&\&\&\&\&\& \& |(Y)| Y \\
        \& |(B')| B' \&\&\&\&\&\&  \&  \\
        |(C)| C \& \&\&\&\&\&\& \& |(Z)| Z }{(A) edge[pro] (B) edge (X) (B) edge (X') edge[pro] node[pos=.7,inner sep=0pt,anchor=south west]
        {} (B') edge[pro] (C) (B') edge (Y) edge[pro] (C) (C) edge (Z) (X) edge[pro] (X') edge[pro] (Y) (X') edge[pro,labelbl={u_2}] (Y) (Y) edge[pro] (Z) }
    \end{minipage}
  \end{center}
  with , , and  and
   iso in .
\end{prop}
A possible reading of this is that in the left and middle cases, the
whole of  embeds into . In the left case, a non-trivial part of
 embeds into .  In the right case, a
non-trivial part of  embeds into .
\begin{proof}
  Choose decompositions of  and  as  and , respectively, and
  of  as . Apply Lemma~\ref{lem:big}
  to obtain . If , we are in the
  right-hand case.  If , we are in the middle case. If , let  and .  Lemma~\ref{lem:big} provides
   and 
  such that .
  Applying~\axref{leftdecomposition} to  gives a decomposition
  of  as on the left below
  \begin{center}
    \Diag (.5,.25) {\twocell[.4][.2]{A'}{A}{X}{}{celllr={0.0}{0.0},bend
          right=10,labelbr={\beta_1}} \twocell[.4][.2]{B}{A'}{Y}{}{celllr={0.0}{0.0},bend
          right=20,labelbr={\beta_2}} \twocell[.2][.2]{C}{B}{Y'}{}{celllr={0.0}{0.0},bend
          right=20,labelbr={\gamma}} \twocell[.2][.4]{B}{A}{A'}{}{celllr={0.0}{0.0},bend
          right=10,labeld={\alpha_4}} \twocell[.4][.2]{Y'}{Y}{Z}{}{celllr={0.0}{0.0},bend
          right=10,labeld={\alpha_5}} }{|(A)| A \& \&\&\&\&\&\& \& |(X)| X \\
        \& |(A')| A' \&\&\&\&\&\& \&  \\
        |(B)| B \& \&\&\&\&\&\& \& |(Y)| Y \\
        \& \&\&\&\&\&\& |(Y')| T \&  \\
        |(C)| C \& \&\&\&\&\&\& \& |(Z)| Z }{(A) edge[pro] (B) edge[pro] (A') edge (X) (A') edge[pro] node[pos=.5,inner sep=0pt,anchor=south east]
        {} (B) edge (Y) (B) edge (Y') edge[pro] (C) (C) edge (Z) (X) edge[pro] (Y) (Y) edge[pro] node[pos=.5,inner sep=0pt,anchor=south east]
        {} (Y') edge[pro] (Z) (Y') edge[pro,labell={u'_2}] (Z) }
\hfil
  \Diag{\twocell[.3][.4]{Bhaut}{A}{A'haut}{}{celllr={0.0}{0.0},bend
          right=10,labelbr={\alpha_4},shorten <=-10} }{|(A)| A \\
   \& |(A'haut)| A' \\
   |(Bhaut)| B \& \& |(A')| A' \\
   |(B)| B  }{(A) edge[pro] (A'haut) edge[pro,bend left=40] (A') edge[pro,bend right=30] (Bhaut) (A'haut) edge[pro,identity] (A') edge[pro,labelal={w_2}] (Bhaut) (Bhaut) edge (A') edge[pro,identity] (B) (A') edge[pro,labelbr={w_2}] (B) }
\end{center}
with  and  isos. If , then we
are in the left-hand case of the proposition, and the middle case is
impossible by essential uniqueness
in~\axref{leftdecomposition}. Otherwise, we may decompose 
as on the right by atomicity (empty cells are given by coherence or
\axref{atomicity}), so we are in the middle case of the proposition.
\end{proof}



Lastly, we need a few more definitions before
Proposition~\ref{prop:decompV}.
\begin{defi}
  Let  be the full subcategory of  consisting of views.
\end{defi}

Consider, for any , the comma category  induced by the
vertical codomain functor 
mapping~\eqref{eq:alpha} to  (following notation from
Section~\ref{subsec:prelim:cats}).  Similarly, consider .
Concretely, an object of  is a pair of a view , and a player  of .  A morphism
 is a morphism  in , such that .  

Recall now from above Definition~\ref{def:beh} the pullback category
. It is isomorphic to the full subcategory of 
consisting of pairs  where .  Similarly, we have
, which is empty unless  is an individual.
   \begin{prop}\label{prop:decompV} We have
     \begin{enumerate}[label=(\roman*)]
     \item The inclusion  mapping  to 
        is an isomorphism of categories. \label{prop:decompV:i}
     \item The inclusion  mapping  to  is an isomorphism of
       categories.
       \label{prop:decompV:ii}
     \item  is a preorder.\label{prop:decompV:iii}
     \end{enumerate}
\end{prop}
   \begin{proof}
     First, because  is discrete, ,
     hence~\ref{prop:decompV:i}. For~\ref{prop:decompV:ii}, the
     functor  mapping any
      to , with  a view and
      a player, is inverse to the given functor.
     Finally, consider any two morphisms  in ,
     say
\begin{center}
  \diag{|(d'_1)| X_1 \& |(d_2)| d_2 \\
    |(d_1)| d_1 \& \\
    |(d)| d \& |(d')| d }{(d'_1) edge[labelu={h_1}] (d_2) edge[pro,labell={w_1}] (d_1) (d_1) edge[pro,labell={v_1}] (d) (d_2)  edge[pro,twor={v_2}] (d') (d) edge[identity] (d') (d_1) edge[cell=.3,labelu={\alpha_1}] (r) }
\hfil and \hfil
   \diag{|(d'_1)| X_2 \& |(d_2)| d_2 \\
    |(d_1)| d_1 \& \\
    |(d)| d \& |(d')| d. }{(d'_1) edge[labelu={h_2}] (d_2) edge[pro,labell={w_2}] (d_1) (d_1) edge[pro,labell={v_1}] (d) (d_2)  edge[pro,twor={v_2}] (d') (d) edge[identity] (d') (d_1) edge[cell=.3,labelu={\alpha_2}] (r) }
\end{center}
Fixing decompositions of  and  into basic moves, we obtain
by Lemmas~\ref{lem:big} and~\ref{lem:preorder} that  and
 respectively decompose as
\begin{center}
  \diag{|(d'_1)| X_1 \& |(d_2)| d_2 \\
    |(d_1)| d_1 \& |(d'')| d' \\
    |(d)| d \& |(d')| d }{(d'_1) edge[labelu={h_1}] (d_2) edge[pro,twoleft={w1}{w_1}] (d_1) (d_1) edge[pro,twoleft={v1}{v_1}] (d) edge (d'') (d_2)  edge[pro,twor={v^1_2}] (d'') (d'')  edge[pro,tworight={r'}{v^2_2}] (d') (d) edge[identity] (d') (w1) edge[cell=.3,labelu={\alpha^1_1}] (r) (v1) edge[cell=.3,labelu={\alpha^2_1}] (r') }
\hfil and \hfil
  \diag{|(d'_1)| X_2 \& |(d_2)| d_2 \\
    |(d_1)| d_1 \& |(d'')| d' \\
    |(d)| d \& |(d')| d. }{(d'_1) edge[labelu={h_2}] (d_2) edge[pro,twoleft={w1}{w_2}] (d_1) (d_1) edge[pro,twoleft={v1}{v_1}] (d) edge (d'') (d_2)  edge[pro,twor={v^1_2}] (d'') (d'')  edge[pro,tworight={r'}{v^2_2}] (d') (d) edge[identity] (d') (w1) edge[cell=.3,labelu={\alpha^1_2}] (r) (v1) edge[cell=.3,labelu={\alpha^2_2}] (r') }
\end{center}
By Corollary~\ref{cor:Vpreordergroupoid}, . Furthermore, we conclude by~\axref{fibration} and the
quotienting~\eqref{eq:quotient:E} in the definition of  that both
morphisms are equal in  to .
\end{proof}


\subsection{From behaviours to strategies}
   \begin{defi}
     The category  of \emph{strategies} on  is the category
      of presheaves of finite ordinals on .
   \end{defi}
   \begin{exa}
     On ,  as defined here yields a category equivalent
     to the definition in \citetalias{2011arXiv1109.4356H}, so the
     categories of strategies are also equivalent (even isomorphic
     because  contains no non-trivial automorphism).
   \end{exa}
   The rest of this section develops some structure on strategies,
   which is needed for constructing the \lts{} in
   Section~\ref{subsec:lts:strats}. We start by extending the
   assignment  to a pseudo double functor , where  is Ehresmann's double category of
   \emph{quintets} on the 2-category :
   \begin{defi}
      has small categories as objects, functors as both
     horizontal and vertical morphisms, and natural transformations as
     double cells.
   \end{defi}

   Actually, our first step is to extend the assignment 
   to pseudo double functor .  Define the action
   of a horizontal map  to map any object 
   of  to , and any morphism to itself viewed
   as a morphism in . (This functor is induced by universal
   property of  as a comma category.) This defines a functor
   .  The pseudo functor 
   is a bit harder to construct. For any  in
    and , the cell  from
   Proposition~\ref{prop:views} induces a functor  mapping any  to .  Composing with the coproduct injection
   , because , we obtain functors  whose copairing defines a functor .


   Now, for any cell as on the left below,
   we obtain by Proposition~\ref{prop:views} a canonical natural isomorphism as on the right
     \begin{mathpar}
       \begin{minipage}[t]{0.3\linewidth}
         \doublecellpro{Y}{Y'}{X}{X'}{k}{u}{u'}{h}{\alpha}
       \end{minipage} \and
       \begin{minipage}[t]{0.3\linewidth}
         \doublecell{\EVi_Y}{\EVi_{Y'}}{\EVi_X}{\EVi_{X'}.}{\EVi_k}{\EVi_{u}}{\EVi_{u'}}{\EVi_h}{\iso}
       \end{minipage}
     \end{mathpar}
     By canonicity of the above double cell, we have
   \begin{prop}\label{prop:pseudodoublefunctor}
     This assignment defines a pseudo double functor .
   \end{prop}

   \begin{defi}
     Let the \emph{opposite}  of a pseudo double category
      be obtained by reversing both vertical and horizontal
     arrows, and hence double cells.
   \end{defi}


   We obtain:
   \begin{defi}\label{def:SSfunctor}
     Let  be the composite
     
   \end{defi}
   As a shorthand, we denote  by  for 
   horizontal or vertical.  Concretely, for any horizontal ,  satisfies  whereas for any vertical ,  satisfies
   




We conclude this section by constructing the \emph{extension}
functor from strategies to behaviours, in arbitrary playgrounds.

Recall that strategies on a position  are presheaves of finite
ordinals on , and that behaviours are presheaves of finite
sets on .  To go from the former to the latter, we use 
as a bridge.  Recall from Section~\ref{subsec:prelim:cats} that
objects of  are diagrams of the shape , with  a view, and that objects of  are just plays . The idea here is that on the one hand  is richer
than , in that its objects may be plays on \emph{subpositions}
of , whereas objects of  are plays on the whole of .  But
on the other hand,  is richer than  because its objects
may be arbitrary plays, whereas objects of  have to be
views.  contains both  and , its objects
being diagrams , for arbitrary plays .

First, let  denote
postcomposition with .  Because views form a full
subcategory of , all embeddings 
are also full.  This entails:
\begin{lem}\label{lem:kanff}
  For all , right Kan extension  along  is well-defined, full, and faithful.
\end{lem}

\begin{proof}
  One easily shows that, when defined, right extension along a full
  and faithful functor is full and faithful. 

  It remains to show that the considered right extensions exist.  It
  is well-known~\citep{MacLane:cwm} that the right Kan extension of
  any  maps any  to the limit of the
  functor , if
  the latter exists.  Since finite limits exist in  (though not
  in , which explains why we use  instead of  for
  extending strategies), it is enough to prove that each  is essentially finite, i.e., equivalent to a finite
  category. This is proved in the next lemma.
\end{proof}

\begin{lem}\label{lem:kanexists}
  For any play  and horizontal , the category  is
  essentially finite.
\end{lem}

For this lemma to hold, we need more axioms.
\begin{ax}
  \begin{axioms}
  \item (Finiteness) For any position , there are only finitely
    many players, i.e., the category  is finite. \label{finiteness}
\end{axioms}
\end{ax}


\proof[Proof of Lemma~\ref{lem:kanexists}] Let us fix a pair . By
Proposition~\ref{prop:decompV},  is a preorder, so we just
need to prove that its object set is essentially finite.  Now, letting
, we fix a decomposition of  into moves, say . For any morphism  in
, by Lemma~\ref{lem:big},  may not exceed .  Furthermore, by
Lemma~\ref{lem:big}, Proposition~\ref{prop:views}, and our
quotienting~\eqref{eq:quotient:E}, any such  is determined up
to isomorphism by , a strictly monotone map , and
a player  of . Because such triples  are in finite number,
 is essentially finite. \qed







  This concludes the proof of Lemma~\ref{lem:kanff}: right
  Kan extension along 
  yields a full and faithful functor. We now design the second half of
  our bridge from  to  via . Consider the
  embedding  mapping any  to . Restriction along  defines a functor
  .

Recall from Definition~\ref{def:beh} the notion of behaviour.
\begin{defi}
  For any , let the \emph{extension} functor  be the composite 
  
  We call a behaviour on  \emph{innocent} when it is in the
  essential image of .
\end{defi}
Notation: when  is clear from context, we abbreviate  as .

\begin{rem}
  The calculations of Section~\ref{subsubsec:strategies} carry over
  unchanged to the new setting.
\end{rem}
Finally, the definitions of Section~\ref{subsec:fair} apply more or
less verbatim to the playground , yielding a semantic fair
testing equivalence which coincides with that of \citetalias{2011arXiv1109.4356H}.

\section{Playgrounds: transition systems}\label{sec:strats}
In the previous section, we have defined behaviours and strategies,
and constructed the extension functor from the former to the latter.
In this section, we first build on this to state decomposition
theorems, which lead to a syntax and \anlts{} for strategies. Then, we
define our second \lts{}, and relate the two by a strong, functional
bisimulation.

\subsection{A syntax for strategies}\label{subsec:syntax:strats}
Let us begin by proving in the abstract setting of playgrounds
analogues of the decomposition results of
\citetalias{2011arXiv1109.4356H}, in particular that strategies form a
terminal coalgebra for a certain polynomial functor. This is
equivalent to saying that they are essentially infinite terms in a
typed grammar. We use this in the next section to define our \lts{}
, and study transitions therein.

First, we have \emph{spatial} decomposition:
   \begin{prop}\label{prop:spatial} 
     The functor  given at
      by  is an isomorphism of
     categories.
   \end{prop}
   \proof
     We have:
     \begin{center}
       \qed
     \end{center}
For any , let  denote the strategy on 
     corresponding to  accross the isomorphism.

     The second decomposition result is less straightforward, but goes
     through essentially as in the concrete case. Let us be a bit more
     formal here than in Section~\ref{subsubsec:syntax}, by showing
     that strategies form a terminal coalgebra for some endofunctor on
     .  We start by defining the relevant endofunctor.
     

\begin{defi}
       Let  denotes the set of all isomorphism classes of
       basic moves from  (i.e., with vertical codomain ).
     \end{defi}
     \begin{defi}
       Let  be the functor
       mapping any family  to  where 
       denotes finite sequences.
     \end{defi}

     \begin{rem}\label{rem:lists}
       This functor is polynomial in the sense of
       Kock~\citep{Kock01012011}, as 
     \end{rem}
     
     We now show that strategies, viewed as the -indexed family
     , form a terminal -coalgebra. We drop 
     the  for readability.
     
     \begin{defi}\label{defi:restr}
       For any  and , let the
       \emph{restriction}  of  to
        be defined by the fact that .
     \end{defi}
     (Here, we freely use the isomorphism  from
     Proposition~\ref{prop:decompV}, and let  denote the unique
     morphism  in .)

     In view of Remark~\ref{rem:lists}, .  We thus may define the -coalgebra structure
      in  of
     strategies as follows.
     \begin{defi}
       Let, for all ,  send any  to  and the map
       
     \end{defi}
     Here, we view the ordinal  as a natural number, and
     the given map  as a list of elements of .  We further use the action of  on , as below
     Definition~\ref{def:SSfunctor}.
We have:
\begin{thm}\label{thm:stratcoalg}
  The map  makes  into a terminal
  -coalgebra.
\end{thm}
This intuitively means that strategies, on individuals, are
infinite terms for the following typed grammar with
judgements  and , where  is a
\emph{definite strategy} and  is a \emph{strategy}
\begin{mathpar}
\inferrule{\ldots \ d' \vdash S_b \ \ldots \ {(\forall b \colon d' \proto d \in \MMMB_d)}
}{
d \vdashdefinite \langle (S_b)_{b \in \MMMB_d} \rangle
}
\and
\inferrule{\ldots \  d \vdashdefinite D_i \  \ldots \ (\forall i \in n)}{
d \vdash \bigoplus_{i \in n} D_i}~(n \in \Nat). 
\end{mathpar}
Semantically, definite strategies correspond to strategies  such
that , which will play a crucial role in the \lts{}
below.

The rest of this section is a proof of Theorem~\ref{thm:stratcoalg}. 

First of all, we construct an inverse to .  
\begin{defi}
  Consider . For any view , define  by

and on morphisms 
where in the last clause necessarily  and
Lemma~\ref{lem:big} yields  and 
such that .
\end{defi}
\begin{lem}
  We have .
\end{lem}
\begin{proof}
  Starting from a strategy , let , and
  , for any .
We have , and thus
   if , and  if , as desired.

  Conversely, starting from , let .  We have that  has
  length , and its th component maps any 
  to the strategy mapping any  to the
  strategy . Thus, .  But
  by definition, this is equal to , as desired.  
\end{proof}

Consider any -coalgebra .

We define by induction on  a sequence of maps , such that for any  and  the 's agree
on views of length . I.e., for any , ,
view  of length less than , and any , , and similarly the action of  on morphisms
between such views is the same as that of .

To start the induction, take  to be the strategy mapping
 to , i.e., the length of , and all other views to .

Furthermore, given , define  to be


In other words,  is 


Unfolding the definitions yields:
\begin{lem}\label{lem:unfold}
  Consider any , and let .  For
 any , we have
  \begin{itemize}
  \item  , and
  \item  for any composable basic move  and view .
  \end{itemize}
\end{lem}

\begin{cor}\label{cor:unfold}
  We have, for any , .  
  Furthermore, for any basic move , and view , we have for any :
  
\end{cor}

As announced, we have:
\begin{lem}\label{lem:station}
  For any view  and ,
  .
\end{lem}
\proof
  We proceed by well-founded induction on , for the
  lexical ordering. 
  Let again .
  First, we have , and for any ,
   by Corollary~\ref{cor:unfold}.
  Now, if , then by Corollary~\ref{cor:unfold} again:
  \begin{center}
    \length{v} = \length{v'}+1 \qed
  \end{center}

  The sequence  thus has a colimit in :
  the presheaf mapping any view  to . This
  allows us to define:
\begin{defi}
  Let  map any  to the colimit of
  the 's.
\end{defi}

\begin{lem}
  The following diagram commutes:
  \begin{center}
    \diag{|(U)| U \& |(FU)| G U \\
      |(CVhatf)| \SS \& |(FCVhatf)| G  (\SS). }{(U) edge[labelu={a}] (FU) edge[labell={f}] (CVhatf) (FU) edge[labelr={G (f)}] (FCVhatf) (FCVhatf) edge[labelu={\inv\deriv}] (CVhatf) }
  \end{center}
\end{lem}
\proof Consider any  and view , and let .  Let also  and
.
  \begin{itemize}
  \item If , then by Lemma~\ref{lem:unfold} .
  \item If , then by Lemma~\ref{lem:unfold} again we
    have . But by definition of
    , we obtain , which is in turn equal to  by
    Corollary~\ref{cor:unfold}. \qed
  \end{itemize}

\begin{cor}
  The map  is a map  of -coalgebras.
\end{cor}


\begin{lem}
  The map  is the unique map  of -coalgebras.
\end{lem}
\begin{proof}
  Consider any such map  of coalgebras, and let . The map  must be such that 
   by
  Lemma~\ref{lem:unfold}.
  Furthermore, by the same lemma, it must satisfy:
   which imposes by induction that .
\end{proof}

The last two results directly entail Theorem~\ref{thm:stratcoalg}.


\subsection{The labelled transition system for strategies}\label{subsec:lts:strats}
In this section, we go beyond \citetalias{2011arXiv1109.4356H}, and
define \anlts{} for strategies, for an arbitrary playground . 

First, the alphabet for our \lts{} will constist of quasi-moves, in the following sense.
\begin{notation}\label{not:cartesian}
  We use the following notation for cartesian lifting
  (by~\axref{fibration}) of a play  along a horizontal morphism
   (fixing a global choice of liftings):
  \begin{center}
    \doublecellpro{D_{k,u}}{X'}{Y}{X.}{h_{k,u}}{\restr{u}{k}}{u}{k}{\alpha_{k,u}}
  \end{center}
\end{notation}
\begin{defi}\label{def:quasi-move}
  A \emph{quasi-move} is a vertical morphism which locally either is a
  move or has length 0.  More precisely, a play  is
  a quasi-move iff for all players , 
  either is a move or has length 0.

  A quasi-move is \emph{full} when it locally either is a full move
  or has length 0. Let  denote the subgraph of  consisting
  of full quasi-moves.
\end{defi}
Observe that a quasi-move on an individual either is a move or has
length 0.

States in our \lts{} will be the following special kind of strategies:
\begin{defi}
  A strategy  is \emph{definite} when , or equivalently when for all players ,
  we have .
\end{defi}

Intuitively, for any quasi-move , we would like
transitions  in our \lts{} to occur when 
is a definite restriction of  to some state of
.  I.e., a transition roughly corresponds to a way for
 to accept .  However,  is not quite
 so the right notion of restriction may not be
obvious. But we have defined a notion of restriction in
Definition~\ref{defi:restr}, for strategies on individuals.  We now
define restriction for general strategies, and use this to define our
\lts{}. Finally, we elucidate the connection with .

Consider, for any  and , and recall from below
Definition~\ref{def:SSfunctor} that  is shorthand for the
image of  under the action of a horizontal morphism  for the horizontal part of our pseudo double functor
.

\begin{defi}
  Let the \emph{restriction}  of  to
   be defined by the fact that for any player , 
\end{defi}
Concretely, we have, for any , , where
 is the unique morphism  in .

We now define our \lts{} for strategies over .
\begin{defi}
  The underlying graph  for our \lts{} is the graph with as
  vertices all pairs  where  is a position and 
  is a definite strategy, and whose edges  are all
  full quasi-moves  such that there exists a
  state  with 

The assignment  defines a morphism  of reflexive graphs, which is our \lts{}.
\end{defi}
An alternative characterisation of transitions  is the existence of  such that

for all .

Let us now return to the connection between 
and .
First, we have
by definition ,
for any player .  
Now, as recalled above,  may be characterised as a
limit of
   
  Since  is an object in
  , we obtain by projection a map .

\begin{defi}
  For any , let  denote the
  corresponding tupling map.
\end{defi}

\begin{prop}\label{prop:SM:SdotM}
  For any definite , the map  is a bijection.
\end{prop}
We prove this through the following lemma.
For any full quasi-move , observe that for any
player ,  has length at most 
(consider ), and let 
\begin{lem}\label{lem:psibij}
  For any definite , and full quasi-move ,
  the map
   where the
  second map is by projection, is bijective.
\end{lem}
\begin{proof}
  Recall that  is a limit of
   
  and consider the poset  with underlying set  and ordering given by  iff .
  Consider the functor  mapping any  to the unique morphism  with lower border
  , and any  to . Since 
  is a poset,  is faithful.  It is furthermore full by
  Proposition~\ref{prop:decompV}.  Finally,
  for any  in ,
  \begin{itemize}
  \item either  and there is a unique player  such that  is the (unique) morphism 
    with lower border ,
  \item or  and there exists a unique player  such that  (let ; , so by
    Proposition~\ref{prop:views:decomp} ).
  \end{itemize}
  This entails that  is essentially surjective on objects, hence an equivalence.
  Thus,  is also a limit of 

   

  But now, because  is definite, this functor maps any  to a singleton, hence  is also a limit of
 
i.e., isomorphic to ,
as desired.
\end{proof}

\begin{proof}[Proof of Proposition~\ref{prop:SM:SdotM}]
  If , then  is a
  singleton. Thus, the second map of Lemma~\ref{lem:psibij} is bijective, hence so is .
\end{proof}

The moral of Proposition~\ref{prop:SM:SdotM} is that transitions
 in  are precisely given by full
quasi-moves  such that there exists a state
 with

for all .

We now give more syntactic characterisations of transitions, starting 
with transitions from states of the shape .
Recall the syntax for strategies below Theorem~\ref{thm:stratcoalg}.
\begin{prop}
  If  is a definite strategy on , and if for all ,  for definite , then for any  we have  iff
  \begin{itemize}
  \item for all , there exists  such that ,
  \item and for
    all , .
  \end{itemize}
\end{prop}
Let us now characterise transitions from arbitrary positions in terms
of their restrictions to individuals.  Recalling
Notation~\ref{not:cartesian}, we have:
\begin{prop}\label{prop:localtrans}
  We have  iff for all , 
  
\end{prop}

Putting both previous results together, we obtain:
\begin{cor}
  Let, for all ,   and for all ,  for definite .

  Then, for any , we have  iff
  \begin{itemize}
  \item for all , there exists  such that ,
  \item and for
    all , .
  \end{itemize}
\end{cor}

\subsection{Process terms}\label{sec:syn}
In the previous section, starting from a playground , we have
constructed \anlts{}  of strategies. We now begin the
construction of the \lts{}  of \emph{process terms} announced
in Section~\ref{subsec:overview}, starting with process terms themselves.

\begin{defi}\label{defn:MMM}
  For any , let  be the set of isomorphism classes of full
  moves with codomain , in , and let  denote the map
  

  Let  denote the subset of  consisting of
  (isomorphism classes of) full moves  such that
   is a singleton (and hence so is ).  Let
   denote the complement subset.
\end{defi}
The map  is easily checked to be well-defined.

We state one more axiom to demand that basic sub-moves of a full move
 may not be sub-moves of other full moves.
\begin{ax}
  \begin{axioms}
  \item (Basic vs.\ full) For any  and , if , then .
    \label{basic:full}
  \end{axioms}
\end{ax}


  Let \emph{process terms} be infinite terms in the typed grammar:
    \begin{mathpar}
        \inferrule{\ldots \ d_i \vdash T_i \ \ldots \ (\forall i \in n) }{d \vdash \sum_{i \in n} M_i.T_i }~(n \in \Nat; \forall i \in n, M_i \in \MMMFB_d  \mbox{\ and\ } \BsofF[M_i] =
    \ens{b_i \colon d_i \proto d})
\and
  \inferrule{ \ldots \ d' \vdash T_b \ \ldots \ {(\forall
      (b \colon d' \proto d) \in \BsofF [M])} }{ d \vdash M \with{(T_b)_{b
        \in \BsofF [M]}} }~{(M \in \MMMFplus_d).}
    \end{mathpar}

    The first rule is a guarded sum, in a sense analogous to guarded
    sum in CCS. It should be noted that guards have to be full moves
    with only one non-trivial view. There is good reason for that,
    since allowing general moves as guards would break bisimilarity
    between process terms and strategies. To understand this, consider
    a hypothetical guarded sum . Since this has no
    interaction before the choice is made,  behaves, in CCS, just
    like an internal choice . However, our
    translation to strategies does not translate guarded sum as an
    internal choice, with right, since other guarded sums, e.g.,  should certainly not be translated this way. Instead, 
    would be translated as something equivalent to , which is clearly not
    bisimilar to  in general.


    We could easily include internal choice in the grammar, since
    strategies do model it, directly. We refrain from doing so for
    simplicity.


\begin{defi}
  Let  be the set of process terms.
\end{defi}


\begin{exa}\label{ex:ccs:terms}
  For , the obtained syntax is equivalent to
  \begin{mathpar}
    \inferrule{\ldots \ \Gam \cdot \alpha_i \vdash P_i \ldots}{
      \Gam \vdash \sum_i \alpha_i.P_i
    }
    \and
    \inferrule{
      \Gam \vdash P \\       \Gam \vdash Q
    }{
      \Gam \vdash P|Q
    }~\cdot
  \end{mathpar}where
  \begin{itemize}
  \item  ranges over natural numbers;
  \item  (for );
  \item  denotes  if  and
    just  otherwise.
  \end{itemize}
  This grammar obviously contains CCS, and we let  be the injection.
\end{exa}


\subsection{The labelled transition system for process terms}
We now define the \lts{} . States, i.e., vertices of
the graph underlying this \lts{}, are pairs  of a position 
and a family  of process terms, indexed by the players of ,
i.e., , where 
is the set of process terms of type .


To define edges, we need a lemma. For any play 
and , recalling Notation~\ref{not:cartesian},
consider the map 
 sending any  and  to


Consider also the map  in the other direction sending any  to the pair , where  is the (domain in  of
the) unique  making the diagram
\begin{center}
      \diagramme[diag={.4}{1.5}]{baseline=(d'.base)}{}{|(d')| d' \\
      \& |(D)| D_{y^u,u} \& \& |(X')| X' \\
      {} \& \\
      |(dyu)| d^{y,u} \\
      \& |(dyui)| d^{y,u} \& \& |(X)| X }{(X') edge[pro,twor={u}] (X) (d') edge[bend left=10,labelar={y}] (X') edge[pro,twol={v^{y,u}}] (dyu) edge[dashed,labelbl={\restr{y}{y^u}}] (D) (l) edge[bend left=10,cell=1] node[pos=.6,anchor=north] {} (r) (dyu) edge[identity] (dyui) edge[bend left=10] node[pos=.6,anchor=north] {} (X) (dyui) edge[labeld={y^u}] (X) (D) edge[pro,fore,twoleft={uy}{},tworight={uy'}{}] 
      node[pos=.4,anchor=west] {} (dyui) edge[labeld={h_{y^u,u}}] (X') (uy) edge[cell=.5,labeld={\scriptstyle \alpha_{y^u,u}}] (r) (l) edge[cell=.3,labelbl={\scriptstyle \alpha'},dashed] (uy') }
\end{center}
commute (by~\preaxref{fibration}).  This map  is well-defined by
uniqueness of  and cartesianness of .
\begin{lem}\label{lem:ru}
The maps  are  are mutually inverse.
\end{lem}
\begin{proof}
  Straightforward.
\end{proof}





Let us return to the definition of our \lts{}. 
We first say that for any full quasi-move , a
process term  has an -transition to , for , when
one of the following holds:
\begin{enumeratei}
\item \label{pt:trans:i}  , , and, for all ,
  \begin{itemize}
  \item if  is a basic move, then  and ;
  \item otherwise  (hence ), and ;
  \end{itemize}
\item , ,  for some , and for all players 
  \begin{itemize}
  \item if , then 
    ,
  \item and otherwise (),  ;
  \end{itemize}

\item  
  and for all ,  (which, again,
  makes sense by Lemma~\ref{lem:hv}).
\end{enumeratei}
We denote such a transition by .
\begin{rem}
  The first case \ref{pt:trans:i} allows , but
  if , then 
  by~\axref{basic:full}. Also, let us mention that  does not imply  in general, although it
  does in .
\end{rem}

\begin{defi}
Let  be the graph with pairs  as vertices, and as
edges  full quasi-moves  such
that for all , . Here, we let  denote
composition with , viewed as a map .

   is viewed as \anlts{} over , by mapping  to .
\end{defi}

\begin{exa}\label{ex:ltsccs}
  For , the obtained \lts{} differs subtly, but significantly
  from the usual \lts{} for CCS. In order to explain this clearly, let
  us introduce some notation. First, let \emph{evaluation contexts} be
  generated by the grammar
  \begin{mathpar}
    \inferrule{ }{\Gam ; x \colon n \vdash x (a_1, \ldots, a_n)}
    \and
    \inferrule{\Gam ; \Del_1 \vdash \ec_1 \\ 
      \Gam ; \Del_2 \vdash \ec_2 }{\Gam ; \Del_1, \Del_2 \vdash \ec_1 | \ec_2 },
  \end{mathpar}
  where, in the first rule, , and in the
  second .  Here, 
  ranges over a fixed set of \emph{variables}, and 
  range over finite maps from variables to natural numbers. Evaluation
  contexts are considered equivalent up to associativity and
  commutativity of .  Positions are essentially a combinatorial,
  direct representation of such contexts.

  Leaving the details aside, states in  may be viewed as
  pairs  of an evaluation context , plus, for each -ary
  variable  in , a process term over  in
  the grammar of Example~\ref{ex:ccs:terms}.  Instead of separately
  writing the evaluation context and the map from its variables to
  process terms, we inline process terms between brackets in the
  context, thus avoiding variables. Moves are either put in context
  similarly, or located implicitly. E.g., for a state  where
   contains two players respectively mapped by  to process terms
   and , we would write . There is some ambiguity in
  this notation, e.g., in case some channels are absent from : are
  they absent from the arity of , or only unused? Since we use this
  notation mostly for clarifying examples, we will avoid such
  ambiguities.  Finally, we sometimes use brackets to denote the fact
  that some holes are filled with the given state. E.g., 
  denotes a state , where a hole has been replaced by a parallel
  composition of two holes, respectively filled with  and .

  Returning to our comparison of  and , of course,
  a first difference is the fact that labels may contain several
  moves, as quasi-moves only locally have length 1.

  A second difference is the presence of \emph{heating} rules for
  parallel composition and channel creation, in a sense close to the
  chemical abstract machine \citep{DBLP:conf/popl/BerryB90}.  For
  example, we have transitions .

  There is a third important difference, related to channel
  creation. For instance, we have transitions
  
  The second transition cannot occur in a closed-world setting, since
  the environment cannot know .  And it does not occur in 
  either.

  A final difference is that labels contain too much information to be
  relevant for behavioural equivalences. E.g., they contain the whole
  evaluation context in which the transition takes place, as well as
  which players are involved.

  The second difference, i.e., the presence of heating rules, is not
  really problematic, and merely forces us to use weak bisimulations
  rather than strong ones.  All other defects will be corrected below.
\end{exa}

\subsection{Translation and a first correctness result}
We conclude this section on the general theory of playgrounds by
establishing a strong, functional bisimulation from process terms to
strategies.

Mimicking \eqref{eq:traduc} (page~\pageref{eq:traduc}), our
translation from process terms to definite strategies (\emph{qua}
families over ) is defined coinductively by


Let us extend the map  to a map
, defined by
, using
Proposition~\ref{prop:spatial}.


\begin{thm}\label{thm:bisim}
  The map  is a
  functional, strong bisimulation.
\end{thm}
\begin{proof}
  The theorem follows from Proposition~\ref{prop:localtrans} and the next lemma.
\end{proof}

\begin{lem}
  For any full quasi-move , for any  and , we have
  \begin{center}
     \hfil iff \hfil
    .
  \end{center}
\end{lem}
Note the implicit typing: . Also
the second condition on the right is equivalent to .

\begin{proof}
  If , then both sides are equivalent to the fact that
  for all , .

  Otherwise, we proceed by case analysis on . 

  If , then by \axref{basic:full} both sides are
  equivalent to , plus
  \begin{itemize}
  \item for all , , and
  \item for all , .
  \end{itemize}
  Indeed, for any ,  is definite.  We thus put  in the first case and  in the second
  case.

  If , then both sides are equivalent to 
  the existence of  such that 
   and
  \begin{itemize}
  \item for the unique , , and
  \item for all , .
  \end{itemize}
  This uses~\axref{basic:full}, since the left-hand side unfolds to
  the existence of  such that  and , i.e.,  for some , by definition of
  . This entails in particular 
  by~\axref{basic:full}.
\end{proof}



\section{Graphs and fair morphisms}\label{sec:graphs}
In this section, we derive our main result.  For this, we develop a
notion of \emph{graph with complementarity}, which aims at being a
theory of \ltss{} over which fair testing makes sense.  Although the
theory would apply with any predicate  compatible with
 equivalence classes (see below), the question of
whether such a generalisation would have useful applications is
deferred for now.

For any graph with complementarity  and relation  over , we exhibit sufficient conditions for  to be
\emph{fair}, i.e., to preserve and reflect fair testing
equivalence. We then relate this theory to our semantics, and show
that it entails our main result.  For now, this section lies outside
the scope of playground theory. Some aspects of it could be formalised
there, but we leave the complete formalisation for further
work. Because the only playground involved is , we often omit
sub or superscripts, e.g., in ,  (even just ),
etc.



Before we start, let us define  to be the set of
\emph{closed-world quasi-moves}, i.e., vertical morphisms in 
which either are closed-world moves
(Definition~\ref{def:cw:successful}) or have length 0.  
Please note: quasi-moves must locally restrict to plays of length , whereas
closed-world quasi-moves have length  globally.
Let  be
the subbicategory of  generated by , and let  be the
free reflexive graph on an endo-edge .  Finally, let
 be the pseudo functor
determined by the mapping  sending all closed-world
quasi-moves to  except  moves, which are sent to .

\subsection{Graphs with complementarity}
A \emph{relation}  between two reflexive graphs  and
 is a subgraph . Such a relation  is
\emph{total} when, for all vertices, resp.\ edges, , there
exists a vertex, resp.\ an edge , such that . It
is \emph{partially functional} if there is at most one such .  It is
\emph{functional} when it is total and partially functional.  The
\emph{domain} of  is the subgraph of  consisting of vertices and
edges related to something in .
\begin{defi}
  A \emph{graph with complementarity} is a reflexive graph ,
  equipped with a subgraph , a relation , and a map , such that
  the composite  is partially functional
  and symmetric.
\end{defi}
We let  and write  for . We further denote the map  by , and deem edges in 
\emph{closed-world}.

\begin{rem}
   has to be symmetric as the domain of a symmetric relation.
\end{rem}

\begin{defi}
  A morphism of graphs with complementarity is a morphism  of reflexive graphs such that
  \begin{mathpar}
    f(\aW) \subseteq \bW
\and
    \labelb \rond \fW = \labela \and ((a_1,a_2) \compata a_3)
    \Rightarrow ((f(a_1),f(a_2)) \compata f(a_3)),
  \end{mathpar}
  where  is the restriction of .
\end{defi}

\begin{prop}
  Graphs with complementarity and morphisms between them form a category .
\end{prop}





We now introduce the graph , which as announced in the
introduction will serve as a base for making  and
 into graphs with complementarity. It is an
\emph{interfaced} variant of , hence its name.
\begin{exa}
  Let  be the graph with as vertices all horizontal morphisms  from some interface to some position, and whose
  edges  are given by diagrams

in , where  is either a full move or an identity, such that if
 is an input or an output, then the corresponding channel is in the
image of .   forms a reflexive graph with identities given by
the case where , which forms a graph with complementarity as
follows.

Let  consist of all closed-world quasi-moves in . For any , , and , let
 iff , , and  is
the corresponding map . On edges, for any , , and , let  iff there exists a diagram
      
    where  is a closed-world quasi-move and double cells with a
    `double pullback' mark are cartesian, as below
    Axiom~\axref{fibration} (page~\pageref{fibration}). (One
    easily shows that the upper square is also a pushout.)  Then
    , consists of all pairs  for which there
    exists a diagram of the shape~\eqref{eq:trans}.

    Let  be the composite . It thus maps tick moves to  and
    all other closed-world moves to . The composite  is indeed partially
    functional and symmetric.

    There is an obvious morphism  of reflexive graphs.
\end{exa}

\begin{exa}\label{exa:Axi}
  Recall the alphabet  for CCS. It also forms a graph with complementarity, as follows.
Let  consist of all vertices and of all  and  edges.
Let  consist, on vertices, of the diagonal, i.e., all pairs .
On edges, let  when  and:
\begin{itemize}
\item one of  and  is in , the other being an identity,
\item or one of  and  is an input on some ,
  the other being an output on .
\end{itemize}
Define now our relation  to be the graph of the map sending
all coherent pairs  to , except when one is a ,
in which case the pair is sent to . The axioms
are easily satisfied.

Let  map any vertex  to 
, and any edge~\eqref{eq:limove} to
\begin{itemize}
\item  if  is an identity, a synchronisation, a fork, or a channel creation,
\item  if  is a tick move,
\item  if  is an input on ,
\item  if  is an output on .
\end{itemize}
This map  is a morphism of graphs with complementarity.
\end{exa}


We have the following general way of constructing graphs with
complementarity.  For any graph with complementarity  and morphism
of reflexive graphs , consider the following
candidate complementarity structure on . 

  Let  denote the pullback
  
Further, let  be the composite , and let  iff  (for both vertices and edges). In other words,
   is the relational composite 
    
    where the backwards  arrow denotes the converse of the graph
    of .

    \begin{prop}\label{prop:compatpR}
      For any subrelation , if 
      is symmetric, then  forms a graph
      with complementarity, and  is a morphism of graphs with
      complementarity to .
    \end{prop}
    \begin{proof}
    By standard relational algebra, the composite relation
    
    which is equal to
    
    is included in
    

    Composing with , we obtain that , which is
    straightforwardly symmetric and partially functional.  A
    subrelation of a partially functional relation is automatically
    partially functional, so  is partially functional.
    It is symmetric because  is, hence the result.
    \end{proof}

\begin{exa}\label{ex:lgraphs}
   forms a graph with complementarity over  by the last
  proposition, taking  to relate
  \begin{itemize}
  \item all pairs  to 
    on vertices,
  \item any transitions  and  with
    , and symmetrically,
  \item and any two transitions  and  with .
  \end{itemize}
\end{exa}

    \begin{prop}\label{prop:constructcompl} Suppose given a choice, for all  and  such that , of a vertex  such that , satisfying the following
      condition: for all edges  and  in , and  in , if
      , then there exists a
       such that
      .

      Then,  forms a graph with
      complementarity, and  is a morphism of graphs with
      complementarity.
  \end{prop}
  \begin{proof}
    Recalling the beginning of the proof of Proposition~\ref{prop:compatpR},
    the hypothesis implies that the inclusion
    
    is actually an equality.
    
    Composing with , we obtain that , which is straightforwardly
    symmetric and partially functional. The morphism  is a morphism
    of graphs with complementarity by construction.
\end{proof}


\begin{defi}
  Let  and  be
  the pullbacks of  and  along .   
\end{defi}

\begin{exa}
   and  form graphs with complementarity over  by
  Proposition~\ref{prop:constructcompl}.  The canonical relation
   does not satisfy the condition of
  Proposition~\ref{prop:constructcompl}, however. Indeed, e.g., any
  non-silent transition  and silent but non-identity transition  are not coherent in , although
  their images under the projection to  are so.  (Amalgamating two
  such transitions in  requires a path of length 2, as will be
  used below.) What saves  and  from this issue is that
  projecting to  does not hide away, e.g., synchronisations.
\end{exa}

\subsection{Modular graphs and fair testing equivalence}
We now introduce the notion of \emph{modular} graph, which is
appropriate for defining fair testing. We could actually introduce
fair testing for arbitrary graphs with complementarity, but the extra
generality would make little sense.

For any graph with complementarity ,  forms \anlts{} over
, through .
\begin{defi}
   is \emph{modular} iff for all  we have both:
  \begin{enumerate}
  \item for all , there exists  and
     such that ; and\label{modularity:i}
  \item for all  and  such that 
    there exists  such that . \label{modularity:ii}
  \end{enumerate}
\end{defi}
\begin{rem}
  The second condition is almost redundant: in any graph with
  complementarity , there exists  such that , but the target of  may be any  such that ; it does not have to be .
\end{rem}

\begin{prop}\label{prop:modbis}
    is \emph{modular} iff  is a strong bisimulation
  over .
\end{prop}
We here implicitly view  as a relation .
\begin{proof} 
Since  is a relation over , it is enough to prove that both 
projections are graph fibrations, which is directly equivalent to modularity.
\end{proof}

\begin{exa}
   and , as well as , are modular.
\end{exa}

We now define fair testing in any modular graph, and compare with both
semantic fair testing equivalence () for strategies and
standard fair testing equivalence () for CCS processes.
Recall that  denotes strong bisimilarity over .
\begin{lem}
  For any modular graph with complementarity  and , if  and , then .
\end{lem}
\begin{proof}
  We have .
\end{proof}

Any modular graph may be equipped with a choice of  such that
, for all . We denote such a choice by
. By the lemma, the choice of  does not matter as long as we
only consider properties invariant under .  Here, we only
need the standard predicate for fair testing.

\begin{defi}
  For any reflexive graph  over , let  denote the set of all
   such that for all  there exists .
\end{defi}
When  is a graph with complementarity,
we often denote  by . There is no confusion because 
 is not even a graph over  in general.

In any modular graph with complementarity , let, for any ,
, and let 
iff .
\begin{defi}
  For any , let  iff  and
  for all ,  iff .
\end{defi}

We may at last define fair relations:
\begin{defi}\label{def:fairrel}
  For all modular graphs with complementarity  and , and full
  relations , let  \emph{preserve fair testing
    equivalence} when, for all  and ,  implies .   \emph{reflects
    fair testing equivalence} when the converse implication holds.
   is \emph{fair} when it preserves and reflects fair testing
  equivalence.
\end{defi}

Modularity enables a first, easy characterisation of fair testing.
\begin{prop}
  If  is modular, then for any ,  iff
  .
\end{prop}
\begin{proof}
A direct consequence of Proposition~\ref{prop:modbis}.
\end{proof}

We now prove that the general definition of fair testing equivalence
instantiates correctly for  and .  First, we easily have 
\begin{prop}\label{prop:fairccs}
  For any two CCS processes  and  over ,  iff
  .
\end{prop}
\begin{proof}
  Straightforward.
\end{proof}

We now wish to compare , as defined in this section, and
the semantic . As an intermediate step, we consider the
following, bare , which lives over , but is defined in
terms of \ltss{} (as opposed to successful states of strategies).  Let
 be the restriction of  to closed-world transitions,
i.e., the pullback of  along the inclusion ; this is \anlts{} over  via .  Let  denote the set of pairs  such that
for all  there exists .
\begin{lem}\label{lem:bbot:bot}
  For all ,   iff .
\end{lem}

This essentially amounts to checking that the notions of closed-world,
successful, and unsuccessful play
(Definition~\ref{def:cw:successful}), correspond with closed-world,
successful, and unsuccessful transition sequences.  The former are
defined in terms of plays and moves therein, while the latter rest
upon the map .

  We first observe:
\begin{lem}\label{lem:closedworld}
  For any two closed-world plays  over , and  in ,  is an isomorphism, and it is unique.
\end{lem}

\begin{proof}[Proof of Lemma~\ref{lem:bbot:bot}]
  Let  and assume . Let  (over ).  This
  means that there exists a path 

such that, omitting positions, 

and  is mapped by  to the path of length  consisting
only of  edges. This implies by induction the existence of
, where 
is closed-world and unsuccessful, such that .  Because , there exists a
successful, closed-world play , a morphism  in , and  such that .  By
Lemma~\ref{lem:closedworld},  is isomorphic to an extension of  with
closed-world moves, say . By induction on , we obtain a path
 where . Because  is successful, there exists 
such that , hence . Thus, .

Conversely, assume . Let  be an
unsuccessful, closed-world play over  and . Picking a decomposition  of , we obtain a path 

in  such that , which 
yields . Because , there exists
, with underlying path

in , such
that  for all  and .  But by definition this means that  for some
 where  and  is the extension.
By construction, . Hence, .  
\end{proof}

We furthermore have:
\begin{lem}\label{lem:barebat:botL}
  For any vertex  of  and
  ,  iff .
\end{lem}
\begin{proof}
  The map  is a strong, functional bisimulation,
  because for any  and closed-world move , there exists a diagram~\eqref{eq:limove}.  Thus, the
  projection  is a strong, functional bisimulation by
  Proposition~\ref{prop:change of base}.
\end{proof}
\begin{rem}
  Interfaces are pretty irrelevant here, and indeed we could have
  decreed that closed-world moves only relate vertices with empty
  interfaces in . This is unnecessary here, though, so we stick
  to the simpler definition, but it will be crucial for the
  -calculus.
\end{rem}

This entails:
\begin{cor}\label{cor:SSSLI}
  For any , , , and
  ,  iff .
\end{cor}
\proof We have
  \begin{center}
     
    
      \makebox[0pt][l]{(by definition)}

      

      \makebox[0pt][l]{(by Lemma~\ref{lem:bbot:bot})}

      

      \makebox[0pt][l]{(by Lemma~\ref{lem:barebat:botL})}

      

      \makebox[0pt][l]{(by definition)}

      
\end{center}
which concludes the proof.
\qed







\subsection{Adequacy}
Until now, our study of graphs with complementarity and fair testing
therein is intrinsic, i.e., fair testing equivalence in a modular
graph with complementarity  does not depend on any alphabet.  We
now address the question of what an alphabet should be, for . The
main idea is that such an alphabet  should be a graph with
complementarity, and that viewing it as an alphabet for  is the
same as providing a morphism  in , satisfying
a certain condition called \emph{adequacy}. To understand the role of
this condition, one should realise that edges in  may be much too
fine a tool for checking fair testing equivalence. E.g., in ,
they include information about which players played which move.  Thus,
although it is true that weak bisimilarity implies fair testing
equivalence, this property is essentially useless for fair testing,
because too few strategies are weakly bisimilar.  Any morphism  induces an \emph{a priori} coarser version of fair
testing for , where one only looks at labels in .
\emph{Adequacy} is a sufficient condition for this latter version to
coincide with the original. This will in particular entail that weak
bisimilarity over  is finer than fair testing equivalence.

Adequacy relies on the following:
\begin{defi}
  Consider, for any  and  the pullback
    \begin{center}
      \Diag{\pbk{m-2-1}{m-1-1}{m-1-2} }{\combinea{G}{H} \& \acoh \\
        G \times H \& A^2. }{(m-1-1) edge[labelu={}] (m-1-2) edge[labell={}] (m-2-1) (m-2-1) edge[labeld={p \times q}] (m-2-2) (m-1-2) edge[into,labelr={}] (m-2-2) }
    \end{center}
    We call  the \emph{blind composition} of  and
     over , viewed as \anlts{} over  via
    .
\end{defi}

Recall from Section~\ref{subsec:prelim:lts} that  denotes
weak bisimilarity for reflexive graphs over .
\begin{defi}
  Let  be a morphism of graphs with
  complementarity. We say that  is \emph{adequate} iff
  \begin{itemize}
  \item the graph of  is
    included in , and
  \item for all ,  iff .
  \end{itemize}

\end{defi}
Concretely, any transition  is matched, without
any hypothesis on , by  itself. Conversely, having a
transition  in 
means that . Adequacy demands that
there exists a path  in , such that , and , where the left-hand side is in  and the
right-hand side is in .

Recall the map  from Example~\ref{exa:Axi}.
Via this map,  and  form \ltss{} and even graphs with
complementarity over .
\begin{prop}
  The maps from , , and  to  are adequate.
\end{prop}
\begin{proof}
  For all three graphs  over , both  and
   form graphs over , because  is actually partially functional.  In each case,
  the graph of  is a weak
  bisimulation over , because for all  and  in , if
  , then either , or both interleavings
  are coherent, i.e.,  and , pointwise. (Here, e.g.,  denotes the \emph{path}
  .)
\end{proof}
The only subtle point is that this only holds thanks to the
restrictions put on edges of . E.g., consider the graph the
graph  with the same vertices as , and edges  given just as for , except that we
do not require existence of a diagram~\eqref{eq:limove}.  Pullback
yields a graph  over .  Extending  to  in the obvious way, we obtain a graph over
.  Consider now the moves , let , and let  be one of the two
embeddings , say the one which is an inclusion at ,
 being the other.  Recalling labels in  from
Definition~\ref{def:A}, we have edges  and , and . However, the two edges are not coherent, because any attempt
to construct a diagram~\eqref{eq:trans} (with here ,
and ) fails (even if we forget about the vertical
identity). This is the very reason we use  instead of
.

We have the following two easy properties of blind composition.
\begin{prop}\label{prop:combine:adeq}
  For any modular , adequate , and  in , we have 
   iff .
\end{prop}
\begin{proof}
We have  .
\end{proof}

\begin{prop}
  For any  over , modular , adequate , , and
   in , if , then
  \begin{center}
     iff 
  \end{center}
\end{prop}
\begin{proof}
  By Proposition~\ref{prop:combine:adeq}, it is enough to prove that
  the right-hand side is equivalent to , which is straightforward by hypothesis.
\end{proof}



We conclude this section by stating the main property of blind
composition, Proposition~\ref{prop:combinecombine} below, which will
be used extensively in the next section.

To start with, recall the following notation from
Section~\ref{subsubsec:notation:lts}. There, considering a morphism  of reflexive graphs, we defined ,
for  and  in
.  Namely, this denotes any path  in , such that .

In order to state Proposition~\ref{prop:combinecombine}, we now need
to equip  with complementarity structure, but we cannot
do it over the graph , because closed-world paths may contain
more than one  edge, hence cannot all be mapped to .  We
thus define \emph{categories} with complementarity.

The notions of relation, partial functionality, functionality,
totality, and domain on reflexive graphs carry over to categories,
e.g., a relation  is a subcategory . The only subtlety is that the definitions imply certain
functoriality properties.  E.g., for any composites  in 
and  in , if  and ,
because , as a subcategory, is stable under composition, we have
for free that .  Similarly, if  for objects  and , then .  We thus rename partial functionality and functionality into
partial functoriality and functoriality in this setting.
\begin{defi}
  A \emph{category with complementarity} is a category , equipped
  with a subcategory , a relation , and a functor , such
  that the composite  is
  partially functorial and symmetric.
\end{defi}
Again, we let  and write  for
. We further denote the map  by , and deem
morphisms in  \emph{closed-world}.

Defining functors with complementarity in the obvious way, we obtain:
\begin{prop}
  Categories with complementarity form a (locally small) category
  .
\end{prop}

Consider the functor 
mapping any category with complementarity  to its underlying graph, say , which we equip
with complementarity structure as follows. First, define
 and  by the pullback
\begin{center}
  \Diag{\pbk{m-2-1}{m-1-1}{m-1-2} }{\GW \& \C^\W \\
    \Sierp \& \freecat{\Sierp}. }{(m-1-1) edge[labelu={i}] (m-1-2) edge[labell={\labelG}] (m-2-1) (m-2-1) edge[labeld={\eta}] (m-2-2) (m-1-2) edge[labelr={\labelC}] (m-2-2) }
\end{center}
Furthermore, let  consist of all triples  of
vertices (resp.\ edges) such that  and
 (which is a pullback of  along ).  This
clearly equips  with complementarity structure and extends to the
announced functor .

This functor does not appear to have a left adjoint, because
complementarity in  may behave badly w.r.t.\ composition in
. However, we may define the following candidate structure on .
Consider any graph with complementarity , and
  let us start by defining a complementarity structure on .
  Let  denote the subcategory of closed-world paths in , 
  i.e., .
  Accordingly, let  be the composite
  
  Finally, consider the functor
  
  It yields a relation , whose
  converse we use to define  as the composite relation
   Concretely,  is  on objects, 
  and on paths, we have  iff all three
  paths  and  have the same length  and
   for all .  This clearly makes
   into a category with complementarity.
  
  Let us now define our candidate complementarity structure on ,
  for any .  Let first  be the image of
  , i.e., all
  -free, closed-world paths.  This in particular induces a
  functor , with which
   is obviously compatible, hence we define
   to be the induced functor.  Finally, let
   be the following relational composite, where the backwards
  arrow denotes a converse:
   Concretely, 
  iff there exist  such that  for .  Intuitively,  and  are
  coherent if upon insertion of identities at appropriate places they
  become pointwise coherent.  

  The relational composite  is obviously symmetric and furthermore partially functional
  on objects, so in order to equip  with complementarity
  structure, it only misses partial functoriality on morphisms.

  \begin{defi}
    Let  denote the full subcategory of  spanning
    objects  such that the above composite is partially functorial
    on morphisms, which we call \emph{functorial} graphs with
    complementarity.
  \end{defi}

  \begin{exa}
    A sufficient condition for a graph with complementarity  to be
    functorial is to satisfy
     \begin{enumerate}[label=(\roman*)]
     \item for any two edges  and , and object , if , , and , then  is an identity;
     \item for all edges  and ,  and 
       are defined at the same time and then equal.
     \end{enumerate}    
     The three graphs with complementarity , , and
      satisfy these conditions, hence are functorial.
  \end{exa}

  The forgetful functor  of course lands into  and
  we view it as a functor  from now on.
  \begin{prop}
    The above construction of ,
    , and  extends to a left
    adjoint to , which coincides with  on
    underlying graphs.
  \end{prop}
  We henceforth denote the left adjoint by . 
\begin{proof}
  Proving that this is left adjoint to  reduces to showing
  that the composite
  
  factors through , and conversely the composite
  
  factors through ,
  which is routine.
\end{proof}

We may now state the main property of blind composition:
\begin{prop}\label{prop:combinecombine}
  For any graphs with complementarity  and  over , and
  transition sequences  and  respectively in  and , if
  , then  in .
\end{prop}
\begin{proof}
  Let  and  be the given
  projections. Let also  for
  all  witness the fact that .  It is enough to prove , which is in fact a
  trivial induction on the length of  using the definition of
  .
\end{proof}


\subsection{Trees}
Returning to our main question, we know by Theorem~\ref{thm:bisim}
that the graph morphism  is a functional, strong
bisimulation over . Hence, by Proposition~\ref{prop:change of
  base}, we have:
\begin{prop}\label{prop:strongbisima}
  The graph morphism  is a functional, strong
  bisimulation over , and thus also over .
\end{prop}
In this section, we introduce a criterion for a relation  between modular graphs with complementarity over some
adequate alphabet , which essentially ensures that if , then  is fair.  This will reduce our main question to
proving that the full relation induced by the map 
is included in weak bisimilarity over , which we do in
Section~\ref{subsec:horror}.

Our criterion will rest upon the notion of -tree, for any graph
with complementarity , which is directly inspired by the work of
Brinksma et al.\ on
\emph{failures}~\cite{DBLP:journals/iandc/RensinkV07}.

Let the set  of \emph{-trees} consist of possibly infinite terms in the
grammar
\begin{mathpar}
  \inferrule{\ldots \\ v_i \vdash t_i \\ \ldots \\ (\forall i \in n) }{v \vdash \sum_{i \in n} a_i.t_i }~(n \in \Nat)
\end{mathpar}
where for all ,  in  is not silent,
i.e.,  implies . -trees form a
reflexive graph over  with edges determined by


\begin{defi}
  A modular graph  over  \emph{has enough
    -trees} iff for all ,  such that , for all -trees , there exists  such
  that  and  is weakly bisimilar to  (over ).
\end{defi}
\begin{rem}\label{rem:trees}
  In the case where  iff ,
  this is equivalent to requiring that for all  and -tree
   over , there exists  such that  and
  .
\end{rem}
\begin{exa}\label{ex:enoughatrees}
  , , and  have enough -trees, and
  Remark~\ref{rem:trees} applies.
\end{exa}

-trees yield a new testing equivalence, called \emph{-tree}
equivalence, as follows.
\begin{defi}
  For any modular , let
   be the relation defined by  iff
   and for all  such that 
  and -trees ,
  \begin{center}
     iff .
  \end{center}
\end{defi}

A graph with complementarity  \emph{has enough ticks} iff for all
, there exists an edge  such that
. Furthermore,  is \emph{inertly silent}
iff for all  in  such that ,
we have  and .
\begin{defi}\label{def:nice}
  A graph with complementarity  is a \emph{nice alphabet} iff it
  has enough ticks, and is finitely branching and inertly silent.
\end{defi}

\begin{exa}
   is a nice alphabet, but  is not, because it is not
  inertly silent.
\end{exa}

The main property of -trees is:

\begin{prop}\label{prop:failures}
  Consider any modular  and adequate , where 
  has enough -trees and  is a nice alphabet. Then,
  .
\end{prop}

We start with some preparation.  Let a path in  be \emph{loud} iff
it contains no silent (=identity if  is inertly silent) edge, and
\emph{-free} iff no edge is in .  Let
the set  of \emph{failures} over  consist of all
pairs , where  is any loud, -free
path in  and  is a set of loud paths such that
for all , .

  We define a map  to -trees
  over , for all , by induction on , followed by coinduction
  on :
  .5em]
      L & \mapsto & 
\sum_{\ens{e \in A(-,a) \aalt L \cdot e \neq \emptyset}}
        e.\failof{L \cdot e} 
\end{array}
  \rho' \in \ens{r \in A^\star \aalt \exists r' \in A^\star, l \in L, r \rond r' = \rho \rond l}.(\para_{n} \para_{x \in X[n]} P_x
[l \mapsto x \cdot s_l]),I(\star) \vdash \nu^{X (\star) - I (\star)}. \left (\para_{n} \para_{x \in X[n]} P_x
\left [
  \begin{array}[c]{ll}
    l \mapsto \epsilon a.(h_\star(a) = x \cdot s_l) & \mbox{if } \\
    l \mapsto \gamma_h(x \cdot s_l) & \mbox{otherwise} 
  \end{array}
\right ] \right ),\ob\ccs \xmodto{\scong} \ob\ccs \xmodto{\III} \ob\TTTL.\mu(i) = \left \{
\begin{array}[c]{ll}
  i & \mbox{if } \\
  i_0 & \mbox{if  or } \\
  {i-1} & \mbox{if }
\end{array} \right .P'_i = \left \{
\begin{array}[c]{ll}
  P_i & \mbox{if } \\
  P_{i_0}^1 & \mbox{if } \\
  P_{i_0}^2 & \mbox{if } \\
  P_{i-1} & \mbox{if },
\end{array} \right .\epsilon a.(h_\star(a) = x_i \cdot s_l) =
\epsilon b.(k_\star(b) = y_j \cdot s_l).h[P] =  \nu^{X (\star) - I (\star)}. \left (\para_{i \in n} P_i\left [
  \begin{array}[c]{ll}
    l \mapsto \epsilon a.(h_\star(a) = x_i \cdot s_l) & \mbox{if } \\
    l \mapsto \gamma_h(x_i \cdot s_l) & \mbox{otherwise} 
  \end{array}
\right ] \right ) k[P'] =  \nu^{Y (\star) - I (\star)}. \left (\para_{j \in n+1} P'_j\left [
  \begin{array}[c]{ll}
    l \mapsto \epsilon b.(k_\star(b) = y_j \cdot s_l) & \mbox{if } \\
    l \mapsto \gamma_k(y_j \cdot s_l) & \mbox{otherwise} 
  \end{array}
\right ] \right ). 
\begin{array}{rcl}
h[P] & \scong & \nu^{Y (\star) - I (\star)}. \left (\para_{j \in n+1, j \neq i_0 + 1} P_{\mu(j)} \left [
  \begin{array}[c]{ll}
    l \mapsto \epsilon b.(k_\star(b) = y_j \cdot s_l) & \mbox{if } \\
    l \mapsto \gamma_k(\delta_M(x_i \cdot s_l)) & \mbox{otherwise} 
  \end{array}
\right ] \right ) \\
& \scong & \nu^{Y (\star) - I (\star)}. \left (\para_{j \in n+1, j \neq i_0 + 1} P_{\mu(j)} \left [
  \begin{array}[c]{ll}
    l \mapsto \epsilon b.(k_\star(b) = y_j \cdot s_l) & \mbox{if } \\
    l \mapsto \gamma_k(y_j \cdot s_l)) & \mbox{otherwise} 
  \end{array}
\right ] \right ) \\
& \xot{\id} & \nu^{Y (\star) - I (\star)}. \left (\para_{j \in n + 1} P'_j\left [
  \begin{array}[c]{ll}
    l \mapsto \epsilon b.(k_\star(b) = y_j \cdot s_l) & \mbox{if } \\
    l \mapsto \gamma_k(y_j \cdot s_l)) & \mbox{otherwise} 
  \end{array}
\right ] \right ) \\
& \scong & k[P'].
\end{array}Q = \nu^{X (\star) - I (\star)}. \left (\para_{i \in n} P'_i\left [
  \begin{array}[c]{ll}
    l \mapsto \epsilon a.(h_\star(a) = x_i \cdot s_l) & \mbox{if } \\
    l \mapsto \gamma_h(x_i \cdot s_l) & \mbox{otherwise} 
  \end{array}
\right ] \right ), 
      \diag{X \& X' \\
        U \& V \\
        Y \& Y' }{(m-1-1) edge[into,labelu={h}] (m-1-2) (m-2-1) edge[into,labelo={k}] (m-2-2) (m-3-1) edge[into,labeld={l}] (m-3-2) (m-1-1) edge[into,labell={s}] (m-2-1) (m-1-2) edge[into,labelr={s'}] (m-2-2) (m-3-1) edge[linto,labell={t}] (m-2-1) (m-3-2) edge[linto,labelr={t'}] (m-2-2) } \hfil \mbox{as double cells} \hfil
      \doublecellpro{X}{X'}{Y}{Y',}{h}{U}{V}{l}{(h,k,l)}
      \label{eq:doublecelll}
    \past{M} \into {\elements M}
\to {\elements U}.U
\fatbslash \mu = \bigcup \ens{V \into U \aalt \elements V \cap \past{\mu} =
  \emptyset}.Y \xinto{s_2} U' \xotni{t_2} Z \xinto{s_1} M' \xotni{t_1} X,
  \diag{|(X)| X \& |(U)| U \& |(Y)| Y. }{(X) edge[into,labeld={s}] (U) (Y) edge[linto,bend left=20,labeld={t}] (U) (U) edge[history,bend left=20,labelu={p}] (Y) }\label{eq:vmor}

  \Diag{\twocellbr{B}{A}{X}{\alpha} }{|(A)| A \& |(X)| X \\
    |(B)| B \&  \\
    |(C)| C \& |(Y)| Y, }{(A) edge[labelu={h}] (X) edge[pro,labell={w}] (B) (X) edge[pro,labelr={u}] (Y) (B) edge[pro,labell={v}] (C) (C) edge[labeld={k}] (Y) }\label{eq:alphaa}
u_1 = \bigcap
  \ens{u' \subseteq u \aalt (Y \subseteq u') \wedge (\im_\alpha (G_v)
    \subseteq G_{u'})}.u_2 = \bigcap \ens{u'' \subseteq u \aalt G_{u''} \supseteq {{\uparrow} Z}}.
 The union 
  is , i.e., the square
  \begin{center}
    \Diag{\pbk{m-2-1}{m-1-1}{m-1-2} }{Z \& u_1 \\
      u_2 \& u }{(m-1-1) edge[labelu={}] (m-1-2) edge[labell={}] (m-2-1) (m-2-1) edge[labeld={}] (m-2-2) (m-1-2) edge[labelr={}] (m-2-2) }
  \end{center}
  is a pushout, i.e.,  in . So
  it only remains to prove that  and  are plays, for which we use
  Theorem~\ref{thm:completeness}. First,  and , as
  subpresheaves of , both are locally 1-injective. Furthermore,
   and , as subgraphs of a linear and acyclic graph,
  are also linear and acyclic. Now, by definition of , 
  contains all channels and the final players of . Further, since
  , being initial in  implies being initial in
  , so  indeed is a play. Symmetrically, no
  player of  not in  is final, so , and hence
   indeed contains all channels and final players.
  Finally, the players and channels of  are precisely the initial
  players and channels of .  

  It remains to show that the induced decomposition of  is
  weakly initial.  But any decomposition, inducing a decomposition
   of , should satisfy ,
  , and , so, ignoring isomorphisms for readability,  and , as desired.
\end{proof}

\subsection{CCS as a playground}
We are now ready to prove the decomposition axioms, which entail
Theorem~\ref{thm:playground}. They are proved in
Lemmas~\ref{lem:decompleft} and~\ref{lem:decompsym} below.


Let us start with the following easy lemma.
\begin{lem}\label{lem:causalsplit}
  If , then, in 
  \begin{itemize}
  \item no player of  is reachable from any core of
    ;
  \item no core of  is reachable from any element of
    .
  \end{itemize}
\end{lem}
\begin{proof}
  For the first point, cores of  only reach initial channels of .

  For the second point, we further observe that channel and players of 
  only reach initial players and channels of , hence no core.
\end{proof}

The easiest decomposition axiom is~\axref{views:decomp}.
\begin{lem}\label{lem:decompsym}
   satisfies~\axref{views:decomp}.
\end{lem}

\begin{proof}
  Although the statement is complicated, this is rather easy: 
  restricts to a map of presheaves , on which we
  proceed by case analysis.

  If , then by Lemma~\ref{lem:decomp} and
  correctness we are in the left-hand case.  Otherwise, assume that a
  move  is in the image of , say of a move . We have a path  in , hence a path
   in , contradicting
  Lemma~\ref{lem:causalsplit}.
\end{proof}

Let us now attack the last axiom.
\begin{lem}\label{lem:decompleft}
 satisfies~\axref{leftdecomposition}.
\end{lem}

We need a few lemmas.


\begin{lem}\label{lem:causalcompo}
  For any plays , for any player or channel
   and core , there is no edge  in
  .
\end{lem}
\begin{proof}
  The existence of  implies , hence 
  initial in , which contradicts the very existence of~.
\end{proof}

\begin{lem}\label{lem:presfinal}
  Morphisms of plays preserve finality.
\end{lem}
\begin{proof}
  If a player is final in the domain, then it is in the final
  position, hence has an image in the final position of the codomain,
  hence is final there.
\end{proof}

\begin{lem}\label{lem:mapfib}
  For any map  in , for any player  in
   and edge  from a core in ,
  there exists a core  and an edge  in
   such that .
\end{lem}
\begin{proof}
  Let first  and  be the considered
  morphisms.

  Then, observe that  is not final in , for otherwise it would
  be in , hence  would be in  and final,
  contradicting the existence of .

  So there exists  in . But now, by
  target-linearity, , which entails the result.
\end{proof}

\begin{lem}\label{lem:morpbk}
  In any double cell~\eqref{eq:doublecelll}, both squares are pullbacks.
\end{lem}
\begin{proof}
   must consist precisely of all final players and channels of
  , which must also be final in , so finality in 
  implies finality in . Conversely, any player or channel mapped
  to a final one in  has to be final. So  is a pullback of 
  and .  The lower square being a pullback follows from similar
  reasoning.
\end{proof}

\begin{proof}[Proof of Lemma~\ref{lem:decompleft}]
  Consider any , and construct  and the
  morphisms in Figure~\ref{fig:proof:lem:decompleft}, as follows. \begin{figure}[t]
    \centering
      \Diag (.4,.6) {\pbk[.6cm]{w_1}{w}{w_2} \path[->,draw] (C) edge (Y) (Y) edge (w_1) edge (w_2) (w_1) edge (w) (w_2) edge (w) (C) edge[fore] (u_1) edge[fore] (u_2) (u_1) edge[fore] (u) (u_2) edge[fore] (u) (u) edge[fore,labelu={f}] (w) (u_1) edge[fore,labelu={f_1}] (w_1) (u_2) edge[fore,labeld={f_2}] (w_2) ; \pbk[.6cm]{u}{u_1}{w_1} \pbk[.6cm]{u}{u_2}{w_2} \pbk[.6cm]{u_2}{C}{Y} \pbk[.6cm]{u_1}{C}{Y} \pullback[.6cm]{u_1}{u}{u_2}{draw,-,fore} \path[->,draw] (A) edge[dashed] (u_1) edge[bend left,fore] (u) edge[labelu={f_s}] (X) (X) edge (w_1) edge[bend left,fore] (w) (B) edge[dashed] (u_2) edge[bend right,fore] (u) edge[labeld={f_t}] (Z) (Z) edge (w_2) edge[bend right,fore] (w) ; }{\& \& |(A)| A \& \& \& \& \& \& \& |(X)| X \& \\ \& \& \& \& \& \& \& \& \& \& \\ \& \& \& \& \& \& \& \& \& \& \\ \& \& |(u_1)| u_1 \& \& \& \& \& \& \& |(w_1)| w_1 \& \\ |(C)| C \& \& \& \& \& \& \& |(Y)| Y \& \& \& \\ \& \& \& \& \& \& \& \& \& \& \\ \& \& \& |(u)| u \& \& \& \& \& \& \& |(w)| w \\ \& |(u_2)| u_2 \& \& \& \& \& \& \& |(w_2)| w_2 \& \& \\ \& \& \& \& \& \& \& \& \& \& \\ \& \& \& \& \& \& \& \& \& \& \\ \& |(B)| B \& \& \& \& \& \& \& |(Z)| Z, \& }{}
    \caption{Proof of Lemma~\ref{lem:decompleft}}
\label{fig:proof:lem:decompleft}
\end{figure}First, let  be the pullback , and then . Let then , and the arrow  be induced by universal property of pullback. By the pullback
lemma, . Because presheaf categories are
adhesive~\cite{DBLP:conf/fossacs/LackS04},  is, and,  being monic, we have a Van Kampen square. Thus, by the main axiom
for adhesive categories,  is a pushout , i.e.,  in . Letting  be the
arrow , for , this yields the desired
decomposition of
.  \\

We still need to show that  and  are
plays, and that the obtained decomposition is unique.  Uniqueness
follows from adhesivity of  and Lemma~\ref{lem:morpbk}. Indeed,
any decomposition looks like Figure~\ref{fig:proof:lem:decompleft},
except that , , and  are not \emph{a priori} obtained by
pullback. But by Lemma~\ref{lem:morpbk}, both back faces have to be
pullbacks, hence so are the front faces by adhesivity.

Let us finally show that  and  are plays. It is easy to see
that non-linearity or non-acyclicity of  (resp.\ )
would entail non-linearity or non-acyclicity of  or  (resp.\
or ). Local 1-injectivity
is also easy. \\

Let us now prove the missing conditions for .

a) Any player  of  in the image of  is final, for
otherwise its image in  would be in the image of  and
non-final. 

b) Conversely, if a player  is final but not in , then
its image in  must be non-final by Theorem~\ref{thm:completeness},
because  is monic. But then there is a core  of 
with a path  in , whose images in  yield a path
from a core of  to a player of , contradicting
Lemma~\ref{lem:causalsplit}. So  contains precisely the final
players of . 

c) Now, if a channel  is not in , then its image in 
must be in , hence  cannot be mono, so neither can , so neither can , contradiction.

d) Finally, by construction,  contains precisely the initial
players
and channels of .\\

Now, for .

a) By universal property of pullback,  contains all channels of
. 

b) For players, clearly, for any player  in ,  is final in
. Indeed, otherwise, there would be a path  from a
core  in , yielding a path  in
. But since  is in , , which hence contains
a non-final player, contradiction.

c) Conversely, if  is final in , then  is final
in . Indeed, otherwise, there would be an edge  from
a core in , so, by Lemma~\ref{lem:mapfib}, an edge  in
 with . But then, , so  cannot be
final. This shows that  is final in . But then ,
so, because , .

d) Consider now any player or channel  initial in . First,  is also
initial in : otherwise, there would be an edge  to a
core in , with , hence an edge  in
 from a channel of  to a core of , which is impossible by
Lemma~\ref{lem:causalcompo}. So  is initial in , hence .

e) Now, for any player or channel ,  is initial in , hence  is
\emph{a fortiori} initial in . 
\end{proof}

\section{Conclusion and perspectives}\label{sec:conc}

\subsection{Conclusion}
We have described a denotational semantics of CCS based on presheaves,
with a strong game-semantical flavour. Some aspects of the approach
look promising to us. 

First, our result is encouraging for potential applications of Kleene
coalgebra to programming language theory, i.e., ascribing a semantics
to the `rule of the game' rather than attempting to organise
operational semantics into some categorical structure.

Second, our use of techniques from categorical combinatorics (e.g.,
defining positions and plays as finite presheaves) provide a
high-level, yet rigorous toolbox for dealing with string diagrams.
(Compare, e.g., with available definitions of linear logic proof nets
or interaction nets.)

Third, our notion of play encompassing both views and closed-world
plays, and its rich notion of morphism yields a convincing interplay
between strategies (presheaves on views) and behaviours (presheaves on
plays). In particular,
\begin{itemize}
\item passing from one to the other
is handled by standard categorical constructions,
\item the general syntax and \lts{} for strategies provides a link to
  syntactic approaches.
\end{itemize}

Other aspects of our model are not as satisfactory.

First of all, the notion of playground is very complicated.  In work
in progress on a similar approach for -calculus, we bypass the
intermediate \lts{}  of process terms, because it does not help so
much ---  strategies are already really close to -calculus
terms.  This seems to hint that the main result of playground theory
is actually the characterisation of strategies by the syntax of
Section~\ref{subsec:syntax:strats}. The good point is: this result
does not at all need all axioms for playgrounds.

A second negative point is that some proofs may probably be improved.
E.g., our proof that  is included
in weak bisimilarity is a bit of a nightmare, with no apparent good
reason.  Similarly, we know already that our constructions for showing
the fibration axiom~\preaxref{fibration} may be improved. Indeed, the
trick we use to restore synchronisations after restriction rests upon
a \emph{factorisation system}~\cite{FK,Joyal:ncatlab:facto}.  In our
current work on , we use factorisation systems to prove the
fibration axiom in a much more direct way (which was prompted by the
fact that the method used here does not apply).
 
\subsection{Perspectives}
Beyond these rather technical concerns, we plan to adapt our semantics
to more complicated calculi like , the Join and Ambients calculi,
calculi with passivation, functional calculi, possibly with extra
features (e.g., references, data abstraction, encryption), with a view
to eventually generalising it, perhaps to some SOS format.  In
particular, adapting the approach to functional calculi should clarify
the relationship with Hyland-Ong innocence.  In work in progress
mentioned above, we construct a playground for , whose proof of
full abstraction remains to be completed. More speculative directions
include
\begin{itemize}
\item designing a general way of constructing playgrounds
  automatically from more elementary data; work in progress reveals
  that this is a very subtle task;
\item defining a notion of morphisms for playgrounds, which should
  induce translation functions between strategies, and find sufficient
  conditions for such morphisms to preserve, resp.\ reflect testing
  equivalences;
\item generalising playgrounds to apply them beyond programming
  language semantics; in particular, preliminary work shows that
  playgrounds easily account for cellular automata; this raises the
  question of how morphisms of playgrounds would compare with various
  notions of simulations between cellular
  automata~\cite{DBLP:journals/tcs/DelormeMOT11};
\item incorporate quantitative aspects from Kleene coalgebra into
  playground theory; this may start by refining fair testing
  equivalence to keep track of the probability of passing each test
  successfully.
\end{itemize}



\bibliographystyle{plainnat}
\bibliography{../common/bib}

  \begin{figure}[p]
\vspace*{-2em}    \begin{multicols}{2}
\hspace*{-4em}      \begin{tabular}{lp{.8\linewidth}}
         & base category, over which positions and plays are presheaves \\
        \begin{minipage}[t]{.3\linewidth}
          \raggedright , , , , ,
          , , , 
        \end{minipage} & objects of  \\
         &
        two players sharing some channels \\
         & bicategory of cospans of  \\
         & category of positions and embeddings \\
         & bicategory of positions and plays \\
         & playground \\

& playground for CCS \\
         & category of plays and extensions \\
         & category of behaviours on  \\
         & category of views and extensions \\
         & category of strategies on  \\
         & players of position  \\
         & view of  in  \\
         & initial player of  in  \\
         & 
        restriction of  along  \\
         & players of position  whose view in  is non-trivial \\
         & projection of  to  \\
         & copairing of  and  \\
         & residual of  after  \\
         & restriction of  to antecedents of  \\
         & graph of full quasi-moves \\
 & set of isomorphism classes of basic moves over  \\
         & set of isomorphism classes of full moves over  \\
         & set of basic 's s.t.\   \\
         & subset of full moves  such
        that  is a singleton \\
         & subset of full moves  such
        that  is not a singleton \\
         &
        bijection, for all plays , 
         \\

         & strategy term \\
         & definite strategy term \\
         & process term \\

         & set of tests passed by  \\

         & fair testing eq.\ in graph w.c.\  \\
         & standard fair testing eq.\ in CCS \\
         & semantic fair testing eq. \\

      \end{tabular}

      \begin{tabular}{lp{.7\linewidth}}

         & pole for fair testing eq.\ in  \\
         & pole for semantic fair test.\ eq. \\
         & pole for CCS (Def.~\ref{def:ccsfair}) \\
         & intermediate pole (Lem.~\ref{lem:bbot:bot}) \\


         & \lts{} for CCS \\
         & \lts{} for strategies \\
         & set of process terms \\
         & \lts{} for : {} \\
         & translation  \\
         & translation  \\
         & translation  \\

         & set of closed-world quasi-moves \\
         & subbicat.\ of closed-world plays \\
         &
        labelling of closed-world plays in :
         \\

         & `closed-world' subgraph of a graph with complementarity  \\
         & compatibility relation for :   \\
         & notation for the composite  \\

         & choice of `amalgamation' in  \\


 & subgraph of edges with double cell  \\
         & mapping to CCS labels \\
        
         modular &   strong bisim over  \\
        
         &  \\
         &  \\

         & blind composition of  and  over  \\
        \begin{minipage}[t]{.2\linewidth}
        adequacy of 
        \end{minipage} &
        (essentially)  \\
        
         & -trees \\
         & failures over  \\
         & failures to -trees:  \\
        nice alphabet & enough ticks, finitely branching, inertly silent 
        (Def.~\ref{def:nice}) \\
        
        core & move element of some presheaf, of maximal dimension \\
         locally 1-inj. & cores map inj.\ to , except 
        perhaps for channels in the interface  \\
         & causal graph of  \\
         & elements  synchronisations \\
         & map between 's \\
        horn  & synchro. minus  \\
         & change of base along 
      \end{tabular}
    \end{multicols}
    \caption{Cheat sheet}
\label{fig:cheat}
\end{figure}


\end{document}
