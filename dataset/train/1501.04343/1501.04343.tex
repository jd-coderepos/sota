








\documentclass[10pt,journal,compsoc]{IEEEtran}
















\ifCLASSOPTIONcompsoc
\usepackage[nocompress]{cite}
\else
\usepackage{cite}
\fi






\ifCLASSINFOpdf
\else
\fi





















































\hyphenation{op-tical net-works semi-conduc-tor}








\usepackage{amsmath}
\usepackage{color}
\usepackage{graphicx}
\usepackage{threeparttable}
\usepackage[linesnumbered, ruled, vlined]{algorithm2e}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}

\newtheorem{theorem}{\textbf{Theorem}}\newtheorem{definition}{\textbf{Definition}}\newtheorem{feature}{Feature}\newtheorem{proposition}{\textbf{Proposition}}\newtheorem{lemma}{Lemma}\newtheorem{assumption}{Assumption}\newtheorem{principle}{\textbf{Principle}}\newtheorem{observation}{\textbf{{\em Observation}}}\newtheorem{property}{\textbf{{\em Property}}}


\usepackage[noend]{algpseudocode}
\usepackage{indentfirst}


\newcommand{\tth}{t^{\textrm{th}}}

\makeatletter
\newcommand{\rmnum}[1]{\romannumeral #1}
\newcommand{\Rmnum}[1]{\expandafter\@slowromancap\romannumeral #1@}
\makeatother


\usepackage{array}
\newcolumntype{C}[1]{>{\centering\arraybackslash}m{#1}}











\begin{document}
\title{Algorithms for Scheduling Malleable Tasks}


\author{Xiaohu~Wu,
        and~Patrick~Loiseau
\IEEEcompsocitemizethanks{\IEEEcompsocthanksitem Xiaohu Wu is with Fondazione Bruno Kessler, Trento,
Italy.\protect\\
E-mail: xiaohuwu@fbk.eu
\IEEEcompsocthanksitem Patrick Loiseau is with Univ. Grenoble Alpes, LIG, France and MPI-SWS, Germany. E-mail: patrick.loiseau@univ-grenoble-alpes.fr




}\thanks{Manuscript received April 19, 2005; revised August 26, 2015.}}





\markboth{Journal of \LaTeX\ Class Files,~Vol.~14, No.~8, August~2015}{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Computer Society Journals}












\IEEEtitleabstractindextext{\begin{abstract}
Due to the ubiquity of batch data processing in cloud computing, the related problems of scheduling malleable batch tasks have received significant attention recently. In this paper, we consider a fundamental model where a set of  tasks is to be processed on  identical machines and each task is specified by a value, a workload, a deadline and a parallelism bound. Within the parallelism bound, the number of machines assigned to a task can vary over time without affecting its workload. For this model, we first give two core results: the definition of an optimal state under which multiple machines could be utilized by a set of tasks with hard deadlines, and, an algorithm achieving such a state.
The optimal utilization state plays a key role in the design and analysis of scheduling algorithms
(\rmnum{1}) when several typical objectives are considered, such as social welfare maximization, machine minimization, and minimizing the maximum weighted completion time, and, (\rmnum{2}) when the algorithmic design techniques such as greedy and dynamic programming are applied to the social welfare maximization problem. As a result, we give four new or improved algorithms for the above problems.
\end{abstract}

}


\maketitle


\IEEEdisplaynontitleabstractindextext




\IEEEpeerreviewmaketitle




\section{Introduction}
\label{intro}


Cloud computing has become the norm for a wide range of applications and batch processing constitutes the most significant computing paradigm \cite{Hu}. Applications such as web search index update, monte carlo simulations and big-data analytics require executing a new type of parallel tasks on clusters, termed {\em malleable tasks}. Two basic features of malleable tasks are about {\em workload} and {\em parallelism bound}. There are multiple machines, and, throughout the execution, the number of machines assigned to a task can vary over time within the parallelism bound but its workload is not affected by the number of used machines \cite{Jain11a,Jain}. Beyond understanding how to schedule the fundamental batch task model, many efforts are also devoted to its online version \cite{Lucier,Azar,Jain14} and its extension in which each task contains several subtasks with precedence constraints \cite{Bodik,Nagarajan}. In practice, for better efficiency, companies such as IBM have integrated these smarter scheduling algorithms for various time metrics  \cite{Nagarajan} (than the popular dominant resource fairness strategy) into their batch processing platforms \cite{Wolf}.


In scheduling theory, the above malleable task model can be viewed as an extension of the classic model of scheduling preemptive tasks on a single or multiple machines where the parallelism bound is one \cite{Lawler91,Karger}.  When each task has to be completed by some deadline, the results from the special single machine case have already implied that the state of optimally utilizing machines plays a key role in the design and analysis of scheduling algorithms under several objectives \cite{Karger}. In particular, the famous EDF (Earliest Deadline First) rule can achieve an optimal schedule for the single machine case. It is initially designed so as to find an exact algorithm for scheduling batch tasks to minimize the maximum task lateness (i.e., task's completion time minus due date) \cite{Jac55}. So far, numerous applications of this rule have been found, e.g., (\rmnum{1}) to design exact algorithms for the extended model with release times \cite{Hor74} and for scheduling tasks with deadlines (and release times) to minimize the total weighted number of tardy tasks \cite{Lawler69}, and (\rmnum{2}) as a significant principle in the analysis of scheduling feasibility for real-time systems \cite{Stankovic98}.

Similarly, we are convinced that, as far as malleable tasks are concerned, achieving such an optimal resource utilization state is also very important for designing and analyzing scheduling algorithms (\rmnum{1}) under various objectives, or (\rmnum{2}) when different algorithmic design techniques such as greedy and dynamic programming are applied. The intuition for this is that, if the utilization state was not optimal in an algorithm, its performance could be improved by utilizing the machines optimally to allow more tasks to be completed. All these considerations motivate us to develop an theoretical framework proposed in this paper.








Before this paper, a greedy algorithm was proposed in \cite{Jain} that achieves a performance guarantee ; here,  is the number of machines,  is the maximum parallelism bound of all tasks,  is the minimum slackness of all tasks where each task's slackness is defined to be the ratio of its deadline to its minimum execution time, which is the time when a task is always allocated the maximum number of machines during the execution.  is a system parameter and is assumed to be finite \cite{White}. Intuitively,  characterizes the resource allocation urgency (e.g.,  means that the maximum amount of machines have to be allocated to a task at every time slot to meet its deadline).




\subsection{Our Results}
\label{sec.contributions}




\vspace{0.22em}\noindent\textbf{Core result} (Section~\ref{sec.optimal}). The core result of this paper is to identify a sufficient and necessary condition under which a set of independent malleable tasks could be all completed by their deadlines on  machines, also referred to as boundary condition in this paper.







In particular, by understanding the basic constraints of malleable tasks, we first identify and formally define a state in which  machines can be said to be optimally utilized by a set of tasks with deadlines in terms of resource utilization. Then, we propose an optimal scheduling algorithm LDF() (Latest Deadline First) that achieves such an optimal state. The LDF() algorithm has a polynomial time complexity of  and is different from the EDF algorithm that gives an optimal schedule in the single-machine case. Here, the maximum deadline of tasks is assumed to be finitely bounded by a constant.


\vspace{0.22em}\noindent\textbf{Applications} (Sections~\ref{more-application} and~\ref{more-app-2}). The above core results have several applications to propose new or improved algorithmic design and analysis for scheduling malleable tasks under different objectives. The scheduling objectives considered in this paper include:
\begin{enumerate}
\item [(a)] \textit{social welfare maximization:} maximize the sum of values of tasks completed by their deadlines;

\item [(b)] \textit{machine minimization:} minimize the number of machines needed to produce a feasible schedule for a set of tasks such that each task is completed by their deadline;

\item [(c)] \textit{maximum weighted completion time minimization:} minimize the maximum weighted completion time of tasks.
\end{enumerate}
Here, the first and second objectives above have been considered in \cite{Jain11a,Jain,Nagarajan}. The second objective that concerns the optimal utilization of machines has been considered for other types of tasks \cite{Chuzhoy04a} but we are the first to consider it for malleable tasks. After applying the core results above, we obtain the following algorithmic results:
\begin{itemize}
\item [(\rmnum{1})] an improved greedy algorithm GreedyRLM with a performance guarantee  for social welfare maximization with a time complexity of ;
\item [(\rmnum{2})] the first exact dynamic programming algorithm for social welfare maximization with a pseudo-polyno- mial time complexity of  , where  is the number of deadlines,  and  are the maximum workload and deadline of tasks;
\item [(\rmnum{3})] the first exact algorithm for machine minimization with a time complexity of ;
\item [(\rmnum{4})] a polynomial time (1+)-approximation algorithm for maximum weighted completion time minimization.
\end{itemize}


In the greedy algorithm of \cite{Jain}, the tasks are considered in the non-decreasing order of their marginal values of tasks (i.e., the ratio of a task's value to its size), and only if a task could be fully completed by its deadline according to the currently remaining resource, it will be accepted and allocated possibly different number of machines over time according to an allocation algorithm; otherwise, it will be rejected. In this paper, we also show that
\begin{itemize}
\item for social welfare maximization,  is the best possible performance guarantee that a class of greedy algorithms could achieve where they consider tasks in the non-increasing order of their marginal values.
\item as a result, the proposed greedy algorithm of this paper is the best possible among this kind of greedy algorithms.
\end{itemize}






The second algorithm for social welfare maximization can work efficiently when  is small since its time complexity is exponential in . However, this may be reasonable in a machine scheduling context. In scenarios like \cite{Bodik}, tasks are often scheduled periodically, e.g., on an hourly or daily basis, and many tasks have a relatively soft deadline (e.g., finishing after four hours instead of three will not trigger a financial penalty). Then, the scheduler can negotiate with the tasks and select an appropriate set of deadlines , thereafter rounding the deadline of a task down to the closest  (). By reducing , this could permit to use the dynamic programming (DP) algorithm rather than GreedyRLM in the case where the slackness  is close to 1. With  close to 1, the approximation ratio of GreedyRLM approaches 0 and possibly little social welfare is obtained by adopting GreedyRLM while the DP algorithm can still obtain the almost optimal social welfare.



\vspace{0.22em}\noindent\textbf{Technical Difference.} The second algorithm can be viewed as an extension of the pseudo-polynomial time exact algorithm in the single machine case \cite{Lawler91} that is also designed via the generic dynamic programming procedure. However, before our work, how to enable this extension to malleable tasks was not clear as indicated in \cite{Jain11a,Jain}. This is mainly due to the lack of a notion of the optimal state of machines being utilized by malleable tasks with deadlines and the lack of an algorithm that achieves such a state. In contrast, the optimal state in the single machine case can be defined much more easily and achieved by the EDF algorithm. The core results of this paper are the enabler of a DP algorithm.





The way of applying the core results to a greedy algorithm is less obvious since in the single machine case there is no corresponding algorithm to hint its role in the algorithmic design. For the above class of greedy algorithms, we manage to give a new algorithm analysis, figuring out what resource allocation features of tasks can benefit and determine the algorithm's performance. This analysis is an extended analysis of the greedy algorithm for the standard knapsack problem \cite{Brassard} and it does not rely on the dual-fitting technique, on which the algorithm in \cite{Jain} is built.
Here, the problem could be viewed as an extension of the knapsack problem where each item has two additional constraints in a two-dimensional space: a (time) window in which an item could be placed and a maximum width of the space that it could utilize at every moment. Two of the most important algorithms there are either based on the DP technique or of greedy type, that also considers items by their marginal values \cite{Brassard}; we give in this paper their counterparts in the scenario of malleable tasks.


In the construction of the greedy and optimal scheduling algorithms, we are inspired by the algorithm in \cite{Jain}. After our definition of the optimal state and a new analysis of the above class of greedy algorithms, we found that the algorithm in \cite{Jain} could achieve an optimal resource utilization state from the maximum deadline of tasks  to some earlier time slot . However, this is achieved by guaranteeing the existence of a time slot  earlier than  such that the number of available machines at  is , which leads a suboptimal utilization of resources. In our algorithm, we only require  to be such that the number of available machines at  is , which leads to an optimal resource utilization. More details could be found in the remarks of Section~\ref{sec.scheduling}.


The above third and fourth algorithms are obtained by respectively applying the above core result to a binary search procedure, and the related results in \cite{Nagarajan}.













\subsection{Related works}
\label{sec.related-work}



Now, we introduce the related works.
The linear programming approaches to designing and analyzing algorithms for the task model of this paper \cite{Jain11a,Jain} and its variants \cite{Lucier,Bodik,Azar} have been well studied\footnote{We refer readers to \cite{Karger,Williamson} for more details on the general techniques to design scheduling algorithms.}. All these works consider the same objective of maximizing the social welfare. In \cite{Jain11a}, Jain {\em et al.} proposed an algorithm with an approximation ratio of  via {\em deterministic rounding of linear programming}. Subsequently, Jain {\em et al.} \cite{Jain} proposed a greedy algorithm GreedyRTL and used the {\em dual-fitting technique} to derive an approximation ratio .
In \cite{Bodik}, Bodik {\em et al.} considered an extension of our task model, i.e., DAG-structured malleable tasks, and, based on {\em randomized rounding of linear programming}, they proposed an algorithm with an expected approximation ratio of  for every , where . The online version of our task model is considered in \cite{Lucier,Azar}; again based on the {\em dual-fitting technique}, two weighted greedy algorithms are proposed respectively for non-committed and committed scheduling and achieve the competitive ratios of  where  \cite{Jain} and  where  and .



In addition, Nagarajan {\em et al.} \cite{Nagarajan} considered DAG-structured malleable tasks and propose two algorithms with approximation ratios of 6 and 2 respectively for the objectives of minimizing the total weighted completion time and the maximum weighted lateness of tasks. Nagarajan {\em et al.} showed that {\em optimally scheduling deadline-sensitive malleable tasks in terms of resource utilization is a key to the solutions to scheduling for their objectives.} In particular, seeking a schedule for DAG tasks can be transformed into seeking a schedule for tasks with simpler chain-precedence constraints; then whenever there is a feasible schedule to complete a set of tasks by their deadlines, Nagarajan {\em et al.} proposed a non-optimal algorithm where each task is completed by at most 2 times its deadline and give two procedures to obtain near-optimal completion times of tasks in terms of the above two objectives.






Technically, the works \cite{Jain11a,Jain,Lucier,Bodik,Azar} formulate their problem as an Integer Program (IP) and relax the IP to a relaxed linear program (LP). The techniques in \cite{Jain11a,Bodik} require to solve the LP to obtain a fractional optimal solution and then manage to round the fractional solution to an integer solution of the IP that corresponds to an approximate solution to their original problem. In \cite{Jain,Lucier,Azar}, the dual fitting technique first finds the dual of the LP and then construct a feasible algorithmic solution  to the dual in some greedy way. This solution corresponds to a feasible solution  to their original problems, and, due to the weak duality, the value of the dual under the solution  (expressed in the form of the value under  multiplied by a parameter ) will be an upper bound of the optimal value of the IP, i.e., the optimal value that can be achieved in the original problem. Therefore, the approximation ratio of the algorithm involved in the dual becomes clearly  . Here, the approximation ratio is a lower bound of the ratio of the actual value obtained by the algorithm to the optimal value.





A part of results of this paper appeared at the Allerton conference in the year 2015 \cite{Wu15a,Wu15b}. Following \cite{Wu15a,Wu15b}, a recent work also gave a similar (sufficient and necessary) feasibility condition to determine whether a set of malleable tasks could be completed by their deadlines and showed that such a condition is central to the application of the LP technique to the three problems of this paper: greedy and exact algorithms for social welfare maximization and an exact algorithm for machine minimization. Guo \& Shen first used the LP technique to give a new proof of this feasibility condition in the core result. Based on this condition, the authors gave a new formulation of the original problems as IP programs, different from the ones in \cite{Jain11a,Jain}. This new formulation enables from a different perspective proposing almost the same algorithmic results as this paper, e.g., for the machine minimization problem an exact algorithm with a time complexity , and for the social welfare maximization problem an exact algorithm with a complexity , where  is the length of the LP's input. In addition, we have shown that the best performance guarantee is  when a greedy algorithm considers tasks in the non-increasing order of their marginal values. Guo \& Shen also considered another standard to determine the order of tasks, and proposed a greedy algorithm with a performance guarantee  and a complexity .






















































\section{Model and Problem Description}
\label{sec.model}





\begin{table}
\centering
\begin{threeparttable}[!ht]

\caption{Main Notation}
\begin{tabular}{|C{1.5cm}|C{6.2cm}|}
\hline

   Notation & Explanation\\ \hline

 & the total number of machines \\ \hline

 & a set of tasks to be scheduled on  machines \\ \hline

 & a task in  \\ \hline

 & the workload, deadline, and value of a task  \\ \hline

 & the parallelism bound of , i.e., the maximum number of machines that can be allocated to and utilized by  simultaneously \\ \hline

 & the number of machines allocated to  at a time slot  where  and set all  to  initially \\ \hline

 & the total number of machines that are allocated out to the tasks at , i.e.,  \\ \hline

 &  the total number of machines idle at , i,e.,  \\ \hline


 & the minimum execution time of  where  is allocated  machines in the entire execution process, i.e., \\ \hline

 & the slackness of a task, i.e., , measuring the urgency of machine allocation to complete  by the deadline \\ \hline

  &  the minimum slackness of all tasks of , i.e.,  \\ \hline

,  & the maximum deadline and workload of all tasks of , i.e.,  and  \\ \hline

 & the marginal value of , i.e.,  \\ \hline

 & the set of the deadlines  of all tasks  of , where  \\ \hline

 & all the tasks  of  that have a deadline ,  \\ \hline

\end{tabular}
\label{table-1}
 \end{threeparttable}
\end{table}







There are  identical machines and a set of  tasks . The task  is specified by several characteristics: (1) {\em value} , (2) {\em demand} (or {\em workload}) , (3) {\em deadline} , and (4) {\em parallelism bound} . Time is discrete and the time horizon is divided into  time slots: , where  and the length of each slot may be a fixed number of minutes. A task  can only utilize the machines located in time slot interval . The parallelism bound  limits that, at any time slot ,  can be executed on at most  machines simultaneously. Let  be the maximum parallelism bound; here,  is a system parameter and  is therefore assumed to be finite \cite{White}. An {\em allocation} of machines to a task  is a function , where  is the number of machines allocated to task  at a time slot . In this model,  for all .

For the system of  machines, denote by  the system's workload at time slot ; and by  its complementary, i.e., the amount of available machines at time . We say that time  is {\em fully utilized} if , and is {\em not fully utilized} if . In addition, we assume that the maximum deadline of tasks is bounded. Given the model above, the following three scheduling objectives are considered separately in this paper:
\begin{itemize}
  \setlength\itemsep{0.17em}
\item \textit{The first objective} is social welfare maximization and it aims to choose an a subset  and produce a feasible schedule for  so as to maximize the social welfare  (i.e., the sum of values of tasks completed by deadlines); here, the value  of a task  is gained if and only if it is {\em fully allocated} by the deadline, i.e., , and partial execution of a task yields no value.
\item \textit{The second objective} is machine minimization, i.e., seeking the minimum number of machines needed to produce {\em a feasible schedule} of  on  machines such that the task's parallelism bound and deadline constraints are not violated.
\item \textit{The third objective} is to minimize the maximum weighted lateness of tasks, i.e., , where  is the completion time of a task .
\end{itemize}
Furthermore, we denote by  and  the sets  and  for a positive integer . Let  denote the {\em minimum execution time} of . Define by  the slackness of , measuring the urgency of machine allocation (e.g.,  may mean that  should be allocated the maximum amount of machines  at every ) and let  be the slackness of the least flexible task (). Denote by  the {\em marginal value} of task , i.e., the value obtained by the system {\em per unit of demand}. We assume that the demand of each task is an integer. Let  be the demand of the largest task. Given a set of tasks , the deadlines  of all tasks  constitute a finite set , where , , and . Let  denote the set of tasks with deadline , where  ().

The notation of this section is used in the entire paper and summarized in Table~\ref{table-1}. Throughout this paper, we use , , , , or  as subscripts to index the element of different sets such as tasks and use  or  to index a time slot.



\section{Optimal Schedule}
\label{sec.optimal}

In this section, we identify a state under which  machines can be said to be optimally utilized by a set of tasks. We then propose a scheduling algorithm that achieves such an optimal state. Besides Table~\ref{table-1}, the additional notation to be used in this section is summarized in Table~\ref{table-2}. 







\subsection{Optimal Resource Utilization State}
\label{sec.optimal-utilization}


In this paper, all tasks are denoted by a set , and we denote by  an arbitrary subset of ; all tasks of  with a deadline  are denoted by  and we denote by  all tasks of  with a deadline  (). In this subsection, we define the maximum amount of workload of  that could be processed in a fixed time interval  on  machines for all , where , i.e., the maximum deadline of tasks.















\begin{figure}[!ht]\centering

\includegraphics[width=3.2in]{maximum-000.png}

  \caption{The green areas denote the maximum demand of  that need or could be processed in .}\label{Fig.1}
\end{figure}





We first define {\em the maximum amount of resource, denoted by , that could be utilized by  in  in an idealized case} where there is an indefinite number of machines, i.e., , for all . To define this, we clarify the maximum amount of resource that an individual task  can utilize in . The basic constraints of malleable tasks with deadlines imply that:
\begin{itemize}
\item the deadline of  limits that  can only utilize the machines in , and

\item the parallelism bound limits that  can only utilize at most  machines simultaneously at every time slot.
\end{itemize}
The tasks with  cannot be executed in the interval . Let us consider a task  with . The number of time slots available in  is  in the discrete case, and, also recall that  the (minimum) execution time of  when it always utilizes the maximum number  of machines throughout the execution. In the illustrative Fig.~\ref{Fig.1}, the green area in the left (resp. right) subfigure denotes the maximum demand of a task, i.e.,  (resp. ), that could or need be processed in  in the case where the minimum execution time is such that  (resp. ).

As a consequence of the observation above,  equals the sum of the maximum workload of every task in  that could executed in  and is defined as follows.
\begin{definition}\label{Def-1}
Initially, set  to zero for all . In the case where  (i.e., the capacity constraint is ignored), for all ,  is defined as follows:
\begin{center}
, for every task ,
\end{center}
where  is such that
\begin{itemize}
  \setlength\itemsep{0.2em}


\item if  where , ;

\item if  where , as illustrated in Figure~\ref{Fig.1},

\begin{itemize}
  \setlength\itemsep{0.25em}
\item in the case that , ;

\item otherwise, .
\end{itemize}
\end{itemize}
Here,  represents the maximum workload of a task  that could be executed in .
\end{definition}






Built on Definition~\ref{Def-1}, we move to the case where  is finite and define the maximum amount of resource  that can be utilized by  on  machines in every , .





\begin{figure}[!ht]\centering

\includegraphics[width=3.45in]{derivation.png}

  \caption{Derivation from the definition  to .}\label{Fig.2}
\end{figure}




To help readers grasp the underlying intuition in the process of deriving  from , we first illustrate this process in the case where  with the help of Fig.~\ref{Fig.2}. Fig.~\ref{Fig.2} (left) illustrates the parameter  in Definition~\ref{Def-1}, where the green area denotes  and the green and blue areas together denote . As illustrated in Fig.~\ref{Fig.2} (right), due to the capacity constraint that  is finite, we have that
\begin{enumerate}
\item [\textbf{(\rmnum{1})}]  is the maximum possible workload that could be processed in  due to the capacity constraint, and  is the maximum available workload of  that needs to be processed in  due to the deadline and parallelism constraints. As a result, on  machines, the maximum workload  of  that can be processed in  is the size of the green area in , i.e.,
    

\item [\textbf{(\rmnum{2})}] After  workload of  has been processed in , the remaining workload of  that needs to processed in  is ; the maximum workload that could be processed in  is  due to the capacity constraint. As a result,  is defined as follows:

i.e., the size of all the colored areas in .
\end{enumerate}
Generalizing the above process, we derived a recursive definition of .


\begin{definition}\label{Def-2}
In the case where  is finite (i.e., with the capacity constraint), for all , the maximum amount of resource  that could be utilized by  in  is defined by the following recursive procedure:
\begin{itemize}
  \setlength\itemsep{0.3em}
\item set  to zero trivially;
\item set  to the sum of  and \\
.
\end{itemize}
\end{definition}











We finally state our definition that formalizes the concept of optimal utilization of  machines by a set  of malleable tasks with deadlines:


\begin{definition}[Optimal Resource Utilization State]\label{Def-3}
We say that  machines are optimally utilized by a set of tasks , if, for all ,  utilizes  resources in  on  machines.
\end{definition}


We define  as the remaining (minimum) workload of  that needs to be processed after  has maximally utilized  machines in  for all .



\begin{lemma}[Boundary Condition]\label{boundary-condition}
If there exists a feasible schedule for ,  the following inequality holds for all :
\begin{center}
,
\end{center}
which is referred to as \textbf{{\em boundary condition}} in this paper.
\end{lemma}
\begin{proof}Recall the definition of  in Definition~\ref{Def-2}. After  has maximally utilized the machines in  and been allocated the maximum amount of resource, i.e., , if there exists a feasible schedule for , the total amount of the remaining demands of  to be processed should be no more than the capacity  in .
\end{proof}





\begin{table}
\centering
\begin{threeparttable}[!ht]

\caption{Main Notation for the algorithms LDF(), Fully-Utilize(), Fully-Allocate(), and AllocateRLM(, , )}

\begin{tabular}{|C{1.2cm}|C{6.2cm}|}
\hline
   Notation & Explanation\\
\hline

 & a set of tasks to be allocated by LDF() and  \\ \hline

 & the tasks of  with a deadline   \\ \hline

 & the maximum amount of resource that could be utilized by  in  in an idealized case where there is an indefinite number of machines,    \\ \hline

  & the maximum amount of resource that can be utilized by  on  machines in every ,   \\ \hline

  &  the remaining workload of  that needs to be processed after  has optimally utilized  machines in , i.e., ,   \\ \hline

 & a task that is being allocated by the algorithm LDF(); the actual allocation is done by Allocate-B() \\ \hline

 & so far, all tasks that have been fully allocated by LDF() and are considered before   \\ \hline

 &   \\ \hline

 & a turning point defined in Property~\ref{proper-2}, with time slots respectively later than and no later than  having different resource utilization state  \\ \hline

 & similar to , a turning point defined in Lemma~\ref{lemma-fully-utilize} upon completion of Fully-Utilize()  \\ \hline

 & similar to , a turning point defined in Lemma~\ref{lemma-allocate} upon completion of Fully-Allocate()  \\ \hline

 & the latest time slot in  with   \\ \hline


,  & a time slot that satisfies some property defined and only used in Section~\ref{sec.phase-2}  \\ \hline

\end{tabular}
\label{table-2}
 \end{threeparttable}
\end{table}









\subsection{Scheduling Algorithm}
\label{sec.scheduling}


In this section, we assume that  satisfies the boundary condition above, and, propose an algorithm LDF() that achieves the optimal resource utilization state, producing a feasible schedule for .

\subsubsection{Overview of LDF()}
\label{sec.overview}






\begin{figure*}\centering
  \includegraphics[width=2.2in]{phase-11.png}\includegraphics[width=2.05in]{phase-22.png}
  \includegraphics[width=2.2in]{phase-33.png}

  \caption{The resource allocation state of  and the previous tasks  respectively upon completion of Fully-Utilize(), Fully-Allocate(), and AllocateRLM(, , ) where : the blue area in the rectangle denotes the allocation to the previous tasks that satisfies Property~\ref{proper-1} and Property~\ref{proper-2} before executing Allocate-B() while the green area in the interval  denotes the allocation to  at every time slot.}\label{Fig.5}
\end{figure*}








Initially, for all  and , we set the allocation  to zero and LDF() runs as follows:
\begin{enumerate}
 \setlength\itemsep{0.15em}
  \item the tasks in  are considered in the non-increasing order of the deadlines, i.e., in the order of , , , ;

  \item for a task  being considered, the algorithm Allocate-B(), presented as Algorithm~\ref{Allocate-B}, is called to allocate  resource to  under the constraints of deadline and parallelism bound.
\end{enumerate}

At a high level, we show in the following that, only if  satisfies the boundary condition and the resource utilization satisfies some properties upon every completion of Allocate-B(), all tasks in  will be fully allocated.

Now, we begin to elaborate this high-level idea. In LDF(), when a task  is being considered, suppose that the allocated task  belongs to  and denote by  the tasks that have been fully allocated so far and are considered before . Here,  satisfies the boundary condition and so do all its subsets including  and .  Before the execution of Allocate-B(), we assume that the resource utilization satisfies the following two properties:



Recall the optimal resource utilization state in Definitions~\ref{Def-3}, and the first property is that such an optimal resource utilization state of  machines is achieved by the current allocation to .
\begin{property}\label{proper-1}
For all ,  is allocated  resource in  where  is defined in Definition~\ref{Def-2}.
\end{property}


The second property is that a stepped-shape resource utilization state is achieved in  by the current allocation to .
\begin{property}\label{proper-2}
If there exists a time slot  such that , let  be the latest slot in  such that ; then we have .
\end{property}

If Property~\ref{proper-1} and Property~\ref{proper-2} hold, we will show in Section~\ref{sec.phase-1} and \ref{sec.phase-2} that, there exists an algorithm Allocate-B() such that, upon completion of Allocate-B(), the following two properties are satisfied:

\begin{property}\label{proper-3}
 is fully allocated.
\end{property}

\begin{property}\label{proper-4}
The resource allocation to  still satisfies Property~\ref{proper-1} and Property~\ref{proper-2}.
\end{property}
Due to the existence of the above Allocate-B(), only if  satisfies the boundary condition,  can be fully allocated by LDF(). The reason for this can be explained by induction. When the first task  in  is considered,  is empty, and, before the execution of Allocate-B(), Property~\ref{proper-1} and Property~\ref{proper-2} holds trivially. Further, upon completion of Allocate-B(),  will be fully allocated by Allocate-B() due to Property~\ref{proper-3}, and Property~\ref{proper-4} still holds. Then, assume that  that denotes the current fully allocated tasks is nonempty and Property~\ref{proper-1} and Property~\ref{proper-2} hold; the task  being considered by LDF() will still be fully allocated and Property~\ref{proper-3} and Property~\ref{proper-4}, upon completion of Allocate-B(). Hence, all tasks in  will be finally fully allocated upon completion of LDF().



In the rest of this subsection, we will propose an algorithm Allocate-B() mentioned above such that, upon completion of Allocate-B(), Property~\ref{proper-3} and Property~\ref{proper-4} holds, {\em if}, before the execution of Allocate-B(), the resource allocation to  satisfies Property~\ref{proper-1} and Property~\ref{proper-2} hold. Then, we immediately have the following proposition:
\begin{proposition}\label{property-task}
If  satisfies the boundary condition, LDF() will produce a feasible schedule of  on  machines.
\end{proposition}




\vspace{0.05em}\noindent\textbf{Overview of Allocate-B().} The construction of Allocate-B() will proceed with two phases. In the first phase, we introduce what operations are feasible to make  fully allocated  resource under Property~\ref{proper-1} and Property~\ref{proper-2}. We will use two algorithms Fully-Utilize() and Fully-Allocate() to describe them, and the sketch of this phase is as follows:
\begin{itemize}
 \setlength\itemsep{0.2em}

\item From the deadline  towards earlier time slots, Fully-Utilize() makes  fully utilize the maximum amount of machines available at every slot. Upon its completion, the resource allocation state is illustrated in Fig.~\ref{Fig.5} (left) and will be described in Lemma~\ref{lemma-fully-utilize}.

\item If  is not fully allocated yet, as illustrated in Fig.~\ref{Fig.5} (middle), Fully-Allocate() transfers the allocation of the previous tasks  at the time slots closest to  to the latest slots in  that have idle machines, so that,  machines are finally allocated to  at each of these slots closest to ; as a result,  is fully allocated.


\end{itemize}
Upon completion of Fully-Allocate(), the resource allocation state may not satisfy Property~\ref{proper-1} and Property~\ref{proper-2}, as illustrated by Fig.~\ref{Fig.5} (middle). We therefore propose an algorithm AllocateRLM(, , ) in the second phase:
\begin{itemize}
\item the allocation of the previous tasks at every slot  closest to the deadline is again transferred to the latest slots that have idle machines, and, the allocation of  in the earliest slots is transferred to ; the final resource allocation state is illustrated in Fig.~\ref{Fig.5} (right).
\end{itemize}


Following the above high-level ideas, the details of the first and second phases are respectively presented in Section~\ref{sec.phase-1} and Section~\ref{sec.phase-2}.





\subsubsection{Phase 1}
\label{sec.phase-1}










Now, we introduce Fully-Utilize() and Fully-Allocate() formally. Before their execution, recall that we assume in the last subsection ; the allocation to the previously allocated tasks in  satisfies Properties~\ref{proper-1} and~\ref{proper-2}. The whole set of tasks  to be scheduled satisfies the boundary condition where .


Initially, set  to zero for all time slots, and, \textbf{Fully-Utilize()} operates as follows:\begin{itemize}
\item for every time slot  from the deadline  to 1, set .
\end{itemize}
Here,  is the parallelism bound,  is the remaining workload to be processed upon completion of its allocations at slots , and  is the number of machines idle at ; specially,  is set to 0, representing the allocation to  is zero before the allocation begins. Their minimum denotes the maximum amount of machines that  can or needs to utilize at  after the allocation to  at slots .


Before executing Fully-Utilize(), the resource allocation to the previous tasks  satisfies Property~\ref{proper-1}. Its execution does not change the previous allocation to . Let
\begin{center}
.
\end{center}
Since , the workload of  can only be processed in ; the maximum workload of  that could be processed in  still equals its counterpart when  is considered. We come to the following conclusion in order to not violate the boundary condition:






\begin{lemma}\label{exit-condition-1}
Upon completion of Fully-Utilize(), all tasks of  would have been fully allocated {\em in the case that} the total allocation to  in  is , i.e., .
\end{lemma}
\begin{proof}
See the appendix for detailed proof.
\end{proof}










Upon completion of Fully-Utilize(), {\em in the other case that} the total allocation to  is , even for , it may not be fully allocated. In this case, there exists a slot  such that , and let  denote the latest such time slot in .


In Fully-Utilize(), upon completion of the allocation to  at , if  has not been fully allocated yet, it is allocated  machines at , i.e., , and these allocations in  are non-decreasing, i.e.,
\begin{center}
.
\end{center}
Before executing Fully-Utilize(), the numbers of idle machines have a stepped shape, i.e.,  by Property~\ref{proper-2}, where . Upon its completion, with  machines occupied by , we conclude that





\begin{lemma}\label{lemma-fully-utilize}
Upon completion of Fully-Utilize(), in the case that the total allocation to  is ,
\begin{itemize}
 \setlength\itemsep{0.3em}
  \item for all , if the total allocation of  in  is  the workload of , i.e.,  , we have ;

  \item the numbers of idle/unallocated machines in  have a stepped shape, i.e., .
\end{itemize}
\end{lemma}












With the current resource allocation state shown in Lemma~\ref{lemma-fully-utilize}, we are enabled to propose the algorithm Fully-Allocate() to make  fully allocated. Deducting the current resource allocated to , let  denote the remaining workload of  to be allocated more resource, i.e.,
\begin{center}
.
\end{center}
For every slot , the number  of machines allocated to  at  is  in the case that  by Lemma~\ref{lemma-fully-utilize}. The total workload  is , and, with the parallelism bound, \textbf{Fully-Allocate}() considers each slot  from  towards  and operates as follows repeatedly at each  until :
\begin{enumerate}
 \setlength\itemsep{0.3em}

  \item   .

          \setlength{\parindent}{1em}\vspace{0.15em}{\em Notes.}  is the maximum number of additional machines that could be utilized at  with its previous allocation . 

  \item Call Routine(, 1, 0, ), presented as Algorithm~\ref{Routine}.

        \setlength{\parindent}{1em}\vspace{0.15em}{\em Notes.} Routine() aims to increase the number of available machines  at  to  by transferring the allocation of other tasks to an earlier time slot.

  \item Allocate  more machines to  at : , and, .

      \setlength{\parindent}{1em}\vspace{0.15em}{\em Notes.}  denotes the currently remaining workload to be processed; in this iteration, if  currently,  and the allocation  of  at  becomes .

  \item .
\end{enumerate}


\begin{algorithm}[!ht]\SetKwInOut{Begin}{Begin}
\SetKwInOut{Input}{Input}





  \While{}{


      the current time slot earlier than and closest to  so that \;

    \If{}{
      \If{there exists no such }{
        , break\;
}
    }
    \Else{
      \If{, or there exists no such }{
        , break\;
}
    }
	
	\If{}{
        \If{}{
           , break\;
}
	}

		
	let  be a task such that \;

    , \;

 }
\caption{Routine(, , , )\label{Routine}}
\end{algorithm}






Now, we explain the existence of  in line 12 of Routine() and the reason why  will be finally fully allocated by Fully-Allocate(). The only operation that changes the allocation to  occurs at the third step of Fully-Allocate(). Hence, we have
\begin{lemma}\label{lemma-decrease}
Fully-Allocate() never decreases the allocation  to  at any time slot  during its execution, compared with the  just before executing Fully-Allocate().
\end{lemma}



We could also prove by contradiction that
\begin{lemma}\label{lemma-existence}
When Routine(, 1, 0, ) is called, the task  in line 12 always exists if (\rmnum{1}) the condition in line 4 is false, (\rmnum{2}) , and (\rmnum{3})  and .
\end{lemma}
\begin{proof}
See the Appendix for the detailed proof.
\end{proof}



At each iteration of Fully-Allocate(), if there exists a  such that  in the loop of Routine(), with Lemmas~\ref{lemma-fully-utilize} and~\ref{lemma-decrease}, we have . Since  and , when Routine() is called, we have ; otherwise, this contradicts Lemma~\ref{lemma-fully-utilize}. With Lemma~\ref{lemma-existence}, we will conclude that the task  in line 11 exists when it is called by Fully-Allocate(). In addition, the operation at line 12 of Routine() does not change the total allocation to , and violate the parallelism bound  of  since the current  is no more than the initial .

\begin{proposition}\label{proposi-fully-allocate}
Upon completion of Fully-Allocate(), the task  is fully allocated.
\end{proposition}
\begin{proof}
Fully-Allocate() ends up with one of the following three events. The first is that the condition in line 4 of Routine() is true. Then, with Lemma~\ref{exit-condition-1}, all tasks in  has been fully allocated. If the first event doesn't happen, the second is  and  has been fully allocated. If the first and second events don't happen, the third occurs after finishing the iteration of Fully-Allocate() at time slot ; then, there is a slot  in  that are not fully utilized. As a result, we have that  has been fully allocated; otherwise, , which implies , and we have  for all  due to Lemma~\ref{lemma-fully-utilize}, which contradicts . Finally, the theorem holds.
\end{proof}



Upon completion of Fully-Utilize(), the resource allocation feature is described in Lemma~\ref{lemma-fully-utilize} and illustrated in Fig.~\ref{Fig.5} (left). Built on this, Fully-Allocate() considers every slot from  to ; as illustrated in Fig.~\ref{Fig.5} (middle) and roughly explained there, upon completion of Fully-Allocate(), the resource allocation feature is described as follows.



\begin{lemma}\label{lemma-allocate}
Upon completion of Fully-Allocate(), if there exists a  such that , let  be the latest such slot:
\begin{itemize}
 \setlength\itemsep{0.2em}

  \item for all , if the total allocation of  in  is  (i.e., ), we have ;

  \item the numbers of available machines in  have a stepped shape, i.e, .
\end{itemize}
Here .
\end{lemma}
\begin{proof}
See the Appendix for the formal proof.
\end{proof}





\subsubsection{Phase 2}
\label{sec.phase-2}




Now, we introduce AllocateRLM(, , ). Recall that  always denotes the slot closest to but earlier than  (i.e., the latest slot in ) such that  and, before executing AllocateRLM(),  due to Lemma~\ref{lemma-allocate}. The resource allocation feature before executing AllocateRLM(, , ) is described in Lemma~\ref{lemma-allocate} and illustrated in Fig.~\ref{Fig.5} (middle); the underlying intuition of AllocateRLM(, , ) is described in Section~\ref{sec.overview} and, upon its completion, the resource allocation feature is illustrated in Fig.~\ref{Fig.5} (right).


Formally, \textbf{AllocateRLM(, , )} considers each slot  from  to  and operates as follows repeatedly at each  until the total allocation of  in , i.e., , equals zero, where  and  in this section:
\begin{enumerate}
 \setlength\itemsep{0.1em}

  \item  .

        \setlength{\parindent}{1em}\vspace{0.01em}{\em Notes.}  denotes the maximum allocation of  before  that can be transferred to  with the parallelism constraint.

  \item if , go to the step 5; otherwise, execute the steps 3-5.

  \item set  and call Routine(, , 1, ).

      \setlength{\parindent}{1em}\vspace{0.01em}{\em Notes.} Routine() aims to increase the number  of available machines at  to . With Lemma~\ref{lemma-allocate}, the slots  earlier than but closest to  in Routine() will become fully utilized one by one and, together with the next step 4, upon completion of the iteration at , for all , .


  \item set . Allocate  more machines to :
  \begin{center}
  ,
  \end{center}
   and reduce the allocations of  at the earliest slots by : in particular, let  be such a slot that  and , and execute the following operations:
      \begin{enumerate}
 \setlength\itemsep{0.15em}
        \item set , and, for every , ;
        \item .
      \end{enumerate}

      \setlength{\parindent}{1em}{\em Notes.} The number of idle machines at  becomes zero again, i.e., . The allocation  of  at every  is zero.

  \item if Routine(, , 1, ) does not change the value of , i.e., , ; otherwise, exit AllocateRLM(, , ).

\end{enumerate}
Here, at each slot , when Routine() is called, , and . Further, we have ; otherwise, this contradicts Lemma~\ref{lemma-allocate}. Hence, with Lemma~\ref{lemma-existence}, we conclude that the task  in line 12 of Routine() exists.

Based on our notes in the description of AllocateRLM(), we conclude that
\begin{proposition}\label{theo-structure}
Upon completion of AllocateRLM(, 1, ) where , the final allocation to  can guarantee that Property~\ref{proper-4} holds where .
\end{proposition}
\begin{proof}
Fully-Utilize(), Fully-Allocate() and AllocateRLM(, , ) never change the allocation at any slot in . AllocateRLM(, 1, ) ends up with one of the following four events. The first event occurs when the condition in line 4 of Routine() is true; then, the proposition holds trivially since all the slots  have been fully utilized, i.e., . If the first event doesn't occur, the second event is that, for the first time, at some , ; then, we have that,  is fully allocated  resource in . The third event occurs when the condition in line 10 of Routine() is true. In the following, we will analyze the resource utilization state when either of the second and third events occurs.

Recall that  is defined in line 2 of Routine() where each slot in  will be fully utilized; when the second or third event occurs, all the slots in  are fully utilized, i.e., , for all . Upon completion of the iteration of AllocateRLM() at  when the third event occurs, or, at  when the second event occurs, we have the following three points, in contrast to the allocation achieved just before executing Allocate-B(),
\begin{enumerate}
 \setlength\itemsep{0.1em}
\item [(\rmnum{1})]  and the allocation to the previous tasks  at every  is still the allocation achieved before executing Allocate-B();

\item [(\rmnum{2})] , i.e., the allocation to  in  is zero and  is fully allocated  resource in ;

\item [(\rmnum{3})] the allocation to  at  is not decreased;

\item [(\rmnum{4})] the allocation to  at  does not change.
\end{enumerate}
Noticing the above resource allocation state in  where , since Property~\ref{proper-2} holds before executing Allocate-B(), we conclude that Property~\ref{proper-2} still holds upon its completion where . Without loss of generality, assume that  for some . Then, all the slots in  have been fully utilized and the allocation in  does not change at all; hence, we have that every interval , where , is optimally utilized by  due to Property~\ref{proper-1}. Since the total allocation to  in  isn't changed by Allocate-B() if , due to Property~\ref{proper-1}, the interval  is still optimally utilized by  and the task  is fully allocated  resource in this interval; hence, it is still optimally utilized by . Further, every interval  is also optimally utilized where . Hence, the theorem holds.


If the first three events don't occur, the fourth event occurs upon completion of the iteration of AllocateRLM() at , i.e., the last iteration. In this case, we have that the conditions in lines 4 and 10 of Routine() are always false where at each iteration of AllocateRLM() there always exists such  (defined in line 2 of Routine() with ); due to the current resource allocation state, we conclude that, at each of the slots in ,  is allocated  machines. Upon completion of AllocateRLM(), there exists a  defined in line 2 of Routine(), and, let  denote the earliest slot at which  where ; then, similar to our conclusion in the second and third events, we have that
\begin{enumerate}
 \setlength\itemsep{0.1em}
\item [(\rmnum{1})] the first point here is the same as the first and third points in the last paragraph;
\item [(\rmnum{2})]  is fully allocated  resource in ;

\item [(\rmnum{3})] if , the allocation to  at each  does not change and  due to Lemma~\ref{lemma-allocate}, and, the allocation to  at  is greater than zero.\end{enumerate}
Similar to our analysis in the last paragraph for other events, we conclude that the proposition holds.
\end{proof}





Proposition~\ref{proposi-fully-allocate} and Proposition~\ref{theo-structure} finish to show that Allocate-B() satisfies Property~\ref{proper-3} and Property~\ref{proper-4} and hence completes the proof of Proposition~\ref{property-task}. We finally analyze the time complexity of Allocate-B().


\begin{lemma}\label{lemma-complexity}
The time complexity of Allocate-B() is .
\end{lemma}
\begin{proof}
See the Appendix for the proof.
\end{proof}




\begin{algorithm}[!ht]\SetKwInOut{Begin}{Begin}
\SetKwInOut{Input}{Input}

Fully-Utilize()\;

Fully-Allocate()\;

AllocateRLM(, 1, )\;

\caption{Allocate-B()\label{Allocate-B}}
\end{algorithm}



Since LDF() considers a total of  tasks, its complexity is  with Lemma~\ref{lemma-complexity}. Finally, we draw a main conclusion in this section from Lemma~\ref{boundary-condition} and Proposition~\ref{property-task}:

\begin{theorem}\label{main-theorem}
A set of tasks  can be feasibly scheduled and be completed by their deadlines on  machines {\em if and only if} the boundary condition holds, where the feasible schedule of  could be produced by LDF() with a time complexity .
\end{theorem}

In other words, if LDF() cannot produce a feasible schedule for  on  machines, then  cannot be successfully scheduled by any algorithm; as a result, LDF() is optimal. The relationships between the various algorithms of this paper are illustrated in Fig.~\ref{Fig.3} where GreedyRLM will be introduced in the next section. 




\begin{figure*}[!ht]
\centering

\includegraphics[width=4.3in]{function-relation-2.png}

  \caption{Relationship among Algorithms: for , the blue and green arrows denote the relations that the algorithm  calls , and, the algorithm  is executed upon completion of .}\label{Fig.3}
\end{figure*}






\vspace{0.2em}\noindent\textbf{Remarks.} We are inspired by the GreedyRTL algorithm \cite{Jain} in the construction of LDF(). In terms of the two algorithms themselves, LDF() considers tasks in the decreasing order of deadlines while the order is determined by the marginal values in GreedyRTL(). In both algorithms, the allocation to a task  is considered from  to 1 (once in GreedyRTL, and possibly three times in LDF()); to make time slots  closest to the deadline of a task  being considered fully utilized, the key operations are finding a time slot  earlier than  such that there exists a task  with  when , and transferring a part of the allocation of  at  to . In GreedyRTL(), the existence of  requires that (\rmnum{1}) the number  of available machines at  is  and (\rmnum{2})\footnote{The particular condition there is .} ; as a result, before doing any allocation to  at , the existence could be proved by contradiction. In LDF(), to achieve the optimality of resource utilization, one requirement for such existence is relaxed to be that the number of available machines at  is . The existence is guaranteed by (\rmnum{1}) first make every time slot from  to 1 fully utilized, as what Fully-Utilize() does, and (\rmnum{2}) a stepped-shape resource utilization state in  upon completion of the allocation to the last task, as described in Property~\ref{proper-2}.











\section{Applications: Part \Rmnum{1}}
\label{more-application}


In this section, we illustrate the application of the results in Section~\ref{sec.optimal} to the greedy algorithm for social welfare maximization.




In terms of the maximization problem, {\em the general form of a greedy algorithm} is as follows \cite{Brassard,Even}: it tries to build a solution by iteratively executing the following steps until no item remains to be considered in a set of items: (1) selection standard: in a greedy way, choose and consider an item that is locally optimal according to a simple criterion at the current stage; (2) feasibility condition: for the item being considered, accept it if it satisfies a certain condition such that this item constitutes a feasible solution together with the tasks that have been accepted so far under the constraints of this problem, and reject it otherwise. Here, an item that has been considered and rejected will never be considered again. The selection criterion is related to the objective function and constraints, and is usually the ratio of 'advantage' to 'cost', measuring the efficiency of an item. In the problem of this paper, the constraint comes from the capacity to hold the chosen tasks and the objective is to maximize the social welfare; therefore, the selection criterion here is the ratio of the value of a task to its demand that will refer to as the {\em marginal value} of this task.

Given the general form of greedy algorithm, we define a class GREEDY of algorithms that operate as follows:
\begin{enumerate}
  \item Considers the tasks in the non-increasing order of the marginal value; assume without loss of generality that ;
  \item Denoting by  the set of the tasks that have been accepted so far, a task  being considered is accepted and fully allocated {\em iff} there exists a feasible schedule for .
\end{enumerate}
In the following, we refer to the generic algorithm in GREEDY as {\em Greedy}.


\begin{proposition}\label{bound-greedy}
The best performance guarantee that a greedy algorithm in GREEDY can achieve is .
\end{proposition}
\begin{proof}
Let us consider a special instance: (\rmnum{1}) let , where ,  and , and ; (\rmnum{2}) for all , , ,
, and, there is a total of  such tasks, where  is small enough; (\rmnum{3}) for all , ,  and . Greedy will always fully allocate resource to the tasks in , with all the tasks in  rejected to be allocated any resource. The performance guarantee of Greedy will be no more than . Further, with , this performance guarantee approaches . In this instance,  and . When , . Hence, the proposition holds.
\end{proof}

\subsection{Notation}

Greedy will consider tasks sequentially. The first considered task will be accepted definitely and then it will use to the feasibility condition to determine whether or not to accept or reject the next task according to the current available resource and the characteristics of this task. To describe the process under which Greedy accepts or rejects tasks, we define the sets of consecutive accepted (i.e., fully allocated) and rejected tasks . Specifically, let  be the -th set of the adjacent tasks that are accepted by Greedy where  while  is the -th set of the adjacent that are rejected tasks following the set , where  for some integer .
Integer  represents the last step: in the -th step,  and  can be empty or non-empty. We also denote by  the maximum deadline of all rejected tasks of , i.e.,
\begin{center}
,
\end{center}
and by  the maximum deadline of , i.e.,
\begin{center}
.
\end{center}
While the tasks in  are being considered, we refer to Greedy as being in the -th phase. Before the execution of Greedy, we refer to it as being in the 0-th phase. Upon completion of the -th phase of Greedy, we define a {\em threshold} parameter  such that
\begin{enumerate}
 \setlength\itemsep{0.35em}
\item [(\rmnum{1})] if , set , and
\item [(\rmnum{2})] if , set  to any time slot in .
\end{enumerate}
Here,  for all . For ease of the subsequent exposition, we let  and . We also add a dummy time slot 0 but the task  can not get any resource there, that is,  forever. We also let . Besides the notation in Section~\ref{sec.model}, the additional key notation used for this section is also summarized in Table~\ref{table-3}.






\begin{table}
\centering
\begin{threeparttable}[!ht]

\caption{Main Notation for Section~\ref{more-application}}

\begin{tabular}{|C{1.1cm}|C{6.8cm}|}

\hline
   Notation & Explanation\\
\hline

   & the sets of consecutive accepted (i.e., fully allocated) and rejected tasks by Greedy where  \\ \hline



 & the maximum deadline of all rejected tasks of   \\ \hline

 & the maximum deadline of  \\ \hline

 & a threshold parameter such that (\rmnum{1}) if , set , and (\rmnum{2}) if , set  to any time slot in ; when introducing GreedyRLM, it will be set to a specific value  \\ \hline

\end{tabular}
\label{table-3}
 \end{threeparttable}
\end{table}






\subsection{A New Algorithmic Analysis}
\label{sec.algo.analysis}



We will show that as soon as the resource allocation done by Greedy satisfies some features, its performance guarantee can be deduced immediately, i.e., the main result of this subsection is Theorem~\ref{spaa}.


For all , upon completion of Greedy, we define the following two features that we want the allocation to  to satisfies:
\begin{feature}\label{utilization1}
The total allocation to  in  is at least , where .
\end{feature}

\begin{feature}\label{fully}
For each task , its maximum amount of demand that can be processed in each  is processed where , i.e.,
\begin{center}
.
\end{center}
\end{feature}


\begin{theorem}\label{spaa}
If Greedy achieves a resource allocation structure that satisfies Feature~\ref{utilization1} and Feature~\ref{fully} for all , it gives an -approximation to the optimal social welfare.
\end{theorem}






In the rest of Section~\ref{sec.algo.analysis}, we prove Theorem~\ref{spaa}; we will first provide an upper bound of the optimal social welfare.


\vspace{0.45em}\noindent\textbf{Proof Overview.} We refer to the original problem of scheduling  on  machines to maximize the social welfare as \textbf{the MSW-\Rmnum{1} problem}.


In the following, we define a relaxed version of the MSW-\Rmnum{1} problem.
Assume that  consists of a single task  whose deadline is , whose size is infinite, and whose marginal value is the largest one of the tasks in , denoted by ; here, different from the task in , we assume that there is no parallelism constraint on  whose bound is . In addition, partial execution of the task  and the tasks of  can yield linearly proportional value, e.g., if a task  is allocated  resource by its deadline, a value  will still be added to the social welfare. We refer to the problem of scheduling  on  machines as \textbf{the MSW-\Rmnum{2} problem}.



\begin{lemma}\label{lemma-upper-bound-1}
The optimal social welfare of the MSW-\Rmnum{2} problem is an upper bound of the optimal social welfare of the MSW-\Rmnum{1} problem.
\end{lemma}
\begin{proof}
See the appendix for the detailed proof.
\end{proof}


Due to Feature~\ref{utilization1}, Feature~\ref{fully}, and the fact that the marginal value of  is no larger than the ones of the tasks of , we derive the following two lemmas:

\begin{lemma}\label{lemma-upper-bound-2}
The following schedule achieves an upper bound of the optimal social welfare of the MSW-\Rmnum{2} problem, ignoring the capacity constraint:
\begin{enumerate}

\item for all tasks of , their allocation is the same as the one achieved by Greedy with Features~\ref{utilization1} and~\ref{fully} satisfied;

\item for all , execute a part of task  such that the amount of processed workload in  is .
\end{enumerate}
\end{lemma}
\begin{proof}
See the appendix for the detailed proof.
\end{proof}







\begin{lemma}\label{lemma-interval-value}
For all , the total value generated by executing the allocation to  is no larger than  times the total value generated by the allocation to  in .
\end{lemma}
\begin{proof}
See the appendix for the detailed proof.
\end{proof}

In the case that , the total value from  is no larger than  times the total value from the allocation to  in . Hence, the total value generated by the schedule in Lemma~\ref{lemma-upper-bound-2} is no larger than  times the total value generated by the allocation to all tasks of . By Lemmas~\ref{lemma-upper-bound-2} and~\ref{lemma-upper-bound-1}, Theorem~\ref{spaa} holds.









\subsection{Optimal Algorithm Design}


We now introduce the executing process of the optimal greedy algorithm GreedyRLM, presented as Algorithm~\ref{GreedyRLM}:
\begin{itemize}
 \setlength\itemsep{0.15em}
\item [(1)] considers the tasks in the non-increasing order of the marginal value.

\item [(2)] in the -th phase, for a task  being considered, if , call Allocate-A(), presented as Algorithm~\ref{Allocate-A}, where the details on Fully-Utilize() and AllocateRLM(, 0, ) can be found in Section~\ref{sec.phase-1} and Section~\ref{sec.phase-2}.

\item [(3)] if the allocation condition is not satisfied, set the threshold parameter  of the -th phase that is defined by lines 8-15 of Algorithm~\ref{GreedyRLM}.
\end{itemize}



\begin{algorithm}[!ht]\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}





\Input{ tasks with }
\Output{A feasible allocation of resources to tasks}
\BlankLine





initialize:  for all  and , , \;

sort tasks in the non-increasing order of the marginal values: \;

\;
\While{}{

  \If{}{\nllabel{forins}
    Allocate-A()\tcp*{\footnotesize{in the -th phase}}
  }
  \Else{
    \If{ has ever been accepted}{
      \tcp*{\footnotesize{in the -th phase, the allocation to  was completed; the first rejected task is }}
    }

    \While{}{\nllabel{forins}

      \;
    }\tcc{\footnotesize{the last rejected task is  and }}

    \If{}{

      \;
    }
    \Else{

      set  to time slot just before the first time slot  with  after  or to  if there is no time slot  with  in \;
    }
  }
  \;
}




\caption{GreedyRLM\label{GreedyRLM}}
\end{algorithm}





\begin{algorithm}[!ht]\SetKwInOut{Begin}{Begin}
\SetKwInOut{Input}{Input}


Fully-Utilize()\;

\If{}{
   AllocateRLM(, 0, ) where  that are defined in Section~\ref{sec.phase-1}\;
}

\caption{Allocate-A()\label{Allocate-A}}
\end{algorithm}




When the condition in line 5 of GreedyRLM is true, every accepted task can be fully allocated  resource using Fully-Utilize(). The reason for the existence of  in Routine() is the same as the reason when introducing LDF() since .




\begin{proposition}\label{proposition-GreedyRLM}
GreedyRLM gives an -approximation to the optimal social welfare with a time complexity of .
\end{proposition}






Now, we begin to prove Proposition~\ref{proposition-GreedyRLM}. The time complexity of Allocate-A() depends on AllocateRLM(). Using the time complexity analysis of AllocateRLM() in Lemma~\ref{lemma-complexity}, we get that AllocateRLM() has a time complexity of , and, the time complexity of GreedyRLM is . Due to Theorem~\ref{spaa}, in the following, we only need to prove that Features~\ref{utilization1}~and~\ref{fully} holds in GreedyRLM where , which is given in Propositions~\ref{proposition-utilization-2}~and~\ref{fully-2}.


The utilization of GreedyRLM is derived mainly by analyzing the resource allocation state when a task  cannot be fully allocated (the condition in line 5 of GreedyRLM is not satisfied), and we have that
\begin{proposition}\label{proposition-utilization-2}
Upon completion of GreedyRLM, Feature~\ref{utilization1} holds in which .
\end{proposition}\begin{proof}
See the Appendix for the detailed proof.
\end{proof}





In GreedyRLM, when a task  is accepted (lines 5 and 6), Allocate-A() is called to make it fully allocated. In Allocate-A(), Fully-Utilize() and AllocateRLM() are sequentially called; both of them consider time slots  from the deadline towards earlier ones: (\rmnum{1}) Fully-Utilize() makes  utilize the remaining (idle) machines at , and it does not change the allocations of the previous tasks; (\rmnum{2}) at every , if  does not utilize the maximum number of machines it can utilize (i.e., ), AlloacteRLM() (a) transfers the allocations of the previous allocated tasks to an earlier slot that is closest to  but not fully utilized (i.e., with idle machines), and (b) increases the allocation of  at  to the maximum (i.e., ) and, correspondingly reduce the equal allocations at the earliest slots, ensuring the total allocation to  does not exceed . Finally, upon completion of the whole execution of Allocate-A(), we have that
\begin{itemize}
\item the number of allocated machines at each slot does not decrease,
\end{itemize}
in contrast to that amount just before executing Allocate-A(). For every accepted task , upon completion of Allocate-A(), time slot  is not fully utilized by the definition of , i.e., . Further, we have that whenever Allocate-A() completes the allocation to a previous task  where ,  is also not fully utilized then. Based on this, we draw the following conclusion.


\begin{lemma}\label{structure-2}
Due to the definition of , we have for all  that
\begin{itemize}
 \setlength\itemsep{0.25em}
\item [(1)]  is optimally utilized by  upon completion of the allocation to it using Allocate-A();
\item [(2)] for the total amount of the allocations to  in the interval  just upon completion of Allocate-A(), it does not change upon completion of GreedyRLM.
\end{itemize}
\end{lemma}
\begin{proof}
We first prove the first point. Given a , for every , upon completion of Allocate-A(),  for all ; based on this, we conclude that, in the case where , either  if  or  for all  otherwise. The reason for this conclusion is similar to our analysis for the fourth event when proving Proposition~\ref{theo-structure}; here, there always exists a slot  that is not fully utilized, i.e., , leading to that the  defined in line 2 of Routine() always exists where .




Now, we prove the second point in Lemma~\ref{structure-2}. For every , we observe the subsequent execution of Allocate-A() whose input is a task in  and could conclude that,
\begin{enumerate}
 \setlength\itemsep{0.2em}

\item upon its completion, the allocations to  in  are still the ones before executing Allocate-A();

\item Allocate-A() can only change the allocations of  in the time range  where  and the total amount of allocations in  upon its completion is still the amount before its execution.
\end{enumerate}
As a result, we have that, upon completion of Allocate-A(), every subsequent execution of Allocate-A() never change the total amount of allocations of  in  for all . 

In the following, it suffices to prove the above two points. In the execution of Allocate-A(), Fully-Utilize() is first called and it does not change the allocation to the previous tasks; then, AllocateRLM(, 0, ) is called in which only Routine() (i.e., its lines 12 and 13) in the step 3 can change the allocation to the previous tasks including . In lines 12 and 13, a previous task  is found to change its allocations at  and ; here,  is defined in lines 2 and 7 of Routine() and . As a result, Allocate-A() cannot change the allocations of the previous tasks in ; for all  where , during the execution of the iteration of AllocateRLM() at , we have . Hence, the change to the allocations of the previous tasks can only happen in the interval .
\end{proof}


From the first and second points of Lemma~\ref{structure-2}, we could conclude that
\begin{proposition}\label{fully-2}
Given a ,  is optimally utilized by every task  for all .
\end{proposition}










\section{Applications: Part \Rmnum{2}}
\label{more-app-2}

In this section, we illustrate the applications of the results in Section~\ref{sec.optimal} to (\rmnum{1}) the dynamic programming technique for social welfare maximization, (\rmnum{2}) the machine minimization objective, and (\rmnum{3}) the objective of minimizing the maximum weighted completion time.


\subsection{Dynamic Programming}



For any solution, there must exist a feasible schedule for the tasks selected to be fully allocated by this solution. So, the set of tasks in an optimal solution satisfies the boundary condition by Lemma~\ref{boundary-condition}. Then, to find the optimal solution, we only need address the following problem: if we are given  machines, how can we choose a subset  of tasks in  such that (\rmnum{1}) this subset satisfies the boundary condition, and (\rmnum{2}) no other subset of selected tasks achieves a better social welfare? This problem can be solved via dynamic programming (DP). To propose a DP algorithm, we need to identify a dominant condition for the model of this paper \cite{Williamson}. Let  and recall that the notation  in Section~\ref{sec.optimal-utilization}. Now, we define a -dimensional vector
\begin{center}
,
\end{center}
where , , denotes the optimal resource that  can utilize on  machines in the segmented timescale  after  has utilized  resource in . Let  denote the total value of the tasks in  and then we introduce the notion of one pair  {\em dominating} another  if  and , that is, the solution to our problem indicated by  uses the same amount of resources as , but obtains at least as much value.




\begin{algorithm}\SetKwInOut{Begin}{Begin}
\SetKwInOut{Output}{Output}
\BlankLine
\BlankLine

\;

\;

\For{ \KwTo }{

  \;

  \For{each }{
    \If{ satisfies the boundary condition}{
      \If{there exist a pair  so that (1) , and (2) }{
        Add  to \;
        Remove the dominated pair  from \;
      }
      \Else{
        Add  to \;
      }
    }
  }
}
return \;
\caption{DP()\label{Recurrence}}
\end{algorithm}





We now give the general DP procedure DP(), also presented as Algorithm~\ref{Recurrence} \cite{Williamson}. Here, we iteratively construct the lists  for all . Each  is a list of pairs , in which  is a subset of  satisfying the boundary condition and  is the total value of the tasks in . Each list only maintains all the dominant pairs. Specifically, we start with . For each , we first set , and for each , we add  to the list  if  satisfies the boundary condition. We finally remove from  all the dominated pairs.
DP() will select a subset  of  from all pairs  so that  is maximum.








\begin{proposition}\label{selection}
DP() outputs a subset  of   such that  is the maximum value subject to the condition that  satisfies the boundary condition; the time complexity of DP() is .
\end{proposition}
\begin{proof}
The proof is similar to the one in the knapsack problem \cite{Williamson}. By induction, we need to prove that  contains all the non-dominated pairs corresponding to feasible sets . When , the proposition holds obviously. Now suppose it hold for . Let  and  satisfies the boundary condition. We claim that there is some pair  such that  and . First, suppose that . Then, the claim follows by the induction hypothesis and by the fact that we initially set  to  and removed dominated pairs. Now suppose that  and let .  By the induction hypothesis there is some  that dominates . Then, the algorithm will add the pair  to . Thus, there will be some pair  that dominates . Since the size of the space of  is no more than , the time complexity of DP() is . \end{proof}



\begin{proposition}\label{proposition-DP}
Given the subset  output by DP(), LDF() gives an optimal solution to the welfare maximization problem with a time complexity .
\end{proposition}
\begin{proof}
It follows from Propositions~\ref{selection}~and~\ref{property-task}.
\end{proof}

\noindent\textit{Remark.} As in the knapsack problem \cite{Williamson}, to construct the algorithm DP(), the pairs of the possible state of resource utilization and the corresponding best social welfare have to be maintained and a -dimensional vector has to be defined to indicate the resource utilization state. This seems to imply that we cannot make the time complexity of a DP algorithm polynomial in .


\subsection{Machine Minimization}





Given a set of tasks , the minimal number of machines needed to produce a feasible schedule of  is exactly the minimum  such that the boundary condition is satisfied, by Theorem~\ref{main-theorem}, where the feasible schedule could be produced with a time complexity . An upper bound of the minimum  is  and this minimum  can be obtained through a binary search procedure with a time complexity of ; the corresponding algorithm is presented as Algorithm~\ref{minimization}.

\begin{lemma}\label{complexity-1}
In each iteration of the binary search procedure, the time complexity of determining the satisfiability of boundary condition (line 4 of Algorithm~\ref{minimization}) is  where .
\end{lemma}
\begin{proof}
See the Appendix for the proof. 
\end{proof}

With Lemma~\ref{complexity-1}, the loop of Algorithm~\ref{minimization} has a complexity . Based on the above discussion, we conclude that

\begin{proposition}\label{machine-minimization}
Algorithm~\ref{minimization} produces an exact algorithm for the machine minimization problem with a time complexity of .
\end{proposition}




\begin{algorithm}\SetKwInOut{Begin}{Begin}
\SetKwInOut{Output}{Output}
\BlankLine
\BlankLine

,  \tcp*{\footnotesize{ and  are respectively the lower and upper bounds of the minimum number of needed machines}}

\;

\While{}{

   \If{the boundary condition is satisfied with }{
   
       \;
   }
   \Else{
   
       \;
    
   } 
   
   \;   

}

\tcp*{\footnotesize{the optimal number of machines}}

call the algorithm LDF() to produce a schedule of  on  machines\;



\caption{Machine Minimization)\label{minimization}}
\end{algorithm}








\subsection{Minimizing Maximum Weighted Completion Time}


Under the task model of this paper and for the objective of minimizing the maximum weighted completion time of tasks, a direction application of LDF() improves the algorithm in \cite{Nagarajan} by a factor 2. In \cite{Nagarajan}, with a polynomial time complexity, Nagarajan {\em et al.} find a completion time  for each task  that is  times the optimal in terms of the objective here; then they propose a scheduling algorithm where each task can be completed by the time at most 2 times . As a result, an -approximation algorithm is obtained. Instead, by using the optimal scheduling algorithm LDF(), we have that
\begin{proposition}
There is a ()-approximation algorithm for scheduling independent malleable tasks under the objective of minimizing the maximum weighted completion time of tasks.
\end{proposition}










\section{Conclusion}
\label{sec.conclusion}


In this paper, we study the problem of scheduling  deadline-sensitive malleable batch tasks on  identical machines. Our core result is a new theory to give the first optimal scheduling algorithm so that  machines can be optimally utilized by a set of batch tasks. We further derive four algorithmic results in obvious or non-obvious ways: (\rmnum{1}) the best possible greedy algorithm for social welfare maximization with a polynomial time complexity of  that achieves an approximation ratio of , (\rmnum{2}) the first dynamic programming algorithm for social welfare maximization with a polynomial time complexity of , (\rmnum{3}) the first exact algorithm for machine minimization with a polynomial time complexity of , and (\rmnum{4}) an improved polynomial time approximation algorithm for the objective of minimizing the maximum weighted completion time of tasks, reducing the previous approximation ratio by a factor 2. Here,  and  are the number of deadlines and the maximum deadline of tasks.





























\begin{thebibliography}{1}






\bibitem{Hu}
Han Hu, Yonggang Wen, Tat-Seng Chua, and Xuelong Li. "Toward scalable systems for big data analytics: A technology tutorial." {\em IEEE Access} (2014): 652-687.



\bibitem{Jain11a}
Jain, Navendu, Ishai Menache, Joseph Naor, and Jonathan Yaniv. "A Truthful Mechanism for Value-Based Scheduling in Cloud Computing." {\em In the 4th International Symposium on Algorithmic Game Theory}, pp. 178-189, Springer, 2011.


\bibitem{Jain}
Navendu Jain, Ishai Menache, Joseph Naor, and Jonathan Yaniv. "Near-optimal scheduling mechanisms for deadline-sensitive jobs in large computing clusters." {\em In Proceedings of the twenty-fourth annual ACM symposium on Parallelism in algorithms and architectures}, pp. 255-266. ACM, 2012.



\bibitem{Lucier}
Brendan Lucier, Ishai Menache, Joseph Seffi Naor, and Jonathan Yaniv. "Efficient online scheduling for deadline-sensitive jobs." {\em In Proceedings of the twenty-fifth annual ACM symposium on Parallelism in algorithms and architectures}, pp. 305-314. ACM, 2013.


\bibitem{Azar}
Yossi Azar, Inna Kalp-Shaltiel, Brendan Lucier, Ishai Menache, Joseph Seffi Naor, and Jonathan Yaniv. "Truthful online scheduling with commitments." {\em In Proceedings of the Sixteenth ACM Conference on Economics and Computation}, pp. 715-732. ACM, 2015.



\bibitem{Jain14}
Ishai Menache, Ohad Shamir, and Navendu Jain. "On-demand, Spot, or Both: Dynamic Resource Allocation for Executing Batch Jobs in the Cloud." {\em In Proceedings of USENIX International Conference on Autonomic Computing}, 2014.




\bibitem{Bodik}
Peter Bod\'ik, Ishai Menache, Joseph Seffi Naor, and Jonathan Yaniv. "Brief announcement: deadline-aware scheduling of big-data processing jobs." {\em In Proceedings of the 26th ACM symposium on Parallelism in algorithms and architectures}, pp. 211-213. ACM, 2014.



\bibitem{Nagarajan}
Viswanath Nagarajan, Joel Wolf, Andrey Balmin, and Kirsten Hildrum. "Flowflex: Malleable scheduling for flows of mapreduce jobs." {\em In Proceedings of the 12th ACM/IFIP/USENIX International Conference on Distributed Systems Platforms and Open Distributed Processing} (MiddleWare), pp. 103-122. Springer, 2013.



\bibitem{Wolf}
J. Wolf, Z. Nabi, V. Nagarajan, R. Saccone, R. Wagle, {\em et al}. "The X-flex Cross-Platform Scheduler: Who's the Fairest of Them All?." {\em In Proceedings of the ACM/IFIP/USENIX 13th MiddleWare conference}, Industry Track. Springer, 2014.



\bibitem{Lawler91}
Eugene L. Lawler. "A dynamic programming algorithm for preemptive scheduling of a single machine to minimize the number of late jobs." {\em Annals of Operations Research} 26, no. 1 (1990): 125-133.


\bibitem{Karger}
D. Karger, C. Stein, and J. Wein. Scheduling Algorithms. In CRC Handbook of Computer Science. 1997.


\bibitem{Jac55}
James R. Jackson. "Scheduling a Production Line to Minimize Maximum Tardiness." {\em Management Science Research Project Research Report} 43, University of California, Los Angeles, 1955.


\bibitem{Hor74}
W. A. Horn. "Some Simple Scheduling Algorithms." {\em Naval Research Logistics Quarterly}, 21:177-185, 1974.


\bibitem{Lawler69}
Eugene L. Lawler, and J. Michael Moore. "A Functional Equation and Its Application to Resource Allocation and Sequencing Problems." {\em Management Science} 16, no. 1 (1969): 77-84.



\bibitem{Stankovic98}
J. A. Stankovic, M. Spuri, K. Ramamritham, and G. Buttazzo, Deadline Scheduling for Real-Time Systems: EDF and Related Algorithms. {\em Kluwer Academic}, 1998.


\bibitem{White}
T. White. "Hadoop: The definitive guide." {\em O'Reilly Media, Inc.}, 2012.




\bibitem{Chuzhoy04a}
Julia Chuzhoy, Sudipto Guha, Sanjeev Khanna, and Joseph Seffi Naor. "Machine minimization for scheduling jobs with interval constraints." In Foundations of Computer Science, 2004. Proceedings. 45th Annual IEEE Symposium on, pp. 81-90. IEEE, 2004.


\bibitem{Williamson}
D. P. Williamson and D. B. Shmoys. The Design of Approximation Algorithm. {\em Cambridge University Press}, 2011.







\bibitem{Wu15a}
Xiaohu Wu, and Patrick Loiseau. "Algorithms for scheduling deadline-sensitive malleable tasks." {\em In Proceedings of the 53rd Annual Allerton Conference on Communication, Control, and Computing} (Allerton), pp. 530-537. IEEE, 2015.


\bibitem{Wu15b}
Xiaohu Wu, and Patrick Loiseau. "Algorithms for Scheduling Malleable Cloud Tasks (Technical Report)." arXiv preprint arXiv:1501.04343v4 (2015).






\bibitem{Guo17a}
Longkun Guo, and Hong Shen. "Efficient Approximation Algorithms for the Bounded Flexible Scheduling Problem in Clouds." IEEE Transactions on Parallel and Distributed Systems 28, no. 12 (2017): 3511-3520.










\bibitem{Brassard}
G. Brassard, and P. Bratley. Fundamentals of Algorithmics. {\em Prentice-Hall, Inc.}, 1996.

\bibitem{Even}
G. Even, Recursive greedy methods, in Handbook of Approximation Algorithms and Metaheuristics, T. F. Gonzalez, ed., CRC, Boca Raton, FL, 2007, ch. 5.


\end{thebibliography}

\appendix



\begin{proof}[Proof of Lemma~\ref{exit-condition-1}]
Before executing Fully-Utilize(), the resource allocation to the previously allocated tasks  satisfies Property~\ref{proper-1}. Its execution does not change the previous allocation to . Let . Since , the workload of  can only be processed in ; the maximum workload of  that could be processed in  still equals its counterpart when  is considered, i.e., . Upon completion of Fully-Utilize(), if the total allocation to  in  is , we could conclude that  is the last task of  being considered and all tasks in  have been fully allocated; otherwise, , which contradicts the fact that  and its subset satisfy the boundary condition, which implies that after the maximum workload of  has been processed in , the remaining workload . Hence, we conclude that
\end{proof}



\begin{proof}[Proof of Lemma~\ref{lemma-fully-utilize}]
During the execution of Fully-Utilize(), upon completion of the allocation to  at , if  has not been fully allocated yet, it is allocated  machines at this slot.
The allocations to  at slots  are non-increasing, i.e.,
\begin{center}
.
\end{center}
The reason for this is as follows: Fully-Utilize() allocates machines to  from  towards earlier slots and, after the allocation at every slot ,  whose value is non-increasing with . With Property~\ref{proper-2}, before executing Fully-Utilize(), the numbers of idle machines have a stepped shape, i.e., . The execution of Fully-Utilize() does not change the previous allocation to  and upon its completion the number of available machines  at every slot  will be no larger than its counterpart before executing Fully-Utilize(); we thus have . Upon completion of Fully-Utilize(), deducting the machines allocated to , the numbers of idle machines still have a stepped shape in . Hence, the lemma holds.
\end{proof}




\begin{proof}[Proof of Lemma~\ref{lemma-existence}]
Recall that  is the sum of the allocations  of all tasks  at  and . Initially, we have the inequality that  due to the conditions (\rmnum{1})-(\rmnum{3}) of Lemma~\ref{lemma-existence}, and, there exists a  such that ; otherwise, that inequality would not hold. In the subsequent iteration of Routine(),  becomes  since partial allocation of  is transferred from  to ; however, it still holds that . So, we have
\begin{center}

\end{center}
and such  can still be found like the initial case.
\end{proof}


\begin{proof}[Proof of Lemma~\ref{lemma-allocate}]
 If  has been allocated  resource just upon completion of Fully-Utilize(), Fully-Allocate() does nothing upon its completion and we have  and the lemma holds. Otherwise, within , by Lemma~\ref{lemma-fully-utilize}, only the time slots  in  have available machines, i.e., , and, at these time slots, ; for all , . So, only for each  in  and from  towards earlier time slots, Fully-Allocate() will reduce the allocations of the previous tasks of  at  and transfer them to the latest time slot  in  with  (see the step 2 of Fully-Allocate()); then, all the available machines at  will be re-allocated to  and  is still zero again (see the step 3 of Fully-Allocate()), and, the number of available machines at  will be decreased to zero one by one from  toward earlier time slots. Due to Lemma~\ref{lemma-fully-utilize}, the lemma holds.
\end{proof}


\begin{proof}[Proof of Lemma~\ref{lemma-complexity}]
The time complexity of Allocate-B() depends on Fully-Allocate() or AllocateRLM(). In the worst case, Fully-Allocate() and AllocateRLM() have the same time complexity from the execution of Routine() at every time slot . In AllocateRLM() for every task , each loop iteration at  needs to seek the time slot  and the task  at most  times. The time complexities of respectively seeking  and  are  and ; the maximum of these two complexities is . Since  and , we have that both the time complexity of Allocate-B() is . Since we assume that  and  are finitely bounded where , we conclude that .\end{proof}



\begin{proof}[Proof of Lemma~\ref{lemma-upper-bound-1}]
 Let us consider an optimal allocation to  for the MSW-\Rmnum{1} problem. If we replace an allocation to a task in  with the same allocation to a task in  and do not change the allocation to , this generates a feasible schedule for the MSW-\Rmnum{2} problem, which yields at least the same social welfare since the marginal value of the task in  is no smaller than the ones of the tasks in ; hence, Lemma~\ref{lemma-upper-bound-1} holds.
\end{proof}








\begin{proof}[Proof of Lemma~\ref{lemma-upper-bound-2}]
We will show in an optimal schedule of the MSW-\Rmnum{2} problem that (\rmnum{1}) only the tasks of ,  will be executed in , and (\rmnum{2}) the upper bound of the maximum workload of  that could be processed in  is . As a result, the total value generated by executing all tasks of  and  workload of each  () is an upper bound of the optimal social welfare for the MSW-\Rmnum{2} problem.


We prove the first point by contradiction. Given a , if , all tasks of  could not be processed in  due to the deadline constraint. If , the marginal value of the task in  is no smaller than the ones of ; instead of processing  in , processing  could generate at least the same value or even a higher value. Hence, the first point holds.


We prove the second point also by contradiction. If there exists a  such that more than  workload of  is processed in , let  denote the minimum such . In the case where , due to Features~\ref{fully} and~\ref{utilization1}, after the maximum workload of the tasks of  has been processed in , the minimum remaining workload that could be processed in  is at least . If more than  workload of  is processed in , this means that the total amount of workload of  processed in  is smaller than ; in this case, we could always remove the allocation to  and add more allocation to  to increase the total value. As a result, the second point holds when . In the other case where , since we are seeking for an upper bound, we could assume that for all ,  workload of  is processed in . Again due to Features~\ref{fully} and~\ref{utilization1}, similar to the case where , the minimum available workload of  that could be processed in  is at least . In this case, we could still remove the allocation to  and add more allocation to  to increase the total value, with the second point holding when .
\end{proof}

\begin{proof}[Proof of Lemma~\ref{lemma-interval-value}]
It suffices to prove that, the total allocation to  in  could be divided into  parts such that, for all , (\rmnum{1}) the -th part has a size , and (\rmnum{2}) the allocation of the -th part is associated with marginal values no smaller than . Then, the total value generated by executing the -th part is no smaller than  times the total value generated by the allocation to  in . As a result, the value generated by the total allocation to  in  is no smaller than  times the value generated by the allocation to .


Due to Feature~\ref{utilization1}, the allocation to  achieves a utilization  in  and we could use a part of this allocation as the first part whose size is . Next, the allocation to  achieves a utilization  in ; we could deduct the allocation used for the first part and get a part of the remaining allocation to  as the second part, whose size is . Similarly, we could get the 3rd, , -th parts that satisfy the first point mentioned at the beginning of this proof. Since the marginal value of the task of  is no larger than the ones of the tasks in  for all , the second point mentioned above also holds.
\end{proof}


\begin{proof}[Proof of Proposition~\ref{proposition-utilization-2}]
We first show that the resource utilization of  in  is  upon completion of the -th phase of GreedyRLM; then, we consider a task  such that . Since  is not accepted when being considered, it means that  at that time and there are at most  time slots  with  in . Then, we assume that the number of the time slots  with  is . Since  isn't fully allocated, we have the current resource utilization of  in  is at least



We assume that  for some . Now, we show that, after  is considered and rejected, the subsequent resource allocation by Allocate-A() to each task  of  doesn't change the utilization in . Fully-Utilize() does not change the allocation to the previous accepted tasks; the operations of changing the allocation to other tasks in AllocateRLM(, 0, ) happen in its call to Routine(, 0, 1, ) where we have  for all . Due to the function of lines 6-8 of Routine(, 0, 1, ), in the -th phase of GreedyRLM, the call to any Allocate-A() will never change the current allocation of  in . Hence, if , upon completion of GreedyRLM, the resource utilization of  where ; if , since each time slot in  is fully utilized by the definition of , the resource utilization in  is 1 and the final resource utilization will also be at least .
\end{proof}


\begin{proof}[Proof of Lemma~\ref{complexity-1}]
Recall the process of defining  where . In Definition~\ref{Def-1} that defines ,  tasks are considered sequentially for each , leading to a complexity . In Definition~\ref{Def-2} that derives  from , , , ,  are considered sequentially, leading to a complexity . Finally, . Hence, the time complexity of determining the satisfiability of boundary condition depends on Definition~\ref{Def-1} and is .
\end{proof}

















\end{document}
