\documentclass[preprint,draft]
{sigplanconf}

\usepackage[
   a4paper,
   pdftex,
   pdfkeywords={},
   pdfborder={0 0 0},
   pdftitle={Foundational Extensible Corecursion},
   pdfauthor={Jasmin Christian Blanchette, Andrei Popescu, and Dmitriy Traytel},
   draft=false,
   bookmarksnumbered,
   bookmarks,
   bookmarksdepth=2,
   bookmarksopenlevel=2,
   bookmarksopen]{hyperref}

\usepackage{flushend}
\usepackage{quoting}
\usepackage[T1]{fontenc}
\usepackage[all]{xy}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{wasysym}
\usepackage{bm}
\usepackage{bussproofs}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{mathptmx}
\usepackage{multicol}
\usepackage{url}
\usepackage[scaled=.825]{beramono}
\usepackage[scaled=.825]{helvet}
\usepackage{tikz}
\usetikzlibrary{positioning,shapes,arrows,matrix}



\hyphenation{i-so-mor-phic in-duc-tive co-in-duc-tive co-iter-a-tion
co-iter-a-tions al-ge-bra-ic co-al-ge-bra-ic
al-ge-bra co-al-ge-bra cate-go-ry cate-go-ri-cal data-type data-types
Proof-Power frame-work wit-ness data-func-tor data-func-tors
bi-sim-u-la-tion bi-sim-u-la-tions bi-sim-u-lated
data-type data-types co-data-type co-data-types Isa-belle
non-empti-ness}

\clearpage{}\usepackage{amssymb}

\newcommand{\leftOut}[1]{}
\newcommand{\comment}[1]{}
\newcommand{\specificStrathclyde}[1]{#1}

\newbox\boxA

\let\vv=\v
\renewcommand{\epsilon}{\varepsilon}


\newcommand\vvthinspace{\kern.041667ex}
\newcommand\vthinspace{\kern.08333ex}
\newcommand\negvthinspace{\kern-.08333ex}
\newcommand\negvvthinspace{\kern-.041667ex}

\newcommand\TC{\mathsf}


\newcommand\keyw[1]{\texttt{#1}}


\newcommand\CHOPFROMUN{.25}
\newcommand\UN{{\setbox\boxA=\hbox{\_}\usebox\boxA\kern-\CHOPFROMUN\wd\boxA{\color{white}\vrule height 0ex depth .444ex width \CHOPFROMUN\wd\boxA}\kern-\CHOPFROMUN\wd\boxA}}



\newtheorem{theorem}{Theorem}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{eexample}[theorem]{Example}
\newenvironment{proofx}{\upshape\noindent{\it Proof.}\enskip\ignorespaces}{\qed\vspace{\topsep}}



\newcommand{\red}{\rightsquigarrow}
\newcommand{\Rred}{\mbox{ \hspace{-2.6ex} }}
\newcommand{\RRred}{\mbox{ \hspace{-2.6ex} }}
\newcommand{\RredT}{\mbox{}}
\newcommand{\vvdash}{\mbox{ }}
\newcommand{\vvvdash}{\mbox{ }}


\newcommand{\sm}{\setminus}
\newcommand{\btw}{\overline}
\newcommand{\ov}{\overline}
\newcommand{\un}{\underline}
\newcommand{\tup}{\overline}
\newcommand{\eps}{\epsilon}
\newcommand{\con}{\mbox{}}
\newcommand{\ds}{\displaystyle}
\renewcommand{\phi}{\varphi}
\newcommand{\bw}{\bigwede}
\newcommand{\bv}{\bigvee}
\newcommand{\w}{\wedge}
\renewcommand{\v}{\vee}
\newcommand{\sta}{\stackrel}
\newcommand{\su}{\subseteq}
\renewcommand{\P}{\TC{P}}
\newcommand{\Pne}{{\TC{P}}}
\renewcommand{\iff}{\allowbreak\mathrel{\leftarrow\nobreak\kern-1.6ex\rightarrow}\allowbreak} \newcommand{\iffla}{\allowbreak\mathrel{\leftarrow\nobreak\kern-1.55ex-}\allowbreak}
\newcommand{\orc}{\forall}
\newcommand{\ex}{\exists}
\let\oo=\o
\renewcommand{\o}{\circ}
\renewcommand{\Im}{{\mathit{Im}}}
\newcommand{\incl}{\hookrightarrow}
\newcommand{\restr}{\upharpoonright}
\newcommand{\la}{\leftarrow}
\newcommand{\defRa}{\looparrowright}
\newcommand{\ra}{\rightarrow}
\def\implies{\Rightarrow} \newcommand{\Ra}{\Rightarrow}
\newcommand{\lra}{\longrightarrow}
\newcommand{\lla}{\leftarrow}
\newcommand{\Lra}{\Rightarrow}
\newcommand{\LRA}{\;\longrightarrow\;}

\newcommand{\llam}{{\llam}}


\renewcommand{\vec}[2]{\ov{#1}^{(#2)}} \newcommand{\vel}[2]{\mbox{}}  


\newcommand{\mat}[3]{{\ov{\un{#1}}}_{(#2)}^{(#3)}} \newcommand{\mel}[3]{{\ov{\un{#1}}}_{(#2)}^{(#3)}} \newcommand{\row}[2]{{\ov{\un{#1}}}_{#2}}  \newcommand{\col}[2]{{\ov{\un{#1}}}^{#2}}  




\newcommand{\<}{\langle}
\renewcommand{\>}{\rangle}
\newcommand{\rlS}[4]{\mbox{}
                         \mbox{\hspace*{0ex} #4}}
\newcommand{\rl}[3]{\mbox{{\mbox{\hspace*{-0.5ex}\TC(#1)}}}}

\newcommand{\axmS}[3]{\mbox{{\mbox{ \TC(#1)}}}\mbox{}}
\newcommand{\axmSD}[3]{\mbox{}
                         \mbox{\hspace*{-1.5ex} #3}}
\newcommand{\axmSpecial}[3]{\mbox{}
                         \mbox{\hspace{-8.5ex} #3}}
\newcommand{\axm}[2]{\mbox{{\mbox{ \TC(#1)}}}}


\newcommand{\SN}{\mathcal{SN}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\U}{\mathcal{U}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\FF}{\mathcal{F}}
\newcommand{\GG}{\mathcal{G}}
\newcommand{\HH}{\mathcal{H}}
\newcommand{\PP}{\mathcal{P}}
 
  
\newcommand{\dd}{\Delta}
\renewcommand{\l}{\Lambda}
\newcommand{\talg}{{{\mathsf{op}}}} 
\renewcommand{\eta}{{{\mathsf{leaf}}}}
\renewcommand{\mu}{{{\mathsf{flat}}}}
\newcommand{\ctor}{{{\mathsf{ctor}}}}
\newcommand{\dtor}{{{\mathsf{dtor}}}}
\newcommand{\lfp}{{{\mathsf{lfp}}}}
\newcommand{\gfp}{{{\mathsf{gfp}}}}
\newcommand{\inc}{{{\mathsf{inc}}}}
\newcommand{\evil}{{{\mathsf{nasty}}}} 
\newcommand{\ccont}{{{\mathsf{cont}}}}
\newcommand{\rroot}{{{\mathsf{root}}}}
\newcommand{\dif}{{{\mathsf{dif}}}}
\newcommand{\llll}{{{\mathsf{l}}}}
\newcommand{\lt}{{{\mathsf{lt}}}}
\newcommand{\intTrm}{{{\mathsf{int\hspace*{-0.2ex}Trm}}}}
\newcommand{\satHcl}{{{\mathsf{sat\hspace*{-0.0ex}Hcl}}}}
\newcommand{\satAtm}{{{\mathsf{sat\hspace*{-0.2ex}Atm}}}}
\newcommand{\Pcond}{{{\mathsf{P\hspace*{-0.2ex}cond}}}}
\newcommand{\KK}{{{\mathsf{K}}}}
\newcommand{\HCL}{{{\mathsf{HCL}}}}
\newcommand{\inhab}{{{\mathsf{reach}}}}
\newcommand{\compat}{{{\mathsf{compat}}}}
\newcommand{\compatHcl}{{{\mathsf{wf}}}}
\newcommand{\trms}{{{\mathsf{trms}}}}
\newcommand{\gtrms}{{{\mathsf{gtrms}}}}
\newcommand{\htrms}{{{\mathsf{htrms}}}} 
\newcommand{\Eq}{{{\mathsf{Eq}}}}
\newcommand{\Geq}{{{\mathsf{Geq}}}}
\newcommand{\Grel}{{{\mathsf{Grel}}}}
\newcommand{\Hrel}{{{\mathsf{Hrel}}}}
\newcommand{\Rl}{{{\mathsf{Rl}}}}  
\newcommand{\Hop}{{{\mathsf{H\hspace*{-0.15ex}op}}}}
\newcommand{\Gop}{{{\mathsf{G\hspace*{-0.15ex}op}}}}
\newcommand{\Op}{{{\mathsf{O\hspace*{-0.15ex}p}}}}
\newcommand{\Horn}{{{\mathsf{Horn}}}}
\newcommand{\nfold}{{{\mathsf{nfold}}}}
\newcommand{\hfold}{{{\mathsf{hfold}}}}
\newcommand{\ifold}{{{\mathsf{ifold}}}}
\newcommand{\embed}{{{\mathsf{emb}}}}
\newcommand{\flt}{{{\mathsf{flat}}}}
\newcommand{\fltLifted}{{{\mathsf{flatLifted}}}}
\newcommand{\ext}{{{\mathsf{ext}}}}
\newcommand{\Sc}{{{\mathsf{Sc}}}}
\newcommand{\Tr}{{{\mathsf{Tr}}}}
\newcommand{\rint}{{{\mathsf{rint}}}}
\newcommand{\Kln}{{{\mathsf{Kl}}}} 
\newcommand{\lang}{{{\mathsf{lang}}}}
\newcommand{\Star}{{{\mathsf{Star}}}}
\newcommand{\One}{{{\mathsf{One}}}}
\newcommand{\Zero}{{{\mathsf{Zero}}}}
\newcommand{\Uminus}{{{\mathsf{Uminus}}}}
\newcommand{\Plus}{{{\mathsf{Plus}}}}
\newcommand{\Times}{{{\mathsf{Times}}}}
\newcommand{\Let}{{{\mathsf{Let}}}}
\newcommand{\hoas}{{{\mathsf{hoas}}}}
\newcommand{\foldFset}{{{\mathsf{fold\_fset}}}} 
\newcommand{\foldNfset}{{{\mathsf{fold\_nfset}}}}
\newcommand{\InsO}{{{\mathsf{Ins_1}}}}
\newcommand{\InsT}{{{\mathsf{Ins_2}}}}
\newcommand{\cmd}{{{\mathsf{comm\_monoid\_add}}}}
\newcommand{\bmap}{{{\mathsf{bag\_map}}}}
\newcommand{\balg}{{{\mathsf{bag\_alg}}}}
\newcommand{\fsetalg}{{{\mathsf{fset\_alg}}}}
\newcommand{\nfsetalg}{{{\mathsf{nfset\_alg}}}}
\newcommand{\ifset}{{{\mathsf{iter\_fset}}}}
\newcommand{\ibag}{{{\mathsf{iter\_bag}}}}
\newcommand{\KKK}{{{\mathsf{K}}}} 
\newcommand{\Subst}{{{\mathsf{Subst}}}}
\newcommand{\Ct}{{{\mathsf{Ct}}}}
\newcommand{\JJJ}{{{\mathsf{J}}}}
\newcommand{\finite}{{{\mathsf{finite}}}}
\newcommand{\ssum}{{{\mathsf{sum}}}}
\newcommand{\card}{{{\mathsf{card}}}}
\newcommand{\mult}{{{\mathsf{mult}}}} 
\newcommand{\Old}{{{\mathsf{Old}}}} 
\newcommand{\occs}{{{\mathsf{occs}}}} 
\newcommand{\app}{{{\mathsf{app}}}} 
\newcommand{\ct}{{{\mathsf{ct}}}}
\newcommand{\subst}{{{\mathsf{subst}}}}
\newcommand{\lam}{{{\mathsf{lam}}}}  
\newcommand{\mem}{{{\mathsf{mem}}}}
\newcommand{\Singl}{{{\mathsf{Singl}}}}
\newcommand{\Un}{{{\mathsf{Un}}}}
\newcommand{\Unn}{{{\mathsf{Unn}}}}
\newcommand{\MEmp}{{{\mathsf{M\hspace*{-0.2ex}Emp}}}}
\newcommand{\MIns}{{{\mathsf{M\hspace*{-0.1ex}Ins}}}}
\newcommand{\listall}{{{\mathsf{list\_all}}}}
\newcommand{\listallt}{{{\mathsf{relList}}}}
\newcommand{\Emp}{{{\mathsf{Emp}}}}
\newcommand{\Signature}{{{\mathsf{Signature}}}}
\newcommand{\HornTheory}{{{\mathsf{HornTheory}}}}
\newcommand{\Ins}{{{\mathsf{Ins}}}}
\newcommand{\prels}{{{\mathsf{prels}}}}
\newcommand{\params}{{{\mathsf{params}}}}
\newcommand{\arOf}{{{\mathsf{arOf}}}}
\newcommand{\rarOf}{{{\mathsf{rarOf}}}}
\newcommand{\arOfP}{{{\mathsf{arOfP}}}}
\newcommand{\rarOfP}{{{\mathsf{rarOfP}}}}
\newcommand{\stOf}{{{\mathsf{stOf}}}}
\newcommand{\emb}{{{\mathsf{emb}}}}
\newcommand{\valTC}{{{\mathsf{valTC}}}}
\newcommand{\valS}{{{\mathsf{valS}}}}
\newcommand{\mode}{{{\mathsf{mode}}}} 
\newcommand{\cc}{{{\circ\!\!\circ}}}
\newcommand{\Gr}{{{\mathsf{Gr}}}}
\newcommand{\All}{{{\mathsf{All}}}}
\newcommand{\Ex}{{{\mathsf{Ex}}}}
\newcommand{\Ball}{{{\mathsf{Ball}}}}
\newcommand{\Bex}{{{\mathsf{Bex}}}}
\newcommand{\per}{{{\mathsf{per}}}}
\newcommand{\CONC}{\mathbin{@}}
\newcommand{\listPred}{{{\mathsf{list\_pred}}}}
\newcommand{\tpOf}{{{\mathsf{tpOf}}}}
\newcommand{\tconOf}{{{\mathsf{tconOf}}}}
\newcommand{\initState}{{{\mathsf{init\hspace*{-0.075ex}State}}}}
\newcommand{\nextState}{{{\mathsf{next\hspace*{-0.075ex}State}}}}
\newcommand{\embL}{{{\mathsf{emb\hspace*{-0.075ex}L}}}}
\newcommand{\embR}{{{\mathsf{emb\hspace*{-0.075ex}R}}}}
\newcommand{\pred}{{{\mathsf{pred}}}}
\newcommand{\dpred}{{{\mathsf{dpred}}}}
\newcommand{\predpred}{{{\mathsf{predpred}}}}
\newcommand{\Lab}{{{\mathsf{Lab}}}}
\newcommand{\Lev}{{{\mathsf{Lev}}}}
\newcommand{\beh}{{{\mathsf{beh}}}}
\newcommand{\rv}{{{\mathsf{rv}}}}
\newcommand{\sub}{{{\mathsf{sub}}}}
\newcommand{\LB}{{{\mathsf{LB}}}}
\newcommand{\Id}{{{\mathsf{Id}}}}
\newcommand{\IFpred}{{{\mathsf{IFpred}}}}
\newcommand{\JFpred}{{{\mathsf{JFpred}}}}
\newcommand{\Fpred}{{{\mathsf{Fpred}}}}
\newcommand{\Apred}{{{\mathsf{Apred}}}}
\newcommand{\Kpred}{{{\mathsf{Kpred}}}}
\newcommand{\Frel}{{{\mathsf{Frel}}}}
\newcommand{\Krel}{{{\mathsf{Krel}}}}
\renewcommand{\max}{{{\mathsf{max}}}}
\newcommand{\collect}{{{\mathsf{collect}}}}
\newcommand{\Collect}{{{\mathsf{Collect}}}}
\newcommand{\Suc}{{{\mathsf{Suc}}}}
\newcommand{\Br}{{{\mathsf{Br}}}}
\newcommand{\onetwos}{{{\mathsf{onetwos}}}}
\newcommand{\UNIV}{{{\mathsf{UNIV}}}}
\newcommand{\Univ}{{{\mathsf{U}}}}
\newcommand{\Fin}{{{\mathsf{Fin}}}}
\newcommand{\reduce}{{{\mathsf{reduce}}}}
\newcommand{\rec}{{{\mathsf{rec}}}}
\newcommand{\Call}{{{\eta}}}
\newcommand{\Exit}{{{\mathsf{Exit}}}}
\newcommand{\eval}{{{\mathsf{eval}}}}
\newcommand{\corec}{{{\mathsf{corecPrim}}}}
\newcommand\corecU{\mathsf{corecTop}}
\newcommand\corecUU{\mathsf{corecFlex}}
\newcommand{\mapS}{{{\mathsf{smap}}}}
\newcommand{\listrel}{{{\mathsf{rel}}}}
\newcommand{\corecS}{{{\mathsf{scorec}}}}
\newcommand{\iter}{{{\mathsf{iter}}}}
\newcommand{\coiter}{{{\mathsf{coiter}}}}
\newcommand{\wpull}{{{\mathsf{wpull}}}}
\newcommand{\Children}{{{\mathsf{sub}}}} \newcommand{\Label}{{{\mathsf{val}}}} \newcommand{\unf}{{{\mathsf{unf}}}}
\newcommand{\fld}{{{\mathsf{fld}}}}
\newcommand{\comp}{{{\mathsf{comp}}}}
\newcommand{\TNil}{{{\mathsf{TNil}}}}
\newcommand{\Nil}{{{\mathsf{Nil}}}}
\newcommand{\hd}{{{\mathsf{head}}}}
\newcommand{\tl}{{{\mathsf{tail}}}}
\newcommand{\SCons}{{{\mathsf{S\hspace*{-0.2ex}Cons}}}}
\newcommand{\Cons}{{{\mathsf{Cons}}}}
\newcommand{\TCons}{{{\mathsf{TCons}}}}
\newcommand{\Node}{{{\mathsf{Node}}}}
\newcommand{\opls}{\mathrel\oplus}
\newcommand{\oprd}{\mathrel\otimes}
\newcommand{\oexp}{{{\mathsf{exp}}}}
\newcommand{\primes}{{{\mathsf{primes}}}}
\newcommand{\GCD}{{{\mathsf{gcd}}}}
\newcommand{\everyOther}{{{\mathsf{everyOther}}}}
\newcommand{\fibA}{{{\mathsf{fibA}}}}
\newcommand{\fibB}{{{\mathsf{fibB}}}}
\newcommand{\facA}{{{\mathsf{facA}}}}
\newcommand{\facB}{{{\mathsf{facB}}}}
\newcommand{\facC}{{{\mathsf{facC}}}}
\newcommand{\facD}{{{\mathsf{facD}}}}
\newcommand{\fac}{{{\mathsf{fac}}}}
\newcommand{\SUP}{{{\mathsf{sup}}}}
\newcommand{\catalan}{{{\mathsf{cat}}}}
\newcommand{\CONG}{{{\mathsf{cl}}}}
\newcommand{\GUARD}[1]{{{\underline{#1}}}}
\newcommand{\rootFSet}{{{\mathsf{root_\FSet}}}}
\newcommand{\rootMSet}{{{\mathsf{root_\MSet}}}} 
\newcommand{\contFSet}{{{\mathsf{cont_\FSet}}}}
\newcommand{\contMSet}{{{\mathsf{cont_\MSet}}}}
\newcommand{\NodeFSet}{{{\mathsf{Node_\FSet}}}}
\newcommand{\NodeMSet}{{{\mathsf{Node_\MSet}}}}
\newcommand{\typeOf}{{\mbox{\mathsf{typeOf}}}}
\newcommand{\cWls}{\mathsf{{cWls}}}
\newcommand{\Ttrue}{\mathsf{{True}}}
\newcommand{\Ffalse}{\mathsf{{False}}}
\newcommand{\Var}{\mathsf{{Var}}}
\newcommand{\dVar}{\mathsf{{dVar}}}
\newcommand{\tVar}{\mathsf{{tVar}}}
\newcommand{\asHctxt}{\mathsf{{asHctxt}}}
\newcommand{\isCtxt}{\mathsf{{isCtxt}}}
\newcommand{\Arr}{\mathsf{Arr}}
\newcommand{\Al}{\mathsf{Al}}
\newcommand{\App}{\mathsf{App}}
\newcommand{\Lam}{\mathsf{{Lam}}}
\newcommand{\Abs}{\mathsf{{Abs}}}
\newcommand{\Dabs}{\mathsf{{Dabs}}}
\newcommand{\Tabs}{\mathsf{{Tabs}}}
\newcommand{\cInV}{\mathsf{{cInV}}}
\newcommand{\cApp}{\mathsf{{cApp}}}
\newcommand{\cLam}{\mathsf{{cLam}}}
\newcommand{\cArr}{\mathsf{{cArr}}}
\newcommand{\cAl}{\mathsf{{cAl}}}
\newcommand{\fresh}{\mathsf{{fresh}}}
\newcommand{\fr}{\mathsf{{fr}}}
\newcommand{\aaa}{\mathsf{{a}}}
\newcommand{\bbb}{\mathsf{{b}}}
\newcommand{\freshAbs}{\mathsf{{freshAbs}}}
\newcommand{\freshEnv}{\mathsf{{freshEnv}}}
\newcommand{\id}{\mathsf{{id}}}
\newcommand{\AppL}{\mathsf{{AppL}}}
\newcommand{\fAppL}{\mathsf{{AppL}}}
\newcommand{\varOfAbs}{\mathsf{{varOfAbs}}}
\newcommand{\termOfAbs}{\mathsf{{termOfAbs}}}

\newcommand{\IF}{{\TC{{IF}}}}
\newcommand{\JF}{{\TC{{JF}}}}
\newcommand{\IFmap}{\mathsf{{IFmap}}}
\newcommand{\JFmap}{\mathsf{{JFmap}}}


\newcommand{\C}{{\TC{C}}}
\newcommand{\F}{{\TC{F}}}
\newcommand{\T}{{\TC{T}}}
\newcommand{\J}{{\TC{J}}}
\renewcommand{\SS}{{\TC{\Sigma}}}
\newcommand{\K}{{\TC{K}}}
\renewcommand{\H}{{\TC{H}}}
\newcommand{\G}{{\TC{G}}}
\newcommand{\sett}{\mathsf{{set}}}
\newcommand{\map}{\mathsf{{map}}}
\newcommand{\zip}{\mathsf{{zip}}}
\newcommand{\mapt}{\mathsf{{map2}}}
\newcommand{\image}{\mathsf{{image}}}
\newcommand{\bimage}{\mathsf{{bimage}}}
\newcommand{\fimage}{\mathsf{{fimage}}}
\newcommand{\cimage}{\mathsf{{cimage}}}
\newcommand{\Fmap}{\mathsf{{Fmap}}}
\newcommand{\Kmap}{\mathsf{{Kmap}}}
\newcommand{\Gmap}{\mathsf{{Gmap}}}
\newcommand{\Hmap}{\mathsf{{Hmap}}}
\newcommand{\Cmap}{\mathsf{{Cmap}}}
\newcommand{\Fset}{\mathsf{{Fset}}}
\newcommand{\IFset}{\mathsf{{IFset}}}
\newcommand{\IFbd}{\mathsf{{IFbd}}}
\newcommand{\JFset}{\mathsf{{JFset}}}
\newcommand{\JFbd}{\mathsf{{JFbd}}}
\newcommand{\Gset}{\mathsf{{Gset}}}
\newcommand{\Hset}{\mathsf{{Hset}}}
\newcommand{\Fbd}{\mathsf{{Fbd}}}
\newcommand{\Fbdtp}{\mathsf{{Fbd\UN{}tp}}}
\newcommand{\Gbd}{\mathsf{{Gbd}}}
\newcommand{\Gbdtp}{\mathsf{{Gbd\UN{}tp}}}
\newcommand{\Hbd}{\mathsf{{Hbd}}}
\newcommand{\Hbdtp}{\mathsf{{Hbd\UN{}tp}}}

\newcommand{\varr}{\mathsf{{var}}}


\newcommand{\Inl}{\mathsf{{Inl}}}
\newcommand{\Inr}{\mathsf{{Inr}}}
\newcommand{\isInl}{\mathsf{{isLeft}}}
\newcommand{\isInr}{\mathsf{{isRight}}}
\newcommand{\fst}{\mathsf{{fst}}}
\newcommand{\snd}{\mathsf{{snd}}}

\newcommand{\att}{\mathsf{{atm}}}

\newcommand\konigPath{\const{wpath}}
\newcommand\infiniteTree{\const{infinite}}
\newcommand\properPath{\const{proper\_path}}
 
\newcommand{\Hl}{{{\mathit{Hl}}}}
\newcommand{\at}{{{\mathit{atm}}}}
\newcommand{\atl}{{{\mathit{atml}}}}
\newcommand{\Ts}{{{\mathit{Ts}}}}
\newcommand{\intSt}{{{\mathit{intSt}}}}
\newcommand{\intOp}{{{\mathit{intOp}}}}
\newcommand{\intRl}{{{\mathit{intRl}}}}
\newcommand{\intEq}{{{\mathit{intEq}}}}
\newcommand{\intPvar}{{{\mathit{intPvar}}}}
\newcommand{\intVar}{{{\mathit{intVar}}}}


\newcommand{\al}{{\mathit{al}}}
\newcommand{\bl}{{\mathit{bl}}}
\newcommand{\ps}{{\mathit{p\hspace*{-0.1ex}s}}}
\newcommand{\psl}{{\mathit{psl}}}
\newcommand{\xl}{{\mathit{xl}}}
\newcommand{\Tl}{{\mathit{Tl}}}
\newcommand{\pl}{{\mathit{pl}}}
\newcommand{\pxl}{{\mathit{pxl}}} 
\newcommand{\px}{{\mathit{p\hspace*{-0.1ex}x}}}


\newcommand{\xs}{{\mathit{xs}}}
\newcommand{\ys}{{\mathit{ys}}}
\newcommand{\as}{{\mathit{as}}}
\newcommand{\bs}{{\mathit{bs}}}
\newcommand{\kl}{{\mathit{kl}}}
\newcommand{\Kl}{{\mathit{Kl}}}
\newcommand{\lab}{{\mathit{lab}}}
\newcommand{\llab}{{\mathit{lab}}}
\newcommand{\tr}{{\mathit{tr}}}
\newcommand{\ttr}{{\mathit{tr}}}
\newcommand{\trl}{{\mathit{trl}}}
\newcommand{\ttrl}{{\mathit{trl}}}
\newcommand{\tx}{{\mathit{tx}}}
\newcommand{\ftx}{{\mathit{tx}}}
\newcommand{\ty}{{\mathit{ty}}}
\newcommand{\fty}{{\mathit{ty}}}
\newcommand{\tz}{{\mathit{tz}}}
\newcommand{\ftz}{{\mathit{tz}}}
\newcommand{\tX}{{\mathit{tX}}}
\newcommand{\ttX}{{\mathit{tX}}}
\newcommand{\ftX}{{\mathit{tX}}}
\newcommand{\tY}{{\mathit{tY}}}
\newcommand{\ftY}{{\mathit{tY}}}
\newcommand{\tZ}{{\mathit{tZ}}}
\newcommand{\ftZ}{{\mathit{tZ}}}
\newcommand{\tA}{{\mathit{tA}}}
\newcommand{\ftA}{{\mathit{tA}}}
\newcommand{\tB}{{\mathit{tB}}}
\newcommand{\ftB}{{\mathit{tB}}}
\newcommand{\tC}{{\mathit{tC}}}
\newcommand{\ftC}{{\mathit{tC}}}
\newcommand{\val}{{\mathit{val}}}
\newcommand{\Zs}{{\mathit{Zs}}}
\newcommand{\fZs}{{\mathit{Zs}}}
   

\newcommand\Real{\TC{Real}} 
\newcommand\Const{\TC{Const}}
\newcommand\LTerm{\TC{LTerm}}
\newcommand\Set{\TC{Set}}
\newcommand\Type{\TC{Type}}
\newcommand\Stream{\TC{Stream}}
\newcommand\Nat{{\TC{Nat}}}
\newcommand{\atm}{{\TC atm}} 
\newcommand{\hcl}{{\TC hcl}} 
\newcommand{\pvar}{{\TC pvar}}  
\newcommand{\psort}{{\TC psort}}
\newcommand{\param}{{\TC param}}
\newcommand{\sort}{{\TC sort}}
\newcommand{\opsym}{{\TC opsym}} 
\newcommand{\rlsym}{{\TC rlsym}}
\newcommand{\semigsum}{{\TC sum}}
\newcommand{\semig}{{\TC semigroup}}
\newcommand{\Ring}{{\TC Ring}}
\newcommand{\cring}{{\TC comm\_ring}}
\newcommand{\infinite}{{\TC infinite}}
\newcommand{\Left}{{\TC Left}}
\newcommand{\Right}{{\TC Right}}
\newcommand{\Poly}{{\TC Poly}}
\newcommand{\reg}{{\TC reg}}
\newcommand{\cn}{{\TC const}}
\newcommand{\univ}{{\TC univ}}
\newcommand{\Ptor}{{\TC Ptor}}
\newcommand{\Tcon}{{\TC Tcon}}
\newcommand{\Tp}{{\TC Tp}}
\newcommand{\Val}{{\TC Val}}
\newcommand{\Pval}{{\TC Pval}}
\newcommand{\aex}{{\TC aex}}
\newcommand{\bex}{{\TC bex}}
\newcommand{\set}{{\TC set}}
\newcommand{\nfset}{{\TC nfset}}
\newcommand{\fset}{{\TC fset}}
\newcommand{\cset}{{\TC cset}}
\newcommand{\func}{{\TC func}}
\newcommand{\Fun}{{\TC Fun}}
\newcommand{\Funpred}{{\TC Funpred}}
\newcommand{\Bool}{{\TC{Bool}}}
\newcommand{\Unit}{{\TC{Unit}}}
\newcommand{\var}{{\TC var}} 
\newcommand{\lterm}{{\TC lterm}}
\newcommand{\trm}{{\TC trm}}
\newcommand{\trmHCL}{{\TC htrm}}
\newcommand{\gtrm}{{\TC gtrm}}
\newcommand{\abs}{{\TC abs}}
\newcommand{\absT}{{\TC abs2}}
\newcommand{\env}{{\TC env}}
\newcommand{\valType}{{\TC val}}
\newcommand{\bag}{{\TC bag}}
\newcommand{\listt}{{\TC list}}


\newcommand{\List}{{\TC{List}}}
\newcommand{\ListOfTree}{{\TC ListOfTree}}
\newcommand{\ITree}{{\TC ITree}}
\newcommand{\Tree}{{\TC{Tree}}}
\newcommand{\TreeFSet}{{\TC Tree_\FSet}}
\newcommand{\TreeMSet}{{\TC Tree_\MSet}}
\newcommand{\CSet}{{\TC CSet}}
\newcommand{\MSet}{{\TC MSet}}
\newcommand{\FSet}{{\TC{FinSet}}}
\newcommand{\treeFF}{{\TC tree_{\tinyGap F}}}
\newcommand{\treeFI}{{\TC tree_{\tinyGap I}}}
\newcommand{\tree}{{\TC tree}}
\newcommand{\treeUFI}{{\TC tree_{\tinyGap UI}}}


\newcommand{\treeFFlist}{\treeFF\UN\listt}


\newcommand{\dvar}{{\TC dvar}}
\newcommand{\dterm}{{\TC dterm}}
\newcommand{\dabs}{{\TC dabs}}
\newcommand{\dabsT}{{\TC dabs2}}
\newcommand{\denv}{{\TC denv}}

\newcommand{\tvar}{{\TC tvar}}
\newcommand{\tterm}{{\TC tterm}}
\newcommand{\tabs}{{\TC tabs}}
\newcommand{\tabsT}{{\TC tabs2}}
\newcommand{\tenv}{{\TC tenv}}
\newcommand{\ctxt}{{\TC ctxt}}
\newcommand{\Hctxt}{{\TC Hctxt}}

\newcommand{\HOASD}{{\mathsf{HOAS\UN{}View\UN{}D}}}
\newcommand{\HOAST}{{\mathsf{HOAS\UN{}View\UN{}T}}}
\newcommand{\Inf}{{\mathsf{Inference}}}
\newcommand{\HOASInf}{{\mathsf{HOAS\UN{}Rep\UN{}Inference}}}
\newcommand{\HOASWork}{{\mathsf{HOAS\UN{}at\UN{}Work}}}

\newmuskip\originalthinmuskip
\originalthinmuskip=\thinmuskip
\thinmuskip=4mu \newmuskip\tinyGapMu
\tinyGapMu=2mu
\newcommand\tinyGap{\mskip\tinyGapMu}
\renewcommand\ldots{\mathinner{.\mskip\originalthinmuskip .\mskip\originalthinmuskip .}}
\renewcommand\cdots{\mathinner{{\cdot}\mskip\originalthinmuskip {\cdot}\mskip\originalthinmuskip {\cdot}}}

\setlength{\fboxsep}{1pt}
\newcommand\bb[1]{\fbox{}}
\newcommand{\LFP}{{\mathsf{LFP}}}
\newcommand{\GFP}{{\mathsf{GFP}}}
\newcommand\const[1]{{\ensuremath{\TC{#1}}}}
\newcommand\PARA[1]{\subsubsection*{#1}}
\newcommand\FUNCTOR[2]{\PARA{#1~\ensuremath{#2}\kern.05ex}} \newcommand{\OMEGA}{\textsc{mega}}

\newcommand\Smash[1]{\kern-200mm\smash{#1}\kern-200mm}
\newcommand\SubItem[2]{\indent\hbox to \leftmargini{\hfill#1\enskip}#2}

\newcommand\XDot{\raise1ex\hbox{\Large.\kern.1em}}

\newcommand\datatypeand{\hbox{}\keyw{and}}

\def\figurename{Fig\hbox{.}}

\def\JJ{\textbf{JJ}} 

\global\def\figurename{Figure}
\clearpage{}

\makeatletter

\DeclareSymbolFont{letters}{OML}{txmi}{m}{it} \bibliographystyle{myabbrv}

\EnableBpAbbreviations
\def\ScoreOverhang{1.5pt}
\def\proofSkipAmount{\vskip 0pt}
\def\defaultHypSeparation{\hskip0.75em}

\let\realS=\S
\def\S{Section~}
\def\refappproofs{Appendix~\ref{app-proofs}}
\def\refappemb{Appendix~\ref{app-emb}}

\begin{document}

\balancecolumns






\pagestyle{plain} 

\title{Foundational Extensible Corecursion}


\authorinfo{Jasmin Christian Blanchette}
{Inria Nancy \& LORIA, France \\ Max-Planck-Institut f\"ur Informatik, Saarbr\"ucken, Germany}
{\texttt{jablanch@inria.fr}}

\authorinfo{Andrei Popescu}
{Department of Computer Science,  \\
School of Science and Technology, \\
Middlesex University, UK
}
{\texttt{a.popescu@mdx.ac.uk}}

\authorinfo{Dmitriy Traytel}
{Technische Universit\"at M\"{u}nchen, Germany}
{\texttt{traytel@in.tum.de}}



\maketitle

\newcommand\XXX{\textbullet}
\newbox\boxHyph\setbox\boxHyph=\hbox{\textbf{-}}
\newbox\boxX\setbox\boxX=\hbox{\XXX}

\renewcommand\UrlFont{\tt}

\begin{abstract}
This paper presents a formalized framework for defining corecursive functions
safely in a total setting, based on corecursion up-to and
relational parametricity. The end product is a general corecursor that allows
corecursive (and even recursive) calls under well-behaved operations, including
constructors. Corecursive functions that are well behaved can be registered as
such, thereby increasing the corecursor's expressiveness.
The metatheory
is formalized in the Isabelle proof assistant and forms the core of a prototype
tool. The corecursor is derived from first
principles, without requiring new axioms or extensions of the logic.
\end{abstract}


\category{F.3.1}{Logics and Meanings of Programs}{Specifying and Verifying and Reasoning about Programs---Mechanical verification}
\category{F.4.1}{Mathematical Logic and Formal Languages}{Mathematical Logic---Mechanical theorem proving, Model theory}



\terms
Algorithms, Theory, Verification

{\raggedright \keywords
(Co)recursion,
parametricity,
proof assistants, \\
higher-order logic,
Isabelle
}



















\section{Introduction}
\label{sec-intro}

Total functional programming is a discipline that ensures computations
always terminate. It is invaluable in a proof assistant, where nonterminating
definitions such as  can yield
contradictions. Hence, most assistants will accept recursive functions
only if they can be shown to terminate. Similar concerns arise in specification
languages and verifying compilers.


However, some processes need to run forever, without their being inconsistent.
An important class of total programs has been identified under the heading of
\emph{productive coprogramming}
\cite{turner-1995,abbott-et-al-2005,mcbride-productive}: These
are functions that progressively reveal parts of their (potentially infinite)
output. For example, given a type of infinite streams constructed by ,
the definition

falls within this fragment, since each call to \const{natsFrom} produces one
constructor before entering the nested call. Not only is the equation
consistent, it also fully specifies the function's behavior.

The above definition is legitimate only if objects are allowed to be infinite.
This may be self-evident in a nonstrict functional language such as Haskell, but
in a total setting we must carefully distinguish between the well-founded
inductive (or algebraic) datatypes and the non-well-founded
coinductive (or coalgebraic) datatypes---often simply called
\emph{datatypes} and \emph{codatatypes}, respectively.
\emph{Recursive} functions consume datatype values, peeling off a finite number
of constructors as they proceed; \emph{co\-recursive} functions produce
codatatype values, consisting of finitely or infinitely many constructors. And
in the same
way that \emph{induction} is available as a proof principle to reason about
datatypes and terminating recursive functions, \emph{coinduction}
supports reasoning over codatatypes and productive corecursive functions.

Despite their reputation for esotericism, codatatypes have an
important role to play in both the theory and the metatheory of programming. On
the theory side, they allow a direct embedding of a large class of
nonstrict functional programs in a total logic. In conjunction
with interactive proofs and code generators, this enables certified functional programming \cite{benton-integrated}.
On the metatheory side, codatatypes conveniently capture infinite, possibly
branching processes. Major proof developments rely on them, including those
associated with a C compiler \cite{leroy-2009}, a Java compiler
\cite{lochbihler-2010-jinja}, and the Java memory model
\cite{lochbihler-2014-jmm}.
\leftOut{Beyond
programming, a number of papers illustrate how coinductive methods can lead to
more elegant solutions than traditional approaches. A recent instance is a formal proof
of the completeness theorem for classical first-order logic
\cite{blanchette-et-al-2014-compl}, failed attempts at finding a proof give rise to
based on possibly infinite derivation trees.}

\newcommand\NOCITE[1]{}

Codatatypes are supported by an increasing number of proof assistants, including
Agda\NOCITE{bove-et-al-2009}, Coq\NOCITE{bertot-casteran-2004},
Isabelle\slash HOL\NOCITE{nipkow-et-al-2002},
Isabelle\slash ZF\NOCITE{paulson-1993-zf,paulson-1995-zf}, Matita\NOCITE{asperti-et-al-2011},
and PVS\NOCITE{crow-et-al-1995}. They are also present in
the CoALP dialect of logic programming\NOCITE{heras-et-al-201x} and in
the Dafny specification language\NOCITE{leino-moskal-2014}.
But the ability to introduce codatatypes is not worth much without adequate support
for defining meaningful functions that operate on them. For most systems, this support
can be characterized as work in progress. The key question they all must answer is:
\emph{What right-hand sides can be safely allowed in a function definition?}


Generally, there are two main approaches to support recursive and corecursive
functions in a proof assistant or similar system:
\begin{description}
\item[The intrinsic approach:]
A syntactic criterion is built into the logic:\ termination for recursive
specifications, productivity (or guardedness) for corecursive specifications.
The termination or productivity checker is part of the system's trusted code
base.

\item[The foundational approach:]
The (co)recursive specifications are reduced to a fixpoint construction,
which permits a simple definition of the form \,,
where \const{f} does not occur in the right-hand side.
The original equations are derived as theorems from this internal definition,
using dedicated proof tactics.
\end{description}
Systems favoring the intrinsic approach
include the proof assistants Agda and Coq, as well
as tools such as CoALP and Dafny. The main hurdle for their
users is that syntactic criteria are inflexible; the specification must be
massaged so that it falls within a given
syntactic fragment, even though the desired
property (termination or productivity) is semantic. But perhaps more troubling in
systems that process theorems, soundness is not obvious at all and very
tedious to ensure; as a result, there is a history of critical bugs in
termination and productivity checkers, as we will see when we review related work
(\S\ref{sec-rel}). Indeed, Abel \cite{abel-2013-coqml} observed that
\begin{quote}
Maybe the time is ripe to switch to a more semantical notion of termination and
guardedness. The syntactic guard condition gets you somewhere, but then needs a
lot of extensions and patching to work satisfactory in practice. Formal
verification of it becomes too difficult, and only intuitive justification is
prone to errors.
\end{quote}

In contrast to Agda and Coq, proof assistants based on higher-order logic (HOL),
such as HOL4, HOL Light, and Isabelle\slash HOL, generally adhere to the
foundational approach. Their logic
is expressive enough to accommodate the (co)algebraic constructions underlying
(co)datatypes and (co)recursive functions in terms
of functors on the category of sets \cite{traytel-et-al-2012}.
The main drawback of this approach is that
it requires a lot of work, both conceptual and implementational. Moreover, it
is not available for all systems, since it requires an expressive enough logic.


Because every step must be formally justified, foundational definitional
principles tend to be simpler and more restrictive than their intrinsic
counterparts. As a telling example, codatatypes were introduced in
Isabelle\slash HOL only recently, almost two decades after their inception in
Coq, and they are still missing from the other HOL systems; and corecursion is
limited to the primitive case, in which corecursive calls occur under exactly
one constructor.

That primitive corecursion (or the slightly extended version supported by Coq)
is too restrictive is an observation that has been made repeatedly by
researchers who use corecursion in Coq and now also Isabelle.
Lochbihler and H\"olzl dedicated a paper \cite{lochbihler-hoelzl-2014}
to ad hoc techniques for defining operations on corecursive lists in Isabelle.
Only after introducing a lot of machinery do they manage to
define their central example---\const{lfilter}, a filter function
on lazy (coinductive) lists---and derive suitable reasoning principles.

We contend that it is possible to combine advanced features as found in
Agda and Coq with the fundamentalism of Isabelle.
The lack of built-in support for corecursion, an apparent weakness, reveals
itself as a strength as we proceed to introduce rich notions of corecursion,
without extending the type system or adding axioms.


In this paper, we formalize a highly expressive corecursion framework that extends primitive
corecursion in the following ways:
It allows corecursive calls under several constructors;
it allows well-behaved operators in the context around or
between the constructors and around the corecursive calls;
importantly, it supports blending terminating recursive calls with guarded corecursive calls.
This general corecursor is accompanied by a corresponding, equally general
coinduction principle that makes reasoning about it convenient. Each of the
corecursor, mixed recursor--corecursor, and the coinduction principle
{\relax grow in expressiveness
during the interaction with the user}, by learning of new well-behaved contexts.
The constructions draw heavily from category theory.

Before presenting the technical details, we first show through examples how a
primitive corecursor can be incrementally enriched to accept ever richer
notions of corecursive call context (\S\ref{sec-exa}). This is made possible by
the modular bookkeeping of additional structure for the involved type constructors,
including a relator structure. This structure can be exploited
to prove parametricity theorems, which ensure the suitability of operators as participants to the call contexts, in the style
of coinduction up-to. Each new corecursive definition is a
potential future participant (\S\ref{sec-meta}).

This extensible corecursor gracefully
handles codatatypes with nesting through arbitrary type constructors (e.g., for
infinite-depth Rose trees nested through finite or infinite lists).
Thanks to the framework's modularity,
function specifications can combine corecursion with recursion, yielding quite expressive mixed fixpoint definitions (\S\ref{sec-mixed}).
This is inspired by the Dafny tool, but our approach is
semantically founded and hence provably consistent.






The complete metatheory is implemented in Isabelle\slash HOL, as a combination of a generic
proof development parameterized by arbitrary type constructors and a tool for instantiating
the metatheory to user-specified instances (\S\ref{sec-for}, \cite{our-formalization}).

Techniques such as corecursion and coinduction up-to have been
known for years in the process algebra community, before they were embraced and
perfected by category theorists (\S\ref{sec-rel}).
This work is part of a wider program aiming at bringing
insight from category theory into proof assistants
\cite{traytel-et-al-2012,blanchette-et-al-2014-impl}. The main contributions of this paper are the following:
\begin{itemize}
\item We represent in higher-order logic an integrated framework for recursion and corecursion
able to evolve by user interaction.





\item We identify a sound fragment of mixed recursive--corecursive
specifications, integrate it in our framework, and present several examples
that motivate this feature.

\item We implement the above in Isabelle/HOL within an interactive loop that maintains the recursive--corecursive infrastructure.

\item We use this infrastructure to automatically derive many examples that are
problematic in other proof assistants.
\end{itemize}

A distinguishing feature of our framework is that it does not require the user
to provide type annotations. On the design space, it lies
between the highly restrictive primitive corecursion and
the more bureaucratic up-to approaches such as clock variables
\cite{mcbride-productive,clouston-et-al-2015}
and sized types \cite{abel-2004}, combining expressiveness and ease of use.
The identification of this ``sweet spot'' can also be seen as a contribution.

\section{Motivating Examples}
\label{sec-exa}







We demonstrate the expressiveness of the corecursor framework by
examples, adopting the user's perspective. The case studies by
Rutten~\cite{rutten05} and Hinze~\cite{hinze10} on stream calculi serve as
our starting point. Streams of natural numbers can be defined as
\begin{quote}
  \keyw{codatatype} \,  
\end{quote}
where  is the constructor and ,  are its selectors.
Although the examples may seem simple or contrived, they were carefully
chosen to show the main difficulties that arise in practice.

\subsection{Corecursion Up-to}
\label{sec-uptoExa}

As our first example of a corecursive function definition,
we consider the pointwise sum of two streams:
\begin{quote}
  
\end{quote}
The specification is productive, since the corecursive call occurs directly
under the stream constructor, which acts as a guard (shown underlined).
Moreover, it is primitively corecursive, because the topmost symbol on the
right-hand side is a constructor and the corecursive call
appears directly as an argument to it.

These syntactic restrictions can be relaxed to allow conditional statements
and `let' expressions \cite{blanchette-et-al-2014-impl}, but despite
such tricks primitive corecursion remains hopelessly primitive.
The syntactic restriction for admissible corecursive definitions in Coq is more
permissive in that it allows for an arbitrary number of constructors to guard
the corecursive calls, as in the following definition:
\begin{quote}

\end{quote}

Our framework achieves the same result by registering  as a
well-behaved operation. Intuitively, an operation is \emph{well behaved} if it
needs to destruct at most one constructor of input to produce one
constructor of output.
For streams, such an operation may inspect the head and the tail
(but not the tail's tail) of its arguments before producing an .
Because the operation preserves productivity, it can safely
surround the guarding constructor.

The rigorous definition of well-behavedness will capture
this intuition in a parametricity property that must be discharged
by the user. In exchange, the framework yields
a strengthened corecursor that incorporates the new operation.

The constructor  is well behaved, since it does not even need to
inspect its arguments to produce a constructor.
In contrast, the selector  is not well behaved---it must destruct two
layers of constructors to produce one:
\begin{quote}

\end{quote}
The presence of non-well-behaved operations in the corecursive call context
is enough to break productivity, as
in the example , which stalls
immediately after producing one constructor, leaving  unspecified.

Another instructive example is the function that keeps every other element in a stream:
\begin{quote}
\kern200mm \end{quote}
The function is not well behaved, despite being primitive corecursive.
It also breaks productivity: 
stalls after producing two constructors.

Going back to our first example, we observe that the operation~ is well
behaved. Hence, it is allowed to participate in corecursive call contexts when
defining new functions. In this respect, the framework is more permissive than
Coq's syntactic restriction. For example, we can define the stream of Fibonacci
numbers in either of the following two ways:
\begin{quote}
 \1\jot]

\end{quote}
Next, we use the defined and registered operations to specify two streams of
factorials of natural numbers  (starting at 1) and  (starting
at 0):\begin{quote}
\-\jot]
&         \keyw{then}~\const{LNil} \-\jot]
&\quad         \keyw{then}~\const{LCons}\; (\hd\; \mathit{xs})\; (\const{lfilter}\; P\; (\tl\; \mathit{xs})) \2\jot]
  \kern-200mm \end{quote}
The step marked with  appeals to associativity and commutativity of  and
   as well as distributivity of  over . These properties are
  likewise proved by coinduction up-to. The implications marked with 
  and  are justified by the respective congruence rules. The last
  implication uses reflexivity and expands  to its closure .

  Finally, it is easy to see that  holds. Therefore, the thesis follows by coinduction up-to.
\end{proofx}

The formalization accompanying this paper \cite{our-formalization} also
contains proofs of
, , and
,
where  is the factorial on .

Nested corecursion up-to is also reflected with a suitable
strengthened coinduction rule.
For , this strengthening takes place
under the  operator on list, similarly to the corecursive calls
occurring nested in the  function:
\begin{center}
\AXC{\kern-1pt\strut} \AXC{\strut\kern-1pt} \BIC{}
\DP
\end{center}
The  operator lifts the binary predicate  to
a predicate . More precisely,
 holds if and only if  and  have the same length
and parallel elements of  and  are related by
. This nested coinduction rule is convenient provided there is
some infrastructure to descend under  (as is the case
in Isabelle\slash HOL). The formalization~\cite{our-formalization} establishes
several arithmetic properties of  and~.


\section{Extensible Corecursors}
\label{sec-meta}

We now describe the definitional and proof mechanisms that substantiate flexible corecursive definitions
in the style of \S\ref{sec-exa}.  They are based on the modular maintenance of
infrastructure for the corecursor associated with a codatatype, with the possibility of open-ended incremental improvement.
We present the approach for an arbitrary codatatype
given as the greatest fixpoint of an arbitrary (bounded) functor.
The approach is quite general
and does not rely on any particular grammar for specifying codatatypes.

Extensibility is an integral feature of the framework. In principle, an
implementation could redo the constructions from scratch each time a
well-behaved operation is registered, but it would give rise to a quadratic
number of definitions, slowing down the proof assistant. The incremental
approach is also more flexible and future-proof, allowing mixed fixpoints and
composition with other (co)recursors, including some that do not exist yet.



\subsection{Functors and Relators}
\label{sec-funcs-rels}

Functional programming languages and proof assistants
necessarily maintain a database of the user-defined
types or, more generally, type constructors, which
can be thought as functions  operating on sets (or perhaps on ordered sets).
It is often useful to maintain more structure along with these type constructors:
\begin{itemize}
\item a functorial action , i.e., a polymorphic function
of the indicated type that commutes with identity  and composition;
\item a relator , i.e.,
a polymorphic function of the indicated type which commutes with binary-relation identity and composition.
\end{itemize}
Following standard notation from category theory, we write  instead of .
Given binary relations  for , we
think of  as the natural
lifting of  along ; for example, if  is  (and hence ),
 lifts a relation on elements to the componentwise relation on lists (also requiring equal length). It is well known that the positive type constructors defined by standard means (basic types, composition, least or greatest fixpoints)
have canonical functorial and relator structure. This is crucial
for the foundational construction of user-specified (co)datatypes in Isabelle\slash HOL  \cite{traytel-et-al-2012}.

But even nonpositive type constructors 
exhibit a relator-like structure  (which
need not commute with relation composition, though).
For example, if  is the function-space constructor  and
, ,
, and ,
then  is defined as .
A polymorphic function ,  is called {\em parametric} \cite{rey-param,wadler-89}
if .
The maintenance of relator-like structures is very helpful for automating theorem transfer along isomorphisms and quotients
\cite{huffman-lifting}.
Here we explore an additional benefit of maintaining functorial and relator structure for type constructors:\
the possibility to extend the corecursor in reaction to user input.

In this section, we assume that all the considered type constructors are both functors and relators,
that they include
basic functors such as identity, constant, sum, and product, and that they are closed under
least fixpoints (initial algebras) and greatest fixpoints (final coalgebras).
Examples of such classes of type constructors include the datafunctors \cite{hensel-interatedRecursion}, the containers \cite{abbott-et-al-2005},
and the bounded natural functors \cite{traytel-et-al-2012}. 

\leftOut{
\begin{figure}
\small

\vspace*{-2ex} \caption{An element  of  with content items }
\label{fig-elem}
\end{figure}
}

We focus on the case of a unary codatatype-generating functor .
The codatatype of interest will be its greatest fixpoint
(or final coalgebra)
.
This generic situation
already covers the vast majority of interesting codatatypes, since  can represent arbitrarily complex nesting.
For example,
if , then  corresponds to the  codatatype
presented in Section~\ref{sec-nest-exa}.
The extension to mutually defined codatatypes is straightforward but tedious.
Our examples will take  to be the  type from Section~\ref{sec-exa}, with
.

Given a set ,
it will be useful to think of the elements  as consisting of a {\em shape} together with
{\em content} that fills the shape with elements of .
If , the shape of  is  and the content is ;
if , the shape of  is the -slot
container  and the content consists of the 's.


According to this view,
for each , the functorial action associated with  sends any 
into an element  of the same shape as~ but with each content item  replaced by .
Technically, this view
can be supported by custom notions such as
containers \cite{abbott-et-al-2005} or, more simply, via a parametric function of type  that collects the content elements \cite{traytel-et-al-2012}.



\subsection{Primitive Corecursion}
\label{sec-prim}

The \keyw{codatatype} that defines 
also introduces the constructor and destructor bijections
 and  and the primitive corecursor
 characterized
by the equation .
In elements ,
the occurrences of content items  in the shape of 
captures the positioning of the corecursive calls.

\begin{eexample}\label{exa-prim} \rm
Modulo currying, the pointwise sum of streams  is definable as ,
by taking  to be .
\end{eexample}

In Example~\ref{exa-prim} and elsewhere, we lighten notation by identify
the curried and uncurried forms of functions, counting on implicit coercions
between the two.

\subsection{The Corecursion State}
\label{sec-state}

Given any functor , we define its {\em free-monad functor}  by .
We write  and  for the left and right injections
into .

The functions  and  are in fact polymorphic; for example,
 has type .
We often omit the set parameters of polymorphic functions if they can be inferred from the context, writing  and  instead of
 and .



At any given moment, we maintain the following data associated with , which we call a
{\em corecursion state}: \begin{itemize}
\item a finite number of functors  and, for each ,
a function ;
\item a polymorphic function .
\end{itemize}
We call the 's the {\em well-behaved operations} and define their
collective {\em signature functor} 
as , where 
is the standard embedding of  into .
We call  the {\em corecursor seed}.
The corecursion state is subject to the following conditions:
\begin{description}
\item[Parametricity:]  is parametric.
\item[Well-behavedness:] Each  satisfies the characteristic equation

\end{description}
The convolution operator  builds a function
 from
two functions  and ,
and  is the canonical
evaluation function defined recursively (using the primitive recursor associated with ):
\begin{quote}
\\
\eval\,(\talg\;z)\kern-\leftmargin
\end{quote}
(Note that, on the recursive call on the right , is applied to  via ``lifting'' it through the functor .)
Functions having the type of 
and additionally assumed parametric (or, equivalently, assumed to be natural transformations)
are known in category theory as ``abstract GSOS rules.''
They were introduced by Turi and Plotkin \cite{turi-plotkin97}
and further studied by Bartels \cite{BartelsGeneralizedCoind}, Jacobs \cite{jacobs06-distrib},
Hinze and James \cite{hinze-adventure},
Milius et al.\ \cite{milius-modular}, and others.



Thus, a corecursion state is a triple .
As we will see in \S\ref{sec-adv}, the state {\em evolves} as users
define and register new functions.
The 's are the operations that have been registered as
safe for participating in the context of corecursion calls.
Since  has type , we think of  as encoding the arity of .
Then , the sum of the 's, represents the signature consisting of all the 's.
Thus, for each ,
 represents the set of formal expressions over  and , i.e., the trees built
starting from the ``variables'' in  as leaves by
applying operations symbols corresponding to the 's.
Finally,  evaluates in  the formal expressions of  by applying
the functions  recursively.

If the functors  are restricted to be finite monomials , the functor
 can be seen as a standard algebraic signature
and  as the standard term algebra for this signature, over the variables .
However, we allow  to be more exotic; for example, 
can be  (representing an infinitary operation) or one of  and 
(representing an operation taking a varying finite number of ordered or unordered arguments).

But what guarantees that the 's are indeed safe as contexts for corecursive
calls? In particular, how can the framework
exclude  while allowing , , and
? This is where the parametricity and well-behavedness conditions on
the state enter the picture.

We start with well-behavedness.
Assume , which is unambiguously represented in  as .
Let  be the content items of  (placed in various slots
in the shape of ). To evaluate  on ,
we first corecursively destruct the 's while also keeping the originals, thus replacing each  with
.
Then we apply the transformation  to obtain an element of , which has an -shape at the top
(the first produced observable data) and for each slot in this shape an element of ,
i.e., a formal-expression tree having leaves in  and built using operation symbols from the signature
(the corecursive continuation):

In summary,  is a schematic representation of the mutually corecursive behavior of the well-behaved operations
up to the production of the first observable data.
This intuition is made formal in the well-behavedness condition, which states that the diagram in Figure~\ref{fig-reg} commutes for each . (We could replace the right upward arrow labeled by  with a downward arrow labeled by  without changing the diagram's meaning.
However, we consistently prefer the constructor view in our exposition.)


In the above explanations, we saw that it suffices to peel off one layer of
the arguments  (by applying )
for a well-behaved operation
 to produce, via , one layer of the result and to delegate the rest of the computation to a context consisting of a combination of well-behaved
operations (an element of ). But how to formally express that exploring one layer is enough, i.e., that applying 
to 
does not result in a deeper exploration? An elegant way of capturing this is to require that , which is a polymorphic function,
operates without analyzing , i.e., that it
operates in the same way on  for any set . This
requirement is precisely parametricity.

Strictly speaking, the well-behaved operations  are a redundant piece of data in the state ,
since, assuming  parametric, we can prove that there exists a unique tuple  that satisfies the well-behavedness condition.
In other words, the operations  could be derived on a per-need basis.





\begin{figure}

\vspace*{-1ex} \caption{The well-behavedness condition}
\label{fig-reg}
\end{figure}


\begin{eexample}\rm \label{exa-state}
Let  and assume that  and
 are the only well-behaved operations registered so far.
Then ), ,
, and .
Moreover, 
consists of formal-expression trees with leaves in  and built using
arity-correct applications of operation symbols corresponding to
 and , denoted by  and .  Given  and ,
an example of such a tree is .
If additionally , then  applied to the above tree is .

But what is ? As we show below, we need not worry about the global definition of , since both  and  will be updated
{incrementally} when registering new operations as well behaved.
Nonetheless, a global definition of  for  and  follows:

Informally,  and  exhibit the following behaviors:
\begin{itemize}
\item to evaluate  on a number  and an item  with ,
produce  and evaluate  on  and , i.e.,
output ;
\item to evaluate  on  with  and ,
produce  and evaluate  on  and , i.e., output
.
\end{itemize}
\end{eexample}

\subsection{Corecursion Up-to}
\label{sec-corec-princ}

A corecursion state  for an -defined codatatype  consists of a collection of operations
on , , that satisfy the well-behavedness properties
expressed in terms of a parametric function .
We are now ready to harvest the crop of this setting:\ a corecursion principle
for defining functions having  as codomain.

\begin{figure*}
        \centering
        \begin{subfigure}[b]{0.175\textwidth}
\centering

                \caption{Primitive corecursion}
                \label{fig-prim-corec}
        \end{subfigure}\quad
        \begin{subfigure}[b]{0.325\textwidth}
\centering

                \caption{Top-guarded corecursion up-to}
                \label{fig-top-guarded-corec}
        \end{subfigure}
        \quad
        \begin{subfigure}[b]{0.425\textwidth}
\centering

                \caption{Flexibly guarded corecursion up-to}
                \label{fig-flexibly-guarded-corec}
        \end{subfigure}
        \caption{The corecursors}\label{fig-corec}
\end{figure*}


The principle will be represented by two corecursors,  and . Although
subsumed by the latter, the former is interesting in its own right and will
give us the opportunity to illustrate some fine points. Below
we list the types of these corecursors
along with that of the primitive corecursor for comparison:
\begin{description}
\item[Primitive corecursor:]
\ \\\hspace*{3ex}

\item[Top-guarded corecursor up-to:]
\ \\\hspace*{3ex}

\item[Flexibly guarded corecursor up-to:]
\ \\\hspace*{3ex}

\end{description}
Figure~\ref{fig-corec} presents the diagrams whose commutativity properties give
the characteristic equations of these corecursors.

Each corecursor implements a contract of the following form:
If, for each , one provides the intended corecursive behavior of  represented as ,
where  is a function
from~,
one obtains the function  (as the corresponding corecursor applied to ) satisfying a suitable fixpoint equation matching this behavior.

The codomain of  is the key to understanding the expressiveness of each corecursor.
The intended corecursive calls are represented by ,
and the call context is represented by the surrounding
combination of functors (involving , , or both):
\begin{itemize}
\item for , the allowed call contexts consist of a single constructor guard (represented by~);
\item for , they consist of a constructor guard (represented by~) followed by any combination of well-behaved
operations  (represented by );
\item for , they consist of any combination of well-behaved operations
satisfying the condition that on every path leading to a corecursive call there exists at least one constructor guard
(represented by ).
\end{itemize}
We can see the computation of 
by following the diagrams in Figure~\ref{fig-corec} counterclockwise from their left-top corners.
The application  first builds the call context {syntactically}.
Then  is applied corecursively on the leaves.
Finally, the call context is evaluated:\ for , it consist only of the guard ();
for , it involves the evaluation of the well-behaved operators (which may also include several occurrences of the guard)
and ends with
the evaluation of the top guard;
for , the evaluation of the guard is
interspersed with that of the other well-behaved operations.


\begin{eexample}\rm \label{exa-defUpToInst}
For each example from \S\ref{sec-uptoExa}, we give
the corecursors that can handle it (assuming the
necessary well-behaved operations were registered):

With the usual identification of  and , we can define
 and  as follows:
\begin{quote}
\kern-200mm \
  \begin{array}{@{}l@{}}
    \phantom{{=}\;}\fibA \\{=}\hfill\mbox{\{by the commutativity of Figure~\ref{fig-top-guarded-corec}\phantom{\}}}\\
	\phantom{=}\hfill\mbox{\phantom{\{}with \ensuremath{\fibA = \corecU\;s}\}} \\\phantom{{=}\;}\ctor\,(\F\,(\eval \mathrel\circ \SS^*\;\fibA)\,s) \\{=}\hfill\mbox{\{by the definitions of  and \}}\\\phantom{{=}\;}\SCons\;0\;((\eval \mathrel\circ \SS^*\;\fibA)\;
      (\bb{\SCons}(1,\Call) \,\bb{\opls}\, (\Call))) \\{=}\hfill\mbox{\{by the definition of \}}\\\phantom{{=}\;}\SCons\;0\;(\eval \, (\bb{\SCons}(1,\Call\;\fibA) \,\bb{\opls}\, (\Call\;\fibA))  \\{=}\hfill\mbox{\{by the definition of \}} \\\phantom{{=}\;}\SCons\;0\;(\SCons\;1\;\fibA \vvthinspace\opls\vvthinspace \fibA)
  \end{array}
  
\xymatrix@C=2pc@R=3pc{
 \F\,(A \times \F\;A)
\ar^{\l}[r]
\ar_{\F\;\snd}[d]    &  \F\,(\F^*A)
                   \\
\F\,(\F\;A)
\ar^{\F\;(\F\;\eta)}[r]  &  \F\;(\F\;(\F^*A)) \ar^{\F\;\talg}[u]
}
s = (\lambda (\xs,\ys).~(\!\begin{aligned}[t]
  & \hd\;\xs \times \hd\;\ys, \
}
The function  decomposes into , where

is defined by
,
which is clearly parametric.
The act of determining  from
 and 
is syntax-directed.
\end{eexample}










\subsection{Coinduction Up-to}
\label{sec-coind}


In a proof assistant, specification mechanisms are not very useful unless
they are complemented by suitable reasoning infrastructure.
The natural counterpart of corecursion up-to is coinduction up-to.
In our incremental framework, the expressiveness of coinduction up-to grows
together with that of corecursion up-to.

We start with structural coinduction \cite{rutten00}, allowing to prove two elements of  equal by exhibiting an -bisimulation,
i.e., a binary relation  on  such that whenever two elements  and  are related, their
-unfoldings are componentwise related by .
\begin{center}
\AXC{}
\AXC{}
\BIC{}
\DP
\end{center}
Recall that our type constructors are not only functors but also relators.
The notion of ``componentwise relationship'' refers to 's relator structure .

Upon integrating a new operation  (Section~\ref{sec-adv}), the coinduction rule is made more flexible
by allowing the -unfoldings to be componentwise related not only by  but more generally
by a closure of  that takes  into account.

For a corecursion state  and a relation ,
we define , the -congruence closure of , as the smallest equivalence relation
that includes  and is compatible with each :

where  is the relator associated with .

The next theorem supplies the reasoning counterpart of the definition principle stated in
Theorem~\ref{corec-char}. It can be inferred from recent, more abstract results \cite{rot-uptoCoind}.


\begin{theorem}\rm \label{th-coindUpTo}
The following coinduction rule up to  holds in the corecursion state :
\begin{center}
\AXC{}
\AXC{}
\BIC{}
\DP
\end{center}
\end{theorem}
Coinduction up to  is the ideal abstraction for proving equalities involving functions defined by corecursion up to :
For example, a proof of commutativity for  naturally relies on contexts involving , because
's corecursive behavior (i.e., 's -unfolding) depends on .


\section{Mixed Fixpoints}
 \label{sec-mixed}








\begin{figure*}
\centering
        \begin{subfigure}[b]{0.52\textwidth}
\centering

                \caption{Assumption}
                \label{fig-mixed-asm}
        \end{subfigure}\enskip\quad
\vspace*{1ex}
\hspace*{1ex}
                \begin{subfigure}[b]{0.43\textwidth}

                \caption{Conclusion}
                \label{fig-mixed-concl}
        \end{subfigure}\vspace*{-2ex}
\caption{Mixed fixpoint}
\label{fig-mixed}
\end{figure*}



When we write fixpoint equations to define a function , we often want to
distinguish corecursive calls from calls that are sound for other reasons---for
example, if they terminate.
We model this situation abstractly
by a function . As usual for each ,
the shape of  represents the calling context for , with the occurrences of
the content items  in  representing calls to . The new twist is that we now distinguish
guarded calls (captured by the left-hand side of ) from possibly unguarded ones
(the right-hand side of ).




We want to define a function  with the behavior indicated by , i.e., making the diagram in Figure~\ref{fig-mixed-concl} commute.
In the figure,
 denotes the map function
 built from two functions  and .
In the absence of pervasive guards, we cannot employ the corecursors directly to
define .
However, if we can show that the noncorecursive calls eventually lead to a corecursive call, we will be able to employ .
This precondition can be expressed in terms of a fixpoint equation.
According to Figure~\ref{fig-mixed-asm},
the call to  (shown on the base arrow) happens only on the right-hand side of , meaning that the intended
corecursive calls are ignored when ``computing'' the fixpoint .
Our goal is to show that the remaining calls behave properly.

The functions  and  that complete the diagrams of Figure~\ref{fig-mixed}
are the expected ones:
\begin{itemize}
\item The elements of  are formal-expression trees guarded on every path to the leaves,
and so are the elements , but with a more restricted shape;
 embeds the latter in the former: , where  is the standard join
operation of the -monad.
\item  evaluates all the formal operations of :

\end{itemize}



\begin{theorem}\rm \label{thm-mixed}
If there exists (a unique)  such that the diagram in Figure~\ref{fig-mixed-asm} commutes,
there exists (a unique)  such that the diagram in Figure~\ref{fig-mixed-concl} commutes, namely,
.
\end{theorem}

The theorem certifies the following procedure for making sense of a mixed fixpoint definition of a function :
\begin{enumerate}
\item Separate the guarded and the unguarded calls (as shown in the codomain  of ).
\item Prove that the unguarded calls eventually terminate or lead to guarded calls (as witnessed by ).
\item Pass the unfolded guarded calls to the corecursor---i.e., take .
\end{enumerate}


\begin{eexample}\rm \label{exa-mixed}
The above procedure can be applied to define ,
, and ,
while avoiding the unsound  (\S\ref{sec-mix-exa}).
A simple analysis reveals that
the first self-call to  is guarded while the second is not.
We define
 by
\begin{quote}

\end{quote}
In essence,  behaves like (the intended)  except that the guarded calls are left
symbolic, whereas the unguarded calls are interpreted as actual calls to .
One can show that  is well defined by a standard termination argument.
This characteristic equation of 
is the commutativity of the diagram
determined by  as in Figure~\ref{fig-mixed-asm},
where  is
defined as follows
(with  and  being the left and right sum embeddings):
\begin{quote}

\end{quote}
Setting  yields the desired characteristic equation for

after simplification (cf.\ Example \ref{exa-state}).
\end{eexample}

The  example has all unguarded calls in tail form, which makes the associated function 
tail-recursive. This need not be the case, as shown by the  example,
whose unguarded calls occur under
the well-behaved operation . However, we do require that the unguarded calls occur in contexts formed by
well-behaved operations alone. After unfolding all the unguarded calls,
the resulting context that is to be handled corecursively
must be well behaved---this precludes unsound definitions like
. 


\section{Formalization and Implementation}
\label{sec-for}

We formalized in Isabelle/HOL the metatheory of Sections~\ref{sec-meta} and \ref{sec-mixed}.
Essentially, this means that the results have been proved
in higher-order logic
with Infinity, Choice, and a mechanism for defining
types by exhibiting non-empty subsets of existing types. The logic is
comparable to Zermelo set theory with Choice (ZC) but weaker than ZFC.
The development would work for any class of functors that are relators
(or closed under weak pullbacks), contain basic functors (identity,
(co)products, etc.) and are closed under intersection, composition, and
have initial algebras and final coalgebra that can be represented in higher-order logic.
However, our Isabelle development focuses on a specific class \cite{traytel-et-al-2012}.



The formalization consists of two parts: The \emph{base} derives a corecursor
up-to from a primitive corecursor; the \emph{step} starts with a corecursor
up-to and integrates an additional well-behaved operation.

The base part starts by axiomatizing a functor 
and defines a codatatype with nesting through :\,
\keyw{codatatype} \,  .
(In~general,  could depend on type variables, but this is an orthogonal concern that would only clutter the formalization.)
Then the formalization defines the free algebra over  and
the basic corecursor seed  for initializing the state with
 as well behaved (Section~\ref{sec-init}). It also needs to lift
 to the free algebra, a technicality that was omitted in the
presentation. Then it defines  and other necessary structure
(Section \ref{sec-state}). Finally, it introduces  and 
(Section~\ref{sec-corec-princ}) and derives the corresponding
coinduction principle (Section~\ref{sec-coind}).

From a high-level point of view, the step part has a somewhat similar structure to the base. It
axiomatizes a domain functor  and a parametric function  associated
with the new well-behaved operation  to integrate.
Then it extends the signature to include , defines the
extended corecursor seed , and lifts  to the free algebra.
Next, it defines the parameterized  and other infrastructure
(Section~\ref{sec-adv}). Finally, it introduces  and 
for the new state and derives the coinduction principle.

The process of instantiating the metatheory to particular user-specified codatatypes
is automated by a prototype tool: the user points to a particular codatatype (typically defined using
Isabelle's existing (co)datatype specification language \cite{blanchette-et-al-2014-impl}), and then the tool
takes over and instantiates the generic corecursor to the indicated type, provinding the concrete corecursion
and mixed recursion-corecursion theorems.
The stream and
tree examples presented in Section~\ref{sec-exa} have all been obtained with this tool.
As a larger case study, we formalized all the examples
from the extended version of Hinze and James's study \cite{hinze-adventure}. The parametricity proof obligations were discharged by Isabelle's
parametricity prover \cite{huffman-lifting}.
The mixed recursion--corecursion definitions were done using Isabelle's
facility for defining terminating recursive functions \cite{krauss-fun}.




Unlike Isabelle's {\relax primitive} (co)recursion mechanism \cite{blanchette-et-al-2014-impl},
our tool currently lacks syntactic sugar support,
so it still requires some boilerplate from the user, namely the explic invocation of the corecursor
and the parametricity prover: these are just a few extra lines of script per definition, and therefore the tool is
also usable in the current form.
Following the design of its primitive ancestor, its envisioned fully user-friendly extension will replace the explicit invocation of the
corecursor with a \keyw{corec} command,
allowing users to specify a function  corecursively and
then performing the following steps (cf.\ Example~\ref{exa-defUpToInst}):
\begin{enumerate}
\item Parse the specification of  and synthesize arguments to the
current, most powerful corecursor.
\item Define  in terms of the corecursor.
\item Derive the original specification from the corecursor theorems.
\end{enumerate}
Passing the \keyw{well\_behaved} option to \keyw{corec}
will additionally invoke the following procedure (cf.\ Example~\ref{exa-integrate}):
\begin{enumerate}
\item[4.] Extract a polymorphic function  from the specification of .
\item[5.] Automatically prove  parametric or pass the proof obligation to the user.
\item[6.] Derive the new strengthened corecursor and its new coinduction principle.
\end{enumerate}
The \keyw{corec} command will be complemented by an additional command,
tentatively called \keyw{well\_behaved\_for\_corec}, for registering arbitrary operations
 (not necessarily defined using
\keyw{corec}) as well behaved. The command will ask the user to provide a
corecursive specification of  as a lemma of the form
 \,and then perform steps 4~to~6.
The \keyw{corec} command will become
stronger and stronger as more well-behaved operations are registered.


The following Isabelle theory fragment gives a flavor of the envisioned functionality
from the user's point of view:

\begin{quote}
  \keyw{codatatype} \,  
\2\jot]
  \keyw{corec} (\keyw{well\_behaved})  \\
  \hbox{}\quad
\2\jot]
  \keyw{lemma} \textit{\_commute}:\enskip  \\
  \keyw{proof} (\textit{coinduction arbitrary}:\ \textit{xs ys rule}:\ \textit{stream.coinduct\_upto})\kern-200mm \\
  \hbox{}\quad\keyw{case} \textit{Eq\_stream} \\
  \hbox{}\quad\keyw{thus} \textit{?case} \keyw{unfolding} \textit{tail\_} \\
  \hbox{}\qquad\keyw{by} (\textit{subst} \textit{\_commute}) (\textit{auto intro}: \textit{stream.cl\_}) \\
  \keyw{qed}
\end{quote}






\section{Related Work}
\label{sec-rel}

There is a lot of relevant work, concerning both the metatheory and applications
in proof assistants and similar systems. We referenced some of the most closely
related work in the earlier sections. Here is an attempt at a more systematic overview.

\paragraph{Category Theory.}
The notions of corecursion and coinduction up-to started with process algebra
\cite{san-bis, RuttenProcAsTerms} before they were
recast in the abstract language of category theory
\cite{BartelsGeneralizedCoind,turi-plotkin97,klin11-bialgebras,milius-modular,jacobs06-distrib,rot-uptoCoind,hinze-adventure}.
Our approach owes a lot to this theoretical work, and indeed formalizes some state-of-the-art
category theoretical results on corecursion and coinduction up-to \cite{milius-modular,rot-uptoCoind}.
Besides adapting existing results to higher-order logic within an incremental corecursor cycle,
we have also extended the state of the art with a sound mechanism for mixing recursion with corecursion up-to.




Category theory provides an impressive body of {\relax abstract} results
that can be applied to solve concrete problems elegantly.
Proof assistants have a lot to benefit from category theory, as we hope to have demonstrated
with this paper.
There has been prior work on integrating coinduction up-to techniques from
category theory into these tools. Hensel and Jacobs
\cite{hensel-interatedRecursion} illustrated the categorical approach to
(co)data\-types in PVS via axiomatic declarations of various flavors of
trees with (co)recursors and proof principles. Popescu and Gunter proposed
incremental coinduction for a deeply embedded proof system in Isabelle\slash HOL
\cite{pop-Coind}. Hur et al.\ \cite{HurNDV13} extended Winskel's
\cite{winskel-nu} and Moss's \cite{moss-param} parameterized coinduction and
studied applications to Agda, Coq, and Isabelle\slash HOL. Endrullis et al.\
\cite{endrulis-circ} developed a method to perform up-to coinduction in Coq adapting insight from behavioral logic \cite{circCALCO09theory}.
To our knowledge, no prior work has realized corecursion up-to in a
proof assistant.

\paragraph{Ordered Structures and Convergence.}
A number of approaches to define functions on infinite types are based on domain
theory, or more generally on ordered structures and notions of convergence, including Matthews
\cite{matthews-rec-coind}, Di~Gianantonio and Miculan \cite{miculan-unifying},
Huffman \cite{huffman-2009}, and Lochbihler and H\"olzl
\cite{lochbihler-hoelzl-2014}. These are not directly comparable to our work
because they do not guarantee productivity or otherwise offer total programming.
They also force the user to switch to a different, richer universe of domains or
to define ordered structures and perform continuity proofs (although Matthews
shows that this process can be partly automated).



Strictly speaking, our approach does not guarantee productivity either. This is an
inherent limitation of the semantic
(shallow embedded)
approach in HOL systems, which do not specify a computational model (unlike Agda and Coq).
Productivity can be argued informally by inspecting the characteristic corecursion equations.


\paragraph{Syntactic Criteria.}
Proof assistants based on type theory include checkers for termination of
recursion functions and productivity of corecursive functions. These checkers
are part of the system's trusted code base; bugs can lead to inconsistencies, as
we saw for Agda \cite{traytel-2014-agda} and Coq \cite{denes-2013-coqml}.\footnote{In all fairness, we should mention that critical bugs were also
found in the primitive definitional mechanism of our proof assistant of
choice, Isabelle \cite{kuncar-2015-cpp}. Our point is not that brand B is superior to brand A, but
rather that it is generally desirable to minimize the amount of trusted code.}
\,For users, such syntactic criteria are also inflexible; for example, Coq allows
more than one constructor to appear as guards but is otherwise limited to
primitive corecursion.

To the best of our knowledge, the only deployed system that explicitly supports mixed
recursive--corecursive definitions is Dafny. Leino and
Moskal's paper \cite{leino-moskal-2014} triggered our interest in the topic.
Unfortunately, the paper is not entirely clear about the supported fragment. A naive
reading suggests that the inconsistent  example from
Section~\ref{sec-mix-exa} is allowed, as was the case with earlier versions of
Dafny. Newer versions reject not only  but also the legitimate
 function from the same subsection.

\paragraph{Type Systems.}
A more flexible alternative to syntactic criteria is to have users annotate
the functions' types with information that controls termination and
productivity. Approaches in these category include
fair reactive programming \cite{fra1,usrp1,cave-et-al-2014},
clock variables \cite{mcbride-productive,clouston-et-al-2015}, and
sized types \cite{abel-2004}. Size types are implemented in
MiniAgda \cite{abel-2010-miniagda}
and in newer versions of Agda, in conjunction with a destructor-oriented
(copattern) syntax for corecursion \cite{abelP-2013}.
These approaches, often featuring a blend of type systems and notions of convergence, achieve a
higher modularity and trustworthiness, by moving away from purely syntactic
criteria and toward semantic properties.
By carefully tracking sizes and timers, they allow
for more general contexts than our well-behavedness criterion.
Our approach captures a 1--1 contract: A well-behaved
function can destroy one constructor to produce one. A function  that would,
map the stream  to  would have a 1--2
contract. And a function  mapping  to
 would require a 2--1 contract. The composition
 would yield a 1--1 contract and could in
principle appear in a corecursive call context, but our framework does not allow it.

Clock variables and sized types require an extension to the type system and
burden the types. These general contracts must be specified by the user and
complicate the up-to corecursion principle; the arithmetic that ensures that
contracts fit together would have to be captured in the principle, giving rise
to new proof obligations. In contrast, well-behaved functions can be freely
combined. This is the main reason why we can claim it is a ``sweet spot.''

There is a prospect of embedding our lighter approach into such heavier but more precise frameworks.
Our well-behaved
operators possibly form the maximal class of context functions
requiring no annotations (in general), amounting to a lightweight subsystem
of Krishnaswami and Benton's type system \cite{usrp1}.



\section{Conclusion}
\label{sec-conc}

We presented a formalized framework for deriving rich corecursors that can be used to
define total functions producing codatatypes. The corecursors gain in
expressiveness with each new corecursive function definition that satisfies a
semantic criterion. They constitute a significant improvement over the state of
the art in the world of proof assistants based on higher-order logic,
including HOL4, HOL Light, Isabelle\slash HOL, and PVS.
Trustworthiness is attained at the cost of elaborate constructions.
Coinduction being somewhat counterintuitive,
we argue that these safeguards are well worth the effort.
As future work, we want
to transform our prototype tool into a solid implementation inside
Isabelle\slash HOL. 



Although we emphasized the foundational nature of the framework, many of the
ideas equally apply to systems with built-in codatatypes and
corecursion. One could imagine extending the productivity check of
Coq to allow corecursion under well-behaved operations, linking a syntactic
criterion to a semantic property, as a lightweight alternative to
clock variables and sized types. The emerging infrastructure
for parametricity in Coq \cite{bernardy-et-al-2012-param,keller-lasson-2012}
would likely be a useful building block.








\paragraph{Acknowledgment.}
Tobias Nipkow made this work possible.
Stefan Milius guided us through his highly relevant work on abstract GSOS rules.
Andreas Abel and Rustan Leino discussed their tools and shared
their paper drafts and examples with us.
Mark Summer\-field suggested many textual improvements.
Reviewers provided useful comments and indicated related work.
Blanchette was supported by the Deutsche
Forschungs\-gemein\-schaft (DFG) project \relax{Hardening the Hammer} (grant
Ni\,491\slash 14-1).
Popescu was supported by the DFG project
\relax{Security Type Systems and Deduction} (grant Ni\allowbreak\,491\slash 13-2) as part
of the program \relax{Reliably Secure Software Systems} (RS\textsuperscript{3},
priority program 1496).
Traytel was supported by the DFG program \relax{Program and Model Analysis}
(PUMA, doctorate program 1480).
 The authors are listed alphabetically.


\begin{raggedright}
\small
\bibliography{bib}
\end{raggedright}



\end{document}
