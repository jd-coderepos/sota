\documentclass[11pt]{article}

\usepackage{fullpage}

\newtheorem{theorem}{Theorem}\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}

\newtheorem{definition}{Definition}\newtheorem{definitions}[definition]{Definitions}
\newtheorem{notation}[definition]{Notation}

\def\myendproof{\hfill{\vbox{\hrule\hbox{\vrule height1.3ex\hskip0.8ex\vrule}\hrule}}}

\newcommand\real{{\rm I\kern-0.2em\rm R}}
\newcommand\itreal{{\it I\kern-0.35em\it R}}

\newenvironment{proof}{

\noindent{\bf Proof:}\ }{
\hfill \myendproof

}

\newenvironment{opt}[2]{
\samepage
\renewcommand{\arraystretch}{1.3}

}

\newcommand{\mathfn}[1]{\mathop{\rm #1}\nolimits }
\newcommand{\maximize}{\mathfn{maximize}}
\newcommand{\minimize}{\mathfn{minimize}}
\newcommand{\val}{\mathfn{value}}

\title{A Bound on the Sum 
  \\ of Weighted Pairwise Distances
  \\ of Points Constrained to Balls
  \thanks{
    Technical Report \#1103,
    School of Operations Research and Industrial Engineering,
    College of Engineering, Cornell University, Ithaca NY.
    This research was partially supported by \'Eva Tardos' NSF PYI grant.}
}

\date{September 1994}

\author{
  Neal E. Young
}

\begin{document}

\maketitle

\begin{abstract}
  We consider the problem of choosing Euclidean points
  to maximize the sum of their weighted pairwise distances,
  when each point is constrained to a ball centered at the origin.
  We derive a dual minimization problem and show strong duality holds
  (i.e., the resulting upper bound is tight)
  when some locally optimal configuration of points is affinely independent.
  We sketch a polynomial time algorithm 
  for finding a near-optimal set of points.
\end{abstract}

\section{Introduction}
We consider the following maximization problem :
\begin{opt}{}{\sum_{1 \le i < j \le n} w(i,j)d(p_i, p_j)}
  p_i & \in & \real^{n-1}  & (i=1,..,n);
  \\ ||p_i|| & \le & \ell(i)     & (i=1,..,n).
\end{opt}
Here each  and each  is fixed, 
 denotes the Euclidean distance between points  and ,
and  denotes the Euclidean length (distance from the origin)
of point .

We derive the following dual problem :
\begin{opt}{}{
    \sqrt{\sum_{1\le i < j \le n} \frac{w^2(i,j)}{x_i x_j}}
    \times \sqrt{\sum_{i=1}^n \ell^2(i) x_i}
    \times \sqrt{\sum_{i=1}^n x_i}}
  x_i & \in & \real & (i=1,..,n);
  \\ x_i & \ge & 0     & (i=1,..,n).
\end{opt}
Throughout the paper,  is defined to be .

We show that the value of the maximization problem
is at most the value of the minimization problem.
We use a physical interpretation of the two problems to show that
the values are equal provided the maximization problem
admits a set of points  that is both affinely independent
and stationary
(i.e., the gradient of the objective function is a nonnegative combination
of the gradients of the active constraints,
a necessary condition at any local maximizer of ).

We sketch how a near-optimal solution to the problem
can be found in polynomial time via the ellipsoid method.

\section{Related Work}

The case 
(in which the optimal points are given by the vertices
of the regular -simplex, achieving a value of )
was previously considered by \cite{Li75}.
Our Lemma \ref{weak duality}
generalizes a bound in that paper.

Specific instances of  
were studied to obtain geometric inequalities 
that were used to analyze approximation algorithms
for finding low-degree, low-weight spanning trees
in Euclidean spaces \cite{KhullerRY94}.

Goemans and Williamson \cite{GoemansW94}
consider related problems with applications
to approximating the maximum cut in a graph
and to maximizing the number of satisfied clauses 
in a CNF formula.
We modify their approach to solving their problems
to obtain a polynomial time algorithm for ours.

\section{A Dual Problem}

\begin{lemma}
  For any , , and ,
  the value of the maximization problem 
  is at most the value of the minimization problem .
  \label{weak duality}
\end{lemma}
\begin{proof}
  Fix any , , and .
  Fix any set of points  and values 
  meeting the constraints of  and , respectively.
  Let 
  and 
  for .
  Then, by the Cauchy-Schwartz inequality 
  (where  and  are interpreted as -dimensional vectors,
  and  denotes the dot product):
  
  It remains only to show
  

  Expanding the left-hand side,
  
\end{proof}

\begin{lemma}
  Fix any , , and .
  Suppose the maximization problem 
  admits a set of points 
  that is both stationary and affinely independent.
  Then the values of the two problems are equal.
  Further, there exists  such that
  
  (where  in case ,
  and  and ),
  and  and  are global optima for the two problems.
  \label{strong duality}
\end{lemma}
\begin{proof}
  Fix any , , and .
  Consider the objective function 
  of .  That  is stationary
  means that the gradient of  is a nonnegative combination
  of the gradients of the constraints of  active at .
  By elementary calculus, 
  the gradient of  consists of a vector  for each point ,
  with each  equal to the right-hand side of (\ref{xeqn}).
  The only constraint on  is ,
  whose gradient (again by elementary calculus) 
  is a nonnegative multiple of .
  Thus, for each , there exists an  such that (\ref{xeqn}) holds.
  Note that if , then the constraint is not active,
  so that  must be the zero vector.
  In this case we take .

  We will show that each inequality in Lemma \ref{weak duality}
  is tight for these  and .
  Inequality (\ref{three}) is tight because, by (\ref{xeqn}),
   is the zero vector.
  Inequality (\ref{two}) is tight
  because  only if .
  
  Inequality (\ref{one}) is tight
  provided the vector  (in the proof of Lemma \ref{weak duality})
  is a scalar multiple of .
  Assume  is affinely independent.
  Then, considering  and  fixed
  and  as the set of unknowns (i.e., reversing their roles),
  (\ref{xeqn}) uniquely determines each .
  Since
  
  is consistent with (\ref{xeqn}) 
  (check this by substitution for  in (\ref{xeqn})),
  it follows that (\ref{weqn}) necessarily holds.
  Thus,  is a scalar multiple of  and Inequality (\ref{one}) is tight.
\end{proof}

A physical model for the quantities involved is as follows.
Consider a physical system of  points .
Each point  is constrained to a ball of radius  
centered at the origin.
For each pair of points ,
 repels  (and vice versa) with a force of magnitude .

Under this interpretation, 
each vector  in the proof corresponds to the force on ,
and  is the magnitude of this force, divided by .

\section{Solving  in Polynomial Time}

If the instance of  is small or has a high degree of symmetry,
the dual problem  might yield a function
that can be minimized directly by symbolic methods.
In general, 
it is possible to solve 
(to any given degree of precision)
in polynomial time using semi-definite programming,
following the approach in \cite{GoemansW94}.

Those authors consider a related problem :
\begin{opt}{}{
    \sum_{1 \le i < j \le n} w(i,j)d^2(p_i, p_j)}
  p_i & \in & \real^{n}  & (i=1,..,n);
  \\ \|p_i\| & = & 1     & (i=1,..,n).
\end{opt}
The authors show how to solve this problem in polynomial time
by formulating it as a semi-definite program,
and how to round a (near-)optimal set of points 
to obtain an approximate solution to a corresponding max-cut problem.
This approach yielded the first polynomial-time approximation algorithm
achieving a performance guarantee better than two for the max-cut problem.

We briefly sketch their aproach for solving 
and how it can be modified to solve .
The connection between sets of points 
and positive semi-definite matrices is the following:
an  symmetric matrix  is positive semi-definite
if and only if there exists a set of  points  in 
such that .
Thus,  is equivalent to following:
\begin{opt}{}{
    \sum_{ij} w(i,j)(2-2 Y_{ij})}
  Y & \mbox{\small is} & 
        \mbox{\small an  symmetric, positive semi-definite matrix};
  \\ Y_{ii} & = & 1     & (i=1,..,n).
\end{opt}

The space of  symmetric, positive semi-definite matrices
admits a polynomial time separation oracle
because a symmetric matrix  is positive semi-definite
if and only if  for each ,
and in fact it suffices to check each eigenvector  of .
Thus, combining the constraint that  is positive semi-definite
with arbitrary linear inequalities on the elements of 
yields a convex space with a polynomial time separation oracle.
Approximate feasibility of such a problem is testable in polynomial time
via the ellipsoid method.  
Thus,  can be solved to near-optimality in polynomial time.

A similar approach can be used to solve  in polynomial time.
In particular,  
corresponds to the following semi-definite program:
\begin{opt}{}{
    \sum_{ij} w(i,j)\sqrt{Y_{ii}+Y_{jj}-2 Y_{ij}}}
  Y & \mbox{is} & 
        \mbox{an  symmetric, positive semi-definite matrix};
  \\ Y_{ii} & \le & \ell(i) & (i=1,..,n).
\end{opt}
Since 
is a concave function in 
whose gradient can be computed in polynomial time,
the above program also admits a separation oracle
sufficient to solve it to near-optimality in polynomial time
using the ellipsoid method.

\section{Open Problems}
It would be interesting to obtain a more efficient algorithm
for solving  than is obtained by reducing to the ellipsoid method.
Especially interesting would be a primal-dual algorithm
along the lines of traditional ``combinatorial'' algorithms
for solving or approximating linear programs.
It is not clear how to achieve such algorithms 
in the semi-definite setting.

Similarly, the only known method for achieving a better factor than two
for the max-cut problem is by reduction to semi-definite programming.
Goemans and Williamson leave open the problem 
of finding a more efficient algorithm that beats a factor of two.
A more efficient algorithm for  (with each )
would solve this,
because applying their randomized rounding technique
to  also yields an approximation algorithm for max-cut
with performance guarantee better than two.

On the other hand, consider the generalization of 
in which the objective function is replaced by
 for some .
For , 
applying Goemans and Williamson's approach 
to this program rather than 
would provide a better approximation to max-cut.
Is the generalization solvable in polynomial time for some ?

\section{Acknowledgements}
Thanks to Michael Todd for helpful discussions 
and comments on an earlier draft of this paper.

\bibliographystyle{plain}
\bibliography{full,tech-report}

\end{document}
