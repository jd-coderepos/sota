

\documentclass[11pt,a4paper]{article}
\renewcommand{\familydefault}{\sfdefault}
\usepackage{float}
\usepackage{multirow}
\usepackage{color}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{capt-of}
\usepackage{ulem}
\usepackage{threeparttable}
\usepackage{placeins}
\usepackage{sistyle}
\usepackage{dblfloatfix}
\usepackage{soul}
\usepackage[table]{xcolor}
\usepackage[hidelinks,breaklinks]{hyperref}
\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{fullpage}



\newcommand{\bC}{\mathbb{C}}
\newcommand{\bF}{\mathbb{F}}
\newcommand{\bH}{\mathbb{H}}
\newcommand{\bZ}{\mathbb{Z}}
\newcommand{\bN}{\mathbb{N}}
\newcommand{\bQ}{\mathbb{Q}}
\newcommand{\bR}{\mathbb{R}}
\newcommand{\bT}{\mathbb{T}}
\newcommand{\cA}{\mathcal{A}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cD}{\mathcal{D}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cG}{\mathcal{G}}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\cK}{\mathcal{K}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cQ}{\mathcal{Q}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\cT}{\mathcal{T}}
\newcommand{\cU}{\mathcal{U}}
\newcommand{\cW}{\mathcal{W}}
\newcommand{\sF}{\mathscr{F}}

\newcommand{\eps}{\epsilon}

\newcommand{\ip}[2]{\langle#1,#2\rangle}
\newcommand{\iptwo}[2]{\langle#1,#2\rangle_{L^2}}
\newcommand{\norm}[1]{\left\Vert#1\right\Vert}
\newcommand{\abs}[1]{\left\vert#1\right\vert}
\newcommand{\absip}[2]{\left\vert\langle#1,#2\rangle\right\vert}
\newcommand{\psic}{{\psi^{\text{c}}}}
\newcommand{\Sim}{\operatorname{S}}




\title{A Haar Wavelet-Based Perceptual Similarity Index for Image Quality Assessment}
\author{Rafael~Reisenhofer\thanks{R. Reisenhofer is with the Working Group Computational Data Analysis, Universit\"at Bremen, Fachbereich 3, Postfach 330440, 28334 Bremen, Germany (e-mail: reisenhofer@math.uni-bremen.de).}
\and Sebastian~Bosse\thanks{S. Bosse is with the Fraunhofer Heinrich Hertz Institute (Fraunhofer HHI), 10587 Berlin, Germany (e-mail: sebastian.bosse@hhi.fraunhofer.de).} \and Gitta~Kutyniok\thanks{G. Kutyniok is with the Department of Mathematics, Technische Universit\"at Berlin, 10623 Berlin, Germany (e-mail: kutyniok@math.tu-berlin.de)}\and~Thomas~Wiegand\thanks{T. Wiegand is with the Fraunhofer Heinrich Hertz Institute
(Fraunhofer HHI), 10587 Berlin, Germany, and with the Image Communication Laboratory, Berlin Institute of Technology,
10587 Berlin, Germany (e-mail: thomas.wiegand@hhi.fraunhofer.de).}}

\date{}

\begin{document}
\maketitle


\begin{abstract}
In most practical situations, the compression or transmission of images and videos creates distortions that will eventually be perceived by a human observer. Vice versa, image and video restoration techniques, such as inpainting or denoising, aim to enhance the quality of experience of human viewers. Correctly assessing the similarity between an image and an undistorted reference image as subjectively experienced by a human viewer can thus lead to significant improvements in any transmission, compression, or restoration system. This paper introduces the Haar wavelet-based perceptual similarity index (HaarPSI), a novel and computationally inexpensive similarity measure for full reference image quality assessment. The HaarPSI utilizes the coefficients obtained from a Haar wavelet decomposition to assess local similarities between two images, as well as the relative importance of image areas. The consistency of the HaarPSI with the human quality of experience was validated on four large benchmark databases containing thousands of differently distorted images. On these databases, the HaarPSI achieves higher correlations with human opinion scores than state-of-the-art full reference similarity measures like the structural similarity index (SSIM), the feature similarity index (FSIM), and the visual saliency-based index (VSI). Along with the simple computational structure and the short execution time, these experimental results suggest a high applicability of the HaarPSI in real world tasks.
\end{abstract}




\section{Introduction}
\label{sec:intro}
Digital images and videos are omnipresent in daily life and the importance of
visual data is still growing: According to \cite{Cisco}, by 2020, nearly a million
minutes of video content is estimated to cross the internet every second.

Typically, video and image signals are intended to be ultimately viewed by
humans. For transmission or storage, most signals are compressed in
order to meet today's channel and/or storage demands. Compression as well 
as transmission errors can introduce distortions to video or image signals that are visible to human viewers. 
For evaluating or optimizing a transmission system or parts of it, e.g. by
controlling the rate-distortion trade-off of a video encoder, it is crucial to
measure the severity of distortions in a perceptually meaningful way.
Quality 'in a perceptually meaningful way' can only be measured reliably in
psychometric tests. In such tests, participants are asked to
rate the subjectively perceived quality of images
or videos that have previously been subject to some kind of distortion introducing processing. The quality ratings of individual participants can eventually be averaged 
to obtain a single mean opinion score (MOS) for each stimulus. 
However, although being the gold standard for assessing perceived quality such studies are expensive and time-consuming and not feasible at all for real-time 
tasks like optimizing or monitoring transmission systems. This has
been motivating research in computational image quality assessment for decades.

Image quality assessment methods typically belong to one of three categories
with different challenges and scopes of applications: Full reference (FR)
image quality assessment approaches require and utilize the availability of a reference image. Reduced reference (RR) methods exploit a small set of features extracted from
the reference image. No reference (NR) approaches estimate the perceived quality of a possibly distorted image
solely from the image itself \cite{Lin2011}.
Unconstrained NR IQA has the notion of being the holy grail of IQA and, when successful,
essentially replicates human abilities. 
It is, however, not a feasible approach for some applications such as, for example, encoder control for video compression. An NR quality metric used for rate-distortion optimization in a video encoder would steer the optimization towards coding decisions that remove any type of noise or artifacts. However, there are videos in which noise and artifacts were intentionally added to create a certain visual effect. As an example, the reader is invited to imagine a video encoder that removes film grain from the Quentin Tarantino movie \textit{The Hateful Eight} due to the application of an NR quality metric that penalizes ''noisy'' coding decisions. Such an encoder would change a deliberate artistic decision made by the filmmakers and thus deteriorate the viewing experience.


The simplest FR image quality metric is the mean
squared error (MSE), which is defined as the average of the squared differences of the reference and the distorted image. Although being widely used, it
does not correlate well with perceived visual quality \cite{Gir93}.
More sophisticated approaches towards perceptually accurate image quality
assessments (IQA) typically follow one of three strategies. \textit{Bottom-up}
approaches explicitly model various processing mechanisms of the human visual
system (HVS), such as masking effects \cite{Watsona1997}, contrast sensitivity
\cite{daly1990}, or just-noticeable-distortion \cite{Lubin1997,
jia2006estimating} in order to assess the perceived quality of images. For
instance, the adaptivity of the HVS to the magnitude of distortions is modeled
explicitly by the concept of most apparent distortion (MAD) \cite{LaCh2010} in order to apply
two different assessment strategies for supra- and near-threshold distortions.      
 
However, the method proposed in this paper as well as most image quality
metrics developed recently follow a \textit{top-down} approach. There, general
functional properties of the HVS (considered as a black box) are assumed in
order to identify and to exploit image features corresponding to the perceived
quality. Prominent examples are the structural similarity index (SSIM)
\cite{WBSS2004}, visual information fidelity (VIF) \cite{ShBo2006}, the gradient
similarity measure (GSM) \cite{LLN2012}, spectral residual based similarity
(SR-SIM) \cite{ZhLi2012}, and the visual saliency-induced index (VSI)
\cite{ZSL2014}.   
The SSIM \cite{WBSS2004} aims at taking into account the sensitivity of the human
visual system towards structural information. This is done by pooling three
complementary components, namely luminance similarity (comparing local mean
luminance values), contrast similarity (comparing local variances) and
structural similarity, which is defined as the local covariance between the
reference image and its perturbed counterpart. Although being criticized
\cite{DoYa2011}, it is highly cited and among the most popular image quality
assessment metrics.  
The SSIM was generalized for a multi-scale setting by the multi-scale structural
similarity index (MS-SSIM) \cite{WSB2003}. 
One of the first information theoretic approaches to FR IQA was presented as visual information fidelity (VIF) \cite{ShBo2006}. VIF models the wavelet coefficients as Gaussian Scale Mixtures and quantifies the mutual information shared between reference and test images. The information theoretic measure of mutual information is  shown to be correlated to perceived image quality.
Changes in contrast and structure are captured by
considering local gradients in \cite{LLN2012}, while the squared difference in
pixel values between the reference image and the distorted image is used to
measure luminance variations. This approach thus follows the basic framework of combining complementary feature maps originally introduced
in \cite{WBSS2004}. Additionally, masking effects are estimated, based
on the local gradient magnitude of the reference image and incorporated when the
two feature maps are combined.  
Spectral residual-based similarity (SR-SIM) \cite{ZhLi2012} takes into account
changes in the local horizontal and vertical gradient magnitudes. Additionally,
it incorporates changes in a spectral residual-based visual saliency estimate.  
The visual saliency-induced index (VSI) \cite{ZSL2014} follows the same line as
SR-SIM by combining similarities in the gradient magnitude and the visual
saliency.  However, it further exploits the visual saliency map for weighting
the spatial similarity pooling. Furthermore, \cite{ZSL2014} also explores the
influence of different saliency models on the performance of the proposed image
quality measure.  
A combination of two feature maps is also applied successfully by the feature
similarity index (FSIM) \cite{ZZMZ2011}. Due to its conceptual similarity to
the proposed method, it will be discussed in more detail in a later section.


Adopting the advances in machine learning and data science, IQA methods
following a third, purely \textit{data driven} strategy have been proposed
recently. So far, data driven approaches were mainly developed for the domain of
NR IQA \cite{Kang2014,Ye2012,Zhang2015,bosse2016dnnNrIqa}, but they have also
been adapted in the context of FR IQA \cite{bosse2016dnnFrIqa}.   



\subsection{Contributions}

This work introduces the Haar wavelet-based perceptual similarity index
(HaarPSI), a novel and computationally inexpensive measure yielding FR image
quality assessments. The HaarPSI utilizes the magnitudes of high-frequency Haar wavelet coefficients to define local similarities and low-frequency Haar wavelet coefficients to weight the importance of (dis)similarities at specific locations in the image domain.

{The six discrete two-dimensional Haar wavelet filters used in the definition of the HaarPSI respond to horizontal and vertical edges on different frequency scales. The HaarPSI is thus based on elementary implementations of functional properties known to be exhibited by neurons in the primary visual cortex, namely orientation selectivity and spatial frequency selectivity. We aim to demonstrate that such a simple model already suffices to define a similarity measure that yields state-of-the-art correlations with human opinion scores.}

The HaarPSI can also be seen as a drastic simplification of the FSIM \cite{ZZMZ2011}, which is based on a similar combination of similarity and weight maps. In the definition of the FSIM, both local similarities and weights rely on the phase congruency measure \cite{Kov2000}, whose computation requires images to be convolved with 16 complex-valued filters and contains several non-trivial steps such as adaptive thresholding. For the HaarPSI on the other hand, the two maps are computed from the responses of only six discrete Haar wavelet filters and are cleanly separated in the sense that local similarities and weights are based on different frequency scales. Surprisingly, these simplifications not only decrease the required computational effort but also lead to consistently higher correlations with human mean opinions scores.

In Section~\ref{sec:results}, we evaluate the consistency of the HaarPSI with the human
quality of experience and compare its performance to state-of-the-art similarity
measures like SSIM \cite{WBSS2004}, FSIM \cite{ZZMZ2011}, and VSI
\cite{ZSL2014}. As depicted in
Tables~\ref{tab:sroccdatabases}~and~\ref{tab:overallperf}, the HaarPSI achieves
higher correlations with human opinion scores than all other considered FR
quality metrics in all test cases except one, where it only comes second to the VSI.
In addition, the HaarPSI can be computed significantly faster than the metrics yielding the
second and third highest correlations with human opinion scores, namely VSI and
FSIM.    
In  order  to  facilitate reproducible research, our Matlab implement of the HaarPSI is publicly available
at \url{http://www.haarpsi.org/}.

It is both convenient and surprising that the promising experimental results of the HaarPSI are based on the responses of Haar filters,
which are arguably the simplest and computationally most efficient wavelet filters existing. The results of a numerical analysis of the applicability
of other wavelet filters in the newly proposed similarity measure can be found in Table~\ref{tab:otherwavelets}.  



\subsection{The Feature Similarity Index (FSIM)}
The feature similarity index (FSIM) \cite{ZZMZ2011}, proposed in 2011, is currently one of the most successful and influential FR image quality metrics. The FSIM combines two feature maps derived from the phase congruency measure \cite{Kov2000} and the local gradients of the reference and the distorted image to assess local similarities between two images. For a grayscale image , the gradient map is defined by  

where  and  denote horizontal and vertical gradient filters (e.g. Sobel or Scharr filters), and  denotes the two-dimensional convolution operator. The method used in the implementation of the FSIM to compute the phase congruency map was developed by Peter Kovesi \cite{KovONLINE} and contains several non-trivial operations, such as adaptive soft thresholding. However, in its essence, the phase congruency map of a grayscale image  is given by 


where  denotes differently scaled and oriented complex-valued wavelet filters. The idea behind \eqref{eq:pc} is that if the obtained complex-valued wavelet coefficients have the same phase at a location , taking the absolute value of the sum is the same as taking the sum of the absolute values. If this is the case,  will be close to or precisely . 

To assess local similarities between two images with respect to the maps defined in \eqref{eq:grad} and \eqref{eq:pc}, the FSIM - like many other image quality metrics - uses a simple similarity measure for scalar values that already appeared in \cite{WBSS2004}, namely

with a constant . The graph of  for values ranging from  to  and  is shown in Figure~\ref{fig:scalarsim}. The local feature similarity map for two grayscale images  is defined by
\setlength{\arraycolsep}{0.0em}

\setlength{\arraycolsep}{5pt}
with constants  and exponents . Based on the assumption that the human visual system is especially sensitive towards structures at which the phases of the Fourier components are in congruency (see e.g. \cite{MRBO1986}), the phase congruency map is not only used in \eqref{eq:localfs} but also applied to determine the relative importance of different image areas with respect to human perception. Eventually, the feature similarity index is computed by taking the weighted mean of all local feature similarities, where the phase congruency map is used as a weight function, that is

where


The original publication of the FSIM proposes a generalization to color images defined in the YIQ color space, named FSIMC. In the YIQ space, the Y channel encodes luminance information, while the I and Q channels encode chromatic information. Color images defined in the RGB color space can easily be transformed to the YIQ space with a linear mapping, namely



FSIMC simply incorporates the chroma channels I and Q into the local feature similarity measure \eqref{eq:localfs}. The gradient maps as well as the phase congruency maps are purely derived from the luminance channel Y in FSIMC and FSIM alike. 






\section{The Haar Wavelet-Based Perceptual Similarity Index}
\label{sec:HaarPSI}

The basic idea of the HaarPSI is to construct feature maps in the spirit of \eqref{eq:grad} as well as a weight function similar to \eqref{eq:pc} by considering a single wavelet filterbank. The response of any high-frequency wavelet filter will look similar to the response yielded by a gradient filter like the Sobel operator. Furthermore, the phase congruency measure used as a weight function in the FSIM is computed directly from the output of a multi-scale complex-valued wavelet filterbank, as illustrated by Equation~\eqref{eq:pc}. This gives a strong intuition that it should be possible to define a similarity measure derived from the response of a single set of discrete wavelet filters that at least matches the performance of the FSIM on benchmark databases but requires significantly less computational effort.

The wavelet chosen for this endeavor is the so-called Haar wavelet, which was already proposed in 1910 by Alfred Haar \cite{Haar1910} and is arguably the simplest and computationally most efficient wavelet there is. The one-dimensional Haar filters are given by

where  denotes the low-pass scaling filter and  the corresponding high-pass wavelet filter.
For any scale , we can construct two-dimensional Haar filters by setting

where  denotes the outer product and the one-dimensional filters  and  are given for  by

where  is the dyadic upsampling operator, and  denotes the one-dimensional convolution operator. Note that  responds to horizontal structures, while   picks up vertical structures. The six Haar filters used to define the HaarPSI are shown in Figure~\ref{fig:haarfilters}.


\setlength{\tabcolsep}{1mm}
\begin{figure}[!htb]
  \subfloat[Haar wavelet filters]{  \label{fig:haarfilters}
  \begin{tabular}[b]{cccc}   
    \includegraphics[width=0.08\textwidth]{figs/haarfilter_hor1.png}&
    \includegraphics[width=0.08\textwidth]{figs/haarfilter_hor2.png}&   
    \includegraphics[width=0.08\textwidth]{figs/haarfilter_hor3.png}\\    \includegraphics[width=0.08\textwidth]{figs/haarfilter_ver1.png}&
    \includegraphics[width=0.08\textwidth]{figs/haarfilter_ver2.png}&   
    \includegraphics[width=0.08\textwidth]{figs/haarfilter_ver3.png}    
  \end{tabular}}\hfil
  \subfloat[]{  \label{fig:scalarsim}\includegraphics[width=0.25\textwidth]{figs/scalarsim.png}}\hfil
  \subfloat[]{\label{fig:logistic}\includegraphics[width=0.25\textwidth]{figs/logisticFunction.png}}
  \caption{(a) The six Haar wavelet filters whose responses build the core of the HaarPSI. (b)  The function  for . (c) The logistic function  for .}
\end{figure}

The local similarity map  multiplicatively combines gradient-based and phase congruency-based similarities whose contributions are weighted by the exponents . The HaarPSI does not consider different types of similarities. However, to correctly predict the perceptual similarity experienced by human viewers, it can be useful to apply an additional non-linear mapping to the local similarities obtained from high-frequency Haar wavelet filter responses. This non-linearity is chosen to be the logistic function, which is widely used as an activation function in neural networks {for modeling thresholding in biological neurons}  and {is} given for a parameter  as


For two grayscale images , the local similarity measure used to compute the HaarPSI is based on the first two stages of a two-dimensional discrete Haar wavelet transform and given by

where ,  selects either horizontal or vertical Haar wavelet filters,  denotes the similarity measure \eqref{eq:scalarsim}, and  is the two-dimensional convolution operator. The local similarity measure  can be seen as an analog to . However,  does not mix different different concepts like gradients and phase congruency and is computed straightforwardly on the responses of two high-frequency discrete Haar wavelet filters. A visualization of the local similarity map  is shown in Figure~\ref{fig:haarmaps}.


Analogous to the phase congruency map  in the definition of the FSIM, the HaarPSI considers a weight map which is derived from the response of a single low-frequency Haar wavelet filter:

where  again differentiates between horizontal and vertical filters. Figure~\ref{fig:haarmaps} shows an example of the weight map  computed from a natural image.


The Haar-wavelet based perceptually similarity index for two grayscale images  is eventually given as the weighted average of the local similarity map  , that is, 

with

for .
The function  maps the weighted average from the interval  back to . Applying  further spreads the HaarPSI in the unit interval and helps to linearize the relationship between the HaarPSI and human opinion scores. In particular, this procedure aims to increase the readability of the HaarPSI in the sense that a single value should be 'meaningful on its own' and not only relative to other HaarPSI values. Please note that, due to the monotonicity of the logistic function, applying  cannot improve or worsen the rank order-based correlations with human opinion scores reported in Section~\ref{sec:results}.

\

Analogous to the FSIM, the HaarPSI can be extended to color images in the YIQ color space by considering a third local similarity map based on the chroma channels I and Q. The map  is computed analogous to \eqref{eq:localhs} by averaging local similarities obtained from comparing  with  and  with . In contrast to  and , the chromatic information used for  is not based on orientation sensitive filters. The corresponding weight map  is thus also computed by averaging  and . Formally, the generalization of the HaarPSI to color images is given by

with  and  defined as in \eqref{eq:localhs},

\setlength{\arraycolsep}{5pt}
with a  mean filter  and


\begin{figure}[!htb]
  \centering
  \begin{minipage}{0.28\textwidth}
	\subfloat[reference ]{\includegraphics[width=1\textwidth]{figs/imgRefColormap.png}}\\
	\subfloat[distorted ]{\includegraphics[width=1\textwidth]{figs/imgDistColormap.png}}
  \end{minipage}\hfil  
  \begin{minipage}{0.28\textwidth}  
  \subfloat[]{\includegraphics[width=1\textwidth]{figs/hs1.png}}\\
  \subfloat[]{\includegraphics[width=1\textwidth]{figs/hs2.png}}
\end{minipage}\hfil  
\begin{minipage}{0.28\textwidth}
\subfloat[]{\includegraphics[width=1\textwidth]{figs/weights1.png}}\\
\subfloat[]{\includegraphics[width=1\textwidth]{figs/weights2.png}}
\end{minipage}  
  \caption{(a) An undistorted reference image. (b) The reference image distorted by the JPEG compression algorithm. (c) The horizontal local similarity map . (d) The vertical local similarity map . (e) The (normalized) horizontal weight function . (f) The (normalized) vertical weight function . The images (a) and (b) are part of the CSIQ database \cite{LaCh2010}.}
  \label{fig:haarmaps}
\end{figure}

\subsection{Parameter Selection}

The HaarPSI as well as the HaarPSIC require only two parameters to be selected, namely  and . Both parameters were optimized on randomly chosen subsets of four large publicly available databases, where each subset was a quarter the size of the original database. Each of the databases, which will be described in more detail in Section~\ref{sec:results}, contains large numbers of differently distorted images and their corresponding MOS values.
The parameters  and  were selected to maximize the mean of the four Spearman rank order correlation coefficients (SROCC) obtained from comparing HaarPSIC and MOS values from subsets of the TID 2008 \cite{PLZECB2009}, TID 2013  \cite{Ponomarenko2015}, LIVE \cite{SWCBOnline} and CSIQ \cite{LaCh2010} image databases. The optimization was carried out in two steps. First, a grid search was performed in which the parameter  took values in the interval  and  in the range between  and . The best  pair was then used as the initial value of the Nelder-Mead algorithm. The thus refined parameters were eventually rounded to the nearest integer in the case of  and to the nearest tenth in the case of . This procedure resulted in the choices of  and .
To verify the generality of the HaarPSI, the same optimization procedure was repeated once only considering the TID 2008 and TID 2013 databases and once restricted to the LIVE and the CSIQ image databases. The results of all three optimizations are compiled in Figure~\ref{fig:optimization}.


\begin{figure}
	\setlength{\tabcolsep}{3mm}
	\subfloat[]{\begin{scriptsize}
			\begin{threeparttable}[b]  
				\begin{tabular}[b]{*{5}{c}}\toprule[0.5mm]
					&  & All databases & TID only & LIVE \& CSIQ only\\
					&  & 30 & 30  & 20  \\
					&  & 4.2 & 4.2 & 5.8\0.1cm]
	      & LIVE & \textbf{0.9683} & \textbf{0.9683} & 0.9677\\
	      & TID2008 & \textbf{0.9097} & \textbf{0.9097} & 0.9031\\
	      & TID2013 & \textbf{0.8732} & \textbf{0.8732} & 0.8651\\
	      & CSIQ & 0.9604 & 0.9604 & \textbf{0.9625}\\
					\hline
				\end{tabular}
				\begin{tablenotes}
					\item The highest correlation in each row is written in boldface.
				\end{tablenotes}
			\end{threeparttable}
		\end{scriptsize}}
		\hfill
		\subfloat[]{\includegraphics[width = 0.4\textwidth]{figs/parameterstability.png}}
		\caption{(a) Values for the parameters  and  which maximize the mean SROCC with respect to randomly selected subsets of the considered databases. The values in the first column were obtained by including all four databases in the optimization procedure. For the results depicted in columns 2 and 3, the optimization was restricted to the TID 2008 \& TID 2013 respectively the LIVE \& CSIQ databases. The SROCC values shown in the last four rows are with respect to the full databases. (b) The mean SROCC with respect to the subsets of all four databases plotted as a function of the parameters  and .}
		\label{fig:optimization}
	\end{figure}


\section{Experimental Results}
\label{sec:results}
The consistency of the HaarPSI with the human perception of image quality was
evaluated and compared with most of the image quality metrics discussed in
Section~\ref{sec:intro} on four large publicly available benchmark databases
of quality-annotated images. Those databases differ in the number of reference images, the number of distortion magnitudes and types, the number of observers, the level of control of the viewing conditions, and the stimulus presentation procedure.

The LIVE database \cite{SWCBOnline} contains 29 reference color images and 779 distorted images that were perturbed by JPEG compression, JPEG 2000 compression, additive Gaussian white
noise, Gaussian blurring as well as JPEG 2000 compressed images that have been transmitted over a simulated Rayleigh fading channel. Each distortion is introduced at five to six different levels of magnitude. On average, about 23 subjects evaluated the quality of each image with respect to the reference image. The viewing conditions were fairly controlled for in terms of viewing distance. Ratings were collected in a double stimulus manner.
 

The TID 2008 database \cite{PLZECB2009} comprises 25 colored reference images and 1700 degraded images, that had been subject to a wide range of distortions, including various types of noise, blur, JPEG and JPEG 2000 compression, transmission errors, local image distortions, as well as luminance and contrast changes. Subjective ratings were gathered by comparisons. The results from several viewing conditions of experiments in three different labs and on the internet were averaged. TID 2008 was later extended to TID 2013 \cite{Ponomarenko2015}, which added new types of distortions, which are mostly of a chromatic nature. In total, TID 2013 contains 3000 differently distorted images.

The CSIQ database \cite{LaCh2010} is based on 30 reference color images and contains 866 distorted images. Six different types of distortions (JPEG compression, JPEG 2000 compression, global contrast decrements, additive pink Gaussian noise, and Gaussian blurring) at four to five different degradation magnitudes were applied to the reference images. The viewing distance was controlled. Images were presented on a monitor array and subjects were asked to place all distorted versions of one reference image according to its perceived quality.

The main goal of most computational image similarity measures is to yield a monotonic relationship with human mean opinion scores across different databases and distortion types. To ensure a fair evaluation, different computational measures are typically compared with respect to rank order-based correlations or after performing nonlinear regression. Throughout the numerical evaluation of the HaarPSI, we apply the rank order-based SROCC to measure correlations between human mean opinion scores and different computational similarity and distortion indexes. We also considered applying Kendall's  and the Pearson product-moment correlation after performing a four parameter logistic regression as alternatives for the SROCC. We found that these correlation coefficients essentially duplicate the results reported in this section. The corresponding versions of Tables~\ref{tab:sroccdatabases}~and~\ref{tab:details} were thus not included here but can be found at \url{www.haarpsi.org}.

Following the ITU guidelines for evaluating quality prediction models \cite{ITUTP1401}, we also tested the statistical significance of the results reported in this section. Correlation coefficients for which the  hypothesis that they are not significantly different than the respective HaarPSI correlation can be refuted with  are highlighted in color in Tables~\ref{tab:sroccdatabases},~\ref{tab:details}~and~\ref{tab:otherwavelets}. In accordance with \cite{fieller1957tests}, the variance of the z-transforms were approximated by , where  denotes the degrees of freedom (i.e. the number of samples in the considered database or distortion specific subset).


\setlength{\tabcolsep}{2mm}
\begin{table}[!htb]
	\centering
	\caption{Spearman Rank Order Correlations of IQA Metrics With Human Mean Opinion Scores}
	\label{tab:sroccdatabases}	
	\begin{threeparttable}
		\begin{scriptsize}
			\begin{tabular}{*{12}{c}}
				\toprule[0.5mm]
				\multicolumn{12}{c}{Grayscale Images}\0.1cm]
				& & PSNR & VIF & SSIM & MS-SSIM & GSM & MAD & SR-SIM & FSIM & VSI & HaarPSI\\
				& LIVE & \cellcolor{green!25}0.8756 & 0.9636 & \cellcolor{green!25}0.9479 & \cellcolor{green!25}0.9513 & \cellcolor{green!25}0.9561 & 0.9672 & 0.9619 & 0.9645 & \cellcolor{green!25}0.9524 & \textbf{0.9683}\\
				& TID2008 & \cellcolor{green!25}0.5531 & \cellcolor{green!25}0.7491 & \cellcolor{green!25}0.7749 & \cellcolor{green!25}0.8542 & \cellcolor{green!25}0.8504 & \cellcolor{green!25}0.8340 & \cellcolor{green!25}0.8913 & \cellcolor{green!25}0.8840 & 0.8979 & \textbf{0.9097}\\
				& TID2013 & \cellcolor{green!25}0.6394 & \cellcolor{green!25}0.6769 & \cellcolor{green!25}0.7417 & \cellcolor{green!25}0.7859 & \cellcolor{green!25}0.7946 & \cellcolor{green!25}0.7807 & \cellcolor{green!25}0.8075 & \cellcolor{green!25}0.8510 & \cellcolor{red!25}\textbf{0.8965} & 0.8732\\
				& CSIQ & \cellcolor{green!25}0.8058 & \cellcolor{green!25}0.9195 & \cellcolor{green!25}0.8756 & \cellcolor{green!25}0.9133 & \cellcolor{green!25}0.9108 & \cellcolor{green!25}0.9466 & \cellcolor{green!25}0.9319 & \cellcolor{green!25}0.9310 & \cellcolor{green!25}0.9423 & \textbf{0.9604}\\\midrule[0.5mm]
			\end{tabular}
			\begin{tablenotes}
				\item \colorbox{green!25}{Lower correlation than HaarPSI. The difference is statistically significant with .}
				\item \colorbox{red!25}{Higher correlation than HaarPSI. The difference is statistically significant with .}
				\item The highest correlation in each row is written in \textbf{boldface}.
			\end{tablenotes}
	\end{scriptsize}
\end{threeparttable}
\end{table}

The four databases used in the numerical evaluation only contain color images. However, out of the metrics considered in our experiments, only the FSIM and the HaarPSI are defined for both grayscale and color images, while the visual saliency-based index (VSI) was specifically designed for color images. All other similarity measures considered in our experiments only accept grayscale images as input or perform an RGB to grayscale conversion as a first processing step. To reflect these differing designs, all methods were tested on all databases once with the original color images and once with grayscale conversions obtained from the Matlab \textit{rgb2gray} function. To obtain the VSI for pairs of grayscale images, corresponding RGB images were created by setting the values for all three color channels to the values of the given grayscale channel. The correlation coefficients of all ten considered similarity measures with the human mean opinion scores for the LIVE image database, TID 2008, TID 2013 and the CSIQ database are compiled in Table~\ref{tab:sroccdatabases}.

Table~\ref{tab:overallperf} provides a quick impression of the overall performance of each metric. It depicts the average SROCC of each metric with respect to all four databases as well as the mean execution time in milliseconds. The average execution time was measured on a Intel Core i7-4790 CPU clocked at  GHz. To measure the execution time, each quality measure was computed ten times for ten different pairs of randomly generated  pixel images. All computations and measurements were carried out in Matlab using implementations made freely available by the respective authors. Note that due to an additional conversion step, metrics that are only defined for grayscale images can have slightly higher execution times when evaluated on color images.


\begin{table}[!htb]
  \centering
  \caption{Mean SROCC and Execution Time} 
  \label{tab:overallperf}
\begin{small}
  \begin{tabular}{*{6}{c}}
    \toprule[0.5mm] &  & \multicolumn{2}{c}{Color Images} & \multicolumn{2}{c}{Grayscale Images}\\
    &  & SROCC & Time (ms) & SROCC & Time (ms)\\
& HaarPSI & 0.9279 & 24 & 0.9093 & 10\\
& VSI & 0.9223 & 79 & 0.8946 & 80\\
& FSIM & 0.9076 & 142 & 0.8925 & 121\\
& SRSIM & 0.8982 & 10 & 0.8982 & 10\\
& MAD & 0.8821 & 892 & 0.8821 & 891\\
& GSM & 0.8780 & 8 & 0.8780 & 7\\
& MSSSIM & 0.8762 & 30 & 0.8762 & 24\\
& SSIM & 0.8350 & 6 & 0.8350 & 5\\
& VIF & 0.8273 & 459 & 0.8273 & 453\\
& PSNR & 0.7185 & 2 & 0.7185 & 1\\
    \midrule[0.5mm]
  \end{tabular}
\end{small}
\end{table}

A high correlation with the mean opinion scores annotated to the distorted images of a large database containing many different types and degrees of distortions is arguably the best indicator of an image quality measure's consistency with human perception. However, for certain applications like compression or denoising, it could be more important to know if an image quality metric has a high correlation with the human experience \textit{within} a single distortion class. Table~\ref{tab:details} depicts the SROC coefficients for all image quality metrics when only subsets of databases containing specific distortions like Gaussian blur or JPEG transmission errors are considered. 

Single correlation coefficients provide a useful means of objectively evaluating and comparing different computational models of image quality. However, they only measure a specific aspect of the relationship between an image similarity metric and human opinion scores, like linearity in the case of the Pearson correlation coefficient or monotonicity in the case of the SROCC. In an attempt to better visualize the relationship between the HaarPSI and human opinion scores, Figure~\ref{fig:scatterplots} shows scatter plots of the HaarPSI against difference mean opinion scores (DMOS) for all four databases. To provide as much insight as possible, the plots are categorized by specific distortion types.


\FloatBarrier
\setlength{\tabcolsep}{1mm}
\begin{table}[!htb]
	\centering
	\caption{Spearman Rank Order Correlations of IQA Metrics With Human Mean Opinion Scores}
	\label{tab:details}
	\begin{scriptsize}
		\begin{threeparttable}
			\begin{tabular}{*{12}{c}}
				\toprule[0.5mm]
				\multicolumn{12}{c}{Color Images}\0.1cm]
  & Daub2PSI & Daub4PSI & Sym4PSI & CDFPSI & Coif1PSI & HaarPSI\\
 LIVE & \cellcolor{green!25}0.9620 & \cellcolor{green!25}0.9530 & \cellcolor{green!25}0.9552 & \cellcolor{green!25}0.9604 & \cellcolor{green!25}0.9603 & \textbf{0.9690}\\
 TID2008 & 0.8971 & \cellcolor{green!25}0.8796 & 0.8915 & \cellcolor{green!25}0.8836 & 0.8965 & \textbf{0.9043}\\
 TID2013 & 0.8064 & 0.7982 & 0.8022 & 0.7965 & 0.8055 & \textbf{0.8094}\\
 CSIQ & 0.9492 & \cellcolor{green!25}0.9442 & 0.9454 & \cellcolor{green!25}0.9404 & 0.9485 & \textbf{0.9546}\\
\\
\multicolumn{7}{c}{Color Images}\0.1cm]
 & & PSNR & VIF & SSIM & MSSSIM & GSM & MAD & SRSIM & FSIM & VSI & HaarPSI\\
& LIVE & \cellcolor{green!25}0.8585 & \cellcolor{green!25}0.9411 & \cellcolor{green!25}0.8290 & \cellcolor{green!25}0.7670 & \cellcolor{green!25}0.7799 & 0.9559 & \cellcolor{green!25}0.7758 & \cellcolor{green!25}0.8595 & \cellcolor{green!25}0.7647 & \textbf{0.9592}\\
& TID2008 & \cellcolor{green!25}0.5190 & \cellcolor{green!25}0.7769 & \cellcolor{green!25}0.7401 & \cellcolor{green!25}0.7897 & \cellcolor{green!25}0.7779 & \cellcolor{green!25}0.8290 & \cellcolor{green!25}0.8242 & \cellcolor{green!25}0.8341 & \cellcolor{green!25}0.8107 & \textbf{0.9032}\\
& TID2013 & \cellcolor{green!25}0.4785 & \cellcolor{green!25}0.7335 & \cellcolor{green!25}0.7596 & \cellcolor{green!25}0.7773 & \cellcolor{green!25}0.7966 & \cellcolor{green!25}0.8074 & \cellcolor{green!25}0.7984 & \cellcolor{green!25}0.8322 & \cellcolor{green!25}0.8373 & \textbf{0.8904}\\
& CSIQ & \cellcolor{green!25}0.7512 & \cellcolor{green!25}0.9219 & \cellcolor{green!25}0.7916 & \cellcolor{green!25}0.7720 & \cellcolor{green!25}0.7471 & \textbf{0.9500} & \cellcolor{green!25}0.7520 & \cellcolor{green!25}0.8208 & \cellcolor{green!25}0.8392 & 0.9463\\
\\
\multicolumn{12}{c}{Color Images}\0.1cm]
\multirow{5}{*}{LIVE} & jpg2k & \cellcolor{green!25}0.8747 & \cellcolor{green!25}0.9476 & \cellcolor{green!25}0.8925 & \cellcolor{green!25}0.8697 & \cellcolor{green!25}0.8564 & \textbf{0.9725} & \cellcolor{green!25}0.8800 & \cellcolor{green!25}0.9036 & \cellcolor{green!25}0.8662 & 0.9673\\
& jpg & \cellcolor{green!25}0.8650 & \cellcolor{green!25}0.9600 & \cellcolor{green!25}0.9279 & \cellcolor{green!25}0.9184 & \cellcolor{green!25}0.9131 & 0.9742 & \cellcolor{green!25}0.9028 & \cellcolor{green!25}0.9117 & \cellcolor{green!25}0.9037 & \textbf{0.9779}\\
& gwn & \textbf{0.9792} & \cellcolor{green!25}0.9632 & \cellcolor{green!25}0.9583 & \cellcolor{green!25}0.9181 & \cellcolor{green!25}0.8904 & 0.9764 & \cellcolor{green!25}0.8684 & \cellcolor{green!25}0.9263 & \cellcolor{green!25}0.9171 & 0.9791\\
& gblur & \cellcolor{green!25}0.7744 & 0.9575 & \cellcolor{green!25}0.8881 & \cellcolor{green!25}0.8450 & \cellcolor{green!25}0.8565 & 0.9486 & \cellcolor{green!25}0.8411 & \cellcolor{green!25}0.9086 & \cellcolor{green!25}0.8544 & \textbf{0.9576}\\
& ff & \cellcolor{green!25}0.8753 & \textbf{0.9560} & \cellcolor{green!25}0.8619 & \cellcolor{green!25}0.8113 & \cellcolor{green!25}0.7925 & 0.9461 & \cellcolor{green!25}0.7837 & \cellcolor{green!25}0.8515 & \cellcolor{green!25}0.8151 & 0.9444\\
\\
\multirow{17}{*}{TID2008} & gwn & \textbf{0.9336} & 0.8657 & \cellcolor{green!25}0.7494 & \cellcolor{green!25}0.7433 & \cellcolor{green!25}0.8078 & \cellcolor{green!25}0.8165 & \cellcolor{green!25}0.8284 & \cellcolor{green!25}0.8076 & 0.8719 & 0.9029\\
& gwnc & \textbf{0.9208} & 0.8928 & \cellcolor{green!25}0.7758 & \cellcolor{green!25}0.7772 & \cellcolor{green!25}0.7833 & \cellcolor{green!25}0.8267 & 0.8625 & 0.8671 & 0.9045 & 0.9131\\
& scn & \textbf{0.9526} & \cellcolor{green!25}0.8578 & \cellcolor{green!25}0.7678 & \cellcolor{green!25}0.7583 & \cellcolor{green!25}0.8422 & \cellcolor{green!25}0.8598 & \cellcolor{green!25}0.8492 & \cellcolor{green!25}0.8217 & 0.8862 & 0.9283\\
& mn & \cellcolor{red!25}0.8627 & \cellcolor{red!25}\textbf{0.8900} & 0.7496 & 0.7849 & \cellcolor{green!25}0.5512 & 0.7566 & 0.7345 & 0.8106 & 0.6114 & 0.7480\\
& hfn & \cellcolor{red!25}\textbf{0.9680} & 0.9441 & \cellcolor{green!25}0.8228 & \cellcolor{green!25}0.8176 & \cellcolor{green!25}0.8452 & \cellcolor{green!25}0.8931 & \cellcolor{green!25}0.8657 & \cellcolor{green!25}0.8597 & \cellcolor{green!25}0.8934 & 0.9393\\
& in & \textbf{0.8566} & 0.8146 & \cellcolor{green!25}0.6202 & \cellcolor{green!25}0.6220 & \cellcolor{green!25}0.6218 & \cellcolor{green!25}0.0417 & 0.6912 & 0.7044 & 0.7651 & 0.8077\\
& qn & \textbf{0.8729} & \cellcolor{green!25}0.7442 & \cellcolor{green!25}0.7239 & \cellcolor{green!25}0.7602 & 0.8090 & 0.7981 & \cellcolor{green!25}0.7586 & 0.7986 & 0.8077 & 0.8602\\
& gblr & 0.8439 & \cellcolor{red!25}\textbf{0.9388} & 0.8936 & 0.8745 & 0.8761 & 0.9227 & 0.9078 & 0.9078 & 0.8731 & 0.8934\\
& den & \cellcolor{green!25}0.9428 & \cellcolor{green!25}0.8968 & \cellcolor{green!25}0.9208 & \cellcolor{green!25}0.9156 & \cellcolor{green!25}0.9052 & 0.9612 & \cellcolor{green!25}0.9133 & \cellcolor{green!25}0.9344 & \cellcolor{green!25}0.9162 & \textbf{0.9739}\\
& jpg & \cellcolor{green!25}0.8597 & \cellcolor{green!25}0.9327 & \cellcolor{green!25}0.9319 & \cellcolor{green!25}0.9279 & 0.9546 & 0.9487 & 0.9444 & \cellcolor{green!25}0.9299 & 0.9566 & \textbf{0.9647}\\
& jpg2k & \cellcolor{green!25}0.8629 & \cellcolor{green!25}0.9169 & \cellcolor{green!25}0.9492 & \cellcolor{green!25}0.9365 & \cellcolor{green!25}0.9564 & \cellcolor{green!25}0.9733 & \cellcolor{green!25}0.8965 & \cellcolor{green!25}0.9566 & \cellcolor{green!25}0.9632 & \textbf{0.9856}\\
& jpgt & \cellcolor{green!25}0.6258 & 0.8720 & 0.8375 & 0.8150 & 0.8441 & 0.8556 & 0.8573 & 0.8446 & 0.8705 & \textbf{0.8882}\\
& jpg2kt & 0.8528 & 0.8307 & 0.8252 & 0.7970 & 0.7958 & 0.8295 & 0.7932 & 0.7883 & 0.8142 & \textbf{0.8688}\\
& pn & \cellcolor{green!25}0.5831 & 0.7366 & 0.6685 & \cellcolor{green!25}0.6637 & 0.7013 & \textbf{0.8242} & 0.7381 & 0.7297 & 0.7314 & 0.7936\\
& bdist & \cellcolor{green!25}0.6277 & 0.8340 & 0.8659 & 0.7861 & \textbf{0.8822} & 0.8007 & 0.7864 & 0.8410 & \cellcolor{green!25}0.6198 & 0.8069\\
& ms & 0.6845 & 0.5896 & 0.6834 & 0.6735 & \cellcolor{red!25}\textbf{0.7431} & 0.5709 & 0.6098 & 0.6700 & 0.6420 & 0.5358\\
& ctrst & 0.5819 & \cellcolor{red!25}\textbf{0.8816} & 0.5158 & 0.7686 & 0.7068 & \cellcolor{green!25}0.2573 & 0.6978 & 0.7275 & 0.6995 & 0.6446\\
\\
\multirow{24}{*}{TID2013} & gwn & \textbf{0.9519} & 0.9010 & \cellcolor{green!25}0.7954 & \cellcolor{green!25}0.7891 & \cellcolor{green!25}0.8500 & \cellcolor{green!25}0.8732 & \cellcolor{green!25}0.8569 & \cellcolor{green!25}0.8435 & 0.8928 & 0.9248\\
& gwnc & 0.8948 & 0.8641 & \cellcolor{green!25}0.7615 & \cellcolor{green!25}0.7629 & \cellcolor{green!25}0.8216 & \cellcolor{green!25}0.8297 & 0.8603 & 0.8543 & 0.8975 & \textbf{0.8998}\\
& scn & \textbf{0.9513} & \cellcolor{green!25}0.8783 & \cellcolor{green!25}0.7840 & \cellcolor{green!25}0.7681 & \cellcolor{green!25}0.8420 & \cellcolor{green!25}0.8804 & \cellcolor{green!25}0.8371 & \cellcolor{green!25}0.8240 & \cellcolor{green!25}0.8714 & 0.9261\\
& mn & 0.8447 & \cellcolor{red!25}\textbf{0.8772} & 0.7569 & 0.7929 & \cellcolor{green!25}0.5934 & 0.7804 & 0.7615 & 0.8214 & 0.6585 & 0.7737\\
& hfn & \textbf{0.9607} & 0.9454 & \cellcolor{green!25}0.8342 & \cellcolor{green!25}0.8307 & \cellcolor{green!25}0.8575 & 0.9098 & \cellcolor{green!25}0.8702 & \cellcolor{green!25}0.8669 & \cellcolor{green!25}0.8939 & 0.9415\\
& in & \textbf{0.8856} & 0.8489 & \cellcolor{green!25}0.6625 & \cellcolor{green!25}0.6541 & \cellcolor{green!25}0.6602 & \cellcolor{green!25}0.2741 & \cellcolor{green!25}0.7183 & \cellcolor{green!25}0.7216 & 0.7776 & 0.8325\\
& qn & \textbf{0.8855} & \cellcolor{green!25}0.7805 & \cellcolor{green!25}0.7514 & \cellcolor{green!25}0.7752 & 0.8199 & 0.8365 & \cellcolor{green!25}0.7677 & 0.8096 & 0.8119 & 0.8643\\
& gblr & 0.8952 & \cellcolor{red!25}\textbf{0.9530} & 0.8832 & 0.8616 & 0.8565 & 0.9336 & 0.8893 & 0.8922 & 0.8548 & 0.9030\\
& den & 0.9572 & \cellcolor{green!25}0.8914 & \cellcolor{green!25}0.9199 & \cellcolor{green!25}0.9110 & \cellcolor{green!25}0.9116 & 0.9602 & \cellcolor{green!25}0.9114 & \cellcolor{green!25}0.9304 & \cellcolor{green!25}0.9187 & \textbf{0.9690}\\
& jpg & \cellcolor{green!25}0.8972 & \cellcolor{green!25}0.9332 & \cellcolor{green!25}0.9278 & \cellcolor{green!25}0.9207 & \cellcolor{green!25}0.9470 & \cellcolor{green!25}0.9510 & \cellcolor{green!25}0.9343 & \cellcolor{green!25}0.9242 & \cellcolor{green!25}0.9479 & \textbf{0.9750}\\
& jpg2k & \cellcolor{green!25}0.9078 & \cellcolor{green!25}0.9184 & \cellcolor{green!25}0.9424 & \cellcolor{green!25}0.9183 & \cellcolor{green!25}0.9462 & 0.9663 & \cellcolor{green!25}0.8772 & \cellcolor{green!25}0.9360 & \cellcolor{green!25}0.9494 & \textbf{0.9787}\\
& jpgt & \cellcolor{green!25}0.6410 & 0.9000 & 0.8721 & \cellcolor{green!25}0.8476 & 0.8697 & \cellcolor{green!25}0.8537 & 0.8772 & 0.8761 & 0.8972 & \textbf{0.9177}\\
& jpg2kt & 0.8834 & 0.8692 & \cellcolor{green!25}0.8260 & \cellcolor{green!25}0.7929 & \cellcolor{green!25}0.7960 & 0.8648 & \cellcolor{green!25}0.7914 & \cellcolor{green!25}0.8010 & \cellcolor{green!25}0.8179 & \textbf{0.8913}\\
& pn & \cellcolor{green!25}0.6702 & 0.7686 & 0.7481 & \cellcolor{green!25}0.7376 & 0.7718 & \textbf{0.8513} & 0.8034 & 0.7957 & 0.7971 & 0.8376\\
& bdist & \cellcolor{green!25}0.1448 & 0.5027 & 0.5589 & 0.4608 & \textbf{0.5939} & 0.3184 & 0.4436 & 0.5237 & \cellcolor{green!25}0.1356 & 0.4441\\
& ms & 0.7482 & 0.6829 & 0.7309 & 0.6823 & \cellcolor{red!25}\textbf{0.8153} & 0.6654 & 0.6364 & 0.7103 & 0.7367 & 0.6365\\
& ctrst & 0.4812 & \cellcolor{red!25}\textbf{0.8730} & 0.4941 & 0.7268 & 0.6701 & \cellcolor{green!25}0.2601 & 0.6520 & 0.6838 & 0.6595 & 0.5916\\
& ccs & \cellcolor{green!25}0.1378 & \cellcolor{green!25}0.3404 & 0.4349 & 0.4237 & \cellcolor{green!25}0.3739 & \cellcolor{green!25}0.0351 & \cellcolor{green!25}0.2491 & 0.6069 & \textbf{0.6852} & 0.6003\\
& mgn & \textbf{0.9187} & 0.8559 & \cellcolor{green!25}0.7358 & \cellcolor{green!25}0.7301 & \cellcolor{green!25}0.7903 & 0.8422 & \cellcolor{green!25}0.8049 & \cellcolor{green!25}0.8008 & 0.8505 & 0.8786\\
& cn & \cellcolor{green!25}0.8548 & \cellcolor{green!25}0.8992 & \cellcolor{green!25}0.8459 & \cellcolor{green!25}0.8105 & \cellcolor{green!25}0.9286 & \cellcolor{green!25}0.9280 & \cellcolor{green!25}0.9260 & \cellcolor{green!25}0.9214 & \cellcolor{green!25}0.9301 & \textbf{0.9571}\\
& lcni & \cellcolor{green!25}0.9372 & \cellcolor{green!25}0.9034 & \cellcolor{green!25}0.9058 & \cellcolor{green!25}0.8917 & \cellcolor{green!25}0.9472 & 0.9520 & \cellcolor{green!25}0.9439 & \cellcolor{green!25}0.9364 & \cellcolor{green!25}0.9463 & \textbf{0.9686}\\
& icqd & \textbf{0.9227} & 0.8582 & \cellcolor{green!25}0.8083 & \cellcolor{green!25}0.7767 & 0.8240 & 0.8626 & \cellcolor{green!25}0.7574 & \cellcolor{green!25}0.8053 & \cellcolor{green!25}0.8083 & 0.8826\\
& cha & \cellcolor{green!25}0.8569 & 0.9441 & 0.9519 & \cellcolor{green!25}0.9071 & \textbf{0.9563} & 0.9560 & \cellcolor{green!25}0.8819 & 0.9478 & 0.9498 & 0.9549\\
& ssr & \cellcolor{green!25}0.9167 & \cellcolor{green!25}0.9067 & \cellcolor{green!25}0.9528 & \cellcolor{green!25}0.9197 & \cellcolor{green!25}0.9601 & 0.9658 & \cellcolor{green!25}0.9135 & \cellcolor{green!25}0.9412 & \cellcolor{green!25}0.9449 & \textbf{0.9791}\\
\\
\multirow{6}{*}{CSIQ} & gwn & 0.9437 & \textbf{0.9590} & \cellcolor{green!25}0.8043 & \cellcolor{green!25}0.8254 & \cellcolor{green!25}0.8517 & 0.9486 & \cellcolor{green!25}0.8669 & \cellcolor{green!25}0.7959 & \cellcolor{green!25}0.8875 & 0.9433\\
& jpeg & \cellcolor{green!25}0.7898 & \cellcolor{green!25}0.9590 & \cellcolor{green!25}0.9165 & \cellcolor{green!25}0.9064 & \cellcolor{green!25}0.8964 & 0.9696 & \cellcolor{green!25}0.8731 & \cellcolor{green!25}0.9077 & \cellcolor{green!25}0.8833 & \textbf{0.9780}\\
& jpg2k & \cellcolor{green!25}0.9270 & \cellcolor{green!25}0.9360 & \cellcolor{green!25}0.8967 & \cellcolor{green!25}0.8843 & \cellcolor{green!25}0.8793 & 0.9808 & \cellcolor{green!25}0.8428 & \cellcolor{green!25}0.9106 & \cellcolor{green!25}0.9008 & \textbf{0.9853}\\
& gpn & 0.9527 & \textbf{0.9552} & \cellcolor{green!25}0.7844 & \cellcolor{green!25}0.7790 & \cellcolor{green!25}0.8293 & 0.9548 & \cellcolor{green!25}0.7777 & \cellcolor{green!25}0.8160 & \cellcolor{green!25}0.8698 & 0.9470\\
& gblr & \cellcolor{green!25}0.9081 & 0.9627 & \cellcolor{green!25}0.8692 & \cellcolor{green!25}0.8670 & \cellcolor{green!25}0.8575 & \textbf{0.9713} & \cellcolor{green!25}0.8675 & \cellcolor{green!25}0.8843 & \cellcolor{green!25}0.8761 & 0.9623\\
& ctrst & 0.8888 & 0.9294 & \cellcolor{green!25}0.7666 & 0.9003 & \cellcolor{green!25}0.8656 & \textbf{0.9306} & 0.8878 & 0.8765 & \cellcolor{green!25}0.8686 & 0.9229\\\midrule[0.5mm]
\end{tabular}
\begin{tablenotes}
\item \colorbox{green!25}{Lower correlation than HaarPSI. The difference is statistically significant with .}
\item \colorbox{red!25}{Higher correlation than HaarPSI. The difference is statistically significant with .}
\item The highest correlation in each row is written in \textbf{boldface}.
\item All correlations were obtained \textbf{without nonlinear regression}.
\end{tablenotes}
\end{threeparttable}}
\end{scriptsize}
\end{table}


\end{document}
