

In this Section we describe a class of stochastic processes called \emph{Markov branching plays} (MBP's) \cite{MioThesis,MIO2012b}  which, as we will observe, is closely related to game automata and will provide a method for calculating the probability of regular languages defined by such automata.  
For a quick overview, a procedure for computing the value associated with a MBP is presented as Algorithm \ref{alg1}, at the end of this section. The procedure for computing the probability  of regular languages defined by game automata in presented as Algorithm \ref{alg2} in the next section.



We assume familiarity with the standard concepts of Markov chain and two-player stochastic ($2\frac{1}{2}$-player) parity game (see, e.g.,  \cite{ChatPhD}).  Ordinary $2\frac{1}{2}$-player parity games are played on directed graphs whose set of states is partitioned into Player $1$, Player $2$ and probabilistic states. A $2\frac{1}{2}$-player parity game with neither Player $1$ nor Player $2$ states can be identified with a \emph{Markov chain}. 



\begin{comment}
Recall that ordinary $2\frac{1}{2}$-player parity games  are played on directed graphs whose set of states is partitioned into Player $1$ and Player $2$ states, where the two players make their moves, and probabilistic states, where the game progresses to a successor state following a prescribed probabilistic rule. A $2\frac{1}{2}$-player parity game without Player $2$ states is called a \emph{Markov Decision Process} (MDP). A $2\frac{1}{2}$-player parity game with neither Player $1$ nor Player $2$ states (i.e., only having probabilistic states) can be identified with a \emph{Markov chain}. \todo{Here I uncommented certain piece which was reserved for the journal version.}
\end{comment}

\emph{Two-player stochastic} \emph{meta-parity games} \cite{MioThesis,MIO2012b} generalize $2\frac{1}{2}$-player parity games by allowing the directed graph to have two additional kinds of states called $\exists$--branching states and $\forall$--branching states. In this paper we will only consider $2\frac{1}{2}$-player meta-parity games with neither Player $1$ nor Player $2$ states. Such structures, which thus constitute a generalization of Markov chains, are called \emph{Markov branching plays} (MBP's). In what follows we provide a quick description of MBP and refer to \cite{MioThesis} for a detailed account.

\begin{definition}[Markov Branching Play]
A Markov branching play (MBP) is a structure $\mathcal{M}\!=\!\langle (S,E), (S_{P}, B_\exists,B_\forall), p , Par \rangle$ where:
\begin{itemize}
\item  $(S,E)$ is a directed graph with finite set of vertices $S$ and transition relation $E$. We say that $s^\prime$ is a successor of $s$ if $(s,s^\prime)\!\in\! E$. We assume that each vertex has at least one successor state in the graph  $(S,E)$. 
\item The triple $(S_{P},B_\exists,B_\forall)$ is a partition of $S$ into probabilistic, $\exists$-branching and $\forall$-branching states.
\item The function $p\! :\! S_{P}\!\rightarrow\! (S\rightarrow[0,1])$ associates to each probabilistic state $s$ a discrete probability distribution $p(s):S\rightarrow[0,1]$ supported over the (nonempty) set of successors of $s$ in the graph $(S,E)$. 
\item Lastly, the function $Par\!:\! S\rightarrow\omega$ is the \emph{parity (or priority) assignment}. 
\end{itemize}\end{definition}



\begin{comment}
In what follows we identify Markov chains with MBP's without $\exists$--branching nor $\forall$--branching states, i.e., such that $B_\exists\!=\!B_\forall\!=\!\emptyset$.

As usual, a Markov chain $\mathcal{M}$ represents the stochastic process associated with a \emph{random infinite walk} on it's set of states, i.e., an infinite sequence of states randomly generated in accordance with the probability transition function $p$. 
\end{comment}

Recall that a Markov chain represents the stochastic process associated with a \emph{random infinite walk} on its set of states. A MBP represents the more involved stochastic process, described below, of generation of a random unranked and unordered \emph{tree} $T$ whose vertices are labeled by states of the MDP. 

\vspace{5mm}
\noindent
\emph{MBP's as Stochastic Processes:} given a MBP $\mathcal{M}\!=\!\langle (S,E), (S_{P}, B_\exists,B_\forall), p , Par \rangle$ and an initial vertex $s_0\!\in\! S$, the stochastic process of construction of $T$ is described as follows. 
\begin{itemize}
\item 
The construction starts from the root of $T$ which is labeled by $s_0$. 
\item A leaf $x$ in the so far constructed tree $T$ is extended, \emph{independently} from all other leaves, depending on the type of its labeling state $s$, as follows:
\begin{itemize}
\item If $s\!\in\! S_P$ then $x$ is extended with a unique child which is labeled by a successor state $s^\prime$ of $s$ randomly chosen in accordance with $p(s)$. 
\item If $s\!\in\! B_\exists$ or $s\!\in\! B_\forall$ and $\{s_1,\dots, s_n\}$ are the successors of $s$ in $\mathcal{M}$, then $x$ is extended with $n$ children $y_1,\dots y_n$ and $y_i$ is labeled by $s_i$, for $1\!\leq\! i\! \leq \! n$. 
\end{itemize}
\end{itemize}

We give in Figure \ref{matteo_pic1} an example of a MBP. Probabilistic states, $\exists$-branching and $\forall$-branching states are marked as circles, diamond and boxes, respectively.  The first six initial steps of the stochastic process associated with $\mathcal{M}$ at state $q_1$ are depicted in Figure \ref{matteo_pic3}.
In the first step, the construction of $T$ starts by labeling the root by $q_1$. Since $q_1$ is a probabilistic state, the tree is extended (second step) with only one child labeled by either $q_2$ (with probability $\frac{1}{3}$) or $q_3$ (prob. $\frac{2}{3})$. The picture  shows the case when $q_2$ is chosen. Since the new leaf is labeled by $q_2$, and this is a $\exists$-branching state, the tree is extended by adding one new vertex for each successor of $q_2$ in $\mathcal{M}$, i.e., for both $q_1$ and $q_4$. The construction continues as described above. For example, the probability that the generated infinite tree will have the prefix as at the bottom right of Figure \ref{matteo_pic3} is $\frac{1}{3}\cdot \frac{2}{3}\cdot \frac{1}{2}\!=\!\frac{2}{18}$.
\begin{figure}[H] 
\centering
\begin{tikzpicture}[scale=.2,->,level distance=0.7in,sibling distance=.4in]

\clip (-10,-2) rectangle (10, 17);


\node (q1) [draw, circle, minimum size = \diameter,inner sep=2] {$q_1$};
\node (q2) [draw, diamond, aspect = 1.5, minimum size = 2*\diameter,inner sep=1] at ($(q1)+(-5,5)$) {$q_2$};
\node (q3) [draw, minimum size = 1.5*\diameter,inner sep=4] at ($(q1)+(5,5)$) {$q_3$};
\node (q4) [draw, circle, minimum size = \diameter,{font=\small},inner sep=2]  at ($(q1)+(0,10)$) {$q_4$};
\path (q1) edge [{font=\small}] node[right = 0.05cm, near end] {$\frac{1}{3}$} (q2);
\path (q1) edge [{font=\small}] node[left = 0.05cm, near end] {$\frac{2}{3}$} (q3);
\path (q2) edge [bend right=40] node {} (q1);
\path (q2) edge node {} (q4);
\path (q3) edge [bend left=40] node {} (q1);
\path (q3) edge node {} (q4);
\path (q4) edge [font=\small, loop above] node {$\frac{1}{2}$} (q4);
\path (q4) edge [font=\small, left = 0.05cm, near end, bend right=40] node {$\frac{1}{2}$} (q2);



\end{tikzpicture}



\caption{An example of a MBP.}
\label{matteo_pic1}
\end{figure}
 
The kind of infinite trees produced by the stochastic process just described are called \emph{branching plays}. Branching plays are characterized by the property that each vertex labeled with a probabilistic state has only one child, and each vertex labeled with a ($\exists$ or $\forall$) branching state $s$ has as many children as there are successors of $s$ in the MBP. \begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.7,->,level distance=0.4in,sibling distance=.15in]

\tikzset{grow'=up}
\Tree 
[.\node [draw, circle, minimum size = 2*\diameter] {$q_1$};
        \edge[{font=\small}] node[right = 0.05cm, near end] {$ $};
        [.\node [draw, diamond, aspect = 1.5, minimum size = 2*\diameter] {$q_2$};
            [.\node [draw, circle, minimum size = 2*\diameter] {$q_1$};
                \node [draw, minimum size = 4*\diameter] {$q_3$};
            ]
            \node [draw, circle, minimum size = 2*\diameter] {$q_4$};
        ]
]

\begin{scope}[shift={(5cm,0cm)}]
\Tree 
[.\node [draw, circle, minimum size = 2*\diameter] {$q_1$};
        \edge[{font=\small}] node[right = 0.05cm, near end] {$ $};
        [.\node [draw, diamond, aspect = 1.5, minimum size = 2*\diameter] {$q_2$};
            [.\node [draw, circle, minimum size = 2*\diameter] {$q_1$};
                \node [draw, minimum size = 4*\diameter] {$q_3$};
            ]
            [.\node [draw, circle, minimum size = 2*\diameter] {$q_4$};
                \node [draw, circle, minimum size = 2*\diameter] {$q_4$};
            ]
        ]
]
\end{scope}

\begin{scope}[shift={(10cm,0cm)}]
\Tree 
[.\node [draw, circle, minimum size = 2*\diameter] {$q_1$};
        \edge[{font=\small}] node[right = 0.05cm, near end] {$ $};
        [.\node [draw, diamond, aspect = 1.5, minimum size = 2*\diameter] {$q_2$};
            [.\node [draw, circle, minimum size = 2*\diameter] {$q_1$};
                [.\node [draw, minimum size = 4*\diameter] {$q_3$};
                    \node (q1) [draw, circle, minimum size = 2*\diameter] {$q_1$};
                    \node (q4) [draw, circle, minimum size = 2*\diameter] {$q_4$};
                ]
            ]
            [.\node [draw, circle, minimum size = 2*\diameter] {$q_4$};
                \node (q4prime) [draw, circle, minimum size = 2*\diameter] {$q_4$};
            ]
        ]
]
\end{scope}

\begin{scope}[shift={(0cm,5.5cm)}]
\Tree 
[.\node [draw, circle, minimum size = 2*\diameter] {$q_1$};
]
\end{scope}

\begin{scope}[shift={(5cm,5.5cm)}]
\Tree 
[.\node [draw, circle, minimum size = 2*\diameter] {$q_1$};
        \edge[{font=\small}] node[right = 0.05cm, near end] {$ $};
        \node [draw, diamond, aspect = 1.5, minimum size = 2*\diameter] {$q_2$};
]
\end{scope}

\begin{scope}[shift={(10cm,5.5c m)}]
\Tree 
[.\node [draw, circle, minimum size = 2*\diameter] {$q_1$};
        \edge[{font=\small}] node[right = 0.05cm, near end] {$ $};
        [.\node [draw, diamond, aspect = 1.5, minimum size = 2*\diameter] {$q_2$};
            \node [draw, circle, minimum size = 2*\diameter] {$q_1$};
            \node [draw, circle, minimum size = 2*\diameter] {$q_4$};
        ]
]
\end{scope}

\node (q1v1) at ($(q1)+(-0.5,1)$) {};
\node (q1v2) at ($(q1)+(0.5,1)$) {};
\node (q4v1) at ($(q4)+(0,1)$) {};
\node (q4primev1) at ($(q4prime)+(0,1)$) {};
\path[draw, densely dotted] (q1) edge node {} (q1v1);
\path[draw, densely dotted] (q1) edge node {} (q1v2);
\path[draw, densely dotted] (q4) edge node {} (q4v1);
\path[draw, densely dotted] (q4prime) edge node {} (q4primev1);
\end{tikzpicture}
\caption{The stochastic process associated with the MBP in Figure \ref{matteo_pic1}.}
\label{matteo_pic3}
\end{figure}
 



\begin{comment}
When $B_\exists\!=\!B_\forall\!=\! \emptyset$ (i.e. when $\mathcal{M}$ is a Markov chain) the produced $T$ has only one infinite branch and can, therefore, be identified as a chain. Hence the stochastic process associated with MBP's generalizes that of Markov chains. 
\end{comment}


The collection of branching plays in a MBP $\mathcal{M}$ starting from a state $s$ is denoted by $\mathcal{BP}(\mathcal{M},s)$. The set $\mathcal{BP}(\mathcal{M},s)$ naturally carries a Polish topology making $\mathcal{BP}(\mathcal{M},s)$ homeomorphic to the Cantor space (see, e.g., Definition 4.4 in \cite{MIO2012b}). The stochastic process associated to a MBP $\mathcal{M}$, specified on the previous page, can be naturally formalized by a probability measure $\mu_{\mathcal{M}}$ over the space $\mathcal{BP}(\mathcal{M},s)$ of branching plays. See also Definition 4.7 in \cite{MIO2012b} for a formal definition.



Each branching play $T$ can itself be viewed as an ordinary (infinite) two-player parity game $\mathcal{G}(T)$, played on the tree structure of $T$,  by interpreting the vertices of $T$ labeled by $\exists$-branching and $\forall$-branching states as under the control of Player $\exists$ and Player $\forall$, respectively. All other states (i.e., those labeled by a probabilistic state) have a unique successor in $T$ to which the game $\mathcal{G}(T)$ progresses automatically. Lastly, the parity condition associated to each vertex corresponds to the parity assigned in $\mathcal{M}$ to the state labeling it.  We denote with $\mathcal{W}_s$ the set of branching plays starting at $s$ and winning for Player $\exists$, i.e., the set defined as: $\mathcal{W}_s = \big\{ T \in \mathcal{BP}(\mathcal{M},s) \mid \textnormal{ Player $\exists$ has a winning strategy in }\mathcal{G}(T) \big\}$.

\begin{definition}[Value of a MBP]
The \emph{value} of a MBP $\mathcal{M}$ at a state $s$, denoted by $val(\mathcal{M},s)$, is the probability of generating a branching play winning for $\exists$ starting the stochastic process from the state $s$. Formally, $val(\mathcal{M},s)= \mu_{\mathcal{M}}(\mathcal{W}_s)$.
\end{definition}

We remark that the above definition is valid because the set $\mathcal{W}_s$ is $\mu$-measurable for every Borel measure $\mu$ on the space $\mathcal{BP}(\mathcal{M},s)$ (\cite{GMMS2014}) and thus also for $\mu_{\mathcal{M}}$. 

\subsection{How to compute the value of a MBP}\label{subsection_howto_compute}
In this subsection we show how the values  $val(\mathcal{M},s)$ can be computed. The algorithm is based on a result of \cite{MioThesis,MIO2012b}, formulated as Theorem \ref{main_theorem_MBP} below, characterizing such values as the solution of an appropriate system of (least and greatest) fixed-point equations. We first formulate Proposition \ref{bellman} exposing a fixed-point property of the value of MBP's. Let us fix a MBP $\mathcal{M}\!=\!\langle (S,E), (S_{P}, B_\exists,B_\forall), p , Par \rangle$ with $S\!=\! \{s_1\dots s_n\}$. 
To improve readability we just write $val_i$ for $val(\mathcal{M},s_i)$ and we denote by $val$ the vector  $val\!=\!(val_i)_{1\leq i \leq n}$ of length $n$. The symbols $\sum$ and $\prod$ denote the usual operations of sum and product on reals. We also use a ``coproduct'' operation defined as  $\coprod_{i\in I}x_i \!= \!  1-\prod_{i\in I }1-x_i$. 


\begin{proposition}\label{bellman}
  The equality $val \!=\! f(val)$ holds, where  $f\!:\![0,1]^n \!\rightarrow\! [0,1]^n$ is:
\begin{center}
$
\big(f\begin{pmatrix} 
x_1\\ 
\vdots\\
x_n
\end{pmatrix}\big)_i = \left\{\begin{array}{l  l}      
								\displaystyle 	\sum_{\{ j \ \mid \ (s_i,s_j)\in E\}} p(s_i)(s_j) \cdot x_j \ \ & \textnormal{if }\ s_i\!\in\! S_{P} \vspace{5pt} \\
								\displaystyle \prod_{\{ j\  \mid \ (s_i,s_j)\in E\}} x_j & \textnormal{if } \  s_i\!\in\! B_{\forall} \vspace{5pt} \\
								\displaystyle \coprod_{\{ j\  \mid\  (s_i,s_j)\in E\}} x_j & \textnormal{if } \  s_i\!\in\! B_{\exists}
                      	      \end{array}      \right.
$
\end{center}
\end{proposition}

\begin{proof} 
Here we sketch the main idea of the argument, for a formal proof, see Theorem 4.22 of \cite{MIO2012b}.
If $s_i$ is a probabilistic state, then $val_i$ is the weighted average of the value of its successors, since the stochastic process associated with the MBP chooses a unique successor $s_j$ of $s_i$ with probability $p(s_i)(s_j)$.  If $s_i$ is a $\forall$-branching state, then $val_i$ is the probability that all \emph{independently} generated subtrees are winning for Player $\exists$ and this is captured by the $\prod$ expression. Similarly, if $s_i$ is a $\exists$-branching state then $val_i$ is the probability that at least one generated subtree is winning for Player $\exists$, as formalized by the $\coprod$ expression.
Hence the vector $val$ is one of the fixed-points of the function $f\!:\![0,1]^n \!\rightarrow\! [0,1]^n$.
\end{proof}
Theorem \ref{main_theorem_MBP} below refines Proposition \ref{bellman} by identifying $val$ as the unique vector satisfying a system of nested (least and greatest) fixed-point equations. Its formulation closely follows the notation adopted in the textbook \cite[\S 4.3]{Rudiments2001} for presenting a similar result valid for ordinary parity games. To adhere to such notation, we will define a function $g$, a variant of the function $f$ presented above. Let $k\!=\!\max\{ Par(s) \mid s\!\in\! S\}$ and $l \!=\!\min\{ Par(s) \mid s\!\in\! S\}$  be the maximal and minimal priorities used in the MBP, respectively, and let $c\!=\!k-l+1$. 


\begin{definition}\label{definition_of_g}
The function $g\!:\! ([0,1]^n)^{c} \rightarrow [0,1]^n$ is defined as follows:
\begin{center}
$
\big(g\begin{pmatrix} 
x^l_1\\ 
\vdots\\
x^l_n
\end{pmatrix},\dots, \begin{pmatrix} 
x^k_1\\ 
\vdots\\
x^k_n
\end{pmatrix} \big)_i = \left\{      \begin{array}{l  l}      

									\displaystyle 	\sum_{\{ j \ \mid \ (s_i,s_j)\in E\}} p(s_i)(s_j) \cdot x^{Par(s_j)}_j \ \ & \textnormal{if }  s_i\!\in\! S_{P}\\ \vspace{5pt}
						
								\displaystyle \prod_{\{ j\  \mid \ (s_i,s_j)\in E\}} x^{Par(s_j)}_j & \textnormal{if } \  s_i\!\in\! B_{\forall}\\ \vspace{5pt}

								\displaystyle \coprod_{\{ j\  \mid\  (s_i,s_j)\in E\}} x^{Par(s_j)}_j & \textnormal{if } \  s_i\!\in\! B_{\exists}\\ 

                      	      		     \end{array}      \right.
$
\end{center}
\end{definition}

The function $g$ depends, like the function $f$,  only on $n$ variables $\{ x^{Par(s_1)}_1, \dots, x^{Par(s_n)}_n\}$ appearing in the body of its definition. The input of $g$ can indeed be regarded as the input of $f$ divided into $c$ baskets, where each variable $x_i$ is put in the basket corresponding  to the priority of $s_i$, for $1\!\leq \! i \!\leq\! n$.

The set $[0,1]^n$, equipped with the pointwise order defined as \[(x_1,\dots,x_n)\!\leq\!(y_1,\dots,y_n) \Leftrightarrow \forall i. (x_i\leq y_i),\] is a complete lattice and the function $g$ is monotone with respect to this order in each of its arguments. Hence the Knaster--Tarski theorem ensures the existence of least and greatest points.  We are now ready to state the main result regarding the values of a given MBP. We adopt standard $\mu$-calculus notation (see, e.g., \cite{Rudiments2001} and \cite{MioThesis,MIO2012b}) to express systems of least and greatest fixed-points equations.
\begin{theorem}[{\cite[Theorem 6.4.2]{MioThesis}}]\label{main_theorem_MBP}
\label{corr1}
The following equality holds:\footnote{Theorem 6.4.2 of \cite{MioThesis} actually proves a stronger result valid for arbitrary $2\frac{1}{2}$-player meta-parity games whereas, as mentioned in the beginning of this section, Markov branching plays are $2\frac{1}{2}$-player meta-parity games without Player $1$ and Player $2$ states. Also, Theorem 6.4.2 of \cite{MioThesis} is stated assuming the validity of the set-theoretic axiom $\textnormal{MA}_{\aleph_1}$, but as shown in \cite{GMMS2014}, such assumption is not necessary and can thus be dropped. 
}


\[ 
\begin{pmatrix} 
val_1\\ 
\vdots\\
val_n
\end{pmatrix}
=
\theta_k
\begin{pmatrix} 
x^k_1\\ 
\vdots\\
x^k_n
\end{pmatrix}.
\cdots
.\theta_l
\begin{pmatrix} 
x^l_1\\ 
\vdots\\
x^l_n
\end{pmatrix}.
g(\begin{pmatrix} 
x^l_1\\ 
\vdots\\
x^l_n
\end{pmatrix},
\ldots,
\begin{pmatrix} 
x^k_1\\ 
\vdots\\
x^k_n
\end{pmatrix}) \]
where $\theta_i$, for $l \!\leq\! i\! \leq\! k$ is a least-fixed point operator ($\mu$) if $i$ is an odd number and a greatest-fixed point operator if ($\nu$) if $i$ is even.
\end{theorem}
\begin{proof}
The proof goes by induction on the number of priorities in the MBP $\mathcal{M}$ and by transfinite induction on a rank-function defined on the space of branching plays.  See \cite{MioThesis} for a detailed proof.
\end{proof}

\noindent


The next theorem states that the value of a MBP is computable and is always a vector of algebraic numbers. 
The examples discussed in Section \ref{examples_section} will illustrate the applicability of this result.

\begin{theorem}\label{computability_of_MBP}
Let $\mathcal{M}$ be a MBP. Then for each state $s_i$ of $\mathcal{M}$ the value $val_i$ is computable and is an algebraic number.\end{theorem}
\begin{proof} (sketch)
Using known ideas (see, e.g., Lemma 9 in \cite{AM04} and Proposition 4.1 in \cite{MioSimpsonFICS2013}) the unique vector $val\!=\!(val_1,\dots, val_n)$ satisfying the system of fixed-point expressions $\mathcal{S}$ given by Theorem \ref{main_theorem_MBP} can be computed by a reduction to the first-order theory of real closed fields. 
A first order formula $F(x_1,\dots,x_n)$, inductively defined from $\mathcal{S}$, is constructed with the property that $(val_1,\dots, val_n)\!\in\!\mathbb{R}^n$ is the unique vector of reals satisfying the formula $F(x_1,\dots,x_n)$. By Tarski's quantifier elimination procedure \cite{Tarski1951}, the formula $F(x_1,\dots,x_n)$ can be effectively reduced to an equivalent formula $G(x_1,\dots, x_n)$ without quantifiers, that is, to a Boolean combination of equations and inequalities between polynomials over $(x_1,\dots,x_n)$. It then follows that the  $(val_1,\dots, val_n)$, which can be extracted from $G$ with standard methods, is a vector of algebraic numbers.  In Section \ref{sec:examples} we apply the procedure described above to a number of examples.
\end{proof}

\begin{algorithm}[caption={computing the vector of values of a MBP.}, label={alg1}]
 input: $\textnormal{a Markov Branching Play } {\mathcal M}$. 
 output: $\textnormal{algebraic numbers }r_1,\ldots,r_n\in{\mathbb R} \textnormal{ equal to } (val_1,\ldots,val_n)$. 
 begin
   $\mathcal{S}\gets \textnormal{Generate system of fixed--point equations associated to }\mathcal{M}$
   $F(x_1,\ldots,x_n)\gets \textnormal{Rewrite }\mathcal{S} \textnormal{ to the corresponding first-order formula over\ } FO(\mathbb{R},<,0,1,+,\times) $
   $G(x_1,\ldots,x_n)\gets \textnormal{Apply quantifier elimination procedure to } F(x_1,\ldots,x_n)$
 return $\textnormal{the unique vector }(r_1,\dots, r_n) \textnormal{ satisfying } G(x_1,\dots, x_n)$ 
\end{algorithm}

\begin{comment}
The unique vector $val$ satisfying the system of fixed-point expression given by Theorem \ref{main_theorem_MBP} can be computed by application of Tarski's celebrated quantifier elimination algorithm. This type of reduction have been already used (see, e.g.,  Lemma 9 in \cite{AM04} and Proposition 4.1 in \cite{MioSimpsonFICS2013}) for computing the solutions of other kinds of systems of fixed-point expressions ($\mu$-calculi) over ${\mathbb R}$. For space reasons, here we only sketch the main ideas. Vectors $\vec{x}\!\in\![0,1]^n$ are represented by $n$-tuples $x_1,\dots, x_n$ of first-order real variables, with the constraint $\bigwedge^n_{i=1} (0\!\leq\! x_i\! \leq\! 1)$. The predicate $\vec{x}\!\sqsubseteq\! \vec{y}$ of point-wise order on vectors is definable by the formula $\bigwedge^n_{i=1} (x_i\!\leq\! y_i)$. The graph\footnote{This is the $(n+1)$-ary relation $G$ defined as $g(\vec{x}^1,\dots, \vec{x}^k)\!=\!\vec{y} \leftrightarrow G(\vec{x}^1,\dots, \vec{x}^k,\vec{y})$} $G$ of the function $g$ is directly definable by a formula $G(\vec{x}^1,\dots, \vec{x}^n,\vec{y})$ in the first-order theory of real closed fields. Lastly, fixed-point operators are definable in first-order logic by the general, and not specific to our present setting, scheme $\mu \vec{x}. \phi (\vec{x},\vec{y}) \!=\!  \exists \vec{x}. \Big(\vec{x} \!=\! \phi (\vec{x},\vec{y})  \wedge \big( \forall \vec{z}. \vec{z}\!=\! \phi (\vec{z},\vec{y}) \rightarrow \vec{x}\! \sqsubseteq\! \vec{y}\Big)$.  As a result, it is possible to translate the expression of Theorem \ref{main_theorem_MBP} to a first-order formula $F(\vec{y})$ such that unique vector $\vec{y}\!\in\![0,1]^n$ satisfying $F(\vec{y})$ is $val$. By applying Tarski's  quantifier elimination procedure, the formula $F$ can be rewritten into an equivalent formula without quantifiers. This is a system of polynomial inequalities and equations over ${\mathbb R}$, hence the solutions are algebraic numbers. \end{comment}

\begin{comment}
Since the fields or reals and algebraic numbers are elementary equivalent by standard methods, $val$ is necessarily a vector of algebraic numbers. The following result then follows.
\end{comment}



