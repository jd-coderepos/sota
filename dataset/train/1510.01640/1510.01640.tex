

In this Section we describe a class of stochastic processes called \emph{Markov branching plays} (MBP's) \cite{MioThesis,MIO2012b}  which, as we will observe, is closely related to game automata and will provide a method for calculating the probability of regular languages defined by such automata.  
For a quick overview, a procedure for computing the value associated with a MBP is presented as Algorithm \ref{alg1}, at the end of this section. The procedure for computing the probability  of regular languages defined by game automata in presented as Algorithm \ref{alg2} in the next section.



We assume familiarity with the standard concepts of Markov chain and two-player stochastic (-player) parity game (see, e.g.,  \cite{ChatPhD}).  Ordinary -player parity games are played on directed graphs whose set of states is partitioned into Player , Player  and probabilistic states. A -player parity game with neither Player  nor Player  states can be identified with a \emph{Markov chain}. 



\begin{comment}
Recall that ordinary -player parity games  are played on directed graphs whose set of states is partitioned into Player  and Player  states, where the two players make their moves, and probabilistic states, where the game progresses to a successor state following a prescribed probabilistic rule. A -player parity game without Player  states is called a \emph{Markov Decision Process} (MDP). A -player parity game with neither Player  nor Player  states (i.e., only having probabilistic states) can be identified with a \emph{Markov chain}. \todo{Here I uncommented certain piece which was reserved for the journal version.}
\end{comment}

\emph{Two-player stochastic} \emph{meta-parity games} \cite{MioThesis,MIO2012b} generalize -player parity games by allowing the directed graph to have two additional kinds of states called --branching states and --branching states. In this paper we will only consider -player meta-parity games with neither Player  nor Player  states. Such structures, which thus constitute a generalization of Markov chains, are called \emph{Markov branching plays} (MBP's). In what follows we provide a quick description of MBP and refer to \cite{MioThesis} for a detailed account.

\begin{definition}[Markov Branching Play]
A Markov branching play (MBP) is a structure  where:
\begin{itemize}
\item   is a directed graph with finite set of vertices  and transition relation . We say that  is a successor of  if . We assume that each vertex has at least one successor state in the graph  . 
\item The triple  is a partition of  into probabilistic, -branching and -branching states.
\item The function  associates to each probabilistic state  a discrete probability distribution  supported over the (nonempty) set of successors of  in the graph . 
\item Lastly, the function  is the \emph{parity (or priority) assignment}. 
\end{itemize}\end{definition}



\begin{comment}
In what follows we identify Markov chains with MBP's without --branching nor --branching states, i.e., such that .

As usual, a Markov chain  represents the stochastic process associated with a \emph{random infinite walk} on it's set of states, i.e., an infinite sequence of states randomly generated in accordance with the probability transition function . 
\end{comment}

Recall that a Markov chain represents the stochastic process associated with a \emph{random infinite walk} on its set of states. A MBP represents the more involved stochastic process, described below, of generation of a random unranked and unordered \emph{tree}  whose vertices are labeled by states of the MDP. 

\vspace{5mm}
\noindent
\emph{MBP's as Stochastic Processes:} given a MBP  and an initial vertex , the stochastic process of construction of  is described as follows. 
\begin{itemize}
\item 
The construction starts from the root of  which is labeled by . 
\item A leaf  in the so far constructed tree  is extended, \emph{independently} from all other leaves, depending on the type of its labeling state , as follows:
\begin{itemize}
\item If  then  is extended with a unique child which is labeled by a successor state  of  randomly chosen in accordance with . 
\item If  or  and  are the successors of  in , then  is extended with  children  and  is labeled by , for . 
\end{itemize}
\end{itemize}

We give in Figure \ref{matteo_pic1} an example of a MBP. Probabilistic states, -branching and -branching states are marked as circles, diamond and boxes, respectively.  The first six initial steps of the stochastic process associated with  at state  are depicted in Figure \ref{matteo_pic3}.
In the first step, the construction of  starts by labeling the root by . Since  is a probabilistic state, the tree is extended (second step) with only one child labeled by either  (with probability ) or  (prob. . The picture  shows the case when  is chosen. Since the new leaf is labeled by , and this is a -branching state, the tree is extended by adding one new vertex for each successor of  in , i.e., for both  and . The construction continues as described above. For example, the probability that the generated infinite tree will have the prefix as at the bottom right of Figure \ref{matteo_pic3} is .
\begin{figure}[H] 
\centering
\begin{tikzpicture}[scale=.2,->,level distance=0.7in,sibling distance=.4in]

\clip (-10,-2) rectangle (10, 17);


\node (q1) [draw, circle, minimum size = \diameter,inner sep=2] {};
\node (q2) [draw, diamond, aspect = 1.5, minimum size = 2*\diameter,inner sep=1] at () {};
\node (q3) [draw, minimum size = 1.5*\diameter,inner sep=4] at () {};
\node (q4) [draw, circle, minimum size = \diameter,{font=\small},inner sep=2]  at () {};
\path (q1) edge [{font=\small}] node[right = 0.05cm, near end] {} (q2);
\path (q1) edge [{font=\small}] node[left = 0.05cm, near end] {} (q3);
\path (q2) edge [bend right=40] node {} (q1);
\path (q2) edge node {} (q4);
\path (q3) edge [bend left=40] node {} (q1);
\path (q3) edge node {} (q4);
\path (q4) edge [font=\small, loop above] node {} (q4);
\path (q4) edge [font=\small, left = 0.05cm, near end, bend right=40] node {} (q2);



\end{tikzpicture}



\caption{An example of a MBP.}
\label{matteo_pic1}
\end{figure}
 
The kind of infinite trees produced by the stochastic process just described are called \emph{branching plays}. Branching plays are characterized by the property that each vertex labeled with a probabilistic state has only one child, and each vertex labeled with a ( or ) branching state  has as many children as there are successors of  in the MBP. \begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.7,->,level distance=0.4in,sibling distance=.15in]

\tikzset{grow'=up}
\Tree 
[.\node [draw, circle, minimum size = 2*\diameter] {};
        \edge[{font=\small}] node[right = 0.05cm, near end] {};
        [.\node [draw, diamond, aspect = 1.5, minimum size = 2*\diameter] {};
            [.\node [draw, circle, minimum size = 2*\diameter] {};
                \node [draw, minimum size = 4*\diameter] {};
            ]
            \node [draw, circle, minimum size = 2*\diameter] {};
        ]
]

\begin{scope}[shift={(5cm,0cm)}]
\Tree 
[.\node [draw, circle, minimum size = 2*\diameter] {};
        \edge[{font=\small}] node[right = 0.05cm, near end] {};
        [.\node [draw, diamond, aspect = 1.5, minimum size = 2*\diameter] {};
            [.\node [draw, circle, minimum size = 2*\diameter] {};
                \node [draw, minimum size = 4*\diameter] {};
            ]
            [.\node [draw, circle, minimum size = 2*\diameter] {};
                \node [draw, circle, minimum size = 2*\diameter] {};
            ]
        ]
]
\end{scope}

\begin{scope}[shift={(10cm,0cm)}]
\Tree 
[.\node [draw, circle, minimum size = 2*\diameter] {};
        \edge[{font=\small}] node[right = 0.05cm, near end] {};
        [.\node [draw, diamond, aspect = 1.5, minimum size = 2*\diameter] {};
            [.\node [draw, circle, minimum size = 2*\diameter] {};
                [.\node [draw, minimum size = 4*\diameter] {};
                    \node (q1) [draw, circle, minimum size = 2*\diameter] {};
                    \node (q4) [draw, circle, minimum size = 2*\diameter] {};
                ]
            ]
            [.\node [draw, circle, minimum size = 2*\diameter] {};
                \node (q4prime) [draw, circle, minimum size = 2*\diameter] {};
            ]
        ]
]
\end{scope}

\begin{scope}[shift={(0cm,5.5cm)}]
\Tree 
[.\node [draw, circle, minimum size = 2*\diameter] {};
]
\end{scope}

\begin{scope}[shift={(5cm,5.5cm)}]
\Tree 
[.\node [draw, circle, minimum size = 2*\diameter] {};
        \edge[{font=\small}] node[right = 0.05cm, near end] {};
        \node [draw, diamond, aspect = 1.5, minimum size = 2*\diameter] {};
]
\end{scope}

\begin{scope}[shift={(10cm,5.5c m)}]
\Tree 
[.\node [draw, circle, minimum size = 2*\diameter] {};
        \edge[{font=\small}] node[right = 0.05cm, near end] {};
        [.\node [draw, diamond, aspect = 1.5, minimum size = 2*\diameter] {};
            \node [draw, circle, minimum size = 2*\diameter] {};
            \node [draw, circle, minimum size = 2*\diameter] {};
        ]
]
\end{scope}

\node (q1v1) at () {};
\node (q1v2) at () {};
\node (q4v1) at () {};
\node (q4primev1) at () {};
\path[draw, densely dotted] (q1) edge node {} (q1v1);
\path[draw, densely dotted] (q1) edge node {} (q1v2);
\path[draw, densely dotted] (q4) edge node {} (q4v1);
\path[draw, densely dotted] (q4prime) edge node {} (q4primev1);
\end{tikzpicture}
\caption{The stochastic process associated with the MBP in Figure \ref{matteo_pic1}.}
\label{matteo_pic3}
\end{figure}
 



\begin{comment}
When  (i.e. when  is a Markov chain) the produced  has only one infinite branch and can, therefore, be identified as a chain. Hence the stochastic process associated with MBP's generalizes that of Markov chains. 
\end{comment}


The collection of branching plays in a MBP  starting from a state  is denoted by . The set  naturally carries a Polish topology making  homeomorphic to the Cantor space (see, e.g., Definition 4.4 in \cite{MIO2012b}). The stochastic process associated to a MBP , specified on the previous page, can be naturally formalized by a probability measure  over the space  of branching plays. See also Definition 4.7 in \cite{MIO2012b} for a formal definition.



Each branching play  can itself be viewed as an ordinary (infinite) two-player parity game , played on the tree structure of ,  by interpreting the vertices of  labeled by -branching and -branching states as under the control of Player  and Player , respectively. All other states (i.e., those labeled by a probabilistic state) have a unique successor in  to which the game  progresses automatically. Lastly, the parity condition associated to each vertex corresponds to the parity assigned in  to the state labeling it.  We denote with  the set of branching plays starting at  and winning for Player , i.e., the set defined as: \exists.

\begin{definition}[Value of a MBP]
The \emph{value} of a MBP  at a state , denoted by , is the probability of generating a branching play winning for  starting the stochastic process from the state . Formally, .
\end{definition}

We remark that the above definition is valid because the set  is -measurable for every Borel measure  on the space  (\cite{GMMS2014}) and thus also for . 

\subsection{How to compute the value of a MBP}\label{subsection_howto_compute}
In this subsection we show how the values   can be computed. The algorithm is based on a result of \cite{MioThesis,MIO2012b}, formulated as Theorem \ref{main_theorem_MBP} below, characterizing such values as the solution of an appropriate system of (least and greatest) fixed-point equations. We first formulate Proposition \ref{bellman} exposing a fixed-point property of the value of MBP's. Let us fix a MBP  with . 
To improve readability we just write  for  and we denote by  the vector   of length . The symbols  and  denote the usual operations of sum and product on reals. We also use a ``coproduct'' operation defined as  . 


\begin{proposition}\label{bellman}
  The equality  holds, where   is:
\begin{center}

\end{center}
\end{proposition}

\begin{proof} 
Here we sketch the main idea of the argument, for a formal proof, see Theorem 4.22 of \cite{MIO2012b}.
If  is a probabilistic state, then  is the weighted average of the value of its successors, since the stochastic process associated with the MBP chooses a unique successor  of  with probability .  If  is a -branching state, then  is the probability that all \emph{independently} generated subtrees are winning for Player  and this is captured by the  expression. Similarly, if  is a -branching state then  is the probability that at least one generated subtree is winning for Player , as formalized by the  expression.
Hence the vector  is one of the fixed-points of the function .
\end{proof}
Theorem \ref{main_theorem_MBP} below refines Proposition \ref{bellman} by identifying  as the unique vector satisfying a system of nested (least and greatest) fixed-point equations. Its formulation closely follows the notation adopted in the textbook \cite[\S 4.3]{Rudiments2001} for presenting a similar result valid for ordinary parity games. To adhere to such notation, we will define a function , a variant of the function  presented above. Let  and   be the maximal and minimal priorities used in the MBP, respectively, and let . 


\begin{definition}\label{definition_of_g}
The function  is defined as follows:
\begin{center}

\end{center}
\end{definition}

The function  depends, like the function ,  only on  variables  appearing in the body of its definition. The input of  can indeed be regarded as the input of  divided into  baskets, where each variable  is put in the basket corresponding  to the priority of , for .

The set , equipped with the pointwise order defined as  is a complete lattice and the function  is monotone with respect to this order in each of its arguments. Hence the Knaster--Tarski theorem ensures the existence of least and greatest points.  We are now ready to state the main result regarding the values of a given MBP. We adopt standard -calculus notation (see, e.g., \cite{Rudiments2001} and \cite{MioThesis,MIO2012b}) to express systems of least and greatest fixed-points equations.
\begin{theorem}[{\cite[Theorem 6.4.2]{MioThesis}}]\label{main_theorem_MBP}
\label{corr1}
The following equality holds:\footnote{Theorem 6.4.2 of \cite{MioThesis} actually proves a stronger result valid for arbitrary -player meta-parity games whereas, as mentioned in the beginning of this section, Markov branching plays are -player meta-parity games without Player  and Player  states. Also, Theorem 6.4.2 of \cite{MioThesis} is stated assuming the validity of the set-theoretic axiom , but as shown in \cite{GMMS2014}, such assumption is not necessary and can thus be dropped. 
}



where , for  is a least-fixed point operator () if  is an odd number and a greatest-fixed point operator if () if  is even.
\end{theorem}
\begin{proof}
The proof goes by induction on the number of priorities in the MBP  and by transfinite induction on a rank-function defined on the space of branching plays.  See \cite{MioThesis} for a detailed proof.
\end{proof}

\noindent


The next theorem states that the value of a MBP is computable and is always a vector of algebraic numbers. 
The examples discussed in Section \ref{examples_section} will illustrate the applicability of this result.

\begin{theorem}\label{computability_of_MBP}
Let  be a MBP. Then for each state  of  the value  is computable and is an algebraic number.\end{theorem}
\begin{proof} (sketch)
Using known ideas (see, e.g., Lemma 9 in \cite{AM04} and Proposition 4.1 in \cite{MioSimpsonFICS2013}) the unique vector  satisfying the system of fixed-point expressions  given by Theorem \ref{main_theorem_MBP} can be computed by a reduction to the first-order theory of real closed fields. 
A first order formula , inductively defined from , is constructed with the property that  is the unique vector of reals satisfying the formula . By Tarski's quantifier elimination procedure \cite{Tarski1951}, the formula  can be effectively reduced to an equivalent formula  without quantifiers, that is, to a Boolean combination of equations and inequalities between polynomials over . It then follows that the  , which can be extracted from  with standard methods, is a vector of algebraic numbers.  In Section \ref{sec:examples} we apply the procedure described above to a number of examples.
\end{proof}

\begin{algorithm}[caption={computing the vector of values of a MBP.}, label={alg1}]
 input: . 
 output: . 
 begin
   
   
   
 return  
\end{algorithm}

\begin{comment}
The unique vector  satisfying the system of fixed-point expression given by Theorem \ref{main_theorem_MBP} can be computed by application of Tarski's celebrated quantifier elimination algorithm. This type of reduction have been already used (see, e.g.,  Lemma 9 in \cite{AM04} and Proposition 4.1 in \cite{MioSimpsonFICS2013}) for computing the solutions of other kinds of systems of fixed-point expressions (-calculi) over . For space reasons, here we only sketch the main ideas. Vectors  are represented by -tuples  of first-order real variables, with the constraint . The predicate  of point-wise order on vectors is definable by the formula . The graph\footnote{This is the -ary relation  defined as }  of the function  is directly definable by a formula  in the first-order theory of real closed fields. Lastly, fixed-point operators are definable in first-order logic by the general, and not specific to our present setting, scheme .  As a result, it is possible to translate the expression of Theorem \ref{main_theorem_MBP} to a first-order formula  such that unique vector  satisfying  is . By applying Tarski's  quantifier elimination procedure, the formula  can be rewritten into an equivalent formula without quantifiers. This is a system of polynomial inequalities and equations over , hence the solutions are algebraic numbers. \end{comment}

\begin{comment}
Since the fields or reals and algebraic numbers are elementary equivalent by standard methods,  is necessarily a vector of algebraic numbers. The following result then follows.
\end{comment}



