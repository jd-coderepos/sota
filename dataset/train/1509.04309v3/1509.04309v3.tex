


\documentclass[10pt,journal,cspaper,compsoc]{IEEEtran}

\usepackage{float}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage[lined]{algorithm2e}

\newcommand\blue[1]{\textcolor{blue}{#1}}
\newcommand\red[1]{\textcolor{red}{#1}}



\newcommand{\R}[1]{\mathbb{R}^{#1}}
\newcommand{\RR}[2]{\mathbb{R}^{#1 \times #2}}
\newcommand{\Bin}[2]{[0,1]^{#1 \times #2}}
\newcommand{\G}{\mathcal{G}}

\newcommand{\inner}[2]{\langle #1, #2\rangle}
\newcommand{\norm}[2]{\left\|#1\right\|_{#2}}
\newcommand{\med}[1]{\mbox{median}\left{#1\right}}
\newcommand{\trace}[1]{\mbox{trace}\left(#1\right)}
\newcommand{\rank}[1]{\mbox{rank}\left(#1\right)}
\newcommand{\vect}[1]{\mbox{vec}\left(#1\right)}
\newcommand{\conv}[1]{\mbox{conv}\left(#1\right)}
\newcommand{\diag}{\mbox{diag}}
\newcommand{\proj}{\mathcal{P}}
\newcommand{\svt}{\mathcal{D}}
\newcommand{\prox}{\mbox{prox}}
\newcommand{\st}{\mbox{s.t.~}}


\newcommand{\refLemma}[1]{Lemma~\ref{#1}}
\newcommand{\refEq}[1]{(\ref{#1})}
\newcommand{\refFig}[1]{Figure~\ref{#1}}
\newcommand{\refProp}[1]{Proposition~\ref{#1}}
\newcommand{\refTheor}[1]{Theorem~\ref{#1}}
\newcommand{\refSec}[1]{Section~\ref{#1}}
\newcommand{\refCh}[1]{Chapter~\ref{#1}}
\newcommand{\refAlg}[1]{Algorithm~\ref{#1}}
\newcommand{\refTab}[1]{Table~\ref{#1}}
\newcommand{\refBib}[1]{\citep{#1}}
\newcommand{\refApp}[1]{Appendix~\ref{#1}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}
\newenvironment{remark}[1][Remark]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}


\def\Pr{\text{Pr}}
\def\eg{{e.g.~}}
\def\ie{{i.e.~}}
\def\vs{{vs.~}}
\def\wrt{w.r.t.~}
\def\etal{{et al.~}}
\def\iid{i.i.d.~}
\def\etc{{etc.~}}

\def\bfa{{\boldsymbol{a}}}
\def\bfb{{\boldsymbol{b}}}
\def\bfc{{\boldsymbol{c}}}
\def\bfd{{\boldsymbol{d}}}
\def\bfe{{\boldsymbol{e}}}
\def\bff{{\boldsymbol{f}}}
\def\bfg{{\boldsymbol{g}}}
\def\bfh{{\boldsymbol{h}}}
\def\bfi{{\boldsymbol{i}}}
\def\bfj{{\boldsymbol{j}}}
\def\bfk{{\boldsymbol{k}}}
\def\bfl{{\boldsymbol{l}}}
\def\bfm{{\boldsymbol{m}}}
\def\bfn{{\boldsymbol{n}}}
\def\bfo{{\boldsymbol{o}}}
\def\bfp{{\boldsymbol{p}}}
\def\bfq{{\boldsymbol{q}}}
\def\bfr{{\boldsymbol{r}}}
\def\bfs{{\boldsymbol{s}}}
\def\bft{{\boldsymbol{t}}}
\def\bfu{{\boldsymbol{u}}}
\def\bfv{{\boldsymbol{v}}}
\def\bfw{{\boldsymbol{w}}}
\def\bfx{{\boldsymbol{x}}}
\def\bfy{{\boldsymbol{y}}}
\def\bfz{{\boldsymbol{z}}}
\def\bfA{{\boldsymbol{A}}}
\def\bfB{{\boldsymbol{B}}}
\def\bfC{{\boldsymbol{C}}}
\def\bfD{{\boldsymbol{D}}}
\def\bfE{{\boldsymbol{E}}}
\def\bfF{{\boldsymbol{F}}}
\def\bfG{{\boldsymbol{G}}}
\def\bfH{{\boldsymbol{H}}}
\def\bfI{{\boldsymbol{I}}}
\def\bfJ{{\boldsymbol{J}}}
\def\bfK{{\boldsymbol{K}}}
\def\bfL{{\boldsymbol{L}}}
\def\bfM{{\boldsymbol{M}}}
\def\bfN{{\boldsymbol{N}}}
\def\bfO{{\boldsymbol{O}}}
\def\bfP{{\boldsymbol{P}}}
\def\bfQ{{\boldsymbol{Q}}}
\def\bfR{{\boldsymbol{R}}}
\def\bfS{{\boldsymbol{S}}}
\def\bfT{{\boldsymbol{T}}}
\def\bfU{{\boldsymbol{U}}}
\def\bfV{{\boldsymbol{V}}}
\def\bfW{{\boldsymbol{W}}}
\def\bfX{{\boldsymbol{X}}}
\def\bfY{{\boldsymbol{Y}}}
\def\bfZ{{\boldsymbol{Z}}}

\def \bfalpha {\boldsymbol{\alpha}}
\def \bfbeta {\boldsymbol{\beta}}
\def \bfgamma {\boldsymbol{\gamma}}
\def \bfmu {\boldsymbol{\mu}}
\def \bfsigma {\boldsymbol{\sigma}}

\def\bfzero{{\boldsymbol{0}}}
\def\bfone{{\boldsymbol{1}}}
\def\half{\frac{1}{2}~}
\def\reg{\mathcal{R}}
\def\incmat{{\mathcal{A}}}
 




\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\begin{document}

\title{Sparse Representation for 3D Shape Estimation: A Convex Relaxation Approach}

\author{Xiaowei~Zhou,~\IEEEmembership{}
        Menglong Zhu, ~\IEEEmembership{}
        Spyridon Leonardos,~\IEEEmembership{}
        and~Kostas~Daniilidis,~\IEEEmembership{Fellow,~IEEE}\IEEEcompsocitemizethanks{\IEEEcompsocthanksitem The authors are with Computer and Information Science Department and GRASP Laboratory, University of Pennsylvania, Philadelphia,
PA, 19104.\protect\\
E-mail: xiaowz@seas.upenn.edu}\thanks{To appear in IEEE Transactions on Pattern Analysis and Machine Intelligence. \url{http://ieeexplore.ieee.org/document/7558185/}}}

\markboth{}{Zhou \MakeLowercase{\textit{et al.}}: Bare Advanced Demo of IEEEtran.cls for Journals}

\IEEEtitleabstractindextext{\begin{abstract}

We investigate the problem of estimating the 3D shape of an object defined by a set of 3D landmarks, given their 2D correspondences in a single image. A successful approach to alleviating the reconstruction ambiguity is the 3D deformable shape model and a sparse representation is often used to capture complex shape variability. But the model inference is still challenging due to the nonconvexity in the joint optimization of shape and viewpoint. In contrast to prior work that relies on an alternating scheme whose solution depends on initialization, we propose a convex approach to addressing this challenge and develop an efficient algorithm to solve the proposed convex program. We further propose a robust model to handle gross errors in the 2D correspondences. We demonstrate the exact recovery property of the proposed method, the advantage compared to several nonconvex baselines and the applicability to recover 3D human poses and car models from single images.
\end{abstract}
\begin{IEEEkeywords}
3D reconstruction, sparse representation, convex optimization.
\end{IEEEkeywords}}

\maketitle


\section{Introduction}

\begin{figure*}
  \centering
\includegraphics[width=0.9\linewidth]{figures/fig1.pdf}\\
  \caption{Illustration of the problem studied in this paper. The unknown 3D model is defined by a set of landmarks and assumed to be a linear combination of some predefined basis shapes with sparse coefficients. Given the 2D correspondences of the landmarks in a single image, the computational problem is to simultaneously estimate the coefficients of the sparse representation as well as the viewpoint of the camera.  }\label{fig:illustration}
\end{figure*}

Recognizing 3D objects from 2D images is a central problem in computer vision. Past years have witnessed an emerging trend towards analyzing 3D geometry of objects including shapes and poses instead of merely providing bounding boxes \cite{xiang2012estimating,aubry2014seeing}. The 3D geometric reasoning can not only provide richer information about the scene for subsequent high-level tasks such as scene understanding, augmented reality and human computer interaction, but also improve 2D recognition performances \cite{fidler20123d,simo2013joint}. 3D reconstruction has been a well studied problem and there have been many practically applicable techniques such as structure from motion, multi-view stereo and depth sensors, but these techniques are limited in some scenarios. For example, a large number of acquisitions from multiple views are often required in order to obtain a complete 3D model, which is not preferred in some real-time applications; the depth sensors in general cannot work outdoor and have a limited sensing range; and reconstructing a dynamic scene is still an open problem. In this paper, we aim to investigate the possibility of estimating the 3D shape of an object from a single 2D image, which is complementary to the aforementioned techniques and may potentially address the above issues.

Estimating the 3D geometry of an object from a single view is an ill-posed problem. But it is a possible task for a human observer, since human can leverage visual memory of object shapes. Inspired by this idea, much effort has been made towards 3D model-based analysis leveraging the increasing availability of online 3D model databases, such as the Google 3D warehouse that includes millions of CAD models of various objects and many publicly available shape scans and motion capture data that model the 3D shape and pose of human.

To address intra-class variability and nonrigid deformation and avoid exhaustively enumerating all possibilities, many previous works, e.g. \cite{hejrati2012analyzing,zia2013detailed}, adopted a 3D deformable model originated from the ``active shape model" \cite{cootes1995active} to represent shapes, where each shape is defined by a set of ordered landmarks and the one to be estimated is assumed as a linear combination of some basis shapes usually obtained from principal component analysis (PCA). For human poses, the sparse representation was proposed to handle highly articulated deformation of human bodies which cannot be captured by PCA \cite{ramakrishna2012reconstructing,wang2014robust}. In model inference, the 3D deformable model is matched to the landmarks annotated or detected in images, and the problem is reduced to a 3D-to-2D shape fitting problem where the shape (weights of the linear combination) and the viewpoint (camera extrinsic parameters) have to be estimated simultaneously. \refFig{fig:illustration} gives an illustration of the problem.

While this approach has achieved promising results in various applications, the model inference is still a challenging problem, since the subproblems of shape and viewpoint estimation are coupled: the viewpoint needs to be known in order to fit the 3D model to 2D, and inversely, the 3D model needs to be known in order to estimate the viewpoint. The joint estimation of shape and viewpoint results in a nonconvex optimization problem, and the orthogonality constraint on the camera rotation makes the problem even more complicated. Previous methods often rely on an alternating scheme to alternately update the shape and viewpoint parameters, which has no guarantee for global convergence and is sensitive to initialization. As mentioned in many previous works, e.g. \cite{ramakrishna2012reconstructing,hejrati2012analyzing}, most of the failed cases were attributed to bad initialization. Some heuristics have been proposed to address this issue, such as initializing multiple times \cite{wang2014robust} or using a viewpoint-aware detector \cite{zia2013detailed}. But there is still no guarantee for global optimality.

In this paper, we propose a convex relaxation approach to addressing the aforementioned issue. We use an augmented shape-space model, in which a shape is represented as a linear combination of rotatable basis shapes. This model gives a linear representation of both intrinsic shape deformation and extrinsic viewpoint changes. Next, we use the convex relaxation of the orthogonality constraint to convert the entire problem into a spectral-norm regularized least squares problem, which is a convex program. Then, we develop an efficient algorithm to solve the proposed convex program based on the alternating direction method of multipliers (ADMM). To achieve fast computation, we derive a closed-form solution to compute the proximal operator of the spectral norm. Furthermore, we extend the proposed model to handle outliers in the input 2D correspondences. This work extends its earlier version \cite{zhou20143d} with the extensions including postprocessing for rotation synchronization, outlier modeling, more experiments and real examples with learned detectors.

The remainder of this paper is organized as follows. We summarize related work in \refSec{sec:related}, formulate the problem in \refSec{sec:formulation}, introduce the proposed method and technical details in \refSec{sec:methods}, report empirical results in \refSec{sec:experiments}, and finally conclude the paper in \refSec{sec:discussion}. The code is available at \url{http://cis.upenn.edu/~xiaowz/shapeconvex.html}.

\section{Related work}\label{sec:related}

The most related work includes the ones that fit a 3D deformable model to the features in a 2D image. A popular application is human face modeling for various tasks such as recognition \cite{blanz2003face}, feature tracking \cite{gu20063d} and facial animation \cite{cao20133d}. Recently, there has been an increased number of works on 3D object modeling. For example, Hejrati and Ramanan \cite{hejrati2012analyzing} used the deformable model for 3D car modeling. They produced 2D landmarks by a variant of deformable part models \cite{felzenszwalb2008discriminatively} and then lifted the 2D model to 3D. Lin et al. \cite{lin2014jointly} proposed a method for joint 3D model fitting and fine-grained classification for cars. Zia \cite{zia2013detailed} et al. developed a probabilistic framework to simultaneously localize 2D landmarks and recover 3D object models.

While the conventional active shape model performs well to describe the shape variability of rigid objects, it can hardly handle the structural variability of nonrigid objects such as human bodies. To address this issue, Ramakrishna et al. \cite{ramakrishna2012reconstructing} proposed a sparse representation based approach to reconstructing 3D human pose from annotated joints in a still image. Wang et al. \cite{wang2014robust} adopted a 2D human pose detector to automatically locate the joints and used a robust estimator to handle inaccurate joint locations. Fan et al. \cite{fan2014pose} proposed to improve the performance of \cite{ramakrishna2012reconstructing} by enforcing locality when building the pose dictionary. Zhou and De La Torre \cite{zhou2014sptio} formulated human pose estimation as a matching problem, where a learned spatio-temporal pose model was matched to point trajectories extracted from a video. Akhter and Black \cite{akhter2015pose} integrated a joint-angle constraint into the sparse representation to reduce the possibility of invalid reconstruction.

Recently, there was growing interest in reconstructing category-specific object models from a collection of single images of different instances with the same category \cite{cashman2013shape,vicente2014reconstructing,carreira2015virtual,kar2015category}. The deformable shape model was adopted and fitted to either visual hulls in the pre-segmented images or landmarks annotated in the images, and at the same time the basis shapes were also learned from images during the model inference. The problem studied in this paper can be regarded as a subproblem in this process where the basis shapes are given.

A common component or an intermediate step in the works mentioned above is to fit a 3D deformable model to 2D correspondences. As we mentioned in the introduction, these works relied on nonconvex optimization, which may be sensitive to initialization. The convex formulation proposed in this paper can potentially serve as a building block or provide a good initialization to improve the performance of the existing methods.

Another line of work tried to solve single-image reconstruction by finding the nearest neighbor in the shape collection followed by a refinement step \cite{su2014estimating,huang2015single}. The initial shape and viewpoint were found by enumerating all instances and viewpoints and comparing the test image with the rendered one. The initial estimate was refined by optimizing both the viewpoint and nonrigid deformation according to image contours. This approach produces very detailed reconstruction and is applicable to a wide range of object categories, but it is computationally expensive and requires accurate image segmentation.

There are also many alternative approaches for 3D human pose recovery from single images such as using a known articulated skeleton \cite{taylor2000reconstruction,guan2009estimating,leonardos2016articulated}, probabilistic graphical models \cite{sigal2006predicting,andriluka2010monocular}, explicit regression \cite{elgammal2004inferring,agarwal2006recovering}, to name a few. But these approaches are customized for human pose modeling and not straightforwardly generalizable for other objects.

Our work is also closely related to nonrigid structure from motion (NRSfM), where a deformable shape is recovered from multi-frame 2D-2D correspondences. The low-rank shape-space model has been frequently used in NRSfM, but the basis shapes are unknown. The joint estimation of shape/pose variables and basis shapes was typically solved via matrix factorization followed by metric rectification \cite{bregler2000recovering,xiao2006closed}. In some recent works, iterative algorithms were employed for better precision \cite{paladini2012optimal,del2012bilinear} or sequential processing \cite{agudo2014good}, and the problem studied in this paper is analogous to the step of fixing basis shapes and updating the remaining variables in those works.


\section{Problem statement}\label{sec:formulation}

The problem studied in this paper can be described by the following linear system:

where  denotes the unknown 3D shape, which is represented by 3D locations of  points.  denotes their projections in a 2D image.  is the camera calibration matrix. To simplify the problem, the weak-perspective camera model is usually used, which is a good approximation when the object depth is much smaller than the distance from the camera. With this assumption, the calibration matrix has the following simple form:

where  is a scalar depending on the focal length and the distance to the object.

There are always more variables than equations in \refEq{eq:basic}. To make the problem well-posed, a widely-used assumption is that the unknown shape can be represented as a linear combination of predefined basis shapes, which is originated from the active shape model \cite{cootes1995active}:

where  for  represents a basis shape and  its weight in the combination. Thus, the reconstruction problem is reduced to a problem of estimating several coefficients by fitting the model \refEq{eq:shape-model-original} to the landmarks in an image, which greatly reduces the number of unknowns.

Since the basis shapes are predefined, the relative rotation and translation between the camera frame and the coordinates that define the basis shapes need to be taken into account, and the 3D-2D projection is depicted by:

where  and  correspond to the rotation matrix and the translation vector, respectively.  should be in the special orthogonal group


Equation \refEq{eq:2d3dcorresp} can be further simplified as

where  denotes the first two rows of the rotation matrix, and the translation  has been eliminated by centralizing the data, i.e. subtracting each row of  and  by its mean. Note that the scalar  in the calibration matrix has been absorbed into .

In the active shape model \cite{cootes1995active}, the principal components of training samples are used as the basis shapes, which assumes that all shapes lie in a low-dimensional linear space. In more recent work, e.g. \cite{ramakrishna2012reconstructing,zhang2011sparse,zhu2010model,zhu2014complex}, it has been shown that the low-dimensional linear space is insufficient to model complex shape variation, e.g., human poses, and a promising approach is to use an over-complete dictionary and represent an unknown shape as a sparse combination of atoms in the dictionary. Such a sparse representation implicitly encodes the assumption that the unknown shape should lie in a union of subspaces that approximates a nonlinear shape manifold. The representabilities of PCA and sparse representation for 3D human pose modeling will be empirically compared in \refSec{sec:human}.

Based on the sparse representation of shapes, the following type of optimization problem is often considered to estimate an unknown shape:

where  and  represents the  norm of , which is the convex surrogate of the cardinality.  denotes the Frobenius norm of a matrix. The terms in the loss function of \refEq{eq:originalnoisy} correspond to the reprojection error and the sparsity of representation, respectively.

The optimization in \refEq{eq:originalnoisy} is nonconvex and there is an orthogonality constraint. A commonly-used strategy to solve the optimization is the alternating minimization scheme, in which two steps are alternated: (1) fixing  and updating  by any  minimization solver, e.g., the methods summarized in \cite{bach2012optimization}; (2) fixing  and updating  using certain rotation representations such as the quaternions, the exponential map or a manifold representation. In some previous works \cite{ramakrishna2012reconstructing,akhter2015pose},  is updated by the singular value decomposition (SVD), and it is worth noting that this method can only yield an approximate solution since  is not a square matrix and . Generally no closed-form solution exists in this case \cite{edelman1998geometry}.

The alternating algorithm is summarized in \refAlg{alg:altern}. Due to the nonconvexity of \refEq{eq:originalnoisy}, \refAlg{alg:altern} may get stuck at local minima when initialization is far away from the true solution.

\begin{algorithm}\label{alg:altern}
\LinesNumbered
\caption{Alternating minimization to solve \refEq{eq:originalnoisy}.}
\KwIn{}
\KwOut{ and .}
\vspace{0.5em}
initialize  and \;
\While{not converged}{
update  using any  minimization solver\;
update  using SVD or any local optimization solver over \;
}
\vspace{0.5em}
\end{algorithm}


\section{Proposed methods}\label{sec:methods}

\subsection{Convex relaxation}\label{sec:relaxation}

We propose to use the following shape-space model:

in which there is a rotation for each basis shape. The model in \refEq{eq:shape-model-relaxed} implicitly accounts for the viewpoint variability and the projected 2D model is

where  is the product of  and the first two rows of , which satisfies


The motivation of using the model in \refEq{eq:new2dmodel} is to achieve a linear representation of shape variability in 2D, such that we can get rid of the bilinear form in \refEq{eq:bilinear}, which is a necessary step towards a convex formulation.

The model in \refEq{eq:new2dmodel} is equivalent to the affine-shape model in literature \cite{blake2000active,xiao2004real}, which uses an augmented linear space to represent the shape variation in 2D caused by both intrinsic shape deformation and extrinsic viewpoint changes. This representation also appears in most NRSfM literature, e.g. \cite{bregler2000recovering,paladini2012optimal}. As mentioned in \cite{xiao2004real}, the augmented linear space can represent any 2D shape produced by the 3D shape model projected into the image plane, but the increased degree of freedom may result in invalid shapes. In this work, we try to reduce the possibility of invalid cases by enforcing the orthogonality constraint on s and the sparsity constraint on the number of activated basis shapes. We will show that these constraints can be conveniently imposed by minimizing a convex regularizer.

Next, replacing the orthogonality constraint in \refEq{eq:orthogonality} by its convex counterpart is considered. The following lemma has been proven in literature \cite[Section 3.4]{journee2010generalized}:

\begin{lemma}\label{lemma1}
The convex hull of the Stiefel manifold  equals the unit spectral-norm ball .  denotes the spectral norm (a.k.a. the induced 2-norm) of a matrix , which is defined as the largest singular value of .
\end{lemma}
Based on \refLemma{lemma1}, we have the following proposition:
\begin{proposition}
Given a scalar , the convex hull of  equals the spectral-norm ball with a radius of : .
\end{proposition}
\begin{proof}
Since , we have

\end{proof}


Consequently, the tightest convex relaxation to the constraint in \refEq{eq:orthogonality} is given by .


Finally, with the modified shape model, the relaxed orthogonality constraint and the assumption of sparse representation, the following optimization is proposed for shape recovery under the noiseless case:

In \refEq{eq:originalnoiseless}, reducing  can decrease the objective and the only constraint on  is that . Therefore,  is equal to  when an optimum is attained. Consequently, \refEq{eq:originalnoiseless} is equivalent to the following problem:

The formulation in \refEq{eq:finalnoiseless} is a linear inverse problem, where a set of orthogonal matrices\footnote{For simplicity, we call a matrix  as orthogonal matrix if it satisfies  or  where  is a scalar.} are estimated by minimizing their spectral norms. Interestingly, the conditions for exact recovery using such a convex program has been theoretically analyzed in \cite{chandrasekaran2012convex}. Numerical results will be presented in \refSec{sec:simulation} to demonstrate the exact recovery property.

To consider noise in real applications, the following formulation is proposed:

The problem \refEq{eq:finalnoisy} is the final formulation, which is a penalized least-squares problem. We have following remarks:
\begin{itemize}
\item[1.] The problem in \refEq{eq:finalnoisy} is convex programming, which can be solved globally. We will provide an efficient algorithm to solve it in \refSec{sec:alg}.
\item[2.] Notice that  in the above formulations denotes the spectral norm of a matrix. As we will show in \refSec{sec:proximal}, minimizing the spectral norm of a matrix is equivalent to minimizing the -norm of the vector of singular values, which will simultaneously shrink the norm of the matrix towards zero and enforce its singular values to be equal. Therefore, by spectral-norm minimization, we can not only minimize the number of activated basis shapes but also enforce each transformation matrix  to be orthogonal (an orthogonal matrix has equal singular values).
\item[3.] For the cases with missing or invisible landmarks, the model parameters can be estimated by minimizing reprojection errors of observed landmarks, i.e., including a binary weight matrix in the first term of \refEq{eq:finalnoisy}. The unobserved landmarks can be hallucinated from the reconstructed model as their locations are known on the basis shapes.
\end{itemize}


\subsection{Proximal operator of the spectral norm}\label{sec:proximal}

Before providing the specific algorithm to solve \refEq{eq:finalnoisy}, we first prove the following proposition, which will serve as an important building block in our algorithm.
\begin{proposition}\label{prop:prox2norm}
The solution to the following problem

is given by , where

,  and  denote the left singular vectors, right singular vectors and the singular values of , respectively.  is the projection of a vector to the unit -norm ball.
\end{proposition}

\begin{proof}
The problem in \refEq{eq:prox-2norm} is a proximal problem \cite{parikh2013proximal}. The proximal problem associated with a function  is defined as

with the solution denoted by  and named the proximal operator of .

For the problem \refEq{eq:prox-2norm}, , where  means the  norm. It says that  is a spectral function operated on singular values of a matrix. Based on the property of spectral functions \cite[Section 6.7.2]{parikh2013proximal}, we have

where  is the -norm. The proximal operator of the -norm can be computed by Moreau decomposition \cite[Section 6.5]{parikh2013proximal}:

given that the -norm is the dual norm of the -norm.
\end{proof}

The solution for the case with two singular values is illustrated in \refFig{fig:proximal}, where  corresponds to  in \refEq{eq:proximal-operator}. From the illustration we have two observations: (1) If the projection is on the edge of the -norm ball, then  and  turns out to be orthogonal; (2) If  is small and lies inside the -norm ball, then the projection will be itself, , and  turns out to be all-zero. These two observations illustrate the effects of spectral-norm regularization in \refEq{eq:finalnoisy}: (1) Enforcing s to be orthogonal; (2) Pruning small s to achieve a sparse representation.

\begin{figure}
  \centering
\includegraphics[width=0.7\linewidth]{figures/fig2.pdf}\\
  \caption{Illustration of the proximal operator of the spectral norm.}\label{fig:proximal}
\end{figure}

\subsection{Optimization}\label{sec:alg}

The algorithm to solve \refEq{eq:finalnoisy} is presented here. The noiseless case \refEq{eq:finalnoiseless} can be solved similarly.

The proposed algorithm is based on ADMM \cite{boyd2010distributed} and the proximal operator of the spectral norm derived in \refSec{sec:proximal}. An auxiliary variable  is introduced and \refEq{eq:finalnoisy} is rewritten as

where


The augmented Lagrangian of \refEq{eq:admm-noisy} is

where  is the dual variable and  is a parameter controlling the step size in optimization. Then, the ADMM alternates the following steps until convergence:


The subproblem in \refEq{eq:admm1} can be rewritten as

where  is the -th column-triplet of . Therefore, each  can be updated separately by solving a proximal problem based on \refProp{prop:prox2norm}:


For the subproblem in \refEq{eq:admm2},  is a quadratic form and admits a closed-form solution:
{\small

}

The steps are summarized in \refAlg{alg:admm-noisy}. Following the standard proof in \cite{boyd2010distributed}, it can be shown that the sequences of values produced by the iterations in \refAlg{alg:admm-noisy} converge to the optimal solution of the problem \refEq{eq:admm-noisy}, which is also the optimal solution to the original problem \refEq{eq:finalnoisy}. In implementation, the convergence criterion and the adaptive scheme for tuning step size  from \cite[Section 3]{boyd2010distributed} are adopted.

\begin{algorithm}
\LinesNumbered
\caption{ADMM to solve \refEq{eq:finalnoisy}}\label{alg:admm-noisy}
\small
\KwIn{, }
\KwOut{}
\vspace{0.5em}
initialize , \;
\While{not converged}{
parallel \For{ \KwTo }{
 the -th column-triplet of  \;
 \;
}
 \;
 \;
}
\vspace{0.5em}
\end{algorithm}
\vspace{-1em}

\subsection{Reconstruction}\label{sec:reconstr}

After \refEq{eq:finalnoisy} is solved, two algorithms for reconstructing the 3D shape from the estimated s are proposed.

\subsubsection{Direct reconstruction}\label{sec:direct}

The 3D shape is reconstructed according to the relaxed shape model \refEq{eq:shape-model-relaxed}, where  and  are recovered from the estimated . The steps are summarized in \refAlg{alg:direct}, where  and  denote the -th row vectors of  and , respectively. Note that  is also a feasible solution. To eliminate the ambiguity, we assume that  and impose this constraint when learning the shape dictionary.

\begin{algorithm}\label{alg:direct}
\LinesNumbered
\caption{Direct reconstruction}
\KwIn{}
\KwOut{}
\vspace{0.5em}
\For{ \KwTo }{
\;
\;
\;
\;
\;
}
\;
\vspace{0.5em}
\end{algorithm}
\vspace{-1em}


\subsubsection{Rotation synchronization and refinement}\label{sec:refine}

The 3D shape is reconstructed according to the original shape model \refEq{eq:shape-model-original}. In order to recover the coefficient vector  and a single rotation  from the estimated s, the following rotation synchronization problem is solved:

The problem in \refEq{eq:rot_avg} corresponds to the ``metric projection" step in \cite{paladini2012optimal,del2012bilinear}, which can be exactly solved by semidefinite programming \cite{paladini2012optimal} or approximately by a more efficient algorithm \cite[Section 4.4.1]{del2012bilinear}.

The solution from the synchronization described above is not necessarily the solution to the original problem \refEq{eq:originalnoisy}, but it can be used as a good initialization and refined by the alternating minimization in \refAlg{alg:altern}. In \refSec{sec:experiments}, it will be demonstrated that such a better initialization can clearly improve the performance of alternating minimization.
A potential issue in the synchronization is that, when the rotations obtained from the convex program are very different from each other, the consensus of them might be meaningless and fails to provide a good initialization.

The full steps are summarized in \refAlg{alg:refine}.

\begin{algorithm}\label{alg:refine}
\LinesNumbered
\caption{Refinement and reconstruction}
\KwIn{}
\KwOut{}
\vspace{0.5em}
initialize  and  by solving \refEq{eq:rot_avg} using the algorithm in \cite[Section 4.4.1]{del2012bilinear}\;
\vspace{0.25em}
refine  and  by \refAlg{alg:altern}\;
\vspace{0.25em}
\;
\vspace{0.5em}
\end{algorithm}
\vspace{-1em}

\subsection{Outlier modeling}\label{sec:outliers}

In real applications, the 2D correspondences are given by detectors and there are likely to be gross errors (outliers). In this case, we explicitly model the outliers by a sparse matrix  and modify the formulation in \refEq{eq:finalnoisy} as

Note that in this case the translation  cannot be eliminated by centralizing the data at the beginning.

The problem in \refEq{eq:finalrobust} can be solved by ADMM as well. The algorithm is presented in \refApp{sec:alg-robust}.

\subsection{Dictionary learning}\label{sec:dl}

In general, one can simply use all existing or a few representative 3D models as the basis shapes. But when the collection is very large, e.g., a motion capture dataset often contains thousands of human skeletons, it is necessary to use the dictionary learning technique to learn a dictionary of basis shapes that can concisely summarize the variability in training data and enable a sparse representation. The dictionary learning problem can be formulated as follows:

where s denote the training shapes, s are the basis shapes to be learned, and  represents the -th coefficient for the -th training shape. The two terms in the cost function correspond to the reconstruction error and the sparsity of representation, respectively. The nonnegativity constraint is introduced to remove the ambiguity as discussed in \refSec{sec:direct}. The problem in \refEq{eq:dl} is locally solved by alternately updating  and s via projected gradient descent, an algorithm widely used in dictionary learning that converges to a local optimum \cite{mairal2010online}. The algorithm is summarized in \refApp{sec:alg-dl}.

\section{Experiments}\label{sec:experiments}

\subsection{Exact recovery}\label{sec:simulation}

\begin{figure}
\centering
\includegraphics[width=0.51\linewidth]{figures/fig3.pdf}
\caption{The frequency of exact recovery. The intensity indicates the frequency of success under a variety of problem settings.} \label{fig:freqexact}
\vspace{-1em}
\end{figure}

We investigate whether the spectral-norm minimization in \refEq{eq:finalnoiseless} can exactly solve the ill-posed inverse problem based on the prior knowledge of sparsity and orthogonality using simulation.

More specifically, the data is synthesized with the following model:

where  ( and  is varying) are randomly generated bases with entries sampled independently from the normal distribution . Each  is generated from , where  is sampled from a uniform distribution  and  denotes the first two rows of a rotation matrix with angles uniformly sampled from . Only a randomly selected subset of  are left as nonzero with a varying cardinality of . Then,  and  are taken as input and s are estimated by solving \refEq{eq:finalnoiseless}. The recovery error is defined as

where s are concatenated in , and  is the algorithm estimate. A recovery is regarded as exact if the relative error .

\refFig{fig:freqexact} shows the frequency of exact recovery with varying  (number of landmarks) and  (cardinality of true coefficients), which is evaluated over 100 trials for each setting. Note that the number of unknowns () is much larger than the number of equations (). The proposed convex program can exactly solve the problem with a frequency equal to 1 in the lower-triangular area, where the number of landmarks is sufficiently large and the coefficients are truly sparse. This demonstrates the power of convex relaxation, which has proven to be successful in many inverse problems, e.g., compressed sensing \cite{candes2008introduction} and matrix completion \cite{candes2010power}. The performance drops in more ill-posed cases in the upper-triangular area. This observation is analogous to the phase transition in compressive sensing, where the recovery probability also depends on the number of observations and the underlying signal sparsity \cite{donoho2009observed}.

Note that the original model \refEq{eq:bilinear} is a special case of the relaxed model \refEq{eq:simu-model} when s are the scaled versions of each other. The result obtained by using the original model for data generation is similar to \refFig{fig:freqexact}.

\subsection{Human pose estimation}\label{sec:human}

The applicability of sparse representation for 3D human pose recovery has been thoroughly studied in previous work \cite{ramakrishna2012reconstructing,wang2014robust,fan2014pose}. In this paper, we aim to illustrate the advantage of the proposed convex program compared to the alternating minimization scheme.

Empirical evaluation is carried out on the CMU motion capture dataset \cite{mocap}. The dataset includes thousands of sequences of 3D human skeletons and part of them are selected for evaluation. More specifically, eight motion categories are considered including walking, running, jumping, climbing, boxing, dancing, sitting and basketball. For each motion, six sequences are collected from different subjects with three sequences for training and the rest for testing. Then, a dictionary is learned with all training sequences from various motions and used to reconstruct the test sequences. A 15-joint model (i.e., head, thorax, pelvis, shoulders, elbows, wrists, hips, knees, and ankles) is adopted to represent a human skeleton.

\begin{figure}
\centering
\includegraphics[width=0.5\linewidth]{figures/fig4.pdf}
\caption{{Representability of principal component analysis (PCA), sparse coding (SC) and nonnegative sparse coding (NNSC) for human poses.}} \label{fig:test-dl}
\end{figure}

\begin{figure*}
  \centering
  \begin{minipage}[b]{0.52\linewidth}
  \centering
  \includegraphics[width=\linewidth]{figures/fig5a.pdf} \\
  \centerline{(a)}
  \end{minipage}
  \hspace{1em}
  \begin{minipage}[b]{0.4\linewidth}
  \centering
  \includegraphics[width=\linewidth]{figures/fig5b.pdf} \\
  \centerline{(b)}
  \end{minipage}\\
  \vspace{1em}
  \begin{minipage}[b]{0.25\linewidth}
  \centering
  \includegraphics[width=\linewidth]{figures/fig5c.pdf} \\
  \centerline{(c)}
  \end{minipage}
  \hspace{1em}
  \begin{minipage}[b]{0.33\linewidth}
  \centering
  \includegraphics[width=\linewidth]{figures/fig5d.pdf} \\
  \centerline{(d)}
  \end{minipage}
  \begin{minipage}[b]{0.33\linewidth}
  \centering
  \includegraphics[width=\linewidth]{figures/fig5e.pdf} \\
  \centerline{(e)}
  \end{minipage}
  \caption{Quantitative results on the CMU motion capture dataset. (a) The mean 3D estimation errors for different motions. (b) The box plot of estimation errors. (c) The comparison between objective values achieved by the mean shape initialization and by the convex initialization. (d) The sensitivity to Gaussian noise. (e) The sensitivity to outliers. The length of error bar in (d) and (e) indicates half standard deviation. }\label{fig:mocap-quant}
\end{figure*}

To build the shape dictionary, all 3D poses in the training set are collected and aligned by the Procrustes method. The size of the dictionary  is set as 128 yielding an overcomplete dictionary since the dimension of the basis vector is 45 (15 joints in 3D). The dictionary is initialized by uniformly sampling  poses from the training data and updated by the algorithm described in \refSec{sec:dl}. The representability of the learned dictionary is measured by the reconstruction error, i.e., the first term in \refEq{eq:dl}. To evaluate the representability, \refEq{eq:dl} is solved multiple times with a variety of  yielding a sequence of reconstruction errors and the corresponding sparsity levels. The more general case without the nonnegativity constraint is also tested. The result is shown in \refFig{fig:test-dl}, which indicates that the sparse coding needs much fewer activated bases compared to PCA to achieve the same reconstruction error, {and adding the nonnegativity constraint sacrifices the representability but the difference is small in our experiment}.

To generate 2D testing data, an orthographic camera rotating around the subject (360 degrees per sequence) is simulated and the 3D joints are projected to 2D with the simulated camera. The following methods are compared:
\begin{itemize}
\item {\bf Convex}: the proposed convex program with direct reconstruction (\refAlg{alg:admm-noisy}+\refAlg{alg:direct}).
\item {\bf Convex+refine}: the proposed convex program followed by refinement (\refAlg{alg:admm-noisy}+\refAlg{alg:refine}). The local update of rotation is implemented by the manifold optimization over the Stiefel manifold with the Manopt toolbox \cite{boumal2014manopt}.
\item {\bf Altern}: the alternating algorithm with the mean shape as initialization (\refAlg{alg:altern}). The rotation is updated by SVD as in previous work \cite{ramakrishna2012reconstructing,fan2014pose,zhou2014sptio}.
\item {\bf PMP}: Projected Matching Pursuit from Ramakrishna et al. \cite{ramakrishna2012reconstructing}, which solves sparse coding by greedily selecting basis shapes instead of  minimization. The dictionary for PMP is constructed by the method provided in the original paper but with the same training data as ours.
\end{itemize}

\begin{figure*}
\centering
\includegraphics[width=0.9\linewidth]{figures/fig6.pdf}
  \caption{Qualitative results on the CMU motion capture dataset. The rows from top to bottom correspond to the input 2D poses, the ground-truth 3D poses (visualized in a novel view), and the reconstructions from the proposed method, the alternating minimization, and the PMP method \cite{ramakrishna2012reconstructing}, respectively. Red and green indicate left and right, respectively. }
  \label{fig:mocap-qual}
\end{figure*}

\begin{figure*}
  \centering
  \includegraphics[width=0.8\linewidth]{figures/fig7.pdf}
  \caption{Qualitative results on the PARSE dataset with 2D poses detected by an existing 2D pose detector \cite{yang2011articulated}. In each example, the detected 2D pose superposed on the original image and the reconstruction in two different views are shown. The last row shows two failed examples.}\label{fig:parse}
\end{figure*}

The estimation error is evaluated by the 3D Euclidian distances between the estimated joint locations and the ground truth in the camera frame up to a translation and scaling. The mean errors for various motions are shown in \refFig{fig:mocap-quant}(a) and the statistics of errors in \refFig{fig:mocap-quant}(b). The proposed convex method consistently outperforms the nonconvex methods for all motions. Comparing ``convex+refine" and ``altern" which solve the same problem \refEq{eq:originalnoisy} at the end, the error is apparently decreased by using better initialization (the convex solution). To further verify the fact that the alternating minimization depends on initialization, we compare the objective values achieved by the alternating algorithm initialized by the convex solution and the mean shape. As shown in \refFig{fig:mocap-quant}(c), the objective values achieved by convex initialization are always smaller. {The mean errors of ``convex" and ``convex+refine" are comparable on the average. The rotation synchronization and refinement may lead to worse reconstructions if the convex solution fails to provide a good initialization or the optimal solution to \refEq{eq:originalnoisy} is not necessarily the best reconstruction, which may happen when the pose to be reconstructed cannot be well represented by the learned dictionary.}




Some visual examples of reconstructed poses for various motions are shown in \refFig{fig:mocap-qual}. All methods perform well in the ``walk" and ``run" examples, where the poses are close to the mean pose (stand upright). But for more complex motions, the nonconvex algorithms may be stuck at local optima as shown in other examples, while the proposed convex algorithm still obtains appealing results. A demonstration video showing several reconstructed 3D pose sequences is included in the supplementary material. The reconstructions by the convex method are much smoother over time compared to the ones by the nonconvex method which suffer from abrupt changes due to the inherent instability of nonconvex optimization.

The robustness of the proposed method against Gaussian noise is also tested. Gaussian noise with a varying standard deviation is added to the 2D input. The estimation error versus the standard deviation of the simulated noise is shown in \refFig{fig:mocap-quant}(d). The performances of the convex methods are consistently better than the alternating ones under all noise levels. To test the robustness of the extended model in \refEq{eq:finalrobust} against outliers, a proportion of landmarks are selected with their 2D locations changed to be some random values within a proper range (roughly the rectangle that covers the skeleton). For comparison, the nonconvex model \refEq{eq:originalnoisy} is also extended by introducing an outlier term similar to the one in \refEq{eq:finalrobust} and minimized by the alternating scheme. The curves of estimation error versus outlier proportion are shown in \refFig{fig:mocap-quant}(e). The robust models clearly outperform the original models and the convex method achieves a better performance than the alternating one.

To illustrate the real applicability of the proposed method, we apply the 2D pose detector from Yang and Ramanan \cite{yang2011articulated} on the PARSE dataset \cite{ramanan2006learning}, and use the proposed method to lift the detected 2D poses to 3D with the dictionary learned on the CMU dataset. Some selected results are shown in \refFig{fig:parse}.


\subsection{Car model estimation}

\begin{figure*}
  \centering
  \includegraphics[width=0.9\linewidth]{figures/fig8.pdf}
  \caption{Qualitative results on the FG3DCar dataset given 2D correspondences. The columns correspond to the original image, the input 2D landmarks, and the 2D/3D models output by the proposed method and the nonlinear optimization \cite{lin2014jointly}, respectively. Only visible landmarks ( per image) are used for model fitting. The 3D models are visualized in a novel view different from the original image. The car models are the BMW 5 Series 2011 (sedan), the Nissan Xterra 2005 (SUV) and the Dodge Ram 2003 (pick-up truck), respectively.} \label{fig:fg3dcar-qual}
\end{figure*}

The applicability of the proposed method for car model estimation is demonstrated using the Fine-Grained 3D Car (FG3DCar) dataset \cite{lin2014jointly}, which provides images of cars, 2D landmark annotations and some 3D models. The 3D models of 15 cars are concatenated as the shape dictionary to reconstruct the other cars from the visible landmarks annotated in the images (40 points per image). Several examples of reconstruction are shown in \refFig{fig:fg3dcar-qual}. For comparison, the reconstructions from the algorithm proposed in the original paper \cite{lin2014jointly} are also shown, which adopts a perspective camera model and locally updates the camera and shape parameters with a Jacobian system initialized by the mean shape and predefined camera parameters. The nonlinear optimization performs well in the sedan example but fails in the SUV and truck examples, where the models deviate far away from the mean shape. Similar results were reported in the original paper \cite{lin2014jointly} and the authors proposed to use the class-specific mean shape for better initialization. Instead, the proposed method can achieve appealing results with arbitrary initialization.

We observed that the alternating minimization in \refAlg{alg:altern} also performed very well for car model reconstruction, as the shape variability of cars was relatively small and the mean-shape initialization was very close to the true solution. But when there are outliers in the observation, the initial estimate of viewpoint might be unreliable and the alternating algorithm may fail. To validate this, some outliers are simulated. More specifically, for each image 20 annotated landmarks are randomly selected with their locations changed to be random values in the image plane. Then, the robust models are solved by the convex method and by the alternating algorithm initialized with the mean shape, respectively. Since there is no 3D ground truth (the 3D models provided in the dataset were reconstructed by the authors), the 2D shape fitting error is evaluated, i.e., comparing the 2D projection of the reconstructed 3D model with the original 2D annotations, to see whether the synthesized outliers can be corrected. The comparison is shown in \refFig{fig:fg3dcar-quant}. While the estimation errors are identical for most examples, there are still many examples in which the convex method performs apparently better than the alternating method. The same conclusion can be drawn by comparing the objective values. {The mean 2D errors of the ``altern'', ``convex'' and ``convex+refine'' methods are 44.47, 37.21 and 34.76 pixels, respectively. The rotation synchronization and refinement is beneficial here as the shape variability is small and a more constrained model is preferred.}

\begin{figure}
\begin{minipage}[b]{0.48\linewidth}
  \centering
  \includegraphics[width=\linewidth]{figures/fig9a.pdf} \\ (a)
\end{minipage}
\begin{minipage}[b]{0.48\linewidth}
  \centering
  \includegraphics[width=\linewidth]{figures/fig9b.pdf} \\ (b)
\end{minipage}
  \caption{Quantitative comparison between the proposed method (``convex+refine") and the alternating minimization (``altern") on the FG3DCar dataset with synthesized outliers. (a) The 2D shape error. (b) The objective value. }\label{fig:fg3dcar-quant}
\end{figure}

Finally, we demonstrate the real applicability of the proposed method with learned landmark detectors. For each landmark, the image patches around the landmark in training images are collected as positive examples and a number of random patches in the background as negative examples. A classifier based on SVM with HOG features is trained with the collected examples. To handle 2D appearance variability, the positive examples are clustered and a mixture of classifiers is learned for each landmark. During testing, a test image is scanned by the learned classifiers and the locations with maximum responses are picked as the landmark locations. The detections are shown in the first column of \refFig{fig:fg3dcar-real}. The false detections are mostly due to self occlusion. The visibility is unknown and we fit the model with all detected landmarks despite of their correctness. The 2D fitted models and 3D reconstructions are shown in the next two columns, which demonstrate that the proposed method can robustly fit the model at the presence of many outliers and without knowing the visibility. The last row shows two failed examples, in which more than half of the landmarks are incorrectly located.

\begin{figure*}
  \centering
  \includegraphics[width=0.9\linewidth]{figures/fig10.pdf}\\
  \caption{Qualitative results on the FG3DCar dataset with detected 2D landmarks. In each example, the detected landmarks superposed on the original image, 2D fitted model and 3D reconstruction are shown. The 2D landmarks are located by learned detectors based on HOG and SVM. The green and red dots correspond to the inliers and outliers, respectively. The outlier is defined as any detected landmark at least 30-pixel away from the manual annotation. Note that the inlier/outlier classification is only for the purpose of illustration and not for model fitting, i.e., the models are fitted with all landmarks despite of the correctness of detection. The last row shows two failed examples.} \label{fig:fg3dcar-real}
\end{figure*}

\subsection{Parameter tuning}
The parameters  and  in the proposed model \refEq{eq:finalnoisy} and \refEq{eq:finalrobust} control the sparsity of shape coefficients and outliers, respectively. In general, the best values of  and  can be obtained by cross validation for a specific task. But empirically we find that the estimation error changes very smoothly with the parameters varying in a proper range and a set of fixed parameters works well after normalizing the data. More specifically, the coordinates of input 2D shape and 3D basis shapes are scaled such that the average variance of each shape along all directions is unit. With the data normalization, the estimation error as a function of parameters over a subset of CMU motion capture data is shown in \refFig{fig:param}. Each curve has a relatively flat valley. In all experiments in this paper, we fix  and  after the data normalization.

\begin{figure}
\begin{minipage}[b]{0.45\linewidth}
  \centering
  \includegraphics[width=\linewidth]{figures/fig11a.pdf}\b)
\end{minipage}
  \caption{Sensitivity to model parameters on the CMU motion capture dataset. (a) Estimation error of model \refEq{eq:finalnoisy} as a function of . (b) Estimation error of model \refEq{eq:finalrobust} as a function of  with  and  simulated outliers.} \label{fig:param}
\end{figure}

\subsection{Computational time}

The proposed algorithms are implemented in MATLAB and tested on a desktop with a Intel i7 3.4GHz CPU and 8G RAM. In our experiments, the ADMM algorithm generally converges within 500 iterations to reach a stopping criterion of . In human pose estimation, the average computational time of our algorithm is 1.91s per frame, while those of the alternating algorithm and the PMP algorithm \cite{ramakrishna2012reconstructing} are 1.34s and 3.70s, respectively. Note that the for-loops in \refAlg{alg:admm-noisy} (Line 3) can be paralleled to further accelerate the computation.

\section{Discussion}\label{sec:discussion}

In summary, we proposed a method for aligning a 3D deformable shape model with a sparse representation to 2D correspondences by solving a convex program, which guarantees global optimality. Intuitively, we adopted an augmented 3D shape space to achieve a linear representation of both shape and viewpoint variability and proposed to use the spectral-norm regularization to penalize invalid cases caused by the augmentation. We also extended our model to handle outliers in 2D correspondences. We empirically demonstrated the exact recovery property of the relaxed model as well as the advantage of convex optimization compared to alternative nonconvex methods especially when the shape variability was large and there were outliers.

We demonstrated the applicability of the proposed method for reconstructing human poses and car models. The point correspondences across 3D training shapes are provided in the used datasets. With the increasing availability of techniques for 3D shape matching, e.g. \cite{huang2013consistent,huang2014functional}, and databases with rich annotations, e.g. PASCAL3D+ \cite{yu2014beyond} and 3D ShapeNet \cite{shapenet}, we expect to see more applications of the proposed framework to reconstruct a variety of object categories in future.

\appendices



\section{Algorithm to solve the robust model}\label{sec:alg-robust}

The algorithm to solve \refEq{eq:finalrobust} is presented. The problem is rewritten as follows by introducing an auxiliary variable :


The augmented Lagrangian of \refEq{eq:admm-rewrite} is


The following steps are iterated until convergence:

The whole procedure is very similar to \refAlg{alg:admm-noisy}. The differences are the steps to update  and . For \refEq{eq:Mstep} and \refEq{eq:Zstep}, they can be computed similarly as the steps in \refAlg{alg:admm-noisy}:

where  is the -th column-triplet of ,

For \refEq{eq:Estep}, the problem is a proximal problem associated with the -norm and can be solved by

where  that refers to the elementwise soft-thresholding operator. For \refEq{eq:Tstep}, the solution is simply given by


Note that there is no theoretical guarantee for the convergence of ADMM solving a multi-block problem such as \refEq{eq:admm-rewrite} \cite{chen2016direct}, though it always converges in our experiments.

\section{Algorithm to solve dictionary learning}\label{sec:alg-dl}

The algorithm to solve the dictionary learning problem in \refEq{eq:dl} is presented. The cost function can be rewritten as:

where  is the concatenation of s. Then, it is minimized by projected gradient descent and the algorithm is summarized in \refAlg{alg:dl}.

\begin{algorithm}\label{alg:dl}
\LinesNumbered
\caption{Dictionary learning}
\KwIn{}
\KwOut{}
\vspace{0.5em}
initialize , , step sizes  and \;
\While{not converged}{
\tcc{solve nonnegative sparse coding}
\While{not converged}{
 \;
\For{ \KwTo }{
\For{ \KwTo }{
\uIf{}{
 \;
}}}}
\tcc{update dictionary}
 \;
\For{ \KwTo }{
\uIf{}{
 \;
}}
}
\end{algorithm}

\vspace{-2em}
\section*{Acknowledgments}
The authors are grateful for support through the following grants:
NSF-DGE-0966142, NSF-IIS-1317788, NSF-IIP-1439681, NSF-IIS-1426840,
ARL MASTCTA W911NF-08-2-0004, ARL RCTA W911NF-10-2-0016, ONR N000141310778
The authors gratefully acknowledge Dr Xiaoyan Hu from Beijing Normal University
for helpful discussions and processing of motion capture data.


\bibliographystyle{IEEEtran}
\bibliography{mybib}

\end{document}
