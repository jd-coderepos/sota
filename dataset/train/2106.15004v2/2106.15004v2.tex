\documentclass{article}

\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[caption=false]{subfig}
\usepackage{amsmath,amsfonts}
\usepackage{bbm}
\usepackage{amssymb}\usepackage{enumitem}\usepackage{pifont}\usepackage{tabularx}
\newcolumntype{Y}{>{\centering\arraybackslash}X}
\usepackage{appendix}
\usepackage[preprint]{corl_2021} \setlength{\belowcaptionskip}{-7pt}
\title{Multimodal Trajectory Prediction Conditioned on Lane-Graph Traversals}


















\author{
  
  Nachiket Deo\thanks{Work done during an internship at Motional.} \qquad Eric M. Wolff \qquad Oscar Beijbom\\
  UC San 
  Diego \qquad Motional \\
  \texttt{ndeo@ucsd.edu, \{eric.wolff, oscar.beijbom\}@motional.com} \\

}


\begin{document}
\maketitle

\begin{abstract}


Accurately predicting the future motion of surrounding vehicles requires reasoning about the inherent uncertainty in driving behavior.
This uncertainty can be loosely decoupled into lateral (e.g., keeping lane, turning) and longitudinal (e.g., accelerating, braking).
We present a novel method that combines learned discrete policy rollouts with a focused decoder on subsets of the lane graph.
The policy rollouts explore different goals given current observations, ensuring that the model captures lateral variability.
Longitudinal variability is captured by our latent variable model decoder that is conditioned on various subsets of the lane graph.
Our model achieves state-of-the-art performance on the nuScenes motion prediction dataset, and qualitatively demonstrates excellent scene compliance.
Detailed ablations highlight the importance of the policy rollouts and the decoder architecture.
\end{abstract}

\keywords{Motion prediction, autonomous vehicles, graph neural networks} 



\section{Introduction}
\label{sec:intro}	




To safely and efficiently navigate through complex traffic scenes, autonomous vehicles need the ability to predict the intent and future trajectories of surrounding vehicles.
There is inherent uncertainty in predicting the future, making trajectory prediction a challenging problem. 
However, there's structure to vehicle motion that can be exploited. Drivers usually tend to follow traffic rules and follow the direction ascribed to their lanes. High definition (HD) maps of driving scenes provide a succinct representation of the road topology and traffic rules, and have thus been a critical component of recent trajectory prediction models as well as public autonomous driving datasets. 


Early work~\citep{cui2019multimodal} encodes HD maps using a rasterized bird's eye view image and convolutional layers.
While this approach exploits the expressive power of modern CNN architectures, rasterization of the map can be computationally inefficient, erase information due to occlusions, and require large receptive fields to aggregate context. The recently proposed VectorNet~\citep{gao2020vectornet} and LaneGCN~\citep{liang2020laneGcn} models directly encode structured HD maps, representing lane polylines as nodes of a graph.
VectorNet aggregates context using attention ~\citep{vaswani2017attention}, while LaneGCN proposes a dilated variant of graph convolution ~\citep{kipf2016semi} to aggregate context along lanes. These approaches achieve state-of-the-art performance using fewer parameters than rasterization-based approaches.

The above methods represent the HD map as a graph and encode the input context into a single context vector as shown in Fig.\ref{fig:concept}.
The context vector is then used by a multimodal prediction header~\citep{cui2019multimodal,chai2019multipath} to output multiple plausible future trajectories. The prediction header thus needs to learn a complex mapping, from the entire scene context to multiple future trajectories, often leading to predictions that go off the road or violate traffic rules. In particular, the prediction header needs to account for both \textit{lateral} or \textit{route} variability (e.g. will the driver change lane, will they turn right etc.) as well as \textit{longitudinal} variability (e.g. will the driver accelerate, brake, maintain speed). This decoupling of routes and motion profiles for trajectories has been used in path planning~\citep{paden2016survey, lavalle2006planning}, and more recently in prediction~\citep{zhang2020map}. 


Our core insight is that the graph structure of the scene can additionally be leveraged to explicitly model the lateral or route variability in trajectories. We propose a novel approach for trajectory prediction termed Prediction via Graph-based Policy (PGP). Our approach relies on two key ideas.



 \textbf{Predictions conditioned on traversals:} We selectively aggregate part of the scene context for each prediction, by sampling path traversals from a learned behavior cloning policy as shown in Fig.~\ref{fig:concept}. By more directly selecting the subset of the graph that is used for each prediction, we lessen the representational demands on the output decoder. Additionally, the probabilistic policy leads to a diverse set of sampled paths and captures the lateral variability of the multimodal trajectory distribution.

\textbf{Latent variable for longitudinal variability:} To account for longitudinal variability of trajectories, we additionally condition our predictions with a sampled latent variable. This allows our model to predict distinct trajectories even for identical path traversals. We show through our experiments that this translates to greater longitudinal variability of predictions.  





We summarize our main contributions on multimodal motion prediction using HD maps:
\begin{itemize}[noitemsep,topsep=0pt,leftmargin=10pt]
    \item A novel method which combines discrete policy roll-outs with a lane-graph subset decoder.
    \item State-of-the-art performance on the nuScenes motion prediction challenge.
    \item Extensive ablations demonstrating ability to capture lateral and longitudinal motion variations.
\end{itemize}


\begin{figure}[t]
\includegraphics[clip,width=\linewidth]{concept.png}

\caption{\textbf{Overview of our approach.} We encode HD maps and agent tracks using a graph representation of the scene. However, instead of aggregating the entire scene context into a single vector and learning a one-to-many mapping to multiple trajectories, we condition our predictions on selectively aggregated context based on paths traversed in the graph by a discrete policy.}
\label{fig:concept}
\end{figure}



















\vspace{-2mm}
\section{Related Work}
\label{sec:related_work}
\vspace{-2mm}


\textbf{Graph representation of HD maps:} Most self-driving cars have access to HD vector maps, which include detailed geometric information about objects such as lanes, crosswalks, stop signs, and more.
VectorNet~\citep{gao2020vectornet} encodes the scene context using a hierarchical representation of map objects and agent trajectories. 
Each component is represented as a sequence of vectors, which are then processed by a local graph network. 
The resulting features are aggregated globally via a fully-connected graph network. LaneGCN~\citep{liang2020laneGcn} extracts a lane graph from the HD map, and uses a graph convolutional network to compute lane features.
These features are combined with both agent and other lane features in a fusion network.
Both methods utilize the entire graph for making predictions, relying on the header to identify the most relevant features.

\textbf{Multimodal trajectory prediction:} Researchers have proposed a variety of ways to model the multiple possible future trajectories that vehicles may take.
One approach is to model the output as a probability distribution over trajectories, using either regression~\citep{cui2019multimodal}, ordinal regression~\citep{chai2019multipath}, or classification~\citep{phan2019cover-net}.
Another approach models the output as a spatial-temporal occupancy grid~\citep{zeng2019costmap}.
Sampling methods use stochastic policy roll outs~\citep{rhinehart2018r2p2, rhinehart2019precog} or latent variable models that map a latent variable sampled from a simple distribution to a predicted trajectory. Latent variable models are trained as GANs~\citep{gupta2018socialGAN, zhao2019multi}, CVAEs~\citep{lee2017desire, salzmann2020trajectron++}, or directly using the winner-takes-all regression loss~\citep{Makansi_2019_CVPR}.
These models must learn a one-to-many mapping from the entire input context (except the random variable) to multiple trajectories, and can lead to predictions that are not scene compliant. 

\textbf{Goal-conditioned trajectory prediction:} Rather than learning a one to many mapping from the entire context to multiple future trajectories, methods such as TnT~\citep{zhao2020tnt}, LaneRCNN~\citep{zeng2021laneRcnn}, and PECNet~\citep{mangalam2020PecNet} condition each prediction on goals of the driver.
Conditioning predictions on future goals makes intuitive sense and helps leverage the HD map by restricting goals to be near the lanes.
However, one limitation is that over moderate time horizons, there can be multiple paths that reach a given goal location.
Additionally, certain plausible goal locations might be unreachable due to constraints in the scene that are not local to the goal location, e.g., a barrier that blocks a turn lane.
In contrast, our method conditions on paths traversed in a lane graph, which ensures that the inferred goal is reachable. 
Furthermore, the traversed path provides a stronger inductive bias than just the goal location. A similar stream of work conditions on candidate lane centerlines as goals (e.g., WIMP~\citep{khandelwal2020whatif}, GoalNet~\citep{zhang2020map}, CXX~\citep{luo2020probabilistic}).
While the lane centerline provides more local context than just the goal, accounting for lane changes can be difficult. 
Additionally, routes need to be deterministically chosen, with multiple trajectories predicted along the selected route. 
Our approach allows for probabilistic sampling of both routes and motion profiles. 
In scenes with just a single plausible route, our model can use its prediction budget of  trajectories purely for different plausible motion profiles.  Closest to our work is P2T~\citep{deo2021p2t}.
They predict trajectories conditioned on paths explored by an IRL policy over a grid defined over the scene. 
However, they use a rasterized BEV image for the scene, which leads to inefficient encoders and loss of connectivity information due to occlusions. 
Additionally, their model cannot generate different motion profiles along a sampled path.


\vspace{-2mm}
\section{Formulation}
\vspace{-2mm}
\label{sec:formulation}
We predict the future trajectories of vehicles of interest, conditioned on their past trajectory, the past trajectories of nearby vehicles and pedestrians, and the HD map of the scene.
We represent the scene and predict trajectories in the bird's eye view and use an agent-centric frame of reference aligned along the agent's instantaneous direction of motion.

\vspace{-2mm}
\subsection{Trajectory representation}
We assume access to past trajectories of agents in the scene obtained from on-board detectors and multi-object trackers. We represent the past trajectory of agent  as a sequence of motion state vectors  over the past  time steps. Each
, where ,  are the BEV location co-ordinates, ,  and  are the speed, acceleration and yaw-rate of the agent at time , and  is an indicator with value 1 for pedestrians and 0 for a vehicles. We nominally assign the index 0 to the target vehicle, and timestamp 0 to the time of prediction.

\vspace{-2mm}
\subsection{Representing HD maps as lane graphs}
\label{sec:lane_graphs}
 


 \textbf{Nodes:} We represent the HD map as a directed graph . The network of lane centerlines captures both, the direction of traffic flow, and the legal routes that each driver can follow. We seek to use both as inductive biases for our model. We thus use lane centerlines as nodes () in our graph. We consider all lane centerlines within a fixed area around the target vehicle. To ensure that each node represents a lane segment of a similar length, we divide longer lane centerlines into smaller snippets of a fixed length, and discretize them to a set of N poses. Each snippet corresponds to a node in our graph, with a node  represented by a sequence of feature vectors . Here each , where ,  and  are the location and yaw of the  pose of  and  is a 2-D binary vector indicating whether the pose lies on a stop line or crosswalk. Thus, our node features capture both the geometry as well as traffic control elements along lane centerlines. 



\textbf{Edges:} We constrain edges () in the lane graph such that any traversed path through the graph corresponds to a legal route that a vehicle can take in the scene. We consider two types of edges. Successor edges () connect nodes to the next node along a lane. A given node can have multiple successors if a lane branches out at an intersection. Similarly, multiple nodes can have the same successor if two or more lanes merge. To account for lane changes, we additionally define proximal edges () between neighboring lane nodes if they are within a distance threshold of each other and their directions of motion are within a yaw threshold. The yaw threshold ensures that proximal edges are not erroneously assigned in intersections where multiple lanes cross each other. 

\vspace{-2mm}
\subsection{Output representation}

To account for multimodality of the distribution of future trajectories, we output a set of  trajectories  for the target vehicle consisting of future x-y locations over a prediction horizon of  time steps. Each of the  trajectories represents a mode of the predictive distribution, ideally corresponding to different plausible routes or different motion profiles along the same route. 

\vspace{-2mm}

\section{Proposed Model}
\label{sec:model}

\begin{figure*}[t]
\centering
\includegraphics[width=\linewidth]{model.png}
\caption{\textbf{Proposed model.} PGP consists of three modules trained end-to-end. The graph encoder (top) encodes agent and map context as node encodings of a directed lane-graph. The policy header (bottom-left) learns a discrete policy for sampled graph traversals. The trajectory decoder (bottom-right) predicts trajectories by selectively attending to node encodings along paths traversed by the policy and a sampled latent variable. }
\label{fig:model}
\end{figure*}

Fig. \ref{fig:model} provides an overview of our model. It consists of three interacting modules trained end-to-end.
The \textit{graph encoder} (Sec. \ref{sec:encoder}) forms the backbone of our model. It outputs learned representations for each node of the lane graph, incorporating the HD map as well as surrounding agent context.
The \textit{policy header} (Sec. \ref{sec:policy}) outputs a discrete probability distribution over outgoing edges at each node, allowing us to sample paths in the graph. Finally, our attention based \textit{trajectory decoder} (Sec. \ref{sec:decoder}) outputs trajectories conditioned on paths traversed by the policy and a sampled latent variable.


\vspace{-2mm}
\subsection{Encoding scene and agent context}
\label{sec:encoder}
Inspired by the simplicity and effectiveness of graph based encoders for trajectory prediction \citep{gao2020vectornet, liang2020laneGcn}, we seek to encode all agent features and map features as node encodings of our lane graph . 

\textbf{GRU encoders.} Both, agent trajectories and lane polylines form sequences of features with a well defined order. We first independently encode both sets of features using gated recurrent unit (GRU) encoders. We use three GRU encoders for encoding the target vehicle trajectory , surrounding vehicle trajectories  and node features . These output the motion encoding , agent encodings  and initial node encodings  respectively.

\textbf{Agent-node attention.} 
Drivers co-operate with other drivers and pedestrians to navigate through traffic scenes. Thus, surrounding agents serve as a useful cue for trajectory prediction. Of particular interest are agents that might interact with the target vehicle's route. We thus update node encodings with nearby agent encodings using scaled dot product attention~\citep{vaswani2017attention}. We only consider agents within a distance threshold of each lane node to update the node encoding. This allows our trajectory decoder (Sec \ref{sec:decoder}) to selectively focus on agents that might interact with specific routes that the target vehicle might take. We obtain keys and values by linearly projecting encodings  of nearby agents, and the query by linearly projecting . Finally, the updated node encoding is obtained by concatenating the output of the attention layer with the original node encoding.





\textbf{GNN layers.} With the node encodings updated with nearby agent features, we exploit the graph structure to aggregate local context from neighboring nodes using graph neural network (GNN) layers. We experiment with graph convolution (GCN) ~\citep{kipf2016semi} and graph attention (GAT) ~\citep{velivckovic2017graph} layers. For the GNN layers, we treat both successor and proximal edges as equivalent and bidirectional. This allows us to aggregate context along all directions around each node. The outputs of the GNN layers serve as the final node encodings learned by the graph encoder.


\subsection{Discrete policy for graph traversal}
\label{sec:policy}

Every path in our directed lane graph corresponds to a plausible route for the target vehicle. However, not every route is equally likely. For example, the past motion of the target vehicle approaching an intersection might indicate that the driver is preparing to make a turn rather than go straight. A slow moving lane make it likelier for the target vehicle to change lane rather than maintain lane. 

We seek to learn a policy  for graph traversal such that sampled roll-outs of the policy correspond to likely routes that the target vehicle would take in the future. We represent our policy as a discrete probability distribution over outgoing edges at each node. We additionally include edges from every node to an \textit{end} state to allow  to terminate at a goal location. 
The edge probabilities are output by the policy header shown in Fig. \ref{fig:model}. The policy header uses an MLP with shared weights to output a scalar score for each edge  given by,





The scoring function thus takes into account the motion of the target vehicle as well as local scene and agent context at the specific edge. We then normalize the scores using a softmax layer for all outgoing edges at each node to output the policy for graph traversal,




We train the policy header using behavior cloning. For each prediction instance, we use the ground truth future trajectory to determine which nodes were visited by the vehicle. We can naively assign each pose in the future trajectory to the closest node in the graph. However, this can lead to erroneous assignment of nodes in intersections, where multiple lanes intersect. We thus only consider lane nodes whose direction of motion is within a yaw threshold of the target agent's pose. An edge  is treated as visited if both nodes  and  are visited. We use negative log likelihood of the edge probabilities for all edges visited by the ground truth trajectory (), as the loss function for training the graph traversal policy, given by 





\subsection{Decoding trajectories conditioned on traversals}
\label{sec:decoder}

Sampling roll-outs of  yields plausible future routes for the target vehicle. We posit that the most relevant context for predicting future trajectories is along these routes and propose a trajectory decoder that selectively aggregates context along the sampled routes. 

Given a sequence of nodes  corresponding to a sampled policy roll-out, our trajectory decoder uses multi-head scaled dot product attention \citep{vaswani2017attention} to aggregate map and agent context over the node sequence as shown in Fig. \ref{fig:model}. We linearly project the target vehicle's motion encoding to obtain the query, while we linearly project the node features  to obtain keys and values for computing attention. The multi-head attention layer outputs a context vector  encoding the route. Each distinct policy roll-out yields a distinct context vector, allowing us to predict trajectories along a diverse set of routes. 


Diversity in routes alone does not account for the multimodality of future trajectories. Drivers can brake, accelerate and follow different motion profiles along a planned route. To allow the model to output distinct motion profiles, we additionally condition our predictions with a sampled latent vector . Unlike routes, vehicle velocities and accelerations vary on a continuum. We thus sample  from a continuous distribution. We use the multivariate standard normal distribution for simplicity. 


Finally, to sample a trajectory  from our model, we sample a roll-out of  and obtain , we sample  from the latent distribution and concatenate both with  and pass them through an MLP to output  the future locations over  timesteps,

The sampling process can often be redundant, yielding similar or repeated trajectories. However our light-weight encoder and decoder heads allows us to sample a large number of trajectories in parallel. To obtain a final set of  modes of the trajectory distribution, we use K-means clustering and output the cluster centers as our final set of  predictions . We train our decoder using the winner takes all average displacement error with respect to the ground truth trajectory () in order to not penalize the diverse plausible trajectories output by our model, 
 
 




We train our model end-to-end using a multi-task loss combining losses from Eq. \ref{eq:l_bc} and Eq. \ref{eq:l_reg},














\vspace{-2mm}

\section{Experiments}
\label{sec:results}

\textbf{Dataset:} We evaluate our method on nuScenes~\citep{nuscenes2019}, a self-driving car dataset collected in Boston and Singapore.
nuScenes contains 1000 scenes, each 20 seconds, with ground truth annotations and HD maps.
Vehicles have manually-annotated 3D bounding boxes, which are published at 2 Hz.
The prediction task is to use the past 2 seconds of object history and the map to predict the next 6 seconds.
We use the standard split from the nuScenes software kit~\citep{nuScenes-website}.

\textbf{Metrics:} To evaluate our model, we use the standard metrics on the nuScenes leaderboard~\citep{nuScenes-website}.
The minimum average displacement error (ADE) over the top K predictions (MinADE).
The miss rate (MissRate) only penalizes predictions that are further than 2 m from the ground truth. The offroad rate measures the fraction of predictions that are off the road. Since all examples in nuScenes are on the road, this should be zero. Additionally, we report metrics measuring sample diversity of a set of  predictions. To measure lateral diversity, we report the average number of distinct final lanes reached, and the variance of final heading angle of the target vehicle () for the set of  trajectories. To measure longitudinal diversity, we report the variance of average speeds () and accelerations () for the set of  trajectories. 




\textbf{Comparison to the state of the art:} We report our results on the standard benchmark split of the nuScenes prediction dataset in table \ref{tab:sota}, comparing with the top performing entries on the nuScenes leaderboard. We achieve state of the art results on almost all metrics, significantly outperforming the previous best entry P2T ~\citep{deo2021p2t} on the MinADE and MissRate metrics, while achieving comparable off-road rate. This suggests that our model achieves better coverage of the modes of the trajectory distribution, while still predicting trajectories that are scene-compliant.    

\begin{table}[]
\caption{Comparison to the state of the art on nuScenes}
\label{tab:sota}
\centering
\resizebox{0.9\textwidth}{!}{
\begin{tabularx}{\linewidth}{@{}lYYYYY@{}}
\toprule
Model          & MinADE        & MinADE        & MissRate      & MissRate      & Offroad rate  \\ \midrule
CoverNet ~\citep{phan2019cover-net}       & 1.96          & 1.48          & 0.67          & -             & -             \\
Trajectron++ ~\citep{salzmann2020trajectron++}   & 1.88          & 1.51          & 0.70          & 0.57          & 0.25          \\
SG-Net ~\citep{wang2021stepwise}         & 1.86          & 1.40          & 0.67          & 0.52          & 0.04          \\
MHA-JAM ~\citep{messaoud2020mha-jam}        & 1.81          & 1.24          & \textbf{0.59} & 0.46          & 0.07          \\
CXX ~\citep{luo2020probabilistic}            & 1.63          & 1.29          & 0.69          & 0.60          & 0.08          \\
P2T ~\citep{deo2021p2t}            & 1.45          & 1.16          & 0.64          & 0.46          & \textbf{0.03} \\
PGP (Ours)           & \textbf{1.30} & \textbf{1.00} & 0.61          & \textbf{0.37} & \textbf{0.03} \\ \bottomrule
\end{tabularx}}
\end{table}

\begin{table}[]
\caption{Encoder ablations}
\label{tab:enc_ablations}
\centering
\resizebox{0.9\textwidth}{!}{\begin{tabularx}{\linewidth}{@{}ccccccccc@{}}
\toprule
\multicolumn{2}{c}{Graph structure} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Agent-node \\ attention\end{tabular}} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}GNN \\ layers\end{tabular}} & \multicolumn{2}{c}{MinADE}    & \multicolumn{2}{c}{MissRate} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Offroad rate\end{tabular}} \\ \cmidrule(r){1-2} \cmidrule(lr){5-6} \cmidrule(lr){7-8}
             &             &                                                                        &                                                                        & K=5           & K=10          & K=5           & K=10          &                                                                          \\ \midrule
\ding{51}          &                  &                                                                        &                                                                        & 1.35          & 1.03          & 0.64          & 0.41          & 0.04                                                                     \\
\ding{51}          & \ding{51}          &                                                                        &                                                                        & 1.33          & 1.01          & 0.63          & 0.38          & 0.03                                                                     \\
\ding{51}          & \ding{51}          & \ding{51}                                                                &                                                                        & \textbf{1.30} & \textbf{1.00} & \textbf{0.61} & \textbf{0.37} & \textbf{0.03}                                                            \\
\ding{51}          & \ding{51}          & \ding{51}                                                                & GCN  1                                                                 & 1.31          & 1.01          & 0.62          & 0.39          & 0.04                                                                     \\
\ding{51}          & \ding{51}          & \ding{51}                                                                & GCN  2                                                                  & 1.31          & 1.01          & 0.61          & 0.39          & 0.04                                                                     \\
\ding{51}          & \ding{51}          & \ding{51}                                                                & GAT  1                                                                  & \textbf{1.30} & \textbf{1.00} & 0.62          & 0.38          & 0.03                                                                     \\
\ding{51}          & \ding{51}          & \ding{51}                                                                & GAT  2                                                                  & 1.31          & 1.01          & \textbf{0.61} & \textbf{0.37} & \textbf{0.03}                                                            \\ \bottomrule
\end{tabularx}}
\end{table}

\begin{table}[h!]
\caption{Decoder ablations}
\label{tab:dec_ablations}
\centering
\resizebox{0.9\textwidth}{!}{
\begin{tabularx}{\linewidth}{@{}lYYYYY@{}}
\toprule
Decoder                     & MinADE        & MinADE        & MissRate      & MissRate      & Offroad rate  \\ \midrule
MTP ~\citep{cui2019multimodal}                         & 1.59          & 1.12          & \textbf{0.57} & 0.48          & 0.08          \\
Latent var (LV) only                          & 1.38          & 1.08          & 0.65          & 0.43          & 0.05          \\
Traversal only       & 1.37          & 1.10          & 0.65          & 0.44          & 0.04          \\
Goals + LV      & 1.33          & 1.02          & 0.60          & 0.42          & 0.06          \\
Traversals + LV & \textbf{1.31} & \textbf{1.01} & 0.61          & \textbf{0.37} & \textbf{0.03} \\ \bottomrule
\end{tabularx}}
\end{table}






\begin{table}[h!]
\begin{minipage}{.5\textwidth}
\centering
\caption{Lateral diversity metrics (K=10)}
\label{tab:dec_ablations_2}
\resizebox{0.9\textwidth}{!}{
\begin{tabularx}{\textwidth}{@{}lcc@{}}
\toprule
Decoder                     & \# distinct final lanes   &       \\ \midrule
LV only                          & 1.22  &0.11      \\
Traversals + LV & \textbf{1.41} & \textbf{0.13}  \\ \bottomrule
\end{tabularx}}\hfill
\end{minipage}
\begin{minipage}{.5\textwidth}
\centering
\caption{Longitudinal diversity metrics (K=10)}
\label{tab:dec_ablations_3}
\resizebox{0.9\textwidth}{!}{
\begin{tabularx}{\textwidth}{@{}lYY@{}}
\toprule
Decoder                     &  &     \\ \midrule
Traversal only                          & 2.33          & 5.28      \\
Traversals + LV & \textbf{4.07}  & \textbf{6.65}  \\ \bottomrule
\end{tabularx}}
\end{minipage}

\end{table}





\textbf{Encoder ablations:} We analyze the effects of our graph structure and components of the graph encoder by performing ablations on the graph encoder reported in table \ref{tab:enc_ablations}. In particular we analyze the effect of including proximal edges, modeling surrounding agents with agent-node attention and finally aggregating local context using GCN ~\citep{kipf2016semi} or GAT ~\citep{velivckovic2017graph} layers. We get improvement across all metrics by adding proximal edges, and agent-node attention, suggesting the importance of modeling lane changes and agent context. Somewhat surprisingly, adding GNN layers gives ambiguous results with GCN layers achieving slightly worse results and GAT layers performing on par with the encoder without GNN layers. This could be because the multi-head attention layer aggregates context across the entire traversed path, making the GNNs redundant.   


\textbf{Decoder ablations:}
We next analyze the effect of our traversal and latent variable based decoder. We compare several decoders, all built on top of our proposed encoder with both types of edges, agent-node attention and 2 GAT layers. First, we consider the multimodal regression header from  MTP~\citep{cui2019multimodal}. Next we consider ablations of our decoder without the graph traversals and without the latent variable conditioning. Finally, we consider a model that conditions predictions on sampled goals at different node locations, instead of traversals. Table \ref{tab:dec_ablations} reports quantitative results while Fig. \ref{fig_qual} shows qualitative examples comparing the decoders. We make the following observations. 

MTP generally fares worse compared to the other decoders, particularly in terms of offroad rate. We note from Fig. \ref{fig_qual} that while it generates a diverse set of trajectories, several veer off-road.

The decoders conditioned purely on the latent variable or purely on traversals both fare worse in terms of MinADE and MissRate compared to our decoder conditioned on both. From the sample diversity metrics (Tables \ref{tab:dec_ablations_2} and \ref{tab:dec_ablations_3}) and qualitative examples (Fig.\ref{fig_qual}) we observe that this is for different reasons. The `LV only' decoder generates diverse motion profiles, but almost always predicts trajectories along a single route, leading to poor lateral diversity of trajectories. On the other hand, the 'Traversal only' decoder predicts trajectories over a variety of routes, but lacks diversity in terms of motion profiles. 


Finally, the `Goals + LV' decoder also fares worse compared to our `Traversals + LV' decoder, again, especially in terms of off-road rate. Qualitatively, we observe that this is due to two types of errors. First, it tends to predict spurious goals which aren't reachable for the target vehicle (Fig.\ref{fig_qual} \textcircled{3}, \textcircled{4}), and second, while it predicts correct goals, it generates trajectories that don't follow accurate paths to those goals (Fig.\ref{fig_qual} \textcircled{2},\textcircled{6}).    













\begin{figure*}[t]
\centering
\includegraphics[width=\linewidth]{qualitative_annotated.png}
\caption{\textbf{Qualitative comparison of decoders:}
MTP (\textit{column 2}) predicts trajectories that often veer off-road (\textcircled{1}-\textcircled{3},\textcircled{6}). The decoder purely conditioned on latent variables (\textit{column 3}) lacks lateral diversity and predicts trajectories along a single route, even missing the correct route in \textcircled{6}. The decoder conditioned purely on traversals (\textit{column 4}) predicts diverse routes, but lacks longitudinal diversity (\textcircled{1},\textcircled{2},\textcircled{5}). Finally, the decoder conditioned on goals rather than path traversals (\textit{column 5}) predicts spurious goals that may not be reachable (\textcircled{3}, \textcircled{4}). Our model (\textit{column 6}) predicts scene-compliant trajectories over a diverse set of routes. In cases with few plausible routes (e.g.\textcircled{5}), it uses its prediction budget of  trajectories to generate more longitudinal diversity.}
\label{fig_qual}
\end{figure*}




\vspace{-2mm}
\section{Conclusions}
\label{sec:conclusion}


We presented a novel method for multimodal trajectory prediction conditioned on paths traversed in a lane graph of the HD map by a discrete policy, and a sampled latent variable. Through experimental analysis and ablation studies using the publicly available nuScenes dataset, we showed that 
\begin{itemize}[noitemsep,topsep=0pt,leftmargin=10pt]
\item Selectively conditioning predictions on lane-graph traversals leads to trajectories that are (i) diverse in terms of routes, and (ii) precise and scene compliant with the lowest offroad-rates.
\item Additionally conditioning predictions on sampled latent variables leads to trajectories that are diverse in terms of motion profiles.
\item Both put together lead to state of the art results in terms of MinADE and MissRate metrics.
\end{itemize}







\clearpage




\bibliography{example}  


\newpage
\appendix
\section{Implementation details}
We implement our model using Pytorch\footnote{\href{https://pytorch.org/}{https://pytorch.org/}}. Here, we provide details of our model architecture, ablations and training. 

\subsection{Map representation}
The nuScenes map API provides lane polylines, their successors, and polygons for cross-walks and stop lines. We consider map elements within an area of [-50, 50] m laterally and [-20, 80] m longitudinally around the target vehicle. This ensures that most ground truth trajectories lie within the area of interest. We split longer lane centerlines into snippets of maximum length 20m, and discretize the polylines at a 1m resolution. Each snippet corresponds to a node in the graph. This ensures that each lane node represents a lane segment of similar length. The node resolution (20m) and pose resolution (1m) for the polylines were experimentally chosen. There is a trade-off associated with the resolution of lane nodes: A finer resolution would provide a more informative set of inputs, but would lead to a graph with a greater number of nodes (and a greater number of poses per node) increasing encoder complexity.

\subsection{GRU encoders}
We embed both agent and node features using linear layers of size 16, followed by a leaky ReLU non-linearity. We use GRUs with depth 1 and hidden state dimension 32 on top of the embeddings for both the agent and node encoders.

\subsection{Agent-node attention}
We use scaled dot-product attention with a single attention head for the agent-node attention layers. We use 32  32 weight matrices for projecting the node and agent encodings for obtaining
the queries, and keys and values respectively. The outputs of the attention layer are concatenated with the original node encodings and passed through a linear layer of size 32, followed by a leaky ReLU non-linearity to obtain updated node encodings of the same size as the original node encodings.

\subsection{GNN layers}
We use Pytorch geometric\footnote{\href{https://github.com/rusty1s/pytorch_geometric}{https://github.com/rusty1s/pytorch\_geometric}} for implementing the GCN and GAT layers of our model. For GCN layers, we use the layer-wise propagation rule from ~\citep{kipf2016semi}. Our adjacency matrix includes both successor and proximal edges (treated as bidirectional), as well as self loops. The outputs at each node have the same dimension, 32, as the inputs. For GAT layers, we use the layer-wise propagation rule from ~\citep{velivckovic2017graph}. We use a single attention head, with the outputs again having the same dimension as the inputs.

\subsection{Policy header}
The policy header is implemented as an MLP with 2 hidden layers of size 32 each and a scalar output. The input to the policy header for each edge is a vector of size 98, consisting of the source node encoding, destination node encoding and motion encoding of the target agent each of size 32, and a one-hot encoding for the edge type of size 2.

\subsection{Trajectory decoder}
We aggregate context along nodes traversed by the policy using a multi-head scaled dot-product attention layer. The attention layer has 32 parallel attention heads, and outputs a context vector  of size 128. We model the latent variable as a multivariate standard normal distribution. , where  is a 55 identity matrix. 
We output a trajectory for each sampled ,  and  using an MLP with a hidden layer of size 128, and output of size 24 ( and  co-ordinates over the prediction horizon of 6 seconds at 2 Hz). We sample 200 trajectories from the model and cluster to obtain =10 trajectories during training to compute the winner takes all regression loss .


\subsection{Training}
We train the model using Adam, with learning rate 1e-4, and a batch size of 32. For the first few epochs of training, since  does not produce meaningful traversals, we use the ground truth traversal for sampling trajectories and computing . We pre-train the model using the ground truth traversal for 100 epochs. We then finetune using paths sampled from  for 100 epochs. We train our model using an AWS "p3-8xlarge" instance with 4 NVIDIA Tesla V100 GPUs. Each pre-training epoch takes roughly 1 minute and each finetuning epoch takes roughly 5 minutes for nuScenes.  


\subsection{Decoder ablation details}
\label{appendix:decoder_blations}
 \textbf{MTP}: For the MTP header, we first aggregate context over the entire graph using a multi-head scaled dot-product attention layer identical to our trajectory decoder, with 32 parallel attention heads and an output context vector  of size 128. We then use two fully connected layers of size 240 and 10 respectively to output =10 trajectories, and  probabilities.   

\textbf{LV only}: For the LV only decoder, similar to the MTP header, we first aggregate context over the entire graph using a multi-head attention layer with 32 attention heads and output  of size 128. The decoder then outputs trajectories conditioned on ,  and a sample  of the latent variable using the final MLP layer.  

\textbf{Traversal only}: The traversal only decoder is identical to the trajectory decoder of our complete model, except for the final MLP layer, which outputs trajectories conditioned only on  and  and not on the sampled latent variable .

\textbf{Goals + LV}: The Goals + LV decoder consists of two output headers:  A goal prediction header that outputs a scalar score at each node normalized using a softmax layer to give goal probabilities, and a trajectory decoder that outputs goal conditioned trajectories. We model the goal prediction header using an MLP with 2 hidden layers, each of size 32, and a scalar output. The input to the goal prediction header at each node is obtained by concatenating  and . The trajectory decoder consists of a multi-head attention layer with 32 heads that aggregates context over the entire graph to output a context vector  of size 128.  is concatenated with , a sampled latent vector  and the node encoding of a sampled goal  and passed through an MLP with a hidden layer of size 128, and output size 24 corresponding to a goal conditioned trajectory. 









\end{document}
