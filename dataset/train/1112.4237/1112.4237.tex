\documentclass{llncs}




\usepackage{proof,latexsym, amsmath, amsfonts,amssymb}





\newcommand{\texcomment}[1]{}
\newcommand{\addappendix}[2]{#1}

\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}

\texcomment{
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{claim}{Claim}
\newtheorem{remark}{Remark}
\newenvironment{proof}{\noindent\rm{\bf Proof:}}{\hbox{}\vspace*{0.2\baselineskip}}
\newenvironment{proofsketch}{\noindent\rm{Proof
    (Sketch):}}{\hbox{}}


\newenvironment{case}[1]{\noindent\rm\framebox{#1}\hspace*{1em}\\}{\vspace*{1em}}
\newtheorem{example}[theorem]{Example}
}

\newenvironment{reflemma}[1]{\begin{trivlist}\item[\hskip
      \labelsep{\bf Lemma #1.}]\it}{\end{trivlist}}



\newcommand{\add}[1]{\textcolor{blue}{#1}}
\newcommand{\comment}[1]{\textbf{[#1]}}

\newenvironment{boxcase}[1]{\noindent\rm\framebox{#1}\hspace*{1em}\\}

\newenvironment{reftheorem}[1]{\begin{trivlist}\item[\hskip
      \labelsep{\bf Theorem #1.}]\it}{\end{trivlist}}

\newcommand{\aset}[1]{\{{#1}\}}
\newcommand{\aseq}[1]{\langle#1\rangle}
\newcommand{\adseq}[1]{\langle\hspace*{-2pt}\langle{#1}\rangle\hspace*{-2pt}\rangle}
\newcommand{\sembrack}[1]{[\hspace*{-1.2pt}[#1]\hspace*{-1.2pt}]}
\newcommand{\dom}{\mathop\textit{dom}\nolimits}
\newcommand{\ran}{\mathop\textit{ran}\nolimits}
\newcommand{\smallcolon}{\hspace*{-2pt}:\hspace*{-2pt}}
\newcommand{\smallless}{\hspace*{-2pt}<\hspace*{-2pt}}

\newcommand{\restrict}{\hspace*{-0.2ex}\restriction}

\newcommand{\ttif}[3]{\textsf{if}\;{#1}\;\textsf{then}\;{#2}\;\textsf{else}\;{#3}}
\newcommand{\ttassign}[2]{{#1}\;:=\;{#2}}

\newcommand{\wpre}[2]{\textit{wp}({#1}, {#2})}

\newcommand{\leqlow}{\preceq_I}

\newcommand{\simeqlow}{\simeq_I}

\newcommand{\ua}{user-attacker}

\newcommand{\vect}[1]{\overrightarrow{{#1}}}

\usepackage{setspace}
\begin{document}

\title{On Bounding Problems of Quantitative Information
  Flow\thanks{This work was supported by MEXT KAKENHI 20700019,
    20240001, and 22300005, and Global COE Program ``CERIES.''}}
\author{Hirotoshi Yasuoka\inst{1} \and Tachio Terauchi\inst{2}}
\institute{Tohoku University\\ \email{yasuoka@kb.ecei.tohoku.ac.jp}
  \and Nagoya University\\\email{terauchi@is.nagoya-u.ac.jp}}
\maketitle

\begin{abstract}
Researchers have proposed formal definitions of quantitative
information flow based on information theoretic notions such as the
Shannon entropy, the min entropy, the guessing entropy, belief, and
channel capacity.  This paper investigates the hardness of precisely
checking the quantitative information flow of a program according to
such definitions.  More precisely, we study the ``bounding problem''
of quantitative information flow, defined as follows: Given a program
 and a positive real number , decide if the quantitative
information flow of  is less than or equal to .  We prove that
the bounding problem is not a -safety property for any  (even
when  is fixed, for the Shannon-entropy-based definition with the
uniform distribution), and therefore is not amenable to the
self-composition technique that has been successfully applied to
checking non-interference.  We also prove complexity theoretic
hardness results for the case when the program is restricted to
loop-free boolean programs.  Specifically, we show that the problem is
PP-hard for all definitions, showing a gap with non-interference which
is coNP-complete for the same class of programs.  The paper also
compares the results with the recently proved results on the
comparison problems of quantitative information flow.\newline
\newline
\noindent{\bf Keywords:} security, quantitative information flow, program verification

\end{abstract}



\section{Introduction}

\label{sec:introduction}

We consider programs containing high security inputs and low security
outputs.  Informally, the quantitative information flow problem
concerns the amount of information that an attacker can learn about
the high security input by executing the program and observing the low
security output.  The problem is motivated by applications in
information security.  We refer to the classic by
Denning~\cite{denning82} for an overview.

In essence, quantitative information flow measures {\em how} secure,
or insecure, a program (or a part of a program --e.g., a variable--)
is.  Thus, unlike
non-interference~\cite{DBLP:conf/sosp/Cohen77,goguen:sp1982}, that
only tells whether a program is completely secure or not completely
secure, a definition of quantitative information flow must be able to
distinguish two programs that are both interferent but have different
degrees of ``secureness.''

For example, consider the following programs.

In both programs,  is a high security input and  is a low
security output.  Viewing  as a password,  is a prototypical
login program that checks if the guess  matches the
password.\footnote{Here, for simplicity, we assume that  is a
  program constant.  See Section~\ref{sec:prelim} for modeling
  attacker/user (i.e., low security) inputs.}  By executing , an
attacker only learns whether  is equal to , whereas she would be
able to learn the entire content of  by executing .  Hence, a
reasonable definition of quantitative information flow should assign a
higher quantity to  than to , whereas non-interference would
merely say that  and  are both interferent, assuming that
there are more than one possible values of .

Researchers have attempted to formalize the definition of quantitative
information flow by appealing to information theory.  This has
resulted in definitions based on the Shannon
entropy~\cite{denning82,clarkjcs2007,malacaria:popl2007}, the min
entropy~\cite{smith09}, the guessing
entropy~\cite{kopf07,DBLP:conf/sp/BackesKR09},
belief~\cite{clarkson:csf2005}, and channel
capacity~\cite{mccamant:pldi2008,malacaria08,NMS2009}.  All of these
definitions map a program (or a part of a program) onto a non-negative
real number, that is, they define a function  such that
given a program ,  is a non-negative real number.
(Concretely,  is  for the
Shannon-entropy-based definition with the distribution ,  for the min-entropy-based definition with the distribution
,  for the guessing-entropy-based definition with
the distribution , and  for the channel-capacity-based
definition.\footnote{The belief-based definition takes additional
  parameters as inputs, and is discussed below.})  Therefore, a
natural verification problem for quantitative information flow is to
decide, given  and a quantity , if .  The problem is well-studied for the case  as it is
actually equivalent to checking non-interference
(cf. Section~\ref{sec:nonint}).  The problem is open for  .  We
call this the {\em bounding problem} of quantitative information flow.

The problem has a practical relevance as a user is often interested in
knowing if her program leaks information within some allowed bound.
That is, the bounding problem is a form of quantitative information
flow {\em checking} problem (as opposed to {\em inference}).  Much of
the previous research has focused on information theoretic properties
of quantitative information flow and approximate (i.e., incomplete
and/or unsound) algorithms for checking and inferring quantitative
information flow.  To fill the void, in a recent
work~\cite{DBLP:conf/csfw/yasuoka2010}, we have studied the hardness
and possibilities of deciding the {\em comparison problem} of
quantitative information flow, which is the problem of precisely
checking if the information flow of one program is larger than that of
the other, that is, the problem of deciding if  given programs  and .  The study has lead
to some remarkable results, summarized in Section~\ref{sec:ksafety}
and Section~\ref{sec:complex} of this paper to contrast with the new
results on the bounding problem.  However, the hardness results on the
comparison problem do not imply hardness of the bounding
problem.\footnote{But, they imply the hardness of the inference
  problem because we can compare  and
   once we have computed them.  We also note
    that the hardness of the bounding problems implies that of the
    comparison problems because we can reduce the bounding problem
     to a comparison problem that compares 
    with a program whose information flow is .  (But, the reverse
    direction does not hold.)}  Thus, this paper settles the open
question.

We summarize the main results of the paper below.  Here, 
is , ,  or , where 
is the uniform distribution.
\begin{itemize}
\item Checking if  is not a -safety
  property~\cite{terauchi:sas05,DBLP:conf/csfw/ClarksonS08} for any .
\item Restricted to loop-free boolean programs, checking if
 is PP-hard.
\end{itemize}
Roughly, a verification problem being -safety means that it can be
reduced to a standard safety problem, such as the unreachability
problem, via self composition~\cite{barthe:csfw04,darvas:spc05}.  For
instance, non-interference is a -safety property (technically, for
the termination-insensitive case\footnote{We restrict to terminating
  programs in this paper.  (The termination assumption is
  nonrestrictive because we assume safety verification as a blackbox
  routine.)}), and this has enabled its precise checking via a
reduction to a safety problem via self composition and applying
automated safety verification
techniques~\cite{terauchi:sas05,naumann:esorics06,unno:plas2006}.
Also, our recent work~\cite{DBLP:conf/csfw/yasuoka2010} has shown that
deciding the comparison problem of quantitative information flow for
all distributions (i.e., checking if , , , and \footnote{See below for the notation
   denoting the belief-based
  quantitative information flow of  with respect to the experiment
  .  The result for the belief-based definition is
  proven in the extended version of the paper that is under
  submission~\cite{yasuoka:toplas2010submit}.}) are -safety problems
(and in fact, all equivalent).

We also prove a complexity theoretic gap with these related problems.
We have shown in the previous paper~\cite{DBLP:conf/csfw/yasuoka2010}
that, for loop-free boolean programs, both checking non-interference
and the above comparison problem with universally quantified
distributions are coNP-complete.  (PP is believed to be strictly
harder than coNP.  In particular,  implies
the collapse of the polynomial hierarchy to level 1.)

Therefore, the results suggest that the bounding problems of
quantitative information flow are harder than the related problems of
checking non-interference and the quantitative information flow
comparison problems with universally quantified distributions, and may
require different techniques to solve (i.e., not self composition).

The belief-based quantitative information flow~\cite{clarkson:csf2005}
differs from the definitions above in that it focuses on the
information flow from a particular execution of the program (called
{\em experiment}) rather than the information flow from all executions
of the program.\footnote{Clarkson et. al.~\cite{clarkson:csf2005}
    also propose a definition which averages the quantitative
    information flow over a distribution of the inputs  and .
    Note that a hardness result for (1) below implies the hardness
    result of the bounding problem for this problem as we may take the
    distribution to be a point mass.}  Therefore, we define and study
the hardness of two types of bounding problems for the belief-based
definition:
\begin{itemize}
\item[(1)] 
\item[(2)] 
\end{itemize}
Here,  denotes the belief-based
information flow of  with the experiment  where
 are the particular (high-security and low-security) inputs.
Note that the problem (2) checks the bound of the belief-based
quantitative information flow for {\em all} inputs whereas (1) checks
the information flow for a particular input.  This paper proves that
neither of these problems are -safety for any , and are PP-hard
for loop-free boolean programs.

We note that the above results are for the case the quantity  is
taken to be an input to the bounding problems.  We show that when
fixing the parameter  constant, some of the problems become
-safety under certain conditions for different 's
(cf. Section~\ref{sec:ksafetyconst}, \ref{sec:ksafetybelief}, and
\ref{sec:ksafetycclike}).

We also define and study the hardness of the following bounding
problems that check the bound over {\em all} distributions.
\begin{itemize}
\item[(1)] 
\item[(2)] 
\item[(3)] 
\item[(4)] 
\item[(5)] 
\end{itemize}
We show that except for (4) and (5), these problems are also not
-safety for any , and are PP-hard for loop-free boolean
programs, when  is not a constant (but are -safety for various
's when  is held constant).  For the problems (4) and (5), we
show that the problems are actually equivalent to that of checking
non-interference.  (1), (2), and (3) are proven by showing that
the problems correspond to various ``channel capacity like'' definitions
of quantitative information flow.

The rest of the paper is organized as follows.
Section~\ref{sec:prelim} reviews the existing information-theoretic
definitions of quantitative information flow and formally defines the
bounding problems.  Section~\ref{sec:ksafety} proves that the bounding
problems are not -safety problems for , ,
, and .  (Section~\ref{sec:ksafetyconst} shows
that when fixing the parameter  constant, some of them become
-safety under certain conditions for different 's.)
Section~\ref{sec:ksafetybelief} shows -safety results for the
belief-based bounding problems, and Section~\ref{sec:ksafetycclike}
shows -safety results for the bounding problems that check the
bound for all distributions.  Section~\ref{sec:complex} proves
complexity theoretic hardness results for the bounding problems for
loop-free boolean programs for , , , and , and Section~\ref{sec:complexbeliefcclike}
proves those for the belief-based bounding problems and the bounding
problems that check the bound for all distributions.
Section~\ref{sec:discussion} discusses some implications of the
hardness results.  Section~\ref{sec:related} discusses related work,
and Section~\ref{sec:concl} concludes.  All the proofs appear in
Appendix~\ref{appendix}.

\section{Preliminaries}

\label{sec:prelim}

We introduce the information theoretic definitions of quantitative
information flow that have been proposed in literature.  First, we
review the notion of the {\em Shannon entropy}~\cite{shannon48},
, which is the average of the information
content, and intuitively, denotes the uncertainty of the random
variable .
\begin{definition}[Shannon Entropy]
  Let  be a random variable with sample space  and 
  be a probability distribution associated with .  (We write 
  explicitly for clarity.)  The Shannon entropy of  is defined as

(The logarithm is in base 2.)
\end{definition}
Next, we define {\em conditional entropy}.  Informally, the conditional
entropy of  given  denotes the uncertainty of  after knowing
.
\begin{definition}[Conditional Entropy]
Let  and  be random variables with sample spaces  and
, respectively, and  be a probability distribution
associated with  and .  Then, the conditional entropy of 
given , written  is defined as

where

\end{definition}
Next, we define (conditional) mutual information.  Intuitively, the
conditional mutual information of  and  given  represents the
mutual dependence of  and  after knowing .
\begin{definition}[Mutual Information]
  Let  and  be random variables and  be an associated
  probability distribution.\footnote{We abbreviate the sample spaces
    of random variables when they are clear from the context.}  Then,
  the conditional mutual information of  and  given  is
  defined as

\end{definition}

Let  be a program that takes a high security input  and a low
security input , and gives the low security output .  For
simplicity, we restrict to programs with just one variable of each
kind, but it is trivial to extend the formalism to multiple variables
(e.g., by letting the variables range over tuples).  Also, for the
purpose of the paper, unobservable (i.e., high security) outputs are
irrelevant, and so we assume that the only program output is the low
security output.  Let  be a probability distribution over the
values of  and .  Then, the semantics of  can be defined by
the following probability equation. (We restrict to terminating
  deterministic programs in this paper.)

Note that we write  to denote the low security output of
the program  given inputs  and .  Now, we are ready to
introduce the Shannon-entropy based definition of quantitative
information flow (QIF)~\cite{denning82,clarkjcs2007,malacaria:popl2007}.
\begin{definition}[Shannon-Entropy-based QIF]
\label{def:se}
Let  be a program with a high security input , a low security input
, and a low security output .  Let  be a distribution over
 and .  Then, the Shannon-entropy-based quantitative information
flow is defined

\end{definition}
Intuitively,  denotes the initial uncertainty
knowing the low security input and  denotes
the remaining uncertainty after knowing the low security output.

\begin{sloppypar}
As an example, consider the programs  and  from
Section~\ref{sec:introduction}.  For concreteness, assume that  is
the value  and  ranges over the space .
Let  be the uniform distribution over , that
is,  for all .  Computing
their Shannon-entropy based quantitative information flow, we have,
\end{sloppypar}

Hence, if the user was to ask if , that is,
``does  leak more than one bit of information (according to )?'', then the answer would be no.  But, for the same query,
the answer would be yes for .

Next, we introduce the {\em min entropy}, which Smith~\cite{smith09}
recently suggested as an alternative measure for quantitative information
flow.
\begin{definition}[Min Entropy]
Let  and  be random variables, and  be an associated probability
distribution.  Then, the min entropy of  is defined

and the conditional min entropy of  given  is defined

where

\end{definition}

\begin{sloppypar}
Intuitively,  represents the highest probability
that an attacker guesses  in a single try.  We now define the
min-entropy-based definition of quantitative information flow.
\end{sloppypar}

\begin{definition}[Min-Entropy-based QIF]
\label{def:me}
Let  be a program with a high security input , a low security input
, and a low security output .  Let  be a distribution over
 and .  Then, the min-entropy-based quantitative information
flow is defined

\end{definition}

Whereas Smith~\cite{smith09} focused on programs lacking low security
inputs, we extend the definition to programs with low security inputs
in the definition above.  It is easy to see that our definition
coincides with Smith's for programs without low security
inputs.  Also, the extension is arguably natural in the sense that we simply
take the conditional entropy with respect to the distribution over the
low security inputs.

Computing the min-entropy based quantitative information flow for our
running example programs  and  from
Section~\ref{sec:introduction} with the uniform distribution, we
obtain,

Hence, if a user is to check whether  is bounded by 
for , then the answer would be yes for , but no for
.

Next, we introduce the {\em guessing-entropy} based definition of
quantitative information
flow~\cite{Massey94,kopf07,DBLP:conf/sp/BackesKR09}.
\begin{definition}[Guessing Entropy]
Let  and  be random variables, and  be an associated probability
distribution.  Then, the guessing entropy of  is defined

where  and  satisfies .

The conditional guessing entropy of  given  is defined

where

\end{definition}

Intuitively,  represents the average number of
times required for the attacker to guess the value of .  We now
define the guessing-entropy-based quantitative information flow.

\begin{definition}[Guessing-Entropy-based QIF]
\label{def:ge}
Let  be a program with a high security input , a low security input
, and a low security output .  Let  be a distribution over
 and .  Then, the guessing-entropy-based quantitative
information flow is defined

\end{definition}

\begin{sloppypar}
Like with the min-entropy-based definition, the previous research on
guessing-entropy-based quantitative information flow only considered
programs without low security
inputs~\cite{kopf07,DBLP:conf/sp/BackesKR09}.  But, it is easy to see
that our definition with low security inputs coincides with the
previous definitions for programs without low security inputs.  Also,
as with the extension for the min-entropy-based definition, it simply
takes the conditional entropy over the low security inputs.
\end{sloppypar}

We test {\it GE} on the running example from
Section~\ref{sec:introduction} by calculating the quantities for the
programs  and  with the uniform distribution. 
\renewcommand{\arraystretch}{1.1}

\renewcommand{\arraystretch}{1.0}

\noindent
Hence, if a user is to check whether  is bounded by
 for , then the answer would be yes for , but no
for .

Next, we introduce the belief-based definition of quantitative
information flow \cite{clarkson:csf2005}.  The belief-based definition
computes the information leak from a single execution of the program,
called an {\em experiment}.

\begin{definition}[Experiment]
  Let  be a distribution over a high-security input such that
  ,  be a high-security input, and
   be a low-security input.  Then, the experiment
   is defined to be the tuple .\footnote{Clarkson et.
    al.~\cite{clarkson:csf2005} also include the output and the
    program itself as part of the experiment.  In this paper, an
    experiment consists solely of the input and the distribution.}
\end{definition}
Intuitively, the distribution  represents the attacker's {\em belief}
about the user's high security input selection, 
denotes the attacker's low-security input selection, and
 denotes the user's actual selection.  Then, the
belief-based quantitative information flow, which is the information flow
of individual experiments, is defined as follows.
\begin{definition}[Belief-based QIF]
\label{def:beliefqif}
Let  be a program with a high security input, a low security input,
and a low security output.  Let  be an experiment such
that .
Then, the belief-based quantitative information flow is defined

where
\end{definition}
Here,  is the {\em relative entropy}
  (or, {\em distance}) of  and , and quantifies the
difference between the two distributions.\footnote{Here, we
    follow \cite{clarkson:csf2005} and use the notation
     over the more standard notation .}  Note that  denotes the point mass
distribution at .  Intuitively, the belief-based quantitative
information flow expresses the difference between the attacker's
belief about the high security input and the output of the experiment.
It can be shown that  is equivalent to {\em
  self-information} (for  deterministic), that is, the
  negative logarithm of the probability the event occurs (i.e., in
  this case, the output occurs).
\begin{lemma}
  Let  be a belief,  be a high-security input,
   be a low-security input.  Then, .
\label{lem:be}
\end{lemma}

Computing the belief-based quantitative information flow for our
running example programs  and  from
Section~\ref{sec:introduction} with the uniform distribution, we
obtain,
\begin{itemize}
\item 


\item 

\end{itemize}
And, for any ,

Therefore, if the user was to ask if  is bounded
by  for , then the answer would be yes for  but no
for .  But, if the user was to ask if  is
bounded by  for all , then the answer would be no for both
 and .

Finally, we introduce the definition of quantitative information flow
based on {\em channel
  capacity}~\cite{mccamant:pldi2008,malacaria08,NMS2009}, which is
defined to be the maximum of the Shannon-entropy based quantitative
information flow over the distribution.
\begin{definition}[Channel-Capacity-based QIF]
Let  be a program with a high security input , a low security input
, and a low security output .  Then, the channel-capacity-based
quantitative information flow is defined

\end{definition}

Unlike the other definitions above, the channel-capacity based
definition of quantitative information flow is not parameterized by
the distribution over the inputs.  As with the other definitions, let
us test the definition on the running example from
Section~\ref{sec:introduction} by calculating the quantities for the
programs  and :

Note that  (resp. ) is equal to  (resp. ).  This is not a coincidence.
In fact, it is known that  for all
programs  without low security inputs~\cite{smith09}.

\subsection{Non-interference}

\label{sec:nonint}

We recall the notion of
non-interference~\cite{DBLP:conf/sosp/Cohen77,goguen:sp1982}.
\begin{definition}[Non-intereference]
A program  is said to be non-interferent iff for any  and , .
\end{definition}

It can be shown that for the definitions of quantitative information
flow  introduced above,  iff 
is non-interferent.\footnote{Technically, we need the non-zero-ness
  condition on the distribution.  (See below.)}  That is, the bounding
problem (which we only officially define for positive bounds --see
Section~\ref{sec:boundprob}--) degenerates to checking
non-interference when  is given as the bound.

\begin{theorem}
\label{thm:nonint}
Let  be a distribution such that .  Then,
\begin{itemize}
\item  is non-interferent if and only if .
\item  is non-interferent if and only if .
\item  is non-interferent if and only if .
\item  is non-interferent if and only if .\footnote{Recall Definition~\ref{def:beliefqif} that  is a distribution over  such that  for all .}
\item  is non-interferent if and only if .
\end{itemize}
\end{theorem}
The equivalence result on the Shannon-entropy-based definition is
proven by Clark et al.~\cite{clark05}.  The proofs for the other four
definitions are given in Appendix~\ref{appendix}.

\subsection{Bounding Problem}

\label{sec:boundprob}

We define the {\em bounding problem} of quantitative information flow
for each definition introduced above.  The bounding problem for the
Shannon-entropy based definition  is defined as
follows: Given a program  and a positive real number , decide if
.\footnote{Note that we treat  as a
    parameter of the bounding problem rather than as an input.}
Similarly, we define the bounding problems for the other three
definitions , , and  as
follows.

We defer the definitions of the belief-based bounding problems to 
Section~\ref{sec:ksafetybelief}.
\section{K-Safety Property}

\label{sec:ksafety}

We show that none of the bounding problems are -safety problems for
any .  Informally, a program property is said to be a {\em
  -safety}
property~\cite{terauchi:sas05,DBLP:conf/csfw/ClarksonS08} if it can be
refuted by observing  number of (finite) execution traces.  A
-safety problem is the problem of checking a -safety property.
Note that the standard safety property is a -safety property.  An
important property of a -safety problem is that it can be reduced
to a standard safety (i.e., -safety) problem, such as the
unreachability problem, via a simple program transformation called
{\em self composition}~\cite{barthe:csfw04,darvas:spc05}.  This allows
one to verify -safety problems by applying powerful automated
safety verification
techniques~\cite{DBLP:conf/popl/BallR02,DBLP:conf/popl/HenzingerJMS02,mcmillan:cav06,DBLP:journals/sttt/BeyerHJM07}
that have made remarkable progress recently.

As stated earlier, we prove that no bounding problem is a -safety
property for any .  (First, we prove the result for {\it SE}, {\it
  ME}, {\it GE}, and {\it CC}, and defer the result for {\it BE} to
Section~\ref{sec:ksafetybelief}.)  To put the result in perspective, we
compare it to the results of the related problems, summarized below.
Here,  is , , , or
, and  is , , or .  (Recall that  denotes the uniform distribution.)
\begin{itemize}
\item[(1)] Checking non-interference is a -safety problem, but it is not -safety.
\item[(2)] Checking  is not a -safety problem for any .
\item[(3)] Checking  is a -safety problem.
\end{itemize}
The result (1) on non-interference is classic (see, e.g.,
\cite{mclean:sp94,barthe:csfw04,darvas:spc05}).  The results (2) and
(3) on comparison problems are proven in our recent
paper~\cite{DBLP:conf/csfw/yasuoka2010}.  Therefore, this section's
results imply that the bounding problems are harder to verify (at
least, via the self-composition approach) than non-interference and
the quantitative information flow comparison problems with universally
quantified distributions.

Let  be the set of all programs, and 
  be the set of positive real numbers.  Let  denote the
  semantics (i.e., traces) of , represented by the set of
  input/output pairs, that is, .  Then,
  formally, -safety property is defined as follows.
\begin{definition}[-safety property]
We say that a property 
is a -safety property iff  implies that there exists
 such that  and .
\end{definition}
Note that the original definition of -safety property is only
defined over
programs~\cite{terauchi:sas05,DBLP:conf/csfw/ClarksonS08}.  However,
because the bounding problems take the additional input , we extend
the notion to account for the extra parameter.

We now state the main results of this section which show that none of
the bounding problems are -safety problems for any .  Because we
are interested in hardness, we focus on the case where the
distribution is the uniform distribution.  That is, the results we
prove for the specific case applies to the general case.
\begin{theorem}
Neither , , , nor  is a k-safety property for any k such that .
\label{thm:senk2}
\end{theorem}
The result follows from the fact that for each of bounding
  problem  above, for any , there exists  such
  that deciding  is not a -safety
  property.  In fact, as we show next, for some of the problems such
  as , even if we fix  to an arbitrary constant,
  there exists no  such that the problem is -safety.  (But for
  other problems, for certain cases, we can find  that depends on
  .)  We defer the details to the next section.  (See also
  Section~\ref{sec:lowsecinputs}.)
\subsection{K-Safety Under a Constant Bound}

\label{sec:ksafetyconst}

The result above appears to suggest that the bounding problems are
equally difficult for , , , and
.  However, holding the parameter  constant (rather than having
it as an input) paints a different picture.  We show that the problems
become -safety for different definitions for different 's under
different conditions in this case.

First, for  fixed, we show that the bounding problem for the
channel-capacity based definition of quantitative information flow is
-safety for .  (Also, this bound is
tight.)
\begin{theorem}
\label{thm:cck}
Let  be a constant.  Then,  is
-safety, but it is not -safety for any .
\end{theorem}

We briefly explain the intuition behind the above result. Recall that
a problem being -safety means the existence of a {\em
  counterexample} trace set of size at most .  That is, for , we have  such that  such that any program that also contains 
as its traces also does not belong to  (with ), that
is, its channel-capacity-based quantitative information flow is
greater than .  Then, the above result follows from the fact that
the channel-capacity-based quantitative information flow coincides
with the maximum over the low security inputs of the logarithm of the
number of outputs~\cite{malacaria08}, therefore, any  containing
 traces of the same low security input and
disjoint outputs is a counterexample.

For concreteness, we show how to check  via self
composition.  Suppose we are given a program  and a positive real
.  We construct the self-composed program  shown below.

where .  In general, a self composition
involves making  copies the original program so that the resulting
program would generate  traces of the original (having the desired
property).  By the result proven by Malacaria and
Chen~\cite{malacaria08}(see also Lemma~\ref{lem:ccloglow}), it follows
that  does not cause an assertion failure iff .

Next, we show that for programs without low security inputs,  and  are also both -safety problems (but for
different 's) when  is held constant.
\begin{theorem}
\label{thm:mek}
Let  be a constant, and suppose  only takes programs
  without low security inputs.  Then,  is -safety, but it is not -safety for any .
\end{theorem}
\begin{theorem}
\label{thm:gek}
Let  be a constant, and suppose  only takes programs
without low security inputs.  If , then,  is -safety, but it is not -safety for any .  Otherwise,  and  is
-safety, but it is not -safety.
\end{theorem}

The result for  follows from the fact that for programs
without low security inputs, the min-entropy based quantitative
information flow with the uniform distribution is actually equivalent
to the channel-capacity based quantitative information
flow~\cite{smith09}.  The result for  may appear less
intuitive, but, the key observation is that, like the channel-capacity
based definition and the min-entropy based definition with the uniform
distribution (for the case without low security inputs), for any set
of traces , the information flow of a program
containing  would be at least as large as that of .  Therefore,
by holding  constant, we can always find a large enough
counterexample .  The reason  is -safety for
 is because, in the absence of low security inputs, the
minimum non-zero quantity of  is bounded (by ),
and so for such , the problem  is equivalent
to checking non-interference.\footnote{In fact, the minimum non-zero
  quantity property also exists for {\it ME}[U] without low security
  inputs and {\it CC}.  There, the minimum non-zero quantity is ,
  which agrees with the formulas given in the theorems.}

But, when low security inputs are allowed, neither  nor
 are -safety for any , even when  is held
constant.
\begin{theorem}
\label{thm:menk}
Let  be a constant.  (And let  take programs with
low security inputs.) Then,  is not a -safety
property for any .
\end{theorem}
\begin{theorem}
\label{thm:genk}
Let  be a constant.  (And let  take programs with
low security inputs.) Then,  is not a -safety
property for any .
\end{theorem}

Finally, we show that the Shannon-entropy based definition (with the
uniform distribution) is the hardest of all the definitions and show
that its bounding problem is not a -safety property for any ,
with or without low-security inputs, even when  is held constant.
\begin{theorem}
\label{thm:senk}
Let  be a constant, and suppose  only takes programs
without low security inputs. Then,  is not a -safety
property for any .
\end{theorem}

Intuitively, Theorems~\ref{thm:menk}, \ref{thm:genk}, and
\ref{thm:senk} follow from the fact that, for these definitions, given
any potential counterexample  to show , it is possible to find  containing 
whose information flow is arbitrarily close to  (and so ).  See Section~\ref{sec:lowsecinputs} for further
discussion.

Because  tends to grow large as  grows for all the definitions
and it is impossible to bound  for all , this section's results
are unlikely to lead to a practical verification of quantitative
information flow.  \footnote{But, a recent
  work~\cite{DBLP:conf/acsac/Heusser2010} shows some promising
  results.}  Nevertheless, the results reveal interesting disparities
among the different proposals for the definition of quantitative
information flow.

\subsection{K-Safety for Belief-based Definition}

\label{sec:ksafetybelief}

This section investigates the hardness of the bounding problems for
the belief-based definition of quantitative information flow.  We
define two types of bounding problems.

 checks the program's information flow against the given
quantity for a specific input pair  whereas 
checks that for all inputs.

We show that these problems are not a -safety problems for any ,
at least when  is not a constant.  To put the result in
perspective, we compare to the results of the comparison problem for
the belief-based quantitative information flow
problem~\cite{yasuoka:toplas2010submit}.
\begin{itemize}
\item[(1)] Checking  is not a -safety problem for any .
\item[(2)] Checking  is not a -safety problem for any .
\item[(3)] Checking  is a -safety problem.
\end{itemize}
Note that the problem in (3) compares the two programs for {\em all}
experiments .  This problem also turns out to
be equivalent to the comparison problems with universally quantified
distributions for {\it SE}, {\it ME}, and {\it GE} discussed in
Section~\ref{sec:ksafety}.  Hence, this section's non--safety
results show that the bounding problems  and  are harder to verify (at least, via the self-composition
approach) than non-interference and the comparison problems with
universally quantified distributions and experiments.


First, we show that  is not a -safety
property for any , even when  is held constant, and even without
low security inputs.
\begin{theorem}
\label{thm:be1nk}
Let  be a constant, and suppose  only
takes programs without low security inputs.  Then,  is not a -safety property for any .
\end{theorem}
Next, we show that  is also not a -safety property
for any  when  is a constant and , even without low
security inputs.  But, when  is held constant and ,  is a -safety property.
\begin{theorem}
\label{thm:be2nk1}
  Let  be a constant.  If , then  is not a
  -safety property for any  even when  only
  takes programs without low security inputs.  Otherwise,  and
   is a 2-safety property, but it is not a 1-safety
  property.
\end{theorem}
The -safety property for the case  follows because  turns out to be equivalent to non-interference for such
.  The results show that the bounding problems for the belief-based
definition is also quite hard, except for the case where one checks if
the information flow is less than  for all inputs, which degenerates
to checking non-interference.


\subsection{K-Safety for Channel Capacity Like Definitions}

\label{sec:ksafetycclike}

In this section, we study the hardness of the bounding problems that
check the bound for all distributions.  We define the following problems.

Note that  because .  For this reason, we call these bounding
problems ``channel capacity like.'' For instance, K{\"o}pf and
Smith~\cite{DBLP:conf/csfw/KopfS10} call 
the {\em min-entropy channel capacity}.  (Note that  iff .)  
follows the same spirit.  We define two types of channel-capacity like
problems for the belief-based definition corresponding to the two
types of bounding problems  and .

We prove -safety results for each of these problems.  The result
below for  follows directly from that of 
(i.e., Theorem~\ref{thm:cck}).  But, the other results proved are
  new.
\begin{theorem}
\label{thm:secck}
Let  be a constant.  Then,  is
-safety, but it is not -safety for any .
\end{theorem}

First, we show that  enjoys the same property as .  That is, when  is held constant, it is
-safety, but it is not -safety for any .  Note that unlike , this holds even
for programs with low security inputs.  We show this by proving the
following lemma stating that  is actually
equivalent to .
\begin{lemma}
\label{lem:mecceqcc}

\end{lemma}
The lemma extends the result by Braun et al.~\cite{Braun:09:MFPS} that
shows the equivalence for the low-security-input-free case.  By the
lemma, the -safety result for  follows directly from
that of .
\begin{theorem}\label{thm:mecck}
  Let  be a constant.  Then,  is
  -safety, but it is not -safety for any .
\end{theorem}

Next, we prove that, when  is held constant,  is
-safety for  when  and is
-safety for .  Recall that these -safety bounds
are equivalent to those of  without low security inputs
(cf.~Theorem~\ref{thm:gek}).  However, unlike , the
-safety result here holds even for programs with low security
inputs.
\begin{theorem}\label{thm:gecck}
  Let  be a constant.  If , then, 
  is -safety, but it is not -safety for any .  Otherwise,  and  is
  -safety, but it is not -safety.
\end{theorem}
\begin{sloppypar}
The above is shown by proving the following lemma which states that the
``guessing entropy channel capacity''  is
actually equivalent to .
(See below for the definition of .)
\end{sloppypar}
\begin{lemma}
\label{lem:gecc}
We have  where  denotes .
\end{lemma}

Finally, we prove somewhat surprising results for  and  stating that they are in fact
equivalent to non-interference, independent of .  It follows that
these problems are -safety but not -safety.
\begin{theorem}
\label{thm:be3ni}
 iff  is non-interferent.
\end{theorem}
Here, .  That is, the theorem states
that, for any ,  iff the
program  restricted to the low security input  is
non-interferent. (Note that checking non-interference at a fixed low
security input is also a -safety property and is not a -safety
property.)

An analogous result holds for .
\begin{theorem}
\label{thm:be4ni}
 iff  is non-interferent.
\end{theorem}
Clarkson et al.~\cite{DBLP:conf/csfw/ClarksonS08} also studies , which they call  in their paper.\footnote{Technically,
  they allow an experiment to consist of a sequence of runs of the
  program whereas we restrict an experiment to a single run.}  They
state that the problem is a {\em hypersafety} property, which is a
superset of -safety properties.\footnote{Informally, a property is
  a hypersafety if there exists a counterexample set of traces of {\em
    any} size.}



\section{Complexities for Loop-free Boolean Programs}

\label{sec:complex}

In this section, we analyze the computational complexity of the
bounding problems when the programs are restricted to loop-free
boolean programs.  We compare the complexity theoretic
hardness of the bounding problems with those of the related problems
for the same class of programs, as we have done with the -safety
property of the problems.

That is, we compare against the comparison problems of quantitative
information flow and the problem of checking non-interference for
loop-free boolean programs.  The complexity results for these problems
are summarized below.  Here,  is , , , or , and  is , , or .
\begin{itemize}
\item[(1)] Checking non-interference is coNP-complete
\item[(2)] Checking  is PP-hard.
\item[(3)] Checking  is coNP-complete.
\end{itemize}
The results (1) and (3) are proven in our recent
paper~\cite{DBLP:conf/csfw/yasuoka2010}.  The result (2) is proven in
the extended version of the paper~\cite{yasuoka:toplas2010submit} and
tightens our (oracle relative) \#P-hardness result from the conference
version~\cite{DBLP:conf/csfw/yasuoka2010}, which states that for each
 such that  is the comparison problem for , , , or , we have .  (Recall that the notation  means the
complexity class of function problems solvable in polynomial time with
an oracle for the problem .)  \#P is the class of counting problems
associated with NP.  PP is the class of decision problems solvable in
probabilistic polynomial time.  PP is known to contain both coNP and
NP, ~\cite{toda91}, and PP is believed to be strictly
larger than both coNP and NP.  (In particular, PP = coNP would imply
the collapse of the polynomial hierarchy (PH) to level 1.)


We show that, restricted to loop-free boolean programs, the bounding
problems for the Shannon-entropy-based, the min-entropy-based, and the
guessing-entropy-based definition of quantitative information flow with
the uniform distribution (i.e., , , and
) and the channel-capacity based definition (i.e., ) are all PP-hard.  (The results for the belief-based definition
and the channel-capacity-like definitions appear in
Section~\ref{sec:complexbeliefcclike}.) The results strengthen the
hypothesis that the bounding problems for these definitions are quite
hard.  Indeed, they show that they are complexity theoretically harder
than non-interference and the comparison problems with the universally
quantified distributions for loop-free boolean programs, assuming that
coNP and PP are separate.

\begin{figure}[t]

\caption{The syntax of loop-free boolean programs}
\label{fig:syntax}
\end{figure}

\begin{figure}[t]

\caption{The weakest precondition for loop-free boolean programs}
\label{fig:wpsemantics}
\end{figure}

We define the syntax of loop-free boolean programs in
Figure~\ref{fig:syntax}.  We assume the usual derived formulas , , , and .
We give the usual weakest precondition semantics in
Figure~\ref{fig:wpsemantics}.

To adapt the information flow framework to boolean programs, we make
each information flow variable , , and  range over functions
mapping boolean variables of its kind to boolean values.  For example,
if  and  are low security boolean variables and  is a high
security boolean variable, then  ranges over the functions
, and  and
 range over .\footnote{ We do not distinguish input boolean variables
  from output boolean variables.  But, a boolean variable can be made
  output-only by assigning a constant to the variable at the start of
  the program and made input-only by assigning a constant at the end.}
(Every boolean variable is either a low security boolean variable or a
high security boolean variable.)  We write  for an
input  and an output  if  for a boolean formula  such that  and  for all output .  Here,
 is the usual logical satisfaction relation, using
, etc.~to look up the values of the boolean variables.
(Note that this incurs two levels of lookup.)

As an example, consider the following program.

Let ,  be high security variables and  be low security
variables.  Then,

We now state the main results of the section, which show that the
bounding problems for , , , and
 are PP-hard.
\begin{theorem}

\label{thm:ppse}
\end{theorem}
\begin{theorem}

\label{thm:ppme}
\end{theorem}
\begin{theorem}

\label{thm:ppge}
\end{theorem}
\begin{theorem}

\label{thm:ppcc}
\end{theorem}

We remind that the above results hold (even) when the bounding
problems , , , and
 are restricted to loop-free boolean programs.  We also
note that the results hold even when the programs are restricted to
those without low security inputs.  These results are proven by a
reduction from MAJSAT, which is a PP-complete problem.  MAJSAT is the
problem of deciding, given a boolean formula  over variables
, if there are more than  satisfying
assignments to  (i.e., whether the majority of the assignments
to  are satisfying).

\subsection{Complexities for Belief and Channel Capacity Like Definitions}

\label{sec:complexbeliefcclike}

This section investigates the complexity theoretic hardness of the
bounding problems for the belief-based definition and the
channel-capacity-like definition of quantitative information flow
introduced in Section~\ref{sec:ksafetybelief} and
Section~\ref{sec:ksafetycclike}.  As in Section~\ref{sec:complex}, we
focus on loop-free boolean programs.

Below shows the complexity results for the belief-based comparison
problems for loop-free boolean
programs~\cite{yasuoka:toplas2010submit}.
\begin{itemize}
\item[(1)] Checking  is PP-hard.
\item[(2)] Checking  is PP-hard.
\item[(3)] Checking  is coNP-complete.
\end{itemize}

First, we prove that the two types of bounding problems for the
belief-based definition,  and , are both
PP-hard.
\begin{theorem}
\label{thm:ppbe1}

\end{theorem}
\begin{theorem}
\label{thm:ppbe2}

\end{theorem}
As in Section~\ref{sec:complex}, the above theorems are proven by
a reduction from MAJSAT.  They show that the bounding problems for
 are complexity theoretically difficult.

Next, we prove the hardness results for the channel-capacity like
definitions of quantitative information flow.
Theorems~\ref{thm:ppsecc} and \ref{thm:ppmecc} for  and
 follow from the equivalence 
(cf. Section~\ref{sec:ksafetycclike}) and Theorem~\ref{thm:ppcc}.
Theorem~\ref{thm:ppgecc} for  follows from
Theorem~\ref{thm:ppge} and the equivalence 
(cf. Lemma~\ref{lem:gecc}).
\begin{theorem}
\label{thm:ppsecc}
  
\end{theorem}
\begin{theorem}
\label{thm:ppmecc}
  
\end{theorem}
\begin{theorem}
\label{thm:ppgecc}
  
\end{theorem}

\begin{sloppypar}
Finally, the following coNP-completeness results for  and  follow from their equivalent to
non-interference and the fact that checking non-interference is
coNP-complete for loop-free boolean programs
(cf. Section~\ref{sec:complex}).
\end{sloppypar}
\begin{theorem}
\label{thm:conpbe3}
 is coNP-complete.
\end{theorem}

\begin{theorem}
\label{thm:conpbe4}
 is coNP-complete.
\end{theorem}

\section{Discussion}

\label{sec:discussion}

\subsection{Bounding the Domains}

The notion of -safety property, like the notion of safety property
from where it extends, is defined over all programs regardless of
their size.  (For example, non-interference is a -safety property
for all programs and unreachability is a safety property for all
programs.)  But, it is easy to show that the bounding problems would
become ``-safety'' properties if we constrained and bounded the
input domains because then the size of the semantics (i.e., the
input/output pairs) of such programs would be bounded by
.  In
this case, the problems are at most
-safety.
(And the complexity theoretic hardness degenerates to a constant.)
But, like the -safety bounds obtained by fixing  constant
(cf. Section~\ref{sec:ksafetyconst}), these bounds are high for all
but very small domains and are unlikely to lead to a practical
verification method.  Also, because a bound on the high security input
domain puts a bound on the maximum information flow, the bounding
problems become a tautology for , where  is the maximum
information flow for the respective definition.

\subsection{Low Security Inputs}

\label{sec:lowsecinputs}

Recall the results from Section~\ref{sec:ksafetyconst} that, under a
constant bound, the bounding problems for both the min-entropy based
definition and the guessing-entropy based definition with the uniform
distribution are -safety for programs without low security inputs,
but not for those with.  The reason for the non--safety results is
that the definitions of quantitative information flow  and
 (and in fact, also ) use the conditional entropy
over the low security input distribution and are parameterized by the
distribution.  This means that the quantitative information flow of a
program is averaged over the low security inputs according to the
distribution.  Therefore, by arbitrarily increasing the number of low
security inputs, given any set of traces , it becomes possible to
find a program containing  whose information flow is arbitrarily
close to  (at least under the uniform distribution).  This appears
to be a property intrinsic to any definition of quantitative
information flow defined via conditional entropy over the low security
inputs and is parameterized by the distribution of low security
inputs.  Note that the channel-capacity-like definitions do not share
this property as it is defined to be the maximum over the
distributions.  The non--safety result for  holds
even in the absence of low security inputs because the Shannon entropy
of a program is the average of the {\em
  surprisal}~\cite{clarkson:csf2005} of the individual observations,
and so by increasing the number of high security inputs, given any set
of traces , it becomes possible to find a program containing 
whose information flow is arbitrarily close to .  The
non--safety results for  and  hold for similar reasons.\footnote{They are, respectively,
  the surprisal of a particular input, and the maximum surprisal over
  all the inputs.}

\section{Related Work}

\label{sec:related}

This work continues our recent
research~\cite{DBLP:conf/csfw/yasuoka2010} on investigating the
hardness and possibilities of verifying quantitative information flow
according to the formal definitions proposed in
literature~\cite{clarkson:csf2005,denning82,clarkjcs2007,malacaria:popl2007,smith09,kopf07,DBLP:conf/sp/BackesKR09,mccamant:pldi2008,malacaria08,NMS2009,Braun:09:MFPS,DBLP:conf/csfw/KopfS10}.
Much of the previous research has focused on information theoretic
properties of the definitions and proposed approximate (i.e.,
incomplete and/or unsound) methods for checking and inferring
quantitative information flow according to such definitions.  In
contrast, this paper (along with our recent
paper~\cite{DBLP:conf/csfw/yasuoka2010}) investigates the hardness and
possibilities of precisely checking and inferring quantitative
information flow according to the definitions.

This paper has shown that the bounding problem, that is, the problem
of checking  given a program  and a positive
real , is quite hard (for various quantitative information flow
definitions ).  This is in contrast to our previous paper
that has investigated the hardness and possibilities of the comparison
problem, that is, the problem of checking  given programs  and .  To the best of our
knowledge, this paper is the first to investigate the hardness of the
bounding problems.  But, the hardness of quantitative information flow
inference, a harder problem, follows from the results of our previous
paper, and Backes et al.~\cite{DBLP:conf/sp/BackesKR09} and also
Heusser and Malacaria~\cite{DBLP:conf/ifip1-7/HeusserM09} have
proposed a precise inference method that utilizes self composition and
counting algorithms.  Also, independently from our work, Heusser and
Malacaria~\cite{DBLP:conf/acsac/Heusser2010} have recently applied the
self-composition method outlined in Section~\ref{sec:ksafetyconst} for
checking the channel-capacity-based quantitative information flow.

\section{Conclusion}

\label{sec:concl}

In this paper, we have formalized and proved the hardness of the
bounding problem of quantitative information flow, which is a form of
(precise) checking problem of quantitative information flow.  We have
shown that no bounding problem is a -safety property for any ,
and therefore that it is not possible to reduce the problem to a
safety problem via self composition, at least when the quantity to
check against is unrestricted.  The result is in contrast to
non-interference and the quantitative information flow comparison
problem with universally quantified distribution, which are -safety
properties.  We have also shown a complexity theoretic gap with these
problems, which are coNP-complete, by proving the PP-hardness of the
bounding problems, when restricted to loop-free boolean programs.

We have also shown that the bounding problems for some quantitative
information flow definitions become -safety for different 's
under certain conditions when the quantity to check against is
restricted to be a constant, highlighting interesting disparities
among the different definitions of quantitative information flow.

It is interesting to note that, as with the comparison problems, the
bounding problems become comparatively easier when the input
distribution becomes universally quantified.  That is, as our previous
work~\cite{DBLP:conf/csfw/yasuoka2010} has shown that checking if
 is
often easier than checking if  (for various quantitative information flow
definitions ), we have shown that the problem of checking
 is often easier than the
problem of checking .

\section*{Acknowledgments}
  This work was supported by MEXT KAKENHI 23700026, 22300005, and the
  Global COE Program ``CERIES.''

\bibliographystyle{abbrv}
\bibliography{boundflow}

\appendix
\section{Proofs}
\label{appendix}

We define some abbreviations.
\begin{definition}
\label{def:distabrv}
  
\end{definition}
We use the above notation whenever the correspondences between random variables
and their values are clear.

We define some useful abbreviations for programs having low security inputs.

\begin{definition}
  
\end{definition}

\begin{definition}

\end{definition}

Note that  is the program  restricted to the low security
input , and that  is the set of outputs of
.

We elide the parameter  from the input to the bounding problems when
it is clear from the context (e.g., when  is held constant).  For
example, we write  and  instead
of  or .

We note the following properties of deterministic
programs~\cite{clark05}.
\begin{lemma}
\label{lem:detse}
Let  be a program without low-security inputs,  be a program
with low-security inputs.  Then, we have

and

\end{lemma}

\begin{definition}

\end{definition}
Intuitively,  is the order of  defined in terms of
.

\begin{lemma}

\end{lemma}
\begin{proof}
Trivial.
\end{proof}

\begin{reflemma}{\ref{lem:be}}
  Let  be a belief,  be a high-security input,
   be a low-security input.  Then, .
\end{reflemma}
\begin{proof}
By definition, we have


\end{proof}

\begin{reftheorem}{\ref{thm:nonint}}
Let  be a distribution such that .  Then,
\begin{itemize}
\item  is non-interferent if and only if .
\item  is non-interferent if and only if .
\item  is non-interferent if and only if .
\item  is non-interferent if and only if .\footnote{Recall Definition~\ref{def:beliefqif} that  is a
distribution over  such that  for all .}
\item  is non-interferent if and only if .  
\end{itemize}
\end{reftheorem}
\begin{proof}
  Let .
\begin{itemize}
\item 

\hspace{0.5em}
  (See~\cite{clark05}.)
\vspace{0.5em}

\item 
\begin{itemize}
\item 

  Suppose  is non-interferent.  By the definition, it suffices to
  show that

That is,

We have for any  and  such that ,
, and 
for all , , and  such that
, for any  and
, .
 Therefore, we
have

\item 

  We prove the contraposition.  Suppose  is interferent.  That is,
  there exist , , and  such that
  .  Let  and
  .  We have

where
.
And,

where
.   
Trivially, we have  and

Therefore, we have .
\end{itemize}

\item 
\begin{itemize}
\item 

  Suppose  is non-interferent.  By the definition,

since for all , , and  such that
, for any  and
, .
\item 

  We prove the contraposition.  Suppose  is interferent.  That is,
  there exist , , and  such that
  .  Let  and
  .  By the definition,

where 

Trivially, we have  and

Therefore, we have .
\end{itemize}

\item 
\begin{itemize}
\item 

Suppose  is non-interferent.  By Lemma~\ref{lem:be}, for any
, , and ,

\item 

  We prove the contraposition. Suppose  is interferent.  That is,
  there exist , , and  such that
  .  Let  be a distribution such
  that for any , .  Then, by Lemma~\ref{lem:be}, we
  have for any ,

\end{itemize}

\item 
\begin{itemize}
\item 

  Suppose  is non-interferent.  By Lemma~\ref{lem:detse}, for any
  ,

since .  Therefore, we have .  It follows that .
\item 

  We prove the contraposition. Suppose  is interferent.  That is, there
  exist , , and  such that
  .  Let , and
  .  Then, there exist  such that 

And, we have .
\end{itemize}

\end{itemize}
\end{proof}

We note the following equivalence of {\it CC} and {\it ME}[U] for
programs without low security inputs~\cite{smith09}.
\begin{lemma}
\label{lem:ccme}
Let  be a program without low security input.  Then, 
.

\end{lemma}

\begin{reftheorem}{\ref{thm:senk2}}
Neither , , , nor  is a
k-safety property for any k such that .
\end{reftheorem}
\begin{proof}
\noindent
\begin{itemize}
\item   is not a k-safety problem for any k such that
  .

Trivial by Theorem~\ref{thm:senk}.

\item   is not a k-safety property for any k such that
  .

Trivial by Theorem~\ref{thm:mek}.

\item  is not a k-safety property for any k such that
  .

Trivial by Theorem~\ref{thm:gek}.

\item  is not a k-safety property for any k such that .

  Trivial from Lemma~\ref{lem:ccme} and the fact that 
  is not a k-safety property for any k.

\end{itemize}
\end{proof}


Malacaria and Chen~\cite{malacaria08} have proved the following result
relating the channel-capacity based quantitative information flow with
the number of outputs.  
\begin{lemma}
\label{lem:ccloglow}
Let  be a program (with low security input).  Then,

\end{lemma}

\begin{reftheorem}{\ref{thm:cck}}
  Let  be a constant.  Then,  is
  -safety, but it is not -safety for any .
\end{reftheorem}
\begin{proof}
  We prove that  is -safety.  Let
   be a program such that .  By
  Lemma~\ref{lem:ccloglow}, it must be the case that there exists
   such that .
  Then, there exists  such that , , and for
  all , .  Then, by
  Lemma~\ref{lem:ccloglow}, it follows that for any program  such
  that , .
  Therefore,  is a -safety
  property.

  Finally, we prove that  is not -safety for any .  Let . For a
  contradiction, suppose  is a -safety property.  Let
   be a program such that .  Then, there
  exists  such that  and , and
  for any  such that , .  Let .  Let
   be a program such that .  More
  formally, let  be the following program.

Then, we have

It follows that , but
.  Therefore, this leads to a
contradiction.
\end{proof}

\begin{reftheorem}{\ref{thm:mek}}
  Let  be a constant, and suppose  only takes
  programs without low security inputs.  Then,  is
  -safety, but it is not -safety for any .
\end{reftheorem}
\begin{proof}
  Straightforward by Theorem~\ref{thm:cck} and Lemma~\ref{lem:ccme}.
\end{proof}

\begin{lemma}
  Let  be a program without low security inputs.  Then, we have
  
  where  is the number of inputs, and .
\label{lem:geu}
\end{lemma}
\begin{proof}
By the definition, we have

\end{proof}

\begin{lemma}
  Let  and  be low-security input free programs such that
   and
  .  Then, we have .
\label{lem:gemono2}
\end{lemma}
\begin{proof}
  We prove .  Let , , , and .

  By Lemma~\ref{lem:geu}, we have

where 
 and .
\end{proof}

\begin{lemma}
Let .  Let  be a program without low security
inputs such that  and .  Then, it must be the case that .
\label{lem:gemax}
\end{lemma}
\begin{proof}
  Let  be the integer such that .  If  returns
  only one output, we have .  Therefore,  must
  have more than 1 output as .  By
  Lemma~\ref{lem:geu}, we have for any 

where  and
.  Because
, we have .  Then, we have

By the definition of , we have .  Let 
where .  Then, we have

Hence, we have

Because 
and , the
largest  occurs when .  That is, when  has exactly two
outputs.  Therefore, it suffices to prove the lemma for just such
's.

Now, we prove .  Recall that
.  Let
.  We have

This means that .  Recall that
 where
.  Then, we have

Because  is an integer, we have  and .  Let
.  By elementary real analysis,
it can be shown that for integers  and  such that  and
,  attains its maximum value when  or
.  Therefore, it follows that
.
\end{proof}

\begin{lemma}
  Let .  Let  be a program without low-security
  inputs such that .  Then, there exists  such
  that
\begin{itemize}
\item 
\item 
\item  where .
\end{itemize}
\label{lem:gemax3}
\end{lemma}
\begin{proof}
  Let .  Let  be a program such that .  By Lemma~\ref{lem:gemono2} and the fact that  is bounded by , there exists
   such that
\begin{itemize}
\item 
\item  where 
\item  where
  .
\end{itemize}
By Lemma~\ref{lem:gemax}, we have .  Therefore, we
have the conclusion.
\end{proof}

\begin{reftheorem}{\ref{thm:gek}}
  Let  be a constant, and suppose  only takes
  programs without low security inputs.  If , then,
   is -safety, but it is not -safety for
  any .  Otherwise,  and 
  is -safety, but it is not -safety.
\end{reftheorem}
\begin{proof}
  First, we prove that  for programs without
  low-security inputs is -safety for .  By the definition of -safety, for any  such
  that , there exists  such that
\begin{enumerate}
\item 
\item 
\item 
\end{enumerate}
We show that if , then there exists  such
that
\begin{itemize}
\item 
\item 
\item  where .
\end{itemize}
Note that  and Lemma~\ref{lem:gemono2} imply the
condition 3 above.  Suppose that .  Then, by
Lemma~\ref{lem:gemax3}, there exists  such
that , and  where .

Next, we prove  for programs without low-security inputs
is not -safety for any .  For a contradiction,
suppose  is a k-safety property.  Let  be a program
such that

where , and  are distinct,
, and .  Let
 and and
.  By Lemma~\ref{lem:geu}, we
have

Let .  If  is an integer, then we have

The last line follows from .

Otherwise, we have .  And,

Hence, we have .  Therefore, .  Then,
there exists  such that , , and
for any  such that , .  Let  be a program such that .
Then, by Lemma~\ref{lem:geu} and Lemma~\ref{lem:gemono2}, we have

It follows that .  Recall that
.  Therefore, this leads to a
contradiction.

Next, we prove that  is -safety for any
.  It suffices to show that  iff
 is non-interferent, because non-interference is a -safety
property and not a -safety
property~\cite{mclean:sp94,barthe:csfw04,darvas:spc05}.  We prove that
if  then  is non-interferent.  The other
direction follows from Theorem~\ref{thm:nonint}.  We prove the
contraposition.  Suppose  is interferent.  It must be the case that
there exist  and  such that .  Let ,
and .  Let  be a program such that
.  Note that we have
.  By Lemma~\ref{lem:gemono2}, we
have

It follows that .
\end{proof}


\begin{lemma}
\label{lem:mel}
  Let  be a program that has a low-security input, a high-security
  input, and a low-security output.  Then, we have

where , and  is sample space of the low-security
input.
\end{lemma}
\begin{proof}
By the definition of , we have

where

It follows that 

\end{proof}

\begin{reftheorem}{\ref{thm:menk}}
  Let  be a constant.  (And let  take programs with
  low security inputs.) Then,  is not a -safety
  property for any .
\end{reftheorem}
\begin{proof}
  For a contradiction, suppose  is a k-safety property.
  Let  be a program such that .  Then,
  there exists  such that , , and
  for any  such that , .  Let
  .  Let
   be the following program.

where , and  are the high security inputs and the low security
inputs of .  Then, by Lemma~\ref{lem:mel}, we have

Therefore, for any , there exists  such that
 and .
Therefore, this leads to a contradiction.
\end{proof}

\begin{lemma}
\label{lem:geu2}
Let  be a program that has a high-security input with sample space
, a low-security input with sample space , and
a low-security output.  Then, we have
 
where .
\end{lemma}
\begin{proof}
By the definition, we have

\end{proof}

\begin{reftheorem}{\ref{thm:genk}}
Let  be a constant.  (And let  take programs with
low security inputs.) Then,  is not a -safety
property for any .
\end{reftheorem}
\begin{proof}
  For a contradiction, suppose  is a k-safety property.
  Let  be a program such that .  Then,
  there exists  such that , , and
  for any  such that , .  Let
  .  Let
   be the following program.

where  and , and
 are the high security inputs and
the low security inputs of .  Then, by Lemma~\ref{lem:geu2},
we have

Therefore, for any , there exists  such that
 and .
Therefore, this leads to a contradiction.
\end{proof}

\begin{reftheorem}{\ref{thm:senk}}
  Let  be a constant and suppose  only takes
  programs without low security inputs. Then,  is not a
  -safety property for any .
\end{reftheorem}
\begin{proof}
  For a contradiction, suppose  is a k-safety property.
  Let  be a program such that .  Then,
  there exists  such that , , and
  for any  such that , .  Let .  Let 
  and  be the following programs.

where , , ,  are distinct, and , ,
, , and  are distinct.  Then, we have

Therefore, for any , there exists  such that  and .
Therefore, this leads to a contradiction.
\end{proof}

\begin{reftheorem}{\ref{thm:be1nk}}
Let  be a constant, and suppose  only
takes programs without low security inputs.  Then,  is not a -safety property for any .
\end{reftheorem}
\begin{proof}
For a contradiction, suppose  is
a -safety property.  Let  be a program such that 

where , and  and  are
distinct.  Then, we have .  That is, .  Then, it
must be the case that there is  such that ,
, and for any  such that , .
Let .  Let  be the
following program.

where 
\begin{itemize}
\item , , ,  are distinct,
\item ,
\item , and
\item .
\end{itemize}
Then, we have 

It follows that there exists  such that .  This leads to a contradiction.
\end{proof}

\begin{lemma}
\label{lem:bemono}
Let  be a trace such that  where  are distinct.  Let 
be the program such that  and  be a program such
that .  Then, we have .
\end{lemma}
\begin{proof}
  By definition, we have 

Therefore, it suffices to show that 
  Then,
where .
\end{proof}

\begin{reftheorem}{\ref{thm:be2nk1}}
  Let  be a constant.  If , then  is not a
  -safety property for any  even when  only
  takes programs without low security inputs.  Otherwise,  and
   is a 2-safety property, but it is not a 1-safety
  property.
\end{reftheorem}
\begin{proof}
First, we show for the case ,  is not a
-safety property for any .  For a contradiction, suppose
 is a -safety property.  Let  be the program such
that

where .  Then, we have .  That is, .  Then, it must be the case that there exists  such
that , , and for any  such that
, .  Note that
for any  such that ,
, and therefore, it must be
the case that such  must be equal to .

Let  be the following program.

where , , ,  are distinct.

Then, we have .  Therefore, for any ,

This leads to a contradiction.

Next, we prove that  is a 2-safety property for any
.  It suffices to show that  iff  is non-interferent, because
non-interference is a -safety property and is not a -safety
property~\cite{mclean:sp94,barthe:csfw04,darvas:spc05}.  We prove that
if  then  is
non-interferent.  The other direction follows from
Theorem~\ref{thm:nonint}.  We prove the contraposition.  Suppose 
is interferent.  It must be the case that there exist , ,
and  such that .  Let
, and .  Let  be a program such
that .  Note
that we have .  By
Lemma~\ref{lem:bemono}, we have
 
It follows that .
\end{proof}

\begin{reftheorem}{\ref{thm:secck}}
Let  be a constant.  Then,  is
-safety, but it is not -safety for any .
\end{reftheorem}
\begin{proof}
  Trivial from Theorem~\ref{thm:cck} and the fact that 
  is equivalent to .
\end{proof}

\begin{lemma}
\label{lem:mecclemma}
Let  be a distribution.  Then, for any low-security input ,
we have  where

\end{lemma}
\begin{proof}

since we have .
\end{proof}

\begin{reflemma}{\ref{lem:mecceqcc}}

\end{reflemma}
\begin{proof}
The statement was proved for programs without low security inputs by
Braun et al.~\cite{Braun:09:MFPS}.  We show that the same result holds
for programs with low security inputs.

Let  be a low-security input such that for any ,
 where .
Let  be a distribution such that
 where  is the
number of high-security inputs.  We have .  Therefore, it suffices to show that for
any , .  By definition,

Therefore, it suffices to show that

By Lemma~\ref{lem:mecclemma},

Therefore, we have .
\end{proof}

\begin{reftheorem}{\ref{thm:mecck}}
  Let  be a constant.  Then,  is
  -safety, but it is not -safety for any .
\end{reftheorem}
\begin{proof}
Trivial by Theorem~\ref{thm:cck} and Lemma~\ref{lem:mecceqcc}.
\end{proof}

We define the ``normal form'' of the guessing-entropy-based quantitative
information flow expression.
\begin{definition}[Guessing entropy QIF Normal Form]
Let  be a program without low-security input.  The guessing-entropy
based quantitative information flow  can be written
as the linear expression (over )  where , and each
 is a non-negative integer.  We call this expression  the {\em normal form} of .
\end{definition}

\begin{lemma}
\label{lem:gecc1}
Let  be a program without low-security input.  Let  be the normal form of .  Then, for any
 such that , we have 

where .
\end{lemma}
\begin{proof}
  By the definition of guessing-entropy-based quantitative information
  flow, we have 

Therefore, we have

where 
\end{proof}

\begin{lemma}
\label{lem:gecc2}
Let  be a program without low-security input.  Let  be the normal form of .  Then, for any
 such that , we have .
\end{lemma}
\begin{proof}
  By Lemma~\ref{lem:gecc1}, we have 

 where , that is, .  Therefore,
 it suffices to show that .  Then,

By elementary numerical analysis, it can be shown that for integers
 and  such that ,  attains its minimum value  when .
Therefore, we have .
\end{proof}

\begin{lemma}
\label{lem:gecc3}
Let  be a program without low-security input.  Let  be a
distribution.  Let  be such that
.
Let  be a distribution such that
, and
.  Then, we have .
\end{lemma}
\begin{proof}
Let  be the normal form of .  By the construction of ,  is the
normal form of .  Therefore,

where .  Since we have  by Lemma~\ref{lem:gecc2}, and
, we have

Therefore, we have .
\end{proof}

\begin{reflemma}{\ref{lem:gecc}}
We have  where  denotes .
\end{reflemma}
\begin{proof}

By Lemma~\ref{lem:gecc3}, we have .  Therefore, we have
.
\end{proof}


\begin{lemma}
\label{lem:geccmono}
  Let  and  be programs such that
   and
  .  Then, we have .
\end{lemma}
\begin{proof}
By Lemma~\ref{lem:gemono2}, for any , we have .  Therefore,
.
\end{proof}

\begin{reftheorem}{\ref{thm:gecck}}
  Let  be a constant.  If , then, 
  is -safety, but it is not -safety for any .  Otherwise,  and  is
  -safety, but it is not -safety.
\end{reftheorem}
\begin{proof}
By Lemma~\ref{lem:gecc},  iff .\footnote{Therefore, for
  programs without low security inputs, this theorem follows from
  Theorem~\ref{thm:gek}.  But, we show that the theorem holds also for
  programs with low security inputs.}  We prove for the case  by a ``reduction'' to the result of Theorem~\ref{thm:gek}.
The case for  follows by essentially the same
argument.

First, we show that  is -safety in this case.  By
the definition of -safety, for any  such that , there exists  such that
\begin{enumerate}
\item 
\item 
\item 
\end{enumerate}
Suppose that .  By Lemma~\ref{lem:gecc}, it
must be the case that there exists  such that .  Then, by
Lemma~\ref{lem:gemax3}, there exists 
such that , and  where
.  Let .
Then, we have  where .  Finally,
by Lemma~\ref{lem:geccmono}, we have that for any  such that
, , and so  is -safety.

To see that  is not -safety for any , recall Theorem~\ref{thm:gek} that  is not
-safety for such  (even) for low-security-input-free programs.
Therefore, the result follows by Lemma~\ref{lem:gecc}.
\end{proof}

\begin{reftheorem}{\ref{thm:be3ni}}
 iff  is non-interferent.
\end{reftheorem}
\begin{proof}
  We prove that if 
  then  is non-interferent.  The other direction follows from
  Theorem~\ref{thm:nonint}.  We prove the contraposition.  Suppose
   is interferent, that is, there exist  and  such
  that . If ,
  then let  be a distribution such that
  .  Otherwise, let
   be a distribution such that .  Then, we have

\end{proof}

\begin{reftheorem}{\ref{thm:be4ni}}
 iff  is non-interferent.
\end{reftheorem}
\begin{proof}
Straightforward from Theorem~\ref{thm:be3ni} and the fact that a program  is
non-interferent iff for all ,  is non-interferent.
\end{proof}

\paragraph*{\bf Notation}
In the proofs below, for convenience, we sometimes use large letters
, , , etc.~to range over boolean variables as well as generic
random variables.  Also, we assume that variables , , ,
etc.~are high security boolean variables and , , , ,
, , etc.~are low security boolean variables.

\paragraph*{\bf Majority SAT}
The following PP-hardness results (Theorems~\ref{thm:ppse},
\ref{thm:ppme}, \ref{thm:ppge}, \ref{thm:ppcc}, \ref{thm:ppbe1},
\ref{thm:ppbe2}, \ref{thm:ppmecc}, and \ref{thm:ppgecc}) are proven by
a reduction from MAJSAT, which is a PP-complete problem.  MAJSAT is
defined as follows.

where  is the number of variables in the boolean formula , and
 is the number of satisfying assignments of .

\begin{figure}[t]

where , , and , ,  are distinct.
\caption{The Boolean Program for Lemma~\ref{lem:semonotone} and Theorem~\ref{thm:ppse}.}
\label{fig:boolenc}
\end{figure}

\begin{lemma}
\label{lem:semonotone}
Let  and  be distinct boolean random variables.  Let 
and  be any non-negative integers such that 
and .  Let  (resp. ) be a formula
over  having  (resp. ) satisfying assignments. Then,
 iff .  where , , and  is defined in
Figure~\ref{fig:boolenc}.\footnote{The encoding  is defined so
    that MAJSAT is reduced to a bounding problem with a rational
    upper-bound  in Theorem~\ref{thm:ppse} below.  A simpler
    encoding is possible if we were to do a reduction with a
    non-rational .}
\end{lemma}
\begin{proof}
  First, we explain the construction  of
  Figure~\ref{fig:boolenc}.  Here, we use ML-like case statements
  (i.e., earlier cases have the precedence).  It is easy to see that the case
  statements can be written as nested if-then-else statements. Note
  that , , and  iff either , or  and at least
  one of  is .  For other inputs,
   returns disjoint outputs.  Therefore, the number of inputs
   such that  is , and for the rest of the  inputs,  returns
  disjoint outputs different from .

Therefore, 

where .
\begin{itemize}
\item 

  Suppose .  Let , and let 
  and  be positive real numbers such that
   and .
  We have .  Therefore,


\item 

  We prove the contraposition.  Suppose .  Let
  , and let  and  be positive real numbers such
  that  and
  .  We have .  Therefore,

\end{itemize}
\end{proof}

\begin{reftheorem}{\ref{thm:ppse}}

\end{reftheorem}
\begin{proof}
Let  be a boolean formula.  Let  be a boolean formula such
that  where  is the number of variables in
.  Let  be the number such that

where  is defined in Figure~\ref{fig:boolenc}.
Then,

by Lemma~\ref{lem:semonotone}.  Therefore, we can decide if
 by deciding if .
Note that the boolean program  and  can be
constructed in time polynomial in the size of .  Therefore, this
is a reduction from \textrm{MAJSAT} to .
\end{proof}

\begin{figure}[t]

where  and  are distinct, and  and  are
distinct.
\caption{The Boolean Program for Lemma~\ref{lem:tme}, Lemma~\ref{lem:memonotone}, and Theorem~\ref{thm:ppme}}
\label{fig:boolenc2}
\end{figure}

\begin{lemma}
\label{lem:tme}
Let  and  be distinct boolean variables.  Let  be
a boolean formula.  Then, we have  where  is defined in
Figure~\ref{fig:boolenc2}.
\end{lemma}
\begin{proof}
  It is easy to see that the number of outputs of  is equal
  to the number of satisfying assignment to  plus .
  Therefore, it follows from Lemma~\ref{lem:mel} that .
\end{proof}

\begin{lemma}
\label{lem:memonotone}
Let  and  be distinct boolean random variables.  Let 
and  be any non-negative integers such that 
and .  Let  (resp. ) be a formula
over  having  (resp. ) satisfying assignments. Then,
 iff .  where , , and  is defined in
Figure~\ref{fig:boolenc2}.
\end{lemma}
\begin{proof}
  By Lemma~\ref{lem:ccme}, Lemma~\ref{lem:ccloglow}, and
  Lemma~\ref{lem:tme}, we have

iff

iff
.
\end{proof}

\begin{reftheorem}{\ref{thm:ppme}}

 \end{reftheorem}
\begin{proof}
  Let  be a boolean formula.  Let  be a boolean formula
  such that  where  is the number of
  variables in .  Let  be the number such that

where  is defined in Figure~\ref{fig:boolenc2}.
Then, we have

by Lemma~\ref{lem:memonotone}.  Therefore, we can decide if
 by deciding if .
Note that  and  can be constructed in time polynomial in
the size of .  Therefore, this is a reduction from
\textrm{MAJSAT} to .
\end{proof}

\begin{definition}
  Let  be a function such that .  For any , we write  to mean

\end{definition}

\begin{lemma}
\label{lem:gemonotone}
Let  and  be distinct boolean random variables.  Let 
and  be non-negative integers such that  and
.  Let  (resp. ) be a formula
over  having  (resp. ) satisfying assignments. Then,
 iff .  where  and .
\end{lemma}
\begin{proof}
By the definition, 

Therefore, we have 

iff

iff .
\end{proof}

\begin{reftheorem}{\ref{thm:ppge}}

\end{reftheorem}
\begin{proof}
Let  be a boolean formula.  Let  be a boolean formula
such that   where  is the number of variables in .  Let  be the number such that

where  is a boolean variable that does not appear in  and .  
Then, we have

by Lemma~\ref{lem:gemonotone}.  Therefore, we can decide if
 by deciding if .  Note that  and  can be constructed in time
polynomial in the size of .  Therefore, this is a reduction from
\textrm{MAJSAT} to .
\end{proof}


\begin{reftheorem}{\ref{thm:ppcc}}
  
\end{reftheorem}
\begin{proof}
  Straightforward from Lemma~\ref{lem:ccme} and Theorem~\ref{thm:ppme}.
\end{proof}

\begin{figure}[t]

where  is the vector of variables appearing in 
, and , , and  are distinct.
\caption{The Boolean Program for Lemma~\ref{lem:be2mono}, Theorem~\ref{thm:ppbe1}, and Theorem~\ref{thm:ppbe2}.}
\label{fig:boolenc3}
\end{figure}

\begin{lemma}
\label{lem:be2mono}
Let , , and  be distinct boolean random variables.
Let  and  be any non-negative integers such that  and .  Let  (resp.
) be a formula over  having  (resp. )
satisfying assignments. Then,  iff , where
, , and  is defined in
Figure~\ref{fig:boolenc3}.
\footnote{As in Lemma~\ref{lem:semonotone}, the encoding is
    chosen so as to reduce MAJSAT to the bounding problem with a
    rational upper-bound.}
\end{lemma}
\begin{proof}
First, we explain the construction  of
Figure~\ref{fig:boolenc3}.  Note that  iff
either , or 
and at least one of  is .  Therefore,
there are strictly more inputs  such that  than inputs  such that .  Hence,
 where  is any input such that
.

Now, let .  Then,

Therefore,  iff .
\end{proof}

\begin{reftheorem}{\ref{thm:ppbe1}}

\end{reftheorem}
\begin{proof}
Let  be a boolean formula.  Let  be a boolean formula such that  where  is the number of variables in .  Let  be the number such that

where  is defined in Figure~\ref{fig:boolenc3},  is a high
security input such that , ,
, and .  Note that
.  Then, we have

by Lemma~\ref{lem:be2mono}, and the fact that  and
.  Therefore, we can decide if
 by deciding if .  Note that  and  can be
constructed in time polynomial in the size of  (in fact,  is
just the constant ).  Therefore, this is a reduction from
\textrm{MAJSAT} to .
\end{proof}

\begin{reftheorem}{\ref{thm:ppbe2}}

\end{reftheorem}
\begin{proof}
Let  be a boolean formula.  Let  be a boolean formula such that  where  is the number of variables in .  Let  be the number such that

where  is defined in Figure~\ref{fig:boolenc3}.  We have

by Lemma~\ref{lem:be2mono}.  Therefore, we can decide if
 by deciding if .  Note that  and  can be
constructed in time polynomial in the size of  (in fact,  is
just the constant ).  Therefore, this is a reduction from
\textrm{MAJSAT} to .
\end{proof}

\begin{reftheorem}{\ref{thm:ppsecc}}
  
\end{reftheorem}
\begin{proof}
  Trivial from Theorem~\ref{thm:ppcc} and the fact that 
  is equivalent to .
\end{proof}

\begin{reftheorem}{\ref{thm:ppmecc}}
  
\end{reftheorem}
\begin{proof}
Straightforward from Lemma~\ref{lem:mecceqcc} and Theorem~\ref{thm:ppcc}.
\end{proof}

\begin{reftheorem}{\ref{thm:ppgecc}}
  
\end{reftheorem}
\begin{proof}
Straightforward from Lemma~\ref{lem:gecc} and Theorem~\ref{thm:ppge}.
\end{proof}

We have shown in a previous work~\cite{DBLP:conf/csfw/yasuoka2010} that
checking non-interference for loop-free boolean programs is coNP-complete.
\begin{lemma}
\label{lem:niconp}
Checking non-interference is coNP-complete for loop-free boolean programs.
\end{lemma}

\begin{reftheorem}{\ref{thm:conpbe3}}
 is coNP-complete.
\end{reftheorem}
\begin{proof}
Straightforward from Lemma~\ref{lem:niconp} and Theorem~\ref{thm:be3ni}. 
\end{proof}

\begin{reftheorem}{\ref{thm:conpbe4}}
 is coNP-complete.
\end{reftheorem}
\begin{proof}
Straightforward from Lemma~\ref{lem:niconp} and Theorem~\ref{thm:be4ni}. 
\end{proof}

\end{document}
