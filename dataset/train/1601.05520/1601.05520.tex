



\newif\ifAlpha \Alphafalse




\newif \ifhyperlinks    \hyperlinkstrue




\newif \ifDraft \Draftfalse
\newif\ifFinal \Finalfalse

\documentclass[9pt\ifFinal\else,preprint,nocopyrightspace\fi,\ifAlpha\else natbib,authoryear\fi]{sigplanconf}
\ifAlpha\else\bibpunct{[}{]}{;}{a}{}{,}\fi \usepackage{amsmath,times}
\usepackage[pdftex]{graphicx}

\usepackage{amsmath,times,amsthm}
\usepackage[pdftex]{graphicx}
\usepackage{float}
\usepackage{mathpartir}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{txfonts}
\usepackage{ulem}
\usepackage{util}
\usepackage{haskell}
\usepackage{placeins}
\usepackage{xspace}
\usepackage{xfrac}
\usepackage{tikz}
\usepackage{alltt}
\usetikzlibrary{shapes.arrows,chains,positioning}
\usepackage{paralist}           \usepackage{color}

\definecolor{commentcol}{rgb}{0.3,0.3,0.3}
\definecolor{keywordcol}{rgb}{0,0,0.4}
\definecolor{typecol}{rgb}{0.4,0.1,0}
\definecolor{funccol}{rgb}{0.1,0.4,0}
\definecolor{anticol}{rgb}{0.1,0.4,0.4}
\definecolor{light-gray}{gray}{0.90}
\usepackage{listings}
\lstset{
  basicstyle=\ttfamily\footnotesize,
  keywordstyle=\color{keywordcol}\tt\bf\ttfamily,
  commentstyle=\color{commentcol}\it,
  numberstyle=\tiny\color{commentcol},
  numbers=left,
  numbersep=3pt,
  xleftmargin=7pt,
  breaklines=true,
  showstringspaces=false,
emph={[1]RR,ExSt,FsSt,U32,U16,U8,U64,VfsInode,Buf,ObjAddr,WordArray,Obj,Idx,Pair2,UArray,Opt,Node,Acc,Cnt},
  emphstyle={[1]\color{typecol}},
  emph={[2]ext2_inode_get,ext2_inode_get_buf,deserialise_Inode,osbuffer_destroy,_cdsl_debug,foo,swap,wordarray_length,foo,strangePairSwap,uarray_create,ext2_free_branch,uarray_map_no_break,ext2_free_branch_entry,ext2_free_branch_cleanup},
  emphstyle={[2]\color{funccol}},
  emph={[3]id},
  emphstyle={[3]\color{anticol}}
}
\lstdefinelanguage{CDSL}{
  basicstyle=\ttfamily\scriptsize,
  morecomment=[l]{--},
  morekeywords={type, let, in, and, if, then, else},
}

  \lstdefinestyle{isa}{
    basicstyle=\ttfamily\scriptsize,  
    columns=fullflexible,
    keepspaces,
    mathescape=true,
    morekeywords={locale,fixes,assumes,shows,and,lemma,definition,in,
      type_synonym,where,procedures,theorem,if,then,case,of,let},
    literate=
      {"}{}0
      {ÔøΩ}{}1
      {'}{}1
      {\\<^sub>6}{}1      
      {\\<^sub>3}{}1      
      {\\<^sub>2}{}1      
      {\\<^sub>1}{}1      
      {\\<^sub>0}{}1      
      {\\<^sub>f}{}1      
      {\\<forall>}{}1
      {\\<exists>}{}1
      {\\<equiv>}{}1
      {\\<Longrightarrow>}{}2
      {\\<longrightarrow>}{}2
      {\\<Rightarrow>}{}1
      {\\<rightarrow>}{}1
      {\\<longleftrightarrow>}{}2
      {\\<Down>}{}2
      {\\<guillemotleft>}{}2
      {\\<guillemotright>}{}2
      {\\<And>}{}1
      {\\<and>}{}1
      {\\<or>}{}1
      {\\<not>}{}1
      {\\<in>}{}1
      {\\<notin>}{}1
      {\\<noteq>}{}1
      {\\<le>}{}1
      {\\<ge>}{}1
      {\\<cup>}{}1
      {\\<cap>}{}1
      {\\<lambda>}{}1
      {\\<times>}{}1
      {\\<turnstile>}{}1
      {\\<turnstile-t>}{}2
      {\\<subseteq>}{}1
      {\\<lbrace>}{}1
      {\\<rbrace>}{}1
      {\\<lbrakk>}{}1
      {\\<rbrakk>}{}1
      {\\<infinity>}{}1
      {\\<sigma>}{}1
      {\\<mu>}{}1
      {\\<gamma>}{}1
      {\\<tau>}{}1
      {\\<Gamma>}{}1
       {\\<le>}{}1
      {\\<Sum>}{}1
      }

  \lstnewenvironment{isalst}{\lstset{style=isa,
    basicstyle=\footnotesize}}{}
  \newcommand{\inlineisa}[1]{\lstinline[style=isa]^#1^}

\renewcommand{\cite}[1]{\errmessage{Don't use cite, you probably want citep}}
\usepackage{verbatim}           

\usepackage{xspace}             \newcommand{\theSystem}{seL4\xspace} 

\usepackage{balance}            

\newcommand{\myFunc}{\mathrm{myFunc}}
\newcommand{\myVar}{\mathit{diff}}

\newcommand{\code}[1]{\texttt{#1}}

\ifDraft
\newcommand{\STATUS}[2]{\fbox{\textsf{\textcolor{orange}{Owner: }}{\textbf{#1}}\quad{\textsf{\textcolor{orange}{Status: }{#2}}}}}
\else
\newcommand{\STATUS}[2]{}{}
\fi

\newenvironment{DIFnomarkup}{}{}

\usepackage[pdftex]{graphicx}
\setkeys{Gin}{keepaspectratio=true,clip=true,draft=false,width=\linewidth}
\graphicspath{{./imgs/}}
\renewcommand{\ttdefault}{lmtt}	

\ifDraft
  \usepackage{draftwatermark}
  \SetWatermarkLightness{0.85}
  \newcommand{\Comment}[1]{\textbf{\textsl{#1}}}
  \newenvironment{LongComment}[1] {\begingroup\par\noindent\slshape \textbf{Begin Comment[#1]}\par}
    {\par\noindent\textbf{End Comment}\endgroup\par}
  \newcommand{\FIXME}[1]{\textbf{\textsl{\colorbox{yellow}{FIXME:} #1}}}
  \newcommand{\TODO}[1]{\textbf{\textsl{TODO: #1}}}
\else
  \newcommand{\Comment}[1]{\relax}
  \newenvironment{LongComment}[1]{\expandafter\comment}{\expandafter\endcomment}
  \newcommand{\FIXME}[1]{\relax}
  \newcommand{\TODO}[1]{\relax}
\fi

\newcommand{\gernot}[1]{\Comment{#1 [gernot]}}
\newcommand{\liam}[1]{\Comment{#1 [liam]}}
\newcommand{\toby}[1]{\Comment{#1 [toby]}}
\newcommand{\gabi}[1]{\Comment{#1 [gabi}}
\newcommand{\christine}[1]{\Comment{#1 [christine]}}
\newcommand{\gerwin}[1]{\Comment{#1 [gerwin]}}
\newcommand{\zilin}[1]{\Comment{#1 [zilin]}}
\newcommand{\yutaka}[1]{\Comment{#1 [yutaka]}}
\newcommand{\sidney}[1]{\Comment{#1 [sidney]}}

\newcommand{\ignore}[1]{}

\usepackage[pdftex]{hyperref}
\ifhyperlinks 
    \hypersetup{
      colorlinks,
      linkcolor={red},
      citecolor={blue},
      urlcolor={blue} 
    }
\else
  \hypersetup{nolinks=true}
\fi





\begin{document}

\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}
\newtheorem{theorem}{Theorem}




\floatstyle{boxed}
\restylefloat{table}
\restylefloat{figure}

\newcommand{\CDSL}{\textsc{Cogent}\xspace}
\newcommand{\cdsl}{\CDSL}
\newcommand{\DDSL}{DDSL\xspace}
\newcommand{\todo}[1]{\TODO{#1}}

\newcommand{\Cone}{\ding{172}\xspace}
\newcommand{\Ctwo}{\ding{173}\xspace}
\newcommand{\Cthree}{\ding{174}\xspace}
\newcommand{\Cfour}{\ding{175}\xspace}

\normalem

  \def\Snospace~{\S\nobreak\hspace{0.1ex}{}}
\renewcommand{\figureautorefname}{Fig.}
  \renewcommand{\sectionautorefname}{\Snospace}
  \renewcommand{\subsectionautorefname}{\Snospace}
  \renewcommand{\subsubsectionautorefname}{\Snospace}
  \renewcommand{\appendixautorefname}{Appendix}
  \renewcommand{\Hfootnoteautorefname}{Footnote}
\newcommand{\Htextbf}[1]{\textbf{\hyperpage{#1}}}

  \makeatletter
  \newsavebox{\@brx}
  \newcommand{\llangle}[1][]{\savebox{\@brx}{}\mathopen{\copy\@brx\mkern2mu\kern-0.9\wd\@brx\usebox{\@brx}}}
  \newcommand{\rrangle}[1][]{\savebox{\@brx}{}\mathclose{\copy\@brx\mkern2mu\kern-0.9\wd\@brx\usebox{\@brx}}}
  \makeatother

\title{\CDSL: Certified Compilation for a Functional Systems Language}




\authorinfo{Liam~O'Connor,
Christine~Rizkallah,
Zilin~Chen,
Sidney~Amani,
Japheth~Lim,
Yutaka~Nagashima,
Thomas~Sewell,
Alex~Hixon,
Gabriele~Keller,
Toby~Murray,
Gerwin~Klein}
  {NICTA, Sydney, Australia \\
            University of New South Wales, Australia}
  {\href{mailto:christine.rizkallah@nicta.com.au}{first.last@nicta.com.au}\ifDraft Draft of \today \pageref{p:lastpage} pages (of 12 total excl. bib). \fi}


  \maketitle


  \urlstyle{sf}
  \thispagestyle{empty}
  \begin{abstract}


    We present a self-certifying compiler for the \CDSL systems language.
    \CDSL is a restricted, polymorphic, higher-order, and purely functional
    language with linear types and without the need for a trusted runtime or
    garbage collector. It compiles to efficient C code that is designed to
    interoperate with existing C functions.
The language is suited for layered systems code with minimal sharing such
    as file systems or network protocol control code.
     
    For a well-typed \CDSL program, the compiler produces C code, a
    high-level shallow embedding of its semantics in Isabelle/HOL, and a
    proof that the C code correctly implements this embedding. The aim is
    for proof engineers to reason about the full semantics of
    real-world systems code productively and equationally,
    while retaining the interoperability and leanness of C.
    
    We describe the formal verification stages of the compiler, which include
    automated formal refinement calculi, a switch from imperative update
    semantics to functional value semantics formally justified by the linear
    type system, and a number of standard compiler phases such as type
    checking and monomorphisation. The compiler certificate is a series of
    language-level meta proofs and per-program translation validation phases,
    combined into one coherent top-level theorem in Isabelle/HOL.









  \end{abstract}

 \ifFinal
  \pagestyle{empty}
\fi

\category{F.3.2}{Logics and Meanings of Programs}{Semantics of Programming Languages}
\ifFinal
\category{D.3.2}{Programming Languages}{Language Clas\-si\-fication}[Applicative (functional) languages]
\category{D.2.4}{Software Engineering}{Software / Program Verification}[For\-mal methods]
\fi

\keywords verification, semantics, linear types
\ifFinal, domain-specific languages, file systems, Isabelle/HOL\fi

\section{Introduction}\label{s:intro}

Imagine writing low-level systems code in a purely functional language and then
reasoning about this code equationally and productively in an interactive
theorem prover. Imagine doing this without the need for a trusted compiler,
runtime or
garbage collector and letting this code interoperate with native C parts of
the system, including your own efficiently implemented and formally verified
additional data types and operations.

\CDSL achieves this goal by certified compilation from a high-level, pure,
polymorphic, functional language with linear types, specifically designed for
certain classes of systems code. For a given well-typed \CDSL program, the
compiler will produce a high-level shallow embedding of the program's
semantics in Isabelle/HOL~\citep{Nipkow_Klein:Isabelle}, and a theorem that
connects this shallow embedding to the C code that the compiler produces:~any 
property proved of the shallow embedding is guaranteed
to hold for the generated C.

The compilation target is C, because C is the language most existing 
systems code is written in, and because with the advent of tools like
CompCert~\citep{Leroy_06,Leroy_09} and gcc translation
validation~\citep{Sewell_MK_13}, C is now a language with well understood
semantics and existing formal verification infrastructure.

If C is so great, why not verify C systems code directly? After all, there is
an ever growing list of successes
\citep{Klein_EHACDEEKNSTW_09,Klein_AEMSKH_14,Gu_KRSWWZG_15,Beringer_PYA_15}
in this space. The reason is simple: verification of manually written C
programs remains expensive. Just as high-level languages increase
programmer productivity, they should also increase verification productivity.
Certifying compilation of a language with verification-friendly semantics is
a key step in achieving this goal for \CDSL.

The state of the art for certified compilation of a full featured
functional language is
CakeML~\citep{Kumar_MNO_14}, which covers an entire ML dialect. \CDSL is
targeted at a substantially different point in the design space. CakeML includes a verified runtime and garbage collector,
while \CDSL
works hard to avoid these so it can be applicable to low-level embedded
systems code. CakeML covers full turing-complete ML with complex semantics
that works well for code written in theorem provers.
\CDSL is a restricted language of total functions with intentionally simple
semantics that are easy to reason about equationally.
CakeML is great for application code; \CDSL is great for systems code,
especially layered systems code with minimal sharing such as the control
code of file systems or network protocol stacks. \CDSL is not designed for
systems code with closely-coupled, cross-cutting sharing, such as
microkernels.

\CDSL's main restrictions are the (purposeful) lack of recursion and
iteration and its linear type system. The former ensures totality,
which is important for both systems code correctness as well as for a simple
shallow representation in higher-order logic. The latter is important for
memory management and for making the transition from imperative C semantics
to functional value semantics. Even in the restricted target domains of
\CDSL, real programs will of course contain some amount of iteration. 
This is
where \CDSL's integrated foreign function interface comes in: the engineer 
provides her own verified data types and
iterator interfaces in C and uses them seamlessly in \CDSL, including in
formal reasoning.

\CDSL is restricted, but it is not a toy language. We have used it to
implement two efficient full-scale Linux file systems --- a custom Flash file system
and an implementation of standard Linux ext2. We plan to report on the experience with these implementations in
separate work. The focus of this paper is what can be learned 
from \CDSL about the formal verification of certifying compilation.

In particular, this paper discusses in detail the following contributions:
\begin{inparaenum}[a)]
\item the self-certifying \CDSL compiler and language;
\item the formal semantics of the \CDSL language and the switch from
imperative update semantics to functional value semantics formally justified
by the linear type system (\autoref{s:lang});
\item the top-level compiler certificate (\autoref{s:toplevel}), which is a series of language-level
meta proofs and per-program translation validation phases;
\item the verification stages that make up the correctness theorem (\autoref{s:verification}), including
automated refinement calculi, formally verified type checking, A-normalisation, and monomorphisation; and
\item the lessons learned in this project on functional language formalisation and
compiler correctness proofs (\autoref{s:lessons}).
\end{inparaenum}


\section{Overview}\label{s:overview}

Our aim in this paper is to build a self-certifying compiler from \cdsl to
efficient C code, such that a proof engineer can reason equationally about
its semantics in Isabelle/HOL and apply the compiler theorem to derive
properties about the generated C code. Formally, the certificate theorem is a
refinement statement between the shallow embedding and the C code. This
generated C code can be compiled by CompCert. It also falls into the subset
of the gcc translation validation tool by \citet{Sewell_MK_13}, whose theorem
would compose directly with our compiler certificate.\footnote{At the time of writing, \cdsl's occasionally larger stack frames lead to gcc emitting
\texttt{memcpy()} calls that, while conceptually straightforward to handle,
the translation validator does not yet cover.}

Shallow embeddings are nice for the human user, but they do not provide much
syntactic structure for constructing the compiler theorem.
Therefore, the compiler also generates a deep embedding for each \CDSL
program to use in the internal proof chain.
There are two semantics for this deep embedding.
\begin{inparaenum}[(1)]
\item a formal functional \emph{value semantics} where programs evaluate to values and 
\item a formal imperative \emph{update semantics} where programs manipulate references to mutable global state.
\end{inparaenum}

\floatstyle{plain} \restylefloat{figure}
\begin{figure}[tbh]
    \begin{center}
      \includegraphics[width=\columnwidth]{detailed-overview.pdf}
    \end{center}
    \caption{A detailed overview of the verification chain.}
\label{fig:refinement}
  \end{figure}
\floatstyle{boxed}
\restylefloat{figure}

\noindent 
\autoref{fig:refinement} shows an overview of the program representations
generated by the compiler and the break-down of the automatic refinement
proof that makes up the compiler certificate. The program representations
are, from the bottom of \autoref{fig:refinement}: the C code, the semantics
of the C code expressed in Isabelle/Simpl~\citep{schirmer:phd}, the same
expressed as a monadic functional
program~\citep{Greenaway_AK_12,Greenaway_LAK_14}, a monomorphic A-normal deep
embedding of the \cdsl program, a polymorphic A-normal deep embedding of the
same, an A-normal shallow embedding, and finally a `neat' shallow embedding
of the \cdsl program that is syntactically close to the \cdsl input of the
compiler. Most of the theorems assume that the \cdsl program is well-typed,
which is discharged automatically in Isabelle with type inference
information from the compiler.

The solid arrows on the right-hand side of the figure represent refinement
proofs and the labels on these arrows correspond to the numbers in the
following description. The only arrow that is not formally verified is the
one crossing from C code into Isabelle/HOL at the bottom of
\autoref{fig:refinement} --- this is the C-to-Isabelle parser~\citep{Tuch_KN_07},
which is a mature verification tool used in a number of large-scale
verifications. As mentioned, it could additionally be checked by translation
validation. We briefly describe each intermediate theorem, starting with the
Simpl code at the bottom of the figure. For well-typed \cdsl programs, we
automatically prove:

\begin{enumerate}
  \item Theorem: The Simpl code produced by the C parser corresponds to a
    monadic representation of the C code. The proof is generated using an adjusted version of the AutoCorres tool.
 \item Theorem: The monadic program terminates and is a refinement of the monomorphic \CDSL deep embedding 
    under the update semantics.
 \item Theorem: If a \CDSL deep embedding evaluates in the update
semantics then it evaluates to the same result in the value semantics.
This is a known consequence of linear type systems~\citep{Hofmann_00}, but to our knowledge
it is the first mechanised proof of such a property, esp.\ for a full-scale language.
 \item Theorem: If a monomorphic \CDSL deep embedding evaluates in the value semantics 
     then the polymorphic deep embedding evaluates equivalently in the value semantics.
 \item Theorem: If the polymorphic \CDSL deep embedding evaluates in the value semantics then 
     the \CDSL shallow embedding evaluates to a corresponding shallow Isabelle/HOL value.
 \item Theorem: The A-normal shallow embedding is (extensionally) equal in
Isabelle/HOL to a syntactically neater shallow embedding, which is more
convenient for human reasoning. This human-friendly shallow embedding
corresponds to the \CDSL code before the compiler's A-normalisation phase.
\end{enumerate}

\noindent
Arrow 7 indicates verification of user-supplied abstract data types
(ADTs) implemented in C and further manual high-level proofs on top of the
human-friendly shallow embedding. These are enabled by the previous steps,
but are not part of this paper.

In \autoref{s:verification} we define in more detail the relations that
formally link the values (and states, when applicable) that these programs
evaluate to. Steps (3) and (4) are general properties about the language and
we therefore prove them manually once and for all. Steps (1), (2), (5), and
(6) are generated by the compiler for every program. The proof for step (1)
is generated by AutoCorres. For steps (2) and (5) we define compositional
refinement calculi that ease the automation of these proofs. Step (6), the
correctness of A-normalisation, is straightforward to prove via rewriting
because at this stage we can already use equational reasoning.










\section{Language}\label{s:lang}

In this section we formally define \CDSL, including its linear type system,
its two dynamic semantics --- update and value --- mentioned earlier in
\autoref{s:overview}, and the refinement theorem between them. We begin the section by walking through an example
\CDSL programs.

\subsection{Example}

\autoref{fig:cdsl-snippet} shows an excerpt of our \CDSL ext2 implementation.
The example uses not all, but many features of the language.







\begin{figure}[th]
\begin{lstlisting}[language=CDSL]
type ExSt
type UArray a
type Opt a = <None () | Some a>
type Node = #{mbuf:Opt Buf, ptr:U32, fr:U32, to:U32}
type Acc = (ExSt, FsSt, VfsInode)
type Cnt = (UArray Node, 
  (U32, Node, Acc, U32, UArray Node) -> (Node, Acc))

uarray_create: all (a :< E). (ExSt, U32) 
  -> <Success (ExSt, UArray a) | Err ExSt>

ext2_free_branch: (U32, Node, Acc, U32) 
  -> (Node, Acc, <Expd Cnt | Iter ()>
ext2_free_branch (depth,nd,(ex,fs,inode),mdep) =
  if depth + 1 < mdep 
    then
      uarray_create[Node] (ex,nd.to-nd.fr) !nd
      | Success (ex, children) =>
        let nd_t { mbuf } = nd
        and (children, (ex, inode, _, mbuf)) = 
          uarray_map_no_break #{
            arr  = children,
            f    = ext2_free_branch_entry,
            acc  = (ex, inode, node_t.fr, mbuf),
            ... } !nd_t
        and nd = nd_t { mbuf }
        in (nd, (ex, fs, inode), 
          Expd (children, ext2_free_branch_cleanup))
      | Err ex -> (nd, (ex,fs,inode), Iter ())
    else ...
\end{lstlisting}
\caption{\CDSL example}\label{fig:cdsl-snippet}
\end{figure}


\newcommand{\cdslfunc}[1]{\texttt{\textcolor{funccol}{#1}()}\xspace}
\newcommand{\cdslvar}[1]{\texttt{#1}\xspace}
\newcommand{\cdsltype}[1]{\texttt{\textcolor{typecol}{#1}}\xspace}
\newcommand{\cdsltypenospace}[1]{\texttt{\textcolor{typecol}{#1}}}

\noindent
The first line in \autoref{fig:cdsl-snippet} shows the \cdsl side of the
foreign function interface. It declares an abstract \CDSL data
type~\cdsltype{ExSt}, implemented in C. Line 2 shows a parametric abstract
type, and line 9 shows a corresponding abstract
function~\cdslfunc{uarray\_create}, also implemented in C. Note that this
abstract function is polymorphic, with a kind constraint~ (see
\autoref{s:kinding}) on type argument \cdslvar{a}.

The integration of such foreign functions is seamless on the \CDSL side, but
naturally has requirements on the corresponding C code. The C side must
respect the \CDSL type system, and, for example, keep all shared state
internal to the abstract type to comply with linearity constraints. It must
also be terminating and implement the user-supplied semantics that appear in
the corresponding shallow embedding of the \CDSL program in Isabelle/HOL ---
ideally the user should provide a formal proof to discharge the corresponding
assumption of the compiler certificate theorem.

Abstract functions can be higher-order and provide the
iteration constructs that are intentionally left out from core \cdsl.
E.g.\ line 21, \cdslfunc{uarray\_map\_no\_break} implements a map iterator
for arrays. In our
file system applications we have found it sufficient to provide a small
library of iterators for types such as arrays. We also interfaced to an
existing mature red-black tree implementation.

Returning to the example in \autoref{fig:cdsl-snippet}, lines 3--7 show basic
type constructors and declarations of variants, records and tuples
using type variables and the primitive type \cdsltype{U32}. For instance, type
\cdsltype{Cnt} is defined as a pair of \cdsltype{UArray Node} and a function
type. Types in \cdsl are structural~\citep{Pierce_02}, i.e.\ two types with
the same structure but different names are intensionally equal.

Moreover, line 17 calls the abstract polymorphic function   
\cdslfunc{uarray\_create}, instantiated with type argument \cdsltype{Node}.
The \code{!nd} notation temporarily turns a linear object of type
\cdsltype{Node} into a read-only one (see \autoref{s:letbang}). The two
basic, non-linear fields \code{to} and \code{fr} in type \cdsltype{Node} can
directly be accessed read-only using projection functions.
Line 18 and 29 are pattern matches on the result of the function invocation.
Line 19 shows surface syntax for \CDSL's linear \textbf{take} construct (see
\autoref{sec:records}), accessing and binding the \code{mbuf} field of
\code{nd} to the name~\code{mbuf} (punning as in Haskell), as well as
binding the rest of the record to the name \code{nd\_t}.


The linear type system tracks that the field \code{mbuf} is logically absent
in \code{nd\_t}. It also tracks that \code{nd} on line 19 has been used,
so cannot be accessed again. Thus the programmer is safe to bind a new object
to the same name \code{nd} (on line 26) without worrying about name
shadowing. Line 26 shows surface syntax for , the dual to ,
which re-establishes the \code{mbuf} fields in the example.














\subsection{Types and Kinding}\label{s:kinding}

\citet{Wadler_90} first noted that linear types can be used as a way to safely
model mutable state and similar effects while maintaining a purely functional
semantics.  \citet{Hofmann_00} later proved Wadler's intuition by
showing that, for a linear language, imperative C code can implement a simple
set-theoretic semantics. We use linear types for two reasons: to ensure safe handling of heap-allocated objects, without the need for runtime 
support, and to allow us to assign to \CDSL programs a simple, equational, purely functional semantics implemented via mutable state and imperative effects.


\begin{figure}
\begin{grammar}
\text{prim. types}     & t              & \Coloneqq & \PrimType{U8} \alt \PrimType{U16} \alt \PrimType{U32} \alt \PrimType{U64} \alt \PrimType{Bool} \\
\text{types}           & \tau, \rho     & \Coloneqq & \alpha \alt \Observed{\alpha} \alt \Unit \\
                       &                & \alt      & t \alt \AbsTy{T}{\many{\tau}}{m} \alt \FunTy{\tau}{\rho} \\
                       &                & \alt      & \VariantTy{\many{\Cons{C}{\tau}}} \alt \RecordTy{\many{\FieldTy{f}{\perhaps{\tau}}}}{m} \\
\text{field types}     & \perhaps{\tau} & \Coloneqq & \tau \alt \taken{\tau}\\
\text{permissions}     & \mathcal{P}    & =         & \{ \Discardable, \Shareable, \Escapable \}\\
\text{kinds}           & \kappa         & \subseteq & \mathcal{P} \\
\text{polytypes}       & \pi            & ::=       & \PolyTy{\many{\OfKind{\alpha}{\kappa}}}{\tau}\\
\text{modes}           & m              & \Coloneqq & \ReadOnly \alt \Writable \alt \Unboxed \\
\text{type variables}  &                & \ni       & \alpha, \beta \\
\text{abs. type names} &                & \ni       & \AbsN{T}, \AbsN{U} \\
\text{kind context}    & \Delta         & \Coloneqq & \many{\ofKind{\alpha}{\kappa}} \\
\text{type context}    & \Gamma         & \Coloneqq & \many{\ofType{x}{\tau}}
\end{grammar} \
  \inferrule{\text{for each :}\ \Kinding{\Delta}{\tau_i}{\{\Discardable\}}}
            {\Weakening{\Delta}{\many{\ofType{x_i}{\tau_i}},\Gamma}{\Gamma}}
-1.3em]
\boxlabel{} &
\end{tabular}
\vspace{-0.7em}
\begin{center}
  ( indicates lists, i.e. zero or more)
\end{center}
\vspace{-0.5em}
\caption{Type Structure of \CDSL \& structural context operations}
\label{fig:typestruct}
\end{figure}

The type structure and associated syntax of \CDSL is presented in \autoref{fig:typestruct}. Our type system is loosely based on the polymorphic
 of \citet{Ahmed_FM_05}. We restrict this polymorphism to be rank-1 and predicative, in the style of ML, to permit easy implementation
by specialisation with minimal performance penalty. 

To ease implementation, and to eliminate any direct dependency on a heap allocator, we require that all functions be defined on the top-level. 
This eliminates the need for linear function types: any top-level function can be shared freely because they cannot capture \emph{any} local variables, 
let alone linear ones.

We include a set of primitive integer types (, 
etc.). Records  comprise
(1)~a sequence of fields , where  is the type on
an inaccessible field, and (2)~a mode  (see
 \mbox{\autoref{sec:records}} and \autoref{s:kindrec} for a more detailed description). We also have polymorphic variants
, a generalised sum type in the style of
OCaml, the mechanics of which are briefly described in
\autoref{s:variants}. Abstract types  are also
parametrised by modes.
We omit product types from this presentation; they are desugared into unboxed records.

The most obvious similarity to  is our use of \emph{kinds} to determine if a type may be freely shared or discarded, as 
opposed to earlier linear type systems, such as that of~\citet{Wadler_90}, where a type's linearity is encoded directly into its syntactic structure. Kinds 
in \CDSL are sets of \emph{permissions}, denoting whether a variable of that type may be discarded without being used (), shared freely and used 
multiple times (), or safely bound in a  expression (). A \emph{linear} type, values of which must be used exactly once, 
has a kind
that excludes~ and~, and so forbids it being discarded or shared.
We discuss  expressions in \autoref{sec:kindletb}. 

Another similarity to  is that we explicitly represent the context operations of weakening and contraction, normally relegated to structural rules, 
as explicit judgements:  for weakening (discarding assumptions) and  for contraction (duplicating them). 
The rules for these judgements are presented in \autoref{fig:typestruct}. For a typing assumption to be discarded (respectively duplicated),
the type must have kind  (resp. ).


\begin{figure}
\begin{inductive}{\Kinding{\Delta}{\tau}{\kappa}}
  \inferrule{ }{\Kinding{\Delta}{\Unit}{\kappa}}{\rulename{KUnit}} \quad
  \inferrule{ }{\Kinding{\Delta}{t}{\kappa}}{\rulename{KPrim}} \quad
  \inferrule{ }{\Kinding{\Delta}{\FunTy{\tau}{\rho}}{\kappa}}{\rulename{KFun}} \\
  \inferrule{(\ofKind{\alpha}{\kappa'}) \in \Delta \quad \kappa \subseteq \kappa'}
            {\Kinding{\Delta}{\alpha}{\kappa}}{\rulename{KVar}} \quad
  \inferrule{(\ofKind{\alpha}{\kappa'}) \in \Delta \quad \kappa \subseteq \BangF{\kappa'}}
            {\Kinding{\Delta}{\alpha!}{\kappa}}{\rulename{KVar}!} \\
\inferrule{ \text{for each :}\ \Kinding{\Delta}{\tau_i}{\kappa} }
            {\Kinding{\Delta}{\VariantTy{\many{\Cons{C_\mathit{i}}{\tau_i}}}}{\kappa}}{\rulename{KVariant}} \\
  \inferrule{ \ofKind{m}{\kappa'} \\ \kappa \subseteq \kappa' \\\\ \text{for each :}\ \Kinding{\Delta}{\tau_i}{\kappa} }
            {\Kinding{\Delta}{\AbsTy{T}{\many{\tau_i}}{m}}{\kappa}}{\rulename{KAbs}} \quad\!\!\!
  \inferrule{ \ofKind{m}{\kappa'} \\ \kappa \subseteq \kappa' \\\\ \text{for each  not taken:}\ \Kinding{\Delta}{\tau_i}{\kappa} }
            {\Kinding{\Delta}{\RecordTy{\many{\FieldTy{f}{\perhaps{\tau_i}}}}{m}}{\kappa}}{\rulename{KRec}} \\
\end{inductive}
\vspace{-2.5em}
\begin{inductive}{\ofKind{m}{\kappa}}
  \inferrule{}{\ofKind{\ReadOnly}{\{\Discardable, \Shareable\}}} \quad
  \inferrule{}{\ofKind{\Writable}{\{\Escapable\}}} \quad
  \inferrule{}{\ofKind{\Unboxed}{\{\Discardable, \Shareable, \Escapable\}}} 
\end{inductive}
\vspace{-1em}
  \boxlabel{}
  
  \boxlabel{}
  
  \boxlabel{}
  
\caption{Kinding rules for \CDSL types and the  operator}
\label{fig:kinding}
\end{figure}

The full kinding rules for the types of \CDSL are given in \autoref{fig:kinding}. Basic types such as  or , as well as functions,
are simply passed by value and do not contain any heap references, so they may be given any kind. Kinding for structures and abstract functions is discussed
shortly in \autoref{s:kindrec}.


A type may have multiple kinds, as a nonlinear type assumption may be used linearly, never being shared and being used exactly once. Therefore, a type with a
permissive kind, such as , would be an acceptable instantiation of a type variable of kind , as we are free to 
\emph{waive} permissions that are included in a kind. We can prove formally by straightforward rule induction:
\begin{lemma}[Waiving rights] If  and , then .
\end{lemma}
\noindent This result allows for a simple kind-checking algorithm, not immediately apparent from the rules. For example, the maximal kind of an unboxed
structure with two fields of type  and  respectively can be computed by taking the intersection of the computed maximal kinds of  and . This result ensures
that this intersection is also a valid kind for  and .

\subsubsection{Kinding for Records and Abstract Types}\label{s:kindrec}

Recall that \CDSL may be extended with \emph{abstract types}, implemented in
C, which we write as
 in our formalisation. We allow abstract types
to take any number of \emph{type parameters} , where each specific
instance corresponds to a distinct C type. For example, a  abstract type,
parameterised by its element type, would correspond to a family of C  types,
each one specialised to a particular concrete element type. Because the implementations of these
types are user supplied, the user is free to specialise implementations based on these type parameters,
for example representing an array of boolean values as a bitstring, so long as they can show 
that every different operation implementation is a refinement of the same user-supplied CDSL 
semantics for that operation.

Values of abstract types may be represented by references to heap data structures. 
Specifically, an abstract type or structure is stored on the heap when its associated
\emph{storage mode}~ is not ``\Unboxed''. For boxed records and abstract
types, the storage mode distinguishes between those that are ``\Writable'' vs.
``\ReadOnly''. The same is true for record types, written ,
which are discussed in more detail in \autoref{sec:records}.


The storage mode  affects the maximal kind that can be assigned
to the type. For example, an unboxed structure with two components of type  is freely shareable, but if the structure is
instead stored on the heap, then a writable reference to that structure must be linear. Thus, the type given to such references has the ``'' mode,
whose kind is , thereby preventing such a reference from being assigned a nonlinear kind such as .




\subsubsection{Kinding and }
\label{sec:kindletb}

Like \citet{Wadler_90}, we allow linear values to be shared read-only in a limited scope. This is useful for practical programming
in a language with linear types, as it makes our types more informative. For example, to write a function to determine the size of a (linear) buffer object, 
a naive approach would be to write a function:

This function has a cumbersome additional return value just so that the linear
argument is not discarded. Further, the type above does not express the fact that the
input buffer and output buffer are identical --- this would need to be established by additional proof.  To address this problem, we include a type operator~, in the style
of Wadler's  operator, which changes all writable modes in a type to read-only ones. The full definition of  is in \autoref{fig:kinding}.
We can therefore write the type of our function as:

For any valid type , the kind of  will be
nonlinear, which means that our  function no longer needs to be encumbered by the 
extra return value. This kinding result is formally stated as:

\begin{lemma}[Kinding for ] For any type , if  then .
\end{lemma}

\noindent To integrate this type operator with parametric polymorphism, we borrow a trick from Odersky's Observer types~\citep{Odersky_92}, and tag type variables that
have been made read only, using the syntax . Whenever a variable  is instantiated to some concrete type , we also replace 
 with . The lemma above ensures that our kinding rule for such tagged variables is sound, and enables us to prove the following:

\begin{lemma}[Type instantiation preserves kinds] For any type , 
      implies  when, for each , .
\end{lemma}

\subsection{Expressions and Typing}
\begin{figure}
\begin{grammar}
\text{primops}         & o              & \in       & \{\texttt{+}, \texttt{*}, \texttt{/}, \texttt{<=}, \texttt{==}, \texttt{||}, \texttt{{<}<}, \dots\} \\
\text{literals}        & \ell           & \in       & \{123, \mathtt{True}, \texttt{'a'}, \dots\} \\
\text{expressions}     & e              & \Coloneqq & \VarN{x} \alt \Unit \alt \TyApp{f}{\many{\tau}} \alt \GenPrimOp{o}{\many{e}} \alt \App{e_1}{e_2} \\
                       &                & \alt      & \Let{x}{e_1}{e_2} \\
                       &                & \alt      & \LetBang{\many{y}}{x}{e_1}{e_2} \\
&                & \alt      & \If{e_1}{e_2}{e_3} \\
                       &                & \alt      & \ell \alt \Cast{t}{e} \alt \Promote{\many{\Cons{C}{\tau}}}{e} \\
                       &                & \alt      & \Case{e_1}{\Cons{C}{\VarN{x}}}{e_2}{y}{e_3} \\
                       &                & \alt      & \Esac{e} \alt \Cons{C}{e} \\
                       &                & \alt      & \StructInit{\many{\FieldEq{f}{e}}} \alt \Member{e}{f} \alt \Put{e_1}{f}{e_2} \\
                       &                & \alt      & \Take{x}{f}{y}{e_1}{e_2} \\
\text{function def.}   & d              & \Coloneqq & \FunDef{f}{\pi}{x}{e} \alt \AbsFunDef{f}{\pi} \\
\text{programs}        & P              & \Coloneqq & \many{d}\\
\text{function names}  &                & \ni       & \FunN{f}, \FunN{g} \\
\text{variables}       &                & \ni       & \VarN{x}, \VarN{y} \\
\text{constructors}    &                & \ni       & \ConsN{A},\ConsN{B},\ConsN{C} \\
\text{record fields}   &                & \ni       & \FieldN{f}, \FieldN{g} \\
\end{grammar}

\caption{Syntax of \CDSL programs (after desugaring)}
\label{fig:syntax}
\end{figure}
\noindent 
While \CDSL features a rich surface syntax, due to space constraints, we only document the (full) core language in \autoref{fig:syntax} to which the surface syntax is desugared.

\begin{figure*}
  \begin{inductive}{\Typing{\Delta}{\Gamma}{e}{\tau}}
    \inferrule{\Weakening{\Delta}{\Gamma}{\ofType{x}{\tau}}}{\Typing{\Delta}{\Gamma}{x}{\tau}}{\rulename{Var}} \quad
    \inferrule{ }{\Typing{\Delta}{\Gamma}{\Unit}{\Unit}}{\rulename{Unit}} \quad
    \inferrule{ \ell < |t|}{\Typing{\Delta}{\Gamma}{\ell}{t}}{\rulename{Literal}} \quad
    \inferrule{ \TypingS{\Delta}{\Gamma}{\many{e_i}}{\many{t_i}} \\\\
               \PrimOpType{o} = (\many{t_i}, t) }
              {\Typing{\Delta}{\Gamma}{\GenPrimOp{o}{\many{e_i}}}{t}}{\rulename{PrimOp}}\quad
    \inferrule{ \Typing{\Delta}{\Gamma}{e}{t'} \\ |t'| \le |t| }{\Typing{\Delta}{\Gamma}{\Cast{t}{e}}{t}}{\rulename{Cast}} \\
    \inferrule{\Contraction{\Delta}{\Gamma}{\Gamma_1}{\Gamma_2} \\\\
               \Typing{\Delta}{\Gamma_1}{e_1}{\rho \rightarrow \tau} \\
               \Typing{\Delta}{\Gamma_2}{e_2}{\rho} }
              {\Typing{\Delta}{\Gamma}{\App{e_1}{e_2}}{\tau}}{\rulename{App}} \quad\!\!
    \inferrule{\FunTyEnv{f}{\PolyTy{\many{\OfKind{\alpha_i}{\kappa_i}}}{\tau \rightarrow \tau'}}\\\\
               \text{for each :}\ \Kinding{\Delta}{\rho_i}{\kappa_i}}
              {\Typing{\Delta}{\Gamma}{\TyApp{f}{\many{\rho_i}}}{\Subst{(\tau \rightarrow \tau')}{\many{\alpha_i}}{\many{\rho_i}}}}{\rulename{Fun}} \quad\!\!
    \inferrule{\Contraction{\Delta}{\Gamma}{\Gamma_1}{\Gamma_2} \\
               \Typing{\Delta}{\Gamma_1}{e_1}{\VariantTy{\Cons{A}{\rho} \alt \many{\Cons{C_i}{\tau_i}}}} \\\\
               \Typing{\Delta}{\ofType{x}{\rho}, \Gamma_2}{e_2}{\tau} \\
               \Typing{\Delta}{\ofType{y}{\VariantTy{\many{\Cons{C_i}{\tau_i}}}}, \Gamma_2}{e_3}{\tau}}
              {\Typing{\Delta}{\Gamma}{\Case{e_1}{\Cons{A}{\VarN{x}}}{e_2}{y}{e_3}}{\tau}}{\rulename{Case}}    
\\
  \end{inductive}
  \begin{center}
    \begin{tabular}{p{0.625\textwidth}|p{0.25\textwidth}}
      \begin{inductive0}
    \begin{tabular}{c}
    \inferrule{\Typing{\Delta}{\Gamma}{e}{\tau}}
              {\Typing{\Delta}{\Gamma}{\Cons{C}{e}}{\VariantTy{\Cons{C}{\tau}}}}{\rulename{Cons}} \quad\!\!\!
    \inferrule{\Typing{\Delta}{\Gamma}{e}{\VariantTy{\many{\Cons{B}{\rho}}}} \\
               \many{\Cons{B}{\rho}} \subseteq \many{\Cons{C}{\tau}}}
              {\Typing{\Delta}{\Gamma}{\Promote{\many{\Cons{C}{\tau}}}{e}}{\VariantTy{\many{\Cons{C}{\tau}}}}}{\rulename{Prom}} \quad\!\!\!
    \inferrule{\Typing{\Delta}{\Gamma}{e}{\VariantTy{\Cons{C}{\tau}}}}
              {\Typing{\Delta}{\Gamma}{\Esac{e}}{\tau}}
              {\rulename{Esac}} \quad\!\!\!
\\\\
        \inferrule{\Contraction{\Delta}{\Gamma}{\Gamma_1}{\Gamma_2} \\\\
                   \Typing{\Delta}{\Gamma_1}{e_1}{\rho} \\
                   \Typing{\Delta}{\ofType{x}{\rho}, \Gamma_2}{e_2}{\tau}}
                  {\Typing{\Delta}{\Gamma}{\Let{x}{e_1}{e_2}}{\tau}}{\rulename{Let}} \quad
        \inferrule{\Contraction{\Delta}{\Gamma}{\Gamma_1}{\Gamma_2} \\
                   \Kinding{\Delta}{\rho}{\{\Escapable\}}\\\\
                   \Typing{\Delta}{\many{\ofType{v_i}{\BangF{\tau_i}}}, \Gamma_1}{e_1}{\rho} \\\\
                   \Typing{\Delta}{\many{\ofType{v_i}{\tau_i}}, \ofType{x}{\rho},\Gamma_2}{e_2}{\tau}}
                  {\Typing{\Delta}{\many{\ofType{v_i}{\tau_i}}, \Gamma}{\LetBang{\many{v_i}}{x}{e_1}{e_2}}{\tau}}{\rulename{Let}!} \\
\end{tabular}
      \end{inductive0}
      &\vspace{-2ex}
      \begin{inductive}{\TypingS{\Delta}{\Gamma}{\many{e}}{\many{\tau}}}
        \inferrule{\Weakening{\Delta}{\Gamma}{\emptyset} }
                  {\TypingS{\Delta}{\Gamma}{\varepsilon}{\varepsilon}}{\rulename{L}_\varepsilon} \\
        \inferrule{\Contraction{\Delta}{\Gamma}{\Gamma_1}{\Gamma_2} \\\\
                   \Typing{\Delta}{\Gamma_1}{e}{\tau} \\
                   \TypingS{\Delta}{\Gamma_2}{\many{e_i}}{\many{\tau_i}}}
                  {\TypingS{\Delta}{\Gamma}{e\ \many{e_i}}{ \tau\ \many{\tau_i} }}{\rulename{L}_C}
      \end{inductive}
    \end{tabular}
  \end{center}\vspace{1.5ex}
  \begin{inductive0}
    \inferrule{\Contraction{\Delta}{\Gamma}{\Gamma_1}{\Gamma_2} \\
               m \neq \ReadOnly \\\\
               \Typing{\Delta}{\Gamma_1}{e_1}{\RecordTy{\many{\FieldTy{g}{\perhaps{\tau_i}}}, \FieldTy{f}{\rho} ,\many{\FieldTy{g}{\perhaps{\tau_j}}}}{m}} \\\\
               \Typing{\Delta}{\ofType{x}{\RecordTy{\many{\FieldTy{g}{\perhaps{\tau_i}}}, \FieldTy{f}{\taken{\rho}} ,\many{\FieldTy{g}{\perhaps{\tau_j}}}}{m}}, \ofType{y}{\rho}, \Gamma_2}{e_2}{\tau}}
              {\Typing{\Delta}{\Gamma}{\Take{x}{f}{y}{e_1}{e_2}}{\tau}}{\rulename{Take}_1} \quad
    \inferrule{\Contraction{\Delta}{\Gamma}{\Gamma_1}{\Gamma_2} \\
               \Kinding{\Delta}{\rho}{\{\Shareable\}} \\\\
               m \neq \ReadOnly \\ \perhaps{\tau_k} = \rho \\
               \Typing{\Delta}{\Gamma_1}{e_1}{\RecordTy{\many{\FieldTy{f}{\perhaps{\tau_i}}}}{m}} \\\\
               \Typing{\Delta}{\ofType{x}{\RecordTy{\many{\FieldTy{f}{\perhaps{\tau_i}}}}{m}}, \ofType{y}{\rho}, \Gamma_2}{e_2}{\tau}}
              {\Typing{\Delta}{\Gamma}{\Take{x}{f}{y}{e_1}{e_2}}{\tau}}
              {\rulename{Take}_2} \\
    \inferrule{\Contraction{\Delta}{\Gamma}{\Gamma_1}{\Gamma_2} \\
               m \neq \ReadOnly \\\\
               \Typing{\Delta}{\Gamma_1}{e_1}{\RecordTy{\many{\FieldTy{g}{\perhaps{\tau}_i}}, \FieldTy{f}{\taken{\rho}} ,\many{\FieldTy{g}{\perhaps{\tau}_j}}}{m}} \\
               \Typing{\Delta}{\Gamma_2}{e_2}{\rho}}
              {\Typing{\Delta}{\Gamma}{\Put{e_1}{f}{e_2}}{\RecordTy{\many{\FieldTy{g}{\perhaps{\tau}_i}}, \FieldTy{f}{\rho} ,\many{\FieldTy{g}{\perhaps{\tau}_j}}}{m}}}{\rulename{Put}_1} \quad
    \inferrule{\Contraction{\Delta}{\Gamma}{\Gamma_1}{\Gamma_2} \\
               m \neq \ReadOnly \\ \perhaps{\tau}_k = \rho\\\\
               \Typing{\Delta}{\Gamma_1}{e_1}{\RecordTy{\many{\FieldTy{f}{\perhaps{\tau}_i}}}{m}} \\
               \Kinding{\Delta}{\rho}{\{\Discardable\}} \\
               \Typing{\Delta}{\Gamma_2}{e_2}{\rho}}
              {\Typing{\Delta}{\Gamma}{\Put{e_1}{f}{e_2}}{\RecordTy{\many{\FieldTy{f}{\perhaps{\tau}_i}}}{m}}}{\rulename{Put}_2} \\
    \inferrule{\Kinding{\Delta}{\RecordTy{\many{\FieldTy{g}{\perhaps{\rho}_i}}, \FieldTy{f}{\tau} ,\many{\FieldTy{g}{\perhaps{\rho}_j}}}{m}}{\{\Shareable\}} \\\\
              \Typing{\Delta}{\Gamma_1}{e_1}{\RecordTy{\many{\FieldTy{g}{\perhaps{\rho}_i}}, \FieldTy{f}{\tau} ,\many{\FieldTy{g}{\perhaps{\rho}_j}}}{m}}}
              {\Typing{\Delta}{\Gamma}{\Member{e}{f}}{\tau}}{\rulename{Member}} \quad
    \inferrule{\TypingS{\Delta}{\Gamma}{\many{e_i}}{\many{\tau_i}}}
              {\Typing{\Delta}{\Gamma}{\StructInit{\many{\FieldEq{f}{e_i}}}}{\RecordTy{\many{\FieldTy{f}{\tau_i}}}{\Unboxed}}}
              {\rulename{Struct}}
  \end{inductive0}
  \caption{Typing rules for \CDSL}
  \label{fig:typing}
\end{figure*}

\autoref{fig:typing} shows the typing rules for \CDSL expressions.
Many of these are standard for any linear type system. We will
discuss here the rules for , where we have taken a slightly different approach to established literature, and the rules for the 
extensions we have made to the type system, such as variants and record types.

\subsubsection{Typing for }\label{s:letbang}

On the expression level, the programmer can use  expressions, in the style of \citet{Wadler_90}, to temporarily convert variables of linear types to their
read-only equivalents, allowing them to be freely shared. In this example, we wish to copy a buffer  onto a buffer  only when  will fit inside
. 
 
Note that even though  and  are used multiple times, they are only used once in a linear context. Inside the  binding, they have been made
temporarily nonlinear. Our kind system ensures these read-only, shareable references inside  bindings cannot ``escape'' into
the outside context. For example, the expression  would violate the invariants of the linear type system, and ruin the purely
functional abstraction that linear types allow, as both  and  would refer to the same object, and a destructive update to  would change the shareable . 

We are able to use the existing kind system to handle these safety checks with
the inclusion of the  permission, for
scapable, which indicates that the type may be safely returned
from within a . We ensure, via the typing rules of
\autoref{fig:typing}, that the left hand side of the binding ( in the example) has the
 permission, which excludes temporarily nonlinear references via
 (see \autoref{fig:kinding}). Our solution is as powerful as
Odersky's, but we encode the restrictions in the kind system directly, not as 
side-condition constraints that recursively descend into the structure of
the binding's type.




\subsubsection{Typing for Variants}\label{s:variants}
A variant type  is a generalised sum type, where each alternative is distinguished by a unique \emph{data constructor}~. The order in which the constructors appear in the type is not important.
One can create a variant type with a single alternative simply by invoking a constructor, e.g.  might be given the type
. The original value of  can be retrieved using the  construct. The set of alternatives is enlarged 
by using  expressions that are automatically inserted by the type-checker of the surface language, which uses subtyping to infer the type of a given
variant. A similar trick is used for numeric literals and . 

In order to pattern match on a variant, we provide a  construct that attempts to match against one constructor. If the constructor does not match, 
it is \emph{removed} from the type and the reduced type is provided to the  branch. In this way, a traditional multi-way pattern match can be desugared
by nesting:

Note that because the typing rule for  only applies when only one alternative remains, our pattern matching is necessarily total.

\subsubsection{Typing for Records}
\label{sec:records}




Some care is needed to reconcile record types and linear types.
Assume that  is a type synonym for an (unboxed) record type containing an integer and two (linear) buffers.

Let us say we want to extract the field  from an . If we extract just a single , we have implicitly discarded the other buffer .
But, we can't return the entire  along with the , as this would introduce aliasing. Our solution is to return along with the 
 an  where the field  cannot be extracted again, and reflect this in the field's type, written as . 
This field extractor, whose general form is , operates as follows: given a record~, it binds the field  of  
to the variable
, and the new record to the variable  in . Unless the type of the field  has kind , that field will be marked as unavailable, or \emph{taken}, in the type of the new record .

Conversely, we also introduce a  operation, which, given a record with a taken field, allows a new value to be supplied in its place. The expression  returns the
record in  where the field  has been replaced with the result of . Unless the type of the field  has kind , that field must already be taken, to avoid
accidentally destroying our only reference to a linear resource.

Unboxed records can be created using a simple struct literal _i. We also allow records to be stored on the heap to minimise unnecessary copying,
as unboxed records are passed by value.  These boxed records are created by invoking an externally-defined C allocator function.
For these allocation functions, it is often convenient to allocate a record with all fields already taken, to indicate that they are uninitialised. Thus a function for allocating
\texttt{Object}-like records might return values of type: .

For any nonlinear record (that is, (1)~read-only boxed records, which cannot have linear fields, as well as~(2)~unboxed records without linear fields)
 we also allow traditional member syntax  for field access. The typing rules for all of these expressions are given in \autoref{fig:typing}. 

\subsubsection{Type Specialisation} 
\label{sec:typing:poly}
As mentioned earlier, we implement parametric polymorphism by specialising code to avoid paying the performance penalties of other approaches such as
boxing. This means that polymorphism in our language is restricted to predicative rank-1 quantifiers.

This allows us to specify dynamic objects, such as our value typing relations (see \autoref{sec:updvalrel}) and our dynamic semantics (see \autoref{sec:dynsem}), in
terms of simple monomorphic types, without type variables. Thus, in order to evaluate a polymorphic program, each type variable must first be instantiated
to a monomorphic type. We show that typing of the instantiated program follows from the typing of the polymorphic program, if the type instantiation used matches
the kinds of the type variables.

\begin{lemma}[Type specialisation]
\label{lemma:spec} 

      implies  when, for each , .
\end{lemma}
\noindent The above lemma is sufficient to show the monomorphic instantiation case, by setting  (the empty context). This lemma is a
key ingredient for the refinement link between polymorphic and monomorphic deep embeddings (See \autoref{s:mono-correctness}).

\subsection{Dynamic Semantics}
\label{sec:dynsem}
\begin{figure}
  \boxlabel{Value Semantics}
  \begin{grammar}
    \text{values} & v & \Coloneqq & \ell \alt \Unit \\ 
                  &   & \alt      & \FunVal{x}{e}                     & \text{(function values)} \\
                  &   & \alt      & \AbsFunVal{f}{\many{\tau}}        & \text{(abstract functions)} \\
                  &   & \alt      & \Cons{C}{v}                       & \text{(variant values)} \\
&   & \alt      & \RecordVal{\many{\FieldEq{f}{v}}} & \text{(records)} \\
                  &   & \alt      & a_v                               & \text{(abstract values)} \\
    \text{environments} & V & \Coloneqq & \many{\EnvBind{x}{v}} \\
    \text{abstract values} & a_v 
  \end{grammar}
  
  \boxlabel{Update Semantics}
  \begin{grammar}
    \text{u. sem. values} & u & \Coloneqq & \ell \alt \Unit \\ 
                            &   & \alt      & \FunVal{x}{e}                     & \text{(function values)} \\
                            &   & \alt      & \AbsFunVal{f}{\many{\tau}}        & \text{(abstract functions)} \\
                            &   & \alt      & \Cons{C}{u}                       & \text{(variant values)} \\
&   & \alt      & \RecordVal{\many{\FieldEq{f}{u}}} & \text{(records)} \\
                            &   & \alt      & a_u                               & \text{(abstract values)} \\
                            &   & \alt      & p                                 & \text{(pointers)} \\
    \text{environments}     & U & \Coloneqq & \many{\EnvBind{x}{u}}\\
    \text{pointers}         & p & & \multicolumn{2}{l}{\ \hspace{5ex} } \\
    \text{abstract values}  & a_u & & 
    \multicolumn{2}{l}{\text{stores}\ \hspace{13ex} \ensuremath{\mu : p \nrightarrow u}}\\
  \end{grammar}
  
  \caption{Definitions for Value and Update Semantics}
  \label{fig:semdef}
\end{figure}
\autoref{fig:updvalsem} defines the big-step evaluation rules for the 
\emph{value} semantics of \CDSL. The relation
\mbox{} states that under
environment , the expression  evaluates to a resultant value
. These values are documented in \autoref{fig:semdef}. In many
ways, the semantics is entirely typical of a purely functional
language, albeit with some care to handle abstract function calls
appropriately. This is intentional, since our goal is to automatically
produce a purely functional shallow embedding from this semantics.

As functions must be defined on the top level, our function values
 consist only of an unevaluated expression, which is
evaluated when the function is applied. Abstract function values,
written , are instead passed more
indirectly, as a pair of the function name and a list of the types
used to instantiate any type variables.  When an abstract function
value  is applied, the user-supplied
semantics  are invoked, which is simply a function from
input value to output value.

The \emph{update} semantics, by contrast, is much more imperative. The
semantic rules can also be found in \autoref{fig:updvalsem}, with associated
definitions in
\autoref{fig:semdef}. This semantics is also an evaluation
semantics, written  in the style 
of~\citet{Pierce_02}. Values in the update semantics may now be 
\emph{pointers}, written , to values in a mutable store or \emph{heap} .  
This mutable store is modelled as a partial function from a pointer to 
an update semantics value. 


Most of the rules in \autoref{fig:updvalsem} only differ from the value
semantics in that they thread the store~ through the
evaluation of the program. However, the key differences arise in the
treatment of records and of abstract types, which may now be
represented as \emph{boxed} structures, stored on the heap. In
particular, note that the rule  destructively
updates the heap, instead of creating a new record value, and the
semantics of abstract functions  may also modify the
heap.

\renewcommand{\rulename}[1]{\textsc{\scriptsize #1}}
\begin{figure*}[t]
\small
  \begin{inductive}{\ValSem{V}{e}{v}}
    \inferrule{(\EnvBind{x}{v}) \in V}{\ValSem{V}{x}{v}}{\rulename{VVar}} \quad\!
    \inferrule{ }{\ValSem{V}{\Unit}{\Unit}}{\rulename{V()}} \quad\!
    \inferrule{\FunDefn{f} = \FunDef{f}{\PolyTy{\many{\OfKind{\alpha_i}{\kappa_i}}}{\FunTy{\tau}{\rho}}}{x}{e}}
              {\ValSem{V}{\TyApp{f}{\many{\tau_i}}}{\FunVal{x}{\Subst{e}{\many{\alpha_i}}{\many{\tau_i}}}}}
              {\rulename{VFun}_C}\quad\!
    \inferrule{\FunDefn{f} = \AbsFunDef{f}{\PolyTy{\many{\OfKind{\alpha_i}{\kappa_i}}}{\FunTy{\tau}{\rho}}}}
              {\ValSem{V}{\TyApp{f}{\many{\tau_i}}}{\AbsFunVal{f}{\many{\tau_i}}}}
              {\rulename{VFun}_A}\\
    \inferrule{ }{\ValSem{V}{\ell}{\ell}}{\rulename{VLit}} \quad\!\!\!\!
    \inferrule{ \ValSem{V}{e}{\ell}}{\ValSem{V}{\Cast{t}{e}}{\ell}}{\rulename{VCast}} \quad\!\!\!\!
    \inferrule{\ValSem{V}{e_1}{\FunVal{x}{e}} \\\\ \ValSem{V}{e_2}{v'} \quad\!\! \ValSem{(\EnvBind{x}{v'})}{e}{v}}
              {\ValSem{V}{\App{e_1}{e_2}}{v}}
              {\rulename{VApp}_C}\quad\!\!\!\!\!
    \inferrule{\ValSem{V}{e_1}{\AbsFunVal{f}{\many{\tau}}} \\\\ \ValSem{V}{e_2}{v'} \quad\!\! \AbsValSem{f}{v'}{v}}
              {\ValSem{V}{\App{e_1}{e_2}}{v} }{\rulename{VApp}_A} \quad\!\!\!\!\!
\inferrule{\text{for each :}\ \ValSem{V}{e_i}{\ell_i}}{\ValSem{V}{\GenPrimOp{o}{\many{e_i}}}{\GenPrimOp{o}{\many{\ell_i}}}}{\rulename{VPrimOp}}\\
    \inferrule{\ValSem{V}{e_1}{v'} \\\\ \ValSem{\EnvBind{x}{v'},V}{e_2}{v}}{\ValSem{V}{\Let{x}{e_1}{e_2}}{v}}{\rulename{VLet}}\quad
    \inferrule{\ValSem{V}{e_1}{v'} \\\\ \ValSem{\EnvBind{x}{v'},V}{e_2}{v}}{\ValSem{V}{\LetBang{\many{y}}{x}{e_1}{e_2}}{v}}{\rulename{VLet}!}\quad
\inferrule{\ValSem{V}{e}{v}}{\ValSem{V}{\Cons{C}{e}}{\Cons{C}{v}}}{\rulename{VCons}} \quad
    \inferrule{\ValSem{V}{e}{\Cons{C_k}{v}}}{\ValSem{V}{\Promote{\many{\Cons{C_i}{\tau_i}}}{e}}{\Cons{C_k}{v}}}\rulename{VProm}\\
    \inferrule{\ValSem{V}{e_1}{\Cons{C}{v'}} \\ \ValSem{\EnvBind{x}{v'}, V}{e_2}{v}}{\ValSem{V}{\Case{e_1}{\Cons{C}{\VarN{x}}}{e_2}{y}{e_3}}{v}}{\rulename{VCase}_1} \quad
    \inferrule{\ValSem{V}{e_1}{\Cons{B}{v'}} \\ \ConsN{B} \neq \ConsN{C} \\ \ValSem{\EnvBind{x}{(\Cons{B}{v'})}, V}{e_3}{v}}
              {\ValSem{V}{\Case{e_1}{\Cons{C}{\VarN{x}}}{e_2}{y}{e_3}}{v}}{\rulename{VCase}_2} \quad
    \inferrule{\ValSem{V}{e}{\Cons{C}{v}}}{\ValSem{V}{\Esac{e}}{v}}{\rulename{VEsac}} \\
    \inferrule{\text{for each :}\ \ValSem{V}{e_i}{v_i}}
              {\ValSem{V}{\StructInit{\many{\FieldEq{f}{e_i}}}}{\RecordVal{\many{\FieldEq{f}{v_i}}}}}
              {\rulename{VStr}} \quad\!\!\!
    \inferrule{\ValSem{V}{e}{\RecordVal{\many{\FieldEq{f}{v_i}}}}}
              {\ValSem{V}{\Member{e}{f}}{v_k}}
              {\rulename{VMem}} \quad\!\!\!
    \inferrule{\ValSem{V}{e_1}{\RecordVal{\many{\FieldEq{f}{v_i}}}} 
              \\\\ \ValSem{\EnvBind{x}{\RecordVal{\many{\FieldEq{f}{v_i}}}}, \EnvBind{y}{v_k}, V}{e_2}{v} }
              {\ValSem{V}{\Take{x}{f}{y}{e_1}{e_2}}{v}}{\rulename{VTake}}\quad\!\!\!
    \inferrule{\ValSem{V}{e_1}{\RecordVal{\many{\FieldEq{f}{v_i}}}} 
              \quad \ValSem{V}{e_2}{v'_k}
              \\\\ \text{for each :}\ v'_i = v_i}
              {\ValSem{V}{\Put{e_1}{f}{e_2}}{\RecordVal{\many{\FieldEq{f}{v'_i}}}}}{\rulename{VPut}}
  \end{inductive}
\vspace{0.5ex}
\begin{inductive}{\UpdSem{U}{e}{\mu}{u}{\mu'}}
\inferrule{\FunDefn{f} = \FunDef{f}{\PolyTy{\many{\OfKind{\alpha_i}{\kappa_i}}}{\FunTy{\tau}{\rho}}}{x}{e}}
              {\UpdSem{U}{\TyApp{f}{\many{\tau_i}}}{\mu}{\FunVal{x}{\Subst{e}{\many{\alpha_i}}{\many{\tau_i}}}}{\mu}}
              {\rulename{UFun}_C}\quad\!
    \inferrule{\FunDefn{f} = \AbsFunDef{f}{\PolyTy{\many{\OfKind{\alpha_i}{\kappa_i}}}{\FunTy{\tau}{\rho}}}}
              {\UpdSem{U}{\TyApp{f}{\many{\tau_i}}}{\mu}{\AbsFunVal{f}{\many{\tau_i}}}{\mu}}
              {\rulename{UFun}_A} \quad\!
    \inferrule{\UpdSem{U}{e_1}{\mu}{u'}{\mu_1} \\\\ \UpdSem{\EnvBind{x}{u'},U}{\mu_1}{e_2}{u}{\mu_2}}{\UpdSem{U}{\Let{x}{e_1}{e_2}}{\mu}{u}{\mu_2}}{\rulename{ULet}}\\
\inferrule{\UpdSem{U}{e_1}{\mu}{\FunVal{x}{e}}{\mu_1} \\\\ \UpdSem{U}{e_2}{\mu_1}{u'}{\mu_2} \quad\!\! \UpdSem{(\EnvBind{x}{u'})}{e}{\mu_2}{u}{\mu_3}}
              {\UpdSem{U}{\App{e_1}{e_2}}{\mu}{u}{\mu_3}}
              {\rulename{UApp}_C}\quad\!
    \inferrule{\UpdSem{U}{e_1}{\mu}{\AbsFunVal{f}{\many{\tau_i}}}{\mu_1} \\\\ \UpdSem{U}{e_2}{\mu_1}{u'}{\mu_2} \quad\!\! \AbsUpdSem{f}{u'}{\mu_2}{u}{\mu_3}}
              {\UpdSem{U}{\App{e_1}{e_2}}{\mu}{u}{\mu_3} }{\rulename{UApp}_A} \quad\!
    \inferrule{\UpdSem{U}{e_1}{\mu}{u'}{\mu_1} \\\\ \UpdSem{\EnvBind{x}{u'},U}{\mu_1}{e_2}{u}{\mu_2}}{\UpdSem{U}{\LetBang{\many{y}}{x}{e_1}{e_2}}{\mu}{u}{\mu_2}}{\rulename{ULet!}}\\ 
\inferrule{\UpdSem{U}{e}{\mu}{\Cons{C_k}{u}}{\mu'}}{\UpdSem{U}{\Promote{\many{\Cons{C_i}{\tau_i}}}{e}}{\mu}{\Cons{C_k}{u}}{\mu'}}\rulename{UProm}\quad\!\!
    \inferrule{\UpdSem{U}{e}{\mu}{\Cons{C}{u}}{\mu'}}{\UpdSem{U}{\Esac{e}}{\mu}{u}{\mu'}}{\rulename{UEsac}} \quad\!\!
    \inferrule{\UpdSemA{U}{\many{e_i}}{\mu}{\many{u_i}}{\mu'}}
              {\UpdSem{U}{\StructInit{\many{\FieldEq{f}{e_i}}}}{\mu}{\RecordVal{\many{\FieldEq{f}{u_i}}}}{\mu'}}
              {\rulename{UStr}} \quad\!\!\!
    \inferrule{\UpdSem{U}{e}{\mu}{\RecordVal{\many{\FieldEq{f}{u_i}}}}{\mu'}}
              {\UpdSem{U}{\Member{e}{f}}{\mu}{u_k}{\mu'}}
              {\rulename{UMem}_1} 
              \\
    \inferrule{\UpdSem{U}{e_1}{\mu}{\Cons{C}{u'}}{\mu_1} \\\\ \UpdSem{\EnvBind{x}{u'}, U}{\mu_1}{e_2}{u}{\mu_2}}
              {\UpdSem{U}{\Case{e_1}{\Cons{C}{\VarN{x}}}{e_2}{y}{e_3}}{\mu}{u}{\mu_2}}{\rulename{UCase}_1} \quad\!\!\!
    \inferrule{\UpdSem{U}{e_1}{\mu}{\Cons{B}{u'}}{\mu_1} \\ \ConsN{B} \neq \ConsN{C} \\\\ \UpdSem{\EnvBind{x}{(\Cons{B}{u'})}, U}{e_3}{\mu_1}{u}{\mu_2}}
              {\UpdSem{U}{\Case{e_1}{\Cons{C}{\VarN{x}}}{e_2}{y}{e_3}}{\mu}{u}{\mu_2}}{\rulename{UCase}_2} \quad\!\!\!
    \inferrule{\UpdSem{U}{e}{\mu}{p}{\mu'} \\\\ \mu'(p) = {\RecordVal{\many{\FieldEq{f}{u_i}}}}}
              {\UpdSem{U}{\Member{e}{f}}{\mu}{u_k}{\mu'}}
              {\rulename{UMem}_2}
    \end{inductive}
    \begin{center}
\begin{inductive0}
    \inferrule{(\EnvBind{x}{u}) \in U}{\UpdSem{U}{x}{\mu}{u}{\mu}}{\rulename{UVar}} \quad\!
          \inferrule{\UpdSem{U}{e_1}{\mu}{\RecordVal{\many{\FieldEq{f}{u_i}}}}{\mu_1} 
                \\\\ \UpdSem{\EnvBind{x}{\RecordVal{\many{\FieldEq{f}{u_i}}}}, \EnvBind{y}{u_k}, U}{e_2}{\mu_1}{u}{\mu_2} }
                    {\UpdSem{U}{\Take{x}{f}{y}{e_1}{e_2}}{\mu}{u}{\mu_2}}{\rulename{UTake}_1}\quad\!\!\!
          \inferrule{\UpdSem{U}{e_1}{\mu}{\RecordVal{\many{\FieldEq{f}{u_i}}}}{\mu_1} 
                \\\\ \UpdSem{U}{e_2}{\mu_1}{u'_k}{\mu_2}
                \quad \text{for each :}\ u'_i = u_i}
                    {\UpdSem{U}{\Put{e_1}{f}{e_2}}{\mu}{\RecordVal{\many{\FieldEq{f}{u'_i}}}}{\mu_2}}{\rulename{UPut}_1} \0.4em]
    \inferrule{ \VTR{u}{\mu}{v}{\tau}{r}{w}
            \\  \VTRA{\many{u_i}}{\mu}{\many{v_i}}{\many{\perhaps{\tau_i}}}{r'}{w'}
            \\\\ \HiBlue{w \cap (r' \cup w') = \emptyset} \\
               \HiBlue{w' \cap (r \cup w) = \emptyset}}
              {\VTRA{u\ \many{u_i}}{\mu}{v\ \many{v_i}}{\tau\ \many{\perhaps{\tau_i}}}{r \cup r'}{w \cup w'}}{\rulename{RL}_2} \(\mu^\prime, \sigma^\prime) \in \srel \ \wedge 
    \UpdSem{U}{e}{\mu}{u}{\mu^\prime}\wedge \
    \ValSem{V}{e}{\monoval \ \rename \ v} \wedge \
       \mathcal{V} \  r \ \mu^\prime \ v_m\ u\ v \ s 
\begin{array}{l}
    \forall \mu\ \sigma.\ \mathcal{V} \ \rename \ \mu  \ v_m\ u\ v \ s \  \longrightarrow \\
   \quad\quad\correspond \ \rename \ \srel
     \  (s \; v_s) \ (\monoexpr \ \rename \ e) \ (p_m v_m)\ 
       U\  V\  \Gamma \ \mu \ \sigma
\end{array}

\begin{array}{l}
\corres \;R\; e\; p_m\;U\; \Gamma\; \mu\; \sigma = \\
\quad (\exists r \; w.\; U\ |\ \mu : \Gamma\ [\textbf{ro:}\ r\ \textbf{rw:}\ w])\longrightarrow \\
\quad \;\;     (\mu,\sigma) \in R \longrightarrow \\
\quad\quad   \;(\neg\ \failed \ (p_m \ \sigma)\; \wedge \\
\quad\quad   \;(\forall v_m \;\sigma^\prime. \ (v_m,\sigma^\prime) \in \results\ (p_m\;\sigma) \longrightarrow \\
\quad\quad\quad    (\exists \mu^\prime \ u. \ \UpdSem{U}{e}{\mu}{u}{\mu^\prime} \wedge 
      (\mu^\prime,\sigma^\prime) \in R \wedge \valrel\ u\ v_m)))
\end{array}

\begin{array}{l}
\forall \mu\ \sigma. \;\valrel\ u \ v_m \longrightarrow \corres\ \srel\ e\ (p_m\ v_m)\ (x \mapsto u)\ (x : \tau)\ \mu \ \sigma
\end{array}

\begin{array}{l}
\forall v'.\  \ValSem{(x \mapsto \monoval \ \rename \ v)}{\monoexpr\  \rename \ e}{\monoval\ \rename\ v'}
\longrightarrow \ValSem{(x \mapsto v)}{e}{v'}
\end{array}
\scorres\ s\ e\ V\ \equiv\ \forall r.\ \ValSem{V}{e}{r} \longrightarrow \valRel\ s\ r\forall v_s\ v.\ \valRel\ v_s\ v \longrightarrow \scorres\ (s\ v_s)\ e\ (x \mapsto v)\mathrm{Shallow.}\extfb = \mathrm{Neat.}\extfb
The proof is simple as well. Since we can now use equational reasoning with
Isabelle's powerful rewriter, we just unfold both sides, apply extensionality
and the proof is automatic given the right congruence rules and equality
theorems for functions lower in the call graph. This proof stage was the
easiest and fastest of the stages to construct; it took about 1 person day.

This is a strong indication that this representation of the program is well
suited for further reasoning on top.

\section{Discussion and Lessons Learned}\label{s:lessons}


\paragraph{Language Restrictions: Totality}
The current version of \CDSL purposefully omits primitive constructs for
iteration and recursion, because we wanted to ensure that the language was
total for a neat shallow embedding in HOL (which is total). However, since
our language meta-level proofs do not require totality, we only require that
\emph{each program} is terminating. We are therefore contemplating to relax
this restriction and allow \CDSL iterator constructs where termination is
obvious enough for Isabelle to prove automatically.

\paragraph{Formal Language Semantics}
The \CDSL semantics in Isabelle departs slightly from that presented in
\autoref{s:lang}. In particular, we enriched the update semantics to carry
enough value type information to infer their corresponding C types, and
adjusted the typing rules accordingly. While not needed for any of the
proofs of \autoref{s:lang}, this information is used in the automatic
C-correspondence proof.
In addition, we found ourselves repeating parts of the (linear) type
preservation proof in rule inductions on the semantics that make use of
typing assumptions. This means, while type erasure is an important
property for languages to enjoy (and \emph{is} enjoyed by \CDSL), dynamic
semantics with type information are helpful for mechanised
reasoning. Ideally, there should be an erased and a typed dynamic
semantics, with type safety implying their equivalence.



\paragraph{Optimisation}

The current \CDSL compiler performs little optimisation when generating C
code and leaves low-level optimisation to gcc or CompCert. Clever
optimisations in the \cdsl-to-C stage would complicate our current
syntax-directed correspondence approach. \CDSL-to-\CDSL optimisations,
however, are different. The ease by which we prove the correctness of the
A-normalisation over the shallow embedding via rewriting, suggests fruitful
ground for optimisation. We leave exploring this idea for future work.






































































\newcommand{\totalEffort}{ person-years\xspace}

\newcommand{\compilerEffort}{ person-months\xspace}

\newcommand{\certcompEffort}{ person-months\xspace}

\newcommand{\langproofEffort}{ person-months\xspace}




































\newcommand{\isabelleLOC}{ lines of code (including comments and whitespace)\xspace}

\newcommand{\compilerSLOC}{ source lines of code (excluding comments and whitespace)\xspace}

\newcommand{\exttwoloc}{6,454\xspace}
\newcommand{\extproof}{76,759\xspace}

\paragraph{Effort and Size} \CDSL has been
under development for over 2 years and has continually evolved
as we have scaled the language to ever larger applications.
All up, the combined language development
and certifying compiler took \totalEffort. Engineering the
\CDSL compiler, excluding \certcompEffort spent on
proof automation and proof framework development,
consumed \compilerEffort. The remaining \langproofEffort was for the
design, formalisation and proof of \CDSL and its properties (e.g. the
theorems of \autoref{s:lang}), a small amount of which was also spent on
early compiler development.
The total size of the development in
the Isabelle theorem prover is \isabelleLOC, which includes the
once-and-for-all language proofs plus automated proof tactics to perform
the translation validation steps, given appropriate hints from the \CDSL
compiler. The \CDSL compiler, written in Haskell, is \compilerSLOC.
For \exttwoloc lines of etx2 \cdsl code we generate \extproof lines of Isabelle/HOL proofs
and embeddings.



\section{Related Work}\label{s:related}

Like us, the High-Assurance Systems Programming~\citet{Habit:lang} pro\-ject 
seeks to improve systems software by combining formal 
methods and programming language research. Like \CDSL, 
HASP's systems
language, Habit, is a domain specific functional language. 
\citet{McCreight_CT_10} show the correctness of a garbage collector in this project; however, to the best 
of our knowledge, there exist no full formal language semantics yet. 

Ivory~\citep{Pike_HBEDL_14} is a domain specific language embedded in Haskell
also for implementing correct systems software. It generates well-defined,
memory safe C code; however, unlike \CDSL it does not \emph{prove} correctness
of the generated code.

Linear types have been used in several general purpose imperative languages
to ensure memory safety without depending on a runtime, such as in Vault~\citep{Fahndrich_DeLine_02} and \citet{Rust:lang}.
PacLang \citep{Ennals_SM_04} is an imperative domain-specific language which uses linear
types to guide optimisation of packet processing applications on network
processors. Similar substructural type systems, namely uniqueness types, have been
integrated into functional programming languages such as
Clean~\citep{Barendsen_Smeters_93}. However, the type system there is only
used as a way to provide a purely functional abstraction over effects, 
and thus Clean still depends on a run-time garbage collector.



To the best of our knowledge, \citet{Hofmann_00} is the only work which proves the equivalence of the functional and imperative interpretation of a language with a linear type
system. The proof is by pen and paper, from a first order functional language with linear types to its translation in C. \CDSL in comparison is higher order and its compiler
produces a machine checked proof linking a purely functional shallow embedding
to its C implementation.



Examples for verified compilers for high-level languages are
CakeML~\citep{Kumar_MNO_14}, discussed in more detail in \autoref{s:intro}, which compiles a full ML dialect, including verified runtime and garbage
collection. In contrast, \citep{Neis_HKMDV_15} focuses on a compositional approach to
compiler verification for a relatively simple functional language, Pilsner,
to an idealised assembly language.

\citet{Chargueraud_10, Chargueraud_11} also generate a shallow
embedding representation of a program to facilitate proofs about
properties via a proof assistant, as we do. However, they do not address the
verification of the code generated by the compiler.

\section{Conclusions}\label{s:concl}

We have presented the \cdsl language, its self-certifying compiler, their
formal definitions and top-level compiler certificate theorem,
and the correctness theorems for each compiler stage. The
language targets systems code where data sharing is minimal or can be abstracted,
performance and small memory footprint are requirements, and formal
verification is the aim.

\cdsl is a pure, total functional language to enable productive equational
reasoning in an interactive theorem prover. It is higher-order and
polymorphic to increase conciseness. It uses linear types to make memory
management bugs compile time errors, and to enable efficient destructive
in-place update. It avoids garbage collection and a trusted runtime to reduce
footprint. It supports a formally modelled foreign-function interface to
interoperate with C code and to implement additional data types, iterators
and operations.

It does all of these with full formal proof of compilation correctness
and type-safety in Isabelle/HOL.

\CDSL sets a new benchmark for trustworthy systems languages, and
demonstrates, through the careful application of language design
with verified compilation in mind, that writing systems code that
supports purely functional equational reasoning is possible.




\balance
{
  \Finalfalse

  \ifAlpha
    \bibliographystyle{alpha}
  \else
    \bibliographystyle{plainnat}
  \fi
  \ifFinal
    \errmessage{Replace this by the content of your .bbl file!}
  \else
    \bibliography{references}
  \fi
}
\end{document}
