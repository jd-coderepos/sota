\documentclass{llncs}

\usepackage{etex}
\reserveinserts{28}


\usepackage[american]{babel}
\usepackage [autostyle]{csquotes}
\MakeOuterQuote{"}


\usepackage{amssymb, amsmath}
\usepackage{graphicx}

\let\proof\relax  \let\endproof\relax
\usepackage{amsthm}

\usepackage{mathtools,array}
\usepackage{amsfonts}
\usepackage{amssymb,bm,bbm}




\PassOptionsToPackage{hyphens}{url}
\usepackage[linktocpage,
            colorlinks=true,linkcolor=black,
            citecolor=black,urlcolor=black,
            pdfpagemode=UseNone,
            bookmarks=true,
            breaklinks,
            bookmarksopen=false,
            hyperfootnotes=false,
            pdfhighlight=/I,
            pdftitle={On the diameter of hyperbolic random graphs},
pdfauthor={Friedrich, Krohmer}]{hyperref}
            
\sloppy

\let\theorem\relax  \let\lemma\relax
\let\definition\relax
\let\corollary\relax

\usepackage{thmtools, thm-restate}
\declaretheorem[name=Theorem]{theorem}
\declaretheorem[sibling=theorem,name=Lemma]{lemma}
\declaretheorem[sibling=theorem,name=Definition]{definition}
\declaretheorem[sibling=theorem,name=Corollary]{corollary}


\usepackage{xspace}
\usepackage{etex}  \usepackage{url}
\usepackage{tikz}
\usetikzlibrary{decorations.pathmorphing} 
\usetikzlibrary{decorations.pathreplacing,calc}
\usetikzlibrary{graphs}
\usetikzlibrary{arrows}
\usepackage{subfig}
 \usepackage{floatrow}


\usepackage{float}
\floatstyle{ruled}
\newfloat{myalgorithm}{thp}{lop}
\floatname{myalgorithm}{Algorithm}

\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{algorithm,booktabs}
\usepackage[noend]{algpseudocode}


\usepackage[numbers,longnamesfirst,sort&compress,sectionbib]{natbib}
\bibliographystyle{myabbrvnat}
\newcommand{\arxiv}[1]{\href{http://arxiv.org/abs/#1}{\emph{arXiv}, #1}}


 \usepackage[labelfont=bf,font=footnotesize,indention=0.3cm,margin=0cm]{caption}  




\usepackage{setspace,color}   \setlength{\marginparwidth}{1.5cm}
\newcounter{nummer}
\newcommand{\NOTE}[2]{\addtocounter{nummer}{1}{\bf\textcolor{red}{}}\marginpar{\begin{flushleft}\setstretch{0.43}\bf\tiny\textcolor{blue}{\arabic{nummer} #1:} \textcolor{red}{#2}\end{flushleft}}}

\newcommand{\Rd}{\ensuremath{\mathbb{R}^d}}
\newcommand{\Rdp}{\mathbb{R}_{\ge 0}^d}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Rp}{\mathbb{R}_{\ge 0}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Oh}{\mathcal{O}}
\newcommand{\fun}[1]{\textsc{#1}}
\newcommand{\Set}{\mathcal{S}}
\newcommand{\Vol}[1]{\textsc{vol}(#1)}
\newcommand{\ov}[1]{\overline{#1}}
\newcommand{\cG}{\mathcal{G}}
\newcommand{\ER}{\mathcal{ER}}
\newcommand{\CL}{\mathcal{CL}}
\newcommand{\GRG}{\mathrm{GRG}}
\newcommand{\CM}{\mathrm{CM}}
\newcommand{\bw}{\ensuremath{\mathbf{w}}}
\newcommand{\dif}{\,\mathrm{d}}
\newcommand{\dist}{\mathrm{d}}

\newcommand{\IGNORE}[1]{}

\newcommand{\ol}[1]{\overline{#1}}
\newcommand{\ul}[1]{\underline{#1}}

\newcommand{\sortEvent}{\textsc{SortedSubsetSampling}}
\newcommand{\unsortEvent}{\textsc{UnsortedSubsetSampling}}
\newcommand{\sortDist}{\textsc{SortedProportionalSampling}}
\newcommand{\unsortDist}{\textsc{UnsortedProportionalSampling}}

\def\argmax{\operatornamewithlimits{argmax}}
\def\argmin{\operatornamewithlimits{argmin}}
\def\Geo{\operatorname{Geo}}
\def\Ber{\operatorname{Ber}}
\def\Bin{\operatorname{Bin}}
\def\bBer{\operatorname{\mathbf{Ber}}}
\def\Uni{\operatorname{Uni}}
\def\poly{\operatorname{poly}}
\def\ddiv{\operatorname{div}}
\def\mod{\operatorname{mod}}
\def\min{\operatorname{min}}
\def\max{\operatorname{max}}
\def\deg{\operatorname{deg}}
\def\diam{\operatorname{diam}}
\def\Ex{\mathbb{E}}
\def\Pr{\operatorname{Pr}}
\def\Var{\operatorname{Var}}
\def\ind{\operatorname{ind}}
\def\sig{\operatorname{sig}}
\def\polylog{\operatorname{polylog}}
\def\ss{\operatorname{ss}}

\renewcommand{\algref}[1]{Algorithm~\ref{alg:#1}}
\newcommand{\algrefs}[2]{Algorithms~\ref{alg:#1} and~\ref{alg:#2}}
\newcommand{\figref}[1]{Figure~\ref{fig:#1}}
\newcommand{\figrefs}[2]{Figure~\ref{fig:#1} and~\ref{fig:#2}}
\newcommand{\tabref}[1]{Table~\ref{tab:#1}}
\newcommand{\defref}[1]{Definition~\ref{def:#1}}
\newcommand{\thmref}[1]{Theorem~\ref{thm:#1}}
\newcommand{\thmrefs}[2]{Theorems~\ref{thm:#1} and~\ref{thm:#2}}
\newcommand{\thmrefss}[3]{Theorems~\ref{thm:#1}, \ref{thm:#2} and~\ref{thm:#3}}
\newcommand{\thmrefsss}[4]{Theorems~\ref{thm:#1}, \ref{thm:#2}, \ref{thm:#3} and~\ref{thm:#4}}
\newcommand{\lemref}[1]{Lemma~\ref{lem:#1}}
\newcommand{\lemrefs}[2]{Lemmas~\ref{lem:#1} and~\ref{lem:#2}}
\newcommand{\corref}[1]{Corollary~\ref{cor:#1}}
\newcommand{\secref}[1]{Section~\ref{sec:#1}}
\newcommand{\appref}[1]{Appendix~\ref{app:#1}}
\newcommand{\secrefs}[2]{Sections~\ref{sec:#1} and~\ref{sec:#2}}
\newcommand{\secrefss}[3]{Sections~\ref{sec:#1}, \ref{sec:#2} and~\ref{sec:#3}}
\newcommand{\eq}[1]{equation~\eqref{eq:#1}}
\newcommand{\ineq}[1]{inequality~\eqref{eq:#1}}
\newcommand{\eqpl}[1]{equations~\eqref{eq:#1}}
\newcommand{\eqs}[2]{equations~\eqref{eq:#1} and~\eqref{eq:#2}}
\newcommand{\eqss}[3]{equations~\eqref{eq:#1},~\eqref{eq:#2}, and~\eqref{eq:#3}}
\newcommand{\Eqs}[2]{Equations~\eqref{eq:#1} and~\eqref{eq:#2}}


\renewcommand{\epsilon}{\ensuremath{\varepsilon}}
\newcommand{\eps}{\ensuremath{\varepsilon}}
\newcommand{\iid}{i.i.d.}

\renewcommand{\labelitemi}{\textbullet}

\newcommand{\epsapproximation}{\nobreakdash-approximation\xspace}

\newcommand{\temporary}[1]{}


\let\oldsqrt\sqrt
\def\hksqrt{\mathpalette\DHLhksqrt}
\def\DHLhksqrt#1#2{\setbox0=\hbox{}\dimen0=\ht0
   \advance\dimen0-0.2\ht0
   \setbox2=\hbox{\vrule height\ht0 depth -\dimen0}{\box0\lower0.4pt\box2}}
\renewcommand{\sqrt}{\hksqrt}
\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}
\renewcommand{\le}{\leqslant}
\renewcommand{\ge}{\geqslant}
\renewcommand{\bar}{\overline}

\catcode`@=11
\def\nphantom{\v@true\h@true\nph@nt}
\def\nvphantom{\v@true\h@false\nph@nt}
\def\nhphantom{\v@false\h@true\nph@nt}
\def\nph@nt{\ifmmode\def\next{\mathpalette\nmathph@nt}\else\let\next\nmakeph@nt\fi\next}
\def\nmakeph@nt#1{\setbox\z@\hbox{#1}\nfinph@nt}
\def\nmathph@nt#1#2{\setbox\z@\hbox{}\nfinph@nt}
\def\nfinph@nt{\setbox\tw@\null
  \ifv@ \ht\tw@\ht\z@ \dp\tw@\dp\z@\fi
  \ifh@ \wd\tw@-\wd\z@\fi \box\tw@}
\newcount\minute \newcount\hour \newcount\hourMins
\def\now{\minute=\time \hour=\time \divide \hour by 60 \hourMins=\hour \multiply\hourMins by 60
  \advance\minute by -\hourMins \zeroPadTwo{\the\hour}:\zeroPadTwo{\the\minute}}
\def\timestamp{\today\ \now}
\def\today{\the\year-\zeroPadTwo{\the\month}-\zeroPadTwo{\the\day}}
\def\zeroPadTwo#1{\ifnum #1<10 0\fi #1}


\sloppy
 
\begin{document}

\frontmatter

\title{On the diameter of hyperbolic random graphs}


\author{Tobias Friedrich \and Anton Krohmer}





\institute{
    \small
    \begin{tabular}{c}
         Hasso Plattner Institute, Potsdam, Germany
    \end{tabular}
}


\maketitle

\pagestyle{headings}
\pagenumbering{arabic}

\begin{abstract}
Large real-world networks are typically scale-free.
Recent research has shown that such graphs are described best in a geometric space.
More precisely, the internet can be mapped to a hyperbolic space such that geometric greedy
routing performs close to optimal (\citeauthor{boguna2010sustaining}. Nature Communications, 1:62, 2010).
This observation pushed the interest in hyperbolic networks as
a natural model for scale-free networks.
Hyperbolic random graphs follow a power-law degree distribution
with controllable exponent~
and show high clustering
(\citeauthor{gugelmann2012random}. ICALP, pp.\ 573--585, 2012).

\medskip
\qquad
For understanding the structure of the resulting graphs and for analyzing the behavior of network algorithms,
the next question is bounding the size of the diameter.
The only known explicit bound is

(\citeauthor{KiwiMitsche15}. ANALCO, pp.\ 26--39, 2015).
We present two much simpler proofs for an improved upper bound of 
and a lower bound of .
\end{abstract}


\section{Introduction}

Large real-world networks are almost always sparse and non-regular. Their degree distribution
typically follows a \emph{power law}, which is synonymously used for being \emph{scale-free}.
Since the 1960's, large networks have been studied in detail and hundreds of models
were suggested. In the past few years, a new line of research emerged, which showed
that scale-free networks can be modeled more realistically when incorporating \emph{geometry}.

\textbf{Euclidean random graphs.}
It is not new to study graphs in a geometric space.
In fact, graphs with \emph{Euclidean geometry} have been studied intensively for more than a decade.
The standard Euclidean model are random geometric graphs which result
from placing ~nodes independently and uniformly at random on an Euclidean
space, and creating edges between pairs of nodes 
if and only if their distance is at most some fixed threshold~.
These graphs have been studied in relation to subjects
such as cluster analysis, statistical physics, hypothesis testing,
and wireless sensor networks~\cite{penrose2003random}.
The resulting graphs are more or less regular and hence
do not show a scale-free behavior with power-law degree distribution
as observed in large real-world graphs.

\begin{table}[t]
\newcommand{\tikzmark}[1]{\tikz[overlay,remember picture] \node (#1) {};}
\begin{tabular}{@{\ }lc}
\toprule
\textbf{Random Graph Model}  & \textbf{Diameter} \\ \midrule
Sparse Erd\H{o}s-R\'{e}nyi 
\cite{bollobas1998random} 
& ~\cite{riordan2010diameter}  \\
-dim.\ Euclidean
\cite{penrose2003random}
& ~\cite{diamEucRGG} \\
Watts-Strogatz
\cite{WattsStrogatz98} 
& ~\cite{BollobasC88}  \\
Kleinberg
\cite{Kleinberg00}
 & ~\cite{MartelN04}  \\
\midrule
Chung-Lu
\cite{chung2002average} 
&  ~\cite{chung2002average} \tikzmark{topbrace} \\
Pref. Attachment
\cite{barabasi1999emergence}
& ~\cite{diamPA}  \\
Hyperbolic
\cite{krioukov2010hyperbolic}
 & ~\cite{KiwiMitsche15} \tikzmark{bottombrace}\tikzmark{right} 
\\
\bottomrule
\end{tabular}
\hspace*{2cm}
\begin{tikzpicture}[overlay, remember picture]
  \draw [decoration={brace,amplitude=0.5em},decorate,thick,black]
    let \p1=(topbrace), \p2=(bottombrace) in
    ({max(\x1,\x2)}, {\y1+0.8em}) -- node[right=0.6em] {power-law graphs} ({max(\x1,\x2)}, {\y2});
\end{tikzpicture}
\caption[test]{
Known diameter bounds for various random graphs.
In all cases the diameter depends on the choice of the model parameters.
Here we consider a constant average degree.
For scale-free networks, we also assume a power law exponent .\footnotemark
\vspace{-2em}
}
\label{tab:diameters}
\end{table}

\textbf{Hyperbolic random graphs.}
For modeling scale-free graphs, it is natural to apply a non-Euclidean geometry with negative curvature.
\citet{krioukov2010hyperbolic} introduced a new graph model based on \emph{hyperbolic geometry}. Similar to euclidean random graphs,
nodes are uniformly distributed in a hyperbolic space and two nodes are connected
if their hyperbolic distance is small. 
The resulting graphs have many properties observed in large real-world networks.
This was impressively demonstrated by \citet{boguna2010sustaining}:
They computed a maximum likelihood fit of the internet graph in the hyperbolic space
and showed that greedy routing in this hyperbolic space finds nearly optimal shortest paths in the internet graph.
The quality of this embedding is an indication that hyperbolic geometry naturally appears in large scale-free graphs.

\textbf{Known properties.}
\footnotetext{Note that the table therefore refers to a non-standard Preferential Attachment version with adjustable power law exponent  (normally, ).} 
A number of properties of hyperbolic random graphs have been studied.
\citet{gugelmann2012random} compute exact asymptotic expressions for the expected number of vertices of degree  and prove a constant lower bound for the clustering coefficient.
They confirm that the clustering is non-vanishing and that the degree sequence follows a power-law distribution with controllable exponent . For , the hyperbolic random graph has a giant component of size  \cite{Bode:2013aa,bfmconnected}, similar to other scale-free networks like Chung-Lu \cite{chung2002average}. Other studied properties include the clique number \cite{friedrich2015cliques}, bootstrap percolation~\cite{candellero2014bootstrap}; as well as algorithms for efficient generation of hyperbolic random graphs \cite{von2015fast} and efficient embedding of real networks in the hyperbolic plane \cite{6705650}.

\textbf{Diameter.}
The diameter, the length of the longest shortest path, is a fundamental property of a network.
It also sets a worst-case lower bound on the number of steps required for all communication processes
on the graph. In contrast to the average distance, it is determined by a single---atypical---long path.
Due to this sensitivity to small changes, it is notoriously hard to analyze.
Even subtle changes to the graph model can make an exponential difference in the diameter, as can be seen when comparing
Chung-Lu (CL) random graphs~\cite{chung2002average} and
Preferential Attachment (PA) graphs~\cite{barabasi1999emergence} 
in the considered range of the  power law exponent :
On the one hand, we can embed a CL graph in the PA graph and they behave effectively
the same~\cite{UltraFastRumor:unpub};
on the other hand,
the diameter of 
CL graphs is ~\cite{chung2002average}
while for PA graphs it is
~\cite{diamPA}.
\tabref{diameters} provides an overview over existing results.
It was open so far how the diameter of hyperbolic random graphs compares to the aforementioned
bounds for other scale-free graph models.
The only known results for their diameter are
 by \citet{KiwiMitsche15}, and a polylogarithm with no explicit constant by \citet{bringmann2015geometric}.

\textbf{Our contribution.}
We improve upon the previous results as described by the following theorems.
First, we present a much simpler proof which also shows polylogarithmic upper bound for the diameter,
but with a better (i.e.\ smaller) exponent.\footnote{The conference version of this paper \cite{DBLP:conf/icalp/FriedrichK15} also contained an incorrect proof of a logarithmic upper bound on the diameter for small average degrees. In particular, Lemma~14 contained a mistake where the expected value was taken over probabilities  that did not add up to .
It is an open problem to close the gap between the polylogarithmic upper and logarithmic lower bound. }
\begin{theorem}
\label{thm:largesection}
Let . The diameter of the giant component in the hyperbolic random graph  is  with probability .
\end{theorem}
The proof of \thmref{largesection} is presented in \secref{polyupper}.
For a lower bound on the diameter, we prove the following theorem.
\begin{theorem}
\label{thm:lowerbound}
Let . Then, the diameter of the giant component in the hyperbolic random graph  is  with probability .
\end{theorem}
We point out that although we prove all diameter bounds on the giant component, our proofs will make apparent that the giant component is in fact the component with the largest diameter in the graph.
\medskip



\section{Notation and Preliminaries}
In this section, we briefly introduce hyperbolic random graphs. Although this paper is self-contained, we recommend to a reader who is unfamiliar with the notion of hyperbolic random graphs the more thorough investigations \cite{krioukov2010hyperbolic,gugelmann2012random}. 

Let  be the hyperbolic plane. Following \cite{krioukov2010hyperbolic}, we use the {\em native} representation; in which a point  is represented by polar coordinates ; and  is the hyperbolic distance of  to the origin.\footnote{Note that this seemingly trivial fact does not hold for conventional models (e.g.\ Poincar\'e halfplane) for the hyperbolic plane.}

To construct a hyperbolic random graph , consider now a circle  with radius  that is centered at the origin of . Inside ,  points are distributed independently as follows. For each point , draw  uniformly at random from , and draw  according to the probability density function

Next, connect two points  if their hyperbolic distance is at most , i.e.\ if

By  we describe the small relative angle between two nodes , i.e. . 

This results in a graph whose degree distribution follows a power law with exponent , if , and  otherwise \cite{gugelmann2012random}. Since most real-world networks have been shown to have a power law exponent , we assume throughout the paper that . \citet{gugelmann2012random} proved that the average degree in this model is then .

We now present a handful of Lemmas useful for analyzing the hyperbolic random graph. Most of them are taken from \cite{gugelmann2012random}. We begin by an upper bound for the angular distance between two connected nodes. Consider two nodes with radial coordinates . Denote by  the maximal radial distance such that these two nodes are connected. By \eq{distance}, 

This terse expression is closely approximated by the following Lemma.
\begin{lemma}[\cite{gugelmann2012random}]
\label{lem:maxangle}
Let  and . Then,

\end{lemma} 
For most computations on hyperbolic random graphs, we need expressions for the probability that a sampled point falls into a certain area. To this end, \citet{gugelmann2012random} define the {\em probability measure} of a set  as

where  is the probability mass of a point  given by .
We further define the {\em ball} with radius  around a point  as

We write  for . Note that . Using these definitions, we can formulate the following Lemma.
\begin{lemma}[\cite{gugelmann2012random,KiwiMitsche15}]
\label{lem:intersection}
For any  we have

\end{lemma}
Since we often argue over sequences of nodes on a path, we say that a node~ is {\em between} two nodes , if  
Recall that  describes the small angle between  and . E.g., if , then  lies between  and . However,  does not lie between  and  as  but .

Finally, we define the area  as the {\em inner band}, and  as the {\em outer band}, where  is a large enough constant. 


\medskip \noindent \textbf{The Poisson Point Process.}
We often want to argue about the probability that an area  contains one or more nodes. To this end, we usually apply the simple formula

Unfortunately, this formula significantly complicates once the positions of some nodes are already known. This introduces conditions on  which can be hard to grasp analytically. To circumvent this problem, we use a Poisson point process  \cite{penrose2003random} which describes a different way of distributing nodes inside . It is fully characterized by the following two properties:
\begin{itemize}
\item If two areas  are disjoint, then the number of nodes that fall within  and  are independent random variables.
\item The expected number of points that fall within  is .
\end{itemize}
One can show that these properties imply that the number of nodes inside  follows a Poisson distribution with mean . In particular, we obtain that the number of nodes  inside  is distributed as , i.e.\ , and 

Let the random variable  denote the resulting graph when using the Poisson point process to distribute nodes inside . Since it holds

we have that every property  with  holds for the hyperbolic random graphs with probability .

We explicitly state whenever we use the Poisson point process  instead of the normal hyperbolic random graph . In particular, we can use a matching expression for \eq{existsnode}:

\section{Polylogarithmic Upper Bound}
\label{sec:polyupper}
As an introduction to the main proof, we first show a simple polylogarithmic upper bound on the diameter of the hyperbolic random graph. We start by  investigating nodes in the inner band  and show that they are connected by a path of at most  nodes.  
We prove this by partitioning  into  layers of constant thickness . Then, a node in layer  has radial coordinate . We denote the layer  by .
\begin{lemma}
\label{lem:constbounds}
Let , and consider two nodes . Then,

Furthermore, we have

and, if  for some constant , we have for large 

\end{lemma}
\begin{proof}
The statements follow directly from \lemrefs{maxangle}{intersection} and the fact that we have  for a node .
\end{proof}
Using \lemref{constbounds}, we can now prove that a node  has a path of length  that leads to . Recall that the inner band was defined as , where  is a large enough constant.
\begin{lemma}
\label{lem:diamlarge}
Consider a node  in layer . With probability  it holds 
\begin{enumerate}
\item if , then  has a neighbor in layer , and
\item if , then  has a neighbor in layer  for .
\end{enumerate}
\end{lemma}
\begin{proof}
The probability that node  does not contain a neighbor in  is

Since  and  is a large enough constant, this proves part (1) of the claim. An analogous argument shows part (2).
\end{proof}
\lemref{diamlarge} shows that there exists a path of length  from each node   to some node . Similarly, from  there exists a path of length  to  with high probability. Since we know that the nodes in  form a clique by the triangle inequality, we therefore obtain that all nodes in  form a connected component with diameter .
\begin{corollary}
\label{cor:smalldiam}
Let . With probability , all nodes  in the hyperbolic random graph are connected by a path of length .
\end{corollary} 

\subsection{Outer Band}
\label{sec:outer}

By \corref{smalldiam}, we obtain that the diameter of the graph induced by nodes in  is at most . In this section, we show that each component in  has a polylogarithmic diameter. Then, one can easily conclude that the overall diameter of the giant component is polylogarithmic, since all nodes in  belong to the giant component \cite{bfmconnected}.
We begin by presenting one of the crucial Lemmas in this paper that will often be reused. 
\begin{lemma}
\label{lem:underpass}
Let  be nodes such that  lies between  and , and let . If  and , then  is connected to both  and . If  but , then  is at least connected to . 
\end{lemma}
\begin{proof}
By \cite[Lemma 5.28]{bfmconnected}, we know that if two nodes  are connected, then so are  where  and . Since the distance between nodes is monotone in the relative angle , this proves the first part of the claim. The second part can be proven by an analogous argument.
\end{proof}
For convenience, we say that an edge  {\em passes under}  if one of the requirements of \lemref{underpass} is fulfilled. Using this, we are ready to show \thmref{largesection}. In this argument, we investigate the angular distance a path can at most traverse until it passes under a node in . By \lemref{underpass}, we then have with high probability a short path to the center  of the graph.

\begin{proof}[(Proof of \thmref{largesection})]
Partition the hyperbolic disc into  disjoint sectors of equal angle . The probability that  consecutive sectors contain no node in  is

Hence, we know that with probability , there are no  such consecutive sectors. By a Chernoff bound, the number of nodes in  such consecutive sectors is  with probability . Applying a union bound, we get that with probability , every sequence of  consecutive sectors contains at least one node in  and at most  nodes in total. Consider now a node  that belongs to the giant component. Then, there must exist a path from  to some node . By \lemref{underpass}, this path can visit at most  sectors---and therefore use at most  nodes---before reaching~. From , there is a path of length  to the center  of the hyperbolic disc by \corref{smalldiam}. Since this holds for all nodes, and the center forms a clique, the diameter is therefore .
\end{proof}
From the proof it follows that every component inhabiting  sectors is connected to the center. We derive the following Corollary.
\begin{corollary}
\label{cor:2ndcomp}
Let . The second largest component of the hyperbolic random graph is of size at most  with probability .
\end{corollary}
These bounds improves upon the results in \cite{KiwiMitsche15} who show an upper bound of  on the diameter and  on the second largest component.
As we will see in \thmref{lowerbound}, however, the lower bound on the diameter is only . It is an open problem to bridge this gap.









\section{Logarithmic Lower Bound}
\label{sec:lower}

\citet{KiwiMitsche15} provide a proof for the existence of a path component of length  with high probability. In this section, we show a stronger statement, namely that the {\em largest} component has a diameter of . This proves the intuition that the component with the largest diameter is in fact the giant component, which is not obvious a priori. 

\begin{proof}[Proof of \thmref{lowerbound}]
Let . Observe that for , we have . Consider the model , i.e.\ {\em not} the Poisson point process. With high probability, there are no nodes in :

In the following, we condition on the fact that there are no such nodes; and switch to the Poisson point process. Consider now a node . The largest angular distance  can have to one of its neighbors is


Similarly to \thmref{largesection}, we partition the Disc  into  sectors of equal angle . Then, two nodes  in neighboring sectors have angular distance at most  , and are therefore connected. On the flip side, two nodes with at least  sectors between them have no edge, since their angle is .

Consider now  consecutive sectors, where  is to be fixed later. For each of these  sectors, the probability that it contains exactly one node in  is 
, i.e.\ a constant smaller than . The probability that this node has no further neighbors (apart from the neighbors in  in the other sectors) is again  by \lemref{intersection}. We name these nodes .

Similarly, the probability that sector  contains exactly one node  in  is again . From here, we expose a path to the inner band  as follows. Assume we have a node . Assume further that all nodes  are to the left of . Then, we consider the probability that  has a neighbor in layer  for , while we condition on the fact that none of the nodes  have neighbors in the upper layers as stated before. By \lemref{constbounds} this means that in layer , we have not yet uncovered an angle of at least 

as . Therefore, the probability that node  has a neighbor in layer  that is not connected to , is at least

In total, the probability that  exist as described above; and that they are connected to  is thereby


Furthermore, by \eq{uncoveredangle}, we know that when exposing this information we at most expose an angle of  of the graph. 
Therefore, if , we can repeat this experiment independently  times. The probability that all of them fail is at most
  
if  is chosen small enough. This proves the claim.
\end{proof}


\section{Conclusion}
We derive a new polylogarithmic upper bound on the diameter of hyperbolic random graphs; and further prove a logarithmic lower bound. This  immediately yields lower bounds for any broadcasting protocol that has to reach all nodes. Processes such as bootstrap percolation or rumor spreading therefore must run at least  steps until they inform all nodes in the giant component. In particular, this result stands in contrast to the average distance of two nodes in the hyperbolic random graph, which is of order  \cite{bringmann2015geometric,abdullah2015typical}. This implies the existence of a path that is exponentially longer than the average path.

Our work focuses on power law exponents , but we believe that it is possible to bound the diameter for  by . For other scale-free models it was also interesting to study the phase transition at  and .


\bibliography{bibliography.bib}

\end{document}