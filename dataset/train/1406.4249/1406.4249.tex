\documentclass{llncs}


\usepackage{makeidx}  \usepackage{times}
\usepackage{xspace}
\usepackage{amsmath, amssymb, latexsym}
\usepackage{bbm}
\usepackage{stmaryrd}
\usepackage{color}
\usepackage{dsfont}
\usepackage{microtype}\usepackage{boxedminipage}
\usepackage{smallsec}
\usepackage{fullpage}


\newtheorem{observation}[theorem]{Observation}

\newcommand{\qedsymb}{\hfill{\rule{2mm}{2mm}}}
\def\squarebox#1{\hbox to #1{\hfill\vbox to #1{\vfill}}}
\renewcommand{\qed}{\hspace*{\fill}
       \vbox{\hrule\hbox{\vrule\squarebox{.667em}\vrule}\hrule}\smallskip}
\renewenvironment{proof}{\begin{trivlist}
\item[\hspace{\labelsep}{\bf\noindent Proof: }]
}{\qed\end{trivlist}}

\bibliographystyle{abbrv}









\newcommand{\shaull}[1]{}
\newcommand{\short}[1]{}
\newcommand{\set}[1]{{\left\{#1\right\}}}
\newcommand{\Nat}{\mathbbm{N}}
\newcommand{\Rat}{\mathbbm{Q}}
\newcommand{\con}{\cdot}
\newcommand{\restrict}[1]{\!\!\upharpoonright\!\! _{#1}}
\newcommand{\tuple}[1]{\langle #1  \rangle}
\newcommand{\zug}[1]{\langle #1  \rangle}
\newcommand{\pair}{\tuple}
\newcommand{\val}[2]{[\![#1]\!]_{#2}} \newcommand{\sem}[1]{[\![#1]\!]}
\newcommand{\vali}[3]{[\![#1]\!]^{#3}_{#2}} \newcommand{\semb}[1]{[\![#1]\!]_B} \newcommand{\rT}{\tau}
\mathchardef\mhyphen="2D
\newcommand{\True}{\mathtt{True}}
\newcommand{\False}{\mathtt{False}}
\newcommand{\LTL}{{\ensuremath{\rm LTL}}\xspace}
\newcommand{\PLTL}{{\ensuremath{\rm PLTL}}\xspace}
\newcommand{\CTL}{{\rm CTL}}
\newcommand{\ELTL}{\factor\mhyphen \LTL}
\newcommand{\ECTL}{\factor\mhyphen \CTL}
\newcommand{\ULTL}{\LTL^{\factorU}}
\newcommand{\UCTL}{\CTL^{\factorU}}
\newcommand{\UCTLs}{\CTL^{\star \factorU}}
\newcommand{\PCTL}{\Competence\mhyphen \CTL}
\newcommand{\NLTL}{\Necessity\mhyphen \LTL}
\newcommand{\NCTL}{\Necessity\mhyphen \CTL}
\newcommand{\AvLTL}{\oplus\mhyphen \LTL}
\newcommand{\NFLTL}{\LTL^{\Competence+}}
\newcommand{\AvFLTL}{\avg{}\mhyphen disc\mhyphen \FLTL}


\newcommand{\Next}{\mathsf{X}}
\newcommand{\Yest}{\mathsf{Y}}
\newcommand{\Ev}{\mathsf{F}}
\newcommand{\Alw}{\mathsf{G}}
\newcommand{\Until}{\mathsf{U}}
\newcommand{\Since}{\mathsf{S}}
\newcommand{\dSince}{\widetilde{\mathsf{S}}}
\newcommand{\Release}{\mathsf{R}}
\newcommand{\dUntil}{\widetilde{\mathsf{U}}}
\newcommand{\dRelease}{\widetilde{\mathsf{R}}}
\newcommand{\parUntil}{\mathsf{O}}
\newcommand{\dparUntil}{\widetilde{\parUntil}}


\newcommand{\Exists}{\mathsf{E}}
\newcommand{\All}{\mathsf{A}}

\newcommand{\BMC}{\texttt{BMC}} 

\newcommand{\K}{{\mathcal K}}
\newcommand{\T}{{\mathcal T}}

\newcommand{\tr}{\mathsf{next}}
\newcommand{\atleast}{{\rm at\_least}}
\newcommand{\bool}{{\it Bool}}

\newcommand{\NFA}{\mbox{\rm NFA}\xspace}
\newcommand{\AFA}{\mbox{\rm AFA}\xspace}
\newcommand{\NBA}{\mbox{\rm NBA}\xspace}
\newcommand{\NGBW}{\mbox{\rm NGBA}\xspace}
\newcommand{\ABA}{\mbox{\rm ABA}\xspace}
\newcommand{\WNFA}{\mbox{\rm WNFA}\xspace}
\newcommand{\WAFA}{\mbox{\rm WAFA}\xspace}
\newcommand{\WNBA}{\mbox{\rm WNBA}\xspace}
\newcommand{\WABA}{\mbox{\rm WABA}\xspace}
\newcommand{\NFW}{\mbox{\rm NFA}\xspace}
\newcommand{\AFW}{\mbox{\rm AFA}\xspace}
\newcommand{\NBW}{\mbox{\rm NBA}\xspace}
\newcommand{\ABW}{\mbox{\rm ABA}\xspace}
\newcommand{\AWW}{\mbox{\rm AWA}\xspace}
\newcommand{\UCW}{\mbox{\rm UCA}\xspace}
\newcommand{\UCT}{\mbox{\rm UCT}\xspace}
\newcommand{\WNFW}{\mbox{\rm WNFA}\xspace}
\newcommand{\WAFW}{\mbox{\rm WAFA}\xspace}
\newcommand{\WNBW}{\mbox{\rm WNBA}\xspace}
\newcommand{\WABW}{\mbox{\rm WABA}\xspace}
\newcommand{\twAWW}{\mbox{\rm 2AWA}\xspace}


\newcommand{\todo}[1]{\textsf{To do: #1}}
\newcommand{\gap}{\vspace*{0.25 cm}}
\newcommand{\stam}[1]{}

\newcommand{\B}{{\cal B}}
\newcommand{\C}{{\cal C}}
\newcommand{\D}{{\cal D}}
\newcommand{\E}{{\cal E}}
\newcommand{\A}{{\cal A}}
\newcommand{\M}{{\cal M}}
\newcommand{\F}{{\cal F}}
\newcommand{\R}{{\bf IR}}

\newcommand{\lab}{\ell} 

\newcommand{\Competence}{\triangledown}
\newcommand{\Necessity}{\blacktriangledown}
\newcommand{\Confidence}{\triangledown\!\!\!\blacktriangledown}


\definecolor{gray}{RGB}{127,127,127}
\newcommand{\factor}{{\mathrlap{\color{gray}\blacktriangledown}\triangledown}}


\newcommand{\factorF}{\Confidence}
\newcommand{\factorP}{\Competence}
\newcommand{\factorU}{\Competence}

\newcommand{\avg}[1]{\oplus_{#1}}

\renewcommand{\phi}{\varphi}
\newcommand{\mins}[1]{\min\set{#1}}
\newcommand{\maxs}[1]{\max\set{#1}}
\newcommand{\infs}[1]{\inf\set{#1}}
\newcommand{\sups}[1]{\sup\set{#1}}

\newcommand{\Inf}{\mbox{inf}}

\newcommand{\Paragraph}[1]{\paragraph*{#1.}}
\newcommand{\ST}{ : \:}


\newcommand{\Fu}[2]{\ensuremath {{#1}{[#2]}}\xspace}
\newcommand{\FuLTL}[1]{\Fu{\LTL}{#1}}

\newcommand{\FLTL}{\Fu{\LTL}{\F}}
\newcommand{\FCTL}{\Fu{\CTL}{\F}}
\newcommand{\FCTLs}{\Fu{\CTL^*}{\F}}
\newcommand{\DLTL}{\ensuremath{\LTL^{\text{disc}}[\D]}}
\newcommand{\DLTLE}{\ensuremath{\LTL^{\text{disc}}[E]}}
\newcommand{\LTLD}{\DLTL}
\newcommand{\DPLTL}{\ensuremath{\PLTL^{\text{disc}}[\D]}}
\newcommand{\AvDLTL}{\ensuremath{\LTL^{\text{disc}}[\D]}}


\newcommand{\draft}{--- Draft of \date{\today} ---}
\newcommand{\sep}{~ | ~}
\newcommand{\xcl}{xcl}

\newcommand{\df}{\eta}
\newcommand{\pos}[1]{{#1}^{+}}
\newcommand{\notone}[1]{{#1}^{<1}}


\newcommand{\pb}{\hspace*{-0.62cm}} \newcommand{\spb}{\hspace*{-0.42cm}}



\begin{document}

\belowdisplayskip=3pt
\abovedisplayskip=3pt
\title{Discounting in LTL}
\titlerunning{Discounting in LTL}
\author{Shaull Almagor\inst{1} \and Udi Boker\inst{2} \and Orna Kupferman\inst{1}}
\institute{The Hebrew University, Jerusalem, Israel. \and The Interdisciplinary Center, Herzliya, Israel.}
\maketitle

\begin{abstract}
In recent years, there is growing need and interest in formalizing and reasoning about the quality of software and hardware systems. As opposed to traditional verification, where one handles the question of whether a system satisfies, or not, a given specification, reasoning about quality addresses the question of \emph{how well} the system satisfies the specification. One direction in this effort is to refine the ``eventually'' operators of temporal logic to {\em discounting operators}: the satisfaction value of a specification is a value in , where the longer it takes to fulfill eventuality requirements, the smaller the satisfaction value is.

In this paper we introduce an augmentation by discounting of Linear Temporal Logic (LTL), and study it, as well as its combination with propositional quality operators. We show that one can augment LTL with an arbitrary set of discounting functions, while preserving the decidability of the model-checking problem. Further augmenting the logic with unary propositional quality operators preserves decidability, whereas adding an average-operator makes some problems undecidable.
We also discuss the complexity of the problem, as well as various extensions.
\end{abstract}



\section{Introduction}
\label{sec:introduction}
One of the main obstacles to the development of complex hardware and software systems lies in ensuring their correctness. A successful paradigm addressing this obstacle is {\em temporal-logic model checking\/} -- given a mathematical model of the system and a temporal-logic formula that specifies a desired behavior of it, decide whether the model satisfies the formula \cite{CGP99}.
Correctness is Boolean: a system can
either satisfy its specification or not satisfy it. The richness
of today's systems, however, justifies specification formalisms that
are {\em multi-valued}. The multi-valued setting arises directly in systems
with quantitative aspects (multi-valued / probabilistic / fuzzy) \cite{DR09b,DV12,FLS08,Kwi07,MLL04}, but is applied also with respect to Boolean systems, where it origins from the semantics of the specification formalism itself 
\cite{ABK13,AFHMS05}.

When considering the \emph{quality} of a system,
satisfying a specification should no longer be a yes/no matter. Different ways of satisfying a specification should induce different levels of quality, which should be reflected in the output of the verification procedure. Consider for example the specification
 (``every request is eventually responded, with either a grant or a denial''). There should be a difference between a computation that satisfies it with responses generated soon after requests and one that satisfies it with long waits. Moreover, there may be a difference between grant and deny responses, or cases in which no request is issued.
The issue of generating high-quality hardware and software systems attracts a lot of attention \cite{Kan02,Spi06}. Quality, however, is traditionally viewed as an art, or as an amorphic ideal.  
In \cite{ABK13}, we introduced an approach for formalizing quality. Using it, a user can specify quality formally, according to the importance he gives to components such as security, maintainability, runtime, and more, and then can formally reason about the quality of software.

As the example above demonstrates, we can distinguish between two 
aspects 
of the quality of satisfaction. The first, to which we refer as ``temporal quality'' concerns the waiting time to satisfaction of eventualities. The second, to which we refer as ``propositional quality'' concerns prioritizing related components of the specification. 
Propositional quality was studied in \cite{ABK13}. In this paper we study temporal quality as well as the combinations of both aspects. One may try to reduce temporal quality to propositional quality by a repeated use of the  (``next") operator or by a use of  bounded (prompt) eventualities \cite{AHK10,BC06}. Both approaches, however, partitions the future into finitely many zones and are limited: correctness of  is Boolean, and thus has inherent dichotomy between satisfaction and dissatisfaction. On the other hand, the distinction between ``near'' and ``far'' is not dichotomous.
\stam{
One may try to reduce ``temporal quality'' to ``propositional quality'', using the fact that an eventuality involves a repeated choice between satisfying it in the present or delaying its satisfaction to the strict future. This attempt, however, requires unboundedly many applications of the propositional choice, and is similar to a repeated use of the  (``next") operator rather than a use of eventuality operators.
Repeated use of  is a limited solution, 
as it partitions the future into finitely many zones, all of which are in the ``near future'', except for a single, unbounded, ``far future''. A more involved approach to distinguish between the ``near'' and ``far'' future  includes bounded (prompt) eventualities \cite{AHK10,BC06}. There, one distinguishes between eventualities whose waiting time is bounded and ones that have no bound.

The weakness of both approaches is not surprising -- correctness of  is Boolean, and thus has inherent dichotomy between satisfaction and dissatisfaction. The distinction between ``near'' and ``far'', however, is not dichotomous.
} This suggests that in order to formalize temporal quality, one must extend  to an unbounded setting. Realizing this, researchers have suggested to augment temporal logics with {\em future discounting} \cite{AHM03}. In the discounted setting, the satisfaction value of specifications is a numerical value, and it depends, according to some discounting function, on the time waited for eventualities to get satisfied.

In this paper we add discounting to Linear Temporal Logic (\LTL), and study it, as well as its combination with propositional quality operators.
We introduce  -- an augmentation by discounting of \LTL. The logic  is actually a family of logics, each parameterized by a set  of discounting functions --  strictly decreasing functions from  to  that tend to 
(e.g., linear decaying, exponential decaying, etc.).  includes a discounting-``until'' () 
operator, parameterized by a function . We solve the model-checking threshold problem for : given a Kripke structure , an  formula  and a threshold , the algorithm decides whether the satisfaction value of  in  is at least .

In the Boolean setting, the automata-theoretic approach has proven to be very useful in reasoning about \LTL specifications. The approach is based on translating \LTL formulas to nondeterministic B\"uchi automata on infinite words \cite{VW86b}.
Applying this approach to the discounted setting, which gives rise to infinitely many satisfaction values, poses a big algorithmic challenge: model-checking algorithms, and in particular those that follow the automata-theoretic approach, are based on an exhaustive search, which cannot be simply applied when the domain becomes infinite.
A natural relevant extension to the automata-theoretic approach is to translate formulas to {\em weighted automata} \cite{Moh97}. Unfortunately, these extensively-studied models are complicated and many problems become undecidable for them \cite{Kro94}.
We show that for threshold problems, we can translate  formulas into (Boolean) nondeterministic B\"uchi automata, with the property that the automaton accepts a lasso computation iff the formula attains a value above the threshold on that computation.
Our algorithm relies on the fact that the language of an automaton is non-empty iff there is a lasso witness for the non-emptiness.
We cope with the infinitely many possible satisfaction values by using the discounting behavior of the eventualities and the given threshold in order to partition the state space into a finite number of classes.
The complexity of our algorithm depends on the discounting functions used in the formula.
We show that for standard discounting functions, such as exponential decaying, the problem is PSPACE-complete -- not more complex than standard \LTL. 
The fact our algorithm uses Boolean automata also enables us to suggest a solution for threshold satisfiability, and to give a partial solution to threshold synthesis. In addition, it allows to adapt the heuristics and tools that exist for Boolean automata.

Before we continue to describe our contribution, let us review existing work on discounting.
The notion of discounting has been studied in several fields, such as economy, game-theory, and Markov decision processes \cite{Sha53}. In the area of formal verification, it was suggested in
\cite{AHM03} to augment the -calculus with discounting operators. The discounting suggested there is exponential; that is, with each iteration, the satisfaction value of the formula decreases by a multiplicative factor in . Algorithmically, \cite{AHM03} shows how to evaluate discounted -calculus formulas with arbitrary precision. Formulas of  can be translated to the -calculus, thus \cite{AHM03} can be used in order to approximately model-check discounted- formulas. However, the translation from  to the -calculus involves an exponential blowup \cite{Dam94} (and is complicated), making this approach inefficient. Moreover, our approach allows for arbitrary discounting functions, and the algorithm returns an exact solution to the threshold model-checking problem, which is more difficult than the approximation problem.

Closer to our work is \cite{AFHMS05}, where  is augmented with discounting and weighted-average operators.  The motivation in~\cite{AFHMS05} is to introduce a logic whose semantics is not too sensitive to small perturbations in the model. Accordingly, formulas are evaluated on weighted-systems or on Markov-chains. Adding discounting and weighted-average operators to  preserves its appealing complexity, and the model-checking problem for the augmented logic can be solved in polynomial time. As is the case in the traditional, Boolean, semantics, the expressive power of discounted  is limited.
The fact the same combination, of discounting and weighted-average operators, leads to undecidability in the context of LTL witnesses the technical challenges of the  setting.  

Perhaps closest to our approach is~\cite{Man12}, where a version of discounted-\LTL was introduced. Semantically, there are two main differences between the logics. The first is that ~\cite{Man12} uses discounted sum, while we interpret discounting without accumulation, and the second is that the discounting there replaces the standard temporal operators, so all  eventualities are discounted. As discounting functions tend to , this strictly restricts the expressive power of the logic, and one cannot specify traditional eventualities in it. On the positive side, it enables a clean algebraic characterization of the semantics, and indeed the contribution in \cite{Man12} is a comprehensive study of the mathematical properties of the logic. Yet, ~\cite{Man12} does not study algorithmic questions
about to the logic. We, on the other hand, focus on the algorithmic properties of the logic, and specifically on the model-checking problem.

Let us now return to our contribution. After introducing  and studying its model-checking problem, we augment  with propositional quality operators. Beyond the operators , , and , which are already present, two basic propositional quality operators are the multiplication of an  formula by a constant in , and the averaging between the satisfaction values of two  formulas \cite{ABK13}. We show that while the first extension does not increase the expressive power of  or its complexity, the latter causes 
some problems (e.g. validity) to become undecidable. In fact, things become undecidable even if we allow averaging in combination with a single discounting function. Recall that this is in contrast with the extension of discounted  with an average operator, where the complexity of the model-checking problem stays polynomial \cite{AFHMS05}.

We consider additional extensions of . First, we study a variant of the discounting-eventually operators in which we allow the discounting
to tend to arbitrary values in  (rather than to ). This captures the intuition that we are not always pessimistic about the future, but can be, for example, ambivalent about it, by tending to . We show that all our results hold under this extension.
Second, we add to  {\em past\/} operators and their discounting versions (specifically, we allow a discounting-``since" operator, and its dual). In the traditional semantics, past operators enable clean specifications of many interesting properties, make the logic exponentially more succinct, and can still be handled within the same complexity bounds \cite{LS94,LPZ85}. We show that the same holds for the discounted setting.
Finally, we show how  and algorithms for it can be used also for reasoning about weighted systems.



Due to lack of space, the full proofs appear in the appendix.


\section{The Logic \DLTL}
The linear temporal logic  generalizes  by adding discounting temporal operators. The logic is actually a family of logics, each parameterized by a set  of discounting functions.

Let . A function  is a {\em discounting function} if , and  is strictly monotonic-decreasing. Examples for natural discounting functions are , for some , and .

Given a set of discounting functions , we define the logic  as follows. The syntax of  adds to  the operator  (discounting-Until),
for every function .
Thus, the syntax is given by the following grammar, where  ranges over the set  of atomic propositions and .



The semantics of  is defined with respect to a {\em computation\/} . Given a computation  and an  formula , the truth value of  in  is a value in , denoted . The value is defined by induction on the structure of  as follows, where .
\begin{itemize}
\item . \hspace{2.98cm} \labelitemi ~.
\item   \hspace{1.5cm} \labelitemi ~.
\item .
\item .
\item .


\end{itemize}

The intuition is that events that happen in the future have a lower influence,
 and the rate by which this influence decreases depends on the function .
\footnote{Observe that in our semantics the satisfaction value of future events tends to . One may think of scenarios where future events are discounted towards another value in  (e.g. discounting towards  as ambivalence regarding the future). We address this in Section~\ref{sec:DiscountingTendency}.} For example, the satisfaction value of a formula  in a computation  depends on the best (supremum) value that  can get along the entire computation, while considering the discounted satisfaction of  at a position , as a result of multiplying it by ,
and the same for the value of  in the prefix leading to the -th position.

We add the standard abbreviations , and , as well as their quantitative counterparts: , and .
We denote by  the number of subformulas of . 

A computation of the form , for , with , is called a {\em lasso computation}. 
We observe that since a specific lasso computation has only finitely many distinct suffixes, the  and  in the semantics of  can be replaced with  and , respectively, when applied to lasso computations.

The semantics is extended to {\em Kripke structures} by taking the path that admits the lowest satisfaction value. Formally, for a Kripke structure  and an  formula  we have that \K.




\begin{example}
Consider a lossy-disk: every moment in time there is a chance that some bit would flip its value. Fixing flips is done by a global error-correcting procedure. This procedure manipulates the entire content of the disk, such that initially it causes more errors in the disk, but the longer it runs, the more bits it fixes. 

Let  and  be atomic propositions indicating when the error-correcting procedure is initiated and terminated, respectively.
The quality of the disk (that is, a measure of the amount of correct bits) can be specified by the formula  for some appropriate discounting functions  and . 
Intuitively,  gets a higher satisfaction value the shorter the waiting time is between initiations of the error-correcting procedure, and the longer the procedure runs (that is, not terminated) in between these initiations. Note that the ``worst case'' nature of  fits here. For instance, running the procedure for a very short time, even once, will cause many errors.
\end{example}


\section{ Model Checking}
\label{sec:alg proc}
In the Boolean setting, the model-checking problem asks, given an  formula  and a Kripke structure , whether . In the quantitative setting, the model-checking problem is to compute , where  is now an  formula. A simpler version of this problem is the threshold model-checking problem: given , , and a threshold , decide whether . In this section we show how we can solve the latter.


Our solution uses the automata-theoretic approach, and consists of the following steps. We start by translating  and  to an alternating weak automaton  such that  iff there exists a computation  such that .
The challenge here is that  has infinitely many satisfaction values, naively implying an infinite-state automaton. We show that using the threshold and the discounting behavior of the eventualities, we can restrict attention to a finite resolution of satisfaction values, enabling the construction of a finite automaton.  Complexity-wise, the size of  depends on the functions in . In Section~\ref{subsec:ExpDiscounting}, we analyze the complexity for the case of exponential-discounting functions.

The second step is to construct a nondeterministic B\"uchi automaton  that is equivalent to . In general, alternation removal might involve an exponential blowup in the state space \cite{MH84}.
We show, by a careful analysis of , that we can remove its alternation while only having a polynomial state blowup.

We complete the model-checking procedure by composing the nondeterministic B\"uchi automaton  with the Kripke structure , as done in the traditional, automata-based, model-checking procedure.

The complexity of model-checking an  formula depends on the discounting functions in . Intuitively, the faster the discounting tends to 0, the less states there will be. For exponential-discounting, we show that the complexity is NLOGSPACE in the system (the Kripke structure) and PSPACE in the specification (the  formula and the threshold), staying in the same complexity classes of standard \LTL model-checking.

We conclude the section by showing how to use the generated nondeterministic B\"uchi automaton for 
addressing threshold satisfiability and synthesis.

\subsection{Alternating Weak Automata}

For a given set , let  be the set of positive Boolean formulas over  (i.e., Boolean formulas built from elements in 
using  and ), where we also allow the formulas  and . For , we say that  {\em satisfies\/} a
formula  iff the truth assignment that assigns {\em true} to the members of  and assigns {\em false} to the
members of  satisfies .
An {\em alternating B\"uchi automaton on infinite words\/} is a tuple
, where 
is the input alphabet,  is a finite set of states,  is an initial state, 
is a transition function, and  is a set of accepting states. We define runs of  by means of (possibly) infinite {\sc dag}s
(directed acyclic graphs).  A run of  on a word
 is a (possibly) infinite {\sc dag}   satisfying the following (note that there may be several runs
of  on ).
\begin{itemize}
\item
 is as follows. Let  denote
 all states
 in level . Thus, . Then,
, and  satisfies .
\item For every ,  is minimal with respect to containment.
\item
 is such that for every state , the set  satisfies .
\end{itemize}
Thus, the root of the {\sc dag} contains the initial state of the automaton, and the states associated with nodes in level  satisfy the
transitions from states corresponding to nodes in level .
The run  accepts the word  if all its infinite paths satisfy the acceptance condition . Thus, in the case of B\"uchi automata,
all the infinite paths have infinitely many nodes  such that 
(it is not hard to prove that every infinite path in  is part of an infinite path starting in level ).
A word  is accepted by  if there is a run that accepts it. The language of ,
denoted , is the set of infinite words that  accepts.

When the formulas in the transition function of  contain only disjunctions, then  is  nondeterministic, and its runs are {\sc dag}s of width 1, where at each level there is a single node. 

The alternating automaton  is {\em weak\/}, denoted , if its state space  can be partitioned into sets , such that the following hold: First, for every  either , in which case we say that  is an accepting set,  or , in which case we say that  is rejecting. Second, there is a partial-order  over the sets, and for every , if , , and  for some , then . Thus, transitions can lead only to states that are smaller in the partial order. Consequently, each run of an  eventually gets trapped in a set  and is accepting iff this set is accepting. 


\subsection{From  to }\label{sec:DltlToAww}
Our model-checking algorithm is based on translating an  formula  to an .
Intuitively, the states of the  correspond to assertions of the form  or  for every subformula  of , and for certain thresholds . 
A lasso computation is then accepted from state  iff . The assumption about the computation being a lasso is needed only for the ``only if'' direction, and it does not influence the proof's generality since the language of an automaton is non-empty iff there is a lasso witness for its non-emptiness. By setting the initial state to , we are done. 

Defining the appropriate transition function for the  follows the semantics of  in the expected manner. A naive construction, however, yields an infinite-state automaton (even if we only expand the state space on-the-fly, as discounting formulas can take infinitely many satisfaction values).
As can be seen in the proof of Theorem~\ref{thm:DLTL to AWW}, the ``problematic'' transitions are those that involve the discounting operators. The key observation is that, given a threshold  and a computation , when evaluating a discounted operator on , one can restrict attention to two cases: either the satisfaction value of the formula goes below , in which case this happens after a bounded prefix, or the satisfaction value always remains above , in which case we can replace the discounted operator with a Boolean one. This observation allows us to expand only a finite number of states on-the-fly.

Before describing the construction of the , we need the following lemma, which reduces an extreme satisfaction of an  formula, meaning satisfaction with a value of either  or , to a Boolean satisfaction of an LTL formula. The proof proceeds by induction on the structure of the formulas.
\begin{lemma}
\label{lem:LTL for positive}
Given an  formula , there exist  formulas  and  such that  and  are both  and the following hold for every computation .
\begin{enumerate}
\item If  then , and if  then .
\item If  is a lasso, then if  then  and if  then .
\end{enumerate} 
\end{lemma}

Henceforth, given an  formula , we refer to  as in Lemma~\ref{lem:LTL for positive}.

Consider an  formula . By Lemma~\ref{lem:LTL for positive}, if there exists a computation  such that , then  is satisfiable. Conversely, since  is a Boolean  formula, then by \cite{Var96} we know that  is satisfiable iff there exists a lasso computation  that satisfies it, in which case . We conclude with the following.
\begin{corollary}
\label{cor:satisfaction}
Consider an  formula . There exists a computation  such that  iff there exists a lasso computation  such that , in which case  as well.
\end{corollary}

\begin{remark}
The curious reader may wonder why we do not prove that  iff  for every computation . As it turns out, a translation that is valid also for computations with no period is not always possible. For example, as is the case with the prompt-eventuality operator of \cite{KPV08}, the formula  is such that the set of computations  with  is not -regular, thus one cannot hope to define an \LTL formula .
\end{remark}




We start with some definitions. For a function  and for , we define  as follows. For every  we have that . 

Let  be an  formula over .
We define the {\em extended closure} of , denoted , to be the set of all the formulas  of the following {\em classes}:
\begin{enumerate}
\item  is a subformula of .
\item  is a subformula of  or , where  is a subformula of . 
\item  is of the form  for , where  is a subformula of .
\end{enumerate}
Observe that  may be infinite, and that it has both  formulas (from Classes  and ) and  formulas (from Class ).

\begin{theorem}
\label{thm:DLTL to AWW}
Given an  formula  and a threshold , there exists an   such that for every computation  the following hold.
\begin{enumerate}
\item If , then  accepts .
\item If  accepts  and  is a lasso computation, then .
\end{enumerate} 
\end{theorem}
\vspace*{-3mm}
\begin{proof}
We construct  as follows.


The state space  consists of two types of states. Type-1 states are assertions of the form  or , where  is of Class 1 or 3 and . Type-2 states correspond to  formulas of Class 2. Let  be the set of Type-1 and Type-2 states for all  and thresholds . Then,  is the subset of  constructed on-the-fly according to the transition function defined below. We later show that  is indeed finite.

The transition function 
is defined as follows. For Type-2 states, the transitions are as in the standard translation from  to  \cite{Var96} (see Appendix~\ref{apx: standard LTL to AWW} for details). For the other states, we define the transitions as follows. Let .
\begin{itemize}
\item 


\item .

\item


\item 

\item 


\item

\item
.
\item
.

\item 
\item .

\item .
 \item .

\item
0<t< 1t \geq 1t=0

\item
0<t\le 1t > 1t=0

\item

0<\frac{t}{\df(0)}< 1\frac{t}{\df(0)} \geq 1\frac{t}{\df(0)}=0t=0

\item

0<\frac{t}{\df(0)}\le 1\frac{t}{\df(0)}> 1\frac{t}{\df(0)}=0t=0
\end{itemize}



We provide some intuition for the more complex parts of the transition function: consider, for example, the transition . Since  is decreasing, the highest possible satisfaction value for  is . Thus, if  (equivalently, ), then it cannot hold that , so the transition is to . If , then we only need to ensure that the satisfaction value of  is not . 
To do so, we require that  is satisfied. By Corollary~\ref{cor:satisfaction}, this is equivalent to the satisfiability of the former. 
So the transition is identical to that of the state . Finally, if , then (slightly abusing notation) the assertion  is true if either  is true, or both  and  are true.

The initial state of  is .
The accepting states are these of the form , as well as accepting states that arise in the standard translation of Boolean \LTL to \AWW (in Type-2 states).
Note that each path in the run of  eventually gets trapped in a single state. Thus,  is indeed an . The intuition behind the acceptance condition is as follows. Getting trapped in state of the form  is allowed, as the eventuality is satisfied with value . On the other hand, getting stuck in other states (or Type-1) is not allowed, as they involve eventualities that are not satisfied in the threshold promised for them.

This concludes the definition of .  Finally, observe that while the construction as described above is infinite (indeed, uncountable), only finitely many states are reachable from the initial state , and we can compute these states in advance.
Intuitively, it follows from the fact that once the proportion between  and  goes above , for Type-1 states associated with threshold  and sub formulas with a discounting function , we do not have to generate new states.

A detailed proof of 's finiteness and correctness is given in the appendix.\vspace{-2mm}
\end{proof}

Since  is 
a Boolean automaton, 
then its language is not empty iff it accepts a lasso computation. Combining this observation with Theorem~\ref{thm:DLTL to AWW}, we conclude with the following.
\begin{corollary}
For an  formula  and a threshold , it holds that  iff there exists a computation  such that .
\end{corollary}

\subsection{Exponential Discounting}
\newcommand{\dfl}[1]{\exp_{#1}} \newcommand{\fac}{F}
\label{subsec:ExpDiscounting}
The size of the  generated as per Theorem~\ref{thm:DLTL to AWW} depends on the discounting functions.
In this section, we analyze its size for the class of {\em exponential discounting} functions, showing that it is singly exponential in the specification formula and in the threshold. This class is perhaps the most common class of discounting functions, as it describes what happens in many natural processes (e.g., temperature change, capacitor charge, effective interest rate, etc.) \cite{AHM03,Sha53}.

For  we define the {\em exponential-discounting} function  by .
For the purpose of this section, we restrict to .
Let , and consider the logic .

For an  formula  we define the set  to be   the operator . Let  be the length of the description of . That is, in addition to , we include in  the length, in bits, of describing .
\begin{theorem}
\label{thm: exp disc to AWW}
Given an  formula  and a threshold , there exists an   such that for every computation  the following hold.
\begin{enumerate}
\item If , then  accepts .
\item If  accepts  and  is a lasso computation, then .
\end{enumerate} 
Furthermore, the number of states of  is singly exponential in  and in the description of .
\end{theorem}
The proof follows from the following observation. Let  and . When discounting by , the number of states in the  constructed as per Theorem~\ref{thm:DLTL to AWW} is proportional to the maximal number  such that , which is at most , which is polynomial in the description length of  and . A similar (yet more complicated) consideration is applied for the setting of multiple discounting functions and negations.


\subsection{From  to an }
Every  can be translated to an equivalent nondeterministic B\"uchi automaton (, for short), yet the state blowup might be exponential 
{BKR10,MH84}. 
By carefully analyzing the   generated in Theorem~\ref{thm:DLTL to AWW}, we show that it can be translated to an \NBW with only a polynomial blowup.

The idea behind our complexity analysis is as follows.
Translating an  to an  involves alternation removal, which proceeds by keeping track of 
entire 
levels in a run-{\sc dag}. Thus, a run of the  corresponds to a sequence of subsets of . The key to the reduced state space is that the number of such subsets is only  and not . To see why, consider a subset  of the states of . We say that  is {\em minimal} if it does not include two states of the form  and , for , nor two states of the form  and , for , and similarly for ``''. Intuitively, sets that are not minimal hold redundant assertions, and can be ignored. Accordingly, we restrict the state space of the  to have only minimal sets.

\vspace*{-3pt}
\begin{lemma}
\label{lem:DLTL to NBW}
For an  ~formula  and , the   constructed in Theorem~\ref{thm:DLTL to AWW} with state space  can be translated to an  with  states.
\end{lemma}



\subsection{Decision Procedures for }
\Paragraph{Model checking and satisfiability} Consider a Kripke structure , an  formula , and a threshold . By checking the emptiness of the intersection of  with
, we can solve the threshold model-checking problem. Indeed,  iff there exists a lasso computation  that is induced by  such that , which happens iff it is not true that .



The complexity of the model-checking procedure depends on the discounting functions in . For the set of exponential-discounting functions , we provide the following concrete complexities, showing that it stays in the same complexity classes of standard \LTL model-checking.

\begin{theorem}\label{thm:ExpModelCheck}
For a Kripke structure , an  formula , and a threshold , the problem of deciding whether  is in NLOGSPACE in the number of states of , and in PSPACE in  and in the description of .
\end{theorem}
\begin{proof}
By Theorem~\ref{thm: exp disc to AWW} and Lemma~\ref{lem:DLTL to NBW},  the size of an   corresponding to  and  is singly exponential in  and in the description of . Hence, we can check the emptiness of the intersection of  and  via standard ``on the fly'' procedures, getting the stated complexities.
\end{proof}

Note that the complexity in Theorem~\ref{thm:ExpModelCheck} is 
only
NLOGSPACE in the system, since our solution does not analyze the Kripke structure, but only takes its product with the specification's automaton. This is in contrast to the approach of model checking temporal logic with (non-discounting) accumulative values, where, when decidable, involves a doubly-exponential dependency on the size of the system~\cite{BCHK11}.

Finally, observe that the  obtained in Lemma~\ref{lem:DLTL to NBW} can be used to solve the threshold-satisfiability problem: given an  formula  and a threshold , we can decide whether there is a computation  such that , for , and return such a computation when the answer is positive. This is done by simply deciding whether there exists a word that is accepted by the .


\paragraph{Threshold synthesis}
\label{rmk:SAT and synthesis}
Consider an  formula , and assume a partition of the atomic propositions in  to input and output signals, we can use the   in order to address the {\em synthesis} problem, as stated in the following theorem (see Appendix~\ref{apx: synthesis} for the proof).
\begin{theorem}
\label{thm:synthesis}
Consider an  formula . If there exists a transducer  all of whose computations  satisfy , then we can generate a transducer  all of whose computations  satisfy .
\end{theorem}




\section{Adding Propositional Quality Operators}
\label{sec:adding quality}

As model checking is decidable for , one may wish to push the limit and extend the expressive power of the logic. In particular, of great interest is the combining of discounting with propositional quality operators \cite{ABK13}.
\subsection{Adding the Average Operator}
\label{sec:average}
A well-motivated extension is the introduction of the average operator , with the semantics .
The work in~\cite{ABK13} proves that extending  by this operator, as well as with other propositional quantitative operators, enables clean specification of quality and results in a logic for which the model-checking problem can be solved in PSPACE.

\newcommand{\inc}{\mbox{\sc inc}\xspace}
\newcommand{\dec}{\mbox{\sc dec}\xspace}
\newcommand{\goto}{\mbox{\sc goto }}
\newcommand{\halt}{\mbox{\sc halt}\xspace}
\newcommand{\jz}[3]{\mbox{\sc if =0 goto  else goto }\xspace}
\newcommand{\CMrun}{\rho}
\newcommand{\comcheck}{\mbox{\rm ComCheck}\xspace}

We show that adding the  operator to  gives a logic, denoted , for which the validity problem is undecidable.
The validity problem asks, given an  formula  over the atomic propositions  and a threshold , whether  for every .

In the undecidability proof, we show a reduction from the 0-halting problem for two-counter machines.
A {\em two-counter machine}  is a sequence  of commands involving two counters  and . We refer to
 as the {\em locations} of the machine. There are five possible forms of commands:

where  is a counter and  are locations. Since we can always check whether  before a  command, we
assume that the machine never reaches  with . That is, the counters never have negative values. Given a counter machine ,
deciding whether  halts is known to be undecidable \cite{Min67}. Given , deciding whether  halts with both counters having value
, termed the {\em -halting problem}, is also undecidable: given a counter machine , we can replace every \halt command with a code that clears the counters before
halting. 
In fact, from this we see that the promise problem of deciding whether  -halts given the promise that either it -halts, or it does not halt at all, is also undecidable.

\begin{theorem}\label{thm:UndecidableAverage}
The validity problem for  is undecidable (for every nonempty set of discounting functions ).
\end{theorem}
\begin{proof}
We start by showing a reduction from the -halting problem for two-counter machines to the following  problem: given an  formula  over the atomic propositions , whether there exists a path  such that . We dub this the {\em -co-validity} problem. We will later reduce this problem to the (complement of the) validity problem.

Let  be a two-counter machine
with commands . A {\em halting run} of a two-counter machine with commands from the set  is a sequence
 such that the following hold.
\begin{enumerate}
\item .
\item For all , let  and . Then, the following hold.
\begin{itemize}
\item If  is an  command (resp. ), then ,  (resp. , ), and .
\item If  is a  command (resp. ), then ,  (resp. , ), and .
\item If  is a  command, then , , and .
\item If  is an  command, then , , and  if , and  otherwise.
\item If  is an  command, then , and  if , and  otherwise.

\item If  is a  command, then . That is, a run does not continue after .
\end{itemize}
\item  such that  is a  command.
\end{enumerate}

Observe that the machine  is deterministic. We say that  0-halts if there exists  that is a  command, such that the run of  ends in .

We say that a sequence of commands  {\em fits} a run , if  is the projection of  on its first component.

We construct from  an  formula  such that  0-halts iff there exists a computation  such that . The idea behind the construction is as follows.  reads computations over the atomic propositions , where  are the commands of . The computation that  reads corresponds to a description of a run of , where every triplet  is encoded as the string . We ensure that computations that satisfy  with value greater than  are such that in every position only a single atomic proposition is true.

\begin{example}
Consider the following machine :
\begin{enumerate}
\item[:] 
\item[:] 
\item[:] 
\item[:] 
\item[:] 
\item[:] 
\item[:] 
\end{enumerate}
The command sequence that represents the run of this machine is

and the encoding of it as a computation is

\end{example}

The formula  ``states'' (recall that the setting is quantitative, not Boolean) the following properties of the computation :
\begin{enumerate}
\item The first configuration in  is the initial configuration of  (, or  in our encoding).
\item The last configuration in  is  (or  in our encoding), where  can be any line whose command is .
\item  represents a legal run of , up to the consistency of the counters between transitions.
\item The counters are updated correctly between configurations.
\end{enumerate}
Properties 1-3 are can easily be specified by a  formulas, such that computations which satisfy properties 1-3 get satisfaction value . Property 4 utilizes the expressive power of , as we now demonstrate.
The intuition behind property 4 is the following. We need to compare the value of a counter before and after a command, such that the formula takes a low value if a violation is encountered, and a high value otherwise. Specifically, the formula we construct takes value  if no violation occurred, and a lower value if a violation did occur.

We start with a simpler case, to demonstrate the point. Let  be a discounting function.
Consider the formula  and the computation . It holds that . Similarly, it holds that . Denote the latter by . Let 
 
We now have that

and observe that the latter is  iff , and is less than  otherwise. This is because  is strictly decreasing, and in particular an injection.

Thus, we can compare counters. To apply this technique to the encoding of a computation, we only need some technical formulas to ``parse'' the input and find consecutive occurrences of a counter.

We now dive into the technical definition of . The atomic propositions are  (where  are the commands of ).
We let

\vspace*{-3mm}
\paragraph*{ForceSingletons:} This formula ensures that for a computation to get a value of more than , every letter in the computation must be a singleton. Formally,


\paragraph*{CheckInit and CheckFinal:}
These formulas check that the initial and final configurations are correct, and that after the final configuration, there are only s.


Let , we define

Note that  also ensures that there counters are 0.

\vspace*{-3mm}
\paragraph*{CheckCmds:} This formula verifies that the local transitions follow the instructions in the counter machine, ignoring the consistency of the counter values, but enforcing that a jump behaves according to the counters.
We start by defining, for every , the formula:

Intuitively, a computation satisfies this formula (i.e., gets value ) iff it reads counter descriptions until the next delimiter, and the next command is .

Now, for every  we define  as follows.
\begin{itemize}
\item If , then .
\item If , then . \footnote{if  then this line can be omitted from the initial machine, so w.l.o.g this does not happen.}
\item If  then
.
\item If  then
.
\item If  we do not really need additional constraints, due to . Thus we have .
\end{itemize}
Finally, we define


\vspace*{-3mm}
\paragraph*{CheckCounters:} This is the heart of the construction. The formula checks whether consecutive occurrences of the counters match the transition between the commands.
We start by defining
 and . Similarly, we have  and .

We need to define a formula to handle some edge cases. 

Let , and similarly define  and . We define


Intuitively,  holds exactly in the last transition, that is - before the final 0-halting configuration.


Testing the counters involves six types of comparisons: checking equality, increase by 1, and decrease by 1 for each of the two counters. We define the formulas below for these tests. To explain the formulas, consider for example the formula . This formula compares the number of 's in the current configuration, with the number of 's in the next configuration. The comparison is based on the comparison we explained above, and is augmented by some parsing, as we need to reach the next configuration before comparing.
\begin{itemize}
\item 

.

\item 




\item 



\item 



\item 



\item 


\end{itemize}

Now, for every  we define  as follows.
\begin{itemize}
\item If  , we need to make sure the value of the counters do not change. We define\\

\item If , we need to make sure that  increases and  does not change. We define\\

\item If , we define\\

\item If , we define\\

\item If , we define\\

\item If  we do not need additional constraints, due to . Thus we have .
\end{itemize}
Finally, we define


The correctness of the construction is obvious, once one verifies that the defined formulas indeed test what they claim to.
Thus, we conclude that  0-halts iff there exists a computation  such that . 

Finally, we reduce the -co-validity problem to the complement of the validity problem: given a formula , the reduction outputs . Now, there exists a computation  such that  iff there exists a computation  such that , iff 
it is not true that  for every computation . Thus,  is -co-valid iff  is not valid for threshold . We conclude that the validity problem is undecidable.

\end{proof}


Studying the proof of Theorem~\ref{thm:UndecidableAverage}, we can actually formulate the reduction more carefully as follows.
\begin{lemma}
\label{lem:reductionProperties}
Given a two-counter machine  that is promised to either -halt, or not to halt at all, there exists an  formula  such that for every computation  that represents a computation of , the following hold.
\begin{enumerate}
\item If  is a legal halting computation of , then .
\item If  cheats in a transition between commands, then .
\item If  cheats in the counter values, then  such that  for the minimal difference  where  is a counter value in .

\end{enumerate}

\end{lemma}

We now turn to show that the {\em strict} model-checking problem and the {\em strict} model-checking problem are undecidable for  as well. The strict model-checking problem is to decide, given a Kripke structure , a formula , and a threshold , whether .



\begin{theorem}
\label{thm:strict model checking und}
The strict model-checking problem for  is undecidable (for every nonempty set of Discounting functions ).
\end{theorem}
\begin{proof}
Assume by way of contradiction that the strict model-checking problem is decidable. We show how to decide the -halting promise problem for two-counter machines, thus reaching a contradiction.

Given a two-counter machine  that is promised to either -halt, or not halt at all, construct the formula  as per Lemma~\ref{lem:reductionProperties}, and consider the Kripke structure  that generates every computation. Observe that by Lemma~\ref{lem:reductionProperties} it holds that .

Decide whether . If , then for every computation  it holds that , and by Lemma~\ref{lem:reductionProperties} we conclude that  does not halt.

If , then . We observe that there are now two possible cases:
\begin{enumerate}
\item  halts.
\item  does not halt, and for every , there are computations that reach  while cheating in counter values larger than , and not cheating in the commands.
\end{enumerate}


We show how to distinguish between cases 1 and 2.

Consider the  formula 


It is not hard to verify that for every computation  that represents a computation of , it holds that , where .
Let . 

If  halts (case 1), then for every computation  we have one of the following.
\begin{itemize}
\item[a.]  describes a legal halting run of , in which case  and  for some  (independent of ), since the counters are bounded. Thus, .
\item[b.]  cheats in the commands, in which case , so .
\item[c.]  cheats in the counters, in which case, since the counters are bounded, the first cheat must occur with small counters, and thus  for some  independent of . So .
\end{itemize}
In all three cases, we get that , so .

If  does not halt (case 2), then for every  and for every computation  that cheats with counters larger than , it holds that  where  as , and since the counters in  are large, it also holds that , where  as . We conclude that there exists a sequence of computations whose satisfaction values in  tend to , and thus .

Thus, in order to distinguish between cases 1 and 2, it is enough to decide whether .  

To conclude, the algorithm for deciding whether  0-halts is as follows.
Start by constructing . If , then  does not halt. Otherwise, construct . If , then  halts, and otherwise  does not halt.
\end{proof}

\begin{theorem}
\label{thm:model checking und}
The model-checking problem for  is undecidable (for every nonempty set of Discounting functions ).
\end{theorem}
\begin{proof}
Recall that for every Kripke structure  and formula  it holds that  iff there does not exist a computation  of  such that . 

We show that the latter problem is undecidable, even if we fix  to be the system that generates every computation. 

We show a reduction from the -halting promise problem to the latter problem.
Given a two-counter machine  that is promised to either -halt, or not halt at all, construct the formula  as per Lemma~\ref{lem:reductionProperties} and the formula  such that for every computation  we have that , where . The formula  can be defined as
.

Let . We claim that  halts iff there exists a computation  such that .

If  halts, then for the computation  that describes the halting run of  it holds that , and thus . Since the counters in  are bounded (as the run is halting), then , and thus .

If  does not halt, consider a computation .
\begin{itemize}
\item If  cheats in the commands, then , so .
\item If  cheats in the counters, then  and , where  for the smallest difference  in . 
Thus, .
\end{itemize}

\end{proof}










\subsection{Adding Unary Multiplication Operators}
\label{subsec: adding unary}
As we have seen in Section~\ref{sec:average}, adding the operator  to  makes model checking undecidable. One may still want to find propositional quality operators that we can add to the logic preserving its decidability. In this section we describe one such operator. We extend  with the operator , for , with the semantics . This operator allows the specifier to manually change the satisfaction value of certain subformulas. This can be used to express importance, reliability, etc. of subformulas. For example, in , we limit the satisfaction value of computations in which a response is given with a delay to .

Note that the operator  is similar to a one-time application of
, thus  is equivalent to . In practice, it is better to handle  formulas directly, by adding the following transitions to the construction in the proof of Theorem~\ref{thm:DLTL to AWW}.

\hspace{-.6cm}

\vspace*{-3mm}
\section{Extensions}\label{sec:ext}

\subsection{ with Past Operators}
\label{ext:past}
One of the well-known augmentations of  is the addition of {\em past operators\/} \cite{LPZ85}. These operators enable the specification of exponentially more succinct formulas, while preserving the PSPACE complexity of model checking.
In this section, we add {\em discounting-past} operators to , and show how to perform model-checking on the obtained logic.

We add the operators , , and  (for ) to , and denote the extended logic , with the following semantics. For  formulas , a function , a computation , and an index , we have
\begin{itemize}
\item  if , and  otherwise.
\item .
\item .
\end{itemize}
Observe that since the past is finite, then the semantics for past operators can use  and  instead of  and . 

As in , our solution for the  model-checking problem is by translating  formulas to automata. The construction extends the construction for the Boolean case, which uses 2-way weak alternating automata (). The details of the construction appear in Appendix~\ref{apx:LTL with past}. The use of the obtained automata in decision procedures is similar to that in Section~\ref{sec:alg proc}. In particular, it follows that the model-checking problem for  with exponential discounting is in PSPACE.


\subsection{Weighted Systems}
\label{wsys}
A central property of the logic  is that the verified system need not be weighted in order to get a quantitative satisfaction -- it stems from taking into account the delays in satisfying the requirements. Nevertheless,   also naturally fits weighted systems, where the atomic propositions have a value between  and .


A {\em weighted Kripke structure} is a tuple , where , and  are as in Boolean Kripke structures, and  maps each state to a weighted assignment to the atomic propositions. Thus, the value  of an atomic proposition  in a state  is a value in . The semantics of  with respect to a weighted computation coincides with the one for non-weighted systems, except that for an atomic proposition , we have that .

It is possible to extend the construction of  described in Section~\ref{sec:DltlToAww} to an alphabet , where  is a set of possible values for the atomic propositions. Indeed, we only have to adjust the transition for states that correspond to atomic propositions, as follows: for , , and , we have that

\noindent {\labelitemi}~
\hspace{.6cm}
\noindent {\labelitemi}~

\subsection{Changing the Tendency of Discounting}\label{sec:DiscountingTendency}
One may observe that in our discounting scheme, the value of future formulas is discounted toward . This, in a way, reflects an intuition that we are pessimistic about the future, or at least we are impatient. While in some cases this fits the needs of the specifier, it may well be the case that we are ambivalent to the future. To capture this notion, one may want the discounting to tend to . Other values are also possible. For example, it may be that we are optimistic about the future, say when a system improves its performance while running and we know that components are likely to function better in the future. We may then want the discounting to tend, say, to . 

To capture this notion, we define the operator , parameterized by 
 and , with the following semantics.
\\ 
The discounting function  determines the rate of convergence, and  determines the limit of the discounting. The longer it takes to fulfill the ``eventuality'', the closer the satisfaction value gets to .
We observe that .
\begin{example}
Consider a process scheduler. The scheduler decides which process to run at any given time. The scheduler may also run a defragment tool, but only if it is not in expense of other processes. This can be captured by the formula . Thus, the defragment tool is a ``bonus'': if it runs, then the satisfaction value is above , but if it does not run, the satisfaction value is . Treating  as ``good'' and  as ``bad'' means that  is ambivalent.
\end{example}



We claim that Theorem~\ref{thm:DLTL to AWW} holds under the extension of  with the operator .
Indeed, the construction of the  is augmented as follows. For , denote  by . One may observe that the conditions on  correspond to conditions on  when dealing with . Accordingly, the transitions from the state  are defined as follows.

First, if , then  and we identify the state  with the state
. Otherwise,  and we define:
\begin{itemize}
\item

 0\le \tau< 1\tau \geq 1\tau < 0

\item

0< \tau\le 1\tau > 1\tau \le 0
\end{itemize}
The correctness of the construction is proved in Appendix~\ref{apx:disc tendency proof}.




\section{Discussion}

An ability to specify and to reason about quality would take formal methods a significant step forward. 
Quality has many aspects, some of which are propositional, such as prioritizing one satisfaction scheme on top of another, and some are temporal, for example having higher quality for implementations with shorter delays. In this work we provided a solution for specifying and reasoning about temporal quality, augmenting the commonly used linear temporal logic (LTL). A satisfaction scheme, such as ours, that is based on elapsed times introduces a big challenge, as it implies infinitely many satisfaction values. Nonetheless, we showed the decidability of the model-checking problem, and for the natural exponential-decaying satisfactions, the complexity remains as the one for standard LTL, suggesting the interesting potential of the new scheme. As for combining propositional and temporal quality operators, we showed that the problem is, in general, undecidable, while certain combinations, such as adding priorities, preserve the decidability and the complexity.

\gap\noindent
{\bf Acknowledgement.} We thank Eleni Mandrali for pointing to an error in an earlier version of the paper.
\tiny
\bibliography{../ok}
\normalsize

\newpage
\appendix
\section{Proofs}

\subsection{Proof of Lemma~\ref{lem:LTL for positive}}

We construct  and  by induction on the structure of  as follows. In all cases but the  case we do not use the assumption that  and prove an ``iff'' criterion. 
\begin{itemize}
\item If  is of the form , or , for an atomic proposition , then  and . Correctness is trivial.

\item If  is of the form , then   and . Indeed, for every computation  we have that  iff either  or , and   iff both  and .

\item If  is of the form , then  and . Correctness is trivial.


\item If  is of the form , then  and . 

We start with . For every computation  we have that  iff there exists  such that  and for every  it holds that . This happens iff  satisfies . 

Before we turn to the case of , let us note that
readers familiar with the release () operator of  may find it clearer to observe that , which perhaps gives a clearer intuition for the correctness of the construction.

Now, if , then for every  it holds that either  or  for some . Thus, for every , either , or  for some . So for every , either , or  for some . It follows that . Equivalently, .

Conversely, if  and , then , so for every , either  or  for some . By the induction hypothesis, for every , either  or  for some . We now use the assumption that  to observe that the  in the expression for  is attained as a , as there are only finitely many distinct suffixes for  (namely ). Thus, since all the elements in the  are strictly smaller than , we conclude that .


\item  If , then  and . Again, correctness is trivial.

\item
If  for , then
. Indeed, since  for all , then 
.

Now,  is defined as follows. First, if , then . If , then . Indeed, since  is strictly decreasing, the only chance of  to have  is when both  and . Since a satisfaction value cannot exceed , the latter happens iff  and  (where the ``only if'' direction is valid when  is a lasso, as is assumed). 

\end{itemize}

Finally, it is easy to see that  and  are both .


\subsection{The standard translation of  to }
\label{apx: standard LTL to AWW}
For completeness, we bring here the construction of the translation from  to , which we use in Theorem~\ref{thm:DLTL to AWW}. For the correctness proof, see e.g.~\cite{Var96}.

Given an \LTL formula  over the atomic propositions , we construct an \AWW  as follows. The state space  consists of all the subformulas of , and their negations (we identify  with ). The initial state is , and the accepting states are all the formulas of the form . It remains to define the transition function.

We start with a few notations. For a Boolean formula  over , we define its {\em dual formula}  by induction over the construction of , as follows.
\begin{itemize}
\item For  we have .
\item  and .
\item  and 
\end{itemize}
The transition function can now be defined as follows. Let  and .
\begin{itemize}
\item If , then 
\item If , then ,
\item If , then ,
\item If , then ,
\item If , then .
\end{itemize}


\subsection{Continuation of the Proof of Theorem~\ref{thm:DLTL to AWW}}
We continue the proof that is given in the main text, showing that the constructed   is indeed finite and correct.

We first make some notations and observations regarding the structure of . For every state  (resp. ) we refer to  and  as the state's {\em formula} and {\em threshold}, respectively. If the outermost operator in  is a discounting operator, then we refer to its discounting function as the state's {\em discounting function}. For states of Type-2 we refer to their {\em formula} only (as there is no threshold).

First observe that the only cycles in  are self-loops. Indeed, consider a transition from state  to state . Let  be the formulas of  and , respectively.
Going over the different transitions, one may see that either  is a strict subformula of , or  is a Type-2 state, or both  and  have an outermost discounting operator with discounting functions  and  respectively. By induction over the construction of , this observation proves that there are only self-cycles in .

We now observe that in every run of  on an infinite word , every infinite branch (i.e., a branch that does not reach ) must eventually be in a state of the form , ,  or  (if it's a Type-2 state). Indeed, these states are the only states that have a self-loop, and the only cycles in the automaton are self-loops.

We start by proving that there are finitely many states in the construction. First, all the sub-automata that correspond to Type-2 states have  states. This follows immediately from Lemma~\ref{lem:LTL for positive} and from the construction of an  from an  formula.

Next, observe that the number of possible state-formulas, up to differences in the discounting function, is . Indeed, this is simply the standard closure of . It remains to prove that the number of possible thresholds and discounting functions is finite.

We start by claiming that for every threshold , there are only finitely many reachable states with threshold . Indeed, for every discounting function  (that appears in ), let . The value of  is defined, since the functions tend to . Observe that in every transition from a state with threshold , if the next state is also with threshold , then the discounting function (if relevant) is either some , or . There are only finitely many functions of the former kind. As for the latter kind, after taking   times, we have that . By the definition of , in this case the transitions are to the Boolean-formula states (i.e., , or some ), from which there are finitely many reachable states. We conclude that for every threshold, there are only finitely many reachable states with this threshold.

Next, we claim that there are only finitely many reachable thresholds. This follows immediately from the claim above. We start from the state . From this state, there are only finitely many reachable discounting functions. The next threshold that can be encountered is either , or  for  that is either in  or one of the  for . Thus, there are only finitely many such thresholds. Further observe that if a different threshold is encountered, then by the definition of , the state's formula is deeper in the generating tree of . Thus, there are only finitely many times that a threshold can change along a single path. So by induction over the depth of the generating tree, we can conclude that there are only finitely many reachable thresholds.

We conclude that the number of states of the automaton is finite.

Next, we prove the correctness of the construction. From Lemma~\ref{lem:LTL for positive} and the correctness of the standard translation of  to , it remains to prove that for every path  and for every state  (resp. ):
\begin{enumerate}
\item If  (resp. ), then  is accepted from  (resp. ).
\item If  and  is accepted from state  (resp. ) then  (resp. ).
\end{enumerate} 

The proof is by induction over the construction of , and is fairly trivial given the definition of .




\subsection{Proof of Lemma~\ref{lem:DLTL to NBW}}
We start by defining {\em generalized B\"uchi automata}. An  is , where  are as in . The acceptance condition is  where  for every . A run  of  is accepting if for every ,  visits  infinitely often.

We now proceed with the proof.

Consider the   obtained from  using the construction of Section~\ref{sec:DltlToAww}.

In the translations of  to  using the method of~\cite{GO01}, the  is translated to an  whose states are the subset-construction of the .
This gives an exponential blowup in the size of the automaton. We claim that in our translation, we can, in a sense, avoid this blowup.

Intuitively, each state in the  corresponds to a conjunction of states of the . Consider such a conjunction of states of . If the conjunction contains two states  and , and we have that , then by the correctness proof of Theorem~\ref{thm:DLTL to AWW}, it holds that a path  is accepted from both states, iff  is accepted from . Thus, in every conjunction of states from , there is never a need to consider a formula with two different ``'' thresholds. Dually, every formula can appear with at most one ``'' threshold.

Next, consider conjunctions that contain states of the form  and . Again, since the former assertion implies the latter, there is never a need to consider two such formulas. Similar observations hold for the other discounting operators.

Thus, we can restrict the construction of the  to states that are conjunctions of states from the , such that no discounting operator appears with two different ``offsets''.

Further observe that by the construction of the , the threshold of a discounting formula does not change, with the transition to the same discounting formula, only the offset changes. That is, from the state , every reachable state whose formula is  has threshold  as well. Accordingly, the possible number of thresholds that can appear with the formula  in the subset construction of , is the number of times that this formula appears as a subformula of , which is .

We conclude that each state of the obtained  is a function that assigns each subformula\footnote{where a subformula may have several occurences, e.g., in the formula  we have two occurences of the subformula } of  two thresholds.
The number of possible thresholds and offsets is linear in the number of states of , thus, the number of states of the  is .

Finally, translating the  to an  requires multiplying the size of the state space by , so the size of the obtained  is also .


\subsection{Proof of Theorem~\ref{thm: exp disc to AWW}}
We construct an \AWW  as per Section~\ref{sec:DltlToAww}, with some changes.

Recall that the ``interesting'' states in  are those of the form .
Observe that for the function  it holds that . Accordingly, we can replace a state of the form  with the state , as they express the same assertion.
Finally, notice that . Thus, we can simplify the construction of  with the following transitions:

Let , then we have that
\begin{itemize}
\item
\\0<t< 1t \geq 1t=0


\item
\\0<t\le 1t> 1t=0

\item
\\0<t< 1t \geq 1t=0

\item
\\0<t\le 1t> 1t=0
\end{itemize}

The correctness and finiteness of the construction follows from Theorem~\ref{thm:DLTL to AWW}, with the observation above. We now turn to analyze the number of states in .

For every state  (resp. ) we refer to  and  as the state's {\em formula} and {\em threshold}, respectively. Observe that the number of possible state-formulas is .
Indeed, the formulas in the states are either in the closure of , or are of the form , where  is in the closure of . This is because in the new transitions we do not carry the offset, but rather change the threshold, so the state formula does not change.

It remains to bound the number of possible thresholds.
Consider a state with threshold . In every succeeding state\footnote{This is almost correct. In fact, since  is defined inductively, we may go through several transitions.}, the threshold (if exists) can either remain , or change to  (in case of negation), or , where , providing .

Initially, we ignore negations. In this case, the number of states that can be reached from a threshold  is bounded by the size of the set

This length of the products can be bounded by , where . Thus, the number of possible values is bounded by .
From here we denote  by .

Next, we consider negations. Observe that in every path, there are at most  negations. In every negation, if the current state has threshold , the threshold changes to . We already proved that from threshold  we can get at most  states. Furthermore, every such state has a threshold of the form

where  (we allow 1 instead of allowing shorter products).

Consider a negation state with threshold . If  then in the next state the threshold is , and every reachable state is part of a Boolean  corresponding to an  formula, and thus has polynomially many reachable states.

Otherwise, we have that . Denote , and assume that  can be written as  and for all ,  (which is possible as they are in ), then we have that

 ,
where the last transition is because .

Let , we now observe that


where the last transitions are because all the numbers are natural, and , so the numerator must be a positive integer.
From this we get that

We see that we can bound  from below by a rational number whose representation is linear in that of  and . Denote this linear function by .
Thus, continuing in this manner through  negations, starting from the threshold , we have that the number of thresholds reachable from every state is bounded by

which is single exponential in  and the description of .

We conclude that the number of states of the automaton is single-exponential.


\subsection{Proof of Theorem~\ref{thm:synthesis}}
\label{apx: synthesis}
Recall that if  is a computation such that , hen  accepts . The converse however, is not true. Still, by carefully examining the construction in Theorem~\ref{sec:DltlToAww}, we observe that if  accepts a computation , then  (note the non-strict inequality). 

Assume a partition of the letters in  to input and output signals, denoted  and , respectively. By following standard (Boolean) procedures for synthesis (see \cite{PR89a}), we can generate from  a deterministic tree automaton  that accepts a -labeled -tree iff all the paths along the tree are accepted in . A tree that is accepted in this manner represents a transducer that realizes  with value at least . Accordingly, if there exists a transducer , all of whose computations satisfy , then the tree that represents such a transducer is accepted in . Thus, the language of  is non-empty, and a non-emptiness witness is a transducer (tree) , all of whose computations 
satisfy .



We remark that this solution is only partial, as there might be an -transducer whose computations  all satisfy , but we will not find it. 



\subsection{Translating  formulas to }
\label{apx:LTL with past}
As we now show, the construction we use when working with the ``infinite future''  operator is similar to that of the one we use for the ``finite past''  operator.
The key for this somewhat surprising similarity is the fact our construction is based on a threshold. Under this threshold, we essentially bound the future that needs to be considered, thus the fact that it is technically infinite plays no role.









A  is a tuple  where  are as in . The transition function is . That is, positive Boolean formulas over atoms of the form , describing both the state to which the automaton moves and the direction in which the reading head proceeds.


As in , the construction extends the construction for the Boolean case. 
It is not hard to extend Lemma~\ref{lem:LTL for positive} and generate Boolean PLTL formulas for satisfaction values in . 

Given a  formula  and a threshold , we construct a  as in
Theorem~\ref{thm:DLTL to AWW} with the following additional transitions:\footnote{In addition, the atoms in the transitions in Theorem~\ref{thm:DLTL to AWW} are adjusted to the  syntax by replacing each atom  by the atom .}.
\begin{itemize}
\item 
\item .
\item .
\item .

\item 
\\ \spb
0<\frac{t}{\df(0)}< 1\frac{t}{\df(0)} \geq 1\frac{t}{\df(0)}=0

\item 
\\ \spb
0<\frac{t}{\df(0)}\le 1\frac{t}{\df(0)} > 1\frac{t}{\df(0)}=0
\end{itemize}



The correctness of the construction and the analysis of the blowup
are similar to those in Section~\ref{sec:alg proc}. 


\subsection{Correctness Proof of the Construction in Section~\ref{sec:DiscountingTendency}}
\label{apx:disc tendency proof}
Consider the case of  (the dual case is similar). We check when this assertion holds.

First, if , then this assertion is equivalent to  (this follows directly from the semantics).
Thus, assume that .

If , then , so in particular, for every value of , it holds that , so the assertion is true, since the first operand in the  is greater than .

If  then , so both
 and . Thus, every operand in the  has an element less than , so the  cannot be greater than , so the assertion is false.

If , then similarly to the case of  - the assertion is equivalent to the following: either , or both  and .


It remains to show that there are still only finitely many states. Since , we get that 
Thus, after a certain number of transitions,  takes a value that is not in , in which case the next state is  or , so the number of states reachable from  is finite.

We remark that this is not true if , which is why we needed to treat this case separately.
\end{document}
