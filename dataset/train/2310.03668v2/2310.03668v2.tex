
\documentclass{article} \usepackage{iclr2024_conference,times}
\usepackage{graphicx}
\usepackage{scalerel} 


\usepackage{amsmath,amsfonts,bm}

\newcommand{\figleft}{{\em (Left)}}
\newcommand{\figcenter}{{\em (Center)}}
\newcommand{\figright}{{\em (Right)}}
\newcommand{\figtop}{{\em (Top)}}
\newcommand{\figbottom}{{\em (Bottom)}}
\newcommand{\captiona}{{\em (a)}}
\newcommand{\captionb}{{\em (b)}}
\newcommand{\captionc}{{\em (c)}}
\newcommand{\captiond}{{\em (d)}}

\newcommand{\newterm}[1]{{\bf #1}}


\def\figref#1{figure~\ref{#1}}
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
\def\secref#1{section~\ref{#1}}
\def\Secref#1{Section~\ref{#1}}
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
\def\eqref#1{equation~\ref{#1}}
\def\Eqref#1{Equation~\ref{#1}}
\def\plaineqref#1{\ref{#1}}
\def\chapref#1{chapter~\ref{#1}}
\def\Chapref#1{Chapter~\ref{#1}}
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
\def\algref#1{algorithm~\ref{#1}}
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
\def\partref#1{part~\ref{#1}}
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}

\def\eps{{\epsilon}}


\def\reta{{\textnormal{}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}

\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

\newcommand{\pdata}{p_{\rm{data}}}
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}

\newcommand{\laplace}{\mathrm{Laplace}} 

\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}

\newcommand{\parents}{Pa} 

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Tr}{Tr}
\let\ab\allowbreak
 \usepackage{hyperref}
\usepackage{url}
\usepackage{arydshln}
\usepackage{color}
\usepackage{colortbl}
\usepackage{booktabs}
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{wrapfig}

\usepackage[symbol]{footmisc}





\newcommand{\GoLLIE}{\scalerel*{\includegraphics{logo/GoLLIE.pdf}}{\textrm{\textbigcircle}} }

\newcommand{\GoLLIET}{\scalerel*{\includegraphics{logo/GoLLIE.pdf}}{\textrm{\textbigcircle}} GoLLIE}




\newcommand\nolinkthanks[1]{\begin{NoHyper}\thanks{#1}\end{NoHyper}}

\newcommand\nolinkmark{\begin{NoHyper}\footnotemark[1]\end{NoHyper}}







\title{\scalerel*{\includegraphics{logo/GoLLIE.pdf}}{\textrm{\textbigcircle}} GoLLIE: Annotation Guidelines improve\\ Zero-Shot Information-Extraction}






\author{Oscar Sainz\nolinkthanks{Equal contribution}\:, \: Iker Garc√≠a-Ferrero\nolinkmark  \\
\textbf{Rodrigo Agerri, \: Oier Lopez de Lacalle, \: German Rigau, \: Eneko Agirre} \\
HiTZ Basque Center for Language Technology - Ixa NLP Group \\
University of the Basque Country (UPV/EHU)\\
\texttt{\{oscar.sainz, iker.garciaf\}@ehu.eus} \\
}



\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy \begin{document}


\maketitle

\begin{abstract}
Large Language Models (LLMs) combined with instruction tuning have made significant progress when generalizing to unseen tasks. However, they have been less successful in Information Extraction (IE), lagging behind task-specific models. Typically, IE tasks are characterized by complex annotation guidelines which describe the task and give examples to humans. 
Previous attempts to leverage such information have failed, even with the largest models, as they are not able to follow the guidelines out-of-the-box. 
In this paper we propose GoLLIE (\textbf{G}uideline-f\textbf{o}llowing \textbf{L}arge \textbf{L}anguage Model for \textbf{IE}), a model able to improve zero-shot results on unseen IE tasks by virtue of being fine-tuned to comply with  annotation guidelines.
Comprehensive evaluation empirically demonstrates that GoLLIE is able to generalize to and follow unseen guidelines, outperforming previous attempts at zero-shot information extraction. The ablation study shows that detailed guidelines is key for good results. Code, data and models are publicly available: \url{https://github.com/hitz-zentroa/GoLLIE}. 

\end{abstract}


























\section{Introduction}
\begin{figure}[b]
    \centering
    \includegraphics[width=1.0\linewidth]{images/zero_shot_results.pdf}
    \caption{Out of domain zero-shot NER results. GPT results are not  available for all domains.}
    \label{fig:zero-shot-results}
\end{figure}

The task of Information Extraction (IE) is highly challenging. This challenge is evident in the detailed guidelines, which feature granular definitions and numerous exceptions, that human annotators must follow to perform the task. The performance of current state-of-the-art models heavily depends on the quantity of human-annotated data, as the model learns the guidelines from these examples. However, this performance significantly decreases when tested in new annotation schema \citep{DBLP:conf/aaai/Liu0YDJCMF21}. The common practice in IE to achieve good results is to manually annotate in each new domain and schema from scratch, as almost no transfer exists across application domains. Unfortunately, this is unfeasible, both, in terms of financial cost and human effort.


Recent advancements in Large Language Models (LLM) \citep{10.1145/3605943} have enabled the development of models capable of generalizing to unseen tasks. Thus, current zero-shot IE systems leverage the knowledge encoded in LLMs to annotate new examples \citep{sainz-etal-2022-textual,DBLP:journals/corr/abs-2304-08085}. As a by product of the pre-training process, models possess now a strong representation of what a person or an organization is. Therefore, they can be prompted to extract mentions to those categories from a text. However, this has a clear limitation: not every annotation schema\footnote{We define schema as the set of labels and their definitions.} defines "person" (or any other label) in the same way. For example, ACE05~\citep{ACE} annotates pronouns as persons, while, CoNLL03 \citep{tjong-kim-sang-de-meulder-2003-introduction} does not. IE tasks require more information than just label names, they require annotation guidelines. 

Current LLMs have been trained to follow instructions, but they fail to follow annotation guidelines out-of-the-box. 
For instance, Figure \ref{fig:zero-shot-results} shows results on domain specific zero-shot Named Entity Recognition. The results of gpt-3.5-turbo when prompted with guidelines  \citep{ashok2023promptner} are low, around 20 F1 score on Music or Politics domains. Building a system that enables high-performance zero-shot information extraction, reducing the dependence on costly human annotations, remains an open challenge.  

In this work, we present \GoLLIE GoLLIE  (\textbf{G}uideline-f\textbf{o}llowing \textbf{L}arge \textbf{L}anguage Model for \textbf{IE}), a LLM fine-tuned to learn how to attend to the guidelines on a small set of well known IE tasks. Comprehensive zero-shot evaluation empirically demonstrates that GoLLIE outperforms the state-of-the-art~\citep{DBLP:journals/corr/abs-2304-08085}  in zero-shot information extraction (see Figure \ref{fig:zero-shot-results}). 













\section{Related Work}
Large Language Models (LLMs) have made significant advancements toward the development of systems that can generalize to unseen tasks~\citep{10.1145/3605943}. \citet{radford2019language} trained a series of LLMs using a vast amount of internet data. They discovered that, during inference, pretrained models given natural language task descriptions can perform tasks such as question answering, machine translation, reading comprehension, and summarizing without explicit supervision. Building on this discovery, instruction tuning, often referred to as multitask fine-tuning, has emerged as the leading method to achieve generalization to unseen tasks. This process involves pre-training a model on a massive amount of unlabeled data and subsequently fine-tuning it on a diverse collection of tasks \citep{DBLP:conf/emnlp/WangMAKMNADASPK22,DBLP:journals/corr/abs-2210-11416} phrased as text-to-text problems \citep{DBLP:journals/jmlr/RaffelSRLNMZLL20}. A natural language instruction or prompt is given to the model to identify the task it should solve \citep{DBLP:conf/eacl/SchickS21,DBLP:conf/naacl/ScaoR21}. Research has demonstrated that increasing the parameter count of the language model \citep{DBLP:conf/nips/BrownMRSKDNSSAA20}, coupled with improvements in the size and quality of the instruction tuning dataset, results in enhanced generalization capabilities \citep{DBLP:journals/corr/abs-2302-12692,DBLP:journals/corr/abs-2205-01068,DBLP:journals/corr/abs-2204-02311,DBLP:conf/acl/MuennighoffWSRB23,DBLP:journals/corr/abs-2302-13971,DBLP:journals/corr/abs-2307-09288}. LLMs have displayed impressive zero-shot generalization capabilities in various challenging tasks, including coding \cite{wang2021gpt,black-etal-2022-gpt,DBLP:journals/corr/abs-2308-12950}, common sense reasoning \cite{DBLP:journals/corr/abs-2302-13971}, and medical applications \cite{singhal2023large}, among others. 

In the field of Information Extraction (IE), recent shared tasks \citep{DBLP:conf/semeval/FetahuKCRM23} have shown that encoder-only language models such as XLM-RoBERTa \citep{DBLP:conf/acl/ConneauKGCWGGOZ20} and mDEBERTA \citep{DBLP:conf/iclr/HeGC23} remain the most effective models. Attempts to utilize LLMs and natural language instructions for IE have been less successful \citep{DBLP:conf/semeval/TanHJCL0ZTXH23,DBLP:journals/corr/abs-2308-03279,DBLP:journals/corr/abs-2305-12217}, as their performance lags behind that of encoder-only models. To adapt the instruction-tuning paradigm for the IE field, \cite{sainz-etal-2021-label, sainz-etal-2022-textual, sainz-etal-2022-zs4ie} proposed reformulating various IE tasks into an entailment task. This approach has shown success in relation and event extraction in a few-shot setting, thus reducing the need for manual annotations. \cite{DBLP:conf/acl/0001LDXLHSW22} introduced a unified text-to-structure generation that can model different IE tasks universally. \cite{DBLP:conf/aaai/Lou0DJLH0023} proposed converting IE tasks to a semantic matching problem, allowing their method to generalize successfully to new domains and label ontologies not seen during training. \cite{DBLP:journals/corr/abs-2304-08085} framed IE tasks as natural language descriptive instructions and trained an LLM across a diverse range of IE tasks. In evaluations on tasks with unseen label ontologies, their model outperformed other instruction-tuning methods. 

Most instruction tuning attempts for IE share a limitation: they only consider label names in the prompts (e.g., \textit{"List all the Persons in the following sentence"}). This poses two major challenges. Firstly, not all datasets share the same definition for labels like \textit{Person} (some exclude fictional characters or pronouns). Secondly, a label name alone doesn't sufficiently describe complex or less common labels. While there have been attempts to prompt LLMs using guidelines~\citep{DBLP:journals/corr/abs-2305-12217}, strong prior knowledge of LLMs regarding task labels \citep{DBLP:conf/acl/BlevinsGZ23} deter the model from learning to adhere to those guidelines. 


\section{Approach}

Different from previous approaches, \GoLLIE GoLLIE forces the model to attend to the details in the guidelines, performing robustly on schemas not seen during training. On this section we deep dive into the details of our approach, describing how the input and output was represented and the regularization techniques used to force the model to attend to the guidelines.

\subsection{Input-output representation}

\begin{figure}
    \centering
    \includegraphics[width=0.95\linewidth]{images/input-output_representation.pdf}
    \caption{Example of the input and output of the model.}
    \label{fig:input-output}
\end{figure}

We have adopted a Python code-based representation~\citep{wang-etal-2023-code4struct, li-etal-2023-codeie} for both the input and output of the model. This approach not only offers a clear and human-readable structure but also addresses several challenges typically associated with natural language instructions. It enables the representation of any information extraction task under a unified format. The inputs can be automatically standardized using Python code formatters such as Black. The output is well-structured and parsing it is trivial. Furthermore, most current LLMs incorporate code in their pretraining datasets, indicating that these models are already familiar with this representation.

Figure~\ref{fig:input-output} shows the three main parts of the format: schema definition, input text and output annotations. \textbf{Schema definition} forms the initial segment of the input. This section contains the information about the labels which are represented as Python classes; guidelines, articulated as docstrings; and representative annotation candidates presented in the form of code comments. The number of class definitions corresponds to the number of labels in the dataset. Classes are flexible and vary for each task. For example, classes for a NER dataset merely require an attribute to specify the text span that correspond to the class. On the other side, more complex tasks such as Event Argument Extraction (EAE) or Slot Filling (SF) demand more class attributes to categorize the task, such as a list of participants in an event (refer to examples in Appendix~\ref{ap:repr_examples}). \textbf{Input text} is the second part of the input. The input text is represented as an string variable in Python. \textbf{Output annotations} is the part generated by the model. The model starts generating after \texttt{result =}. The annotations are represented as a list of instances of the classes defined on the schema definition part. Parsing the output is straightforward; executing the generated code in Python yields a list containing the result. This ease of parsing the output stands as a significant advantage of our model.


\subsection{Guidelines enhanced representation}

\begin{figure}
    \centering
    \includegraphics[width=0.95\linewidth]{images/guideline_example.pdf}
    \caption{Example of the input representation. (left) An example of an event definition w/o guidelines information. (right) The same example but with guideline information as Python comments.}
    \label{fig:guidelines-example}
\end{figure}

The main contribution of this work is the use of the guidelines as part of the inference process to improve the zero-shot generalization. An example of a class definition with and without guidelines is shown in the Figure~\ref{fig:guidelines-example}. Different datasets usually define guidelines on many different ways: some provides a complex definition of a label with several exceptions and special treatments and others just give a few representative candidates of the fillers of the label. To normalize the input format, we included the label definitions as class docstrings and the candidates as a comment for the principal argument (which is usually \textit{mention} or \textit{span}). Complex tasks such as EAE or SF requires additional definitions for the arguments or slots, to that end,  we included small definitions as comments on each class argument. In this paper, we will refer to the model without guidelines as Baseline and the model with guidelines as \GoLLIET.

\subsection{Training regularization}
\label{sec:components}

We want to ensure that the model follows the guidelines and does not just learn to identify specific datasets and perform correctly on them. To do this, we introduce various kinds of noise during training. This stops the model from recognizing particular datasets, recalling specific labels, or attending only to the label names rather than learning to follow the actual description for each label in the guidelines.


We applied the following regularizations. \textbf{Class order shuffling}, for each example, the order of the input classes is randomly shuffled. This makes it more difficult for the model to memorize entire task definitions. \textbf{Class dropout}, we delete some of the input classes randomly. By eliminating few classes from both the input and output, we force the model to learn to only output instances of classes defined in the input. This not only encourages the model to focus on the schema definition but also minimizes the occurrence of hallucinations during inference. \textbf{Guideline paraphrasing}, we generate variations of the label definitions to prevent the model from easily memorizing them. We also think this will make the method more robust to different variations on the definition. \textbf{Representative candidate sampling}, similar to what we do with the paraphrases, for each input we sample 5 different candidates from a fixed pool of 10 per class. \textbf{Class name masking} involves substituting the label class names (e.g., \textsc{Person}) with placeholders, such as \textsc{LABEL\_1}. This prevents the model from exploiting the label names during training, and forces it to attend and understand the guidelines. 


\section{Experimental Setup}

\subsection{Data}

Evaluating zero-shot capabilities requires dividing the data into training and evaluation datasets. However, many benchmarks for Information Extraction are based on the same domain or share part of their schema. To ensure that the zero-shot evaluation is not affected by similar data, we have divided our set of benchmarks based on the domain of the data. For training we kept mostly datasets from \textbf{News and Biomedical} domains, for evaluation instead, we used datasets from \textbf{diverse domains}. This approach helps to avoid introducing any noise into the evaluation process. Among the evaluation datasets we included CrossNER~\citep{liu2021crossner}, a dataset that is split into many domains, for simplicity, we will call each domain as a separate dataset: AI, Literature, Music, Politics and Science. Also, we will call MIT Movie and MIT Restaurant as Movie and Restaurant. Table~\ref{tab:datasets} contains the information about the data used in the experiments. 

\begin{table}
    \centering
    \caption{Datasets used on the experiments. The table shows the domain, tasks and whether are use for training, evaluation or both.}
    \resizebox{1.\textwidth}{!}{
        \begin{tabular}{l|l|ccccc|cc}
            \multicolumn{8}{c}{} \\
            \toprule
            \textbf{Dataset} & \textbf{Domain} & \textbf{NER} & \textbf{RE} & \textbf{EE} & \textbf{EAE} & \textbf{SF} & \textbf{Training} & \textbf{Evaluation} \\
            \midrule
            ACE05 \citep{ACE} & News & \checkmark & \checkmark & \checkmark & \checkmark & & \checkmark & \checkmark \\
            BC5CDR~\citep{bc5cdr} & Biomedical & \checkmark & & & & & \checkmark & \checkmark \\
            CoNLL 2003~\citep{tjong-kim-sang-de-meulder-2003-introduction} & News & \checkmark & & & & & \checkmark & \checkmark \\
            DIANN~\citep{diann} & Biomedical & \checkmark & & & & & \checkmark & \checkmark \\
            NCBIDisease~\citep{islamaj-dogan-lu-2012-improved} & Biomedical & \checkmark & & & & & \checkmark & \checkmark \\
            Ontonotes 5~\citep{pradhan-etal-2013-towards} & News & \checkmark & & & & & \checkmark & \checkmark \\
            RAMS~\citep{ebner-etal-2020-multi} & News & & & & \checkmark & & \checkmark & \checkmark \\
            TACRED~\citep{zhang-etal-2017-position} & News & & & & & \checkmark & \checkmark & \checkmark \\
            WNUT 2017~\citep{derczynski-etal-2017-results} & News & \checkmark & & & & & \checkmark & \checkmark \\
            \midrule
            BroadTwitter~\citep{derczynski-etal-2016-broad} & Twitter & \checkmark & & & & & & \checkmark \\
            CASIE~\citep{casie} & Cybercrime & & & \checkmark & \checkmark & & & \checkmark \\
            CrossNER~\citep{liu2021crossner} & \textit{Many} & \checkmark & & & & & & \checkmark \\
            E3C~\citep{Magnini2021} & Biomedical & \checkmark & & & & & & \checkmark \\
            FabNER~\citep{fabner}& Science & \checkmark & & & & & & \checkmark \\
            HarveyNER~\citep{chen-etal-2022-crossroads} & Twitter & \checkmark & & & & & & \checkmark \\
            MIT Movie~\citep{DBLP:conf/icassp/LiuPCG13} & Queries & \checkmark & & & & & & \checkmark \\
            MIT Restaurants~\citep{DBLP:conf/icassp/LiuPCG13} & Queries & \checkmark & & & & & & \checkmark \\
            MultiNERD~\citep{tedeschi-navigli-2022-multinerd} & Wikipedia & \checkmark & & & & & & \checkmark \\
            WikiEvents\citep{li-etal-2021-document} & Wikipedia & \checkmark & & \checkmark & \checkmark & & & \checkmark \\
            \bottomrule
        \end{tabular}
    }
    
    \label{tab:datasets}
\end{table}

We have trained the model to perform 5 different tasks: Named Entity Recognition (NER), Relation Extraction (RE), Event Extraction (EE), Event Argument Extraction (EAE) and Slot Filling (SF). However,  we only evaluated the model on the three main tasks of interest: NER, EE and EAE. The other two tasks are added in the training data in order to add diversity and improve the flexibility of the model.

Few modifications has been done to two datasets in order to improve the quality of the model. First, the training data of Ontonotes 5 was reduced drastically as it was automatically annotated. Second, the TACRED dataset was converted from RE to SF in order to increase the complexity of the task. These modifications make our system not comparable with the state of the art on those tasks. However, our focus of interest is in the zero-shot evaluation and, therefore, the benefits (see Appendix~\ref{ap:repr_examples}) are more interesting than adding 2 more comparable points on the supervised setup. In the CASIE dataset, we detected that the annotated event spans are inconsistent. The models typically annotate a substring rather than the entire span. Therefore, we evaluate all the models based on the predicted event categories, without considering the exact text span. For arguments, we use partial matching.

We use the guidelines released by the authors of each dataset. When such guidelines are not publicly available, we ask human experts to create them, based on the annotations from the development split. The representative candidates are extracted from the guidelines when available, otherwise, the candidates are sampled from the the train split based on word frequency or manually curated based on the guidelines. Paraphrases are automatically generated using Vicuna 33B v1.3 \citep{DBLP:journals/corr/abs-2306-05685}. 

\subsection{Language Models and Baselines}

\paragraph{Backbone LLMs.} \GoLLIE GoLLIE is a fine-tuned version of Code-LLaMA \cite{DBLP:journals/corr/abs-2308-12950}. Other backbone LLMs, such as LLaMA~\citep{DBLP:journals/corr/abs-2302-13971}, LLaMA-2 \cite{DBLP:journals/corr/abs-2307-09288} or Falcon \cite{DBLP:journals/corr/abs-2306-01116} were considered during the development, however, as our approach uses code to represent the input and output, Code-LLaMA model worked better on the preliminary experiments. In order to perform fair comparisons the baseline developed in this paper is based on Code-LLaMA as well. All the development of this paper was done with the 7B parameter version of Code-LLama, but, for a scaling analysis we also trained the 13B and 34B parameter models.

\paragraph{Training setup.} To train the models we use QLoRA~\citep{lora, qlora}. LoRA freezes the pre-trained model weights and injects trainable rank decomposition matrices into linear layers of the Transformer architecture. On a preliminary experiment this setup outperformed fine-tuning the entire model on the zero-shot tasks, while trained much faster (more details in Appendix \ref{ap:lora_full_model_finetuning}). We applied the LoRA to all linear transformer block layers as recommended by \cite{qlora}. The models were trained for 3 epochs with an effective batch-size of 32 and a learning-rate of 3e-4 with cosine scheduler. Our training infrastructure was 2 NVIDIA's A100 with 80gb each. More details about the training are given in the Appendix~\ref{ap:extended_training_details}.


\paragraph{Comparable systems.} Our main point of comparison is Instruct-UIE~\citep{DBLP:journals/corr/abs-2304-08085} as it is the approach closer to our system, but without guidelines. Another system considered for comparison is PromptNER, \cite{ashok2023promptner} propose to prompt GPT-3.5 and T5 with definitions using Chain-of-Though in order to perform few-shot NER. Different from us, they did not fine-tuned the model to attend the guidelines. For a fair comparison, we only considered the zero-shot results reported in the paper. In addition, other state-of-the-art systems are added for comparison when results from Instruct-UIE and PromptNER are not available.

\section{Results}

\subsection{Supervised evaluation}

\begin{table}
    \centering
    \caption{Supervised evaluation results. "*" indicates that results are not directly comparable.}
\begin{tabular}{l|r|cc|cc}
            \multicolumn{6}{c}{} \\
            \toprule
            \textbf{Dataset} & \textbf{SoTA} & \textbf{Baseline} & \textbf{\GoLLIE} & \textbf{\GoLLIE 13B} & \textbf{\GoLLIE 34B} \\
            \midrule
            ACE05\textsubscript{NER} & \citep{lu-etal-2022-unified} 85.8 & 89.1\tiny{0.2} & 88.1\tiny{0.5} & 89.4\tiny{0.1} & \textbf{89.6}\tiny{0.1}\\
            
            ACE05\textsubscript{RE} & \citep{lu-etal-2022-unified} 66.1 & 63.8\tiny{0.6} & 63.6\tiny{1.5} & 67.5\tiny{0.4} & \textbf{70.1}\tiny{1.3} \\
            
            ACE05\textsubscript{EE} & \citep{lu-etal-2022-unified} \textbf{73.4} & 71.7\tiny{0.1} & 72.2\tiny{0.7} & 70.9\tiny{1.4} & 71.9\tiny{1.0} \\
            
            ACE05\textsubscript{EAE} & \citep{lu-etal-2022-unified} *54.8 & 65.9\tiny{0.6} & 66.0\tiny{0.7} & 67.8\tiny{0.8} & \textbf{68.6}\tiny{1.0} \\
            
            BC5CDR & \citep{zhang2023optimizing} \textbf{91.9} & 87.5\tiny{0.2} & 87.5\tiny{0.2} & 87.9\tiny{0.1} & 88.4\tiny{0.2} \\
            
            CoNLL 2003 & \citep{lu-etal-2022-unified} 93.0 & 92.9\tiny{0.1} & 92.8\tiny{0.3} & 93.0\tiny{0.2} & \textbf{93.1}\tiny{0.2} \\
            
            DIANN & \citep{zabala2018hybrid} 74.8 & 80.3\tiny{0.6} & 79.4\tiny{1.0} & 82.6\tiny{1.1} & \textbf{84.1}\tiny{0.9} \\
            
            NCBIDisease & \citep{10.1007/978-3-030-68763-2_48} \textbf{89.1} & 86.2\tiny{0.1} & 85.4\tiny{0.3} & 86.5\tiny{0.7} & 85.8\tiny{0.2} \\
            
            Ontonotes 5 & - & 83.4\tiny{0.2} & 83.4\tiny{0.2} & 84.0\tiny{0.2} & \textbf{84.6}\tiny{0.3} \\
            
            RAMS & \citep{li-etal-2021-document} 48.6 & 48.9\tiny{0.3} & 48.7\tiny{0.6} & 49.6\tiny{0.1} & \textbf{51.2}\tiny{0.2} \\
            
            TACRED & - & 56.6\tiny{0.2} & 57.1\tiny{0.8} & 56.7\tiny{0.4} & \textbf{58.7}\tiny{0.1} \\
            
            WNUT 2017 & \citep{wang-etal-2021-improving} \textbf{60.2} & 53.7\tiny{0.5} & 52.0\tiny{0.6}  & 50.5\tiny{0.7} & 54.3\tiny{0.4} \\
            
            \midrule
            Average & & 73.3\tiny{0.1}  & 73.0\tiny{0.2} & 73.9\tiny{0.2} & \textbf{75.0}\tiny{0.3} \\
            \bottomrule
        \end{tabular}
\label{tab:main-results}
\end{table}

The results on the supervised datasets are shown in Table~\ref{tab:main-results}. Comparing GoLLIE with the baseline, they both obtain very similar results, with an absolute difference of 0.3 F1 points on average. This is expected, as the model implicitly learns the guidelines for annotating the datasets based on the data distribution during fine-tuning. In addition, despite the bigger noise introduced to GoLLIE fine-tuning, the model's performance remains close to that of the baseline.

Comparing to the state-of-the-art our model achieves pretty similar results as well. Focusing on the two datasets where our model under-performs significantly, NCBIDisease and WNUT, we find that task specific techniques are still needed. \cite{10.1007/978-3-030-68763-2_48} leverages a model pre-trained on Biomedical domain corpora to better detect diseases, and, \cite{wang-etal-2021-improving} uses external knowledge to detect emergent and rare entities. These, however, are complementary to our proposal. 


\subsection{Zero-Shot evaluation}

\begin{table}
    \centering
    \caption{Zero-shot evaluation results. "*" indicates results obtained using the original code.}
\begin{tabular}{l|r|cc|cc}
            \multicolumn{6}{c}{} \\
            \toprule
            \textbf{Dataset} & \textbf{SoTA} & \textbf{Baseline} & \textbf{\GoLLIE} & \textbf{\GoLLIE 13B} & \textbf{\GoLLIE 34B} \\
            \midrule
            BroadTwitter & - & 39.0\tiny{0.5} & 49.5\tiny{0.7} & \textbf{51.4}\tiny{1.6} & 50.3\tiny{1.8} \\
            
            CASIE\textsubscript{EE} & - & 33.9\tiny{5.6} & 59.3\tiny{2.0} & 62.2\tiny{0.8} & \textbf{65.5}\tiny{1.5} \\
            
            CASIE\textsubscript{EAE} & -& 47.9\tiny{1.2} & 50.0\tiny{0.2} & 52.6\tiny{0.2} & \textbf{55.2}\tiny{0.4} \\
            
            AI & \citep{DBLP:journals/corr/abs-2304-08085} 49.0 & 32.3\tiny{0.7} & 59.1\tiny{1.0} & 56.7\tiny{2.6} & \textbf{61.6}\tiny{1.7} \\
            
            Literature & \citep{DBLP:journals/corr/abs-2304-08085} 47.2 & 39.4\tiny{0.6} & \textbf{62.7}\tiny{2.8} & 59.7\tiny{0.3} & 59.1\tiny{2.2} \\
            
            Music & \citep{DBLP:journals/corr/abs-2304-08085} 53.2 & 56.2\tiny{1.2} & 67.8\tiny{0.1} & 65.5\tiny{3.1} & \textbf{68.4}\tiny{1.8} \\
            
            Politics & \citep{DBLP:journals/corr/abs-2304-08085} 48.2 & 38.3\tiny{0.9} & 57.2\tiny{0.8} & 54.4\tiny{3.5} & \textbf{60.2}\tiny{2.6} \\
            
            Science & \citep{DBLP:journals/corr/abs-2304-08085} 49.3 & 37.1\tiny{1.3} & 55.5\tiny{1.4} & 56.2\tiny{0.8} & \textbf{56.3}\tiny{0.4} \\
            
            E3C & - & 59.8\tiny{0.2} & 59.0\tiny{0.3} & 59.0\tiny{0.8} & \textbf{60.0}\tiny{0.4} \\
            
            FabNER & - & 06.1\tiny{0.4} & 24.8\tiny{0.5} & 25.4\tiny{0.5} & \textbf{26.3}\tiny{0.5} \\
            
            HarveyNER & - & 23.2\tiny{0.3} & 37.3\tiny{1.6} & \textbf{41.3}\tiny{0.8} & 38.9\tiny{0.5} \\
            
            Movie & \citep{DBLP:journals/corr/abs-2304-08085} 63.0 & 43.4\tiny{1.0} & \textbf{63.0}\tiny{0.5} & 62.5\tiny{0.9} & 62.4\tiny{1.2} \\
            
            Restaurants & \citep{DBLP:journals/corr/abs-2304-08085} 21.0 & 31.3\tiny{1.9}  & 43.4\tiny{0.7} & 49.8\tiny{1.2} & \textbf{52.7}\tiny{1.4} \\
            
            MultiNERD & - & 55.0\tiny{0.9} & 76.0\tiny{0.6} & \textbf{77.5}\tiny{0.3} & 77.2\tiny{0.5} \\
            
            WikiEvents\textsubscript{NER} & \citep{sainz-etal-2022-zs4ie} *49.1 & 76.9\tiny{4.4} & 80.7\tiny{0.6} & 80.2\tiny{0.6} & \textbf{81.3}\tiny{0.5} \\
            
            WikiEvents\textsubscript{EE} & \citep{sainz-etal-2022-zs4ie} *10.4 & 47.5\tiny{0.4} & 43.0\tiny{0.5} & 45.7\tiny{0.7} & \textbf{47.0}\tiny{0.9} \\
            
            WikiEvents\textsubscript{EAE} & \cite{sainz-etal-2022-textual} 35.9 & 51.6\tiny{0.5} & 51.9\tiny{0.4} & \textbf{52.5}\tiny{1.0} & 50.7\tiny{0.3} \\
            
            \midrule
            Average SoTA & 42.6 & 45.4\tiny{0.4} & 58.4\tiny{0.4} & 58.3\tiny{0.6} & \textbf{60.0}\tiny{0.8} \\
            
            Average all & - & 42.3\tiny{0.2} & 55.3\tiny{0.2} & 56.0\tiny{0.2} & \textbf{57.2}\tiny{0.5} \\
            \bottomrule
        \end{tabular}
\label{tab:zero-results}
\end{table}

The results on the zero-shot are shown in Table~\ref{tab:zero-results}. Overall, comparing to the baseline, \textbf{the results are improved significantly when using guidelines} on almost every dataset, with an absolute difference of 13 F1 points on average. Despite dividing the evaluation benchmarks based on the domain, there is always some overlap between labels of train and evaluation benchmarks. For instance, the datasets E3C and WikiEvents share a large part of their schema with datasets like BC5CDR, ACE05 and RAMS. This phenomena is reflected in the results.

GoLLIE surpass by a large margin the current state-of-the-art methods Instruct-UIE~\citep{DBLP:journals/corr/abs-2304-08085} and Entailment based IE~\citep{sainz-etal-2022-zs4ie}.
Focusing on the comparison with Instruct-UIE, there are three main difference with our approach: the backbone model, the amount of training data, and, the use or not of the guidelines. Instruct-UIE leverages the 11B FlanT5, which in addition to the LM pre-training the model is fine-tuned with 473 datasets. Respect to the data, Instruct-UIE leverages a total of 34 IE datasets (counting different tasks as datasets) from diverse domains, we only leverage 12 datasets. Comparing to us however, they do not use guideline information. Still, our method performs significantly better suggesting that the guidelines have an important effect on the results. 

PromptNER~\citep{ashok2023promptner} also adds some definition information into the prompt in order to perform zero-shot NER. We compare our approach with them (represented as GPT-3.5) in Figure~\ref{fig:zero-shot-results}. Although their approach leverages guidelines too, our approach performs significantly better on all datasets, showing that LLMs (even with 175B parameters) struggle to follow guidelines. They solve this by adding examples in the context but still far behind on a comparable setting (T5-XXL).


\subsection{Model scaling}
Recent research has shown that increasing the parameter count of language models leads to improved generalization capabilities \cite{DBLP:conf/nips/BrownMRSKDNSSAA20}. As presented in Table \ref{tab:zero-results}, we scale GoLLIE by using Code-LLaMA LLMs with 13 billion and 34 billion parameters as backbone. Higher parameter count yields superior average zero-shot performance. However, some datasets and tasks greatly benefit from a larger LLM, while others do not. We believe that some datasets do not see benefits from increasing the LLM size because their performance is hindered by the issues with the guidelines that we discuss in Section \ref{sec:Ablation}. While, in general, larger models achieve better results in both supervised and zero-shot settings, GoLLIE with a 7B parameter backbone already exhibits strong zero-shot capabilities. As described in Appendix \ref{ap:extended_training_details}, the 13B and 34B parameter versions require orders of magnitude more compute. Thus, one must carefully weigh the benefits of enhanced performance against the significantly increased computational costs and resources required

\subsection{Ablation study}
\label{sec:Ablation}

We have performed an ablation to see the contribution of several components in the zero-shot evaluation as follows. We use "w/o Masking"  for \GoLLIE GoLLIE without class name masking regularization. We use "w/o Dropout" when we remove class dropout regularization, and "w/o Candidates" for removing the use of representative annotation candidates. Finally "w/o \textit{all}" when removing all components, including  guidelines, which is actually the baseline. As shown in Table~\ref{tab:ablation}, the results show a clear tendency, \textbf{the more regularization the better zero-shot results}. 
The class name masking and label dropout seems to have little but still beneficial effect, in contrast to the representative annotation items, which give some stronger signal to the model. We see how definitions and representative candidates from the guidelines are complementary and help to improve each other.

\begin{table}[htb]
    \centering
    \caption{Ablation results.}
    \begin{tabular}{l|c}
        \multicolumn{2}{c}{} \\
        \toprule
        \textbf{Model} & \textbf{Zero-Shot F1} \\
        \midrule
        \GoLLIET & 55.3\tiny{0.2} \\
        \midrule
        w/o Masking & 54.6\tiny{0.5} \\
        w/o Dropout & 54.0\tiny{0.2} \\
        w/o Candidates & 49.9\tiny{0.1} \\
        w/o \textit{all} (baseline) & 42.3\tiny{0.2} \\
        \bottomrule
    \end{tabular}
    \label{tab:ablation}

\end{table}





\section{Error analysis} 

In this section, we aim to better understand the effect of prompting LLMs with guidelines. We focus on specific labels across various datasets, with the results displayed in Table \ref{tab:error_analysis}. Our analysis covers both successful and unsuccessful cases of entity labeling by GoLLIE. For the latter, we also aim to identify the reasons why the model fails to correctly label these entities.

\begin{table}[htb]
\centering

\small
    \caption{This table shows the F1 scores for specific labels from different datasets. The guideline column is a small summary of the actual guideline used to prompt the model.}
    \adjustbox{max width=0.90\linewidth}{\begin{tabular}{@{}llp{7.5cm}cc@{}}
        \multicolumn{4}{c}{} \\
        \toprule
        \multicolumn{1}{l}{\textbf{Dataset}} & \multicolumn{1}{l}{\textbf{Label}} &  \multicolumn{1}{l}{\textbf{Guideline}} & \textbf{Baseline} & \GoLLIE \\ \midrule
        \rowcolor{ForestGreen!10} MultiNERD & Media & Titles of films, books, songs, albums, fictional characters and languages. &  13.6 & 69.1 \\ 
        \rowcolor{ForestGreen!10} \rule{0pt}{2.25ex} CASIE & Vul. Patch & When a software company addresses a vulnerability by releasing an update. & 27.7 & 70.5 \\
        \rowcolor{ForestGreen!10} \rule{0pt}{2ex} Movie & Trailer & Refers to a short promotional video or preview of a movie. & 00.0 & 76.4 \\
        \rowcolor{ForestGreen!10} \rule{0pt}{2ex} AI & Task & Particular research task or problem within a specific AI research field.  & 02.7 & 63.9 \\ 
\rowcolor{CornflowerBlue!10} \rule{0pt}{2ex} MultiNERD & Time & Specific and well-defined time intervals, such as eras, historical periods, centuries, years and important days. &  01.4 & 03.5 \\
\rowcolor{Thistle!10} \rule{0pt}{2ex} Movie & Plot & Recurring concept, event, or motif that plays a significant role in the development of a movie. & 00.4 & 05.1 \\
        \rowcolor{Thistle!10} \rule{0pt}{2ex} AI & Misc & Named entities that are not included in any other category. & 01.1 & 05.2 \\
        \rowcolor{Thistle!10} \rule{0pt}{2ex} Literature & Misc & Named entities that are not included in any other category.  &  03.7 & 30.8 \\
        \rowcolor{Thistle!10} \rule{0pt}{2ex} Literature & Writer & Individual actively engaged in the creation of literary works. &   04.2 & 65.1 \\
        \rowcolor{Thistle!10} \rule{0pt}{2ex} Literature & Person & Person name that is not a writer. & 33.5 & 49.4 \\
        \rowcolor{Thistle!10} \rule{0pt}{2ex} Science & Scientist & A person who is studying or has expert knowledge of a natural science field.  &  02.1 & 05.8 \\
        \rowcolor{Thistle!10} \rule{0pt}{2ex} Science & Person & Person name that is not a scientist. &   46.1 & 45.9 \\
\rowcolor{Thistle!10} \rule{0pt}{2ex} Politics & Polit. Party & Organization that compete in a particular country's elections. & 11.2 & 34.9 \\ \bottomrule
    \end{tabular}}
    \label{tab:error_analysis}
\end{table}

\paragraph{The details are in the guidelines:} Labels such as \textsc{Media}, \textsc{VulnerabilityPatch}, \textsc{Trailer}, and \textsc{Task} are inherently polysemous, making it challenging to determine the appropriate categorization based solely on the label name. As a result, the baseline struggles to effectively classify items under these labels due to having insufficient information. Conversely, GoLLIE successfully follows the guidelines, underscoring their utility.

\paragraph{When the annotations do not comply with the guidelines:} In the case of the \textsc{Time} label of the MultiNERD dataset, we found that our model labels years as \textsc{Time} entities. This is correct according to the annotation guidelines. Surprisingly, years are not labeled as entities in the dataset. In this case, GoLLIE successfully follows the guidelines; unfortunately, the dataset annotations do not.

\paragraph{Ambiguous labels:} The \textsc{Miscellaneous} category, used by CoNLL03 and CrossNER datasets, refers to any named entity that is not included in the predefined categories set by the dataset. This definition is highly ambiguous and serves as a catch-all for various elements that do not fit into any of the predefined categories. Similarly,  the \textsc{Plot} category of the Movie dataset is used to label a wide range of elements. For example, events in a movie (e.g., murder, love, horse racing), characters (e.g., vampires, zombies, cats), and the country of origin (e.g., British, American), among others. This lack of specificity hinders the development of consistent rules or guidelines for tagging such elements \citep{ratinov-roth-2009-design}, which is a problem for humans and machines alike. As a consequence, GoLLIE also fails to label them accurately. 


\paragraph{Conflicts Between Fine-Grained and Coarse Entities:} The CrossNER dataset introduces two labels for person names within each domain. For example, in the Science domain, the labels \textsc{Scientist} and \textsc{Person} are used. The former, is used to label any person that is not a Scientist. Similarly, the Literature domain includes the labels \textsc{Writer} and \textsc{Person}. The guidelines assist GoLLIE in correctly labeling entities as \textsc{Writer}. However, GoLLIE still categorizes individuals as \textit{Person} even when they are \textit{Scientist}, despite the guidelines. This is not technically incorrect, as every scientist is, by definition, also a person. 


\paragraph{Strong Label Preconceptions:} In its Political domain set, CrossNER includes the label \textsc{Political Party}. GoLLIE outperforms the baseline, once again demonstrating the utility of providing the model with guidelines. However, we often find that the model categorizes political parties as organizations. As listed in Table \ref{tab:datasets}, most of the pretraining datasets originate from the news domain, where political parties are a common entity. However, none of the fine-tuning datasets include the \textsc{Political Party} entity; they are instead categorized as \textsc{Organization}. Consequently, during inference, the model consistently labels political parties as organizations. We believe this issue can be resolved by expanding the number and diversity of the fine-tuning datasets.

In summary, we anticipate that \textbf{GoLLIE will perform well on labels with well-defined and clearly bounded guidelines}. On the other hand, ambiguous labels or very coarse labels pose challenges. To this regard, be believe that GoLLIE would benefit from learning to follow instructions such as \textit{"Label always the most specific class"} or \textit{"Annotate this class in the absence of other specific class"}. We also expect that GoLLIE would benefit from expanding the number and diversity of the pre-training datasets. For this study, we selected a limited number of fine-tuning datasets to more effectively validate our method.






\section{Conclusions}
In this paper we introduce \GoLLIET, a LLM specifically fine-tuned to comply with annotation guidelines that were devised for helping humans to annotate the dataset. A comprehensive zero-shot evaluation empirically demonstrate that annotation guidelines are of great value for LLMs, as GoLLIE successfully leverages them. GoLLIE achieves better zero-shot results than previous attempts at zero-shot IE which do not leverage the guidelines, or use models not finetuned for following guidelines. 

GoLLIE is a significant progress towards the development of models that can generalize to unseen IE tasks. In the future, we plan to enhance GoLLIE by using a larger and more diverse set of pre-training datasets. We will also improve the model's performance with ambiguous and coarse labels by expanding the set of instructions that the model can follow. 




\bibliography{iclr2024_conference, anthology}
\bibliographystyle{iclr2024_conference}


\clearpage

\appendix
\section{Examples}
\label{ap:repr_examples}

In addition to NER, EE and EAE for which examples are shown in Figures~\ref{fig:input-output} and ~\ref{fig:guidelines-example} respectively, we also feed the model with data from RE and SF. The formulation of RE is similar to the NER but with two argument attributes. However, the SF task is more complex as shown in the Figure~\ref{fig:slot_filling_example}. With this task, we added several layers of complexity to the input: extended definitions for each possible attribute (slot), optional arguments, and, fine-grained definitions of types such as Names, Values or Strings. We also added constraints into the prompt to condition the model to just output the information of our desired query instead of every single template on the text. In the future, we would like to add more complex tasks into the train and evaluation to improve the capabilities and flexibility of the model. For more examples refer to the GitHub repository.

\begin{figure}[htb]
    \centering
    \includegraphics[width=1.\linewidth]{images/slot_filling_example.pdf}
    \caption{Example of the TACRED dataset converted to Slot Filling task represented as code.}
    \label{fig:slot_filling_example}
\end{figure}

\subsection{Example of generalization to new custom Tasks}

Our model allows the user to define custom annotation schemas using Python code.
We provide an example where we define two new types of entities: Launcher and Mission.
As shown in Figure \ref{fig:custom-example}, Launcher and Mission are not simple entities, they correspond to what we call \textit{Template}, a class similar to \textit{Entity} but with additional arguments, like the SF task.
For example, the space\_company or the crew of the launcher are some of the additional arguments we added to the schema. 
As shown in the example, the model's output (everything after \texttt{result = [}) satisfies the type constraints defined in the guidelines, attributes defined as strings are filled with strings and, the arguments defined as lists (like \textit{crew}) are filled with lists. 
The model is able to correctly analyze the given sentence with our newly created annotation schema.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=1.\linewidth]{images/custom_task.pdf}
    \caption{Example of generalization to custom tasks defined by the user.}
    \label{fig:custom-example}
\end{figure}



\section{Model hallucinations}

\begin{table}[htb]
\caption{Percentage of impossible to parse outputs and label hallucinations. Scores are in the range 0\%-100\%. F1 scores on the dataset are shown for reference.}
\centering
\small
\begin{tabular}{@{}lccc@{}}
\multicolumn{4}{c}{} \\
\toprule
 & \multicolumn{3}{c}{\GoLLIE} \\ \cmidrule(l){2-4} 
\textbf{Dataset} & \textbf{Impossible to Parse} & \textbf{Hallucinations} & \textbf{F1 Score} \\ \midrule
BroadTwitter & 0.00\tiny{0.00} & 0.00\tiny{0.00} & 49.5\tiny{0.7} \\
CASIE\textsubscript{EE} & 0.03\tiny{0.02} & 0.39\tiny{0.06} & 59.3\tiny{2.0} \\
CASIE\textsubscript{EAE} & 0.07\tiny{0.04}  & 0.12\tiny{0.05} & 50.0\tiny{0.2} \\
AI & 0.00\tiny{0.00} & 0.05\tiny{0.06} & 59.1\tiny{1.0} \\
Literature & 0.00\tiny{0.00}  & 0.02\tiny{0.02} & 62.7\tiny{2.8} \\
Music & 0.00\tiny{0.00}  & 0.18\tiny{0.06} & 67.8\tiny{0.1} \\
Politics & 0.00\tiny{0.00}  & 0.07\tiny{0.03} & 57.2\tiny{0.8} \\
Science & 0.06\tiny{0.08}  & 0.27\tiny{0.04} & 55.5\tiny{1.4} \\
E3C & 0.00\tiny{0.00}  & 0.15\tiny{0.00} & 59.0\tiny{0.3} \\
FabNER & 0.03\tiny{0.02}  & 0.30\tiny{0.05} & 24.8\tiny{0.5} \\
HarveyNER & 0.00\tiny{0.00}  & 0.19\tiny{0.16} & 37.3\tiny{1.6} \\
Movie & 0.00\tiny{0.00}  & 0.03\tiny{0.03} & 63.0\tiny{0.5} \\
Restaurants & 0.00\tiny{0.00}  & 0.18\tiny{0.03} & 43.4\tiny{0.7} \\
MultiNERD & 0.15\tiny{0.03}  & 0.09\tiny{0.08} & 76.0\tiny{0.6} \\
WikiEvents\textsubscript{NER} & 0.00\tiny{0.00}  & 0.02\tiny{0.03} & 80.7\tiny{0.6} \\
WikiEvents\textsubscript{EE} & 0.00\tiny{0.00}  & 0.43\tiny{0.18} & 43.0\tiny{0.5} \\
WikiEvents\textsubscript{EAE} & 0.52\tiny{0.34}  & 0.00\tiny{0.00} & 51.9\tiny{0.4} \\ \bottomrule
\end{tabular}
\label{tab:Hallucination}
\end{table}


In this section, we evaluate the hallucinations generated by the model. We examine two different phenomena. First, we consider instances where the output is so corrupted that it is \textit{impossible to parse}. In such cases, we treat the output as an empty list. Second, we look at instances where the model outputs a label \textit{Hallucination}, that is, a label not defined among the input classes. In these instances, we remove the label from the output. As demonstrated in Table \ref{tab:Hallucination}, for all the zero-shot datasets, both phenomena occur in less than 1\% of the predictions. This demonstrates that GoLLIE is highly resistant to hallucinations and closely adheres to the classes defined in the input.



\section{Extended training details}
\label{ap:extended_training_details}

\subsection{Loss calculation}

We have used the standard Next Token Prediction (NTP) loss to train our models. However, several regularizations that we applied to the models made the loss computed over the guideline tokens much higher than the actual output tokens. This is because we randomly shuffle the guidelines order, mask names or, drop classes, which makes impossible to predict what goes next. To avoid the loss of the guideline tokens overshadow the actual output tokens loss, we decided to only compute the loss over the output tokens. This way, we can also avoid some overfitting on the guidelines. This resulted on a faster training and better results overall.

\subsection{Carbon footprint}

Fine-tuning LLMs is not as expensive as pre-training these models. Still, we believe that it is important to measure and document the costs that our experiments have on our planet. We provide the resources required for a single run of our experiments in Table~\ref{tab:train_extended_details}. All the experiments were done on our private infrastructure. For the carbon footprint estimation, we estimated the values considering a 400W consumption per GPU with a 0.141 kg/kWh carbon intensity\footnote{Statistic taken from \url{https://app.electricitymaps.com/map}}.

\begin{table}[htb]
    \centering
    \caption{Details about the training resources required for each model.}
    \begin{tabular}{l|rrrr}
        \multicolumn{5}{c}{} \\
        \toprule
         \textbf{Model} & \textbf{Hardware} & \textbf{FLOPs} & \textbf{Time (h)} & \textbf{CO\textsubscript{2}eq (kg)} \\
        \midrule
         Baseline & 1xA100 & 4.5e\textsuperscript{18} & 17.3 & 0.61 \\
        \GoLLIET & 1xA100 & 11.9e\textsuperscript{18} & 44.5 & 1.57 \\
        \GoLLIE 13B & 1xA100 & 22.7e\textsuperscript{18} & 79.5 & 2.80 \\
        \GoLLIE 34B & 2xA100 & 55.8e\textsuperscript{18} & 94.6 & 6.67 \\
        \bottomrule
    \end{tabular}
    
    \label{tab:train_extended_details}
\end{table}

\subsection{LoRa vs Full Model Fine-Tuning}
\label{ap:lora_full_model_finetuning}
We conducted preliminary experiments to compare the performance of QLoRA \citep{lora, qlora} with that of training all the parameters in the model. These preliminary experiments were conducted using the LLaMA2 7B model \cite{DBLP:journals/corr/abs-2307-09288} and an early version of the code. However, the experimental setup for both models was identical. Both approaches were prompted with guidelines. First, we compared the training loss of both approaches. Figure \ref{fig:TrainingLoss} shows that when fine-tuning all the parameters, the loss decreases much more rapidly than when training only the LoRA layers. It also achieves a lower loss at the end of training. However, when evaluating the model at the end of the first and third epochs, we observed that training the full model performs very poorly, as shown in Table \ref{tab:LoravsFullModel}. We hypothesize that when training all the parameters, the model overfits quickly (indicated by the lower training loss) and memorizes the training data. On the other hand, training only the LoRA layers, which represent around 0.5\% of the total model weights, introduces a bottleneck that prevents the model from memorizing the training dataset. It is also noteworthy that the QLoRA approach was trained using just one Nvidia A100 80GB GPU thanks to 4 bits quantization of the frozen model \cite{qlora}. Training the full model required a minimum of four Nvidia A100 80GB GPUs to fit the model into memory. We used DeepSpeed \footnote{\url{github.com/microsoft/DeepSpeed}} to distribute the model across the four GPUs for training. Due to the high cost of training, we did not perform an extensive hyper-parameter search for the full model.

\begin{figure}
\centering
    \caption{Training loss of fine-tuning the full model vs training LoRA layers only.}
    \includegraphics[width=0.8\linewidth]{tables/FullvsQlora.png}
    \label{fig:TrainingLoss}
\end{figure}


\begin{table}[htb]
\centering
\caption{F1 scores achieved when training the full model vs only training the LoRA Layers at the end of the first and third epoch.}
\small
\adjustbox{max width=0.98\linewidth}{\begin{tabular}{@{}cccl|cccccc@{}}
\multicolumn{10}{c}{} \\
\toprule
\textbf{Training} & \textbf{Epoch} & \textbf{Precision} & \textbf{LR} & \textbf{HarveyNer} & \textbf{FabNER} & \textbf{Restaurant} & \textbf{Movie} & \textbf{CASIE\textsubscript{EE}} & \textbf{CoNLL03} \\ \midrule
Full & 1 & BF16 &  & 0.00 & 0.00 & 0.25 & 4.74 & 0.00 & 85.57 \\
Full & 3 & BF16 &  & 3.45 & 0.21 & 46.7 & 16.72 & 0.42 & 84.83 \\\midrule
QLoRA & 1 & 4Bit + BF16 &  & 34.98 & \textbf{20.78} & \textbf{45.01} & \textbf{51.14} & 55.83 & 91.41 \\
QLoRA & 3 & 4Bit + BF16 &  & \textbf{35.34} & 16.21 & 39.07 & 44.18 & \textbf{57.93} & \textbf{93.14} \\ \bottomrule
\end{tabular}}
\label{tab:LoravsFullModel}
\end{table}


\section{Data-contamination statement}

We believe data-contamination is a relevant problem that affects the NLP evaluations nowadays, becoming more prevalent with LLMs~\citep{dodge-etal-2021-documenting, magar-schwartz-2022-data}. Detecting whether a dataset was inside a LLM pretrained corpora is challenging even with the pre-training data itself. In this paper, unfortunately, we do not have access to the pre-training data used to train Code-LLaMA the backbone LLM of our model. This issue is particularly worrying for us because one big source of contamination is probably GitHub and other code repositories which are also used to upload evaluation benchmarks~\cite{dodge-etal-2021-documenting}. As Code-LLaMA is trained on code, there is a chance for this particular data-leakage. However, all of our comparisons were made against our baseline, which has the same backbone LLM as GoLLIE. Even if the results were impacted, \textbf{the improvements of our model over the baseline would not be affected by data-contamination as both share the same pre-training}. We hope that in the future more transparency will allow to perform safer evaluations.


\end{document}
