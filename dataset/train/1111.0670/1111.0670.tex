\documentclass[11pt]{article}

\usepackage{bigstrut}
\usepackage{fullpage}
\usepackage{amsfonts,color,amssymb,graphicx,stmaryrd}
\usepackage{amsmath}
\usepackage{tikz}
\usetikzlibrary{arrows,backgrounds,decorations,decorations.pathmorphing,positioning,fit,automata,shapes,matrix,patterns}
\usepackage{booktabs}
\usepackage[htt]{hyphenat}
\usepackage{amsmath, amssymb, amsfonts}
\usepackage{color,graphicx, enumerate, subfig}
\usepackage{mathtools}
\usepackage{array}
\usepackage{scalefnt}
\usepackage{bm}
\usepackage{xspace}
\usepackage{stmaryrd}
\usepackage{upgreek}
\usepackage{multirow}
\usepackage{mathrsfs}
\usepackage{url}
\usepackage{bbm}
\usepackage{algorithmic,algorithm}
\usepackage{eufrak}
\usepackage{bigstrut}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{example}[theorem]{Example}
\newtheorem{conjecture}[theorem]{Conjecture}
\def\Proof{{\bf Proof.}}
\def\qed{{\bf }}
\newcommand{\mypar}[1]{\subsection{#1}}


\usepackage{tikz}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations.pathmorphing}
\usetikzlibrary{backgrounds}
\usetikzlibrary{positioning}
\usetikzlibrary{fit}
\usetikzlibrary{petri}

\tikzstyle{background}=[fill=gray!20, inner sep=0.2cm]

\newcommand{\Fig}[1]{Fig. #1}
\newcommand{\Def}[1]{Def. #1}
\newcommand{\Tab}[1]{Tab. #1}
\newcommand{\Lemma}[1]{Lemma #1}
\newcommand{\trule}[1]{\ensuremath{\lfloor\text{\sc{#1}}\rfloor}}

\def\bigO{{O}}
\def\qed{{\bf }}
\newcommand{\st}{\ensuremath{^*}}

\newcommand{\domain}{\ensuremath{\mathbb{D}}}
\newcommand{\naturalnumb}{\ensuremath{\mathbb{N}}}
\newcommand{\integernumb}{\ensuremath{\mathbb{Z}}}
\newcommand{\rationalnumb}{\ensuremath{\mathbb{Q}}}
\newcommand{\posrat}{\ensuremath{\mathbb{Q}^+}}
\newcommand{\realnumb}{\ensuremath{\mathbb{R}}}
\newcommand{\posrealnumb}{\ensuremath{\mathbb{R}^{\geq 0}}}
\newcommand{\Nat}{\ensuremath{\mathbb{N}}}
\newcommand{\Rat}{\ensuremath{\mathbb{Q}}}
\newcommand{\Int}{\ensuremath{\mathbb{Z}}}
\newcommand{\TNW}[1]{\lsem{#1}\rsem}

\newcommand{\ignore}[1]{}
\newcommand{\discuss}[1]{\textbf{Discuss:} #1}
\newcommand{\todo}[1]{\textbf{TODO:} #1}

\def\hole{?}
\newcommand{\vocab}{F}
\newcommand{\F}{{\cal F}}
\newcommand{\trees}{T}
\newcommand{\ptrees}{T^{\hole}}
\newcommand{\Func}[1]{\ensuremath{\mathcal{F}_{#1}}}
\newcommand{\CG}{G}
\newcommand{\CF}{{\mathbb F}}
\newcommand{\CCF}{{\mathbb F}^c}
\newcommand{\sep}{\ensuremath{\,|\,}}
\newcommand{\langof}[1]{\ensuremath{{\cal L}(#1)}}
\newcommand{\reg}[1]{{\mathbb R}(#1)}
\newcommand{\regm}{{\sc\textsc{reg()}\xspace}}
\newcommand{\dom}{{\cal D}}
\newcommand{\sttclass}{\SSTT}
\newcommand{\treesof}[1]{T_{#1}}
\newcommand{\CostModel}{\ensuremath{\mathbb{C}}}
\newcommand{\costmod}[1]{\textsc{cm}(#1)}
\newcommand{\emptytree}{\ensuremath{t_\epsilon}}
\newcommand{\lmap}{\leftarrow}

\newcommand{\sradd}{\oplus}
\newcommand{\srmul}{\otimes}

\newcommand{\CGpc}{\CG_{\setof{\oplus c}}}
\newcommand{\CGpp}{\CG_{\{\oplus\}}}
\newcommand{\CGptd}{\CG_{\setof{\oplus, \odot d}}}
\newcommand{\CGpctd}{\CG_{\setof{\oplus c,\odot d}}}
\newcommand{\CGpct}{\CG_{\setof{\oplus c, \odot}}}
\newcommand{\CGpt}{\CG_{\setof{\oplus, \odot}}}
\newcommand{\CGmpd}{\CG_{\setof{\min,+d}}}
\newcommand{\CGmmpps}{\CG_{\setof{++,**,\left[\cdot\right]}}}

\newcommand{\CGp}{\CGpc}

\def\pms{\Pi}
\def\occ{\eta}
\def\E{E}
\def\val{\alpha}
\def\pval{\beta}
\def\sval{\Lambda}
\def\H{H}
\def\lt{\langle}
\def\rt{\rangle}
\def\W{W}
\newcommand{\brac}[1]{\ensuremath{\llbracket #1\rrbracket}}

\newcommand{\SST}{{\sc\textsc sst}}
\newcommand{\STTR}{{\sc\textsc stt}-{\sc\textsc r}}
\newcommand{\STT}{{\sc\textsc stt}\xspace}
\newcommand{\SSTT}{{\sc\textsc sstt}\xspace}

\newcommand{\sst}{\ensuremath{T}}
\newcommand{\stt}{\ensuremath{U}}
\newcommand{\sststates}{\ensuremath{Q}}
\newcommand{\sstinitst}{\ensuremath{q_0}}
\newcommand{\sstfinalst}{\ensuremath{F}}
\newcommand{\sstvariables}{\ensuremath{X}}
\newcommand{\ssttrans}{\ensuremath{\delta}}
\newcommand{\sstvarup}{\ensuremath{\gamma}}
\newcommand{\sstout}{\ensuremath{O}}
\newcommand{\sstpath}{\ensuremath{\pi}}

\newcommand{\inputalph}{\ensuremath{\Sigma}}
\newcommand{\outputalph}{\ensuremath{\Gamma}}
\newcommand{\state}{\ensuremath{q}}
\newcommand{\Expr}[1]{\ensuremath{Expr(#1)}}
\newcommand{\fm}[1]{\ensuremath{#1^{*}}}

\newcommand{\context}{\ensuremath{\Delta}}
\newcommand{\valuation}{\ensuremath{\nu}}
\newcommand{\interpf}[1]{\ensuremath{|#1|_f}}
\newcommand{\interp}[1]{\ensuremath{\llbracket #1\rrbracket}}
\newcommand{\tr}{\ensuremath{\alpha}}
\newcommand{\computation}[1]{\ensuremath{\llbracket #1\rrbracket}}


\newcommand{\exptime}{\ensuremath{\sc\textsc{ExpTime}}\xspace}
\newcommand{\pspace}{\ensuremath{\sc\textsc{PSpace}}\xspace}
\newcommand{\nlogspace}{\ensuremath{\sc\textsc{NLogSpace}}}
\newcommand{\ptime}{\ensuremath{\sc\textsc{PTime}}\xspace}
\newcommand{\bigo}{\ensuremath{{\em O}}\xspace}
\newcommand{\nls}{{\sc\textsc NLogSpace}\xspace}
\newcommand{\npc}{{\sc\textsc NP}-{\sc\textsc Complete}\xspace}
\newcommand{\np}{{\sc\textsc NP}\xspace}
\newcommand{\nphard}{{\sc\textsc NP}-{\sc\textsc Hard}\xspace}

\newcommand{\funcomp}[2]{#1\!\circ#2}

\newcommand{\EDWA}{{CRA}\xspace}
\newcommand{\REDWA}{{CRA}-{RLA}\xspace}
\newcommand{\CEDWA}{{\sc\textsc ccra}}

\newcommand{\edwa}{\ensuremath{M}}
\newcommand{\edwaoutput}{\ensuremath{\mathcal{F}}}
\newcommand{\edwaoutputco}{\ensuremath{\mathcal{F}_0}}
\newcommand{\edwaoutputun}{\ensuremath{\mathcal{F}_1}}
\newcommand{\edwastates}{\ensuremath{Q}}
\newcommand{\edwastate}{\ensuremath{q}}
\newcommand{\edwainitst}{\ensuremath{\edwastate_0}}
\newcommand{\edwavariables}{\ensuremath{X}}
\newcommand{\edwafinalst}{\ensuremath{F}}
\newcommand{\edwatrans}{\ensuremath{\delta}}
\newcommand{\edwavarup}{\ensuremath{\rho}}
\newcommand{\edwainit}{\ensuremath{I}}
\newcommand{\edwafinal}{\ensuremath{\mu}}
\newcommand{\edwapath}{\ensuremath{\pi}}
\newcommand{\edwavaluation}{\ensuremath{\nu}}

\newcommand{\edwavariable}{\ensuremath{x}}
\newcommand{\rlastate}{\ensuremath{r}}
\newcommand{\rlaalph}{\ensuremath{R}}
\newcommand{\rlatrans}{\ensuremath{\delta_R}}
\newcommand{\rlainit}{\ensuremath{\rlastate_0}}

\newcommand{\edwaexpr}[1]{\ensuremath{E(#1)}}
\def\pexpr{E^\hole}



\newcommand{\cainterp}{\ensuremath{\interp\oplus_{CA}}}
\newcommand{\pEDWA}{\EDWA()}

\newcommand{\pCEDWA}{\CEDWA()}
\newcommand{\ppCEDWA}{\CEDWA()}

\newcommand{\cpcn}{\ensuremath{\CostModel(\naturalnumb,+c)}}
\newcommand{\cpz}{\ensuremath{\CostModel(\integernumb,+)}}
\newcommand{\cpn}{\ensuremath{\CostModel(\naturalnumb,+)}}
\newcommand{\cpcr}{\ensuremath{\CostModel(\rationalnumb,+c)}}
\newcommand{\cpcz}{\ensuremath{\CostModel(\integernumb,+c)}}
\newcommand{\cpcac}{\ensuremath{\CostModel(\oplus c)}}
\newcommand{\cpac}{\ensuremath{\CostModel(\oplus)}}



\newcommand{\Exprp}[1]{\ensuremath{Expr_{\{\oplus c\}}(#1)}}
\newcommand{\Exprpp}[1]{\ensuremath{Expr_{\{\oplus\}}(#1)}}

\newcommand{\WA}{{\sc\textsc wa}\xspace}
\newcommand{\SVWA}{{\sc\textsc nsvwa}\xspace}

\newcommand{\srset}{\ensuremath{\domain}}
\newcommand{\srplus}{\ensuremath{\oplus}}
\newcommand{\srtimes}{\ensuremath{\otimes}}
\newcommand{\srzero}{\ensuremath{\bar{0}}}
\newcommand{\srone}{\ensuremath{\bar{1}}}

\newcommand{\emptystring}{\ensuremath{\varepsilon}}
\newcommand{\wa}{\ensuremath{W}}
\newcommand{\wastates}{\ensuremath{P}}
\newcommand{\wainitst}{\ensuremath{I}}
\newcommand{\wafinalst}{\ensuremath{F}}

\newcommand{\watrans}{\ensuremath{E}}
\newcommand{\wainit}{\ensuremath{\lambda}}
\newcommand{\wafinal}{\ensuremath{\rho}}
\newcommand{\wapath}{\ensuremath{\pi}}

\newcommand{\affineprogram}{\ensuremath{AP}}
\newcommand{\apvariables}{\ensuremath{X}}
\newcommand{\apvector}{\ensuremath{\texttt{x}}}
\newcommand{\apstates}{\ensuremath{N}}
\newcommand{\aptrans}{\ensuremath{E}}
\newcommand{\apinitst}{\ensuremath{\texttt{st}}}
\newcommand{\apstatement}{\ensuremath{\texttt{Stmt}}}
\newcommand{\papath}{\ensuremath{\pi}}

\newcommand{\DM}{{\sc\textsc dm}}
\newcommand{\dmvariables}{\ensuremath{R}}
\newcommand{\dmstates}{\ensuremath{S}}
\newcommand{\dmtrans}{\ensuremath{\eta}}
\newcommand{\dminitst}{\ensuremath{\texttt{st}}}
\newcommand{\dmfinalstates}{\ensuremath{F}}
\newcommand{\dmvarup}{\ensuremath{\beta}}

\newcommand{\PDM}{{\EDWA }}
\newcommand{\FDM}{{\EDWA }}
\newcommand{\GDM}{{\EDWA }}





\def\A#1#2#3{{\cal A}({#1},{#2},{#3})}


\newcommand{\exref}[1]{Ex.~\ref{ex:#1}\xspace}
\newcommand{\lemref}[1]{Lemma~\ref{lem:#1}\xspace}
\newcommand{\defref}[1]{Def.~\ref{def:#1}\xspace}
\newcommand{\secref}[1]{Sec.~\ref{sec:#1}\xspace}
\newcommand{\appref}[1]{Appendix~\ref{app:#1}\xspace}
\newcommand{\subsecref}[1]{Sec.~\ref{subsec:#1}\xspace}
\newcommand{\figref}[1]{Fig.~\ref{fig:#1}\xspace}
\newcommand{\algoref}[1]{Algorithm~\ref{algo:#1}\xspace}
\newcommand{\procref}[1]{\ref{proc:#1}\xspace}
\newcommand{\tableref}[1]{Table~\ref{tab:#1}\xspace}
\newcommand{\thmref}[1]{Theorem~\ref{thm:#1}\xspace}
\newcommand{\eqnref}[1]{\ref{eqn:#1}\xspace}
\newcommand{\ruleref}[1]{Rule~\ref{eq:#1}\xspace}
\newcommand{\consref}[1]{Cons.~\ref{eq:#1}\xspace}
\newcommand{\algolineref}[1]{Line~\ref{algoline:#1}\xspace}
\newcommand{\lineref}[1]{Line~\ref{line:#1}\xspace}
\newcommand{\transdof}[1]{\llbracket#1\rrbracket}
\newcommand{\setof}[1]{\{#1\}}
\newcommand{\es}{\varepsilon}
\newcommand{\pset}[1]{2^{#1}}

\newcommand{\lmark}{\vdash}
\newcommand{\rmark}{\dashv}

\newcommand{\ie}{{\em i.e.}\xspace}
\newcommand{\eg}{{\em e.g.}\xspace}
\newcommand{\etc}{{\em etc.}\xspace}
\newcommand{\viz}{{\em viz.}\xspace}
\newcommand{\etal}{{\em et al.}\xspace}


\newcommand{\loris}[1]{}
\newcommand{\jyo}[1]{}
\newcommand{\mux}[1]{}
\newcommand{\yyf}[1]{}
\newcommand{\changeto}{}

\tikzstyle{smalltext}=[font=\fontsize{7}{7}\selectfont]
\tikzstyle{captiontext}=[font=\fontsize{9}{9}\selectfont]
\tikzstyle{state}=[draw, ellipse, minimum height=5mm,
                   minimum width=5mm, inner sep=1pt,
                   text=black, font=\fontsize{8}{8}\selectfont,
                   semithick]

\def\myplus{\otimes}
\def\mytimes{\oplus}

\def\dadd{\,\underline\mytimes\,}
\def\dscale{\,\underline\myplus\,}
\def\gdplus{\,\underline{+}\,}




\begin{document}
\thispagestyle{empty}
\begin{titlepage}

\title{Regular Functions, Cost Register Automata, and Generalized Min-Cost Problems}

\author{
Rajeev Alur \and
Loris D'Antoni \and
Jyotirmoy V. Deshmukh \and
Mukund Ragothaman \and
Yifei Yuan
}



\maketitle
\thispagestyle{empty}

\begin{abstract}
Motivated by the successful application of the theory of regular
languages to formal verification of finite-state systems, there is a
renewed interest in developing a theory of analyzable functions from
strings to numerical values that can provide a foundation for
analyzing {\em quantitative\/} properties of finite-state systems.  In
this paper, we propose a deterministic model for associating costs
with strings that is parameterized by operations of interest (such as
addition, scaling, and ), a notion of {\em regularity\/} that
provides a yardstick to measure expressiveness, and study decision
problems and theoretical properties of resulting classes of cost
functions.  Our definition of regularity relies on the theory of
string-to-tree transducers, and allows associating costs with events
that are conditional upon regular properties of future events.  Our
model of {\em cost register automata\/} allows computation of regular
functions using multiple ``write-only'' registers whose values can be
combined using the allowed set of operations.  We show that classical
shortest-path algorithms as well as algorithms designed for computing
{\em discounted costs\/}, can be adopted for solving the min-cost
problems for the more general classes of functions specified in our
model.  Cost register automata with  and increment give a
deterministic model that is equivalent to {\em weighted automata\/},
an extensively studied nondeterministic model, and this connection
results in new insights and new open problems.
\end{abstract}

\end{titlepage}


\section{Introduction}
\mypar{Motivation}
The classical shortest path problem is to determine the minimum-cost
path in a finite graph whose edges are labeled with costs from a
numerical domain.  In this formulation, the cost at a given step is
determined locally, and this does not permit associating alternative
costs in a speculative manner. For example, one cannot specify that
``the cost of an event  is 5, but it can be reduced to 4 provided
an event  occurs sometime later.'' Such a constraint can be
captured by the well-studied framework of {\em weighted
automata\/}~\cite{Sch61,droste_handbook_2009}.  A weighted automaton
is a {\em nondeterministic\/} finite-state automaton whose edges are
labeled with symbols in a finite alphabet  and costs in a
numerical domain. Such an automaton maps a string  over  to
the minimum over costs of all accepting paths of the automaton over
.  There is extensive literature on weighted automata with
applications to speech and image processing~\cite{MPR02}.  Motivated
by the successful application of the theory of regular languages to
formal verification of finite-state systems, there is a renewed
interest in weighted automata as a plausible foundation for analyzing
{\em quantitative\/} properties (such as power consumption) of
finite-state systems~\cite{CDH10,AKL10,almagor_what_2011}.  Weighted
automata, however, are inherently nondeterministic, and are restricted
to cost domains that support two operations with the algebraic
structure of a {\em semiring}, one operation for summing up costs
along a path (such as ), and one for aggregating costs of
alternative paths (such as ).  Thus, weighted automata, and
other existing frameworks
(see~\cite{colcombet_regular_2010,neven_finite_2004}), do not provide
guidance on how to combine and define costs in presence of multiple
operations such as paying incremental costs, scaling by discounting
factors, and choosing minimum.  In particular, one cannot specify that
``the cost of an event  is 10, but for every future occurrence of
the event , we offer a refund of 5\% to the entire cost
accumulated until .'' The existing work on ``generalized shortest
paths'' considers extensions that allow costs with future discounting,
and while it presents interesting polynomial-time
algorithms~\cite{goldberg_combinatorial_1988,
oldham_combinatorial_1999}, does not attempt to identify the class of
models for which these algorithmic ideas are applicable.  This
motivates the problem we address: {\em what is a plausible definition
of regular functions from strings to cost domains, and how can such
functions be specified and effectively analyzed?\/}


\mypar{Proposed Definition of Regularity}

When should be a function from strings to a cost domain, say the set
 of natural numbers, be considered {\em regular\/}? Ideally, we
wish for an abstract machine-independent definition with appealing
closure properties and decidable analysis questions.  We argue that
the desired class of functions is parameterized by the operations
supported on the cost domain.  Our notion of regularity is defined
with respect to a regular set  of terms specified using a grammar.
For example, the grammar  specifies terms that can
be built from constants using a binary operator , and the grammar
 specifies terms that can be built from
constants using two binary operators  and  in a left-linear
manner.  Given a function  that maps strings to terms in , and
an interpretation  for the function symbols over a domain
, we can define a cost function  that maps a string  to
the value .  The theory of tree transducers, developed
in the context of syntax-directed program transformations and
processing of XML documents,  suggests that the class of {\em
regular\/} string-to-term transformations has the desired trade-off
between expressiveness and analyzability as it has appealing closure
properties and multiple characterizations using transducer models as
well as Monadic-Second-Order
logic~\cite{engelfriet_macro2_1999,courcelle_graph_2002,alur_stt_2011,Ho11}.
As a result, {\em we call a cost function  from strings to a cost
domain  regular with respect to a set  of terms and an
interpretation  for the function symbols, exactly when 
can be expressed as a composition of a regular function from strings
to  and evaluation according to .}

\mypar{Machine Model: Cost Register Automata}

Having chosen a notion of regularity as a yardstick for
expressiveness, we now need a corresponding machine model that
associates costs with strings in a natural way.  Guided by our recent
work on {\em streaming
transducers\/}~\cite{alur_streaming_2011,alur_stt_2011}, we propose
the model of {\em cost register automata}: a CRA is a deterministic
machine that maps strings over an input alphabet to cost values using
a finite-state control and a finite set of cost registers.  At each
step, the machine reads an input symbol, updates its control state,
and updates its registers using a parallel assignment, where the
definition is parameterized by the set of expressions that can be used
in the assignments.  For example, a CRA with increments can use
multiple registers to compute alternative costs, perform updates of
the form  at each step, and commit to the cost computed in
one of the registers at the end.  Besides studying CRAs with
operations such as increment, addition, min, and scaling by a factor,
we explore the following two variants.  First, we consider models in
which registers hold not only cost {\em values}, but (unary) {\em cost
functions\/}: we allow registers to hold pairs of values, where a pair
 can represent the linear function .  Operations on
such pairs can simulate ``substitution'' in trees, and allow computing
with contexts, where parameters can be instantiated at later steps.
Second, we consider ``copyless'' models where each register can be
used at most once in the right-hand-sides of expressions updating
registers at any step.  This ``single-use-restriction'', known to be
critical in theory of regular tree
transducers~\cite{engelfriet_macro2_1999}, ensures that costs (or the
sizes of terms that capture costs) grow only linearly with the length
of the input.


\mypar{Contributions}
In Section~4, we study the class of cost functions over a domain
 with a commutative associative function ; in
Section~5, we study the class of cost functions over a semiring
structure with domain  and binary operations  (such
as ) and  (such as addition); and in Section~6, we
consider different forms of discounted cost functions with scaling and
addition.  In each case, we identify the operations a CRA must use for
expressiveness equivalent to the corresponding class of regular
functions, and present algorithms for computing the min-cost value and
checking equivalence of CRAs.  We summarize some interesting insights
that emerge from our results about specific cost models.  First, our
notion of regularity implies that regular cost functions are closed
under operations such as string reversal and regular look-ahead,
leading to an appealing symmetry between past and future.  Second, the
use of multiple registers and explicit combinators allows CRAs to
compute all regular functions in a deterministic manner.  Third,
despite this added expressiveness, decision problems for CRAs are
typically analyzable.  In particular, we get algorithms for solving
min-cost problems for more general ways of specifying discounting than
known before.  Fourth, since CRAs ``construct'' costs over an infinite
domain, it suffices to use registers in a ``write-only'' mode without
any tests.  This critically distinguishes our model from the
well-studied models of {\em register machines}, and more recently,
{\em data
automata\/}~\cite{kaminski_finite_1994,neven_finite_2004,bjorklund_notions_2010}:
a data automaton accepts strings over an infinite alphabet, and the
model allows at least testing equality of data values leading to
mostly negative results regarding decidability.  Fifth, it is known
that weighted automata are not determinizable, which has sparked
extensive research~\cite{mohri_weighted_2009,
kirsten_determinization_2005}.  Our results show that in presence of
multiple registers that can be updated by explicitly applying both the
operations of the semiring, classical subset construction can be
modified to get a deterministic machine.  Finally, the class of
regular functions over the semiring turns out to be a {\em strict\/}
subset of functions definable by weighted automata due to the copyless
(or linear) restriction.  It is known that checking equivalence of
weighted automata over the tropical semiring (natural numbers with
 and addition) is
undecidable~\cite{krob_equality_1992,almagor_what_2011}. Existing
proofs critically rely on the ``copyful'' nature raising the
intriguing prospect that equivalence is decidable for regular
functions over the tropical semiring.

\section{Cost Register Automata}\label{sec:cra}
\mypar{Cost Grammars}
A ranked alphabet  is a set of function symbols, each of which
has a fixed arity.  The arity-0 symbols, also called constants, are
mapped to domain elements.  To allow infinite domains such as the set
 of natural numbers, we need a way of encoding constants as
strings over a finite set of symbols either in unary or binary, but we
suppress this detail, and assume that there are infinitely many
constant symbols.  The set  of terms over a ranked
alphabet is defined in the standard fashion: if  is a constant
symbol in , then , and if
 and  is an arity- symbol
in , for , then .
A {\em cost grammar}  is defined as a tuple 
where  is a ranked alphabet and  is a {\em regular}
subset of . In this paper, we define this regular
subset using a grammar containing a single nonterminal.  In
particular, we focus on the following grammars: For a binary function
symbol , the terms of the {\it additive-grammar } are
specified by , where  is a constant, and the
terms of the {\it increment-grammar } are specified by .  Given binary functions  and , the terms of
the {\em min-inc-grammar \/} are given by , which restricts the use of addition
operation.  Given binary functions  and , the terms of the {\it
inc-scale Grammar } are generated by the left-linear
grammar , that uses both operations in
a restricted manner, and  and  denote constants, ranging over
possibly different subsets of domain elements.

\mypar{Cost Models}
Given a cost grammar , a cost model
 is defined as the tuple ,
where the {\em cost domain\/}  is a finite or infinite set.
For each constant  in ,  is a unique value in
the domain , and for each function symbol  of arity ,
 defines a function .
We can inductively extend the definition of  to assign
semantics to the terms in  in a standard fashion.  For a
numerical domain  such as  (the set of natural numbers)
and  (the set of integers), we use 
to denote the cost model with the cost grammar , domain
, and  as the standard addition operation.
Similarly,  denotes the cost model with the cost
grammar , domain , and  as the standard
addition operation.  For cost grammars with two operations we denote
the cost model by listing the domain, the two functions, and sometimes
the subdomain to restrict the set of constants used by different
rules:  denotes the cost model with
the cost grammar , the set  of
non-negative rational numbers as the domain,  and  interpreted
as standard addition and multiplication, and the rational numbers in
the interval  as the range of encodings corresponding to the
scaling factor .

\mypar{Cost Register Automata}
A {\em cost register automaton} (\EDWA) is a deterministic machine
that maps strings over an input alphabet to cost values using a
finite-state control and a finite set of cost registers.  At each
step, the machine reads an input symbol, updates its control state,
and updates its registers using a parallel assignment.  It is
important to note that the machine does not test the values of
registers, and thus the registers are used in a ``write-only'' mode.
The definition of such a machine is parameterized by the set of
expressions that can be used in the assignments.  Given a set  of
registers and a cost grammar , we define the set of assignment
expressions  by extending the set of terms in 
so that each internal node can be replaced by a register name.  For
example, for the additive grammar , we get the set
 of expressions defined by the grammar , for ; and for the , we get
the expressions  defined by the grammar , for .  We assume that the
ranked alphabet contains a special constant symbol, denoted 0, used as
the initial value of the registers.

Formally, a cost register automaton  over a cost grammar  is a tuple
 where
 is a finite input alphabet,
 is a finite set of states,
 is the initial state,
 is a finite set of registers,
 is the state-transition function,

is the register update function, and
 is a {\em partial\/}
final cost function.

The semantics of such an automaton is defined with respect to a cost
model , and is a partial
function  from  to
.  A configuration of  is of the form
, where  and
the function  maps each
register to a cost in .  Valuations naturally map expressions
to cost values using the interpretation of function symbols given by
the cost model.  The initial configuration is
, where  maps each register
to the initial constant .  Given a string , the run of  on  is a sequence of
configurations  such that for ,
 and for each , .  The
output of  on , denoted by
, is undefined if
 is undefined, and otherwise it equals
.

\mypar{CRA-definable Cost Functions}
Each cost model  defines a
class of cost functions : a partial function  from
 to  belongs to this class iff there exists a
\EDWA\  over the cost grammar  such that  equals
.  The class of cost functions
corresponding to the cost model  is abbreviated as
, the class corresponding to the cost model
 as , etc.

\newcommand{\sqp}{\ensuremath{\!\!+\!\!}}
\newcommand{\muc}{\multicolumn{1}{c}}

\begin{figure}[t]
\begin{tikzpicture}[->,-stealth',semithick]

\node[state] (q0) {};
\node[coordinate,node distance=7mm,above left of=q0] (start1) {};
\draw (start1) to (q0);

\draw (q0) to[loop left] node[smalltext, left] (t1) {} (q0);
\node[smalltext,node distance=5mm,left of=t1]
     {};

\draw (q0) to[loop above] node[smalltext, above] (t2)
        {}
      (q0);

\draw (q0) to[loop below] node[smalltext, below] (t3)
        {}
      (q0);

\node[smalltext,node distance=19mm,below of=q0] {};

\node[coordinate,node distance=27mm,below of=q0]  (co1) {};
\node[captiontext,node distance=3mm, left of=co1] (cap1) {: CRA over};
\node[coordinate,node distance=3mm,below of=cap1]  (co11) {};
\node[captiontext, node distance=3.5mm,right of=co11] {};


\node[state,right of=q0,node distance=30mm] (q02) {};
\node[coordinate,node distance=7mm,above left of=q02] (start2) {};
\node[font=\fontsize{6}{6}\selectfont,right of=start2,node distance=1.5mm,
      anchor=south east] {};
\draw (start2) to (q02);

\draw (q02) to[loop left] node[smalltext, left, node distance=1.5mm] (t4) {}
      (q02);
\node[smalltext,node distance=6mm,left of=t4]
     {};
\draw (q02) to[loop above] node[smalltext, above] (t5) {}
      (q02);

\node[smalltext,node distance=6mm,above right of=t5]
      {};

\draw (q02) to[loop below] node[smalltext, below, node distance=1.5mm]
        {}
      (q02);

\node[smalltext,node distance=19mm,below of=q02] {};

\node[coordinate,node distance=27mm,below of=q02]  (co2) {};
\node[captiontext,node distance=3mm, left of=co2] (cap1) {: Copyless CRA};
\node[coordinate,node distance=3mm,below of=cap1]  (co22) {};
\node[captiontext, node distance=3.5mm,right of=co22] {over };


\node[state,right of=q02,node distance=22mm] (q03) {};
\node[state,right of=q03,node distance=25mm] (q13) {};
\node[coordinate,node distance=7mm,above left of=q03] (start3) {};
\draw (start3) to (q03);
\draw (q03) to[loop below] node[smalltext, below, node distance=1.5mm]
        {}
      (q03);
\draw (q03) to[loop above] node[smalltext, above]
        {}
      (q03);
\draw (q03) to node[node distance=2mm,above,smalltext] (mid)
        {}
      (q13);
\draw (q13) to[loop above] node[smalltext, above]
        {}
      (q13);

\draw (q13) to[loop right] node [smalltext, right] (lab3) {} (q13);
\node[smalltext,right of=lab3,node distance=4mm]
     {};
\draw (q13) to[loop below] node[smalltext, below, node distance=1.5mm]
        {}
      (q13);
\node[smalltext,node distance=24mm,below of=mid]
    {};
\node[captiontext,node distance=31mm, below of=mid] (cap3) {: CRA over};
\node[coordinate,node distance=3mm,below of=cap3] (co3) {};
\node[captiontext,node distance=4mm, right of=co3] {};


\node[state,right of=q03,node distance=52mm] (q04) {};
\node[state,right of=q04,node distance=20mm] (q14) {};
\node[coordinate,node distance=7mm,above left of=q04] (start4) {};
\draw (start4) to (q04);
\draw (q04) to[loop above] node [smalltext,above] {} (q14);
\draw (q04) to[loop below] node [smalltext,below] {} (q14);
\draw (q04) to node[smalltext,above] (mid4) {} (q14);
\draw (q14) to[loop below] node[smalltext,below]
     {}
      (q14);
\draw (q14) to[loop above] node[smalltext,above]
     {}
      (q14);
\node[smalltext,node distance=23mm,below of=mid4]
    {};
\node[captiontext,node distance=30mm,below of=mid4] (cap4) {: CRA over};
\node[coordinate,node distance=3mm,below of=cap4] (co4) {};
\node[captiontext,node distance=3mm, right of=co4] {};

\end{tikzpicture}
\caption{Examples of Cost Register Automata\label{rcfex1}}
\end{figure}


\mypar{Examples}
Figure~\ref{rcfex1} shows examples of cost register automata for
.  Consider the cost function  that maps a
string  to the length of the substring obtained by deleting all
's after the last occurrence of  in .  The automaton
 computes this function using two cost registers and
increment operation.  The register  is incremented on each symbol,
and hence equals the length of string processed so far.  The register
 is not incremented on  symbols, but is updated to the total
length stored in  when  symbol is encountered.  This example
illustrates the use of two registers: the computation of the desired
function  in register  update crucially relies on the
auxiliary register .

For a string  and symbol , let  denote the count of 
symbols in .  For a given string  of the form , where each block  contains only 's and
's, let  be the minimum of the set
.  The \EDWA\ 
over the grammar  computes this function using three
registers by an explicit application of the  operator.

For a given string , where each
 contains only 's and 's, consider the function  that
maps  to .  This function is computed by the
\EDWA\  over the grammar .

The final example concerns use of scaling. Consider a computation
where we wish to charge a cost of  upon seeing an  event until
a  event occurs.  Once a  event is triggered, for every
subsequent  event, the cost is discounted by . Such a cost
function is computed by the \EDWA\  over the grammar
.

\mypar{Copyless Restriction}
A \EDWA\  is said to be {\em copyless\/} if each register is
used at most once at every step: for each state  and input
symbol  and each register , the register  appears at
most once in the set of expressions  and  appears at most once in the output expression
.  Each cost model  then defines another class of cost functions
: a partial function  from  to
 belongs to this class iff there exists a copyless \EDWA\
 over the cost grammar  such that  equals
.  In Figure~\ref{rcfex1}, the
automata for function  and  are copyless, while the ones for
 and  are not.

\mypar{Regular Look-Ahead}\label{subsec:rla}
A \EDWA\  with {\em regular look-ahead} (\REDWA) is a
\EDWA\xspace that can make its decisions based on whether the
remaining suffix of the input word belongs to a regular language.  Let
 be a regular language, and let  be a DFA for  (such
a DFA exists, since regular languages are closed under the reverse
operation). Then, while processing an input word, testing whether the
suffix  belongs to  corresponds to testing whether
the state of  after processing  is an accepting
state of .  We now try to formalize this concept Let  be a word over , and let  be a DFA with states 
processing words over . Then the \emph{-look-ahead labeling} of
, is the word  over the alphabet  such
that for each position , the corresponding symbol is
the state of the DFA  after reading  (it reads the
reverse of the word).  A \REDWA consists of an DFA  over
 with states , and a \EDWA  over the input
alphabet .  The output of \REDWA  on , denoted by
, is defined as
.  In Figure~\ref{cra_rla} we
show the \REDWA for  of Figure~\ref{rcfex1}.

\begin{figure}[t]
\centering
\begin{tikzpicture}[->,-stealth',semithick]

\node[state] (q0) {};
\node[coordinate,node distance=7mm,above left of=q0] (start0) {};

\draw (start0) to (q0);

\draw (q0) to[loop above] node[smalltext,above,near end]
           {} (q0);
\draw (q0) to[loop below] node[smalltext,below]
           {}  (q0);
\draw (q0) to[loop right] node[smalltext,right]
           {} (q0);
\node[smalltext,below of=q0,node distance=15mm] {};

\node[state,right of=q0,node distance=52mm] (r0) {};
\node[state,above right of=r0,node distance=40] (r1) {};
\node[state,below right of=r0,node distance =40] (r2) {};
\node[state,right of=r0,node distance=70] (r3) {};
\node[coordinate,node distance=7mm,left of=r0] (start1) {};

\draw (start1) to (r0);
\draw (r0) to node [smalltext,above left] {} (r1);
\draw (r0) to node [smalltext,below left] {} (r2);
\draw (r1)[loop above] to node [smalltext,above left] {} (r1);
\draw (r1) to[out=0, in=100] node [smalltext,above] {} (r3);
\draw (r2)[loop right] to node [smalltext,right] {} (r2);
\draw (r2) to node [smalltext,right] {} (r1);
\draw (r3)[loop right] to node [smalltext,above left] {} (r3);
\draw (r3) to[out=180, in=315] node [smalltext,above] {} (r1);



\end{tikzpicture}
\caption{On the left a \REDWA over  corresponding to  in
Figure~\ref{rcfex1}. On the right the corresponding labeling automaton.
The states of  corresponds to the languages used in the informal description of .
\label{cra_rla}}
\end{figure}


\section{Regular Cost Functions} \label{sec:rcf}
Consider a cost grammar .  The terms in 
can be viewed as trees: an internal node is labeled with a function
symbol  of arity  and has  children, and each leaf is
labeled with a constant.  A {\em deterministic streaming
string-to-tree transduction\/} is a (partial) function .  The theory of such transductions has been well
studied, and in particular, the class of {\em regular\/}
string-to-tree transductions has appealing closure properties, and
multiple characterizations using Macro-tree-transducers (with
single-use restriction and regular
look-ahead)~\cite{engelfriet_macro2_1999}, Monadic-Second-Order logic
definable graph transformations~\cite{courcelle_graph_2002}, and
streaming tree transducers~\cite{alur_stt_2011}.  We first briefly
recap the model of streaming string-to-tree transducers.

\mypar{Streaming String-to-Tree Transducers (\SSTT)} A streaming
string-to-tree transducer is a deterministic machine model that can
compute regular transformations from strings to ranked trees in a
single pass.  We note that \SSTT can be viewed as a variant of
\EDWA~\footnote{To make the connection precise, we need to allow
registers in CRAs to be {\em typed\/}, and use function symbols with
typed signatures. We also use  to denote the output function
instead of ,. For simplicity of presentation, we defer this detail
to a later version.}, where each register stores a term, that is, an
{\em uninterpreted expression}, and these terms are combined using the
rules allowed by the grammar.  To obtain a model whose expressiveness
coincides with the regular transductions, we must require that the
updates are copyless, but need to allow terms that contain ``holes'',
\ie, parameters that can be substituted by other terms.

Let  be a cost grammar.  Let  be a special
0-ary symbol that denotes a place holder for the term to be
substituted later. We obtain the set  by adding the symbol
 to , and requiring that each term has at most one leaf
labeled with .  For example, for the cost grammar ,
the set  of parameterized terms is defined by the grammar ; and for the cost grammar , the set
 of parameterized terms is defined by the grammar , where  stands for (complete)
terms generated by the original grammar .  A
parameterized term such as  stands for an incomplete
expression, where the parameter  can be replaced by another
term to complete the expression.  Registers of an \SSTT hold
parameterized terms.  The expressions used to update the registers at
every step are given by the cost grammar, with an additional rule for
{\em substitution\/}: given a parameterized expression  and another
expression , the expression  is obtained by substituting
the sole -labeled leaf in  with the expression .

Given a set  of registers, the set
 represents parameterized expressions that
can be obtained using the rules of , registers in
, and substitution.  For example, for the grammar
 and a set  of registers, the set
 is defined by the grammar , for .  The output
of an \SSTT  is a (complete) term in  defined using the final
cost function.  The register update function and the final cost
function are required to be {\em copyless}: each register is used at
most once on the right-hand-side in any transition.  The semantics of
an \SSTT gives a partial function from  to .
We refer the reader to \cite{alur_stt_2011} for details.

\mypar{Regular Cost Functions}\label{subsec:reg}
Let  be a finite input alphabet.  Let  be a cost
domain. A {\em cost function}  maps strings in  to
elements of . Let 
be a cost model.  A cost function  is said to be {\em regular with
respect to the cost model \/} if there exists a regular
string-to-tree transduction  from  to  such that
for all , .  That is, given a
cost model, we can define a cost function using an \SSTT: the \SSTT
maps the input string to a term, and then we evaluate the term
according to the interpretation given by the cost model.  The cost
functions obtained in this manner are the regular functions.  We use
 to denote the class of cost functions regular with
respect to the cost model .

As an example, suppose .  Consider a vocabulary with
constant symbols ,  and , and the grammar .
Consider the \SSTT  with a single register that is initialized
to , and at every step, it updates  to  on input ,
and  on input .  Given input , the \SSTT
generates the term , where each
 if  and  otherwise.  To obtain the
corresponding cost function, we need a cost model that interprets the
constants and the function symbol , and we get the cost of the
input string by evaluating the expression .  Now, consider another
\SSTT  that uses a single register initialized to .  At
every step, it updates  to  on input , and
 on input , using the substitution operation.  The
output is the term  obtained by replacing the parameter by 0.
Given input , the \SSTT generates the term , where each  if  and 
otherwise.  Note that the \SSTT~ builds the cost term by adding
costs on the right, while the \SSTT~ uses parameter
substitution to build costs terms in the reverse order.  If the
interpretation of the function  is not commutative, then these two
mechanisms allow to compute different functions, both of which are
regular.

Let's now consider a different grammar. Consider the constant symbols
,  and , and the grammar .
Consider the \SSTT~ with a single register that is initialized
to  and, at every step, it updates  to  on input 
and to  on input .
Given input , the \SSTT
generates the term
, where each
 if  and  otherwise.
Now, consider another
\SSTT  that uses a single register initialized to .
At every step, it updates  to  on input , and
 on input , using the substitution operation.  The
output is the term  obtained by replacing the parameter by 1.
Given input , the \SSTT
generates the term
, where each
 if  and  otherwise. The same considerations as before follow.


\mypar{Closure Properties}
If  is a regular cost function from  to a cost domain
, then the {\em domain} of , \ie, the set of strings 
such that  is defined, is a regular language. Closure properties
for regular string-to-tree transductions immediately imply certain
closure properties for regular cost functions.  For a string , let
 denote the reverse string.  We define a {\em reverse function}
 such that for all , .
Given cost functions  from  to  and a
language , the {\em choice\/} function ``if 
then  else '' maps an input string  to  if , and to  otherwise.  If the two cost functions  and
 are regular and if  is a regular language, then the choice
function is also regular. We now show that regular cost functions are
closed under reverse and regular choice.

\begin{theorem}[Closure Properties of Regular Cost Functions]
For every cost model ,
\begin{enumerate}
\item[(a)]
if a cost function  belongs to the class , then
so does the function ;
\item[(b)]
if cost functions  and  belong to the class ,
then so does the function ``if  then  else '' for every regular language .
\end{enumerate}
\end{theorem}

\Proof~ (a) The proof of the first statement follows from the
application of theorems from
\cite{alur_expressiveness_2010,alur_stt_2011}.  Let  be a regular
cost function belonging to the class , and let
 be an \SSTT that computes the function . A streaming string
transducer (\SST) is a machine similar to an \SSTT. It maps strings to
strings with the help of a fixed number of registers that store
strings, and uses updates that involve concatenating registers and
strings in a copyless fashion.  Given an alphabet , computing
the reverse  of strings  is an \SST-definable
transduction \cite{alur_expressiveness_2010}.  Let \SST~ that
computes such a transduction. As proved in \cite{alur_stt_2011}, the
composition of an \SST-definable transduction and an \SSTT~definable
transduction is an \SSTT~definable transduction.  Thus the sequential
composition of  and  is also \SSTT~definable. Thus, for
every regular function  in , we can construct the
\SSTT  that maps every string  to the
corresponding term , which is, by definition, the cost
function .   Thus, if  belongs to , so
does .

(b) To prove the second statement, we show how we can construct an
\SSTT  that defines the function ``if  then  else
.''  As  and  are regular cost functions, they are
definable by \SSTT~ and  respectively. The
\SSTT~ maintains  disjoint sets of registers, where the
first set corresponds to registers of  and the second to the
registers of . A state of  is a tuple ,
where  and  exactly track the states of  and
, and  is the state of the DFA corresponding to the regular
language . The output function of  is defined such that if
the input word  is in  (\ie, it is accepted by the corresponding
DFA), then  uses the first set of registers to compute the
output, and, otherwise uses the second set of registers.  For any cost
model, the  exactly defines the choice function.  \qed

An \SSTT with regular look ahead is a pair  where  is
an \SSTT and  a DFA.  As discussed earlier regular-look-ahead tests
allow machines to make its decisions based on whether the remaining
suffix of the input word belongs to a given regular language.  \SSTT
are closed under the operation of regular-look-ahead
\cite{alur_stt_2011}, which implies the same for regular cost
functions.

\begin{theorem}[Closure Under RLA]\label{thm:stt-rla}
For every cost model \SSTT with regular-look-ahead , there
exists an \SSTT  without regular-look-ahead which computes the
same function.
\end{theorem}
\Proof~Theorem 9 in \cite{alur_stt_2011}.
\qed

\mypar{Constant Width and Linear Size of Output Terms}
While processing symbols of an input string , in each step an \SSTT
performs a copyless update. Thus, the sum of the sizes of all terms
stored in registers grows only by a constant additive factor.  It
follows that  is .  Viewed as a tree, the depth of
 can be linear in the length of , but its width is
constant, bounded by the number of registers.  This implies that if
 is a cost function in , then  must be
. In particular, the function  is not regular in
this cost model.  Revisiting the examples in \secref{cra}, it turns
out that the function  is regular for , and
the function  is regular for .  The
function  does not appear to be
regular for , as it seems to require
 terms to construct it.

\section{Commutative-Monoid Cost Functions}\label{sec:cmcf}
In this section we explore and analyze cost functions for the cost
models of the form , where  is a cost
domain (with a designated identity element) and the interpretation
 is a commutative and associative function.


\mypar{Expressiveness}
Given a cost model , we can use regular
string-to-term transductions to define two (machine-independent)
classes of functions: the class  defined by
the grammar  and the class 
defined by the grammar .  Relying on commutativity and
associativity, we show these two classes to be equally expressive.
This class of ``regular additive cost functions'' corresponds exactly
to functions computed by CRAs with increment operation, and also, by
copyless-CRAs with addition.  We are going to show the result via
intermediate results.


\begin{lemma}
\label{ssttostt}
For cost domain  with a commutative and associative operation
,
.
\end{lemma}
\Proof~  is
trivially true.  We now prove the other direction.  Consider a
function  over 
defined by the \SSTT~. In effect,  outputs trees over the
grammar .  We show that there exists an \SSTT~ that
outputs trees over the grammar  and computes .  As
shown in \cite{alur_stt_2011} the class of string-to-tree
transductions computable by an \SSTT coincides with the class of
transductions computed by MSO transducers
\cite{engelfriet_macro2_1999}. Thus, for a given \SSTT , there
is an MSO string-to-tree transducer  that computes .

The {\em yield} of a tree  is the string obtained by concatenating all
the leaves of  as they appear in an pre-order search.  In Lemma 7.6
of \cite{engelfriet_macro2_1999}, the authors prove that computing the
yield of a tree is an MSO-definable transduction.  Consider the MSO
tree-to-string transducer  that computes the yield of trees over
the grammar .  Essentially, the yield of a tree 
generated by the \SSTT  contains constant symbols. If

is a commutative and associative operator, the order in which the
symbols appear is not important, and any tree  with internal nodes
 and leaves corresponding to the yield of  represents an
equivalent expression to the one represented by .

 outputs strings over  where  is the set of constants in the
output alphabet of .  Given a string  over  we
want to produce the string  that belongs to the grammar
. This transduction is clearly MSO-definable (it is a
simple relabeling). Let  be the MSO transducer that computes this
relabeling.

As MSO transducers are closed under composition
\cite{engelfriet_macro2_1999} the transduction  is also MSO-definable.  Observe that for any string ,  is a term equivalent to the function ,
but is a term over the cost grammar  (due to
associativity and commutativity of ).  Clearly,
 computes the function .  As MSO-definable transductions are
equivalent to \SSTT-definable transductions, there is an \SSTT
 equivalent to . Thus for every  in
 (defined by the \SSTT ) there is an
\SSTT  that defines an equivalent function in
.
\qed

\begin{lemma}
\label{mvcmrtosst}
For cost domain  with a commutative associative operation ,
.
\end{lemma}
\Proof~ Consider a cost function  belonging
to .  We show that we can construct an \SSTT
 such that for all , .

Recall that a cost function in  is definable
by a \EDWA  over , where  is given
by the tuple
.
In order to construct the desired \SSTT , we first construct an
\SSTT with regular-look-ahead, denoted by  that computes
.  Here  is an \SSTT defined by the tuple
 and  is a DFA 
specifying the regular-look-ahead. Given an input string , recall
that  reads -labeled words corresponding to the run of 
on the reverse string .

The final cost function  of the \EDWA  maps a state
to a term in . This can be extended to the partial function
 as follows. For
all , , and
 is obtained by replacing each  in
 by the expression .
 gives the output of  starting in state 
after reading . For the grammar , it is easy to
show by induction that for all  and , the expression
 contains at most one register name.

We now describe how the RLA automaton  is
constructed.  Consider an input string , and recall
that  reads the reverse string .  At position , we need 
to report the register name that will contribute to the final output,
\ie, the register that ``flows'' into the final output after 
reads the remaining suffix . To do so, each state
of  is a pair  of the form  such that
 and
 is a
function mapping every state in  to a register name or a
special empty symbol.  While reading a string  in the
reverse order, the invariant maintained by a state  of 
is that if for each state , if the \EDWA 
reads the symbol , then the register name that flows into the
final output after reading the string  is
.



The initial state of , , where
 if  is the (only) register name appearing in
, and is  if no register name appears in
. Note that the first component of the state, \ie, the
input symbol is not used at this point as this corresponds to the case
where the \SSTT~ has reached the end of the string. We define
 using the register update functions of  as follows:

Suppose  is in state  and it reads the symbol
.  We define , where
the function  is defined as follows:



In the above definition,  is some constant in .
We can now define how the state transition function  and
register update function  of  are defined:
 if in , .  In
state ,  exactly knows the register  that
contributes to the final output by reading the symbol .
Thus, it is enough for  to have just one register (denoted
).  For an expression  in , let  be the
expression obtained by renaming the register  to .  The register
update function  is defined to be
 if ,
and  otherwise.

Finally, as \SSTT are closed under regular-look-ahead, there exists an
\SSTT  equivalent to the \SSTT with regular-look-ahead .
Thus for every function definable by \EDWA over , there exists an \SSTT  that computes , which means that
 is in .
\qed


\begin{lemma}
\label{ppcedwatopedwa}
For cost domain  with a commutative associative operation
, .
\end{lemma}

\Proof~ Consider a function  belonging to
.  Let

be a copyless \EDWA~over  that computes .  We
construct an
\EDWA~
over  that also computes .

For every subset ,  maintains a
register denoted by .   maintains the following invariant: If
the configuration of  is , then the
corresponding configuration of  is  such
that for all , .  Informally, each register  maintains the sum of the
registers in the set .

The update function  of  corresponding to the updates of
 can be defined as follows.  Let .
Note that the expression  is composed of two parts: an expression
denoting the sum of register names, and a constant obtained by summing all
the constants in each of the  expressions. Let 
denote the set of registers appearing in  and let  denote the
computed constant.  Then, we define . Note that as  is copyless, for every , any register  appears in the expression  at most once. Also note that
 may not be copyless as the registers  denoting the same
subset  may appear in two or more expressions . The
output function can be define in a similar fashion by defining the
expression  to be , and setting .
\qed

See Fig. \ref{subsetc} for an example of this construction.  The CRA on
the right of the figure will have one register for every possible subset
of registers of the CRA on the left of the figure. Let's consider the
transition on the symbol .  In the original CRA the update performed on
 is  and all the other registers are reset to .  This
means that for all the  containing ,  is updated to
 while all the other registers are reset.

\begin{figure}[t]
\centering
\begin{tikzpicture}[->,-stealth',semithick]

\node[state] (q0c) {};
\node[coordinate,above left of=q0c,node distance=7mm] (start0c) {};
\draw (start0c) to (q0c);

\draw (q0c) to[loop above] node[smalltext,above]
          {}
      (q0c);

\draw (q0c) to[loop below] node[smalltext,below]
          {}
      (q0c);

\draw (q0c) to[loop right] node[smalltext,right]
          {}
      (q0c);
\node[smalltext,below of=q0c,node distance=35mm] {};
\node[captiontext,below of=q0c,node distance=45mm] {(a) \EDWA};

\node[state,node distance=50mm,right of=q0c] (q0) {};
\node[coordinate,above left of=q0,node distance=7mm] (start0) {};
\draw (start0) to (q0);
\draw (q0) to[loop above] node[smalltext,above] (t) {} (q0);

\node[smalltext,node distance=15mm,above of=t]
          {};

\draw (q0) to[loop below] node[smalltext,below] (u) {} (q0);

\node [coordinate,node distance=15mm,below of=u] (ub) {};
\node [smalltext,right of=ub,node distance=5mm]
          {};

\draw (q0) to[loop right] node[smalltext,right]
          {} (q0);
\node[smalltext,node distance=35mm,below of=q0] {};
\node[captiontext,below of=q0,node distance=45mm] {(b) Corresponding \EDWA};

\end{tikzpicture}
\caption{Translation from copyless \EDWA to \EDWA\label{subsetc}}
\end{figure}

\begin{lemma}
\label{ssttopcedwa}
For a cost domain  with a commutative and associative operation
, .
\end{lemma}

\Proof~ Consider a function  belonging to
, \ie, there is an \SSTT
 over the cost grammar 
such that , for the cost model
.  We show how we can construct a
copyless \EDWA~

over  that also computes .

The \EDWA faithfully mimics the computation of the \SSTT  in its
state. The only difference is the register update function and the
final output function.  The translation ensures that  maintains
the invariant that if a configuration of  is
, the corresponding configuration for  is
 such that for all ,
.

A register update expression  for  has one of the
following forms: , , .
Except for the last assignment, each RHS expression is in
, and with , can be can be
directly mimicked by  by setting  to be the
expressions   and  respectively.  To simulate
, we note that as  is associative and
commutative, for a term in , the term  is
equivalent to the term . Thus, with ,  can simulate parameter substitution by the {\em copyless}
assignment .  The output function  can be
mimicked in a similar fashion for the corresponding expressions in
.
\qed



\begin{theorem}[Expressiveness of Additive Cost Functions]\label{regplus}
For cost domain  with a commutative associative operation ,
.
\end{theorem}
\Proof~ Follows from Lemma
\ref{ssttostt},\ref{mvcmrtosst},\ref{ppcedwatopedwa} and
\ref{ssttopcedwa}.
\qed \\

We can also establish the following results establishing an
expressiveness hierarchy between different classes.  First we show
that the copyless restriction for \EDWA over 
reduces the expressivity.

\begin{theorem}\label{thm:plus-c-copying-essential}
.
\end{theorem}

\Proof~ Consider the function  computed by the \EDWA  in
Fig.  \ref{rcfex1} that maps a string  to the length of the
substring obtained by deleting all 's after the last occurrence of
 in . We show that for any fixed , there does not exist a
copyless \EDWA capable of computing this function.

Assume that \edwa~is a copyless \EDWA~ over  that
can compute this function with  registers.  Without loss of
generality we can assume that in every assignment of the form ,  and  are the same register (if the original machine is
doing some copyless renaming, we can remember the renaming in the
state).

Now consider a string of the form , where
 is greater than the number of states in . Thus, for each
, while processing the  block of , some
state  (possibly depending on the block number ) must
be visited at least twice. For each , let  be the register
used to calculate the output after reading the input string .
Now observe that for all ,  and  are necessarily
distinct: if we pump  to ,
the value of  after  blocks must be unchanged, but the
value of  must change. We have thus established that a different
register must be used to produce the output after each block, but
this is not possible if the machine has only a finite number ()
of registers.
\qed

We then show that removing the copyless restriction from CRAs over
 is too permissive as it allows computing cost
functions that grow exponentially.

\begin{theorem}
\label{mvcmtomvcmr}
There exists a \EDWA~\edwa~over  that cannot be
expressed as a copyless \EDWA~\edwa~over , \ie,
.
\end{theorem}

\Proof~We prove this result by contradiction.  We create a
\EDWA~\edwa~over  over the alphabet  such
that on the first  it perform the update  and on the
subsequent 's it performs the update . Given a string , the function computed is .  Let's assume that there
exists a copyless \EDWA~ that can compute .  By Theorem
\ref{regplus}, there must be an \SSTT~ in  that also computes .  However, as the output is not linearly
bounded, this function cannot be computed by an \SSTT and so we reach
a contradiction.  \qed \\

Finally we show that having multiple registers is essential for
expressive completeness.

\begin{theorem}\label{kvar}
For every , there is a cost function  so that every
\EDWA~ over  has at least  registers.
\end{theorem}

\Proof~For each , consider the function
 defined as
.  The input  is
expressed in a unary alphabet .  This function
outputs one of , , , \ldots{}, , depending on the
length of .

First, these functions can be implemented by a \EDWA  (shown
in \Fig \ref{fig:k-var-reqd:MRAA:M_k}).   has  registers
, \ldots{}, , all initialized to  and has  states
, \ldots{}, .  For each , , , and .

\begin{figure}
\begin{centering}
\begin{tikzpicture}

  \node [place] (q0)    [              label=below:  ] {};
  \node [place] (q1)    [right=of q0,  label=below:  ] {};
  \node         (el1)   [right=of q1                        ] {};
  \node [place] (qi)    [right=of el1, label=below:] {};
  \node         (el2)   [right=of qi                        ] {};
  \node [place] (qkm1)  [right=of el2, label=below:  ] {};

  \draw [->] (q0)   to                 (q1);
  \draw [->] (q1)   to                 (el1);
  \draw [->] (el1)  to                 (qi);
  \draw [->] (qi)   to                 (el2);
  \draw [->] (el2)  to                 (qkm1);
  \draw [->] (qkm1) to [out=135, in=45] (q0);

\end{tikzpicture}
\par\end{centering}

\caption{\label{fig:k-var-reqd:MRAA:M_k}\EDWA~  implementing .
Each transition performs , for all .}
\end{figure}

We now show that at least  registers are necessary. Consider
otherwise, and say we are able to produce such an \EDWA~  with
 registers.  The main idea is that the difference between any two
{}``sub''-functions  and , , grows without bound
Since  works over a unary input
alphabet, the only form it can assume is that of a lasso (\Fig
\ref{fig:k-var-reqd:MRAA:Mkm1:Structure}). Say there are 
states in the initial approach to the loop, and  states in a
single pass of the loop.

\begin{figure}
\begin{centering}
\begin{tikzpicture}

  \node [place] (q0)                       {};
  \node         (el1) [right=of q0]        {};
  \node [place] (q1)  [right=of el1]       {};

  \node [place] (q2)  [right=of q1]        {};
  \node         (el2) [below right=of q2]  {};
  \node [place] (q3)  [above right=of el2] {};
  \node         (el3) [above left=of q3]   {};

  \draw [->] (q0)  to                   (el1);
  \draw [->] (el1) to                   (q1);
  \draw [->] (q1)  to                   (q2);

  \draw [->] (q2)  to [out=270, in=180] (el2);
  \draw [->] (el2) to [out=0, in=270]   (q3);
  \draw [->] (q3)  to [out=90, in=0]    (el3);
  \draw [->] (el3) to [out=180, in=90]  (q2);

  \begin{pgfonlayer}{background}

    \node [background, fit=(q0) (el1) (q1), label=below: states] {};
    \node [background, fit=(q2) (el2) (q3) (el3), label=below: states] {};

  \end{pgfonlayer}

\end{tikzpicture}
\par\end{centering}
\caption{\label{fig:k-var-reqd:MRAA:Mkm1:Structure}The structure of a possible
-register \EDWA~  implementing .}
\end{figure}

In the following argument, let  denote the largest constant that
appears in the description of .  Without loss of generality, we can
assume that no register renaming occurs, as for a \EDWA with register
renaming, there is an equivalent \EDWA with no register renaming, by
tracking register renaming as part of its state. Thus, if in state
, if  is the expression  (where ), then there is no  such that  appears in
.

Also observe that no register that ever gets reset during the loop can
contribute to the output afterwards. Say there is some transition
during which  is updated as . If this register
influences the output  states later, then for , the output must be incorrect.

Now pick some state  occurring in the loop. Say that the output in
 depends on some register . Let us call  good if register
 in  influences the output in some state  which
is  transitions from . At least one good state has to exist,
since the machine has at most  registers. We now use the presence
of this good state to derive a contradiction: the outputs in  and
 can differ by no more than . But since  and
 are closer than  steps apart, they output necessarily
different functions, and hence for , the outputs in
these two states are required to differ by more than this amount. The
contradiction is complete.
\qed \\

We now prove some closure properties of the model.

\begin{theorem}[Addition]
Given two CRAs  and  over the cost model ,
there exists a \edwa~over the same cost model such that  .
\end{theorem}

\Proof~ Given  (where
) we construct . We assume  and
 are disjoints sets.  The registers in  are
pairs of the form  or singletons of the form .  Whenever
, while processing an input word , is in the configuration
,  has the configuration
 such that:
(1) ,
(2)  if , and
(3)  if .

We now define the update functions  and .
Given , define
,
and
.

Given an expression ,  is equal 
when  is the only variable appearing in , to  when
 are the only two variable
appearing in  and  when no variable appears in ,
while  is the sum of all the constants appearing in .  Note
that, at every point, at most 2 registers can appear in the combined
right-hand side.  The output function can be defined in a similar way.
\jyo{We need a little more explanation here.} By construction 
computes the right function.
\qed

\begin{theorem}[Subtraction]\label{subtraction}
Given two CRAs  and  over the cost model ,
there exists a  over the same cost model such that
 .
\end{theorem}
\Proof~ Similar to the proof for addition.
\qed \\


\mypar{Weighted Automata}\label{wa}
A weighted automaton~\cite{droste_handbook_2009} over an input
alphabet  and a cost domain  is a {\em
nondeterministic\/} finite-state automaton whose edges are labeled
with input symbols in  and costs in .  For an input
string , the automaton can have multiple accepting paths from its
initial state to an accepting state.  The semantics of the automaton
is defined using two binary functions  and  such
that  is associative and commutative, and 
distributes over  (to be precise, form a {\em semiring\/}
algebraic structure).  The cost of a path is the sum of the costs of
all the transitions along the path according to , and the
cost of a string  is obtained by applying  to the set of
costs of all accepting paths of the automaton over .


Let  be the semiring .
Formally, a weighted automaton \WA with weights from , from an
input alphabet  into the domain  is a tuple  where  is a finite input alphabet,  is a
finite set of states,  the set of initial
states,  the set of final states,
  a finite multiset of transitions, which are elements of
,  an initial weight function, and  a final weight function mapping
 to .

Consider a string  and a \WA~\wa.  A
sequence  is an accepting
in sequence for  if, for every ,
 and .  The weight
of  (denoted as ) is computed as .  Given a word  we denote by 
the set of all the accepting paths of .  The weight  of the
string  is defined as: 
where  is also an operation over .  A weighted automaton
is called {\em single-valued} if each input string has at most one
accepting path\footnote{In some of the literature these are called
\emph{unambiguous} weighted automata, while a \emph{single-valued}
weighted automaton is one where the weights of all the accepting paths
are the same. The two notions are proved to be equivalent.}.  To
interpret a single-valued weighted automaton, we need only an
interpretation for . Thus, we can compare the class of
functions definable by such automata with regular additive functions.

\begin{theorem}[Single-valued Weighted Automata]\label{exprplus}
A cost function  is in 
iff it is definable by a single valued weighted automaton.
\end{theorem}
\Proof~ Let  a \emph{single valued} weighted automaton that
computes the function .  We construct an
\SSTT with \emph{regular look-ahead}
,
 that computes . The \SSTT  uses the cost
grammar  to construct its terms.  We then use
\thmref{stt-rla} to show that there exists an \SSTT~ that computes
, which means that  is regular.

Even though  is nondeterministic, since it is \emph{single
valued}, it will have only one accepting path.  We construct
 such that the states in  give information on
what is the next transition to take to reach an accepting path.  Every
state  is a pair  where
 and  is a partial function
from  to . After reading the  symbol of
the input word ,  and  if:
1)  for some , and
2) if  starts reading  in , it will reach an accepting state.

The initial state  is defined as .  and for
every  . The initial state does not encode
any information as it corresponds to the case where the  has
reached the end of the string .  We now define . Suppose
 is in state  and it is reading the input . The new state
will be  where  if  is defined and
 for some .

We now define the state transition function for the \SSTT . We
define  if .  Particular attention must
be made for the case when  is in state .  In this
case on input symbol ,  where 
is the only state in  such that . Notice that
there can be only one state of this form otherwise  would not be
single valued.  For every transition of the form  in
, in , the register update function  maps 
to the expression . This shows that for every weighted
automaton , we can construct an \SSTT  over the cost
grammar  such that for all input strings ,
.

We now prove the other direction.  By Theorem~\ref{regplus} we know
that every function  in  can be computed
by a \EDWA  over . Let
.
We show how we can construct a \emph{single valued} weighted automaton
 that
also computes .

After processing an input word , if  has the configuration
, we have that: corresponding to every  there exists a path in  from the initial state such that the
cost along that path is equal to .  Let's now give the
definition of :
(1) if  and , then ,
(2) if  and , then , and
(3) if , ,
The nodes  are always reachable with cost  and are used to
represent resets, but none of them is accepting.  can be
defined in a similar way.

A simple inductive proof establishes that in a \EDWA over
, in any state, only one register eventually
contributes to the final output, or in other words, only one value
flows to the final output. Thus, the constructed weighted automaton is
is single-valued.
\qed

An example of the translation of the function  of
Figure~\ref{rcfex1} is in Figure~\ref{wam1}. The machine has only two
states , and . If we take for example the transition
of the first automaton when reading , we can see that  is
updated to . In the automaton of Figure~\ref{wam1} this is
reflected by the transition from  to  with label 
and with weight .


\begin{figure}[t]
\centering
\begin{tikzpicture}[->,-stealth',semithick]

\node[state] (q0) {};
\node[state,right of=q0,node distance=30mm] (q1) {};
\node[coordinate,above left of=q0,node distance=10mm] (start0) {};
\node[coordinate,above left of=q1,node distance=10mm] (start1) {};

\node[smalltext,above left of=start0,node distance=2mm] {};
\node[smalltext,above left of=start1,node distance=2mm] {};

\draw (start0) to (q0);
\draw (start1) to (q1);

\draw (q1) to node[smalltext,above] (mid) {} (q0);
\draw (q0) to[loop above] node[smalltext,above] {} (q0);
\draw (q0) to[loop below] node[smalltext,below] {}  (q0);
\draw (q1) to[loop above] node[smalltext,above] {} (q1);
\draw (q1) to[loop below] node[smalltext,below] {} (q1);
\draw (q1) to[loop right] node[smalltext,right] {} (q1);

\node[smalltext,node distance=17mm,below of=mid] {};
\node[smalltext,node distance=20mm,below of=mid] {};

\end{tikzpicture}
\caption{Weighted Automaton corresponding to  in Figure~\ref{rcfex1}\label{wam1}}
\end{figure}


\mypar{Decision Problems}
\paragraph{Minimum Costs.}
The shortest path problem for CRAs is to
find a string  whose cost is the minimum.
For numerical domain with addition, for CRAs with increment, we can solve the shortest path problem by reducing
it to classical shortest paths using the translation from CRAs with increment to single-valued weighted automata
used in the proof of Theorem~\ref{exprplus}.
If the CRA has  states and  registers, the graph has  vertices.
The exact complexity depends on the weights used: for example, if
the costs are nonnegative, we can use Dijkstra's algorithm.

\begin{theorem}[Shortest Path for CRAs with Inc]\label{pEDWAmcp}
Given a CRA  over the cost model , computing 
is solvable in .
\end{theorem}

\Proof~ We reduce the problem to shortest finding the shortest path in
a weighted graph. Using the construction of Theorem~\ref{exprplus} we
create a weighted graph. The graph has  nodes and
 edges where  are the number of states and variable of  respectively.  If the weights are all positive we can use
Dijkstra's algorithm with a final complexity of
 otherwise we can use
the Bellman-Ford algorithm, making the complexity .  \qed \\

\begin{figure}[t]
\centering
\begin{tikzpicture}[->,-stealth',semithick]

\node[state] (q0) {};
\node[coordinate,left of=q0,node distance=7mm] (start) {};
\draw (start) to (q0);

\draw (q0) to[loop above] node[smalltext,above]
     {}
      (q0);

\node[coordinate,right of=q0,node distance=40mm] (mid) {};

\node[state,node distance=20mm,above of=mid] (q1) {};
\node[state,node distance=20mm,below of=mid] (q2) {};

\draw (q1) to[loop above] node[smalltext,above]
     {}
      (q1);

\draw (q2) to[loop below] node[smalltext,below]
     {}
      (q2);

\draw (q0) to node[smalltext,sloped,above]
     {}
      (q1);

\draw (q2) to node[smalltext,sloped,above]
     {}
      (q0);

\draw (q1) to node[smalltext,right]
     {}
      (q2);

\node[coordinate,node distance=20mm,right of=q0] (c) {};
\node[smalltext,below of=c,node distance=25mm]
        {};
\end{tikzpicture}
\caption{Example CRA over  needing less registers than CRA
over \label{succint}}
\end{figure}



Even though , the model
with addition can be more succinct (see Fig. \ref{succint} for an
example).  To solve minimum-cost problem for copyless-CRAs over  the
cost model , we can use the translation to CRAs
over  used in the proof of Theorem~\ref{regplus},
which causes a blow-up exponential in the number of registers. We can
establish an NP-hardness bound for the min-cost problem by a simple
reduction from 3-SAT.

\begin{theorem}[Shortest Paths for CRAs with Addition]\label{ppCEDWAmcp}
Given a copyless-CRA  over the cost model  with 
states and  registers, computing  is solvable in time polynomial in  and exponential
in .  Given a copyless CRA  over the cost model  and a
constant , deciding whether there exists a string  such
that  is \nphard.
\end{theorem}

\Proof~The first result follows from the complexity of the translation
in Lemma \ref{ppcedwatopedwa}.  For the second part we give a
reduction from 3-SAT.  Given an instance  where  is the set of literals and  the set
of clauses we construct a \EDWA  over .  is
defined as the tuple (), where
, , . The update functions are defined as follows:
For each , and , , and
 if the clause  becomes  when
the variable  is .  Similarly  if the clause  becomes  when  is
.  Finally, we define , and .  It is easy to see that
every path in the  corresponds to a unique valuation for the
literals . Finally, if the minimum-cost computed by
 is , then we have an instance of SAT, as there is a
valuation of the literals that makes every clause . If
the minimum-cost computed is greater than , then the conjunction of
the clauses is unsatisfiable.  This means that solving min-value
problem for a \EDWA over  is as hard as solving 3-SAT.
\qed \\

\paragraph{Equivalence and Containment.} Given two cost register
automata using addition over a numerical domain, checking whether they
define exactly the same function is solvable in polynomial time
relying on properties of systems of linear equations.

\begin{theorem}[Equivalence of CRAs with Addition]\label{thm:equiv-CRA-add}
Given two CRAs  and  over the cost model ,
deciding whether for all ,  is solvable in .
\end{theorem}
\Proof~
Given  (where
) we construct . We assume the two sets variables  and
 are disjoint.

For every  and
,
.
 updates the two constituent sets of registers separately. For
,
, and for

.

We want to check if along every path of the , and for every
state , the equation 
holds.  We adapt the algorithm for checking validity of affine
relations over affine programs presented in \cite{olm_note_2004} to do
this. The algorithm in \cite{olm_note_2004}, checks the validity of
affine relations (equality constraints over linear combinations of
real-valued or rational-valued program variables and constants), over
affine graphs (graphs where each edge is labeled by an affine
assignment). We can cast the equivalence check for CRAs over  as  a subcase of this problem.

The algorithm propagates the
equation  backward along each
transition using the register update function: for an edge from  to
 with some label , every equation  that must hold at
 yields an equation  that must hold at , where the
expressions  and  are obtained from  and  using
substitution to account for the update of registers along the edge
from  to .   will be equal to  where every register
 is replaced by .  At every
step of the back propagation, we compute the basis of the set of
equations in every state using Gaussian elimination.  If we reach a
system of equations with no solution the two machines are
inequivalent, while if we reach a fix point where no independent
equations can be added, the two machines are equivalent.

As shown in Theorem 2 of \cite{olm_note_2004}, such a propagation
terminates in  where  is the size of the machine (in
our case ) and  is the
number of registers (in our case
).



For CRAs that use only increment, the cubic complexity of the Gaussian
elimination in the inner loop of the equivalence check can be
simplified to quadratic: at every step  in the back propagation, all
equations are of the form .  The final complexity is

if we only have increments and

otherwise ( are as defined before).
\qed

We now show that general containment is also decidable in polynomial
time and that checking if a number is in the range of a CRA over
 is decidable in polynomial time.

\begin{theorem}[]
Given two CRAs  and  over the cost model ,
deciding whether 
is in .
\end{theorem}
\Proof~
We reduce the problem to shortest path. We in fact have that if
 then . But from Theorem
\ref{subtraction} we can construct an  which is equivalent to
 and has polynomial size. Now we can solve
shortest path on . The algorithm is clearly polynomial.
\qed

\begin{theorem}[ Range]
Given two CRAs   over the cost model  and a constant ,,
deciding whether  is in .
\end{theorem}
\Proof~
We reduce the problem to 0 reachability in a weighted graph. Using Theorem \ref{subtraction} we compute .
Now we want to check . We can create the same graph of shortest path
and look for a 0 path on it. The problem of -reachability over finite graphs is known to be in .
\qed


\section{Semiring Cost Models}\label{sec:scm}


In this section, we consider the cost models which result when the
cost model supports two binary operations,
 and , that impose a semiring structure (see subsection \ref{wa} for the definition of semiring).
This structure has been studied extensively in the literature on weighted automata and rational power series.
A specific case of interest is the {\em tropical semiring\/},
where the cost domain is ,  is the  operation, and  is arithmetic addition.
While choosing a grammar, we can restrict either or both of  and  to be ``unary''
(that is, the second argument is a constant).
To study the tropical semiring, it makes sense to choose  to be binary, while
addition to be unary. Hence, in this section, we will focus on the grammar ,
and the class  of cost functions.

\mypar{CRA Models}
Our first task is to find a suitable set of operations for cost register automata so as
to have expressiveness same as the class  .
It turns out that (unrestricted) CRAs with  and  are too expressive,
while their copyless counterparts are too restrictive.
We need to enforce the copyless restriction, but allow substitution.
In the proposed model, each register 
has two fields ranging over values from : .
The intuitive understanding is that  represents the expression
 where  denotes the parameter.
Such a pair can be viewed as the ``most evaluated'' form
of a parameterized term in the corresponding \SSTT.
Expressions used for the update are given by the grammar

where  is a register, and  and  are constants.
For the min-inc interpretation, the initial values are of the form
 corresponding to the additive
and multiplicative identities.
We require that registers are used in a copyless manner, so that any
particular register  appears in the update of at most one register.
The semantics of the operators on pairs is defined below:
 is defined to be  ;
 equals ; and
 is given by .
While registers contain and expressions evaluate to pairs, the output function projects out
the ``'' component of this pair: this is equivalent to instantiating the parameter  to , the additive
identity, since over semirings, the additive identity annihilates any other element under multiplication
().
The resulting model of CRA-definable cost functions is


\begin{example}
\label{ex:4:1:3}Consider strings ,
so that  is the number of 's between the closest
pair of 's. This function is in , but not in the more restricted classes:
 and . In figure \ref{fig:4:1:3}, we show
a 
machine that can compute . The output in both  and  is identically , while the output in 
is the ``'' component of the ouput function : .

\begin{figure}
\centering{}\begin{tikzpicture}

  \node [state] (q0) {};
  \node [coordinate,above left of=q0,node distance=7mm] (start) {};
  \node [state] (q1) [right=4cm of q0] {};
  \node [state] (q2) [right=4cm of q1] {};

  \draw [->] (start) to (q0);
  \draw [->] (q0) edge [loop above] node [smalltext]
    {} (q0);
  \draw [->] (q0) edge node [smalltext, label=above:{}] {} (q1);
  \draw [->] (q1) edge [smalltext, loop above] node
    {} (q1);
  \draw [->] (q1) edge node [smalltext, text width=2cm, label=above:{}] {} (q2);
  \draw [->] (q2) edge [smalltext, loop above] node
    {} (q2);
  \draw [->] (q2) edge [smalltext, loop below] node
    {} (q2);

 \node[below of=q1,node distance=15mm,smalltext]
      {};

\end{tikzpicture}\caption{\label{fig:4:1:3}The

machine for example \ref{ex:4:1:3}.}
\end{figure}

\end{example}

\mypar{Expressiveness}

The next theorem summarizes the relationship between functions definable by different CRA models. The rest of the session contains the proof of this theorem.

\begin{theorem}[Expressiveness of Semi-ring Cost Functions]\label{thm:semiring-exp}
If  forms a semiring, then

\end{theorem}
We split the proof into the following lemmas.
\begin{lemma}
If  forms a semiring, then

\end{lemma}
\Proof~
We first show that the containment holds and then that it is strict.
Copyless CRAs with  and  can be simulated by copyless CRAs operating over pairs and performing , , and . Given a  machine , construct an  machine  with the same states, and same registers. Replace every occurrence of  and  in the update expressions to  and  respectively.

To show strict containment, let 
be the tropical semiring. Our witness function is  from Fig.
\ref{rcfex1}. First off, observe that ,
as shown in figure \ref{rcfex_f1}. We now demonstrate that ,
and our proof is similar to that of theorem \ref{thm:plus-c-copying-essential}.

\begin{figure}[t]
\centering
\begin{tikzpicture}[->,-stealth',semithick]
\node[state] (q0) {};
\node[coordinate,node distance=7mm,above left of=q0] (start1) {};
\draw (start1) to (q0);

\draw (q0) to[loop left] node[smalltext, left] (t1) {} (q0);
\node[smalltext,node distance=5mm,left of=t1]
     {};

\draw (q0) to[loop above] node[smalltext, above] (t2)
        {}
      (q0);

\draw (q0) to[loop below] node[smalltext, below] (t3)
        {}
      (q0);

\node[smalltext,node distance=19mm,below of=q0] {};



\end{tikzpicture}
\caption{ from figure \ref{rcfex1} is in . \label{rcfex_f1}}
\end{figure}

We proceed by contradiction. Say we are given a copyless CRA machine
 over  that implements . Without
loss of generality, we can assume that in every update, a register
 is either reset, or appears in its own update expression: .

Consider a string of the form , where 
is greater than the number of states in . Thus, for each ,
while processing the  block of , some state
 (possibly depending on the block number ) must be visited
at least twice. For each , let  be the register which
influences the output after reading the input string .
Now observe that for all ,  and  are necessarily
distinct: if we pump  to ,
the value of  after  blocks must be unchanged, but the
value of  must change. We have thus established that a different
register must be used to produce the output after each block, but
this is not possible if the machine has only a finite number ( in this case)
of registers.
\qed

\begin{lemma}
If  forms a semiring, then

\end{lemma}
\Proof~
From the definition of CRAs the terms constructed by the SSTTs are in correspondence with their most evaluated versions maintained by CRAs.
\qed

\begin{lemma}\label{lemma:reg-to-cra}
If  forms a semiring, then

\end{lemma}
\Proof~
Consider a copyless CRA machine  over .
Let  be the set of its registers. We construct a copyful CRA 
over  equivalent to .
We perform the following subset construction over registers. The states
and transitions of  are the same as in .
The set of registers  of  is the following:
\begin{enumerate}
\item  and  for every .
\item for every , we maintain ,
and for all , .
\end{enumerate}
The expression on the right of each of the above equalities is the
intended invariant we'll maintain. Because of the properties of the
semiring, we can simplify the resulting expression into a linear form (an expression of the form , for some constants  and , where  ranges over the registers).

We define an elementary update in  as one in which:
the value of no register changes, or
exactly two registers permute: , or
exactly one register is reset: , or
exactly one register changes: , or
exactly two registers change (addition): , or
exactly two registers change (substitution): .
Observe that any copyless register update can be written as a finite
sequence of elementary updates. Also a finite sequence of updates
in a CRA machine over  can be summarized into a single update. Thus,
if we demonstrate a semantics-preserving transformation from elementary
updates to copyful linear updates, we are done.

Given a register , let  be its value before the update,
and  be its intended value after. We show that 
in each case can be written as a linear combination of the old values,
thus giving a linear update rule . Only the last two cases are interesting:

\begin{enumerate}
\item Addition: .

\begin{enumerate}
\item , . 
and .
\item For .  and .
\item For , . , .
, and .
\item For , , but . , ,
and . (Exactly the same as the previous case.)
\item For , , but . Let .
.
.
.
\item For , . .
.
.
\end{enumerate}
\item Substitution: . This shows why we needed to keep the subset
registers.

\begin{enumerate}
\item .
. 
and .
\item For ,  and .
\item For , . , .
, and .
\item For ,  but . Let .
.
, and .
\item , but . Let .
.
.
.
\item Both . Let .
.
.\end{enumerate}
\end{enumerate}
\qed\\\\
Finally, the containment established by the above theorem is strict.

\begin{lemma}
Over the tropical semiring, there exist functions in  which are not in .
\end{lemma}
\Proof~
An example of such a function is  in figure \ref{rcfex1}.
Regardless of the string , .
Thus, in any state , the machine has to contain, in some register
, . However, for all  and
, there is some  so that .
Let's identify some witness for this by writing .
In particular, this means that there has to be some register tracking
the value of the function, which is distinct from the register 
tracking . We have thus established that at least
two registers are necessary.

Consider a machine with two registers. For the largest constant 
appearing in the description of the machine, consider the string .
At this point, we have two registers - one containing the number of
s, and the other containing the function. If we now feed the machine
a suffix , the value
of the function is equal to the number of s in the input string.
The machine now has two choices: either copy the value, or choose
to track both the functions and the number of s in the same register.
This latter choice cannot happen: for we can then feed the suffix
,
and force the machine into making a mistake.

For multiple registers, we perform a multi-step pumping argument similar
to the above. Define the sequence: ,
, \ldots{},
,
\ldots{} The argument involves observing after reading each ,
the number of ``useful'' variables, in the absence of copyful assignments,
decreases by one: .
\qed

\mypar{Relation to Weighted Automata}
In Section~\ref{wa}, we noted that single-valued weighted automata correspond exactly to
CRAs with addition. Now we show that nondeterministic weighted automata and
(deterministic) CRAs (without the copyless restriction)
with  and  express exactly the same class of functions.
The translation from weighted automata to CRAs can be viewed
as a generalization of the classical subset construction for determinization.

\begin{theorem}[Weighted Automata Expressiveness]\label{wa-cra}
If  forms a semiring, then the
class of functions 
is exactly that representable by weighted automata.
\end{theorem}
\Proof~
Let  be a weighted
automaton. We construct the corresponding CRA  over :
The set of states . The state set is obtained by the standard
subset construction. The intuition is that  is in state 
after processing a string  if  is exactly the set of states
reached in  after processing . Thus, .
The initial state  is the set of initial states of the weighted
automaton, .
The set of registers is : there
is a register  for every state . The following is the intuition behind these registers: consider some state , and all paths from the set of initial states  to . Along each path, take the -product of the weights, and -add the values thus obtained for all paths. The intent is for  to hold this value.
For each state , the register  is initialized to
. Even though in the definition of CRAs, registers were initialized to  (or some other constant), by simply adding a new initial state which explicitly initializes registers before use, we can simulate registers being initialized to anything we choose.
When the CRA makes a transition , the register
update is given by , .
That is, to obtain the value of , we consider each
state  such that there is an -labeled transition from 
to  with cost  in the weighted automaton, add 
to  according to , and take  over all such
values.
In state , the output function is defined as .
The output function is the -sum of all the product of all
paths.
To prove the correctness of this construction, observe the inductive
invariant: for all , and for all states , the register 
in the CRA  contains the -sum of the -product
of the weights of all paths leading from some initial state to 
on . This depends on the distributivity of  over .
Note that the same register  contributes to all s
for all its -successor states . Thus, the update
is not necessarily copyless.


In the reverse direction, let  be a CRA over 
with states  and registers . Construct the following weighted
automaton :
\begin{enumerate}
\item The state set  is . Intuitively, a state 
calculates transformations happening to individual registers, and
states  calculates the constant offset possibly imposed by
the output function. Formally, after processing some word , if
 reaches state , then the value of register  is equal
to the value reaching state : along each path from
some initial state to , multiply all the weights,
and add the values thus obtained along all such paths. Also, such
paths exist iff processing  takes  to state .
\item The initial states are .
All initial weights are equal to the multiplicative identity.
\item Say the output function at  in  is given by .
Then, for each , the output weight ,
and .
\item For every transition  in , create the transition
 in . Also, for every variable update 
that occurs during this transition, create the transitions 
in  (for each ). Also add the transition .
That the intended invariant is maintained follows from the distributivity
properties of a semiring.\end{enumerate}
\qed


\mypar{Decision Problems for Min-Plus Models}
Now we turn our attention to semirings in which the cost domain
is a numerical domain such as ,  is the minimum operation, and  is the addition.
First let us consider shortest path problems for CRAs over the cost model .
Given a CRA over such a cost model, we can construct a weighted automaton using the construction
in the proof of Theorem~\ref{wa-cra}.
Shortest paths in a weighted automaton can be solved in polynomial-time using standard algorithms \cite{mohri_weighted_2009}.

\begin{theorem}[Shortest Paths in CRAs over min and ]
Given a CRA  over the cost model , computing 
is solvable in .
\end{theorem}

It is known that the equivalence problem for weighted automata over the tropical semiring
is undecidable.
It follows that checking whether two CRAs over the cost model  compute the same cost function,
is undecidable.
The existing proofs of the undecidability of equivalence rely
on the unrestricted non-deterministic nature of weighted automata, and thus on
the copyful nature of CRAs with  and .
We conjecture that the equivalence problem for copyless CRAs over ,
and also for the class  is decidable.


\section{Discounted Costs}\label{sec:disc}
In this section, we focus on the class of regular cost functions
definable using  and . Such cost functions allow both adding
costs and scaling by discount factors.

\mypar{Past Discounts} First let us focus on CRAs over the cost
model . At every step, such a
machine can set a register  to the value : this
corresponds to discounting previously accumulated cost in  by a
factor , and paying an additional new cost . We call such
machines the {\em past-discount} CRAs (see  of
Figure~\ref{rcfex1} for an example). Note that the use of multiple
registers means that this class of cost functions is closed under
regular choice and regular look-ahead: the discount factors can
depend conditionally upon future events. It is easy to check that
the cost functions definable by past-discount CRAs belong to the
class . Our main result for past-discount CRAs is
that the min-cost problem can be solved in polynomial-time. First,
multiple registers can be handled by considering a graph whose
vertices are pairs of the form , where  is a state of the
CRA, and  is a register. Second, classical shortest path
algorithm can be easily modified when the update along an edge
scales the prior cost before adding a weight to it, this is
sometimes called {\em generalized shortest path\/}
(see~\cite{batagelj_generalized_2000,oldham_combinatorial_1999}).

\newcommand{\fp}{f_{pd}}
\newcommand{\ff}{f_{fd}}

\begin{theorem}[Shortest Paths for Past Discounts]
Given a past-discount CRA  over the cost model
, computing  is
solvable in .
\end{theorem}
\Proof~
We reduce this problem to the {\em generalized shortest path\/}
 problem (see~\cite{batagelj_generalized_2000,oldham_combinatorial_1999}) on a graph, where edges are parameterized
 by cost  and weight  and the cost of a path  is
, while the weight of  is .

Consider a past-discount CRA ,
without loss of generality, assume that for each , , if , then
for all ,  has the form  for some ; and for all ,
if  is defined, then it has the form  for some .
We construct the following graph . For each  and ,  has a vertex .
Moreover,  has a source vertex , a target vertex . The graph  maintains the invariant that
there is a path from  to  if and only if there is a run of  such that the value of  in state  "flows" to the
final output.
\loris{This invariant is too informal, you should say something like:
The graph  maintains the invariant that
there is a path  from  to 
if and only if there exists a string 
such that  on  reaches the configuration 
and  (or something like that).
}
Formally, for each  and , such that
, for any register :
if , for some ,  has an
edge  from  to  with weight  and  cost .

Finally,
for all , if ,  has
an edge  from  to  with weight , cost ;
for each ,  has an edge  from  to ,  with weight , cost .

Given a run  of  on input string , if the output is defined,
we claim that there is a  path  in  such that the cost of  is equal to the output of  on .
For convenience, let's define  be the register that contributes to final output on state ,
i.e. ;  for all .
Let's define  be the function that outputs on state , i.e. ,
and for , .
It's clear that  is the final output of  on .
Let  be the path , where . It is easy to see that the cost of 
is equal to the cost of the path .
We inductively prove that .
In the base case, if , by construction,  and .
Therefore, .
Suppose, for all , the inductive invariant holds.
If , then
, since  and .
Therefore, the output of  on  .
On the other hand, given an  path ,  it is easy to see that there exists a run   of  on some string , that the output of  is equal to .
\qed

\mypar{Future Discounts} Symmetric to past discounts are future
discounts: at every step, the machine wants to pay an additional new
cost , and discount all future costs by a factor . While
processing an input , if the sequence of local costs
is  and discount factors is , then
the cost of the string is the value of the term . {\em Future-discount} CRAs are able to compute
such cost functions using registers that range over 
and substitution: each register holds a value of the form 
where  is the accumulated cost and  is the accumulated
discount factor, and updates are defined by the grammar . The interpretation for  is defined to be
 (that is, the current discount factor  is
scaled by new discount , and current cost  is updated by
adding new cost , scaled by the current discount factor ).
Like past-discount CRAs,future-discount CRAs are closed under
regular choice and regular look-ahead. Processing of future
discounts in forward direction needs maintaining a pair consisting
of cost and discount, and the accumulated costs along different
paths is not totally ordered due to these two objectives. However,
if we consider paths in ``reverse'', a single cost value updated
using assignments of the form  as in past-discount CRAs
suffices.


\begin{theorem}[Shortest Paths for Future Discounts]
Given a future-discounted CRA  over the cost model
, computing  is
solvable in .
\end{theorem}
\Proof~
We reduce this problem to the {\em generalized shortest path\/} problem
(see~\cite{batagelj_generalized_2000,oldham_combinatorial_1999}) on a graph.

Consider a future-discount CRA .
First we construct an equivalent future-discount CRA  that every updating function and output function has the form . Formally,
, where
 , such that . For each ,
 and , such that , for each :
\begin{enumerate}
\item if  for some , ;
\item if , ;
\item .
\end{enumerate}
For each ,  if ,
 otherwise.
Second, we construct the graph  with source  and target , such that there is a path  from  to  if and only if
there is a run  of  and some , such that .
Formally, for each , and each ,  has a vertex .
Moreover,  has a source vertex , a target vertex . For each
 and , such that
,  for each register :
if  for some ,  has an
edge  from  to , with weight , cost ;
Finally,
for each , if ,  has
an edge  from  to  with weight , cost ;
for each ,  has an edge  from  to , with weight , cost .

Given a run  of  on input string , if the output is defined,
we claim that there is a  path  in  such that the cost of  is equal to the output of  on .
Let's define  be the register that contributes to final output on state ,
i.e. ;  for all .
Let  be the path , where  and .
For simplicity. we abuse the notation of the name of register and functions to mean their values under
interpretation.
We inductively prove that .
In the base case,  by construction.
Suppose, for all , the inductive invariant holds.
If , then
,since by construction,
 and .
Therefore, the output of  on  , since by construction  and .
On the other hand, given an  path ,  it is easy to see that there exists a run   of  on some string , that the output of  is equal to .
\qed

\mypar{Global Discounts} A {\em global-discount CRA\/} is capable of
scaling the global cost (the cost of the entire path) by a discount
factor. As in case of future-discount CRAs, it uses registers that
hold cost-discount pairs. We now assume that discounts range over
 and costs range over . The registers are updated
using the grammar . The
interpretation for  is defined to be  (that is, the current discount factor  is scaled by new
discount , and current cost  is updated by first scaling it
by the new discount, and then adding new cost  scaled by the
current discount factor ). Analyzing paths in a global-discount
CRA requires keeping track of both the accumulated cost and
discount. We can show a pseudo-polynomial upper bound; it remains
open whether there is a strongly polynomial algorithm for shortest
paths for this model:

\begin{theorem}[Shortest Paths for Global Discounts]
Given a global-discount CRA  over the cost model
 and a constant , deciding
 is solvable in \np.
Computing the minimum is solvable in \ptime\ assuming increments are
restricted to adding natural numbers in unary encoding.
\end{theorem}
\Proof~
Consider a global-discount CRA 
, we construct a graph , that each edge  is parameterized with a cost  and a discount  as we did above.
For a path ,
the cost of the path is defined as   .
Following the proof above, it is easy to see solving the shortest path in  is equivalent to solving the shortest path in .

To prove the \np bound, we first observe that if there is a reachable cycle that
contains an edge  with , then repeating this cycle
drives the global discount to 0, and thus, existence of such a cycle implies
that the min-cost (at the limit) is 0.
Notice that the shortest path doesn't need to involve a cycle
in which all discount factors are equal to 1 (since costs are non-negative).
The \np-bound follows from following fact. We can write an \np algorithm that guesses: 1) a reachable cycle and verifies if there is an edge  with  in this cycle, or 2) a simple path and verify if its cost is less than .
Suppose incremental costs 's are small natural numbers.
The pseudo-polynomial algorithm for this case relies on the following idea: for a given value  and a vertex ,
computing the ``best'' global discount over all paths from source to  with
sum of incremental costs equal to , can be solved by adopting shortest path algorithms, and
the set of interesting choices of  can be bound by  for a graph with  vertices if
each increment is a number between  to . Thus a variation of Bellman-Ford suffices (See algorithm \ref{shortestpath}).
\begin{algorithm}
\caption{Shortest Path Algorithm on Global Discount CRA }
\label{shortestpath}
\begin{algorithmic}
    \STATE \slash \slash  stores the best global discount from  to  among paths with length , when the sum of incremental cost is .
    \STATE , for every node  and 
    \STATE 
    \FOR { to }
        \FORALL { in  and }
            \STATE 
        \ENDFOR
    \ENDFOR
    \STATE \slash \slash checks if there is a cycle with discount 
    \IF {, s.t. }
        \STATE return 
    \ENDIF
    \STATE \slash \slash Output the best simple path
    \RETURN 
\end{algorithmic}
\end{algorithm}
\qed

\mypar{Regular Functions for Inc-Scale Model} The class of regular
functions for the cost model  is defined via
SSTTs over the inc-scale grammar . It is to show that:

\begin{theorem}[Expressiveness of Inc-Scale Models]
The cost functions definable by past-discount CRAs, by
future-discount CRAs, and by global-discount CRAs all belong to
.
\end{theorem}

The min-cost problem for this class of functions is still open.
However, we can show the equivalence problem to be decidable. First,
using the construction similar to the one used to establish
 (see
Theorem~\ref{thm:semiring-exp}), we can represent cost functions in
 using (copyful) CRAs that use  and . Such
CRAs have {\em linear\/} updates, and the algorithm for checking
equivalence of CRAs with addition can be used for this case also.
\begin{theorem}
Given two functions  represented by SSTTs
over the cost grammar , checking whether the two
functions coincide, can be solved in time polynomial in the number
of states and exponential in the number of registers.
\end{theorem}
\Proof~
Given an \SSTT  for , we use lemma \ref{lemma:reg-to-cra} to construct an equivalent
CRA  using  and .  has the same number of states as , and an exponential number of variables.
We claim that checking equivalence between two CRAs with  and  is solvable in time polynomial in the number of
states and number of variables (the proof is similar to that of theorem \ref{thm:equiv-CRA-add}). Thus, checking the equivalence
of two functions  and  expressed as STTs over  can be done in time polynomial in the number of
states and exponential in the number of variables. \qed


\section{Related Work}\label{sec:rel}
\paragraph{Weighted Automata (\WA) and Logics.}
Finite-state \WA have been an active area of research, with numerous
articles studying their algebraic and algorithmic properties. See
\cite{droste_handbook_2009} for a comprehensive exposition.  An important
problem for \WA is that of determinization \cite{mohri_weighted_2009,
kirsten_determinization_2005}. A deterministic \WA is defined in the usual
sense: no two outgoing transitions from a state share the same input
label.  It has been shown that there are \WA that do not admit equivalent
deterministic \WA. In contrast, the cost register automata that we
introduce in this paper are deterministic machines with equivalent
expressive power and equally efficient decision problems as weighted
automata. We believe that this makes them a more suitable model for
expressing weighted computations.

It has been shown that the equivalence problem for \WA over the tropical
semiring is undecidable using a reduction from Hilbert's tenth problem
\cite{krob_equality_1992}, and by a reduction from the halting problem for
two counter machines \cite{almagor_what_2011}. The only known class of
weighted automata over the tropical semiring with decidable equivalence problem is that of
finite-valued weighted automata \cite{weber_finite_1994}. For a given ,
a weighted automaton is said to be -valued if the number of distinct
values computed along all accepting paths is at most . A weighted
automaton is called finite-valued if there exists a  such that it is
-valued.  We conjecture that the equivalence problem for \EDWA over
 and  with the copyless restriction is decidable. If this is
true, it would give the largest known class with decidable equivalence.
In \cite{Kiefer} the authors provide a randomized algorithm
to solve equivalence of weighted automata over the semiring with addition and
scaling.

In \cite{droste_weighted_2005}, the authors discuss a weighted
MSO-logic that disallows universal second order quantification and
places restrictions on universal first order quantification. The
authors show that the formal power series definable in this logic
coincides with the set of behaviors of weighted automata. In contrast,
in this paper, we introduce automata and machines that exactly capture
MSO-definable cost functions.

\paragraph{Discounted weighted computations and Generalized Shortest Paths.}
Generalized network flow problems extend flow problems on directed
graphs by specifying multipliers on edges in addition to costs
\cite{goldberg_combinatorial_1988, oldham_combinatorial_1999}.  The
problem of finding the minimum cost flow (which in some cases is
equivalent to the shortest distance path) from a source to a target
can be solved in polynomial time \cite{oldham_combinatorial_1999,
batagelj_generalized_2000}.  Future discount machines that we
introduce in this paper provide a nice formalism that subsumes such
problems, and have strongly polynomial time algorithms for determining
the minimum cost path.  In this paper, we also introduce past discount
and global discount machines that also have efficient algorithms for
determining the minimum cost paths.

In \cite{droste_weighted_2009}, the authors introduce weighted logic
for infinite words. In order to address convergence of the weighted
sum, the authors assume discounting along later edges in a path (\ie,
future discounting). Extending the results of this paper to discounted
weighted computations over infinite words remains open.

\paragraph{Transducer Models.}
A wide variety of different models have been proposed to model string
and tree transductions. The models that are most relevant to this
paper are MSO-definable transductions
\cite{courcelle_graph_2002,engelfriet_mso_2001} and macro tree
transducers \cite{engelfriet_macro_1985,engelfriet_macro2_1999}. An
MSO-definable graph transduction specifies a function between sets of
graphs; the nodes, edges and labels of the output graph are described
in terms of MSO formulas over the nodes, edges and labels of a finite
number of copies of the input graph.  A macro tree transducer (MTT) is
a top-down tree to tree transducer equipped with parameters.
Parameters can store temporary trees and append them to the final tree
during the computation. In general, MTT are more expressive than
MSO-definable tree transductions. A subclass of MTTs obtained by
restricting the number of times a subtree and a parameter can be used
has been shown to be equi-expressive as MSO-definable tree
transductions \cite{engelfriet_macro2_1999}. In addition to these
models, formalisms such as attribute grammars
\cite{engelfriet_macro2_1999}, attribute tree transducers
\cite{bloem_comparison_2000} have also been studied.

Streaming tree transducers \cite{alur_stt_2011} (STTs), introduced by
two of the co-authors in this paper are a new formalism for expressing
MSO-definable tree-to-tree and string-to-tree transductions. In
comparison to some of the transducer models discussed above, STTs have
distinguishing features that make them desirable as a canonical model
for specifying regular or MSO-definable transductions: (1) STTs
produce the output in linear time by performing a single pass over the
input, (2) they preserve desirable properties such as closure under
sequential composition and regular look-ahead, and (3) they have good
algorithmic properties such as decidability of functional equivalence.


\paragraph{Regularity over Data Languages.} Data languages allow
finite strings over data values that can be drawn from a possibly
infinite data domain \cite{neven_finite_2004},
\cite{kaminski_finite_1994} \cite{bjorklund_notions_2010}. Register
automata are often used as acceptors for data languages. A key feature
of such automata is that they allow registers to store and test data
values.  Beyond the similarity in nomenclature, register automata that
are studied in this line of work are quite distinct from cost register
automata introduced in this paper. The former are essentially defined
over an infinite input alphabet, and the critical difference lies in
the fact that almost every variant of data automata allows testing
equality of data values, which mostly causes interesting decision
problems to become undecidable. Cost register automata use the cost
registers in a strictly write-only fashion, which makes them
incomparable to variants of data automata that use read/write
registers.



\paragraph{Regular Cost Functions.}
In \cite{colcombet_theory_2009}, Colcombet defines a regular cost
function as a mapping from words to  (the set of
nonnegative integers and the ordinal ). A cost function is
precisely defined as an equivalence class over mappings from the set
of words to , such that functions  and  are
in the same equivalence class if for all words ,  is bounded
by some constant iff  is bounded is bounded by some constant.
The author then defines two classes of automata (- and
-automata), each of which uses a finite set of counters and allows
the counters to be incremented, reset or checked for equality with a
constant. The operational semantics of these automata are that the
automaton computes the least upper bound or the greatest lower bound
over the set of counter values encountered during its run. A cost
function is then called regular if it is accepted by a
history-deterministic - or -automaton.  The author also provides
an algebraic characterization of regular cost functions in terms of
stabilization monoids and equates recognizability of cost functions
with regularity. In \cite{colcombet_regular_2010}, the authors extend
this notion to regular cost functions over trees.

It is clear that the notions proposed in this line of work are
orthogonal to our characterization of regularity of cost functions.
The authors state that the motivation for the work in
\cite{colcombet_theory_2009,colcombet_regular_2010} is preserving nice
algorithmic and closure properties of regular languages for problems
such as equivalence and projection. However, the integer values in
these functions are considered modulo an equivalence which preserves
existence of bounds on the function values, but not the values
themselves. We believe that the notion of regularity of cost functions
that we propose in this paper is closer to the classical notions of
regularity such as MSO-definability.

\paragraph{Affine Programs.} In \cite{karr_affine_1976}, and more
recently in \cite{olm_note_2004, olm_precise_2004}, the authors
present the problem of deriving affine relations among variables of a
program.  An affine relation is a property of the form , where
 are program variables that range
over a field such as the rationals or reals and   are constants
over the same domain. An affine program is a program with
nondeterministic branching where each edge of the program is labeled
with an assignment statement of the form ,
\ie, where the RHS is an affine expression. We could define a \EDWA
over the cost model , with the cost
grammar . An affine program is then
simply obtained by ignoring the input labels of the transitions in
such a \EDWA.  While the cost functions defined by such \EDWA do not
have interesting regularity properties, we remark that the equivalence
of such \EDWA can be checked in polynomial time by using ideas similar
to the ones in \cite{olm_note_2004}.

\paragraph{Quantitative Languages.} A quantitative language
\cite{CDH10,almagor_what_2011,AKL10} over infinite words is a function
. Such languages are generated by
weighted automata, where the value of a word  is set as the maximal
value of all runs over . By defining various value functions such
as , , ,
, different values can be computed for the run of a
weighted automaton on the string .  Quantitative languages use the
fixed syntax of weighted automata, and thereby restricted to having a
single weight along each transition in their underlying automata.
Moreover, they face similar difficulties in determinization: for
interesting models of value functions, the corresponding automata
cannot be determinized.  An extension of \EDWA\ to -regular
cost functions could prove to be a more expressive and robust model to
specify quantitative languages and to analyze their decision problems.


\section{Conclusions}\label{sec:conc}
\usetikzlibrary{patterns}

\begin{figure}
\subfloat[Hierarchy for CRA models]{
\label{fig:hierarchy}
\begin{minipage}[t]{0.49\textwidth}
    \begin{tikzpicture}[fill opacity=0.2]
        \tikzstyle{textz}=[font=\fontsize{8}{8}\selectfont,text opacity=1,text=black]

        \draw[thick] (0.9,0.7) rectangle (4.9,3.0);
        \node at (0.9,1.0) [textz,right] {Global Discounts};

        \draw[very thick] (-0.2,0.5) rectangle (7.3,3.0);
        \node at (4.85,1.0) [textz, right] {Reg };
        \node at (4.85,0.7) [textz, right] { CRA Inc-Scale};

        \draw (0.9,1.2) rectangle (4.9,3.0);
        \node at (0.9,2.8) [textz,right] {Reg };
        \node at (0.9,2.45) [textz,right] {Reg };
        \node at (0.9,2.1) [textz,right] {CRA };
        \node at (0.9,1.75) [textz,right] {CopylessCRA };
        \node at (0.9,1.4) [textz,right] {Single-valued \WA};

        \draw[thick] (-0.1,1.2) rectangle (4.9,3.0);
        \node at (-0.1,2.8) [textz,right] {Past};
        \node at (-0.1,2.5) [textz,right] {Disc-};
        \node at (-0.1,2.2) [textz,right] {ounts};

        \draw[thick] (0.9,1.2) rectangle (6.3,3.0);
        \node at (4.85,2.8) [textz,right] {Future};
        \node at (4.85,2.5) [textz,right] {Discounts};

        \draw[semithick] (0.9,1.2) rectangle (4.9,3.4);
        \node at (0.85,3.2) [textz,right] {CopylessCRA };

        \draw[thick] (0.9,1.2) rectangle (4.9,3.8);
        \node at (0.9,3.6) [textz,right] {Reg };

        \draw[ultra thick] (0.9,1.2) rectangle (4.9,4.6);
        \node at (0.9,4.35) [textz,right] {CRA };
        \node at (0.9,4.0) [textz,right] {Weighted Automata};

\end{tikzpicture}
\end{minipage}
} \hfil
\subfloat[Complexity of Decision Problems]{
    \label{fig:complexity}
\begin{minipage}[t]{0.49\textwidth}
{\small
\begin{tabular}[b]{||l|c|c||}
\hline\hline
CRA with              &  Equivalence            & Min-Cost \bigstrut \\
\hline\hline
                &  \ptime                 & \ptime    \\
\hline
Copyless        &  \ptime                 & \exptime   \\
\hline
            &  Undecidable            & \ptime     \\
\hline
Copyless   &  ?                      & \ptime     \\
\hline
Past-discounts        &                         & \ptime     \\
\cline{1-1} \cline{3-3}
Future-discounts      &  Poly in states      & \ptime     \\
\cline{1-1} \cline{3-3}
Global-discounts      &  Exp in registers & Pseudo-Poly \\
\cline{1-1} \cline{3-3}
Inc-Scale             &                         & ? \\
\hline\hline
\end{tabular}}
\end{minipage}
}
\caption{Summary of Results\label{results}}
\end{figure}

We have proposed a new approach to define regular functions for associating costs with strings.
The results for various classes of functions are summarized in Figure~2.
We hope that our work provides new insights into the well-studied topic of weighted automata, and
opens a whole range of new problems.
First, it is plausible that there is a compelling notion of congruences and canonicity for CRAs with increment.
Second, the decidability of copyless-CRAs with  and increment remains an intriguing open problem.
Third, we don't have algorithms for the min-cost problem for the class of regular functions with increment and scaling.
While we have not succeeded even in establishing decidability, we suspect that this problem admits efficient
approximation algorithms.
Fourth, we have considered only a small set of combinations of operations; studying the effects of adding operators
such as {\it max} would be worthwhile. Fifth, our notion of regularity and cost register automata
for mapping strings to costs can be extended to infinite strings and trees, as well as to timed and probabilistic systems.
Finally, we would like to explore practical applications: our framework seems suitable for expressing
complex, yet analyzable, pricing policies, say, for power distribution.

\newcommand{\BIBdecl}{\setlength{\itemsep}{0em}}
\bibliographystyle{abbrv}
\bibliography{../rcf}


\end{document}
