We will use the operations from the previous section to obtain a dynamic algorithm for \BP with respect to large items. The operations insert and delete are designed to process the input depending of whether an item is to be inserted or removed. Keep in mind that the parameter $k = \lfloor \kappa\rfloor =  \left\lfloor\frac{\SIZE(I_L)\cdot \epsilon}{2(\lfloor \log(\nicefrac{1}{\epsilon})\rfloor +5)} \right\rfloor$ changes over time as $\SIZE(I_L)$ may increase or decrease. In order to fulfill the properties $\nameref{prop:c}$ and $\nameref{prop:d}$, we need to adapt the number of items per group whenever $k$ changes. The shiftA and shiftB operations are thus designed to manage the dynamic number of items in the groups as $k$ changes.
Note that a group in the $A$-block with parameter $k$ has by definition the same number of items as a group in the $B$-block with parameter $k-1$ assuming they are in the same size category. If $k$ increases, the former $A$ block is treated as the new $B$ block in order to fulfill the properties $\nameref{prop:c}$ and $\nameref{prop:d}$ while a new empty $A$ block is introduced. To be able to rename the blocks, the $B$ block needs to be empty. Accordingly the $A$ block needs to be empty if $k$ decreases in order to treat the old $B$ block as new $A$ block. Hence we need to make sure that there are no groups in the $B$-block if $k$ increases and vice versa, that there are no groups in the $A$-block if $k$ decreases.

We denote the number of all groups in the $A$-blocks at time t by $A(t)$ and the number of groups in $B$-blocks at time $t$ by $B(t)$. To make sure that the $B$-block (respectively the $A$-block) is empty when $k$ increases (decreases) the ratio $\frac{A(t)}{A(t)+B(t)}$ needs to correlate to the fractional digits of $\kappa(t)$ at time $t$ denoted by $\Delta(t)$. Hence we partition the interval $[0,1)$ into exactly $A(t)+B(t)$ smaller intervals $J_i=\left[\frac{i}{A(t)+B(t)},\frac{i+1}{A(t)+B(t)}\right)$. We will make sure that $\Delta(t)\in J_i$ iff $\frac{A(t)}{A(t)+B(t)}\in J_i$. Note that the term $\frac{A(t)}{A(t)+B(t)}$ is $0$ if the $A$-block is empty and the term is $1$ if the $B$-block is empty. This way, we can make sure that as soon as $k(t)$ increases, the number of $B$-blocks is close to $0$ and as soon as $k(t)$ decreases, the number of $A$-blocks is close to $0$. Therefore, the $A,B$-block can be renamed whenever $k(t)$ changes. The algorithm uses shiftA and shiftB operations to adjust the number of $A$- and $B$-blocks. Recall that a shiftA operation reduces the number of groups in the $B$-block by $1$ and increases the number of groups in the $A$-block by $1$ (shiftB works vice versa). Let $d$ be the number of shiftA/shiftB operations that need to be performed to adjust $\frac{A(t)}{A(t)+B(t)}$. 



\begin{figure}[ht]
  \begin{subfigure}{.99\textwidth}
\centering
\scalebox{0.9}{
\begin{tikzpicture}
\draw (0,0) -- (10,0);
\draw[very thick] (0,-7pt) -- (0,7pt);
\node at (0,-15pt) {$k(t-1)$};
\draw[very thick] (5,-7pt) -- (5,7pt);
\node at (5,-15pt) {$k(t-1)+1$};

\draw[very thick] (10,-7pt) -- (10,7pt);
\node at (10,-15pt) {$k(t-1)+2$};

\foreach \x in {0,1,...,9}{
  \draw (\x+1,-2pt) -- (\x+1,2pt);
}
\node at (0.5,10pt) {$J_{0}$};
\node at (1.5,10pt) {$J_{1}$};
\node at (2.5,10pt) {$\ldots$};
\node at (3.5,10pt) {$J_{j}$};
\node at (4.5,10pt) {$\ldots$};



\node[rectangle,draw,minimum width=8cm, minimum height=1cm] (A) at
(4,-2.7) {$A(t-1)$};
\node[below = of A,yshift=1cm] {98\%};
\node[right = of A, rectangle,draw,minimum width=1cm, minimum
height=1cm,xshift=-0.9cm] (B) {$B(t-1)$};
\node[below = of B,yshift=1cm] {2\%};

\node at (3.2,-23pt) (dt) {$\Delta(t-1)$};
\draw[thick,->] (dt) to (3.8,0);
\end{tikzpicture}
}
\caption{Before Insert}
  \end{subfigure}

  \begin{subfigure}{.99\textwidth}
\centering
\scalebox{0.9}{
\begin{tikzpicture}[every text node part/.style={align=center}]
\draw (0,0) -- (10,0);
\draw[very thick] (0,-7pt) -- (0,7pt);
\node at (0,-25pt) {$k(t)-1$\\ $\|$ \\$k(t-1) $};
\draw[very thick] (5,-7pt) -- (5,7pt);
\node at (5,-25pt) {$k(t)$\\$\|$ \\$k(t-1)+1$};

\draw[very thick] (10,-7pt) -- (10,7pt);
\node at (10,-25pt) {$k(t)+1$\\$\|$\\$k(t-1)+2$};

\foreach \x in {0,1,...,9}{
  \draw (\x+1,-2pt) -- (\x+1,2pt);
}
\node at (5.5,10pt) {$J_{0}$};
\node at (6.5,23pt) {$J_j$\\ $\|$ \\ $J_{1}$};
\node at (7.5,10pt) {$\ldots$};
\node at (8.5,10pt) {$\ldots$};
\node at (9.5,10pt) {$\ldots$};



\node[rectangle,draw,minimum width=1cm, minimum height=1cm] (A) at
(1,-2.7) {$A(t)$};
\node[below = of A,yshift=1cm] {1\%};
\node[right = of A, rectangle,draw,minimum width=8cm, minimum
height=1cm,xshift=-0.9cm] (B) {$B(t)$};
\node[below = of B,yshift=1cm] {99\%};

\node at (6.0,-23pt) (dt) {$\Delta(t)$};
\draw[thick,->] (dt) to (6.7,0);
\end{tikzpicture}
}
    
\caption{After Insert}
    \end{subfigure}
  \caption{Comparison of the situation before and after an Insert Operation}
\end{figure}

In the following algorithm we make use of an algorithm called \textsc{improve}, which was developed in \cite{jansen2013binpacking} to reduce the number of used bins. Using \textsc{improve}(x) on a packing $B$ with approximation guarantee $\max_i B(i) \leq (1+\bar{\epsilon})\OPT + C$ for some $\bar{\epsilon} = \mathcal{O}(\epsilon)$ and some additive term $C$ yields a new packing $B'$ with approximation guarantee $\max_i B(i) \leq (1+\bar{\epsilon})\OPT + C-x$. We use the operations in combination with the improve algorithm to obtain a fixed approximation guarantee. 




\begin{algo}[\ac{afptas} for large items] \label{alg-afptas}
  \ 
  \begin{small}
    

    \begin{algorithm}[H]
    \TitleOfAlgo{Insertion}
    \If{SIZE($I(t)) < (m+2)(\nicefrac{1}{\delta} +2)$ or 
	SIZE$(I(t)) < 8 (\nicefrac{1}{\delta} +1)$}{use offline Bin Packing}
    \Else{
    \textsc{improve}(2);
    insert($i$)\;
    \tcp{Shifting to the correct interval}
    Let $J_i$ be the interval containing $\Delta(t)$\;
    Let $J_j$ be the interval containing $\frac{A(t)}{A(t)+B(t)}$\;
    Set $d=i-j$\;
    \If(\tcp*[h]{Modulo $A(t)+B(t)$ when $k$ increases}){$k(t) > k(t-1)$}{
        $d$ = $d$ + $(A(t)+B(t))$\;
    }
    \tcp{Shifting $d$ groups from $B$ to $A$}
    \For{$p :=0$ to $|d|-1$}{
        \If{i+p = A(t) + B(t)}{Rename($A,B$);}
        \textsc{improve}(1);
        shiftA\;
    }
    }
\end{algorithm}
  \end{small}
  \begin{small}
    

\begin{algorithm}[H]
    \TitleOfAlgo{Deletion}
    \If{SIZE($I(t)) < (m+2)(\nicefrac{1}{\delta} +2)$ or 
	SIZE$(I(t)) < 8 (\nicefrac{1}{\delta} +1)$}{use offline Bin Packing}
    \Else{
    \tcp{Departing item $i$}
    \textsc{improve}(4);
    delete($i$)\;
    \textsc{ReduceComponents}\;
    \tcp{}
    \tcp{Shifting to the correct interval}
    Let $J_i$ be the interval containing $\Delta(t)$\;
    Let $J_j$ be the interval containing $\frac{A(t)}{A(t)+B(t)}$\;
    Set $d=i-j$\;
    \If(\tcp*[h]{Modulo $A(t)+B(t)$ when $k$ decreases}){$k(t) < k(t-1)$}{
        d = d - (A(t)+B(t))\;
    }
    \tcp{Shifting $d$ groups from A to B}
    \For{$p :=0$ to $|d|-1$}{
        \If{i-p = 0}{Rename(A,B);}
        \textsc{improve}(3);
        shiftB\;
    }
    }\end{algorithm}
  \end{small}    
\end{algo}
Note that as exactly $d$ groups are shifted from $A$ to $B$ (or $B$ to $A$) we have by definition that $\Delta(t) \in  \left[ \frac{A(t)}{A(t)+B(t)}, \frac{A(t)+1}{A(t)+B(t)}\right)$ at the end of the algorithm. Note that $d$ can be bounded by $11$.

\begin{lemma}
\label{lem:disbounded}
At most $11$ groups are shifted from $A$ to $B$ (or $B$ to $A$) in Algorithm \ref{alg-afptas}.
\end{lemma}

\begin{proof}
Since the value $|\SIZE(I(t-1))-\SIZE(I(t))|$ changes at most by $1$ we can bound $|\kappa(t-1) - \kappa(t)|$ by $\frac{\epsilon}{2(\lfloor \log(1/\epsilon)\rfloor +5)}\leq \frac{\epsilon}{\log(\nicefrac{1}{\epsilon})+5}$ to obtain the change in the fractional part. By  Lemma \ref{lem1} the number of intervals (=the number of groups) is bounded by $(\frac{8}{\epsilon}+2)(\log (\nicefrac{1}{\epsilon})+5)$. Using $\Delta(t-1) \in [ \frac{A(t-1)}{A(t-1)+B(t-1)}, \frac{A(t-1)+1}{A(t-1)+B(t-1)})$ and the fact that the number of groups $A(t-1)+B(t-1)$ increases or decreases at most by $1$, we can give a bound for the parameter $d$ in both cases by
\begin{align*}
&d \leq \frac{D}{\text{interval length}} +1 = D \cdot \#intervals +1 \leq \\
&\left((\frac{\epsilon}{\log (\nicefrac{1}{\epsilon})+5})\cdot (\frac{8}{\epsilon}+2)\cdot (\log(\nicefrac{1}{\epsilon})+5)\right)+1=\\
&8+2\epsilon +1 < 11
\end{align*}
Hence, the number of shiftA/shiftB operations is bounded by $11$.
\end{proof}


\begin{lemma}
\label{lem:binpackingalg}
    Every rounding function $R_t$ produced by Algorithm \ref{alg-afptas} fulfills properties $\nameref{prop:a}$ to $\nameref{prop:d}$ with parameter $k(t)= \left\lfloor \frac{\SIZE(I_{L})\cdot \epsilon}{2(\lfloor \log(1/\epsilon)\rfloor +5)}\right\rfloor$.
\end{lemma}

\begin{proof}
Since Algorithm \ref{alg-afptas} uses only the operations insert, delete, shiftA and shiftB, the properties $\nameref{prop:a}$to$\nameref{prop:d}$ are always fulfilled by Lemma $\ref{lem4}$ and the \ac{lp}/\ac{ilp} solutions $x,y$ correspond to the rounding function by Lemma $\ref{lem5}$. 

Furthermore, the algorithm is designed such that whenever $k$ increases the $B$-block is empty and the $A$-block is renamed to be the new $B$-block. Whenever $k$ decreases the $A$-block is empty and the $B$-block is renamed to be the new $A$-block. Therefore the number of items in the groups is dynamically adapted to match with the parameter $k$.
\end{proof}


\subsection{Large items}
In this section we prove that Algorithm \ref{alg-afptas} is a dynamic robust \ac{afptas} for the \BP problem if all items have size at least $\nicefrac{\epsilon}{14}$. The treatment of small items is described in Section \ref{sec:small} and the general case is described in Section \ref{sec:general}. 

We will prove that the migration between packings $B_t$ and $B_{t+1}$ is bounded by $\mathcal{O}(\nicefrac{1}{\epsilon^3}\log(\nicefrac{1}{\epsilon}))$ and that we can guarantee an asymptotic approximation ratio such that $\max B_{t}(i) \leq (1+2\Delta) \OPT(I(t),s) + \text{poly}(\nicefrac{1}{\Delta})$ for a parameter $\Delta = \mathcal{O}(\epsilon)$ and for every $t \in \mathbb{N}$.
The Algorithm \textsc{improve} was developed in \cite{jansen2013binpacking} to improve the objective value of an \ac{lp} with integral solution $y$ and corresponding fractional solution $x$. For a vector $z \in \mathbb{R}^n$ let $V(z)$ be the set of all integral vectors $v = (v_1, \ldots v_n)^T$ such that $0 \leq  v_i \leq  z_i$.

Let $x$ be an approximate solution of the \ac{lp} $\min \mengest{\nor{x}_1}{Ax \geq b, x \geq 0 }$ with $m$ inequalities and let $\nor{x}_1 \leq (1+ \delta) \LIN$ and $\nor{x}_1 \geq 2 \alpha (1/ \delta +1)$, where $\LIN$ denotes the fractional optimum of the \ac{lp} and $\alpha\in \mathbb{N}$ is part of the input of the algorithm (see Jansen and Klein \cite{jansen2013binpacking}). 
Let $y$ be an approximate integer solution of the \ac{lp} with $\nor{y}_1 \leq \LIN +2C$ for some value 
$C \geq \delta \LIN$ and with $\nor{y}_1 \geq (m+2)(1/\delta +2)$. 
Suppose that both $x$ and $y$ have only $\leq C$ non-zero components. For every component $i$ we suppose that $y_i \geq x_i$. Furthermore we are given indices $a_1, \ldots ,a_K$, such that the non-zero components $y_{a_j}$ are sorted in non-decreasing order, i.\,e., $y_{a_1} \leq \ldots \leq y_{a_K}$.
\begin{algo}[\textsc{improve}]\label{improve}
\ 
  \begin{enumerate}
   \item Set $x^{var} := 2 \frac{ \alpha(1 / \delta +1)}{\nor{x}}x$, $x^{fix} := x - x^{var}$ and 
   $b^{var} = b - A(x^{fix})$
    \item Compute an approximate solution $\hat{x}$ of the \ac{lp} $\min \mengest{\nor{x}_1}{Ax \geq b^{var}, x\geq 0 }$
	with ratio $(1+ \delta/2)$
	\item If $\nor{x^{fix} + \hat{x}}_1 \geq \nor{x}_1$ then set $x' = x$, 
	$\hat{y} = y$ and goto step 9
  \item Choose the largest $\ell$ such that the sum of the smallest components $y_1, \ldots , y_{\ell}$ is bounded by
  $\sum_{1\leq i \leq \ell} y_{a_i} \leq (m+2)(1/ \delta +2)$
	\item For all $i $ set $\bar{x}^{fix}_{i} = 
	\begin{cases} 0 & \text{if }i= a_j, j \leq \ell \\
	x^{fix}_i & \text{else}
	\end{cases}$ 
	and $\bar{y}_i = \begin{cases} 0 & \text{if }i= a_j, j \leq \ell \\
	y_i & \text{else}
	\end{cases}$
	\item Set $\bar{x} = \hat{x} + x_{\ell}$ where $x_{\ell}$ is a
          vector consisting of the components 
	$x_{a_1}, \ldots ,x_{a_{\ell}}$. Reduce the number of non-zero components to at most $m+1$.
  \item $x' = \bar{x}^{fix} + \bar{x}$
  \item For all non-zero components $i$ set $\hat{y}_i = \max \{\lceil x'_i \rceil , \bar{y}_i \}$
	\item If possible choose $d \in V(\hat{y}-x')$ such that $\nor{d}_1 = \alpha (1/ \delta +1)$ otherwise
  choose $d \in V(\hat{y}-x')$ such that $\nor{d}_1 < \alpha (1/ \delta +1)$ is maximal.
  \item Return $y' = \hat{y} -d$
  \end{enumerate}
\end{algo}


In the following we prove that the algorithm \textsc{improve} applied to the \BP \ac{ilp} actually generates a new improved packing $B'$ from the packing $B$ with corresponding \ac{lp} and \ac{ilp} solutions $x'$ and $y'$. We therefore use Theorem \ref{thm-improve} and Corollary \ref{cor-improve} that were proven in \cite{jansen2013binpacking}.

\begin{theorem}\label{thm-improve}
    Let $x$ be a solution of the \ac{lp} with $\nor{x}_1 \leq (1+\delta)
    \LIN$ and furthermore $\nor{x}_1 \geq 
	2 \alpha (1/ \delta +1)$. Let $y$ be an integral
	 solution of the \ac{lp} with  $\nor{y'}_1 \leq \LIN +2C$ for some value $C \geq \delta \LIN$
	 and with $\nor{y}_1 \geq (m+2)(1/\delta +2)$.
	 Solutions $x$ and $y$ have the same number of non-zero components and for each component we have 
	 $x_i \leq y_i$.
	The Algorithm $\textsc{improve}(\alpha)$ then returns a fractional solution $x'$ with $\nor{x'}_1 \leq (1+ \delta)\LIN -\alpha$ and an integral solution
	$y''$ where one of the two properties hold:
	 $\nor{y'}_1 = \nor{y}_1 - \alpha$ or $\nor{y'}_1 = \nor{x'}_1 + C$. 
	 Both, $x'$ and $y'$ have at most $C$
	non-zero components and the distance between $y'$ and $y$ is bounded by $\nor{y'-y}_1 
	= \mathcal{O}(\frac{m + \alpha}{\delta})$.
\end{theorem}
\begin{corollary}\label{cor-improve}
    Let $\nor{x}_1 = (1+ \delta')\LIN$ for some $\delta' \geq \delta$ and $\nor{x}_1 \geq 2 \alpha (1/ \delta +1)$
	and let $\nor{y}_1 \leq \LIN + 2C$ for some $C \geq \delta'\LIN$ and $\nor{y}_1 \geq (m+2)(1/\delta +2)$. 
	Solutions $x$ and $y$ have the same number of non-zero components and for each component we have 
	 $x_i \leq y_i$.
	 Then Algorithm $\textsc{improve}(\alpha)$ returns a fractional solution
	$x'$ with $\nor{x'}_1 \leq \nor{x}_1 - \alpha = (1+ \delta')\LIN - \alpha$ and integral solution $y'$ where one of the two properties hold:
	 $\nor{y'}_1 = \nor{y}_1 - \alpha$ or $\nor{y'}_1 = \nor{x}_1 - \alpha + C$. 
	Both, $x'$ and $y'$ have at most $C$
	non-zero components and the distance between $y'$ and $y$ is bounded by $\nor{y'-y}_1 
	\in \mathcal{O}(\frac{m + \alpha}{\delta})$.
\end{corollary}
Let $\Delta = \epsilon + \delta + \epsilon \delta$ and $C = \Delta \OPT(I,s) + m$.

\begin{theorem}\label{thm-packing}
    Given a rounding function $R$ and an \ac{lp} defined for $(I,s^{R})$, let $x$ be a fractional solution of the \ac{lp} with
	$\nor{x}_1 \leq (1+ \Delta) \OPT(I,s)$, $\nor{x}_1 \geq 2\alpha(1/\delta +1)$ and $\nor{x}_1 = (1+\delta')\LIN(I,s^{R})$ for some $\delta'>0$. Let $y$ be an integral solution of the \ac{lp} with $\nor{y}_1 \geq (m+2)(1/\delta +2)$ and corresponding packing $B$ such that $\max_i B (i) = \nor{y}_1 \leq (1+ 2\Delta) \OPT(I,s)+m$.
	Suppose $x$ and $y$ have the same number $\leq C$ of non-zero components and for all components $i$ we have
	$y_i \geq x_i$.	Then Algorithm $\textsc{improve}(\alpha)$ on $x$ and $y$ returns a new fractional solution $x'$ with $\nor{x'}_1 \leq (1+ \Delta) 
	\OPT(I,s) - \alpha$ and also a new integral solution $y'$ with corresponding packing $B'$ such that
	\begin{align*}
    \max_i B' (i) =\nor{y'}_1 \leq (1+ 2 \Delta) \OPT(I,s) +m- \alpha.
    \end{align*}
	Further, both solutions $x'$ and $y'$ have the same number $\leq C$ of non-zero components and for each component we have
	$x'_i \leq y'_i$. The number of changed bins from the packing
        $B$ to the packing $B'$ is bounded by $\mathcal{O}(\frac{m}{\delta})$.
    \end{theorem}
\begin{proof}
	

    To use Theorem \ref{thm-improve} and Corollary \ref{cor-improve} we have to prove that certain conditions follow from the requisites of Theorem \ref{thm-packing}.
    We have $\max_i B (i) = \nor{y}_1 \leq (1+ 2\Delta) \OPT(I,s)+m$ by condition. Since
	$ \OPT(I,s) \leq  \OPT(I,s^{R})$ we obtain for the integral solution $y$ that
	$\nor{y}_1 \leq 2\Delta \OPT(I,s)+m + \OPT(I,s^{R}) \leq  2 \Delta \OPT(I,s)+ m + \LIN(I,s^{R}) +m$.
	Hence by definition of $C$ we get $\nor{y}_1 \leq  \LIN(I,s^{R}) + 2C$. This is one requirement to use Theorem \ref{thm-improve}
	or Corollary \ref{cor-improve}.
	We distinguish the cases where  $\delta' \leq \delta$ and $\delta' > \delta$ and look at them separately.
	
	Case 1: $\delta' \leq \delta$.
    For the parameter $C$ we give a lower bound by the inequality $C > \Delta \OPT(I,s) = (\delta + \epsilon + \delta \epsilon)\OPT(I,s)$. Lemma \ref{lem2} shows that $\OPT(I,s^R) \leq (1+\epsilon)\OPT(I,s)$ and therefore yields  
    \begin{align*}
    &\frac{\delta + \epsilon + \delta \epsilon}{1+ \epsilon} \OPT(I,s^R)
    = \frac{(1+\delta)(1+\epsilon)-1}{1+\epsilon} \OPT(I,s^R)\\
    &= (1+\delta)\OPT(I,s^R) - \frac{1}{1+\epsilon}\OPT(I,s^R)\\
        &\geq \delta \OPT(I,s^R) \geq \delta LIN(I,s^R)
    \end{align*}
    and hence $C > \delta \LIN(I,s^R)$. We can therefore use Theorem \ref{thm-improve}.
    
	Algorithm \textsc{improve} returns by Theorem \ref{thm-improve} a $x'$ with $\nor{x'}_1 \leq (1+\delta)\LIN(I,s^{R})-\alpha \leq (1+\delta)\OPT(I,s^{R})-\alpha$ and an integral solution $y'$ with	$\nor{y'}_1 \leq \nor{x'}_1 + C$ or $\nor{y'}_1 \leq \nor{y}_1 - \alpha$. Using that $\OPT(I,s^R) \leq (1+\epsilon)\OPT(I,s)$ we can conclude $\nor{x'}_1 \leq (1+ \delta)(1+ \epsilon)\OPT(I,s) - \alpha = (1+\Delta)\OPT(I,s) - \alpha$. In the case where $\nor{y'}_1 \leq \nor{x'}_1 + C$ we can bound the number of bins of the new packing $B'$ by	$\max_i B' (i) = \nor{y'}_1 \leq \nor{x'}_1 + C \leq (1 + 2 \Delta) \OPT(I,s)+ m - \alpha$.
	In the case that $\nor{y'}_1 \leq \nor{y}_1 - \alpha$ we obtain $\max_i B' (i) = \nor{y'}_1 \leq \nor{y}_1 - \alpha \leq (1+ 2\Delta) \OPT(I,s) +m- \alpha$. Furthermore we know by Theorem \ref{thm-improve} that $x'$ and $y'$ have at most $C$ non-zero components.
	
	Case 2: $\delta' > \delta$.
    First we prove that $C$ is bounded from below. Since $\nor{x}_1 = (1+\delta') \LIN(I,s^R) \leq (1+ \Delta) \OPT(I,s)\leq (1+ \Delta) \OPT(I,s^R) \leq (1+ \Delta) \OPT(I,s^R) \leq (1+ \Delta) (\LIN(I,s^R) + \frac{m}{2}) \leq \LIN(I,s^R) +C$ we obtain that $C\geq \delta' \LIN(I,s^R)$, which is a requirement to use Corollary \ref{cor-improve}.
	By using Algorithm \textsc{improve} on solutions $x$ with $\nor{x}_1 = (1+\delta')\LIN(I,s^{R})$ and $y$ with $\nor{y}_1 \leq  \LIN(I,s^{R}) + 2C$ we obtain by Corollary \ref{cor-improve} a fractional solution $x'$ with
	$\nor{x'}_1 \leq \nor{x}_1 - \alpha \leq (1+\Delta)\OPT(I,s) - \alpha$ and an integral solution $y'$ with either $\nor{y'}_1 \leq \nor{y}_1 - \alpha$ or $\nor{y'}_1 \leq \nor{x}_1 + C - \alpha$.
	So for the new packing $B'$ we can guarantee that $\max_i B' (i) = \nor{y'}_1 \leq \nor{y}_1 - \alpha =  \max_i B (i) - \alpha	\leq (1+ 2\Delta) \OPT(I,s) +m - \alpha$ if $\nor{y'}_1 \leq \nor{y}_1 - \alpha$. In the case that $\nor{y'}_1 \leq \nor{x}_1 + C - \alpha$, we can guarantee that $\max_i B' (i) = \nor{y'}_1 \leq \nor{x}_1 + C - \alpha \leq (1+ \Delta) \OPT(I,s)+ C - \alpha \leq (1+ 2\Delta) \OPT(I,s) +m - \alpha$. Furthermore we know by Corollary \ref{thm-improve} that $x'$ and $y'$ have at most $C$ non-zero components.
    
Theorem \ref{thm-improve} as well as Corollary \ref{cor-improve} state that the distance $\nor{y'-y}_1$ is bounded by $\mathcal{O}(\nicefrac{m}{\delta})$. Since $y$ corresponds directly to the packing $B$ and the new integral solution $y'$ corresponds to the new packing $B'$, we know that only $\mathcal{O}(\nicefrac{m}{\delta})$ bins of $B$ need to be changed to obtain packing $B'$.
\end{proof}

In order to prove correctness of Algorithm \ref{alg-afptas}, we will make use of the auxiliary Algorithm \ref{reducecomponents} (\textsc{ReduceComponents}). Due to a delete-operation, the value of the optimal solution $\OPT(I,s)$ might decrease. Since the number of non-zero components has to be bounded by $C = \Delta \OPT(I,s) + m$, the number of non-zero components might have to be adjusted down. The following algorithm describes how a fractional solution $x'$ and an integral solution $y'$ with reduced number of non-zero components can be computed such that $\nor{y-y'}_1$ is bounded. The idea behind the algorithm is also used in the \textsc{Improve} algorithm. The smallest $m+2$ components are reduced to $m+1$ components using a standard technique presented for example in \cite{beling1998}. Arbitrary many components of $x'$ can thus be reduced to $m+1$ components without making the approximation guarantee worse.
\begin{algo}[\textsc{ReduceComponents}]\label{reducecomponents}
\ 
  \begin{enumerate}
  \item Choose the smallest non-zero components $y_{a_1}, \ldots , y_{a_{m+2}}$.
  \item If $\sum_{1\leq i \leq m+2} y_{a_i} \geq (1/ \Delta +2)(m+2)$ then return $x=x'$ and $y=y'$
  
  \item Reduce the components $x_{a_1}, \ldots , x_{a_{m+2}}$ to $m+1$ components $\hat{x}_{b_1}, \ldots , \hat{x}_{b_{m+1}}$ with $\sum_{j=1}^{m+2}x_{a_{j}}=\sum_{j=1}^{m+1}\hat{x}_{b_{j}}$.
  \item For all $i $ set $x'_i = 
	\begin{cases} \hat{x}_i +x_i & \text{if $i= b_j$ for some } j \leq m \\
	0 & \text{if $i= a_j$ for some } j \leq m+1 \\
	x_i & \text{else}
	\end{cases}$ 
	 
	
    and $\hat{y}_i = 	\begin{cases} \lceil \hat{x}_i + x'_i \rceil & \text{if $i= b_j$ for some } j \leq m \\
 	0 & \text{if $i= a_j$ for some } j \leq m+1 \\
	y_i & \text{else}
	\end{cases}$
  \item If possible choose $d \in V(\hat{y}-x')$ such that $\nor{d}_1 = m+1$ otherwise
  choose $d \in V(\hat{y}-x')$ such that $\nor{d}_1 < m+1$ is maximal.
  \item Return $y' = \hat{y} -d$
  \end{enumerate}
\end{algo}
The following theorem shows that the algorithm above yields a new fractional solution $x'$ and a new integral solution $y'$ with a reduced number of non-zero components.
\begin{theorem}
\label{thm:reduce}
    Let $x$ be a fractional solution of the \ac{lp} with	$\nor{x}_1 \leq (1+ \Delta) \OPT(I,s)$. Let $y$ be an integral solution of the \ac{lp} with $\nor{y}_1 \leq (1+ 2\Delta) \OPT(I,s)+m$. Suppose $x$ and $y$ have the same number $\leq C+1$ of non-zero components and for all components $i$ we have
	$y_i \geq x_i$.	Using the Algorithm $\textsc{ReduceComponents}$ on $x$ and $y$ returns a new fractional solution $x'$ with $\nor{x'}_1 \leq (1+ \Delta) \OPT(I,s)$ and a new integral solution $y'$ with $\nor{y'}_1 \leq (1+ 2 \Delta) \OPT(I,s) +m$. Further, both solutions $x'$ and $y'$ have the same number of non-zero components and for each component we have $x'_i \leq y'_i$. The number of non-zero components can now be bounded by $\leq C$. Furthermore, we have that $\nor{y-y'}_1 \leq 2\cdot (1/\Delta +3) (m+2)$.
\end{theorem}
\begin{proof}
    Case 1: $\sum_{1\leq i \leq m+2} y_{a_i} \geq (1/ \Delta +2)(m+2)$. We will show that in this case, $x$ and $y$ already have $\leq C$ non-zero components. In this case the algorithm returns $x' = x$ and $y' =y$. Since $\sum_{1\leq i \leq m+2} y_{a_i} \geq (1/ \Delta +2)(m+2)$ the components $y_{a_1}, \ldots , y_{a_{m+2}}$ have an average size of at least $(1/ \Delta +2)$ and since $y_{a_1}, \ldots , y_{a_{m+2}}$ are the smallest components, all components of $y$ have average size at least $(1/ \Delta +2)$. The size $\nor{y}_1$ is bounded by $(1+ 2\Delta) \OPT(I,s)+m$. Hence the number of non-zero components can be bounded by $\frac{(1+ 2\Delta) \OPT(I,s)+m}{\nicefrac{1}{\Delta}+2} \leq \Delta \OPT(I,s)+ \Delta m \leq C$.

Case 2: $\sum_{1\leq i \leq m+1} y_{a_i} < (1/ \Delta +2)(m+2)$. We have to prove different properties for the new fractional solution $x'$ and the new integral solution $y'$.

\textbf{Number of non-zero components}: The only change in the number of non-zero components is in step 3 of the algorithm, where the number of non-zero components is reduced by $1$. As $x,y$ have at most $C+1$ non-zero components, $x',y'$ have at most $C$ non-zero components. In step 4 of the algorithm, $\hat{y}$ is defined such that $\hat{y}_i \geq x'_i$. In step 5 of the algorithm $d$ is chosen such that $\hat{y}_i -d \geq x'_i$. Hence we obtain that $y'_i = \hat{y}_i -d \geq x'_i$.

\textbf{Distance between $y$ and $y'$}: The only steps where components of $y$ changes are in step 4 and 5. The distance between $y$ and $\hat{y}$ is bounded by the sum of the components that are set to $0$, i.\,e., $\sum_{j=1}^{m+2}y_{a_{j}}$ and the sum of the increase of the increased components $\sum_{j=1}^{m+1}\lceil \hat{x}_{b_{j}}\rceil \leq \sum_{j=1}^{m+1}\hat{x}_{b_{j}} +m+1 = \sum_{j=1}^{m+2}x_{a_{j}} +m+1$. As $\sum_{j=1}^{m+2}x_{a_{j}}\leq \sum_{j=1}^{m+2}y_{a_{j}} < (1/ \Delta +2)(m+2)$, we obtain that the distance between $y$ and $\hat{y}$ is bounded by $2\cdot (1/\Delta +2)(m+2)+m+1$. Using that $\nor{d}_1 \leq m+1$, the distance between $y$ and $y'$ is bounded by $\nor{y'-y}_1 < 2\cdot (1/\Delta +3) (m+2)$.

\textbf{Approximation guarantee}: The fractional solution $x$ is modified by condition of step 3 such that the sum of the components does not change. Hence $\nor{x'}_1=\nor{x}_1\leq (1+\Delta)\OPT(I,s)$.\\
Case 2a: $\nor{d}_1 < m+1$. Since $d$ is chosen maximally we have for every non-zero component that $y'_i-x'_i <1$. Since there are at most $C=\Delta\OPT(I,s)+m$ non-zero components we obtain that $\nor{y'}_1 \leq \nor{x'}_1 + C \leq (1+ 2\Delta)\OPT(I,s)+m$.
Case 2b: $\nor{d}_1 = m+1$.
By definition of $\hat{y}$ we have $\nor{\hat{y}}_1 \leq \nor{y}_1 + \sum_{j=1}^{m+1} \lceil \hat{x_{b_j}}+x_{b_j}\rceil  - \sum_{j=1}^{m+2}x_{a_j}  \leq \nor{y}_1 + m+1$. We obtain for $y'$ that $\nor{y'}_1 = \nor{\hat{y}}_1 - \nor{d}_1 \leq \nor{y}_1 + m+1 - (m+1) =\nor{y}_1 \leq (1+ 2\Delta) \OPT(I,s)+m$.
\end{proof}

\begin{theorem}
\label{thm-main}
Algorithm \ref{alg-afptas} is an \ac{afptas} with migration factor at most $\mathcal{O}(\frac{1}{\epsilon^3}\cdot \log(\nicefrac{1}{\epsilon}))$ for the fully dynamic \BP problem with respect to large items.
\end{theorem}

\begin{proof}
Set $\delta = \epsilon$. Then $\Delta = 2 \epsilon + \epsilon^2 = \mathcal{O}(\epsilon)$. We assume in the following that $\Delta \leq 1$ (which holds for $\epsilon\leq \sqrt{2}-1$).

We prove by induction that four properties hold for any packing $B_t$ and the corresponding \ac{lp} solutions. Let $x$ be a fractional solution of the \ac{lp} defined by the instance $(I_t,s^{R_{t}})$ and $y$ be an integral solution of this \ac{lp}.
    The properties $(2)$ to $(4)$ are necessary to apply Theorem \ref{thm-packing} and property $(1)$ provides the wished approximation ratio for the \BP problem.
	\begin{enumerate}
		\item[(1)\label{prop:1}] $\max_i B_t(i) = \nor{y}_1 \leq (1+ 2\Delta)\OPT(I(t),s) +m$ (the number of bins is bounded)
		\item[(2)\label{prop:2}] $\nor{x}_1  \leq (1+ \Delta) \OPT(I(t),s)$
		\item[(3)\label{prop:3}] for every configuration $i$ we have $x_i \leq y_i$
		\item[(4)\label{prop:4}] $x$ and $y$ have the same number of non-zero components and that number is bounded by $\Delta \OPT(I(t),s) +m$
	\end{enumerate}
	To apply Theorem \ref{thm-packing} we furthermore need a guaranteed minimal size for $\nor{x}_1$ and $\nor{y}_1$.
	According to Theorem \ref{thm-packing} the integral solution $y$ needs $\nor{y}_1 \geq (m+2)(\nicefrac{1}{\delta} +2)$ and 
	$\nor{x}_1 \geq 8 (\nicefrac{1}{\delta} +1)$ as we set $\alpha \leq 4$.
	By condition of the while-loop the call of \textsc{improve} is made iff $SIZE(I_t,s) \geq 8 (\nicefrac{1}{\delta} +1)$ and $SIZE(I_t,s) \geq (m+2)(\nicefrac{1}{\delta} +2)$. Since $\nor{y}_1 \geq \nor{x}_1 \geq SIZE(I_t,s)$ the requirements for the minimum size are fulfilled. As long as the instance is smaller than $8 (\nicefrac{1}{\delta} +1)$ or $(m+2)(\nicefrac{1}{\delta} +2)$ an offline algorithm for \BP is used. Note that there is an offline algorithm which fulfills properties $(1)$ to $(4)$ as shown by Jansen and Klein \cite{jansen2013binpacking}.
	
    Now let $B_t$ be a packing with $SIZE(I_t,s) \geq 8 (\nicefrac{1}{\delta} +1)$ and $SIZE(I_t,s) \geq (m+2)(\nicefrac{1}{\delta} +2)$ for instance $I_t$ with solutions $x$ and $y$ of the \ac{lp} defined by $(I(t),s^{R_t})$. Suppose by induction that the properties $(1)$ to $(4)$ hold for the instance $I_t$. We have to prove that these properties also hold for the instance $I(t+1)$ and the corresponding solutions $x''$ and $y''$. The packing $B_{t+1}$ is created by the repeated use of an
	call of \textsc{improve} for $x$ and $y$ followed by an operation (insert, delete, shiftA or shiftB).
    We will prove that the properties $(1)$ to $(4)$ hold after a call of \textsc{improve} followed by an operation.
	\\{\bf improve:} Let $x'$ be the resulting fractional solution of Theorem \ref{thm-packing}, let $y'$ be the resulting integral solution of Theorem \ref{thm-packing} and let $B'_t$ be the corresponding packing. Properties $(1)$ to $(4)$ are fulfilled 
	for $x$, $y$ and $B_t$ by induction hypothesis. Hence all conditions are fulfilled to use Theorem \ref{thm-packing}. 
	By Theorem \ref{thm-packing} the properties $(1)$ to $(4)$ are still fulfilled for $x'$, $y'$ and $B'_t$ and moreover we get
	$\nor{x'}_1 \leq (1+ \Delta) \OPT(I(t),s)- \alpha$ and $\nor{y'}_1 = \max_i B'_t (i) \leq (1+ 2 \Delta) \OPT(I(t),s) + m - \alpha$ for chosen parameter $\alpha$. Let $x''$ and $y''$ be the fractional and integral solution after an operation is applied to $x'$ and $y'$. We have to prove that the properties $(1)$ to $(4)$ are also fulfilled for $x''$ and $y''$.
	\\{\bf operations:} First we take a look at how the operations modify $\nor{x'}_1$ and $\nor{y'}_1 =\max_i B'_t (i)$. By construction of the insertion operation, $\nor{x'}_1$ and $\nor{y'}$ are increased at most by $2$. By construction of the delete operation, $\nor{x'}_1$ and $\nor{y'}_1$ are increased by $1$. By construction of the shiftA and shiftB operation, $\nor{x'}_1$ and $\nor{y'}_1$ are increased by $1$.
	An \textsc{improve}(2) call followed by an insertion operation therefore yields $\nor{y''} = \nor{y'}_1 +2 = (1+ 2\Delta)\OPT(I(t),s) +m -2 +2 = (1+ 2\Delta)\OPT(I(t+1),s) +m$ since $\OPT(I(t),s) \leq \OPT(I(t+1),s)$.
    An \textsc{improve}(4) call followed by a delete operation yields $\nor{y''} = \nor{y'}_1 + 1 = (1+ 2\Delta)\OPT(I(t),s) + m -3 \leq (1+ 2\Delta)\OPT(I(t+1),s) + (1+2\Delta) +m - 3 \leq (1+ 2\Delta)\OPT(I(t+1),s)$ since $\OPT(I(t),s) \leq \OPT(I(t+1),s) +1$ (an item is removed) and $\Delta \leq 1$. In the same way we obtain that $\nor{y''}_1 \leq \nor{y'}_1 +1 \leq (1+ 2\Delta)\OPT(I(t+1),s) +m$ for an \textsc{improve}(1)/\textsc{improve}(3) call followed by a shiftA/shiftB operation. This concludes the proof that property $(1)$ is fulfilled for $I(t+1)$.
	The proof that property $(2)$ holds is analog since $\nor{x'}_1$ increases in the same way as $\nor{y'}_1$ and $\nor{x'}_1   \leq (1+ \Delta) \OPT(I(t),s) - \alpha$.
	For property $(3)$ note that in the operations a configuration $x_i$ of the fractional solution is increased by $1$ if and only if a configuration $y_i$ is increased by $1$. Therefore the property that for all configurations $x''_i \leq y''_i$ retains from $x'$ and $y'$. By Theorem \ref{thm-packing} the number of non-zero components of $x'$ and $y'$ is bounded by $\Delta \OPT(I(t),s) +m \leq \Delta \OPT(I(t+1),s) +m$ in case of an insert operation. If an item is removed, the number of non-zero components of $x'$ and $y'$ is bounded by $\Delta \OPT(I(t),s) +m \leq \Delta \OPT(I(t+1),s) +m +1 = C+1$. By Theorem \ref{thm:reduce} the algorithm \textsc{ReduceComponents} guarantees that there are at most $C=\Delta \OPT(I(t+1),s) +m$ non-zero components. By construction of the shift-operation, $x''$ and $y''$ might have two additional non-zero components. But since these are being reduced by Algorithm \ref{alg-afptas} (note that we increased the number of components being reduced in step 6 by $2$ to- see \cite{jansen2013binpacking} for details), the \ac{lp} solutions $x''$ and $y''$ have at most $\Delta \OPT(I(t+1),s) +m$ non-zero components which proves property $(4)$. Algorithm \ref{alg-afptas} therefore has an asymptotic approximation ratio of $1+\epsilon$.
    
    We still need to examine the migration factor of Algorithm \ref{alg-afptas}. In the case that the offline algorithm is used, the size of the instance is smaller than $8 (\nicefrac{1}{\delta} +1) = \mathcal{O}(\nicefrac{1}{\epsilon})$ or smaller than $(m+2)(\nicefrac{1}{\delta} +2) = \mathcal{O}(\frac{1}{\epsilon^2} \log(\nicefrac{1}{\epsilon}))$. Hence the migration factor in that case is bounded by $\mathcal{O}(\frac{1}{\epsilon^3} \log(\nicefrac{1}{\epsilon}))$. If the instance is bigger the call of \textsc{improve} repacks at most $\mathcal{O}(\nicefrac{m}{\epsilon})$ bins by Theorem \ref{thm-packing}. Since every large arriving item has size $> \nicefrac{\epsilon}{14}$ and $m = \mathcal{O}(\frac{1}{\epsilon} \log (\nicefrac{1}{\epsilon}))$ we obtain a migration factor of $\mathcal{O}(\frac{1}{\epsilon^3} \log (\nicefrac{1}{\epsilon}))$ for the Algorithm \textsc{improve}. Since the migration factor of each operation is also bounded by $\mathcal{O}(\frac{1}{\epsilon^2} \log (\nicefrac{1}{\epsilon}))$, we obtain an overall migration factor of $\mathcal{O}(\frac{1}{\epsilon^3} \log (\nicefrac{1}{\epsilon}))$. 
    
    The main complexity of Algorithm \ref{alg-afptas} lies in the use of
    Algorithm \textsc{improve}. As described by Jansen and Klein
    \cite{jansen2013binpacking} the running time of \textsc{improve} is
    bounded by $\mathcal{O}(M(\nicefrac{1}{\epsilon}
    \log(\nicefrac{1}{\epsilon}))\cdot \nicefrac{1}{\epsilon^3}
    \log(\nicefrac{1}{\epsilon}))$, where $M(n)$ is the time needed to
    solve a system of $n$ linear equations. By using heap structures to
    store the items, each operation can be performed in time
    $\mathcal{O}(\nicefrac{1}{\epsilon}
    \log(\nicefrac{1}{\epsilon})\cdot \log(\epsilon^2\cdot n(t)))$ at
    time $t$, where $n(t)$ denotes the number of items in the instance
    at time $t$. As the number of non-zero components is bounded by
    $\mathcal{O}(\epsilon\cdot n(t))$, the total running time of the
    algorithm is bounded by $\mathcal{O}(M(\nicefrac{1}{\epsilon}
    \log(\nicefrac{1}{\epsilon}))\cdot \nicefrac{1}{\epsilon^3}
    \log(\nicefrac{1}{\epsilon})+\nicefrac{1}{\epsilon}
    \log(\nicefrac{1}{\epsilon}) \log(\epsilon^2\cdot n(t))+\epsilon
    n(t))$. The best known running time for the dynamic \BP problem
    \emph{without} removals was
    $\mathcal{O}(M(\nicefrac{1}{\epsilon^2})\cdot
    \nicefrac{1}{\epsilon^4}+\epsilon
    n(t)+\frac{1}{\epsilon^2}\log(\epsilon^2 n(t)))$ and is due to
    Jansen and Klein \cite{jansen2013binpacking}.  As this is polynomial
    in $n(t)$ and in $\nicefrac{1}{\epsilon}$ we can conclude that
    Algorithm \ref{alg-afptas} is an \ac{afptas}.
\end{proof}

If no deletions are present, we can use a simple FirstFit algorithm (as described by Jansen and Klein \cite{jansen2013binpacking}) to pack the small items into the bins. This does not change the migration factor or the running time of the algorithm and we obtain a robust \ac{afptas} with $\mathcal{O}(\frac{1}{\epsilon^3}\cdot \log(\nicefrac{1}{\epsilon}))$ migration for the case that no items is removed. This improves the best known migration factor of $\mathcal{O}(\frac{1}{\epsilon^4})$ \cite{jansen2013binpacking}.



















