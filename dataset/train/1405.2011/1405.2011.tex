\pdfpagewidth=8.5in
\pdfpageheight=11in

\pdfoutput=1

\documentclass[letterpaper,11pt]{article}

\usepackage{times}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
\usepackage{paralist}
\usepackage{xspace}
\usepackage[linesnumbered,algoruled,vlined]{algorithm2e}
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\SetKwComment{Comment}{// }{}
\SetCommentSty{textit}
\SetEndCharOfAlgoLine{}

\usepackage{color}
\usepackage{soul}
\newcommand{\boaz}[1]{\hl{\textbf{BPS}: #1}}


\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{condition}[theorem]{Condition}

\newcommand{\namedref}[2]{\hyperref[#2]{#1~\ref*{#2}}}
\newcommand{\sectionref}[1]{\namedref{Section}{#1}}
\newcommand{\appendixref}[1]{\namedref{Appendix}{#1}}
\newcommand{\subsectionref}[1]{\namedref{Subsection}{#1}}
\newcommand{\theoremref}[1]{\namedref{Theorem}{#1}}
\newcommand{\defref}[1]{\namedref{Definition}{#1}}
\newcommand{\figureref}[1]{\namedref{Figure}{#1}}
\newcommand{\figref}[1]{\namedref{Figure}{#1}}
\newcommand{\claimref}[1]{\namedref{Claim}{#1}}
\newcommand{\lemmaref}[1]{\namedref{Lemma}{#1}}
\newcommand{\tableref}[1]{\namedref{Table}{#1}}
\newcommand{\corollaryref}[1]{\namedref{Corollary}{#1}}
\newcommand{\propertyref}[1]{\namedref{Property}{#1}}
\newcommand{\appref}[1]{\namedref{Appendix}{#1}}
\newcommand{\propref}[1]{\namedref{Proposition}{#1}}
\newcommand{\algref}[1]{\namedref{Algorithm}{#1}}
\newcommand{\conditionref}[1]{\namedref{Condition}{#1}}
\newcommand{\lineref}[1]{\namedref{Line}{#1}}
\newcommand{\equalityref}[1]{\hyperref[#1]{Equality~\eqref{#1}}}
\newcommand{\inequalityref}[1]{\hyperref[#1]{Inequality~\eqref{#1}}}

\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\BO}{\mathcal{O}}
\newcommand{\sO}{\tilde{\mathcal{O}}}
\newcommand{\sOmega}{\tilde{\Omega}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\Comp}{\lambda}
\newcommand{\Set}[1]{\left\{#1\right\}}
\newcommand{\Congest}{\textsc{congest}\xspace}
\def\cI{\mathcal{I}}
\def\cA{\mathcal{A}}
\DeclareMathOperator{\In}{in}
\DeclareMathOperator{\act}{act}
\DeclareMathOperator{\moat}{rad}
\DeclareMathOperator{\Wd}{wd}
\DeclareMathOperator{\WD}{WD}
\DeclareMathOperator{\reg}{Reg}
\DeclareMathOperator{\vor}{Vor}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator{\Dist}{dist}
\DeclareMathOperator{\polylog}{polylog}
\DeclareMathOperator{\cP}{{\cal P}}
\DeclareMathOperator{\nA}{{na}}
\DeclareMathOperator{\sent}{sent}
\DeclareMathOperator{\unsent}{list}
\def\rW{\hat{W}}
\newcommand{\true}{\mathbf{true}}
\newcommand{\false}{\mathbf{false}}
\newcommand{\sfcr}{\textsc{dsf-cr}\xspace}
\newcommand{\sfic}{\textsc{dsf-ic}\xspace}

\renewcommand{\paragraph}[1]{\smallskip\par\noindent\textbf{#1}}

\usepackage[colorlinks,linkcolor=blue,filecolor=blue,citecolor=blue,urlcolor=blue]{hyperref}


\renewcommand*{\theHsection}{\thesection}

\begin{document}
\setcounter{tocdepth}{2}

\title{\textbf{Improved Distributed Steiner Forest Construction}
}

\author{
Christoph Lenzen\thanks{MIT CSAIL, The Stata Center, 32 Vassar Street,
Cambridge, MA 02139, USA.
\hbox{Email: {\tt clenzen@csail.mit.edu}.} Phone: +1 617-253-4632.
Supported by the Deutsche Forschungsgemeinschaft (DFG, reference
number Le 3107/1-1).}
\and 
Boaz Patt-Shamir\thanks{School of Electrical Engineering, Tel Aviv
  University, Tel Aviv 69978, Israel. Email:
  \texttt{boaz@eng.tau.ac.il}. Supported in part by Israel
  Ministry for Science and Technology.}
}

\date{}


\begin{titlepage}

\setcounter{page}{0}

\maketitle





\begin{abstract}
  We present new distributed algorithms for constructing a Steiner Forest in the
  \Congest model. Our deterministic algorithm finds, for any given constant
  , a -approximation in
   rounds, where  is the ``shortest path
  diameter,''  is the number of terminals, and  is the number of terminal
  components in the input. Our randomized algorithm finds, with high
  probability, an -approximation in time , where  is the unweighted diameter of the network. We prove a
  matching lower bound of on the running time of any distributed approximation
  algorithm for the Steiner Forest problem. The best previous algorithms were
  randomized and obtained either an -approximation in 
  time, or an -approximation in  time.
\end{abstract} 
\thispagestyle{empty}
\end{titlepage}

\section{Introduction}
Ever since the celebrated paper of Gallager, Humblet, and Spira \cite{GHS-83},
the task of constructing a minimum-weight spanning tree (MST) continues to be
a rich source of difficulties and ideas that drive network algorithmics (see,
e.g., \cite{Elkin-MST,GarayKP-98,LotkerPP,PelegR-00}).
The \emph{Steiner Forest} (SF) problem is a strict generalization of MST: We are
given a network with edge weights and some disjoint node subsets called
\emph{input components}; the task is to find a minimum-weight edge set which
makes each component connected. MST is a special case of SF, and so are the
Steiner Tree and shortest - path problems.
The general SF problem is well motivated by many practical situations involving
the design of networks, be it physical (it was famously posed as a problem of
railroad design), or virtual (e.g., VPNs or streaming multicast). The problem
has attracted much attention in the classical algorithms community, as detailed
on the dedicated website \cite{Steiner-site}.

The first network algorithm for
SF in the \Congest model (where a link can deliver  bits in a
time unit---details in \sectionref{sec:model}) was presented by
Khan \textit{et al.}\ \cite{KKMPT-12}. 
It provides -approximate solutions in time , where  is
the number of nodes,  is the number of components, and  the \emph{shortest
path diameter} of the network, which is
(roughly---see \sectionref{sec:model})  the maximal number of edges in a weighted shortest path. Subsequently, in \cite{LenzenP13}, it was shown that for any given
, an -approximate solution to SF can
be found in time , where  is the diameter
of the unweighted version of the network, and  is the number of
\emph{terminals}, i.e., the total number of nodes in all input components.  The
algorithms in \cite{KKMPT-12,LenzenP13} are both randomized.

\paragraph{Our Results.}
In this paper we improve the results for SF in the \Congest model in two ways.
First, we show that for any given constant , a
-approximate solution to SF can be computed by a deterministic
network algorithm in time .
Second, we show that an -approximation can be attained by a
randomized algorithm in time .
On the other hand, we show that any algorithm in the \Congest model that
computes a solution to SF with non-trivial approximation ratio has running time
in . If the input is not given by
indicating to each terminal its input component, but rather by
\emph{connection
requests} between terminals, i.e., informing each terminal which
terminals  it must be
connected to, an   lower bound
holds.  (It is easy to transform connection requests into equivalent
input components in  rounds.)


\paragraph{Related work.}
The Steiner Tree problem (the special case of SF where there is one
input component) has a remarkable history, starting with Fermat, who
posed the geometric 3-point on a plane problem circa 1643, including
Gauss (1836), and culminating with a popularization in 1941 by Courant
and Robbins in their book ``What is Mathematics'' \cite{CourantR-41}. An
interesting account of these early developments is given in
\cite{SteinerHistory}.
The contribution of Computer Science to the history of the problem apparently
started with the inclusion of Steiner Tree as one of the original 21 problems
proved NP-complete by Karp \cite{Karp-72}. There are quite a few variants of the
SF problem which are algorithmically interesting, such as Directed Steiner Tree,
Prize-Collecting Steiner Tree, Group Steiner Tree, and more. The site
\cite{Steiner-site} gives a continuously updated state of the
art results for many variants. Let us mention results for just the most common
variants: For the Steiner Tree problem, the best (polynomial-time) approximation
ratio known is  for any constant
 \cite{ByrkaGRS-10}. For Steiner Forest, the best approximation
ratio known is  \cite{AgrawalKR-95}. It is also known that the
approximation ratio of the Steiner Tree (or Forest) problem is  at least
, unless P=NP~\cite{ChlebikC-08}.

Regarding distributed algorithms, there are a few relevant results. First, the
special case of minimum-weight spanning tree (MST) is known to have time
complexity of  in the \Congest model
\cite{DHKNPPW-11,Elkin-MST,GarayKP-98,KuttenP-98,PelegR-00}. In \cite{CF05}, a
2-approximation for the special case of Steiner Tree is presented, with time
complexity . The first distributed solution to the Steiner Forest
problem was presented by Khan \textit{et al.}~\cite{KKMPT-12}, where a
randomized algorithm is used to embed the instance in a virtual tree with
 distortion, then finding the optimal solution on the tree (which
is just the minimal subforest connecting each input component), and finally
mapping the selected tree edges back to corresponding paths in the original
graph. The result is an -approximation in time .
Intuitively,  is the time required by the Bellman-Ford algorithm to compute
distributed single-source shortest paths, and the virtual tree of
\cite{KKMPT-12} is computed in  rounds.
A second distributed algorithm for Steiner Forest is presented in
\cite{LenzenP13}.
Here, a sparse spanner for the metric induced on the set of terminals and a
random sample of  nodes is computed, on which the
instance then is solved centrally. To get an
-approximation, the algorithm runs for  rounds. For approximation ratio ,
the running time is . 

\paragraph{Main Techniques.}
Our lower
bounds are
derived by the standard technique of reduction from results on -party
communication complexity.
Our deterministic algorithm is an adaptation of the ``moat growing'' algorithm
of Agrawal, Klein, and Ravi \cite{AgrawalKR-95} to the \Congest model. It
involves determining the times in which ``significant events'' occur (e.g., all
terminals in an input component becoming connected by the currently selected
edges)
and extensive usage of pipelining. The algorithm generalizes
the MST algorithm from~\cite{KuttenP-98}: for the special case of a Steiner Tree (i.e.,
), one can interpret the output as the edge set induced by an MST of the
complete graph on the terminals with edge weights given by the terminal-terminal
distances, yielding a factor- approximation; specializing further to the MST
problem, the result is an exact MST and the running time becomes
.



Our randomized algorithm is based on the embedding of the graph into a tree
metric from \cite{KKMPT-12}, but we improve the complexity of finding a Steiner
Forest. A key insight is that while the least-weight paths in the original
graph corresponding to virtual tree edges might intersect, no node participates
in more than  distinct paths. Since the union of
all least-weight paths ending at a specific node induces a tree, letting each
node serve routing requests corresponding to different destinations in a
round-robin fashion achieves a pipelining effect reducing the complexity to
.  If , the virtual tree and the corresponding
solution are constructed only partially, in time ,
and the partial result is used to create another instance with
 terminals that captures the remaining connectivity demands; we solve it using
the algorithm from~\cite{LenzenP13}, obtaining an -approximation.






\paragraph{Organization.}
In \sectionref{sec:model} we define the model, problem and basic
concepts.  \sectionref{sec-lb} contains our lower bounds.  
In \sectionref{sec-alg1} and \sectionref{sec-alg2} we  present our
deterministic and randomized algorithms, respectively. We only give a high-level overview in this extended abstract. Proofs
are deferred to the appendix.

\section{Model and Notation}
\label{sec:model}
\paragraph{System Model.}
We consider the  or simply the \Congest model as
specified in~\cite{Peleg:book}, briefly described as follows. The
distributed system is represented 
by a weighted graph  of  nodes. The weights  are polynomially bounded in  (and therefore polynomial sums of
weights can be encoded with  bits). Each node initially
knows its unique identifier of  bits, the identifiers of
its neighbors, the weight of its incident edges, and the local
problem-specific input specified below. Algorithms proceed in
synchronous rounds, where in each round, (i) nodes perform arbitrary,
finite local computations,\footnote{All our algorithms require polynomial computations only.} (ii) may
send, to each neighbor, a possibly distinct message of  bits, and
(iii) receive the messages sent by their neighbors. For randomized algorithms,
each node has access to an unlimited supply of unbiased, independent random
bits. Time complexity is measured by the number of rounds until all nodes
(explicitly) terminate. 


\paragraph{Notation.}
We use the following conventions and graph-theoretic notions.
\begin{compactitem}
\item The \emph{length} or number of \emph{hops} of a path  in  is .
\item The weight of such a path is
  . For notational
  convenience, we assume w.l.o.g.\ that different paths have different
  weight (ties broken lexicographically).
\item By  we denote the set of all paths between  in , i.e.,  and .
\item The (unweighted) \emph{diameter} of  is \hfill\\.
\item The (weighted) \emph{distance} of  and  in  is .
\item The \emph{weighted diameter} of  is .
\item Its \emph{shortest-path-diameter} is .
\item For  and , we use  to denote the
  ball of radius  around  in , which includes all nodes and
  edges at weighted distance at most  from . The ball may
  contain edge fractions: for an edge  for which  is in
  , the  fraction of the edge closer to 
  is considered to be within , and the remainder is considered
  outside .
\end{compactitem}
We use ``soft''  asymptotic notation.
Formally, given functions
 and , define (i)  iff there is some  so that , (ii)  iff
, 
and (iii)
 iff .
By ``w.h.p.,'' we abbreviate ``with probability '' for a
sufficiently large constant in the  term.

\paragraph{The Distributed Steiner Forest Problem.}
In the Steiner Forest problem, the output is a set of edges. We
require that the output edge set  is represented distributively,
i.e., each node 
can locally answer which of its adjacent 
edges are in the output.
The input may be represented by two alternative methods, both are
justified and are common in the
literature. We give the two definitions.
\begin{definition}
[Distributed Steiner Forest with Connection Requests (\sfcr)]\ 
\begin{compactitem}
\item[\textbf{Input:}] At each node , a set of \emph{connection
    requests} .
\item[\textbf{Output:}] An edge set  such that
  for each connection request ,  and  are connected by
.
\item[\textbf{Goal:}] Minimize .
\end{compactitem}
\end{definition}
\noindent


The set of \emph{terminal} nodes is defined to be , i.e., the
set of nodes  for which there is some connection request .

\begin{definition}[Distributed Steiner Forest with Input Components (\sfic)]\ 
\begin{compactitem}
\item[\textbf{Input:}] At each node , , where  is the set of \emph{component
    identifiers}. The set of \emph{terminals} is . An \emph{input component}  for
 is the set of terminals with label .
\item[\textbf{Output:}] An edge set  such that all terminals
  in each
  {input component}  are connected by .
\item[\textbf{Goal:}] Minimize .
\end{compactitem}
\end{definition}
An instance of \sfic is \emph{minimal}, if  for all
. We assume that the labels  are encoded
using  bits. We define  and , i.e., the number of terminals and input components, respectively. 

We say that any two instances of the above problems on the same
weighted graph, regardless of the way the input is given, are
\emph{equivalent} if the set of feasible outputs for the two instances
is identical.
\begin{lemma}\label{lemma:transform_to_input}
Any instance of \sfcr can be transformed into an
  equivalent instance of \sfic in  rounds.
\end{lemma}

\begin{lemma}\label{lemma:transform_to_minimal}
Any instance of \sfic can be transformed into
an equivalent minimal instance of \sfic in  rounds.
\end{lemma}

\section{Lower Bounds}
\label{sec-lb}


In this section we state our lower bounds (for proofs and more
discussion, see \appendixref{app-lb}.) 
As our first result,
we show that applying \lemmaref{lemma:transform_to_input} to
instances of \sfcr comes at no penalty in asymptotic running time (a lower bound
of  is trivial). 
\begin{lemma}
\label{lem-lb1}
  Any distributed algorithm for \sfcr with finite approximation ratio
  has time complexity . This is true even in graphs
  with diameter at most  and no more than two input components.
\end{lemma}

The main result of this section is the following theorem.
\begin{theorem}
\label{thm-lb}
  Any algorithm for the distributed Steiner Forest problem with non-trivial
  approximation ratio has worst-case time complexity in
   in expectation.
\end{theorem}
The proof of \theoremref{thm-lb} in fact consists of proving the following two
separate lower bounds.



\begin{lemma}\label{lem:lower_k}
  Any distributed algorithm for \sfic with finite approximation ratio
  has time complexity . This is true even for
  unweighted graphs of diameter 3.
\end{lemma}

\begin{lemma}\label{lem:lower_s}
  Any distributed algorithm for \sfic or \sfcr with finite approximation ratio
  has running time  for . This holds  even for instances with , ,
  and .
\end{lemma}

We remark that the proofs of Lemmas~\ref{lem-lb1} and  \ref{lem:lower_k},
are by reductions from Set Disjointness
\cite{KushilevitzN-book}.
In Lemmas~\ref{lem-lb1} and~\ref{lem:lower_k}, it is trivial to increase the
other parameters, i.e., , , , or , so we may apply
Lemmas~\ref{lemma:transform_to_input} and~\ref{lemma:transform_to_minimal} to
obtain a minimal instance of \sfic without affecting the asymptotic time
complexity.

\section{Deterministic Algorithm}
\label{sec-alg1}
In this section we describe our deterministic algorithm. We start by
reviewing the moat growing algorithm of \cite{AgrawalKR-95}, and then
adapt it to the \Congest model.

\paragraph{Basic Moat Growing Algorithm}
(pseudocode  
 in \algref{algo:centralized}). The algorithm proceeds by 
``moat growing'' and ``moat merging.'' 
A \emph{moat} of radius  around a terminal
 is a set that contains all
nodes and edges within distance  from , where edges may be
included fractionally: for example, if the only edge
incident with  has 
weight , then the moat of radius  around  contains  and the 
 of the edge closest to . 
\emph{Moat growing} is a process in which multiple moats
increase their radii at the same rate. 

The algorithm proceeds as follows. All terminals, in parallel, grow moats around
them until two moats intersect. When this happens, 
\begin{inparaenum}[(1)]
\item moat growth is temporarily suspended,
\item the edges of a shortest path connecting two terminals in the meeting moats
are output (discarding edges that close cycles), and
\item the meeting  moats are contracted into a single node. 
\end{inparaenum}
This is called a \emph{merge step} or simply \emph{merge}. Then moat growing
resumes, where the newly formed node is considered an active terminal if some
input component is contained partially (not wholly) in the contracted region,
and otherwise the new node is treated like a regular (non-terminal) node. If the
new node is an active terminal, it resumes the moat-growing with initial radius
. The algorithm terminates when no active terminals remain.

Formal details and analysis are provided
in \appendixref{app-basic}. The bottom line is as follows.

\begin{theorem}\label{theorem:2approx}
  \algref{algo:centralized} outputs a -approximate Steiner forest.
\end{theorem}



\paragraph{Rounded Moat Radii.}
To reduce the
number of times the moat growing is suspended due to moats meeting, 
we defer moat merging  to the next integer power of
, where  is a given
parameter. Pseudo-code is given in 
\algref{algo:central_approx} in the Appendix.
Obviously, the 
number of distinct radii in which merges may occur in this algorithm
is now
bounded by  by our assumption that all edge weights, and hence
the weighted diameter, are bounded by a polynomial in
. Furthermore, approximation deteriorates only a little, as the
following result  states (proof in
\appref{app-epsilon}). 

\begin{theorem}\label{theorem:2+eps_approx}
\algref{algo:central_approx} outputs a -approximate Steiner
forest.
\end{theorem}



\subsection{Distributed Moat-Growing Algorithm}
\label{ssec-dist}
Our goal in this section is to derive a distributed implementation of the
centralized \algref{algo:centralized}. To do this, it is sufficient to follow
the order in which moats merge in the sequential algorithm. The first main
challenge we tackle is to achieve pipelining for the merges that do not change
the activity status of terminals; since all active moats grow at the same rate,
we can compute the merge order simply by finding the distances between moats and
ordering them in increasing order. When the active status of some terminal
changes, we recompute the distances.


We start by defining \emph{merge phases}. Intuitively, a merge phase is a
maximal subsequence of merges in which no active terminal turns inactive and no
inactive terminal is merged with an active one.

\begin{definition}\label{def:merge}
Consider a run of \algref{algo:centralized}, and let 
   be the values of  in which  for some , where . Steps
   are called \emph{merge phase }, and we denote
  , i.e., node 's activity status
  throughout merge phase . We use  to denote the \emph{phase of merge
  }.
\end{definition}
\begin{lemma}\label{lem-numphases}
  The number of merge phases is at most . 
\end{lemma}
Next, we define \emph{reduced weights}, formalizing moat contraction.
We use the following notation.

\smallskip\noindent\textbf{Notation.} For a terminal  and merge step , 
.

\begin{definition}Given merge phase  of \algref{algo:centralized}, define the
  \emph{reduced weight} of an edge  by , where fractionally contained edges lose
  weight accordingly.
\end{definition}
Note that  is determined by the state of the moats just
before phase  starts. We now define the Voronoi decomposition for phase .
\begin{definition}
  Let  be a graph with non-negative edge weights, and let
   be a set of nodes called \emph{centers},
  with positive distances
  between any two centers. The \emph{Voronoi decomposition} of  w.r.t.\ 
  is a partition of the nodes and edges into  subsets called \emph{Voronoi
  regions}, where region  contains all nodes and all edge parts
  whose closest center is  (ties broken lexicographically).
\end{definition}

In each phase , we consider the Voronoi decomposition using reduced
weights  and active terminals
as centers. Let  denote
the Voronoi region of a node  under this decomposition.
Since we need to consider inactive moats too,  the concept we actually
use is the following. 
\begin{definition}
  The \emph{region} of a
  terminal  in phase , denoted , is defined as
  follows. 
  , and for ,

The  terminal decomposition is given by a collection of
shortest-path-trees spanning, for each , . We require that
the tree of  extends the tree of .
\end{definition}

In other words,  is obtained from  by growing all
active moats at the same rate, but only into uncovered parts of the graph; this growth
stops at the end of a merge phase. Given the  terminal
decomposition, it 
is straightforward to compute  and the required spanning trees
using the Bellman-Ford algorithm, as the following lemma states.


\begin{lemma}\label{lemma:partition}
  Suppose that each node 
knows the
  following about the  terminal decomposition:
  \begin{compactitem}
  \item the node  for which ;
  \item ;
  \item the parent in the shortest-path-tree spanning   (unless
   is the root);
  \item .
  \end{compactitem}
  Then, in  rounds we can compute shortest-path-trees rooted
  at nodes , that extend the given trees and span
 for active  (trees of inactive terminals
remain unchanged). By the end of the computation, each node
knows: \begin{compactitem}
  \item the node  in whose tree  participates;
  \item the parent in the shortest-path-tree rooted at  (unless 
    is the root);
  \item for each edge incident to , the fraction of it contained in
  the tree rooted at ;
  \item .
  \end{compactitem}
\end{lemma}
Note that \lemmaref{lemma:partition} says that we can ``almost'' compute
the  terminal
decomposition (the  remain unknown).
What justifies the trouble of computing decompositions is the
following key observation.


\begin{lemma}\label{lemma:path_in_region}
  For , let  and  be the 
  terminals whose moats are joined in the  merge of
  \algref{algo:centralized}. Let  be a shortest path connecting
  them. Then .
\end{lemma}
\lemmaref{lemma:path_in_region} implies that each merging path is ``witnessed''
by the nodes of the respective edge crossing the boundary between the regions.
By the construction from \lemmaref{lemma:partition}, these nodes will be
able to correctly determine the reduced weight of the path. This
motivates the following 
definition.

\begin{definition}\label{def-induced}
  For each , fix a shortest-paths tree on .
  Suppose that  is an edge so that  and
   for some terminals . Then 
  \emph{induces} the unique path  that is the concatenation of the
  shortest path from  to  given by the terminal decomposition with 
  and the path from  to  given by the terminal decomposition.
\end{definition}

Since the witnessing nodes cannot determine locally whether ``their''
path is the next merging path, they need to
encapsulate and communicate the salient information about the witnessed path.

\begin{definition}\label{def-cands}
Suppose that  is an edge satisfying  and
   with , , , 
   and . Then  is said to induce a
  \emph{candidate merge}  in phase  with \emph{associated path} .
\end{definition}
 specifies the
increment of the moat radius of the (active) terminal  before the
respective balls intersect.
To order candidate merges we need the following additional concept.


\begin{definition}\label{def-cand-graph}
The \emph{candidate multigraph} is defined as
, where for each candidate merge
 there is an edge
.
\end{definition}

We can now  relate the paths selected by
\algref{algo:centralized} to the candidate merges.

\begin{lemma}\label{lemma:equivalent}
Consider the sequence of candidate merges ordered in
ascending lexicographical order: 
first by phase index, then by reduced weight, and finally break ties by
identifiers.  Discard
each merge that closes a 
cycle (including parallel edges) in . Let  be
the resulting forest in . Then union of the paths corresponding
to    is exactly the set 
computed by \algref{algo:centralized} (with the same tie-breaking rules).
\end{lemma}

\lemmaref{lemma:equivalent} implies that, similarly to Kruskal's
algorithm, it suffices to scan the candidate
merges in ascending order and filter out cycle-closing edges.
Using the technique introduced for MST \cite{GarayKP-98,KuttenP-98},
the filtering 
procedure can be done concurrently with collecting the merges, achieving full
pipelining effect. For later development,
we show a general
statement that allows for multiple merge phases to be handled concurrently and
out-of-order execution of a subset of the merges.
\begin{lemma}\label{lemma:filtering}
  Denote by  the subset of candidate merges in phase 
  and set . For a set , assume that each node  is
  given a set  of candidate merges such that 
. Finally, assume
  that for each , each candidate merge in  is tagged
  by the connectivity components of its terminals in the subgraph
   of . Then  can be made known to all nodes in  rounds.
\end{lemma}

When emulating \algref{algo:centralized} distributively, we may
overrun the end of the phase if the causing event occurs
remotely. This may lead to spurious merges, which should be
invalidated later.

\begin{definition}
A \emph{false candidate} is a tuple  with ,
, , and  that is not a candidate
merge. Candidate merges' order is extended to false candidates in the
natural way.
\end{definition}

Fortunately, false candidates originating from the  Voronoi
decomposition given by \lemmaref{lemma:partition} will always have larger
weights than candidate merges in phase , since they are 
induced by edges outside  (see \lemmaref{lemma:decomp}). This
motivates the following corollary.

\begin{corollary}\label{coro:filtering}
Let  denote the set of candidate merges in phase  and set
. Suppose
 is globally known, as well
, for all . If each node  
is given a set  of candidate merges and false candidates so that
 and each false candidate has larger
weight than all candidate merges in , then  can be made
globally known in  rounds.
\end{corollary}

We can now describe the algorithm (see pseudocode in
\appref{app-distalg}). The algorithm
proceeds in merge phases. In each phase, it constructs the
 terminal decomposition except for knowing the  values
(\lemmaref{lemma:partition}). Using this decomposition, nodes propose
candidate merges, of which some are false candidates. The filtering
procedure from \corollaryref{coro:filtering} is applied to determine
. The weight of the last merge
is the increase in moat radii during phase , setting
 and thus  for each , which allows us
to proceed to the next phase. Finally, the algorithm computes
the minimal subforest of the computed forest,  as in 
\algref{algo:centralized}. We summarize the analysis with the
following statement.


\begin{theorem}\label{theorem:2_distributed}
\sfic can be solved deterministically with approximation factor  in
 rounds.
\end{theorem}

\subsection{Achieving a Running Time that is Sublinear in
\texorpdfstring{}{t}}
\label{sec:sublinear}

The additive  term in \theoremref{theorem:2_distributed} can be
avoided. We do this by generalizing a technique first used for MST 
construction~\cite{GarayKP-98,KuttenP-98}. 
Roughly, the idea is to allow moats to grow locally until
they are ``large,'' and then use centralized filtering. A new
threshold that distinguishes ``large'' from ``small'' in this case is .




\begin{definition}Define . A moat is called \emph{small} if when
formed, its connected component using edges that were selected to the output up
to that point contains fewer than  nodes. A moat which is not small
is called \emph{large}.
\end{definition}



To reduce the time complexity, we implement
\algref{algo:central_approx}, where moats change
their ``active'' status only between \emph{growth phases}. In each growth phase,
the maximal moat radius grows by a factor of . The key insight here is that all we need is to determine at which
moat size the first inactive moat gets merged, because all active terminals
keep growing their moats throughout the
entire growth phase. 

We first slightly
adapt the definition of merge phases.

\begin{definition}For an execution of \algref{algo:central_approx}, denote by ,
, the merges for which either the if-statement in
\lineref{line:growth_phase} is executed or one of the moats participating in the
merge is inactive. Then the merges  constitute the
\emph{ merge phase}. For , denote by  the
index so that  is the  merge for which the if-statement in
\lineref{line:growth_phase} is executed. Then the merges
 constitute the \emph{ growth phase} and
we define that . For convenience,  and
.
\end{definition}

For constant , the number of growth phases is in
 (see \lemmaref{lemma:number_merge_growth_phase}).


\paragraph{Algorithm overview.}
The algorithm is specified in \appref{app:sublinear-code}, except for the final
pruning step, which is discussed
below. The main loop runs over growth phases:
first, regions and terminal decompositions are computed. Then, each
small moat proposes its least-weight candidate merge. 
To avoid long chains of merges, we run a matching algorithm with
small moats as nodes and proposed merges as edges, and then add the
candidate merges proposed by the unmatched small moats. 
After a
logarithmic number of iterations of this procedure, at most 
moats remain that may participate in further merges in the growth
phase; the filtering procedure from \lemmaref{lemma:filtering} then
selects the remaining merges in  rounds. Finally, the
activity status for the next growth phase is computed;
small moats are handled by communicating over the edges connecting
them, and large moats rely on pipelining communication over a BFS
tree.






\paragraph{Analysis overview.}
The analysis is given in \appref{app:sublinear-analysis}. We only review the
main points here.  First, \lemmaref{lemma:large_moats} shows that
small moats have strong diameter at most , and that the number
of large moats is bounded by .
We show, in \lemmaref{lemma:growth_3b}, that the set  the
algorithm selected by the end of growth phase  is identical to that selected
by an execution of \algref{algo:central_approx} on the same instance of \sfic.
To this end, \lemmaref{lemma:decomp_correct} first shows
that the terminal decompositions are computed correctly in 
  rounds.
Finally, we prove in \lemmaref{lemma:growth_phase} that the growth
 phase is completed in  rounds and, if it was not
 the last phase, it provides the necessary information to perform the
 next one.  We summarize the results of this subsection as follows.

\begin{corollary}\label{coro:growth}
For any instance of \sfic, a distributed algorithm can compute a solving forest
 in  rounds that satisfies that its minimal subforest solving
the instance is optimal up to factor .
\end{corollary}

\paragraph{Fast Pruning Algorithm.}
\label{sec:prune}
After computing , it remains to select the minimal
subforest solving the given instance of problem \sfic: we may have
included merges with non-active moats that need to be pruned.
Simply collecting  and  at a single node takes
 rounds, and the depth of (the largest tree in)  can be
 in the worst case. Thus, we employ some of the strategies for
computing  again. First, we grow clusters to size  locally, just like
we did for moats, and then solve a derived instance on the clusters to decide
which of the inter-cluster edges to select. Subsequently, the subtrees inside
clusters have sufficiently small depth to resolve the remaining demands by a
simple pipelining approach. Details are provided in \appref{app:prune}. We
summarize as follows.
\begin{corollary}\label{coro:2+eps_distributed}
For any constant , a deterministic distributed algorithm can
compute a solution for problem \sfic that is optimal up to factor
 in  rounds,
where  is the number of input components with at least two terminals.
\end{corollary}
\
\section{Randomized Algorithm}
\label{sec-alg2}
In \cite{KKMPT-12}, Khan \textit{et al.}\ propose a randomized
algorithm for \sfic that constructs an 
expected -approximate solution in  time
w.h.p.
In this section we
show how to modify it so as to reduce the running time to
 while keeping the approximation ratio
in .

\paragraph{Overview of the algorithm in \cite{KKMPT-12}.}
The algorithm consists of two main steps. First, a
virtual tree is constructed and embedded in the network, where each
physical node is a virtual leaf.  Then the algorithm selects, for each
input component , the minimal subtree containing all terminals
labeled , and adds, for each virtual edge in these
subtrees, the physical edges of the corresponding path in . Since
the selected set of virtual
edges corresponds to an optimal solution in the tree topology, and
since it can be shown that the expected stretch factor of the embedding is in
, the result follows.

In more detail, the virtual tree is constructed as follows.  Nodes
pick IDs independently at random.  Each node of the graph is a leaf in
the tree, with ancestors , where  the base-2 logarithm of
the weighted diameter (rounded up). The  ancestor  is the
node with the largest ID within distance  from , for a
global parameter  picked uniformly at random from . The
weight of the virtual edge  is defined to be
.  We note that the embedding in  is via a shortest path
from each node  to each of its  ancestors (and not from
 to ), implemented by ``next hop'' pointers along the
paths.  It is shown that w.h.p., at most  such distinct
paths pass through any physical node.

Now, consider the second phase. Let , for an input component ,  denote the minimal
subtree that contains all terminals of  as leaves.
Clearly,  is the optimal solution
to \sfic on the virtual tree. Thus, all that needs to be done is to select
for each virtual edge in this solution a path in  (of weight smaller or
equal to the virtual tree edge) so that the nodes in  corresponding to the
edge's endpoints get connected. However, since the embedding of the
tree may have paths of  hops, and since there are  labels
to worry about,  the straightforward
implementation from~\cite{KKMPT-12} requires  rounds to
select the output edges due to possible
congestion.


\paragraph{Overview of our algorithm.}
Our first idea is to improve  the second phase from~\cite{KKMPT-12} as
follows.  Each internal node  is the root of a shortest paths
tree of weighted diameter .
For  any virtual tree edge
, we
make sure that exactly one node  in the virtual subtree rooted at 
includes the edges of a shortest physical path 
(in ) connecting  and  in the edge set  output of the
algorithm. 
This is done by  by sending  a message  to  up
the shortest paths tree rooted at , and these messages are
filtered along the way so that only the first 
 message is forwarded for each .
This ensures that the only  steps are needed per
destination. 
Since there are  such destinations for each node, by
time-multiplexing 
we get running time of  (w.h.p.). 

When ,\footnote{W.l.o.g., we present the algorithm as if  was known, because it
  can be determined in  rounds as follows:
  Compute  by convergecast, then run Bellman-Ford until
  stabilization or until  iterations have elapsed, whichever
  happens first. Since stabilization can be detected  time
  after it occurs, we are done.
} 
the running time can be improved further to . The idea is as
follows. Let  be the set of the  nodes of highest rank.
We truncate each leaf-root path in the virtual tree at the first occurrence of a
node from : instead of connecting to that ancestor, the node 
connects to the \emph{closest} node from . This construction can be
performed in time  w.h.p.\ (see \appendixref{sec:partial}).
Consider now the edge set  returned by the procedure above: for each input
component , the terminals labeled  will be partitioned
into connected components, each containing a node from  (if there is a
single connected component it is possible that it does not include any node from
). We view each such connected component as a ``super-terminal'' and
solve the problem by applying an algorithm from \cite{LenzenP13}. The output is
obtained by the set  from the first virtual tree and the additional edges
selected by this algorithm. We show that the overall approximation ratio remains
 and that the total running time is
.

\paragraph{Detailed description.}
We present the construction for  and  in a unified
way. Detailed proofs for the claimed properties are given in
\appendixref{sec:tree_selection}. The first stage consists of the following
steps.
\begin{compactenum}
  \item If , set . Otherwise, let  be the set of  nodes of highest rank. Delete from the virtual
  tree internal nodes mapped to nodes of . Compute the remaining part of
  the virtual tree and, if , let each node learn about
  its closest node from . In other words, each node 
   learns the identity of and the shortest paths to
  , where  is
  the node closets to  from . If ,  and
  .
  \item For each terminal , set . For all other
  terminals, .
  \item For  phases:
  \begin{compactenum}
    \item Make for each  known to all nodes whether it
    satisfies that there is only one terminal  with .
    If this is the case, delete  from .
    \item Each node  sets
     if  and
     otherwise. Then
    all nodes set , , and
    .
    \item Repeat until no more messages are sent:
    \begin{compactitem}
      \item For each node , do the following. Each node  for which
       picks some  and sets . If
      , it sends  to the next node on the least-weight path
      to  known from the tree construction, otherwise it sets
      .
      Each traversed edge is added to .
      \item Each node  that receives a message  sets
      .
    \end{compactitem}
    \item Each node  with  selects a node  that
    added, for some ,  to its  variable in Step~3b.
    It sends all entries in its  variable to . The node  and
    the routing path to  are determined by backtracing a sequence of messages
     from Step 3c. The receiving node  sets .
  \end{compactenum}
  \item Return .
\end{compactenum}
\emph{The Second Stage.}
If ,  is the solution.
Otherwise, we construct a new instance and solve it.
To define the new instance,
define, for each , the node set

 ties  broken lexicographically. Let . 
The new instance is defined over the following graph.

\begin{definition}The
  \emph{-reduced graph}   is
  defined as
  follows. 
  \begin{compactitem}
  \item 
  \item 
  \item 
  \end{compactitem}
\end{definition}

To complete the description of the new instance, we specify the new terminals
and labels.
Given an instance of \sfic and the edge set  computed in the first
stage, the \emph{-reduced instance} is defined over the 
-reduced graph  as follows. The set of terminals is 
. To
construct the labels, define the helper graph ,
where 
  
Now, let
 be the set of connected components of
, identified by   bits
each. Finally, the
label  of a node  in  is the identifier of the
connected component in  of any label 
which belongs to any node in  ( is well defined,
because all these labels belong to the same connected component of
). 

Since the reduced instance imposes fewer constraints, its optimum is at most
that of the original instance. We show that the reduced instance can be
constructed efficiently, within  rounds, and then apply the
algorithm from~\cite{LenzenP13} to solve it with approximation factor . For this approximation guarantee, the algorithm has time complexity
; since we made sure that the reduced instance has
 terminals only, this becomes .
The union of the returned edge set with  then yields a solution of the
original instance that is optimal up to factor . Detailed proofs of
these properties and the following main theorem can be found in
\appendixref{sec:spanner}.
\begin{theorem}\label{theorem:fast}
There is an algorithm that solves \sfic in 
rounds within factor  of the optimum w.h.p.
\end{theorem}

\newpage



{\small
\begin{thebibliography}{10}

\bibitem{AgrawalKR-95}
A.~Agrawal, P.~Klein, and R.~Ravi.
\newblock {When trees collide: An approximation algorithm for the generalized
  Steiner tree problem on networks}.
\newblock {\em SIAM J. Computing}, 24:440--456, 1995.

\bibitem{SteinerHistory}
M.~Brazil, R.~Graham, D.~Thomas, and M.~Zachariasen.
\newblock {On the history of the {Euclidean} {Steiner} tree problem}.
\newblock {\em Archive for History of Exact Sciences}, pages 1--28, 2013.

\bibitem{ByrkaGRS-10}
J.~Byrka, F.~Grandoni, T.~Rothvo\ss, and L.~Sanit\`a.
\newblock {An improved {LP}-based Approximation for Steiner Tree}.
\newblock In {\em Proc.\ 42nd ACM Symp.\ on Theory of Computing}, pages
  583--592, 2010.

\bibitem{CF05}
P.~Chalermsook and J.~Fakcharoenphol.
\newblock {Simple Distributed Algorithms for Approximating Minimum Steiner
  Trees}.
\newblock In {\em Proc.\ 11th Conf.\ on Computing and Combinatorics}, pages
  380--389, 2005.

\bibitem{ChlebikC-08}
M.~Chleb\'{\i}k and J.~Chleb\'{\i}kov\'a.
\newblock {The {Steiner} tree problem on graphs: Inapproximability results}.
\newblock {\em Theoretical Computer Science}, 406(3):207--214, 2008.

\bibitem{CV-86}
R.~Cole and U.~Vishkin.
\newblock {Deterministic Coin Tossing and Accelerating Cascades: Micro and
  Macro Techniques for Designing Parallel Algorithms}.
\newblock In {\em Proc. 18th ACM Symp. on Theory of Computing}, pages 206--219,
  1986.

\bibitem{CourantR-41}
R.~Courant and H.~Robbins.
\newblock {\em {What is Mathematics? An Elementary Approach to Ideas and
  Methods}}.
\newblock London. Oxford University Press, 1941.

\bibitem{DHKNPPW-11}
A.~{Das Sarma}, S.~Holzer, L.~Kor, A.~Korman, D.~Nanongkai, G.~Pandurangan,
  D.~Peleg, and R.~Wattenhofer.
\newblock {Distributed Verification and Hardness of Distributed Approximation}.
\newblock In {\em Proc.\ 43th ACM Symp.\ on Theory of Computing}, pages
  363--372, 2011.

\bibitem{Elkin-MST}
M.~Elkin.
\newblock {An Unconditional Lower Bound on the Time-Approximation Tradeoff for
  the Minimum Spanning Tree Problem}.
\newblock {\em SIAM J. Computing}, 36(2):463--501, 2006.

\bibitem{GHS-83}
R.~G. Gallager, P.~A. Humblet, and P.~M. Spira.
\newblock {A Distributed Algorithm for Minimum-Weight Spanning Trees}.
\newblock {\em ACM Trans. on Comp. Syst.}, 5(1):66--77, 1983.

\bibitem{GarayKP-98}
J.~Garay, S.~Kutten, and D.~Peleg.
\newblock {A sub-linear time distributed algorithm for minimum-weight spanning
  trees}.
\newblock {\em SIAM J. Computing}, 27:302--316, 1998.

\bibitem{Steiner-site}
M.~Hauptmann and M.~Karpinski.
\newblock {A Compendium on {Steiner} Tree Problems}.
\newblock
  \url{http://theory.cs.uni-bonn.de/info5/steinerkompendium/netcompendium.html}.
\newblock Retreived January 2014.

\bibitem{Karp-72}
R.~M. Karp.
\newblock Reducibility among combinatorial problems.
\newblock In {\em {Complexity of Computer Computations}}, pages 85--103.
  Plenum, New York, 1972.

\bibitem{KKMPT-12}
M.~Khan, F.~Kuhn, D.~Malkhi, G.~Pandurangan, and K.~Talwar.
\newblock {Efficient Distributed Approximation Algorithms via Probabilistic
  Tree Embeddings}.
\newblock {\em Distributed Computing}, 25:189--205, 2012.

\bibitem{KushilevitzN-book}
E.~Kushilevitz and N.~Nisan.
\newblock {\em {Communication Complexity}}.
\newblock Cambridge University Press, 1997.

\bibitem{KuttenP-98}
S.~Kutten and D.~Peleg.
\newblock {Fast Distributed Construction of Small {\it k}-Dominating Sets and
  Applications}.
\newblock {\em J. Algorithms}, 28(1):40--66, 1998.

\bibitem{LenzenP13}
C.~Lenzen and B.~{Patt-Shamir}.
\newblock {Fast Routing Table Construction Using Small Messages: Extended
  Abstract}.
\newblock In {\em Proc.\ 45th Ann.\ ACM Symp.\ on Theory of Computing}, pages
  381--390, 2013.

\bibitem{LotkerPP}
Z.~Lotker, B.~{Patt-Shamir}, and D.~Peleg.
\newblock Distributed {MST} for constant diameter graphs.
\newblock {\em Distributed Computing}, 18(6):453--460, 2006.

\bibitem{Peleg:book}
D.~Peleg.
\newblock {\em {Distributed Computing: A Locality-Sensitive Approach}}.
\newblock SIAM, Philadelphia, PA, 2000.

\bibitem{PelegR-00}
D.~Peleg and V.~Rubinovich.
\newblock {Near-tight Lower Bound on the Time Complexity of Distributed MST
  Construction}.
\newblock {\em SIAM J. Computing}, 30:1427--1442, 2000.

\end{thebibliography}

}

\section*{APPENDIX}
\appendix
\section{Preliminaries}
\begin{proof}[Proof of \lemmaref{lemma:transform_to_input}]
  We construct an (unweighted) breadth-first-search (BFS) tree rooted at
an arbitrary node, say the one with the largest identifier. Clearly,
this results in a tree of depth  this can be done in 
rounds. For the first transformation, each node sends all connection
requests it initially knows or receives from its children and that do
not close cycles in  to the root. Since any forest on  has at
most  edges, this takes at most  rounds using messages
of size . Subsequently, the remaining set of requests at
the root is broadcasted over the BFS tree to all nodes, also in time
. By transitivity of connectivity, a set  is feasible in
the original instance iff it is feasible w.r.t.\ the remaining set of
connectivity requests. Since these are now global knowledge, the nodes
can locally compute the induced connectivity components (on the set of
terminals) and and unique labels for them: say, the smallest ID in the
component. Setting the label of
terminal  to the label of its connectivity component, the resulting
instance with input components is equivalent as well. 
\end{proof}
\begin{proof}[Proof of \lemmaref{lemma:transform_to_minimal}]
As for the previous lemma, we construct a BFS tree rooted at some
node. Each terminal sends the message  to its parent in the
BFS tree. For each label , if a node ever learns about two
different messages , , it sends  to
its parent and ignores all future messages with label . All other
messages are forwarded to the parent. Since for each label , no
node sends more than  messages, this step completes in 
rounds. Afterwards, for each  with , the root
has either received a message , or it has received two messages
, , or it has received one message  and is
in input component  itself. On the other hand, if
, clearly none of these cases applies. Therfore, the
root can determine the subset of labels  and broadcast it over the BFS tree,
taking another  rounds. The minimal instance is then
obtained by all terminals in singleton input components deleting their
label. 
\end{proof}

\section{Lower Bounds}
\label{app-lb}
\begin{proof}[Proof of \lemmaref{lem-lb1}]
Let  be a distributed algorithm for \sfcr with approximation
ratio . 
We reduce Set Disjointness (SD) to -approximate \sfcr as follows.
Let  be an instance of SD. Alice, who knows ,
constructs the following graph: the nodes are the set
 and two additional nodes denoted  and
. 
All nodes corresponding to elements in  are connected to  and
all nodes corresponding to  are connected to
. Formally, define .
Similarly, Bob  constructs nodes  and edges 
.
In addition to the edges  and , the graph contains the edges
. 
All edges, except  have unit cost,
and the edges  have cost
.
This concludes the description of the graph (see \figureref{fig-lb} left). 
Finally, we define the
connection requests 
as follows: for each  we introduce the connection request
, and similarly for each  we introduce the
request . Note that we have  and .

\begin{figure}[t]
  \centering
  \includegraphics[height=2.2in]{lb}\hspace*{15mm}
  \includegraphics[height=2.2in]{lb2}
  \caption{\small Reductions of Set Disjointness to Distributed Steiner
    Forest. Left: reduction to \sfcr (solid edges are light, dashed
    edges are heavy). Right: reduction to \sfic (all edges have unit weight).} 
  \label{fig-lb}
\end{figure}
This completes the description of the \sfcr instance. We now claim
that if  computes a -approxima\-tion to \sfcr, then we can output
the answer ``YES'' to
the original SD instance iff  produces an output that does not
include neither of the heavy edges
. To see this, consider the optimal
solutions. If , then all connection requests can be
satisfied using edges from . Hence the optimal cost is at most
, which means that any -approximate solution cannot include
a heavy edge; and if , then any solution must
include at least one of the
heavy edges, and hence its weight is larger than .

It follows that if  is a -approximate solution to \sfcr,
then the following algorithm solves SD: Alice and Bob construct the
graph based on their local input without any communication. Then Alice
simulates  on the  nodes  and Bob simulates  on
the  nodes. The only communication required between Alice
and Bob to run the simulation is the messages that cross the edges in
. Now,  solving SD requires exchanging  bits
in the worst case (see,
e.g., \cite{KushilevitzN-book}). In the  model,
at most  bits can cross  in a round, and hence it must
be the case that the running time of  is in
.
\end{proof}

\noindent\textbf{Remarks.}
\\  In the lower bound,   is a parameter describing the universe
  size  of the input
  to SD. Let  denote the number of nodes in the  corresponding
  instance of \sfcr. Note that we can set  to any number larger
  than  just by adding 
  isolated nodes. Similarly we can extend the diameter to any number
  larger than  so long as it's smaller than  by attaching
  a chain of  nodes to . Finally, we can also extend
   to any number larger than  by adding pairs of nodes
  , each pair connected  by an edge, and have
  .
\\  Since  is a trivial
lower bound, we may apply
\lemmaref{lemma:transform_to_input} to convert any \sfcr instance with
 into an \sfic instance without losing worst-case performance
w.r.t.\ the 
set of the considered parameters. (If we are
guaranteed that , the transformation is trivial, as all terminals
are to be connected.) 
\\  We note that in the hard instances of SD, 
  and .
\\  The hardness result applies to \sfcr algorithms that do not require
  symmetric requests. More specifically, if the \sfcr algorithm works only
  for inputs satisfying  , then the reduction from
  SD fails.
\\  The special case of MST ( and ) can be solved
in time  \cite{KuttenP-98}. 


\begin{proof}[Proof of \lemmaref{lem:lower_k}]
As in \lemmaref{lem-lb1}, we reduce Set Disjointness (SD) to \sfic.
Specifically, 
the reduction is as follows.
Let  be the input sets
to Alice and Bob, respectively, where .
Alice constructs a star whose leaves are the nodes
, all connected to a center node  (see
\figureref{fig-lb} right).  
 For each node  Alice sets  if  and
 otherwise. Similarly Bob
constructs another star whose leaves are , all
connected to the center node , 
and sets  if  and 
otherwise. In addition the instance to \sfic contains the edge
. All edges have unit weight.
Note that using \sfic terminology, we have that the number of input
components satisfies .


We now claim that given any -approximation algorithm  for \sfic,
the following algorithm solves SD: Alice and Bob construct the graph
(without any communication), and then they simulate 
, where Alice simulates all the  nodes and Bob simulates
all the  nodes. The answer to SD is YES iff the
edge  is not in the output of .
To show the algorithm correct, consider two cases.
If the SD instance is  a NO instance, then there exists some , which implies, by construction, that  and  must be
connected by the output edges, and, in particular, the edge   must 
be in the output of  (otherwise  did not produce a
valid output); and if the SD
instance was   a 
NO instance, then the optimal solution to the constructed \sfic instance
contains no edges, i.e., its weight is , and therefore no
finite-approximation 
algorithm may include any edge, and in particular the edge , in its output. This
establishes the correctness of the reduction. 

Finally, we note that 
the simulation of  requires communicating only the messages
that are sent over the edge . Since, as mentioned above, any
algorithm for SD 
requires communicating  bits between Alice and Bob, we conclude that if 
guarantees finite approximation ratio, the number of bits  it must
communicate over  is in , and
since in the 
 model only  bits can be communicated over
a single edge in each round,
it must be the case that the running time of  is in
.
\end{proof}


\begin{proof}[Proof of \lemmaref{lem:lower_s}]
Follows from the observation that the shortest - path is a
special case of the Steiner Forest problem where  and  are the
only two terminals, belonging to the same component. Therefore the
lower bound of 
\cite{DHKNPPW-11} on distributed algorithms solving the shortest -
path problem applies.
\end{proof}


\section{Basic Moat Growing Algorithm}
\label{app-basic}
\begin{algorithm}[H]\small
\caption{Centralized Moat-Growing.}\label{algo:centralized}
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\Input{\hfill // input
components}
\Output{feasible forest \hfill // -approximation}
 \hfill// moats partition ; for
, let  s.t.\ \\
\For{each }{
  \hfill // by how much moats grew while 's moat was active\\
   \hfill // input components are merged when
  moats merge\\
   \hfill // satisfied components' moats become inactive
}
 \hfill // set of selected edges\\
\\
\While{}{
  \\
  \\
  \\
  \\
  \\
   \hfill // minimal moat growth so
  that two moats touch\\
  \For{each  with }{
    \hfill // grow moats
  }
  Denote by  a pair of terminals giving rise to
  \nllabel{line:select_v_i_w_i}\\
  Let  be the edge set of a least-weight path from  to 
  (drop edges in cycles with )\\
  \hfill // connect  and \\
  \}\hfill // merge moats\\
  \For{each }{
    \If{}{
      
    }
    \ElseIf{}{
      \hfill // merge input components (if
      different)
    }
    \Else{
      
    }
  }
  \If{}{
     \hfill// new moat's
    component connected by 
  }
  \Else{
    
  }
  \For{}{
    
  }
}
\Return{minimal feasible subset of }\hfill // may have selected useless
paths
\end{algorithm}

\begin{definition}[Merges]
Each iteration of the while-loop of \algref{algo:centralized} is
called  a
\emph{merge step}, or simply a \emph{merge}.  The total number of
merges is denoted . The number of active moats
during the  merge  is denoted , i.e., .
\end{definition}



\begin{lemma}\label{lemma:components}
For , the set  computed by
\algref{algo:centralized} is an inclusion-minimal forest such that each  is the cut of  with a component of .
\end{lemma}
\begin{proof} We show the claim by induction on . We have that 
and , i.e., the claim holds for . Now assume that it holds
for  and consider index . The choice of
 guarantees that the joint moat
 is subset of the same connectivity
component of . To see that no terminal from  is connected to this component by
, observe that a least-weight path from  to  contains
no terminal from  (otherwise
it is not of least weight or  would not have been minimal). By the
induction hypothesis, this implies that 
is a maximal subset of  that is in the same component .

It remains to show that  is an inclusion-minimal forest with this
property. Since  closes no cycles, it follows from the
induction hypothesis that  is a forest. From this and the
inclusion-minimality of  it follows that deleting any edge from  will
disconnect a pair of terminals in the same moat. Similarly, removing an edge
from  will disconnect the new moat .
\end{proof}

\begin{lemma}\label{lemma:feasible}
The output  of \algref{algo:centralized} is a feasible forest.
\end{lemma}
\begin{proof}
By \lemmaref{lemma:components} and the fact that the algorithm terminates once
all moats are inactive, it is sufficient to show that an inactive moat contains
only complete input components.

Note that if the algorithm changes component identifiers, it does so by changing
them for all moats  with  into some
. Hence all terminals  which initially shared
the same value  are always in moats with identical component
identifiers. Since initially for each  there are at least two
distinct terminals  with , for each 
initially there are at least two moats  with . A
merge between moats  assigns component identifier  to
all moats with identifier  or . The merged moat (which
is a connectivity component of ) becomes inactive if and only if it is
the only remaining moat with label . The statement of the lemma
follows.
\end{proof}


\begin{lemma}\label{lemma:cost} 
For any feasible output , \algref{algo:centralized} satisfies that

\end{lemma}
\begin{proof}
We show the statement by induction on . The statement is trivial for
 (i.e., no input components), so suppose it holds for
 and consider . We split up the weight function
 into  so that  and define a modified
instance to which we can apply the induction hypothesis, proving that .

For each , define  to be  within  and  outside (boundary edges have the appropriate fraction of
their weight) and . Consider the edge set  of a connectivity
component  induced by . We claim that if it contains  nodes, it must hold that . To see this, note that the
choice of  guarantees that the  are disjoint for all
. Moreover, by definition, any path connecting  to a node
outside  must contain edges of weight at least  within
. The claim follows. Summing over all connectivity components
 induced by  (which satisfy  since by the problem
definition each terminal must be connected to at least one other terminal), we
infer that .

Recall that . We take the following steps:
\begin{compactitem}
  \item The algorithm replaces the moats  and  by the
  joint moat . For the purpose of our induction, we simply
  interpret this as setting  if the resulting moat is
  active.
  \item If the merge connected the only two terminals  and  sharing
  the same component identifier, the respective moat becomes inactive. In this
  case, we also remove  from , i.e., .
  \item The algorithm assigns to all moats  with
   the component identifier , i.e.,
  . Analogously, we set 
  for all  and
   for .
  \item Note that the previous steps guarantee that for each terminal ,
  there is a terminal  so that .
  \item The new instance of the problem is now given by the graph
  , the terminal set , and the terminal component function
  .
\end{compactitem}
Consider an execution of \algref{algo:centralized} on the new instance. We make
the following observations:
\begin{compactitem}
  \item For each  and any radius , it holds that
  . 
  \item Since  (as their distance in  is ),
  deleting  from the set of terminals has the same effect as joining them
  into one moat.
  \item Hence, if the merged moat  remains active and thus  is
  part of the set of terminals of the new instance, we get a one-to-one
  correspondence between merges of the two instances, i.e., it holds that
   and  for all  (where  indicates values for the new instance).
  \item By the induction hypothesis, this implies that
  
  \item If  became inactive, but never participates in a merge, the
  same arguments apply.
\end{compactitem}
Hence, suppose that  participates in a merge in step
. For all indices , the above correspondence holds. Moreover,
since  is inactive, (i) the moat  with which it is
merged must satisfy that  and (ii) we have that
, i.e., the resulting moat is active (as
 for any  would
contradict the fact that  is inactive). Thus, the merge does not
affect the number of active moats, i.e., .
Furthermore, it holds that , since
 has been active only during merge . We conclude that, for any
,

as the moats of size  around  and  at the end of the 
merge exactly compensate for the fact that the edges inside the respective
weighted balls in  have no weight in . By induction on , it follows that, for any ,

and we can map the following merges of the two runs onto each other, i.e.,
 and, for ,  as well as
. In particular,

and the induction hypothesis yields that

Hence, in both cases , and the proof is complete.
\end{proof}

\begin{proof}[Proof of \theoremref{theorem:2approx}]
By \lemmaref{lemma:feasible}, the output  of the algorithm is a feasible
forest. With each merge, the algorithm adds the edges of a path of cost
 to . Hence


We construct  and  from  by contracting edges in
 for all . If edges are ``partially
contracted'' since they are only fractionally part of
 for some , their weight simply is
reduced accordingly; note that since  is a forest, no edges are ``merged'',
i.e., the resulting weights are well-defined. By \lemmaref{lemma:components},
this process identifies for each moat  its terminals. Note that
the edges from  are completely contained in these balls. We interpret
the set of active moats  (which after
contraction are singletons) as the set of terminals in . Since  is
minimal w.r.t.\ satisfying all constraints, so is  (where in  two
terminals need to be connected if the corresponding moats contain terminals
that need to be connected). As only active moats contain terminals with
unsatisfied constraints (cf.~\lemmaref{lemma:feasible}),  is the union of at
most  shortest paths between terminal pairs from  that
contain no other terminals.

Now consider the balls  around nodes . By the choice
of , they are disjoint. For each such ball , by
definition any least-weight path has edges of weight at most  within the
ball. We claim that any path in  that connects nodes , but
contains no third node , does not pass through
 for any . Otherwise, consider the subpath from 
to a node in  for some  and
concatenate a shortest path from its endpoint to . The result is a path
from  to  that smaller weight than the original path from  to .
Symmetrically, there is a path shorter than the one from  to  connecting
 and . However, together with the fact that the algorithm connects moats
incrementally using least-weight paths of ascending weight implies that the
pairs  and  must end up in the same moat \emph{before} the
path connecting  and  is added. By transitivity of connectivity this
necessitates that  and  are in the same moat when a path connecting them
is added, a contradiction. We conclude that indeed each of the considered paths
passes through the balls around its endpoints only.

Overall, we obtain that in the above double summation, for each index , there
are at most  summands of :  for each of the at
most  paths connecting nodes in  considered in the previous
paragraph (note that the contraction did not change weights of edges covered by
these summands). We conclude that

By \lemmaref{lemma:cost}, this is at most twice the cost of any feasible
solution. In particular, the cost of  is smaller than twice that of an
optimal solution.
\end{proof}

\section{Rounded Moat Radii}
\label{app-epsilon}


\begin{algorithm}[p!]\small
\caption{Centralized Approximate Moat-Growing with
approximation ratio .}\label{algo:central_approx}
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\Input{\hfill // input
components}
\Output{feasible forest \hfill // -approximation}
 \hfill// moats partition ; for
, let  s.t.\ \\
\For{each }{
  \hfill // by how much moats grew while 's moat was active\\
   \hfill // input components are merged when
  moats merge\\
   \hfill // satisfied components' moats become inactive
}
 \hfill // set of selected edges\\
\\
\\
\While{}{
  \\
  \\
  \\
  \\
  \\
   \hfill // minimal moat growth so
  that two moats touch\\
  \If{\nllabel{line:growth_phase}}{
     \hfill // stop moat growth at
    \\
    \hfill // no merge, just checking whether moats are active\\
    \\
    \For{each }{
      \\
      \If{}{
         \hfill// moat's terminals satisfied
      }
      \Else{
        
      }
    }
    \hfill // threshold for next check
  }
  \Else{
    Denote by  a pair of terminals giving rise to \\
    Let  be the edges of a least-weight path from  to 
    (drop edges in cycles with )\nllabel{line:select_path}\\
    \hfill // connect  and \\
    \}\hfill // merge moats\\
    \\
    \\
    \For{each }{
      \If{}{
        \hfill // merge input components (if
        different)
      }
      \Else{
        
      }
      
    }
  }
  \For{each  with }{
    \hfill // grow moats
  }
}
\Return{minimal feasible subset of }\hfill // may have selected useless
paths
\end{algorithm}
\clearpage

\begin{corollary}\label{coro:cost_approx}
For any solution , \algref{algo:central_approx} satisfies that

where  is the final iteration of the while-loop of the algorithm.
\end{corollary}
\begin{proof}
Denote by  the number of unsatisfied moats in the  iteration of the
while-loop of \algref{algo:central_approx}, i.e., the moats which can terminals
that need to be connected to terminals in different moats. Analogously to
\lemmaref{lemma:cost}, we have that

Now consider a satisfied moat  that is formed in iteration 
out of two unsatisfied moats; we call such a moat bad. Denote by 
the first iteration in which a moat  is unsatisfied or
inactive, whichever happens earlier. Since the minimal edge weight is  and
 is increased by factor  whenever the algorithm
checks whether to inactivate moats, it holds that . As an unsatisfied moat
can only be created by merging an unsatisfied moat (with a satisfied or
unsatisfied moat), there is a sequence of unsatisfied moats  such that .

We observe that if we pick a different moat  and merge  as above and
apply the same construction, the resulting sequence
 must be disjoint from the sequence
, since for each , the set of moats  forms a partition of  and
the sequences contain no unsatisfied moats. We conclude that

\end{proof}

\begin{proof}[Proof of \theoremref{theorem:2+eps_approx}]
Analogous to \theoremref{theorem:2approx}, except that the final bound on the
approximation ratio follows from \corollaryref{coro:cost_approx}.
\end{proof}

\section{\texorpdfstring{Proofs for \sectionref{ssec-dist}}{Proofs Concerning
the Distributed Moat Growing Algorithm}}
\label{app-dist}


\begin{proof}[Proof of \lemmaref{lem-numphases}]
  Clearly, the total number of times moats become inactive is at
  most , because every input component becomes completely contained in a moat
  exactly once throughout the execution. When  an inactive moat
  merges, either all its 
  terminals become active again or a new inactive moat is formed. Hence, the
  total number of merges for which the activity status of some terminals change
  is at most .
\end{proof}

\begin{proof}[Proof of \lemmaref{lemma:partition}]
To compute the Voronoi decomposition in phase , we use the single-source
Bellman-Ford algorithm, where active moats are sources.
All nodes in active moats are initialized with distance , and the edge
weights are given by the reduced weight function  (which is known
locally, because the moat size is locally known). Messages are tagged by the
identifier of the closest source w.r.t.\  (the ``old'' trees are not
touched, but simply extended). In  rounds, the Bellman-Ford algorithm
terminates, and the result is that the shortest paths trees are extended to
include all nodes in the respective Voronoi regions  that are not in
 for a terminal  with , and each node
knows its distance from the closest moat according to , i.e.,
. Finally, observe that nodes in 
for some  with  simply can use the information
from the previous phase .
\end{proof}

\begin{lemma}\label{lemma:decomp}
For each , it holds that .
\end{lemma}
\begin{proof}
We prove the statement by induction on ; it trivially holds for , so
consider the induction step from  to . For any node (or part of an edge)
in ,
the statement trivially holds by the induction hypothesis. Hence, suppose a node
(or part of an edge) is outside  and
consider the least-weight path  that leads to  (for simplicity, suppose it contains no
fractional edges; the general case follows by subdividing edges into lines).
Suppose  is the terminal in whose region  the path ends.
Then, by the definition of reduced weights and , the path is
contained in .
Hence, if , i.e., the node (or part
of an edge) is contained in , it must be in . The choice of  implies that  is
equivalent to . Because
the node (or part of an edge) is outside , this is equivalent to the node (or
part of an edge) being in . We
conclude that , i.e., the
induction step succeeds.
\end{proof}

\begin{proof}[Proof of \lemmaref{lemma:path_in_region}]
Since  is a least-weight path, . By the definition of
, hence . By \lemmaref{lemma:decomp},
.
Thus, any path  between to terminals that enters the uncovered region in
phase  must have weight ; in particular,  cannot enter the
uncovered region.

Hence, assume for contradiction that  enters  for some . Denote by  a minimal prefix of  ending at node 
for some . We make a case distinction, where the first case is that
. Consider the concatenation  of the suffix of  starting
at  to a least-weight path from  to . By the definition of regions, we
have that

By assumption  and  are in the same moat after merge , which must
have been active. By the definition of merge phases,  and  thus were
both in active moats during all merges . This entails
that their  variables have been increased by the same value in each of
these merges, yielding that

As  is a least-weight path from  to , we conclude that

This contradicts the minimality of , since  is in an active moat in
merge .


Hence it must hold , which is the second case. Consider
the path  which is the concatenation of a least-weight path between  and
 to . Similarly to the first case, we have that

If  is active,  is in active moats during merges , and similarly to the first case we can infer that

the same applies if . Again this contradicts the
minimality of , as  is active. 

It remains to consider the possibility that  and
. Symmetrically to the first case, we can exclude that
. Since  is in inactive moats during phase , it holds that
. By definition of  and , we
thus have that

As , this
yields

By the pidgeon hole principle, we obtain that

or that

As both  and , this contradicts the minimality of . We conclude that all
cases lead to contradiction and therefore the claim of the lemma is true.
\end{proof}
\begin{proof}[Proof of \lemmaref{lemma:filtering}]
To specify the execution of \algref{algo:centralized}, the following symmetry
breaking rule is introduced: Among all feasible combinations of choices for
 and  in \lineref{line:select_v_i_w_i}, and paths  in
\lineref{line:select_path}, the algorithm selects the path  such
that  is minimal w.r.t.\ the order used in point (iii) of
\defref{def-cand-graph}.

For the respective execution, we show the claim by induction on the merges .
We anchor the induction at , for which , which equals the
union of edges in the paths associated with . Hence, consider merge
, assuming that the claim holds for the first 
merges/candidate merges in . \lemmaref{lemma:path_in_region} shows that the
least-weight path  from  to  selected by
\algref{algo:centralized} in merge  satisfies that . Since  and
,  induces candidate merge
.

We claim that this candidate merge is the next element of  (according to
the order). Assuming otherwise for contradiction, the symmetry breaking rules
specified above imply that there is a candidate merge
 which (i) satisfies that

(lexicographically), (ii) closes no cycle with the first  selected merges,
and (iii) satisfies that . By property (ii) and the
induction hypothesis, . If , the candidate merge
must have been selected as element  into , contradicting the
fact that no w.r.t.\  duplicate edges are selected into . Therefore,
by (i),  and . By the definition of regions,\footnote{TODO: A bit of a leap
here, but should not be hard to show by a case distinction. Should be done at
some point\ldots} this implies that .
It follows that  and  must satisfy that , since otherwise
\algref{algo:centralized} would merge these moats instead in merge . However,
the induction hypothesis and the facts that  closes no cycles and contains
no duplicate edges entail that , a contradiction; the claim
follows.

Because the path associated with candidate merge
 is
, the induction hypothesis yields that the edge set of the union
of paths associated with the first  elements of  is a superset of .
Since  is contained in the shortest-path-trees at
 and , the respective edges close no cycles with the cut of 
with the trees rooted at  and , respectively. Since ,  does not close a cycle in  either. We conclude that
\algref{algo:centralized} adds all edges in  to  when
 does not close a cycle with , implying that
constructing . Hence, the the edge set of the union of paths associated
with the first  elements of  equals , the induction step succeeds,
and the proof is complete.
\end{proof}

\begin{proof}[Sketch of Proof of \lemmaref{lemma:filtering}]
We use the edge elimination procedure introduced for MST
\cite{GarayKP-98,KuttenP-98}, which works as follows. We use an (unweighted) BFS
tree rooted at some node , which can be constructed in  rounds.
For round , let  denote the set of candidate merges node  holds at the end of round , where . In each round each
node executes the following convergecast procedure.
\begin{compactenum}
\item  is scanned in ascending weight order, and a merge that closes
a cycle in  with the union of  and previous merges is deleted. (This
is possible because the merges are tagged by the connectivity components of
the terminals they join in .)
\item The least-weight unannounced merge in  is announced by  to
its parent ( skips this step).
\item  is assigned the union of  with all merges received
from children.
\end{compactenum}
Once all sets stabilize (which can be detected at an overhead of 
rounds), the set  equals .
Perfect pipelining is achieved, leading to the stated running time bound.
\end{proof}

\begin{proof}[Proof of \lemmaref{coro:filtering}]
Set . Each node  locally
computes the connectivity components of  and tags the elements of
 accordingly. We apply the same procedure as for
\lemmaref{lemma:filtering}, except that we need to detect termination
differently, as we would like to stop the routine once the root knows
. The pipelining guarantees that after  rounds of the routine,
the first  elements of the ascending list of merges (whose sublist up to
element  equals ) are known to the root. Since the root
knows  and, for each , , it can locally compute the
variables , , and will detect in round  that
some terminal changes its activity status. This enables to determine when to
terminate the collection routine and which elements of 
constitute .
\end{proof}
We put the pieces of our analysis together to bound the time complexity of our
algorithm.
\begin{lemma}\label{lemma:2_time}
The above algorithm can be implemented such that it runs in 
rounds.
\end{lemma}
\begin{proof}
Clearly, Step 1 can be executed in  rounds. Step 2 consists of local
computations only. By \lemmaref{lemma:equivalent}, we have that
, since at the end of merge phase , no active
terminals remain. We conclude that the loop in Step 3 of the above algorithm is
executed for  iterations. By \lemmaref{lem-numphases}, .

We claim that iteration  of the loop can be executed
in  rounds, which we show by induction on . The induction
hypothesis is that, after  iterations of the loop, the prerequisites of
\lemmaref{lemma:partition} are satisfied for index ,
 for all , and the value of the
variable  is correct for each . This is trivially satisfied
for  by initialization, hence suppose the hypothesis holds for
. Under this assumption, \lemmaref{lemma:partition}
shows that Step 3a can be executed in  rounds, in the sense that the
trees become locally known as stated in the lemma. Clearly, this implies that
Step 3b can be executed in one round, by each node  sending  to each
neighbor.

Consider . We have that
. For each entry, we have that  and . Thus,
if , the hypothesis that
 implies that

and . Hence,
 and an entry
 is a candidate merge if and only
if .

As , it holds that that
 is identical for all
. We have that

Similarly, if ,

because . It follows that

On the other hand, if , the statement  is trivially satisfied, because  spans
. We conclude that  is a candidate merge if and only if .

Therefore, each false candidate in  is of larger weight
than all candidate merges in . We conclude that the prerequisites of
\corollaryref{coro:filtering} are satisfied for merge phase , yielding that
Step 3c can be executed in  rounds.

Step 3d requires local computation only. We observe that:
\begin{compactitem}
\item For each , , since we established
that  for each  with .
\item By \lemmaref{lemma:partition}, the local information available to the
nodes from Step 3a and the  variables permit to determine, for each
, whether  and the fraction of its incident edges
inside .
\item By \lemmaref{lemma:equivalent}, , i.e., the moats
at the beginning of merge phase .
\item The computed variables , , are thus correct.
\end{compactitem}
This establishes the induction hypothesis for index . The total time
complexity of the  iteration of the loop in Step 3 is
, yielding a total of

rounds to complete Step 3.

Step 4 requires local computations only. For Step 5, for an edge 
inducing a candidate merge from ,  and  send a token to their
respective parents. Each node receiving a token for the first time forwards it,
other tokens will be ignored. Edge  and all edges traversed by a token
are selected into . Since the goal is to select for each edge  the
edge and the paths from  and  to the roots in their respective trees, this
rule ensures that  is computed correctly. Because the shortest-path-trees
have depth at most  and there is no congestion, this implementation of Step 4
completes in  rounds (where termination is detected in
 rounds over the BFS tree). Since Step 6 requires no
communication, summing up the time complexities for Steps 1 to 6 yields a total
running time bound of .
\end{proof}
\begin{proof}[Proof of \theoremref{theorem:2_distributed}]
By \lemmaref{lemma:2_time}, the above algorithm can be executed within the
stated running time bound. By \lemmaref{lemma:equivalent}, the edge set  of
the union of paths associated with  equals the set 
computed by some execution of \algref{algo:centralized}. Hence, if we can show
that the set  returned in Step 6 of the above algorithm is the minimal subset
of  that solves the instance, the theorem readily follows from
\theoremref{theorem:2approx}.

Recall that because \algref{algo:centralized} never closes a cycle,
 is a forest, and so is . By the minimality of ,
any two terminals connected by  (viewed as forest in ) must be
connected by any subforest of  that is a solution. For any edge , there is an element of  such that
 is on the associated path connecting  and . Deleting 
from  will disconnect  and  (because  is a forest), implying that
the resulting edge set does not solve the instance of \sfic. We conclude that
 is indeed the edge set returned by \algref{algo:centralized}, and therefore
optimal up to factor .
\end{proof}


\subsection{The distributed algorithm}
\label{app-distalg}
\begin{compactenum}
\item Construct a directed BFS tree, rooted at . For each , broadcast
 to all nodes (via the BFS tree).
\item Set  (index of the merge phase) and . For
each , set , , and
.
\item While  with :
\begin{compactenum}
\item Compute the collection of shortest-path-trees spanning for each 
with   and for each  with 
.
\item For each , denote by  the root of the tree  it
participates in. For each  with , locally construct
 as follows. For each neighbor  of  so that  and
, 
adds  to . For all other nodes ,
.
\item Determine  and make it known to all nodes.
\item Suppose the maximal merge in  is
. Each  locally computes:
\begin{compactitem}
\item for  with ,
; 
\item for  with ,
;
\item whether  or not, and the fraction of its
incident edges inside ;
\item the set  of connectivity components of the forest on 
induced by  (for , denote by  the moat so that );
\item for  with , ;
\item for  with , .
\end{compactitem}
\item .
\end{compactenum}
\item Set .
Each node locally computes the minimal subset  such that
the induced forest on  connects for each  all terminals
 with .
\item . For each element of , suppose  is the
inducing edge and  the associated path. Add  to  and also all
edges on the paths from  to  and  to  that are given by the
shortest-path-trees spanning  and ,
respectively.
\item Return .
\end{compactenum}

\section{Material for \texorpdfstring{\sectionref{sec:sublinear}}{Section
\ref*{sec:sublinear}}}
\label{app:sublinear}
\subsection{Specification of the Algorithm}
\label{app:sublinear-code}
\paragraph{Specification of the algorithm.}
\begin{compactenum}
\item Construct a directed BFS tree, rooted at .
\item Set  (index of the merge phase), , and
. At each , set , ,
, , and  (the leader of moat ).
\item While :
\begin{compactenum}
\item While :
\begin{compactenum}
\item .
\item Compute the shortest-path-trees spanning for each 
with   and for other terminals
.
\item For each , denote by  the root of the tree  it
participates in. For each  with , check whether there
is a neighbor  with . If so, set

i.e.,  is the least-weight candidate merge with an inactive terminal
induced by an edge incident to . For all other nodes , .
\item Over the BFS tree, determine
 and make it known to
all nodes. If there is no such candidate merge or
, set
. Otherwise,
. All terminals  with  set
. Other terminals set
. Each terminal  broadcasts
 over its current shortest-path-tree. Each node
 determines whether it is in  and the fraction of its
incident edges in .
\item If  (i.e., merge phase  does not end the growth
phase), terminal  (i.e., the one with ) broadcasts
 over the BFS tree. All terminals  with  set
. Each terminal  broadcasts  over
its current shortest-path-tree.
\end{compactenum}
\item For  iterations:
\begin{compactenum}
\item Denote by 
the set of current moats. Each small moat  finds the smallest
candidate merge  satisfying that , , and  (if there is any). Denote the set of such candidate merges
by .
\item Interpret  as the edge set of a simple graph on the node set , by
reading each candidate merge  as an edge
.\footnote{This is well-defined, since the minimality of edges in
 ensures that there can be only one edge between any pair of moats.}
Define M_vM_w. Determine an inclusion-maximal matching . Each (small) moat that is not incident to an edge in , but added an
edge to , adds the respective edge to  again, resulting in a set of
candidate merges .
\item For each , add the edges of  to
.
\item Denote by  the set of connectivity components of . For
each , set , where  is the component
such that . Each terminal  learns the identifier of ,
the terminal with largest identifier among all terminals  with .
Each terminal  learns whether  is small.
\item For each small , make the complete set  known to all its
terminals.
\end{compactenum}
\item For each , broadcast  to all nodes in  (over
its shortest-path-tree).
\item For each , locally construct  as follows. Starting from
, for each  with 
and each neighbor  of  so that  and ,  adds
 to . Each candidate merge is tagged by the
identifiers of the moat leaders  and .
\item Denote by  the set of candidate merges whose associated paths' edges
have been added to  so far. Determine .
\item For each , add the edges of  to
.
\item Denote by  the set of connectivity components of . For
each , set , where  is the component
such that . Each terminal  learns the identifier of ,
the terminal with largest identifier among all terminals  with .
Each terminal  learns whether  is small.
\item For each small , make the complete set  known to all its
terminals.
\item For each , determine whether there are  and  so that . If this is the case, set
, otherwise set .
\end{compactenum}
\item Return .
\end{compactenum}

\subsection{Proofs}
\label{app:sublinear-analysis}
\begin{lemma}\label{lemma:number_merge_growth_phase}
For  and any execution of \algref{algo:central_approx},
there are at most  growth phases and
.
\end{lemma}
\begin{proof}We claim that . Assuming the
contrary, there must be some active moat . Since the moat
is active, there are terminals  and  so that
. Clearly, these terminals were not in the same moats after
any merge  and therefore remain active throughout the entire
execution of the algorithm. It follows that
.
However, by definition , implying that

Because , this yields the contradiction

We conclude that indeed . Since
 is initialized to  and grows by factor  with
each growth phase, we obtain that the number of growth phases is bounded by

where the last step exploits that for ,
. The bound on the number of merge
phases follows from this bound and the definition of the , since there are
at most  merges which may result in inactive moats (i.e., input components
become satisfied), each of which can be merged only once.
\end{proof}



\begin{lemma}\label{lemma:large_moats}
At any stage of the above algorithm, the number of large moats is bounded by
 and the connectivity component of  of a small moat has a hop
diameter of at most .
\end{lemma}
\begin{proof}
The bound on the hop diameter of small moats' components trivially follows from
the fact that they contain at most  nodes.

Suppose . We claim that the connectivity component of a moat with 
terminals contains at most  nodes. This holds trivially for the
initial moats. Now suppose moats  and  are merged. The merging path has
at most  hops, implying that at most  nodes are added. Hence the new
moat has at most  nodes. The claim follows. This entails that the total
number of nodes in moats' components is bounded by .

We conclude that there are at most  nodes in moats' connectivity
components w.r.t.\ , and therefore at most  large moats.
\end{proof}
\begin{lemma}\label{lemma:decomp_correct}
Suppose that after  growth phases, the
variables , ,
the local representations of , , and the trees
spanning them, membership of edges in , and
 are identical to the corresponding values for an
execution of \algref{algo:central_approx}. Then in growth phase , Step 3a
of the algorithm correctly computes the terminal decompositions , as well as the variables
 and . It can be completed in
 rounds.
\end{lemma}
\begin{proof}
We prove the claim by induction on the iterations  of the loop in Step 3a, anchored at . The
hypothesis is that all respective values for index  are correct, which holds
for  by assumption. For the induction step from  to , observe
that the hypothesis and \lemmaref{lemma:partition} yield that Step 3aii can be
performed in  rounds. Clearly, Step 3aiii requires one round of
communication only.

If , suppose
. If , we claim that  is the candidate merge
completing merge phase . Otherwise (also if ),  and
active moats grow by exactly  during the
merge phase. To see this, recall that merge phase  ends if (i) an active and
an inactive moat merge or (ii) active moats have grown by
. Note that, by
\lemmaref{lemma:partition} and the induction hypothesis,

for any  so that  and
. Moreover, , as otherwise  and  would have been connected
in an earlier merge phase and cannot satisfy that .

Suppose (i) applies, i.e., \algref{algo:central_approx} merges the moats of
terminals  and  in step , and suppose it does so by the
path  induced by  with 
and  (by \lemmaref{lemma:path_in_region}, we know that
such an edge exists). Since the merge phase ends due to this merge and terminals
can become inactive only at the end of a growth phase, it must hold that
. It follows that
, as any  would imply that another pair of terminals
from active and inactive moats would be merged earlier, ending the merge phase
at an earlier point. The same argument yields that in case of (ii), no
 can exist with
, as otherwise an active and
inactive terminal would get merged before the growth phase ends.

We conclude that the above claim holds. It follows that in Step 3aiv, which can
be completed in  rounds, the correct variables
, , and therefore also regions  are
determined. If , the induction halts. Otherwise, we know that the
merge  connects an active and inactive moat. Because the input labels of
terminals in the inactive moat must be disjoint from those of other terminals
(as by the hypothesis the variables  have correct values), the resulting
moat must consist of active terminals; no terminals outside the new moat change
their activity status. By the prerequisites of the lemma, the terminals in the
inactive moat  recognize their membership by the identifier of their leader
. Since any merge with an inactive moat makes its terminals active and no
terminals can become inactive except for the end of a growth phase, we conclude
that Step 3av results in the correct values of the variables ,
. Step 3av requires  rounds, resulting in a total
complexity of  of the iteration of the while-loop in Step 3a.

The above establishes that, unless , the induction hypothesis is
established for index . Hence, the induction succeeds. We conclude that
there are  iterations of the loop in Step 3a, for each of which
we observed that it can be implemented with running time .
\end{proof}




\begin{lemma}\label{lemma:growth_3b}
Suppose that the prerequisites of \lemmaref{lemma:decomp_correct} are satisfied
for growth phase . Then, each candidate merge selected by the above
algorithm in Step 3b of growth phase  is in  for a (specific, for all
applications of the lemma to an instance fixed) execution of
\algref{algo:central_approx}. The step can be completed in 
rounds.
\end{lemma}
\begin{proof}As in \lemmaref{lemma:equivalent}, we consider the execution of
\algref{algo:central_approx} employing the same tie breaking mechanism as we use
to order candidate merges.

We prove the claim by induction on the iterations of the loop in Step 3b. The
hypothesis is that all merges performed by the algorithm up to the beginning of
the current loop iteration correspond indeed to candidate merges from  and
the moats  defined in Step 3bi implicitly given by the variable 
known to each  are the moats induced by the union of edges of associated
paths. The induction is anchored by the assumptions of the lemma; hence consider
some iteration of the loop.

Suppose for a moat , the smallest candidate merge is
. By \lemmaref{lemma:decomp_correct}, the nodes in 
can detect the existence of the candidate merge by communicating over ;
performing this concurrently for all nodes, this takes one round, since each
edge induces one candidate merge only. Since the moat is small, by
\lemmaref{lemma:large_moats}, the moat's component in  has diameter at
most . Hence, a spanning tree rooted at the leader can be constructed
and used to determine the least-weight candidate merge as specified in Step 2bi
within  rounds (the additive  accounts for the depth of the
trees of the terminal decomposition).

In Step 2bii, only small moats  need to participate in the computation.
We interpret the subgraph of the graph specified in Step 2bii induced by 
as a directed graph, where each small moat has one outgoing edge. We -color
the graph by simulating the Cole-Vishkin algorithm~\cite{CV-86} on this graph,
where moat leaders take the role of the nodes and communication is routed
through the spanning trees of the moats. Observe that since nodes need to
receive messages only from their ``parent'' and send identical messages to their
children, the congestion is constant. Hence, each round of the Cole-Vishkin
algorithm can be simulated in  rounds in , the depth bound for
the trees constructed in Step 2bi. After  rounds, a
-coloring is computed, which in  additional simulated rounds can be used
to determine a maximal matching. After another simulated round, each moat
leader in a small moat knows its incident edges from . Consequently, Step
2biii requires another  rounds.

Concerning Step 3biv, observe that the construction of  ensures for each
connectivity component of , either all moats in the component are
small and it consists of two stars connected by a matching edge, or it is a star
centered at a large moat, whose leaves are all small moats. If the former
applies, \lemmaref{lemma:large_moats} shows that Step 3biv can be completed for
small moats within  rounds using the edges from  in the
respective component of  only. Moreover, in this time a spanning tree can
be constructed and used to count the number of terminals or nodes, respectively,
determining whether the new moat is small. For the case where a large moat is
involved, the new leader will be the leader of the unique large moat in the
respective connectivity component of . Since this leader is already known
to all terminals in the large moat, \lemmaref{lemma:large_moats} shows that its
identifier can be distributed to all nodes in the ``attached'' small moats in
 rounds. Trivially, the resulting moat is large.

With respect to Step 3bv, we again apply \lemmaref{lemma:large_moats}, showing
that for each small moat, in  rounds, a spanning tree with edges
from  can be constructed that spans its component in . This tree is
used to broadcast the terminal identifiers of its at most 
terminals to all constituent nodes within  rounds.

To complete the induction step, it thus remains to show that 
and therefore indeed all edges selected into  in Step 3biii are also selected
by the execution of \algref{algo:central_approx} that selects the same merges
and the associated paths, and also that the computed moats are indeed the cuts
of  with the connectivity components of . Observe that for a candidate
merge added to  by moat , any cycle it might close in  must contain
another candidate merge between terminals in  and . Since any
candidate merge selected into  is minimal among \emph{all} candidate merges
for , it follows that it will never be filtered out. Therefore, it must
hold that . As we already observed earlier,
 is a forest at the end of Step 3bii. Since for each
 the associated path is contained in
 for some , it connects exactly the moats
. We conclude that the new moats are exactly those computed in
the iteration of the loop in Step 3b. We conclude that the induction hypothesis
for the next loop iteration is established, i.e., the induction succeeds. Since
there are  iterations, the total time complexity is
.
\end{proof}

\begin{lemma}\label{lemma:growth_phase}
Suppose the prerequisites of \lemmaref{lemma:decomp_correct} are satisfied for a
growth phase . Then the growth phase can be
completed in  rounds and the prerequisites of
\lemmaref{lemma:decomp_correct} hold for index .
\end{lemma}
\begin{proof}By \lemmaref{lemma:decomp_correct}, the regions , ,
have been determined in Step 3a, within  rounds. By
\lemmaref{lemma:growth_3b}, the Step completes in  rounds and
determines for  the variable  in accordance with , where 
is the edge set of paths associated with a set . Step 3c can
thus be correctly executed in  rounds, and Step 3d, which requires local
computations only, will determine sets , , so that
. Hence, the
preconditions of \lemmaref{lemma:filtering} are satisfied, permitting to perform
Step 3e in  rounds.

We claim that . To
see this, observe that in each iteration of the loop in Step 2b, each small moat
that has an incident candidate merge will be merge with some other moat. Hence,
the minimal number of terminals (if ) or nodes (if ) in a moat
that can still participate in a merge in the growth phase doubles in each
iteration of the loop. It follows that after Step 2b, any moat that can still
participate in a merge in merge phase  is large. By
\lemmaref{lemma:large_moats}, there are at most  large moats. Since
 (as edge set in ) contains neither cycles nor duplicate edges, the
claim follows. In particular, Step 3d completes within  rounds.

Since  becomes known to all nodes, Step 3f can be performed in 
rounds. For Step 3g, we collect for each candidate merge in  the
identifiers of the merged moats' leaders over the BFS tree, in
 rounds. The new leaders then can be
computed locally by all nodes, since  is known by all nodes. For each new
moat, the number of terminals (or nodes) is then determined by pipelining the
respective additions on the BFS tree and broadcasting the result to all nodes,
again requiring  rounds. This enables each node to determine
whether its moat is small or large. Step 3h is performed, for each small moat,
within its connectivity component of . Because
\lemmaref{lemma:large_moats} states that the diameter of these components is at
most  and small moats contain at most  terminals, this
completes in  rounds.

To perform Step 3i, we identify all terminals in each moat with the moat leader
and then apply the technique from \lemmaref{lemma:transform_to_minimal}. Since
an input component  is subset of a moat if and only if there
will be only one tuple  with  present
(possibly at several nodes), this will determine correctly which input
components are satisfied, after  rounds. A moat is
active in growth phase  if and only if there is a terminal whose input
component is not subset of some moat. By \lemmaref{lemma:large_moats}, small
moats have diameter at most  w.r.t.\ , enabling to complete the
step within another  rounds for small moats. For large moats, we
perform the respective convergecasts and broadcasts on the BFS tree, tagging
the messages with the moat leader's identifier. Because, by
\lemmaref{lemma:large_moats}, there are at most  large moats, the
congestion at each node is bounded by  and the step can be
completed in  rounds for large moats.

Summing up the time complexities of all steps, a total of 
rounds suffices to complete the growth phase. The variables
, , have been determined in Step 3i. The variables
 are, by \lemmaref{lemma:decomp_correct}, known by the end of
Step 3a of growth phase , alongside  and the corresponding
spanning trees, for . By \lemmaref{lemma:growth_3b},
the moat leader variables reflected the moats corresponding to the respective
set of selected edges  after Step 3b, which in turn matched a set
 (since there were never any
candidate merges for phases ). By \lemmaref{lemma:filtering} and
Steps 3e to 3g, we conclude that  is the edge set of the paths associated
with , i.e.,  for the
considered execution of \algref{algo:central_approx}, and leader variables
, , have the correct values for these moats. In summary, all
claims of the lemma hold and the proof concludes.
\end{proof}


\begin{proof}[Proof of \corollaryref{coro:growth}]
Constructing a BFS tree requires  rounds.
\lemmaref{lemma:number_merge_growth_phase} and inductive application of
\lemmaref{lemma:growth_phase} shows that Steps 2, 3, and 4 of the algorithm can
be executed in  rounds.
Moreover, the returned set  equals the set  computed by
\algref{algo:central_approx}. Therefore, it is a forest, and its minimal
subforest solving the instance is, by \theoremref{theorem:2+eps_approx}, optimal
up to factor .
\end{proof}

\subsection{Fast Pruning Algorithm}
\label{app:prune}
The following routine assumes that for an instance of \sfic, a forest  on at
most  nodes solving the instance is given, where each
node knows which of its incident edges are in . At the heart of the routine
are Steps 4 to 6, which heavily exploit that  is a tree to ensure optimal
pipe-lining for the edge selection process.
\begin{compactenum}
\item Set  (this will be the pruned edge set). Construct an
(unweighted) BFS tree on , rooted at  and make the set of labels 
known to all nodes.
\item For each connectivity component of  of diameter at most ,
optimally solve the respective (sub)instance of \sfic. Add the respective edges
to  and delete these components from . W.l.o.g., assume that all
components of  have diameter larger than  in the following.
\item Construct a partition of  into clusters , so that
(i) , (ii) for each , the depth of the
minimal subtree of  spanning  is , and (iii) for each , the spanning subtree induced by  is directed to a root 
(in the sense that each node knows its parent and the identifier of ).
\item Denote by  the
forest on  resulting from contracting each  in .
Make  known to all nodes.
\item Each node  initializes for each 
 and for each  . Terminals
 set  (where  is uniquely identified by the
identifier of ).
\item Perform the following on the BFS tree until no more messages are sent
\begin{compactitem}
\item Each node  sends a \emph{non-redundant} node label  for
 to its parent (if there is one). A label is \emph{redundant}
if the following holds. Start from variables  and
 and simulate the operations below for all messages
sent to the parent in previous rounds. If the label in question would not alter
the state of the variables further, it is redundant.
\item If  receives ``'', it sets
. If there is some other  with 
, it sets  and
 for all edges  and nodes  on the
path connecting  and .\footnote{Note that different connectivity
components of  must have disjoint sets of labels, since  solves the
instance. Since  is a forest, there is thus always a unique such path.}
\item Whenever there is for any node  an edge  with
, for each  with  set  and
for each  with  set .
\end{compactitem}
\item Once this is done, the root  of the BFS tree broadcasts the result
(using the same encoding).
\item For each edge in  with , add  to
.
\item For each terminal , set . Nodes  set . If node  is the endpoint of an edge
,  sets .
\item For each tree spanning a cluster , select for each
 the edges of the minimal subtree spanning all terminals  with  into .
\item Return .
\end{compactenum}

We start by analyzing the time complexity of the routine. The first lemma covers
the selection procedure for trees of depth at most  used in Steps 2 and
10.

\begin{lemma}\label{lemma:prune_2_10}
Steps 2 and 10 of the above routine can be completed in  rounds.
\end{lemma}
\begin{proof}
Consider a tree of depth at most , where each node  in the tree is
given a set  and the requirement is to mark all edges
that are on a path connecting some nodes  and  in the tree with , communicating over tree edges only. This is the
requirement of Step 10, and by setting  for terminals  and
 otherwise, we see that Step 2 can be seen as a special case.

We root the tree in  rounds. Consider a fixed label . Each node  with  a message  to its parent,
which is forwarded to the root; each node sends only one such message .
All edges traversed by a message are tentatively marked. Once this is complete,
the root  checks whether it received at least two messages  or
satisfies that . If this is not the case, it sends an ``unmark''
message to the child sending a  message (if there is one). The receiving
child performs the same check w.r.t.\ its subtree, possible sending another
``unmark'' message, and so on. Clearly, removing the edges traversed by an
``unmark'' message from the set of tentatively marked edges is the minimal set
of edges connecting the nodes with . We perform this process
concurrently for all  (tagging the unmark messages by the
respective component label), using pipelining to avoid congestion. Each of
the two phases can be completed in  rounds, since there are at
most  distinct labels and each node sends at most two messages per label.
\end{proof}

The next lemma discusses the growing of clusters. The employed technique is the
same as for Step 3b of the subroutine from \sectionref{sec:tree_selection},
analyzed in detail in \lemmaref{lemma:growth_3b}.

\begin{lemma}\label{lemma:prune_3}
Step 3 of the above routine can be completed in  rounds.
\end{lemma}
\begin{proof}
Initialize the clusters to singletons. We consider a cluster \emph{small}, if it
contains fewer than  nodes. Otherwise it is \emph{large}. For  iterations, perform the following.
\begin{compactenum}
\item Each small cluster selects an arbitrary outgoing edge from  (this is
feasible, since after Step 2 each connectivity component contains at least
 nodes). Denote the set of selected edges by .
\item Suppose  is the subset of edges between small clusters. Find a
maximal matching .
\item Each small cluster without an incident edge from  adds the previously
selected edge to , resulting in set .
\item Merge clusters according to  (constructing rooted spanning trees).
The new clusters select a leader and determine whether they are small or not.
\end{compactenum}
Since for each small cluster in each iteration at least one edge is selected,
the minimal number of nodes in a cluster grows by at least factor  in each
iteration, implying that no small clusters remain in the end. Since there can be
at most  large clusters, the bound on 
holds. Due to the construction of , in each iteration the longest path in
the graph on the current clusters that is selected into  has  hops.
Moreover, at most one large cluster is present in each connectivity component of
the subgraph induced by , implying that the maximal diameter of clusters
remains in .

Concerning the running time, observe that the matching can be selected by
simulating the Cole-Vishkin algorithm~\cite{CV-86} on the cluster graph. Due to
the bound on the diameter of clusters, the routine can be completed in
 rounds.
\end{proof}

Step 6 of our subroutine pipelines several related pieces of information, namely
(i) the inter-cluster edges to select, (ii) input components ``responsible'' for
this edge to be selected, and (iii) input components which can be identified,
because the minimal subtrees of  spanning them are not disjoint (and any
subforest of  solving the instance connects the terminals in the respective
different input components, too).

\begin{lemma}\label{lemma:prune_6_7}
Steps 6 and 7 of the above routine can be completed in  rounds.
\end{lemma}
\begin{proof}
For each , any non-redundant (received) message
 after the first implies that some edge receives a new label.
Initially, the number of different possible labels for edges is at most .
Whenever an already labeled edge receives an additional label, the number of
possible different edge labels is decreased by one. The number of times an
unlabeled edge can become labeled is at most . We
conclude that no node sends more than  messages.

Denote by  the number of non-redundant messages non-root node  will send
and by  the depth of the subtree rooted at . We claim that after 
rounds,  has sent  non-redundant messages, which we show
by induction on . The statement is trivial for , i.e., leaves. For
, by the induction hypothesis at the end of round , either  has
received all non-redundant messages from its children or at least one child sent
at least  non-redundant messages. Hence, if  has not yet sent
 non-redundant messages, it will send another message in
round . By the induction hypothesis, it thus has sent 
messages by the end of round , and the induction step succeeds.

We conclude that Step 6 completes within  rounds. By
broadcasting  non-redundant messages over the BFS tree, it can
make the result known to all nodes, also in  rounds.
\end{proof}

It remains to show that the algorithm chooses the correct set of inter-cluster
edges and the demands derived from the respective selection process in Step 9
ensures that the intra-cluster edges selected into  in Step 10 complete the
minimal solution.

\begin{lemma}\label{lemma:prune_correct}
The set  returned is minimal with the property that it solves
the instance of \sfic solved by .
\end{lemma}
\begin{proof}
Clearly, Step 2 does not affect the correctness of the solution. Hence,
w.l.o.g.\ assume that  contains only components of diameter larger than
, i.e., no deletions happen in Step 2.

Observe that the minimal subforest solving the instance is the union over all
 of the minimal trees  spanning all
terminals  with . Note that by the initialization and
due to the rules of Step 6,  will be labeled by
, i.e., . On the other hand, if , the set of input labels on each side of the edge must be
disjoint. Since Step 6 will maintain this invariant, the edge will satisfy that
. We conclude that the edges selected into  in Step 8 are
exactly the edges from  in a minimal solution.

Denote for each node  in the minimal solution by  its
component in the minimal solution; for  for some such , denote
 ( otherwise). We claim that  at the end of Step 6. To see
this, we claim that the algorithm maintains for all  the invariants that
 and
. This
holds trivially after the initialization in Step 5. According to the first rule
of Step 6 and the invariants, an sent message  satisfies that . Hence, a
node  receiving ``'' will not violate the invariant due to its
change of . If there is some  with ,
the invariant implies that  and  both contain nodes that are connected by
the minimal solution to terminals  with .
Since these terminals must be connected, too, the path connecting  and 
is part of a single connectivity component of the minimal solution, which
contains terminals labeled . We conclude that the invariants cannot be
violated (first) due to the second rule of Step 6. Because if , they must be part of the same connectivity component
of the minimal solution, the invariants cannot be violated (first) due to the
third rule of Step 6. In summary, the invariants are upheld, yielding in
particular that  for each  with .

From this result, it follows that replacing the labels , , by
the sets , , defined in Step 9, does not change the minimal subset
of  that satisfies all constraints: if endpoint  of edge  sets  for , it follows
that  and therefore  is connected to all terminals
 with  by the minimal solution.

Trivially, Step 10 cannot violate the minimality of the computed solution; it
thus remains to show that after Step 10,  solves the instance. Suppose
 with . If  for some , Step 10 ensures
that  and  are connected by , since . Hence,
suppose that . Denote by  the unique path connecting
 and  in . We already observed that 
and each edge  satisfies that . Due to
Steps 9 and 10, it follows that  connects  and .
\end{proof}

We summarize the results of our analysis of the pruning routine as follows.

\begin{corollary}\label{coro:prune}
Given an instance of \sfic and a forest  on  nodes that solves
it, the above routine computes the minimal  solving the
instance. It can be implemented with running time .
\end{corollary}
\begin{proof}
Correctness is shown in \lemmaref{lemma:prune_correct}. Step 1 requires
 rounds. Step 4 can be completed in  rounds, since due
to Step 3  and the nodes incident to the edges in
 know that these edges are in . Steps 5, 8, 9, and 11
require local computations only. The remaining steps can be completed within
 rounds by Lemmas~\ref{lemma:prune_2_10}, \ref{lemma:prune_3},
and \ref{lemma:prune_6_7}.
\end{proof}

We conclude that executing the pruning routine on the input  determined by
the algorithm from \sectionref{sec:sublinear} yields a fast factor
-approximation.

\begin{theorem}\label{theorem:2+eps_distributed}
For any constant , a deterministic distributed algorithm can
compute a solution for problem \sfic that is optimal up to factor
 in  rounds.
\end{theorem}
\begin{proof}
By \corollaryref{coro:growth}, a forest solving the problem whose minimal
subforest is optimal up to factor  can be computed in
. Note that the
forest is the union of at most  paths of hop length at most , and
trivially contains at most  nodes. Hence, we can apply
\corollaryref{coro:prune} with  to show the claim of
the theorem.
\end{proof}

Since any instance can be transformed to one with minimal inputs efficiently and
the number of different terminal decompositions that needs to be computed is
trivially bounded by , we obtain the following stronger bound as a
corollary.

\begin{proof}[Proof of \corollaryref{coro:2+eps_distributed}]
By \lemmaref{lemma:transform_to_minimal}, we can transform the instance to a
minimal instance in  rounds; the minimal instance has  input
components. The number of different possible moat sizes at which merges may
happen is bounded by  (since edge weights are assumed to be integer and
moats grow to size at most ). If multiple merge phases end for the same
such value, we can complete all of them without having to recompute the terminal
decomposition. The result thus follows from
\theoremref{theorem:2+eps_distributed}.
\end{proof}


\section{Proofs for \texorpdfstring{\sectionref{sec-alg2}}{Section
\ref*{sec-alg2}}}

\subsection{Partial Construction of the Virtual Tree}\label{sec:partial}
We start out with some basic observations on the virtual tree that is
constructed by the algorithm from~\cite{KKMPT-12}.
\begin{lemma}\label{lemma:stage1_tree_s}
The following holds for the virtual tree described above.
\begin{compactenum}
\item The tree nodes corresponding to the set  of the  nodes
of highest rank induce a subtree.
\item For each leaf , denote by  the
minimal index so that . Then,
for , there is a least-weight path from  to  of
 hops w.h.p.
\item For each leaf , w.h.p.\ there is a node
 for which  and there is a least-weight path from  to 
of  hops.
\end{compactenum}
\end{lemma}
\begin{proof}
The first statement follows from the fact that for each ,
the index of  w.r.t.\ the random order must be larger than that of
, since  attains the maximum index over
.

For the second statement, consider for any pair of nodes  and  a
least-hop shortest path from  to . If this path contains at least
 hops (for a given constant ), it contains also at least
 nodes (since least-weight paths cannot revisit nodes).
Observe that  is a uniformly random subset of the nodes. Hence, the
probability that no node from  is on the path is bounded from above
by

By the union bound applied to all pairs of nodes , we conclude that
the probability that \emph{any} of these paths contains no node from 
is at most . In other words, w.h.p., for each pair of nodes , either a least-weight path from  to  with
 hops exists, or there is a node from  on a
least-weight path from  to , which therefore is closer to  w.r.t.\
weighted distance than . The second claim of the lemma follows. Regarding
the third claim, observe that the same reasoning applies if we condition on
, showing that w.h.p.\ the least-weight path from  the nodes
 minimizing  must have  hops.
\end{proof}
We leverage these insights to compute the virtual tree partially.
\begin{lemma}\label{lemma:stage1_partial}
Delete the internal nodes corresponding to the set  of the 
nodes of highest rank from the virtual tree. W.h.p., the resulting forest can be
computed within  rounds. Moreover, within this number
of rounds, each node  can learn about
 and all nodes on the corresponding least-weight path can learn
the next hop on this path w.h.p. All detected least-weight paths have
 hops w.h.p.
\end{lemma}
\begin{proof}
We compute a Voronoi decomposition of  w.r.t.\ to . This can be
done by, essentially, the single-source Bellmann-Ford algorithm\footnote{Connect
all nodes in  to a virtual node by edges of weight  and piggy-back
the identifier of the node from  through which the constructed path to
the virtual node would pass on each message.} in time 
w.h.p., since by Statement (iii) of \lemmaref{lemma:stage1_tree_s}, for each
, there is a least-weight path from  to  of  hops w.h.p. Termination can be detected
over a BFS tree, requiring additional  rounds. This shows the second
claim of the lemma. As a byproduct, each node  learns ,
and the nodes on the corresponding least-weight path from  to
 learn the next routing hop on the path.

Now we execute the algorithm from~\cite{KKMPT-12}, however, constructing only
the forest resulting from deleting the internal nodes corresponding to nodes
from . By Statement~(i) of \lemmaref{lemma:stage1_tree_s}, this can be
done by determining, for each , the nodes ,
, and the corresponding least-weight paths in 
connecting  to the . The algorithm from~\cite{KKMPT-12} requires time
 to do so, where  is the maximal length of
any of the detected paths;\footnote{At the heart of the tree embedding algorithm
from~\cite{KKMPT-12} lies the construction of so-called LE lists. The algorithm
proceeds in phases of  rounds, where in each round, information
spreads by one hop along least-weight paths.} by Statement~(ii) of
\lemmaref{lemma:stage1_tree_s},  w.h.p.
\end{proof}


\subsection{Tree Construction and Edge Selection
Stage}\label{sec:tree_selection}

\subsubsection*{Time Complexity}

To prove that the first stage can be completed sufficiently fast, we show
helper lemmas concerning Steps 3a, 3c, and 3d of each phase of the stage.

\begin{lemma}\label{lemma:stage1_3a}
Fix a phase  of the first stage. Step 3a of the phase can
be completed in  rounds.
\end{lemma}
\begin{proof}
The following is performed on a BFS tree.
\begin{compactitem}
\item If the third rule does not prohibit this, each node sends for each
 a message  to its parent.
\item Each node receiving a message forwards it to its parent, unless prohibited
by the third rule.
\item If a node ever receives a second message containing label
, it sends  to its parent and ignores all other messages
concerning .
\item Once this completes, the root of the tree can determine for which labels
 there is only a single active terminal  with
.
\end{compactitem}
This operation completes within  rounds, since no node sends more than
two messages for each label. The root broadcasts the result over the BFS tree to
all nodes, which also takes time .
\end{proof}

\begin{lemma}\label{lemma:stage1_3cd}
Fix a phase  of the first stage. Steps 3c and 3d of the
phase can be implemented such that they complete within
 rounds w.h.p.
\end{lemma}
\begin{proof}
Observe that if , for each  and each , the least-weight path from  to  determined by the tree
construction has at most  hops. If  and the partial construction
was executed, by \lemmaref{lemma:stage1_partial} no detected path has more than
 hops w.h.p. Therefore, all least-weight paths in
 used in Step 3c have at most  hops w.h.p.

In Step 3c, in each iteration of the sending rule, each node sends at most one
message for each node  such that it is on a least-weight path from some leaf
of the virtual tree to  determined by the tree construction. By the
properties of the tree, each node  participates in at most 
different such paths w.h.p. Hence each iteration requires  rounds
w.h.p.\footnote{Note that the respective bound can be computed from , which
can be determined and communicated to all nodes in  rounds. Therefore,
the iterations can be performed sequentially without the need to explicitly
synchronize their execution.}

Consider all messages  that are sent in phase . These messages are
sent along least-weight paths, i.e., they induce a tree rooted at  in .
For each , each node in the tree sends at most one message. In
each iteration of the sending rule, a node will send some message  if
it currently stores any message . Hence,
the total number of iterations until all messages  are delivered is
bounded by the sum of the depth of the tree, which is bounded by 
w.h.p., and . Termination of Step 3c can be detected at an additive
overhead of  rounds over a BFS tree. We conclude that Step 3c can be
performed in  rounds w.h.p.

Concerning Step 3d, the same arguments apply: on each tree rooted at some ,
at most  messages need to be sent to some node 
in the tree. Using the same approach as for Step 3c, this requires
 rounds.
\end{proof}

\begin{corollary}\label{coro:stage1_time}
The first stage can be completed in 
rounds w.h.p.
\end{corollary}
\begin{proof}
In~\cite{KKMPT-12}, the authors show that the virtual tree can be constructed in
 rounds w.h.p. In \lemmaref{lemma:stage1_partial}, we show that
the partial tree can be constructed in  rounds w.h.p.
Therefore, Step 1 of the algorithm completes in
 rounds w.h.p. As Steps 2 and 4 are local
and , it is sufficient to show that each phase
can be implemented in time  w.h.p. By
\lemmaref{lemma:stage1_3a}, Step 3a of each phase can be completed in 
rounds. Step 3b requires local computations only. \lemmaref{lemma:stage1_3cd}
shows that Steps 3c and 3d can be executed in 
rounds w.h.p.
\end{proof}

\subsubsection*{Approximation Ratio}

We now prove that the weight of the edge set  selected in the first stage is
bounded by the cost of the optimal solution on the virtual tree, which is
optimal up to factor  in expectation. This is facilitated by the
following definition.

\begin{definition}[-subtrees]
For , denote by  the minimal subtree of the
virtual tree such that all terminals  with  are leaves
in the subtree.
\end{definition}

We now show that the edges selected into  correspond to edges in the optimal
solution on the virtual tree, which is the edge set of the
union . We first prove that the entries
made into the  variables in Step 3b can be mapped to virtual tree edges
in .

\begin{lemma}\label{lemma:stage1_subtree}
Suppose in phase  of the first stage, node  adds
 or  to its  variable in Step 3b.
Then  for some .
\end{lemma}
\begin{proof}
Assume for contradiction that the statement is wrong and 
is the minimal phase in which some node  violates it. Hence,
 for any . For the subtree
 of the virtual tree rooted at , this implies that
 is partitioned into the sets of labels  and . By induction on phases , we see that at the beginning of each such phase , 
is partitioned into the subsets  and : for , by the induction hypothesis and
Steps 3b to 3d of phase  this would imply that there is a node  on level
 of the virtual tree that has at least one descendant from 
and one descendant outside ; this is impossible for ,
as the root of  is on level .

Due to Steps 3b and 3d in phase , there is at most one node  that has  at the end of phase ; by Step 3b
for phase , it must hold that . However, we just showed that each node
 satisfies that . Thus,  sets
 in Step 3a of phase , contradicting the assumption that it
adds an entry to its  variable in Step 3b of the phase. Therefore, our
assumption that the statement of the lemma is wrong must be false, concluding
the proof.
\end{proof}

With this lemma in place, we are ready to prove that the total weight of the
selected edge set does not exceed the weight of the optimal solution on the
virtual tree. This is done by charging the weight of a selected least-weight
path (or prefix of such a path) to the corresponding virtual tree edge given
by \lemmaref{lemma:stage1_subtree}.

\begin{lemma}\label{lemma:stage1_approx}
The weight of the set  returned by the first stage is bounded from above
by the weight of an optimal solution on the virtual tree.
\end{lemma}
\begin{proof}
Suppose edge  is added to  in phase .
This must have happened because in Step 3c of the phase, it was traversed by
some message  or , where some node 
made the respective entry to its  variable in Step 3b of the phase. In
the latter case, we claim that . Assuming the contrary, clearly 
and Steps 3b to 3d of phase  would entail that  was selected in Step 3d
of phase  by some node  for which it added an entry  to its
 variable in Step 3b of the phase. It follows that ,
and each edge on the respective least-weight path from  to 
has been traversed by a message in Step 3c of phase . In particular, 
was added to  already in an earlier phase. Thus, indeed it must hold that
.

Hence,  is traversed by a message  or 
in phase . From \lemmaref{lemma:stage1_subtree}, we have that
 for some . Moreover, by Steps
3b and 3d of phase , the node  that made the respective entry in Step 3b
of phase  is unique; there can be only one node  in the subtree rooted at
 that satisfies  at the beginning of phase . We
``charge'' the weight of  to the edge . Because node  is unique with the property that the
cost of edges traversed by messages  or  that
are charged to  can be backtraced to an entry it made in Step
3b of phase , virtual tree edge  is in total charged at most
weight  (if ) or  (if ), the
weight of the respective least-weight paths in  from  to  or
, respectively. Because  and ,  is in total
charged at most its own weight of . We conclude that  is indeed at most the weight of the optimal solution on the virtual
tree, i.e., of the edge set of .
\end{proof}

\subsubsection*{Feasibility}

It remains to examine what we have gained from selecting the edge set  in
the first stage.

\begin{lemma}\label{lemma:stage1_connect}
For each terminal , at least one of the
following holds for the graph , where  is the output of the first
stage: (i) all terminals  with  are in the same
connectivity component or (ii)  is at most  hops
from a node in  w.h.p.
\end{lemma}
\begin{proof}
We claim that, for each phase  and ,
the following holds w.h.p.: If at the beginning of the phase there are two or
more terminals  with , at the end of the phase each such 
will be connected to a terminal  with  by a path of
 hops in . 

To see this, observe first that if there are two or more terminals  with
 at the beginning of phase ,  will not be deleted from
the  variables of these nodes in Step 3a of the phase. Hence, each such
 will add an entry , where either  or ,
to its  variable in Step 3b of the phase. In Step 3c, all edges on the
least-weight path from  to  will be added to . Each of the respective
paths has by Step 1 of the algorithm and \lemmaref{lemma:stage1_partial}
 hops w.h.p.

Due to Step 3c,  will add  to . In Step 3d, it will select
some node  that added  to its  variable in Step 3b and
sent  to it;  will hence set . Again,  is connected to  by a path of at most
 hops whose edges have been added to , since in Step
3d a sequence of messages from Step 3c is backtraced. This shows the claim.

By induction on the phases, for each , (i) each terminal  with  is connected in  to some node  with
 via  hops w.h.p.\ at the end of the first
stage, or (ii) there is a unique node so that all terminals  with
 are connected by  to this node. If (i) applies and
, note that in phase  all entries made to 
variables in Step 3b were of the form , where  is the root of
the virtual tree. Hence, all terminals  with  are
connected to the root of the virtual tree by edges in . If , the root of the virtual tree, i.e., the node of highest rank, must
be in . Hence, all entries made to  variables in Step 3b of
phase  were of the form , and all terminals 
with  are connected to a node in~.
\end{proof}

\begin{corollary}\label{coro:stage1_smalls_feasible}
If , the first stage solves problem .
\end{corollary}
\begin{proof}
Because  if , Statement~(i) of
\lemmaref{lemma:stage1_connect} applies to all terminals.
\end{proof}

\subsection{Spanner Construction and Completion Stage}\label{sec:spanner}




\subsubsection*{Running Time of the Transformation}
\begin{corollary}\label{coro:stage2_group}
Within  rounds, each  can learn
the identifier of the node  such that . W.h.p.,
terminals  satisfy that all terminals  with
 are connected in .
\end{corollary}
\begin{proof}
Membership in , , can be concurrently determined for all
terminals  by running (essentially) the single-source Bellmann-Ford
algorithm for  rounds on the (unweighted) graph ,
with a virtual source connected by -weight edges to nodes in  and
piggy-backing the identifiers of nodes in  on messages referring to
paths to them. This can be simulated on  at no overhead, since for each
,  and  know that . The second statement of
the lemma directly follows from \lemmaref{lemma:stage1_connect}.
\end{proof}

As we will see, it is not necessary to construct  explicitly. However,
obviously we must determine .

\begin{lemma}\label{lemma:stage2_compute}
For an -reduced instance,  and  can be computed and
made known to all nodes in  rounds.
\end{lemma}
\begin{proof}
By \corollaryref{coro:stage2_group}, for each  and each terminal
,  can learn  in  rounds. We also make
the set  global knowledge, by broadcasting it over the BFS tree; this
takes  rounds. Next, each node
 locally initializes  and  for each
 if  and  otherwise.
Subsequently, the following is executed on a BFS tree until no node sends any
further messages.
\begin{compactitem}
\item If node  has stored an edge  or some  that it has not yet sent, it sends a message with this information to its
parent.
\item If node  receives a message ``'' and it currently stores
, it sets .
\item If node  receives a message ``'' and it currently stores
, it adds edge  to its set 
unless the edge would close a cycle in .
\item If node  receives a message ``'', it adds
 to its set  unless the edge would close a cycle in
.
\end{compactitem}
Since there are  variables  at each node 
and  remains a forest, each node sends at most  messages.
Since forests are matroids, we have optimal pipelining and no messages are sent
any more after  rounds; this can be detected in additional
 rounds.

We claim that once the above subroutine terminated, at the root  of the BFS
tree the connectivity components of  are the same as the
connectivity components of . To see this, observe first
that , since a node  adds an edge
 to its set  only if it either receives a message
``'' or it receives a message ``'' and stores
 (or vice versa); this implies that some nodes  and
 must have had  and  initially, which
by the initialization values of the variables implies that indeed
. Hence, for any node , any connectivity
component of  is a subset of a connectivity component of
.

Now suppose that . Thus, there are  and  so that  and .
Consider the sequence of ancestors  of  in the BFS
tree, and consider their variables  and , , at the end of the computation. We will prove by induction on
 that for each such ,  connects  to . Trivially, this holds for , so assume that it holds for some  and consider . Since  sends  at
some point, . At the latest upon reception of this
message,  and  become connected by ;
since  is modified only once and  can only add edges
to , but not remove them,  and  are
connected by  when the subroutine terminates. By the induction
hypothesis,  and  are connected by . Due to the
rules of the algorithm,  will announce all edges in  at
some point to . Whenever such a message is received,  either
adds the edge to  or its endpoints are already connected by
. This shows that  eventually gets connected to
, i.e., the induction hypothesis holds for index . In particular,
 connects  and . Reasoning analogously for
,  connects  and , and therefore also
 and . Hence, any connectivity component of  is
a superset of a connectivity component of .

We conclude that the connectivity components of  are the same
as those of , as claimed. Since  is a forest, the
root can broadcast  over the BFS tree in
 rounds. From this, each node can determine
the connectivity components of  locally. Now, each node
can compute  (for ,  iff it is not
isolated in ) and  locally, as  is
already known to all nodes.
\end{proof}

\subsubsection*{Feasibility}

\begin{lemma}\label{lemma:stage2_feasible}
Suppose  is a solution of an -reduced instance, where  is the set
returned by the first stage. Define  by selecting for each
 an edge  inducing it into . Then  is
a solution of the original instance w.h.p.
\end{lemma}
\begin{proof}
Suppose for  we have that . If  or  are
not in , \corollaryref{coro:stage2_group} shows that
 connects  and  w.h.p. Hence, suppose that  and  for some . This implies that
. Because  solves the -reduced
instance, there is a path in  connecting  and
. By definition of  and induced edges together with the fact 
connects each of the sets , ,  connects  and
. Since  where arbitrary with the property that
, applying the union bound over all pairs of terminals
shows that  is a solution of the original instance w.h.p.
\end{proof}

\subsubsection*{Approximation Ratio}

\begin{lemma}\label{lemma:stage2_cost}
An optimal solution to an -reduced instance has at most the weight of an
optimal solution of the original instance.
\end{lemma}
\begin{proof}
Denote by  an optimal solution of the original instance. For each , drop all edges between nodes . The remaining edge set
induces an edge set  of at most weight  in
, which we claim to be a solution to the reduced instance; from this
the statement of the lemma follows immediately.

Consider terminals  of the new instance with
. By definition of , this
entails that there are nodes  and  and a path
 in
. For each edge  on the path,
, there is a node  and terminals
 so that  and
. Because  is a solution of the original instance and
 for each , there is a path
in  connecting  and . Hence, 
connects  and . It follows that it also connects 
and . As  and , there are
paths in  that connect  to  and  to , respectively.
Therefore,  connects  to  and  to ,
respectively. Overall,  connets  and . Since
 were arbitrary with the property that
, we conclude that  is indeed
a solution of the -reduced instance.
\end{proof}

\subsubsection*{Solving the New Instance}

\begin{lemma}\label{lemma:stage2_solve}
A solution  of the -reduced instance determined by the output of the
first stage of weight  times the optimum can be found in
 rounds w.h.p., in the sense that an inducing edge set
 is marked in  that satisfies .
\end{lemma}
\begin{proof}
We use our algorithm from \cite{LenzenP13} with a minor tweak. The (unmodified)
algorithm proceeds in the following main steps.
\begin{compactitem}
\item Sample a uniformly random set  of
 nodes.
\item Construct and make known to all nodes a spanner of the complete graph on
the node set , where the edge weights are the weighted distances
in .
\item For each , make  known to all nodes and locally solve
the instance on the spanner by a deterministic -approximation algorithm.
\item For each edge in the computed solution, select the edges from a
corresponding least-weight path in  into the returned edge set.
\end{compactitem}
Adding the set  ensures that any least-weight path between pairs of
nodes in  that has no inner nodes from  has
 hops. This property is already guaranteed in  and
thus also  due to the uniformly random set  of the 
nodes of highest rank; therefore, it can be skipped.

To simulate the algorithm on , it suffices to slightly modify the
second step of the algorithm. The spanner construction iteratively grows
clusters of nodes that are connected by spanner edges, where usually the
clusters are initialized to the singletons given by the node set of the spanner.
In our setting, for each , the nodes in  are already
connected after the first stage and identified to a single node in .
To reflect this in the spanner construction, we simply initialize the clusters
to be the sets , ; the algorithm then constructs a spanner
on the complete graph on  with edge weights given by
distances in . The paths the algorithm detects and whose edges will be
returned in the last step of the algorithm have weight equal to the edge weights
in .

Because the third step operates on the spanner only, it does not have to be
modified. Using the (deterministic) moat-growing algorithm, which guarantees
, and parameter  in the spanner construction, Theorem 5.2
from \cite{LenzenP13} shows that the returned edge set  has weight at most
 times the optimum of the -reduced instance. The above
modifications to the algorithm do not affect the running time apart from
ensuring that the number of nodes in the spanner (and the instance of \sfic on
the spanner solved in the third step) becomes , so the analysis from
\cite{LenzenP13} yields a running time of .
\end{proof}

\subsection{Completing the Algorithm}

Finally, we can state the complete algorithm as follows.
\begin{compactenum}
\item For a sufficiently large constant , run the first stage 
times.
\item Among the computed edge sets, determine a set  of minimal weight.
\item If , return . Otherwise,
\begin{compactenum}
\item Compute the -reduced instance.
\item Solve the -reduced instance, resulting in edge set .
\item Return .
\end{compactenum}
\end{compactenum}

\begin{proof}[Proof of \theoremref{theorem:fast}]
The time complexity follows from the observation that checking the weight of an
edge set returned by the first stage can be done in  rounds using a BFS
tree, Lemmas~\ref{lemma:stage2_compute} and~\ref{lemma:stage2_solve}, and
Corollaries~\ref{coro:stage1_time} and~\ref{coro:stage2_group}.

In~\cite{KKMPT-12}, it is shown that the weight of the optimal solution on the
virtual tree is within factor  of the optimum in expectation. By
Markov's inequality, with probability at least , this expectation is
exceeded by factor at most . Hence, with probability at least , i.e., w.h.p., at least one of the computed virtual trees exhibits an
optimal solution that is within factor  of the optimum for the
instance on . By \lemmaref{lemma:stage1_approx}, the weight of the set  is
at most that of the optimal solution on the corresponding virtual tree, implying
that the set  determined in the second step of the algorithm has weight
within factor  of the optimum w.h.p.

For , by \corollaryref{coro:stage1_smalls_feasible}  is a
solution, i.e., the claim of the theorem holds. For , the algorithm
proceeds to compute . By \lemmaref{lemma:stage2_solve},  induces a
solution of the -reduced instance, yielding by
\lemmaref{lemma:stage2_feasible} that  solves the original instance
w.h.p. \lemmaref{lemma:stage2_solve} also guarantees that  has weight within
factor  of the optimum of the -reduced instance, which by
\lemmaref{lemma:stage2_cost} implies that  weighs also at most  times optimum of the original instance. We conclude that  is
optimal up to factor  w.h.p. Applying the union bound over the
various statements that hold w.h.p., the statement of the theorem follows for
.
\end{proof}

\end{document}
