\documentclass[paper_2425.tex]{subfiles}

\renewcommand \thepart{}
\renewcommand \partname{}

\begin{document}

\appendix


\twocolumn[{\centering
\Large\textbf{Omni-GAN and Omni-INR-GAN \\Supplementary Material}
\\
[1.5em]
}]

\begin{center}
  \doparttoc \faketableofcontents \part{}
  \parttoc
  \vspace{2cm}
\end{center}




\begin{figure*}[t]
\begin{subfigure}{0.5\textwidth}
    \centering
\includegraphics[width=0.49\linewidth]{figures/save_grad_unified_loss_snsp/spsn_dsn.pdf}
    \includegraphics[width=0.49\linewidth]{figures/save_grad_unified_loss_snsp/spsn_dsp.pdf}
\caption{}
\end{subfigure}
  \hspace{0.1cm}
  \begin{subfigure}{.5\textwidth}
    \centering
\includegraphics[width=0.49\linewidth]{figures/save_grad_unified_loss_spsp/spsp_dsp0.pdf}
    \includegraphics[width=0.49\linewidth]{figures/save_grad_unified_loss_spsp/spsp_dsp1.pdf}
\caption{}
\end{subfigure}
  \vspace{-0.3cm}
  \caption{Gradients of the omni-loss. (a) Gradients \wrt  and  are independent. (b) Gradients \wrt , , are automatically balanced. Please see the text in Sec.~\ref{sec:gradients} for details. This figure is inspired by \cite{sun2020Circle}.}
  \vspace{-0.3cm}
  \label{fig:gradient}
\end{figure*}

\section{Derivation from Unified Loss to Omni-loss.}
\label{apx:derivation_omniloss}


\subsection{Derivation of Omni-loss}

The unified loss~\cite{sun2020Circle} is defined as

where  stands for a scale factor, and  for a margin between positive and negative scores.  and  denote positive score set and negative score set, respectively.
\myeqref{apx:equ:unified_loss} aims to maximize  and to minimize .


The omni-loss is defined as

where  is a set consisting of indexes of negative scores (), and  consists of indexes of positive scores ().

\myeqref{apx:equ:multi_label_loss} is a special case of \myeqref{apx:equ:unified_loss}, which has been proved by ~\cite{su2020multilabelloss}. For the convenience of readers in the English community, we provide our proof here. Let  be  and  be , then

where  means .

According to , we get

where minimizing \myeqref{apx:equ:unified_loss_approx} makes the smallest  greater than the largest .

Let  and . According to \myeqref{apx:equ:unified_loss_r1_m0}, we get

where from \myeqref{apx:equ:unified_loss_approx} we know that minimizing \myeqref{apx:equ:omni_loss_l1} makes  less than .

Let  and . According to \myeqref{apx:equ:unified_loss_r1_m0}, we get

where minimizing \myeqref{apx:equ:omni_loss_l2} makes  greater than .

Adding \myeqref{apx:equ:omni_loss_l1} and \myeqref{apx:equ:omni_loss_l2}, we get

where minimizing \myeqref{apx:equ:omni_loss} makes  less than  and  greater than .
We finish the derivation.


\subsection{Gradient Analysis}
\label{sec:gradients}

The gradients of omni-loss have two properties: on one hand, the gradients \wrt  and  are independent; on the other hand, the gradients \wrt  (or ), , are automatically balanced. To illustrate these properties, we visualize the gradients of omni-loss. Fig.~\ref{fig:gradient}a shows a case that only contains one  and one . , , and  have the same , which is , but different  (\ie, , respectively). As a result, the gradients \wrt  at these three points are the same (\ie, ). Nevertheless, the gradients \wrt  at these three points are different. For example, the gradient \wrt  at  is largest (equal to ).  The reason for this is that the objective of omni-loss is to minimize . Thus the larger the , the larger the gradient \wrt .

In Fig.~\ref{fig:gradient}b, we show the ability of omni-loss to automatically balance gradients. We consider a case with only two positive labels, namely  and . We can observe that for , its  is smaller than  (\ie, -2 vs. 0). As a result, the gradients \wrt  is larger than that \wrt  (\ie, 0.79 vs. 0.11), meaning that the omni-loss try to increase  with higher superiority. A similar analysis applies to  as well. For , since  and  are equal, the gradients of them are also equal ().


\section{Gradient Penalty for Classification-based cGANs}
\label{apx:sec:gp}

We investigate whether gradient penalty will alleviate early collapse. We chose AC-GAN~\cite{odena2017Conditional}, the currently widely known classification-based cGAN, as the testbed, and evaluate three gradient penalty methods: WGAN-GP~\cite{gulrajani2017Improved}, WGAN-div~\cite{mescheder2018Which}, and R1 regularization~\cite{wu2018Wasserstein}. Because cGANs are more likely to collapse when the number of categories is large, we evaluate them on CIFAR100 instead of CIFAR10. As shown in Fig.~\ref{apx:fig:acgan_gp}, none of the three gradient penalty methods can prevent AC-GAN from collapsing. We emphasize that computing gradient penalties will introduce additional computational overhead during GAN's training, which is very unfriendly to large-scale datasets such as ImageNet. However, weight decay effectively alleviates the collapse problem without adding any additional training overhead.


\begin{figure}[t]
\centering
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth,height=3.3cm]{figures/ACGAN_GP/ACGAN_gradient_penalty_c100_FID.pdf}
    \caption{FID on CIFAR100}
  \end{subfigure}
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth,height=3.3cm]{figures/ACGAN_GP/ACGAN_gradient_penalty_c100_IS.pdf}
    \caption{IS on CIFAR100}
  \end{subfigure}
  \vspace{-0.2cm}
  \caption{FID and IS on CIFAR100. We test three gradient penalty methods (\ie, WGAN-GP, WGAN-div, and R1 regularization), none of which can alleviate the collapse issue of AC-GAN.}
  \label{apx:fig:acgan_gp}
\end{figure}


\section{Improved AC-GAN (ImAC-GAN)}
\label{apx:sec:imacgan}

Auxiliary classifier GAN (AC-GAN)~\cite{odena2017Conditional} uses an auxiliary classifier to enhance the standard GAN model. Its objective function consists of tow parts: the GAN loss, , and the classification loss, :


where  is a random variable denoting the class label and  is the ground truth label of .  and  represent a real image and a generated image respectively. The discriminator  of AC-GAN is trained to maximize , and the generator is trained to maximize .

The discriminator loss of AC-GAN is not optimal. We give a slightly modified version below. Suppose the dataset owns  categories, then the discriminator is trained to maximize

where  is the ground truth class label of , and  means that  belongs to the fake class. To sum up, we use an additional class to represent the generated image. In practice, this is achieved by setting the dimension of the fully connected layer of the auxiliary classification layer to be  rather than .

The objective function of the generator is consistent with that of the original AC-GAN, \ie, maximizing

where  is the class label used by the generator to generate .

We name this improved version of AC-GAN ImAC-GAN. As shown in the paper, ImAC-GAN is comparable to Omni-GAN, both of which achieve superior performance compared to projection-based cGANs. However, because ImAC-GAN uses cross-entropy as the loss function for classification, it can only handle the case where the sample has a positive label. Omni-GAN uses omni-loss, essentially a multi-label classification loss, which naturally supports handling samples with one positive label or multiple positive labels. We will give an example of generating images with multiple positive labels in Sec.~\ref{apx:sec:multi_label_D}.

\section{Technical Details of Omni-INR-GAN}
\label{apx:sec:omni_inr_gan}


Learning image prior model is helpful for image restoration and manipulation, such as denoising, inpainting, and harmonizing. Deep generative prior (DGP)~\cite{pan2020Exploiting} showed the potential of employing the generator prior captured by a pre-trained GAN model (\ie, a BigGAN model trained on a large-scale image dataset, ImageNet). However, BigGAN can only output images with a fixed aspect ratio, limiting the practical application of DGP. To make the pre-trained GAN model more flexible for downstream tasks, we propose a new GAN named Omni-INR-GAN, which can output images with any aspect ratio and any resolution.

Images are usually represented by a set of pixels with fixed resolution. A popular method named implicit neural representation (INR) is prevalent in the 3D field~\cite{park2019DeepSDF,mescheder2019Occupancy,chen2019Learninga}. Recently, people introduced the INR method to 2D images~\cite{chen2020Learning,skorokhodov2020Adversarial}. As shown in Fig.~\ref{apx:fig:omni_inr_gan} (a), the INR of an image directly maps (, ) coordinates to image's RGB pixel values. Since the coordinates are continuous, once we get the INR of an image, we can get images of arbitrary resolutions by sampling different numbers of coordinates.

Inspired by the local implicit image function (LIIF)~\cite{chen2020Learning}, we use INR to enhance Omni-GAN, with the goal of enabling the generator to output images with any aspect ratios and any resolution. We name our method Omni-INR-GAN.
As shown in Fig.~\ref{apx:fig:omni_inr_gan} (b), we keep the backbone of the generator network unchanged and employ an INR network for the output layer. Let  represent the output feature map of the backbone,  be the implicit neural function. Then the RGB signal at (, ) coordinate is given by , where  stands for the feature vector at (, ). Note that since  and  can be any real numbers,  may not exist in . In such a case, we adopt the bilinear interpolation of the four feature vectors near (, ) as the feature at (, ).

Omni-INR-GAN can generate images with any aspect ratio, so as to be more friendly to downstream tasks like image restoration and manipulation. After trained on the large-scale dataset ImageNet, Omni-INR-GAN can be combined with DGP to do restoration tasks. Omni-INR-GAN eliminates cropping operations before image restoration, making it possible to repair the entire image directly. Since the generator has seen considerable natural images, utilizing the generator prior can facilitate downstream tasks significantly.


\begin{figure}[t]
  \begin{center}
\includegraphics[width=\linewidth]{./figures/omni_inr_gan.pdf}
  \end{center}
  \vspace{-0.5cm}
  \caption{(a) An example of an image represented in INR form. A fully connected network maps coordinates  to pixel values . (b) Using an INR network to enhance the generator so that the generator can output images with any resolution and any aspect ratio.}
  \label{apx:fig:omni_inr_gan}
\end{figure}



\section{An Example of Multi-label Discriminator}
\label{apx:sec:multi_label_D}


Omni-loss is essentially a multi-label classification loss and naturally supports classification with multiple positive labels. To verify the ability of Omni-GAN for generating samples with multiple positive labels, we construct a mixed dataset containing images of digits from two distinct domains, namely MNIST~\cite{lecun1998gradient} of handwritten digits and SVHN~\cite{netzer2011reading} of house numbers. Some example images from the datasets are shown in Fig.~\ref{apx:fig:mnist_svhn}. In this setting, the discriminator needs to predict three attributes, class (recognizing digits), domain, and reality.

Let us take images of MNIST as an example, and show how to set the loss for the discriminator. As for SVHN, the case is analogous. Suppose  is an image sampled from MNIST, its multi-label vector is given by

where  means the corresponding score belongs to the negative set, and  to the positive set. As can be seen,  possesses three positive labels. The multi-label vector for  is then given by

which is a one-hot vector with the last element being . The discriminator loss is given by


For generator, its goal is to cheat the discriminator. The multi-label vector for  is given by

where  is  if its index in the vector is equal to the label adopted by the generator to generate , otherwise . The generator loss is given by.


We experimentally found that this multi-label discriminator can instruct the generator to generate images from different domains. Some generated images are shown in Fig.~\ref{apx:fig:generated_mnist_svhn}. We must emphasize that this is only a preliminary experiment to verify the function of the multi-label discriminator. We look forward to applying the multi-label discriminator to other tasks in the future, such as translation between images in different domains, domain adaptation, \etc.



\begin{figure}[tbp]
  \centering
  \begin{minipage}[t]{\linewidth}
    \begin{subfigure}{0.49\linewidth}
      \centering
\includegraphics[width=\linewidth]{figures/save_mnist_svhn_generated/mnist.png}
\caption{MNIST}
\end{subfigure}
    \begin{subfigure}{0.49\linewidth}
      \centering
\includegraphics[width=\linewidth]{figures/save_mnist_svhn_generated/svhn.png}
\caption{SVHN}
\end{subfigure}
    \vspace{-0.3cm}
    \caption{Real images sampled from the dataset.}
    \vspace{0.5cm}
    \label{apx:fig:mnist_svhn}
  \end{minipage}\\
  \begin{minipage}[t]{\linewidth}
    \begin{subfigure}{0.49\linewidth}
      \centering
\includegraphics[width=\linewidth]{figures/save_mnist_svhn_generated/Gz_mnist.png}
\caption{MNIST}
\end{subfigure}
    \begin{subfigure}{0.49\linewidth}
      \centering
\includegraphics[width=\linewidth]{figures/save_mnist_svhn_generated/Gz_svhn.png}
\caption{SVHN}
\end{subfigure}
    \vspace{-0.3cm}
    \caption{Images generated by a generator which is guided by a multi-label discriminator.}
    \vspace{0.5cm}
    \label{apx:fig:generated_mnist_svhn}
  \end{minipage}
\end{figure}





\section{Additional Results on CIFAR}
\label{apx:sec:results_cifar}

\subsection{Over-fitting of the Discriminator}

\begin{figure}[!t]
  \begin{subfigure}{0.49\linewidth}
    \centering
\includegraphics[width=\linewidth]{figures/save_early_collapse_Dx_on_cifar100/D_logits_biggan_cifar100.pdf}
\caption{}
  \end{subfigure}
\begin{subfigure}{.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/save_early_collapse_Dx_on_cifar100/D_logits_biggan_weight_decay_cifar100.pdf}
    \caption{}
  \end{subfigure}
  \vspace{-0.3cm}
  \caption{The raw logits of  and the corresponding FID score of a projection-based cGAN are plotted in the same figure. The black dashed line indicates where the minimum FID is reached. (a) training without weight decay. (b) training with weight decay.  The figures of  are inspired by~\cite{karras2020Training}.}
  \label{apx:fig:early_collapse}
\end{figure}


Karras \etal~\cite{karras2020Training} found that the discriminator overfits the training dataset, which will lead to incorrect gradients provided to the generator. Thus the training diverges. To verify that the collapse of the projection-based cGAN is due to the over-fitting of the discriminator, we plotted the scalar output of the discriminator, , over the course of training. We utilized the test set of CIFAR100 containing  images as the verification set, which was not used in the training.

As shown in Fig.~\ref{apx:fig:early_collapse}a, obviously, as training progresses, the  of the validation set tends to that of the generated images, substantiating that the discriminator overfits the training data. We also plotted the FID curve in the same figure. We can see that the training commences diverging when showing about M real images (\ie, around  epoch) to the discriminator. The best FID is obtained when approximately M real images are shown to the discriminator.

In Fig.~\ref{apx:fig:early_collapse}b, we show the  and FID after applying weight decay to the projection-based discriminator. We can find that although the discriminator still overfits the training data, the training dose not collapse during the whole training process (the minimum FID, , is reached at the end of the training).




\subsection{Comparison of One-sided Omni-GAN and Projection-based GAN on CIFAR10}
\label{apx:sec:one_side}

\begin{figure}[!t]
  \begin{subfigure}{0.49\linewidth}
    \centering
\includegraphics[width=\linewidth]{figures/save_oneside_cifar10_FID/cGAN_oneside_FID_c10.pdf}
\caption{}
\end{subfigure}
  \begin{subfigure}{0.49\linewidth}
    \centering
\includegraphics[width=\linewidth]{figures/save_oneside_cifar10_IS/cGAN_oneside_IS_c10.pdf}
\caption{}
\end{subfigure}
  \caption{One-sided Omni-GAN is on par with projection-based BigGAN on CIFAR10, proving that one-sided Omni-GAN indeed belongs to projection-based cGANs. Both of them are inferior to the classification-based cGAN, Omni-GAN.}
  \label{apx:fig:oneside_c10}
\end{figure}

We provide the results of one-sided Omni-GAN and projection-based BigGAN on CIFAR10. As shown in Fig.~\ref{apx:fig:oneside_c10}, one-sided Omni-GAN is comparable to the projection-based BigGAN in terms of both FID and IS. This proves that one-sided Omni-GAN indeed belongs to projection-based cGANs. Both one-sided Omni-GAN and projection-based BigGAN are inferior to Omni-GAN. Because the only difference between one-sided Omni-GAN and Omni-GAN is whether the supervision is fully utilized, we conclude that the superiority of Omni-GAN lies in the full use of supervision.


\subsection{Comparison with Multi-hinge GAN}
\label{sec:comparison_multihinge}

Multi-hinge GAN belongs to classification-based cGANs, and also suffers from the early collapse issue. We study whether weight decay is effective for Multi-hinge GAN. As shown in Fig.~\ref{apx:fig:multihinge_wd_c100}, original Multi-hinge GAN suffers a severe early collapse issue. After equipped with weight decay, Multi-hinge GAN enjoys a safe optimization and its FID is even comparable to that of Omni-GAN. However, its IS is worse than that of Omni-GAN.

Multi-hinge GAN combined with weight decay does not always perform well. The results on CIFAR10 are shown in Fig.~\ref{apx:fig:multihinge_wd_c10}. Weight decay deteriorates Multi-hinge GAN in terms of both FID and IS. However, Omni-GAN outperforms Multi-hinge GAN. In addition, omni-loss is more flexible than multi-hinge loss. It supports implementing a multi-label discriminator. As a result, we suggest first considering using Omni-GAN when choosing cGANs.



\begin{figure}[t]
  \centering
  \begin{subfigure}{0.49\linewidth}
\includegraphics[width=\linewidth]{figures/save_multihinge_weight_decay_cifar100_FID/cGAN_multihinge_wd_FID.pdf}
    \caption{}
  \end{subfigure}
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/save_multihinge_weight_decay_cifar100_IS/cGAN_multihinge_wd_IS.pdf}
    \caption{}
  \end{subfigure}
  \caption{FID and IS on CIFAR100. Weight decay can eliminate the early collapse problem of Multi-hinge GAN on CIFAR100.}
  \label{apx:fig:multihinge_wd_c100}
\end{figure}

\begin{figure}[t]
  \begin{subfigure}{0.49\linewidth}
    \centering
\includegraphics[width=\linewidth]{figures/save_multihinge_weight_decay_cifar10_FID/cGAN_multihinge_wd_FID_c10.pdf}
\caption{}
\end{subfigure}
  \begin{subfigure}{0.49\linewidth}
    \centering
\includegraphics[width=\linewidth]{figures/save_multihinge_weight_decay_cifar10_IS/cGAN_multihinge_wd_IS_c10.pdf}
\caption{}
\end{subfigure}
  \caption{FID and IS on CIFAR10. Weight decay deteriorates Multi-hinge GAN.}
  \label{apx:fig:multihinge_wd_c10}
\end{figure}

\subsection{Applying Weight Decay to the Generator}
\label{apx:sec:weight_decay_generator}

\begin{figure}[t]
  \centering
  \centering
  \includegraphics[width=0.7\linewidth]{figures/save_G_weight_decay_cifar100_IS/cGAN_G_wd_IS.pdf}
  \caption{Applying weight decay to the generator. Applying weight decay to the discriminator helps alleviate the collapse issue, but the IS gradually decreases as the training progresses. Applying weight decay to the generator simultaneously solves this problem. Experiments are conducted on CIFAR100.}
  \label{apx:fig:generator_wd}
\end{figure}


We found empirically that applying weight decay also to the generator can make training more stable. As shown in Fig.~\ref{apx:fig:generator_wd}, although only applying weight decay to the discriminator can avoid the risk of collapse earlier, the IS has a trend of gradually decreasing as the training progresses. Fortunately, applying weight decay (set to be  in our most experiments) to the generator can solve this problem. This phenomenon seems to indicate that the generator is also at a risk of over-fitting.



\subsection{How to Set the Weight Decay?}

We did a grid search for the weight decay on CIFAR and found that its value is related to the size of the training dataset. For CIFAR100, there are only  images per class, and the weight decay is set to be . For CIFAR10, there are  images per class, and the weight decay is set to be . For ImageNet, it is a large dataset with a considerable number of training data (approximate M). The weight decay is set to 0.00001. The conclusion is that the smaller the dataset, the higher the risk of over-fitting for the discriminator. Then weight decay should be larger.


\section{Additional Results on ImageNet}
\label{apx:sec:curves_imagenet}

We provide convergence curves on ImageNet . As shown in Fig.~\ref{apx:fig:imagenet256}, both Omni-GAN and Omni-INR-GAN converge faster than BigGAN, proving the effectiveness of combining strong supervision and weight decay. Omni-INR-GAN clearly outperforms Omni-GAN, showing its significant potential for future applications. In Fig.~\ref{apx:fig:truncation_imagenet256.}, we show the tradeoff curve of these methods using the truncation trick on ImageNet . Omni-INR-GAN is consistently superior to Omni-GAN and BigGAN.

\begin{figure}[t]
\centering
\begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth,height=3.3cm]{figures/imagenet/save_OmniGAN_ImageNet256_FID.pdf}
    \caption{FID on ImageNet }
  \end{subfigure}
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth,height=3.3cm]{figures/imagenet/save_OmniGAN_ImageNet256_IS.pdf}
    \caption{IS on ImageNet }
  \end{subfigure}
  \vspace{-0.2cm}
  \caption{FID and IS on ImgeNet . Omni-GAN and Omni-INR-GAN converge faster than the projection-based BigGAN. Omni-INR-GAN clearly outperforms Omni-GAN, showing its significant potential for future applications.}
  \label{apx:fig:imagenet256}
\end{figure}

\begin{figure}[t]
  \centering
  \centering
  \includegraphics[width=0.7\linewidth]{figures/imagenet/truncation_imagenet256.pdf}
  \caption{Tradeoff curves using truncation trick on ImageNet . We show truncation values from  to  with step being . Omni-INR-GAN outperforms Omni-GAN and BigGAN.}
  \label{apx:fig:truncation_imagenet256.}
\end{figure}


\section{Application to Image-to-Image Translation}
\label{apx:sec:imagetoimage}


\begin{table*}[t]
  \centering
  \resizebox{0.9\textwidth}{!}{\begin{tabular}{ccccccccccc}
      \toprule
      \multirow{4}{*}{SPADE~\cite{park2019Semantic}} & \textit{road} & \textit{sidewalk} & \textit{building} & \textit{wall} & \textit{fence} & \textit{pole} & \textit{traffic light} & \textit{traffic sign} & \textit{vegetation} & \textit{terrain} \\
&        &            &            &        &         &        &                 &                &              &           \\
      \cmidrule{2-11}
                                                     & \textit{sky}  & \textit{person}   & \textit{rider}    & \textit{car}  & \textit{truck} & \textit{bus}  & \textit{train}         & \textit{motorcycle}   & \textit{bicycle}    & mIoU             \\
                                                     &        &            &            &        &         &        &                 &                &              &           \\
      \midrule
      \multirow{4}{*}{+ Omni-GAN}                    & \textit{road} & \textit{sidewalk} & \textit{building} & \textit{wall} & \textit{fence} & \textit{pole} & \textit{traffic light} & \textit{traffic sign} & \textit{vegetation} & \textit{terrain} \\
                                                     &        &            &            &        &         &        &                 &                &              & 
      \\
      \cmidrule{2-11}
                                                     & \textit{sky}  & \textit{person}   & \textit{rider}    & \textit{car}  & \textit{truck} & \textit{bus}  & \textit{train}         & \textit{motorcycle}   & \textit{bicycle}    & mIoU             \\
                                                     &        &            &            &        &         &        &                 &                &              &  \\
      \bottomrule
    \end{tabular}}
  \vspace{-0.2cm}
  \caption{Semantic image synthesis using SPADE. Replacing the GAN used by SPADE with Omni-GAN can improve the quality of synthesized images.}
  \vspace{-0.4cm}
  \label{tab:spade}
\end{table*}


Omni-GAN can be used for image-to-image translation tasks. We verify the effectiveness of Omni-GAN on semantic image synthesis~\cite{wang2018VideotoVideo,qi2018Semiparametric}. In particular, we replace the GAN loss of SPADE~\cite{park2019Semantic} with Omni-GAN's loss, and keep other hyper-parameters unchanged.
The discriminator is a fully convolutional network, which is widely adopted by image-to-image translation tasks~\cite{park2019Semantic,isola2017ImagetoImage,wang2018HighResolution}. As shown in Fig.~\ref{apx:fig:per_pixel_omni_loss}, the discriminator takes images as input and outputs feature maps with the number of channels being .  represents the number of classes which is analogous to that of the semantic segmentation task.  indicates there are two extra feature maps representing to what extent the input image is real or fake. We adopt nearest neighbor downsampling to downsample the label map to the same resolution as the output feature maps of the discriminator. Then we use the downsampled label map as the ground truth label, and apply a per-pixel omni-loss to the output feature maps of the discriminator.

We use Cityscapes dataset~\cite{cordts2016Cityscapes} as a testbed, and train models on the training set with size of . The images is resized to . Models are evaluated by the mIoU of the generated images on the test set with  images. We use a pre-trained DRN-D-105~\cite{yu2017Dilated} as the segmentation model for the sake of evaluation. As shown in Table~\ref{tab:spade}, Omni-GAN improves the mIoU score of SPADE from  to , substantiating that the synthesized images possess more semantic information. We believe that the improvement comes from the improved ability of the discriminator in distinguishing different classes, so that the generator receives better guidance and thus produces images with richer semantic information.

\begin{figure}[t]
  \begin{center}
\includegraphics[width=\linewidth]{./figures/per_pixel_unified_loss.pdf}
  \end{center}
  \vspace{-0.5cm}
  \caption{Combine omni-loss with a fully convolutional discriminator whose outputs are feature maps. In the figure, the green and red feature maps represent scores that the input images are real and fake, respectively. Omni-loss is applied to the output feature maps pixel-by-pixel. }
  \label{apx:fig:per_pixel_omni_loss}
\end{figure}

\section{Application to Downstream Tasks}
\label{apx:sec:downstream_tasks}


\subsection{Colorization and Super-resolution}

Deep generative prior (DGP)~\cite{pan2020Exploiting} showed the potential of employing image prior captured by a pre-trained GAN model. Our colorization and super-resolution schemes are based on DGP. We first introduce the preliminary knowledge of DGP.

Suppose  is a natural image and  is a degradation function, \eg, gray transform for colorization and down-sampling for super-resolution. Then  represents the degraded image, \ie, a partial observation of the original image, . The goal of image restoration is to recover  from  with the help of some statistical image prior of . DGP proposes employing the image prior stored in a pre-trained GAN's generator. The objective is defined as

where  is a noise vector.  represents the generator in GAN and is parameterized by .  is a discriminator-based distance metric: .  is the discriminator coupled with .  is a index set for feature maps of different blocks of . Note that both  and  have been trained on a large-scale natural image dataset. DGP employs the prior of  by fine-tuning  and . After fine-tuning, we get the restored image .


Although DGP has achieved noteworthy results in image restoration and manipulation, it has limitations due to the inflexibility of the pre-trained GAN model. For example, if DGP adopts a  BigGAN model, DGP must first crop the original image into image patch of size  before restoration, restricting its practical application. However, because Omni-INR-GAN can output images of any resolution, combining it with DGP can directly restore the original image.

We use Omni-INR-GAN pre-trained on ImageNet  for colorization and super-resolution. \myeqref{apx:equ:dgp_objective} is the objective. For colorization,  is a grayscale image, and for super-resolution,  is a low-resolution image. We resize the input image's short edge to  and keep the aspect ratio of the image unchanged.  After fine-tuning,  is the restored image. Because  represents  in the INR form, we can get the restored image at any resolution through . Therefore, Omni-INR-GAN is more friendly to downstream tasks.



\subsection{Reconstruction}

We compare pre-trained GAN models for image reconstruction tasks. Specifically, we finetune the parameters of the generator to make it reconstruct given images. Note that we do not use mse or L1 loss, because these loss functions make it easy for the generator to overfit the given image, as long as the training iterations are enough. Instead, we only use the discriminator feature loss, because it has been proven to be very effective for utilizing the prior of the generator. For the dataset, we use 1k images sampled from the ImageNet validation set, which is the same as DGP's choice. Note that these data have not been used in GAN's training. We adopt the progressive reconstruction strategy of DGP~\cite{pan2020Exploiting}, and finetune each GAN model for the same number of iterations.


\section{Implementation Details}

We adopt BigGAN architectures of  and  in our experiments. Table~\ref{apx:tab:omnigan_imagenet128}, \ref{apx:tab:omnigan_imagenet256}, \ref{apx:tab:omniinrgan_imagenet128}, and \ref{apx:tab:omniinrgan_imagenet256} show the architectural details. Each experiment is conducted on eight v100 GPUs. Training Omni-GAN on ImageNet  and  took  days and  days, respectively. Training Omni-INR-GAN on ImageNet  and  took  days and  days, respectively. No collapse occurred during the entire training process. We have found experimentally that classification-based cGANs cannot set a large batch size like projection-based BigGAN. For all experiments of Omni-GAN and Omni-INR-GAN, the batch size is set to . We adopt the ADAM optimizer in all experiments, with betas being  and . The learning rates of the generator and discriminator are set to  and , respectively.

For  experiments, the generator and discriminator use non-local block at  resolution. The generator is updated once every time the discriminator is updated. The weight decay of the generator and discriminator are set to  and , respectively. For Omni-INR-GAN, we removed the non-local block at  resolution of the discriminator. Because when Omni-INR-GAN is used for downstream tasks, the input image of the discriminator may be of any size, so the middle layer of the discriminator may not output  resolution features. Moreover, although Omni-INR-GAN can generate images of any resolution, we did not adopt a multi-scale training strategy. We found that multi-scale training led to training collapse. We think that a possible reason is that multi-scale training enhances the discriminator, resulting in the ability of the generator and the discriminator to be out of balance. Thus we only generate  images during training, and the real images are also resized to .

For  experiments, the weight decay of the generator and discriminator are set to  and , respectively. The generator is updated once every time the discriminator is updated twice. We have found experimentally that this will make training more stable. The generator and discriminator use non-local block at  resolution rather than  due to limited GPU memory. For Omni-INR-GAN, in order to support downstream tasks friendly, we do not use non-local block in the discriminator. Moreover, due to GPU memory limitation, we reduce the batch size to  and accumulate the gradient twice to approximate the gradient when the batch size is . We did not adopt a multi-scale training strategy. Only  images are generated during training, and the real images are also resized to .

\begin{table*}[htbp]
  \begin{subtable}[t]{0.48\linewidth}
    \centering
    \resizebox{0.8\linewidth}{!}{\centering
      \begin{tabular}{c}
        \toprule
         \\
        \midrule
        Linear                                           \\         \midrule
        ResBlock up                                                     \\         \midrule
        ResBlock up                                                      \\         \midrule
        ResBlock up                                                       \\         \midrule
        ResBlock up                                                       \\         \midrule
        Non-local Block  ()                                                      \\         \midrule
        ResBlock up                                                        \\         \midrule
        BN, ReLU,  Conv                                            \\         \midrule
        Tanh                                                                                   \\
        \bottomrule
      \end{tabular}}
    \caption{Generator}
  \end{subtable}
  \centering
  \begin{subtable}[t]{0.48\linewidth}
    \centering
    \resizebox{.6\linewidth}{!}{\begin{tabular}{c}
        \toprule
        RGB image  \\ \midrule
        ResBlock down                          \\ \midrule
        Non-local Block ()                         \\ \midrule
        ResBlock down                        \\ \midrule
        ResBlock down                       \\ \midrule
        ResBlock down                       \\ \midrule
        ResBlock down                      \\ \midrule
        ResBlock                          \\ \midrule
        ReLU, global sum pooling                                 \\ \midrule
        Linear                                 \\
        \bottomrule
      \end{tabular}}
    \caption{Discriminator}
  \end{subtable}
  \caption{Omni-GAN architecture on ImageNet .  is set to be .}
  \label{apx:tab:omnigan_imagenet128}
\end{table*}


\begin{table*}[htbp]
  \begin{subtable}[t]{0.48\linewidth}
    \centering
    \resizebox{0.8\linewidth}{!}{\centering
      \begin{tabular}{c}
        \toprule
         \\
        \midrule
        Linear                                           \\         \midrule
        ResBlock up                                                     \\         \midrule
        ResBlock up                                                      \\         \midrule
        ResBlock up                                                       \\         \midrule
        ResBlock up                                                       \\         \midrule
        Non-local Block  ()                                                      \\         \midrule
        ResBlock up                                                       \\         \midrule
        ResBlock up                                                        \\         \midrule
        BN, ReLU,  Conv                                            \\         \midrule
        Tanh                                                                                   \\
        \bottomrule
      \end{tabular}}
    \caption{Generator}
  \end{subtable}
  \centering
  \begin{subtable}[t]{0.48\linewidth}
    \centering
    \resizebox{.6\linewidth}{!}{\begin{tabular}{c}
        \toprule
        RGB image  \\ \midrule
        ResBlock down                          \\ \midrule
        ResBlock down                        \\ \midrule
        Non-local Block ()                         \\ \midrule
        ResBlock down                       \\ \midrule
        ResBlock down                       \\ \midrule
        ResBlock down                       \\ \midrule
        ResBlock down                      \\ \midrule
        ResBlock                          \\ \midrule
        ReLU, global sum pooling                                 \\ \midrule
        Linear                                 \\
        \bottomrule
      \end{tabular}}
    \caption{Discriminator}
  \end{subtable}
  \caption{Omni-GAN architecture on Imagenet .  is set to be .}
  \label{apx:tab:omnigan_imagenet256}
\end{table*}


\begin{table*}[htbp]
  \begin{subtable}[t]{0.48\linewidth}
    \centering
    \resizebox{0.8\linewidth}{!}{\centering
      \begin{tabular}{c}
        \toprule
         \\
        \midrule
        Linear                                           \\         \midrule
        ResBlock up                                                     \\         \midrule
        ResBlock up                                                      \\         \midrule
        ResBlock up                                                       \\         \midrule
        ResBlock up                                                       \\         \midrule
        Non-local Block  ()                                                      \\         \midrule
        ResBlock up                                                        \\         \midrule
        Unfold(kernel\_size=3)                                             \\         \midrule
        Grid\_sample(), Concat feature and                                       \\         \midrule
        Linear, Relu                                                   \\         \midrule
        Linear, Relu                                                        \\         \midrule
        Linear                                                               \\         \midrule
        Tanh                                                                                   \\
        \bottomrule
      \end{tabular}}
    \caption{Generator}
  \end{subtable}
  \centering
  \begin{subtable}[t]{0.48\linewidth}
    \centering
    \resizebox{.6\linewidth}{!}{\begin{tabular}{c}
        \toprule
        RGB image  \\ \midrule
        ResBlock down                          \\ \midrule
        ResBlock down                        \\ \midrule
        ResBlock down                       \\ \midrule
        ResBlock down                       \\ \midrule
        ResBlock down                      \\ \midrule
        ResBlock                          \\ \midrule
        ReLU, global sum pooling                                 \\ \midrule
        Linear                                 \\
        \bottomrule
      \end{tabular}}
    \caption{Discriminator}
  \end{subtable}
  \caption{Omni-INR-GAN architecture on ImageNet .  is set to be .}
  \label{apx:tab:omniinrgan_imagenet128}
\end{table*}


\begin{table*}[htbp]
  \begin{subtable}[t]{0.48\linewidth}
    \centering
    \resizebox{0.8\linewidth}{!}{\centering
      \begin{tabular}{c}
        \toprule
         \\
        \midrule
        Linear                                           \\         \midrule
        ResBlock up                                                     \\         \midrule
        ResBlock up                                                      \\         \midrule
        ResBlock up                                                       \\         \midrule
        ResBlock up                                                       \\         \midrule
        Non-local Block  ()                                                      \\         \midrule
        ResBlock up                                                       \\         \midrule
        ResBlock up                                                        \\         \midrule
        Unfold(kernel\_size=3)                                             \\         \midrule
        Grid\_sample(), Concat feature and                                       \\         \midrule
        Linear, Relu                                                   \\         \midrule
        Linear, Relu                                                        \\         \midrule
        Linear                                                               \\         \midrule
        Tanh                                                                                   \\
        \bottomrule
      \end{tabular}}
    \caption{Generator}
  \end{subtable}
  \centering
  \begin{subtable}[t]{0.48\linewidth}
    \centering
    \resizebox{.6\linewidth}{!}{\begin{tabular}{c}
        \toprule
        RGB image  \\ \midrule
        ResBlock down                          \\ \midrule
        ResBlock down                        \\ \midrule
        ResBlock down                       \\ \midrule
        ResBlock down                       \\ \midrule
        ResBlock down                       \\ \midrule
        ResBlock down                      \\ \midrule
        ResBlock                          \\ \midrule
        ReLU, global sum pooling                                 \\ \midrule
        Linear                                 \\
        \bottomrule
      \end{tabular}}
    \caption{Discriminator}
  \end{subtable}
  \caption{Omni-INR-GAN architecture on Imagenet .  is set to be .}
  \label{apx:tab:omniinrgan_imagenet256}
\end{table*}





\section{Additional Results}

\subsection{Generated Images on CIFAR}

In Fig.~\ref{apx:fig:cifar10} and \ref{apx:fig:cifar100}, we show generated images from Omni-GAN on CIFAR10, CIFAR100 respectively. Due to limited space, we only show images of some categories on CIFAR100.

\begin{figure}[t]
  \centering
\includegraphics[width=\linewidth]{figures/save_generated_images_cifar10/cifar10.png}
\caption{Randomly generated image by Omni-GAN for CIFAR10}
  \label{apx:fig:cifar10}
\end{figure}

\begin{figure}[t]
  \centering
\includegraphics[width=\linewidth]{figures/save_generated_images_cifar100/cifar100.png}
\caption{Randomly generated image by Omni-GAN for CIFAR100}
  \label{apx:fig:cifar100}
\end{figure}





\subsection{Generated Images on ImageNet}

Omni-INR-GAN inherently supports generating images of arbitrary resolution. We adopt the Omni-INR-GAN  model to generate some images with different resolutions, \eg, Fig.~\ref{apx:fig:omniinrgan_sample_c1}, ~\ref{apx:fig:omniinrgan_sample_c10}, etc.



\begin{figure*}[t]
  \footnotesize
  \centering
  \renewcommand{\tabcolsep}{1pt} \renewcommand{\arraystretch}{0.8}
  \graphicspath{{figures/results/OmniINGAN_samples/class_0001_20210324_113415_932/}}
  \resizebox{0.7\linewidth}{!}{\begin{tabular}{cccc}
\includegraphics[width=0.25\linewidth]{0032.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0064.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0128.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0256.jpg}                                                                                             \\
                                                              &                          &  &  \\
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{0512.jpg}} &
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{1024.jpg}}                                                                          \\
      \multicolumn{2}{c}{}                                  & \multicolumn{2}{c}{}
    \end{tabular}
  }
  \vspace{-5pt}
  \caption{Samples generated by our Omni-INR-GAN  model. Omni-INR-GAN has the ability to generate images of any resolution.}
  \label{apx:fig:omniinrgan_sample_c1}
  \vspace{-5pt}
\end{figure*}



\begin{figure*}[t]
  \footnotesize
  \centering
  \renewcommand{\tabcolsep}{1pt} \renewcommand{\arraystretch}{0.8}
  \graphicspath{{figures/results/OmniINGAN_samples/class_0010_20210324_114434_254/}}
  \resizebox{0.7\linewidth}{!}{\begin{tabular}{cccc}
\includegraphics[width=0.25\linewidth]{0032.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0064.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0128.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0256.jpg}                                                                                             \\
                                                              &                          &  &  \\
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{0512.jpg}} &
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{1024.jpg}}                                                                          \\
      \multicolumn{2}{c}{}                                  & \multicolumn{2}{c}{}
    \end{tabular}
  }
  \vspace{-5pt}
  \caption{Samples generated by our Omni-INR-GAN  model. Omni-INR-GAN has the ability to generate images of any resolution.}
  \label{apx:fig:omniinrgan_sample_c10}
  \vspace{-5pt}
\end{figure*}

\begin{figure*}[t]
  \footnotesize
  \centering
  \renewcommand{\tabcolsep}{1pt} \renewcommand{\arraystretch}{0.8}
  \graphicspath{{figures/results/OmniINGAN_samples/class_0011_20210324_114622_559/}}
  \resizebox{0.7\linewidth}{!}{\begin{tabular}{cccc}
\includegraphics[width=0.25\linewidth]{0032.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0064.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0128.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0256.jpg}                                                                                             \\
                                                              &                          &  &  \\
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{0512.jpg}} &
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{1024.jpg}}                                                                          \\
      \multicolumn{2}{c}{}                                  & \multicolumn{2}{c}{}
    \end{tabular}
  }
  \vspace{-5pt}
  \caption{Samples generated by our Omni-INR-GAN  model. Omni-INR-GAN has the ability to generate images of any resolution.}
\vspace{-5pt}
\end{figure*}


\begin{figure*}[t]
  \footnotesize
  \centering
  \renewcommand{\tabcolsep}{1pt} \renewcommand{\arraystretch}{0.8}
  \graphicspath{{figures/results/OmniINGAN_samples/class_0014_20210324_114836_556/}}
  \resizebox{0.7\linewidth}{!}{\begin{tabular}{cccc}
\includegraphics[width=0.25\linewidth]{0032.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0064.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0128.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0256.jpg}                                                                                             \\
                                                              &                          &  &  \\
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{0512.jpg}} &
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{1024.jpg}}                                                                          \\
      \multicolumn{2}{c}{}                                  & \multicolumn{2}{c}{}
    \end{tabular}
  }
  \vspace{-5pt}
  \caption{Samples generated by our Omni-INR-GAN  model. Omni-INR-GAN has the ability to generate images of any resolution.}
\vspace{-5pt}
\end{figure*}


\begin{figure*}[t]
  \footnotesize
  \centering
  \renewcommand{\tabcolsep}{1pt} \renewcommand{\arraystretch}{0.8}
  \graphicspath{{figures/results/OmniINGAN_samples/class_0143_20210324_142740_544/}}
  \resizebox{0.7\linewidth}{!}{\begin{tabular}{cccc}
\includegraphics[width=0.25\linewidth]{0032.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0064.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0128.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0256.jpg}                                                                                             \\
                                                              &                          &  &  \\
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{0512.jpg}} &
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{1024.jpg}}                                                                          \\
      \multicolumn{2}{c}{}                                  & \multicolumn{2}{c}{}
    \end{tabular}
  }
  \vspace{-5pt}
  \caption{Samples generated by our Omni-INR-GAN  model. Omni-INR-GAN has the ability to generate images of any resolution.}
\vspace{-5pt}
\end{figure*}


\begin{figure*}[t]
  \footnotesize
  \centering
  \renewcommand{\tabcolsep}{1pt} \renewcommand{\arraystretch}{0.8}
  \graphicspath{{figures/results/OmniINGAN_samples/class_0153_20210324_131040_858/}}
  \resizebox{0.7\linewidth}{!}{\begin{tabular}{cccc}
\includegraphics[width=0.25\linewidth]{0032.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0064.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0128.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0256.jpg}                                                                                             \\
                                                              &                          &  &  \\
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{0512.jpg}} &
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{1024.jpg}}                                                                          \\
      \multicolumn{2}{c}{}                                  & \multicolumn{2}{c}{}
    \end{tabular}
  }
  \vspace{-5pt}
  \caption{Samples generated by our Omni-INR-GAN  model. Omni-INR-GAN has the ability to generate images of any resolution.}
\vspace{-5pt}
\end{figure*}


\begin{figure*}[t]
  \footnotesize
  \centering
  \renewcommand{\tabcolsep}{1pt} \renewcommand{\arraystretch}{0.8}
  \graphicspath{{figures/results/OmniINGAN_samples/class_0156_20210324_131419_171/}}
  \resizebox{0.7\linewidth}{!}{\begin{tabular}{cccc}
\includegraphics[width=0.25\linewidth]{0032.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0064.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0128.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0256.jpg}                                                                                             \\
                                                              &                          &  &  \\
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{0512.jpg}} &
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{1024.jpg}}                                                                          \\
      \multicolumn{2}{c}{}                                  & \multicolumn{2}{c}{}
    \end{tabular}
  }
  \vspace{-5pt}
  \caption{Samples generated by our Omni-INR-GAN  model. Omni-INR-GAN has the ability to generate images of any resolution.}
\vspace{-5pt}
\end{figure*}


\begin{figure*}[t]
  \footnotesize
  \centering
  \renewcommand{\tabcolsep}{1pt} \renewcommand{\arraystretch}{0.8}
  \graphicspath{{figures/results/OmniINGAN_samples/class_0278_20210324_132057_656/}}
  \resizebox{0.7\linewidth}{!}{\begin{tabular}{cccc}
\includegraphics[width=0.25\linewidth]{0032.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0064.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0128.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0256.jpg}                                                                                             \\
                                                              &                          &  &  \\
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{0512.jpg}} &
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{1024.jpg}}                                                                          \\
      \multicolumn{2}{c}{}                                  & \multicolumn{2}{c}{}
    \end{tabular}
  }
  \vspace{-5pt}
  \caption{Samples generated by our Omni-INR-GAN  model. Omni-INR-GAN has the ability to generate images of any resolution.}
\vspace{-5pt}
\end{figure*}


\begin{figure*}[t]
  \footnotesize
  \centering
  \renewcommand{\tabcolsep}{1pt} \renewcommand{\arraystretch}{0.8}
  \graphicspath{{figures/results/OmniINGAN_samples/class_0323_20210324_132407_993/}}
  \resizebox{0.7\linewidth}{!}{\begin{tabular}{cccc}
\includegraphics[width=0.25\linewidth]{0032.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0064.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0128.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0256.jpg}                                                                                             \\
                                                              &                          &  &  \\
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{0512.jpg}} &
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{1024.jpg}}                                                                          \\
      \multicolumn{2}{c}{}                                  & \multicolumn{2}{c}{}
    \end{tabular}
  }
  \vspace{-5pt}
  \caption{Samples generated by our Omni-INR-GAN  model. Omni-INR-GAN has the ability to generate images of any resolution.}
\vspace{-5pt}
\end{figure*}


\begin{figure*}[t]
  \footnotesize
  \centering
  \renewcommand{\tabcolsep}{1pt} \renewcommand{\arraystretch}{0.8}
  \graphicspath{{figures/results/OmniINGAN_samples/class_0326_20210324_132706_954/}}
  \resizebox{0.7\linewidth}{!}{\begin{tabular}{cccc}
\includegraphics[width=0.25\linewidth]{0032.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0064.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0128.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0256.jpg}                                                                                             \\
                                                              &                          &  &  \\
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{0512.jpg}} &
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{1024.jpg}}                                                                          \\
      \multicolumn{2}{c}{}                                  & \multicolumn{2}{c}{}
    \end{tabular}
  }
  \vspace{-5pt}
  \caption{Samples generated by our Omni-INR-GAN  model. Omni-INR-GAN has the ability to generate images of any resolution.}
\vspace{-5pt}
\end{figure*}


\begin{figure*}[t]
  \footnotesize
  \centering
  \renewcommand{\tabcolsep}{1pt} \renewcommand{\arraystretch}{0.8}
  \graphicspath{{figures/results/OmniINGAN_samples/class_0331_20210324_133147_310/}}
  \resizebox{0.7\linewidth}{!}{\begin{tabular}{cccc}
\includegraphics[width=0.25\linewidth]{0032.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0064.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0128.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0256.jpg}                                                                                             \\
                                                              &                          &  &  \\
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{0512.jpg}} &
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{1024.jpg}}                                                                          \\
      \multicolumn{2}{c}{}                                  & \multicolumn{2}{c}{}
    \end{tabular}
  }
  \vspace{-5pt}
  \caption{Samples generated by our Omni-INR-GAN  model. Omni-INR-GAN has the ability to generate images of any resolution.}
\vspace{-5pt}
\end{figure*}


\begin{figure*}[t]
  \footnotesize
  \centering
  \renewcommand{\tabcolsep}{1pt} \renewcommand{\arraystretch}{0.8}
  \graphicspath{{figures/results/OmniINGAN_samples/class_0358_20210324_133427_825/}}
  \resizebox{0.7\linewidth}{!}{\begin{tabular}{cccc}
\includegraphics[width=0.25\linewidth]{0032.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0064.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0128.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0256.jpg}                                                                                             \\
                                                              &                          &  &  \\
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{0512.jpg}} &
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{1024.jpg}}                                                                          \\
      \multicolumn{2}{c}{}                                  & \multicolumn{2}{c}{}
    \end{tabular}
  }
  \vspace{-5pt}
  \caption{Samples generated by our Omni-INR-GAN  model. Omni-INR-GAN has the ability to generate images of any resolution.}
\vspace{-5pt}
\end{figure*}



\begin{figure*}[t]
  \footnotesize
  \centering
  \renewcommand{\tabcolsep}{1pt} \renewcommand{\arraystretch}{0.8}
  \graphicspath{{figures/results/OmniINGAN_samples/class_0425_20210324_140054_456/}}
  \resizebox{0.7\linewidth}{!}{\begin{tabular}{cccc}
\includegraphics[width=0.25\linewidth]{0032.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0064.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0128.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0256.jpg}                                                                                             \\
                                                              &                          &  &  \\
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{0512.jpg}} &
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{1024.jpg}}                                                                          \\
      \multicolumn{2}{c}{}                                  & \multicolumn{2}{c}{}
    \end{tabular}
  }
  \vspace{-5pt}
  \caption{Samples generated by our Omni-INR-GAN  model. Omni-INR-GAN has the ability to generate images of any resolution.}
\vspace{-5pt}
\end{figure*}


\begin{figure*}[t]
  \footnotesize
  \centering
  \renewcommand{\tabcolsep}{1pt} \renewcommand{\arraystretch}{0.8}
  \graphicspath{{figures/results/OmniINGAN_samples/class_0449_20210324_140507_216/}}
  \resizebox{0.7\linewidth}{!}{\begin{tabular}{cccc}
\includegraphics[width=0.25\linewidth]{0032.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0064.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0128.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0256.jpg}                                                                                             \\
                                                              &                          &  &  \\
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{0512.jpg}} &
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{1024.jpg}}                                                                          \\
      \multicolumn{2}{c}{}                                  & \multicolumn{2}{c}{}
    \end{tabular}
  }
  \vspace{-5pt}
  \caption{Samples generated by our Omni-INR-GAN  model. Omni-INR-GAN has the ability to generate images of any resolution.}
\vspace{-5pt}
\end{figure*}


\begin{figure*}[t]
  \footnotesize
  \centering
  \renewcommand{\tabcolsep}{1pt} \renewcommand{\arraystretch}{0.8}
  \graphicspath{{figures/results/OmniINGAN_samples/class_0946_20210324_141318_570/}}
  \resizebox{0.7\linewidth}{!}{\begin{tabular}{cccc}
\includegraphics[width=0.25\linewidth]{0032.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0064.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0128.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0256.jpg}                                                                                             \\
                                                              &                          &  &  \\
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{0512.jpg}} &
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{1024.jpg}}                                                                          \\
      \multicolumn{2}{c}{}                                  & \multicolumn{2}{c}{}
    \end{tabular}
  }
  \vspace{-5pt}
  \caption{Samples generated by our Omni-INR-GAN  model. Omni-INR-GAN has the ability to generate images of any resolution.}
\vspace{-5pt}
\end{figure*}


\begin{figure*}[t]
  \footnotesize
  \centering
  \renewcommand{\tabcolsep}{1pt} \renewcommand{\arraystretch}{0.8}
  \graphicspath{{figures/results/OmniINGAN_samples/class_0970_20210324_141828_735/}}
  \resizebox{0.7\linewidth}{!}{\begin{tabular}{cccc}
\includegraphics[width=0.25\linewidth]{0032.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0064.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0128.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0256.jpg}                                                                                             \\
                                                              &                          &  &  \\
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{0512.jpg}} &
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{1024.jpg}}                                                                          \\
      \multicolumn{2}{c}{}                                  & \multicolumn{2}{c}{}
    \end{tabular}
  }
  \vspace{-5pt}
  \caption{Samples generated by our Omni-INR-GAN  model. Omni-INR-GAN has the ability to generate images of any resolution.}
\vspace{-5pt}
\end{figure*}


\begin{figure*}[t]
  \footnotesize
  \centering
  \renewcommand{\tabcolsep}{1pt} \renewcommand{\arraystretch}{0.8}
  \graphicspath{{figures/results/OmniINGAN_samples/class_0980_20210324_142034_652/}}
  \resizebox{0.7\linewidth}{!}{\begin{tabular}{cccc}
\includegraphics[width=0.25\linewidth]{0032.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0064.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0128.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0256.jpg}                                                                                             \\
                                                              &                          &  &  \\
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{0512.jpg}} &
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{1024.jpg}}                                                                          \\
      \multicolumn{2}{c}{}                                  & \multicolumn{2}{c}{}
    \end{tabular}
  }
  \vspace{-5pt}
  \caption{Samples generated by our Omni-INR-GAN  model. Omni-INR-GAN has the ability to generate images of any resolution.}
\vspace{-5pt}
\end{figure*}


\begin{figure*}[t]
  \footnotesize
  \centering
  \renewcommand{\tabcolsep}{1pt} \renewcommand{\arraystretch}{0.8}
  \graphicspath{{figures/results/OmniINGAN_samples/class_0985_20210324_142348_264/}}
  \resizebox{0.7\linewidth}{!}{\begin{tabular}{cccc}
\includegraphics[width=0.25\linewidth]{0032.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0064.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0128.jpg}                    &
      \includegraphics[width=0.25\linewidth]{0256.jpg}                                                                                             \\
                                                              &                          &  &  \\
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{0512.jpg}} &
      \multicolumn{2}{c}{\includegraphics[width=0.5\linewidth]{1024.jpg}}                                                                          \\
      \multicolumn{2}{c}{}                                  & \multicolumn{2}{c}{}
    \end{tabular}
  }
  \vspace{-5pt}
  \caption{Samples generated by our Omni-INR-GAN  model. Omni-INR-GAN has the ability to generate images of any resolution.}
\vspace{-5pt}
\end{figure*}


\begin{figure*}[!t]
  \footnotesize
  \centering
  \renewcommand{\tabcolsep}{1pt} \renewcommand{\arraystretch}{0.4}
  \centering
  \resizebox{\linewidth}{!}{\centering
    \begin{tabular}{cc|ccc}
\includegraphics[width=.19\linewidth]{figures/DGP_SR/val_1955/OmniINRGAN/ILSVRC2012_val_00001955_target_origin.png}                         &
      \includegraphics[width=.19\linewidth]{figures/DGP_SR/val_1955/OmniINRGAN/ILSVRC2012_val_00001955_target_input.png}          \hspace{0.01cm} &
      \hspace{0.01cm}
      \includegraphics[width=.19\linewidth]{figures/DGP_SR/val_1955/liif/ILSVRC2012_val_00001955_target_input_x1_hw_32x42.jpg}                    &
      \includegraphics[width=.19\linewidth]{figures/DGP_SR/val_1955/liif/ILSVRC2012_val_00001955_target_input_x4.6_hw_147x193.jpg}                &
      \includegraphics[width=.19\linewidth]{figures/DGP_SR/val_1955/liif/ILSVRC2012_val_00001955_target_input_x63.5_hw_2032x2667.jpg}
      \\
      Size ()                                                                                                                       & Size ()          &  ()                          &  () &  ()
      \\
      (a) Ground truth                                                                                                                            & (b) Input                    & \multicolumn{3}{c}{(c) LIIF}
      \\ \midrule
\includegraphics[width=.19\linewidth]{figures/DGP_SR/val_1955/dip/ILSVRC2012_val_00001955_target_origin_factor_8.jpg}                       &
      \includegraphics[height=2.51cm]{figures/DGP_SR/val_1955/BigGAN/00999.png}                                                                   &
      \hspace{0.01cm}
      \includegraphics[width=.19\linewidth]{figures/DGP_SR/val_1955/OmniINRGAN/000000_hw_32_42_r_1.0.png}                                         &
      \includegraphics[width=.19\linewidth]{figures/DGP_SR/val_1955/OmniINRGAN/000072_hw_147_193_r_4.6.png}                                       &
      \includegraphics[width=.19\linewidth]{figures/DGP_SR/val_1955/OmniINRGAN/000395_hw_2032_2667_r_63.5.png}
      \\
       ()                                                                                                                &  () &  ()                          &  () &  ()
      \\
      (d) DIP                                                                                                                                     & (e) DGP w/ BigGAN            & \multicolumn{3}{c}{(f) DGP w/ Omni-INR-GAN (ours)}                                                                    \\
      \midrule
    \end{tabular}
  }
  \vspace{-0.3cm}
  \caption{Super-resolution using Omni-INR-GAN's prior, at any scale (-). (b) input image with low resolution. (c) LIIF~\cite{chen2020Learning} can extrapolate the input image to any scale, but it cannot add semantic details, so the result is still blurred. (d) DIP~\cite{ulyanov2018Deep} also failed because the input image resolution is too low. (e) DGP~\cite{pan2020Exploiting} with BigGAN must crop the input and upsamples the cropped patch to a fixed size, which is inflexible. (f) Omni-INR-GAN has the ability to upsample the input image to any scale and also adds rich semantic details.}
\label{apx:fig:dgp_SR}
  \vspace{-.5cm}
\end{figure*}


\subsection{Results of Semantic Image Synthesis}

In Fig.~\ref{apx:fig:cityscapes}, we show several results of Omni-GAN as well as those of SPADE for semantic image synthesis. The label maps and the ground truth images are from the first ten items in the test set of Cityscapes dataset, without cherry-picking.

\begin{figure*}[htbp]
  \footnotesize
  \centering
  \renewcommand{\tabcolsep}{1pt} \renewcommand{\arraystretch}{0.4}
  \begin{tabular}{cccc}
    Label                                                                                                                                & Ground Truth                                                                                                                & SPADE                                                                                                                                      & Ours                                                                                                                                          \\
\includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/input_label/000.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/gt/000.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/synthesized_image/000.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_omni_GAN/spade/cityscapes_pretrained/test_latest/images/synthesized_image/000.png} \\
    \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/input_label/001.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/gt/001.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/synthesized_image/001.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_omni_GAN/spade/cityscapes_pretrained/test_latest/images/synthesized_image/001.png} \\
    \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/input_label/002.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/gt/002.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/synthesized_image/002.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_omni_GAN/spade/cityscapes_pretrained/test_latest/images/synthesized_image/002.png} \\
    \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/input_label/003.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/gt/003.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/synthesized_image/003.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_omni_GAN/spade/cityscapes_pretrained/test_latest/images/synthesized_image/003.png} \\
    \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/input_label/004.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/gt/004.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/synthesized_image/004.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_omni_GAN/spade/cityscapes_pretrained/test_latest/images/synthesized_image/004.png} \\
    \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/input_label/005.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/gt/005.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/synthesized_image/005.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_omni_GAN/spade/cityscapes_pretrained/test_latest/images/synthesized_image/005.png} \\
    \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/input_label/006.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/gt/006.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/synthesized_image/006.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_omni_GAN/spade/cityscapes_pretrained/test_latest/images/synthesized_image/006.png} \\
    \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/input_label/007.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/gt/007.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/synthesized_image/007.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_omni_GAN/spade/cityscapes_pretrained/test_latest/images/synthesized_image/007.png} \\
    \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/input_label/008.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/gt/008.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/synthesized_image/008.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_omni_GAN/spade/cityscapes_pretrained/test_latest/images/synthesized_image/008.png} \\
    \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/input_label/009.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/gt/009.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_spade/spade/cityscapes_pretrained/test_latest/images/synthesized_image/009.png} & \includegraphics[width=0.23\linewidth]{figures/save_images_omni_GAN/spade/cityscapes_pretrained/test_latest/images/synthesized_image/009.png} \\
\end{tabular}
\caption{Results of semantic image synthesis on Cityscapes.}
  \label{apx:fig:cityscapes}
  \vspace{-5pt}
\end{figure*}

\clearpage

\end{document}