\documentclass{llncs}
\usepackage{mathptmx}
\usepackage{latexsym}
\usepackage{times}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{color,graphicx,subfig}
\usepackage{epic}
\usepackage{fancybox,graphpap}
\usepackage{pb-diagram,pb-xy}
\usepackage[all]{xy}
\usepackage{bbm}
\usepackage{array}
\usepackage{algorithmic}
\usepackage{hyperref}

\begin{document}



\newcommand{\END}{\qed}
\newcommand{\LT}{\mathcal{L}}
\newcommand{\eqa}{\thickapprox}
\newcommand{\eqb}{\equiv}
\newcommand{\PS}[1]{\wp(#1)}
\newcommand{\PSB}[1]{\wp^{\setminus \set{\emptyset}}(#1)}

\newcommand{\h}[1]{\overline{#1}}
\newcommand{\set}[1]{\{#1\}}
\newcommand{\bset}[1]{\bigl\{#1\bigr\}}
\newcommand{\Bset}[1]{\Bigl\{#1\Bigr\}}
\newcommand{\Al}{\biguplus}
\newcommand{\RC}{\div_R}
\newcommand{\LC}{\div_L}
\newcommand{\wei}{\textit{weight}}
\newcommand{\LG}[1]{\langle #1 \rangle}
\newcommand{\E}{\mathbb{S}}
\newcommand{\EC}{\widehat{\mathcal{S}}}
\newcommand{\PO}{\prec}
\newcommand{\st}{\mathsf{st}}
\newcommand{\com}{<\!\!>}
\newcommand{\df}{\triangleq}
\newcommand{\iffdf}{\stackrel{\textit{\scriptsize{df}}}{\iff}\ }
\newcommand{\calf}[1]{\mathcal{#1}}
\newcommand{\sq}{\sqsubset}
\newcommand{\ccl}{\;\bowtie}
\newcommand{\todo}[1]{ \textcolor{red}{TODO: #1}}
\newcommand{\tcomment}[1]{\text{\hspace*{2mm}~\parbox[t]{\textwidth}{ #1 }}}
\newcommand{\ttcomment}[1]{\text{~#1~}}
\newcommand{\sym}[1]{{#1}^{\mathsf{sym}\;}}
\newcommand{\imm}[1]{{#1}^{\mathsf{cov}\;}}


\newcommand{\TR}{\mathsf{TR}}
\newcommand{\LCT}{\mathsf{LCT}}
\newcommand{\DCD}{\mathsf{CDG}}
\newcommand{\andspace}{\hspace*{3mm}\text{ and }\hspace*{3mm}}
\newcommand{\myspace}[1]{\mbox{\hspace{#1cm}}}
\newcommand{\map}{\mathsf{map}}
\newcommand{\bt}{\mathsf{bt}}
\newcommand{\cl}{\mathsf{ct2lct}}
\newcommand{\lc}{\mathsf{lct2ct}}
\newcommand{\cd}{\mathsf{ct2dep}}
\newcommand{\dl}{\mathsf{dep2lct}}
\newcommand{\ld}{\mathsf{lct2dep}}


\newcommand{\lhdf}{\lhd^\frown}
\newcommand{\flhd}{\frown_\lhd}
\newcommand{\lex}[1]{\,{#1}^{\textit{lex}}\,}
\newcommand{\optord}{\,<^{\textit{opt}}\,}
\newcommand{\stor}[1]{\,{#1}^{\textit{st}}\,}
\newcommand{\reco}[1]{ {#1}^{\,{\textsf{C}}} }
\newcommand{\si}[1]{(#1)^\Cap}
\newcommand{\CT}[1]{\mathfrak{C}(#1)}
\newcommand{\GCT}[1]{\mathfrak{gC}(#1)}
\newcommand{\eqrel}[1]{\equiv_{#1}}
\newcommand{\quotient}[2]{{#1}/\!{#2}}
\newcommand{\FEC}{\mathbb{C}\mathit{at}_{\mathsf{FE}}}
\newcommand{\cau}{\longrightarrow}
\newcommand{\wcau}{\dashrightarrow}
\newcommand{\bcau}{\rightsquigarrow}

\newcommand{\seq}[1]{\left[   #1 \right] }

\newcommand{\It}[1]{\mathit{#1}}
\newcommand{\defref}[1]{Definition~\ref{def:#1}}
\newcommand{\theoref}[1]{Theorem~\ref{theo:#1}}
\newcommand{\propref}[1]{Proposition~\ref{prop:#1}}
\newcommand{\corref}[1]{Corollary~\ref{cor:#1}}
\newcommand{\lemref}[1]{Lemma~\ref{lem:#1}}
\newcommand{\exref}[1]{Example~\ref{ex:#1}}
\newcommand{\reref}[1]{Remark~\ref{re:#1}}
\newcommand{\eref}[1]{\eqref{eq:#1}}
\newcommand{\figref}[1]{Figure~\ref{fig:#1}}

\newcommand{\secref}[1]{Section~\ref{sec:#1}}
\newcommand{\eqnref}[1]{Eq.~(\ref{eq:#1})}
\newcommand{\TCT}{\stackrel{\mathsf{t}\leftrightsquigarrow \mathsf{c}}{\equiv}}



\newcommand{\EOD}{\hfill {\scriptsize }}




\numberwithin{equation}{section}

\title{A Characterization of Combined Traces Using  Labeled Stratified Order Structures}

\author{Dai Tri Man L\^e}
\institute{Department of Computer Science, University of Toronto\\
10 King's College Road, Toronto, ON, M5S 3G4 Canada\\
\email{ledt@cs.toronto.edu}}



\maketitle
\pagestyle{headings} 
\begin{abstract}
This paper defines a class of labeled stratified order structures that characterizes exactly the notion of \emph{com}bined \emph{traces} (i.e., \emph{comtraces}) proposed by Janicki and Koutny in 1995. Our main technical contributions are the representation theorems showing that comtrace quotient monoid,  \emph{combined dependency graph} (Kleijn and Koutny 2008) and our labeled stratified order structure characterization are three different and yet equivalent ways to represent comtraces.\\
\textbf{Keywords. } causality theory of concurrency, combined traces monoids, step sequences, stratified order structures, label-preserving isomorphism.
\end{abstract}



\section{Introduction}
Partial orders are a principle tool for modelling ``true concurrency'' semantics of concurrent systems (cf. \cite{Pra}). They are utilized to develop powerful partial-order based automatic verification techniques, e.g.,  \emph{partial order reduction} for model checking concurrent software (see, e.g., \cite[Chapter 10]{CGP} and \cite{EH}). Partial orders are also equipped with \emph{traces}, their powerful formal language counterpart,  proposed by Mazurkiewicz \cite{Ma1}. In  \emph{The Book of Traces} \cite{DR}, trace theory has been used to tackle problems from diverse areas including formal language theory, combinatorics, graph theory, algebra, logic, and \emph{concurrency theory}.


However, while partial orders and traces can sufficiently model the ``earlier than" relationship, Janicki and Koutny argued that it is problematic to use a single partial order to specify both  the ``earlier than" and  the ``not later than" relationships \cite{J4}. This motivates them to develop the theory of \emph{relational structures}, where a pair of relations is used to capture concurrent behaviors.  The most well-known among the classes of relational structures  proposed by Janicki and Koutny is the class of \emph{stratified order structures} (\emph{so-structures}) \cite{GP,JK0,JK95,JK97,J0}. A so-structure is a triple , where  and  are binary relations on . They were invented to model both the ``earlier than" (the relation ) and ``not later than" (the relation ) relationships, under the assumption that system runs are described by \emph{stratified partial orders}, i.e., step sequences. They have been successfully applied to model inhibitor and priority systems, asynchronous races, synthesis problems, etc. (see for example \cite{JK95,JK99,JLM06,JLM08,KK,KK08} and others). 

The \emph{com}bined \emph{trace} (\emph{comtrace}) notion, introduced by Janicki and Koutny \cite{JK95}, generalizes the trace notion by utilizing step sequences instead of words. First the set of all possible steps that generates step sequences are identified by a relation , which is called {\em simultaneity}. Second a congruence relation is determined by a relation , which is called {\em serializability} and in general \emph{not} symmetric. Then a comtrace is defined as a finite set of congruent step sequences. Comtraces were introduced as a formal language representation of so-structures to provide an operational semantics for  Petri nets with inhibitor arcs. Unfortunately, comtraces have been less often known and applied than so-structures, even though in many cases they appear to be more natural. We believe one  reason is that the comtrace notion was too succinctly discussed in \cite{JK95} without a full treatment dedicated to comtrace theory. Motivated by this, Janicki and the author have devoted our recent effort on the study of comtraces \cite{JL08,Le,JL09}, yet there are too many different aspects to explore and the truth is we can barely scratch the surface. In particular, the huge amount of results from  trace theory (e.g., from \cite{DR,DM}) desperately needs to be generalized to comtraces. These  tasks are often non-trivial since we are required to develop intuition and novel techniques to deal with the complex interactions of the ``earlier than'' and ``not later than'' relations.

This paper gives a novel characterization of comtraces using labeled so-structures. Such definition is interesting for the following reasons. 

First, it defines exactly the class of labeled so-structures that can be represented by comtraces. It is worth noting that this point is particularly important. Even though it was shown in \cite{JK95} that every comtrace can be represented by a labeled so-structure, the converse could not be shown because a class of labeled so-structures that defines precisely the class of  comtraces was not known. The closest to our characterization is  the \emph{combined dependency graph} (\emph{cd-graph}) notion (analogous to \emph{dependence graph} representation of traces) introduced recently by Kleijn and Koutny \cite{KK08}, but again a theorem showing that combined dependency graphs can be represented by comtraces was not given. Our approach is quite different and based on some new ideas discussed in Section 4 of this paper. 

Second, even though the step sequence definition of comtraces is more suitable when dealing with formal language aspects of comtraces, the labeled so-structure representation is more suitable for a variety of powerful order-theoretic results and techniques available to us (cf. \cite{Fis,DP02,J0}). 


Finally, the labeled so-structure definition of comtrace can be easily extended to \emph{infinite comtraces}, which describe nonterminating concurrent processes. The labeled poset representation of infinite traces is already successfully applied in both theory and practice, e.g.,  \cite{TW02,FM06,FM07,GGH09}. Although such definition is equivalent to  the one using quotient monoid over infinite words \cite{Gas90,Die91}, we believe that infinite labeled posets are sometimes simpler. Indeed the celebrated work by Thiagarajan and Walukiewicz (cf. \cite{TW02}) on linear temporal logic for traces utilizes the labeled poset characterization of infinite traces, where \emph{configurations} of a trace are conveniently defined as \emph{finite downward closed subsets} of the labeled poset representation. We will not analyze infinite comtraces or logics for comtraces in this paper, but these are fruitful directions to explore using the results from this paper.


The paper is organized as follows. In Section 2, we recall some preliminary definitions and notations. In Section 3, we give a concise exposition of the theory of so-structures and comtraces by Janicki and  Koutny \cite{JK95,JK97}. In Section 4, we give our definition of comtraces using labeled so-structure and some remarks on how we arrived  at such definition. In Section 5, we prove a representation theorem showing that our comtrace definition and the one by Janicki and Koutny are indeed equivalent; then using this theorem, we prove another representation theorem showing that our definition is also equivalent to the cd-graph definition from \cite{KK08}. In Section 6, we define  \emph{composition} operators for our comtrace representation and for cd-graphs. Finally, in Section 7, some final remarks and future works are presented.


\section{Notations \label{sec:background}}


\subsection{Relations, Orders and Equivalences}

The \emph{powerset} of a set  will be denoted by , i.e.
. The set of all {\em non-empty} subsets of 
will be denoted by . In other words,
 

We let  denote the \emph{identity relation} on a set . If  and  are binary relations on a set  (i.e., ), then their \emph{composition}  is defined as . We also define

The relations  and  are called the \emph{(irreflexive) transitive closure} and \emph{reflexive transitive closure} of  respectively.


A binary relation  is an \emph{equivalence relation} relation on  if and only if (iff)  is {\em reflexive},  {\em symmetric} and {\em transitive}. If  is an equivalence relation, then for every , the set  is the equivalence class of  with respect to . We also define , i.e., the set of all equivalence classes of  under . We drop the subscript and write  when  is clear from the context. 

A binary relation  is a
{\em partial order} iff  is {\em irreflexive} and {\em transitive}.
The pair  in this case is called a \emph{partially ordered set} (\emph{poset}). The pair  is called a \emph{finite poset} if  is finite. For convenience, we define:



A poset  is {\em total} iff  is empty; and {\em stratified} iff  is an equivalence relation. Evidently every total order is stratified.


\subsection{Step Sequences\label{sec:steps}}
For every finite set , a set  can be seen as an alphabet. 
The elements of  are called {\em steps} and
the elements of  are called {\em step sequences}. For example, if the set of possible steps is 
, then
 is a step sequence.
The triple , where  denotes the step sequence concatenation operator (usually omitted) and  denotes the empty step sequence, is a monoid.

Let  be a step sequence. We define  , the number of occurrences of an event  in , as , where  denotes the cardinality of the set .  
Then we can construct its unique \emph{enumerated step sequence}  as\\
\mbox{\hspace{2.5cm}}\\
We will call such  an \emph{event occurrence} of . For instance, if we let  ,
then   

We let  denote the set of all event occurrences in all steps of . For example, when
,  We also define  to be the function that returns the \emph{label} of  for each . For example, if , then . Hence, from an enumerated step sequence , we can uniquely reconstruct its step sequence 


For each , we let  denote the consecutive number of a step where  belongs, i.e., if  then . For our example, ,  , etc.

It is important to observe that step sequences and stratified orders are interchangeable concepts. Given a step sequence , define the binary relation   on  as\\
\mbox{\hspace{3.6cm}}

Intuitively,  simply means  occurs before  on the step sequence . Thus,  iff ; and  iff  . Obviously, the relation  is a stratified order and we will call it the stratified order {\em generated by the step sequence} .


Conversely, let  be a stratified order on a set . The set  can be represented as a
sequence of equivalence classes  () such that 
The sequence  is called the step sequence \emph{representing} . A detailed discussion on this connection between stratified orders and step sequences can be found in \cite{JL09}.







\section{Stratified Order Structures and Combined Traces}
In this section, we review the Janicki -- Koutny theory of stratified order structures and comtraces from \cite{JK95,JK97}. The reader is also referred to \cite{KK08} for an excellent introductory survey on the subject with many motivating examples.

\subsection{Stratified Order Structures}
A \emph{relational structure} is a triple , where  is a set and ,  are binary relations on . A relational structure  is an \emph{extension} of , denoted as , iff ,  and .


\begin{definition}[stratified order structure \cite{JK97}]
A \emph{stratified order structure} (\emph{so-structure}) is a relational structure  such that for all , the following hold:

When  is finite,  is called a \emph{finite so-structure}. \EOD
\label{def:sos}
\end{definition}


The axioms \textsf{S1}--\textsf{S4} imply that  is a partial order and   The axioms \textsf{S1} and \textsf{S3} imply  is a \emph{strict preorder}. The relation  is called \textit{causality} and represents the ``earlier than" relationship while the relation  is called \textit{weak causality} and represents the ``not later than" relationship. The axioms \textsf{S1}--\textsf{S4} model the mutual relationship between ``earlier than" and ``not later than" relations, provided that {\em the system runs are stratified orders}.  Historically, the name ``stratified order structure'' came from the fact that stratified orders can be seen as a special kind of so-structures.



\begin{proposition}[\cite{J4}]
For every stratified poset , the triple  is a so-structure.\END
\label{prop:soss}
\end{proposition}

We next recall the notion of \emph{stratified order extension}. This concept is extremely important  since the relationship between stratified orders and so-structures is exactly analogous to the one between total orders and partial orders.

\begin{definition}[stratified extension \cite{JK97}]
Let  be a so-structure. A {\em stratified} order  on  is a {\em stratified extension} of  if and only if . 

The set of all stratified extensions of   is denoted as  . \EOD
\label{def:extsos}
\end{definition}

Szpilrajn's Theorem \cite{Szp} states that every poset can be reconstructed by taking the intersection of all of its total order extensions. Janicki and Koutny showed that a similar result holds for so-structures and stratified extensions:

\begin{theorem}[{\cite{JK97}}]
Let  be a so-structure. Then\\
\mbox{\hspace{3.5cm}} 
\qed
\label{theo:SzpStrat}
\end{theorem}

Using this theorem, we can show the following properties relating so-structures and their stratified extensions.
\begin{corollary}
For every so-structure ,
\begin{enumerate}
 \item 
 \item 
\end{enumerate}
\label{cor:SzpStrat}
\end{corollary}
\begin{proof}\textbf{1. } See \cite[Theorem 3.6]{JK97}. \textbf{2. } Follows from \textbf{1.} and \theoref{SzpStrat}. \qed


\end{proof}


\subsection{Combined Traces}

{\em Comtraces} were introduced in \cite{JK95} as a generalization of traces to represent so-structures. The \emph{comtrace congruence} is defined via two relations {\em simultaneity} and {\em serializability}.

\begin{definition}[comtrace alphabet \cite{JK95}] Let  be a finite set (of events) and let  be two relations called \emph{serializability} and \emph{simultaneity} respectively and the relation  is irreflexive and symmetric. The triple  is called a \emph{comtrace alphabet}. \EOD
\label{def:comalpha}
\end{definition}

Intuitively, if  then  and  can occur simultaneously
(or be a part of a {\em synchronous} occurrence in the sense of \cite{JLM06}),
while  means that  and  may occur simultaneously
or  may occur before . We define , the set of all possible {\em steps},
 to be the set of all cliques of
the graph , i.e.,\\


\begin{definition}[comtrace congruence \cite{JK95}]
For a comtrace alphabet , we define  to be the relation comprising all pairs  of step sequences such that \smallskip\\
\myspace{4.3}\smallskip\\
where  and , ,  are steps satisfying  and . 

We define \emph{comtrace congruence} . We define the comtrace concatenation operator  as . The quotient monoid  is called the monoid of {\em comtraces} over . \EOD
\label{def:commonoid}
\end{definition}

Note that since  is irreflexive,  implies that . We will omit the subscript  from the comtrace congruence , and write  and  when it causes no ambiguity. To shorten our notations, we often write  or  instead of  to denote the comtrace generated by the step sequence  over .

\begin{example}
Let  where ,  and  are three atomic operations, where\smallskip\\
\myspace{2}\smallskip\\
Assume simultaneous reading is allowed. Then only  and  can be performed simultaneously, and the simultaneous execution of  and  gives the same outcome as executing  followed by .
 We can then define the comtrace alphabet , where
 and . This yields .
Thus,  is a comtrace.
But . \EOD
\label{ex:comtrace1}
\end{example}

Even though traces are quotient monoids over sequences and comtraces are
quotient monoids over step sequences, traces can be regarded as special kinds
of comtraces when the relation . For a more detailed discussion on this connection between traces and comtraces, the reader is referred to \cite{JL09}.

\begin{definition}[\cite{JK95}]
Let . We define the relations 
as:
\begin{enumerate}
\item


\item
. \EOD
\end{enumerate}

\label{def:s2inv}
\end{definition}

It is worth noting that the structure  is exactly the \emph{cd-graph} (cf. \defref{comdag}) that represents the comtrace . This gives us some intuition on how Koutny and Kleijn constructed the cd-graph definition in \cite{KK08}. We  also observe that  is usually \emph{not} a so-structure since  and  describe only basic ``local'' causality and weak causality invariants of the event occurrences of  by considering pairwise serializable relationships of event occurrences. Hence,  and  might not capture ``global'' invariants that can be inferred from \textsf{S2}--\textsf{S4} of \defref{sos}. To ensure  all invariants are included, we need the following -closure operator. 

\begin{definition}[\cite{JK95}]
For every relational structure  we define  as\smallskip\\
\mbox{\hspace{2cm}} \EOD
\label{def:SO-CL}
\end{definition}


Intuitively -closure is a generalization of transitive closure for relations to relational structures. The motivation is that for appropriate  relations  and  (see assertion (3) of \propref{so-cl}), the relational structure  is a so-structure. The -closure operator satisfies the following properties:

\begin{proposition}[\cite{JK95}]
Let  be a relational structure.
\begin{enumerate}
\item If  is irreflexive then .
\item .
\item  is a so-structure if and only if 

is irreflexive.
\item If  is a so-structure then .
\item If  be a so-structure and , then  and  is a so-structure. \hspace{-5mm}
\END
\end{enumerate}
\label{prop:so-cl}
\end{proposition}


\begin{definition}
Given a step sequence   and its respective comtrace , we define the relational structures  as: \\
\mbox{\hspace{3.5cm}}.\EOD
\label{def:s2sos}
\end{definition}

The relational structure  is called the \emph{so-structure defined by the comtrace} , where ,   and  are used to denote the event occurrence set, causality relation and weak causality relation induced by the comtrace  respectively.  The following nontrivial theorem and its corollary justifies the name by showing that  step sequences in a comtrace  are exactly stratified extension of the so-structure , and that  is uniquely defined for the comtrace  regardless of the choice of . 

\begin{theorem}[\cite{JK95}]
For each , the relational structure  is a so-structure and . \END
\label{theo:com2sos}
\end{theorem}

\begin{corollary} For all ,
\begin{enumerate}
\item 
\item  
\qed
\end{enumerate}
\label{cor:com2sos}
\end{corollary}



\section{Comtraces as Labeled Stratified Order Structures \label{sec:lsos-comtrace}}
Even though \theoref{com2sos} shows that each comtrace can be represented uniquely by a labeled so-structure, it does not give us an explicit definition of how these labeled so-structures look like. In this section, we will give an exact definition of labeled so-structures that represent comtraces. To provide us with more intuition, we first recall how Mazurkiewicz traces can be characterized as labeled posets.

A \emph{trace concurrent alphabet}  is  a pair , where
 is a symmetric irreflexive binary relation on the finite set . A \emph{trace congruence}  can then be defined as the smallest  equivalence relation such that for all sequences , if , then . The elements of  are called \emph{traces}.  

Traces can also be defined alternatively as posets whose elements are labeled with symbols of a concurrent alphabet  satisfying certain conditions.  

Given a binary relation , the \emph{covering relation} of  is defined as . An alternative definition of Mazurkiewicz trace is:


\begin{definition}[cf. \cite{TW02}] A trace over a concurrent alphabet  is a finite labeled poset , where  is a labeling function, such that for all ,
\begin{enumerate}
\item , and
\item . \EOD
\end{enumerate}
\label{def:ltraces}
\end{definition}

A trace in this definition is only identified unique up to  \emph{label-preserving isomorphism}. The first condition says that immediately causally related event occurrences  must be labeled with dependent events. The second condition ensures that any two event occurrences with dependent labels must be causally related.  The first condition is particularly important since two immediately causally related event occurrences will occur next to each other in at least one of its linear extensions. This is the key to relate  \defref{ltraces} with quotient monoid definition of traces. Thus, we would like to establish a similar relationship for  comtraces. An immediate technical difficulty  is that weak causality might be cyclic, so the notion of ``immediate weak causality''  does not make sense. However, we can still deal with cycles of a so-structure by taking advantage of  the following simple fact: \emph{the weak causality relation is a strict preorder}.

Let  be a so-structure. We define the relation  as\\


Since  is a strict preorder, it follows that  is an equivalence relation. The relation  will be called the \emph{-cycle equivalence relation} and an element of the quotient set  will be called a \emph{-cycle equivalence class}.  We then define the following binary relations  and  on  the quotient set  as


Using this quotient construction,  every so-structure, whose weak causality relation might be cyclic, can be uniquely represented by an \emph{acyclic} quotient so-structure. 
\begin{proposition} The relational structure  is a so-structure, the relation  is a partial order, and for all ,
\begin{enumerate}
\item  
\item   
\end{enumerate}
\end{proposition}
\begin{proof} Follows from \defref{sos}. \qed
\end{proof}

Using (\ref{qsos}) and \theoref{SzpStrat}, it is not hard to prove the following simple yet useful properties of -cycle equivalence classes.

\begin{proposition} Let  be a so-structure. We use  and   to denote some step sequences over . Then for all ,
	\begin{enumerate}
	\item 
	\item 
	\item  \qed
	\end{enumerate}
\label{prop:covlsos}
\end{proposition}


Each -cycle equivalence class is what Juh\'as, Lorenz and Mauser called a \emph{synchronous step} \cite{JLM06,JLM08}. They also used equivalence classes to capture synchronous steps but only for the special class of \emph{synchronous closed} so-structures, where  is an equivalence relation. We extend their ideas by using -cycle equivalence classes to capture what we will call  \emph{non-serializable sets} in arbitrary so-structures. The name is justified in assertion (1) of \propref{covlsos} stating that two elements belong to the same non-serializable set of a so-structure  iff they must be executed simultaneously in every stratified extension of . Furthermore, we show in assertion (2) that all elements of a non-serializable set must occur together as a single step in at least one stratified extension of . Assertion (3) gives a sufficient condition for two non-serializable sets to occur as consecutive steps in at least one stratified extension of .


Before we proceed to define comtrace using labeled so-structure, we need to define  \textit{label-preserving isomorphisms} for labeled so-structures more formally. A tuple  is a \textit{labeled relational structure} iff  is a relational structure and  is a function with domain . If  is a so-structure, then  is a \textit{labeled so-structure}.

\begin{definition}[label-preserving isomorphism] Given two labeled relational structures  and , we write  to denote that  and  are  \emph{label-preserving isomorphic} (\emph{lp-isomorphic}). In other words, there is a bijection  such that for all , 
\begin{enumerate}
\item 
\item 
\item 
\end{enumerate}
Such function  is called a \emph{label-preserving isomorphism} (\emph{lp-isomorphism}). \EOD
\end{definition}

Note that all notations, definitions and results for so-structures are applicable to labeled so-structures. We also write  or  to denote the lp-isomorphic class of a labeled relational structure . We  will not distinguish  an lp-isomorphic class  with a single labeled relational structure  when it does not cause ambiguity.



We are now ready to give an alternative definition for comtraces. To avoid confusion with the comtrace notion by Janicki and Koutny in \cite{JK95}, we will use the term \emph{lsos-comtrace} to denote a comtrace defined using our definition.

\begin{definition}[lsos-comtrace] Given a comtrace alphabet , a \emph{lsos-comtrace} over  is (an lp-isomorphic class of) a finite labeled so-structure  such that   and for all ,
\begin{enumerate}
\item[] \textsf{LC1:\mbox{\hspace{5mm}}} 
\item[] \textsf{LC2:\mbox{\hspace{5mm}}} 
\item[] \textsf{LC3:\mbox{\hspace{5mm}}} 
\item[] \textsf{LC4:\mbox{\hspace{5mm}}} 
\item[] \textsf{LC5:\mbox{\hspace{5mm}}}  
\end{enumerate}
We write  to denote the class of all lsos-comtraces over . \EOD
\label{def:lcomtrace}
\end{definition}

\begin{example}
Let ,  and  . Then we have
. The lp-isomorphic class  of the labeled so-structure  depicted in \figref{f1} (the dotted edges denote  relation and the solid edges denote both  and  relations) is a lsos-comtrace. The graph in \figref{f2} represents the labeled quotient  so-structure  of , where we define .
\begin{figure}[ht]
\begin{minipage}{0.45\linewidth}\centering


\caption{lsos-comtrace }
\label{fig:f1}
\end{minipage}
\begin{minipage}{0.5\linewidth}\centering

\caption{the quotient structure  of }
\label{fig:f2}
\end{minipage}
\end{figure}



The lsos-comtrace  actually corresponds to the comtrace , and we will show this relationship formally in \secref{representation}. 
\EOD
\label{ex:comtrace2}
\end{example}




\begin{remark}
\defref{lcomtrace} can be extended to define \emph{infinite comtrace} as follows. Instead of asking  to be finite, we require a labeled so-structure to be  \emph{initially finite} (cf. \cite{JK97}), i.e.,  is finite for all . The initially-finiteness not only gives us a sensible interpretation that every event only  causually depends  on finitely many events, but also guarantees that the covering relations of  and  are well-defined. \EOD
\end{remark}

Since each lsos-comtrace is defined as a class of lp-isomorphic labeled so-structures, dealing with lsos-comtrace might seem tricky. Fortunately, the \emph{no autoconcurrency} property, i.e., the relation  is irreflexive, gives us a \emph{canonical} way to enumerate the events of a lsos-comtrace very similar to how the events of a comtrace are enumerated.

Given a step sequence  and any function  defined on , we define , i.e., the step sequence derived from  by applying the function  successively on each . Note that  denotes the \emph{image} of  under .

Given a lsos-comtrace   over a comtrace alphabet ,  a stratified order  can be seen as a step sequence .

\begin{proposition}  
\begin{enumerate}
\item For every  (), 
\item . \qed
\end{enumerate}
\label{prop:validss}
\end{proposition}


 \propref{validss} ensures that   is a valid step sequence over . Recall that  denotes the enumerated step sequence of  and  denotes the set of event occurrences. Define a  \emph{bijection}  as\\
\mbox{\hspace{2.7cm}}\smallskip

By \propref{validss}, the function  is well-defined.  Moreover, we can show that  is uniquely determined by  regardless of the choice of .

\begin{proposition} Given , let  and . Then . \qed
\label{prop:uniquexi}
\end{proposition}



Henceforth, we will ignore subscripts and reserve  the notation   to denote the kind of mappings as defined above. We then define the \emph{enumerated so-structure} of  to be the labeled so-structure , where  for  and ;  and the relations  are defined as\\
\mbox{\hspace{1.6cm}}

Clearly, the  enumerated so-structure  can be uniquely determined from  using the preceding definition.  From our construction, we can easily show the following important relationships:

\begin{proposition} 
\begin{enumerate}
\item  and  are  lp-isomorphic under the mapping . 
\item The labeled so-structures   and  are lp-isomorphic under the mapping  and . \qed 
\end{enumerate} 
\label{prop:isoExt}
\end{proposition}
\begin{minipage}{7.2cm}
\hspace{0.5cm}In other words, the mapping  plays 
the role of both the lp-isomorphism from  to  and the lp-isomorphism from the stratified extension  of  to the stratified extension  of . These relationships can be best captured using the commutative diagram on the right.\smallskip
\end{minipage}
\begin{minipage}{4.5cm}\centering\small\vspace{-3mm}

 \end{minipage}

We can even observe further that two lsos-comtraces are identical if and only if they define the same enumerated so-structure. Henceforth, we will call an enumerated so-structure defined by a lsos-comtrace  \emph{the canonical representation} of . 

Recently, inspired by the dependency graph notion for Mazurkiewicz traces (cf. \cite[Chapter 2]{DR}), Kleijn and Koutny claimed without proof that their \emph{combined dependency graph} notion is another alternative way to define comtraces \cite{KK08}. In \secref{representation}, we will give a detailed proof of their claim.


\begin{definition}[combined dependency graph \cite{KK08}] 
Given an comtrace alphabet , a \emph{combined dependency graph} (\emph{cd-graph}) over  is (a lp-isomorphic class of) a finite labeled relational structure  such that , the relations  are irreflexive,  is a so-structure, and for all ,\smallskip

\textsf{CD1:\mbox{\hspace{5mm}}} 

\textsf{CD2:\mbox{\hspace{5mm}}} 

\textsf{CD3:\mbox{\hspace{5mm}}} 

\textsf{CD4:\mbox{\hspace{5mm}}} \smallskip\\
We will write  to denote the class of all cd-graphs over . \EOD
\label{def:comdag}
\end{definition}

Cd-graphs can be seen as reduced graph-theoretic representations for lsos-comtraces, where some arcs that can be recovered using -closure are omitted. It is interesting to observe that the non-serializable sets of a cd-graph are exactly the \emph{strongly connected components} of the directed graph  and can easily be found in time  using any standard algorithm (cf. \cite[Section 22.5]{CLR}). \smallskip\\
\begin{minipage}{8.2cm}\begin{remark} Cd-graphs were called \emph{dependence comdags} in \cite{KK08}. But this name could be misleading since the directed graph  is not necessarily acyclic. For example, the graph on the right is the cd-graph that corresponds to  the lsos-comtrace from \figref{f1}, but it is not acyclic. (Here, we use the dotted edges to denote  and the solid edges to denote \emph{only} .) Thus, we use the name ``combined dependency graph'' instead. \EOD\end{remark}
\end{minipage}
\begin{minipage}{4cm}\centering

\end{minipage}




\section{Representation Theorems \label{sec:representation}}
This section contains the main technical contribution of this paper by showing that for a given comtrace alphabet , ,  and  are three equivalent ways of talking about the same class of objects. We will next prove the first representation theorem which establishes the representation mappings between  and .

\subsection{Representation Theorem for Comtraces and lsos-Comtraces}
\begin{proposition}
Let  and  be stratified order structures such that . Then .
\label{prop:stratsubset}
\end{proposition}
\begin{proof} Follows from \theoref{SzpStrat}. \qed
\end{proof}

For the next two lemmata, we let  be a lsos-comtrace over a comtrace alphabet . Let  be the canonical representation of . Let  and . Since  is a valid step sequence in  (by \propref{validss}), we can construct  from \defref{s2sos}. Our goal is to show that the stratified order  defined by the comtrace  is exactly .

\begin{lemma} .
\label{lem:l1}
\end{lemma}
\begin{proof} By \propref{so-cl}, to show , it suffices to show that . Since  is the canonical representation of , it is important to observe that .

(): Assume . Then from \defref{s2inv}, . Since , it follows from \defref{lcomtrace} that   or .  Suppose for a contradiction that , then by \theoref{SzpStrat},  . But since we assume that , it follows that  and , a contradiction. Hence, we have shown .

():  Can be shown in a similar way.
\qed
\end{proof}





\begin{lemma} .
\label{lem:l2}
\end{lemma}

In this proof, we will include subscripts for equivalence classes to avoid confusing the elements from quotient set  with the elements from the quotient comtrace monoid . In other words, we write  to denote an element of the quotient set , and write  to denote the comtrace generated by . 


\begin{proof}[of \lemref{l2}] Let . To show , by \propref{stratsubset}, it suffices to show . From \theoref{com2sos}, we know that . Thus we only need to show that for all , .

We observe that from , by \defref{commonoid}, we can generate all the step sequences in the comtrace  in stages using the following recursive definition:


Since the set  is finite,  for some stage . For the rest of the proof, we will prove by induction on  that for all , if  then . \\
\textbf{Base case:} When , . Since , it follows from \propref{isoExt} that . \\
\textbf{Inductive case:} When , let  be an element of . Then either  or . For the former case, by inductive hypothesis, . For the latter case, there must be some element  such that  or  . By induction hypothesis, we already known . We want to show that . There are two cases to consider:\smallskip\\
\textit{\textbf{Case (i):}} \\
When , by \defref{commonoid}, there are some  and steps  such that  and  where , ,  satisfy  and  and . Let  and  be enumerated step sequences of  and  respectively. 

Suppose for a contradiction that . By \defref{extsos}, there are   and  such that . We now consider the quotient set . By  \propref{covlsos} (1), . 
Since , it follows that . Thus, from the fact that  is partial order, there must exists a chain


Then by \theoref{SzpStrat} and the fact that , we know that  for all . In other words, since the chain \eref{chain1} implies that every  must always occur between  and  in all stratified extensions of  and , we also have . Hence, by \propref{covlsos} (1), we have  for all , . Also from \textsf{LC3} of \defref{lcomtrace} and that , we know that for each , either  or . Now we note  that the first element on the chain  and the last element on the chain . Thus, there exist two consecutive elements  and  on the chain such that  and . But then it follows that
\begin{itemize}
 \item[(a)]  and 
 \item[(b)]  since  and 
\end{itemize}
These contradict \textsf{LC2} of \defref{lcomtrace} since  is a lsos-comtrace.\smallskip\\
\textit{\textbf{Case (ii):}} \\
When , by \defref{commonoid}, there are some  and steps  such that  and   where , ,  satisfy  and  and . Let  and  be enumerated step sequences of  and  respectively. 

Suppose for a contradiction that . By \defref{extsos}, there are   and  such that . By  \propref{covlsos} (1), . Thus, using a dual argument to the proof of Case (i), we can build a chain

We then argue that there are two consecutive elements on the chain such that  and , which implies 
\begin{enumerate}
 \item[(a)]  and 
 \item[(b)]  since  and 
\end{enumerate}
These contradict  \textsf{LC1} of \defref{lcomtrace}. \qed

\end{proof}


We also need to show that the labeled so-structure defined from each comtrace is indeed a lsos-comtrace. In other words, we need to show the following lemma.

\begin{lemma}  Let  be a comtrace alphabet. Given a step sequence  , the lp-isomorphic class  is a lsos-comtrace over . \qed
\label{lem:l3}
\end{lemma}

The proof of this lemma is straightforward by checking that  satisfies all conditions \textsf{LC1}--\textsf{LC5}.


\begin{definition}[representation mappings  and ] Let  be a comtrace alphabet. 
\begin{enumerate}
 \item The mapping   is defined as\smallskip\\
 \mbox{\hspace{4cm}}\smallskip\\
where the function  is defined in \secref{steps} and  is the so-structure defined by the comtrace  from \defref{s2sos}. 
 \item The mapping   is defined as\smallskip\\
\mbox{\hspace{1.5cm}} 
 \EOD
\end{enumerate}
\label{def:repmaps}
\end{definition}

Intuitively, the mapping  is used to convert a comtrace to lsos-comtrace while the mapping  is used to transform a lsos-comtrace into a comtrace. The fact that  and  are valid representation mappings for  and   will be  shown in the following theorem. 




\begin{theorem}[The 1 Representation Theorem]  Let  be a comtrace alphabet.
\begin{enumerate}
\item For every , .
\item For every , .
\end{enumerate}
\label{theo:rep}
\end{theorem}

\begin{proof}\textbf{1. } The fact that  follows from \lemref{l3}. Now for a given ,  we have . Thus, it follows that
 

\textbf{2. }  Assume  is the canonical representation of . Observe that since , we have 

Let . We will next show that  and  . Fix an arbitrary , from Lemmas \ref{lem:l1} and \ref{lem:l2},  . From \theoref{com2sos}, . And the rest follows. \qed
\end{proof}

The theorem says that the mappings  and  are inverses of each other and hence are both \emph{bijective}. 


\subsection{Representation Theorem for lsos-Comtraces and Combined Dependency Graphs}
Using \theoref{rep}, we are going to show that the \emph{combined dependency graph} notion proposed in \cite{KK08} is another correct alternative definition for comtraces. First we need to define several  representation mappings  that are needed for our proofs.


\begin{definition}[representation mappings ,  and ] Let  be a comtrace alphabet. 
\begin{enumerate}
 \item The mapping   is defined as\smallskip\\
 \mbox{\hspace{3.5cm}}  \smallskip\\
where  is any step sequence in  and  and  are defined as in \defref{s2inv}. 
 \item The mapping   is defined as  .
 \item The mapping   is defined as\smallskip\\
 \mbox{\hspace{3.2cm}}   . \EOD
\end{enumerate}
\label{def:drepmaps}
\end{definition}

Before proceeding futher, we want to make sure that:
\begin{lemma}
\begin{enumerate}
\item  is a well-defined function.
\item  is a well-defined function.
\end{enumerate}
\end{lemma}


\begin{proof} \textbf{1. } Given a cd-graph , let . We know that  is uniquely defined, since by \defref{comdag},  is a so-structure, and so-structures are fixed points of -closure (by \propref{so-cl} (4)). We will next show that  is a lsos-comtrace by verifying the conditions \textsf{LC1}--\textsf{LC5} of \defref{lcomtrace}. Conditions \textsf{LC4} and \textsf{LC5} are exactly \textsf{CD1} and \textsf{CD2}.

\textsf{LC1}: Suppose for contradiction that there exist two distinct non-serializable sets  such that  and . Clearly, this implies that , and thus by the -closure definition,  is reachable from  on the directed graph , where . Now we consider a shortest path \smallskip\\
\mbox{\hspace{3.3cm}} \smallskip\\
on  that connects  to . We will prove by induction on  that there exist two consecutive  and  on  such that  and  and , which contradicts with  . \\
\textbf{Base case:} when , then . Since , we have , which by \textsf{CD3} implies .\\ \textbf{Inductive case:} when , we consider   and  . If  and , then by ,  we have , which immediately yields . Otherwise, we have  or . For the first case, we get , which contradicts that . For the latter case, we can apply induction hypothesis on the path .

\textsf{LC2} and \textsf{LC3} can also be shown similarly using ``shortest path'' argument as above. These proofs are easier since we only need to consider paths with edges in . 
 
\textbf{2. } By the proof of \cite[Lemma 4.7]{JK95}, for any two step sequences  and  in , we have  iff . Thus the mapping  is well-defined. \qed
\end{proof}



\begin{lemma} The mapping   is injective.
\label{lem:dlinj}
\end{lemma}
\begin{proof} Assume that , such that . Since -closure operator does not change the labeling function, we can assume that  and . We will next show that .

(): Let  such that . Suppose for a contradiction that . Since , by \textsf{CD3},  . Thus, by \textsf{CD2}, . But since , it follows that  (by \propref{so-cl}). Thus,  and , a contradiction.

(): Can be proved similarly.

By reversing the role of  and , we have . Thus, we conclude .
\qed
\end{proof}

We are now ready to show the following representation theorem which ensures that  and  are valid representation mappings for  and .

\begin{theorem}[The 2 Representation Theorem] Let  be a comtrace alphabet.
\begin{enumerate}
\item For every , .
\item For every , .
\end{enumerate}
\label{theo:deprep}
\end{theorem}
\begin{proof}\textbf{1. } Let  and let . Suppose for a contradiction that  and . From how  is defined, . Thus, it follows that . But this contradicts the injectivity of  from \lemref{dlinj}.

\textbf{2. } Let  and let . Suppose for a contradiction that  and . Since , if we let , then  . Thus, we have shown that  and , contradicting \theoref{rep} (2).
\qed 
\end{proof}

This theorem shows that lsos-comtraces and cd-graphs are equivalent representations for comtraces.  The main advantage of cd-graph definition is its simplicity while the lsos-comtrace definition is stronger and more convenient to prove properties about labeled so-structures that represent comtraces. 

We do not need to prove another representation theorem for cd-graphs and comtraces since their representation mappings are simply the composition of the representation mappings from Theorems \ref{theo:rep} and \ref{theo:deprep}.

\section{Composition Operators}
Recall for a comtrace monoid , the comtrace operator  is defined as . We will construct analogous composition operators for lsos-comtraces and cd-graphs. We will then show that lsos-comtraces (cd-graphs) over a comtrace alphabet  together with its composition operator form a monoid isomorphic to the comtrace monoid .

Given two sets  and , we  write  to denote the \emph{disjoint union} of  and . Such disjoint union can be easily obtained by renaming the elements in  and  so that . We define the lsos-comtrace composition operator as follows.


\begin{definition}[composition of lsos-comtraces] Let  and  be lsos-comtraces over an alphabet , where . The \emph{composition}  of  and  is defined as (a lp-isomorphic class of) a labeled so-structure  such that , , and , where\smallskip\\
\mbox{\hspace{1.5cm}}\\
\mbox{\hspace{1.5cm}} \EOD
\end{definition}

Observe that the operator is well-defined since  we can easily check that:
\begin{proposition}
For every , . \qed 
\end{proposition}

We will next show that this composition operator  properly corresponds to the operator   of the comtrace monoid over .

\begin{proposition}  Let  be a comtrace alphabet. Then  
\begin{enumerate}
\item For every , 

\item For every ,

\end{enumerate}
\label{prop:hom1}
\end{proposition}
\begin{proof}\textbf{1. }Assume ,  and . We can pick  and . Then observe that a stratified order  satisfying  is an extension of . Thus, by \theoref{rep}, we have 
 as desired.

\textbf{2. } Without loss of generality, we can assume that ,  and , where . By appropriate reindexing, we can also assume that . Under these assumptions, let ,  and , where  is simply the standard labeling functions. It will now suffice to show that .


(): Let . By Definitions \ref{def:s2inv} and \ref{def:s2sos}, we have\\
\mbox{\hspace{1.5cm}}\\
\mbox{\hspace{1.5cm}}\\
Thus, by \propref{so-cl} (5),  we have  as desired. Furthermore, by  \propref{so-cl} (5),   is a so-structure.


(): By Definitions \ref{def:s2inv} and \ref{def:s2sos}, we have  and . Since we already know  is a so-structure, it follows from \propref{so-cl} (5) that \\
\mbox{\hspace{1.3cm}}\qed
\end{proof}

Let  denote the lp-isomorphic class  . Then we observe that  and . By \propref{hom1} and \theoref{rep}, the structure  is isomorphic to the monoid  under the isomorphisms  and . Thus, the triple  is also a monoid. We can summarize these facts in the following theorem:
\begin{theorem}
The mappings  and  are monoid isomorphisms between two monoids  and  . \qed
\end{theorem}

Similarly, we can also define a composition operator for cd-graphs.
\begin{definition}[composition of cd-graphs] Let  and  be cd-graphs over an alphabet , where . The \emph{composition}  of  and  is defined as (a lp-isomorphic class of) a labeled so-structure  such that , , and \smallskip\\
\mbox{\hspace{1.5cm}}\\
\mbox{\hspace{1.5cm}} \EOD
\end{definition}

From this definition, it is straightforward to show the following propositions, which we will state without proofs.

\begin{proposition}
For every , . \qed 
\end{proposition}

\begin{proposition}  Let  be a comtrace alphabet. Then  
\begin{enumerate}
\item For every , 
\item For every ,  \qed
\end{enumerate}
\label{prop:hom2}
\end{proposition}

Putting the two preceding propositions  and \theoref{deprep} together, we conclude:
\begin{theorem}
The mappings  and  are monoid isomorphisms between two monoids  and . \qed
\end{theorem}


\section{Conclusion}

The simple yet useful construction we used extensively in this paper is to build a quotient so-structure modulo the -cycle equivalence relation. Intuitively, each -cycle equivalence class consists of all the events that must be executed simultaneously with one another and hence can be seen as a single ``composite event''.  The resulting quotient so-structure  is technically  easier to handle since both relations of the quotient so-structure are acyclic. From this construction, we were able to give a labeled so-structure definition for comtraces similar to the labeled poset definition for traces. This quotient construction also explicitly  reveals the following connection: a step on a step sequence  is not serializable with respect to  the relation  of a comtrace alphabet if and only if it corresponds to a -cycle equivalence class of the lsos-comtrace representing the comtrace  (cf. \propref{covlsos}). 

We have also formally shown that the quotient monoid of comtraces, the monoid of lsos-comtraces and the monoid of cd-graphs \emph{over the same comtrace alphabet} are indeed isomorphic by establishing monoid isomorphisms between them. These three models are  formal linguistic,  order-theoretic, and  graph-theoretic respectively, which allows us to apply a variety of tools and techniques. 

An immediate future task is to develop a framework similar to the one in this paper for \emph{generalized comtraces}, proposed and developed in \cite{JL08,Le,JL09}. Generalized comtraces extend comtraces with the ability to model events that can be executed \emph{earlier than or later than but never simultaneously}. Another direction is to define and analyze infinite comtraces (and generalized comtraces) in a spirit similar  to the works on infinite traces, e.g., \cite{Gas90,Die91}. It is also promising to use infinite lsos-comtraces and cd-graphs  to develop logics for comtraces similarly to what have been done for traces (cf. \cite{TW02,DHK07}). 

\subsubsection*{Acknowledgments.} I am grateful to Prof. Ryszard Janicki for introducing me  comtrace theory. I also thank the Mathematics Institute of Warsaw University and the Theoretical Computer Science Group of Jagiellonian University for their supports during my visits. It was during these visits that the ideas from this paper emerge. This work is financially  supported by the Ontario Graduate Scholarship and the Natural Sciences and Engineering Research Council of Canada. The anonymous referees are thanked for their valuable comments that help improving the readability of this paper.

\begin{thebibliography}{19}




\bibitem{CGP}
E. Clarke, O. Grumberg and D. Peled,  {\em Model Checking}, MIT Press, Cambridge, 1999.

\bibitem{CLR}
T. H. Cormen, C. E. Leiserson and R. L. Rivest, \emph{Introduction
to Algorithms}, Second Edition, MIT Press, 2001.



\bibitem{DP02}
B. A. Davey and H. A. Priestley, \newblock {\em Introduction to Lattices and Order}, \newblock Cambridge University Press 2002.





\bibitem{Die91}
V. Diekert, On the Concatenation of Infinite Traces, Proc. of STACS, \emph{LNCS} 480 (1991), 105--117.


\bibitem{DR}
V. Diekert and G. Rozenberg (eds.),
\newblock {\em The Book of Traces}.
\newblock World Scientific 1995.

\bibitem{DM}
V. Diekert and Y M\'etivier,
\newblock {\em Partial Commutation and Traces}, {\em Handbook of Formal Languages, Vol. 3: Beyond Words},  pp 457 - 533, Springer 1997. 

\bibitem{DHK07}
V. Diekert, M. Horsch, M. Kufleitner, On First-Order Fragments for Mazurkiewicz Traces, \emph{Fundam. Inform.} 80(1-3): 1-29, 2007.


\bibitem{EH}
J. Esparza and K. Heljanko,
\emph{Unfoldings -- A Partial-Order Approach to Model Checking},
Springer 2008. 

\bibitem{FM06}
A. Farzan and  P. Madhusudan,   Causal Dataflow Analysis for Concurrent Programs,  Proc. of  CAV, {\em LNCS} 4144 (2006): 315--328.

\bibitem{FM07}
A. Farzan and P. Madhusudan,   Causal Atomicity,  Proc. of TACAS 2007, {\em LNCS} 4424 (2007),  102--116.


\bibitem{Fis}
P. C. Fishburn, {\em Interval Orders and Interval Graphs},
J. Wiley 1985, New York.

\bibitem{GP}
H. Gaifman and V. Pratt, Partial Order Models of Concurrency and the Computation of Function,
{\em Proc. of LICS'87}, pp. 72--85.

\bibitem{Gas90}
P. Gastin, Infinite Traces, Proc. of Semantics of Systems of Concurrent Processes, \emph{LNCS}  469 (1990), 277--308.



\bibitem{GGH09}
T. Gazagnaire, B. Genest, L. H\'elou\"et, P. S. Thiagarajan, S. Yang, Causal Message Sequence Charts, \emph{Theor. Comput. Sci.} 410(41): 4094--4110, 2009.







\bibitem{J0}
R. Janicki,
\newblock Relational Structures Model of Concurrency.
\newblock {\em Acta Informatica}, 45(4): 279--320, 2008.

\bibitem{JK0}
R. Janicki and M. Koutny,
Invariants and Paradigms of Concurrency Theory, Proc. of \emph{PARLE} '91,
{\em LNCS} 506, Springer 1991, pp. 59--74.

\bibitem{J4}
R. Janicki and M. Koutny,
\newblock Structure of Concurrency,
\newblock {\em Theoretical Computer Science}, 112(1): 5--52, 1993.

\bibitem{JK95}
R. Janicki and M. Koutny,
 Semantics of Inhibitor Nets,
 {\em Information and Computation}, 123(1): 1--16, 1995.

\bibitem{JK97}
R. Janicki and M. Koutny, Fundamentals of Modelling Concurrency Using Discrete
Relational Structures, {\em Acta Informatica}, 34: 367--388, 1997.

\bibitem{JK99}
R. Janicki and M. Koutny, On Causality Semantics of Nets with Priorities,
{\em Fundamenta Informaticae} 34: 222--255, 1999.

\bibitem{JL08}
R. Janicki and D. T. M. L\^e, Modelling Concurrency with Quotient Monoids, Proc of PETRI NETS 2008, {\em LNCS} 5062, Springer 2008, pp. 251--269.

\bibitem{JL09}
R. Janicki and D. T. M. L\^e, Modelling Concurrency with Comtraces and Generalized Comtraces, submitted in 2009. Available at: \href{http://arxiv.org/abs/0907.1722}{http://arxiv.org/abs/0907.1722}


\bibitem{JLM08}
G. Juh\'{a}s, R. Lorenz, S. Mauser, Causal Semantics of Algebraic Petri Nets distinguishing Concurrency and Synchronicity, {\em Fundamenta Informatica} 86(3): 255-298, 2008.

\bibitem{JLM06}
G. Juh\'{a}s, R. Lorenz, S. Mauser, Synchronous + Concurrent + Sequential = Earlier Than + Not Later Than, Proc. of ACSD'06, Turku, Finland 2006, pp. 261-272,
IEEE Press.



\bibitem{KK}
H. C. M. Kleijn and M. Koutny, Process Semantics of General Inhibitor Nets,
{\em Information and Computation}, 190:18--69, 2004.

\bibitem{KK08}
J. Kleijn and M. Koutny, Formal Languages and Concurrent Behaviour,
{\em Studies in Computational Intelligence}, 113:125-182, 2008.

\bibitem{Le}
D. T. M. L\^e, Studies in Comtrace Monoids, Master Thesis, Dept. of Computing and Software, McMaster University, Canada, August 2008.


\bibitem{Ma1}
A.~Mazurkiewicz,
\newblock Concurrent Program Schemes and Their Interpretation, TR DAIMI PB-78, Comp. Science Depart., Aarhus University, 1977.





\bibitem{Pra}
V. Pratt,
\newblock Modeling concurrency with partial orders,
{\em International Journal of Parallel Programming}, 15(1):33--71, 1986.



\bibitem{Szp}
E.~Szpilrajn, Sur l'extension de l'ordre partiel, {\em Fund. Mathematicae} 16, 386--389, 1930.


\bibitem{TW02}
 P. S. Thiagarajan and I. Walukiewicz, An expressively complete linear time temporal logic for Mazurkiewicz traces, \emph{Inf. Comput.} 179(2): 230--249, 2002.





\end{thebibliography}

\appendix
\section{Proof of \propref{covlsos}}
\begin{proof}\textbf{1.} ():  Since ,  we know that  or . The former case is trivial. For the latter case, by \theoref{SzpStrat},  we have
 and . 
But this implies that .

(): The case when  is trivial. Assume that   and . Thus, by \theoref{SzpStrat},  and . But this means  and  belong to the same equivalence class.

\textbf{2. } Suppose for a contradiction that all  cannot be written in the form of . This implies that there exists some  such that for all , . But by \theoref{SzpStrat}, this yields  and , contradicting with .

\textbf{3. } Assume . Suppose for a contradiction that there does not exist  such that  for some step sequences  and . Then, by  \theoref{SzpStrat},  there must exist some , such that . Since , this yields , which  contradicts that .
\qed
\end{proof}



\section{Proof of \propref{validss}}
\begin{proof}\textbf{1. } Assume  and . Thus, .  Thus, by \corref{SzpStrat} (2), we have . Hence, by \textsf{LC5} of \defref{lcomtrace},  . Since  is irreflexive, this also shows that any two distinct  and  in  have different labels. Thus,  for all .

\textbf{2. } From the proof of \textbf{1.}, we know that   and  implies . Thus,  for all .
\qed
\end{proof}






\section{Proof of \propref{uniquexi}}
\begin{proof} Observe that from \propref{validss}, we have . It remains to show that   for all . 

Suppose for a contradiction that  for some . From the definition above, there are two distinct elements , such that  and  and . Since  is irreflexive, . Thus, by \textsf{LC4} of \defref{lcomtrace},  or . Without loss of generality, we assume  and that  for some event . 

Again by \textsf{LC4} of \defref{lcomtrace}, we know that elements  having the same label are totally ordered by . Thus, if  is the number of elements in  labeled by , then we have  and  . But then   implies that , while  implies that , which is absurd. \qed
\end{proof}

\section{Proof of \lemref{l3}}
\begin{proof} Let . From \theoref{com2sos},  is a labeled so-structure. It only remains to show that  satisfies conditions \textsf{LC1}--\textsf{LC5} of \defref{lcomtrace}. 

\textsf{LC1}: Assume   and suppose for a contradiction that . Then from \propref{covlsos} (3), there exists  such that . From \theoref{com2sos}, since we have , it follows that . But   implies . Hence,   is also a stratified extension of , which contradicts that . Using a similar argument, we can show \textsf{LC2} using \propref{covlsos} (1,4) and \textsf{LC3} using \propref{covlsos} (1,2).  

\textsf{LC4}: Follows from Definitions \ref{def:s2inv} and \ref{def:s2sos} and the -closure definition.

\textsf{LC5}: Since ,  it follows from \corref{SzpStrat} that there exists  where . Since , there exists a sequence  such that . This implies  and  belong to the same step in  . Thus, we have . \qed
\end{proof}


\end{document} 
