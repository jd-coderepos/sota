
\documentclass[12pt]{article}



\usepackage{epsfig}
\usepackage{fullpage}
\usepackage{latexsym}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{xspace}
\usepackage{subfigure,xspace}

\usepackage{multirow,booktabs}

\newtheorem{theorem}{Theorem}

\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{property}[theorem]{Property}



\newtheorem{claim}[theorem]{Claim}






\newcommand{\desc}{\ensuremath{\mathrm{desc}}}
\newcommand{\poly}{\ensuremath{\mathrm{poly}}}
\newcommand{\OPT}{\ensuremath{\mathrm{OPT}\xspace}}
\newcommand{\BMC}{{BMC}\xspace}
\newcommand{\DST}{{DST}\xspace}
\newcommand{\greedy}{{\sc Greedy}\xspace}






\begin{document}

\title{The Knapsack Problem with Neighbour Constraints}

\author{Glencora Borradaile\footnote{Supported
by NSF grant CCF-0963921.}\\Oregon State University\\{\tt
glencora@eecs.oregonstate.edu} \and Brent
Heeringa\footnote{Supported by NSF grant IIS-0812514}\\Williams College\\{\tt heeringa@cs.williams.edu} \and
Gordon Wilfong\\Bell Labs\\ {\tt
gtw@research.bell-labs.com}}

\maketitle


\begin{abstract}
We study a constrained version of the knapsack problem in which
dependencies between items are given by the adjacencies of a graph.  In the {\em 1-neighbour knapsack problem}, an item can be selected only if at least one of its neighbours is also
selected.  In the {\em all-neighbours knapsack problem}, an item can be selected only if all its neighbours are also selected.

We give approximation algorithms and
hardness results when the nodes have both uniform and arbitrary
weight and profit functions, and when the dependency graph is
directed and undirected.
\end{abstract}


\newpage

\section{Introduction}

We consider the knapsack problem in the presence of constraints.  The input is a graph  where each vertex  has a {\em weight}  and a {\em profit} , and a knapsack of size .  We start with the usual knapsack goal---find a set of vertices of maximum profit whose total weight does not exceed ---but consider two natural variations.  In the {\em 1-neighbour knapsack problem}, a vertex can be selected only if {\em at least one} of its neighbours is also selected (vertices with no neighbours can always be selected).  In the {\em all-neighbour knapsack problem} a vertex can be selected only if all its neighbours are also selected.

We consider the problem with {\em general}
(arbitrary) and {\em uniform} () weights
and profits, and with undirected and directed graphs.  In the case of
directed graphs, the constraints only apply to the {\em out}-neighbours of a vertex.

Constrained knapsack problems have applications to scheduling, tool
management, investment strategies and database
storage~\cite{KPP,BFFS05,Johnson:1983p1256}.  There are also
applications to network formation.  For example, suppose a set of
customers  in a network  wish to connect to a
server, represented by a single sink .  The server may
activate each edge at a cost and each customer would result in a
certain profit.  The server wishes to activate a subset of the edges
with cost within the server's budget. By introducing a vertex mid-edge
with zero-profit and weight equal to the cost of the edge and giving
each customer zero-weight, we convert this problem to a 1-neighbour
knapsack problem.




























































































\subsection{Results}

We show that the eight resulting problems

vary in complexity but afford several algorithmic approaches.  We
summarize our results for the 1-neighbour knapsack problem in Table~\ref{tbl:results}.  In addition, we show that uniform, directed
all-neighbour knapsack has a PTAS but is NP-complete.  The general,
undirected all-neighbour knapsack problem reduces to 0-1 knapsack, so there is a fully-polynomial time approximation scheme.











\begin{table}[tb]
\begin{center}
\begin{tabular}{cccc}
\toprule

&  & Upper & Lower \\
\cmidrule(r){2-4}
\multirow{2}{*}{\hspace{3mm}Uniform\hspace{3mm}} & \hspace{3mm}Undirected\hspace{3mm} & \multicolumn{2}{c}{linear-time exact}  \\
\cmidrule(r){2-4}
& Directed & PTAS & \hspace{3mm}NP-hard (strong sense) \hspace{3mm} \\
\cmidrule(r){2-4}
\multirow{2}{*}{General} & Undirected & \hspace{3mm}\hspace{3mm} &    \\
\cmidrule(r){2-4}
& Directed & {\em open} &  \\
\bottomrule
\end{tabular}
\end{center}
\caption{\label{tbl:results} 1-Neighbour Knapsack Problem results:  upper and lower bounds on the approximation ratios for combinations of .  For uniform, undirected, the bounds are running-times of optimal algorithms.}


\end{table}





In Section~\ref{sec:g1n} we describe a greedy algorithm that applies to the general 1-neighbour problem for both directed and undirected dependency graphs.  The algorithm requires two oracles: one for finding a set of vertices with high profit and another for finding a set of vertices with high profit-to-weight ratio.  In both cases, the total weight of the set cannot exceed the knapsack capacity and the subgraph defined by the vertices must adhere to a strict combinatorial structure which we define later.   The algorithm achieves an approximation ratio of .  The approximation ratios of the oracles determines the  and  terms respectively.

For the general, undirected 1-neighbour case, we give polynomial-time oracles that achieve  for any .  This yields a polynomial time -approximation.  We also show that no approximation ratio better than  is possible (assuming PNP).  This matches the upper bound up to (almost) a factor of 2.  These results appear in Section~\ref{sec:gu1n}.

In Section~\ref{sec:gd1n}, we show that the general, directed 1-neighbour knapsack problem is -hard to approximate, even in DAGs.  

In Section~\ref{sec:ud1n} we show that the uniform, directed
1-neighbour knapsack problem is NP-hard in the strong sense but that it has a polynomial-time
approximation scheme (PTAS)\footnote{A PTAS is an algorithm that,
given a fixed constant , runs in polynomial time and
returns a solution within  of optimal.  The algorithm
may be exponential in }.  Thus, as with general, undirected 1-neighbour problem, our upper and lower bounds are essentially matching.

In Section~\ref{sec:uu1n} we show that the uniform, undirected
1-neighbour knapsack problem affords a simple, linear-time solution.

In Section~\ref{sec:all-neighbours} we show that uniform, directed
all-neighbour knapsack has a PTAS but is NP-complete.  We also discuss the general, undirected all-neighbour problem.




























\subsection{Related work} \label{sec:related}

There is a tremendous amount of work on maximizing submodular functions under a single knapsack constraint~\cite{Sviridenko:orl2004}, multiple knapsack constraints~\cite{Kulik:2009}, and both knapsack and matroid constraints~\cite{Lee:2009,groundan-schulz:prepreint2009}.  While our profit function is submodular, the constraints given by the graph are not characterized by a matroid (our solutions, for example, are not closed downward).  Thus, the 1-neighbour knapsack problem represents a class of knapsack problems with realistic constraints that are not captured by previous work.

As we show in Section~\ref{sec:apx-hardness}, the general, undirected 1-neighbour knapsack problem generalizes several maximum coverage problems including the budgeted variant considered by Khuller, Moss, and Naor~\cite{kmn:ipl1999} which has a tight -approximation unless P=NP.  Our algorithm for the general 1-neighbour problem follows the approach taken by Khuller, Moss, and Naor but, because of the dependency graph, requires several new technical ideas.  In particular, our analysis of the greedy step represents a non-trivial generalization of the standard greedy algorithm for submodular maximization.



























Johnson and Niemi~\cite{Johnson:1983p1256} give an FPTAS for knapsack
problems on dependency graphs that are in-arborescences (these are
directed trees in which every arc is directed toward a single root).
In their problem formulation, the constraints are given as
out-arborescences---directed trees in which every arc is directed away
from a single root---and feasible solutions are subsets of vertices
that are closed under the {\em predecessor} operation. This problem
can be viewed as an instance of the general, directed 1-neighbour
knapsack problem.














In the subset-union knapsack problem (SUKP)~\cite{KPP}, each item is a subset
of a ground set of elements.  Each element in the ground set has a
weight and each item has a profit and the goal is to find a
maximum-profit set of elements where the weight of the union of the
elements in the sets fits in the knapsack.  It is easy to see that
this is a special case of the general, directed all-neighbours
knapsack problem in which there is a vertex for each item and each
element and an arc from an item to each element in the item's set.
In~\cite{KPP}, Kellerer, Pferschy, and Pisinger show that SUKP is
NP-hard and give an optimal but badly exponential algorithm.  The
precedence constrained knapsack problem~\cite{BFFS05} and
partially-ordered knapsack problem~\cite{Kolliopoulos:2007p1242} are
special cases of the general, directed all-neighbours knapsack problem
in which the dependency graph is a DAG.  Hajiaghayi et.~al.~show that
the partially-ordered knapsack problem is hard to approximate within a
 factor unless
3SATDTIME~\cite{Hajiaghayi:2006p1244}.









\subsection{Notation.}

We consider graphs  with  vertices  and  edges .
Whether the graph is directed or undirected will be clear from
context and we refer to edges of directed graphs as arcs.
For an undirected graph,  denotes the neighbours of a vertex  in
.  For a directed graph,  denotes the out-neighbours of 
in , or, more formally, .  Given a set of nodes ,  is the set of nodes not in  but that have a neighbour (or out-neighbour in the directed case) in .  That is, .
The degree (in undirected graphs) and out-degree (in directed graphs) of a vertex 
in  is denoted .  The subscript  will be dropped
when the graph is clear from context.  For a set of vertices {\em or}
edges ,  is the graph induced on .

For a directed graph ,  is the directed, acyclic graph (DAG)
resulting from contracting maximal strongly-connected components
(SCCs) of .  For each node , let  be the set of
vertices of  that are contracted to obtain .


For a vertex ,
let  be the set of all descendants of  in , {\em i.e.},~all
the vertices in  that are reachable from  (including ).  A
vertex is its own descendant, but not its own
strict descendant.





For convenience, extend any function  defined on items in a set 
to any subset  by letting .
If  is a set, then .  If  is
defined over vertices, then we extend it to edges: .  For any knapsack problem, \OPT~is the set of
vertices/items in an optimal solution.

\subsection{Viable Families and Viable Sets.}



A set of nodes  is a {\em 1-neighbour set} for  if for every vertex , .  That is, a 1-neighbour set is feasible with respect to the dependency graph.  A family of graphs  is a {\em viable family} for  if, for any subgraph  of , there exists a partition  of  into 1-neighbour sets for , such that for every , there is a graph  spanning .  For directed graphs, we take {\em spanning} to mean that  is a directed subgraph of  and that  and  contain the same number of nodes.  For a graph ,  we call  a {\em viable partition} of  with respect to .

\begin{figure}[bt]
\centering\includegraphics[scale=0.5]{figures/viable-partition}
\caption{ \label{fig:viable-partition}  An undirected graph.   If  is the family of star graphs, then the shaded regions give the only viable partition of the nodes---no other partition yields 1-neighbour sets.  However, every {\em edge} viable with respect to .  The singleton node is also viable since it is a 1-neighbour set for the graph.}
\end{figure}


\begin{figure}[tb]
\centering
\subfigure[]{\includegraphics[scale=0.5]{figures/A-B-Partition}}
\subfigure[]{\includegraphics[scale=0.5]{figures/A-B-Partition-Directed}}
\caption{ \label{fig:viable-partition-lemma}  An undirected  in (a) and a directed graph  in (b) with 1-neighbour sets  (dark shaded) and  (dotted) marked in both.  Similarly, in both (a) and (b) the lightly shaded regions give viable partitions for  and the white nodes denote .  In (a)  is viable for , and since , it is viable for .   is not viable for  but it is in .  In (b),  is viable in  whereas  is a viable because we consider  with the dotted arc removed.}
\end{figure}

In Section~\ref{sec:gu1n} we show that star graphs form a viable
family for any undirected dependency graph.  That is, we show that any
undirected graph can be partitioned into 1-neighbour sets that are
stars.  Fig.~\ref{fig:viable-partition} gives an example.  In
contrast, edges do not form a viable family since, for example, a
simple path with 3 nodes cannot be partitioned into 1-neighbour sets
that are edges.  For DAGs, in-arborescences are a viable family  but
directed paths are not  (consider a directed graph with 3 nodes
 and two arcs  and ).  Note that every vertex
must be included as a set on its own in any viable family.

A 1-neighbour set  for  is {\em viable} with respect to  if there is a graph  spanning . Note that the 1-neighbour sets in  are, by definition, viable for , but a viable set for  need not be in .  For example, if  is the family of stars and  is the undirected graph in Fig.~\ref{fig:viable-partition}, then any edge is a viable set for  but the only viable partition is the shaded region.  Note that if  is a viable set for  then it is also a viable set for any subgraph  of  provided .







Viable families and viable sets play an essential role in our greedy algorithm for the general 1-neighbour knapsack problem.  Viable families establish a set of structures over which our oracles can search.  This restriction simplifies both the design and analysis of efficient oracles as well as coupling the oracles to a shared family of graphs which, as we'll show later, is essential to our analysis.  In essence, viable families provide a mechanism to coordinate the oracles into returning sets with roughly similar structure.  Viable sets correctly capture the idea of an indivisible unit of choice in the greedy step.  We formalize this with the following lemma which is illustrated in Fig.~\ref{fig:viable-partition-lemma}.

\begin{lemma} \label{lemma:viable-correct} Let  be a graph and
 be a viable family for .  Let  and  be
1-neighbour sets for .  If  is a
viable partition of  where  then every set  is either (i) a singleton node 
such that  (i.e.,  has a neighbour in ),
or (ii) a viable set for , which is the subgraph obtained by deleting
vertices in  and arcs in  where  is empty if  is
undirected and  is the set of arcs with tails in 
if  is directed. 





\end{lemma}

\begin{proof}
If  then let .  If  then  is a
viable set for  so it is viable set for . Otherwise, since
 is a 1-neighbour set for ,  must have a neighbour in 
so .  If  then, provided  is
undirected,  is also a viable set in  so it is a viable set
in .  If  is directed and  contains a node  that is in
, an arc out of  is not needed for feasibility
since  already has a neighbour in .

\end{proof}



\section{The general 1-neighbour knapsack problem} \label{sec:g1n}


Here we give a greedy algorithm {\sc Greedy-1-Neighbour} for the general 1-neighbour knapsack problem on both directed and undirected graphs.  A formal description of our algorithm is available in Fig.~\ref{alg:greedy-1-neighbour}.  {\sc Greedy1-Neighbour} relies on two oracles {\sc Best-Profit-Viable} and {\sc Best-Ratio-Viable} which find viable sets of nodes with respect to a fixed viable family .  In each iteration , we call {\sc Best-Ratio-Viable} which, given the nodes not yet chosen by the algorithm, returns the highest profit-to-weight ratio, viable set  with weight not exceeding the remaining capacity.  We also consider the set of nodes  not in the knapsack, but with at least one neighbour already in the knapsack.  Let  be the node with highest profit-to-weight ratio in  not exceeding the remaining capacity.  We greedily add either  or  to our knapsack  depending on which has higher profit-to-weight ratio. We continue until we can no longer add nodes to the knapsack.

For a viable family , if we can efficiently approximate the highest profit-to-weight ratio viable set to within a factor of  and if we can efficiently approximate the highest profit viable set to within a factor of , then our greedy algorithm yields a polynomial time -approximation.













\begin{figure}[tb]
\begin{center}
\fbox{
\begin{minipage}[h]{.9\linewidth}
\noindent {\sc Greedy-1-Neighbour}
\begin{tabbing}
\qquad \=  = {\sc best-profit-viable} \\
\> , , , ,  \\
\> WHILE there is either a viable set in  or a node in  with weight  \\
\> \qquad \=  = {\sc best-ratio-viable} \\
\> \>  \\
\> \> IF \\
\> \> \qquad \\
\> \> \\
\> \> \\
\> \> \\
\> \> If  is directed, remove any arc in  with a tail in \\
\> RETURN 
\end{tabbing}
\end{minipage}
}
\end{center}
\caption{\label{alg:greedy-1-neighbour} The {\sc Greedy-1-Neighbour} algorithm.  In each iteration , we greedily add either the viable set  or the node  to our knapsack  depending on which has higher profit-to-weight ratio.  This continues until we can no longer add nodes to the knapsack.}
\vspace{-4mm}
\end{figure}







\begin{theorem} \label{thm:gd1n}
{\sc Greedy-1-Neighbour} is a
-approximation for the
general 1-neighbour problem on directed and undirected graphs.
\end{theorem}

\begin{proof}
Let  be the set of vertices in an optimal solution.  In addition, let  correspond to  after the first  iterations where .  Let  be the first iteration in which there is either a node in  or a viable set in  whose profit-to-weight ratio is larger than .  Of these, let  be the node or set with highest profit-per-weight.  For convenience, let   and  for , and .  Notice that  is a feasible solution to our problem but that  is not since it contains  which has weight exceeding .  We analyze our algorithm with respect to .

\begin{lemma} \label{lem:profit-inc-dag}
For each iteration , the following holds:

\end{lemma}









\begin{proof}
Fix an iteration  and let  be the graph induced by .  Since both  and  are 1-neighbour sets for , by Lemma~\ref{lemma:viable-correct}, each  is either a viable set for  (so it can be selected by {\sc best-ratio-viable}) or a singleton vertex in  (which {\sc Greedy-1-Neighbour} always considers).  Thus, if , then by the greedy choice of the algorithm and approximation ratio of {\sc best-ratio-viable} we have

If  then  is, by definition, at least as large as the profit-to-weight ratio of any .  It follows that for :

Rearranging gives Lemma~\ref{lem:profit-inc-dag}.
\hfill  \end{proof}

\begin{lemma} \label{lem:profit}
For , the following holds:

\end{lemma}

\begin{proof}
We prove the lemma by induction on .  For , we need to
show that

This follows immediately from Lemma~\ref{lem:profit-inc-dag} since  and . Suppose the lemma holds for iterations 1 through .  Then it is
easy to show that the inequality holds for iteration  by applying
Lemma~\ref{lem:profit-inc-dag} and the inductive hypothesis.  This
completes the proof of Lemma~\ref{lem:profit}.
\hfill
\end{proof}










We are now ready to prove Theorem~\ref{thm:gd1n}.  Starting with the inequality in Lemma~\ref{lem:profit} and using
the fact that adding  violates the knapsack constraint (so
) we have

where the penultimate inequality follows because equal  maximize the product.  Since  is within a factor of  of the maximum profit viable set of weight  and  is contained in \OPT,
.  Thus, we have .  Therefore
.

\hfill
\end{proof}













\subsection{The general, undirected 1-neighbour problem} \label{sec:gu1n}

Here we formally show that stars are a viable family for undirected
graphs and describe polynomial-time implementations of {\sc
Best-Profit-Viable} and {\sc Best-Ratio-Viable} for the star family.  Both oracles achieve an approximation ratio of  for any .  Combined with {\sc Greedy-1-Neighbour} this yields a polynomial time -approximation for the general, undirected 1-neighbour problem.  In addition, we show that this approximation is nearly tight by showing that the general, undirected 1-neighbour problem generalizes many coverage problems including the max -cover and budgeted maximum coverage, neither of which have a -approximation for any  unless P=NP.

\subsubsection{Stars} \label{sec:stars}

For the rest of this section, we assume  is the family of
star graphs ({\em i.e.} graphs composed of a center vertex  and a (possibly empty) set of edges all of which have  as an endpoint) so that
given a graph  and a capacity , {\sc Best-Profit-Viable} returns
the highest profit, viable star with weight at most  and {\sc Best-Ratio-Viable} returns the highest profit-to-weight, viable star with weight at most .

\begin{lemma}\label{lem:graphs-into-stars}
The nodes of any undirected constraint graph  can be partitioned into 1-neighbour sets that are stars.
\end{lemma}

\begin{proof}
Let  be an arbitrary connected component of .  If  then  is trivially a 1-neighbour set and the trivial star consisting of a single node is a spanning subgraph of .  If  is non-trivial then let  be any spanning tree of  and consider the following construction: while  contains a path  with , remove an interior edge of  from .  When the algorithm finishes, each path has at least one edge and at most two edges, so  is a set of non-trivial stars, each of which is a 1-neighbour set.
\hfill  \end{proof}

\paragraph{{\sc Best-Profit-Viable}}

Finding the maximum profit, viable star of a graph  subject to a knapsack constraint  reduces to the traditional unconstrained knapsack problem which has a well-known FPTAS that runs in  time~\cite{ibarra-kim:jacm1975,vazirani}. Every vertex  defines a knapsack problem:  the items are  and the capacity is .  Combining  with the solution returned by the  FPTAS  yields a candidate star.  We consider the candidate star for each vertex and return the one with highest profit.  Since we consider all possible star centers, {\sc Best-Profit-Viable} runs in  time and returns a viable star within a factor of  of optimal, for any .

\paragraph{{\sc Best-Ratio-Viable}}

We again turn to the FPTAS for the standard knapsack problem.  Our goal is to find a high profit-to-weight star in  with weight at most .  The standard FPTAS for the unconstrained knapsack problem builds a dynamic programing table   with  rows and  columns where  is the number of available items and  is the maximum adjusted profit over all the items.  Given an item , its adjusted profit is  where  is the true maximum profit over all the items.  Each entry  gives the weight of the minimum weight subset over the first  items achieving profit .

Notice that, for any fixed profit ,  is the highest profit-to-weight ratio for that .  Therefore, for , the  maximizing  gives the highest profit-to-weight ratio of any feasible subset provided .  Let  be this subset.  We will show that  is within a factor of  of \OPT\ where \OPT\ is the profit-to-weight ratio of the highest profit-to-weight ratio feasible subset .

Letting  and , and following~\cite{vazirani}, we have

since, for any item , the difference between  and  is at most  and we can fit at most  items in our knapsack.  Because  and \OPT \ is at least  we have

Now, just as with {\sc Best-Profit-Viable}, every vertex  defines a knapsack instance where  is the set of items and  is the capacity.  We run the modified FPTAS for knapsack on the instance defined by  and add  to the solution to produce a set of candidate stars.  We return the star with highest profit-to-weight ratio.  Since we consider all possible star centers, {\sc Best-Ratio-Viable} runs in  time and returns a viable star within a factor of  of optimal, for any .

\paragraph{Justifying Stars}

Besides some isolated vertices, our solution is a set of edges, but
the edges are not necessarily vertex disjoint.  Analyzing our greedy
algorithm in terms of edges risks counting vertices multiple times.
Partitioning into stars allows us to charge increases in the profit
from the greedy step without this risk.  In fact, stars are
essentially the {\em simplest} structure meeting this requirement
which is why we use them as our viable family.

\paragraph{Improving the approximation ratio}

Often this style of greedy algorithm can be augmented with an
``enumeration over triples'' step to improve the ratio of
.  However, such an enumeration
would require enumerating over all possible triples of {\em stars} in
our case.  Doing so cannot be done in polynomial time, unless the
graph has bounded degree.



\subsubsection{General, undirected 1-neighbour knapsack is APX-complete} \label{sec:apx-hardness}











Here we show that it is NP-hard to approximate the general, undirected 1-neighbour knapsack problem to within a factor better than  for any  via an approximation-preserving reduction from max -cover~\cite{feige:jacm1998}.  An instance of max -cover is a set cover instance  where  is a ground set of  items and  is a collection of subsets of .  The goal is to cover
as many items in  using at most  subsets from .

\begin{theorem}
The general, undirected 1-neighbour knapsack problem has no -approximation for any  unless PNP.
\end{theorem}

\begin{proof}
Given an instance of  of max -cover, build a bipartite
graph  where  has a node  for each  and  has a node  for each set .  Add
the edge  to  if and only if .
Assign profit  and weight  for each vertex
 and profit  and weight  for each
vertex .  Since no pair of vertices in  have an edge
and since every vertex in  has no weight, our strategy is to pick
vertices from  and all their neighbours in .  Since every
vertex of  has unit profit, we should choose the  vertices from
 which collectively have the most neighbours.  This is exactly the
max -cover problem.

\end{proof}

The max -cover problem represents a class of {\em budgeted maximum
coverage} (\BMC) problems where the elements in the base set have
unit profit (referred to as weights in~\cite{kmn:ipl1999}) and the
cover sets have unit weight (referred to as costs
in~\cite{kmn:ipl1999}).  In fact, one can use the above reduction to
represent an arbitrary \BMC instance: form the same bipartite graph,
assign the element weights in \BMC as vertex profits in , and finally
assign the covering set costs in \BMC as vertex weights in .










\subsection{General, directed 1-neighbour knapsack is hard to approximate} \label{sec:gd1n}

Here we consider the 1-neighbour knapsack problem where  is directed and has arbitrary profits and weights.  We show via a reduction from {\em directed Steiner tree} (\DST) that the general, directed 1-neighbour problem is hard to approximate within a factor of .  Our result holds for DAGs.  Because of this negative result, we also don't expect that good approximations exist for either {\sc Best-Profit-Viable} and {\sc Best-Ratio-Viable} for any family of viable graphs.

In the \DST problem on DAGs we are given a DAG  where each arc has an associated cost, a subset of 
vertices called {\em terminals} and a root vertex .  The goal
is to find a minimum cost set of arcs that together connect  to all
the terminals ({\em i.e.}, the arcs form an out-arborescence rooted at
).  For all , \DST admits no
-approximation algorithm unless ~\cite{HK}.  This result holds even for very
simple DAGs such as {\em leveled DAGs} in which  is the only root,  is at level 0,
each arc goes from a vertex at level  to a vertex at level ,
and there are  levels.  We use leveled DAGs in our proof of the following theorem.





\begin{theorem} \label{thm:gd1nlb}
The general, directed 1-neighbour knapsack problem is
-hard to approximate unless .
\end{theorem}





\begin{proof}
Let  be an instance of \DST where the underlying graph  is a leveled DAG with a single root .  Suppose there is a solution to  of cost .

\begin{claim} \label{claim:cover}
If there is an -approximation algorithm for
the general, directed 1-neighbour knapsack problem then a solution
to  with cost  can be found where 
is the number of terminals in .
\end{claim}

\begin{proof}
Let  be the DAG in instance .  We modify it to
 where we split each arc  by placing a dummy
vertex on  with weight equal to the cost of  according to 
and profit of 0.  In addition, we also reverse the orientation of each arc.
Finally, all other vertices are given weight 0 and terminals are assigned
a profit of 1 while the non-terminal vertices
of  are given a profit of 0.  We create an instance  of the
general, directed 1-neighbour knapsack problem consisting of 
and budget bound of .  By assumption, there is a solution to 
with cost  and profit .  Therefore given , an
-approximation algorithm would produce a set of arcs whose
weight is at most  and includes at least  terminals.
That is, it has a profit of at least .  Set the weights of
dummy nodes to 0 on the arcs used in the solution. Then for all
terminals included in this solution, set their profit to 0 and
repeat.  Standard set-cover analysis shows that after  repetitions, each terminal will have been connected to the root
in at least one of the solutions.  Therefore the union of all the
arcs in these solutions has cost at most 
and connects all terminals to the root.
\hfill  \end{proof}
Using the above claim, we'll show that if there is an -approximation algorithm for the general, directed-1-neighbour problem then there is an -approximation algorithm for \DST which implies the theorem.  Let  be the total cost of the arcs in the instance of \DST.  For
each , take  and perform the procedure in the previous claim for  iterations.  If after
these iterations all terminals are connected to the root then call
the cost of the resulting arcs a valid cost.  Finally, choose the
smallest valid cost, say  and  will be no more than
 where  is the optimal cost of a solution for
the \DST instance.  By the previous claim we have a solution
whose cost is at most .
\hfill  \end{proof}










\section{The uniform, directed 1-neighbour knapsack problem} \label{sec:ud1n}

In this section, we give a PTAS for the uniform, directed 1-neighbour
knapsack problem.  We rule out an FPTAS by proving the following theorem.



\begin{theorem} \label{thm:ud1n-hard}
The uniform, directed 1-neighbour problem is strongly NP-hard.
\end{theorem}




\begin{proof}
The proof is a reduction from set cover.  Let the base set for an
instance be  and the collection of
subsets of  be .  The maximum
number of sets desired to cover the base set is .

We build an instance of the 1-neighbour knapsack problem.  Let .  The dependency graph is as follows.  For
each subset  create a cycle  of size ; the set of cycles are
pairwise vertex disjoint.  In each such cycle  choose some node
arbitrarily and denote it by .  For each , define a new
node in  and label it .  Define .   Let the capacity of the knapsack be .

Suppose  is a solution to the set-cover instance.  Since
, we can define  to be such that
.  Let  be a collection of  elements of  not in . Let  be the graph induced by the union of the nodes in
 for each  or , and :  consists of exactly  nodes.  Every vertex
in the cycles of  has out-degree 1.  Since  is a set
cover, for every  there is some  where
 and so the arc  is in .  It follows that
 is a witness for a 1-neighbour set of size .

Now suppose that the subgraph  of  is a solution to the
1-neighbour knapsack instance with value .  Since , it is straightforward to
check that  must consist of a collection  of exactly 
cycles, say , and
each node , , along with some arc
.  But by definition of , that means that  for  and so  is a solution to the set cover
instance.
\end{proof}


\subsection{A PTAS for the uniform, directed 1-neighbour problem.}
Let  be a 1-neighbour set.  Let  be a minimal set of arcs of
 such that for every vertex , .  That is,  is a
{\em witness} to the feasibility of  as a 1-neighbour set.  Since
each node of  in  has out-degree 0 or 1, the structure of
 has the following form.

\begin{property}
\label{prop:structure}
Each connected component of  is a cycle  and a collection
of vertex-disjoint in-arborescences, each rooted at a node of .  
may be trivial, i.e.,~ may be a single vertex , in which case
.
\end{property}

For a strongly connected component , let  be the size of the
shortest directed cycle in  with  if and only if .

\begin{lemma}
\label{lem:scc-structure}
There is an optimal 1-neighbour knapsack  and a witness  such that
for each non-trivial, maximal SCC  of , there is at most one
cycle of  in  and this cycle is a smallest cycle of .
\end{lemma}





\begin{proof}
First we modify  so that it contains smallest cycles of maximal
SCCs.  We rely heavily on the structure of  guaranteed by
Property~\ref{prop:structure}.  The idea is illustrated
in Fig.~\ref{fig:1-neighbour-structure}.

Let  be a cycle of  and let  be the maximal SCC of 
that contains .  Suppose  is not the smallest cycle of  or
there is more than one cycle of  in .  Let  be the
connected component of  containing .  Let  be a smallest
cycle of .  Let  be the shortest directed path from  to
.  Since  and  are in a common SCC,  exists.  Let 
be an in-arborescence in  spanning ,  and  rooted at a
vertex of .

Some vertices of  might already be in the
1-neighbour set : let  be these vertices.  Note that  and  are
disjoint because of Property~\ref{prop:structure}.  Let  be a
sub-arborescence of  such that:
\begin{itemize}
\item  has the same root as , and
\item .
\end{itemize}
Since  and
 is connected, such an in-arborescence exists.

Let .  Let  be a witness
spanning  contained in  that contains the arcs in .  We
have that  has  vertices and contains a smallest cycle of
.

We repeat this procedure for any SCC in our witness that contains
a cycle of a maximal SCC of G that is not smallest or contains two
cycles of a maximal SCC.
\hfill  \end{proof}


\begin{figure}[tb]
\centering
\subfigure[]{\includegraphics[scale=0.4]{figures/1-friend-structure-a}}
\subfigure[]{\includegraphics[scale=0.4]{figures/1-friend-structure-b}}
\caption{Construction of a witness containing the smallest cycle
of an SCC.  The shaded region highlights the vertices of an
SCC (edges not in , , or  are not depicted).  The edges of the witness are solid.  (a) The smallest
cycle  is not in the witness.  (b) By removing an edge from
 and leaf edges from the in-arborescences rooted on , we
create a witness that includes the smallest cycle .}
\label{fig:1-neighbour-structure}
\end{figure}






To describe the algorithm, let  be the DAG of maximal
SCCs of  and let  be a fixed constant where  is
the knapsack bound. (If 
then the brute force algorithm which considers all subsets 
with  yields an acceptable bound for a PTAS.)

We say that  is {\em large} if ,
{\em petite} if , or {\em tiny} if .
Let , , and  be the set of all large, petite and tiny SCCs
respectively.
Note that since , for every , .



\begin{center}
\fbox{
\begin{minipage}[h]{.9 \linewidth}
\noindent {\sc uniform-directed-1-neighbour}
\begin{tabbing} \qquad  \\
\qquad For every subset  such that \\
\qquad\qquad \= .\\
\> \mathcal{D}D_X \\
\>  any maximal subset of  such that .\\
\> \\
\> Greedily add vertices to  such that  remains a 1-neighbour \\
\> \qquad set until there are no more vertices to add or \\
\> \qquad .  (Via a backwards search rooted at .)\\
\>  \\
\qquad Return .
\end{tabbing}
\end{minipage}
}
\end{center}



\begin{theorem} \label{thm:1-neighbour-ptas} {\sc
uniform-directed-1-neighbour} is a PTAS for the uniform, directed
1-neighbour knapsack problem.
\end{theorem}


\begin{proof}
Let  be an optimal 1-neighbour knapsack and let  be
its witness as guaranteed by Lemma~\ref{lem:scc-structure}.
Let , and  be the sets of large, petite, and tiny cycles in
 respectively.   
By Lemma~\ref{lem:scc-structure}, each of these cycles is in a
different maximal SCC and each cycle is a smallest cycle in its
maximal SCC.

Let  and let  be the set of large SCCs that intersect .  Note that .  Since  we have .
So, in some iteration of {\sc uniform-directed-1-neighbour}, .  We analyze this iteration of the algorithm.  There are two
cases:
\begin{description}
\item[.] First we show that every vertex in  has a descendant in .  Clearly if a vertex of  has a descendant in some , it has
a descendant in .  Suppose a vertex of  has a descendant in
some .   is within an SCC of , and so it must have a
descendant that is in a sink of .  Similarly, suppose a vertex of 
has a descendant in some .   is either a sink in  or has a
descendant that is either a sink of  or a sink of .
All these sinks are contained in . Since every vertex of  can reach a
vertex in , greedily adding to
this set results in  and the result of {\sc
uniform-directed-1-neighbour} is optimal.

\item[.]For any sink ,  but  by the definition of tiny and petite.  So, , and the resulting solution is within
 of optimal.
\end{description}

The running time of {\sc uniform-directed-1-neighbour} is
.  It is dominated by the number of iterations,
each of which can be executed in poly time. \hfill  \end{proof}


\section{The uniform, undirected 1-neighbour  problem} \label{sec:uu1n}

We now consider the final case of 1-neighbour problems, namely the
uniform, undirected 1-neighbour problem.
We note that there is a relatively straightforward
linear time algorithm for finding an optimal solution for instances of this problem.  The algorithm essentially breaks the graph into connected components and then, using a counting argument, builds an optimal solution from the components.



\begin{theorem} \label{thm:uu1n}
The uniform, undirected 1-neighbour knapsack problem has a linear-time solution.
\end{theorem}




\begin{proof}
Let  be the connected components of the dependency graph
 in {\em decreasing} order by size (we can find such an ordering in linear time).  Note that each connected
component  constitutes a feasible set for the
uniform, undirected 1-neighbour problem on .  If  is odd and
 for all , then the optimal solution has size  since no vertex can
be included on its own.  In this case the first  connected
components constitutes a feasible, optimal solution.

Otherwise, let  be smallest index such that .  If  then
let .  Otherwise, take .  If  then the first 
components of  have exactly  nodes and constitute a feasible,
optimal solution for .  Otherwise, by our choice of ,
 and .  Let  be an ordering of the nodes in
 given by a breadth-first search (start the search
from an arbitrary node).  Collect the first  nodes of  in .  We consider three cases:
\begin{enumerate}
\item If  and , then the first 
connected components along with  constitute a
feasible, optimal solution.
\item If  and , then .  If  then return
 since there is no feasible solution, otherwise drop an
appropriate node from  (one that keeps the rest of
 connected) and add  to  since
.  Now the first  connected components
(without the one node in ) along with 
constitute a feasible, optimal solution.
\item If , then the
first  connected components along with  constitute a
feasible, optimal solution.
\end{enumerate}
\end{proof}







\section{The all-neighbours knapsack problem} \label{sec:all-neighbours}

In this section, we consider the all-neighbours knapsack problem.  Our
primary result is a PTAS for the uniform, directed all-neighbours
problem.  We also show that uniform, directed all-neighbours is
NP-hard in the strong sense, so no polynomial-time algorithm can yield
a better approximation unless P=NP.  In addition, we show that
uniform, undirected all-neighbours knapsack reduces to the classic
knapsack
problem.

A set of vertices  is a {\em feasible} all-neighbours knapsack
solution if, for every vertex , .  Recall
that for an SCC  is obtained by contracting
.  For convenience, let  and
.  Let  be the set of descendant sets for every node of
.  We now show that all feasible solutions to the
all-neighbour knapsack problem can be decomposed into sets from
.

\begin{property} \label{prop:all-neighbours}
Every feasible solution to a general, directed all-neighbour instance has the form  where .
\end{property}

\begin{proof}
Let  be a feasible solution for the dependency graph .  We claim
that if  then there exists a set  such
that  and .  Notice that the
all-neighbours constraint implies that if  is a neighbor of  in
 and  is a neighbor of  in , then  implies .  Thus, by transitivity, if  and  is reachable from 
then .  Let  and  be the node in 
such that .  Suppose that .
Then every node in  is reachable from  in  as is every
node in  so  which proves the claim since .  The property follows.
\end{proof}

Property~\ref{prop:all-neighbours} tells us that if  is a feasible solution for  and , then every node reachable from  in  must also be in the optimal solution.  We use this property extensively throughout the rest of Section~\ref{sec:all-neighbours}.

\subsection{The uniform, directed all-neighbour knapsack problem}

We show that {\sc uniform-directed-all-neighbour} (below) is a
PTAS for the uniform, directed all-neighbours knapsack problem.  The
key ideas are to (a) identify a set  of {\em heavy nodes} in  i.e., those nodes  where ,
and then (b) augment subsets of the heavy nodes with nodes from
the set  of {\em light nodes}, i.e., those nodes  with .  We note that this algorithm works on the set of SCCs and
can handle the slightly more general than uniform case: that in which
the weight and profit of a vertex is equal, but different vertices may
have different weights.

\begin{center}
\fbox{
\begin{minipage}[h]{.9\linewidth}
\noindent {\sc uniform-directed-all-neighbour}
\begin{tabbing}
\qquad \=, ,  \\
\> For every subset  of  such that  \\
\>  \qquad \= \\
\>  \> Let  \\
\>  \> While  and  \\
\>  \> \qquad \= Add any element  to . \\
\>  \> \> Update  \\
\>  \> If  then  \\
\>  Return \\
\end{tabbing}
\end{minipage}
}
\end{center}

\begin{theorem} \label{thm:uniform-directed-all}
{\sc uniform-directed-all-neighbour} is a PTAS for the uniform,
directed all-neighbour knapsack problem.
\end{theorem}

\begin{proof}
Let  be a set of vertices of  forming an optimal solution to
the uniform, directed all-neighbours knapsack problem.  By Property~\ref{prop:all-neighbours},
there is a subset of nodes  such that . Let .  Since the size of
any node in  is at least  and the weight of  is
at most , .  Since all subsets of  of
size at most  are considered in the for loop of {\sc
uniform-directed-all-neighbours}, set  will be one such set.

Let .  Let  be all the nodes of  added to
the solution in all iterations of the while loop.  Let .

Since ,  by
Property~\ref{prop:all-neighbours}.  Let .   and  are not necessarily the same
set of nodes.  Suppose  and  are not the same set of
nodes and .  Then there is a node  such that 's neighbours are in
.  Since ,  could be added to ,
a contradiction.


We now bound the running time of {\sc uniform-directed-all-neighbour}.
Line 1, which find the set of heavy nodes ,
compute a simple set difference, and initialize the return value, take
at most  time.  Since  and  there are at most  subsets of 
considered in line 2, so line 2 executes at most  times.  Since we will never execute line 4 more than
 times we have an -time algorithm.
\end{proof}

\begin{theorem} \label{thm:uniform-directed-all-hard}
The uniform, directed-all-neighbour problem is NP-hard.
\end{theorem}

\begin{proof}
We reduce the set-union knapsack problem to the uniform, directed
all-neighbours knapsack problem.  An instance of SUKP consists of a
base set of elements  where each  has
an integer weight , a positive integer capacity , a target
profit , a collection  where
, each subset  has a non-negative profit .
Then the question asked is: Does there exist a sub-collection
 of  such that
 and for ,
.  This problem is known to be NP-hard in
the strong sense even for the case where  and  for
~\cite{goldschmidt-etal:nrl1994}.

We consider instances of SUKP where
every subset  in  has cardinality 2 and profit .
Also, each element  has weight .
Let  be the capacity and  be the target profit.
Given such an instance of SUKP we define next an
instance of uniform, directed all-neighbours that has a solution if and only
if the SUKP instance has a solution.

Let  be a directed graph where for each element  there
is a strongly connected component  with  nodes one
of which is labeled .
Let  denote the set of nodes in .
For each subset  there is a node .
For every  there is an arc  and
these are the only other arcs.
Let  be the target party size.
Then we claim that there is a party of size  if and only
if there is a solution to the SUKP instance
having weight at most  and profit at least .

Suppose there is solution  of size  to uniform, directed all-neighbours.
Since  and , there must be some collection  of
node sets  of strongly connected components such
that  contains the union of nodes of the 's
in  where .
Hence  must also contain a set  of at least  nodes .
Since  is feasible solution it must be that for every 
if  then .
It is straightforward then to check that the collection of sets

is a solution to the SUKP instance
with profit  and
since )
it has weight at most .

Now suppose  is a solution
to the SUKP instance where  and
.
Let  and hence .
Arbitrarily choose some  where .
Then take .
Let  be a set of elements such that  and .
Define .
Since , it must be for every , if
 then .
Therefore  is a solution to the all-neighbours
problem where .
\end{proof}

\subsection{The uniform, undirected all-neighbour knapsack problem}

The problem of uniform, undirected all-neighbour knapsack is
solvable in polynomial time.
In this case we just need to find the subset of connected components of 
whose total size is as large as possible without exceeding .
But this is exactly the subset sum problem.  Since , the standard
dynamic programming algorithm yields a truly polynomial-time 
solution.

\subsection{The general, all-neighbour knapsack problem}

As mentioned in Section~\ref{sec:related} the general, directed, all-neighbours
knapsack problem is a generalization of the partially ordered knapsack
problem~\cite{Kolliopoulos:2007p1242} which has been shown to be hard to
approximate within a  factor unless
3SATDTIME~\cite{Hajiaghayi:2006p1244}.
Hence the general, directed all-neighbours knapsack problem is hard
to approximate within this factor under the same complexity assumption.

In the undirected case, i.e., the case where the dependency graph 
is undirected,  becomes a set of disjoint nodes,
one for each connected component of ,
and .  By Property~\ref{prop:all-neighbours},
we are left with the problem of finding a subset of nodes  such that  is maximal subject to .
But this is exactly the 0-1 knapsack problem which has a well-known
FPTAS.  Thus, general, undirected all-neighbours also has an FPTAS.
Contrast this with the uniform, directed all-neighbours problem.
There, the sets in  are not disjoint, so we cannot use
the 0-1 knapsack ideas.


\section{Future directions}

There are several open problems to consider, including closing gaps,
improving the running times of the PTASes, and giving approximation
algorithms for the general, directed versions of both 1-neighbour and
all-neighbour. We believe that fully understanding these problems will
lead to ideas for a much more general problem: maximizing a linear
function with a submodular constraint.






\paragraph{{\bf Acknowledgments}}
We thank Anupam Gupta for helpful
discussions in showing hardness of approximation for general,
directed 1-neighbour knapsack.



\bibliographystyle{plain}
\bibliography{party-problem}

\newpage






\end{document}
