\documentclass[11pt]{article}
\usepackage[pdftex,paper=a4paper,left=3cm,right=3cm,top=4cm,bottom=4cm]{geometry}
\usepackage{amsthm, amsmath, amssymb} \usepackage{mathrsfs}         \usepackage{graphicx}
\usepackage{url} \usepackage{algorithmic}
\usepackage{algorithm}
\usepackage[T1]{fontenc}
\usepackage{lmodern}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{claim}{Claim}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{example}[theorem]{Example}
\newtheorem{property}[theorem]{Property}
 
\newcommand{\RR}{\mathbb{R}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\fmax}{f_{\max}}
\newcommand{\e}{\varepsilon}
\renewcommand{\sp}{\ell}
\newcommand{\COST}{\mathscr{C}}
\newcommand{\event}{\mathsf{E}}
\providecommand{\qed}{\hfill }
\newcommand{\G}{\overleftrightarrow{G}}

\newcommand{\DOT}{\,.}
\newcommand{\COMMA}{\,,}
\newcommand{\WHERE}{\,\colon\,}

\newcommand{\tIF}{\text{if}}
\newcommand{\tAND}{\text{and}}
\DeclareMathOperator{\Reconstruct}{\mathsf{Reconstruct}}
\DeclareMathOperator{\sgn}{sgn}

\newcommand{\Ex}[2][]{\operatorname{\textbf{E}}_{#1}\left[#2\right]}
\renewcommand{\Pr}[2][]{\operatorname{\textbf{Pr}}_{#1}\left[#2\right]}
\newcommand{\SET}[1]{\left\{#1\right\}}
\newcommand{\sSET}[1]{\{#1\}}
\newcommand{\ceil}[1]{\left\lceil#1\right\rceil}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\PATH}[1][]{\stackrel{#1}{\rightsquigarrow}}
\newcommand{\spm}[1][]{\sp^{#1}_{-}}
\newcommand{\spp}[1][]{\sp^{#1}_{+}}
\newcommand{\REVERSE}[1]{\stackrel{\leftarrow}{#1}}

\newcommand{\GFX}[2][]{\includegraphics[#1]{#2.pdf}}

\newenvironment{fig}
{\begin{figure}[th]\begin{center}}
{\end{center}\end{figure}}

\newenvironment{GFXFIG}[2][]
{\begin{fig}\GFX[#1]{#2}}
{\end{fig}}

\begin{document}

\title{Smoothed Analysis of the Successive~Shortest~Path~Algorithm\thanks{This research was supported by ERC Starting Grant 306465 (BeyondWorstCase)
and NWO grant 613.001.023. The upper bound (Theorem 1) of this paper has been presented at the 24th ACM-SIAM Symp.\ on Discrete Algorithms (SODA 2013).}}

\newcommand*\samethanks[1][\value{footnote}]{\footnotemark[#1]}

\author{Tobias Brunsch\thanks{University of Bonn,
                Department of Computer Science,
                Germany.
                Email: {\tt \{brunsch,roeglin,roesner\}@cs.uni-bonn.de}}
 \and Kamiel Cornelissen\thanks{University of Twente,
              Department of Applied Mathematics,
              Enschede, The Netherlands.
              Email: {\tt \{k.cornelissen,b.manthey\}@utwente.nl}}
 \and Bodo Manthey\samethanks[3]
 \and Heiko R{\"o}glin\samethanks[2]
 \and Clemens R{\"o}sner\samethanks[2]
}

\date{}

\maketitle

 
\begin{abstract}
The minimum-cost flow problem is a classic problem in combinatorial optimization with various applications. Several pseudo-poly\-no\-mi\-al,
polynomial, and strongly polynomial algorithms have been developed in the past decades, and it seems that both the problem and the
algorithms are well understood. However, some of the algorithms' running times observed in empirical studies contrast the running times
obtained by worst-case analysis not only in the order of magnitude but also in the ranking when compared to each other. For example, the
Successive Shortest Path (SSP) algorithm, which has an exponential worst-case running time, seems to outperform the strongly polynomial
Minimum-Mean Cycle Canceling algorithm.

To explain this discrepancy, we study the SSP algorithm in the framework of smoothed analysis and
establish a bound of  for the number of iterations, which implies a smoothed running time of , 
where~ and~ denote the number of nodes and edges, respectively, and~ is a measure for the amount of random noise. 
This shows that worst-case instances for the SSP algorithm are not robust and unlikely to be encountered in practice. Furthermore, we prove a
smoothed lower bound of  for the number of iterations of the SSP algorithm, showing that the
upper bound cannot be improved for .
\end{abstract}



\section{Introduction}

Flow problems have gained a lot of attention in the second half of the twentieth century to model, for example, transportation and communication networks~\cite{DBLP:books/daglib/0069809,ForFul62}. Plenty of algorithms have been developed over the last fifty years. The first pseudo-polynomial algorithm for the minimum-cost flow problem was the Out-of-Kilter algorithm independently proposed by Minty~\cite{Min60} and by Fulkerson~\cite{Ful61}. The simplest pseudo-polynomial algorithms are the primal Cycle Canceling algorithm by Klein~\cite{Kle67} and the dual Successive Shortest Path (SSP) algorithm by Jewell~\cite{Jew62}, Iri~\cite{Iri60}, and Busacker and Gowen~\cite{BusGow60}. By introducing a scaling technique Edmonds and Karp~\cite{DBLP:journals/jacm/EdmondsK72} modified the SSP algorithm to obtain the Capacity Scaling algorithm, which was the first polynomial time algorithm for the minimum-cost flow problem.

The first strongly polynomial algorithms were given by Tardos~\cite{DBLP:journals/combinatorica/Tardos85} and by Orlin~\cite{Orl84}. Later,
Goldberg and Tarjan~\cite{DBLP:journals/jacm/GoldbergT89} proposed a pivot rule for the Cycle Canceling algorithm to obtain the strongly
polynomial Minimum-Mean Cycle Canceling (MMCC) algorithm. The fastest known strongly polynomial algorithm up to now is the Enhanced Capacity
Scaling algorithm due to Orlin~\cite{Orl93} and has a running time of , where~ and~ denote the number of nodes and edges, respectively. For an extensive overview of
minimum-cost flow algorithms we suggest the paper of Goldberg and Tarjan~\cite{GolTar90}, the paper of Vygen~\cite{Vyg02}, and the book of
Ahuja, Magnanti, and Orlin~\cite{DBLP:books/daglib/0069809}.

Zadeh~\cite{Zad73} showed that the SSP algorithm has an exponential worst-case running time. Contrary to this,
the worst-case running times of the Capacity Scaling algorithm and the MMCC algorithm are  \cite{DBLP:journals/jacm/EdmondsK72} and  \cite{DBLP:journals/algorithmica/RadzikG94}, respectively. Here,~ denotes the maximum edge capacity and~ denotes the maximum edge cost. In particular, the former is polynomial whereas the latter is even strongly polynomial.
However, the notions of pseudo-polynomial, polynomial, and strongly polynomial algorithms always refer to worst-case running times,
which do not always resemble the algorithms' behavior on real-life instances. Algorithms with large worst-case running times do not inevitably perform poorly in practice. An experimental study of Kov{\'a}cs~\cite{Kir14} indeed observes running time behaviors significantly deviating from what the worst-case running times indicate. The MMCC algorithm is completely outperformed by the SSP algorithm. The Capacity Scaling algorithm is the fastest of these three algorithms, but its running time seems to be in the same order of magnitude as the running time of the SSP algorithm.
In this article, we explain why the SSP algorithm comes off so well by applying the framework of smoothed analysis.

Smoothed analysis was introduced by Spielman and Teng~\cite{DBLP:journals/jacm/SpielmanT04} to explain why the simplex method is efficient in practice despite its exponential worst-case running time. In the original model, an adversary chooses an arbitrary instance which is subsequently slightly perturbed at random. In this way, pathological instances no longer dominate the analysis. Good smoothed bounds usually indicate good behavior in practice because in practice inputs are often subject to a small amount of random noise. For
instance, this random noise can stem from measurement errors, numerical imprecision, or rounding errors. It can also model influences that cannot be quantified exactly but for which there is no reason to believe that they are adversarial. Since its invention, smoothed analysis has been successfully applied in a variety of contexts. Two recent surveys~\cite{MR,SpielmanT09} summarize some of these results.

We follow a more general model of smoothed analysis due to Beier and V{\"o}cking~\cite{BeierV04}. In this model, the adversary is even
allowed to specify the probability distribution of the random noise. The power of the adversary is only limited by the \emph{smoothing
parameter}~. In particular, in our input model the adversary does not fix the edge costs~, but he
specifies for each edge~ a probability density function~ according to which the costs~ are randomly
drawn independently of the other edge costs. If , then the adversary has no choice but to specify a uniform distribution on the
interval~ for each edge cost. In this case, our analysis becomes an average-case analysis. On the other hand, if~ becomes
large, then the analysis approaches a worst-case analysis since the adversary can specify a small interval~ of length~ (which
contains the worst-case costs) for each edge~ from which the costs~ are drawn uniformly.

As in the worst-case analysis, the network graph, the edge capacities, and the balance values of the nodes are chosen adversarially. The edge capacities and the balance values of the nodes are even allowed to be real values.
We define the smoothed running time of an algorithm as the worst expected running time the adversary can achieve and we prove the following theorem.

\begin{theorem}
\label{maintheorem}
The SSP algorithm requires  augmentation steps in expectation and its smoothed running time is .
\end{theorem}

If~ is a constant -- which seems to be a reasonable assumption if it models, for example, measurement errors -- then the smoothed bound simplifies to . Hence, it is unlikely to encounter instances on which the SSP algorithm requires an exponential amount of time.





The following theorem, which we also prove in this article, states that the bound for the number of iterations of the SSP algorithm stated in Theorem~\ref{maintheorem} cannot be improved for . 

\begin{theorem}
\label{theorem:lower bound}
For given positive integers , , and  there exists a minimum-cost flow network with  nodes,  edges, and random edge costs with smoothing parameter~ on which the SSP algorithm requires  augmentation steps with probability~1.
\end{theorem}

The main technical section of this article is devoted to the proof of Theorem~\ref{maintheorem}
(Section~\ref{sec:analysis}). In Section~\ref{sec:lower bound} we derive the lower bound stated in Theorem~\ref{theorem:lower bound}.
At the end of this article (Section~\ref{sec:simplex}), we point out
some connections between SSP and its smoothed analysis
to the simplex method with the shadow vertex pivot rule, which has been used
by Spielman and Teng in their smoothed analysis~\cite{DBLP:journals/jacm/SpielmanT04}.

\subsection{The Minimum-Cost Flow Problem}

A \emph{flow network} is a simple directed graph~ together with a \emph{capacity function}~. For convenience, we assume that there are no directed cycles of length two. In the minimum-cost flow problem there are an additional \emph{cost function}~ and a \emph{balance function}~ indicating how much of a resource some node~ requires () or offers (). A \emph{feasible -flow} for such an instance is a function~ that obeys the capacity constraints  for any edge~ and Kirchhoff's law adapted to the balance values, i.e.,

for all nodes . (Even though~, , and~ are functions, we use the notation~, , and  instead of~, , and  in this article.) If , then there does not exist a feasible -flow. We therefore always require .
The cost of a feasible -flow is defined as . In the \emph{minimum-cost flow problem} the goal is to find the cheapest feasible -flow, a so-called \emph{minimum-cost -flow}, if one exists, and to output an error otherwise.

 
\subsection{The SSP Algorithm}
\label{sec:SSPAlg}

For a pair , we denote by~ the pair . Let~ be a flow network, let~ be a cost function, and let~ be a flow. The \emph{residual network}~ is the directed graph with vertex set~, arc set , where

is the set of so-called \emph{forward arcs} and

is the set of so-called \emph{backward arcs}, a capacity function , defined by

and a cost function , defined by

In practice, the simplest way to implement the SSP algorithm is to transform the instance to an equivalent instance with only one \emph{supply node} (a node with positive balance value) and one \emph{demand node} (a node with negative balance value). For this, we add two nodes~ and~ to the network which we call \emph{master source} and \emph{master sink}, edges  for any supply node~, and edges  for any demand node~. The capacities of these \emph{auxiliary edges}  and  are set to  and , respectively. The costs of the auxiliary edges are set to~. Now we set  where~ is the sum of the capacities of the auxiliary edges incident with~ (which is equal to the sum of the capacities of the auxiliary edges incident with~ due to the assumption that~). All other balance values are set to .

This is a well-known transformation of an arbitrary minimum-cost flow instance into a minimum-cost flow instance with only a single source~, a single sink~, and~ for all nodes~. Nevertheless, we cannot assume without loss of generality that the flow network we study has only a single source and a single sink. The reason is that in the probabilistic input model introduced above it is not possible to insert auxiliary edges with costs~ because the costs of each edge are chosen according to some density function that is bounded from above by~. We have to consider the auxiliary edges with costs~ explicitly and separately from the other edges in our analysis.

The SSP algorithm run on the transformed instance computes the minimum-cost -flow for the original instance.
In the remainder of this article we use the term \emph{flow} to refer to a feasible -flow for an arbitrary~ with  and  for .
We will denote by  the amount of flow shipped from  to  in flow ,
i.e.,
.

The SSP algorithm for a minimum-cost flow network with a single source~, a single sink~, and with  is given as Algorithm~\ref{algorithm:SSP}.

\begin{algorithm*}
  \caption{SSP for single-source-single-sink minimum-cost flow networks with .}
  \label{algorithm:SSP}
  \begin{algorithmic}[1]
    \STATE start with the empty flow~
    \FOR{}
      \STATE \textbf{if}  does not contain a (directed) - path \textbf{then} output that there does not exist a flow with value~
      \STATE find a shortest - path~ in~ with respect to the arc costs
      \STATE augment the flow as much as possible along path~ to obtain a new flow~
      \STATE \textbf{if}  \textbf{then} output~
    \ENDFOR
  \end{algorithmic}
  \medskip

  \small  Since the value~ of flow~ must not exceed~ and the flow~ must obey all capacity constraints, the flow is increased by the minimum of ,  and .
\end{algorithm*}

\begin{theorem}
\label{thm:AllFlowsOpt}
In any round~, flow~ is a minimum-cost -flow for the balance function~ defined by

and
v\notin\{s,t\}.
\end{theorem}

Theorem~\ref{thm:AllFlowsOpt} is due to Jewell~\cite{Jew62}, Iri~\cite{Iri60}, and Busacker and Gowen~\cite{BusGow60}. We refer to Korte and Vygen~\cite{Korte:2007:COT:1564997} for a proof.
As a consequence, no residual network~ contains a directed cycle with negative total costs. Otherwise, we could augment along such a cycle to obtain a -flow~ with smaller costs than~. In particular, this implies that the shortest paths in~ from~ to nodes~ form a shortest path tree rooted at~. Since the choice of the value~ only influences the last augmentation of the algorithm, the algorithm performs the same augmentations when run for two different values  until the flow value~ exceeds~. We will exploit this observation in Lemma~\ref{lemma:cost function form}. 

Note that one could allow the cost function~ to have negative values as well. As long as the network does not contain a cycle with negative total costs, the SSP algorithm is still applicable. However, as we cannot ensure this property if the edge costs are random variables, we made the assumption that all edge costs are non-negative.

\subsection{A Connection to the Integer Worst-case Bound}

We can concentrate on counting the number of augmenting steps of the SSP algorithm since each step can be implemented to run in time  using Dijkstra's algorithm. Let us first consider the case that all edge costs are integers from . In this case the length of any path in any residual network is bounded by~. We will see that the lengths of the augmenting paths are monotonically increasing. If there is no unique shortest path to augment flow along and ties are broken by choosing one with the fewest number of arcs, then the number of successive augmenting paths with the same length is bounded by 
(this follows from the analysis of the Edmonds-Karp algorithm for computing a maximum flow~\cite{CLRS}).
 Hence, the SSP algorithm terminates within  steps.

Now let us perturb the edge costs of such an integral instance independently by, for example, uniform additive noise from the interval .
This scenario is not covered by bounds for the integral case. Indeed, instances can be generated with positive probability for which the number of augmentation
steps is exponential in~ and~. Nevertheless, an immediate consequence of Theorem~\ref{maintheorem} is that, in expectation, the SSP
algorithm terminates within  steps on instances of this form.

\section{Terminology and Notation}

Consider the run of the SSP algorithm on the flow network~. We denote the set  of all flows encountered by the SSP algorithm by~. Furthermore, we set .
(We omit the parameter  if it is clear from the context.)

Let us remark that we have not specified in Algorithm~\ref{algorithm:SSP} which path is chosen if the shortest - path is not unique. This is not important for our analysis because we will see in Section~\ref{sec:analysis} that this happens only with probability~ in our probabilistic model. We can therefore assume  to be well-defined.

By~ and~, we denote the empty flow and the maximum flow, i.e., the flow that assigns~ to all edges~ and the flow of maximum value encountered by the SSP algorithm, respectively.

Let~ and~ be two consecutive flows encountered by the SSP algorithm and let~ be the shortest path in the residual network~, i.e., the SSP algorithm augments along~ to increase flow~ to obtain
flow~. We call~ the \emph{next path} of~ and the \emph{previous path} of~. To distinguish between the original network~ and some residual network~ in the remainder of this article, we refer to the edges in the residual network
as \emph{arcs}, whereas we refer to the edges in the original network
as \emph{edges}.

For a given arc~ in a residual network~, we denote by~ the corresponding edge in the original network~, i.e.,  if  (i.e.~ is a forward arc) and  if  (i.e.~ is a backward arc). An arc~ is called \emph{empty} (with respect to some residual network~) if~ belongs to~, but  does not. Empty arcs~ are either forward arcs that do not carry flow or backward arcs whose corresponding edge~ carries as much flow as possible. We say that an arc \emph{becomes saturated} (during an augmentation) when it is contained in the current augmenting path, but it does not belong to the residual network that we obtain after this augmentation.

In the remainder, a \emph{path} is always a simple directed path.
Let~ be a path, and let~ and~ be contained in~ in this order. By , we refer to the sub-path of~ starting from node~ going to node~, by  we refer to the path we obtain by reversing the direction of each edge of~. We call any flow network~ a \emph{possible residual network} (of~) if there is a flow~ for~ such that . Paths and cycles in possible residual networks are called \emph{possible paths} and \emph{possible cycles}, respectively. Let  for  denote the flow network that consists of all forward arcs and backward arcs. 

\section{Outline of Our Approach}

Our analysis of the SSP algorithm is based on the following idea: We identify a flow~ with a real number by mapping~ to the length~ of the previous path~ of~. The flow~ is identified with . In this way,
we obtain a sequence  of real numbers. We show that this sequence is strictly monotonically increasing with probability~. Since all costs are drawn from the interval , each element of~ is from the interval . To count the number of elements of~, we partition the interval  into small sub-intervals of length~ and sum up the number of elements of~ in these intervals. By linearity of expectation, this approach carries over to the expected number of elements of~. If~ is very small, then -- with sufficiently high probability -- each interval contains at most one element. 
If this is the case then it suffices to bound the probability that an element of~ falls into some interval~ because
this probability equals the expected number of elements in~.

To do so, we assume for the moment that there is an integer~ such that .
By the previous assumption that for any interval of length~ there is at most
one path whose length is within this interval, we obtain that . We show that the augmenting path~ uses an empty arc~. Moreover, we
will see that we can reconstruct the flow~ and the path~ without knowing the costs of
edge~ that corresponds to arc~ in the original network.
This allows us to use the principle of deferred decisions: to bound the probability that~ falls into the interval , we first reveal all costs~
with~. Then~ is known and its length, which equals~, can be expressed
as a linear function~ or~ for a known constant~. 
Consequently, the probability that~ falls into the interval  is bounded by~, as the probability density of  is bounded by .
Since the arc~ is not always the same, we have to apply a union bound over all~ possible arcs. Summing up over all~ intervals the expected number of flows encountered by the SSP algorithm can be bounded by roughly .

There are some parallels to the analysis of the smoothed number of Pareto-optimal solutions in bicriteria linear optimization problems by Beier and V\"ocking~\cite{DBLP:journals/siamcomp/BeierV06}, although we have only one objective function.
In this context, we would call~ the loser,  the winner, and the difference~ the loser gap. Beier and V\"ocking's analysis is also based on the observation
that the winner (which in their analysis is a Pareto-optimal solution and not a flow) can be reconstructed when all except for one random coefficients are revealed.
While this reconstruction is simple in the setting of bicriteria optimization problems, the reconstruction of the flow~  in our setting is significantly more challenging and a main
difficulty in our analysis.

\section{Proof of the Upper Bound}
\label{sec:analysis}

Before we start with the analysis, note that due to our transformation of the general minimum-cost flow problem to a single-source-single-sink minimum-cost flow problem the cost perturbations only affect the original edges. The costs of the auxiliary edges are not perturbed but set to~. Thus, we will slightly deviate from what we described in the outline by treating empty arcs corresponding to auxiliary edges separately.

The SSP algorithm is in general not completely specified, since at some point during the run of the algorithm there could exist multiple shortest - paths in the residual network of the current flow.
The SSP algorithm then allows any of them to be chosen as the next augmenting path. Due to Lemma~\ref{lemma:different path lengths} and Property~\ref{property:different path lengths} we can assume that this is not the case in our setting and that the SSP algorithm is completely specified.

\begin{lemma}
\label{lemma:different path lengths}
For any real~ the probability that there are two nodes~ and~ and two distinct possible - paths whose lengths differ by at most~ is bounded from above by~.
\end{lemma}

\begin{proof}
Fix two nodes~ and~ and two distinct possible - paths~ and~. Then there is an edge~ such that one of the paths -- without loss of generality path~ -- contains arc~ or~, but the other one does not. If we fix all edge costs except the cost of edge~, then the length of~ is already determined whereas the length of~ depends on the cost~. Hence,  must fall into a fixed interval of length~ in order for the path lengths of~ and~ to differ by at most~. The probability for this is bounded by~ because~ is chosen according to a density function that is bounded from above by~. A union bound over all pairs~ and all possible - paths concludes the proof. \end{proof}

The proof also shows that we can assume that there is no - path of length~ and according to Lemma~\ref{lemma:different path lengths} we can assume that the following property holds since it holds with a probability of 1.

\begin{property}
\label{property:different path lengths}
For any nodes~ and~ the lengths of all possible - paths are pairwise distinct.
\end{property}

\begin{lemma}\label{lemma:distance monotonicity}
Let~ denote the distance from~ to node~ and  denote the distance from node~ to~ in the residual network~. Then
the sequences  and  are monotonically increasing
for every~.
\end{lemma}

\begin{proof}
We only show the proof for the sequence . The proof for the sequence  can be shown analogously.
Let  be an arbitrary integer. We show  by induction on the depth of node~ in the shortest path tree~ of the residual network~ rooted at~. For the root~, the claim holds since . Now assume that the claim holds for all nodes up to a certain depth~, consider a node~ with depth~, and let~ denote its parent. Consequently,  for . If arc~ has been available in~, then . If not, then the SSP algorithm must have augmented along~ in step~ to obtain flow~ and, hence, . In both cases the inequality  holds. Applying the induction hypothesis for node~, we obtain
.
\end{proof}

\begin{definition}
For a flow~, we denote by  and  the length of the previous path~ and the next path~ of~, respectively. By convention, we set  and . If the network~ is clear from the context, then we simply write~ and~. By~ we denote the cost function that maps reals~ from the interval  to the cost of the cheapest flow~ with value~, i.e., .
\end{definition}

The lengths~ correspond to the lengths~ mentioned in the outline. The apparent notational overhead is necessary for formal correctness. In Lemma~\ref{lemma:cost function form}, we will reveal a connection between the values~ and the function~. Based on this, we can focus on analyzing the function~.

Lemma~\ref{lemma:distance monotonicity} implies in particular that the distance from the source~
to the sink~ is monotonically increasing, which yields the following corollary. 
\begin{corollary}\label{corollary:path monotonicity}
Let~ be two flows with . Then .
\end{corollary}



\begin{lemma}
\label{lemma:cost function form}
The function~ is continuous, monotonically increasing, and piecewise linear, and the break points of the function are the values of the flows  with . For each flow , the slopes of~ to the left and to the right of~ equal~ and~, respectively.
\end{lemma}

\begin{proof}
The proof follows from Theorem~\ref{thm:AllFlowsOpt} and the observation that the cost of the flow is linearly increasing when gradually increasing the flow along the shortest path in the residual network until at least one arc becomes saturated. The slope of the cost function is given by the length of that path. \end{proof}

\begin{example}
\label{example}
Consider the flow network depicted in Figure~\ref{fig:example network}. The cost~ and the capacity~ of an edge~ are given by the notation~. For each step of the SSP algorithm, Figure~\ref{exampletable} lists the relevant part of the augmenting path (excluding~, , , and~), its length, the amount of flow that is sent along that path, and the arcs that become saturated. As can be seen in the table, the values~ of the encountered flows  are , , , , , , and~. These are the breakpoints of the cost function~, and the lengths of the augmenting paths equal the slopes of~ (see Figure~\ref{fig:example cost function}).

\begin{fig}
  \begin{minipage}{0.54\textwidth}
  	\GFX[width=\textwidth]{ExampleNetwork}
  	\caption{Minimum-cost flow network with master source~ and master sink~.}
  	\label{fig:example network}
  \end{minipage}
  \qquad
  \begin{minipage}{0.4\textwidth}
	\GFX[width=\textwidth]{ExampleCostFunction}
  	\caption{Cost function~.}
  	\label{fig:example cost function}
  \end{minipage}\\\vspace{0.5cm}
  \begin{minipage}{\textwidth}
\centering\newcommand{\CENTER}{@{\hspace{0.5ex}}c@{\hspace{0.5ex}}}
  \begin{tabular}{|@{\hspace{0.5ex}}l@{\hspace{0.5ex}}|\CENTER|\CENTER|\CENTER|\CENTER|\CENTER|\CENTER|}
    \hline
    \textbf{step}           &        &        &       &        &        &       \cr
    \hline
    \textbf{path}           &  &        &    &        &        &    \cr
    \hline
    \textbf{path length}    &        &        &       &        &        &      \cr
    \hline
    \textbf{amount of flow} &        &        &       &        &        &       \cr
    \hline
    \textbf{saturated arcs} &   &  &  &  &  &  \cr
    \hline
  \end{tabular}
\caption{The augmenting paths for Example~\ref{example}.}
\label{exampletable}    
  \end{minipage}
\end{fig}

\end{example}

With the following definition, we lay the foundation for distinguishing between original edges with perturbed costs and auxiliary edges whose costs are set to~.

\begin{definition}
Let  be an arbitrary flow. An empty arc~ in the residual network~ that does not correspond to an auxiliary edge is called a \emph{good arc}. We call~ a \emph{good flow} if  and if the previous path of~ contains a good arc in the previous residual network. Otherwise,  is called a \emph{bad flow}.
\end{definition}

Before we can derive a property of good arcs that are contained in the previous path of good flows, we need to show that for each flow value the minimum-cost flow is unique with probability~.

\begin{lemma}
\label{lemma:non zero cycle lengths}
For any real~ the probability that there exists a possible cycle whose costs lie in~ is bounded from above by~.
\end{lemma}

\begin{proof}
Assume that there exists a cycle~ whose costs lie in~. Then~ contains two nodes~ and~ and consists of a - path~ and a - path~.
Then  and  are two distinct - paths. Since~ has costs in~, the costs of~ and  differ by at most~.
Now Lemma~\ref{lemma:different path lengths} concludes the proof.
\end{proof}

According to Lemma~\ref{lemma:non zero cycle lengths} we can assume that the following property holds since it holds with a probability of 1.

\begin{property}
\label{property:non zero cycle lengths}
There exists no possible cycle with costs~.
\end{property}

With Property~\ref{property:non zero cycle lengths} we can show that the minimum-cost flow is unique for each value.

\begin{lemma}
\label{lemma:unique minimum cost flow}
For each value  there either exists no flow~ with  or there exists a unique minimum-cost flow~ with .
\end{lemma}

\begin{proof}
Assume that there exists a value  and two distinct minimum-cost flows  and  with . Let  be the set of edges on which  and  differ. We show in the following that the set  contains at least one undirected cycle~.
Since  and  are distinct flows, the set  cannot be empty. For , let us denote by  the flow entering  and by  the flow going out of~ ( and  are defined analogously). Flow conservation and  imply  for all . 
Now let us assume  does not contain an undirected cycle. In this case there must exist a vertex~ with exactly one incident edge in~. We will show that this cannot happen.

Assume  for some . Then the flows  and  differ on at least one edge~. Since this case implies , they also differ on at least one edge~ and both these edges belong to~. It remains to consider nodes~ with  and at least one incident edge in~. For such a node~ there exists an edge  (or ) with . It follows  (or ) which implies that there exists another edge  (or ) with .

For the flow~, which has the same costs as~ and~ and is hence a minimum-cost flow with  as well, we have  for all . The flow~ can therefore be augmented in both directions along . Due to Property~\ref{property:non zero cycle lengths}, augmenting  in one of the two directions along~ will result in a better flow. This is a contradiction.
\end{proof}

Now we derive a property of good arcs that are contained in the previous path of good flows.
This property allows us to bound the probability that one of the lengths  falls into a given interval of length~.

\begin{lemma}
\label{lemma:cost monotonicity}
Let~ be a predecessor of a good flow for which  holds Additionally, let~ be a good arc in the next path of~, and let~ be the edge in~ that corresponds to~. Now change the cost of~ to  () if  (), i.e., when  is a forward (backward) arc. In any case, the cost of arc~ increases. We denote the resulting flow network by~. Then . Moreover, the inequalities

hold.
\end{lemma}

\begin{proof}
Let~ and~ be the cost functions of the original network~ and the modified network~, respectively.
Both functions are of the form described in Lemma~\ref{lemma:cost function form}. In particular, they are continuous and the breakpoints correspond to the values of the flows  and  with  and , respectively.

We start with analyzing the case~. In this case, we set  and observe that increasing the cost of edge~ to~ cannot decrease the cost of any flow in . Hence, . Since flow~ does not use arc~, its costs remain unchanged, i.e., .

If~, then we set  for . This function is also piecewise linear and has the same breakpoints and slopes as~. Since the flow on edge~ cannot exceed the capacity~ of edge~ and since the cost on that edge has been reduced by~ in~, the cost of each flow is reduced by at most~ in~. Furthermore, this gain is only achieved for flows that entirely use edge~ like~ does. Hence,  and .

\begin{GFXFIG}[width=0.5\textwidth]{CostMonotonicity}
\caption{Cost function~ and function~.}
\label{fig:cost monotonicity}
\end{GFXFIG}

Due to , , and the form of both
functions, the left-hand derivative of~ at~ is at most the
left-hand derivative of~ at~ (see Figure~\ref{fig:cost
monotonicity}). Since~ is a breakpoint of~, this implies that~
is also a breakpoint of~ and that the slope of~ to the left 
of~ is at most the slope of~ to the left of~.
For the same reasons, the right-hand derivative of~ at~ is at
least the right-hand derivative of~ at~ and the slope 
of~ to the right of~ is at least the slope of~ to the right of~.
These properties carry over to~. Hence,  contains a flow~ with . Since  is a minimum-cost flow with respect to ,  is a minimum-cost flow with respect to , we have  and  for all possible flows~, Lemma~\ref{lemma:unique minimum cost flow} yields  and therefore . Recalling the fact that the slopes correspond
to shortest - path lengths, the stated chain of inequalities follows.
\end{proof}

Lemma~\ref{lemma:cost monotonicity} suggests Algorithm~\ref{reconstruct} () for reconstructing a flow~ based on a good arc~ that belongs to the shortest path in the residual network~ and on a threshold . The crucial fact that we will later exploit is that for this reconstruction the cost~ of edge~ does not have to be known.
(Note that we only need  for the analysis in order to show that the flow~ can be reconstructed.)

\begin{algorithm}[t]
  \caption{.}
  \begin{algorithmic}[1]
    \STATE let~ be the edge that corresponds to arc~ in the original network~

    \STATE change the cost of edge~ to  if~ is a forward arc or to  if~ is a backward arc

    \STATE start running the SSP algorithm on the modified network~

    \STATE stop when the length of the shortest - path in the residual network of the current flow~ exceeds~

    \STATE output~
  \end{algorithmic}
  \label{reconstruct}
\end{algorithm}


\begin{corollary}
\label{corollary:flow reconstruction}
Let~ be a predecessor of a good flow, let~ be a good arc in the next path of~, and let  be a real number. Then  outputs flow~.
\end{corollary}

\begin{proof}
By applying Lemma~\ref{lemma:cost monotonicity}, we obtain  and . Together with Corollary~\ref{corollary:path monotonicity}, this implies that  does not stop before encountering flow~ and stops once it encounters~. Hence,  outputs flow~. \end{proof}

Corollary~\ref{corollary:flow reconstruction} is an essential component of the proof of Theorem~\ref{maintheorem} but it only describes how to reconstruct predecessor flows~ of good flows with . In the next part of this section we show that
most of the flows are
good flows and that, with a probability of~, the inequality  holds for any flow~.

\begin{lemma}
\label{lemma:one empty arc}
In any step of the SSP algorithm, any - path in the residual network contains at least one empty arc.
\end{lemma}

\begin{proof}\renewcommand{\P}{P'}
The claim is true for the empty flow~. Now consider a flow~, its predecessor flow~, the path~, which is a shortest path in the residual network~, and an arbitrary - path~ in the current residual network~. We show that at least one arc in~ is empty.

For this, fix one arc~ from~ that is not contained in the current residual network~ since it became saturated by the augmentation along~. Let~ be the first node of~ that occurs in the sub-path~ of~, and let~ be the last node in the sub-path~ of~ that belongs to the sub-path~ of~ (see Figure~\ref{fig:one empty arc}). By the choice of~ and~, all nodes on the sub-path~ of~ except~ and~ do not belong to~. Hence, the arcs of~ are also available in the residual network~ and have
the same capacity in both residual networks~ and~.

\begin{GFXFIG}[width=0.6\textwidth]{OneEmptyArc}
\caption{Paths~ and~ in the residual network~.}
\label{fig:one empty arc}
\end{GFXFIG}

In the remainder of this proof,
we show that at least one arc of~ is empty. Assume to the contrary
that none of the arcs is empty in~ and, hence, in~. This implies that, for each arc~, the residual network~ also contains the arc~. Since~ is the shortest - path in~ and since the lengths of all possible - paths are pairwise distinct, the path~ is longer than~. Consequently, the path~ is longer than the path~. This contradicts the fact that flow~ is optimal since the arcs of path~ combined with the reverse arcs~ of all the arcs~ of path~ form a directed cycle~ in~ of negative costs. \end{proof}

We want to partition the interval  into small sub-intervals of length~ and treat the number of lengths  that fall into a given sub-interval as a binary random variable. This may be wrong if there are two possible - paths whose lengths differ by at most~. In this case whose probability tends to  (see Lemma~\ref{lemma:different path lengths}) we will simply bound the number of augmentation steps of the SSP algorithm by a worst-case bound according to the following lemma.

\begin{lemma}
\label{lemma:worst case number}
The number~ of flows encountered by the SSP algorithm is bounded by~. 
\end{lemma}

\begin{proof}
We call two possible residual networks equivalent if they contain the same arcs. Equivalent possible residual networks have the same shortest - path in common. The length of this path is also the same. Assume that for two distinct flows  with , the residual networks~ and~ are equivalent. We then have  =  and due to Corollary~\ref{corollary:path monotonicity},  for all . Property~\ref{property:different path lengths} then implies  for all  and especially , which is a contradiction. Therefore the number of equivalence classes is bounded by~ since there are~ original edges and at most~ auxiliary edges. This completes the proof. \end{proof}

\begin{lemma}
\label{lemma:upper bound bad flows}
There are at most~ bad flows~.
\end{lemma}

\begin{proof}
According to Lemma~\ref{lemma:one empty arc}, the augmenting path contains an empty arc~
in each step. If~ is an arc that corresponds to an auxiliary edge (this is the only case when~ is not a good arc), then~ is not empty after the augmentation. Since the SSP algorithm does not augment along arcs~ if~ is an arc that corresponds to an auxiliary edge, non-empty arcs that correspond to auxiliary edges cannot be empty a second time. Thus, there can be at most~ steps where the augmenting path does not contain a good arc. This implies that there are at most~ bad flows~. \end{proof}

We can now bound the probability that there is a flow~ whose previous path's length  falls into a given sub-interval of length~. Though we count bad flows separately, they also play a role in bounding the probability that there is a \emph{good} flow~ such that  falls into a given sub-interval of length~.

\begin{lemma}
\label{lemma:loser gap}
For a fixed real , let~ be the event that there is a flow~ for which , and let~ be the event that there is a bad flow~ for which . Then the probability of~ can be bounded by
.
\end{lemma}

\begin{proof}
Let  be the event that there is a good flow~ for which . Since , it suffices to show that . Consider the event that there is a good flow whose previous path's length lies in the interval . Among all these good flows, let~ be the one with the smallest value , i.e.,  is the first good flow~ encountered by the SSP algorithm for which , and let~ be its previous flow. Flow~ always exists since~ cannot be the empty flow~. Corollary~\ref{corollary:path monotonicity} and Property~\ref{property:different path lengths} yield . Thus, there can only be two cases: If , then~ is a bad flow by the choice of~ and, hence, event~ occurs. The interesting case, which we consider now, is when  holds. If this is true, then  due to .

As~ is a good flow, the shortest path in the residual network~ contains a good arc . Applying Corollary~\ref{corollary:flow reconstruction} we obtain that we can reconstruct flow~ by calling . The shortest - path~ in the residual network~ is the previous path of~ and its length equals~. Furthermore,  is of the form , where  and  are shortest paths in~ from~ to~ and from~ to~, respectively. These observations yield

where~ for some arc~ denotes the following event: The event~ occurs if , where~ is the length of the shortest - path that uses arc~ in~, the residual network of the flow~ obtained by calling the procedure . Therefore, the probability of event~ is bounded by

We conclude the proof by showing . For this, let~ be the edge corresponding to arc~ in the original network. If we fix all edge costs except cost~ of edge~, then the output~ of  is already determined. The same holds for the shortest - path in~ that uses arc~ since it is of the form  where  is a shortest - path in~ that does not use~ and where  is a shortest - path in~ that does not use~. The length~ of this path, however, depends linearly on the cost~. To be more precise, , where  is the length of~ plus the length of~ and where

Hence,  falls into the interval  if and only if~ falls into some fixed interval of length~. The probability for this is bounded by  as~ is drawn according to a distribution whose density is bounded by~. \end{proof}

\begin{corollary}
\label{corollary:expected number of SSP steps}
The expected number of augmentation steps the SSP algorithm performs is bounded by .
\end{corollary}

\begin{proof}
Let~ be the number of augmentation steps of the SSP algorithm. For reals , let~ and  be the events defined in Lemma~\ref{lemma:loser gap}, let~ be the number of flows  for which , and let  be the indicator variable of event~.


Since all costs are drawn from the interval , the length of any possible - path is bounded by~. Furthermore, according to Corollary~\ref{corollary:path monotonicity}, all lengths are non-negative (and positive with a probability of 1). Let~ denote the event that there are two possible - paths whose lengths differ by at most~. Then, for any positive integer~, we obtain

Consequently,

The second inequality is due to Lemma~\ref{lemma:loser gap} whereas the third inequality stems from Lemma~\ref{lemma:upper bound bad flows}. The claim follows since  for  in accordance with Lemma~\ref{lemma:different path lengths}.
\end{proof}

Now we are almost done with the proof of our main theorem.

\begin{proof}
Since each step of the SSP algorithm runs in time  using Dijkstra's algorithm (see, e.g.,
Korte~\cite{Korte:2007:COT:1564997} for details), applying Corollary~\ref{corollary:expected number of SSP steps} yields the desired result. \end{proof}





\section{Proof of the Lower Bound}
\label{sec:lower bound}





This section is devoted to the proof of Theorem~\ref{theorem:lower bound}. For
given positive integers~, , and 
let  and . In the following we assume that , such that we have . If , the lower bound on the number of augmentation steps from Theorem~\ref{theorem:lower bound} reduces to  and a simple flow network like the network~, as explained below, which we will use as initial network in case , with  nodes,  edges, and uniform edge costs proves the lower bound.  

We construct a flow
network with  nodes,  edges, 
and smoothing parameter~ on
which the SSP algorithm requires  augmentation steps in expectation. To be
exact, we show that for any realization of the edge costs 
for which there do not exist multiple paths with exactly the same costs (Property~\ref{property:different path lengths}) 
the SSP algorithm requires that many iterations. Since this happens with probability~1,
we will assume in the following that Property~\ref{property:different path lengths} 
holds without further mention. 

For the sake of simplicity we consider edge cost densities  instead of . This is an equivalent
smoothed input model because both types of densities can be transformed into
each other by scaling by a factor of~ and because the behavior of the SSP
algorithm is invariant under scaling of the edge costs. Furthermore, our
densities~ will be uniform distributions on intervals~ with lengths of
at least~. In the remainder of this section we only construct these
intervals~. Also, all minimum-cost flow networks constructed in this
section have a unique source node~ and a unique sink node~, which is
always clear from the context. The balance values of the nodes are defined as
 for all nodes~ and , that is, each -flow equals a maximum
--flow.

The construction of the desired minimum-cost flow network~ consists of three steps,
which we sketch below and describe in more detail thereafter. Given Property~\ref{property:different path lengths}, our choice of distributions for the edge costs ensures that the behavior of the SSP algorithm is the same for every realization of the edge costs.
\begin{enumerate}
\item In the first step we define a simple flow network~ with a source~ and a sink~ on which the SSP algorithm requires~ augmentation steps. 

\item In the second step we take a flow network~, starting with , as the basis for constructing a larger flow network~. We obtain the new flow network by adding a new source~, a new sink~, and four edges connecting the new source and sink with the old source and sink. Additionally, the latter two nodes are downgraded to ``normal'' nodes (nodes with a balance value of ) in~ (see Figure~\ref{fig:step II}). By a careful choice of the new capacities and cost intervals we can ensure the following property: First, the SSP algorithm subsequently augments along all paths of the form

where~ is an - path encountered by the SSP algorithm when run on the network~. Then, it augments along all paths of the form

where~ is again an - path encountered by the SSP algorithm when run on the network~. Hence, by adding two nodes and four edges we double the number of iterations the SSP algorithm requires. For this construction to work we have to double the maximum edge cost of our flow network. Hence, this construction can be repeated  times, yielding an additional factor of  for the number of iterations required by the SSP algorithm.

\item In the third step we add a global source~ and a global sink~ to the flow network~ constructed in the second step, and add four directed paths of length , where each contains  new nodes and has exactly one node in common with .
The first path will end in , the second path will end in , the third path will start in , and the fourth path will start in . We will also add an arc from~ to every new node in the first two paths and an arc from every new node in the last two paths to~ (see Figure~\ref{fig:step III}). We call the resulting flow network~. By the right choice of the edge costs and capacities we will ensure that for each - path~ in~ encountered by the SSP algorithm on~ the SSP algorithm on~ encounters~ augmenting paths having~ as a sub-path and~ augmenting paths having~ as a sub-path. In this way, we gain an additional factor of~ for the number of iterations of the SSP algorithm.
\end{enumerate}

In the following we say that the SSP algorithm \emph{encounters} a path~ on a flow network~ if it augments along~
when run on~.

\paragraph{Construction of~.}
For the first step, consider two sets  and  of~ nodes and an arbitrary set  containing exactly  edges. The initial flow network~ is defined as  for  and

The edges~ from~ have capacity~ and costs from the interval . 
The edges  have a capacity equal to the out-degree of~, 
the edges  have a capacity equal to the in-degree of  and both have costs from the interval ] (see Figure~\ref{fig:step I}).
(Remember that we use uniform distributions on the intervals .)
\begin{fig}
  \GFX[width=0.5\textwidth]{Initialgraph}
 \caption[]
   {Example for  with  and  with capacities different from 1 shown next to the edges and the cost intervals shown below each edge set.} 
  \label{fig:step I}
\end{fig}

\begin{lemma}
\label{lemma:step I}
The SSP algorithm requires exactly~ iterations on~ to obtain a maximum --flow. Furthermore all augmenting paths it
encounters have costs from the interval~.
\end{lemma}
\begin{proof}
First we observe that the SSP algorithm augments only along paths that are of the form~ for some  and :
Consider an arbitrary augmenting path~ the SSP algorithm encounters and assume for contradiction that~ is not of this form.
Due to the structure of~, the first two edges of~ are of the form  and  for some  
and . The choice of the capacities ensures that the edge~ cannot be fully saturated if the edge~ is not.
Hence, when the SSP algorithm augments along~, the edge~ is available in the residual network.
Since this edge is not used by the SSP algorithm, the sub-path~ has smaller costs than the edge~.
This means that the distance of~ to the sink~ in the current residual network is smaller than in the initial residual network
for the zero flow. This contradicts Lemma~\ref{lemma:distance monotonicity}.

Since every path the SSP algorithm encounters on~ is of the form~, every such path consists of two edges with
costs from the interval~ and one edge with costs from the interval~. This implies that the total costs of any such path 
lie in the interval~.

The choice of capacities ensures that on every augmenting path of the form~ the edge~ is a bottleneck
and becomes saturated by the augmentation. As flow is never removed from this edge again, there is a one-to-one correspondence between
the paths the SSP algorithm encounters on~ and the edges from~. This implies that the SSP algorithm encounters
exactly~ paths on~. 
\end{proof}

\paragraph{\boldmath Construction of~ from~.}
Now we describe the second step of our construction more formally. Given a flow network  with a source~ and a sink~, we define , where  and

Let~, which is the value of the maximum - flow in~. The new edges  have capacity  and costs from the interval . The new edges  also have capacity , but costs from the interval  (see Figure~\ref{fig:step II}).


\begin{fig}
  \GFX[width=0.5\textwidth]{Iteration1}
 \caption[]
   { with  as sub-graph with edge costs next to the edges.}
  \label{fig:step II}
\end{fig}

Next we analyze how many iterations the SSP algorithm requires to reach a maximum - flow in~ when run on the network~.
Before we can start with this analysis, we prove the following property of the SSP algorithm.
\begin{lemma}
\label{lemma: shortest backward path} 
After augmenting flow via a cheapest --path  in a network without a cycle with negative total costs,  is a cheapest --path. 
\end{lemma}
\begin{proof}
Since we augmented along , all edges of  will be part of the residual network.  will therefore be a feasible --path.
Assume that after augmenting along~ there exists a --path~
that is cheaper than~.
Let us take a look at the multi-set , which contains every arc~ twice.
The total costs of this multi-set are negative because
 
by the assumption that~ is cheaper than~.
Furthermore, for each node the number of incoming and outgoing arcs from~ is the same.
This property is preserved if we delete all pairs of a forward arc~ and the corresponding 
backward arc~ from~, resulting in a multi-set~.
The total costs of the arcs in~ are negative because they equal the total costs of the arcs in~.  

For every arc~ that did not have positive residual capacity before augmenting along~, the arc~ must be part of  and therefore be part of~ as well.
This is due to the fact that only for arcs~ with~ the residual capacity increases when augmenting along .
Since all such pairs of arcs are deleted, the set~ will only contain arcs that had a positive residual capacity
before augmenting along~. Since each node has the same number of outgoing and
incoming arcs from~, we can partition~ into subsets, where the arcs in each subset
form a cycle. Since the total costs of all arcs are negative at
least one of these cycles has to have negative costs, which is a contradiction.
\end{proof}

Since during the execution of the SSP algorithm all residual networks have conservative costs on the arcs, Lemma~\ref{lemma: shortest backward path} always applies.
\begin{lemma}\label{lemma:CostsGi}
Let~.
All --paths the SSP algorithm encounters when run on the network  have costs from the interval~.
Furthermore the SSP algorithm encounters on  the network  twice as many paths as on the network .
\end{lemma}
\begin{proof}
We prove the first half of the lemma by induction over~.
In accordance with Lemma~\ref{lemma:step I}, all paths the SSP algorithm encounters on~ have costs from the interval~.

Now assume that all paths the SSP algorithm encounters in~, for some~, have costs from the interval~.
We distinguish between three different kinds of --paths in .
\begin{definition}
We classify the possible --paths~ in~ as follows.
\begin{enumerate}\setlength{\itemsep}{0em}
  \item If , then~ is called a \emph{type-1-path}.
  \item If  or , then~ is called a \emph{type-2-path}.
  \item If , then~ is called a \emph{type-3-path}.
\end{enumerate}
\end{definition}
For any type-2-path  we have 


Since due to Lemma~\ref{lemma:distance monotonicity} the distance from 
to  does not decrease during the run of the SSP algorithm, the SSP
algorithm will only augment along a type-3-path~ once the
edge~ is saturated. Otherwise the
--sub-path of  could be replaced by the edge 
to create a cheaper path. Once the edge  has been saturated,
the SSP algorithm cannot augment along type-1-paths anymore.
Therefore, the SSP algorithm will augment along all type-1-paths it encounters
before it augments along all type-3-paths it encounters.
 
Since during the time the SSP algorithm augments along type-1-paths no other
augmentations alter the part of the residual network corresponding to~,
the corresponding sub-paths~ are paths in~ that the
SSP algorithm encounters when run on the network~.
Using the induction hypothesis, this yields that all type-1-paths the SSP algorithm encounters have costs
from the interval

Since all of these type-1-paths have less costs than the two type-2-paths, the
SSP algorithm will augment along them as long as there still exists an
augmenting --sub-path . Due to the choice of capacities this is
the case until both edges  and  are saturated.
Therefore, the SSP algorithm will not augment along any type-2-path.

When analyzing the costs of type-3-paths, we have to look at the --sub-paths.
Let  be the number of --paths the SSP algorithm encounters when
run on the network  and let  be the corresponding paths
in the same order, in which they were encountered.
Then Lemma~\ref{lemma: shortest backward path} yields that for any  after augmenting along the paths  the cheapest
--path in the residual network is . Property~\ref{property:different path lengths} yields that it is the only cheapest path. Also
the residual network we obtain, if we then augment via
 is equal to the residual network obtained, when
only augmenting along the paths . Starting with  this
yields that the --sub-paths corresponding to the type-3-paths the SSP
algorithm encounters are equal to
.
By induction the cost of each such path  lies in . This
yields that every type-3-path the SSP algorithm encounters has costs from the interval


The previous argument also shows that the SSP algorithm encounters on~ twice as many paths as on~
because it encounters~ type-1-paths, no type-2-path, and~ type-3-paths, where~ denotes the
number of paths the SSP algorithm encounters on~. 
\end{proof}

Since the SSP algorithm augments along  paths when run on the network , it will augment along  paths when run on the network .
Note, that at the end of the SSP algorithm, when run on  for , only the  arcs incident to  and  carry flow. 


\paragraph{Construction of~ from~.}
Let , which is the value of a maximum - flow in . We will now use  to define  as follows
(see also Figure~\ref{fig:step III}).
\begin{itemize}
\setlength{\itemsep}{0cm}
\item , with , , , and . .\newline
\item  contains the edges , , with cost interval  and infinite capacity,
, , with cost interval  and capacity , and  with cost interval  and infinite capacity.\newline
\item  contains the edges , , with cost interval  and infinite capacity,
, , with cost interval  and capacity , and  with cost interval  and infinite capacity.\newline
\item  contains the edges , , with cost interval  and infinite capacity,
, , with cost interval  and capacity , and  with cost interval  and infinite capacity.\newline
\item  contains the edges , , with cost interval  and infinite capacity,
, , with cost interval  and capacity , and  with cost interval  and infinite capacity.
\end{itemize}

\begin{fig}
  \GFX[width=0.95\textwidth]{Iteration2}
  \caption{ with  as sub-graph with approximate edge costs on the edges. A value  below an edge  means the the cost of  is drawn uniformly at random from the interval .}
  \label{fig:step III}
\end{fig}

\begin{theorem}
The SSP algorithm encounters  paths on the network~.
\end{theorem}

\begin{proof}
We categorize the different --paths the SSP algorithm encounters on  by the node after  and the node before~.
Each such --path can be described as an -, -, -, or -path for some .

All --paths encountered by the SSP algorithm, when run on , have costs from the interval~ in accordance with Lemma~\ref{lemma:CostsGi}.
For any~, the costs of the ---path and the ---path lie
in  with  and the costs of the ---path and the
---path lie in  with .
Furthermore .

Therefore, the SSP algorithm will
only augment along -paths if no -paths are available.
Also, any -path is shorter than any -path and any -path is shorter than any
-path. Finally, any -path is shorter than any -path or -path.
Therefore, the SSP algorithm will start with augmenting along -paths. After augmenting along -paths it will augment
along -paths and after augmenting along -paths it will augment along -paths.
Due to the choice of the capacities we can see that once the SSP algorithm starts augmenting along an -path it keeps augmenting
along -paths until there is no --path in the residual network that lies completely in the sub-network corresponding
to . Also, once the SSP algorithm starts augmenting along an -path it keeps augmenting along -paths until
there is no --path in the residual network that lies completely in the sub-network corresponding  to .
After the SSP algorithm augmented along the last -path the residual network in the sub-network corresponding to  is equal
to the residual network of a maximum flow in . After the SSP algorithm augmented along the last -path the residual network
in the sub-network corresponding to  is equal to . We can see that the SSP algorithm augments along an -path for every path  it encounters on  and along an
-path for the backwards path  of every path  it encounters on .
Therefore, the SSP-algorithm will augment  times along paths corresponding to the paths it encounters on  and  times along
paths corresponding to the backward paths of these paths and therefore augment along  times as many paths in
 as in .
\end{proof}

To show that  contains  nodes and  edges, we
observe that  has  nodes and  edges, the  iterations to
create  add a total of  nodes and  edges and the construction
of  from  adds  nodes and  edges. This gives a total of
 nodes and  edges. Since  and ,  has  nodes and  edges and forces the SSP
algorithm to encounter  paths on . For  this lower
bound shows that the upper bound of  augmentation steps in
Theorem~\ref{maintheorem} is tight.

\section{Smoothed Analysis of the Simplex Algorithm}
\label{sec:simplex}

In this section we describe a surprising connection between our result about the SSP algorithm and the smoothed analysis of the
simplex algorithm. Spielman and Teng's original smoothed analysis~\cite{DBLP:journals/jacm/SpielmanT04} as well as 
Vershynin's~\cite{DBLP:journals/siamcomp/Vershynin09} improved analysis are based on the shadow vertex method. To describe this
pivot rule, let us consider a linear program with an objective function~ and a set of constraints~. Let us
assume that a non-optimal initial
vertex~ of the polytope~ of feasible solutions is given. The shadow vertex method computes an objective function~ that is
optimized by~. Then it projects the polytope~ onto the 2-dimensional plane that is spanned by the vectors~ and~. If we assume
for the sake of simplicity that~ is bounded, then the resulting projection is a polygon~.

The crucial properties of the polygon~ are as follows: both the projection of~ and the projection of the optimal solution~ are vertices of~, and every edge of~ corresponds to an edge of~. The shadow vertex method follows the edges of~ from the projection
of~ to the projection of~. The aforementioned properties guarantee that this corresponds to a feasible walk on the polytope~. 

To relate the shadow vertex method and the SSP algorithm, we consider the canonical linear program for the maximum-flow problem with one
source and one sink. In this linear program, there is a variable for each edge corresponding to the flow on that edge.
The objective function, which is to be
maximized, adds the flow on all outgoing edges of the source and subtracts the flow on all incoming edges of the source. There are constraints for each edge 
ensuring that the flow is non-negative and not larger than the capacity, and there is a constraint for each node except the source and the sink ensuring
Kirchhoff's law.

The empty flow~ is a vertex of the polytope of feasible solutions. In particular, it is a feasible solution with minimum costs. Hence, letting~ be
the vector of edge costs is a valid choice in the shadow vertex method. For this choice every feasible flow~ is projected to the pair~. 
Theorem~\ref{thm:AllFlowsOpt} guarantees that the cost function depicted in Figure~\ref{fig:example cost function} forms the lower envelope of the  
polygon that results from projecting the set of feasible flows. There are two possibilities for the shadow vertex method for the first step: it can choose
to follow either the upper or the lower envelope of this polygon. If it decides for the lower envelope, then it will encounter exactly the same sequence of flows
as the SSP algorithm.

This means that Theorem~\ref{maintheorem} can also be interpreted as a statement about the shadow vertex method applied to the maximum-flow linear
program. It says that for this particular class of linear programs, the shadow vertex method has expected polynomial running time even if the linear program is chosen
by an adversary. It suffices to perturb the costs, which determine the projection used in the shadow vertex method. Hence, if the projection
is chosen at random, the shadow vertex method is a randomized simplex algorithm with polynomial expected running time
for any flow linear program. 

In general, we believe that it is an interesting question to study whether the strong assumption in Spielman and Teng's~\cite{DBLP:journals/jacm/SpielmanT04} and 
Vershynin's~\cite{DBLP:journals/siamcomp/Vershynin09} smoothed analysis that all coefficients in the constraints are perturbed is necessary. In particular, we find
it an interesting open question to characterize for which class of linear programs it suffices to perturb only the coefficients in the objective
function or just the projection in the shadow vertex method to obtain polynomial smoothed running time.

Two of us have studied a related question~\cite{BrunschR13}. 
We have proved that the shadow vertex method can be used
to find short paths between given vertices of a polyhedron. Here, short
means that the path length is~, where~ denotes the number of
variables,  denotes the number of constraints, and~ is a parameter 
that measures the flatness of the vertices of the polyhedron.
This result is proven by a significant extension of the analysis presented in this article.


\begin{thebibliography}{99}

\bibitem{DBLP:books/daglib/0069809}
Ravindra K. Ahuja, Thomas L. Magnanti, and James B. Orlin.
\newblock {\em Network flows -- theory, algorithms and applications}.
\newblock Prentice Hall, 1993.

\bibitem{BeierV04}
Ren{\'e} Beier and Berthold V{\"o}cking.
\newblock Random knapsack in expected polynomial time.
\newblock {\em Journal of Computer and System Sciences}, 69(3):306--329, 2004.

\bibitem{DBLP:journals/siamcomp/BeierV06}
Ren{\'e} Beier and Berthold V{\"o}cking.
\newblock Typical properties of winners and losers in discrete optimization.
\newblock {\em SIAM Journal on Computing}, 35(4):855--881, 2006.

\bibitem{BrunschR13}
Tobias Brunsch and Heiko R{\"o}glin.
\newblock Finding Short Paths on Polytopes by the Shadow Vertex Algorithm.
\newblock In {\em Proceedings of the 40th International Colloquium on Automata, Languages and Programming (ICALP)}, pages 279--290, 2013.

\bibitem{BusGow60}
Robert G. Busacker and Paul J. Gowen.
\newblock A procedure for determining a family of minimum-cost network flow
  patterns.
\newblock Technical Paper 15, Operations Research Office, Johns Hopkins University, 1960.

\bibitem{CLRS}
Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. 
\newblock Introduction to Algorithms.
\newblock MIT Press, 2009.

\bibitem{DasGup97}
Ali Dasdan and Rajesh K. Gupta.
\newblock Faster maximum and minimum mean cycle algorithms for
  sys\-tem-per\-for\-mance analysis.
\newblock {\em IEEE Transactions on Computer-Aided Design of Integrated
  Circuits and Systems}, 17:889--899, 1997.

\bibitem{DBLP:journals/jacm/EdmondsK72}
Jack Edmonds and Richard M. Karp.
\newblock Theoretical improvements in algorithmic efficiency for network flow
  problems.
\newblock {\em Journal of the ACM}, 19(2):248--264, 1972.

\bibitem{ForFul62}
Lester R. Ford, Jr. and Delbert R. Fulkerson.
\newblock {\em Flows in Networks}.
\newblock Princeton University Press, 1962.

\bibitem{Ful61}
Delbert R. Fulkerson.
\newblock An out-of-kilter algorithm for minimal cost flow problems.
\newblock {\em Journal of the SIAM}, 9(1):18--27, 1961.

\bibitem{DBLP:journals/jacm/GoldbergT89}
Andrew V. Goldberg and Robert E. Tarjan.
\newblock Finding minimum-cost circulations by canceling negative cycles.
\newblock {\em Journal of the ACM}, 36(4):873--886, 1989.

\bibitem{GolTar90}
Andrew V. Goldberg and Robert E. Tarjan.
\newblock Finding minimum-cost circulations by successive approximation.
\newblock {\em Mathematics of Operations Research}, 15(3):430--466, 1990.

\bibitem{Iri60}
Masao Iri.
\newblock A new method for solving transportation-network problems.
\newblock {\em Journal of the Operations Research Society of Japan},
  3(1,2):27--87, 1960.

\bibitem{Jew62}
William S. Jewell.
\newblock Optimal flow through networks.
\newblock {\em Operations Research}, 10(4):476--499, 1962.





\bibitem{Kir14}
P{\'e}ter Kov{\'a}cs.
\newblock Minimum-cost flow algorithms: an experimental evaluation.
\newblock {\em Optimization Methods and Software}, DOI: 10.1080/10556788.2014.895828, 2014.



\bibitem{Kle67}
Morton Klein.
\newblock A primal method for minimal cost flows with applications to the
  assignment and transportation problems.
\newblock {\em Management Science}, 14(3):205--220, 1967.

\bibitem{Korte:2007:COT:1564997}
Bernhard Korte and Jens Vygen.
\newblock {\em Combinatorial Optimization: Theory and Algorithms}.
\newblock Springer, 4th edition, 2007.

\bibitem{MR}
Bodo Manthey and Heiko R\"oglin.
\newblock Smoothed analysis: analysis of algorithms beyond worst case.
\newblock {\em it -- Information Technology}, 53(6):280-286, 2011.


\bibitem{Min60}
George J. Minty.
\newblock Monotone networks.
\newblock In {\em Proceedings of the Royal Society of London A}, pages
  194--212, 1960.

\bibitem{Orl84}
James B. Orlin.
\newblock Genuinely polynomial simplex and non-simplex algorithms for the
  minimum cost flow problem.
\newblock Technical report, Sloan School of Management, MIT, Cambridge, MA,
  1984.
\newblock Technical Report No. 1615-84.

\bibitem{Orl93}
James B. Orlin.
\newblock A faster strongly polynomial minimum cost flow algorithm.
\newblock {\em Operations Research}, 41(2):338--350, 1993.

\bibitem{DBLP:journals/algorithmica/RadzikG94}
Tomasz Radzik and Andrew V. Goldberg.
\newblock Tight bounds on the number of minimum-mean cycle cancellations and
  related results.
\newblock {\em Algorithmica}, 11(3):226--242, 1994.

\bibitem{DBLP:journals/jacm/SpielmanT04}
Daniel A. Spielman and Shang-Hua Teng.
\newblock Smoothed analysis of algorithms: Why the simplex algorithm usually
  takes polynomial time.
\newblock {\em Journal of the ACM}, 51(3):385--463, 2004.

\bibitem{SpielmanT09}
Daniel A. Spielman and Shang-Hua Teng.
\newblock Smoothed analysis: an attempt to explain the behavior of algorithms
  in practice.
\newblock {\em Communications of the ACM}, 52(10):76--84, 2009.

\bibitem{DBLP:journals/combinatorica/Tardos85}
{\'E}va Tardos.
\newblock A strongly polynomial minimum cost circulation algorithm.
\newblock {\em Combinatorica}, 5(3):247--256, 1985.

\bibitem{DBLP:journals/siamcomp/Vershynin09}
Roman Vershynin.
\newblock Beyond Hirsch conjecture: Walks on random polytopes and smoothed
  complexity of the simplex method.
\newblock {\em SIAM Journal on Computing}, 39(2):646--678, 2009.

\bibitem{Vyg02}
Jens Vygen.
\newblock On dual minimum cost flow al\-go\-ri\-thms.
\newblock {\em Mathematical Methods of Operations Research}, 56(1):101--126,
  2002.

\bibitem{Zad73}
Norman Zadeh.
\newblock A bad network problem for the simplex method and other minimum cost
  flow algorithms.
\newblock {\em Mathematical Programming}, 5(1):255--266, 1973.

\end{thebibliography}

\end{document}
