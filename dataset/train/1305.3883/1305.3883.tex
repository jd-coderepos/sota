This section details on implementation of our framework and provides a set of experiments to validate the approach.
\subsection{Implementation}
From the implementation perspective, the present work is composed of two major components- STAC and TAGA. STAC is implemented in Caml, using Frama-C framework. Details of its implementation can be found in \cite{dumitru_tds10}. After the source code is analyzed by STAC, we get all the information that we require to perform dynamic analysis. For a given vulnerable statement, we get a set of corresponding TDSs. We select a TDS which has maximum unique nodes to reach vulnerable statement. The reason for doing so is that smaller TDS may be very trivial or may provide less precise path. \par Dynamic component TAGA is composed of instrumented binary of the program, GA to generate inputs and an interface to communicate with a debugger to get after-crash information. In this study, we choose to work with GDB as our preferred debugger. As TDS includes control flow of the program, we get to know which branch of a conditional statement is executed. This information is used by our fitness function. Therefore, based on a particular TDS for a particular vulnerability path, we instrument lines in source code corresponding to the chosen TDS. For example, for the code given in listing \ref{fig:cCode}, one of the TDSs that we select is $\langle21,5,7,8\rangle$ for the vulnerable statement \texttt{strcpy(bp, login)}. Therefore, we instrument statements after each of these labels- 21, 5, 7, 8. In this way, at runtime, we get execution trace of the program in terms of executed statement's frequency.\par GA is implemented as Python module. Inputs to GA module are instrumented binary and regular expressions to generate inputs. Regular expressions are constructed based on the static analysis of the program which extract information on constraints e.g. character matching in \texttt{IF} statements. Such characters, along with other ASCII characters, are included in regular expression to help GA generating valid inputs faster. GA is run until we get \texttt{SIGSEGV} signal or a predefined iteration threshold is reached (1000 iterations in our experimental setup). We look for \texttt{SIGSEGV} signal because BoF will result in invalid memory reference or segmentation fault. Once we get malicious inputs corresponding to \texttt{SIGSEGV} signal, with the help of another Python module, we run the binary with GDB to get more information which is useful for understanding the impact of analysis on exploit generation (see section \ref{sec:vulnExploit}). Using such information, we can infer as how easy (or difficult) it is to write a real exploit for the vulnerability.
\subsection{Experimentation}
For empirical results, we experiment with Verisec benchmark suite \cite{verisec08}. The suite consists of snippets of open source programs containing BoF vulnerabilities of varied difficulties. For us the level of difficulty is directly proportional to the manipulation done on the tainted input by the program i.e. if there are checks on the input before it reaches the vulnerable statement, it is more difficult to generate such input. From this perspective, we find that Verisec suite has programs as simple as \texttt{bind-> CVE-2001-001-> nslookupComplain-small\_bad.c, gxine-> CVE-2007-0406-> main, Samba-> CVE-2007-0453} etc., wherein generating a larger \emph{random} string overflows the buffer, to as hard as \texttt{sendmail-> CVE-2003-0681-> buildfname}, \texttt{edbrowse-> CVE-2006-6909-> ftpls->\\ strchr\_bad.c} etc. wherein input should contain (or does not contain) specific characters (at specific positions) in order to reach the vulnerable statement. 

There are many programs which contain BoF vulnerability mainly due to \emph{off-by-one} error. We could not experiment with such programs as gcc 4.4.1 compiles the binaries such that vulnerable buffer does not appear just above the saved \texttt{frame pointer} (ebp). This makes it impossible to overwrite last byte of saved ebp which is the technique to exploit \emph{off-by-one} error \cite{klog_offByone99}. Therefore in practice, there is no \emph{off-by-one} error as such and without the dynamic analysis, this would have been a false positive. 

Table \ref{tab:result} shows the findings of our analysis on three programs which do string (inputs) manipulations before letting it reach the vulnerable statement. In order to evaluate the gain by including TDS with GA, we compare our results with two other approaches- random fuzzing approach and code coverage based GA approach, similar to \cite{Grosso_GAbof04}. However, even for random approach, we use the same regular expression that we use in our proposed approach to generate the random inputs i.e. random fuzzing is not completely random. For the second approach, we use \emph{gcov} tool for calculating code-coverage. In this case, the fitness function depends on percentage of code covered by an input and number of times a vulnerable statement is executed (and therefore, reached). We do not use any specific path (slicing) to reach vulnerable statement. The weights are selected as per heuristics discussed in \cite{Grosso_GAbof04}.


\begin{table}[h]
\caption{List of the programs used in experimentation}
\scriptsize
\begin{tabular}{p{0.5cm}|p{1.6cm}|p{1.9cm}|p{0.6cm}|p{1.8cm}|p{1.0cm}|p{1.2cm}|p{1.2cm}}
\hline S.No. & Application & Name & \# LoC & Constraints & TDS + GA & coverage + GA & Random inputs \\
\hline 1 & sendmail & mime\_fromqp & 65 &'=n' & 20 & 26 &243\\
       2 & sendmail & buildfname & 52 &'\&' and not(,;\%)  & 6 & 10 & 34\\
       3 & edbrowse & ftpls & 49 & '-{-} ' (in the beginning) & 35 & * & * \\
\hline
 \end{tabular}
\label{tab:result}
\end{table}


In the table, columns 2--3 denote the path of the vulnerable program in the Verisec suite. \emph{lines of code} parameter is given in column 4. Column 5 shows constraints that an input must satisfy in order to reach vulnerable statement. Column 6 shows the number of iterations (generations) taken by TDS based GA to generate inputs that crash the application. These numbers are average taken over 20 different runs of GA. Column 7 shows the same for coverage based GA. Last column shows the number of iteration taken by random fuzzing approach. A noticeable difference (shown as asterisk) comes out in the case of \emph{edbrowse} program. In this case, out of 20 times, coverage based GA could generate malicious inputs only 3 times and random fuzzing could generate malicious inputs only 2 times. This comparison shows the effectiveness of GA enabled inputs generation \emph{viz-a-viz} randomly generated inputs, specially in the case, when we have knowledge about the precise path to reach the vulnerable statement by means of TDS. The experiments also show that even for the small programs, data- and control-flow assisted GA outperforms other similar approaches\footnote{For larger programs, the cyclomatic complexity will be high which will further widen the gap.}.

\subsection{Vulnerability Exploitability}\label{sec:vulnExploit}
Next step in vulnerability analysis is to check if the vulnerability is exploitable in real world by generating exploits. Generating exploits for a stack BoF vulnerability involves getting information about the execution stack when the buffer overflow occurs. When we get a \texttt{SIGSEGV} signal on a particular input, another python module is used to run the program  with GDB to collect after-the-crash information which includes various stack register contents e.g. \emph{return pointer, stack pointer, frame pointer} etc., offset of input that caused overflowing \emph{saved return address}. The purpose of getting this information is to further validate the exploitability of the vulnerability (explained below). Following we show a typical output of our tool for the program at S. No. 3 in the table. In that program, there exists a BoF when \texttt{strcpy()} is called with a fixed length buffer \texttt{user[USERSZ]} and user controlled input. In order to reach the \texttt{strcpy()} statement, the input string must have '\texttt{-- }' as first three characters. For convenience, we denote \texttt{<space>} by \texttt{S} in the output shown in figure \ref{fig:out}.
\begin{figure}[h]
 \begin{Verbatim}[frame=single,numbers=left,fontsize=\scriptsize]
Generation# 35
Malicious inputs: --S1--*an1Lengths:  107
Calling GDB...Returned from GDB..
....
EIP is overwritten by:  a*a-  at index:  68
EBP is overwritten by:  *a1*  at index:  64
ESP is pointing to: a*a-\end{Verbatim}
\caption{Output of the tool.}\label{fig:out}
\end{figure}
Line 2-3 shows the malicious input that caused the program to crash, followed by its length 107. Line \# 7 shows the status of \texttt{eip} which is overwritten by \texttt{a*a-} at an offset 68 in the string and line 9 shows the contents pointed by \texttt{esp} at offset 72. With this information, one can construct a real exploit with the following skeleton:
\begin{Verbatim}[fontsize=\small]
<--S...Ax67...><4 bytes address to 'jump esp' instruction>
<...shellcode..(starting at 72th byte>
\end{Verbatim}
Based on this information, we can infer that it is easy to exploit \texttt{edbrowse} program. On the other hand, in the case of \texttt{ mime\_fromqp}, we find it difficult to exploit as values of \texttt{eip, esp} were not always affected \emph{meaningfully} by the user controlled input which makes it hard to construct an  exploit.
