[{'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'InfiMM-Eval', 'Metric': 'Overall score', 'Score': '26.84'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'InfiMM-Eval', 'Metric': 'Deductive', 'Score': '26.77'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'InfiMM-Eval', 'Metric': 'Abductive', 'Score': '35.97'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'InfiMM-Eval', 'Metric': 'Analogical', 'Score': '18.61'}}, {'LEADERBOARD': {'Task': 'Visual Question Answering (VQA)', 'Dataset': 'InfiMM-Eval', 'Metric': 'Params', 'Score': '9B'}}]
