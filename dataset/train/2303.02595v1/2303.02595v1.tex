\section{Experiment and Discussion}

In this chapter, we perform unsupervised anomaly localization experiments on MVTec Anomaly Detection Dataset\cite{MVTecAD} (MVTecAD) and BeanTech Anomaly Detection Dataset\cite{VT-ADL} (BTAD). 
MVTecAD contains 15 categories of industrial defect images, five of which are textural images and the other ten are object images. The object images contain three classes (grid, metal nut, screw) without rough registration and one class (hazelnut) without fine registration, and we will discuss these cases in \cref{Sec45}.
The BTAD contains three types of real-world and industry-oriented textural images, which is more challenging for pixel-level localization.

All experiments take Area Under the Receiver Operating characteristic Curve (AUROC) and Area Under the Per Region Overlap (AUPRO) as evaluation metrics.
AUROC is the most widely used anomaly evaluation metric, and higher values indicate that various thresholds have less impact on performance. However, AUROC prefers larger anomalies and may fail in small proportions of anomalies. 
Thus, we further evaluate AUPRO for localization metric, similar to Intersection Over Union (IoU) commonly used in semantic segmentation. Detailed definitions can be found in \cite{MVTecAD}.


\subsection{Complexity Analysis}\label{Sec41}
\begin{figure}
    \centering


    \includegraphics[width=0.9\linewidth]{Fig/Fig5-v3.pdf}
    \caption{Analysis of model complexity for various depths.
        The bars correspond to the Training Memory Usage (GB) in the left vertical coordinate, while the line graph and horizontal lines relate to the Model Parameters (M) on the other side. 
        For each depth , the left bar presents the normalizing flow implemented based on \textit{autoFlow} framework with memory-saving tricks, while the right is implemented by PyTorch with auto-differentiation. 
    }
    \label{fig5}
\end{figure}

The normalizing flow based on \cref{eq3:affine_forward,eq4:affine_inverse} is computationally invertible, which indicates that only one copy of the variables is necessary for all stages.
This feature decreases the memory footprint during backpropagation from linear to constant complexity. We have analyzed the above characteristics based on a fixed number of pyramid layers , image resolution with  , and channels , then changed the number of stacked layers  to explore the trends of memory usage and model parameters.
The forward and memory-saving backpropagation is implemented based on the self-developed PyTorch-based\cite{Pytorch} framework \textit{autoFlow}.
All indicators are recorded during steady-state training, then plotted as bar and line graphs, as shown in \cref{fig5}.


The memory usage based on auto-differentiation increases linearly with depth , while the implementation based on normalizing flow achieves approximate depth-independent memory usage.
The memory superiority enables the proposed method to be trained in memory-constrained devices below 4G without powerful hardware.
The line graph shows the exponential trends between model parameters and depth, while the horizontal line represents the parameters of the usual pre-trained model.
We mainly adopt methods with  or even shallower, where the number of parameters is far smaller than popular pre-training-based methods.
In summary, in scenarios of memory constraint, the proposed PyramidFlow enables dealing with larger images and requires fewer parameters than others.


\subsection{Study on Volume Normalization}\label{Sec42}
In this subsection, based on MVTecAD, we investigate the impact of volume normalization on generalization.
The experiment without data augmentation, fixed pyramid layers , channels , and linear interpolated image to .
During the training, the volume normalization applies sample mean normalization and updates the running mean with 0.1 momenta, while in the testing, the volume normalization is based on the running mean.
We sufficiently explored the volume normalization methods proposed in \cref{Sec32}. Some representative categories are shown as \cref{tab1}.

\begin{table}[htbp]
    \centering
    \setlength{\abovecaptionskip}{0.cm} \setlength{\belowcaptionskip}{-0.3cm} \caption{Quantitative results of CVN and SVN on different categories. For each case in the table, the first column is \colorbox{green!5}{Pixel-AUROC\%} and the second is \colorbox{blue!5}{AUPRO\%}, while the values within parentheses represent the relative improvement.}

    \resizebox{.45\textwidth}{!}{
        
\begin{tabular}{c>{\columncolor{green!5}}c>{\columncolor{blue!5}}c>{\columncolor{green!5}}c>{\columncolor{blue!5}}c}
    \toprule
    \multirow{2}[4]{*}{\textbf{Classes}} & \multicolumn{2}{c}{\textbf{CVN}} & \multicolumn{2}{c}{\textbf{SVN}} \\
    \cmidrule{2-5}    \multicolumn{1}{c}{} & AUROC & AUPRO & AUROC & AUPRO \\
    \midrule
    capsule    & \textbf{96.1\footnotesize{(+2.6)}}  & \textbf{93.1\footnotesize{(+5.1)}} & 93.5\footnotesize{(+0.0)}  & 88.0\footnotesize{(+0.0)} \\
    pill       & \textbf{96.2\footnotesize{(+1.8)}}  & \textbf{96.3\footnotesize{(+1.4)}} & 94.4\footnotesize{(+0.0)}  & 94.9\footnotesize{(+0.0)} \\
    toothbrush & \textbf{98.9\footnotesize{(+2.5)}}  & \textbf{97.9\footnotesize{(+4.3)}} & 96.4\footnotesize{(+0.0)}  & 93.6\footnotesize{(+0.0)} \\
    carpet     &  88.9\footnotesize{(+0.0)}          & 88.3\footnotesize{(+0.0)}          & \textbf{90.8\footnotesize{(+1.9)}}  & \textbf{91.0\footnotesize{(+2.7)}} \\
    grid       &  86.2\footnotesize{(+0.0)}          & 84.5\footnotesize{(+0.0)}          & \textbf{94.2\footnotesize{(+8.0)}}   & \textbf{92.7\footnotesize{(+8.2)}} \\
    zipper     &  92.2\footnotesize{(+0.0)}          & 91.9\footnotesize{(+0.0)}          & \textbf{95.4\footnotesize{(+3.2)}}   & \textbf{95.1\footnotesize{(+3.2)}} \\
    \bottomrule
\end{tabular}
         
    }

    \label{tab1}\end{table}\vspace{-0.5em}

The result in \cref{tab1} shows the performance differences between the various volume normalization methods: CVN outperforms SVN for the first three classes, while the latter behaves the opposite. We further visualize these defect distributions in \cref{fig4}, which shows that SVN-superior classes are commonly textural images with a larger range of defects, while CVN-superior classes are object images. 

\begin{figure}
    \centering
    \setlength{\abovecaptionskip}{0.cm} \setlength{\belowcaptionskip}{-0.6cm} 

    \includegraphics[width=0.8\linewidth]{Fig/Fig4.pdf}
    
    \caption{
        Defects in \cref{tab1} are visualized as heat maps. The top row displays CVN-superior class object images, while the bottom row displays SVN-superior class texture images.
    }
    \label{fig4}
\end{figure}

SVN with larger receptive fields achieves non-local localization by aggregating an extensive range of texture features, while CVN realizes accurate localization by shuffling channels. In a word, different volume normalization techniques implicitly embody distinct task-specific priors.
Furthermore, our ablation study in \cref{Sec43} shows that volume normalization does help to improve average performance.


\subsection{Ablation Study}\label{Sec43}
This subsection discusses the impact of some proposed methods on performance. The study is conducted on full MVTecAD, and other settings are the same as \cref{Sec42}. We ablate four methods from baseline individually. 
In particular, experiment \numroman{1} is based on latent Gaussian assumption and \cref{eq8:probtrans} without volume normalization. For experiment \numroman{2}, the category-independent zero template  is applied.
Then, Experiment \numroman{3} does not adopt the method of \cref{eq10:anomalious} but composes the pyramid first and localizes its difference later. Finally, experiment \numroman{4} adopts a spatial version of the loss function instead of \cref{eq9:fourierloss}.
The result of the above ablation experiments is shown in \cref{tab2}.


\begin{table}[htbp]
    \centering
    \setlength{\abovecaptionskip}{0.0cm} \setlength{\belowcaptionskip}{-0.3cm} \caption{
        The ablation study on full MVTecAD. 
        For each cell in the table, the first row is \colorbox{green!5}{Pixel-AUROC\%} and the second is \colorbox{blue!5}{AUPRO\%}.
        The number within parentheses means the change relative to baseline, the larger absolute value with larger importance.
    }

    \resizebox{.4\textwidth}{!}{
        
\begin{tabular}{lccc}
\toprule
\multicolumn{1}{c}{\multirow{2}[4]{*}{\textbf{Method}}} & \multicolumn{2}{c}{\textbf{Classes}} & \multirow{2}[4]{*}{\textbf{MEAN}} \\
\cmidrule{2-3} & Texture & Object & \multicolumn{1}{c}{} \\
\midrule

\multirow{2}[2]{*}{Ours (baseline)} 
& \cellcolor{green!5}\textbf{95.2\footnotesize{(+0.0)}} & \cellcolor{green!5}\textbf{95.7\footnotesize{(+0.0)}} & \cellcolor{green!5}\textbf{95.5\footnotesize{(+0.0)}} \\
& \cellcolor{blue!5} \textbf{95.1\footnotesize{(+0.0)}} & \cellcolor{blue!5} \textbf{93.5\footnotesize{(+0.0)}} & \cellcolor{blue!5} \textbf{94.0\footnotesize{(+0.0)}} \\
\midrule

\multirow{2}[2]{*}{\makecell[l]{\enumroman{1} w/o Volume\\ Normalization}} 
& \cellcolor{green!5} 89.4\footnotesize{(-5.8)} & \cellcolor{green!5} 85.2\footnotesize{(-10.5)} & \cellcolor{green!5} 86.6\footnotesize{(-8.9)} \\
& \cellcolor{blue!5}  87.5\footnotesize{(-7.6)} & \cellcolor{blue!5}  83.6\footnotesize{(-9.9)}  & \cellcolor{blue!5} 84.9\footnotesize{(-9.1)} \\
\midrule

\multirow{2}[2]{*}{\makecell[l]{\enumroman{2} w/o Latent\\ Template}} 
& \cellcolor{green!5} 93.1\footnotesize{(-2.1)} & \cellcolor{green!5} 90.7\footnotesize{(-5.0)} & \cellcolor{green!5} 91.5\footnotesize{(-4.0)} \\
& \cellcolor{blue!5}  91.9\footnotesize{(-3.2)} & \cellcolor{blue!5}  84.7\footnotesize{(-8.8)} & \cellcolor{blue!5}  87.1\footnotesize{(-6.9)} \\
\midrule

\multirow{2}[2]{*}{\makecell[l]{\enumroman{3} w/o Pyramid\\ Difference}} 
& \cellcolor{green!5} 87.8\footnotesize{(-7.4)} & \cellcolor{green!5} 93.1\footnotesize{(-2.6)} & \cellcolor{green!5} 91.3\footnotesize{(-4.2)} \\
& \cellcolor{blue!5}   87.8\footnotesize{(-7.3)} & \cellcolor{blue!5} 89.4\footnotesize{(-4.1)} & \cellcolor{blue!5}  88.9\footnotesize{(-5.1)} \\
\midrule

\multirow{2}[2]{*}{\makecell[l]{\enumroman{4} w/o Fourier\\ Loss}} 
& \cellcolor{green!5} 92.0\footnotesize{(-3.2)} & \cellcolor{green!5} 93.3\footnotesize{(-2.4)} & \cellcolor{green!5} 92.9\footnotesize{(-2.6)} \\
& \cellcolor{blue!5}  92.8\footnotesize{(-2.3)} & \cellcolor{blue!5}  91.9\footnotesize{(-1.6)} & \cellcolor{blue!5}  92.2\footnotesize{(-1.8)} \\
\bottomrule

\end{tabular}

        
    }
    \label{tab2}\end{table}


\cref{tab2} demonstrates that experiments \numroman{1}-\numroman{4} present various performance degradation.
Experiment \numroman{1} has the largest average degradation, with the object classes being more affected. Although the non-volume-preserving enables larger outputs and higher Image-AUROC performance, the implicit prior in volume normalization discussed in \cref{Sec42} is more helpful for generalization.
For experiment \numroman{2}, it shows that the latent template benefits the performance, and object classes are improved greatly. It is because the category-specific latent template reduces intra-class variance, helping convergence during training.
Then, experiment \numroman{3} suggests that multi-scale differences had a more pronounced impact on textural classes, as higher-level operators with larger receptive fields correspond to large defects.
Finally, Experiment \numroman{4} reveals that Fourier loss (\ref{eq9:fourierloss}) is the icing on the cake that helps performance improvement. 
To summarize, methods \numroman{1}-\numroman{3} are critical for the proposed model, while tricks \numroman{4} help further improvements.

\subsection{Anomaly Localization}\label{Sec44}
\begin{table*}[htbp]
    \centering
    \setlength{\abovecaptionskip}{0.0cm} \setlength{\belowcaptionskip}{-0.3cm} \caption{
    Quantitative results of various challenging methods on MVTecAD.
    In the table, the fully normalized flow method is labeled as FNF, while the abbreviations Res18, WRes50, EffiB5, and DTD are denoted as ResNet18, Wide-ResNet50-2, EfficientNet-B5, and Describable Textures Dataset, respectively.
    For each case in the table, the first row is \colorbox{green!5}{Pixel-AUROC\%} and the second is \colorbox{blue!5}{AUPRO\%}, where the best results are marked in bold. 
    }

    \resizebox{\textwidth}{!}{
        
\begin{tabular}{ccccccccccccccc}
\toprule
\multicolumn{1}{c}{\multirow{2}[2]{*}{\textbf{\makecell{External\\Prior}}}} & \multirow{2}[2]{*}{\textbf{Methods}} & \multicolumn{1}{c}{\multirow{2}[2]{*}{\textbf{carpet}}} & \multicolumn{1}{c}{\multirow{2}[2]{*}{\textbf{leather}}} & \multicolumn{1}{c}{\multirow{2}[2]{*}{\textbf{tile}}} & \multicolumn{1}{c}{\multirow{2}[2]{*}{\textbf{wood}}} & \multicolumn{1}{c}{\multirow{2}[2]{*}{\textbf{bottle}}} & \multicolumn{1}{c}{\multirow{2}[2]{*}{\textbf{cable}}} & \multicolumn{1}{c}{\multirow{2}[2]{*}{\textbf{capsule}}} & \multicolumn{1}{c}{\multirow{2}[2]{*}{\textbf{hazelnut}}} & \multicolumn{1}{c}{\multirow{2}[2]{*}{\textbf{pill}}} & \multicolumn{1}{c}{\multirow{2}[2]{*}{\textbf{toothbrush}}} & \multicolumn{1}{c}{\multirow{2}[2]{*}{\textbf{transistor}}} & \multicolumn{1}{c}{\multirow{2}[2]{*}{\textbf{zipper}}} & \multicolumn{1}{c}{\multirow{2}[2]{*}{\textbf{MEAN}}} \\
    & \multicolumn{1}{c}{} &       &       &       &       &       &       &       &       &       &       &       &       &  \\
\midrule
\multicolumn{1}{c}{\multirow{8}[8]{*}{}} 


& \multirow{2}[2]{*}{AnoGAN\cite{AnoGAN}} & 
\cellcolor{green!5} 54.2  & \cellcolor{green!5} 64.1  & \cellcolor{green!5} 49.7  & \cellcolor{green!5} 62.1  & \cellcolor{green!5} 85.8  & \cellcolor{green!5} 78.0    & \cellcolor{green!5} 84.1  & \cellcolor{green!5} 87.1  & \cellcolor{green!5} 86.8  & \cellcolor{green!5} 90.0    & \cellcolor{green!5} 79.9  & \cellcolor{green!5} 78.1  & \cellcolor{green!5} 75.0 \\
& \multicolumn{1}{c}{} & 
\cellcolor{blue!5} 20.4  & \cellcolor{blue!5} 37.8  & \cellcolor{blue!5} 17.7  & \cellcolor{blue!5} 38.6  & \cellcolor{blue!5} 62.0    & \cellcolor{blue!5} 38.3  & \cellcolor{blue!5} 30.6  & \cellcolor{blue!5} 69.8  & \cellcolor{blue!5} 77.6  & \cellcolor{blue!5} 74.9  & \cellcolor{blue!5} 54.9  & \cellcolor{blue!5} 46.7  & \cellcolor{blue!5} 47.4 \\
\cmidrule{2-15}          

& \multirow{2}[2]{*}{Vanilla VAE\cite{VanillaVAE}} & 
\cellcolor{green!5} 62.0    & \cellcolor{green!5} 83.5  & \cellcolor{green!5} 52.0    & \cellcolor{green!5} 69.9  & \cellcolor{green!5} 89.4  & \cellcolor{green!5} 81.6  & \cellcolor{green!5} 90.7  & \cellcolor{green!5} 95.1  & \cellcolor{green!5} 87.9  & \cellcolor{green!5} 95.3  & \cellcolor{green!5} 85.1  & \cellcolor{green!5} 77.5  & \cellcolor{green!5} 80.8 \\
& \multicolumn{1}{c}{} & 
\cellcolor{blue!5} 61.9  & \cellcolor{blue!5} 64.9  & \cellcolor{blue!5} 24.2  & \cellcolor{blue!5} 57.8  & \cellcolor{blue!5} 70.5  & \cellcolor{blue!5} 77.9  & \cellcolor{blue!5} 77.9  & \cellcolor{blue!5} 77.0    & \cellcolor{blue!5} 79.3  & \cellcolor{blue!5} 85.4  & \cellcolor{blue!5} 61.0    & \cellcolor{blue!5} 60.8  & \cellcolor{blue!5} 66.6 \\
\cmidrule{2-15}          

& \multirow{2}[2]{*}{AE-SSIM\cite{AE-SSIM}} & 
\cellcolor{green!5} 87.0    & \cellcolor{green!5} 78.0    & \cellcolor{green!5} 59.0    & \cellcolor{green!5} 73.0    & \cellcolor{green!5} 93.0    & \cellcolor{green!5} 82.0    & \cellcolor{green!5} 94.0    & \cellcolor{green!5} 97.0    & \cellcolor{green!5} 91.0    & \cellcolor{green!5} 92.0    & \cellcolor{green!5} 80.0    & \cellcolor{green!5} 88.0    & \cellcolor{green!5} 84.5 \\
& \multicolumn{1}{c}{} & 
\cellcolor{blue!5} 64.7  & \cellcolor{blue!5} 56.1  & \cellcolor{blue!5} 17.5  & \cellcolor{blue!5} 60.5  & \cellcolor{blue!5} 83.4  & \cellcolor{blue!5} 47.8  & \cellcolor{blue!5} 86.0    & \cellcolor{blue!5} 91.6  & \cellcolor{blue!5} 83.0    & \cellcolor{blue!5} 78.4  & \cellcolor{blue!5} 72.4  & \cellcolor{blue!5} 66.5  & \cellcolor{blue!5} 67.3 \\
\cmidrule{2-15} \multicolumn{1}{c}{\multirow{2}[2]{*}{}} 

& Ours  & 
\cellcolor{green!5} \textbf{90.8}  & \cellcolor{green!5} \textbf{99.6} & \cellcolor{green!5} \textbf{97.9} & \cellcolor{green!5} \textbf{93.8}  & \cellcolor{green!5} \textbf{95.9}  & \cellcolor{green!5} \textbf{92.1}  & \cellcolor{green!5} \textbf{96.1}  & \cellcolor{green!5} \textbf{98.0} & \cellcolor{green!5} \textbf{96.2}  & \cellcolor{green!5} \textbf{98.9} & \cellcolor{green!5} \textbf{97.4}  &  \cellcolor{green!5} \textbf{95.4}  & \cellcolor{green!5} \textbf{96.0} \\
& (FNF) & 
\cellcolor{blue!5} \textbf{91.0}    & \cellcolor{blue!5} \textbf{99.7} & \cellcolor{blue!5} \textbf{95.8}  & \cellcolor{blue!5} \textbf{96.2}  & \cellcolor{blue!5} \textbf{94.0} & \cellcolor{blue!5} \textbf{86.4}  & \cellcolor{blue!5} \textbf{93.1}  & \cellcolor{blue!5} \textbf{97.3}  & \cellcolor{blue!5} \textbf{96.3} & \cellcolor{blue!5} \textbf{97.7}  & \cellcolor{blue!5} \textbf{91.4}  & \cellcolor{blue!5} \textbf{95.1}  & \cellcolor{blue!5} \textbf{94.5} \\
\midrule

\multirow{2}[2]{*}{Res18} & \multirow{2}[2]{*}{S-T\cite{S-T}} & 
\cellcolor{green!5} 93.5  & \cellcolor{green!5} 97.8  & \cellcolor{green!5} 92.5  & \cellcolor{green!5} 92.1  & \cellcolor{green!5} 97.8  & \cellcolor{green!5} 91.9  & \cellcolor{green!5} 96.8  & \cellcolor{green!5} 98.2  & \cellcolor{green!5} \textbf{96.5}  & \cellcolor{green!5} 97.9  & \cellcolor{green!5} 73.7  & \cellcolor{green!5} 95.6  & \cellcolor{green!5} 93.7 \\
& \multicolumn{1}{c}{} & 
\cellcolor{blue!5}  87.9  & \cellcolor{blue!5} 94.5  & \cellcolor{blue!5} 94.6  & \cellcolor{blue!5} 91.1  & \cellcolor{blue!5} 93.1  & \cellcolor{blue!5} 81.8  & \cellcolor{blue!5} 96.8  & \cellcolor{blue!5} 96.5  & \cellcolor{blue!5} \textbf{96.1}  & \cellcolor{blue!5} 93.3  & \cellcolor{blue!5} 66.6  & \cellcolor{blue!5} 95.1  & \cellcolor{blue!5} 90.6 \\
\cmidrule{2-15}      

\multirow{2}[2]{*}{WRes50}    & \multirow{2}[2]{*}{SPADE\cite{SPADE}} & 
\cellcolor{green!5} 97.5  & \cellcolor{green!5} 97.6  & \cellcolor{green!5} 87.4  & \cellcolor{green!5} 88.5  & \cellcolor{green!5} \textbf{98.4} & \cellcolor{green!5} \textbf{97.2} & \cellcolor{green!5} \textbf{99.0} & \cellcolor{green!5} \textbf{99.1} & \cellcolor{green!5} \textbf{96.5} & \cellcolor{green!5} 97.9  & \cellcolor{green!5} 94.1  & \cellcolor{green!5} 96.5  & \cellcolor{green!5} 95.8 \\
& \multicolumn{1}{c}{} & 
\cellcolor{blue!5} 94.7  & \cellcolor{blue!5} 97.2  & \cellcolor{blue!5} 75.9  & \cellcolor{blue!5} 87.4  & \cellcolor{blue!5} 95.5  & \cellcolor{blue!5} 90.9 & \cellcolor{blue!5} 93.7  & \cellcolor{blue!5} 95.4  & \cellcolor{blue!5} 94.6  & \cellcolor{blue!5} 93.5  & \cellcolor{blue!5} \textbf{97.4} & \cellcolor{blue!5} 92.6  & \cellcolor{blue!5} 92.4 \\
\cmidrule{2-15}     

\multirow{2}[2]{*}{WRes50}    & \multirow{2}[2]{*}{PaDiM\cite{PaDiM}} & 
\cellcolor{green!5} \textbf{99.1} & \cellcolor{green!5} 99.2  & \cellcolor{green!5} 94.1  & \cellcolor{green!5} 94.9  & \cellcolor{green!5} 98.3  & \cellcolor{green!5} 96.7  & \cellcolor{green!5} 98.5  & \cellcolor{green!5} 98.2  & \cellcolor{green!5} 95.7  & \cellcolor{green!5} \textbf{98.8}  & \cellcolor{green!5} \textbf{97.5} & \cellcolor{green!5} \textbf{98.5} & \cellcolor{green!5} \textbf{97.5} \\
& \multicolumn{1}{c}{} & 
\cellcolor{blue!5} 96.2  & \cellcolor{blue!5} 97.8  & \cellcolor{blue!5} 86.0    & \cellcolor{blue!5} 91.1  & \cellcolor{blue!5} 94.8  & \cellcolor{blue!5} 88.8  & \cellcolor{blue!5} 93.5  & \cellcolor{blue!5} 92.6  & \cellcolor{blue!5} 92.7  & \cellcolor{blue!5} 93.1  & \cellcolor{blue!5} 84.5  & \cellcolor{blue!5} \textbf{95.9} & 92.3 \\
\cmidrule{2-15}     

\multirow{2}[2]{*}{EffiB5}    & \multirow{2}[2]{*}{CS-Flow\cite{CSFlow}} & 
\cellcolor{green!5} 98.0    & \cellcolor{green!5} 98.4    & \cellcolor{green!5} 93.9    & \cellcolor{green!5} 88.6    & \cellcolor{green!5} 90.9    & \cellcolor{green!5} 95.3    & \cellcolor{green!5} 97.9    & \cellcolor{green!5} 96.3    & \cellcolor{green!5} 95.7    & \cellcolor{green!5} 96.3    & \cellcolor{green!5} 95.5    & \cellcolor{green!5} 96.4    & \cellcolor{green!5} 95.3 \\
& \multicolumn{1}{c}{} & 
\cellcolor{blue!5} \textbf{98.0}  & \cellcolor{blue!5} 98.5  & \cellcolor{blue!5} 94.5  & \cellcolor{blue!5} 92.9  & \cellcolor{blue!5} 88.7  & \cellcolor{blue!5} \textbf{94.0}  & \cellcolor{blue!5} 96.1    & \cellcolor{blue!5} 95.1  & \cellcolor{blue!5} 91.1    & \cellcolor{blue!5} 89.9  & \cellcolor{blue!5} 96.9  & \cellcolor{blue!5} 95.4  & \cellcolor{blue!5} 94.2 \\
\cmidrule{2-15}     

\multirow{2}[2]{*}{DTD}     & \multirow{2}[2]{*}{DRÃ†M\cite{DRAEM}} & 
\cellcolor{green!5} 94.9 & \cellcolor{green!5} \textbf{96.6}  & \cellcolor{green!5} \textbf{99.6}  & \cellcolor{green!5} \textbf{97.3}  & \cellcolor{green!5} 97.6  & \cellcolor{green!5} 95.4  & \cellcolor{green!5} 94.0  & \cellcolor{green!5} 99.2  & \cellcolor{green!5} 95.0  & \cellcolor{green!5} 98.1  & \cellcolor{green!5} 90.0 & \cellcolor{green!5} 94.4 & \cellcolor{green!5} 96.0 \\
& \multicolumn{1}{c}{} & 
\cellcolor{blue!5} 96.1  & \cellcolor{blue!5} 97.9  & \cellcolor{blue!5} \textbf{99.7}  & \cellcolor{blue!5} \textbf{97.9}  & \cellcolor{blue!5} \textbf{97.2}  & \cellcolor{blue!5} 90.4  & \cellcolor{blue!5} 96.5  & \cellcolor{blue!5} \textbf{98.7}  & \cellcolor{blue!5} 93.7  & \cellcolor{blue!5} 97.1  & \cellcolor{blue!5} 92.9  & \cellcolor{blue!5} 94.7 & \cellcolor{blue!5} 96.1 \\
\cmidrule{2-15}    

\multirow{2}[2]{*}{Res18}     & \multirow{2}[2]{*}{Ours}   & 
\cellcolor{green!5} 97.4  & \cellcolor{green!5} 98.7  & \cellcolor{green!5} 97.1  & \cellcolor{green!5} 97.0 & \cellcolor{green!5} 97.8  & \cellcolor{green!5} 91.8  & \cellcolor{green!5} 98.6  & \cellcolor{green!5} 98.1  & \cellcolor{green!5} 96.1  & \cellcolor{green!5} 98.5  & \cellcolor{green!5} 96.9  & \cellcolor{green!5} 96.6  & \cellcolor{green!5} 97.1 \\
& \multicolumn{1}{c}{} & 
\cellcolor{blue!5} 97.2  & \cellcolor{blue!5} \textbf{99.2}  & \cellcolor{blue!5} 97.2  & \cellcolor{blue!5} \textbf{97.9} & \cellcolor{blue!5} 95.5 & \cellcolor{blue!5} 90.3  & \cellcolor{blue!5} \textbf{98.3}  & \cellcolor{blue!5} 98.1 & \cellcolor{blue!5} \textbf{96.1}  & \cellcolor{blue!5} \textbf{97.9} & \cellcolor{blue!5} 94.7  & \cellcolor{blue!5} 95.4  & \cellcolor{blue!5} \textbf{96.5} \\
\bottomrule

\end{tabular}



   
    }

    \label{tab3}\end{table*}


\noindent\textbf{MVTecAD.}
We performed defect localization for 12 registered classes in MVTecAD.
In our comparisons, the method based on pre-trained models or using external datasets is viewed as requiring external prior, corresponding to the first column of \cref{tab3}.
In our implementation, we augment textural classes with flips and rotations, each with a probability of 0.5, while object categories do not undergo any augmentation operation.
It is worth noting that those base on complex augmentation or weak supervision is not considered in our comparisons, as our approach is capable of incorporating these techniques to improve performance. The detailed results are shown in \cref{tab3}.

First, we take three methods based on image contrast, AnoGAN\cite{AnoGAN}, Vanilla VAE\cite{VanillaVAE}, and AE-SSIM\cite{AE-SSIM}. They are not dependent on external datasets, so it is fair to compare them with our FNF model.
Furthermore, we also compared our method to those that utilize external priors, such as S-T, SPADE, \etc. All methods were reproduced based on the official implementation or AnomaLib\cite{Anomalib}.
For fair comparisons, we adapted the  convolution  to the pre-trained encoder, where the pre-trained encoder is the first two layers of ResNet18 for extracting the image into features of original 1/4 size and with 64 channels.

As shown in \cref{tab3}, our FNF method greatly outperforms the comparable methods without external priors, even exceeding S-T, SPADE, and CS-Flow that using external priors.
Most of the reconstruction-based methods in \cref{tab3} suffer from ill-posedness in complex scenarios (\eg, tile and wood.), while our method achieves the best AUPRO score owing to high-resolution contrast in latent space.
However, a larger resolution implies larger intra-class variance, which degrades the overall AUROC performance for hard-to-determine anomaly boundaries.
Furthermore, \cref{fig7}(a) visualizes representative examples of MVTecAD anomaly localization, which shows that our method achieves precise localization with reasonable scale.


\begin{figure*}
    \centering
    \setlength{\abovecaptionskip}{0.cm} \setlength{\belowcaptionskip}{-0.6cm} 

    \includegraphics[width=\linewidth]{Fig/Fig7.pdf}
    \caption{
        Visualization of our results on MVTecAD and BTAD. 
        From top to bottom are original images, estimated image templates, our localization results, and ground truths.
        \textbf{(a)} The six challenging results on MVTecAD. \textbf{(b)} Two representative results on BTAD. \textbf{(c)} Results for the four unregistered categories on MVTecAD.
    }
    \label{fig7}
\end{figure*}


\noindent\textbf{BTAD.}
To fully illustrate our superiority, we experimented on the more challenging BTAD dataset without any data augmentation, and other settings are the same as MVTecAD. The detailed result in \cref{tab4} shows that our method also achieves state-of-the-art performance, and \cref{fig7}(b) visualizes representative examples of BTAD anomaly localization.

\begin{table}[htbp]
    \centering
    \setlength{\abovecaptionskip}{0.0cm} \setlength{\belowcaptionskip}{-0.1cm} \caption{
        Quantitative results of various challenging methods on BTAD.
        For each case in the table, the first row is \colorbox{red!5}{Image-AUROC\%} and the second is \colorbox{green!5}{Pixel-AUROC\%}, where the best results are marked in bold.
    }

    \resizebox{.35\textwidth}{!}{
        

\begin{tabular}{ccccc}
\toprule
\multicolumn{1}{c}{\multirow{2}[4]{*}{\textbf{Methods}}} & \multicolumn{3}{c}{\textbf{Classes}} & \multicolumn{1}{c}{\multirow{2}[4]{*}{\textbf{MEAM}}} \\
\cmidrule{2-4}          & 01     & 02     & 03     &  \\
\midrule

\multicolumn{1}{c}{\multirow{2}[2]{*}{VT-ADL\cite{VT-ADL}}} 
& \cellcolor{red!5} 97.6  & \cellcolor{red!5} 71.0  & \cellcolor{red!5} 82.6  & \cellcolor{red!5} 83.7  \\
& \cellcolor{green!5} \textbf{99.0 } & \cellcolor{green!5} 94.0  & \cellcolor{green!5} 77.0  & \cellcolor{green!5} 90.0  \\
\midrule

\multicolumn{1}{c}{\multirow{2}[2]{*}{P-SVDD\cite{PSVDD}}} 
& \cellcolor{red!5} 95.7  & \cellcolor{red!5} 72.1  & \cellcolor{red!5} 82.1  & \cellcolor{red!5} 83.3  \\
& \cellcolor{green!5} 91.6  & \cellcolor{green!5} 93.6  & \cellcolor{green!5} 91.0  & \cellcolor{green!5} 92.1  \\
\midrule

\multicolumn{1}{c}{\multirow{2}[2]{*}{SPADE\cite{SPADE}}} 
& \cellcolor{red!5} 91.4  & \cellcolor{red!5} 71.4  & \cellcolor{red!5} \textbf{99.9 } & \cellcolor{red!5} 87.6  \\
& \cellcolor{green!5} 97.3  & \cellcolor{green!5} 94.4  & \cellcolor{green!5} 99.1  & \cellcolor{green!5} 96.9  \\
\midrule

\multicolumn{1}{c}{\multirow{2}[2]{*}{PatchCore\cite{PatchCore}}} 
& \cellcolor{red!5} 90.9  & \cellcolor{red!5} 79.3  & \cellcolor{red!5} 99.8  & \cellcolor{red!5} 90.0  \\
& \cellcolor{green!5} 95.5  & \cellcolor{green!5} 94.7  & \cellcolor{green!5} \textbf{99.3 } & \cellcolor{green!5} 96.5  \\
\midrule

\multicolumn{1}{c}{\multirow{2}[2]{*}{PaDiM\cite{PaDiM}}} 
& \cellcolor{red!5} 99.8  & \cellcolor{red!5} 82.0  & \cellcolor{red!5} 99.4  & \cellcolor{red!5} 93.7  \\
& \cellcolor{green!5} 97.0  & \cellcolor{green!5} 96.0  & \cellcolor{green!5} 98.8  & \cellcolor{green!5} 97.3  \\
\midrule

\multicolumn{1}{c}{\multirow{2}[2]{*}{Ours (Res18)}} 
& \cellcolor{red!5} \textbf{100.0 } & \cellcolor{red!5} \textbf{88.2 } & \cellcolor{red!5} 99.3  & \cellcolor{red!5} \textbf{95.8 } \\
& \cellcolor{green!5} 97.4  & \cellcolor{green!5} \textbf{97.6 } & \cellcolor{green!5} 98.1  & \cellcolor{green!5} \textbf{97.7 } \\
\bottomrule

\end{tabular}


           
    }

    \label{tab4}\end{table}


\subsection{Study on unregistered categories}\label{Sec45}
In principle, template-based methods require pixel-level registration between images and templates, which is typically satisfied in most real-world scenarios, but may fail in some cases. This subsection explores the performance of the proposed method on unregistered (\eg rotation, shift) categories (\eg grid, metal nut, screw, and hazelnut), as shown in \cref{tab5}.
The reconstruction-based AE-SSIM heavily relies on pixel-level contrast, which decreases the average localization accuracy (AUPRO\%). In contrast, the anomaly-based SPADE avoids registration issues and achieves better performance. Fortunately, our ResNet18-based method, which utilizes normalizing flow to reduce patch variance, remains competitive in unregistered scenes, although it falls short of state-of-the-art performance. 
We visualize these categories in \cref{fig7}(c).

\begin{table}[htbp]
    \centering
    \setlength{\abovecaptionskip}{0.cm} \setlength{\belowcaptionskip}{-0.2cm} \caption{
        Quantitative results on unregistered categories without Rough Registration (RR) or Fine Registration (FR).
        For each case in the table, the first row is \colorbox{green!5}{Pixel-AUROC\%} and the second is \colorbox{blue!5}{AUPRO\%}, where the best results are marked in bold.
    }

    \resizebox{.4\textwidth}{!}{
        

\begin{tabular}{cccccc}
\toprule
\multicolumn{1}{c}{\multirow{3}[6]{*}{\textbf{Methods}}} & \multicolumn{4}{c}{\textbf{Classes}} & \multicolumn{1}{c}{\multirow{3}[6]{*}{\textbf{MEAN}}} \\
\cmidrule{2-5}          & \multicolumn{3}{c}{w/o RR} & \multicolumn{1}{c}{w/o FR} &  \\
\cmidrule{2-5}          & \multicolumn{1}{c}{grid} & \multicolumn{1}{c}{metal nut} & \multicolumn{1}{c}{screw} & \multicolumn{1}{c}{hazelnut} &  \\

\midrule    \multicolumn{1}{c}{\multirow{2}[2]{*}{AE-SSIM\cite{AE-SSIM}}} 
& \cellcolor{green!5} 94.0    & \cellcolor{green!5} 89.0    & \cellcolor{green!5} 96.0    & \cellcolor{green!5} 97.0    & \cellcolor{green!5} 94.0 \\
& \cellcolor{blue!5} 84.9  & \cellcolor{blue!5} 60.3  & \cellcolor{blue!5} 88.7  & \cellcolor{blue!5} 91.6  & \cellcolor{blue!5} 81.4 \\
\midrule

\multicolumn{1}{c}{\multirow{2}[2]{*}{SPADE\cite{SPADE}}} 
& \cellcolor{green!5} 93.7  & \cellcolor{green!5} \textbf{98.1} & \cellcolor{green!5} \textbf{98.9} & \cellcolor{green!5} \textbf{99.1} & \cellcolor{green!5} \textbf{97.5} \\
& \cellcolor{blue!5} 86.7  & \cellcolor{blue!5} \textbf{94.4} & \cellcolor{blue!5} \textbf{96.0} & \cellcolor{blue!5} 95.4  & \cellcolor{blue!5} 93.1 \\
\midrule

\multicolumn{1}{c}{\multirow{2}[2]{*}{Ours (Res18)}} 
& \cellcolor{green!5} \textbf{95.7} & \cellcolor{green!5} 97.2  & \cellcolor{green!5} 94.6  & \cellcolor{green!5} 98.1  & \cellcolor{green!5} 96.4 \\
& \cellcolor{blue!5} \textbf{94.3} & \cellcolor{blue!5} 91.4  & \cellcolor{blue!5} 94.7  & \cellcolor{blue!5} \textbf{98.1} & \cellcolor{blue!5} \textbf{94.6} \\
\bottomrule

\end{tabular}


 
    }

    \label{tab5}\end{table}





