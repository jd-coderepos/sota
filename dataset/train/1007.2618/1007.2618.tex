\documentclass[11pt]{article}
\usepackage{graphics,latexsym}
 \usepackage{citesort}
\hyphenation{super-terse mea-sure semi-recursive non-recursive
             non-superterse}
\newcounter{savenumi}
\newenvironment{savenumerate}{\begin{enumerate}
\setcounter{enumi}{\value{savenumi}}}{\end{enumerate}
\setcounter{savenumi}{\value{enumi}}}
\newtheorem{theoremfoo}{Theorem}\newenvironment{theorem}{\pagebreak[1]\begin{theoremfoo}}{\end{theoremfoo}}
\newenvironment{repeatedtheorem}[1]{\vskip 6pt
\noindent
{\bf Theorem #1}\ \em
}{}
\newtheorem{propositionfoo}[theoremfoo]{Proposition}
\newenvironment{proposition}{\pagebreak[1]\begin{propositionfoo}}{\end{propositionfoo}}
\newtheorem{lemmafoo}[theoremfoo]{Lemma}
\newenvironment{lemma}{\pagebreak[1]\begin{lemmafoo}}{\end{lemmafoo}}
\newtheorem{conjecturefoo}[theoremfoo]{Conjecture}
\newenvironment{conjecture}{\pagebreak[1]\begin{conjecturefoo}}{\end{conjecturefoo}}
\newtheorem{corollaryfoo}[theoremfoo]{Corollary}
\newenvironment{corollary}{\pagebreak[1]\begin{corollaryfoo}}{\end{corollaryfoo}}
\newtheorem{exercisefoo}{Exercise}
\newenvironment{exercise}{\pagebreak[1]\begin{exercisefoo}\rm}{\end{exercisefoo}}
\newtheorem{openfoo}[theoremfoo]{Question}
\newenvironment{open}{\pagebreak[1]\begin{openfoo}}{\end{openfoo}}
\newtheorem{nttn}[theoremfoo]{Notation}
\newenvironment{notation}{\pagebreak[1]\begin{nttn}\rm}{\end{nttn}}

\newtheorem{dfntn}[theoremfoo]{Definition}
\newenvironment{definition}{\pagebreak[1]\begin{dfntn}\rm}{\end{dfntn}}

\newenvironment{proof}
    {\pagebreak[1]{\narrower\noindent {\bf Proof:\quad\nopagebreak}}}{\QED}
\newenvironment{sketch}
    {\pagebreak[1]{\narrower\noindent {\bf Proof sketch:\quad\nopagebreak}}}{\QED}
\newenvironment{comment}{\penalty -50 \nolinebreak\ }{\nolinebreak \linebreak[1]\ }
\renewcommand{\theenumi}{\roman{enumi}}
\newcommand{\yyskip}{\penalty-50\vskip 5pt plus 3pt minus 2pt}
\newcommand{\blackslug}{\hbox{\hskip 1pt
        \vrule width 4pt height 8pt depth 1.5pt\hskip 1pt}}


\newcommand{\dash}{{\rm\mbox{-}}}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\ceiling}[1]{\left\lceil#1\right\rceil}
\newcommand{\st}{\mathrel{:}}
\newcommand{\ang}[1]{\langle#1\rangle}
\newcommand{\DTIME}{{\rm DTIME}}
\newcommand{\DSPACE}{{\rm DSPACE}}
\newcommand{\NSPACE}{{\rm NSPACE}}
\newcommand{\polylog}{\mathop{\rm polylog}}
\newcommand{\UP}{{\rm UP}}
\newcommand{\PH}{{\rm PH}}
\newcommand{\R}{{\rm R}}
\newcommand{\NTIME}{{\rm NTIME}}
\newcommand{\PTIME}{{\rm PrTIME}}
\newcommand{\PSPACE}{{\rm PSPACE}}
\newcommand{\NE}{{\rm NE}}
\newcommand{\poly}{{\rm poly}}
\newcommand{\LOGSPACE}{{\rm LOGSPACE}}
\newcommand{\E}{{\rm E}}
\newcommand{\SAT}{{\rm SAT}}
\newcommand{\NP}{{\rm NP}}
\let\paragraphsym\P
\renewcommand{\P}{{\rm P}}      \newcommand{\coNP}{{\co\NP}}
\newcommand{\propersubset}{\subset}
\newcommand{\xor}{\oplus}
\newcommand{\m}{{\rm m}}
\newcommand{\T}{{\rm T}}
\let\savett\tt
\renewcommand{\tt}{{\rm tt}}    \newcommand{\btt}{{\rm btt}}
\newcommand{\ntt}{{n\rm\mbox{-}tt}}
\newcommand{\ktt}{{k\rm\mbox{-}tt}}
\newcommand{\kT}{{k\rm\mbox{-}T}}
\newcommand{\onett}{{1\rm\mbox{-}tt}}
\newcommand{\Abar}{{\bar{A}}}
\newcommand{\Bbar}{{\bar{B}}}
\newcommand{\Cbar}{{\bar{C}}}
\def\nre.{\/-r.e.}
\newcommand{\ie}{{\it i.e.}}
\newcommand{\eg}{{\it e.g.}}
\newenvironment{multi}{\left\{\begin{array}{ll}}{\end{array}\right.}
\newcommand{\union}{\cup}
\newcommand{\Union}{\bigcup}
\newcommand{\intersection}{\cap}
\newcommand{\Intersection}{\bigcap}
\newcommand{\OR}{\vee}
\newcommand{\AND}{\wedge}
\newcommand{\reason}[1]{\mbox{\qquad\rm #1}}     \newcommand{\nlreason}[1]{\\ & & \mbox{\rm #1}}  \newcommand{\infinity}{\infty}
\newcommand{\implies}{\mathrel{\Rightarrow}}
\newcommand{\Implies}{\mathrel{\Longrightarrow}}
\newcommand{\Iff}{\mathrel{\Longleftrightarrow}}
\newcommand{\scrod}{\quad\nopagebreak}
\newcommand{\ACCEPT}{{\rm ACCEPT}}
\newcommand{\PARITY}{{\rm PARITY}}
\newcommand{\PARITYP}{\PARITY\P}
\newcommand{\MOD}{{\rm MOD}}
\newcommand{\PP}{{\rm PP}}
\newcommand{\FewP}{{\rm FewP}}
\newcommand{\EP}{{\rm EP}}
\tolerance=2000
\def\pmod#1{\allowbreak\mkern6mu({\rm mod}\,\,#1)}
\newcommand{\co}{{\rm co}\dash}
\newcommand{\PF}{{\rm PF}}
\newcommand{\EXP}{{\rm EXP}}
\newcommand{\NEXP}{{\rm NEXP}}
\newcommand{\Hastad}{H{\aa}stad}
\newcommand{\Kobler}{K\"obler}
\newcommand{\Schoning}{Sch\"oning}
\newcommand{\Toran}{Tor\'an}
\newcommand{\Balcazar}{Balc{\'a}zar}
\newcommand{\Diaz}{D\'{\i}az}
\newcommand{\Gabarro}{Gabarr{\'o}}
\newcommand{\RIA}{CCR-8808949}
\newcommand{\PYI}{CCR-8958528}
\newcommand{\NSFFT}{CCR-9415410}
\newcommand{\NSFALEXIS}{CCR-9522084}
\newtheorem{factfoo}[theoremfoo]{Fact}
\newenvironment{fact}{\pagebreak[1]\begin{factfoo}}{\end{factfoo}}
\newenvironment{acknowledgments}{\par\vskip 20pt\noindent{\footnotesize\em Acknowledgments.}\footnotesize}{\par}
\newcommand{\POLYLOGSPACE}{{\rm POLYLOGSPACE}}
\newcommand{\SPACE}{{\rm SPACE}}
\newcommand{\BPP}{{\rm BPP}}
\newcommand{\lookatme}{\marginpar[]{}}
\newcommand{\muchless}{\ll}
\newcommand{\plusminus}{\pm}
\newcommand{\nopagenumbers}{\renewcommand{\thepage}{\null}}
\newenvironment{algorithm}{\renewcommand{\theenumii}{\arabic{enumii}}\renewcommand{\labelenumii}{Step \theenumii :}\begin{enumerate}}{\end{enumerate}}
\newcommand{\squeeze}{
\textwidth 6in
\textheight 8.8in
\oddsidemargin 0.2in
\topmargin -0.4in
}
\newcommand{\existsunique}{\exists \! ! \,}
\newcommand{\YaleAddress}{Yale University,
Dept.\ of Computer Science,
P.O.\ Box 208285, Yale Station,
New Haven, CT\ \ 06520-8285.
Email: {\savett beigel-richard@cs.yale.edu}}
\newcommand{\pageline}[2]{[{\bf p.~#1, l.~#2}]}
\newcommand{\Beigel}{Richard Beigel\thanks{\newsupport} \\
Yale University \\
Dept.\ of Computer Science \\
P.O. Box 208285, Yale Station \\
New Haven, CT\ \ 06520-8285}

\newcommand{\newsupport}{Supported in part by grants \RIA\ and \PYI\
from the National Science Foundation}
\newtheorem{propertyfoo}[theoremfoo]{Property}
\newenvironment{property}{\pagebreak[1]\begin{propertyfoo}}{\end{propertyfoo}}


\makeatletter

\def\@makechapterhead#1{ \vspace*{50pt} { \parindent 0pt \raggedright 
 \ifnum \c@secnumdepth >\m@ne \huge\bf \@chapapp{} \thechapter. \par 
 \vskip 20pt \fi \Huge \bf #1\par 
 \nobreak \vskip 40pt } }

\def\@sect#1#2#3#4#5#6[#7]#8{\ifnum #2>\c@secnumdepth
     \def\@svsec{}\else 
     \refstepcounter{#1}\edef\@svsec{\csname the#1\endcsname.\hskip 1em }\fi
     \@tempskipa #5\relax
      \ifdim \@tempskipa>\z@ 
        \begingroup #6\relax
          \@hangfrom{\hskip #3\relax\@svsec}{\interlinepenalty \@M #8\par}
        \endgroup
       \csname #1mark\endcsname{#7}\addcontentsline
         {toc}{#1}{\ifnum #2>\c@secnumdepth \else
                      \protect\numberline{\csname the#1\endcsname}\fi
                    #7}\else
        \def\@svsechd{#6\hskip #3\@svsec #8\csname #1mark\endcsname
                      {#7}\addcontentsline
                           {toc}{#1}{\ifnum #2>\c@secnumdepth \else
                             \protect\numberline{\csname the#1\endcsname}\fi
                       #7}}\fi
     \@xsect{#5}}

\def\@begintheorem#1#2{\it \trivlist \item[\hskip \labelsep{\bf #1\ #2.}]}

\def\@opargbegintheorem#1#2#3{\it \trivlist
      \item[\hskip \labelsep{\bf #1\ #2\ (#3).}]}

\makeatother



\newcommand{\kstar}{{\textstyle *}}
\newcommand{\F}[2]{F_{#1}^{#2}}
\newcommand{\FQ}[2]{\PF_{{#1\rm\mbox{-}T}}^{#2}}
\newcommand{\Q}[2]{\P_{{#1\rm\mbox{-}T}}^{#2}}
\newcommand{\FQp}[2]{\PF_{{#1\rm\mbox{-}tt}}^{#2}}
\newcommand{\Qp}[2]{\P_{{#1\rm\mbox{-}tt}}^{#2}}
\newcommand{\ppoly}{\P/\poly}
\newcommand{\pnplog}{\P^{\NP[\log]}}
\newcommand{\pleq}[1]{\leq_{#1}^{p}}

\def\abs#1{\left|#1\right|}
\def\exp#1{{\rm exp}\left(#1\right)}
\newcommand{\transfig}[1]{\begin{center}\vspace{-6pt}\input{#1.tex}\vspace{-12pt}\end{center}}



\newif\ifshortconferences
\shortconferencesfalse
\newif\ifmediumconferences
\mediumconferencesfalse

\def\ending#1{{\count1=#1\relax
\count2=\count1
\divide\count2 by 100
\multiply\count2 by 100
\advance\count1 by -\count2
\ifnum\count1=11
th\else \ifnum\count1=12
th\else \ifnum\count1=13
th\else 
\count2=\count1
\divide\count1 by 10
\multiply\count1 by 10
\advance\count2 by -\count1
\ifnum\count2=1
st\else \ifnum\count2=2
nd\else \ifnum\count2=3
rd\else th\fi\fi\fi\fi\fi\fi
}}

\def\STOC{\conf{STOC}}
\def\STOCname{\ifshortconferences ACM STOC\else\ifmediumconferences Ann. ACM Symp. Theor. Comput.\else Annual ACM Symposium on Theory of Computing\fi\fi}
\def\STOCzero{68}

\def\FOCS{\conf{FOCS}}
\def\FOCSname{\ifshortconferences IEEE FOCS\else\ifmediumconferences Ann. Symp. Found. Comput. Sci.\else IEEE Symposium on Foundations of Computer Science\fi\fi}
\def\FOCSzero{59}

\def\FSTTCS{\conf{FSTTCS}}
\def\FSTTCSname{\ifshortconferences FST\&TCS\else\ifmediumconferences Ann. Conf. Found. Softw. Theor. and Theor. Comp. Sci.\else Conference on Foundations of Software Theory and Theoretical Computer Science\fi\fi}
\def\FSTTCSzero{80}

\def\Complexity{\conf{Complexity}}
\def\Complexityname{\ifshortconferences Conf. Computational Complexity\else\ifmediumconferences Ann. Conf. Computational Complexity\else Annual Conference on Computational Complexity\fi\fi}
\def\Complexityzero{85}
\def\ComplexityOne{Structure in Complexity Theory}

\def\Structures{\conf{Structures}}
\def\Structuresname{\ifshortconferences Ann. Conf. Structure in Complexity Theory\else\ifmediumconferences Ann. Conf. Structure in Complexity Theory\else Annual Conference on Structure in Complexity Theory\fi\fi}
\def\Structureszero{85}
\def\StructuresOne{Structure in Complexity Theory}

\def\SODA{\conf{SODA}}
\def\SODAname{\ifshortconferences ACM-SIAM Symp. on Discrete Algorithms\else Annual ACM-SIAM Symposium on Discrete Algorithms\fi}
\def\SODAzero{89}

\def\STACS{\conf{STACS}}
\def\STACSname{\ifshortconferences STACS\else\ifmediumconferences\else Annual Symposium on Theoretical Aspects of Computer Science\fi\fi}
\def\STACSzero{83}

\def\SPAA{\conf{SPAA}}
\def\SPAAname{\ifshortconferences ACM SPAA\else\ifmediumconferences Ann. ACM Symp. Par. Alg. Arch.\else Annual ACM Symposium on Parallel Algorithms and Architectures\fi\fi}
\def\SPAAzero{88}

\def\Proceedings{\ifshortconferences Proc.\else\ifmediumconferences Proc.\else Proceedings\fi\fi}
\def\Proceedingsofthe{\ifshortconferences Proc.\else\ifmediumconferences Proc.\else Proceedings of the\fi\fi}

\newcounter{confnum}

\def\conf#1#2{\setcounter{confnum}{#2}\addtocounter{confnum}{-\csname #1zero\endcsname}\ifnum\value{confnum}=1\expandafter\ifx\csname #1One\endcsname\relax \Proceedingsofthe\ \arabic{confnum}\ending{\value{confnum}}\ \csname #1name\endcsname \else \csname #1One\endcsname\fi \else \Proceedingsofthe\
\arabic{confnum}\ending{\value{confnum}}\ \csname #1name\endcsname\fi}





\def\qsym{\vrule width0.7ex height0.9em depth0ex}


\newif\ifqed\qedtrue


\def\noqed{\global\qedfalse}


\def\qed{\ifqed{\penalty1000\unskip\nobreak\hfil\penalty50
\hskip2em\hbox{}\nobreak\hfil\qsym
\parfillskip=0pt \finalhyphendemerits=0\par\medskip}\fi\global\qedtrue}

\def\QEDcomment#1{\ifqed{\penalty1000\unskip\nobreak\hfil\penalty50
\hskip2em\hbox{}\nobreak\hfil\qsym\ #1
\parfillskip=0pt \finalhyphendemerits=0\par\medskip}\fi\global\qedtrue}

\makeatletter
\def\eqnqed{\noqed
	\def\@tempa{equation}
	\ifx\@tempa\@currenvir\def\@eqnnum{\qsym}\addtocounter{equation}{-1}\else \def\@@eqncr{\let\@tempa\relax
    \ifcase\@eqcnt \def\@tempa{& & &}\or \def\@tempa{& &}\else \def\@tempa{&}\fi
     \@tempa {\def\@eqnnum{{\qsym}}\@eqnnum}\global\@eqnswtrue\global\@eqcnt\z@\cr}\fi}



\def\eqnlabel#1#2{\if@filesw {\let\thepage\relax \def\protect{\noexpand\noexpand\noexpand}\edef\@tempa{\write\@auxout{\string
      \newlabel{#2}{{{#1}}{\thepage}}}}\expandafter}\@tempa \if@nobreak \ifvmode\nobreak\fi\fi\fi \def\@tempa{equation}
	\ifx\@tempa\@currenvir\def\theequation{{#1}}\addtocounter{equation}{-1}\else \def\@@eqncr{\let\@tempa\relax
    \ifcase\@eqcnt \def\@tempa{& & &}\or \def\@tempa{& &}\else \def\@tempa{&}\fi
     \@tempa {\def\@eqnnum{{#1}}\@eqnnum}\global\@eqnswtrue\global\@eqcnt\z@\cr}\fi}



\makeatother



\newcommand{\listqed}{\qed\noqed} \def\littleqed{\ifqed{\penalty1000\unskip\nobreak\hfil\penalty50
\hskip2em\hbox{}\nobreak\hfil\littleqsym
\parfillskip=0pt \finalhyphendemerits=0\par\medskip}\fi\global\qedtrue}
\def\littleqsym{\vrule width0.6ex height0.6em depth0ex}
\def\QED{\qed}

\makeatother



\def\aftereqnskip{\vskip-3pt} 



\newcommand{\SPASAM}[1]{{\rm MOL\dash A}(#1)}
\newcommand{\SPASM}[1]{{\rm MOL'}(#1)}
\newcommand{\SPAM}[1]{{\rm MOL}(#1)}
\newcommand{\NPbits}[1]{{\rm NPbits}(#1)}
\newcommand{\NPinit}[1]{{\rm NPinit}(#1)}
\newcommand{\NPpaths}[1]{{\rm NPpaths}(#1)}
\newcommand{\LOR}{\bigvee}

\newcommand{\set}[1]{\left\{{#1}\right\}}

 

\usepackage[top=1.in, bottom=0.9in, left=1.0in, right=1.0in]{geometry}





\newcommand{\dist}{{\rm dist}}
\newcommand{\shift}{{\rm shift}}
\newcommand{\grid}{{\rm grid}}
\newcommand{\extract}{{\rm Extract}}
\newcommand{\diff}{{\rm diff}}
\newcommand{\match}{{\rm Match}}
\newcommand{\alphavalue}{0.1771}
\newcommand{\vote}{{\rm Vote}}
\newcommand{\major}{{\rm Maj}}
\newcommand{\occ}{{\rm Occur}}
\newcommand{\algmnam}{Recover-Motif}
\newcommand{\algmname}{Algorithm~\algmnam}
\newcommand{\algma}{\algmname~}
\newcommand{\algmb}{Algorithm-One~} \newcommand{\roughleft}{{\rm roughLeft}}
\newcommand{\roughright}{{\rm roughRight}}
\newcommand{\phaseone}{Boundary-Phase}
\newcommand{\phasetwo}{Extract-Phase}
\newcommand{\phasethree}{Voting-Phase}

\newcommand{\LB}{{\rm LB}}
\newcommand{\RB}{{\rm RB}}
\newcommand{\thresholdL}{{(\log n)^{3+\tau}\over 100}}
\newcommand{\algtype}{{\rm algorithm-type}}
\newcommand{\sublinear}{{\rm RANDOMIZED-SUBLINEAR}}
\newcommand{\randomized}{{\rm RANDOMIZED-SUBQUADRATIC}}
\newcommand{\deterministic}{{\rm DETERMINISTIC-SUPERQUADRATIC}}


\newcommand{\prob}{{\rm Pr}}



\newcommand{\Prr}{{\rm Probability}}



\begin{document}
\setcounter{page}{1}
\date{March 7, 2012}

\title{Sublinear Time Motif Discovery from Multiple Sequences\thanks{This research is supported in part by
National Science Foundation Early Career Award 0845376.}}



\author{ Bin Fu, Yunhui Fu,  and Yuan Xue\\
Department of Computer Science, University of Texas--Pan American\\
Edinburg, TX 78541, USA\\
Emails: binfu@cs.panam.edu,  fuyunhui@gmail.com, xuey@utpa.edu}
\maketitle



\begin{abstract}
A natural  probabilistic model for motif discovery has been used to
experimentally test the quality of motif discovery
programs. In this model, there are  background sequences, and each
character in a background sequence is a random character from an
alphabet . A motif  is a string of 
characters. Each background sequence is implanted a
probabilistically generated approximate copy of  . For a
probabilistically generated approximate copy  of
, every character  is probabilistically  generated such that
the probability for  is at most . We develop
three algorithms that under the probabilistic model can find the
implanted motif with high probability via a tradeoff between
computational time and the probability of mutation. Each algorithm
has the preprocessing part and the voting part. We use a pair of
function  to describe the computational
complexity of motif detection algorithm, where  is the largest
length of input sequence, and  is the number of sequences.
Function  is the time complexity for the part for
preprocessing  and  is the time complexity for recovering
one character for motif after preprocessing. The total time is
.

(1) There exists a randomized algorithm such that there are positive
constants  and  that if the alphabet size is at least ,
the number of sequences is at least , the motif length is
at least , and each character in motif region has
probability at most  of mutation for some
fixed , then motif can be recovered in  time, where
 is the longest length of any input sequences, and

 The algorithm total time is sublinear if the motif
length  is in the range  . This is the first sublinear time algorithm with
rigorous analysis in this model.

(2) There exists a randomized algorithm such that there are positive
constants , and  that if the alphabet size is at
least , the number of sequences is at least , the
motif length is at least , and each character in motif
region has probability at most  of mutation, then motif can
be recovered in 
time.

(3) There exists a deterministic algorithm such that there are
positive constants , and  that if the alphabet
size is at least , the number of sequences is at least , the motif length is at least , and each character in
motif region has probability at most  of mutation, then
motif can be recovered in 
time.

The methods developed in this paper have been used in the software
implementation. We observed some encouraging results that show
improved performance for motif detection compared with other
softwares.
\end{abstract}

\newpage

\section{Introduction}
Motif discovery is an important problem in computational biology and
computer science. For instance, it has applications in coding
theory~\cite{FrancesLitman97,GasieniecJanssonLingas99}, locating
binding sites and conserved regions in unaligned
sequences~\cite{StormoHartzell91,LawrenceReilly90,HertzStormo94,Stormo90},
genetic drug target identification~\cite{LanctotLiMaWangZhang99},
designing genetic probes \cite{LanctotLiMaWangZhang99}, and
universal PCR primer
design~\cite{LucasBusch91,DopazoSobrino93,ProutskiHolme96,LanctotLiMaWangZhang99}.


This paper focuses on the application of motif discovery to find
conserved regions in a set of given DNA, RNA, or protein sequences.
Such conserved regions may represent common biological functions or
structures. Many performance measures have been proposed for motif
discovery. Let  be a subset of - sequences of length .
The {\it covering radius} of  is the smallest integer  such
that each vector in  is at a distance at most  from a
string in . The decision problem associated with the covering
radius for a set of binary sequences is
NP-complete~\cite{FrancesLitman97}. The similar closest string and
substring problems were proved to be
NP-hard~\cite{FrancesLitman97,LanctotLiMaWangZhang99}.
Some approximation algorithms have been proposed.
  Li et
al.~\cite{LiMaWang99} gave an approximation scheme for the closest
string and substring problems. The related consensus patterns
problem is that given  sequences , find a region
of length  in each , and a string  of length  so that
the total Hamming distance from  to these regions is minimized.
Approximation algorithms for the consensus patterns problem were
reported in~\cite{LiMaWang99b}. Furthermore, a number  of heuristics
and programs have been
developed~\cite{PevznerSze00,KeichPevzner02,KeichPevzner02b,WangDong05,ChinLeung05}.



In many applications,  motifs are faint and may not be apparent when
two sequences alone are compared but may become clearer when  more
sequences are compared together~\cite{Gusfield97}.
For this reason, it has been conjectured that comparing more
sequences together can help with identifying faint motifs.
This paper is a theoretical approach with a rigorous probabilistic
analysis.


We study a natural probabilistic model for motif discovery. In this
model, there are  background sequences and each character in the
background sequence is a random character from an alphabet .
A motif  is a string of  characters. Each
background sequence is implanted a probabilistically generated
approximate copy of  .  For a probabilistically  generated
approximate copy  of , every character  is
probabilistically  generated such that the probability for , which is called a {\it mutation}, is at most . This
model was first proposed in \cite{PevznerSze00} and has been widely
used in experimentally testing motif discovery programs
\cite{KeichPevzner02,KeichPevzner02b,WangDong05,ChinLeung05}. We
note that a mutation in our model converts a character  in  the
motif into a different character  without probability
restriction. This means that a character  in the motif may not
become any character  in  with equal
probability.

We develop three algorithms that under the probabilistic model, one
can find the implanted motif with high probability via a tradeoff
between computational time and the probability of mutation. Each
algorithm has the preprocessing phase and the voting phase. We use a
pair of function  to describe the
computational complexity of motif detection algorithm, where  is
the largest length of input sequence, and  is the number of
sequences. Function  is the time complexity for the part
for preprocessing,  and  is the time complexity for
recovering one character for motif after preprocessing. The total
time is .

(1) There exists a randomized algorithm such that there are positive
constants  and  that if the alphabet size is at least ,
the number of sequences is at least , the motif length is
at least , and each character in motif region has
probability at most  of mutation for some
fixed , then motif can be recovered in  time, where
 is the longest length of any input sequences, and

 The algorithm total time is sublinear if the motif
length  is in the range  . This is the first sublinear time algorithm with
rigorous analysis in this model.

(2) There exists a randomized algorithm such that there are positive
constants , and  that if the alphabet size is at
least , the number of sequences is at least , the
motif length is at least , and each character in motif
region has probability at most  of mutation, then motif can
be recovered in 
time.

(3) There exists a deterministic algorithm such that there are
positive constants , and  that if the alphabet
size is at least , the number of sequences is at least , the motif length is at least , and each character in
motif region has probability at most  of mutation, then
motif can be recovered in 
time.

The research in this model has been reported
in~\cite{FuKaoWang09b,FuKaoWang08b,LiuMaWang08}.
In~\cite{FuKaoWang09b}, Fu et al. developed an algorithm that needs
the alphabet size to be a constant that is much larger than 4.
In~\cite{FuKaoWang08b}, our algorithm cannot handle all possible
motif patterns. In~\cite{LiuMaWang08}, Liu et al. designed algorithm
that runs in  time and is lack of rigorous analysis about
its performance. The motif recovery in this natural and simple model
has not been fully understood and seems a complicated problem.

This paper presents two new randomized algorithms and one new
deterministic algorithm. They make advancements in the following
aspects: 1. The algorithms are much faster than those before. Our
algorithms can even run in sublinear time. 2. They can handle any
motif pattern. 3. The restriction for the alphabet size is as small
as four, giving them potential applications in practical problems
since gene sequences have an alphabet size . 4. All algorithms
have rigorous proofs about their performances.

The entire \algmnam~is described in
Section~\ref{algorithm-sec}. We analyze \algma
in Section~\ref{analysis-sec}.


\section{Notations and the Model of Sequence Generation}\label{notation-sec}
For a set ,  denotes the number of elements in .
 is an alphabet with . For an integer
,  is the set of sequences of length  with
characters from . For a sequence ,
 denotes the character , and  denotes the
substring  for .  denotes
the length of the sequence .
We use  to represent the empty sequence, which has length
.

Let  be a fixed sequence of  characters. 
is the motif to be discovered by our algorithm. A
-sequence has the form , where ,
each  has probability  to be equal to  for
each , and  has probability at most  not
equal to  for , where .  denotes
the motif region  of . A mutation converts a
character  in  the motif into an arbitrary different character
 without probability restriction. This allows a character 
in the motif to change into any character  in 
with even different probability. The motif region of  may start
at an arbitrary or worst-case position in . Also, a mutation may
convert a character  in the motif into an arbitrary or
worst-case different character  only subject to the restriction
that  will mutate with probability at most .


A -sequence has the form , where , each  has
probability  to be equal to  for each
, and there are at most  characters  not
equal to  for  and each mutation occurs at a
random position of , where .






For two sequences  and  of the
same length, let the {\it relative Hamming distance} .


\begin{definition}\label{shift-def}
For two intervals  and , define
.
\end{definition}







\section{Brief Introduction to Algorithm}

Every detection algorithm in this paper has two phases. The first
phase is preprocessing so that the motif regions from multiple
sequences can be aligned in the same column region. The second phase
is to recover the motif via voting. We use a pair of function
 to describe the computational complexity of
motif detection algorithm. Function  is the time
complexity for the preprocessing phase and  is the time
complexity for outputting one character for motif in the voting
phase.




The motif  is a pattern unknown to algorithm \algmnam, and
algorithm \algmnam~will attempt to recover  from a series of
-sequences generated by the probabilistic model.



\subsection{Algorithm}

The algorithm first detects a position that is close to the left
motif boundary in a sequence. It finds such a position via sampling
and collision between two sequences. After the rough left boundary a
sequence is found, it is used to find the rough boundaries of the
rest of the sequences. Similarly, we find those right boundaries of
motif among the input sequences. The exact left boundary of each
motif region will be detected in the next phase via voting. Each
character of the motif is recovered by voting among all the
characters at the same positions in the motif regions of input
sequences.

{\bf Descriptions of Algorithm}

Input: , where  and
 are two sets of input sequences.

Output:Planted motif in each sequence and consensus string

{\bf Start:}

Randomly select sample points from each sequence both in  and 

For each pair of sequences selected from  and ,

\qquad  Find the rough left and rough right boundaries.

\qquad  Improve rough boundaries.

If motif boundaries of each sequence in  are not empty,

\qquad  Use Voting algorithm to get the planted motifs.

{\bf End of Algorithm}



 \subsection{An Example}


We provide the following example for the brief idea of our
algorithm. Let the following input strings be defined as below. We
assume that the original motif is {\bf TTTTTAACGATTAGCS}. The motif
part is displayed with bold font, and the mutation characters in the
motif region are displayed with small font.


\subsubsection{Input Sequences}

It contains two groups  and
.



The above two strings are used to detect the initial motif region
and use them to deal with the motif in the second group below.






\subsubsection{Select Sample Points}

Some sample points of two sequences in  are selected and
marked.



\subsubsection{Collision Detection}

In this step, the left and right rough boundaries of two sequences will be marked.
The following show the left collision, which happens nearby the left
motif boundary and are marked by two overline  and
 subsequences.



The following show the right collision, which happens nearby the
right motif boundary and are marked by two overline
 subsequences.


\subsubsection{Improving the Boundaries}


In the early phase of the algorithm, we first detect a small piece
of motif in  by comparing  and . Assume ``T{\small
A}TT" and ``TTAG" are found in the left and right motif region of
 respectively. The rough motif length will be calculated via
the difference of the location first character `T' of the first
subsequence and the location of the last character `G' of the
second subsequence. The position marked by ``\underline{A}" is the
rough left boundary of motif and the position marked by
``\underline{T}" is the rough right boundary of motif in 
below.


\subsubsection{Select Sample Points for the Sequences in }

Some sample points near the motif boundaries of  are selected.

 .

Sample points are selected in each sequence in .




\subsubsection{Collision Detection Between  with the Sequences in }

Some sample points near the motif boundaries of  are selected.

 .

Sample points are selected in each sequence in .




\subsubsection{Improving the Motif Boundaries for the Sequences in }

After the collision with the sequences in , we obtain the rough
location of motifs of the sequences in . Their motif boundaries
for the sequences in  are improved.

.

The improved motif boundaries of the sequences in  are marked
below.



\subsubsection{Motif Boundaries for the Sequences in }

.

Use the pair  with  and
 to find the motif boundaries in the
sequences of . The rough boundaries of the second group is
marked below with underlines.









\subsubsection{Extracting the Motif Regions}

The motif regions of the second group will be extracted. The
original motif is recovered via voting at each column.



\subsubsection{Recovering Motif via Voting}

The original motif {\bf TTTTTAACGATTAGCS} is recovered via voting at
all columns. For example, the last {\bf S} in the motif is recovered
via voting among the characters {\bf S, S, S, A, S} in the last
column.

\subsection{Our Results}

We give an algorithm for the case with at most  mutation rate. The performance of the algorithm is
stated in Theorem~\ref{main-theorem1}. Theorem~\ref{main-theorem1}
implies Corollary~\ref{corollary1} by selecting  with
some constant  large enough.



\begin{theorem}\label{main-theorem1}Assume that  is a fixed number in 
and the alphabet size  is at least . There exists a randomized
algorithm such that there is a constant  that
 if the length of the motif  is at least ,
then given  independent -sequences, the algorithm outputs  such that

1) with probability at most , , and

2) for each , with probability at most
, , and

3) with probability at most , the algorithm
\algmnam~does not stop in  time,

 where  is the longest length of any input
sequences, and .
\end{theorem}






\begin{corollary}\label{corollary1}
There exists a randomized algorithm such that there are positive
constants  and  that if the alphabet size is at least
, the number of sequences is at least , the motif
length is at least , and each character in motif region
has probability at most  of mutation,
then motif can be recovered in  time, where  is the longest length
of any input sequences, and .
\end{corollary}

We give a randomized algorithm for the case with 
mutation rate. The performance of the algorithm is stated in
Theorem~\ref{main-theorem2}. Theorem~\ref{main-theorem2} implies
Corollary~\ref{corollary2} by selecting  with some
constant  large enough..

\begin{theorem}\label{main-theorem2}Assume that the alphabet size  is at least . There
exists a randomized algorithm such that there is a constant 
that
 if the length of the motif  is at least ,
then given  independent -sequences, the
algorithm
 outputs
 such that

1) with probability at most , , and

2) for each , with probability at most
, ,

3)  with probability at most , the algorithm
\algmnam~does not stop in ,

 where  is the longest length of any input
sequences, and .
\end{theorem}


\begin{corollary}\label{corollary2}
There exists a randomized algorithm such that there are positive
constants , and  that if the alphabet size is at
least , the number of sequences is at least , the
motif length is at least , and each character in motif
region has probability at most  of mutation, then motif can
be recovered in 
time.
\end{corollary}





We give a deterministic algorithm for the case with 
mutation rate.  The performance of the algorithm is stated in
Theorem~\ref{main-theorem3}. Theorem~\ref{main-theorem3} implies
Corollary~\ref{corollary3} by selecting  with some
constant  large enough.

\begin{theorem}\label{main-theorem3}Assume that the alphabet size  is at least . There
exists a deterministic
algorithm such that there is a constant  that if the length of
the motif  is at least , then given  independent
-sequences, algorithm runs in , and outputs  such that

1) with probability at most , , and

2) for each , with probability at most
, ,

3)  with probability at most , the algorithm
\algmnam~does not stop in 
time,

 where  is the longest length of any input
sequences, and .
\end{theorem}

\begin{corollary}\label{corollary3}
There exists a deterministic algorithm such that there are positive
constants , and  that if the alphabet size is at
least , the number of sequences is at least , the
motif length is at least , and each character in motif
region has probability at most  of mutation, then motif can
be recovered in  time.
\end{corollary}










\section{\algmname}
In this section, we give an unified approach to describe three
algorithms. The performance of the algorithms is stated in the
Theorems~\ref{main-theorem1}, \ref{main-theorem2}, and
\ref{main-theorem3}. The description of \algma is given at
section~\ref{algorithm-sec}. The analysis of the algorithm is given
at section~\ref{analysis-sec}.







\subsection{Some Parameters}
\begin{definition}\label{param-def}\scrod
\begin{enumerate}
\item
Constant  is selected to be . This parameter controls the
failure probability of our algorithms to be at most .
\item
The size of alphabet is  that is at least .
\item
Select a constant  to have
inequality~(\ref{alpha-init-ineqn})

\item The constant  is selected to satisfy

The existence of  follows from
inequality~(\ref{alpha-init-ineqn}). The constant  is used
to control the mutation in the motif area. It is a part of parameter
 defined in item~(\ref{beta-def}) of this definition.

\item
Let . The constant  is used to simply
probabilistic bounds which are derived from the applications of
Chernoff bounds (See Corollary~\ref{chernoff-lemma-a}).

\item
Define .

\item
 Define  to be a large constant that for all ,




\item Select constant  such that


The existence of  follows from , which is implied by
inequality~(\ref{epsilon-set-ineqn}).



\item Select constant  and  constant positive integer  large enough such that


\item
Define , and
.




\item Select constant  such that

 Adding inequalities~(\ref{rho1-ineqn}), (\ref{rho2-ineqn}), and (\ref{rho2-alpha0-inequality}), we have
 inequality~(\ref{median-ineqn})



By arranging the terms in inequality~(\ref{median-ineqn}) and the
definitions of  and , we have
inequality~(\ref{v-alpha0-ineqn})





\item
The maximal mutation rate  for the second algorithm
(Theorem~\ref{main-theorem2}) and third algorithm
(Theorem~\ref{main-theorem3}) are selected as . Since the
mutation rate of our sublinear time algorithm is bounded by , the maximal mutation rate  for the first
algorithm (Theorem~\ref{main-theorem1}) is less than  when
 is large enough. We always assume that all mutation rates
 in our three algorithms are in the range .



\item
Define . By inequality~(\ref{v-alpha0-ineqn}), the definition of , and
the fact , we have


Inequality~(\ref{v-set-ineqn1}) implies . By
inequality~(\ref{v2-ineqn}), we have that




\item\label{beta-def}
 Let
. The parameter  controls the
similarity of  and the original motif  (see
Lemma~\ref{base}).

\item
Define .




\item
We define the following . 
The parameter  used in~Lemma~\ref{base} gives an upper  bound
of the probability that a -sequence  whose
 will not be similar enough to the original motif 
according to the conditions in~Lemma~\ref{base}.


\item
Select constant  such that





\item
Select constant  such that .

\item
Select number  such that

Since only  is variable, we can make .





\item
For a fixed , define .
\end{enumerate}
\end{definition}



\subsection{Description of  \algma}\label{algorithm-sec}

The algorithm is described in this section. Before presenting the
algorithm, we define some notions.



\begin{definition}\label{match-def}{\scrod}
\begin{itemize}
\item
Two sequences  and  are {\it weak left matched} if (1)
both  and  are at least , (2)
 for all integers , .

\item
Two sequences  and  are {\it left matched} if (1) , (2)  for , and
(3)  for all integers , .

\item
Two sequences  and  are {\it weak right matched} if
 and  are weak left matched, where 
is the inverse sequence of .

\item
Two sequences  and  are {\it right matched} if  and
 are left matched, where  is the inverse
sequence of .

\item
Two sequences  and  are {\it matched} if  and 
are both left and right matched.
\end{itemize}
\end{definition}


Variable  will be controlled in the range  in our algorithm with
high probability. We define the following functions that depend on
.

\begin{definition}\label{M-M1-def}
Define .
 Define  (see
Definition~\ref{param-def} for ), where .
\end{definition}

We would like to
minimize the function . This selection can
make the total time complexity sublinear.





















\begin{definition}
For a  sequence , define \LB() to be the
left boundary  of the motif region  in , and
\RB() to be the right boundary  of the motif region
 in  such that .
\end{definition}



\subsubsection{\phaseone~of \algma}
 The first phase of \algma~finds the rough motif boundaries of all
input sequences. It first detects the rough motif boundaries of one
sequence via comparing two input sequences. Then the rough
boundaries of the first sequence is used to find the rough motif
boundaries of other input sequences.


Three algorithms share most of the functions. We have a unified
approach to describe them. A special variable ``\algtype" selects
one of the three algorithms, respectively.

\begin{definition}
Let \algtype~represent one of the three algorithm types,
``\sublinear", "\randomized", and "\deterministic".
\end{definition}


\begin{definition}
Assume that  is a set of positions in a 
sequence  and  is a set of positions in a
 sequence . If there is a position
 and  such that for some position  with
,  is the position of  in 
and  is the position of  in , then 
and  have a {\it collision} at .
\end{definition}


In the following function Collision-Detection, the parameter
 is defined below in the three  algorithms.



\vskip 10pt {\bf Collision-Detection}

{\bf Input:} a pair of -sequences  and
,  is a set of locations in  for .


{\bf Output:} the left and right rough boundaries of two sequences.


\qquad Let  be all subsequences  of 
of length  with .

\qquad Let  be all subsequences  of 
of length  with .



\qquad Find two  subsequences 
and

\qquad  such that  is the
least and .

\qquad Find two subsequences  and

\qquad  such that  is
the largest and

\qquad .

\qquad Find two  subsequences 
and

\qquad  such that  is the
least and

\qquad .

\qquad Find two subsequences  and

\qquad  such that  is
the largest and

\qquad .


\qquad Return .

{\bf End of Collision-Detection}

Function Point-Selection will be defined differently in
three different algorithms. It selects some positions from each
interval of length  in both  and .




\vskip 10pt {\bf Point-Selection}

{\bf Input:} a pair of -sequences ,  a size
parameter  of partition, and an interval of positions  in .

{\bf Output:} a set  of positions from  respectively.


 {\bf Steps:}

Let .


If \algtype=\sublinear~or~\randomized

\qquad If 


\qquad\qquad For each interval  in , partition   into
intervals of size .

\qquad\qquad  Sample  random positions at every

\qquad\qquad\qquad\qquad interval of size  derived in the above
partition, and put them into .

\qquad Else

\qquad\qquad Put every position  of  into .

If \algtype=\deterministic

\qquad\qquad Put every position  of  into .

Return .



{\bf End of Point-Selection}













\vskip 10pt {\bf Improve-Boundaries}

{\bf Input:} a -sequence  with rough left
and right boundaries  and , a
-sequences  with rough left and right
boundaries  and , and the rough distance  to the
nearest motif boundary from those rough boundaries.


{\bf Output:} improved rough left and right boundaries for both
 and .


 {\bf Steps:}








\qquad Find two subsequences  and





\qquad with  and  such
that  and  is

\qquad the least.


\qquad Find two subsequences  and


\qquad with  and 
such that   and   is

\qquad the largest.


\qquad Find two subsequences  and


\qquad with  and  such
that   and  is


\qquad the least.


\qquad Find two subsequences  and


\qquad with  and 
such that   and  is

\qquad  the largest.

\qquad Return .

{\bf End of Improve-Boundaries}







\vskip 10pt {\bf Initial-Boundaries}

{\bf Input:} a pair of -sequences  and


{\bf Output:} rough left boundary  of , right
boundary  of , rough left boundary
 of , and right boundary 
of .


 {\bf Steps:}

\qquad Let .

\qquad Let .

\qquad Repeat


\qquad\qquad Let Point-Selection.

\qquad\qquad Let Point-Selection.

\qquad\qquad Let
Collision-Detection.

\qquad\qquad If ( and
)


\qquad\qquad Then Goto H.

\qquad\qquad Else .

\qquad Until 

\qquad H: Return Improve-Boundaries.



{\bf End of Initial-Boundaries}


\vskip 10pt

{\bf Motif-Length-And-Boundaries()}

{\bf Input:}  is a set of
independent  sequences.

{\bf Steps:}

For  to 

\qquad let
=Initial-Boundaries.


Let  be the median of
.


Return .

 {\bf End of Motif-Length-And-Boundaries}







\subsubsection{\phasetwo~ of \algma}




After a set of motif candidates  is produced from \phaseone~ of
algorithm \algmnam, we use this set to match with another set of
input sequences to recover the hidden motif by voting.

\vskip 10pt





{\bf Match}

{\bf Input:} a motif left part   (which can be derived from the
rough left boundary of an input sequence ), a motif right part
, a sequence  from the group , with known rough
left and right boundaries.

{\bf Output:} either a rough motif region of , or an empty
sequence which means the failure in extracting the motif region
 of .


{\bf Steps:}

\qquad Find a position  in  with .


\qquad such that  and  are left matched
(see Definition~\ref{match-def}).


\qquad Find a position  in  with


\qquad such that  and  are right matched
(see Definition~\ref{match-def}).


\qquad If both  and  are found

\qquad Then output 


\qquad Else output  (empty string).


{\bf End of Match}



\vskip 10pt



{\bf Extract):}

Input  and their rough left
boundaries and rough right boundaries.


{\bf Steps:}

\qquad For each  with ,

\qquad\qquad let .

\qquad  Return .

{\bf End of Extract}

\vskip 10pt



The following is \phasetwo~ of algorithm \algmnam. It  extracts the
motif regions of another set  of input sequences.

{\bf \phasetwo():}

Input  is an input sequence with known  and
 for its rough left and right boundaries
respectively, and  is a set of
input sequences.


{\bf Steps:}

\qquad For each subsequence  with 

\qquad and  with 

\qquad\qquad let  be the output
from Extract).

\qquad\qquad  If  the number of empty sequences in  is at most 


\qquad\qquad Then return .


\qquad Return  (empty set).

{\bf End of \phasetwo~}


\subsubsection{\phasethree}

The function Vote is to generate
another sequence  by voting, where  is the most frequent
character among .

 \vskip 10pt

{\bf \phasethree}

{\bf Input:}  sequences  of the same length .


{\bf Output:} a sequence , which is derived by voting on every
position of the input sequences.


 {\bf Steps:}



\qquad For each 

\qquad\qquad let  be the most frequent character among
.

\qquad Return .

{\bf End of Vote}


\subsubsection{Entire \algma}

 The entire algorithm is described below. We maintain the size of  and  to be
roughly equal, which implies


{\bf \algma(Z)}


Input: , where  and
 are two sets of input sequences.

{\bf Steps:}


{\bf Preprocessing Part:}

For each , let  (the
two boundaries are unknown).

MotifLengthAndBoundaries().


Let .

For  to ,

\qquad let Point-Selection

\qquad \qquad \qquad\hskip 13pt Point-Selection.


For  to 

\qquad let Point-Selection.


For  to 



\qquad For each 

\qquad\qquad Let Collision-Detection.

\qquad\qquad Let =

\qquad\qquad\qquad Improve-Boundaries.



\qquad Let  be the output from
\phasetwo().



\qquad If  is not empty

\qquad Then go to Voting Part.



{\bf Voting Part:}

\qquad Return \phasethree().

{\bf End of \algma}










\section{Analysis of Algorithm}\label{analysis-sec}
 The correctness
of the algorithm will be proved via a series of Lemmas in
Sections~\ref{sec-analysis} and~\ref{sec-analysis2}.
Section~\ref{sec-analysis} is for \phaseone~ and
Section~\ref{sec-analysis2} is for \phasetwo. Furthermore,
Section~\ref{sec-analysis2} gives some lemma for the two randomized
algorithms and Section~\ref{deterministic-sec} gives the proof for
the deterministic algorithm.





\subsection{Review of Some Classical Results in Probability}

Some well known results in classical probability theory are listed.
The readers can skip this section if they understand them well. The
inclusion of these results make the paper self-contained.
\begin{itemize}
\item
 For a list of events ,
.
\item
For two independent events  and , .
\item
For a random variable ,  for all
positive real number . This is called Markov inequality.
\end{itemize}


The analysis of our algorithm employs the Chernoff bound
\cite{MotwaniRaghavan00} and Corollary~\ref{chernoff-lemma-a} below,
which can be derived from it
(see~\cite{LiMaWang99}).



\begin{theorem}[\cite{MotwaniRaghavan00}]\label{chernoff-theorem}
Let  be  independent random - variables,
where  takes  with probability . Let , and . Then for any ,
\begin{enumerate}
\item , and
\item
.
\end{enumerate}
\end{theorem}






We follow the proof of Theorem~\ref{chernoff-theorem} to make the
following version of Chernoff bound so that it can be used in our
algorithm analysis. 

\begin{theorem}\label{ourchernoff-theorem}
Let  be  independent random - variables,
where  takes  with probability at most . Let
. Then for any ,
.
\end{theorem}


\begin{proof} Let  be an arbitrary positive real number. By the
definition of expectation, we have
. Since the function
 is increasing for all  and ,
we have . We have the following
inequalities:

The inequality (\ref{markov-inequ}) is based on Markov inequality.
The transition from (\ref{independent1}) to (\ref{independent2}) is
due to the independence of those variables .

Since  is minimal at
, we have
.
\end{proof}

Define .
We note that  is always strictly less than  for all
, and  is fixed if  is a constant. This
can be verified by checking that the function  is decreasing and . This is
because , which is less than  for all .


\begin{theorem}\label{ourchernoff-theorem}
Let  be  independent random - variables,
where  takes  with probability at most . Let
. Then for any ,
.
\end{theorem}

\begin{proof}

for each real number . Applying Markov inequality, we have

The transition from~(\ref{chernoff-2}) to (\ref{chernoff-2}) is to
let . The transition
from~(\ref{chernoff-3}) to (\ref{chernoff-4}) follows from the fact
.
\end{proof}

\begin{corollary}[\cite{LiMaWang99}]\label{chernoff-lemma-a}
Let  be  independent random - variables
and .

 i. If  takes  with probability at most , then for any , .


ii. If   takes  with probability at least , then for any
, .
\end{corollary}




\begin{proof}
For , . Let
. (1) follows from
Theorem~\ref{chernoff-theorem}.  By Taylor theorem,
. We have that
. Thus, . Since
 and the function  is
increasing for ,  Thus (ii) is proved.
\end{proof}

\subsection{Analysis of \phaseone~ of  \algma}\label{sec-analysis}
















Lemma~\ref{base-probability-lemma} shows that with only small
probability, a sequence can match a random sequence. It will be used
to prove that when two substrings in two different
-sequences are similar, they are unlikely not to
coincide with  the motif regions in the two
-sequences, respectively.


\begin{lemma}\label{base-probability-lemma}
Assume that  and  are two independent sequences of the
same length and that every character of  is a random character
from . Then
\begin{enumerate}
\item
 if , then the probability that  and
 are matched is  (); and
\item
 the probability for  is at most .
\end{enumerate}
\end{lemma}


\begin{proof} The two statements are proved as follows.

Statement i: For every character  with , the
probability is  that .

\hskip 35pt Statement ii: For every character  with , the probability is  for  to equal
. If , the two sequences  and
 are identical at least  positions, but the
expected number of positions where the two sequences are identical
is . The probability for 
is at most  by Corollary~\ref{chernoff-lemma-a},
and Definitions~\ref{param-def} and~\ref{match-def}.
\end{proof}





Lemma~\ref{diff-motif-lemma} shows that with small probability, an
input  sequence contains motif region that has
many mutations.


\begin{lemma}\label{diff-motif-lemma}
With probability at most ,  a 
sequence  changes more than  characters in its
first left  motif region  for some  with , where .
\end{lemma}

\begin{proof}
Every character in the  region has probability at most
 to mutate. We know that .  By
Corollary~\ref{chernoff-lemma-a}, with probability at most
, a sequence  in  has more than
 mutations (recall the setting for  at
Definition~\ref{match-def}) among the first left  characters. The
total is .
\end{proof}


Lemma~\ref{v+u-lemma2} shows that Improve-Boundaries() has good
chance to improve the accuracy of rough motif boundaries.

\begin{lemma}\label{v+u-lemma2}
Assume that  sequence  has 
 and  for . Then
 for  =Improve-Boundaries,
 we  have the following two facts:
\begin{enumerate}
\item
 With probablity at most
,  is not in  for
.
\item
 With probablity at most
,  is not in  for
.
\item
Improve-Boundaries runs
in  time.
\end{enumerate}
\end{lemma}

\begin{proof}
We need a bound for the following inequality:

 Let . Compute the
derivative . We
also have the closed form for the function , which implies


 Let  and . We have
 .


Statement i. By Lemma~\ref{diff-motif-lemma}, with probability at
most , one of the left motif first  characters
region of  will change  characters. Therefore,
with probability at most ,
.


For a pair of positions  in  and  in , without loss
generality, assume that  has larger distance to the left boundary
 of  than  to the left boundary  of
. Let  be the distance from  to the left boundary
 of .

By Lemma~\ref{base-probability-lemma}, the probability is at most
 that there will be a match. There are at most 
cases for . With probability is at most  by inequality
(\ref{sum-eqn}), .

For the cases that one position  is in random region and has
distance more than  with the left boundary, the
probability is at most 
by inequality~(\ref{d0-sel-eqn}).

Therefore, we have total probability at most  that
 is not in .


Statement ii. One can also provide a symmetric analogous proof for
this statement.

Statement iii. The computation time easily follows from the
implementation of
Improve-Boundaries.
\end{proof}











\begin{lemma}\label{initial-boundary-lemma}
Assume that for each  with , with
probability at most ,  for , where Collision-Detection(,
Point-Selection, and Point-Selection.
 Then with probability at most , Initial-Boundary returns  with  
 or  for ;
\end{lemma}


\begin{proof}
It follows from Lemma~\ref{v+u-lemma2}.
\end{proof}


\begin{lemma}\label{select-median-lemma}
Assume that with probability , each  has its rough
boundaries  or , then with probability at most
,  is not in , where  is selected as median of
.
\end{lemma}


\begin{proof}
If both  and , then
 is in .

If the median of

is not in , then there are at least 
s to have  or .


On the other hand, the probability is at most ,
 or
.
So,  this lemma follows from Corollary~\ref{chernoff-lemma-a}.
\end{proof}


For a -sequence , we often obtain its left
rough boundary with . Some times its
exactly left boundary may be miss in the algorithm.

\begin{definition}\scrod
\begin{itemize}
\item
A -sequence  misses its left boundary if
.
\item
A -sequence  misses its right boundary if
 .
\end{itemize}
\end{definition}

\begin{definition}\label{stable-def}\scrod
\begin{itemize}
\item
  A -sequence  contains a {\it left half stable} motif region 
if  for all
, where ,  and  as defined in Definition~\ref{param-def}
and Section~\ref{notation-sec}, respectively.
\item
 A -sequence  contains a {\it right half stable} motif region 
if  for
, where  and .
\item
  A -sequence  contains a {\it stable} motif region 
satisfying  the following conditions: (1)  for
; (2)  for ;
(3)  motif region is both left and right half stable, where
 and .
\end{itemize}
\end{definition}

\begin{lemma}\label{left-boundary-detect-lemma}
 Assume that
\begin{itemize}
\item
  ;
\item
  contains a both left half and right half stable motif region and 
 and  (see Definition~\ref{param-def} for  and
 ); and
\item
for each  with , if  has
 and
, then
 with probability at most
, 
for , where Collision-Detection(,
Point-Selection
Point-Selection, and
Point-Selection .
\item
The rough boundaries for all sequences  are computed
via Collision-Detection, and =Improve-Boundaries
.
\end{itemize}

 Then with probability at most , there are
more than  sequences  in  with  or .
\end{lemma}

\begin{proof}
According to the condition of this lemma, with probability at most
, , where Collision-Detection( and Point-Selection.

For a fix pattern from , by Lemma~\ref{base-probability-lemma},
with probability at most , it has distance more than  to the true left boundary. As
we need to deal with  possible patterns from , with
probability at most ,
.

Similarly, with probability at most , . Let
.


With probability at most ,   does
not contain a left half stable motif region by
Lemma~\ref{diff-motif-lemma}. Similarly, with probability at most
,   does not contain a right half
stable motif region. Let .

Although  is involved to search the left boundary with all other
sequences. The non-missing condition is to let each sequence do not
change too many characters in the motif region. Therefore, this is
an independent event for each sequence. It is safe to use Chernoff
bound to deal with it.

With probability at most , the are
more than  sequences  in
 with  or .

\end{proof}





\subsection{Analysis of \phasetwo~and \phasethree~of  \algma}\label{sec-analysis2}



\begin{figure}{
\vskip 100pt
  {\begin{picture}(5.0,5.0)

      \put(0.0, 75.0){{} }




      \put(190.0, 20.0){{} }

      \put(180.0, 23.0){\begin{picture}(0.0,0.0)
                           \thinlines{\vector(-1,0){130.0}}
                         \end{picture}
                        }


      \put(215.0, 23.0){\begin{picture}(0.0,0.0)
                           \thinlines{\vector(1,0){150.0}}
                         \end{picture}
                        }

    \put(380.0, 30.0){  }

    \put(25.0, 30.0){  }



      \put(0.0, 33.0){}



      \put(20.0, 40.0){\begin{picture}(0.0,0.0)
                           \thicklines{\line(1,0){390.0}}
                         \end{picture}
                        }



      \put(365.0, 40.0){\begin{picture}(0.0,0.0)
                           \thinlines{\line(0,-1){5.0}}
                         \end{picture}
                        }

      \put(50.0, 40.0){\begin{picture}(0.0,0.0)
                           \thinlines{\line(0,-1){5.0}}
                         \end{picture}
                        }


      \put(20.0, 80.0){\begin{picture}(0.0,0.0)
                           \thicklines{\line(1,0){390.0}}
                         \end{picture}
                        }


   \end{picture}
 }\caption{ and }\label{figure2}
}\end{figure}

Lemma~\ref{base} shows that with high probability, the left and last
parts of the motif region in a -sequence do not
change much.


\begin{lemma}\label{base}  With probability at most
,
a -sequence  does not contain a stable motif
region.
\end{lemma}

\begin{proof}
The probability is  not to satisfy conditions (1)
and (2) of Definition~\ref{stable-def}. Consider condition (3).
Since every character of  (notice that ) has
probability at most  to mutate, by
Corollary~\ref{chernoff-lemma-a}, the probability is at most
 that . Let
,
where  as defined in
Definition~\ref{param-def}. Therefore, the probability is at most
 that  for some .
Similarly we define  for the probability on the right-hand side.
The probability is at most  that  for some . The probability that  does not contain a stable motif
region is at most .
\end{proof}

\begin{definition} Assume that  contains
 that contains a stable motif region. We fix such a
.
\begin{itemize}
\item
Define  to be the left part
of the motif region .
\item
Define  to be the
right part of the motif region .
\end{itemize}
\end{definition}

Lemma~\ref{small-shift-lemma} shows that with high probability,
\phasetwo~ of algorithm \algmnam~extracts the correct motif regions
from the sequences in . It uses  to match  in
another sequences . The parameter  gives a small probability
that the matched region between  and  is not in .

\begin{lemma}\label{small-shift-lemma}\scrod
\begin{enumerate}
\item
 Assume that  and  are  fixed sequences of length .
 Let  be a
-sequence with  and
let  be the number of characters of M that are not in the
region of . Then the probability is  at most  that
, where  is defined in Definition~\ref{param-def}.
\item
 The probability is  at most
 that given a -sequence ,
.
\end{enumerate}
\end{lemma}



\begin{proof} Assume that . Let  be the number of characters outside of  on
the left of , and let  be the number of characters outside of
 on the right of . Clearly, . Since , either  or . See Figure~\ref{figure2}. Without
loss of generality, we assume .

Statement i: There are two cases.


Case (a): .  By Lemma~\ref{base-probability-lemma}, the
probability for this case is at most  for a fixed .
The total probability for this case for  is at most
.

Case (b): . By Lemma~\ref{base-probability-lemma}, the
probability is at most  for a fixed .
The total probability for  is at most .


The probability analysis is similar when . Therefore, the
probability for this case is at most  for .

Statement ii: By Lemma~\ref{base}, with probability at most  ,
  does not contain a stable motif region.
Therefore, we have probability at most  that given a random
-sequence , .
\end{proof}

Lemma~\ref{large-algphabet-shift0-lemma} shows that we can use 
and  to  extract most of the motif regions for the sequences in
 if
  (recall that  is defined right after Lemma~\ref{base}).

\begin{lemma}\label{large-algphabet-shift0-lemma} Assume that  and 
are two sequences of length , and
  for  and   (recall that
 each sequence
 is either an empty sequence or a sequence of the length
).
\begin{enumerate}
\item
 If , , and there are no more than  ()
sequences  with  or , then the probability is  at most
 that there are more than
 sequences  with .
\item
For arbitrary  and , with probability at most
, , where
 is defined in Definition~\ref{param-def}.
\end{enumerate}
\end{lemma}



\begin{proof} Recall that sequence  is selected right after
Lemma~\ref{base}.


Statement i: By Lemma~\ref{small-shift-lemma}, for every , the probability is  at most  that  does not
contain a stable motif region . By
Corollary~\ref{chernoff-lemma-a}, we have probability at most
 that there are more than
 sequences  with .

Statement ii:  By Lemma~\ref{small-shift-lemma}, the probability is
at most  that .  By
Corollary~\ref{chernoff-lemma-a}, with probability  at most
, .
\end{proof}







\begin{definition}\scrod
\begin{itemize}
\item
 Given two sequences  and , define

Match .
\item
For a  sequence , define  to be
the , which is the leftmost subsequence of
length  in the motif region of .
\item
For a  sequence , define   to be
the , which is the rightmost subsequence
of length  in the motif region of , where
.
\end{itemize}
\end{definition}

the condition~\ref{V_0-condition} of Lemma~\ref{general-lemma}

\begin{lemma}\label{general-lemma}
Assume that we have the following conditions:
\begin{enumerate}
\item\label{varsigma1-condition}
For each  with , with probability at most
,  and
 for , where
Collision-Detection(, Point-Selection, and
Point-Selection.

\item\label{varsigma2-condition}
For each  with , if  has
 and
, then
 with probability at most
,  for , where Collision-Detection(,
Point-Selection
Point-Selection, and
Point-Selection.

\item\label{P0-Q0-condition}
The inequality  holds for some constant ,
where  is defined at equation (\ref{Q0-def-eqn}) and
.

\item\label{V_0-condition} The inequality
 holds, where
.
\end{enumerate}

Then the algorithm generates a set of at most  subsequences for
voting and votes a sequence  such that

(1) with probability at most ,
, and

(2) for each , with probability at most
, .
\end{lemma}

Before proving Lemma~\ref{small-shift-lemma}, we note that both
 and  is at most 
for all of the three algorithms. They will be proved by
Lemma~\ref{collision-lemma} and Lemma~\ref{collision-lemma2} for the
case~\algtype=\sublinear, Lemma~\ref{collision-lemma-2A} and
Lemma~\ref{collision-all-select-lemma} for the
case~\algtype=\randomized, and Lemma~\ref{collision-lemma2-3A} for
the case~\algtype=\deterministic.


\begin{proof}



By Lemmas~\ref{initial-boundary-lemma}, with probability at most ,  or
.

 By
Lemma~\ref{select-median-lemma}, with probability at most
, the
approximate motif length  is not in the range
.


 By Lemma~\ref{base}, with probability at
most , a  sequence does not contain a
stable motif region. Therefore, with probability at most
, the following statement is false.

(i) One of  for  has
,
, and has a stable motif
region.

By Lemma~\ref{left-boundary-detect-lemma}, with probability at most
, there are more than
 sequences  with
 or
. In
other words, with probability at most , the following statement
is false:

(ii) There are no more than  sequences  with
 or
, where
.





Assume that Statement (ii) is true. By
Lemma~\ref{large-algphabet-shift0-lemma}, with probability at most
, the following statement is false.

(iii)  contains at most  empty
sequences.



We start from the rough left boundary  of  to
match the other left boundaries of  for .
There are totally at most  candidates to consider.

By Lemma~\ref{large-algphabet-shift0-lemma},  if ,
which consists  matched regions,  has at most
 empty sequences, then it has more than
 from non-motif regions with probability at most
.
After the pattern is fixed, those events in the matching are
considered to be independent each other. This is why we can apply
the Chernoff bound to deal with them. So, the probability is at most
, the following statement is false.

(iv). If   contains at most 
empty sequences, then  contains at most

elements not from motif regions .

Therefore, with probability at most , the sequences are not ready for
voting in the next phase, which means the following two conditions
are satisfied:

(a). There exists  and  generated by the algorithm such
that  contains at most  elements
not from motif regions .

(b). For every  and  that   contains at most
 empty sequences generated by the algorithm,
 contains at most

elements not from motif regions .

Statement (1): For a  with at most
 elements not from motif regions
, we still have
 elements in  from
motif regions .
By by the condition~(\ref{V_0-condition}) in this lemma, we have
.
Therefore,  is selected to be the length of  in the
\phasethree().



Statement (2): For a  with
at most  elements not from motif regions
, we still have
 elements in  from
motif regions .
By Corollary~\ref{chernoff-lemma-a}, with probability at most
 there are more than
 characters are mutated in the same position
among all  the motif regions for the sequences in . We
have that

by the condition~(\ref{V_0-condition}) in this lemma.
We let  be the most
frequent character among  in
\phasethree.
 Therefore, with probability at most , .

\end{proof}


We will use multiple variable functions to characterize the
computational time for three algorithms. In order to unify the
complexity analysis of three algorithm, we introduce the following
notation.

\begin{definition}
A function  is monotonic if it is
monotonic on both variables. If for arbitrary positive constants
 and ,   for some positive
constant , then  is {\it slow}.
\end{definition}

\begin{lemma}\label{total-time-lemma} Assume that , 
and  are monotonic slow functions.
 Assume that Collision-Detection() returns
 the result in time  time and the Point-Selection() selects  positions in
  time.
Assume that with probability at most , the function does
not stop Initial-Boundaries() does not stop when , and
 in the algorithm \algmnam~ is no
more than .

 Then with probability at most ,
the entire algorithm \algmnam~  does not stop in the time complexity
, where  is the largest
 such that  and
.
\end{lemma}

\begin{proof}
The function Initial-Boundaries()is executed  times. According
to the condition that with probability at most , the
function does not stop Initial-Boundaries(.) does not stop when
, we have the fact that with probability at most
, one of those executions of Initial-Boundaries(.)
does not stop when .


In the rest of the proof, we assume that all executions of
Initial-Boundaries(.) stops when .

When , we detect rough left and right motif boundaries and
run Improve-Boundaries(), which takes  time. It takes
 time to run Initial-Boundaries() one time for one pair () in . It
takes  time to run
Initial-Boundaries() one time for all pairs
() in .

It takes  time to find the rough
boundaries for all sequences in  with a fixed sequence  from
 by executing the for loop ``For each " in the
algorithm \algmnam. It takes  time
to find the rough boundaries for all sequences in  via all
sequences  from  through for loop ``For each
" in the algorithm \algmnam.

Recall that parameters  and  are constants, and  is
. Calling Match() takes  time for each . The total times for calling
Match() is .


The voting part takes  time for executing voting for
recovering one character in motif.
\end{proof}




\subsection{Randomized Algorithms for Motif Detection}

In this section, we present two randomized algorithms for motif
detection. The first one is a sublinear time algorithm that can
handle  mutation, and the second one is a
super-linear time algorithm that can handle  mutation.
They also share some common functions.



\begin{lemma}\label{alpha-lemma} Let  be a constant in .
Assume  and  are two non-negative integer with . Then
for every integer  with ,
, where constant
 as defined in Definition~\ref{param-def}.
\end{lemma}

\begin{proof} We have the inequalities

\end{proof}


\begin{lemma}\label{spread-lemma}
Let   be a set of  elements with .
Assume that  are  random elements in . Then
with probability at most , the list  contains at most  different
elements from  (in other words, ).
\end{lemma}

\begin{proof}
For a subset  with , the probability is at
most  that all elements  are in
. For every subset  with , there
exists another subset  such that . We have
that . There are 
subsets of  with size . We have the probability at most
 that 
contains at most  different elements in .
\end{proof}





\begin{lemma}\label{intersection-lemma}
Let  be the same as that in Lemma~\ref{alpha-lemma}.
Let  be a constant in  and .
Let   and  for some fixed . Let  and  be
two sets of  elements with  and  be
a set of size  for some constant . Then for all large , with probability is at most
, we have , where  and  are two sets, which may have multiplicities, of  random
elements from  and , respectively.
\end{lemma}

\begin{proof} In the entire proof of this lemma, we always assume
that  is sufficiently large.
We are going to give an upper bound about the probability that 
does not contain any element in . For each element ,
with probability at most  that  is not in .
Therefore, the probability is at most 
that  does not contain any element in .

By Lemma~\ref{spread-lemma}, the probability is at most  that . We have the inequalities


The inequality , which is used from (\ref{ineq3b}) to (\ref{ineq4}),
follows from the fact that . The transition from
(\ref{ineq4}) to (\ref{ineq5}) follows from the fact  since  according to the conditions
of the lemma.

It is easy to see that  for all large . Thus,
 (note that  as
). Thus, by Lemma~\ref{alpha-lemma},  . This is why we have the transition from
(\ref{ineq6}) to (\ref{ineq7}). Therefore, .
\end{proof}


\subsubsection{Sublinear Time Algorithm for  Mutation Rate}




In this section, we give an algorithm for the case with at most
 mutation rate. The performance of the
algorithm is stated in Theorem~\ref{main-theorem1}.
















\begin{definition}
A position  in the motif region  of an input sequence
 is {\it damaged} if there exists at least one  mutation in
.
\end{definition}

\begin{lemma}\label{affected-points-lemma} Assume that . With probability at most ,  there are more than  positions  that  are from the  sampled positions
in an interval of length  and are damaged.
\end{lemma}

\begin{proof} By Theorem~\ref{ourchernoff-theorem},
with probability at most  (let ), there
are more than  mutation in an interval of length .
Therefore, with probability at most , there are more than  positions
are damaged. Therefore, each random position in an interval of
length  has at most probability  to be damaged.

Since  and  positions
are sampled,  by Theorem~\ref{ourchernoff-theorem}, with probability
at most 
(let ), the number of damaged positions sampled in an
interval of length  is more than . Thus, with
total probability at most ,
there are more than  damaged
positions that are from the  sampled positions in an interval of
length .
\end{proof}


\begin{definition}
Let  be a set of positions in an input sequence  with
. Let .
\end{definition}




\begin{lemma}\label{collision-lemma} Assume that   and .
Let  be a union of intervals that include  and . Let
Point-Selection,
Point-Selection,   and
  Collision-Detection.
Then
\begin{enumerate}
\item
With probability at most , the left rough
boundary  has at most  distance from  and
the left rough boundary  has at most  distance from
.

\item
 With probability at most , the right rough boundary  has at most
 distance from ; and the right boundary of 
has at most  distance from .
\end{enumerate}
\end{lemma}

\begin{proof}
We prove the following two statements which imply the lemma.
\begin{enumerate}
\item
With probability at most , there is no
intervals  from  and  from  such that (1)
 is at least
; (2) the left boundary of  has at most 
distance from ; (3) the left boundary of  has at most 
distance from ; and (4) there is collision between the sampled
positions in  and .

\item
 With probability at most , there is no intervals  from  and  from
 such that (1)  is at least ; (2) the right
boundary of  has at most  distance from ; (3) the
right boundary of  has at most  distance from ; and
(4) there is collision between the sampled positions in  and
.
\end{enumerate}
We only prove the statement i. The proof for statement ii is similar
to that for statement i.
Note that  goes down by half each cycle in the algorithm. Assume
that  satisfies the condition of this lemma.

Select  from  and  from  to be the first pair of
intervals with . It is easy to see that such a pair exists and both have
distance from the left boundary with distance at most . This is
because when an leftmost interval of length  is fully inside the
motif region of the first sequence, we can always find the second
interval from the second sequence with intersection of length at
least .


 Replace  by ,  by  (see Definition~\ref{M-M1-def}), and  by  to apply
Lemma~\ref{intersection-lemma}. We also let  be the set of
damaged positions  affected by the mutated positions. With
probability at most ,  has size more than
 by Lemma~\ref{affected-points-lemma}. With
probability at most , there is an no
intersection  from  and  from .
\end{proof}




\begin{lemma}\label{collision-lemma2} Assume that    and  is an integer with .
Let  be a union of intervals that include  and . Let
Point-Selection,
Point-Selection,   and
  Collision-Detection.
 Then
\begin{enumerate}
\item
With probability at most , the left rough
boundary  has at most  distance from  and
the left rough boundary  has at most  distance from
.

\item
 With probability at most , the right rough boundary  has at most
 distance from ; and the right boundary of
 has at most  distance from .
\end{enumerate}
\end{lemma}

\begin{proof}
For two sequences  and , it is easy to see that there a
common position in both motif regions of the two sequences such that
there is no mutation in the next  characters with high
probability. This is because that mutation probability is small.

By Theorem~\ref{ourchernoff-theorem}, with probability at most
 (let ), there are more than
 mutated characters in the interval  for
. Therefore, with probability at most , there are more than  positions are damaged in  .

Since the mutation probability is  and  positions are sampled, with
probability at most  (with ), the number of
damaged positions is more than  by
Theorem~\ref{ourchernoff-theorem}. The probability is
 that left side has
more than  damaged positions.

We have similar 
probability for the right side for more than  damaged positions in
.

Now we assume that left side has more than  damaged positions and
the right side for more than  damaged positions in
. Since each position in each
interval of length  is selected in
Point-Selection???, it is easy to verify the
conclusions of this lemma.
\end{proof}




\begin{lemma}\label{collision-time-lemma1}
For the case~\algtype=\sublinear, we have
\begin{enumerate}
\item
 CollisionDetection()  takes
 time.
\item
Point-Selection() selects  positions in  time if .
\item
Point-Selection() selects  positions
in  time if .
\item
 in the algorithm \algmnam~ is no
more than .
\item
With probability at most , the  algorithm \algmnam~
does not stop in  time.
\end{enumerate}
\end{lemma}

\begin{proof}
Statement i. The parameter  is set to be  in
the Collision-Detection. It follows from the time complexity of
bucket sorting, which is described in standard algorithm textbooks.

Statements ii and iii. They follows from the implementation of
Point-Selection().

Statement iv. It follows from the choice of Point-Selection(.) for
the sublinear time algorithm at Recover-Motif(.).



Statement v. It follows from Lemma~\ref{collision-lemma2},
Lemma~\ref{collision-lemma}, Lemma~\ref{total-time-lemma} and
Statements i, ii, and iii, and iv.
\end{proof}

We give the proof for Theorem~\ref{main-theorem1}.

\begin{proof}[Theorem~\ref{main-theorem1}]
The computational time part of this theorem follows from
Lemma~\ref{collision-time-lemma1}.


By Lemma~\ref{collision-lemma}, Lemma~\ref{collision-lemma2}, we can
let  for the
probability bound  in the
condition~(\ref{varsigma1-condition}) of Lemma~\ref{general-lemma}.

By Lemma~\ref{collision-lemma}, Lemma~\ref{collision-lemma2}, we can
let  for the
probability bound  in the
condition~(\ref{varsigma2-condition}) of Lemma~\ref{general-lemma}.

By inequality~(\ref{support-P0-Q0-inequality}),
the condition~(\ref{P0-Q0-condition}) of Lemma~\ref{general-lemma}
is satisfied.

 By inequality~(\ref{v-set-ineqn1}), we know that the
condition~(\ref{V_0-condition}) of Lemma~\ref{general-lemma} can be
satisfied.

 The failure
probability part of this theorem follows from
Lemma~\ref{v+u-lemma2}, and Lemma~\ref{general-lemma} by using the
fact that , and  are of the same order (see
equation~(\ref{Z1-Z2-eqn})).
\end{proof}


\subsubsection{Randomized Algorithm for  Mutation Rate} In
this section, we give an algorithm for the case with 
mutation rate.  The performance of the algorithm is stated in
Theorem~\ref{main-theorem2}.















\begin{lemma}\label{collision-lemma-2A} Assume that  
  and . Let  be a union of intervals that include  and . Let
Point-Selection,
Point-Selection,   and
  Collision-Detection.
  Then
\begin{enumerate}
\item
With probability at most , the left rough
boundary  has at most  distance from  and
the left rough boundary  has at most  distance from
.

\item
 With probability at most , the right rough boundary  has at most
 distance from ; and the right boundary of 
has at most  distance from .
\end{enumerate}
\end{lemma}

\begin{proof}
We prove the following two statements which imply the lemma.

\begin{enumerate}
\item
With probability at most , there is no
intervals  from  and  from  such that (1)
 is at least
; (2) The left boundary of  has at most 
distance from ; (3) The left boundary of  has at most 
distance from ; and (4) There is collision between the sampled
positions in  and .

\item
 With probability at most , there is no intervals  from  and  from
 such that (1)  is at least ; (2) The right
boundary of  has at most  distance from ; (3) The
right boundary of  has at most  distance from ; and
(4) There is collision between the sampled positions in  and
.
\end{enumerate}


We only prove the statement i. The proof for statement ii is
similar.
Note that  goes down by half each cycle in the algorithm. Assume
that  satisfies the condition of this lemma, and let 
happen in the algorithm.

Select  from  and  from  to be the first pair of
intervals with . It is easy to see that such a pair exists and both have
distance from the left boundary with distance at most . This is
because when an leftmost interval of length  is fully inside the
motif region of the first sequence, we can always find the second
interval from the second sequence with intersection of length at
least .


Replace  by ,  by  (see
Definition~\ref{M-M1-def}), and  by  to apply
Lemma~\ref{intersection-lemma}. We do not consider any damaged
position in this algorithm, therefore, let  be empty. With
probability at most , there is no intersection
 from  and  from .
\end{proof}







\begin{lemma}\label{collision-all-select-lemma}
  Let  and  contain all positions of the input sequences
   and , respectively.
  Assume Collision-Detection.
   Then
\begin{enumerate}
\item
With probability at most , the left rough
boundary  has at most  distance from 
and the left rough boundary  has at most 
distance from .

\item
 With probability at most , the right rough boundary  has at most
 distance from ; and the right rough
boundary of  has at most
 distance from .
\end{enumerate}

\end{lemma}

\begin{proof}
For two sequences  and , let  be the
subsequence  for . By
Corollary~\ref{chernoff-lemma-a}, with probability at most
 (see
inequality~\ref{param-def} at Definition~\ref{d0-sel-eqn}), there
are more than  mutations in  for .






In this case, every position in the two sequences  and  is
selected by Point-Selection().
With probability at most , the left boundary position is missed during the matching.
We have similar  to miss the right boundary.

Assume that  and  are two positions of  and  
respectively.  If one of two positions is outside the motif region
and has more than  distance to the motif boundary, with
probability at most 
(see inequality~\ref{param-def} at Definition~\ref{d0-sel-eqn}) for
them to match that requires  by
Lemma~\ref{base-probability-lemma}, where  is a subsequence
 for .
\end{proof}













\begin{lemma}\label{collision-lemma2-2Ab} Assume that  
  and .
  Let  be a union of intervals that include  and . Let
Point-Selection,
Point-Selection,   and
  Collision-Detection.
   Then
\begin{enumerate}
\item
With probability at most , the left rough
boundary  has at most  distance from 
and the left rough boundary  has at most 
distance from .

\item
 With probability at most , the right rough boundary  has at most
 distance from ; and the right boundary of
 has at most  distance from .
\end{enumerate}

\end{lemma}

\begin{proof}
In this case, every position in the two sequences  and  is
selected by Point-Selection(). It follows from
Lemma~\ref{collision-all-select-lemma}.
\end{proof}





\begin{lemma}\label{collision-time-lemma2}
For the case~\algtype=\randomized, we have
\begin{enumerate}
\item
 CollisionDetection()  takes
 time.
\item
Point-Selection() selects  positions in  time if .
\item
Point-Selection() selects  positions
in  time if .
\item
 in the algorithm \algmnam~ is no
more than .
\item
With probability at most , the algorithm \algmnam~
does not stop in  time.
\end{enumerate}
\end{lemma}

\begin{proof}
Statement i. The parameter  is set to be
 in the Collision-Detection. It follows from the time
complexity of brute force method.

Statements ii and iii. They follows from the implementation of
Point-Selection().

Statement iv.
It follows from the choice of Point-Selection(.) for the sublinear
time algorithm at Recover-Motif(.).

 Statement iv. It follows from
Lemma~\ref{collision-all-select-lemma},
Lemma~\ref{collision-lemma2-2Ab}, Lemma~\ref{total-time-lemma}, and
Statements i, ii, and iii.
\end{proof}








We give the proof for Theorem~\ref{main-theorem3}.

\begin{proof}[Theorem~\ref{main-theorem2}]
The computational time part of this theorem follows from
Lemma~\ref{collision-time-lemma2}.


By Lemma~\ref{collision-lemma-2A},
Lemma~\ref{collision-all-select-lemma}, we can let
 for the probability
bound  in the condition~(\ref{varsigma1-condition})
of Lemma~\ref{general-lemma}.

By Lemma~\ref{collision-lemma-2A},
Lemma~\ref{collision-all-select-lemma}, we can let
 for the probability
bound  in the condition~(\ref{varsigma1-condition})
of Lemma~\ref{general-lemma}.

By inequality~(\ref{support-P0-Q0-inequality}),
the condition~(\ref{P0-Q0-condition}) of Lemma~\ref{general-lemma}
is satisfied.

 By inequality~(\ref{v-set-ineqn1}), we know that the
condition~(\ref{V_0-condition}) of Lemma~\ref{general-lemma} can be
satisfied.

The failure
probability part of this theorem follows from
Lemma~\ref{v+u-lemma2}, and Lemma~\ref{general-lemma} by using the
fact that , and  are of the same order (see
equation~(\ref{Z1-Z2-eqn})).
\end{proof}


\subsection{Deterministic  Algorithm for  Mutation
Rate}\label{deterministic-sec}

 In this section, we give a deterministic algorithm for
the case with  mutation rate.  The performance of the
algorithm is stated in Theorem~\ref{main-theorem3}.














\begin{lemma}\label{collision-lemma2-3A} Assume that  
  and . Let  be a union of intervals that include  and . Let
Point-Selection,
Point-Selection,   and
  Collision-Detection.
  Then
\begin{enumerate}
\item
With probability at most , the left rough
boundary  has at most  distance from 
and the left rough boundary  has at most 
distance from .



\item
 With probability at most , the right rough boundary  has at most
 distance from ; and the right rough
boundary of  has at most
 distance from .
\end{enumerate}

\end{lemma}

\begin{proof}
In this case, every position in the two sequences  and  is
selected by Point-Selection(). It follows from
Lemma~\ref{collision-all-select-lemma}.
\end{proof}




\begin{lemma}\label{collision-time-lemma3}
For the case~\algtype=\deterministic, we have
\begin{enumerate}
\item
 CollisionDetection()  takes
 time.
\item
Point-Selection() selects  positions
in  time.

\item
 in the algorithm \algmnam~ is no
more than .

\item
With probability at most , the algorithm \algmnam~
does not stop .
\end{enumerate}
\end{lemma}

\begin{proof}
Statement i. The parameter  is set to be
 in the Collision-Detection. It follows from the time
complexity of brute force method.

Statement ii. They follows from the implementation of
Point-Selection().

Statement iii.
It follows from the choice of Point-Selection(.) for the sublinear
time algorithm at Recover-Motif(.).

Statement iv. It follows from Lemma~\ref{collision-lemma2-3A},
Lemma~\ref{total-time-lemma} and Statements i, ii, and iii.
\end{proof}





We give the proof for Theorem~\ref{main-theorem3}.

\begin{proof}[Theorem~\ref{main-theorem3}]
The computational time part of this theorem follows from
Lemma~\ref{collision-time-lemma3}.



By Lemma~\ref{collision-lemma2-3A}, we let  for the probability bound 
in the condition~(\ref{varsigma1-condition}) of
Lemma~\ref{general-lemma}.

By Lemma~\ref{collision-lemma2-3A}, we can let
 for the probability
bound  in the condition~(\ref{varsigma1-condition})
of Lemma~\ref{general-lemma}.

By inequality~(\ref{support-P0-Q0-inequality}),
the condition~(\ref{P0-Q0-condition}) of Lemma~\ref{general-lemma}
is satisfied.

By inequality~(\ref{v-set-ineqn1}), we know that the
condition~(\ref{V_0-condition}) of Lemma~\ref{general-lemma} can be
satisfied.

The failure
probability part of this theorem follows from
Lemma~\ref{v+u-lemma2}, and Lemma~\ref{general-lemma} by using the
fact that , and  are of the same order (see
equation~(\ref{Z1-Z2-eqn})).
\end{proof}















\section{Conclusions}
We develop an algorithm that under the probabilistic model. It finds
the implanted motif with high probability if the alphabet size is at
least , the motif length is in  and each character in motif region has probability at
most  of mutation. The motif region can
be detected and each motif character can be recovered in sublinear
time. A sub-quadratic randomized algorithm is developed to recover
the motif with  mutation rate. A quadratic deterministic
algorithm is developed to recover the motif with 
mutation rate. It is interesting problem if there is an algorithm to
handle the case for the alphabet of size . A more interesting
problem is to extend the algorithm to handle larger mutation
probability.



 \section*{Acknowledgements} We thank Ming-Yang Kao for introducing
 us to this topic. We also thank
 Lusheng Wang and Xiaowen Liu for some discussions. We would like to
 thank Eugenio De Hayos to his helpful comments.






\section{Experimental Results}



\subsection{Implementation and Results}
\noindent Aiming at solving the motif discovery problem, we
implemented our algorithm by JAVA. Our program could accept many
popular DNA sequence data formats, such as FASTA,GCG, GenBank and so
on. Our tests were all done on a PC with an Intel Core 1.5G CPU and
3.0G Memory.

In the first experiment, we tested our  algorithm on several sets of
simulated data, which are all generated from our probability model
with a small mutation rate. All input sets contain 20 or 15
sequences, each of length is 600 or 500 base pair. And each bp of
all the simulated gene sequences was generated independently with
the same occurrence probability. A motif with a length of 15 or 12
was randomly planted to each input sequence. The number of
iterations is between 10 and 30. The minimum Hamming distances
between the results and consensus are recorded.

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
 &N & M & L & R & Accuracy & timecost \\ [0.5ex]
\hline
Sets1&20 & 600 & 15 & 10 & 100 & 23\\
Sets1&20 & 600 & 15 & 30 & 100 & 85\\
Sets2&15 & 600 & 15 & 10 & 95 & 18\\
Sets3&20 & 600 & 12 & 10 & 95 & 15\\
Sets4&20 & 500 & 15 & 20 & 100 & 112\\
\hline

\end{tabular}
\end{center}

\begin{center}
Tab 1. Results on simulated data
\end{center}
\


In the second experiment,we tested our algorithm on real sets of
sequences, which are obtained from SCPD. SCPD contains a large
number of gene data and transcription factors of yeast. For each set
of gene sequences that are regulated by the same motif, we chose
1000bp as the length of input gene sequence. In order to make
comparisons among several existed motif finding methods, we also
tested Gibbs, MEME, Info-Gibbs and Consensus in our experiment to
show the difference of their performance. Here are the specific
experimental results:


\begin{center}
\begin{tabular}{|c|c|c|}
\hline
 & Number of Sequences & Motif Length\\ [0.5ex]
\hline
GCR1 & 6 & 10\\
\hline
\end{tabular}
\end{center}

\begin{center}
Tab 2. Number of sequences and motif length
\end{center}




\
\begin{center}
\begin{tabular}{|c|c|}
\hline & GCR1\\ [0.5ex] \hline
Voting& 4 \\
Gibbs& 5 \\
MEME& 10\\
InfoGibbs& 5\\
Consensus& 5\\
\hline
\end{tabular}
\end{center}
\begin{center}
Tab 3. Total number of mismatch positions compared to motif
\end{center}

\
\begin{center}
\begin{tabular}{|c|c|}
\hline &GCR1\\ [0.5ex] \hline
Voting& 0.67\\
Gibbs& 0.83\\
MEME& 1.67\\
InfoGibbs& 0.83\\
Consensus& 0.83\\
\hline
\end{tabular}
\end{center}

\begin{center}
Tab 4. Average mismatch numbers per sequence
\end{center}

\subsection{Analysis}
In the first experiment, we tested our algorithm on 4 sets of
simulated sequences. From our experimental results, we find that the
accuracy of our algorithm for finding motif in simulated data is
nearly 100\%. The accuracies of the experiments in simulated data
sets are satisfactory. Our algorithm can get the results within
several minutes.

From the second experimental results, we find that our  algorithm is
able to find the real motifs from given gene sequences in little
time. Our algorithm shows higher speed than other four motif finding
methods, because an initial motif pattern is first extracted from
comparing two sequences in the first stage of our algorithm. In
addition, unlike Gibbs sampling and EM methods, our algorithm could
avoid some extra time consuming computations, such as the
calculations of likelihoods. According to this feature, we use the
consensus string of the voting operation obtained from the result of
last iteration as a new starting pattern to program, and continue
doing voting until there is no further improvement. Experimental
results show that if we set the number of iterations to be large
enough, the program could give more accurate results in reasonable
time. Besides, in order to detect unknown motifs in sequences, our
program also provides several possible motifs existed in specific
sequences, and the average mismatch numbers of motifs that is
greatly lower than other four methods.

\section{Future works}
Compared with other tested motif finding methods, we could find that
the voting algorithm has advantages in some aspects, but there are
still some improvements could be done on this algorithm. As we know,
though a set of sequences may have the consensus, but each motif in
sequence may has mutations, and the length of each motif could also
be different. So the two factors increase the difficulties in
finding unknown motifs. In the future, we plan to improve the
efficiency of voting algorithm by studying other motif finding
methods, such as MEME, a combination may be made between voting
algorithm and MEME so that voting algorithm could have better
performance in finding unknown motifs.\\






\begin{thebibliography}{10}

\bibitem{ChinLeung05}
F.~Chin and H.~Leung.
\newblock Voting algorithms for discovering long motifs.
\newblock In {\em Proceedings of the 3rd Asia-Pacific Bioinformatics
  Conference}, pages 261--272, 2005.

\bibitem{DopazoSobrino93}
J.~Dopazo, A.~Rodr\'{\i}guez, J.~C. S\'{a}iz, and F.~Sobrino.
\newblock Design of primers for {{\rm PCR}} amplification of highly variable
  genomes.
\newblock {\em Computer Applications in the Biosciences}, 9:123--125, 1993.

\bibitem{FrancesLitman97}
M.~Frances and A.~Litman.
\newblock On covering problems of codes.
\newblock {\em Theoretical Computer Science}, 30:113--119, 1997.

\bibitem{FuKaoWang09b}
B.~Fu, M.-Y. Kao, and L.~Wang.
\newblock Probabilistic analysis of a motif discovery algorithm for multiple
  sequences.
\newblock {\em SIAM Journal Discrete Mathematics}, 23(4):1715--173, 2009.

\bibitem{FuKaoWang08b}
B.~Fu, M.-Y. Kao, and L.~Wang.
\newblock Discovering almost any hidden motif from multiple sequences in
  polynomial time with low sample complexity and high success probability.
\newblock {\em ACM Transactions on Algorithms}, 7(2):26, 2011.

\bibitem{GasieniecJanssonLingas99}
L.~G\c{a}sieniec, J.~Jansson, and A.~Lingas.
\newblock Efficient approximation algorithms for the {{\rm H}}amming center
  problem.
\newblock In {\em {Proceedings of the 10th Annual ACM-SIAM Symposium on
  Discrete Algorithms}}, pages S905--S906, 1999.

\bibitem{Gusfield97}
D.~Gusfield.
\newblock {\em Algorithms on Strings, Trees, and Sequences}.
\newblock Cambridge University Press, 1997.

\bibitem{HertzStormo94}
G.~Hertz and G.~Stormo.
\newblock Identification of consensus patterns in unaligned {{\rm DNA}} and
  protein sequences: a large-deviation statistical basis for penalizing gaps.
\newblock In {\em Proceedings of the 3rd International Conference on
  Bioinformatics and Genome Research}, pages 201--216, 1995.

\bibitem{KeichPevzner02}
U.~Keich and P.~Pevzner.
\newblock Finding motifs in the twilight zone.
\newblock {\em Bioinformatics}, 18:1374--1381, 2002.

\bibitem{KeichPevzner02b}
U.~Keich and P.~Pevzner.
\newblock Subtle motifs: defining the limits of motif finding algorithms.
\newblock {\em Bioinformatics}, 18:1382--1390, 2002.

\bibitem{LanctotLiMaWangZhang99}
J.~K. Lanctot, M.~Li, B.~Ma, L.~Wang, and L.~Zhang.
\newblock Distinguishing string selection problems.
\newblock {\em Information and Computation}, 185:41--55, 2003.

\bibitem{LawrenceReilly90}
C.~Lawrence and A.~Reilly.
\newblock An expectation maximization ({{\rm EM}}) algorithm for the
  identification and characterization of common sites in unaligned biopolymer
  sequences.
\newblock {\em Proteins}, 7:41--51, 1990.

\bibitem{LiMaWang99b}
M.~Li, B.~Ma, and L.~Wang.
\newblock Finding similar regions in many strings.
\newblock In {\em Proceedings of the 31st Annual ACM Symposium on Theory of
  Computing}, pages 473--482, 1999.

\bibitem{LiMaWang99}
M.~Li, B.~Ma, and L.~Wang.
\newblock On the closest string and substring problems.
\newblock {\em Journal of the ACM}, 49(2):157--171, 2002.

\bibitem{LiuMaWang08}
X.~Liu, B.~Ma, and L.~Wang.
\newblock Voting algorithms for the motif problem.
\newblock In {\em Proceedings of Computational Systems Bioinformatics
  Conference (CSB'08)}, pages 37--47, 2008.

\bibitem{LucasBusch91}
K.~Lucas, M.~Busch, S.~Mossinger, and J.~Thompson.
\newblock An improved microcomputer program for finding gene- or gene
  family-specific oligonucleotides suitable as primers for polymerase chain
  reactions or as probes.
\newblock {\em Computer Applications in the Biosciences}, 7:525--529, 1991.

\bibitem{MotwaniRaghavan00}
R.~Motwani and P.~Raghavan.
\newblock {\em Randomized Algorithms}.
\newblock Cambridge University Press, 2000.

\bibitem{PevznerSze00}
P.~Pevzner and S.~Sze.
\newblock Combinatorial approaches to finding subtle signals in {{DNA}}
  sequences.
\newblock In {\em {\it Proceedings of the 8th International Conference on
  Intelligent Systems for Molecular Biology}}, pages 269--278, 2000.

\bibitem{ProutskiHolme96}
V.~Proutski and E.~C. Holme.
\newblock Primer master: a new program for the design and analysis of {{PCR}}
  primers.
\newblock {\em Computer Applications in the Biosciences}, 12:253--255, 1996.

\bibitem{Stormo90}
G.~Stormo.
\newblock Consensus patterns in {{\rm DNA}}, in {{\rm R. F. Doolitle}} (ed.),
  {{M}}olecular evolution: computer analysis of protein and nucleic acid
  sequences.
\newblock {\em Methods in Enzymolog}, 183:211--221, 1990.

\bibitem{StormoHartzell91}
G.~Stormo and G.~Hartzell{{\rm\ }}III.
\newblock Identifying protein-binding sites from unaligned {{\rm DNA}}
  fragments.
\newblock {\em {Proceedings of the National Academy of Sciences of the United
  States of America}}, 88:5699--5703, 1991.

\bibitem{WangDong05}
L.~Wang and L.~Dong.
\newblock Randomized algorithms for motif detection.
\newblock {\em {\em Journal of Bioinformatics and Computational Biology}},
  3(5):1039--1052, 2005.

\end{thebibliography}



























\end{document}
