\documentclass[11pt]{article}

\usepackage{graphicx}
\usepackage{amsmath, amssymb, amsthm, amsfonts}
\usepackage{fullpage}
\usepackage{mathptmx}
\usepackage{latexsym}
\usepackage[scaled]{helvet}
\usepackage{color}
\usepackage{subfigure}



\newcommand{\eat}[1]{}
\newcommand{\debmalya}[1]{{\fontcolor{red}\\Debmalya:#1\\}}
\newcommand{\opt}{{\text{\sc opt}}}
\newcommand{\pr}{{\mathbb{P}}}
\newcommand{\ex}{{\mathbb{E}}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\title{Online Load Balancing on Unrelated Machines with Startup Costs\thanks{Part
of this work was done while the first author was visiting and the
second author was an intern at Microsoft Research, Redmond, WA 98052.}}
\author{Yossi Azar\thanks{
Blatavnik School of Computer Science,
Tel-Aviv University, Tel-Aviv 69978, Israel. Email: {\tt azar@tau.ac.il}.}
\and Debmalya Panigrahi\thanks{
Computer Science and Artificial Intelligence Laboratory,
Massachusetts Institute of Technology,
Cambridge, MA 02139, USA. Email: {\tt debmalya@mit.edu}.}}
\date{}


\begin{document}


\maketitle

\thispagestyle{empty}

\begin{abstract}
Motivated by applications in energy-efficient scheduling in data 
centers, Khuller, Li, and Saha introduced the {\em machine activation} problem 
as a generalization of the classical optimization problems of minimum set cover 
and minimum makespan scheduling on parallel machines. 
In this problem, a set of  jobs
have to be distributed among a set of  (unrelated) machines, given the
processing time of each job on each machine. Additionally, each machine incurs
a startup cost if at least one job is assigned to it. 
The goal is to produce a schedule of minimum total
startup cost subject to a constraint  on its makespan.
While Khuller~{\em et al} considered the offline version of this problem, 
a typical scenario in scheduling is one where jobs arrive online and 
have to be assigned to a machine immediately on arrival. 
We give an -competitive randomized online algorithm
for this problem, i.e. the schedule produced by our algorithm has 
a makespan of  with high probability, and a total expected 
startup cost of 
 times that of an optimal offline schedule with makespan 
. Our algorithm is almost optimal since it follows from previous results
that the two approximation factors cannot be improved to  
(under standard complexity assumptions) and  respectively. 

Our algorithms use the online primal dual framework introduced by 
Alon~{\em et al} for the online set cover problem, and subsequently developed 
further by Buchbinder, Naor and co-authors in various papers. To the best of 
our knowledge, all previous applications of this framework have been to 
linear programs (LPs) with either packing or covering constraints. One 
novelty of our application is that we use this framework for a mixed LP that 
has both covering and packing constraints. We combine the packing constraint with
the objective function to design a potential function on the machines that is exponential
in the current load of the machine and linear in the cost of the machine.
Then, we create a dynamic order of machines based on this potential function and
assign larger fractions of the job to machines that appear earlier in this 
order. This allocation is somewhat unusual in that
the increase in load on a machine is inverse in the 
value of this potential function itself, i.e. inverse exponential in the
current load on the machine. Finally, we show that we can round
this fractional solution online using a randomized algorithm. 
We hope that the algorithmic 
techniques developed in this paper to simultaneously handle packing and
covering constraints will be useful for solving other online optimization 
problems as well. 

\end{abstract}

\clearpage

\setcounter{page}{1}

\section{Introduction}

In recent times, the emergence and widespread use of large-scale data centers with 
massive power requirements has elevated the problem of energy-efficient scheduling 
to one of paramount importance (see e.g.~\cite{BirmanCR09}). A natural strategy 
for achieving energy savings is that of {\em partial shutdown}, i.e. only 
a subset of machines/processors are active at any point of time. This immediately leads to 
the following scheduling question: {\em which set of machines should be activated 
to serve a given set of jobs?} Note that such a schedule must address twin
objectives:
\begin{itemize}
	\item The total cost (e.g. in terms of energy consumption) of all 
	machines used in the schedule must be small (thereby achieving energy
	efficiency).
	\item The sum of processing times of all jobs assigned to any machine
	must be small (thereby satisfying throughput requirements).
\end{itemize}
Motivated by this application, Khuller, Li, and Saha~\cite{KhullerLS10} 
introduced the {\em machine activation} problem that involves scheduling jobs 
to machines so as to minimize the cost of the machines used in the schedule, while
ensuring that the ``load'' on any machine is small.
Observe that treating each of these objectives individually leads to classical
problems in combinatorial optimization, namely {\em minimum set cover} and
{\em minimum makespan scheduling} on parallel machines, 
that have been extensively studied over
the last thirty years. The novelty of the algorithm proposed in 
\cite{KhullerLS10} for the machine activation problem lies in being able to
handle both objectives simultaneously. 

More formally, let  be a set of  machines and  be a set of  jobs, 
where the {\em processing time} of job  on machine  is .
Further, machine  has {\em startup cost} . A {\em schedule}
is defined as an assignment  of jobs to machines; we denote
the set of jobs assigned to machine  in schedule  by . 
The set of {\em active machines}  in schedule  are the machines 
to which at least one job has been assigned, i.e. 
, and the cost of schedule  
is defined as . The {\em load}  on machine 
is the sum of processing times of all jobs assigned to machine , 
i.e. , and the {\em makespan}
 is the maximum load on a machine, i.e.
. (Often, we will drop the 
superscript  in the above notation if the schedule is clear from the context.) 
The objective of the machine activation problem is to obtain a schedule of minimum 
cost, subject to the constraint that its makespan is at most some given value .

In real-life scheduling tasks, the set of jobs is often not known in advance.
This has motivated extensive algorithmic research in online scheduling problems, 
where the  set of machines are available offline but the jobs appear online 
and have to be scheduled to a machine when they arrive. A natural and 
important question left open in \cite{KhullerLS10} was to obtain an algorithm for 
the machine activation problem in the online model. Here, the set of machines,
their individual startup costs, and the budget on the total startup cost of the 
machines activated by the schedule are known offline, but the jobs arrive online.
The processing time of a job on each machine is also revealed on arrival of the 
job. The goal is to assign the arriving job to a machine such that the cost
of the resulting schedule is minimized subject to the constraint that its makespan
is at most . We call this the {\em online machine activation problem}.

\noindent
\paragraph{Our Contributions.} 
Our main contribution is a randomized online algorithm 
for the machine activation problem with a bicriteria competitive ratio of 
: suppose an offline 
optimal schedule for an instance of our problem has cost  and makespan at most ; 
then our online algorithm produces a schedule of expected
cost  and makespan 
with high probability. 
\begin{theorem}
\label{thm:main}
There is a randomized online algorithm for the machine activation problem that
has a bicriteria competitive ratio of .
\end{theorem}

In the minimum set cover problem, we are given a collection of subsets defined on 
a universe of elements. The goal is to select a minimum cost sub-collection
such that every element of the universe is in at least
one selected subset. If the elements appear online
and the current selection of subsets must cover every element that has
appeared thus far, a lower bound of  is 
known~\cite{Korman05}
for  sets and  elements, under standard complexity assumptions. 
Since the set cover problem is a special case of the machine activation problem
where the limit  on the makespan of the schedule is , 
the competitive ratio in the cost of the schedule for any online algorithm 
for the machine activation problem must be .

On the other hand, the (minimum makespan) scheduling problem 
for unrelated parallel machines is 
defined as that of distributing  jobs among  machines so as to minimize the 
makespan of the schedule (machines do not have cost). It can be shown using standard 
techniques that an online algorithm that produces a schedule of makespan at most 
 for the online machine activation 
problem can be used to obtain an -competitive algorithm for the online
scheduling problem on unrelated parallel machines. 
It is well-known~\cite{AzarNR95} that the competitive ratio of any algorithm 
for the latter problem is ; therefore, this
lower bound also holds for the online machine activation problem. 
\begin{theorem}
\label{thm:lowerbound}
No algorithm for the online machine activation problem can have a competitive
ratio of  in the makespan. Further, under standard complexity 
assumptions, no algorithm for the online machine activation problem can have 
an approximation factor of  in the cost of the schedule.
\end{theorem}
\noindent
\paragraph{Our Techniques.}
Our algorithm draws inspiration from the techniques used to solve the online 
versions of the set cover problem and the scheduling problem for unrelated 
parallel machines. So, let us first summarize the key ideas involved in these
two algorithms. For the latter problem, Aspnes {\em et al}~\cite{AspnesAFPW97} 
gave an elegant solution based on the following exponential potential function: 
if the current load on machine  is
, then its potential is   for some constant . 
The algorithm assigns the arriving job to a machine that suffers the minimum
increase of potential, i.e. to machine 
. Observe that if all
processing times are scaled down sufficiently and  is small enough, then
, i.e. the 
increase in potential function is linear in the processing time but exponential
in the current load on the machine. Therefore, the algorithm favors 
lightly loaded machines in preference to those offering low processing times.
It was shown in \cite{AspnesAFPW97} that this strong ``bias'' for lightly loaded 
machines ensures that the sum of the potentials of all machines is at most 
 times that in an optimal offline schedule, thereby leading to a competitive 
ratio of  on the makespan of the schedule. 

For the online set cover problem, Alon {\em et al}~\cite{AlonAABN09} introduced 
a two-phase online primal dual framework that works as follows. In the first 
phase, the goal is to obtain a feasible fractional solution to the online 
instance of the problem. In each step of this phase, in response to a new 
constraint (i.e. a new element in the online set cover problem) 
that arrives online, the fractional solution is updated to preserve 
feasibility while ensuring that the cost incurred can be accounted for by a 
suitably updated dual solution.\footnote{The dual was not used explicitly in Alon 
{\em et al}'s original analysis. In fact, we will also not use the dual explicitly
even though our algorithm can also be analyzed via the dual.}
In the second phase, the fractional solution is rounded {\em online} to obtain 
an integer solution. It is important to note that while the two phases are presented
sequentially for clarity, the algorithm needs to operate both phases (the fractional
updates followed by the rounding) in response
to response to the arrival of a new constraint. 
These two phases aim to notionally distinguish between 
the information-theoretic aspect of the online problem and the computational aspect
of rounding a fractional solution. In fact, Alon~{\em et al} showed 
for  sets and  elements, this two-phase framework can be used to 
design an algorithm that has a competitive ratio of , where the 
 factor arises in the first phase due to information-theoretic
limitations of the online algorithm, and the  factor arises in the
second phase due to computational limitations encapsulated by the integrality
gap of the linear program (LP) for set cover.

\begin{figure}[!htb]
	\centering
	\small
	Minimize  subject to
	
	\caption{\small The integer scheduling linear program (or ISLP). In the fractional scheduling linear
		program (or FSLP), Eqns.~\ref{eqn:range1} and \ref{eqn:range2} are relaxed to 
		for all machines , and  for all machines  and jobs , 
		respectively.}
	\label{fig:lp}
\end{figure}

This two-phase primal dual framework has since been extensively  
used for various online problems (see \cite{BuchbinderN09b} for a survey);
our algorithm also uses this framework. However, to the best of our knowledge,
whereas all previous applications of the framework have been to LPs that have 
exclusively covering or packing constraints, we apply the framework to a mixed LP. 
Consider the integer LP formulation of our problem 
given in Fig.~\ref{fig:lp} (we call this the {\em integer scheduling LP} or ISLP). 
The variable  is 1 iff machine  is active, 
and  is 1 iff job  is assigned to machine . In the fractional
relaxation (which we call the {\em fractional scheduling LP} or FSLP), 
these variables are constrained to be in the range  
instead of Eqns.~\ref{eqn:range1} and \ref{eqn:range2}. 
Note that we have both covering 
(Eqn.~\ref{eqn:covering}) and packing (Eqn.~\ref{eqn:packing}) constraints
in the ISLP/FSLP.

We interpret the online set cover algorithm as one that 
maintains a bound on a potential function that is linear in the cost of the 
active machines, whereas the online scheduling algorithm translates its 
objective of minimizing makespan into maintaining a bound on the value of 
a potential function that is exponential in the load on each machine. We 
design a potential function that combines both objectives: it is linear in
the startup cost and exponential in the load on a machine. Our fractional
algorithm preferentially assigns (fractions of) jobs to machines in a way that 
leads to a small increase in this potential. It should be noted that even 
if we use this potential function, we cannot afford to simply assign
the entire job  to the machine that would suffer the minimum increase in 
potential---such a 
greedy strategy can be easily shown to fail even for the special case of the
online set cover problem. Instead, our algorithm creates a dynamic list of 
machines in increasing order of its change in potential if the current job 
were assigned to it, and then assigns larger fractions of the job to 
machines that appear earlier in the order. 
This allocation is also somewhat unusual in that
the increase in load on a machine is inverse in the 
value of this potential function itself, i.e. inverse exponential in the
current load on the machine. For some of the machines in the
order, this might also involve increasing the fraction to which the machine
is active, i.e. increasing the value of , if the assignment violates 
Eqn.~\ref{eqn:packing} or \ref{eqn:fraction}. The analysis of the fractional
algorithm involves proving a bound on the value of the cumulative
potential function over all the machines. Depending on the behavior of a
fixed optimal offline solution (which is unknown to the algorithm and is 
used only for analysis), we classify jobs into three different categories, and
prove a bound on the total increase in potential due to jobs in each individual
category using three different techniques:
\begin{itemize}
\item The increase of potential for jobs in category 1 is charged globally to 
the offline optimal solution using a primal dual argument (without introducing
the dual solution explicitly) similar in spirit to that used by Alon {\em et al} 
in~\cite{AlonAABN09} for the online set cover problem.
\item We give a bound on the increase in potential for each individual job in 
category 2 by showing that the ratio of increase in potential to the fraction
of job assigned is bounded.
\item We give a global bound on the increase of potential for jobs in category
3 by using a recursive argument which is similar in spirit 
to the one used in the online scheduling
algorithm for unrelated machines by Aspnes {\em et al}~\cite{AspnesAFPW97}.
\end{itemize}
The novelty of our analysis lies in being able to seamlessly combine, and
non-trivially extend, the disparate 
techniques from \cite{AlonAABN09} and \cite{AspnesAFPW97}.
Ultimately, we show that the potential of the fractional schedule 
produced by our algorithm is , where the cost and makespan
of the offline optimal solution are respectively  and 1 by 
a suitable initial scaling. We hope that the algorithmic 
techniques developed in this paper to simultaneously handle packing and
covering constraints will be useful for solving other online optimization 
problems that can be expressed as mixed LPs as well. 

In the second phase of the algorithm, we use an online randomized rounding scheme 
to obtain an integer solution. To ensure that the expected cost of 
the integer schedule is bounded by that of the fractional schedule, each machine  
is activated with probability proportional to . This is implemented online using 
standard techniques. The more challenging aspect of the rounding is the actual 
scheduling of jobs to active machines. The natural approach would be to assign 
job  to machine  with probability . 
Translated to conditional probabilities, this implies
that job  should be assigned to machine  with probability 
if machine  is active, where  is the value of  at the end of the
update to the fractional solution for job . This immediately implies that the expected
load on a machine in the integer schedule is at most that in the fractional schedule. 
However, our goal is to obtain a bound
on the {\bf makespan} of the integer solution; in fact, since the events of 
jobs being assigned to a fixed machine are positively
correlated, a bound on the expected load does not immediately
yield a concentration bound on the load. Instead, we show that even if job  
were to be assigned to machine  {\em unconditionally} with probability ,
the expected load on machine  given by  would be small. 
This overcomes the problem of positive correlation mentioned above since the events are 
no longer conditioned on machine  being active. We now derive
concentration bounds on the load on a machine, which translates to a bound on the 
makespan of the integer schedule thereby proving Theorem~\ref{thm:main}.

\noindent
\paragraph{Previous Work.} 
Many variants of the machine scheduling (or {\em load balancing}) problem have been 
extensively studied in the literature. Perhaps the most celebrated result in 
scheduling theory is a 2-approximation for the offline minimum makespan scheduling problem
for unrelated machines due to Lenstra, Shmoys and Tardos~\cite{LenstraST90},
which was later simplified by Shmoys and Tardos~\cite{ShmoysT93}.
Rather surprisingly, this algorithm continues to offer the best competitive ratio for
this problem (and even for several natural special cases such as the restricted
assignment problem) even after more than two decades
of research. 
In the online setting, Graham~\cite{Graham66, Graham69} showed that the natural greedy
heuristic achieves
a competitive ratio of  for  identical machines. The competitive ratio of 
this problem has been subsequently improved in a series of results 
(see e.g.~\cite{BartalFKV95} and subsequent improvements). 
For the more general restricted assignment problem
where the processing time of each job  on any machine is either some value  
or , an online algorithm having competitive ratio  was designed
by Azar, Naor and Rom~\cite{AzarNR95}. This algorithm was later generalized to 
the unrelated machines scenario by Aspnes {\em et al}~\cite{AspnesAFPW97} 
with the same competitive ratio.
Various other models and objectives have been considered for the load balancing 
problem; for a comprehensive survey, see \cite{Azar96} and \cite{Sgall96}. 
In particular, the machine activation problem was introduced by 
Khuller~{\em et al} in \cite{KhullerLS10}, where they gave an 
-approximation algorithm for
any . Recently, this result was extended by Khuller and
Li~\cite{LiK11} to a more general set of cost functions.





























\section{The Fractional Algorithm}
\label{sec:fractional}

\begin{figure}[!htb]
	\small
	\centering
	Minimize  subject to
	
	\caption{\small The relaxed fractional scheduling linear program (or RFSLP). 
		Eqn~\ref{eqn:packingnew} is enforced only for partially active machines .
		(Note that for inactive machines, Eqns.~\ref{eqn:packingnew} and
		\ref{eqn:fractionnew} are identical.)}
	\label{fig:lp-relaxed}
\end{figure}

In this section, we will describe the online updates to the fractional
solution to maintain feasibility for FSLP on receiving a new job . 
This involves updating the values of 
 (denoting the fraction of job  assigned to machine )
so as to satisfy Eqn.~\ref{eqn:covering}, and corresponding updates 
to the values of  if Eqns.~\ref{eqn:packing} or \ref{eqn:fraction}
is violated. 
In fact, we relax the constraints in FSLP in two ways.
Let machine  be said to be {\em inactive}, {\em partially active} or
{\em fully active} depending on whether ,  or
 respectively. First, for technical reasons, 
we relax Eqns.~\ref{eqn:packing} and \ref{eqn:fraction} 
to Eqns.~\ref{eqn:packingnew} and \ref{eqn:fractionnew} respectively
(see Fig.~\ref{fig:lp-relaxed}). Further, we 
enforce Eqn.~\ref{eqn:packing} only if , i.e. if machine 
 is not fully active. The load on a fully active machine will
be bounded separately in the analysis.
We call this the {\em relaxed fractional scheduling LP} or RFSLP.

Before describing these updates, let us set up some 
conventions that we will use throughout the paper.
We divide all processing times by  at the outset;
this allows us to assume that the makespan of the optimal solution is 1.
We also assume that we know the value  of the optimal 
offline (integer) solution, i.e. the minimum startup cost of an offline 
assignment of jobs to machines that has makespan at most 1. 
This is also without loss of generality because we can guess the 
value of the optimal solution, doubling our guess whenever the 
current algorithmic solution exceeds the cost bounds that we are 
going to prove (thereby implying that our current guess is too small). 
In the following discussion, it is sufficient to
know the value of  up to a multiplicative 
factor of 2, but for simplicity
of presentation, we will assume that we know it exactly.

Our algorithm uses the value of , which is the total number of
jobs that arrive online. If this value is not known offline, each job 
estimates  by assuming that it is the last job. We can show that 
using such estimates for  incurs a small {\em additive} factor of 
 in the makespan, and an {\em additive} factor of 
 in the cost of the schedule. 
However, for simplicity, the rest of the paper assumes that the value 
of  is known offline.

We define the {\em virtual cost} of job  on machine  as 

where  is a constant that we will fix later. 
(Recall that  represents the load on machine , 
i.e. .)
Let  denote
an ordering of machines in non-decreasing order of virtual cost 
 for job . 
Let  denote the maximal prefix of  such that 
. (Note that  may be empty.)  
If , then  
denotes the first machine in  that is not in ; 
 is undefined if .

If  is increased to  for a partially
active machine , then
we say that the {\em effective capacity} created by this increase 
for job  is .
Note that the effective capacity created by an increase in  
is a feasible increase in the value of  independent of the 
current load on machine .

\subsection{The Algorithm}
The algorithm has two phases---an offline pre-processing phase, and
an online phase that (fractionally) schedules the arriving jobs.
 
\paragraph{Pre-processing.} We multiply the startup cost of every machine
by , and discard machines with startup cost greater than 
(after the scaling) at the outset. Further, for every machine 
whose startup cost is at most 1, we increase its
cost to 1, and initialize  to 1. For all other
machines with , we initialize  to .
At the end of the pre-processing phase, we have the following properties:
\begin{itemize}
	\item The cost of an optimal solution is between  and .
	\item The cost of every machine is between 1 and .
	\item Every machine whose cost is 1 is fully active; all other
	machines have .
\end{itemize}



\paragraph{Online Algorithm.}
Suppose job  arrives online. 
We increase s using the following rules repeatedly until 
Eqn.~\ref{eqn:coveringnew} is satisfied.
\begin{itemize}
\item {\bf Type A:  is undefined (i.e. ) or 
 (i.e. machine  is not fully active).} 
We increase  to  for each machine 
 (and also for  if it is defined), and correspondingly
increase  by the effective capacity created in each machine.
\item {\bf Type B:  (i.e. machine  is fully active).}
We increase  to  for each machine 
, and correspondingly increase  by the effective 
capacity created in each machine. Further,
we increase  by . 
\end{itemize}

\subsection{Analysis}
Our goal is to show the following bounds
on the makespan and cost of the fractional schedule.
\begin{lemma}\label{lma:fractional-main}
The fractional schedule produced by the online algorithm satisfies 
 
for each machine , and  
.
\end{lemma}
\noindent
We introduce a potential function  for machine  defined as 

The cumulative potential function .
Our goal will be to show that . 
This will immediately imply Lemma~\ref{lma:fractional-main}.

We prove the bound on  in three steps. First, we bound the increase of 
 in the pre-processing phase; next, we bound the increase of  in
each algorithmic step (of either type A or type B); and finally, we bound the 
total number of algorithmic steps. 

\noindent
{\bf Pre-processing.}
The next lemma bounds the increase of  in the pre-processing phase.
\begin{lemma}
\label{lma:initial}
At the end of the pre-processing phase, .
\end{lemma}
\begin{proof}
The startup cost of each machine that is fully active after pre-processing is 1;
on the other, every partially active machine  has  and 
after pre-processing.
\end{proof}

\noindent
{\bf Single Algorithmic Step.}
Now, we bound the increase in  due to a single algorithmic step of either type.
\begin{lemma}
\label{lma:singleA}
The increase in potential in a single algorithmic step of type A 
is at most .
\end{lemma}
\begin{proof}
The total increase in potential in an algorithmic step of type A (due to increase
in the value of  for machines ) is 
at most 
.
\end{proof}
\noindent
\begin{lemma}
\label{lma:singleB}
For any constant , the increase in potential in a single algorithmic 
step of type B is at most .
\end{lemma}
\begin{proof}
The total increase in potential for machines  due to an 
algorithmic step of type B is at most
.
The other source of increase in potential is the scheduling of 
a fraction of job  to machine , due of which
the load on machine 
 increases by . The resulting
increase of potential  is 

The penultimate inequality follows from the property that
, 
for any .
\end{proof}

\noindent
{\bf Number of Algorithmic Steps.}
We classify the algorithmic steps according to a fixed 
optimal offline (integer) schedule that we call {\sc opt}. Suppose {\sc opt}
assigns job  to machine , and let  denote the machines
that are active in the optimal offline schedule. The three categories are:
\begin{enumerate}
\item .
\item  and  is partially active.
\item  is fully active.
\end{enumerate}
The next lemma bounds the total increase in potential due to algorithmic 
steps in the first category above.
\begin{lemma}
\label{lma:category1}
The total increase in potential due to all algorithmic steps in the first 
category is .
\end{lemma}
\begin{proof}
In any algorithmic step of the first category, the value of 
either increases to  or to 1. 
Since  is initialized
to at least  for each machine  in the pre-processing phase, 
there are at most 
 
algorithmic steps of the first category.
The lemma now follows from Lemmas~\ref{lma:singleA} and \ref{lma:singleB}.
\end{proof}
\noindent
The next lemma bounds the total increase in potential due to algorithmic 
steps in the second category.
\begin{lemma}
\label{lma:category2}
The total increase in potential due to all algorithmic steps in the second 
category is .
\end{lemma}
\begin{proof}
Consider the first  algorithmic steps in the second category for any 
particular job . We have two cases: 
\begin{itemize}
\item {\bf Case~1}: these
algorithmic steps contain at least  steps of 
type B, or
\item {\bf Case~2}: these algorithmic steps contain at least
 steps of type A.
\end{itemize} 
In case~1, each algorithmic step of type B creates an effective capacity
of  in machine . Since in each such algorithmic
step, ,
the total effective capacity created by these algorithmic steps is 
at least 1.

In case~2, let  denote the set  
for the last of these algorithmic steps. (Note that since 
,  is defined.) Further, let  and
 respectively denote 
the value of  for machine  before the first
algorithmic step for job , and after the last
algorithmic step. For each machine ,  has been increased in 
each of at least  algorithmic steps of type A. Thus, for each 
machine ,

since  for all machines . The 
total effective capacity created in these steps is 

The first inequality follows from Eqn.~\ref{eqn:diff} while the 
second inequality follows from the observation that for any ,
we have
.
Hence, the effective capacity created by these algorithmic steps is at least
. The lemma now follows from
Lemmas~\ref{lma:singleA} and \ref{lma:singleB} coupled with the fact that
.
\end{proof}
\noindent
Finally, we bound the total increase of potential due to algorithmic 
steps in the third category.
\begin{lemma}
\label{lma:category3}
For any ,
the total increase in potential due to all algorithmic steps in the third 
category is at most , 
where  is the final load on machine  in the schedule produced
by the algorithm and  is the set of machines that are fully 
activated by the algorithm.
\end{lemma}
\begin{proof}
First,
we consider an algorithmic step of type A. In such a step,  must 
be defined since ; thus,
. Further, for each machine
, we have 
.
Thus, the fraction of job  assigned in this algorithmic step is at least

since .
We first consider the situation where the whole of job  was assigned 
in this algorithmic step. In this case, the increase in potential due
to job  is 
; cumulatively for
all jobs, such increases in potential add up to at most 2.
Otherwise, the sum of increase in  over all machines in 
this algorithmic step is at least . 
Now, consider an algorithmic step of type B.
Then the increase in  is  
since . In either case, 
the total number of algorithmic steps in the third category
for job  is at most . 

Note that .
Therefore, summing over all jobs, the total increase in potential 
due to algorithmic steps in the third category is bounded by 
(using Lemmas~\ref{lma:singleA} and \ref{lma:singleB})

where the penultimate inequality follows from the fact that the
makespan of the optimal offline schedule is at most 1.
\end{proof}
\noindent
Finally, we bound the total potential ; this immediately yields
Lemma~\ref{lma:fractional-main}.
\begin{lemma}
The online fractional algorithm produces a schedule that satisfies 
.
\end{lemma}
\begin{proof}
Lemmas~\ref{lma:initial}, \ref{lma:category1}, 
\ref{lma:category2} and \ref{lma:category3} imply
,
which proves the lemma.
\end{proof}



























\section{The Online Randomized Rounding Procedure} 
\label{sec:rounding}

In this section, we give an online randomized rounding scheme for the fractional solution produced by
the algorithm in the previous section. 

\subsection{The Algorithm}
For each machine , we select (offline) a number  uniformly at random and 
independently from . In response to a new job  arriving online, the
algorithm updates the schedule in three steps:
\begin{itemize}
\item {\bf Fractional step.} The fractional schedule is updated according to the algorithm 
described in the previous section.
\item {\bf Activation step.} Each inactive machine  that satisfies 
is activated.
\item {\bf Assignment step.} Let  be the set of active machines in the integer solution. Let 
 if  and  otherwise. 
Let  be the normalized probability proportional to  in a distribution defined on the 
set of machines . We assign job  to machine  with probability .
\end{itemize}


\subsection{Analysis}
The next lemma is an immediate consequence of the fact that machine 
 is active in the integer solution with probability
.
\begin{lemma}
\label{lma:cost-integer}
The total startup cost of all machines activated in the integer
schedule is  in expectation.
\end{lemma}
\begin{proof}
The expected startup cost of machine  in the integer schedule 
is at most ;
the lemma now follows from Lemma~\ref{lma:fractional-main} and
linearity of expectation.
\end{proof}
\noindent
To bound the makespan of the integer solution, we first bound the probabilities .
(This lemma also shows that with high probability, at least one machine is active for even
one job, thereby proving correctness of the algorithm.)
\begin{lemma}
\label{lma:open}
With probability at least ,  for all machines  and jobs .
\end{lemma}
\begin{proof}
We show that  with probability at least 
for any job ; the lemma then follows using the union bound over all jobs. 
We classify machines into  and  depending on whether or not 
. Every machine  is also in . Therefore, 
the contribution of machines in 
to  is exactly . On 
the other hand, the contribution of each machine  to this sum
is  with probability , and 0 otherwise. Define
a random variable  with probability , and 0 otherwise. 
Since ,
 
by Chernoff bounds (cf. e.g.~\cite{MotwaniR97}). 
\end{proof}
\noindent
\begin{lemma}
\label{lma:load-whp}
The makespan of the integer schedule is  with probability .
\end{lemma}
\begin{proof}
First, we prove that the load on any machine in the integer schedule is 
 with probability at least 
conditioned on the following:
\begin{itemize} 
\item Lemma~\ref{lma:open} holds, i.e.  for all machines  and
jobs , and
\item Machine  is active from the outset in the integer algorithm.
\end{itemize}
Given that machine  is active from the outset and , 
the load on machine  due to job  is  with probability at most . 
Now,

Let job  immediately precede job  in the online order; if  is the first job,
. Then,

The first inequality follows from the fractional algorithm which assigns a 
fraction  of job  to machine .
Since  for all jobs , it follows using 
Chernoff bounds that the load on machine  is 
 with probability at least .

Using the union bound over all machines and Lemma~\ref{lma:open},
we can now claim that the load on machine  is 
 (unconditionally) for all machines ,
with probability at least . 
The lemma now follows using Lemma~\ref{lma:fractional-main}.
\end{proof}
\noindent
Finally, we note that Lemmas~\ref{lma:cost-integer} and \ref{lma:load-whp} imply 
Theorem~\ref{thm:main}.

\newpage

\bibliographystyle{plain}
\bibliography{ref}

\end{document}
