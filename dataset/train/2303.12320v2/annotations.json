[{'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'OpenBookQA', 'Metric': 'Accuracy', 'Score': '90'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'OpenBookQA', 'Metric': 'Accuracy', 'Score': '82'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'OpenBookQA', 'Metric': 'Accuracy', 'Score': '66.2'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'MedQA-USMLE', 'Metric': 'Accuracy', 'Score': '39.51'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'CommonsenseQA', 'Metric': 'Accuracy', 'Score': '73.5'}}]
