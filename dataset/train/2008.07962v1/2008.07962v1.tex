\documentclass[sigconf,camera-ready]{acmart}

\AtBeginDocument{\providecommand\BibTeX{{\normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}



\copyrightyear{2020}
\acmYear{2020}
\setcopyright{acmlicensed}\acmConference[CIKM '20]{Proceedings of the 29th ACM International Conference on Information and Knowledge Management}{October 19--23, 2020}{Virtual Event, Ireland}
\acmBooktitle{Proceedings of the 29th ACM International Conference on Information and Knowledge Management (CIKM '20), October 19--23, 2020, Virtual Event, Ireland}
\acmPrice{15.00}
\acmDOI{10.1145/3340531.3412001}
\acmISBN{978-1-4503-6859-9/20/10}
\settopmatter{printacmref=true}




\usepackage{multirow}
\usepackage{pifont}
\usepackage{bm}

\begin{document}
\fancyhead{}
\title{Relational Reflection Entity Alignment}

\author{Xin Mao, Wenting Wang, Huimin Xu, Yuanbin Wu, Man Lan}
\email{{xmao,hmxu}@stu.ecnu.edu.cn, {wenting.wang}@lazada.com, {ybwu,mlan}@cs.ecnu.edu.cn}
\affiliation{East China Normal University, Alibaba Group}





\begin{abstract}
Entity alignment aims to identify equivalent entity pairs from different Knowledge Graphs (KGs), which is essential in integrating multi-source KGs. 
Recently, with the introduction of GNNs into entity alignment, the architectures of recent models have become more and more complicated.
We even find two counter-intuitive phenomena within these methods:
(1) The standard linear transformation in GNNs is not working well.
(2) Many advanced KG embedding models designed for link prediction task perform poorly in entity alignment.
In this paper, we abstract existing entity alignment methods into a unified framework, \emph{Shape-Builder \& Alignment},
which not only successfully explains the above phenomena but also derives two key criteria for an ideal transformation operation.
Furthermore, we propose a novel GNNs-based method, \emph{Relational Reflection Entity Alignment} (RREA).
RREA leverages \emph{Relational Reflection Transformation} to obtain relation specific embeddings for each entity in a more efficient way.
The experimental results on real-world datasets show that our model significantly outperforms the state-of-the-art methods, exceeding by - on \emph{Hits@1}.
\end{abstract}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10010147.10010178.10010187</concept_id>
<concept_desc>Computing methodologies~Knowledge representation and reasoning</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010147.10010178.10010179</concept_id>
<concept_desc>Computing methodologies~Natural language processing</concept_desc>
<concept_significance>300</concept_significance>
</concept>
<concept>
<concept_id>10010147.10010257.10010258.10010259</concept_id>
<concept_desc>Computing methodologies~Supervised learning</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Knowledge representation and reasoning}
\ccsdesc[300]{Computing methodologies~Natural language processing}
\ccsdesc[300]{Computing methodologies~Supervised learning}



\keywords{Graph Neural Networks; Knowledge Graph; Entity Alignment}



\maketitle

\section{Introduction}
\label{sec:intro}
With more and more KGs emerging, integrating multi-source KGs becomes necessary and beneficial to not only complement information but also improve downstream tasks such as recommendation system and search engine.
One of the key steps to integrating KGs is to identify equivalent entity pairs.
Therefore, the task of entity alignment attracts increasing attention in recent years.
Existing entity alignment methods can be divided into two main categories:
(1) \textbf{Translation-based.}
Inspired by cross-lingual word embedding task, these methods presume that embeddings of different KGs have similar distributions, so the entity pairs who are aligned between KGs would also have relatively similar positions in their own vector spaces.
These methods \cite{DBLP:conf/ijcai/ChenTYZ17,DBLP:conf/semweb/SunHL17,DBLP:conf/ijcai/SunHZQ18,DBLP:conf/icml/GuoSH19} first use translation-based KGs embedding models (e.g., TransE \cite{DBLP:conf/nips/BordesUGWY13}) on every single KG to get its embeddings of entities and relations, and then align entities from two vector spaces into a unified one based on some pre-aligned entity pairs.
(2) \textbf{GNNs-based.}
Different from translation-based methods where the relation is a translation from one entity to another, Graph Neural Networks (GNNs) generate node-level embeddings through aggregating information from the neighboring nodes.
Inspired by Siamese Neural Networks \cite{DBLP:conf/cvpr/ChopraHL05} which are widely used in computer vision, a typical architecture of GNNs-based methods \cite{DBLP:conf/acl/CaoLLLLC19,sun2019knowledge,DBLP:conf/emnlp/WangLLZ18} consists of two multi-layer GNNs with the contrastive loss \cite{DBLP:conf/cvpr/HadsellCL06} or triplet loss \cite{DBLP:conf/cvpr/SchroffKP15}.

With the introduction of GNNs into entity alignment task, recent model architectures have become more and more complicated which are hard to interpret the effectiveness of individual components.
Despite the success in empirical results, we observe two counter-intuitive phenomena in these complicated methods that need to be further clarified and studied:

Q: \textbf{Why the standard linear transformation of GNNs is not working well in entity alignment?}
GNNs are originally designed with a standard linear transformation matrix,
however, many GNNs-based methods \cite{DBLP:conf/emnlp/WangLLZ18,DBLP:conf/acl/CaoLLLLC19,li-etal-2019-semi,yang2019aligning}\footnote{GCN-Align:\url{https://github.com/1049451037/GCN-Align}; MuGNN: \url{https://github.com/thunlp/MuGNN}; HMAN: \url{https://github.com/h324yang/HMAN}; KECG: \url{https://github.com/THU-KEG/KECG}}
constrain it to be unit (i.e., removing this matrix from GNNs) or diagonal with unit initialization.
All previous methods just treat it as parameter reduction but do not explore nor explain about this setting.
When we try to undo this setting in GCN-Align \cite{DBLP:conf/emnlp/WangLLZ18}, the performances significantly drop by  on \emph{Hits@1}.
So we believe this should be related to some more fundamental issues.

Q: \textbf{Why many advanced KG embedding models are not working well in entity alignment?}
In other tasks that also need KG modeling, such as link prediction, many advanced KG embedding models are proposed and proved to be very effective.
Strangely, a lot of these advanced embedding models designed for link prediction do not show success in entity alignment.
\citet{DBLP:conf/semweb/SunHHCGQ19} experiments with many advanced KG embedding models, such as TransR \cite{DBLP:conf/aaai/LinLSLZ15}, ConvE \cite{DBLP:conf/aaai/DettmersMS018} and etc., but performances are even worse than TransE.
The authors conclude with "not all embedding models designed for link prediction are suitable for entity alignment" but not giving any further exploration or explanation.

To analyze these two issues from a global and unified perspective, we propose an abstract entity alignment framework, named as \emph{Shape-Builder \& Alignment}.
In this framework, both translation-based and GNNs-based methods are just special cases under respective special settings.
With this framework, we successfully derive the answers to address the above questions:
(Q) Entity alignment presumes similarity between distributions, so in order to avoid destroying the shape, the norms and the relative distances of entities should remain unchanged after transformation.
Thus, it is mandatory that the transformation matrix is orthogonal.
(Q) Many advanced KG embedding models share one key idea --- transforming  entity embeddings into relation specific ones.
However, their transformation matrix is difficult to comply with the orthogonal property.
This is the fundamental reason why they perform poorly in entity alignment.

Inspired by the above findings, we propose two key criteria of an ideal transformation operation for entity alignment: \textbf{Relational Differentiation} and \textbf{Dimensional Isometry}.
Then, we design a new transformation operation, \emph{Relational Reflection Transformation}, which fulfills these two criteria.
This new operation is able to reflect entity embeddings along different relational hyperplanes to construct relation specific embeddings.
Meanwhile, the reflection matrix is orthogonal which is easy to prove, so reflection transformation could keep the norms and the relative distances unchanged.
By integrating this proposed transformation into GNNs, we further present a novel GNNs-based entity alignment method, \emph{Relational Reflection Entity Alignment} (RREA).
The experimental results on real-world public datasets validate that our model greatly exceeds existing state-of-the-art methods by - on \emph{Hits@1} across all datasets.
We summarize the main contributions of this paper as follows:
\begin{itemize}
  \item To our best knowledge, this is the first work to abstract existing entity alignment methods into a unified framework.
      Through this framework, we successfully derive two key criteria for an ideal transformation operation: relational differentiation and dimensional isometry.
  \item To our best knowledge, this is the first work to design a new transformation operation, \emph{Relational Reflection Transformation}, which fulfills the above two criteria.
        By integrating this operation into GNNs, we further propose a novel GNNs-based method \emph{Relational Reflection Entity Alignment} (RREA).
  \item The extensive experimental results show that our model is ranked consistently as the best across all real-world datasets and outperforms the state-of-the-art methods by - on \emph{Hits@1}.
      In addition, we also carry ablation experiments to demonstrate that each component of our model is effective.

\end{itemize}

\section{Related Work}
\label{sec:RW}
Existing entity alignment methods can be divided into two categories according to their motivations.
In this section, we will give a detailed illustration of these methods.

\subsection{Translation-based Methods}
Translation-based methods are originated from cross-lingual word embedding task.
So they also have a core assumption that the entity embeddings of different KGs have similar distributions, just like the word embeddings of different languages.
As shown in Figure \ref{figure:rw}(a), translation-based methods usually consist of two modules: translation module and alignment module.

\textbf{Translation Module}:
The major function of the translation module is to constrain the randomly initialized embeddings into a fixed distribution through translation-based KGs embedding models.
Due to its solid theoretical foundation and minimum implementation effort, the majority of translation-based methods adopt TransE \cite{DBLP:conf/nips/BordesUGWY13} as the translation module (e.g., MtransE \cite{DBLP:conf/ijcai/ChenTYZ17}, JAPE \cite{DBLP:conf/semweb/SunHL17} and BootEA \cite{DBLP:conf/ijcai/SunHZQ18}).
Inspired by WordVec \cite{DBLP:journals/corr/MikolovLS13}, TransE interprets a relation as the translation from its head to its tail (), so that entity embeddings also have the property of translation invariance.
Theoretically, any KG embedding model could act as a translation module.
However, as mentioned in Section \ref{sec:intro}, many advanced embedding models \cite{DBLP:conf/aaai/DettmersMS018,DBLP:conf/aaai/LinLSLZ15} which perform well in link prediction do not show success in entity alignment.

\textbf{Alignment Module}:
By taking pre-aligned entities as seeds, the alignment module is responsible for aligning the embeddings of different KGs into a unified vector space.
At present, there are two types of alignment modules:

() \emph{mapping}:
Similar to its counterparts in cross-lingual word embedding, this approach embeds different KGs into a unified vector space through a linear transformation matrix.
For example, MtransE \cite{DBLP:conf/ijcai/ChenTYZ17}, KDCoE \cite{DBLP:conf/ijcai/ChenTCSZ18}, and OTEA \cite{DBLP:conf/ijcai/Pei0Z19} minimize the distances between the pre-aligned pairs by optimizing one or two linear transformation matrices (i.e.,  or ).

() \emph{sharing}:
The \emph{sharing} approach embeds different KGs into a unified vector space by letting each pre-aligned pair directly share the same embedding, which is more straightforward compared to the \emph{mapping} approaches.
There are three different implementations about \emph{sharing}:
(a) MTransE \cite{DBLP:conf/ijcai/ChenTYZ17} proposes to minimize the equation  for each pre-aligned pairs\footnote{Hereafter,  means L or L norm unless explicitly specified.}.
(b) JAPE \cite{DBLP:conf/semweb/SunHL17} and RSNs \cite{DBLP:conf/icml/GuoSH19} directly configure  and  to share a common embedding when the model is built.
(c) BootEA \cite{DBLP:conf/ijcai/SunHZQ18} and TransEdge \cite{DBLP:conf/semweb/SunHHCGQ19} swap the pre-aligned entities in their triples to generate extra triples for supervision,
e.g., given  is a pre-aligned pair and a triple  in KGs, the model will produce a new triple .

\begin{figure}
 \resizebox{0.95\linewidth}{!}{
  \centering
  \includegraphics[width=\linewidth]{rw.pdf}
  }
  \caption{Decomposition of existing alignment methods.}\label{figure:rw}
\end{figure}

\subsection{GNNs-based Methods}
Due to the fact that TransE is only trained on individual triples, it may lack the ability to exploit the global view of entities and relations.
Therefore, many recent studies introduce GNNs into entity alignment task, which is originated with the ability to model global information of graphs.

Inspired by Siamese Neural Networks \cite{DBLP:conf/cvpr/ChopraHL05}, a typical GNNs-based method has a simple and intuitive architecture (as shown in Figure \ref{figure:rw}(b)) --- two multi-layer GNNs encoders with a loss function, either contrastive loss \cite{DBLP:conf/cvpr/HadsellCL06} or triplet loss \cite{DBLP:conf/cvpr/SchroffKP15}.
The first GNNs-based method is proposed by GCN-Align \cite{DBLP:conf/emnlp/WangLLZ18} using multi-layer vanilla GCN as the encoder and successfully applies GNNs to entity alignment task.
However, due to the disability of vanilla GCN in modeling heterogeneous graphs, GCN-Align is unable to effectively utilize the rich relation information in KGs.

Many more recent studies attempt to incorporate relation information into GNNs and build relation-aware models to better represent KGs.
HMAN \cite{yang2019aligning} concatenates the entity embeddings obtained by GCN with the average of the neighboring relation and attribute embeddings.
MuGNN \cite{DBLP:conf/acl/CaoLLLLC19}, NAEA \cite{DBLP:conf/ijcai/ZhuZ0TG19} and MRAEA \cite{DBLP:conf/wsdm/MaoWXLW20} assign different weight coefficients to entities according to relation types between them, which empowers the model to distinguish the importance between different entities.
RDGCN \cite{DBLP:conf/ijcai/WuLF0Y019} establishes a dual relation graph for KGs which regards relation as node and entity as edge.
Strangely, many GNNs-methods \cite{DBLP:conf/acl/CaoLLLLC19,DBLP:conf/emnlp/WangLLZ18,li-etal-2019-semi,yang2019aligning,DBLP:conf/wsdm/MaoWXLW20} adopt counter-intuitive constraint in their transformation matrix design,
i.e., forcing the matrix to be unit or diagonal.
All previous methods just treat it as parameter reduction but do not explore nor explain about this setting.

In addition, there are also some other GNNs-based models proposed for modeling KGs in link prediction task.
By assigning different transformation matrices to different relations, RGCN \cite{DBLP:conf/esws/SchlichtkrullKB18} maps entities to corresponding relational vector spaces before convolution.
KBAT \cite{DBLP:conf/acl/NathaniCSK19} converts the triple embeddings into new entity embeddings with a linear transformation matrix and assigns different weight coefficients to the new embeddings via attention mechanism.
However, according to our experimental results in Table \ref{table:KEM}, these advanced models perform even worse than vanilla GCN in entity alignment.



\section{Preliminary}
\subsection{Problem Formulation}
KGs store the real-world information in the form of triples, 
, which describe the relations between two entities.
A KG could be defined as , where  and  represent the sets of entities and relations respectively,  represents the set of triples.
Although different KGs are constructed from different sources, there are still many entity pairs referring to the same real-world object.
Entity alignment aims to find these aligned entity pairs from multi-source KGs, which is the key step of knowledge integration.
Formally,  and  are two multi-source KGs,  represents the set of pre-aligned seed pairs.
The aim of entity alignment is to find new aligned entity pairs based on these pre-aligned seeds.

\begin{table}[t]
\begin{center}
\resizebox{0.95\linewidth}{!}{
\begin{tabular}{cc|cccc}
\hline
\multicolumn{2}{c|}{Datasets} & Entity & Relation  & Triple \\
\hline
\multirow{2}{1.3cm}{} & DBpedia & 100,000 &  302  & 428,952  \\
& YAGO3 & 100,000 & 31  &  502,563 \\
\hline
\multirow{2}{1.3cm}{} & DBpedia & 100,000 &  330 & 463,294 \\
& Wikipedia & 100,000 &  220  &  448,774  \\
\hline
\multirow{2}{1.3cm}{} & Chinese & 66,469 & 2,830& 153,929\\
& English & 98,125 & 2,317 & 237,674 \\
\hline
\multirow{2}{1.3cm}{} & Japanese & 65,744 & 2,043 & 164,373 \\
& English & 95,680 & 2,096  & 233,319 \\
\hline
\multirow{2}{1.3cm}{} & French & 66,858 & 1,379 & 192,191 \\
& English & 105,889 & 2,209 & 278,590  \\
\hline
\end{tabular}
}
\end{center}
\caption{Statistical data of DBP15K and DWY100K.}\label{table:data1}
\end{table}

\subsection{Datasets}
In order to make the comparison with previous methods reliable and fair, we experiment on two widely used open-source datasets:
\begin{itemize}
  \item  \cite{DBLP:conf/semweb/SunHL17} which contains three cross-lingual datasets constructed from the multilingual version of DBpedia, including  (Chinese to English),  (Japanese to English), and  (French to English).
  \item  \cite{DBLP:conf/ijcai/SunHZQ18} are extracted from DBpedia, Wikidata, and YAGO. It has two monolingual datasets:  (DBpedia-Wikidata) and  (DBpedia-YAGO). Each dataset has  reference entity alignments and more than nine hundred thousand triples.
\end{itemize}
Table \ref{table:data1} shows the statistics of these datasets.
Following the setting of previous studies, we randomly split  of aligned pairs for training and keep  of them for testing.
The reported performance is the average of five independent training runs and the train/test datasets are shuffled in every round.

\section{A Unified Entity Alignment Framework}
\label{sec:transformation}
In this section, we model GNNs-based methods and translation-based methods into an abstract but unified entity alignment framework.
Then this framework successfully leads to not only the answers regarding the two questions raised in Section \ref{sec:intro} but also the key criteria of an ideal transformation operation for entity alignment.

\subsection{Shape-Builder \& Alignment}
\label{4.1}
The motivation behind translation-based entity alignment methods is cross-lingual word embedding (word alignment).
So naturally, they all can be abstracted into a unified framework composed of \textbf{Shape-Builder} and \textbf{Alignment} as shown in Figure \ref{fig:1}:
\begin{figure}[t]
  \centering
\includegraphics[width=\linewidth]{fig.pdf}\\
  \caption{The unified framework of entity alignment and representative alignment methods.
}\label{fig:1}
\end{figure}

\textbf{Shape-Builder}:
The main function of shape-builder is to constrain the random initialized distribution to a specific distribution which we define as \emph{shape}.
Obviously, the \emph{translation module} mentioned in Section \ref{sec:RW} is a shape-builder.
In fact, besides TransE, any embedding model can be used as a shape-builder.
The only prerequisite is that the obtained embeddings from two KGs should have \emph{Shape Similarity} in-between. 
In other words, equivalent elements (such as word or entity) have relatively similar positions in their own vector spaces.

\textbf{Alignment}:
When the \emph{Shape Similarity} holds, different shapes can be matched by pre-aligned seeds.
As mentioned in Section \ref{sec:RW}, \emph{mapping} is one of the alignment modules in translation-based methods which trains a matrix  to minimize the distances between the pre-aligned seeds \cite{DBLP:conf/ijcai/ChenTYZ17} as follow:

where  is a pre-aligned pair,  represents the embedding vector of entity .
However, if matrix  has no constraint, then there is no guarantee that the norms and the relative distances of embeddings will be reserved after transformation, which in turn could destroy the original shape similarity.
The seed pairs are well fitted, but the rest of entities could be misaligned (as illustrated in Figure \ref{fig:1}(a)).
On the other hand, if  is constrained to be orthogonal, it becomes a rotation operation and then shape similarity will not be destroyed.
This is why many word alignment methods\cite{DBLP:conf/naacl/XingWLL15,DBLP:conf/iclr/SmithTHH17} use orthogonal constraint.
In entity alignment, OTEA \cite{DBLP:conf/ijcai/Pei0Z19} also proposes to constrain the transformation matrix to be orthogonal (as illustrated in Figure \ref{fig:1}(b)).

In addition, in another alignment module \emph{sharing}, pre-aligned entities are treated as anchors and then the rest of the entities can be gradually aligned during the optimization process of shape-builder (as illustrated in Figure \ref{fig:1}(c)).
Compared to \emph{mapping}, \emph{sharing} abandons the transformation matrix at all which reduces parameters and simplifies the architecture.
So far, all translation-based methods could be abstracted into this framework.

\subsection{GNNs-based Methods Are Also Subject to Our Unified Framework}
\label{4.2}
Many GNNs in entity alignment task contains the following equa-\\tions\cite{DBLP:conf/nips/HamiltonYL17}:


where  represents the set of neighboring nodes around ,  is the transformation matrix of layer .
Equation \ref{eq2} is responsible for aggregating information from the neighboring nodes while Equation \ref{eq3} transforms the node embeddings into better ones.
There are many operations available that can serve the purpose of , such as normalized mean pooling (vanilla GCN\cite{DBLP:conf/iclr/KipfW17}) and attentional weighted summation (GAT \cite{DBLP:conf/iclr/VelickovicCCRLB18}).

After generating the embeddings, GNNs-based methods often use triplet loss to make the equivalent entities close to each other:
e_i',e_j')\in P'}}max\left(\underset{alignment}{\underline{\|\bm{h}_{e_i}-\bm{h}_{e_j}\|}}-\underset{apart}{\underline{\|\bm{h}_{e_i'}-\bm{h}_{e_j'}\|+\lambda}},0\right)

L=\sum_{(e_i,e_j)\in P}\underset{alignment}{\underline{\|\bm{h}_{e_i}-\bm{h}_{e_j}\|}}+\sum_{(e_i',e_j')\in P'}max\left(\underset{apart}{\underline{\|\bm{h}_{e_i'}-\bm{h}_{e_j'}\|+\lambda}},0\right)

  L_{apart} = \sum_{(e_i',e_j')\in P'}max\left(\lambda-{\left\|\bm{h}_{e_i{'}}-\bm{h}_{e_j{'}}\right\|}_1,0\right)

  {\rm \emph{SS}}=\frac{\sum_{(e_i,\widetilde{e_i})\in P}\sum_{(e_j,\widetilde{e_j})\in P}dist(e_i,e_j)\;-\;dist(\widetilde{e_i},\widetilde{e_j})}{\sum_{(e_i',\widetilde{e_i}')\in P'}\sum_{(e_j',\widetilde{e_j}')\in P'}dist(e_i',e_j')\;-\;dist(\widetilde{e_i}',\widetilde{e_j}')}
\label{eq7}

L_o=\left\|\bm{W}^{T}\bm{W}-\bm{I}\right\|^2_2

    \varphi(\bm{h}_e,\bm{h}_{r_1}) \neq \varphi(\bm{h}_e,\bm{h}_{r_2}), \forall e\in E, \forall r_1,r_2\in R

    \|\bm{h}_e\| = \|\varphi(\bm{h}_e,\bm{h}_r)\| ,\; \forall &e\in E, \forall r\in R\\
    \bm{h}_{e_1}^T\bm{h}_{e_2} = \varphi(\bm{h}_{e_1},\bm{h}_r)^T\varphi(\bm{h}_{e_2},\bm{h}_r),&\; \forall e_1,e_2\in E, \forall r\in R

    \bm{M}_r= \bm{I}-2\bm{h}_r\bm{h}_r^T

\begin{aligned}
    \bm{M}_r^T\bm{M}_r &= (\bm{I}-2\bm{h}_r\bm{h}_r^T)^T(\bm{I}-2\bm{h}_r\bm{h}_r^T)\\
             &= \bm{I} - 4\bm{h}_r\bm{h}_r^T + 4\bm{h}_r\bm{h}_r^T\bm{h}_r\bm{h}_r^T = \bm{I}
\end{aligned}

\bm{h}_{e_i}^{l+1}={\rm ReLU}\left(\sum_{e_j\in \mathcal N_{e_i}^e}\sum_{r_k\in R_{ij}}\alpha_{ijk}^l \bm{M}_{r_k}\bm{h}_{e_j}^l\right)

  \beta_{ijk}^l = \bm{v}^T[\bm{h}_{e_i}^l\|\bm{M}_{r_k}\bm{h}_{e_j}^l\|\bm{h}_{r_k}]

\alpha_{ijk}^l=\frac{exp(\beta_{ijk}^l)}{\sum_{e_j\in \mathcal N^e_{e_i}}\sum_{r_k\in R_{ij}}exp(\beta_{ijk}^l))}

 \bm{h}^{out}_{e_i} = [\ \bm{h}^{0}_{e_i}\| ...\| \bm{h}^{l}_{e_i}\ ]

\bm{h}^{Mul}_{e_i}=\left[\bm{h}^{out}_{e_i}\Big|\Big|\frac1{|\mathcal N^r_{e_i}|}\sum_{r_j\in \mathcal N^r_{e_i}}\bm{h}_{r_j}\right]

\small
\begin{split}
L=\sum_{\substack{\left(e_i,e_j\right)\in P}}&{max}\left(dist\left(e_i,e_j\right)-dist\left(e'_i,e_j'\right)+\lambda,0\right)
\end{split}

dist\left(e_i,e_j\right)=\left\| \bm{h}^{Mul}_{e_i}-\bm{h}^{Mul}_{e_j} \right\|_1
\sim4.01\%l\lambda5.8$\% on \emph{Hits@1}.


\bibliographystyle{ACM-Reference-Format}
\bibliography{acmart}
\appendix

\end{document}
