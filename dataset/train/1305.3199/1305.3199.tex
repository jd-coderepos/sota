\documentclass{sig-alternate}

\usepackage{booktabs}
\usepackage{multirow}
\usepackage{subfigure}
\usepackage{wrapfig}
\usepackage{url}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{tikz}
\usepackage{etoolbox}
\usepackage{csquotes}
\usepackage{nag}
\usepackage{flushend}
\usepackage{pifont}

\urlstyle{sf}

\usepackage[maxnames=4,sorting=none]{biblatex}
\bibliography{literature}

\usetikzlibrary{arrows,calc,fit,shapes,arrows,shadows}

\renewcommand*{\bibfont}{\raggedright}

\newcommand{\pt}{\textsf{ScrambleSuit}}

\newcounter{notesctr}
\numberwithin{enumi}{section}

\newenvironment{notes}{
\bigskip\noindent
\refstepcounter{notesctr}
\textsc{Draft notes \thenotesctr}
\color{BrickRed}
\begin{itshape}
\newline
}{\end{itshape}\bigskip}
\numberwithin{notesctr}{section}

\hypersetup{
	colorlinks=true,
	urlcolor=blue,
	linkcolor=blue,
	citecolor=blue
}

\title{
	ScrambleSuit: A Polymorph Network \\
	Protocol to Circumvent Censorship
}

\begin{document}

\numberofauthors{3}

\author{
	\alignauthor
		Philipp Winter \0.2cm]
		\affaddr{Karlstad University}
	\alignauthor
		Juergen Fuss \\label{equ:example}
& b_{0} \gets 0 \\
& b_{1} \overset{R}{\gets}\ ]0, 1 - b_{0}[ \\
& b_{2} \overset{R}{\gets}\ ]0, 1 - b_{0} - b_{1}[ \\
& b_{n} \overset{R}{\gets}\ ]0, 1 - b_{0} - ... - b_{n-1}[

	
We will show in \S \ref{sec:experimental_evaluation} that this naive approach turns out to be
sufficient to obfuscate Tor's flow characteristics. A specialised algorithm---e.g., to optimise
throughput---would be conceivable but is beyond the scope of this paper.


\subsubsection{Packet Length Adaption}
\label{sec:packet_lengths}
It is well known that a network flow's packet length distribution leaks information about the
network protocol \cite{Hjelmvik2010,Crotti2007,Lim2010} and even the content
\cite{Panchenko2011,Cai2012}. For instance, a large fraction of Tor's traffic contains 568-byte
packets which is the result of Tor's internal use of 512-byte cells plus TLS' header (see Figure
\ref{fig:c2spl} and \ref{fig:s2cpl}). These 568-byte packets form a strong distinguisher which can
be used to detect Tor by simply capturing a few dozen network packets as shown by Weinberg et al.
\cite{Weinberg2012}. To defend against such simple applications of traffic analysis, we modify
\pt{}'s packet length distribution.

An efficient way to morph a source distribution to a target distribution was proposed
by Wright, Coull and Monrose \cite{Wright2009}. Their concept, traffic morphing, relies on the
computation of a morphing matrix to minimise the overhead when morphing a source distribution to a
target distribution. Unfortunately, we cannot make use of traffic morphing because our target
distribution is dynamic which would require frequent recomputation of the morphing matrix which is
an expensive operation. This would lead to unnecessary CPU load on the client as well as on the
bridge. Furthermore, our source distribution is not known since \pt{} is designed to be able
to handle arbitrary application protocols.

Instead, we adopt \emph{naive sampling} to disguise the application protocol's packet length
distribution. Every time \pt{} establishes a connection to a server, it randomly generates a fresh
discrete probability distribution as discussed earlier. Every bin in the probability distribution is
uniformly chosen from the set . The newly generated distribution is then randomly
sampled for every chunk of application data, \pt{} is about to send over the wire. After a sample
length is obtained, our algorithm either \emph{a)} pads the current packet to fit the sample's
length or \emph{b)} splits and sends it and then proceeds to morph the remaining data the same way.



\subsubsection{Inter Arrival Time Adaption}
Analogous to the packet length distribution, the distribution of inter arrival times between
consecutive packets has discriminative power and could be used by censors to identify protocols
\cite{Jaber2011}. In contrast to the packet length distribution, inter arrival times are frequently
distorted by network jitter, overloaded middle boxes and the communicating end points. Nevertheless,
we believe that it would be no sound strategy to assume the network to be unreliable enough to
render measurements useless. Therefore, \pt{} is also able to modify its inter arrival times. The
mechanism is the same as for the packet length adaption: a random distribution is generated and then
random samples are drawn from it. The samples are the parameters for short \texttt{sleep()} calls
which are invoked prior to sending data to the remote end.

We are only able to increase inter arrival times but not to decrease them. Increased inter arrival
times have a direct negative effect on throughput and can easily turn into a nuisance for users when
getting too high. As a result, we keep the sleep intervals within the interval of 
milliseconds. We believe that this interval represents a reasonable tradeoff between obfuscation
and throughput as we will show in \S \ref{sec:blocking_resistance}.




\newpage
\subsubsection{Shortcomings}
\label{sec:shortcomings}
It is important to note that for a censor armed with a well-chosen set of features, traffic analysis
can be a powerful attack and strong defences are believed to be expensive \cite{Dyer2012b,Cai2012}.
We made an effort to disguise obvious flow features while keeping throughput high enough to
facilitate comfortable web surfing and enable the transportation of low-latency applications over
\pt{}.

A censor can still measure derived flow metrics such as ``total bytes transferred'', packet
directions or the ``burstiness'' of \pt{}'s behaviour. These metrics would be expensive to disguise
and by exploiting them, a censor would at least be able to guess whether \pt{}'s transported
application is a bulk file transfer or a request-response protocol. Nevertheless, traffic analysis
does not give censors a \emph{certain answer}. False positives are always a problem and can lead to
overblocking. As mentioned in our threat model, we believe that the censor might use traffic
analysis to select a subset of traffic for closer inspection but not to block flows.


\section{Experimental Evaluation}
\label{sec:experimental_evaluation}


We implemented a prototype of \pt{} in the form of several Python modules for obfsproxy. Our
prototype consists of approximately 2000 lines of code. The measurements below were all
conducted using this prototype.

As illustrated in Figure \ref{fig:experimental_setup}, our experimental setup consisted of two
Debian GNU/Linux machines which were connected via a router which performed the measurements. All
three machines were connected over Fast Ethernet. We expect this setup to be ideal for a censor
because it does not cause IP fragmentation or high latency due to overloaded middle boxes. As a
result, we believe that a censor would do worse in practice. Both of our machines were running Tor
v0.2.4.10-alpha and obfsproxy. The Tor bridge was configured to be private and was only used by
our client. The bridge then relayed all traffic into the public Tor network. Note that \pt{} is only
``spoken'' in between the client and the bridge.

\begin{figure}[h]
\centering
\begin{center}
		\includegraphics[width=0.27\textwidth]{experimental_setup.pdf}
	\end{center}
	\caption{The experimental setup.}
	\label{fig:experimental_setup}
\end{figure}


\subsection{Blocking Resistance}
\label{sec:blocking_resistance}
To create network traffic for our measurements, we downloaded the 1 MB Linux kernel v1.0 from
kernel.org\footnote{\url{https://www.kernel.org/pub/linux/kernel/v1.0/linux-1.0.tar.bz2}.} on
the client. We downloaded the file once over Tor\footnote{In fact, we downloaded the file many times
over Tor and found that consecutive runs differed mostly in the ratio between 586-byte and 1448-byte
packets. As a result, we only plot one run.} and 5 times over \pt{}.

The packet length distribution for client-to-server traffic is illustrated in Figure \ref{fig:c2spl}
and the server-to-client traffic in Figure \ref{fig:s2cpl}. The solid orange line represents the
download over Tor. The prevalence of 586-byte packets is clearly visible; especially for the
client-to-server traffic. These packets contain internal Tor cells which handle flow control. All
these segments had to be wrapped into a 512-byte Tor cell. In addition, more than 50\% of the
server-to-client traffic consists of 1448-byte packets. The remaining brown lines represent 5
consecutive downloads over \pt{}. Both empirical cumulative distribution functions visibly deviate
from Tor's.



\begin{figure}[t]
\centering
\includegraphics[width=0.35\textwidth]{c2s-pl-ecdf.pdf}
\caption{Client-to-server packet lengths.}
\label{fig:c2spl}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=0.35\textwidth]{s2c-pl-ecdf.pdf}
\caption{Server-to-client packet lengths.}
\label{fig:s2cpl}
\end{figure}

Figure \ref{fig:c2siat} and \ref{fig:s2ciat} depict the inter arrival times of the same data. The
delays in Figure \ref{fig:c2siat} tend to be rather high---only 40\% of Tor packets had an inter
arrival delay under 10 ms---because the client only acknowledged the bulk data coming from the
server. For this reason, the delays are much smaller in Figure \ref{fig:s2ciat}. For both, the
packet lengths as well as the inter arrival times, a two-sample Kolmogorov-Smirnov test rejected the
hypothesis that the Tor distributions equal any of \pt{}'s distributions.

\begin{figure}[t]
\centering
\includegraphics[width=0.35\textwidth]{c2s-iat-ecdf.pdf}
\caption{Client-to-server inter arrival times.}
\label{fig:c2siat}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=0.35\textwidth]{s2c-iat-ecdf.pdf}
\caption{Server-to-client inter arrival times.}
\label{fig:s2ciat}
\end{figure}

\begin{table*}[t]
\caption{Mean () and standard deviation () of the goodput, transferred KBytes and the
total overhead. The data was generated based on the download of a 1,000,000-byte file.}
\label{table:performance}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
& \multicolumn{2}{|c|}{\textbf{HTTP}} & \multicolumn{2}{|c|}{\textbf{Tor}} &
	\multicolumn{2}{|c|}{\textbf{\pt{}}} \\
& \multicolumn{2}{|c|}{} &
   \multicolumn{2}{|c|}{} &
   \multicolumn{2}{|c|}{} \\

\hline
\textbf{Goodput} & 6.3 MB/s & 3.4 MB/s & 279.7 KB/s & 293.9 KB/s & 89.8 KB/s & 41.1 KB/s \\
\hline
\textbf{CS KBytes} & 23.1 & 1.6 & 71.9 & 7.7 & 132.5 & 35.5 \\
\hline
\textbf{SC KBytes} & 1047 & 20.7 & 1121.6 & 38.8 & 1242.3 & 70.2 \\
\hline
\textbf{Total overhead} & 9.5\% & 2.2\% & 22.2\% & 4.4\% & 40.7\% & 10.1\% \\
\hline
\end{tabular}
\end{center}
\end{table*}

\subsection{Performance}
In order to evaluate \pt{}'s overhead and goodput, we created a 1,000,000-byte file consisting of
random bytes and placed it on a web server operated by our institution. We then downloaded the file
with \texttt{wget} 25 times over HTTP, Tor and \pt{}, respectively. For Tor and \pt{}, we
established a new circuit for every download but we used the same entry guard in order to make the
results more comparable. Based on the measured data, we calculated the mean  and the standard
deviation  for several performance metrics. The results are depicted in Table
\ref{table:performance}.


The goodput refers to the application layer throughput. We achieved very high values for the HTTP
download because the file transfer could be carried out over the LAN. Tor averaged at roughly 280
KB/s and \pt{} achieved approximately one third of that. Just like Tor, \pt{} exhibits a high
standard deviation. We believe that this was mostly caused by differences in circuit throughput but
\pt{} also fluctuates due to its different shapes. Shapes featuring many large packet lengths lead
to higher throughput whereas shapes with small packets tend to harm throughput.

The next two rows of Table \ref{table:performance} refer to the transferred KBytes from client to
server (CS) and server to client (SC). Note that this covers all the data which was
present on the wire; including IP and TCP header. The consideration of IP and TCP overhead is
important because one of the reasons for \pt{}'s overhead is the varying packet lengths which
imply an increase in IP and TCP headers. Unsurprising, Tor transferred more data than HTTP because
of Tor's and TLS' protocol overhead. \pt{} transferred the most data because of the additional
protocol header (see \S \ref{sec:confidentiality}) as well as the varying packet lengths.
This is emphasised by the high standard deviation of 35 and 70 KBytes, respectively.

The last row illustrates the total protocol overhead. Once again, we also consider IP and TCP
headers. HTTP has the lowest overhead followed by Tor and finally \pt{}. Our protocol exhibits 40\%
overhead with a high standard deviation of 10\% which stems from the shape shifts.



\section{Discussion}
\label{sec:discussion}
We made an effort to design \pt{} in a way to be resistant against current censorship threats; most
notably active probing. In this section we discuss the remaining attack surface and point out
emerging problems.

\subsection{Attacks on ScrambleSuit}

\textbf{Active Probing}: A censor could still actively probe a \pt{} server. Upon
establishing a TCP connection, a censor could proceed by sending arbitrary data. However, the server
will not respond without prior authentication. In contrast to SilentKnock \cite{Vasserman2007} and
BridgeSPA \cite{Smits2011}, \pt{} does not disguise its ``aliveness''. While this approach does
leak information\footnote{A censor learns that a server is online but unwilling to talk unless given
the ``correct'' data.}, it has the benefit of making \pt{} significantly easier to deploy due to
lack of platform dependencies.

\textbf{Packet Injection, Modification and Dropping}: A censor could tamper with an existing \pt{}
connection by injecting data, modifying bytes on the wire or dropping packets. Both communicating
parties will detect injected or modified data due to the MAC being invalid. Hijacking a \pt{} TCP
connection boils down to the same problem; a censor would bypass the authentication but is unable to
talk to the \pt{} server because the session keys are unknown. Finally, dropped packets are handled
by the application protocol and could trigger TCP retransmissions.

\textbf{Payload \& Flow Analysis}: Payload analysis would only yield data which is computationally
indistinguishable from randomness. Flow analysis, on the other hand, would yield a certain
distribution of packet lengths and inter arrival times which changes from connection to connection.
While \S \ref{sec:shortcomings} showed that defending against traffic analysis can be costly, our
main objective is to thwart active probing attacks because they enable \emph{deterministic protocol
identification}. Sophisticated traffic analysis attacks will always have a range of
\emph{uncertainty}. We believe that the GFW's very reason to conduct active probing is to obtain
certainty and avoid collateral damage. Protocol blocking based on traffic analysis will unavoidably
imply false positives.

\subsection{Future Work}
Improving Tor's censorship resistance is a two-sided problem. On the one hand, bridge descriptors
need to be distributed to users while not falling into the hands of censors and on the other hand,
the subsequent Tor connection should be hard to identify for censors. While we focused on the
latter, the former remains an open problem as well. Recent work focused on reputation-based models to
maximise bridge aliveness \cite{McCoy2011,Wang2013}.

The arms race with circumvention tools might pressure censors into introducing whitelisting. While
we are not aware of country-wide whitelists, Russia is experimenting with a ``Clean Internet''
\cite{russiawl}. Should this approach turn out to be successful for censors, the arms race will
shift towards tunneling circumvention traffic through whitelisted protocols.

We finally point out that no protocol is ``fingerprintless''. In our design, we tried to avoid
obvious distinguishers and minimised the interaction surface for attackers who lack the shared
secret. But since \pt{} does not mimic a cover protocol, it hides within the set of \emph{unknown
rather than known} protocols. As long as a censor's network features a high diversity of
network protocols, the censor is unable to fully control or model, we expect our approach to provide
a decent level of protection.


\section{Conclusion}
\label{sec:conclusion}
We presented \pt{}; a transport protocol which provides lightweight obfuscation for application
protocols such as Tor and VPN. The two major contributions of our protocol are the ability to defend
against \emph{active probing} and \emph{protocol classifiers}. We achieve the former by proposing
two authentication mechanisms---one general-purpose and the other specifically for Tor---and the
latter by proposing morphing techniques to disguise packet lengths and inter arrival times.

We further developed a prototype of \pt{} and used it to conduct an experimental evaluation. In
particular, we discussed the effectiveness of our obfuscation techniques as well as \pt{}'s
overhead. Our evaluation suggests that \pt{} can provide strong protection against censors who do
not overblock significantly. Finally, we believe that the low protocol overhead makes \pt{}
comfortable to use for web surfing and other low-latency applications.


\section*{Acknowledgements}
We want to thank George Kadianakis, Harald Lampesberger, Stefan Lindskog, and Michael Rogers who all
provided valuable feedback which improved this paper. We further want to thank Internetfonden
of the Swedish Internet Infrastructure Foundation for supporting the main author's work with a
research grant.

Our code is publicly available at
\url{http://www.cs.kau.se/philwint/scramblesuit/}. Finally, we point out that all of the references
listed below contain a link to an open access version of the respective resource. Please consider
doing the same in your papers.

\printbibliography

\end{document}
