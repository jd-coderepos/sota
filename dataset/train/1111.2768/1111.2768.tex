\documentclass[letterpaper,twocolumn,10pt]{article}

\usepackage[latin1]{inputenc}
\usepackage[english]{babel}
\usepackage{scs}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{amssymb,amsmath}
\usepackage{ amsthm}
\usepackage{hyperref}
\usepackage{gastex}

\renewcommand{\topfraction}{0.95}
\renewcommand{\bottomfraction}{0.95}
\renewcommand{\textfraction}{0.05}
\renewcommand{\floatpagefraction}{0.35}

\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}



\newcommand{\ignore}[1]{}

\def    \ctl        {\mbox{\textsc{CTL }\xspace}}
\def    \CTL        {\mbox{\textsc{CTL }\xspace}}
\def    \ltl        {\mbox{\textsc LTL\xspace}}
\def    \U          {\mathcal{U}}
\def    \G          {\mathcal{G}}
\def    \F          {\mathcal{F}}
\def    \TRUE       {\mbox{\textsc{True}}}

\def    \M          {{\cal M}}
\def    \X          {\mathcal{X}}
\def    \K          {\mathcal{K}}
\def    \O          {\mathcal{O}}

\newcommand{\VHSM}{SHSM}
\newcommand{\HSM}{HSM}
\newcommand{\CHSM}{restricted \VHSM}
\newcommand{\boxhsm}{box}   \newcommand{\boxes}{boxes}
\newcommand{\pspace}{{\sc Pspace}}
\newcommand{\exptime}{{\sc Exptime}}
\newcommand{\np}{{\sc Np}}
\newcommand{\nnode}{node} \newcommand{\nnodes}{nodes} \newcommand{\expand} {\mathit{expn}}
\newcommand{\OUT} {\mbox{\sc out}}
\newcommand{\prop}{\mbox{{\sc true}}}
\newcommand{\vertex}{\mbox{vertex}}   \newcommand{\vertices}{\mbox{vertices}}
\newcommand{\iin}{in}
\newcommand{\tuple}[1]{\langle #1 \rangle}
\newcommand{\word}{well-formed sequence}
\newcommand{\words}{well-formed sequences}
\newcommand{\false}{\mbox{{\sc false}}}
\newcommand{\Ffalse}{\mbox{{\em false}}}
\begin{document}

\title{Graded \CTL\ Model Checking for Test Generation}
\author{
Margherita Napoli and Mimmo Parente\\
Dip.to di Informatica ed Applicazioni\\
Universit\`a di Salerno, Italy\\
\href{mailto:napoli@unisa.it}{napoli@unisa.it}
\hspace{1truecm}
\href{mailto:parente@unisa.it}{parente@unisa.it}
}

\maketitle

\keywords{Model Checking, Test Generation, Graded Temporal Logics, Hierarchical Finite State Machines.}

\begin{abstract}
\noindent
Recently there has been a great attention from the scientific community towards the use
of the model-checking technique as a tool for {\em test generation} in the simulation field.
This paper aims to provide a useful mean
to get more insights along these lines. By applying recent results
in the field of {\em graded} temporal logics, we present a new efficient model-checking algorithm
for Hierarchical Finite State Machines (\HSM), a well established symbolism long and widely
used for representing hierarchical models of discrete systems.
Performing model-checking against specifications expressed using graded temporal logics
has the peculiarity of returning more counterexamples within a {\em unique run}.
We think that this can greatly improve the efficacy
of automatically getting test cases.
In particular we ve\-ri\-fy two different models of  HSM
against branching time temporal properties.
\end{abstract}



\section{Introduction}\label{intro}
The {\em model-checking}  is a widely used technique to verify correctness of hardware and software systems.
A model checker explores the state space of a model of a given system to determine whether a given specification is satisfied.
Usually such specifications are expressed by means of formulas in a temporal logic, such as the Computational Temporal
Logics CTL, \cite{CE82}.
A very useful feature to fix the possible errors in the model is that when the model checker detects that the specification is violated then it returns a counterexample. In  the last years this feature  has also been exploited in
the simulation framework.
In fact, it is nowadays a well-established fact that formal (both software and hardware) analysis
is a valid complementary technique to simulation and testing (see e.g.,\cite{DHRPV07}).
On one side, the model checking approach, \cite{CGP99}, allows a full verification of system
components to be free of errors,
but its use is limited to small and medium sized models, due to the so-called state explosion
problem.
On the other hand the testing and simulation approaches \cite{PY} are usually applied to larger systems:
they  check the presence of errors in the system behavior through the observation of a chosen set of controlled executions.
Shortly, the efficacy of testing relies on the creation of test benches and that
of model-checking on the ability of formally defining the properties to be verified,
through temporal logic formulas.
More explicitly, the complementarity of the two techniques lies in the fact that the
counterexamples generated by a model-checker can be interpreted as test cases.
A good choice of the test suite is  the key for successful deductions of faults in
simulation processes. It is now more than a decade that model-checking is used for this purpose,
see \cite{FWA09, WASF07, A95, AB99, ABM98,GH99}.
In this context, a high level abstraction of the System Under Test (SUT),
is necessary.
Such abstraction should be simple and easy to model check,
but precise enough to serve as a basis for the generation of test cases.
This approach can be usefully adopted also in the DEVS modeling and simulation framework, \cite{Z76}.

However not surprisingly, the most challenging problem is the performance and two issues are crucial:
the choice of an efficient tool to generate the test suite and the choice of a suitable  abstract
model to check.

For the first issue, we propose the use of graded temporal logic specifications. In fact
standard model-checking tools generate only one counterexample for each
run and the check stage (of the model against a specification) is often expensive, in terms
of time resources.
We claim that it is highly desirable to get more meaningful counterexamples with a unique
run of the model checker.
For the second issue we propose the use of HSM as an abstract model of a DEVS
modeling the SUT, which preserves the
hierarchical structure while abstracting the continuous variables.
Thus we focus on how to generate simulation scenarios for
DEVS by providing a tool  which automatically generates multiple
counter-examples in an unique run, using hierarchical state machines as abstract model.
The sequence of events of each counterexample will
then be used to create a timed test trace for DEVS simulation.
In Figure~\ref{esempioAstrazione} a small example of our idea is shown
(the states labeled {\em Try1} and {\em Try2} are states on a higher hierarchy level
standing for the graph ).
Suppose we want to check whether the (timed) model in the figure satisfies the specification
(clearly false) stating that if a {\em Fail} occurs in the first attempt ({\em Try1}) of sending a message,
then an {\em Abort} event is eventually reached.
We can model-check an (untimed) over-approximation of the model (shown on the left)
obtaining the error trace {\em Start, Try1.(Send, Wait, Timeout, Fail), Try2.(Send, Wait, Ack), Success}.
This trace lets us concentrate on the portion of the model with a
potential error and can guide the simulation process to detect the error in the timed model.
\begin{figure*}[t]
\begin{picture}(70,50)(-40,-10)

\node[ExtNL=y, NLdist= 1, NLangle=165,Nw=73.0,Nh=20.0,Nmr=3.0](M2)(0,25){}
\node[Nw=10,Nh=6,Nmr=3,Nmarks=i](n1)(-29,25){Start}
\node[Nw=10,Nh=6,Nmr=0](n2)(-13,25){Try}
\node[Nw=10,Nh=6,Nmr=0](n3)(9,25){Try}
\node[Nw=13,Nh=6,Nmr=3](n4)(27,30){Success}
\node[Nw=11,Nh=6,Nmr=3](n5)(27,20){Abort}
\drawedge(n1,n2){}
\drawedge(n2,n3){}
\drawedge(n3,n4){}
\drawedge(n3,n5){}
\drawedge[curvedepth=5](n2,n4){}

\drawline[dash={1.5}0](-18,22)(-28,10)
\drawline[dash={1.5}0](-8,22)(28,10)
\drawline[dash={1.5}0](4,22)(-28,10)
\drawline[dash={1.5}0](14,22)(28,10)

\node[ExtNL=y, NLdist= 1, NLangle=165,Nw=60.0,Nh=20.0,Nmr=3.0](M1)(0,0){}
\node[Nw=10,Nh=6,Nmr=3,Nmarks=i](n6)(-23,0){Send}
\node[Nw=10,Nh=6,Nmr=3](n7)(-9,0){Wait}
\node[Nw=13,Nh=6,Nmr=3](n8)(9,-5){Timeout}
\node[Nw=10,Nh=6,Nmr=3,Nmarks=f](n9)(24,5){Ack}
\node[Nw=10,Nh=6,Nmr=3,Nmarks=f](n10)(24,-5){Fail}
\drawedge(n6,n7){}
\drawedge(n7,n8){}
\drawedge(n8,n10){}
\drawedge[curvedepth=3,ELside=r](n7,n9){}

\node[ExtNL=y, NLdist= 1, NLangle=165,Nw=73.0,Nh=20.0,Nmr=3.0](M2t)(95,25){}
\node[Nw=10,Nh=6,Nmr=3,Nmarks=i](n11)(66,25){Start}
\node[Nw=10,Nh=6,Nmr=0](n12)(82,25){Try}
\node[Nw=10,Nh=6,Nmr=0](n13)(104,25){Try}
\node[Nw=13,Nh=6,Nmr=3](n14)(122,30){Success}
\node[Nw=11,Nh=6,Nmr=3](n15)(122,20){Abort}
\drawedge(n11,n12){}
\drawedge(n12,n13){{\small }}
\drawedge(n13,n14){}
\drawedge(n13,n15){}
\drawedge[curvedepth=5](n12,n14){}

\drawline[dash={1.5}0](77,22)(67,10)
\drawline[dash={1.5}0](87,22)(123,10)
\drawline[dash={1.5}0](99,22)(67,10)
\drawline[dash={1.5}0](109,22)(123,10)

\node[ExtNL=y, NLdist= 1, NLangle=165,Nw=60.0,Nh=20.0,Nmr=3.0](M1t)(95,0){}
\node[Nw=10,Nh=6,Nmr=3,Nmarks=i](n16)(72,0){Send}
\node[Nw=10,Nh=6,Nmr=3](n17)(86,0){Wait}
\node[Nw=13,Nh=6,Nmr=3](n18)(104,-5){Timeout}
\node[Nw=10,Nh=6,Nmr=3,Nmarks=f](n19)(119,5){Ack}
\node[Nw=10,Nh=6,Nmr=3,Nmarks=f](n110)(119,-5){Fail}
\drawedge(n16,n17){}
\drawedge(n17,n18){{\small }}
\drawedge(n18,n110){}
\drawedge[curvedepth=3,ELside=r](n17,n19){}

\end{picture}
\caption{An over-approximation of a model (untimed on the left and timed on the right).}\label{esempioAstrazione}
\end{figure*}
Let us now briefly detail the two notions of graded logics and HSM.
In order to get more counterexamples in a unique run we use
specifications expressed in {\em graded}-\CTL, recently introduced in \cite{FNP08}.
Graded-\CTL\ strictly extends classical \CTL\ with graded modalities: classical CTL can be used for reasoning
about the temporal behavior of systems con\-si\-de\-ring either {\em all} the possible futures
or {\em at least one} possible future, while graded-CTL uses graded extensions on
both exi\-stential and universal quantifiers.
With graded-\CTL\ formulas one can describe a constant number of future scenarios. For example,
one can express that in  different cases it is possible that a waiting process never
obtains a requested resource, or that there are  different ways for a system to reach a
{\em safe state} from a given state.

The notion of finite state machine with a hierarchical structure
has been used for many years for modelling discrete systems,
since the introduction of Statecharts, \cite{H87}, and is actually
applied into many fields as a specification formalism.
In particular, in the  model-checking framework, one of the most considered models is the Hierarchical State Machine (\HSM)
 (see e.g. \cite{AY01}).
A generalization of \HSM\ is introduced
in \cite{LNPP08}, as an exponentially more succinct model  where also higher level states, called {\em boxes},  are labeled with atomic propositions.
The intended meaning of such labeling is that when a box 
expands to a machine , all the vertices of  \emph{inherit} the
atomic propositions of  (\emph{scope}), such that different
vertices expanding to  can place  into different scopes.
Such model is called a \emph{hierarchical state machine
with scope-dependent properties} (Scope-dependent Hierarchical State Machine, shortly \VHSM).


Our contribution aims in providing also strong theoretical evidence of
the soundness of our approach.
In particular we study the problem of verifying whether an \VHSM\ models a given graded-\ctl\ formula.
We first give an algorithm to solve the graded-\ctl\ model-checking  of an \HSM, and then
we extend it to model-check general \VHSM s.
We show that the problem has the same computational complexity as
 \ctl\ model checking, and we show how to solve it both for  \HSM\ and  \VHSM, with an extra factor in the exponent which is
logarithmic in the maximal grading constant occurring in the \CTL\ formula.
Let us stress that the experimental results for flat models reported in \cite{FMNPS10} shows that
 this  extra factor does not have real effects in the running time of the algorithms
(currently we are implementing also the algorithms presented here for
hierarchical structures and the initial tests are very promising).

The rest of the paper is organized as follows:
in Sections~\ref{sec:gradedDefinition}
and~\ref{sec:hierarDefinition}
we give basic definitions and known results
of graded-CTL, and of SHSM, respectively;
in Section~\ref{sec:Algo} we give the algorithm to model-check \VHSM\
against graded-CTL  specifications.
In Section~\ref{sec:Conclusions} we give our conclusions.

\section{Graded \CTL}\label{sec:gradedDefinition}
In this section we first recall the definitions of \ctl and then give that of
graded-\ctl,
see \cite{FNP08}.
The temporal logic \ctl \cite{CE82} is a branching-time logic in
which each temporal operator, expressing properties about a
possible future, has to be preceded either by an  existential or
by an universal path quantifier. So, in \ctl
one can express properties that have to be true either
\emph{immediately after now} (), or \emph{each time from now}
(), or \emph{from now until something happens} (), and it
is possible to specify that each property must hold either in
\emph{some possible futures} () or in \emph{each possible
future} (). Formally, given a finite set of \emph{atomic
propositions} , \ctl is the set of formulas
 defined as follows:
    
where  is an atomic proposition and  and
 are \ctl formulas.
The semantics of a \ctl formula is defined with respect to a
\emph{Kripke Structure} by means of the classical relation
. As usual, a Kripke structure over a set of atomic
propositions , is a tuple  , where  is a finite set of states,  is
the initial state,  is a transition
relation with the property that for each  there is  such that , and  is a
labeling function.
A path in  is denoted by the sequence of states  or by , if it is infinite. The length of a path, denoted by
, is the number of states in the sequence, and 
denotes the -th state .
Then, the relation  for a state  of  is
iteratively defined as follows:
\begin{itemize}
\item
 iff ;
\item
 iff 
(in short, );
\item
 iff  and ;
\item
 iff there exists  such
that  and  (the path
 is called an \emph{evidence} of the formula
);
\item
 iff there exists an infinite path
 starting from  (i.e., ) such that for all ,  (the path  is called
an \emph{evidence} of the formula );
\item
 iff there exists a finite
path  with length  starting from  such that
 and, for all ,  (the path  is called an
\emph{evidence} of the formula );
\end{itemize}
We say that a Kripke structure  \emph{models} a \ctl formula  iff .
Note that we have expressed the syntax of \ctl with one of the
possible minimal sets of operators. Other temporal operators as well as
the universal path quantifier ,  can be easily derived
from those.
\textbf{Graded-\ctl} extends the classical \ctl by adding graded modalities on the quantifier
operators. Graded modalities specify in how many possible futures  a given path property has to hold,
and thus generalize \ctl allowing to reason
about more than a given number of possible distinct future
behaviors. Let us first define the notion of {\em distinct}.
Let  be a Kripke structure. We say that two paths 
and  on  are \emph{distinct} if there exists an index
 such that . Observe that from this definition if a path is the
prefix of another path, then they are not distinct.
The \emph{graded existential path quantifier} , requires
the existence of  pairwise distinct evidences of a path-formula. Given a
set of atomic proposition , the syntax of graded-\ctl is
defined as follows:
    
where ,  is a non-negative integer and  and
 are graded-\ctl formulas.
The semantics of graded-\ctl is still defined with respect to a
Kripke structure  on the set
of atomic propositions . In particular, for formulas of the
form ,  and  the semantics is the same as in the classical \ctl.
For the remaining formulas, the semantics is defined as follows:
\begin{itemize}
\item
, with  and either  or  or , iff there exist  pairwise
distinct evidences of  starting from .
\end{itemize}
It is easy to observe that classical \ctl is a proper fragment of
graded-\ctl since the simple graded formula  cannot be
expressed in \ctl, whereas any \ctl formula is also a graded-\ctl
formula  (note that  is equivalent to ).
We can also consider the graded extension of the universal
quantifier, , with the meaning that \emph{all the
paths starting from a node , but at most  pairwise distinct
paths, are evidences of a given path-formula}. The quantifier
 is the dual operator of  and can obviously be
re-written in terms of . However, while  and  can be easily re-written
respectively as  and , the transformation of the formula  with  in terms of  deserves more care
(see \cite{FNP08} for a detailed treatment).
\ignore{
In fact, we have that 
is equivalent to  (note that this formula is
not a graded-\ctl formula because of the occurrence of the
innermost negation), that can be translated in graded-\ctl in the
following way:


In fact observe that a path not
satisfying  is a path that satisfies either
 or  (clearly,
the paths satisfying  are all distinct from the paths
satisfying ). Therefore the formula  holds in , if  pairwise distinct paths stem
from this, each satisfying either  or .
}

The \textbf{graded-\ctl model-checking} is the problem of
verifying whether a Kripke structure  models a graded-\ctl
formula .
The complexity of the graded-\ctl model-checking problem
is linear with respect to the size of
the Kripke structure and to the size of the formula,
(this latter being the number of the temporal and the boolean
operators occurring in it). Let us remark that this complexity is
independent from the integers  occurring in the formula.

\section{Scope-dependent  Hierarchical State Machines}\label{sec:hierarDefinition}
In this section we  formally define the Scope-dependent Hierarchical State Machines and
recall some known results.
The Scope-dependent Hierarchical State Machines are defined as follows.
\begin{definition}
A {\em Scope-dependent Hierarchical State Machine}
(\VHSM) over  is a tuple , each
 is called {\em
machine} and consists of:
\begin{itemize}
\item a finite set of \vertices\ ,
an {\em initial} \vertex\ 
and a set of {\em output} \vertices\ ;
\item a labeling function  that
maps each \vertex\ with a set of atomic propositions;
\item an expansion mapping 
such that , for each , and
, for each ;
\item a set of edges  where each edge is
either a couple , with  and
, or a triple  with
, , and
.
\end{itemize}
\end{definition}
\begin{figure*}[t]
\begin{center}
\begin{picture}(137,52)(-8,-52)
\node[NLangle=163.0,NLdist=35.0,Nw=74.0,Nh=17.0,Nmr=2.98](n0)(34.55,-16.19){ }

\node[Nfill=y,fillgray=0.9,NLangle=-90.0,NLdist=6.0,Nw=15.0,Nmr=1.0](n39)(46.55,-16.19){
} \nodelabel[NLangle=0.0](n39){}

\node[Nfill=y,fillgray=1.0,Nw=2.2,Nh=2.2,Nmr=1.1](n41)(40.55,-16.19){}

\node[Nfill=y,fillgray=0.9,NLangle=0.0,Nw=15.0,Nmr=1.0](n56)(22.55,-16.19){
} \nodelabel[NLangle=-90.0,NLdist=6.0](n56){}

\node[Nfill=y,fillgray=1.0,Nw=2.2,Nh=2.2,Nmr=1.1](n57)(28.55,-16.19){}

\node[Nfill=y,fillgray=1.0,Nw=2.2,Nh=2.2,Nmr=1.1](n58)(16.65,-16.19){}

\node[Nfill=y,fillgray=1.0,NLangle=0.0,ilength=8.0,Nmarks=i,Nw=4.5,Nh=4.5,Nmr=2.25](n108)(4.55,-16.19){
}
\nodelabel[NLangle=-90.0,NLdist=5.0](n108){}

\drawedge(n108,n58){}

\node[Nfill=y,fillgray=1.0,Nw=2.2,Nh=2.2,Nmr=1.1](n76)(52.55,-16.19){}

\node[Nfill=y,fillgray=1.0,NLangle=0.0,flength=8.0,Nmarks=f,Nw=4.5,Nh=4.5,Nmr=2.25](n188)(64.55,-16.19){
} \nodelabel[NLangle=-90.0,NLdist=5.0](n188){
}

\drawedge(n57,n41){}

\drawedge(n76,n188){}

\drawloop[loopdiam=5.0,loopangle=50.0](n108){}

\drawloop[loopdiam=5.0,loopangle=50.0](n188){}

\node[Nfill=y,fillgray=0.8,NLangle=149.0,NLdist=20.5,Nw=44.0,Nh=17.0,Nmr=2.98](n230)(102.71,-40.32){
}

\node[Nfill=y,fillgray=1.0,NLangle=0.0,ilength=8.0,Nmarks=i,Nw=4.5,Nh=4.5,Nmr=2.25](n232)(87.71,-40.32){
}
\nodelabel[NLangle=-90.0,NLdist=5.0](n232){}

\node[Nfill=y,fillgray=1.0,NLangle=0.0,flength=8.0,Nmarks=f,Nw=4.5,Nh=4.5,Nmr=2.25](n234)(117.71,-40.32){
} \nodelabel[NLangle=-90.0,NLdist=5.0](n234){}

\drawloop[loopdiam=5.0,loopangle=50.0](n232){}

\drawloop[loopdiam=5.0,loopangle=50.0](n234){}

\drawedge(n232,n234){}

\node[Nfill=y,fillgray=0.9,NLangle=163.0,NLdist=35.0,Nw=74.0,Nh=17.0,Nmr=2.89](n95)(34.55,-40.52){
}

\node[Nfill=y,fillgray=0.8,NLangle=-90.0,NLdist=6.0,Nw=15.0,Nmr=1.0](n96)(46.55,-40.52){
} \nodelabel[NLangle=0.0](n96){}

\node[Nfill=y,fillgray=1.0,Nw=2.2,Nh=2.2,Nmr=1.1](n97)(40.55,-40.52){}

\node[Nfill=y,fillgray=0.8,NLangle=0.0,Nw=15.0,Nmr=1.0](n98)(22.55,-40.52){
} \nodelabel[NLangle=-90.0,NLdist=6.0](n98){
}

\node[Nfill=y,fillgray=1.0,Nw=2.2,Nh=2.2,Nmr=1.1](n99)(28.55,-40.52){}

\node[Nfill=y,fillgray=1.0,Nw=2.2,Nh=2.2,Nmr=1.1](n100)(16.55,-40.52){}

\node[Nfill=y,fillgray=1.0,NLangle=0.0,ilength=8.0,Nmarks=i,Nw=4.5,Nh=4.5,Nmr=2.25](n101)(4.55,-40.52){
}
\nodelabel[NLangle=-90.0,NLdist=5.0](n101){}

\drawedge(n101,n100){}

\node[Nfill=y,fillgray=1.0,Nw=2.2,Nh=2.2,Nmr=1.1](n102)(52.55,-40.52){}

\node[Nfill=y,fillgray=1.0,NLangle=0.0,flength=8.0,Nmarks=f,Nw=4.5,Nh=4.5,Nmr=2.25](n103)(64.55,-40.52){}
\nodelabel[NLangle=-90.0,NLdist=5.0](n103){}

\drawedge(n99,n97){}

\drawedge(n102,n103){}

\drawloop[loopdiam=5.0,loopangle=50.0](n101){}

\drawloop[loopdiam=5.0,loopangle=50.0](n103){}

\end{picture}
\end{center}



\caption{A simple \VHSM\ .  }\label{esempioCHSM}
\end{figure*}
In the rest of the paper we use  as the number of machines of
an \VHSM\  and  is called {\em top-level} machine.
We assume that the sets of \vertices\  are pairwise disjoint.
The set of all \vertices\ of  is . The
mappings  and  extend the mappings  and
, respectively. If , the \vertex\ 
expands to the machine  and is called {\em \boxhsm}. When
,  is called a {\em \nnode}. Let us define the
closure , as:
 if either  or there exists
 such that . We say
that a \vertex\  is an \emph{ancestor} of  and  is a
\emph{descendant} from  if , for .

A vertex  is called a \emph{successor} of  if there is an edge
 , and it is called a \emph{z-successor} of ,
 for ,  if .

An \HSM\ is an \VHSM\ such that  ,
for any box .


As an example of an \VHSM\  see
Figure~\ref{esempioCHSM}, where  are atomic
propositions labeling \nnodes\ and \boxes\ of ,  and 
are respectively entry \nnodes\ and exit \nnodes\ for , and
 for  and .




\ignore{
\begin{definition}\label{restricted}
A restricted \VHSM\  is an \VHSM\
where for all vertices 
such that  is an ancestor of  in  it holds:\\
\centerline{}
\end{definition}

Such a restriction is quite natural and still allows us to succinctly represent
interesting systems. Note that
the \VHSM\ of Figure~\ref{esempioCHSM} is also restricted.
}



\noindent{\large\bf Semantics.}
The semantics of an \VHSM\ 
is given by a {\em flat}  Kripke structure, denoted .

A sequence of \vertices\ , , is
called a {\em \word} if , for
.
Moreover,  is also {\em complete} when  and
 is a \nnode.

A state of  is  where  is
a complete \word\ of .
Note that the length of a complete \word\ is at most , therefore
the number of states  of  is at most exponential in the number of
machines composing .
Transitions of  are obtained by using as templates the
edges of .
Figure~\ref{peggioDiNoi} shows the Kripke structure
which is equivalent to the \VHSM\ of Figure~\ref{esempioCHSM}.
We formally define  as follows.
\ignore{
\begin{definition}\label{semDef}
Given an \VHSM\ , the corresponding flat
Kripke structure  is defined as:
\begin{itemize}
\item The states of  are , for
, where  is a complete
\word.

\item The initial state of  is , where
 is the initial \vertex\ of 
(the top-level machine of ).

\item
If  and  are states, then  is a
transition of  if there is an edge , ,
such that one of the following cases occurs:
\begin{itemize}

\item , , for ,
and , that is the edge connects two \nnodes;

\item , , for , , and
, that is the edge connects a \nnode\  to
a \boxhsm\  and  is the initial \vertex\ of the
machine which  expands to;

\item , , for , and
, that is the edge connects a \boxhsm\
 to a \nnode\ , through the output \vertex\ ;

\item , , for , ,
 , and
,
that is the edge connects two \boxes.
\end{itemize}

\item
The labeling of  is such that a state
 is labeled by the set of atomic propositions
.
\end{itemize}

\end{definition}

A \emph{run} of an \VHSM\  is a path of  starting from .

\noindent{\bf An alternative recursive definition of .}\\
}
Given an \VHSM\ , it is immediate to
observe that the tuple , , is an \VHSM\ as well. Clearly, . In the following, we
sketch how to compute recursively the flat Kripke structures
.

We start with  which is obtained from machine  by
simply replacing each \vertex\  with a state 
labeled with  (recall that by
definition all \vertices\ of  are \nnodes). Thus, for each
edge  we add a transition  in .

For ,  is obtained from  by simply replacing each
\boxhsm\  of  with a copy of the Kripke structure
. More precisely, for each \nnode\ ,
 is a state of  which is labeled with
 and for each \boxhsm\  and state  of , 
is a state of  and is labeled with . The transitions of
 are all inherited in , that is, there is
a transition  in
 for each  transition  of . The remaining transitions of
 correspond to the edges of :
\begin{itemize}
\item for each \nnode\  and edge 
(resp. ) there
is a transition
from  (resp. ) to ;

\item for each \boxhsm\  and
edge  (resp. ) there
is a transition from  (resp.  )
to .
\end{itemize}

A \boxhsm\  expanding into
 is a placeholder for   and determines
a subgraph in   isomorphic to  .
This is emphasized in Figure~\ref{peggioDiNoi}, where
we have enclosed in shades of the same shape and color the isomorphic
subgraphs corresponding to a same graph .
Therefore, Figure~\ref{peggioDiNoi} also illustrates
the recursive definition of .

If two distinct \boxes\  and  both expand into the same
machine , that is ,
then the states of  appear in  in two different scopes,
possibly labeled with different sets of atomic propositions:
in one scope this set contains  and in the other it
contains .
The atomic propositions labeling \boxes\ represent
\emph{scope-properties}.
In fact, for a given \boxhsm\ , the set  of atomic propositions
is meant to hold true at  and at all its possible descendants.


\begin{figure*}[t]
\begin{picture}(213,58)(0,-58)

\drawpolygon[fillgray=0.92,Nframe=n,arcradius=3](18,-1)(18,-23)(120,-23)(120,-1)

\drawpolygon[fillgray=0.85,Nframe=n,arcradius=3](35,-4)(35,-20)(67,-20)(67,-4)

\drawpolygon[fillgray=0.85,Nframe=n,arcradius=3](69,-4)(69,-20)(101,-20)(101,-4)


\drawpolygon[fillgray=0.92,Nframe=n,arcradius=3](9,-31.07)(9,-53.07)(111,-53.07)(111,-31.07)

\drawpolygon[fillgray=0.85,Nframe=n,arcradius=3](27,-34.07)(27,-50.07)(59,-50.07)(59,-34.07)

\drawpolygon[fillgray=0.85,Nframe=n,arcradius=3](61,-34.07)(61,-50.07)(93,-50.07)(93,-34.07)


\node[NLangle=0.0,Nh=6.0,Nmr=3.0](n2)(4.98,-12.0){
} \nodelabel[NLangle=-90.0,NLdist=5.5](n2){
}

\node[NLangle=0.0,Nw=13.0,Nh=6.0,Nmr=3.0](n6)(111.98,-12.0){
} \nodelabel[NLangle=-90.0,NLdist=5.5](n6){
 }

\node[NLangle=0.0,Nw=10.0,Nh=6.0,Nmr=3.0](n7)(24.98,-12.0){
}
\nodelabel[NLangle=-90.0,NLdist=5.5](n7){}

\node[NLangle=0.0,Nw=13.0,Nh=6.0,Nmr=3.0](n14)(58.57,-12.48){
}
\nodelabel[NLangle=-90.0,NLdist=5.5](n14){
 }

\node[NLangle=0.0,Nw=13.2,Nh=6.0,Nmr=3.0](n15)(42.97,-12.48){
}
\nodelabel[NLangle=-90.0,NLdist=5.5](n15){
 }

\node[NLangle=0.0,Nw=13.0,Nh=6.0,Nmr=3.0](n57)(92.97,-12.48){
}
\nodelabel[NLangle=-90.0,NLdist=5.5](n57){
 }

\node[NLangle=0.0,Nw=13.2,Nh=6.0,Nmr=3.0](n58)(77.47,-12.48){
}
\nodelabel[NLangle=-90.0,NLdist=5.5](n58){
 }
\node[NLangle=0.0,Nh=6.0,Nmr=3.0](n63)(123.88,-42.01){
} \nodelabel[NLangle=-90.0,NLdist=5.5](n63){
}

\node[NLangle=0.0,Nw=10.0,Nh=6.0,Nmr=3.0](n64)(103.11,-42.01){
} \nodelabel[NLangle=-90.0,NLdist=5.5](n64){
}

\node[NLangle=0.0,Nw=10.0,Nh=6.0,Nmr=3.0](n65)(16.49,-42.15){
}
\nodelabel[NLangle=-90.0,NLdist=5.5](n65){}

\node[NLangle=0.0,Nw=13.0,Nh=6.0,Nmr=3.0](n68)(50.68,-42.07){
}
\nodelabel[NLangle=-90.0,NLdist=5.5](n68){
 }

\node[NLangle=0.0,Nw=13.2,Nh=6.0,Nmr=3.0](n69)(35.28,-42.07){
}
\nodelabel[NLangle=-90.0,NLdist=5.5](n69){
 }

\node[NLangle=0.0,Nw=13.0,Nh=6.0,Nmr=3.0](n72)(85.18,-42.07){
}
\nodelabel[NLangle=-90.0,NLdist=5.5](n72){
 }
\node[NLangle=0.0,Nw=13.2,Nh=6.0,Nmr=3.0](n73)(69.08,-42.07){
}
\nodelabel[NLangle=-90.0,NLdist=5.5](n73){
 }

\drawedge(n2,n7){}

\drawedge(n68,n73){}

\drawedge(n64,n63){}

\drawloop[ELpos=15,loopdiam=4.0,loopangle=38.0](n2){ }

\drawloop[ELpos=15,loopdiam=4.0,loopangle=38.0](n7){ }

\drawloop[ELpos=15,loopdiam=4.0,loopangle=38.0](n6){ }

\drawloop[ELpos=15,loopdiam=4.0,loopangle=38.0](n65){ }

\drawloop[ELpos=15,loopdiam=4.0,loopangle=38.0](n64){ }

\drawloop[ELpos=15,loopdiam=4.0,loopangle=38.0](n63){ }

\drawloop[ELpos=15,loopdiam=4.0,loopangle=38.0](n73){ }

\drawloop[ELpos=15,loopdiam=4.0,loopangle=38.0](n15){ }

\drawloop[ELpos=15,loopdiam=4.0,loopangle=38.0](n14){ }

\drawloop[ELpos=15,loopdiam=4.0,loopangle=38.0](n58){ }

\drawloop[ELpos=15,loopdiam=4.0,loopangle=38.0](n57){ }

\drawloop[ELpos=15,loopdiam=4.0,loopangle=38.0](n69){ }

\drawloop[ELpos=15,loopdiam=4.0,loopangle=38.0](n68){ }
\drawloop[loopdiam=4.0,loopangle=38.0](n72){ }

\drawedge(n14,n58){}

\drawedge(n15,n14){}

\drawedge(n58,n57){}

\drawedge(n7,n15){}

\drawedge(n65,n69){}

\drawedge(n73,n72){}

\drawedge(n72,n64){}

\drawedge(n69,n68){}
\drawbpedge(n6,-18,85.88,n65,-203,66.37){}

\drawedge(n57,n6){}
\end{picture}
\caption{The Kripke structure obtained by flattening the \VHSM\ 
of Figure~\ref{esempioCHSM}. }\label{peggioDiNoi}
\end{figure*}

\noindent{\large\bf Succinctness.}
Clearly, any  hierarchical structure, either an \HSM\ or an \VHSM,
is in general more succinct than a
traditional Kripke structure. Scope properties make \VHSM\
possibly even more succinct than \HSM.
In fact, two isomorphic subgraphs of a Kripke structure which differ only on the labeling
of the vertices can be represented in an \VHSM\ by the single machine ,
while it should be represented by two different machines in an \HSM.
Let us recall two main results from \cite{LNPP08} on the succinctness
of these models,
where a  restricted \VHSM\  is an \VHSM\
where for all vertices 
such that  is an ancestor of  in  it holds that
.


\begin{theorem}[\cite{LNPP08}]\label{theo:succintezza1}
Restricted \VHSM s can be exponentially more succinct than
\HSM s and finite state machines.
\end{theorem}

There is an exponential gap also between \CHSM s and \VHSM s as
shown in the following proposition.

\begin{theorem}[\cite{LNPP08}]
\VHSM s can be exponentially more succinct than \CHSM s.
\end{theorem}

Observe that  \HSM s, \CHSM s and \VHSM s can all be
translated to equivalent finite state machines with a single exponential
blow-up. Thus, the two succinctness results do not add up to each other, in the
sense that it is not true that \VHSM s can be double exponentially more
succinct than \HSM s.
\ignore{
From Proposition~\ref{theo:succintezza1} and the fact that any
\CHSM\ is also an \VHSM, we have the following.
\begin{corollary}
\VHSM s can be exponentially more succinct than
\HSM s and finite state machines.
\end{corollary}

}



\section{Model checking Problem}\label{sec:Algo}
The \textbf{\ctl model-checking} is the problem of verifying
whether a Kripke structure  models a \ctl formula.
For an \VHSM\ ,  the \textbf{\ctl model-checking} is the problem of verifying
whether the flat structure  models a \ctl formula.
It is known that the \ctl model-checking problem can be solved in
linear time  in the size of both the formula and  the machine,
see \cite{CE82}, while it is exponential for both  \HSM\ and \VHSM.
More precisely, the following theorem holds.


\begin{theorem}[\cite{AY01},\cite{LNPP08}]\label{theo:ctlMc}
The \ctl\ model-checking  of an \VHSM\  for a formula  can be solved in
 time, where  is the maximum number of exit
nodes of  and  is the set of atomic proposition occurring in . Moreover, if  is an \HSM, then it can be solved in
  time.
\end{theorem}



In this section we extend the result to  model-checking a hierarchical structure against a graded-\ctl\-formula.
We first show an algorithm for graded-\ctl\ model-checking  of an \HSM, and then
we  extend it to model-check \VHSM s.

The aim of the algorithm is to determine, for each node  in a machine
 of  and each subformula  of , whether   \emph{satisfies}   or not.
Anyway, the concept of satisfiability  may be  ambiguous, since  whether
  satisfies   or not  may depend on the possible different sequences of boxes
which expand in . Thus, the algorithm transforms  in such a way that
either  for every  box sequence  it holds that

(and in this case we say that  satisfies ), or for every   it holds that
.
This transformation determines multiple copies of each  , for 
(clearly, since there are no nodes expanding in the top-level machine ,   there
is not such ambiguity for a ).

The algorithm considers the subformulas    of , starting from the innermost subformulas, and,
for each node  in    sets  if  satisfies , modifying possibly the hierarchical
structure.
If  is an atomic proposition or it is either   or , the algorithm is trivial.
For subformulas with temporal operators and grade , then the algorithm behaves exactly as in \cite{AY01} for
the \ctl\ model-checking.
We now show how it behaves for subformulas of the form , with 
and  . By inductive hypothesis, we assume that
the algorithm has already set  if  satisfies , for .


The algorithm for    is rather simple.
It starts from the nodes of  setting
 if  satisfies , and  then inductively considers  all the machines.
Let  be a node  of .
If  , then it
satisfies  if there are at least  successors in  satisfying .
For an output  node , whether  satisfies   depends also on the successors of a box expanding in .
Multiple copies of  are then created, denoted , where  ,
which correspond  to the different contexts in which  occurs.
The  nodes  of   are   , for a node   of ,  and the boxes are , for a box 
of .
The idea is that  is the number of  -successors,
satisfying ,  of a box expanding in 
(recall that the edges outgoing from a box  are of the type , and we call such 
a -successor of ).
Thus,  the algorithm sets  if the sum of  and the number of successors in  satisfying ,
is greater than .
Moreover, for each box , the algorithm calculates   the number of  -successors of  satisfying  .
 The new \HSM\ is then obtained by defining the new expansion of   in :
 expands in the copy   of  such that
 is  the number of  -successors of  satisfying  .



Consider  now formulas of the type  and let us call .

The algorithm  first determines which nodes of the \HSM\  satisfy the \ctl
formula .  At the end of this step
  is modified in such a way that  each node  either  satisfies  or
satisfies . In doing that, the size of  may double (cf.~\cite{AY01}).
Call  the set of the nodes satisfying .

The algorithm determines, for  each node , whether  satisfies 
using the following idea. Let a {\em sink-cycle} be a cycle
containing only nodes with out-degree .

\noindent{\bf Claim 1.}
Consider
 the graph induced by the states of  where   holds.
Then, given a state ,    iff in this graph
either there is a \emph{non-sink-cycle} reachable from , or
there are  pairwise distinct finite paths connecting  to
\emph{sink-cycles}.

The algorithm  checks the property of the claim analyzing all the machines  of 
starting from the bottom-level machine , which  contains no boxes.
For each machine , it performs a preliminary step to determine
the set of non-sink-cycles  of nodes  such that   a non sink-cycle
is reachable in  from  , through nodes of .


Then, in a successive  step, the algorithm detects the other nodes satisfying  .
In particular for any detected node  and
for any sequence  of boxes (below we show how to remove this dependency from )
the following situation can occur:
 \begin{itemize}
 \item
there is a non-sink cycle reachable in  from a state  including only nodes in ;
\item
  paths start in 
from  ,  each going through nodes belonging to  , and ending into sink-cycles.
\end{itemize}

Observe that, if the  non-sink cycle is in   , but it is not  in , then
  and thus
 the former case has not been detected by the algorithm in the previous preliminary step.

In order to  get that the above properties do not depend on the choice of
, also in  this case multiple copies of each  are created, each for a different
context in which  occurs.
Each copy is denoted  where  
is a mapping such that if  does not satisfies  then .
Its nodes and boxes are obtained by renaming  nodes and boxes of
, as in the previous case.




Let us now give some details on how the above steps are realized.


The set , for ,
is computed by visiting a graph
, with the nodes in .
If , then  contains also
 the boxes  of , such that , and
new vertices , for  (recall that there are no boxes in ). The
edges of  connecting the boxes and the nodes above are edges also of this graph,
moreover, there is an edge from  to  if there is a path from  to  in ,
constituted of all vertices not belonging to .

The algorithm  proceeds inductively,
starting from . When   is considered, for ,  we assume that
the sets   have already been determined, for all , and that, for each ,
 it has also been checked
whether there is a path from  to  , constituted of all vertices not belonging to 
(observe that  this property is used to define the edges in  ).
Moreover, we assume that, if there is such a path, it has also  been  checked whether  there are  vertices in the path with out-degree
greater than  and
whether  has an out-going edge within  .
The result of this test  is useful to detect the non-sink cycles and thus to
determine the  set .
In fact,   if  either a node 
 has an out-going edge or there is a vertex with out-degree
at least  in the path from  to , then
a cycle going through   in  determines  a non-sink cycle on the corresponding flat machine.



Once the set   has been computed, the algorithm sets  for all
 and then it performs the successive step considering only the remaining nodes.

For each  and each
mapping  , a dag  is constructed with the
nodes  such that  , the boxes  and the new vertices  , for ,
 such that  both
 and  satisfy  and do not belong to , and with
the exception that the sink cycles are substituted
by a single vertex. The edges in    are those of  .



\ignore{
If , we inductively assume that for   and
for all the nodes   of ,
for a mapping ,
 if  satisfies  and

for a mapping ,,
the maximum value  in 
such that  satisfies  has been determined.}

 The algorithm
labels the vertices of ,  starting from  the leaves,   as follows.


\begin{itemize}
\item
  is labeled by ,
\item
if  in  is not a box  and
 has successors , labeled by , then  is labeled by
 ;
\item
for a box , such that , let  be the mapping  such that   if 
is labeled by , for .
If   has been labeled by  in the dag    then  is labeled  as well
(observe that  the labeling of  in    has already been determined,  since ).
\end{itemize}

As said above,  new machines   have been constructed as copies of  , by renaming its nodes and boxes.
Now, for each , the algorithm sets  if  is labeled by  in .


Finally, the expansion mapping for  is defined as follows: if  then 
now expands into , where  is such that    for  which has been labeled by  in
.






Finally, for the case of a subformula , for , the algorithm
behaves in a similar way.
It first determines the nodes of  which satisfy
  and then it
 determines, for  each node , whether  satisfies ,
with an   approach suggested by the following claim.

\noindent{\bf Claim 2.}
Consider  the graph induced by the states of  where    holds,
and by deleting the edges outgoing from states
where  does not hold.
Then, given a state ,    iff in this graph
either there is a \emph{non-sink-cycle} reachable from , or
there are  pairwise distinct finite paths connecting  to
states where   holds.

Thus, the main difference with respect to the steps described above, is in the definition of
the graphs  and  since they now do not have edges  outgoing from states
where  does not hold, in accordance to the Claim 2.
We will omit further details.



Now we can state the first main result,
where  is  the number of the boolean and temporal operators in  ,
  is the maximum number of exit
nodes of  and  is the maximal constant occurring in a graded modalities of .


\begin{theorem}\label{theo:ghsmMc}
The graded-\ctl\ model-checking of an \HSM\  can be solved in .
\end{theorem}
\begin{proof}
The algorithm sketched above considers the subformulas  of , and,
for each node  in ,   sets  if  satisfies .
For , with , and , the correctness of the algorithm is rather immediate,
while if either   or ,
the correctness of the  algorithm mainly relies on the given claims.
For sake of brevity, we omit here the proof of the claims.

The crucial point is to prove that the algorithm
detects all the nodes  in a machine  such that
 a non-sink cycle is reached from   along a path  including only nodes satisfying .
 Let  be a node in . If there is a  non-sink cycle  reachable
from  in  ,
including only nodes in the set  of nodes satisfying , then 
and  the algorithm sets .
Now suppose that there are boxes  and that a  non-sink cycle is reachable from  in
 (again including only nodes in ) and suppose also that no non-sink cycles are reachable from
, for . This implies that
there is ,
and a  non-sink cycle  reachable from  in  ,
and
there are  
 such that, for ,
\begin{itemize}
\item

\item
  is reachable from , in ,
\item
 is reachable from , in 

\end{itemize}
In this case the algorithm
sets .
Moreover, in  the new \HSM\, each  will expand in a
copy  of ,
where  is such that . And thus, called  the copy of
 in  in ,  the algorithm sets 
Similarly, the algorithm detects all the nodes  in  such that  paths  start from
  ending
in sink cycles including only nodes in .
To state the complexity of the algorithm, observe that, while processing a subformula
, with 
and  , the algorithm creates several copies of each
machine ,
 denoted  where  . Thus the size of the
current \HSM\ grows for a factor not exceeding  , where   is the maximum number of exit
nodes of  and  is the maximal constant occurring in a graded modalities of .
Since, for each  operator in , the time spent by  the algorithm is linear in the size of the current
\HSM, than the overall running time is .
\end{proof}
Let us remark that, although the multiple copies created by the given algorithm can be seen
as a  step towards the flattening of
the input \HSM, the resulting structure is in general much smaller than the corresponding flat Kripke structure.
To solve the graded-\ctl\ model-checking for \VHSM\ we show now how to reduce it to the model-checking
problem for \HSM.
Let   be an  \VHSM\ and let  be a graded-\ctl\ formula.
Let  be the set of atomic propositions that occur
in . The first step of our algorithm consists of constructing
an \HSM\  such that  is isomorphic to .
Let 
be a bijection such that
 whenever
. Clearly,  maps   into a strictly
increasing sequence of consecutive positive integers starting from .
For a machine
,  and
,
define  as the machine 
where:
\begin{itemize}
\item , and ;
\item  if  is a \nnode\ and
      , otherwise;
\item  if  is a \nnode\ and
      , otherwise;
\item .
\end{itemize}
Let . We define  be the tuple of
machines 
such that for ,  where .
From the definition of  it is simple to verify that 
is an \HSM\ and  is .
Moreover,  and  coincide,
up to a renaming of the states.
Thus, from Theorem~\ref{theo:ghsmMc}, we have the following second main result.
\begin{theorem}\label{theo:gshsmMc}
The graded \ctl\ model checking of an \VHSM\ can be solved in
 time.
\end{theorem}

\section{Conclusions}\label{sec:Conclusions}
In this paper we have proposed the use of graded-CTL specifications to model-check
hierarchical state machines. We think that the added power in the specification formalism can be fruitfully
exploited in the simulation and testing community to get more meaningful test benches to
perform simulation of more and more complex systems.
We have given algorithms for checking classical \HSM s and so-called \VHSM s.
Let us observe that the alternative approach of model-checking the
fully expanded flat structure
has in general a worse performance because of the exponential gap between an \HSM\ and its corresponding
flat structure. In fact the gain in size of the hierarchical model, is in practice
much greater than the extra exponential factor paid, which depends on the size of (the formula for)
the spe\-ci\-fication, usually quite small.
One last consideration is that we have considered only sequential hierarchical finite state
machines (as an abstraction of the DEVS model).
It is a standard approach, when model checking concurrent systems, to first sequentialize
the model of the SUT (possibly on-the-fly) and then check it with model checking algorithms
for sequential models.
Moreover, the cost of considering
parallel and communicating machines would lead to a double exponential blow-up, the so-called
state explosion problem.
\\\noindent{\bf Acknowledgements.} We thank the anonymous referees for their valuable
comments.
\bibliographystyle{plain}
\begin{thebibliography}{10}

\bibitem{AY01}
R.~Alur and M.~Yannakakis.
\newblock Model checking of hierarchical state machines.
\newblock {\em ACM Trans. Program. Lang. Syst.}, 23(3):273--303, 2001.

\bibitem{AB99}
P.~Ammann and P.~E. Black.
\newblock Abstracting formal specifications to generate software tests via
  model checking.
\newblock In {\em DASC 99}, page 10.A.6. IEEE, 1999.

\bibitem{ABM98}
P.~Ammann, P.~E. Black, and W.~Majurski.
\newblock Using model checking to generate tests from specifications.
\newblock In {\em ICFEM}, pages 46--, 1998.

\bibitem{A95}
L.~Apfelbaum.
\newblock Automated functional test generation.
\newblock In {\em AUTOTESTCON '95.}, pages 101 --107, August 1995.

\bibitem{CE82}
E.M. Clarke and E.A. Emerson.
\newblock Using branching time temporal logic to synthesize synchronization
  skeletons.
\newblock {\em Science of Computer Programming}, 2:241--266, 1982.

\bibitem{CGP99}
E.M. Clarke, O.~Grumberg, and D.~Peled.
\newblock {\em Model Checking}.
\newblock The MIT Press, 1999.

\bibitem{DHRPV07}
M.~B. Dwyer, J.~Hatcliff, R., C.~S. Pasareanu, and W.~Visser.
\newblock Formal software analysis emerging trends in software model checking.
\newblock In {\em FOSE}, pages 120--136, 2007.

\bibitem{FMNPS10}
A.~Ferrante, M.~Memoli, M.~Napoli, M.~Parente, and F.~Sorrentino.
\newblock A {NuSMV} extension for graded-{CTL} model checking.
\newblock In {\em CAV 2010}, pages 670--673, 2010.

\bibitem{FNP08}
A.~Ferrante, M.~Napoli, and M.~Parente.
\newblock {CTL} model-checking with graded quantifiers.
\newblock In {\em Proc. of ATVA '08}, volume 5311 of {\em Lect. Notes in Comp.
  Sci.}, pages 18--32, 2008.

\bibitem{FWA09}
Gordon Fraser, Franz Wotawa, and Paul Ammann.
\newblock Testing with model checkers: a survey.
\newblock {\em Softw. Test., Verif. Reliab.}, 19(3):215--261, 2009.

\bibitem{GH99}
A.~Gargantini and C.~L. Heitmeyer.
\newblock Using model checking to generate tests from requirements
  specifications.
\newblock In {\em ESEC / SIGSOFT FSE}, pages 146--162, 1999.

\bibitem{H87}
D.~Harel.
\newblock Statecharts: A visual formalism for complex systems.
\newblock {\em Sience of Computer Programming}, 8:231--274, 1987.

\bibitem{LNPP08}
S.~{La Torre}, M.~Napoli, M.~Parente, and G.~Parlato.
\newblock Verification of scope-dependent hierarchical state machines.
\newblock {\em Information and Computation}, 206(9-10):1161--1177, 2008. A
  preliminary version appeared in ICALP 2003, pp 776-789.

\bibitem{PY}
M.~Young M.~Pezze.
\newblock {\em Software Testing and Analysis: Process, Principles and
  Techniques}.
\newblock Wiley, 2007.

\bibitem{WASF07}
D.~Wijesekera, P.~Ammann, L.~Sun, and G.~Fraser.
\newblock Relating counterexamples to test cases in {CTL} model checking
  specifications.
\newblock In {\em A-MOST '07}, pages 75--84. ACM, 2007.

\bibitem{Z76}
Bernard~P. Zeigler.
\newblock {\em Theory of Modeling and Simulation}.
\newblock John Wiley, 1976.

\end{thebibliography}

\end{document}
