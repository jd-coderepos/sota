


\documentclass{IEEEtran}



\usepackage{amsmath} 
\usepackage{amssymb} 
\usepackage{amsthm} 
\usepackage{bbm}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage{mathrsfs}



\usepackage{graphicx,psfrag, color}
\graphicspath{Figures/}
\usepackage{tikz}


\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{trule}{Rule}
\newtheorem{corollary}{Corollary}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{assumption}{Assumption}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}
\newtheorem{problem}{Problem}












\newcommand{\fromto}[2]{\{#1,\dots, #2\}}
    \newcommand{\until}[1]{\{1,\dots, #1\}}
    \newcommand{\subscr}[2]{#1_{\textup{#2}}}
    \newcommand{\supscr}[2]{#1^{\textup{#2}}}
    \newcommand{\setdef}[2]{\{#1 \, : \; #2\}}
    \newcommand{\map}[3]{#1: #2 \rightarrow #3}
    \renewcommand{\l}{\left}
    \renewcommand{\r}{\right}

\def\startmodif{\color{blue}}
\def\stopmodif{\color{black}}


\newcommand{\todo}[1]{\par\noindent{\color{red}\raggedright\textsc{#1}\par\marginpar{\Large}}}
    \newcommand{\margin}[1]{\marginpar{\footnotesize \color{blue} #1}}
    \newcommand{\pfmargin}[1]{\marginpar{\footnotesize \color{blue} from PF: #1}}

    \newcommand{\blue}{\color{blue}}
    \newcommand{\red}{\color{red}}
    \newcommand{\rmv}[1]{{\color{yellow}removed: #1}}
    \newcommand{\add}[1]{{\color{blue} #1}}


\newcommand{\complex}{\mathbb{C}}
\newcommand{\real}{\mathbb{R}}
\newcommand{\realpositive}{\mathbb{R}_{>0}}
\newcommand{\realnonnegative}{\mathbb{R}_{\geq0}}
\renewcommand{\natural}{\mathbb{N}}
\newcommand{\integer}{\mathbb{Z}}
\newcommand{\integernonnegative}{\mathbb{Z}_{\ge 0}}

\newcommand{\R}{\mathbb{R}} \newcommand{\N}{\mathbb{N}}  \newcommand{\Z}{\mathbb{Z}}  

\newcommand{\G}{\mathcal{G}} \newcommand{\V}{\mathcal{V}} \newcommand{\E}{\mathcal{E}} 

\newcommand{\neigh}{ \mathcal{N}} 	\newcommand{\card}[1]{|#1|}  	

\def\Exp{\mathbb{E}}
\def\Prob{\mathbb{P}}


\newcommand{\ave}{\textup{ave}}
\newcommand{\pgr}{{\subscr{x}{pgr}^{\star}}} \newcommand{\loc}{{\subscr{x}{loc}^{\star}}} \newcommand{\op}{{\subscr{x}{opd}^{\star}}} 

\newcommand{\e}{\textup{e}} 

\newcommand{\1}{\mathbf{1}} \newcommand{\ind}{\mathds{1}} 

\newcommand{\diag}{\operatorname{diag}} 


\newcommand{\argmax}[1]{\underset{#1}{\mathrm{argmax\,}}}
\newcommand{\argmin}[1]{\underset{#1}{\mathrm{argmin\,}}}


\newcommand{\eps}{\varepsilon} 


\title{Ergodic Randomized Algorithms and Dynamics over Networks}\author{Chiara~Ravazzi\thanks{Chiara Ravazzi is with the Department of Electronics and Telecommunications (DET),
        Politecnico di Torino, Italy. E-mail: {chiara.ravazzi@polito.it}}, \and Paolo~Frasca\thanks{Paolo Frasca is with the Department of Applied Mathematics, University of Twente, The Netherlands. E-mail: {p.frasca@utwente.nl}},
\and Roberto~Tempo\thanks{Roberto~Tempo is with CNR-IEIIT, Politecnico di Torino, Italy. E-mail: roberto.tempo@polito.it} and
\and Hideaki~Ishii\thanks{Hideaki~Ishii is with the Department of Computational Intelligence and Systems Science,        Tokyo Institute of Technology, Japan. E-mail:        {ishii@dis.titech.ac.jp}} 
}

\date{\today}

\begin{document}

\maketitle
\begin{abstract}
Algorithms and dynamics over networks often involve randomization, and 
randomization may result in oscillating dynamics which fail to converge in a deterministic sense. In this paper, we observe this undesired feature in three applications, in which the  dynamics is the randomized asynchronous counterpart of a well-behaved synchronous one.
These three applications are network localization, PageRank computation, and opinion dynamics.
Motivated by their formal similarity, we show the following general fact, under the assumptions of independence across time and linearities of the updates: if the expected dynamics is stable and converges to the same limit of the original synchronous dynamics, then the oscillations are ergodic and the desired limit can be locally recovered via time-averaging.
\end{abstract}



\section{Introduction}

Randomization has proved to be a useful ingredient for effective algorithms in control and optimization, as reviewed in~\cite{RT-GC-FD:13}.
In network dynamics, randomization is specially natural, either by the uncertain nature of the network at hand, or by design aimed at improving performance and robustness.

In this work, we focus on a class of randomized affine dynamics which do not possess equilibria, but are stable on average. This stability property ensures that the dynamics, although it features persistent random oscillations, has an ergodic behavior. 
This ergodicity result, which we prove by classical facts of probability theory, can be readily applied to several network-based algorithms, in which randomization apparently prevents convergence.
As a consequence, the desired convergence property --holding in expectation-- can be recovered by each node through a process of time-averaging, which can be performed locally and, in some cases, without even access to a common clock.



In the examples considered in this paper, nodes interact in randomly chosen pairs, following a ``gossip'' approach which has been popularized in the field of control by~\cite{SB-AG-BP-DS:06} and has been followed in several papers. 
There has been a wide range of applications since then. Indeed, many network algorithms can be randomized in such a way that the randomized dynamics converges (almost surely) to the same limit of the synchronous dynamics.
Notable examples include consensus algorithms, studied in many papers as~\cite{FF-SZ:08a,ATS-AJ:08}, and other algorithms for estimation and classification~\cite{AC-FF-LS-SZ:10} and for optimal deployment of robotic networks~\cite{FB-RC-PF:08u}.
Nevertheless, examples of randomized algorithms which do not converge also have recently appeared in the literature. Such algorithms require some sort of additional ``smoothing'' operation in order to converge: in our approach, this goal is achieved by time-averaging.


A prime example we consider involves the problem of distributed estimation from relative measurements, which has applications from self-localization in robotic networks to synchronization in networks of clocks and to phase estimation in power grids. This problem was first introduced in a least-squares formulation in the context of clock synchronization~\cite{AG-PRK:06a} and then studied in much detail in \cite{PB-JPH:07,PB-JPH:08,PB-JPH:09,SB-SDF-LS-DV:10,WSR-PF-FF:12}, where both fundamental performance limitations and distributed algorithms have been presented. More recently, randomized algorithms for its solution have been proposed by several researchers \cite{NMF-AZ:12,RC-AC-LS-MT:13}. Regarding this problem, our contribution includes a randomized asynchronous algorithm, in which nodes update in pairs in a {\em gossip} fashion: its novelty is further discussed in Section~\ref{sect:random-localization}. A related but different randomized algorithm for least-squares estimation has been recently proposed in~\cite{KY-SS-LQ:14}.

A second example is PageRank computation, which has attracted much attention in recent years for the importance of its applications~\cite{SB-LP:98,KB-TL:06,ANL-CDM:06} and for its similarities with the consensus problem, as illustrated in~\cite{HI-RT:10}. Randomized algorithms for PageRank computation have been studied in a series of papers, including~\cite{HI-RT:10,Nazin:2011:RAD:1960870.1960904,HI-RT-EWB:12b,DBLP:journals/corr/abs-1305-3178}.
Other recent references on PageRank are listed in \cite{journals/corr/abs-1203-6606,fercoq:hal-00782749, Blondel13}.
Our contribution provides a general convergence result for randomized algorithms, which we apply to a novel pair-wise {\it gossip} algorithm in Section~\ref{sect:random-pagerank}.

A third example comes from social sciences, where there has been long-time interest in the mechanisms of opinion evolutions. It comes out that opinion dynamics models, where agents have some degree of obstinacy and interactions are randomized, gives rise to ergodic oscillations. This observation has first been made in~\cite{DA-GC-FF-AO:11} and here we extend it in connection with the Friedkin and Johnsen's model~\cite{NEF-ECJ:99} from social sciences. We propose in Section~\ref{sect:random-friedkin} a {\it gossip} mechanism of update for the opinions, which allows us to interpret the classical opinion dynamics --which makes simplistic assumptions on the communication process among individuals-- as the ``average'' evolution of our randomized model. This observation answers an open question on modeling the communication process which was raised in the original paper~\cite{NEF-ECJ:99}.

Preliminary versions of part of our results have been reported in the proceedings of technical conferences as~\cite{CR-PF-HI-RT:13a,CR-PF-RT-HI:13b}, regarding relative localization, and as~\cite{PF-CR-RT-HI:13c}, regarding opinion dynamics. 
The current presentation incorporates and builds upon the previous ones. Additionally, it includes the case study of PageRank computation, and most importantly embeds them into a comprehensive framework which is suitable for the study of other applications. 



\subsection{Paper outline} In Section~\ref{sect:synchro} we study deterministic synchronous dynamics, presenting the three examples of relative localization, PageRank computation, and opinion dynamics. These dynamics are then translated into corresponding randomized asynchronous dynamics in Section~\ref{sect:randomized}. Additional remarks and research outlooks are given in a concise Section~\ref{sect:conclusion}, and an Appendix contains the technical derivation of our main result.



\subsection{Notation and preliminaries}
Throughout this paper, we use the following notation. 
Real and nonnegative integer numbers are denoted by  and , respectively. 
The symbol  denotes either the cardinality of a set or the absolute value of a real number.
The symbol  is the vector with the -th entry equal to 1 and all the other elements equal to , and we write  for the vector with all entries equal to 1. A vector  is stochastic if its entries are nonnegative and .
A matrix  is row-stochastic (column-stochastic) when its entries are nonnegative and  (). A matrix is doubly stochastic when it is both row and column-stochastic. A matrix  is said to be Schur stable if the absolute value of all its eigenvalues is smaller than 1. A graph is a pair , where  is the set of nodes and  is the set of edges. 
To avoid trivialities, we implicitly assume that graphs have at least three nodes, i.e., .
A graph  is called strongly connected if there is a path from each vertex in the graph to every other vertex.
To any matrix  with non-negative entries, we can associate a graph  by putting  if and only if . The matrix  is said to be adapted to graph  if .


 

\section{Synchronous affine dynamics over networks}\label{sect:synchro}
Consider the affine dynamics representing  a time-invariant discrete-time dynamical system with state , 

with  and constant input . 




\begin{proposition}
\label{prop:synch-converge}
If  is Schur stable, then the dynamics in~\eqref{eq:synchro-algo} converges to 

for any initial conditions .
\end{proposition}
\begin{IEEEproof}
Equation~\eqref{eq:synchro-algo} implies that
 Since all the eigenvalues of  lie in the open unit disk, we have
  
and 
 
These limits imply that  is the convergence value. 
\end{IEEEproof}

More specifically, in this paper we study affine dynamics over a certain network, described by a graph  with  nodes, that is, such that {\em the matrix  is adapted to the graph .}
In the rest of this section, we review the three applications of affine dynamics over networks which we have mentioned in the introduction. Even though these applications are quite diverse, we show that the algorithms for their solutions can be represented by the affine dynamics~\eqref{eq:synchro-algo}, provided suitable manipulations are performed.

\subsection{Sensor localization in wireless networks}
\label{es1}
In sensor localization in wireless networks, we seek to estimate the relative position of sensors using noisy relative measurements. We formulate the problem using an oriented graph\footnote{
An oriented graph  is a graph such that  only if .  is said to be weakly connected if the graph  where (h,k)\in \E(k,h)\in \E  has a path which connects every pair of nodes.} 
 .
Each node  in  has to estimate its own variable 
, knowing only noisy measurements of some difference with neighboring edges

where  is additive noise.
The graph topology is encoded in the incidence matrix  defined by 
 for every . We can collect all the measurements and variables in vectors  and , so that 

where . 
A least-squares approach can be used to determine the best estimate of the state  based on the measurements . That is, we define the unconstrained quadratic optimization problem

where  denotes the Euclidean norm.
The solution of this problem is summarized in the following standard result.
\begin{lemma}[Least-squares localization]
\label{lemma:centralized-LS} 
Given a weakly connected oriented graph
 with incidence matrix , let  be the set of solutions of \eqref{LS} and let  be the Laplacian. The following facts hold:
\begin{enumerate}
\item  if and only if ;
\item there exists a unique minimizer  such that ;
\item ,
where  is the pseudoinverse matrix.
\end{enumerate}
\end{lemma}

We note that the optimal least-squares solution  is the minimum-norm element of the affine space of solutions of~\eqref{LS} and  for any scalar~.
As shown in Lemma~\ref{lemma:centralized-LS}, the solution to the least-squares relative localization problem \eqref{LS} is explicitly known. Furthermore, it can be easily computed by an iterative gradient algorithm.
Given a parameter  and the initial condition , we let 

where the matrix  is doubly stochastic. For this reason, it holds true that

for all .
Defining , we have that 
because  and moreover

because  and 
Then, equation~\eqref{grad_des} can be rewritten as

and falls in the class of affine dynamics
(\ref{eq:synchro-algo}) taking

The convergence properties of this algorithm are summarized in the following simple result (also available as~\cite[Proposition~1]{WSR-PF-FF:12}), where we let  be the maximum degree given by .
\begin{proposition}[Convergence of gradient descent algorithm]
Assume that the graph  is weakly connected. Then, the gradient descent algorithm in~\eqref{grad_des} with  converges to the optimal least-squares solution  if . \end{proposition}

\begin{IEEEproof}
By Gershgorin Circle Theorem and~\cite[Theorem~1.37]{FB-JC-SM:09}, the eigenvalues of  satisfy . 
Then, it is clear that the spectral radius of  is equal to . 
By the assumption on , we thus conclude that  is Schur stable, and convergence to the least-squares solution immediately follows by Proposition~\ref{prop:synch-converge} and Lemma~\ref{lemma:centralized-LS}.
\end{IEEEproof}


\subsection{PageRank computation in Google}

In this application, we study a network consisting of web pages~\cite{SB-LP:98}. This network can be represented by a graph , where the set of vertices correspond to the web pages and edges represent the links between the pages, i.e., the edge , if page  has an outgoing link to page , or in other words, page  has
an incoming link from page . 

The goal of the PageRank algorithm is to provide a measure of relevance of each web page: the PageRank value of a page is a real number in , which is defined next.
Let us denote  and , for each node , and  the matrix such that 

Let  and recall , and define 
 
The PageRank of the graph  is the vector  such that  and .

Given the initial condition such that  (i.e., it is a stochastic vector), the PageRank vector can be computed through the recursion

In this case, we observe that the PageRank vector can be represented in terms of the affine dynamics (\ref{eq:synchro-algo})
simply taking 


Before showing the convergence of this recursion, which is studied in Proposition \ref{prop:convPR}, we present a simple technical lemma. 
Although the result has already been used in the literature (e.g. in~\cite{DA-GC-FF-AO:11}), we include a short proof for completeness. 
We recall that a matrix is said to be substochastic if it is nonnegative and the entries on each of its rows (or columns) sum up to no more than one. Moreover, every node corresponding to a row (or column) which sums to less than one is said to be a {\em deficiency} node. 

\begin{lemma}\label{lemma:substoch_stab}
Consider a  substochastic matrix . If in the graph associated to  there is a path from every node to a deficiency node, then  is Schur stable.
\end{lemma}

\begin{IEEEproof}
First note that   is substochastic for all .  More precisely,  if we let  to be the set of deficiency nodes of ,  then  for every positive integer . Moreover, there exists  such that 
, that is all nodes for  are deficiency nodes.
Stability then follows by Gershgorin Circle Theorem.
\end{IEEEproof}

\begin{proposition}[Convergence of PageRank computation]\label{prop:convPR}
For any initial condition  such that , the sequence in \eqref{eq:pow_meth} converges to

\end{proposition}

\begin{IEEEproof}
Since  is column-stochastic and  then  is a substochastic matrix and every node is a deficiency node. From Lemma~\ref{lemma:substoch_stab}, the matrix  is Schur stable and from Proposition~\ref{prop:synch-converge} the dynamics in \eqref{eq:pow_meth} converges to .
Moreover, , from which we conclude .
\end{IEEEproof}

\subsection{Opinion dynamics in social networks}
In this application, we study a classical model introduced in~\cite{NEF-ECJ:99} to describe the effect of social influence and prejudices in the evolution of opinions in a population in the presence of the so-called stubborn agents. We briefly review and cast this model into the general framework of affine dynamics defined in \eqref{eq:synchro-algo}.

We consider a finite population  of interacting agents, whose {\it social network} of potential interactions is encoded by a graph , endowed with a self-loop   at every node. At time , each agent  holds a {\it belief or opinion} about an underlying state of the world. We denote the vector of beliefs as . An edge  means that agent  may directly influence the opinion of agent .

Let  be a nonnegative matrix which defines the strength of the interactions ( if ) and  be a diagonal matrix describing how sensitive each agent is to the opinions of the others based on interpersonal influences. We assume that  is row-stochastic, i.e.,  and we set , where  collects the self-weights given by the agents.
The dynamics of opinions  proposed in \cite{NEF-ECJ:99} is 

where  and . The vector , which corresponds to the individuals' preconceived opinions, also appears as an input at every time step. This model falls under the class of 
affine dynamics (\ref{eq:synchro-algo}) simply taking 

As a consequence of~\eqref{eq:friedkin} and Proposition \ref{prop:synch-converge}, the opinion profile at time  is equal to 
 
The limit behavior of the opinions is described in the following 
convergence result.

\begin{proposition}[Convergence of opinion dynamics]
\label{prop:convergence-friedkin}
Assume that in the graph
associated to  for any node  there exists a path from
 to a node  such that  . Then, the opinions converge to

\end{proposition}

\begin{IEEEproof}
Due to the assumption,  is a substochastic matrix. Then,  is substochastic also, and 
Schur stable by Lemma~\ref{lemma:substoch_stab}. Thus, the dynamics in~\eqref{eq:friedkin} converges to . 
\end{IEEEproof}

We remark that our assumption on the existence of the path implies that each agent is influenced by at least one stubborn agent.
As shown in the proof, this is sufficient to guarantee the stability of the opinion dynamics.
In practice, it is reasonable to think that most agents in a social network will have some (positive) level of obstinacy .



\section{Ergodic randomized dynamics over networks}\label{sect:randomized}



In this section, we first present our main result about ergodicity properties of randomized dynamics over networks. Our result regards suitable randomized versions of the dynamics in \eqref{eq:synchro-algo}. 
Subsequently, we show applications of this result to localization of sensor networks, PageRank computation, and opinion dynamics in social networks, according to the problem statements made above.

We consider a sequence of independent identically distributed (i.i.d.) random variables  taking values in a finite set .
Given a realization , , we associate to it a matrix  and an input vector , obtaining a time-varying discrete-time dynamical system of the form

with initial condition .
We observe that the state  is a Markov process because, given the current position of the chain, the conditional distribution of the future values does not depend on the past values.

It may happen that the dynamics~\eqref{eq:asynchro-algo} oscillates persistently and fails to converge in a deterministic sense: this behavior is  apparent in the examples we are interested in.
In view of this fact, we want to give simple conditions which guarantee other types of probabilistic convergence. To this end, we provide some classical probabilistic convergence notions \cite{VB:95}.

The process  is {\em ergodic} if there exists a random variable  such that almost surely
 
The closely related definition of {\em{mean-square ergodicity}} instead requires  
The time-average in~\eqref{eq:ergodicity} is called Ces\'aro average or Polyak average in some contexts~\cite{BTP-ABJ:92}.
In what follows, we mostly focus on almost-sure ergodicity, although also mean-square ergodicity is mentioned. Indeed, it is often possible to deduce mean-square convergence from almost sure convergence: for instance, this implication is true for a uniformly bounded sequence of random variables, by the Dominated Convergence Theorem~\cite{VB:95}.
Our main analysis tool is the following result.

\begin{theorem}[Ergodicity of affine dynamics]
\label{thm:ergodic}
Consider the random process  defined in~(\ref{eq:asynchro-algo}), where  and  are i.i.d.\ and have finite first moments. If there exists  such that 
 where  and  are given in Proposition \ref{prop:synch-converge}, then
\begin{enumerate}
\item  converges in distribution to a random variable , and the distribution of  is the unique invariant distribution for \eqref{eq:asynchro-algo};
\item the process is {\em ergodic};
\item the limit random variable satisfies
 
\end{enumerate}
\end{theorem}
The proof of Theorem~\ref{thm:ergodic} is technical and is postponed to the Appendix. We instead make the following first-order analysis of~\eqref{eq:asynchro-algo} under the assumptions of the Theorem.
Since  is Schur stable in Proposition~\ref{prop:synch-converge}, so is  under the hypothesis~\eqref{eq:hyp}, and the expected dynamics of the process~\eqref{eq:asynchro-algo} can be interpreted as a ``lazy'' (slowed down) version of the synchronous dynamics~\eqref{eq:synchro-algo} associated to the matrix . Indeed, 
 
from which
. 

The following refinement of Theorem~\ref{thm:ergodic} --proved in Appendix~\ref{sec:proofB}-- is specially useful to our purposes.
\begin{corollary}[Ergodicity of affine dynamics on random subsequences]
\label{cor:ergodic2}
Consider the random process  defined in~(\ref{eq:asynchro-algo}), where  and  are i.i.d.\ and have finite first moments. 
Let  be an i.i.d. random sequence such that, for all ,  is independent of  for all  and   with positive probability.
If there exists  such that 
 where  and  are given in Proposition~\ref{prop:synch-converge}, then almost surely

\end{corollary}

In the rest of this section, Theorem~\ref{thm:ergodic} and Corollary~\ref{cor:ergodic2} will be applied to specific dynamics in sensor localization, PageRank computation, and opinion dynamics. 


\subsection{Sensor localization in wireless networks (cont'd)}\label{sect:random-localization}

This section is devoted to describe a randomized algorithm, which was proposed in~\cite{CR-PF-HI-RT:13a} to solve the sensor localization problem.
For each node , the algorithm involves a triple of states , which depend on a discrete time index . These three variables play the following roles:  is the ``raw'' estimate of  obtained by  at time  through communications with its neighbors,  counts the number of updates performed by  up to time , and  is the ``smoothed'' estimate obtained through time-averaging.
The algorithm is defined by choosing a scalar parameter  and a sequence of random variables  taking values in . 
The state variables are initialized as  for all , and at each 
time , provided that , 
the states are updated according to the following recursions, namely the raw estimates as
 \label{dyn2a}
\begin{split}
x_i(k+1)&=(1-\gamma)x_i(k)+ \gamma x_j(k)+ \gamma b_{(i,j)}\\
x_j(k+1)&=(1-\gamma)x_j(k)+ \gamma x_i(k)-\gamma b_{(i,j)}\\
x_{\ell}(k+1)&=x_{\ell}(k)\qquad \text{if }\ell\notin\{i,j\};\\
\end{split}

\begin{split}
\kappa_i(k+1)&=\kappa_i(k)+1\\
\kappa_j(k+1)&=\kappa_j(k)+1\\
\kappa_{\ell}(k+1)&=\kappa_{\ell}(k)\qquad \text{if }\ell\notin\{i,j\};\\
\end{split}

\begin{split}\label{dyn2b}
\widetilde x_i(k+1)&=\frac1{\kappa_i(k+1)}\big( \kappa_i(k) \widetilde x_i(k) + x_i(k+1)\big)\\
\widetilde x_j(k+1)&=\frac1{\kappa_j(k+1)}\big( \kappa_j(k) \widetilde x_j(k) + x_j(k+1)\big)\\
\widetilde x_{\ell}(k+1)&=\widetilde x_{\ell}(k)\qquad \text{if }\ell\notin\{i,j\}.
\end{split}

Next, we assume the sequence  to be i.i.d., and its probability distribution to be {\it uniform}, i.e.,

Note that this choice is made for simplicity, but this approach may easily accommodate other distributions if required by specific applications.

\begin{remark}[Local and global clocks]
It should be noted that the time index  counts the number of updates which have occurred in the network, whereas for each  the variable  is the number of updates involving  up to the current time. Hence,  is a local variable which is inherently known to agent , even in case a common clock  is unavailable.
Therefore, this algorithm is {\it totally asynchronous} and {\it fully distributed}, in the sense that the updates, including the time-averaging process, do not require the nodes to be aware of a common clock. This feature is especially attractive if the algorithm has to be applied to clock synchronization problems.
\end{remark}

\begin{figure}[h]
\begin{center}
\psfrag{x2}[][][1][-90]{}
\psfrag{x4}[][][1][-90]{}
 \psfrag{k}{}
\includegraphics[width=0.85\columnwidth]{Figures/Loc1.eps}
\includegraphics[width=0.85\columnwidth]{Figures/Loc2.eps}
\caption{Dynamics~\eqref{dyn2} running on a complete graph with  nodes, with .}
\label{fig:simul-complete}
\end{center}
\end{figure}

The dynamics in \eqref{dyn2a} oscillates persistently and fails to converge in a deterministic sense, as shown in Figure~\ref{fig:simul-complete} for a complete graph\footnote{A 
complete graph is
an graph in which every pair of distinct vertices is connected by an edge.}.
However, the oscillations asymptotically concentrate around the solution of the least-squares problem, as it is formally stated in the following result, which shows that the sample dynamics is well-represented by the average one. This 
indicates that  is ``the right variable'' to approximate the optimal estimate  because the process  is ergodic. In the proof of the theorem, we show that the dynamics in equation (\ref{dyn2a})
can be written in terms of the more general process (\ref{eq:asynchro-algo}). 

\begin{theorem}[Ergodicity of sensor localization]
\label{theorem:convforlocal}
The dynamics in~\eqref{dyn2} with uniform selection \eqref{eq:uniform} is such that 
almost surely. 
\end{theorem}
\begin{IEEEproof}
We rewrite the dynamics of~\eqref{dyn2a} as

and, provided , we define
 
and
 
where the vector  is defined in the preliminaries.
We note that  for all  the matrix  is doubly stochastic and the sum of the elements in  is zero:
in particular, given , then  for each .
These observations further imply that the dynamics of  is equivalently described by the iteration

where  as previously in Subsection~\ref{es1}.
Letting , the dynamics of the algorithm is cast in the form of \eqref{eq:asynchro-algo}.
Next, using the uniform distribution~\eqref{eq:uniform}, we compute

and observe that  satisfies ergodicity condition in Theorem~\ref{thm:ergodic} with  and  defined in~\eqref{Pu-def-localization},  and . 
If we define, for all  and all , 
then

and

Being  an i.i.d. random sequence, by Corollary~\ref{cor:ergodic2} we conclude our argument.
\end{IEEEproof}

\begin{remark}[Noise-free measurements]\label{rem:noise-free-localization}
It is easy to see that if measurements have no noise (), then  itself converges to the exact solution , and moreover convergence is exponentially fast. This fact is also proved in~\cite{NMF-AZ:12}.
\end{remark}

\begin{remark}[Mean-square ergodicity]
It is also true that  converges to  in the mean-square sense. 
A proof can be obtained with similar arguments as in~\cite{CR-PF-HI-RT:13a} and is not detailed here.
\end{remark}

\subsection{PageRank computation in Google (cont'd)}\label{sect:random-pagerank}




We now describe a new example of an ``edge-based'' randomized gossip algorithm. Its motivation comes from the interest in reducing the communication effort required by the network. Being only one edge activated at each time, such effort is minimal. 

Each node  holds a couple of states . For every time step  an edge  is sampled from a uniform distribution over  (note that sampling is independent at each time ).
Then, the states are updated as follows:
 
x_i(k+1)=&(1-r) \left(1-\frac1{n_i}\right)\, x_i(k)+ \frac{r}{n}\\
x_j(k+1)=&(1-r) \left(x_j(k)+\frac1{n_i} x_i(k)\right)+ \frac{r}{n}\\
x_h(k+1)=&(1-r) \, x_h(k)+ \frac{r}{n} \qquad \text{if}\; h\neq i,j \label{eq:gossip-pr1-3}

and

where  is a design parameter to be determined.
The update in \eqref{eq:gossip-pr1} can also be formally rewritten in vector-wise form as

where 
 
Here  and  are random matrices which are determined by the choice of 

Then,  is uniformly distributed over the set of matrices .

\begin{remark}[Local and global clocks]
We note that, opposed to~\eqref{dyn2}, algorithm~\eqref{eq:gossip-pr1} does require the nodes to access the global time variable . The reason for this synchrony requirement comes from the need to preserve the stochasticity of the vector , which is guaranteed by~\eqref{eq:gossip-pr1-3}. We believe this is a reasonable assumption, because these algorithms are to be implemented on webpages or domain servers which are typically endowed with clocks.
\end{remark}

In the next result, we state convergence of this algorithm.
\begin{theorem}[Ergodic PageRank convergence]
\label{cor:pagerank}
Let us consider the dynamics~\eqref{eq:gossip-pr1}-\eqref{eq:gossip-pr2} with 
 
where  is a stochastic vector. Then, the
sequence  
is such that 

almost surely. 
\end{theorem}

\begin{IEEEproof}
For each , we have

It should be noted that, setting  and  and  as in~\eqref{Pu-def-pagerank},

and 
From Theorem~\ref{thm:ergodic} we conclude convergence almost surely. 
\end{IEEEproof}

This result can also be proved by techniques from stochastic approximation. Such techniques have already been effectively applied to specific algorithms for PageRank computation~\cite{DBLP:journals/corr/abs-1305-3178}. 

\begin{remark}[Mean-square ergodicity]\label{rem:ms-pgr}
Since  are stochastic vectors, they are uniformly bounded and by the Dominated Convergence Theorem we conclude the convergence in the mean-square sense. Mean-square ergodicity of randomized PageRank was already proved in~\cite{HI-RT-EWB-FD:09} under assumptions which are equivalent to those in Theorem~\ref{thm:ergodic}.
\end{remark}




\subsection{Opinion dynamics in social networks (cont'd)}
\label{sect:random-friedkin}
In this subsection, we introduce a randomized model of the communication process among the agents in the Friedkin and Johnsen's model presented above. As a result, we obtain a new class of randomized opinion dynamics.

The problem is now described.
Each agent  possesses an initial belief , as in the model~\eqref{eq:friedkin}. At each time  a link is randomly sampled from a uniform distribution over . If the edge  is selected at time , agent  meets agent  and updates its belief to a convex combination of its previous belief, the belief of , and its initial belief. Namely, 

where the weighting coefficients  and  are defined as 


where the matrices  and  are those in~\eqref{eq:friedkin} and . Recall that  by the presence of self-loops. 
It is immediate to observe that
(a)  for all ; (b)  is adapted to the graph ;
(c)  is row-stochastic; and (d) at all times the opinions of the agents are convex combinations of their initial prejudices.

We now study the convergence properties of the gossip opinion dynamics and we show that the opinions converge to the same value  given in Proposition~\ref{prop:convergence-friedkin}. 
In the proof of the result, we show that the dynamics in equation~\eqref{eq:gossip-friedkin}
can be written in terms of the more general process (\ref{eq:asynchro-algo}).

\begin{theorem}[Ergodic opinion dynamics]
\label{thm:gossip-opinions} 
Assume that in the graph
associated to W for any node  there exists a path from
 to a node  such that  .
Then, the dynamics~\eqref{eq:gossip-friedkin} is 
almost surely and mean-square ergodic, and the time-averaged opinions defined in \eqref{eq:ergodicity} converge to .
\end{theorem}
\begin{IEEEproof}
Provided the edge  is chosen at time , the dynamics~\eqref{eq:gossip-friedkin} can be rewritten in vector form as

If we define the matrices 

then the dynamics is 

Note that
the expressions in \eqref{eqn:H} and \eqref{eqn:Gamma} imply

where  and . Consequently, one can compute the generic entries of the expected matrix  as 
 if ,   and
 From these formulas, we conclude that  and .
Then, using~\eqref{Pu-def-opinions} the claim follows by Theorem~\ref{thm:ergodic} and Proposition~\ref{prop:convergence-friedkin}.
\end{IEEEproof}

\begin{remark}[Mean-square ergodicity]
Since the opinions are uniformly bounded, by the Dominated Convergence Theorem we  also conclude the convergence in the 
mean-square sense. Mean-square ergodicity is also proved in~\cite{PF-CR-RT-HI:13c} under assumptions which are equivalent to those in Theorem~\ref{thm:ergodic}.
\end{remark}
The ergodicity of the opinion dynamics is illustrated by the simulations in
Figure \ref{fig:simul-od}, which plots the state ) and the
corresponding time-averages, respectively.
\begin{figure}[t]
\begin{center}
\psfrag{x}[][][1][-90]{}
\psfrag{averaged}[][][1][-90]{}
 \psfrag{time}{}
\includegraphics[width=0.85\columnwidth]{Figures/Od1.eps}
\includegraphics[width=0.85\columnwidth]{Figures/Od2.eps}
\caption{Four-nodes social network from~\cite{NEF-ECJ:99}. The opinion process
 (top plot) oscillates persistently. As the belief process is ergodic, the time-averages  (bottom plot) converge, when time goes to
infinity, to  (marked by blue circles).}
\label{fig:simul-od}
\end{center}
\end{figure}

We notice that the dynamics~\eqref{eq:gossip-friedkin} assume the edges to be chosen for the update according to a uniform distribution. This choice is made for simplicity, but our analysis can easily be extended to consider more general or different distributions.


We now discuss the interpretation of our convergence theorem in the
context of opinion dynamics. The original model by Friedkin and Johnsen abstracts from a precise analysis of the communication process among the agents, and postulates synchronous rounds of interaction. In fact, the lack of a more precise model for inter-agent interactions is acknowledged in~\cite{NEF-ECJ:99} by saying that ``it is obvious that interpersonal influences do not occur in the simultaneous way that is assumed''.
Our gossip dynamics introduces a more realistic model of  the communication process among the agents: indeed the agents were allowed to discuss asynchronously and in pairs in the experiments reported in~\cite{NEF-ECJ:99}. 
We believe that the relationship between the randomized and the synchronous dynamics provides an additional justification and a new perspective on the model originally proposed by Friedkin and Johnsen: an example of social network derived from their experiments is analysed in detail in~\cite{PF-CR-RT-HI:13c}.

The forms of~\eqref{eqn:H} and \eqref{eqn:Gamma} may seem complicated at first sight. However, this is not surprising if we think of other examples of randomized dynamics over networks. For instance, in problems of consensus~\cite{FF-SZ:08a}, localization~(see Section \ref{sect:random-localization}), and PageRank computation~(see Section \ref{sect:random-pagerank}), the definition of the update matrices of the randomized dynamics is not trivial and must be done carefully in order to reconstruct, on average, the desired synchronous dynamics.
From a sociological perspective, \eqref{eqn:H} and~\eqref{eqn:Gamma} postulate a specific form of interaction for individuals in pairwise meetings, which is reflected on average by Friedkin and Johnsen's dynamics. Since by~\eqref{eqn:H} , we observe that individuals display a lower obstinacy during pairwise interaction.


\section{Concluding remarks}\label{sect:conclusion}
In this work, we have proposed time-averaging as a tool for smoothing oscillations in randomized network systems.  Other authors have proposed different solutions, which damp the inputs to the dynamics in the long run: this goal is achieved through ``under-relaxations'', that is, by using gains (or equivalently step-sizes) which decrease with time.
The analysis of the resulting dynamics is often based on tools from stochastic approximation~\cite{VSB:08} or semi-martingale theory~\cite[Ch~2]{BP:87}. Notably, also the choice of decreasing gains can be performed asynchronously and without coordination, albeit at the price of a more complex analysis~\cite[Ch.~7]{VSB:08} \cite{AN:11}.


Our method of time-averaging, together with its analysis based on ergodicity, has three advantages:  (i) it is simple to apply as it requires minimal assumptions, (ii) it allows for a unified treatment of different algorithms, and (iii) it gives a qualitative insight into the stochastic processes of interest. 
However, the use of time-averaging is not itself free from drawbacks. Indeed, rate of convergence of time-averages is not exponential, as for the original synchronous dynamics, but polynomial ().
This fact can be observed by inspecting the proof of Theorem~\ref{thm:ergodic} or from a mean-square convergence analysis, as we did in~\cite{HI-RT:10} and~\cite{CR-PF-HI-RT:13a}.
This drawback, which is shared by over-relaxation approaches, stimulates research towards exponentially-fast algorithms. Likely, effective algorithms can be constructed by endowing the nodes with some memory capabilities: an example is provided in~\cite{RC-AC-LS-MT:13} for the localization problem. More generally, their design may be based on the so-called asynchronous iteration method from numerical analysis~\cite[Section 6.2]{DPB-JNT:89}: for instance, the application of this method to PageRank computation is discussed in~\cite[Section~VII]{HI-RT:10}.

Finally, we expect that the approach presented here can be applied to a wide range of problems in network systems, besides the three examples detailed here. Venues for application include gossip algorithms to solve problems of simultaneous estimation and classification in sensor networks~\cite{FF-SF-CR:11}, convex optimization~\cite{AN:11}, and optimization in power networks~\cite{SB-SZ:13}.



\section*{Acknowledgements}
The authors are grateful to Noah E. Friedkin for posing the problem studied in Section~\ref{sect:random-friedkin} and to Keyou You for finding an error in a preliminary version of this paper~\cite{CR-PF-RT-HI:13b} and for providing a copy of~\cite{KY-SS-LQ:14}. The authors would also like to thank Francesco Bullo, Giacomo Como, and Fabio Fagnani for interesting conversations on the topics of this paper. 


\appendices
\section{Proof of Theorem~\ref{thm:ergodic}}
\label{sec:proof}
In this appendix, we provide the proof of our main result regarding randomized dynamics defined in~\eqref{eq:asynchro-algo}. The proof is based on techniques for iterated random functions, which we recall from~\cite{PD-DF:99}. These techniques require, in order to study the random process~\eqref{eq:asynchro-algo}, to consider the associated {\em backward} process , which we define below.

For any time instant , consider the random matrices  and  and define the matrix product

with 
Then, the iterated affine system in~\eqref{eq:dyn3} can be rewritten as

The corresponding \emph{backward process} is defined by

where

with 
Crucially, the backward process  has at every time  the same probability distribution as . 
The main tool to study the backward process is the following result. Let  denote any norm.

\begin{lemma}[Theorem~2.1 in~\cite{PD-DF:99}]\label{Diaco}
Let us consider the Markov { {process}}  defined by
 
where  and  are i.i.d. random variables.
Let us assume that

The corresponding backward random process  converges almost surely to a finite limit  if and only if

If \eqref{eq:ip_Diaco} holds, then the distribution of  is the unique invariant distribution for the Markov process .
\end{lemma}

This result provides conditions for the backward process to converge to a limit. Although the forward process has a different behavior compared to the backward process, the forward and backward processes have the same distribution. This fact allows us to determine, by studying the backward process , whether the sequence of random variables  converges in distribution to the invariant distribution of the Markov { {process}} in~\eqref{eq:asynchro-algo}.
This analysis is done in the following result.
\begin{lemma}\label{lem:back_convergence}
Consider the random process  defined in~\eqref{eq:asynchro-algo}, where  and  are i.i.d. and have finite first moments  and . If there exists  such that 
 where  is Schur stable, then, 
 converges almost surely to a finite limit , and the distribution of  is the unique invariant distribution for .
\end{lemma}
\begin{IEEEproof}
In order to apply Lemma~\ref{Diaco}, let us compute

Let  be the number of distinct eigenvalues of , denoted as 
, and consider the Jordan canonical decomposition . Then . 
Since the -th power of the Jordan block of size  is 

we deduce that 

where  is the size of the largest  Jordan block corresponding to 
Then

where  is a constant independent of  and  is the spectral radius of , which is known to be smaller than 1 because  is Schur stable.
We conclude that there exists a constant , independent of , such that 

and, consequently,

The claim then follows from Lemma~\ref{Diaco}.
\end{IEEEproof}

As a consequence, we deduce that also the (forward) random process  converges in distribution to a limit , and the distribution of  is the unique invariant distribution for .
We are now ready to verify the ergodicity of  under the assumptions of Theorem~\ref{thm:ergodic}.
Let  be a random vector independent from  with the same distribution as . Let  be the sequence such that

where  is defined as in \eqref{P}.
Since the process  is stationary and the invariant measure is unique we can apply the Birkhoff Ergodic Theorem (see for instance~\cite[Chapter~6]{DS:1993} or \cite[Chapter~5]{MH:06} for a simpler introduction) and conclude that with probability one

On the other hand, we can compute 

where we have used~\eqref{eq:bound-for-Diaco}.
If we choose , then the Borel-Cantelli Lemma \cite[Theorem~1.4.2]{VB:95} implies that with probability one  for all but finitely many values
of . Therefore, almost surely  converges
 to zero as  goes to infinity, and 

To complete the proof, we only need to observe that , which is equal to  as argued after the statement of Theorem~\ref{thm:ergodic}.

\section{Proof of Corollary~\ref{cor:ergodic2}}\label{sec:proofB}
The argument follows the lines of~\cite[Theorem 4.1]{KY-SS-LQ:14}.
Let us define for all  and  in 

Since  almost surely,  forms a Toeplitz array with probability one.
Since by~\eqref{eq:conv_distr} , we can apply Silverman-Toeplitz Theorem~\cite{OT:11} to conclude that almost surely 

This equality implies that almost surely

where the last equality comes from the law of large numbers. 
Again by Birkhoff Ergodic Theorem,  is a stationary and ergodic process and we finally conclude

thanks to the independence between  and .

\bibliographystyle{ieeetran}
\bibliography{aliases,biblio-ergodic}
\end{document}
