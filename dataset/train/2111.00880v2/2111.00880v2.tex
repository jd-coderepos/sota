

\section{Experiments}

\subsection{Benchmarking SOTA Methods}

\begin{figure}[htbp]
    \centering
    \begin{minipage}[t]{0.495\linewidth}
        \centering
        \includegraphics[width=1.0\linewidth]{figure/images/new_bubble-eps-converted-to.pdf}
        \caption*{(a) Clean dataset}
    \end{minipage}
    \begin{minipage}[t]{0.495\linewidth}
        \centering
        \includegraphics[width=1.0\linewidth]{figure/images/new_bubble_c-eps-converted-to.pdf}
        \caption*{(b) Corrupted dataset}
    \end{minipage}
    \caption{Performance evaluations of the person ReID methods in recent years. The x-axis, y-axis, and bubble size indicate Rank-1, mAP, and mINP, respectively. (a) Evaluations on clean Market-1501 test dataset. (b) Evaluations on Market-1501-C (corrupted query and gallery). In general, performance on the clean test set is not positively correlated with performance on the corrupted test set, and there is considerable room for improvement on corruption robustness.}
    \vspace{-3mm}
    \label{fig:bench_method}
\end{figure}
 
In this part, we evaluate the corruption robustness of 21 ReID methods, including AGW \cite{DBLP:journals/corr/abs-2001-04193}, BoT \cite{DBLP:conf/cvpr/0004GLL019}, ABD-Net \cite{DBLP:conf/iccv/ChenDXYCYRW19}, OS-Net \cite{DBLP:conf/iccv/ZhouYCX19}, DG-Net \cite{DBLP:journals/tomccap/ZhengZY18}, MHN \cite{DBLP:conf/iccv/ChenDH19}, BDB \cite{DBLP:conf/iccv/DaiCGZT19}, TransReID \cite{DBLP:journals/corr/abs-2102-04378}, LGPR \cite{DBLP:journals/corr/abs-2101-08533}, F-LGPR \cite{DBLP:journals/corr/abs-2101-08783}, TDB \cite{DBLP:conf/icpr/QuispeP20}, LUPerson \cite{DBLP:journals/corr/abs-2012-03753}, LightMBN \cite{DBLP:journals/corr/abs-2101-10774}, PLR-OSNet \cite{DBLP:conf/prcv/XieWZZL20}, CaceNet \cite{yu2020devil}, PCB \cite{DBLP:conf/eccv/SunZYTW18}, Pyramid \cite{DBLP:conf/cvpr/ZhengDSJGYHJ19}, AlignedReID++ \cite{DBLP:journals/pr/LuoJZFQZ19}, RRID \cite{DBLP:conf/aaai/ParkH20}, VPM \cite{DBLP:conf/cvpr/SunXLZLWS19}, and MGN \cite{DBLP:conf/mm/WangYCLZ18} (see our appendix for specific parameter settings of models).
Fig. \ref{fig:bench_method} illustrates the Rank-1, mAP, and mINP performance indicators of 21 ReID methods in recent years for both the clean test set and the corrupted dataset (the corrupted query and gallery).
The bubble size indicates the relative level of mINP indicator (see the appendix for more details).
In general, existing methods perform poorly on the corrupted test set, and there is vast room for improvement.
In Fig. \ref{fig:bench_method}, there is no obvious trade-off or positive correlation between the model performance on the clean test set and the corrupted test set.

TransReID \cite{DBLP:journals/corr/abs-2102-04378} significantly outperforms other methods in terms of indicators (most notably the mINP) of corrupted test sets.
It is worth noting that the mINP index measures the ability to retrieve difficult samples, which makes it an appropriate indicator of the ReID model corruption robustness.
From Fig. \ref{fig:outlook} and \ref{fig:bench_method}, we can observe that part-level based ReID methods perform well on clean and corrupted test sets. This demonstrates that learning local features is still critical for the corrupted images, and it can also make the model more robust to corruption variation.
On the corrupted test set, the performance of the vanilla PCB \cite{DBLP:conf/eccv/SunZYTW18} is still competitive, even surpassing some methods that perform excellently on the clean dataset.

Some of the above reproduced ReID methods were proposed to learn a noise-robust model.
These sample noises include heavy occlusion (e.g. VPM \cite{DBLP:conf/cvpr/SunXLZLWS19}), inaccurate bounding boxes caused by sampling errors (e.g. Pyramid \cite{DBLP:conf/cvpr/ZhengDSJGYHJ19}), illumination variation (e.g. BDB \cite{DBLP:conf/iccv/DaiCGZT19}), style changing (e.g. DG-Net \cite{DBLP:journals/tomccap/ZhengZY18}), and adversarial perturbations (e.g. F-LGPR \cite{DBLP:journals/corr/abs-2101-08783}).
But unfortunately, the corruption robustness of the above methods is not particularly strong.
Therefore, we argue that the corruption invariant ReID is complementary to the previous research on noise-robust ReID and merits special investigation.


\subsection{Connection with Generalizable Person ReID}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1.0\linewidth]{figure/images/generalizable_msmt.pdf}
    \caption{Cross-dataset generalization (Market-1501 to MSMT17) improves as corruption robustness increases. In contrast, the cross-dataset generalization has little correlation with performance on the clean samples. The histogram represents performance on the clean Market-1501 test set, the blue line depicts performance on the Market-1501-C (corrupted query and gallery), and the green line depicts performance when transferring directly to the MSMT17 dataset. On the \textbf{left} are the results of various methods, while on the \textbf{right} are the results of the same model trained with different augmentations. For different augmentations, the green histograms represent the random (\textbf{left} half) and soft random erasing (\textbf{right} half), respectively. The value on the x-axis represents the probability of erasure. See our appendix for more experiment results.}
    \vspace{-3mm}
    \label{fig:generalizable}
\end{figure}
 
In the previous corruption robustness research, it is less clear how a robust model generalizes across different datasets.
For image classification, Taori \textit{et al.} \cite{DBLP:conf/nips/TaoriDSCRS20} found that current robustness measures for synthetic distribution shift are at most weakly predictive for robustness on the natural distribution shifts presently available.
However, we found that corruption robustness measures are predictive for robustness on the natural distribution shifts on person ReID.
As illustrated in Fig. \ref{fig:generalizable}, extensive experiments with various methods and data enhancements reveal that the ability to generalize across datasets increases as corruption robustness increases.
The cross-dataset generalization ability refers to the performance of the model trained on the Market-1501 dataset and tested on another dataset (\textit{e.g.} CUHK-03 and MSMT17).
The histogram represents the performance on the clean Market-1501, and the mAP is the value on the left y-axis.
The blue and green lines respectively reflect the trend of the corruption robustness and the cross-dataset generalization, and the mAP is the value on the right y-axis.
As illustrated in the left panel of Fig. \ref{fig:generalizable}, the cross-dataset generalization exhibits a consistent upward trend with the corruption robustness (correlation coefficient ). However, there is no obvious correlation between cross-dataset generalization and clean sample performance (correlation coefficient ).


\subsection{Benchmarking Network Architecture}

\setlength{\tabcolsep}{3.2pt}
\begin{table}[t]
    \scriptsize
    \renewcommand\arraystretch{1.5}
    \centering
    \caption{Comparisons of transformer-based models and CNN-based models. All the models are trained with 256  128 inputs. Trans- denotes the TransReID method. Compared to the original ViT, the TransReID includes SIE and JPM modules. While ViT-based models generally outperform the CNN-based models in terms of corruption robustness, the advantage of the ViT over CNN-based models with an attention mechanism is not obvious.}
    \vspace{1mm}
    \begin{tabular}{l|cc|ccc|ccc|ccc|ccc}
        \hline
        \multirow{2}{*}{Network} & MACs  & Params & \multicolumn{3}{c|}{Clean Eval.} & \multicolumn{3}{c|}{Corrupted Eval.} & \multicolumn{3}{c|}{Corrupted Query} & \multicolumn{3}{c}{Corrupted Gallery}                                                                                                                                        \\
                                 & (G)   & (M)    & mINP                             & mAP                                  & R-1                                  & mINP                                  & mAP            & R-1            & mINP           & mAP            & R-1            & mINP          & mAP            & R-1            \\
        \hline
        ResNet-50                & 4.06  & 23.51  & 59.30                            & 85.06                                & 93.38                                & 0.21                                  & 8.50           & 27.30          & 14.34          & 26.42          & 30.52          & 0.39          & 27.00          & 77.15          \\
        ResNet-50-ibn            & 4.06  & 23.51  & 67.79                            & 86.55                                & 94.36                                & 0.33                                  & 13.90          & 37.75          & 20.45          & 36.77          & 43.39          & 0.85          & 35.78          & 83.34          \\
        ResNeSt-50               & 4.68  & 25.44  & 65.49                            & 87.97                                & 95.28                                & 0.26                                  & 9.82           & 30.57          & 18.26          & 31.71          & 37.65          & 0.51          & 31.79          & 82.93          \\
        ResNet-101-ibn           & 6.49  & 42.50  & 65.27                            & 87.90                                & 95.22                                & 0.37                                  & 13.96          & 37.35          & 21.99          & 37.35          & 43.42          & 0.90          & 36.61          & 84.09          \\
        SE-ResNet-101-ibn        & 6.50  & 47.25  & 67.75                            & \textbf{89.08}                       & \textbf{95.49}                       & 0.69                                  & 16.99          & 43.14          & 27.87          & 45.28          & 51.48          & 2.60          & 47.39          & 88.32          \\
        ResNeXt-101-ibn          & 6.51  & 42.13  & \textbf{67.81}                   & 89.05                                & 95.04                                & \textbf{1.34}                         & \textbf{21.65} & \textbf{48.25} & \textbf{31.38} & \textbf{50.49} & \textbf{56.59} & \textbf{3.78} & \textbf{50.30} & \textbf{88.48} \\
        \hline
        DeiT-S                   & 2.78  & 22.31  & 56.36                            & 83.90                                & 93.23                                & 1.07                                  & 19.30          & 44.38          & 23.41          & 43.30          & 51.49          & 2.57          & 43.98          & 83.73          \\
        ViT-S                    & 6.16  & 47.81  & 53.34                            & 82.42                                & 92.79                                & 1.02                                  & 18.06          & 42.47          & 22.76          & 43.94          & 53.39          & 2.68          & 43.64          & 82.83          \\
        ViT-S + SIE              & 6.16  & 47.81  & 55.99                            & 83.70                                & 93.35                                & 0.82                                  & 16.88          & 40.26          & 22.54          & 42.34          & 50.76          & 2.29          & 43.07          & 82.96          \\
        ViT-S + JPM              & 6.94  & 53.72  & 55.42                            & 83.40                                & 92.70                                & 1.10                                  & 19.33          & 43.62          & 23.85          & 43.84          & 51.91          & 2.55          & 43.87          & 82.86          \\
        ViT-B                    & 11.03 & 85.61  & 64.08                            & 87.11                                & 94.60                                & 1.82                                  & 25.84          & 51.31          & 31.41          & 51.54          & \textbf{59.44} & \textbf{4.40} & 52.00          & 87.60          \\
        Trans-ViT-S              & 11.33 & 53.72  & 57.01                            & 84.46                                & 93.74                                & 1.02                                  & 18.23          & 42.57          & 23.65          & 43.19          & 50.71          & 2.48          & 43.29          & 83.47          \\
        Trans-DeiT-B             & 19.55 & 92.70  & 67.16                            & 88.54                                & 95.07                                & 1.70                                  & 24.71          & 51.67          & 32.39          & 50.79          & 57.12          & 3.84          & 50.03          & 87.65          \\
        Trans-ViT-B              & 19.55 & 92.70  & \textbf{69.31}                   & \textbf{88.97}                       & \textbf{95.10}                       & \textbf{1.93}                         & \textbf{27.10} & \textbf{52.77} & \textbf{34.52} & \textbf{52.30} & 57.96          & 4.18          & \textbf{52.19} & \textbf{88.60} \\
        \hline
    \end{tabular}
    \vspace{3mm}
    \label{tab:bench_network}
\end{table}
 
To further analyze the corruption robustness of the TransReID method, we compare CNN-based models and transformer-based models in this part.
The number of parameters (Params) and multi-adds (MACs) of evaluated models are presented.
To begin, the performance of TransReID illustrated in Fig. \ref{fig:outlook} is identical to that of Trans-Vit-base in Fig. \ref{fig:bench_method}. Although it outperforms other models, it requires more memory and computation time.
Additionally, we present the robustness performance in two settings, one in which only the query is corrupted and one in which only the gallery is corrupted. In general, a corrupted query makes models more difficult to sort simple samples correctly (Rank-1 is low), whereas a corrupted gallery makes models more difficult to retrieve difficult samples (mINP is low).
When memory and computational overhead are considered, we discover that the ViT architecture is still superior in terms of corruption robustness.
On the corrupted test set (corrupted query and gallery setting), ViT-S and DeiT-S outperform all CNN-based models except for ResNeXt-101-ibn \cite{DBLP:conf/cvpr/XieGDTH17}.
Additionally, we discover that when ResNet-50 is combined with an IBN \cite{DBLP:conf/eccv/PanLST18} module, the corruption robustness of ResNet-50 is significantly improved. This is consistent with their findings \cite{DBLP:conf/eccv/PanLST18} that instance normalization (IN) learns features that are invariant to changes in appearance, such as colors and styles. In summary, incorporating attention modules and judicious use of IN into network architecture can significantly improve the corruption robustness.



\subsection{Benchmarking Data Augmentation}

\setlength{\tabcolsep}{3.2pt}
\begin{table}[t]
    \tiny
    \renewcommand\arraystretch{1.8}
    \centering
    \caption{Comparisons of various data augmentations. The upper part compares the global augmentation methods (Random affine transformation, AutoAugment and AugMix). The bottom part compares the local-based augmentation methods when combined with the AugMix. REA stands for random erasing, S-REA stands for soft random erasing, R-PATCH stands for random patch mixing, and S-PATCH stands for self patch mixing augmentation.}
    \vspace{1mm}
    \begin{tabular}{l|ccccc|ccccc|cccc|cccc}
        \hline
        \multirow{2}{*}{Augmentation} & \multicolumn{5}{c|}{Clean Eval.} & \multicolumn{5}{c|}{Corrupted Eval.} & \multicolumn{4}{c|}{Corrupted Query} & \multicolumn{4}{c}{Corrupted Gallery}                                                                                                               \\
                                      & mINP                             & mAP                                  & R-1                                  & R-5                                   & R-10  & mINP & mAP   & R-1   & R-5   & R-10  & mINP  & mAP   & R-1   & R-5   & mINP & mAP   & R-1   & R-5   \\
        \hline
        Standard                      & 45.70                            & 77.76                                & 91.69                                & 96.44                                 & 97.83 & 0.43 & 14.31 & 37.31 & 53.36 & 59.99 & 16.79 & 34.45 & 42.99 & 53.06 & 0.90 & 33.54 & 77.74 & 90.28 \\
        R-Affine                      & 59.34                            & 85.69                                & 93.88                                & 98.16                                 & 98.93 & 0.27 & 8.01  & 27.46 & 39.70 & 45.20 & 16.28 & 30.69 & 36.34 & 45.04 & 0.83 & 33.02 & 81.29 & 92.12 \\
        AutoAug                       & 46.39                            & 80.18                                & 92.34                                & 97.60                                 & 98.57 & 0.37 & 10.55 & 30.40 & 42.71 & 48.41 & 14.39 & 31.87 & 40.23 & 49.24 & 1.12 & 35.22 & 80.64 & 91.86 \\
        \rowcolor{green!10} AugMix    & 45.92                            & 77.16                                & 91.03                                & 96.88                                 & 98.13 & 1.05 & 22.47 & 48.06 & 65.07 & 71.27 & 21.79 & 43.46 & 53.93 & 65.58 & 1.95 & 41.32 & 80.25 & 92.21 \\
        \hline
        + REA                         & 57.10                            & 83.40                                & 93.08                                & 97.83                                 & 98.43 & 1.49 & 24.32 & 49.80 & 66.82 & 72.68 & 26.86 & 48.08 & 57.33 & 68.92 & 3.30 & 47.46 & 84.71 & 94.45 \\
        \rowcolor{green!10} + S-REA   & 57.34                            & 83.48                                & 92.99                                & 97.57                                 & 98.43 & 2.19 & 26.66 & 52.60 & 69.64 & 75.52 & 28.75 & 50.33 & 56.69 & 71.49 & 4.44 & 49.54 & 85.27 & 94.58 \\
        + R-PATCH                     & 47.37                            & 77.78                                & 90.97                                & 96.53                                 & 98.10 & 1.00 & 22.05 & 47.49 & 64.35 & 70.42 & 21.97 & 43.20 & 53.60 & 64.84 & 1.74 & 41.19 & 80.85 & 92.45 \\
        \rowcolor{green!10} + S-PATCH & 54.30                            & 81.86                                & 92.55                                & 97.48                                 & 98.49 & 1.17 & 22.72 & 47.99 & 64.84 & 70.73 & 25.19 & 45.78 & 55.02 & 66.49 & 2.45 & 44.60 & 83.18 & 93.83 \\
        \hline
    \end{tabular}
    \vspace{0mm}
    \label{tab:bench_da}
\end{table}
 
Data augmentation is vital to improve the corruption robustness.
From Tab. \ref{tab:bench_da}, we find that the AugMix is significantly more effective in boosting robustness than other augmentation methods, which is consistent with previous research \cite{DBLP:conf/iclr/HendrycksMCZGL20}.
As depicted in the right part of Fig. \ref{fig:generalizable}, corruption robust decreases with increasing erasing probability.
Besides, soft random erasing are more effective for improving corruption robustness and less sensitive to the tuning of erasing probability compared with random erasing.
In Tab. \ref{tab:bench_da}, we have a similar observation that soft random benefits more for improving corruption robustness.
Meanwhile, the SelfPatch augmentation method outperforms the RandomPatch augmentation method on clean and corrupted test sets.



\subsection{A Strong Baseline on Corruption Invariant ReID}

\setlength{\tabcolsep}{2.0pt}
\begin{table}[t]
    \scriptsize
    \renewcommand\arraystretch{1.5}
    \centering
    \caption{Corruption invariant person ReID benchmarks on single-modality datasets. SBS \cite{DBLP:journals/corr/abs-2006-02631} represents a stronger baseline on top of BoT. In single-modality datasets, our proposed baseline CIL achieves competitive performance on the clean test set and remarkable results on three corrupted scenarios.}
    \vspace{1mm}
    \begin{tabular}{lc|cccc|cccc|cccc|cccc}
        \hline
        \multirow{2}{*}{Dataset}     & \multirow{2}{*}{Method} & \multicolumn{4}{c|}{Clean Eval.} & \multicolumn{4}{c|}{Corrupted Eval.} & \multicolumn{4}{c|}{Corrupted Query} & \multicolumn{4}{c}{Corrupted Gallery}                                                                                                                                                                                                           \\
                                     &                         & mINP                             & mAP                                  & R-1                                  & R-5                                   & mINP          & mAP            & R-1            & R-5            & mINP           & mAP            & R-1            & R-5            & mINP          & mAP            & R-1            & R-5            \\
        \hline
        \multirow{4}{*}{Market-1501} & BoT                     & 59.30                            & 85.06                                & 93.38                                & 97.71                                 & 0.20          & 8.42           & 27.05          & 40.28          & 14.56          & 26.89          & 31.92          & 40.24          & 0.39          & 26.82          & 76.78          & 89.57          \\
                                     & AGW                     & \textbf{64.03}                   & 86.51                                & 94.00                                & 98.01                                 & 0.35          & 12.13          & 31.90          & 46.54          & 19.44          & 31.75          & 35.25          & 44.09          & 0.67          & 33.38          & 80.45          & 91.90          \\
                                     & SBS                     & 60.03                            & \textbf{88.33}                       & \textbf{95.90}                       & \textbf{98.49}                        & 0.29          & 11.54          & 34.13          & 47.28          & 18.47          & 35.33          & 42.06          & 51.21          & 0.53          & 32.65          & 83.11          & 92.87          \\
                                     & CIL                     & 57.90                            & 84.04                                & 93.38                                & 97.95                                 & \textbf{1.76} & \textbf{28.03} & \textbf{55.57} & \textbf{72.34} & \textbf{29.99} & \textbf{52.53} & \textbf{62.29} & \textbf{73.34} & \textbf{3.45} & \textbf{48.95} & \textbf{85.52} & \textbf{94.76} \\
        \hline
\multirow{4}{*}{MSMT17}      & BoT                     & 9.91                             & 48.34                                & 73.53                                & 85.29                                 & 0.07          & 5.28           & 20.20          & 31.11          & 2.75           & 15.78          & 25.92          & 35.50          & 0.09          & 16.10          & 59.06          & 76.48          \\
                                     & AGW                     & 12.38                            & 51.84                                & 75.21                                & 86.30                                 & 0.08          & 6.53           & 22.77          & 34.08          & 3.82           & 18.42          & 28.06          & 37.33          & 0.15          & 18.08          & 61.45          & 78.43          \\
                                     & SBS                     & 10.26                            & \textbf{56.62}                       & \textbf{82.02}                       & \textbf{90.39}                        & 0.05          & 7.89           & 28.77          & 40.00          & 3.23           & 22.71          & 36.68          & 46.53          & 0.12          & 21.16          & \textbf{70.65} & \textbf{83.95} \\
                                     & CIL                     & \textbf{12.45}                   & 52.40                                & 76.10                                & 87.19                                 & \textbf{0.32} & \textbf{15.33} & \textbf{39.79} & \textbf{54.83} & \textbf{5.84}  & \textbf{29.08} & \textbf{45.51} & \textbf{58.27} & \textbf{0.50} & \textbf{27.99} & 68.31          & 82.87          \\
        \hline
        \multirow{2}{*}{CUHK03}      & AGW                     & 49.97                            & 62.25                                & 64.64                                & 81.50                                 & 0.46          & 3.45           & 5.90           & 11.59          & 12.69          & 17.20          & 16.26          & 26.29          & 2.89          & 19.40          & 33.43          & 53.85          \\
                                     & CIL                     & \textbf{53.87}                   & \textbf{65.16}                       & \textbf{67.29}                       & \textbf{83.79}                        & \textbf{4.25} & \textbf{16.33} & \textbf{22.96} & \textbf{39.89} & \textbf{26.61} & \textbf{34.62} & \textbf{34.03} & \textbf{50.44} & \textbf{9.07} & \textbf{31.81} & \textbf{46.81} & \textbf{69.66} \\
        \hline
    \end{tabular}
    \vspace{1mm}
    \label{tab:baseline}
\end{table}
 \setlength{\tabcolsep}{2.0pt}
\begin{table}[t]
    \scriptsize
    \renewcommand\arraystretch{1.5}
    \centering
    \caption{Corruption invariant person ReID benchmarks on cross-modality datasets. For SYSU-MM01 dataset, Mode A and Mode B mean all-search (including indoor and outdoor cameras) and indoor-search experimental settings, respectively. For RegDB dataset, Mode A and Mode B represent visible-to-thermal and thermal-to-visible experimental settings, respectively. Note that we only corrupt RGB (visible) images in the corruption evaluation.}
    \vspace{1mm}
    \begin{tabular}{lc|cccc|cccc|cccc|cccc}
        \hline
        \multirow{3}{*}{Dataset}   & \multirow{3}{*}{Method} & \multicolumn{8}{c|}{Mode A}      & \multicolumn{8}{c}{Mode B}                                                                                                                                                                                                                                                                                         \\
        \cline{3-18}
                                   &                         & \multicolumn{4}{c|}{Clean Eval.} & \multicolumn{4}{c|}{Corrupted Eval.} & \multicolumn{4}{c|}{Clean Eval.} & \multicolumn{4}{c}{Corrupted
            Eval.}                                                                                                                                                                                                                                                                                                                                                                                                   \\

                                   &                         & mINP                             & mAP                                  & R-1                              & R-5                          & mINP           & mAP            & R-1            & R-5            & mINP           & mAP            & R-1            & R-5            & mINP           & mAP            & R-1            & R-5            \\
        \hline
        \multirow{2}{*}{SYSU-MM01} & AGW                     & 36.17                            & \textbf{47.65}                       & \textbf{47.50}                   & \textbf{74.68}               & 14.73          & 29.99          & 34.42          & 62.26          & \textbf{59.74} & \textbf{62.97} & \textbf{54.17} & \textbf{83.50} & 35.39          & 40.98          & 33.80          & 61.61          \\
                                   & CIL                     & \textbf{38.15}                   & 47.64                                & 45.41                            & 73.95                        & \textbf{22.48} & \textbf{35.92} & \textbf{36.95} & \textbf{65.54} & 57.41          & 60.45          & 50.98          & 81.34          & \textbf{43.11} & \textbf{48.65} & \textbf{40.73} & \textbf{71.44} \\
        \hline
        \multirow{2}{*}{RegDB}     & AGW                     & 54.10                            & 68.82                                & \textbf{75.78}                   & \textbf{85.24}               & 32.88          & 43.09          & 45.44          & 55.26          & 52.40          & 68.15          & \textbf{75.29} & 83.74          & 6.00           & 41.37          & \textbf{67.54} & 81.23          \\
                                   & CIL                     & \textbf{55.68}                   & \textbf{69.75}                       & 74.96                            & 84.71                        & \textbf{38.66} & \textbf{49.76} & \textbf{52.25} & \textbf{65.83} & \textbf{55.50} & \textbf{69.21} & 74.95          & \textbf{86.12} & \textbf{11.94} & \textbf{47.90} & 67.17          & \textbf{83.25} \\

        \hline
    \end{tabular}
    \vspace{-1mm}
    \label{tab:baseline_thermal}
\end{table}
 
\setlength{\tabcolsep}{3.2pt}
\begin{table}[t]
    \tiny
    \renewcommand\arraystretch{1.8}
    \centering
    \caption{Ablation study on CIL components, including pre-BNNeck inference, local-based augmentation (soft random erasing and self patch mixing) and consistent ID loss.}
    \vspace{1mm}
    \begin{tabular}{l|cccc|cccc|cccc|cccc}
        \hline
        \multirow{2}{*}{Component} & \multicolumn{4}{c|}{Clean Eval.} & \multicolumn{4}{c|}{Corrupted Eval.} & \multicolumn{4}{c|}{Corrupted Query} & \multicolumn{4}{c}{Corrupted Gallery}                                                                                                               \\
                                      & mINP                             & mAP                                  & R-1                                  & R-5                                     & mINP & mAP   & R-1   & R-5    & mINP  & mAP   & R-1   & R-5   & mINP & mAP   & R-1   & R-5   \\
        \hline
        Standard ResNet-50                      & \textbf{60.57} & \textbf{85.52} & \textbf{94.48} & 97.95 & 0.55 & 15.26 & 39.87 & 55.84 & 21.67 & 38.36 & 45.00 & 55.29 & 1.27 & 38.48 & 83.50 & 93.48  \\
        + infer. before BNNeck & 47.39 & 79.58 & 91.66 & 97.15 & 0.89 & 18.16 & 42.41 & 58.98 & 20.53 & 42.94 & 53.35 & 65.29 & 2.14 & 42.65 & 82.23 & 93.27  \\
        + soft random erasing                       & 59.57 & 84.74 & 93.26 & \textbf{98.07} & 1.37 & 25.98 & 53.89 & 70.92 & 29.44 & 50.96 & 60.11 & 71.89 & 2.67 & 46.82 & 85.68 & 94.86 \\
        + self patch mixing    & 55.96 & 82.93 & 93.05 & 97.51 & \textbf{1.78} & 27.59 & \textbf{57.37} & 71.81 & \textbf{30.33} & \textbf{53.69} & \textbf{64.08} & \textbf{75.81} & 3.23 & 48.08 & 84.70 & 94.59  \\
        + consistent ID loss   & 57.90                            & 84.04                                & 93.38                                & 97.95                                 & 1.76 & \textbf{28.03} & 55.57 & \textbf{72.34} & 29.99 & 52.53 & 62.29 & 73.34 & \textbf{3.45} & \textbf{48.95} & \textbf{85.52} & \textbf{94.76}  \\
        \hline
    \end{tabular}
    \vspace{-3mm}
    \label{tab:CIL_ablation}
\end{table}
 \begin{figure}[htbp]
    \centering
    \includegraphics[width=1.0\linewidth]{figure/images/corruption_type_ablation.pdf}
    \caption{Ablation study on different corruption types (corrupted query and gallery), including 20 types of algorithmically generated corruptions from noise, blur, weather, and digital categories.}
    \vspace{-5mm}
    \label{fig:corruption_type_ablation}
\end{figure}
 

On the basis of the foregoing investigation, we propose three general and simple techniques for enhancing corruption robustness (detailed ablations see the appendix).
The first is the consistent ID loss that enforces a smoother network response \cite{DBLP:conf/iclr/HendrycksMCZGL20}. The second technique is inference with features before BNNeck, in case the feature is too domain-specific. The third one is the proposed local-based augmentation techniques, soft random erasing and self patch mixing.
Our baseline is CIL (\textbf{C}onsistent identity loss, \textbf{I}nference before BNNeck and \textbf{L}ocal-based augmentation).
In single-modality datasets (see Tab. \ref{tab:baseline}), our proposed baseline CIL achieves competitive performance on the clean test set and outstanding results on three corrupted situations.
We also evaluate the corruption robustness of the CIL baseline using a two-stream architecture on the cross-modality visible-infrared ReID task.
As seen by the results in Tab. \ref{tab:baseline_thermal}, our baseline CIL considerably improves corruption robustness while compromising little performance on clean test sets.

We conduct ablation experiments on the components of our proposed baseline, as shown in Tab. \ref{tab:CIL_ablation}. 
The standard ResNet-50 we use here is built on the AGW baseline, which deletes the non-local block and adds the loss function used by the SBS baseline. 
It can be seen from Table 6 that our suggested pre-BNNeck inference and local data augmentation approaches can increase the corruption robustness, and the consistency ID loss can effectively maintain the corruption robustness while boosting the performance on clean samples.
In addition, we also perform ablation experiments of different corruption types on our CIL baseline to see the impacts of each individual corruption, as shown in Fig. \ref{fig:corruption_type_ablation}. 
Experimental results are also averaged after ten evaluations. 
We can see that the model is more vulnerable to corruption types such as saturate, contrast, and fog that produce greater color interference.

