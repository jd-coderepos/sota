

\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage[pagenumbers]{cvpr} 

\usepackage[accsupp]{axessibility} \renewcommand{\rmdefault}{ptm}
\renewcommand{\sfdefault}{phv}
   
   
\usepackage{epsfig}
\usepackage{dsfont}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{color}
\usepackage{cite,eucal}
\usepackage{multirow,xcolor}



\definecolor{citecolor}{HTML}{0071bc}
\usepackage[pagebackref,breaklinks=true,letterpaper=true,colorlinks,citecolor=citecolor,bookmarks=false]{hyperref}




\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\xvec}{{\mathbf{x}}}
\newcommand{\yxvec}{{y_{\mathbf{x}}}}
\newcommand{\svec}{{\mathbf{s}}}

\def\cvprPaperID{6784} \def\confName{CVPR}
\def\confYear{2022}



\begin{document}



  
\title{Catching Both Gray and Black Swans: Open-set Supervised Anomaly Detection\thanks{Corresponding author: CS (e-mail: {\tt  chunhua@me.com}). This work was in part
done when GP and CS were with The University of Adelaide.}
}

\author{Choubo Ding,\qquad Guansong Pang\thanks{First two authors contributed equally.},\qquad Chunhua Shen\
\argmin_{\Theta}\sum_{i=1}^{|\mathcal{G}|} \ell_i\big(g_i(f (\mathbf{x};\Theta_f);\Theta_{i}), y_{\xvec}\big),
\label{eqn:mil}
    \ell_{s}(\mathbf{x}, \yxvec) = \ell\big(g_s(\mathbf{M}_{\xvec}; \Theta_{s}), \yxvec\big),
\label{eqn:seenabnormality}
g_s(\mathbf{M}_{\xvec}; \Theta_{s}) = \max_{\Psi_K(\mathbf{M}_{\xvec})\subset \mathcal{D}} \frac{1}{K} \sum_{\mathbf{d}_{i} \in \Psi_K(\mathbf{M}_{\xvec})} g_s(\mathbf{d}_{i}; \Theta_{s})
\label{eqn:dataaugmentation}
    \tilde{\mathbf{x}}= T\circ C(\mathbf{R}\odot \mathbf{x}_n) + \big(\mathbf{1}-T(\mathbf{R})\big) \odot \mathbf{x}_n
\label{eqn:pseudoanomaly}
    \ell_{p}(\xvec, y_{\xvec}) = \ell\big(g_p(\mathbf{M}_{\xvec};\Theta_p), y_{\xvec}\big),

    \mathbf{M}_r = \frac{1}{\mathit{N}_{r}}\sum_{i=1}^{\mathit{N}_{r}} f(\xvec_{{r}_i};\Theta_f),

    \mathbf{M}_{r \ominus \xvec} = \mathbf{M}_r \ominus  \mathbf{M}_{\xvec},

    \ell_{r}(\mathbf{x}, \yxvec) = \ell\big(g_r(\mathbf{M}_{r \ominus \xvec};\Theta_r), \yxvec\big),

    \ell_{n}(\mathbf{x}, \yxvec) = \ell\Big(g_n\big(\frac{1}{h^\prime\times w^\prime}\sum_{i=1}^{h^\prime \times w^\prime} \mathbf{d}_i; \Theta_{n}\big), \yxvec\Big),
\label{eqn:deviation}
    \mathit{dev}(\mathbf{x}_{i};\Theta) = \frac{g(f (\mathbf{x};\Theta_f);\Theta_{g}) - \mu_{\mathcal{R}}}{\sigma_{\mathcal{R}}},
\label{eqn:loss}
    \ell\big(\mathbf{x}_{i}, \mu_{\mathcal{R}}, \sigma_{\mathcal{R}};\Theta \big) = (1-y_{i})|\mathit{dev}(\mathbf{x}_{i};\Theta)|\\ + y_{i} \max\big(0, a - \mathit{dev}(\mathbf{x}_{i};\Theta)\big),

where  indicate an anomaly and  indicate a normal sample,
and  is equivalent to a Z-Score confidence interval parameter.


\subsection{Implementation of Competing Methods}
In the main text, we present five recent and closely related state-of-the-art (SOTA) competing methods. Here we introduce two additional competing methods. Following is the detailed description and implementation details of these seven methods:

\noindent\textbf{KDAD} \cite{salehi2021multiresolution} is an unsupervised deep anomaly detector based on multi-resolution knowledge distillation. We experiment with the code provided by its authors\footnote{\url{https://github.com/rohban-lab/Knowledge\_Distillation\_AD}} and report the results. Since KDAD is unsupervised, it is trained with normal data only, but it is evaluated on exactly the same test data as DRA.


\noindent\textbf{DevNet} \cite{pang2019deep,pang2021explainable} is a supervised deep anomaly detector based on a prior-based deviation. The results we report are based on the implementation provided by its authors\footnote{\url{https://github.com/choubo/deviation-network-image}}.


\noindent\textbf{FLOS} \cite{lin2017focalloss} is a deep imbalanced classifier that learns a binary classification model using the class-imbalance-sensitive loss -- focal loss. The implementation of FLOS is also taken from \cite{pang2021explainable}, which replaces the loss function of DevNet with the focal loss.


\noindent\textbf{SAOE} is a deep out-of-distribution detector that utilizes pseudo anomalies from both data augmentation-based and outlier exposure-based methods. Motivated by the success of using pseudo anomalies to improve anomaly detection in recent studies \cite{tack2020csi,li2021cutpaste}, SAOE is implemented by learning both seen and pseudo abnormalities through a multi-class (\ie, normal class, seen anomaly class, and pseudo anomaly class) classification head using the plain feature learning method as in DRA. In addition to this multi-class classification, the outlier exposure module \cite{hendrycks2018deep} in SAOE is implemented according to its authors\footnote{\url{https://github.com/hendrycks/outlier-exposure}}, in which the MVTec AD \cite{Bergmann_2019_CVPR} or LAG \cite{Li_2019_CVPR} dataset is used as external data. In all our experiments we removed the related data from the outlier data that has any overlapping with the target data to avoid data leakage.


\noindent\textbf{MLEP} \cite{liu2019margin} is a deep open set anomaly detector based on margin learning embedded prediction. The original MLEP\footnote{\url{https://github.com/svip-lab/MLEP}} is designed for open set video anomaly detection, and we adapt it to image tasks by modifying the backbone network and training settings to be consistent with DRA.

\noindent\textbf{Deep SAD} \cite{ruff2019deep} is a supervised deep anomaly detector that extends Deep SVDD \cite{ruff2018deep} by using a few labeled anomalies and normal samples to learn more compact one-class descriptors. Particularly, it adds a new marginal constraint to the original Deep SVDD that enforces a large margin between labeled anomalies and the one-class center in latent space. The implementation of DeepSAD is taken from the original authors\footnote{\url{https://github.com/lukasruff/Deep-SAD-PyTorch}}.

\noindent\textbf{MINNS} \cite{wang2018revisiting} is a deep multiple instance classification model, which is implemented based on \cite{pang2021explainable}.

\begin{table}[bt]
  \centering
  \caption{AUC results (mean±std) of DRA and two additional competing methods under the general setting. All methods are trained using ten random anomaly examples, with the best results are \textbf{highlighted}.
}
  \vspace{-0.2cm}
  \scalebox{0.77}{
    \begin{tabular}{l@{}|c|ccc}
    \hline
    \textbf{Dataset} &  & \multicolumn{1}{c}{\textbf{DeepSAD}} & \multicolumn{1}{c}{\textbf{MINNS}} & \multicolumn{1}{c}{\textbf{DRA (Ours)}} \\\hline
    Carpet & 5 & 0.791\footnotesize{±0.011}& 0.876\footnotesize{±0.015}& \textbf{0.940}\footnotesize{±0.027} \\
    
    Grid & 5 & 0.854\footnotesize{±0.028}& 0.983\footnotesize{±0.016}& \textbf{0.987}\footnotesize{±0.009} \\
    
    Leather & 5 & 0.833\footnotesize{±0.014}& 0.993\footnotesize{±0.007}& \textbf{1.000}\footnotesize{±0.000}\\
    
    Tile & 5 & 0.888\footnotesize{±0.010}& 0.980\footnotesize{±0.003}& \textbf{0.994}\footnotesize{±0.006}\\
    
    Wood & 5 & 0.781\footnotesize{±0.001}& \textbf{0.998}\footnotesize{±0.004}& \textbf{0.998}\footnotesize{±0.001} \\

    Bottle & 3 & 0.913\footnotesize{±0.002}& 0.995\footnotesize{±0.007}& \textbf{1.000}\footnotesize{±0.000} \\
    
    Capsule & 5 & 0.476\footnotesize{±0.022}& 0.905\footnotesize{±0.013}& \textbf{0.935}\footnotesize{±0.022} \\
    
    Pill & 7 & 0.875\footnotesize{±0.063}& \textbf{0.913}\footnotesize{±0.021}& 0.904\footnotesize{±0.024}\\
    
    Transistor & 4 & 0.868\footnotesize{±0.006}& 0.889\footnotesize{±0.032}& \textbf{0.915}\footnotesize{±0.025}\\
    
    Zipper & 7 & 0.974\footnotesize{±0.005}& 0.981\footnotesize{±0.011}& \textbf{1.000}\footnotesize{±0.000} \\
    
    Cable &8 & 0.696\footnotesize{±0.016}& 0.842\footnotesize{±0.012}& \textbf{0.909}\footnotesize{±0.011} \\
    
    Hazelnut &4 & \textbf{1.000}\footnotesize{±0.000}& \textbf{1.000}\footnotesize{±0.000}& \textbf{1.000}\footnotesize{±0.000} \\
    
    Metal\_nut & 4 & 0.860\footnotesize{±0.053}& 0.984\footnotesize{±0.002}& \textbf{0.997}\footnotesize{±0.002} \\
    
    Screw & 5 & 0.774\footnotesize{±0.081}& 0.932\footnotesize{±0.035}& \textbf{0.977}\footnotesize{±0.009} \\
    
    Toothbrush & 1 & \textbf{0.885}\footnotesize{±0.063}& 0.810\footnotesize{±0.086}& 0.826\footnotesize{±0.021} \\
    
    \hline
    \textbf{MVTec AD} & - & 0.830\footnotesize{±0.009}& 0.939\footnotesize{±0.011}& \textbf{0.959}\footnotesize{±0.003} \\
    
    \textbf{AITEX } &12 & 0.686\footnotesize{±0.028}& 0.813\footnotesize{±0.030}& \textbf{0.893}\footnotesize{±0.017} \\
    
    \textbf{SDD}& 1 & 0.963\footnotesize{±0.005}& 0.961\footnotesize{±0.016}& \textbf{0.991}\footnotesize{±0.005} \\
    
    \textbf{ELPV} & 2 & 0.722\footnotesize{±0.053}& 0.788\footnotesize{±0.028}& \textbf{0.845}\footnotesize{±0.013} \\
    
   \textbf{Optical}& 1 & 0.558\footnotesize{±0.012}& 0.774\footnotesize{±0.047}& \textbf{0.965}\footnotesize{±0.006}\\
   
   \textbf{Mastcam}& 11 & 0.707\footnotesize{±0.011}& 0.803\footnotesize{±0.031}& \textbf{0.848}\footnotesize{±0.008}\\
   
    \textbf{BrainMRI}& 1 & 0.850\footnotesize{±0.016}& 0.943\footnotesize{±0.031}& \textbf{0.970}\footnotesize{±0.003}\\
    
   \textbf{HeadCT}& 1 & 0.928\footnotesize{±0.005}& \textbf{0.984}\footnotesize{±0.010}& 0.972\footnotesize{±0.002}\\
   
   \textbf{Hyper-Kvasir}& 4 & 0.719\footnotesize{±0.032}& 0.647\footnotesize{±0.051}& \textbf{0.834}\footnotesize{±0.004} \\
   \hline
    \end{tabular}
    }
  \label{tab:randomanomalies}\vspace{-0.3cm}
\end{table}\section{Additional Empirical Results}
\subsection{Additional Comparison Results}
\noindent\textbf{General Setting.} We report the results of DRA and two additional competing methods under general setting in Tab \ref{tab:randomanomalies}. Our method achieves the best AUC performance in eight of the nine datasets and the close-to-best AUC performance in the another dataset. In the eight best-performing datasets, our method improves AUC by 2\% to 19.1\% over the best competing method.

\noindent\textbf{Hard Setting.} Tab. \ref{tab:hard} shows the results of DRA and two additional competing methods under the hard setting. Our method performs best on most of the data subsets and achieves the best AUC performance on five of the six datasets at the dataset level. 
Our method improves from 9.2\% to 24.4\% over the suboptimal method in the other five datasets.

The experimental results in both settings show the superiority of our method compared to Deep SAD and MINNS.



\begin{table}[tb]
  \centering
  \caption{AUC results of DRA and two additional competing methods under the hard setting, where models are trained with one known anomaly class and tested to detect the rest of all other anomaly classes. Each data subset is named by the known anomaly class.}
  \vspace{-0.2cm}
  \scalebox{0.85}{
    \begin{tabular}{p{0.2cm}p{1.92cm}|ccc}
    \hline
    \multicolumn{2}{l}{\textbf{Module}}   & \multicolumn{1}{|c}{\textbf{DeepSAD}} & \multicolumn{1}{c}{\textbf{MINNS}} & \multicolumn{1}{c}{\textbf{DRA (Ours)}} \\ 
    \hline
    \multirow{6}{*}{\rotatebox{90}{\textbf{Carpet}}} & Color & 0.736\footnotesize{±0.007}& 0.767\footnotesize{±0.011}& \textbf{0.886}\footnotesize{±0.042} \\
          & Cut & 0.612\footnotesize{±0.034}& 0.694\footnotesize{±0.068}& \textbf{0.922}\footnotesize{±0.038}\\
          & Hole & 0.576\footnotesize{±0.036}& 0.766\footnotesize{±0.007}& \textbf{0.947}\footnotesize{±0.016}\\
          & Metal & 0.732\footnotesize{±0.042}& 0.789\footnotesize{±0.097}& \textbf{0.933}\footnotesize{±0.022}\\
          & Thread & 0.979\footnotesize{±0.000}& 0.982\footnotesize{±0.008}& \textbf{0.989}\footnotesize{±0.004}\\
          \cline{2-5}
          & \textbf{Mean} & 0.727\footnotesize{±0.011}& 0.800\footnotesize{±0.022}& \textbf{0.935}\footnotesize{±0.013} \\
    \hline
    \multirow{5}[0]{*}{\rotatebox{90}{\textbf{Metal\_nut}}} & Bent & 0.821\footnotesize{±0.023}& 0.868\footnotesize{±0.033}& \textbf{0.990}\footnotesize{±0.003}\\
          & Color & 0.707\footnotesize{±0.028}& \textbf{0.985}\footnotesize{±0.018}& 0.967\footnotesize{±0.011} \\
          & Flip & 0.602\footnotesize{±0.020}& \textbf{1.000}\footnotesize{±0.000}& 0.913\footnotesize{±0.021} \\
          & Scratch & 0.654\footnotesize{±0.004}& \textbf{0.978}\footnotesize{±0.000}& 0.911\footnotesize{±0.034} \\
          \cline{2-5}
          & \textbf{Mean} & 0.696\footnotesize{±0.012}& \textbf{0.958}\footnotesize{±0.008}& 0.945\footnotesize{±0.017}  \\
    \hline
    \multirow{7}[0]{*}{\rotatebox{90}{\textbf{AITEX}}} & Broken\_end & 0.442\footnotesize{±0.029}& \textbf{0.708}\footnotesize{±0.103}& 0.693\footnotesize{±0.099} \\
          & Broken\_pick & 0.614\footnotesize{±0.039}& 0.565\footnotesize{±0.018}& \textbf{0.760}\footnotesize{±0.037} \\
          & Cut\_selvage & 0.523\footnotesize{±0.032}& 0.734\footnotesize{±0.012}& \textbf{0.777}\footnotesize{±0.036}\\
          & Fuzzyball & 0.518\footnotesize{±0.023}& 0.534\footnotesize{±0.058}& \textbf{0.701}\footnotesize{±0.093}\\
          & Nep & 0.733\footnotesize{±0.017}& 0.707\footnotesize{±0.059}& \textbf{0.750}\footnotesize{±0.038} \\
          & Weft\_crack & 0.510\footnotesize{±0.058}& 0.544\footnotesize{±0.183}& \textbf{0.717}\footnotesize{±0.072}\\
          \cline{2-5}
          & \textbf{Mean} & 0.557\footnotesize{±0.014}& 0.632\footnotesize{±0.023}& \textbf{0.733}\footnotesize{±0.009} \\
    \hline
    \multirow{3}[0]{*}{\rotatebox{90}{\textbf{ELPV}}} & Mono & 0.554\footnotesize{±0.063}& 0.557\footnotesize{±0.010}& \textbf{0.731}\footnotesize{±0.021}\\
          & Poly & 0.621\footnotesize{±0.006}& 0.770\footnotesize{±0.032}& \textbf{0.800}\footnotesize{±0.064} \\
          \cline{2-5}
          & \textbf{Mean} & 0.588\footnotesize{±0.021}& 0.663\footnotesize{±0.015}& \textbf{0.766}\footnotesize{±0.029}\\
    \hline
    \multirow{10}[0]{*}{\rotatebox{90}{\textbf{Mastcam}}} 
          & Bedrock & 0.474\footnotesize{±0.038}& 0.419\footnotesize{±0.025}& \textbf{0.658}\footnotesize{±0.021} \\
          & Broken-rock & 0.497\footnotesize{±0.054}& \textbf{0.687}\footnotesize{±0.015}& 0.649\footnotesize{±0.047} \\
          & Drill-hole & 0.494\footnotesize{±0.013}& 0.651\footnotesize{±0.035}& \textbf{0.725}\footnotesize{±0.005}\\
          & Drt & 0.586\footnotesize{±0.012}& 0.705\footnotesize{±0.043}& \textbf{0.760}\footnotesize{±0.033} \\
          & Dump-pile & 0.565\footnotesize{±0.046}& 0.697\footnotesize{±0.022}& \textbf{0.748}\footnotesize{±0.066}\\
          & Float & 0.408\footnotesize{±0.022}& 0.635\footnotesize{±0.073}& \textbf{0.744}\footnotesize{±0.073} \\
          & Meteorite & 0.489\footnotesize{±0.010}& 0.551\footnotesize{±0.018}& \textbf{0.716}\footnotesize{±0.004} \\
          & Scuff & 0.502\footnotesize{±0.010}& 0.502\footnotesize{±0.040}& \textbf{0.636}\footnotesize{±0.086}\\
          & Veins & 0.542\footnotesize{±0.017}& 0.577\footnotesize{±0.013}& \textbf{0.620}\footnotesize{±0.036}\\
          \cline{2-5}
          & \textbf{Mean} & 0.506\footnotesize{±0.009}& 0.603\footnotesize{±0.016}& \textbf{0.695}\footnotesize{±0.004} \\
    \hline
    \multirow{5}{*}{\rotatebox{90}{\textbf{Hyper-Kvasir}}} & Barretts & 0.672\footnotesize{±0.017}& 0.679\footnotesize{±0.009}& \textbf{0.824}\footnotesize{±0.006}\\
          & B.-short-seg & 0.666\footnotesize{±0.012}& 0.608\footnotesize{±0.064}& \textbf{0.835}\footnotesize{±0.021}\\
          & Esophagitis-a & 0.619\footnotesize{±0.027}& 0.665\footnotesize{±0.045}& \textbf{0.881}\footnotesize{±0.035}\\
          & E.-b-d & 0.564\footnotesize{±0.006}& 0.480\footnotesize{±0.043}& \textbf{0.837}\footnotesize{±0.009} \\
          \cline{2-5}
          & \textbf{Mean} & 0.630\footnotesize{±0.009}& 0.608\footnotesize{±0.014}& \textbf{0.844}\footnotesize{±0.009} \\
    \hline
    \end{tabular}}
    \vspace{-0.2cm}
  \label{tab:hard}\end{table}

\subsection{Sensitivity w.r.t. Loss Function}\label{subsec:loss}

\begin{figure}[t]
  \centering
    \includegraphics[width=0.42\textwidth]{figure/loss_bar.pdf}
  \caption{The AUC performance of our proposed method using different loss functions under the hard setting. We report the averaged results over all data subsets per dataset.}
  \label{fig:ana_loss}
\end{figure}

In our paper, we use the deviation loss \cite{pang2021explainable} in all our four heads by default. Here we vary the use of the loss function and analyze the impact of the loss function on the performance of anomaly detection. Any related binary classification loss functions may be used for training all the four heads of DRA.
We evaluate the applicability of two additional popular loss functions, including binary cross-entropy loss and focal loss, in addition to deviation loss. The results are reported in Fig. \ref{fig:ana_loss}, where all results are the averaged AUC of three independent runs of the experiments. 
In general, the deviation loss function, which is specifically designed for anomaly detection, has clear superiority on most cases. The two classification losses perform better on the medical dataset Hyper-Kvasir. Based on such empirical findings, the deviation loss function is generally recommended in DRA.

\subsection{Cross-domain Anomaly Detection}
An interesting extension area of open-set anomaly detection is cross-domain anomaly detection, aiming at training detection models on a source domain to detect anomalies on datasets from a target domain different from the source domain. To demonstrate potential of our method in such setting, we report cross-domain AD results of our model DRA on all five texture anomaly datasets in MVTec AD in Tab. \ref{tab: cross_domain}. DRA is trained on one of five datasets (source domain) and in fine-tuned with 10 epochs on the other four datasets (target domains) using normal samples only. The results show that the domain-adapted DRA significantly outperforms the SOTA unsupervised method KDAD that is directly trained on the target domain. This demonstrates some promising open-domain performance of DRA.
\begin{table}[ht]
\caption{AUC results of domain-adapted DRA and unsupervised method KDAD in texture datasets. The top row is the source domain and the left column is the target domain.}
\centering
\label{tab: cross_domain}
\scalebox{0.85}{
\begin{tabular}{c|cccccc} 
\hline
        & carpet   & grid    & leather   & tile & wood & KDAD    \\ 
\hline
\hline
carpet              & - & 0.833 & 0.921 & 0.930 & 0.917 & 0.774\\ 
\hline
grid                & 0.983 & - & 0.924 & 0.940 & 0.916 & 0.749\\ 
\hline
leather             & 0.988 & 0.998 & - & 0.994 & 1.000 & 0.948\\
\hline
tile                & 0.917 & 0.971 & 0.958 & - & 0.955 & 0.911\\
\hline
wood                & 0.993 & 0.985 & 0.972 & 0.948 & - & 0.940\\
\hline
\end{tabular}}
\label{tab:cross_domain}\end{table}

\section{Failure Cases}
Although DRA shows competitive results on most datasets, it still fails on individual datasets; the most notable is the toothbrush dataset. After in-depth research and analysis of the results, we believe the failure of the toothbrush dataset is mainly due to its small size of normal samples (60 normal samples, see Tab. \ref{tab:stat}). Due to the more complex architecture, DRA often requires a relatively larger set of normal training samples to learn the disentangled abnormalities, while simpler methods like FLOS and SAOE that perform mainly binary classification do not have this requirement and work better on this dataset. In practice, we need to pay attention to the available data size of the target task, and apply a lightweight network in DRA instead when facing small-scale tasks.


\end{document}
