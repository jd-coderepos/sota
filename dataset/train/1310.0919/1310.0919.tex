\documentclass[a4paper]{llncs}
\usepackage{graphicx,latexsym}

\newcommand{\lnon}{\overline}

\begin{document}

\title{On the Parameterized Complexity of Associative and Commutative Unification\thanks{
This work was partially supported by the Collaborative Research Programs
of National Institute of Informatics.}}
\titlerunning{}

\author{Tatsuya Akutsu\inst{1}
\and Takeyuki Tamura\inst{1}
\and 
Atsuhiro Takasu\inst{2}}

\institute{Bioinformatics Center, Institute for Chemical Research,
Kyoto University,\\
Gokasho, Uji, Kyoto, 611-0011, Japan.\\
\email{\{takutsu, tamura\}@kuicr.kyoto-u.ac.jp}\\
\and
National Institute of Informatics, Tokyo 101-8430, Japan.\\
\email{takasu@nii.ac.jp}}

\maketitle

\begin{abstract}
This paper studies the unification problem with
associative, commutative, and associative-commutative functions mainly
from a viewpoint of the parameterized complexity on the number of
variables.
It is shown that
both associative and associative-commutative unification problems
are -hard.
A fixed-parameter algorithm and a polynomial-time algorithm are presented for
special cases of commutative unification in which
one input term is variable-free and the number of variables is bounded by 
a constant, respectively.
Related results including those on
the string and tree edit distance problems with variables are shown too.
\keywords{unification, parameterized algorithms, dynamic programming, tree edit distance.}
\end{abstract}

\section{Introduction}

\emph{Unification} plays an important role in various areas of computer science,
including theorem proving, logic programming, natural language processing,
and database query systems \cite{kapur92,knight89}.
The unification problem is, in the fundamental form,
to find a substitution for variables that will make the two given
terms identical, where terms are built up from function symbols, 
variables, and constants \cite{knight89}.
For example, two terms  and  become identical
by substituting  and  by  and , respectively.
If one input term contains no variable, the problem is called \emph{matching}.

Although unification has a long history beginning from a seminal work by
Herbrand in 1930 (e.g., see \cite{knight89}),
it is becoming important again because 
math search recently attracts researchers in information retrieval
(IR) community \cite{kamali10,kim12,nguyen12}.
For example, math search is adopted as a pilot task in an IR evaluation
conference
NTCIR \footnote{http://research.nii.ac.jp/ntcir/ntcir-10/conference.html}.
The math search is a sort of IR task to retrieve documents
containing mathematical formulas
and/or formulas themselves similar to a query.
Several systems have been developed such as
Wolfram Formula Search\footnote{http://functions.wolfram.com/formulasearch} and
formula search for Wikipedia\footnote{ http://shinh.org/wfs/}.
Since mathematical formulas are usually represented
with tree structures, structural similarity is important
to measure the similarity between formulas.
Approximate tree matching \cite{bille05} is
a key to measure the similarity.
However, when measuring the similarity between mathematical formulas,
we need to unify substitution of variables.
For example, a query  has same similarity to formulas
 and  by tree edit distance,
although these two formulas are mathematically different.
Therefore, approximate tree matching is not enough and 
combination with unification is strongly needed.

Returning to unification, many variants have been proposed
\cite{benanav87,kapur92,knight89}.
Among them, unification with commutative and associative functions
are important from the viewpoint of math search
because many functions satisfy either one or both of these two properties,
where functions satisfying  and 
are called \emph{commutative} and \emph{associative}, respectively.

Extensive studies have been done on the computational complexity
of various unification problems.
For the fundamental one, beginning from Robinson's exponential time
algorithm \cite{robinson65},
a linear time algorithm was finally developed \cite{paterson78}.
However, all of associative, commutative, and associative-commutative
unification (and matching) problems are known to be
NP-hard \cite{benanav87,eker02,kapur92}.
Polynomial time algorithms are known only for very restricted cases
\cite{aikou05,benanav87,kapur92}.
For example, it is known that associative-commutative matching
can be done in polynomial time if
every variable occurs only once \cite{benanav87}.
From a practical viewpoint, many studies have been done on
various extensions of unification.
Furthermore, combination with approximate tree matching 
has been studied \cite{gilbert00,iranzo10}.
However, these are heuristic algorithms.

In this paper, we study associative, commutative, and associative-commutative
unification mainly from a viewpoint of parameterized complexity on
the number of variables because
the number of variables is often much smaller than the size of terms.
We show the following results along with related results:
(i) both associative and
associative-commutative matching problems are -hard,
(ii) both associative and associative-commutative unification 
can be done in polynomial time if every variable occurs only once,
(iii) commutative matching can be done in  time
where  is the number of variables and  are the size of
input terms,
(iv) commutative unification can be done in polynomial time
if the number of variables is bounded by a constant.
In addition, we show that 
both the string and tree edit distance problems with variables 
are -hard.
All algorithms presented in this paper simply decide whether two terms
are unifiable and do not output the corresponding substitutions.
However, the algorithms can be modified to output such substitutions
(when unifiable)
by using the standard \emph{traceback} technique.

\section{String Edit Distance with Variables}

Let  be an alphabet and  be a set of variables,
where we mainly consider  that is defined as
the set of variables appearing in the input.
A string is a sequence of symbols over .
Let  be a \emph{substitution},
which is a mapping from  to .
For a string , let  denote the string over 
obtained by replacing all occurrences of variables 
by .
We call two strings  and  are \emph{unifiable}
if there exists a substitution  such that
.

\begin{example}
Let , , and ,
where .
Then,  and  are unifiable since
 holds
by .\footnote{ means that  is substituted by
.}
However,  and  are not unifiable since there does not exist
 such that .
\end{example}

For string  and integer ,  denotes the -th character of ,
 denotes , and
 denotes the length (i.e., the number of characters) of .
For two strings  and  (including the case of  and/or  are
single characters),
 denotes the string obtained by concatenating  and .
An {\it edit operation on a string}  over  is either
a {\it deletion}, an {\it insertion}, 
or a {\it replacement} of a character of  \cite{bodlaender95}.\footnote{
Usually, `substitution' is used instead of `replacement'.
However, we use `replacement' in order to discriminate
from `substitution' in unification.}
The {\it edit distance between two strings}  and  over 
is defined as
the minimum number of operations to transform  to ,
where we consider unit cost operations here.
Let  denote the edit distance 
between  and .
From the definition, 
  
holds where  is a sequence of edit operations.
For example,  because  is obtained from
 by deletion of , replacement of  to , and insertion of . 
We also define the edit distance 
between two strings over 
by

This variant of edit distance is called \emph{edit distance with variables}.
Although it is well known that  can be computed
in polynomial time, computation of  is -hard
as shown below.

\begin{theorem}
The edit distance problem with variables is -hard with respect to
the number of variables even if the number of occurrences of each variable
is bounded by 3.
\label{thm:edhard}
\end{theorem}
\begin{proof}
We present an \emph{FPT-reduction} \cite{flum06}
from the longest common subsequence problem (LCS).
LCS is, given a set of strings  over  and 
an integer ,
to decide whether there exists a string  of length 
that is a subsequence of each string .
where  is called a \emph{subsequence} of  if  is obtained by
deletion operations from .
It is known that LCS is -hard
for parameters  and  \cite{bodlaender95}.

First we consider the case in which there is no constraint on the number
of occurrences of variables.
From an instance of LCS, we construct an instance of
edit distance with variables as follows.
Let  and ,
where  is a symbol not appearing in .
We construct  and  by

where  appears  times in .
Then, we can see that
there exists an LCS of length  iff

(i.e., there exists  such that  is a subsequence of
).
Since the number of variables appearing in this instance is ,
it is an FPT reduction.
The proof for the case of the bounded number of occurrences 
is given in Appendix A1.
\qed
\end{proof}

If each variable occurs only once, then the problem is equivalent
to approximate string matching with don't care characters,
which can be solved in polynomial time \cite{akutsu95}.
It should be noted that if an alphabet  is fixed,
the number of possible  is bounded by ,
where .
Therefore, we have a fixed-parameter algorithm with parameter 
for a fixed alphabet.

\begin{proposition}
The edit distance problem with variables can be solved in\\
 time where  is the number of variables
and  and  are the size of input strings.
\end{proposition}


\section{Unification}

In order to define unification,
we regard  as a set of function symbols, where 
arity (i.e., the number of arguments) is associated with each symbol.
We call a function symbol with arity 0 a \emph{constant}.
We define a \emph{term} as follows:
\begin{itemize}
\item a constant is a term,
\item a variable is a term,
\item if  are terms and
 is a function symbol with arity ,
 is a term.
\end{itemize}
We identify each term  with a rooted ordered tree where
each node corresponds to a function symbol and each leaf
corresponds to a constant.
For a term ,  denotes the set of nodes in a tree ,
 denotes the root of ,
and  denotes the function symbol of .
For a node ,  denotes a subterm (i.e., subtree)
of  rooted at .
The \emph{size} of  is defined as .

Let  be a set of terms over  and .
Then, a \emph{substitution}  is defined as 
a (partial) mapping from  to ,
where  must not contain a variable  if .
For a term  and a substitution ,
 is the term obtained by simultaneously replacing
variables according to .
We say that terms  and  are \emph{unifiable}
if there exists  such that .
Such  is called a \emph{unifier}.
In this paper, the unification problem is to decide
whether two given terms are unifiable and output a unifier
if unifiable.\footnote{In the standard case, it is required to
output the most general unifier (mgu). However, in most variants
considered in this paper, there does not exist mgu.}
It is well-known that the unification problem can be solved in
linear time \cite{paterson78}.
A special case of the unification problem in which  is
variable-free is called a \emph{matching} problem.
If every variable (resp., a variable ) occurs in a term  only once,
the term (resp., the variable) is called a \emph{DO-term} (resp.,
\emph{DO-variable}), where DO means distinct occurrence(s) \cite{benanav87}.
Unless otherwise stated,  and  denote the size of two input terms 
 and .


\begin{example}
Let ,
,
,
,
,
where .
 and  are unifiable since 
 holds for
.
 and , and  and  are also unifiable since 
 and
 hold for
 and
, respectively.
 is not unifiable to , , or .
 is unifiable to , but is not unifiable to
 (or ) because it is impossible to simultaneously satisfy
 and .\footnote{This kind of matching can be avoided by
\emph{occur check}.}
\end{example}

As in the case of string edit distance,
we can combine \emph{tree edit distance} \cite{bille05}
with unification.
Let  denote the tree edit distance where
the distance can be for both ordered and unordered trees.
Then, we define the tree edit distance 
between two trees (i.e., two terms) over 
by

By combining the proofs of Thm.~\ref{thm:edhard} and
Thm.~\ref{thm:asohard}, we have:

\begin{theorem}
The tree edit distance problem
with variables is -hard for both ordered and unordered trees
with respect to
the number of variables for a fixed alphabet even if
the number of occurrences of each variable is bounded by 3.
\label{thm:tree-ed-hard}
\end{theorem}

We also have the following theorem as in several matching problems
\cite{benanav87},
where the proof is given in Appendix A2.\footnote{
The original (i.e., variable-free) edit distance problem is known to NP-hard
for unordered trees \cite{bille05}.}

\begin{theorem}
The ordered tree edit distance problem with variables
can be solved in polynomial time for DO-terms.
\label{thm:tree-ed-do}
\end{theorem}

\section{Associative Unification}

A function  is called \emph{associative} if
 always holds.
Associative unification is a variant of unification
in which some functions are associative.
In this section, we assume that all functions are associative
although all the results are valid even if usual functions are included.

It is shown that associative matching is NP-hard \cite{benanav87}.
However, the proof in \cite{benanav87} does not work to show
the parameterized hardness.

\begin{theorem}
Associative matching is -hard with respect to the number of variables
even for a fixed .
\label{thm:asohard}
\end{theorem}
\begin{proof}
As in the proof of Thm.~\ref{thm:edhard},
we use a reduction from LCS (see also Fig.~\ref{fig:asohard}).

First we consider an infinite alphabet.
Let  be an instance of LCS.
For each , we create a term  by

where  is a character not appearing in .
We create a term  by concatenating , which can be done
by replacing the last occurrence of  of each
 by  for .
Then, we transform each  into a string  of length
 by inserting a special character  
in front of each character in , and appending 
at the end of ,
where each  is considered as a distinct constant
(i.e.,  cannot match any symbol, but can match any variable).
We represent each  by a term  given as

We create a term  by concatenating .

\begin{figure}[ht]
\begin{center}
\includegraphics[width=7cm]{uniffig1.eps}
\caption{Example of a reduction for the case of , ,
and  in the proof of Thm.~\ref{thm:asohard}.}
\label{fig:asohard}
\end{center}
\end{figure}

Then, we can see that  and  are unifiable
iff there exists an LCS of length .
Since the number of variables in  is ,
it is an FPT-reduction and thus the problem is -hard.

Finally, we represent each constant by a distinct term using
a function symbol  and binary-encoding 
(e.g., 10-th symbol (among 16 symbols) can be represented as
 ).
\qed
\end{proof}

Next, we consider associative unification for DO-terms,
where it has some similarity with DO-associative-commutative matching
\cite{benanav87}.
We begin with the simplest case in which each term does not
contain a variable.

\begin{proposition}
Associative unification can be done in polynomial time if
there exists no variable.
\end{proposition}
\begin{proof}
We transform each input term into its \emph{canonical form} in which 
consecutive and same function symbols are simplified into one symbol.
For example, both  and 
are transformed into .
Since  and  means ,
it is enough to test the isomorphism of the canonical forms in order to
examine .
Since the rooted ordered tree isomorphism between the resulting
canonical forms can be trivially tested in linear time,
we have the proposition.
\qed
\end{proof}

In order to treat DO-terms,
we transform terms  and  into their canonical forms  and .
Then, we apply the following procedure to  and 
(see also Fig.~\ref{fig:asopoly}),
where it returns `true' iff  and  are unifiable, and
 iff  and  are unifiable.
It is to be noted that step (\#) can be done in constant time because
 and  are unifiable there iff
these are the same constant or one of  and  is a variable.

\begin{rm}
\begin{tabbing}
\quad \= \quad \= \quad \= \quad \= \quad \= \quad \= \quad \= \kill
\> Procedure \\
\> \> {\bf for all}  {\bf do}~~~~~~~~~~~~~~~~~~~~~~~~~/* in post-order */ \\
\> \> \> {\bf for all}  {\bf do}~~~~~~~~~~~~~~~~~~~~~~/* in post-order */ \\
\> \> \> \> {\bf if}  or  is a constant {\bf then}\\
\> \> \> \> \> {\bf if}  and  are unifiable ~~~~~~~~~~~~~~~~~~~~~~-(\#) \\
\> \> \> \> \> {\bf then}  {\bf else} 
;\\
\> \> \> \> {\bf else if}  or  is a variable {\bf then}\\
\> \> \> \> \> ;\\
\> \> \> \> {\bf else}~~~/* ,
 */\\
\> \> \> \> \> {\bf if}  and 
 can match   \\
\> \> \> \> \> {\bf then}  {\bf else} ; \\
\> \> {\bf if} 
{\bf then} {\bf return} true {\bf else} {\bf return} false.
\end{tabbing}
\end{rm}

Match of  
and  can be tested in
polynomial time by regarding each of these two sequences as a string
and applying string matching with variable length don't cares
\cite{akutsu96} with setting the difference to be 0 and allowing don't
care characters appear in both strings,
where
 (resp., ) is regarded as a don't care symbol
that can match any substring of length at least 1 if it is a variable,
otherwise  can match  iff 
(see Appendix A3 for the details).
Since for-loops are repeated  times and
string matching with variable length don't cares can be done in polynomial time,
we have:

\begin{theorem}
Associative unification for DO-terms can be done in polynomial time.
\label{thm:asspoly}
\end{theorem}

\begin{figure}[ht]
\begin{center}
\includegraphics[width=11cm]{uniffig2.eps}
\caption{Illustration of associative unification for DO-terms  and .
 and  are transformed into  and ,
which are then unified by
.}
\label{fig:asopoly}
\end{center}
\end{figure}

We can also consider another variant in which
 can contain a constant number of non-DO variables
but  cannot contain any variable.
Let  be the set of non-DO variables in .
We examine all possible mappings from  to the set of
consecutive children of each node in the canonical form  of .
If we apply such a mapping, all occurrences of variables in 
are replaced by terms without variables.
Then, we can apply  to the resulting terms.
Since the number of mappings is clearly ,
we have:

\begin{corollary}
Associative matching can be done in polynomial time 
if  contains a constant number of non-DO terms and
any number of DO-terms.
\label{cor:asspoly}
\end{corollary}


\section{Commutative Unification}

A function  is called \emph{commutative} if
 always holds.
Commutative unification is a variant of unification
in which some functions are commutative.
It is known that 
even commutative matching
is NP-hard (by a reduction from 3SAT) \cite{benanav87}.
In this section,
we present a parameterized algorithm for commutative matching
and a polynomial-time algorithm for commutative unification
with a bounded number of variables.

First we note that commutative unification can be done in polynomial time
if both  and  are variable-free because it is equivalent to
the rooted unordered tree isomorphism problem.

\begin{proposition}
Commutative unification can be done in polynomial time
if both  and  are variable-free.
\end{proposition}

Next we consider commutative matching.
We construct a 0-1 table  for node pairs

by applying dynamic programming in a bottom-up manner,
where  iff  is unifiable to .
It is enough to construct such table entries only for pairs
with the same depth.
We also construct a table , where each element
holds a set of possible substitutions 
such that .

Let  and
 be
substitutions.
 is said to be \emph{compatible} with
 if there exists no variable  such that
 but 
.
Let  and  be sets of substitutions.
We define  by

For a node ,  and  denote the left and right children of
, respectively.

\begin{rm}
\begin{tabbing}
\quad \= \quad \= \quad \= \quad \= \quad \= \quad \= \quad \= \kill
\> Procedure \\
\> \> {\bf for all} pairs  with the same depth\\
\> \> {\bf do} \hspace{6cm} /* in a bottom-up way */ \\
\> \> \> {\bf if}  is a variable {\bf then} \\
\> \> \> \> ;
 \\
\> \> \> {\bf else if}  does not contain a variable {\bf then}\\ 
\> \> \> \> ; \\
\> \> \> \> {\bf if}  {\bf then} 
{\bf else}  \\
\> \> \> {\bf else if}  {\bf then}\\
\> \> \> \> ;  \\
\> \> \> {\bf else} \\
\> \> \> \> ; ; \\
\> \> \> \> {\bf for all}  {\bf do} ~~~~~ -(\#)\\
\> \> \> \> \> {\bf if}  and  and
\\
\> \> \> \> \> {\bf then} ;
;\\
\> \> {\bf if}  {\bf then return} true {\bf else return} false.
\end{tabbing}
\end{rm}


\begin{theorem}
Commutative matching can be done in  time where
 is the number of variables in .
\end{theorem}
\begin{proof}
The correctness follows from the observation that
each variable is substituted by a term without variables and
 is taken into account at step (\#).

In order to analyze the time complexity,
we consider the size (i.e., the number of elements) 
of .
An important observation is that
if  does not
contain a variable,
 holds
(an analogous property holds for ).
Let  denote the maximum size of  when
the number of (distinct) variables in  is .
Then, we can see that the following relations hold:

from which  follows.
Therefore, computation of
 can be done in
 time by using `sorting' as in usual `join' operations.
Then, we can see that the total computation time is also
.
\qed
\end{proof}

Next, we consider the case where both  and  contain variables.
As in the case of linear time unification \cite{paterson78},
we assume that two variable free terms  and 
are represented by a DAG (directed acyclic graph) ,
where  and  respectively correspond to  and  
of indegree 0 ().
Then, whether  and  represent the same term can be tested 
in polynomial time with respect to the size of 
by using the following procedure, where  denotes the term
corresponding to a node  in .

\begin{rm}
\begin{tabbing}
\quad \= \quad \= \quad \= \quad \= \quad \= \quad \= \quad \= \quad \= \quad \= \kill
\> Procedure \\
\> \> {\bf for all}  {\bf do}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~/* in post-order */\\
\> \> \> {\bf for all}  {\bf do}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~/* in post-order */\\
\> \> \> \> {\bf if}  {\bf then} ; {\bf continue};\\
\> \> \> \> {\bf if}  or  is a constant {\bf then} \\
\> \> \> \> \> {\bf if}  {\bf then}  {\bf else} ;\\
\> \> \> \> {\bf else}\\
\> \> \> \> \> Let  and ; \\
\> \> \> \> \> {\bf if}  {\bf then}\\
\> \> \> \> \> \> {\bf if} ( and ) or \\
\> \> \> \> \> \> \> \> \> ( and ) \\
\> \> \> \> \> \> {\bf then}  {\bf else} \\
\> \> \> \> \> {\bf else} ;\\
\> \> {\bf if}  {\bf then} {\bf return} true {\bf else} {\bf return} false.
\end{tabbing}
\end{rm}

In order to cope with terms with variables,
we consider all possible mappings from the set of variables to
.
For each mapping,
we replace all appearances of the variables by the corresponding nodes,
resulting in a DAG to which we can apply .
The following is a pseudo-code of the procedure for terms with variables.

\begin{rm}
\begin{tabbing}
\quad \= \quad \= \quad \= \quad \= \quad \= \quad \= \quad \= \kill
\> Procedure \\
\> \> {\bf for all} mappings  from a set of variables to nodes in  and  {\bf do} \\
\> \> \> {\bf if} there exists a directed cycle (excluding a self-loop) {\bf then} {\bf continue};\\
\> \> \> Replace each variable having a self-loop with a distinct constant symbol;\\
\> \> \> Replace each occurrence of a variable node  with node ;\\
\> \> \> \> \> \> /* if   and ,  is replaced by  */\\ 
\> \> \> Let  be the resulting DAG;\\
\> \> \> Let  and  be the nodes of  corresponding to  and ;\\
\> \> \> {\bf if} true {\bf then} {\bf return} true;\\
\> \> {\bf return} false.
\end{tabbing}
\end{rm}

\noindent
Then, we have the following, where the proof is given in Appendix A4.

\begin{theorem}
Commutative unification can be done in polynomial time
if the number of variables in  and  is 
bounded by a constant.
\label{thm:com-unif-poly}
\end{theorem}

\section{Associative-Commutative Unification}

Associative-commutative unification is a variant of unification
in which some functions can be both associative and commutative.
We show that associative-commutative matching is
-hard even if all every function is associative and commutative,
where the proof is a bit involved and is given in Appendix A5.

\begin{theorem}
Matching is -hard with respect to the number of variables
even if every function symbol is associative and commutative.
\label{thm:ac-hard}
\end{theorem}

It is shown in \cite{benanav87} that associative-commutative matching
can be done in polynomial time if  is a DO-term.
We can extend their algorithm as below.
For extension, it is enough to add a condition in their algorithm that
 and
 can be unified
if  and  are variables for some .

\begin{proposition}
Associative-commutative unification
can be done in polynomial time if both  and  are DO-terms.
\label{prop:do-ac-unif}
\end{proposition}

\begin{thebibliography}{99}

\bibitem{aikou05}
Aikou, K., Suzuki1, Y., Shoudai, T., Uchida, T., Miyahara, T.:
A polynomial time matching algorithm
of ordered tree patterns having height-constrained variables.
In: CPM 2005. LNCS, vol. 3537, pp. 346--357.
Springer, Heidelberg (2005)

\bibitem{akutsu95}
Akustu, T.:
Approximate string matching with don't care characters.
Information Processing Letters 55, 235--239 (1995)

\bibitem{akutsu96}
Akustu, T.:
Approximate string matching with variable length don't care characters,
IEICE Trans. Information and Systems E79-D, 1353--1354 (1996)


\bibitem{benanav87}
Benanav, D., Kapur, D., Narendran, P.:
Complexity of matching problems.
Journal of Symbolic Computation 3, 203--216 (1987)

\bibitem{bille05}
Bille, P.:
A survey on tree edit distance and related problem.
Theoretical Computer Science 337, 217--239 (2005)

\bibitem{bodlaender95}
Bodlaender, H.L., Downey, R.G., Fellows, M.R., Wareham, H.T.:
The parameterized complexity of sequence alignment and consensus.
Theoretical Computer Science 147, 31--54 (1995)


\bibitem{eker02}
Eker, S.:
Single elementary associative-commutative matching.
Journal of Automated Reasoning 28, 35--51 (2002)

\bibitem{flum06}
Flum, J., Grohe, M.:
Parameterized Complexity Theory.
Springer, Berlin (2006)

\bibitem{gilbert00}
Gilbert, D., Schroeder, M.:
FURY: fuzzy unification and resolution based on edit distance.
In: Proc. 1st IEEE International Symposium on Bioinformatics
and Biomedical Engineering, pp. 330--336 (2000)

\bibitem{iranzo10}
Iranzo, P.J., Rubio-Manzano, C.:
An efficient fuzzy unification method and its implementation
into the Bousi~Prolog system.
In: Proc. 2010 IEEE International Conference on Fuzzy Systems,
pp. 1--8 (2010)

\bibitem{kamali10}
Kamali, S., Tompa, F.W.:
A new mathematics retrieval system.
In: Proc. ACM Conference on Information and Knowledge Management,
pp. 1413--1416 (2010)

\bibitem{kapur92}
Kapur, D., Narendran, P.:
Complexity of unification problems with associative-commutative operators.
Journal of Automated Reasoning 28, 35--51 (2002)

\bibitem{kim12}
Kim, S., Yang, S., Ko, Y.:
Mathematical equation retrieval using plain words as a query.
In: Proc. ACM Conference on Information and Knowledge Management,
pp. 2407--2410 (2012)

\bibitem{knight89}
Knight, K.:
Unification: a multidisciplinary survey.
ACM Computing Surveys 21, 93--124 (1989)


\bibitem{nguyen12}
Nguyen, T.T., Chang, K., Hui, S.C.:
A Math-aware search engine for math question answering system.
In: Proc. ACM Conference on Information and Knowledge Management,
pp. 724--733 (2012)

\bibitem{paterson78}
Paterson, M.S., Wegman, M.N.:
Linear unification.
Journal Computer and System Sciences 16, 158--167 (1978)

\bibitem{robinson65}
Robinson, J.A.:
A machine-oriented logic based on the resolution principle.
J. ACM 12, 23--41 (1965)

\end{thebibliography}



\newpage

\section*{Appendix}

\subsection*{A1. Latter Part of the Proof of Theorem~\ref{thm:edhard}}

Next we consider the case in which the number of occurrences of each
variable is bounded by 3.
For that purpose, we rename -th occurrence of  in 
by  and then we append  and
 to the end of  and , respectively,
where  and  are defined as follows:

Let the resulting strings be  and .
Then, it is seen that
there exists an LCS of length  iff
.
Since the number of variables is , which is still a polynomial of
 and , it is an FPT reduction.
\qed

\subsection*{A2. Proof of Theorem~\ref{thm:tree-ed-do}}

Let  and  be ordered forests.
Let  (resp., ) be the rightmost tree
of  (resp., ).
It is well-known \cite{bille05} that
the rooted ordered tree edit distance can be
computed by the following dynamic programming procedure:

where  is a delta function
(i.e., , otherwise ),
 denotes the empty tree,
 (resp., ) denotes the forest obtained by deleting  (resp., )
from , and  gives the required edit distance.
In order to cope with DO-variables,
it is enough to add the following in taking the minimum at the recursion
of computing :

Then, it is clear that
the order of the time complexity is the same (i.e., )
as that of the original one.
\qed

\subsection*{A3. String Matching with Variable Length Don't Cares}

Let  and  be strings including
variables length don't care characters `*'.
The following is a pseudo-code for deciding whether  matches ,
where  iff  matches .

\begin{rm}
\begin{tabbing}
\quad \= \quad \= \quad \= \quad \= \quad \= \quad \= \quad \= \kill
\> Procedure \\
\> \> {\bf for all}  {\bf do} 
;\\
\> \> ;\\
\> \> {\bf for}  {\bf to}  {\bf do}\\
\> \> \> {\bf for}  {\bf to}  {\bf do}\\
\> \> \> \> {\bf if}  and  {\bf then}\\
\> \> \> \> \>  \\
\> \> \> \> {\bf else if}  {\bf then}
\\
\> \> \> \> {\bf else if}  {\bf then}
\\
\> \> \> \> {\bf else} if  matches  {\bf then}
\\
\> \> \> \> {\bf else} 
;\\
\> \> {\bf if}  {\bf then} {\bf return} true {\bf else} {\bf return} false.
\end{tabbing}
\end{rm}

It is obvious that this algorithm works in  time.

\subsection*{A4. Proof of Theorem~\ref{thm:com-unif-poly}}

The correctness of  follows from the fact
that  matches  iff
 and  are the identical function symbols and
either  matches  or 
 matches .
It is clear that this procedure works in  time.
Therefore, commutative match of two variable-free terms can be tested in 
polynomial time.

Next we consider the correctness of 
(see also Fig.~\ref{fig:dag}).
It is straight-forward to see that if there exists  which returns `true',
 and  are commutatively unifiable and such a mapping
gives a substitution  satisfying .
Conversely, suppose that
 and  are commutatively unifiable.
Then,
there exist unifiable non-commutative terms  and 
that are obtained by exchanging
left and right arguments in some terms in  and .
Let  be the substitution satisfying .
Then,  holds.
We assign distinct constants to variables appearing in .
We also construct a mapping from the remaining variables to 
by regarding  as a mapping of  to .
We construct  according to this mapping.
Then, it is obvious that true holds.

Since the number of possible mappings is bounded by 
where  is the number of variables in  and ,
 works in polynomial time.
\qed

\begin{figure}[ht]
\begin{center}
\includegraphics[width=8cm]{uniffig3.eps}
\caption{Example of DAG  for the algorithm and proof of Theorem~\ref{thm:com-unif-poly}.}
\label{fig:dag}
\end{center}
\end{figure}

\subsection*{A5. Proof of Theorem~\ref{thm:ac-hard}}

We show an FPT-reduction from LCS.
Let  be an instance of LCS
where  is a set of strings and  is an integer.

Different from the previous proofs,
we cannot represent the order of letters directly.
Therefore, we represent the position of each letter by
the size of the corresponding term.

Let  be distinct functional symbols
and  be a constant not appearing in .
For each ,
we define the term  by

Then, we define the term  by


Next, we define the term  (,  by

where  and s are variables.
Then, we define  () and  by

where  is a variable.

We show that  and  are unifiable if and only if
LCS of  has length at least .
First we show the `if' part.
Let  be a common subsequence of  such that .
We consider a partial substitution  defined by

Then, it is straight-forward to see
that  can be extended to a substitution  such
that .

Conversely, suppose that there exists a substitution  satisfying
.
We can see from the construction of  and  that
if  matches  and  matches 
for some  where ,
then  must hold.
Let  ().
Then, we can see from the above property that
 is a common subsequence of .

Since the reduction can be done in polynomial time and
the number of variables is bounded by a polynomial of  and ,
the theorem holds.
\qed

\end{document}
