\pdfoutput=1











\documentclass[journal,12pt, onecolumn]{IEEEtran}

\usepackage{setspace}
\doublespacing

\ifCLASSINFOpdf
\else
\usepackage[dvips]{graphicx}
\DeclareGraphicsExtensions{.eps}
\fi
\usepackage{amsthm}


\newtheorem{pr}{Proposition}
\newtheorem{co}{Collolary}
\newtheorem{lemma}{Lemma}
\newtheorem{df}{Definition}
\newtheorem{thm}{Theorem}


\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
\graphicspath{{../pdf/}{../jpeg/}}
\DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
\usepackage[dvips]{graphicx}
\graphicspath{{../eps/}}
\DeclareGraphicsExtensions{.eps}
\fi





\usepackage{tikz}
\usetikzlibrary{shapes, arrows, patterns}
\newcommand{\squeezeup}{\vspace{-2.5mm}}


\usepackage{amsmath,amsthm,amssymb}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{dsfont}
\usepackage{enumerate}
\usetikzlibrary{calc}






\usepackage{stfloats}

















\usepackage[tight,footnotesize]{subfigure}
















\usepackage{caption}


\captionsetup{font=small,labelfont=footnotesize}


\usepackage{multirow}
\newcommand{\tp}{\intercal}		\newcommand{\R}{\mathbb{R}}			\newcommand{\Z}{\mathbb{Z}}			\newcommand{\C}{\mathbb{C}}			\newcommand{\ord}{\mathcal{O}}		\newcommand{\eqt}{\buildrel\smash{\smash t}\over =}
\newcommand{\geqt}{\buildrel\smash{\smash t}\over \geq}
\newcommand{\gt}{\buildrel\smash{\smash t}\over >}

\DeclareMathOperator{\norml}{\mathcal{N}}		\DeclareMathOperator{\ee}{\mathbb{E}}			\DeclareMathOperator{\prob}{\mathbb{P}}			\DeclareMathOperator{\vecc}{\mathbf{vec}}		\DeclareMathOperator{\tr}{\mathbf{tr}}			\DeclareMathOperator{\cov}{\mathbf{cov}}		





\hyphenation{op-tical net-works semi-conduc-tor}




\begin{document}

 
\title{LORD: Leader-based framework for Resource Discovery in Mobile Device Clouds
}


\author{Seyed~Mohammad~Asghari,~Yi-Hsuan~Kao,~Mohammad~Hassan~Lotfi, \\Mohammad~Noormohammadpour,~Bhaskar~Krishnamachari, \\
~Babak~Hossein~Khalaj, and Marcos~Katz
\thanks{
S. M. Asghari, Yi-Hsuan Kao, M. Noormohammadpour, Bhaskar~Krishnamachari are with the Department of Electrical Engineering, University of Southern California, Los Angeles, CA, USA
(e-mail:\{asgharip, yihsuank, noormoha, bkrishna\}@usc. edu)}
\thanks{
M. H. Lotfi is with the Department of Electrical and System Engineering, University of Pennsylvania, Pennsylvania, USA (e-mail: lotfm@seas.upenn.edu).}
\thanks{
B. H. Khalaj is with the Department of Electrical Engineering, Sharif University of Technology, Tehran, Iran (e-mail: khalaj@sharif.edu).}
\thanks{
M. Katz is with the Department of Electrical Engineering, University of Oulu, Oulu, Finland (e-mail: mkatz@ee.oulu.fi).
}}



























\maketitle


\begin{abstract}
We provide a novel solution for Resource Discovery (RD) in mobile device clouds consisting of selfish nodes. Mobile device clouds (MDCs) refer to cooperative arrangement of communication-capable devices formed with resource-sharing goal in mind. Our work is motivated by the observation that with ever-growing applications of MDCs, it is essential to quickly locate resources offered in such clouds, where the resources could be content, computing resources, or communication resources. The current approaches for RD can be categorized into two models: decentralized model, where RD is handled by each node individually; and centralized model, where RD is assisted by centralized entities like cellular network. However, we propose LORD, a Leader-based framewOrk for RD in MDCs which is not only self-organized and not prone to having a single point of failure like the centralized model, but also is able to balance the energy consumption among MDC participants better than the decentralized model. 
Moreover, we provide a credit-based incentive to motivate participation of selfish nodes in the leader selection process, and present the first energy-aware leader selection mechanism for credit-based models.
The simulation results demonstrate that LORD balances energy consumption among nodes and prolongs overall network lifetime compared to decentralized model.

\end{abstract}









\section{Introduction}
According to Gartner \cite{xx1}, smartphone sales have surpassed one billion units in 2014. All such devices are typically equipped with multiple types of wireless networking interfaces especially Wi-Fi. By taking advantage of traditional device to device communications (e.g., Wi-Fi direct \cite{x37}, and Bluetooth), devices are able to communicate directly with each other without assistance of any access points or involvement of network operators. 
Throughout this paper, we use the term \textit{Mobile Device Cloud (MDC)} \cite{x334}, \cite{x335} for the cooperative arrangement of these communication-capable devices, which is formed with the resource sharing goal in mind. The resources can include content (e.g., music, photo, and video files) \cite{xx4}, computing resources \cite{xx7}, and communication resources (e.g., communication link to LTE network) \cite{xx3}. In MDC environments, computational offloading is performed by means of a set of mobile devices instead of remote cloud resources. 


Despite the advantages of MDCs, a number of key problems should be addressed before they can be realized in practice. One of the most important issues is resource discovery (RD), i.e., identifying which resources are offered in such MDCs and also how to obtain them. 
As an example, consider a situation where a client wants to solve engineering problems or process photos and video files, yet it is unable to perform this task individually either due to lack of enough battery life or because of the fact that the computing requirements of such a task outstrip what his device is able to accomplish. However, there are often a large number of nearby smartphones which remain unused most of the time. Smartphones now have powerful processors (e.g., Dual-core 1.4 GHz Cyclone and PowerVR GX6450 of iPhone 6), powerful operating systems (e.g., Apple iOS and Google Android), remarkable battery life, and plentiful memory that make them appropriate for processing tasks.
This client can offload his task to one (or more) near device(s) and hence, it needs to discover which devices can offer computing resources.

The current approaches for RD can be categorized into two models: decentralized and centralized. 
In the decentralized model, each node is responsible for RD itself; however, in the centralized one, RD is handled by one server. As an example of centralized model, a network-assisted device to device communication has been proposed in \cite{x53} where LTE network can act as the server.
Although centralized models have significant advantages in comparison with decentralized one (e.g., lower communication overhead, lower RD delay, more suited to dynamic environments \cite[and references therein]{x14}), they suffer from the important drawback of having a critical point of failure \cite{x14}. In case of the model proposed in \cite{x53}, such failures can be due to the fact that the devices have no access to the LTE network, or the Base Transceiver Station (BTS) operation is disrupted.  


The centralized model does not suit very well MDC environments that lack a predefined organization and where accessibility of nodes to an external server (e.g. via LTE connection) can be intermittent. On the other hand, considering the advantages of centralized model in comparison with decentralized one, task-based self-organizing algorithms can be used to address the point of failure problem by sequentially selecting the best nodes to act as servers \cite{x34}. In \cite{x15}, authors proposed a management framework for MDCs in which a node with highest level of resources is selected as leader. Such a leader is responsible for introducing a suitable resource provider to each RD requesting node. However, such a framework suffers from the key disadvantage that it assumes each node reports its resource level truthfully, which is not necessarily true in the presence of selfish nodes. Since the leader consumes more energy compared to the other nodes in the MDC, nodes have no inherent incentives for accepting the leadership role. 

Although the presence of selfish nodes in the packet forwarding problem has been addressed well in the literature (e.g., \cite{x20}, \cite{x21}), leader selection and RD in the presence of such nodes is not a well-studied topic
\cite{Mohammad_2013_malicious}. In \cite{x22}, in order to provide selfish nodes with incentives in the form of reputations, the authors have proposed a secure leader selection model for intrusion detection systems based on the Vickrey, Clarke, and Groves (VCG) mechanism. 
In addition to the fact that there is no formal specification and analysis of the type of
incentive provided by reputation-based systems, the use of price-based systems is more advantageous for RD in MDC since they are more secure than reputation-based ones \cite{x23}. However, 
the model in \cite{x22} cannot be applied to price-based systems. That is due to the fact that VCG mechanism is not budget-balanced\footnote[1]{For a mechanism which requires transfer of money among the nodes, Budget-Balanced means that the net transfer among nodes is zero. Hence, there is no need to inject money to the system \cite{x24}.} and it needs money to be injected to the system which is not suitable \cite{x2200}. 
In \cite{Mohammad_2013_leader}, the authors proposed a leader selection process which is based on a series of one-on-one incomplete information, alternating offers bargaining games. However, the proposed leader selection process is not appropriate for MDC environment because of the messaging overhead it imposes on the MDC.
Therefore, a new leader selection model compatible with price-based systems is required.


We list our main contributions as follows:
\begin{enumerate}
\item \textbf{LORD, a Leader-based framewOrk for RD:} 
We propose LORD which is not only self-organized and not prone to having a single point of failure like the centralized model, but also is able to balance the energy consumption among MDC participants better than the decentralized model. In LORD, to encourage nodes to assume leadership role, incentives are designed in the form of credit transfer from RD requesting nodes to the leader as an RD fee. 


\item \textbf{The first leader selection mechanism for credit-based systems:}
We propose a leader selection mechanism which is based on first-price sealed-bid auction. The pivotal difference between our mechanism and preceding ones is that we are seeking two objectives simultaneously: \textit{sequentially selecting nodes with the highest remaining energy as the leader based on proposed credit transfer model} and \textit{determining an appropriate RD fee that is lucrative for both the leader and RD requesting nodes}.

\item \textbf{Comparative performance evaluation:}
We evaluate the performance of LORD through simulation. Compared to decentralized model for RD, simulation results demonstrate that LORD balances energy consumption among nodes in the MDC and prolongs overall network lifetime. Furthermore, nodes enjoy higher payoffs in LORD compared to decentralized model.

\end{enumerate}




\section{The System Architecture}
We consider a mobile device cloud (MDC) in which all participating nodes have demand for RD. If a node is selected as the leader, the cost imposed on this node is expressed in its Resource Discovery Provisioning Cost (RDPC), which will be defined in Section \ref{section:parameters}. In LORD, we select the node with the lowest RDPC as the leader. To encourage nodes to assume leadership role, we consider incentives in the form of credit transfer from RD requesting nodes to the leader. 

In order to select the node with the lowest RDPC as the leader, we propose a leader selection mechanism which is based on multi-player first-price sealed-bid auction. In the leader selection process, each node offers an RD fee in order to compensate for the RDPC imposed on it. The amount of the RD fee offered by each node reflects the private value of its RDPC. Then, the node with the lowest offered RD fee is selected as the leader, which minimizes the total RD cost of participants in the MDC. 

As the resource level of nodes decreases over time, their RDPC values will increase. Since the amount of payment offered by each node in the leader selection process is on the basis of the current value of RDPC, at some point, the amount of payment may not be enough to compensate its RDPC. In order to address this issue, each node assumes leadership role for one time-slot that lasts  units of time.
In order to implement a multi-player auction among participating nodes, LORD consists of two different phases as illustrated in Fig. \ref{figure 5}. 



\begin{figure}[b]
\begin{center}
\includegraphics[width=2.8in,keepaspectratio]{2.png}
\caption{LORD timing for MDC}
\label{figure 5}
\end{center}
\end{figure}

The aim of the first phase is to form a MDC including all participants, and to select the node with the lowest RD fee as its leader. Since there is no central entity known to all nodes to perform a multi-player auction, 
we perform the auction as a series of two-node interactions. In each two-node interaction, the node that has the lowest RD fee is selected as the leader, and another node is considered as a client. Then, the interactions are performed one-on-one among the remaining leaders. The first phase ends when just one node is left which is the leader. This node is recognized as the leader of the MDC by others, i.e., clients.

In the second phase, the leader selected in the first phase assumes the leadership role during the first time-slot. Such a leader is responsible for classifying the available resource status data in a database based on the information each node sends regularly to it. After receiving an RD request from a client, the leader uses the information available in the database to find a proper resource provider, and then receives a voucher from the RD requesting node in return. 

The value of each voucher is equal to the amount of the RD fee it has offered in the leader selection process. Afterwards, the RD requesting node and the resource provider reach an agreement over the protocols and other requirements of the resource sharing such as resource price; a process which is beyond the scope of this paper. Finally, after a time equal to , where  is slightly smaller than 1, a new leader should be selected for the next time-slot. Since current leader of the MDC is known to clients, such a node performs an auction among all participants of the MDC. The winner of the auction assumes leadership role for the next time-slot.

We also consider the presence of one Trusted Unit (TU) which is only responsible for credit transfer among participants \cite{x23} and also can act as a mediator \cite{x500} to avoid misbehavior of nodes. It should be noted that since our objective is to design a framework which is independent of permanent presence of any unit outside of the MDC, the TU cannot act as the entity performing the auction among participating nodes. In general, any trusted entity outside the MDC which is intermittently accessible by all members, can be considered as TU. 


In LORD, a specific amount of credit is assigned to each node entering the MDC for the first time. In addition, each node can earn credits by providing resource for other nodes. In return, they can spend such credits to get resource from other nodes.
A typical architecture of LORD is shown in Fig. \ref{figure 2}. One node plays the role of leader while others act as clients. When client 3 sends a request to the leader, the leader finds a proper resource provider among other nodes, which is client 5 in this case. Then, the leader introduces client 5 to client 3, and receives a voucher as RD fee in return. Finally, after reaching an agreement over the resource sharing requirements, client 5 provides the resource for client 3 and receives some credit in return. 
\begin{figure}[t]
\begin{center}
\includegraphics[width=2.8in,keepaspectratio]{Drawing5.png}
\caption{System architecture for LORD}
\label{figure 2}
\end{center}
\end{figure}

\section{LORD: Leader-Based Framework for Resource Discovery} \label{section:model}

In this section, we present LORD for mobile device clouds (MDCs). First, we state our assumptions (Section~\ref{section:assumptions}). Then parameters of LORD are introduced in Section~\ref{section:parameters}. Section~\ref{section:Leader Selection Game} formulates the leader selection problem. Then, the two phases of LORD are introduced (Sections~\ref{section:Phase1} and \ref{section:phase2}). Finally, we consider the event of entrance and departure of nodes to/from the MDC.   

\subsection{Assumptions}\label{section:assumptions}
A MDC consisting of \textit{n} nodes is considered where each node has a unique identity. This MDC can be formed in various ways including manual assignment (similar to adding all iOS devices to one's iTunes, or android devices with Google), intelligent device
contact profiling, or via social profiles present on these devices (e.g. devices of members in the same household might be assigned to a single MDC). Such discovery and cloud clustering process can be addressed in various ways in the research
community \cite{x27} and therefore, we assume that such mechanisms exist \cite{x335}. Furthermore, we assume that the credit of all nodes are stored in a secure manner by the TU. In order to get credit from RD requesting nodes, the leader needs to report the vouchers it has received to the TU. It can save its vouchers inside a local storage such as a CompactFlash card, or a secure element such as a Subscriber Identification Module (SIM) card. Vouchers should be reported to the TU when the nodes have access to it.

In addition, since RDPCs of nodes should be calculated prior to beginning of each time-slot, the value of  is fixed. We assume that the demand of participating nodes for RD in the MDC is high, but the leader responds to only  number of RD queries.

Furthermore, we consider the following assumptions: 
\begin{itemize}
\item Every MDC participant is aware of the number of nodes participating in the leader selection process\footnote[1]{
Note that the duration of each leader selection process is negligible. Furthermore, each node maintains a table for routing purposes. Therefore, this assumption is reasonable because the number of nodes participating in the leader selection could be obtained easily from routing tables.}.
\item Time-slot synchronization is available among all nodes. 
\item A reliable pairwise connection among nodes is established at the transport layer. Therefore, all routing and error-correcting operations are handled by lower network layers and are hidden to the procedures we explain. As a result, there is an error-free route available between each two nodes. 



\end{itemize}
It should be noted that the first two assumptions have also been implemented in \cite{x22}.
\subsection{Parameters and Concepts}\label{section:parameters}

In LORD, one node is selected as the leader among  participants. The selected leader has the responsibility of RD for a given time-slot. All clients should send the information about the status of their resources to the leader at the beginning of each time-slot. The information each node sends to the leader should represent whether this node can provide  (Resource Type ) and the amount of money (resource price) it expects to receive if it can provide such a resource. Based on such information, the leader prepares a database in which for each , it has been specified which nodes are able to provide this resource and how much their corresponding resource prices are. The leader uses this database to find the best resource provider, i.e., the one with the lowest resource price, for each RD request. Furthermore, the leader is responsible for selecting a new leader for the next time-slot.

If node  is the leader and receives  for each RD, its payoff will be as follows:

where , as mentioned in Section~\ref{section:assumptions}, is the number of RD requests of each client to which the leader responds,  is the processing cost imposed on node  for searching the database in order to find a proper resource provider,  is the messaging cost imposed on node  for introducing such a resource provider to the RD requesting node,  is the processing cost imposed on node  for preparing a database, and  is the messaging cost imposed on node  for selecting a new leader among all the participants.  Finally,  is the number of times this node searches the database for finding a resource provider for itself.



Simplifying (\ref{equation:xx1}), the leader's payoff can be rewritten as,

where  is the total number of RDs the leader should perform for clients during one time-slot, i.e., , and  is the Resource Discovery Provisioning Cost (RDPC) per RD imposed on the leader given by:
 

It should be noted that  and  are the processing costs of preparing and searching a database which hinges on the processing power of node , and the number of entries in the database (which depends on the number of nodes ()). Therefore, although the database has not been constructed when nodes want to set their RDPC, since the number of nodes is specific (using the information of routing tables),  and  can be readily calculated.
For simplicity of analysis, we assume these two costs are equal to  which represents the processing cost imposed on node . Furthermore, the term  is a messaging cost requiring only 3 messages (as will be explained in Section \ref{trans_protocol}), and the term  is also a messaging cost requiring  messages (as will be explained in Section \ref{section:phase2}). If we define  as the cost imposed on node  for sending a message,  and  will be equal to  and , respectively. Therefore, (\ref{equation:xx3}) can be simplified as follows:
 

At each time-slot, each client should send a message to the leader representing which resources this node can provide and how much money (resource price) it expects to receive if it can provide such a resource. Subsequently, if a client intends to receive one RD from the leader, it should send one RD request imposing  on this node and also pay  to the leader. Assume that the valuation of each RD for a client is fixed and high. Therefore, such a valuation does not affect the strategy of the client. If client  intends to receive  number of RDs from the leader, the payoff of this node is defined as:

where the first term of the right-hand side of (\ref{equation:xx4}) is the monetary cost imposed on this client for  number of RDs, the second term is the messaging cost imposed on this client for sending  number of RD requests to the leader, and the third term is the cost of sending one message including the information about the status of this client's resources to the leader.

On the other hand, in decentralized scheme for RD, there is no leader. Therefore, each node performs RD itself. Similar to our model which introduces the best resource provider to each RD requesting node, if node  desires to find the best resource provider for  itself, it should send messages to all other  nodes one-by-one and ask them whether they can provide  and inquire about the amount of money (resource price) they expect to receive if they can provide such a resource. After sending  messages which impose  cost on node , this node is able to find the best resource provider for , i.e., the one with the lowest resource price. Therefore, if node  intends to perform  number of RDs itself, its payoff is given by: 

where  is the Resource Discovery Cost (RDC) per RD imposed on node  in a decentralized scheme.

In this paper, we assume RDPC of each node is smaller in comparison with its RDC, i.e., . Since RDPC and RDC depend on  and , specifying the precise value of RDPC and RDC needs experimental data which is beyond the scope of this paper. It can be shown that if  (which is plausible since  is a negligible cost due to high processing power available in today's smartphones \cite{x29}), our assumption that  is valid (See Appendix \ref{validating}).

By comparing (\ref{equation:xx4}) and (\ref{equation:xx5}), it can be concluded that the client  participates in LORD if, 
 

Assume that every node  bids an RD fee () in the interval  and proportional to its RDPC (i.e.,  and the higher the RDPC, the higher the RD fee). If node  with the lowest RD fee is selected as the leader, this node not only has the lowest RDPC, but also has the lowest RDC (i.e., ). This is due to the fact that both RDPC and RDC depend on the resource status of a node and have a strictly decreasing relation with the resources status, i.e., if nodes are arranged based on their RDPCs and RDCs, all nodes have the same ranking position in both arrangements. 
If node  has the lowest RD fee, i.e., , this node has the lowest RDPC and RDC, i.e., . Therefore,
 
which satisfies the condition of (\ref{equation:xx668}).




Let  denote the minimum level of energy required for node \textit{i} in order to assume the leadership role for one time-slot, then by considering (\ref{equation:xx2}) and (\ref{equation:xx333}),
 
Subsequently, each node can set its RDPC as follows: 

where  is the current level of energy for the node \textit{i}. Based on (\ref{equation:xx8}), a node has a very high RDPC if its remaining energy is less than the energy required to assume leadership role for one time-slot.

\subsection{Auction-Based Leader Selection}
\label{section:Leader Selection Game}
Since the RDPC values of nodes are private to every node, we model the leader selection problem by an incomplete information game known as Bayesian Game. The leader selection problem is considered as a multi-player first-price sealed-bid auction game, where players are the nodes that participate in the MDC denoted by . The payoff of winner and losers are the payoff of leader node and client node, respectively. Since our objective is to compare the payoff of nodes in LORD with the corresponding payoffs in decentralized scheme for RD, in order to simplify our analysis, we eliminate  in (\ref{equation:xx4}) and rewrite (\ref{equation:xx2}), (\ref{equation:xx4}), and (\ref{equation:xx5}). By doing so, if node \textit{i} is the leader of LORD, its modified payoff will be as follows: 

where  which is called modified RDPC is given by,

If node \textit{i} is a client in LORD, its modified payoff will be as follows:

Finally, if node \textit{i} participates in a decentralized scheme for RD, its modified payoff is given by:

where  which is called modified RDC is given by,


In our game, the type of a player is its modified RDPC, i.e., , which is private. The strategy of each player is the bid it submits as its RD fee. Such a parameter denoted by  for node  is a function of , i.e.,  where  is an increasing, continuous, and differentiable function. We will later prove that the Nash Equilibrium (NE) solution indeed satisfies such an assumption. Assume that the belief of each player about the modified RDPC of others is independent of the player, and is  uniformly distributed in the interval . Furthermore, the payoff of winner and losers of the game are (\ref{equation:xx222}) and (\ref{equation:xx223}), respectively. 

If player  bids , its expected payoff is,

\begin{small}

\end{small}
where  and  denote the probability of an event and the expectation of a random variable, respectively. In (\ref{equation:xx9}), the term  is the payoff of player  if it wins the auction, and the term  is its payoff when it loses the auction and another player (without loss of generality call it ) wins the auction. 

We investigate the class of symmetric NEs, i.e., . Utilizing the notion of symmetric equilibria helps us reduce the multiplicity of NE. The payoff of player  is,

\vspace*{-3mm}
\begin{small}

\end{small}

Note that the distribution of modified RDPCs are independent from each other, therefore the bids are independent. Thus,


Player  submits  that maximizes its expected payoff. The first order necessary condition (with respect to ) is,


After simplification, Bayesian Nash equilibrium of the auction must satisfy the following differential equation:


The following Lemma provides us with the solution to (\ref{equation:x13}).
\begin{lemma}\label{lemma:diff}
The following strategy solves the differential equation given by (\ref{equation:x13}):
\vspace{-2mm}
 
 
\end{lemma}
See Appendix \ref{p_l1} for a proof.

First note that, the solution  is indeed an increasing, continuous, and differentiable function. Furthermore, (\ref{equation:x14}) implies that each node offers an RD fee which is quite close to its modified RDPC for large enough . Therefore, if the value of  in (\ref{equation:xx1}) is selected properly, we can conclude that for every ,  which ascertains (\ref{equation:xx601}). In the following Proposition, we derive a condition on the value of  by which  will be satisfied for every~.

\begin{pr}\label{peoposition:etha}
In order to satisfy the condition , the minimum number of RD queries done by the leader for each client in a MDC of size  should be,

where  indicates the upper bound of  for all nodes and  denotes the resource status of node . Furthermore,  and  are the lowest and highest values of resource status of all nodes, respectively.
\end{pr}
See Appendix \ref{p_p1} for a proof.
In the numerical result presented in Appendix \ref{p_p1}, we justify that when  and , .
Hence, there is no constraint on  and  holds. 


Based on the next Theorem, the strategy identified in (\ref{equation:x14}) is indeed the unique NE for the game. 

\begin{thm}\label{peoposition:sufficiency}
In our proposed multi-player auction, the strategy identified in (\ref{equation:x14}) is the unique symmetric Bayesian Nash equilibrium.
\end{thm}

In the proof, we will argue that if all players except a particular player, say , opt the strategy identified in (\ref{equation:x14}), then the unique strategy which maximizes the payoff of player  is (\ref{equation:x14}). For details of proof, see Appendix \ref{p_t1}.

\begin{thm}
Using the aforementioned leader selection mechanism and considering the assumption of , the payoffs of MDC participants are higher in LORD compared to decentralized model.
\end{thm}

\begin{proof}
The proof is simply resulted from the fact that our proposed leader selection mechanism selects the node with the lowest RD fee. Therefore, according to (\ref{equation:xx601}), the condition of (\ref{equation:xx668}) is satisfied. 
\end{proof}

\begin{pr}\label{energy_saving}
Total consumed energy of nodes is lower in LORD compared to decentralized model if the following condition holds:
\vspace{-2mm}

\end{pr}
See Appendix \ref{p_p2} for a proof. In the numerical result presented in Appendix \ref{p_p2}, we justify that when  and , the condition of Proposition \ref{energy_saving} holds. 

In the following subsections, we describe different phases of LORD.


\subsection{Phase I}\label{section:Phase1}
The goal of the first phase is to form a MDC including all participants, and to select the node with the lowest RD fee as its leader. In order to implement a multi-player auction among all participants in a way that does not impose significant communication overhead on the network, we implement the auction as a series of two-node interactions.  
First, nodes calculate their bids for RD fee based on (\ref{equation:x14}). Then, they interact with each other in a one-on-one basis. The node that has lower RD fee is considered as the winner of the interaction, and the other node is considered as the loser. In order to implement a simultaneous interaction between two nodes in which no one is able to change its RD fee after observing RD fee of another one, we define the interaction between nodes  and  as follows:
\begin{enumerate}
\item One of the nodes (e.g., node ) sends a MDC formation request including  to node , where  is the bid of node  and  stands for a Message Digest function such as MD5 \cite{x30} or SHA-1 \cite{x31}.
\item When node  receives such a request, if it is a client, it forwards the request to its leader. Otherwise, it submits its bid, i.e.,  to node . Since node  cannot extract  from , its offer is independent of .
\item Upon receiving such a response, node  submits its bid, i.e.,  to node \textit{j}. Since node  has previously submitted  to node , it cannot change its bid after observing . 
\item The node submitting lower bid is recognized as a leader. The other node sends the list of its clients (if any) to the leader. 
\item The loser node informs its clients (if any) of their new leader. The leader adds the loser node (and its clients) to the list of its clients.

\end{enumerate}
The aforementioned process continues among the winners of previous interactions, i.e., remaining leaders. Such a process continues until the number of participants reaches . In this case, the single remaining leader is recognized as the leader of the MDC. Then, the management procedure enters phase II.

It should be noted that nodes have no incentive to change their bid for RD fee after an interaction. This is due to fact that if one node increases its RD fee, none of its clients accept this node as its leader anymore. If such a node decides to increase its RD fee only for new incoming clients, since the amount of RD should be identical for all clients, the TU punishes this node (if this node is selected as the single leader of the MDC) when it wants to receive its credits by reporting its voucher to the TU. In addition, this node has no incentive to decrease its RD fee because it reduces its benefit based on (\ref{equation:xx1}).





\subsection{Phase II}\label{section:phase2}
In the second phase of LORD, the selected leader begins its task and assumes the leadership role for one time-slot. Before the end of the current time-slot, the leader should perform an auction among all participants including itself.




In order to implement the auction as a simultaneous game, we define the process of leader selection as follows:

\begin{enumerate}
\item The current leader of the MDC computes the hash value of its bid using a message digest function (), sends it to all clients, and asks them for their bids.
\item Each client sends its bid to the leader regardless of leader's offer because it cannot reveal the bid of leader.
\item Upon receiving the bids from all clients, the current leader sorts nodes based on the values of their bids. The node which has the lowest bid is selected as the leader and the value of its bid is assigned as its RD fee. The current leader sends the name of the selected leader and its RD fee, as well as the list of other nodes including itself, and their bids to all clients. 

Each client that has received such a message, first calculates the hash of the current leader's bid using . Then, the result is compared with the one offered by the current leader at the beginning of this auction. The leader does not change its bid because it knows that the clients can find out if it does so.
If the values are identical, the result of auction is valid. Therefore, such a node considers the selected leader as the new leader for the next time-slot.

The selected leader considers itself as the leader of the MDC for the next time-slot.
\end{enumerate}

Based on this process, since the current leader has sent the hash value of its bid at the first step, it cannot change its bid after receiving the values offered by clients. If it does so, all clients will notice and will put the name of such a leader in their blacklists. As a punishment, such a node is deprived of further participation in the MDC. If we consider a MDC with \textit{n} nodes, the total number of messages required in the leader selection is equal to , among which  number of messages is related to the leader. 

Note that the current leader can misbehave in the leader selection process in two ways. First, it can manipulate the values offered by others in order to select itself as the next leader. Second, it can deviate from performing the auction for selecting a new leader. In order to address these issues, suitable punishment policy such as exclusion from the MDC can be used in order to make sure that the leader do not misbehave. For details of punishment policy, see Appendix \ref{punishment}.







 





\subsection{Entrance or Departure of Nodes}\label{section:entrance}
After introducing our leader selection process, we focus on entrance and departure of nodes. When a node intends to join the MDC by switching its resource sharing feature on, it sends a message to the leader of MDC. When the leader receives such a message, it invites the entering node to wait until the next leader selection process. At the next leader selection process, all nodes modify the number of participating nodes to  and the new node can enter the MDC.


The departure event may also occur due to a number of reasons such as mobility and battery depletion. If the departing node is not the leader, the MDC continues its regular function. The leader will remove the name of the departed node from the list of clients. 
In the case of a departing leader, the solution is to start from phase I and perform a leader selection in order to select a new leader for the MDC. 



\section{Transaction Protocol}
\label{trans_protocol}

According to LORD, for each RD, the RD requesting node should give the leader a voucher of value RD fee. However, without a secure transaction protocol, an RD requesting node can cheat by not sending the voucher to the leader when it receives RD from the leader. As a result, a protocol is required to guarantee that no party can cheat during the RD procedure. This issue has been addressed well in the literature of fair-exchange protocols (e.g., \cite{x500}, \cite{x502}, \cite{x25}), especially for wireless environments. Regardless of the differences among such protocols, there are two involved parties (called Alice and Bob), and one entity as a mediator (Trusted Third Party (TTP)) in ``optimistic" class of these protocols. Although not repeated here, such protocols guarantee the fair exchange between involved parties. By the assistance of these secure protocols, we present the transaction protocol among the leader, the RD requesting node, and the resource provider as follows.

When an RD requesting node sends a request to the leader to find a resource provider for  (Resource Type ), the RD requesting node, the leader, and the resource provider execute the following protocol collectively: 
\begin{enumerate} 
\item Resource requesting node sends an RD request for  to the leader. 
\item When the leader receives such a message, it searches its database for a proper resource provider for the specified resource. If the leader cannot find a proper node for that type of resource, it sends RD failure message to the RD requesting node. On the other hand, if the leader finds a resource provider, it sends a message verified by resource provider to the RD requesting node indicating that the proposed resource provider can provide . The fact that the leader should send a message confirmed by a resource provider to the RD requesting node prevents the leader from cheating and introducing a fake resource provider to the RD requesting node.

\item When one node (as a resource provider) receives such a message, if it can provide the requested resource, it sends a confirmation message to the leader.
\item Upon receiving the verification from the resource provider, the leader should introduce the resource provider to the RD requesting node and in return receive the voucher from this node. Considering the leader, the RD requesting node, and the TU in our framework as Alice, Bob, and the TTP in the optimistic fair-exchange protocols, respectively, such protocols can ensure a secure transaction between the leader and the RD requesting node. 

\end{enumerate}

Considering the proposed protocol, neither the leader nor the RD requesting node can cheat. Hence, in practice, no node has incentive to cheat and there is no need for the TU to mediate in such situations.


\section{Performance Evaluation} 
\subsection{LORD Performance}
We compare LORD with decentralized model for RD. To this end, we consider a MDC including 10 nodes \footnote[1]{As our analytical analysis (Propositions 1 and 2) indicates LORD works for large number of nodes. Limiting the number of nodes to 10 is only for the sake of clarity of results presentation.} where each one is randomly assigned an initial energy level in the interval  joles. Then, based on the initial energy levels, modified RDPC of each node is calculated in the interval  joles (the higher the initial energy level, the lower the modified RDPC). For example, if the initial energy level of node  is 60 joles, the modified RDPC of this node is 0.4 joles. Then, considering the relationship between messaging and processing costs of node  as ,  and  can be calculated using (\ref{equation:xx2232}). By substituting the value of  in (\ref{equation:xx2233}), modified RDC of node  can be computed. 
We assume  is equal to 2 minutes in LORD, and the leader provides 3 RDs for each node at every time-slot (i.e., ). Similarly, we assume that each node performs 3 RDs itself every 2 minutes in decentralized model for RD. Furthermore, for simplicity, we assume  for all . 


In order to compare LORD with decentralized model, we consider three general cases, , , and .

\begin{enumerate}
\item Fig. \ref{figure7} compares LORD with the decentralized model when . In Fig. \ref{figure7.a} and Fig. \ref{figure7.b}, we have plotted the percentage of nodes' energy over time. Fig. \ref{figure7.a} indicates that LORD is able to balance the energy consumption among all nodes. However, the energy consumption of nodes is unbalanced in the decentralized RD model (Fig. \ref{figure7.b}), leading to earlier death of some nodes. Fig. \ref{figure7.c} compares the percentage of alive nodes in LORD with that of the decentralized model. We consider
a node to be alive as long as it has not depleted its energy.
This figure demonstrates that overall lifetime of MDC participants is higher in LORD. In Fig. \ref{figure7.d}, we compare the improvement in payoff of the participating nodes in LORD in comparison with that of in the decentralized model for RD. This figure represents that participating nodes always have higher payoffs in LORD. Furthermore, if we sort nodes based on their energy levels after 10 minutes () from Fig. \ref{figure7.a}, we have ; and if we sort nodes based on their improved payoff after 10 minutes () from Fig. \ref{figure7.d}, we have . This indicates that LORD is more lucrative for nodes with lower levels of energy.

\begin{figure}\centering
  \subfigure[Energy level of nodes in LORD]
  {
       \includegraphics[width=1.62in,keepaspectratio]{RDPC_f_4-eps-converted-to.pdf}
      \label{figure7.a}
    }
   \subfigure[Energy level of nodes in decentralized model for RD]
    {
        \includegraphics[width=1.62in,keepaspectratio]{RDC_f_4-eps-converted-to.pdf}
      \label{figure7.b}
   }
      \subfigure[Percentage of alive nodes]
    {
        \includegraphics[width=1.62in,keepaspectratio]{alives_f_4-eps-converted-to.pdf}
      \label{figure7.c}
   }
   \subfigure[Improved payoff for LORD in comparison with decentralized model]
    {
        \includegraphics[width=1.62in,keepaspectratio]{diff_f_4-eps-converted-to.pdf}
      \label{figure7.d}
   }
 \caption{Comparison of LORD with the decentralized model for , i.e., }
\label{figure7}
\end{figure}

\item Fig. \ref{figure8} compares LORD with the decentralized model for . Similar to case , Fig. \ref{figure8.a} and Fig. \ref{figure8.b} indicate that LORD is able to balance the energy consumption among all nodes while decentralized RD model is unable to do so. Comparison of Fig. \ref{figure8.c} with Fig. \ref{figure7.c}, and Fig. \ref{figure8.d} with Fig. \ref{figure7.d} demonstrates that the overall lifetime and improvement in payoff of the participating nodes are higher in LORD than these values in the decentralized model when . 


\begin{figure}\centering
  \subfigure[Energy level of nodes in LORD]
  {
       \includegraphics[width=1.62in,keepaspectratio]{RDPC_f_2-eps-converted-to.pdf}
      \label{figure8.a}
    }
   \subfigure[Energy level of nodes in decentralized model for RD]
    {
        \includegraphics[width=1.62in,keepaspectratio]{RDC_f_2-eps-converted-to.pdf}
      \label{figure8.b}
   }
      \subfigure[Percentage of alive nodes]
    {
        \includegraphics[width=1.62in,keepaspectratio]{alives_f_2-eps-converted-to.pdf}
      \label{figure8.c}
   }
   \subfigure[Improved payoff for LORD in comparison with decentralized model]
    {
        \includegraphics[width=1.62in,keepaspectratio]{diff_f_2-eps-converted-to.pdf}
      \label{figure8.d}
   }
 \caption{Comparison of LORD with the decentralized model for , i.e., }
\label{figure8}
\end{figure}


\item Fig. \ref{figure9} compares LORD with the decentralized model for . In this case, messaging cost is negligible in comparison with processing cost. Since RD in decentralized model imposes only messaging cost while RD in LORD imposes both processing and messaging costs, Fig. \ref{figure9.a}, Fig. \ref{figure9.b}, and Fig. \ref{figure9.c} indicate that nodes die earlier in LORD in comparison with decentralized RD model because RD in LORD imposes more cost on nodes. Furthermore, Fig. \ref{figure9.d} indicates that the payoff of nodes is lower in LORD in comparison with the payoff of nodes in decentralized RD model.  


\begin{figure}\centering
  \subfigure[Energy level of nodes in LORD]
  {
       \includegraphics[width=1.62in,keepaspectratio]{RDPC_f_3-eps-converted-to.pdf}
      \label{figure9.a}
    }
   \subfigure[Energy level of nodes in decentralized model for RD]
    {
        \includegraphics[width=1.62in,keepaspectratio]{RDC_f_3-eps-converted-to.pdf}
      \label{figure9.b}
   }
      \subfigure[Percentage of alive nodes]
    {
        \includegraphics[width=1.62in,keepaspectratio]{alives_f_3-eps-converted-to.pdf}
      \label{figure9.c}
   }
   \subfigure[Improved payoff for LORD in comparison with decentralized model]
    {
        \includegraphics[width=1.62in,keepaspectratio]{diff_f_3-eps-converted-to.pdf}
      \label{figure9.d}
   }
 \caption{Comparison of LORD with the decentralized model for , i.e., }
\label{figure9}
\end{figure}

\end{enumerate}

Considering the aforementioned cases, if , we can conclude that,
\begin{enumerate}
\item LORD ascertains our goal in balancing the energy consumption among participating nodes while the energy consumption of nodes is unbalanced in decentralized RD model.
\item LORD increases the overall lifetime of nodes in comparison with the decentralized RD model. Since in a MDC nodes provide resource for each other, as the percentage of alive nodes is higher, the probability of finding a proper resource provider increases. However, death of several nodes due to unbalanced energy consumption in the decentralized model decreases the probability of performing a successful RD.
\item Nodes prefer participation in MDCs where RD is based on LORD to the ones where RD is carried out by each node individually (i.e., decentralized RD model) since they have higher payoffs in LORD. Furthermore, the improvement in payoff of nodes increases over time since as the energy level of nodes decrease, performing RD by nodes themselves imposes much more cost on them. In addition, LORD is even more lucrative for nodes with lower levels of energy.

\item As the amount of  increases in comparison with , the advantage of LORD is more significant in comparison with decentralized RD model.  
\end{enumerate}

On the other hand, since the messaging cost is negligible when , it is better for nodes to perform RD themselves instead of participating in a MDC where RD is based on LORD.

\subsection{LORD Communication Overhead Analysis}
We evaluate the communication overhead imposed on the network in the leader selection algorithms proposed for phases I and II. 
\subsubsection{Overhead Analysis: Phase I} \label{Performance Overhead_1}
The leader selection process proposed for Phase I consists of a series of two-node interactions. At each interaction, one node (loser of the interaction) is added to the list of clients. Therefore, if we consider a MDC with  nodes, the number of required interactions is . Each proposed interaction has five steps as explained in Section \ref{section:Phase1}. 
Each of the first four steps requires one message and therefore, the total number of messages of the first four steps in all  interactions is . However, the number of messages of step 5 depends on the number of clients of the loser node which itself depends on the arrangement of earlier two-node interactions. If we denote the total number of messages of last step in all  interactions by , total number of messages required in the leader selection procedure is equal to . Although  cannot be calculated exactly, its average value can be approximated by performing enough number of simulations as indicated in Fig. \ref{figure 10}.

\subsubsection{Overhead Analysis: Phase II}
The leader selection process proposed for Phase II consists of one multi-player auction which has three steps as explained in Section \ref{section:phase2} where each step requires  number of messages. As a result, if we consider a MDC with \textit{n} nodes, the total number of messages required in the leader selection is equal to .
\subsubsection{Overhead Analysis: Comparison of Phase I and Phase II}
Fig. \ref{figure 10} indicates the imposed communication overhead for different number of nodes. It can be seen that the number of messages required in the leader selection of phase I and II are  and , respectively. Therefore, the results of simulation indicate that the total number of messages required for the leader selection in both phases is in the order of .

\begin{figure}
\centering
      \includegraphics[width=2.1in,keepaspectratio]{overhead_2-eps-converted-to.pdf}
      \caption{Communication overhead imposed on the network}
\label{figure 10}
\end{figure}
\section{Conclusion}
In this paper, we have provided a new solution for Resource Discovery (RD) in mobile device clouds (MDCs). In order to balance the energy consumption of all nodes and prolong the overall lifetime of MDCs, we have proposed LORD, a leader-based framework for RD in MDCs, in which the RD task is handled by a node selected as the leader. We have proposed a multi-player first-price sealed-bid auction to select the most qualified node as the leader. Through simulation results, we have demonstrated that LORD is able to balance the energy consumption among mobile devices and increase their payoffs in comparison with the decentralized RD model. 






\begin{thebibliography}{31}
\bibitem{xx1}
Gartner, ``Gartner Says Smartphone Sales Surpassed One Billion Units in 2014," March 2015.
\bibitem{x37}
D. Camps-Mur, A. Garcia-Saavedra, and P. Serrano, ``Device to device communications with wifi direct: overview and experimentation," \textit{IEEE Commun. Mag}, 2012. 
\bibitem{x334}
C. Shi, V. Lakafosis, M. H. Ammar, and E. W. Zegura, ``Serendipity: Enabling remote computing among intermittently connected mobile devices," \textit{Proc. of ACM MobiHoc}, 2012.
\bibitem{x335}
A. Mtibaa, A. Fahim, K. A. Harras, and M. H. Ammar, ``Towards resource sharing in mobile device clouds: Power balancing across mobile devices," \textit{Proc. of ACM SIGCOMM workshop on Mobile cloud computing}, 2013.
\bibitem{xx4}
A. Horvath, M. Telek, D. Rossi, P. Veglia, D. Ciullo, A. Garcia da Rocha Neta, E. Leonardi, and M. Mellia, ``Network Awareness of P2P Live Streaming Applications: a Measurement Study," \textit{IEEE Trans. Multimedia}, vol. 12, no. 1, pp. 54-63, Jan. 2010. 
\bibitem{xx7}
L. Duan, T. Kubo, K. Sugiyama, J. Huang, T. Hasegawa, and J. Walrand, ``Incentive mechanisms for smartphone collaboration in data acquisition and distributed computing," \textit{Proc. of IEEE Infocom}, 2012.
\bibitem{xx3}
N. Mehta, A. Molisch, and Jin Zhang, ``Energy-Efficient Cooperative Relaying over Fading Channels with Simple Relay Selection," \textit{IEEE Trans. Wireless Commun.}, vol. 7, no. 8, pp. 3013-3025, Aug. 2008. 


\bibitem{x53}
A. Pyattaev, K. Johnsson, S. Andreev, and Y. Koucheryavy, ``3GPP LTE Traffic Offloading onto WiFi Direct," \textit{Proc. of the IEEE WCNC}, 2013.
\bibitem{x14}
R. Moreno-Vozmediano, ``A hybrid mechanism for resource/service discovery in ad-hoc grids," \textit{Future Generation Computer Systems}, vol. 25, pp. 717-727, July 2009. 
\bibitem{x34} 
M. A. Razzaque, S. Dobson, and P. Nixon, ``Enhancement of Self-organization in Wireless Networking through a Cross-layer Approach,'' \textit{Ad Hoc Networks}, vol. 28, pp.144-159, 2009. 
\bibitem{x15}
M. J. Salehi, B. H. Khalaj, M. Katz, G. Fazelnia, and P. Karimi, ``Mobile Cloud Management: A New Framework," \textit{Proc. of IEEE PIMRC}, 2012.
\bibitem{x20}
P. Michiardi and R. Molva, ``Analysis of coalition formation and cooperation strategies in mobile ad-hoc networks," \textit{Journal of Ad hoc Networks}, vol. 3, no. 2, pp. 193-219, 2005.
\bibitem{x21}
Z. Li and H. Shen, ``Game-Theoretic Analysis of Cooperation Incentive Strategies in Mobile Ad Hoc Networks," \textit{IEEE Trans. Mobile Comput}., vol. 11, no. 8, pp. 1287-1303, Aug. 2012.
\bibitem{Mohammad_2013_malicious}
S. M. A. Pari, M. Noormohammadpour, M. J. Salehi, B. H. Khalaj, H. Bagheri and M. Katz, ``A self-organizing approach to malicious detection in leader-based mobile ad-hoc networks," \textit{2013 IFIP Wireless Days (WD)}, Valencia, 2013.
\bibitem{x22}
N. Mohammed, H. Otrok, L. Wang, M. Debbabi and P. Bhattachary, ``Mechanism Design-Based Secure Leader Election Model for Intrusion Detection in MANET," \textit{IEEE Trans. Dependable Secure Comput.}, vol. 8, no. 1, pp. 89-103, Jan.-Feb. 2011. 
\bibitem{x23}
S. Zhong, J. Chen, and Y. R. Yang, ``Sprite: A Simple, Cheat-Proof, Credit-Based System for Mobile Ad-hoc Networks," \textit{Proc. of INFOCOM}, 2003.
\bibitem{x24}
N. Nisan and A. Ronen, ``Algorithmic mechanism design," \textit{Games and Economic Behavior}, vol. 35, pp. 166196, 2001.
\bibitem{x2200}
P. Maill and B. Tuffin, ``Why VCG auctions can hardly be applied to the pricing of inter-domain and ad hoc networks," \textit{Proc. of 3rd EuroNGI Conference on Next Generation Internet Networks}, 2007.
\bibitem{Mohammad_2013_leader}
S. M. A. Pari, M. J. Salehi, M. Noormohammadpour, B. H. Khalaj, H. Bagheri and M. Katz, ``An incentive-based leader selection mechanism for mobile ad-hoc networks (MANETs)," \textit{2013 IFIP Wireless Days (WD)}, Valencia, 2013.

\bibitem{x500}
Alptekin K{\"u}p{\c{c}}{\"u} and Anna Lysyanskaya, ``Usable optimistic fair exchange," \textit{Journal of Computer Networks}, vol. 56, no. 1, pp. 50-63, 2012.
\bibitem{x27}
M. Abdellatif, A. Mtibaa, K. A. Harras, and M. Youssef, ``GreenLoc: an energy efficient architecture for WiFi-based indoor localization on mobile devices," \textit{Proc. of IEEE ICC}, 2013.\bibitem{x29}
A. Carroll and G. Heiser, ``An Analysis of Power Consumption in a Smartphone," \textit{USENIX annual technical conference}, 2010.
\bibitem{x30}
R. L. Rivest, \textit{The MD5 Message Digest Algorithm, RFC 1321}, Apr. 1992. [Online]. Available: http://andrew2.andrew.cmu.edu/rfc/rfc1321.htm
\bibitem{x31}
\textit{Secure hash standard}, Federal Information Processing Standards Publication 180-1, 1995.
\bibitem{x502}
M. T. Dashti, ``Efficiency of optimistic fair exchange using trusted devices," \textit{ACM Trans. Autonomous and Adaptive Systems (TAAS)}, vol. 7, no. 1, pp. 3-23, 2012.
\bibitem{x25}
G. Wang, F. Bao, J. Zhou, and R. H. Dengt, ``An Efficient Certified E-Mail Scheme Suitable for Wireless Mobile Environments," \textit{Proc. of IEEE PIMRC}, 2005.


\end{thebibliography}






\newpage
\appendices
\section{Validating the Assumption }
\label{validating}
Let's consider three general cases, , , and . In order to be able to compare RDPC and RDC, we assume that number of nodes is at least 10 (), number of RDs for each node is at least 1 (), and the number of times the leader searches the database for finding a resource provider for itself is smaller than or equal to 10 (). Considering these assumption as well as (\ref{equation:xx333}), it can be easily shown that:
 
Furthermore, considering aforementioned assumptions and (\ref{equation:xx5}), it can be shown that:
 
Now, we compare (\ref{equation:xx666}) and (\ref{equation:xx667}) in three aforementioned cases,
\begin{itemize}
\item . In this case, we have  and  , and therefore we can conclude that . 
\item . In this case, we have  and  , and therefore we can conclude that .
\item . In this case, we have  and  , and therefore we cannot conclude that .
\end{itemize}

Considering these cases, if  (which is plausible since  is a negligible cost due to high processing power available in today's smartphones \cite{x29}), our assumption that  is valid. 



\section{Proof of Lemma 1}
\label{p_l1}
Rewriting (\ref{equation:x13}) as follows:

we get to the form of first order linear differential equation that is . Considering the general solution of this equation, the solution of (\ref{equation:x15}) can be written as follows:

where  in which . Therefore,

Simplifying (\ref{equation:x17}), the solution is,
 
Substituting  where  in (\ref{equation:x18}) results in,
 

\section{Proof of Proposition 1}
\label{p_p1}
In order to have , based on (\ref{equation:x14}) we need,
 
Substituting  from (\ref{equation:xx2232}) and  from (\ref{equation:xx5}) in (\ref{eq1}),


After simplifying, the value of  that satisfies (\ref{eq3}) can be obtained as follows:
 
where,


Recall that  is a function of  and the resource status of node  (),  is a function of only . RHS of (\ref{eq_2}) is a function of , , and , therefore (\ref{eq_2}) can be rewritten as, 
 

Let us denote the upper bound of  for all  by . If we assume that the resource status of all nodes to belong to , the minimum number of RD queries done by the leader for each client in a mobile device cloud (MDC) of size  to satisfy  is,

Choosing  in a MDC of size  is a sufficient condition to ensure  .  

To see whether (\ref{contraint_1}) is a hard constraint or not, we analyze this constraint numerically. To this end, we consider a MDC of varying size . For each , we assume RDPC (as a representation for resource status) of nodes are distributed uniformly in the interval . Then, considering the relationship between messaging and processing costs of node  as  and using (\ref{equation:xx2232}),  and  can be calculated. Furthermore, we assume  (that is, a leader performs RD at most  times for itself). We change  from 10 to 30 and for each , we find  according to (\ref{contraint_1}). Figure \ref{eta} shows  for various values of . As can be seen from this figure, for , we need . Since we know that the leader provides at least 1 RD for each client (that is, ), the requirement on  is satisfied. Hence, there is no constraint on  and  holds.

\begin{figure}
\begin{center}
\includegraphics[width=3.3in,keepaspectratio]{eta_min-eps-converted-to.pdf}
\end{center}
\caption{Minimum number of RDs () for a MDC with different sizes}
\label{eta}
\end{figure}

\section{Proof of Theorem 1}
\label{p_t1}
If all players except for player  play based on (\ref{equation:x14}), the expected payoff for node  can be written as:

\begin{small}

\end{small}
Simplifying,
\begin{small}

\end{small}
For any \begin{small}
:

\end{small}
Substituting (\ref{equation:x21}) in (\ref{equation:x20}) yields:
\begin{small}

\end{small}
For any \begin{small} :

\end{small}

Therefore,  is strictly concave in \begin{small}
,
\end{small}
and has a maximum value at  identified in (\ref{equation:x14}). It is clear that deviation from such  is not profitable. Hence, the strategy identified in (\ref{equation:x14}) is the unique symmetric Bayesian Nash equilibrium.

\section{Proof of Proposition 2}
\label{p_p2}
Let  and  denote consumed energy of node  at time-slot  for LORD and decentralized model, respectively. According to (\ref{equation:xx2}) and (\ref{equation:xx333}), if node  is the leader at time-slot 
,  can be written as,


If node  is a client at time-slot , according to (\ref{equation:xx4}),  can be written as,

 
For decentralized model, according to (\ref{equation:xx5}),  can be written as,

 
In order to compare the total consumed energy per time-slot between LORD and decentralized model, let  and  denote total consumed energy of nodes at time-slot  for LORD and decentralized model, respectively. According to (\ref{proof_p2_1}) and (\ref{proof_p2_2}),  is,


According to (\ref{proof_p2_3}),  is, 


By considering the relationship between  and  as , (\ref{proof_p2_4}) can be simplified as, 
 
Note that by assuming  for all ,  for . Therefore, we have,
 
 
Now, in order to have , considering (\ref{proof_p2_7}), we should have,

 
Substituting  from (\ref{proof_p2_5}) in  (\ref{proof_p2_8}), we have,

 
Simplifying (\ref{proof_p2_9}), the sufficient condition for  can be written as,


If , 


Furthermore, assuming node  has the lowest , that is ; we have 


Combining (\ref{proof_p2_11}) and (\ref{proof_p2_12}), we have,


Now, considering  (\ref{proof_p2_10}) and (\ref{proof_p2_13}), we can find a new condition for  as,


We define . Table \ref{Energy_table} shows the values of  for  10 to 30 and  1 to 10. As can be seen from Table \ref{Energy_table}, . Therefore, for , the condition of (\ref{proof_p2_14}) holds for any . In other words,  for  LORD consumed less energy per time-slot compared to decentralized model, that is .

Furthermore, note that according to aforementioned analysis, 

which means that  is a lower-bound on the amount of energy that LORD saves compared to decentralized model. As can be seen from Table \ref{Energy_table},
\begin{itemize}
\item For a fixed , as the size of MDC (that is, ) increases,  increases. This means that as the size of MDC increases, LORD saves more energy in comparison with decentralized model.
\item For a fixed , as  increases,  increases. This means that as the demand of nodes for RD increases, LORD saves more energy in comparison with decentralized model.

\end{itemize}

\begin{table*}[b]
\begin{center}
\begin{tabular}{ cc||c|c|c|c|c|c|c|c|c|c||}
\cline{3-12} & & \multicolumn{10}{c||}{}\\
\cline{3-12} &  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 &10 \\ [0.5ex] 
 \hline \hline
\multicolumn{1}{||c|}{\multirow{21}{*}{} }
& 10 &     0.78 &     2.33 &     2.85 &     3.11 &     3.27 &     3.37 &     3.44 &     3.50 &     3.54 &     3.58 \\ 
\multicolumn{1}{||c|}{}
& 11 &     1.80 &     3.35 &     3.87 &     4.12 &     4.28 &     4.38 &     4.46 &     4.51 &     4.56 &     4.59 \\ 
\multicolumn{1}{||c|}{}
& 12 &     2.82 &     4.36 &     4.88 &     5.14 &     5.29 &     5.39 &     5.47 &     5.52 &     5.57 &     5.60 \\ 
\multicolumn{1}{||c|}{}
& 13 &     3.83 &     5.38 &     5.89 &     6.15 &     6.30 &     6.40 &     6.48 &     6.53 &     6.57 &     6.61 \\ 
\multicolumn{1}{||c|}{}
& 14 &     4.85 &     6.38 &     6.90 &     7.15 &     7.31 &     7.41 &     7.48 &     7.54 &     7.58 &     7.62 \\ 
\multicolumn{1}{||c|}{}
& 15 &     5.86 &     7.39 &     7.90 &     8.16 &     8.31 &     8.42 &     8.49 &     8.54 &     8.59 &     8.62 \\ 
\multicolumn{1}{||c|}{}
& 16 &     6.87 &     8.40 &     8.91 &     9.17 &     9.32 &     9.42 &     9.50 &     9.55 &     9.59 &     9.63 \\ 
\multicolumn{1}{||c|}{}
& 17 &     7.88 &     9.41 &     9.92 &    10.17 &    10.32 &    10.43 &    10.50 &    10.55 &    10.60 &    10.63 \\ 
\multicolumn{1}{||c|}{}
& 18 &     8.88 &    10.41 &    10.92 &    11.18 &    11.33 &    11.43 &    11.50 &    11.56 &    11.60 &    11.64 \\ 
\multicolumn{1}{||c|}{}
& 19 &     9.89 &    11.42 &    11.93 &    12.18 &    12.33 &    12.44 &    12.51 &    12.56 &    12.60 &    12.64 \\ 
\multicolumn{1}{||c|}{}
& 20 &    10.89 &    12.42 &    12.93 &    13.18 &    13.34 &    13.44 &    13.51 &    13.57 &    13.61 &    13.64 \\ 
\multicolumn{1}{||c|}{}
& 21 &    11.90 &    13.43 &    13.93 &    14.19 &    14.34 &    14.44 &    14.51 &    14.57 &    14.61 &    14.64 \\ 
\multicolumn{1}{||c|}{}
& 22 &    12.90 &    14.43 &    14.94 &    15.19 &    15.34 &    15.44 &    15.52 &    15.57 &    15.61 &    15.65 \\ 
\multicolumn{1}{||c|}{}
& 23 &    13.91 &    15.43 &    15.94 &    16.19 &    16.35 &    16.45 &    16.52 &    16.57 &    16.62 &    16.65 \\ 
\multicolumn{1}{||c|}{}
& 24 &    14.91 &    16.43 &    16.94 &    17.20 &    17.35 &    17.45 &    17.52 &    17.58 &    17.62 &    17.65 \\ 
\multicolumn{1}{||c|}{}
& 25 &    15.92 &    17.44 &    17.94 &    18.20 &    18.35 &    18.45 &    18.52 &    18.58 &    18.62 &    18.65 \\ 
\multicolumn{1}{||c|}{}
& 26 &    16.92 &    18.44 &    18.95 &    19.20 &    19.35 &    19.45 &    19.53 &    19.58 &    19.62 &    19.66 \\ 
\multicolumn{1}{||c|}{}
& 27 &    17.92 &    19.44 &    19.95 &    20.20 &    20.35 &    20.46 &    20.53 &    20.58 &    20.62 &    20.66 \\ 
\multicolumn{1}{||c|}{}
& 28 &    18.93 &    20.44 &    20.95 &    21.20 &    21.36 &    21.46 &    21.53 &    21.58 &    21.63 &    21.66 \\ 
\multicolumn{1}{||c|}{}
& 29 &    19.93 &    21.45 &    21.95 &    22.21 &    22.36 &    22.46 &    22.53 &    22.58 &    22.63 &    22.66 \\ 
\multicolumn{1}{||c|}{}
& 30 &    20.93 &    22.45 &    22.95 &    23.21 &    23.36 &    23.46 &    23.53 &    23.59 &    23.63 &    23.66 \\ 
\hline
\end{tabular}
\end{center}
\caption{}
\label{Energy_table}
\end{table*}

\section{Suitable Punishment Policy for Phase II}
\label{punishment}
Before the end of each time-slot, the leader should perform an auction among all participants including itself. Since the current leader of the MDC has the responsibility of performing the auction for the next time-slot, such a node can disturb our leader selection process in order to select itself as the next leader by manipulating the values offered by other. In order to avoid such misbehavior, as illustrated in Fig. \ref{figure_5}, we consider a period of time at the end of each auction process where nodes can claim that their bids are manipulated by the current leader. We also consider a consecutive period in which such claims are evaluated by other participants. 

\begin{figure}[h]
\begin{center}
\includegraphics[width=3in,keepaspectratio]{3.png}
\caption{Mobile device cloud management timing}
\label{figure_5}
\end{center}
\end{figure}

According to Fig. \ref{figure_5}, after the auction process and in claim announcement period, nodes are able to object to the result if their bids have been changed by the current leader. If there is only one node with such a claim, it will broadcast a message containing the valid value of its bid. When other nodes receive such a message, in claim justification period, they compare the bid declared by such a node with the one sent by the current leader. In the case that the claim is indeed legitimate, all MDC members except for the current leader confirm such a claim, send a message to such a node, and ask it to perform the leader selection process itself. 

If there is more than one node claiming that the current leader has changed their bids, all nodes process the received messages by comparing the values sent by the current leader with the ones claimed by these nodes. If the claims of such nodes are valid, the current leader is put into the blacklist and deprived of participating in the MDC. Then, among the claimant nodes, the node with the lowest bid is selected as the node which should perform the leader selection process. On the other hand, in the case that the claims are not valid, nodes which have received such claims send a message to the current leader, and ask it to put such nodes in the blacklist due to their fake claim. Then, as a punishment, such nodes are deprived of participating in the MDC.

Considering such punishment policy, the current leader has no incentive to deviate from the truthful strategy. Furthermore, clients have no incentive to misbehave, because they know that they will be punished if they raise an invalid objection.

Since the leader selection process imposes a cost mainly on the leader, based on (\ref{equation:xx1}), the leader receives payment in order to compensate for the cost imposed on it due to performing a leader selection process. Suitable punishment policy such as exclusion from the MDC can be used in order to make sure that the leader does not deviate from performing the auction.

\end{document}
