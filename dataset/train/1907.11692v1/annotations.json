[{'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'RACE', 'Metric': 'Accuracy', 'Score': '83.2'}}, {'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'RACE', 'Metric': 'Accuracy (High)', 'Score': '81.3'}}, {'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'RACE', 'Metric': 'Accuracy (Middle)', 'Score': '86.5'}}, {'LEADERBOARD': {'Task': 'Multi-task Language Understanding', 'Dataset': 'MMLU', 'Metric': 'Humanities', 'Score': '27.9'}}, {'LEADERBOARD': {'Task': 'Multi-task Language Understanding', 'Dataset': 'MMLU', 'Metric': 'Average (%)', 'Score': '27.9'}}, {'LEADERBOARD': {'Task': 'Multi-task Language Understanding', 'Dataset': 'MMLU', 'Metric': 'Parameters (Billions)', 'Score': '0.354'}}, {'LEADERBOARD': {'Task': 'Multi-task Language Understanding', 'Dataset': 'MMLU', 'Metric': 'STEM', 'Score': '27.0'}}, {'LEADERBOARD': {'Task': 'Multi-task Language Understanding', 'Dataset': 'MMLU', 'Metric': 'Social Sciences', 'Score': '28.8'}}, {'LEADERBOARD': {'Task': 'Multi-task Language Understanding', 'Dataset': 'MMLU', 'Metric': 'Other', 'Score': '27.7'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'Quora Question Pairs', 'Metric': 'Accuracy', 'Score': '90.2%'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD2.0', 'Metric': 'EM', 'Score': '86.820'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD2.0', 'Metric': 'F1', 'Score': '89.795'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD2.0 dev', 'Metric': 'F1', 'Score': '89.4'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD2.0 dev', 'Metric': 'EM', 'Score': '86.5'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'CommonsenseQA', 'Metric': 'Accuracy', 'Score': '72.1'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'SWAG', 'Metric': 'Test', 'Score': '89.9'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'QNLI', 'Metric': 'Accuracy', 'Score': '98.9%'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'ANLI test', 'Metric': 'A1', 'Score': '72.4'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'ANLI test', 'Metric': 'A2', 'Score': '49.8'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'ANLI test', 'Metric': 'A3', 'Score': '44.4'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'WNLI', 'Metric': 'Accuracy', 'Score': '89%'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'RTE', 'Metric': 'Accuracy', 'Score': '88.2%'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MultiNLI', 'Metric': 'Matched', 'Score': '90.8'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'MultiNLI', 'Metric': 'Mismatched', 'Score': '90.2'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'MRPC', 'Metric': 'Accuracy', 'Score': '92.3%'}}, {'LEADERBOARD': {'Task': 'Semantic Textual Similarity', 'Dataset': 'STS Benchmark', 'Metric': 'Pearson Correlation', 'Score': '0.922'}}, {'LEADERBOARD': {'Task': 'Sentiment Analysis', 'Dataset': 'SST-2 Binary classification', 'Metric': 'Accuracy', 'Score': '96.7'}}, {'LEADERBOARD': {'Task': 'Type prediction', 'Dataset': 'ManyTypes4TypeScript', 'Metric': 'Average Accuracy', 'Score': '59.84'}}, {'LEADERBOARD': {'Task': 'Type prediction', 'Dataset': 'ManyTypes4TypeScript', 'Metric': 'Average Precision', 'Score': '57.45'}}, {'LEADERBOARD': {'Task': 'Type prediction', 'Dataset': 'ManyTypes4TypeScript', 'Metric': 'Average Recall', 'Score': '57.62'}}, {'LEADERBOARD': {'Task': 'Type prediction', 'Dataset': 'ManyTypes4TypeScript', 'Metric': 'Average F1', 'Score': '57.54'}}, {'LEADERBOARD': {'Task': 'Document Image Classification', 'Dataset': 'RVL-CDIP', 'Metric': 'Accuracy', 'Score': '90.06'}}, {'LEADERBOARD': {'Task': 'Document Image Classification', 'Dataset': 'RVL-CDIP', 'Metric': 'Parameters', 'Score': '125M'}}, {'LEADERBOARD': {'Task': 'Text Classification', 'Dataset': 'arXiv-10', 'Metric': 'Accuracy', 'Score': '0.779'}}, {'LEADERBOARD': {'Task': 'Linguistic Acceptability', 'Dataset': 'CoLA', 'Metric': 'Accuracy', 'Score': '67.8%'}}]
