\documentclass[english]{llncs}
\usepackage[latin9]{inputenc}
\usepackage{babel}

\usepackage{tipa}
\usepackage{amsmath}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{color}
\usepackage{wrapfig}
\usepackage[unicode=true, pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}

\makeatletter

\newtheorem{thm}{Theorem}
\newtheorem{defn}[thm]{Definition}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}

\usepackage[nothing]{algorithm} \usepackage[noend]{algorithmic} 
\usepackage{float}
\newdimen\algorithmicindent \algorithmicindent=0.5cm

\usepackage{color}
\graphicspath{{figures/}{./}}

\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}

\newcommand{\PedanticComment}[1]{\textcolor{blue}{#1}}


\def\var{\mathbb{Var}}
\def\cov{\textrm{Cov}}
\def\bern{\textrm{Bernoulli}}
\def\bin{{\rm Bin}}

\def\geom{{\rm Geom}}
\def\ind{\mathbb{I}}
\def\deg{\textrm{deg}}

\def\al{\alpha}
\def\bt{\beta}
\def\dl{\delta}
\def\lm{\lambda}
\def\ep{\varepsilon}
\def\eps{\varepsilon}
\def\th{\theta}
\def\sgm{\sigma}
\def\sg{\sigma}
\def\Lm{\Lambda}
\def\lm{\lambda}
\def\approx{(1 - 1/k^\varepsilon)}

\newcommand{\ds}{\displaystyle}


\newif\ifnotesw\noteswtrue
\newcommand{\comment}[1]{\ifnotesw \ {\sf #1}\ 
   \fi}

\newif\ifnotesw\noteswtrue
\newcommand{\cm}[1]{\ifnotesw \ {\sf #1}\ 
   \fi}

\def\blfootnote{\xdef\@thefnmark{}\@footnotetext}

\makeatother

\usepackage[affil-it]{authblk}

\begin{document}

\title{Network installation and recovery: approximation lower bounds and faster exact formulations}
\date{}

\author{Alexander Gutfraind\inst{1} \and
Jeremy Kun\inst{2} \and
\'Ad\'am D. Lelkes\inst{2} \and
Lev Reyzin\inst{2}}  

\institute{
Division of Epidemiology and Biostatistics\\
\and
Department of Mathematics, Statistics, and Computer Science\\
University of Illinois at Chicago\\
\texttt{\{agutfrai,jkun2,alelke2,lreyzin\}@uic.edu}
}

\maketitle
 
 
\begin{abstract}
We study the Neighbor Aided Network Installation Problem (NANIP) introduced
previously which asks for a minimal cost ordering of the vertices of
a graph, where the cost of visiting a node is a function of the number of
neighbors that have already been visited. This problem has applications in
resource management and disaster recovery. In this paper we analyze the
computational hardness of NANIP. In particular we show that this problem is
NP-hard even when restricted to convex decreasing cost functions, give a
linear approximation lower bound for the greedy algorithm, and prove a  
general sub-constant approximation lower bound. Then we give a new
integer programming formulation of NANIP and empirically observe its speedup
over the original integer program.

\noindent
\textbf{Keywords}: Infrastructure Network; Disaster Recovery; Permutation
Optimization; Neighbor Aided Network Installation Problem.  
\end{abstract}

\section{Introduction}
\setcounter{footnote}{3} 

We motivate our study with an example from infrastructure networks.  It is
well known that many vital infrastructure systems can be represented as
networks, including transport, communication and power networks.  Large parts
of these networks can be severely damaged in the event of a natural disaster.
When faced with large-scale damage, authorities must develop a plan for
restoring the networks. A particularly challenging aspect of the recovery is
the lack of infrastructure, such as roads or power, necessary to support the
recovery operations.  For example, to clear and rebuild roads, equipment must
be brought in, but many of the access roads are themselves blocked and damaged.
Abstractly, as the recovery progresses, previously recovered nodes provide
resources that help reduce the cost of rebuilding their neighbors. We call this
phenomenon ``neighbor aid''.

Recently, \cite{Gutfraind14} introduced and analyzed a simple
model of neighbor aided recovery in terms of a convex discrete optimization
problem called the \emph{Neighbor Aided Network Installation Problem} (NANIP).
We will henceforth use the terms ``recover'' and ``install'' interchangeably.
For simplicity, we assume that during the recovery of a network all of its
nodes and edges must be visited and restored. They asked how to optimize the
recovery schedule in order to minimize the total cost?  This is also the
question we address herein.

In the NANIP model, the cost of recovering a node depends only on the number of
its already recovered neighbors, capturing the intuition that neighbor aid is
the determining factor of the cost of rebuilding a new node.  NANIP offers a
stylized model for disaster recovery of networks (among other applications) but
the interest in disaster recovery of networks is not new.  A partial list of
existing studies include
\cite{Guha99,nurre2010restoring,Lee07,Adibi94,Bertoli02,coffrin2011strategic}.
A common framework is to consider infrastructure systems as a set of
interdependent network flows, and formulate the problem of minimizing the cost
of repairing such damaged networks.  Another class of models
\cite{Hentenryck10} develops a stochastic optimization problem for stockpiling
resources and then distributing them following a disaster.  More abstract
problems related to NANIP are the single processor scheduling problem
\cite{Karp61}, the linear ordering problem \cite{Mitchell96}, and the study of
tournaments in graph theory \cite{West01}.  

NANIP assumes that certain tasks are dependent and cannot be performed in
parallel, but unlike many scheduling problems, there are no partial order
constraints.  Similarly to traveling salesman problem (TSP)
\cite{schrijver2005history}, the NANIP problem also asks for an optimal
permutation of the vertices of the graph but, unlike in the case of the
traveling salesman problem, the cost associated with visiting a given node
could depend on \emph{all} of the nodes visited before the given node. Another
key difference between NANIP and TSP is that in NANIP it is allowed to visit
nodes that are not neighbors of any previously-visited nodes. As we will see,
such disconnected traversals provide  multiplicative
improvements over connected ones.

Since neighbor aid is assumed to reduce the cost of recovery, we are mainly
interested in decreasing cost functions. Furthermore, since convexity for
decreasing functions captures the ``law of diminishing returns'', i.e. that as
the number of recovered neighbors increases, the per-node value of the aid
provided by one neighbor decreases, convex decreasing functions are of special
interest. Although \cite{Gutfraind14}  gave NP-hardness of
NANIP for general cost via a straightforward reduction from Maximum Independent
Set, the cost function used there was increasing, thus leaving the complexity
of the convex decreasing case an open question.  In this paper we show this
problem is NP-hard as well.  We also provide a new convex integer programming
formulation and analyze the performance of the greedy algorithm, showing that
its worst case approximation ratio is .


\section{Preliminaries}
An instance of NANIP is specified by an undirected graph  and a
real-valued function . The function 
represents the cost of installing a vertex , where the argument is the
number of neighbors of  that have already been installed. Hence, the domain
of  is the non-negative integers, bounded by the maximum degree of  (for
terminology see \cite{West01}).  The goal is to find a permutation of the nodes
that minimizes the total cost of the network installation. The cost of
installing node  under a permutation  of  is given by
 where  is the number of nodes
adjacent to  in  that appear before  in the permutation .
The total cost of installing  according to  is given by


The problem is illustrated in Fig.~\ref{fig:illustration}.  Generally, the
choice of  depends on the application, and  will often be convex
decreasing. 

\begin{figure}[th]
\begin{subfigure}[b]{0.4\textwidth}
\centering
\includegraphics[width=0.5\textwidth]{simple}
\caption{Simple NANIP instance}
\end{subfigure}\begin{subfigure}[b]{0.6\textwidth}
\centering
\includegraphics[width=1.0\textwidth]{Chicago_Loop_schematic} 
\caption{Central Chicago ``Loop''}
\end{subfigure}
\caption{Illustrations of NANIP.
(a) Simple instance.  
When ,  and , the naive installation sequence 
gives cost of , but all optimal solutions have cost .\label{fig:illustration}
(b) Actual metro stations and their connections in downtown Chicago ``Loop''.  
With the same , any optimal sequences must recover Clark/Lake (CL) station before at least one of its neighbors.}
\end{figure}

We assume that  is connected and undirected, unless we note otherwise. If
 has multiple connected components, NANIP could be solved on each component
independently without affecting the total cost.

We begin by quoting a preliminary lemma from \cite{Gutfraind14} which
establishes that all the arguments used in calculating the node costs must sum
to , the number of edges in the network.

\begin{lem}[\cite{Gutfraind14}]
\label{lem:edge-decomp}
For any network , and any permutation  of the nodes of , 

\end{lem}

One application of this lemma is the case of a linear cost function
, for some real numbers  and .  With such a function the
optimization problem is trivial in that all installation permutations have the
same cost.

In the next section we will prove hardness results about NANIP; let us recall
some relevant definitions.

\begin{defn}

An optimization problem is called \emph{strongly NP-hard} if it is NP-hard and
the optimal value is a positive integer bounded by a polynomial of the input
size.

\end{defn}


\begin{defn}

An algorithm is an \emph{efficient polynomial time approximation scheme
(EPTAS)} for an optimization problem if, given a problem instance and an
approximation factor , it runs in time 
for some constant  and some function  and finds a solution whose
objective value is within an  fraction of the optimum. An EPTAS is
called a \emph{fully polynomial time approximation scheme (FPTAS)} it runs in
polynomial in the size of the problem instance and .  

\end{defn}

A strongly NP-hard optimization problem cannot have an FPTAS unless
P=NP: otherwise, if  denotes the input size and  denotes the polynomial
such that the optimum value is bounded by , setting
 for the FPTAS would yield an exact polynomial
time algorithm.

Some NP-hard problems become efficiently solvable if a natural parameter is
fixed to some constant. Such problems are called fixed parameter tractable.

\begin{defn}
FPT, the set of \emph{fixed parameter tractable} problems, is the set
of languages  of the form 
such that there is an algorithm running in time  for some function
 and constant  deciding whether .
\end{defn}

An example of a fixed parameter tractable problem is the vertex cover problem
(where the parameter is the size of the vertex cover). 
Problems believed to be fixed parameter intractable include the graph coloring problem
(the parameter being the number of colors) and the clique problem (with the size of 
the clique as parameter).

For parametrized languages, there is a natural fixed parameter tractable analogue of polynomial time reductions.
These so-called \emph{fpt-reductions} are used to define hardness for classes of parametrized languages,
similarly to how NP-hardness is defined using polynomial time reductions.
One important class of parametrized languages is . For the definition of  and for more background
on parametrized complexity, we refer the reader to the monograph of Downey and Fellows~\cite{DowneyF13}.
They proved that under standard complexity-theoretic assumptions,  is a strict superset of
; consequently, -hard problems are fixed parameter intractable.
We will use this fact to show the fixed parameter intractability of NANIP.


\section{Convex decreasing NANIP is NP-hard} \label{sec:computation} We now
consider the hardness of solving NANIP with convex decreasing cost functions.

\begin{thm} \label{thm:np-hard} The Neighbor Aided Network Installation Problem
is strongly NP-hard when  is convex decreasing; as a consequence it admits
no FPTAS. \end{thm}

\begin{proof} 

We reduce from CLIQUE, that is, the problem of deciding given a graph  whether it contains as an induced subgraph the complete graph on 
vertices.  Given a graph  with  and an integer , we
construct an instance of NANIP on a graph  with a convex cost function
 as follows.  Define  by adding  new vertices  to
 which are made adjacent to every vertex in  but not to each other, establishing
an independent set of size .
Define the cost function 




Let .  In a traversal  whose
first  vertices yield cost , every new vertex must be adjacent to every
previously visited vertex, i.e. the vertices form a -clique.  Moreover, 
is the lower bound on the cost incurred by the first  vertices of any
traversal of . 

Suppose that  has a clique of size , and denote by  the
vertices of the clique, with  the remaining vertices of
. Then the following ordering is a traversal of  of cost exactly :


Conversely, let  be an ordering of the vertices of 
achieving cost .  Then by the above, the vertices  must
form a -clique in .  In the case these  prefix vertices are all
vertices of  we are done.  Otherwise, the independence of the 's
implies that at most one  is used in ; using more
would incur a total cost greater than .  In this case the  remaining
vertices of the prefix form a -clique of .
Since it is NP-hard to approximate CLIQUE within a polynomial factor
\cite{Zuckerman06}, this proves the NP-hardness of convex decreasing NANIP.

Moreover, since the optimum value of a NANIP instance obtained by this reduction
is at most  which is upper bounded by , the size of the NANIP instance,
it also follows that convex decreasing NANIP is strongly NP-hard and therefore
does not admit an FPTAS. 

\end{proof}

The cost function  used in the proof of Theorem~\ref{thm:np-hard} is
parametrized by .  Call  the subproblem of NANIP with cost
functions of finite support where the size of the support is . Because we
consider  a subproblem of general NANIP, stronger
parametrized hardness results for the former give insights about the latter.
Indeed, the following corollary is immediate.

\begin{cor}
 is -hard.
\end{cor}

\begin{proof} 

CLIQUE is -complete when parametrized by the size of the clique.
-hardness is preserved by so-called -reductions (see
\cite{DowneyF13}), and the reduction from the proof of
Theorem~\ref{thm:np-hard} is such a reduction. 

\end{proof}

In particular, standard complexity assumptions imply from this that
 is not fixed-parameter tractable and has no efficient
polynomial-time approximation scheme (EPTAS). Now we will show that the same
reduction can be used to obtain a stronger approximation lower bound of  for all . First a lemma.

\begin{lemma}
Let  and  constructed as above, and let  denote a NANIP
traversal.  Suppose  denote the vertices of  and  denote the vertices
of the independent set.  If  is obtained from  by moving the
 to positions  (without changing the precedence relations of the vertices
in ), then .
\end{lemma}


\begin{proof}
Consider the positions in  of the first  vertices from , and let
 be the positions of the vertices from . Call .

\textbf{Case 1:} . In this case all the  are free, as are all
vertices visited after . If , apply the cyclic permutation
 to move  to position . The cost
of visiting  is still zero, and the cost of the other manipulated vertices
does not increase because they each gain one previously visited neighbor. Now
repeat this manipulation with  for . An identical argument shows the cost never increases, and at the end
we have precisely . 

\textbf{Case 2:} . In this case  is not free. Let  be the
index of the first  that occurs after . Then apply the
cyclic permutation  to move  before .
The cost of  increases by at most  (and this is not tight since it
is possible that ). But since all , and they each gain a neighbor as a result of applying
, so their total cost decreases by exactly , and the total cost
of  does not increase. Now repeatedly apply  (using the new values
of ) until . Then apply case 1 to finish.

\end{proof}


\begin{thm}
For all , there is no efficient -approximation
algorithm for NANIP on graphs with  vertices with convex decreasing cost
functions, unless .  
\end{thm}

\begin{proof}
It is NP-hard to distinguish a clique number of at least  from a clique
number of at most  in graphs on  vertices ()
\cite{Zuckerman06}.  We will reduce this problem to finding an
-approximation for NANIP.  In particular, we will show that there
is no efficient -approximation approximation algorithm for NANIP, where  and
.

This is equivalent to the statement of the theorem since by setting
, we get that there is no efficient
-approximation
algorithm for NANIP.

Let  be a graph on  vertices containing a -clique
where  and construct  from  by adding a
-independent set as before, with . Suppose we have an
efficient -approximation algorithm for NANIP. After running it on input
, modify the output sequence according to the previous lemma. Then all
the nodes after the first  are free, thus the cost of the sequence is
determined by the first  vertices. Since they all have fewer than 
preceding neighbors, the cost function for them is linear, implying that the
total cost of the sequence depends only on the number of edges in between the
first  vertices.

The cost of the optimal NANIP sequence in  is , thus the cost of
the sequence returned by the approximation algorithm is at most



Since  it
follows by \cite{Gutfraind14}, Corollary 2, that there are more than
 edges between the first  vertices.

Tur\'an's theorem~\cite{Turan1941} states that, a graph on  vertices that
does not contain an -clique can have at most  edges.
The contrapositive implies that the induced subgraph on the first  vertices
of the NANIP sequence contains a -clique.  Since , this completes the proof.

\end{proof}





\section{Greedy analysis for convex NANIP}

In this section we discuss the approximation guarantees of the greedy algorithm
on convex NANIP. The greedy algorithm is defined to choose the
cheapest cost vertex at every step, breaking ties arbitrarily. A useful
observation here is that the greedy algorithm always produces a connected
traversal of a connected graph, in the sense that every prefix of the final
traversal induces a connected subgraph. We call an algorithm which always produces a
connected traversal a \emph{connected algorithm}.

Our next theorem shows a rather surprising result, that optimal recovery
sometimes requires disconnected solutions, even on convex cost functions.
Connected solutions can perform quite badly, having a cost that is a
 multiple of the optimum.

\begin{thm}
Connected algorithms have an approximation ratio  for convex
NANIP problems.
\end{thm}

\begin{proof}

We construct a particular instance for which a connected algorithm incurs cost
 while the optimal route has constant cost. Define the graph
 to be a complete binary tree  with  levels, and a pair of vertices
 such that the leaves of  and  form the complete bipartite
graph . As an example,  is given in Figure~\ref{fig:b3}.

\begin{figure}[th]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \scalebox{0.45}{\includegraphics{binary-tree-gadget}}
\end{subfigure}\begin{subfigure}{.5\textwidth}
  \centering
  \scalebox{0.40}{\includegraphics{connected-ctex}}
\end{subfigure}
\caption{Left: the graph ; Right: two  pieced together to force a
connected algorithm to incur  cost.}
\label{fig:b3}
\end{figure}

Define the cost function  such that , and 
for all . For this cost function it is clear that the minimum cost of
a traversal of  is exactly 4 by first choosing the two vertices of 
that are not part of the tree, and then traversing the rest of the tree at zero
cost. However, if a connected algorithm were forced to start at the root of the
tree, it would incur cost  since every vertex
would have at most one visited neighbor. 

To force such an algorithm into this situation we glue two copies of 
together so that their trees share a root. Then any connected ordering must
start in one of the two copies, and to visit the other copy it must pass
through the root, incurring a total cost of . On the other
hand, the optimal traversal has total cost 8. 

\end{proof}

Further, the greedy algorithm, which simply chooses the cheapest vertex at each
step and breaks ties arbitrarily, gives a  approximation ratio in
the worst case. To see this, note that in the construction from the theorem the
only way a connected algorithm can achieve the logarithmic lower bound is by
traveling directly from the root to the leaves. But by breaking ties
arbitrarily, the greedy algorithm may visit every interior node in the tree
before reaching the leaves, thus incurring a linear cost overall.



\section{Integer programming for NANIP}\label{section:IP}

In this section we describe a new integer programming (IP) formulation of the
NANIP problem by adding in Miller-Tucker-Zemlin-type subtour elimination
constraints~\cite{miller1960integer}.  An IP, of course, does not give a
polynomial time algorithm, but can be sufficiently fast for some instances of
practical interest.  We then show that this formulation, experimentally,
improves on the previous formulation by \cite{Gutfraind14}.

\subsection{A new integer program}

In what follows we will assume that the cost function  is a continuous
convex decreasing function  rather
than one . It is necessary to extend  to
a continuous function for the LP relaxation to be well-defined.  While there
are many ways to do so, formulating the IP for a general continuous 
encapsulates all of them.

For an undirected graph  on  vertices, and introduce the
arc set  by replacing each undirected edge with two directed arcs.  For all
 define variables .  The choice 
has the interpretation that  is traversed before  in a candidate ordering
of the vertices, or that one chooses the directed edges  and discards
the other. In order to maintain consistency of the IP we impose the constraint
 for all edges  with . Finally, we wish to
enforce that choosing values for the  corresponds to defining a partial
order on  (i.e., that the subgraph of chosen edges forms a DAG). We use the
subtour elimination technique of Miller, Tucker, and Zemlin
\cite{miller1960integer} and introduce variables  for 
with the constraints


\noindent Thus, if  is visited before  then .
Now denote by , which is the number of
neighbors of  visited before  in a candidate ordering of . The
objective function is the convex function , and putting these
together we have the following convex integer program: 

\begin{figure}[th]
\begin{centering}

\end{centering}
\end{figure}

The integer program has a natural LP relaxation by replacing the integrality
constraints with . 
Because  is only evaluated at integer points, it is possible to replace 
with a real-valued variable bound by a set of linear inequalities, as detailed in~\cite{Gutfraind14}.

\subsection{Experimental results}

We compared the new IP formulation with the formulation of
\cite{Gutfraind14}, in the algebraic optimization framework
(IBM ILOG CPLEX 12.4 solver) running with a single thread on Intel(R) Core(TM)
i5 CPU U 520  @ 1.07GHz with 3.84E6 kB of random access memory.  The simulation
used graphs on 15 nodes, where the number of edges was increased from 14 (tree)
until the running time exceeded 1 hour.  For each edge density, we constructed
5 graphs and reported the average running time of the two algorithms.

From the computational experiments it is clear that our formulation gives
significant improvements.  For instance, the solve time seems to not depend on
the number of nodes in the graph (Fig.~\ref{fig:iptime}(a)), unlike in the
previous formulation.  We are also able to solve NANIP instances on 45 edges in
under an hour, whereas the previous formulation solved only 30 edge graphs in
that time (Fig.~\ref{fig:iptime}(b)).

\begin{figure}[th]
\begin{centering}
(a)\includegraphics[width=0.45\textwidth]{perf_ip_nodes} 
(b)\includegraphics[width=0.45\textwidth]{perf_ip_edges} 
\par
\end{centering}
\caption{A comparison of the formulations in
\cite{Gutfraind14} and our new IP formulation with MTZ-type
constraints.  This graph plots running time vs.\ (a) number of nodes and, (b)
number of edges in the target graph.
In (a) the number of edges was kept at 30 throughout, while in (b) the number
of nodes was 15 throughout.\label{fig:iptime}} 
\end{figure}


\section{Conclusion} \label{sec:concl}
We analyzed the recently introduced Neighbor-Aided Network Installation
Problem.  We proved the NP-hardness of the problem for the practically most
relevant case of convex decreasing cost functions, addressing an open problem
raised in \cite{Gutfraind14}.  We then showed that the worst case approximation
ratio of the natural greedy algorithm is .  We also gave a new IP
formulation for optimally solving NANIP, which outperforms previous
formulations.

The approximability of NANIP remains an open problem. In particular, it is
still not known whether an efficient  approximation algorithm exists for
general convex decreasing cost functions. One obstacle to finding a good
rounding algorithm is that the IP we presented has an infinite integrality gap.
As proof, the graph  with the function  has
 but the linear relaxation has . So an approximation algorithm via LP rounding would require a different IP
formulation.

\section*{Acknowledgments and Funding}
We thank our colleagues for insightful discussions.
AG was supported in part by an ORISE fellowship at the Food and Drug Administration.
CPLEX software was provided by IBM through the IBM Academic Initiative program.

\bibliographystyle{plain}
\bibliography{nanip}

\end{document}
