

\newif\ifJFP
\JFPfalse
\ifJFP
\documentclass{jfp1}
\else
\documentclass[a4paper,12pt,fullpage]{article}
\fi
\ifJFP \else 
\usepackage{fullpage} 
\usepackage{amsmath}
\newenvironment{proof}[1]{\begin{quotation}\noindent\textsf{Proof:} #1}
{\end{quotation}}
\usepackage{authblk}
\fi
\usepackage{marvosym}
\usepackage{alltt}
\usepackage{lscape}
\usepackage{url}
\usepackage[all]{xy}
\usepackage{qsymbols}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{enumerate}

\newtheorem{theo}{Theorem}
\newtheorem{fact}[theo]{Fact}
\newtheorem{prop}[theo]{Proposition}
\newtheorem{lemma}[theo]{Lemma}
\newtheorem{corollary}[theo]{Corollary}
\newtheorem{conj}[theo]{Conjecture}

\newcommand{\ie}{i.e.,~}
\newcommand{\nat}{\ensuremath{\mathbb{N}}}
\newcommand{\E}{\mathcal{E}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\T}{\mathcal{T}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\G}{\mathcal{G}}
\newcommand{\U}{\mathcal{U}}
\newcommand{\Uu}{U_1}
\newcommand{\Y}{\mathcal{Y}}
\newcommand{\Fw}{\mathcal{F}_w}
\newcommand{\Gw}{\mathcal{G}_w}
\newcommand{\Var}[1]{\underline{\mathsf{#1}}}
\newcommand{\PNF}{{}^{\tiny \textsf{NF}}\!P}
\newcommand{\QNF}{{}^{\tiny \textsf{NF}}\!Q}
\newcommand{\p}[2]{p^{[#1]}_{#2}}
\newcommand\subrel[2]{\mathrel{\mathop{#2}\limits_{#1}}}
\newcommand{\simtozero}{\subrel{z \to z_0}{\sim}}

\usepackage[usenames,dvipsnames]{color}
\definecolor{darkbrown}{cmyk}{.3,.75,.75,.15}
\definecolor{vertfonce}{rgb}{0,.5,0}
\newcommand{\brown}[1]{{\color{darkbrown} #1}}
\newcommand{\rouge}[1]{{\color{red} #1}}
\newcommand{\bl}[1]{\textcolor{blue}{#1}}
\newcommand{\verte}[1]{{\color{green}#1}}
\definecolor{vertfonce}{rgb}{0,.5,0}
\newcommand{\verdir}[1]{{\color{vertfonce} #1}}
\newif\ifcomment

\commenttrue           

\newcommand{\comment}[2]{\ifcomment
                         \begin{bf}#1: \color{blue}{#2}
                           ***\end{bf}
                         \fi}
\newcommand{\Kassia}[1]{\comment{\color{PineGreen}{Kassia}}{#1}}
\newcommand{\Kas}[1]{\ifcomment {\color{Green} {#1}} \else #1\fi}
\newcommand{\pierre}[1]{\ifcomment {\color{darkbrown} {#1}} \else #1\fi}
\newcommand{\compier}[1]{\comment{\color{RedOrange}{Pierre}}{#1}}


\ifJFP
\title[Counting and generating lambda terms]{Counting and generating lambda terms}
\author[K. Grygiel and P. Lescanne]{Katarzyna Grygiel
\thanks{This work was supported by the National Science Center of Poland, grant number 2011/01/B/HS1/00944, when the author hold a post-doc position at the Jagiellonian University within the SET project co-financed by the European Union.}\\
 \and\\
Pierre Lescanne\10pt]
ENS de Lyon, University of Lyon, \\
LIP (UMR 5668 CNRS ENS Lyon UCBL INRIA)\\ 46 all\'ee
d'Italie, 69364 Lyon, France\\
\email{grygiel@tcs.uj.edu.pl,pierre.lescanne@ens-lyon.fr}
}
\else
\title{Counting and generating lambda terms}
\author[1]{Katarzyna Grygiel\thanks{This work was supported by the National Science Center of Poland, grant number 2011/01/B/HS1/00944, when the author hold a post-doc position at the Jagiellonian University within the SET project co-financed by the European Union.}
\thanks{\textsf{email:} grygiel@tcs.uj.edu.pl}}
\author[1,2]{Pierre Lescanne\thanks{\textsf{email:} pierre.lescanne@ens-lyon.fr}
}
\affil[1]{Theoretical Computer Science Department

Faculty of Mathematics and Computer Science

Jagiellonian University 

ul. Prof. {\L}ojasiewicza 6, 30-348 Krak\'ow, Poland
\medskip
}

\affil[2]{ENS de Lyon

 LIP  (UMR 5668 CNRS ENS Lyon UCBL INRIA)

University of Lyon

46 all\'ee d'Italie, 69364 Lyon, France
}
\fi

\begin{document}

\maketitle

\begin{abstract}
  Lambda calculus is the basis of functional programming and higher order proof
  assistants.  However, little is known about combinatorial properties of lambda
  terms, in particular, about their asymptotic distribution and random
  generation. This paper tries to answer questions like: How many terms of a given
  size are there?  What is a ``typical'' structure of a simply typable term?  Despite
  their ostensible simplicity, these questions still remain unanswered, whereas
  solutions to such problems are essential for testing compilers and optimizing
  programs whose expected efficiency depends on the size of terms.  Our approach
  toward the aforementioned problems may be later extended to any language with bound
  variables, i.e., with scopes and declarations.

  This paper presents two complementary approaches: one, theoretical, uses complex
  analysis and generating functions, the other, experimental, is based on a generator
  of lambda terms.  Thanks to de Bruijn indices, we provide three families of
  formulas for the number of closed lambda terms of a given size and we give four
  relations between these numbers which have interesting combinatorial
  interpretations.  As a by-product of the counting formulas, we design an algorithm
  for generating -terms.  Performed tests provide us with experimental data, like
  the average depth of bound variables and the average number of head lambdas. We
  also create random generators for various sorts of terms.  Thereafter, we conduct
  experiments that answer questions like: What is the ratio of simply typable terms
  among all terms?  \emph{(Very small!)}  How are simply typable lambda terms
  distributed among all lambda terms?  \emph{(A~typable term almost always starts
    with an abstraction.)}

  In this paper, abstractions and applications have size  and variables have
  size~.

  \medskip

  \noindent \textbf{Keywords:} lambda calculus, combinatorics, functional
  programming, test, random generator, ranking, unranking

\end{abstract}

\ifJFP \pagebreak[4] \fi

\section{Introduction}
\label{sec:introduction}

Let us start with a few questions relevant to the problems we address.
\begin{itemize}
\item How many closed -terms are of size  (up to -conversion)?

\item How many closed terms of size  are there?\\
\emph{We will give a recursive formula for this number in Section~.}
\item What does the following sequence enumerate:
   \emph{This
    sequence enumerates closed terms of size , , , , , , , ,
    , , .  It is the sequence A220894 of the Online Encyclopedia of Integer
    Sequences (\url{https://oeis.org/A220894}).  We will provide three ways to compute
    it (Section~). }
\item Is it possible to generate simply typable terms randomly?\\
  \emph{Yes, according to the process which consists in generating random -terms
    with uniform probability and sieving those that are simply typable.  Thus, we can
    generate random simply typable terms of size up to .}
\item Is a term starting with an abstraction more likely to be typable than a term
  starting with an application?\\
\emph{The answer is positive as shown in Figure~,
  which gives the distribution of simply typable -terms among all -terms.}
\item Do these results have practical consequences?\\
\emph{Yes, they enable random generation of simply typable terms in the case of terms of size
  up to  in order to debug compilers or other programs,
  manipulating terms, e.g., type checkers or pretty printers.}
\end{itemize}

The above questions seem rather classical, but amazingly very little is known about
combinatorial aspects of -terms, probably because of the intrinsic difficulty of
the combinatorial structure of lambda calculus due to the presence of bound
variables.    However, the answers to these questions are extremely
important not only for a better understanding of the structure of -terms, but also
for people who build test samples for debugging compilers.  Perhaps the
reason for this ignorance lies in the surprising form of the recurrences.  Indeed, due to the
presence of bound variables, the recurrence does not work in the way mathematicians expect
and are used to.  The induction lies on two variables, one decreasing (the size),
the other increasing (the number of free variables). 
Thus none of the methods used in the reference book of
Flajolet and Sedgewick \cite{flajolet08:_analy_combin} applies.  Why is that?  In what
follows we compute the number of -terms (and of normal forms) of size  with at
most  distinct free variables.  Denoting the number of such terms by , the formula for
 contains  and this growth of  makes the formula averse to
treatments by generating functions and classical analytic combinatorics.  We notice that
for a given  the expression for  is a polynomial in .  These polynomials can
be described inductively and their coefficients are given by recurrence formulas.  These formulas
are still complex, but can be used to compute the constant coefficients, which correspond
to the numbers of closed -terms.  For instance, the leading coefficients of the
polynomials are the well known Catalan numbers which count binary trees.

In order to find the recurrence formula for the number of \mbox{-terms} of a
given size, we make use of the representation of variables in -terms by de Bruijn
indices.  Recall that a de Bruijn index is a natural number which replaces a term
variable and enumerates the number of 's encountered on the way between the
variable and the  which binds the latter.  In this paper, we assume the
combinatorial model in which the size of each occurrence of abstraction or
application is counted as , while the size of variables (de~Bruijn indices)
as~.  This method is a realistic model of the complexity of -terms and allows
us to derive the recurrences very naturally.  


From the formula for counting -terms we derive one-to-one assignments of terms of
size  with at most  distinct free indices to the numbers in the interval
.  From this correspondence, we develop a program for generating
-terms, more precisely for building -terms associated with numbers in the
interval .  In combinatorics the function that counts objects by
assigning a number to each object is called a \emph{ranking} and its inverse, i.e.,
the function that assigns an object to a rank is called an
\emph{unranking}~\cite{integer:ranking}.  Thus, in this paper, we can say that we rank and unrank
lambda-terms and normal forms.  If we pick a random number in the interval
, then we get a random term of size  with at most  distinct free
variables.  Most of the time we consider closed -terms, which means .
Beside the interest in such a random generation for applications like testing, this
allows us to compute practical values of parameters by Monte-Carlo methods.  Overall,
we are able to build a random generator for simply typable terms. Unlike the method
used so far \cite{Palka:2011:TOC:1982595.1982615}, which consists in unfolding the
typing tree, we generate random \mbox{-terms} and test their typability, until we
find a simply typable term.  This method allows us to generate uniformly simply
typable -terms up to size .  We also use this method to describe the
distribution of typable terms among all terms and typable normal forms among all
normal forms.


\subsection*{Structure of the paper}
\label{sec:structure-ther-paper}

According to its title, the paper is divided into two parts, the first one focuses on counting terms
and its mathematical treatment, the second one addresses term generation and its applications. The
first part (Sections~\ref{sec:polyn-count-lambd} and \ref{sec:generating}) is devoted to
the formulas counting -terms.  In Section~\ref{sec:polyn-count-lambd} we study
polynomials giving the numbers of terms of size~ with at most  distinct free
variables.  In
Section~\ref{sec:an-comb-interpr}, we show that the numbers of -contexts give a
combinatorial interpretation of the coefficients of the polynomials and yield a new formula
for counting the closed terms of size . If we add formulas for counting -terms of
size  with exactly  distinct free variables, we have three formulas of three different origins for
counting closed terms which we describe and compare in Section~\ref{sec:three-formulas}.
In Section~\ref{sec:generating} we derive generating functions and asymptotic values for
these coefficients.  In Section~\ref{sec:count-norm-forms} we give a formula for counting
normal forms.  In the second part of the paper, \ie in Section~\ref{sec:lambda-term-gener} and
Section~\ref{sec:simply-typed-terms}, we propose programs to generate untyped and typable
terms and normal forms.  Section~\ref{sec:exper-data} is devoted to experimental
results.  Section~\ref{sec:related-work} presents related works.









\section{Counting terms with at most  distinct free variables}
\label{sec:polyn-count-lambd}


We represent terms using de Bruijn indices \cite{deBruijn72}, which means that
variables are represented by numbers ,
where an index, for instance~, is the number of 's above the location of
the index and below the~ that binds the variable, in a representation of
-terms by trees.  For instance, the term with variables  is
represented by the term with de Bruijn indices . The variable
 is bound by the top~.  Above the occurrence of~ there are two 's,
therefore  is represented by , and from the occurrence of~ we count
just the~ that binds , so  is represented by .  Notice that unlike
\ifJFP Lescanne~\shortcite{LescannePOPL94} \else Lescanne~\cite{LescannePOPL94} \fi and like
\ifJFP de Bruijn~\shortcite{deBruijn72} and Abadi \emph{et al.}
\shortcite{AbadiCCL91JFP} \else de Bruijn~\cite{deBruijn72}  and Abadi \emph{et
  al.}~\cite{AbadiCCL91JFP} \fi we start
indices at , since it fits better with our aim of counting terms.

In what follows, by \emph{terms} we mean untyped terms with de Bruijn indices and we
often speak indistinctively of variables and (de Bruijn) indices.  Assume that in a
term~ not all occurrences of indices need to be bound, i.e., there may occur indices that do
not correspond to surrounding 's. Such indices are called ``free'' in .  Now,
we introduce the notational convention for ``free'' indices occurring in terms. An
\emph{interval of free indices} for a term  is a set  of indices, written , such that
\begin{enumerate}[(i)]
\item if  is an index , then any interval  with  is an interval for ,
\item if  is an abstraction  and an interval of free indices for  is
  , then the interval of free indices for  is
   (since the index  is now bound and the others are
  assumed to decrease by one),
\item if  is an application  and an interval of indices for  and
   is , then an interval of indices for  is
  .
\end{enumerate}
To illustrate (ii), assume . An interval of free
indices for  is  for any .  For
instance for ,  is an interval of free
indices for .  For ,  is another interval of
free indices for . An interval of free indices for  is  
for any  and for ,  is an
interval of free indices for .  For ,  is another interval
of free indices for .  To say it in rough words, whereas one sees  as
 in , one sees  as  in  due to the abstraction 
which decreases the indices as they are seen.

We measure the size of a term in the following way:


Since -terms can be represented as unary-binary trees with labels or pointers,
the notion of size of a term  corresponds to the number of unary and binary
vertices in the tree representing . This also means that adding a new variable (in
other words, adding a new leaf to a tree) or a new operator (a unary or a binary
vertex) always increases the size of a term by .

One can define  using the concept of term openness (due to John Tromp).  The \emph{openness} of a
terms is the minimum number of outer 's necessary to close the terms, i.e., to
make the term a closed term.  For instance, the openness of  is equal to  since the term needs two abstractions to become closed.

Let us denote by  the set of terms of size  with at most  distinct
free de Bruijn indices.   is isomorphic to the set of terms having an
openness equal to at most~.  In what follows, we use the symbol  to denote
applications, whereas classical theory of -calculus uses concatenation, which we
find not explicit enough for our purpose.



For all , let  denote the cardinality of the set
. According to the
definition of size, operators  and  have size  and de Bruijn indices have
size~. Therefore, we get the following two equations specifying :



This means that there are  terms of size  with at most  distinct free de Bruijn indices, which are terms
that are just these indices.   Terms of size  with at most  distinct free de
Bruijn indices are either abstractions with at most  distinct free indices on a term of size
 or applications of terms with at most  distinct free indices to make a term of size .  As we said in the introduction, the  first values of  are:
  is sequence \textbf{A220894} in the \emph{On-line Encyclopedia of Integer Sequences}.
\begin{figure*}
  \centering
  \begin{tiny}
    
  \end{tiny}
  \caption{Values of  for  and  up to  and , respectively}
  \label{fig:T_n_m}
\end{figure*}

Figure~\ref{fig:T_n_m} gives all the values of  for  up to  and  up
to~.  For instance, there is  closed term of size , namely , there are
 closed terms of size , namely ,
and there are  closed terms of size , namely



\begin{center}
  
\end{center}

Notice that in Section~\ref{sec:lambda-term-gener} we describe how to assign a term 
to a number and therefore how to list terms with increasing numbers.  The above terms
are listed in that order.

\subsection{Computing the 's}
\label{sec:actual}

The recursive definition of  yields an easy naive program in a functional
programming language (here \textsf{Haskell}):
\begin{verbatim}
naiveT :: Int -> Int -> Integer
naiveT 0 m = fromIntegral m
naiveT n m = naiveT (n-1) (m+1) + 
             sum [naiveT i m * naiveT (n-1-i) m | i <- [0..n-1]]
\end{verbatim}
This program is inefficient since it recomputes the values of  at each recursive
call.   For actual computations a program with memoization is required.  In
\textsf{Sage}  this is obtained by requiring the function to be ``cached''. In
\textsf{Haskell} we use the laziness of streams:
\begin{verbatim}
ttab' :: [[Integer]]
ttab' = [0..] : [[t' (n-1) (m+1) + s n m | m <- [0..]] | n <- [1..]]
  where s n m = sum   ti n m)
        ti n m = [t' i m | i <- [0..(n-1)]]

t' :: Int -> Int -> Integer
t' n m = ttab !! n !! m
\end{verbatim}
This program is not efficient enough and John Tromp proposed us a better program:
\begin{verbatim}
ttab :: [[[Integer]]]
ttab = iterate nextn . map return  zipWith (*) ms (reverse ms)
  
t :: Int -> Int -> Integer
t n m = head O(n)O(n)O(n)O(n)O(log^2(T_{n,0}))T_{n,0}nn^nO(n^3\times log^2(T_{n,0}))n^5n^5 \log^2 (n)O(n+m)P_n`l`ln \geq 0T_{n,m}P_n(m)mP_n\left( P_n(0) \right)_{n \geq 0}\left(
  T_{n,0} \right)_{n \geq 0}`lP_nP_n(m)`lnnP_nn+1nP_ni>0n\geq 0\p{i}{n}i^{th}P_nn \geq 0i > 0P_0(m)=mi^{th}P_{n+1}(m)m^{n+3-i}P_n(m+1)\sum_{j=0}^{n} P_j(m) P_{n-j}(m)P_n(m+1)m^{n+3-i}P_n(m+1)\sum_{j=0}^{n} P_j(m) P_{n-j}(m)m^{n+3-i}\sum_{j=0}^{n} P_j(m) P_{n-j}(m)\p{i}{j}`lii`l01, \ldots, i[\ ](`l \Var{1} [\ ])`l `l [\ ]\Var{2}26(`l \Var{1} [\
]_{\bl{1}})`l `l [\ ]_{\bl{2}}\Var{2}010i0i\neq 1c_{n,i}inin+1jj \in [i..n+1]nj-ijj{j \choose i}\,c_{n,j}ijin+1ijk(i-j)n-kj \in [0..i]k \in [0..n]in+11jkc_{k,j}c_{n-k,i-j}ij=0j=ik=0k=niniminf[1..i][1..m]f(j)j^{th}c_{n,i} m^i\lambdanmP_n(m)c_{n,n+2-i} = \p{i}{n}c_{n,i}P_ninc_{n,i}=0i>n+1i=n+2i=n+2c_{n,i}=0i>n+1(\dagger)(\star)(n+1)n(c_{n,i})_{n,i \in \nat}1\mathcal{L}`liL(z,0)nT_{n,0}M(z,u)z_u1-4z_u u - 2z_u M(z_u,u+1) = 0M(z,u+1)z_u M(z_u,u+1)>0z_u<\frac{1}{4u}L(z,0)(z_u)_{u`:\nat}0L(z,0)R\left(\frac{1}{R}\right)^n0a^na`:\ensuremath{\mathbb{R}}n[k=j]1k=j0k\neq jm=0mT_{n,0}m=0mf_{n,0}0c_{n,0}R^{(m)}_i[1..i][1..m]T_{n,m}f_{n,m}c_{n,i}k^{th}P_nia_i\left( \p{i}{n} \right)_{n \geq 0}\p{i}{n}nn+2-ia_i(z)a_ia_ifg\left( f_n \right)_{n \geq 0}\left( g_n \right)_{n \geq 0}\left( {n \choose k}f_n \right)_{n \geq 0}k\frac{z^k f^{(k)}}{k!}\left( \sum_{i=0}^n f_i g_{n-i} \right)_{n \geq 0}f \cdot g\left( {n-j \choose i} f_n \right)_{n \geq 0}i \geq 0j > 0\sum_{k=0}^{i} (-1)^k {k+j-1 \choose j-1}z^{i-k} \frac{f^{(i-k)}}{(i-k)!}n,i \geq 0j > 0a_ia_ia_i1-2a_1 z= \sqrt{1-4z}a_1a_7P_n(m)a_1a_1(z) =
\frac{1-\sqrt{1-4z}}{2z}[z^n]f(z)n^{th}z^nf(z) = \sum_{n=0}^{\infty} f_n z^n\simf_n \sim g_n(f_n/g_n)_{n\geq 0}1f(z) \simtozero g(z)f(z)/g(z)1z \to z_0f(z)g(z)z \to z_0Af(z) \simtozero A\cdot g(z)\alpha\mathbb{C}\setminus \mathbb{Z}_{\leq 0}z^n\Gamma\Re(\alpha) > 0a_iz \to 1/4C_ii^{th}\sim\subrel{z \to \frac{1}{4}}{\sim}z \to 1/4i=1i>1j\le ia_j(z)\frac{1}{(1-4z)^{(2j-3)/2}}(\ddagger)a_{i+1}(z)\frac{1}{(1-4z)^{(2i-1)/2}}i^{th}a_1\frac{1}{(1-4z)^{(2i-1)/2}}(i-2)^{th}\frac{1}{(1-4z)^{(2i-5)/2}}(i-3)^{th}\frac{1}{(1-4z)^{(2i-7)/2}}i^{th}a_2\frac{1}{(1-4z)^{(2i+1)/2}}(i-3)^{th}\frac{1}{(1-4z)^{(2i-5)/2}}j+2\le i-3a_{j+2}\frac{1}{(1-4z)^{(2j+1)/2}}i-3-j\frac{1}{(1-4z)^{(2i-5)/2}}a_j a_{i-j+1}\frac{1}{(1-4z)^{i-2}}(\ddagger)a_{i+1}(z)a_j a_{i-j+1}\frac{1}{\sqrt{1-4z}}\frac{1}{(1-4z)^{(2i-1)/2}}K_iC_{i-2}/2^{3i-5}\frac{1}{(1-4z)^{(2j-3)/2}}K_2= \frac{1}{2} = \frac{C_0}{2^{3\times 2-5}}z~\sum_{j=2}^{i-1} a_j a_{i-j+1}z=\frac{1}{4}a_iz^na_k(z)`J(n,k)`a = \frac{2k-3}{2}a_ii > 2Q_iS_i{\mathbb Z}z\deg Q_i = \left\lfloor \frac{i-3}{2} \right\rfloor\deg S_i = \left\lfloor \frac{i-1}{2} \right\rfloor(\ddagger)(\ddagger)nP_n(0)n^{th}a_{n+2}`l\left( [z^n]a_{n+2}(z) \right)_{n \geq 0}nQ_{n+2}(0) + S_{n+2}(0)Q_nS_n\F_{n,m}nm\G_{n,m}nmF_{n,0}n=10F_{n,m}G_{n,m} zipWith (*) fi gi
 
f' :: Int -> Int -> Integer
f' n m = ftab !! n !! m
g' n m = gtab !! n !! m
\end{verbatim}
 \hrule
  \caption{\textsf{Haskell} program for counting normal forms}
\label{fig:nf-program}
\end{figure}

The efficiency of this program can be improved (Figure~\ref{fig:nf-imp-program}).
\begin{figure}[!htb]
  \centering
\hrule

\medskip

\begin{verbatim}
fgtab :: [[[(Integer,Integer)]]]
fgtab = iterate nextn . map return  zipWith (_,b) -> a*b) ms (reverse ms)

f :: Int -> Int -> Integer
f n m = fst  fgtab !! n !! m
g n m = snd  fgtab !! n !! m
\end{verbatim}
\hrule
  \caption{\textsf{Haskell} improved program for counting normal forms}
  \label{fig:nf-imp-program}
\end{figure}
 Like for terms we derive polynomials:

\begin{lemma}
For every , the degree of the polynomials  and  is equal to .
\end{lemma}
\begin{proof}
  Like the proof of Lemma~\ref{lem:degree},  by induction on  from the definition of
   and .
\end{proof}


\subsection{Coefficients of the polynomials  and }

Let us count -nf-contexts.  They are closed normal forms with  holes.  The
-nf-contexts of size  are counted by . They are abstractions of
-contexts of the form , which we call -nf-pre-contexts,
where each  is a -nf-context (with ) and
which are counted by .  There is one -nf-context and one
-nf-pre-context of size , whereas there are  -nf-contexts and 
-nf-pre-contexts for  of size . Thus we get


By reasoning similarly as in Section~\ref{sec:an-comb-interpr} and by using the
description of normal forms given above, we get:


Therefore 


\subsection{Generating functions}
\label{sec:D_and_G}
Consider the two generating functions:

Then we have

Therefore

and

Consequently the two functions  and  satisfy 

 is the generating function for the numbers of closed normal forms of size
.
By solving the above system of equations, we get:

which yields


\section{Lambda term generation}
\label{sec:lambda-term-gener}

From the simple equation defining the number  of terms, we define the
function generating them.  More precisely, we define a function \textsf{unrankT~n~m~k}
which returns the  term of size  with at most  distinct free variables
(see the \textsf{Haskell} program in Figure~\ref{fig:prog-gen}).  The variable ~is
an \textsf{Integer} (\ie an arbitrary-precision integer) which belongs to the interval .  The unranking program mimics counting terms. If  is , then the
program returns the de Bruijn index .  Otherwise, if  is less than
, the rank  lies in the part of the interval  with
terms that are abstractions. Therefore, for  \textsf{unrankT~n~m~k}
returns \textsf{(unrankT~(n-1)~(m+1)~k)}. If the rank  is larger than
, it lies in the part of the interval  with
applications.  Therefore we call a function \textsf{appTerm} which tries to identify which
sub-interval contains a pair of terms with indices  and  such that 
is at the right place. The product of these values correspond to one of the products
 in the sum.  When the number~ is found, two recursive calls of
\textsf{unrankT}, with appropriate  and , build the subterms of the application.  One
may notice  and  which take into account the fact that  lies in an
interval  while \textsf{divMod} works in an interval
.

The function \textsf{unrankT} relies on the function  presented in
Section~\ref{sec:actual} and called here  times.  Assuming that  has been
called once already and therefore runs in , \textsf{unrankT} performs 
recursive calls and its complexity depends on one side linearly on the operations
\textsf{divMod},  and  performed on arbitrary-precision integers and on the other side is in
 due to the accesses generated by .

For a given , this program can be used to enumerate all the closed -terms of size  and, more
generally, all the -terms of size  with at most  distinct free variables.
This is appropriate only for small values of , since the number of -terms gets superexponentially 
large with~.  But overall, in order to generate a random term of size~ with at most 
distinct free variables, it suffices to feed  with a random value  in the
interval .  Similarly, on the basis of the recursive formula for the
number of normal forms, one defines a program for their generation (Figure~\ref{fig:nf}).

\begin{figure*}
\centering
\hrule

\medskip

\begin{verbatim}
data Term = Index Integer
          | Abs Term
          | App Term Term

unrankT :: Int -> Int -> Integer -> Term
unrankT 0 m k = Index k
unrankT n m k
    | k <= (t (n-1) (m+1)) = Abs (unrankT (n-1) (m+1) k)
    | (t (n-1) (m+1)) < k = appTerm (n-1) 0 (k - t (n-1) (m+1))
    where appTerm n j h
            | h <=  tjmtnjm  = let (dv,md) = ((h-1) `divMod` tnjm) 
                               in App (unrankT j m (dv+1)) 
                                      (unrankT (n-j) m (md+1))
            | otherwise = appTerm n (j + 1) (h -tjmtnjm) 
            where tnjm = t (n-j) m
                  tjmtnjm = (t j m) * tnjm 
\end{verbatim}
\hrule
\caption{\textsf{Haskell} program for term unranking}
\label{fig:prog-gen}
\end{figure*}

\begin{figure*}[!htb]
  \centering
\hrule
\medskip
\begin{verbatim}
unrankNF :: Int -> Int -> Integer -> Term
unrankNF 0 m k = Index k
unrankNF n m k
  | k <= f (n-1) (m+1) = Abs (unrankNF (n-1) (m+1) k)
  | f (n-1) (m+1) < k = unrankNG n m (k - f (n-1) (m+1))

unrankNG :: Int -> Int -> Integer -> Term
unrankNG 0 m k = Index k
unrankNG n m k = appNF (n-1) 0 m k
                                   
appNF :: Int -> Int -> Int -> Integer -> Term
appNF n j m h
    |  h <=  gjmfnjm  = let (dv,md) = (h-1) `divMod` fnjm
                        in App (unrankNG j m (dv+1)) 
                               (unrankNF (n-j) m (md +1))
    | otherwise = appNF n (j + 1) m (h -gjmfnjm)
    where fnjm = f (n-j) m                            
          gjmfnjm = g j m * fnjm
\end{verbatim}
\hrule
  \caption{\textsf{Haskell} program for normal form unranking}
  \label{fig:nf}
\end{figure*}

\section{Simply typable terms}
\label{sec:simply-typed-terms}

Once we have a random generator for untyped terms, it is easy to build a random generator
for simply typable terms. It suffices to sieve all terms by a predicate, which we call
\emph{isTypable}. This predicate is a classical principal type
algorithm
\cite{newman43:_strat,DBLP:conf/popl/DamasM82,DBLP:journals/logcom/Hindley08}.  In
Appendix~\ref{sec:typ_prog}, we give a \textsf{Haskell} program.
For instance,
applying the random generator with parameter~ (for the size of the term), we got:

This is a ``typical'' simply typable random closed -term of size  written with de
Bruijn indices.  Its type is

\begin{center}
  

    
\end{center}

We were able to generate typable terms of size .
For such terms, the generating process is slow, since it requires  generations of
terms, with (unsuccessful) tests of their typability before getting a typable one.  But for
size , 
the number of attempts falls to  for .


This kind of random generator is useful for testing functional programs. Micha{\l}
Pa{\l}ka \cite{palka12:_testin_compil,Palka:2011:TOC:1982595.1982615} proposed a tool
to debug Haskell compilers based on a -term generator.  His generator is
designed on the development of a typing tree, with choices made when a new rule is
created.  Such a method needs to cut branches in developing the tree to avoid loops.
This way his generator is not random, which may be a drawback in some cases.  As a
matter of fact, a method for generating simply typed terms based on developing a
typing tree does not produce terms on a uniform random distribution since it requires
to cut the tree at arbitrary locations to avoid loops, ``arbitrary'' in the sense of
randomness preservation.  In other words, there is no simple recursive definition of
simply typed terms, as well as of simply typable terms,  that would allow an easy uniform random generation.  This is also
what makes the combinatorial study of typed terms difficult.  A term is typable
because it satisfies some constraints, not because it is generated in a specific way.

\section{Experimental data}
\label{sec:exper-data}

Given a random term generator, we are able to write programs to make statistics on some
features of terms.  While there are many possible experiments of this type, here we
present only two that we find interesting and suggestive of other possibilities. 






\subsection{Average variable depth in closed terms and closed normal forms}
\label{sec:avearge-depth-var}

\begin{figure}[htb!]
  \centering
  \includegraphics[width=0.9\textwidth]{average_depth.pdf}
  \caption{\textsf{From top to bottom:} Curve , average variable
    depth for closed terms, average variable depth for closed normal forms and curve
    .}
  \label{fig:av_depth}
\end{figure}

\begin{figure}[htb!]
  \centering
  \includegraphics[width=0.9\textwidth]{average_depth-170-175.pdf}
  \caption{Magnification of Figure~\ref{fig:av_depth} between  and .}
  \label{fig:av_depth_170_175}
\end{figure}

Let us define the \emph{variable depth} as the number of symbols (abstractions and
applications) between a variable and the top of the term. For instance, given the
term , the first occurrence of variable 
has depth~ and the second occurrence of variable  has depth , while the
depth of  is~.  This gives the average depth~ for this term.  Looking at the de
Bruijn indices of the brother term , we
say that the first index~ has depth , the second index  has
depth  and the third index  has depth~, with the same average  as
previously.  In Figure~\ref{fig:av_depth}, we draw the average variable depth for
 random closed terms of size~ up to size  (top scatter plot) and the average
variable depth for  random normal forms of size~ up to size  (bottom
scatter plot) squeezed between the curves  for  and 
(plain lines).  In Figure~\ref{fig:av_depth_170_175} we see the same four curves
enlarged in the interval .  This shows clearly that the
average variable depth of closed terms and closed normal forms are different.  On this basis, we
conjecture that the average depth of variables in closed terms is asymptotically bounded from above by
 and that the average variable depth is slightly smaller for
normal forms than for closed terms.

\subsection{Average number of head 's per closed term}
\label{sec:average-number-l}

We say that  is a \emph{head lambda} in a term  if the latter is of the
form  for some positive integer  and a
certain term .  In order to know the structure of an average term, we are
interested in the average number of head 's occurring in closed terms.  In
Figure~\ref{fig:L-in-terms}, we compare values of some functions  
with the number of head 's in 1000 random closed terms and
the average number of head 's in 1000 normal forms, both in the case when size
goes from~ to .  We see that, in the case of closed terms, these numbers are
in accordance with Theorem~35 in~\cite{DBLP:journals/corr/abs-0903-5505}.

\begin{figure}[thb!]
  \centering
  \includegraphics[width=0.9\columnwidth]{average_nb_head_L_in_terms_and_NF.pdf}
  \caption{\textsf{Bottom}: average number of head 's per closed term.
    \textsf{Top}: average number of head 's per closed normal form.
    \textsf{In between}: curves  for .}
  \label{fig:L-in-terms}
\end{figure}

    \subsection{Ratio of simply typable terms among all terms}
    \label{sec:ratio-simply-typed}
    It is interesting to investigate the ratio of simply typable closed terms among
    all closed terms.
    There are  closed -terms of size , whereas
    there are  closed -terms of size~. Therefore, we performed
    computations for closed terms of size less than . In fact, one cannot go much
    further due to the superexponential growth of the sequence enumerating closed
    terms.
Table~\ref{tab:array9} gives the ratio of simply typable closed terms over all closed terms by an
    exhaustive examination of the closed terms up to .
 \begin{table*}[htb!]
   \centering
    
   \caption{Numbers and ratios of simply typable closed terms up to size }
   \label{tab:array9}
 \end{table*}
 For closed terms of size  or larger, we computed the ratio by the Monte Carlo
 method. The results are given in Table~\ref{tab:array8}. We added the sequence of the numbers
 of simply typable closed terms of a given size to the \emph{On-line
   Encyclopedia of Integer Sequences} and it can be found under the number \textbf{A220471}.
 \begin{table*}[htb!]
   \centering
     \begin{scriptsize}
       
     \end{scriptsize}
   \caption{Ratios of simply typable closed terms (of size at least )}
   \label{tab:array8}
 \end{table*}


 We conclude that simply typable closed terms become very scarce as the size of the
 closed terms grows, falling to less than one over  when the size gets
 larger than .  Likewise, we have done the same task for normal forms.  We got
 the ratio by an exhaustive examination of normal forms up to  in
 Table~\ref{tab:nfUpToSeven} and by the Monte Carlo method thereafter in
 Table~\ref{tab:ratioNF}.

\begin{table}[htb!]
  \centering
  
  \caption{Numbers and ratios of simply typable closed normal forms up to size }
\label{tab:nfUpToSeven}
\end{table}
\begin{table*}[htb!]
  \centering
  

  \caption{Ratios of simply typable closed normal forms}
\label{tab:ratioNF}
\end{table*}

\subsection{Distribution of simply typable lambda terms among terms}

\begin{figure}[htb!]
  \centering
   \includegraphics[width=0.5\textwidth]{dist_typ_size_25_segments_250_range_200}
\ifJFP
 \xymatrix@C 20pt{&& \ar@{->}[ll]_{abstractions} &&&& \ar@{->}[rr]^{applications}&&}
\else
\\\centerline{\xymatrix@C 20pt{&& \ar@{->}[ll]_{abstractions} &&&&
    \ar@{->}[rr]^{applications}&&}}
\fi
  \caption{Distribution of simply typable closed -terms of size \textbf{}.  segments on the
    horizontal axis, percentage ( -- ) of typable closed -terms in segments on the vertical axis.}
  \label{fig:dist_typed_size_25}
\end{figure}

\begin{figure}[htb!]
  \centering
   \includegraphics[width=0.5\textwidth]{dist_typ_size_30_segments_250_range_200}
 \ifJFP
 \xymatrix@C 20pt{&& \ar@{->}[ll]_{abstractions} &&&& \ar@{->}[rr]^{applications}&&}
\else
\\\centerline{\xymatrix@C 20pt{&& \ar@{->}[ll]_{abstractions} &&&&
    \ar@{->}[rr]^{applications}&&}}
\fi
\caption{Distribution of simply typable closed -terms of size
  \textbf{}.  segments on the horizontal axis, percentage ( -- )
  of typable closed -terms in segments on the vertical axis.}
  \label{fig:dist_typed_size_30}
\end{figure}


We said that simply typable terms are scarce, but we may wonder what scarce exactly
means.  More precisely, we may wonder how terms are distributed.  To provide an
answer to this question, we conducted experiments to approximate the distribution of
typable closed -terms  in segments of the interval . We divided the
interval into regular segments and computed the ratio of simply typable terms
for a random sample of terms in each segment. 
Figure~\ref{fig:dist_typed_size_25} is typical of the results we got.  This
corresponds to an experiment on closed terms of size  on  segments with tests for
simple typability on  random closed terms in each segment.  For each segment the height
of the vertical bar represents the ratio of typable closed terms to general closed terms in the corresponding
segment.   The simply typable closed terms are not uniformly distributed.  They
are more concentrated on the left of the interval corresponding to closed terms with low
numbers.  Those closed terms correspond to closed terms starting more often with abstractions than
with applications and this is recursively so for subterms giving the impression of
rolling waves.  For instance, there are  to  of typable closed terms (of size
) starting with many abstractions, whereas for closed terms starting with many
applications there are large subintervals with almost no typable closed terms.
Figure~\ref{fig:dist_typed_size_30}, which gives the same statistics for closed terms of
size , shows that typable closed terms get more scarce as the size of the closed terms grows.


The typable closed normal forms are even more scarcely distributed. As a comparison,
we drew the same graphs for closed normal forms (size of the closed normal forms:
 and , number of segments , tests on  closed terms) in
Figure~\ref{fig:dist_typed_NF_size_25}.  The typable closed normal forms aggregate
more on the left of the interval where closed terms start mostly with abstractions,
with peaks of  to  by segments.  Figure~\ref{fig:dist_typed_NF_size_30}
shows that scarcity of typable normal forms increases as the size of closed terms grows.

\begin{figure}[htb!]
  \centering
   \includegraphics[width=0.5\textwidth]{dist_typ_NF_size_25_segments_250_range_200}
  \ifJFP
 \xymatrix@C 20pt{&& \ar@{->}[ll]_{abstractions} &&&& \ar@{->}[rr]^{applications}&&}
\else
\\\centerline{\xymatrix@C 20pt{&& \ar@{->}[ll]_{abstractions} &&&&
    \ar@{->}[rr]^{applications}&&}}
\fi
  \caption{Distribution of simply typable closed normal forms  of size \textbf{}.  segments on the
    horizontal axis, percentage ( -- ) of typable closed normal forms in segments on the vertical axis.}
  \label{fig:dist_typed_NF_size_25}
\end{figure}

\begin{figure}[htb!]
  \centering
   \includegraphics[width=0.5\textwidth]{dist_typ_NF_size_30_segments_250_range_200}
  \ifJFP
 \xymatrix@C 20pt{&& \ar@{->}[ll]_{abstractions} &&&& \ar@{->}[rr]^{applications}&&}
\else
\\\centerline{\xymatrix@C 20pt{&& \ar@{->}[ll]_{abstractions} &&&&
    \ar@{->}[rr]^{applications}&&}}
\fi
  \caption{Distribution of simply typable closed normal forms  of size \textbf{}.  segments on the
    horizontal axis, percentage ( -- ) of typable closed normal forms in segments on the vertical axis.}
  \label{fig:dist_typed_NF_size_30}
\end{figure}



\section{Related work}
\label{sec:related-work}


There are very few papers on counting -terms, whereas counting first order
terms is a classical domain of combinatorics. Apparently, the first traces of
counting expressions with (unbound) variables can be attributed to Hipparchus of
Rhodes (c. 190--120~BC) (see \cite{flajolet08:_analy_combin} p.~68).  Flajolet and
Sedgewick's book \cite{flajolet08:_analy_combin} is the reference on this subject.
Concerning counting -terms, we can cite only five works.  \ifJFP David
\emph{et. al.} \shortcite{DBLP:journals/corr/abs-0903-5505} and Bodini \emph{et. al.}
\shortcite{gittenberger-2011-ltbuh} \else \cite{DBLP:journals/corr/abs-0903-5505} and
\cite{gittenberger-2011-ltbuh} \fi study asymptotic behavior of formulas on counting
-terms.  Strictly speaking, they do not exhibit a recurrence formula for
counting.  In particular, David \emph{et al.} \ifJFP
\shortcite{DBLP:journals/corr/abs-0903-5505} \else
\cite{DBLP:journals/corr/abs-0903-5505} \fi provide only upper and lower bounds for
the numbers of -terms in order to get information about the distribution of
families of terms. For instance, they prove that ``asymptotically almost all
-terms are strongly normalizing''.  In \cite{DBLP:journals/tcs/Lescanne13} the
second author of the present paper proposes formulas for counting -terms in the
case of variables of size , with more complex formulas and less results.  On
another hand, Christophe Raffalli proposed a formula for counting closed -terms,
which he derives from the formula for counting -terms with exactly  distinct
free variables.  His formula appears in the \emph{On-line Encyclopedia of Integer
  Sequences} under the number \textbf{A135501}.  He considers size  for the
variables.  Beside those works, John Tromp \ifJFP
\shortcite{DBLP:conf/dagstuhl/Tromp06} \else ~\cite{DBLP:conf/dagstuhl/Tromp06} \fi
proposes a rather different way of counting -terms which deserves to be
investigated further from the viewpoint of combinatorics.  His size function works on
terms with de Bruijn indices like ours and is (in our convention of starting at )
as follows:
  
  producing sequence \textbf{A114852} (and sequence \textbf{A195691} for closed
  normal forms) in the \emph{On-line Encyclopedia of Integer Sequences}.  This work
  is connected to program size complexity and \emph{Algorithmic Information
    Theory}~\cite{261084}.

  As concerns random generation, Wang in
  \cite{Wang05generatingrandom,wang04:_effic_gener_random_progr_their_applic}
  proposed algorithms for random generation of untyped -terms in the spirit of the
  counting formula of Raffalli for~\cite{Wang05generatingrandom} and in the spirit of
   for~\cite{wang04:_effic_gener_random_progr_their_applic}.  On term
  generation, we can also mention two works. In \cite{DBLP:conf/haskell/DuregardJW12}
  the authors enumerate and generate many more structures than
  -terms. In~\cite{DBLP:journals/jfp/KennedyV12}, the authors address a problem
  similar to ours. Indeed they play on the duality \emph{encoder-decoder} or
  \emph{ask-build}, when we speak of \emph{counting-generating} or
  \emph{ranking-unranking}.  Our unranking program (Figure~\ref{fig:prog-gen}) can be
  made easily a game, with questions like ``Is ?'' or like
  ``Is ?'', but Kennedy and Vytiniotis do not know the precise
  range of their questions since they do not base their generation on counting. Since
  the size is not a parameter, their games may have unsuccessful issues and their
  programs can raise errors and are only error-free on well-formed games.  Pa{\l}ka
  \cite{palka12:_testin_compil,Palka:2011:TOC:1982595.1982615} uses generation of
  typable -terms to test Haskell compilers.  He acknowledges that, due to his
  method, he cannot guarantee the uniformity of his generator (see discussion in
  \cite{palka12:_testin_compil} p. 21 and p.~45).  Nonetheless, he found eight
  failures and four bugs in the \emph{Glasgow Haskell Compiler} demonstrating the
  interest in the method, probably due the ability of generating large terms. \ifJFP
  {Rodriguez~Yakushev} \& Jeuring \shortcite{DBLP:conf/aaip/YakushevJ09} \else {Rodriguez~Yakushev} \& Jeuring
  \cite{DBLP:conf/aaip/YakushevJ09} \fi study the feasibility of generic
  programming for the enumeration of typed terms. The given examples are of size 
  or , no realistic examples are provided, randomness is not addressed and the
  authors confess that their algorithm is not efficient.  Knowing that there are
  simply typable closed terms of size , one wonders if there is an
  actual use for such enumeration and it seems unrealistic to utilize enumeration for
  larger numbers.  The ``related work'' section of \cite{DBLP:conf/aaip/YakushevJ09}
  covers similar approaches, which all consist in cutting branches.  For this reason
  they do not generate terms uniformly.  A presentation of tree-like structure
  generation and a history of combinatorial generation is given \ifJFP by Knuth
  \shortcite{KnuthTAOCP_4_4}\else in \cite{KnuthTAOCP_4_4}\fi.

  Since we cited, as an application, the random generation of terms for the
  construction of samples for debugging functional programming compilers and the
  connection with languages with bound variables, it is sensible to mention
  \textsf{Csmith}~\cite{DBLP:conf/pldi/YangCER11}, which is the most recent and the
  most efficient bug tracker of C compilers.  It is based on random program
  generation and uses filters for generating programs enforcing semantic
  restrictions, like ours when generating simply typable terms.  However, the generation
  is not based on unranking, therefore \textsf{Csmith} lacks the ability to construct
  test case of a specific size on demand, but \textsf{Csmith} can generate large
  terms, which reveals to be useful, since the greatest number of distinct crash
  errors is found by programs containing 8K-16K tokens. However, one may wonder if
  this feature is not a consequence of the non-uniformity of the distribution.

\section{Acknowledgments}
\label{sec:acknowledgments}

Clearly Nikolaas de Bruijn and  Philippe Flajolet were influential all along this research.  We would like to
thank Marek Zaionc for stimulating discussions and for setting the problem of
counting -terms, Bruno Salvy for his help in the proof of
Proposition~\ref{prop:equiv}, Olivier Bodini, Jonas Dureg{\aa}rd, Dani\`{e}le Gardy,
Bernhard Gittenberger, Patrik Jansson, Jakub Kozik, John Tromp and the referees of this paper for
their useful suggestions and interactions.

\section{Conclusion}
\label{sec:conclusion}

This paper opens tracks of research in two directions, which are intrinsically
complementary, namely counting and generating, aka ranking and unranking. On counting terms, some hard problems
remain to be solved.  Probably the hardest and the most informative one is to
give an asymptotic estimation for the numbers of closed terms of size . It seems that big
obstacles remain to be hurdled before getting a solution, since combinatorial
structures with binders have not been studied so far by combinatorists.  On generation of
terms, implementations have to be improved to go further in the production of
uniformly distributed terms, in particular, of uniformly generated typable terms.  



\begin{thebibliography}{10}

\bibitem{AbadiCCL91JFP}
Martin Abadi, Luca Cardelli, Pierre-Louis Curien, and Jean-Jacques L{\'e}vy.
\newblock Explicit substitutions.
\newblock {\em Journal of Functional Programming}, 1(4):375--416, 1991.

\bibitem{gittenberger-2011-ltbuh}
Olivier Bodini, Dani\`ele Gardy, and Bernhard Gittenberger.
\newblock Lambda terms of bounded unary height.
\newblock In {\em Proceedings of the Eighth Workshop on Analytic Algorithmics
  and Combinatorics}, pages 23--32, 2011.

\bibitem{DBLP:journals/corr/abs-cs-0501035}
Pierre-Louis Curien.
\newblock Introduction to linear logic and ludics, part {I}.
\newblock {\em CoRR}, abs/cs/0501035, 2005.
\newblock \url{http://arxiv.org/abs/cs/0501035}.

\bibitem{DBLP:conf/popl/DamasM82}
Lu\'{\i}s Damas and Robin Milner.
\newblock Principal type-schemes for functional programs.
\newblock In {\em Conference Record of the Ninth Annual {ACM} {Symposium on
  Principles of Programming Languages}, Albuquerque, New Mexico, USA, January
  1982}, pages 207--212. ACM Press, 1982.
\newblock Richard A. DeMillo ed.

\bibitem{DBLP:journals/corr/abs-0903-5505}
Ren{\'e} David, Katarzyna Grygiel, Jakub Kozik, Christophe Raffalli, Guillaume
  Theyssier, and Marek Zaionc.
\newblock Asymptotically almost all -terms are strongly normalizing.
\newblock {\em CoRR}, abs/0903.5505v3, 2009.
\newblock \url{http://http://arxiv.org/abs/0903.5505v3}.

\bibitem{deBruijn72}
N.~de~Bruijn.
\newblock Lambda calculus notation with nameless dummies, a tool for automatic
  formula manipulation, with application to the {Church-Rosser} theorem.
\newblock {\em Indagationes Mathematicae}, 34(5):381--392, 1972.

\bibitem{DBLP:conf/haskell/DuregardJW12}
Jonas Dureg{\aa}rd, Patrik Jansson, and Meng Wang.
\newblock Feat: functional enumeration of algebraic types.
\newblock In Janis Voigtl{\"a}nder, editor, {\em Proceedings of the 5th {ACM
  SIGPLAN} {Symposium on Haskell, Haskell} 2012, {Copenhagen, Denmark}, 13
  {September} 2012}, pages 61--72. ACM, 2012.

\bibitem{flajolet08:_analy_combin}
Philippe Flajolet and Robert Sedgewick.
\newblock {\em Analytic Combinatorics}.
\newblock Cambridge University Press, 2008.

\bibitem{GallierSnyderTCS89}
Jean Gallier and Wayne Snyder.
\newblock Complete sets of transformations for general {E}-unification.
\newblock {\em Theoret. Comput. Sci.}, 67(2-3):203--260, October 1989.

\bibitem{GraKnuPat}
Ronald~L. Graham, Donald~E. Knuth, and Oren Patashnik.
\newblock {\em Concrete mathematics}.
\newblock Addison-Wesley, Reading, MA, 1989.

\bibitem{DBLP:journals/logcom/Hindley08}
J.~Roger Hindley.
\newblock {M. H. Newman's} typability algorithm for lambda-calculus.
\newblock {\em J. Log. Comput.}, 18(2):229--238, 2008.

\bibitem{JouannaudKirchner-rob91}
Jean-Pierre Jouannaud and Claude Kirchner.
\newblock Solving equations in abstract algebras: a rule-based survey of
  unification.
\newblock In Jean-Louis Lassez and G.~Plotkin, editors, {\em Computational
  {L}ogic. {E}ssays in honor of {A}lan {R}obinson}, chapter~8, pages 257--321.
  The MIT press, Cambridge (MA, USA), 1991.

\bibitem{DBLP:journals/jfp/KennedyV12}
Andrew~J. Kennedy and Dimitrios Vytiniotis.
\newblock Every bit counts: The binary representation of typed data and
  programs.
\newblock {\em J. Funct. Program.}, 22(4-5):529--573, 2012.

\bibitem{KnuthTAOCP_4_4}
Donald~E. Knuth.
\newblock {\em The Art of Computer Programming, Generating All Trees-History of
  Combinatorial Generation}, volume 4 (fascicle 4).
\newblock Addison-Wesley Publishing Company, 2006.

\bibitem{lang02:_polyn_cataly}
Wolfdieter Lang.
\newblock On polynomials related to derivatives of the generative functions of
  the {Catalan} numbers.
\newblock {\em The Fibonacci Quarterly}, 40(4):299--313, 2002.

\bibitem{LescannePOPL94}
Pierre Lescanne.
\newblock From  to , a journey through calculi
  of explicit substitutions.
\newblock In Hans Boehm, editor, {\em Proceedings of the 21st Annual {ACM}
  Symposium on {P}rinciples {O}f {P}rogramming {L}anguages, {Portland (Or.,
  USA)}}, pages 60--69. ACM, 1994.

\bibitem{DBLP:journals/tcs/Lescanne13}
Pierre Lescanne.
\newblock On counting untyped lambda terms.
\newblock {\em Theor. Comput. Sci.}, 474:80--97, 2013.

\bibitem{261084}
Ming Li and Paul Vit\'{a}nyi.
\newblock {\em An introduction to {Kolmogorov} complexity and its applications
  (2nd ed.)}.
\newblock Springer-Verlag New York, Inc., Secaucus, NJ, USA, 1997.

\bibitem{newman43:_strat}
Max H.~A. Newman.
\newblock Stratified systems of logic.
\newblock {\em Proceedings of the {Cambridge} Philosophical Society},
  39:69--83, 1943.

\bibitem{palka12:_testin_compil}
Micha{\l} Pa{\l}ka.
\newblock Testing an optimising compiler by generating random lambda terms.
\newblock Licentiatavhandling, Department of Computer Science and Engineering,
  Chalmers University of Technology and G\"oteborg University, May 2012.

\bibitem{Palka:2011:TOC:1982595.1982615}
Micha{\l}~H. Pa{\l}ka, Koen Claessen, Alejandro Russo, and John Hughes.
\newblock Testing an optimising compiler by generating random lambda terms.
\newblock In {\em Proceedings of the 6th International Workshop on Automation
  of Software Test}, AST'11, pages 91--97, New York, NY, USA, 2011. ACM.

\bibitem{DBLP:conf/aaip/YakushevJ09}
Alexey {Rodriguez~Yakushev} and Johan Jeuring.
\newblock Enumerating well-typed terms generically.
\newblock In Ute Schmid, Emanuel Kitzelmann, and Rinus Plasmeijer, editors,
  {\em AAIP}, volume 5812 of {\em Lecture Notes in Computer Science}, pages
  93--116. Springer, 2009.

\bibitem{sage}
William Stein et~al.
\newblock {\em {S}age {M}athematics {S}oftware ({V}ersion 4.8)}.
\newblock The Sage Development Team, 2012.
\newblock {\tt http://www.sagemath.org}.

\bibitem{integer:ranking}
{The On-Line Encyclopedia of Integer Sequences
  (OEIS) Wiki}.
\newblock Ranking and unranking functions, 2013.
\newblock \url{https://oeis.org/wiki/Ranking_and_unranking_functions}, [Online;
  accessed 18-June-2013].

\bibitem{DBLP:conf/dagstuhl/Tromp06}
John Tromp.
\newblock Binary lambda calculus and combinatory logic.
\newblock In Marcus Hutter, Wolfgang Merkle, and Paul M.~B. Vit{\'a}nyi,
  editors, {\em Kolmogorov Complexity and Applications}, volume 06051 of {\em
  Dagstuhl Seminar Proceedings}. Internationales Begegnungs- und
  Forschungszentrum fuer Informatik (IBFI), Schloss Dagstuhl, Germany, 2006.

\bibitem{wang04:_effic_gener_random_progr_their_applic}
Jue Wang.
\newblock The efficient generation of random programs and their applications.
\newblock Master's thesis, Honors Thesis, Wellesley College, Wellesley, MA, May
  2004.

\bibitem{Wang05generatingrandom}
Jue Wang.
\newblock Generating random lambda calculus terms.
\newblock Citeseer, 2005.
\newblock available from
  \url{http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.95.2624}.

\bibitem{DBLP:conf/pldi/YangCER11}
Xuejun Yang, Yang Chen, Eric Eide, and John Regehr.
\newblock Finding and understanding bugs in {C} compilers.
\newblock In Mary~W. Hall and David~A. Padua, editors, {\em Proceedings of the
  32nd {ACM SIGPLAN} {Conference on Programming Language Design and
  Implementation}, {PLDI} 2011, {San Jose, CA, USA, June 4-8}, 2011}, pages
  283--294. ACM, 2011.

\end{thebibliography}

\appendix

\section{Terms with exactly  distinct free variables}
\label{sec:number-terms-with}

Here we study the numbers of terms with exactly  distinct
free variables, the formulas for counting those numbers and their relations with
quantities we considered.

\subsection{A formula}
\label{sec:formula}

Let us show how to derive the formula for counting -terms with exactly 
distinct free variables.  This formula is adapted from a similar one when variables
have size  due to Raffalli (\emph{On-line Encyclopedia of Integer Sequences}
under the number \textbf{A135501}).  We assume that terms are built with usual variables
(not de Bruijn indices) and that they are equivalent up to a renaming of bound variables
and up to -conversion.  Let us denote the number of -terms of size  with
exactly  distinct free variables by .

Notice first that there is no term of size  with no free variable, hence .  There is one term of size  with one free variable, hence .  The maximum number of variables for
a -term of size  is when the only operators are applications and all the
variables are different.  One has then a binary tree with  internal nodes and
 leaves holding  variables.  This means that for  beyond  variables
there is no term of size  with exactly  distinct free variables.  Hence


In the general case, a term of size  with  free variables starts either with
an abstraction or with an application. Terms starting with an abstraction, say , on a term  contribute in two ways: either  does not contain  as a free
variables or  contains  as a free variable.  There are  such 's in
the first case and  in the second.  This gives the two first summands
 in the formula.  Now, let us see how terms starting with an
application look like.  Assume they are of the form  and of size .  For
some , the term  is of size  and  is of size .  These
terms share  common variables (), while  has  distinct
free variables altogether.  The term~ has  distinct free variables, which do not occur in ,
hence  has  distinct free variables altogether.  The term  has 
distinct free variables.  Therefore, given a set of private variables for , a set of
common variables, and a set of private variables for , there are  possible pairs .  There are  ways to choose the 
common variables among  and there are  ways to split the
remaining variables into  and , namely  for  and  for , hence
the third summand of the formula:

Now, we obtain the whole formula:


\subsection{Relations between  and }
\label{sec:relat-betw}

The number of terms of size  with exactly  indices in  is

Therefore the number of terms with indices in  is:

By the inversion formula (\cite{GraKnuPat} p.~192), we get:
 This shows
with no surprise that  and  are simply connected.  Knowing
that the 's can be easily computed, this provides a formula simpler than
Raffalli's to compute the 's.

\subsection{A relation between  and }
We write  the number of surjections from  to .
To get a relation between  and , we can reproduce the process with
which we associated  and  (Section~\ref{sec:an-comb-interpr}), but
instead of applications from  to , we have surjections from 
to , since this time we count terms with exactly  variables and all the de
Bruijn indices must be reached by the applications.  Therefore

Recall that

We can now go further in the expression of .

which is another proof of the formula of Section~\ref{sec:relat-betw}.

\section{A program for testing simple typability}
\label{sec:typ_prog}

In this section we give a simple \textsf{Haskell} program for \emph{testing simple
typability} of a term also called \emph{type reconstruction}.  The program which
works on the types \textsf{Type} and \textsf{Equation}:
\begin{verbatim}
data Type = Var Int
          | Arrow Type Type

type Equation = (Type,Type)            
\end{verbatim}
has three parts. First, a function builds the set of typability equational
constraints of a closed term. This function called \textsf{buildConstraint}
(Figure~\ref{fig:bldcons}) takes a term and returns its potential principal type,
which will be made explicit after solving the constraints, and a list of equational
constraints.  It requires a function \textsf{build} which will be called through the
terms.  Along its traversal of the term, the function \textsf{build} has to know the
depth  (the number of 's it crossed). Moreover, \textsf{build} creates type
variables.  Actually, a constraint builder creates type variables in two situations:
when it creates a context for the first time, that is when it deals with a de Bruijn
index, and when it creates the type to be returned by an application.  Since type
variables are objects of the form \textsf{Var~i}, where \textsf{i} is an
\textsf{Int}, \textsf{build} takes an \textsf{Int} which is increased whenever a new
type variable is created. We call the latter a \emph{cursor} and denote it by
\textsf{cu}. \textsf{build} returns a 4-uple, namely the potential principal type of
the term, a context (a list of types associated with de Bruijn indices), a set of
equational constraints and the updated cursor.

\begin{figure}[!btph]
  \centering
  \begin{normalsize}
\begin{verbatim}
buildConstraint :: Term -> (Type, [Equation])
buildConstraint t = 
  let (ty,[],constraint,_) = build t 0 0 
  in (ty, constraint)
  where
    build :: Term -> Int -> Int -> (Type, [Type], [Equation],Int)
    build (Index i) d cu = 
      let ii = fromIntegral i 
      in (Var (cu+ii-1), [Var j | j<-[cu..cu+d-1]],[],cu+d)
    build (Abs t) d cu = 
      let (ty,(a:cntxt),constraint,cu') = build t (d+1) cu 
      in ((Arrow a ty),cntxt,constraint,cu')
    build (App t1 t2) d cu = 
      let (ty1, cntxt1, constraint1, cu1) = build t1 d cu 
          (ty2, cntxt2, constraint2, cu2) = build t2 d cu1
          ty = (Var cu2) in (ty,
                             cntxt1,
                             (ty1,(Arrow ty2 ty)):(zip cntxt1 cntxt2) 
                                ++ constraint1 ++ constraint2, 
                             cu2+1)
\end{verbatim}
  \end{normalsize}
  \caption{The function \textsf{buildConstraint}}
\label{fig:bldcons}
\end{figure}
To solve equational constraints we use a method based on transformation
rules~\cite{GallierSnyderTCS89,JouannaudKirchner-rob91}. For that, we use a function
\textsf{decompose} which splits an equation when both sides are arrow types.
Moreover, when \textsf{decompose} meets an equation , the latter
is transformed into .

\begin{verbatim}
decompose :: Equation -> [Equation]
decompose ((Arrow ty1 ty2), (Arrow ty1' ty2')) = 
  decompose (ty1,ty1') ++ decompose (ty2,ty2')
decompose ((Arrow ty1 ty2),(Var i)) = [(Var i,(Arrow ty1 ty2))]
decompose (ty1,ty2) = [(ty1,ty2)]
\end{verbatim}

A predicate \textsf{nonTrivialEq} is necessary to filter out the trivial
equations, i.e., of the form .
\begin{verbatim}
nonTrivialEq :: Equation -> Bool
nonTrivialEq (Var i, Var j) = i /= j
nonTrivialEq (ty1, ty2) = True
\end{verbatim}
A predicate {\EUR} checks whether a given variable belongs to a composed type. This
is necessary to detect cycles. For instance,  is a cycle and shall
be detected, whereas  is a trivial equation, not a cycle, and shall be
removed.
\begin{alltt} 
(\EUR) :: Type -> Type -> Bool 
(Var i) \EUR (Var j) = False -- strict occurrence only
(Var i) \EUR (Arrow ty1 ty2) =  (Var i) \EUR= ty1 || (Var i) \EUR= ty2
    where (Var i) \EUR= (Var j) = i == j
          (Var i) \EUR= (Arrow ty1 ty2) = (Var i) \EUR= ty1 || 
                                       (Var i) \EUR= ty2
\end{alltt}
Once this test is done, one can replace a variable  occurring in an equation of
the form  by  everywhere else in the set of equational constraints
before putting the equation  in the solved part.
\pagebreak[4]
\begin{alltt}
( :: Type -> Equation -> Type
(Var j)  (Var i, ty) = if i == j then ty else Var j
(Arrow ty1 ty2)  (Var i, ty) = 
  Arrow (ty1  (Var i, ty)) (ty2  (Var i, ty))

replace::  Equation -> Equation -> Equation
replace (Var i,ty) (ty1,ty2) = (ty1  (Var i,ty),  ty2  (Var i,ty))
\end{alltt}
The function \textsf{solve} solves the set of equational constraints.  It returns three things:
first a~list of equations which are the equations yet to be solved, second a list of
equations which are the already solved equations and third a condition that says if the set
of equational constraints is solvable or not.  In other words, \textsf{solve} returns
\textsf{True} as the third component if the set of equational constraints has a solution, that
is when the set of equational constraints is empty.  It returns \textsf{False} when it detects a
cycle. Otherwise it tries to apply the transformations whenever it is possible, that
is when the set of equational constraints is not empty. Indeed if there is no cycle and if the
set of equational constraints is not empty, a~transformation is always applicable.
\begin{normalsize}
\begin{alltt}
solve :: [Equation] -> [Equation]
                    -> ([Equation],[Equation],Bool)
solve ((Var i,ty):l) sol = 
  if Var i \EUR ty 
  then ((Var i,ty):l,sol,False) -- cycle detected
  else solve (map (replace (Var i,ty)) l) ((Var i,ty):sol)
solve (eq:l) sol = solve (filter nonTrivialEq (decompose eq) ++ l) sol
solve [] sol = ([],sol,True)
\end{alltt}
\end{normalsize}
Since we have all the ingredients, the test of typability consists in building the equational constraint and trying to
solve it. 
\begin{verbatim}
isTypable :: Term -> Bool
isTypable t = let (_,c) = buildConstraint t 
                  (_,_,b) = solve c []
              in b
\end{verbatim}
Notice that we have everything to build the principal type of the term if it is
typable. 
\end{document}
