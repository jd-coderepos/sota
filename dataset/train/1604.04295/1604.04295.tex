\documentclass[envcountsame]{llncs}

\usepackage{microtype}
\usepackage{hyperref}
\usepackage{latexsym}
\usepackage{amsmath,amssymb,stmaryrd}
\usepackage{graphicx}
\usepackage{breakurl}\hypersetup{colorlinks=false}
\usepackage{versions}\excludeversion{ignore}
\newcommand{\Continuous}[1]{\mathit{Flow}(#1)}   \newcommand{\notContinuous}[1]{\mathit{Jump}(#1)}   \newcommand{\Machine}{\textsc{Dynamic}}
\newcommand{\St}{\ensuremath{\mathcal {S}}}
\newcommand{\Rs}{\ensuremath{\mathcal{R}}}
\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand{\Run}{\ensuremath{\mathcal{R}un}}
\newcommand{\N}{\ensuremath{\mathbb{N}}}
\newcommand{\I}{\ensuremath{\mathbb{I}}}
\newcommand{\T}{\ensuremath{\mathcal {T}}}
\newcommand{\TT}{\ensuremath{\mathbb{T}}}
\newcommand{\In}{\St_0}
\newcommand{\Ot}{\ensuremath{\mathcal {O}}}
\newcommand{\U}{\ensuremath{\mathcal {V}}}
\newcommand{\E}{\ensuremath{\mathcal {E}}}
\newcommand{\F}{\ensuremath{\mathcal {F}}}
\newcommand{\G}{\ensuremath{\mathcal {G}}}
\renewcommand{\H}{\ensuremath{\mathcal {H}}}
\newcommand{\Inp}{\ensuremath{\imath}}
\newcommand{\K}{\ensuremath{\mathcal{U}}}
\newcommand{\evaluation}[2][]{\ensuremath{\left\llbracket #2\right\rrbracket_{#1}}}
\newcommand{\val}[2]{\evaluation[#2]{#1}}
\newcommand{\vall}[2]{\val{#2}{#1}}
\newcommand{\Dom}{\mathrm{Dom}~}
\renewcommand{\emptyset}{\varnothing}
\newcommand{\Flow}{\ensuremath{\mbox{\bf FLOW}~}}
\newcommand{\If}{\ensuremath{\mbox{\bf if}~}}
\newcommand{\Not}{\ensuremath{\mbox{\bf not}~}}
\newcommand{\Then}{~\mbox{\bf then}~}
\newcommand{\True}{\textsf{true}}
\newcommand{\False}{\textsf{false}}
\newcommand{\Undef}{\textsf{undef}}
\newcommand{\wave}[1]{\widetilde{#1}}
\newcommand{\st}{\mbox{ \bf such that }}
\newcommand{\restrict}{\!\upharpoonright\!}
\newcommand{\updated}[2]{#1 \mapsto  #2}
\newcommand{\update}[3]{(#1,#2,#3)}\spnewtheorem{postulate}{Postulate}{\bfseries}{\itshape}
\spnewtheorem{postulatep}{Postulate}{\bfseries}{\itshape}
\renewcommand{\thepostulate}{\Roman{postulate}}
\renewcommand{\thepostulatep}{\Roman{postulatep}}
\renewcommand\labelenumi{{\rm (}\alph{enumi}{\rm )}}
\usepackage{color}
\newcommand\eref[1]{(\ref{#1})}
\newcommand{\RR}{\mathbb{R}}
\renewcommand\eqref[1]{(\ref{#1})}
\newcommand\zero{{0}}
\newcommand\one{{1}}
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand\LOCATION[2]{(#1,#2)}
\newcommand{\beh}{\Delta}
\newcommand{\J}[1]{\{\JJ\}\times #1}\newcommand{\C}[1]{\{\CC\}\times #1}\newcommand{\JJ}{\mathcal{J}}
\newcommand{\CC}{\mathcal{F}}
\newcommand{\gen}[1]{\Delta_t(#1)}
\newcommand{\last}[1]{#1_{*}}
\newcommand\Deltapsi{\Delta_\psi}
\newcommand{\itm}[1]{\mbox{\rm(}#1\mbox{\rm)}}
\newcommand{\nd}[1]{#1}\let\ep\endproof
\renewcommand{\endproof}{\qed\ep}
\newenvironment{ttcode}{\begin{ttfamily}\rm\tt}{\end{ttfamily}}
\newcommand\s{\phantom{x}}
\sloppy
\begin{document}
\title{Axiomatizing Analog Algorithms}
\author{Olivier Bournez\inst{1}\thanks{This author's research was
    partially supported by a French National Research
    Agency's grant (ANR-15-CE40-0016-02).}
  \and Nachum
  Dershowitz\inst{2}\thanks{This author's research benefited from
    a fellowship at the Institut d'\'Etudes Avanc\'ees de Paris
    (France), with the financial support of the French National Research Agency's ``Investissements
    d'avenir'' program (ANR-11-LABX-0027-01 Labex RFIEA+).}
\and Pierre N\'eron\inst{3}}
\institute{Laboratoire d'Informatique de l'X (LIX), \'Ecole
  Polytechnique, France \and
School of Computer Science, Tel Aviv University, Ramat Aviv, Israel
\and French Network and Information Security Agency (ANSSI), France \\
\email{bournez@lix.polytechnique.fr}~~\email{nachum@cs.tau.ac.il}~~\email{pierre.neron@ssi.gouv.fr}}
\authorrunning{O. Bournez and N. Dershowitz and P. N\'eron}

\maketitle

\begin{abstract}
  We propose a formalization of generic algorithms that includes analog
  algorithms.  This is achieved by reformulating and extending the framework of abstract
  state machines to include continuous-time models of computation.
     {We prove that every hybrid algorithm satisfying some reasonable postulates   may be expressed precisely by
   a program in a simple and expressive language.}
\end{abstract}

\section{Introduction}

In \cite{Gur00}, Gurevich showed
that any algorithm that satisfies three intuitive ``Sequential
Postulates'' can be step-by-step emulated by an {abstract state machine (ASM)}.  These postulates
formalize the following intuitions: (I) one is dealing with
discrete deterministic state-transition systems; (II) the information in states
suffices to determine future transitions and may be captured by
logical structures that respect isomorphisms; and (III) transitions
are governed by the values of a finite and input-independent set of
ground
terms.
All notions of algorithms for ``classical'' \emph{discrete-time} models of
computation in computer science are covered by this formalization.
This includes Turing machines, random-access memory (RAM) machines,
and their sundry extensions.
The geometric constructions in \cite{Reisig}, for example, are
loop-free examples of discrete-step continuous-space (real-number) algorithms.
The ASM formalization also covers general discrete-time models evolving over continuous
space like the Blum-Shub-Smale machine model \cite{BSS}.

However, capturing \emph{continuous-time} models of computation is
still a challenge, that is to say, capturing models of computation that operate
in continuous (real) time and with real values.
Examples of continuous-time models of computations include models of analog
machines like the General Purpose Analog Computer (GPAC) of Claude Shannon
\cite{Sha41}, proposed as a mathematical model of the Differential
Analyzers, built for the first time in 1931 \cite{Bush31}, and
used to solve various problems ranging from
ballistics to aircraft design -- before the era of the digital computer
\cite{Nyc96}. 
Others include
Pascal's 1642 \textit{Pascaline},
Hermann's 1814 \textit{Planimeter},
as well as
Bill Phillips' 1949 water-run \textit{Financephalograph}.
Continuous-time computational models also include neural networks
and systems built using electronic
analog devices.
Such systems begin in some initial state and evolve over time;
results are read off from the evolving
state and/or from a terminal state. More generally, determining which
systems can actually be considered to be computational models is an
intriguing question and relates to philosophical discussions about
what constitutes a programmable machine.
Continuous-time
computation theory is far less understood than its discrete-time
counterpart \cite{Survey}.
Another line of development of continuous-time  models was
 motivated by hybrid systems, particularly by questions related to
the hardness of their verification and control.  In hybrid
 systems, the dynamics change in response to changing
conditions, so there are discrete transitions as well as continuous
ones.
Here, models are not
seen as necessarily modeling analog machines, but,
rather, as abstractions of systems about
which one would like to establish properties or derive
verification algorithms \cite{Survey}.
Some work on ASM models dealing with
continuous-time systems has been accomplished
for specific cases \cite{Cohen,Cohen2}.
Rust \cite{rust2000hybrid} specifies  forms of continuous-time evolution
based on ASMs using infinitesimals.
However, we find that a comprehensive framework
capturing general analog systems is still wanting.

Our goal is to capture all such analog and hybrid models within one uniform notion of
computation and of algorithm.
To this end, we formalize a generic notion of
continuous-time algorithm. The proposed
framework is an extension of \cite{Gur00}, as discrete-time
algorithms are a simple special case of analog algorithms.
(The initial attempt \cite{BournezDF12} was not fully satisfactory, as no
completeness theorem nor general-form result was obtained. Here, we
indeed achieve both.)
We
provide postulates defining continuous-time algorithms, in the spirit of
  those of \cite{Gur00},
  and we
prove some completeness results.
We define a simple notion of an analog ASM
program and  prove that all models satisfying the postulates
have
  corresponding analog programs (Lemma
  \ref{mlemma} and Theorem \ref{thone}).
Furthermore, we provide  conditions guaranteeing that said program is unique up
to equivalence (Theorem \ref{thtwo} and Corollary
\ref{coromain}).
All of this seamlessly extends the
results of \cite{Gur00} to analog and hybrid systems.
The proposed framework  covers all classes of
continuous-time systems that can be modeled by ordinary differential
equations or have hybrid dynamics, including the models in \cite{Survey} and
 the examples in \cite{BournezDF12}. 
 It is a first step towards a general understanding of
computability theory for continuous-time models, taken in the hope that it will also lead to a
formalization of a ``Church-Turing thesis'' for analog systems in the spirit of what has been achieved for discrete-time models~\cite{BD,dershowitz2008natural,3P}.
Systems with continuous input signals
and other means of specifying continuous behavior are left for future
work.

Some of our ideas were inspired by the way the semantics
of hybrid systems are given in the approach of
Platzer~\cite{Platzer08}.
Among attempts at studying the semantics of analog systems  within a general
framework  is
\cite{TZ}. Recent results on comparing analog models include
\cite{fu2015models}. Soundness and (relative) completeness results for
a programming language with infinitesimals have also been obtained in
\cite{suenaga2011programming}. Applications to verification have  been
explored \cite{hasuo2012exercises}.



\section{General Algorithms}

We want to generalize the notion of algorithms introduced by Gurevich in \cite{Gur00} in
order to capture not only the sequential case but also continuous
behavior. (For lack of place, we assume some familiarity with
\cite{Gur00}.)
However, when evolving continuously, an algorithm can no longer be viewed as a discrete sequence of
states, and we need a notion of evolution that can capture both kinds of behavior. This
is based on a notion of a \emph{timeline}  that corresponds
to  algorithm execution.





\begin{definition}[Time]
  \emph{Time}   corresponds
to a totally ordered monoid: there is an associative binary
    operation , with some neutral element , and a total relation  preserved
  by :   implies  for all .
\end{definition}


An element of  will be called a \emph{moment}. Examples of time \TT\@
are  and . As expected,  will mean  but not .





\begin{definition}[Timeline]
A timeline is a subset of  containing . We let  denote the set of all timelines.
\end{definition}



For a moment  of timeline ,  we write  if there exists
 with , and there is no  with .
We write  otherwise: that means that for all , ,
there is some in-between  with .
\nd{A moment  with  is meant to indicate a
  discrete transition.  In this case, we write  for the smallest
   greater than .}
A timeline  is non-Zeno if for any moment , there is a
finite number of moments  with .  is
non-Zeno if all its timelines are. 



For timelines , for instance, we have  for all .
    For , we have  for all , and
    .
We intend (for hybrid systems, in particular) to also
    consider timelines  mixing both properties, that is, with
     for some  and  for
    other . Formally building  such timelines is easy (for
      example ). All these examples are non-Zeno.



\begin{definition}[Truncation]
Given a timeline  and a moment  of , the
\emph{truncated} timeline  is the timeline defined by
.
\end{definition}








With timelines in hand, we can define hybrid dynamical systems.

\begin{definition}[Dynamical System]\label{LTS} \label{def:ts}
A \emph{dynamical  system} 
consists of the following:
\itm{a} a nonempty set (or class)
 of \emph{states};
\itm{b} a nonempty subset (or subclass) , called \emph{initial} states;
\itm{c} a \emph{timeline} map , with  non-Zeno;
\itm{d} a \emph{trajectory} map .
We require that,
for any state  and moments , one has

\end{definition}

Together, the \emph{timeline} and \emph{trajectory} maps associate to each state its future
evolution. For a state ,  defines the timeline corresponding to the system behavior
starting from , and  defines its concrete evolution by associating to each moment in
 its corresponding state. The third condition ensures that evolution during  is similar to
first evolving during  and then during ; the preceding condition ensures a similar
property for timelines (and ensures  consistency of the last condition).

\begin{postulatep} An algorithm is a dynamical system.
\end{postulatep}





A vocabulary  is a finite collection of fixed-arity (possibly
nullary)  function
symbols,
 some functions of which may be tagged \emph{relational}.  A term whose
 outermost function symbol is relational is termed \emph{Boolean}. We
 assume that  contains the scalar (nullary) function \textit{true}.
A (first-order) \emph{structure}  of vocabulary  is a nonempty set , the
\emph{base set (domain)} of , together with interpretations of the function
symbols in  over : A -ary function  symbol  is interpreted as a function,
denoted  , from  to .  Elements of  are also called elements of
, or \emph{values}. Similarly, the interpretation of a term  in 
is recursively defined by .

Let  and  be structures of the same vocabulary . An
\emph{isomorphism} from  onto  is a one-to-one function 
from the base set of  onto the base set of  such that  in  whenever 
in .


\begin{definition}[Abstract Transition System]\label{ATS}
An \emph{abstract transition system} is a dynamical system
whose states  are (first-order) structures over some finite vocabulary ,
such that the following hold:
\begin{enumerate}
\item States are closed under isomorphism, so if  is a state of the system, then any structure  isomorphic to  is also a state in , and  is an initial state if  is.
\item Transformations preserve the base set: that is, for every state , for any ,  has the same base set as .




\item Transformations respect isomorphisms:   if 
  is an isomorphism of states ,  then

   and for all , ,
    where , and .


\end{enumerate}
\end{definition}

\begin{postulatep} \label{postulateats} An
  algorithm is an abstract
  transition system.
\end{postulatep}

When  is  (or order-isomorphic to ) for all , this corresponds precisely to the concepts
 introduced by \cite{Gur00}, considering that .






It is convenient to think of a structure  as a memory of some kind: If
 is a -ary function symbol in vocabulary , and
 is a -tuple of elements of the base set of , then
the pair  is called a
\emph{location}. We denote by  its interpretation
in , i.e.\@ .
If  is a
location of  and  is an element of  then
 is an \emph{update} of .
When  and  are structures over the same domain and vocabulary,
 denotes the set of updates 


We want instantaneous evolution to be describable by updates:


\begin{definition} \label{defmachin}
An \emph{infinitesimal generator}   is \itm{a} a function  that  maps states  to a set  of updates,
and \itm{b} preserves
  isomorphisms: if  is an isomorphism of states
  , then for all updates
  , we have an isomorphic update
  .
\end{definition}



\nd{We write  and say that  is a \emph{jump} when   in
timeline
; otherwise, we write  and say that it is a \emph{flow}.}
For states  with
, the following is natural:


\begin{definition} \label{defupdate}
The \emph{update generator} is the infinitesimal generator defined on
jump states  as
, where  stands for
.
\end{definition}


To deal with flow states, we will also define some corresponding infinitesimal
generator . Before doing so, let's see  how to go from semantics to
generators.




An \emph{initial evolution} over  is a function whose
domain of definition is a timeline and whose range is . An initial evolution is said to be \emph{initially constant} if it has
a constant prefix: that is to say, there is some  such that
the function is constant over .


\begin{definition}[Semantics]
A \emph{semantics}  over a class  of sets 
is a partial function mapping
initial evolutions over some 
to an element of .
\end{definition}

\begin{remark} \label{rq:ex}
When , an example of
semantics over the class of sets  containing  is the derivative , mapping a function
 to its
derivative at  when that exists. When , an example of
semantics over the class of all sets would be the function  mapping
 to . More generally, when  is such that , an example of
semantics over the class of all sets is the function  mapping
 to .
\end{remark}

Consider a semantics  over a class of sets .
Let  be a state whose domain is in the class and a location 
of .  Denote by  the corresponding initial
evolution: that is to say, the
function given formally by  for , for some , with  for a jump.
We use  to denote the image of this evolution under  (when it exists).

\begin{definition}[Infinitesimal generator associated with
  ] The infinitesimal generator associated with ,
 maps each state , such that  is defined for all locations, to
the set: X
\end{definition}

The update generator  (see Definition
\ref{defupdate}) is the infinitesimal generator associated with the
semantics  (of Remark \ref{rq:ex}) over flow states. 

From now on, we assume that some semantics  is fixed to deal
with flow states. It could be
, but it could also be another one (for example:
talking about integrals or built using infinitesimals as in \cite{rust2000hybrid}).  We denote by
 the associated infinitesimal generator.


We are actually discussing algorithms relative to some
    , and to be more precise, we should be refering to -algorithms.
The point is that not every infinitesimal generator is appropriate
    and that appropriateness is actually relative to a time domain and
    to the class of allowed dynamics over this time domain.
\nd{To see this, keep in mind that -- when  corresponds to derivative
    -- to be able to talk about
    derivatives, one implicitly restricts oneself to dynamics that are
    differentiable, hence non-arbitrary. In other words, one is restricting
    to a particular class of possible dynamics, and not all dynamics
    are allowed. Restricting to other classes of dynamics (for example, analytic
    ones) may lead to  different notions of algorithm.}






From the update generator  and , we build a
generator also tagging states by the fact that they correspond to a
jump or a flow:

\begin{definition}[Generator of a State] \label{def:behaviord}
We define the \emph{tagged generator} of a state , denoted , as a
function that maps state  to  when
 and  is defined and to  when
.
\end{definition}







Let  be a set of ground terms.
We say that states  and  \emph{coincide} over ,
if  for all .
This will be abbreviated .
The fact that   and  {coincide} over  implies that  and 
necessarily share  some common elements in their
respective base sets,  at least all the  for .


An algorithm should have a finite imperative description. Intuitively, the evolution
of an algorithm from a given state is only determined by inspecting part of this
state by means of the terms appearing in the algorithm
description. The following
corresponds to the \emph{Bounded Exploration} postulate in
\cite{Gur00}.


\begin{postulatep} \label{postulatetrois}

For any algorithm, there exists a finite set  of ground terms over
  vocabulary  such that for all states  and  that coincide
  for ,   and  both exist and .
\end{postulatep}

A ground term of  is a \emph{critical term} and a \emph{critical
  element} is the value (interpretation) of a critical term.



\begin{definition}[Analog Algorithm] \label{defalgo}
An \emph{algorithm} is an object satisfying Postulates I through III.
\end{definition}

\section{Characterization Theorem}



We now go on to define the rules of our programs (adding to those of ASM
programs  in \cite{Gur00}).



\begin{definition}\begin{itemize}
\item \textbf{Update Rule:}  An \emph{update rule} of vocabulary  has the
  form  where  is a -ary function symbol
  in  and  are ground terms over .



\item \textbf{Parallel Update Rule: }
If  are update rules of vocabulary , then
\begin{center}
\begin{minipage}{8cm}
\begin{ttcode}
par \\
\s  \\
\s    \\ 
\s  \\ 
\s   \\
endpar \\ 
\end{ttcode}
\end{minipage}
\end{center}
is a \emph{parallel update rule} of vocabulary .
\end{itemize}
\end{definition}

 denotes the interpretation of a rule  in state 
and is defined as expected: If  is an update rule  then

and when  is  then  where  for all .

Next, we introduce rules to deal with .

\begin{definition}\begin{itemize}
\item \textbf{Basic Continuous Rule:}
  A \emph{basic continuous rule} of vocabulary  has the
  form  where  is a symbol of arity   and  are ground terms of vocabulary .





\item \textbf{Flow Rule:}
If  are basic continuous rules of vocabulary , then
  \begin{center}
  \begin{minipage}{8cm}
\begin{ttcode}
flow \\ 
\s  \\ 
\s   \\
\s   \\ 
\s  \\ 
endflow \\ 
\end{ttcode}
  \end{minipage}
   \end{center}
is a \emph{flow rule} of vocabulary .
\end{itemize}
\end{definition}

Their semantics are then defined as follows.
If  is a  basic continuous rule  then

where each .
If  is a  flow rule with constituents , then

where .


Finally, we allow conditionals:

\begin{definition}
\begin{itemize}
\item \textbf{Selection Rule:}
If  is a ground boolean term over vocabulary  and
   and  are  rules of vocabulary  then:
   \begin{center}
   \begin{minipage}{8cm}
    \begin{ttcode}
      if  then \\
     \s  \\ 
      else\\
      \s  \\ 
      endif \\
    \end{ttcode}
   \end{minipage}
   \end{center}
is a rule of vocabulary .
\end{itemize}
\end{definition}



Given such a rule  and a state , if  evaluates to
 \textit{true} (the interpretation of scalar function \textit{true}) in   then
 else .


An ASM program of vocabulary  is a rule of vocabulary .
The first key result is the following, which can be seen as a
completeness result.


\begin{theorem}[Completeness] \label{mlemma} \nd{For every algorithm of vocabulary , there
  is an ASM program  over   with the identical behavior:
   for all states .}
 \end{theorem}



\section{Proof of Theorem \ref{mlemma}}


Before turning to the proof of our main theorem, we reformulate and
extend several of the constructions in \cite{Gur00}.





\begin{lemma}[{\cite[Lemma 6.2]{Gur00}}] \label{lem1}
Consider an algorithm , consider a state  of  and assume
. By definition,  .

Consider ,
  an update of .  Then all elements 
  are critical elements of , that is, they correspond to values
  (interpretations) of critical terms.
\end{lemma}



\begin{proof}
The proof proceeds by contradiction. Assume that some  does not correspond to the
value of any critical term.  One can easily consider a structure  isomorphic to  which is obtained from  by
replacing  with a fresh element .
By Postulate
\ref{postulateats},  is a state and  for every
 critical term .
By Postulate \ref{postulatetrois}, we know that
, and we must have:
.
By Postulate \ref{postulateats},
 does not occur in  (the base set of)   either. Hence, it cannot occur in
. This gives the desired
contradiction.
\end{proof}



\begin{lemma}[Generalization of {\cite[Lemma 6.2]{Gur00}}] \label{lem2}
Consider an algorithm  and assume . Then by definition
.

Consider ,
an element of .  Then all elements 
are critical elements of , that is, they correspond  to values of critical terms.
\end{lemma}

\begin{proof}
The proof proceeds by contradiction. Assume that some  does not correspond to the
value of any critical term.  One can easily consider a structure  isomorphic to  which is obtained from  by
replacing  with a fresh element .

By Postulate
\ref{postulateats},  is a state. Observe that  for every
 critical term .

By Postulate \ref{postulatetrois}, we know that
, and we must have:

By Postulate \ref{postulateats},
 does not occur in  (the base set of)  . Hence it cannot occur in
, since by Definition \ref{defmachin} elements in  are
elements of the base set of . This gives the desired
contradiction.
\end{proof}





The following follows directly from Lemmas \ref{lem1} and \ref{lem2}.

\begin{corollary}[Corollary 6.6 of \cite{Gur00}]
For every state , there exists a
rule  such that .



\end{corollary}

We now generalize some of the other lemmas from \cite{Gur00} to apply to our
more general setting.

\begin{lemma}[Generalization of {\cite[Lemma 6.7]{Gur00}}]
\label{sixsept}
If states  and  coincide over the set  of critical terms,
then:

\end{lemma}

\begin{proof}
We have .
The first equality holds because  involves only critical terms
and because critical terms have the same values in  and . The
second equality holds by the definition of  (that is to say, this
is the previous corollary). The third equality
holds because of the choice of  and because  and  coincide
over .
\end{proof}


\begin{lemma}[Generalization of {\cite[ Lemma 6.8]{Gur00}}] \label{prevle}
Suppose that  are states and that  for some
state  isomorphic to  then:

\end{lemma}

\begin{proof}
Let  be an isomorphism from  onto an appropriate . Extend  to tuples,
locations, updates and set of updates. It is easy to check that .
By the choice of , .

By Definition \ref{defmachin}, generators preserve isomorphisms,
thus  and then .
It remains to apply  to both sides of the last equality.
\end{proof}

At each state , the equality relation between critical elements
induces an equivalence relation

over critical terms.

States  and  are -similar if .

\begin{lemma}[Generalization of {\cite[Lemma 6.9]{Gur00}}]\label{lemma:lem62gur}
Let  be a state. Then,  for every
state  that is  -similar to , we have:

\end{lemma}

\begin{proof}
Replace every element of  that
belongs to  with a fresh element. This gives a structure  that
is isomorphic to  and disjoint from . By Postulate
\ref{postulateats},  is a state. Since  is isomorphic to ,
it is -similar to  and therefore -similar to .

Let  be the structure isomorphic to  that is obtained
from  by replacing  with  for all critical
term  (the definition of  is coherent because  and  are
-similar). By Lemma \ref{sixsept}, we have .

Since  is isomorphic to  isomorphic to , then  is isomorphic to 
and by Lemma \ref{prevle}, we conclude .
\end{proof}



By previous Lemma \ref{lemma:lem62gur}, for every state , there exists a boolean term  that
evaluates to  in a structure  if and only if  is
-similar to . Indeed, the desired term asserts that the equality
relation on the critical terms is exactly the equivalence relation
.

Since there are only finitely many critical terms, there are
only finitely many possible equivalence relations . Hence there
exists a finite set  of states such that every
state is -similar to one of the state  or , and such that
  and  for all  (recall that the
property of being  is preserved by -similarity
from the previous lemma).  States   can
be chosen mutually exclusive, that is to say in different equivalence
relations. Boolean terms  and   then realize a partition of the
set of states.

We can then go to the proof of Theorem \ref{mlemma}: 
Let  be as above. The desired  is
\begin{center}
  \begin{minipage}{5cm}
\begin{ttfamily}
\noindent
   if  then\\  \s \\  else \\
   \s if  then\\ \s\s   \\ \s else \\
\s\s\s\s   \\
\s\s\s\s    if  then \\
\s\s\s\s \s  \\
\s\s\s\s  else \\
\s\s\s\s \s\s
   if  then\\
\s\s\s\s \s\s\s  \\
\s\s\s\s  \s\s else \\
\s\s\s\s \s\s\s    if  then \\
\s\s\s\s \s\s\s\s \\
\s\s\s\s \s\s\s  else  \\
\s\s\s\s \s\s\s\s\s\s\s   \\
\s\s\s\s \s\s\s\s \s\s\s   if  then\\
\s\s\s\s \s\s\s\s \s\s\s\s  
\s\s\s\s \s\s\s\s \s\s\s else
\s\s\s\s \s\s\s\s \s\s\s\s  
\s\s\s\s \s\s\s\s \s\s\s endif \\
\s\s\s\s \s\s\s endif \\
\s\s\s\s  \s\s endif\\
\s\s\s\s endif\\
\s endif\\
endif
\end{ttfamily}
\end{minipage}
\end{center}
where the  are (possibly parallel) update  rules, and the  are flow
rules.



\section{Extended Statements}



We are now very close to formulating our other theorems. First we define an
abstract state machine relative to semantics .


\begin{definition} A -abstract state machine  comprises the following:
\itm{a} an ASM program ;
\itm{b} a set  of (first-order) structures over some finite
    vocabulary  closed under isomorphisms, and a subset  closed under isomorphisms;
\itm{c} a map  and a map  such that   is an algorithm, where  is fixed to be the infinitesimal
generator associated with , and
for all
states  in ,
.
\end{definition}


By definition, a  -abstract state machine  satisfies all the
postulates and hence is an algorithm.

\begin{definition}
An ASM program  is \emph{-solvable} for a set  of (first-order) structures over some finite
    vocabulary  closed under isomorphisms and a subset  closed under isomorphisms if there exists a unique
     and  such that  is a -abstract
    state machine.
\end{definition}


\begin{definition}
A semantics  is \emph{unambiguous} if for all sets  of (first-order) structures over some finite
    vocabulary  closed under isomorphisms, and for all subsets  closed under isomorphisms, whenever there exists some 
    and  such that  is a -abstract
    state machine, then  and  are unique.
\end{definition}

Our main results follow.


\begin{theorem} \label{thone}
  For every -definable algorithm , there exists an equivalent -abstract state machine .
\end{theorem}


\begin{proof}By construction,  is a hybrid dynamical
  system such that  for some  given by
  previous discussions. Set the states of  to be the
  states of  and the initial states of
   to the initial states of .
\end{proof}





\begin{theorem} \label{thtwo}
  Assume that  is unambiguous.
For every -definable algorithm , there exists a unique equivalent -abstract
  state machine  with same states and initial states.
\end{theorem}



\begin{proof}[of Theorem \ref{thtwo}]
This is exactly the same proof as for Theorem \ref{thone}. Unicity comes from the definition of
unambiguity.
\end{proof}




\begin{corollary} \label{coromain}
Assume that  is unambiguous.
For every -definable algorithm , there exists an equivalent -solvable ASM
  program.
\end{corollary}


To any algorithm  that is -definable there corresponds an
    equivalent -abstract state machine , and hence a
    -solvable program . Conversely, a -abstract state
    machine  corresponds to a -definable algorithm.
However, not every program  is -solvable.

When -corresponds to , unambiguity comes from
(unicity in)
the Cauchy-Lipschitz theorem.  The fact that
    not every program  is -solvable is due to the fact that
    not all differential equations have a solution.







\section{Examples}


The examples in this section are for semantics .
Our settings cover, first of all, analog algorithms that are  pure flow, in particular all systems that can be modeled as ordinary differential equations.
A very simple, classical example is the pendulum: the motion of an idealized simple pendulum is governed by the second-order
differential equation 
where
 is angular displacement,  is gravitational acceleration,
and  is the length of the pendulum rod.
This can indeed be modeled as the program

 \begin{center}
  \begin{minipage}{8cm}
\begin{ttcode}
flow \\
 \s   \\
\s   \\
endflow
\end{ttcode}
   \end{minipage}
  \end{center}

\noindent
using the fact that any ordinary differential equation can be put in the form of a vectorial first-order equation, here  corresponding to the derivative of .

As a consequence, our formalism covers very generic classes of continuous-time models of computation, including the GPAC, which corresponds to ordinary differential equations with polynomial right-hand sides \cite{GC03,GBC09}.
Recall that the GPAC was proposed as a mathematical model of
differential analyzers (DAs), one of the most famous analog computer
machines in history.  Figure~\ref{gpac} (left) depicts a (non-minimal) GPAC that generates sine and cosine.
In this
picture,   signifies  some integrator, and   denotes
some constant block.
This simple GPAC can be modeled by the program

\begin{center}
 \begin{minipage}{8cm}
\begin{ttcode}
flow \\
 \s  \\
\s   \\
\s   \\
endflow
\end{ttcode}
  \end{minipage}
 \end{center}




\begin{figure}[t]\begin{tabular}{ll}
\begin{minipage}{0.5\textwidth}
\begin{center}
\small
\begin{picture}(200,60)(13,10)
\put(40,20){\framebox(30,20){}}
\put(100,16){\framebox(30,20){}} \put(100,30){\line(-1,0){30}}
\put(160,20){\framebox(30,20){}} \put(160,26){\line(-1,0){30}}
\put(105,45){\framebox(20,15){\textrm{-1}}}
\put(160,34){\line(-1,0){15}} \put(145,34){\line(0,1){18.5}}
\put(145,52.5){\line(-1,0){20}} \put(40,26){\line(-1,0){20}}
\put(30,26){\circle*2} \put(30,26){\line(0,-1){16}}
\put(100,22){\line(-1,0){10}} \put(90,22){\line(0,-1){12}}
\put(90,10){\line(-1,0){60}} \put(210,30){\line(-1,0){20}}
\put(200,30){\circle*2} \put(200,30){\line(0,1){40}}
\put(200,70){\line(-1,0){170}} \put(30,70){\line(0,-1){36}}
\put(40,34){\line(-1,0){10}} \put(16,24){}
\put(212,29){} \put(140,21){} \put(80,33){}
\end{picture}
\end{center}
\end{minipage}
&
\begin{minipage}{0.5\textwidth}

\end{minipage}
\end{tabular}
\caption{A GPAC for sine and cosine (left). Corresponding evolution (right).}\label{gpac}
\end{figure}








Our proposed model can also adequately describe hybrid
systems, made of alternating sequences of continuous evolution and discrete transitions.
This includes, for example, a simple model of a bouncing ball,
the physics of which are given by the flow equations
,
where  is the gravitational constant and  is the velocity,
except that upon impact, each time , the velocity changes according to

where  is the coefficient of impact. Every time the ball
bounces, its speed is reduced by a factor .
This system can be described by a program like

\bigskip

\noindent
\qquad\begin{minipage}{15cm}
\begin{ttcode}
if  then \\
\s   \\
else \\
\s flow \\
\s\s    \\
\s\s   \\
\s endflow \\
endif
\end{ttcode}
\end{minipage}

\bigskip

Our setting is an extension of classical discrete-time algorithms; hence, all classical discrete-time algorithms can also be modeled.

 As for examples with semantics other than :  Observe
  that one can consider timelines like  instead of . (For such
  a timeline, we have  for all .) One
  can define a semantics on such a timeline where for every state 
  we have  by first extending the evolution function
  to  (for example by
restricting to continuous
  dynamics) and then using the derivative.
Constructions of \cite{rust2000hybrid} are also covered by our
  settings: In some sense, the example at the beginning of the paragraph is the
  spirit of the constructions from \cite{rust2000hybrid}, where the
  timeline is the set of hyperreals obtained by multiplying some fixed
  infinitesimal by some hyperinteger (using hyperreals and
  infinitesimals).
Notice  that there is no need to consider derivatives or similar
notions: we could also consider analytic dynamics, and consider a
semantics related to the family of  Taylor coefficients. Weaker
notions of solution, like variational approaches, can also be considered.







\bibliographystyle{splncsa}
\bibliography{biblio2}
\end{document}
