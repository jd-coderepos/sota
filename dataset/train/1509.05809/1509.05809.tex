\clString and \clSubstring are two computational problems motivated by questions in molecular biology connected to identifying functionally similar regions of DNA or RNA sequences, as well as by applications in coding theory. In \clString we are given a family $\Cnst$ of strings over some fixed alphabet $\Sigma$, each of length $\Len$. The task is to find one string $y\in \Sigma^\Len$ for which $\max_{x\in \Cnst} \Ham(x,y)$ is minimum possible, where $\Ham(x,y)$ is the {\em{Hamming distance}} between $x$ and $y$, that is, the number of positions on which $x$ and $y$ have different letters. We will consider both the optimization variant of the problem where the said distance is to be minimized, and the decision variant where an upper bound $\dst$ is given on the input, and the algorithm needs to decide whether there exists a string $y$ with $\max_{x\in \Cnst} \Ham(x,y)\leq d$. \clSubstring is a more general problem where the strings from the input family $\Cnst$ all have length $m\geq \Len$, and we look for a string $y\in \Sigma^\Len$ that minimizes $\max_{x\in \Cnst}\min_{x'\textrm{ substring of }x} \Ham(x',y)$. In other words, we look for $y$ that can be fit as close as possible to a substring of length $\Len$ of each of the input strings from $\Cnst$.

Both \clString and \clSubstring, as well as numerous variations on these problems, have been studied extensively from the point of view of approximation algorithms. Most importantly for us, for both of these problems there are classic results providing {\em{polynomial-time approximation schemes}} ({\em{PTASes}}): for every $\eps>0$, it is possible to approximate in polynomial time the optimum distance within a multiplicative factor of $(1+\eps)$. The first PTASes for these problems were given by Li et al.~\cite{limawang}, and they had running time bounded by $n^{\Oh(1/\eps^4)}$. This was later improved by Andoni et al.~\cite{AndoniIP06} to $n^{\Oh(\frac{\log 1/\eps}{\eps^2})}$, and then by Ma and Sun~\cite{MaS09} to $n^{\Oh(1/\eps^2)}$, which constitutes the current frontier of  knowledge. We refer to the works~\cite{Boucher15,LiMW02a,GrammNR03,limawang,MaS09,Marx08} for a broad introduction to biological applications of \clString, \clSubstring, and related problems, as well as pointers to relevant literature.

One of the immediate questions stemming from the works of Li et al.~\cite{limawang}, Andoni et al.~\cite{AndoniIP06}, and Ma and Sun~\cite{MaS09}, is whether either for \clString or \clSubstring one can also give an {\em{efficient polynomial-time approximation scheme}} ({\em{EPTAS}}), i.e., an approximation scheme that for every $\eps>0$ gives a $(1+\eps)$-approximation algorithm with running time $f(\eps)\cdot n^{\Oh(1)}$, for some computable function $f$. In other words, the degree of the polynomial should be independent of $\eps$, whereas the exponential blow-up (inevitable due to NP-completeness) should happen only in the multiplicative constant standing in front of the running time. EPTASes are desirable from the point of view of applications, since they provide approximation algorithms that can be useful in practice already for relatively small values of $\eps$, whereas running times of general PTASes are usually prohibitive.

For the more general \clSubstring problem, this question was answered negatively by Marx~\cite{Marx08} using the techniques from parameterized complexity. More precisely, Marx considered various parameterizations of \clSubstring, and showed that when parameterized by $\dst$ and $|\Cnst|$, the problem remains W[1]-hard even for the binary alphabet. This means that the existence of a fixed-parameter algorithm with running time $f(\dst,|\Cnst|)\cdot n^{\Oh(1)}$, where $n$ is the total size of the input, would imply that $\mathrm{FPT}=\mathrm{W[1]}$, a highly unexpected collapse in the parameterized complexity. This result shows that, under $\mathrm{FPT}\neq \mathrm{W[1]}$, also an EPTAS for \clSubstring can be excluded. Indeed, if such an EPTAS existed, then by setting any $\eps<\frac{1}{\dst}$ one could in time $f(\dst)\cdot n^{\Oh(1)}$ distinguish instances with optimum distance value $\dst$ from the ones with optimum distance value $\dst+1$, thus solving the decision variant in fixed-parameter tractable (FPT) time. Using more precise results about the parameterized hardness of the \clique problem, Marx~\cite{Marx08} showed that, under the assumption of {\em{Exponential Time Hypothesis}} ({\em{ETH}}), which states that {\sc{3-SAT}} cannot be solved in time $\Oh(2^{\delta n})$ for some $\delta>0$, one even cannot expect PTASes for \clSubstring with running time $f(\eps)\cdot n^{o(\log (1/\eps))}$ for any computable function $f$. We refer to a survey of Marx~\cite{Marx08-survey} for more examples of links between parameterized complexity and the design of approximation schemes.

The methodology used by Marx~\cite{Marx08}, which is the classic connection between parameterized complexity and EPTASes that dates back to the work of Bazgan~\cite{bazgan:thesis} and of Cesati and Trevisan~\cite{CesatiT97}, completely breaks down when applied to \clString. This is because this problem actually does admit an FPT algorithm when parameterized by $\dst$. An algorithm with running time $d^d\cdot n^{\Oh(1)}$ was proposed by Gramm et al.~\cite{GrammNR03}. Later, Ma and Sun~\cite{MaS09} gave an algorithm with running time $2^{\Oh(d)}\cdot |\Sigma|^d\cdot n^{\Oh(1)}$, which is more efficient for constant-size alphabets. Both the algorithms of Gramm et al. and of Ma and Sun are known to be essentially optimal under ETH~\cite{LokshtanovMS11}, and nowadays they constitute textbook examples of advanced branching techniques in parameterized complexity~\cite{platypus}. Therefore, in order to settle the question about the existence of an EPTAS for \clString, one should look for a substantial refinement of the currently known techniques.

An approach for overcoming this issue was recently used by Boucher et al.~\cite{Boucher15}, who attribute the original idea to Marx~\cite{Marx08-survey}. Boucher et al. considered a problem called \cPattern, which is a variation of \clSubstring where the goal function is the total sum of Hamming distances between the center string and best-fitting substrings of the input strings, instead of the maximum among these distances. The problem admits a PTAS due to Li et al.~\cite{LiMW02a}, and was shown by Marx~\cite{Marx08} to be fixed-parameter tractable when parameterized by the target distance $\dst$. Despite the latter result, Boucher et al.~\cite{Boucher15} managed to prove that the existence of an EPTAS for \cPattern would imply that $\mathrm{FPT}=\mathrm{W[1]}$. The main idea is to provide a reduction from a W[1]-hard problem, such as \clique, where the output target distance $\dst$ is not bounded by a function of the input parameter $k$ (indeed, the existence of such a reduction would prove that $\mathrm{FPT}=\mathrm{W}[1]$), but the multiplicative gap between the optimum distances yielded for yes- and no-instances is $1+\frac{1}{g(k)}$, for some computable function $g$. Even though the output parameter is unbounded in terms of $k$, an EPTAS for the problem could be still used to distinguish between output instances obtained from yes- and no-instances of \clique in FPT time, thus proving that $\mathrm{FPT}=\mathrm{W[1]}$.

\paragraph*{Our contribution} In this paper we provide a negative answer to the question about the existence of an EPTAS for \clString by proving the following theorem.

\begin{theorem}\label{thm:closest-hardness}
The following assertions hold:
\begin{itemize}
\item Unless $\mathrm{FPT}=\mathrm{W[1]}$, there is no EPTAS for \clString over binary alphabet.
\item Unless ETH fails, there is no PTAS for \clString over binary alphabet with running time $f(\eps)\cdot n^{o(1/\eps)}$, for any computable function~$f$.
\end{itemize}
\end{theorem}

Thus, one should not expect an EPTAS for \clString, whereas for PTASes there is still a room for improvement between the running time of $n^{\Oh(1/\eps^2)}$ given by Ma and Sun~\cite{MaS09} and the lower bound of Theorem~\ref{thm:closest-hardness}. It is worth noting that our $f(\eps)\cdot n^{o(1/\eps)}$ time lower bound for $(1+\eps)$-approximating \clString also holds for the more general \clSubstring problem. This yields a significantly stronger lower bound than the previous $f(\eps)\cdot n^{o(\log (1/\eps))}$ lower bound of Marx~\cite{Marx08}.

Our proof of Theorem~\ref{thm:closest-hardness} follows the methodology proposed Marx~\cite{Marx08-survey} and used by Boucher et al.~\cite{Boucher15} for \cPattern. 
The following theorem, which is the main technical contribution of this work, states formally the properties of our reduction.

\begin{theorem}\label{thm:main}
There is an integer $c$ and an algorithm that, given an instance $(G,k)$ of \clique, works in time $2^k\cdot n^{\Oh(1)}$ and outputs an instance $(\Cnst,\Len,\dst)$ of \clString over alphabet $\{0,1\}$ with the following properties:
\begin{itemize}
\item If $G$ contains a clique on $k$ vertices, then there is a string $w\in \{0,1\}^\Len$ such that $\Ham(w,x)\leq \dst$ for each $x\in \Cnst$.
\item If $G$ does not contain a clique on $k$ vertices, then for each string $w\in \{0,1\}^\Len$ there is $x\in \Cnst$ such that $\Ham(w,x)>(1+\frac{1}{ck})\cdot \dst$. 
\end{itemize}
\end{theorem}

The statement of Theorem~\ref{thm:main} is similar to the core of the hardness proof of Boucher et al.~\cite{Boucher15}. However, our reduction is completely different from the reduction of Boucher et al., because the causes of the computational hardness of of \clString and \cPattern are quite orthogonal to each other. In \cPattern the difficulty lies in {\em picking} the right substrings of the input strings. Once these substrings are known the center string is easily computed in polynomial time, since we are minimizing the sum of the Hamming distances. In \clString there are no substrings to pick, we just have to find a center string for the given input strings. This is a computationally hard task because we are minimizing the maximum of the Hamming distances to the center, rather than the sum. 






Theorem~\ref{thm:closest-hardness} follows immediately by combining Theorem~\ref{thm:main} with the known parameterized hardness results for \clique, gathered in the following theorem, and setting $\eps=\frac{1}{ck}$.

\begin{theorem}[cf. Theorem 13.25 and Corollary 14.23 of~\cite{platypus}]\label{thm:clique-hardness}
The following assertions hold:
\begin{itemize}
\item Unless $\mathrm{FPT}=\mathrm{W}[1]$, \clique cannot be solved in time $f(k)\cdot n^{\Oh(1)}$ for any computable function~$f$.
\item Unless ETH fails, \clique cannot be solved in time $f(k)\cdot n^{o(k)}$ for any computable function~$f$.
\end{itemize}
\end{theorem}

The main idea of the proof of Theorem~\ref{thm:main} is to encode the $n$ vertices of the given graph $G$ as an ``almost orthogonal'' family $\Sel$ of strings from $\{0,1\}^\bl$, for some $\bl=\Oh(\log n)$. Strings from $\Sel$ are used as identifiers of vertices of $G$, and the fact that they are almost orthogonal means that the identifiers of two distinct vertices of $G$ differ on approximately $\bl/2$ positions. On the other hand $\bl=\Oh(\log n)$, so the whole space of strings into which $V(G)$ is embedded has size polynomial in $n$. Using these properties, the reduction promised in Theorem~\ref{thm:main} is designed by a careful construction.


