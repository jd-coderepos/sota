\documentclass[preprint,12pt,english]{article}
\usepackage{amssymb,amsmath,amsthm,tikz,xcolor,float}
\def\tpl{\mathtt{tpl}}
\def\sz{\mathtt{sz}}
\def\xpm{\mathtt{dh}}
\def\hole{\bullet}
\def\tr{\mathtt{r}}
\def\tty{\mathtt{st}}
\def\tR{\mathtt{R}}
\def\tS{\mathtt{S}}
\def\cS{\mathcal{S}}
\def\tA{\mathtt{A}}
\def\tB{\mathtt{B}}
\def\cE{\mathcal{E}}
\def\tX{\mathtt{X}}
\def\tZ{\mathtt{Z}}
\def\cA{\mathcal{A}}
\def\cC{\mathcal{C}}
\def\cF{\mathcal{F}}
\def\cL{\mathcal{L}}
\def\cT{\mathcal{T}}
\def\cQ{\mathcal{Q}}
\def\sk{\mathtt{sk}}
\def\depth{\mathtt{d}}
\def\tppl{\mathtt{tpl}}
\def\vtr{\vartriangleright}
\def\Ra{\Rightarrow}
\newcommand\pair[1]{\langle{#1}\rangle}
\newcommand\comment[1]{}
\def\prece{\prec_{\mathtt{e}}}
\def\ty{\mathtt{t}}
\def\todo{\begin{center}{\color{red}\tt [TODO]}\end{center}}
\def\checked{\begin{center}{{\color{red}\tt [PROOFREAD UNTIL HERE ...]}}\end{center}}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{theorem}{Theorem}

\begin{document}

\title{Learning cover context-free grammars from structural data}



\author{ Mircea Marin, 
Gabriel Istrate \footnote {Dept. of Computer Science, West University of Timi\c{s}oara and e-Austria Research Institute, Bd. V. P\^{a}rvan 4, cam. 045
B, Timi\c{s}oara, RO-300223, Romania. Corresponding author's email: {\tt mmarin@info.uvt.ro }}}



\maketitle
\begin{abstract}
We consider the problem of learning an unknown context-free grammar when the only knowledge available and of interest to the learner is about its structural descriptions with  depth at most  The goal is to learn a {\em cover context-free grammar} (CCFG) with respect to , that is, a CFG whose structural descriptions with depth at most  agree with those of the unknown CFG. 
We propose an algorithm, called ,  that efficiently learns a CCFG using two types of queries: structural equivalence  and structural membership. 
We show that   runs in time polynomial in the number of states of a minimal deterministic finite cover tree automaton (DCTA) with respect to . This number is often much smaller than the number of states of a minimum deterministic finite tree automaton for the structural descriptions of the unknown grammar. 
\end{abstract}

{\bf Keywords:} automata theory and formal languages, grammatical inference, structural descriptions.


\section{Introduction}

Angluin's approach to grammatical inference \cite{Angluin:87} is an important contribution to computational learning, with extensions to problems, such as compositional verification and synthesis \cite{farzan2008extending,maler1995learnability}, that go beyond the usual applications to natural language processing and computational biology \cite{de2010grammatical}. 


Practical concerns, e.g. \cite{kumar2006minimization}, seem to require going beyond regular languages to classes of languages with regular tree nature.  However, Angluin and Kharitonov have shown that learning CFGs from membership and equivalence queries is intractable under plausible cryptographic assumptions \cite{angluin1995won}. A way out is to learn structural descriptions of context free languages. Sakabibara has shown that Angluin's algorithm extends to this setting \cite{Sak:1990}. His approach has applications in learning the structural descriptions of natural languages, which describe the shape of the parse trees of well chosen CFGs. Often, these structural descriptions are subject to additional restrictions arising from modelling considerations. For instance, in natural language understanding, the bounded memory restriction on human comprehension seems to limit the recursion depth of such a parse tree to a constant. A natural example with a similar flavour is the limitation imposed by the \LaTeX\ system, that limits the number of nestings of itemised environments to a small constant.

Imposing such a restriction leads to the idea of learning cover languages, that is, languages that accurate up to an equivalence. For regular languages modulo a finite prefix such an approach has been pursued by Ipate \cite{Ipate:2012} (see also \cite{holzer2012equivalence}).

\comment{
We address the problem of learning an unknown context-tree grammar (CFG) when the only information available and of interest to the learner are its structural descriptions with depth at most . The structural descriptions of a CFG are the trees obtained from the derivation trees of the grammar by unlabelling all its internal nodes. They have been recognised by Levy and Joshi as useful data for the efficient learning of the unknown grammar \cite{LJ:1978}. 

Using the fact that, for a CFG, the set of derivation trees  and the set of structural descriptions  are rational sets of trees, Sakabibara proposed in \cite{Sak:1990} an algorithm, called , which reduces the problem of learning a CFG from structural descriptions to that of learning a tree automaton. His algorithm is an extension of Angluin's efficient learning algorithm  for finite automata  \cite{Angluin:87} to  one for tree automata, using two types of queries: structural equivalence queries and structural membership queries.   runs in time polynomial in the number of states of a minimal deterministic bottom-up tree automaton for the structural descriptions of the unknown grammar and the maximum size of any counterexample returned by a structural equivalence~query.

Algorithms  and  are suitable for learning efficiently an {\em exact} characterisation of the (regular or context-free) language under consideration. But, as noticed by Ipate in \cite{Ipate:2012}, there are many practical applications where characterisations of finite subsets of the language suffice. For regular languages where the interest is only in words with length at most , Ipate defines the notion of minimal {\em deterministic finite cover automaton} (DFCA) with respect to , and proposes an algorithm to learn such an DFCA in time polynomial in the number or its states~\cite{Ipate:2012}. His algorithm, called ,  is a nontrivial adaptation of algorithm~.


Ipate's ideas can be carried over to context-free languages if we restrict the learning to a CFG whose structural descriptions are of interest only when they are of depth at most . In this case, we are interested to learn a {\em cover CFG}, that is, a context-free grammar whose structural descriptions with depth at most  coincide with the structural descriptions of the unknown CFG; structural descriptions of higher depth can also be generated, but they are of no interest to the learning process. Like Sakakibara, we reduce the problem of learning such a CFG to that of learning a special tree automaton which, in our case, turns out to be a minimal deterministic finite cover tree automaton (DCTA) for the structural descriptions of interest. Formally, a minimal DCTA of an unknown context-free grammar  with respect to  is a minimal deterministic bottom-up tree automaton which accepts all structural descriptions of  with depth at most , and possibly other with depth larger than . This kind of tree automaton is an adaptation of Ipate's minimal DFCA to languages of structural descriptions.

a\\
a\\
a\\
a\\
a
}

In this paper, we extend this approach to context-free languages with structural descriptions. 
We propose an algorithm called  which 
\comment{is an adaptation of the learning algorithms  and  in the following ways:
It} 
asks two types of queries: structural equivalence and structural membership queries, both restricted to structural descriptions with depth at most , where  is a constant.
 stores the answers retrieved from the teacher in an {\em observation table} which is used to guide the learning protocol and to construct a minimal DCTA of the unknown context-free grammar with respect to .
Our main result shows that  runs in time  polynomial in  and , where  is the number of states of a minimal DCTA of the unknown CFG with respect to , and  is the maximum size of a counterexample returned by a failed structural membership query. 

The paper is structured as follows. Section \ref{prelim} introduces the basic notions and results to be used later in the paper. It also describes algorithm . 
In Sect. \ref{sect4} we introduce the main concepts related to the specification and analysis of our learning algorithm . They are natural generalisations to languages of structural descriptions of the concepts proposed by Ipate \cite{Ipate:2012} in the design and study of his algorithm . In Sect. \ref{sect5} we analyse the space and time complexity of  and show that its time complexity is a polynomial in  and , where  is the number of states of a minimal deterministic finite cover automaton w.r.t.  of the language of structural descriptions of interest, and  is an upper bound to the size of counterexamples returned by failed structural equivalence queries. \section{Preliminaries}
\label{prelim}
We write  for the set of nonnegative integers,  for the set of finite strings over a set , and  for the empty string. If , we write  if there exists  such that ;  if  and ; and  if neither  nor   
\subsection*{Trees, terms, contexts, and context-free grammars}
A {\em ranked alphabet} is a finite set  of function symbols  together with a finite {\em rank} relation  We denote the subset  by ,  the set  by , and   by .
The {\em terms} of the set  are the strings of symbols defined recursively by the grammar

where  and  with . The {\em yield} of a term  is the finite string  defined as follows:  if , and  where  for 

A {\em finite ordered tree} over a set of labels  is a mapping  from a nonempty and prefix closed set  into . Each element in  is called a {\em position}. The tree  is {\em ranked} if  is a ranked alphabet, and  satisfies the following additional property:
For all , there exists  such that   and  .

Thus, any term  may be viewed as a finite ordered ranked tree, and we will  refer to it by ``tree'' when we mean the finite ordered tree with the additional property mentioned above. The {\em depth} of  is  where  denotes the length of  as sequence of numbers. The {\em size}  of   is the number of elements of the set , that is, the number of internal nodes of .

The {\em subterm}  of a term  at position  is defined by the following: , and  for all  
We denote by  the term obtained by replacing in  the subterm  with , that is: , and 
The set  of {\em contexts} over  is the set of terms  over , where:
\begin{itemize}
\item  is a distinguished fresh symbol with , called {\em hole},
\item , and 
\item every element  contains only one occurrence of . This is the same as saying that  is a singleton set. 
\end{itemize}
If  and  then  stands for the context or term , where  The {\em hole depth} of a context  is  where  is the unique position of  such that  
From now on, whenever  is a set of terms,  is a set of contexts, and  is a non-negative integer, we define the sets
 and .

\comment{
A {\em context-free grammar} (CFG) is a quadruple  where:  is a finite set of {\em nonterminals};  is a finite set of {\em terminals};  is a finite set of {\em productions}   with  and ; and  is a special nonterminal called the {\em start symbol}.  Such a CFG induces a {\em derivation relation}  on the set of finite strings , defined by  whenever   and  The {\em language generated} by  is , where  is the reflexive and transitive closure of . A {\em context-free language} is a language generated by a CFG.}
We assume that the reader is acquainted with the notions of CFG and the context-free language  generated by a CFG , see, e.g., \cite{Sipser:2006}.
A CFG is -free if it has no productions of the form . It is well known~\cite{Hopcroft:2003} that every -free context-free language  (that is, ) is generated by an -free CFG. 
The derivation trees of an -free CFG   correspond to terms from  with  for al  and  with  for all . The sets  of derivation trees  issued from , and  of derivation trees of , are defined recursively as follows:

 Note that 
\subsection*{Structural descriptions and cover context-free grammars}
A {\em skeletal alphabet} is a ranked alphabet  , where  is a special symbol with  a finite subset of , and a {\em skeletal set} is a ranked alphabet  where  and  for all . 
Skeletal alphabets are intended to describe the structures of the derivation trees of -free CFGs. For an -free CFG  we consider the skeletal alphabet  with , and the skeletal set 
The {\em skeletal} (or {\em structural}) {\em description} of a derivation tree  is the term  where 
 
For example, if  is the grammar  then  and , where  and . Graphically,  we have
\begin{center}
\begin{tikzpicture}[scale=.4,baseline=-3.3em]
\node {}
  child {node {}
      child {node {}}
      child {node {}
        child {node {}}
        child {node {}}
      }
      child {node {}}
  };
\end{tikzpicture}
\quad\qquad
\begin{tikzpicture}[scale=.4,,baseline=-3.3em]
\node {}
  child {node {}
      child {node {}}
      child {node {}
        child {node {}}
        child {node {}}
      }
      child {node {}}
  };
\end{tikzpicture}
\end{center}
If  is a set of ranked trees, the set of its structural descriptions is  . Two context-free grammars  and  over the same alphabet of terminals are {\em structurally equivalent} if 

\begin{definition}[cover CFG]
Let  be a positive integer and  be an -free CFG of a language . 
A {\em cover context-free grammar} of  with respect to  is an -free CFG  such that . 
\end{definition}

\subsection*{Tree automata}

The definition of tree automaton presented here is equivalent with that given in~\cite{Sak:1990}. It is non-standard in the sense that it cannot accept any tree of depth 0. 
\begin{definition}
A {\em  nondeterministic (bottom-up) finite tree automaton} (NFTA) over  is a quadruple  where  is a finite set of {\em states},  is the set of {\em final states}, and  is a set of {\em transition rules} of the form  where , ,  and . 
\end{definition}
Such an automaton  induces a {\em move} relation  on the set of terms  where  for all , as follows: 
\begin{itemize}
\item[]  if there exist  and  such that  and 
\end{itemize}
The {\em language accepted by } is  where  is the reflexive-transitive closure of . In this paper, a {\em regular tree language} is a language accepted by such an NFTA.
Two NFTAs are {\em equivalent} if they accept the same language.

 is {\em deterministic} (DFTA) if the transition rules of  describe a mapping  which assigns to every  a function  such that
,  for all , and 
  if 
This implies that  if and only if  The  extension  of  to  is defined as expected:  if , and  otherwise. Note that, if  is a DFTA then 

Two DFTAs  and  are {\em isomorphic} if there exists a bijection  such that  and for every , ,  A {\em minimum DFTA} of a regular tree language  is a DFTA  with minimum number of states such that 

There is a strong correspondence between tree automata and -free CFGs.
The NFTA corresponding to an -free CFG  is  with 

Conversely, the -free CFG corresponding to an NFTA  over the skeletal set  is  where  is a fresh symbol and 

These  constructs are dual to each other, in the following sense:
\begin{enumerate}
\item[] If  is an -free CFG then . \hfill \cite[Prop. 3.4]{Sak:1990}
\item[] If  is an NFTA for the skeletal set  then . That is, the set of structural descriptions of  coincides with the set of trees accepted by . \hfill\cite[Prop. 3.6]{Sak:1990}
\end{enumerate}
We recall the following well-known results: 
every NFTA is equivalent to an DFTA~\cite{LJ:1978}, and every two minimal DFTAs are isomorphic~\cite{Brainerd:68}.

\subsection*{Cover tree automata}

\begin{definition}[determinstic DCTA]
Let  and  be a tree language over ranked alphabet .
A {\em deterministic cover tree automaton} (DCTA) of   with respect to  is a DFTA  over a skeletal set  such that . 
\end{definition}
The correspondence between tree automata and -free CFGs is carried over to a  correspondence between cover tree automata and cover CFGs. More precisely, it can be shown that if  is an -free CFG, then a DFTA  is a DCTA of  w.r.t.  if and only if  is a cover CFG of  w.r.t. .

\section{Learning context-free grammars}

In \cite{Sak:1990}, Sakakibara's  assumes  a {\em learner} eager to learn a CFG which is structurally equivalent with the CFG  of an unknown context-free language  by asking  questions to a {\em teacher}. We assume that the learner and the teacher share the skeletal set  for the structural descriptions in . The learner can pose the following types of queries:
\begin{enumerate}
\item {\em Structural membership queries}: the learner asks if some  is in . The answer is {\em yes} if so, and {\em no} otherwise.
\item {\em Structural equivalence queries}: The learner proposes a CFG  and asks whether  is structurally equivalent to . 
If the answer is {\em yes}, the  process stops with the learned answer . Otherwise, the teacher provides a counterexample  from the symmetric set difference  .
\end{enumerate}
This learning protocol is based on what is called {\em minimal adequate teacher} in~\cite{Angluin:87}.
Ultimately, the learner constructs a minimal DFTA  of  from which it can infer immediately the CFG   which is structurally equivalent to , that is, .  In order to understand how  gets constructed, we shall introduce a few auxiliary notions. 

For any subset  of , we define the sets 

Note that  for all  
\begin{definition}
A subset  of  is {\bf -prefix closed} with respect to a set  if  implies the existence of  and  such that  If  and  then  denotes the set of structural descriptions defined by


We say that  is {\bf subterm closed} if  for all , and  whenever  is a subterm of some  with .
\end{definition}

An {\em observation table} for , denoted by , is a tabular representation of the finitary function 
defined by  if , and 0 otherwise,
where  is a finite nonempty subterm closed subset  of , and  is a finite nonempty subset of  which is -prefix closed with respect to .
Such an observation table is visualised as a matrix with rows labeled by elements from , columns labeled by elements from , and the entry for row of  and column of  equal to . If we fix a listing  of all elements of , then the row of values of some  corresponds to the vector . In fact, for every such ,  is a finitary representation of the function  defined by . 


\comment{\begin{figure}[ht]

\caption{Tabular representation of an observation table .}
\label{opa}
\end{figure}}

The observation table  is {\em closed} if every   with  is identical to some  of . It is 
{\em consistent} if whenever  such that , we have 
for all 

The DFTA {\em corresponding to a closed and consistent observation table}  is  where
, , and  is uniquely defined by

where  if , and  if .
\vskip .4em\noindent
It is easy to check that, under these assumptions,  is well-defined, and that . Furthermore, Sakakibara proved that the following properties hold whenever  is a closed and consistent observation table:
\begin{enumerate}
\item  is consistent with , that is, for all  and  we have  iff \hfill \cite[Lemma 4.2]{Sak:1990}
\item If  has  states, and  is any DFTA consistent with  that has  or fewer states, then  is isomorphic to .\hfill \mbox{\cite[Lemma 4.3]{Sak:1990}}
\end{enumerate}
\subsection*{The  algorithm}
In this subsection we briefly recall Sakakibara's algorithm LA whose pseudocode is given in Appendix \ref{LA}.
 extends the observation table whenever one of the following situations occurs: the table is not consistent, the table is not closed, or the table is both consistent and closed but the CFG corresponding to the resulting automaton   is not structurally equivalent to  (in which case a counterexample is produced). The first two situations trigger an extension of the observation table with one distinct row.
From properties  and , if  is the number of states of the minimum bottom-up tree automaton for the structural descriptions of  , then the number of unsuccessful consistency and closedness checks during the whole run of this algorithm is at most . 
For each counterexample of size at most  returned by a structural equivalence query, at most  subtrees are added to .  Since the algorithm encounters at most  counterexamples, the total number of elements in  cannot exceed , thus  must terminate. It also follows that the number of elements of the domain  of the function  is at most
,
where  is the number of distinct ranks of , and  is the maximum rank of a symbol in .  A careful analysis of  reveals that its time complexity is indeed bounded by a polynomial in  and  \cite[Thm. 5,3]{Sak:1990}.

\section{Learning cover context-free grammars}
\label{sect4}
We assume we are given a teacher who knows an -free CFG  for a language , and a learner who  knows the skeletal set  for .  
The teacher and learner both know a positive integer , and the learner is interested to learn a cover CFG  of  w.r.t.  or, equivalently, a cover DCTA of  w.r.t. .
The learner is allowed to pose the following types of questions:
\begin{enumerate}
\item {\em Structural membership queries}: the learner asks if some  is in . The answer is {\em yes} if so, and {\em no} otherwise.
\item {\em Structural equivalence queries}: The learner proposes a CFG , and asks if  is a cover CFG of  w.r.t. .  If the answer is {yes}, the  process stops with the learned answer . Otherwise, the teacher provides a counterexample from the set  
\end{enumerate}
We will describe an algorithm  that learns a cover CFG of  with respect to  in time that is polynomial in the number of states of a minimal DCTA of the rational tree language 
\subsection{The observation table}
 is a generalisation of the learning algorithm  proposed by Ipate \cite{Ipate:2012}. Ipate's algorithm is designed to learn a minimal finite cover automaton of an unknown finite language of words in polynomial time, using membership queries and language equivalence queries that refer to words and languages of words with  length at most . Similarly,   is designed to learn a minimal DCTA  for  with respect to  by maintaining an observation table  for  which differs from the observation table of  in the following respects:
\begin{enumerate}
\item  is a finite nonempty subterm closed subset of . 
\item   is a finite nonempty  subset of  which is -prefix closed with respect to .
\item  is defined by 

\end{enumerate}
In a tabular representation, the observation table  is a two-dimensional matrix with rows labeled by elements from , columns labeled by elements from , and the entry corresponding to the row of  and column of  equal to 
If we fix a listing  of all elements from , then the row of  in the observation table is described by the vector  of values from  The rows of an observation table are used to identify the states a a minimal DCTA for  with respect to . But, like Ipate \cite{Ipate:2012}, we do not compare rows by equality but by a similarity relation. 

\subsection{The similarity relation}
This time, the rows in the observation table correspond to terms from , and the comparison of rows should take into account only terms of depth at most . For this purpose, we define a relation  of {\em -similarity}, which is a  generalisation to terms of Ipate's relation of -similarity on strings \cite{Ipate:2012}.
\begin{definition}[-similarity] 
For  we define the relation  on the elements of  the set  of an observation table  as follows:
\begin{itemize}
\item[]  if, for every ,  
\end{itemize}
When the relation  does not hold between two terms , we write  and say that  and  are {\em -dissimilar}. When   we simply say that  and  are {\em similar} or {\em dissimilar} and write  or , respectively.

We say that a context  {\bf -distinguishes}  and , where , if  and 
\end{definition}
Note that only the contexts  with  are relevant to check whether , because if  then  and , and therefore  Also, if  with  then it must be the case that , and then  for all  and  because 

The relation of -similarity is obviously reflexive and symmetric, but  not transitive. The following example illustrates this fact.
\begin{example}
Let , , ,   , , , and
  is a nonempty subterm closed subset of , and  is a nonempty subset of  which is -prefix closed with respect to . We have , 
 because  and  and
 because   and 
However,  because  and , but \qed
\end{example}
Still, -similarity has a useful property, captured in the following lemma.
\begin{lemma}
\label{lema1}
Let  be an observation table. If  such that , then  whenever  and 
\end{lemma}

In addition, we will also assume given a total order  on the alphabet , and the following total orders induced by  on  and 
\begin{definition}
\label{def1}
The total order  on  induced by a total order  on  is defined as follows:  if either (a) , or (b)  and
\begin{enumerate}
\item  and , or else
\item  and , or else
\item ,  and there exists  such that  and  for all , or else
\item  and , , and  for .
\end{enumerate}
The total order  on  induced by a total order  on  is defined as follows:
 if either (a) , or (b)  and  where  are interpreted as terms over the signature with  extended with the constant  such that  for all 
\end{definition}
\begin{definition}[representative]
Let  be an observation table and . We say  \emph{has a representative} in  if  If so, the \emph{representative} of   is 
\end{definition}
We will show later that the construction an observation table  is instrumental to the construction of a cover tree automaton,  and the states of the automaton correspond to representatives of the elements from .
Note that, if  is an observation table and  has  then  and  for all . Then  because  for all . Thus  has a representative in , and  For this reason, only the rows for elements  are kept in an observation table. 
\subsection{Consistency and closedness}
\comment{
Using this definition, we choose the representative  of  in a closed observation table  to be the minimum element of the set  Note that  when  is closed,  thus  is well defined for all . Also, if  has  then  for all , and thus  is the minimum element of . For this reason, we we do not need to keep a row for elements   in the observation table because  is known a priori.
}

The   consistency and closedness of an observation table are defined as follows.
\begin{definition}[Consistency]
An observation table  is consistent if, for every , , and , the following implication holds:
If  then . 
\end{definition}
The following lemma captures a useful property of consistent observation tables.
\begin{lemma}
\label{lele}
Let  be a consistent observation table. Let , , and  such that, for all , either 
, or 
,  and ,
and ,  Then 
\end{lemma}

\begin{definition}[Closedness]
An observation table  is closed if, for all , there exists  with  such that 
\end{definition}
The next five lemmata capture  important properties of closed observation tables:
\begin{lemma}
\label{lema2}
If  is closed then every  has a representative, and .
\end{lemma}
\begin{lemma}
\label{lema4}
If  is closed, , and  then  
\end{lemma}
\begin{lemma}
\label{lema5}
If   is closed and , then 
\end{lemma}
\begin{proof}
Let  Then  and  By Lemma~\ref{lema4}, 
\qed
\end{proof}
\begin{lemma}
\label{lema6}
If  is closed, then for every  and , there exists  such that .
\end{lemma}

\begin{lemma}
\label{lem6}
Let  be closed, , , and .  If  then 
\end{lemma}
\subsection*{The automaton }
Like  , our algorithm relies on the construction of a consistent and closed observation table of the unknown context-free grammar. The table is used to build an automaton which, in the end, turns out to be a minimal DCTA for the structural descriptions of the unknown grammar.
\begin{definition}
Suppose  is a closed and consistent observation table. The automaton corresponding to this table, denoted by , is the DFTA  where
, , and  is uniquely defined by
 for all .
\end{definition}
The transition function  is well defined because, for all  and  from , 
, thus  and  for some , by Lemma \ref{lema6}. Hence, . 
Also, the set  can be read off directly from the observation table because 
 (since  is -prefix closed), thus  for all ,
and we can read off from the observation table all  with 
\vskip .5em
In the rest of this subsection we assume  that  is  closed and consistent, and   is the transition function of the corresponding DFTA 
\begin{lemma}
\label{lmm}
 and  for every .
\end{lemma}

\begin{corollary}
\label{cor1}
 for all 
\end{corollary}
\begin{proof}
By Lemma \ref{lmm},  Since both  and  belong to the set of representatives ,   by Lemma \ref{lema4}.\qed
\end{proof}
The following theorem shows that the DFTA of a closed and consistent observation table is consistent with the function  on terms with depth at most .
\begin{theorem}
\label{thm1}
Let  be a closed and consistent observation table. For every  and  such that  we have  if and only if 
\end{theorem}

\begin{theorem}
\label{oops}
Let  be a closed and consistent observation table, and  be the number of states of  If  is any other DFTA with  or fewer states, that is consistent with  on terms with depth at most , then  has exactly  states and . 
\end{theorem}

\begin{corollary}
\label{cor2}
Let  be the automaton corresponding to a closed and consistent observation table  of the skeletons of a CFG  of an unknown language , and  be its number of states. Let  be the number of states of a minimal DCTA of  with respect to . If  then  and  is a minimal DCTA of  with respect to .
\end{corollary}
\subsection*{The  algorithm}
The algorithm  extends the observation table  whenever one of the following situations occurs: the table is not consistent, the table is not closed, or the table is both consistent and closed but the resulting automaton   is not a cover tree automaton of  with respect to .

The pseudocode of the algorithm is shown below. 
\begin{tabbing}
ask if  is a cover CFG of  w.r.t. \\
{\bf if} answer is {\em yes} {\bf then} halt and output the CFG \\
{\bf if}\=\ answer is {\em no} with counterexample  {\bf then}\\
\>set  is a subterm of  with depth at least  and \\
\>construct \=the table  using structural membership queries\\
\>{\bf rep}\={\bf{eat}}\\
\>\ \ {\bf repeat}\\
\>\>/* check consistency */\\
\>\>{\bf for}\=\ every  in increasing order of  {\bf do}\\
\>\>\>search \=for  with  and \\
\>\>\>\>such that \=,\\
\>\>\>\>\> where ,\\
\>\>\>\>\>and \\
\>\>\>{\bf if} \=found {\bf then}\\
\>\>\>\>add  to \\
\>\>\>\>extend  to  using structural membership queries\\
\>\>/* check closedness */\\
\>\>\\
\>\>{\bf repeat} for every , in increasing order of \\
\>\>\>search for  such that \= for all  \\
\>\>\>{\bf if} \=found {\bf then}\\
\>\>\>\>add  to \\
\>\>\>\>extend  to  using structural membership queries\\
\>\>\>\>\\
\>\>{\bf until}  or all elements of  have been processed\\
\>\ \ {\bf until} \\
\>\ \ /*  is now closed and consistent */ \\
\>\ \ make the query whether  is a cover CFG of  w.r.t. \\
\>\ \ {\bf if}\=\ the reply is {\em no} with a counterexample  {\bf then}\\
\>\>add to  \=all subterms of , including , with depth at least 1, \\
\>\>\>in the increasing order given by \\
\>\>extend  to  using structural membership queries\\
\>{\bf until} \=the reply is {\em yes} to the query if  is a cover CFG of  w.r.t. \\
\>halt and output .
\end{tabbing}


Consistency is checked by searching for  and  such that  will -distinguish  two terms   not distinguished by any other context   with  Whenever such a pair of contexts  is found,   is added to . Note that 
 because only such contexts can distinguish terms from , and the addition of  to  yields a -prefix closed subset of .


The search of such a pair of contexts  is repeated in increasing order of the hole depth of , until all contexts from  have been processed. Therefore, any context  with  and  that was added to  because of a failed consistency check will be processed itself in the same {\bf for} loop.

The algorithm checks closedness by searching for  and  such that  for all  for which  The search is performed in increasing order of the depth of . If  and  are found,   is added to the  component of the observation table, and the algorithm checks again  consistency.  Note that adding  to  yields a subterm closed subset of . Also, closedness checks are performed only on consistent observation tables.

When the observation table is both consistent and closed, the corresponding DFTA is constructed and it is checked whether the language accepted by the constructed automaton coincides with the set of skeletal descriptions of the unknown context-free grammar  (this is called a {\em structural equivalence query}). If this query fails, a counterexample from  is produced,  the component  of the observation table is expanded to include  and all its subterms with depth at least 1, and the consistency and closedness checks are performed once more. At the end of this step, the component  of the observation table is subterm closed, and  is unchanged, thus -prefix closed.

Thus, at any time during the execution of algorithm , the defining properties of an observation table are preserved:
the component  is a subterm closed subset of , and
the component  is a -prefix closed subset of .


\section{Algorithm analysis}
\label{sect5}
We notice that the number of states of the DFTA constructed by algorithm  will always increase between two successive structural equivalence queries. When this number of states reaches the number of states of a minimal DCTA of , the constructed DFTA is actually a minimal DCTA of  (Corollary \ref{cor2}) and the algorithm terminates.

From now on we assume implicitly that  is the number of states of a minimal DCTA of  with respect to , and that  is the observation table  before execution step  of the algorithm. 
By Corollary \ref{cor2},  will always have between 1 and  elements. Note that the representative of an element  in  is a notion that depends on the observation table  Therefore, we will use the notation  to refer to the representative of  in the observation table  With this notation, 

Note that the execution of algorithm  is a sequence of steps characterised by the detection of three kinds of failure:  closedness,  consistency, and structural equivalence query. The -th execution step is
\begin{enumerate}
\item a failed closedness check when the algorithm finds  and  such that  for all  with ,
\item a failed consistency check when the algorithm finds  with ,  with , and , such that   ,  where , and ,
\item a failed structural equivalence query when the observation table  is closed and consistent, and the learning algorithm receives from the teacher a counterexample  as answer to the structural equivalence query with the grammar 
\end{enumerate}
In the following subsections we perform a complexity analysis of the algorithm by identifying upper bound estimates to the computations due to failed  consistency checks, failed closeness checks, and failed structural equivalence queries. 

\comment{
First, we define inductively an enumeration ordering of the elements of .
If the enumeration of the elements  of  is   then the enumeration of the elements of  is defined as follows:
\begin{enumerate}
\item If the -th execution step is a failed closedness check which introduces a term  from  into  (that is, ) then:
\begin{enumerate}
\item If there is no  with  then  has  elements, and the enumeration of its elements is 
 \item Otherwise, there is an  such that  and  Note that there is no  such that  because Lemma \ref{lema1} would imply the contradiction  In this case,  has  elements, and the ordering of its elements is 
 \end{enumerate}
 \item If the -th execution step is a failed consistency check which introduces a context  into  then  and, in the  table ,  for all . Therefore  where  is the set of representatives newly created by the introduction of context  into  
In this case, the enumeration of the elements of  is  where 
 is the enumeration of the elements of   given by .
 \item If the -th execution step is a failed structural membership query with a counterexample  then  where  is the set of subterms of , including . Let , where . Then we can trace the computation of the observation table  from the observation table  via the computation of the sequence of  intermediary observation tables  with  for all . Note that  is a closed observation table, and . Let  in the table  for all . Let , and suppose the enumeration of elements of  is .
 For the computation of   from  we distinguish the following situations: 
 \begin{enumerate}
 \item If there is no  with  in  then  has  elements, and the enumeration of its elements is  This situation is similar to the situation 1.(a) for a failed closedness check.
 \item If there is  with  in  and  then , , and  has the same enumeration of elements as .
\item If there is  with   in  and  then  and there is no   with  in  because this would imply  by Lemma \ref{lema1}, and thus the contradiction  by Lemma \ref{lema4}.  In this situation,  has  elements, and the enumeration of its elements is .
This situation is similar to the situation 1.(b) for a failed closedness check.
 \end{enumerate}
\end{enumerate}
From now on we denote by  the -th element of  in this enumeration ordering. 
A useful property of this definition is indicated in the following lemma.
\begin{lemma}
For any  , if  is a subterm of  and , then the representative of  in the observation table  is  for some .
\end{lemma}
\begin{proof}
This property is obviously preserved by the execution steps  corresponding to cases 1.(a), 1, 3.(a), and 3.(b). In cases 1.(b) and 3.(c), the execution step replaces a term  with a new term  after all proper subterms of  are guaranteed to have representatives in the  component of the observation table.
\todo
\qed
\end{proof}
}
\subsection{Failed closedness checks}
We recall that the -th execution step is a failed closedness check  if the algorithm finds a context  and a term  such that  for all  with . 
We will show that the number of failed closedness checks performed by  algorithm  has an upper bound which is a polynomial in . To prove this fact, we will rely on the following auxiliary notions:
\begin{itemize}
\item For , we define  if either  or  and there exists  such that  but  (that is,  became a representative in the observation table before ).
\item To every set of representatives  with 
we associate the tuple  where  
 if  and  if 
\item We consider the following  partial order on :  iff there exists  such that  and  for all .
\item We denote by  the -th component of   in the order given by . 
\end{itemize}
\comment{
\begin{lemma}
\label{lmng}
Let  such that 
 and  Then
 Then .
\end{lemma}
\begin{proof}
Obvious.\qed
\end{proof}
\comment
It is easy to see that the following inequalities hold for all execution steps : 

}

\begin{lemma}
\label{lema8}
Suppose  has been introduced in  as a result of a failed closedness check. There exists   such that  and for every prefix  of  different from , .
\end{lemma}

\begin{corollary}
\label{cor3}
Whenever the -th execution step is a failed closedness check, the term introduced in  is in  and its depth is at most , where  is the position in  of the newly introduced element  according to  ordering 
\end{corollary}

\begin{corollary}
\label{mmon}
 for all  which was introduced in the table by a failed closedness check.
\end{corollary}
\begin{proof}
 by Cor. \ref{cor3}, and  because  for all . Thus  
\end{proof}
\begin{lemma}
\label{cor4}
Let  be the position of the element  introduced in  by a failed closedness check. Then 
 and 
\end{lemma}

\begin{theorem}
\label{tyury}
The number of failed closedness checks performed during the entire run of  is at most .
\end{theorem}
\subsection{Failed consistency checks}
The -th execution step is a failed consistency check if the algorithm finds   with ,  with , and , such that   ,  where , and . In this case, the context  is newly introduced in the component  of the observation table .

We will show that the number of failed consistency checks performed by the learning algorithm  has an upper bound which is a polynomial in . 
 To prove this fact, we  rely on the following auxiliary notions:
\begin{itemize}
\item For , we define  if either  or  and there exists  such that  but  (that is,  became an experiment in the observation table before ).
\item We define 
\ells_1s_2
for every  such that .
\item A nonempty subset  of  induces a partition of a subset  of  into equivalence classes  if the following conditions are satisfied:
\begin{enumerate}
\item  and  whenever ,
\item Whenever ,  and , there exists  that -distinguishes  and .
\item Whenever  for some , there is no  that -distinguishes  and .
\end{enumerate}
\end{itemize}
Let . 
Since  is not an equivalence, not every subset of  induces a partition of  into equivalence classes. However, the next lemma shows that   induces a partition of  into at least  classes.
\begin{theorem}
\label{conscheck}
If  with  then, for every ,   induces a partition of  into at least  classes.
\end{theorem}
 \begin{corollary}
 \label{cor5}
 For any ,  has at most  elements.
 \end{corollary}
We will compute an upper bound on the number of failed consistency checks by examining the evolution of  during the execution of   Initially,  
 \begin{lemma}
\label{tmy4}
At any time during the execution of the algorithm, if  has  elements, then the hole depth of any context in  is less than or equal to .
\end{lemma}


Let  before some execution step  of the algorithm , where . Then  by Cor. \ref{cor5}. We associate to every such  the -tuple , where, for every ,  is defined as follows:\par
- If  has at least  elements then, if  is the minimum integer such that  partitions  into at least  classes then . Since every  partitions  into at least  classes (by Lemma \ref{conscheck}) and we assume that  partitions  into  classes, 
we conclude that such  exists.\par
- otherwise .\vskip .4em
For   we denote the -th component of  by 
Note that, for all , 
 by Theorem \ref{tmy4},  and , hence . Therefore, we can always distinguish the components  of  that correspond to the defining case (1) from those 
in case (2).
\begin{lemma}
\label{lups}
 whenever  and 
\end{lemma}
\begin{theorem}
\label{inconsistentthm}
If  has at least 2 elements then the number of failed consistency checks over the entire run of  is at most 
\end{theorem}

\subsection{Failed structural equivalence queries} 
Every failed structural equivalence query yields a counterexample which increases the number of representatives in . Thus \begin{theorem}
\label{failstruct}
The number of failed structural equivalence queries is at most .
\end{theorem}

\subsection{Space and time complexity}
We are ready now to express the space and time complexity of  in terms of the following parameters:\par
-  = the number of states of a minimal DFCA for the language of structural descriptions of the unknown grammar with respect to ,\par
-  = the maximum size of a counterexample returned by a failed structural equivalence query,\par
-  = the cardinality of the alphabet  of terminal symbols, and\par
-  = the maximum rank (or arity) of the symbol  \vskip .3em
First, we determine the space needed by the observation table. The number of elements in  is initially 0 (i.e., ) and is increased either by a failed closedness check or by a failed structural membership query. By Theorem \ref{tyury}, the number of failed closedness checks is at most , and each of them adds one element to . By Theorem  \ref{failstruct}, the number of failed structural equivalence queries is at most . A failed structural equivalence query which produces a counterexample  with , adds at most  terms to . Thus,  and ,  therefore  and  Thus  has  elements.
By Theorem \ref{inconsistentthm}, there may be at most  failed consistency checks, and each of them adds a context to . Thus  has  elements and  has  elements. By Lemma \ref{lups},  for all . We also know that, if , then  if it originates from a failed structural equivalence query, and  if it originates from a failed closedness check (by Cor. \ref{mmon}). Therefore  for all , and thus  for all  and  for all  Since the number of positions of such a term  is , we conclude that the total space occupied by an observation table at any time is 

Next, we examine the time complexity of the algorithm by looking at the time needed to perform each kind of operation. 

Since the consistency checks of the observation table are performed in  a {\bf for} loop which checks the result produced by  (where ) in increasing order of , the result produced by  can be reused in checking  and so the corresponding elements in the rows of  and  are compared only once. Thus, the total time needed to check if the observation table is consistent involves at most , comparisons.
As  has   elements, a consistency check of the  table takes  time.
As there are at most  consistency checks, the total time needed to check if the  table is consistent is 

Checking if the observation table is closed takes at most  time, which is 


Extending an observation table  with a new element in  requires the addition of  contexts to , thus the addition of at most  new rows for the new elements of  in the observation table  This extension requires 
at most
 membership queries. The number of elements added to  as a result of a failed structural equivalence query is at most  As there will be at most  failed structural equivalence queries and at most  failed closedness checks, the maximum number of elements added to  is  Thus the total time spent on inserting new elements in the -component of the observation table is . 
 Adding a context to  requires at most  membership  queries. These additions are performed only by failed consistency checks, and there are at most  of them. Thus, the total time spent to insert new contexts in the -component of the observation table is 
We conclude that the total time spent to add elements to the components  and  of the observation table is , which is polynomial.
 
The identification of the representative  for every  can be done by performing  comparisons.

Thus, all DFCAs  corresponding to consistent and closed observation tables  can be constructed in time  polynomial in  and . Since the algorithm encounters at most  consistent and closed observation tables, the total running time of the algorithm is polynomial in  and .
\section{Conclusions and acknowledgments}
\label{sect6}
We have presented an algorithm, called , for learning cover context-free grammars from structural descriptions of languages of interest.  is an adaptation of Sakakibara's algorithm  for learning context-free grammars from structural descriptions, by following a methodology similar to the design of Ipate's algorithm  as a nontrivial adaptation of Angluin's algorithm . Like , our algorithm synthesizes  a minimal deterministic cover automaton consistent with an observation table maintained via a learning protocol based on what is called in the literature a ``minimally adequate teacher'' \cite{Angluin:87}. And again, like algorithm , our algorithm is guaranteed to synthesize the desired automaton in time  polynomial in  and , where  is its number of states and  is the maximum size of a counterexample to a  structural equivalence query. As the size of a minimal finite cover automaton is usually much smaller than that of a minimal automaton that accepts that language, the algorithm  is a  better choice than algorithm  for applications where we are interested only in an accurate characterisation of the structural descriptions with depth at most .

This work has been supported by CNCS IDEI Grant PN-II-ID-PCE-2011-3-0981 ``Structure and computational difficulty in combinatorial
optimization: an interdisciplinary approach.''

\bibliographystyle{abbrv}
\bibliography{bibliography}
\newpage
\section*{Appendix}
\section{Pseudocode of algorithm }
\label{LA}
\begin{tabbing}
Set  and \\
let \\
check if  is structurally equivalent with \\
{\bf if} answer is {\tt yes} {\bf then} halt and output \\
{\bf if}\=\ answer is {\tt no} with counterexample  {\bf then}\\
\>add  and all its subterms with depth at least 1 to \\
\>construct the observation table  using structural membership queries\\
\>{\bf rep}\={\bf{eat}}\\
\>\ \ {\bf while}  is not closed or not consistent\\
\>\>{\bf if}\=\  is not consistent {\bf then}\\
\>\>\>fi\=nd , and  such that\\
\>\>\>\> and \\
\>\>\>add  to \\
\>\>\>extend  to  using structural membership queries\\
\>\>{\bf if}  is not closed {\bf then}\\
\>\>\>find  such that  for all \\
\>\>\>add  to \\
\>\>\>extend  to  using structural membership queries\\
\>\ \ /*  is now closed and consistent */ \\
\>\ \ let\=\ \\
\>\ \ make the structural equivalence query between  and \\
\>\ \ {\bf if}\=\ the reply is {\tt no} with a counterexample  {\bf then}\\
\>\>add  and all its subterms with depth at least 1 to \\
\>\>extend  to  using structural membership queries\\
\>{\bf until} the reply is {\tt yes} to the structural equivalence query between  and \\
\>halt and output .
\end{tabbing}

\section{Proof of Lemma \ref{lema1}}
Suppose   and  By definition of , we have 
\begin{itemize}
\item[]  for all , and
\item[]  for all .
\end{itemize}
Let  Since , it follows that for every  we also have  and . Thus  for all . Hence 
\section{Proof of Lemma \ref{lele}}
Let  and . 
If  then  and the result follows from the reflexivity of . 
If , let , and  for .
For all  we have

because the observation table  is consistent. Thus , \ldots, , and  Repeated applications of Lemma \ref{lema1} yield  But  and , thus 
\section{Proof of Lemma \ref{lema2}}
If  then  has a representative since  and we can take . Then , which implies  If  then, since the observation table is closed, there exists  with  and   and  imply , hence . Thus  because  
\section{Proof of Lemma \ref{lema4}}
Suppose  and  for some . By Lemma~\ref{lema2},  and  
Since  and , Lemma~\ref{lema1} implies , thus  and . By a similar argument, we learn that . From  and  we conclude that  
\section{Proof of Lemma \ref{lema6}}
Let  and . The fact that  is closed implies , thus  and therefore  We can choose  for which , by Lemma \ref{lema5}. 
\section{Proof of Lemma \ref{lem6}}
We provide a proof by contradiction. Assume 
Since  and  is closed, ,   (by Lemma \ref{lema2}),  , and . Thus  by Lemma~\ref{lema1}.
Since , we have  by Lemma \ref{lema4}. Thus , which yields a contradicton. 

\section{Proof of Lemma \ref{lmm}}
By induction on the depth of . If  then  and  by Lemma \ref{lema2}. 

If  then  with , and  where  for  Let  Then, by induction hypothesis for all ,  and . 
Thus

Hence  follows from  

To prove  , we 
\comment{reason as follows. Suppose , and 
let , and  for . 
For all  we have

because the observation table  is consistent. Also,  whenever  because, by induction hypothesis,  for all . Hence  by repeated applications of Lemma~\ref{lema1}. }
notice that  follows from Lemma \ref{lele}.
Thus

\section{Proof of Theorem \ref{thm1}}
Let  and  such that . We proceed by induction on the hole depth of . 
If  then  and  has   By Lemma \ref{lmm},  and  Thus, since  and ,  if and only if 
By definition of ,  if and only if . Hence  if and only if 

If  then  implies  and  Since  is -prefix closed, there exist  and  such that  Let  Then  by Lemma \ref{lmm}, thus , and we learn from the induction hypothesis for  that  if and only if  Since 

we have 
Therefore, it suffices to show that  if and only if . By Lemma \ref{lmm},  and , thus 
Hence,  since  and ,   if and only if .  
\section{Proof of Theorem~\ref{oops}}
Let  and  defined by  for all . We show that  is injective. If  such that  then  for some . Since  is consistent with   , exactly one of  and  is in . Hence  
Since  is injective and  has at most the same number of states as ,  is bijective. Thus 


Next, we show that  By Theorem \ref{thm1},  if and only if  By Corollary \ref{cor1},  for all . Thus  Similarly, since  is consistent with , for every ,  if and only if  By definition,  Thus,  and 

We prove by induction on the depth of  that, if  and  then the following statements hold:
\begin{enumerate}
\item ,
\item  ,
\item if , then .
\end{enumerate}
In the base case, 
and . By Lemma \ref{lema2},  and , thus  can only be .  implies  for all . Since  is consistent with  on , this implies   if and only if  Therefore  . From  , , and , we learn by Lemma \ref{lema1} that   
Then  by Lemma \ref{lema4}, because  and . Thus  In this case,  and statement 3 obviously holds because 
is reflexive.

In the induction step, we assume that all three statements hold for all terms  with . Let  with  Then  with  for  Let  and ,  and  such that ,  , and ,  for all .

Let  where  if  and  otherwise. Then  and , thus  and  by Lemma \ref{lema2}. Also  because  , and
\begin{itemize}
\item  for all , by induction hypothesis, 
\item  for all , hence  for all .
\end{itemize}
Thus  follows from   and 

To show , we reason as follows. . Since  for all , and  for all , we learn that  where  with  if  and  if .  Note that  and  for all . Thus  if and only if  because  is consistent with  on . Therefore , and since  with  and  for any , we can apply Lemma~\ref{lem6} to learn that 
Also
\begin{itemize}
\item for all ,  by induction hypothesis, and
\item for all , , thus ,
\end{itemize}
therefore  From  and  we learn 

Let .
We prove  by contradiction. 
If   there exists  such that  Then  and , thus  and  . 
Also,  and , thus  and  Thus  On the other hand, by induction hypothesis,  for all , where 
Let's assume ,  , and  for all  
Then  and  for all , because the observation table is consistent. Therefore  whenever  and  . Since , we have
, thus  for all .
 Note that

which yields a contradiction. 


Finally, we prove that . Let  and  such that  and  Then  where  Since  and ,    is consistent with  on  and , thus  if and only if   is also consistent with  on , thus  if and only if  Since , we have  if and only if  Thus  if and only if . That is,

\section{Proof of Corollary \ref{cor2}}
Let  be a minimal DCTA of  with respect to . Then  is consistent with   on  and has  states. Since , by Theorem~\ref{oops},  and  Thus  is a minimal DCTA of   with respect to . 

\section{Proof of Lemma \ref{lema8}}
We prove by induction on  that for every  there exists a sequence of positions  from  such that, for all , the following statements hold:
\begin{enumerate}
\item[](L1):  and ,  
\item[](L2): .
\end{enumerate}

For  we reason as follows: Since  has been introduced in  as a result of a failed closedness check,  for all  with  Then  becomes a new element of the set ,  and, if we choose , the sequence of positions  fulfils  requirements  (L1) and (L2). 

For the inductive step, assume the condition holds for , that is, there exists a sequence of positions 
 from  which fulfils requirements (L1) and (L2) for all . We show that this sequence can be extended with a position  such that  requirements (L1) and (L2) hold for . Let  Then  and, since  and , we have . Therefore, we can write   such that 


Assume, by contradiction, that no such position  exists. Let  for all , and  where  if  and  otherwise. Then ,
  and  for all . It follows that , and
 in , by Lemma \ref{lele}. We distinguish two cases:
\begin{enumerate}
\item . Then , which is a contradiction.
\item . Then  for all  with , because:
\begin{itemize}
\item[] If there exists  with  such that , then  (by Lemma \ref{lema1}) and , which contradicts .
\end{itemize}
As ,  would be introduced in  instead of  as the result of a failed closedness check. This also provides a contradiction.
\end{enumerate}
Thus, there exists a sequence of positions  from  such that requirements (L1) and (L2) hold for all . 
It follows that the statement of this lemma holds for 
\section{Proof of Lemma \ref{cor4}}
Let  be the representative newly introduced  in  at position  (that is, ), , and 
 Then  and we distinguish two situations.
\begin{enumerate}
\item If  replaces a representative with depth  at position  in  then ,  and . Thus  and
\begin{itemize}
\item if  then , 
\item , 
\item if  then , 
\item if  then .
\end{itemize}
Hence 
\item Otherwise,  is newly introduced at position  in  and all elements of  are preserved in . If  then
\begin{itemize}
\item if  then , 
\item , 
\item if  then ,
\item 
\end{itemize}
which, again, implies   \qed
\end{enumerate}
\section{Proof of Theorem \ref{tyury}}
By Lemma \ref{cor4},  and  whenever  is the state introduced in  by a failed closedness check. It is also easy to see that  always holds. 
Since  and the minimum possible value of  is ,  the maximum number of failed closedness checks in any sequence 
 is at most 


\section{Proof of Corollary \ref{cor3}}
If  is introduced in  by a failed closedness check then  for all  with  Therefore,  Furthermore, from the proof of the previous lemma we know there exists a sequence  of positions from  with  for all  Since  for all  and , we have

 we conclude that, if , then . 
\section{Proof of Theorem \ref{conscheck}}
First, we prove by induction on , , that  induces a partition of . 
In the base case, , , and the statement of the lemma is obviously true.
In the induction step, we assume that  induces a partition  \ldots,  of .  Let , and . As all pairs of elements in  are -distinguished by some element of  and  for all , the depth of any term contained in  is at most  Thus  for all , and therefore  induces a partition of .

Let  be the order in which the contexts were added to  by failed consistency checks. Because every  -distinguishes some elements of  that were not -distinguished by any of  with , we conclude that  induces a partition of  into at least  classes. 

\section{Proof of Corollary  \ref{cor5}}
 Let  be the number of elements of , and  be the number of classes in the partition of  induced by . By Lemma \ref{conscheck}, . Since ,  we conclude that .
\section{Proof of Lemma \ref{tmy4}}
The proof is by induction on the execution step  of the algorithm.

In the base case, assume  has  elements. Then  and 
In the induction case, we assume that the result holds at some step  in the execution of the algorithm, and we prove that the result holds at the next step  

If step  is a failed closedness check or a failed structural equivalence query, then , and  has at least the same number of elements as  Therefore, the result will hold at step 

Otherwise, the execution step  is a failed consistency check. Let  , and  be the values for which this failed consistency check is performed. Then . We distinguish two cases:
\begin{enumerate}
\item  and  are  -distinguished by some , but   Then   for all . Since   by induction hypothesis, and , we learn that   for all .
\item  and  are not -distinguished by any element of . If , the result will hold at step . Otherwise, by induction hypothesis  and thus  Let  Since  at step , at least one of  and  is not contained in , thus  will have at least  elements. As  -distinguishes   and  and ,  and  for every  Thus, both  and  will induce a partition of . As  at step , but  and  are -distinguished by  at step ,  will partition  into at least  classes. Thus, . Hence  for all  
 \end{enumerate}
\section{Proof of Lemma \ref{lups}}
Suppose  is the first execution step when  This means that  is the first execution step from where on  we distinguish at least  representatives in the observation table. Therefore, at the previous step ,  and so, by Lemma \ref{tmy4},  for all  Thus,  for all , and in particular  Since it it obvious that  whenever , we conclude that  whenever  and 
\section{Proof of Theorem \ref{inconsistentthm}}
It is easy to see that   holds for every execution step . Moreover, if the -th execution step is a failed consistency check then a  context  is newly added to  in order to produce . The context  will -distinguish two elements  that were not -distinguished before or had been -distinguished by some  with  Since  and ,  will -distinguish two elements of  that were not -distinguished before or were -distinguished by a context with bigger hole-depth. Therefore  if  is a failed  consistency check.

Note that  and the minimum possible value of  is .  Also, by Lemma \ref{lups},  whenever  for . Therefore, any run of the algorithm performs at most 
failed consistency checks. 
\section{Proof of Theorem \ref{failstruct}}
Algorithm  performs a failed structural equivalence query when the observation table  is closed, consistent, and has less than  states (by Corollary \ref{cor2} of Theorem \ref{thm1}). Suppose the algorithm performed a 
 failed structural equivalence query for  which rendered the counterexample . After extending the -component of observation table  with all subterms of  that were not yet there, the algorithm constructs a new observation table  which is closed and consistent. Since , , and  in the table  differs from  in the table , the automata  and  are not equivalent with respect to  (that is, ). Therefore, by Theorem \ref{oops}, the automaton  must have at least one more state than 
. Since the number of states is increased by every failed structural equivalence query and can not exceed , the number of failed structural equivalence queries performed by algorithm  is at most . 
\end{document}