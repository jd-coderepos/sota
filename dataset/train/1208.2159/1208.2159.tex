\documentclass{LMCS}

\def\doi{8(3:27)2012}
\lmcsheading {\doi}
{1--15}
{}
{}
{Dec.~10, 2010}
{Sep.~29, 2012}
{}
 
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage{microtype}
\usepackage{enumerate,hyperref}

\usetikzlibrary{snakes}



\newcommand{\step}[1]{[#1\rangle}
\newcommand{\nat}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\then}{\Longrightarrow}
\newcommand{\parikh}{\wp}
\newcommand{\I}{C} \newcommand{\C}{{\ensuremath \Gamma}} \newcommand{\ord}{\ensuremath{\Omega}}

\def\hascolor#1#2{#2} \hascolor{
\tikzstyle{place}=[circle,draw=black!50,fill=black!10,thick,inner sep=0pt,minimum size=6mm]
\tikzstyle{oplace}=[circle,draw=green!50,fill=green!10,thick,inner sep=0pt,minimum size=6mm]
\tikzstyle{iplace}=[circle,draw=red!50,fill=red!10,thick,inner sep=0pt,minimum size=6mm]
\tikzstyle{transition}=[rectangle,draw=black!50,fill=black!20,thick,inner sep=0pt,minimum size=6mm]
\tikzstyle{token}=[circle,draw=black,fill=black,inner sep=0pt,minimum size=1mm]
\tikzstyle{arrow}=[-latex]
\tikzstyle{myred}=[red]
\tikzstyle{mygreen}=[green]
}{
\usetikzlibrary{patterns}
\tikzstyle{place}=[circle,draw=black,thick,inner sep=0pt,minimum size=6mm]
\tikzstyle{gplace}=[circle,draw=black,fill=black!40,thick,inner sep=0pt,minimum size=6mm]
\tikzstyle{oplace}=[circle,draw=black,pattern=north west lines,pattern color=black!30,thick,inner sep=0pt,minimum size=6mm]
\tikzstyle{iplace}=[circle,draw=black,pattern=north east lines,pattern color=black!30,thick,inner sep=0pt,minimum size=6mm]
\tikzstyle{transition}=[rectangle,draw=black,thick,inner sep=0pt,minimum size=6mm]
\tikzstyle{gtransition}=[rectangle,draw=black,fill=black!40,thick,inner sep=0pt,minimum size=6mm]
\tikzstyle{otransition}=[rectangle,draw=black,pattern=north west lines,pattern color=black!30,thick,inner sep=0pt,minimum size=6mm]
\tikzstyle{itransition}=[rectangle,draw=black,pattern=north east lines,pattern color=black!30,thick,inner sep=0pt,minimum size=6mm]
\tikzstyle{token}=[circle,draw=black,fill=black,inner sep=0pt,minimum size=1mm]
\tikzstyle{arrow}=[-latex]
\tikzstyle{myred}=[black!60]
\tikzstyle{mygreen}=[black!40]
}

\begin{document}

\title[Applying CEGAR to the Petri Net State Equation]{Applying CEGAR to the Petri Net State Equation}

\author[H.~Wimmel]{Harro Wimmel} 
\author[K.~Wolf]{Karsten Wolf}

\address{Universit\"at Rostock, Institut f\"ur Informatik}
\email{\{harro.wimmel, karsten.wolf\}@uni-rostock.de}


\begin{abstract}
We propose a reachability verification technique that combines the {\em 
Petri net state equation} (a linear algebraic
overapproximation of the set of reachable states) with the concept of
{\em counterexample guided abstraction refinement}. In essence, we 
replace the search through the set of reachable
states by a search through the space of solutions of the state equation. 
We demonstrate the excellent performance of the
technique on several real-world examples. The technique is particularly 
useful in those cases where the reachability query
yields a negative result: While state space based techniques need to 
fully expand the state space in this case, our
technique often terminates promptly. In addition, we can derive some 
diagnostic information in case of unreachability
while state space methods can only provide witness paths in the case of 
reachability.
\end{abstract}

\keywords{
Petri Net, Reachability Problem, Integer Programming, CEGAR, Structure
Analysis, Partial Order Reduction.}
\subjclass{F.2.2, I.6.4}

\maketitle
\enlargethispage*{2\baselineskip}

\section{Introduction}

Reachability is {\em the} fundamental verification problem.
For place/transition Petri nets (which may have infinitely many states), it is one of the hardest decision problems 
known among the naturally emerging yet decidable problems
in computer science. General solutions have been found by
Mayr~\cite{mayr84} and Kosaraju~\cite{kosaraju82} with later simplifications made by Lambert~\cite{lambert92}, but there are
complexity issues. All these approaches use coverability graphs which can have a non-primitive-recursive
size with respect to the corresponding Petri net. A new approach by Leroux~\cite{leroux09} not using
such graphs gives some hope, but a concrete upper bound for the worst case complexity so far
eludes us. In a sense even worse, Lipton~\cite{lipton76} has shown that the problem is {\sf EXPSPACE}-hard,
so any try at programming a tool efficiently solving this problem to the full extent must surely fail.

Nevertheless, efficient tools exist that are applicable to a considerable number of problem instances.
Model checkers, symbolic~\cite{cms06} or with partial order reduction~\cite{Wolf_2007_icatpn}, have been used
successfully to solve quite large reachability problems. On a positive answer, a model checker can typically generate
a trace, i.e. a firing sequence leading to the final marking. In contrast, negative answers are usually
not accompanied by any diagnostic information. Such information, i.e.\ a counterexample or reasoning
why the problem has a negative solution would require a deep analysis of the structure of the
Petri net. So far, no tools are known that analyze the structure of a net and allow for such
reasoning. 

This paper presents an approach to the reachability problem that combines two existing methods. First,
we employ the {\em state equation} for Petri nets. This is a linear-algebraic overapproximation on the
set of reachable states. Second, we use the concept of {\em counterexample guided abstraction refinement}
(CEGAR) \cite{cegar} for enhancing the expressiveness of the state equation. In essence, we iteratively analyse spurious
solutions of the state equation and add constraints that exclude a solution found to be spurious but do not exclude
any real solution. The approach has several advantages compared to (explicit or symbolic) purely state space based
verification techniques:
\begin{iteMize}{}
\item The search is quite focussed from the beginning as we traverse the solution space of the state equation rather than the set of reachable states;
\item The search is close to breadth-first traversal, so small witness traces are generated;
\item The method may perform well on unreachable problem instances (where state space techniques compute maximum size state spaces);
\item In several unreachable problem instances, some kind of diagnostic information can be provided; 
\item A considerable workload can be shifted to very mature tools for solving linear programming problems.
\end{iteMize}

\noindent In Sect.~\ref{sec2} we give the basic
definitions. Section~\ref{sec3} shows how to use integer programming tools to find candidates
for a solution. Section~\ref{sec4} deals with the analysis of the Petri net structure that
is needed to push the integer programming onto the right path. In Sect.~\ref{sec5} we
use methods of partial order reduction to mold the results of the integer programming
into firing sequences solving the reachability problem. 
In Sect.~\ref{sec6} the overall algorithm is presented and in Sect.~\ref{sec7} we drop
a few hints on how and when diagnostic information for unreachability can be generated.
Finally, Sect.~\ref{sec8} compares the results of an implementation
with another model checker, showing that structure analysis can compete with other approaches.

\section{The Reachability Problem}\label{sec2}

\begin{defi}[Petri net, marking, firing sequence]
A {\em Petri net}  is a tuple  with a set  of {\em places}, a set  of {\em transitions},
where  and , and a mapping : 
defining {\em arcs} between places and transitions.

A {\em marking} or {\em state} of a Petri net is a map : . A place  is said to contain 
{\em tokens} under  if . A transition  is 
{\em enabled under }, , if  for every . A transition 
{\em fires under  and leads to }, , if additionally 
for every .

A word  is a {\em firing sequence under  and leads to }, ,
if either  and , the empty word, or , , 
and : . A firing sequence  under  is enabled under ,
i.e.\ . The {\em Parikh image} of a word  is the vector
:  with , where  is the number of
occurrences of  in . For any firing sequence , we call  {\em realizable}.
\end{defi}

As usual, places are drawn as circles (with tokens as black dots inside them), transitions as rectangles, 
and arcs as arrows with  yielding an arrow pointing from  to . If an arc has a weight of
more than one, i.e. , the number  is written next to the arc. In case ,
we may sometimes draw a line with arrowheads at both ends.

Note, that the Parikh image is not an injective function. Therefore,  can be realizable
even if  is not a firing sequence (provided there is another firing sequence 
with .

\begin{defi}[Reachability problem]
A marking  is {\em reachable} from a marking  in a net  if there is a firing sequence 
 with . A tuple  of a net and two markings is called a
{\em reachability problem} and has the answer ``yes'' if and only if  is reachable from  in .
The set  is a Petri net,  is reachable from  in  is generally 
called {\em the} reachability problem, for which membership is to be decided.
\end{defi}

It is well-known that a necessary condition for a positive
answer to the reachability problem is the feasibility of the {\em state equation}.

\begin{defi}[State equation]
For a Petri net  let , defined by , be the
{\em incidence matrix} of . For two markings  and , the system of linear equations
 is the {\em state equation} of  for  and . A vector  fulfilling
the equation is called a {\em solution}.
\end{defi}

\begin{prop}
For any firing sequence  of a net  leading from  to , i.e. ,
holds , i.e.\ the Parikh vector of  is a solution of the state equation for
, , and . 
\end{prop}
This is just a reformulation of the firing condition for .

\begin{prop}
If the Petri net is acyclic, i.e.~the transitive closure of  is irreflexive then the existence of a
solution of the state equation for , , and  is a sufficient condition for reachability of 
from  in .
\end{prop}
In an acyclic net, minimal transitions (with respect to ) that occur in the support of a solution  of the state equation
must be enabled under . Firing such a transition with resulting marking  leads to a smaller
reachability problem  that has  minus one occurrence of  as a solution. By induction, the whole
solution can be unwound to a firing sequence.

In Petri nets with cycles, it is possible to have a sequence  such that its Parikh image fulfills the state equation but it is
not a firing sequence. 
The easiest example for this occurs in a net  with .
Let  and  be the {\em empty marking}, i.e. one with zero tokens overall, then  is
obviously wrong but  holds since . The effect can occur whenever the Petri net
contains a cycle of transitions. Interestingly, certain cycles of transitions can also help to overcome
this problem, see Fig.~\ref{f.tinv}. Here, we would like to fire a word  from the marking  with
 and , but obviously, this is impossible. If we interleave, however,  with the sequence 
we can fire . The sequence  corresponds to a solution of the state equation for , , and  that is not minimal.
More precisely, we have . At first glance, such a sequence does not change the marking and appears to be neglegible.
However, it has a valuable effect on  in ``lending a token'' to . The transition  provides that token,  takes it back, but meanwhile the token
helps the sequence  to proceed. The process of ``lending tokens'' is not visible in the state equation as the latter overapproximates the
token game of Petri nets to linear algebra. In consequence, it is necessary for our approach to consider non-minimal solutions of the state equation
and in particular solutions to the corresponding homogeneous system of equations.

\begin{figure}[tb]
\centering
\begin{tikzpicture}[scale=0.5]
\node[transition,label=above:] (t) {};
\node[place,label=above:] (s2) [below right of=t,xshift=5mm] {};
\node[transition,label=below:] (tx) [below left of=s2,xshift=-5mm] {};
\node[place,label=above:] (s1) [below left of=t,xshift=-5mm] {};
\node[transition,label=below:] (ux) [below right of=s2,xshift=5mm] {};
\node[transition,label=above:] (u) [above right of=s2,xshift=5mm] {};
\node[place,label=above:] (s3) [below right of=u,xshift=5mm] {};
\draw (s3) node[token] {};
\draw[arrow] (s2) to (t);
\draw[arrow] (t) to (s1);
\draw[arrow] (s1) to (tx);
\draw[arrow] (tx) to (s2);
\draw[arrow] (s2) to (ux);
\draw[arrow] (ux) to (s3);
\draw[arrow] (s3) to (u);
\draw[arrow] (u) to (s2);
\end{tikzpicture}
\hspace*{2cm}
\unitlength1cm
\begin{picture}(3,1.5)(0,-1.3)
\put(0,0){}
\put(0.2,0){}
\put(3.7,0.05){}
\put(0.4,1.0){}
\end{picture}
\caption{\label{f.tinv}The word  cannot fire, but we can borrow a token from the circle , so  can
fire and leads to the same marking as . The incidence matrix of the net is shown on the right}
\end{figure}

\begin{defi}[T-invariant]
Let  be a Petri net and  its incidence matrix. A vector  is called a
{\em -invariant} if . If a T-invariant corresponds to some executable firing sequence, it is called
realizable.
\end{defi}

A realizable -invariant represents a cycle in the state space. Corresponding firing sequences do not change the marking. However, its interleaving with another sequence 
may turn   from unrealizable to realizable. 

Solving the state equation is a
non-negative integer programming problem. From linear algebra we know that the solution space is 
semi-linear.

\begin{cor}[Solution space]
For a given state equation  over a net , there are numbers  and finite sets of vectors 
 (base vectors) and  (period vectors) such that:
\begin{iteMize}{}
\item all  are pairwise incomparable (by standard componentwise comparison for vectors) and thus minimal solutions,
\item  forms a basis for the non-negative solution space  of ,
\item for all solutions  there are  for  and  such that
	,
\item for every solution , all vectors of the set  are solutions as well.
\end{iteMize}
\end{cor}

Note that only linear combinations with nonnegative coefficients are considered in this representation.
In this setting, the number of base vectors as well as the number of period vectors may exponentially depend on the
size of the net. Permitting negative combinations (and thus solutions in the integers instead of the natural numbers)
would yield a significant loss in precision of the state equation.


So we know that all solutions can be obtained by taking a minimal solution  of the state equation
and adding a linear combination of -invariants from some basis . Usually, not all the elements
from  and  we use for a solution are realizable, though. While the sum of two realizable -invariants
remains realizable (just concatenate the according firing sequences as they have identical initial and final marking), 
the sum of two non-realizable
-invariants may well become realizable. This can be seen in Fig.~\ref{f.tinv2}, where neither 
nor  is realizable under the marking  with  and , 
but the sequence  realizes . The matter is even more complicated when a minimal
solution from  is introduced, because positive minimal solutions are never -invariants (unless ), i.e.\ 
they change the marking of the net, so their realizations cannot just be concatenated.

\begin{figure}[tb]
\centering
\begin{tikzpicture}[scale=0.5]
\node[transition,label=above:] (t) {};
\node[place,label=above:] (s2) [right of=t] {};
\node[transition,label=below:] (tx) [below of=s2] {};
\node[place,label=below:] (s1) [below of=t] {};
\node[transition,label=above:] (u) [right of=s2,xshift=5mm] {};
\node[place,label=above:] (s4) [right of=u] {};
\node[transition,label=below:] (ux) [below of=s4] {};
\node[place,label=below:] (s3) [below of=u] {};
\draw (s1) node[token] {};
\draw (s4) node[token] {};
\draw[arrow] (s1) to (t);
\draw[arrow] (t) to (s2);
\draw[arrow] (s2) to (tx);
\draw[arrow] (tx) to (s1);
\draw[arrow] (s4) to (u);
\draw[arrow] (u) to (s3);
\draw[arrow] (s3) to (ux);
\draw[arrow] (ux) to (s4);
\draw[arrow] (s2) to (u);
\draw[arrow] (u) to (s2);
\draw[arrow] (s3) to (tx);
\draw[arrow] (tx) to (s3);
\end{tikzpicture}
\caption{\label{f.tinv2}Neither the -invariant  nor  is realizable, but  is, 
	by the sequence }
\end{figure}

\section{Traversing the Solution Space}\label{sec3}

Though realizability of transition vectors is and remains a problem, 
the first real problem we encounter when we try to solve the
state equation is a practical one. While there are solvers that can determine the complete sets of base
and period vectors for the solution space, e.g. {\em 4ti2}~\cite{4ti2}, these programs can only do that for very
small systems. If the system has a hundred or more variables, we are out of luck. On the other hand,
integer programming (IP) solvers like {\em lp\_solve}~\cite{lpsolve} are much faster but will only find one solution 
to the state equation at a time. 

Another point of interest to know about IP solvers is the objective
function, which can be any function over the variables of the linear system to solve. 
While looking for a solution, the solver tries to minimize or maximize this function. Minimizing seems more
valuable here, since we might use the sum over all variables as our objective function, effectively telling
the solver to produce a solution that would lead to a shortest firing sequence if realizable.
In the following, we will assume such an objective function.

Fortunately, we can force an IP solver to produce more than just one solution --- this is the CEGAR part of our approach. 
If a solution found is not realizable, we may add an inequation to our state
equation to forbid that solution. Starting the IP solver again will then lead to a different solution. The trick is,
of course, to add inequations in such a way that no realizable solution is lost. 

\begin{defi}[Constraints]
Let  be a Petri net.
We define two forms of constraints, both being linear inequations over transitions:
\begin{iteMize}{}
\item a {\em jump constraint} takes the form  with  and . 
In general, it is intended to switch (jump)
to another base solution, exploiting the incomparability of different minimal base solutions.
\item an {\em increment constraint} takes the form  with , , and .
Among others, it can be used to force non-minimal solutions.
\end{iteMize}
\end{defi}

\noindent To understand the idea for differentiating between these two forms of constraints, it is necessary to introduce
the concept of a partial solution first. A partial solution is obtained from a solution of the state equation under
given constraints by firing as many transitions as possible.

\begin{defi}[Partial solution]
Let  be a Petri net and  a total order over  that includes the partial order given by
 if . 

\noindent A {\em partial solution} of a reachability problem 
 is a 
tuple 
 
of
\begin{iteMize}{}
\item a family of (jump and increment) constraints ,
\item the -smallest solution  fulfilling the state equation of  {\em and} the constraints of ,
\item a firing sequence  with  and ,
\item a remainder  with  and : .
\end{iteMize}
The vectors  and  are included for convenience only, they can be computed from , , , and the problem instance.

A {\em full solution} is a partial solution  with . In this case,  is a firing
sequence solving our reachability problem (with answer 'yes').
\end{defi}

We choose  such that an IP solver can be assumed to always 
produce the -smallest solution that does not contradict its linear system of equations.
Note that from any firing sequence solving our reachability problem we can easily deduce a full solution:

\begin{cor}[Realizable solutions are full solutions]
For any realizable solution  of the state equation (realized by a firing sequence )
we find a full solution 
where  consists of constraints  for every  with , and .
\end{cor}
Note, that  is the smallest solution fulfilling  and therefore also the -smallest solution.

By adding a constraint to a partial solution we may obtain new partial solutions (or not, if the linear
system becomes infeasible). Any full solution can eventually be reached by consecutively extending an -minimal 
partial solution with constraints. The following lemma is thus a core argument for the correctness of our approach.

\begin{lem}[A path to a full solution]\label{L.PTFL}
Let  be the -minimal solution of the state equation of a reachability problem  and 
 a full solution of the problem. 
For , there are partial solutions 
with , , and  for .
\end{lem}
\begin{proof}
Let .
If  are two partial solutions (with ) then  is a solution
of the state equation plus , since it even fulfills the state equation plus  with .
As  is the -smallest solution of the state equation plus ,  holds.
Therefore, . Since  is an existing solution of the
strictest system, i.e. state equation plus , each system of state equation plus one family of constraints 
is solvable. As a  can be determined by just firing transitions as long as possible, all the partial
solutions  exist.
\end{proof}

Now, let us assume a partial solution  that is not a full solution, i.e. .
Obviously, some transitions cannot fire often enough. There are three possible remedies for this situation:
\begin{enumerate}[(1)]
\item  may still be realizable by a different firing sequence that corresponds to . That is, we can find a full solution  with .
\item We can add a jump constraint to obtain an -greater solution vector for a different partial solution.
\item If  for some transition , we can add an increment constraint to increase the maximal number of tokens available on
	a place in the preset of . Since the final marking remains the same, this means to borrow tokens for such a place. This
	can be done by adding a -invariant containing the place to the solution. 
\end{enumerate}\smallskip

\noindent A visualization of these ideas can be seen in Fig.~\ref{f.solpath} where  denotes the -smallest solution.
The cone over  represents all solutions  with  being the set of period vectors, i.e. -invariants.
Jump constraints lead along the dashed or dotted lines to the next -minimal solution while normal arrows representing
increment constraints lead upwards to show the addition of a -invariant. How to build constraints doing just
what we want them to do is the content of the next section.

\begin{figure}[tb]
\centering
\begin{tikzpicture}[scale=0.5]
\shade[top color=black!1, bottom color=black!50] (1,1)--(0,0)--(-1,1)--cycle;
\draw(-1,1)--(0,0)--(1,1);
\shadedraw[top color=black!1, bottom color=black!30] (0,1) ellipse (1 and 0.2);
\fill[color=black] (0,0) circle (0.05);
\draw(0,0) node[label=below:] (c1) {};

\shade[top color=black!1, bottom color=black!50] (5,1.1)--(4,0.1)--(3,1.1)--cycle;
\draw(3,1.1)--(4,0.1)--(5,1.1);
\shadedraw[top color=black!1, bottom color=black!30] (4,1.1) ellipse (1 and 0.2);
\fill[color=black] (4,0.1) circle (0.05);
\draw(4,0.1) node (c2) {};

\shade[top color=black!1, bottom color=black!50] (8,1.2)--(7,0.2)--(6,1.2)--cycle;
\draw(6,1.2)--(7,0.2)--(8,1.2);
\shadedraw[top color=black!1, bottom color=black!30] (7,1.2) ellipse (1 and 0.2);
\fill[color=black] (7,0.2) circle (0.05);
\draw(7,0.2) node (c3) {};

\shade[top color=black!1, bottom color=black!50] (0.1,2.2)--(-0.9,1.2)--(-1.9,2.2)--cycle;
\draw(-1.9,2.2)--(-0.9,1.2)--(0.1,2.2);
\shadedraw[top color=black!1, bottom color=black!30] (-0.9,2.2) ellipse (1 and 0.2);
\fill[color=black] (-0.9,1.2) circle (0.05);
\draw(-0.9,1.2) node (c11) {};

\shade[top color=black!1, bottom color=black!50] (1.9,2.5)--(0.9,1.5)--(-0.1,2.5)--cycle;
\draw(-0.1,2.5)--(0.9,1.5)--(1.9,2.5);
\shadedraw[top color=black!1, bottom color=black!30] (0.9,2.5) ellipse (1 and 0.2);
\fill[color=black] (0.9,1.5) circle (0.05);
\draw(0.9,1.5) node (c12) {};

\shade[top color=black!1, bottom color=black!50] (4.1,2.5)--(3.1,1.5)--(2.1,2.5)--cycle;
\draw(2.1,2.5)--(3.1,1.5)--(4.1,2.5);
\shadedraw[top color=black!1, bottom color=black!30] (3.1,2.5) ellipse (1 and 0.2);
\fill[color=black] (3.1,1.5) circle (0.05);
\draw(3.1,1.5) node (c21) {};

\shade[top color=black!1, bottom color=black!50] (5.9,2.7)--(4.9,1.7)--(3.9,2.7)--cycle;
\draw(3.9,2.7)--(4.9,1.7)--(5.9,2.7);
\shadedraw[top color=black!1, bottom color=black!30] (4.9,2.7) ellipse (1 and 0.2);
\fill[color=black] (4.9,1.7) circle (0.05);
\draw(4.9,1.7) node (c22) {};

\shade[top color=black!1, bottom color=black!50] (1,4)--(0,3)--(-1,4)--cycle;
\draw(-1,4)--(0,3)--(1,4);
\shadedraw[top color=black!1, bottom color=black!30] (0,4) ellipse (1 and 0.2);
\fill[color=black] (0,3) circle (0.05);
\draw(0,3) node (c111) {};

\draw[arrow] (c1) to[out=100,in=315] (c11);
\draw[arrow] (c1) to[out=80,in=225] (c12);
\draw[arrow] (c11) to[out=80,in=225] (c111);
\draw[arrow] (c12) to[out=100,in=315] (c111);
\draw[arrow] (c2) to[out=100,in=315] (c21);
\draw[arrow] (c2) to[out=80,in=225] (c22);
\draw[arrow,dashed] (c1) to[out=0,in=180] (c2);
\draw[arrow,dashed] (c2) to[out=0,in=180] (c3);
\draw[arrow,dashed] (c11) to[out=0,in=180] (c12);
\draw[arrow,dotted] (c12) to[out=0,in=180] (c21);
\draw[arrow,dashed] (c21) to[out=0,in=180] (c22);
\end{tikzpicture}
\caption{\label{f.solpath}Paths from the -minimal solution  to any solution. Black dots represent solutions, cones
stand for linear solution spaces over such solutions, which may or may not intersect or include each other.
Normal arrows increment a solution by adding a -invariant, dashed arrows are jumps to an incomparable -greater solution.
Such jumps can also occur on higher levels of linear solution spaces, shown by the dotted arrow}
\end{figure}

\section{Building Constraints}\label{sec4}

Let us first argue that for a state equation, any of the minimal solution vectors in  can be obtained by using jump
constraints.

\begin{lem}[Jumps to minimal solutions]\label{L.BJ}
Let  be base vectors of the solution space of the state equation  plus some set of constraints . 
Assume  to be the -minimal solution of the system. 
Then, we can obtain  as output of our IP solver by consecutively adding jump constraints of the form  with  to .
\end{lem}
\begin{proof}
We know  holds, but since  is a minimal solution,  cannot hold. Therefore, a transition  with
 must exist. After adding the constraint  to 
the IP solver can no longer generate  as a solution. Assume  is the newly generated solution. If 
we are done. Otherwise, since  fulfills , it is still a solution of our system, and also a minimal one as the
solution space is restricted by the added constraint. Thus,  holds and
we may recursively use the same argument as above for . Since there are only finitely many solutions -smaller
than , the argument must terminate reaching .
\end{proof}

Non-minimal solutions may not be reachable this way, since the argument `` for some '' does not necessarily hold.
We will need increment constraints for this, but unluckily, increment constraints and jump constraints may 
contradict each other. Assume our state equation has a solution of the form  with a period vector 
and to obtain  from the -minimal solution  we need to add (at least) a jump constraint  to the state equation.
If  contains  often enough, we will find that  holds. Therefore,  is not a solution of the
state equation plus the constraint , i.e. adding an increment constraint demanding enough occurrences of 
for  will render the linear equation system infeasible. The only way to avoid this problem is to remove the jump
constraints before adding increment constraints.

\begin{lem}[Transforming jumps]
Let  be the -minimal solution of the state equation  plus some constraints . Let  consist of all
increment constraints of  plus a constraint  for each transition . Then, for all ,
 is a solution of  plus  if and only if  is a solution of  plus .
Furthermore, no -smaller solution of  plus  than  solves  plus .
\end{lem}
\begin{proof}
Let  be a solution of  plus . The additional constraints in  only demand , which
is obviously the case. The other direction is trivial. For the second part, let  with  be some solution of
 plus . Since  (following from ) but , for at least one transition  holds . 
Due to the constraint  in ,  cannot be a solution of  plus .
\end{proof}

As a consequence, if we are only interested in solutions of the cone  over , we can add increment constraints guaranteeing
solutions greater or equal than  and remove all jump constraints without any further restriction. Our IP solver will yield  as the -minimal
solution for both families of constraints,  and , and we can add further constraints leading us to any solution in the
cone  now.

Let  now be a partial solution with . We would like to determine sets of places that need additional tokens
(and the number of these tokens) that would enable us to fire the remainder  of transitions. Obviously, this problem is harder
than the original problem of finding out if a transition vector is realizable, i.e. just testing if zero additional tokens are
sufficient. A recursive approach would probably be very inefficient as for every solution  there may be many different remainders .
Even though the remainders are smaller than the solution vector , the number of recursion steps might easily grow exponentially with
the size of , i.e. . We therefore adopt a different strategy, namely finding good heuristics to estimate the number of
tokens needed. If a set of places actually needs  additional tokens with , our estimate may be any number from one to .
If we guess too low, we will obtain a new partial solution allowing us to make a guess once again, (more or less) slowly approaching
the correct number. We propose a two-part algorithm.The first part computes sets of places and transitions that are of interest, the second
estimates the number of tokens. For the first part, we use a dependency graph that is known from partial order reduction approaches \cite{valmari2009}.
For every disabled transition, we can choose an insufficiently marked place. For every such place, we consider its pre-transitions. Applying this
idea to a partial solution (where all transitions in  are disabled), this graph yields cycles, or more generally strongly connected components) of mutually blocked 
transitions and their insufficiently marked scapegoat places. In order to make parts of  fireable, we need to interleave  with a T-invariant that
is able to lend tokens to any of the involved scapegoat places. Obviously, source SCC (i.e.~SCC without incoming edges) are of particular
interest for enabling parts of . The following algorithm computes sets of places where additional tokens are necessary.

\smallskip{\small\noindent
{\tt
{\bf input}: Reachability prob. ; partial solution \\
{\bf output}: A set of tuples  with , \\
Determine  with ;\\
Build a bipartite graph  with\\
; : ;\\
;\\
Calculate the strongly connected components () of ;\\
;\\
{\bf for each} source  (i.e.~one without incoming edges):\\
\hspace*{3mm} ;\\
\hspace*{3mm} ;\\
\hspace*{3mm} ;\\
\hspace*{3mm} ;\\
{\bf end for}
}}\smallskip

The edges of the graph  constructed in the algorithm have a different meaning depending on their direction.
Edges from transitions to places signal that the transition would increase the number of tokens on the place
upon firing, while edges in the other direction show the reason for the non-enabledness of the transition.
A source SCC, i.e. a strongly connected component without incoming edges from other components, can therefore
not obtain tokens by the firing of transitions from other SCCs. This means, tokens must come from somewhere else, 
that is, from firing transitions
not appearing in the remainder . For each set of places  such identified as non-markable by the remainder itself,
there are two sets of transitions. If one transition from the set  would become firable, it is possible that
all other transitions could fire as well, since the former transition effectively produces tokens on some place in
the component. If the set  is empty (the SCC consisting of a single place), the transitions mentioned in 
will not produce any tokens on the SCC. Thus, the token needs of the transitions depending on this SCC, i.e.\
those in , must all be fulfilled together, since they cannot activate each other. Overall, we obtain:
\begin{lem}\label{L.ALG1}
The previous algorithm determines source SCCs  with insufficient numbers of tokens to enable the
remainder  of a partial solution as well as sets  of transitions depending on those SCCs for firing.
\end{lem}

Since enough additional tokens to enable one transition from a set  might later enable the rest of  and
 as well, it is difficult to compute the exact number of tokens needed on some SCC and where to place them.
The following algorithm thus is a heuristic to determine a least number of tokens necessary on a source SCC.

\smallskip{\small\noindent
{\tt
{\bf input}: A tuple ;  and  from above\\
{\bf output}: A number of tokens  (additionally needed for )\\
{\bf if} \\
{\bf then} \\
{\bf else} sort  in groups  (with );\\
\hspace*{7mm} ; ;\\
\hspace*{7mm} {\bf for}  {\bf with}  {\bf downwards loop}\\ 
\hspace*{14mm} ;\\
\hspace*{14mm} {\bf if}  {\bf then}  {\bf end if};\\
\hspace*{14mm} \\
\hspace*{7mm} {\bf end for}\\
{\bf end if}
}}\smallskip

\begin{lem}\label{L.ALG2}
For each set of places  that need additional tokens according to the first part of the algorithm, the second
part estimates that number of tokens (in a range from one to the actual minimum number of tokens necessary).
\end{lem}
\begin{proof}
Consider a triple (,,) computed by the first algorithm.
If  is not empty, only line~4 of the second algorithm is executed, computes the number of tokens missing
for each of the transitions in , and takes the minimum over these numbers. By construction, this number is
at least one and any lower number would not activate any transition from . 

If  is empty, all transitions in  depend on a single place which must provide all the
necessary tokens to fire all the transitions in . 
Note that while the transitions in  all effectively consume tokens from , they may also put tokens back onto this
place due to a loop. By firing those transitions with the lowest -values last, we minimize the leftover.
Transitions with the same -value  can be processed together, each consuming effectively  tokens
except for the ``first'' transition which requires the existence of  additional tokens. 
If some group  of transitions leaves tokens
on , the next group can consume them, which is memorized in the variable  (for carryover or consumption).
Overall, we get the minimal number of tokens necessary to fire all transitions in .

Observe, that the algorithm cannot return zero or negative values: 
There must be at least one transition in , otherwise
there would be no transition that cannot fire due to a place in  and the places in  would not have been
computed at all. If  is not empty, line~4 in the algorithm minimizes over positive values, i.e.\ the
numbers of tokens missing for each transition in ; if 
is empty, line~8 will set  to a positive value at its first execution, yielding a positive value for . 
\end{proof}

We can thus try to construct a constraint from a set of places  generated by the first part of the algorithm
and the token number calculated in the second part. Since our state equation has transitions as variables, we
must transform our condition on places into one on transitions first. 


\begin{lem}\label{L.CON}
Let  be a Petri net,  the reachability problem to be solved,  a partial solution
with , and  the marking reached by .
Let  be a set of places and  a number of tokens to be generated on .
Further, let .
We define a constraint  by

Then, for the system  plus  plus , if our IP solver can generate a solution  ( being a -invariant) 
we can obtain a partial solution  with . Furthermore,
.
\end{lem}
\begin{proof} {\em (Sketch)}
First, note that  contains the transitions that produce more on  than they consume, but we have explicitly excluded
all transitions of the remainder , since we do not want the IP solver to increase the token production on  by adding
transitions that could not fire anyway. I.e., we would like to have a chance to fire the additional transitions in  at
some point, though there are no guarantees. The left hand side of  contains one instance of a transition  for each
token that  effectively adds to . If we apply some transition vector  to the left hand side of  (i.e.\ 
replacing  by  for each transition ), we therefore
get the number of tokens added to  by firing the transitions from  in . Of course, other transitions in  (outside ) might
reduce this number again. For the right hand side of , we calculate how many tokens are actually added to  by the
transitions from  in the firing sequence  (and therefore also in the solution ) and increase that number by 
the  extra tokens we would like to have. Since the extra tokens cannot come from  in a solution , they must
be produced by , i.e. . We might be able to fire some portion of 
after , resulting in the obvious .
\end{proof}

When we apply our constraint we might get less or even more than the  extra tokens, depending on the -invariants in the net.
There are three possible outcomes when we apply the new constraint: The constraint might be unsatisfiable, we might detect
that the new constraint has not brought us any closer to a solution, or some of the remainder
transitions can now fire (or have at least come closer to firing). In the first two cases, our partial solution just cannot 
be extended to a full solution, nothing is lost if we throw it away. Failing to detect the second case will not cut off
any solutions but might prohibit termination. In the third case, we continue extending the partial
solution with the help of further constraints. Therefore, if a solution exists, we can still find it, and we know that we
can find it with the help of jump and increment constraints, since we only add necessary constraints. Further jump
constraints may be necessary as there may be many incomparable, minimal solutions fulfilling the latest increment constraint.


\begin{thm}[Reachability of solutions]
If a reachability problem has a solution, a realizable solution of the solution space of the state equation can be reached by consecutively adding constraints
to the system of equations, always transforming jump constraints before adding increment constraints.
This even holds, given some solution , if we limit the increment constraints to those built by lemma~\ref{L.CON} and jump constraints to
those of the form .
\end{thm}
\begin{proof} {\em (Sketch)}
The first sentence is obvious from lemma~\ref{L.PTFL}. For the second part, let  be a realizable solution
with  and let  be a minimal solution with . We can obtain  by a set of jump
constraints according to lemma~\ref{L.BJ}. Either  is realizable and we are done, or  is not realizable.
In the latter case, we compute an increment constraint forcing additional tokens to undermarked places according
to lemma~\ref{L.ALG1}, \ref{L.ALG2}, and~\ref{L.CON}, not losing any full solutions. Let  be the solution
computed for this extended system, then  holds. If  is realizable, we are done. If , we add the next
increment constraint. Otherwise, we test further jump constraints now and obtain all solutions  
fulfilling the increment constraint but being incomparable to . For one of them,  must hold (as we
have not lost any full solutions). We continue by checking realizability of  and, in the negative case,
repeat adding a necessary increment constraint. Since  is finite and each constraint leads only to
bigger solutions, at some point we must find a realizable solution or reach .
\end{proof}

\section{Finding Partial Solutions}\label{sec5}

Producing partial solutions  from a solution  of the state equation (plus ) is actually
quite easily done by brute force. We can build a tree with marking-annotated nodes and the firing of transitions as edges,
allowing at most  instances of a transition  on any path from the root of the tree to a leaf. Any leaf is
a new partial solution from which we may generate new solutions by adding constraints to the state equation and
forwarding the evolving linear system to our IP solver. If we just make a depth-first-search through our tree and
backtrack at any leaf, we build up all possible firing sequences realizable from . This is obviously possible
without explicitly building the whole tree at once, thus saving memory.
Of course, the tree might grow exponentially in the size of the solution vector  and so some optimizations
are in order to reduce the run-time. We would like to suggest a few ones here, especially partial order reductions.

\begin{enumerate}[(1)]
\item The stubborn set method \cite{ksv06} determines a set of transitions that can be fired before all others by
investigating conflicts and dependencies between transitions at the active marking. The stubborn set is often much smaller than
the set of enabled transitions under the same marking, leading to a tree with a lower degree. In our case, in particular the version
of \cite{schmidt_atpn99} is useful as, using this method, the reduced state space contains, for each trace to the target marking,
at least one permution of the same trace. Hence, the reduction is consistent with the given solution of the state equation.
\item Especially if transitions should fire multiple times () we observe that the stubborn set
method alone is not efficient. The situation in Fig.~\ref{f.tree} may occur quite often. Assume we reach some marking
 by a firing sequence , so that transitions  and  are enabled. After proceeding through the
subtree behind  we backtrack to the same point and now fire  followed by some sequence  after which 
is enabled, leading to . If  holds, we know that
it reaches the same marking  and the same remainder  of transitions still has to fire. Therefore, in
both cases the future is identical. Since we have already investigated what happens after firing ,
we may backtrack now omitting the subtree after . Note that a test if  holds
is quite cheap, as only those places  with  can prevent the sequence .
Enabledness of  after  can be tested by reverse calculating  and 
checking whether  is a marking and  holds. 
\item There are situations where a leaf belongs to a partial solution  that cannot lead to a (new) full solution. In this
case the partial solution does not need to be processed. If we already tried to realize  yielding a partial solution
 and  is our new partial solution with an increment constraint 
and a -invariant , any realizable solution  obtainable from  can also be reached from  by first
adding a constraint  for the -invariant  (and later , ). If no transition of  can be fired after ,
 is also not realizable after firing . We may be able to
mingle the realization of  with the firing of , but that will be reflected by alternate partial solutions
(compared to both,  and ). Therefore, not processing  will not lose any full solutions.
\item A similar situation occurs for  with . There is one problem,
though. Since we estimated a token need when choosing  and that estimate may be too low, it is possible that while
firing  we get closer to enabling some transition  in  without actually reaching that limit where 
becomes firable. We thus have to check for such a situation (by counting the minimal number of missing tokens for
firing  in the intermediate markings occurring when firing  and ). If  does not help in
approaching enabledness of some  in , we do not need to process  any further.
\item Partial solutions should be memorized if possible to avoid using them as input for CEGAR again if they show up more than once.
\end{enumerate}

\begin{figure}[tb]
\centering
\begin{tikzpicture}[scale=0.5]
\fill (0,3) circle (0.05);
\draw (0,3) node[label=above:] (root) {};
\fill (3,3) circle (0.05);
\draw (3,3) node[label=above:] (hm) {};
\draw[arrow,snake=snake] (root) -- node[label=above:] {} (hm);
\fill (5,4.1) circle (0.05);
\draw (5,4.1) node[label=above:] (hm1) {};
\fill (5,1.9) circle (0.05);
\draw (5,1.9) node[label=below:] (hm2) {};
\draw[arrow] (hm) -- node[label=above:] {} (hm1);
\draw[arrow] (hm) -- node[label=below:] {} (hm2);
\fill (8,4.1) circle (0.05);
\draw (8,4.1) node[label=above:] (tm1) {};
\fill (8,1.9) circle (0.05);
\draw (8,1.9) node[label=below:] (tm2) {};
\draw[arrow,snake=snake] (hm1) -- node[label=above:] {} (tm1);
\draw[arrow,snake=snake] (hm2) -- node[label=below:] {} (tm2);
\fill (10,4.1) circle (0.05);
\draw (10,4.1) node[label=above:] (tm3) {};
\fill (10,1.9) circle (0.05);
\draw (10,1.9) node[label=below:] (tm4) {};
\draw[arrow] (tm1) -- node[label=above:] {} (tm3);
\draw[arrow] (tm2) -- node[label=below:] {} (tm4);
\draw (tm3) -- +(2,1) -- +(2,-1) -- (tm3);
\draw (tm4) -- +(2,1) -- +(2,-1) -- (tm4);
\end{tikzpicture}
\caption{\label{f.tree}If both sequences  and  can be fired, the subtrees
after the nodes with marking  are identical. Only one of the subtrees needs to be evaluated, the other one
may be omitted. Snaked lines denote firing sequences}
\end{figure}



\section{The complete algorithm}\label{sec6}

The following algorithm integrates the results from the previous sections, using a queue of
partial solutions as a job queue that is ordered by ascending size of the possible output, i.e.\ 
the firing sequence from an initial marking  to a final marking .

\smallskip{\small\noindent
{\tt
{\bf input}: Reachability problem \\
{\bf output}: Firing sequence from  to  if one exists\\
{\bf var}: Queue  of partial solutions  to work on\\
{\bf var}: Set  of all partial solutions computed (for optimisation (5))\\
Put  into ;\\
{\bf while} :\\
\hspace*{3mm} Remove from  an element  with minimal size for ;\\ 
\hspace*{3mm} Compute new increment constraints  from  (see section~\ref{sec4});\\
\hspace*{3mm} {\bf if}  {\bf then continue} to the next loop;\\ 
\hspace*{3mm} Compute the minimal solution  for state equation plus ;\\
\hspace*{3mm} {\bf if} no solution  exists {\bf then continue} to the next loop;\\ 
\hspace*{3mm} {\bf for each} set of jump constraints \\
\hspace*{6mm} Transform jump constraints in  to increment constraints;\\
\hspace*{6mm} Create a new partial solution  in  and ;\\
\hspace*{3mm} Traverse the tree of firing sequences  with :\\
\hspace*{6mm} (Depth first, use optimisations (1) and (2) to prune the tree)\\ 
\hspace*{6mm} Upon reaching a leaf ( cannot be prolonged):\\
\hspace*{9mm} {\bf if}  {\bf then halt} with solution ;\\
\hspace*{9mm} {\bf if} optimisation (3) or (4) applies {\bf then} backtrack;\\ 
\hspace*{9mm} {\bf if}  {\bf then} backtrack;\\
\hspace*{9mm} Put  into  and \\
{\bf end while};\\
Print "no solution"
}}\smallskip

In each while-loop one candidate from the partial solutions queue is processed. First, the constraints 
are added according to the non-firable remainder  and a minimal solution vector  is computed.
If this is successful, jump constraints are added to the old solution  to obtain other new solutions
in a later loop. The minimal solution vector  is then checked for realizable firing sequences.
If at some point a firing sequence is incomplete and not extendable, a new partial solution is
generated to be able to add more increment constraints later on. The result ``no solution''
can be obtained by two mechanisms: a partial solution is thrown away if no solution vector 
can be computed and the optimisations may prune the trees of firing sequences so much that no
new partial solutions are created anymore. There is no guarantee for termination, of course,
but in practise this works well.

Note that new jump constraints can lead to an exponential growth in the number of partial solutions,
as one such partial solution is created for each subset of transitions where the new solution
exceeds the old one. Usually, there are only few different partial solutions, i.e.\ we have just a
problem with space limitations but not really with computation time. Thus, we advise to modify the algorithm
such that the new partial solutions created from jump constraints are not introduced all at once but one at a time, each time
a former one has been processed. If a full solution is found, the unprocessed jump constraints
are deleted before they consume space and time, if no full solution exists our experience says
that jump constraints are scarce anyway.

\section{Diagnostic Information for Unreachability}\label{sec7}

If one of the optimizations~3 or~4 occurs, we know that an increment constraint  added to our system of linear equations
did not have the desired effect. This means, we wanted to increase the number of tokens on some set of places but
were not able to do so, i.e. a -invariant either was not firable or it had some side effect cancelling the usefulness
of the token increase. Such a thing could happen for example if we added a transition  to Fig.~\ref{f.tinv}
that consumes a token from each  and  and tried to fire it. The -invariant  will produce a token on , where we need
it, but takes away that token from , cancelling its positive effect. Even if we fire this -invariant more
than once, it is of no use.

Compare the partial solutions  and 
resp.\  from optimizations~3 and~4. It is obvious that
adding the constraint  had not the desired effect, i.e.  failed. We were not able to
obtain enough tokens on some set of places  (that was the reason for introducing ) to
enable some transitions  (or , see section~\ref{sec4}). If we memorize  and 
/ and the number of tokens  missing on  together with , we can now give a 
(partial) reason for unreachability. We need at least  more tokens on the set 
to fire one transition in  or all transitions in  after the firing sequence .
Indeed,  produces a kind of deadlock:  forms a component of the net 
that is strongly connected and the transitions of  cannot fire after 
since there are not enough tokens left in . There may be other transitions though, that could put
tokens onto . If our partial solutions could not be extended with them to obtain a
full solution, these transitions are either dead after firing  or they lead to a
system of state equation plus constraints that can not be fulfilled. In the latter case,
after firing such a transition the final marking becomes unreachable.

Even if we find a reason for unreachability, there may still be other paths that lead
to a solution. But if the algorithm terminates altogether (which we are not able to 
guarantee) and we have not found any solution, we can pick up our failed constraints
and present them as diagnostic information. Fig.\ref{f.counternet} in the next section shows a visualization
of such information in a small example Petri net. Hence, our tool cannot
only tell the user that a certain marking is unreachable but can also give hints as to where the
bottlenecks of the token distribution are that cannot be passed.  


\section{Experimental Results}\label{sec8}

The algorithm presented here has been implemented in a tool named Sara \cite{sara}. We compare Sara
to LoLA~\cite{Wolf_2007_icatpn}, a low level analyzer searching the (reduced) state space of a Petri net. According to
independent reports, e.g.~\cite{talcottdill}, LoLA performs very well on reachability queries
and possibly is the fastest tool for standard low level Petri nets.
The following tests, real-world examples as well as academic constructions, were run on a 2.6GHz PC 
with 4GB RAM under Windows XP and Cygwin. While the CPU had four cores, only one was used for the tools.
Tests on a similar Linux system lead to comparable but slightly faster results.

\begin{iteMize}{}
\item 590 business processes with about 20 up to 300 actions each were tested for ``relaxed
soundness''. Relaxed soundness means that, for each transition  of the net, it is possible to reach the final marking from the initial marking with a path that contains . 
This problem can be solved using the methods presented above for reachability. The occurrence of  can be asserted by an additional constraint  to the IP solver.
The processes were transformed into Petri nets and for each action a test was performed
to decide if it was possible to execute the action and reach the final state of the process afterwards.
Successful tests for all actions/transitions yield relaxed soundness.
Sara was able to decide relaxed soundness for all of the 590 nets together (510 were relaxed sound)
in 198 seconds, which makes
about a third of a second per net. One business process was especially hard and took 12278 calls
to lp\_solve and 24 seconds before a decision could be made. LoLA was unable to solve 17
of the problems (including the one mentioned above) and took 24 minutes for the remaining 573. 
\item Four Petri nets derived in the context of verifying parameterized boolean programs (and published on a web page \cite{wsts}) were presented to us to decide coverability.
Sara needed less than one time slice of the CPU per net and solved all instances correctly.
LoLA was not able to find the negative solution to one of the problems due to insufficient memory (here, tests were made with up to 32GB RAM),
the remaining three problems were immediately solved.
\item In 2003, H. Garavel~\cite{garavel03} proposed a challenge on the internet to check a Petri net derived from
a LOTOS specification for dead (i.e. never firable) transitions. The net consisted of 776 transitions
and 485 places, so 776 tests needed to be made. Of the few tools that succeeded, LoLA was the fastest
with about 10 minutes, but it was necessary to handle two of the transitions separately with a differently
configured version of LoLA. In our setting, seven years later, LoLA needed 41 seconds to obtain the
same result. Sara came to the same conclusions in 26 seconds. In most cases the first solution of
lp\_solve was sufficient, but for some transitions it could take up to 15 calls
to lp\_solve. Since none of the 776 transitions is dead,
Sara also delivered 776 firing sequences to enable the transitions, with an average length of
15 and a longest sequence of 28 transitions. In 2003 the best upper bound for the sequences
lengths was assumed to be 35, while LoLA found sequences of widely varying length (the longest having several thousand transition occurrences), though most
were shorter than 50 transitions.
\item We investigated five nets that represent biochemical reaction chains. The nets stem from the Pathway Logic Assistent \cite{talcottdill} where LoLA
is integrated for solving reachability problems. For some of the nets (which have several hundred places and transitions), LoLA was incapable of
verifying reachability. Sara was able to solve the problems. For three systems, Sara ran less than a second, the remaining two problems
could be solved in approximately half an hour. In one of these problem instances the given marking was unreachable.
\item Using specifically constructed nets with increasing arc weights (and token numbers) it was possible to outsmart
Sara -- the execution times rose exponentially with linearly increasing arc weights, the first five
times being 0.1, 3.3, 32, 180, and 699 seconds. LoLA, on the other hand,
decided reachability in less than 3 seconds (seemingly constant time) in these cases.
\end{iteMize}\smallskip

\noindent In addition to these experiments, Sara participated in the Model Checking Contest \cite{mcc} that was organized within the workshop on
Scalable and Usable Model Checking for Petri Nets and Other Models of Concurrency in June 2011 in Newcastle upon Tyne.
In this contest, Sara competed in reachability queries on place/transition Petri nets representing a flexible manufacturing system,
a KANBAN system, and a biochemical reaction chain. Experiments were done on increasing state spaces that were obtained by adding
additional tokens (up to several hundred) on certain places. Sara was able to solve most problem instances in less than a second, the remaining cases
were solved within a few seconds. Only two queries led to memory overflow. Sara outperformed all other participating tools including LoLA.

\begin{table}[tb]
\centering\small
\begin{tabular}{|l|r|r|c|c|c|c|c|}\hline
Net & Inst. & Sol? & Full & 1 & 2 & 3/4 & 5\\\hline
garavel & 776 & 15 & 26s (0.11) & 25s (0.11) & 26s (0.11) & 26s (0.11) & 26s (0.11)\\\hline
bad-bp & 142 & - & 24s (85) & 24s (85) & 24s (85) & 24s (85) & NR\\\hline
good-bp & 144 & 53 & 1.7s (0) & 1.7s (0) & 1.7s (0) & 1.7s (0) & 1.7s (0)\\\hline
test7 & 10 & 175 & 29s (13) & 990s (22) & NR & 49s (14) & 29s (13)\\\hline
test8-1 & 1 & 40 & 0.1s (13) & 0.35s (22) & 49s (13) & 0.2s (14) & 0.11s (13)\\\hline
test8-2 & 1 & 76 & 3.3s (21) & 24s (51) & NR & 11s (34) & 3.8s (21)\\\hline
test8-3 & 1 & 112 & 32s (27) & 390s (80) & NR & 175s (71) & 33s (27)\\\hline
test9 & 1 & - & 0.4s (53) & 22s (464) & NR & NR & 0.9s (65)\\\hline
\end{tabular}\vspace*{2mm}
\caption{\label{t.1}Results for shutting down one heuristic. Inst.\ is the number of problem
instances to be solved for the net, Sol? the average solution length or ``-'' if no solution
exists. Columns Full, 1, 2, 3/4, and 5 contain the result
with all optimizations, without stubborn sets, without
subtree cutting, without partial solution cutting, and without saving intermediate results 
(numbers are according to Sect.~\ref{sec5}).
Each entry shows the elapsed time and the number of necessary CEGAR steps (average), or
NR if no result could be obtained in less than a day}
\end{table}

We also checked our heuristics from Sect.~\ref{sec5} with some of the above nets by switching
the former off and comparing the results (see Table~\ref{t.1}). Our implementation needs both forms of constraints,
jump and increment, to guarantee that all solutions of the state equation can be visited.
Going through these solutions in a different order, e.g.\ the total order , is difficult
and a comparison was not possible so far.

The nets tested fall in two categories. Garavel's net 
and the business processes are extensive nets with a low token count and without much
concurrency that could be tackled by partial order reduction. The heuristics have no effect
here, short runtimes result from finding a good solution to the state equation early on.
Only for the hardest of the business processes (bad-bp) memorizing intermediate results
to avoid checking the same partial solution over and over made sense -- without it we did not get
a result at all.

The other category are compact nets. In our test examples a high number of tokens is produced 
and then must be correctly distributed, before
the tokens can be removed again to produce the final marking.
With a high level of concurrency in the nets, partial order
reduction is extremely useful, the cutting off of already seen subtrees(2) even more than
the stubborn set method(1). In the last net (test9), the sought intermediate token distribution is
unreachable but the state equation has infinitely many solutions. Only by cutting off
infinite parts of the solution tree with the help of optimization~3 and~4 it becomes
possible to solve the problem at all. Without them, the number of outstanding CEGAR
steps reaches 1000 within less than a minute and continues to increase monotonically.
The algorithm slows down more and more then as the solutions to the state equation and thus
the potential firing sequences become larger.

As mentioned in the previous section, Sara can also provide diagnostic information
for unreachable problem instances as long as the state equation has a solution. This feature was tested
e.g.\ with the hardest of the 590 business processes from above, which provides such a negative
case for some of its 142 transitions. Using the diagnostic information, we were able to understand the
reason for unreachability thus validating the result computed by Sara.
Since we cannot present such a large net here, a condensed
version with the same important features is shown in Fig.~\ref{f.counternet}.

\begin{figure}[tb]
\centering
\begin{tikzpicture}[scale=0.5]
\node[gplace,label=left:] (i) {};
\node[transition,label=above:] (u) [above right of=i] {};
\node[gtransition,label=below:] (d) [below right of=i] {};
\node[iplace,label=above:] (c1) [right of=u, xshift=1cm] {};
\node[gplace,label=above:] (a1) [right of=d] {};
\node[itransition,label=above:] (k1) [right of=c1] {};
\node[iplace,label=above:] (c2) [right of=k1] {};
\node[itransition,label=above:] (k2) [right of=c2] {};
\node[otransition,label=above:] (x2) [right of=a1] {};
\node[oplace,label=below:] (a2) [right of=x2] {};
\node[transition,label=right:] (l) [right of=a2] {};
\node[transition,label=left:] (x1) [below of=a1] {};
\node[oplace,label=right:] (o) [right of=x1] {};
\draw (i) node[token] {};
\draw[arrow] (i) to (u);
\draw[arrow] (i) to (d);
\draw[arrow] (u) to (c1);
\draw[arrow] (u) to (a1);
\draw[arrow] (d) to (a1);
\draw[arrow] (c1) to (k1);
\draw[arrow] (k1) to (c2);
\draw[arrow] (c2) to (k2);
\draw[arrow] (k2) to[out=225,in=315] (c1);
\draw[arrow] (k1) to (a2);
\draw[arrow] (c2) to (l);
\draw[arrow] (l) to (a2);
\draw[arrow] (a1) to (x2);
\draw[arrow] (a2) to (x2);
\draw[arrow] (a1) to (x1);
\draw[arrow] (x1) to (o);
\draw[arrow] (x2) to (o);
\end{tikzpicture}
\caption{\label{f.counternet}A condensed, flawed business process. One token should flow
	from the initial place  to the output place  with all other places empty finally.
	Non-white transitions
	appear in Sara's solution to the state equation, but only the dark gray one is fireable.
	Ascending stripes show the area with non-fireable transitions where additional tokens could not be generated}
\end{figure}

Sara provides a partitioning of the net showing where the relaxed soundness test (for any of the
transitions , , or ) fails, e.g.\ it is impossible to fire  and afterwards reach the
final marking with exactly one token on place  (other places being empty). The solution 
 of the state equation
can neither be realized nor extended to a ``better'' solution.
The ascending pattern shows a region of the net (given by Sara)
where tokens are needed but cannot be generated without violating the state equation.
The descending pattern marks areas that are affected by the former ones, i.e. areas with
also non-fireable transitions. The gray transition  is the only fireable transition occurring
in the solution. When analyzing the net we can see that the cycle  indeed
constitutes a flaw for a business process: if the cycle gets marked and then emptied later,
at least two tokens must flow through , one of which can never be removed.
Using  instead of  is therefore impossible, i.e.\  is the only
firing sequence reaching the final marking.

\section{Towards Parallel Execution}

In essence, Sara solves and evaluates a large number of IP problems corresponding to partial solutions.
Different partial solutions are processed mostly independently. In addition, Fig.~\ref{f.solpath} suggests that
our search space is in fact a tree. It is thus natural to consider a parallelization scheme where new threads are
opened whenever there is more than one possibility to add a constraint to a partial solution. 

The network traffic for opening a new thread is rather low. The Petri net input as well as the problem instance can be 
loaded by each thread independently and ahead of the actual activation. Then, only the description of a partial
solution, especially a set of additional constraints, needs to be transmitted. Compared to the network traffic,
the internal work involves solving at least one IP problem including subsequent analysis. 

Hence, the crucial factor for feasibility of
this approach is the branching factor in the search space. With branching factor, we mean the number of new subproblems
that are introduced upon the analysis of a partial solution. If the branching factor is one, the subproblems appear sequentially
and parallelization does not make sense. Larger values suggest better parallelization results.

We measured the branching factors in several of the examples listed in the previous section. Among those instances that were
solved by Sara in less then a second, the maximum branching factor was two while the average branching factor was close to one.
In nontrivial examples with practical background (e.g.~the hard instances of biochemical reaction chains), the maximal branching factor was
two. The average branching factor ranged between 1.25 and 1.99, so there is enough room for feeding many independent threads.
Substantial speedup can be expected for processing the large number of IP instances (beyond 160.000).
In academic challenges, the maximum branching factor was four, with 2.6 being a typical average value.

We conclude, that the potential for parallel execution is excellent, especially in those problem instances where it is
most needed. 

\section{Conclusion}

We proposed a promising technique for reachability verification. It is based on the Petri net state equation that naturally
provides an overapproximation of the set of reachable states of  Petri net. Using the idea of counterexample
guided abstraction refinement, we were able to significantly improve the precision of the technique. Our approach has
several advantages compared to state space techniques:

(1) It is very efficient, for two reasons. First, we traverse the set of solutions of the state equation rather than the set of all
reachable states. That is, our search space is already substantially constrained. Second, we employ the very mature
technology of IP solving. We could validate the efficiency in a large number of challenging examples as well as in the
independent assessment made in the model checking contest in 2011.

(2) It tends to produce very small (not necessarily minimal) witness paths. This is due to the gradual introduction of
period vectors to a minimal solution of the state equation. Unlike explicit state space techniques, short witnesses come
without exponentially blowing up the search space. In this regard, the state equation as such resembles a symbolic
state representation. Indeed, one solution to the state equation represents up to exponentially many different firing
sequences.

(3) It has the tendency to terminate early on unreachable problem instances. In several cases, the initial state equation
may already assert unreachability. In contrast, state space techniques (whether explicit or symbolic)
cannot benefit from the on-the-fly paradigm if
the target state is unreachable. So they would produce all the reachable states modulo the applied state space reduction
techniques.

(4) It has a rather pleasant memory consumption. As IP solving is an NP complete problem, polynomial space is sufficient for
the core procedure. Only the management of open subproblems may require arbitrary space.

(5) It has an excellent potential for parallelization. Internal executions (IP solving) are nontrivial while network traffic (transmitting
a problem description) is rather lightweight.

(6) It produces some kind of diagnostic information for unreachable problem instances. This potential must be further explored.
In particular, usefulness of the diagnostics must be assessed in studies with independent users unaware of the
internal mechanisms of Sara.

On the negative side, we need to mention that our approach is incomplete. We are not able to show termination of our procedure
and a guaranteed termination may even contradict the EXPSPACE hardness of the reachability problem in general. On the
other hand, our experience with Sara so far is very encouraging.

Our approach applies the concept of counterexample guided abstraction refinement in a novel context: the
abstraction is not given as a transition system but as a linear-algebraic overapproximation of the reachable states.

The state equation as such has been used earlier for verification purposes, see for instance \cite{melzer00}.
In \cite{narrowing}, it is used as an initial way of narrowing the state space exploration but not refined
according to the CEGAR.

\bibliographystyle{plain}
\bibliography{reachability}

\end{document}
