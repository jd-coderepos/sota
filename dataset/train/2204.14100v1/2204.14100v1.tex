



\documentclass[journal,twoside,web]{ieeecolor}
\usepackage{tmi}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{textcomp}

\usepackage[pdftex]{graphicx}
\graphicspath{}


\usepackage{subfigure}
\usepackage{multicol}
\usepackage{dirtytalk}
\usepackage{hyperref}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage[switch]{lineno}

\let\Setlength\setlength \usepackage{calc}
\newlength{\arrayrulewidthOriginal}
\newcommand{\Cline}[2]{\noalign{\global\Setlength{\arrayrulewidthOriginal}{\arrayrulewidth}}\noalign{\global\Setlength{\arrayrulewidth}{#1}}\cline{#2}\noalign{\global\Setlength{\arrayrulewidth}{\arrayrulewidthOriginal}}}
  
  
\usepackage{stackengine}
\def\delequal{\mathrel{\ensurestackMath{\stackon[1pt]{=}{\scriptstyle\Delta}}}}
     
\def\kformat{\textit{K}}
\def\mformat{\textit{M}}
\def\etal{\textit{et al.}}


\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\markboth{\journalname, VOL. XX, NO. XX, XXXX 2020}
{GHAHREMANI \MakeLowercase{\textit{et al.}}: Adversarial Distortion Learning for Medical Image Denoising}
\begin{document}
\title{Adversarial Distortion Learning for Medical Image Denoising}
\author{Morteza~Ghahremani,~\IEEEmembership{Member,~IEEE}, Mohammad Khateri,~\IEEEmembership{Member,~IEEE}, Alejandra Sierra, \\and Jussi Tohka
\thanks{The authors are with A. I. Virtanen Institute for Molecular Sciences, University of Eastern Finland, 70211 Kuopio, Finland (e-mail: morteza.ghahremani@uef.fi; mohammad.khateri@uef.fi; alejandra.sierralopez@uef.fi; jussi.tohka@uef.fi). }
}

\maketitle

\begin{abstract} 
We present a novel adversarial distortion learning (ADL) for denoising two- and three-dimensional (2D/3D) biomedical image data. 
The proposed ADL consists of two auto-encoders: a denoiser and a discriminator. The denoiser removes noise from input data and the discriminator compares the denoised result to its noise-free counterpart. This process is repeated until the discriminator cannot differentiate the denoised data from the reference. 
Both the denoiser and the discriminator are built upon a proposed auto-encoder called Efficient-Unet. 
Efficient-Unet has a light architecture that uses the residual blocks and a novel pyramidal approach in the backbone to efficiently extract and re-use feature maps. During training, the textural information and contrast are controlled by two novel loss functions. 
The architecture of Efficient-Unet allows generalizing the proposed method to any sort of biomedical data. 
The 2D version of our network was trained on ImageNet and tested on biomedical datasets whose distribution is completely different from ImageNet; so, there is no need for re-training. 
Experimental results carried out on magnetic resonance imaging (MRI), dermatoscopy, electron microscopy and X-ray datasets show that the proposed method achieved the best on each benchmark. 
Our implementation and pre-trained models are available at~\url{https://github.com/mogvision/ADL}.
\end{abstract}

\begin{IEEEkeywords}
Adversarial networks, Deep learning, Deep neural network, Image denoising 
\end{IEEEkeywords}

\section{Introduction}
\label{sec:introduction}
\IEEEPARstart{I}{mage} denoising aims to recover latent noise-free two/three-dimensional (2D/3D) image data  from its noisy counterpart , where  denotes noise that is independent with respect to .
The denoising problem tends to be an ill-posed inverse problem as no unique solution exists. 
Denoising is an essential preprocessing step in many medical imaging applications. A vast number of methods have been proposed over the past decades~\cite{gal2009denoising,manjon2010adaptive,kaur2018review,sagheer2020review}, and recently, methods based on deep neural networks (DNNs) attract more attention due to their good performance~\cite{gondara2016medical,yang2018low,sharif2020learning,ma2020cycle,zhang2021plug}. 

For additive noise, it is possible to establish the Bayesian approach, where the posterior  is a combination of the data likelihood  and a prior model , i.e.:

The denoising problem Eq.~~\ref{eq:denoising1} can be also expressed as an optimization of a data term penalized by one or more regularization terms as follows:

where  denotes the -norm, .  poses penalty terms on the unknown latent  which is associated with the prior term  defined in Eq.~\ref{eq:denoising1}. 
 is a Lagrangian parameter, which can be determined manually or automatically~\cite{chan2011augmented,tiddeman2021principal}.
In general, the denoising methods can be divided into model- and learning-based categories. The model-based approach solves Eq.~\ref{eq:denoising2} using one or several regularization terms~\cite{getreuer2012rudin,mairal2009non,maggioni2012nonlocal,zhang2016statistical}. In the learning-based approach, a model can learn features with supervision~\cite{elad2006image,papyan2017convolutional} or it may learn the features simultaneously during image reconstruction~\cite{rai2021unsupervised}. 
Recently, the deep learning-based approaches~\cite{gondara2016medical,liu2018applications,li2021assessing} have reached excellent performance in denoising biomedical images by training DNNs on paired or unpaired images of target clean and noisy data. 
Despite the success of the existing denoising techniques, the contents of denoised images by such methods still suffer from poor preservation of texture and contrast. Requiring prior knowledge of noise and the lack of generalizability to various types of biomedical image data are other limitations of the current techniques. 

In this study, we propose an adversarial distortion learning-based (ADL) method that does not require any prior knowledge about the noise in images.
ADL is a supervised feature learning method that is comprised of a denoiser and a discriminator that iteratively optimizes each other to find high-quality denoised contents. Both the denoiser and the discriminator are built upon a novel network called Efficient-Unet. Efficient-Unet has a light architecture with pyramidal residual blocks backbone that enforces the higher-level features are in consonance with each other hierarchically. 
A remarkable feature of our approach is that it can be used for denoising any type of 2D/3D biomedical image data with no need for re-training. The light architecture of the proposed method allows a fast evaluation of test data and it considerably reduces the computational time of the conventional model-based approaches. 
The key contributions of this study are as follows:
\begin{itemize}
    \item We design a novel pyramidal learning scheme, named Efficient-Unet, to further participate high-level features in the output results during training. Efficient-Unet does not need training data whose distribution is close to that of the test data, so improving the generalizability of the proposed network.
    \item We introduce a novel pyramidal loss function using `algorithme Ã  trous' (ATW)~\cite{starck2007undecimated}. The proposed loss function keeps textural information of the reference data without amplifying noise's side effects in non-textured regions. 
    \item To preserve the histograms of reference images, we propose a novel histogram-based loss function for improving the appearance contents of denoised images.
    \item We provide both 2D and 3D networks of our method for denoising any sort of 2D/3D biomedical image data.
\end{itemize}
Experimental results show that the proposed ADL achieves state-of-the-art results on all the benchmarks alongside solving overfitting, generalizability to any sort of biomedical data, and computational burdens.
\section{Related Work}
Medical image denoising approaches can be grouped into two subcategories: model-based and learning-based methods. 
In the model-based approach, optimization of Eq.~\ref{eq:denoising1} with respect to the likelihood term only is typically ill-posed, so needs one or more regularization terms alongside the data fidelity term to find and stabilize the denoised outputs. 
Thus far, a wide range of model-based techniques have been developed, ranging from total variation (TV) regularizers~\cite{getreuer2012rudin,zhang2016statistical,sidky2008image} to non-local self-similarity regularizers~\cite{mairal2009non,dabov2007image,maggioni2012nonlocal,kong2017new,gal2009denoising,manjon2010adaptive,chen2019denoising}. 
TV-based regularization terms can successfully recover piecewise constant images but cause several artifacts to complex images with rich edges and textures. 
Since natural images tend to contain repetitive edge and textural information, combination of non-local self-similarity~\cite{mairal2009non,dabov2007image,maggioni2012nonlocal,kong2017new} with the sparse representation~\cite{papyan2017convolutional} and low-rank approximation~\cite{cai2014cine} lead to significant improvements over their local counterparts. 
The regularization terms play an important role in the quality of resultant denoised images. Despite the acceptable performance of the model-based methods in image denoising, there are still several drawbacks with these techniques. Requiring a specific model for a single denoising task, lack of generalizability to various types of data, or the need for manually or semi-automatically tuning parameters are the challenging that is still required to be addressed. Moreover, the non-local self-similarity-based methods iteratively optimize Eq.~\ref{eq:denoising2} so their convergence often needs considerable time.

A learning-based method aims at learning the parameters of a model with available datasets. Sparsity-based techniques are well-studied learning approaches, which represent local image structures with a few elemental structures so-called atoms from an off-the-shelf transformation matrix-like Wavelets~\cite{guleryuz2007weighted} or a learned dictionary~\cite{xu2012low,rai2021unsupervised}. 
In recent years, deep learning methods have been widely used for the enhancement of biomedical images, ranging from 
MRI~\cite{liu2018applications,stimpel2019multi}, CT~\cite{yang2018low,wu2020self}, X-ray~\cite{gondara2016medical}, to electron microscopy (EM)~\cite{quan2019removing,lee2021iscl}. 
The learning process of DNNs can be categorized into supervised~\cite{zhang2017beyond,sharif2020learning,liang2021swinir} or unsupervised~\cite{zhu2017unpaired,bera2021noise,lee2021iscl} approaches. 
Supervised learning DNNs consider clean and noisy image pairs for training where the noisy counterparts are obtained through adding synthesized noise to the target clean ones. 
To overcome the lack of availability of sufficient clean data for training, unsupervised methods~\cite{zhu2017unpaired,huang2020noise,lee2021iscl} have been developed that estimate the map of noise from unpaired images, leveraging the supervision of clean targets. 
Unsupervised techniques often explore the noise map by generative adversarial networks (GANs)~\cite{goodfellow2014generative} and its variants like conditional GAN~\cite{mirza2014conditional} or CycleGAN~\cite{zhu2017unpaired}. Typically, the supervised DNNs have shown superior performance over the unsupervised and conventional model-based approaches. 
Despite the great success of DNNs in denoising biomedical images, the contents of denoised images still suffer from poor textural information. 
Although several works~\cite{liang2021swinir,sharif2020learning} show less tendency toward overfitting and being data-driven, their performance is still highly dependent on the training samples. Since clean biomedical images for training are not available or available only in very limited quantities, this aspect of the current DNN techniques limits their generalizability to different sorts of biomedical images. 
\section{Proposed Method}\label{sec:proposed_preafce}
The intuition of ADL is that the representation of images must be robust against random phenomena like noise. ADL consists of a denoiser and a discriminator, where both have the same Unet-like architecture called \textit{Efficient-Unet}. There is some minor difference between the Efficient-Unet of the denoiser and that of the discriminator (Section \ref{sec:Efficient}). 
ADL is trained by minimizing competing multiscale objectives between the denoiser and the discriminator. During training, we enforce the networks on keeping the edges, histogram, and paramedical information of the reference/ground-truth data. The proposed loss functions are detailed in Section~\ref{sec:loss}.

\begin{figure*} 
\centering
    \includegraphics[width=0.85\textwidth]{framework.PNG}
\caption{Framework of the Efficient-Unet for denoiser with the training steps. Efficient-Unet is composed of the encoder, decoder, and Content Enhancer blocks. The output of the decoder at every scale is mapped into the image domain by a Transformer block. We then enforce consistency between the outputs of the decoder and their counterparts . Low-level features further contribute into the denoised image by the Content Enhancer block. When the noise level is low, the filters of this block are activated improving the convergence with no need for high-level features.
}
\label{fig:framework}
\end{figure*}

\subsection{Efficient-Unet}\label{sec:Efficient}
Let  (  for 2D) be the noise-free 3D (/2D) image data, and  the observed image data that is generated by adding WGN of standard deviation () to its noise-free counterpart . 
During training,  plays as a reference, noise level  is unknown, and the goal is to recover  from . Efficient-Unet and the training architecture for learning network parameters of the proposed denoiser is depicted in Fig.~\ref{fig:framework}. Efficient-Unet consists of an encoder, a bridge, a decoder, a content enhancer, and transformers. Similarly, the framework of Efficient-Unet for the discriminator is depicted in Fig.~\ref{fig:frameworkdisc}.

The \textit{encoder} unit is comprised of three consecutive residual blocks with strides one and two (denoted by  in Fig.~\ref{fig:framework}) that extracts the features from the observed data. 
The number of filters in the encoder layers is doubled after each downsampling operation (i.e., ). Several studies\cite{he2016deep,zhang2017beyond,sharif2020learning} have shown the effectiveness of residual blocks in deep learning. We use the residual blocks in our auto-encoder structure for effective denoiser prior modeling. To have large activation maps, we delayed the downsampling of the first layer, where its stride is 1. 
The extracted features by the encoder are then passed through a bridge with  filters followed by the decoder unit that provides an estimation of the denoised input data  in the feature domain. The features of each decoder layer are mapped into the image domain by the \textit{transformer} unit  where  is the index of the corresponding layer. 
The transformer unit is a set of  residual blocks followed by a  convolution and a sigmoid activation layers. The number of filters in the transformer layers is halved  times\footnote{For example, the filter size of the residual block in  is . Similarly, we have  for the residual blocks in .} and the filter size of  convolution layer is equal to , which is the number of input channels. Throughout this paper, the kernel size and dilation of the convolutional layers are 3 and 1, respectively, unless otherwise noted. 

\begin{figure*} \centering
    \includegraphics[width=0.72\textwidth]{frameworkDisk.PNG}
\caption{Framework of the proposed Efficient-Unet for discriminator with the training steps.}
\label{fig:frameworkdisc}
\end{figure*}


Thus far, the only difference between the Efficient-Unet of the denoiser and that of the discriminator is the filter size of convolution layers, i.e. . 
It is set as  for the denoiser and  for the discriminator.
The discriminator network needs a lower number of learning parameters compared to the denoiser because the discriminator is a classifier that computes the loss for misclassifying a noise-free instance as noisy or a noisy instance as noise-free. Since the discriminator is a classifier, the output of each transformer is mapped into a binary mask by a \textit{mapper} which is shown in Fig.~\ref{fig:frameworkdisc}. The mapping layer is comprised of convolution layers with a filter size of 1 followed by a sigmoid activation layer to map the input to a binary mask. 
The denoiser has also one extra unit called \textit{content enhancer} and it is designed to preserve the sparse information like edges and textures that are not or less affected by noise. 
As shown in Fig.~\ref{fig:framework}, the content enhancer is a residual block, wherein the first layer extracts features by three different dilation values, . Several studies~\cite{ghahremani2020ffd,starck2007undecimated} have shown that the structural information, which is mainly edges and textures, exists at different scales. So we consider three convolutions of strides 1, 2, and 4 to extract such features from the input noisy data directly. In the absence of noise, this unit has more activated layers. The content enhancer layer is concatenated by the last layer of the decoder before feeding . The denoised data  is the output of layer , shown by a blue rectangle in Fig.~\ref{fig:framework}. It is also worth mentioning that the bias parameter in the proposed Efficient-Unet is deactivated since bias-free networks increase the linearity property by canceling the bias parameter\footnote{In~\cite{mohan2019robust}, it is shown that for any input  and any non-negative constant , we have  is equal to  if the feed-forward network uses ReLU as the activation function with no additive constant terms (bias) in any layer.}~\cite{mohan2019robust}. Moreover, when the magnitude of the bias is much larger than that of filters, the generalizability of the model is limited so less prone to overfitting~\cite{zhang2021plug}.


\subsection{Multiscale loss functions}\label{sec:loss}
ADL consists of two auto-encoders: a denoiser  and a discriminator . 
Generally, the parameters of adversarial nets are optimized by minimizing a two-player game in an alternating manner~\cite{goodfellow2014generative}:

Denoiser  aims to estimate a clean image while discriminator  distinguishes between reference  and denoised  instances. Eq. \eqref{eq:GD} does not maintain textural, global, and local data representation. 
To this end, we propose novel multiscale loss functions for both the denoiser and the discriminator. 
We minimize the loss of denoiser from coarse to fine resolution for enforcing the participation of the decoder's features in the resultant high-resolution denoised image. Likewise, we enforce the discriminator network to discriminate the target and the denoised images from bottom to top. 
Moving from coarse resolution towards fine one enhances structural features at the corresponding resolution, resulting in rich edge and textural information in the denoised data. 
\subsubsection{Denoiser's loss function ()}
We define the loss function of the denoiser as a combination of an  loss (denoted by ), a novel pyramidal textural loss , and a novel histogram loss  that are weighted by , , and , respectively:

\begin{itemize}
    \item[] : The data fidelity is an -norm between the denoised and reference instances. Compared to the -norm, the -norm is more robust against outliers.
\item[] : The pyramidal textural loss aims at preserving edges and texture in to-be-denoised images. Unlike the conventional edge-preserving regularization terms like TV and its variants~\cite{papafitsoros2014combined,wang2019structural} that compute the differential of given noisy images, our goal is to measure the textural difference between to-be-denoised images and their corresponding reference only. 
    Traditional TVs use first-, second- or higher order-based derivative operators to filter noisy images. The main drawback of such operators is to boost the pixels with high-level noise so it may bias the loss towards dominant values. 
    For this reason, the images denoised by TV-like regularisation terms are often accompanied by smoothness in both textural and non-textural regions. 
    To cope with this problem, we introduce a pyramidal loss function using ATW~\cite{starck2007undecimated}. ATW is a stationary Wavelet transform that decomposes an image into several levels by a cubic spline filter and then subtracts any two successive layers to obtain fine images with edges and texture. 
    The low-pass filters in ATW alleviate the side effects of noise so it enables us to include texture information of input images in the loss function. 
    Fig.~\ref{fig:atw} briefs ATW. In short, it decomposes an input image into  levels by a cubic spline finite impulse response that is denoted by . Unlike the non-stationary multiscale transforms that downscale the images and then apply a filter, ATW upscales the kernel by inserting `' zeros  between each pair of adjacent elements in , where  denotes the -th decomposition level. 
    Fine images with texture and edges are derived via subtraction of any two successive filtered images. Further details can be found in~\cite{starck2007undecimated,ghahremani2020ffd}. 
    In Eq.~\ref{eq:loss-denoiser}  denotes the textural image at the -th level derived by ATW.  is a positive integer that denotes the number of decomposition levels. Typically, four decomposition levels () have been able to extract the majority of edges and texture laid in a wide range of sigma values~\cite{ghahremani2020ffd}. 
\item[] : The histogram loss assures that the histograms of  and  are close to each other. This term maintains the global structure of  with respect to  since the added edges and texture information (by ATW) may change the overall histogram of the denoised instance. To compute this loss, we first compute the histogram of both  and  denoted by . Then, we use an strictly increasing function that computes the loss between  and . To this end, we use `' that is approximately equal to  for small  and to  for large \footnote{If the number of color channels is more than one, i.e. , we first compute the histogram loss between corresponding channels and then take the average of losses as the final histogram loss.}. It is worth noting that here we use the histogram loss for preserving the global structure between the denoised image and its reference, and this is different from other histogram works like~\cite{zuo2013texture,talebi2021projected}. In \cite{zuo2013texture}, a gradient histogram is used for texture preservation, and Delbracio~\etal~\cite{talebi2021projected} proposed a DNN-based histogram as a fidelity term.
\end{itemize}
In Efficient-Unet, features at fine-resolution maps are reconstructed from its coarser ones (Fig.~\ref{fig:framework}). Thus, an inefficiency in coarser spatial scales (or equivalently, higher-level feature maps) may yield poor resultant feature maps. To cope with this problem, we propose a pyramidal version of the loss function defined in Eq.~\ref{eq:loss-denoiser} that keeps the consistency between  and its counterpart  at each spatial scale. To compute the proposed multiscale loss, we generalize the transformer unit, introduced in Section~\ref{sec:Efficient}, to lower spatial scales (here, two scales  and ) and then get the corresponding denoised image data. Then, we compute the loss function presented in Eq.~\ref{eq:loss-denoiser} at every scale and finally take an average of the losses to yield the denoiser loss:
 
where superscript  denotes the scale of the data pyramid and the total number of scales is set to 3 in the study. 
\subsubsection{Discriminator's loss function ()} Most discriminators are based on an encoder that determines whether the input instance is fake or real. Schonfeld \etal~\cite{schonfeld2020u} have shown that using an Unet structure for discriminator could increase the performance of the generator (here, the denoiser). Borrowed the same concepts from~\cite{schonfeld2020u} and similar to Eq.\ref{eq:loss-denoisermulti}, we propose the following loss function for the discriminator (see Fig.~\ref{fig:frameworkdisc}):

where  is the bridge loss and it is defined as 

Here, subscripts  denote discriminator decision at pixel . Likewise,  in Eq.~\ref{eq:loss-discmulti} is defined as follows:

\begin{figure}
    \centering
    \includegraphics[width=0.35\textwidth]{atw.PNG}
\caption{ATW decomposition for image data. Since 2D kernel  is separable, the ATW decomposition for 3D image data is obtained by convolving three 1D cubic kernels in the x, y, and z directions. ATW is comprised of inherently low-pass filters that attenuate the side effects of noise.}
\label{fig:atw}
\end{figure}
\subsection{Training details}\label{sec:implementation}
We implemented ADL for both 2D and 3D data. To show the generalizability of the denoiser, we trained the 2D model on ImageNet~\cite{russakovsky2015imagenet}, whose data distribution is different from that of biomedical images. 
The training and the validations sets contain 1,281,168 and 50,000 images of size , respectively. 
The denoiser model was trained on color and gray-scale images separately. We augmented the data by rotation, , and flips. 
We added zero-mean WGN to input images with  that was randomly selected in interval [0,55]. 
The noisy images were not clipped into the interval [0,255], making sure that the distribution of added noise was still WGN. 
The 3D model was trained on the IXI Dataset~\footnote{\url{https://brain-development.org/ixi-dataset}}, containing approximately 570 8-bit T1, T2 and PD-weighted MR images acquired at three different hospitals in London: Hammersmith Hospital using a Philips 3T system, Guyâs Hospital using a Philips 1.5T system, and Institute of Psychiatry using a GE 1.5T system. 
The size of MRI volumes is 256256, where .
We randomly cropped the volumes into sub-volumes of 12812848 to facilitate the training. 
we added zero-mean white Gaussian (), Rician ( and ), and Rayleigh () noise to input MRI volumes. Likewise to the 2D training, the values of the parameters in the above-mentioned intervals were randomly selected . 
We used the Adam algorithm~\cite{kingma2014adam} as an optimizer with the \textit{ReduceLRonPlateau} scheduler~\cite{ReduceLROnPlateau}. The optimization started with a learning rate of  and it was reduced (by the ReduceLRonPlateau scheduler) until the PSNR of validation has stopped improving. 
The 
weights in Eq.~\ref{eq:loss-denoisermulti}, i.e. , , , were set to 1.

\textbf{Reproducibility}: The reference implementation of ADL is based on TensorFlow. All the experiments were conducted on 4 A-100 GPUs. 
The implementation and pre-trained models are available at \url{https://github.com/mogvision/ADL}. We also provided PyTorch and Colab implementation of ADL on the GitHub.
\renewcommand{\tabcolsep}{2.5pt}
\begin{table*}
\caption{PSNR (dB) and SSIM results (average  standard deviation) of different method on the image-based datasets for noise levels 10, 15, 25, 35, 50. The best and second best results are highlighted in \textbf{boldface} and in \textit{italic}, respectively.} 
    \label{table:psnr}
\centering 
\begin{tabular}{lcccccccccccccc} \toprule
    \multirow{3}{*}{
    \parbox[c]{.05\linewidth}{\centering Dataset}}&
    \multirow{3}{*}{
    \parbox[c]{.05\linewidth}{\centering Noise\\Level}}
    &&& \multicolumn{1}{c}{PSNR	} &&
    &&&&\multicolumn{1}{c}{SSIM	} \\ 
    \cmidrule{3-7} \cmidrule{9-13}
 && \multicolumn{1}{c}{BM3D} & \multicolumn{1}{c}{DRAN} & \multicolumn{1}{c}{DnCNN-S} & \multicolumn{1}{c}{SwinIR} & \multicolumn{1}{c}{ADL} & & \multicolumn{1}{c}{BM3D} & \multicolumn{1}{c}{DRAN} & \multicolumn{1}{c}{DnCNN-S} & \multicolumn{1}{c}{SwinIR} & \multicolumn{1}{c}{ADL}\\
  && \multicolumn{1}{c}{\cite{makinen2020collaborative}} & \multicolumn{1}{c}{\cite{sharif2020learning}} & \multicolumn{1}{c}{\cite{zhang2017beyond}} & \multicolumn{1}{c}{\cite{liang2021swinir}} & \multicolumn{1}{c}{(ours)} & & \multicolumn{1}{c}{\cite{makinen2020collaborative}} & \multicolumn{1}{c}{\cite{sharif2020learning}} & \multicolumn{1}{c}{\cite{zhang2017beyond}} & \multicolumn{1}{c}{\cite{liang2021swinir}} & \multicolumn{1}{c}{(ours)}\\
\toprule
& 10 & 37.41.3 & 37.51.1 & 381.4 & \textit{38.41.4} & \textbf{38.81.3}&& 0.910.02 & \textit{0.930.02} & 0.910.02 & 0.920.02 & \textbf{0.950.02}\\
& 15 & 35.91.3 & 36.91.4 & 35.81.7 & \textit{37.11.4} & \textbf{37.51.3} && 0.900.03 & 0.910.03 & 0.910.03 & \textit{0.920.02} & \textbf{0.940.02}\\
\verb//HAM10000~\cite{DBW86T_2018}& 25 & 34.41.5 & 34.51.5 & 34.91.6 & \textit{35.51.6} & \textbf{36.11.4}
&& 0.880.03 & 0.850.04 & 0.860.04 & \textit{0.900.03} & \textbf{0.930.02}\\
& 35 & 33.41.6 & 32.61.5 & 33.91.7 & \textit{34.81.7} & \textbf{35.21.5} && 0.850.04 & 0.820.05 & 0.840.05 & \textit{0.860.05} & \textbf{0.930.02}\\
& 50 & 32.31.6 & 30.51.9 & 31.21.8 & \textit{33.6}1.7 & \textbf{34.21.6} && 0.850.04 & 0.810.05 & 0.820.05 & \textit{0.870.04} & \textbf{0.920.03}\\
\midrule
& 10 & 38.6 1.1 & 38.61.6 & 38.81.1 & \textit{38.91.2} & \textbf{39.61.1} && 0.940.02 & \textit{0.950.02} & 0.940.02 & \textbf{0.960.02} & \textbf{0.960.02}\\
& 15 & 37.61.1 & 37.91.8 & 38.51.2 & \textbf{38.71.2} & \textit{38.61.2} && 0.930.02 & 0.940.03 & 0.930.02 & \textbf{0.940.02} & \textbf{0.940.02}\\
\verb//Chest X-Ray~\cite{kermany2018identifying}& 25 & 35.40.9 & 36.51.7 & 35.81 & \textit{36.91.1} & \textbf{37.11.2} && 0.910.02 & 0.920.04 & 0.920.02 & 0.920.02 & \textbf{0.930.02}\\
& 35 & 33.80.9 & 351.8 &34.50.9 & \textit{35.11} & \textbf{35.71.1} && 0.890.02 & 0.900.04 & 0.900.02 & \textit{0.910.03} & \textbf{0.920.03}\\
& 50 & 32.10.7 & 32.71.8 & 32.91 & \textit{34.11.1} & \textbf{34.41.2} && 0.870.03 & 0.890.05 & 0.880.03 & \textit{0.900.03} & \textbf{0.910.03}\\
\midrule
& 10 & 30.50.3 & 31.20.5 & 31.10.3 & \textit{310.3} & \textbf{31.50.3} && 0.910.02& 0.910.03 & 0.890.01 &  0.910.03 & \textbf{0.930.02}\\
& 15 & 28.20.3 & 290.5 & 28.90.3 & \textit{29.10.3} & \textbf{29.30.3} && 0.850.02 & \textit{0.870.02} & 0.860.01 & \textit{0.870.02} & \textbf{0.880.01}\\
\verb//EM~\cite{isbi2021}& 25 & 25.60.4 & 26.50.6 & 26.30.4 & \textit{26.60.4} & \textbf{270.4} && 0.760.03 & \textit{0.790.04} & 0.780.03 & \textit{0.790.02} & \textbf{0.800.02}\\
& 35 & 240.4 & 24.90.5 & 24.70.4& 2\textit{50.5} & \textbf{25.30.4} && 0.690.04 & 0.740.04 & 0.720.03 & \textit{0.730.03} & \textbf{0.750.03}\\
& 50 & 22.40.5&22.80.6& 23.20.5& \textit{23.30.6} & \textbf{23.70.5} && 0.610.04 & \textit{0.660.04} & 0.650.03 & \textit{0.660.03} & \textbf{0.680.03}\\
\bottomrule
\end{tabular}
\end{table*}

\section{Experimental Results}\label{sec:experimental}
\textbf{Datasets}: We used five biomedical imaging datasets from different modalities (3D brain and knee MRI), EM, X-ray, and dermatoscopy to evaluate our model. The datasets are summarized below and an example image from each dataset is shown in Fig.~\ref{fig:datasets}.  Note that our method was trained on data fully independent (ImageNet for 2D and IXI for 3D) on these five test datasets and the training set was used for training of the competing deep learning techniques.

\begin{itemize}
    \item \textbf{BrainWeb} database (3D)~\cite{cocosco1997brainweb} contains simulated 3D brain MRI based on healthy and multiple sclerosis (MS) anatomical models. MRI volumes have been simulated modelling three pulse sequences (T1-, T2- and PD-weighted), five slice thicknesses (1, 3, 5, 7, and 9 mm; pixel size is 1 mm), clean and noisy samples with five levels of Rician noise (1\%, 3\%, 5\%, 7\%, 9\%), and three levels of intensity non-uniformity (INU) 0\%, 20\%, and 40\%. In total, this results in 30 reference (clean, no INU) and 510 noisy MRI volumes of size 181217, where  depending on slice thickness. 
    \item The NYU \textbf{fastMRI} Initiative database (fastmri.med.nyu.edu) (3D) ~\cite{zbontar2018fastmri} contains PD-weighted knee MRI scans with and without fat suppression with in-plane size  and the number of slices varying from 27 to 45. We randomly sampled 200 volumes from the database for evaluation.
    \item \textbf{MitoEM Challenge} ~\cite{isbi2021} contains multibeam scanning EM volume taken from Layer II in temporal lobe of adult human. The volume was 1000  4096  4096  with the voxel size of 30nm  8nm  8nm. Due to large slice separation, we considered slices as 2D images, resized them to 2048  2048 to reduce noise and sampled  non-overlapping patches - 4,008 for training and 646 for test.
    \item \textbf{Chest X-ray} database ~\cite{kermany2018identifying} contains routine clinical images (anterior-posterior, ) from pediatric patients (healthy, pneumonia) of one to five years old from Guangzhou Women and Childrenâs Medical Center, Guangzhou. The dataset was split into 5,232 training and 624 test images. 
    \item \textbf{The HAM10000 }~\cite{DBW86T_2018} database contains 10,015 dermatoscopic RGB images () of pigmented skin lesions from different populations, acquired and stored by different modalities. We set the training/test set ratio to 80\%-20\% .
\end{itemize}

\begin{figure}\centering
    \includegraphics[width=0.35\textwidth]{datasets2.PNG}
\caption{A sample of each dataset used for evaluation in this study. From top to bottom and left to right: 3D Brain MRI~\cite{cocosco1997brainweb}, 3D knee MRI~\cite{zbontar2018fastmri}, EM~\cite{isbi2021}, chest X-ray~\cite{kermany2018identifying}, and dermatoscopic RGB~\cite{DBW86T_2018}.}
\label{fig:datasets}
\end{figure} 

\begin{figure*}
    \centering
    \subfigure[HAM10000 Dermatoscopic RGB]{
        \centering
        \includegraphics[width=0.81\textwidth]{2d_b.PNG}
        \label{fig:2dskin}
    }
    \subfigure[Chest X-Ray]{
        \centering
        \includegraphics[width=0.81\textwidth]{2d_a.PNG}
        \label{fig:2dchest}
    }
    \subfigure[EM]{
        \centering
        \includegraphics[width=0.81\textwidth]{2d_c.PNG}
        \label{fig:2dssTEM}
    }
\caption{Color and gray-scale image denoising results
on a) skin, b) chest, and c) EM images with noise level 35. From left to right: Reference, noisy, BM3D, SwinIR, and the proposed ADL.}
\label{fig:visual2D}
\end{figure*}For 2D databases, we compared the proposed ADL to improved BM3D~\cite{makinen2020collaborative}\footnote{\url{https://pypi.org/project/bm3d/}} as the conventional model-based method, and three deep learning-based methods, Dynamic Residual Attention Network (DRAN)~\cite{sharif2020learning}, DnCNN-S~\cite{zhang2017beyond}, and recently-developed SwinIR~\cite{liang2021swinir}. We compared the 3D version of our model to BM4D~\cite{maggioni2012nonlocal} that is widely used for denoising 3D biomedical image data.

\subsection{Experiments with 2D data with synthetic noise}
Synthesised WGN with  were added into the test images of the skin~\cite{DBW86T_2018}, chest~\cite{kermany2018identifying}, and EM~\cite{isbi2021} datasets. The PSNR (dB) and SSIM results for different methods are represented in Table~\ref{table:psnr}.
According to the PSNR and SSIM results, one can see that the deep learning techniques yield better results compared to the model-based BM3D. The results of ADL are on par with those of the other methods, and it outperforms the other competing methods by a large margin for almost any noise level.
The standard deviation measures the compactness of the denosing results.
Although our method was not trained on the training sets (see Section~\ref{sec:experimental}), its PSNR's standard deviation are on par with the conventional techniques' ones. The SSIM results report that ADL gained the most compact results over all the noise levels. 
Fig.~\ref{fig:visual2D} shows a denoising example of different methods on the 2D datasets with noise level 35. To save space, we only show the results of model-based BM3D and SwinIR as SwinIR was the best one among the competing deep learning-based techniques. The example images are accompanied by profile lines.
In the HAM10000 dataset (see Fig.~\ref{fig:2dskin}),  ADL could recover much sharper edges than BM3D and SwinIR while maintaining the contrast of the reference image. The RGB profile lines of ADL have the highest similarity with the reference ones while the competing methods failed to preserve the contrast.

\begin{figure*}\centering
        \centering
        \includegraphics[width=0.8\textwidth]{BW3Dvisual.PNG}
        \label{fig:visualmri}
\caption{Denoising results of BM4D and the proposed ADL on the BrainWeb data with noise level 9 and RF 40\%. From left to right: Reference, noisy, BM4D, and proposed ADL.}
\label{fig:visualcomp3d}
\end{figure*}In the Chest X-Ray dataset (Fig.~\ref{fig:2dchest}), although the profile lines of all the methods were highly correlated to the reference one, ADL preserved more textural information compared to the others. BM3D resulted in blurred texture regions and SwinIR smoothed out the bones while the proposed ADL recovered more fine details and textures.
The same trend is seen in the EM results depicted in Fig.~\ref{fig:2dssTEM}, where SwinIR yielded a toy-like result and BM3D blurred the borders. The smoothness of BM3D and SwinIR is apparaent in their profile lines while the profile line of ADL tracked the reference one tightly. This means that ADL could successfully preserve the contrast and edges of the reference. 




\begin{figure}\centering
    \includegraphics[width=0.5\textwidth]{BW3D.PNG}
\caption{Average PSNR(dB) and SSIM of BM4D~\cite{maggioni2012nonlocal} and the proposed ADL on the BrainWeb database~\cite{cocosco1997brainweb}.}
\label{fig:mri3d}
\end{figure} 



\begin{table}\caption{PSNR (dB) and SSIM results (average  standard deviation) of BM4D~\cite{maggioni2012nonlocal} and the proposed ADL on the 3D MRI knee dataset~\cite{zbontar2018fastmri} for noise levels 10, 15, 25, 35, 50. The best results are highlighted in \textbf{boldface}.} 
    \label{table:resultslnee}
\centering 
\begin{tabular}{lcccccccc} \toprule
    \multirow{3}{*}{
    \parbox[c]{.04\linewidth}{\centering Dataset}}&
    \multirow{3}{*}{
    \parbox[c]{.09\linewidth}{\centering Noise\\Level}}
    & \multicolumn{2}{c}{PSNR} &
    &\multicolumn{2}{c}{SSIM} \\ 
    \cmidrule{3-4} \cmidrule{6-7}
 && \multicolumn{1}{c}{BM4D} & \multicolumn{1}{c}{ADL} & & \multicolumn{1}{c}{BM4D} &  \multicolumn{1}{c}{ADL}\\
  && \multicolumn{1}{c}{\cite{maggioni2012nonlocal}} &  \multicolumn{1}{c}{(ours)} & & \multicolumn{1}{c}{\cite{maggioni2012nonlocal}} & \multicolumn{1}{c}{(ours)}\\
\toprule
& 10 & 37.11.8 &\textbf{38.31}  && 0.890.04  & \textbf{0.920.02}\\
& 15 & 35.91.6 &\textbf{36.91.1}  && 0.870.05  & \textbf{0.900.03}\\
\verb//fastMRI~\cite{zbontar2018fastmri}& 25 & 34.31.4 & \textbf{35.11.1} && 0.850.05 & \textbf{0.890.03}\\
& 35 & 33.11.2 &\textbf{34.11} && 0.820.04 & \textbf{0.880.03}\\
& 50 & 31.51.1 &\textbf{33.10.9} && 0.780.04  & \textbf{0.860.04}\\
\bottomrule
\end{tabular}
\end{table}


\subsection{Experiments with 3D data with synthetic noise}
Similarly to the 2D experiment, synthesised WGN with  were added into the test images in the fastMRI~\cite{zbontar2018fastmri} dataset. The quantitative results are tabulated in Table~\ref{table:resultslnee}.
The noise in the simulated BrainWeb images has Rayleigh statistics in the background and Rician statistics in the signal regions. 
The average PSNR (dB) and SSIM results of the BM4D and the proposed ADL on the BrainWeb database are plotted in Fig.~\ref{fig:mri3d}. 
ADL was able to reduce the noise effects to a greater extent as compared to BM4D. 
The results of both the databases verify the high performance of ADL in noise and RF distortion removal. 
Fig.~\ref{fig:visualcomp3d} provides a comparison of the visual results of BM4D and ADL on a noisy T2-weighted image of BrainWab with noise level of 9 and RF 40\%. From the appearance perspective, ADL preserved the histogram better than BM4D. Since the edges are blur in the BM4D result, in particular the zoom region, ADL restored the texture successfully. In short, the results of 3D are in consonance with 2D results and ADL well restored both the appearance and texture information. 
\subsection{Experiments with noisy data with no reference}
We experimented the denoising with a T1-weighted brain MRI from OASIS3-project~\cite{Oasis3}, selected randomly (male, cognitively normal, 87 years), and with a high-resolution EM dataset from rats' corpus callosum~\cite{abdollahzadeh2021deepacson}. 
The input noisy images, the denoised results by ADL, and the histogram of images are depicted in Fig.~\ref{fig:norefEM}. Both the denoised results and the histogram plots verify that ADL successfully denoised the noisy images and preserved structural information with high precision.

\begin{figure*}
    \centering
    \subfigure[Brain MRI]{
        \centering
        \includegraphics[width=0.7\textwidth]{norefBrain.PNG}
        \label{fig:norefBrain}
    }
    \subfigure[EM]{
        \centering
        \includegraphics[width=0.7\textwidth]{norefEM.PNG}
        \label{fig:norefEM}
    }
\caption{ADL results on no-reference noisy images. From left to right: noisy, ADL, and histograms of the input noisy and the denoised image.
}
\label{fig:noref}
\end{figure*}




\subsection{Computational complexity} Table~\ref{table::runningTime} reports the running time of the methods. The size of data for 2D and 3D experiments is  and , respectively. For 2D data, our denoiser needs less than 5  parameters which is much lower than 11.9 of SwinIR. ADL also needs 2 FLOPs which is considerably lower than that of SwinIR. 
For this reason, we named the proposed Unet as Efficient-Unet. For 3D data, Our denoiser does not require the cumbersome calculation of BM4D and this characteristic of our method is more appealing for real-time applications.
\renewcommand{\tabcolsep}{4pt}\begin{table}\begin{minipage}[h]{1.\linewidth}
    \centering
    \caption{Computational complexity and running time of different methods over 256256 2D and 256256256 3D MRI data.}
    \label{table::runningTime}
    \begin{tabular}{clcccc} 
    \toprule
    &\multirow{2}{*}{Method}
            &{Model Parameters}
                &{FLOPs }
                        &{Running Time }\\
                        &&() & ()& \\
                             \midrule \multirow{2}{*}{2D}&
    \verb//{SwinIR~\cite{liang2021swinir}}&11.9&71.2&539 \\
    &\verb//{ADL (ours)}&4.75&2.1&143 \\
    \midrule
    \multirow{2}{*}{3D}&
    \verb//{BM4D}~\cite{maggioni2012nonlocal}&-&-&597.6  \\
    &\verb//{ADL (ours)}&14.8&121& 14.6 \\
    \bottomrule
    \end{tabular}
    \end{minipage}
    \vspace{0.00mm}
\end{table}


\begin{figure}
\centering
    \includegraphics[width=0.3\textwidth]{validation_PSNR.png}
\caption{PSNR (dB) results of ADL for the validation using different loss functions. The results are averaged over noise levels 10, 15, 25, 35, and 50.}
\label{fig:ablationPSNR}
\end{figure}\subsection{Ablation study}
\textbf{Multiscale loss functions}: Fig.~\ref{fig:ablationPSNR} compares the performance of ADL for different loss functions. The average PSNR results on the validation dataset when 
is reported here. 
It is seen that the pyramidal loss function considerably enhanced PSNR. This scheme was further improved by adding the histogram loss into the training.

\textbf{Content Enhancer block}: As described in Section~\ref{sec:Efficient}, this block contributes to the denoising process directly when the depth of noise is low. In other words, the aim of the Content Enhancer block is to alleviate the vanishing-gradient problem in DNNs when the input noise is low, so it improves the convergence pace. 
We plotted the response of a few filters in the Content Enhancer block in Fig.~\ref{fig:ablationfig}. We also reported the correlation between the filer responses and the denoised images by ADL. It is worth noting that the filter responses for edges and texture are not reported here because it is not straightforward to measure the texture similarity between the edge-oriented filters and the denoised contents. For noise levels less than 10, one can observe that filters' responses are highly correlated to the denoised contents and this scheme is reduced by increasing the level of AWGN noise. It can be referred from the results that the filters of the Content Enhancer block are highly contributed to the denoised content when the level of noise is small. 
Since the ADL outcomes remained almost unchanged over high-level noise, we deduce that the network switched to the decoders' filters in this condition.
\begin{figure}
    \centering
    \includegraphics[width=0.3\textwidth]{Filters.PNG}
    \includegraphics[width=0.27\textwidth]{corr.png}
\caption{Performance of the \textit{Content Enhancer} block in the Efficient-Unet for different noise levels. Top: Visual comparison of the response of few filters. Bottom: The correlation between the response of the filters and the ADL outcome.}
\label{fig:ablationfig}
\end{figure}

\section{Conclusion}\label{sec:conclusion}
In this study, we have proposed a novel adversarial distortion learning technique, named ADL, for efficiently restoring images from noisy and distorted observations.
The key idea is to design an auto-encoder called Efficient-Unet that preserves texture and appearance during distortion removal.
Efficient-Unet is based on a hierarchical approach in which low-level features are highly dependent on high-level ones. This enforces the model to restore the images from coarse to fine scales. To alleviate the vanishing-gradient problem and to improve the convergence pace, we added the Content Enhancer block to Efficient-Unet. The proposed model has been implemented for both 2D and 3D image data.
For training the ADL's parameters, we have proposed a pyramidal loss function for preserving textural information in different scales.
We have also introduced a histogram loss to keep the appearance of the denoised contents. Experimental results and a comparative study with the conventional techniques over several publicly accessible 2D and 3D datasets have shown that ADL can restore more accurate images in the shortest time, which makes it more suitable for real-time applications.

\subsection*{Acknowledgment}
We acknowledge the HPC resources by Bioinformatics Center, University of Eastern Finland.
Data were provided in part by OASIS-3: PIs: T. Benzinger, D. Marcus, J. Morris; NIH P50 AG00561, P30 NS09857781, P01 AG026276, P01 AG003991, R01 AG043434, UL1 TR000448, R01 EB009352.



{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}
\end{document}