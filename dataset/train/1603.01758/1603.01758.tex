\documentclass[11pt,a4paper]{amsart}
\usepackage{fullpage}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage{enumerate}


\usepackage{listings}
\usepackage[dvipsnames]{xcolor}
\lstset{language=Haskell,
                basicstyle=\ttfamily,
                keywordstyle=\color{blue}\ttfamily,
                stringstyle=\color{red}\ttfamily,
                commentstyle=\color{Gray}\ttfamily,
                morecomment=[l][\color{magenta}]{\#}
}

\usepackage{eqnarray, amstext}
\usepackage{qsymbols,xparse}
\usepackage{algpseudocode}
\usepackage[Algorithm,ruled]{algorithm}
\usepackage{nicefrac}

\newcommand\ie{\emph{i.e.}\ }
\newcommand\eg{\emph{e.g.}\ }
\newcommand\etc{\emph{etc.}}

\usepackage{syntax}
\renewcommand{\syntleft}{}
\renewcommand{\syntright}{}

\usepackage{caption}
\captionsetup[algorithm]{labelformat=empty}
\renewcommand{\algorithmicrequire}{\textbf{Input:}} 
\renewcommand{\algorithmicensure}{\textbf{Output:}} 

\usepackage{needspace}

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{cor}[theorem]{Corollary}
\newtheorem{example}[theorem]{Example}

\newcommand{\KExpansions}[1]{\textsc{K-Expansions}(#1)}
\newcommand{\SExpansions}[1]{\textsc{S-Expansions}(#1)}
\newcommand{\RewritingSet}[2]{\textsc{RewritingSet}(#1,#2)}
\newcommand{\MeshSet}[2]{\textsc{MeshSet}(#1,#2)}
\newcommand{\potential}[1]{\pi(#1)}
\newcommand{\rank}[1]{\rho(#1)}
\newcommand{\gammaF}[1]{\Gamma(#1,1)}

\begin{document}

\title{Normal-order reduction grammars}
\author{Maciej Bendkowski}
\address{
  Theoretical Computer Science Department\\
  Faculty of Mathematics and Computer Science\\
  Jagiellonian University\\
  ul. Prof. {\L}ojasiewicza 6, 30-348 Krak\'ow, Poland}
\email{bendkowski@tcs.uj.edu.pl}
\thanks{This work was partially supported within the grant 2013/11/B/ST6/00975
            founded by the Polish National Science Center.} 

\maketitle

\begin{abstract}
We present an algorithm which, for given , generates an unambiguous regular tree grammar defining the set of combinatory logic terms, over the set  of primitive combinators, requiring exactly  normal-order reduction steps to normalize. As a consequence of Curry and Feys's standardization theorem, our reduction grammars form a complete syntactic characterization of normalizing combinatory logic terms. Using them, we provide a recursive method of constructing ordinary generating functions counting the number of -combinators reducing in  normal-order reduction steps. Finally, we investigate the size of generated grammars, giving a primitive recursive upper bound.
\end{abstract}

\section{Introduction}

Since the time of the pioneering works of Moses SchÃ¶nfinkel~\cite{schonfinkel} and Haskell Curry~\cite{curry}, combinatory logic is known as a powerful, yet extremely simple in structure, formalism expressing the notion of computability. With the dawn of functional programming languages in the early 1970s,
combinatory logic, with its standard normal-order reduction scheme~\cite{curry-feys1958}, is used as a practical implementation of
lazy semantics in languages such as SASL~\cite{turner1979} or its successor
Miranda~\cite{turner1986}. Lack of bound variables in the language resolves
the intrinsic problem of substitution in \mbox{-calculus}, making the reduction relation a simple computational step and so, in consequence, the leading workhorse in implementing call-by-need reduction schemes.

Surprisingly, little is known about the combinatorial properties of normal-order reduction and, in particular, its behaviour in the `typical' case of large random combinators. With the growing popularity of random software testing (see, \eg \cite{DBLP:conf/icse/PalkaCRH11}) `typical' properties of random -terms and combinators became of immense practical importance. In this approach to software verification, large random terms are generated and used to check the programmer-declared function invariants, making it crucial to understand and exploit the semantic properties of so generated terms. 

State-of-the-art research in this field includes counting and generating -terms (see \eg~\cite{DBLP:journals/jfp/GrygielL13}~\cite{DBLP:journals/corr/Lescanne14}~\cite{DBLP:conf/stacs/GittenbergerG16}), their restricted classes~\cite{1510.01167}, investigating their asymptotic properties~\cite{lmcs:848}~\cite{Bendkowski2016} as well as the asymptotic properties of combinatory logic~\cite{Bendkowski2015}. 

Main tools used in this line of research include formal power series and generating functions. Interested in a particular counting sequence  corresponding to a set of terms , we construct a suitable generating function, which treated as a complex function in one variable  yields a Taylor series expansion around  with coefficients forming our sequence . Methods of analytic combinatorics~\cite{Flajolet:2009:AC:1506267} allow us to derive, sometimes surprisingly accurate, asymptotic approximations of the growth rate of  and, in consequence, use them to study the asymptotic behaviour of . 

Finding appropriate generating functions plays therefore an important role in the process of investigating properties of `typical' terms. In~\cite{Bendkowski2015}, authors investigated the asymptotic density of weakly normalizing terms in the set of all combinators, showing that a `typical' combinator cannot have a trivial  --  asymptotic probability of normalization. The result was obtained by constructing large classes of terms with and without the normalization property. Though sufficient for the purpose of showing the non-trivial behaviour of normalization, their classes reveal the combinatorial structure of just a small asymptotic portion of normalizing terms.

In this paper we give a complete combinatorial characterization of normalizing combinatory logic terms over the set  of primitive combinators. We construct a recursive family  of regular tree grammars defining combinators reducing in exactly  normal-order reductions. By Curry and Feys's standardization theorem~\cite{curry-feys1958}, normal-order evaluation of normalizing combinators leads to their normal forms, hence our \emph{normal-order reduction grammars} form a complete partition of normalizing combinators. Our approach is algorithmic in nature and provides fully automated methods for constructing  as well as their corresponding ordinary generating functions.

The paper is organized as follows. In Sections~\ref{sec:combinatory-logic}, and~\ref{sec:regular-tree-grammars} we give preliminary definitions and notational conventions. In Section~\ref{sec-pseudocodes} we explain our pseudo-code notation and related implementation. In Section~\ref{sec:algorithm} we present a high-level overview on the algorithm. In Section~\ref{sec:analysis} we analyse the algorithm giving proofs of soundness~\ref{sec:soundness}, completeness~\ref{sec:completeness} and unambiguity~\ref{sec:unambiguity}. In Section~\ref{sec:gen-funs} we give a recursive construction of ordinary generating functions corresponding to . In Section~\ref{sec:applications} we discuss some consequences and applications of normal-order reduction grammars. Finally, in Section~\ref{sec:upper-bound} we investigate the size of the generated grammars.

\subsection{Combinatory Logic}\label{sec:combinatory-logic}
We consider the set of terms over primitive combinators  and . In other words, the set  of combinatory logic terms defined as . We follow standard notational conventions (see e.g.~\cite{barendregt1984}) --- we omit outermost parentheses and drop parentheses from left-associated terms, e.g.~instead of  we write . We use  to denote the normal-order reduction relation (reduce the leftmost outermost redex) to which we usually refer briefly as the reduction relation. We use lower case letters  to denote combinatory logic terms. For an introduction to combinatory logic we refer the
reader to~\cite{barendregt1984},~\cite{curry-feys1958}.

\subsection{Regular tree grammars}\label{sec:regular-tree-grammars}
In order to characterize terms normalizing in  steps we use
regular tree grammars (see e.g.~\cite{tata2007}), a generalization of regular
word grammars. A \emph{regular tree grammar}
 consists of an axiom , a set  of non-terminal
symbols such that , a set of terminal symbols  with
corresponding arities and a finite set of production rules  of the form
 where  is a non-terminal and  is a term in the corresponding term algebra
, i.e.~the set of directed trees built upon terminals
 according to their associated arities. To build terms of grammar
, we start with the axiom  and use the corresponding derivation relation,
denoted by , as defined through the set of production rules .

\begin{example} 
Consider the following regular tree grammar defined as  where
, , , and  consists of the two following rules: 

Note that  defines the set of terms isomorphic to plane binary trees where
leafs correspond to the nullary constant  and inner nodes correspond to
the binary terminal .
\end{example}

In our endeavour, we are going to recursively construct regular tree grammars
generating sets of combinatory logic terms. We set a priori their axioms and
both terminal and non-terminal symbols, leaving the algorithm to define the
remaining production rules. And so, the th grammar  will have:
\begin{enumerate}[(i)]
    \item an axiom ,
    \item a set  of terminal symbols consisting of two nullary
            constants ,  and a single binary application operator,
    \item a set of non-terminal symbols  where  denotes the axiom of the set
            of all combinatory logic terms, as defined in the previous section.
\end{enumerate}
In other words, the grammar  defining terms normalizing in  steps, will
reference all previous grammars  and the set of all
combinatory logic terms . 

Throughout the paper, we adopt the following common definitions and notational
conventions regarding trees. We use lower case letters
 to denote trees, i.e.~elements of the term
algebra  where 
for some . Whenever we want to use a combinator without specifying its type,
we use capital letters . We define the \emph{size} of  as
the number of applications in .  We say that  is \emph{normal}
if either  is of size , or , for
some , where all  are normal. In the latter
case we say moreover that  is \emph{complex}. Since we are going to work exclusively with normal trees, we assume that all trees are henceforth normal.
We say that a complex  is of \emph{length}  if  is in form of . Otherwise, if  is not complex, we say that it is of length . The \emph{degree} of , denoted as , is the minimum natural number  such that  does not contain references to any  for . In particular, if  does not reference any reduction grammar, its degree is equal to . We use  to denote the language of  in grammar . Since  does not reference grammars of greater index, we have
 for arbitrary .
And so, for convenience, we use  to denote the language of  in grammar  if . Otherwise, if 
 we assume that  denotes the language of  in grammar . Finally, we say that two normal trees are
\emph{similar} if both start with the same combinator  and are of equal
length.

\begin{example}
        Consider the following trees:
        \begin{enumerate}[(i)]
                \item , and
            \item .
        \end{enumerate}
        Note that both  and  are of size  and of equal length
        , although they are not similar since both start with
        different combinators. Moreover, only  is normal as  has
        a subtree , which is of positive size, but does not start
        with a combinator. Since  contains a reference to  and no
        other reduction grammar, its degree is equal to , whereas the degree of
         is equal to .
\end{example}

A crucial observation, which we are going to exploit in our construction, is the fact that normal trees \emph{preserve} length of generated terms. In other words, if  is of length , then any term  is of length  as well, i.e.~.

\subsection{Pseudo-codes and implementation}\label{sec-pseudocodes}

We state our algorithm using functional pseudo-codes formalising key design subroutines. The adopted syntax echoes basic Haskell notation and build-in primitives, though we use certain abbreviations making the overall presentation more comprehensible. And so, we use the following data structure representing normal trees.

\begin{lstlisting}
    -- | Normal trees.
    data Tree = S | K | C | R Int
              | App Tree Tree
\end{lstlisting}
 
In our subroutines, we use the following `syntactic sugar' abbreviating the structure of normal trees.

\begin{lstlisting}
    -- | Syntactic sugar.
    X a_1 ... a_m := App X (App a_1 (... App a_{m-1} a_m) ...)
\end{lstlisting}

Moreover, we allow the use of this abbreviated notation in pattern matching, meaning that by writing \verb|(X a_1 ... a_m)| we expect a complex tree of length  for some . If multiple arguments are supposed to share the same length, we use the same natural number , e.g.~\verb|(X a_1 ... a_m)| and \verb|(X b_1 ... b_m)|.
A working Haskell implementation of our algorithm is available at~\cite{mb-haskell-implementation}.

\section{Algorithm}\label{sec:algorithm}

The key idea used in the construction of reduction grammars is to generate new productions in  based on the productions in . Necessarily, any term normalizing in  steps reduces directly to a term normalizing
in  steps, hence their syntactic structure should be closely related. As the base of our inductive construction, we use the set of normal forms  given by
 
 
 Clearly, primitive combinators  and  are in normal form. If we take a normal form , then both  and  are again normal since we did not create any new redex. For the same reason, any term  where  and  are normal forms, is itself in normal form. And so, with the above grammar we have captured exactly all redex-free terms.

Let us consider productions of . Note that from both the cases of  and  we can abstract a more general rule --- if  reduces in  steps, then  and  reduce in  steps as well, since after reducing  we have no additional redexes left to consider. It follows that any  should contain productions  and . Similarly, from the case of  we can abstract a more general rule --- if  reduces in  steps, then both  and  must reduce in total of  steps. The normal-order reduction of  proceeds to normalize  and  sequentially. As there is no head redex, after  steps we obtain a term in normal form. And so,  should also contain productions  for .
 
 As we have noticed, all the above productions do not contain head redexes and hence do not increase the total amount of required reduction steps to normalize. Formalizing the above observations, we say that  is \emph{short} if either  or . Otherwise,  is said to be \emph{long}. Hence, we can set a priori the short productions of  for  and continue to construct the remaining long productions. Naturally, as we consider terms over two primitive combinators  and , we distinguish two types of long productions, i.e.~\textsc{S-} and \textsc{K-Expansions}.
 
 \subsection{K-Expansions}\label{sec:k-expansions}
Let us consider a production  where . The set  is defined as


\begin{prop}\label{prop-K}
        Let . If , then .
\end{prop}

\begin{proof}
    Let . Consider its direct reduct . Clearly,  for  which finishes the proof.
\end{proof}

In other words, the set  has the property that any \textsc{K-Expansion} of  generates terms that reduce in one step to terms generated by . If we compute the sets  for all productions , we have almost constructed all of the long -productions in . What remains is to include the production  as any term  reduces directly to  for some production .

We use the following subroutine computing the set of \textsc{K-Expansions} of a given production.

\begin{lstlisting}
    -- | Returns K-Expansions of the given production.
    kExpansions :: Tree -> [Tree]
    kExpansions p = case p of
        (K a_1 ... a_m) -> kExpansions' K [a_1,...,a_m]
        (S a_1 ... a_m) -> kExpansions' S [a_1,...,a_m]
        where
            kExpansions' _ [] = []
            kExpansions' h [x_1,...,x_k] = K h C x_1 ... x_k
                : kExpansions' (App h x_1) [x_2,...,x_k]
\end{lstlisting}

\subsection{S-Expansions}\label{sec:s-expansions}
Let us consider a production  where . We would like to define the set  similarly to , i.e.~in such a way that any term generated by an \textsc{S-Expansion} of  reduces in a single step to some . Unfortunately, defining and computing such a set is significantly more complex than the corresponding .

Let . Suppose that  for some production . Evidently,  and so we would like to guarantee that  for some . Assume that  where  and . Unfortunately, in order to guarantee that we capture all terms reducing to  via an -redex and nothing more, we cannot use both  and  directly. We require an additional `rewriting' operation that would extract the important sublanguages of  and  so that we can operate on them, instead of  and . 

Hence, let us consider the following rewriting relation , extending the standard derivation relation:



We use  to denote the transitive-reflexive closure of . The important property of  is the fact that if , then . To denote the fact that  does not rewrite to  and vice versa, we use the symbol . In such case we say that  and  are \emph{non-rewritable}. Otherwise, if one of them rewrites to the other, meaning that  and  are \emph{rewritable}, we use the symbol .

\subsubsection{Mesh Set}
In the endeavour of finding appropriate \textsc{S-Expansions} rewritings, we need to find common \emph{meshes} of given non-rewritable trees . In other words, a complete partition of  using all possible trees  such that . For this purpose, we use the following pseudo-code subroutines.

\begin{lstlisting}[mathescape=true]
    -- | Given X  and X  computes
    -- the family  of tree meshes. 
    mesh :: [Tree] -> [Tree] -> [[Tree]]
    mesh (x : xs) (y : ys)
        | x `rew` y = [y] : mesh xs ys -- case when x  y
        | y `rew` x = [x] : mesh xs ys -- case when y  x
        | otherwise = meshSet x y : mesh xs ys -- case when x  y
    mesh [] [] = []
\end{lstlisting}

The function \textsc{Mesh}, when given two similar productions  and , constructs a family  where each  depends on the comparison of corresponding arguments. In the case when  rewrites to  (denoted as \verb|x `rew` y| in the pseudo-code) the singleton  is constructed. Similarly, when , the singleton  is constructed. Otherwise, when  and  are both non-rewritable,  is computed using the \textsc{MeshSet} subroutine.

\begin{lstlisting}
    -- | Returns the mesh set of given trees.
    meshSet :: Tree -> Tree -> [Tree]
    meshSet (X a_1 ... a_m) (X b_1 ... b_m) =
    	cartesian X [mesh a_i b_i | i <- [1..m]]
    meshSet (R k) b @ (X b_1 ... b_m) = 
    	nub  productions (R k)
    meshSet b @ (X b_1 ... b_m) (R k) =
    	nub  productions (R k)
    meshSet _ _ = []		
\end{lstlisting}

When given two similar trees  and , \textsc{MeshSet} computes meshes  of corresponding arguments  and  using the subroutine \textsc{Mesh}. Next, argument meshes  are used to construct meshes for  and , using the subroutine \textsc{Cartesian} which computes the Cartesian product  using term application.
In the case when one of \textsc{MeshSet}'s argument is a reduction grammar  and the other  is complex, \textsc{MeshSet} computes recursively mesh sets of  and each production , outputting their set-theoretic union. In any other case, \textsc{MeshSet} returns the empty set.

\begin{example}
Let  and . Consider . Both  and  are similar and complex, hence
\textsc{MeshSet} proceeds directly to construct mesh sets of corresponding arguments
of  and . Since , we get . Then, as both  and  are non-rewritable, . It follows that 
is equal to . Further inspection reveals that
 and thus . Finally,  as  rewrites trivially to itself. Since each  is a singleton, it follows that

\end{example}

We leave the analysis of \textsc{MeshSet}  until we fully define the construction of reduction grammars .

\subsubsection{Rewriting Set}
Consider again our previous example of  where  such that both  and . In order to capture terms reducing to  via an -redex, we need to find all pairs of trees  such that  and . Since such pairs of trees follow exactly the structure of  we can use them to define the set . And so, to find such rewriting pairs, we use the following \textsc{RewritingSet} pseudo-code subroutine.

\begin{lstlisting}[escapeinside={(*}{*)}]
    -- | Given (**) and (**) computes their rewriting set. 
    rewritingSet :: Tree -> Tree -> [Tree]
    rewritingSet a S = []
    rewritingSet a K = []
    rewritingSet a C = [C a]
    rewritingSet a (R k) = 
    	nub  productions (R k)
    rewritingSet a (X b_1 ... b_m)
    	| a `rew` b_m => [X b_1 ... b_m]
    	| b_m `rew` a => [X b_1 ... b_{m-1} a]
    	| otherwise => 
    		cartesian (X b_1 ... b_{m-1}) [meshSet a b_m] 
\end{lstlisting}

The outcome of \textsc{RewritingSet}() depends on 's structure. If  is a primitive combinator  or , \textsc{RewritingSet} returns the empty set. If , a singleton  is returned. When  for some , \textsc{RewritingSet} computes recursively the rewriting sets of  and , outputting their set-theoretic union. Otherwise when , \textsc{RewritingSet} determines whether . If , a singleton  is returned. Conversely, in the case of , \textsc{RewritingSet} returns . Finally if  and  are non-rewritable, \textsc{RewritingSet} invokes the \textsc{Cartesian} subroutine computing the Cartesian product of  using term application, passing afterwards its result as the computed rewriting set.

\begin{example}
Let us consider the rewriting set . Since , we know that .
It follows therefore that in order to compute , we have to consider rewriting sets involving productions of . Note that both productions  and  do not contribute new trees. It remains to consider productions ,  and . Evidently, each of them is complex and has  as its final argument. Hence, their corresponding rewriting sets are ,  and , respectively. And so, we obtain that

\end{example}

Similarly to the case of \textsc{MeshSet}, we postpone the analysis until we define the construction of .

Equipped with the notion of mesh and rewriting sets, we are ready to define the set of \textsc{S-Expansions}. And so, let  where . The set  is defined as

where . We use the following subroutine computing the set of \textsc{S-Expansions} for a given .

\begin{lstlisting}
  -- | Returns S-Expansions of the given production.
  sExpansions :: Tree -> [Tree]
  sExpansions p = case p of
      (K a_1 ... a_m) -> sExpansions' K [a_1,...,a_m]
      (S a_1 ... a_m) -> sExpansions' S [a_1,...,a_m]
      where
          sExpansions' _ [] = []
          sExpansions' _ [_] = []
          sExpansions' h [x_1,x_2,...,x_k] =
                map ( \potential{S} = \potential{K} = \potential{\mathcal{C}} = 0, \potential{X \alpha_1 \ldots \alpha_m} = m + \sum_{i=1}^{m}
\potential{\alpha_i},  \potential{R_n} = 1 + \max_{\gamma \in \Phi (R_n)} \potential{\gamma}  \alpha = K (X \overline{\alpha_1} \ldots \overline{\alpha_k}) \mathcal{C}
            \alpha_3 \ldots \alpha_m \in \KExpansions{\gamma},  \beta = K (X \overline{\beta_1} \ldots \overline{\beta_k}) \mathcal{C}
            \beta_3 \ldots \beta_m \in \KExpansions{\delta}, \gamma = X \overline{\alpha_1}
            \ldots \overline{\alpha_k} \alpha_3 \ldots \alpha_m,\delta = X \overline{\beta_1}
            \ldots \overline{\beta_k} \beta_3 \ldots \beta_m. \alpha = S (X \overline{\alpha_1} \ldots \overline{\alpha_k}) \varphi_l
                        \varphi_r \alpha_4
                    \ldots \alpha_m \in \SExpansions{\gamma}, \beta = S (X \overline{\beta_1} \ldots \overline{\beta_k})
                            \overline{\varphi_l} \overline{\varphi_r} \beta_4
                    \ldots \beta_m \in \SExpansions{\delta}, \gamma = X \overline{\alpha_1} \ldots \overline{\alpha_k} \alpha_2
                \alpha_3 \alpha_4 \ldots \alpha_m,  \delta = X \overline{\beta_1} \ldots \overline{\beta_k} \beta_2
                \beta_3 \beta_4 \ldots \beta_m. R_n(z) = \sum_{k=0}^{\infty} r_{n,k}\, z^k. \label{eq:r0(z)}
C(z) = \frac{1 - \sqrt{1 - 8z}}{2 z} \qquad \quad R_0(z) = \frac{1 - 2 z - \sqrt{1- 4 z - 4 z^2}}{2 z^2}.
\label{eq:rn(z)-fun-eq}
R_n(z) = \sum_{\alpha \in R_n} z^{k(\alpha)} {C(z)}^{c(\alpha)} \prod_{i=0}^{n} {R_i(z)}^{r_i(\alpha)},
\label{eq:rn(z)-fun-eq-2}
R_n(z) = 2 z R_n(z) + 2 z^2 R_0(z) R_n(z) + \sum_{\alpha \in \Phi(R_n)} z^{k(\alpha)} {C(z)}^{c(\alpha)} \prod_{i=0}^{n-1} {R_i(z)}^{r_i(\alpha)},
\label{eq:rn(z)-fun-eq-simplified}
R_n(z) = \frac{1}{\sqrt{1-4 z - 4 z^2}} \sum_{\alpha \in \Phi(R_n)} z^{k(\alpha)} {C(z)}^{c(\alpha)} \prod_{i=0}^{n-1} {R_i(z)}^{r_i(\alpha)}.
 \beta = K(X \alpha_1 \ldots \alpha_k) \mathcal{C} \alpha_{k+1} \ldots
    \alpha_m \qquad \text{for} \quad 0 \leq k \leq m-1.  \beta = S(X \alpha_1 \ldots \alpha_k) \varphi_l \varphi_r \alpha_{k+3}
    \ldots \alpha_m \qquad \text{for} \quad 0 \leq k \leq m -2. 
|x| + 2 |x| + 4 |x| + \cdots + 2^n |x| &=& |x| \Big(1 + 2 + 4 + \cdots + 2^n \Big) \\
 &=& |x| \Big( 2^{n+1} - 1 \Big) = O(|x|).

  f_n(k) = \left\{\begin{array}{r@{}l@{\qquad}l}
    & 1 & \text{if }\ k = 0, \

    We claim that . Note that it suffices
    to consider such  that  since
     is an increasing function attaining positive values for any given input.
	It follows that the base case  is clear, as if , then  is necessarily empty.
	Now, let us assume that . From the construction of the common mesh set  of  and , we can distinguish two cases left to consider.
    \begin{enumerate}[(i)]
        \item Suppose that  and
                . In order to maximize the
                size of , we can furthermore assume that none of the pairs
                  are rewritable. And so, the total
                number of meshes in  is equal to the product of all meshes in
                corresponding mesh sets for  and . The degree
                of  and  is still at most ,
                however . Hence,
                using the induction hypothesis we get
                .
                Since both  are of length  we can furthermore
                state that
                
        \item Let us assume w.l.o.g.~that  and  is complex.
                In order to maximize the total number of meshes in , we can
                moreover assume that all productions  are
                similar to  and generate disjoint sets of meshes. We claim
                 that . 
                 Clearly,
                 if  does not reference , then our claim is trivially true.
                Suppose that  is a self-referencing production. If 
                , then  is in form of .
                From the construction of , we get that  As , we can apply the induction hypothesis to 
                   and immediately obtain 
                  . Now, suppose w.l.o.g.~that
                 and hence .
                Again, from the construction of  we know that
                
                Due to the fact that both  and ,
                  we can use the induction hypothesis and immediately get that
                
                Note that  for  and, in
                 consequence, . Indeed, 
                 if , then
                 . Otherwise if 
                 , then
                
                As
                 for , we finally obtain
				                
                
				We know therefore that  for 
				each . Finally, using the fact that 
				, we get
				
    \end{enumerate}
    And so, we know that . Solving the
    recurrence for , using e.g.~Mathematica \textregistered~\cite{mathematicaSoft}, we obtain the following closed form expression
    
    where
    
    is the upper incomplete gamma function (see e.g.~\cite{abramowitz-stegun1974}).
    Simplifying the above expression in the case  and using the observation
    that  for arbitrary , we finally
    obtain the anticipated upper bound
    
\end{proof}

\begin{lemma}\label{lem-rewritingset-size-upperbound}
    Let  be two trees of degree at most  such that their total potential  is equal to . Then, the number of distinct trees in  is bounded by .
\end{lemma}

\begin{proof}
	If , then our claim is trivially true. Let us focus therefore on the remaining cases when either  and both  and  are non-rewritable, or . 
	
	First, consider the former case. Note that the resulting rewriting set is of equal size as
    . Since , we can use Lemma~\ref{lem-meshset-upperbound} to deduce that
    
	
	Now, let us consider the latter case. In order to maximize
    the resulting rewriting set we assume that each production  generates a disjoint set of trees. We claim that each production
      contributes at most  new trees to the resulting
      rewriting set and therefore , as there are at most  productions in . Indeed, consider an arbitrary . Evidently, if , then our claim is true. Hence, let us assume that . It follows that  is complex. Let us rewrite it as . Note that as in the previous case, the resulting rewriting set is of equal size as . Since  we use Lemma~\ref{lem-meshset-upperbound} and get
      
\end{proof}

\begin{lemma}\label{lem-meshset-potential-upperbound}
    Let  be two trees of total potential
     equal to . Then, each mesh in
     has potential bounded by .
\end{lemma}

\begin{proof}
        Induction over total potential . Again, it suffices to consider such  that  is not empty. Immediately, the base case  is clear. Let us assume that . Consider the following primitive recursive function .
\jot]
    & k \cdot \left( f(k-1) + 1 \right) & \text{otherwise.}
  \end{array}\right.
\potential{\gamma} \leq m \cdot f(p-2) + m \leq p \cdot (f(p-2) + 1) \leq f(p). \potential{\gamma} = 2 + \potential{\gamma_1} + \potential{\gamma_2}
                  \leq 2 + 2 \cdot f(p-2).
				\potential{\gamma} &= 2 \left(1 + f(p-2)\right)\\
				&\leq (p-1) \left( 1 + f(p-2) \right)\\
				&=f(p-1) \leq f(p).
				
        f(p) &= \Gamma (1 + p) + e\, p\, \gammaF{p}\\
             &\leq p! + e\, p!\\
             &= p! (1 + e)
     \Gamma(n) = (n - 1)! 
  \psi(k) = \left\{\begin{array}{r@{}l@{\qquad}l}
    & 1 & \text{if }\ k = 0, \

    Clearly,  is an increasing primitive recursive function.
    We show that  bounds the potential of  using induction over .
    Since , the base case is clear.
    Let . In order to prove our claim, we have to check that  for all productions  which do not reference .
     \begin{enumerate}[(i)]
     \item Suppose that . Clearly, the potential of  is equal to . Using the induction hypothesis, we know moreover that
     
     \item Let . Due to the fact that , we use the induction hypothesis and immediately obtain 
     \item Suppose that  for some . Note that  as the productions of greatest potential in  are exactly  and . Since , we get
     
     \item Finally, let  for some . Again,  and hence from the induction hypothesis . Let us rewrite  as  where
     . Note that
     . Moreover, as , we get
     .
     Since  and thus, , we can use Lemma~\ref{lem-rewritingset-potential-upperbound}
     to obtain 
     It follows therefore that
     
     where the last inequality follows from the fact that
     
     \end{enumerate}
\end{proof}

\begin{theorem}
 There exists a primitive recursive function 
    such that the number  of productions in  is bounded by .
\end{theorem}

\begin{proof}
Consider  for some . Note that  consists of:
\begin{enumerate}[(i)]
\item two productions  and ,
\item  short -productions in form of ,
\item an additional -production ,
\item  for each  and
\item  for each .
\end{enumerate}

It suffices therefore to bound the number of \textsc{K-} and \textsc{S-Expansions}, as
the number of other productions in  is clear. Let us start with \textsc{K-Expansions}. Suppose that  is of length . Clearly, . Using Proposition~\ref{prop-LRn-production-length}, we know that that each production  is of length at most . It follows that there are at most  \textsc{K-Expansions} in . Now, let us consider \textsc{S-Expansions}. In order to bound the number of \textsc{S-Expansions} in , we assume that each production  is of length  and moreover each \textsc{RewritingSet} of appropriate portions of  generates a worst-case set of trees. And so, assuming that  is of length  we can rewrite it as . Let  denote the upper bound function on the potential of  from Lemma~\ref{prop-Rn-potential-upperbound}. Evidently, . Now, using Lemma~\ref{lem-rewritingset-size-upperbound} we know that each  contributes at most 
new \textsc{S-Expansions}. As there are at most  pairs of indices  yielding \textsc{RewritingSets}, we get that the number of \textsc{S-Expansions} in  is bounded by


Finally, since , we combine the above observations and get the following primitive recursive upper bound on .
\jot]
    & 4 + k + 2k \cdot \chi(k-1) &\\
    & + (2k-1) \cdot {\chi(k-1)}^{2 + 3 \big(\psi(k-1) + 3\big)!} & \text{otherwise.}
  \end{array}\right.
 5, 12, 75, 625, 5673, 53164, 508199, \ldots 

\vspace{2mm}
The upper bound  on the size of  is already of order , whereas the actual size of  is equal to . Naturally,
we conjecture that  grows much slower than
, although the intriguing problem of 
giving better approximations on the size of  for large 
 is still open.
 
\section*{Acknowledgements}
We would like to thank Katarzyna Grygiel for many fruitful discussions and valuable comments.

\bibliographystyle{plain}
\bibliography{references}

\end{document}
