\documentclass{llncs} 



\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{STYLES/proof}
\usepackage{float} \floatstyle{boxed}
\newfloat{Fig.}{t}{lof}
\newfloat{Ex.}{t}{lof}

\newcommand{\marginnote}[1]{\marginpar{\tiny #1}
}







\def\scriptInfer[#1]#2#3{\infer[\scriptstyle #1]{\scriptstyle #2}{\scriptstyle #3}}\def\scriptInferD#1#2{\infer{\scriptstyle #1}{\scriptstyle #2}}


\newlength{\hauteurAcentrer}\newcommand{\heightcenter}[1]{\settoheight{\hauteurAcentrer}{#1}\raisebox{-.47\hauteurAcentrer}[.5\hauteurAcentrer][.5\hauteurAcentrer]{#1}}\newcommand{\fullcenter}[1]{\centerline{\heightcenter{#1}}}\newcommand{\lien}[1]{{#1}}

 %
 
\newcommand{\plus}{\oplus}
\newcommand{\stimes}{\ominus}
\newcommand{\spar}{\triangleleft}

\newcommand{\ctimes}{\odot}
\newcommand{\bigctimes}{\bigodot}
\newcommand{\cpar}{\mid}

\newcommand{\un}{\mathbf 1}

\newcommand{\zero}{\mathbf 0}

\newcommand\distrib{\mathcal{D}
}

\newlength{\lgctimes}
\settowidth{\lgctimes}{}

\newcommand\ConcImp{\mathrel{\relbar \mathchoice{\hspace{-.85\lgctimes}}{\hspace{-.85\lgctimes}}{\hspace{-.4\lgctimes}}{\hspace{-.35\lgctimes}}\ctimes }}

\newcommand{\rMLL}{rMLL}		\newcommand{\rMALL}{rMALL}		\newcommand{\RMLL}{RMLL}		\newcommand{\CMALL}{CMALL}		\newcommand{\CMALLc}{CMALL}	\newcommand{\CMLLm}{CMLL}	\newcommand{\CMELL}{CMELL}		\newcommand{\MLL}{MLL}			\newcommand{\MALL}{MALL}		

\newcommand{\Mronde}[1]{\mathcal{#1}}
\newcommand{\Mcross}[1]{\Mronde{M}^{\times_{#1}}}
\newcommand{\Msym}[1]{\Mronde{M}^{\circ_{#1}}}
\newcommand{\Mfock}{\texttt{Fock(}M\texttt{)}}
\newcommand{\Mfockc}{\texttt{Fock(}M\texttt{)}^c}
\newcommand{\Pfock}{\texttt{Fock(}P\texttt{)}}
\newcommand{\perpfock}{\protect\mathpalette{\protect\doublePerp}{\perp}}
\def\doublePerp#1#2{\mathrel{\rlap{}{\mkern2mu{#1#2}}}}
\newcommand{\topfock}{\overline{\top}}

\DeclareMathOperator*{\bigcircop}{\bigcirc}
\DeclareMathOperator*{\bigctimesop}{\bigctimes}
\DeclareMathOperator*{\bigstarop}{\bigstar}

\newcommand{\compctx}{\mathbb{C}}	\newcommand{\simctx}{\mathbb{S}}	\newcommand{\Cfock}{\texttt{Fock(}\compctx\texttt{)}}


\newlength{\lgcirc}
\newcommand\PreImp{\settowidth{\lgcirc}{}
\mathrel{
\circ
\mathchoice{\hspace{-.86\lgcirc}}{\hspace{-.86\lgcirc}}{\hspace{-.41\lgcirc}}{\hspace{-.36\lgcirc}}

\relbar
}}

\newcommand\PostImp{\settowidth{\lgcirc}{}
\mathrel{
\relbar
\mathchoice{\hspace{-.85\lgcirc}}{\hspace{-.85\lgcirc}}{\hspace{-.4\lgcirc}}{\hspace{-.35\lgcirc}}

\circ
}}

\newcommand\PreSup[2]{
\mathrel{
{}^{#1}\!{#2}
}}

\newcommand\PreNeg[1]{
\mathrel{
\PreSup{\perp}{#1}
}}




\newlength{\Mentrylength}
\newlength{\Mentryheight}
\newcommand{\Mentrylabel}[1]{\settowidth{\Mentrylength}{\textsf{#1\raisebox{\Mentryheight-1.5ex}{ : }}}\settoheight{\Mentryheight}{\textsf{#1\raisebox{\Mentryheight-1.5ex}{ : }}}
	\ifthenelse{\lengthtest{\Mentrylength > 60pt}}{\setlength{\labelwidth}{\Mentrylength+5pt}}{\setlength{\labelwidth}{65pt}}\raisebox{1.5ex-\Mentryheight}[1ex][\Mentryheight]{\makebox[\labelwidth]{{\parbox[t]{\labelwidth}{\textsf{#1\raisebox{\Mentryheight-1.5ex}{ : }}}}}}}
\newenvironment{Mentry}{\begin{list}{}{\renewcommand{\makelabel}{\Mentrylabel}\setlength{\labelwidth}{40pt}\setlength{\leftmargin}{\labelwidth+\labelsep}}}{\end{list}}
 \usepackage{STYLES/nfpar}





 
\begin{document}

\pagestyle{plain} \mainmatter       

\title{A Sequent Calculus for Modelling Interferences}

\author{Christophe Fouquer\'e}

\institute{LIPN -- UMR7030 \\ CNRS -- Universit\'e Paris 13
\\99 av. J-B Cl\'ement, F--93430 Villetaneuse, France\\
\email{cf@lipn.univ-paris13.fr}\\
}

\maketitle

\begin{abstract}
A logic calculus is presented that is a conservative extension of linear logic. 
The motivation beneath this work concerns lazy evaluation,
true concurrency and interferences in proof search.
The calculus includes two new connectives to deal with multisequent structures and has the cut-elimination property. Extensions are proposed that give first results concerning our objectives.
\end{abstract}

\section{Introduction}\label{sec:introduction}




Linear Logic is a good framework for interpreting and computing over linear structures.
Since Girard's seminal paper~\cite{Girard87} that gives first insights (proof nets, phase and coherent spaces), a lot has been achieved among which normalization of proofs via focusing and polarization~\cite{Andreoli92,Laurent05a}. These last results seem to be intrinsically related to principles underlying cut elimination as it allows for investigating a reconstruction of logical structures as in Ludics~\cite{Girard01}.
Recent works done on concurrent modelling using such a framework seem promising~\cite{DBLP:conf/csl/CurienF05,DBLP:conf/csl/GiamberardinoF06}.
However, non series-parallel situations are not taken into account.

We present a logic calculus (and variants) that is a conservative extension of linear logic. 
The motivation beneath this work is a careful study of lazy evaluation in logic programming. Since works of Andreoli~\cite{Andreoli92}, we know that full linear logic may be used as a logical programming language thanks to focalization and works have been done on lazy evaluation in this case~\cite{DBLP:conf/elp/CervesatoHP96}. However we show in Sect.~\ref{sec:calculus} that cut elimination is false for a naive calculus taking laziness as a principle. A second motivation concerns the control of true concurrency and interferences in proof search. For instance, suppose the following problem to be modelled in logic programming. We have two 'packs' of actions:  (resp. ) such that  (resp. ) transforms  occurences of  (resp. ) into  occurences of  and  occurences of , where . We suppose at the initial state only one resource
of each kind (hence one  and one ).
We want to simulate exactly the two following situations: 
\begin{itemize}
\item[(i)] if the two actions are applied (whatever may be the order) then we have three possible results:
3  and 2 , 2  and 3 , 2  and 2 . The first (resp. second) result is obtained when action  (resp. ) is applied first followed by action  (resp. ). The third result occurs when the two actions are performed independently.
\item[(ii)] if the two actions are applied strictly concurrently, there is only one possible result: we get 2  and 2 .
\end{itemize}
This is not possible inside propositional classical or linear logic as it requires a control between proofs.
For that purpose, we basically shift from a sequent view to a multisequent view. Moreover sharing of formulas occurences between such sequents is allowed. The reader should have in mind the following elements:
\begin{itemize}
\item logical operations are done on occurences of formulas that may be shared among different sequents,
\item a sequent is a place grouping a bunch of occurences,
\item each step of a proof transforms zero, one or two multisequents into one by means of an operation, either structural or logical (in this last case the operation is done on occurences of formula and entails the structure of the conclusion),
\item equivalently, a multisequent may be defined as a set of places, a set of occurences of formulas and a function relating a place to a set of occurences.
\end{itemize}
In the following the two interpretations may be used. 
Shifting from sequents to multisequents gives place for a new structural operation that joins sequents (to be compared with the par operation that joins occurences in a sequent). In a first step we consider a "2-way" connective that "relates" two sequents in a multisequent. Its dual is denoted  and called cpar.
We then consider the following extensions:
\begin{itemize}
\item add of a 'cloning' structural rule: this comes from the observation that interaction of a sequent by means of a cut elimination is behaviouraly equivalent to interaction with two sequents sharing exactly the same occurences. However this last observation is not provable without such a cloning rule.
\item add exponential-like modalities (Sec.~\ref{sec:modalities}): standard modalities for linear logic are available. However as sharing is internal, it allows for adding modalities whose behaviour is the converse of the standard one.
\end{itemize}



 
\section{Related Works}\label{sec:RelatedWorks}




Modelling interferences has not yet been really investigated in logic. First of all, classical logic as well as modal logic do not take seriously into account the notion of resource, hence appear to be inadequate. Second, modelling (and controlling) interferences may seem contradictory in the framework of Linear Logic as the splitting mechanism seems at the heart of cut-elimination. However, current works done on concurrency are close.
Following Girard's works on Ludics, Curien, Faggian, Giamberardino~\cite{DBLP:conf/csl/CurienF05,DBLP:conf/csl/GiamberardinoF06} were able to formalize L-nets that quotient (abstract) proof trees w.r.t. commutation of tensors. This normalization goes further than the one given by Andreoli with focusing and polarization.
However, non series-parallel situations cannot be taken into account in their denotational model.
Works close to the research presented here include Bunched Implications~\cite{DBLP:journals/bsl/OHearnP99} and Deep Inference~\cite{DBLP:journals/tocl/Guglielmi07}.
But these two last frameworks seem to fail in keeping basic logical properties as focalization and polarization.
The line of research that is undertaken here introduces a syntactic novelty by considering that occurences of formulae may be shared by different sequents. This sharing induces a strict synchronization between different computations (i.e. developments of proofs) and new connectives may be defined that internalize this mechanism.

 
\section{A Multisequent Calculus}\label{sec:calculus}




Besides the classical multiplicative and additive connectives of Linear Logic, we introduce two new connectives ctimes  and cpar  whose intended meaning is to model strict concurrency.

\begin{definition}
The {\em formulas}, denoted , are built from atoms , , 
, , , ,
constants , , ,  and the following (linear) connectives:
\begin{itemize}
\item (parallel) multiplicative conjunction  (times) and 
disjunction  (par),
\item (concurrent) multiplicative conjunction  (ctimes) and 
disjunction  (cpar),
\item additive conjunction  (plus) and disjunction  (with).
\end{itemize}

Negation is defined by De Morgan rules:
\center


\end{definition}

\subsection{Structures of Multisequents}
\begin{definition}
A {\em formula context}  has one of the two following forms:
\begin{itemize}
\item A formula 
\item A finite multiset of formula contexts separated by commas .
',' is considered commutative and associative.
\end{itemize}
{\em Sequents} are of the form , where  is a formula context.
A {\em multisequent} is a finite multiset of sequents. 
Multisequents are denoted  If a multisequent is reduced to one sequent, '' and '' may be omitted.
A multisequent may contain sequents that are not disjoint: an occurence of a formula may appear in different sequents. Such sequents
are said to be {\em linked}. Superscripts are put if different occurences of the same formula occur.
The {\em principal} formulas occurences of a (logical) rule are formulas from the hypotheses on which the rule applies. The {\em principal} sequents are sequents where the principal formulas occur.
\end{definition}

\begin{example}[multisequents]
: this multisequent involves four formulas and two (disjoint) sequents whereas
 involves three sequents and four occurences of formulas. \end{example}

At first glance, rules given in sequent calculi may seem strange:
Throughout the paper, contexts of a principal occurence are identified by a free subscript. For example, 
 means a multiset of sequents (the domain of the free subscript ) where the
{\em same} occurence  appears. Note that the domain of  cannot be empty.
Sequents that remain unchanged by a rule are either replaced by dots or by a notation for a multisequent. 
If a proof involves different occurences
of the same fomula (hence different contexts), these occurences are distinguished by a superscript:\footnote{A context  with a supersript supposes the superscript for
each formula of the context.} remark this in the -rule in Fig.~\ref{fig:seq-imp}.

\subsection{A Naive (and Wrong) Attempt}

Lazy logic programming relies mainly on a lazy splitting of contexts when considering the  rule. The standard  rule is the following one:

In a bottom-up proof search, as it is the case in logic programming, applying this rule requires to know how to split the multiset . A lazy way consists in delaying this separation. Let us note  the connective  defined in a lazy way. Shifting to multisequents, this may be given by sharing the whole multiset  between the two sequents in the hypothesis (remember that occurences are shared between sequents if no superscript is present):


We suppose further  still dual to : . Following these guidelines, a system for a lazy Multiplicative Linear Logic (lazy MLL) is given in Fig.~\ref{badCLL}. However a counter-example to cut-elimination is easy to find:\\
 ~~~and~~~ 
 ~~~are provable.\\ 
But~~~~ 
 ~~~~is not provable:

\settoheight{\hauteurAcentrer}{\scriptInfer[]{\{A^\perp \cpar 1, A \Par \bot\}\{A^\perp \cpar 1, 1^1 \Par 1^2\}}{
	\scriptInfer[]{\{A^\perp \cpar 1, A, \bot\}\{A^\perp \cpar 1, 1^1, 1^2\}}{
		\scriptInfer[]{\{A^\perp \cpar 1, A\}\{A^\perp \cpar 1, 1^1, 1^2\}}{
			\scriptInfer[]{\{A^\perp, A\}\{A^\perp, 1^1, 1^2\}\{1, A\}\{1, 1^1, 1^2\}}{
				\scriptInfer[]{\{A^\perp, A\}\{1^1\}\{1\}\{1^2\}}{
				}
			}
		}
	}
}
}





\begin{Fig.}
{\em Structural rules}


{\em Logical rules} (in rules  and , the multisequent consists of only one sequent)


{\em Cut rule}

\caption{Sequent calculus for a bad lazy MLL.  in rules.}\label{badCLL}
\end{Fig.}

\subsection{The Calculus \CMALL}

In order to circumvent the previous situation, lazyness is modelled by means of two specific connectives  and  besides the two multiplicative connectives  and  of Linear Logic. The rules of the sequent calculus Concurrent Multiplicative Additive Linear Logic (\CMALL) are given in Fig.~\ref{fig:seq-imp}. The system includes a cloning structural rule (c), however one may note that proofs of cut elimination, asynchrony, ... we give in the following are still true without this rule. Examples of instantiation of the rules are given below to help the reader recover standard situations.


\begin{example}[Rule instantiation]
( are formulas)\\

\end{example}

It is easy to prove the following statements (multisequents may be given two-sided for easiness of reading):
\begin{itemize}
\item  is provable:\vspace*{-3mm}\\
\centerline{}

\item   is asynchronous (lemma~\ref{lemma:asynchrony}) whereas  is synchronous. Although  does neither distribute over , nor the converse. But  does distribute over :  is provable\vspace*{1mm}\\
\hspace*{-2cm}
	
	


\item 
Remark that  is not provable, but  is provable (the two  are indexed to distinguish 
them, however these two denote the same constant; note also that there is 
only one occurence of  throughout the proof):
\vspace{-.4cm}

\end{itemize}



\begin{proposition}
The system enjoys cut-elimination: if  is a provable multisequent, 
then there exists at least one cut-free proof of .
\end{proposition}

The proof of cut-elimination (see annex) relies mainly on a reconstruction of proofs in case the two last rules concern the cut formulas, and on the three following lemmas that allow the commutation of rules. The standard definition of the height of a proof is generalized: the height of the proof of a multisequent is the
maximum of the heights of each partial proof.

 
\begin{lemma}[Separability]
Let  and  be disjoint multisequents (i.e. there is no occurence of formulas shared by  and ), the multisequent  is provable iff  is provable and  is provable. 
\end{lemma}

\begin{lemma}[Asynchrony]\label{lemma:asynchrony}
The connectives  are asynchronous: let R be an 
inference rule of one of these connectives (denoted  below), let 
 be a provable sequent of proof

then there exists a proof of the same height of  with R as the last rule.
\end{lemma}

\begin{lemma}[Synchrony of the cut rule]
The cut rule is synchronous, i.e. let a proof of  be of the form in the left hand side (R is a rule), then one can build a proof of the same height of  of the form in the right hand side:
\vspace{-.2cm}

\end{lemma}



\begin{Fig.}
{\em Structural rules}


{\em Logical rules} (in rules  and , the multisequent consists of only one sequent)


{\em Cut rule}

\caption{Sequent calculus for \CMALL}
\label{fig:seq-imp}
\end{Fig.}
 
\section{Shared and Unshared Modalities}\label{sec:modalities}



Modalities may be added to the system in the spirit of exponentials in Soft Linear Logic~\cite{DBLP:journals/tcs/Lafont04}.
They are written as upperscripts on formulas:  and .
The sharing  modality (resp. the unsharing ) is reminiscent of the why-not  (resp. the of-course ). Rules are completed with the ones given below:



\begin{proposition}
Cut-elimination for \CMALL\ with modalities is valid.
\end{proposition}

\begin{example}(Rule instantiation)

\end{example}




The sharing modality enjoys the following property:  is provable


The previous example shows that a unique resource  may be used for two different actions: let us suppose a system has one resource , and a set of processes each needing 
one resource , may we run them together ? The answer is yes if two conditions
are satisfied: (i) each process accepts to share its needed resource with others,
(ii) the processes run concurrently.
We formalize each process  as  where  ( is
the formula modelling the result of ): this answers condition (i).
Concurrence between processes is denoted as .
We have then the following provable and non-provable two-sided sequents ():




The fact that the third sequent is not provable is obvious (even if each process is modelled  !). We just give the proofs for the two others (we set  in the
second proof for sake of clarity).







 


\section{Conclusion}\label{sec:conclusion}



An original logic calculus (with variants) is presented that is a conservative extension of Linear Logic, at the theoretical level, and at the language level. 
The motivation beneath this work concerns lazy evaluation,
true concurrency and interferences in proof search.
We show that cut elimination is false if one considers a naive approach. The calculus \CMALL\ adds two new connectives to deal with multisequent structures. It has the cut-elimination property. Extensions are proposed that give first results concerning our objectives.
 

\bibliographystyle{splncs}
\bibliography{Fouquere}



\newpage
\section{Annex: Sequent Calculus}





We only give sketches of the proofs.

\begin{lemma}[Separability]
Let  and  be disjoint multisequents (i.e. there are no occurences of formulae appearing in  and 
in ), the multisequent  is provable iff  is provable and  is provable. 
\end{lemma}

\begin{proof}
The structural rule of separation  gives one direction. The other direction results from the following remark: principal sequents give linked sequents in the conclusion, except for the rule of separation . Hence rules apply independently on  and .
\end{proof}





\begin{lemma}[Asynchrony]
The connectives  are asynchronous: let R be an 
inference rule of one of these connectives (noted  below), let 
 be a provable sequent of proof

then there exists a proof of  with R as the last rule.
\end{lemma}

\begin{proof}
It suffices to prove that a rule may be shifted upward if the before last rule
concerns an asynchronous connective. This is proved by induction on the 
height of the proof.

\begin{description}
\item[\fbox{case }] \ \\
     \begin{description}
     \item[rule : ] From ( and  range over  and  in the following proof):
          
          then one can define the following proof:
          
     \item[rule : ] From:
          
          One can build (twice rule d):
                  
     \item[rule : ] From ( ranges over  and ,
 and  range over  and ):
          
          One can build:
          
     \item[rule : ] From ( and  range over  and ,  and  range 
     over  and ):
          
          One can build:
                
     \item[Other rules: ] Other cases are immediate.
     \end{description}
\item[\fbox{case }] \ \\
     \begin{description}
     \item[rule : ] From:
          
          One can build (twice rule w):
          
     \item[rule : ] From:
          
          One can build (twice rule d):
          
     \item[rule : ] From:
              
          One can build:
          
      \item[rule : ] From:
          
         One can build:
         
      \item[rule : ] From:
         
         One can build:
         
      \item[rule : ] From:
         
         One can build:
         
      \end{description}
\item[\fbox{case other}] Other cases are treated as usual.
\end{description}

\end{proof}



\begin{lemma}[Synchrony of the cut rule]
The cut rule is synchronous, i.e. let a proof of  be of the following form (R is a rule):

one can build a proof of  of the form:

Moreover, the height of the partial proof ending with the cut rule in the second case is less than in the first case.
\end{lemma}

\begin{proof}
By proving permutation properties as for proving synchrony of .
\end{proof}





\begin{proposition}
The system enjoys cut-elimination: if  is a provable multi-sequent, 
then there exists at least one cut-free proof of .
\end{proposition}

\begin{proof} By induction on the height of the proof. The synchrony of cut 
allows us to check only the last rule applied on each branch. Furthermore,
as the connectives ,  and  are asynchronous, we are
allowed to consider that only dual rules are applied as last rules.
\begin{description}
\item[\fbox{case Axiom}] Obvious.
\item[\fbox{case /} ] This case is obvious as the proof looks like:

\item[\fbox{case /} ] From:

One can build:

\item[\fbox{case /} ] From:

One can build:

\item[\fbox{case }] From:
     
     One can infer:
     
\end{description}
\end{proof}
 

\end{document}
