\documentclass[dvips,11pt,letter]{article}

\textwidth=6.5in                                \hoffset=0in
\oddsidemargin=0in                                \evensidemargin=0in                                

\textheight=9in                                        \voffset=0in
\topmargin=-0.5in                                        \headheight=0.3in                                        \headsep=0.2in                                        



\skip\footins=4ex                                \hbadness=10000                                        

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}

\usepackage{graphicx}



\usepackage{algorithmic} \usepackage{algorithm} 




\newcommand{\oneone}{1\!\!1}
\newcommand{\one}[1]{\oneone\left(#1\right)}
\newcommand{\stacktwo}[2]{\begin{array}{c}#1 \\#2\end{array}}
\newcommand{\mat}[2]{\left(\begin{array}{#1}#2\end{array}\right)}
\newcommand{\piecewise}[1]{\left\{\begin{array}{@{\;}ll}#1\end{array}\right.}
\newcommand{\set}[1]{\{#1\}}                        \newcommand{\setof}[2]{\{\,{#1}\::\:{#2}\,\}}        \newcommand{\groupFrac}[2]{\left(\frac{#1}{#2}\right)}

\newcommand{\sm}{\setminus} \newcommand{\compl}[1]{\overline{#1}}                \newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\argmax}{\arg\max}
\DeclareMathOperator{\argmin}{argmin}

\newcommand{\C}{\mathbb{C}}                        \newcommand{\N}{\mathbb{N}}                     \newcommand{\Q}{\mathbb{Q}}                     \newcommand{\R}{\mathbb{R}}                     \newcommand{\Z}{\mathbb{Z}}                     

\newcommand{\pr}[1]{\mathrm{Pr}\left(#1\right)}
\newcommand{\var}[1]{\mathbf{Var}\left[#1\right]}
\newcommand{\E}[1]{\mathbf{E}\left[#1\right]}
\newcommand{\Esub}[2]{\mathbf{E}_{#1}\left[#2\right]}
\newcommand{\cpr}[2]{\mathrm{Pr}\left(#1|#2\right)}

\newcommand{\tand}{\textrm{ and }} \newcommand{\tif}{\textrm{if }} \newcommand{\tor}{\textrm{ or }} \newcommand{\ow}{\textrm{otherwise}}

\newcommand{\bigO}[1]{O\left(#1\right)}
\newcommand{\bigOTilde}[1]{\tilde O\left(#1\right)}
\newcommand{\bigOmega}[1]{\Omega\left(#1\right)}

\newcommand{\tab}{\hspace*{1em}} 



\newtheorem{theorem}{Theorem} \newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{anonCorollary}{Corollary}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{prob}[theorem]{Problem}



\addtolength{\marginparwidth}{-10pt}
\newcommand{\footcomment}[1]{} \newcommand{\margincomment}[1]{} \newcommand{\commentw}[1]{\margincomment{WS: #1}}
\newcommand{\commentc}[1]{\margincomment{CM: #1}}
\newcommand{\footcommentw}[1]{\footcomment{WS: #1}}
\newcommand{\footcommentc}[1]{\footcomment{CM: #1}}



\newcommand{\unaryOrdering}{\!\!\mapsto\!\!}
\newcommand{\addApprox}{\textsc{AddApprox}}

\newcommand{\betTour}{\textsc{BetweennessTour}}
\newcommand{\fast}{\textsc{FAST}}

\newcommand{\posns}{\mathcal{P}}

\newcommand{\bp}{\,\,\rule[-0.22em]{0.08em}{1em}\,\,} \newcommand{\restrictO}[2]{{#1}_{#2}}

\newcommand{\roundOpt}{\sigma^{\Box}} 

\newcommand{\costlyB}{2 \binom{k}{2} \epsilon \binom{n-1}{k-1}} 

\newcommand{\versions}[2]{#2} \newcommand{\fullOnly}[1]{\versions{}{#1}}
\newcommand{\shortOnly}[1]{\versions{#1}{}}

\begin{document}

\title{\huge
  \textbf{
    Approximation Schemes for the~Betweenness~Problem in Tournaments   
    and Related Ranking Problems\2ex]}
\date{}
\maketitle

\begin{abstract}
{\normalsize
We design the first \emph{polynomial time approximation schemes (PTASs)} for the
\emph{Minimum Betweenness} problem in tournaments and some related higher arity
ranking problems. This settles the approximation status of the Betweenness problem
in tournaments along with other ranking problems which were open for some time now. The results depend on a new technique of dealing with fragile ranking constraints and could be of independent interest.
}
\end{abstract}



\section{Introduction}

We study the approximability of the Minimum Betweenness problem in tournaments
(see \cite{AA07}) that resisted so far efforts of designing polynomial time approximation algorithms with a constant approximation ratio.
For the status of the general Betweenness problem, see e.g. \cite{O79,CS98,AA07,CGM09}.

In this paper we design the first \emph{polynomial time approximation scheme} (PTAS) for that problem, and generalize it to much more general class of ranking CSP problems, called here \emph{fragile} problems.
To our knowledge it is the first nontrivial approximation algorithm for the Betweenness problem in tournaments.

In the Betweenness problem we are given a ground set of \emph{vertices} and a set of \emph{betweenness constraints} involving  vertices and a \emph{designated} vertex among them.
The cost of a ranking of the elements is the number of betweenness constraints with the designated vertex not between the other two vertices.
The goal is to find a ranking \emph{minimizing} this cost.
We refer to the Betweenness problem in tournaments, that is in instances with a constraint for every triple of vertices, as the \betTour{} or \emph{fully dense} Betweenness problem (see \cite{AA07}).
We consider also the -ary extension -\fast{} of the Feedback Arc Set in tournaments (\fast) problem (see \cite{mathieu09fast,A07,ACN08}).

We extend the above problems by introducing a more general class of \emph{fragile ranking} -CSP problems.
A \emph{constraint}  of a ranking -CSP problem is called \emph{fragile} if no two rankings of the vertices  that both satisfy the constraint differ by the position of a single vertex.
A \emph{ranking} -CSP problem is called \emph{fragile} if all its
constraints are fragile.

We now formulate  our main results.
\begin{theorem} \label{thm:main}
There exists a PTAS for the \betTour{} problem.
\end{theorem}
The above answers an open problem of \cite{AA07} on the approximation status of the Betweenness problem in tournaments.

We now formulate our first generalization.
\begin{theorem} \label{thm:strongFragile}
There exist PTASs for all \emph{fragile ranking} -CSP problems in tournaments.
\end{theorem}

Theorem \ref{thm:strongFragile} entails, among other things, existence of a PTAS for the -ary
extension of \fast{}. A PTAS for 2-\fast{} was given in \cite{mathieu09fast}.

\begin{anonCorollary}
There exists a PTAS for the -\fast{} problem.
\end{anonCorollary}

We  generalize \betTour{} to arities  by specifying for each constraint  a pair of vertices in  that must be placed at the ends of the ranking induced by the vertices in . Such constraints do not satisfy our definition of fragile, but do satisfy a weaker notion that we call \emph{weak fragility}. The definition of weakly fragile is identical to the definition for fragile except that only four particular single vertex moves are considered, namely swapping the first two vertices, swapping the last two, and moving the first or last vertex to the other end.
We now formulate our most general theorem.
\begin{theorem} \label{thm:weakFragile}
There exist PTASs for all \emph{weak-fragile ranking} -CSP problems in tournaments.
\end{theorem}

\begin{anonCorollary}
There exists a PTAS for the -\betTour{} problem.
\end{anonCorollary}

Additionally our algorithms are guaranteed not only to find a \emph{low-cost} ranking but also a ranking that is \emph{close to an optimal ranking} in the sense of Kendall-Tau distance. Karpinski and Schudy \cite{karpinski10exact} recently utilized this extra feature to find an improved parameterized algorithm for \betTour{} with runtime .

\begin{theorem}
The PTASs of Theorem \ref{thm:weakFragile} additionally return a set of  rankings, one of which is guaranteed to be both cheap (cost at most ) and close to an optimal ranking (Kendall-Tau distance ).
\end{theorem}

All our PTASs are randomized but one can easily derandomize them by exhaustively considering every possible random choice.

\medskip

Section \ref{sec:notation} introduces notations and the problems we study. Section \ref{sec:algo} introduces our algorithm and an intuitive sense of why it works. Section \ref{sec:runtime} analyzes the runtime. The remaining sections analyze the cost of the output of our algorithms.

\section{Notation}\label{sec:notation}
First we state some core notation. Throughout this paper let  refer to the set of  objects (vertices) being ranked and  the desired approximation parameter. Our  hides  but not  or . Our  additionally hides . A \emph{ranking} is a bijective mapping from a ground set  to . An \emph{ordering} is an injection from  into . We use  and  (plus superscripts) to denote rankings and orderings respectively. Let  denote an optimal ordering and  its cost. We let  (for example) denote the standard binomial coefficient and  denote the set of subsets of set  of size .

For any ordering  let  denote the ranking naturally associated with . To help prevent ties we relabel the vertices so that .
We will often choose to place  in one of  positions  (the  term breaks ties).
We say that an ordering is a \emph{bucketed ordering} if  for all .
Let  denote the bucketed ordering corresponding to  (rounding down), i.e.\  equals  rounded down to the nearest multiple of , plus .

Let  denote the ordering over  which maps vertex  to position .
For set  of vertices and ordering  with domain including  let  denote the ordering over  which maps  to , i.e.\ the restriction of  to . For orderings  and  with disjoint domains let   denote the natural combined ordering over . For example of our notations,  denotes the ordering over  that maps  to  and  to .

A ranking -CSP consists of a ground set  of \emph{vertices}, an arity , and a \emph{constraint system} , where  is a function from rankings of  vertices to .\footnote{Our results transparently generalize to the  case as well, but the 0/1 case allows simpler terminology.}
Note that  depends on the names of the vertices in the domain of its argument. In particular if ,  and  are vertices then ,   and  are all different (although  and  are the same).
We say that a subset  of size  is \emph{satisfied} in ordering  of  if . For brevity we henceforth abuse notation and omit the ``'' and  write simply . The objective of a ranking CSP is to find an ordering  (w.l.o.g.\ a ranking) minimizing the number of unsatisfied constraints, which we denote by . We will frequently omit the superscript , in which case it should be understood to be the constraint system of the overall problem we are trying to solve.

Abusing notation we sometimes refer to  as a \emph{constraint}, when we really are referring to  applied to orderings of .
A constraint  is \emph{fragile} if no two orderings that satisfy it differ by the position of a single vertex. In other words constraint  is fragile if  for all rankings  and  over  that differ by a single vertex move, i.e.\  for some  and . An alternate definition is that a satisfied fragile constraint becomes unsatisfied whenever a single vertex is moved, which is why it is called ``fragile.'' Fragility is illustrated in Figure \ref{fig:fragile}.

\begin{figure}[t]
\begin{center}
\includegraphics[width=0.7\textwidth]{fragile}
\end{center}
\caption{An illustration of fragility. For a constraint to be fragile all the illustrated single vertex moves must make any satisfied constraint unsatisfied.}
\label{fig:fragile}
\end{figure}

\begin{figure}[t]
\vspace{1.5em} \begin{center}
\includegraphics[width=0.7\textwidth]{weakFragile}
\end{center}
\caption{An illustration of weak fragility. For a constraint to be weak fragile all the illustrated single vertex moves must make any satisfied constraint unsatisfied.}
\label{fig:weakFragile}
\end{figure}

A constraint  is \emph{weakly fragile} if  for all rankings  and  that differ by a swap of the first two vertices, a swap of the last two, or a cyclic shift of a single vertex. In other words  for some  and  with . Observe that this is equivalent to ordinary fragility for . Weak fragility is illustrated in Figure \ref{fig:weakFragile}.

Our techniques handle ranking CSPs that are \emph{fully dense} with weakly fragile constraints, i.e.\ every set  of  vertices corresponds to a weakly fragile constraint. Fully dense instances are also known as tournaments.

Let  denote the cost of the constraints involving vertex  in ordering  formed by moving  to position  in ordering . Formally , where the sum is over sets  of size . Note that this definition is valid regardless of whether or not  is in . The only requirement is that the range of  excluding  must not contain . This ensures that the argument to  is an ordering (injective). We will usually omit the superscript  (as with ).

We call a non-negative weight function  over the edges of the complete graph induced by some vertex set  a \emph{feedback arc set (FAS) instance}. We can express the feedback arc set problem in our framework by the correspondence .
Abusing notation slightly we also write  for  with the above .
More concretely .
Similarly we write .
If a FAS instance satisfies  for all  and some  we call it a (weighted) feedback arc set tournament (\fast{}) instance.
It is easy to see that \fast{} captures all possible fragile constraints with .
We generalize to -FAST as follows: a -FAST constraint over  is satisfied by one particular ranking of  and no others. Clearly -FAST constraints are fragile.

We generalize \betTour{} to  as follows. Each constraint  designates two vertices , which must be the first and last positions, i.e.\ if  is the ranking of the vertices in  then . It is easy to see that \betTour{} constraints are weakly fragile.

We use the following two results from the literature.

\begin{theorem}[\cite{mathieu09fast}] \label{thm:fastPTAS}
Let  be a FAS instance satisfying  for  and . 
There is a PTAS for the problem of finding a ranking  minimizing  with runtime .
\end{theorem}

\begin{theorem}[e.g.\ \cite{AKK95,MS08}] \label{thm:addApproxCSP}
For any -ary MIN-CSP and  there is an algorithm that produces a solution with cost at most  more than optimal. Its runtime is .
\end{theorem}

Theorem \ref{thm:addApproxCSP} entails the following corollary.

\begin{corollary}\label{thm:addApproxRank}
For any  and constraint system  there is an algorithm \addApprox{} for the problem of finding a ranking  with , where  is an optimal ranking. Its runtime is .
\end{corollary}

\section{Intuition and algorithm}\label{sec:algo}

We are in need for some new techniques different in nature from the techniques used for weighted FAST \cite{mathieu09fast}.

Our first idea in this direction is somehow analogous to the approximation of a differentiable function by a tangent line. Given a ranking  and any ranking CSP, the change in cost from switching to a similar ranking  can be well approximated by the change in cost of a particular weighted feedback arc set problem (see proof of Lemma \ref{lem:piThree}). Furthermore if the ranking CSP is fragile and fully dense the corresponding feedback arc set instance is a (weighted) tournament (Lemma \ref{lem:wBarFAST}). So \emph{if} we somehow had access to a ranking similar to the optimum ranking  we could create this FAST instance and run the existing PTAS for weighted \fast{} \cite{mathieu09fast} to get a good ranking.

We do not have access to  but we can use a variant of the fragile techniques of \cite{KS09} to get close. We pick a random sample of vertices and guess their location in the optimal ranking to within (an additive) . We then create an ordering  greedily from the random sample.
We show that this ordering is close to , in that  for all but  of the vertices (Lemma \ref{lem:piOne}).

We then do a second greedy step (relative to ), creating . We then identify a set  of \emph{unambiguous} vertices for which we know  (Lemma \ref{lem:piTwo}). We temporarily set aside the  (Lemma \ref{lem:Usmall}) remaining vertices. These two greedy steps are similar in spirit to previous work on ordinary (non-ranking) everywhere-dense fragile CSPs \cite{KS09} but substantially more involved.

We then use  to create a (weighted) \fast{} instance  that locally represents the CSP. It would not be so difficult to show that  is a close enough representation for an additive approximation, but we want a multiplicative  approximation. Showing this requires overcoming two obstacles that are our main technical contribution.

Firstly the error in  causes the weights of  to have significant error (Lemma \ref{lem:w}) even in the extreme case of . At first glance even an exact solution to this \fast{} problem would seem insufficient, for how can solving a problem similar to the desired one lead to a precisely correct solution? Fortunately \fast{} is somewhat special. It is easy to see that a zero-cost instance of \fast{} cannot be modified to change its optimal ranking without modifying an arc weight by at least 1/2. We extend this idea to cases where  is small but non-zero (Lemma \ref{lem:piThree}).

The second obstacle is that the incorrect weights in FAST instance  may increase the optimum cost of  far above , leaving the PTAS for FAST free to return a poor ranking. To remedy this we create a new FAST instance  by canceling weight on opposing arcs, i.e.\ reducing  and  by the same amount. The resulting simplified instance  clearly has the same optimum ranking as  but a smaller optimum value. The PTAS for FAST requires that the ratio of the maximum and the minimum of  must be bounded above by a constant so we limit the amount of cancellation to ensure this (Lemma \ref{lem:wBarFAST}). It turns out that this cancellation trick is sufficient to ensure that the PTAS for FAST does not introduce too much error (Lemma \ref{lem:fastCheap}).

Finally we greedily insert the relatively few ambiguous vertices into the ranking output by the PTAS for \fast{} \cite{mathieu09fast} (Appendix \ref{sec:analysis}).

\bigskip

\begin{algorithm}[btp]
Input: Vertex set , , arity , system  of fully dense arity  constraints, and approximation parameter .
\begin{algorithmic}[1]
\STATE Run  and return the result if its cost is at least 
\STATE Pick sets  uniformly at random with replacement from , where .  Guess (by exhaustion) bucketed ordering , which is the restriction of  to the sampled vertices , where  is an optimal ranking.
\STATE Compute bucketed ordering  greedily with respect to the random samples and : \\
 where .
\STATE For each vertex : If  for some  then call  \emph{unambiguous} and set  to the corresponding  (pick any if multiple  satisfy). Let  denote the set of unambiguous vertices, which is the domain of bucketed ordering .
\STATE Compute feedback arc set instance over unambiguous vertices  with weights  (see text). Solve it using the \fast{} PTAS \cite{mathieu09fast}. Do single vertex moves until local optimality (with respect to the \fast{} objective function), yielding ranking  of .
\STATE Create ordering  over  defined by . In other words insert each vertex  into  greedily. 
\STATE Return .
\end{algorithmic}
\caption{A -approximation for weak fragile rank -CSPs in tournaments.\label{alg:main}}
\end{algorithm}


For any ordering  with domain  we define a weighted feedback arc set instance  as follows. Let  equal the number of the constraints  with  where (1) , (2)  if  and  otherwise, and (3)  is sufficiently small to put  adjacent to . In other words if  is after  in  it is placed immediately before  in . Observe that . For any two orderings  and  we use the abbreviation .
The following Lemma follows easily from the definitions.

\begin{lemma}\label{lem:objEq}
For any ordering  we have (1)  and (2)  for all .
\end{lemma}

\begin{proof}
Observe that all  that contribute to  or  satisfy  and hence such  are equal to the number of constraints containing  and  that are unsatisfied in . The  and  factors appear because constraints are counted multiple times.
\end{proof}

For any ordering  we define another weighted feedback arc set instance \\
,
 where  is the domain of . For any orderings  and  let . Observe that the feedback arc set problems induced by  and  have the same optimal rankings but  has a smaller objective value and hence they are not equivalent for approximation purposes. In other words  for all rankings  and .

For any orderings  and  with domain , we say that  is a \emph{-inversion} if  and  have different signs. Let  denote the number of -inversions (a.k.a.\ Kendall Tau distance).
We say that  does a \emph{left to right -crossing} if  and . 
We say that  does a \emph{right to left -crossing} if  and . We say that  does a \emph{-crossing} if  does a crossing of either sort.
We say that  \emph{-crosses}  if it does a -crossing.

With these notations in hand we now formalize the ideas described in our Algorithm \ref{alg:main}. The non-deterministic ``guess (by exhaustive sampling)'' on line 2 of our algorithm should be implemented in the traditional manner: place the remainder of the algorithm in a loop over possible orderings of the sample, with the overall return value equal to the best of the  rankings found. Our algorithm can be derandomized by choosing   non-deterministically rather than randomly; see Section \ref{sec:runtime} for details.

If  then the first line of the algorithm is sufficient for a PTAS so for the remainder of the analysis we assume that . \fullOnly{For most of the analysis we actually need something weaker, namely that  is at most some sufficiently small constant times . We only need the full  in one place in Section \ref{sec:analysis}.}

\section{Runtime analysis} \label{sec:runtime}

By Theorem~\ref{thm:addApproxRank} the additive approximation step takes time . There are at most  bucketed orderings  to try. The PTAS for FAST takes time  by Theorem~\ref{thm:fastPTAS}. The overall runtime is 


Derandomization increases the runtime of the two algorithms that we use as subroutines to . There are at most  possible sets  that the derandomized algorithm must consider. Therefore the overall runtime is 


\section{Analysis of } \label{sec:sigmaOne}

Let .
Call vertex  \emph{costly} if  and \emph{non-costly} otherwise.

\begin{lemma}\label{lem:fewCostly}
The number of costly vertices is at most .
\end{lemma}

\begin{proof}At most an  fraction of all pairs of vertices are a /-inversion. Therefore by union bound at most an  fraction of the  possible constraints involving any particular vertex  contain a /-inversion. Therefore for any costly  we have

Rearranging we get


Finally observe that , completing the proof.
\end{proof}

\begin{lemma}\label{lem:fragile} Let  be an ordering of , ,  be a vertex and .
Let  be the set of vertices (excluding ) between  and  in . 
Then
. 
\end{lemma}

\begin{proof}By definition

where the sum is over sets  of  vertices.

We first consider the illustrative special case of betweenness tournament (or more generally fragile problems with arity ). Betweenness constraints have a special property: the quantity in brackets in (\ref{eqn:pen}) is at least 1 for every  that has at least one vertex between  and  in . There are at least  such sets, which can easily be lower-bounded by the desired .

Returning to the general case of weak fragility, observe that the quantity in brackets in (\ref{eqn:pen}) is at least 1 for every  that either has all  vertices between  and  in  or has one vertex between them and the remaining  either all before or all after. To lower-bound the number of such  we consider two cases.

If  then the number of such  is at least  for sufficiently large .

If  then either at least  vertices are before or at least  vertices are after hence the number of such  is at least 
 for sufficiently large .
\end{proof}


For vertex  we say that a position  is  \emph{-out of place} if there are at least  vertices between  and  in . We say vertex  is \emph{out of place} if  is -out of place.

\begin{lemma}\label{lem:random}
The number of non-costly out of place vertices is at most  with probability at least 9/10.
\end{lemma}

\begin{proof}Focus on some  and . From the definition of out-of-place and Lemma \ref{lem:fragile} we have

for any -out of place . Next recall that for non-costly  we have

hence 

for any -out of place .

Recall that

for any . Each term of the sum is a 0/1 random variable with mean . Therefore . We can bound  using (\ref{eqn:onCheap}). For any -out of place  we can bound  by (\ref{eqn:offExpensive}).

We can bound the probability that sum in  is at least  using a Chernoff bound as 

for sufficiently large . Similarly for any -out of place  we can bound the probability that  is at most  by .  Therefore by union bound the probability of some -out of place  having  too small is at most . Clearly  so each vertex  is out of place with probability at least . A Markov bound completes the proof.
\end{proof}

\begin{lemma}\label{lem:piOne}
With probability at least 9/10 the following are simultaneously true:
\begin{enumerate}
\item The number of out of place vertices is at most .
\item The number of vertices  with  is at most 
\item 
\end{enumerate}
\end{lemma}
\begin{proof}
By Lemma \ref{lem:fewCostly} and the fact  we have at most  costly vertices for   sufficiently large. Therefore Lemma \ref{lem:random} implies the first part of the Lemma. We finish the proof by showing that whenever the first part holds the second and third parts hold as well.

Observe that there are exactly  vertices in  between any two consecutive positions in . It follows that any vertex with  must necessarily be -out of place, completing the proof of the second part of the Lemma.

For the final part observe that if  and  are a /-inversion and not among the  out of place vertices then, by definition of out-of-place, there can be at most   vertices between  and  in . Each  therefore only  possibilities for . Therefore .
\end{proof}

Our remaining analysis is deterministic, conditioned on the event of Lemma \ref{lem:piOne} holding.

\section{Analysis of } \label{sec:sigmaTwo}

The following key Lemma shows the sensitivity of  to its first and third arguments.
\begin{lemma}\label{lem:bChangeFirst}
For any constraint system  with arity , orderings  and  over vertex set , vertex  and  we have

where  if ,  is , and  is the number of  that do a -crossing.
\end{lemma}
\begin{proof}
Fix , , , ,  and . Let  (resp. ) denote the vertices in  that do left to right (resp. right to left) -crossings. It is easy to see that a constraint ,  contributes identically to  and  unless either:
\begin{enumerate}
\item  and  have non-empty intersection (or)
\item  contains a -inversion .
\end{enumerate}
The first part of the Lemma follows easily.

Towards proving the second part we first bound . Observe that . Assume w.l.o.g.\ that . Observe that every pair  and  are a -inversion, hence
. We conclude that . Therefore the number of constraints of the first type is at most .

To simplify we bound

for sufficiently large .
\end{proof}

Observe that the quantity  in Lemma \ref{lem:bChangeFirst} is zero whenever  and  and  are both \emph{rankings}. Therefore we have the following useful corollary.

\begin{corollary} \label{lem:fastSVMlandscape}
Let  and  be rankings over vertex set  and  a FAST instance over . Then  for all  and .
\end{corollary}

\begin{lemma}\label{lem:Usmall}
For  in Algorithm \ref{alg:main} we have
.
\end{lemma}
\begin{proof}
Observe that the number of vertices that /-cross a particular  is at most  by Lemma~\ref{lem:piOne} (first part). Therefore we apply Lemmas \ref{lem:piOne} and \ref{lem:bChangeFirst}, yielding

for all  and .

Fix a non-costly . By definition of costly , hence , so .

Finally recall Lemma \ref{lem:fewCostly}.
\end{proof}

We define  to be the ranking induced by the restriction of  to , i.e.\ .

\begin{lemma}\label{lem:piTwo}
All vertices in the unambiguous set  satisfy . 
\end{lemma}
\begin{proof}
The triangle inequality  allows us to instead bound the two terms  and  separately by . We bound  first.

Since  is a ranking the number of vertices  between  and  in  is at least . Therefore we have


We next apply the first part of Lemma \ref{lem:bChangeFirst} to  and , bounding the number of crossings and  using the definition , yielding


Next recalling (\ref{eqn:s1bClose}) from the proof of Lemma \ref{lem:Usmall} we have


Combining (\ref{eq:technical1}), (\ref{eq:technical2}) and (\ref{eq:technical3}) we conclude that .

Now we prove .
Lemma~\ref{lem:Usmall}, the definition of , and the assumption that  imply that .
\end{proof}

\section{Analysis of } \label{sec:piThree}

Note that all orderings and costs in this section are over , not . We note that  Lemma~\ref{lem:Usmall} and the assumption that  is small imply that .

\begin{lemma}\label{lem:wBarFAST}
, i.e.\  is a weighted FAST instance.
\end{lemma}
\begin{proof}
We prove the more interesting lower-bound and leave the straightforward proof of the upper bound to the reader. Fix . We consider two cases.

If there are at least  vertices between  and  in  then we note that by weak fragility every constraint  with all vertices in  between  and  in  contributes at least  to . Therefore  for sufficiently large  and small .

If there are at most  vertices between  and  in  then consider constraints with all their vertices either all before or all after  and . We note that by weak fragility each such constraint  contributes at least  to . There are clearly either at least  vertices  before or at least  vertices after, hence at least  constraints for sufficiently large  and small .

We conclude that . The Lemma follows from the definition of .
\end{proof}

\begin{lemma}\label{lem:footInv}
Assume ranking  and ordering  satisfy  for all . 
For any , let  denote the number of  such that not all pairs  are in the same order in  and . We have .
\end{lemma}
\begin{proof}
Such a pair  must satisfy , but few constraints contain such a pair.
\end{proof}

\begin{lemma}\label{lem:w} The following inequalities hold:
\begin{enumerate}
\item  
\item 
\end{enumerate}
\end{lemma}
\begin{proof}
The only constraints  that contribute differently to the left- and right-hand sides of the first part are those containing a  that are a /-inversion. By Lemmas \ref{lem:piTwo} and \ref{lem:footInv} we can bound the number of such constraints by , completing the proof of the first part.

If  the second part follows from the first part and the trivial fact . Otherwise by the first part we have . Therefore by Lemma \ref{lem:wBarFAST}  hence  using the first part of the Lemma in the penultimate inequality.
\end{proof}

\begin{lemma}\label{lem:fastCheap} 
\begin{enumerate}
\item 

\item

\item

\end{enumerate}
\end{lemma}
\begin{proof}
From the second part of Lemma \ref{lem:w} and Lemma \ref{lem:objEq} we conclude that

proving the first part of this Lemma.

The PTAS for FAST guarantees

which combined with the first part  of this Lemma yields the second part.

Finally the first part of Lemma \ref{lem:w} followed by the first part of this Lemma imply

completing the proof of the third part of this Lemma.
\end{proof}

\begin{lemma}\label{lem:Dsmall}

\end{lemma}
\begin{proof}
 and  both have cost at most  (Lemma \ref{lem:fastCheap}, first and second parts) for the FAST instance  (Lemma \ref{lem:wBarFAST}).
\end{proof}

\begin{lemma}\label{lem:23close}
We have
 for all .
\end{lemma}
\begin{proof}
Fix . In this proof we write  (resp. ) as a short-hand for  (resp. ). Observe that there are at least  vertices between  and  in . Any such vertex  must contribute  to one of  and  and contribute  to the other.
By Lemma \ref{lem:wBarFAST} and local optimality of  we have


Now apply Corollary \ref{lem:fastSVMlandscape}

and then recall  by Lemma \ref{lem:Dsmall} and the assumption that  is small.

Next

Finally

which completes the proof of the Lemma.
\end{proof}

\begin{lemma}\label{lem:piThree}
.
\end{lemma}
\begin{proof}
First we claim that

where  is the number of constraints that contain one pair of vertices  in different order in  and  and another pair  with relative order in ,  and  not all equal. Indeed constraints ordered identically in  and  contribute zero to both sides of (\ref{eqn:piThree}), regardless of . Consider some constraint  containing a  /-inversion . If the restrictions of the three orderings to  are identical except possibly for swapping  then  contributes equally to both sides of (\ref{eqn:piThree}), proving the claim.

To bound  observe that the number of inversions  is . For any  Lemmas \ref{lem:23close}, \ref{lem:piTwo} and \ref{lem:footInv} allow us to show at most  constraints containing  contribute to , so  (Lemma \ref{lem:Dsmall}).

Finally bound , where the equality follows from the definition of  and the inequality is the third part of Lemma \ref{lem:fastCheap}.
\end{proof}


\section{Analysis of }  \label{sec:analysis}
In this section we prove Theorem~\ref{thm:weakFragile}:

and


If  then, as discussed in Section \ref{sec:algo}, Equation (\ref{eqn:pi4}) follows from the algorithm and the additive error guarantee. Equation (\ref{eqn:pi4close}) is vacuous in this case. It remains to show (\ref{eqn:pi4}) and (\ref{eqn:pi4close}) in the case that that Sections \ref{sec:sigmaOne}-\ref{sec:piThree} dealt with: .

First we prove (\ref{eqn:pi4}). We consider three contributions to these costs separately: constraints with 0, 1, or 2+ vertices in . 

The contribution of constraints with 0 vertices in  to the left- and right-hand sides of (\ref{eqn:pi4}) are clearly  and  respectively. We showed  in Lemma~\ref{lem:piThree}.

Second we consider the contribution of constraints with exactly 1 vertex in . Consider some .  We want to compare  and . Let  be the half-integer so that . The algorithm's greedy choice minimizes  so . Now using Lemmas \ref{lem:bChangeFirst} and \ref{lem:Dsmall} we have .  Note . Let .
We conclude by Lemma \ref{lem:Usmall} that the contribution of constraints with exactly 1 vertex in  is .

Finally by Lemma \ref{lem:Usmall} there are at most  constraints containing two or more vertices from .

This ends the proof of (\ref{eqn:pi4}).

Finally we prove (\ref{eqn:pi4close}). By Lemma \ref{lem:Dsmall} we have

Finally a pair of vertices can only be counted in  but not  if at least one of the vertices is in the ambiguous set . By Lemma \ref{lem:Usmall}
 so there at most  such pairs.

\section*{Acknowledgements}
We would like to thank Venkat Guruswami, Claire Mathieu, Prasad Raghavendra and Alex Samorodnitsky for interesting remarks and discussions.

\nocite{gutin09,KS09,CS98,KS09,AA07,ALS09,RV07,MS08,FK99,FKK06,BFK03,AKK95,AFKK02,CGM09}   

\bibliographystyle{abbrv}
\bibliography{bib}  







\end{document}
