[{'LEADERBOARD': {'Task': 'Multi-task Language Understanding', 'Dataset': 'MGSM', 'Metric': 'Average (%)', 'Score': '49.9'}}, {'LEADERBOARD': {'Task': 'Multi-task Language Understanding', 'Dataset': 'MMLU', 'Metric': 'Average (%)', 'Score': '70.7'}}, {'LEADERBOARD': {'Task': 'Multi-task Language Understanding', 'Dataset': 'MMLU', 'Metric': 'Parameters (Billions)', 'Score': '540'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'StrategyQA', 'Metric': 'Accuracy', 'Score': '76.6'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'StrategyQA', 'Metric': 'Accuracy', 'Score': '76.4'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'StrategyQA', 'Metric': 'Accuracy', 'Score': '61.9'}}, {'LEADERBOARD': {'Task': 'Cross-Lingual Question Answering', 'Dataset': 'TyDiQA-GoldP', 'Metric': 'EM', 'Score': '78.4'}}, {'LEADERBOARD': {'Task': 'Cross-Lingual Question Answering', 'Dataset': 'TyDiQA-GoldP', 'Metric': 'F1', 'Score': '88.5'}}, {'LEADERBOARD': {'Task': 'Cross-Lingual Question Answering', 'Dataset': 'TyDiQA-GoldP', 'Metric': 'EM', 'Score': '54.6'}}, {'LEADERBOARD': {'Task': 'Arithmetic Reasoning', 'Dataset': 'GSM8K', 'Metric': 'Accuracy', 'Score': '58.5'}}, {'LEADERBOARD': {'Task': 'Arithmetic Reasoning', 'Dataset': 'GSM8K', 'Metric': 'Parameters (Billion)', 'Score': '540'}}]
