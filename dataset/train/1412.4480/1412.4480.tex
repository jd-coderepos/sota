\begin{comment}
Performance fidelity represents the stability and precision of replay execution, which determines whether the performance improvement of the ULCP-free replay execution comes entirely from the benefits of ULCPs. (Section~\ref{sec:perf:fidelity})

Effectiveness tells us whether \textsc{PerfPlay} finds the most beneficial code region incurring the ULCPs (Section~\ref{sec:perf}) and the detected beneficial code region indeed leads to the severe performance impact (Section~\ref{sec:case:study}).

Efficiency shows whether the proposed dynamic locking strategy reduces the runtime overhead introduced by the lockset significantly.
\end{comment}
\subsection{Experimental Setup}
\begin{comment}
\begin{table}[tbp]   \centering
\tiny
\caption{Race checking}
\begin{tabular}{|c|c|c|}\hline
  \multirow{2}{*}{\textbf{App.}} &\multicolumn{2}{c|}{\textbf{\# Races}}\\
  \cline{2-3}
  &\textbf{original} &\textbf{ISO-free} \\ \hline \hline
  blackscholes  &0&0 \\
  bodytrack     &48&48 \\
  canneal       &1&1 \\
  dedup         &3&3 \\
  facesim       &131&131 \\
  ferret        &108&108 \\
  fluidanimate  &52&52 \\
  streamcluster &21&21 \\
  swaptions     &0&0 \\
  vips          &103&103 \\
  x264          &177&177 \\ \Xhline{1pt}
\end{tabular}
\label{table:race}
\end{table}
\end{comment}
\begin{comment}
Our evaluation mainly answers the following questions:
\begin{itemize}
  \item What's the number and distribution of each category of ISOs in multi-threaded applications?
  \item What's the growth scale of ISOs with the increase of the number of the threads?
  \item Are the test results produced by \textsc{PerfPlay} reliable?
  \item To what extent is the performance improved for the ISO-free execution with the incremental number of threads?
\end{itemize}
\end{comment}
\textbf{System configuration:} All experiments are performed on a machine with two Intel quadcore Xeon E5310 1.60Ghz processors, 8GB memory, one 250GB SATA hard disk, and 1Gbit Ethernet interface. The operating system was CentOS 5.6 (X86\_64) with Linux kernel 3.0.0-12.

\textbf{Benchmark test configuration:}
We evaluate \textsc{PerfPlay} using two servers (\emph{openldap} \cite{OpenLDAP} and \emph{mysql} \cite{mysql}), three desktop applications (\emph{pbzip2} \cite{pbzip2}, \emph{transmissionBT} \cite{transmissionbt} and \emph{handBrake} \cite{handbrake}) and PARSEC benchmarks \cite{parsec}. 

1) \emph{openldap}: a lightweight directory access protocol server. In our test, we use the default thread pool mode for \emph{openldap} server, and use the professional tool DirectoryMark by MindCraft\footnote{http://www.mindcraft.com/directorymark/} to benchmark it with the option of searching $2000$ entries.

2) \emph{mysql}: an open source database system which is widely-used in the world. We use the test tool mysqlslap released in \emph{mysql} software package to test \emph{mysql} with $1000$ queries, and $2$ iteration.

3) \emph{pbzip2}: a parallel implementation of the bzip2 compressor. We test it by compressing a $256$M file with two processors.

4) \emph{transmissionBT}: a BitTorrent client. We only test its download function by downloading a local 300M file.

5) \emph{handBrake}: a video transcoder. We test it by conversing a $256$M  DVD format file into MP$4$ format with H.$264$ codec, $30$ FPS.

6) \emph{PARSEC Benchmarks}: a benchmark suite with $12$ multi-threaded programs. We test all PARSEC benchmarks (except \emph{freqmine}) with \emph{simlarge} input. \textsc{PerfPlay} is implemented currently based on \textsf{pthread} library. As \emph{freqmine} benchmark is an \textsf{openMP} program, \textsc{PerfPlay} can not identify its synchronization. 

\textbf{Methodology:} To demonstrate the performance fidelity of \textsc{PerfPlay}, we perform the replay execution with the following four schemes:


1. Memory-based schedule (MEM-S)~\cite{pinplay}, which enforces a deterministic execution sequence of all shared memory accesses.

2. Synchronization-based schedule (SYNC-S)~\cite{Kendo} that enforces the total order of locks for the same input.

3. ELSC-based schedule (ELSC-S), which enforces the total order of locks for the same schedule.

4. Parallel replay for the original execution without any enforcement strategy for the events (ORIG-S).


We focus on the key part of dynamic executions in the trace replay. In our implementation, we have decoupled the replayed execution time of program from the other time-consuming manipulations, such as the loading of trace from disk into memory, and the trace format transformation from the string-style into the instruction-style.
\begin{comment}
\begin{figure*}
\setlength{\abovecaptionskip}{10pt}
\setlength{\belowcaptionskip}{-15pt}
\begin{minipage}[t]{0.34\linewidth}
\centering
\setcaptionwidth{2.2in}
\includegraphics[scale=1.32]{fig/growth.eps}
\caption{Growing number of ULCPs with the increasing number of threads}
\label{fig:growth}
\end{minipage}
\begin{minipage}[t]{0.34\linewidth}
\centering
\setcaptionwidth{2.2in}
\includegraphics[scale=0.235]{fig/performancefidelity.eps}
\caption{Performance fidelity comparison among different enforcement strategies for the order }
\label{fig:performancefidelity}
\end{minipage}
\begin{minipage}[t]{0.34\linewidth}
\centering
\setcaptionwidth{2.1in}
\includegraphics[scale=0.23]{fig/ISO_free.eps}
\caption{The normalized execution time through replaying the traces with and without ULCPs}
\label{fig:overlap}
\end{minipage}
\end{figure*}
\end{comment}
\begin{comment}
\begin{figure}[tbp] \setlength{\abovecaptionskip}{10pt}
\setlength{\belowcaptionskip}{-10pt}
\begin{minipage}{.5\linewidth}
\centering
\includegraphics[scale=0.22]{fig/performancefidelity.eps}
\caption{Performance fidelity comparison between different execution schemes for the replay}
\label{fig:performancefidelity}
\end{minipage}
\begin{minipage}{.5\linewidth}
\centering
\includegraphics[scale=0.23]{fig/ISO_free.eps}
\caption{The normalized execution time through replaying the traces with and without ULCPs}
\label{fig:overlap}
\end{minipage}
\end{figure}
\end{comment}
\begin{figure}[tbp] \centering
\includegraphics[scale=0.35]{performancefidelity.pdf}
\caption{Performance fidelity comparison between different execution schemes for the replay}
\label{fig:performancefidelity}
\end{figure}
\begin{figure}
\centering
\includegraphics[scale=0.35]{ISO_free.pdf}
\caption{The normalized execution time through replaying the traces with and without ULCPs}
\label{fig:overlap}
\end{figure}
\begin{comment}
\begin{table}[tbp]   \centering
\small
\caption{The proportional optimization range of the ISO performance regions for all ten sets of input data. For example, "2-5" column shows the performance proportion range of the identified regions appearing in 2-5 input after the optimization for each input.}
\begin{tabular}{|c|c|c|c|c|}\Xhline{1pt}
\multirow{2}{*}{\textbf{Application}}&\multicolumn{4}{|c|}{\textbf{Relative opt-proportion}}  \\ \cline{2-5}
  & \textbf{Single}&\textbf{2-5}&\textbf{6-9}&\textbf{All} \\ \hline \hline
  OpenLDAP&0&9.2-11.3\%&13.5-24.8\%&57.8-79.8\% \\
  MySQL&0.7-1.1\%&8.9-15.2\%&7.5-24.9\% &62.2-76.3\% \\ \hline
  pbzip2&0.3-0.9\%&2.7-6.5\%&19.2-25.3\% &78.1-84.2\% \\
  TransmissionBT&0&3.1-6.8\%&18.9-28.4\% &65.6-76.3\% \\
  Handbrake&0&11.7-19.9\%&26.7-36.6\% &51.5-72.1\% \\ \hline
  blacksholes&0&0&0 &0 \\
  bodytrack&1.7-3.4\%&5.9-9.8\%&11.4-30.4\%&71.2-84.5\% \\
  facesim&0&5.2-18.4\%&13.2-28.9\% &67.4-81.1\% \\
  fluidanimate&0&6.4-18.2&11.1-32.1&59.3-79.9\% \\
  swaptions&0&0&0 &0 \\ \Xhline{1pt}
\end{tabular}
\label{table:region}
\end{table}
\end{comment}
\subsection{Performance Fidelity of \textsc{PerfPlay}}
\label{sec:perf:fidelity}
To evaluate performance fidelity, two aspects are needed to be assessed, including performance stability and precision. Stability represents whether \textsc{PerfPlay} shows the same performance across the multiple replays with the same trace. The precision means whether \textsc{PerfPlay} strictly adheres to the original execution. If our debugging framework has a high precision, we can determine that the performance improvement of ULCP-free replayed execution comes entirely from the optimization of ULCPs.

We record all PARSEC benchmarks with \emph{simlarge} input, and we replay the trace of each application ten times using different replay schemes (i.e., MEM-S, SYNC-S, ELSC-S, and ORIG-S). Figure~\ref{fig:performancefidelity} shows the final replayed execution time using these schemes. {From the small error bars, we can see that MEM-S, SYNC-S, and ELSC-S all enforce the deterministic program execution for the multiple times}, thus providing the \emph{stable} performance analysis. Nevertheless, ORIG-S shows the indeterminate {(large error bars)} program execution due to the inter-thread lock interleaving. Except the nature of enforcement scheme itself, both MEM-S and SYNC-S manifest themselves with the additional performance introduction compared with ORIG-S. While ELSC-S eliminates the waiting time of SYNC-S for lock acquisition by only enforcing the synchronization order based on the scheduled synchronization order for the same schedule. As a result, we can see that ELSC-S almost produces the same program performance with ORIG-S. This yields the conclusion that \textsc{PerfPlay} with ELSC scheme strictly schedules the replay execution as the original scheduled execution without any additional performance introduction, thus providing the \emph{precise} performance analysis. {From the above-discussed results, it is revealed that only ELSC-S provides both the performance stability and performance precision, thus ensuring the performance fidelity of replay execution.}


\begin{table}[tbp]   \caption{\# Grouped ULCP code regions and optimization opportunity of the most beneficial one}
\small
\tabcolsep=0.1cm
\setlength{\abovecaptionskip}{10pt}
\setlength{\belowcaptionskip}{-10pt}
\centering
\begin{tabular}{|c|c|c|}\hline
\textbf{Applications}& \minitab[c]{\#Grouped\\ULCPs}& \textbf{$\sf ULCP_1.P$} \\ \hline \hline
{\sf openldap}&18 &30.1\%  \\
{\sf mysql}&57 &12.5\%  \\\hline
{\sf pbzip2}&4 &59.4\%  \\
{\sf transmissionBT}&2 &53.5\% \\
{\sf handbrake}&29 &15.4\%  \\ \hline
{\sf blackscholes}&0 &0  \\
{\sf bodytrack}&5 &20.9\%  \\
{\sf facesim}&11 & 31.2\% \\
{\sf fluidanimate}&3 &26.5\%  \\
{\sf swaptions}&0 &0  \\ \hline
\end{tabular}
\label{table:region}
\end{table}
\subsection{Performance Impact Evaluation}
\label{sec:perf}
Performance impact of ULCPs in this work includes:
\begin{itemize}
  \item \textbf{Performance degradation} ($T_{pd}$): The performance improvement of program before and after the optimization;
  \item \textbf{Resource wasting} ($T_{rw}$): In our test, resource wasting mainly refers to the wasting of CPU resource, which makes the useless ULCP computation (e.g., spin-lock) on the non-critical path.
\end{itemize}
\noindent where $T_{pd}$ can be directly quantified by replaying ULCP trace ($T_{ut}$) and ULCP-free trace ($T_{uft}$), i.e., $T_{pd}=T_{ut}-T_{uft}$. With Equation~\ref{equ:ilcp}, $T_{rw}$ can be indirectly calculated as $\sum \Delta ULCP -T_{pd}$. To quantify them in the following experiments, we evaluate them with the metric of the normalized performance impact (i.e., ${T_{pd}}/{T_{real}}$) and CPU-time wasting per thread on average (${T_{rw}}/{N_{thread}}$), respectively.
All tests are executed with two threads. 

\textbf{Performance impact of ULCPs:} Figure~\ref{fig:overlap} illustrates the normalized performance impact and normalized CPU-time wasting of ULCPs from $5$ real world programs and PARSEC benchmarks. In our tests, \textsc{PerfPlay} produces different opportunities of performance impact for different applications. For example, \emph{blacksholes}, \emph{canneal}, \emph{streamcluster}, and \emph{swaptions} hardly obtain any performance impact due to the correct use of lock or exclusive use of lock. While for other applications, such as \emph{openldqp}, \emph{mysql}, \emph{pbzip2}, the program has a significant percent for the improvement of performance ($1.6\%$--$11\%$) and CPU time per thread ($1.1\%$--$16.7\%$) due to the ULCPs. On average, the performance of these applications can be improved by $5.1\%$ and the resource utilization per thread by $7.85\%$. Usually, a program with more ULCPs has larger performance improvement, which indicates the benefits of removing ULCPs by our performance debugging framework. One exception is that, \emph{fluidanimate} has a larger number of ULCPs than \emph{facesim}, but produces a lower speedup. That is because ULCPs in \emph{facesim} have the larger-scale critical sections.

\textbf{Performance gain from the most beneficial ULCPs:} Table~\ref{table:region} reports the number of the exploited ULCP code regions and corresponding performance gain of the most beneficial one.
Column \emph{grouped ULCPs} counts total number of the unique ULCPs after the fusion and performance accumulation of ULCPs.
Column $ULCP_1.P$ (discussed in Section~\ref{sec:priortization}) shows the relative optimization portion of the most beneficial ULCP code regions among the total ULCP group set.
From Table~\ref{table:region}, we find that different applications show different optimization opportunities. For instance, \emph{openldap} has 18 grouped ULCP code regions while its most beneficial one takes up 30.1\% of optimization gain among the total ULCP set. \emph{mysql} produces a larger number (57), but the most beneficial one exhibits only 12.5\% of performance benefit.
The performance gain of the most beneficial ULCP code region for other applications can be seen in Table~\ref{table:region}.



\begin{comment}
\begin{table}[tbp]   \centering
\scriptsize
\tabcolsep=0.06cm
\caption{Number and corresponding overall performance gain of the beneficial ULCPs using K-constraint with $\theta=80\%$ and different $\eta$ =0.5, 0.15, 0.1, 0.05}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}\hline
\multirow{3}{*}{\textbf{Applications}}&\multicolumn{8}{c|}{\textbf{Choice of $\eta$}}&\multirow{3}{*}{\minitab[c]{grouped\\ ULCPs}}\\
\cline{2-9}
&\multicolumn{2}{c|}{\textbf{$\eta=0.5$}}&\multicolumn{2}{c|}{\textbf{$\eta=0.15$}}& \multicolumn{2}{c|}{\textbf{$\eta=0.1$}}&\multicolumn{2}{c|}{\textbf{$\eta=0.05$}}& \\ \cline{2-9}
 &k&$\sf \Sigma_{i=1}^k P_i$&k&$\sf \Sigma_{i=1}^k P_i$&k&$\sf \Sigma_{i=1}^k P_i$&k&$\sf \Sigma_{i=1}^k P_i$&\\ \hline \hline

openldap&- &- &\textbf{6} &\textbf{82.7\%} &11 &91.7\% &18 &100\% & 18\\
mysql&\textbf{27} &\textbf{80.1\%} &27 &80.1\% &27 &80.1\% &27 &80.1\% & 57\\ \hline
pbzip2&\textbf{2} &\textbf{85.7\%} &- &- &- &- &- &- &4 \\
transmissionBT&\textbf{2} &\textbf{100\%} &- &- &- &- &- &- & 2\\
handbrake&\textbf{14} &\textbf{80.3\%} &14 &80.3\% &14 &80.3\% &18 &88.2\% &29 \\ \hline
blackscholes&- &- &- &- &- &- &- &- &0 \\
bodytrack&\textbf{4} &\textbf{90.3\%} &- &- &- &- &- &- &5 \\
facesim&\textbf{4} & \textbf{80.1\%}&6 &88.5\% &10 &98.5\% &- &- &11 \\
fluidanimate&\textbf{2} &\textbf{85.6\%} &- &- &- &- &- &- &3 \\
swaptions&- &- &- &- &- &- &- &- &0 \\ \hline
\end{tabular}
\label{table:region}
\end{table}
\end{comment}

\begin{table}[tbp]   \caption{Runtime overhead of locksets with/without dynamic locking strategy}
\small
\tabcolsep=0.1cm
\setlength{\abovecaptionskip}{10pt}
\setlength{\belowcaptionskip}{-10pt}
\centering
\centering
\begin{tabular}{|c|c|c|}\hline
\textbf{Applications}& \textbf{w/o DSL}& \textbf{w/ DSL} \\ \hline \hline
{\sf blackscholes}& 0& 0 \\
{\sf bodytrack}& 5.3\% & 0.5\% \\
{\sf canneal}& 0.2\%& 0.2\%\\
{\sf dedup} &4.6\% & 0.7\%\\
{\sf facesim}&7.8\% &1.2\%  \\
{\sf ferret}& 10.7\%&3.6\% \\
{\sf fluidanimate}& 14.1\%& 4.3\%  \\
{\sf streamcluster}& 2.9\%&0.6\% \\
{\sf swaptions}& 0.4\%& 0.4\% \\
{\sf vips} &7.6\% & 2.4\% \\
{\sf x264}& 5.0\%& 1.9\% \\ \hline
\end{tabular}
\label{table:dsl}
\end{table}
\subsection{Overhead Reduction via Dynamic Locking Strategy}
Lockset is introduced to transform ULCPs into the parallel pattern. However, it also introduces the significant overhead for the determination of mutex relationship by intersecting two locksets in RULE~\ref{rule:4}, especially for the lock intensive programs. To quantify lockset (LS) overhead, we replay PARSEC benchmarks with and without dynamic locking strategy (DLS), respectively. Table~\ref{table:dsl} compares runtime overhead of locksets with and without DLS. When not using DSL, lockset maintenance incurs significant ($0.2\%-14.1\%$) amount of runtime overhead. In contrast, lockset with DLS further reduces performance impact of lockset into a negligible level, only incurring $4.3\%$ overhead even for the lock intensive application \emph{fluidanimate} which makes extensive use of locks.


\begin{figure}[tpb]
\centering
 \subfloat[The performance loss with the increasing number of threads]{\includegraphics[scale=0.17]{PD_threadnum.pdf}}
 \hfill
 \subfloat[The CPU wasting with the increasing number of threads]{\includegraphics[scale=0.17]{RW_threadnum.pdf}}
 \caption{ULCP impact with the increasing number of threads}
 \label{fig:perfImpact:threadnum}
\end{figure}
\begin{figure}[tpb]
\centering
 \subfloat[The performance loss with the varying input size]{\includegraphics[scale=0.16]{PD_input.pdf}}
 \hfill
 \subfloat[The CPU wasting with the varying input size]{\includegraphics[scale=0.16]{RW_input.pdf}}
  \caption{ULCP impact with the varying input size}
 \label{fig:perfImpact:input}
\end{figure}
\subsection{Sensitivity Study of ULCPs}
\label{lable:sensitivity}
To evaluate the evolution of ULCP impact, we study the ULCP sensitivity to the thread number and input size. We select \emph{canneal}, \emph{bodytrack}, \emph{fluidanimate} from PARSEC benchmarks with different numbers (i.e., a few, medium, large) of ULCPs.

Figure~\ref{fig:perfImpact:threadnum} depicts the sensitivity of ULCPs to the thread number. We can find that ULCPs lead to the increasing performance loss as the number of threads increases while the resource wasting per thread stays the same.
Figure~\ref{fig:perfImpact:input} depicts the sensitivity of ULCPs to the input size. It can be observed that both performance loss and resource wasting increase as the input size increases.
The explanation for both figures is: in those applications 1) all threads reuse the same code (e.g., functions) to perform the program execution; 2) more input sizes merely mean the number of executions on some code segments is increasing.

Note that \emph{canneal} still does not show any potential opportunity with both the increasing thread number and input size. Combining the results from \emph{bodytrack} with \emph{fluidanimate}, we seems to reveal that in most cases the ULCP code-sites are not affected by the thread numbers and input sizes of these applications. ULCPs can manifest themselves in two threads, and more thread numbers may only change their performance impact.
\begin{figure}[t]
\centering
\begin{tabular}{c}
\begin{lstlisting}[escapechar=@,linewidth=8cm]
int Query_cache::try_lock(bool){
  @\textbf{mysql\_mutex\_lock}@(&structure_guard_mutex);
  while(1){
  set_timespec_nsec(waittime,(@\textbf{\textcolor[rgb]{0.00,0.00,1.00}{ulong}}@)5000000L);
  int res=mysql_cond_timedwait(
            &COND_cache_status_changed,
            &structure_gurad_mutex,&waittime);
  if(res==EITMEOUT){
     ...
     break;
  }
  }
  @\textbf{mysql\_mutex\_unlock}@(&structure_guard_mutex);
}
\end{lstlisting}
\end{tabular}
\caption{A verified ULCP problem from \textsf{mysql}}
\label{fig:official:case}
\end{figure}
\begin{figure}[t]
\centering
\begin{tabular}{c}
\begin{lstlisting}[escapechar=@,linewidth=8cm]
void *consumer(void *q){
2109:   @\textbf{pthread\_mutex\_lock}@(&mu);
2122:   if(fifo->empty&&syncGetProducerDone()==1)
2124:         @\textbf{pthread\_mutex\_unlock}@(&mu);
     }
int syncGetProducerDone(){
 533:     int ret;
 534:     @\textbf{pthread\_mutex\_lock}@(&muDone);
 535:     ret=producerDone;
 536:     @\textbf{pthread\_mutex\_unlock}@(&muDone);
 537:     return ret;
 538: }
\end{lstlisting}
\end{tabular}
\caption{A ULCP problem from \texttt{pbzip2}}
\label{fig:pbzip}
\end{figure}
\begin{figure}[htpb]
\centering
 \subfloat[Case study with the varying number of threads]{\includegraphics[scale=0.17]{CS_threadnum.pdf}}
 \hfill
 \subfloat[Case study with the varying input size]{\includegraphics[scale=0.17]{CS_input.pdf}}
 \caption{Sensitivity study of \#BUG 1 and \#BUG 2}
 \label{fig:case:study}
\end{figure}

\subsection{Case Study}
\label{sec:case:study}
To evaluate the effectiveness of \textsc{PerfPlay}, we have checked some ULCP bugs that have already been verified by official bug system under \textsc{PerfPlay} framework.

{\bf MySQL \#68573}. Figure~\ref{fig:official:case} depicts the code snippet of this case from \textsf{mysql} version-$5.6.11$. The real designed intention of the programmers is that "a 50ms timeout for a SELECT statement waiting for the query cache lock is set. If the timeout expires, the statement executes without using the query cache"---\textsf{mysql} official documents. However, the ULCP performance problem "increases" this timeout threshold unwittingly when multiple threads invoke this code, thus severely degrading the efficiency of SELECT statement. Other examples in \textsf{mysql} include \textbf{\#37844}, \textbf{\#60951} and \textbf{\#69276}.

We also re-implement a few \emph{easy-to-understand} ULCP cases found by \textsc{PerfPlay} in a ULCP-free fashion, and further re-quantify its performance impact.

\textbf{Resource wasting from openldap} {\bf (\#BUG 1).} We re-implement the code snippet in Figure~\ref{fig:mtexample} with \texttt{pthread\_mutex\_barrier}, and re-quantify the CPU utilization of this ULCP problem by testing the program compared with the original code. 

\textbf{Performance degradation from pbzip2} {\bf (\#BUG 2).} Figure~\ref{fig:pbzip} depicts the simplified code of ULCP problem from the parallel compression utility pbzip2. It employs the producer-consumer idiom for the parallel compression: the producer produces the blocks by reading file and the multiple consumers consume (compress) these blocks in parallel. When the last file block is dequeued (i.e., \texttt{fifo->empty}=1 and \texttt{producerDone}=1), the program starts the end stage of thread join. In this case, the example above will incur many read-read ULCPs as follows:
\begin{lstlisting}[escapechar=@]
@\textbf{lock}@(mu);
@\textcolor[rgb]{0.25,0.00,0.50}{\textbf{load}}@(fifo->empty);
@\textbf{lock}@(muDone);@\textcolor[rgb]{0.25,0.00,0.50}{\textbf{load}}@(producerDone);@\textbf{unlock}@(muDone);
@\textbf{unlock}@(mu);
\end{lstlisting}
The joins of all threads are serialized and extra nested lock overhead is added by this read-read ULCP, which causes the performance loss. We fix it via the signal/wait model: we take the producer, rather than the consumer, with the responsibility of checking the state of \texttt{fifo->empty} and \texttt{producerDone}. If both of them are \textsf{true}, the producer will give a signal to inform all consumers of their safe exit without any check when their work is completed.

\textbf{Results}. Figure~\ref{fig:case:study} depicts the sensitivity of two exploited ULCP bugs (i.e., \#BUG 1 and \#BUG 2). As the number of threads increases, \#BUG 1 causes the stable resource wasting per thread while \#BUG 2 has an increasing performance loss of program. Whereas, different from the illustration shown in Figure~\ref{fig:perfImpact:input}(b), the performance impact of both \#BUG 1 and \#BUG 2 presents a downward trend as the input sizes increases. That is because for a given thread number both \#BUG 1 and \#BUG 2 have the fixed execution frequency, which rises superior to the input size. Moreover, the increasing input size aggravates the workload of application, thus increasing the program execution time. As a result, the performance impact of both \#BUG 1 and \#BUG 2 is declining. Both results verify that the real ULCPs can be exploited by \textsc{PerfPlay}.
\subsection{Discussion}
It is well-known that replay technique generally incurs the prohibitive overhead for the program execution. Hence it comes a big question that "\emph{is it reliable to use replay technique for the performance analysis?}" In our work, we investigate every time-consuming process of replay execution, such as the loading of trace from disk into memory, and the format transformation of trace. In the replay phase, we differentiate them from the real execution. Besides, in the real execution, there may be different strategies for the replay executions (such as, MEM-S and SYNC-S), which slows down the program execution to some extent. ELSC-S strategy eliminates the imprecise performance caused by them, further providing the faithfully original scheduling. Consequently, we argue that \textsc{PerfPlay} with ELSC-S strategy provides the correct ULCP recommendations although PIN framework may introduce the fairly-low (almost negligible~\cite{PIN}) baseline overhead. Our above-depicted results (shown in Section~\ref{sec:perf} and \ref{sec:case:study}) also verify this conclusion.

\textsc{PerfPlay} adapts one execution trace of the program to expose ULCPs, but we still believe it is useful to the programmers. First, we believe that performance debugging (ULCP in particular for this paper) is similar to the debugging process of common software bugs (e.g., error, failure, or fault). Programmers usually define a set of debugging cases. They usually perform step-by-step debugging as the program runs for a given input. This is simple and effective strategy. Likewise, we follow this strategy. Second, \textsc{PerfPlay}, still, can be extended to multiple traces.
