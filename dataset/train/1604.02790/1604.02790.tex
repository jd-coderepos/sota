\documentclass[oribibl]{llncs}

\usepackage{amsmath}
\usepackage[dvips]{graphicx}
\usepackage{dsfont}
\usepackage{amssymb}
\usepackage{amstext}
\DeclareGraphicsExtensions{.eps}
\usepackage{pdfsync}
\usepackage{subfigure}


\input xy
\xyoption{all}



\usepackage{proof}


\vfuzz2pt 

\newtheorem{thm}{Theorem}
 \newtheorem{cor}{Corolary}
 \newtheorem{lem}{Lemma}
 \newtheorem{prop}{Proposition}
 \newtheorem{defn}{Definition}
 \newtheorem{rem}{Remark}
 \newtheorem{exam}{Example}
 \newtheorem{motiv}{Motivation}
 \newtheorem{alg}{Algorithm}

\newcommand{\eps}{\varepsilon}
 \newcommand{\To}{\longrightarrow}
 \newcommand{\h}{\mathcal{H}}
 \newcommand{\s}{\mathcal{S}}
 \newcommand{\A}{\mathcal{A}}
 \newcommand{\B}{\mathcal{B}}
 \newcommand{\C}{\mathcal{C}}
 \newcommand{\D}{\mathcal{D}}
 \newcommand{\E}{\mathcal{E}}
 \newcommand{\F}{\mathcal{F}}
 \newcommand{\G}{\mathcal{G}}
 \newcommand{\J}{\mathcal{J}}
 \newcommand{\M}{\mathcal{M}}
 \newcommand{\R}{\mathcal{R}}
 \newcommand{\T}{\mathcal{T}}
 \newcommand{\W}{\mathcal{W}}
 \newcommand{\U}{\mathcal{U}}
 \newcommand{\X}{\mathcal{X}}
 \newcommand{\K}{\mathcal{K}}
\begin{document}


\title{Categorical semiotics}

\author{ Carlos Leandro}

\institute{
   \email{miguel.melro.leandro@gmail.com}\\ Departamento de Matem\'{a}tica, Instituto Superior de Engenharia de Lisboa,  Portugal. 
 }







\begin{abstract}
The integration of knowledge extracted from different models described by domain experts or from models generated by machine learning algorithms is strongly conditioned by the lack of an appropriated framework to specify and integrate structures, learning processes, data transformations and data models or data rules. In this work we extended algebraic specification methods to be used in this  type of framework. This methodology uses graphic structures similar to Ehresmann's sketches \cite{Adamek94}  interpreted on a fuzzy set universe. This approach takes advantages of the sketches ability to integrate data deterministic and nondeterministic structures. Selecting this strategy we also try to take advantage on how the graphic languages, used in Category theory in general and used for sketch definition in particular, are suited to reasoning about problems, to structural description and to task specification and task decomposition.
\end{abstract}

\maketitle


\section*{Introduction}

A model is a system of sets with relations providing
constrains upon the set system. A class of models, all similarly
structures, together with the structure preserving maps between them
is a category. For instance a relational database schema can be
viewed as a specification of a class of systems of sets having the
category of models defined by all the database states and
transformations between states. The relational database schema give
constrains on the state of the database.

The core of an information
system is a set of databases and sets of data transformations,
usually taking the form of workflows. In the modern view database
presents an internal model of real world fragment, and the
transformations offer different ways for construct views of this
fragment and integrate the different aspects of it. A
crucial step for the proper information system design is to specify
the universe and its views in abstract and formalized terms suitable
for semantic refinement, such as be used for low-level system
specification, and able to be used on the specification improvement
though the introduction of new knowledge about the data stored on
the system during its life time. This type of data structure
specification is called semantic modeling. It has to compress
information and process description into a comprehensible way
suitable for communication between database tools or designs, such
as between data mining processes and data analysts. The usual choice
is to use graphic languages, and indeed a great effort has been put
in the development of graphic denotational systems. The history of
graphic notations invented in various scientific and engineering
disciplines is rich. In last years one can observe a great diversity
of visual modeling languages and methods: ERdiagrams and a lot of
their dialects, OOA\&D-schemas in a million of versions and UML which itself comprises a host of various
notations. Our goal is to clarify the basic semantic foundations of
graph languages and present an integrated framework where different
languages and its semantics can be approached consistently and
integrated.

A good graphic language should be formalizable, sufficiently
expressive to capture all the pecualities of the real word, and must
be suitable for semantic refinement. We are particularly interested
in use the same language to model both deterministic and nondeterministic involved structures; for instance data structures and
models generated using machine learning algorithms. In our opinion the best
approach in terms of expressiveness and formalization  to
deterministic graphic specification is Category theory.

Category theory generalized the use of graphic language to specify
structures and properties through diagrams. These categorical
techniques provide powerful tools for formal specification,
structuring, model construction, and formal verification for a wide
range of systems, presented on a grate variety of papers. The data
specification requires finite, effective and comprehensive
presentation of complete structures, this type of methodology was
explored on Category theory for algebraic specification by
Ehresmann. He developed sketches as a specification methodology of
mathematical structures and presented it as an alternative to the
string-based specification employed in mathematical logic. The
functional semantic of sketches is sound in the informal sense that
it preserves by definition the structure given in the sketch. The
analogy to the semantics of traditional model theory is close enough
that sketches and their models fit the definition of "institution"
(see \cite{goguen83}), which is an abstract notion of a logic system
having syntactic and semantic components. The soundness of semantics
appears trivial contrasting with the inductive proof of soundness
that occur in string-based logic because the semantics functor is
not defined recursively. Sketch specification enjoy a unique
combination of rigor, expressiveness and comprehensibility. They can
be used for data modeling, process modeling and metadata modeling as
well thus providing a unified specification framework for system
modeling. However sketch structure forces us to take a global
perspective of the system. It makes impossible decomposing a
specification problem in subproblems. This makes difficult to
specify a large system as the interaction between subsystems or
components, which is a common practice, in engineering. We can give
a better view to this problem by means of a typical application, the
specification of workflows (for more details see
\cite{Baldanall05}). A workflow describes a business process in
terms of tasks and shared resources. Such descriptions are needed,
for example, when interoperability of the workflows of different
organizations is an issue, for example, when applications of
different enterprises are to be integrated over the Internet
\cite{Baldanall05}. A workflow is a net \cite{Aalst98}, some times a
Petri net, satisfying some structural constraints and the
corresponding soundness conditions. Usually the methodology used to
specify workflows have associated a library of components. An
interorganizational workflow is modeled as a set of such workflow
nets \cite{Aalst99} connected through additional places for
asynchronous communication and synchronisation requirements on
transitions. The difficulty of applying sketch to this type of task
results of the way composition is defined on the the category of
sets. We want to interpret a workflow as a arrow, where the gluing
of different workflows must be also interpreted as an arrow and must
be always defined. The net structure defined by a workflow is called
an oriented multi-graph since its components are relations linking
together families defined by sets of entities or data structures.

For our goal we extend the syntax of sketch to multi-graphs and
define its models on a class of fuzzy relations (see \cite{Johnstone02}). Where multi-graphs nodes are interpreted as relations. To extend the
syntax of a sketch we began by formalize a library as the syntactic
structure of admissible configurations using components on that
library. This approach is based on the notion of component, used to
define relationships between two families of entities, and which can
be organized following an hierarchy of complexity. A
component if not atomic is defined by the plugging of other
components. We see the set of admissible configurations as the
graphic language defined by the library structure. A model of a
library is a map from the library multi-graph to the structure associated to the class of relations defined using a multi-valued logic. An interpretation for an
admissible configuration, is defined for each library model. It is
the limit of the multi-graph, in the category of -sets, resulting of applying a library model to a
admissible multi-graph. It seems to be the adequate framework for the definition and the study of graphic-based logics, if we interpret one of its node as the set of truth values.

We used libraries as a way to define the lexicon of the language used on the description of a domain. The category defined by library models and natural transformation aren't a accessible category (see \cite{Adamek94}) it can't be axiomatized by a basic theory in first-order logic. By this we mean what classic Ehresmann sketches not have sufficient expressive power to specify the category of library models defined in a multi-valued logic with more than three truth values.

To be able to formalize linguistic, Chomsky in \cite{chomsky57}
propose a language as a set of grammatically correct sentences
possible in the language. The goal of defining a language is then to
characterize the set of grammatical sentences explicitly, by means
of a formal grammar. The two main categories of grammar are that of
\emph{generative grammar}, which are sets of rules for how elements
of a language can be generated, and that of \emph{analytic
grammars}, which are sets of rules for how a structure can be
analyzed to determine whether it is a member of the language. In
this sense, our approach to the definition of a graphic language
based on libraries of components uses a multi-graph as the language
analytic grammar.

A generative grammar does not in any way correspond to the algorithm
used to parse the generated language. Analytic grammar corresponds
more directly to the structure and the semantic of a parser for the
language. Examples of analytic grammars formalisms include top-down parsing language (TDPL)\cite{Birman}, link
grammars \cite{Sleator91} and parsing expression grammars \cite{Ford04}.

Our extension to the syntax of sketch is based on Link grammars. A
theory of syntax proposed by Davy Temperley and Daniel Slator in
\cite{Sleator91} which builds relations between pairs of words,
rather than constructing constituents in a tree-like hierarchy. They
are similar to dependency grammars developed by Lucien Tesni\`{e}re
in the 60's \cite{Tesniere59}. Link grammar is a form of analytic grammar designed for linguistics, which derives syntactic structures by  examining the
positional relationships between pairs of words. This can be seen in
the model that the Davy Temperley and Daniel Slator provided
for English in this system: Their grammar deals with most of the
linguistic phenomena in English. Informally, a sentence is correct
in this system if it is possible to link all words according to the
links needed by each word, defined in the lexicon. Link represents
syntactic relations. It is shown in \cite{Sleator91} that link
grammars have the expressive power of context-free grammars.


We call sign system to the extension of the Ehresmann sketch notion.
A formal definition for an identical notion appeared is presented by Goguen in
\cite{Gog??}, in our version it is a library defined by a
multi-graph more, just as sketch, a set of commutative multi-diagrams, a
set of limit cones and a set of colimit cocones. In this context the limit and the colimit for a multi-diagram must be seen as a relation defined on a fuzzy set theory. We consider a semiotic system as a pair defined by a
sign system and one of its models, and they can be seen as an institution in Goguen sense \cite{goguen83}.

Our goal was to develop a mathematically precise theory of semiotics based on Ehresmann sketch notion. This structure try to internalized the formalization made by the \emph{Vienna Circle} in their \emph{International Encyclopedia of Unified Science}, by breaking out the filed, which they called "\emph{Semiotic}", into three branches: \emph{Semantics} (relation between signs and the things they refer to) \emph{Syntactics} (Relation of signs to each other in formal structures) and \emph{Pragmatics} (Relation of signs to their impacts on those processes which use them).

Signs appear as members of sign systems. Must signs are complex objects constructed from others, lower level signs. In this sense they can be seen as structures defined using signs and sign systems capture the systematic structure of signs. Marking an entity with a sign can be seen as a way to named entities or assign properties to entities, such as two entities marked with the some signs are identical. We defined the model of a sign system a consistent process for marking entities belonging to a fixed universe, preserving labeled relations between signs.

Following the spirit used by Peirce on \emph{Semiotics} we identify entities from the universe of discourse with some of this signs. We do this
by marking some of the objects or morphisms of a topos with
signs used on library specification using a library model. If, in the topos, the object classifier have a monoidal logics structure, and its operators are marked with signs from a library, we can use this library to specify monoidal
graphic logics. And a relation on a semiotic system must be seen as a
configuration having by interpretation a multi-morphism with target
a object marked as having associated a monoidal logic structure.
This allows the extension of the concepts used in logics to the
graphic logics associated to a semiotic system. We can use graphic
relations to define queries on the semiotic. An answer for it is a
fibre on the source, of its interpretation, defined by all the
"points" transformed in the true for the semiotic associated
ML-algebra. In this context a "set" of points is consistent with a
graphic relation if every point is associated by the relation
interpretation to the true of the semiotic monoidal logic. Since
monoidal logics can be seen as fuzzy logics or multi-valued logics,
logics definable in this framework are in reality fuzzy graphic
logics. This extends the logic used for Ehresmann sketches. And
allows making fuzzy the notion of a relation evaluation, an
important issue for practical applications.

Day living activities generate information which can be stored in information systems spread by different databases.  A query to a information system can be seen as a view of the data stored in the system, and it is presented by a dataset. Many times this information is useful to produce new knowledge about the reality. Given the amount of data stored this transformation must be automatized and this is the goal of fields of AI, like Machine Learning, see \cite{Michell86}.

In fuzzy set theory a dataset can be expressed by a relation. The interpretation of a word in a logic semiotic is called a model for the dataset if the relation is the multi-diagram limit. If we see a dataset as a way of codifying data, we can seen its model as a way of represent the knowledge in the graphic language, associated to a fixed logic semiotic. This relation between data and knowledge, is only useful, if we define the notion of structure -consistent with a relation. Where  is a logic value quantifying the degree of similarity between interpretation of a word and the concept defined codified in the dataset. In this sense the fact of a dataset be -consistent with a diagram catches the idea of approximation.

If the data, presented in a dataset, is -consistent with a set of diagrams we call  semiotic defined by this set of diagrams a theory -consistent with the data. Naturally this can be extended to databases. The knowledge available about a database can be codified in a semiotic and the quality of this knowledge is given by the way its model describe good approximations to data, associated to tables what can be, generated in a database state. Since different human specialists or machine learning algorithms express the extracted knowledge using, many times, different languages: the problem of knowledge integration is the problem of semiotic integration. The objective of integration is then to construct one semiotic that exploits all the knowledge that is available and as good performance. We describe methodologies for merging several separate theories. However this processes some times also requires the integration of languages and the associated logics which is simplified following our approach.



\textbf{Overview of the paper:}

We began section \ref{monoidal logics} describing a partially-ordered monoidal structure
for the set of truth-values used on the definition of our graphic
logics. The language used in this logics is based on possible
circuit configurations using a libraries of components, structure
defined on section \ref{specifying libraries}. As a framework for the definition of models
for this libraries we used a class of relations defined between sets and evaluated in a multi-valued logic, which are described in
section \ref{multi-morphisms}. For that we need to define composition of relations compatible with circuit gluing. In this sense composition must be seen as a total operator in the class of relations, relaxing the diagram equality, evaluated in a multi-valued logic, allowing in section \ref{multidiagrams}, the presentation of a generalized version for the notion of commutative diagrams. This is explored  in section \ref{bayesian inference}, on the definition of a version for Bayesian inference on fuzzy logics. In
section \ref{modeling libraries} the language defined by a libraries is seen as a set of circuits closed to the plug-in operation, every word is a string of component labels or signs and define a relation
between a family of inputs requirements and a family of output
structures, both identified using families of signs. We present how
libraries are modeled on the class of relations on section \ref{modeling libraries}. The descriptive power of languages defined using libraries allow defining structure what are not definable using first order basic theory. This is presented in section \ref{descritive power} by showing what the category defined using library models is not accessible. Accessible categories are known to be specified using Ehresmann sketch. We toke advantage of its specification power by enriching the structure of a library
with a structure similar to a Ehresmann sketch, in section \ref{Sings Semiotics}, we called to this specification tool a sign system or a
specification system. This enrichment is made using multi-diagrams instead of diagrams specified respecting library constrains and where limits and colimits are interpret as multi-morphisms and used in section \ref{multidiagrams}, on the definition of diagram commutativity evaluation on a multi-valued logic.  A specification system where we fixed a model we called a semiotic system, with this and an example we finish section \ref{Sings Semiotics}. On section \ref{logics} we use
signs systems to specify fuzzy logics. They are semiotics with special structure, for that we impose interpretations for some of the
sign system signs allowing the interpretation or words as evaluations of relations in a monoidal logic.  When some signs
are interpreted as ML-algebras operators the library was called a logic
library and the associated language was called a logic language. We formalize this concepts and describe when a diagram
defines a relation and an equation. However, some problems in Mathematics require more expressive languages than the ones defined using libraries. We improve the expressive power of libraries Lagrangian syntactic operators. An example is describe on section \ref{synopt}  allowing the definition of Differencial semiotics.  On section \ref{Concept description} we present how to
evaluate relations in a semiotic, and use it to define what we mean by
the level of consistence of a relation. This notion is extended to
relations -consistent with words in a semiotic. We emphasize the idea what a diagram defining a relation can be seen as a query to the semiotic. In this context a
-answer is a structure where the query is
-consistent. This notions are used on section \ref{fuzzy computability} the definition of
bottom and upper presentation to a structure  in the a semiotic;
the bottom presentation is the lower structure in  codified in
the semiotic language, and the upper presentation is the short
structure containing  and codified in the fixed language. These
notion can be seen as two approximations to the concept, following the spirit of Pawlaks' of the standard version of rough set theory. They
define an interior and a closure operators for structures, allowing
the definition of a formal topology.  Which we use on the definition of a inference system for words evaluation on a semiotic system based on
properties of ML-algebras. What is made for descriptions can be made for relations evaluated in a multi-valued logic. In section \ref{fuzzy computability} a fuzzy relation is computable in a semiotic if it can be seen as a interpretation for a diagram defined in the associated language.  Section \ref{integration} is dedicated to the the integration of semiotics and models for concepts. The goal is construct one system that exploits all the knowledge that is available, allowing improve concept description by combining different description for the concept on the same concept possibility expressed using different languages. For specification reasons a string-based modal logic is present, on section \ref{reasoning}, where propositional variables are  interpreted as diagrams defined on a semiotic. This intents to be a meta-language to reasoning about models of concepts and knowledge.

\section{Monoidal logics}\label{monoidal logics}
Fuzziness is the rule than the exception in practical problems. A lot of research is being done on fuzzy sets and the associated fuzzy logics; we are specially interested in the possibility of extending the data specification paradigm using Ehresmann sketches to the fuzzy case. This paper is motivated to the introduction to -Categories given in \cite{Clementino04} and to -Sets given in \cite{valverde??}.

Ulrich H\"{o}hle introduced Monoidal Logic in 1995 in order to give a common framework to several first order non-classical logics, such as Linear logic, Intuitionistic logic and Lukasiewicz logic. A Monoidal Logic is a Full Lambek calculus with  exchange and weakening. We supposed what problems involving the specification of structures, using libraries of components, can be formulate in a framework defined by a set theory with a monoidal logic.

Recall that a algebra   is a partially-ordered monoid
if  is a monoid and    is a partial order
on   such that the operator  is monotone
increasing; i.e.


An algebra   is a resituated
partially-ordered monoid if  is a
partially-ordered monoid and moreover the following condition is
satisfied for all ;

This condition is called the \emph{law of residuation}, and  and
 are called the right and left residual of ,
respectively.

Any residuated partial-ordered monoid   such that
 forms a lattice and   has a unit
it is called a \emph{residuated lattice}. More precisely, an algebra
  is a residuated
lattice if
\begin{enumerate}
  \item  is a monoid such that  and  are the right and the left residual
of  , respectively, and
  \item  is a lattice.
\end{enumerate}
When  is commutative, we call it a \emph{commutative residuated
lattice}. In any commutative residuated lattice, 
hold for all . In such a case, we use the symbol 
and write  instead of   (and of
). Also the commutative residuated lattice is denoted by
.

\begin{defn}
A \emph{ML-algebra} is a bounded commutative residuated lattice where
, formally, is a system
 satisfying:
\begin{enumerate}
  \item  is a commutative monoid,
  \item  for every ,
  \item  is a bounded lattice,
  and
  \item the residuation property holds, 
\end{enumerate}
\end{defn}
In this paper we assume that ML-algebra  is non-trivial, i.e. .

A structure equivalente to a ML-algebra is presented in \cite{Clementino04} as a commutative and unital quantale where  is a complete lattice equipped with a symmetric and associative tensor product , with unit  and with right adjoint . Considered  as a thin category,  is said to be symmetric monoidal-closed.

Logics having as models refinements of ML-algebras are called
\emph{monoidal logics}. In many-valued logics, such as fuzzy logics,
 is the standard truth degree function for conjunction
connective. Since operator  is monotone and have right adjoint, we have:

\begin{prop}
On a ML-algebra one has
\begin{enumerate}
  \item if  then ,
  \item  iff , and
  \item .
\end{enumerate}
\end{prop}

And,

\begin{prop}\cite{klawonn??}\label{prop:implic}
In any ML-algebra the following equalities hold, for all  ,
\begin{enumerate}
  \item , and
  \item .
\end{enumerate}
\end{prop}

Every non-trivial Heyting algebra - with  and  the top element - is an example of a ML-algebra, in particular the two element chain  with the monoidal structure given by "and" and "true".

The complete real half-line , with the categorical structure induced by the relation  admits several interesting monoidal structures. If  it is a Heyting algebra. Another possible choice of  is +, note that in this case the right adjoint  is given by truncated minus: .

\begin{exam}[t-norm based fuzzy logic]
A t-norm is a function  used to define a ML-algebra structure on the real unit interval . We may define a monoidal logic using a t-norm by taken the unite interval as the set of truth values and where the residuum of  is defined as the operation . The other truth function considered important in fuzzy logic are \emph{weak conjunction}  and \emph{weak disjunction} . However in the following we interpret a fuzzy logic on a ML-algebra  where  is continuo t-norm and  is its residuum, the lattice structures are given by  and .
The following are importante examples of fuzzy logics interpreted in ML-algebras defined by specific continuous t-norms:
\begin{itemize}
  \item \textbf{{\L}ukasiewicz} logic defined using the t-norm  and its residuum 
  \item \textbf{G\"{o}del logic} defined using the t-norm  and its residuum 
  \item \textbf{Product logic} defined using the t-norm  and its residuum 
\end{itemize}
\end{exam}

Particularly important to this work are the basic logics, with have by instances ML-algebras with are divisible, i.e. such that

Examples of this type of logic are classic boolean logic and fuzzy logic like product, G\"{o}del and {\L}ukasiewicz. Note that must of the examples presented in the following are construct using product logics with the natural order in interval [0,1].

For the sequel we define


Let

be a finite family of ML-algebra. The product of this ML-algebras is the ML-algebra

such that
\begin{enumerate}
  \item  is the cartesian product of sets of truth values,
  \item ,
  \item ,
  \item ,
  \item  ,
  \item , and
  \item .
\end{enumerate}
This structure has associated two types of morphisms. The projections

and the upper interpretations

Note what upper interpretation is the right inverse to projection,

We will use this structure as a vehicle for integration of ML-logics.

\section{Multi-morphisms}\label{multi-morphisms}

A surprising result discovered in Category Theory, presented by M. Makkai in \cite{Makki89}, is that the arrow specification language is absolutely expressive, in the sense that any construction having a formal semantic meaning can be described in the arrow language as well. Moreover, if basic object of interest are described by arrows then normally it turned out that many derived objects of interest can be also derived by arrows in a quite natural way \cite{Diskin99}. To define the universe we are going to deal with it is necessary and sufficient to define what we mean by a morphisms between objects of the universe.

Our universe for semantic modeling must be "essentially the same" as  but able to represent soft structures specified thought monoidal logics. Let  be a set with a ML-algebra structure . We use as universe  defined using   having by entities -sets, i.e. sets  furnished with a -valued map

which is symmetric and transitive in the sense that both

hold for all . This is called a \emph{similarity} in . We will use Greek letters to denote  -sets, we write , to mean a -sets defined by set  and a similarity , and it is interpreted as a relation evaluated in  or a distribution in . The diagonal of this fuzzy relation is used on definition of fuzzy sets with support . For each -set  and  we define

and called it the \emph{extend} of . Then  is a representation for the fuzzy set  codified thought similarity . An element  is called \emph{global} in  if .

Note that every set  have a natural structure of -set defined by the equality  in , i.e. having by similarity
The crisp similarity , defined by the equality in , is denoted by .


Entities belonging to a -set  are characterized by a set of attributes  if . Given , on the description of  many of the values associated to some of this attributes are "non-observable" or unknown. In this sense we will differentiate between two types of attributes: \emph{observable attributes} and \emph{non-observable attributes}. Let   be a set of observable attributes in , where . We define an observable -set of  as the  -set  such that


\begin{defn}[Observable description]
If  is a -set with a set of observable attributes , we call to every  an \emph{observable description} for an entity in .
\end{defn}


We define a multi-morphism in  as a tracking morphism between -sets  and  as a map

(usually called a -map or a -matrix in \cite{Clementino04}).
 If  is a multi-morphism between  and  in  we write  to identify  as the source of  and  as the target of . And if  and  are observable descriptions for entities in  and  respectively we define
 
 The complete partial order on the ML-algebra  induces a complete partial order on the set of multi-morphisms. Given two multi-morphisms between -sets  and  in   we write  if , for every .
 Graphically a multi-morphism  is present in fig. \ref{multiarrow} by a multi-arrow
\begin{figure}[h]
 
\caption{Multi-arrow.}\label{multiarrow}
\end{figure}
having by sources  and  and by targets  and .

We classify multi-morphisms preserve entity evaluation in :
 \begin{defn}[Total multi-morphism]\label{total}
 A multi-morphism  is \emph{total} in  if 
 for every .
 \end{defn}

 \begin{defn}[Faithful multi-morphism]\label{total}
 A multi-morphism  is \emph{faithful} in  if 
 for every .
 \end{defn}

 Note what, for every -set  we can use the similarity diagonal to define a multi-morphism by selecting a set of sources  sets and a set of targets  sets, with disjoint indexes, i.e. such that . This multi-morphism is given by a map
 
 for every  and , which defines
 

 Composition of multi-morphisms  is defined as matrix multiplication, the composition of

as the multi-morphism

given by

Note what if  and  are total and faithful then  is total and faithful. This composition have by identity for a -set  the multi-morphism  defined by the equality in , since for  we have .

\begin{prop}\label{prop:comprestriction} In  let  be a multi-morphism such that . If in the ML-algebra  for every truth value , , then  And, when the logic have more than two truth values, i.e. if , we have

\end{prop}

The set of multi-morphisms defined between -sets  and  is denoted by . And, every map  in  defines a multi-morphism, with source  and target , given by

In this sense the hom-set , of morphism between  and  in , define a subset of . To keep notation simple in the sequel we will write  rather than  for the multi-morphism induced by a map. Then  defines a total multi-morphism from , having by similarity the equality, and it is a faithful multi-morphism to , having by similarity


The formula for multi-morphism composition became considerably easier if one of the multi-morphism is a set-map. For maps  and  and multi-morphisms  and  we have

The operator of multi-morphism composition can be extended to multi-morphisms which are not composable, in the usual sense. Let

then we define

given by

In particular if ,  and  then  is given by  This reflects the independence between entities in  and  and we define:

\begin{defn}[Independence]
Two multi-morphisms  and  are called independent if

\end{defn}

\begin{exam}(Keys in a relational database)\label{def:indexproduct}
The relational model for database management is a database model based on predicate logic and set theory. The fundamental assumption of the relational model is that data is represented as mathematical -ary relations, an -ary relation being a subset of the Cartesian product of  domains. In the usual mathematical model, reasoning about such data is done in two-valued logic or three-valued logic. Data are operated upon by means of a relational calculus or relational algebra.

The relational model of data permits the database designer to create a consistent, logical representation of information. Consistency is achieved by including declared constraints in the database design, which is usually referred to as the logical schema.


A weight table  in a database defined using attributes  is a map in a ML-algebra

in this sense a weight table is a -set .

Every weight table , may be describe as the multi-morphism , and can be decomposed using two weight tables


such that

In this case we call to  a set of \emph{keys}, between  and , and write

to denote the joint of  and  using the keys in .

Generically, if  are sets of keys between  and respectively  we write

to denote the joint product

or

When the family  of keys is defined by the same set  the joint product is called the  indexed product of  and denoted by

In this case  is called the -\emph{indexed product} of .
\end{exam}

Given the importance of multi-morphism composition in this work lets formalize that we mean by the multi-morphism composition:
\begin{defn}[Multi-morphism composition]\label{def:composition}
Given multi-morphisms  and  defined by -maps

where  for every  and ,  iff . Without selection of sources and targets sets for  and  we define

for every  and . However, if we select sets of sources  and , and sets of targets  and , such  and , we define

for every  and .
\end{defn}
\begin{figure}[h]

\caption{Multi-morphism composition.}\label{multimorphism composition}
\end{figure}

The transpose  of a multi-morphism  is defined by . It is easy to see that

is order preserving and

In this sense, if  is a multi-morphism having by set of sources  and by set of targets  then  is the set of sources for  and  its set of targets.
\begin{figure}[h]

\caption{Transpose.}\label{multimorphism:transpose}
\end{figure}

We classify multi-morphisms by its ability to preserve its domain or codomain truth values distribution.

\begin{defn}\label{def:isomorphism}
A multi-morphism  is an \emph{epimorphism} between  and  if

It is a \emph{monomorphism} between  and  when

Naturally, when the two conditions are valid  is called an \emph{isomorphism} between -objects  and .
\end{defn}

For each set-map  we have

i.e.  is left adjoint to , . If  is a multi-morphism and  and  the multi-morphism  is called \emph{orthogonal}.

In general given multi-morphisms
 and  we say that  is the \emph{left adjoint} to  for  and  if


The tensor product on  can be naturally transported to -sets. More precisely, for -sets  and , we denote by  the -sets defined using the Cartesian product  in  and furnished with

Then, for each -set , the functor

has a adjoint the hom functor  defined by   with the similarity given by

and, for every ,
 such that .

Being monoidal-closed  has a natural structure as -set given by


Given similarities   and
. If we sets  and  are distinct,  applying composition definition we have   given by  and it is a similarity relation defining the -object  . More generically we define:

\begin{defn}[Product of -sets]\label{ProdSimil}
Given -sets  and  we define the product of  as the -sets  given by
 such that

\end{defn}

By the transitivity imposed on the definition of similarity we have,   

\section{Bayesian inference in a basic logic}\label{bayesian inference}
The presented definition for multi-morphism composition  is compatible to the Bayes' theorem used on Bayesian inference when   logic is a basic logic.

\begin{prop}[Bayes Rule]
Let  be a divisible ML-algebra. Given a faithful and total multi-morphism  and observable descriptions  and  of entities in  and , respectively. The equations
\begin{enumerate}
  \item  and
  \item ,
\end{enumerate}
have solution, and they define -maps  and , given by  and .
\end{prop}

\begin{proof}
In a divisible ML-algebra  we have . Since  is faithful , then . Because  we have

And, we can use the same strategy to proof  .
\end{proof}

We will interpret the -map  as a classifier in , defined by relation , for an entity described by  using the basic monoidal logic .

Applying in the multi-morphism context the principles of Bayes inference: For faithful and total multi-morphisms  and , and -sets , , , we have
\begin{center}
\begin{tabular}{rcl}
   & = &  \\
   & = & \\
   & = & , \\
\end{tabular}
\end{center}
then

i.e.

since in a divisible ML-algebra  we have .

When  and  are independent we have

Naturally, if  we write  for . And in this case we interpret the classifier   as the combination of two classifiers  and , defining entities of  described by  and .

\begin{exam}[Binding]
Drugs are typically small organic molecules that achieve their desired
activity by binding to a target site on a receptor. The first step in
the discovery of a new drug is usually to identify and isolate the
receptor to which it should bind, followed by testing many small
molecules for their ability to bind to the target site. This leaves
researchers with the task of determining what separates the active
(binding) compounds from the inactive (non-binding) ones.  Such a
determination can then be used in the design of new compounds that not
only bind, but also have all the other properties required for a drug
(solubility, oral absorption, lack of side effects, appropriate duration
of action, toxicity, etc.).

The DuPont Pharmaceuticals provided a data set to KDD Cup 2001 consisting of 1909 compounds tested for their ability to bind to a target site on thrombin, a key receptor in blood clotting. Of these compounds, 42
were active (bind well) and the others were inactive. Each compound is
described by a single feature vector, of observable descriptions, comprised of a class value (A for
active, I for inactive) and 139,351 binary features, which describe
three-dimensional properties of the molecule. The definitions of the
individual bits were not included, they can be seen as not observable descriptions of a compound - we didn't know what each individual
bit means, only that they are generated in an internally consistent
manner for all 1909 compounds. Biological activity in general, and
receptor binding affinity in particular, correlate with various
structural and physical properties of small organic molecules. The task
proposed on KDD Cup 2001 by DuPont Pharmaceuticals  was to determine which of these three-dimensional properties are critical in this case and to learn to accurately predict the class value of a new compound.

Let  be the set of available compounds and suppose what the process of compound classification in laboratory evacuate proposition "Compound  is active" in the a fuzzy logic . A classification of each compound as active or inactive may be seen as a multi-morphism, in ,

where  and  define the truth value of proposition "Compound  is inactive" and "Compound  is active", respectively in . Each compound in  is described by a set of observable three-dimensional characteristics, measured in laboratory processes, and codified on the dataset. The similarity between compound must be codified by a -set . In the case of  be an observable three-dimensional structure of a compound in  it can be seen as a compound structure generalization. A description  describe a class of compounds  and we defined the truth value of proposition "Compounds satisfying description  are active" by

where the -set  codify the similarity between the stat of a compound be "active" or "inactive".
\end{exam}

In this example the best description  for an active compound in , can be seen as the description that maximizes . However from this notion emerges the need of have a way to codify observable descriptions and the existence of a framework for the selection of a best observable description. In the sequel we give a process to describe entities based on a graphic language. Words in this language are used to codifying relations between observable characteristics of entities in a multi-valued logic.


\section{Multi-diagrams}\label{multidiagrams}

A \emph{multi-diagram} in  is a multi-graph homomorphism  defined by mapping the multi-graph vertices to -sets and multi-arrows to multi-morphisms in .

Formally, if the multi-graph  is defined using nodes  and by a family of multi-arrows , where the multi-arrow  have by source  and by target  A multi-graph homomorphism  transform every node  in a -sets  and each multi-arrow   in a multi-morphism 

The usual definition of limit in  for a diagram can be extended to multi-diagrams in . For that we must see category  as the topos , where  define a two element chain with the monoidal structure given by the logic operator "and" and "true". Recall that the limit for a diagram or multi-diagram  is defined as a -set, denote by , which is a subobject of a cartesian product defined by the diagram vertices (see \cite{maclane71} or \cite{Borceux94}). We use these relation on the limit extension to multi-diagrams in . Since the cartesian product of -sets  was defined in \ref{ProdSimil} as the -set  given by

we define
\begin{defn}[Limit of a multi-diagram]\label{lim}
Let  be a multi-diagram where  have by vertices . Its limit  is a subobject of the multi-diagram vertices cartesian product:

given by
 
such that


\end{defn}
We see a limit as the result of applying the pattern used on the definition of each multi-morphism in the cartesian product of its vertices. This definition satisfies the usual universal property when the object classifier used  is the two-element chain, , with the monoidal structure given by "and" and "true". In other words this definition coincide with the classical one on the context of classical logic.

Note what we can see the limit for a multi-diagram   as a multi-morphism by selecting a set of source -sets and a set of targets. The canonical multi-morphism associated to a multi-diagram  have by source  the union of sources used to define the diagram multi-morphisms and have by target  the union of targets of  multi-arrows.

\begin{exam}
By definition the multi-diagram  given bellow
\begin{figure}[h]

\caption{Multi-diagram.}\label{multidiagram1}
\end{figure}
have by limit the -map

given by

\begin{figure}[h]

\caption{Multi-diagram limit functionality.}\label{multidiagram2}
\end{figure}
\end{exam}
The limit of a multi-diagram collapses the diagram into a multi-morphism by internalizing all the interconnections, thus delivering a multi-diagram as a whole.

In this sense the equalizer of a parallel pair of multi-morphisms  is defined by

where


And, the pullback of  and  is the multi-morphism

where


Given a discrete multi-diagram   its limit is denoted by  given by

i.e. when , .

The presented definition for limit simplifies the proof of:

\begin{prop}[Existence of limit in ]
Every multi-diagram  have limit, i.e. exists a multi-morphism  such that .
\end{prop}

But more interesting is the fact what we can show the opposite for basic logics:

\begin{prop}
If  is a divisible ML-algebra, then for every -map  and -map  such that  there is a multi-diagram  such that 
\end{prop}

We may proof this just by showing that multi-diagram

where 
have by limit .



We can see a multi-diagram as a way to express dependencies between classes of entities. When the limit of a diagram  is an -object  we want to see the diagram as way to codify  or a model for . But for this type of relationship be useful we need to have a language to codify the diagram structure. Define this languages is one of the goals for this work.

Let  be a multi-diagram with vertices , having by arrow interpretations faithful and total multi-morphisms and let  be an observable descriptions of an entity in . The limit in  of , where  is a divisible ML-algebra, defines the classifier  such that

i.e.

which can be seen as the combination of classifiers related through diagram  to predicted . This expression is simplified when in  we don't have multi-arrows with source , we have



We see the limit of diagram as a generalization for multi-morphism composition of a chain of composable multi-morphisms. This interpretation allows the definition of a semantic for circuits, when we assume a dependence between execution of circuit componentes. This point of view is also used to extend the classic notion of commutative diagram to fuzzy structures. For that we assume that a set of vertices  was selected in a diagram . The set  is  called the set of \emph{sources} for diagram .

\begin{defn}[Commutativity of multi-diagrams]
Let  be a multi-diagram where we select  as set of sources. If  is the cartesian product defined by all the vertices of  not in . The multi-diagram  is commutative for  if  for every . It is -commutative if  for every .
\end{defn}

In other words, a multi-diagram is commutative if the multi-morphism defined by its limit, with the selected sources, is total.

\begin{exam} Lets  defined by the product logic,  be the set of real number and  be a relation defined by the multi-morphism  given by Gaussian function   The diagram , presented in fig. \ref{equation1}, with sources  and ,
\begin{figure}[h]

\caption{Multi-diagram  codifying .}\label{equation1}
\end{figure}
where  is defined as equality in , is commutative for every , when we have by densities in  and , 
Because, using the definition presented to the multi-diagram limit, we have

then, since , we have , and

This proofs the commutativity for diagram  when its sources have the fixed distributions. The diagram , presented on fig. \ref{equation2},
\begin{figure}[h]

\caption{Multi-diagram  codifying .}\label{equation2}
\end{figure}
having by source the -set , defined by distribution   
is also commutate, when the -set  is defined by distribution
 where the parameter  is a truth value selected in . Since

and

However, if we change in diagram  the interpretation of  using the new distribution
 depending from a parameter . We have
 thus

Then, since we are working in a multiplicative logic, we have

which means that  is -commutative.
\end{exam}

Naturally, if a diagram is -commutative, it also is -commutative, when . When for every  the diagram isn't -commutative it is called a non-commutative diagram.

However, when we see a multi-diagram as a way of specify a architectural connectors, in the sense of \cite{Backhouse03}, we may want to interpret diagrams by collapsing the joint execution of its components, generalizing the notion of parallel composition.  We may do this through the symmetry between operators  and  on classic logic. We define:

\begin{defn}[Colimit of multi-diagrams]\label{colim}
Given a multi-diagram  in  with vertices  the colimit is defined by the multi-morphism

i.e.
 
given by

\end{defn}
This definition allows the formalization of knowledge integration. Colimits capture a generalized notion of parallel composition of components in which the designer makes explicit what interconnections are used between components. We can see this operation as a generalization of the notion of superimposition as defined in \cite{Bosch99}.

The colimit for a multi-diagram   can be used to define multi-morphism by selection of a set of source and a set of targets. The canonical multi-morphism associated to a multi-diagram , using colimit, have by source  the union of sources used to define the diagram multi-morphisms and have by target  the union of targets of  multi-morphisms.

\begin{exam}
By definition the multi-diagram , presented in fig. \ref{multidiagram1},
have by colimit the -map

given by

\end{exam}

In this sense the coequalizer of a parallel pair of multi-morphisms  is defined by the multi-morphism  given by

And the pushout of  and  is the multi-morphism
 given by


When  is a discrete diagram colimit coincide with the limit of , and in this case, we write


Naturally
\begin{prop}[Existence of coLimit in ]
Every multi-diagram  have colimit.
\end{prop}

Since  have limit and colimit of multi-diagrams we use it, in the following, as "Universe of Discurse" to construct model for structures specified by diagrams on the monoidal logic described in .

\begin{exam}[Genome]
The genomes of several organisms have now been completely sequenced, including
the human genome.  Interest within bioinformatics is therefore shifting somewhat away from sequencing, to learning about the genes encoded in the sequence.  Genes code for proteins, and these proteins tend to localize in various parts of cells and interact with one another, in order to perform crucial functions.  A data set presented to KDD Cup 2001 consists of
a variety of details about the various genes of one particular type of organism.
The two tasks proposed for the Data Analysis
Challenge were to predict the functions and localizations of the
proteins encoded by the genes.  A gene/protein can have more than one function,
and more than one localization.  The other information from
which function and localization can be predicted includes the class of the
gene/protein, the phenotype (observable characteristics) of individuals with a
mutation in the gene (and hence in the protein), and the other proteins with
which each protein is known to interact. The dependencies associated to the problem may be expressed by the multi-diagram  presented by fig. \ref{genomeattrib}.
\begin{figure}[h]

\caption{Dependencies between attributes.}\label{genomeattrib}
\end{figure}
The diagram limit defines a morphism which caracterize the involved entities:


This map can be seen as a data set were we can compute  describing the similarity between of pair on . Given a description  for a gene, the -map

reflect the truth value in  of the proposition "the class of genes characterized by   have function  and localization ".
\end{exam}
In this sense a multi-diagram can be aggregate in a relation via its limit. In the following sections we will describe the inverse problem: Define a multi-diagram having by limit an "approximation" to a given multi-morphism. By this we mean, the possibility of express graphically a fuzzy relations between attributes aggregate in a multi-morphism codifying a data set.

\section{Specifying libraries of components}\label{specifying libraries}

In Computer Sciences a formal grammar is an abstract structure that describes a formal language. Formal grammars are classified into two main categories: generative or analytic.

The generative grammars are the must well-known kind. It is a set of rules by which all possible strings in the language to be described can be generated by successively rewriting strings from a designated start symbol. An analytic grammar, in contrast, is a set of rules that assume an arbitrary string to be given as input, and which successively reduces or analyzes the input string yield a final boolean, "yes/no", result indicating whether or not the input string is a member of the language described by the grammar.

The languages used in this work are expressed through a type of generative grammar where words are configurations defined using componentes selected from a library. Each component have associated a set of requisites and a configuration is valid in the language if every requisite for the used componentes are satisfied. The use of this type of structure and the definition of its semantic was motivated on the Architectural Connectors domain which emerged as a powerful tool for supporting the description of the overall organization of systems in terms of components and there interactions \cite{Fiadeiro97} \cite{Bass98} \cite{Perry92}. According to \cite{Allen97}, an architectural connector can be defined by a set of roles and a glue specification. The roles of a connector type can be instantiated with specific components of the system under construction, which leads to an overall system structure consisting of components and connector instances establishing the interactions between the components.

Let  be the forgetful functor from the category of total ordered sets and its
homomorphisms to , the category of all sets. If we interpret a set  as a set of symbols or signs, objects on the comma category  can
be seen as words defined by strings over \emph{alphabet} . A set of signs  equipped with a partial order  is called a \emph{ontology}. Given signs  and  on an ontology  such that ,  is called a \emph{generalization} of  and   is called a \emph{particularization} of .

Given , we write , where  denotes the chain used on the indexation ,
and it is interpreted as an ordered sequence of symbols from
.

An ontology  is called a \emph{bipolarized ontology}, if we have
a nilpotent operator , such that
, where , and preserving the ontology structure, i.e. given signs  and   if  then .
Set  is called the set of  \emph{input symbols}
and  is called the set of  \emph{output symbols}.
If the symbol  is an input symbol,  is called
the dual of  and it is an output symbol. A bipolarized
ontology will be denoted by .

Using lifting we define for every word
, the words:
\begin{enumerate}
  \item  defined by all output symbols in  and
  \item  defined by all input symbols in .
\end{enumerate}
\begin{figure}[h]

\caption{Pullbacks used to select input and output signs from word .}\label{inoutsign}
\end{figure}
Given a word , we define   as the set of symbols used
in ,  . On an bipolarized ontology, let  and  be two words,
 is a substring from concatenation 
inductively described by the following algorithm:

\begin{alg}\label{op:StringGluing}
    (Input:  Output: )
    \begin{enumerate}

    \item let  and .
    \item let  be the first output symbol, in  having its dual   in
     or one of its generalizations :
            \begin{enumerate}
            \item  is generated removing the first occurrence of  from
    ;
            \item  is generated removing the first occurrence of  or a  generalization
    from 
            \end{enumerate}
    \item the step 2 is repeated while there are signs in  with dual or generalization in .
    \end{enumerate}
\end{alg}

In this sense we can see the word  as the result of the ordered elimination of output symbols on  and input symbols on  linked by duality.

From the definition of operator  we can proof:
\begin{prop}
For every pair of words  and  in a bipolarized ontology
 we have:
    \begin{enumerate}
    \item ;
    \item , if  (and ) not have the dual neither one of its generalizations of signs from  (and , respectively);
    \item .
    \end{enumerate}
\end{prop}

For our goal of finding a framework for library specification,
we supposed processes inputs and outputs requirements codified over
signs from a polarized ontology . Thus \emph{the
universe of libraries} having components requirements codified over
the polarized ontology  can be seen as the comma category

With this we mean that a library is a list for componentes specified using words defined over .

A \emph{library specification} is a map , where each node in the chain  is
called a \emph{component label} or a \emph{sign} in the library. Given a component label
 we can see  as the
specification of the component input requirements, , and its
output requirements . In this sense we see a library as an
oriented multi-graph having by multi-arrows a selection of
objects in  and having by nodes objects
from .

Let , if
,  is interpreted as a dependence between families of
nodes  and . And in this case we write
 or for short , defining
a multi-arrow in the  multi-graph  associated to the library
.

A homomorphism between libraries is a morphism in . Every morphism 
between libraries  and  have associated a multi-graph
homomorphism , defining a correspondence between signs and a correspondence between component labels in  and , preserving component requirements.

Naturally, we may define an order relation between libraries, we write  if for every  we have , i.e. every componente existent in  is in . In this case  is called a \emph{sublibrary} of  and the associated homomorphism  is called the \emph{library inclusion}.

We denote by  the \emph{free monoid} on  for operator . Formally, given a library  we define  as the -closure of , i.e. it is the least library in  such that:
\begin{enumerate}
  \item every word generated using signs of  is a label in ;
  \item the empty word defines a label for a component having empty requisites ;
  \item  is a sublibrary of ;
  \item if  such that  then
  
\end{enumerate}
Note what the empty word  is a label in . Since  is a sublibrary of  the requirements of a label in  can be interpreted as the requirements for the plugging of the components used on the label definition. In this sense a word in  can be seen as a circuit defined by the plugging of components from .

A library is a formal system where we may stratify in different levels of abstraction. The level of abstraction of a circuit is define by the number of steps of refinement need to obtain an equivalent circuit using only atomic components. In order to presente what we mean by a circuit refinement, note that in an ontology  the order defined for sign can be lifted to words. We write  if and only if  in . When for two words from ontology we have ,  is called a \emph{generalization} of  on the ontology.

Circuit refinement is based on the notion of \emph{semantic for a library} in , and it is a pair of equivalence relations
 , where  is defined for labels in  and  is
 defined for words in , such that:

In  a label  is called a \emph{decomposable componente} if there are words  and  such that:

  We called to a labels that can't be decomposable  an \emph{atomic componente}. In this sense if a label in  is atomic, it is a label in library .

A \emph{normal form} presentation for a label  is a sequence of atomic components

such that


Given a library  we call \emph{library of atomic components} of  to the library  such that,   if and only if  is atomic in .

We want to describe structures, like Architectural connectors, using a graphic language to describe the global organization of complex structures having by resource simplest ones. For that, each component is associated to a graphic presentation and the circuit specification result of the linkage between components satisfying a set of rules and a glue specification \cite{Allen97}. The essence of our approach is to provide a general framework that gives circuit explicit semantic status. To formalize this, for a library  we associated a  multi-graph , having by nodes symbols from , and by multi-arcs componentes such that each component  have by input  and output .
By  we denote the comma category

having by objects homomorphisms defined between a multi-graph and the multi-graph .

Trivially, for a library  with polarized ontology
, any diagram  can be
codified as a library 
having as component labels multi-arcs, from , each one must be associated to a word defined concatenating, in a single word, the multi-arc sources vertices labels and its targets vertices dual labels. Given a diagram  defined through:
\begin{enumerate}
  \item the source map  and
  \item the target map .
\end{enumerate}
Any library  have associated two words, defined using symbols from  ; This words are its
input requisites  and its output structures , where:
\begin{enumerate}
  \item  is the word define concatenating labels belonging to vertices without input multi-arc;
  \item  is a word defined by concatenation of the dual of labels belonging to vertices without output multi-arc.
\end{enumerate}

On the category , for every pair of diagrams
 and , we define the diagram  by gluing
together vertices with equal labels belonging to  and , taken others as distinct. The order used to gluing vertices must respect the order given by the chain of symbols used to define the words  and .

When   is restricted to pairs of diagrams  and 
such that , we used this operator as a "composition"
between relations specified using multi-graphs. With it we define a
category having by objects words from 
and by morphisms diagrams from . Given a
diagram , the fact of  and  is denoted by
. Given diagrams  and
 from , if  is a subobject of , denoted by writing , if here is an epimorphism in  from  to , or equivalently, if there is a decomposition .

A diagram  is \emph{decomposable} if there are two not null subobjects  and  such that . If a diagram isn't decomposable it is called \emph{atomic}. Let  be the class of atomic diagrams in . We can see atomic diagrams as building blocks for generate diagrams. A functor , where  have a semantic, is called a \emph{diagram refinement} if:
\begin{enumerate}
  \item , i.e. the refinement of a diagram is semantically equivalente to the refinement for its parts;
  \item , i.e. the refinement of a diagram is semantically equivalent to it self;
  \item  if and only if , i.e. atomic elements cannot be simplified.
\end{enumerate}
A refinement can be seen as a rewriting rule allowing unpacking subdiagram encapsulations. If a diagram is a fixed-point for the refinement function we say it is in \emph{normal form}. And since diagrams are finite structure, for every diagram  we can find, at least, a representation of  in normal form in a finite number of steps.

A diagram refinement  have the nice property of defining a partial order in , denoted by  and where  is true if , i.e. if  is a refinement of  through , and in this case we call to  a \emph{generalization} of .

\begin{exam}[Signatures as libraries]\label{ex:signature}
A signature can be expressed through a library of components, where each component represents a function symbol where its arity is codified on the component requirements. Formalizing this: Following \cite{Makki89} a signature
,  with type symbols from , consists of a finite
set  of function symbols (or operators)  where each
function  has an arity  defined by a chain of
input type symbols and one output type symbol. In this case we write
 and . We can sort the set  of symbols
function and taking these symbols as labels of components having its
requirements codified over the polarized alphabet  generated from
. The set  is defined adding a new dual symbol  for
each type symbol  in . The library associated to the signature
, will be denoted by .

A constant, of type , is a function symbols in a signature with
arity , i.e. without input and having  as output. It
is usual to take a countable infinite set of variables for each type
used on the signature. They are codified on a diagram using
inputs on components without associated links, and defining the
set of diagram sources.
\end{exam}

Bellow we present some examples of libraries associated to models generated by machine learning algoritmos in \cite{Michell86} and used on the following for the presentation of examples by describing fuzzy structures :
\begin{exam}[Binary Library ]\label{binarylibrary}
Binary libraries are define using a set of component labels  and a set of type signs . A binary library  presuppose the existence of a sign , interpretable as the set  of truth values in , and a
constant  in  interpreted as true. In  we must have  defined  components of type , one for each symbol , interpreted as a
similarity  on the interpretation for , and also components of type , where  and , interpreted as a constants selected on the interpretation for .

Since data sets or tables can be codified using this primitives, binary libraries are also called data set libraries
\end{exam}

\begin{exam}[Linear Library ]\label{linearlibrary}
Linear libraries , extend binary libraries, are defined
using similarities , components specified as
, for each symbol , interpretable as a total order
and constant components , where  and .

Linear library are associated to processes for the discretization of continuous domains in this sense they are also called grid libraries.
\end{exam}

\begin{exam}[Additive Library ]\label{addlibrary}
An additive libraries  is an extension to a linear libraries. They are defined
using equality and order components , ,
with a component specified as , interpretable as an
addition for all symbol , and constantes  where  and .
\end{exam}

\begin{exam}[Multiplicative Library ]\label{multlibary}
Multiplicative libraries  are extensions to additive libraries. They are
defined using components , ,,
also have a component , for each symbol ,
interpretable as a multiplication and constantes  for  and .
\end{exam}

\section{Modeling libraries and Graphic Languages}\label{modeling libraries}

Since libraries and multi-graphs have structural compatibility it is natural to assume the soundness for library semantic in  as equivalente to the library structural preservation.

A model for a library  in  is a multi-graph homomorphism  from the \emph{library parser graph}  to ,
 such that
\begin{enumerate}
  \item equivalente componentes are interpreted as the same multi-morphism, i.e.  if ;
  \item transform componente gluing in multi-morphism composition, i.e. 
  \item preserves componente requirements and truth value distribution, i.e. if  then 
  \item preserves sign ontological structure, i.e. if sign  is a generalization for sign  (i.e. if ) then ;
  \item words are mapped to as chains of -set products defined in \ref{ProdSimil}, i.e. if  then ;
  \item equivalente words are mapped to the same -set defined in \ref{def:isomorphism}, i.e. if  then .
\end{enumerate}
In other words a model transform multi-arcs into multi-morphisms preserving its structure and the semantic induced through relations  and . Property (3) imposes the preservation of truth values distribution by componente interpretation. The class of models for a library  is used, in the sequel, on definition of a category of models 

A model for  can be defined lifting interpretation of atomic components to circuits. For that we must note that, since a model preserves componente gluing, it can be defined by fixing interpretations for its atomic components. This is expressed by the following completion principle:

\begin{prop}[Universal property]
Let  be the sublibrary defined by atomic components in . Every multi-graph homomorphism  defines a unique model  for , such that  where  is the homomorphism defined by library inclusion.
\end{prop}

The proof to this result is made defining  if the circuit  have a normal form given by a sequence
, i.e. the 's are atomic and


For every component label  we called \emph{a realization}
for  through  in  or a \emph{Chu representation} of  to the a \emph{epi multi-morphism}  In this case, if  in , then  can be decomposed in 
as


Since library refinement preserves semantics, it is idempotent with regard to library models, given a model  and if  is a refinement in library , we have

This property can be used to characterize refinement:
\begin{prop}
A library homomorphism  having by fixed-points atomic components is a refinement in  if and only if for every model  we have
 for each natural .
\end{prop}

In this sense, for every component  which is a refinement for  by , i.e. , we have, for every library model , .



A library can be seen as an analytic grammar and we can use them to characterize languages. We define the \emph{graphic language} associated to a library  as the set of valid finite configurations using components indexed by
. A configuration of components  is \emph{valid or allowed} in  if

i.e. if  is a multi-graph homomorphism
 Formally, given a library , a graphic word  defined by  is a finite
configuration
 In this sense a word in the language is a multi-graph homomorphisms where the multi-arrows are library components. Since the homomorphism  have  as codomain it satisfy library constrains and it can be seen, and is called, the \emph{parsing} of word .

The \emph{graphic language defined by} library , is denoted by ,
and it is the comma category
 of allowed configurations in
. Given an allowed configuration  we call
  the \emph{configuration shape} and  to  a
\emph{word} or \emph{diagram} on the language defined by .

Given a configuration  and a model , we define
\begin{enumerate}
  \item  and
  \item ,
\end{enumerate}
where  and  denote -sets in  used to give meaning to multi-diagram input and output vertices.

We may collapse the structure of a word interpretation on a multi-morphism using limits.

\begin{defn}[Limits as multi-morphisms]\label{def:word interpret}
Given a model , the \emph{interpretation for a configuration}
 through  is   a multi-morphism

In this case we write  to denote the multi-morphism .
\end{defn}

Naturally we define

\begin{defn}[coLimits as multi-morphisms]\label{def:colim interpret}
Given a model  and a diagram
. Its colimit  can be seen as a multi-morphism

\end{defn}

By definition the model for a library preserves component decomposition, which can be extended to multi-diagrams when interpreted in a basic logic.
\begin{prop}
Let  be a basic logic. If multi-diagram  is a word on the language defined by library  and if it can be obtain by gluing diagrams  and , i.e. . An interpretation for word   is the result of composing the interpretation of  and  , i.e.

where  is the set of -sets that are sources for diagram  and targets for .
\end{prop}

Note that, if  and  then 
In a basic logic , this strategy can be extended to configurations colimit:

where .

\section{Library descriptive power}\label{descritive power}

Lets define now the structure for the category of models for a library, . It has by objects models 
and by morphisms natural transformations. In this context, taking  the graphic library structure, a natural transformation from model  to model  is a pair of epi multi-morphisms , such that

Naturally, by definition of epi multi-morphism,  

\begin{figure}[h]

\caption{Natural transformation .}\label{naturaltransf}
\end{figure}

 We use the composition for multi-morphism to define the composition of natural transformation. Given two natural transformations  and  we define

A model  have by identity in  the natural transformation  where both epi multi-morphisms are defined using the identity relation in .

The usual limits and colimits in  are computed based on that are made in the category of -sets and epi multi-morphism, -. Where the product (in usual sense) exists for two -sets  and , if
and it is defined by object  and the usual projections  and  in  and codified as a function in . Note that, for instance,  is a epi multi-morphism, since  define the multi-diagram, presented in fig. \ref{product},

\begin{figure}[h]

\caption{Multi-morphism .}\label{product}
\end{figure}

by composition we have




 The category - doesn't has an initial object. However, for -object  with a unique factorization , the multi-morphism   is the only epi multi-morphism, since . But there is only one epi multi-morphism to  given by the empty relation  since .

 Given a pair of epi multi-morphisms  from  to . There is a equalizer for  and , and it is given by  if and only if
 
Every pair of epi multi-morphisms  and  has a coequalizer and it is given by  such that

And, every family  of epi multi-morphisms have wild pushouts given by the product  and its projections . Since,  and . Because - have coequalizers and  wild pushouts it has connected colimits (see \cite{Borceux94}). By definition of natural transformation in  we have:

\begin{prop}
The category  has connected colimits in the usual sense.  \end{prop}

Since - and  have connected colimits they have directed colimits, i.e. exist colimit for diagrams like -  where  is a poset and if the vertices are models then its colimit is a model (see definition in \cite{Adamek94}).

Following \cite{Adamek94}, a category is accessible, provided that has directed colimits and has a set  of presentable objects such that every object is a direct colimit of objects from . And accessible categories can be characterized by:

\begin{prop}\cite{Adamek94}
Each small category with split idempotents is accessible
\end{prop}
Where, a category has split idempotents if for every morphism  with  there exist a factorization  where .

\begin{exam}
If  is a ML-algebra with at least three logic values . The multi-morphism 
is an epi multi-morphism and is idempotent but non-splitable, since for every factorization ,  by proposition \ref{prop:comprestriction}.
\end{exam}

The fact described by this example are the rule in - and . Since must of the idempotents aren't split idempotents the have:

\begin{prop}
Let  is a ML-algebra with more than two logic values. Then categories of models of libraries , aren't accessible.
\end{prop}

This means that, we can't use Ehreasman sketches to specify the category of models of a library \cite{Adamek94}, i.e. model categories can't be axiomatizable by basic theories in first-order logic.

\section{Sign systems and Semiotics}\label{Sings Semiotics}

Lets new find what is the basic structure need on a library to define useful fuzzy structures.

\begin{exam}[Signatures as libraries]
Let   be a signature. By example \ref{ex:signature} a
signature can be seen as a library. The set  of terms
defined by  is given, in \cite{Makki89}, as the least set satisfying:
\begin{enumerate}
  \item each variable  is in , and if it
has type  we write ;
  \item if    with  and 
is a list of terms from , with  for every , then  is in , and it has type , and we
write in this case .
\end{enumerate}

A term is closed if it doesn't contain variables.  We have
 if and only if we impose the
existence of:
\begin{enumerate}
  \item especial symbols  and  in , as described in example \ref{ex:signature} ;
  \item diagonal components   in  with
  and  , in , one for each
alphabet symbol  in  and each "class" of chain
equivalences . These components represent dependencies in the term
structure inherent to the use of the same variable more than once
on the term definition.
\end{enumerate}

If  is a term in  then it can be represented as a
multi-graph homomorphism  This
graph homomorphism is usually called the parsing graphs for . If
variables involved on the definition of a term are different then
the diagram  shape, , is a tree. On fig. \ref{terms} we present allowed configurations
defining terms 
\begin{figure}[h]

\caption{Multi-morphism  and
.}\label{terms}
\end{figure}

Let now   be a signature with a special collection of
functional symbols denoted by , one for each data type symbol a
used on the signature, where  In the arity of
, the symbol  must be seen as an identification for the set
of truth-values and should have associated two constant operators
 and , both with arity , used to identifying the true
and the false on the associated logic framework. By practical
reasons, given two terms of type ,  and , instead of
writing the term , we use the usual infix notation and
write  calling it an equation of type . In a signature
with this characteristics we called relational symbol to every
functional symbol  with arity of type  In
this sense the symbol  is relational, and this sort of
signature  is said to have a logic structure.

A formula , on a signature  with a logic structure, is a
term which has by representation a multi-graph
homomorphism having by output a relation, i.e. .
\end{exam}

The above example requires the existence in  of a special symbol "" and the existence of special component labels "="
and "", having predefined interpretations. This necessity can be seen frequently in other examples. For this type of labels we will define restrictions to the language  model structures by fixing interpretation to some signs and to some structures definable in the library.  We specify this type of structures using Ehresmann sketches defined by multi-graphs. We called  specification systems to this generalization.

\begin{defn}
A \emph{specification system} , using a library  ( or a
\emph{sign system}  using ) is a structure 
where
\begin{enumerate}
  \item  is a set of \textbf{finite diagrams}, interpreted as a total multi-morphism (see definition \ref{total}),
  \item  is a set of tuples  where  is a component and  is a \textbf{finite configurations}, such that  is interpreted as the multi-morphism defined by the limit of  having sign  as input vertices and sign  as output vertices (see definition \ref{def:word interpret}), and
  \item  is a set of tuples  where  is a component and  is a \textbf{finite configurations}, such that  is interpreted as the multi-morphism defined by the colimit of  from sign  to  (see definition \ref{def:colim interpret}).
\end{enumerate}
\end{defn}

In a specification system  , while the set  define structural proprieties to be preserved by its models, sets  and  impose restrictions to the structure for sign interpretations.

Extending the definition of model of a small Ehresmann sketches to interpretations of sign systems in  we have:
\begin{defn}[Model for a specification system]\label{Modelspec}

 A model  in , for library , is a model for the specification system
 if:
\begin{enumerate}
  \item for every pair ,   is a total multi-morphism;
  \item for every ,  is the multi-morphism defined by  from  to ;
  \item for every ,  is the multi-morphism defined by  from  to  .
\end{enumerate}

\end{defn}
The category defined by models for a specification system in
 and natural transformations between interpretations is denoted by . And we call \emph{the sketch structure of}  to . By definition, the category  is a full subcategory of . And, since the category of library models don't have split idempotents relations evaluated in :

\begin{prop}
Let  be a not trivial ML-algebra with more than two truth values. Given a specification system , the category  isn't an accessible category.
\end{prop}

Since the category  is a full subcategory of  each map can be seen as a relation and because we can codify commutative diagrams using total morphisms and limit cones using the limit structure, defined in \ref{lim}, trivially we have:
\begin{prop}
Every model for a Ehresmann Limit sketch in  ,
defined using finite diagrams, can be specified by a sign systems in
 for every not trivial ML-algebra .
\end{prop}

By this, every algebraic theory (see definition in \cite{Adamek94}) has a fuzzy version defined in .

Since in the following we will work over models of specification systems we define a semiotic as a sign system furnished with a model. This structure associates syntactic and semantic components to a language on the Goguen's  institution spirit \cite{goguen83}. Formally
\begin{defn}[Semiotic system]
A \emph{semiotic system} is a pair  defined by a sign system
 and a model .
\end{defn}
We will denoted by  the language associated to a sign
system  or associated to a semiotic system
.

In the context of information systems: we can see a system specification as a database structure and a semiotic defined with this structure as a database state. Each database update induces a change in the database state, implying a semiotic change since it reflects a change in the system attributes relations codified on the database tables. The information system is then a semiotic since it is usually defined as a database instance or state. Then the information stored in the information system can be queried in the associated semiotic.

Lets see an example of a semiotic and how we can query it using limits.
\begin{exam}\cite{Cohen01}
For the IDA'01 - Robot Data Challenge - series of vectors of binary data was generated by the perceptual system of a mobile robot. We suspect the generated time series contains several patterns (where a pattern must be see as a structure in the data that is observed, completely or partially, more than once) but we not know the pattern boundaries, the number of patterns, or the structure of patterns. We suspect that at least some patterns are similar, but perhaps no two are identical. The challenge is to find the patterns and elucidate their structure. A supervised approach to the problem might involve learning to recognize patterns given known examples of patterns.

The robot dataset is a time series of 22535 binary vectors of length 9, generated by a mobile robot as it executed 48 replications of a simple approach-and-push plan. In each trial, the robot visually located an object, oriented to it, approached it rapidly for a while, slowed down to make contact, and attempted to push the object. In one block of trials, the robot was unable to push the object, so it stalled and backed up. In another block the robot pushed until the object bumped into the wall, at which point the robot stalled and backed up. In a third block of trials the robot pushed the object unimpeded for a while. Two trials in 48 were anomalous.

Data from the robot's sensors were sampled at 10Hz and passed through a simple perceptual system that returned values for nine binary variables. These variables indicate the state of the robot and primitive perceptions of objects in its environment. They are: STOP, ROTATE-RIGHT, ROTATE-LEFT, MOVE-FORWARD, NEAR-OBJECT, PUSH, TOUCH, MOVE-BACKWARD, STALL. For example, the binary vector [0 1 0 1 1 0 1 0 0] describes a state in which the robot is rotating right while moving forward, near an object, touching it but not pushing it. Most of the 512 possible states are not semantically valid, however the robot's sensors are noisy and its perceptual system makes mistakes.

The dataset was segmented into episodes by hand. Each of 48 episodes  contains zero or more instances of seven episode types, labelled A, B1, B2, C1, C2, D and E. The entire corpus contains 356 instances of these episode types.

We may use domain knowledge to define a library  which can be used to characterize relations between attributes. The easier way to do this library is by directly specifying its parsing graphic . For that we fixed as signs \emph{Move}, \emph{Objects}, \emph{Path}, \emph{Node}, \emph{Episode}, \emph{Rotate}, \emph{Stalled} and \emph{Class} and by specifying components \emph{pushing}, \emph{direction}, , \emph{proximity}, \emph{source}, \emph{target}, \emph{start}, \emph{end}, \emph{direction},  and \emph{type} having its constrains defined in the graph bellow.
\begin{figure}[h]
    \begin{center}
    \includegraphics[width=150pt]{Drawing1.eps}
    \includegraphics[width=150pt]{Drawing3-2.eps}
    \end{center}
    \caption{Parsing Graph and example of a query.}\label{parsinggraph}\label{query1}
\end{figure}

This structure defines a semiotic when we assign to it a model by fixing an interpretation to each sign and for each component. Note that the defined semiotic is consistent with the available data if there is a word in the associated graphic language having as part of its the given dataset. However, for practical proposes, the lack of expressive power for the used language make this notion of consistence to restrictive. We relaxed this by defining what we mean by a semiotic -consistent with the data: a specification expressed in the graphic language, is -consistent with the data, if there is an  interpretation having a part that is "good approximation" to the given data.

A semiotic selected for the parsing graph from fig. \ref{parsinggraph} have the signs interpretation domains equipped with a similarity relation. The limit for the diagram in fig. \ref{query1}, where we identify the diagram sources    , the target  and as auxiliary signs
 , is a "good" approximation to the dataset. This limit can be seen as a -set  The discrepancies between  and the real data must then be seen as information that are not semantically valid for defined semiotic. This type of limit can be seen as a view of the data described by the semiotic. However the information in the generated limit isn't adequate to be used for solve the proposed problem of patterns detection, using machine learning algorithms. It doesn't codify the structure of time series generated by the robot perceptual system, since it doesn't use temporal relation between stats.

We used limits of admissible configuration to extract potential useful information from the universe modeled by the semiotic. The existence of patterns associate to robot stall on first three states of each episode should be detected in the limit for diagram  in fig. \ref{query2}, using the adequate machine learning tools.
\begin{figure}[h]
    \begin{center}
    \includegraphics[width=150pt]{Drawing3-3.eps}
    \includegraphics[width=170pt]{Drawing3-4.eps}
    \end{center}
    \caption{Queries  and .}\label{query2}\label{query3}
\end{figure}
However, to classify episodes it seems to be more relevant the last robot stats. Patterns of information associated to the last three states of a robot are present in the limit for diagram  from fig. \ref{query3}.

If we wish to use, for episode class prediction, the relational information available for three consecutive states we must change used library. We have a problem, the defined library structure doesn't have sufficient expressive power to describe this type of query. We may improve the library expressive power by adding to the specification system more a component: associating each automata stat to its episode. The query can be defined by diagram  in fig. \ref{query3}.

The update of libraries can be made also to restricted its interpretations. In fig. \ref{enrichsemiotic} we enriched the sign system by imposing a restriction to its interpretation by adding two equalizers. We used them to impose that in a path the source and the target must be different. This can be codify by restricting the equalizer between components \emph{source} and \emph{targets} to a initial relation. If we want also consider only episode having more than a stat the limit of diagram define by component \emph{start} and \emph{end} must be the initial relation. The specification bellow is enriched also with new components , ,  and  interpreted as the limit of presented queries , ,  and , respectively, add as signs interpreted as the source of this new components. This new signs add a new level to the sign ontology. They are more general than the signs defined initially.

\begin{figure}[h]
    \begin{center}
    \includegraphics[width=150pt]{Drawing2_2.eps}
    \end{center}
    \caption{Enriched sign system.}\label{enrichsemiotic}
\end{figure}

Note what the limit of diagram , presented in fig. \ref{query3}, describe available information about signs having by interpretation three consecutive stats, and the limit of  describes three consecutive stats of episodes such that the robot stall.

\begin{figure}[h]
    \begin{center}
    \includegraphics[width=150pt]{Drawing2_3.eps}
    \includegraphics[width=170pt]{Drawing2_4.eps}
    \end{center}
    \caption{ querying three consecutive stats and  querying three consecutive stats of episodes where the robot stall.}\label{query4}
\end{figure}
\end{exam}

In the example we used limits as a way to query the structure of a semiotic. On the following we will formalize some of the concepts presented in this example, particulary that we mean by an "approximation" to the given data.

\begin{exam}[Neural Networks \cite{Michell86}]
A neural network is a network of simple processing elements (neurons), which can exhibit complex global behavior, determined by the connections between the processing elements and element parameters.  Formally, a network is a function  defined as a composition of other functions , with can further be defined as a composition of other functions. This dependencies can be conveniently represented as a network structure, with arrows depicting the dependencies between variables. What has attracted the most interest in neural network is the possibility of be parameterized to learning a task. Given a specific task to solve, and a class of functions  defined using a network structure and a class os neurons, learning means using a set of observations, in order to find  with solves the task in a optimal sense.

In this sense we can see an artificial Neural Network as an admissible diagram defined in the semiotic codifying  every possible parametrization of each processing element. More precisely, the associated sign system describe the possible Neural Network structures and a model for it represents a set of parameterizations describing the behave of each processing element.

There are three major learning paradigms, each corresponding to a particular learning task \cite{Bishop96}. These are supervised learning, unsupervised learning and reinforcement learning and can be seen as different ways of search the space defined by models of admissible configurations in order to find the optimal solution, i.e. the model what best fits the data.

Given a diagram  on a Neural Network Semiotic the multi-morphism  describe the functional behavior for the network  when applied to its input space. In this sense, a network  learned a concept describe in a dataset if part of its limit  is a good approximation to the dataset.
\end{exam}

More examples can be taken from applications of generic programming, see for instance \cite{Fiadeiro97}.

\section{Logics}\label{logics}

We can see a semiotic as a formal way to specify a problem Universe of Discurse. We are particulary interest on the specification of universes where its entities can be characteristics by propositions on monoidal logics. For that we define:
\begin{defn}
A semiotic system , with

is a \emph{logic semiotic system}, if:
\begin{enumerate}
  \item exists a sign in  interpreted as the support  of a ML-algebra having as operators interpretations of
component labeled with the signs   and ,
  \item for every string  of sign in  there is a label  interpreted by  as the similarity  where  is the similarity on the -set , defined in \ref{ProdSimil},
  \item for every sign  in  and every natural number  there is a
  component in  labeled by  and interpreted by  as a
  diagonal 
  given by 
  \item for every sign  in  and every natural number,  there is a
  component in  labeled by  and interpreted by  as a
  codiagonal relation  given by 
  \item we suppose the existence of a disjoint decomposition for the set of signs , given by 
  and , where signs in  are called \emph{auxiliary}, and
  for every pair  there are
  components  and  in , called \emph{rename component}, and interpreted by  as the
  identity in , i.e. 
\end{enumerate}
\end{defn}
In a semiotic logic the signs  and  are used to relate together similar component inputs and similar components outputs. Rename components are used as a mechanism to codify the wires or links between components inputs and outputs on the diagram.

As usual, equations can be specified by commutative diagrams, in fig. \ref{identity} we
specify the property  (existence of identity )
using a commutative diagram. A model  for an additive
library  defines an additive operator with identity if
the diagram limit defines a total multi-morphism.
\begin{figure}[h]

\caption{Diagrams codifying .}\label{identity}
\end{figure}

This diagram presented in fig. \ref{identity} can be codified in string base notation by the chain of signs:

  
  .

By this we want to say that every diagram defining a word in a graphic language can be codified using string-based notation using rename components.

\begin{exam}
Let  be defined using the ML-algebra  , where     is a model for product logic and  the usual complete lattice defined in  by relation "less than". The -set defined in  by the similarity relation given by the table
\begin{center}
\small
\begin{tabular}{c|ccc}
   & 0 & 1 & 2 \\
  \hline
  0 & 1.0 & 0.5 & 0.0 \\
  1 & 0.5 & 1 & 0.5 \\
  2 & 0.0 & 0.5 & 1.0 \\
\end{tabular}
\end{center}
and the additive relational operator
\begin{center}
\small
\begin{tabular}{c|ccc}
   & 0 & 1 & 2 \\
  \hline
  0 & 1.0 & 0.5 & 0.0 \\
  1 & 0.5 & 1 & 0.5 \\
  2 & 0.0 & 0.5 & 1.0 \\
\end{tabular}
\begin{tabular}{c|ccc}
   & 0 & 1 & 2 \\
  \hline
  0 & 0.5 & 1.0 & 0.5 \\
  1 & 0.0 & 0.5 & 1.0 \\
  2 & 1.0 & 0.5 & 0.5 \\
\end{tabular}
\begin{tabular}{c|ccc}
   & 0 & 1 & 2 \\
  \hline
  0 & 0.0 & 0.5 & 1.0 \\
  1 & 1.0 & 0.0 & 0.5 \\
  2 & 0.5 & 1.0 & 0.0 \\
\end{tabular}
\end{center}
define a model for an additive library and the operator have by identity , since the diagram in fig. \ref{identity} have by limit
\begin{center}
\small
\begin{tabular}{c|c}
  A &  \\
  \hline
  0 & 1.0=[0] \\
  1 & 1.0=[1] \\
  2 & 1.0=[2] \\
\end{tabular}
.
\end{center}
\end{exam}

In a logic semiotic system  the language , is called a
\emph{logic language}. Logic semiotics have sufficient expressive power to distinguish between diagrams defining relations and diagrams defining entities. For that, we classify the words as:

\begin{defn}(Graphic relations)
A diagram , for a logic semiotic , is called a \emph{relation}
when its output  is interpreted by  as the set of truth values  on .
\end{defn}
\begin{defn}
A relation  is called an \emph{equation} if diagram  can be decomposed
as  where  is defined through realizations of diagonals,
, and , are diagrams satisfying  and '=' is a
diagram defined using the unique component, interpreted as a similarity relation, and
satisfying . In this case we simplify notation by denoting the diagram 
 as . Note what, diagram  codifies the dependencies between interpretations of signs used as inputs for diagram , relating together signs having similar values.
\end{defn}
In definition diagram  captures in a graphic logic the dependence relations defined on string-based logic by repeating bounded variables on a proposition.
\begin{figure}[h]

\caption{Sketch for a multi-morphism of type .}\label{identity2}
\end{figure}
The relation  is called \emph{true} by  if
the limit  is a total multi-morphism. In this sense a equation  is universal if the interpretation of  by  is
a total multi-morphism.

Given a logic semiotic system , let  be the
subcategory of  having by objects diagrams defining relations. Using the operation of diagram gluing we define for pairs of relations  the following operators between diagrams:
\begin{enumerate}
  \item  is the diagram ,
  \item  is the diagram ,
  \item  is the diagram 
  and
  \item  is the diagram ,
\end{enumerate}
where  is defined through realization of diagonals, linking
together inputs having the some meaning by . This allows the definition of new relations from pairs of simplest ones, and they correspond to the lifting part of  structure to diagrams in .

In the following we present some useful examples of logic semiotics important to caracterize the expressive power of language used by some machine learning algorithms:
\begin{exam}[Binary semiotic ]
A binary semiotic is a logic semiotic where sets  and  define a binary library  (presented in example \ref{binarylibrary}). We call to this sort of semiotic dataset semiotic or table semiotic since we can use instantiations of relations in  to codify datasets or tables.

The use of binary semiotic can be seen in machine learning algorithm used to generate decision rules like Apriori described in \cite{Michell86}.
\end{exam}

\begin{exam}[Linear semiotic ]
A linear semiotic  extends a binary semiotic. It is defined by a linear library  (presented in example \ref{linearlibrary}) where  is interpreted as a partial
order in the interpretation of sign , , for all symbol . This type of relation is codified in the model of a linear
semiotic  if it includes in the set  the diagrams
presented in fig. \ref{linear}, codifying propositions represented in string-based first-order logic by  and  and are "preserved" by its models.
\begin{figure}[h]

\caption{Diagrams codifying  and .}\label{linear}
\end{figure}

 Lets present an example on   having  the a structure of ML-algebra where   is a model for product logic and  the usual complete lattice defined in . For the -set defined with support  and the similarity relation
\begin{center}
\small
\begin{tabular}{c|ccccc}
   & 0 & 1 & 2 & 3 & 4 \\
  \hline
  0 & 1.0 & 0.5 & .25 & 0.0 & 0.0 \\
  1 & 0.5 & 1.0 & 0.5 & .25 & 0.0 \\
  2 & .25 & 0.5 & 1.0 & 0.5 & .25 \\
  3 & 0.0 & .25 & 0.5 & 1.0 & 0.5 \\
  4 & 0.0 & 0.0 & .25 & 0.5 & 1.0 \\
\end{tabular}
\end{center}
and the relational operator defined form  to  by:
\begin{center}
\small
\begin{tabular}{c|ccccc}
   & 0 & 1 & 2 & 3 & 4 \\
  \hline
  0 & 1.0 & 0.5 & .25 & 0.0 & 0.0 \\
  1 & 1.0 & 1.0 & 0.5 & .25 & 0.0 \\
  2 & 1.0 & 1.0 & 1.0 & 0.5 & .25 \\
  3 & 1.0 & 1.0 & 1.0 & 1.0 & 0.5 \\
  4 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 \\
\end{tabular}
\end{center}
When this relations are used for the sign interpretation in the three diagrams presented on fig. \ref{linear} they have by limit, respectively,

Which grants the commutativity of each diagram.

We call to this type of semiotics \textbf{grid semiotics}. They appear associated algorithms of machine learning used to generate decision rules  like the C4.5Rules of J.R. Quinlan see \cite{Michell86}.
\end{exam}

\begin{exam}[Additive semiotic ]
A \emph{additive semiotic}  is a linear semiotic
 such that it is a additive library  (presented in example \ref{addlibrary}) where
 is a monoid, for all symbol , and the interpretation for  is the monoid identity, with . Monoid proprieties can be codified in the semiotic structure if the model
transform each of the diagrams presented in fig. \ref{additive} in a total multi-morphism, for each sign  in the semiotic.
\begin{figure}[h]

\caption{Diagrams codifying  and .}\label{additive}
\end{figure}
\end{exam}

\begin{exam}[Multiplicative Semiotic ]
A \emph{multiplicative semiotic}  is an additive semiotic
 defined by a multiplicative library  (presented in example \ref{multlibary}) where
 is a commutative semigroup, for all symbol
.

In this semiotics we can codify rules defined using regression like the rules generated by machine learning algorithms like M5, of J.R. Quinlan, described in \cite{Quinlan93}.
\end{exam}

The definition of Domain of Discurse structure may impose restrictions to signs interpretations. In a binary semiotic we may impose rules for sign interpretation defined by Horn clauses of type:

The expressive power of linear semiotic allows the codification of rules like
 and on multiplicative semiotic sign interpretation can be restricted to semiotics defined by models satisfying regression rules like:
 This type of regression rules can be codified by
diagrams like the one represented on fig. \ref{regrassion}, where frames present the obvious
subdiagrams.
\begin{figure}[h]

\caption{Diagram codifying a regression rule.}\label{regrassion}
\end{figure}

Models generated by some of the Data Mining and Machine Learning tools can be codified in one of this sign systems. By this we mean that we can extract rules from models generated by learning algorithms, what reflect the available data structure. This type of structure can be used on the enrichment of the sign system, employed to specify the information system, allowing the definition of constrains to its models compatible with, the existent data or views for, the reality. By this we want to say that the best description we may have for an information system is the best generalization available for the stored data.

\section{Lagrangian syntactic operators}\label{synopt}
The expressive power of our specification languages can be increased using \emph{Lagrangian syntactic operators} or \emph{sign operators}. This operator are defined at the level of sign systems signs or/and components, and must be preserved via sign systems models, allowing the generation of new signs or components based on others signs or components.

An example of this operators, with evident applicability, are the differential operators. For that we define:

\begin{defn}[Differential semiotic]
A logic semiotic system  is called a \emph{differential semiotic
system} if it is a multiplicative semiotic where exists a sign  interpreted as the support for a ring
, and labels , in , for components   in  with output , and  a word over its input symbols such that:
\begin{enumerate}
 \item ,
 \item ,
 \item and the following for component label defined below, using  and  on infix notation, we must have:
  \begin{enumerate}
    \item if  then ,
    \item if  then , and
    \item if  then 
  \end{enumerate}
\end{enumerate}
\end{defn}

The component label operator  allows the characterization of
multi-morphisms impossible of represente on the associated logic
semiotic. For instance, in a differential semiotic system we may interpret a component  as a
multi-morphism satisfying the conservative law when the following
diagram is interpreted by the model as a total multi-morphism.
\begin{figure}[h]

\caption{Conservative law in a diferencial semiotic.}\label{conservative}
\end{figure}

Lets  see a naif application:
\begin{exam}[Modeling traffic]
In Lighthill-Whithams-Richards (LWR) model (presented in \cite{Lighthill55} and \cite{Richards56}), the traffic state is represented from a macroscopic point of view by the function  which represents the density of vehicles at position  and time . The dynamics of the traffic are represented by a conservation law expressed as

where  is the velocity of cars at . The main assumption of LWR model is that the drivers instantaneously adapt their speed in function of the surrounding density:
 the function  is then the "flow rate" representing the number of vehicles per time unit. We have then

The model is defined for a single unidirectional road. And it define a diferencial semiotic having the base library presented in fig. \ref{baselibary}
\begin{figure}[h]

\caption{The library for a sing unidirectional road model.}\label{baselibary}
\end{figure}
and where the associated sign system have by total diagrams
 where the least condition describes the road maximal density. A model for this sign system can be seen as an admissible car distribution on the road.

The above library doesn't has descriptive power to specify a road network. In fig. \ref{networklibrary}, we present an extension to the initial library. This new library allows the graphic modeling of a singles network
\begin{figure}[h]

\caption{A road network defined by the junction of two incoming roads and one outgoing road.}\label{network}
\end{figure}
defined by the junction of two incoming roads  and one outgoing road  with single direction. The semiotic of this problem is defined using the library from fig. \ref{networklibrary}
\begin{figure}[h]

\caption{The library for the presented road network.}\label{networklibrary}
\end{figure}
where we also add three "flow rate" components  one for each roads and initial condition constants . Network traffic model restrictions are described by the following conservative laws and flow restrictions in each roads:
\begin{enumerate}
  \item   and ,
  \item   and , and
  \item   and .
\end{enumerate}
In order to complete the model description, we define the mechanism that occurs at the junction. A first condition is the conservation of flows

One of the elementary problem we can study, and from which a model exists, is the Riemann problem. For a Riemann problem at a junction, we take as initial condition a constant density on the three roads:
\begin{enumerate}
  \item ,
  \item , and
  \item .
\end{enumerate}

Models for this sign system may be totally unrealistic. For instance, constants,  ,  and  can be associated to a possible semiotic, however this model although is clearly counterintuitive (except obviously in the presence of a red light at the entrance of the third road). A natural way to have a realistic model, for a particular road junction, is by adding rules describing the behavior of the drivers at the junction. We may enriched the sign system by adding extra information using models generated by machine learning algorithms for the data. This requires the integration of the defined semiotic with a semiotic associated to the language used in the description of machine learning model, problem described in the following.
\end{exam}



\section{Concept description}\label{Concept description}
 A \emph{concept description}, using attributes ,  on the logic semiotic system  is a -map

where the family  is a sequence of -sets. A concept description is defined in a semiotic  if the sequence  is defined using interpretation of signs in the language . For short, we write  when we  want to select a concept description in the semiotic . Note what,  defines a relation in a monoidal logic and it may not be the interpretable by  of a relation in . Intuitively, a concept description can be seen as the state of knowledge about a concept at a given moment. A database specified by the sign system  can codify the concept  if there is a model  and a diagram  such that

In this case  we say that the query  on the information system defined by semiotic  have by answer .

Given two concept descriptions  we write  if  for every  in . And we should note that every -set  defines a concept description by the extend map . In this sense we will see every -set as a concept description. And in  every -set with support  have associated a complete lattice, of concept descritivos, having by bottom  and by top . Particularly, the limit  is a concept description for every .

Some concept descriptions can be codified by a semantic, others doesn't. Given a pair of concept descriptions 
we define
 The biimplication  is a -\emph{similarity
relation} in  since:
\begin{enumerate}
  \item  (reflexivity)
  \item  (symmetry)
  \item 
  (transitivity) (by proposition \ref{prop:implic})
\end{enumerate}
When  is a two valued logic,  is clearly an equivalence relation
on .

\begin{defn}
Given a semiotic , and a concept . A diagram  of a -codification or a -description for  if

In this case we also say that  is an approximation to the concept . In this sense, relation  is an hypothesis describing the concept presented by , selected on language .
\end{defn}

This definition may be extended to concept descriptions having different support sets. Given concept descriptions
 such that exist a projection map , we write , we call  a -projection of  if


Given a concept description  and an hypothesis  in  the quality of  as a description for  is given by:

where
\begin{enumerate}
  \item  if :
  \item  if .
\end{enumerate}

We see a model as the fuzzy answers to a query on a semiotic for what we define:
\begin{defn}\label{def:lambda model}
A concept  is a -model for  in  if  or  and the diagram presented in fig. \ref{lambdamodel}
is a pullback such that  where  is a chain on lattice . In this case we write

\end{defn}
\begin{figure}[h]

\caption{Diagram evaluation.}\label{lambdamodel}
\end{figure}

If in the above pullback diagram we have

we write

or, when we want be more formal,

where . This notation is also used as  when .


When , we write ,  and  can be seen as
the answer to the query  on the information system given by . Similarly, if , we write , part of  is -consistente with interpretation for  in the semiotic .

Note what,  may not be seen as a formula on the language associated to the used semiotic. Because the language may not have sufficient expressive power to define . However if  i.e. if domain  can be specified using diagram  in the language we write 
Note what, in this case, for every description  we have

When  and  we have



From the proposed definition every diagram has a -model since:

\begin{prop}
In a logic semiotic  if  is a relation defined on language  then

\end{prop}

And from the presented notion of similarity, defined by biimplication, we have also as -models for  concepts -similar to its interpretation :

\begin{prop}
If  then .
\end{prop}

Naturally, we used the similarity definition to formalize what we mean by concepts consistent with relations.

\begin{defn}[Consistence]
Given a semiotic . A relation  from  is
\emph{consistent with}  if , and it
is -\emph{consistent with}  when . The relation  is consistent with part of  if
 and it is -\emph{consistent with a
part of}  when .
\end{defn}

The set of hypotheses consistent with  is denoted by
. For every , the set of hypotheses
-consistent with  is denoted by
-. And, for a chain of truth values in 

we have


\begin{exam}[Description consistent with a dataset]
Let  be a binary semiotic having by signs  and let  be a finite crisp concept description, i.e.  or  for every entity , and the number of entities  such that  is finite. Then there is a word  in the language, associated to the semiotic, consiste with  called the dataset used to describe .

Let be more specific, suppose that signs  have the some interpretation, let . And suppose that:
\begin{enumerate}
  \item 
  \item , and
  \item 
\end{enumerate}
 are the only tuples true in relation . This relation is consistent with the diagram
or  is the answer to the query defined by the diagram,
usually represented using table notation by:
\begin{figure}[h]
\begin{center}
\begin{tabular}{|c|c|c|c|}
  \hline
  A & B & C & D \\
  \hline
  1.0 & 0.5 & 0.2 & 0.2 \\
  1.0 & 1.0 & 0.2 & 0.2 \\
  1.0 & 1.0 & 0.0 & 0.2 \\
  \hline
\end{tabular}
\end{center}
\caption{Dataset.}\label{dataset}
\end{figure}
\end{exam}

\section{Fuzzy computability}\label{fuzzy computability}
When the interpretation of a diagram is consistent with a multi-morphism we consider the multi-morphism computable in the semiotic. Formally:
\begin{defn}[Computability]
Given a semiotic . A multi-morphism  is computable in  if there is a diagram  in :
\begin{enumerate}
  \item having  as input, ,  by output, and
  \item codify , i.e. .
\end{enumerate}
The multi-morphism  is -computable in  if ,  and  . These notions are very restrictive. We  relaxed them by calling to a diagram  a specification to compute part of  if
. When the domain of the computable part of  can be described by a diagram  we write 
\end{defn}

When , with  and , we call diagram  a \emph{program} or a \emph{specification}, in language , and its image by  is an implementation for .

In this sense every, and only, interpretation of words from  are computable in the semiotic . And, since words in  are generated from atomic componentes we have:
\begin{prop}
If  and  are computable multi-morphisms in the semiotic  the  is also computable in .
\end{prop}

And, since  is defined by finite diagrams, every finite diagram  in , having by arrows computable multi-morphisms, has by limit a computable multi-morphism.

The set of interpretations of words from  and computable multi-morphisms define a category, denoted by . In this category we write  if  is a computable multi-morphism and  and  are consistent, descriptions in the semiotic, satisfying . Note what, if  is consistent with  and  is the specification for  then the diagram  is consistent with .


Generically, if  and  then , i.e. . Formally:
\begin{prop}
 Let  be a description -consistent with  and  a computable multi-morphism specified by . Then  is a description  -consistent with diagram .
\end{prop}

In this sense a computable multi-morphism is known as a pre-processing tool in the data mining community. This allows the definition of -, the category of concept -consistentes and  computable multi-morphisms in the semiotic . Naturally, the limit and the colimit, in the usual sense, of finite diagrams in - define computable relations. We call this type of finite diagrams \emph{mining schemas}. And, given a mining schema , in semiotic , and a -consistent concept , the limit  defines a computable multi-morphism and  is a -consistent concept, interpreted as the output of schema  when applied to concept .

As usual we extend the notion of computability defining:
\begin{defn}[Turing computable]
A concept  is called \emph{Turing computable} in the semiotic  if there is a diagram , possible infinite but enumerable, such that 
\end{defn}

Computability is usually associated with state-based systems. The interpretation, in a semiotic, of a stat must be time dependent. Given the presented static definition of sign interpretation we only catch the dynamic beaver using an ontological hierarchy. We see the possible interpretation of a sign as a class of structures used as possible instantiation for it during the system execution. We achieved this using a syntactic operator linking together signs in a same class representing different views for the same entity. The class of related signs using the syntactic operator must have the same generalization sign in the sign ontology. The existence of this type of syntactic operator, in a semiotic, defines what we called a syntactic operator in section \ref{synopt}.

\begin{defn}[Temporal semiotics]
A \emph{temporal semiotic} is a semiotic , defined by a library , and having a syntactic operator  such that:
\begin{enumerate}
  \item preserves polarization of signs, , for every ;
  \item preserves concatenation,  for every pair of words ;
  \item preserves components functionality, if , it must exists a component 
\end{enumerate}
We imposed the existence of a component  for every component , and an ontological hierarch for signs time invariant relating time dependent sings, i.e. if  then it must exist a sign  such that ,  and . In this sense, every sequence of time dependent signs   have by generalization the same sign  on the ontology. We call  a \emph{time invariant sign}.
\end{defn}

In a temporal semiotic , if  is a component in the semiotic then its interpretation  is called a \emph{coalgebra}. A sign  is \emph{time-invariant} in the semiotic if .

A \emph{temporal logic semiotic} is a semiotic which is a logic semiotic and a temporal semiotic.

\begin{exam}[Fuzzy Turing machine]
A fuzzy Turing machine, with tape define using signs from , can be defined as a word in language associated to a temporal logic semiotic . And the interpretation for this word can be seen as an execution for it.  The machine structure can be codified in a sign system  with library  having by signs a set of machine stats, , and having by components the Turing machine instructions with labels in a set .

Each of the instructions in  has conditional form: it tells what to do, depending on whether the symbols distribution being scanned (the distribution of symbols in the scanned square). Namely, there are three classes of things that can be done:
\begin{enumerate}
  \item Print: Change signs distribution in place of whatever is in the scanned square;
  \item Move one square to the right;
  \item Move one square to the left;
\end{enumerate}
So depending on what instruction is being carried out and on what distribution is being scanned, the machine or its operator will perform one or another of these actions.

An instruction define a link between two stats and are codified as component labels with the following structure.
\begin{enumerate}
  \item  if in stat  the scanned distribution is changed using component  interpretation and then change to stat ;
  \item  if in stat  is reading a distribution  and   then move left and change to stat ;
  \item  if in stat  is reading a distribution  and   then move right and change to stat .
\end{enumerate} An instruction is executed if its condition is verified.

 In this sense a diagram in , defined using signs time invariant, is a \emph{Turing machine specification} with stats in  and tape signs from .  Every refinement of a Turing machine specification in , defined using only time variant sings, is called a \emph{flow chart} and codifies a Turing machine execution. However to garante the correct interpretation of an instruction we have, for each stat  in the sign system,  signs 
 where  is interpreted as the tape right half,  the reading square,  is interpreted as the tape left half. And, for each tape halfs we select the right half head , the right tail head , the left half head  and the left tail head . The sign system structure sketch is defined such that the relation between this signs and  are preserved if a model  satisfies:
 \begin{enumerate}
   \item ;
   \item ;
   \item ;
 \end{enumerate}
this interpretation for signs reflect the relations between I-projections (see example  \ref{def:indexproduct}) expressed in the following diagram:

\begin{figure}[h]

\caption{Sign interpretation structure.}\label{struct}
\end{figure}
And models of each instruction must satisfy the following conditions:
\begin{enumerate}
  \item For print instruction  we should have;

  \item For instructions of type "Move one square to the left"   we must have;

  \item For instructions of type "Move one square to the right"   we must have;

\end{enumerate}
So a model  assigning to each stat a \emph{fuzzy tape} with signs in , which can be seen as a infinite chain of indexed products ( see example \ref{def:indexproduct}):

where we fixed a componente  and such that each  is a concept description . And, the model  associates to each possible instruction (componente) a relation between fuzzy tapes  and , satisfying the described proprieties.

A fuzzy Turing machine begins its execution in a initial stat and it is a parallel device, at a given moment it can assume more than a stat. It finish its execution when it is stall in a stat or set of stats.
\end{exam}


\section{Consequence relation}\label{consequence relation}
In a semiotic , we define for every relation  in 
the set of its -answers as:

and it can be seen as the set of concepts -consistent with  on the domain defined by .
\begin{exam}
The examples presented in this section are defined using a grid semiotic, having expressive power to codify structures in a grid, using a three truth-values logic .

Let  be the diagram defining a relation between pais of entities in a grid, presented in fig. \ref{grid1}, where white points  mean , gray points mean  and darker points  mean .

\begin{figure}[h]
\begin{center}
\includegraphics[width=130pt]{ansD} \hspace{1cm}
\includegraphics[width=130pt]{ansD3}
\end{center}
\caption{Relation defined interpreting  and finite relations  where a point  marked with a X means  and a point marked with 0 means .}\label{grid1}
\end{figure}

  The interior of the box, presented on the figure and labeled with , can be seen as the set of points described by this diagrams. The relation  presented we can be seen as an example satisfying

which can be expressed writing

\end{exam}


Note what, given  the set  have at least an element, . Naturally:
\begin{thm}
If  is a relation in  and  then

\end{thm}
If , with , we express this relation by writing .

Let  be a relation defined is a semiotic, by
  
we mean that
  
We use this relation and the operator  to define two
modal operators,  and , as the
weak and the strong images, respectively, for description  along the relation :


Where  and  can be seen,
respectively, as the set of models -consistent with parts
of  and the set of models -consistent with  in the
language .
\begin{exam}
For grid semiotic with three truth-values we presente in fig. \ref{grid2} two possible diagrams  and .

\begin{figure}[h]
\begin{center}
\includegraphics[width=80pt]{ansD1a} \hspace{1cm}
\includegraphics[width=80pt]{ansD2a}
\end{center}
\caption{ and .}\label{grid2}
\end{figure}
\end{exam}

We have:

\begin{thm}
Given relations  and  in  and a description
:
\begin{enumerate}
  \item if , then ,
  \item if , then ,
  \item if  then  and
  \item if  then .
\end{enumerate}
\end{thm}

In the other direction we can extend  to a set of
relations  in :

the greatest description -consistent with a model from ,
and let

be a description -consistent with every model existent in
.

\begin{thm}
Let  and  be sets of relations in . Then
\begin{enumerate}
  \item if , ,
  \item ,
  and
  \item .
\end{enumerate}
And if 
\begin{enumerate}
  \item  and
  \item .
\end{enumerate}
\end{thm}

The -interior of concept  in the semiotic system 
is defined as the greatest part of  -consistent with a
model defined in the associated language and is given by:
 and can be seen as the greatest fragment of
 having a model -consistent in the language of the
semiotic. It is an \emph{interior operator} since;
\begin{enumerate}
  \item ,
  \item if  then  and
  \item .
\end{enumerate}
And given , . A concept description  is called
-\emph{open} in  if

For every set of relations ,  and
 are examples of -opens since:

\begin{prop}
In a semiotic for every set of relations  and :
\begin{enumerate}
  \item , and
  \item .
\end{enumerate}
\end{prop}

More precisely:

\begin{thm}
In a semiotic for every set of relations ,

\end{thm}

The closure of concept  in the semiotic system  is defined
as the shorter cover of  codified in the language   and
is given by:

and can be seen as the shortest cover containing  and codified in
the language associated to the semiotic. It is a \emph{closure
operator} since;
\begin{enumerate}
  \item ,
  \item if  then , and
  \item .
\end{enumerate}
And given , . Trivially we have:

\begin{prop}
Given a semiotic , for every ,

\end{prop}

A concept description  is called -\emph{close} in
 if
.
Descriptions  and  are also
-closed concepts. This can be extended to every
-open description:

\begin{prop}
Given a semiotic , for every ,  is
-closed iff it is -open.
\end{prop}

In this sense when a description is \emph{-open} or
\emph{-close} we called it a description -representable
on the semiotic. By this we mean that:

\begin{prop}
Let  be a description in the semiotic . Exists a relation
, such that , iff  is -open or
-close.
\end{prop}

Because of the symmetry between the left and the right side of
, from the above definitions we have
 and they also have
symmetric definitions, obtained by replacing each operator with its
symmetric:

 By symmetry it is immediate that  is an interior operator and  is a
closure operator.

Spelling out the definition of , for every set of
relations ,
 i.e. all -answers for  are
-codified using relation in . And we have:

\begin{thm}\label{soundness}
For every pair  and  of relations in the semiotic ,
\begin{enumerate}
  \item ,
  \item if , ,
  \item if , ,
  \item if  then , and
  \item if  then .
\end{enumerate}
\end{thm}

Spelling out operator  we have
  by
 we mean that  have an -answer and
every -codification for it are in . In this case we may
proof:

\begin{thm}
For every pair  and  of relations in the semiotic ,

when , .
\end{thm}

Lets write

and since  is a closure operator:
\begin{thm} In a semiotic , for every , we have:
    \begin{enumerate}
        \item if  then (Inclusion),
        \item if  then  (Monotony), and
        \item if  and , then  (Cut).
    \end{enumerate}
\end{thm}

By this we mean that  is a
\emph{inference system} \cite{abramsky92}  for every .

\begin{exam}
Given interpretations, presented in fig. \ref{grid4}, for three diagrams ,  and  in the grid semiotic with three valued logic:

\begin{figure}[h]
\begin{center}
\includegraphics[width=150pt]{anscon}
\end{center}
\caption{Interpretations for diagrams , ,  and .}\label{grid4}
\end{figure}

The diagram , with the represented interpretation, can be see as the result of applying inference to the set of diagrams , symbolically we write

\end{exam}

Since , if
, we have:



And we have using definition of -consistence:

\begin{thm} Let  and :
\begin{enumerate}
  \item ,
  \item ,
  \item , and
  \item .
\end{enumerate}
\end{thm}

Using this properties on the definition of -answer we have:

\begin{thm} On a semiotic we have:
\begin{enumerate}
  \item For every diagram :
   \begin{enumerate}
     \item ,
     \item  and
     \item ;
   \end{enumerate}

  \item For every concept description :
  \begin{enumerate}
    \item ,
    \item  and
    \item ;
  \end{enumerate}

  \item For every set of diagrams :
  \begin{enumerate}
    \item ,
    \item  and
    \item .
  \end{enumerate}

\end{enumerate}
\end{thm}

Which gives support to the definition of the introduction rules:


The fact of, if  then  and , can be expressed by the elimination rule:


Naturally, in a divisible logic, we have

since if  and  then . Because, if  and  then
. By this we mean what for
every , , and
for every , , and . Note that, in a divisible ML-algebra, . Then .

A diagram  codifies all the information existent in a concept , using the syntax associated to semiotic , if for every diagram  such that , . This diagrams are called \emph{total} an can be defined by 

In the category  having by objects diagrams codifying relations and where a diagram  is a morphism from relation  to relation  if , we consider composition as the operations of diagram gluing. The consequence operator  can be seen as a functor:

A diagram  is called a \emph{theory} in the -semiotic  if it is a fixed-point for consequence operator 

The semiotic model , can be interpreted as a functor 
in the category of concepts -consistentes and computable multi-morphisms. A functor in the opposite direction can be defined using  the operator of consistence

assigning to each -consistente description a total diagram with its codification on the semiotic.

Since  we have

and by definition of consequence relation


If  is a -theory in the semiotic,  is the model -consistent with this theory.

\section{Integration}\label{integration}
Our aim is to construct an integration semiotic base from several separated semiotics. This need can arise, for example, when knowledge bases are acquired independently from interactions with several domain experts. A similar problem can also arise whenever separated knowledge bases are generated by learning algorithms.  The objective of integration is then construct one system that exploits all the knowledge that is available and has a good performance, i.e. a good degree of consistence with the data.

We must differentiate between two types of integration: semiotics integration and integration of models in a semiotic. The semiotic integration goal is the definition of a semiotic integrating the sintaxe and semantic of a given family of semiotics. By the integration of models in a semiotic we mean the possibility of improve the description of concepts integrating models for it using diferente data or diferente views of the same data. The integration of models is defined by an integration schema describing the relations between different models in the same semiotic. In the semiotic integrating we integrate different logics in the same semiotic associated to different languages used by domain experts or associated to structure specification language. In both senses Knowledge integration, in conjunction with inference, can play an important rule in the process of knowledge acquisition.

We impose an important restriction to the semiotic integration: Given a family of semiotics  its integration is defined, if and only if, equal signs and components with the same label in different semiotics have the some interpretation, with only a possible exception, the interpretations of sign  associated to the semiotics logic and its operators may be different.

The integration of semiotics  is denoted by  and it is given by the sign system

 if, for each , the semiotic  is defined by the structure . Where  is the library defined by the union of libraries  associated to each semiotic. This library is given by
 having by signs the union of ontology  defined by the signs existent in each library, and having by component labels the union of labels existent in both libraries. Note that the integration of libraries must preserve component functionalities. In this sense, the union of libraries is only defined if the component existente in different libraries, with equal label, have the some functionalities. The graphic language associate to  is denoted by , and we have .

From the description for the language associated to  recall what: Given two graphs  and  we define  as the graph defined having by vertices the vertices of  and  and having by arrows the arrows of  and . If each library  have associated multi-graphs , we have 
Then, if we have models   for different libraries, the homomorphism   is a model for the sign system ,  constructed using the union of models , making for nodes  if  and , for some , and  for multi-arrows , and  for some . By this we mean that not logic signs and multi-arrows which not represent relations are interpreted as it where in its libraries. This definition only makes sense when equal signs and equal labels have equal interpretations in different libraries.

For the logic family of logic signs  associated to the family of logic semiotics  we define the sign  interpreted by  as the ML-algebra product . The interpretation of sign  is a ML-algebra and for every relation  existent in each semiotic  its interpretation by  is the relation

where  is the map such that  having different of  only the component of order . Formally,

\begin{prop}
If  are sign systems with models  then
 defined as above is a model for the sign system  
\end{prop}

Since, for models  of sign system , we have, by definition \ref{Modelspec}, for every :
\begin{enumerate}
  \item if , then  is a total multi-morphism;
  \item if , then  is the -set defined by ;
  \item if , then  is the -set defined by .
\end{enumerate}

Naturally, the resulting semiotic of an integration process have the syntax and the semantic generated by the syntax and semantic associated to the semiotics. The some principle can be seen for some syntactic operators. The integration of a family of semiotics, where at last one is a  differential semiotics, is a diferencial semiotic and the same happens for temporal semiotics. If  is a family where  is a subfamily of temporal semiotics, given by syntactic operator . Then the integration  is a temporal semiotic where the syntactic operator  is defined by making:
\begin{enumerate}
  \item  if  where , and
  \item  if .
\end{enumerate}

An integration schema is a diagram  defined on the category of interpretations and computable multi-morphisms, such that  for every vertices  in . Let  be a family of diagrams used on integration schema  definition. The concept description   defined by  is given by the colimit of 

where  is computed as defined in \ref{colim}, i.e.



\section{Reasoning about models of concepts}\label{reasoning}

The language -RL of -representable logic is a
formalism to speak of structures -representable on a
semiotic . It is basically a classic string-based modal logic
defined by a generative grammar where propositional variables are
interpreted as diagrams belonging to the language associated to the
sign system .

-RL is constructed from relations in , modal
operators limit, closure, interior and the lifting of the monoidal logic
connectives  , ,  and  to relations.

Every semiotic  defines a sematic for -RL(S) by the
truth-relation  given, for every formula
-RL(S) and every concept description  in
, as follows:
\begin{enumerate}
  \item  iff  is the diagram  and ,
 \item  iff ,
  \item  iff .
\end{enumerate}
And given formulas
 and  in -RL(S), if

we have:
\begin{enumerate}
  \item ,
  \item ,
  \item  and
  \item .
\end{enumerate}
Using the structural compatibility between multi-morphism composition
and diagram gluing we have:

\begin{prop}
Given multi-morphism  and  such that
 we have: 
\end{prop}

By the lifting of the ML-algebra structure to the set of concept
descriptions we have:
\begin{prop}
Given concept descriptions  and  in  such that
 and  we
have:
\begin{enumerate}
  \item ,
  \item ,
  \item 
  and
  \item .
\end{enumerate}
\end{prop}

Given a set of relations  from  and  a
relation in -RL we define:

Using theorem \ref{soundness} we have:
\begin{thm}[Soundness]
Given a set of relations  from  and  a
relation in -RL,
 for every
.
\end{thm}
Naturally, the completeness isn't valid, if , we may not prove using deduction .

\section{Conclusions and future work}\label{conclusions}

The use of semiotics seems to be the appropriate formalism for defining syntax and the meaning of graphic language. Particularly when this languages are based on a library of functional components interpreted as relations evaluated in a multi-valued logic. This approach makes simplifies the integration of knowledge expressed using different languages and allowing the ingerence of new knowledge.




\bibliographystyle{amsplain}
\bibliography{multibib}
\end{document}
