\documentclass[]{eptcs}
\providecommand{\event}{QAPL 2012}
\usepackage{proof, amsmath, amssymb, latexsym, enumerate}

\usepackage[all]{xy}
\usepackage{epsfig}
\usepackage{float}
\usepackage{graphicx}



\floatstyle{boxed}
\newfloat{boxedfig}{thp}{lop}
\floatname{boxedfig}{Figure}

\newcommand{\texcomment}[1]{}
\newcommand{\comment}[1]{\textbf{[#1]}}

\newcommand{\aset}[1]{\{{#1}\}}
\newcommand{\aseq}[1]{\langle#1\rangle}
\newcommand{\sembrack}[1]{[\hspace*{-1.2pt}[{#1}]\hspace*{-1.2pt}]}
\newcommand{\dom}{\mathop\textit{dom}\nolimits}
\newcommand{\ran}{\mathop\textit{ran}\nolimits}
\newcommand{\smallcolon}{\hspace*{-2pt}:\hspace*{-2pt}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}

\newenvironment{proof}{\noindent\rm{\bf Proof:}}{\hbox{}\vspace*{0.2\baselineskip}}

\newtheorem{claim}[theorem]{Claim}
\newtheorem{remark}[theorem]{Remark}


\newenvironment{reftheorem}[1]{
 \trivlist
  \item[\hskip \labelsep \bf{Theorem #1.}]
  \itshape\selectfont
  \ignorespaces}

\newenvironment{reftheoremtitle}[2]{\trivlist
  \item[\hskip\labelsep \bf{Theorem #1}\nut (#2).]\itshape\selectfont
  \ignorespaces}


\newenvironment{reflemma}[1]{
 \trivlist
  \item[\hskip \labelsep \bf{Lemma #1.}]
  \itshape\selectfont
  \ignorespaces}

\newcommand{\addappendix}[2]{#2}

\newcommand{\ttif}[3]{\texttt{if}\;{#1}\;\texttt{then}\;{#2}\;\texttt{else}\;{#3}}
\newcommand{\ttassign}[2]{{#1}\;\texttt{:=}\;{#2}}

\newcommand{\ttwhile}[2]{\texttt{while}\;{#1}\;\texttt{do}\;{#2}}

\newcommand{\ttskip}{\texttt{skip}}

\newcommand{\vect}[1]{\overrightarrow{{#1}}}



\begin{document}

\title{Quantitative Information Flow as Safety and Liveness
  Hyperproperties\thanks{This work was supported by MEXT KAKENHI
    23700026, 22300005, 23220001, and Global COE Program ``CERIES.''}}


\author{Hirotoshi Yasuoka
\institute{Tohoku University\\
Sendai, Japan}
\email{yasuoka@kb.ecei.tohoku.ac.jp}
\and
Tachio Terauchi
\institute{Nagoya University\\
Nagoya, Japan}
\email{\quad terauchi@is.nagoya-u.ac.jp}
}


\def\titlerunning{Quantitative Information Flow as Safety and Liveness
  Hyperproperties}
\def\authorrunning{H. Yasuoka \& T. Terauchi}
\maketitle

\begin{abstract}
  We employ Clarkson and Schneider's ``hyperproperties'' to classify
  various verification problems of quantitative information flow.  The
  results of this paper unify and extend the previous results on the
  hardness of checking and inferring quantitative information flow.
  In particular, we identify a subclass of liveness hyperproperties,
  which we call ``-observable hyperproperties'', that can be
  checked relative to a reachability oracle via self composition.
\end{abstract}

\section{Introduction}
\label{sec:introduction}

We consider programs containing high security inputs and low security
outputs.  Informally, the quantitative information flow problem
concerns the amount of information that an attacker can learn about
the high security input by executing the program and observing the low
security output.  The problem is motivated by applications in
information security.  We refer to the classic by
Denning~\cite{denning82} for an overview.

In essence, quantitative information flow measures {\em how} secure,
or insecure, a program (or a part of a program --e.g., a variable--)
is.  Thus, unlike
non-interference~\cite{DBLP:conf/sosp/Cohen77,goguen:sp1982}, that
only tells whether a program is completely secure or not completely
secure, a definition of quantitative information flow must be able to
distinguish two programs that are both interfering but have different
levels of security.

For example, consider the programs  and .  In both programs,  is a high security input and
 is a low security output.  Viewing  as a password,  is a
prototypical login program that checks if the guess  matches the
password.  By executing , an attacker only learns whether  is
equal to , whereas she would be able to learn the entire content of
 by executing .  Hence, a reasonable definition of
quantitative information flow should assign a higher quantity to 
than to , whereas non-interference would merely say that 
and  are both interfering, assuming that there are more than one
possible value of .

Researchers have attempted to formalize the definition of quantitative
information flow by appealing to information theory.  This has
resulted in definitions based on the Shannon
entropy~\cite{denning82,clarkjcs2007,malacaria:popl2007}, the min
entropy~\cite{smith09}, and the guessing
entropy~\cite{kopf07,DBLP:conf/sp/BackesKR09}.  All of these
definitions map a program (or a part of a program) onto a non-negative
real number, that is, they define a function  such that
given a program ,  is a non-negative real number.
(Concretely,  is  for the
Shannon-entropy-based definition with the distribution ,  for the min-entropy-based definition with the distribution
, and  for the guessing-entropy-based definition
with the distribution .)

In a previous
work~\cite{DBLP:conf/csfw/YasuokaT10,DBLP:conf/esorics/YasuokaT10}, we
have proved a number of hardness results on checking and inferring
quantitative information flow (QIF) according to these definitions.  A
key concept used to connect the hardness results to QIF verification
problems was the notion of -safety, which is an instance in a
collection of the class of program properties called {\em
  hyperproperties}~\cite{DBLP:journals/jcs/ClarksonS10}.  In this paper,
we make the connection explicit by providing a fine-grained
classification of QIF problems, utilizing the full range of
hyperproperties.  This has a number of benefits, summarized below.
\begin{itemize}
\item[1.)] A unified view on the hardness results of QIF problems.
\item[2.)] New insights into hyperproperties themselves.
\item[3.)] A straightforward derivation of some complexity theoretic results.
\end{itemize}
Regarding 1.), we focus on two types of QIF problems, an
upper-bounding problem that checks if QIF of a program is bounded
above by the given number, and a lower-bounding problem that checks if
QIF is bounded below by the given number.  Then, for each QIF
definitions {\it SE}, {\it GE}, {\it ME}, we classify whether or not
they are safety hyperproperty, -safety hyperproperty, liveness
hyperproperty, or -observable hyperproperty (and give a bound on
 for -safe/-observable).  Safety hyperproperty, -safety
hyperproperty, liveness hyperproperty, and observable hyperproperty
are classes of hyperproperties defined by Clarkson and
Schneider~\cite{DBLP:journals/jcs/ClarksonS10}.  In this paper, we
identify new classes of hyperproperties, -observable hyperproperty,
that is useful for classifying QIF problems.  -observable
hyperproperty is a subclass of observable hyperproperties, and
observable hyperproperty is a subclass of liveness
hyperproperties.\footnote{Technically, only non-empty observable
  hyperproperties are liveness hyperproperties.}  We focus on the case
the input distribution is uniform, that is, , as showing the
hardness for a specific case amounts to showing the hardness for the
general case.  Also, checking and inferring QIF under the
uniformly distributed inputs has received much
attention~\cite{DBLP:conf/ifip1-7/HeusserM09,DBLP:conf/sp/BackesKR09,DBLP:conf/csfw/KopfR10,clark05,malacaria:popl2007,clarkjcs2007},
and so, the hardness for the uniform case is itself of research
interest.\footnote{In fact, computing QIF under other input
  distributions can sometimes be reduced to this
  case~\cite{DBLP:conf/ccs/SamaratiV10}.  See also Section~\ref{sec:maxqif}.}

Regarding 2.), we show that the -observable subset of the
observable hyperproperties is amenable to verification via self
composition~\cite{barthe:csfw04,darvas:spc05,terauchi:sas05,naumann:esorics06,unno:plas2006},
much like -safety hyperproperties, and identify which QIF problems
belong to that family.  We also show that the hardest of the QIF
problems (but nevertheless one of the most popular) can only be
classified as a general liveness hyperproperty, suggesting that
liveness hyperproperty is a quite permissive class of hyperproperties.

Regarding 3.), we show that many complexity theoretic results for QIF
problems of loop-free boolean programs can be derived from their
hyperproperties
classifications~\cite{DBLP:conf/csfw/YasuokaT10,DBLP:conf/esorics/YasuokaT10}.
We also prove new complexity theoretic results, including the
(implicit state) complexity results for loop-ful boolean programs,
complementing the recently proved explicit state complexity
results~\cite{DBLP:conf/csfw/CernyCH11}.

Table~\ref{fig:hysummary} and Table~\ref{fig:comsummary} summarize the
hyperproperties classifications and computational complexities of
upper/lower-bounding problems.  We abbreviate lower-bounding problem,
upper-bounding problem, and boolean programs to LBP, UBP, and BP,
respectively.  The ``constant bound'' rows correspond to bounding
problems with a constant bound (whereas the plain bounding problems
take the bound as an input).
\begin{table}
\begin{center}
  \begin{tabular}{|c|c|c|c|}
    \hline
    &  &  & \\
    \hline
    LBP& Liveness & Liveness & Liveness\\
    \hline
    UBP& Liveness & Safety & Safety\\
    \hline
    LBP constant bound& Liveness & -observable & -observable\\
    \hline
    UBP constant bound& Liveness & -safety~\cite{DBLP:conf/esorics/YasuokaT10} & -safety~\cite{DBLP:conf/esorics/YasuokaT10}\\
    \hline
\end{tabular}
\end{center}
  \caption{A summary of hyperproperty classifications}
\label{fig:hysummary}
\end{table}
\begin{table}
\begin{center}
  \begin{tabular}{|c|c|c|c|}
    \hline
    &  &  & \\
    \hline
    LBP for BP& {\it PSPACE}-hard& {\it PSPACE}-complete& {\it PSPACE}-complete\\
    \hline
    UBP for BP& {\it PSPACE}-hard & {\it PSPACE}-complete& {\it PSPACE}-complete\\
    \hline
    LBP for loop-free BP& {\it PP}-hard & {\it PP}-hard & {\it PP}-hard\\
    \hline
    UBP for loop-free BP& {\it PP}-hard~\cite{DBLP:conf/esorics/YasuokaT10} & {\it PP}-hard~\cite{DBLP:conf/esorics/YasuokaT10} & {\it PP}-hard~\cite{DBLP:conf/esorics/YasuokaT10}\\
    \hline
    LBP for loop-free BP, constant bound& Unknown & {\it NP}-complete & {\it NP}-complete\\
    \hline
    UBP for loop-free BP, constant bound& Unknown & {\it coNP}-complete & {\it coNP}-complete\\
    \hline
\end{tabular}
\end{center}
\caption{A summary of computational complexities}
\label{fig:comsummary}
\end{table}

\addappendix{The proofs omitted from the main body of the paper appear
  in the Appendix.}{The proofs omitted from the paper appear in the
  extended report~\cite{longversion}.}

\section{Preliminaries}

\subsection{Quantitative Information Flow}

We introduce the information theoretic definitions of QIF that have
been proposed in literature.  First, we review the notion of the {\em
  Shannon entropy}~\cite{shannon48}, , which is
the average of the information content, and intuitively, denotes the
uncertainty of the random variable .  And, we review the notion of
the {\em conditional entropy}, , which denotes
the uncertainty of  after knowing .
\begin{definition}[Shannon Entropy and Conditional Entropy]
  Let  be a random variable with sample space  and 
  be a probability distribution associated with  (we write 
  explicitly for clarity).  The Shannon entropy of  is defined as


Let  and  be random variables with sample space  and ,
respectively, and  be a probability distribution associated with
 and .  Then, the conditional entropy of  given  is
defined as

where

(The logarithm is in base 2.)
\end{definition}


Let  be a program that takes a high security input , and gives
the low security output trace .  For simplicity, we restrict to
programs with just one variable of each kind, but it is trivial to
extend the formalism to multiple variables (e.g., by letting the
variables range over tuples or lists).  Also, for the purpose of the
paper, unobservable (i.e., high security) output traces are
irrelevant, and so we assume that the only program output is the low
security output trace.  Let  be a probability distribution over
the values of .  Then, the semantics of  can be defined by the
following probability equation.  (We restrict to deterministic
programs in this paper.)

Here,  denotes the infinite low security output trace of the
program  given a input , and  denotes the output trace
of  given  that is equivalent to .  In this paper, we adopt
the termination-insensitive security observation model, and let the
outputs  and  be equivalent iff  where  and  denotes the th
element of , and  is the special symbol denoting
termination.\footnote{Here, we adopt the trace based QIF formalization
  of~\cite{malacaria08}.}

In this paper, programs are represented by sets of traces, and traces
are represented by lists of stores of programs.  More formally,

Here,  denotes a store that maps variables to values.  Because
we restrict all programs to deterministic programs, every program 
satisfies the following condition: For any trace
, we have
 where
 and  denote the first elements of 
and , respectively.  Now, we are ready to define
Shannon-entropy-based quantitative information
flow.
\begin{definition}[Shannon-Entropy-based
  QIF~\cite{denning82,clarkjcs2007,malacaria:popl2007}]
\label{def:se}
Let  be a program with a high security input , and a low
security output trace .  Let  be a distribution over .
Then, the Shannon-entropy-based quantitative information flow is
defined

\end{definition}
Intuitively,  denotes the initial uncertainty and
 denotes the remaining uncertainty after
knowing the low security output trace.  (For space, the paper focuses
on the low-security-input free definitions of QIF.)  

As an example, consider the programs  and  from
Section~\ref{sec:introduction}.  For concreteness, assume that  is
the value  and  ranges over the space .
Let  be the uniform distribution over , that
is,  for all .  The results are
as follows.

Consequently, we have that ,
but .  That is,  is
more secure than  (according to the Shannon-entropy based
definition with uniformly distributed inputs), which agrees with our
intuition.

Next, we introduce the {\em min entropy}, which has recently been
suggested as an alternative measure for quantitative information
flow~\cite{smith09}.
\begin{definition}[Min Entropy]
Let  and  be random variables, and  be an associated probability
distribution.  Then, the min entropy of  is defined

and the conditional min entropy of  given  is defined

where

\end{definition}

Intuitively,  represents the highest probability
that an attacker guesses  in a single try.  We now define the
min-entropy-based definition of QIF.

\begin{definition}[Min-Entropy-based QIF~\cite{smith09}]
\label{def:me}
Let  be a program with a high security input , and a low
security output trace .  Let  be a distribution over .
Then, the min-entropy-based quantitative information flow is defined

\end{definition}

Computing the min-entropy based quantitative information flow for our
running example programs  and  from
Section~\ref{sec:introduction} with the uniform distribution, we
obtain,

Again, we have that  and , and so  is deemed less
secure than .

The third definition of quantitative information flow treated in this
paper is the one based on the guessing entropy~\cite{Massey94}, that
has also recently been proposed in
literature~\cite{kopf07,DBLP:conf/sp/BackesKR09}.
\begin{definition}[Guessing Entropy]
Let  and  be random variables, and  be an associated probability
distribution.  Then, the guessing entropy of  is defined

where  and
.

The conditional guessing entropy of  given  is defined

where  and .
\end{definition}

Intuitively,  represents the average number of
times required for the attacker to guess the value of .  We now
define the guessing-entropy-based quantitative information flow.

\begin{definition}[Guessing-Entropy-based
  QIF~\cite{kopf07,DBLP:conf/sp/BackesKR09}]
\label{def:ge}
Let  be a program with a high security input , and a low
security output trace .  Let  be a distribution over .
Then, the guessing-entropy-based quantitative information flow is
defined

\end{definition}

We test {\it GE} on the running example from
Section~\ref{sec:introduction} by calculating the quantities for the
programs  and  with the uniform distribution.  

Therefore, we again have that 
and , and so  is
considered less secure than , even with the guessing-entropy
based definition with the uniform distribution.

\subsection{Bounding Problems}
\label{subsec:bp}
We introduce the bounding problems of quantitative information flow
that we classify.  First, we define the QIF upper-bounding problems.
Upper-bounding problems are defined as follows: Given a program 
and a rational number , decide if the information flow of  is
less than or equal to .

Recall that  denotes the uniform distribution.

Next, we define lower-bounding problems.  Lower-bounding problems are
defined as follows: Given a program  and a rational number ,
decide if the information flow of  is greater than .


\subsection{Non Interference}

We recall the notion of non-interference, which, intuitively, says that
the program leaks no information.
\begin{definition}[Non-intereference~\cite{DBLP:conf/sosp/Cohen77,goguen:sp1982}]
  A program  is said to be non-interfering iff for any , .
\end{definition}

Non-interference is known to be a special case of bounding problems that
tests against .
\begin{theorem}[\cite{clark05,DBLP:conf/esorics/YasuokaT10}]
\label{thm:nonint}
1.)  is non-interfering iff .
2.)  is non-interfering iff .
3.)  is non-interfering iff .
\end{theorem}

\section{Liveness Hyperproperties}

Clarkson and Schneider have proposed the notion of
hyperproperties~\cite{DBLP:journals/jcs/ClarksonS10}.  
\begin{definition}[Hyperproperties~\cite{DBLP:journals/jcs/ClarksonS10}]
  We say that  is a hyperproperty if  where  is the set of
  all infinite traces, and  denote the powerset of
  .
\end{definition}
Note that hyperproperties are sets of trace sets.  As such, they are
more suitable for classifying information properties than the
classical trace properties which are sets of traces.  For example,
non-interference is not a trace property but a hyperproperty.

Clarkson and Schneider have identified a subclass of hyperproperties,
called liveness hyperproperties, as a generalization of liveness
properties.  Intuitively, a liveness hyperproperty is a property that
can not be refuted by a finite set of finite traces.  That is, if 
is a liveness hyperproperty, then for any finite set of finite traces
, there exists a set of traces that contains  and satisfies .
Formally, let  be the set of finite sets of finite traces,
and  be the set of sets of infinite traces (i.e.,
hyperproperties), that is,

(Here,  denotes the finite subsets of ,
 denotes the set of finite traces.)  Let 
be the relation over  such that

where  is the sequential composition of  and .
Then,
\begin{definition}[Liveness
  Hyperproperties~\cite{DBLP:journals/jcs/ClarksonS10}]
  We say that a hyperproperty  is a liveness hyperproperty if for
  any set of traces , there exists a set of traces
   such that  and .
\end{definition}

Now, we state the first main result of the paper: the lower-bounding
problems are liveness hyperproperties.\footnote{We implicitly extend
  the notion of hyperproperties to classify hyperproperties that take
  programs and rational numbers.
  See~\cite{DBLP:conf/esorics/YasuokaT10}.}  We note that, because QIF
is restricted to that of deterministic programs in this paper, the
results on bounding problems are for hyperproperties of deterministic
systems.\footnote{This is done simply by restricting {\it Obs} and
  {\it Prop} to those of deterministic systems.  See
  \cite{DBLP:journals/jcs/ClarksonS10} for detail.}
\begin{theorem}
\label{thm:Llp}
, , and  are liveness hyperproperties.
\end{theorem}
The proof follows from the fact that, for any program , there
exists a program  containing all the observations of  and has
an arbitrary large information flow.\footnote{Here, we assume that the
  input domains are not bounded.  Therefore, we can construct a
  program that leaks more high-security inputs by enlarging the input
  domain.  Hyperproperty classifications of bounding problems with
  bounded domains appear in Section~\ref{sec:bounddomain}.}

We show that the upper-bounding problem for Shannon-entropy based
quantitative information flow is also a liveness hyperproperty.
\begin{theorem}
\label{thm:USElp}
 is a liveness hyperproperty.
\end{theorem}
The theorem follows from the fact that we can lower the amount of the
information flow by adding traces that have the same output trace.
Therefore, for any program , there exists  having more
observation than  such that .

\subsection{Observable Hyperproperties}
Clarkson and Schneider~\cite{DBLP:journals/jcs/ClarksonS10} have
identified a class of hyperproperties, called {\em observable
  hyperproperties}, to generalize the notion of observable
properties~\cite{DBLP:journals/apal/Abramsky91} to sets of
traces.\footnote{Roughly, an observable property is a set of traces
  having a finite evidence prefix such that any trace having the
  prefix is also in the set.}
\begin{definition}[Observable
  Hyperproperties~\cite{DBLP:journals/jcs/ClarksonS10}]
  We say that  is a observable hyperproperty if for any set of
  traces , there exists a set of traces  such
  that , and for any set of traces , .
\end{definition}
We call  in the above definition an {\em evidence}.

Intuitively, observable hyperproperty is a property that can be verified
by observing a finite set of finite traces.  We prove a relationship
between observable hyperproperties and liveness hyperproperties.
\begin{theorem}
\label{thm:nonempty}
  Every non-empty observable hyperproperty is a liveness
  hyperproperty.
\end{theorem}
\begin{proof}
  Let  be a non-empty observable hyperproperty.  It must be the
  case that there exists a set of traces .  Then, there exists
   such that  and .  For any set of traces ,
  there exists  such that .  Then, we have
  , because .  Therefore,  is a
  liveness hyperproperty.
\end{proof}\\
We note that the empty set is not a liveness hyperproperty but an
observable hyperproperty.

We show that lower-bounding problems for min-entropy and
guessing-entropy are observable hyperproperties.
\begin{theorem}
\label{thm:LMEsl}
   is an observable hyperproperty.
\end{theorem}
\begin{theorem}
\label{thm:LGEsl}
   is an observable hyperproperty.
\end{theorem}
Theorem~\ref{thm:LMEsl} follows from the fact that, if , then  contains an evidence of
.  This follows from the fact that when a
program  contains at least as much observation as ,  (cf. Lemma~\ref{lem:melog}).
Theorem~\ref{thm:LGEsl} is proven in a similar manner.

We show that neither of the bounding problems for Shannon-entropy are
observable hyperproperties.
\begin{theorem}
\label{thm:ULSEnsl}
  Neither  nor  is an
  observable hyperproperty.
\end{theorem}
We give the intuition of the proof for .
Suppose .   does not provide an evidence of
, because for any potential evidence, we can
raise the amount of the information flow by adding traces that have
disjoint output traces.  The result for  is
shown in a similar manner.

It is interesting to note that the bounding problems of {\it SE} can
only be classified as general liveness hyperproperties (cf.
Theorem~\ref{thm:Llp} and \ref{thm:USElp}) even though {\it SE} is
often the preferred definition of QIF in
practice~\cite{denning82,clarkjcs2007,malacaria:popl2007}.  This
suggests that approximation techniques may be necessary for checking
and inferring Shannon-entropy-based QIF.

\subsection{K-Observable Hyperproperties}

We define -observable hyperproperty that refines the notion of
observable hyperproperties.  Informally, a -observable
hyperproperty is a hyperproperty that can be verified by observing 
finite traces.
\begin{definition}[K-Observable Hyperproperties]
  We say that a hyperproperty  is a -observable hyperproperty if
  for any set of traces , there exists  such
  that , , and for any set of traces , .
\end{definition}
Clearly, any -observable hyperproperty is an observable
hyperproperty.

We note that -observable hyperproperties can be reduced to
-observable hyperproperties by a simple program transformation
called {\em self composition}~\cite{barthe:csfw04,darvas:spc05}.
\begin{definition}[Parallel Self
  Composition~\cite{DBLP:journals/jcs/ClarksonS10}]
Parallel self composition of  is defined as follows.

where  denotes the th element of .
\end{definition}
Then, a -product parallel self composition (simply self composition
henceforth) is defined as .
\begin{theorem}
Every -observable hyperproperty can be reduced to a -observable
hyperproperty via a -product self composition.
\end{theorem}
As an example, consider the following hyperproperty.  The
hyperproperty is the set of programs that return  and  for some
inputs.  Intuitively, the hyperproperty expresses two good things
happen (programs return  and ) for programs.

This is a -observable hyperproperty as any program containing two
traces, one having  as the output and the other having  as the
output, satisfies it.

We can check the above property by self composition.  (Here, 
denotes a parallel composition.)

Clearly,  satisfies the property iff the assertion failure is
reachable in the above program, that is, iff the predicate  holds for some inputs .  (Note that, for convenience, we
take an assertion failure to be a ``good thing''.)

We show that neither the lower-bounding problem for min-entropy nor
the lower-bounding problem for guessing-entropy is a -observable
hyperproperty for any .
\begin{theorem}
\label{thm:LMELGEnkl}
  Neither  nor  is a
  -observable property for any .
\end{theorem}

However, if we let  be a constant, then we obtain different
results.  First, we show that the lower-bounding problem for
min-entropy-based quantitative information flow under a constant bound
, is a -observable hyperproperty.
\begin{theorem}
\label{thm:lmel}
Let  be a constant.  Then,  is a -observable hyperproperty.
\end{theorem}
The theorem follows from Lemma~\ref{lem:melog} below which states that
min-entropy based quantitative information flow under the uniform
distribution coincides with the logarithm of the number of output
traces.  That is,  iff there is an
evidence in  containing  disjoint outputs.
\begin{lemma}[\cite{smith09}]
\label{lem:melog}

\end{lemma}

Next, we show that the lower-bounding problem for
guessing-entropy-based quantitative information flow under a constant
bound  is a -observable hyperproperty.
\begin{theorem}
\label{thm:lgel}
  Let  be a constant.  Then,  is a -observable hyperproperty.
\end{theorem}
The proof of the theorem is similar to that of Theorem~\ref{thm:lmel},
in that the size of the evidence set can be computed from the bound
.


\subsection{Computational Complexities}
\label{sec:complower}

We prove computational complexities of  and
 by utilizing their hyperproperty
classifications.  Following previous
work~\cite{DBLP:conf/csfw/YasuokaT10,DBLP:conf/esorics/YasuokaT10,DBLP:conf/csfw/CernyCH11},
we focus on boolean programs.

First, we introduce the syntax of boolean programs.  \addappendix{The
  semantics of boolean programs is standard and is deferred to
  Appendix (Figure~\ref{fig:semantics}).}{The semantics of boolean
  programs is standard.}  We call boolean programs without {\sf while}
statements {\em loop-free} boolean programs.
\begin{figure}[h]

\caption{The syntax of boolean programs}
\label{fig:syntax}
\end{figure}

In this paper, we are interested in the computational complexity with
respect to the syntactic size of the input program (i.e., ``implicit
state complexity'', as opposed to \cite{DBLP:conf/csfw/CernyCH11}
which studies complexity over programs represented as explicit
states).

We show that the lower-bounding problems for min-entropy and
guessing-entropy are -hard.
\begin{theorem}
\label{thm:lmelgepp}
 and  for loop-free
boolean programs are {\it PP}-hard.
\end{theorem}
The theorem is proven by a reduction from , which is
a -hard problem.   is the set of decision problems
solvable by a polynomial-time nondeterministic Turing machine which
accepts the input iff more than half of the computation paths accept.
{\text{MAJSAT}} is the problem of deciding, given a boolean formula
 over variables , if there are more than
 satisfying assignments to .

Next, we show that if  be a constant, the upper-bounding problems
for min-entropy and guessing-entropy become {\it NP}-complete.
\begin{theorem}
\label{thm:lmelgenp}
  Let  be a constant.  Then,  and
   are {\it NP}-complete for loop-free boolean
  programs.
\end{theorem} 
{\it NP}-hardness is proven by a reduction from , which
is a -complete problem.  The proof that  and  for a constant  are in {\it NP}
follows from the fact that  and
 are -observable hyperproperties for some
.  We give the proof intuition for .  Recall
that -observable hyperproperties can be reduced to -observable
hyperproperties via self composition.  Consequently, it is possible to
decide if the information flow of a given program  is greater than
 by checking if the predicate of the {\sf assert} statement is
violated for some inputs in the following program.

where .  Let  be the weakest
precondition of  with
respect to the post condition
.  Then,
 iff  is satisfiable.  Because a weakest
precondition of a loop-free boolean program is a polynomial size
boolean formula over the boolean variables representing the
inputs\footnote{For loop-free boolean programs, a weakest precondition
  can be constructed in polynomial
  time~\cite{DBLP:conf/popl/FlanaganS01,DBLP:journals/ipl/Leino05}.},
deciding  is reducible to {\text SAT}.

For boolean programs (with loops),  and
 are {\it PSPACE}-complete, and
 is {\it PSPACE}-hard (the tight upper-bound is
open for ).
\begin{theorem}
\label{thm:lmelgepspace}
   and  are {\it
    PSPACE}-complete for boolean programs.
\end{theorem}

\begin{theorem}
\label{thm:lsepspace}
 is {\it PSPACE}-hard for boolean programs.
\end{theorem}

\section{Safety Hyperproperties}

\label{sec:safety}

Clarkson and Schneider~\cite{DBLP:journals/jcs/ClarksonS10} have
proposed safety hyperproperties, a subclass of hyperproperties, as a
generalization of safety properties.  Intuitively, a safety
hyperproperty is a hyperproperty that can be refuted by observing a
finite set of finite traces.
\begin{definition}[Safety Hyperproperties~\cite{DBLP:journals/jcs/ClarksonS10}] We say that a
hyperproperty  is a safety hyperproperty if for any set of traces
, there exists a set of traces  such that
, and .
\end{definition}

We classify some upper-bounding problems as safety hyperproperties.
\begin{theorem}
\label{thm:umeugesp}
   and  are safety hyperproperties.
\end{theorem}

Next, we review the definition of -safety
hyperproperties~\cite{DBLP:journals/jcs/ClarksonS10}, which refines
the notion of safety hyperproperties.  Informally, a -safety
hyperproperty is a hyperproperty which can be refuted by observing 
number of finite traces.
\begin{definition}[K-Safety
  Hyperproperties~\cite{DBLP:journals/jcs/ClarksonS10}]
  We say that a hyperproperty  is a -safety property if for any
  set of traces , there exists a set of traces  such that , , and .
\end{definition}
Note that -safety hyperproperty is just the standard safety
property, that is, a property that can be refuted by observing a
finite execution trace.  The notion of -safety hyperproperties
first came into limelight when it was noticed that non-interference
is a -safety hyperproperty, but not a -safety
hyperproperty~\cite{terauchi:sas05}.

A -safety hyperproperty can be reduced to a -safety
hyperproperty by self composition~\cite{barthe:csfw04,darvas:spc05}.
\begin{theorem}[\cite{DBLP:journals/jcs/ClarksonS10}]
  -safety hyperproperty can be reduced to -safety hyperproperty
  by self composition.
\end{theorem}

We have shown in our previous work that  and
 are -safety hyperproperties when the bound
 is fixed to a constant.
\begin{theorem}[\cite{DBLP:conf/esorics/YasuokaT10}]
\label{thm:umes}
Let  be a constant.   is a -safety property.
\end{theorem}
\begin{theorem}[\cite{DBLP:conf/esorics/YasuokaT10}]
\label{thm:uges}
Let  be a constant.   is a -safety property.
\end{theorem}

The only hyperproperty that is both a safety hyperproperty and a
liveness hyperproperty is , that is, the
set of all traces~\cite{DBLP:journals/jcs/ClarksonS10}.  Consequently,
neither  nor  is a
liveness hyperproperty.

We have also shown in the previous work that the upper-bounding
problem for Shannon-entropy based quantitative information flow is not
a -safety hyperproperty, even when  is a constant.
\begin{theorem}[\cite{DBLP:conf/esorics/YasuokaT10}]
  Let  be a constant.   is not a -safety
  property for any .
\end{theorem}

\subsection{Computational Complexities}
We prove computational complexities of upper-bounding problems by
utilizing their hyperproperty classifications.  As in
Section~\ref{sec:complower}, we focus on boolean programs.

First, we show that when  is a constant,  and
 are -complete.
\begin{theorem}
\label{thm:umeugeconp}
  Let  be a constant.  Then,  and
   are {\it coNP}-complete for loop-free boolean
  programs.
\end{theorem}
{\it coNP}-hardness follows from the fact that non-interference is
{\it coNP}-hard~\cite{DBLP:conf/esorics/YasuokaT10}.  The {\it coNP}
part of the proof is similar to the {\it NP} part of
Theorem~\ref{thm:lmelgenp}, and uses the fact that  is -safety for a fixed  and uses self composition.  By
self composition, the upper-bounding problem can be reduced to a
reachability problem (i.e., an assertion failure is unreachable for
any input).  To decide if , we construct the
following self-composed program  from the given program .

where .  Then, the weakest precondition of
 with respect to the post
condition  is
valid iff .  Because a weakest precondition of a
loop-free boolean program is a polynomial size boolean formula, and
the problem of deciding a given boolean formula is valid is a {\it
  coNP}-complete problem,  is in {\it coNP}.

Like the lower-bounding problems  and
 for boolean programs (with loops) are {\it
  PSPACE}-complete, and  is {\it PSPACE}-hard.
\begin{theorem}
\label{thm:umeugepspace}
   and  are {\it
    PSPACE}-complete for boolean programs.
\end{theorem}
\begin{theorem}
\label{thm:usepspace}
 is {\it PSPACE}-hard for boolean programs.
\end{theorem}

\section{Discussion}

\subsection{Bounding Domains}

\label{sec:bounddomain}
The notion of hyperproperty is defined over all programs regardless of
their size. (For example, non-interference is a -safety property
for all programs and reachability is a safety property for all
programs.) But, it is easy to show that the lower bounding problems
would become ``-observable'' hyperproperties if we constrained and
bounded the input domains because then the size of the semantics
(i.e., the number of traces) of such programs would be bounded by
 (and upper bounding problems would become
``-safety''
hyperproperties~\cite{DBLP:conf/esorics/YasuokaT10}). In this case,
the problems are trivially -observable hyperproperties.
However, these bounds are high for all but very small domains, and are
unlikely to lead to a practical verification method.


\subsection{Observable Hyperproperties and Observable Properties}
As remarked in~\cite{DBLP:journals/jcs/ClarksonS10}, observable
hyperproperties generalize the notion of observable
properties~\cite{DBLP:journals/apal/Abramsky91}.  It can be shown that
there exists a non-empty observable property that is not a liveness
property (e.g., the set of all traces that starts with ).  In
contrast, Theorem~\ref{thm:nonempty} states that every non-empty
observable hyperproperty is also a liveness hyperproperty.
Intuitively, this follows because the hyperproperty extension relation
 allows the right-hand side to contain traces that does not
appear in the left-hand side.  Therefore, for any ,
there exists  that contains  and an evidence of
the observable hyperproperty.

\subsection{Maximum of QIF over Distribution}

\label{sec:maxqif}

Researchers have studied the maximum of QIF over the distribution.
For example, {\em channel
  capacity}~\cite{mccamant:pldi2008,malacaria08,NMS2009} is the
maximum of the Shannon-entropy based quantitative information flow
over the distribution (i.e., ).
Smith~\cite{smith09} showed that for any program without low-security
inputs, the channel capacity is equal to the min-entropy-based
quantitative information flow, that is, .  Therefore, we obtain the same hyperproperty
classifications and complexity results for channel capacity as .

{\it Min-entropy channel capacity} and {\it guessing-entropy channel
  capacity} are respectively the maximums of min-entropy based and
guessing-entropy based QIF over distributions (i.e.,  and ).  It has been shown that
~\cite{DBLP:journals/entcs/BraunCP09,DBLP:conf/csfw/KopfS10}
and ~\cite{yasuoka:jocssubmit},
that is, they attain their maximums when the distributions are
uniform.  Therefore, they have the same hyperproperty classifications
and complexities as  and , which we have
already analyzed in this paper.


\section{Related Work}
{\v C}ern\'y et al.~\cite{DBLP:conf/csfw/CernyCH11} have investigated
the computational complexity of Shannon-entropy based QIF.  Formally,
they have defined a Shannon-entropy based QIF for interactive boolean
programs, and showed that the explicit-state computational complexity
of their lower-bounding problem is {\it PSPACE}-complete.  In
contrast, this paper's complexity results are ``implicit'' complexity
results of bounding problems of boolean programs (i.e., complexity
relative to the syntactic size of the input) some of which are
obtained by utilizing their hyperproperties classifications.

Clarkson and Schneider~\cite{DBLP:journals/jcs/ClarksonS10} have
classified quantitative information flow problems via hyperproperties.
Namely, they have shown that the problem of deciding if the channel
capacity of a given program is , is a liveness hyperproperty.  And,
they have shown that an upper-bounding problem for the {\em
  belief}-based QIF~\cite{clarkson:csf2005} is a safety hyperproperty.
(It is possible to refine their result to show that their problem for
deterministic programs is actually equivalent to non-interference, and
therefore, is a -safety hyperproperty~\cite{yasuoka:jocssubmit}.)


\section{Conclusion}

We have related the upper and lower bounding problems of quantitative
information flow, for various information theoretic definitions
proposed in literature, to Clarkson and Schneider's hyperproperties.
Hyperproperties generalize the classical trace properties, and are
thought to be more suitable for classifying information flow
properties as they are relations over sets of program traces.  Our
results confirm this by giving a fine-grained classification and
showing that it gives insights into the complexity of the QIF bounding
problems.  One of the contributions is a new class of hyperproperties:
{\em k-observable} hyperproperty.  We have shown that -observable
hyperproperties are amenable to verification via self composition.

\bibliographystyle{eptcs}
\bibliography{klive}

\end{document}
