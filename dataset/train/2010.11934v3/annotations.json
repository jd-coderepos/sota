[{'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'MuSeRC', 'Metric': 'Average F1', 'Score': '0.844'}}, {'LEADERBOARD': {'Task': 'Reading Comprehension', 'Dataset': 'MuSeRC', 'Metric': 'EM', 'Score': '0.543'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'DaNetQA', 'Metric': 'Accuracy', 'Score': '0.657'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'PARus', 'Metric': 'Accuracy', 'Score': '0.504'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'RuCoS', 'Metric': 'Average F1', 'Score': '0.57'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'RuCoS', 'Metric': 'EM', 'Score': '0.562'}}, {'LEADERBOARD': {'Task': 'Common Sense Reasoning', 'Dataset': 'RWSD', 'Metric': 'Accuracy', 'Score': '0.669'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'TERRa', 'Metric': 'Accuracy', 'Score': '0.561'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'RCB', 'Metric': 'Average F1', 'Score': '0.366'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'RCB', 'Metric': 'Accuracy', 'Score': '0.454'}}, {'LEADERBOARD': {'Task': 'Natural Language Inference', 'Dataset': 'LiDiRus', 'Metric': 'MCC', 'Score': '0.061'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Cross-Lingual Transfer', 'Dataset': 'XTREME', 'Metric': 'Sentence-pair Classification', 'Score': '89.8'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Cross-Lingual Transfer', 'Dataset': 'XTREME', 'Metric': 'Structured Prediction', 'Score': 'NA'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Cross-Lingual Transfer', 'Dataset': 'XTREME', 'Metric': 'Question Answering', 'Score': '73.6'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Cross-Lingual Transfer', 'Dataset': 'XTREME', 'Metric': 'Sentence Retrieval', 'Score': 'NA'}}, {'LEADERBOARD': {'Task': 'Zero-Shot Cross-Lingual Transfer', 'Dataset': 'XTREME', 'Metric': 'Avg', 'Score': '40.9'}}]
