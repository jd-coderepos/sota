









In the previous sections we saw that \slrbsc\ parameterized by $r$ is para-\NP-complete and is  \W[1]-hard parameterized by 
$k_\ell$.  So there is no hope of an \FPT\ algorithm unless $P = \NP$ or \FPT\ =\W[1], when parameterized by $r$ and $k_\ell$ respectively.  As a consequence, we consider combining different natural parameters with $r$ to see if this helps to find \FPT\ algorithms. In fact, in this section, we describe a \FPT\ algorithm for \slrbsc\ parameterized by $k_\ell+k_r$.  Since $k_r \leq r$, this implies that \slrbsc\ parameterized by $k_\ell+ r$ is \FPT. This is one of our main technical/algorithmic contribution. 
Also, since $k_\ell \leq b$ for any minimal solution family of an instance, it follows that \slrbsc\ parameterized by $b+k_r$ belongs to \FPT. It is natural to ask whether the \srbsc\ problem, that is, where sets in the family are arbitrary subsets  of the universe and need not correspond to lines, is \FPT\ parameterized by $k_\ell+k_r$. In fact, Theorem~\ref{MeCC_redn} states that the problem is \W[1]-hard even when each set is of size three and contains at least two red points. This shows that indeed restricting ourselves to sets corresponding to lines makes the problem tractable. 











We start by considering a simpler case, where the input instance is such that every line contains exactly $1$ blue point. Later we will show how we can reduce our main problem to such instances. By the restrictions assumed on the input, no two blue points can be covered by the same line and any solution family must contain at least $b$ lines. Thus, $b\leq k_\ell$ or else, it is a \NO\ instance. Also, a minimal solution family will contain at most $b\leq k_\ell$ lines. Hence, from now on we are only interested in the existence of minimal solution families. In fact, inferring from the above observations, a minimal solution family, in this special case, contains exactly $b$ lines. Let $G_{\F'}$ be the intersection graph that corresponds to a minimal solution $\F'$. Recall, that in $G_{\F'}$ vertices correspond to lines in $\F'$ and there is an edge between two vertices  in $G_{\F'}$ if the corresponding lines intersect either at a blue point or a red point. Next, we define notions of 
{\em good tuple} and {\em conformity} which will be useful in designing the \FPT\ algorithm for the special case. 
Essentially, a good tuple provides a numerical representation of connected components of $G_{\F'}$. 

\begin{definition} \label{goodtuple}Given an instance $(R,B,{\cal F})$ of \slrbsc\, we call a tuple 
$$\Big(b,p,s, P,   \{I'_1,\ldots,I'_s\}, (k_r^1,k_r^2,\ldots, k_r^s)\Big)$$  {\em good} if the following hold. 
\begin{enumerate}[(a)] 
 \item Integers $p\leq k_r$  and $s\leq b \leq k_\ell$; Here $b$ is the number of blue vertices in the instance.
 \item $P=P_1 \cup \cdots \cup  P_s$ is an $s$-partition of $B$;
 \item For each $1 \leq i \leq s$, $I'_i$ is an ordering for the blue points in part $P_i$;
 \item Integers $k_r^i,1 \leq i \leq s$, are such that $\Sigma_{1 \leq i \leq s} k_r^i = p$. 
\end{enumerate}
\end{definition}


Below, we define the relevance of good tuples in the context of our problem.
\begin{definition}\label{conforming_tuple}
 We say that the minimal solution family $\F'$ {\em conforms} with a good tuple $\Big(b,p,s, P,   \{I'_1,\ldots,I'_s\}, (k_r^1,k_r^2,\ldots, k_r^s)\Big)$
if the following properties hold:
 \begin{enumerate}
\item The components $C_1,\ldots, C_s$ of $G_{\F'}$ give the partition $P = P_1,\ldots, P_s$ on the blue points.
    \item For each component $C_i$, $1 \leq i \leq s$, let $t_i= \vert P_i \vert$. Let $I_i'=b_1^i,\ldots,b_{t_i}^i$  be an ordering of blue points in $P_i$. Furthermore assume that $L^i_j \in \F'$ covers the blue point $b_j^i$. $I_i'$ has the property that for all $j\leq t_i$ $G_{\F'}[\{L_1^i,\ldots,L_{j}^i \} ]$ is connected. In other words for all $j\leq t_i$, $L_{j}^i$ intersects with at least one of the lines from the set $\{L_1^i,\ldots,L_{j-1}^i \}$.  Notice that, by minimality of  
     $\F'$, the point of intersection for such a pair of lines is a red point.  
    
\item $\F'$ covers $p \leq k_r$ red points.
  \item In each component $C_i$, $k_r^i$ is the number of red points covered by the lines in that component. It follows that $\Sigma_{1 \leq i \leq s} k_r^i =p$. In other words, the integers $k_r^i$ form a combination of $p$.
 \end{enumerate}
\end{definition}

The next lemma says that the existence of a minimal solution subfamily $\F'$ results in a conforming good tuple. 
\begin{lem}
\label{lem:conformingoodtuplexists}
Let  $(U,\F )$ be an input to  \slrbsc\ parameterized by $k_\ell+ k_r$, such that every line contains exactly $1$ blue point. If there exists a solution subfamily $\F'$ then there is a conforming good tuple. 
\end{lem}
\begin{proof}
Let $\F'$ be a minimal solution family of size $b \leq k_\ell$ that covers $p\leq k_r$ red points. Let $G_{\F'}$ have $s$ components viz. $C_1,C_2,\cdots,C_{s}$, where $s \leq k_\ell$. For each $i \leq s$, let $\F_{C_i}$ denote the set of lines corresponding to the vertices of $C_i$. $P_i = B \cap \F_{C_i}$, $t_i = \vert P_i \vert$ and $k_r^i = \vert R \cap \F_{C_i} \vert$. In this special case and by minimality of $\F'$, $\vert \F_{C_i} \vert = t_i$. As $C_i$ is connected, there is a sequence $\{L_1^i,L_2^i,\ldots L_{t_i}^i\}$ for the lines in $\F_{C_i}$ such that for all $j\leq t_i$ we have that 
    $G_{\F'}[\{L_1^i,\ldots,L_{j}^i \} ]$ is connected. This means that, for all $j\leq t_i$ $L_{j}^i$ intersects with at least one of the lines from the set $\{L_1^i,\ldots,L_{j-1}^i \}$. By minimality of $\F'$, the point of intersection for such a pair of lines is a red point. For all $j \leq t_i$, let $L_j^i$ cover the blue point $b_j^i$. Let $I'_i = b_1^i,b_2^i,\ldots,b_{t_i}^i$. 
The tuple $\Big(b,p,s, P=P_1\cup P_2 \ldots \cup P_s, \{I'_1,\ldots,I'_s\}, (k_r^1,k_r^2,\ldots, k_r^s)\Big)$ is a good tuple and it also conforms with $\F'$.   This completes the proof.  
\end{proof}



The idea of the algorithm is to generate all good tuples and then check whether there is a 
solution subfamily $\F'$ that conforms to it. The next lemma states we can check for a conforming minimal solution family when we are given a good tuple. 
\begin{lem}\label{good_tuples}
 For a good tuple $(b,p,s, P,   \{I'_1,\ldots,I'_s\}, (k_r^1,k_r^2,\ldots, k_r^s))$, 
we can verify in $\Oh(b \ell p^b)$ time whether there is a minimal solution family $\F'$ that conforms with this tuple.
\end{lem}

\begin{proof}
The algorithm essentially builds a search tree for each partition $P_i, 1\leq i \leq s$. For each part $P_i$, we define a set of points $R'_i$ which is initially an empty set. 




For each $1 \leq i \leq s$, let $t_i=|P_i|$ and let $I_i'=b_1^i,\ldots,b_{t_i}^i$  be the ordering of blue points in $P_i$. Our objective is to check whether there is a subfamily $\F_i' \subseteq \F$ such that it covers $b_1^i,\ldots,b_{t_i}^i$, and at most $k_r^i$ red point. At any stage of the algorithm, we have a subfamily $\F_i'$ covering  
$b_1^i,\ldots, b_j^i$ and at most $k_r^i$ red points. In the next step we try to enlarge $\F_i'$  in such a way 
that it also covers $b_{j+1}^i$, but still covers at most $k_r^i$ red points. In some sense we follow the ordering given by $I_i'$ to build $\F_i'$. 

Initially, 
$\F_i'=\emptyset$. At any point of the recursive algorithm we represent the problem to be solved by the following tuple: 
($\F_i'$, $R_i'$, ($b_j^i,\ldots,b_{t_i}^i$), $k_r^i -|R_i'|$). 
We start the process by guessing the line in $\cal F$ that covers $b_1^i$, say $L_1^i$. That is, for every $L\in \F$ such that 
$b_1^i$ is contained in $L$ we recursively check whether there is a solution to the tuple 
 ($\F_i':=\F_i'\cup \{L\}$, $R_i':=R_i'\cup (R \cap L) $, ($b_2^i,\ldots,b_{t_i}^i$),$k_r^i:=k_r^i -|R_i'|$).  If any tuple returns \YES\ then we return that there is a subset $\F_i' \subseteq \F$ which covers $b_1^i,\ldots,b_{t_i}^i$, and at most $k_r^i$ red points. 

Now suppose we are at an intermediate stage of the algorithm and the tuple we have is ($\F_i'$, $R_i'$, ($b_j^i,\ldots,b_{t_i}^i$), $k_r^i$). Let $\cal L$ be the set of lines such that it contains $b_j^i$ and a red point from $R_i'$. Clearly, $|{\cal L}|\leq |R_i'| \leq k_r^i$. For every line $L\in  {\cal L}$, we  recursively check whether there is a solution to the tuple ($\F_i':=\F_i'\cup \{L\}$, $R_i':=R_i'\cup (R \cap L) $, ($b_{j+1}^i,\ldots,b_{t_i}^i$),$k_r^i:=k_r^i -|R_i'|$).  If any tuple returns \YES\ then we return that there is a subset $\F_i' \subseteq \F$ which covers $b_1^i,\ldots,b_{t_i}^i$, and at most $k_r^i$ red points. 

Let $\mu=t_i$.  At each stage $\mu$ drops by one and, except for the first step, the algorithm recursively solves at most $k_r^i$ subproblems. This implies that the algorithm takes at most $\Oh(|\F| k_r^{t_i})= \Oh(\ell k_r^{t_i})$ time.  




Notice that the lines in the input instance are partitioned according to the blue points contained in it. Hence, the search corresponding to each part $P_i$ is independent of those in other parts. In effect, we are searching for the components for $G_{\F'}$ in the input instance, in parallel. If for each $P_i$ we are successful in finding a minimal set of lines covering exactly the blue points of $P_i$ while covering at most $k_r^i$ red points, we conclude that a solution family $\F'$ that conforms to the given tuple exists and hence the input instance is a \YES\ instance.

The time taken for the described procedure in each part is at most $\Oh(\ell k_r^{t_i})$. Hence, the total time taken to check if there is a conforming minimal solution family $\F'$ is at most 
$$ \Oh(\ell \cdot \sum_{i=1}^s k_r^{t_i})=  \Oh(s \ell   p^b)=\Oh(b \ell p^b).$$ 
This concludes the proof. 
\end{proof}


We are ready to describe our \FPT\ algorithm for this special case of \slrbsc\ parameterized by $k_\ell+k_r$.
\begin{lem}\label{solution_1blue}
Let  $(U,\F , k_\ell ,k_r)$ be an input to  \slrbsc\ such that every line contains exactly $1$ blue point. Then we can check whether there is a solution subfamily $\F'$ to this instance in time 
$k_\ell^{\Oh(k_\ell)}\cdot k_r^{\Oh(k_r)}\cdot (\vert U \vert+ \vert {\cal F}\vert)^{\Oh(1)}$ time.
\end{lem}
\begin{proof}
Lemma~\ref{lem:conformingoodtuplexists} implies that for the algorithm all we need to do is to enumerate all possible good tuples 
$(b,p,s, P,   \{I'_1,\ldots,I'_s\}, (k_r^1,k_r^2,\ldots, k_r^s))$, and for each tuple, check whether there 
is a conforming minimal solution family. Later, we use the algorithm described in Lemma~\ref{good_tuples}. 
We first give an upper bound on the number of tuples  and how to enumerate them. 
\begin{enumerate}
\item There are $k_\ell$ choices for $s$ and $k_r$ choices for $p$.
\item There can be at most $b^{k_\ell}$ choices for $P$ which can be enumerated in  $\Oh(b^{k_\ell}\cdot k_\ell)$ time. 
\item For each $j\leq s$, $I'_j$ is ordering for blue points in $P_i$. Thus, if $|P_i|=t_i$, then the number of  ordering 
tuples $\{I'_1,\ldots,I'_s\}$ is upper bounded by $\prod_{i=1}^s t_i! \leq \prod_{i=1}^s t_i^{t_i} \leq  \prod_{i=1}^s b^{t_i} =b^b$. 
Such orderings can be enumerated in $\Oh(b^b)$ time.
 
\item For a fixed $p\leq k_r,s\leq k_\ell$, there are 
at most $p + s-1 \choose s -1$ solutions for $k_r^1+k_r^2+ \ldots + k_r^s = p$  
and this set of solutions can be enumerated in $\Oh({{p+s-1} \choose {s-1}}\cdot ps)$ time. Notice that if $p \geq s$ then the time required for enumeration is $\Oh((2p)^{p}\cdot ps)$. Otherwise, the required time is $\Oh((2s)^{s}\cdot ps)$. As $p \leq k_r$ and $s \leq k_\ell$, the time required to enumerate the set of solutions is $\Oh(k_\ell^{\Oh(k_\ell)}k_r^{\Oh(k_r)}\cdot k_\ell k_r)$. 
\end{enumerate}
   Thus we can generate the set of tuples in time $k_\ell^{\Oh(k_\ell)}\cdot k_r^{\Oh(k_r)}$.Using Lemma~\ref{good_tuples}, for each tuple we check in at most $\Oh(k_r^{k_\ell}\cdot k_\ell \ell)$ time whether there is a conforming solution family or not. If there is no tuple with a conforming solution family, we know that the input instance is a \NO\ instance. 
   The total time for this algorithm is $k_\ell^{\Oh(k_\ell)}k_r^{\Oh(k_r)}k_r^{\Oh(k_\ell)}\cdot (\vert U \vert+\vert {\cal F} \vert)^{\Oh(1)}$. Again, if $k_r \leq k_l$ then $k_r^{\Oh(k_\ell)} = k_\ell^{\Oh(k_\ell)}$. Otherwise, $k_r^{\Oh(k_\ell)} = k_r^{\Oh(k_r)}$. Either way, it is always true that $k_r^{\Oh(k_\ell)} = k_\ell^{\Oh(k_\ell)}k_r^{\Oh(k_r)}$. Thus, we can simply state the running time to be 
   $k_\ell^{\Oh(k_\ell)}\cdot k_r^{\Oh(k_r)}\cdot (\vert U \vert + \vert {\cal F}\vert)^{\Oh(1)}$.  
\end{proof}








We return to the general problem of \slrbsc\ parameterized by $k_\ell+k_r$. Instances in this problem may have lines containing $2$ or more blue points. 
We use the results and observations described above to arrive at an \FPT\ algorithm for \slrbsc\ parameterized by $k_\ell+k_r$.

\begin{theorem}
\label{thm:colour_coding}
 \slrbsc\ parameterized by $k_\ell+k_r$ is \FPT, with an algorithm that runs in $k_\ell^{\Oh(k_\ell)}\cdot 
 k_r^{\Oh(k_r)} \cdot (\vert U \vert + \vert {\cal F} \vert)^{\Oh(1)}$ time.
\end{theorem}
\begin{proof}
Given an input $(U,\F , k_\ell ,k_r)$ for \slrbsc\ parameterized by $k_\ell+k_r$, we do some preprocessing to make the instance simpler. We exhaustively apply Reduction Rules~\ref{redn1}, \ref{red_vertices_bd} and~\ref{redn4}. After this, by Observation~\ref{blue_size}, the reduced equivalent instance has at most $k_\ell \choose 2$ blue points  if it is a \YES\ instance.

A minimal solution family can be broken down into two parts:  the set of lines containing at least $2$ blue points, and the remaining set of lines which contain exactly $1$ blue point.  Let us call these sets $\F_2$ and $\F_1$ respectively. We start with the following observation. 

\begin{observation}\label{2blue_lines}
 Let $\F'' \subseteq \F$ be the set of lines that contain at least $2$ blue points. There are at most $k_\ell^{4} \choose k_\ell$ ways in which a solution family can intersect with $\F''$.
\end{observation}
\begin{proof}
 Since $b \leq {k_\ell \choose 2}$, it follows from Observation~\ref{covering_lines_bd} that $\vert \F''\vert \leq k_\ell^4$. For any solution family, there can be at most $k_\ell$ lines containing at least $2$ blue points. Since the number of subsets of $\F''$ of size at most $k_\ell$ is bounded by $k_\ell^{4k_\ell}$, the observation is true.
\end{proof}

 From Observation~\ref{2blue_lines}, there are $k_\ell^{4k_\ell}$ choices for the set of lines in $\F_2$. We branch on all these choices of $\F_2$. On each branch, we reduce the budget of $k_\ell$ by the number of lines in $\F_2$ and the budget of $k_r$ by $\vert R \cap \F_2 \vert$. Also, we make some modifications on the input instance: we delete all other lines containing at least $2$ blue points from the input instance. We delete all points of $U$ covered by $\F_2$ and all lines passing through blue points covered by $\F_2$. Our modified input instance in this branch now satisfies the assumption of Lemma~\ref{solution_1blue} and we can find out in $k_\ell^{\Oh(k_\ell)}k_r^{\Oh(k_r)}\cdot (\vert U\vert +\vert {\cal F} \vert)^{\Oh(1)}$ time whether there is a minimal solution family $\F_1$ for this reduced instance. If there is, then $\F_2 \cup \F_1$ is a minimal solution for our original input instance and we correctly say \YES.
Thus the total running time of this algorithm is $k_\ell^{\Oh(k_\ell)} \cdot k_r^{\Oh(k_r)} \cdot (\vert U \vert + \vert {\cal F}\vert)^{\Oh(1)}$. 

It  may be noted here that for a special case where we can use any line in the plane as part of the solution, the second part of the algorithm becomes considerably simpler. Here for each blue point $b$, we can use an arbitrary line containing only $b$ and no red point.
 \end{proof} 
 





\begin{corollary}\label{sp_case_red}
\slrbsc\ parameterized by $k_\ell+d$, where every line contains at most $d$ red points, is \FPT. The running time of the \FPT\ algorithm is $(dk_\ell)^{\Oh(dk_\ell)} \cdot (\vert U\vert +\vert {\cal F}\vert)^{\Oh(1)}$. The problem remains \FPT\ for all parameter sets $\Gamma'$ that contain $\{k_\ell,d\}$ or $\{b,d\}$. 
\end{corollary}

\begin{proof}
In this special case, any solution family can contain at most $dk_\ell$ red points. Hence we can safely assume that $k_r \leq dk_\ell$ and apply Theorem~\ref{thm:colour_coding}. 
\end{proof}
\subsection{Kernelization for \slrbsc\ parameterized by $k_\ell+k_r$ and $b+k_r$}


We give a polynomial parameter transformation from \SC\ parameterized by universe size $n$, to \slrbsc\ parameterized by $k_\ell+k_r+b$. Proposition \ref{SC_results}(ii) implies that on parameterizing by any subset of the parameters $\{k_\ell,k_r,b\}$, we will also obtain a negative result for polynomial kernels.


\begin{thmk}\label{set_cover_redn}
 \slrbsc\ parameterized by $k_\ell+k_r+b$ does not allow a polynomial kernel unless $\CoNP\subseteq \NP/\mbox{poly}$.
\end{thmk}
 
\begin{proof}
 
 Let $(U,\mathcal{S})$ be a given instance of \SC. Let $\vert U \vert =n, \vert {\mathcal S} \vert =m$. We construct an instance $(R \cup B,\F)$ of \slrbsc\ as follows. We assign a blue point $b_u \in B$ for each element $u \in U$ and a red point $r_S \in R$ for each set $S \in \mathcal{S}$. The red and blue points are placed such that no three points are collinear. We add a line between $b_u$ and $r_S$ if $u \in S$ in the \SC\ instance. Thus the \slrbsc\ instance $(R\cup B,\mathcal{F})$ that we have constructed has $b =n$, $r=m$ and $\ell =\sum_{S\in {\cal S}} |S|$. We set $k_r = k$ and $k_\ell=n$.
 
 \begin{claim}
  All the elements in $(U,\mathcal{S})$ can be covered by $k$ sets if and only if there exist $n$ lines in $(R\cup B,\mathcal{F})$ that contain all blue points but only $k$ red points.
 \end{claim}
\begin{proof}
 Suppose $(U,\mathcal{S})$ has a solution of size $k$, say $\{S_1,S_2,\cdots S_k\}$. The red points in the solution family for \slrbsc\ are $\{r_{S_1},r_{S_2},\cdots r_{S_k}\}$  corresponding to $\{S_1,S_2,\cdots S_k\}$. For each element $u \in U$, we arbitrarily assign a covering set $S_u$ from $\{S_1,S_2,\cdots S_k\}$. The solution family is the set of lines defined by the pairs 
 $\{(b_u, r_{S_u})~\mid ~ u \in U\}$. This covers all blue points.

 Conversely, if $(R\cup B,\mathcal{F})$ has a solution family $\F'$ covering $k$ red points and using at most $n$ lines, the sets in $\mathcal{S}$ corresponding to the red points in $\F'$ cover all the elements in $(U,\mathcal{S})$.
\end{proof}
If $k > n$, then the \SC\ instance is a trivial \YES\ instance. Hence, we can always assume that $k \leq n$.
This completes the proof that \slrbsc\ parameterized by $k_\ell+k_r+ b$ cannot have a polynomial sized kernel unless $\CoNP\subseteq \NP/\mbox{poly}$.
\end{proof}


