\documentclass[letterpaper]{article}
\usepackage{aaai}
\usepackage{times}
\usepackage{helvet}
\usepackage{courier}
\usepackage{amsmath}

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}[theorem]

\newcommand{\systemname}[1]{\textit{#1}}

\newcommand{\alphabet}{\mathcal{A}}
\newcommand{\calphabet}{\mathcal{C}}
\newcommand{\assignment}{\mathbf{A}}
\newcommand{\cassignment}{A}
\newcommand{\theory}{\mathcal{T}}
\newcommand{\tass}[1]{\mathbf{T}#1}
\newcommand{\fass}[1]{\mathbf{F}#1}
\newcommand{\Tass}{\assignment^\mathbf{T}}
\newcommand{\Fass}{\assignment^\mathbf{F}}
\newcommand{\atom}[1]{atom(#1)}
\newcommand{\head}[1]{head(#1)}
\newcommand{\body}[1]{body(#1)}
\newcommand{\dneg}{not\ }
\newcommand{\domain}[1]{dom(#1)}
\newcommand{\range}[1]{range(#1)}
\newcommand{\scope}[1]{scope(#1)}

\newcommand{\encsup}{}
\newcommand{\encbou}{}
\newcommand{\encran}{}
\newcommand{\encbouh}[1]{\encbou}
\newcommand{\encranh}[1]{\encran}

\newcommand{\citeay}[1]{\citeauthor{#1} \citeyear{#1}}
\newcommand{\citeap}[1]{\citeauthor{#1} (\citeyear{#1})}

\pdfinfo{
/Title (Reformulation of Global Constraints in Answer Set Programming)
/Subject (AAAI-10 Workshop on Abstraction, Reformulation, and Approximation)
/Author (Christian, Drescher; Toby, Walsh;)
}

\title{Reformulation of Global Constraints in Answer Set Programming}
\author{
Christian Drescher \\
Vienna University of Technology \\
Austria
\And
Toby Walsh \\
NICTA and University of New South Wales \\
Australia
}

\begin{document}
\maketitle

\begin{abstract}
We show that global constraints on finite domains like \emph{all-different} can be reformulated into answer set programs on which we achieve arc, bound or range consistency.
These reformulations offer a number of other 
advantages beyond providing the power of global
propagators to answer set programming. For example,
they provide other constraints with access to the state of the propagator by sharing variables. Such sharing can be used to improve propagation between constraints. Experiments with these encodings demonstrate their promise.
\end{abstract}

\section{Introduction}


There are several approaches to representing and solving constraint satisfaction problems: constraint programming (CP; \citeay{dechter03}, \citeay{robewa06a}), answer set programming (ASP; \citeay{baral03}), propositional satisfiability checking (SAT; \citeay{bihemawa09a}), its extension to satisfiability modulo theories (SMT; \citeay{niolti06a}), and many more. Each has its particular strengths: for example, CP systems support global constraints, ASP systems permit recursive definitions and offer default negation, whilst SAT solvers often exploit very efficient implementations. In many applications it would often be helpful to exploit the strengths of multiple approaches. Consider the problem of timetabling at a university~\cite{jaoijani09a}.  To model the problem, we need to express the mutual exclusion of events (for instance, 
we cannot place two events in the same room at the same time). A
straightforward representation of such constraint with clauses and rules uses
quadratic space. In contrast, global constraints such as \emph{all-different} typically supported by CP systems can give a much more concise encoding. On the other hand, there are features which are hard to describe in traditional constraint programming, like the temporary unavailability of a particular room. However, this is easy to represent with non-monotonic rules such as those used in ASP. Such rules also provide a flexible mechanism for defining new relations on the basis of existing ones.

Answer set programming has been put forward as a powerful paradigm to solve constraint  satisfaction problems. \citeap{niemela99a} shows that ASP embeds SAT but provides a more expressive framework from a knowledge representation point of view. Moreover, modern ASP solvers compete\footnote{\texttt{http://www.satcompetition.org}} with the best SAT solvers.
An empirical comparison of the performance of ASP and constraint logic programming (CLP; \citeay{jama94a}) systems on solving combinatorial problems conducted by \citeauthor{dofopo05a} shows ASP encodings to be more compact, more declarative, and highly competitive.
However, as some problems are more naturally modelled by using non-pro\-po\-si\-tional constructs, like resources or functions over finite domains, and by using global
constraints in particular, there is an increasing desire to handle constraints beyond pure ASP.

One approach to combining ASP and CP is to integrate theory-specific predicates into propositional formulas (motivated by SMT), and to extend the ASP solver's decision engine with a higher level proof procedure \cite{baboge05a,melgel08a,geossc09a}. However, the resulting systems have a number of limitations. First, they are tied to particular ASP and CP solvers. Second, the support for global constraints is limited. Third, communication between the ASP and CP solver is restricted.
Alternative techniques, such as reformulating constraints into ASP have received little attention.
The key contribution of our work is an investigation of reformulation in the context of answer set programming, illustrated by reformulations of the popular \emph{all-different} constraint. The resulting approach has been implemented in the new preprocessor \systemname{inca}. Empirical evaluation demonstrates its computational potential.



\section{Background}
\paragraph{Answer Set Programming}
A \emph{(normal) logic program}  over a set of primitive propositions  is a finite set of rules of the form

where  and  are \emph{atoms} for . A \emph{literal}  is an atom  or its default negation .
For a rule~, let  be the \emph{head} of  and  the \emph{body} of . The set of atoms occurring in a logic program  is denoted by , and the set of bodies in  is . For regrouping bodies sharing the same head~, define .
The semantics of a logic program is given by its answer sets, being total well-founded models of . For a formal introduction to ASP, we refer the reader to \citeap{baral03}.
The semantics of important extensions to logic programs, such as choice rules, integrity, and cardinality constraints, is given through program transformations that introduce additional propositions (cf. \citeay{siniso02a}).
A \emph{choice rule} allows for the non-deterministic choice over atoms in  and has the form

An \emph{integrity constraint} of the form

is a short hand for a rule with an unsatisfiable head, and thus forbids its body to be satisfied in any answer set.
A~\emph{cardinality constraint} of the form

is interpreted as no  literals of the set  are included in an answer set.
\citeauthor{siniso02a} provide a transformation that needs just  rules, introducing atoms  to represent the fact that at least  of the literals with index , i.e. the literals in ,
 are in a particular answer set candidate. Then, the cardinality constraint can be encoded by an integrity constraint  and the three following rules, where  and :



\paragraph{Nogoods of Logic Programs}
We want to view inferences in ASP as unit-propagation on nogoods. 
Following \citeap{gekanesc07a}, inferences in ASP rely on atoms and program rules, which can be expressed by using atoms and bodies. Thus, for a program~, the \emph{domain} of Boolean assignments~ is fixed to .

Formally, a Boolean \emph{assignment}  is a set  of \emph{signed literals}~ for  of the form  or  where .  expresses that  is assigned \emph{true} and  that it is \emph{false} in . (We omit the attribute \emph{Boolean} for assignments whenever clear from the context.) The complement of a signed literal~ is denoted by , that is  and .
In the context of ASP, a \emph{nogood} is a set  of signed literals, expressing a constraint violated by any assignment~ such that .
For a nogood , a signed literal , and an assignment , we say that  is \emph{unit} and  is \emph{unit-resulting} if .
Let  the set of true propositions and  the set of false propositions. A \emph{total} assignment, that is  and , is a \emph{solution} for a set  of nogoods if  for all .

As shown in \citeap{lee05a}, the answer sets of a logic program  correspond to the models of the completion of  that satisfy the loop formulas of all non-empty subsets of . For , define

Intuitively, the nogoods in  enforce the truth of body~ iff all its literals are satisfied.
For an atom  with , let

Then, the solutions for  correspond to the models of the completion of . Loop formulas, expressed in the set of nogoods~, have to be added to establish full correspondence to the answer sets of .
Typically, solutions for  are computed by applying \emph{conflict-driven nogood learning} (CDNL; \citeap{gekanesc07a}). This combines search and propagation by recursively assigning the value of a proposition and using \emph{unit-propagation} to determine logical consequences of an assignment \cite{mitchell05a}.


\paragraph{Constraint Satisfaction Problem}
The classic definition of a constraint satisfaction problem is as follows (cf. \citeay{robewa06a}). A \emph{constraint satisfaction problem} is a triple  where  is a set of \emph{variables} ,  is a set of finite \emph{domains}  such that each variable~ has an associated domain , and  is a set of \emph{constraints}. A constraint~ is a pair~ where  is a -ary \emph{relation} on the variables in , called the \emph{scope} of . In other words,  is a subset of the Cartesian product of the domains of the variables in . To access the relation and the scope of  define  and . For a \emph{(constraint variable) assignment}  and a constraint  with , define , and call  \emph{satisfied} if . Given this, define the set of constraints satisfied by  as


A binary constraint~ has . For example,
 ensures that  and  take different
values. A global (or -ary) constraint~ has parametrized
scope. For example, 
the \emph{all-different} constraint ensures that
a set of variables,  take all different values. 
This can be decomposed into  binary
constraints,  for . However, as 
we shall see, such reformulation can hinder inference. 
An assignment~ is a \emph{solution} iff it satisfies all constraints in .

Constraint solvers typically use backtracking search to explore the space of partial assignments. Various heuristics affecting, for instance, the variable selection criteria and the ordering of the attempted values, can be used to guide the search. Each time a variable is assigned a value, a deterministic propagation stage is executed, pruning the set of values to be attempted for the other variables, i.e., enforcing a certain type of local consistency.

A binary constraint~ is called \emph{arc consistent} iff when a variable~ is assigned any value~, there exists a consistent value~ for the other variable~.
An -ary constraint~ is \emph{hyper-arc consistent} or \emph{domain consistent} iff when a variable~ is assigned any value~, there exist compatible values in the domains of all the other variables~ for all  such that .

Relational consistency \cite{debe97a} extends the concept of local consistency. I.e. a constraint~ is \emph{relationally -arc consistent} if any consistent assignment of a -elementary subset of variables from  extends to a consistent assignment of all variables in .

The concepts of bound and range consistency are defined for constraints on ordered intervals.
Let  and  be the minimum value and maximum value of the domain~. A constraint~ is \emph{bound consistent} iff when a variable~ is assigned  (i.e. the minimum or maximum value in its domain), there exist compatible values between the minimum and maximum domain value for all the other variables in the scope of the constraint. Such an assignment is called a \emph{bound support}. A constraint is \emph{range consistent} iff when a variable is assigned any value in its domain, there exists a bound support. Notice that range consistency is in between domain and bound consistency, where domain consistency is the strongest of the three formalisms.


\section{Encoding Global Constraints in ASP}
In this section we explain how to reformulate multi-valued variables and constraints on finite domains into a logic program under answer set semantics. In what follows, we assume  for all  to save the reader from multiple superscripts.

\paragraph{Direct Encoding}
A popular choice is called the \emph{direct encoding} \cite{wa00}. In the direct encoding, a propositional variable , representing , is introduced for each value~ that can be assigned to the constraint variable~. Intuitively, the proposition  is true if  takes the value , and false if  takes a value different from . For each , the truth-assignments of atoms  are encoded by a choice rule (1). Furthermore, there is an integrity constraint (2) to ensure that  takes at least one value, and a cardinality constraint (3) that ensures that  takes at most one value.

In the direct encoding, each forbidden combination of values in a constraint is expressed by an integrity constraint. On the other hand, when a relation is represented by allowed combinations of values, all forbidden combinations have to be deduced and translated to integrity constraints. Unfortunately, the direct encoding of constraints hinders propagation:
\begin{theorem}
Enforcing arc consistency on the binary decomposition of the original constraint prunes more values from the variables domain than unit-propagation on its direct encoding.
\end{theorem}

\paragraph{Support Encoding}
The \emph{support encoding} has been proposed to
tackle this weakness \cite{gent02}. A \emph{support} for a constraint variable~ to take the value~ across a constraint~ is the set of values  of another variable in~ which allow , and can be encoded as follows, extending (1--3):

This integrity constraint can be read as whenever , then at least one of its supports must hold.
In the support encoding, for each constraint~ there is one support for each pair of distinct variables , and for each value~.
\begin{theorem}
Unit-propagation on the support encoding enforces arc consistency on the binary decomposition of the original constraint.
\end{theorem}
We illustrate this approach on an encoding of the global \emph{all-different} constraint. For variables  and value  it can be reduced from the definition by using the equivalence covered by (2--3) to

Observe, that this is also
the direct encoding of the binary decomposition of the global \emph{all-different} constraint. However, this observation does not hold in general for all constraints.
As discussed in the Background section of this paper, we can express above condition as  cardinality constraints:


\begin{corollary}
Unit-propagation on (1--4) enforces arc consistency on the binary decomposition of the global \emph{all-different} constraint in  down any branch of the search tree.
\end{corollary}


\paragraph{k-support Encoding}
The support encoding can be generalized to the \emph{-support encoding} \cite{behewa03a} representing supports on subsets of  for an assignment of another -elementary subset of variables in . More formal, a -support~ for an assignment  of ~variables from , say , is an assignment  such that  which allows . We introduce a \emph{support-variable}~, that evaluates to true iff  holds:

Furthermore, let  be the set of all -supports of . A -support rule for  is defined as

meaning that as long as  holds then at least one of its -supports  must hold.
In the -support encoding, for each constraint~ there is one -support rule for each assignment~ of ~variables from .
\begin{theorem}
Unit-propagation on the -support encoding enforces relational -arc consistency on the original constraint.
\end{theorem}


\paragraph{Range Encoding}
In the \emph{range encoding}, a propositional variable~ is introduced for all  to represent whether the value of~ is between  and . For each range~, the following  rules encode  whenever it is safe to assume that  and , and enforce a consistent set of ranges such that :

Constraints are encoded into integrity constraints representing conflict regions. When the combination  violates the constraint, the following rule is added:

\begin{theorem}
Unit-propagation on the range encoding enforces range consistency on the original constraint.
\end{theorem}
A propagator for the global \emph{all-different} constraint that enforces range consistency pruning Hall intervals has been proposed by \citeap{le96a} and encoded to SAT by \citeap{bekanaquwa09a}.
An interval~ is a \emph{Hall interval} iff . In other words, a Hall interval of size~ completely contains the domains of ~variables. Observe that in any bound support, the variables whose domains are contained in the Hall interval consume all values within the Hall interval, whilst any other variable must find their support outside the Hall interval.
The following reformulation of the global \emph{all-different} constraint will permit us to achieve range consistency via unit propagation. It ensures that no interval  can contain more variables than its size. 

This simple reformulation can simulate a complex propagation algorithm like \citeauthor{le96a}'s with a similar overall complexity of reasoning.
\begin{corollary}
Unit-propagation on (5--8) enforces range consistency on the global \emph{all-different} constraint in  down any branch of the search tree.
\end{corollary}
A hybrid that links the range encoding of  to its direct representation extends the range encoding as follows, for each :

These rules encode the equivalence .

\paragraph{Bound Encoding}
A last encoding is called the \emph{bound encoding} \cite{crba94a}. In the bound encoding, a propositional variable~ is introduced for each value  to represent that the value of~ is bounded by~. That is,  if  is assigned \emph{true}, and  if  is assigned \emph{false}. Similar to the direct encoding, for each , the truth-assignments of atoms~ are encoded by a choice rule (9). In order to ensure that assignments represent a consistent set of bounds, the condition  is posted as integrity constraints (10) . Another integrity constraint (11) encodes , that at least one value must be assigned to :

Constraints are encoded into integrity constraints representing conflict regions similar to the range encoding. When all combinations in the region

violate a constraint, the following rule is added:

\begin{theorem}
Unit-propagation on the bound encoding enforces bound consistency on the original constraint.
\end{theorem}
In order to get a representation of the global \emph{all-different} constraint that can only prune bounds, the bound encoding for variables is linked to (8) as follows:

\begin{corollary}
Unit-propagation on (8--14) enforces bound consistency on the global \emph{all-different} constraint in  down any branch of the search tree.
\end{corollary}
Note that an upper bound  can be posted on the size of Hall intervals. The resulting encoding with only those cardinality constraints (5) for which  detects Hall intervals of size at most , and therefore enforces a weaker level of consistency.

To access the value of , the bound encoding can be extended to a hybrid by adding the following rules to the bound encoding for each :

The first rule enforces  to be true if possible values for  are bound to the singleton , i.e.  and  are in the assignment. On the other hand, the condition  is represented as integrity constraints.

\paragraph{Non-ground Logic Programs}
Although our semantics is propositional, atoms in  and can be constructed from a first-order signature , where
 is a set of function symbols (including constant symbols),
 is a denumerable collection of first-order variables, and
 is a set of predicate symbols.
The logic program over  is then obtained by a grounding process, systematically substituting all occurrences of variables  by terms in , where  denotes the set of all ground terms over . Atoms in  are formed from predicate symbols  and terms in .


\section{Experiments}
To evaluate these reformulations, we conducted experiments on encodings containing \emph{all-different} and \emph{permutation} constraints.
The global \emph{permutation} constraint is a special case of \emph{all-different} when the number of variables is equal to the number of all their possible values. A reformulation of \emph{permutation} extends (4) by

or (8) by the following rule where :

This can increase propagation.
Our reformulations have been implemented within the prototypical preprocessor \systemname{inca}\footnote{\texttt{http://potassco.sourceforge.net/} provides the systems \systemname{clasp}, \systemname{clingo}, \systemname{gringo}, \systemname{inca}, and the benchmark set} which compiles an (extended) logic programs with high-level statements for global constraints, constraint variables, first-order variables, function symbols, and aggregates, etc. in linear time and space, such that the logic program can be obtained by a \emph{grounding} process.
Experiments consider \systemname{inca} in different settings using different reformulations. We denote the support encoding of the global constraints by \encsup, the bound encoding of the global constraints by \encbou, and the range encoding of the global constraints by \encran. To explore the impact of small Hall intervals, we also tried \encbouh{k} and \encranh{k}, an encoding of the global constraints with only those cardinality constraints (8) for which . The consistency achieved by \encbouh{k} and \encranh{k} is therefore weaker than full bound and range consistency, respectively.

We also include the pure CP system \systemname{gecode}\footnote{\texttt{http://www.gecode.org/}} (3.2.0), and the integrated system \systemname{ezcsp}\footnote{\texttt{http://krlab.cs.ttu.edu/\~{}marcy/ezcsp/}} (1.6.9; \citeay{ba09a}) in our empirical analysis. The latter combines the grounder \systemname{gringo} (2.0.3) and ASP solver \systemname{clasp} (1.3.0) with \systemname{sicstus}\footnote{\texttt{http://www.sics.se/sicstus/}} (4.0.8) as a constraint solver.
Since \systemname{inca} is a pure preprocessor, we select the ASP system \systemname{clingo} (2.0.3) as its backend to provide a representative comparison with \systemname{ezcsp}. Note that \systemname{clingo} stands for \systemname{clasp} on \systemname{gringo} and combines both systems in a monolithic way.
All experiments were run on a 2.00~GHz PC under Linux. We report results in seconds, where each run was limited to 600 s time and 1 GB RAM.

\paragraph{Pigeon Hole Problem}
The \emph{pigeon hole problem} (PHP) is to show that it is impossible to put  pigeons into  holes if each pigeon must be put into a distinct hole.
Clearly, our bound and range reformulations are faster compared to weaker encodings (see Table \ref{tab:php}). It appears that \systemname{sicstus}' and \systemname{gecode}'s default configuration uses filtering algorithms for the global \emph{all-different} constraint achieve arc consistency on its binary decomposition. However, on such problems, detecting large Hall intervals is essential.
\begin{table}
\centering
\begin{tabular}{cccccccc} \hline\hline
 & \encsup & \encbouh{3} & \encbou & \encranh{3} & \encran & \systemname{ezcsp} & \systemname{gecode} \\ \hline
10 & 5 & \textbf{1} & \textbf{1} & 1 & \textbf{1} & 2 & \textbf{1} \\
11 & 46 & 1 & \textbf{1} & 2 & \textbf{1} & 17 & 9 \\
12 & 105 & 4 & \textbf{1} & 3 & \textbf{1} & 184 & 104 \\
13 & --- & 25 & \textbf{1} & 30 & \textbf{1} & --- & --- \\
14 & --- & 125 & \textbf{1} & 197 & \textbf{1} & --- & --- \\
15 & --- & --- & \textbf{1} & --- & \textbf{1} & --- & --- \\
16 & --- & --- & \textbf{1} & --- & \textbf{1} & --- & --- \\ \hline\hline
\end{tabular}
\caption{Runtime results in seconds for PHP. \label{tab:php}}
\end{table}

\paragraph{Latin Squares}
A \emph{Latin square} is an -table filled with  different elements such that each element occurs exactly once in each row and each column of the table. The \emph{Latin square puzzle}~(LSP) is to determine whether a partially filled table can be completed in such a way that a Latin square is obtained.
Randomly generated LSP has been proposed as a benchmark domain for CP systems by \citeauthor{gose97a} since it combines the features of purely random problems and highly structured problems.
\begin{table}
\centering
\begin{tabular}{cccccccc} \hline\hline
\% & \encsup & \encbouh{3} & \encbou & \encran & \systemname{ezcsp} & \systemname{gecode} & \systemname{gecode} \\ \hline
10 & \textbf{3} & 5 & 8 & 7 &30 (7)  & 2 (4) & 1 (1) \\
20 & \textbf{2} & 5 & 8 & 7 &21 (20) & 5 (4) & 1 (3) \\
30 & \textbf{2} & 5 & 8 & 7 &10 (30) & 3 (13) & 1 (5) \\
35 & \textbf{2} & 5 & 8 & 7 &22 (24) &14 (13) & 6 (7) \\
40 & \textbf{2} & 5 & 8 & 7 &52 (29) &12 (20) & 6 (9) \\
45 & \textbf{2} & 5 & 8 & 7 &36 (35) &18 (25) & 6 (13) \\
50 & \textbf{2} & 5 & 8 & 7 &36 (50) &25 (32) & 6 (18) \\
55 & \textbf{2} & 4 & 8 & 7 &61 (51) &20 (41) &31 (29) \\
60 & \textbf{2} & 4 & 8 & 7 &60 (63) &36 (51) &27 (35) \\
70 & \textbf{2} & 4 & 7 & 6 &70 (66) &28 (45) &17 (27) \\
80 & \textbf{2} & 4 & 7 & 5 &16 (18) &17 (13) & 7 (7) \\
90 & 2 & 4 & 7 & 5 & \textbf{1} & 1 (1) & 3 \\ \hline\hline
\end{tabular}
\caption{Average times over 100 runs on LSP. Timeouts are given in parenthesis, if any.\label{tab:qcp}}
\vspace{-1\baselineskip}
\end{table}
Table \ref{tab:qcp} compares the runtime for solving LSP problems of size  where the first column gives the percentage of preassigned values. We included \systemname{gecode} with algorithms that enforce bound and domain consistency, denoted as \systemname{gecode} and \systemname{gecode} (not shown due to space constraints), in the experiments. Our analysis exhibits phase transition behaviour of the systems \systemname{ezcsp}, \systemname{gecode}, and \systemname{gecode}, while our Boolean encodings and \systemname{gecode} solve all problems within seconds. Interestingly, learning constraint interdependencies as in our approach is sufficient to tackle LSP. In fact, most of the time for , ,  is spent on grounding, but not for solving the actual problem.

\paragraph{Graceful Graphs}
A labelling  of the nodes of a graph  is \emph{graceful} if  assigns a unique label~ from  to each node  such that, when each edge  is assigned the label , the resulting edge labels are distinct. The problem of determining the existence of a graceful labelling of a graph (GGP) has been modelled in CP \citeap{pesm03a}, using auxillary variables  for edge labels. We represent the equivalence  in the direct encoding which weakens the overall consistency. Our experiments consider double-wheel graphs  composed by two copies of a cycle with  vertices, each connected to a central hub.
\begin{table}
\centering
\begin{tabular}{cccccccc} \hline\hline
 & \encsup & \encbouh{1} & \encbouh{3} & \encbou & \encran & \systemname{ezcsp} & \systemname{gecode} \\ \hline
 & 11 &  4 &  6 &  9 &  6 & 6 & \textbf{2} \\
 &  1 &  2 &  1 &  3 &  3 & \textbf{1} & \textbf{1} \\
 &  4 &  5 &  4 & 13 & 12 & 1 & \textbf{1} \\
 &  7 & 11 & 18 & 48 & 21 & \textbf{1} & 7 \\
 & 24 & 28 & 68 &228 & 60 & \textbf{18} & --- \\
 & 48 & 68 & ---  &208 & 58 & \textbf{4} & --- \\
 & \textbf{83} &106 &200 &487 & ---  & 390 & --- \\ \hline\hline
\end{tabular}
\caption{Runtime results in seconds for GGP. \label{tab:ggp}}
\vspace{-1\baselineskip}
\end{table}
Table \ref{tab:ggp} shows that our encodings compete with \systemname{ezcsp} and outperform \systemname{gecode}, where the support encoding performs better than bound and range encodings. In most cases, the branching heuristic used in our approach appears to be misled by the extra variables introduced in  and . That explains some of the variability in the runtimes.


\section{Conclusions}

We have reformulated global and other constraints into answer set programs. In particular, we have investigated various generic ASP encodings for constraints on finite domains and proved which level of consistency unit-pro\-pa\-ga\-tion achieves on them.
Our techniques were formulated as preprocessing and can be applied to any ASP system without changing its source code, which allows for programmers to select the ASP solver that best fit their needs. We have empirically evaluated the performance of
such an approach on benchmarks from CP and found that such reformulations outperform integrated ASP(CP) systems as well as pure CP solvers.
Our future works includes the reformulation of other useful
global constraints into answer set programming like the
\emph{regular} constraint, as well as global constraints
like \emph{lex} which are very useful for symmetry breaking .

\begin{thebibliography}{}

\bibitem[\protect\citeauthoryear{Balduccini}{2009}]{ba09a}
Balduccini, M.
\newblock 2009.
\newblock {CR}-prolog as a specification language for constraint satisfaction
  problems.
\newblock In {\em Proc. of LPNMR'09},  402--408.
\newblock Springer.

\bibitem[\protect\citeauthoryear{Baral}{2003}]{baral03}
Baral, C.
\newblock 2003.
\newblock {\em Knowledge Representation, Reasoning and Declarative Problem
  Solving}.
\newblock Cambridge University Press.

\bibitem[\protect\citeauthoryear{Baselice, Bonatti, and
  Gelfond}{2005}]{baboge05a}
Baselice, S.; Bonatti, P.; and Gelfond, M.
\newblock 2005.
\newblock Towards an integration of answer set and constraint solving.
\newblock In {\em Proc. of ICLP'05},  52--66.
\newblock Springer.

\bibitem[\protect\citeauthoryear{Bessi{\`e}re \bgroup et al.\egroup
  }{2009}]{bekanaquwa09a}
Bessi{\`e}re, C.; Katsirelos, G.; Narodytska, N.; Quimper, C.-G.; and Walsh, T.
\newblock 2009.
\newblock Decompositions of all different, global cardinality and related
  constraints.
\newblock In {\em Proc. of IJCAI'09}.
\newblock AAAI Press/The MIT Press.

\bibitem[\protect\citeauthoryear{Bessi{\`e}re, Hebrard, and
  Walsh}{2003}]{behewa03a}
Bessi{\`e}re, C.; Hebrard, E.; and Walsh, T.
\newblock 2003.
\newblock Local consistencies in {SAT}.
\newblock In {\em Proc. of SAT'03},  299--314.
\newblock Springer.

\bibitem[\protect\citeauthoryear{Biere \bgroup et al.\egroup
  }{2009}]{bihemawa09a}
Biere, A.; Heule, M.; {van Maaren}, H.; and Walsh, T., eds.
\newblock 2009.
\newblock {\em Handbook of Satisfiability}.
\newblock IOS Press.

\bibitem[\protect\citeauthoryear{Crawford and Baker}{1994}]{crba94a}
Crawford, J.~M., and Baker, A.~B.
\newblock 1994.
\newblock Experimental results on the application of satisfiability algorithms
  to scheduling problems.
\newblock In {\em Proc. of AAAI'94},  1092--1097.

\bibitem[\protect\citeauthoryear{Dechter and {van Beek}}{1997}]{debe97a}
Dechter, R., and {van Beek}, P.
\newblock 1997.
\newblock Local and global relational consistency.
\newblock {\em Theory of Computer Science} 173(1):283--308.

\bibitem[\protect\citeauthoryear{Dechter}{2003}]{dechter03}
Dechter, R.
\newblock 2003.
\newblock {\em Constraint Processing}.
\newblock Morgan Kaufmann Publishers.

\bibitem[\protect\citeauthoryear{Dovier, Formisano, and
  Pontelli}{2005}]{dofopo05a}
Dovier, A.; Formisano, A.; and Pontelli, E.
\newblock 2005.
\newblock A comparison of {CLP(FD)} and {ASP} solutions to {NP}-complete
  problems.
\newblock In {\em Proc. of ICLP'05},  67--82.
\newblock Springer.

\bibitem[\protect\citeauthoryear{Gebser \bgroup et al.\egroup
  }{2007}]{gekanesc07a}
Gebser, M.; Kaufmann, B.; Neumann, A.; and Schaub, T.
\newblock 2007.
\newblock Conflict-driven answer set solving.
\newblock In {\em Proc. of IJCAI'07},  386--392.
\newblock AAAI Press/The MIT Press.

\bibitem[\protect\citeauthoryear{Gebser, Ostrowski, and
  Schaub}{2009}]{geossc09a}
Gebser, M.; Ostrowski, M.; and Schaub, T.
\newblock 2009.
\newblock Constraint answer set solving.
\newblock In {\em Proc. of ICLP'09},  235--249.
\newblock Springer.

\bibitem[\protect\citeauthoryear{Gent}{2002}]{gent02}
Gent, I.~P.
\newblock 2002.
\newblock Arc consistency in {SAT}.
\newblock In {\em Proc. of ECAI'02},  121--125.
\newblock IOS Press.

\bibitem[\protect\citeauthoryear{Gomes and Selman}{1997}]{gose97a}
Gomes, C.~P., and Selman, B.
\newblock 1997.
\newblock Problem structure in the presence of perturbations.
\newblock In {\em Proc. of AAAI'97},  221--226.
\newblock AAAI Press.

\bibitem[\protect\citeauthoryear{Jaffar and Maher}{1994}]{jama94a}
Jaffar, J., and Maher, M.~J.
\newblock 1994.
\newblock Constraint logic programming: A survey.
\newblock {\em Journal of Logic Programming} 19/20:503--581.

\bibitem[\protect\citeauthoryear{J{\"a}rvisalo \bgroup et al.\egroup
  }{2009}]{jaoijani09a}
J{\"a}rvisalo, M.; Oikarinen, E.; Janhunen, T.; and Niemel{\"a}, I.
\newblock 2009.
\newblock A module-based framework for multi-language constraint modeling.
\newblock In {\em Proc. of LPNMR'09},  155--169.
\newblock Springer.

\bibitem[\protect\citeauthoryear{Leconte}{1996}]{le96a}
Leconte, M.
\newblock 1996.
\newblock A bounds-based reduction scheme for constraints of difference.
\newblock In {\em CP'96, Second International Workshop on Constraint-based
  Reasoning}.

\bibitem[\protect\citeauthoryear{Lee}{2005}]{lee05a}
Lee, J.
\newblock 2005.
\newblock A model-theoretic counterpart of loop formulas.
\newblock In {\em Proc. of IJCAI'05},  503--508.
\newblock Professional Book Center.

\bibitem[\protect\citeauthoryear{Mellarkod and Gelfond}{2008}]{melgel08a}
Mellarkod, V., and Gelfond, M.
\newblock 2008.
\newblock Integrating answer set reasoning with constraint solving techniques.
\newblock In {\em Proc. of FLOPS'08},  15--31.
\newblock Springer.

\bibitem[\protect\citeauthoryear{Mitchell}{2005}]{mitchell05a}
Mitchell, D.
\newblock 2005.
\newblock A {SAT} solver primer.
\newblock {\em Bulletin of the European Association for Theoretical Computer
  Science} 85:112--133.

\bibitem[\protect\citeauthoryear{Niemel{\"a}}{1999}]{niemela99a}
Niemel{\"a}, I.
\newblock 1999.
\newblock Logic programs with stable model semantics as a constraint
  programming paradigm.
\newblock {\em Annals of Mathematics and Artificial Intelligence}
  25(3-4):241--273.

\bibitem[\protect\citeauthoryear{Nieuwenhuis, Oliveras, and
  Tinelli}{2006}]{niolti06a}
Nieuwenhuis, R.; Oliveras, A.; and Tinelli, C.
\newblock 2006.
\newblock Solving {SAT} and {SAT} modulo theories: From an abstract
  {D}avis--{P}utnam--{L}ogemann--{L}oveland procedure to {DPLL(T)}.
\newblock {\em Journal of the ACM} 53(6):937--977.

\bibitem[\protect\citeauthoryear{Petrie and Smith}{2003}]{pesm03a}
Petrie, K.~E., and Smith, B.~M.
\newblock 2003.
\newblock Symmetry breaking in graceful graphs.
\newblock In {\em Proc. of CP'03},  930--934.
\newblock Springer.

\bibitem[\protect\citeauthoryear{Rossi, {van Beek}, and
  Walsh}{2006}]{robewa06a}
Rossi, F.; {van Beek}, P.; and Walsh, T., eds.
\newblock 2006.
\newblock {\em Handbook of Constraint Programming}.
\newblock Elsevier.

\bibitem[\protect\citeauthoryear{Simons, Niemel{\"a}, and
  Soininen}{2002}]{siniso02a}
Simons, P.; Niemel{\"a}, I.; and Soininen, T.
\newblock 2002.
\newblock Extending and implementing the stable model semantics.
\newblock {\em Artificial Intelligence} 138(1-2):181--234.

\bibitem[\protect\citeauthoryear{Walsh}{2000}]{wa00}
Walsh, T.
\newblock 2000.
\newblock {SAT} v {CSP}.
\newblock In {\em Proc. of CP'00},  441--456.
\newblock Springer.

\end{thebibliography}
\end{document} 
