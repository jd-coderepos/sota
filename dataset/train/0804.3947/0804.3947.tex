\documentclass[12pt]{article}
\usepackage{fullpage}
\addtolength{\textheight}{0.8cm}
\usepackage[utf8]{inputenc}
\usepackage{psfrag}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[dvips]{graphicx}
\usepackage{url}
\usepackage{multirow}


\newcommand{\hdelta}{\rot{\hat{\delta}}}
\newcommand{\Bdelta}{\blau{\bar{\delta}}}
\newcommand{\folgt}{\longrightarrow}
\newcommand{\equivalent}{\longleftrightarrow}
\newcommand{\seq}[1]{\left\langle #1\right\rangle}
\newcommand{\seqGilt}[2]{\left\langle #1\gilt #2\right\rangle}
\newcommand{\Id}[1]{\ensuremath{\text{{\sf #1}}}}
\newcommand{\ceil}[1]{\left\lceil #1\right\rceil}
\newcommand{\floor}[1]{\left\lfloor #1\right\rfloor}
\newcommand{\abs}[1]{\left| #1\right|}
\newcommand{\norm}[1]{\left\|#1\right\|}
\newcommand{\enorm}[1]{\norm{#1}_{2}}
\newcommand{\sumnorm}[1]{\norm{#1}_{1}}
\newcommand{\maxnorm}[1]{\norm{#1}_{\infty}}
\newcommand{\xor}{\oplus}
\newcommand{\set}[1]{\left\{ #1\right\}}
\newcommand{\gilt}{:}
\newcommand{\sodass}{\mid}
\newcommand{\setGilt}[2]{\left\{ #1\gilt #2\right\}}
\newcommand{\Def}{:=}
\newcommand{\zvektor}[2]{\left(#1,#2\right)}
\newcommand{\vek}[1]{{\bf#1}}
\newcommand{\vektor}[2]{\left(\begin{smallmatrix}#1\\#2\end{smallmatrix}\right)}
\newcommand{\condition}[1]{\left[#1\right]}
\newcommand{\binomial}[2]{\binom{#1}{#2}}
\newcommand{\even}{\mathrm{even}}
\newcommand{\odd}{\mathrm{odd}}
\newcommand{\mymod}{\,\bmod\,}



\newcommand{\nat}{\mathbb{N}}
\newcommand{\natnull}{\mathbb{N}_{0}}
\newcommand{\natless}[1]{\mathbb{N}_{#1}}
\newcommand{\nplus}{\mathbb{N}_+}
\newcommand{\real}{\mathbb{R}}
\newcommand{\rplus}{\mathbb{R}_+}
\newcommand{\rnneg}{\mathbb{R}_*}
\newcommand{\integer}{\mathbb{Z}}
\newcommand{\intint}[2]{{#1}..{#2}}
\newcommand{\realrange}[2]{\left[#1, #2\right]}
\newcommand{\realrangeo}[2]{\left(#1, #2\right)}
\newcommand{\realrangelo}[2]{\left(#1, #2\right]}
\newcommand{\realrangero}[2]{\left[#1, #2\right)}
\newcommand{\unitrange}[2]{\realrange{0}{1}}
\newcommand{\bool}{\set{0,1}}
\newcommand{\mapping}[2]{{#2}^{#1}}
\newcommand{\powerset}[1]{{\cal P}\left(#1\right)}
\newcommand{\NP}{\ensuremath{\mathbf{NP}}}
\newcommand{\Bild}{\mathbf{Bild}\:}

\newcommand{\withtype}[1]{\in#1}

\newcommand{\prob}[1]{{\mathbb{P}}\left[#1\right]}
\newcommand{\condprob}[2]{{\mathbb{P}}\left(#1\;|\;#2\right)}
\newcommand{\condexpect}[2]{{\mathbb{E}}\left(#1\;|\;#2\right)}
\newcommand{\expect}{{\mathbb{E}}}
\newcommand{\var}{{\mathbb{V}}}
\newcommand{\quant}[2]{\tilde{#1}_{#2}}

\newcommand{\whpO}[1]{\tilde{\mathrm{O}}\left( #1\right)}
\newcommand{\Oschlange}{}
\newcommand{\Ohh}[1]{\mathrm{O}\!\left( #1\right)}
\newcommand{\Oh}[1]{\mathrm{O}\!\left( #1\right)}
\newcommand{\Ohlarge}[1]{\mathrm{O}\!\left( #1\right)}
\newcommand{\Ohsmall}[1]{\mathrm{O}(#1)}
\newcommand{\oh}[1]{\mathrm{o}\!\left( #1\right)}
\newcommand{\Th}[1]{\Theta\!\left( #1\right)}
\newcommand{\Om}[1]{\Omega\left(#1\right)}
\newcommand{\om}[1]{\omega\!\left( #1\right)}
\newcommand{\Oleq}{\preceq}

\newcommand{\lref}[1]{\ref{\labelprefix:#1}}
\newcommand{\llabel}[1]{\label{\labelprefix:#1}}
\newcommand{\labelprefix}{} 

\newcommand{\discussionsize}{\small}
\newenvironment{discussion}{\par\discussionsize}{\par}

\marginparpush2mm
\marginparsep1mm 
\newcommand{\notiz}[1]{}
\newcommand{\frage}[1]{}


\newcommand{\mysubsubsection}[1]{\vspace{2mm}\noindent{\bf #1 }}

\newcommand{\punkt}{\enspace .}

\newenvironment{code}{\noindent \begin{tabbing}\hspace{2em}\=\hspace{2em}\=\hspace{2em}\=\hspace{2em}\=\hspace{2em}\=\hspace{2em}\=\hspace{2em}\=\hspace{2em}\=\hspace{2em}\=\hspace{2em}\=\kill}{\end{tabbing}}

\newcommand{\labelcommand}{}
\newcommand{\captiontext}{}
\newsavebox{\codeparam}
\newcounter{lineNumber}
\newenvironment{disscodepos}[3]{\renewcommand{\labelcommand}{#2}\renewcommand{\captiontext}{#3}\sbox{\codeparam}{\parbox{\textwidth}{#3}}\begin{figure}[#1]\begin{center}\begin{code}\setcounter{lineNumber}{1}}{\end{code}\end{center}\caption{\llabel{\labelcommand}\captiontext}\end{figure}}

\newenvironment{disscode}[2]{\begin{disscodepos}{htb}{#1}{#2}}{\end{disscodepos}}

\newcommand{\codel}[1]{\mbox{\rm "`#1"'}}
\newcommand{\codem}[1]{\mathrm{#1}}

\newcommand{\Assert}{{\bf assert\ }}
\newcommand{\Invariant}{{\bf invariant\ }}
\newcommand{\Old}[1]{{\bf old}\ensuremath{(}#1\ensuremath{)}}
\newcommand{\Class}{{\bf Class\ }}
\newcommand{\Constant}{{\bf Constant\ }}
\newcommand{\Array}{{\bf Array\ }}
\newcommand{\Of}{{\bf of\ }}
\newcommand{\Function} {{\bf Function\ }}
\newcommand{\Funct}[3]{\Function #1\Declare{{\rm (}{#2\rm )}}{#3}}
\newcommand{\TFunct}[2]{\Function #1\Declare{}{#2}}
\newcommand{\Procedure}{{\bf Procedure\ }}
\newcommand{\Operator}{{\bf Operator\ }}
\newcommand{\Type}{{\bf Type\ }}
\newcommand{\Address}{{\bf address of\ }}
\newcommand{\Pointer}{{\bf Pointer\ }}
\newcommand{\Points}{\ensuremath{\rightarrow}}
\newcommand{\Allocate}{{\bf allocate\ }}
\newcommand{\This}{{\bf this\ }}
\newcommand{\Null}{{\bf null\ }}
\newcommand{\Dispose}{{\bf dispose\ }}
\newcommand{\Deallocate}{{\bf dispose\ }}
\newcommand{\Delete}{{\bf dispose\ }}
\newcommand{\Process}{{\bf process\ }}
\newcommand{\While}    {{\bf while\ }}
\newcommand{\Repeat}   {{\bf repeat\ }}
\newcommand{\Until}    {{\bf until\ }}
\newcommand{\Loop}     {{\bf loop\ }}
\newcommand{\Exit}     {{\bf exit\ }}
\newcommand{\Goto}     {{\bf goto\ }}
\newcommand{\Do}       {{\bf do\ }}
\newcommand{\Od}       {{\bf od\ }}
\newcommand{\Dopar}       {{\bf dopar\ }}
\newcommand{\For}      {{\bf for\ }}
\newcommand{\Foreach}      {{\bf foreach\ }}
\newcommand{\Rof}      {{\bf rof\ }}
\newcommand{\Is}{\mbox{\rm := }}
\newcommand{\Forall}      {{\bf forall\ }}
\newcommand{\ForEach}      {{\bf foreach\ }}
\newcommand{\ForFromTo}[3]{{\For  \Is  \To  \Do}}
\newcommand{\ForFromToWhile}[4]{{\For  \Is  \To  \While  \Do}}
\newcommand{\ForFromDowntoWhile}[4]{{\For  \Is  \Downto  \While  \Do}}
\newcommand{\ForFromDownto}[3]{{\For  \Is  \Downto  \Do}}
\newcommand{\ForFromWhile}[3]{{\For  \Is  \To  \While  \Do}}
\newcommand{\ForFromdownWhile}[3]{{\For  \Is  \Downto  \While  \Do}}
\newcommand{\ForFromToStep}[4]{{\For  \Is  \To  \Step   \Do}}
\newcommand{\ForFromDowntoStep}[4]{{\For  \Is  \Downto   \Step  \Do}}
\newcommand{\ForFromStepWhile}[4]{{\For  \Is  \To  \Step   \While  \Do}}
\newcommand{\ForFromdownStepWhile}[4]{{\For  \Is  \Downto  \Step   \While  \Do}}
\newcommand{\To}       {{\bf to\ }}
\newcommand{\Step}       {{\bf step\ }}
\newcommand{\Downto}       {{\bf downto\ }}
\newcommand{\If}       {{\bf if\ }}
\newcommand{\Endif}    {{\bf endif\ }}
\newcommand{\Fi}       {{\bf fi\ }}
\newcommand{\Then}     {{\bf then\ }}
\newcommand{\Else}     {{\bf else\ }}
\newcommand{\Elsif}    {{\bf else if\ }}
\newcommand{\Return}   {{\bf return\ }}
\newcommand{\Set}      {{\bf set\ }}
\newcommand{\Boolean}  {\ensuremath{\set{0,1}}}
\newcommand{\Integer}  {}
\newcommand{\True}     {\mathtt{1}}
\newcommand{\False}    {\mathtt{0}}
\newcommand{\Bitand}   {{\bf bitand\ }}
\newcommand{\Xor}       {\ensuremath{\oplus}}
\newcommand{\Not}       {\ensuremath{\neg}}
\newcommand{\Or}       {\ensuremath{\vee}}
\newcommand{\Div}       {{\bf\ div\ }}
\newcommand{\Mod}       {{\bf\ mod\ }}
\newcommand{\Decrement}  {\ensuremath{\mathbf{-}\mathbf{-}\ }}
\newcommand{\Increment}  {\ensuremath{\mathbf{+}\mathbf{+}\ }}
\newcommand{\End}       {{\bf end\ }}
\newcommand{\Endfor}       {{\bf endfor\ }}
\newcommand{\Rem}[1]   {{\bf //\hspace{0.5mm}{\rm#1}}}
\newcommand{\RRem}[1]   {\`{\bf //\hspace{0.5mm}~}{\rm#1}}
\newcommand{\Flush}[1]   {\`{\bf \hspace{0.5mm}~}{\rm#1}}
\newcommand{\RRemNL}[1]   {\`{\bf (*~ }{\rm#1}{\bf ~*)}{\tiny\arabic{lineNumber}}\stepcounter{lineNumber}}
\newcommand{\Declare}[2]{#1\mbox{ \rm : }#2}
\newcommand{\DeclareInit}[3]{#1#3 \mbox{ \rm : }#2}
\newcommand{\At}[1]{@#1}
\newcommand{\NL}{\`{\tiny\arabic{lineNumber}}\stepcounter{lineNumber}}

\newcommand{\iProc}{i_\mathrm{PE}}

\newcommand{\dissepslong}[5]{\begin{figure}[#1]\begin{center}\epsfxsize#2\leavevmode\epsfbox{#3.eps}\end{center}\caption{\llabel{#4}#5}\end{figure}}

\newcommand{\dissepspos}[4]{\dissepslong{#1}{#2}{\labelprefix/#3}{#3}{#4}}
\newcommand{\disseps}[3]{\dissepspos{htb}{#1}{#2}{#3}}

\newdimen\endofsize\endofsize=0.5em
\def\endofbeweis{~\quad\hglue\hsize minus\hsize
                 \hbox{\vrule height \endofsize width
\endofsize}\par}
\newenvironment{proof}{Proof:}{\endofbeweis}




\newcommand{\invisible}[1]{\setbox0=\hbox{#1}\makebox[\wd0]{\raisebox{0pt}[\ht0][\dp0]{}}}

\newcommand{\Z}[0]{{\mathbb{Z}}}



\newcommand{\R}[0]{{\mathbb{R}}}

\newcommand{\C}[0]{{\mathbb{C}}}

\newcommand{\F}[0]{{\rm\sf F}}

\newcommand{\GL}[0]{{\rm\sf GL}}

\newcommand{\GF}[1]{{\mathbb{F}_{#1}}}

\newcommand{\bigsqcap}[1]{
  \hspace{-1.0em}\raisebox{-1.0ex}{
    \renewcommand{\arraystretch}{0.5}
    \sqcap#1}\!\!}

\newcommand{\combinations}[2]{{\renewcommand{\arraystretch}{0.8}\setlength{\arraycolsep}{0.2em}\left( \begin{array}{c} {#1} \\ {#2} \end{array} \right)}}

\newcommand{\smallexpr}[1]{\mbox{\footnotesize}}

\newcommand{\smallsmallexpr}[1]{\mbox{\scriptsize}}
 \newcommand{\ignore}[1]{}
\renewcommand{\topfraction}{0.99}
\renewcommand{\bottomfraction}{0.99}
\renewcommand{\textfraction}{0.01}
\newcommand{\myparagraph}[1]{\paragraph*{#1}}
\newcommand{\Gup}{G_{\uparrow}}
\newcommand{\Gdown}{G_{\downarrow}}
\newcommand{\Eall}{E^*}
\newcommand{\Eup}{E_{\uparrow}}
\newcommand{\Emarked}{E_{\mathrm{marked}}}
\newcommand{\Edown}{E_{\downarrow}}
\newcommand{\Astar}{}
\newcommand{\psfrage}[1]{\frage{PS:#1}}
\newcommand{\tent}[1]{D[#1]}
\newcommand{\delMin}{\emph{deleteMin}}
\newcommand{\ins}{\emph{insert}}
\newcommand{\decKey}{\emph{decreaseKey}}
\newcommand{\dij}{\textsc{Dijkstra}}
\newcommand{\dijAlg}{\dij's algorithm}
\newcommand{\drk}[2]{\mbox{rk}_{#1}(#2)} \newcommand{\mypath}[1]{\langle #1 \rangle}
\newcommand{\subpath}[3]{#1|_{#2 \rightarrow #3}}
\newcommand{\gd}{\leftrightharpoons} \newcommand{\ld}{\leftarrow} \newcommand{\rd}{\rightarrow} \newcommand{\undir}{\leftrightarrow} \newcommand{\rf}[2]{r^\rd_{#1}(#2)} \newcommand{\rb}[2]{r^\ld_{#1}(#2)} \newcommand{\rg}[2]{r^\gd_{#1}(#2)} \newcommand{\nbhf}[2][\ell]{\mathcal{N}^\rd_{#1}(#2)} \newcommand{\nbhb}[2][\ell]{\mathcal{N}^\ld_{#1}(#2)} \newcommand{\innf}[3][\ell]{#2 \in \nbhf[#1]{#3}} \newcommand{\innb}[3][\ell]{#2 \in \nbhb[#1]{#3}} \newcommand{\ninnf}[3][\ell]{#2 \not \in \nbhf[#1]{#3}} \newcommand{\ninnb}[3][\ell]{#2 \not \in \nbhb[#1]{#3}} \newcommand{\hg}[1]{G_{#1}} \newcommand{\chg}[1]{\hg{#1}'} \newcommand{\fw}[1]{\overrightarrow{#1}} \newcommand{\bw}[1]{\overleftarrow{#1}} \newcommand{\fbw}[1]{\stackrel{\gd}{#1}} \newcommand{\fwpq}{\fw{Q}} \newcommand{\bwpq}{\bw{Q}} \newcommand{\fbwpq}{\fbw{Q}} \newcommand{\gap}{\mbox{gap}} \newcommand{\lnf}[3]{\fw{\omega}_{#1}^{#2}(#3)} \newcommand{\lnb}[3]{\bw{\omega}_{#1}^{#2}(#3)} \newcommand{\fcf}[3]{\fw{\alpha}_{#1}^{#2}(#3)} \newcommand{\fcb}[3]{\bw{\alpha}_{#1}^{#2}(#3)} \newcommand{\snbs}[2][\ell]{\mathcal{SN}_{#1}(#2)} \newcommand{\scns}[2][\ell]{\mathcal{SC}_{#1}(#2)} \newcommand{\rl}[1]{\overline{\ell\,}(#1)} \newcommand{\crl}[1]{\underline{\ell\,}(#1)} \newcommand{\prl}[2]{\ell'(#1,#2)} \newcommand{\slack}[2][]{\Delta_{#1}(#2)}
\newcommand{\tslack}[1]{\widehat{\Delta}(#1)}
\newcommand{\ou}{\overline{u}}
\newcommand{\ov}{\overline{v}}
\newcommand{\ox}{\overline{x}}
\newcommand{\oy}{\overline{y}}
\newcommand{\df}[3][\ell]{d_{#1}(#2,#3)} \newcommand{\db}[3][\ell]{d^{\ld}_{#1}(#2,#3)} \newcommand{\du}[3][\ell]{d^{\undir}_{#1}(#2,#3)} \newcommand{\indeg}[1]{\deg_{\mbox{\small in}}(#1)}
\newcommand{\outdeg}[1]{\deg_{\mbox{\small out}}(#1)}
\newcommand{\twdeg}[1]{\deg_{\undir}(#1)} \newcommand{\fl}[1]{\fw{s_{#1}}} \newcommand{\flp}[1]{\fw{s_{#1}}'} \newcommand{\bl}[1]{\bw{t_{#1}}} \newcommand{\blp}[1]{\bw{t_{#1}}'} \newcommand{\strongf}[3][\ell]{#2\blacktriangleright_{#1}#3} \newcommand{\concat}{\mathbf{*}} \newcommand{\sptf}[2]{\fw{\mathcal{P}}(#1,#2)} \newcommand{\sptb}[2]{\bw{\mathcal{P}}(#1,#2)} \newcommand{\dsucc}[2]{\mathrm{succ}(#1,#2)} \newcommand{\dpred}[2]{\mathrm{pred}(#1,#2)} 

\newcommand{\nbh}[2][]{\mathcal{N}_{#1}(#2)}
\newcommand{\nbhbar}[2][]{OBSOLETE~\bar \mathcal{N}_{#1}(#2)}
\newcommand{\hgf}{OBSOLETE~\hg{1}} \newcommand{\chgf}{OBSOLETE~\chg{1}} \newcommand{\ninn}[2]{OBSOLETE~#1 \not \in \nbh{#2}} \newcommand{\inn}[2]{OBSOLETE~#1 \in \nbh{#2}} \newcommand{\hhname}{HH}
\newcommand{\hhd}{HHD}
\newcommand{\localS}{F}
\newcommand{\entrance}{f}
\newcommand{\Dijkstra}{\mathrm{Dijkstra}}
\newcommand{\Transit}{\mathcal{T}}
\newcommand{\Access}{A}
\newcommand{\Local}{L}
\newtheorem{theorem}{Theorem}



\title{Time Dependent Contraction Hierarchies\\ --- Basic Algorithmic Ideas\thanks{Partially supported by
DFG grant SA 933/4-1 and a Google Research Award}}
\author{Veit Batz, Robert Geisberger and Peter Sanders\\\normalsize
Universit\"at Karlsruhe (TH), 76128 Karlsruhe, Germany\\\normalsize {\tt
\{batz,robert.geisberger,sanders\}@ira.uka.de}}
\begin{document}

\maketitle


\begin{abstract}
Contraction hierarchies are a simple hierarchical routing technique
that has proved extremely efficient for static road networks.
We explain how to generalize them to networks with time-dependent edge weights.
This is the first hierarchical speedup technique for time-dependent routing that
allows bidirectional query algorithms.
\end{abstract}

\section{Introduction}

This technical note explains how contraction hierarchies (CHs) can be
generalized to allow time-dependent edge weights. 
We assume familiarity with CHs
\cite{GSS08b,Gei08}. Like many of the most successful speedup techniques for
routing in road networks, the CH query-algorithm uses
\emph{bidirectional} search.  This is a challenge since bidirectional
searching in a time-dependent network requires knowing the arrival
time\footnote{Wlog we assume that a query specifies source,
destination and departure time.} which is what we want to compute in
the first place.



Due to the difficulty of bidirectional routing, the first promising
approaches to fast routing used goal directed rather than hierarchical
routing and accepted suboptimal routes \cite{NDLS08}.  SHARC routing \cite{BD08}
was specifically developed to encode hierarchical information into a
goal-directed framework allowing unidirectional search and recently
was generalized to exact time-dependent routing \cite{Del08}.
Schultes \cite{Sch08} gives a way to make queries in static
networks unidirectional but this approach does not directly yield 
a time-dependent approach.

\section{Preliminaries}\label{s:preliminaries}

There are classical results on time-dependent route planning
\cite{CH66}  that show that a simple generalization of Dijkstra's
unidirectional algorithm works for time-dependent networks  if the
objective function is travel time and a cost function
 has the \emph{FIFO-property}:
, i.e., there is no
overtaking. We focus on this case and further assume that the travel
time functions are representable by a piece-wise linear
function. However, all our algorithms view travel-time functions (TTFs) as an
abstract data type with a small number of operations, basically
evaluation, chaining (operation  computes a time-dependent function for a sequence of edges) and minimum computations. Also note, that the
format used in public transportation with lists of departure times and
arrival times can also be represented in this way.
The basic primitives can be implemented in such a way that evaluation
at a point in time takes logarithmic time\footnote{Actually our implementation uses a bucketing heuristics that takes constant time on average.} 
and the other operations take
time linear in the number of line segments representing the inputs.


It seems that any exact time-dependent preprocessing technique needs a
basic ingredient that computes travel times not only for a point in
time a travel time \emph{profile}
but for an entire \emph{time-interval}.  An easy way to implement
this profile queury a generalization of Dijkstra's algorithm to profiles \cite{KS93}.
Tentative distances then become TTFs. Adding edge weights is replaced
by chaining TTFs and taking the minimum takes the minimum of
TTFs. Unfortunately, the algorithm looses its label-setting
property. However, the performance as a label-correcting algorithm
seems to be good in important practical cases.\frage{refs to refinements?}
 


\section{Construction}\label{s:construction}

The most expensive preprocessing phase of static CHs orders the nodes by importance.
For a first version we propose to adopt the \emph{static} algorithm for
the time-dependent CHs (TCHs).
This is based on the assumption that averaged over the planning
period, the importance of a node is not heavily affected by its
exact traffic pattern. 

The second stage of CH-preprocessing -- contraction -- is in principle
easy to adapt to time-dependence: we \emph{contract} the nodes of the
graph in the order computed previously. When contracting node , we are given a current (time-dependent) overlay graph
. For every combination of incoming edge  and
outgoing edge  we have to decide whether the path
 may be a shortest path at any point in time.  If so, we
have to insert the shortcut  into the next overlay graph
. The weight function of this shortcut can be computed
by chaining the weight functions of its constituents.
Later, we only need to consider shortcuts during time intervals when they
may represent a shortest path.\footnote{Although this can be viewed as a violation of
the FIFO-property, we do not get a problem when appliying time-dependent Dijkstra --
it never makes sense to wait for a shortcut to become valid since
this would not result in a shortest connection.}
The
required information can be computed by running profile-Dijkstra from
each node  with . The shortcut is needed for  if
 at any point in time.


\section{Query}\label{s:query}

The basic static query algorithm for CHs consists of a forward search in
an upward graph  and a backward search in a downward graph .
Wherever, these searches meet, we have a candidate for a shortest path.
The shortest such candidate is a shortest path.

Since the departure time is known, the forward search is easy to
generalize. In particular, the only overhead compared to the static case
is that we have to evaluate each relaxed edge for one point in time.
In our experience with a plain time-dependent Dijkstra, this means
a small constant factor overhead in practice.

The most easy way to adapt the backward search is to explore
\emph{all} nodes that can \emph{reach}  in .
Experiments for static CHs \cite{Gei08} indicate that
this search space is only a small constant factor larger than
the search space that takes edge weights into account.
During this exploration we mark all edges connecting nodes that
can reach . Let  denote the set of marked edges.

Now, we can perform an ---query by a forward search from  in
. 

\begin{theorem}
The above algorithm is correct.
\end{theorem}
\begin{proof}(Outline)
This immediately follows from the properties of TCHs.
The detailed proof is analogous to the proof in \cite{Gei08}. 
Roughly, the properties of TCHs imply that there
must be a shortest path  in the TCH that consists of two segments:
One using only eges in  leading to a peak node  and
one connecting  to  in . Since all edges of  are
in the search space of our forward search, this path or some other
shortest path will be found.  
\end{proof}



\section{Refinements}\label{ss:crefinements}

\subsection{Node Ordering}\label{ss:orefinements}

Note that there are many ways to adapt the
node ordering to take time-dependence into account without resorting
to full-fledged time-dependent processing. For example, we can take
the average travel time of an edge or look at a sample of departure times
and base our priority for node-ordering on the entire sample.

\subsection{Contraction}\label{ss:crefinements}

The main difficulty in constructing TCHs is that 
the the complexities of time-dependent edge weights and
tentative distances grows with progressive contraction
and with the diameter of the profile-Dijkstra searches.
One way to counter this is to use approximations.
With some care, this can be done without compromising 
the exactness of queries.
In particular, we propose to compute piece-wise linear
approximations that are always within a factor  from the
true travel time.

First, during a local search, we can replace tentative distances with less complex
upper bounds on the tentative distance.
The worst that can happen is that we introduce additional shortcuts.
The hope is that for sufficiently good approximations of the true
tentative distance, the number of superfluous shortcuts will be small.
The intuition behind this is that if traffic changes the shortest path at all,
it is unlikely that the travel time difference is tiny.  

For shortcuts that are actually introduced, we compute both upper and lower bounds.
For comparing a shortcut  with a witness , we compare a lower bound for  
with an upper bound for . 
Once the (approximate) TCH is computed, we have a choice whether we 
want to condense it into an exact TCH (i.e., for all shortcuts
introduced, we compute there exact edge cost functions)
or we later modify the query to compute exact shortest paths using
approximate TCHs (ATCH). Note that
the complexity of the functions affects the space requirements but
has little influence on the cost of evaluation and thus on the query time.


\subsection{Query}\label{ss:qrefinements}

We can prune the forward search by marking all nodes  in the 
backward search space with a lower bound  on the travel time to .
Note that this information can be gathered with a static Dijkstra algorithm
that is likely to be faster than time-dependent Dijkstra.
Furthermore, we compute an upper bound  for the travel time from  to 
using any static routing technique, unpacking of the statically optimal path ,
and time-dependent evaluation of .
Now, during forward search, if  we do not need to continue
the search. 

There are various ways to compute better upper and lower bounds.
Assume we have computed a lower bound  on the total travel time
using search in a static graph. Using ,  and the departure time,
we know a time window  for the arrival time.
For computing the lower bounds  we can then perform 
a variation of Dijkstras algorithm that computes minimum
travel times over a time interval. If the time interval is small,
this might be fast.

\paragraph*{Exact Routing in ATCHs (Outline)}
We modify our query algorithm to compute a graph that contains all edges
that \emph{might} be in the shortest path tree using upper and lower bounds
in a conservative way. Then, using the pruning techniques from above,
we remove all parts of this graph that cannot be part of a shortest path
from  to  at a given departure time. 
Then, we unpack all surviving edges. Hopefully, the resulting
graph will mostly consist of a small number of partially overlapping
paths from  to .
Finally,
we perform an exact forward search from  in the unpacked graph.



\section{Conclusions}\label{s:conclusions}

We have developed algorithmic ideas for time dependent routing using CHs.
Now experiments have to show whether already the most basic approach
or some of its refinements yields a good exact query algorithm for road networks
or public transportation.
If problems show up, it is likely that the density of the graph or
the complexity of shortcuts gets out of hands in the later stages
of contraction. From the experience with static routing
\cite{BDSSSW08}, it is likely that such problems could be mitigated using
a combination with goal directed techniques, e.g., arc-flags. 
Again from \cite{BDSSSW08} it could be expected that at least this 
combination will outperform SHARC \cite{Del08}.

For commercial applications, approximate queries are not a big problem.
In this case, many simplifications suggest themselves where we 
can simply use approximations of time dependent functions
that are neither upper nor lower bounds and where we only introduce
shortcuts that bring significant improvements. 



\bibliographystyle{splncs}
\bibliography{hwy}
\end{document}
