\section{Experiments}
We evaluated our proposed STraTS model against state-of-the-art baselines on two real-world EHR databases for the mortality prediction task. This section starts with a description of the datasets and baselines, followed by a discussion of results focusing on generalization and interpretability.
\begin{table}
\centering
    \caption{Basic statistics of the two datasets used in our experiemnts. Note that the Avg. variable missing rate and Avg. \# observations/stay are calculated using only the supervised samples.}
    \label{tab:dataset_stats}
    \begin{tabular}{lcc}
    \toprule
    &MIMIC-III &PhysioNet-2012 \\
    \midrule
     \# ICU stays &52,871 &11,988 \\
     \# ICU stays (supervised) &44,812 &11,988 \\
     \# Avg. span of time-series &101.9h &47.3h \\
     \# Avg. span of time-sries (supervised) &23.5h &47.3h\\
      \# Variables &129 &37\\
      Avg. variable missing rate &89.7\% &79.7\%  \\
      Avg. \# observations/stay &401 &436\\
      Demographics &Age, Gender &Age, Gender, Height, ICU Type \\
      Task &24-hour mortality &48-hour mortality \\
      \% positive class &9.7\% &14.2\% \\
      \bottomrule
    \end{tabular}
\end{table}
\label{sec:exp}
\subsection{Datasets}
We experiment with time-series extracted from two real-world EHR datasets which are described below. 
The dataset statistics are summarized in Table \ref{tab:dataset_stats}.  \\ \\
\noindent
\textbf{MIMIC-III} \citep{mimiciii}: This is a publicly available database containing medical records of about  critical care patients in Beth Israel Deaconess Medical Center between 2001 and 2012. We filtered ICU stays to include only adult patients and extracted   features from the following tables: input events, output events, lab events, chart events, and prescriptions for each ICU stay. For mortality prediction task, we only include ICU stays that lasted for atleast one day with the patient alive at the end of first day, and predict in-hospital mortality using the first  hours of data. For forecasting, the set of observation windows is defined (in hours) as  and the prediction window is the -hour period following the observation window. Note that we only consider those samples which have atleast one time-series measurement in both observation and prediction windows. The data is split at patient level into training, validation, and test sets in the ratio .
\\ 


\noindent
\textbf{PhysioNet Challenge 2012} \citep{goldberger2000physiobank}: This processed dataset from Physionet Challenge 2012 \footnote{\url{https://physionet.org/content/challenge-2012/1.0.0/}} contains records of   ICU stays of adult patients. 
The target task aims to predict in-hospital mortality given the first  hours of data for each ICU stay. Since demographic variables `gender' and `height' are not available for all ICU stays, we perform mean imputation and add missingness indicators for them as additional demographic variables.
To generate inputs and outputs for forecasting, the set of observation windows is defined (in hours) as  and the prediction window is the -hour period following the observation window. The data from set-b and set-c together is split into training and validation (80:20) while set-a is used for testing.






\begin{comment}
\begin{table*}[!ht]
    \centering
    \begin{tabular}{|l|ccc|ccc|}
    \hline
    &\multicolumn{3}{c|}{MIMIC-III}
    &\multicolumn{3}{c|}{PhysioNet-2012}  \\
     \cline{2-7}
       &ROC-AUC &PR-AUC &min(Re,Pr) &ROC-AUC &PR-AUC &min(Re,Pr)\\
      \hline
      RF & & & & & & \\
      GRU-simple & & & & & & \\
      TCN & & & & & &   \\
      SAnD & & & & & & \\
      GRU-D & & & & & & \\
      InterpNet & & & 
      & & & \\
      SeFT & & & & & & \\
      \hline
      STraTS & & & & & &  \\
      STraTS & & & & & &  \\
STraTS & & & & & &\\
      STraTS & & & & & &  \\
      \hline
    \end{tabular}
    \caption{Mortality prediction performance on MIMIC-III and PhysioNet-2012 datasets.}
    \label{tab:pred_mor}
\end{table*}
\end{comment}










\subsection{Baseline Methods} 
To demonstrate the effectiveness of STraTS over the state-of-the-art methods, 
we compare it with the following baseline models.
\begin{itemize}
\item \textbf{Gated Recurrent Unit (GRU)} \citep{chung2014empirical}: The input is a time-series matrix with hourly aggregation where missing variables are mean-imputed. Binary missingness indicators and time since the last observation of each variable are also included as additional features at each time step. The final hidden state is transformed by a dense layer to generate output.
\item \textbf{Temporal Convolutional Network (TCN)} \citep{bai2018empirical}: This model takes the same input as GRU which is passed through a stack of temporal convolution layers with residual connections. The representation from the last time step of the last layer is transformed by a dense layer to generate output.
    \item \textbf{Simply Attend and Diagnose (SaND)} \citep{song2018attend}: This model also has the same input representation as GRU and the input is passed through a Transformer with causal attention and a dense interpolation layer.
    \item \textbf{GRU with trainable Decays (GRU-D)} \citep{che2018recurrent}: The GRU-D cell takes a vector of variable values at each time one or more measurements are seen. The GRU-D cell, which is a modification to the GRU cell, decays unobserved values in this vector to global mean values and also adjusts the hidden state according to elapsed times since the last observation of each variable.
    \item \textbf{Interpolation-prediction Network (InterpNet)} \citep{shukla2019interpolation}: This model consists of a semi-parametric interpolation network that interpolates all variables at regular predefined time points,
    followed by a prediction network which is a GRU. It also uses a reconstruction loss to enhance the interpolation network. The input representation is similar to that of GRU-D and therefore, no aggregation is performed.
    \item \textbf{Set Functions for Time Series (SeFT)} \citep{horn2020set}: This model also inputs a set of observation triplets, similar to STraTS. It uses sinusoidal encodings to embed times and the deep network used to combine the observation embeddings is formulated as a set function using a simpler but faster variation of multi-head attention.
\end{itemize}
For all the baselines, we use two dense layers to get the demographics encoding and concatenate it to the time-series representation before the last dense layer. All the baselines use sigmoid activation at the last dense layer for mortality prediction. The time-series measurements (by variable) and demographics vectors are normalized to have zero mean and unit variance. All models are trained using the Adam optimizer \citep{kingma2014adam}.

\subsection{Evaluation Metrics}
The following metrics are used to quantitatively compare the baselines and proposed models for the binary classification task of mortality prediction. (i) ROC-AUC: Area under ROC curve. (ii) PR-AUC: Area under precision-recall curve. (iii) min(Re, Pr): This metric is computed as the maximum of ‘minimum of recall and precision’ across all thresholds.


\begin{table}[h]
\small
    \caption{Hyperparameters used for our experiments in this paper.}
    \begin{tabular}{p{2cm}@{\hskip 1cm}p{4.5cm}@{\hskip 1cm}p{4.5cm}}
    \toprule
    Model &MIMIC-III &PhysioNet-2012  \\
    \midrule
    GRU  &units=50, rec d/o=0.2, output d/o=0.2, lr=0.0001 &units=43, rec d/o=0.2, output d/o=0.2, lr=0.0001\\ 
    \hline
TCN &layers=4, filters=128, kernel size=4, d/o=0.1, lr=0.0001 &layers=6, filters=64, kernel size=4, d/o=0.1, lr=0.0005\\
    \hline
    SAnD &N=4, r=24, M=12, d/o=0.3, d=64, h=2, he=8, lr=0.0005 &N=4, r=24, M=12, d/o=0.3, d=64, h=2, he=8, lr=0.0005\\
    \hline
    GRU-D  &units=60, rec d/o=0.2, output d/o=0.2, lr=0.0001 &units=49  rec d/o=0.2, output d/o=0.2, lr=0.0001\\ 
    \hline
    SeFT & \RaggedRight lr=0.001, n\_phi\_layers=4, phi\_width=128, phi\_dropout=0.2,
n\_psi\_layers=2, psi\_width=64, psi\_latent\_width=128, dot\_prod\_dim=128,
n\_heads=4, attn\_dropout=0.5, latent\_width=32,
n\_rho\_layers=2, rho\_width=512, rho\_dropout=0.0,
max\_timescale=100.0,
n\_positional\_dims=4 
& \RaggedRight lr=0.00081, n\_phi\_layers=4, phi\_width=128, phi\_dropout=0.2,
n\_psi\_layers=2, psi\_width=64, psi\_latent\_width=128, dot\_prod\_dim=128,
n\_heads=4, attn\_dropout=0.5, latent\_width=32,
n\_rho\_layers=2, rho\_width=512, rho\_dropout=0.0,
max\_timescale=100.0,
n\_positional\_dims=4
\\
    \hline
    InterpNet &ref\_points=96, units=100, input d/o=0.2, rec d/o=0.2, lr=0.001 &ref\_points=192, units=100, input d/o=0.2, rec d/o=0.2, lr=0.001\\
    \hline
    STraTS(ss-) \& I-STraTS(ss-) &d=32, M=2, h=4, d/o=0.2, lr=0.0005 &d=32, M=2, h=4, d/o=0.2, lr=0.001\\
    \hline
    STraTS \& I-STraTS &d=50, M=2, h=4, d/o=0.2, lr=0.0005 &d=50, M=2, h=4, d/o=0.2, lr=0.0005\\
    \bottomrule
    \end{tabular}
    \label{tab:hyper}
\end{table}


\subsection{Implementation Details}
Table \ref{tab:hyper} lists the hyperparameters  used in the experiments for all models for MIMIC-III and PhysioNet-2012 datasets.
All models are trained using a batch size of  with Adam optimizer and training is stopped when sum of ROC-AUC and PR-AUC does not improve for  epochs. 
For pretraining phase using the self-supervision task, the patience is set to  epochs and epoch size is set to  samples.
For MIMIC-III dataset, we set the maximum number of time-steps for GRU-D and InterpNet, and the maximum no. of observations for STraTS using the  percentile for the same. This is done to avoid memory overflow with batch gradient descent.
The deep models are implemented using keras with tensorflow backend. 
For InterpNet, we adapted the official code from \url{https://github.com/mlds-lab/interp-net}. For GRU-D and SeFT, we borrowed implementations from \url{https://github.com/BorgwardtLab/Set_Functions_for_Time_Series}.
The experiments are conducted on a single NVIDIA GRID P40-12Q GPU. Our implementation and data-processing codes for STraTS are available at \url{https://github.com/sindhura97/STraTS}. 





\begin{comment}
\begin{table}[h!]
    \centering
    \begin{tabular}{|l|cc|}
      \hline
       &macro ROC-AUC &micro ROC-AUC\\
      \hline
      RF & & \\
      GRU & &\\
      GRU-D & &\\
      TCN & & \\
      InterpNet & & \\
      \hline
      STraTS  & & \\
      STraTS & & \\
      STraTS & & \\
      STraTS & &\\
      \hline
    \end{tabular}
    \caption{Phenotype classification performance on MIMIC-III dataset.}
    \label{tab:pred_phen}
\end{table}
\end{comment}

\begin{table}[]
\centering
    \caption{Mortality prediction performance on MIMIC-III and PhysioNet-2012 datasets. The results show mean and standard deviation of the metrics after repeating the experiment  times by sampling  labeled data each time.}
    \label{tab:pred_perf}
    \begin{tabular}{llccc}
    \toprule
    & &ROC-AUC &PR-AUC &min(Re,Pr) \\
    \midrule
    \multirow{7}{*}{MIMIC-III}
    &GRU & & &\\
&TCN & & &\\
    &SAnD & & &\\
    &GRU-D & & &\\
    &InterpNet & & &\\
    &SeFT & & &\\
    &STraTS & & &\\
    \hline
    \multirow{7}{*}{PhysioNet-2012}
    &GRU & & &\\
    
    &TCN & & &\\
    &SAnD & & &\\
    &GRU-D & & &\\
    &InterpNet & & &\\
    &SeFT & & &\\
    &STraTS & & &\\
    \bottomrule
    \end{tabular}
\end{table}


\begin{figure}
    \centering
    \includegraphics[scale=0.415, trim={0.4cm 0 0 0} ]{gen_mimic_mortality.png}
    \caption{Mortality prediction performance on MIMIC-III dataset for different percentages of labeled data averaged over  runs.}
    \label{fig:gen_mimic_mort}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[scale=0.55, trim={0.5cm 0 0 0} ]{gen_physionet_mortality2.png}
    \caption{Mortality prediction performance on PhysioNet-2012 dataset for different percentages of labeled data averaged over  runs.}
    \label{fig:gen_phy_mort}
\end{figure}

\subsection{Prediction Performance}
We train each model using  different random samplings of  labeled data from the train and validation sets. Note that STraTS uses the entire labeled data and additional unlabeled data (if available) for self-supervision. 
Table \ref{tab:pred_perf} shows the results for mortality prediction on MIMIC-III and PhysioNet-2012 datasets which are averaged over the  runs. 
STraTS achieves the best performance on all metrics, improving PR-AUC by  and  on MIMIC-III and PhysioNet-2012 datasets over the best baseline,  respectively. This shows that our design choices of triplet embedding, attention-based architecture, and self-supervision enable STraTS to learn better representations.
We expected the interpolation-based models GRU-D and InterpNet to outperform the simpler models GRU, TCN, and SaND. This was true for all cases except that GRU showed a better performance than GRU-D and InterpNet on the MIMIC-III dataset, for reasons that are unclear.


To test the generalization ability of different models, we evaluate STraTS and the baseline models by training them on varying percentages of labeled data. Lower proportions of labeled data can be observed in real-world when there are several right-censored samples.
Figures \ref{fig:gen_mimic_mort} and \ref{fig:gen_phy_mort} show the results for MIMIC-III and PhysioNet-2012 datasets, respectively. The performance of all models degrades with reduced amount of labeled data. But STraTS is seen to have a crucial advantage compared to other models in scarce labeled data settings which can be attributed to self-supervision.


\subsection{Ablation Study}
We compared the predictive performance of STraTs and I-STraTS, with and without self-supervision and the results are reported in Table \ref{tab:ablation}. `ss+' and `ss-' are used to refer to models trained with and without self-supervision, respectively. We observe that (i) Adding interpretability to STraTS slightly reduces the prediction scores as a result of constraining model representations. (ii) Adding self-supervision improves performance of both STraTS and I-STraTS. (iii) I-STraTS(ss+) outperforms STraTS(ss-) on all metrics on MIMIC-III dataset, and on the PR-AUC metric for PhysioNet-2012 dataset. This demonstrates that the performance drop from introducing interpretability can be compensated by the performance improvements obtained through self-supervision. 
\begin{table}[]
\centering
    \caption{Ablation Study: comparing mortality prediction performance of STraTS and I-STraTS with and without self-supervision. (`ss+' and `ss-' are used to indicate models trained with and without self-supervision, respectively.)}
    \label{tab:ablation}
    \begin{tabular}{llccc}
    \toprule
    & &ROC-AUC &PR-AUC &min(Re,Pr) \\
    \midrule
    \multirow{4}{*}{MIMIC-III}
    &I-STraTS (ss-) &&&\\    
    &I-STraTS (ss+) &&&\\
    &STraTS (ss-)      &&&\\ 
    &STraTS (ss+) &&&\\
    \hline
    \multirow{4}{*}{PhysioNet-2012}
    &I-STraTS (ss-) &&&\\
    &I-STraTS (ss+) &&&\\
    &STraTS (ss-)  &&&\\
    &STraTS (ss+)  &&&\\
    \bottomrule
    \end{tabular}
\end{table}

\subsection{Interpretability}
To illustrate how I-STraTS explains its predictions, we present a case study for an  year old female patient from the MIMIC-III dataset who expired on the  day after ICU admission. The I-STraTS model predicts the probability of her in-hospital mortality as  using only the data collected on the first day. The patient had  measurements corresponding to  time-series variables. The top  variables ordered by their average `contribution score' along with the range (for multiple observations)  or value (for only one observation) are shown in Table \ref{tab:interp}. In addition to old age, we can also observe that I-STraTS considers the abnormal values of Lactate, LDH, Platelet count, and RDW as the most important factors in predicting that the patient is at high risk of mortality. The discharge summary for this patient indicates PEA arrest as the cause of death. Elevated Lactate and LDH levels as seen in this case are known to be associated with cardiac arrest \citep{dell2017prognostic, farhana2021biochemistry}.
Such predictions can not only guide the care givers in identifying high-risk patients for better resource allocation but also guide the clinicians into understanding the contributing factors and make better diagnoses and treatment choices, especially at the early stages of treatment before the condition becomes more severe and uncontrollable.

To obtain a more fine-grained intuition, the observed time-series for some variables in this ICU stay are plotted in Figure \ref{fig:interp} along with the corresponding contribution scores. It is interesting to see that the contribution scores appear to be positively or negatively correlated with the underlying values or time for several variables. For example, the model gives more weight to higher values of Lactate and LDH that are linked to cardiac arrest which is the patient's cause of death. Similarly, the model pays more attention to increased blood glucose of  mg/dL. As GCS-verbal remains at a constant low of , the model gives it more and more weight as time progresses. 


\begin{table}[]
\centering
\caption{Case study: Top 5 variables ordered by `average contribution score' obtained from I-STraTS model for an ICU stay from MIMIC-III dataset.}
\label{tab:interp}
\begin{tabular}{lcc}
\toprule
Variable &Range/Value &`avg. contribution score' \\
\midrule
Age &85 &0.458 \\
Lactate &[1.7, 6.4] mmol/L &0.175 \\
LDH &[275, 306] IU/L &0.115 \\
Platelet Count &[127, 132] K/uL &0.100 \\
RDW &[22.0-22.1]\% &0.083 \\
\bottomrule
    \end{tabular}
\end{table}

\begin{figure}
    \centering
    \includegraphics[scale=0.37]{download.png}
    \caption{Case study: An illustration of a few time-series with contribution scores for a patient from MIMIC-III dataset.}
    \label{fig:interp}
\end{figure}
