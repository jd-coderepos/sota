\section{Proofs}\label{app:proof}
We first summarize the notations and assumptions used in our theorems.
\paragraph{Notations} 
The drift and diffusion coefficients of the SDE in \cref{eq:sde} are denoted as  and  respectively, where  represents a fixed time horizon, and  denotes the Cartesian product. The solution to \cref{eq:sde} is a stochastic process . We use  to represent the marginal distribution of , and  to denote the transition distribution from  to . The data distribution and prior distribution are given by  and . We use  to denote all continuous functions, and let  denote the family of functions with continuous -th order derivatives. For any vector-valued function , we use  to represent its divergence with respect to the first input variable.
\paragraph{Assumptions}
We make the following assumptions throughout the paper:
\begin{enumerate}[label=(\roman*)]
    \item  and .
    \item  and .
    \item , .
    \item .
    \item  and .
    \item For any open bounded set , .
    \item .
    \item .
    \item .
    \item .
    \item Novikov's condition: .
    \item  as .
\end{enumerate}
Below we provide all proofs for our theorems.
\bound*
\begin{proof}
We denote the path measure of  and  as  and  respectively. Due to assumptions (i) (ii) (iii) (iv) (v) (ix) and (x), both  and  are uniquely given by the corresponding SDEs. Consider a Markov kernel . Since  and , we have the following result

Here the Markov kernel  essentially performs marginalization of path measures to obtain ``sliced'' distributions at . We can use the data processing inequality with this Markov kernel to obtain

Recall that by definition  and . Leveraging the chain rule of KL divergences (see, for example, Theorem 2.4 in \cite{leonard2014some}), we have

Under assumptions (i) (iii) (iv) (v) (vi) (vii) (viii), the SDE in \cref{eq:sde} has a corresponding reverse-time SDE given by

Since \cref{eqn:reverse_sde_proof} is the time reversal of \cref{eq:sde}, it induces the same path measure . As a result,  can be viewed as the KL divergence between the path measures induced by the following two (reverse-time) SDEs:

The KL divergence between two SDEs with shared diffusion coefficients and starting points exists under assumptions (vii) (viii) (ix) (x) (xi) (see, \eg, \cite{tzen-NeuralStochasticDifferential-2019a,li-ScalableGradientsStochastic-2020}), and can be computed via the Girsanov theorem~\cite{oksendal2013stochastic}:

where (i) is due to Girsanov Theorem II~\cite[Theorem 8.6.6]{oksendal2013stochastic}, and (ii) is due to the martingale property of It\^{o} integrals.
Combining \cref{eqn:data_processing,eqn:chain_rule,eqn:girsanov} completes the proof.
\end{proof}

\thm*
\begin{proof}
When  and , the reverse-time SDE that defines , \ie,

becomes equivalent to

which yields the same stochastic process as the following forward-time SDE

Since  by definition, we immediately have . Similarly, the ODE that defines  is

which is equivalent to the following when  and ,

The theory of probability flow ODEs~\cite{song2020score} guarantees that \cref{eqn:q_sde} and \cref{eqn:q_ode} share the same set of marginal distributions, , which implies that . Since by definition , we have .

The next part of the theorem can be proved by first rewriting the KL divergence from  to  in an integral form:

where (i) holds due to our definition  and ; (ii) is due to the fundamental theorem of calculus.

Next, we show how to rewrite \cref{eqn:int} as a mixture of score matching losses. 
The Fokker--Planck equation for the SDE in \cref{eq:sde} describes the time-evolution of the stochastic process's associated probability density function, and is given by

where for simplified notations we define . Similarly, . Since we assume  and  are smooth functions with at most polynomial growth at infinity (assumption (xii)), we have  and  for all . Then, the time-derivative of  can be rewritten in the following way:


where (i) is due to integration by parts. Combining with \cref{eqn:int}, we can conclude that

Since  and , we also have

which completes the proof.
\end{proof}



Using a similar technique to \cref{thm:1}, we can express the entropy of a distribution in terms of a time-dependent score function, as detailed in the following theorem.
\begin{theorem}\label{thm:entropy}
Let  be the differential entropy of the initial probability density . Under the same conditions in \cref{thm:1}, we have

\end{theorem}
\begin{proof}
Once more we proceed analogously to the proofs of \cref{thm:1}.
We have

Expanding the integrand, we have

where again (i) follows from integration by parts and the limiting behaviour of  given by assumption (xii).
Plugging this expression in for the integrand in \cref{eqn:thm3-entropy-integral} then completes the proof for \cref{eqn:entropy1}. For \cref{eqn:entropy}, we can once again perform integration by parts and leverage the limiting behavior of  in assumption (xii) to get

which establishes the equivalence between \cref{eqn:entropy} and \cref{eqn:entropy1}.
\end{proof}

\paragraph{Remark} The formula in \cref{thm:entropy} provides a new way to estimate the entropy of a data distribution from \iid samples. Specifically, given  and an SDE like \cref{eq:sde}, we can first apply score matching to train a time-dependent score-based model such that , and then plug  into \cref{eqn:entropy1} to obtain the following estimator of :

or plug it into \cref{eqn:entropy} to obtain the following alternative estimator

Both estimators can be computed from a score-based model alone, and do not require training a density model. 

\begin{theorem}\label{thm:elbo_bound}
Let  denote the transition kernel from  to  for any . With the same conditions and notations in \cref{thm:bound}, we have

\end{theorem}
\begin{proof}
Since , we can combine \cref{thm:bound} and \cref{thm:entropy} to obtain

The second term of \cref{eqn:combine} can be simplified via integration by parts

where (i) is due to integration by parts and the limiting behavior of  given by assumption (xii). Combining \cref{eqn:partial_integral} and \cref{eqn:combine} completes the proof for \cref{eqn:elbo1}.

The proof for \cref{eqn:elbo2} parallels that of denoising score matching~\cite{vincent2011connection}. Observe that . As a result,

Substituting \cref{eqn:denoising} into the second term of \cref{eqn:combine}, we have

We can now complete the proof for \cref{eqn:elbo2} by combining \cref{eqn:denoising_2} an \cref{eqn:combine}.
\end{proof}

\pointelbo*
\begin{proof}
The result in \cref{thm:elbo_bound} can be re-written as

Given a fixed SDE (and its transition kernel ), \cref{thm:elbo_bound} holds for any data distribution  that satisfies our assumptions. Leveraging proof by contradiction, we can easily see that  in both sides of \cref{eqn:elbo1,eqn:elbo2} can be cancelled to get 

which finishes the proof.
\end{proof}


\section{Numerical stability}\label{app:stability}
In our previous theoretical discussion, we always assume that data are perturbed with an SDE starting from . However, in practical implementations,  often leads to numerical instability. As a pragmatic solution, we choose a small non-zero starting time , and consider the SDE in the time horizon . Using the same proof techniques, we can easily see that when the time horizon is  instead of , the original bound in \cref{thm:bound},

shall be replaced with

where , and  denotes the marginal distribution of . Here the stochastic process  is defined according to \cref{eqn:reverse_sde_model}. When  is sufficiently small, we always have

so we train with \cref{eqn:kl_bound_tilde} to approximately maximize the model likelihood for . However, at test time, we should report the likelihood bound for  for mathematical rigor, not . To this end, we first derive an analogous result to \cref{thm:elbo_bound2} with the time horizon , given as below.
\begin{theorem}\label{thm:bound_epsilon}
Let  denote the transition distribution from  to  for the SDE in \cref{eq:sde}. With the same notations and conditions in \cref{thm:elbo_bound2}, as well as the definitions of  and  given above, we have

where  is defined as

and  is given by
\begin{small}

\end{small}
\end{theorem}
\begin{proof}
The proof closely parallels that of \cref{thm:elbo_bound2}, by noting that .
\end{proof}

Although  is a probabilistic model for , we can transform it into a probabilistic model for  leveraging a denoising distribution  that approximately converts  to . Suppose . Inspired by Tweedie's formula, we choose 

and define , which is a probabilistic model for . With slight abuse of notation, we identify  with  in \cref{tab:results}. With Jensen's inequality, we have

Combined with \cref{thm:bound_epsilon}, we have

The above bound \cref{eqn:correction} was applied to both computing the test-time likelihood bounds in \cref{tab:results}, and training the flow model used in variational dequantization. Note that it was not used to train the time-dependent score-based model.

In practice, we choose  for VP SDEs and  for subVP SDEs, except that on ImageNet we use  for VP SDE models trained with likelihood weighting and importance sampling. Note that \cite{song2020score} chooses  for all cases. We found that when using likelihood weighting and optionally importance sampling,  for subVP SDEs can cause stiffness for numerical ODE solvers. In contrast, using  for subVP SDEs sidesteps numerical issues without hurting the performance for score-based models trained with original weightings in \cite{song2020score}. For the bound values in \cref{tab:results}, we draw 1000 time values uniformly in  and use them to estimate  for each datapoint, with the same importance sampling technique in \cref{eqn:importance_sampling}. We use the correction in \cref{eqn:correction} and report upper bounds for . For computing the likelihood of , we use the Dormand-Prince RK45 ODE solver~\cite{dormand1980family} with absolute and relevant tolerances set to . We do not use the correction in \cref{eqn:correction} for , because it is still a valid likelihood for the data distribution even in the time horizon .

Below is a related result to bound  directly. We include it here for completeness, though we do not use it for either training or inference in our experiments.
\begin{theorem}\label{thm:bound_epsilon_2}
Let  denote the transition distribution from  to  for the SDE in \cref{eq:sde}. With the same notations and conditions in \cref{thm:elbo_bound2}, as well as the definitions of  and  in \cref{thm:bound_epsilon}, we have

where  is defined as

and  is given by
\begin{small}

\end{small}
\end{theorem}
\begin{proof}
Proof closely parallels those of \cref{thm:elbo_bound2,thm:bound_epsilon}.
\end{proof}

\section{Experimental details}\label{app:exp}
\paragraph{Datasets} All our experiments are performed on two image datasets: CIFAR-10~\cite{krizhevsky2014cifar} and down-sampled ImageNet~\cite{van2016pixel}. Both contain images of resolution . CIFAR-10 has 50000 images as the training set and 10000 images as the test set. Down-sampled ImageNet has 1281149 training images and 49999 test images. It is well-known that ImageNet contains some personal sensitive information and may cause privacy concern~\cite{yang2021study}. We minimize this risk by using the dataset with a small resolution ().

\paragraph{Model architectures}
Our variational dequantization model, , follows the same architecture of Flow++~\cite{ho2019flow++}. We do not use dropout for score-based models trained on ImageNet. We did not tune model architectures or training hyper-parameters specifically for maximizing likelihoods. All likelihood values were reported using the last checkpoint of each setting.

\paragraph{Training} We follow the same training procedure for score-based models in \cite{song2020score}. We also use the same hyperparameters for training the variational dequantization model, except that we train it for only 300000 iterations while fixing the score-based model. All models are trained on Cloud TPU v3-8 (roughly equivalent to 4 Tesla V100 GPUs). The baseline DDPM++ model requires around 33 hours to finish training, while the deep DDPM++ model requires around 44 hours. The variational dequantization model for the former requires around 7 hours to train, and for the latter it requires around 9.5 hours.



\paragraph{Confidence intervals}
All likelihood values are obtained by averaging the results on around 50000 datapoints, sampled with replacement from the test dataset. We can compute the confidence intervals with Student's t-test. On CIFAR-10, the radius of 95\% confidence intervals is typically around 0.006 bits/dim, while on ImageNet it is around 0.008 bits/dim. 

\paragraph{Sample quality}
All FID values are computed on 50000 samples from , generated with numerical ODE solvers as in \cite{song2020score}. We compute FIDs between samples and training/test data for CIFAR-10/ImageNet. Although likelihood weighting + importance sampling slightly increases FID scores, their samples have comparable visual quality, as demonstrated in \cref{fig:cifar,fig:imagenet}.

\begin{figure}
     \centering
     \begin{subfigure}{\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/cifar10_best.jpg}
         \caption{DDPM++ (deep, subVP)~\protect\cite{song2020score}, FID = 2.86}
     \end{subfigure}
     \begin{subfigure}{\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/cifar10_nll.jpg}
         \caption{ScoreFlow, FID = 5.34}
     \end{subfigure}
     \caption{Samples on CIFAR-10. (a) Model with the best FID. (b) ScoreFlow trained with likelihood weighting + importance sampling + VP SDE. Samples of both models are generated with the same random seed.}\label{fig:cifar}
\end{figure}

\begin{figure}
     \centering
     \begin{subfigure}{\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/imagenet_best.jpg}
         \caption{DDPM++ (VP)~\protect\cite{song2020score}, FID = 8.34}
     \end{subfigure}
     \begin{subfigure}{\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/imagenet_nll.jpg}
         \caption{ScoreFlow, FID = 10.18}
     \end{subfigure}
     \caption{Samples on ImageNet . (a) Model with the best FID. (b) ScoreFlow trained with likelihood weighting + importance sampling + VP SDE. Samples of both models are generated with the same random seed.}\label{fig:imagenet}
\end{figure}







