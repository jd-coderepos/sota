\documentclass[a4paper,UKenglish]{lipics}

\usepackage{etoolbox}
\usepackage{tikz}
\usepackage{wrapfig}
\usepackage{bbding}







\usetikzlibrary{positioning}
\usetikzlibrary{arrows}
\usetikzlibrary{calc}
\usetikzlibrary{automata}



\def\myfill{\vrule height 2mm depth 0.8mm width 0pt}
\tikzstyle{state}=[minimum size = 6.3mm, inner sep = 0.5mm, circle, draw]
\tikzstyle{statemdp}=[minimum size = 6.2mm, inner sep = 0mm, rounded corners=0, draw,rectangle split, rectangle split horizontal=false, rectangle split parts=2, rectangle split draw splits=false]



\newcommand{\bscc}[1]{\mathsf{bscc}(#1)}
\newcommand{\poly}[1]{\mathsf{poly}(#1)}
\newcommand{\symbopen}{\text{\scriptsize\FiveStarOpen}}
\newcommand{\symbclosed}{\text{\scriptsize\FiveStar}}

\newcommand{\tran}[1]{\stackrel{#1}{\rightarrow}}

\newcommand{\true}{\mathsf{true}}
\newcommand{\false}{\mathsf{false}}
\newcommand{\cyl}{\mathit{Cyl}}
\newcommand{\dist}{\mathcal{D}}
\newcommand{\mc}{\mathcal{M}}
\newcommand{\mdp}{\mathcal{M}}
\newcommand{\states}{S}
\newcommand{\actions}{A}
\newcommand{\tra}{\Delta}
\newcommand{\Gf}[1]{\mathbf{G}^{#1}}
\newcommand{\X}{\mathbf{X}\,}
\newcommand{\G}{\mathbf{G}\,}
\newcommand{\U}{\,\mathbf{U}\,}
\newcommand{\F}{\mathbf{F}\,}
\newcommand{\idf}{\mathbf{1}}

\newcommand{\Ex}[3][]{\ifblank{#1}{\mathbb{E}_{#2}}{\mathbb{E}^{#1}_{#2}}(#3)}
\newcommand{\E}[2][]{\ifblank{#1}{\mathbb{E}(#2)}{\mathbb{E}^{#1}(#2)}} 
\newcommand{\Prb}[2][]{\ifblank{#1}{\mathbb{P}_{#2}}{\mathbb{P}^{#1}_{#2}}} 
\renewcommand{\Pr}[3][]{\ifblank{#1}{\mathbb{P}_{#2}}{\mathbb{P}^{#1}_{#2}}(#3)} 
\renewcommand{\P}[2][]{\ifblank{#1}{\mathbb{P}(#2)}{\mathbb{P}^{#1}(#2)}} 

\newcommand{\ssf}[1]{x_{#1}}
\newcommand{\rabin}{R}
\newcommand{\rstates}{Q}
\newcommand{\rinit}{q_{in}}
\newcommand{\ract}{\Sigma}
\newcommand{\rtra}{\delta}
\newcommand{\racc}{\mathcal{F}}
\newcommand{\freq}[1]{\mathsf{freq}(#1)}

\newcommand{\Nset}{\mathbb{N}}
\newcommand{\Rset}{\mathbb{R}}


\newcommand{\sinit}{s_{in}}

\newcommand{\fix}[1]{{#1^\star}}
\newcommand{\fixs}{\fix{s}}
\newcommand{\fixq}{\fix{q}}
\newcommand{\fixI}{\fix{I}}
\newcommand{\fixh}{\fix{h}}


\newcommand{\eps}{\varepsilon}

\newcommand{\ap}[1]{\ensuremath{\mathsf{#1}}}

\allowdisplaybreaks
\newtheorem{proposition}[theorem]{\bfseries  Proposition}




\newcommand{\citeapp}[1]{Appendix~\ref{#1}}



\newcommand{\depth}{\mathit{depth}}
\newcommand{\trunc}[1]{\mathsf{trunc}(#1)}
\newcommand{\compl}[1]{\textit{co-}#1}
\newcommand{\rank}[1]{\mathit{rank}(#1)}
\newcommand{\last}[1]{\mathit{last}(#1)}
\newcommand{\thetas}{\theta_S}
\newcommand{\thetaa}{\theta_A}
\newcommand{\occu}{\mathrm{occ}}
\newcommand{\infi}{\mathrm{inf}}




\newcommand{\theoremlike}[2]{\par\medskip\penalty-250\refstepcounter{theorem}{{\bfseries\noindent#2
			\ref{#1}.}}}
\newcommand{\thmhelperpre}[2]{\theoremlike{#1}{#2}}
\newcommand{\thmhelperpost}{\par\medskip}

\newenvironment{reftheorem}[1]{\thmhelperpre{#1}{Theorem}}{\thmhelperpost}
\newenvironment{reflemma}[1]{\thmhelperpre{#1}{Lemma}}{\thmhelperpost}
\newenvironment{refproposition}[1]{\thmhelperpre{#1}{Proposition}}{\thmhelperpost}





\begin{document}
\title{On Frequency LTL in Probabilistic Systems}

\author[1]{Vojt\v{e}ch~Forejt}
\author[2]{Jan Kr\v{c}\'al}
\affil[1]{Department of Computer Science, University of Oxford, UK}
\affil[2]{Saarland University -- Computer Science,  Saarbr\"{u}cken, Germany}

\Copyright{Vojt\v{e}ch~Forejt, Jan Kr\v{c}\'al}

\subjclass{F.4.1 Mathematical Logic}


\keywords{Markov chains, Markov decision processes, LTL, controller synthesis}

\maketitle

\begin{abstract}
We study frequency linear-time temporal logic (fLTL) which extends the
linear-time temporal logic (LTL) with a path operator 
expressing that on a path, certain formula holds with at least a given frequency , thus relaxing
the semantics of the usual  operator of LTL. Such logic is particularly useful
in probabilistic systems, where some undesirable events such as random failures may occur
and are acceptable if they are rare enough.
Frequency-related extensions of LTL have been previously studied by several authors, where mostly
the logic is equipped with an extended ``until'' and ``globally'' operator, leading to undecidability
of most interesting problems. 

For the variant we study, we are able to establish fundamental decidability results. We show that for Markov chains,
the problem of computing the probability with which a given fLTL formula holds has the same complexity
as the analogous problem for LTL. We also show that for Markov decision processes the problem becomes
more delicate, but when restricting the frequency bound  to be 1 and negations not to be outside any  operator, we can
compute the maximum probability of satisfying the fLTL formula. This can be again performed with the same time
complexity as for the ordinary LTL formulas.
\end{abstract}

\section{Introduction}

Probabilistic verification is a vibrant area of research that aims to formally check properties of stochastic systems. Among the most
prominent formalisms, with applications in e.g. modelling of network security protocols~\cite{Shm04} or
randomised algorithms~\cite{KNP12a}, are Markov chains and Markov decision processes (MDPs). Markov chains are
apt for modelling systems that contain 
purely stochastic behaviour,
for example random failures,
while MDPs can also express nondeterminism,
most commonly present as decisions of a controller or dually as adversarial events in the system.

More technically, MDP is a process that moves in discrete steps within a finite state space (labelled by sets of atomic propositions). Its evolution starts in a given initial state . In each step a \emph{controller} chooses an action  from a finite set  of actions available in the current state . The next state  is then chosen randomly according to a fixed probability distribution . The controller may base its choice on the previous evolution  and may also choose the action randomly. A Markov chain is an MDP where the set  is a singleton for each state .

For the systems modelled as Markov chains or MDPs, the desired properties such as ``whenever a signal arrives to the system, the system eventually switches off'' can be often captured by
a suitable linear-time logic. The most prominent one in the verification community is Linear Temporal Logic (LTL).
Although LTL is suitable in many scenarios, it does not allow to capture some important linear-time properties,
for example that a given event takes place {\em sufficiently often}.
The need for such properties becomes even more apparent in stochastic systems, in which probabilities often model random failures.
Instead of requiring that no failure ever happens, it is natural to require that failures are infrequent, while still having the power of the LTL to specify these failures using a complex LTL formula.

A natural solution to the above problem is to extend LTL with operators that allow us to talk about {\em frequencies} of events.
Adding such operators can easily lead to undecidability as they often allow one to encode
values of potentially infinite counters~\cite{BDL-tase12,BMM14}. In both the above papers this is caused by a variant of a ``frequency until'' operator
that talks about the ratio of the number of given events happening along a finite path. The undecidability results from \cite{BDL-tase12,BMM14} carry over to the stochastic setting easily, and so, to avoid undecidability, care needs to be taken.

In this paper, we take an approach similar to~\cite{AT12} and in addition to usual operators of LTL such as , ,  or  we only allow {\em frequency globally} formulae  that require the formula  to hold on -fraction of suffixes of an infinite path,
or more formally,  is true on an infinite path  of an MDP if and only if


This logic, which we call \emph{frequency LTL (fLTL)}, is still a significant extension to LTL, and because all operators can be nested, it allows to express much larger class of properties (a careful reader will notice that {\em nesting} of frequency operators is not the main challenge when dealing with fLTL as it can be easily removed for the price of exponential blow-up of the size of the formula).

The problem studied in this paper asks, given a Markov chain and an fLTL formula, to compute the probability with which
the formula is satisfied in the Markov chain when starting in the initial state. Analogously, for MDPs we study the
{\em controller synthesis} problem which asks to compute the maximal probability of satisfying the formula, over all controllers.


\begin{wrapfigure}[8]{r}{0.31\textwidth}
	\begin{tikzpicture}[-latex', rounded corners, xscale=1.25,yscale=1.25,
	font=\footnotesize,
	prob/.style={font=\footnotesize}]
	
	\node[statemdp] (s) at (0,0) {\myfill\nodepart{two}\myfill\ap{w}};
	\node[statemdp] (q) at (-1.1,-1) {\myfill\nodepart{two}\myfill\ap{q}};
	\node[statemdp] (r) at (0,-1) {\myfill\nodepart{two}\myfill\ap{r}};
	
	\node[statemdp] (m1) at (1.5,0) {\myfill\nodepart{two}\myfill\ap{m}};
	\node[statemdp] (mq1) at (1.5,-1) {\myfill\nodepart{two}\myfill\ap{q}{,}\ap{m}};
	
	\draw  (q) edge  (r);
	
	\draw  (s) -| node[pos=0.3, below] {w} node[pos=.8,left,prob] {0.5}  (q);
	\draw  (s) -- (0.6,0) coordinate (v2){} node[pos=.7,above] {m} -- node[pos=.7,above,prob] {0.5}   (m1);
	\draw  (m1)  |- (1,0.5) -| (s);
	
	\draw  (mq1)  -- +(-0.6,0) -- (s);
	
	
	\draw  () -- (s);
	
	\draw  (s) -- +(0.6,-0)  -- node[pos=.7,right,prob] {0.5} (mq1);
	\draw  (s) edge[out=180,in=225,loop, looseness=7] node[pos=0.8,below,prob] {0.5}  (s);
	\draw  (r) edge (s);
	\end{tikzpicture}
	\caption{An example MDP.\label{fig:intro}}
\end{wrapfigure}
For an example of possible application, suppose a network service accepts \ap{queries} by immediately sending back , and in addition
it needs to be switched off for  during which the queries are not accepted.
In most states, a new \ap{query} comes in the next step with probability . In the \ap{waiting} state, the system chooses either to wait further (action ), or to start a \ap{maintenance} (action ) which takes one step to finish.
The service is modelled as an MDP from Figure~\ref{fig:intro}, leaving some parts of the behaviour unspecified. The aim is to synthesise a control strategy that meets with a given probability the requirements on the system. Example requirements can be given by a formula  which will require that the service sometimes accepts the request, and sometimes goes for maintenance. However, there is no quantitative restriction on how often the maintenance can take place, and such restriction is inexpressible in LTL. However, in fLTL we can use the formula  to restrict
that the service is running sufficiently often, or a strong restriction  saying that it is running with frequency 1. The formula may also contain several frequency operators.
In order to push the frequency of correctly handled queries towards a bound , the controller needs to choose to perform the maintenance less and less frequently during operation.

\subparagraph{Related work}
Controller synthesis for ordinary LTL is a well-studied problem solvable in time polynomial in the size of the model and doubly exponential
in the size of the formula~\cite{BP08}. Usually, the LTL formula is transformed to an equivalent Rabin automaton, and
the probability of reaching certain subgraphs is computed in a product of the MDP (or Markov Chain) with the automaton. 


A similar approach is taken by~\cite{AT12}. They study a logic similar to our fLTL, where LTL is extended with a mean-payoff reward constraints
in which the reward structures are determined by validity of given subformulas. The authors show that any formula can be converted
to a variant of non-deterministic B\"uchi automata, called multi-threshold mean-payoff B\"uchi automata, with
decidable emptiness problem, thus yielding decidability for model-checking and
satisfiability problems of labelled transition systems. Results of~\cite{AT12} cannot be applied
to probabilistic systems:
here one needs to work with {\em deterministic automata},
but as pointed out in \cite[Section 4, Footnote 4]{AT12} the approach of~\cite{AT12} heavily relies on non-determinism, since reward values depend on complete future, and so deterministic ``multi-threshold mean-payoff Rabin automata'' are strictly less expressive than the logic.
Another variant of frequency LTL was studied in~\cite{BDL-tase12,BMM14}, in which also a modified until operator is introduced. 
The work~\cite{BDL-tase12} maintains boolean semantics of the logic, while in~\cite{BMM14} the value of a formula is a number between
0 and 1. Both works obtain undecidability results for their logics, and~\cite{BDL-tase12} also yields decidability for restricted nesting.
Another logic that speaks about frequencies on a finite interval was introduced in~\cite{DBLP:journals/corr/abs-1111-3111} but provides analysis algorithm only for a bounded fragment.

Significant attention has been given to the study of quantitative objectives. The work \cite{boker2011temporal} adds mean-payoff objectives to temporal logics, but only as atomic propositions and not allowing more complex properties to be quantified. 
The work \cite{baier2014weight} extends LTL with another form of quantitative operators, allowing accumulated weight constraint expressed using automata, again not allowing quantification over complex formulas.
\cite{bloem2009better} introduces lexicographically ordered mean-payoff objectives in non-stochastic parity games and \cite{chatterjee2011energy} gives a polynomial time algorithm for almost-sure winning in MDPs with mean-payoff and parity objectives. These objectives do not allow to attach mean-payoff (i.e. frequencies) to properties more complex than atomic propositions. The solution to the problem requires infinite-memory strategy which at high level has a form similar to the form of strategies we construct for MDPs. Similar strategies also occur in \cite{chatterjee2005mean,chatterjee2012games,BFK08} although each of these works deals with a fundamentally different problem.

In branching-time logics, CSL is sometimes equipped with a ``steady-state'' operator whose semantics is similar
to our  (see e.g. \cite{BHHK00}), and an analogous approach has been taken for the logic PCTL~\cite{kuvcera2005controller,de1998specify}.
In such logics every temporal subformula
is evaluated over states, and thus the model-checking of a frequency operator can be directly reduced to achieving a single mean-payoff reward.
This is contrasted with our setting in which the whole formula is evaluated over a single path, giving rise to much more complex
behaviour.

\subparagraph{Our contributions}
To our best knowledge, this paper gives the first decidability results for probabilistic verification against linear-time temporal logics extended by frequency operators with \emph{complex nested subformulas} of the logic.

We first give an algorithm for computing the probability of satisfying an fLTL formula in a Markov Chain.
The algorithm works by breaking the fLTL formula into linearly many ordinary LTL formulas, and then off-the-shelf
verification algorithms can be applied. We obtain that the complexity of fLTL model-checking
is the same as the complexity of LTL model checking. Although the algorithm itself is very simple, some
care needs to be taken when proving its correctness: as we explain later, the ``obvious'' proof approach would fail
since some common assumptions on independence of events are not satisfied.

We then proceed with Markov decision processes, where we show that the controller synthesis problem is significantly more complex.
Unlike the ordinary LTL, for fLTL the controller-synthesis problem may require strategies to use {\em infinite memory}, even
for very simple formulas. On the positive side, we give an algorithm for synthesis of strategies for formulas in which the
negations are pushed to atomic propositions, and all the frequency operators have lower bound 1. Although this might appear to be
a simple problem, it is not easily reducible to the problem for LTL, and the proof of the correctness of the algorithm is in
fact very involved.
This is partly because even if a strategy satisfies the formula, it can exhibit a very ``insensible'' behaviour,
as long as this behaviour has zero frequency in the limit. In the proof, we need to identify these cases and eliminate them.
Ultimately, our construction again yields the same complexity as the problem for ordinary LTL. We believe the contribution of
the fragment is both practical, as it gives a ``weaker'' alternative of the  operator usable in controller synthesis, and
theoretical, giving new insights into many of the challenges one will face in solving the controller-synthesis problem for the whole
fLTL.


\section{Preliminaries}
\label{sec:prelims}

We now proceed with introducing basic notions we use throughout this paper.

A {\em probability distribution} over a finite or countable set  is a function  such that
, and  denotes the set of all probability distributions over .

\subparagraph{Markov decision processes and Markov chains}
A {\em Markov decision process} (MDP) is a tuple  where  is a finite set of states,
 is a finite set of actions, and 
is a partial probabilistic transition function.
A {\em Markov chain} (MC) is an MDP in which for every  there is exactly one  with
 being defined. We omit actions completely when we speak
about Markov chains and no confusion can arise.

An infinite {\em path}, also called \emph{run}, in  is a sequence  of states and actions
such that  for all , and we denote by  the suffix .
A finite path , also called \emph{history}, is a prefix of an infinite path
ending in a state. 
Given a finite path  and a finite or infinite path 
we use  to denote the concatenated path .
The set of paths starting with a prefix  is denoted by , or simply by  if it leads to no confusion.
We overload the notation also for sets of histories, we simply use  instead of .

A {\em strategy} is a function  that to every finite path  assigns a probability distribution over actions such that
if an action  is assigned a non-zero probability, then  is defined where  denotes the last state in . A strategy  is {\em deterministic} if it assigns
Dirac distribution to any history, and {\em randomised} otherwise. Further, it is {\em memoryless} if its choice only depends on
the last state of the history, and {\em finite-memory} if there is a finite automaton such that  only makes its choice based on
the state the automaton ends in after reading the history.

An MDP , a strategy  and an initial state  give rise to a probability space  defined in a standard way~\cite{KSK76}. For a history  and a measurable set of runs  starting from the last state of , we denote by  the probability
.
Similarly, for a random variable  we denote by  the expectation of  in this probability space and by  the expectation . Here,  is defined by  for runs of the form , and by  for all other runs.
We say that a property holds {\em almost surely} (or for almost all runs, or almost every run)
if the probability of the runs satisfying the property is .


\subparagraph{Frequency LTL}
The syntax of {\em frequency LTL (fLTL)} is defined by the equation:

where  ranges over a set  of atomic propositions. The logic LTL is obtained by omitting the rule for
.
For Markov chains we study the whole fLTL whereas for MDP, we restrict to a fragment that we call \emph{1-fLTL}. In this fragment, negations only occur immediately preceding atomic propositions, and  operators occur only with .

For an infinite sequence
 of numbers, we set .
Given a valuation , the semantics of fLTL is defined over a path  of an MDP as follows.

where  is  for  iff , and  otherwise.
We define , , and  by their usual definitions and introduce standard operators
 and  by putting  and
. 
Finally, we use  as a shorthand for .

\begin{definition}[Controller synthesis]
	The controller synthesis problem asks to decide, given an MDP , a valuation , an initial state , an fLTL formula  and
	a probability bound , whether
	 for some strategy .
\end{definition}

As an alternative to the above problem, we can ask to compute the maximal possible  for which the answer is true.
In the case of Markov chains, we speak about {\sf Satisfaction} problem since there is no strategy to synthesise.


\subparagraph{Rabin automata}
A {\em (deterministic) Rabin automaton} is a tuple  where 
is a finite set of states,  is an input alphabet, 
is a transition function, and  is an accepting condition.
A computation of  on an infinite word  over the alphabet  is the
infinite sequence  with  and . A computation
is accepting (or `` accepts '')
if there is  such that all states of  occur only
finitely many times in the computation, and some state of  occurs in it infinitely many times.
For a run  and a valuation , we use  for the sequence 
of sets of atomic propositions.

As a well known result~\cite{BP08}, 
for every MDP , valuation  and an LTL formula  there is a Rabin automaton  over the alphabet  such that  is constructible in doubly exponential time and  iff 
accepts . We say that  is equivalent to .
It is not clear whether this result and the definition of Rabin automata can be extended to work with fLTL in a way
that would be useful for our goals. The reason for this is, as pointed out in~\cite[Section 4, Footnote 4]{AT12}, that the frequencies in fLTL depend on the future of a run, and so require non-determinism, which is undesirable in stochastic verification.




\section{Satisfaction problem for Markov Chains}
\label{sec:mc}

In this section we show how to solve the satisfaction problem for MCs and fLTL.
Let us fix a MC , an initial state  and fLTL formula .
We will use the notion of {\em bottom strongly connected component} (bscc) of , which
is a set of
states  such that for all  the set of states reachable from 
is exactly . If  is in a bscc, by  we denote the bscc containing .

We first describe the algorithm computing the probability of satisfying  from , and
then prove its correctness.

\subparagraph{The algorithm}
The algorithm proceeds in the following steps. First, 
for each state contained in some bscc , we compute the steady-state
frequency  of  within . It is the number  where  equals  if the th state of  is , and , otherwise. Afterwards,
we repeat the following steps and keep modifying  for as long as it contains any  operators:
\begin{enumerate}
	\item Let  be a LTL formula and  a number such that  contains .
	\item Compute  for every state  contained in some bscc.
	\item Create a fresh atomic proposition  which is true in a state  iff  is contained in a bscc and
	. 
	\item Modify  by replacing any occurrence of  with .
\end{enumerate}
Once  contains no  operators, it is an LTL formula and we can use off-the-shelf techniques to compute ,
which is our desired value.

\subparagraph{Correctness}
The correctness of the algorithm relies on the fact that  labels states in a bscc  if almost every run reaching  satisfies the corresponding frequency constraint:

\begin{proposition}\label{prop:mc-replace}
	For every LTL formula , every number , every bscc  and almost every run  that enters  we have
	 if and only if .
\end{proposition}

The proposition might seem ``obviously true'', but the proof is not trivial.
The main obstacle is that satisfactions of  on  and 
are {\em not independent} events in general: for example if  and , then  implies
. Hence we cannot apply the Strong law of large numbers (SLLN) for independent random variables or
Ergodic theorem for Markov chains~\cite[Theorems 1.10.1-2]{Norris}, which would otherwise be obvious candidates.
Nevertheless, we can use the following variant of SLLN for correlated events.
\begin{lemma}\label{lemma:alt-slln}
	Let  be a sequence of random variables which only take values  or  and have expectation . Assume there are  such that for all  we have . Then
	 almost surely.
\end{lemma}

Using the above lemma, we now prove Proposition~\ref{prop:mc-replace} for fixed , , . Let  denote the Rabin automaton equivalent to  and  be the Markov chain product of  and . 

First, we say that a finite path  of  is \emph{determined} if the state  reached by  after reading  satisfies that  is in a bscc of .
We point out that for a determined path , either almost every run of  satisfies , or almost no run of  satisfies .
Also, the probability of runs determined within  steps is at least
 where  is the number of states of  and  is the minimum probability that occurs in .


Now fix a state .
For all  and 
we define random variables  over runs initiated in . We let  take value  if  is visited at least  times in  and the suffix of  starting from the th visit to  satisfies . Otherwise, we let .
Note that all  have a common expected value .

Next, let  and  be two numbers with .
We denote by  the set of all runs and by  the set of runs  for which the suffixes starting from the th visit to  are determined before the th visit to  (note that  can possibly be ).
Because on these determined runs , we get

as shown in Appendix~\ref{app:rv-xti}. 
Thus, Lemma~\ref{lemma:alt-slln} applies to the random variables  for a fixed .
Considering all  together, we show in Appendix~\ref{app:mc-bscc}
that

for almost all runs initiated in the state  we fixed above.
Because almost all runs that enter  eventually visit , and because satisfaction of   is independent of any prefix,
the proof of Proposition~\ref{prop:mc-replace} is finished, and we can establish the following.

\begin{theorem}
	The satisfaction problem for Markov chains and fLTL is solvable in time polynomial in the size of the model, and doubly exponential in the size of the formula. 
\end{theorem}




\section{Controller synthesis for MDPs}
\label{sec:mdp}

We now proceed with the controller synthesis problem for MDPs  and 1-fLTL. The problem for this restricted fragment of 1-fLTL is still highly non-trivial. In particular, it is not equivalent to synthesis for the \emph{LTL} formula where every  is replaced with . Indeed, for satisfying any LTL formula, finite memory is sufficient, while for 1-fLTL, the following theorem shows that infinite memory may be necessary.

\begin{theorem}\label{thm:inf}
	There is a 1-fLTL formula  and a Markov decision process  with valuation  such that the answer to the controller synthesis problem is ``yes'', but there is no finite-memory strategy witnessing this.
\end{theorem}
\begin{proof}[Proof idea]
	Consider the MDP from Figure~\ref{fig:intro} together with the formula
	.
	Independent of the strategy being used, no run initiated in  satisfies
	the subformula , while every run initiated in any other state satisfies
	this subformula. This means that we need the frequency of visiting  to be .
	The only finite-memory strategies achieving this are those that from some history
	on never choose to go right in the controllable state. However, under such strategies the formula  
	 is not almost surely satisfied.
On the other hand, the infinite-memory strategy that on -th visit to  picks  if and only if  is of the form  for some  satisfies .
	
	Note that although the above formula requires infinite memory due to ``conflicting'' conjuncts, infinite memory is needed already for simpler
	formulae of the form .
\end{proof}

The above result suggests that it is not possible to easily re-use verification algorithms for
ordinary LTL. Nevertheless, our results allow us to establish the following theorem.

\begin{theorem}\label{thm:main-mdp}
	The controller-synthesis problem for MDPs and 1-fLTL is solvable in time polynomial
	in the size of the model and doubly exponential in the size of the formula.
\end{theorem}

For the rest of this section, in which we prove Theorem~\ref{thm:main-mdp}, we fix an MDP , valuation , an initial state ,
and a 1-fLTL formula . The proof is given in two parts. In the first part, in Section~\ref{sec:strat} we show that the controller-synthesis problem is equivalent to problems of reaching a certain set  and then ``almost surely winning'' from this set. To prove this, the ``almost surely winning'' property will further be reduced to finding certain set of states and actions on a product MDP (Lemma~\ref{prop:screwing-paths}). In the second part of the proof, given in Section~\ref{sec:alg}, we will show that all the above sets can be computed.

\subsection{Properties of satisfying strategies}
\label{sec:strat}

Without loss of generality suppose that the formula  does not contain  as the outermost operator, and that it contains  subformulas of the form . Denote these subformulas . 
For example, 
contains  and .

The first step of our construction is to convert these formulae  to equivalent Rabin automata. However, as the formulae contain  operators, they cannot be directly expressed using Rabin automata (and as pointed out by \cite{AT12}, there is a fundamental obstacle preventing us from extending Rabin automata to capture ). 

To overcome this, we replace all occurrences of  in such formulae by either  or , to capture that the frequency constraint is or is not satisfied on a run. 
Such a replacement can be fixed only after a point in the execution is reached where it becomes clear which frequency constraints in  can be satisfied.
For a formula , any subset  of satisfied constraints defines a LTL formula  obtained from 
 by replacing all subformulas  (not contained in any other ) with  if  and with  if . The Rabin automaton for  is then denoted by .
For the formula  above, we have, e.g.,
, and . 

We use  for a disjoint union of the state spaces of these distinct Rabin automata, and  for a disjoint union of the state spaces of the automata , called \emph{main} automata, for all . 
Finally, for  belonging to a Rabin automaton  we denote by  the automaton obtained from  by changing its initial state to .

Let us fix a state  of  and a state  of  for some . We say that a run  \emph{reaches}  if for some  we have  and  is the state reached by the main automaton  after reading . Once  is reached, we say that a strategy  is \emph{almost-surely winning} from  if  assigns probability  to the set of runs  such that  is accepted by , and  whenever\footnote{Note that the product construction that we later introduce does not give us ``iff'' here. This is also why we require the negations to only occur in front of atomic propositions} we have .

\begin{proposition}\label{prop:reach}
	There is a strategy  such that 
	if and only if
	there is a set  for which the following two conditions are satisfied:
	\begin{enumerate}
		\item\label{item:2a} There is a strategy  such that \omega\Upsilon.
		\item\label{item:2b} For any  there is  almost-surely winning from .
	\end{enumerate}
\end{proposition}

\noindent
Intuitively, the proposition relies on the fact that if  holds on a run, then it holds on all its suffixes, and says that any strategy  can be altered so that almost surely there will be a prefix after which we know which of the  will be satisfied.

\begin{example}\label{ex:upsilon-intuition}
	Let us first illustrate the set  on a formula  that can be satisfied on the MDP from Figure~\ref{fig:intro} with probability . Figure~\ref{fig:rabin} shows Rabin automata for the formulae
	 (left) and . 
In this simple example, the ``decision'' whether the formula will be satisfied (and which  subformulas will be satisfied) comes after the first step. Thus, we can set .
\end{example}

\begin{wrapfigure}[10]{r}{0.35\textwidth}
	\begin{tikzpicture}
	\begin{scope}[x=0.4cm,y=0.4cm]
	\node[state,initial, initial below,initial text=] (a) {}; 
	\node[state] (b) [right=1 of a] {};
	\node[state] (c) [above=1 of b] {};
	\node[state,accepting] (d) [left=1 of c] {};
	\node[state] (e) [below=1 of b] {};
	\path[-latex'] 
	(a) edge[] node[below=0.3]{} (b)
	(b) edge[] node[right=0.3]{} (e)
	(b) edge[] node[right]{} (c)
	(c) edge[bend left] node[auto]{} (d)
	(d) edge[bend left] node[auto]{} (c)
	(c) edge[loop right] node[pos=0.7,below]{} (c)
	(e) edge[loop right] node[pos=0.7,below]{} (e)
	;
	\end{scope}
	
	\begin{scope}[xshift=2.3cm,x=0.4cm,y=0.4cm]
	\node[state,initial, initial below,initial text=] (a) {}; 
	\node[state] (b) [right=1 of a] {};
	\node[state,accepting] (c) [above=1 of b] {};
	\node[state] (d) [below=1 of b] {};
	\path[-latex'] 
	(a) edge[] node[below, pos=0.5]{} (b)
	(a) edge[] node[above, pos=0.2]{} (c)
	(b) edge[] node[auto,swap]{} (c)
	(b) edge[] node[auto]{} (d)
	(c) edge[loop right] node[pos=0.3,above]{} (c)
	(d) edge[loop right] node[pos=0.7,below]{} (d)
	;
	\end{scope}
	\end{tikzpicture}
	\caption{Example Rabin aut.\label{fig:rabin}}
\end{wrapfigure}

We now prove Proposition~\ref{prop:reach}. The direction  is straightforward. It suffices to define  so that it behaves as  initially until it reaches some  for the first time; then it behaves as .

Significantly more difficult is the direction  of Proposition~\ref{prop:reach} that we address now. We fix a strategy  with .
The proof is split into three steps. We first show how to identify the set , and then we show that items \ref{item:2a} and \ref{item:2b} of Proposition~\ref{prop:reach} are satisfied. The last part of the proof requires most of the effort.
In the proof, we will need to eliminate some unlikely events, and for this we will require that their probability is small to start with.
For this purpose, we fix a {\em very small} positive number \label{page:lambda}; to avoid cluttering of notation, we do not give
a precise value of , but instead point out that it needs to be chosen such that any numbers that depend on
it in the following text have the required properties (i.e. are sufficiently small or big; note that such choice is indeed possible). 
We should stress that  is influencing \emph{neither} the size of representation of our strategy \emph{nor} the complexity of our algorithm.
\paragraph*{Identifying the set }\label{page:sqI}

In the first step, we identify an appropriate set .
Intuitively, we put into  positions of the runs satisfying  where \emph{the way  is satisfied} is (nearly) decided, i.e. where it is (nearly) clear which frequency constraints will be satisfied by  in the future.
To this end, we mark every run  satisfying  with a set  such that  iff the formula
 holds on the run. We then define a set of finite paths  to contain all paths
 for which there is  such that exactly the frequency constraints from  as well as  are satisfied on (nearly) all runs starting with . Precisely, such that
.
Finally, for every  we add to  the pair  where  and  is the state in which  ends after reading .



\paragraph*{Reaching }

It suffices to show that the strategy  itself satisfies . We will use the following variant of L\'evy's Zero-One Law, a surprisingly powerful formalization of the intuitive fact that ``things need to get (nearly) decided, eventually''.

\begin{lemma}[L\'evy's Zero-One Law~\cite{chung}]\label{lemma:levy}
	Let  be a strategy and  a measurable set of runs. Then for \emph{almost} every run  we have
	
	where each  denotes the prefix of  with  states and the function  assigns  to  and  to .
\end{lemma}
\noindent
For every  we define  to be the set of runs that are marked by  and satisfy the formula . 
Then by Lemma~\ref{lemma:levy}, for almost every run  that satisfies  and has , there must be a prefix  of the run for which  because . Any such prefix was added to , with .

\paragraph*{Almost-surely winning from }

For the third step of the proof of direction  of Proposition~\ref{prop:reach} we fix  and we construct a strategy  that is almost-surely winning from . Furthermore, let  denote the set such that  is a state from . 
As we have shown in Theorem~\ref{thm:inf}, strategies might require infinite memory, and this needs to be taken into
consideration when constructing . The strategy cycles through two ``phases``, called {\em accumulating} and {\em reaching} that we illustrate on our example.

\begin{example}\label{ex:accum-intuition} 
	Returning to Example~\ref{ex:upsilon-intuition}, 
	we fix  and , with the corresponding history from  being . The strategy  we would like to obtain
	\begin{itemize} 
		\item first ``accumulates'' arbitrarily many steps from which all  can be almost surely satisfied. I.e., it accumulates arbitrarily many newly started instances of the Rabin automaton  (all being in state ) by repeating action  in .
		\item Then it ``reaches'' with all the Rabin automata  and  accumulated in the previous phase their accepting states  and  respectively. For  this happens without any intervention of the strategy,
		but for  the strategy needs to take the action . Then after returning to  it comes back to a state where the next accumulating
		phase starts.
Thus, we need to make sure we make the accumulating phases progressively longer so that in the long run they take place with frequency 1.
	\end{itemize}
	The proof that such a simple behaviour suffices is highly non-trivial.
To illustrate this, let us extend the MDP from Figure~\ref{fig:intro} with an action \ap{decline} with .
	The strategy  from the proof of Theorem~\ref{thm:inf} satisfies  for .
However, we can modify  and obtain a ``weird'' strategy  that takes the action \ap{decline} in the -th visit to  with probability . Such a strategy (a) still satisfies  but (b) it does not guarantee almost sure satisfaction of  in . Thus, it does not accumulate in the sense explained above. We will show that any such weird strategy can be slightly altered to fit into our scheme. \qed
\end{example}

To show that alternation between such accumulating and reaching suffices (and to make a step towards the algorithm to construct such ), we introduce a tailor-made product construction . The product keeps track of a \emph{collection} of arbitrarily many Rabin automata accumulated up to now. 
We need to make sure that almost all runs of all automata in the collection are accepting, and we will do this by ensuring that:
(i) almost every computation of all Rabin automata eventually commits to an accepting condition , and (ii) from the point the automaton
``commits'' to the accepting condition, no more elements of  are visited and (iii) some element of  is visited infinitely often.
To ensure this, we store additional information along any state  of each automaton:
\begin{itemize}
	\item  is a new instance that has to commit to an accepting condition soon;
	\item  is an instance that has to visit a state of  soon;
	\item  is an instance that recently fulfilled the accepting condition by visiting ;
	\item  is an instance that violated the accepting condition it had committed to.
\end{itemize}

\noindent
Let  denote the set of these pairs for all  and all accepting conditions  of the Rabin automaton where the state  belongs.
Note that  is finite; because we need to encode unbounded number of instances of Rabin automata along the run, each element of a collection  might stand for multiple instances that are in exactly the same configuration.
We say that  is {\em fulfilled} if it contains only elements of the form 
.
The aim is to fulfil the collection infinitely often, the precise meaning of ``recently'' and ``soon'' above is then ``since the last fulfilled state'' and ``before the next fulfilled state''. 

Using the product , we show that if there is a satisfying strategy in , there is a  strategy in  with a simple structure that visits a fulfilled state infinitely often (in Lemma~\ref{prop:screwing-paths}). Due to the simple structure, such a strategy can be found algorithmically. Finally, we show that such a strategy in the product induces a satisfying strategy in  (in Lemma~\ref{lemma:prod-to-orig}) yielding correctness of the algorithm.

\subparagraph{The product}
Let  be an MDP with states ,
actions
, and transition function  defined as follows.
We first define possible choices of a strategy in . Given a state , we say that an action  is \emph{legal} in  if
 is a valid choice in  in the original MDP, i.e.  is defined; and  satisfies the following:
\begin{itemize}
	\item for all tuples  we have  or  for some accepting condition ,
	{\footnotesize ( can ``commit'' to , or keep waiting)}
	\item for all  with  we have , {\footnotesize (all  are kept along with the commitments)}
	\item all , not added by one of the two above items, are of the form  where  is the initial state of a Rabin automaton  for , {\footnotesize (initial states can be added)}
\end{itemize}


\noindent
\label{page:det-evolv}The randomness in  comes only from . We set 
for any state , any action  legal in , and any state  such that  ``deterministically evolves'' by reading  into . 
Precisely, we require that  is the minimal set such that for any  there is  with  and  where the latter relation is defined by  and   and for any  by
\begin{itemize}
	\item  if  and  is not fulfilled, {\footnotesize (no special state visited)}
	\item  if  and  is fulfilled, {\footnotesize (resetting back to )}
	\item   if , {\footnotesize (the accepting condition becomes fulfilled)} 
	\item  if ; {\footnotesize (the accepting condition is violated)} 
\end{itemize}

\noindent
Finally, a state is called {\em fulfilled} if its second component is fulfilled.


\begin{figure*}
	\begin{center}
		\begin{tikzpicture}[font=\scriptsize,inner ysep=0mm,inner xsep=-1.5mm,x=1.07cm]
		\node at (1.5,1.52) {};
		\node at (1.5,1.32) {};
		\node[draw] (v1) at (1,0) {};
		\node[draw] (v2) at (3,0) {};
		\node[draw] (v3) at (5,0) {};
		\node[draw] (v6) at (7,0) {};
		\node[draw] (v7) at (9,0) {};
		\node[draw] (v8) at (11,0) {};
		\node[draw] (v9) at (13,0) {};

		\draw (v1.0) edge[bend left,-latex'] node[midway,above] {}  (v2.180);
		\draw (v2.28) edge[bend left,-latex'] node[midway,above] {}  (v3.152);
		\draw (v3.25) edge[bend left,-latex'] node[midway,above] {}  (v6.155);
		\draw (v6.25) edge[bend left, -latex'] node[midway,above] {}  (v7.155);
		\draw (v7.30) edge[bend left,-latex'] node[xshift=2mm,midway,above] {}  (v8.150);
\draw (v8.30) edge[bend left,-latex'] node[midway,above] {}  (v9.150);
		\end{tikzpicture}
	\end{center}
	\caption{Illustration for Example~\ref{ex:product}. The names of actions from  are omitted when only a single action is available.\label{fig:product}}
\end{figure*}

\begin{example}\label{ex:product}
	Figure~\ref{fig:product} shows one path in the product  for the MDP and the Rabin automata from Example~\ref{ex:upsilon-intuition}. The path shown illustrates how the initial states can be added non-deterministically (in the first three steps), and then reaches a fulfilled state.
\end{example}

A very useful property of the product is that any strategy that ensures visiting fulfilled states infinitely often yields a strategy in the original MDP such that the automata the strategy added almost surely accept. This is formalised in the following lemma.

\begin{lemma}\label{lemma:prod-to-orig}
	For a deterministic strategy  in  there is a strategy  in  that for any  with
	:
	\begin{itemize}
		\item , and 
		\item for any  where  is the automaton of , 
		\rabin^q\omega.
	\end{itemize}
\end{lemma}

To be able to use above lemma, we need to establish that it is {\em sufficient} to look for a strategy that visits fulfilled states infinitely often. In other words that existence of the satisfying strategy  implies existence of a strategy that visits fulfilled states infinitely often.
Here we use the following lemma saying that  and  give rise to two
strategies in the product  that can be used to add initial states into the collections, and to
reach fulfilled states. We will show below how these strategies can be used to finish the proof of Proposition~\ref{prop:reach}.

\begin{lemma}\label{prop:screwing-paths}
Assume  are chosen as described on page~\pageref{page:sqI}.	
	Then there are sets ,  where 
	 contains only ``accumulating`` actions, i.e. actions  with \rabin_{\varphi_i,\fixI};
	and there are finite-memory deterministic strategies  and  such that:
	\begin{enumerate} 
		\item\label{item:screwing-a}
		When starting in ,  only uses actions from  and never leaves 
		\item\label{item:screwing-c} When starting in ,   almost surely reaches a fulfilled state (possibly leaving ) and then reaches .
	\end{enumerate}
\end{lemma}


\begin{proof}[Proof idea]
	The proof is involved and gives a crucial insight into the main obstacles of the proof of Theorem~\ref{thm:main-mdp}.
	Due to the space constraints we only sketch it here.
	
	We first prove that for any fixed , almost every  that satisfies all  has infinitely many {\em good} prefixes. Intuitively, a finite path  is \emph{good} if, when starting from ,
	all the automata  for  started within  first steps accept with probability at least .
	
	In the second step, we show how to avoid actions that cause that any  does not accept.
To do so, we inductively start labelling the prefixes of runs of the MDP with elements of . Having fixed a label for a prefix, the label for its extension is obtained by ``deterministic evolving'' as in the definition of the product MDP, and by (non-deterministically) adding .
	The latter part is performed by switching between a ``pseudo-accumulating'' and ``pseudo-reaching'' phase. Initially, we start in a pseudo-reaching phase, only with singletons corresponding to the current state of , and do not add any . When a good prefix is reached (which happens almost surely), we switch to a pseudo-accumulating phase for the next  steps and we keep adding ``initial states''  of  for each . After  steps, we switch back to a pseudo-reaching phase and do not add any new elements to the label until we pass through a state whose label is fulfilled and get to a good prefix again, in which point another pseudo-accumulating phase starts.
	
	Along the way, we might obtain tuples of the form  in the label, or we might not ever visit a fulfilled state. Indeed, if we repeated our steps to infinity, such an ``error'' might take place almost surely. However, before an error happens with too high probability, the labels start repeating because  is finite. 
We show that supposing  was large enough and our tolerance  was small enough, there must be a strategy that \emph{almost-surely} traverses such a cycle without any error.
We can extract from the pseudo-accumulating and pseudo-reaching phases of such a strategy the sets  (and ), given by the tuples of the MDP states (actions) and their labels.
\end{proof}

We are now ready to finish the proof of Proposition~\ref{prop:reach}. We show that Lemma~\ref{prop:screwing-paths} allows us to
construct a strategy  for  that almost surely (i) visits fulfilled states, and (ii) with frequency  it takes actions from . By Lemma~\ref{lemma:prod-to-orig} this strategy yields an almost-surely winning strategy  in .

The strategy  is constructed as follows.
Inductively, for path  in , we say that its first accumulating phase starts in the first step, th accumulating phase takes  steps, and the th accumulating phase starts when the set  is reached through a fulfilled state after the th accumulating phase ended.
Within every accumulating phase started in a history ,  is defined to play as  initiated after . Similarly, outside every accumulating phase ended in a history ,  is defined to play as .

\subsection{The algorithm}
\label{sec:alg}
To conclude the proof of Theorem~\ref{thm:main-mdp}, we need to give a procedure for  
computing the optimal probability of satisfying .
It works in the following steps (for details, see~\citeapp{app:algorithm}):
\begin{enumerate}
	\item\label{item:alg-a} Initialize , and construct  for all  and .
\item\label{item:alg-b} For every  
find the largest sets  satisfying the conditions \ref{item:screwing-a}--\ref{item:screwing-c} of Lemma~\ref{prop:screwing-paths}, and add to  all pairs  such that  can be almost-surely reached from 
	.
\item\label{item:reach} Compute an optimal strategy  for ``reaching''   and return the probability. Intuitively,
	\begin{itemize}
		\item we build the ``naive'' product of  with all the main automata  for ;
\item 
		reaching  is reduced to ordinary reachability of all states of the form  such that  for some .
\item
		By standard algorithms for reachability in MDP, we find an optimal strategy  in the naive product that easily induces the strategy  in .
	\end{itemize}
\end{enumerate}

\noindent
By connecting Proposition~\ref{prop:reach}, Lemmas~\ref{lemma:prod-to-orig} and~\ref{prop:screwing-paths}, and the construction of  above, there is a strategy  in  yielding probability  iff the set  computed by the algorithm can also be reached with probability .

We briefly discuss the complexity of the algorithm. Each of the Rabin automata in step \ref{item:alg-a} above can be computed in time ,
and since there is exponentially many such automata (in ), step 1. takes time .
Step \ref{item:alg-b} can be performed in time .
In step \ref{item:reach} we are computing reachability probability in the naive product MDP which is of size ,
and so also this step can be done in time .




\section{Conclusions}

We have given algorithms for controller synthesis of the logic LTL extended with
an operator expressing that frequencies of some events exceed a given bound.
For Markov chains we gave an algorithm working with the complete logic, and for
MDPs we require the formula to be from a certain fragment.
The obvious next step is extending the MDP results to the whole fLTL.
This will require new insights. Our product construction relies on the (non-trivial) observation
that given , the formula  is almost surely satisfied from
any history of an accumulating phase. This is no longer true when the frequency bound is
lower than . In such cases different histories may require different probability of
satisfying . However, both authors strongly believe that even for these cases the problem
is decidable.
Another promising direction for future work is implementing the algorithms into a probabilistic model checker and evaluating their time requirements experimentally.

\subparagraph{Acknowledgements.} The authors would like to thank anonymous reviewers for their insightful comments on an earlier version of this paper. 
This work is partly supported by the German Research Council (DFG) as part of the Transregional Collaborative Research Center AVACS (SFB/TR 14), by the Czech Science Foundation under grant agreement P202/12/G061, by the EU 7th Framework Programme under grant agreement no. 295261 (MEALS) and 318490 (SENSATION), by the CAS/SAFEA International Partnership Program for Creative Research Teams, and EPSRC grant EP/M023656/1. Vojt\v{e}ch Forejt is also affiliated with Faculty of Informatics, Masaryk University, Brno, Czech Republic.




\bibliographystyle{plain}
\bibliography{bib}


\onecolumn
\newpage
\appendix
\section{Details for proof for Markov chains}


\begin{reflemma}{lemma:alt-slln}
Let  be a sequence of random variables which only take values  or  and have expectation . Assume there are  such that for all  we have . Then
 almost surely.
\end{reflemma}
\begin{proof}
We can use \cite[Corollary 4]{lyons} applied to random variables  (we cannot use the result directly for  since \cite{lyons} requires the random variables to have expectation value equal to ). Clearly if ,
then
. 
Finally, the corollary of \cite{lyons} indeed applies since

\end{proof}
\subsection{Properties of random variables }
\label{app:rv-xti}
The following is a more detailed computation for properties of the random variables . First, we need to extend the definition of a path being determined. We say that a path  is {\em positively determined} if almost every run of  satisfies , and {\em negatively determined} if almost no run of  satisfies . Now splitting runs of  to  and  depending on whether the associated path
is positively or negatively determined, we have:


Now let us show that  by showing that . The argument for  is analogous.

Let  be the sequence of all finite paths ending in , containing  occurrences of , and satisfying the condition that
the suffix from th to th occurrence of  is positively determined. The sets  partition  and moreover
. Hence, we have


where the second equality follows because the value of  does not depend on the prefix up to the th visit to , and because  is a cylindric set.
\subsection{Relating frequency with probability of achieving bsccs.}
\label{app:mc-bscc}
The following is the final computation for the proof of Proposition~\ref{prop:mc-replace}. Below, we use  for the random variable
that for a run  returns the number of visits to  on the prefix of  of length .
 




\section{Details for proof for Markov decision processes} \label{app:algorithm}

\subsection{Proof of Lemma~\ref{lemma:prod-to-orig}}

\begin{reflemma}{lemma:prod-to-orig}
For a deterministic strategy  in  there is a strategy  in  that for any  with
:
\begin{itemize}
	\item , and 
	\item for any  where  is the automaton of , 
	\rabin^q\omega.
\end{itemize}
\end{reflemma}
\begin{proof}
For every finite path  in  there is at most one path of the form , denoted  which satisfies that:
 \begin{itemize}
  \item  with  fixed above
  \item  all  are as chosen with probability  by the deterministic strategy  and
  \item  all  all given uniquely by the definition of 
 \end{itemize}
	
	We define the strategy  by 
	 for all  starting with , and define  arbitrarily otherwise.
       
	Let  be a path. Clearly,
         by the definition of . Also,
	since , when starting after , almost surely fulfils infinitely often, it also never reaches any state with
        second component containing . Hence, it is easy to see from the definition of
         that , then 
	From the definition of  it is easy to see that fulfilling infinitely often implies that for all  the automaton
         (where  is the automaton containing ) almost surely accepts suffixes of .
\end{proof}


\subsection{Proof of Lemma~\ref{prop:screwing-paths}}
\label{sec:prop-proof}

First of all, let us introduce further definitions that we will require later in the proof. For a run  and a state  of a Rabin automaton , by  (resp. ) we denote the set of states of 
that occur infinitely many times in  (resp. that occur at least once in )
when the Rabin automaton is started from state  instead of .


\begin{reflemma}{prop:screwing-paths}
Assume  are chosen as described on page~\pageref{page:sqI}.	
	Then there are sets ,  where 
	 contains only ``accumulating`` actions, i.e. actions  with \rabin_{\varphi_i,\fixI};
	and there are finite-memory deterministic strategies  and  such that:
	\begin{enumerate} 
		\item\label{item:screwing-a}
		When starting in ,  only uses actions from  and never leaves 
		\item\label{item:screwing-c} When starting in ,   almost surely reaches a fulfilled state (possibly leaving ) and then reaches .
	\end{enumerate}
\end{reflemma}

We will now prove Lemma~\ref{prop:screwing-paths}. As before, fix , , and , and we also fix a finite path  from  witnessing that .
We also fix \label{page:ell} and  where  is the small number introduced at page~\pageref{page:lambda}.

The following definition and Lemma~\ref{lemma:brew-often} will help us identify (possible) recurring behaviour of . We need to identify long enough parts of runs where all the frequency formulae  are satisfied with probability very close to . Based on the behaviour of  within these parts, we later define the ``accumulating'' strategy.

For a path , let  be length of , i.e. the number of states in .
We say that a finite path  extending  is {\em good} 
if 

where  is the indicator function that the suffix of  starting at -th position satisfies all .

\begin{lemma}\label{lemma:prefix-approximate}
Let  be a set of runs, , and let |h|=i\mathbb{P}(X \mid h) \ge \beta then
, i.e. for every  there is  such that
for all  we have  iff .
\end{lemma}
\begin{proof}
If , then by Lemma~\ref{lemma:levy} there is  such that for all  we have
 where  is the prefix of  of length . Then  is the required number.
If , then again by Lemma~\ref{lemma:levy} there is  such that for all  we have
 where  is the prefix of  of length . Then again we pick .
\end{proof}

The following lemma allows us to simplify the notation and only deal with one frequency-globally formula .
\begin{lemma}\label{lemma:one-formula}
	Let  be LTL formulae, and  a run. We have
	
	if and only if
	.
\end{lemma}

\begin{lemma}\label{lemma:brew-often}
	Almost every  satisfying 
	has infinitely many good prefixes.
\end{lemma}
\begin{proof}
	By contradiction.
        Employing Lemma~\ref{lemma:one-formula} we can slightly simplify the problem and
        consider runs satisfying   for 
        Suppose that there is a set  with  such that
	all  satisfy  and have only finitely
	many good prefixes.
	
	Further, let  for a run  denote the smallest number such that
	for all  the prefix  of  of length  is not good.
	We can pick  and  satisfying that ,
	and every  satisfies that . 
	Note that such choice is possible, as with increasing  the set  tends monotonically to .
	
	Note that we have
	
	
	Furthermore, by Fatou's Lemma, by linearity of expectation, and by taking a subsequence of averages of chunks of length , we have
	
	
	Let  be the set defined as in Lemma~\ref{lemma:prefix-approximate}, and denote .
	For  we have
	
	and hence
	
	which is a contradiction with (\ref{eq:freq}).
\end{proof}


By heavily relying on existence of good prefixes, we define labellings of histories of  that will help us establish a connection to . Namely, the labellings (1) identify what is the current state in  and (2) resolve the additional choices w.r.t. the second component of .

We introduce functions  and  that label histories starting with  with elements of  and define the current state and the current action to pick in  in the given history, respectively. Inductively, together with defining the labellings, we also assign one of two distinct tags to these histories, {\em pseudo-accumulating} or {\em pseudo-reaching}.
We will then speak about pseudo-reaching and pseudo-accumulating \emph{phases} which are maximal consecutive ranges within histories labelled so far such that all prefixes in this range are tagged as pseudo-reaching or pseudo-accumulating, respectively. A pseudo-reaching phase is fulfilled if it contains a prefix  in its range such that  is fulfilled. 





Initially, we tag the history  of  as pseudo-reaching and set  and .


Suppose that  has already been defined and the tag of a history  of  has been determined. 

First for an action  and state , we tag the extension  of  as pseudo-accumulating if (i)
 is tagged as pseudo-accumulating and the length of the current pseudo-accumulating phase is less than  so far; or (ii)
 is in a pseudo-reaching phase such that some prefix of  within that phase is fulfilled
and  is good.
Otherwise we tag  as pseudo-reaching.

Next, we define  by ``deterministically evolving'' by reading the last state of  as in the definition of  at page~\pageref{page:det-evolv}, i.e.  is the minimal set such that for any  there is  with  and  where the latter relation is the relation from the definition of 

We define  to be the minimum element (w.r.t. set inclusion) of  satisfying the following
\begin{itemize}
	\item If  is in a pseudo-accumulating phase, then  contains  for the initial states  of  for all .
	\item For all  such that for some ,

		we put , and otherwise we put . In the case there are several 
		satisfying the condition above, we pick the least one w.r.t. an arbitrary but a priori fixed total order.
	\item For all  we put .
\end{itemize}
Note that the minimum element satisfying these conditions always exists. Also note that these definitions are analogous to those in , but in addition we give a rule for ``committing'' to an accepting condition.

Finally, any (finite or infinite) path  in  initiated in  corresponds to a path

in . Similarly, the strategy  gives rise to a strategy  defined, for all , by
.
The connection between the labellings and the MDP  is completed by the following lemma that can be proven immediately from the definitions.

\begin{lemma}\label{lemma:to-product}
	
	For any set ,
	.
\end{lemma}

Note that the strategy  in Lemma~\ref{lemma:to-product} is possibly still very complex in
its structure and in particular can reach states with  in the second component. We however show that within a certain finite horizon
this happens with a small probability.

Let  be the number of pseudo-accumulating phases along the path  . Let
 be the set of runs  that have , and for which no prefix  with  has .
We will show below that the probability of runs in  is very large. 

\begin{lemma}\label{lemma:alternating-runs}
	. 
\end{lemma}
\begin{proof} 
	First, we start with the set of runs
	
	with  as given by the assumption of Lemma~\ref{prop:screwing-paths} (here  denotes the set of all runs).
	
	Furthermore, let  be the set of runs where all the ``accumulated'' Rabin automata accept, i.e. runs  such that for all  and for all prefixes  in an at most -th pseudo-accumulating phase, we have that  accepts  where .
For a fixed accumulating phase which starts at some good history , we have (denoting  by  where  is the number of states in )
	
	yielding . Thus for  denoting the number of Rabin automata accepting in all  accumulating phases, we easily obtain  and thus .
	
	For every , we say that \emph{starting after , the history  decides for an acceptance condition  of } if
	\begin{itemize}
		\item  is in pseudo-accumulating phase, 
		\item  is the shortest history such that for some  
		
		where  is the state in which  ends after reading , and
		\item  is the minimal one among such acceptance conditions  (w.r.t. the above fixed order).
	\end{itemize}   
	
	We define a set  of runs where this ``decision'' turns out to be correct for all automata started in the first  accumulating phases. Technically,  if for every  and every splitting  such that  is in an at most -th pseudo-accumulating phase we have the following. If starting after ,  decides for some , we have  and  where again  is the state in which  ends after reading . 
	
	When starting after a single ,  decides for some , the probability of not sticking to this decision is by definition at most  (conditioned by ). Similarly as before, there are at most  decisions to take, yielding the overall probability at most  of runs that do not stick to decisions up to .
	
	For almost every run  we have that  if . Indeed, inductively, for all prefixes  of  such that  is in an at most -th pseudo-accumulating or pseudo-reaching phase and , we have  because no forbidden state  of a previously decided automaton is visited along any  of . Furthermore, every label  is eventually replaced by  because ; and every  is eventually replaced by some  (for almost every ) due to Lemma~\ref{lemma:rabin-determined} given below. Thus, the set of labels along  becomes at least  times fulfilled.
	
	Summing up ,  and , we obtain the statement of the lemma.
\end{proof}

An important step in the previous proof was that on almost every accepting path there is a prefix where the Rabin automaton ``decides'' for one accepting condition with high probability.
The proof is again based on Lévy's Zero-One Law.

\begin{lemma}\label{lemma:rabin-determined}
	Let  be a Rabin automaton,  be a path, , and .
For almost all  there is a prefix  of  and an acceptance pair  of  such that	
	where  is the state in which  ends after reading . 
\end{lemma}
\begin{proof}
	Let the acceptance conditions of  be  and its initial state be . 
For each , let  be the set  and  be its indicator function.
As for each  in some 
, 
	, we also have from Lemma~\ref{lemma:levy} (Lévy's zero one law) that  where  are the prefixes of  of length . 
Hence, there is  such that all prefixes  for  satisfy:

	
	Let us fix an arbitrary partition of  into \emph{disjoint} sets  such that for all , . 
For each  and run  let 
	


	Let . 
As we have , we also have from Lemma~\ref{lemma:levy} that .  Hence, there is  such that  and all prefixes  of length  satisfy
	
	


	\noindent
	In total, we obtain from~\ref{eq:rabin-det1} and~\ref{eq:rabin-det2} the desired statement.
\end{proof}



Before constructing the accumulating and reaching strategies, we state the following  lemmas that we will need.


The first lemma says that if we can achieve a certain event with a large enough probability in an MDP, then we can achieve it with probability . The proof follows from the fact that there are optimal deterministic strategies with memory of size 2.
\begin{lemma}\label{lemma:pone}
	Let  be an MDP with state space , where each state  is labelled with an atomic proposition  unique to this state, let  be the minimal probability occurring in it, and let  and  be two sets of states. The following statements hold true:
	\begin{enumerate}
		\item  If , then  for some .
		\item  If , then  for some .
	\end{enumerate}
\end{lemma}
\begin{proof}
	Let us analyse the second case which is slightly more technical.
	The set  can be captured using an LTL property
	and so the supremum is realised by some deterministic strategy . Suppose it is lower than .
	Then, since  is deterministic, there must be a history  for 
	such that  and , which is a contradiction.
	
	The first case can be proved similarly, we only need to consider that deterministic strategies with memory of size 2 are
	sufficient to achieve the supremum.
\end{proof}




From now on, we will consider the strategy  in  instead of . We transfer the labelling with a pseudo-reaching and pseudo-accumulating phase to runs of  in the straightforward way.


Let  be the set of histories that are in -th pseudo-accumulating phase and whose predecessors are not in -th pseudo-accumulating phase.
In order to define accumulating and reaching strategies, we need to select subsets of these histories that are ``connected'' with high probability.
We thus select non-empty sets  which in addition satisfy 

(recall that we interchangeably interpret a set of histories also as a set of runs starting with some history from the set).
This is indeed possible, it suffices to put  that satisfies the first condition by Lemma~\ref{lemma:alternating-runs}. Supposing  has been defined, we get  by the following.

\begin{lemma}\label{lemma:future-prob}
Let  and  be a probability measure. Further, let  be a set of runs such that , and let  be the prefix-free set of finite paths such that . There is a set  with 
	and  for all .
\end{lemma}
\begin{proof}
	We can assume , otherwise the statement holds for any set  as .
	
	We set . We claim that . Let us assume the contrary. This means that all  with  satisfy  and hence, also . We have 
	
	yielding a contradiction which proves that .



	As all runs can be partitioned into sets , , and , we have
	
	where  overapproximates (potentially undefined) probabilities  and .
	Since  and , we obtain
	
	and so .
\end{proof}

\noindent
In fact, it suffices to set  and  and obtain  as  from the lemma. The probability of all such  is . It is easy to prove by induction that the probability of each  is  where  obtaining the first inequality as . The second inequality is guaranteed by the properties of  by Lemma~\ref{lemma:future-prob}.

Even the sets of  are still not enough for our proof, we would like to get sets of histories that are ``connected'' with high probability from anywhere \emph{within} the accumulating phase.
For all  and all  we apply the following lemma and obtain a prefix-free set of paths  such that
 and for all prefixes  of any path in  we have .

\begin{lemma}\label{lemma:still-in-set}
	Let  be a set of runs such that
	
	then there is a prefix-free set  of finite paths of length
	 such that 
	and for all prefixes  of a path in 
	we have
	
\end{lemma}
\begin{proof}
	For all , we can find a set
	 of paths of length  such that  and
	 for all ; this is possible by
	Lemma~\ref{lemma:future-prob}, where for  we take all paths
	of length . The set  is then
	obtain  (note that this is indeed a set of paths).
\end{proof}

Finally, we are ready to obtain the accumulating and reaching strategies. Below,  is the last state of a path .

\begin{lemma}
	For ,  and , there is a strategy 
	that from  almost surely reaches  after passing through a fulfilled state.
\end{lemma}
\begin{proof}
	Such strategy always exists because of Lemma~\ref{lemma:pone} and because
	 by properties of elements of  and .
\end{proof}

The following lemma can be easily obtained from Lemma~\ref{lemma:pone}.
\begin{lemma}
	For all , there is a memoryless deterministic strategy  (in ) which, when started in , only ever reaches
	states and uses actions that occur on some history of .
\end{lemma}

In addition, denote by 
a strategy  for  belonging to  for .
By  we denote the tuple of sets of states and actions that  visits when started in .

Let  be a strategy  where  for . Let .

We inductively build  as follows. Initially,  and . We then keep adding to  and , until a fixpoint is reached, (i) the states and actions of  for all ,
and (ii) last states of histories  for  such that there is  with .
We claim that this procedure is well-defined in the sense that
the sets  in step (ii) above were always defined, i.e. that  in every case.
For this, we need to show that whenever  is taken in the definition,
then . Letting
, we can argue that initially  and with every iteration of steps (i) and (ii) the rank increases at most by 1.
Since only  elements can be added to  before a fixpoint is reached, we get that the bound on  is .

Now we claim that the Lemma~\ref{prop:screwing-paths} is satisfied.
\begin{itemize}
 \item As for the property of , note that
we were only adding states to  if they were last states of a history in a pseudo-accumulating phase, and by definition of  we have
 in the second component of such states for the initial states  of the automata  for all .
 \item For item \ref{item:screwing-a}, the strategy  is defined as follows. Let  be a history starting in , we put  where  is the element such that . For any other history we define  arbitrarily.
 \item For item \ref{item:screwing-c}, the strategy  is defined as follows. Let  be a history starting in , we put . For any other history we define  arbitrarily.
\end{itemize}



\subsection{Details for proof of Theorem~\ref{thm:main-mdp} and Section~\ref{sec:alg}}

\begin{reftheorem}{thm:main-mdp}
	The controller-synthesis problem for 1-fLTL for MDPs is solvable in time polynomial
	in the size of the model and doubly exponential in the size of the formula.
\end{reftheorem}

\begin{proof}
        We now give a more detailed description of the algorithm that is presented in Section~\ref{sec:alg}.
	
	\begin{enumerate}
		\item Construct the automata  for all  and .
\item Initialize .
		\item Repeat the following for every . Find the largest sets  satisfying the conditions \ref{item:screwing-a}--\ref{item:screwing-c} of Lemma~\ref{prop:screwing-paths}.
		It can be done as follows:
		\begin{itemize}
			\item Let  denote the tuple  that contains maximal subsets of  and 
			satisfying that for every  there is  such that  is defined and for every 
			contained in the support of  we have . (Easily obtained by iteratively pruning actions and states violating the conditions.)
			\item We start with  and  containing all ``accumulating'' actions  with \rabin_{\varphi_i,\fixI}. Then we apply the following steps until a fixpoint is reached:
			\begin{itemize}
				\item[(a)] ;
				\item[(b)] Remove from  all states that do not satisfy item~\ref{item:screwing-a} or item~\ref{item:screwing-c} of
				Lemma~\ref{prop:screwing-paths}. (Easily achieved by qualitative safety and reachability analysis in .)
			\end{itemize}
		\end{itemize}
		This yields a set , and we add to  all pairs  such that
		.
\item Compute an optimal strategy  for ``reaching''  (defined in Proposition~\ref{prop:reach}) and return the probability that  ``reaches'' . It can be done as follows:
		\begin{itemize}
			\item By  we denote the ``naive'' product of  with all the main Rabin automata 
			for all . Formally, fixing  an enumeration of subsets of ,
			the state space  of  contains tuples
			 where  is a state of ,
			the set of actions is , and the transition function 
			is given by
			
			when for every , we have .
			
			\item Furthermore, let  be the set of all  s.t.
			there is  with .
			
			\item By the construction, we easily obtain equivalence of strategies of the following form.
For any  in  there is  in , and also for any  there is  such that 
			
Let us prove the statement. For any \emph{finite or infinite} path  in  initiated in 
			there is a unique path  with  and  for all . 
For a fixed  we define  by  for all .
			Similarly, for a fixed , we define  by  for all .
The equality easily follows from the definitions.
			
			\item The above statement allows us to compute an optimal strategy  in  using ordinary reachability algorithms and set  to the corresponding strategy .
		\end{itemize}
\end{enumerate}
	
	\noindent
	
	Let us now analyse the complexity of the algorithm in more detail. Each of the Rabin automata in step 1. above can be computed in time ,
	and since there is exponentially many such automata (in ), step 1. takes time .
	In step 3., for a fixed ,  and  the result of  can be computed in polynomial time in the size of  and ; the same holds 	for satisfaction of the conditions in (b).
The size of  and
	 is
	, and for a fixed  the fixpoint is reached in at most  iterations.
	Moreover, there is
	at most  different s. Hence, step 3. can be performed in time .
	Finally, in step 4. we are computing reachability probability in a MDP  which is of size ,
	and so also this step can be done in time .
	This completes proof of Theorem~\ref{thm:main-mdp}.
\end{proof}
 
\end{document}
