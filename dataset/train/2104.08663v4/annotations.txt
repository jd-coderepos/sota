[{'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'HotpotQA (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.707'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'FiQA-2018 (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.347'}}, {'LEADERBOARD': {'Task': 'Passage Retrieval', 'Dataset': 'MSMARCO (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.413'}}, {'LEADERBOARD': {'Task': 'Passage Retrieval', 'Dataset': 'MSMARCO (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.408'}}, {'LEADERBOARD': {'Task': 'Passage Retrieval', 'Dataset': 'MSMARCO (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.401'}}, {'LEADERBOARD': {'Task': 'Passage Retrieval', 'Dataset': 'MSMARCO (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.388'}}, {'LEADERBOARD': {'Task': 'Passage Retrieval', 'Dataset': 'MSMARCO (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.351'}}, {'LEADERBOARD': {'Task': 'Passage Retrieval', 'Dataset': 'MSMARCO (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.338'}}, {'LEADERBOARD': {'Task': 'Passage Retrieval', 'Dataset': 'MSMARCO (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.296'}}, {'LEADERBOARD': {'Task': 'Passage Retrieval', 'Dataset': 'MSMARCO (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.228'}}, {'LEADERBOARD': {'Task': 'Passage Retrieval', 'Dataset': 'MSMARCO (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.177'}}, {'LEADERBOARD': {'Task': 'Biomedical Information Retrieval', 'Dataset': 'BioASQ (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.523'}}, {'LEADERBOARD': {'Task': 'Biomedical Information Retrieval', 'Dataset': 'BioASQ (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.514'}}, {'LEADERBOARD': {'Task': 'Biomedical Information Retrieval', 'Dataset': 'NFCorpus (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.350'}}, {'LEADERBOARD': {'Task': 'Biomedical Information Retrieval', 'Dataset': 'NFCorpus (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.305'}}, {'LEADERBOARD': {'Task': 'Biomedical Information Retrieval', 'Dataset': 'TREC-COVID (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.757'}}, {'LEADERBOARD': {'Task': 'Biomedical Information Retrieval', 'Dataset': 'TREC-COVID (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.677'}}, {'LEADERBOARD': {'Task': 'Fact Checking', 'Dataset': 'CLIMATE-FEVER (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.253'}}, {'LEADERBOARD': {'Task': 'Fact Checking', 'Dataset': 'SciFact (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.688'}}, {'LEADERBOARD': {'Task': 'Fact Checking', 'Dataset': 'SciFact (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.671'}}, {'LEADERBOARD': {'Task': 'Fact Checking', 'Dataset': 'FEVER (BEIR)', 'Metric': 'nDCG@10', 'Score': '0.819'}}]
