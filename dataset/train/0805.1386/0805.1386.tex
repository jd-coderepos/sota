\documentclass{llncs}

\usepackage{amssymb,amsfonts,mathrsfs,epsfig}

\newcommand{\limplies}{\rightarrow}
\newcommand{\liff}{\leftrightarrow}
\newcommand{\ex}[1]{\exists #1 \;} \newcommand{\fa}[1]{\forall #1 \;} 

\newcommand{\denotes}{\mathord{\downarrow}}
\newcommand{\myrule}{\noindent \rule{\textwidth}{0.3mm}}



\newcommand{\na}[1]{\mathit{#1}}    \newcommand{\fn}[1]{\mathit{#1}}    \newcommand{\ax}[1]{\mathit{(#1)}}  \newcommand{\mdl}[1]{\mathcal{#1}}  

\newcommand{\gn}[1]{\ulcorner #1 \urcorner} \newcommand{\lam}[1]{\lambda #1 \;} \newcommand{\proves}{\vdash}
\newcommand{\forces}{\Vdash}
\newcommand{\nforces}{\nVdash}

\newcommand{\NN}{\mathbb{N}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\CC}{\mathbb{C}} 
\newcommand{\TT}{\mathbb{T}} 

\newcommand{\lip}{\langle}
\newcommand{\rip}{\rangle}
\newcommand{\la}{(}
\newcommand{\ra}{)}
\newcommand{\st}{ \; | \; } \newcommand{\ph}{\varphi}
\newcommand{\concat}{\mathord{\hat{\;}}}
\newcommand{\dash}{\mathalpha{\mbox{-}}} \newcommand{\res}{\upharpoonright}
\newcommand{\nin}{\not\in}
\newcommand{\length}{\fn{length}}

\newcommand{\seq}[1]{\left\langle #1 \right\rangle}
\newcommand{\set}[1]{\left\lbrace #1 \right\rbrace}
\newcommand{\less}{\backslash}

\title{A language for mathematical\\ knowledge management}


\author{Steven Kieffer\inst{1} \and Jeremy Avigad \inst{2} \and 
  Harvey Friedman\inst{3}\thanks{Work by Avigad and Friedman partially
  supported by NSF grant DMS-0700174.}}

\institute{Simon Fraser University \and Carnegie Mellon University \and 
  Ohio State University}

\begin{document}

\maketitle

\begin{abstract}
  We argue that the language of Zermelo Fraenkel set theory with
  definitions and partial functions provides the most promising
  bedrock semantics for communicating and sharing mathematical
  knowledge. We then describe a syntactic sugaring of that language
  that provides a way of writing remarkably readable assertions
  without straying far from the set-theoretic semantics. We illustrate
  with some examples of formalized textbook definitions from
  elementary set theory and point-set topology. We also present
  statistics concerning the complexity of these definitions, under
  various complexity measures.
\end{abstract}

\section{Introduction}

With the growing use of digital means of storing, communicating,
accessing, and manipulating mathematical knowledge, it becomes
important to develop appropriate formal languages for the
representation of such knowledge. But the scope of
``mathematical knowledge'' is broad, and the meaning of the word
``appropriate'' will vary according to the application. At the
extremes, there are competing desiderata:
\begin{itemize}
\item At the \emph{foundational level}, one wants a small and simple
  syntax, and a precise specification of its semantics. In particular,
  one wants a specification as to which inferences are valid.
\item At the \emph{human level}, one wants to have mathematical
  languages that are as easy to read and understand as ordinary
  mathematical texts, yet also admit a precise interpretation to the
  foundational level.
\end{itemize}
For ordinary working mathematicians, the foundational interpretation
is largely irrelevant, but some sort of formal semantics is necessary
if the information encoded in mathematical texts is to be used and
manipulated at the formal level. Of course, one solution is simply to
pair each informal mathematical assertion with a formal translation,
but then there is the problem of obtaining the formal translations and
ensuring that they match the intention of the informal text. As a
result, it is more promising to use semi-structured languages that
integrate features of both the foundational and human levels.  This
results in a smooth spectrum of languages in between the two extremes.
At intermediate ``expert user'' levels, one may want a language whose
structure is close to that of the underlying foundational framework,
yet is as humanly readable as possible.

To complicate matters, there are features of mathematical knowledge
that are not captured at the level of assertions: mathematical
language is used to communicate definitions, theorems, proofs,
algorithms, and problems, among other things. At the level of a
mathematical theory, language is also used to communicate
relationships between these different types of data. The formal
information that is relevant will vary depending on the application
one has in mind, be it database access and search, theorem proving,
formal verification, etc.

Here we will be primarily concerned with mathematical assertions as
they are used to state definitions and theorems.\footnote{In passing,
  we note that computational proof assistants like Mizar
  \cite{rudniki:92}, HOL~\cite{gordon:melham:93},
  Isabelle~\cite{nipkow:et:al:02}, Coq~\cite{bertot:casteran:04} and
  HOL light~\cite{harrison:96} all provide languages that can be used
  to describe mathematical proofs. Of these, the Mizar and
  Isabelle/Isar languages model human proof languages most closely.
  The Isar effort~\cite{wenzel:07} shows that the proof language is
  somewhat orthogonal to the assertion language; that is, Isar can be
  instantiated to various foundational frameworks, subject only to
  minor constraints.} If one is looking for a foundational
framework that is robust enough to subsume those used by most systems
of MKM, it is hard to beat the language of set theory: we know of no
foundational system other than Quine's New Foundations that cannot be
interpreted in the language of set theory in such a way that
inferences are reduced to inferences in Zermelo-Fraenkel set theory
with the axiom of choice (), or some plausible extension
(say, with large universes of sets). To be clear, we are not denying
the importance of other frameworks for more specific purposes.  For
example, the theory of real closed fields is appropriate to
representing many constraint problems, and constructive frameworks are
better suited to certain forms of algorithmic reasoning. It is also
important to find ways of sharing the additional information that
comes with the use of these more restricted frameworks. We are simply
singling out set theory as a unifying framework for expressing what
assertions in the various local frameworks have in common.

We extend the foundational framework in two ways. First, we allow for
explicit definitions of new predicates and functions on the universe
of sets. And, second, we allow function symbols to denote functions
that are only partially defined, using a logic of partial terms. We
call the resulting formal system . As we observe in
Section~\ref{dzfc:section}, this system is easily shown to be
conservative over .  We argue that these extensions are
\emph{not} just a matter of syntactic sugar, but, rather, are
essential to adequate representation of the mathematical data: there
is a difference between assertions using defined terms and their
expanded versions, and, in mathematical terms,  really is an
undefined quantity. Thus  is our proposal for a
foundational language and its semantics.

Our main goal here is to show that the distance between this
foundational level and ordinary mathematical text is not as far as is
commonly supposed, by presenting a syntactically-sugared version of
set theory, , that is simultaneously close to both. On the
one hand, we show that our language is easily parsed and translated to
. On the other hand, by automatically replacing symbolic
expressions with user-provided natural language equivalents, we obtain
output that is humanly readable, and, although not exactly literary,
recognizably faithful to the original mathematical texts. 

We support this last claim with examples from Suppes's \emph{Axiomatic
  set theory} \cite{suppes} and Munkres's \emph{Topology}
\cite{munkres}. In each case, we present our formal input with both
 and our natural language translations.
Indeed, the appendices to
Kieffer~\cite{kieffer:07} provide a corpus of 341 definitions, taken
from Chapters 2--6 of Suppes and Sections 12--38 of Munkres. Examples
of the natural language translations can be found in Appendix B,
below. These examples show that  offers a promising target
semantics for mathematical markup languages, like OMDoc
\cite{kohlhase:06}.

To illustrate the utility of , we describe two pieces of
software that take advantage of both the formal structure of the
definitions and their proximity to the informal text.  First, we
describe statistical studies of the complexity of definitions in our
corpus, measured in various ways. Our analysis shows, not
surprisingly, that expanding definitions to the pure language of set
theory yields formulas that are huge. Perhaps more surprisingly,
quantifier complexity of definitions remains remarkably low, even when
they are expanded to . We also describe software that makes
it possible to explore definitional dependencies, expanding and
compressing nodes via a graphical interface. To be sure, data like
this can be mined from contemporary formal verification
efforts.\footnote{See, for example, the MPTP challenges,
  http://www.cs.miami.edu/tptp/MPTPChallenge/} But mathematical
developments are often changed significantly in the process of
formalization; what distinguishes the data presented here is the
extent to which it faithfully represents the informal texts it is
supposed to model.

Our ``user-friendly'' version of set theory is based on
Friedman~\cite{friedman:unp:05}; see also an earlier version in
Friedman~\cite{friedman:flagg:90}. Most of the work described here,
including the implementation of the parser, the entering of the data
from Suppes's and Munkres's books, and associated software,
constitute Kieffer's MS thesis~\cite{kieffer:07}, written under
Avigad's supervision. The thesis and code described here, as well as
additional samples of the natural language translations, can be found
via Avigad's web page.\footnote{Specifically, see
  http://www.andrew.cmu.edu/user/avigad/Papers/mkm/.}

\section{ with definitions and partial terms}
\label{dzfc:section}

It is widely acknowledged that Zermelo-Fraenkel axiomatic set theory
with the axiom of choice, , is robust enough to accommodate
ordinary mathematical arguments in a straightforward way. The most
notable exceptions are category-theoretic arguments which rely on the
existence of large universes with suitable closure properties; but
these can be formalized in extensions of  with suitable
large cardinal axioms, or by restricting the closure properties of the
universes in question. 

In this section, we describe a conservative extension  of
. This theory incorporates two features that allow for a
more direct and natural mathematical modeling:
\begin{itemize}
\item it accommodates partially defined functions, and hence
  undefined terms; and
\item it allows the introduction of new function and predicate
  symbols to stand for explicitly defined functions and predicates.
\end{itemize}
We describe each of these extensions, in turn. 

To start with,  is based on a free logic, with a special
predicate . This is usually written , and can be
read `` is defined'' or `` denotes.'' The axioms governing the
terms are presented as the ``logic of partial terms'' in Beeson
\cite{beeson:85},  logic in Troesltra and Schwichtenberg
\cite{troelstra:schwichtenberg:00}; see also the very helpful
explanation and overview in Feferman~\cite{feferman:95}. The basic idea
is that variables in the language range over objects in the intended
domain (in our case, sets), but, as function symbols may denote
partial functions, some terms fail to denote. So, for example, the
axioms for universal instantiation are given by . The basic relation symbols of
, which we take to be  and , are assumed only to
hold between terms that denote; thus we have axioms  and . Partial equality  is defined as usual
by the axiom . 

Next, the syntax of ordinary set theory is extended to include
definition descriptions, \emph{\`a la} Russell. Formally, for each
formula , the expression  is a term whose
free variables are just those of , other than . These terms
are governed by the axioms

Thus in  one can show that  is defined if
and only if there is a unique  satisfying , in which case,
 is equal to that . 

Finally, one is allowed to introduce new function symbols and relation
symbols to abbreviate formulas and terms. That is, for each formula
, one can introduce a new function symbol 
with the axiom

and for every formula  one can introduce a new relation
symbol  with the axiom

It is not hard to show that adding the usual axioms of set theory to
this framework yields a conservative extension:

\begin{theorem}
 is a conservative extension of .
\end{theorem}

The proof amounts to an interpretation of partial functions and
elimination of definitions that is by now standard; details can be
found in \cite{troelstra:schwichtenberg:00,kieffer:07}. Note, however,
that the usual method of eliminating defined function symbols and
relation symbols by replacing them by their definiens can result in an
exponential increase in length.

\section{The language of practical set theory, }
\label{PST_section}

We now describe a more flexible language, \emph{Practical set theory},
or , designed by Friedman. This language has two key
features:
\begin{itemize}
\item The language incorporates a healthy amount of syntactic sugar,
  making it possible to express ordinary mathematical definitions and
  assertions in a natural way.
\item The language is easily and efficiently translatable to
  . 
\end{itemize}
In this section we describe some of the features of  and
the translation to . A full and precise specification of
the  and its  semantics can be found in
\cite{kieffer:07,friedman:unp:05}, where it was called the
\emph{Language of Proofless Text}, or .  The claims of
naturality will be supported with examples in the next section and in
Appendix B.

The starting point for  is the usual syntax of first-order
logic. We adopt conventions to distinguish between variables, defined
functions, and relations; application of a defined relation 
to terms  is written with square brackets
, while application of a defined function
 is written with parentheses,
. The usual language of first-order logic is
augmented with a significant amount of ``syntactic sugar,'' to make
the expression of mathematical notions as convenient as
possible. These include the following.

\bigskip

\noindent \emph{Function application for sets.} Any term may be used
as though it were a function, of any arity (including ``infix''). For
example, one may quantify a variable , and then proceed to use it
as though it were a function. In ,  denotes the unique
 such that the ordered pair  is in ,
assuming there is such . The following definition of the unary
predicate {\tt FCN} therefore asserts that  is a function if it is
a set of ordered pairs  in which no  occurs
more than once as the first component of a pair.

\medskip

\myrule

\noindent DEFINITION FS.2.58: 1-ary relation .
.

\myrule

\bigskip

\noindent \emph{Finite sets and tuples.} In the previous example, we saw a finite tuple; namely, the ordered pair . Tuples of any finite length are terms in .

A finite set can be denoted by simply listing all of its elements. For example, in defining the Wiener-Kuratowski ordered pair, we may use the term .

\bigskip

\noindent \emph{Set-builder notation.} The example above illustrates
the use of set-builder notation. In , the term 
denotes the set of all values of , where the
variables  occurring in  range over tuples
satisfying . Note that this involves an essential
use of partiality; for example, in the intended semantics, the term
 is undefined.

Suppose we wish to define  to be the
set of all  such that . The expression
 is
not what we want, because  on the right-hand side is taken to be a
bound variable ranging over the universe of sets. Instead, 
has us write

to indicate that the expression depends on a fixed value of . 

\bigskip

\noindent \emph{Defined function symbols.} We use an exclamation mark
in place of Russell's  as a definite description operator.
It is used in the next example, where we define an infix function,
, for addition on the rational numbers. Every infix function
is given a \emph{precedence} number, for use in determining order of
operations.

\medskip

\myrule

\noindent DEFINITION FS.5.25: Infix function . 

\noindent . Precedence 40.

\myrule

\medskip
A definition may be composed of any number of ``If ... then ...'' clauses, and may end with one ``Otherwise ...'' clause, which allows definition by cases, as in the example below. In this example the `Otherwise' clause introduces a condition under which the function is undefined. For this we use the predicate , and this allows for the definition of partial functions.

\medskip

\myrule

\noindent DEFINITION FS.2.3: 1-ary function . If
 then R. Otherwise
.

\myrule

\bigskip

\noindent \emph{Defined relation symbols.} As with functions, we may define infix relations, as in the definition of  on the rational numbers, below.
\medskip

\myrule

\noindent DEFINITION FS.5.24: Infix relation
. .

\myrule

\bigskip

\noindent \emph{Lambda notation.}  includes a lambda operator
which can be used to bind variables and thereby denote functions. In
the example below, we define a binary function called {\tt Cartespow}
(for ``Cartesian power''). This function maps a pair of sets , 
to the set ; i.e., a product of -many copies of . The
definition relies on a previously defined function, {\tt Cartesprod}
(for ``Cartesian product''), a binary function taking a map  and a
set  to the product over  of the sets . The
definition of {\tt Cartespow} uses lambda abstraction to define the
constant function  on the fly, to serve as the first
argument to {\tt Cartesprod}.

\medskip

\myrule

\noindent DEFINITION MunkTop.19.2.5: 2-ary function
. .

\myrule

\bigskip

\noindent \emph{Infix relation chains.} Infix relations may be chained
together in the usual way, as with the 
relation in the example below.

\medskip

\myrule

\noindent DEFINITION MunkTop.13.3.a.basis: 0-ary function
.

\noindent .

\myrule

\bigskip

\noindent \emph{Bounded quantifiers.} Quantified variables and
variables used in set-builder notation may be bounded by any infix
relation, as in the example above.

\bigskip

The translation from  to  is not difficult. Since
our grammar for  is not LL, we used the ACCENT compiler-compiler
\footnote{http://accent.compilertools.net/}, which implements
Earley's algorithm. The latter can parse any context-free grammar in
cubic time, and runs in quadratic time when the grammar is unambiguous
\cite{aho:ullman}.

Appendix A contains a number of examples of  definitions,
together with their translations to . In each case, we
present the  input, a \LaTeX{} representation of that input
generated by the parser, and the translation to . A much
larger corpus of examples --- 183 definitions from Suppes's
\emph{Axiomatic Set Theory} \cite{suppes} and 148 definitions from
Munkres's \emph{Topology} \cite{munkres} --- can be found in
\cite{kieffer:07}. In practice, the translation took at most a few
seconds to process a file containing a dozen large
definitions. Comparing the (\LaTeX{})  output with the (\LaTeX{}
version of the)  input yields a factor of about ,
which is to say, the  translations are actually slightly
shorter.

\section{Natural language output}
\label{NLoutputSection}

The examples of  input in the last section are readable, but
not attractive. It is hard to remember meaning of symbols ``BR'' or
``TOPSP''; it would help to have phrases like ``is a binary relation''
or ``is a topological space.'' In fact, even for logical connectives
like , natural language equivalents like ``and'' are generally
easier to read. In an ordinary mathematical language text, however,
words are not always favored over symbols. For example, defined
functions are usually given symbols:  instead of ``the
greatest common divisor of  and .'' Binary relations like 
and  are usually preferred to ``equal to'' and ``less than.'' On
the other hand, unary relations often represent concepts that are
expanded to words, as shown by the examples above.

In light of these observations, we chose to output natural language
equivalents for the connectives, and allow the user to input natural
language equivalents for defined symbols. For example, with the entry
\begin{center}
\begin{verbatim}
TOPSP:2@
  reln: is a negn: is not a topological space@
  plur:nplu:\end{verbatim}
\end{center}
the user can specify the natural language that should be used in place of the {\tt TOPSP} relation.

In some cases, either symbols or a natural language equivalent can be
used, as in  or ``the set of  such that \ldots.'' It is usually awkward to have natural
language occur as a subterm of a symbolic expression; for example,
consider ``xy.''
Thus we incorporate a monotonicity rule: once a subterm of a term has
been expanded to natural language, natural language versions are
favored from then on. This choice yields, for example, , but also ``the set of  in 
such that  and  is even.''

Accordingly, the user supplies two clauses for a defined function or relation for which symbols are preferred over words:
\begin{verbatim}
\wp:1@
  symb:@
  word:the power set of #0@@
\end{verbatim}
whereas if words are the desired default then just one clause is needed:
\begin{verbatim}
Stdrealtop:0@
  word:the standard topology on @@
\end{verbatim}

Appendix B provides examples of natural language output. We emphasize
that these were generated directly from the  input, using
the additional natural language data, supplied by the user, described
above. Although the definitions are not exactly literary, they are
surprisingly readable, and close to ordinary mathematical text. It is
certainly the case that additional heuristics could be used to render
the output more attractive, and additional markup from the user would
result in improvements. In other words, there is a lot more that can
be done along these lines; our claim here is only that 
offers an auspicious start.

\section{Exploring definitions}

Among the benefits of having a database of definitions is the ability to explore those definitions interactively. We designed two simple programs with which to demonstrate some of the possibilities.

Our first program allows the interactive display and manipulation of
directed acyclic graphs (dags) of conceptual dependencies, as depicted
in Figure 1.

\begin{figure}
\begin{center}
\label{kmap_screenshot}
\epsfig{figure=screen_cropped2.eps, width=\textwidth}
\caption[]{Exploring the definition dag for the Stone-\v Cech compactification.}
\end{center}
\end{figure}

With a second program we gathered statistics on these graphs.
Associated to each definition is the dag of all definitions on which
it depends; by the \emph{size} of this dag we mean the number of
vertices, and by the \emph{depth} of this dag we mean the length of
its longest directed path. Table 1 shows the maximum and mean values
for all definitions in our database.

\begin{table}
\label{dag_data}
\begin{center}
\caption{Max and mean dag sizes and depths}
\begin{tabular}{|r|r|c|c|}
\hline
& & Max & Mean \\\hline
All & Depth & 32 & 10.77 \\
  & Size & 110 & 29.56 \\\hline
Suppes & Depth & 26 & 10.09 \\
  & Size & 77 & 25.91 \\\hline
Munkres & Depth & 32 & 12.25 \\
  & Size & 110 & 36.01 \\
\hline
\end{tabular}
\end{center}
\end{table}
Additional statistics, including data on the quantifier complexity of
definitions in our corpus, can be found in Appendix C. 

\section{Conclusions}

We have argued that one should adopt a language close to definitional
set theory as a uniform language to support communication and exchange
of mathematical results. The particular language we describe here,
\emph{Practical set theory}, fares well in that regard: it
is easy and natural to work with, providing a high-degree of
readability while remaining close to a clear foundational semantics.


\section*{Appendix A: Examples of  input and 
  translations} 
\label{PST_DZFC_appendix}

We consider a few examples of formal definitions, highlighting the
naturality of  over . (The  function
appearing in the  translations is a function defined to
take  to the Wiener-Kuratowski ordered pair .)

\smallskip
\myrule

\medskip

\noindent {\bf Example 1.} Here the description operator is used in
 to bind an ordered pair, so that we are able to refer to
``the unique ordered pair  such that....'' This
translates to a much clumsier expression in , requiring two
additional bound variables.

\medskip
\noindent \emph{ input:}

\vspace{-2mm}

\begin{verbatim}
DEFINITION MunkTop.29.4: 2-ary function Oneptcompactification.
If TOPSP[X,T] then Oneptcompactification(X,T) \simeq
(!<Y,T'>)(
  COMPACTIFICATION[Y,T',X,T] \wedge Y \less X \approx_{C} 1_{N}
).
\end{verbatim}

\noindent \emph{ rendered in \LaTeX{}:}

\medskip
\noindent DEFINITION MunkTop.29.4: 2-ary function
. If \hfil\break 
then  \hfil\break .

\bigskip
\noindent \emph{ translation:}

\medskip
\noindent 

\myrule

\medskip
\noindent {\bf Example 2.} Next observe what happens in ,
where we cannot match the brevity of expression used in our definition
of the {\tt FCN[f]} predicate in  (which says that {\tt f}
is a function).

\bigskip
\noindent \emph{ input:}

\vspace{-2mm}

\begin{verbatim}
DEFINITION FS.2.58: 1-ary relation FCN. FCN[f] \iff
f = {<x,y> : f(x) = y}.
\end{verbatim}

\noindent  \emph{ rendered in \LaTeX{}:}

\medskip
\noindent DEFINITION FS.2.58: 1-ary relation .
.

\bigskip

\noindent \emph{ translation:}

\medskip
\noindent 

\myrule

\medskip

\noindent {\bf Example 3.} Here we see how important the lambda operator is:

\medskip
\noindent \emph{ input:}

\vspace{-2mm}

\begin{verbatim}
DEFINITION MunkTop.19.2.5: 2-ary function Cartespow. Cartespow(A,B)
\simeq Cartesprod((\lambda b \in B)(A),B).
\end{verbatim}

\noindent \emph{ rendered in \LaTeX{}:}

\medskip
\noindent DEFINITION MunkTop.19.2.5: 2-ary function
. .

\bigskip
\noindent \emph{ translation:}

\medskip
\noindent 

\myrule

\section*{Appendix B: Examples of the natural language translations}

In some cases our natural language generating program {\tt pst2nl}
produces output that is quite close to what a human being might
write. For example, from the following  input,

\medskip

DEFINITION MunkTop.13.2: 2-ary function
. If
 then


\noindent .

\medskip
\noindent we get the following NL (natural language) output:

\medskip

\vbox{
\myrule

{\bf Definition:} If  is a basis for a topology on 
then \emph{the topology on  generated by } is the
unique    such that for every 
 ,    if and only if for every 
 , there exists    such that  
 and   .

\myrule
}

Indeed, this is not substantially different from the original text in
Munkres \cite{munkres}, page 78. After defining what it means for
 to be a basis, Munkres says,

\begin{quote}
  If  satisfies these two conditions, then we define the
  \emph{topology  generated by}  as follows:
  A subset  of  is said to be open in  (that is, to be an
  element of ) if for each , there is a basis
  element  such that  and . Note that each basis element is itself an element of
  .
\end{quote}

\medskip What is more common is that the output of {\tt pst2nl} reads
nicely except for a ``run-on'' sound, resulting from insufficient
punctuation. For example:

\medskip

\vbox{
\myrule

{\bf Definition:} If  is a strong simple order on  then
\emph{the basis for the order topology on } is the set of 
such that there exist ,    such that    or
 is a first element in  and    or  is a last
element in  and   .

\myrule
}

In Munkres, page 84, all of this information is spread out over a
numbered list:
\begin{quote}
  \noindent {\bf Definition.} Let  be a set with a simple order
  relation; assume  has more than one element. Let  be
  the collection of all sets of the following types:
\begin{enumerate}
\item All open intervals  in .

\item All intervals of the form , where  is the smallest
  element (if any) of .

\item All intervals of the form , where  is the largest
  element (if any) of .
\end{enumerate}
The collection  is a basis for a topology on , which
is called the \emph{order topology}.
\end{quote}

\medskip
Heuristics, combined with additional user markup, could eventually be
incorporated to help improve the flow and punctuation of the
translations. We have implemented one easy improvement already,
whereby adjacent assertions of a common predicate are combined into a
single assertion using plural form. Thus, from the  input,

\medskip

DEFINITION MunkTop.12.4.a: 3-ary relation
. If
 then
.

\medskip
\noindent we obtain:

\medskip

\vbox{
\myrule

{\bf Definition:} If  and  are
topological spaces then  is \emph{finer} than
 on  if and only if  
.

\myrule
}

This time Munkres is able to make several definitions in a single
paragraph, and can abbreviate a more complex logical locution with
the phrase ``respective situations.''

\begin{quote}
  \noindent {\bf Definition.} Suppose that  and
   are two topologies on a given set . If
  , we say that  is
  \emph{finer} than ; if  \emph{properly}
  contains , we say that  is \emph{strictly
    finer} than . We also say that  is
  \emph{coarser} than , or \emph{strictly coarser}, in
  these two respective situations. We say  is
  \emph{comparable} with  if either  or .
\end{quote}

\medskip
We consider a final example,

\medskip

\noindent DEFINITION MunkTop.13.3.c: 0-ary function
. 
\hfil\break

\hfil\break .

\medskip
\noindent for which the NL output is as follows:

\medskip

\vbox{
\myrule

{\bf Definition:} \emph{The K-topology on } is the
topology on  generated by the standard basis for a
topology on  union the set of   
such that there exists  in the standard basis for a topology on
 such that     .  \myrule }

\medskip There are two sets mentioned in this definition: the set of
 such that ..., and the set of  such that
.... According to the ``monotonicity rule'' described in Section
\ref{NLoutputSection}, the latter is rendered in symbols since it has
no subterm in words; the former is rendered in words since its
subterm, ``the standard basis for a topology on '' has no
symbolic form, and is displayed in words by default.

Another feature of {\tt pst2nl} is apparent in this last example,
where the word ``in'' appears before ``the standard basis....'' We get
this preposition rather than the incorrect phrase ``is in,'' thanks to
the final clause in the user-supplied natural language equivalents for
the  relation:

\vbox{
\begin{verbatim}
\in:infix@
  symb:#0  #1@
  nsym:#0  #1@
  reln:#0 is negn:#0 is not in #1@
  plur:nplu:prep:#0 in #1@@
\end{verbatim}
}

Finally we note that the user is free to suppress artifacts of
formalization, in the NL output. In the  above there is an
inclusion function , and the number  is
subscripted as . None of this shows up in the NL
output.

\medskip Comparison with Munkres, page 82, reveals that he is free to
write in a less regimented form than that of our definitions:
\begin{quote}
  Finally, let  denote the set of all numbers of the form ,
  for , and let  be the collection
  of all open intervals , along with all sets of the form
  . The topology generated by  will be
  called the \emph{-topology} on .
\end{quote}

\section*{Appendix C: Data on quantifier complexity and length}

Our database of definitions entered in  consists of 183
definitions from Suppes's \emph{Axiomatic Set Theory} \cite{suppes}
and 148 definitions from Munkres's \emph{Topology} \cite{munkres}.

\medskip

\noindent \emph{Quantifier complexity data.} For each definition in
our database, we measured quantifier complexity in eight different
ways. In the first place, we considered both alternating quantifier
depth, and non-alternating. Secondly, we considered each definition in
four different states: (1) as given in ; (2) as translated
into ; (3) the \emph{expanded} version of the ,
that is, with all definienda replaced by their definiens, recursively,
until the process halts; and (4) a \emph{partially expanded} version
of the  in which certain low-level, foundational definienda
were left unexpanded, namely: the union, intersection, and set
difference operations, the ordered pair, and powerset functions, the
empty set, and the subset and superset relations. The maximum and mean
depths are presented in Table 2.

\begin{table}
\label{qDepths}
\begin{center}
\caption{Max and mean quantifier depths}
\begin{tabular}{|r|r|r|}
\hline
 & Max & Mean \\\hline
 & 4 & 0.66 \\
unexpanded  & 5 & 1.31 \\
fully expanded  & 1235 & 78.68 \\
partially expanded  & 552 & 38.54 \\\hline
 alternating & 3 & 0.63 \\
unexpanded  alternating & 5 & 1.18 \\
fully expanded  alternating & 422 & 36.19 \\
partially expanded  alternating & 239 & 22.16 \\
\hline
\end{tabular}
\end{center}
\end{table}
It has been said that among actually occurring definitions in
mathematics texts, the maximum alternating quantifier depth is three.
Insofar as  comes close to what actually occurs in
textbooks, the maximum alternating depth of 3 tends to
confirm this conjecture.

Note that the maximum depth after translating into  goes up
to 5. This reflects what we saw in Appendix A, where a definition that
used no quantifiers in  turned out to require them after
translation into .

The maximum depth of 1235 for a fully expanded definition confirms the
necessity of using definitions to package information into manageable
chunks. Meanwhile, the contrast between the total expansion maximum,
and the partial expansion maximum of 552, demonstrates that the
lowest, most foundational definitions, lend quite a bit of this
complexity.

The ratio  of the mean fully expanded depth
to the mean fully expanded alternating depth suggests that quantifiers
often occur in runs of two, before alternating, when definitions are
written in pure set theory. The somewhat lower ratio of  for the partially expanded cases indicates the extent to
which the lowest-level concepts contribute to this doubling of
consecutive quantifiers.

The mean depth for  alternating (again, what comes closest
to what we ordinarily think of as quantifier depth in textbooks) shows
that, while the maximum is three, the most common depths are 0 and
1. The exact number of occurrences are presented in Table 3.

\begin{table}
\label{PSTdepths}
\begin{center}
\caption{Quantifier depth frequencies in }
\begin{tabular}{|c|c|c|}
\hline
 & \multicolumn{2}{|c|}{Occurrences} \\\hline
Depth &  &  alternating \\\hline
0 & 178 & 178 \\
1 & 118 & 120 \\
2 & 30  & 35  \\
3 & 14  & 8   \\
4 & 1   & 0   \\
\hline
\end{tabular}
\end{center}
\end{table}

\noindent \emph{Length data.} As was expected, there is rapid blowup
in the size of definitions when they are expanded. In collecting our
data we set a maximum of  before we stopped counting, and
this maximum was often reached.

In particular, since the development of the real numbers taken from
Suppes \cite{suppes} involves such deep definition trees, any
definition mentioning the real numbers will have enormous expanded
length. For example, the definition of the basis for the standard
topology on the reals (see Section \ref{PST_section}) is just 303
symbols long after initial translation into , but blows up
to over  symbols after expansion.

The longest definition we formalized from Suppes \cite{suppes} was 526
symbols, and the longest from Munkres \cite{munkres} was 714 symbols.



\begin{thebibliography}{10}

\bibitem{aho:ullman} Alfred V.~Aho and Jeffrey D.~Ullman \newblock
  {\em The Theory of Parsing, Translation, and Compiling, volume 1}.
  \newblock Prentice-Hall, Englewood Cliffs, N.J., 1972.

\bibitem{beeson:85}
Michael~J. Beeson.
\newblock {\em Foundations of Constructive Mathematics}.
\newblock Springer, Berlin, 1985.

\bibitem{bertot:casteran:04}
Yves Bertot and Pierre Cast\'eran.
\newblock {\em Interactive theorem proving and program development: Coq'Art:
  The calculus of inductive constructions}.
\newblock Springer, Berlin, 2004.

\bibitem{feferman:95}
Solomon Feferman.
\newblock Definedness.
\newblock {\em Erkenntnis}, 43(3):295--320, 1995.
\newblock Varia with a Workshop on the Foundations of Partial Functions and
  Programming (Irvine, CA, 1995).

\bibitem{friedman:flagg:90}
H.~Friedman and R.~C. Flagg.
\newblock A framework for measuring the complexity of mathematical concepts.
\newblock {\em Adv. in Appl. Math.}, 11(1):1--34, 1990.

\bibitem{friedman:unp:05}
Harvey Friedman.
\newblock Proofless text.
\newblock Manuscript, September 29, 2005.

\bibitem{gordon:melham:93}
M.~J.~C. Gordon and T.~F. Melham, editors.
\newblock {\em Introduction to HOL: A theorem proving environment for
  higher-order logic}.
\newblock Cambridge University Press, 1993.

\bibitem{harrison:96}
John Harrison.
\newblock {HOL} light: a tutorial introduction.
\newblock In Mandayam Srivas and Albert Camilleri, editors, {\em Proceedings of
  the First International Conference on Formal Methods in Computer-Aided
  Design}, pages 265--269, 1996.

\bibitem{kieffer:07}
Steven Kieffer.
\newblock A language for mathematical knowledge management.
\newblock Master's thesis, Carnegie Mellon University, 2007.

\bibitem{kohlhase:06}
Michael Kohlhase.
\newblock {\em OMDoc: An open markup format for mathematical documents}, volume
  4810 of {\em LNAI}.
\newblock Springer, Berlin, 2006.

\bibitem{munkres}
James~R. Munkres.
\newblock {\em Topology}.
\newblock Prentice Hall, Upper Saddle River, N.J., second edition, 2000.

\bibitem{nipkow:et:al:02} Tobias Nipkow, Lawrence Paulson, and Markus
  Wenzel.  \newblock {\em Isabelle/HOL: A Proof Assistant for
    Higher-Order Logic}, volume 2283 of {\em Lecture Notes in Computer
    Science}.  \newblock Springer, Berlin, 2002.

\bibitem{rudniki:92}
P.~Rudnicki.
\newblock An overview of the Mizar project.
\newblock In {\em 1992 Workshop on Types for Proofs and Programs}. Chalmers
  University of Technology, Bastad, 1992.

\bibitem{suppes}
Patrick Suppes.
\newblock {\em Axiomatic Set Theory}.
\newblock Van Nostrand, Princeton, 1960.

\bibitem{troelstra:schwichtenberg:00}
A.~S. Troelstra and Helmut Schwichtenberg.
\newblock {\em Basic Proof Theory}.
\newblock Cambridge University Press, Cambridge, second edition, 2000.

\bibitem{wenzel:07}
Makarius Wenzel.
\newblock Isabelle/Isar --- a generic framework for human-readable proof
  documents.
\newblock {\em Studies in Logic, Grammar, and Rhetoric}, 10(23), 2007.
\newblock From Insight to Proof --- Festschrift in Honour of Andrzej Trybulec,
  edited by R. Matuszewski and A. Zalewska.

\end{thebibliography}

\end{document}
