

\documentclass[11pt,a4paper]{llncs}
\usepackage[left=30mm,right=30mm,top=32mm,bottom=35mm]{geometry}

\usepackage{lineno}
\pagestyle{headings}
\usepackage{latexsym,amsmath,amssymb}
\usepackage{graphicx,epsfig}
\usepackage{algo}
\usepackage{url}
\usepackage{multirow}
\usepackage[nocompress]{cite}

\newcommand{\Suff}{\textit{Suff}}\newcommand{\Pref}{\textit{Pref}}\newcommand{\Fact}{\textit{Fact}}\newcommand{\PL}{P\!L}

\def\swap{\textit{swap}}
\def\polylog{\mathrm{polylog}}

\def\IN{{\mathbb N}}

\newcommand{\select}{{\textit{select}}}
\newcommand{\rank}{{\textit{rank}}}
\renewcommand{\epsilon}{\varepsilon}
\newcommand{\pr}{P}
\newcommand{\pos}{\mathit{pos}}

\newcommand{\PNF}{\mathrm{PNF}}
\newcommand{\LPN}{{\mathcal L}_{\textrm{PN}}}

\newtheorem{observation}{Observation}








\newcommand{\todo}[1]{\marginpar{\tiny #1}}

\begin{document}


\title{On Combinatorial Generation of Prefix Normal Words}


\author{P\'eter Burcsi\inst{1} \and Gabriele Fici\inst{2} \and Zsuzsanna Lipt\'ak\inst{3} \and Frank Ruskey\inst{4} \and Joe Sawada\inst{5}}

\institute{Dept.\ of Computer Algebra,
E\"otv\"os Lor\'and Univ., Budapest, Hungary, 
\email{bupe@compalg.inf.elte.hu}
\and Dip.\ di Matematica e Informatica, University of Palermo, Italy, 
\email{gabriele.fici@math.unipa.it} 
\and Dip.\ di Informatica, University of Verona, Italy, 
\email{zsuzsanna.liptak@univr.it}
\and Dept.\ of Computer Science, University of Victoria, Canada, 
\email{ruskey@cs.uvic.ca}
\and School of Computer Science, University of Guelph, Canada, 
\email{jsawada@uoguelph.ca}
}


\date{}

\maketitle

\begin{abstract}
A prefix normal word is a binary word with the property that no substring has more s than the prefix of the same length. This class of words is important in the context of binary jumbled string matching. In this paper we present an efficient algorithm for exhaustively listing the prefix normal words with a fixed length. The algorithm is based on the fact that the language of prefix normal words is a bubble language, a class of binary languages with the property that, for any word  in the language, exchanging the first occurrence of  by  in  results in another word in the language. We prove that each prefix normal word is produced in  amortized time, and conjecture, based on experimental evidence, that the true amortized running time is . 
\end{abstract}

\section{Introduction}


A binary word of length  is {\em prefix normal} if for all , no substring of length  has more s than the prefix of length . For example,  is not prefix normal because the substring  has more s than the prefix . These words were introduced in~\cite{FL11}, where it was shown that each binary word  has a canonical {\em prefix normal form}  of the same length:  and  are equivalent in a certain sense. 

The study of prefix normal words, and prefix normal forms, is motivated by the string problem known as {\em binary jumbled pattern matching}. In that problem, we are given a text of length  over a binary alphabet, and two numbers  and , and ask whether the text has a substring with exactly  s and  s. While the online version can be solved with a simple sliding window algorithm in  time, the offline version, where many queries are expected, has recently attracted much interest: here an index of size  can be generated which then allows answering queries in constant time~\cite{CFL09}. However, the best construction algorithms up to date have running time O~\cite{BCFL10,MR10}. Several recent papers have yielded better results under specific assumptions, such as word level parallelism or highly compressible strings~\cite{MR12,BFKL13,GG13,CGGLLRT13}, or for constructing an approximate index~\cite{CLWY12}; but the general case has not been improved. It was demonstrated in~\cite{FL11,BFKL13} that prefix normal forms of the text can be used to construct this index. See the Appendix for a brief explanation of this connection.

{\em Jumbled Pattern Matching} (JPM), over an arbitrary alphabet, is a variant of approximate pattern matching: We are given a text and a pattern, and want to answer the question whether the text has a substring which is a permutation of the pattern (existence), or find one or all occurrences of such substrings (occurrence, listing).\footnote{Formally: the Parikh vector of a string  over a finite ordered alphabet  is the vector  s.t.\ for all ,  is the number of occurrences of  in . Given the text  and pattern , we want to find (occurrences of) substrings  of  s.t.\ .}
This problem has also been studied under the terms {\em Abelian pattern matching, Parikh vector matching, and permutation matching}. A closely related problem is that of Parikh fingerprints~\cite{AALS03}.
Applications in computational biology include SNP discovery, alignment, gene clusters, pattern discovery, and mass spectrometry data interpretation~\cite{Boecker07,Benson03,BoeckerJMS08,DuhrkopLMB13,Parida06}. 

For one query, the JPM problem can be solved in optimal linear time with a classical sliding window approach~\cite{BEL04}, while recently, interest has turned towards the indexing problem~\cite{CFL09,KRR13}. Moreover, several variants of the original problem have recently been introduced: approximate JPM \cite{BCFL12_TOCS}, JPM in the streaming model \cite{LLZ12}, JPM on trees and graphs \cite{GHLW13,CGGLLRT13}. 


{\em Bubble languages} are an interesting new class of binary languages defined by the following property:  is a bubble language if, for every word , replacing the first occurrence of  (if any)  by  results in another word in ~\cite{RSW12,Ruskey12,SW12}. A generic generating algorithm for bubble languages was given in~\cite{SW12}, leading to Gray codes for each of these languages, while the algorithm's efficiency depends only on a language-dependent subroutine. In the best case, this leads to CAT (constant amortized time) generating algorithms. Many important languages are bubble languages, among them necklaces, binary Lyndon words, and -ary Dyck words. 




In this paper, we show that prefix normal words form a bubble language and present an efficient generating algorithm which runs in  amortized time per word, and which yields a Gray code for prefix normal words. The best previous generating algorithm for prefix normal words ran in  time, and consisted simply in testing each binary word for the prefix normal property (unpublished). Based on experimental evidence, we conjecture that the running time of our algorithm is in fact   amortized. We also give a new characterization of bubble languages in terms of a closure property in the computation tree of a certain generating algorithm for binary words. 
We prove new properties of prefix normal words and present a linear time testing algorithm for words which have been obtained from prefix normal words via a simple operation. This could lead to a better understanding of prefix normal words and in the long run, to faster  computation of prefix normal forms, and thus contribute to the goal of strongly subquadratic algorithms for binary jumbled pattern matching.



\section{Basics}


A {\em binary word} (or {\em string})  over  is a finite sequence of elements from . Its length  is denoted by . For any , the -th symbol of a word  is denoted by . 
We denote by  the words over  of length , and by  the set of finite words  over . The empty word is denoted by . 
Let . If  for some , we say that  is a \emph{prefix} of  and  is a \emph{suffix} of . A \emph{substring} of  is a prefix of a suffix of . A {\em binary language} is any subset  of .

In the following, we will often write binary words  in a canonical form , where  and . In other words,  is the length of the first, possibly empty, -run of ,  the length of the first -run, and  the remaining, possibly empty, suffix. Note that this representation is unique. We call  the {\em critical prefix} of  and  the {\em critical prefix length} of . We denote by  the number of occurrences in  of character , and by  the set of all binary strings  of length  such that  (the  {\em density} of  is ). 

Given a string , we can obtain another string , the string obtained from  by exchanging the characters in positions  and . 

\subsection{Prefix Normal Words}\label{sec:pnw}

Let . For , we set 
\begin{itemize}
\item , the number of s in the -length prefix of 
\item , the maximum number of s over all substrings of length . 
\end{itemize}

\begin{definition} 
A binary word  is {\em prefix normal} if, for all , . In other words, a word is prefix normal if no substring contains more s than the prefix of the same length.
\end{definition}

For example,  is not prefix normal because the substring  has more s than the prefix . We denote by  the language of prefix normal words. In~\cite{FL11} it was shown that for every word  there exists a unique word , called its {\em prefix normal form}, or , such that for all , , and  is prefix normal. Therefore, a prefix normal word is a word coinciding with its prefix normal form.

{\em Note:} In~\cite{FL11}, the property `prefix normal' was defined both with respect to  and with respect to . Here we restrict ourselves to prefix normal words w.r.t.\ .


\begin{table}[ht]
\centering \begin{small}
\begin{raggedright}

\begin{tabular}{*{2}l @{\hspace{6mm}}||@{\hspace{6mm}} *{2}l}
 \quad  & words with this PNF  &   \quad  & words with this PNF\\
\hline &&&\rule[-2pt]{0pt}{3pt}\\
 & \{\} &  & \{\}\\
 & \{, \}&  & \\
 & \{, \}&  & \\
 & \{, , \}&  & \\
 & \{\}&  & \\
 & \{\}&  & \\
 & \{\}&  &  \\
&&&\\
\hline \vspace{4mm}
\end{tabular}
\end{raggedright}\caption{All prefix normal words of length 5 and their equivalence classes.\label{table:classes5}}
\end{small}
\end{table}


In Table~\ref{table:classes5} we list all prefix normal words of length , and, for each , the set of binary words  such that  (i.e., its equivalence class).
Several methods were presented in~\cite{FL11} for testing whether a word is prefix normal; however, all ran in quadratic time. One open problem given there was that of enumerating prefix normal words (counting). The number of prefix normal words of length  can be computed by checking for each binary word whether it is prefix normal, i.e.\ altogether in  time. In this paper, we present an algorithm that is far superior in that it generates only prefix normal words, rather than testing every binary word; it runs in  time per word; and it generates prefix normal words in cool-lex order, constituting a Gray code (subsequent words differ by a constant number of swaps or flips). 


\subsection{Bubble Languages and Combinatorial Generation}

Here we give a brief introduction to bubble languages, mostly summarising results from~\cite{RSW12,SW12}. We also give a new characterization of bubble languages in terms of the computation tree of a generating algorithm (Obs.~\ref{obs:tree}).

\begin{definition}
A language  is called {\em a bubble language} if, for every word , exchanging the first occurrence of  (if any) by  results in another word in . 
\end{definition}



For example, the languages of Lyndon words, necklaces and pre-necklaces are bubble languages. 
A language  is a bubble language if and only if each of its fixed-density subsets  is a bubble language~\cite{RSW12}. This implies that for generating a bubble language, it suffices to generate its fixed-density subsets.

Next we consider combinatorial generation of binary strings.

Let  be a binary string of length . Let  be the number of s in , and let  denote the positions of the s in . 
Clearly, we can obtain  from the word  with the following algorithm: first swap the last  with the  in position , then swap the st  with the  in position  etc. Note that every  is moved at most once, and in particular, once the 'th  is moved into the position , the suffix  remains fixed for the rest of the algorithm. 

These observations lead us to the following generating algorithm (Fig.~\ref{algo:bubble}), which we will refer to as Recursive Swap Generation Algorithm (like Alg.\ 1 from~\cite{SW12}, which in addition includes a language-specific subroutine). It generates recursively all binary strings from  with fixed suffix , 
where , starting from the string . The call Generate() generates all binary strings of length  with density .  

\begin{figure}
\begin{algorithm}{Generate()}{
\qcomment{current string resides in array }
} 
\qif  and  \\ \qthen 
\qfor \\
\qdo 
 \\
{\em Generate}()\\

\qend
\qfi \\
{\em Visit}()
\end{algorithm}
\vspace{-4mm}
\caption{The Recursive Swap Generation Algorithm\label{algo:bubble}}
\end{figure}



The algorithm swaps the last  of the first -run with each of the s of the first -run, thus generating a new string each, for which it makes a recursive call. During the execution of the algorithm, the current string resides in a global array .  In the subroutine Visit() we can, but do not have to, print the contents of this array; we may just want to increment a counter (for enumeration), or check some property of the current string. The main point of Visit() is that it touches every object once. 


Let  denote the recursive computation tree generated by a call to {\em Generate}().
As an example,  Fig.~\ref{fig:example1} illustrates the computation tree . 
\begin{figure}
\begin{center}
\includegraphics[width=1\textwidth]{GenExample2.pdf}
\caption{\label{fig:example1}The computation tree  for .}
\end{center}
\end{figure}

\noindent The depth of the tree equals , the number of s; while the maximum degree is , the number of s. In general, for the subtree rooted at , we have depth  and maximum degree ; in particular, the number of children of  is exactly . In fact, 's th child has the form . Moreover, the suffix  remains unchanged in the entire subtree, and the computation tree is isomorphic to the computation tree of . This  is called {\em fixed suffix}~\cite{RSW12}. Note also that the critical prefix length  strictly decreases along any downward path in the tree. 

The algorithm performs a post-order traversal of the tree, yielding an enumeration of the strings of  in what is referred to as {\em cool-lex order}~\cite{Wi09,SW12,RSW12}. A pre-order traversal of the same tree, which implies moving line 4 of the algorithm before line 1, would yield an enumeration in {\em co-lex order}. A crucial property of cool-lex order is that any two subsequent strings differ by at most two swaps (transpositions), thus yielding a {\em Gray code}~\cite{RSW12}. 
This can be seen in the computation tree  as follows. Note that in a post-order traversal of , we have:\\

u

\medskip


Let  both be children of . This means that for some  and , we have ,  , and . Let  be a  descendant of  along the leftmost path, i.e.\  for some . Then



\medskip 

We now state a crucial property of bubble languages with respect to the Recursive Swap Generating Algorithm which follows immediately from the definition of bubble languages: 


\begin{observation}\label{obs:tree}
A language  is a bubble language if and only if, for every , its fixed-density subset  is closed w.r.t.\ parents and left siblings in the computation tree  of the Recursive Swap Generating Algorithm. In particular, if , then it forms a subtree rooted in .
\end{observation}

Using this property, the Recursive Swap Generating Algorithm can be used to generate {\em any} fixed-density bubble language , as long as we have a way of deciding, for a node , already known to be in , which is its rightmost child (if any) that is still in . If such a child exists, and it is the th child , then the bubble property ensures that all children to its left are also in . Thus, line  in the algorithm can simply be replaced by ``for ''. Moreover, the Recursive Swap Generating Algorithm, which visits the words in the language in cool-lex order, will yield a Gray code, since because of this closure property,  will again either be the parent, or a node on the leftmost path of the right sibling, both of which are reachable within two swaps, see~\eqref{eq:swap}.

In~\cite{SW12}, a generic generating algorithm was given which moves the job of finding this rightmost child  into a subroutine Oracle(). If Oracle() runs in time , then we have a CAT algorithm. In general, this will not be possible, and a generic Oracle  tests for each child from left to right (or from right to left) whether it is in the language. Because of the bubble property, after the first negative (positive) test, it is guaranteed that no more children will be in the language, and the running time of the algorithm is amortized that of the membership tester. The crucial trick is  that it is not necessary to have a {\em general} membership tester, since all we want to know is which of the children of a node {\em already known to be in } are in ; moreover, the membership tester is allowed to use other information, which it can build up iteratively while examining earlier nodes.

\section{Combinatorial Generation of Prefix Normal Words}~\label{sec:combgenpnw}


In this section we prove that the set of prefix normal words  is a bubble language.  Then, by providing some properties regarding membership testing, we can apply the cool-lex framework to generate all prefix normal words of a given length  and density  in -amortized time.  By concatenating the lists together for all densities in increasing order, we obtain an -amortized time algorithm to list all prefix normal words of length .

\begin{lemma}
\label{lemma:PNbubble}
 The language  is a bubble language.
\end{lemma}

\begin{proof}
Let  be a prefix normal word containing an occurrence of . Let  be the word obtained from  by replacing the first occurrence of  with . Then ,  for some . Let  be a substring of . We have to show that .
 
Note that for any , . In fact, , and for every , . Now if  is contained in  or in , then  is a substring of , and thus . If , with  suffix of  and  prefix of , then  . If , with  prefix of , then , and  is a substring of , thus . 
Else , with  suffix of . We can assume that  is a proper suffix of . Let  be the substring of  of the same length as  and starting one position before  (in other words,  is obtained by shifting  to the left by one position). Since  does not contain  as a substring, we have  for some . If  is a power of 's, then  and the claim holds. Else, , and  is a substring of . Thus . \hfill \qed
\end{proof}



In Fig.~\ref{fig:example2}, we give the computation tree  and highlight the subtree corresponding to .  Since  is a bubble language, by Obs.~\ref{obs:tree} it is closed w.r.t.\ left siblings and parents. However, we still have to find a way of deciding which is the rightmost child of a node that is still in .

\begin{figure}
\begin{center}
\includegraphics[width=1\textwidth]{GenExample2b.pdf}
\caption{\label{fig:example2}The computation tree  for . Prefix normal words in bold.}
\end{center}
\end{figure}




The following lemma states that, given a prefix normal word , in order to decide whether one of its children in the computation tree is prefix normal, it suffices to check the PN-property for one particular length only: the critical prefix length of the child node. Moreover, this check can be done w.r.t.\  only. This fact will be crucial in the generating algorithm.

\begin{lemma}\label{lemma:isPNF}
Let , with , with . Let , i.e.\  padded with s to length . Let . Then , unless one of the following holds:


\begin{enumerate}
\item  has a substring of length  with at least  s, or 
\item the string  has at least  s.
\end{enumerate}

Moreover, the latter is the case if and only if  (where by convention, we regard a prefix of negative length as the empty word).

\end{lemma}

\begin{proof}
Let's assume that . Then there is a substring  of  s.t.\ . Let  be the length of .

{\em Case 1.}  is a substring of . Since , therefore . Since also , this implies , because for all other arguments,  and  coincide. Note that  must have an occurrence in  which contains neither of the swapped bits, else it would not be a substring of . Thus  starts at some position to the right of . Therefore we can write , with  a substring of ; in particular, if  is a substring of , then  and ; otherwise,  is a prefix of . Now set , with  the substring of  of length  following . Then  has length , and since ,  it contains at least  many s.

{\em Case 2.}  is not a substring of . Therefore it contains at least one of the two swapped bits. It cannot contain the swapped  (in position ) because then it would be preceded only by s, in which case the prefix of  of length  could not have fewer s than . Thus,  contains the swapped  only (in position ). If , then the prefix of  of length  overlaps with , i.e.\ we can write  and  for some non-empty  containing the swapped . Since , this implies that also  has more s than the prefix of the same length. Since  is a substring of , we are back in Case 1. 

So we have . We can write , with  prefix of . Now remove the starting s from  and extend it to the right to get , with  be the prefix of  of length . Then  and . Moreover, . \hfill \qed
\end{proof}


\begin{corollary}\label{coro:isPNF}
Given . If we know  and , then it can be decided in constant time whether  is prefix normal.
\end{corollary}

\begin{lemma}
\label{lemma:FPCalculate}
Let , with . Then for all ,



\end{lemma}

\begin{proof}
A substring of length  either uses the new  in the first position, or it does not. If it does, then it is a prefix of  and its number of s is given by . Else it is a substring of , and its number of s is given by  for  up to the length of , or by the number of s in , , if  spans all of . \hfill \qed
\end{proof}



\begin{corollary}\label{coro:F}
The -function of  for node  can be computed in linear time based on the -function of 's parent node.
\end{corollary}


By applying these results, the algorithm {\em GeneratePN()}  can be used to generate  in cool-lex Gray code order.  Starting from the left child and proceeding right (with respect to the computation tree ), the algorithm will make a recursive call until a child is no longer prefix normal. 
The membership test is done in the subroutine {\em isPN}, which uses the conditions of Lemma~\ref{lemma:isPNF}. The algorithm maintains an array  which contains the maximum number of s in -length substrings of  (the -function of ), and a variable . Before testing the first child, in {\em update()}, it computes the current 's -function based on the parent's (Corollary~\ref{coro:F}). Note that it is not necessary to compute all of the -function, since all nodes in the subtree have critical prefix length smaller than , thus this update is done only up to length . After the recursive calls to the children, the array is restored to its previous state in {\em restore()}. The variable  contains the number of s in the prefix of  which is spanned by the substring of case 2. of Lemma~\ref{lemma:isPNF}, for the first child. It is updated in constant time after each successful call to {\em isPN}, to include the number of s in the two following positions in .




\begin{figure}
\begin{algorithm}{GeneratePN()}{
\qcomment{ must be prefix normal}}
\qif  {\bf and}  \\
\qthen {\em update}\\
 \\
\\
\qwhile  {\bf and} {\em isPN}()\\
\qdo \\
{\em GeneratePN}()\\
{\em update} \\
\\

\qend \\
{\em restore}()
\qfi \\
{\em Visit}()
\end{algorithm}
\vspace{-4mm}
\caption{Algorithm generating all prefix normal words in the subtree rooted in .\label{algo:genPN1}}
\end{figure}

\noindent  By concatenating the lists of prefix normal words with densities , we obtain an exhaustive listing of .


\begin{figure}
\begin{algorithm}{GeneratePN()}{
\qcomment{generates all prefix normal words of length }}
\qfor \\
\qdo initialize  of length  with all s\\
{\em GeneratePN()}
\qend
\end{algorithm}
\caption{Algorithm generating all prefix normal words of length .\label{algo:genPN2}}
\end{figure}

As an example, a call to {\em GeneratePN()} produces the following list of prefix normal words of length 5:
\small

\normalsize
These strings are also given in Sec.~\ref{sec:pnw}.  Since the fixed-density listings are a cyclic Gray code (Theorem 3.1 from \cite{RSW12}), it follows that this complete listing is also a Gray code.  In fact, if the fixed-density listings are listed by the odd densities (increasing), followed by the even densities (decreasing), the resulting listing would be a cyclic Gray code.



\begin{theorem}
Algorithm {\em GeneratePN()} generates all prefix normal words of length  in amortized  time per word. 
\end{theorem}

\begin{proof}
Since  is prefix normal for every , we only need to show that the correct subtrees of  are generated by the algorithm. By Lemma~\ref{lemma:isPNF}, only those children will be generated that are prefix normal; on the other hand, by the bubble property (Obs.~\ref{obs:tree}), as soon as a child tests negative, no further children will be prefix normal. The running time of the recursive call on  consists of (a) updating and restoring  (lines 2 and 9): the number of steps equals the critical prefix length of , which is ; (b) computing  (line 3): again , the critical prefix length of , many steps, so ; and (c) work within the while-loop (lines 5 to 8), which, for a word with  prefix normal children, consists of  positive and  negative membership tests, of  updates of , and the recursive calls on the positive children. The membership tests take constant time by Corollary~\ref{coro:isPNF}, so does the update of . Since  has  prefix normal children, we charge the positive membership tests and the -updates to the children, and the negative test to the current word.
So for one word , we get  work.
\hfill \qed 
\end{proof}




\section{Experimental results}
\newcommand{\pnn}{\ensuremath{\textit{pnw}}}

In this section we present some theoretical and numerical results about the number of prefix normal words and their structure. These have become available thanks to the algorithm presented, which allowed us to generate  up to length 50 on a home computer. 
Let . The following lemma follows from the observation that  is a prefix normal word of length  for all words  of length .

\begin{lemma}
The number of prefix normal words grows exponentially in . We have that . 
\end{lemma}

The first members of the sequence  are listed in \cite{sloane2}, and these values suggest that the lower bound above is not sharp. We turn our attention to the growth rate of  as  increases. Note that . The lower bound follows form the fact that all prefix normal words can be extended by adding a  to the end, and the upper bound is implied by the prefix-closed property of .  Fig.~\ref{figGrowth} (left) shows the growth ratio for small values of . The figure shows two interesting phenomena: the values seem to approach 2 slowly, i.e., the number of prefix normal words almost doubles as we increase the length by 1. Second, the values show on oscillation pattern between even and odd values. We have so far been unable to establish these observations theoretically.

\begin{figure}
\begin{minipage}[c]{8cm}
\begin{center}
\includegraphics[scale=0.25]{pnf_increase_ratio.pdf}
\end{center}
\end{minipage}
\begin{minipage}[c]{8cm}
\begin{center}
\includegraphics[scale=0.25]{st_growth.pdf}
\end{center}
\end{minipage}
\caption{The value of  (left), and of  for prefix normal words for  (right).} 
\label{figGrowth}
\label{figSTGrowth}
\end{figure}

The structure of prefix normal words is also relevant for the generation algorithm, since the amortized running time of the algorithm is bounded above by the average value of the critical prefix length  taken over all prefix normal words. This differs from the expected critical prefix length of the prefix normal form of a uniformly random word. For the latter we have the following result.

\begin{lemma}\label{lemma:random_pnf_st}
Given a random word , let . Let  denote the critical prefix length of . Then for the the expected value of  we have .
\end{lemma}

\begin{proof} 
Write  in the usual form, i.e.\ with , and consider the random variables  and . It is known that the expected maximum length of a run of 1s in a random word is \cite{GO80}. Clearly,  equals the length of the longest run of s of , thus . To determine , consider a -run of  of maximum length . If  has at least another occurrence of , then there is a substring of  consisting of the maximal -run and one more ; the number of 's in this substring is an upper bound on . Since these s form a single -run, their number is again  in expectation. If on the other hand, all occurrences of  in  are in the maximal run, then  so . The number of words with at most one -run is . So we have: 

\end{proof}


The expected value of the critical prefix length for prefix normal words is shown in Fig.~\ref{figSTGrowth} (right) for , on a loglinear scale. We conjecture that  is polylogarithmic for prefix normal words. The linear alignment of the data points together with lemma \ref{lemma:random_pnf_st} seems to support that.







\section{Conclusion and Open Problems}


We presented a new generating algorithm for prefix normal words, which produces all prefix normal words of length  in amortized linear  time per word. Notice that the number of words that are {\em not} prefix normal also grows exponentially and greatly dominates prefix normal words (e.g., ), so the gain of any algorithm that runs in amortized time per word, over brute-force testing of all binary words, is considerable. 
We believe, moreover, that our algorithm actually runs in time  per word. This could be proved by showing that the expected critical prefix length of a prefix normal word is polylogarithmic in .

In Sec.~\ref{sec:combgenpnw} we gave a linear time testing algorithm for words which are derived from a word  already known to be prefix normal, via a particular operation (swapping the last  of the first 1-run with a  in the first 0-run). This testing algorithm relies both on the knowledge that  is prefix normal, and on the presence of a data structure for  (the -function). We pose as an open problem to find a strongly subquadratic time testing algorithm {\em for arbitrary words}. Another open problem is the computation of prefix normal forms. 
Solving this problem would lead immediately to an improvement for indexed binary jumbled pattern matching.


The observation that our language is a bubble language has opened up
completely new roads. An efficient implementation of the generating algorithm
led to new experimental results which were not available with our previous approach. The obtained
data led to new conjectures and results. We are confident that the connection
to bubble languages will also help in establishing theoretical results about
the number and structure of prefix normal words, and could hopefully lead to a strongly subquadratic testing algorithm.




\begin{small}
\begin{thebibliography}{10}

\bibitem{AALS03}
A.~Amir, A.~Apostolico, G.~M. Landau, and G.~Satta.
\newblock Efficient text fingerprinting via {Parikh} mapping.
\newblock {\em J. Discrete Algorithms}, 1(5-6):409--421, 2003.

\bibitem{BFKL13}
G.~Badkobeh, G.~Fici, S.~Kroon, and {\relax Zs}.~Lipt{\'a}k.
\newblock Binary jumbled string matching for highly run-length compressible
  texts.
\newblock {\em Inf. Process. Lett.}, 113(17):604--608, 2013.

\bibitem{Benson03}
G.~Benson.
\newblock Composition alignment.
\newblock In {\em Proc. of the 3rd International Workshop on Algorithms in
  Bioinformatics (WABI'03)}, pages 447--461, 2003.

\bibitem{Boecker07}
S.~B{\"o}cker.
\newblock Simulating multiplexed {SNP} discovery rates using base-specific
  cleavage and mass spectrometry.
\newblock {\em Bioinformatics}, 23(2):5--12, 2007.

\bibitem{BoeckerJMS08}
S.~B\"ocker, K.~Jahn, J.~Mixtacki, and J.~Stoye.
\newblock Computation of median gene clusters.
\newblock In {\em Proc.\ of the Twelfth Annual International Conference on
  Computational Molecular Biology (RECOMB 2008)}, pages 331--345, 2008.
\newblock LNBI 4955.

\bibitem{BCFL10}
P.~Burcsi, F.~Cicalese, G.~Fici, and {\relax Zs}.~Lipt{\'a}k.
\newblock On {T}able {A}rrangements, {S}crabble {F}reaks, and {J}umbled
  {P}attern {M}atching.
\newblock In {\em Proc.\ of the 5th International Conference on Fun with
  Algorithms ({FUN} 2010)}, volume 6099 of {\em LNCS}, pages 89--101, 2010.

\bibitem{BCFL12_TOCS}
P.~Burcsi, F.~Cicalese, G.~Fici, and {\relax Zs}.~Lipt{\'a}k.
\newblock On approximate jumbled pattern matching in strings.
\newblock {\em Theory Comput. Syst.}, 50(1):35--51, 2012.

\bibitem{BEL04}
A.~Butman, R.~Eres, and G.~M. Landau.
\newblock Scaled and permuted string matching.
\newblock {\em Inf. Process. Lett.}, 92(6):293--297, 2004.

\bibitem{CFL09}
F.~Cicalese, G.~Fici, and {\relax Zs}.~Lipt{\'a}k.
\newblock Searching for jumbled patterns in strings.
\newblock In {\em Proc.\ of the Prague Stringology Conference 2009 (PSC 2009)},
  pages 105--117. Czech Technical University in Prague, 2009.

\bibitem{CGGLLRT13}
F.~Cicalese, T.~Gagie, E.~Giaquinta, E.~S. Laber, {\relax Zs}.~Lipt{\'a}k,
  R.~Rizzi, and A.~I. Tomescu.
\newblock Indexes for jumbled pattern matching in strings, trees and graphs.
\newblock In {\em Proc.\ of the 20th String Processing and Information
  Retrieval Symposium (SPIRE 2013)}, volume 8214 of {\em LNCS}, pages 56--63,
  2013.

\bibitem{CLWY12}
F.~Cicalese, E.~S. Laber, O.~Weimann, and R.~Yuster.
\newblock Near linear time construction of an approximate index for all maximum
  consecutive sub-sums of a sequence.
\newblock In {\em Proc.\ 23rd Annual Symposium on Combinatorial Pattern
  Matching (CPM 2012)}, volume 7354 of {\em LNCS}, pages 149--158, 2012.

\bibitem{DuhrkopLMB13}
K.~D{\"u}hrkop, M.~Ludwig, M.~Meusel, and S.~B{\"o}cker.
\newblock Faster mass decomposition.
\newblock In {\em WABI}, pages 45--58, 2013.

\bibitem{FL11}
G.~Fici and {\relax Zs}.~Lipt{\'a}k.
\newblock On prefix normal words.
\newblock In {\em Proc.\ of the 15th Intern.\ Conf.\ on Developments in
  Language Theory (DLT 2011)}, volume 6795 of {\em LNCS}, pages 228--238.
  Springer, 2011.

\bibitem{GHLW13}
T.~Gagie, D.~Hermelin, G.~M. Landau, and O.~Weimann.
\newblock Binary jumbled pattern matching on trees and tree-like structures.
\newblock In {\em Proc.\ of the 21st Annual European Symposium on Algorithm
  (ESA 2013)}, pages 517--528, 2013.

\bibitem{GG13}
E.~Giaquinta and {\relax Sz}.~Grabowski.
\newblock New algorithms for binary jumbled pattern matching.
\newblock {\em Inf. Process. Lett.}, 113(14-16):538--542, 2013.

\bibitem{GO80}
L.~J. Guibas and A.~Odlyzko.
\newblock Long repetitive patterns in random sequences.
\newblock {\em Zeitschrift f\"ur Wahrscheinlichkeitstheorie und verwandte
  Gebeite}, 53:241--262, 1980.

\bibitem{KRR13}
T.~Kociumaka, J.~Radoszewski, and W.~Rytter.
\newblock Efficient indexes for jumbled pattern matching with constant-sized
  alphabet.
\newblock In {\em Proc.\ of the 21st Annual European Symposium on Algorithm
  (ESA 2013)}, pages 625--636, 2013.

\bibitem{LLZ12}
L.-K. Lee, M.~Lewenstein, and Q.~Zhang.
\newblock Parikh matching in the streaming model.
\newblock In {\em Proc.\ of 19th International Symposium on String Processing
  and Information Retrieval, SPIRE 2012}, volume 7608 of {\em Lecture Notes in
  Computer Science}, pages 336--341. Springer, 2012.

\bibitem{MR10}
T.~M. Moosa and M.~S. Rahman.
\newblock Indexing permutations for binary strings.
\newblock {\em Inf. Process. Lett.}, 110:795--798, 2010.

\bibitem{MR12}
T.~M. Moosa and M.~S. Rahman.
\newblock Sub-quadratic time and linear space data structures for permutation
  matching in binary strings.
\newblock {\em J. Discrete Algorithms}, 10:5--9, 2012.

\bibitem{Parida06}
L.~Parida.
\newblock Gapped permutation patterns for comparative genomics.
\newblock In {\em Proc.\ of the 6th International Workshop on Algorithms in
  Bioinformatics, (WABI 2006)}, pages 376--387, 2006.

\bibitem{RSW12}
F.~Ruskey, J.~Sawada, and A.~Williams.
\newblock Binary bubble languages and cool-lex order.
\newblock {\em J. Comb. Theory, Ser. A}, 119(1):155--169, 2012.

\bibitem{Ruskey12}
F.~Ruskey, J.~Sawada, and A.~Williams.
\newblock De {Bruijn} sequences for fixed-weight binary strings.
\newblock {\em SIAM Journal of Discrete Mathematics}, 26(2):605--517, 2012.

\bibitem{SW12}
J.~Sawada and A.~Williams.
\newblock Efficient oracles for generating binary bubble languages.
\newblock {\em Electr. J. Comb.}, 19(1):P42, 2012.

\bibitem{sloane2}
N.~J.~A. Sloane.
\newblock The {O}n-{L}ine {E}ncyclopedia of {I}nteger {S}equences.
\newblock Available electronically at \url{http://oeis.org}.
\newblock {S}equence {A}194850.

\bibitem{Wi09}
A.~M. Williams.
\newblock {\em Shift {G}ray {C}odes}.
\newblock PhD thesis, University of Victoria, Canada, 2009.

\end{thebibliography}
\end{small}






\section*{Appendix: Connection between prefix normal forms and binary jumbled pattern matching}

\newcommand{\fmax}{F}
\newcommand{\subword}{\sqsubseteq}
\def\pequiv{\sim_P}
\newcommand{\pmax}{\mathop{\rm pmax}}
\newcommand{\pmin}{\mathop{\rm pmin}}
\newcommand{\fmin}{f}
\newcommand{\M}{{\textrm M}}
\renewcommand{\epsilon}{\varepsilon}
\def\P{p}



The linear space solutions for binary pattern matching all rely on a simple property of binary strings, which we refer to as Interval Lemma (folklore): For a binary string  and any fixed length , if  has two substrings of length , with one containing  s, and the other  s, where , then, for any ,  also contains a substring of length  with exactly  s. In other words, all Parikh vectors of substrings of the same length build an interval. The lemma implies that in order to be able to answer existence jumbled pattern matching queries, it suffices to store, for every length , the maximum and minimum number of s in any substring of length :  When querying whether  has a substring with Parikh vector , we can simply ask whether  lies between the maximum and minimum number of s for length . This list of minima and maxima for every length is the linear size index used. The big open question is how to compute it faster than the current  time. 

Now, prefix normal forms of a word  can be used to compute this index. We know that two words have the same Parikh set (Parikh vectors of substrings) if and only if they have the same prefix normal forms both w.r.t.\  and to  (see~\cite{FL11}, Thm.~2). 

In Fig. \ref{fig:esempio}, we present the word  and its prefix normal forms in a standard representation for binary words: Draw in the Euclidean plane the word  by representing each letter  by an upper unit diagonal and each letter  by a lower unit diagonal, starting from the origin . The region between  and  forms exactly the Parikh set of . For example, all substrings of length  have one of the Parikh vectors . 

\begin{figure}
\begin{minipage}{8cm}
\begin{center}
  \includegraphics[height=35mm]{esempio2.pdf}
\end{center}
\end{minipage}
\begin{minipage}{6cm}
\end{minipage}
\begin{minipage}{7cm}
\begin{center}

\end{center}
\end{minipage}
\caption{The word  (dashed line) and its prefix normal forms (grey lines). The area between the two PNFs is the Parikh set of . The vertical line shows all Parikh vectors of substrings of length , namely .}\label{fig:esempio}
\end{figure}





\end{document}
