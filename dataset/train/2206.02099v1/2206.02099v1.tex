

\noindent \textbf{Datasets.} Following the practice of Cylinder3D~\cite{zhu2021cylindrical}, we conduct experiments on two popular LiDAR semantic segmentation benchmarks, \ie, nuScenes~\cite{caesar2020nuscenes} and SemanticKITTI~\cite{behley2019semantickitti}. For nuScenes, it consists of 1000 driving scenes, in which 850 scenes are selected for training and validation, and the remaining 150 scenes are chosen for testing. 16 classes are utilized for LiDAR semantic segmentation after merging similar classes and eliminating infrequent classes. For SemanticKITTI, it is comprised of 22 point cloud sequences, where sequences 00 to 10, 08 and 11 to 21 are used for training, validation and testing, respectively. A total number of 19 classes are chosen for training and evaluation after merging classes with distinct moving status and discarding classes with very few points.

\noindent \textbf{Evaluation metrics.} Following~\cite{zhu2021cylindrical}, we adopt the intersection-over-union (IoU) of each class and mIoU of all classes as the evaluation metric. The calculation of IoU is: $IoU_{i} = \frac{TP_{i}}{TP_{i}+FP_{i}+FN_{i}}$, where $TP_{i}$, $FP_{i}$ and $FN_{i}$ represent the true positive, false positive and false negative of class $i$.

\noindent \textbf{Implementation details.} Following~\cite{zhu2021cylindrical}, we leverage Adam~\cite{kingma2015adam} as the optimizer and the initial learning rate is set as 2e-3. Batch size is set as 4 and the number of training epochs is 40. $\alpha_{1}$, $\alpha_{2}$, $\beta_{1}$ and $\beta_{2}$ are set as 0.1, 0.15, 0.15 and 0.25, respectively. We take the rival and open sourced Cylinder3D\footnote{https://github.com/xinge008/Cylinder3D}~\cite{zhu2021cylindrical} approach as the backbone since the top-performing RPVNet~\cite{Xu_2021_ICCV} and AF2S3Net~\cite{cheng20212} do not release their codes. Random flipping, rotation, scaling and transformation are taken as the data augmentation strategy. The size of the voxel output is 480$\times$360$\times$32, where the three dimensions denote the radius, angle and height, respectively. The size of the supervoxel is set as 120$\times$60$\times$8. $N_{v}$ and $N_{p}$ are set as 3000 and 6000, respectively. The number of sampled supervoxels $K$ is set as 4. The inter-point affinity distillation is performed on the output of the point feature extraction module and the inter-voxel affinity distillation is conducted on the output of the encoder-decoder backbone. For nuScenes, Cylinder3D\_0.5$\times$ is produced from the original Cylinder3D model by pruning 50\% channels for each layer of the whole network. For SemanticKITTI, Cylinder3D\_0.5$\times$ is obtained by merely pruning 50\% channels for each layer of the asymmetrical 3D convolution network and we keep the point feature extraction module unchanged as it is vital to extract rich information from the input point cloud. We also apply our method to compress SPVNAS\footnote{https://github.com/mit-han-lab/spvnas}~\cite{tang2020searching} and MinkowskiNet~\cite{choy20194d} to verify the scalability of our algorithm. More details are provided in the supplementary material. 

\noindent \textbf{Baseline distillation algorithms.} In addition to the state-of-the-art methods in each benchmark, we also compare our method with classical KD methods and contemporary distillation approaches tailored for 2D semantic segmentation, including vanilla KD~\cite{hinton2015distilling}, SKD~\cite{liu2019structured}, CD~\cite{shu2020channel}, IFV~\cite{wang2020intra} and KA~\cite{he2019knowledge}. Here, SKD takes the output probability maps and pairwise similarity maps as mimicking targets. We remove the original holistic distillation loss for SKD as incorporating GANs into current framework will cause severe training instability; CD utilizes the intermediate feature maps and score maps as knowledge; IFV transfers the intra-class feature variation from the teacher to the student; KA makes the student distil the compressed knowledge and the affinity information of the whole output from the teacher.



\subsection{Results}



\noindent \textbf{Comparison with state-of-the-art LiDAR segmentation models:} We compare our model with contemporary LiDAR semantic segmentation models, \eg, KPConv~\cite{thomas2019kpconv}, TORNADONet~\cite{gerdzhev2021tornado} and SPVNAS~\cite{tang2020searching}. From Table~\ref{semantickitti}, we can see that Cylinder3D\_0.5$\times$+\algorithmname~(the penultimate row) achieves comparable performance with the original Cylinder3D model on the SemanticKITTI test set. Compared to KPConv and SPVNAS, our Cylinder3D\_0.5$\times$+\algorithmname~not only achieves better performance, \eg, \textbf{3.8\%} higher than SPVNAS in mIoU, but also has much lower latency than the SPVNAS method (259 ms v.s. 76 ms). Specifically, on minority classes such as bicycle, motocycle and bicyclist, the IoU of Cylinder3D\_0.5$\times$+\algorithmname~is at least \textbf{10.5\%} higher than the SPVNAS method. And with some engineering tricks like finetuning and flip \& rotation test ensemble, our Cylinder3D\_0.5$\times$+\algorithmname~(the last row) can obtain \textbf{71.2} mIoU, which is \textbf{2.3} mIoU higher than the original Cylinder3D model. Impressive performance is also observed in nuScenes validation set. Our Cylinder3D\_0.5$\times$+\algorithmname~exhibits similar performance with the original Cylinder3D network in terms of the overall mIoU and the IoU on each class.

\noindent \textbf{Comparison with previous distillation methods:} From Table~\ref{semantickitti} and~\ref{nuscenes}, we can see that \algorithmname~significantly outperforms baseline distillation algorithms in both benchmarks. The performance gap between \algorithmname~and the most competitive KD method is larger than 1.8. For instance, on SemanticKITTI test set, our \algorithmname~is \textbf{2.8} mIoU higher than the CD method. And on both majority classes and minority classes, our \algorithmname~significantly outperforms traditional distillation algorithms. For instance, on nuScenes dataset, \algorithmname~is at least \textbf{2} mIoU higher than SKD in classes such as bicycle, bus, car, trailer and sidewalk. The aforementioned results strongly demonstrate the effectiveness of \algorithmname~in transferring knowledge for teacher-student learning.

\begin{table*}[t]
\caption{Quantitative results of our proposed method and state-of-the-art LiDAR semantic segmentation methods as well as previous distillation approaches on SemanticKITTI test set. Cylinder3D\_0.5$\times$ is abbreviated as C3D\_0.5$\times$ to save space. * means that finetuning and flip \& rotation test ensemble are applied. All results can be found in the online leaderboard.}
\vskip -0.2cm
\label{semantickitti}
\centering
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c}
\hline
\textbf{Methods} & \textbf{mIoU} & \rotatebox{90}{Latency (ms)} & \rotatebox{90}{car} &  \rotatebox{90}{bicycle} & \rotatebox{90}{motorcycle} & \rotatebox{90}{truck} & \rotatebox{90}{other-vehicle} & \rotatebox{90}{person} & \rotatebox{90}{bicyclist} & \rotatebox{90}{motorcyclist} & \rotatebox{90}{road} & \rotatebox{90}{parking} & \rotatebox{90}{sidewalk} & \rotatebox{90}{other-ground} &
\rotatebox{90}{building} & \rotatebox{90}{fence} & \rotatebox{90}{vegetation} & \rotatebox{90}{trunk} & \rotatebox{90}{terrain} & \rotatebox{90}{pole} & \rotatebox{90}{traffic} \\
\hline
\hline
Salsanext~\cite{cortinhal2020salsanext} & 59.5 & -- & 91.9 & 48.3 & 38.6 & 38.9 & 31.9 & 60.2 & 59.0 & 19.4 & 91.7 & 63.7 & 75.8 & 29.1 & 90.2 & 64.2 & 81.8 & 63.6 & 66.5 & 54.3 & 62.1 \\
\hline
KPConv~\cite{thomas2019kpconv} & 58.8 & 263 & 96.0 & 32.0 & 42.5 & 33.4&44.3&61.5 & 61.6 & 11.8 & 88.8 & 61.3&  72.7&31.6& \bf{95.0} & 64.2 & 84.8 & 69.2 & 69.1 & 56.4 & 47.4 \\
\hline
FusionNet~\cite{zhang2020deep} * & 61.3 & -- & 95.3 & 47.5 & 37.7 & 41.8 & 34.5 & 59.5 & 56.8 & 11.9 & 91.8 & 68.8 & 77.1 & 30.8 & 92.5 & \bf{69.4} & 84.5 & 69.8 & 68.5&60.4 & 66.5 \\ 
\hline
KPRNet~\cite{kochanov2020kprnet} * & 63.1 & -- & 95.5&54.1& 47.9&23.6 & 42.6&65.9 & 65.0 & 16.5 & \bf{93.2} & \bf{73.9} & \bf{80.6} & 30.2 & 91.7 & {68.4} & 85.7 & 69.8 & 71.2 & 58.7 & 64.1 \\
\hline
TORNADONet~\cite{gerdzhev2021tornado} * & 63.1 & --&94.2& 55.7& 48.1& 40.0& 38.2& 63.6& 60.1& 34.9& 89.7& 66.3& 74.5& 28.7& 91.3& 65.6& 85.6& 67.0& 71.5 & 58.0 & {65.9} \\
\hline
SPVNAS~\cite{tang2020searching} * & 66.4 & 259 & \bf{97.3} & 51.5 & 50.8 & 59.8 & 58.8 & 65.7 & 65.2 & 43.7 & 90.2 & 67.6 & 75.2 & 16.9 & 91.3 & 65.9 & 86.1 & 73.4 & 71.0 & 64.2 & 66.9 \\
\hline
Cylinder3D~\cite{zhu2021cylindrical} * & 68.9 & 170 & 97.1 & 67.6 & 63.8 & 50.8 & 58.5 & 73.7 & 69.2 & 48.0 & 92.2 & 65.0 & 77.0 & 32.3 & 90.7 & 66.5 & 85.6 & 72.5 & 69.8 & 62.4 & 66.2 \\
\hline
C3D\_0.5$\times$ & 65.3 & \multirow{8}*{\textbf{76}} & 93.4 & 62.3 & 59.2 & 48.3 & 56.4 & 72.3 & 66.3 & 21.0 & 91.2 & 61.3 & 75.3 & 30.4 & 89.8 & 65.4 & 84.2 & 71.4 & 67.3 & 60.2 & 64.2 \\
\cline{1-2}\cline{4-22}
C3D\_0.5$\times$ + KD & 65.6 & ~ & 93.8 & 62.5 & 59.4 & 48.6 & 55.3 & 72.9 & 66.5 & 21.9 & 91.8 & 61.3 & 75.7 & 30.5 & 90.4 & 65.5 & 84.3 & 71.7 & 67.6 & 60.3 & 64.8 \\
\cline{1-2}\cline{4-22}
C3D\_0.5$\times$ + CD & 66.1 & ~ & 94.5 & 62.7 & 59.8 & 49.3 & 57.2 & 72.1 & 67.1 & 22.7 & 92.1 & 61.4 & 74.9 & 30.8 & 90.9 & 67.3 & 84.6 & 72.2 & 68.3 & 61.1 & 65.1 \\
\cline{1-2}\cline{4-22}
C3D\_0.5$\times$ + IFV & 65.5 & ~ & 93.7 & 62.4 & 59.1 & 48.7 & 56.7 & 72.4 & 66.6 & 21.4 & 91.5 & 62.0 & 75.6 & 30.4 & 90.3 & 66.2 & 84.7 & 71.5 & 67.5 & 60.6 & 64.3 \\
\cline{1-2}\cline{4-22}
C3D\_0.5$\times$ + SKD & 65.8 & ~ & 93.6 & 62.7 & 59.6 & 48.5 & 57.4 & 72.8 & 66.7 & 24.3 & 91.6 & 61.4 & 75.9 & 30.8 & 90.1 & 65.6 & 84.8 & 71.7 & 67.5 & 60.7 & 65.2 \\
\cline{1-2}\cline{4-22}
C3D\_0.5$\times$ + KA & 65.5 & ~ & 93.4 & 62.6 & 58.9 & 48.5 & 56.5 & 72.7 & 66.5 & 20.7 & 91.6 & 61.5 & 75.3 & 30.1 & 89.9 & 65.6 & 84.4 & 71.3 & 67.8 & 60.3 & 65.8 \\
\cline{1-2}\cline{4-22}
\bf{C3D\_0.5$\times$ + \algorithmname} & 68.9 & ~ & 96.7 & 66.4 & 61.0 & \bf{60.0} & 59.3 & 73.2 & 72.1 & 25.0 & 91.4 & 66.5 & 76.2 & 37.1 & 93.0 & 70.5 & 85.9 & 72.7 & 69.8 & 64.1 & \bf{67.8} \\
\cline{1-2}\cline{4-22}
\bf{C3D\_0.5$\times$ + \algorithmname~*} & \bf{71.2} & ~ & 97.0 & \bf{67.9} & \bf{69.3} & 53.5 & \bf{60.2} & \bf{75.1} & \bf{73.5} & \bf{50.5} & 91.8 & 70.9 & 77.5 & \bf{41.0} & 92.4 & \bf{69.4} & \bf{86.5} & \bf{73.8} & \bf{71.9} & \bf{64.9} & 65.8 \\
\hline
\end{tabular}
\end{adjustbox}
\vspace{-2ex}
\end{table*}



\begin{table*}[t]
\caption{Quantitative results of our proposed method and state-of-the-art LiDAR semantic segmentation methods as well as previous distillation approaches on nuScenes validation set.}
\vskip -0.2cm
\label{nuscenes}
\centering
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c}
\hline
\textbf{Methods} & \textbf{mIoU} & \rotatebox{90}{barrier} &  \rotatebox{90}{bicycle} & \rotatebox{90}{bus} & \rotatebox{90}{car} & \rotatebox{90}{construction} & \rotatebox{90}{motorcycle} & \rotatebox{90}{pedestrian} & \rotatebox{90}{traffic-cone} & \rotatebox{90}{trailer} & \rotatebox{90}{truck} & \rotatebox{90}{driveable} & \rotatebox{90}{other} &
\rotatebox{90}{sidewalk} & \rotatebox{90}{terrain} & \rotatebox{90}{manmade} & \rotatebox{90}{vegetation} \\
\hline
\hline
RangeNet++~\cite{milioto2019rangenet++} & 65.5 & 66.0 & 21.3 & 77.2 & 80.9 & 30.2 & 66.8 & 69.6 &  52.1 & 54.2 & {72.3} & {94.1} & 66.6 & 63.5 & 70.1 & 83.1 & 79.8 \\
\hline
PolarNet~\cite{zhang2020polarnet} & 71.0 & 74.7 & 28.2 & 85.3 & 90.9 & 35.1 & 77.5 & 71.3 & 58.8 & 57.4 & 76.1 & 96.5 & 71.1 & 74.7 & {74.0} & 87.3 & 85.7  \\
\hline
Salsanext~\cite{cortinhal2020salsanext} & 72.2 & 74.8 & 34.1 & 85.9 & 88.4 & 42.2 & 72.4 & 72.2 & 63.1 & 61.3 & 76.5 & 96.0 & 70.8 & 71.2 & 71.5 & 86.7 & 84.4 \\
\hline
\hline
Cylinder3D~\cite{zhu2021cylindrical} & \bf{76.1} & \bf{76.4} & \bf{40.3} & \bf{91.2} & 93.8 & \textbf{51.3} & \bf{78.0} & \bf{78.9} & \bf{64.9} & \bf{62.1} & \bf{84.4} & \bf{96.8} & \bf{71.6} & \bf{76.4} & 75.4 & \bf{90.5} & \bf{87.4}  \\
\hline
C3D\_0.5$\times$ & 73.6 & 74.6 & 36.2 & 88.2 & 87.3 & 47.9 & 76.4 & 77.0 & 63.4 & 58.8 & 82.3 & 95.1 & 70.0 & 73.5 & 73.6 & 88.7 & 85.2 \\
\hline
C3D\_0.5$\times$ + KD & 73.9 & 75.2 & 35.4 & 88.3 & 88.2 & 47.6 & 76.8 & 77.2 & 63.6 & 57.3 & 83.1 & 95.7 & 70.1 & 75.2 & 73.1 & 89.2 & 85.3 \\
\hline
C3D\_0.5$\times$ + CD & 74.1 & 75.4 & 36.1 & 88.4 & 89.3 & 46.9 & 76.1 & 77.6 & 62.9 & 58.0 & 84.3 & 96.0 & 70.3 & 74.8 & 74.6 & 90.1 & 85.6 \\
\hline
C3D\_0.5$\times$ + IFV & 73.8 & 74.7 & 36.6 & 88.3 & 88.6 & 47.2 & 76.7 & 77.1 & 63.1 & 58.2 & 83.5 & 95.1 & 70.2 & 73.4 & 73.8 & 88.9 & 84.3 \\
\hline
C3D\_0.5$\times$ + SKD & 74.2 & 74.9 & 37.3 & 87.6 & 89.1 & 47.5 & 76.2 & 77.4 & 63.2 & 59.3 & 83.4 & 95.9 & 70.4 & 73.9 & 74.3 & 90.3 & 87.1 \\
\hline
C3D\_0.5$\times$ + KA & 73.9 & 74.2 & 36.3 & 88.5 & 87.6 & 47.1 & 76.9 & 78.3 & 63.5 & 57.6 & 83.4 & 94.9 & 70.3 & 73.8 & 73.2 & 88.4 & 86.3 \\
\hline
\bf{C3D\_0.5$\times$ + \algorithmname~} & 76.0 & 76.2 & 40.0 & 90.2 & \bf{94.0} & 50.9 & 77.4 & 78.8 & 64.7 & 62.0 & 84.1 & 96.6 & 71.4 & 76.4 & \bf{76.3} & 90.3 & 86.9 \\
\hline
\end{tabular}
\end{adjustbox}
\vspace{-3ex}
\end{table*}

\begin{comment}
C3D\_0.5$\times$ \\
\hline
\end{comment}


\begin{table}[!t]
\caption{Performance of different algorithms on compressing SPVNAS and MinkowskiNet on SemanticKITTI validation set.}
\vskip -0.3cm
\label{spvnas_table}
\centering
\small{
\begin{tabular}{c|c|c}
\hline
Algorithm & mIoU & MACs (G) \\
\hline
\hline
SPVNAS~\cite{tang2020searching} & \bf{63.8} & 118.6 \\
\hline
SPVNAS$\_$0.5$\times$ & 60.4 & \multirow{4}*{29.7}  \\
\cline{1-2}
SPVNAS$\_$0.5$\times$ + CD & 60.9 & ~ \\
\cline{1-2}
SPVNAS$\_$0.5$\times$ + SKD & 61.2 & ~ \\
\cline{1-2}
\textbf{SPVNAS$\_$0.5$\times$ + \algorithmname~} & \textbf{63.8} & ~ \\
\hline \hline
MinkowskiNet~\cite{choy20194d} & 61.9 & 114.0 \\
\hline
MinkowskiNet$\_$0.5$\times$ & 58.9 & \multirow{4}*{28.5}  \\
\cline{1-2}
MinkowskiNet$\_$0.5$\times$ + CD & 59.6 & ~ \\
\cline{1-2}
MinkowskiNet$\_$0.5$\times$ + SKD & 59.4 & ~ \\
\cline{1-2}
\textbf{MinkowskiNet$\_$0.5$\times$ + \algorithmname~} & 61.8 & ~ \\
\hline
\end{tabular}
}
\vspace{-4ex}
\end{table}


\noindent \textbf{Generalization to more architectures:} To verify the generalization of our method, we also apply \algorithmname~to compress SPVNAS~\cite{tang2020searching} and MinkowskiNet~\cite{choy20194d}. Since SPVNAS does not provide the training code for the NAS-based architecture, we conduct experiments on its manually designed architecture. As can be seen from Table~\ref{spvnas_table}, our \algorithmname~still brings more gains to the student model than baseline distillation algorithms. For instance, our \algorithmname~outperforms the SKD algorithm by \textbf{2.6} mIoU in terms of mIoU on the SPVNAS backbone. It is noteworthy that \algorithmname~can safely achieve 75\% MACs reduction without causing severe performance drop. The above results strongly demonstrate the good scalability of our method.


\begin{figure*}[t]
 \centering
 \includegraphics[width=1.0\linewidth]{./visual_comparison.pdf}
 \vskip -0.3cm
 \caption{Visual comparison of different methods on the SemanticKITTI validation set. Here, the ground-truth for the inter-voxel affinity map is the ideal map where the intra-class similarity score is 1 and inter-class similarity score is 0.}
 \centering
 \vskip -0.6cm
 \label{fig:visual_compare}
\end{figure*}

\noindent \textbf{Qualitative results:} As can be seen from Fig.~\ref{fig:visual_compare}, compared with the SKD approach, our \algorithmname~greatly improves the prediction of the student model. The prediction errors of \algorithmname~on those minority classes, \eg, person and bicycle, are significantly smaller than those of SKD. Besides, on objects that are faraway from the origin, \eg, the car highlighted by the green rectangle, \algorithmname~also yields more accurate predictions than SKD. And \algorithmname~has lower inter-class similarity and higher intra-class similarity, which explicitly showcases the efficacy of \algorithmname~in distilling structural knowledge from the teacher model.     

\noindent 


\subsection{Ablation studies}

In this section, we perform comprehensive ablation studies to examine the efficacy of each component, supervoxel size as well as the sampling strategy on the final performance. The experiments are conducted in the SemanticKITTI validation set. More ablation studies are put in the supplementary material.

\begin{table}[!t]
\caption{Influence of each component on the final performance.}
\label{each_component_table}
\centering
\vskip -0.3cm
\small{
\begin{tabular}{c|c|c|c|c}
\hline
$\mathcal{L}_{out\_p}$ & $\mathcal{L}_{out\_v}$ & $\mathcal{L}_{aff\_p}$ & $\mathcal{L}_{aff\_v}$ & mIoU \\
\hline
        &         &         &         &  63.1 \\
$\surd$ &         &         &         &  63.4 \\
$\surd$ & $\surd$ &         &         &  64.1 \\
$\surd$ & $\surd$ & $\surd$ &         &  64.7 \\
$\surd$ & $\surd$ & $\surd$ & $\surd$ &  66.4 \\
\hline
\end{tabular}
}
\vspace{-4ex}
\end{table}


\noindent \textbf{Effect of each component.} From Table~\ref{each_component_table}, we have the following observations: 1) Combining both point-to-voxel output distillation and affinity distillation brings the most performance gains. 2) The voxel-level distillation brings more gains than the point-level distillation, suggesting the necessity of introducing the voxel-level mimicking loss. 3) The affinity distillation yields more gains than the output distillation, demonstrating the importance of leveraging the relational knowledge to better capture the structural information. 

\begin{table}[!t]
\caption{Effect of supervoxel size on the performance.}
\label{supervoxel_size_table}
\centering
\vskip -0.3cm
\small{
\begin{tabular}{c|c}
\hline
supervoxel size & mIoU \\
\hline
(60, 30, 4) & 65.3 \\
\hline
(90, 45, 6) & 65.7 \\
\hline
(120, 60, 8) & 66.4 \\
\hline
(180, 90, 12) & 65.6 \\
\hline
(240, 180, 16) & 65.2 \\
\hline
\end{tabular}
}
\vspace{-3ex}
\end{table}

\noindent \textbf{Supervoxel size.} Note that we perform the inter-point and inter-voxel distillation on the sampled supervoxels. Supervoxel size has a non-negligible effect on the efficacy of \algorithmname~since a overly small size will make student learn little from the affinity distillation loss while a large supervoxel size will weaken the learning efficiency of \algorithmname. Here, we keep the number of sampled supervoxels as 4 to remove the effect of this factor. From Table~\ref{supervoxel_size_table}, we can see that setting the supervoxel size to (120, 60, 8) yields the best performance. Remarkably increasing or decreasing the supervoxel size will harm the distillation efficacy.   



\begin{figure}[t]
 \centering
 \includegraphics[width=0.75\linewidth]{./sampling_strategy.pdf}
 \vskip -0.2cm
 \caption{Comparison between different sampling strategies.}
 \centering
 \vskip -0.5cm
 \label{fig:sampling_compare}
\end{figure}

\noindent \textbf{Sampling strategy.} We compare four different sampling strategies, \ie, the original difficulty-aware sampling, distance-aware sampling, category-aware sampling and random sampling. Here, distance-aware sampling is to only more frequently sample distant points while category-aware sampling will more likely sample points belonging to rare classes. From Fig.~\ref{fig:sampling_compare}, it is apparent that difficulty-aware sampling brings more gains than the other three strategies. Specifically, difficulty-aware sampling outperforms both distance-aware and category-aware sampling, suggesting that both distance and categorical awareness are crucial to the distillation effect. The large gap between difficulty-aware sampling and random sampling validates the necessity of difficulty-aware sampling strategy. 