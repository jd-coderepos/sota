\documentclass{article} \usepackage{iclr2018_conference,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{kotex}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{footnote}
\usepackage[bottom]{footmisc}
\usepackage{subcaption}
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{makecell}
\usepackage{diagbox}
\usepackage{color}
\usepackage{colortbl}
\usepackage{array}
\usepackage{amsmath}
\usepackage{amssymb}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\renewcommand{\vec}[1]{\mathbf{#1}}

\title{Finding ReMO (Related Memory Object): \\
A Simple Neural Architecture \\ for Text based Reasoning}




\author{Jihyung Moon\thanks{Code is publicly available at: https://github.com/juung/RMN} , Hyochang Yang, Sungzoon Cho \\
Department of Industrial Engineering\\
Seoul National University\\
Seoul, South Korea\\
\texttt{\{jhmoon, hyochang\}@dm.snu.ac.kr, zoon@snu.ac.kr}}



\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy 

\begin{document}


\maketitle

\begin{abstract}
To solve the text-based question and answering task that requires relational reasoning, it is necessary to memorize a large amount of information and find out the question relevant information from the memory.
Most approaches were based on external memory and four components proposed by Memory Network.
The distinctive component among them was the way of finding the necessary information and it contributes to the performance.
Recently, a simple but powerful neural network module for reasoning called Relation Network (RN) has been introduced. 
We analyzed RN from the view of Memory Network, and realized that its MLP component is able to reveal the complicate relation between question and object pair.
Motivated from it, we introduce \textit{Relation Memory Network (RMN)} which uses MLP to find out relevant information on Memory Network architecture.
It shows new state-of-the-art results in jointly trained bAbI-10k story-based question answering tasks and bAbI dialog-based question answering tasks.
\end{abstract}

\section{Introduction}

Neural network has made an enormous progress on the two major challenges in artificial intelligence: seeing and reading.
In both areas, embedding methods have served as the main vehicle to process and analyze text and image data for solving classification problems. As for the task of logical reasoning, however, more complex and careful handling of features is called for.
A reasoning task requires the machine to answer a simple question upon the delivery of a series of sequential information. For example, imagine that the machine is given the following three sentences: ``Mary got the milk there.'',  ``John moved to the bedroom.'', and ``Mary traveled to the hallway.'' 
Once prompted with the question, ``Where is the milk?", the machine then needs to sequentially focus on the two supporting sentences, ``Mary got the milk there." and ``Mary traveled to the hallway." in order to successfully determine that the milk is located in the hallway.

Inspired by this reasoning mechanism, \citet{Weston15} has introduced the memory network (MemNN), which consists of an external memory and four components: input feature map ($I$), generalization ($G$), output feature map ($O$), and response ($R$).
The external memory enables the model to deal with a knowledge base without loss of information. 
Input feature map embeds the incoming sentences. Generalization updates old memories given the new input and output feature map finds relevant information from the memory. Finally, response produces the final output.

Based on the memory network architecture, neural network based models like end-to-end memory network (MemN2N)~\citep{sukhbaatar2015end}, gated end-to-end memory network (GMemN2N)~\citep{liu2017gated}, dynamic memory network (DMN)~\citep{kumar2016ask}, and dynamic memory network + (DMN+)~\citep{xiong2016dynamic} are proposed.
Since strong reasoning ability depends on whether the model is able to sequentially catching the right supporting sentences that lead to the answer, the most important thing that discriminates those models is the way of constructing the output feature map. As the output feature map becomes more complex, it is able to learn patterns for more complicate relations.
For example, MemN2N, which has the lowest performance among the four models, measures the relatedness between question and sentence by the inner product, while the best performing DMN+ uses inner product and absolute difference with two embedding matrices.



Recently, a new architecture called Relation Network (RN)~\citep{santoro2017simple} has been proposed as a general  solution to relational reasoning. 
The design philosophy behind it is to directly capture the supporting relation between the sentences through the multi-layer perceptron (MLP).
Despite its simplicity, RN achieves better performance than previous models without any catastrophic failure. 

The interesting thing we found is that RN can also be interpreted in terms of MemNN. 
It is composed of $O$ and $R$ where each corresponds to MLP which focuses on the related pair and another MLP which infers the answer.
RN does not need to have $G$ because it directly finds all the supporting sentences at once.
In this point of view, the significant component would be MLP-based output feature map.
As MLP is enough to recognize highly non-linear pattern, RN could find the proper relation better than previous models to answer the given question.

However, as RN considers a pair at a time unlike MemNN, the number of relations that RN learns is $n^2$ when the number of input sentence is $n$.
When $n$ is small, the cost of learning relation is reduced by $n$ times compared to MemNN based models, which enables more data-efficient learning~\citep{santoro2017simple}.
However, when $n$ increases, the performance becomes worse than the previous models.
In this case, the pair-wise operation increases the number of non-related sentence pairs more than the related sentence pair, thereby confuses RN's learning.
\citet{santoro2017simple} has suggested attention mechanisms as a solution to filter out unimportant relations; however, since it interrupts the reasoning operation, it may not be the most optimal solution to the problem.

Our proposed model, “Relation Memory Network” (RMN), is able to find complex relation even when a lot of information is given.
It uses MLP to find out relevant information with a new generalization which simply erase the information already used.
In other words, RMN inherits RN's MLP-based output feature map on Memory Network architecture.
Experiments show its state-of-the-art result on the text-based question answering tasks. 

\section{Relation Memory Network}



\begin{figure}[h!]
\centering
	\includegraphics[width=1\textwidth]{figure/RMN.eps}
	\caption{Relation Memory Network}
	\label{fig:RMN}
\end{figure}

Relation Memory Network (RMN) is composed of four components - embedding, attention, updating, and reasoning.
It takes as the inputs a set of sentences $\vec{x}_1, \vec{x}_2, ..., \vec{x}_n$ and its related question $\vec{u}$, and outputs an answer $\vec{a}$.
Each of the $\vec{x}_i$, $\vec{u}$, and $\vec{a}$ is made up of one-hot representation of words, for example, $\vec{x}_i = \{ \vec{x}_{i1}, \vec{x}_{i2}, \vec{x}_{i3}, ..., \vec{x}_{in_i}\}$ $(\vec{x}_{ij} \in \mathbb{R}^{V}, j = (1,2,...,n_i), V=$ vocabulary size$, n_i=$ number of words in sentence $i)$.


\subsection{Embedding component} 
We first embed words in each $\vec{x}_i = \{\vec{x}_{i1}, \vec{x}_{i2}, \vec{x}_{i3}, ..., \vec{x}_{in_i}\}$ and $\vec{u}$ to a continuous space multiplying an embedding matrix $A \in \mathbb{R}^{d \times V}$.
Then, the embedded sentence is stored and represented as a memory object $\vec{m}_i$ while question is represented as $\vec{q}$.
Any of the following methods are available for embedding component: simple sum (equation~\ref{eq:sum}), position encoding~\citep{Weston15} (equation~\ref{eq:PE}), concatenation (equation~\ref{eq:concat}), LSTM, and GRU.
In case of LSTM or GRU, $\vec{m}_i$ is the final hidden state of it.
\begin{equation}\label{eq:sum}
\vec{m}_i = \sum_j A \vec{x}_{ij}
\end{equation}
\begin{equation}\label{eq:PE}
\vec{m}_i = \sum_j l_j \cdot A \vec{x}_{ij} \quad (l_{kj} = (1-j/n_i) - (k/d)(1-2j/n_i))
\end{equation}
\begin{equation}\label{eq:concat}
\vec{m}_i = [A \vec{x}_{i1}, A \vec{x}_{i2}, ...\ , A \vec{x}_{in_i}]
\end{equation}
As the following attention component takes the concatenation of $\vec{m}_i$ and $\vec{q}$, it is not necessarily the case that sentence and question have the same dimensional embedding vectors unlike previous memory-augmented neural networks.


\subsection{Attention component} 
Attention component can be applied more than once depending on the problem; Figure~\ref{fig:RMN} illustrates 2 hop version of RMN.
We refer to the $i^{th}$ embedded sentence on the $t^{th}$ hop as $\vec{m}_i^t$.


To constitute the attention component, we applied simple MLP represented as $g_\theta^t$.
It must be ended with 1 unit output layer to provide a scalar weight $w_i^t$, which leads to an attention weight $\alpha_i^t$ between 0 and 1.
In the beginning, a vector concatenated with $\vec{m}_i^1$ and $\vec{q}$ flows to the $g_\theta^1$.
From the result of $g_\theta^1$, attention weight $\alpha_i^1$ is calculated using additional variable $\beta^1$ ($\geq$ 1) to control the intensity of attention, inspired by the way Neural Turing Machine~\citep{graves2014neural} reads from the memory.
Then we get the related memory object $\vec{r}^1$, a weighted sum of $\alpha_i^1$ and memory object $\vec{m}_i^1$ for all $i$.
If there exist more hops, $\vec{r}^1$ is directly taken to the next hop and iterates over this process with the updated memory object $\vec{m}_i^2$.
All the procedures are rewritten as equation~\ref{eq:g_theta}, \ref{eq:alpha}, and \ref{eq:aggregate_alpha}:
\begin{equation}\label{eq:g_theta}
w_i^t \leftarrow g_\theta^t ([\vec{m}_i^t, \vec{r}^{t-1}]) \quad (i = (1, 2, ..., n),\ \vec{r}^0 = \vec{q})
\end{equation}
\begin{equation}\label{eq:alpha}
\alpha_i^t \leftarrow \frac{\exp (\beta^t w_i^t)}{\sum_i \exp (\beta^t w_i^t)} \quad (\beta^t(z) = 1 + \log(1 + \exp(z)))
\end{equation}

\begin{equation}\label{eq:aggregate_alpha}
\vec{r}^{t} \leftarrow \sum_i \alpha_i^t \cdot \vec{m}_i^t
\end{equation}

\subsection{Updating component} 
To forget the information already used, we use intuitive updating component to renew the memory.
It is replaced by the amount of unconsumed from the old one:
\begin{equation}\label{eq:update}
\vec{m}_i^{t+1} \leftarrow (1 - \alpha_i^t )\ \vec{m}_i^t
\end{equation}
Contrary to other components, updating is not a mandatory component.
When it is considered to have 1 hop, there is no need to use this.


\subsection{Reasoning component} 
Similar to attention component, reasoning component is also made up of MLP, represented as $f_\phi$.
It receives both $\vec{q}$ and the final result of attention component $\vec{r}^f$ and then takes a softmax to produce the model answer $\hat{\vec{a}}$:
\begin{equation}
\hat{\vec{a}} \leftarrow \text{Softmax} ( f_\phi ([\vec{r}^f, \vec{q}]))
\end{equation}



\section{Related Work}



\subsection{Memory-Augmented Neural Network}
To answer the question from a given set of facts, the model needs to memorize these facts from the past. 
Long short term memory (LSTM)~\citep{hochreiter1997long}, one of the variants of recurrent neural network (RNN), is inept at remembering past stories because of their small internal memory~\citep{sukhbaatar2015end}. 
To cope with this problem, \citet{Weston15} has proposed a new class of memory-augmented model called Memory Network (MemNN). 
MemNN comprises an external memory $m$ and four components: input feature map ($I$), generalization ($G$), output feature map ($O$), and response ($R$). 
$I$ encodes the sentences which are stored in memory $m$.
$G$ updates the memory, whereas $O$ reads output feature $o$ from the memory.
Finally, $R$ infers an answer from $o$.


MemN2N, GMemN2N, DMN, and DMN+ all follow the same structure of MemNN from a broad perspective, however, output feature map is composed in slightly different way.
The relation between question and supporting sentences is realized from its cooperation.
MemN2N first calculates the relatedness of sentences in the question and memory by taking the inner product, and the sentence with the highest relatedness is selected as the first supporting sentence for the given question.
The first supporting sentence is then added with the question and repeat the same operation with the updated memory to find the second supporting sentence.
GMemN2N selects the supporting sentence in the same way as MemN2N, but uses the gate to selectively add the the question to control the influence of the question information in finding the supporting sentence in the next step.
DMN and DMN + use output feature map based on various relatedness such as absolute difference, as well as inner product, to understand the relation between sentence and question at various points.

The more difficult the task, the more complex the output feature map and the generalization component to get the correct answer.
For a dataset experimenting the text-based reasoning ability of the model, the overall accuracy could be increased in order of MemN2N, GMemN2N, DMN, and DMN+, where the complexity of the component increases.


\begin{table}[t]
\centering
	\caption{MemN2N, RN, and RMN in terms of MemNN architecture}
	\label{table:comparisons}
\begin{tabular}{l|c|c}
\hline
        & Output feature map & Generalization \\ \hline
MemN2N  &   \makecell{\rule{0in}{2.7ex}$\alpha_i^t = \text{Softmax}(({\vec{r}^t})^T \vec{m}_i^{t}) \hspace{1pt} (\vec{r}^0 = \vec{q})$ \\ $\vec{o}^t = \sum_i \alpha_i^t \vec{m}_i^t$ \\ $\vec{r}^{t+1} = \vec{o}^{t} + \vec{r}^{t}$}    &         $\vec{m}^t = W^t \vec{m}^{t-1}$          \\ [3.3ex] \hline
RN    &         \makecell{\rule{0in}{2.5ex}$\vec{r}_i = g_\theta$-MLP($[\vec{m}_i, \vec{m}_j, \vec{q}]$) \\ $\vec{o} = \sum_i \vec{r}_i$}           &          -         \\  [2ex] \hline
RMN      &         \makecell{\rule{0in}{2.5ex}$\vec{r}_i^t = g_\theta^t\text{-MLP} ([\vec{m}_i^t, \vec{r}^{t-1}]) \hspace{1pt} (\vec{r}^0 = \vec{q})$ \\\rule{0in}{2.1ex} $\alpha_i^t = \text{Softmax}({\beta^t} \vec{r}_i^{t})$ \\ $\vec{r}^t = \sum_i \alpha_i^t \vec{m}_i^t$ }          &       $\vec{m}_i^t = (1-\alpha_i^{t-1})\vec{m}_i^{t-1}$        \\ [3.5ex] \hline
\end{tabular}
\end{table}


\subsection{Relation Network}

Relation Network (RN) has emerged as a new and simpler framework for solving the general reasoning problem.
RN takes in a pair of objects as its input and simply learns from the compositions of two MLPs represented as $g_\theta$ and $f_\phi$.
The role of each MLP is not clearly defined in the original paper, but from the view of MemNN, it can be understood that $g_\theta$ corresponds to $O$ and $f_\phi$ corresponds to $R$.
Table~\ref{table:comparisons} summarizes the interpretation of RN compared to MemN2N and our model, RMN.


To verify the role of $g_\theta$, we compare the output when pairs are made with supporting sentences and when made with unrelated sentences.
Figure~\ref{fig:RN_g_theta} shows the visualization result of each output.
When we focus on whether the value is activated or not, we can see that $g_\theta$ distinguishes supporting sentence pair from non-supporting sentence pair as output feature map examines how relevant the sentence is to the question.
Therefore, we can comprehend the output of $g_\theta$ reveals the relation between the object pair and the question and $f_\phi$ aggregates all these outputs to infer the answer. 

\begin{figure}[h]
\centering
	\begin{subfigure}[b]{0.45\textwidth}
		\centering
		\includegraphics[width=0.9\textwidth]{figure/object_pair_activate_RN_g_embedded.eps}
	\label{fig:related_pair_RN}
     \caption{related objects}
    \end{subfigure}
	\hspace{0.06\textwidth}
	\begin{subfigure}[b]{0.45\textwidth}
		\centering
		\includegraphics[width=0.9\textwidth]{figure/object_pair_no_activate_RN_g_embedded.eps}
	\label{fig:unrelated_pair_RN}
	\caption{unrelated objects}
	\end{subfigure}
\caption{The output vector of $g_\theta$ when the input objects are related and unrelated}
\label{fig:RN_g_theta}
\end{figure}



\section{Experiments}

\subsection{Dataset}
\label{section:4.1dataset}

\textbf{bAbI story-based QA dataset} \quad 
bAbI story-based QA dataset~\citep{Weston2015towards} is composed of 20 different types of tasks for testing natural language reasoning ability.
Each task requires different methods to infer the answer.
The dataset includes a set of statements comprised of multiple sentences, a question and answer.
A statement can be as short as two sentences and as long as 320 sentences.
To answer the question, it is necessary to find relevant one or more sentences to a given question and derive answer from them.
Answer is typically a single word but in a few tasks, answers are a set of words.  
Each task is regarded as success when the accuracy is greater than 95\%.
There are two versions of this dataset, one that has 1k training examples and the other with 10k examples.
Most of the previous models test their accuracy on 10k dataset with trained jointly.

\textbf{bAbI dialog dataset} \quad 
bAbI dialog dataset~\citep{Bordes16} is a set of 5 tasks within the goal-oriented context of restaurant reservation. 
It is designed to test if model can learn various abilities such as performing dialog management, querying knowledge bases (KBs), and interpreting the output of such queries. 
The KB can be queried using API calls and 4 fields (a type of cuisine, a location, a price range, and a party size).
They should be filled to issue an API call.
Task 1 tests the capacity of interpreting a request and asking the right questions to issue an API call.
Task 2 checks the ability to modify an API call.
Task 3 and 4 test the capacity of using outputs from an API call to propose options in the order of rating and to provide extra-information of what user asks for.
Task 5 combines everything. 
The maximum length of the dialog for each task is different: 14 for task 1, 20 for task 2, 78 for task 3, 13 for task 4, and 96 for task 5.
As restaurant name, locations, and cuisine types always face new entities, there are normal and OOV test sets to assess model's generalization ability. 
Training sets consist fo 1k examples, which is not a large amount of creating realistic learning conditions.




\subsection{Training details}

\textbf{bAbI story-based QA dataset} \quad 
We trained 2 hop RMN jointly on all tasks using 10k dataset for model to infer the solution suited to each type of tasks.  
We limited the input to the last 70 stories for all tasks except task 3 for which we limited input to the last 130 stories, similar to~\citet{xiong2016dynamic} which is the hardest condition among previous models.
Then, we labeled each sentence with its relative position. 
Embedding component is similar to~\citet{santoro2017simple}, where story and question are embedded through different LSTMs; 32 unit word-lookup embeddings; 32 unit LSTM for story and question.
For attention component, as we use 2 hop RMN, there are $g_\theta^1$ and $g_\theta^2$; both are three-layer MLP consisting of 256, 128, 1 unit with ReLU activation function~\citep{nair2010rectified}.
$f_\phi$ is composed of 512, 512, and 159 units (the number of words appearing in bAbI dataset is 159) of three-layer MLP with ReLU non-linearities where the final layer was a linear that produced logits for a softmax over the answer vocabulary. 
For regularization, we use batch normalization~\citep{ioffe2015batch} for all MLPs. 
The softmax output was optimized with a cross-entropy loss function using the Adam optimizer~\citep{kingma2014adam} with a learning rate of 2$e^{-4}$.


\textbf{bAbI dialog dataset} \quad 
We trained on full dialog scripts with every model response as answer, all previous dialog history as sentences to be memorized, and the last user utterance as question. 
Model selects the most probable response from 4,212 candidates which are ranked from a set of all bot utterances appearing in training, validation and test sets (plain and OOV) for all tasks combined. 
We also report results when we use match type features for dialog. 
Match type feature is an additional label on the candidates indicating if word is found on the dialog history.
For example, if the world `Seoul' is found, then the `location' field is checked to hint model this word is important and should be used in API call.
This feature can alleviate OOV problem. 
Training was done with Adam optimizer and a learning rate of 1$e^{-4}$ for all tasks.
Additional model details are given in Appendix~\ref{appendix:hyperparameters}.




\section{Results and Discussion}

\subsection{bAbI story-based QA}

As we can see in table~\ref{table:babi_result}, RMN shows state-of-the-art result on bAbI story-based Question Answering dataset: 98.8\% accuracy where only a single task with no catastrophic failure. 
It succeeded on task 17, 18, 19 where MemN2N, GMemN2N, and DMN are failed to solve, and on task 16 which DMN+, DNC, and EntNet scored high error rates.


\begin{table}[t]
\centering
	\caption{Test error on bAbI story-based tasks with 10k training samples}
	\label{table:babi_result}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{l|lllllllll}
\hline
Task                                 & \multicolumn{1}{c}{MemNN} & \multicolumn{1}{c}{MemN2N} & \multicolumn{1}{c}{GMemN2N} & \multicolumn{1}{c}{DMN} & \multicolumn{1}{c}{DMN+} & \multicolumn{1}{c}{DNC} & \multicolumn{1}{c}{EntNet\footnotemark }& \multicolumn{1}{c}{RN\footnotemark} & \multicolumn{1}{c}{RMN} \\ \hline
1: Single Supporting Fact            & \textbf{0.0}                       & \textbf{0.0}                        & \textbf{0.0} & \textbf{0.0}                     & \textbf{0.0}                      & \textbf{0.0}                     & \textbf{0.1}                        & \textbf{0.0}                    & \textbf{0.0}                     \\
2: Two Supporting Facts              & \textbf{0.0}                       & \textbf{0.3}                        & \textbf{0.0}                         & \textbf{1.8}                     & \textbf{0.3}                      & \textbf{0.4}                     & \textbf{2.8} & 8.3                    & \textbf{0.5}                     \\
3: Three Supporting Facts            & \textbf{0.0}                       & 9.3                        & \textbf{4.5                        } & \textbf{4.8}                     & \textbf{1.1}                      & \textbf{1.8}                     & 10.6                       & 17.1                  & 14.7                     \\
4: Two Argument Relations            & \textbf{0.0}                       & \textbf{0.0}                        & \textbf{0.0} & \textbf{0.0}                     & \textbf{0.0}                    & \textbf{0.0}                    & \textbf{0.0} & \textbf{0.0}                    & \textbf{0.0}                   \\
5: Three Argument Relations          & \textbf{2.0 }                      & \textbf{0.6}                        & \textbf{0.2 } & \textbf{0.7}                     & \textbf{0.5}                     &\textbf{0.8}                     &\textbf{0.4}                       & \textbf{0.7}                   & \textbf{0.4}                     \\
6: Yes/No Questions                  & \textbf{0.0}                       & \textbf{0.0}                        & \textbf{0.0} & \textbf{0.0}                     & \textbf{0.0}                      & \textbf{0.0}                     & \textbf{0.3}                       & \textbf{0.0}                    & \textbf{0.0}                     \\
7: Counting                          & 15.0                      & \textbf{3.7}                       & \textbf{1.8}                         & \textbf{3.1}                     & \textbf{2.4}                      & \textbf{0.6}                    & \textbf{0.8}                        &\textbf{0.4}                &\textbf{0.5}                    \\
8: Lists/Sets                        & 9.0                       & \textbf{0.8}                        & \textbf{0.3}                         & \textbf{3.5}                     & \textbf{0.0}                     & \textbf{0.3}                     &\textbf{0.1} & \textbf{0.3}                   & \textbf{0.3}                     \\
9: Simple Negation                   & \textbf{0.0}                       & \textbf{0.8}                        & \textbf{0.0}                         & \textbf{0.0 } & \textbf{0.0}                      & \textbf{0.2}                     &\textbf{ 0.0 }                       & \textbf{0.0}                   &\textbf{0.0}                    \\
10: Indefinite Knowledge             & \textbf{2.0}                       & \textbf{2.4}                      & \textbf{0.2} &\textbf{2.5}                     & \textbf{0.0}                      & \textbf{0.2}                     & \textbf{0.0}                        & \textbf{0.0}                    & \textbf{0.0}                   \\
11: Basic Coreference                & \textbf{0.0}                       & \textbf{0.0}                        & \textbf{0.0}                         & \textbf{0.1}                    & \textbf{0.0}                      & \textbf{0.0}                     & \textbf{0.0}                        & \textbf{0.4}                  & \textbf{0.5}                    \\
12: Conjunction                      & \textbf{0.0}                       & \textbf{0.0}                        & \textbf{0.0}                         & \textbf{0.0}                     &\textbf{0.0}                      &\textbf{0.0}                     & \textbf{0.0}                        & \textbf{0.0}                   & \textbf{0.0}                     \\
13: Compound Coreference             & \textbf{0.0}                       & \textbf{0.0}                        & \textbf{0.0} & \textbf{0.2}                     & \textbf{0.0}                      & \textbf{0.1} & \textbf{0.0}                        & \textbf{0.0}                 & \textbf{0.0}                     \\
14: Time Reasoning                   & \textbf{1.0}                       &\textbf{0.0}                        & \textbf{0.0}                         &\textbf {0.0}                     & \textbf{0.0}                      & \textbf{0.4} & \textbf{3.6}                      &\textbf{0.0}                    & \textbf{0.0}                    \\
15: Basic Deduction                  & \textbf{0.0}                       & \textbf{0.0}                        &\textbf{0.0}                         & \textbf{0.0}                    &\textbf{0.0}                    & \textbf{0.0}                     &\textbf{0.0}                        & \textbf{0.0}                   &\textbf{0.0}                     \\
16: Basic Induction                  &\textbf{0.0}                       & \textbf{0.4}                        & \textbf{0.0}                         & \textbf{0.6}                   & 45.3                     & 33.1                    & 52.1                       & \textbf{4.9}                   & \textbf{0.9}                    \\
17: Positional Reasoning             & 35.0                        & 40.7                       & 27.8                        & 40.4                    & \textbf{4.2}                      & 12.0                    & 11.7                       & \textbf{1.6}                    & \textbf{0.3} \\
18: Size Reasoning                   & \textbf{5.0}                      & 6.7                        & 8.5                         & \textbf{4.7}                     & \textbf{2.1}                     & \textbf{0.8}                     & \textbf{2.1}                        & \textbf{2.1}                    & \textbf{2.3}                     \\
19: Path Finding                     & 64.0                      & 66.5                       & 31.0                        & 65.5                    & \textbf{0.0}                      & \textbf{3.9}                     & 63.0                       & \textbf{3.2}                    & \textbf{2.9}                     \\
20: Agent's Motivations              & \textbf{0.0}                       & \textbf{0.0}                        & \textbf{0.0} & \textbf{0.0}                    &\textbf{ 0.0}                      & \textbf{0.0}                     & \textbf{0.0}                        &\textbf{0.0}                    & \textbf{0.0}                     \\ \hline
Mean error (\%)                      & 6.7                       & 6.6                        & 3.7                         & 6.4                     & 2.8                      & 2.7                     & 7.4                        & 2.0                    & \textbf{1.2}                     \\
Failed tasks (err. \textgreater  5\%) & 4                         & 4                          & 3                           & 2                       & \textbf{1}                        & 2                       & 4                          & 2                       & \textbf{1}                       \\ \hline
\end{tabular}
\end{adjustbox}
\end{table}

\addtocounter{footnote}{-1}
\footnotetext{For a fair comparison, we report EntNet's result which was jointly trained on all tasks. It was written in the appendix of the paper.}
\addtocounter{footnote}{1}
\footnotetext{Our implementation. The result is different from what \citet{santoro2017simple} mentioned, which is caused by the initialization.}

\begin{table}[t]
\centering
\caption{bAbI story-based task visualization of $\alpha$}
\label{table:babi_attention}
\begin{subtable}[t]{0.48\textwidth}
\vspace{0pt}
\caption{Task 7}
\label{table:babi_task7}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{|c|L{6.5cm}|c|c|}
\hline
Seq. & \textbf{Task 7: Counting}                  & \multicolumn{1}{c|}{ $\alpha^1$}     & \multicolumn{1}{c|}{$\alpha^2$}     \\ \hline
8    & John grabbed the apple there . & \cellcolor[HTML]{FCF5F8}0.02 & \cellcolor[HTML]{FCFCFF}0.00 \\
9    & John gave the apple to Mary .        & \cellcolor[HTML]{FBD5D8}0.08 & \cellcolor[HTML]{FAB3B5}0.16 \\
10    & Mary passed the apple to John . & \cellcolor[HTML]{FAA9AB}0.17 & \cellcolor[HTML]{FA9092}0.24 \\
11    & Mary journeyed to the hallway .    & \cellcolor[HTML]{FCFCFF}0.00 & \cellcolor[HTML]{FCFAFD}0.01 \\
13   & Sandra went to the garden .   & \cellcolor[HTML]{FCFCFF}0.00 & \cellcolor[HTML]{FCFCFF}0.00 \\
14   & Mary went to the kitchen .   & \cellcolor[HTML]{FCFCFF}0.00 & \cellcolor[HTML]{FCF0F3}0.03 \\
15   & Mary picked up the football there .     & \cellcolor[HTML]{F8696B}0.29 & \cellcolor[HTML]{FA9193}0.24 \\
16   & Mary picked up the milk there .       & \cellcolor[HTML]{F97375}0.27 & \cellcolor[HTML]{F8696B}0.32 \\ \hline
\multicolumn{1}{|l|}{User input}   & \multicolumn{3}{l|}{How many objects is Mary carrying?}   \\ \hline
\multicolumn{1}{|l|}{Answer}       & \multicolumn{3}{l|}{Two}  \\ \hline
\multicolumn{1}{|l|}{Model answer} & \multicolumn{3}{l|}{Two \hspace{5.3cm} \textbf{[Correct]}}   \\ \hline
\end{tabular}
\end{adjustbox}
\vspace{3pt}
\caption{Task 14}
\label{table:babi_task14}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{|c|L{6.5cm}|c|c|}
\hline
Seq.                               & \textbf{Task 14: Time reasoning}             & $\alpha^1$                           &$\alpha^2$ \\ \hline
1                                  & Mary went back to the school yesterday .     & \cellcolor[HTML]{FFFFFF}0.00 & \cellcolor[HTML]{FFFFFF}0.01 \\
2                                  & Fred went to the school yesterday .          & \cellcolor[HTML]{FFFFFF}0.00 & \cellcolor[HTML]{FCFCFF}0.00 \\
3                                  & Julie went back to the kitchen yesterday .   & \cellcolor[HTML]{FCE8EB}0.13 & \cellcolor[HTML]{F8696B}0.98 \\
4                                  & Fred journeyed to the kitchen this morning . & \cellcolor[HTML]{FFFFFF}0.00 & \cellcolor[HTML]{FCFCFF}0.00 \\
5                                  & This morning julie journeyed to the school . & \cellcolor[HTML]{FA999B}0.66 & \cellcolor[HTML]{FCFAFD}0.02 \\
6                                  & This evening mary went back to the school .  & \cellcolor[HTML]{FCFBFE}0.01 & \cellcolor[HTML]{FCFCFF}0.00 \\
7                                  & This afternoon julie went to the bedroom .   & \cellcolor[HTML]{FCF4F7}0.06 & \cellcolor[HTML]{FCFCFF}0.00 \\ \hline
\multicolumn{1}{|l|}{User input}   & \multicolumn{3}{l|}{Where was Julie before the school ?}                                                   \\ \hline
\multicolumn{1}{|l|}{Answer}       & \multicolumn{3}{l|}{Kitchen}                                                                               \\ \hline
\multicolumn{1}{|l|}{Model answer} & \multicolumn{3}{l|}{Kitchen \hspace{4.8cm} \textbf{[Correct]}}   \\ \hline
\end{tabular}
\end{adjustbox}

\end{subtable}
\hfill
\begin{subtable}[t]{0.49\textwidth}
\caption{Task 3}
\label{table:babi_task3}
\vspace{0pt}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{|c|L{6cm}|c|c|}
\hline
Seq.         & \textbf{Task 3: Three Supporting Facts} & $\alpha^1$ & $\alpha^2$ \\ \hline
33           & Daniel took the football .              & \cellcolor[HTML]{F8696B}0.46 & \cellcolor[HTML]{FCFCFF}0.01 \\
39           & Sandra travelled to the bedroom .       & \cellcolor[HTML]{FCFBFE}0.01 & \cellcolor[HTML]{FCFCFF}0.00 \\
40           & Daniel moved to the bathroom .          & \cellcolor[HTML]{FCFBFE}0.01 & \cellcolor[HTML]{FA9A9D}0.31 \\
41           & Sandra got the milk .                   & \cellcolor[HTML]{FCFBFE}0.00 & \cellcolor[HTML]{FCFCFF}0.00 \\
42           & Daniel travelled to the garden .        & \cellcolor[HTML]{FCF1F4}0.04 & \cellcolor[HTML]{F97577}0.42 \\
46           & Daniel went to the hallway .            & \cellcolor[HTML]{FCFBFE}0.00 & \cellcolor[HTML]{FAADB0}0.25 \\
50           & Daniel put down the apple .             & \cellcolor[HTML]{FCFBFE}0.00 & \cellcolor[HTML]{FCFCFF}0.01 \\
51           & Daniel put down the football there .    & \cellcolor[HTML]{F98486}0.38 & \cellcolor[HTML]{FCFCFF}0.00 \\ \hline
\multicolumn{1}{|l|}{User input}   & \multicolumn{3}{l|}{Where was the football before the garden ?}                                     \\ \hline
\multicolumn{1}{|l|}{Answer}         & \multicolumn{3}{l|}{Bathroom}                                                                       \\ \hline
\multicolumn{1}{|l|}{Model answer} & \multicolumn{3}{l|}{Bathroom \hspace{4.2cm} \textbf{[Correct]}}                                                                       \\ \hline
\end{tabular}
\end{adjustbox}
\vspace{3pt}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{|c|L{6cm}|c|c|}
\hline
Seq.         & \textbf{Task 3: Three Supporting Facts}& $\alpha^1$ & $\alpha^2$ \\ \hline
1            & Mary got the football .                 & \cellcolor[HTML]{FA9B9D}0.26 & \cellcolor[HTML]{FCFCFF}0.00 \\
3            & Mary picked up the football .           & \cellcolor[HTML]{F8696B}0.39 & \cellcolor[HTML]{FCFCFF}0.00 \\
5            & Mary moved to the office .              & \cellcolor[HTML]{FCFCFF}0.00 & \cellcolor[HTML]{FCE2E5}0.05 \\
6            & Mary went to the hallway .              & \cellcolor[HTML]{FCFCFF}0.00 & \cellcolor[HTML]{FCE2E5}0.05 \\
11           & Mary travelled to the garden .          & \cellcolor[HTML]{FCFCFF}0.00 & \cellcolor[HTML]{FA9496}0.21 \\
12           & Mary travelled to the kitchen .         & \cellcolor[HTML]{FCFCFF}0.00 & \cellcolor[HTML]{F8696B}0.29 \\
14           & Mary moved to the office .              & \cellcolor[HTML]{FCFCFF}0.00 & \cellcolor[HTML]{F8696B}0.25 \\
16           & Mary went to the garden .               & \cellcolor[HTML]{FCFCFF}0.00 & \cellcolor[HTML]{FCE2E5}0.05 \\
22           & Mary discarded the football there .     & \cellcolor[HTML]{FAA1A3}0.24 & \cellcolor[HTML]{FCFCFF}0.00 \\ \hline
\multicolumn{1}{|l|}{User input}   & \multicolumn{3}{l|}{Where was the football before the garden ?}      \\ \hline
\multicolumn{1}{|l|}{Answer}       & \multicolumn{3}{l|}{Office}                                                                       \\ \hline
\multicolumn{1}{|l|}{Model answer} & \multicolumn{3}{l|}{Kitchen \hspace{4.2cm} \textbf{[Incorrect]}}                                                                       \\ \hline
\end{tabular}
\end{adjustbox}
\end{subtable}
\end{table}



Table~\ref{table:babi_attention} shows how our model solved several tasks.
RMN's attention component $g_\theta^1$ and $g_\theta^2$ complement each other to identify the necessary facts to answer correctly.
Sometimes both $g_\theta^1$ and $g_\theta^2$ concentrate on the same sentences which are all critical to answer the question, and sometimes $g_\theta^1$ finds a fact related to the given question and with this information $g_\theta^2$ chooses the key fact to answer. 
While trained jointly, RMN learns these different solutions for each task.
For the task 3, the only failed task, attention component still functions well; it focuses sequentially on the  supporting sentences.  
However, the reasoning component, $f_\phi$, had difficulty catching the word `before'. 
We could easily figure out `before' implies `just before' the certain situation, whereas RMN confused its meaning. 
As shown in table~\ref{table:babi_task3}, our model found all previous locations before the garden. 
Still, it is remarkable that the simple MLP carried out all of these various roles. 



\subsection{bAbI dialog}

\begin{table}[h]
\centering
\caption[Caption for LOF]{Test error on bAbI dialog tasks \protect\footnotemark}
\label{table:babi_dialog_result}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{l|llll|llll}
\hline
\multirow{2}{*}{Task}                & \multicolumn{4}{c|}{Plain}                    & \multicolumn{4}{c}{With Match}               \\ \cline{2-9} 
                                     & MemN2N        & GMemN2N     &RN\footnotemark   & RMN           & MemN2N        & GMemN2N    &RN\footref{fn:RN}   & RMN           \\ \hline
1: Issuing API calls                 & 0.1     & \textbf{0.0}      & \textbf{0.0}  & \textbf{0.0}  & \textbf{0.0}  & \textbf{0.0}  & \textbf{0.0} & \textbf{0.0} \\
2: Updating API calls                & \textbf{0.0}  & \textbf{0.0}  & 0.5 & \textbf{0.0}  & 1.7           & \textbf{0.0}  & \textbf{0.0} & \textbf{0.0}  \\
3: Displaying options                & \textbf{25.1} & \textbf{25.1} &  26.6 & \textbf{25.1} & \textbf{25.1} & \textbf{25.1} &27.1  & \textbf{25.1} \\
4: Providing extra information       & 40.5          & 42.8    & \textbf{0.0}      & \textbf{0.0}  & \textbf{0.0}  & \textbf{0.0} & \textbf{0.0}  & \textbf{0.0}  \\
5: Conducting full dialogs           & 3.9           & 3.7       &23.3    & \textbf{2.5}  & 6.6           & 2.0  &16.6 &\textbf{1.8}           \\ \hline
Average error rates (\%)             & 13.9          & 14.3     & 10.1     & \textbf{5.5}  & 6.7           & 5.4 &   8.7 & \textbf{5.4}           \\ \hline
1 (OOV): Issuing API calls           & 27.7          & 17.6      & 17.8      & \textbf{16.8} & 3.5           & \textbf{0.0} &1.5 & \textbf{0.0}  \\
2 (OOV): Updatining API calls        & \textbf{21.1} & \textbf{21.1} &23.2 & \textbf{21.1} & 5.5           & 5.8           & \textbf{0.0} & \textbf{0.0}  \\
3 (OOV): Displaying options          & 25.6          & \textbf{24.7} &27.2 & 24.9          & \textbf{24.8} & 24.9          &29.8  & 25.1          \\
4 (OOV): Providing extra information & 42.4          & 43.0       & \textbf{0.0}    & \textbf{0.0}  & \textbf{0.0}  & \textbf{0.0}  & \textbf{0.0} & \textbf{0.0}  \\
5 (OOV): Conducting full dialogs     & 34.5          & \textbf{33.3}  &38.3  & 34.5          & 22.3          & \textbf{20.6}  & 28.4 & 21.7          \\ \hline
Average error rates (\%)             & 30.3          & 27.9       &21.3  & \textbf{19.5} & 11.2          & 10.3        &12.0  & \textbf{9.4}  \\ \hline
\end{tabular}
\end{adjustbox}
\end{table}

The results in the Table~\ref{table:babi_dialog_result} show that the RMN has the best results in any conditions.
Without any match type, RN and RMN outperform previous memory-augmented models on both normal and OOV tasks.
This is mainly attributed to the impressive result on task 4 which can be interpreted as an effect of MLP based output feature map.  

To solve task 4, it is critical to understand the relation between `phone number' of user input and `r\_phone' of previous dialog as shown in Table~\ref{table:dialog_task4}.
We assumed that inner product was not sufficient to capture their implicit similarity and performed an supporting experiment.
We converted RMN's attention component to inner product based attention, and the results revealed the error rate increased to 11.3\%.

For the task 3 and task 5 where the maximum length is especially longer than the others, RN performs worse than MemN2N, GMemN2N and RMN.
The number of unnecessary object pairs created by the RN not only increases the processing time but also decreases the accuracy. 


With the match type feature, all models other than RMN have significantly improved their performance except for task 3 compared to the plain condition.
RMN was helped by the match type only on the OOV tasks and this implies RMN is able to find relation in the With Match condition for the normal tasks.

\addtocounter{footnote}{-1}
\footnotetext{We only compare models under the same conditions}
\addtocounter{footnote}{+1}
\footnotetext{Our implementation.\label{fn:RN}}

When we look at the OOV tasks more precisely, RMN failed to perform well on the OOV task 1 and 2 even though $g_\theta^1$ properly focused on the related object as shown in Table~\ref{table:dialog_task1}.
We state that this originated from the fact that the number of keywords in task 1 and 2 is bigger than that in task 4.
In task 1 and 2, all four keywords (cuisine, location, number and price) must be correctly aligned from the supporting sentence in order to make the correct API call which is harder than task 4.
Consider the example in Table~\ref{table:dialog_task1} and Table~\ref{table:dialog_task4}.
Supporting sentence of task 4 have one keyword out of three words, whereas supporting sentences of task 1 and 2 consist of four keywords (cuisine, location, number and price) out of sixteen words. 

Different from other tasks, RMN yields the same error rate 25.1\% with MemN2N and GMemN2N on the task 3. 
The main goal of task 3 is to recommend restaurant from knowledge base in the order of rating.
All failed cases are displaying restaurant where the user input is \textless silence\textgreater which is somewhat an ambiguous trigger to find the input relevant previous utterance. 
As shown in Table~\ref{table:dialog_task3}, there are two different types of response to the same user input. 
One is to check whether all the required fields are given from the previous utterances and then ask user for the missing fields or send a “Ok let me look into some options for you.” message.
The other type is to recommend restaurant starting from the highest rating. 
All models show lack of ability to discriminate these two types of silences so that concluded to the same results.  
To verify our statement, we performed an additional experiment on task 3 and checked the performance gain (extra result is given in Table~\ref{table:dialog_task3_add} of Appendix~\ref{appendix:dialog_task3}). 








\subsection{Model analysis}

\textbf{Effectiveness of the MLP-based output feature map}\quad
The most important feature that distinguishes MemNN based models is the output feature map.
Table~\ref{table:ablation study} summarizes the experimental results for the bAbI story-based QA dataset when replacing the RMN's MLP-based output feature map with the idea of the previous models.
inner product was used in MemN2N, inner product with gate was used in GMemN2N, and inner product and absolute difference with two embedding matrices was used in DMN and DMN+.
From the Table~\ref{table:ablation study}, the more complex the output feature map, the better the overall performance.
In this point of view, MLP is the effective output feature map. 

\begin{table}[h]
\centering
\caption{Test error of RMN on bAbI story-based QA dataset with different configurations}
\label{table:ablation study}
\begin{adjustbox}{max width=0.95\textwidth}
\begin{tabular}{l|c|c|c|c}
\hline
           & inner product & inner product with gate & \begin{tabular}[c]{@{}c@{}}inner product and absolute difference \\ with two embedding matrices\end{tabular} & MLP \\ \hline
error rate & 29.4          & 25.9                    & 11.2                                                                                                   & \textbf{1.2} \\ \hline
\end{tabular}
\end{adjustbox}
\end{table}


\textbf{Performance of RN and RMN according to memory size}\quad
Additional experiments were conducted with the bAbI story-based QA dataset to see how memory size affects both performance and training time of RN and RMN. 
Test errors with training time written in parentheses are summarized in Table~\ref{table:RN_RMN}.

When memory size is small, we could observe the data-effeciency of RN.
It shows similar performance to RMN in less time.
However, when the memory size increases, performance is significantly reduced compared to RMN, even though it has been learned for a longer time.
It is even lower than itself when the memory size is 20.
On the other hand, RMN maintains high performance even when the memory size increases.


\begin{table}[h]
\centering
\caption{Test error and training time of RN and RMN on bAbI story-based QA dataset with different memory size}
\label{table:RN_RMN}
\begin{adjustbox}{max width=0.95\textwidth}
\begin{tabular}{l|c|c}
\hline
memory size & RN              & RMN             \\ \hline
20          & 2.0 (0.65 days) &      1.5 (1.46 days)           \\ \hline
130         & 9.8 (9.47 days) & \textbf{1.2} (4.94 days) \\ \hline
\end{tabular}
\end{adjustbox}
\end{table}

\textbf{Effectiveness of the number of hops}\quad
bAbI story based QA dataset differs in the number of supporting sentences by each task that need to be referenced to solve problems.
For example, task 1, 2, and 3 require single, two, and three supporting facts, respectively.
The result of the mean error rate for each task according to the number of hops is in Table~\ref{table:task-wise_hop}.

\begin{table}[h]
\centering
\caption{Test error of RMN on bAbI story-based QA dataset with different number of hops}
\label{table:task-wise_hop}
\begin{adjustbox}{max width=0.95\textwidth}
\begin{tabular}{l|c|c|c} \hline
            & hop 1 & hop 2 & hop 3 \\ \hline
task 1 (1)~\footnotemark  & \textbf{0.0}   & \textbf{0.0}   & 0.2 \\ \hline
task 2 (2)  & 62.0 & \textbf{0.5} & 2.1 \\ \hline
task 3 (3)  & 62.4 & 14.7 & \textbf{14.6} \\ \hline
task 10 (1) & \textbf{0.0}   & \textbf{0.0}   & 3.6 \\ \hline
		\end{tabular}
\end{adjustbox}
\end{table}
\footnotetext{Number in parentheses indicates the number of supporting sentences to solve the task}

Overall, the number of hops is correlated with the number of supporting sentences.
In this respect, when the number of relations increases, RMN could reason across increasing the number of hops to 3, 4 or more.










\section{Conclusion}

Our work, RMN, is a simple and powerful architecture that effectively handles text-based question answering tasks when large size of memory and high reasoning ability is required.
Multiple access to the external memory to find out necessary information through a multi-hop approach is similar to most existing approaches.
However, by using a MLP that can effectively deal with complex relatedness when searching for the right supporting sentences among a lot of sentences, RMN raised the state-of-the-art performance on the story-based QA and goal-oriented dialog dataset.
When comparing RN which also used MLP to understand relations, RMN was more effective in the case of large memory.

Future work will apply RMN to image based reasoning task (e.g., CLEVR, DAQUAR, VQA etc.). 
To extract features from the image, VGG net~\citep{simonyan2014very} is used in convention and outputs 196 objects of 512 dimensional vectors which also require large sized memory. 
An important direction will be to find an appropriate way to focus sequentially on related object which was rather easy in text-based reasoning.













\begin{table}[h]
\centering
\caption{Visualization of $\alpha$ on bAbI dialog task 1, 3, and 4 without match type}
\label{table:dialog_attention}
\begin{subtable}[t]{0.9\textwidth}
\centering
\caption{Plain and OOV result of task 1}
\label{table:dialog_task1}
\vspace{0pt}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{|c|c|L{14cm}|c|}
\hline
Seq. & Locutor & \textbf{Task 1: Issuing API calls} & $\alpha^1$                           \\ \hline
1    & user    & Good morning                                                                                                                               & \cellcolor[HTML]{FFFFFF}0.01                         \\
2    & bot     & Hello what can i help you with today                                                                                                       & \cellcolor[HTML]{FFFFFF}0.01                         \\
3    & user    & \begin{tabular}[c]{@{}l@{}}Can you make restaurant reservation for eight people in cheap price range with british cuisine\end{tabular} & \cellcolor[HTML]{F97072}0.23 \\
4    & bot     & I'm on it                                                                                                                                & \cellcolor[HTML]{FCFCFF}0.00 \\
5    & user    & \textless silence\textgreater                                                                                                               & \cellcolor[HTML]{FAACAE}0.14 \\
6    & bot     & Where should it be                                                                                                                         & \cellcolor[HTML]{FFFFFF}0.01                         \\
7    & user    & In madrid                                                                                                                                  & \cellcolor[HTML]{F8696B}0.25 \\
8    & bot     & Ok let me look into some options for you                                                                                                   & \cellcolor[HTML]{FA9396}0.18 \\ \hline
\multicolumn{2}{|l|}{User input}   & \multicolumn{2}{l|}{\textless silence\textgreater}   \\ \hline
\multicolumn{2}{|l|}{Answer}       & \multicolumn{2}{l|}{API\_call british madrid eight cheap}  \\ \hline
\multicolumn{2}{|l|}{Model answer} & \multicolumn{2}{l|}{API\_call british madrid eight cheap \hspace{6cm} \textbf{[Correct]}}   \\ \hline
\end{tabular}
\end{adjustbox}
\vspace{0.5cm}
\begin{adjustbox}{max width=\textwidth}
\centering
\begin{tabular}{|c|c|L{14cm}|c|}
\hline
Seq. & Locutor & \textbf{Task 1 (OOV): Issuing API calls} & $\alpha^1$                            \\ \hline
1    & user    & Hi                                                                                                                               & \cellcolor[HTML]{FFFFFF}0.01 \\
2    & bot     & Hello what can i help you with today                                                                                             & \cellcolor[HTML]{FFFFFF}0.01 \\
3    & user    & \begin{tabular}[c]{@{}l@{}}May I have table with cantonese cuisine in cheap price range in seoul for two people\end{tabular} & \cellcolor[HTML]{F8696B}0.49 \\
4    & bot     & I'm on it                                                                                                                      & \cellcolor[HTML]{FCE0E3}0.10 \\
5    & user    & \textless silence\textgreater                                                                                                     & \cellcolor[HTML]{FFFFFF}0.01 \\
6    & bot     & Ok let me look into some options for you                                                                                         & \cellcolor[HTML]{FAADB0}0.27 \\ \hline
\multicolumn{2}{|l|}{User input}   & \multicolumn{2}{l|}{\textless silence\textgreater}   \\ \hline
\multicolumn{2}{|l|}{Answer}       & \multicolumn{2}{l|}{API\_call cantonese seoul two cheap}  \\ \hline
\multicolumn{2}{|l|}{Model answer} & \multicolumn{2}{l|}{API\_call italian paris two cheap \hspace{6.4cm} \textbf{[Incorrect]}}   \\ \hline
\end{tabular}
\end{adjustbox}
\end{subtable}
\begin{subtable}[t]{0.9\textwidth}
\centering
\caption{Same user input with different goal in task 3}
\vspace{0pt}
\label{table:dialog_task3}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{|c|c|L{14cm}|c|}
\hline
Seq. & Locutor & \textbf{Task 3: Displaying options}                                                           &  $\alpha^1$                           \\ \hline
7    & user    & resto\_1 r\_rating 1                                                                 & \cellcolor[HTML]{FFFFFF}0.01 \\
14   & user    & resto\_8 r\_rating 8                                                                 & \cellcolor[HTML]{FFFFFF}0.01 \\
21   & user    & resto\_3 r\_rating 3                                                                 & \cellcolor[HTML]{FFFFFF}0.01 \\
22   & user    & Hello                                                                                & \cellcolor[HTML]{FFFFFF}0.01 \\
23   & bot     & Hello what can i help you with today                                                 & \cellcolor[HTML]{FFFFFF}0.01 \\
24   & user    & Can you book table with french food for two people in madrid in moderate price range & \cellcolor[HTML]{F8696B}0.21 \\
25   & bot     & I'm on it                                                                          & \cellcolor[HTML]{FFFFFF}0.01 \\ \hline
\multicolumn{2}{|l|}{User input}   & \multicolumn{2}{l|}{\textless silence\textgreater}   \\ \hline
\multicolumn{2}{|l|}{Answer}       & \multicolumn{2}{l|}{Where should it be?}  \\ \hline
\multicolumn{2}{|l|}{Model answer} & \multicolumn{2}{l|}{Where should it be? \hspace{8cm} \textbf{[Correct]}}   \\ \hline
\end{tabular}
\end{adjustbox}
\vspace{0.5cm}
\begin{adjustbox}{max width=\textwidth}
\centering
\begin{tabular}{|c|c|L{14cm}|c|}
\hline
Seq.   & Locutor   & \textbf{Task 3: Displaying options}                                                            & $\alpha^1$                            \\ \hline
7      & user      & resto\_1 r\_rating 1                                                                   & \cellcolor[HTML]{FFFFFF}0.00  \\
14     & user      & resto\_8 r\_rating 8                                                                   & \cellcolor[HTML]{FFFFFF}0.00  \\
21     & user      & resto\_3 r\_rating 3                                                                   & \cellcolor[HTML]{FFFFFF}0.00  \\
24     & user      & Can you book table with french food for two people in madrid in moderate price range  & \cellcolor[HTML]{F96D6F}0.14  \\
25     & bot       & I'm on it                                                                            & \cellcolor[HTML]{FFFFFF}0.00  \\
26     & user      & \textless silence\textgreater                                                           & \cellcolor[HTML]{FAA1A4}0.09  \\
27     & bot       & Ok let me look into some options for you                                               & \cellcolor[HTML]{F8696B}0.15  \\
28     & user      & \textless silence\textgreater                                                           & \cellcolor[HTML]{FA9B9D}0.10  \\
29     & bot       & What do you think of this option : resto\_8                                            & \cellcolor[HTML]{FAA8AA}0.08  \\
30     & user      & No this does not work for me                                                           & \cellcolor[HTML]{FBC2C5}0.06  \\
31     & bot       & Sure let me find other option for you                                                  & \cellcolor[HTML]{FAAFB2}0.08  \\ \hline
\multicolumn{2}{|l|}{User input}   & \multicolumn{2}{l|}{\textless silence\textgreater}   \\ \hline
\multicolumn{2}{|l|}{Answer}       & \multicolumn{2}{l|}{What do you think of this option: resto\_3}  \\ \hline
\multicolumn{2}{|l|}{Model answer} & \multicolumn{2}{l|}{What do you think of this option: resto\_7 \hspace{5cm} \textbf{[Incorrect]}}   \\ \hline
\end{tabular}
\end{adjustbox}
\end{subtable}
\begin{subtable}[t]{0.9\textwidth}
\centering
\caption{Plain and OOV result of task 4}
\label{table:dialog_task4}
\vspace{0pt}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{|c|c|L{14cm}|c|}
\hline
Seq.        & Locutor        & \textbf{Task 4: Providing extra information}                                                                   & $\alpha^1$                                  \\ \hline
1             & user           & resto\_3 r\_phone resto\_3\_phone            & \cellcolor[HTML]{F8696B}0.77        \\
3             & user           & resto\_3 r\_address resto\_3\_address        & \cellcolor[HTML]{FCFCFF}0.01        \\
4             & user           & resto\_3 r\_location london                                               & \cellcolor[HTML]{FCFCFF}0.01        \\
6             & user           & resto\_3 r\_price cheap                                                   & \cellcolor[HTML]{FCFCFF}0.01        \\
10            & user           & I'd like to book table at resto\_3                                      & \cellcolor[HTML]{FCFCFF}0.02        \\
11            & bot            & Great let me do reservation                                                                            & \cellcolor[HTML]{FCF9FC}0.03        \\ \hline
\multicolumn{2}{|l|}{User input}   & \multicolumn{2}{l|}{What is phone number of restaurant?}   \\ \hline
\multicolumn{2}{|l|}{Answer}       & \multicolumn{2}{l|}{Here it is: resto\_3\_phone}  \\ \hline
\multicolumn{2}{|l|}{Model answer} & \multicolumn{2}{l|}{Here it is: resto\_3\_phone \hspace{7.3cm} \textbf{[Correct]}}   \\ \hline
\end{tabular}
\end{adjustbox}
\vspace{0.5cm}
\begin{adjustbox}{max width=\textwidth}
\centering
\begin{tabular}{|c|c|L{14cm}|c|}
\hline
Seq.                  & Locutor                 & \textbf{Task 4 (OOV): Providing extra information}                                                                               & $\alpha^1$                                           \\ \hline
1                     & user                    & resto\_1 r\_phone resto\_1\_phone                     & \cellcolor[HTML]{F8696B}0.79                 \\
3                     & user                    & resto\_1 r\_address resto\_1\_address                 & \cellcolor[HTML]{FCFCFF}0.01                 \\
4                     & user                    & resto\_1 r\_location hanoi                                                             & \cellcolor[HTML]{FCFCFF}0.01                 \\
6                     & user                    & resto\_1 r\_price expensive                                                            & \cellcolor[HTML]{FCFCFF}0.01                 \\
10                    & user                    & Can you make restaurant reservation at resto\_1 & \cellcolor[HTML]{FCFCFF}0.01                 \\
11                    & bot                     & Great let me do reservation                                                                                             & \cellcolor[HTML]{FCF9FC}0.04  \\ \hline
\multicolumn{2}{|l|}{User input}   & \multicolumn{2}{l|}{What is phone number of restaurant?}   \\ \hline
\multicolumn{2}{|l|}{Answer}       & \multicolumn{2}{l|}{Here it is: resto\_1\_phone}  \\ \hline
\multicolumn{2}{|l|}{Model answer} & \multicolumn{2}{l|}{Here it is: resto\_1\_phone  \hspace{7.3cm} \textbf{[Correct]}}   \\ \hline
\end{tabular}
\end{adjustbox}
\end{subtable}
\end{table}






\clearpage
\bibliography{iclr2018_conference}
\bibliographystyle{iclr2018_conference}


\clearpage
\appendix

\section{Model details}\label{appendix:hyperparameters}

\begin{table}[h]
\centering
\caption{Hyperparameters of Relation Memory Networks on bAbI dialog tasks}
\label{table:hyperparameters}
\begin{adjustbox}{max width=0.9\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
Task & \begin{tabular}[c]{@{}c@{}}Story and Question\\ Embedding\end{tabular} & \begin{tabular}[c]{@{}c@{}}Word-lookup \\ Embedding Dim\end{tabular} & Hop & $g_\theta$          & $f_\phi$               & Activation & Use Batch Norm \\ \hline
1    & sum                                                                    & 128                                                                  & 1   & 2048, 2048, 1       & 2048, 2048, 4212       & tanh       & True           \\ \hline
2    & sum                                                                    & 128                                                                  & 1   & 1024, 1024, 1       & 1024, 1024, 4212       & tanh       & True           \\ \hline
3    & sum                                                                    & 128                                                                  & 1   & 1024, 1024, 1024, 1 & 1024, 1024, 1024, 4212 & tanh       & True           \\ \hline
4    & concatenation                                                          & 50                                                                   & 1   & 1024, 1024, 1       & 1024, 1024, 4212       & tanh       & True           \\ \hline
5    & concatenation                                                          & 64                                                                   & 2   & 4096, 4096, 1       & 4096, 4096, 4212       & tanh       & True           \\ \hline
\end{tabular}
\end{adjustbox}
\end{table}

\section{Additional Results}\label{appendix:dialog_task3}


\begin{table}[h]
\centering
\caption{Visualization of $\alpha^1$ and $\alpha^2$ on user input revised bAbI dialog task 3 without match type}
\label{table:dialog_task3_add}
\begin{adjustbox}{max width=0.9\textwidth}
\begin{tabular}{|c|c|L{11cm}|C{1cm}|C{1cm}|}
\hline
Seq.           & Locutor           & Task 3: Displaying options                & $\alpha^1$                           & $\alpha^2$ \\ \hline
1              & user              & resto\_8 r\_phone resto\_8\_phone         & \cellcolor[HTML]{FFFFFF}0.00 & \cellcolor[HTML]{FFFFFF}0.01 \\
2              & user              & resto\_8 r\_cuisine french                & \cellcolor[HTML]{FFFFFF}0.01 & \cellcolor[HTML]{FFFFFF}0.01 \\
3              & user              & resto\_8 r\_address resto\_8\_address     & \cellcolor[HTML]{FFFFFF}0.01 & \cellcolor[HTML]{FFFFFF}0.01 \\
4              & user              & resto\_8 r\_location madrid               & \cellcolor[HTML]{FFFFFF}0.01 & \cellcolor[HTML]{FFFFFF}0.01 \\
5              & user              & resto\_8 r\_number two                    & \cellcolor[HTML]{FFFFFF}0.00 & \cellcolor[HTML]{FFFFFF}0.01 \\
6              & user              & resto\_8 r\_price moderate                & \cellcolor[HTML]{FFFFFF}0.00 & \cellcolor[HTML]{FFFFFF}0.01 \\
7              & user              & resto\_8 r\_rating 8                      & \cellcolor[HTML]{FFFFFF}0.01 & \cellcolor[HTML]{F8696B}0.39 \\
8              & user              & resto\_3 r\_phone resto\_3\_phone         & \cellcolor[HTML]{FFFFFF}0.01 & \cellcolor[HTML]{FFFFFF}0.01 \\
9              & user              & resto\_3 r\_cuisine french                & \cellcolor[HTML]{FFFFFF}0.00 & \cellcolor[HTML]{FFFFFF}0.01 \\
10             & user              & resto\_3 r\_address resto\_3\_address     & \cellcolor[HTML]{FFFFFF}0.00 & \cellcolor[HTML]{FFFFFF}0.01 \\
11             & user              & resto\_3 r\_location madrid               & \cellcolor[HTML]{FFFFFF}0.00 & \cellcolor[HTML]{FFFFFF}0.01 \\
12             & user              & resto\_3 r\_number two                    & \cellcolor[HTML]{FFFFFF}0.00 & \cellcolor[HTML]{FFFFFF}0.01 \\
13             & user              & resto\_3 r\_price moderate                & \cellcolor[HTML]{FFFFFF}0.00 & \cellcolor[HTML]{FFFFFF}0.01 \\
14             & user              & resto\_3 r\_rating 3                      & \cellcolor[HTML]{FFFFFF}0.00 & \cellcolor[HTML]{FFFFFF}0.01 \\
15             & user              & resto\_1 r\_phone resto\_1\_phone         & \cellcolor[HTML]{FFFFFF}0.01 & \cellcolor[HTML]{FFFFFF}0.01 \\
16             & user              & resto\_1 r\_cuisine french                & \cellcolor[HTML]{FFFFFF}0.01 & \cellcolor[HTML]{FFFFFF}0.01 \\
17             & user              & resto\_1 r\_address resto\_1\_address     & \cellcolor[HTML]{FFFFFF}0.01 & \cellcolor[HTML]{FFFFFF}0.01 \\
18             & user              & resto\_1 r\_location madrid               & \cellcolor[HTML]{FFFFFF}0.01 & \cellcolor[HTML]{FFFFFF}0.01 \\
19             & user              & resto\_1 r\_number two                    & \cellcolor[HTML]{FFFFFF}0.00 & \cellcolor[HTML]{FFFFFF}0.01 \\
20             & user              & resto\_1 r\_price moderate                & \cellcolor[HTML]{FFFFFF}0.00 & \cellcolor[HTML]{FFFFFF}0.01 \\
21             & user              & resto\_1 r\_rating 1                      & \cellcolor[HTML]{FFFFFF}0.00 & \cellcolor[HTML]{FFFFFF}0.01 \\
22             & user              & Good morning                              & \cellcolor[HTML]{FFFFFF}0.01 & \cellcolor[HTML]{FFFFFF}0.01 \\
23             & bot               & Hello what can I help you with today?      & \cellcolor[HTML]{FAB3B5}0.12 & \cellcolor[HTML]{FFFFFF}0.01 \\
24             & user              & May I have table for two with french food? & \cellcolor[HTML]{FBCBCE}0.08 & \cellcolor[HTML]{FFFFFF}0.02 \\
25             & bot               & I'm on it                               & \cellcolor[HTML]{FCEDF0}0.03 & \cellcolor[HTML]{FFFFFF}0.01 \\
26             & user              & \textless silence\textgreater              & \cellcolor[HTML]{FFFFFF}0.01 & \cellcolor[HTML]{FFFFFF}0.01 \\
27             & bot               & Where should it be                        & \cellcolor[HTML]{FBC9CB}0.09 & \cellcolor[HTML]{FFFFFF}0.01 \\
28             & user              & In madrid                                 & \cellcolor[HTML]{FFFFFF}0.01 & \cellcolor[HTML]{FFFFFF}0.01 \\
29             & bot               & Which price range are looking for?         & \cellcolor[HTML]{FBC9CB}0.09 & \cellcolor[HTML]{FFFFFF}0.01 \\
30             & user              & In moderate price range please            & \cellcolor[HTML]{FFFFFF}0.01 & \cellcolor[HTML]{FFFFFF}0.01 \\
31             & bot               & Ok let me look into some options for you  & \cellcolor[HTML]{F8696B}0.24 & \cellcolor[HTML]{FFFFFF}0.01 \\ \hline
\multicolumn{2}{|l|}{User input}   & \multicolumn{3}{l|}{\textless silence\textgreater \textless silence\textgreater}                          \\ \hline
\multicolumn{2}{|l|}{Answer}       & \multicolumn{3}{l|}{What do you think of this option: resto\_8}                                         \\ \hline
\multicolumn{2}{|l|}{Model answer} & \multicolumn{3}{l|}{What do you think of this option: resto\_8    \hspace{5cm} \textbf{[correct]}}                                         \\ \hline
\end{tabular}
\end{adjustbox}
\end{table}

We modify the user input from \textless silence\textgreater to \textless silence\textgreater \textless silence\textgreater when looking for restaurant recommendations.
This makes model to distinguish two different situations whether to ask for additional fields or to recommend restaurant. 

\end{document}
