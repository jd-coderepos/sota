\documentclass{article}









\PassOptionsToPackage{square,numbers,sort&compress}{natbib}
\usepackage[final]{neurips_2020}



\usepackage{amsmath,amsfonts,bm}

\newcommand{\figleft}{{\em (Left)}}
\newcommand{\figcenter}{{\em (Center)}}
\newcommand{\figright}{{\em (Right)}}
\newcommand{\figtop}{{\em (Top)}}
\newcommand{\figbottom}{{\em (Bottom)}}
\newcommand{\captiona}{{\em (a)}}
\newcommand{\captionb}{{\em (b)}}
\newcommand{\captionc}{{\em (c)}}
\newcommand{\captiond}{{\em (d)}}

\newcommand{\newterm}[1]{{\bf #1}}


\def\figref#1{figure~\ref{#1}}
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
\def\secref#1{section~\ref{#1}}
\def\Secref#1{Section~\ref{#1}}
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
\def\eqref#1{equation~\ref{#1}}
\def\Eqref#1{Equation~\ref{#1}}
\def\plaineqref#1{\ref{#1}}
\def\chapref#1{chapter~\ref{#1}}
\def\Chapref#1{Chapter~\ref{#1}}
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
\def\algref#1{algorithm~\ref{#1}}
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
\def\partref#1{part~\ref{#1}}
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}

\def\eps{{\epsilon}}


\def\reta{{\textnormal{}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}

\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

\newcommand{\pdata}{p_{\rm{data}}}
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}

\newcommand{\laplace}{\mathrm{Laplace}} 

\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}

\newcommand{\parents}{Pa} 

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Tr}{Tr}
\let\ab\allowbreak
 
\usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}    \usepackage[pagebackref=true,breaklinks=true,colorlinks,bookmarks=false]{hyperref}
\usepackage{url}            \usepackage{booktabs}       \usepackage{amsfonts}       \usepackage{nicefrac}       \usepackage{microtype}      

\usepackage{graphicx}
\usepackage{color}
\usepackage{caption}
\usepackage{enumitem}
\usepackage{tabularx}
\usepackage{colortbl}  \usepackage{bm}  \usepackage{amssymb}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{wrapfig}
\usepackage{placeins}
\usepackage{subfig}
\newcommand{\rohit}[1]{\textcolor{red}{{\bf RG:} #1}}
\newcommand{\laurens}[1]{\textcolor{blue}{{\bf LM:} #1}}
\definecolor{darkergreen}{rgb}{0.0, 0.5, 0.0}
\newcommand{\anton}[1]{\textcolor{darkergreen}{{\bf AB:} #1}}
\newcommand{\eltayeb}[1]{\textcolor{cyan}{{\bf EA:} #1}}

\definecolor{Gray}{gray}{0.9}
\newcolumntype{g}{>{\columncolor{Gray}}c}  \newcolumntype{H}{>{\setbox0=\hbox\bgroup}c<{\egroup}@{}}  \definecolor{GrayLine}{gray}{0.7}
\newcolumntype{Y}{>{\centering\arraybackslash}X}


\definecolor{demphcolor}{RGB}{100,100,100}
\newcommand{\demph}[1]{\textcolor{demphcolor}{#1}}
\newcommand{\pms}[2]{#1{\tiny{{\demph{{#2}}}}}}
\newcolumntype{x}[1]{>{\centering\arraybackslash}p{#1pt}}
\newlength\savewidth\newcommand\shline{\noalign{\global\savewidth\arrayrulewidth
  \global\arrayrulewidth 1pt}\hline\noalign{\global\arrayrulewidth\savewidth}}
\newcommand{\tablestyle}[2]{\setlength{\tabcolsep}{#1}\renewcommand{\arraystretch}{#2}\centering\footnotesize}
\newcommand{\colw}{30}

\newcommand{\bb}{\mathbf{b}}
\newcommand{\be}{\mathbf{e}}
\newcommand{\bj}{\mathbf{j}}
\newcommand{\bp}{\mathbf{p}}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bw}{\mathbf{w}}
\newcommand{\bW}{\mathbf{W}}


\title{Physical Reasoning Using Dynamics-Aware Models}



\author{
  Eltayeb Ahmed \quad Anton Bakhtin \quad Laurens van der Maaten \quad Rohit Girdhar \\
  Facebook AI Research, New York
}



\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\begin{document}


\maketitle

\begin{abstract}
A common approach to solving physical-reasoning tasks is to train a value learner on example tasks.
A limitation of such an approach is it requires learning about object dynamics solely from reward values assigned to the final state of a  rollout of the environment.
This study aims to address this limitation by augmenting the reward value with additional supervisory signals about object dynamics.
Specifically, we define a distance measure between the trajectory of two target objects, and use this distance measure to characterize the similarity of two environment rollouts.
We train the model to correctly rank rollouts according to this measure in addition to predicting the correct reward.
Empirically, we find that this approach leads to substantial performance improvements on the PHYRE benchmark for physical reasoning~\cite{bakhtin2019phyre}: our approach obtains a new state-of-the-art on that benchmark.
\end{abstract} \section{Introduction}
\label{sec:introduction}

Many open problems in artificial intelligence require agents to reason about physical interactions between object.
Spurred by the release of benchmarks such as Tools~\cite{allen2019tools} and PHYRE~\cite{bakhtin2019phyre}, such \emph{physical reasoning} tasks have become a popular subject of study~\cite{girdhar2020forward,qi2020longterm,Whitney2020DynamicsawareE}.
Specifically, the tasks define an \emph{initial state} and a \emph{goal state} of the world, and require selecting an \emph{action} that comprises placing one or more additional objects in the world.
After the action is performed, the world simulator is unrolled to determine whether or not the goal state is attained.
Despite their simplicity, benchmarks like PHYRE are surprisingly difficult to solve due to the chaotic nature of the dynamics of physical objects. 
Current approaches for physical reasoning problems can be subdivided into two main types:
\begin{enumerate}[leftmargin=*]
\item \textbf{Dynamics-agnostic approaches} treat the problem as a ``standard'' contextual bandit that tries to learn the value of taking a particular action given an initial state, without using the simulator rollout in any way~\cite{bakhtin2019phyre}. 
An advantage of such approaches is that they facilitate the use of popular learning algorithms for this setting, such as deep Q-networks (DQNs; \cite{mnih-atari-2013}) 
However, the approaches do not use information from the simulator rollout as learning signal, which limits their efficacy.
\item \textbf{Dynamics-modeling approaches} learn models that explicitly aim to capture the dynamics of objects in the world, and use those models to perform forward prediction~\cite{girdhar2020forward,qi2020longterm,Whitney2020DynamicsawareE}.
Such forward predictions can then be used, for example, in a search algorithm to find an action that is likely to be successful.
An advantage of such approaches is that it uses learning signal obtained from the simulator rollout.
However, despite recent progress~\cite{gonzalez2020learning}, high-fidelity dynamics prediction in environments like PHYRE remains an unsolved problem~\cite{girdhar2020forward}.
Moreover, current approaches do not use the uncertainty in the dynamics model to select actions that are most likely to solve the task.
\end{enumerate}
In this paper, we develop a \textbf{dynamics-aware} approach for physical reasoning that is designed to combine the strengths of the current two approaches.
Our approach incorporates information on simulator rollout into the learning signal used to train DQNs.
We show that the resulting models outperform prior models on the PHYRE benchmark, achieving a new state-of-the-art score of  on the 1B, within-template tranche of that benchmark (compared to  in prior work~\cite{girdhar2020forward}).

 \section{Dynamics-Aware Deep Q-Networks}\label{sect:appr}

The basis of the model we develop for physical reasoning is a standard deep Q-network (DQN; \cite{mnih-atari-2013,bakhtin2019phyre}).
We augment the loss function used to train this model with a dynamics-aware loss function. 
This allows the model-free DQN learner to explicitly incorporate dynamics of the environment at training time, without having to do accurate dynamics prediction at inference time.

Our backbone model is a ResNet~\cite{He_16} that takes an image depicting the initial scene for task  as input. 
The action, , is parameterized as a -vector\footnote{For the  PHYRE-2B tier, the action is parametrized via a -vector.} that is processed by a multilayer perceptron with one hidden layer to construct an action embedding.
The action embedding is fused with the output of the third ResNet block using FiLM modulation~\cite{perez2017film}. This fused representation is input into the fourth block of the ResNet to obtain a scene-action embedding, . 
We score action  by applying a linear layer with weights  and bias  on .
At training time, we evaluate this score using a logistic loss that compares it against a label, , that indicates whether or not action  solves task :




\noindent\textbf{Dynamics-aware loss.} We develop an auxiliary loss function that encourages the embeddings of actions that lead to similar rollouts in a given scene to be similar.
Given a pair of actions  for task ,
we compute a joint embedding of the two actions  for that task as follows:


Herein,  refers to a combination function: we use the element-wise product by default but we also experiment with outer products and concatenation in Section~\ref{sec:ablations}.
We pass  through another linear layer to predict the similarity of the two actions in task . 
The model is trained to minimize a loss that compares the predicted similarity to a ``ground-truth'' similarity.
Specifically, we bin the ground-truth similarity into  bins and minimize the cross-entropy loss of predicting the right bin:

Herein,  is a one-hot vector of length  indicating the bin in which the ground-truth similarity falls.
The model is trained to minimize , assigning equal weight to both losses.

\noindent\textbf{Measuring action similarity.} To measure the ground-truth similarity, , between two actions  and  on task , we run the simulator on the two scenes obtained after applying the actions.
We track all objects throughout the simulator roll-outs, and measure the Euclidean distance between each object in one roll-out and its counterpart in the other roll-out. 
This results in distance functions, , for all objects  (where  represents time).
We convert the distance function into a similarity functions and aggregate all similarities over time and over all objects:

where  is a hyperparameter that clips the distance at a maximum value, and  is the number of time steps in the roll-out. The similarity  is binned to construct . See Appendix~\ref{apndx:metric} for details. 

\noindent\textbf{Training.} We follow~\cite{bakhtin2019phyre} and train the model using mini-batch SGD.
We balance the training batches to contain an equal number of positive and negative task-action pairs. 
To facilitate computation of , we further constrain the batch composition.
First, we sample  tasks uniformly at random in a batch. 
For each task, we sample  actions that solve the task and  actions that do not solve the task.
We compute the similarity, , for all  action pairs for a task.
To evaluate , we average over these  action pairs.
Simultaneously, we average  over the  task-action pairs.
Additional details on our training procedure as well as hyperparameter settings are presented in the appendix.

\noindent\textbf{Inference.} At inference time, the agent scores a set of  randomly selected actions using the scoring function . The agent proposes the highest-scoring action as a solution. If that action does not solve the task, the agent submits the subsequent highest-scoring action until the task is solved or until the agent has exhausted its attempts (whichever happens first).











 \begin{table}[t]
    \setlength{\tabcolsep}{2pt}
    \footnotesize
    \centering
    \captionof{table}{AUCCESS and success percentage @10 of our approach compared to state-of-the-art models on the PHYRE-1B and 2B tiers in the within-template and cross-template generalization settings. Results are averaged over 10 test folds. We also report the corresponding standard deviations.
    }\label{tab:expts:sota}
    \vspace{1mm}
\tablestyle{4pt}{1.2}
    \resizebox{\linewidth}{!}{\begin{tabular}{@{}lx{\colw }x{\colw}x{\colw}x{\colw}x{\colw}x{\colw}x{\colw}x{\colw}@{}}
\toprule
        & \multicolumn{4}{c}{\bf AUCCESS} & \multicolumn{4}{c}{\bf Success Percentage @10} \\
        &  \multicolumn{2}{c}{\bf PHYRE-1B} & \multicolumn{2}{c}{\bf PHYRE-2B} & \multicolumn{2}{c}{\bf PHYRE-1B} & \multicolumn{2}{c}{\bf PHYRE-2B} \\
        &  \bf Within & \bf Cross & \bf Within & \bf Cross &  \bf Within & \bf Cross & \bf Within & \bf Cross \\
        \midrule
        RAND~\citep{bakhtin2019phyre} & \pms{13.7}{0.5} & \pms{13.0}{5.0} & \pms{3.6}{0.6} & \pms{2.6}{1.5} & \pms{7.7}{0.8} & \pms{6.8}{4.7} &\pms{3.2}{0.8} &\pms{2.2}{1.7}\\
        MEM~\citep{bakhtin2019phyre} & \pms{2.4}{0.3} & \pms{18.5}{5.1} & \pms{3.2}{0.2} & \pms{3.7}{2.3} & \pms{2.7}{0.5} & \pms{15.2}{5.6} & \pms{3.4}{0.3} & \pms{1.9}{1.5}  \\
        DQN~\citep{bakhtin2019phyre} & \pms{77.6}{1.1} & \pms{36.8}{9.7} & \pms{67.8}{1.5} & {\bf \pms{23.2}{9.1}} & \pms{81.4}{1.8} & \pms{34.5}{9.7} &  \pms{74.9}{1.7} & \pms{22.4}{9.5}\\
        {\tt Dec[Joint]1f}~\cite{girdhar2020forward}&  \pms{80.0}{1.2} & {\bf \pms{40.3}{8.0}} &  -- &  --  & \pms{84.1}{1.8} & {\bf \pms{39.2}{8.6}} & -- & --\\
        {\bf Ours} & {\bf \pms{85.2}{1.3}} & \pms{39.9}{8.9} & {\bf \pms{76.4}{1.1}} & {\bf \pms{23.2}{7.4}} & {\bf \pms{89.1}{1.5}} & \pms{38.5}{9.7} & {\bf \pms{83.1}{1.2}} & {\bf \pms{22.7}{8.4}} \\
        \arrayrulecolor{GrayLine}
        \midrule
        DQN (Online)~\citep{bakhtin2019phyre} & -- & \pms{56.2}{10.5} &  -- & \pms{39.6}{11.1} & -- &  \pms{58.1}{10.9} & -- & \pms{41.6}{11.7} \\
        {\bf Ours (Online)} & -- & {\bf \pms{56.4}{9.9}} & -- & {\bf \pms{40.9}{10.2}} &  -- & {\bf \pms{59.1}{10.4}}& -- & {\bf \pms{43.3}{10.6}} \\


        \arrayrulecolor{black}
        \bottomrule
    \end{tabular}}
\end{table}

\section{Experiments}
\label{sect:expts}
{\bf \noindent Dataset.}
We test our dynamics-aware deep Q-network (DQN) on the PHYRE benchmark on both tiers (1B and 2B) and both generalization settings: within-template and cross-template. Following~\cite{bakhtin2019phyre}, we use all 10 folds and evaluate on the test splits in our final experiments; the results are reported in Table~\ref{tab:expts:sota}. For all ablation studies, we use the 4 folds on the validation splits; results are in Table~\ref{tab:expts:ablations}.

{\bf \noindent Implementation Details.}
We train our models as described in Section~\ref{sect:appr}, using both ResNet-18 and ResNet-50 backbones.
We use 100,000 batches with 512 samples per batch. Each batch contains 64 unique tasks with 8 actions per task, such that half of them solve the task (positives) and half of them do not (negatives).
Training is performed using Adam~\cite{Kingma14} with an initial learning rate of  and a cosine learning rate schedule~\cite{loshchilov2016}.
We set , we set the maximum possible distance in a PHYRE scene , and we set the dimensionality of  to 256.
We train and test all models in both the within-template and the cross-template generalization settings.
Following~\cite{bakhtin2019phyre}, we also study the effect of online updates during inference time in the cross-template setting.

\subsection{Ablation Study}\label{sec:ablations}
The results of our ablation study are presented in Table~\ref{tab:expts:ablations}.
In each subtable, we vary only one component of the model and keep all the other components to their default value.
The default values that we used to produce our final results in Table~\ref{tab:expts:sota} are underlined in the subtables.

{\bf \noindent Effect of network depth.} We evaluate the effect of backbone depth in Table~\ref{tab:expts:ablations:backbones}. We observe that ResNet-50 performs a little better than ResNet-18 in the within-template setting, but not in the cross-template setting. These results hold for both ``vanilla'' DQNs and our dynamics-aware DQNs.

{\bf  \noindent  Effect of projection layer.} In Equation~\ref{eqn:approach:joint_embedding}, we described an MLP to project the embedding from the backbone network. In Table~\ref{tab:expts:ablations:embeddor}, we test replacing this module by a linear layer or directly using the backbone embeddings.
We find a two-layer MLP works slightly better and adopt it in our final model.

{\bf \noindent Effect of number of bins, .} We evaluate the effect of the number of bins, , used for classifying action similarity values in . The results in Table~\ref{tab:expts:ablations:bins} show that  performs well but using fewer bins works fine, too. We also compare the bin-classification approach to a regression approach that minimizes mean-squared error (MSE) on the action similarities, and find it to perform worse.

{\bf \noindent Effect of combination function.} We compare different combination functions  for computing the representations . Table~\ref{tab:expts:ablations:combination} presents the results of this comparison. We find that element-wise multiplication  works substantially better than concatenation and matches the performance of combination via a bilinear layer. We opt to use element-wise multiplication over bilinear combination for our final model, as it is computationally cheaper and uses less parameters.

{\bf \noindent Effect of frames considered in action similarity measure.} We evaluate the effect of changing the frames of the simulator roll-out used to compute the action similarity, . The results of this evaluation in Table~\ref{tab:expts:ablations:time} show that using the first 10 frames or the last 5 frames works best. Although the differences are small, using only the first or the last frame is clearly worse.
In our final model, we average the action similarity over the last five 5 frames of the roll-out.

\newcommand\pageSplit{0.6}
\newcommand\pageSplitR{0.33}
\begin{table}[t]
    \centering
    \caption{AUCCESS on PHYRE-1B (averaged over 4 validation folds) observed in our ablation studies. Unless otherwise noted, results are for the within-template setting.\label{tab:expts:ablations}}
    \vspace{3mm}
    \setlength{\tabcolsep}{2pt}
    \footnotesize
    \centering
    \tablestyle{4pt}{1.2}
\begin{minipage}[t]{\pageSplit\linewidth}
        \begin{minipage}[t]{0.59\linewidth}
            \centering
                \subfloat[ResNet backbone depth.\label{tab:expts:ablations:backbones}]
                {\begin{tabular}{@{}lx{\colw}x{\colw}x{\colw}x{\colw}}
                    \toprule
                    \bf Model & \bf Depth  & \bf Within & \bf Cross \\ \midrule
                    DQN &  18 &\pms{81.2}{0.3} & \pms{44.4}{7.4}  \\
                    DQN &  50   &\pms{82.4}{0.4} &   \pms{43.5}{8.9}\\
                    \underline{Ours} &18 &  \pms{83.2}{0.6}&  \pms{44.4}{7.8} \\
                     \underline{Ours}  &\underline{50} &  \pms{83.5}{0.8} &   \pms{42.3}{8.8}\\
                    \bottomrule
                \end{tabular}}
                \hfill
                \subfloat[Projection layer. \label{tab:expts:ablations:embeddor}]{\begin{tabular}{lc}
                    \toprule
                    & \bf AUCCESS \\
                    \midrule
                    None & \pms{82.7}{0.6} \\
                    Linear  &\pms{82.7}{0.8} \\
                    \underline{2-layer MLP} &\pms{83.1}{0.4} \\
                    3-layer MLP & \pms{82.8}{0.5} \\
                    \bottomrule
                \end{tabular}}
        \end{minipage}
        \hfill
        \begin{minipage}[t]{0.4\linewidth}
            \centering
            \subfloat[Number of bins. \label{tab:expts:ablations:bins}]
            {\begin{tabular}{lc}
                \toprule
                  &\bf AUCCESS \\
                \midrule
                2  & \pms{82.9}{0.4}\\
                \underline{5}  & \pms{83.3}{0.5} \\
                10 & \pms{83.2}{0.6} \\
                20  & \pms{82.8}{0.8} \\
                MSE & \pms{82.8}{0.8} \\
                \bottomrule
            \end{tabular}}
            \hfill
            \subfloat[Combination function.\label{tab:expts:ablations:combination}]
            {\begin{tabular}{lc}
                \toprule
                & \bf AUCCESS \\
                \midrule
                \underline{Multiplication} & \pms{83.2}{0.6}   \\
                Concatenation & \pms{82.2}{0.8}  \\
                Bilinear & \pms{83.2}{0.4} \\
                \bottomrule
            \end{tabular}}
        \end{minipage}
    \end{minipage}
    \hfill
\begin{minipage}[t]{\pageSplitR\linewidth}
        \subfloat[Frames used in . \label{tab:expts:ablations:time}]{\begin{tabular}{lc}
\toprule
\bf Frames & \bf AUCCESS \\
            \midrule
            First 1 & \pms{81.7}{0.5} \\
             First 3 & \pms{82.2}{0.3} \\
               First 5 & \pms{82.7}{0.4} \\
            First 10 &\pms{83.2}{1.0} \\
            \arrayrulecolor{GrayLine}
            \midrule
            Last 1 & \pms{82.8}{1.2} \\
            Last 3 & \pms{82.9}{1.0} \\
            \underline{Last 5} & \pms{83.6}{1.1} \\
            Last 10 & \pms{82.5}{0.6} \\
            \arrayrulecolor{GrayLine}
            \midrule
             Entire Rollout & \pms{82.7}{0.8} \\
            \arrayrulecolor{black}
            \bottomrule
        \end{tabular}}
    \end{minipage}
\end{table}

 \newcommand\widthFrac{0.15}
\begin{table}[t]
    \centering
    \setlength\tabcolsep{1.5pt}
    \resizebox{\linewidth}{!}{\begin{tabular}{ccc@{\hspace{1em}}ccc@{\hspace{1em}}cc}
        GT & Baseline & Ours & GT & Baseline & Ours & Baseline & Ours \\
\frame{\includegraphics[width=\widthFrac\linewidth]{visualizations/00022430/00022430gt.png}} &
        \frame{\includegraphics[width=\widthFrac\linewidth]{visualizations/00022430/00022430baseline.png}} &
        \frame{\includegraphics[width=\widthFrac\linewidth]{visualizations/00022430/00022430ours.png}} &
\frame{\includegraphics[width=\widthFrac\linewidth]{visualizations/00022660/00022660gt.png}} &
        \frame{\includegraphics[width=\widthFrac\linewidth]{visualizations/00022660/00022660baseline.png}}  &\frame{\includegraphics[width=\widthFrac\linewidth]{visualizations/00022660/00022660ours.png}} &
        \frame{\includegraphics[width=\widthFrac\linewidth]{visualizations/action_embedding_sim/threshold_0.90/baseline.png}}  &
        \frame{\includegraphics[width=\widthFrac\linewidth]{visualizations/action_embedding_sim/threshold_0.90/ours.png}}
        \\
        \multicolumn{3}{c@{\hspace{1em}}}{ (a) Task A} & \multicolumn{3}{c@{\hspace{1em}}}{(b) Task B} & \multicolumn{2}{c}{(c) Task B top actions space} \\
    \end{tabular}}
    \captionof{figure}{In (a) and (b), we visualize all the ground truth (GT) and top 10 predicted actions' positions () that solves the above two tasks, with darker color representing higher confidence. On Task A, our method performs similarly to a dynamics-agnostic baseline. In Task B where the incline is slanted the other way, however, the baseline model is confused between two possible sets of positions of the action. By contrast, our dynamics-aware DQN model is able to solve this task correctly. Finally in (c), we visualize all actions with  cosine similarity to any action that solves the task, with denser color higher similarity. The illustration suggests that our dynamics-aware DQN model is able to rule out incorrect actions much more effectively than the baseline DQN model.
    }\label{fig:expts:inclination}
\end{table}





\subsection{Comparison to SOTA and Qualitative Analysis}
Table~\ref{tab:expts:sota} presents the AUCCESS and success percentage of our best dynamics-aware DQNs, and compares it to results reported in prior work.
The results show the strong performance of our models: in the within-template setting, our models improve the prior state-of-the-art AUCCESS by 5 to 8 points.
In the cross-template setting, our dynamics-aware DQN also outperforms it dynamics-agnostic counterpart but does not outperform a model that makes full dynamics prediction~\cite{girdhar2020forward}.
Nevertheless, the results suggest dynamics-aware DQNs have the potential to improve physical-reasoning models.
Figure~\ref{fig:expts:inclination} illustrates these results by visualizing how our dynamics-aware DQN model more effectively rules out parts of the action space that cannot lead to a successful solution.
 \section{Conclusion}
We have presented a dynamics-aware DQN model for efficient physical reasoning that is better at capturing object dynamics than baseline models, without having to do explicit forward prediction. Our best models substantially outperform prior work on the challenging PHYRE benchmark.
 


\bibliography{refs}
\bibliographystyle{iclr2021_conference}


\clearpage
\appendix
\section{Action Similarity Metric}
\label{apndx:metric}
The similarity between two actions is computed from the object feature representation of the actions' rollouts provided by the PHYRE API. For two rollouts of two actions  we use the notation that  and  are the locations of the object  at the timestep  in the rollouts of  and  respectively then:





where  is the set of moving objects in the scene,  and  are the lengths of the first and second rollouts respectively and  is a hyperparameter that clips the distance at a maximum value.
When computing the metric using only "last " frames the frames we consider are the frames from time  to .
The similarity  is binned to construct  as follows:

where  is an operator that rounds continuous numbers to the nearest integer and  is the number of bins used.


In Table~\ref{tab:expts:sota}, we take . This value is suggested by the PHYRE environment since the coordinates of locations in the scene fall in the square limited by the corner points  and  with the maximum possible Euclidean distance between two objects being . In other environments we might not have easy access to the maximum possible Euclidean distance or it might not be finite. To study the sensitivity of our method with respect to this parameter choice we train a group of models with arbitrary values for . Using a value  corresponds to disabling distance thresholding altogether. We show the results in Table~\ref{tab:apndx:maxdist} and find the effect using an arbitrary distance threshold to be negligible.


\section{Additional Ablations}


\begin{table}[t]
    \begin{minipage}[t]{0.53\linewidth}
    \caption{
            Maximum distance at which distances are clipped. We find stable performance across different clipping distance, and use 0.1 for final results.
            \label{tab:apndx:maxdist}}
            \centering
            \vspace{1mm}
            \begin{tabular}{lc}
            \toprule
             & \bf AUCCESS  \\
            \midrule
            \underline{0.1} & \pms{83.2}{0.6} \\
            0.2 & \pms{82.7}{0.9} \\
            0.5  & \pms{83.3}{0.4} \\
            0.7  & \pms{83.3}{0.8}  \\
             & \pms{83.4}{0.5}  \\
            \bottomrule
            \end{tabular}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.44\linewidth}
    \caption{
DQN trained with our modified batch composition approach used for training our dynamics-aware models. We find the batching by itself does not lead to any gains.
    \label{tab:apndx:ablations:sampling}}
       \vspace{1mm}
       \centering
        \begin{tabular}{lc}
                \toprule
                \bf Batching approach   &\bf AUCCESS \\
                \midrule
                Standard~\cite{bakhtin2019phyre} & \pms{81.1}{0.4} \\
                Ours & \pms{81.6}{0.8}\\
                \bottomrule
        \end{tabular}
    \end{minipage}
\end{table}

Here we conduct one further ablation to those that were carried out in Section~\ref{sec:ablations}.
Here we examine the effect of our batch composition on the models
In~\cite{bakhtin2019phyre} the task-actions pairs are sampled uniformly at random with the sole imposed constraint that the number of negative examples are equal to the number of positive examples in the batch.
This label balancing is in line with standard practices such as over-sampling which are beneficial when training on datasets with heavy label imbalances.
In our method, we keep this label balancing and to facilitate using the auxiliary losses we impose an additional constraint such that in each batch we have multiple actions for each task as described in Section~\ref{sect:appr}.
We examine the effect of this modified batch composition in Table~\ref{tab:apndx:ablations:sampling} and we find that this change alone does not lead to a significant performance improvement.



\begin{figure}[t]
    \rotatebox{90}{\small ~~~~~~AUCCESS} \hfill
    \subfloat[Template\label{fig:apndx:aucsbytemp}]{
        \includegraphics[height=0.95in]{visualizations/aucsByTemplate.pdf}
    }\hfill
    \subfloat[No.\ of moving objects\label{fig:apndx:aucsbymov}]{
        \includegraphics[height=0.95in]{visualizations/aucsByMovingObjs.pdf}
    }
    \caption{Here we break down the AUCCESS by template in~\ref{fig:apndx:aucsbytemp} and number of moving objects in \ref{fig:apndx:aucsbymov}. We see our agents biggest gains are on templates where the baseline performs worst, while the baseline marginally outperforms our models in the templates where baseline was already performing well. We aggregate the templates by the number of moving objects in where we see our model outperforming the baseline across all numbers of moving objects.}\label{fig:apndx:templateBreakdown}
\end{figure}

\begin{figure}[t]
    \centering
    \setlength\tabcolsep{1.5pt}
    \begin{minipage}[t]{0.37\linewidth}
        \centering
        \tiny
        \begin{tabular}{cc}
            \rotatebox{90}{~~~~~~~~~ AUCCESS} &
            \includegraphics[width=0.9\linewidth]{visualizations/meanOverSeedRegPlot.pdf} \\
            & Baseline AUCCESS \\
        \end{tabular}
        \captionof{figure}{Here we show baseline AUCCESS vs AUCCESS from our method and find a statistically significant correlation with a Pearson correlation factor of -0.55. This shows we get highest gains on templates where the baseline performs poorly.\label{fig:expts:aucsbytemp}
        \label{fig:apndx:deltacorr}}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.6\linewidth}
        \centering
        \tiny
        \begin{tabular}{cccccc}
            GT & & sim & sim & sim & sim \\
\frame{\includegraphics[width=0.18\linewidth]{visualizations/00022660/00022660gt.png}} &
            \rotatebox{90}{~~~~Baseline} &
            \frame{\includegraphics[width=0.18\linewidth]{visualizations/action_embedding_sim/threshold_-1.00/baseline.png}} &
            \frame{\includegraphics[width=0.18\linewidth]{visualizations/action_embedding_sim/threshold_0.50/baseline.png}} &
            \frame{\includegraphics[width=0.18\linewidth]{visualizations/action_embedding_sim/threshold_0.90/baseline.png}} &
            \frame{\includegraphics[width=0.18\linewidth]{visualizations/action_embedding_sim/threshold_0.98/baseline.png}} \\
&
            \rotatebox{90}{~~~~~Ours} &
            \frame{\includegraphics[width=0.18\linewidth]{visualizations/action_embedding_sim/threshold_-1.00/ours.png}} &
            \frame{\includegraphics[width=0.18\linewidth]{visualizations/action_embedding_sim/threshold_0.50/ours.png}} &
            \frame{\includegraphics[width=0.18\linewidth]{visualizations/action_embedding_sim/threshold_0.90/ours.png}} &
            \frame{\includegraphics[width=0.18\linewidth]{visualizations/action_embedding_sim/threshold_0.98/ours.png}} \\
        \end{tabular}
        \captionof{figure}{Here we show an extended version of Figure~\ref{fig:expts:inclination} (c), showing action space embeddings color coded by similarity to GT actions, at different similarity thresholds. We observe our method leads to actions is able to rule out actions incapable of solving the task at all thresholds, and at 0.98 the selected actions are almost indistinguishable from GT.}\label{fig:appdx:embeddings_full}
    \end{minipage}
\end{figure}


\begin{table}[t]
    \centering

\end{table}


\section{Qualitative Study}
We break down the AUCCESS improvement by template in Figure~\ref{fig:apndx:templateBreakdown} and try to characterize the the templates in which our method improves most over the baseline and we find in Figure~\ref{fig:apndx:deltacorr} that our method introduces the highest gains in templates which the performance of the baseline was lower. This holds even when comparing across templates where the baseline has still not reached maximum performance.
In Figure~\ref{fig:appdx:embeddings_full}, we show all actions for the given task, color coded by their similarity to GT actions for ours and baseline model. We find our dynamics-aware model is able to rule out incorrect actions much more effectively than the baseline, at all different levels of similarity thresholds considered.

















 
\end{document}
