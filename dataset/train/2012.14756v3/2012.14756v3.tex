

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2021}
\usepackage{times}
\usepackage{latexsym}
\renewcommand{\UrlFont}{\ttfamily\small}


\usepackage{tabularx}
\makeatletter
\def\hlinewd#1{\noalign{\ifnum0=`}\fi\hrule \@height #1 \futurelet\reserved@a\@xhline}
\makeatother

\usepackage{microtype}

\aclfinalcopy 



\newcommand\BibTeX{B\textsc{ib}\TeX}

\usepackage{adjustbox}
\usepackage{multicol}  
\usepackage{multirow} 
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{makecell}

\usepackage{verbatim}
\usepackage{mathtools}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{booktabs}
\newcommand\mc[1]{\multicolumn{1}{l}{#1}}
\usepackage{booktabs}
\usepackage{makecell}
\usepackage{ulem}
\usepackage{cleveref}
\usepackage{ulem}

\usepackage{times}
\usepackage{latexsym}
\renewcommand{\UrlFont}{\ttfamily\small}

\usepackage{algpseudocode} 
\newcommand\Tau{\mathrm{T}}
\usepackage[hang,flushmargin]{footmisc}


\usepackage[linesnumbered,ruled]{algorithm2e}
\SetAlFnt{\small}
\SetAlCapNameFnt{\normalsize}
\makeatletter
\newcommand{\nosemic}{\renewcommand{\@endalgocfline}{\relax}}\newcommand{\dosemic}{\renewcommand{\@endalgocfline}{\algocf@endline}}\newcommand{\pushline}{\Indp}\newcommand{\popline}{\Indm\dosemic}\let\oldnl\nl \newcommand{\nonl}{\renewcommand{\nl}{\let\nl\oldnl}}\makeatother

\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}



\usepackage{tabularx}
\makeatletter
\def\hlinewd#1{\noalign{\ifnum0=`}\fi\hrule \@height #1 \futurelet\reserved@a\@xhline}
\makeatother


\usepackage{algpseudocode}  
\usepackage{amsmath}
\usepackage{multicol}  
\usepackage{multirow} 
\usepackage{flexisym}
\usepackage{graphicx}  \usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\usepackage{cleveref}
\crefformat{section}{\S#2#1#3} \crefformat{subsection}{\S#2#1#3}
\crefformat{subsubsection}{\S#2#1#3}




\newcommand{\ys}[1]{\textcolor{blue}{\textbf{ys: #1}}}
\newcommand{\cd}[1]{\textcolor{pink}{\textbf{cd: #1}}}

\title{Dialogue Response Selection with Hierarchical Curriculum Learning}
\author{Yixuan Su\thanks{~~The main body of this work was done during internship at Tencent Inc. The first two authors contributed equally. Yan Wang is the corresponding
author.}~\quad Deng Cai\quad  Qingyu Zhou\quad Zibo Lin\quad Simon Baker\quad \\
\textbf{Yunbo Cao}\quad \textbf{Shuming Shi}\quad \textbf{Nigel Collier}\quad \textbf{Yan Wang}  \\
Language Technology Lab, University of Cambridge \\
The Chinese University of Hong Kong \\
Tencent Inc.\\

\\ {\tt \{ys484,sb895,nhc30\}@cam.ac.uk}\\ {\tt thisisjcykcd@gmail.com} \\ {\tt \{qingyuzhou,jimblin,yunbocao,shumingshi,brandenwang\}@tencent.com}\\
}

\date{}

\begin{document}
\maketitle
\begin{abstract}
We study the learning of a matching model for dialogue response selection. Motivated by the recent finding that models trained with random negative samples are not ideal in real-world scenarios, we propose a hierarchical curriculum learning framework that trains the matching model in an ``easy-to-difficult" scheme. Our learning framework consists of two complementary curricula: (1) corpus-level curriculum (CC); and (2) instance-level curriculum (IC). In CC, the model gradually increases its ability in finding the matching clues between the dialogue context and a response candidate. As for IC, it progressively strengthens the model's ability in identifying the mismatching information between the dialogue context and a response candidate. Empirical studies on three benchmark datasets with three state-of-the-art matching models demonstrate that the proposed learning framework significantly improves the model performance across various evaluation metrics.\end{abstract}


\section{Introduction}
\label{sec:intro}
Building intelligent conversation systems is a long-standing goal of artificial intelligence and has attracted much attention in recent years \cite{DBLP:journals/corr/abs-1801-01957,DBLP:conf/naacl/KollarBSOCMKSM18}. An important challenge for building such conversation systems is the response selection problem, that is, selecting the best response to a given dialogue context from a set of candidate responses \cite{DBLP:conf/emnlp/RitterCD11}.

\begin{table}[tb]
\begin{center}
\resizebox{0.98\columnwidth}{!}{
\begin{tabular}{|l|}
\hline
\textbf{Dialogue Context Between Two Speakers A and B} \\
\hline
\textbf{A}: Would you please recommend me a good TV series \\\hspace{1em} to watch during my spare time?  \\

\textbf{B}: Absolutely! Which kind of TV series are you most\\\hspace{1em} interested in?  \\
\textbf{A}: My favorite type is fantasy drama. \\
\textbf{B}: I think both Game of Thrones and The Vampire \\\hspace{1em} Diaries are good choices.  \\
\hline

\makecell[c]{\textbf{Positive Response}}  \\
\hline
\textbf{P1}: Awesome, I believe both of them are great TV \\\hspace{1em} \; series! I will first watch Game of Thrones. (\textbf{Easy})\\
\textbf{P2}: Cool! I think I find the perfect thing to kill my\\\hspace{1em} \; weekends. \; \; \; \; \; \; \; \; \; \; \; \; \; \; \; \; \; \; \; \;(\textbf{Difficult})\\
\hline
\makecell[c]{\textbf{Negative Response}}  \\
\hline
\textbf{N1}: This restaurant is very expensive. \; \; \; \; \; \; (\textbf{Easy})\\
\textbf{N2}: Iain Glen played Ser Jorah Mormont in the HBO \\\hspace{1em} \; fantasy series Game of Thrones. \; \; \; \; \;(\textbf{Difficult})\\
\hline
\end{tabular}
}
\end{center}
  \caption{An example dialogue context between speakers A and B, where P1 and P2 are easy and difficult positives; N1 and N2 are easy and difficult negatives.}
\label{tb:retrieved_example}
\end{table}

To tackle this problem, different matching models are developed to measure the matching degree between a dialogue
context and a response candidate \cite{DBLP:conf/acl/WuWXZL17,DBLP:conf/acl/WuLCZDYZL18,DBLP:conf/acl/LuZXLZX19,DBLP:conf/cikm/GuLL19}. Despite their differences, most prior works train the model with data constructed by a simple heuristic. For each context, the human-written response is considered as positive (i.e., an appropriate response) and the responses from other dialogue contexts are considered as negatives (i.e., inappropriate responses). In practice, the negative responses are often randomly sampled and the training objective ensures that the positive response scores are higher than the negative ones.

Recently, some researchers \cite{li-etal-2019-sampling,lin2020world} have raised the concern that randomly sampled negative responses are often too trivial (i.e., totally irrelevant to the dialogue context). Models trained with trivial negative responses may fail to handle strong distractors in real-world scenarios. Essentially, the problem stems from the ignorance of the diversity in context-response matching degree. In other words, all random responses are treated as equally negative regardless of their different distracting strengths. For example, Table \ref{tb:retrieved_example} shows a conversation between two speakers and two negative responses (N1, N2) are presented. For N1, one can easily dispel its appropriateness as it unnaturally diverges from the TV show topic. On the other hand, N2 is a strong distractor as it overlaps significantly with the context (e.g., \textit{fantasy series} and \textit{Game of Thrones}). Only with close observation we can find that N2 does not maintain the coherence of the discussion, i.e., it starts a parallel discussion about an actor in \textit{Game of Thrones} rather than elaborating on the enjoyable properties of the TV series. In addition, we also observe a similar phenomenon on the positive side. For different training context-response pairs, their pairwise relevance also varies. In Table \ref{tb:retrieved_example}, two positive responses (P1, P2) are provided for the given context. For P1, one can easily confirm its validity as it naturally replies the context. As for P2, while it expatiates on the enjoyable properties of the TV series, it does not exhibit any obvious matching clues (e.g., lexical overlap with the context). Therefore, to correctly identify P2, its relationship with the context must be carefully reasoned by the model. \\\indent Inspired by the above observations, in this work, we propose to employ the idea of curriculum learning (CL) \cite{DBLP:conf/icml/BengioLCW09}. The key to applying CL is to specify a proper learning scheme under which all training examples are learned. By analyzing the characteristics of the concerned task, we tailor-design a hierarchical curriculum learning (HCL) framework. Specifically, our learning framework consists of two complementary curriculum strategies, corpus-level curriculum (CC) and instance-level curriculum (IC), covering the two distinct aspects of response selection. In CC, the model gradually increases its ability in finding matching clues through an easy-to-difficult arrangement of positive context-response pairs. In IC, we sort all negative responses according to their distracting strength such that the modelâ€™s capability of identifying the mismatching information can be progressively strengthened. \\\indent Notably, our learning framework is independent to the choice of matching models. For a comprehensive evaluation, we evaluate our approach on three representative matching models, including the current state of the art.
Results on three benchmark datasets demonstrate that the proposed learning framework leads to remarkable performance improvements across all evaluation metrics. \\\indent
In a nutshell, our contributions can be summarized as:
(1) We propose a hierarchical curriculum learning framework to tackle the task of dialogue response selection; and (2) Empirical results on three benchmark datasets show that our approach can significantly improve the performance of various strong matching models, including the current state of the art.


\begin{figure*}[t] 
	\centering    
	\setlength{\abovecaptionskip}{3pt}
\includegraphics[width=1.0\textwidth]{images/HCL.png}
	\caption{An illustration of the proposed learning framework: On the left part, two training context-response pairs with different difficulty levels are presented (the upper one is more difficult than the lower one, and \textbf{P} denotes the positive response). For each training instance, we show three associated negative responses (\textbf{N1}, \textbf{N2} and \textbf{N3}) with increasing difficulty from the bottom to the top. In the negative responses, the words that also appear in the dialogue context are marked as \textit{italic}.}
\label{fig:overview_diagram}
\end{figure*}




\section{Background}
Given a dataset , the learning of a matching model  is to correctly identify the positive response  conditioned on the dialogue context  from a set of negative responses . The learning objective is typically defined as 

where  is the number of negative responses associated with each training context-response pair. In most existing studies  \cite{DBLP:conf/acl/WuWXZL17,DBLP:conf/acl/WuLCZDYZL18,DBLP:conf/cikm/GuLL19}, the training negative responses  are randomly selected from the dataset . Recently, \citet{li-etal-2019-sampling} and \citet{lin2020world} proposed different approaches to strengthen the training negatives. In testing, for any context-response , the models give a score  that reflects their pairwise matching degree. Therefore, it allows the user to rank a set of response candidates according to the scores for response selection.


\section{Methodology}
\subsection{Overview}
We propose a \textit{hierarchical curriculum learning} (HCL) framework for training neural matching models. It consists of two complementary curricula: (1) corpus-level curriculum (CC); and (2) instance-level curriculum (IC). Figure \ref{fig:overview_diagram} illustrates the relationship between these two strategies. In CC (\cref{sec:cc}), the training context-response pairs with lower difficulty are presented to the model before harder pairs. This way, the model gradually increases its ability to find the matching clues contained in the response candidate.
As for IC (\cref{sec:ic}), it controls the difficulty
of negative responses that associated with each training context-response pair. Starting from easier negatives, the model progressively strengthens its ability to identify the mismatching information (e.g., semantic incoherence) in the response candidate. 
The following gives a detailed description of the proposed approach. 


\subsection{Corpus-Level Curriculum}
\label{sec:cc}
Given the dataset , the corpus-level curriculum (CC) arranges the ordering of different training context-response pairs. The model first learns to find easier matching clues from the pairs with lower difficulty. As the training progresses, harder cases are presented to the model to learn less obvious matching signals. Two examples are shown in the left part of Figure \ref{fig:overview_diagram}. For the easier pair, the context and the positive response are semantically coherent as well as lexically overlapped (e.g., \textit{TV series} and \textit{Game of Thrones}) with each other and such matching clues are simple for the model to learn. As for the harder case, the positive response can only be identified via numerical reasoning, which makes it harder to learn.


\begin{figure*}[t] 
	\centering    
	\setlength{\abovecaptionskip}{3pt}
\includegraphics[width=1.0\textwidth]{images/hcl_curve.png}
	\caption{(a) Illustration of the corpus-level curriculum. At each step: (1)  is computed based on the current step ; and (2) a batch of context-response pairs are uniformly sampled from the training instances whose corpus-level difficulty is lower than  (shaded area in the example). In this example,  and ; (b) Illustration of the instance-level pacing function. In this example, , , and .}
\label{fig:cc}
\end{figure*}

\paragraph{Difficulty Function.} To measure the difficulty of each training context-response pair , we adopt a pre-trained ranking model  (\cref{sec:ranker}) to calculate its relevance score as . Here, a higher score of  corresponds to a higher relevance between  and  and vice versa. Then, for each pair , its corpus-level difficulty  is defined as 


where  is normalized to . Here, a lower difficulty score indicates the pair  is easier for the model to learn and vise versa.


\paragraph{Pacing Function.} In training, to select the training context-response pairs with appropriate difficulty, we define a corpus-level pacing function, , which controls the pace of learning from easy to hard instances. In other words, at time step ,  represents the upper limit of difficulty and the model is only allowed to use the training instances  whose corpus-level difficulty score  is lower than . In this work, we propose a simple functional form for \footnote{More sophisticated designs for the function  are possible, but we do not consider them in this work.} as

where  is a predefined initial value. At the training warm up stage (first  steps), we learn a basic matching model with a easy subset of the training data. In this subset, the difficulty of all samples are lower than . After  becomes  (at time step ), the corpus-level curriculum is completed and the model can then freely access the entire dataset. In Figure \ref{fig:cc}(a), we give an illustration of the corpus-level curriculum.



\subsection{Instance-Level Curriculum}
\label{sec:ic}
As a complement of CC, the instance-level curriculum (IC) controls the difficulty of negative responses. For an arbitrary training context-response pair , while its associated negative responses can be any responses  () in the training set, the difficulties of different  are diverse. Some examples are presented in the right part of Figure \ref{fig:overview_diagram}. We see that the negative responses with lower difficulty are always simple to spot as they are often obviously off the topic. As for the harder negatives, the model need to identify the fine-grained semantic incoherence between them and the context.

 

The main purpose of IC is to select negative responses with appropriate difficulty based on the state of the learning process. At the beginning, the negative responses are randomly sampled from the entire training set, so that most of them are easy to distinguish. As the training evolves, IC gradually increases the difficulty of negative responses by sampling them from the responses with higher difficulty (i.e., from a harder subset of the training data). In this way, the model's ability in finding the mismatching information is progressively strengthened and will be more robust when handling those strong distractors in real-world scenarios. 
 

\paragraph{Difficulty Function.} Given a specific training instance , we define the difficulty of an arbitrary response  () as its rank in a sorted list of relevance score in descending order, 

In this formula, the response  with the highest relevance score, i.e., , has a rank of 1, thus . For the response  with the lowest relevance score, i.e., , has a rank of , thus . Here, a smaller rank means the corresponding negative response is more relevant to the context , thus it is more difficult for the model to distinguish.



\paragraph{Pacing Function.} 
Similar to CC, in IC, the pace of learning from easy to difficult negative responses is controlled by an instance-level pacing function, . It adjusts the size of the sampling space (in log scale) from which the negative responses are sampled from. Given a training instance , at time step , the negative examples are sampled from the responses  () whose rank is smaller than  (), i.e., the negative responses are sampled from a subset of the training data which consists of the top- relevant responses in relation to . The smaller the  is, the harder the sampled negatives will be. In this work, we define the function  as 

where  is the same as the one in the corpus-level pacing function . , meaning that, at the start of training, the negative responses are sampled from the entire training set .  is a hyperparameter and it is smaller than . After  becomes  (at step ), the instance-level curriculum is completed. For the following training steps, the size of the sampling space is fixed at . An example of  is depicted in Figure \ref{fig:cc}(b).


\normalem
\begin{algorithm}[t]
    \caption{Hierarchical Curriculum Learning}
    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
    
    \Input{Dataset, ; model trainer, , that takes batches of training data as input to optimize the matching model; corpus-level difficulty and pacing function,  and ; instance-level difficulty and pacing function,  and ; number of negative responses, ;}

    \For{train step }
      {
        \nosemic Uniformly sample one batch of context-response pairs, , from all , such that , as shown in Figure \ref{fig:cc}(a).\;
        \For{ in }
        {
            \nosemic Sample  negative responses, , from all responses , where , that satisfies the condition . 
        }
        Invoke the trainer, , using  as input to optimize the model using Eq. \eqref{eq:matching_model}.
      }
    \Output{Trained Matching Model}
\end{algorithm}

\subsection{Hierarchical Curriculum Learning}
\label{sec:ranker}


\paragraph{Model Training.} Our learning framework jointly employs the corpus-level and instance-level curriculum.
For each training step, we construct a batch of training data as follows: First, we select the positive context-response pairs according to the corpus-level pacing function . Then, for each instance in the selected batch, we sample its associated negative examples according to the instance-level pacing function . Details of our learning framework are presented in Algorithm 1.


\paragraph{Fast Ranking Model.} As described in Eq. \eqref{eq:corpus-difficulty} and \eqref{eq:instance-difficulty}, our framework requires a ranking model  that efficiently measures the pairwise relevance of millions of possible context-response combinations. In this work, we construct  as
an non-interaction matching model with dual-encoder structure such that we can precompute all contexts and responses offline and store them in cache. For any context-response pair , 
its pairwise relevance  is defined as 

where  and  are the dense context and response representations produced by a context encoder  and a response encoder \footnote{The encoders can be any model, e.g., LSTM \cite{DBLP:journals/neco/HochreiterS97} and Transformers \cite{DBLP:conf/nips/VaswaniSPUJGKP17}.}. 

\paragraph{Offline Index.} 
After training the ranking model on the same response selection dataset  using the in-batch negative objective \cite{DBLP:conf/emnlp/KarpukhinOMLWEC20}, we compute the dense representations of all contexts and responses contained in . Then, as described in Eq. \eqref{eq:similarity}, the relevance scores of all possible combinations of the contexts and responses in  can be easily computed through the dot product between their representations. After this step, we can compute the corpus-level and instance-level difficulty of all possible combinations and cache them in memory for a fast access in training.  


\section{Related Work}
\label{sec:related}
\paragraph{Dialogue Response Selection.} Early studies in this area devoted to the response selection for single-turn conversations \cite{DBLP:conf/emnlp/WangLLC13,tan2016lstmbased,DBLP:journals/corr/abs-2004-02214}. Recently, researchers turned to the scenario of multi-turn conversations and many sophisticated neural network architectures have been devised \cite{DBLP:conf/acl/WuWXZL17,DBLP:conf/cikm/GuLL19,DBLP:conf/acl/WuLCZDYZL18,DBLP:conf/cikm/GuLLLSWZ20}. 

There is an emerging line of research studying how to improve existing matching models with better learning algorithms. \citet{DBLP:conf/acl/WuwLZ18} proposed to adopt a Seq2seq model as weak teacher to guide the training process. \citet{DBLP:conf/acl/FengTWFZY19} designed a co-teaching framework to eliminate the training noises. Similar to our work, \citet{li-etal-2019-sampling} proposed to alleviate the problem of trivial negatives by sampling stronger negatives. \citet{lin2020world} attempted to create  negative examples with a retrieval system and a pre-trained generation model. In contrast to their studies, we not only enlarge the set of negative examples but also arrange the negative examples in an easy-to-diffuclt fashion.


\begin{table*}[tb]
	\small
	\centering
	\renewcommand{\arraystretch}{1.15}
	\scalebox{0.805}{
	\begin{tabular}{lccccccccccccc}
\hlinewd{0.75pt}
		\multicolumn{1}{c}{\multirow{2}{*}{\textbf{Model}}}    & \multicolumn{6}{c}{\textbf{Douban}}& \multicolumn{4}{c}{\textbf{Ubuntu}}&\multicolumn{3}{c}{\textbf{E-Commerce}}  \\ \cmidrule(lr){2-7}
		\cmidrule(lr){8-11}
		\cmidrule(lr){12-14}
		&  &  & @ & @ & @ & @&@&@ & @ & @&@ & @ & @  \\
		\hline
RNN  &0.390 &0.422 &0.208 &0.118 &0.223 &0.589  &0.768 &0.403 &0.547 &0.819&0.325&0.463&0.775\\ 
		CNN &0.417 &0.440 &0.226 &0.121 &0.252 &0.647  &0.848 &0.549 &0.684 &0.896&0.328&0.515&0.792  \\
		LSTM& 0.485&0.527 &0.320 &0.187 &0.343 &0.720  &0.901 &0.638 &0.784 &0.949&0.365&0.536&0.828  \\
	    BiLSTM&0.479 &0.514 &0.313 &0.184 &0.330 &0.716  &0.895 &0.630 &0.780 &0.944&0.355&0.525&0.825  \\
		MV-LSTM&0.498 &0.538 &0.348 &0.202 &0.351 &0.710  &0.906 &0.653 &0.804 &0.946&0.412&0.591&0.857  \\
		Match-LSTM&0.500 &0.537 &0.345 &0.202 &0.348 &0.720  &0.904 &0.653 &0.799 &0.944&0.410&0.590&0.858  \\
\hline
DL2R& 0.488 &0.527 &0.330 &0.193 &0.342 &0.705  &0.899 &0.626 &0.783 &0.944&0.399&0.571&0.842  \\
		Multi-View&0.505 &0.543 &0.342 &0.202 &0.350 &0.729  &0.908 &0.662 &0.801 &0.951&0.421&0.601&0.861  \\
		DUA&0.551 &0.599 &0.421 &0.243 &0.421 &0.780  &- &0.752 &0.868 &0.962&0.501&0.700&0.921  \\
		DAM&0.550 &0.601 &0.427 &0.254 &0.410  &0.757 &0.938 &0.767 &0.874 &0.969&0.526&0.727&0.933 \\
MRFN&0.571 &0.617 &0.448 &0.276 &0.435 &0.783  &0.945 &0.786 &0.886 &0.976&-&-&-  \\
		IOI& 0.573& 0.621&0.444 &0.269 &0.451 &0.786  &0.947 &0.796 &0.894 &0.974&0.563&0.768&0.950  \\
\hline
SMN  & 0.529 & 0.569 & 0.397 & 0.233 & 0.396 & 0.724  &0.926&0.726&0.847&0.961&0.453&0.654&0.886  \\
		MSN  & 0.587 & 0.632 & 0.470 & 0.295 & 0.452 & 0.788  &-&0.800&0.899&0.978&0.606&0.770&0.937   \\
		SA-BERT &  0.619&  0.659&  0.496&  0.313& 0.481 &   0.847&0.965&0.855&0.928&0.983&0.704&0.879&0.985   \\   
\hline
SMN+HCL  &0.575  & 0.620 &0.446  &0.281  &0.452  &0.807 &0.947&0.777&0.885&0.981&0.507&0.723&0.935   \\
		MSN+HCL &0.620  &0.668  &0.507  &0.321  &0.508  &0.841 &0.969&0.826&0.924&0.989&0.642&0.814&0.968    \\
		SA-BERT+HCL &\textbf{0.639}  &\textbf{0.681}  &\textbf{0.514}  &\textbf{0.330}  &\textbf{0.531}  &\textbf{0.858}   &\textbf{0.977}&\textbf{0.867}&\textbf{0.940}&\textbf{0.992}&\textbf{0.721}&\textbf{0.896}&\textbf{0.993}   \\
\hlinewd{0.75pt}
	\end{tabular}}
	\caption{Experimental results of different models trained with our approach on Douban, Ubuntu, and E-Commerce datasets. All results acquired using HCL outperforms the original results with a significance level .
}
	\label{tb:main_result}
\end{table*}

\paragraph{Curriculum Learning.} Curriculum Learning \cite{DBLP:conf/icml/BengioLCW09} is reminiscent of the cognitive process of human being. Its core idea is first learning easier concepts and then gradually transitioning to more complex concepts based on some predefined learning schemes. Curriculum learning (CL) has demonstrated its benefits in various machine learning tasks \cite{DBLP:conf/naacl/SpitkovskyAJ10,DBLP:conf/cvpr/IlgMSKDB17,DBLP:conf/bmvc/LiZHXK17,DBLP:conf/aaai/SvetlikLSSWS17,DBLP:conf/ijcai/LiuH0018,DBLP:conf/naacl/PlataniosSNPM19}. Recently, \citet{DBLP:conf/ecir/PenhaH20} employed the idea of CL to tackle the response selection task. However, they only apply curriculum learning for the positive-side response selection, while ignoring the diversity of the negative responses.


\section{Experiment Setups}
\subsection{Datasets and Evaluation Metrics}
We test our approach on three benchmark datasets.

\paragraph{Douban Dataset.} This dataset \cite{DBLP:conf/acl/WuWXZL17} consists of multi-turn Chinese conversation data crawled from Douban group\footnote{https://www.douban.com/group}. The size of training, validation and test set are 500k, 25k and 1k. In the test set, each dialogue context is paired with 10 candidate responses. Following previous works, we report the results of Mean Average Precision (MAP), Mean Reciprocal Rank (MRR) and Precision at Position 1 (). In addition, we also report the results of , , , where  means recall at position  in  candidates. 

\paragraph{Ubuntu Dataset.} This dataset \cite{DBLP:conf/sigdial/LowePSP15} contains multi-turn dialogues collected from chat logs of the Ubuntu Forum. The training, validation and test size are 500k, 50k and 50k. Each dialogue context is paired with 10 response candidates. Following previous studies, we use , ,  and  as evaluation metrics.

\paragraph{E-Commerce Dataset.} This dataset \cite{DBLP:conf/coling/ZhangLZZL18} consists of Chinese conversations between customers and customer service staff from Taobao\footnote{www.taobao.com}. The size of training, validation and test set are 500k, 25k and 1k. In the test set, each dialogue context is paired with 10 candidate responses.  are employed as the evaluation metrics. 

\subsection{Baseline Models}
In the experiments, we compare our approach with the following models that can be summarized into three categories. 

\paragraph{Single-turn Matching Models.} This type of models treats all dialogue context as a single long utterance and then measures the relevance score between the context and response candidates, including RNN \cite{DBLP:conf/sigdial/LowePSP15}, CNN \cite{DBLP:conf/sigdial/LowePSP15}, LSTM \cite{DBLP:conf/sigdial/LowePSP15}, Bi-LSTM \cite{DBLP:journals/corr/KadlecSK15},  MV-LSTM \cite{DBLP:conf/ijcai/WanLXGPC16} and Match-LSTM \cite{DBLP:conf/naacl/WangJ16}.

\paragraph{Multi-turn Matching Models.} Instead of treating the dialogue context as one single utterance, these models aggregate information from different utterances in more sophisticated ways, including DL2R \cite{DBLP:conf/sigir/YanSW16}, Multi-View \cite{DBLP:conf/emnlp/ZhouDWZYTLY16}, DUA \cite{DBLP:conf/coling/ZhangLZZL18}, DAM \cite{DBLP:conf/acl/WuLCZDYZL18}, MRFN \cite{10.1145/3289600.3290985}, IOI \cite{DBLP:conf/acl/TaoWXHZY19}, SMN \cite{DBLP:conf/acl/WuWXZL17} and MSN \cite{DBLP:conf/emnlp/YuanZLLZHH19}. 

\paragraph{BERT-based Matching Models.} Given the recent advances of pre-trained language models \cite{DBLP:conf/naacl/DevlinCLT19}, \citet{DBLP:conf/cikm/GuLLLSWZ20} proposed the SA-BERT model which adapts BERT for the task of response selection and it is the current state-of-the-art model on the Douban and Ubuntu dataset. 

\begin{table*}[tb]
    \small
	\centering  \renewcommand{\arraystretch}{1.15}
	\scalebox{0.9}{
	\begin{tabular}{ccccccccccc}
\hlinewd{0.75pt}
		\multirow{2}{*}{CC}&\multirow{2}{*}{IC}&\multicolumn{3}{c}{\textbf{SMN}}&\multicolumn{3}{c}{\textbf{MSN}}&\multicolumn{3}{c}{\textbf{SA-BERT}}\\
\cmidrule(lr){3-5}
		\cmidrule(lr){6-8}
		\cmidrule(lr){9-11}
		&&@ & @&@&@ & @&@&@ & @&@\\
		\hline
&&0.402&0.238&0.410&0.474&0.298&0.462&0.499&0.315&0.493\\
        \hline
\checkmark&&0.422&0.253&0.429&0.482&0.305&0.479&0.504&0.320&0.511\\
        \hline
        &\checkmark&0.441&0.271&0.444&0.499&0.315&0.492&0.511&0.325&0.524\\
\hline
        \checkmark&\checkmark&\textbf{0.446}&\textbf{0.281}&\textbf{0.452}&\textbf{0.507}&\textbf{0.321}&\textbf{0.508}&\textbf{0.514}&\textbf{0.330}&\textbf{0.531}\\
\hlinewd{0.75pt}
	\end{tabular}}
    \caption{Ablation study on Douban dataset using different combinations of the proposed curriculum strategies.}
	\label{tb:ablation_study}
\end{table*}



\begin{table*}[tb]
    \small
	\centering  \renewcommand{\arraystretch}{1.15}
\scalebox{0.85}{
	\begin{tabular}{ccccccccccc}
\hlinewd{0.75pt}
\multicolumn{1}{c}{\multirow{2}{*}{Model}}&\multicolumn{1}{c}{\multirow{2}{*}{Strategy}}& \multicolumn{5}{c}{\textbf{Douban}}&\multicolumn{4}{c}{\textbf{Ubuntu}}\\
\cmidrule(lr){3-7}
	    \cmidrule(lr){8-11}
	    &&  & &@ & @ & @&@&@ & @ & @\\
	    \hline
\multirow{4}{*}{SMN}&Semi&0.554&0.605&0.425&0.253&0.412&0.934&0.762&0.865&0.967\\
	    &CIR&0.561&0.611&0.432&0.267&0.433&0.935&0.760&0.870&0.963\\
		&Gray&0.564&0.615&0.443&0.271&0.439&0.938&0.765&0.873&0.969\\
		&HCL&\textbf{0.575}&\textbf{0.620}&\textbf{0.446}&\textbf{0.281}&\textbf{0.452}&\textbf{0.947}&\textbf{0.777}&\textbf{0.885}&\textbf{0.981}\\
		\hline
	    \multirow{4}{*}{MSN}&Semi&0.591&0.638&0.473&0.301&0.461&0.952&0.804&0.903&0.983\\
	    &CIR&0.595&0.640&0.472&0.304&0.466&0.955&0.808&0.910&0.985\\
		&Gray&0.599&0.645&0.476&0.308&0.468&0.958&0.812&0.911&0.987\\
		&HCL&\textbf{0.620}&\textbf{0.668}&\textbf{0.507}&\textbf{0.321}&\textbf{0.508}&\textbf{0.969}&\textbf{0.826}&\textbf{0.924}&\textbf{0.989}\\
		\hline
	    \multirow{4}{*}{SA-BERT}&Semi&0.623&0.664&0.500&0.317&0.490&0.968&0.858&0.931&0.989\\
	    &CIR&0.624&0.666&0.503&0.318&0.497&0.969&0.860&0.935&0.990\\
		&Gray&0.628&0.670&0.503&0.320&0.503&0.970&0.861&0.934&0.991\\
		&HCL&\textbf{0.639}&\textbf{0.681}&\textbf{0.514}&\textbf{0.330}&\textbf{0.531}&\textbf{0.977}&\textbf{0.867}&\textbf{0.940}&\textbf{0.992}\\
\hlinewd{0.75pt}
	\end{tabular}}
    \caption{Comparisons on Douban and Ubuntu datasets using different training strategies on various models. Results marked with  are from our runs with their released code. }
	\label{tb:learning_comparison}
\end{table*}


\subsection{Implementation Details} 
For all experiments, we set the value of  in the corpus-level pacing function  as , meaning that all models start training with the context-response pairs whose corpus-level difficulty is lower than . For the instance-level pacing function , the value of  is set as , meaning that, after IC is completed, the negative responses of each training instance are sampled from the top- relevant responses. In the experiments, each matching model is trained for  steps with a batch size of 128, and we set the  in both  and  as half of the total training steps, i.e., . To build the context and response encoders in the ranking model , we use a -layer transformers with a hidden size of . We select two representative models (SMN and MSN) along with the state-of-the-art SA-BERT to test the proposed learning framework. To better simulate the true testing environment, the number of negative responses ( in Eq. \eqref{eq:matching_model}) is set to be 5.



\section{Result and Analysis}
\subsection{Main Results}
Table \ref{tb:main_result} shows the results on Douban, Ubuntu, and E-Commerce datasets, where X+HCL means training the model X with the proposed learning HCL. We can see that HCL significantly improves the performance of all three matching models in terms of all evaluation metrics, showing the robustness and universality of our approach. We also observe that, by training with HCL, a model (MSN) without using pre-trained language model can even surpass the state-of-the-art model using pre-trained language model (SA-BERT) on Douban dataset. These results suggest that, while the training strategy is under-explored in previous studies, it could be very decisive for building a competent response selection model.


\subsection{Effect of CC and IC} 
To reveal the individual effects of CC and IC, we train different models on Douban dataset by removing either CC or IC. The experimental results are shown in Table \ref{tb:ablation_study}, from which we see that both CC and IC make positive contributions to the overall performance when used alone. Only utilizing IC leads to larger improvements than only using CC. This observation suggests that the ability of identifying the mismatching information is a more important factor for the model to achieve its optimal performance. However, the optimal performance is achieved when CC and IC are combined, indicating that CC and IC are complementary to each other.

\subsection{Contrast to Existing Learning Strategies}
Next, we compare our approach with other learning strategies proposed recently \cite{li-etal-2019-sampling,DBLP:conf/ecir/PenhaH20,lin2020world}. We use Semi, CIR, and Gray to denote the approaches in \citet{li-etal-2019-sampling}, \citet{DBLP:conf/ecir/PenhaH20}, and \citet{lin2020world} respectively, where Gray is the current state of the art. We conduct experiments on Douban and Ubuntu datasets and the experimental results of three matching models are listed in Table \ref{tb:learning_comparison}. 
From the results, we can see that our approach consistently outperforms other learning strategies in all settings. The performance gains of our approach are even more remarkable given its simplicity; it does not require running additional generation models \cite{lin2020world} or re-scoring negative samples at different epochs \cite{li-etal-2019-sampling}.

\begin{figure}[!t] 
	\centering    
	\setlength{\abovecaptionskip}{3pt}
\includegraphics[width=0.42\textwidth]{images/hyperparameter.png}
	\caption{Plots illustrating the effect of curriculum hyper-parameters, (a)  and (b) , on the SMN model performance in Douban dataset.}
\label{fig:hyperparameter_curve}
\end{figure}
\subsection{Further Analysis on HCL}
In this part, we study how the key hyper-parameters affect the performance of HCL, including the initial difficulty of CC, , and the curriculum length of IC, .\footnote{Our experiments show that other hyper-parameter settings have little impact on the model performance.} In addition, we also investigate the effect of different ranking model choices.
\paragraph{Initial Difficulty of CC.} 
We run sensitivity analysis experiments on Douban dataset with the SMN model by tuning  in the corpus-level pacing function . The results of @ and @ in terms of  and  are shown in Figure \ref{fig:hyperparameter_curve}(a). We observe that when  is small (i.e., ), the model performances are relatively similar. When  approaches to 1.0, the results drop significantly. It concurs with our expectation that, in CC, the model should start learning with training context-response pairs of lower difficulty. Once  becomes 1.0, the CC is disabled, resulting the lowest model performances.

\paragraph{Curriculum Length of IC.} Similair to , we also run sensitivity analysis experiments by tuning  in the instance-level pacing function  and Figure \ref{fig:hyperparameter_curve}(b) shows the results. We observe that a too small or too large  results in performance degradation. When  is too small, after IC is completed, the negative examples are only sampled from a very small subset of the training data that consists of responses with high relevance. In this case, the sampled responses might be false negatives that should be deemed as positive cases. Thus, learning to treat those responses as true negatives could harm the model performance. On the other hand, as  increases, the effect of IC becomes less obvious. When  (), IC is completely disabled, leading to the further decrease of model performances. 

\begin{table}
    \small
	\centering  \renewcommand{\arraystretch}{1.15}
	\scalebox{0.86}{
	\begin{tabular}{c|c|ccc}
\hlinewd{0.75pt}
	    \textbf{Ranking Model}&Model&@ & @ & @\\
	    \hline
\multirow{4}{*}{Transformers}&Ranking Model&0.400&0.253&0.416\\\cline{2-5}&SMN&0.446&\textbf{0.281}&0.452\\
		&MSN&\textbf{0.507}&0.321&\textbf{0.508}\\
		&SA-BERT&\textbf{0.514}&\textbf{0.330}&0.531\\
		\hline
\multirow{4}{*}{BiLSTM}&Ranking Model&0.377&0.227&0.393\\\cline{2-5}
	    &SMN&0.438&0.273&0.441\\
		&MSN&0.491&0.313&0.487\\
		&SA-BERT&0.507&0.323&0.513\\
\hline
	    \multirow{4}{*}{BERT-base}&Ranking Model&0.437&0.275&0.443\\\cline{2-5}
	    &SMN&\textbf{0.451}&0.279&\textbf{0.457}\\
		&MSN&\textbf{0.507}&\textbf{0.323}&0.507\\
		&SA-BERT&0.511&0.329&\textbf{0.53}5\\
\hlinewd{0.75pt}
	\end{tabular}}
    \caption{Comparisons of different ranking model architectures. Best results of each matching model are \textbf{bold-faced}. The ``Ranking Model'' rows represent the performances of different ranking models.}
\label{tb:ranker_choice}
\end{table}

\paragraph{Ranking Model Architecture.}
\label{sec:ranker_choice}
Lastly, we examine the effect of the choice of the ranking model architecture. We build two ranking model variants by replacing the Transformers module  and  in Eq. \eqref{eq:similarity} with other modules. For the first case, we use -layer BiLSTM with a hidden size of 256. For the second one, we use BERT-base \cite{DBLP:conf/naacl/DevlinCLT19} model. Then, we train the matching models using the proposed HCL but with different ranking models as the scoring basis.


The results on Douban dataset are shown in Table \ref{tb:ranker_choice}. We first compare the performance of different ranking models by directly using them to select the best response. The results are shown in the ``Ranking Model" row of Table \ref{tb:ranker_choice}. Among all three variants, BERT performs the best but it is still less accurate than these sophisticated matching models.  
Second, we study the effect of different ranking models on the matching model performance. We see that, for different matching models, Transformers and BERT perform comparably but the results from BiLSTM are much worse. This further leads to a conclusion that, while the choice of ranking model does have impact on the overall results, the improvement of the ranking model  does not necessarily lead to the improvement of matching models once the ranking model achieves certain accuracy. 



\section{Conclusion}
In this work, we propose a novel hierarchical curriculum learning framework for training response selection models for multi-turn conversations. During training, the proposed framework simultaneously employs corpus-level and instance-level curricula to dynamically select suitable training data based on the state of the learning process. Extensive experiments and analysis on two benchmark datasets show that our approach can significantly improve the performance of various strong matching models on all evaluation metrics. Our code, models and other related resources can be found in  \url{https://github.com/yxuansu/HCL}


\section*{Acknowledgments}
The authors wish to thank Jialu Xu and Sihui Wang for their insightful discussions and support. Many thanks to our anonymous reviewers for their suggestions and comments.	


\section*{Ethical Statement}
We honor and support the ACL code of Ethics. Dialogue response selection aims to build a retrieval-based dialogue system which better interacts with users. The selection of the best response does not involve any bias towards to the participants. All datasets used in this work are from previously published works, and in our view, do not have any attached privacy or ethical issues. 


\bibliographystyle{acl_natbib}
\bibliography{anthology,acl2021}

\clearpage
\appendix
\section{Ranking Model Training}
Here we provide more details on how to train the neural ranking model  that serves as the scoring basis in the proposed HCL framework.

\paragraph{Modelling.} Given a dialogue context  and a response , their context-response relevance score is defined as 

Note that, the context  is a long sequence which is acquired by concatenating all utterances in the dialogue context. The  and  are the context and response encoder. The context encoder  takes the token sequence  and returns the context representation  by taking the output state corresponds to the last token . The same operation is applied when computing the response representation . In practice, the choice of  could be any sequence model, e.g., LSTM \cite{DBLP:journals/neco/HochreiterS97}, RNN \cite{DBLP:journals/cogsci/Elman90},  Transformers \cite{DBLP:conf/nips/VaswaniSPUJGKP17}, and BERT \cite{DBLP:conf/naacl/DevlinCLT19}. In this work, we choose Transformers as our modelling basis.

\paragraph{Learning.} The goal of training the ranking model is to create a vector space such that similar pair of dialogue contexts and responses have higher relevance score than the dissimilar ones. 

We train the ranking model with the same response selection data set  using the in-batch negative objective \cite{DBLP:conf/emnlp/KarpukhinOMLWEC20}. For a sampled batch of training data , where  is the batch size, the sampled contexts and responses are separately encoded using Eq. \eqref{eq:similarity} as  and , where  is the output size of encoder modules. Next, the score matrix  is computed as . The in-batch negative objective \cite{DBLP:conf/emnlp/KarpukhinOMLWEC20} is then defined as minimizing the negative log likelihood of positive responses

where .

In this work, we build the context and response encoder with a 3-layer Transformers and its output size is 256. For all considered datasets, we pre-train the ranking model with a batch size  for  steps. For optimization, we use the Adam optimizer \cite{DBLP:journals/corr/KingmaB14} with a learning rate of 2e-5. For more details, we refer the readers to the original paper \cite{DBLP:conf/emnlp/KarpukhinOMLWEC20}. 


\section{Hyper-parameter Setup}
In the following, we provide details on the search space for the hyperparameters. For number of negative responses  in Eq. (1), the search space is \{, \underline{}, , , \}, where the underline indicates the number selected based on the model performance on the validation set. The search space for the  in corpus-level pacing function  is \{, ,  \underline{}, , , , , , , \}. For the  in instance-level pacing function , the search space is \{,  , \underline{}, , , \}, where  is the size of the training set. 

Each matching model is optimized with Adam optimizer \cite{DBLP:journals/corr/KingmaB14} with a learning rate of - and a batch size of 128. The total training step is set as .  in the corpus-level pacing fucntion  and the instance-level pacing function  is set as the half of the total training steps (i.e., ).
\end{document}
