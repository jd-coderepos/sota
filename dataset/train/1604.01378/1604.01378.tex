\documentclass[pageno]{jpaper}


\usepackage{times}

\usepackage{datetime}
\usepackage{url}
\usepackage[dvipdfm]{hyperref}	\hypersetup{citecolor=blue}	\usepackage[normalem]{ulem}
\usepackage{graphicx}
\graphicspath{{./figures/}}
\usepackage{url}
\usepackage{multirow}

\usepackage{subfig}

\usepackage{authblk}

\newcommand{\email}[1]{\small \href{mailto:#1}{\nolinkurl{#1}} } 

\begin{document}


\title{Isolate First, Then Share: a New OS Architecture for Datacenter Computing}

\author[,]{Gang Lu}
\author[,]{Jianfeng Zhan}
\author[]{Chongkang Tan}
\author[]{Xinlong Lin}
\author[,]{Defei Kong}
\author[]{Chen Zheng}
\author[,]{Fei Tang}
\author[,]{Cheng Huang}
\author[]{Lei Wang}
\author[,]{Tianshu Hao}
\affil[]{Beijing Academy of Frontier Science and Technology}
\affil[]{Institue of Computing Technolgy, Chinese Academy of Sciences}
\affil[]{University of Chinese Academy of Sciences}
\affil[ ]{\email{lugang@mail.bafst.com}, \email{zhanjianfeng@ict.ac.cn}, \email{tanchongkang@ict.ac.cn}, \email{linxinlong@mail.bafst.com},  \email{kongdefei@ict.ac.cn}, \email{zhengchen@ict.ac.cn}, 
\email{tangfei@ict.ac.cn}, \email{huangcheng@ict.ac.cn}, \email{wanglei_2011@ict.ac.cn}, \email{haotianshu@ict.ac.cn}}

\date{}

\maketitle

\thispagestyle{empty}

\begin{abstract}






This paper presents the "\emph{isolate first, then share}" OS model in which the machine's processor cores,
memory, and devices are divided up between disparate OS instances, and a new abstraction---subOS---is proposed to encapsulate an OS instance that can be created, destroyed, and resized on-the-fly.  The intuition is that this avoids shared kernel states between applications, which in turn
reduces performance loss caused by contention.  We decompose the OS into the supervisor and several subOSes \emph{running at the same privilege level}:  a subOS directly manages physical resources, while the supervisor can  create, destroy, resize a subOS on-the-fly.
The supervisor and subOSes have few state sharing, but  fast inter-subOS communication mechanisms are provided
   on demand.





We present the first implementation---RainForest, which supports unmodified Linux binaries.
Our comprehensive evaluation shows RainForest outperforms Linux with four different kernels, LXC, and Xen in terms of worst-case  and average performance most of time when running a large number of benchmarks.
The source code is available from \emph{deleted for double-blind review}.



















\end{abstract}

\section{Introduction} \label{section_introduction}



























































The shift  toward datacenter computing (in short, DC), e.g., warehouse-scale computing~\cite{barroso2009datacenter, barroso2013datacenter} and cloud computing~\cite{shue2012performance, sekar2011verifiable, agmon2012resource, mogul2013nic, kooburat2011best, Madhavapeddy:2013:ULO:2451116.2451167} calls for the new OS architecture.

  On one hand, previous joint work between academia and industry~\cite{kanev2015profiling} shows modern DC workloads are with significant diversity
in workload behavior with no single silver-bullet application to optimize for and with no major intra-application hotspots.
  On the other hand,   modern DC workloads have differentiated QoS requirements in terms of  the average  or worst-case performance.
 As a notable emerging class of workloads, user-facing services require very low tail latency~\cite{dean2013tail, kasture2014ubik, janapa2010web}---worst-case performance---instead of average performance on each node.
When a latency-critical workload is mixed with others, if the OS can not improve tail latency, the resource utilization will be low.
Meanwhile, many other workloads face the  scalability challenges in terms of average performance~\cite{unrau1995hierarchical, gough2007kernel, guniguntala2008read, mellor1991algorithms, russinovich2008inside, clements2015scalable, Baumann:2009:multikernel}.


 This observation has two implications for the OS research efforts.
 First, it is no longer  possible to tackle this challenge in  an ad-hoc manner by repeatedly identifying and removing the bottlenecks~\cite{unrau1995hierarchical, gough2007kernel, guniguntala2008read, mellor1991algorithms, russinovich2008inside}. Second, even we can optimize the OS for the main classes of workloads, if they require different kernel changes, there is no guarantee that the changes will compose~\cite{Belay:2012:DSU:2387880.2387913}.



 Traditional OS architectures are mainly proposed for the average performance~\cite{Saltzer:1974:PCI:361011.361067, Graham:1968:PIP:363095.363146, Chase:1994:SPS:195792.195795, Howry:1972:MSP:850614.850619, banga1999resource, barham2003xen}.
The widely used Linux, Linux container (LXC)~\cite{banga1999resource}, or Xen~\cite{barham2003xen}, adopt monolithic kernels or virtual machine monitor (VMM) that share numerous data structures protected by locks (\emph{share first}), and then a process or virtual machine (VM) is proposed to guarantee performance isolation (\emph{then isolate}). In the rest of this paper, we call this kind of OS architectures "\emph{share first, then isolate}" (in short, SFTI).
 In addition to its ad-hoc manner by repeatedly identifying and removing the  (average) performance bottlenecks, the SFTI OS architecture has its inherent structure obstacle in achieving the worst-case performance: contending shared structures in the kernel deteriorates performance outliers. Previous state-of-the-art systems have mainly focused on improving the scalability of the existing model in terms of the average performance (e.g., sv6~\cite{clements2015scalable}, BarrelFish~\cite{Baumann:2009:multikernel}),  or on tackling tail latency reduction challenges (e.g., IX~\cite{belay2014ix}, Arrakis~\cite{peter2014arrakis}).

 \emph{Our goal is to build a new OS architecture that not only gracefully achieves disparate performance goals in terms of both average and worst-case performance, but also protects software investment}.
 While previous work done on exokernels~\cite{peter2014arrakis, Baumann:2009:multikernel, belay2014ix, Belay:2012:DSU:2387880.2387913, boyd2008corey}
offers interesting alternative approaches to either scalability or tail latency reduction challenges, monolithic kernels are  commercially significant~\cite{banga1999resource}, especially for DC workloads.









  \begin{figure}[t]
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{0pt}
  \centering
  \includegraphics[scale=0.50]{horizontal_os_model_no_trusted.eps}
  \caption{The IFTS OS architecture.}
  \label{horizontal_os_model}
\end{figure}













































































































































































\begin{figure*}[t]
\setlength{\abovecaptionskip}{0pt}
\setlength{\belowcaptionskip}{3pt}
    \centering
    \includegraphics[width=0.98\linewidth]{structure_comparison.v2.eps}
    \caption{Structural comparison of RainForest with related systems.}
    \label{fig_related}
\end{figure*}


This paper presents an "isolate first, then share" (in short, IFTS) OS model guided by three design principles: \emph{elastic OS instance}; \emph{run at the
same privilege level}; and\emph{ confined state sharing}.
We divide up the machine's processor cores, memory, and devices among disparate OS instances,
and propose a new OS abstraction---subOS---encapsulating an OS instance that can be created, destroyed, and resized on the fly (\emph{elastic OS instance});
We decompose the OS into the supervisor and subOSes \emph{running at the same privilege level}:  a subOS  directly  manages physical resources and runs applications, while the supervisor enables resource sharing through creating, destroying, resizing a subOS on-the-fly; The supervisor and subOSes have few state sharing, but fast inter-subOS communication mechanisms based on shared memory and IPIs are provided on demand (\emph{confined state sharing}).
As the supervisor and subOSes run in the same privilege level, we take a software approach to enforce security isolation.
We propose Security Guard (in short SG)---an added kernel module in both the supervisor and each subOS kernel space utilizing the mutual protection of Instrumentation-based Privilege Restriction (IPR) and Address Space Randomization (ASR)~\cite{Deng:2017:DWT}.   IPR intercepts the specified privileged
operations in the supervisor or subOS kernels and transfers these operations to
SG, while ASR hides SG in the address
space from the supervisor or subOS kernels, which is demonstrated to be secure with trivial overhead~\cite{Deng:2017:DWT}.










































On several Intel Xeon platforms, we applied the IFTS OS model to build the first working prototype---RainForest on the basis of Linux 2.6.32. Figure~\ref{horizontal_os_model} shows the IFTS OS architecture.
\emph{Our current implementation does not include safety isolation.}
We performed comprehensive evaluation of RainForest against four Linux kernels: 1) 2.6.32; 2) 3.17.4; 3) 4.9.40; 4) 2.6.35M,
a \underline{m}odified version of 2.6.35 integrated with sloppy counters~\cite{Boyd-Wickizer:2010:MOSBench}; LXC (version 0.7.5 ); XEN (version 4.0.0).  Our comprehensive evaluations show RainForest outperforms Linux with four different kernels, LXC, and Xen in terms of worst-case and average performance most of time when running a large number of benchmarks.
























































 \section{Related Work}




\begin{figure*}[t]
\setlength{\abovecaptionskip}{0pt}
\setlength{\belowcaptionskip}{3pt}
    \centering
    \subfloat[]{\label{fig_motivation_mmap}\includegraphics[width=0.267\linewidth]{mmap2_12cores_latency.eps}}
\subfloat[]{\label{fig_motivation_tail_latency_search}\includegraphics[width=0.675\linewidth]{motivation_search_linux_interference_99tail_v2.eps}}
    \caption{\ref{fig_motivation_mmap} shows the cumulative latency distribution of \emph{mmap} from Will-it-scale~\cite{Will-It-Scale} on a 12-core server. (x, y) indicates  processes running on  cores.
\ref{fig_motivation_tail_latency_search} shows the tail latency of Search is slowed down \emph{n} times (in the Y axis) when co-located with each background PARSEC benchmark. The tail latency of \emph{Search} at 300 req/s on a 12-core server with four Linux kernels  is 108.6, 134.5, 127.7 ms, 138.1 ms, respectively.}
    \label{fig_motivation_tail_latency}
\end{figure*}





 RainForest not only gracefully achieves disparate performance goals in terms of \emph{both average and worst-case performance}, but also protects software investments.
The closest system is Solaris/Sparc~\cite{SUN_Dynamic_system_domains}, which runs multiple OS instances. The firmware hypervisor beneath logical domains runs in an additional hyper-privileged mode, and it handles all hyper-privileged requests from logical domains via hypervisor APIs. While in RainForest, the supervisor and several subOSes run at the same privilege level, and a subOS directly manages resources without the intervention from the supervisor. Figure~\ref{fig_related} performs the structural comparison of RainForest with other related systems.



Most of previous systems focus on \emph{the average performance}.
 First, much previous work scales the existing monolithic OSes to accommodate many processors in an ad-hoc manner
~\cite{unrau1995hierarchical, gough2007kernel, guniguntala2008read, mellor1991algorithms, russinovich2008inside}.  Focusing on how to reduce sharing for shared-memory systems, Tornado~\cite{gamsa1999tornado} and K42~\cite{krieger2006k42} introduce clustered objects to optimize data sharing
through the balance of partitioning and replication. Resource containers/LXC~\cite{banga1999resource} separates a protection domain from a resource principal but shares the same structure of a monolithic kernel.

  Second, microkernels~\cite{Ford:1996:MMR:238721.238769, batlivala1992experience, golub1990unix, engler1995exokernel, Elphinstone:2013:LSW:2517349.2522720} move most kernel management into user space services, but globally-shared data structures exist in kernel components. SawMill~\cite{gefflaut2000sawmill}, Mach-US~\cite{julin1995mach}, Pebble~\cite{gabber1999pebble}, and MINIX~\cite{herder2006minix} decompose the OS into a set of user-level servers executing on the globally-shared microkernel, and leverage a set of
services to obtain and manage resources locally.
  A recent system---Tessellation~\cite{Colmenares:2013:TRO:2463209.2488827} factors OS services  and implements them in user space (similar to fos~\cite{wentzlaff2009factored}).  For the multi-server OSes~\cite{gefflaut2000sawmill, julin1995mach, gabber1999pebble, herder2006minix}, the OS is decomposed into several servers or services with complex dependencies, which amplifies the performance outliers in serving a user-facing request. In addition, multi-server OSes have a globally-shared micro-kernel,  while each subOS in RainForest  runs independently most of time.


Third, OS functionalities of an exokernel~\cite{Engler:1995:EOS:224056.224076} are pushed to library OSes linked with individual user-level processes. The globally-shared kernel still controls the access of low-level resources, handles scheduling, interrupts, and exceptions, and delivers network packets.
Corey~\cite{boyd2008corey} resembles an exokernel which defines a shared abstraction that allows applications to dynamically create lookup tables of kernel objects and determine how these tables are shared.  



Fourth, there are a number of other ways to build virtualization systems, which
range from the hardware (e.g., IBM LPARs~\cite{Jann:2003:IBM_LPARs}) up to the full software, including hardware abstraction layer VMs (e.g., Xen~\cite{barham2003xen}), operating system layer VMs (e.g., LXC/Docker~\cite{banga1999resource, merkel2014docker}, VServer~\cite{soltesz2007container}), and hosted VMs (e.g., KVM)~\cite{kivity2007kvm}.
In Xen, even physical resources are directly allocated to a VM, it still needs VMM intervention for privileged operations and  exceptions handling. Differently, in RainForest, the machine's cores,
memory, and devices are divided up among subOSes, and the supervisor and OSes run at the same privilege level. Recursive virtual machines~\cite{Ford:1996:MMR:238721.238769, goldberg1974survey} ~\cite{zhang2011cloudvisor} allow OSes to be decomposed vertically by implementing OS functionalities in stackable VMMs.
Disco and Cellular Disco~\cite{govil1999cellular, bugnion1997disco}
use virtual machines to scale commodity multi-processor OSes.            VirtuOS~\cite{nikolaev2013virtuos} exploits virtualization to isolate
and protect vertical slices of existing OS kernels.
Unikernels~\cite{Madhavapeddy:2013:ULO:2451116.2451167} are single-purpose appliances that are compile-time specialized into standalone kernels and sealed against modification when deployed to a cloud platform.

Finally, a number of systems reconstruct the traditional OS as a distributed system: either base on hardware partitioning~\cite{SUN_Dynamic_system_domains}, or view the OS states as replicated
~\cite{Baumann:2009:multikernel, schupbach2008embracing, beckmann2014pika, barbalacetowards, shimosawa2008logical,kale2011distributing, nomura2011mint}, or span an OS across multiple cache-coherence domains~\cite{lin2014k2} or hardware accelerators~\cite{nightingale2009helios},
or restrict the management functions of the hypervisor~\cite{keller2010nohype, szefer2011eliminating}.
BarrelFish reconstructs the OS as a peer-to-peer distributed system built on exokernels, whose states are strictly synchronized via message passing among all CPU drivers on each core. Popcorn~\cite{Barbalace:2015:popcorn} constructs a single system image on top of multiple Linux kernels (each runs on a different ISA) through a compiler framework, making applications run transparently amongst different ISA processors. Differently, the IFTS OS model lets
applications running on different subOSes to avoid the cost of sharing if they do not intend to do so. In addition, the supervisor is in charge of resource management, while each subOS can be created, destroyed, and resized on the fly.

Focusing on tail latency reduction, the recent two operating systems, Arrakis~\cite{peter2014arrakis, Baumann:2009:multikernel}, and IX ~\cite{belay2014ix, Belay:2012:DSU:2387880.2387913} make applications directly access virtualized and physical I/O devices  through customized service servers and libos, respectively, so as to speed up network-intensive workloads. The subOS abstraction is orthogonal to the existing OS abstraction like DUNE/IX, and we can integrate the DUNE/IX module into subOSes specifically running latency-critical workloads, as the latter is a monolithic Linux kernel. Other tail-latency tolerant systems~\cite{kasture2014ubik, leverich2014reconciling, litales, jalaparti2013speeding, vulimiri2012more, ravindranath2013timecard, zhang2013cpi} tackle this challenges from perspective of architecture or middleware, or scheduling policy.

 Other related  work includes performance isolation solutions~\cite{verghese1998performance, shue2012performance, Gulati:2010:MHT:1924943.1924974, Ghodsi:2011:DRF:1972457.1972490}, using queuing policies or resource allocation algorithms, and resource accountability~\cite{chen2013towards, sekar2011verifiable, agmon2012resource}.









































































 




\section{Motivation} \label{Section_Motivation}

In this section, the hardware and software configurations are consistent with that in Section~\ref{section_evaluation} accordingly.

























\subsection{Tail latency reduction challenge}\label{section_motivation_tail_latency}

Figure ~\ref{fig_motivation_mmap} shows on a recent Linux kernel (4.9.40) the cumulative distribution of latencies of a simple micro-benchmark---\emph{mmap} (\emph{the average is about  few microseconds}) from the Will-it-scale benchmark suite~\cite{Will-It-Scale} on a 12-core server. This benchmark creates multiple processes, each creating a 128M file and then repeatedly mapping and unmapping it into and from the memory. On the same number of cores, we have the following observation: as the process number  increases, tail latency  significantly deteriorates.
It is mainly because of frequent accesses on a global variable \emph{vm\_commited\_as} protected by a spinlock.  vm\_commited\_as is a percpu\_counter and should streamline  concurrent updates by using the local counter in vm\_commited\_as. But once the update is beyond the \emph{percpu\_counter\_batch} limit, it will overflow into the global count, causing false sharing and high synchronization overhead.
Our experiments show similar trends in other Will-It-Scale benchmarks (e.g., pagefault, malloc). 













































































































\subsection{Performance interferences of co-located workloads}\label{section_motivation_isolation}
Figure~\ref{fig_motivation_tail_latency_search} measures the deterioration of the tail latency of \emph{Search}---a search engine workload from the BigDataBench benchmark suite~\cite{Wang:2014:BigDataBench} (\emph{its average latency is about tens or hundreds of milliseconds}) co-located with each PARSEC workload~\cite{PARSEC_Source_code} on a 12-core server running four kernels: 2.6.32, 2.6.35M~\cite{Boyd-Wickizer:2010:MOSBench}, 3.17.4, and 4.9.40.  Although consolidation increases the resource utilization, the tail latency is slowed down tens of times, which is unacceptable for large-scale services. Even we fix  CPU affinities for Search and PARSEC processes and specify the \emph{local allocate} memory allocation policy, the tail latency is maximally slowed down by above forty times. 





















































































































































































\subsection{Root cause discussion}\label{motivation_discussion}

The literatures~\cite{litales, Boyd-Wickizer:2010:MOSBench, gough2007kernel} conclude the microscopic reasons for the performance outliers residing on both software and hardware levels: (1) contention for shared locks, i.e., locks for virtual memory operations, process creation and etc.; (2) competing for software resources, such as caches, lists, and etc.; (3) other in-kernel mechanisms like scheduling and timers; (4) micro-architecture events for consistency, such as TLB shootdown, cache snooping, etc.; and (5) competing limited hardware capacities, such as bandwidth.

We can contribute most of the microscopic reasons (1, 2, 4) to the SFTI architectures that share resources and states from bottom to up.
Since the computers are embracing extraordinary densities of hardware and DC workloads become increasingly  diverse, large scale and sensitive to interferences, we believe it is the right time to reconstruct the OS.
 




\section{The IFTS OS Model}\label{section_os_model}














The IFTS OS model is guided by three design principles.
























\subsection{Elastic OS instance}



In the IFTS OS model, the machine's cores,
memory, and devices are divided up between disparate OS instances.  We propose \emph{subOS} as a new OS abstraction that encapsulates an OS instance.
     Subject to the hardware architecture, each subOS may include at least a CPU core or SMT (Simultaneous Multi-Treading) thread (if supported), a memory region at a fine or coarse granularity, and optionally several peripherals.










This "isolate first" approach lets
applications avoid the cost of sharing if they do not intend to do so.
Instead, in a system with global sharing of kernel structures, processes contend with each other for limited resources, such as dentry cache, inode cache, page cache, and even routing table. Note that we do not preclude subOSes sharing memory between cores (see Section~\ref{subsubsection_state_sharing}).
 On the other hand, hardware units like TLB entries are no longer necessarily shared by subOSes, and TLB shootdown is unnecessary to broadcast to all cores.


















































Physically partitioning node  resources among subOSes makes resource sharing much difficult.  To overcome this limitation, we allow creating, destroying and resizing a subOS on the fly, which we call \emph{elastic OS instance}. This is an important extension to reflect the requirements of DC computing. Their workloads often  change significantly in terms of both load levels and resource demands, so an IFTS OS needs to adjust the subOS number or resize each subOS's resources.
This property not only facilitates flexible resource sharing, but also supports shrinking durations of rental periods and increasingly fine grained resources offered for sale~\cite{agmon2012resource}. 

Most of server workloads are fast changing, e.g., their ratios of peak loads to normal loads are high. So resizing a subOS must be fast or else it will  result in significant QoS violation or throughput loss.
Experiences show the feasibility of hot-adding or hot-plugging a physical device in Linux~\cite{mwaikambo2004linuxCPUhotplug, schopp2006memoryhotplug, kroah2001deivcehotplug} or decoupling cores from the kernel in Barrelfish/DC~\cite{Zellweger:2014:DecouplingCores}.
We can further shorten the long path of initializing or defunctioning the physical resource from the ground up in existing approaches as discussed in Section~\ref{implementation}.





Resource overcommitment increases hardware utilization in VMM as most VMs use only a small portion of the physical memory that is allocated to them. Similarly, an IFTS OS allows resource preemption among subOSes. For example, a subOS preempts cores of others if its load is much heavier. Latency critical workloads with a higher priority definitely  benefit from resource preemption when mixed with offline batches.







































































































































































































































































































































































































































































































































































































































































































































































 SubOS is the main abstraction in our IFTS OS model.
First, the subOS abstraction makes resource accounting much accurate. A subOS owns exclusive resources, independently runs applications, and shares few states with others, which clears up the confusion of attributing resource consumptions to applications because of  scheduling, interrupt serving, peripheral drivers and etc.





Second, the subOS abstraction is proposed as an OS management facility. We can flexibly  provision physical resources through creating, destroying, or resizing a subOS.  From this perspective, the subOS abstraction is orthogonal to the existing OS abstractions proposed for resource management, i.e. the resource container~\cite{banga1999resource}, and the DUNE/IX abstraction~\cite{Belay:2012:DSU:2387880.2387913, belay2014ix}.





















Third, two subOSes can establish internal communication channels, which resembles inter-process communication (IPC) in a monolithic OS. A subOS can map a memory zone of another subOS to enable shared memory like \emph{mmap} in Linux. 




\subsection{Run at the same privilege level}


\begin{table*}[t]
\renewcommand{\arraystretch}{1.1}
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{0pt}
\setlength{\textfloatsep} {0pt plus 2pt}
\setlength{\tabcolsep}{5pt}
\centering
\caption{Shared states compared among different operating systems.}
\label{tab_confined_states}
\newsavebox{\tablebox}
\begin{lrbox}{\tablebox}
\begin{tabular}{|c|p{200pt}|p{120pt}|p{160pt}|}
\hline
\textbf{System} & \textbf{Structures protected by locks} & \textbf{Shared software resources} & \textbf{Micro-architecture level}	\\ \hline
Linux & , , , etc.~\cite{Boyd-Wickizer:2010:MOSBench}
		 & , , , etc.~\cite{Boyd-Wickizer:2010:MOSBench}
		 & Events across all cores: TLB shootdown, LLC snooping, etc. \\ \hline
Linux containers &  Locks in kernel and introduced by cgroups, i.e., page\_cgroup lock~\cite{Ahn:2016:IIR}, request-queue lock~\cite{Huang:2016:ESL}
		& Same as Linux
		& Events across all cores: same as Linux; cache conflict in cgroups subsystems\\ \hline
Xen/VMM & file locks~\cite{Nitu:2017:SBQ}, many spin-locks operations~\cite{Zhong:2012:OXH}, etc.
		& Xenstore, a shared translation array, event channels, etc.~\cite{barham2003xen}
		& Events across all cores: same as Linux. \\ \hline
IX &   Locks in Linux kernel and user space driver
		& None (Static allocation)
		& Events across all cores \\ \hline
Barrelfish/Arakis & All states are globally consistent through one-phase or two-phase commit protocol~\cite{Baumann:2009:multikernel}
		& None
		& Events are limited in a single core \\ \hline
RainForest & Resource Descriptions of a subOS (lock-free)
		& None
		& Events are limited within a subOS \\ \hline
\end{tabular}
\end{lrbox}
\scalebox{0.8}{\usebox{\tablebox}}
\end{table*}

We   decompose the OS into the supervisor and several subOSes \emph{running at the same privilege level}: the supervisor discovers, monitors, and provisions resources,  while each  subOS independently manages resources and runs applications.


The roles of the supervisor and subOSes are explicitly differentiated. The supervisor gains a global view of the machine's physical resources and allocates resources for a subOS. A subOS initializes and drives the resources on its own and creates other high-level OS abstractions for better resource sharing within a subOS, e.g., process, thread, and resource container.
A subOS becomes more efficient not only because of minimum involvement from the supervisor, but also because it  knows   resource management better than the supervisor. In addition,
the transient failure of the supervisor or the other subOSes will not lead to
the failure of the subOS, vice versa.




















































































































































































































































































































































































However,  threats come from the bugs and vulnerabilities within the kernel of the supervisor or subOSes. Since the subOS or supervisor kernel has the highest privilege, attackers who compromise the kernel could manipulate the underlying hardware state  by executing privileged operations.
To avoid such threat, we take a software approach
and propose SG---an added kernel module in both the supervisor and each subOS kernel space---which  utilizes the mutual protection of Instrumentation-based Privilege Restriction (IPR) and Address Space Randomization (ASR)~\cite{Deng:2017:DWT} to enforce security isolation among the supervisor and subOS kernels.
ASR is a lightweight approach to randomize the code and data locations of SG in the supervisor and subOSes kernels  to ensure their locations impossible to guess in the virtual address space, thus preventing the adversary who has knowledge of the memory locations from subverting them.
Through IPR, we can intercept the specified privileged operations in the kernel and transfer them to SG in the same privilege level.








SG in each subOS kernel maps the resource descriptions of each subOS into its own address space as read-only. And only SG in the supervisor kernel has the right to modify it. SG only needs to read the descriptions to check the legality of privileged operations in the kernel. On one hand, it intercepts the operation like  and page table update to refrain the supervisor and subOSes from accessing invalid physical address space.
On the other hand, it intercepts the sensitive interrupt instructions, e.g., HALT and start-up IPI. Besides, intercepting the IOMMU configuration is essential if we need guarantee DMA isolation and interrupt safety.

As the code size of SG is small, we consider it as trusted computing base (TCB) while the other kernel code and user-space applications are untrusted. The integrity of TCB can be ensured using the authenticated boot provided by the platform module (TPM)~\cite{TPM}.






































































































































































\subsection{Confined state sharing}\label{subsubsection_state_sharing}




In the IFTS OS model, the supervisor and subOSes have few state sharing, but  fast inter-subOS communication mechanisms are provided
   on demand.






Physically partitioning node resources inherently reduces the sharing scope  inside a subOS. Within a subOS, software operations like lock/unlock and micro-architectural operations like TLB shootdown and cache synchronization will thus happen within a smaller scope. Meanwhile, the traffic through system interconnects will also decline. However, extremely restricting a subOS onto a single core is probably not the best option. Applications may expect for a different number of cores and thread-to-core mappings~\cite{Tang:2011:IMS}.


Inter-subOS state sharing is kept on a very low level. It is ideal that no state is shared among subOSes.
But the hardware trend towards high density and fast interconnection accelerates intra-node data exchange. And the supervisor has to communicate with subOSes for coordination.
On one hand, we demand the data structures shared by the supervisor and all subOSes are quite limited. As resource management is locally  conducted by subOS kernels, global coordination and monitoring enforced by the supervisor are much reduced. On the other hand, we facilitate  two subOSes to construct mutual communication channels on demand. In this context, the negative effects of frequent updates in the communication are neutralized by  a small sharing degree. It also makes sense in the  scenario that the supervisor transfers messages to a subOS for dynamic resource reconfiguration. The IFTS model encourages  making a tradeoff of resource sharing  within a subOS and among subOSes, which gains the best performance for typical server workloads, e.g., the  Spark workload as shown in Section~\ref{evaluation_spark}.






Table~\ref{tab_confined_states} summarizes RainForest's state sharing reduced against other systems, including Linux, XEN, LXC, BarrelFish/Arrakis, and IX. We investigated the shared states  inside an OS from three aspects: contention for shared locks, competing software resources, and micro-architecture events for consistency. We can see that only RainForest has the least shared states and the micro-architecture events are within a subOS. As for the communication channels between two subOSes, they are established on demand and the shared structures do not have influence on other subOSes.

















































































 








\section{The Implementation}\label{implementation}
We explore the implications of these principles by describing the implementation of the RainForest OS, which is not the only way to apply the IFTS OS model.

















































\begin{table}[t]
\renewcommand{\arraystretch}{1.1}
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{0pt}
\setlength{\textfloatsep} {0pt plus 2pt}
\setlength{\tabcolsep}{5pt}
\centering
\caption{Hardware configurations of two servers.}
\label{table_server_config}
\begin{lrbox}{\tablebox}
\begin{tabular}{|c|c|c|}
\hline
Type & S-A & S-B \\ \hline
CPU & Intel Xeon E5645 & Intel Xeon E7-8870 \\ \hline
Number of cores & 6 cores@2.4GHz & 10 cores@2.4GHz \\ \hline
Number of threads & 12 & 20 \\ \hline
Sockets & 2 & 4 \\ \hline
L3 Cache & 12 MB & 30 MB \\ \hline
DRAM capacity & 32 GB, DDR3 & 1 TB, DDR3\\ \hline
NICs & \multicolumn{2}{c|}{8 Intel 82580 ethernet 1000Mb/s} \\ \hline
HDDs & \multicolumn{2}{c|}{8 Seagate 1TB 7200RPM, 64MB cache} \\ \hline
\end{tabular}
\end{lrbox}
\scalebox{0.8}{\usebox{\tablebox}}
\end{table}


\subsection{Targeted platforms}~\label{section_hardware_platform}
In this paper, we focus on applying the IFTS OS model on a cc-NUMA (cache-coherent non-uniform memory architecture) server with a single PCIe root complex. On such server, we assume there are abundant physical resources divided up among subOSes. Table~\ref{table_server_config} shows the configuration details of two different servers: a mainstream 12-core server (\emph{S-A}) and a near-future mainstream server with 40 cores and 1 TB memory (\emph{S-B}). In the rest of this paper, the performance numbers are reported on these servers.





\subsection{System structure}\label{section_system_structure}



\begin{figure}[t]
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{0pt}
  \centering
  \includegraphics[scale=0.50]{rainforest_structure_v4.eps}
  \caption{The structure of RainForest.}
  \label{architecture}
\end{figure}


Figure~\ref{architecture} depicts the RainForest structure. In our current implementation, the supervisor is the first  OS instance on each machine occupying at least one core or SMT thread and several MB of memory. 

\emph{FICM} (\underline{F}ast \underline{I}nter-subOS \underline{C}ommunication \underline{M}eachnism) provides the basic interfaces for inter-subOS communication. FICM forks low-level message channels among subOSes based on inter-processor interrupt (IPI) and shared memory. A core is selected as the communication core in a subOS. On each subOS, we fork two FICM kernel threads (read/write) with real time priority to transfer \emph{tiny immediate messages} in units of cache lines (typically 64 Bytes) using NAPI  interfaces (New API, which combines interrupts and polling). It supports unicast, multicast, and broadcast operations. Upon FICM, \emph{supcon} in the supervisor and \emph{subOScon} in a subOS implement the primitives command of subOS management, respectively. Primitive commands issued from one end will be conducted and handled by the other. \emph{Resource provisioner} provides management interfaces for a full-fledged user space management tool---\emph{rfm}. Currently, the functions of \emph{Resource provisioner} and \emph{supcon} are implemented into a kernel module named \emph{RFcontroller}.

















\subsection{SubOS management}\label{subos_management}




\begin{figure}[t]
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{0pt}
  \centering
  \includegraphics[scale=0.50]{memory_bootup_v6.eps}
  \caption{Physical memory and virtual memory organizations of a subOS.}
  \label{fig_bootup}
\end{figure}

\textbf{Memory organization}: Figure~\ref{fig_bootup} summarizes the organizations of physical and virtual memory spaces of a subOS. Conventionally, Linux directly maps all physical memory from zero to \emph{PAGE\_OFFSET} so that the conversion between virtual and physical addresses can be easily carried out by macros \emph{\_\_pa} and \emph{\_\_va}. In a subOS, we map the start address of its physical memory to \emph{PAGE\_OFFSET} and rephrase the \emph{\_\_pa} and \emph{\_\_va} macros. Other fix-mapped structures, which are mostly architecture-specific, are revised to create a safe booting environment. To support logical hot-add and hot-plug of memory regions whose physical addresses are ahead of the ones that are initially allocated to a subOS, we map them into a hole after \emph{\_\_START\_KERNEL\_map} in the address space instead of the direct-mapping address space starting from \emph{PAGE\_OFFSET}.






\textbf{Creating a subOS:} Before starting a subOS, RFcontroller prepares the least descriptions of hardware, upon which a subOS can successfully start up. In the normal Linux booting, it is actually conducted by BIOS. The information that RFcontroller fills for a subOS includes the description of SMP (MP Configuration Table), memory regions (E820 Table), and boot parameters. A new \emph{bootparam} parameter is added to instruct the kernel with a white list of passthrough PCIe endpoints. For the X86-64 architecture, we employ a two-phase jump after RFcontroller issues a restart command to the designated BSP (Bootstrap Processor) of a subOS. Once finishing the mode switch in the common trampoline in low memory, the execution will jump to the customized trampoline residing in its exclusive physical memory.



Though in RainForest each subOS independently manages its own physical resources, it still needs help from the supervisor. It is because a few hardware resources must be accessed via atomic operations or strictly protected from simultaneous updates. A typical example is the low memory ( 1M) where resides a small slice of trampoline code that is needed for any X86 processor to finish mode switches.
Similar situations exist in the management of I/O APIC pins and PCI configuration registers. RainForest adopts global spinlocks stored in a globally shared page that is mapped into the address spaces of both the supervisor and subOSes.
Please note that this protection is specific to the x86-64 architecture.



\textbf{Resizing a subOS:}
Linux supports device hot-plug to allow failing hardware to be removed from a live system. However,  the shortest path of functioning or defunctioning a device for elastic resource adjustment in a subOS  is different from failing over hardware failures. We made great effort to shorten the path of logical hot-add and
hot-plug by removing several unnecessary phases. For example, we reduce the overhead of a CPU hot-add operation from ~150 ms to ~70 ms by removing the delay calibration of each CPU. For a memory hot-add operation, we reduce the scope of scanning removable page blocks through a short list recording the page blocks reserved by the kernel.

In RainForest, every resource adjustment operation is recorded by the supervisor, which can be further configured to collect the running information through subOScon from the \emph{proc} subsystem. In particular, hardware performance counters can be accurately employed using the \emph{perf} tools in a subOS to monitor architectural events of its CPUs. Besides, resource borrowing is allowed among subOSes but needs to be registered on the supervisor via a specified command.


\textbf{Destroying a subOS:} A subOS releases all resources before sending a shutdown request to the supervisor. The supervisor then prepares a designated trampoline program, forces it to transfer the CPUs to the supervisor via the trampoline, and finally reclaims other resources.





\subsection{Communication subsystems}\label{communication}
FICM is preferably used for light-weight messages.
To meet with different requirements of continuous and bulk communication, we introduce diverse communicating facilities including RFcom, RFloop, and other virtualization infrastructures.

RFcom exports high-level interfaces to kernel routines and user-space programs to facilitate inter-subOS communication. They are \emph{rf\_open}, \emph{rf\_close}, \emph{rf\_write}, and \emph{rf\_read}, \emph{rf\_map}, and \emph{rf\_unmap}. The former four interfaces operate on a socket-like channel, upon which subOSes easily communicate with packet messages. The other two interfaces help map  and unmap shared memory to individual address spaces, but without explicit synchronization mechanisms.

RFloop creates a fully-transparent inter-subOS network loop channel on the basis of Linux \emph{netfilter}. Network packets going to subOSes in the same machine will be intercepted on the network layer and transferred to the destination subOS. We achieve high bandwidth by adopting a lockless buffer ring and decreasing notification overhead using NAPI interfaces.

When the number of PCI-passthrough devices is insufficient for all subOSes, such as RAID controllers, RainForest adopts the splitting driver model applied in para-virtualization technologies. We base the network virtualization on the universal TUN/TAP device driver~\cite{tun_site} (RFtun), and the filesystem virtualization on FUSE~\cite{fuse_site} (RFfuse).
To gain better performance isolation and access control, we attach all back-end threads into a \emph{control group} created specifically for each subOS. Under the control group, resource consumptions of the back-end drivers can be accounted.

\subsection{State Sharing among the supervisor and subOSes}


Except for the mutually shared states in the private communication channels between two subOSes, the supervisor shares few states with all subOSes.


First, the supervisor manages a few globally-shared states that are publicly available to all subOSes. These states include the communication-core list, which is used for IPIs in FICM, and the MAC list, which is used to sniffer packets in RFLoop. The communication-core list is modified if the CPUs of a subOS change or a different load balancing algorithm is adopted for FICM. The MAC list is modified when a subOS is created or destroyed. As these updates are usually infrequent, state sharing can be implemented via either shared memory or messages.


Second, the supervisor reserves privileged operations on the protected
resources that can not be modified by a subOS. Typical examples include the low memory, the I/O APIC, and the PCIe configuration registers, as discussed in Section~\ref{subos_management}.
























































































































































































































 \subsection{Refactoring Efforts}\label{refactoring}


Most of the Linux software stack is unmodified to support the existing Linux ABI. Table~\ref{refactoring_efforts} summarizes  the new and modified lines of code in RainForest, most of which are performed in the portable functions and independent modules. Out of the key effort in the kernel change, the largest portions are FICM and the functionalities of the supervisor, which can be dynamically activated or deactivated.






\begin{table}[h]
\renewcommand{\arraystretch}{1.1}
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{0pt}
\setlength{\textfloatsep} {0pt plus 2pt}
\setlength{\tabcolsep}{5pt}
\caption{The effort of building RainForest on the basis of a Linux 2.6.32 kernel.}
\centering
\begin{lrbox}{\tablebox}
\begin{tabular}{l|c}
 \hline
 \textbf{Component} & \textbf{Number of Lines}\\ \hline
The supervisor & 994 \\
 The RFcontroller module & 1837 \\
 A subOS & 1969 \\
FICM / RFcom / subOScon &  1438 / 1522 / 1331 \\
 RFloop / RFtun / RFfuse & 752 / 2339 / 980 \\
others (rfm) & 4789\\
 \hline
\end{tabular}
\label{refactoring_efforts}
\end{lrbox}
\scalebox{0.8}{\usebox{\tablebox}}
\end{table}




\section{Evaluation}\label{section_evaluation}
RainForest currently runs well on x86-64 platforms (i.e., Intel Xeon E5620, E5645, E5-2620, E5-2640, and E7-8870). We run the benchmarks on the two servers listed in Table~\ref{table_server_config}. In fact, we have tested two benchmark suites (lmbench~\cite{staelin2002lmbench3} and PARSEC~\cite{bienia2008parsec}) to demonstrate the zero overhead of utilizing the IFTS OS model relative to the virtualization techniques of LXC and Xen. The results are consistent with those reported in ~\cite{soltesz2007container} and we do not represent here. Other comprehensive comparisons are performed on the three Linux kernels, LXC, Xen and IX.











The special technologies including Intel Hyper-Threading, Turbo Boost, and SpeedStep are disabled to ensure better fairness.
We build all the systems (Linux, containers in LXC, Dom0 and DomU in Xen, and subOSes in RainForest) on \emph{SUSE Linux Enterprise Server 11 Service Pack 1}, which is released with the 2.6.32 kernel. Using the original distribution, we compile kernels \emph{3.17.4}, \emph{4.9.40}, and \emph{2.6.35M} so as to compare with  state-of-the-practice. The Linux and Xen versions are 0.7.5 and 4.0.0, respectively. \emph{In this Section, we use \emph{OS instance} to denote a container of LXC, a DomU guest OS on Xen, or a subOS in RainForest.} For RainForest, as the operation overhead of the supervisor is negligible, we also deploy applications on it in our experiments. This ensures the full utilization of the machine resources.
For LXC and Xen, we bind each OS instance's CPUs or virtual CPUs to physical CPUs, which helps decrease the influence of process scheduling. The NUMA memory allocation policy is \emph{local allocation}, which preferably allocates \emph{local} memory in the same node to their CPUs accordingly. For the Linux kernels, we do not pin the benchmarks on specific CPUs or specify the memory allocation policies, making them compete for the system resources without restriction. Since there are abundant ethernet adapters in a single server, we make each OS instance directly access one to get near-native performance. For the storage, we attach each OS instance a directly accessed disk when deploying two OS instances in a 12-core server, one under an LSI SAS1068E SAS controller and the other under an Intel ICH10 AHCI controller.
When running four OS instances on a \emph{S-B}-type server, we adopt the \emph{tmpfs} in-memory file systems to reduce the contention for a single disk.

























































































\begin{figure}[t]
\setlength{\abovecaptionskip}{0pt}
\setlength{\belowcaptionskip}{0pt}
\centering
    \subfloat[malloc]{\label{fig_root_cause_malloc_cdf}\includegraphics[width=0.33\linewidth]{root_cause_malloc_cdf.eps}}
\subfloat[munmap]{\label{fig_root_cause_munmap_cdf}\includegraphics[width=0.33\linewidth]{root_cause_munmap_cdf.eps}}
\subfloat[open]{\label{fig_root_cause_open_cdf}\includegraphics[width=0.33\linewidth]{root_cause_open_cdf.eps}}
    \caption{The cumulative latency distribution of three microbenchmarks. \emph{The number on the system with the maximum tail latency is not reported in each subFigure.}}
    \label{fig_rootcause_microbenchmarks_cdf}
\end{figure}

\subsection{Understanding the root causes}\label{hit_root_cause}

As an application benchmark is about several
orders of magnitude complex than a micro-benchmark, it is difficult to run application benchmarks to understand the OS kernel behaviours. In stead, we run the Will-It-Scale benchmark suite to inspect the advantage of the IFTS architecture and uncover the root causes mentioned in Section~\ref{motivation_discussion}. We deploy six OS instances on an S-A type server. Each OS instance runs a process and the number of threads increases with the cores. 

 We deliberately  only present the performance numbers of three benchmarks:  , , and . Among them, the  operations contend for the free list locks~\cite{Michael:2004:SLD}; the  operations cause TLB shootdown to other CPUs~\cite{DiDi2011}; the  operations competes for both  and  cache~\cite{Tsai:2015:GMV}. Note that RainForest does not intend to eliminate the causes (3) and (5)  in Section~\ref{motivation_discussion}, as well as other systems.


Figure~\ref{fig_rootcause_microbenchmarks_cdf} shows the cumulative latency distribution of each benchmark. The dotted vertical lines indicate the average latencies. Except for , RainForest exhibits the best performance in terms of both the  maximum latencies and standard deviations.
Excluding Linux-3.17.4 and Linux-4.9.40, we also notice that RainForest exhibits lower tail latencies and average latencies in all the benchmarks.
For , Linux-4.9.40 has the lowest average latency, but it has higher  maximum latency and standard deviation with respect to RainForest. For  both Linux-3.17.4 and Linux-4.9.40 shows better tail, average, and maximum latencies with respect to RainForest.
Please note that RainForest is based on Linux 2.6.32, and the performance improvement of Linux kernel evolution is definitely helpful to RainForest.












\subsection{Performance isolation}
In this section, we use both micro benchmarks and application benchmarks to measure (average or worst-case) performance isolation of different systems on an \emph{S-A} type server with two OS instances.

\subsubsection{Mixed microbenchmarks}

The micro benchmarks we used include SPEC CPU 2006~\cite{henning:2006:speccpu} (CPU intensive), cachebench~\cite{Mucci:1998:cachebench} (memory intensive), netperf~\cite{jones:1996:netperf} (network intensive), IOzone~\cite{iozone_site}(filesystem I/O intensive). 11 benchmarks from four benchmark suites are selected to exert heavy pressures to different subsystems. We investigate the mutual interference of any two benchmarks which are deployed in two OS instances in a single server. The two OS instances, each with 3 cores and 8 GB memory, run in the same NUMA node rather in two NUMA nodes, producing more performance interference. As the processes contend heavily on accessing (especially writing) files on a disk in the IOzone case, we make them read/write files in the tmpfs file system to stress the filesystem caches and memory instead of physical disks. For cachebench, we set the footprint to be 32 MB, which is greater than the LLC and makes more pressure on the memory system. When running two netperf benchmarks on Linux, each of them uses a NIC with an IP in different networks.

Figure~\ref{fig_isolation_microbenchmarks} reports the \emph{average} performance degradation of each foreground benchmark affected by the background one with respect to solo running the foreground one. RainForest exhibits good performance isolation except for running cachebench.write and cachebench.modify benchmarks as backgrounds. LXC and Xen have heavier performance interference in the same two scenarios, and the performance is degraded much in the other scenarios. Besides, different Linux kernels show similar behaviors (only report Linux-3.17.4), indicating the performance isolation is poor in an SFTI OS architecture as it shares many data structures  protected by locks.




\begin{figure*}[t]
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{0pt}
\centering
\subfloat[Linux-3.17.4]{\label{fig_isolation.2285.micro.Linux.3.17.4}\includegraphics[width=0.24\linewidth]{isolation_2285_micro_Linux_3_17_4.eps}}
\subfloat[LXC]{\label{fig_isolation.2285.micro.LXC}\includegraphics[width=0.24\linewidth]{isolation_2285_micro_LXC.eps}}
\subfloat[Xen]{\label{fig_isolation.2285.micro.Xen}\includegraphics[width=0.24\linewidth]{isolation_2285_micro_Xen.eps}}
\subfloat[RainForest]{\label{fig_isolation.2285.micro.RF}\includegraphics[width=0.24\linewidth]{isolation_2285_micro_RF.eps}}
    \caption{Performance degradation of co-running two benchmarks on a single server. Numbers 010 on the both \emph{x-} and \emph{y-} axes denotes \emph{SPECCPU.\{bzip2, sphix3\}}, \emph{cachebench.\{read, write, modify\}}, \emph{IOzone.\{write, read, modify\}}, \emph{netperf.\{tcp\_stream, tcp\_rr, tcp\_crr\}}, respectively. The numbers in the grid are the average performance slow down percentages (\%) when a foreground benchmark on y-axis interfered by a background one on x-axis relative to solo-running a foreground one.}
    \label{fig_isolation_microbenchmarks}
\end{figure*}

\subsubsection{Improving worst-case performance}
In this section, we test and verify RainForest's ability of improving the worst-case performance and resource utilization. The latency-critical workload we choose is \emph{Search} from BigDataBench~\cite{Wang:2014:BigDataBench}. The front-end Tomcat server distributes each request from the clients to all back-end servers, merges the records received from the back ends, and finally responds to the clients. Tomcat is not the bottleneck according to our massive tests. In the experiments, we choose the real workload trace and set the distribution to be uniform---sending  requests at a uniform rate.

When running a single Search workload, we found the tail latency dramatically climbs up to seconds when the request rate reaches 400 req/s, while the CPU utilization rate cannot surpass 50\%. So we set up two Search backends on two OS instances on the same server, each with 6 cores and 16 GB memory. Figure~\ref{tail_latency_gurantee_search_99latency} illustrates the tail latencies with increasing load levels. For three Linux kernels, we only show Linux-2.6.35M as it exhibits better worst-case performance. When the load level increases to 400 requests/s, the tail latencies on LXC and Xen deteriorate significantly. The tail latencies are beyond 200 ms except for RainForest. Linux  still keeps tail latency below 200 ms owing to free scheduling across all 12 cores, but the tail latency gets much worse after 450 requests/s, indicating  aggressive resource sharing will  produce more interference. If we demand the endurable limit of the tail latency is 200ms, the maximum throughput of Linux 2.6.35M, LXC, Xen, and RainForest is around  400, 350, 350, 500 request/s, respectively. On these load levels, the CPU utilization is 59.8\%, 58.0\%, 55.7\%, and 69.7\%, respectively. Although the CPU utilization of Linux can finally reach to 90\% at 600 req/s, the tail latency becomes totally unacceptable.









\begin{figure}[t]
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{0pt}
  \centering
  \includegraphics[scale=0.45]{tail_gurantee_2285_search_99latency.eps}
  \caption{Tail latency  of Search running on two OS instances on a single server.}
  \label{tail_latency_gurantee_search_99latency}
\end{figure}


\subsubsection{Services mixed with offline workloads}\label{mixed_search_parsec_static}
\textrm{\\} Co-running online services and offline batches is always a thorny problem.
We investigate RainForest's performance isolation in terms of co-running Search with batch workloads. In this test, each OS instance runs on 6 cores and 16 GB memory within a NUMA node. We run Search and a PARSEC workload on each OS instance, respectively. The baseline is solo running Search on one OS instance of each system. The requests are replayed in a uniform distribution at 300 requests/s, beyond which the Search tail latency on  Xen will deteriorate dramatically.

Figure~\ref{fig_tail_latency_parsec} illustrates the performance degradation of the Search tail latency with respect to the baseline. As shown in  Figure~\ref{tail_latency_gurantee_search_99latency}, Xen has the poorest tail latency performance (210.9 ms) when running Search at 300 req/s. Actually, even at 250 req/s, its tail latency is high as 150.6 ms, worse than LXC and RainForest, and the average slowdown reaches up to 25.6\%. As the virtualization overhead exists, Xen is not suited for a high load level when the tail latency matters, and its performance is worse than LXC.

RainForest exhibits good performance isolation almost in all the cases, while the other systems get larger tail latencies in many cases. The slowdown of tail latency in RainForest is always less than 8\%, while that of LXC is high as 46\%. If we only care about the average performance of offline batches~\cite{barham2003xen}, Xen gains better performance than Linux. But unfortunately, in this case, the tail latency of Search deteriorates worse, which is totally unacceptable.








\begin{figure}[t]
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{0pt}
  \centering
\includegraphics[scale=0.45]{search_parsec_interference_99tail_v2.eps}  \caption{Tail latency slowdown of Search when co-locating with Parsec benchmarks relative to solo running. The Search tail latency when solo running at 300 req/s  on LXC, Xen, and RainForest is 129.3, 210.9, and 128.5 ms, respectively. The performance numbers of Linux kernels are shown in Figure~\ref{fig_motivation_tail_latency_search}.}
  \label{fig_tail_latency_parsec}
\end{figure}


\begin{table}[t]
\renewcommand{\arraystretch}{1.1}
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{0pt}
\setlength{\textfloatsep} {0pt plus 2pt}
\setlength{\tabcolsep}{5pt}
\centering
\label{table_elastic_partition}
\caption{Overhead of adjusting three systems (in seconds).}
\label{table_elastic_partition}
\begin{lrbox}{\tablebox}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
Configuration & \multicolumn{2}{c|}{6 CPUs, 16G RAM} & \multicolumn{2}{c|}{1 CPU} & \multicolumn{2}{c|}{512M RAM} \\ \hline
Operations & create & destroy & online & offline & online & offline \\ \hline
LXC & 2.1 & ~0 & 0.002 & 0.002 & 0.002 & 0.002 \\ \hline
Xen & 14.2 & 5.9 & 0.126 & 0.127 & 0.167 & 0.166 \\ \hline
RainForest & 6.1 & ~0 & 0.066 & 0.054 & 0.020 & 0.060 \\ \hline
\end{tabular}
\end{lrbox}
\scalebox{0.8}{\usebox{\tablebox}}
\end{table}



\subsection{Flexibility of resource sharing}
In this section, we evaluate the overhead and agility of adjusting resources when consolidating Search with varying other workloads.


\subsubsection{Evaluating elasticity overhead}
\textrm{\\} We evaluate the overhead of creating, destroying, and resizing the OS instance  by  performing these operations 100 times on an \emph{S-A} type server. For two OS instance configurations, Table~\ref{table_elastic_partition} lists the overheads on LXC, Xen, and RainForest.

From the experimental results, we can find that the elasticity of these systems can be overall described as LXC  RainForest  Xen. For LXC, allocating and deallocating  resources are not really conducted on physical resources but performed by updating the filter parameters of the cgroup subsystem. Although an adjustment operation is always quickly responded, it may take a long time to take effect. For Xen, the adjusting phase is also longer. Besides getting emulated resources ready before loading a domU kernel, VMM needs to prepare several software facilities, including setting up shadow page tables, shared pages, communication channels, etc.






















\begin{figure}[t]
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{0pt}
  \centering
\includegraphics[scale=0.43]{consolidation_search_parsec_99th_tail_latency_160.eps}
  \caption{Search tail latency varies with time. The threshold  is (160, 200). For Linux, only Linux 2.6.35M is shown as it gains better performance than Linux 2.6.32 and Linux 3.17.4.}
  \label{fig_tail_latency_consolidation_parsec}
\end{figure}


\begin{figure}[t]
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{0pt}
  \centering
\includegraphics[scale=0.43]{consolidation_search_parsec_cpu_number_of_nutch_160.eps}
  \caption{The varying number of the CPU owned by the OS instance running Search v.s. time. The tail latency threshold   is set to be (160, 200).
}
  \label{fig_cpu_number_of_nutch_consolidation_parsec}
\end{figure}







\begin{table}[t]
\renewcommand{\arraystretch}{1.1}
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{0pt}
\setlength{\textfloatsep} {0pt plus 2pt}
\setlength{\tabcolsep}{5pt}
\centering
\caption{Performance of consolidating Search and PARSEC benchmarks. We identify requests invalid if the response time  1 second and exclude them from the throughput.}
\label{table_consolidation_results}
\begin{lrbox}{\tablebox}
\begin{tabular}{|c|c|c|c|c|}
\hline
& PARSEC batch & \multicolumn{2}{c|}{Search} \\ \hline
Platform &  running time & 99\%th tail & throughput \\ \hline
Units & seconds & ms & req/s \\ \hline
Linux-2.6.32 & 1058.7 & 379.3 & 217.1\\ \hline
Linux-2.6.35M & 1136.5 & 371.4 & 217.9  \\ \hline
Linux-3.17.4 & 1054.4 & 410.8  & 219.1 \\ \hline
LXC & 1716.8 & 284.1 & 214.0 \\ \hline
Xen & 4731.0 & 305.4 & 209.4\\ \hline
RainForest& 1520.0 & 230.2 & 214.4\\ \hline
\end{tabular}
\end{lrbox}
\scalebox{0.8}{\usebox{\tablebox}}
\end{table}

\subsubsection{Agile changes to dynamic workloads}\label{agility}
\textrm{\\} Here we evaluate the agility of the three systems to fast-changing workloads.
We initially configure the server with two OS instances as in Section~\ref{mixed_search_parsec_static}. But the request rate is fluctuated according to the original distribution. We \emph{package 13 PARSEC benchmarks into a batch job} and run it repeatedly in one OS instance while Search runs in the other OS instance. Meanwhile, a simple scheduler is adopted to adjust the resources of the two OS instances to reduce the tail latency of Search. In this test, \emph{we only adjust the CPUs of two OS instances} rather than finding the optimal strategy of adjusting all resources, which is an open issue. We set two thresholds  to bound the tail latency. That is if the tail latency of the last 10 seconds is above the upper threshold---, a CPU will be transferred from the PARSEC OS instance to the other, and vice versa.


We record the CPU adjustment events and tail latency variations throughout the replay of 482400 requests in 37.5 minutes. From Figure ~\ref{fig_tail_latency_consolidation_parsec}, we observe that both Linux and LXC have large fluctuations, showing unstable worst-case performance. Xen has smaller fluctuations but the tail latency even exceeds 500 ms. Relatively, RainForest exhibits the most stable worst-case performance, mostly between 200 ms and 300 ms. Meanwhile, after replaying all the requests, the number of PARSEC benchmarks finished on Linux-2.6.32, Linux-2.6.35M, Linux-3.17.4, LXC, Xen, and RainForest is  22, 26, 25, 19, 6, and 20,  respectively. Xen finished less PARSEC benchmarks because the tail latency cannot be reduced to below 200 ms even 11 cores are occupied. RainForest outperforms the other systems in terms of both the worst-case performance of Search and the average  performance of the batch jobs in terms of running time.
Figure~\ref{fig_cpu_number_of_nutch_consolidation_parsec}  records the varying number of the processors owned by the OS
instance when running Search. In Linux, Search and PARSEC workloads compete for resources adversely and we do not report the number in Figure~\ref{fig_cpu_number_of_nutch_consolidation_parsec}.



Table~\ref{table_consolidation_results} reports the running time of the PARSEC batch jobs and the corresponding performance of Search on each system. The Search throughput on each system  does not differ significantly, while the 99\% tail latencies are quite different. In RainForest, the tail latency is the lowest (230.2 ms) and the batch job runs faster (1520.0 seconds) than LXC and Xen. Interestingly, we also observe Linux 3.17.4 gains the best average performance in terms of the running time of the PARSEC benchmarks and the Search throughput, however, its tail latency is the worst (high as 410.8). It again confirms that the SFTI OS architecture is optimized toward the average performance. We do not test Linux 4.9.40 because of time limitation in the rest of experiments.





















\subsection{Scalability}
We initiate  four OS instances for LXC, Xen, and RainForest on a \emph{S-B} type server. Each OS instance has 10 cores and 250GB RAM, among which 50GB is used for the tmpfs file system.



















\begin{figure}[t]
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{0pt}
  \centering
    \subfloat[99th percentile latency]{\label{scalability.5885.memcached.multi-process}\includegraphics[width=0.48\linewidth]{5885_memcached_process_99latency_all.eps}}
\subfloat[Throughput]{\label{scalability.5885.memcached.multi-thread}\includegraphics[width=0.48\linewidth]{5885_memcached_process_throughput_all.eps}}
    \caption{Scalability in terms of tail latency running memcached on different systems.} \label{fig_scalability.5885.memcached}
\end{figure}

\subsubsection{Scalability in terms of worst-case performance}
\textrm{\\} We use an in-memory key-value store (memcached) to evaluate the scalability in terms of the tail latency. The memcached benchmark we use is a variant of that in MOSBench~\cite{Boyd-Wickizer:2010:MOSBench}. Similar to the method in Section~\ref{Section_Motivation}, we run multiple memcached servers in Linux, each on its own port and being bound to a dedicated core. For the other systems, the requests are sent averagely into four OS instances. We profile the lookup time of all requests and present the tail latencies with increasing cores in Figure~\ref{fig_scalability.5885.memcached}. Although the scalability problem still exists, the tail latency on RainForest increases slowly than the others. When the core number is 40, the tail latency improvements of RainForest in comparison with Linux 2.6.32, Linux 2.6.35M, Linux 3.17.4, LXC, and Xen are 7.8x, 4.2x, 2.0x, 1.3x, and 1.4x, respectively. Among the three Linux kernels, Linux 2.6.35M gets the highest throughput. RainForest gains the highest throughput among the six systems.





\begin{figure}[t]
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{0pt}
  \centering
  \includegraphics[scale=0.43]{5885_spark_all_v1.eps}
  \caption{Spark workloads performance.} \label{fig_spark_all_workloads}
\end{figure}











\subsubsection{The average performance}\label{evaluation_spark}
\textrm{\\} On Linux, we use the "standalone" deploy mode with the  4 worker instances on LXC, Xen, and RainForest (each OS instance runs a worker instance). The Spark~\cite{zaharia2012resilient} workloads include OLAP SQL queries (Select, Aggregation, and Join) from~\cite{Wang:2014:BigDataBench, pavlo2009comparison} and offline analytic algorithms (Kmeans and PageRank).


Figure~\ref{fig_spark_all_workloads} shows their performance on the systems, including RainForest with RFloop enabled. Although the bandwidth limit of the memory controllers and peripherals may be bottlenecks, we also get much improvement from RainForest. The maximum speedup is 1.43x, 1.16x, and 1.78x  compared to Linux, LXC, and Xen, respectively. With RFloop enabled, the maximum speedup is  1.71x, 1.69x, and 2.60x, respectively. For Join and Aggregation, the time consumed in data shuffling among Spark workers takes a high proportion out of the whole execution. RFloop facilitates them with fast communication channels. Using netperf, the TCP stream performance of RFloop is 0.63x of the local loop, 1.47x of a virtual NIC of Xen, and 15.95x of a physical NIC. For the UDP stream test, the speedup is 0.44x, 13.02x, and 4.34x, respectively.

As many workloads still benefit from shared memory, the number of OS instances where the application is distributed influences the performance. We tested Select, Aggregation, and Join on 2, 4, 6, and 8 subOSes using the same server. We find that the optimal subOS number is four for Select and Aggregation, while for Join eight subOSes gets the best performance (the improvement can achieve 170\%).
 \section{Experience and Limitations}













RainForest is a concrete implementation of our model. However, it is only a point in the implementation space.

First, implementing a subOS as a Linux-like OS instance is not required by the model. However, it is commercially significant~\cite{banga1999resource} for DC workloads.  


Second, we have compared RainForest with Barrelfish using the  microbenchmark (we failed to run application benchmarks). Barrelfish shows good scalability consistent with ~\cite{ Baumann:2009:multikernel}. But with increasing memory size to be unmapped, the average and tail latencies deteriorate significantly. The reason might reside in the two-phase commit protocol, used to ensure global consistence. In this case, the message passing system needs to queue large amount of messages caused by splitted unmap operations, indicating the potential bottleneck for the message passing approach.









Third, as the supervisor and  subOSes run at the same privileged level, our architecture can be easily extended to multiple coherence domains that have no hardware cache coherence. However, its flexibility of resource sharing will be limited and we can only elastically partition resources within a domain, or else we have to leverage the DSM technology among several domains in ~\cite{lin2014k2}.









Finally, the number of subOSes is strictly limited by the cores or SMT threads, but we can  integrate containers or guest OSes in a subOS. Two-level scheduling is  an interesting open issue.
When the peripheral devices are not enough or sharing them may not significantly slow down the application performance on other subOSes, we can leverage the virtualization technology like the split-driver model~\cite{chisnall2008definitive, liu2006high}.

















































\section{Conclusions}

In this paper, we propose an IFTS OS model, and explore the space of applying the IFTS OS model to a concrete OS implementation:  RainForest, which is  fully compatible with Linux ABI. Our comprehensive evaluations  demonstrate RainForest outperforms Linux with four kernels, LXC, and Xen in terms of worst-case and average performance most of time when running a large number of benchmarks. 























 
\bibliographystyle{plain}
\bibliography{RainForest}

\end{document}
