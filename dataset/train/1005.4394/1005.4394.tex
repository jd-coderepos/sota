\documentclass[final, 11pt]{article}

\usepackage{ltexpprt} \usepackage{amssymb} \usepackage{amsmath} \usepackage{appendix}

\renewcommand{\baselinestretch}{1.0}

\begin{document}

\title{Scheduling Packets with Values and Deadlines in Size-bounded Buffers\thanks{Research is partially supported by NSF grant CCF-0915681.}}

\author{Fei Li\thanks{Department of Computer Science, George Mason University, Fairfax, VA 22030, USA. {\tt lifei@cs.gmu.edu}}}

\maketitle


\begin{abstract}
Motivated by providing quality-of-service differentiated services in the Internet, we consider buffer management algorithms for network switches. We study a {\em multi-buffer model}. A network switch consists of multiple size-bounded buffers such that at any time, the number of packets residing in each individual buffer cannot exceed its capacity. Packets arrive at the network switch over time; they have values, deadlines, and designated buffers. In each time step, at most one pending packet is allowed to be sent and this packet can be from any buffer. The objective is to maximize the total value of the packets sent by their respective deadlines. A -competitive online algorithm has been provided for this model (Azar and Levy. SWAT 2006), but no offline algorithms have been known yet. In this paper, We study the offline setting of the multi-buffer model. Our contributions include a few optimal offline algorithms for some variants of the model. Each variant has its unique and interesting algorithmic feature. These offline algorithms help us understand the model better in designing online algorithms.
\end{abstract}

\newpage


\section{Introduction}

Motivated by providing quality-of-service differentiated services in the Internet, we consider buffer management algorithms for network switches. We study a {\em multi-buffer model}. A network switch consists of  size-bounded buffers , , , ; their sizes are denoted as  respectively. At any time, the number of packets residing in each individual buffer  cannot exceed its capacity . Time is discretized into time steps. Packets arrive at the network switch over time and each packet  has an integer arriving time (release time) , a non-negative value , an integer deadline , and a designated buffer  that it can reside in. The deadline  specifies the time by which  should be sent. This model is preemptive such that the packets already existing in the buffers can be dropped at any time before they are transmitted. A dropped packet cannot be delivered any more. In each time step, at most one pending packet is allowed to be sent and this packet may be from any buffer. The objective is to maximize {\em weighted throughput}, defined as the total value of the packets transmitted by their respective deadlines.

The first QoS buffer management model is introduced in~\cite{AMRR05}. Since then, quite a few researchers have studied this model as well as other variants, mostly in the online settings~\cite{KLMPSS04, H01, CJST07, LSS05, EW07}. A well-studied model is called the {\em bounded-delay model}. In this model, there is only one buffer. Packets have integer release time, integer deadlines, and non-negative values. The objective is to maximize the total value of the packets sent by their deadlines. An implicit assumption on this model is the buffer's sufficiently large size. All released packets can be stored in the buffer before they are delivered or they get to expire. For the bounded-delay model, an optimal offline algorithm running in  time has been proposed in~\cite{KLMPSS04}, where  is the number of packets released. We call the bounded-delay model a {\em bounded-buffer model} in case the buffer size is enforced to be finite. The bounded-buffer model generalizes the bounded-delay model, if we allow the buffer size to be larger than any packet's {\em slack time}. (A packet's slack time is defined as the difference between its deadline and release time.) The bounded-buffer model is one variant of the {\em multi-buffer model} proposed by Azar and Levy~\cite{AL06}. A -competitive online algorithm has been provided for this model~\cite{AL06}, but no offline algorithms have been known yet. In this paper, we study the offline setting of the multi-buffer model. Our contributions include a few optimal offline algorithms for some variants of the model. Each variant has its unique and interesting algorithmic feature. These offline algorithms help us understand the model better when we are designing online algorithms.

The variants and their algorithms' running complexities are summarized in Table~\ref{tbl:summary}. In the {\em uniform-value} setting, all packets have the same value. In the {\em non-uniform-value} setting, packets are allowed to have arbitrary values. (In designing offline algorithms, there is no difference between preemptive and non-preemptive settings.)

\begin{table}[h]
\begin{tabular}{|c|c|c|}
\hline \hline
& uniform-value setting & non-uniform-value setting \\ \hline
 &  &  \\ \hline
 (packets sharing a common deadline) &  &  \\ \hline \hline
\end{tabular}
\label{tbl:summary}
\caption{Summary of the running complexities of the optimal offline algorithms for some variants of the multi-buffer model.  is the number of packets in the input sequence. For the bounded-buffer model, the buffer size is .}
\end{table}


\section{The Bounded-buffer Model, }

Let OPT denote an optimal offline algorithm. Without loss of generality, we assume OPT is {\em non-idling}, that is, OPT sends a packet as long as the buffer is non-empty.


\subsection{The uniform-value setting.}

In the uniform-value setting, all packets have the same `weight' and the objective is to maximize the number of packets delivered successfully. An optimal offline algorithm called DOS (which stands for `Deadline-Order-Sorting/Sending') works simply as follows.

\begin{algorithm}
All packets in the buffer are organized by their deadlines using an augmented red-black tree~\cite{CLRS01}. Upon each new arrival, we insert it into the packet queue in increasing order of deadlines. Let the current time be . If the buffer is full or if more than  packets are to be sent by some deadline  (we call these cases `{\em tight}'), we drop the packet with the earliest deadline. In each time step, the earliest-deadline packet in the buffer is sent.
\end{algorithm}

\begin{Lemma}
For the bounded-buffer model in the uniform-value setting, there exists an optimal offline algorithm running in  time, where  is the number of packets released and  is the buffer size.
\label{lemma:singleoff1}
\end{Lemma}

\begin{proof}
We first prove DOS's correctness using a loop invariant. The loop invariant is: At any time, there exists a one-to-one mapping (injection) from each packet  in OPT's buffer to a packet  in DOS's buffer such that . Without loss of generality, we align the mappings such that an earlier-deadline packet in OPT's buffer maps to an earlier-deadline packet in DOS's buffer. For example, assume  and  in OPT's buffer map to  and  in DOS's buffer respectively. If  but , we swap the mappings and let  map to  and  map to . Note  and .

This invariant holds before any packet is released. Let us assume it holds at time . Consider a new arrival  accepted by OPT.  is either accepted by DOS or there exists a packet  which is not mapped yet by any packet in OPT's buffer has a deadline . (In this case, we can map  in OPT's buffer to  in DOS's buffer.) Otherwise, we can drop  and accept  or OPT's buffer is `tight' as well and OPT rejects . In each time step, both OPT and DOS send one packet as long as their buffers are non-empty. Without loss of generality, we can assume OPT sends the earliest-deadline packet in its buffer. Thus, the loop invariant still holds after each step's deliveries. The loop invariant implies the correctness of the algorithm.

For each new arrival, it takes  to insert  into or drop  out of the packet queue in DOS's buffer. The algorithm has an upper bound of running time . The proof is completed. 
\end{proof}

The following instance shows that no algorithm has a running complexity asymptotically better than .

\begin{Example}
Assume . All packets are released at the same time . To identify whether all packets can be delivered successfully, we have to sort them by deadlines such that packets can be delivered in an earliest-deadline-first (EDF) manner. The lower bound of sorting  numbers takes ~\cite{CLRS01}.
\end{Example}

\begin{corollary}
Consider the bounded-buffer model in the uniform-value setting. If packets' deadlines are weakly increasing along with their release time, EDF is an optimal algorithms running in linear time. Specifically, EDF runs in an online manner.
\end{corollary}


\subsection{The non-uniform-value setting.}

If , the optimal offline algorithm~\cite{KLMPSS04} for the bounded-delay model applies on the bounded-buffer model and has a running time of . We assume . Fix an input sequence . We have the following algorithm.

\begin{algorithm}
We sort all packets in  in non-increasing value order, with ties broken in favor of the one with a later deadline. We start from a set of packets . For each packet , we pick up  in order and run EDF to examine whether all packets in  can be delivered successfully by their respective deadlines. (Actually, we can start from the time  to run EDF over the packets  instead of from scratch; though this does not help to reduce the asymptotic running complexity.) If ``yes'', we update  with . For each examined packet , no matter whether we insert  into  or not, we drop it out of . We examine all packets in  in order till  gets empty.
\label{alg:singlenon}
\end{algorithm}

\begin{Lemma}
For the bounded-buffer model in the non-uniform-value setting, there exists an optimal offline algorithm running in  time, where  is the number of packets released.
\label{lemma:singleoff2}
\end{Lemma}

\begin{proof}
We claim that the schedule of  we finally have from Algorithm~\ref{alg:singlenon} is optimal, based on the matroid property of this model. Consider a set of packets that can be delivered successfully by their deadlines in an EDF manner. Then, its any subset can be delivered successfully as well and the heredity property is satisfied. Also, in each time step, only one packet is allowed to send, and thus, the exchange property holds.

Let . Sorting packets in  takes  time. The buffer has at most  packets at any time, thus, each packet insertion (in increasing deadline order) takes  time. Running EDF over a set of packets  takes time . For each packet , examining  of being successfully sent takes time . Thus, the total running time of the algorithm is . Thus, our algorithm has a running time of . The proof is completed. 
\end{proof}


\section{Scheduling Packets with a Common Deadline or Without Deadlines, }

Let OPT denote an optimal offline algorithm. Without loss of generality, we assume OPT is non-idling. In scheduling packets without deadlines, we assume all packets have a common deadline , where  is the largest release time. We also note that when there are no new arrivals, all packets already in the buffers can be sequentially delivered.

Let  denote the set of packets released at time  targeting the buffer . Since each buffer  cannot accommodate more than  packets at any time, we assume that for each , at any release time , . Let  and  denote the packet queue in the buffer  and its size, respectively.  Let  denote the largest release time of a packet targeting the buffer . Let  be the common deadline.


\subsection{The uniform-value setting.}

In the uniform-value setting, all packets have the same `weight' and the objective is to maximize the number of packets delivered successfully. Instead of directly targeting maximizing the total number of packets delivered, we tackle this variant from the perspective of minimizing the number of packets dropped. For each buffer, our idea is to calculate the number of buffer slots that we have to reserve in order to accept future arrivals (that is, minimizing the number of packets dropped due to `packet overflow'). This value indicates us the latest time that we have to deliver a packet from a buffer.

\begin{algorithm}
For each buffer , consider  in decreasing order of release time . Define a variable  to denote the number of buffer slots that are needed from the buffer  to accommodate packets released at/after time . Set . In reverse order of release time, we calculate , where  is the immediate next release time (of packets) after time  for .

For each new arrival, if its designated buffer is full, drop the packet. Otherwise, append the packet to the queue. In each time step , send any packet from the buffer  if , where  is the immediate next release time of packets for the buffer . Ties are broken arbitrarily. If all buffers  have , choose any packet to send. We switch to another buffer to send a packet only if this buffer is empty or if another buffer  satisfies  at time .
\label{alg:multiuniform}
\end{algorithm}

\begin{theorem}
In scheduling packets with the same value and same deadline, there exists an optimal offline algorithm running in  time, where  is the number of packets released.
\label{theorem:uniformoff}
\end{theorem}

\begin{proof}
We first show the correctness of Algorithm~\ref{alg:multiuniform} using the exchange argument. We call our algorithm TS (standing for `Tight Schedule'). Remember that all packets are with the same value and same deadline and TS accepts packets in a greedy manner for each buffer, thus, as long as OPT and TS schedule packets from the same buffer in each time step, they achieve the same throughput. Let  denote the set of packets sent by OPT. Let  be the first time step in which OPT and TS deliver packets from different buffers. OPT sends a packet  from a buffer  and TS sends a packet  from a buffer . If , it is fine for OPT sends  in this time step such that  is updated with . Here, we assume . Since we choose  to send a packet, one of the following cases must happen. At time , we use  and  to differentiate the two (possibly) distinct next release time of packets targeting buffers  and  respectively.

\begin{enumerate}
\item Assume  and . In this case, delivering either  or  will not result packet overflow for both buffers  and . Thus, OPT can be changed to choose  to send a packet.

\item Assume  and . In this case, if TS does not choose  to send a packet, one packet released at time  or future will not be delivered successfully. Let this packet be . Then, among all packets in 's current buffer and those packets released later targeting , one of them must not be in . Otherwise, OPT will choose  to send a packet to avoid 's packet overflow. Assume the packet sending sequence since time  for OPT is . We modify the sequence for OPT as  and update  as . Since  is delivered in this time step, there exists an extra buffer slot (compared with that of the unmodified OPT which does not send  for step ) to accommodate  in the buffer  and thus, the new packet sequence is feasible. After our modification, OPT's total gain is not reduced and OPT chooses the same queue as TS does to send a packet in this time step.

\item Assume  and . In this case, delivering either  or  will result packet overflow for the other buffer. Thus, with the same analysis as the above case, OPT can be changed to choose  to send a packet.
\end{enumerate}

We then show the running time of Algorithm~\ref{alg:multiuniform}. Sorting all distinct release time for each buffer takes  time. Calculating the variables  takes linear time . For each time , we identify the buffer to send a packet and this takes time . In total, the running complexity of our algorithm is . The proof is completed. 
\end{proof}

The proof of Theorem~\ref{theorem:uniformoff} immediately implies the following corollary.

\begin{corollary}
In scheduling packets with the same value and same deadline, Algorithm~\ref{alg:multiuniform} provides a way to identify whether a set of packets can be delivered successfully.
\end{corollary}


\subsection{The non-uniform-value setting.}

We realize that when each buffer size is large enough, the multi-buffer model is same as the bounded-delay model since all arriving packets can be accommodated in the buffers. Hence, we have two trivial results on the non-uniform-value setting.

\begin{lemma}
For the multi-buffer model, if all buffers have their sizes larger than the maximum slack of a packet targeting at them, the multi-buffer model is same as the bounded-delay model. An optimal offline algorithm running in time  exists, where  is the number of packets released.
\end{lemma}

\begin{corollary}
For the multi-buffer model, if there is no future arrivals, there exists an optimal offline algorithm sending the packets in the buffers, running in  time, where  is the number of packets in the current buffers.
\label{coro:multi}
\end{corollary}

In scheduling weighted packets sharing a common deadline, our idea is to combine Algorithm~\ref{alg:singlenon} and Algorithm~\ref{alg:multiuniform}. We note that this variant is a matroid as well (this can be verified easily as in the proof of Lemma~\ref{lemma:singleoff2}). Then a greedy algorithm  scheduling packets with more values is optimal. Let  be a set of packets we decide to send. Initially,  is empty. We order packets in decreasing order of values. Then, we examine packets one by one, as long as the new one and those already selected packets can be delivered by the common deadline, we add this new packet into . Otherwise, we drop this newly considered packet. There is a questions unsolved: How do we identify whether a set of selected packets can be delivered as they belong to multiple buffers at different time? We apply the idea of Algorithm~\ref{alg:multiuniform}, specifically, the result of Corollary~\ref{coro:multi}.

\begin{algorithm}
Fix an input instance . We sort all packets in  in non-increasing value order. We start from a set of packets . For each packet , we pick up  in order and examine whether all packets in  can be delivered successfully. (See below.) If `yes', we update  with . For each examined packet , no matter whether we insert  into  or not, we drop it out of . We examine all packets in  in order till  gets empty.

Let  denote a subset of selected packets () which are released at time  targeting the buffer . For each buffer , consider  in decreasing order of release time . In reverse order of release time, we calculate , where  is the immediate next release time (of packets) after time  for .

For each new arrival, if its designated buffer is full, drop the packet and return `no'. Otherwise, append the packet to the queue. In each time step , send any packet from the buffer  if , where  is the immediate next release time of packets for the buffer . Ties are broken arbitrarily. If all buffers  have , choose any packet to send. We switch to another buffer to send a packet only if this buffer is empty or if another buffer  satisfies  at time .
\label{alg:multinon}
\end{algorithm}

\begin{theorem}
In scheduling packets with the same deadline, there exists an optimal offline algorithm running in  time, where  is the number of packets released.
\label{theorem:nonuniformoff}
\end{theorem}

\begin{proof}
The correctness of Algorithm~\ref{alg:multinon} depends on the matroid property of this variant and Corollary~\ref{coro:multi}.

We then show the running time of Algorithm~\ref{alg:multinon}. Sorting all distinct release time for each buffer takes  time. Calculating the variables  takes linear time . For each time , we identify the buffer to send a packet and this takes time . In total, the running complexity of our algorithm in examining one packet is . Thus, the total running time of Algorithm~\ref{alg:multinon} is . The proof is completed. 
\end{proof}


\section{Conclusion}

In this paper, we design offline algorithms for some variants of the multi-buffer model. We show that if the number of buffers is restricted to  or if all packets share a common deadline, some efficient offline algorithms can be developed. However, for the general case of the multi-buffer model, the constraints from the buffer sizes, packets' deadlines and packets' values complicate this packet scheduling problem. An optimal offline algorithm for the general multi-buffer model is being under developed.


\bibliographystyle{plain}
\bibliography{../../buffer}


\end{document}
