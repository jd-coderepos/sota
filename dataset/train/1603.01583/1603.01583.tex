\newcommand{\ifArxivVersion}{\iftrue}
\newcommand{\ifLocalVersion}{\iffalse}

\ifArxivVersion  
    \newcommand{\algseparator}{\;}
\else
	\newcommand{\algseparator}{}
\fi


\documentclass{article}[11pt,a4paper]
\pdfoutput=1
 
\usepackage{microtype}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[symbol*]{footmisc}
\usepackage{authblk}
\usepackage{cite}
\usepackage{fullpage}
\usepackage{hyperref}

\newtheorem{definition}{Definition}[section]
\newtheorem{lemma}[definition]{Lemma}
\newtheorem{theorem}[definition]{Theorem}
\newtheorem{proposition}[definition]{Proposition}
\newtheorem{example}[definition]{Example}
\newtheorem{observation}[definition]{Observation}
\newtheorem{corollary}[definition]{Corollary}
\newtheorem{algo}[definition]{Algorithm}

\newcommand{\bigo}{\mathcal{O}}
\newcommand{\oh}{\bigo}
\newcommand{\countballs}{\mathsf{count}}
\newcommand{\ballcolor}{\mathsf{color}}
\newcommand{\balance}{\mathsf{balance}}
\newcommand{\spill}{\mathsf{spill}}
\newcommand{\predict}{\mathsf{predict}}
\newcommand{\cmp}{\mathsf{cmp}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\cnt}{\mathsf{cnt}}

\newcommand{\cupdot}{\mathbin{\mathaccent\cdot\cup}}

\usepackage[noend, noline, ruled, linesnumbered]{algorithm2e}
\SetAlFnt{\normalsize}
\DontPrintSemicolon
\SetKwComment{Comment}{\ }{}
\renewcommand\Affilfont{\normalsize}

\hypersetup{
    colorlinks=true,
    linkcolor=black,
    citecolor=black,
    filecolor=black,
    urlcolor=black,
    pdfauthor={Pawe\l{} Gawrychowski, Jukka Suomela, Przemys\l{}aw Uzna\'nski},
    pdftitle={Randomized algorithms for finding a majority element}
}

\title{Randomized algorithms for finding a majority element}

\author[1]{Pawe\l{} Gawrychowski}
\author[2]{Jukka Suomela}
\author[3]{Przemys\l{}aw~Uzna\'nski}
\affil[1]{Institute of Informatics, University of Warsaw, Poland}
\affil[2]{Helsinki Institute for Information Technology HIIT, \mbox{Department of Computer Science, Aalto University, Finland}}
\affil[3]{Department of Computer Science, ETH Z\"urich, Switzerland}

\date{}    

\begin{document}

\maketitle

\begin{abstract}
Given  colored balls, we want to detect if more than  of them
have the same color, and if so find one ball with such majority color. We are only allowed
to choose two balls and compare their colors, and the goal is to minimize
the total number of such operations. A well-known exercise is to show how to find such
a ball with only  comparisons while using only a logarithmic number of bits for
bookkeeping. The resulting algorithm is called the Boyer--Moore
majority vote algorithm. It is known that any deterministic method needs
 comparisons in the worst case, and this is tight.
However, it is not clear what is the required
number of comparisons if we allow randomization. We construct a randomized
algorithm which always correctly finds a ball of the majority color (or detects that there is
none) using, with high probability, only  comparisons.
We also prove that the expected number of comparisons used by any such randomized
method is at least .
\end{abstract}

\section{Introduction}

A classic exercise in undergraduate algorithms courses is to construct a linear-time
constant-space algorithm for finding the majority in a sequence of  numbers
, that is, a number  such that more than 
numbers  are equal to , or detect that there is no such . The solution
is to sweep the sequence from left to right while maintaining a candidate and a counter.
Whenever the next number is the same as the candidate, we increase the counter;
otherwise we decrease the counter and, if it drops down to zero, set the candidate to
be the next number. It is not difficult to see that if the majority exists, then it is
equal to the candidate after the whole sweep, therefore we only need to count how
many times the candidate occurs in the sequence. This simple yet beautiful solution
was first discovered by Boyer and Moore in 1980; see~\cite{MJRTY} for the history of the problem.

The only operation on the input numbers used by the Boyer--Moore algorithm is testing
two numbers for equality, and furthermore at most  such checks are ever being made.
This suggests that the natural way to think about the algorithm is that the input consists
of  colored balls and the only possible operation is comparing the colors of any two
balls. Now the obvious question is how many such comparisons are necessary and
sufficient in the worst possible case. Fischer and Salzberg~\cite{FischerSalzberg} proved that the answer is
. Their algorithm is a clever modification of
the original Boyer--Moore algorithm that reuses the results of some previously made
comparisons during the verification phase. They also show that no better solution
exists by an adversary-based argument. However, this argument assumes that the
strategy is deterministic, so the next step is to allow randomization.

Surprisingly, not much seems to be known about randomized algorithms for computing
the majority in the general case. For the special case of only two colors, 
Christofides~\cite{Christofides} gives a randomized algorithm that uses 
comparisons in expectation and returns the correct answer with probability ,
and he also proves that this is essentially tight; this improves on
a previous lower bound of  by De Marco and Pelc~\cite{MarcoPelc}.
Note that in the two-color case any deterministic algorithm needs precisely  comparisons, where 
is the number of 1s in the binary expansion of , and this is 
tight~\cite{SaksWerman,AlonsoLowerbound,Wiener}. For a random input, with each
ball declared to be red or blue uniformly at random, roughly  comparisons
are sufficient and necessary in expectation to find the majority color~\cite{AlonsoAverage}.
To the best of our knowledge upper and lower bounds on the expected number
of comparisons with unbounded number of colors have not been studied
before.

Related work include \emph{oblivious} algorithms studied by Chung et al.~\cite{oblivious},
that is, algorithms in which subsequent comparisons do not depend on the previous answers,
and finding majority with larger queries~\cite{MarcoK15,Eppstein,VizerGKPPW15}.
Another generalization is finding a ball of plurality color, that is, the color that occurs
more often than any other~\cite{AignerMM05,GerbnerKPP13,KralST08}.

We consider minimizing the number of comparisons mostly as an academic exercise,
and believe that a problem with such a simple formulation deserves to be thoroughly
studied. However, it is possible that a single comparison is so expensive that their number
is the bottleneck. Such a line of thought motivated a large body of work
studying the related questions of the smallest number of comparisons required to find
the median element; see~\cite{DorZ99,DorZ01,paterson1996progress} and the references
therein. Of course, the simplest Boyer--Moore algorithm has the advantage of
using only two sequential
scans over the input and a logarithmic number of bits, while our algorithm
needs more space
and random access to the input.

Given that the original motivation of Boyer and Moore was fault-tolerant computing,
we find it natural to consider Las Vegas algorithms,
that is, the number of comparisons depends on the random choices of the algorithm
but the answer is always correct. This way the result is correct even if the source of random
bits is compromised; an adversary controlling the random number generator can only
influence the running time.

\paragraph{Model.} We identify balls with numbers . We write  for
the result of comparing the colors of balls  and  (true for equality, false for inequality). We consider randomized
algorithm that, after performing a number of such comparisons, either finds a ball
of the majority color or detects that there is no such color. A majority color is a color 
with the property that more than  balls are of such color. The algorithm
should always be correct, irrespectively of the random choices made during the execution.
However, the colors of the balls are assumed to be fixed in advance, and therefore
the number of comparisons is a random variable. We are interested in minimizing
its expectation.

\paragraph{Contributions.} We construct a randomized algorithm, which always correctly
determines a ball of the majority color or detects that there is none, using 
comparisons with high probability (in particular, in expectation). We also show that
the expected number of comparisons used by any such algorithm must be at least
.

\section{Preliminaries}

We denote the set of balls (items) by . We write  for the color of
ball , and  returns true if the colors of balls  and  are identical.

An event occurs \emph{with very high probability} (w.v.h.p.)\ if it happens with probability at least
. Observe that the intersection of polynomially many very high
probability events also happens with very high probability. 

\begin{lemma}[symmetric Chernoff bound]
The number of successes for  independent coin flips is w.v.h.p.\ at most  .
\end{lemma}


\begin{lemma}[sampling]
\label{lem:sampling}
Let  such that . Let  denote the number of hits on
elements from  if we sample uniformly at random  elements from 
without replacement. Then w.v.h.p.\ .
\end{lemma}


\begin{proof}
Let .
From the tail bound for hypergeometric distribution (see Chv\'atal~\cite{chvatal}), we have


Worth noting is that the error bound here would be essentially the same if we replace ``without replacement'' with ``with replacement''. In that case, we would be invoking a tail bound for binomial distribution.
\end{proof}

Now we consider a process of pairing the items without replacement (choosing a random
perfect matching on ; if  is odd then one item remains unpaired). For any ,
let  be a random variable counting the pairs with both elements belonging to  when
choosing uniformly at random  pairs of elements from  without replacement.
Of course .

\begin{lemma}[concentration for pairs]
\label{lem:pairs}
For any  w.v.h.p.

\end{lemma}

\begin{proof}
For simplicity, we can assume that  is even.
Set .
Instead of choosing a random perfect matching on , we consider an equivalent two-step random process:
\begin{enumerate} 
\item We choose uniformly at random a partition of  into  such that . This partition induces a partition of  into , such that  and .

Observe that, by Lemma~\ref{lem:sampling},  w.v.h.p.

\item Now, instead of pairing uniformly at random the elements from  with the elements from , for our purposes it is enough to choose uniformly at random a set  of elements that are paired with , and count how many elements of  we have chosen. Thus .

By Lemma~\ref{lem:sampling} we have

so the following holds (since ) w.v.h.p.:

Hence

\end{enumerate}
\end{proof}

\begin{lemma}[pairs in partition]
\label{lem:pairs2}
Let  be a partition of .  Then w.v.h.p.

\end{lemma}

\begin{proof}
Let  be a partition  obtained from  by merging all sets  such that  into larger sets of size between  and  (this can be done in a greedy fashion). Let  be the family of original large sets,  the family of original small sets, and  the family of new larger sets.

Since  is a finer partition than , we have that

Since all sets in  are smaller than , we obtain

Then, because all sets in  are large, by a a direct application of Lemma~\ref{lem:pairs}, w.v.h.p.

Similarly, because all sets in  are large, by an application of Lemma~\ref{lem:pairs}, w.v.h.p.

Now our goal is to bound

which, because , is at most

The first and the third addend can be bounded by  because if  then , hence by plugging in the previously derived bounds we obtain

\end{proof}

\begin{lemma}
\label{lem:drawing_until}
Let  such that . Let  denote the number of draws without replacement until we hit  elements from . Then w.v.h.p.

\end{lemma}

\begin{proof}
Denoting by  the number hits on  when drawing without replacement  items, then
by Lemma~\ref{lem:sampling} w.v.h.p.

for some constant . Substituting  we obtain

meaning that indeed w.v.h.p.\ after  draws we will have at least  elements from .
\end{proof}

\section{Algorithm}

In this section we describe a randomized algorithm for finding majority. Recall
that the algorithm is required to always either correctly determine a ball of the majority
color or decide that there is no such color, and the majority color is a color of more
than  balls. For simplicity we will assume for the time being that
 is even, as the algorithm can be adjusted for odd  in a straightforward manner without any change to the asymptotic cost.
Hence to prove that there is a majority color, it is sufficient to find  balls
with the same color. In such case our algorithm will actually calculate the multiplicity
of the majority color. To prove that there is no majority color, it is sufficient to partition
the input into  pairs of balls with different colors.

\pagebreak

The algorithm consists of three parts. Intuitively, by choosing a small random sample
we can approximate the color frequencies and choose the right strategy:
\begin{enumerate}
\item[(i)] There is one color with a large
frequency. We use algorithm . In essence, we have only one candidate for the majority, and
we compute the frequency of the candidate in a naive manner. If the frequency is too small, we need to form sufficiently many pairs of balls with different colors among the balls that are not of the candidate color. This can be done by virtually pairing the non-candidate color elements, and testing these pairs until we find enough of them that have distinct colors. Additionally, we show that one sweep through the pairs is enough.
\item[(ii)] There are two colors with frequencies close to . Now we use algorithm . In essence, we can now reduce the size of the input by a pairing process, and then find the majority recursively.
If the recursion finds the majority, the necessary verification step is speeded up by reusing the results of the comparisons used to form the pairs.
\item[(iii)] All frequencies are small. We use  which, as , applies pairing and recursion. However, if the recursive call reports the majority, we construct enough pairs with different colors: whenever we find a pair of elements with both colors different than the majority color found by the recursive call, we pair them with elements of the majority color. Here we speeded up the process by reusing the results of the comparisons used to form the pairs as well.
\end{enumerate}

We start with presenting the main procedure of the algorithm; see Algorithm~\ref{algo:majority}.
The parameters are chosen by setting ,  and . In fact we could chose any , where  and  is a root to .

\begin{algorithm}
\caption{\label{algo:majority}}
\lIf{}{\KwRet{} is the majority with multiplicity 1 in 
}
sample  such that \;
let  be the representatives of the colors in \;
let  be the frequency of  in , where \label{line:sampling}\;
\If{}{
  \KwRet{}
}\ElseIf{ and }{
  \KwRet{}
}\Else{
  \KwRet{}
}
\end{algorithm}

Before we proceed to describe the subprocedures, we elaborate on the sampling performed
in line~\ref{line:sampling}. Intuitively, we would like to compute the frequencies of all colors
in . This would be too expensive, so we select a small sample  and claim that the
frequencies of all colors in  are not too far from the frequencies of all colors in .
Formally, let  be the frequencies of all colors in , that is
there are  balls of color  in  and let  be the
frequency of color  in the sample . By Lemma~\ref{lem:sampling}, w.v.h.p.\ 
. We argue that 
is a good estimation of .


\begin{lemma}
\label{lem:sum_of_squares}
Let  be the frequency of color  in  and  be its frequency in , where
 a random sample without replacement of size . Then w.v.h.p.

\end{lemma}

\begin{proof}
Let . We analyze the following two sampling methods. 

\begin{enumerate}
\item Partition the elements of  into  disjoint pairs uniformly at random.
Select  of these pairs uniformly at random. Denote by  and 
the pairs with both elements of the same colors in the first and the second pairing, respectively.
By Lemma~\ref{lem:pairs2}, w.v.h.p.\ .
Observe that by Lemma~\ref{lem:sampling} w.v.h.p.\ . Thus, by the triangle inequality, w.v.h.p.


\item Partition the elements of  into  disjoint pairs uniformly at random, and denote
by  all pairs with both elements of the same color. By Lemma~\ref{lem:pairs2}, w.v.h.p.\ 
, or equivalently
.
\end{enumerate}

Now, because  and  have identical distributions, by the triangle inequality we have

\end{proof}

Now we present the subprocedures; see Algorithms \ref{algo:balanced}--\ref{algo:light}.

\begin{algorithm}[p]
\caption{\label{algo:balanced}}
randomly shuffle \;
\;
\For{ \KwSty{to} }{
   \eIf{}{append  to }{append  and  to }
}
run \;
\lIf{\text{there is no majority in }}{\KwRet{}\,no majority in }\algseparator
let  be the majority with multiplicity  in \;
\;
\For{ \KwSty{to} }{\label{line:counting1}
  \If{}{
    
  }\ElseIf{}{
    
  }
}
\eIf{}{\KwRet{no majority in }}{\KwRet{ is the majority with multiplicity  in }}
\end{algorithm}

\begin{algorithm}
\caption{\label{algo:heavy}}
,  \;
\For{ \KwSty{to} }{
  \If{}{
    
  }\Else{
    append  to 
  }
}
\lIf{}{\KwRet{ is the majority with multiplicity  in } \label{line:majority_return}
}\algseparator
\;
randomly shuffle \;
\For{ \KwSty{to} }{ \label{line:heavy_loop}
  \lIf{}{}
  \lIf{}{\KwRet{no majority in }
  }
}
\KwRet{\textsc{Boyer--Moore}(M)} \Comment*[r]{fallback,  comparisons}
\end{algorithm}
\begin{algorithm}
\caption{\label{algo:light}}
randomly shuffle \;
\;
\For{ \KwSty{to} }{ \label{line:light_partition}
  \If{}{
    append  to 
  }\Else{
    append  and  to 
  }
}
run \;
\lIf{\text{there is no majority in }}{\KwRet{no majority in }}\algseparator
let  be the majority with multiplicity  in \;
\;
\For{ \KwSty{to} }{ \label{line:light_loop}
  \If{}{ \If{}{  } }
  \lIf{}{\KwRet{no majority in } }
}
\KwRet{ is the majority with multiplicity  in }
\end{algorithm}

\begin{lemma}
Algorithm \ref{algo:majority} always returns the correct answer.
\end{lemma}

\begin{proof}
We analyze separately every subprocedure.

.
If the majority exists then removing two elements with different colors preserves it.
Hence if the recursive call returns that there is no majority in  then indeed there
is no majority in , and otherwise  is the only possible candidate
for the majority in . The remaining part of the subprocedure simply verifies it.

.
The subprocedure first checks if  is the majority. Hence it is enough to
analyze what happens if  is not the majority. Then  contains all elements
with other colors. We partition the elements in  into pairs and check which of these pairs
consists of elements with different colors. If the number of elements in all the remaining
pairs is smaller than the number of elements of color , then clearly we
can partition all elements in  into disjoint pairs of elements with different colors, hence
indeed there is no majority. Otherwise, we revert to the simple  algorithm,
which is always correct.

.
Again, if the majority exists then removing two elements with different color preserves it.
Hence we can assume that  is the only possible candidate for the
majority. Then,  consists of pairs of two elements with different
colors. From the recursive call we also know what is the frequency of 
in . We iterate through the elements of  and check if their color
is . However, if the color of the first element in a pair is ,
then the second element has a different color. So the subprocedure either correctly
determines the frequency of the majority , or find sufficiently many elements
with different colors to conclude that  is not the majority.
\end{proof}


\begin{theorem}
\label{lem:upperbound}
Algorithm \ref{algo:majority} w.v.h.p.\ uses at most  comparisons on
an input of size~. The expected number of comparisons is also at most .
\end{theorem}

\begin{proof}
Let  be a random variable counting the comparisons on the given input of size .
We will inductively prove that  for a fixed constant  that is sufficiently large.
In the analysis we will repeatedly invoke Lemmas~\ref{lem:sampling}, \ref{lem:pairs}, \ref{lem:pairs2}, \ref{lem:drawing_until}, \ref{lem:sum_of_squares} and Chernoff bound to bound different quantities.
We will assume that each such the application succeeds.
Since there will be a polynomial number of applications, each on a polynomial number of elements,
this happens w.v.h.p.\ with respect to the size of the input.
We also assume that  is large enough.
Algorithm~\ref{algo:majority} uses at most  comparisons
in the sampling stage. We bound the number of subsequent comparisons used by each
subprocedure as follows.

\subparagraph*{{\normalfont }.}
We have that . Thus also . By Lemma~\ref{lem:pairs2}, , thus . Also .

List  consists of pairs of elements with different colors. Because at most  of
all elements are not of color 1 or 2, there are at most  pairs not
of the form . Since the relative order of elements  and  is random,
for each pair  we pay 1 with probability  and pay 2 with probability , and for
any other pair we pay always . Thus the total cost incurred by the loop in line~\ref{line:counting1} is
(by Chernoff bound) at most

Thus the total cost is

and  for a large enough~.

\subparagraph*{{\normalfont }.}
If , then we terminate in line \ref{line:majority_return} after  comparisons.
Thus we can assume that .
Because by Lemmas~\ref{lem:sampling} and~\ref{lem:sum_of_squares} both
 and  are estimated within an absolute error of ,
we have that .

We argue that the loop in line~\ref{line:heavy_loop} will eventually find sufficiently many
pairs of elements with different colors, and thus return without falling back to the  algorithm.
By definition,  and initially . By Lemma~\ref{lem:pairs2},
after the random shuffle the number  of pairs of elements  with different colors
can be bounded by

thus indeed there are sufficiently many pairs. Hence, because the pairs are being considered in
a random order, the total cost can be bounded using Lemma~\ref{lem:drawing_until} by

where we used 
for a large enough~.

\subparagraph*{{\normalfont }.}
We start with bounding  and . By Lemma~\ref{lem:pairs2},
, and by Lemma~\ref{lem:pairs} there
are  elements from  in , thus there are
 of elements from  in  (each paired with
a non- element).

We know that either  or .
If there is no majority in , then  and the total cost is bounded by

which, because , is less than .
Hence we can assume that there is a majority in . In such case,  is set to

We denote by  the total number of iterations of the loop in line~\ref{line:light_loop}.
By Lemma~\ref{lem:drawing_until}

where .
Substituting , by Lemma~\ref{lem:pairs2} we have

Since  and  (as for a larger  the sampled
 would be sufficiently large for other subprocedure to be used),
we have  Thus  . Now, since  we can bound  from above by

which, because  is sufficiently large, can be bounded by


For each of  iterations we pay , and for each of the remaining  iterations we pay
only  in expectation (for each iteration independently). Thus, by Chernoff bound
the total cost is
6pt]
& \le \frac12n + \frac{7}{12}n(p_1^2+S) + \frac{3}{4}(1-p_1^2-S)\frac{p_1^2-S}{(1-p_1)^2-S}n  +  \frac14(p_1^2-S)n + \bigo(n^{26/30}\log n)  + C \cdot |X|^{9/10} = \6pt]
&= \frac{n}{2}\biggl(1+\frac{19}6p_1^2-\frac56S+3 (p_1^2-S)\frac{p_1-p_1^2}{(1-p_1)^2-S} \biggr)+ \bigo( n^{9/10}).
1+\frac{19}{6}p_1^2-\frac{5}{6}S + 3 (p_1^2-S) \frac{p_1(1-p_1)}{(1-p_1)^2-S}T(n) \le \frac{n}{2}\left(1+\frac73p_1^2 \right) + \bigo(n^{9/10}), T(n) \le \frac{n}{2}\left(1+\frac73p_1^2 + \frac32p_1-\frac32p_1^2\right) + \bigo( n^{9/10}), T(n) \le \frac{n}{2}\biggl(1+\frac{19}{6}p_1^2 + 3 \frac{p_1^3}{1-p_1}\biggr) + \bigo(n^{9/10}) = 1.06915 n + \bigo(n^{9/10}).\frac{n}6 + \sum_{k=1}^{n-1} \E\bigl[\min\bigl(0,\tfrac{1}{2}(1-\predict_k) - \frac16\bigr)\bigr] \ge  \sum_{k=1}^{2/3n} \E\bigl[\min\bigl(\tfrac{1}{6},\tfrac{1}{2}(1-\predict_k)\bigr) \bigr].  \qedhere  \Pr(A_1 \text{ in majority}) = \Pr(  \delta_1 + \varepsilon_2 \delta_2 \ldots + \varepsilon_{N_k} \delta_{N_k} \ge 0 ) = \tfrac12 + \tfrac12 \Pr( \varepsilon_2 \delta_2 \ldots + \varepsilon_{N_k} \delta_{N_k} \in [-\delta_1,\delta_1]),\Phi(x) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^x \! e^{-t^2/2} \, \mathrm{d}t \Pr\Bigl(\frac{n}{2} + x_1\sqrt{n} \le S_n \le \frac{n}{2} + x_2 \sqrt{n}\Bigr) \sim \Phi(2x_2) - \Phi(2x_1).  \Pr(A_1 \text{ is the majority}) \le \frac12\biggl(\Phi\biggl(\frac{\delta_1}{\sqrt{N_k-1}}\biggr) - \Phi\biggl(-\frac{\delta_1}{\sqrt{N_k-1}}\biggr)\biggr)+\frac12 = \Phi\biggl(\frac{\delta_1}{\sqrt{N_k-1}}\biggr).\predict_k \le \Phi\left(\sqrt{\frac{M_k}{n-\frac32k - \bigo(\sqrt{n} \log n)}}\right). \E[\predict_k] \le \Phi\left(\sqrt{\frac{\E[M_k]}{n-\frac32k - \bigo(\sqrt{n} \log n)}}\right) \sim \Phi\left(\sqrt{\frac{\frac32k}{n-\frac32k}}\right).  \E\left[\sum_{k=1}^{2n/3} \min\biggl(\frac16,\frac12(1-\predict_k)\biggr)\right] = \sum_{k=1}^{2n/3} \E\biggr[\min\biggl(\frac16,\frac12(1-\predict_k)\biggr)\biggr] \ge  \ge \sum_{k=1}^{2n/3} \frac16 (1-\E[\predict_k]) \ge  n\cdot \int_{0}^{2/3} \! \frac16\left(1-\Phi\left(\sqrt{\frac{\frac32x}{1-\frac32x}}\right)\right) \, \mathrm{d}x - o(n).1 + \int_{0}^{2/3} \! \frac16\left(1-\Phi\left(\sqrt{\frac{\frac32x}{1-\frac32x}}\right)\right) \, \mathrm{d}x \approx 1.0191289.

\begin{theorem}
Any algorithm that reports majority exactly requires in expectation at least  comparisons.
\end{theorem}

\section{Conclusions}
We have presented a Las Vegas algorithm for finding a majority color ball using, with high probability,
 comparisons. We have also shown that the expected number of comparisons
needs to be at least . We believe that a more careful application of our methods might
slightly increase the lower bound, but achieving , which we believe to be the answer, requires
a new approach. Another interesting question is to consider Monte Carlo algorithms.

\section*{Acknowledgments}
Most of the work has been done while PU was affiliated to Aalto University, Finland.


\bibliographystyle{abbrv}
\bibliography{bib}

\end{document}
