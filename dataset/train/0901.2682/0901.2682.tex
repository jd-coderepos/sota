

\documentclass[preprint,12pt]{elsarticle}







\usepackage{amssymb,xspace}
\usepackage{amsfonts,amsmath,latexsym}
\ifx\pdftexversion\undefined
  \usepackage[a4paper,colorlinks,linkcolor=black,filecolor=black,citecolor=black,urlcolor=black,pdfstartview=FitH]{hyperref}
\else
  \usepackage[a4paper,colorlinks,linkcolor=blue,filecolor=blue,citecolor=blue,urlcolor=blue,pdfstartview=FitH]{hyperref}
\fi
\usepackage{epsfig}
\usepackage{graphicx}




\newtheorem{theorem}{Theorem}
\newtheorem{conjecture}{Conjecture}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}[lemma]{Proposition}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{claim}{Claim}
\newtheorem{corollary}{Corollary}
\newtheorem{introtheorem}{Theorem}
\newtheorem{assumption}{Assumption}
\newtheorem{remark}{Remark}
\newenvironment{proof}{\noindent{\bf Proof:~~}}{}
\journal{Theory of Computer Science}


\newcommand{\wbox}{\mbox{\llap{}}}
\newcommand{\ie}{\emph{i.e.,\ }}
\def\beginsmall#1{\vspace{-\parskip}\begin{#1}\itemsep-\parskip}
\def\endsmall#1{\end{#1}\vspace{-\parskip}}











\newcommand{\namedref}[2]{\hyperref[#2]{#1~\ref*{#2}}}

\newcommand{\sectionref}[1]{\namedref{Section}{#1}}
\newcommand{\appendixref}[1]{\namedref{Appendix}{#1}}
\newcommand{\subsectionref}[1]{\namedref{Subsection}{#1}}
\newcommand{\theoremref}[1]{\namedref{Theorem}{#1}}
\newcommand{\defref}[1]{\namedref{Definition}{#1}}
\newcommand{\figureref}[1]{\namedref{Figure}{#1}}
\newcommand{\claimref}[1]{\namedref{Claim}{#1}}
\newcommand{\lemmaref}[1]{\namedref{Lemma}{#1}}

\newcommand{\namedrefeq}[2]{\hyperref[#2]{#1~\mbox{\rm(\ref*{#2})}}}
\newcommand{\equationref}[1]{\namedrefeq{Eq.}{#1}}
\newcommand{\remarkref}[1]{\namedref{Remark}{#1}}
\newcommand{\definitionref}[1]{\namedref{Definition}{#1}}
\newcommand{\tableref}[1]{\namedref{Table}{#1}}
\newcommand{\corollaryref}[1]{\namedref{Corollary}{#1}}
\newcommand{\propertyref}[1]{\namedref{Property}{#1}}
\newcommand{\appref}[1]{\namedref{Appendix}{#1}}
\newcommand{\propref}[1]{\namedref{Proposition}{#1}}
\newcommand{\dagree}{{\em Detect/Agree\ }}

\newcommand{\slsub}[1]{\mbox{\scriptsize\sl {#1}}}

\newcommand{\hydra}{H\textsc{ydra}\xspace}

\newcommand{\hide}[1]{}
\newcommand{\sidenote}[1]{\marginpar{#1}}

\newcommand{\alert}[1]{\textbf{\color{red}
[[[#1]]]}}


\newcommand{\ad}[1]{\textbf{\color{green}[[Aviva: [#1]]]}}


\newcommand{\dd}[1]{\textbf{\color{red}[[[#1]]]}}


\newcommand{\ezra}[1]{\textbf{\color{blue}
[[[EZRA: #1]]]}}
\newcommand{\ezrac}[1]{\textbf{\color{red}
[[[EZRA: #1]]]}}


\newcommand{\db}[1]{\textbf{\color{green}
[[[DB: #1]]]}}


\newcommand{\alerttocheck}[1]{\textbf{\color{blue}
[[[#1]]]}}




\newcommand{\tb}{\makebox[0.4cm]{}}
\newcommand{\due}{\makebox[0.8cm]{}}
\newcommand{\tre}{\makebox[1.2cm]{}}
\newcommand{\quat}{\makebox[1.6cm]{}}

\newcommand{\ra}{\rangle}
\newcommand{\la}{\langle}


\newcommand\ByzAgreementL{\mbox{\Large\sc ss-Byz-Agree\xspace}}
\newcommand\ByzAgreementl{\mbox{\large\sc ss-Byz-Agree\xspace}}
\newcommand\ByzAgreement{{\mbox{\sc ss-Byz-Agree\xspace}}}
\newcommand\initiatorL{\mbox{\Large\sc Init-Accept\xspace}}
\newcommand\initiatorl{\mbox{\large\sc Init-Accept\xspace}}
\newcommand\initiator{\mbox{\sc Init-Accept\xspace}}
\newcommand\broadcastpL{\mbox{\Large\sc msgd-Broadcast\xspace}}
\newcommand\broadcastpl{\mbox{\large\sc msgd-Broadcast\xspace}}
\newcommand\broadcastp{\mbox{\sc msgd-Broadcast\xspace}}
\newcommand\ginit{\mbox{{\sc I}-accept}}
\newcommand\BYZdur{\Delta}
\newcommand\sslargepulser{\mbox{Large-Cycle-Pulserxspace}}
\newcommand\ssstabilizer{\mbox{SS-Byz-Stabilizerxspace}}
\newcommand\byzcheck{\mbox{Byz-State-Checkxspace}}
\newcommand\fastcons{\mbox{Byz-Consensusxspace}}
\newcommand\broadcast{\mbox{Broadcastxspace}}

\newcommand\Bx{\mathcal{BBB}}
\newcommand\pulse{{\sc pulse}\xspace}
\newcommand\pulses{{\sc pulse}s\xspace}
\newcommand\pulsed{{\sc pulse}d\xspace}
\newcommand\pulsing{{\sc pulse}ing\xspace}
\newcommand\pulsesys[1]{{\rm[#1]}-{\sc pulsing}xspace}
\newcommand\A{\mathcal{A}}
\newcommand\BB{\mathcal{B}}
\newcommand\C{\mathcal{C}}
\newcommand\p{\mathcal{P}}
\newcommand\s{\mathcal{S}}
\newcommand\V{\mathcal{V}}
\newcommand\F{\mathcal{F}}
\newcommand\N{N}\newcommand\fl{f_{\!\ell}}
\newcommand\norm[1]{\left|\left|#1\right|\right|}
\newcommand\normi[1]{\left|\left|#1\right|\right|_\infty}
\newcommand\normw[1]{\left|\left|#1\right|\right|_\infty^\ww}


\newsavebox{\theorembox}
\newsavebox{\lemmabox}
\newsavebox{\conjecturebox}
\newsavebox{\claimbox}
\newsavebox{\factbox}
\newsavebox{\corollarybox}

\newsavebox{\propositionbox}
\newsavebox{\examplebox}
\savebox{\theorembox}{\bf Theorem}

\savebox{\lemmabox}{\bf Lemma}

\savebox{\conjecturebox}{\bf Conjecture}

\savebox{\claimbox}{\bf Claim} \savebox{\factbox}{\bf Fact}

\savebox{\corollarybox}{\bf Corollary}

\savebox{\propositionbox}{\bf Proposition}

\savebox{\examplebox}{\bf Example}


\newtheorem{cl}{\usebox{\claimbox}}[section]
\newtheorem{fact}{\usebox{\factbox}}[section]
\newtheorem{notation}{{\sc Notation}\rm }[section]
\newtheorem{definitions}{{\sc Definitions\rm }}[section]
\newtheorem{assumptions}[assumption]{{\sc Assumptions\rm }}
\newtheorem{observation}{{\sc Observation}\rm }[section]
\newtheorem{observations}[observation]{{\sc Observations\rm }}
\newtheorem{algorithm}{{\sc Algorithm}\rm }[section]
\newtheorem{protocol}{{\sc Protocol}\rm }[section]
\newcommand{\hdef}[1]{\noindent{\bf \R{\hunder{#1}~~}}\it }
\newcommand{\hcite}[1]{\L{\nocite{#1}[#1]}}
\newcommand{\hunder}[1]{\underline{\R{#1}}}
\newcommand{\hno}[0]{\ohebrewtext\noindent\hebrewtext}
\newcommand{\hmbox}[1]{\mbox{\R{#1}}}
\newcommand{\NS}{{{\cal NS} }}
\newcommand{\NSS}{{\small\sc ns}\xspace}
\newcommand{\DC}{{DigiClock}\xspace}
\newcommand{\BC}{{{\cal BC} }}
\newcommand{\consistent}[1]{{\textsc{Consistent}}{\rm(#1)}}
\newcommand{\invalid}[1]{\textsc{Invalid}{\rm(#1)}}
\newcommand{\valid}[1]{\textsc{Valid}{\rm(#1)}}
\newcommand{\EH}[1]{\textsc{EH: (#1)}}
\newcommand{\ignore}[1]{}
\newcommand{\byzantine}[0]{\mbox{\emph{Byzantin}\hspace{-0.15em}\emph{e}}\xspace}
\newcommand{\fhat}{\hat{f}_{\NSS}}
\newcommand{\f}{f}
\newcommand{\byz}{\sc{Byz}}
\newcommand{\calm}[1]{\textsc{Calm}{\rm(#1)}\xspace}
\newcommand{\correct}[1]{\textsc{Correct}{\rm(#1)}\xspace}
\newcommand{\working}[1]{\textsc{Working}{\rm(#1)}\xspace}
\newcommand{\ssbyzagree}{ss-\textsc{Byz-Agree}\xspace}
\newcommand{\unevenpulser}{\textsc{Erratic-Pulser}\xspace}
\newcommand{\algQ}{\textsc{ss-Byz-Q}\xspace}
\newcommand{\ByzCon}{\textsc{ByzCon}\xspace}
\newcommand{\Time}{\textsc{Time}\xspace}
\newcommand{\MaxNDeg}[1]{{#1}\!-\!\textsc{MaxDeg}\xspace}
\newcommand{\Num}{\textsc{Num}\xspace}
\newcommand{\Indx}{\textsc{Indx}\xspace}
\newcommand{\Bad}{\textsc{Bad}\xspace}
\newcommand{\Msg}{\textsc{Msg}\xspace}
\newcommand{\consAlg}{\textsc{LocalByzCon}\xspace}
\newcommand{\consAlgSS}{\textsc{Local-SS-Byz-Consensus}\xspace}
\newcommand{\pulser}{\textsc{Balanced-Pulser}\xspace}
\newcommand{\syncAlg}{\textsc{SS-Iterative}\xspace}
\newcommand{\asyncAlg}{\textsc{Async-SS-Iterative}\xspace}
\newcommand{\linenumber}[1]{{\tt #1}}
\newcommand{\lineref}[1]{Line~\linenumber{#1}}
\newcommand{\uu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\cc}{\mathbf{c}}
\newcommand{\xx}{\mathbf{x}}
\newcommand{\ww}{\mathbf{w}}
\newcommand{\bb}{\mathbf{b}}
\newcommand{\diag}{\mathop{\mathrm{diag}}}

\newcommand\Cycle{\mbox{\slshape Cycle}\xspace}
\newcommand\cyclemin{\mbox{}}
\newcommand\cyclemax{\mbox{}}






\def\squarebox#1{\hbox to #1{\hfill\vbox to #1{\vfill}}}





\newcommand{\reals}{\mbox{\msym R}}

\newcommand{\subcase}[1]{{\em Case #1:}\/}
\newcommand{\basis}{{\small \sc Basis }\xspace}
\newcommand{\induction}{{\small \sc Induction }\xspace}
\newcommand{\construction}{{\small \sc Construction: }\xspace}
\newcommand{\correctness}{{\small \sc Correctness: }\xspace}
\newcommand{\analysis}{{\small \sc Analysis: }\xspace}
\newcommand{\G}{\mathcal{G}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\timer}{\textsc{timer}\xspace}
\newcommand{\cycle}{\textsc{cycle}\xspace}
\newcommand{\Ir}[1]{I(#1)}
\newcommand{\Or}[1]{O(#1)}
\newcommand{\II}[2]{I_{#1}(#2)}
\newcommand{\OO}[2]{O_{#1}(#2)}
\newcommand{\as}[2]{r_{#1}(#2)}  

\begin{document}

\begin{frontmatter}






\title{Self-stabilizing Numerical Iterative Computation\footnote{Preliminary version of this work appeared
in the 10th International Symposium on Stabilization, Safety, and Security of Distributed Systems (SSS), Detroit, Nov. 2008.}}




\author{Danny Bickson, Ezra N. Hoch, Harel Avissar and Danny Dolev}



\address[IBM]{
IBM Haifa Research Lab\\
Mount Carmel\\Haifa 31905, Israel\\
Email: \{dannybi\}@il.ibm.com\\
}
\address[HUJI]{School of Computer Science and Engineering\\
The Hebrew University of Jerusalem\\
Jerusalem 91904, Israel\\
Email: \{hoch,harela01,dolev\}@cs.huji.ac.il\\
}






\begin{abstract}
Many challenging tasks in sensor networks, including sensor
calibration, ranking of nodes, monitoring, event region detection,
collaborative filtering, collaborative signal processing, {\em etc.}, can
be formulated as a problem of solving a linear system of
equations. Several recent works propose different distributed
algorithms for solving these problems, usually by using linear iterative numerical
methods.

The main problem with previous approaches is that once the problem inputs
change during the process of computation, the computation may output unexpected results.
In real life settings, sensor measurements are subject to
varying environmental conditions and to measurement noise.

We present a simple iterative scheme called \syncAlg for solving
systems of linear equations, and examine its properties in the self-stabilizing
perspective. We analyze the behavior of the proposed scheme under changing input sequences using two different assumptions on the input: a box bound, and a probabilistic distribution.


As a case study, we discuss the sensor calibration problem and
provide simulation results to support the applicability of our
approach.
\end{abstract}

\begin{keyword}
Self-stabilization \sep numerical iterative methods \sep
Jacobi algorithm \sep sensor-networks






\end{keyword}

\end{frontmatter}







\section{Introduction}
Many challenging tasks in sensor networks, for example distributed ranking algorithms
of nodes and data items \cite{PPNA08}, collaborative filtering \cite{KorenCF},
localization \cite{SensorLocalization}, collaborative signal
processing \cite{SignalProcessing}, region detection
\cite{RegionDetection}, etc., can be formulated as a problem of solving a linear system of
equations. Several recent works \cite{SensorLocalization},\cite{SignalProcessing},\cite{RegionDetection} propose different distributed
algorithms for solving these problems, usually by linear iterative numerical
methods.

In this work, we extend the settings of the above approaches by
adding another dimension to the problem. Specifically, we are
interested in {\em self-stabilizing} algorithms, that continuously run
and converge to a solution from any initial
state. This aspect of the problem is highly important due to the dynamic
nature of the network and the frequent changes in the
values being tracked.

As a case study, we show that the calibration of local sensors' readings can be formulated as a
linear system of equations , where  represents
the calibrated output reading,  represents the local reading, and 
represents a weighted communication graph. However, our work is general and
can be applied to any problem that can be formulated as a distributed solution to a
linear system of equations, including the previous works mentioned above.

The main challenge we have faced in this work, is that in the
classical linear algebra literature,  is assumed to be constant.
In our settings, the environment is constantly changing and the
computed algorithm never terminates, leading to constantly
changing values of . In this paper, we ask the following question: ``Is it possible to
devise a self-stabilizing numerical iterative method?'' We answer
affirmatively, and show that under minor conditions it is possible
to devise a self-stabilizing algorithm that solves a dynamic
system of linear equations, where the input to the system is
constantly changing.

We analyze the behavior of the proposed scheme under changing input sequences
using two different assumptions on the input behavior: a box bound, and a probabilistic bound.
We show that in both cases, once the network stabilizes there is a guarantee on
the quality of the computation.

One of the most efficient distributed approaches for solving a set
of linear equations of the type  is by using linear
iterative algorithms. Unlike Gaussian elimination, which has a
cost of  where  is the number of variables, an
iterative algorithm usually solves a system of linear equations in
time of  where  is the number of iterations, which depends
on the properties of the matrix . In many real life problems, the convergence
is logarithmic in , for example in multiuser detection \cite{Allerton}.
These algorithms are naturally distributed and work well in asynchronous settings. Furthermore,
when converging, the algorithms converge to a solution from {\em
any} initial state. An excellent survey of such methods is found
in \cite{BibDB:BookBertsekasTsitsiklis}.

The main novel contribution of this paper is in analyzing
the self-stabilizing properties of
algorithms from the linear iterative methods domain. For example, in a practical setting, it is
highly unreasonable to assume that sensor readings do not change
over time. However, it is reasonable to assume that at steady
state the change in sensor readings is bounded. Informally, in
this work we show that once the input readings are bounded, the
output solution is bounded as well. This useful observation
enables us to tie together numerical iterative methods and
dynamically changing environments in a self-stabilizing manner.

To the best of our knowledge, this is the
first work tackling this challenging problem. We believe that our
approach can have numerous applications in the field of
distributed self-stabilizing computation.

Other works discuss fault tolerance aspects of distributed
computation. For example, overcoming faults in sensors by
averaging the input was investigated in~\cite{SensorFailures},
using a centralized algorithm. Quantifying faulty nodes'
effect on the system's output is discussed in~\cite{BinaryRept}
and~\cite{MultiValRept}. These papers consider bounded input paths
and their effect on the stability of the output. In
\cite{RepCons-PODC08} infinite input paths are considered under
the assumption that only specific sensors' input may change. All
three papers consider discrete input values, as opposed to a
continuous set of input values discussed in this paper.


The paper is constructed as follows.
\sectionref{sec:model} defines the model and presents the problem definition. \sectionref{sec:Errors} discusses measurement error types and characterization. \sectionref{sec:solution}
presents our novel algorithm \syncAlg. \sectionref{sec:analysis}
analyzes our algorithm and gives bounds on the convergence rate, assuming a box bound on the inputs. \sectionref{sec:async} extends our construction to the asynchronous case. \sectionref{sec:Probabilistic} extends the
analysis of \syncAlg under a probabilistic model when the input is characterized using a normal distribution.
\sectionref{sec:simlation} presents experimental results of
running \syncAlg using sample topologies. We conclude in
\sectionref{sec:discussion}.

\section{Model and Problem Definition}\label{sec:model}
Consider a distributed system of sensors measuring real-world
data. Sensors are located in different areas; for example, the
senors are spread throughout a building and they measure the
temperature to adjust the heating or cooling. We would like the
collected data to be as reliable as possible, reflecting closely the changing
environmental conditions. One of the obstacles we face when designing
algorithms that collect data from a sensor network are measurement errors.
There are two main types of inaccuracies of sensors' measurements: noisy environment
and sensing equipment which is not calibrated.
In our setting sensors are allowed to
communicate among themselves
and
to use data from other nodes for
calibrating their
environmental readings.
Furthermore, we would like our
calibration algorithm to have fault-tolerance properties.
Specifically, we are interested in self-stabilizing algorithms
\cite{DolevSSBook}, which converge to an optimal solution from
any initial state. Observe that self-stabilization helps also in deploying the sensors.
There is no need to explicitly synchronize the sensors, once enough of them
are deployed and begin functioning the results will converge to the expected value.

We model the sensor calibration problem as follows. Given a directed
communication graph ,  is the set of nodes ,  is the set of weighted edges connecting
them (weights can be negative). Edge weights are used to model the directional dependence between nodes' outputs; \ie if  then there is no edge between  and  and their output is not directly dependent on each other. In addition, it is possible to have a non-zero self
connected edge, , which represents the weight of 's own input. Note that the graph
does not have to be symmetric, which means that it is possible that .
We denote  as the set of node 's neighbors, excluding . 

Initially, we assume a synchronous system: during a single round of communication, any pair of connected
nodes may send a single message on each directed edge. In each round
, each node  has a scalar input value , which
represents the local reading of the sensor.\footnote{For simplicity
of notations we use scalar variables in the paper. An extension to
the vector case (where each sensor measures a set of measurements) is immediate.} In addition,  outputs its
output value, which is denoted by ; both inputs and outputs are from the domain of real numbers. Denote by  the
input vector of the entire system at round , and by 
the output vector of the system at the end of round .
In \sectionref{sec:async} we relax the assumption of synchronous rounds
and provide a variant of the algorithm that works in asynchronous settings.

The schematic operation of each node  at round  is
composed of the following steps: (a) read the value of
; (b) send messages; (c) receive messages; and (d) do
some processing and output . Then a new round is
started, and the nodes continue so forever.

\begin{definition}
  A {\bf configuration}  of the system at round  consists of the state
  of each node prior to performing any operation at round ;
  this configuration is denoted by .
\end{definition}

\begin{definition}
  An {\bf input sequence}  of length  is a list of   vectors such that each 
  is a possible input vector of the system (\ie , the domain of allowed values).
  An {\bf output sequence}  of length  is a list
  such that each 
  can potentially be an output vector of the system.
\end{definition}

\begin{definition}
  A step from configuration  to configuration  on input vector
   is {\bf legal} if  is reached from  by the
  system when having  as the input vector.
 is {\bf produced} by a legal step if
   is the output vector of the system resulting from such a legal step.
\end{definition}

\begin{definition}
  A {\bf run} of a system on input sequence  starting
  from configuration  is the sequence 
  s.t. for any : the step from  to  on input vector
   is legal, and   is produced by that
  legal step. The system is said to produce the output sequence
  .
\end{definition}

In the special case when the sensor observations (the input to the
system) are fixed, the output decision of the sensors should converge to
a solution that preserves the linear relations among node inputs
and outputs. More formally, consider an input sequence
 of identical input vectors; \ie . It is desired that for such an input a run
from any configuration  on  would end up
producing an output sequence  such that  as , for a  that solves the following linear
system of equations:

We assume that the above set of equations are uniquely solvable, denoting
 as the solution to .


The following definition bounds the change in sensor observations:
\begin{definition}\label{def:concentrated}
  An input sequence  is -{\bf bounded} around
   if for every , , it holds that .\footnote{.}
\end{definition}

\definitionref{def:concentrated} states that a sequence  is -bounded if all
the vectors in 
are bounded within an  dimensional hypercube with an edge , centered around a point . We note that once changes
in the input are not bounded, then no efficient algorithm
(especially in a network that is sparsely connected) can calculate
the output fast enough. Thus it is easy to construct an example where the diameter of the
communication graph is , for some system of equations it would
take at least  rounds for the information exchange for input readings at
one side of the network to propagate to the other side of the
network.

\begin{definition}\label{def:runconverges}
  Let  be an input sequence that is -bounded
  around  and let  be the solution to input .
  A run from configuration  on input sequence  -{\bf converges} to its solution if
  the produced output sequence  satisfies that
  ; where 
  is a function of  and .
\end{definition}

\definitionref{def:runconverges} requires that if - starting from
configuration  - the inputs are in an  dimensional hypercube of
radius  around  then the output at time  is
bounded within some  dimensional hypercube around  with
radius . We aim at an
 that decreases as 
increases, as long as the inputs are bounded by the same
-centered, -radius hypercube. Clearly, for ,  for any . That is, there
is some minimal radius  around  and we cannot
ensure a tighter bound.

The above definition considers a single initial configuration, and
a single input sequence . We are interested in an
algorithm that works for all initial configurations and all input
sequences.

\begin{definition}\label{def:alwaysconv}
  An algorithm  -{\bf converges} for -bounded input sequence  if every run (from any configuration) on
  ,
  -converges to its solution.  An algorithm  -{\bf always converges} if for
  every -bounded input sequence ,  -converges.
\end{definition}

\definitionref{def:alwaysconv} formally defines the problem at
hand, as an algorithm  that {\em always converges} has the
desired self-stabilizing property: for any system state, once the
sensors' readings changes are bounded, the change in output of the
entire system is bounded as well.

Our goal is to find an algorithm  that is -always
converging for a provably ``good'' . Moreover, we aim at
having  efficient also in its message complexity and
the simplicity of the code, allowing lightweight sensors to actually
implement it.

\section{Measurement Errors}\label{sec:Errors}
As mentioned in the introduction, sensor readings suffer from two types of inaccuracies: measurement errors
and calibration errors. In this section we elaborate on two common types of measurement errors.
This introduction serves as a motivation for bounding the errors using a normal distribution,
a construction that is discussed in detail in \sectionref{sec:Probabilistic}.

Most physical sensors tend to suffer from noise, which is defined as fluctuations in external factors to the stream of target information (signal). Most sensor noise can be attributed to a small number of common noise patterns, this noise is usually due to the nature of physical substance being measured and the nature of the measurement equipment. Two of the most common noise patterns are Shot Noise and Nyquist Noise as defined at \cite{RFCD97}.

\begin{definition}\label{def:ShotNoise}
{\bf Shot Noise} is a type of noise common to the particle-like nature of the charge carriers. It is often thought that a DC current flow in any semiconductor material is constant at every instant. In fact, however, since current flow is made up of individual electrons and holes, it is only the time average flow of these charge carriers that is seen as a constant current. Any fluctuation in the number of charge carriers at any instance produces a random current change in the instance.
\end{definition}
 As these particles (usually photons or electrons) distribute with Poisson distribution the noise itself also follows this distribution. Poisson distribution is nearly Gaussian and can easily be approximated by a Normal distribution.

\begin{definition}\label{def:NyquistNoise}
{\bf Nyquist Noise} (also Thermal noise): In any conducting medium whose temperature is above absolute zero (0 Kelvin), the random motion of charge carriers within the conductor produces random voltages and currents. These voltages and currents produce noise.
\end{definition}
 This noise is nearly white by nature (equally distributed through the spectrum). It is characterized by a normal distribution of its amplitude.

Both noise types discussed above are nearly Gaussian \cite{GIE}. Therefore tolerance to Gaussian noise is an important issue when examining the sensor calibration problem, specifically, and for systems in general. Furthermore, the central limit theorem states that in the average case any i.i.d sample is bound to be distributed as a Gaussian surrounding the mean. This makes Gaussian tolerance a powerful tool when dealing with dynamic input sequences.

\section{Our Proposed Solution}\label{sec:solution}
Getting back to the sensor calibration example, let  be the matrix that has  as entries,
\equationref{eq:Opdef}. It be written in linear algebra
notation, (s.t. it applies to all nodes simultaneously):


If we consider a non-self-stabilizing system in which the inputs
do not change (that is, the input is fixed, as some ), then
\equationref{eq:matrixform} can be seen as , where 
and  are given. In such a case, we are interested in finding
the value of , which is a vector of  unknown variables.
However, we are interested in the case where  changes over
time, and thus \equationref{eq:matrixform} does not describe the
problem properly, but rather helps in understanding the motivation
for our solution.

Rearranging \equationref{eq:Opdef} we get:


Clearly, for the case of , a -bounded input sequence
, if 
as  then \equationref{eq:updaterule}
converges to the solution of \equationref{eq:Opdef}. Thus, if the
update rule of \equationref{eq:updaterule} is executed
simultaneously by all nodes, and for all of the nodes
, then it also
solves \equationref{eq:matrixform}. That is, if each node locally
executes \equationref{eq:updaterule} then the global solution is
reached. This observation motivates algorithm \syncAlg in
\figureref{figure:syncAlg}.

\begin{figure*}[h]
\begin{center}
\begin{minipage}{4.8in}
\hrule \hrule \vspace{1.7mm} \footnotesize
\setlength{\baselineskip}{3.9mm} \noindent Algorithm \syncAlg
 \vspace{1mm} \hrule \hrule
\vspace{1mm}

\linenumber{01:} Each round {\bf do}:\hfill\textit{/* executed on
node 
*/}\\

\makebox[0.93cm]{} \textit{/* send current value of  to all neighbors */}\\
\linenumber{02:} \tb {\bf for} each   \\
\linenumber{03:} \due {\bf send}  to ; \\

\makebox[0.93cm]{} \textit{/* update  according to values sent by neighbors */}\\
\linenumber{04:} \tb {\bf set}   \\
\linenumber{05:} \tb {\bf for} each value  received:  \\
\linenumber{06:} \due {\bf update} ;\\

\linenumber{07:} {\bf od}.

\normalsize \vspace{1mm} \hrule\hrule
\end{minipage}
 \caption{A self-stabilizing iterative algorithm.}\label{figure:syncAlg}
 \end{center}
\end{figure*}

\begin{remark}
  In \syncAlg there is no notion of the ``current round number
  ''. That is,  reads and writes to the variables  and 
  without being ``aware'' of . When we discuss the algorithm ``from the outside'', we will consider  and  instead of
  just .
\end{remark}

Consider  as running at some round . When  performs
\lineref{03}, it sends the value of . The last time
 was updated was at \lineref{04} and \lineref{06} of
round . Thus, the value sent by  at round  is
actually . Therefore, the values received from 
by  and used to update  are .
However, the value read by  in \lineref{04} is the value of
. Concluding that  updates 
exactly according to \equationref{eq:updaterule}.

\begin{remark}\label{rem:partofcode}
  Each node  must know the values of  as ``part of the
  code''. Thus, these values cannot be subject to transient
  faults.
\end{remark}

\section{Analysis of \syncAlg}\label{sec:analysis}
Paper \cite{BibDB:BookBertsekasTsitsiklis} shows that the update rule of
\equationref{eq:updaterule} can be written in linear algebra form
as

where  is a diagonal matrix with  in the main
diagonal, and  for 

 where  is the identity matrix. Using this update rule to solve a set of linear equations iteratively is  known as the Jacobi
algorithm.



Let  be an input sequence of length  that is
-bounded around vector . At some round   . Note
that \syncAlg saves a single scalar variable at each node, and thus the
configuration of round  can be defined by the value of
 at round . Consider \syncAlg's run, starting from an
arbitrary configuration at round . We aim at showing that
 is bounded by a hypercube centered at . Denote
by . If we show
that  is bounded (as  increases),
then  is within a bounded hypercube centered at .
Consider :

Since  is a -bounded input sequence around
, each  can be denoted as
 s.t.  is a vector, and . 



\begin{claim}
At round , it holds that 
\end{claim}
\begin{proof}
  Proof by induction. The base of the induction was shown for ; see \equationref{eq:baseInd}. Assume that the claim holds for . Thus, . By the update rule in
  \equationref{eq:matrixUpdate}, we have that . Combining the two equations implies
  
  Thus, if the claim holds for  it also holds for ;
  and we have that the claim holds for all .
  \qed
\end{proof}


\begin{definition}
  A matrix  is {\bf diagonally dominant} if
  . A matrix  is {\bf normalized} diagonally dominant (normalized, for short) if
   is diagonally dominant, and .
\end{definition}

\begin{lemma}\label{claim:diag}
  For a normalized diagonally dominant matrix , it holds that
   and  where  are defined in \equationref{AB} and .
\end{lemma}
\begin{proof}
   is zero except for its
  main diagonal for which . Since , we have that . Thus, it holds that .
  Furthermore,
  , \ie . Regarding ,  for  and 0 for . Since  is assumed to be normalized diagonally dominant, we have
  that , thus . Therefore,  for all . In total, for any  we have
  , leading to .
\qed\end{proof}

If  is a diagonally dominant matrix then node 's own input effects 's output more than the sum of all of 's neighbors outputs. That is, the weight of 's input is at least the sum of weights of 's neighbors outputs.

\begin{theorem}\label{theorem:main}
  Given a normalized diagonally dominant and invertible , there are constants  where  and ,
  such that \syncAlg -always converges with
  .
\end{theorem}
\begin{proof}
  By \lemmaref{claim:diag} it holds that  and . Consider a -bounded input sequence  around , and
  \syncAlg's run starting from an arbitrary state .
  We are interested in the behavior of :

For an input sequence  that is -bounded around
, denote by  the solution to the original system of
equations . By \equationref{eq:norm},

  Since , we have that
   and by setting  it holds that . By setting  and recalling that  we are done.
\qed\end{proof}

\theoremref{theorem:main} states sufficient conditions s.t. \syncAlg -always
converges. Moreover, the algorithm \syncAlg is lightweight, as it
requires nodes to send only a single value to every neighbor on each
round.



\section{Extension to the Asynchronous Model}\label{sec:async}
Our second novel contribution is in extending our model to support
asynchronous communications. In a large sensor network, it is
unreasonable to assume that the sensors operate in synchronous
rounds. Furthermore, as known from the linear iterative algorithms
literature, algorithms
sometimes
converge in less asynchronous rounds (when compared to synchronous rounds).

When considering the asynchronous model, it is more convenient to
discuss shared-memory as means of communication.\footnote{In
\cite{DolevSSBook} it is shown how to convert an algorithm based
on shared-memory to a message-passing algorithm with links of
bounded capacity.} Thus, assume that for each directed edge
between  there is a read-write register 
that is written by  and read by .

An asynchronous run is an infinite sequence of configurations  such that some process 
performs an atomic step between configuration  and
. An atomic step consists of reading or writing from a
single register. Notice that in the current model a configuration
consists of all the registers and of the local variables at the
different nodes.

In this section we again prove that starting from an arbitrary
configuration, when the changes to the inputs are bounded, the outputs are
bounded as well. We consider each configuration  to be
assigned a vector input  such that if node  reads the
input when performing an atomic step on  it reads the value
of . Equivalently, the output vector of configuration
 is .

\figureref{figure:asyncAlg} outlines \asyncAlg, which is a direct
translation of \syncAlg to the shared-memory model.

\begin{figure*}[h]
\begin{center}
\begin{minipage}{4.8in}
\hrule \hrule \vspace{1.7mm} \footnotesize
\setlength{\baselineskip}{3.9mm} \noindent Algorithm \asyncAlg
 \vspace{1mm} \hrule \hrule
\vspace{1mm}

\linenumber{01:} Forever {\bf do}:\hfill\textit{/* executed on
node 
*/}\\

\makebox[0.93cm]{} \textit{/* write current value of  to all neighbors */}\\
\linenumber{02:} \tb {\bf for} each :  \\
\linenumber{03:} \due {\bf write}  to ; \\

\makebox[0.93cm]{} \textit{/* update  according to values of neighbors */}\\
\linenumber{04:} \tb {\bf set}   \\
\linenumber{05:} \tb {\bf for} each :  \\
\linenumber{06:} \due {\bf read}  into ;  \\
\linenumber{07:} \due {\bf update} ;\\

\linenumber{08:} {\bf od}.

\normalsize \vspace{1mm} \hrule\hrule
\end{minipage}
 \caption{A self-stabilizing iterative algorithm for asynchronous networks.}\label{figure:asyncAlg}
 \end{center}
\end{figure*}

\asyncAlg consists of two phases: in the first, the previous value of  is
written to all its neighbors' registers. In the second phase  calculates
its new value of  by reading the registers of all its
neighbors.

We consider only ``fair'' runs, in which each node performs an
atomic step infinitely many times. Thus, each node performs both
phases infinitely many times. A round is defined to be the shortest
prefix of a run such that each node has performed at least once lines \linenumber{02}-\linenumber{07} in the
algorithm. We number each atomic step and each round. Note that a round consists of many
atomic steps.

We model a fair run as follows. Each node  performs
infinitely many atomic steps, and participates in infinitely many
rounds. Notice that the registers  reads in round  have
all been last written to, no earlier than during round . Since a
round consists of each node performing all the steps in the
algorithm, each node  manages to read all of its neighboring
registers and to write to all of its neighboring registers every
round. Thus, there is some atomic step  (during round )
such that:

where  (for all ) are smaller
than  and are from at least round .

Let  be such that , and let the inputs be
from a -bounded input sequence around . Denote  and .

\begin{theorem}\label{theorem:main2}
  Given a normalized diagonally dominant and invertible , and while considering only fair runs,
  there are constants  where  and ,
  such that \asyncAlg -always converges with
  ; where  counts the asynchronous rounds of a fair run.
\end{theorem}

\begin{proof}
 Notice that if  did not perform the
th atomic step then  and therefore
. Consider the value of
 when  did perform the th atomic step
(during round ).

where  and the different  are smaller than  and are
all from round  or round .

By using \lemmaref{claim:diag} we get:

for some  and  that is from round  or
.

Therefore, for any  during round  there is a list of
length  of nodes  and a
sequence of length  of atomic steps , such that



Denote by , and . We have
that for node  performing the th atomic step during round
 it holds that .
\qed\end{proof}

In fair runs,
there are infinitely many rounds , thus, as  and  go to
infinity, we have that  is bounded by a hypercube of
length  around .



\section{Probabilistic Bound}\label{sec:Probabilistic}
In this section we analyze the behavior of the \syncAlg algorithm, when the input readings are normally distributed
due to noisy readings. 

Let  be an input sequence of length  that is normally distributed around a mean vector . That is, , where each is sampled i.i.d from a Gaussian distribution with mean  and covariance . Consider \syncAlg's run, starting from an arbitrary configuration at round . We aim at showing that  is equivalent to a sequence  sampled i.i.d from a Gaussian distribution  where  is the solution to .

Since we know the distribution , we can calculate  using \equationref{eq:matrixUpdate} after  is sampled. , our sequence's starting point, can take arbitrary values as we will show that \syncAlg  converges from any starting position. 

We can now deduce that after  rounds of sampling the input distribution the output  is distributed as:

This formulation is, however, dependant upon , or upon the specific samples of . The output of each round is normally distributed with mean  and with covariance matrix .



To find  we examine the recursive formula for . For simplifying notations, we mark the starting
round  as round .

Now we take  to find the distribution :

By \lemmaref{claim:diag} it holds that . Using the Maclaurin series we get:


Denoting  we write the distribution of :


Recall the definitions of  and  \eqref{AB} and find that:

Note that the output sequence can now be characterized more intuitively as:


Using known bounds such as multivariate extensions of Chebyshev's bound one can now introduce bounds similar in nature to the box bounds discussed earlier. A better bound can be acquired using the cumulative distribution function for normal distributions; however these can only be estimated numerically. The use of such bounds is:

where the connection between  and  depends on the specific bound used.

So far we have shown that \syncAlg is tolerant towards Gaussian noise, and the output sequence converges to a sequence drawn i.i.d from a normal distribution around the expected solution. 

\subsection{The Asynchronous Setting}

Our proof so far discussed the synchronous case. Next, we extend the analysis of the probabilistic bound for asynchronous case, under mild assumptions. We assume the ``Totally Asynchronous'' model as discussed in \cite{BT97}. We denote  as the set of times in which the 'th node updates its neighbors with new output values. We further denote  as the vector containing the last update times of all received messages at node  at time .
\begin{definition}
 {\bf Total Asynchronism}: the sets  are infinite and if  is a sequence of elements of  that tends to infinity, then  for every .
\end{definition}
This assumption implies that every node is updated infinitely often while allowing maximal flexibility for delay and loss of data.

\cite{BT97} gives a converges proof for the asynchronous case, to an iterative algorithm with constant input values.
The challenge we face is that the input is not constant, but distributed normally. Thus we need to prove that the solution does not infinitely diverge.

For proving that the algorithm output does not diverge, we require some further assumptions. We assume that the update times of each of the nodes are independent of the distribution . The second assumption we make is that the
input noise distribution is normally distributed, where the noisy reading in different sensors are not correlated.
In other words, the inverse covariance matrix of the input is a diagonal matrix.

To prove that under these assumptions  is normally distributed we define the set :

Denote  as the ordered sequence of times in .
For all  we need to find the distribution of the input at time .
\begin{theorem}\label{theorem:main3}
The infinite input sequence  is distributed normally with .
\end{theorem}
\begin{proof}
As  is normally distributed, any marginal distribution computed by a subset of the nodes is normally distributed as well. Now we can induce the requested theorem:

Induction base: By the {\em Total Asynchronism} assumption there exists a time  at which all nodes have updated their value, and thus the input of each node is now drawn from its marginal distribution. This means that at time  the distribution of the entire input vector is (by cartesian product) drawn from .

Induction hypothesis: At time  we assume the input distribution is distributed normally from .

Induction step: At time  we separate the nodes into two groups:
  The first group contains nodes that remained constant from the previous round, that is, their a-priori distribution is their marginal distribution drawn from  by our induction hypothesis.

  The second group contains nodes that are updated with a new input value at this round; this value is distributed again from their marginal distribution.

  Notice that all of these marginal distributions are Gaussian, thus, their cartesian product is Gaussian as well. In addition, any joint covariance between nodes is  due to our assumption. Therefore, we have a cartesian product of all of the nodes distributed as marginal distribution of  and thus the entire input  follows the distribution .

    Finally we induce that at all :  are drawn from . Note that unlike the synchronous model - these samples are no longer taken i.i.d from the distribution .
\qed\end{proof}

Now we can use \theoremref{theorem:main3} and the {\em Total Asynchronism} assumption to draw a similar proof to the synchronous case. Recalling \equationref{eq:recursiveForm}:

\theoremref{theorem:main3} shows that the input distribution, at all rounds, is drawn from . This implies that we may apply the Maclaurin series again:


We now turn to  \cite[Section 6.3.2]{BT97} where the following claim is proven:
\begin{lemma}\label{claim:contraction}
  For a normalized diagonally dominant matrix , it holds that
   asynchronously converges.
\end{lemma}
We now make use of \lemmaref{claim:contraction} under the following notations: , which means that our solution converges to . Recalling \equationref{AB}: , where  is diagonally dominant and  is a diagonal matrix, results in  being diagonally dominant. Combining these results together, we conclude that  is a contraction, thus the linear dynamical system  converges to zero for any initial :


Regarding convergence speed, the speed at which the initial output factor converges to  and the output distribution converges to a normal distribution, is dependant upon the rate of the least updated node. These settings, though somewhat more restricting than the ones used for synchronous convergence, are all ``minimal'' in the sense that removing any of them creates a system that may diverge. Further discussion about the validity of the
above assumptions is given in \sectionref{sec:discussion}.

\section{Experimental Results}\label{sec:simlation}
\subsection{Box Bound}
For illustrating the behavior of our proposed algorithm using the box
bound assumption, we have simulated \syncAlg using two sample topologies of one hundred nodes.
\figureref{figA} depicts a circular topology where each node is
connected to its left and right neighbors. \figureref{figB} shows a
random unit disc graph, where nodes are randomly spread on a
plane, and each node is connected to the nodes that are within a
distance of 1.  The X-axis shows the number of iterations, and the Y-axis shows the value of
. Area colors in the heatmap depict the
average of the following procedure: randomly select a vector
 and a -bounded sequence around ,
run the simulation for the randomly selected values and return the
 distance between the last output vector and 
(calculated as ). The heatmap uses a  scale. Both graphs clearly show that as  decreases
and the number of iterations increases, the output of \syncAlg
converges to be bounded by a small hypercube around .

Note that the unit disc weighted topology matrix is characterized by
 while the circle graph
is characterized by . As expected,
using unit disc topology requires a larger number of iterations
for convergence (depends on ). In addition, in the unit
disc topology the value of  has a smaller effect on the
convergence, due to the value of , which affects the minimal radius around the output.
Since  is smaller in the unit disc topology,
increasing  does not significantly affect the convergence.

\begin{figure}[h!]
\begin{minipage}[b]{0.5\linewidth}
\centering
  \hspace{1.25in} \includegraphics[scale=0.4]{circle2}
  \vspace{-0.5cm}
  \caption{Sim. of a Circle graph.}
  \label{figA}
\end{minipage}
\begin{minipage}[b]{0.5\linewidth}
\centering
  \hspace{1.25in} \includegraphics[scale=0.4]{disc2}
  \vspace{-0.5cm}
  \caption{Sim. of a Unit-Disc graph.}
  \label{figB}
\end{minipage}
\end{figure}

\subsection{Probabilistic Bound}
We have simulated a run of \syncAlg, when the input noise is i.i.d. normally distributed.
\figureref{figC} plots the behavior of the output distribution at specific rounds. The input distribution of two nodes, printed in blue, is a normal distribution where the two nodes are uncorrelated. The output (in red, growing darker in later rounds) are distributed around some round mean, with the means themselves distributed around . It is important to note there is no greedy convergence to . This is because each round contains a different noise sample and thus at a specific round our solution can stray away from .

\figureref{figD} plots the behavior of the mean value of the input and output to the large system limit. The input
 is to the right (in blue axes) the output is to the left (gray circles). After a large number of rounds, the output is normally distributed around , where the plotted  (in green) is the result of an EM estimation of the sample mean.

\figureref{figE} plots a similar experiment from a different angle. 
This figure shows the input reading of the nodes (to the right) which is spherically distributed in a circle because the input noise is uncorrelated. The output of the \syncAlg algorithm (to the left) is correlated among nodes, as seen by the elliptic shape of the distribution. The correlation of the output distribution is supported by the theoretical results.

\begin{figure}[h!]
\begin{minipage}[b]{0.5\linewidth}
\centering
  \hspace{1.25in} \includegraphics[scale=0.3,clip]{per-round2}
  \vspace{-0.5cm}
  \caption{Output of several rounds.}
  \label{figC}
\end{minipage}
\begin{minipage}[b]{0.5\linewidth}
\centering
  \hspace{1.25in} \includegraphics[scale=0.3,clip]{input-output2}
  \vspace{-0.5cm}
  \caption{Convergence behavior.}
  \label{figD}
\end{minipage}
\end{figure}

\begin{figure}[h!]
\centering{
  \includegraphics[scale=0.35,clip]{covariance}\\
  \caption{Self correlation of input and output.}\label{figE}
  }
\end{figure}

\section{Discussion}\label{sec:discussion}
We have shown that the algorithm \syncAlg is a modification of the
Jacobi iterative method to solve a set of equations ,
where  is given and  is dynamically changing but bounded or statistical.
Moreover, \theoremref{theorem:main} is a generalization of
previous analysis of Jacobi's convergence. Our motivation for
\syncAlg originates from the sensor calibration problem, where
sensors need to calibrate their noisy readings. Unlike previous
approaches to this problem, we assume a dynamic system with an
infinite execution of the algorithm. In this setting the readings
of the sensors continuously change. Under the assumption that the
readings' changes are bounded, we have shown that the calibrated
output is bounded as well.


Further application for \syncAlg can be found in any setting where
it is desired to solve  in a converging and
self-stabilizing manner, while  is given, and  may change
slightly from one round to the next. Notice that the analysis
given in
\sectionref{sec:analysis} holds in such a system.

As noted in \remarkref{rem:partofcode} the matrix  is ``part of
the code''. An optional alternative to the current solution is to
compute  (the inverted matrix of ) beforehand and
include it ``as part of the code''. Thus, each node could locally
solve , and it can be shown that  will be
bounded (as long as  is bounded). The main problem with such
a solution is the connectivity requirements it incurs. In our
solution, scalar values are sent in the network only between
direct neighbors. The matrix  represents a weighted adjacency
graph. Once inverted, the matrix  might not be sparse.
A non-zero entry  means that node  needs
to communicate with node . This extra communication might cause the algorithm to lose its self-stabilizing properties, as
non-neighboring nodes would require a self-stabilizing overlay
network for their communication.

The assumption of a predefined  is suitable for static networks
in which the communication graph is predetermined. For dynamic
networks, it would be interesting to adjust \syncAlg to discover
the connectivity of the network, inferring the optimal weights dynamically.
We assume that after the weights are calculated, the topology of the
sensor network remains stable, thus the convergence analysis of \sectionref{sec:analysis} should hold.

\subsection{Necessity of Convergence Conditions for the Probabilistic Bound}
Assuming that the sensor input readings are normally distributed due to measurement noise, the resulting output is also normally distributed. As discussed in \sectionref{sec:Probabilistic}, this is not a sufficient condition for the convergence of \syncAlg in a finite number of rounds.

We give the following example to demonstrate the claim above. Assume the input reading at round  is larger than , and at each of the following rounds the input reading of each node is larger than at the previous round. As the input is normally distributed, for every  there is a small but positive chance for such a sequence of length . Input sequence behaving as described would lead \syncAlg to a growing output sequence for  rounds, meaning for the duration of these rounds \syncAlg diverges. Thus it is obvious the mean can be infinitely far from  as long as  is finite. However, when  is large, the probably of such an anomaly is diminishing to zero.

The convergence results for the asynchronous case had a minimal set of assumptions. One of them is that the input noise distribution must be uncorrelated among nodes. That is because if the input noise distribution is correlated, all nodes
must sample the input concurrently, an assumption which is not valid under the asynchronous model. 

\subsection{Relation to Perturbation Theory}
A large amount of research focused on the problem of solving  when  and
 are not exactly known. That is, let  and
, and consider the equation
; what can be said about  in
relation to ?

Our setting is ``easier'' in one sense, and ``harder'' in a
different sense. In our setting  is known, \ie . However,  is not well defined. That is, the input
vector - which is described by  - changes over time.
When solving  it is assumed that there
is some  that is \emph{constant} but it was measured with an
error. In our case,  is not constant as it changes over time,
while it represents the measurements correctly.

As a future research, it would be interesting to consider the
implications of adding inaccuracy to the measurements. The vast
body of knowledge regarding perturbation theory would definitely
aid in this extension to our model.

\subsection{Relation to Convex Optimization}
Many practical optimization problems are given in the quadratic
form , where the task is to compute
 distributively over a communication network. A
survey showing several applications can be found in \cite{PPNA08}.
Example applications are monitoring, distributed computation of
trust and ranking of nodes and data items.

A standard way for solving  is by computing the
derivative and comparing it to zero to get the global optimum.
When the matrix  is symmetric, , and we get
a linear system of equations . In other words, the convex
optimization problem is reduced into a solution of a linear system
of equations.

Interior point methods \cite[Ch. 11]{BV04} solve linear programming
problems by applying Newton method iteratively. Each computation
of the Newton step involves a solution of a linear systems of
equations. An area of future work is to examine the applications
of our self-stabilizing algorithm to these methods. The
difficulties arise from the fact that the matrix A needs to be
recomputed between iterations, so nodes need to be synchronized
and aware of the current iteration taking place.

\section*{Acknowledgements}
The authors would like to thank Golan Pundak for
assisting with the simulations, and the anonymous reviewers of SSS-08 conference
for their helpful comments.


\bibliographystyle{plain}
\bibliography{TCS09}








\end{document}
