[{'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD1.1 dev', 'Metric': 'EM', 'Score': '67.7'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD1.1 dev', 'Metric': 'F1', 'Score': '77.3'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'NarrativeQA', 'Metric': 'BLEU-1', 'Score': '33.45'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'NarrativeQA', 'Metric': 'BLEU-4', 'Score': '15.69'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'NarrativeQA', 'Metric': 'METEOR', 'Score': '15.68'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'NarrativeQA', 'Metric': 'Rouge-L', 'Score': '36.74'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD1.1', 'Metric': 'EM', 'Score': '73.744'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD1.1', 'Metric': 'F1', 'Score': '81.525'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD1.1', 'Metric': 'EM', 'Score': '67.974'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'SQuAD1.1', 'Metric': 'F1', 'Score': '77.323'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'MS MARCO', 'Metric': 'Rouge-L', 'Score': '23.96'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'MS MARCO', 'Metric': 'BLEU-1', 'Score': '10.64'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'CNN / Daily Mail', 'Metric': 'CNN', 'Score': '76.9'}}, {'LEADERBOARD': {'Task': 'Question Answering', 'Dataset': 'CNN / Daily Mail', 'Metric': 'Daily Mail', 'Score': '79.6'}}, {'LEADERBOARD': {'Task': 'Open-Domain Question Answering', 'Dataset': 'Quasar', 'Metric': 'EM (Quasar-T)', 'Score': '25.9'}}, {'LEADERBOARD': {'Task': 'Open-Domain Question Answering', 'Dataset': 'Quasar', 'Metric': 'F1 (Quasar-T)', 'Score': '28.5'}}]
