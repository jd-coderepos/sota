[{'LEADERBOARD': {'Task': 'Multiple Object Tracking', 'Dataset': 'BDD100K val', 'Metric': 'mMOTA', 'Score': '44.2'}}, {'LEADERBOARD': {'Task': 'Multiple Object Tracking', 'Dataset': 'BDD100K val', 'Metric': 'mIDF1', 'Score': '56.7'}}, {'LEADERBOARD': {'Task': 'Visual Tracking', 'Dataset': 'TNL2K', 'Metric': 'precision', 'Score': '62.8'}}, {'LEADERBOARD': {'Task': 'Visual Tracking', 'Dataset': 'TNL2K', 'Metric': 'AUC', 'Score': '59.3'}}, {'LEADERBOARD': {'Task': 'Visual Object Tracking', 'Dataset': 'LaSOT-ext', 'Metric': 'AUC', 'Score': '56.2'}}, {'LEADERBOARD': {'Task': 'Visual Object Tracking', 'Dataset': 'LaSOT-ext', 'Metric': 'Normalized Precision', 'Score': '63.8'}}, {'LEADERBOARD': {'Task': 'Visual Object Tracking', 'Dataset': 'LaSOT-ext', 'Metric': 'Precision', 'Score': '63.8'}}, {'LEADERBOARD': {'Task': 'Visual Object Tracking', 'Dataset': 'TrackingNet', 'Metric': 'Precision', 'Score': '86.4'}}, {'LEADERBOARD': {'Task': 'Visual Object Tracking', 'Dataset': 'TrackingNet', 'Metric': 'Normalized Precision', 'Score': '89.0'}}, {'LEADERBOARD': {'Task': 'Visual Object Tracking', 'Dataset': 'TrackingNet', 'Metric': 'Accuracy', 'Score': '85.4'}}, {'LEADERBOARD': {'Task': 'Visual Object Tracking', 'Dataset': 'LaSOT', 'Metric': 'AUC', 'Score': '72.4'}}, {'LEADERBOARD': {'Task': 'Visual Object Tracking', 'Dataset': 'LaSOT', 'Metric': 'Normalized Precision', 'Score': '80.7'}}, {'LEADERBOARD': {'Task': 'Visual Object Tracking', 'Dataset': 'LaSOT', 'Metric': 'Precision', 'Score': '78.9'}}, {'LEADERBOARD': {'Task': 'Visual Object Tracking', 'Dataset': 'LaSOT', 'Metric': 'AUC', 'Score': '72.2'}}, {'LEADERBOARD': {'Task': 'Visual Object Tracking', 'Dataset': 'LaSOT', 'Metric': 'Normalized Precision', 'Score': '80.8'}}, {'LEADERBOARD': {'Task': 'Visual Object Tracking', 'Dataset': 'LaSOT', 'Metric': 'Precision', 'Score': '79.4'}}, {'LEADERBOARD': {'Task': 'Object Detection', 'Dataset': 'COCO minival', 'Metric': 'box AP', 'Score': '60.6'}}, {'LEADERBOARD': {'Task': 'Object Detection', 'Dataset': 'COCO minival', 'Metric': 'AP50', 'Score': '77.5'}}, {'LEADERBOARD': {'Task': 'Object Detection', 'Dataset': 'COCO minival', 'Metric': 'AP75', 'Score': '66.7'}}, {'LEADERBOARD': {'Task': 'Object Detection', 'Dataset': 'COCO minival', 'Metric': 'APS', 'Score': '45.1'}}, {'LEADERBOARD': {'Task': 'Object Detection', 'Dataset': 'COCO minival', 'Metric': 'APM', 'Score': '64.8'}}, {'LEADERBOARD': {'Task': 'Object Detection', 'Dataset': 'COCO minival', 'Metric': 'APL', 'Score': '75.3'}}, {'LEADERBOARD': {'Task': 'Described Object Detection', 'Dataset': 'Description Detection Dataset', 'Metric': 'Intra-scenario FULL mAP', 'Score': '17.9'}}, {'LEADERBOARD': {'Task': 'Described Object Detection', 'Dataset': 'Description Detection Dataset', 'Metric': 'Intra-scenario PRES mAP', 'Score': '18.6'}}, {'LEADERBOARD': {'Task': 'Described Object Detection', 'Dataset': 'Description Detection Dataset', 'Metric': 'Intra-scenario ABS mAP', 'Score': '15.9'}}, {'LEADERBOARD': {'Task': 'Instance Segmentation', 'Dataset': 'COCO test-dev', 'Metric': 'mask AP', 'Score': '51.8'}}, {'LEADERBOARD': {'Task': 'Instance Segmentation', 'Dataset': 'COCO test-dev', 'Metric': 'AP50', 'Score': '76.2'}}, {'LEADERBOARD': {'Task': 'Instance Segmentation', 'Dataset': 'COCO test-dev', 'Metric': 'AP75', 'Score': '56.7'}}, {'LEADERBOARD': {'Task': 'Instance Segmentation', 'Dataset': 'COCO test-dev', 'Metric': 'APS', 'Score': '33.3'}}, {'LEADERBOARD': {'Task': 'Instance Segmentation', 'Dataset': 'COCO test-dev', 'Metric': 'APM', 'Score': '55.9'}}, {'LEADERBOARD': {'Task': 'Instance Segmentation', 'Dataset': 'COCO test-dev', 'Metric': 'APL', 'Score': '67.5'}}, {'LEADERBOARD': {'Task': 'Referring Expression Segmentation', 'Dataset': 'Refer-YouTube-VOS (2021 public validation)', 'Metric': 'J&F', 'Score': '70.1'}}, {'LEADERBOARD': {'Task': 'Referring Expression Segmentation', 'Dataset': 'Refer-YouTube-VOS (2021 public validation)', 'Metric': 'J', 'Score': '67.6'}}, {'LEADERBOARD': {'Task': 'Referring Expression Segmentation', 'Dataset': 'Refer-YouTube-VOS (2021 public validation)', 'Metric': 'F', 'Score': '72.7'}}, {'LEADERBOARD': {'Task': 'Referring Expression Segmentation', 'Dataset': 'RefCOCO+ val', 'Metric': 'Overall IoU', 'Score': '72.47'}}, {'LEADERBOARD': {'Task': 'Referring Expression Segmentation', 'Dataset': 'RefCOCO+ test B', 'Metric': 'Overall IoU', 'Score': '66.22'}}, {'LEADERBOARD': {'Task': 'Referring Expression Segmentation', 'Dataset': 'DAVIS 2017 (val)', 'Metric': 'J&F 1st frame', 'Score': '72.5'}}, {'LEADERBOARD': {'Task': 'Referring Expression Segmentation', 'Dataset': 'RefCOCO+ testA', 'Metric': 'Overall IoU', 'Score': '76.42'}}, {'LEADERBOARD': {'Task': 'Zero Shot Segmentation', 'Dataset': 'Segmentation in the Wild', 'Metric': 'Mean AP', 'Score': '42.1'}}, {'LEADERBOARD': {'Task': 'Video Instance Segmentation', 'Dataset': 'YouTube-VIS validation', 'Metric': 'mask AP', 'Score': '66.9'}}, {'LEADERBOARD': {'Task': 'Video Instance Segmentation', 'Dataset': 'YouTube-VIS validation', 'Metric': 'AP50', 'Score': '87.5'}}, {'LEADERBOARD': {'Task': 'Video Instance Segmentation', 'Dataset': 'YouTube-VIS validation', 'Metric': 'AP75', 'Score': '75.1'}}, {'LEADERBOARD': {'Task': 'Video Instance Segmentation', 'Dataset': 'OVIS validation', 'Metric': 'mask AP', 'Score': '49.0'}}, {'LEADERBOARD': {'Task': 'Video Instance Segmentation', 'Dataset': 'OVIS validation', 'Metric': 'AP50', 'Score': '72.5'}}, {'LEADERBOARD': {'Task': 'Video Instance Segmentation', 'Dataset': 'OVIS validation', 'Metric': 'AP75', 'Score': '52.2'}}, {'LEADERBOARD': {'Task': 'Video Instance Segmentation', 'Dataset': 'OVIS validation', 'Metric': 'mask AP', 'Score': '34.0'}}, {'LEADERBOARD': {'Task': 'Video Instance Segmentation', 'Dataset': 'OVIS validation', 'Metric': 'AP50', 'Score': '55.5'}}, {'LEADERBOARD': {'Task': 'Video Instance Segmentation', 'Dataset': 'OVIS validation', 'Metric': 'AP75', 'Score': '35.6'}}, {'LEADERBOARD': {'Task': 'Multi-Object Tracking and Segmentation', 'Dataset': 'BDD100K val', 'Metric': 'mMOTSA', 'Score': '35.7'}}, {'LEADERBOARD': {'Task': 'Generalized Referring Expression Comprehension', 'Dataset': 'gRefCOCO', 'Metric': 'Precision@(F1=1, IoUâ‰¥0.5)', 'Score': '58.2'}}, {'LEADERBOARD': {'Task': 'Generalized Referring Expression Comprehension', 'Dataset': 'gRefCOCO', 'Metric': 'N-acc.', 'Score': '50.6'}}]
