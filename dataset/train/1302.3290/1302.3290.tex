\documentclass[submission,copyright,creativecommons]{eptcs}
\providecommand{\event}{Infinity 2012}

\usepackage{times}
\usepackage[cmex10]{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{array}
\usepackage{latexsym}
\usepackage{verbatim}
\usepackage[english]{babel}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{moreverb}
\usepackage{times}
\usepackage{epic,eepic}
\usepackage{subfigure}
\usepackage{float}
\usepackage[all,2cell,ps]{xy}
\usepackage{psfrag}
\usepackage{multirow}

\newcommand{\edge}[1]{\ar@{-}[#1]}
\newcommand{\node}{*+[o][F-]{ }}

\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{example}{Example}
\newtheorem{proof}{Proof}
\newtheorem{property}{Property}








\newcommand{\M}{\mathcal{M}}







\newcommand{\Def}{\overset{\operatorname{def}}{=}}
\newcommand{\parties}[1]{\mathcal{P}(#1)}
\newcommand{\ua}{\uparrow}
\newcommand{\store}{store}
\newcommand{\da}{\downarrow}
\newcommand{\FD}{\hspace{+.1em}}
\newcommand{\CLPFD}{CLP\hspace{+.1em}}

\newcommand{\Z}{Z\hspace{-.6em}Z}
\newcommand{\R}{I\hspace{-.2em}R}
\newcommand{\bbm}{\begin{bmatrix}}
\newcommand{\ebm}{\end{bmatrix}}
\newcommand{\dd}{\ensuremath{\mathcal{D}}}
\newcommand{\ch}{\ensuremath{\textrm{conv\_hull}}}
\newcommand{\is}{\ensuremath{\textrm{int\_sol}}}
\newcommand{\sh}[1]{\ensuremath{#1^\sharp}}
\newcommand{\lfp}{\ensuremath{\textrm{lfp}}}
\newcommand{\gfp}{\ensuremath{\textrm{gfp}}}
\newcommand{\treillisc}{\ensuremath{
(\mathcal{D}, \sqsubseteq, \bigsqcup, \bigsqcap)}}
\newcommand{\treilliscv}{\ensuremath{
(\mathcal{D_V}, \subseteq, \bigcup, \bigcap)}}
\newcommand{\treillisa}{\ensuremath{(\sh{\mathcal{D}}, \sh{\sqsubseteq},
  \sh{\bigsqcup}, \sh{\bigsqcap})}}

\newcommand{\infp}{\ensuremath{\sh{\sqsubseteq}_{poly}}}




\hyphenation{ele-ment state-ment respect how-ever auto-matic theo-retic al-go-rithms pro-grams com-put-ations cond-itions diffi-cul-ties func-tions stands cons-traints sym-bo-lic account criteria exists paths verdict}

\title{Constraint-based reachability}
\author{Arnaud Gotlieb
\institute{Certus Software V\&V Center\\
SIMULA Research Laboratory\\
Lysaker, Norway}
\email{\quad arnaud@simula.no}
\and
Tristan Denmat
\institute{INRIA Rennes Bretagne-Atlantique\\
Rennes, France}
\email{\quad Tristan.Denmat@inria.fr}
\and
Nadjib Lazaar
\institute{LIRMM\\
Montpellier, France}
\email{\quad lazaar@lirmm.fr}
}
\def\titlerunning{Constraint-based reachability}
\def\authorrunning{A. Gotlieb, T. Denmat, N. Lazaar}

\begin{document}
\maketitle

\begin{abstract}
Iterative imperative programs can be considered as infinite-state systems computing over possibly unbounded domains. Studying reachability in these systems is challenging as it requires to deal with an infinite number of states with standard backward or forward exploration strategies. An approach that we call {\it Constraint-based reachability}, is proposed to address reachability problems by exploring program states using a constraint model of the whole program. The keypoint of the approach is to interpret imperative constructions such as conditionals, loops, array and memory manipulations with the fundamental notion of {\it constraint} over a computational domain. By combining constraint filtering and abstraction techniques, {\it Constraint-based reachability} is able to solve reachability problems which are usually outside the scope of backward or forward exploration strategies. This paper proposes an interpretation of classical filtering consistencies used in Constraint Programming as abstract domain computations, and shows how this approach can be used to produce a constraint solver that efficiently generates solutions for reachability problems that are unsolvable by other approaches.
\end{abstract}


\section{Introduction}
Modern automated program verification can be seen as the convergence of three distinct approaches, namely Software Testing, Model-Checking and Program Proving. Even if the general verification problems are often undecidable, investigations on these approaches have delivered the most efficient automated techniques to show that a given property is satisifed or not by all the reachable states of an infinite-state system. 

Several authors have advocated the usage of {\it constraints} to represent an infinite set of states and the usage of constraint solvers to efficiently address reachability problems \cite{Car96,DP01,Fla04,BCE08}. In automated program verification problems, the goal is to find a state of the program which violates a given safety property, i.e., an {\it unsafe state}. Two distinct strategies have been investigated to explore programs with constraints, namely the forward analysis and the backward analysis strategies. In forward analysis, a set of reachable states is explored by computing the transition from the initial states of a program to the next states in forward way. If an unsafe state is detected to belong to the set of reachable states during this exploration then a property violation is reported. In backward analysis, states are computed from an hypotetical unsafe state in a backward way with the hope to discover that one of those is actually an initial state. One advantage of backward analysis over forward analysis is its usage of the targeted unsafe state to refine the state search space.  
However, both strategies are quite powerful and have been implemented into several software model checkers based on constraint solving \cite{HJM03,Fla04} and automated test case generators \cite{WMM05,GKS05,FW07,CG10,BH11}.
 
In this paper, we present an integrated constraint-based strategy that can benefit from the strengths of both forward and backward analysis. The keypoint of the approach, that we have called {\it Constraint-Based Reachability (CBR)}, is to interpret imperative constructions such as conditionals, loops, array and memory manipulations with the fundamental notion of {\it constraint} over a computational domain. By combining constraint filtering and abstraction techniques, CBR is able to solve reachability problems which are usually outside the scope of backward or forward exploration strategies. A main difference is that CBR does not sequentially explore the execution paths of the program~; the exploration is driven by the constraint solver which picks-up the constraint to explore depending on the priorities that are attached to them. It is worth noticing that applying CBR to program exploration results in a semi-correct procedure only, meaning that there is no termination guarantee. CBR has been mainly applied in automatic test data generation for iterative programs \cite{GBR98,GBR00}, programs that manipulate pointers towards named locations of the memory \cite{GDB05b,GDB07}, programs on dynamic data structures and anonymous locations \cite{CBG09}, programs containing floating-point computations \cite{BGM06}. A major improvement of the approach was brought by the usage of Abstract Interpretation techniques to enrich the filtering capabilities of the constraints used to represent conditionals and loops \cite{DGD07a,DGD07b}. This approach permitted us to build efficient test data generator tools for a subset of C \cite{Got09} and Java Bytecode \cite{CG10}.

The first contribution of this paper is the interpretation of classical filtering consistencies notions in terms of 
abstract domain computations. Constraint filtering is the main approach behind the processing of constraints in a finite domains constraint solver. We show in general the existence of tight links between classical filtering techniques and abstract domain computations that were not pointed out elsewhere. We also give the definition of a new consistency filtering inspired from the Polyhedral abstract domain, as consequence of these links. 

The second contribution is the description of a special constraint handling any iterative construction. The constraint {\it w} captures iterative reasoning in a constraint solver and as such, is able to deduce information which is outside the scope of any pure forward or backward abstract analyzer. Its filtering capabilities combines both constraint reasoning and abstract domain computations in order to propagate informations to the rest of the constraint system. In this paper, we focus on the theoretical foundations of the constraints, while giving examples of its usage for test case generation over iterative programs.


{\bf Outline of the paper.}
The rest of the paper is organized as follows. Sec.2 introduces the necessary background in Abstract Interpretation to understand the contributions of the paper. Sec.3 establishes the link between classical constraint filtering and abstract domain computations. Sec.4 describes the theoretical foundation of the {\it w} constraint for handling iterative constructions while Sec.5 concludes the paper.

\section{Background}


Abstract Interpretation (AI) is a theoretical framework introduced by Cousot and Cousot in \cite{CC77} to manipulate
abstractions of program states. An abstraction can be used to simplify program analysis problems otherwise not
computable in realistic time, to manageable problems more easily solvable.
Instead of working on the concrete semantics of a 
program\footnote{Program semantics captures formally all the possible behaviours of a program.}, 
AI computes results over an abstract semantics 
allowing so to produce over-approximating properties of the concrete semantics.
In the following we introduce the basic notions required to understand AI. 

\begin{definition}[Partially ordered set (poset)]
  Let  be a partial order law, then
  the pair  is called a {\it poset} iff

\end{definition}

\begin{definition}[Complete lattice]
  A complete lattice is a 4-tuple  such that
\begin{itemize}
\item  is a poset 
\item  is a upper bound: , we have
  
\item    is a lower bound: , we have
  
\end{itemize}
\end{definition}
\noindent 
Complete lattices have a single smallest element  
and a single greatest element . 
Program semantics can usually be expressed as the least fix point of a monotonic and continuous function.
A function  from a complete lattice  to itself is monotonic iff 
.
It is continuous iff
 and 
. 

\noindent
The following Theorem guarantees the existence
of the fix points of a monotonic function.
\begin{theorem}[Knaster-Tarski]
  In a complete lattice , for all monotonic functions\\ 
, 
\begin{itemize}
\item the least fix point of  (i.e., ) exists and 
\item the greatest fix point of  (i.e., ) exists and 
\end{itemize}
\end{theorem}
\noindent
In addition, when the functions are continuous, these fix points can be computed using an algorithm derived from the
following theorem:
\begin{theorem}[Kleene]\label{theo:limites}
  In a complete lattice , for all monotonic and continuous functions 
  , the least fix point of
   is equal to  and the greatest fix point
  of  is equal to 
\end{theorem}
\noindent
As  is an increasing suite, we get
.
Hence, 
and .

\noindent
For reaching the least fix point of a monotonic and continuous function in a complete lattice, it
suffices to iterate  from  until a fix point is reached.

\noindent
Let  be a complete lattice called the {\it concrete lattice} 
and  a function that defines some concrete semantics over this lattice, let
 be a poset called the {\it abstract poset}, and
 be a continuous function,
then {\it Abstract Interpretation} aims at computing a fix point of  in order to
over-approximate the computation performed by . 

\noindent
Depending on whether the abstract poset is a complete lattice or not,
we have distinct theoretical results regarding the abstraction. Proofs of
the following theorems can be found in~\cite{CH78}.

\paragraph{Galois connection}
When the abstract poset is a complete lattice, the notion of {\it Galois connection} is available
to link the abstract computations with the concrete lattice. 

\begin{definition}[Galois connection]
Let   
and  be two complete lattices,
then a pair of functions
 and
 is a {\it Galois connection} iff

noted:
\begin{center}

\end{center}
\end{definition}
\noindent
Next definition establishes the correction property of an analysis.
\begin{definition}[Sound approximation]\label{correct-app}
Let 
 be a Galois connection, then a function

is a {\it sound approximation} of  iff

\end{definition}
\noindent
Consquently, we have the following notion:
\begin{theorem} [Smallest sound approximation]
 \label{theo:approx}
Let  be a Galois connection,
and a function , then the {\it smallest sound approximation} of 
is 
\end{theorem}
\noindent
This theorem implies that any function greater than
 is a sound approximation of  and
the following theorem characterizes the results of fixpoint computations:
\begin{theorem}[Fixpoint computations with sound approximation]
  Let  be
a Galois connection, let  and  
be two monotonic functions such that  is a sound approximation of , 
then, we have:

\end{theorem}
\noindent
Intuitively, this theorem gives a process to compute an over-approximation by
Abstract Interpretation, as shown in Fig~\ref{fig:algo_ia}.
\begin{figure}
\begin{center}
  \includegraphics[width=10cm,height=7cm]{algo_ia.eps}
\end{center}
\caption{Static approximations of fixed point computations in complete lattices}
\label{fig:algo_ia}
\end{figure}
The left part shows the concrete lattice where the concrete computation of 
is performed starting from initial state . The right part shows the
abstract lattice that is used to over-approximate the computation.
This computation is undertaken in three steps:
\begin{itemize}
\item initial state abstraction;
\item fixpoint computation in the abstract lattice;
\item result concretization.
\end{itemize}
 

\paragraph{Without Galois connection}

When the abstract lattice is not complete, there does not exist necessarily a best
abstraction for all elements of the concrete lattice. The notion of Galois connection is
no more available and the abstract lattice is just linked with the concrete lattice
through a monotonic function .
The definition of sound approximation needs to be adapted:
\begin{definition} [Sound approximation without a Galois connection]
  Let  and
   be two posets, let 
   be a monotonic function and 
   a function, then the function
   is a sound approximation of  iff

\end{definition}
\noindent
In such an (not complete) abstract lattice, nothing guarantees the existence of the least fix point:
 is not necessarily approximated by . However, any fix point of  can be
used:
\begin{theorem}
  Let  be a complete lattice, and  be a poset, let
  ,  and  be three monotonic functions then
if  is a sound approximation of , then we have:

\end{theorem}
\noindent
Next theorem is useful to compute an over-approximation of  when the lattice is not complete:
\begin{theorem}
\label{theo:gfp_incomplet}
  Let  be a complete lattice, let  be a poset with
  a greatest element  and let
  ,  and  be three monotonic functions, then
  \\
  if  is a sound approximation of  and  is an
  element of  such that there exists  such as , then

\end{theorem}
\noindent
Consequently, when the abstract lattice is not complete, instead of
abstracting the initial state, one selects
an element of the abstract lattice that over-approximates the initial state.
And, a fix point is computed in the abstract lattice from this element.
The fix point is still an over-approximation of the concrete semantics.

\subsection{Examples of abstract domains}
\label{sec:ia:exemples}

In this section, we briefly describe two abstract domains:
the Interval \cite{CC76} and the Polyhedral \cite{CH78} domains. 

\subsubsection{The Interval abstract domain}
\label{intervals}
Interval analysis aims at approximating a set of values by an interval of possible values.
If , then the Interval abstract domain is the Cartesian product 
 equipped with
inclusion, union and intersection over intervals. This abstract domain is a complete lattice.

\noindent
State abstraction is performed by computing an interval that over-approximates the set of possible
values for each variable. If the concrete state is an unbounded set of tuples
 then:

The concretization of an abstract state is obtained by computing the Cartesian product of the intervals.
These functions define a Galois connection between the concrete domain and the abstract domain of intervals.

\noindent
The approximation of transfert functions is realized by using their structure and classical results from Interval Analysis \cite{Moo66}.
For example, functions  and  are abstracted by the following (sound) approximations:
 and 
.    

\subsubsection{The Polyhedral abstract domain}
\label{polyhedra}

In Polyhedral analyses, each concrete state is abstracted by a conjunction of linear
constraints that defines a convex polyhedron. Indeed, a {\it convex polyhedron} is a region of an
n-dimensional space that is bounded by a finite set of hyperplanes  where  and .
 The abstract lattice equiped with
inclusion, convex hull\footnote{The union of two polyhedra is not a polyhedron, this is the reason why convex hull or any relaxation of it
must be employed.}, and intersection of polyhedra is not a complete lattice as there is no 
upper bound to the convex union of all the convex polyhedra that can be written in a circle.    

\noindent
Abstract functions can be defined to deal with polyhedra. For example:

\noindent 
If the expression is a linear condition, then it is just added to the polyhedron (case~\ref{eq:poly_1}). 
If the expression is contradictory with the current polyhedron, then it is reduced to  meaning that
there is no abstract (and concrete) state in the approximation (case~\ref{eq:poly_2}). 
If the expression is non-linear, then a linear approximation is derived when available
and added to the polyhedron (case~\ref{eq:poly_3}). 


\section{Filtering consistencies as abstract domain computations}
\label{sec:absdom-cons}
As noticed by Apt \cite{Apt99a}, constraint propagation algorithms can be seen as
instances of algorithms that deal with chaotic iteration. In this context, chaotic means fair application of
propagators until saturation. In this section, we elaborate on a bridge between two
unrelated notions: filtering consistencies and abstract domains. In particular, we show that arc-- and 
bound-- consistency are instances of chaotic iterations over two distinct 
abstract domains. Classical AI notions of sound approximation and abstract domain
computations, not used in \cite{Apt99a}, allows to show that filtering consistencies compute sound 
over-approximations of the solutions set of a constraint system. Thanks to the bridge, we also propose new filtering
consistency algorithms based on the polyhedral abstract domain. 

\subsection{Notations}
Let  be the set of integers and  be a finite set of integer variables, where each variable  in  is
associated with a finite domain . The {\it domain} 
 is the Cartesian product of each variable domain:~ and
 denotes the powerset of .  and  denote
respectivelly the inferior and the superior bounds of  in .
A constraint  is
a relation between variables of . The language of (elementary) constraints is built over arithmetical
operators  and relational operators  but any relation over a subset
of  can be considered. Let {\it vars} be the function that returns the variables of  
appearing in a constraint . A {\it valuation} 
is a mapping of variables to values, noted .  denotes a constraint system , i.e., 
a finite set of constraints.

\subsection{Exact filtering}

Let  be a  over  and let , then
the solution-set of  is an element of , noted .

\noindent
The {\it exact filtering operator} of a constraint  is computed with the function
 which maps an element  to 
.
The exact filtering operator of  removes {\it all} the tuples of  that violate .
Hence, by using an iterating procedure, it permits to compute :
if  then .
By noticing that  is continuous (as each  is continuous) and monotonic and thanks to Theorem~\ref{theo:limites} 
we get . 
\begin{example}
Consider  where . The exact
filtering operator associated with  will remove the tuples  from 
. Iterating over all the constraints of  will eventually exhibit the inconsistency of this example.
\end{example}
\noindent
In fact, this shows that exact filtering of a CS over  
can be reached if one computes over a complete lattice built over the set of possible valuations: 
. 
This lattice will be called the {\it concrete lattice} in the rest of the paper.
Of course, computing over the concrete lattice is usually unreasonable, as it requires to examine every tuple of the Cartesian product 
 w.r.t. consistency of each constraint.
 
\subsection{Domain-consistency filtering}

For binary constraint systems, the most successful local consistency filtering is arc-consistency, 
which ensures that every value in the domain of one variable has a support in the domain of the other variable.
The standard extension of arc-consistency for constraints of more than two variables is domain-consistency (also called
hyper-arc consistency \cite{MS98}).
Roughly speaking, the abstraction that underpins domain-consistency filtering aims at considering
each variable domain separately, instead of considering the Cartesian product of each individual domain. More
formally,
\begin{definition}[Domain-consistency]
A domain  is domain-consistent for a constraint  where  
iff for each variable ,  and for each 
there exist integers  with , 
such that  is an integer solution of .
\end{definition} 
\noindent
Consider the domains  and  
 and
the abstraction function  which maps  to


\noindent
The concretization function is a function  such that

\noindent
If ,  and   denote respectivelly the
inclusion, union and intersection of two tuples of sets, then we got the following Galois connection:
\begin{center}

\end{center}
\noindent
The proof follows comes the monotonicity of the projection and Cartesian product.
From Theorem~\ref{theo:approx}, we get:
\begin{definition}
The best sound approximation of the exact filtering operator  is 

\end{definition}

\begin{theorem}
\label{theo:arc}
  Let  be a filtering operator associated with constraint , then  computes domain-consistency iff
  . 
\end{theorem}
\noindent
This theorem implies that domain-consistency is the strongest property that can be guaranteed by a filtering 
operator using the abstraction . A proof is given in the Appendix of the paper.

\noindent
Let us consider now the function  such that 
.
As  is a sound approximation of  then


\noindent
This result shows if necessary that constraint propagation over domain-consistency filtering 
operators computes an over-approximation of the solution set of .


\subsection{Bound-consistency filtering}
\label{sec:bornes}

Following the same scheme, AI can be used to show the abstraction that underpins
constraint propagation with bound-consistency filtering (also called interval-consistency). But, firstly, let
us recall the definition of bound-consistency we consider in this paper, as several definitions exist in the 
literature \cite{CHL06}~:
\begin{definition}[Bound-consistency]
A domain  is bound-consistent for a constraint  where  
iff for each variable ,  and for each 
there exist integers  with , 
such that  is an integer solution of .
\end{definition}
\noindent 
Roughly speaking, this approximation considers only the bounds of the domain of each variable and
approximates each domain with an interval. 
Let  be the smallest interval that contains all the elements of a finite set of integers .
Similarly,  denotes the set of integers of an interval ~: . 

\noindent
The abstract domain we consider for bound-consistency is 
.

\noindent
Given a tuple of sets  and a tuple of intervals
, we consider the functions 
 and  such that:



\noindent
Let  be an abstraction function such that 

and  be a concretization function such that 


\noindent
If ,  and
 respectively denote inclusion, union and
intersection of intervals (component by component) then we get the following Galois connection:

\begin{center}

\end{center}

\noindent
Let  be the most accurate sound approximation of , then we get:



\begin{theorem}
 If  is a filtering operator associated to constraint , then   computes 
 bound-consistency iff . 
\end{theorem}

\noindent
This theorem, proved in Appendix, implies that bound-consistency is the strongest property that can be reached with an operator
based on the  abstraction.

\noindent
Consider now the function  such that
. As
 is a sound approximation of , then

This result shows if necessary that constraint propagation based on bound-consistency computes
a sound over-approximation of the solution set of .
In addition, as  is also a sound over-approximation of , then 

meaning that filtering with bound-consistency provides an over-approximation of the results given by a 
filtering with domain-consistency.
 
\subsection{New filtering consistencies based on abstract domains}
\label{sec:DynaLIB_global}
In the previous section, classical filtering consistencies are interpreted in terms
of abstract domain computations. In this section, we propose a
new filtering consistency based on the Polyhedral abstract domain \cite{CH78}. 

\subsubsection{Linear relaxations}\label{sec:DLRs}

When non-linear constraints are involved in a constraint store, approximating them 
with linear constraints is natural in order to benefit from powerful Linear
Programming techniques. These techniques can be used to check the satisfiability 
of the constraint store when the approximation is sound. If the approximate constraint 
system is unsatisfiable so is the non-linear constraint system. But, in the context
of optimization problems, the approximation
can also be used to prune current bounds of the function to optimize. 

Another form of approximation comes from the domain in which the computation occurs.
A linear problem over integers can be relaxed in the domain of rationals or reals 
and solved within this domain. As the set of integers belongs to the rationals and reals,
an integer solution of the relaxed problem is also a solution of the original integer problem,
but the converse is false. In this paper, we will consider both kinds of approximations 
under the generic term of ``linear relaxations''.

Computing a linear relaxation of a constraint system  aims at finding a set of
linear constraints that characterizes an over-approximation of the solution set of
. It is not unique but for trivial reasons, we are more interested in the tighter 
possible relaxations. The tightest linear relaxation is the convex hull of the solution set
of  but computing this relaxation is as hard as solving . For  over finite domains,
the problem is therefore NP\_hard. 
Whenever a relaxation is computed by using the current bounds 
of variable domains, it is called {\it dynamic} and the consistencies presented in the rest
of the section are compatible with dynamic linear relaxations.

\subsubsection{Polyhedral-consistency filtering}

Let  be the abstract domain of closed convex polyhedra with rational coefficients.
As said previously,  is not a complete lattice, and then we cannot define
a Galois connection between  and the lattice of the solutions.
Nevertheless, the concretization function  
 can be defined as the function that
returns the integer points of a given polyhedron:

Here,   stands for the whole set of integer solutions of a set of linear constraints
As  is bounded,  is finite.

Without a Galois connection, we do not expect the polyhedral-consistency
proposed in this section to be optimal w.r.t. the abstract domain.
Hence, we only show that the filtering algorithm that computes this
consistency is a sound approximation of the exact filtering operator.

\begin{definition}
Let  be the following abstraction function\\

such that

and the concretization function :

\end{definition}
\noindent
where  (resp. ) stands for the next smallest (resp. largest) integer of ,
and  ( resp. ) computes the smallest (resp. largest) value of  corresponding to a point of .

\noindent
Both  and  link the polyhedral abstract domain with the interval abstract domain.
The abstraction function  maps a set of intervals into a polyhedron by adding two inequalities per variable, while
the concretization function  maps a polyhedron into a set of intervals by computing first the smallest hypercuboid 
containing the polyhedron and second the greatest hypercuboid with integer bounds.
The behaviour of these two functions is illustrated in Fig. \ref{fig:galois_box}.


\begin{figure} 
  \psfrag{alphabox}{}
  \psfrag{gammabox}{}
  \begin{center} 
   \includegraphics[width=11cm,height=5cm]{galois_box2.eps} 
  \end{center} 
  \caption{Connection between the Polyhedral and Interval abstract domains} 
  \label{fig:galois_box} 
\end{figure} 


\begin{definition}[Polyhedral-consistency]
A domain  is polyhedral-consistent for a constraint  where  
iff for each variable ,  and for each 
there exist rationals  with , 
such that  is a (rational) solution of a linear relaxation of .
\end{definition} 
\noindent
The rationale behind this definition is to benefit from efficient polyhedral techniques over the rationals to filter 
the variation domain of variables. Of course, interesting implementations of this filtering consistency should trade 
between efficiency and precision as integer linear constraint solving is costly (NP\_hard problem) even for bounded domains.  
It is worth noticing that the definition depends on the quality of the underlying linear relaxation. On the one hand, a
linear relaxation which over-approximate  by  (the whole search space) is useless while on the other hand 
a linear relaxation which exploits piecewise over-approximations of  is often too costly. 
We give examples of polyhedral-consistency filtering in function of various linear relaxations.

\begin{example}
Consider the following : , let  be the second constraint of : 
and let  be .

\noindent
Note that  is bound-consistent for all the constraints of .

\noindent
The simplest linear relaxation that can be considered is the one that ignores non-linear constraints.
In this example,  is over-approximated by   and then  viewed as  
 is then
polyhedral-consistant w.r.t. this linear relaxation. Note that this approach can be generalized by
associating a new fresh variable to the non-linear term  with a domain computed using the
bounds  and . In this example, this does not help but it could help on other examples.

\noindent
Another linear relaxation consists in building a polyhedron from the ``bounds'' of 
in . By considering the 2-dimensional 
polyhedron\\ 
 we get that a linear relaxation of  in
domain  is\\ 
\\
\\
\\
\\  
Filtering with the polyhedral-consistency, we get that
 where  and  have been pruned.
These results can be easily computed using a Linear Programming tool and truncation operators. For example,
using the clpq library of SICStus Prolog which implements
a simplex over the rationals, the following request permits to compute the max bound of variable :
\begin{verbatim} 
{X >= -7, X =< 10, Y >= -7, Y =< 10, Z >= 3, Z =< 10, Z = X+Y, 
11*X - 8*Y+ 69 >=0, -X - Y + 11 >= 0, -8*X + 11*Y +69 >= 0, 
X + Y + 8 >=0}, sup(X, R).

R = 179/19   \end{verbatim}

Finally, we can automate the computation of linear relaxations of 
by considering the following trivial constraints, which are always true for
any  and :
\\
\\
\\
\\

\noindent
By decomposing these constraints, using the original bounds of  and 
replacing the quadratic term  by , we get:\\
\\ 
\\
\\
\\
Filtering with the polyhedral-consistency, we get that
 where  and  have been pruned.
These domains are still bound-consistent but 
another tighter relaxation can be computed with these new bounds:\\
\\
\\
\\
\\
and then filtering again permits to get that
.
Here, filtering by bound-consistency leads to prune the domains to:
.
Then, by iterating these two process, we get the only solution to  which is:
.
This showed how dynamic linear relaxations can be used to solve a non-linear .
\end{example}

\section{The \textit{w} constraint operator}

In this section, we present the {\it w} constraint operator which captures iterative computations, and how it is processed by a constraint solver. 
The constraint operator has been introduced a long time ago in \cite{GBR98,GBR00} and was further refined using Abstract Interpretation (AI) techniques \cite{DGD07a}. In the following, we recall its interface and semantics and show how fixed point computations can be used to filter 
inconsistant values of the underlying relation. We also explain
how the Polyhedral abstract domain is used to approximate the fixed point computations.

\subsection{\textit{w} as a relation over memory states}
The  operator captures a relation over three memory states that represent the state before, within and after the execution of an iterating statement.
In this paper, we do not specify what a memory state is, or what the iterating statement is, as the approach is generic regarding the content of a memory state and the concrete syntax of the iterator. However, in order to ease the understanding, the reader can consider a memory state to be a mapping between variables of the program to values. More complex examples of memory states in relation with  can be found in \cite{CBG09} and \cite{CG10}.

\noindent
The relation {\it w} is expressed with the following syntax:
 where  denotes the memory state before execution of the iteration,  denotes the memory state reached at the end of execution of the , while  denotes the state after execution,  is a boolean syntactical expression, and  is a list of statements. This three-states consideration is inspired by the Static Single Assignment of a program \cite{WZ91}. If the state of  is irrelevant for a given computation, we simply write . Note that  may also contain other iterators, and thus  is meant to be a compositional operator. The semantics of  is the semantics of an iterating statement (i.e., repetitive application of  over an input state, while  is true).

\noindent
We note  where  is the application composition.

\subsection{Background on }
As described in \cite{GBR00},
the operational semantics of  within a constraint solver is expressed as a set of guarded-constraints: . If  is entailed by the constraint store then  is added to it, and the relation  is solved. If  is disentailed, then the guarded-constraint is discarded and no more considered in further analysis. Finally, if none of these (dis-) entailment deductions is possible, the guarded-constraint just suspends in the constraint store. The set of guarded-constraints is considered each time the constraint  awakes in the constraint store, so that it captures the essence of the iteration through rewriting in recursive calls. In addition, substitution of variables must be considered to faithfully represent the constraints in a  relation.  simply denotes the constraint  where program variables from  have been substituted by the variables from . With these notations, the  relation is expressed as follows:\\
\\ \\
\\
\\
\noindent
The two former guarded-constraints implement forward analysis, by examining the entailment of . Depending on the entailment of , a recursive call to a new  is added to the constraint store. The two followings implement backward reasoning by examining the differences between the stores after and before execution of the iteration. Finally,  the last operation, called , is the most tricky one and implements union of stores in case of suspension of the operator. This  operation is realized iff none of the previous guarded-constraints has been solved.
The rest of the Section is devoted to the presentation of this operator, which is implemented as an abstract operation over abstract domains. 


\subsection{Concrete fixed point computation}
For a given  operator, let  be the following set:


\noindent
 represents all pairs of memory states that are in relation through the {\it w} statement, but still, not all those pairs can be considered as solutions of the relation, as some pairs can only be reached in temporary states of the execution. For this reason, we introduce the set :

  

\noindent
  where  denotes the set of solutions of a constraint .

\noindent
 can be seen as the {\it least fixed point} of:

and  can be computed by filtering the pairs of the fixed point.

\noindent
For instance, considering  and , and
using the notation  for denotating ,
the fix point computation is as follows: 



\noindent
Consequently, the solutions set  of  is:


\noindent
Computing  is undecidable in general as there is no termination guarantee of the iterating process. This is the reason why this computation is usually abstracted using abstract domain computation.

\subsection{Abstracting the fixed point computation}

Implementing the  operator mentionned above can be done by 
abstracting the computation of the fixed point within the Polyhedral abstract domain.
Let  be a conjunction of linear restraints, the intersection of which defines a convex polyhedron, that over-approximates the set .
Hence, we can compute  as the least fixed point of:

Compared to eq.~\ref{eqn:concrete1} and~\ref{eqn:concrete2}, the
computation is realized in the abstract domain using  the abstraction function of the Polyhedral abstract domain.



\noindent
Let  be the approximation of the set of solutions of \textit{w}, obtained by application of :


\noindent
Looking at the above example where  is just composed of the mapping of , 
it is worth introducing different representations of the stores as we progress in the fixed point computation. 
When  is computed over  and establishes a relation in between stores  and  that contains , we note: . If  is then
considered over , then we will simply write  and apply variable substitution. 

\noindent
With these notations, we have the following computation: 


\noindent
Fig.~\ref{approx} illustrates the difference between the abstract fixed point and the approximate fixed point.
Points in the figure correspond to the elements of , while the grey zone represents the convex polyhedron defined by . 

\begin{figure}
\begin{center}
  \includegraphics[width=3cm,height=3cm]{approx.eps}
\end{center}
\caption{Exact and approximated fixed point}
\label{approx}
\end{figure}

\noindent
An approximation of the solutions of  is given by: 


\noindent
On the Polyhedral domain, convergence of the fixed point computation over  can be enforced by using widening techniques.
The computation of  is modified in order to use a widening operator  \cite{CH78}. Thus, we have: 












\noindent
A concrete algorithm for computing this approximation is given in \cite{DGD07a}, which permits to build implementation of  in a constraint solver. As rooted in the Abstract Interpretation domain, the relation  inherits from some of its fundamental correctness results, i.e., soundness and termination.  However, it is worth pinpointing some differences.

\noindent
Usually, a convex abstract polyhedron denotes the set of linear relations that hold
over variables at a given point of a sequential program under analysis. 
As the goal here is to correctly approximate the set of solutions of a \textit{w} relation, the polyhedron describes
relations between input and output values and, thus, they
involve more variables in the equations. In Abstract Interpretation, the
analysis can be performed only once, whereas, in the case of the  relation, the  operation is launched everytime the relation is awaked without being succesfull in solving one of the guarded-constraint.
As a consequence, we found out that it was not reasonable to use standard libraries to compute over polyhedra, such as PPL~\cite{BRZ02}, 
because they use a {\it dual representation for Polyhedra}, which is a source of exponential time
computations for the conversion.  

\subsection{Illustrative example}

Looking at an iterative computation over unbounded domains as a relation captured by a  constraint operator is 
interesting for adressing Constraint-Based Reacheability problems. On the one hand, the suspension mechanism offered by constraint reasoning allows us 
to cope with the approximation problem, i.e., the set of states that is considered is determined by the informations existing 
in the constraint store, which makes the reasoning more accurate w.r.t. the property to be demonstrated. On the other hand, adding abstract domain 
computations to the  relation allows us to increase the level of deductions that can be achieved at each awakening of the  constraint operator. 
To illustrate this remark, consider the following  program:
\begin{verbatim}
f(  int i, ...  )  {
a.    j = 100;
b.      while( i > 0)
c.        { j=j+1 ; i=i-1 ;}
d.      ... 
e.	if( j > 500)
f.	    ...
\end{verbatim}
\noindent
A typical reachability problem is to find out a value of {\tt i} such that statement {\tt f.} is executed. Existing approaches for solving this reachability problem consider a path passing through {\tt f.}, e.g., {\tt a-b-d-e-f}, and try to solve the {\it path condition} attached to this path. In this case, it means extracting constraint  and solving it to show that the constraint system is unsatisfiable, i.e., the corresponding path is infeasible. Then, these approaches backtrack to select another path (e.g., {\tt a-b-c-b-d-e-f} with path condition 
) and repeat the process again, until a satisfiable path condition is found. This example is pathologic for these approaches, as only the paths that iterate more than  times in the loop will reach statement {\tt f.}. Hopefully, using the constraint operator  permits us to unrool dynamically  times the loop without backtracking. The relational analysis performed on the Polyhedral abstract domain by the  operator determines that  whatever be the number of loop unrollings. Here, combining precise constraint reasoning in the concrete domain, with constraint extrapolation through abstract domain computations, offers us an efficient way of solving reachability problems on infinite-state systems.   






\section{Conclusions}

In this paper, we have presented Constraint-Based Reachability as a process to combine constraint reasoning and abstraction techniques for solving reachability problems in infinite-state systems. The contribution is two-fold: first, we have revisited constraint consistency-filtering techniques by the prism of abstract domain computations~; second, we explained how to introduce abstract domain computation within the  constraint operator reasoning. We have illustrated these notions with several examples in order to ease the understanding of the reader.

This appraoch has been implemented and tested on several problems, including real-world programs \cite{Got09,Got12}. The goal is now to broader the scope of these techniques that combine constraint reasoning and abstraction techniques, to adress fundamental problems such as reachability in infinite-state systems.  


\section*{Acknowledgements}
We are indebted to Bernard Botella and Mireille Ducass\'e for fruitful discussions on earlier versions of this work.

\section*{Appendix}
This appendix contains the proofs of some of the results stated in the paper.
\bigskip

\begin{theorem}
\label{theo:arc}
  Let  be a filtering operator associated with constraint , then  computes domain-consistency iff
  . 
\end{theorem}

\begin{proof}
  () Let . From the definitions of
   and , we get that  is the solution set of constraint ,
  given the initial domains  (we write ).  Hence,  with \\.
  So,  computes domain-consistency.\\
  () Let  be a domain-consistency filtering operator. 
  Suppose that there exists  such that 
   be strictly greater than
  .  Then, there exists at least 
  one  such as . Hence, there exists an
  element  of  that does not belong to any solution of constraint . 
  Hence,  cannot computes domain-consistency which is contradictory with the hypothesis.
  On the other side,  cannot be smaller than
   as it means that the filtering operator removes solutions.
  Hence, if  computes domain-consistency then .
 
\end{proof}

\begin{theorem}
 If  is a filtering operator associated to constraint , then   computes 
 bound-consistency iff . 
\end{theorem}

\begin{proof}
  () From theorem~\ref{theo:arc}, given initial intervals , 
  the domains  are domain-consistent for constraint .
  Applying function  is similar to the process that keeps extremal values of each element of 
  . Hence, the resulting intervals satisfy the 
  bound-consistency property.\\
  () (similar to the proof of theorem~\ref{theo:arc}) 
  If the filtering operator  is greater than , 
  then the computed intervals contain at least one bound that is not part
  of a solution of , violating so the bound-consistency property.
  On the contrary, by supposing that  is smaller than
   then solutions are lost and  is no more a filtering operator.
  Hence, if  is a filtering operator guaranteeing bound-consistency
  then . 
\end{proof}

\bibliographystyle{eptcs}
\bibliography{../../../these,../../../AG_publis}
\end{document}
