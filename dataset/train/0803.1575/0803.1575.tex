\newcommand{\bbQ}{\mathbb{Q}}
\newcommand{\bbR}{\mathbb{R}}
\newcommand{\parts}[1]{\mathcal{P}(#1)}
\newcommand{\sem}[1]{\llbracket #1 \rrbracket}

\newcommand{\eabs}{\epsilon_{\text{abs}}}
\newcommand{\erel}{\epsilon_{\text{rel}}}

\newcommand{\lfp}{\text{lfp~}}

\newcommand{\abstr}[1]{#1^\sharp}

\newcommand{\definedAs}{\stackrel{\text{def}}{=}}

\renewcommand{\topfraction}{1.00}
\renewcommand{\floatpagefraction}{1.00}
\renewcommand{\textfraction}{0.00}
\renewcommand{\dbltopfraction}{1.00}
\renewcommand{\dblfloatpagefraction}{1.00}

\maketitle

\begin{abstract}
We propose a new quantifier elimination algorithm for the theory of linear real arithmetic. This algorithm uses as subroutines satisfiability modulo this theory and polyhedral projection; there are good algorithms and implementations for both of these. The quantifier elimination algorithm presented in the paper is compared, on examples arising from program analysis problems and on random examples, to several other implementations, all of which cannot solve some of the examples that our algorithm solves easily.
\end{abstract}

\sloppy

\section{Introduction}
Consider a logic formula , possibly with quantifiers, whose variables lay within a certain set  and whose atomic predicates are relations over . The models of this formula are assignments of values in  for the free variables of  such that  evaluates to ``true''. \emph{Quantifier elimination} is the act of providing another formula , without quantifiers, such that  and  are \emph{equivalent}, that is, have exactly the same models. For instance,  is equivalent to quantifier-free .

If  has no free variables, then  is a ground (quantifier-free, variable-free) formula. In most practical cases such formulas can be easily decided to be true or false; quantifier elimination thus provides a \emph{decision procedure} for quantified formulas.

In this paper, we only consider relations of the form  where  is a linear affine expression (an arithmetic expression where multiplication is allowed only by a constant factor), interpreted over the real numbers (or, equivalently, over the rationals). We can thus deal with any formula over linear equalities or inequalities. Our algorithm transforms any formula of the form , where  has no quantifiers, into a quantifier-free formula  in disjunctive normal form. Nested quantifiers are dealt with by syntactic induction: in order to eliminate quantifiers from  or , where  may contain quantifiers, one first eliminates quantifiers from~. Universal quantifiers are converted to existential ones (), yet our algorithm generally avoids the combinatorial explosion over negations that hinders some other methods.

Our method can be understood as an improvement over the approach of converting to DNF through ALL-SAT and performing projection; we compared both approaches experimentally (see~\S~\ref{part:benchmarks}). We compared our implementation with commercial and noncommercial quantifier elimination procedures over some examples arising from practical program analysis cases, as well as random problems, and ours was the only one capable of processing them without exhausting memory or time, or failing altogether due to the impossibility of handling large coefficients.

\section{The Algorithm}
We first describe the datatypes on which our algorithm operates, then the off-the-shelf subroutines that it uses, then the algorithm and its correctness proof, then possible alterations.

\subsection{Generalities}
We operate on unquantified formulas built using , , ,  or other logical connectives such as exclusive-or (the exact set of connectives allowed depends on the satisfiability tester being used, see below; in this paper we shall only use ,  and ), and on quantified formulas built with the same connectives and the existential () and universal () quantifiers. It is possible to quantify not only on a single variable but also on a set of variables, represented as a vector . The atoms are linear inequalities, that is, formulas of the form  where  is the \emph{constant coefficient} and  is the coefficient associated with variable~. It is trivially possible to represent equalities or strict inequalities using this formula language.
The \emph{models} of a formula  are assignments  of rational numbers to the free variables of  such that  satisfies  (written ).  is said to be \emph{satisfiable} if a model exists for it. If  has no free variables, then  is said to be \emph{true} if  is satisfiable, \emph{false} otherwise. Two formulas  and  are said to be \emph{equivalent}, noted , if they have the same models. Formula  is said to \emph{imply} formula , noted , if any model of  is a model of .

Consider a quantifier-free formula , whose atomic predicates are linear inequalities, and variables . We wish to obtain a quantifier-free formula  equivalent to . Let us temporarily forget about efficiency in order to convince ourselves quickly that quantifier elimination is possible.  can be put into disjunctive normal form (DNF)  (by recursive application of distributivity), and  is thus equivalent to . Various methods exist for finding a conjunction  equivalent to , among which we can cite Fourier-Motzkin elimination (see~\S~\ref{part:complexity}). We therefore obtain  in DNF. For a universal quantifier, through De Morgan's laws, we obtain a formula in conjunctive normal form (CNF).

Such a naive algorithm suffers from an obvious inefficiency, particularly if applied recursively to formulas with alternating quantifiers. A first and obvious step is to replace DNF conversion through distributivity by modern techniques (model enumeration using satisfiability modulo theory). We show in this paper than one can do better by interleaving the projection and the model numeration processes.

\subsection{Building blocks}
If one has propositional formulas with a large number of variables, one never converts formulas naively from CNF to DNF, but one uses techniques such as propositional satisfiability (SAT) solving. Even though SAT is NP-complete, there now exist algorithms and implementations that can deal efficiently with many large problems arising from program verification. In our case, we apply SAT modulo the theory of linear real inequalities (SMT), a problem for which there also exist algorithms, implementations, standard benchmarks and even a competition. Like SAT, SAT modulo linear inequalities is NP-complete. A SMT solver takes as an input a formula  where the literals are linear equalities or inequalities, and answers either ``not satisfiable'', or a model of~, assigning a rational number to each variable in~. We assume we have such an algorithm \textsc{Smt} at our disposal as a building block

Another needed building block is quantifier elimination over conjunctions, named : given a conjunction  of linear inequalities over variables , obtain a conjunction  equivalent to . For efficiency reasons, it is better if  is minimal (no conjunct can be removed without adding more models), or at least ``small''. Fourier-Motzkin elimination is a simple algorithm, yet, when it eliminates a single variable, the output conjunction can have a quadratic number of conjuncts compared to the input conjunction, thus a pass of simplification is needed for practical efficiency; various algorithms have been proposed in that respect~\cite{imbert93fouriers}.
For our implementations, we used ``black box'' libraries implementing
geometrical transformations, in particular polyhedron projection:  defines a convex polyhedron\footnote{A good bibliography on convex polyhedra and the associated algorithms can be found in the documentation of the Parma Polyhedra Library.~\cite{PPL} By \emph{convex polyhedron}, we mean, in a finite-dimension affine linear real space, an intersection of a finite number of half-spaces each delimited by a linear inequality, that is, the set of solutions of a finite system of linear inequalities. In particular, such a polyhedron can be unbounded. In the rest of the paper, the words ``polyhedron'' must be understood to mean ``convex polyhedron'' with that definition.} in , and finding  amounts to computing the inequalities defining the projection of this polyhedron into~.

\section{Quantifier Elimination Algorithm}
\label{part:algorithm}
We shall first describe subroutines \textsc{Generalize1} and \textsc{Generalize2}, then the main algorithm \textsc{ExistElim}.

\subsection{Generalized Models}

\begin{algorithm}
\caption{: Generalize a model  of a formula  to a conjunction}

\begin{algorithmic}
\REQUIRE{}
\STATE 
\FORALL {}
  \IF{}
    \STATE 
  \ELSE
    \STATE 
  \ENDIF
\ENDFOR
\ENSURE{}
\end{algorithmic}
\end{algorithm}


\begin{algorithm}
\caption{\textsc{Generalize2}(G, M): Remove useless constraints from conjunction  so that }
\begin{algorithmic}
\REQUIRE{ is not satisfiable}
\FORALL{ conjunct in }
  \IF{ is not satisfiable (call \textsc{Smt})}
     \STATE remove  from 
  \ENDIF
\ENDFOR
\ENSURE{ is not satisfiable}
\end{algorithmic}
\end{algorithm}

Consider a satisfiable quantifier-free formula . We suppose we have at our disposal a SMT-solving algorithm that will output a model . We wish to obtain instead a generalized model: a conjunction  such that . Ideally, we would like  to have as few conjuncts as possible. We shall now see algorithms in order to obtain such generalized models.

The truth value of  on an assignment  of its variables only depends on the truth value of the atomic predicates of  over . Let us note , where  denotes the cardinality of the set . These truth assignments therefore define at most  equivalence classes over the valuations of the variables appearing in . There can be fewer than  equivalence classes, because some truth assignments can be contradictory (for instance,  assigned to \textsf{true} and  assigned to \textsf{false}). One can immediately generalize a model of a formula to its equivalence class, which motivates our algorithm \textsc{Generalize1}. Its output is a conjunction of literals from .

This conjunction may itself be insufficiently general. Consider the formula .  is a model of~. \textsc{Generalize1} will output the conjunction . Yet, the first conjunct could be safely removed.  will remove unnecessary conjuncts from  while preserving the property that . Figure~\ref{fig:generalize2} illustrates why it is better to generalize the conjunctions.

The problem of obtaining a minimal (or at least, ``reasonably small'') inconsistent subset out of an inconsistent conjunction has already been studied. In DPLL(T) algorithms~\cite{Ganzingeretal2004CAV} for SMT-solving, the problem is to find out, given a consistent conjunction of literals  and a new literal , whether , , or neither; and if one of the implications holds, produce a minimal \emph{explanation} why it holds, that is, a subset  of the  such that  (respectively, ). Since this decision and explanation procedure is called often, it should be fast and much effort has been devoted in that respect by implementors of SMT-solvers (e.g. \cite{NieuwenhuisOliverasIC2007} for congruence theories). It is however not straightforward to use such explanation procedures for our purposes, since we do not consider conjunctions of literals only: when algorithm \textsc{ExistElim} invokes ,  is in general a complex formula, not a literal.

We therefore present here a straightforward inconsistent set minimization algorithm similar to the one found in~\cite[\S6]{dMRS:CADE2002}.
, where  is a conjunction such that  is unsatisfiable, works as follows:
\begin{itemize}
\item
It attempts removing the first conjunct from  (thus relaxing the  constraint). If  stays unsatisfiable, the conjunct is removed. If it becomes satisfiable, then the conjunct is necessary and is kept.
\item The process is continued with the following conjuncts.
\end{itemize}

Unsurprisingly, the results of this process depend on the order of the conjuncts inside the conjunction . Some orders may perform better than others; the resulting set of conjuncts is minimal with respect to inclusion, but not necessarily with respect to cardinality.
\footnote{This is the case even if we consider a purely propositional case. As an example, consider . , otherwise said  is not satisfiable. If one first relaxes the constraint , one gets the conjunction , which still implies~; this conjunction has two propositional models ( and ). Yet, one could have chosen to relax  and obtain , and then to relax  and obtain  (which still implies ); this formula has four propositional models.}

\begin{figure}
\begin{center}
\includegraphics[scale=\redi]{projection1}
\end{center}
\caption{Subsumption of one generalized model by another}
\label{fig:projection1}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[scale=\redii]{generalize1}
\end{center}
\caption{The gray area is the set of points matched by formula . Point  is found as a model. This model is first generalized to  according to its valuations on the atomic boolean formulas. Depending on whether one first tries to relax  or , one gets either a half plane (one conjunct) or a vertical band (three conjuncts); the former is ``simpler'' than the second. The simplicity of the formula output by \textsc{Generalize2} thus depends on the ordering of the input conjuncts.}
\label{fig:generalize1}
\end{figure}

\subsection{Main Algorithm}
\begin{algorithm}
\caption{\textsc{ExistElim}: Existential quantifier elimination}

\begin{algorithmic}
\STATE 
\STATE 
\WHILE[ and  and  does not mention variables from ]{ is satisfiable (call \textsc{Smt})}
  \STATE  a model of  \COMMENT{}
  \STATE  \COMMENT{}
  \STATE  \COMMENT{}
  \STATE 
    \COMMENT{}
  \STATE 
  \STATE 
\ENDWHILE
\ENSURE{}
\end{algorithmic}
\end{algorithm}
\begin{figure}
\begin{center}
\includegraphics[scale=\rediii]{generalize2}
\end{center}
\caption{ is the first generalized model selected. If , the initial value of , is replaced at the next iteration by  where  is the projection of , then it is possible to generate a single generalized model encompassing both  and  (for instance . If  stays constant, then the  constraint defining the left edge of  cannot be relaxed.}
\label{fig:generalize2}
\end{figure}

The main algorithm is  which computes a DNF formula equivalent to .  is a vector of variables.  can be empty, and then the algorithm simply computes a ``simple'' DNF form for~. The algorithm computes generalized models of  and projects them one by one, until exhaustion. It maintains three formulas  and . ~is a DNF formula containing the projections of the models processed so far.  contains the models yet to be processed; it is initially equal to~. For each generalized model , its projection  is added to  and removed from~.
 can thus be understood as an ALL-SAT implementation coupled with a projection, where the projection is performed inside the loop so as to simplify the problem (as opposed to waiting for all models to be output and projecting them).

The partial correctness of the algorithm ensues from the loop condition and the following loop invariants:
,
 and 
 does not mention variables from .

Given a formula , we denote by  the number of equivalence classes induced by the atomic predicates of  with nonempty intersection with the models of~. Termination is ensured because  decreases by at least one at each iteration:  defines exactly one equivalence class,  defines a union of equivalence classes which includes the one defined by , and the models of  include those of  thus also at least one equivalence class. The number of iterations is thus at most . Note that \textsc{Generalize2} is needed neither for correctness nor for termination, but only for efficiency: otherwise, the number of iterations would always be the number of equivalence classes, which can be huge.

\section{Possible Changes and Extensions}
We investigated two variations of the same algorithm, both of which perform significantly worse. In addition, we extended the algorithm to quantifier elimination modulo a user-specified theory.

\label{part:variants}

\subsection{ALL-SAT then project  (Mod1)}
\label{part:algo-mod1}
The algorithm would still be correct if  was removed from  instead of . It then becomes equivalent to performing ALL-SAT (obtaining all satisfying assignments) then projection. On the one hand, with this modified algorithm, the set of atomic formulas of  would stay included in that of  throughout the iterations, while this set can grow larger with the original algorithm since the set of atomic formulas of the projection of  can be much larger than the set of atomic formulas in~ (see~\S\ref{part:complexity}). On the other hand, the original algorithm may need fewer iterations because  may subsume several generalized models, as shown by Fig.~\ref{fig:projection1}~:  is the first generalized model being generated, and its projection subsumes~; thus, the original algorithm will not have to generate , while the modified algorithm will generate~. Our experiments (\S\ref{part:benchmarks}) showed that the unmodified algorithm often performs much better in practice than this approach.

\subsection{Removals from Negated Set  (Mod2)}
\begin{algorithm}
\caption{\textsc{ExistElim}(Mod2): Existential quantifier elimination}
\small
\begin{algorithmic}
\STATE 
\STATE 
\STATE 
\WHILE[ and  and  and  does not mention variables from ]{ is satisfiable (call \textsc{Smt})}
  \STATE  a model of  \COMMENT{}
  \STATE  \COMMENT{}
  \STATE  \COMMENT{}
  \STATE 
    \COMMENT{}
  \STATE 
  \STATE 
  \STATE 
\ENDWHILE
\ENSURE{}
\end{algorithmic}
\end{algorithm}

\label{part:algo-mod2}
The algorithm given previously was not the first we experimented; we had originally a slightly more complicated one, given as \textsc{ExistElim}(Mod2), which we wrongly thought would be more efficient. Instead of using  to check for inappropriate generalizations, we used a formula  initially equal to , and then progressively altered. The termination proof stays the same, while correctness relies on the additional invariant . \textsc{ExistElim} can be thought of as identical to  \textsc{ExistElim}(Mod2) except that  stays constant.

We thought this scheme allowed more generalization of models than the algorithm we gave earlier in the article, as shown by Fig.~\ref{fig:generalize2}. \textsc{ExistElim} tries to generalize  to a conjunction that implies , but in fact this is too strict a condition to succeed, whereas \textsc{ExistElim}(Mod2) succeeds in generalizing  to a conjunction that implies . If at least one variable is projected out, and  actually depends on that variable, then the models of  are strictly included in those of the final value of , which is equivalent to .

Experiments (\S\ref{part:benchmarks}) however showed that this ``more clever'' algorithm is slower by approximately a factor of two, because adding extra assertions to  is costly for the SMT-solver.

\subsection{Extra Modulo Theory}
The algorithm can be easily extended to quantifier elimination modulo an assumption~ on the free variables of~. All definitions stay the same except that  is replaced by , defined as  and  is replaced by , defined as . \textsc{ExistElim} is modified by replacing the initialization of  and  by  and  respectively. Intuitively,  defines a universe of validity such that values outside of the models  are irrelevant to the problem being studied.

\section{Comparison with Other Algorithms}
The ``classical'' algorithm for quantifier elimination over linear inequalities is Ferrante and Rackoff's~\cite{FerranteRackoff75}. Another algorithm based on similar ideas, but with better performance, was proposed by Loos and Weispfenning \cite{LoosWeispfenning93}.
We shall therefore compare our method to these algorithms, both theoretically and experimentally. We also compared our algorithm with other available packages using other quantifier elimination techniques.

\subsection{Complexity bounds}
\label{part:complexity}
\begin{table}[htb]\renewcommand{\footnoterule}{}\makeatletter \setlength{\skip\@mpfootins}{1ex}\makeatother \begin{minipage}{\textwidth}\begin{center}\small \begin{tabular}{|l|r|r|r|r|}
\hline
Benchmark & r. lim.  & r. lim. float & \texttt{prsb23} & \texttt{blowup5} \\
\hline
\textsc{Mjollnir} & 1.4 & 17 & 0.06 & negligible \\
\textsc{Mjollnir} (mod1) & 1.6 & 77\footnote{Memory consumption grows to 1.1~GiB.} & 0.06 & negligible\\
\textsc{Mjollnir} (mod2) & 1.5 & 34 & 0.07 & negligible\\
\textsc{Mjollnir} Loos-Weispfenning & o-o-m & o-o-m & o-o-m & negligible \\
Proof-of-concept & n/a & 823 & n/a & n/a \\
\textsc{Mjollnir} Ferrante-Rackoff & o-o-m & o-o-m & o-o-m & negligible \\
Proof-of-concept & n/a & 823 & n/a & n/a \\
\textsc{Lira} & o-o-m & o-o-m & 8.1 & 0.6\\
\textsc{Redlog} \texttt{rlqe} & 182  & o-o-m & 1.4 & negligible \\
\textsc{Redlog} \texttt{rlqe}+\texttt{rldnf} & o-o-m  & o-o-m  & n/a & n/a\\
\textsc{Mathematica} \texttt{Reduce} & (> 12000) & o-o-m & (> 780) & 7.36\\
\hline
\end{tabular}
\end{center}
\end{minipage}

\caption{Timings (in seconds, on an AMD Turion TL-58 64-bit Linux system) for eliminating quantifiers from our benchmarks. The first line is the algorithm described in this paper, the two following linear variants from \S\ref{part:variants}, then other packages. \textsc{Reduce} has \texttt{rlqe} (quantifier elimination) and \texttt{rlqe}+\texttt{rldnf} (same, followed by conversion to DNF).  means that the computation was killed after  seconds because it was running too long. The \texttt{prsb23} and following are decision problems, the output is \texttt{true} or \texttt{false}, thus DNF form does not matter. Out-of-memory is noted ``o-o-m''.}
\label{tab:benchmarks1}
\end{table}

We consider in this section that inequalities are written using integer coefficients in binary notation. We shall prove that a complexity bound  where  is the number of atomic formulas and  is the number of quantifiers to be eliminated. This yields an overall complexity of  where  is the size of the formula.

Let us consider a conjunction of inequalities taken from a set of  inequalities. The Fourier-Motzkin algorithm \cite{BradleyManna07,imbert93fouriers} eliminates variable  from this conjunction as follows. It first partitions these inequalities into those where  does not appear, which are retained verbatim, and those where  appears positively () and negatively (). From each couple of inequalities  in , an inequality where  does not appear is obtained by cancellation between  and . The size in bits of the coefficients in the output inequalities can be at most  where  is the maximal size of the input coefficients.

The inequalities output therefore belong to a set of size asymptotically at most  (the worst-case occurs when the inequalities split evenly between those in which  appears positively and those where it appears negatively). The output conjunction is in general too large: many inequalities in it are superfluous; yet it is guaranteed to include all inequalities defining the facets of the projection of the polyhedron.

Consider a formula  written with inequalities  as atomic formulas, with maximal coefficient size . Our algorithm eliminates the quantifier from  and outputs a DNF formula  built with inequalities found in the output of the Fourier-Motzkin algorithm operating on the set  and variable~. It follows that  is built from at most, asymptotically,  inequalities as atomic formulas. The running time for this quantifier elimination comes from:
\begin{itemize}
\item The SMT solving passes. There are at most  branches to explore in total. For each branch, SMT has to test whether the solution set of a conjunction of polynomial inequalities is empty or not, which is a particular case of linear programming, with polynomial complexity. The overall SMT cost is therefore bounded by  for some polynomial ;
\item The projections, with complexity , applied to each of at most  polyhedra.
\end{itemize}
This gives an overall complexity of  where  is a constant.

Consider now a succession of quantifier eliminations (with or without alternations). We now have  consisting of a sequence of quantifiers followed by a quantifier-free formula built out of atomic formulas . Our algorithm performs eliminations in sequence, starting from the rightmost quantifier.

Let us note  the set of atomic formulas that can be obtained after  eliminations; . Clearly,  asymptotically, since at each iteration the size of the set of atomic formulas can at most get squared by Fourier-Motzkin elimination. The size of the coefficients grows at most as . This yields the promised bound.

It is possible that the bound , obtained by observation of the Fourier-Motzkin algorithm, is too pessimistic. The literature does not show examples of such doubly exponential blowups, while polyhedra with single exponential blowups can be constructed.









The ``classical'' algorithm for quantifier elimination over real or rational arithmetic is Ferrante and Rackoff's method \cite{FerranteRackoff75}\cite[\S 7.3]{BradleyManna07}\cite[\S 4.2]{NipkowIJCAR08}. A related algorithm was proposed by Loos and Weispfenning \cite{LoosWeispfenning93}\cite[\S 4.4]{NipkowIJCAR08}. Both these algorithms are based on the idea that an existentially quantified formula  with free variables  can be replaced by  where  are expressed as functions of . In the case of Ferrante and Rackoff,  is quadratic in the worst case in the length of the formula, while for Loos and Weispfenning it is linear. In both cases, the overall complexity bound is .

The weakness of both algorithms is that they never simplify formulas. This may explain that while their theoretical bounds are better than ours, our algorithm is in practice more efficient, as shown in the next subsection.

One could at first assume that the complexity bounds for our algorithm are asymptotically worse than Ferrante and Rackoff's. Our algorithm, however, outputs results in CNF or DNF form, while Ferrante and Rackoff's algorithm does not. If we add a step of transformation to CNF or DNF to their algorithm, then we also obtain a triple exponential bound.

\subsection{Practical results}
\label{part:benchmarks}

\begin{table}[htb]
\begin{center}
\tableaularge
\begin{tabular}{|l|r|r|r|r|r|r|r|r|r|}
\hline
& \multicolumn{3}{|c}{depth 14}
& \multicolumn{3}{|c|}{depth 15}
& \multicolumn{3}{|c|}{depth 16}\\
& Solved & Avg & O-o-m
& Solved & Avg & O-o-m
& Solved & Avg & O-o-m\\
\hline
\textsc{Mjollnir} & 100 & 1.6 & 0 & 94 & 9.8 & 0 & 73 & 35.3 & 0\\
\textsc{Mjollnir} (mod1) & 94 & 8.2 & 3 & 80 & 27.3 & 7 & 39 & 67.1 & 25\\
\textsc{Mjollnir} (mod2) & 100 & 3.8 & 0 & 91 & 13.9 & 0 & 65 & 39.2 & 0\\
\textsc{Mjollnir} Loos-W. & 93 & 1.77 & 4 & 90 & 6.42 & 5 & 62 & 17.65 & 27\\
Proof-of-concept & 94 & 1.4 & 0 & 86 & 2.2 & 0 & 55 & 17.7 & 0\\
\textsc{Mjollnir} Ferrante-R. & 51 & 18.2 & 41 & 23 & 23.2 & 65 & 3 & 7.3 & 85\\
Proof-of-concept & 94 & 1.4 & 0 & 86 & 2.2 & 0 & 55 & 17.7 & 0\\
\textsc{Lira} & 14 & 102.4 & 83 & 3 & 77.8 & 94 & 1 & 8 & 95\\
\textsc{Redlog} (\texttt{rlqe}) & 92 & 13.7 & 0 & 53 & 27.4 & 0 & 27 & 33.5 & 0\\
\textsc{Mathematica} & 6 & 30.2 & 0 & 1 & 255.7 & 0 & 1 & 19.1 & 0\\
\hline
\end{tabular}
\end{center}
\caption{Benchmarks on  random instances generated using \texttt{randprsb}, with formula depths  respectively 14, 15 and 16 (obtained by\texttt{randprsb 0 7 -10 10  }) where  ranges in ). The table shows the number of instances solved within the timeout period out of the proposed 100, the average time spent per solved instance, and the number of instances resulting in out-of-memory.}
\label{tab:benchmarks2}
\end{table}

We benchmarked several variants of our method against other algorithms:
\begin{description}
\item[Mjollnir] is the algorithm described in \S\ref{part:algorithm}, implemented on top of SMT solver \textsc{Yices}\footnote{\url{http://yices.csl.sri.com/}} and the \textsc{NewPolka} polyhedron package from \textsc{Apron}\footnote{\url{http://apron.cri.ensmp.fr/library/}}, or optionally the Parma Polyhedra Library (PPL\footnote{\url{http://www.cs.unipr.it/ppl/}}). Profiling showed that most of the time is spent in the SMT solver, so performance differences between NewPolka and PPL are negligible.

\item[Proof-of-concept] is an early version of the same algorithm, implemented on top of a rudimentary SMT solver and the PPL. The SMT algorithm used is simple and lazy: the SMT problem is turned into SAT by replacing each atomic inequality by a propositional variable, and the SAT problem is input into \textsc{Minisat}. A full SAT solution is obtained, then tested for emptiness by solving a linear programming problem: finding a vector of coefficients suitable as a contradiction witness for Farkas' lemma. If a witness is found, it yields a contradictory conjunction, whose negation is added to the SAT problem and SAT is restarted.

\item[Mjollnir (mod1)] is the ALL-SAT then projection algorithm from~\S\ref{part:algo-mod1}. It is invoked by option \texttt{--no-block-projected-model}.

\item[Mjollnir (mod2)] is the algorithm from \S\ref{part:algo-mod2}; it is invoked by option \texttt{--add-blocking-to-g}.

\item[Mjollnir Ferrante-Rackoff] implements \cite{FerranteRackoff75}\cite[\S 7.3]{BradleyManna07}.

\item[Mjollnir Loos-Weispfenning] implements \cite{LoosWeispfenning93}.

\item[Lira\footnotemark]\footnotetext{\url{http://lira.gforge.avacs.org/}} is based on B\"uchi automata and handles both Presburger arithmetic (integer linear inequalities) and rational linear inequalities.

\item[Mathematica\footnotemark]\footnotetext{\url{http://www.wolfram.com/}} is a general-purpose symbolic algebra package. Its \texttt{Reduce} fonction appears to implement CAD~\cite{CAD_1998}, an algorithm suitable for nonlinear inequalities interpreted in the theory of real closed fields, though it is difficult to know what exactly is implemented because this program is closed source.

\item[Redlog\footnotemark]\footnotetext{\url{http://www.algebra.fim.uni-passau.de/~redlog/}} is a symbolic formula package implemented on top of the computer algebra system \textsc{Reduce}~3.8.\footnote{\url{http://www.uni-koeln.de/REDUCE/}} \textsc{Redlog} implements various algorithms due to Volker Weispfenning and his group~\cite{LW93}.
\end{description}

Table~\ref{tab:benchmarks1} compares these various implementations on a few benchmark examples
\footnote{Available from \url{http://www-verimag.imag.fr/~monniaux/download/linear_qe_benchmarks.zip}.} coming from two sources:
\begin{enumerate}
\item Examples produced from problems of program analysis following our method for the parametric computation of least invariants.~\cite{Monniaux_SAS07}
To summarize, each formula expresses the fact that a set of program states (such as a product of intervals for the numerical variables) is the least invariant of a program, or the strongest postcondition if there is no fixed point involved. Most of the examples, being extracted by hand from simple subprograms, were easily solved and thus did not constitute good benchmarks, but one of them, defining the least invariant of a rate limiter, proved to be tougher to solve, and we selected it as a benchmark. We have two versions of this example: the first for a rate limiter operating over real numbers (``r.~lim '')
the second over floating-point numbers, abstracted using real numbers (``r.~lim float''), and considerably tougher to process than the real example.
\item Examples procured from the \textsc{Lira} designers (\texttt{prsb23} and \texttt{blowup5}).
\end{enumerate}

Memory consumption stayed modest for all examples (< 15~MiB), except for r.~lim float.
Profiling showed that most of the time is spent in the SMT-solver and only a few percents in the projection algorithm. The fact that the proof-of-concept implementation, with a very naive SMT-solver, performs decently on an example where other algorithms exhaust memory shows that the performance of our algorithm cannot be solely explained by the good quality of \textsc{Yices}.

Table~\ref{tab:benchmarks2} compares the various algorithms on random examples.
We then used the LIRA team's \texttt{randprsb} tool\footnote{\url{http://lira.gforge.avacs.org/toolpaper/randPrsb.hs}}
to generate  random instances, by changing the seed of the random
number generator from 0 to~99, for each of three values (14, 15, 16) of the depth parameter, which measures complexity.\footnote{We used the command line \texttt{randprsb 0 7 -10 10  } where  is the depth parameter (here, 14, 15 or 16) and  ranges in .}
The programs were then tested with both
a 1.8~GiB memory limit and a timeout of five minutes.
It is clear from Tab.~\ref{tab:benchmarks2} that
\texttt{Mjollnir --no-add-blocking-to-g} is the most efficient of the
tested tools.

\section{Conclusion and Future Work}
We have proposed a new quantifier elimination algorithm for the theory of linear inequalities over the real or rational numbers, and investigated possible variants. Our motivation was the practical application of a recent result of ours on program analysis, stating that formulas for computing the least invariants of certain kinds of systems can be obtained through quantifier elimination~\cite{Monniaux_SAS07}.

This algorithm is efficient on examples obtained from this program analysis technique, as well as other examples, whereas earlier published algorithms, as well as several commercial packages, all exhaust time or memory resources. Our algorithm leverages the recent progresses on satisfiability modulo theory solvers (SMT) and, contrary to older algorithms, performs on-the-fly simplifications of formulas that keep formula sizes manageable. Our algorithm also performs better than a straight application of SMT solvers (ALL-SAT followed by projection).

Our algorithm is described for rational or real linear arithmetic, but it can be extended to any theory for which there is an efficient satisfiability testing algorithm for unquantified formulas and a reasonably efficient projection algorithm for conjunctions. Among extensions that could be interesting from a practical point of view would be on the one hand the nonlinear case for real arithmetic (polynomials), and on the other hand the mixed integer / real problems. Of course, nonlinear integer arithmetic cannot be considered, since Peano arithmetic is undecidable.

Tarski showed that the theory of the real closed fields (inequalities of polynomial expressions) admits quantifier elimination,~\cite{Tarski51} however his algorithm had impractical (non-elementary) complexity. Later, the \emph{cylindrical algebraic decomposition} (CAD)~\cite[Ch.~11]{Basu_Pollack_Roy_2003} method was introduced, with doubly exponential complexity, which is unavoidable in the worst case~\cite[\S 11.4]{Basu_Pollack_Roy_2003}. Our experiments with both \textsc{Mathematica} and \textsc{Qepcad}, both of which implement CAD, as well as with \textsc{Reduce}/\textsc{Redlog}, which implement various algorithms for quantifier elimination, showed us that combinatorial blowup occurs very quickly. For such techniques to be interesting in practice, practical complexity should be lowered. Perhaps our technique could help. There are, however, significant difficulties in that respect. Our technique starts with some single model of the target formula over the rational numbers; but a system of nonlinear inequalities needs not have rational models when it is not full-dimensional (for instance, ). Our technique reduces the geometrical computations to computations on conjunctions; but in the nonlinear case, single inequalities can be reduced to disjunctions. As an example,  is reduced to . Most importantly, our technique relies at several steps on the availability of a decision procedure that stays efficient even when the answer is negative.

Regarding the mixed integer / real problems, the \textsc{Lira} tool implements quantifier elimination using a weak form of B\"uchi automata matching the -ary expression of the integers or reals, where  is an arbitrary base.~\cite{Becker_et_al_CAV05} The output of the process  is an automaton and not a readable formula. While it is possible to decide a closed formula, and to obtain one model from a satisfiable non-closed formula, it is an open problem how to efficiently reconstruct a quantifier-free formula from the resulting automaton. The automaton construct is unsuitable for large coefficients (as our examples obtained from the analysis of floating-point programs). Even on examples with small coefficients, the tool was unable to complete quantifier elimination without blowing up. We think therefore that it would be interesting to be able to apply our technique to the mixed integer / real problems, but there are difficulties: the algorithms on integer polyhedra are considerably more complex than on rational polyhedra.

A classical objection to automatic program analysis tools meant to prove the absence of bugs is that these tools could themselves contain bugs. Our method uses complex algorithms (SMT-solving, polyhedron projection) as sub-procedures. We consider developing techniques so that the algorithm outputs easily-checkable proofs or ``proof witnesses'' of the correctness of its computation. Furthermore, we showed in earlier publications \cite{Monniaux_SAS07} that certain program analysis tasks were equivalent to quantifier elimination problems; that is, an effective static analyzer can be extracted from the quantifier-free form of an analyzer specification. This therefore suggests a new way for writing safe static analyzers: instead of painstakingly writing an analyzer, then proofs of correctness in a proof assistant \cite{Pich:these}, one could formulate the analysis problem as an equivalent quantifier elimination problem, with a relatively simple proof of equivalence, then apply a ``certified'' quantifier elimination procedure in order to extract the effective analyzer.

\bibliography{monniaux-lpar08}
