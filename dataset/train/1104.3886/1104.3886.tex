\documentclass[11pt,onecolumn,draftcls]{IEEEtran}
\usepackage{multicol}
\usepackage{amsmath,amssymb,cite,multirow,subfigure, amsthm}
\usepackage{graphicx}
\usepackage{url}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{makecell}
\usepackage{flushend}


\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{theorem}{Theorem}
\newtheorem{example}{Example}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{problem}{Problem}
\newtheorem{remark}{Remark}
\newtheorem{conjecture}{Conjecture}




\newcommand{\df}{\stackrel{\mbox{\scriptsize def}}{=}}
\newcommand{\gf}{\mathrm{GF}}
\newcommand{\rk}{\mathrm{rk}}
\newcommand{\vspan}[1]{\left< #1 \right>}
\newcommand{\wh}{\mathrm{w}_{\mbox{\tiny{H}}}}

\newcommand{\Ar}{A_{\mbox{\tiny{R}}}}
\newcommand{\Ac}{A_{\mbox{\tiny{C}}}}

\newcommand{\dr}{d_{\mbox{\tiny{R}}}}
\newcommand{\ds}{d_{\mbox{\tiny{S}}}}
\newcommand{\di}{d_{\mbox{\tiny{I}}}}

\newcommand{\gr}{g_{\mbox{\tiny{R}}}}

\newcommand{\Ic}{I_{\mbox{\tiny{C}}}}

\newcommand{\Jr}{J_{\mbox{\tiny{R}}}}
\newcommand{\Js}{J_{\mbox{\tiny{S}}}}
\newcommand{\Ji}{J_{\mbox{\tiny{I}}}}
\newcommand{\Jc}{J_{\mbox{\tiny{C}}}}

\newcommand{\Nr}{N_{\mbox{\tiny{R}}}}
\newcommand{\Ns}{N_{\mbox{\tiny{S}}}}
\newcommand{\Ni}{N_{\mbox{\tiny{I}}}}
\newcommand{\Nc}{N_{\mbox{\tiny{C}}}}

\renewcommand{\Pr}{P_{\mbox{\tiny{R}}}}
\newcommand{\Pc}{P_{\mbox{\tiny{C}}}}
\newcommand{\Ps}{P_{\mbox{\tiny{S}}}}
\renewcommand{\Pi}{P_{\mbox{\tiny{I}}}}

\newcommand{\Vr}{V_{\mbox{\tiny{R}}}}
\newcommand{\Vs}{V_{\mbox{\tiny{S}}}}
\newcommand{\Vi}{V_{\mbox{\tiny{I}}}}
\newcommand{\Vc}{V_{\mbox{\tiny{C}}}}

\begin{document}
\title{General Linearized Polynomial Interpolation\\and Its Applications}

\author{Hongmei Xie, Zhiyuan Yan,~\IEEEmembership{Senior Member, IEEE}, and Bruce W. Suter,~\IEEEmembership{Senior Member, IEEE}
\thanks{Hongmei Xie and Zhiyuan Yan are with the Department of Electrical and Computer
Engineering, Lehigh University, Bethlehem, PA 18015, USA (E-mails:
{\tt hox209,yan@lehigh.edu}). Bruce W. Suter is with Air Force Research Laboratory, Rome, NY 13441, USA
(E-mail: {\tt bruce.suter@rl.af.mil}).}}

\maketitle

\thispagestyle{empty}
\begin{abstract}
In this paper, we first propose a general interpolation algorithm in a free module of a \textbf{linearized} polynomial ring, and then apply this algorithm to decode several important families of codes, Gabidulin codes, KK codes and MV codes. Our decoding algorithm for Gabidulin codes is different from the polynomial reconstruction algorithm by Loidreau. When applied to decode KK codes, our interpolation algorithm is equivalent to the Sudan-style list-1 decoding algorithm proposed by K\"{o}tter and Kschischang for KK codes. The general interpolation approach is also capable of solving the interpolation problem for the list decoding of MV codes proposed by Mahdavifar and Vardy, and has a lower complexity than solving linear equations.
\end{abstract}


\section{Introduction}\label{sec:intro}
Given a set of points, polynomial interpolation finds one or more polynomials that go through these points. Since error correcting codes are often defined through polynomials, polynomial interpolation is instrumental in decoding such error control codes. For instance, Reed-Solomon (RS) codes can be defined using evaluation of polynomials~\cite{RothBookRS}, and bivariate polynomial interpolation has been used in RS decoders. In particular, the K\"{o}tter interpolation~\cite{kotter_it96} implements the interpolation step of the Guruswami-Sudan algorithm~\cite{GS99} for RS codes with low complexity. Also, the Welch-Berlekamp key equation can be viewed as a rational interpolation problem, and the Welch-Berlekamp algorithm (WBA) solves this problem~\cite{WelchBerlekamp86}.

Polynomial interpolation was extended by Wang \emph{et al.}~\cite{WangMcEliece05} to a general interpolation problem in a free module that is defined over a polynomial ring over some finite field  and admits an ordering. Since the free module is also a vector space over , one can define linear functionals on the free module. Given any set of linear functionals, the general interpolation problem is to find a minimum element in the intersection of the kernels of the linear functionals. Wang \emph{et al.} proposed a general interpolation algorithm, and showed that the K\"{o}tter interpolation and the WBA are both special cases of this general interpolation algorithm \cite{WangMcEliece05}.

Recently, error control codes defined using evaluation of \textbf{linearized polynomials} have attracted growing attention, such as Gabidulin codes~\cite{gabidulin_pit0185} and a family of subspace codes proposed by K\"{o}tter and Kschischang \cite{kotter_it08}, referred to as KK codes. While both Gabidulin and KK codes are important to error control in random linear network coding (see, for example, \cite{kotter_it08,silva_it08,silva_it09}), Gabidulin codes are also considered for potential applications in wireless communications \cite{lusina_it03}, public-key cryptosystems \cite{gabidulin_lncs91}, and storage systems
\cite{gabidulin_pit0285, RothBookRS}. A decoding algorithm of Gabidulin codes through linearized polynomial reconstruction was proposed by Loidreau~\cite{loidreau_wcc05}, and K\"{o}tter and Kschischang proposed a Sudan-style list-1 decoding algorithm for KK codes based on bivariate linearized polynomial interpolation \cite{kotter_it08}. Following similar list decoding idea for RS codes by Guruswami and Sudan~\cite{GS99}, Mahdavifar and Vardy considered list decoding of KK codes in~\cite{mahdavifar_isit10}\cite{mahdavifar_it10}, where the construction of KK codes were modified accordingly. Codes in ~\cite{mahdavifar_isit10}\cite{mahdavifar_it10} are similar to but different from KK codes, and we call the new class of subspaces codes MV codes.

Parallel to the work of Wang \emph{et al}.~\cite{WangMcEliece05}, we investigate the general interpolation problem in a free module of a \textbf{linearized polynomial ring}. The main contributions of this paper are listed as follows.
\begin{itemize}
\item We propose a general interpolation algorithm in a free module of a linearized polynomial ring, and show that our interpolation algorithm has a polynomial time complexity.
\item We apply our interpolation algorithm to decode Gabidulin codes. The resulted decoding algorithm resembles Loidreau's decoding algorithm \makeatletter
    \renewcommand\@cite [1]{#1}
    \makeatother (cf. [\cite{loidreau_wcc05}, Table~1]), \makeatletter
    \renewcommand\@cite [1] {[#1]}
    \makeatother and both algorithms have quadratic complexity, but the two differ in several key aspects.
\item Our general interpolation approach is also used to decode KK codes. In fact, in this case, our algorithm is equivalent to the Sudan-style list-1 decoding algorithm in~\cite{kotter_it08}. That is, the Sudan-style list-1 decoding algorithm is a special case of our general interpolation algorithm, when some operations and parameters are specified.
\item Finally, we use our general interpolation algorithm to obtain the multivariate polynomial for the list decoding of MV codes in~\cite{mahdavifar_isit10}. To the best of our knowledge, there is no other efficient algorithm to accomplish the task. We also show that our algorithm has lower complexity than solving linear equations.
\end{itemize}

The rest of the paper is organized as follows. Section~\ref{sec:preliminaries} reviews the general interpolation over free modules of polynomial rings, and then introduces Gabidulin codes, KK codes and MV codes, as well as their respective decoding algorithms. In Section~\ref{sec:generalinterpo}, we propose our general interpolation algorithm over a free module of a linearized polynomial ring, and analyze its computational complexity. We apply our general interpolation algorithm to decode Gabidulin codes as well as KK codes and MV codes in Sections~\ref{sec: GeneralGb}, \ref{sec: generalKK}, and \ref{sec: generalMV}, respectively. Concluding remarks are provided in Section~\ref{sec: conclusion}.

\section{Preliminaries} \label{sec:preliminaries}
\subsection{General Polynomial Interpolation over Polynomials Ring}
Motivated by the K\"{o}tter interpolation, Wang \emph{et al}.~\cite{WangMcEliece05} consider a general interpolation problem. Let  be the ring of all the polynomials over some finite field . A free -module  is an -module with a basis. Suppose  is also a vector space over  with a basis , then we can define a set of  linear functionals 's from  to , with corresponding kernels 's, where . If there is a total ordering on ,  admits an ordering. That is, for a subset of  we can find an element with the smallest order, and the element is a \emph{minimum} in this subset. The general interpolation algorithm in~\cite{WangMcEliece05} finds a minimum in .




\subsection{Linearized Polynomial Ring} \label{sec: L[x]}
Suppose GF is an extension field of GF, where  is a prime power and  is a positive integer. A polynomial of the form

with coefficients  GF is called a \emph{linearized polynomial} over GF. We assume  is fixed, and denote  as  in this paper. For a linearized polynomial  over GF, its -degree, denoted as deg, is given by .

Linearized polynomials are so named because for a linearized polynomial  over GF,  and  in an extension field  of GF, and  GF, we have . In other words,  can be treated as a linear mapping from  to  with respect to GF~\cite{lidl_book83}. Given two linearized polynomials  and   over GF, their GF-linear combination  with  GF, is also a linearized polynomial over GF. We define the multiplication between  and   as , and  is also a linearized polynomial over GF. Note that generally  does not necessarily equal . Thus the set of linearized polynomials over GF with polynomial addition and the multiplication  forms a noncommutative ring, denoted by . Note that there is no left or right divisor of zero in \cite{ore_ams33}.

\subsection{Gabidulin Codes and Loidreau's Reconstruction Algorithm}\label{sec: GB}
The rank of a vector  GF is the \textbf{maximal} number of coordinates that are linearly independent over GF, denoted as . The rank distance between two vectors  GF is defined to be

The minimum rank distance of a code , denoted as  , is simply the minimum rank distance
over all possible pairs of distinct codewords, that is, .


The maximum cardinality of a rank metric code in GF with minimum rank distance  is  \cite{delsarte_jct78, gabidulin_pit0185, roth_it91}. We refer to codes with maximum cardinality as maximum rank distance (MRD) codes.
A family of linear MRD codes was proposed by Gabidulin \cite{gabidulin_pit0185}, and is often referred to as Gabidulin codes.
An  Gabidulin code  over GF () is defined by a generator matrix  of the form

where  are linearly independent over GF. We introduce the vector  for future reference. For a message vector  and its corresponding message polynomial , the codeword to be transmitted is . Suppose an additive error  occurs, and the received vector is , where  for . Given , a bounded distance decoder with decoding radius  tries to find  GF such that  with . If such  and  exist, the received vector  is said to be decodable~\cite{gabidulin_pit0185}.

Gabidulin codes can be defined using evaluation of linearized polynomials, analogous to RS codes, which are defined using evaluation of polynomials. Hence Loidreau devised a method to decode Gabidulin codes through \emph{reconstruction of linearized polynomials}\makeatletter
    \renewcommand\@cite [1]{#1}
    \makeatother (cf. [\cite{loidreau_wcc05}, Table~1]),\makeatletter
    \renewcommand\@cite [1] {[#1]}
    \makeatother
where a pair of linearized polynomials,  and  are constructed such that  for , with deg and deg. It is shown~\cite{loidreau_wcc05} that if , one gets a solution of decoding Gabidulin codes from any solution of the reconstruction problem. Loidreau's algorithm~\cite{loidreau_wcc05} constructs two sequences of polynomials  and , and updates them iteratively by discrepancy-based update rules, so that each sequence satisfies the objective equation for the first  points after the th iteration. To implement the degree constraints on the linearized polynomials, Loidreau's algorithm starts with initial polynomials of designated -degrees, and then aims to increase the -degrees of each sequence of polynomials strictly once every two iterations. The algorithm outputs  with -degree no more than  and  of -degree no more than .

\subsection{KK Codes and Their Decoding Algorithm}
\label{sec: introKK}
KK codes~\cite{kotter_it08} are a type of subspace codes for random linear network coding, where subspaces are transmitted and received at both ends. Suppose  is a vector space over GF, and  is the set of all subspaces of . For , the subspace distance ~\cite{kotter_it08} between  and  is defined as

where dim denotes the dimension of a subspace ,  is the intersection space of  and , and  is the smallest subspace that contains both  and .

Suppose an -dimensional subspace  is a codeword of a KK code. The basis of  is obtained via evaluation of linearized polynomials. First we select  () elements  GF that are linearly independent over GF. Theses  elements span an -dimensional vector space  GF, where . We then construct  by  GF GF. Given a message vector  over GF, the message polynomial is defined to be . Finally, the subspace spanned by  is an -dimensional subspace of , as all the pairs  are linearly independent~\cite{kotter_it08}.

Suppose  is transmitted over the operator channel~\cite{kotter_it08}, and an -dimensional subspace  of  is received, with dim and . It is proved that the error is decodable by the list-1 decoding algorithm~\cite{kotter_it08} if .
Let , and  be a basis for . The decoding algorithm in~\cite{kotter_it08} consists of an interpolation step and a factorization step. First the interpolation procedure finds a nonzero bivariate polynomial  such that

where  and  are linearized polynomials of -degrees at most  and  respectively. Then a message polynomial  is obtained in the factorization step by right division~\cite{kotter_it08} if . Decodability is guaranteed if we select ~\cite{kotter_it08}.

The interpolation procedure of the decoding algorithm in~\cite{kotter_it08}, called  a Sudan-style list-1 decoding algorithm,  adopts some discrepancy based update rules. During the -th iteration, the algorithm generates an -minimal bivariate polynomial and a -minimal bivariate polynomial,  and , that interpolate through the first  points for , where  is the total number of points to be interpolated. Finally, the minimum one between  and , defined under an order of ~\cite{kotter_it08}, is the decoding output.



\subsection{MV Codes and Their List Decoding Algorithm}
\label{sec: introMV}
MV codes are similar to but different from KK codes~\cite{kotter_it08}. To enable list decoding, different code constructions are proposed for different code dimensions in~\cite{mahdavifar_isit10}~\cite{mahdavifar_it10}.

To construct an -dimensional MV code over GF,  has to be a positive integer that divides . Then the equation  has  distinct roots  over GF. Choose a primitive element  over GF with  being a normal basis for GF. Then construct elements  over GF by  for . It is proved~\cite{mahdavifar_it10} that the set  is a basis of GF over GF.

For a message vector  over GF, the message polynomial is . Let  denote the composition of  with itself by  times for any nonnegative integer , while . Then the codeword  corresponding to the message  is spanned by a set of vectors  for , where , , and  is the desired list size. Note that  GF for any  and ~\cite{mahdavifar_it10}. Then  is an -dimensional subspace of the -dimensional ambient space . Suppose an error of dimension  occurs, and an -dimensional subspace  of  is received. The decoder first finds subspaces  such that  for . Then, a basis  of  is found, where  is the dimension of . If , we ignore the first step and simply find a basis for the -dimensional received subspace . For , the decoder obtains , and finds a basis  of , where  is the dimension of . Finally, the decoder constructs a nonzero multivariate polynomial , where  is a linearized polynomials over GF of -degree at most  for , such that for , , and ,

Using the LRR algorithm in~\cite{mahdavifar_isit10}, the decoder finds all possible polynomials 's such that

It is proved~\cite{mahdavifar_it10} that~(\ref{equ: lLinter}) has a nonzero solution if

and there are at most  solutions to (\ref{equ: lLfactor}), among which the transmitted message polynomial  is guaranteed to be included.



\section{General Interpolation by Linearized Polynomials}
\label{sec:generalinterpo}

In this section, we investigate the general interpolation problem by linearized polynomials. We first present the general interpolation problem, then propose our general interpolation algorithm, which follows a strategy similar to that in~\cite{WangMcEliece05}.


\subsection{General Interpolation over Free -Modules} \label{section: GeneralInterpolation}

Suppose  is the ring of linearized polynomials over GF, and  is a free -module with a basis .  We denote the multiplication between an element in  and an element in the module by , and any element  can be represented by

where  and . Thus  is also a vector space over GF with a basis

Suppose there exists a total ordering  on , and we can write  such that  when . Then  can be represented by

where  and .  is called the \emph{order} of , denoted as order, and  is the \emph{leading monomial} of , denoted as LM. We write  if order order, and  if order order. An element  is a minimum in a subset of  if its order is the lowest among all the elements in the subset. Further, we define Ind, and Ind IndLM. Then we introduce a partition of  as , where .


For the vector space  over GF, we consider a set of  linear functionals  from  to GF: . Suppose  is the kernel of  and  is an -submodule, then the general interpolation problem is to find a minimum , that is, to find an element  such that it lies in the kernels of all the given linear functionals. Furthermore, we can show the uniqueness of  as in~\cite{WangMcEliece05}.
\begin{lemma} \label{lemma: uniqueness}
The minimum in  is unique up to a scalar.
\end{lemma}
\begin{proof}
Suppose both  and  have the minimum order in , then there exists a nontrivial linear combination , where  GF, such that . Since , this contradicts the minimality of  and .
\end{proof}

\begin{algorithm}
\caption{General Interpolation by Linearized Polynomials}
\label{alg: GILinearized}
\begin{algorithmic}
\FOR{ to }
\STATE {}
\ENDFOR
\FOR{ to }
\FOR{ to }
\STATE{}
\STATE{}
\ENDFOR
\STATE{}
\IF{}
\STATE{}
\FOR{  }
\IF{}
\STATE{}
\ELSIF{}
\STATE{}
\ENDIF
\ENDFOR
\ENDIF
\ENDFOR
\STATE{}
\end{algorithmic}
\end{algorithm}

Define , and , then the general interpolation problem is equivalent to finding  for . The key idea is to iteratively construct  from  by a discrepancy based update, starting from some initial values. We propose an algorithm to solve this general interpolation algorithm, given in  Algorithm~\ref{alg: GILinearized}. In Algorithm~\ref{alg: GILinearized}, there are three cases, and in each case a different update is used to obtain  based on .
\begin{enumerate}
\item If , then .
\item For 's not in , we find one of them with the lowest order, denoted as , and check whether . If , then . We call this type of update a cross-term update. Note in this case, the order of  is preserved, that is, .
\item For , we construct  by . We call this type of update an order-increase update. In this case,  takes a higher order than , that is, .
\end{enumerate}

\begin{lemma} \label{lemma: GIminimum}
In each of the three cases,  is a minimum in .
\end{lemma}
The following proof follows the same approach in the corresponding proof of minimality in~\cite{McEliece03} and~\cite{WangMcEliece05}.
\begin{proof}
We deal with the three cases separately:
\begin{enumerate}
\item We choose  if . Since  is a minimum in  and ,  is also a minimum in the smaller set .
\item If , we construct . One can verify that , and thus . Since Ind = Ind,  is also in , thus .  Furthermore,  for any , since . Hence . Since  and  is a minimum in ,  is also a minimum in , hence a minimum in the smaller set .

\item In this case, . First note that , and hence . For any , when we apply  to , we also get zero because both  and  lie in , as  is a submodule of . Thus . Also, Ind Ind by our definition Ind. Thus we have . Next we show that  is a minimum in  by contradiction. Suppose there exists  such that . Note that order order. Since ,  also lies in . Hence order order, as  is a minimum in , which results in order order order. Since both  and  lie in the set  by definition, there does not exist  such that order order order. Hence the only possibility is that . But in this case, we could construct  with GF such that . Note that  but  as  but . The fact that  but  contradicts the minimality of  in , as  has the lowest order among all 's  where  but .
\end{enumerate}
\end{proof}

\subsection{Complexity Analysis of Algorithm~\ref{alg: GILinearized}} \label{section: ComplexityGeneral}
There are a total of  iterations in Algorithm~\ref{alg: GILinearized}. In each iteration,  linear functionals are first carried out to calculate the discrepancies, followed by at most  finite field additions (subtractions) to find the minimum candidate and its index among those with nonzero discrepancies. Then to update the candidates, we conduct at most  finite field multiplications,  finite field additions, one multiplication between elements in the ring  and elements in the module , and one computation of the linear functional, where  is the highest -degree of the linearized polynomials in  among all the iterations. Notice that the -degree of each candidate is non-decreasing in an iteration based on the update rules. Hence it is safe to choose  to be the highest -degree of the polynomial in  of the ultimate output. To sum up, the complexity of Algorithm~\ref{alg: GILinearized} is dominated by  finite field additions,  field multiplications,  linear functional calculations, and  multiplications between elements in the ring  and elements in the module . Since the complexity of the  linear functional calculations and the multiplications between elements in the ring and elements in the module might vary in different situations, we consider the complexity of each realization of Algorithm~\ref{alg: GILinearized} on a case-by-case basis.

\section{Decoding of Gabidulin Codes}
\label{sec: GeneralGb}
\subsection{Decoding of Gabidulin Codes}
We consider an  Gabidulin code over GF as defined in Section~\ref{sec: GB}, and the ring of linearized polynomials  over GF discussed in Section~\ref{sec: L[x]}. Based on Loidreau's polynomial reconstruction approach~\cite{loidreau_wcc05}, we generalize the decoding problem of Gabidulin codes from an interpolation point of view. Suppose we have a set of points  with  for , where 's are linearly independent and . Try to construct a nonzero bivariate polynomial  with  and  being linearized polynomials over GF, such that  is as small as possible and

We will show that a solution of~(\ref{equ: GGeneralInter}) gives a solution to the decoding problem of Gabidulin codes under some conditions. Then we formalize~(\ref{equ: GGeneralInter}) to a general interpolation problem over free -modules, and solve it by Algorithm~\ref{alg: GILinearized}.

Suppose deg, and deg. To have a nonzero solution of~(\ref{equ: GGeneralInter}), the number of unknown coefficients should be greater than the number of equations, that is,

Next suppose  is a nonzero solution of~(\ref{equ: GGeneralInter}). Substituting  by the message polynomial , we get . When , i.e.,  is the zero polynomial,  satisfies  and thus can be obtained by right division over the linearized polynomial ring~\cite{kotter_it08}.

It remains to identify the condition under which  is identically zero. Since  is a nonzero solution of (\ref{equ: GGeneralInter}), , i.e.,  with the rank of  no more than . Then there exists a nonzero linearized polynomial  of -degree at most  such that  for . Then we have a linearized polynomial  of -degree at most  with  linearly independent roots  for . Thus when , we have . Since there is no left or right divisor or zero in the linearized polynomial ring~\cite{ore_ams33} and  is nonzero, we have , hence  can be obtained by right division over the linearized polynomial ring. The condition  will be satisfied by forcing

and restricting

Combining~(\ref{equ: tau1mod}) and~(\ref{equ: tau2mod}), we select , and have

Hence if~(\ref{equ: tandtau}) is satisfied, a solution of~(\ref{equ: GGeneralInter}) gives a solution to the decoding problem of Gabidulin codes. Next we formalize the interpolation problem in (\ref{equ: GGeneralInter}) to a general interpolation problem over free -modules.

We select  as a basis, and construct a free -module  from

where , and the multiplication  is defined as

Hence , and we call such  a  \emph{bivariate linearized polynomial}. Following~(\ref{equ: GIexpand}) and~(\ref{equ: GIM}),  is also a vector space over GF with a vector space basis . Then we define a total ordering on  as follows. We write  for  and , and write  for . Once the total ordering on  is determined, the leading monomial and the order of any  can be defined as described in Section~\ref{section: GeneralInterpolation}. Consequently, given a subset of , a minimum element in  can be found.

Finally, we define a set of linear functionals  from  to GF to be  for , where 's are the points to be interpolated. If ,  is said to be in the kernel  of . The kernels are -submodules by the following lemma.

\begin{lemma} \label{lemma: LxKernels}
 is an -submodule.
\end{lemma}
\begin{proof}
Since  is a subgroup of , it is easy to show that  is an Abelian group under polynomial addition, and the associative  and distributive laws hold for the multiplication between elements in  and elements in . Now we consider an arbitrary element  and an element . Suppose  with  GF, and  with . Then . Given , we have  . Hence  is a submodule of .
\end{proof}

Hence  is also an -submodule. Consequently, the interpolation problem described by (\ref{equ: GGeneralInter}) is to find a minimum  such that  is a minimum in . This is a general interpolation problem over free -modules as described in Section~\ref{section: GeneralInterpolation}, and Algorithm~\ref{alg: GILinearized} solves it by finding a \textbf{minimum} nonzero solution.

To use Algorithm~\ref{alg: GILinearized}, first we set , and  in the initialization step. In the following iterations, multiplication between an element in  and an element in  in the cross-term and order-increase updates follow (\ref{equ: GIcirc}). In particular, . Since , we can also omit it from the right hand side, and instead use , as scaling by a nonzero scalar does not affect the order of an element in .

Now we consider the complexity of Algorithm~\ref{alg: GILinearized} when used to decode Gabidulin codes. Adopting the same set of parameters in the complexity analysis in Section~\ref{section: ComplexityGeneral}, we have , , and  based on~(\ref{equ: KKinterpolation}) and the following argument. Second, each linear functional in this case carries out evaluations of the bivariate linearized polynomial by the given points, with a total of  finite field multiplications and   finite field additions.
Finally, the multiplication between  and  is accomplished by raising the coefficients of  to the -th power, which is simply a cyclic shift if a normal basis is chosen~\cite{silva_isit09}\cite{max_ciss08}.
In summary, when used to decode KK codes, Algorithm~\ref{alg: GILinearized} takes a total of  finite field multiplications in GF.  On the other hand, the complexity analysis in \cite{Loidreau_wcc06} gives an overall complexity of . Hence both algorithms are of quadratic complexity.

\subsection{Comparison to Loidreau's Reconstruction Algorithm}

Although our cross-term and order-increase update rules are similar to that of the alternate increasing degree step in Loidreau's algorithm, we observe that Algorithm~\ref{alg: GILinearized} differs from Loidreau's algorithm in two aspects, stated as follow.

First, Loidreau's algorithm uses another algorithm~\cite{ore_ams34} in the precomputation step before initializing the main algorithm, for the purpose of reduced complexity, whereas our decoding algorithm carries out all the iterations solely from the interpolation approach. But as shown in the previous section, both Loidreau's algorithm and Algorithm \ref{alg: GILinearized} have quadratic complexities. Further, we will show the equivalence of the polynomials derived after the initialization step of Loidreau's algorithm and the ones obtained after the first  iterations of Algorithm~\ref{alg: GILinearized}. The initialization step of Loidreau's algorithm actually introduces two bivariate polynomials  and . Given our previous notations, Algorithm~\ref{alg: GILinearized} produces two bivariate polynomials  and  after the first  iterations. The relation between these four polynomials are stated in Lemma~\ref{Lemma: LdGIkit}.

\begin{lemma} \label{Lemma: LdGIkit}
The initial bivariate polynomials of Loidreau's algorithm and the bivariate polynomials derived after the first  iterations of Algorithm~\ref{alg: GILinearized} are of the same order correspondingly, i.e.,  and .
\end{lemma}
\begin{proof}
 In the initialization step of Algorithm~\ref{alg: GILinearized},  is of lower order than , and  as 's are linearly independent, so  updates by the order-increase rule, while  updates according to its discrepancy value. Then  is actually a linearized polynomial in  of -degree 1, and  is a bivariate polynomial with a leading monomial , where  GF is a constant.

 In the second iteration, again  based on our total ordering on , and  as 's are linearly independent, i.e., there does not exist a linearized polynomial of -degree 1 that has two linearly independent roots. Hence  takes the order-increase rule and  adopts others accordingly. Similar situation occurs in all the first  iterations, given the total ordering we defined on  and the fact that  for any .

 Finally, a  in  of -degree  is derived, which actually only interpolates over the first  's. Note that  is obtained in the same way by  in Loidreau's algorithm. Given that ,  we have . Hence . On the other hand,  is a bivariate polynomial with a leading monomial , where  GF is also a constant. Since  is a linear combination of linearized polynomials of -degree , it is a linearized polynomial in  of -degree at most , then the leading monomial of  is . As a result, .
\end{proof}
Note that the -degree of  is exactly , as it actually interpolates over  linearly independent points .  is a linear combination of polynomials of -degree , but its -degree might be lower than , as the most significant coefficients may cancel each other. Thus the claim in~\cite{loidreau_wcc05} that after the final iteration deg is inaccurate.


The second difference between Loidreau's and our decoding algorithms lies in the update of the interpolation steps when some of the discrepancies are zero. It should be pointed out that in the alternate increasing degree step of Loidreau's algorithm,  in operations  and  should be 
in\makeatletter
    \renewcommand\@cite [1]{#1}
    \makeatother ([\cite{loidreau_wcc05}, Table~1]).\makeatletter
    \renewcommand\@cite [1] {[#1]}
    \makeatother
After the correction of this typo, the key difference between Loidreau's algorithm and Algorithm~\ref{alg: GILinearized} is that the latter accounts for zero discrepancies, while the former only covers it partially. To be specific, Loidreau's algorithm\makeatletter
    \renewcommand\@cite [1]{#1}
    \makeatother [\cite{loidreau_wcc05}, Table~1]\makeatletter
    \renewcommand\@cite [1] {[#1]}
    \makeatother
malfunctions when  but , as shown in Lemma~\ref{lemma: Ldzero}.
\begin{lemma} \label{lemma: Ldzero}
If  but  at the beginning of any iteration, all four linearized polynomials of the  and  in Loidreau's algorithm will be the zero polynomial after a certain number of iterations.
\end{lemma}
The proof can be conducted simply by tedious calculations, hence we will not present it here. Instead, an example is given to illustrate Lemma~\ref{lemma: Ldzero}, where  but  happens during an intermediate iteration. To fix the problem in Lemma~\ref{lemma: Ldzero}, one way is not to update the candidates when the zero discrepancy is involved. But such an operation breaks the rule of updating the -degrees of the candidates alternately, which is designed to ensure strict degree constraints on the output of the algorithm. Further notice that  and  are involved in different types of update rules for the two pairs of candidate polynomials, hence for the case of  but , the algorithm in\makeatletter
    \renewcommand\@cite [1]{#1}
    \makeatother [\cite{loidreau_wcc05}, Table~1]\makeatletter
    \renewcommand\@cite [1] {[#1]}
    \makeatother works properly.

\begin{example} \label{example: 2szeros}
We construct a  Gabidulin code over GF with , where  is a primitive element of GF and is a root of . Given the message vector , the message polynomial is , with a codeword . Suppose the error vector is , and the received vector is . The decoding procedures by Loidreau's algorithm and Algorithm~\ref{alg: GILinearized} are presented in Table~\ref{tab: LdvsGI}. Based on Lemma~\ref{Lemma: LdGIkit}, we start from the initial polynomials of Loidreau's algorithm and the polynomials after the first  iterations by Algorithm~\ref{alg: GILinearized}. Note that  in the final iteration is not listed, as it is of higher order than . Since ,  is decodable. As shown in Table~\ref{tab: LdvsGI}, however, Loidreau's algorithm fails. On the other hand, our algorithm produces a bivariate polynomial , from which the correct decoding result  is obtained.
\end{example}


\begin{table*}[htbp]
\begin{center}
\caption{Example~\ref{example: 2szeros}: Use Loidreau's algorithm and Algorithm~\ref{alg: GILinearized} to decode Gabidulin codes}
\label{tab: LdvsGI}
\begin{tabular}{|l|l|l|}
\hline
  &  Loidreau's algorithm   &  Algorithm~\ref{alg: GILinearized} \\ \hline
\multirow{2}{*}{2} &  &  \\
    &  &  \\ \hline

\multirow{3}{*}{3} &  &  \\		
		&  &  \\
    &  &  \\ \hline

\multirow{3}{*}{4} &  &  \\		
		&  &  \\
    &  &  \\ \hline

\multirow{3}{*}{5} &  &  \\		
		&  &  \\
    &  &  \\ \hline

\multirow{2}{*}{6} &  &  \\		
		&  &  \\ \hline
\end{tabular}
\end{center}
\end{table*}



\section{Decoding of KK Codes} \label{sec: generalKK}

For a KK code over GF as described in Section~\ref{sec: introKK}, the decoding algorithm in~\cite{kotter_it08} finds a \textbf{minimum} solution to~(\ref{equ: KKinterpolation}) based on an interpolation procedure. In this section, we will show that this list-1 decoding algorithm is a special case of our general interpolation algorithm over free -modules, where   is the ring of linearized polynomials over GF.



\begin{lemma} \label{lemma: KKspecialcase}
When , Algorithm~\ref{alg: GILinearized} reduces to the Sudan-style list-1 decoding algorithm in~\cite{kotter_it08}.
\end{lemma}
\begin{proof}
We assume that the condition of decodability~\cite{kotter_it08} is satisfied so that an interpolation approach works to gives a solution of . Given the linearized polynomial ring  over GF, we set , choose a set  as a basis, and construct the same free -module  with the same ordering as that in Section~\ref{sec: GeneralGb}. Hence Algorithm~\ref{alg: GILinearized} has exactly the same initial values and the same update rules as the Sudan-style list-1 decoding algorithm in~\cite{kotter_it08} (it should be pointed out that the pseudocode in ~\cite{kotter_it08} contains a typo, and no update is going to take place when both discrepancies are zero~\cite{kschischang_privatecomm10}). Hence we only have to show that the final output of the two algorithms are the same (of the same order).

We consider the definition of minimum in Algorithm~\ref{alg: GILinearized} and the notion of -minimal and -minimal in~\cite{kotter_it08}. According to the definition in~\cite{kotter_it08},  is -minimal if it interpolates through the first  points and is a minimal polynomial under , while its leading term is in . Comparing this definition to that in our general interpolation construction, we find that this  is a minimum in , hence . Similarly,  being -minimal means that  in Algorithm~\ref{alg: GILinearized}. Since KK's decoding algorithm finds -minimal and -minimal bivariate linearized polynomials in each step, it works the same as Algorithm~\ref{alg: GILinearized} during intermediate steps. Finally, KK's decoding algorithm outputs the one with a smaller -weighted degree, which equals to finding the minimum among  and  as performed in Algorithm~\ref{alg: GILinearized}. Hence our general interpolation algorithm reduces to the list-1 decoding algorithm in~\cite{kotter_it08} when .
\end{proof}

The proof of Lemma~\ref{lemma: KKspecialcase} also indicates that when used to decode KK codes,  Algorithm~\ref{alg: GILinearized} requires finite field multiplications of order  .

\section{List Decoding of MV Codes} \label{sec: generalMV}

In~\cite{mahdavifar_isit10}, the list decoding procedure first constructs a multivariate polynomial  that interpolates through a number of given points as indicated by (\ref{equ: lLinter}). Hence we call this process the interpolation step of the list decoding of MV codes. No specific algorithm is mentioned in~\cite{mahdavifar_isit10} on how to get this multivariate polynomial. Of course, a nonzero solution can be obtained by solving the corresponding homogeneous systems, but with high computational complexity. Here, we utilize the general interpolation over free -modules to solve this problem efficiently. The complexity of our algorithm is compared to that of  solving homogeneous equations.

As in Section~\ref{sec: GeneralGb}, we have to construct a free module for a given ring, and define relative operations so that Algorithm~\ref{alg: GILinearized} can be carried out. We consider an -dimensional MV codes over GF defined in Section~\ref{sec: introMV}, with a message vector length of  and dimension of subspace . In this case, the linearized polynomials ring  is defined over GF, and a set  is selected to form a free -module . Following a similar definition of the multiplication between  and , the module  is constructed in the same way as in Section~\ref{sec: GeneralGb}. Hence an element  can be written as , called a \emph{multivariate linearized polynomial}, where  for .  Following similar process as in the previous section, we can claim that  is also a vector space over GF with a vector space basis . Then we define an total ordering on  as follows. We write  for  and , and write  if  and  for  and . Then  such that  when . Hence we can define the leading monomial and the order of any  in the same way as in Section~\ref{section: GeneralInterpolation}, as well as the minimum elements in a subset of . Finally, a set of linear functionals  for  from  to GF are also defined to be evaluations of multivariate linearized polynomials by the given points, as indicated in (\ref{equ: lLinter}). Here, the total number of points to be interpolated in (\ref{equ: lLinter}) is , hence the numbers of linear functionals  and of the kernels  are . Furthermore, the kernels  are also -submodules by Lemma~\ref{lemma: LxKernels}. In summary, the interpolation problem in~(\ref{equ: lLinter}) is to find a nonzero  such that . Hence this is a general interpolation problem over free -modules, thus can be solved by Algorithm~\ref{alg: GILinearized}, which gives a \textbf{minimum} nonzero solution to (\ref{equ: lLinter}), as stated in the following lemma.
\begin{lemma} \label{lemma: 1Lalg1}
The general interpolation algorithm solves the interpolation problem of the list decoding algorithm for -dimensional MV codes if the dimension of the error .
\end{lemma}
\begin{proof}
As shown in~\cite{mahdavifar_isit10}, when , there exist nonzero solutions for the interpolation step of the list decoding algorithm fir MV codes. Hence we assume , then Algorithm~\ref{alg: GILinearized} solves the interpolation problem by finding a \textbf{minimum} nonzero solution to~(\ref{equ: lLinter}), when we adopt the free modules and related operations as described above.
\end{proof}


For Algorithm~\ref{alg: GILinearized}, we set  for  in the initialization step. The update rules in the intermediate iteration steps are the same as in Section~\ref{sec: GeneralGb}, only that we have to use the new ordering related definitions in this section to determine a minimum among the  candidates.

Finally we discuss the complexity of Algorithm~\ref{alg: GILinearized} when used to decode -dimensional MV codes. As mentioned above, a nonzero multivariate linearized polynomial  can also be obtained by solving the homogeneous system determined by (\ref{equ: lLinter}). The size of the coefficient matrix is . Gaussian elimination has a complexity of  . Given the fact that  (the -degree of  has to be nonnegative), this complexity is . On the other hand, for Algorithm~\ref{alg: GILinearized}, we have  linear functionals in this case and a total of  elements in the basis of the free module, and the highest -degree of the linearized polynomials in  is at most  among all the iterations. Since the linear functional operation and the multiplication between elements in the ring and elements in the module are defined in the same manner as in KK codes case, the complexity of Algorithm~\ref{alg: GILinearized} is of . Hence the general interpolation approach is more efficient when compared to solving linear equations.




\section{Conclusion} \label{sec: conclusion}
In this paper, we investigate the general interpolation problem over free modules of a linearized polynomial ring, and propose a general interpolation algorithm. Our general interpolation algorithm are used to decode Gabidulin codes and KK codes. Comparisons are made between our algorithm for Gabidulin codes and Loidreau's decoding algorithm. Analysis shows that the Sudan-style list-1 decoding algorithm for KK codes is a special case of our general interpolation algorithm. Our general interpolation approach also applies to find the multivariate linearized polynomial in the list decoding of MV codes by Mahdavifar and Vardy, while currently no efficient algorithm is available to accomplish the task.
\bibliographystyle{IEEEtran}
\bibliography{interpolation0102}

\end{document}
