\documentclass[12pt,a4paper]{article}

\usepackage{lineno, hyperref, multirow, amsmath, amssymb, color, mathtools, ulem}
\usepackage[a4paper]{geometry}
\usepackage[ruled]{algorithm2e}

\bibliographystyle{elsarticle-num}

\providecommand{\keywords}[1]
{
  \small	
  \textbf{\textit{Keywords---}} #1
}



\begin{document}

\title{Harmonic Convolutional Networks based on Discrete Cosine Transform}

\author{Matej Ulicny, Vladimir A. Krylov, Rozenn Dahyot}
\date{ADAPT Centre\\School of Computer Science \& Statistics, Trinity College Dublin, Ireland\\School of Mathematical Sciences, Dublin City University, Ireland\\}

\maketitle

\begin{abstract}
\noindent Convolutional neural networks (CNNs) learn filters in order to capture local correlation patterns in feature space. 
We propose to learn these filters as combinations of preset spectral filters defined by the Discrete Cosine Transform (DCT).
Our proposed DCT-based harmonic blocks  replace conventional convolutional layers to produce partially or fully harmonic versions of new or existing CNN architectures. 
Using DCT energy compaction properties, we demonstrate how the harmonic networks can be efficiently compressed  by truncating high-frequency information in harmonic blocks thanks to the redundancies in the spectral domain.
We report extensive experimental validation demonstrating benefits of the introduction of harmonic blocks into state-of-the-art CNN models in image classification, object detection and semantic segmentation applications.
\end{abstract}

\keywords{
Harmonic Network, Convolutional Neural Network, Discrete Cosine Transform, Image Classification, Object Detection, Semantic Segmentation
}


\section{Introduction}\label{sec:introduction}

CNNs have been designed to take advantage of implicit characteristics of natural images, specifically correlation in local neighborhood and feature equivariance.
Standard CNNs rely on learned convolutional filters hence finetuned to the data available. However, it can be advantageous to revert to preset filter banks: for instance, with limited training data~\cite{Ulicny19}, using a  collection of preset filters can help in avoiding overfitting and in reducing the computational complexity of the system.
Scattering networks are examples of such networks with preset (wavelet based) filters  which have achieved state-of-the-art results in handwritten digit recognition and texture classification~\cite{Bruna13}.

We propose instead to replace the standard convolutional operations in CNNs by harmonic blocks that learn the weighted sums of responses to the Discrete Cosine Transform (DCT) filters, see Fig.~\ref{fig:harmlayer}.
\begin{figure}[!h]
\begin{center}
\begin{center}
   \includegraphics[width=0.27\linewidth]{graphics/hblock1.png}
   \includegraphics[width=0.72\linewidth]{graphics/harmonic_block_graphic.png}
\end{center}
\end{center}
\vspace{-.5\baselineskip}
\caption{Left: Design of the harmonic block. 
Boxes show operation type, size of filter (if applicable) and the number of output channels given the block filter size , number of input channels  and output channels . Batch normalization (BN) block is optional. Right: Visualization of the harmonic block applied to an input layer.}
\label{fig:harmlayer}
\end{figure}
DCT has been successfully used for JPEG encoding to transform image blocks into spectral representations to capture the most information with a small number of coefficients.
Motivated by frequency separation and energy compaction properties of DCT, the proposed harmonic networks rely on combining responses of window-based DCT with a small receptive field.
Our method learns how to optimally combine spectral coefficients at every layer to produce a fixed size representation defined as a weighted sum of responses to DCT filters. The use of DCT filters allows one to easily address the task of model compression. 
Other works that propose convolutional filters decomposition to particular basis functions~\cite{Qiu18,Tayyab19} have predominantly focused on network compression. In our study we demonstrate that prior information coming from well chosen filter basis can not only be used to compress but also speeds up training convergence and improves performance.

Based on our earlier works~\cite{Ulicny19b,Ulicny19},  
this paper  contributions are as follows. 
First we demonstrate that the theoretical computational overheads of the optimised formulation of a harmonic block are minimal (experimentally, within 3-7\%) whereas the memory footprint requirements are comparable to those of the benchmark architecture based on standard convolutional blocks (and are lower if harmonic blocks undergo compression). Second, we substantially expand experimental validation to demonstrate a consistent increase in performance due to the use of harmonic blocks. Specifically, on the small NORB dataset we achieve state-of-the-art results and demonstrate how DCT-based harmonic blocks allow one to efficiently generalise to unseen lighting conditions. We further report quantitative as well as qualitative results of application of harmonic blocks to a representative variety of vision tasks: object detection and instance/semantic segmentation. We observe a consistent average improvement of 1\% AP on these tasks, which demonstrates the practical appeal of using harmonic networks.
Section ~\ref{sec:soa} presents the relevant background research to   our harmonic network formulation (Sec.~\ref{sec:method}).
It is extensively validated against state-of-the-art alternatives  for image classification (Sec.~\ref{sec:experiments1}), for object detection, instance and semantic segmentation (Sec.~\ref{sec:experiments.detection}).
All our architectures in the reported results are denoted as \textit{Harm};
the PyTorch implementations for our harmonic networks are publicly available at \url{https://github.com/matej-ulicny/harmonic-networks}.


\section{Related work}
\label{sec:soa}

\subsection{DCT \& CNNs }

Networks trained on DCT coefficients are frequently used in forensics for detection of tampered parts in images. These parts are assumed to have different distribution of DCT coefficients from the rest of the image.
A common practice is to classify histograms of preselected JPEG-extracted DCT coefficients by 1-D or 2-D convolutional network~\cite{Zheng19}.
A number of studies have also investigated the use of spectral image representations for object and scene recognition. 
DCT features from an entire image were used to train Radial Basis Function Network for face recognition~\cite{Er05}. 
A DCT-based scene descriptor was used together with a CNN classifier~\cite{Farinella15}.
A significant convergence speedup and case-specific accuracy improvement have been achieved by applying DCT transform to early stage learned feature maps in shallow CNNs~\cite{Ghosh16} whereas the later stage convolutional filters were operating on a sparse spectral feature  representation. 
In~\cite{Ulicny17,Gueguen18} it was demonstrated how DCT coefficients can be efficiently used to train CNNs for classification, where the DCT coefficients can be computed or taken directly from JPEG image format. 
\textit{Wang et al.}~\cite{Wang16b} compresses CNN filters by separating cluster centers and residuals in their DCT representation. Weights in this form were quantized and transformed via Huffman coding (used for JPEG compression) for limiting storage. Lastly, DCT image representation has been used for calculation of more informative loss function in generative learning~\cite{Atapour19}. 
\subsection{ Wavelets \& CNNs}

\paragraph{Wavelet networks} 
As an alternative to DCT, scattering networks~\cite{Bruna13} are built on complex-valued wavelets.
The scattering network has its filters designed to extract translation and rotation invariant representations.
It was shown to effectively reduce the input representation while preserving discriminative information for training CNN on image classification and object detection task~\cite{Oyallon18b} achieving performance comparable to deeper models. \textit{Williams et al.}~\cite{Williams16} have advocated image preprocessing with wavelet transform, but used different CNNs for each frequency subband. Wavelet filters were also used as a preprocessing method prior to NN-based classifier~\cite{Said16}.

\paragraph{Spectral based CNNs}
Other works have used wavelets in CNN computational graphs. 
Low-frequency components of the Dual-Tree Complex Wavelet transform were used in a noise suppressing pooling operator~\cite{Duan17}. 
\textit{Ripperl et al.} have designed a spectral pooling~\cite{Rippel15} based on Fast Fourier Transform and truncation of high-frequency coefficients. They also proposed to parameterise filters in the Fourier domain to decrease their redundancy and speed up the convergence when training the network. 
The pooled features were recovered with Inverse Discrete Fourier Transform, thus the CNN still operates in the spatial domain.

A Wavelet Convolutional Network proposed by \textit{Lu et al.}~\cite{Lu18} learns from both spatial and spectral information that is decomposed from the first layer features. The higher-order coefficients are concatenated along with the feature maps of the same dimensionality. 
However, contrary to our harmonic networks, Wavelet CNNs decompose only the input features and not the features learned at intermediate stages. 
Robustness to object rotations was addressed by modulating learned filters by oriented Gabor filters~\cite{Luan18}. \textit{Worrall et al.} incorporated complex circular harmonics into CNNs to learn rotation equivariant representations~\cite{Worrall17}. Similarly to our harmonic block, the structured receptive field block~\cite{Jacobsen16} learns new filters by combining fixed filters, a set of Gaussian derivatives with considerably large spatial extent. Additionally, an orthogonal set of Gaussian derivative bases of small spatial extend have been used by \textit{Kobayashi} to express convolutional filters~\cite{Kobayashi18}. DCFNet~\cite{Qiu18} expresses filters by truncated expansion of Fourier-Bessel basis, maintaining accuracy of the original model while reducing the number of parameters. 



\section{Harmonic Networks}\label{sec:method}

A convolutional layer extracts correlation of input patterns with locally applied learned filters. The idea of convolutions applied to images stems from the observation that pixels in local neighborhoods of natural images tend to be strongly correlated. In many image analysis applications, transformation methods are used to decorrelate signals forming an image~\cite{Wang12}. In contrast with spatial convolution with learned kernels, this study proposes feature learning by weighted combinations of responses to predefined filters. The latter extracts harmonics from lower-level features in a region. The use of well selected predefined filters allows one to reduce the impact of overfitting and decrease computational complexity. We focus here on the use of DCT as the underlying transformation.

\subsection{Discrete Cosine Transform} \label{sec:dct}

DCT is an orthogonal transformation method that decomposes an image to its spatial frequency spectrum. A 2D signal is expressed as a sum of sinusoids with different frequencies. The contribution of each sinusoid towards the whole signal is determined by its coefficient calculated during the transformation.
DCT is also a separable transform and due to its energy compaction properties on natural images~\cite{Wang12} it is commonly used for image and video compression in widely used JPEG and MPEG formats. Note that Karhunen-Lo{\`e}ve transform (KLT) is considered to be optimal in signal decorrelation, however it transforms signal via unique basis functions that are not separable and need to be estimated from the data. On locally correlated signals such as natural images DCT was shown to closely approximate KLT~\cite{Wang12}.

We use the most common DCT formulation, noted DCT-II,  computed on a 2-dimensional grid of an image  of size  representing the image patch with 1 pixel discretisation step:

 is  the DCT coefficient  of the input  using a sinusoid with horizontal and vertical frequencies noted   and  respectively. Basis functions are typically normalized with factors  (resp. ) when  (resp. when )   and  (resp. ) otherwise to ensure their orthonormality. 


\subsection{Harmonic blocks}

We propose the harmonic block  to replace a conventional convolutional operation hence relying on processing the data in two stages (see Fig.~\ref{fig:harmlayer}). Firstly, the input features undergo harmonic decomposition using window-based DCT. 
In the second stage, the transformed signals are combined by learned weights. 
The fundamental difference from standard convolutional network is that the optimization algorithm is not searching for filters that extract spatial correlation, rather learns the relative importance of preset feature extractors (DCT filters) at multiple layers.

Harmonic blocks are integrated as a structural element in the existing or new CNN architectures. We thus design harmonic networks that consist of one or more harmonic blocks and, optionally, standard learned convolutions and fully-connected layers, as well as any other structural elements of a neural net.
Spectral decomposition of input features into block-DCT representation is implemented as a convolution with DCT basis functions. A 2D kernel with size  is constructed for each basis function, comprising a filter bank of depth , which is separately applied to each of the input features. Convolution with the filter bank isolates coefficients of DCT basis functions to their exclusive feature maps, creating a new feature map per each channel and each frequency considered. The number of operations required to calculate this representation can be minimized by decomposing 2D DCT filter into two rank-1 filters and applying them as separable convolution to rows and columns sequentially. 

Each feature map  at depth  is computed as a weighted linear combination of DCT coefficients across all input channels :

where  is a  frequency selective DCT filter of size ,  the 2-dimensional convolution operator and  is learned weight for  frequency of the -th feature. The linear combination of spectral coefficients is implemented via a convolution with  filter that scales and sums the features, see Fig.~\ref{fig:harmlayer}.
In our implementation we use a fixed collection of DCT bases. Specifically, if we are to replace a  convolution layer, the DCT filter bank  has filters defined for every filter coordinate  as given in Eq.~\ref{eq:dct}.
Since the DCT is a linear transformation, backward pass through the transform layer is performed similarly to a backward pass through a convolution layer. Harmonic blocks are designed to learn the {\it same} number of parameters as their convolutional counterparts. Such blocks can be considered a special case of depth-separable convolution with predefined spatial filters. 

DCT is distinguished by its energy compaction capabilities which typically results in higher filter responses in lower frequencies. The behaviour of relative loss of high frequency information can be efficiently handled by normalizing spectrum of the input channels. This can be achieved via batch normalization that adjusts per frequency mean and variance prior to the weighted combination. The spectrum normalization transforms Eq.~\eqref{eq:feature} into: 

with parameters  and  estimated per input batch.

\subsection{Harmonic Network Compression} \label{sec:method.subsample}


The JPEG compression encoding relies on stronger quantisation of higher frequency DCT coefficients. This is motivated by the human visual system which often prioritises low frequency information over high frequencies. We propose to employ similar idea in the harmonic network architecture. Specifically, we limit the visual spectrum of harmonic blocks to only several most informative low frequencies, which results in a reduction of number of parameters and operations required at each block. The coefficients are (partially) ordered by their relative importance for the visual system in triangular patterns starting at the most important zero frequency at the top-left corner, see Fig.~\ref{fig:filters}. We limit the spectrum of considered frequencies by hyperparameter  representing the number of levels of coefficients included perpendicularly to the main diagonal direction starting from zero frequency: DC only for , three coefficients used for , and six coefficients used for .
Fig.~\ref{fig:filters} illustrates filters used at various levels assuming a  receptive field.
\begin{figure}[t]
\begin{center}
   \includegraphics[width=.8\linewidth]{graphics/dct_filters1.png}
\end{center}
\vspace{-.5\baselineskip}
   \caption{  DCT filter bank employed in the harmonic networks and its compression.}
\label{fig:filters}
\end{figure} 
Thus, reformulating convolutional layers as harmonic allows one  to take advantage of this natural approach to model compression, and in doing also introduce additional regularization into the model. The empirical impact of harmonic model compression is  investigated experimentally in more details Sections \ref{sec:experiments1} and \ref{sec:experiments.detection}.

\subsection{Overlapping cosine transform} \label{sec:overlap_dct}

DCT computed on overlapping windows is also known as Lapped Transform or Modified DCT (MDCT), related to our harmonic block using strides. The overlapped DCT has a long history in signal compression and reduces artefacts at window edges~\cite{Malvar90}. Dedicated strategies for efficient computations have been proposed~\cite{Malvar90}, including algorithms and hardware optimisations. DCT is equivalent to the discrete Fourier transform of real valued functions with even symmetry within twice larger window. DCT lacks imaginary component given by the sine transform of real valued odd functions. However, harmonic block allows convolution with DCT basis with an arbitrary stride, creating redundancy in the representation. Ignoring the boundary limitations, sine filter basis can be devised by shifting the cosine filters. Given the equivariant properties of convolution, instead of shifting the filters the same result is achieved by applying original filters to the shifted input. Considering DCT-II formulation for 1D signal  with  values, the DCT coefficient at frequency  is:

a corresponding sine transform is

which is equivalent to

The shift given by  for any  can be directly converted to shift in pixels applied to data . After simplification, sine transform can be expressed as 
which is equivalent to the cosine transform of the image shifted by  defined in~\eqref{eq:dct_shifted_data}. 

This value represents the stride to shift the cosine filters to capture correlation with sine function. 
In other words, by applying DCT with a certain stride it is possible to obtain the feature representation as rich as that obtained with the full Fourier transform.

\subsection{Computational Requirements} \label{sec:methodrequirements}

Harmonic blocks are designed to learn the same number of parameters as their convolutional counterparts. Requirements for the DCT transform scale linearly with the number of input channels and result in a modest increase to the theoretical number of operations. Standard convolutional layer used in many popular architectures that has  input and  output channels with a kernel size  learns  parameters and performs  operations if the filter is applied  and  times in particular directions. Harmonic block with  transformation filters of size  upsamples representation to  features and then learns one weight for each upsampled-output feature pair hence  weights. Transformation of an  feature set costs  on top of weighted combination  that matches the number of multiply-add operations of  convolution. The total number of operations is thus . The theoretical number of multiply-add operations over the standard convolutional layer increases by a factor of . If we assume truncated spectrum (use of ) given by  filters, proportion of operations becomes .

While keeping the number of parameters intact, a harmonic block requires additional memory during training and inference to store transformed feature representation. In our experiments with WRN models (Sec.\ref{sec:experiments.cifar}), the harmonic network trained with full DCT spectrum requires almost 3 times more memory than the baseline.
This memory requirement can be reduced by using the DCT spectrum compression.

Despite the comparable theoretical computational requirements, the run time of harmonic networks is larger compared to the baseline models, at least twice slower (on GPU) in certain configurations. This effect is due to generally less efficient implementation of separable convolution and the design of harmonic block that replaces a single convolutional layer by a block of 2 sequential convolutions (with individual harmonic filters and 1x1 convolution). Most blocks do not need BN between the convolutions and thus represent a combined linear transformation. The associativity property of convolutions allows one to reformulate the standard harmonic block defined above so that the DCT transform and linear combination can be effectively merged into a single linear operation:

In other words, equivalent features can be obtained by factorizing filters as linear combinations of DCT basis functions. We thus propose a faster Algorithm~\ref{alg:mem_eff_harm_block} that is a more memory efficient alternative to the standard two-stage harmonic block formulation and uses dense convolution. 

\begin{algorithm}[t]
 \KwIn{}
 {Define updates} \;
 \For{}{
  \For{}{
   \;
  }
 }
 \;
 \KwOut{}
 \caption{Memory efficient harmonic block} 
 \label{alg:mem_eff_harm_block}
\end{algorithm}
The Algorithm~\ref{alg:mem_eff_harm_block} overhead in terms of multiply-add operations with respect to the standard convolutional layer is only , where the input image size for the block is . The experimental performance of the algorithm is evaluated in Section~\ref{sec:experiments.cifar}. 



\section{Image Classification } 
\label{sec:experiments1}

The performance of the harmonic networks is assessed for image classification  on small (NORB, Sec. \ref{sec:experiments.norb}), medium (CIFAR-10 and CIFAR-100, Sec \ref{sec:experiments.cifar}) and large (ImageNet-1K, Sec. \ref{sec:experiments.imagenet}) scale datasets.

\subsection{Small NORB dataset} \label{sec:experiments.norb}

The small NORB dataset~\cite{Lecun04} is a synthetic set of  binocular images of 50 toys sorted into 5 classes (four-legged animals, human figures, airplanes, trucks, and cars), captured under different lighting and pose conditions (i.e. 18 angles, 9 elevations and 6 lighting conditions induced by combining different light sources). Training  and test sets used in our experiments are retained original~\cite{Lecun04}.
We show first that harmonic networks outperform standard and state-of-the-art CNNs in both accuracy and compactness (c.f. Section \ref{sec:norb:comparison}) and also illustrate how Harmonic networks can be naturally resilient to unseen illumination changes without resorting to using data augmentation (Sec. \ref{sec:norb:illumination}).

\subsubsection{Comparisons CNN vs. Harmonic Nets}
\label{sec:norb:comparison}

\vskip .1cm
\noindent{\bf Baseline architectures.} 
Our baseline CNN2 consists of 2 convolution and 2 fully-connected layers. Features are subsampled by convolution with stride and overlapping max-pooling. All hidden layer responses are batch normalized and rectified by ReLU. We also use a slightly deeper network CNN3 with an additional convolutional layer preceding the first pooling. Details of the architectures are summarised in Table~\ref{tab:norb_nn}. 

\noindent{\bf Optimisation.}
The baseline CNNs are trained with stochastic gradient descent for 200 epochs with momentum 0.9 and weight decay 0.0005. The initial learning rate 0.01 is decreased by factor 10 every 50 epochs. The network is trained with batches of 64 stereo image pairs, each pair is zero-padded 5 pixels and a random crop of 9696 pixels is fed to the network.


\begin{table}[!t]
\tabcolsep = 1.0mm
\begin{center}
\caption{Models used in NORB experiments.
Convolution and harmonic operation are denoted as \{conv, harm\}~M,KK/S with M output features, kernel size K and stride S; similarly for pooling~KK/S and fully connected layers~fc~M.}
\vspace{0.3\baselineskip}
\label{tab:norb_nn}
\footnotesize
\begin{tabular}{cccccc}
\hline
\textbf{Resol.} & \textbf{CNN2} & \textbf{CNN3} & \textbf{Harm-CNN2}& \textbf{Harm-CNN3 }& \textbf{Harm-CNN4}\\
\hline
96x96 & conv 32, 5x5/2 & conv 32, 5x5/2 & harm 32, 4x4/4 & harm 32, 4x4/4 & harm 32, 4x4/4\\
48x48 & pool 3x3/2 & conv 64, 3x3/2 & - & - & - \\
24x24 & conv 64, 3x3/2 & pool 2x2/2 & harm 64, 3x3/2 & harm 64, 3x3/2& harm 64, 3x3/2 \\
12x12 & pool 3x3/2 & conv 128, 3x3/2 &  pool 3x3/2&pool 3x3/2&pool 3x3/2\\
6x6 & fc 1024 & pool 2x2/2 & fc 1024 & harm 128, 3x3/2 & harm 128, 3x3/2 \\
3x3 & - & fc 1024 & - & fc 1024 & harm 1024, 3x3/3 \\
1x1 & dropout 0.5 & dropout 0.5 & dropout 0.5& dropout 0.5& dropout 0.5\\
1x1 & fc 5 & fc 5 & fc 5& fc 5& fc 5\\
\hline
\end{tabular}
\end{center}
\end{table}

\noindent{\bf Harmonic Networks architectures.} Several versions of harmonic networks are considered (Tab. \ref{tab:norb_nn}), by substituting the first, first two or all three of CNN2 and CNN3 convolution layers by harmonic blocks. Furthermore, the first fully-connected layer can be transformed to a harmonic block taking global DCT transform of the activations. The first harmonic block uses 4 DCT filters, the further blocks mimic their convolutional counterparts.

\vskip .1cm
\noindent{\bf Performance evaluation.} The baseline CNN architecture shows poor generalization performance in early stages of training, see Fig.~\ref{fig:norb_convergence}. Baseline CNN2 achieved mean error 3.48\%0.50 from 20 trials, while CNN2 utilizing harmonic blocks without explicit normalization of harmonic responses exhibits similar behavior resulting in lower mean error of 2.40\%0.39. Normalizing DCT responses at the first block prevents harmonic network from focusing too much on pixel intensity, allows using 10 higher learning rate, significantly speeds up convergence, improves performance and stability. 
\begin{figure}[t]
\begin{center}
   \includegraphics[width=.6\linewidth]{graphics/norb_convergence.png}
\end{center}
\vspace{-1.5\baselineskip}
\caption{Mean classification error on small NORB test set. Weak generalization of CNN (green) and harmonic network (blue) is observed during the early stages of training. Filled areas (best seen in color) show 50\% empirical confidence intervals from 20 runs. Batch normalization of DCT spectrum (first block) significantly speeds up convergence of harmonic network (red).}
\label{fig:norb_convergence}
\end{figure}
All variants of the harmonic network perform comparably.
Particularly we observe the overlapping average pooling to work well in combination with harmonic blocks. The best result was obtained by the Harm-CNN4 model with 4 harmonic blocks (the latter replaces the fully-connected layer), misclassifying only 1.10\%0.16 of test samples.


\vskip .1cm
\noindent{\bf Comparison with state-of-the-art.} Table~\ref{tab:norb_state_of_art} shows that these results surpass the best previously reported error rate for this dataset to the best of our knowledge. The capsule network~\cite{Hinton18} claims 1.4\% error rate, however estimated under a different evaluation protocol.

\begin{table}[h]
\begin{center}
\caption{Comparison with the state-of-the-art on small NORB dataset, showing the proposed method outperforms other reported results.} 
\label{tab:norb_state_of_art}
\vspace{0.3\baselineskip}
\begin{tabular}{ l c c c c }
\hline
\textbf{Method} & \textbf{Parameters}  & \textbf{Error \%}  \\
\hline
CNN3 & 1.28M & 3.43  0.31 \\
CapsNet~\cite{Hinton18} multi-crop & 310K & 1.4* \\
\hline
Harm-CNN2 & 2.39M & 1.56  0.18 \\
Harm-CNN3 & 1.28M & 1.15  0.22 \\
Harm-CNN4 & 1.28M & \textbf{1.10  0.16} \\
\hline
\end{tabular}\.05cm]
*scores reported by~\cite{Luan18}.
\end{center}
\end{table}

\begin{figure}[!b]
\begin{center}
   \includegraphics[width=.9\linewidth]{graphics/freq_heatmap.png}
\end{center}
\vspace{-.25\baselineskip}
\caption{Distribution of weights (averaged in each layer) assigned to DCT filters in the first harmonic block (left-most) and the remaining blocks in the Harm-WRN-28-10 model trained on CIFAR-10. Vertical lines separate the residual blocks.}
\label{fig:freq_heatmap}
\end{figure}

\begin{figure*}[!t]
\begin{center}
   \includegraphics[width=.49\linewidth]{graphics/cifar10_graph.png}
   \includegraphics[width=.49\linewidth]{graphics/cifar100_graph.png}
\end{center}
\vspace{-1.25\baselineskip}
\caption{Decrease of classification error as a function of model size on CIFAR-10 (left) and CIFAR-100 (right). Parameters of harmonic networks are controlled by the compression parameter , the WRN baselines by the width multiplier {\it w}.}
\label{fig:compression_graph}
\end{figure*}

Analysis of fully harmonic WRN weights learned with 3x3 spectrum revealed that the deeper layers tend to favour low-frequency information over high frequencies when learning representations. Relative importance of weights corresponding to different frequencies shown in Fig.~\ref{fig:freq_heatmap} motivates truncation of high-frequency coefficients for compression purposes. While preserving the input image spectrum intact, we train the harmonic networks on limited spectrum of hidden features for =2 and =3 using 3 and 6 DCT bases respectively. 
To assess the loss of accuracy associated with parameter reduction we train baselines with reduced widths having comparable numbers of parameters: WRN-28-8 and WRN-28-6, see Fig.~\ref{fig:compression_graph}. Fully harmonic WRN-28-10 with =3 has comparable error to the network using the full spectrum and outperforms the larger baseline WRN-28-10, showing almost no loss in discriminatory information. On the other hand Harm-WRN-28-10 with =2 is better on CIFAR-100 and slightly worse on CIFAR-10 compared to the similarly sized WRN-28-6. The performance degradation indicates that some of the truncated coefficients carry important discriminatory information.

We further compare performance with the Gabor CNN 3-28~\cite{Luan18} that relies on modulating learned filters with Gabor orientation filters. To operate on a similar model we remove dropouts and reduce complexity by applying progressive : no compression for filters on 32x32 features, =3 for 16x16, and =2 for the rest. With a smaller number of parameters the Harm-WRN-28-10 performs similarly on CIFAR-10 and outperforms Gabor CNN on CIFAR-100.

\vskip .1cm
\noindent{\bf Harmonic block implementations.}
Here we compare the standard harmonic block implementation with its memory efficient version introduced in Algorithm~\ref{alg:mem_eff_harm_block}, see Table~\ref{tab:alg_req}. The comparison on CIFAR-10 dataset demonstrates that Algorithm~\ref{alg:mem_eff_harm_block} provides similar overall performance but reduces both the runtime and memory requirements nearly three times. We will therefore use solely this implementation of the harmonic block except for the root (first) layer due to the use of BN on that first layer.


\begin{table}[b]
\caption{Modifications of the WRN-16-4 baseline on CIFAR-100: mean classification errors and standard deviations from 5 runs when replacing particular layers by harmonic blocks.} \label{tab:ablation}
\vspace{0.3\baselineskip}
\centering
\begin{tabular}{ c c c c }
 \hline
 \textbf{Root block} & \textbf{Harmonic root BN} & \textbf{Residual blocks} & \textbf{Error \%}  \\
 \hline
 & & & 24.07  0.24 \\
 \checkmark & & & 23.79  0.24 \\
 \checkmark & \checkmark & & 23.67  0.12 \\
 & & \checkmark & 23.22  0.28 \\
 \checkmark & & \checkmark & 23.25  0.25 \\
 \checkmark & \checkmark & \checkmark & 23.21  0.11 \\
 \hline
\end{tabular}
\end{table}

\vskip .1cm
\noindent{\bf Ablation study.}
The effect of filter parametrisation by DCT bases is investigated by replacing particular layers of WRN-16-4 (w/o dropout) with harmonic blocks, see Table~\ref{tab:ablation}. 
We consider replacing the root convolution layer (with or without BN), or layers in residual blocks. Replacing each layer has provided the greatest improvement, while BN in the first block decreases the variance by half.
These observations correspond to the results obtained on NORB dataset. We will always be employing BN as part of the root harmonic block.

\vskip .1cm
\noindent{\bf Compressing existing models.}
Section~\ref{sec:method.subsample} described how convolutional filters in certain layer can be approximated with fewer parameters. So far we have only considered uniform coefficient truncation by truncating the same frequencies in all the layers, or a simple progressive compression. This scheme omits higher number of frequencies in deeper layers, but the same subset of coefficients is used in all harmonic blocks applied to feature maps of a particular size. A better compression-accuracy trade-off can be achieved by using more elaborate coefficient selection at each layer. In this experiment we start with the WRN-28-10 baseline trained without dropout which has been converted to harmonic WRN-28-10 net (omitting BN in the first harmonic block) by re-expressing each 33 filter as a combination of DCT basis functions. The first harmonic block is kept intact (no compression in DCT representation), while all other blocks are compressed. We compare three different coefficient selection strategies:\begin{itemize}
    \item \textit{Uniform selection}: at every layer the same  is used;\item \textit{Progressive selection}: the level of compression is selected based on the depth of the layer  for  or , constant , and  is the size of filter ( corresponds to no compression);\item \textit{Adaptive selection}: the compression level is selected adaptively for each layer; the filter is excluded if its  compared to the other frequencies in the same layer is too low. Specifically, if  then the coefficient is truncated.\end{itemize}
The results reported in Fig.~\ref{fig:compression_types} confirm the behavior observed in Fig.~\ref{fig:freq_heatmap}, i.e. the high frequencies appear to be more relevant in the early layers of the network compared to deeper layers. The uniform compression discards the same amount of information in all the layers, and is surpassed by the other compression strategies. By using progressive or adaptive coefficient selection a model can be compressed by over 20\% without a loss in accuracy. The best progressive method loses less than 1\% of accuracy when compressed by 45\% without a need for finetuning. 

\begin{figure}
\begin{center}
  \includegraphics[width=.6\linewidth]{graphics/compression_types}
\end{center}
\vspace{-.5\baselineskip}
\caption{Accuracy of compressed WRN-28-10 on CIFAR-100 dataset using different coefficient truncation strategies.}
\label{fig:compression_types}
\end{figure}

\subsection{ImageNet dataset} 
\label{sec:experiments.imagenet}

We present here results obtained on ImageNet-1K classification task.
ResNet~\cite{He16} with 50 layers is adopted as the baseline. 
To reduce memory consumption maxpooling is not used, instead the first convolution layer employs stride 4 to produce equally-sized features; we refer to this modification as ResNet-50 (no maxpool). The following harmonic modifications refer to this baseline without maxpooling after the first layer. We investigate the performance of three harmonic modifications of the baseline: (i) replacing solely the initial 7x7 convolution layer with harmonic block (with BN) with 7x7 DCT filters, (ii) replacing all convolution layers with receptive field larger than 1x1 with equally-sized harmonic blocks, (iii) compressed version of the fully-harmonic network.
The models are trained as described in~\cite{Ulicny19b}, and here we report accuracy after 100 epochs.

\begin{table}[h]
\caption{Classification errors on ImageNet validation set using central crops.} 
\label{tab:imagenet_spec}
\vspace{0.3\baselineskip}
\centering
\begin{tabular}{ l c c c }
\hline
 \textbf{Model} & \textbf{Parameters}  & \textbf{Top-1 \%}  & \textbf{Top-5 \%}  \\
\hline
 VGG16-BN & 138.4M & 25.86 & 8.05 \\
 Harm-VGG16-BN & 138.4M & 25.55 & 8.01 \\
 ResNet-50 (no maxpool) & 25.6M & 23.83 & 7.01 \\
 Harm1-ResNet-50 & 25.6M & 23.01 & \textbf{6.47} \\
 Harm-ResNet-50 & 25.6M & \textbf{22.98} & 6.64 \\
 Harm-ResNet-50, progr.  & 19.7M & 23.21 & 6.67 \\
 Harm-ResNet-101 & 44.5M & 21.45 & 5.78 \\

\hline
{\bf Benchmarks}\\
 ResNet-50 (maxpool)~\cite{ResNetPyTorch} & 25.6M & 23.87 & 7.14 \\
 ScatResNet-50~\cite{Oyallon18b} & 27.8M & 25.5 & 8.0 \\
 JPEG-ResNet-50~\cite{Gueguen18} & 28.4M & 23.94 & 6.98 \\
 ResNet-101 (maxpool)~\cite{ResNetPyTorch} & 44.5M & 22.63 & 6.45 \\
\hline
\end{tabular}
\end{table}

\begin{table}[h]
\caption{Performance of the converted harmonic networks (error on ImageNet).} 
\label{tab:imagenet_spec2}
\vspace{0.3\baselineskip}
\small
\centering
\tabcolsep = 1.5mm
\begin{tabular}{ lclcc }
\hline
\textbf{Training} & \textbf{Epochs} & \textbf{Model} & \textbf{Top-1\%} & \textbf{Top-5\%} \\
\hline
full & 90 & ResNet-50 (no maxpool) & 24.36 & 7.33 \\
finetuned & 90+5 & ResNet-50 (no maxpool) & 24.34 & 7.30 \\
\hline
finetuned & 90+5 & ResNet-50\,\,Harm-ResNet-50 & 24.06 & 7.12 \\
finetuned & 90+5 & ResNet-50\,\,Harm-ResNet-50, progr.  & 24.62 & 7.44 \\
\hline
\end{tabular}
\end{table}


\begin{figure}[h]
\begin{center}
   \includegraphics[width=0.48\linewidth]{graphics/imagenet_curve}\;\;
   \includegraphics[width=0.48\linewidth]{graphics/imagenet_curve_zoom}
\end{center}
\vspace{-.5\baselineskip}
   \caption{Training of harmonic networks on ImageNet classification task. Left: comparison with the baseline showing validation error (solid line) and training error (dashed). Right: last 40 epochs of training for all the ResNet-50 based models including scores reported for the benchmark models.
   }
\label{fig:imagenet_curve}
\end{figure}

Table~\ref{tab:imagenet_spec} reports error rates on ImageNet validation set using central 224224 crops from images resized such that the shorter side is 256.
All three harmonic networks have similar performance and improve over the baseline by  in top1 and  in top5 accuracy. We observe similar progress of the three modifications during training, see Fig.~\ref{fig:imagenet_curve}. ResNet-50 architecture has 17 layers with spatial filters which correspond to 11M parameters. We reduce this number by using progressive  compression: =3 on 14x14 features and =2 on the smallest feature maps. This reduces the number of weights roughly by half, in total by about 23\% of the network size. The compressed network loses almost no accuracy and still clearly outperforms the baseline.
Even with compression the proposed Harm-ResNet-50 confidently outperforms the standard ResNet-50 (maxpool), as well as the ScatResNet-50~\cite{Oyallon18b} and JPEG-ResNet-50~\cite{Gueguen18}.
Furthermore, we also observe a substantial improvement of 1.15 in top-1 error \% associated with the introduction of harmonic blocks into a deeper ResNet-101. 

\begin{table}[h]
\centering
\caption{GPU training memory requirements and speed of harmonic block implementations on CIFAR-10 and ImageNet. All ImageNet models use harmonic blocks based on Alg.~\ref{alg:mem_eff_harm_block}. Values are measured on Nvidia RTX6000 using batch size 128.} \label{tab:alg_req}
\vspace{0.3\baselineskip}
 \begin{tabular}{lcccc}
  \hline
  \multirow{2}{*}{\textbf{Model}} & {\bf GPU}  & \multicolumn{2}{c}{\bf Images/s }  & \multirow{2}{*}{{\bf Error \%}}  \\
 &  {\bf memory} & {\bf train.} & {\bf infer.} & \\
  \hline
  {\bf CIFAR-10} \\
  WRN-28-10~\cite{Zagoruyko16} & 4.6GB & 606.4 & 1876.9 & 3.89 \\
  Harm-WRN-28-10 (non-optimized) & 14.1GB & 211.0 & 600.4 & 3.71 \\
  Harm-WRN-28-10 (Alg.~\ref{alg:mem_eff_harm_block}) & 4.8GB & 573.3 & 1736.5 & 3.78 \\
  \hline
  {\bf ImageNet} \\
  ResNet-50 (no maxpool) & 11.2GB & 306.2 & 820.5  & 23.83 \\
  ResNet-50 (maxpool) & 12.1GB & 292.9 & 790.1 & 23.87 \\
  Harm-ResNet-50 & 11.4GB & 296.3 & 766.5 & 22.98 \\
  ResNet-101 (maxpool) & 17.4GB & 174.1 & 526.7 & 22.63 \\
  Harm-ResNet-101 & 16.9GB & 174.4 & 507.9 & 21.45 \\
  \hline
 \end{tabular}
\end{table}

We validate the use of harmonic blocks on an architecture without residual connections as well, specifically the VGG16~\cite{Simonyan14} architecture with BN layers. Harm-VGG16-BN, obtained by replacing all convolutional layers by harmonic blocks yields an improvement of 0.8\% in top-1 classification error. This demonstrates that the improvement is not limited to residual-based architectures. 

Finally, we evaluate conversion of weights of a pretrained non-harmonic network to those of its harmonic version. Each learned filter in the pretrained baseline (ResNet-50 without maxpooling after 90 epochs of training) is transformed into DCT domain, skiping BN inside the first harmonic block. The direct conversion resulted in the exact same numerical performance due to the basis properties of DCT.
We then finetune the converted model for another 5 epochs with the learning rate of 0.001, which results in the top1 (top5) performance improvement of 0.21\% (0.19\%) over the pretrained baseline, see Table~\ref{tab:imagenet_spec2}. We also investigate the conversion to a harmonic network with progressive  compression. After casting the pretrained filters into the available number of DCT filters (from full basis at the early layers to 3 out of 9 filters at the latest layers), the top1 performance degrades by 6.3\% due to loss of information. However, if we allow finetuning for as few as 5 epochs the top1 (top5) accuracy falls 0.24\% (0.09\%) short of the baseline, while reducing the number of parameters by 23\%. This analysis shows how the harmonic networks can be used to improve the accuracy and/or compress the existing pretrained CNN models.


\begin{table}[h]
\caption{SE-ResNeXt networks: harmonic vs. baseline errors and comparison with the state of the art on ImageNet.} \label{tab:resnext}
\vspace{0.3\baselineskip}
\small
\centering
\tabcolsep = 1.2mm
\begin{tabular}{lccccccc}
 \hline
 \multirow{2}{*}{\textbf{Model}} & \multirow{2}{*}{\textbf{Param}} & \multicolumn{3}{c}{\textbf{224224}} & \multicolumn{3}{c}{\textbf{320320 / 331331}} \\
& & \textbf{FLOPS} & \textbf{Top-1} & \textbf{Top-5} & \textbf{FLOPS} & \textbf{Top-1} & \textbf{Top-5} \\
 \hline
 {\bf ResNeXt-101 (RNX):} \\
 RNX (64x4d)~\cite{Xie17} & 83.6M & 15.5B & 20.4 & 5.3 & 31.5B & 19.1 & 4.4 \\
 SE-RNX(32x4d) & 49.0M & 8.0B & 19.73 & 4.90 & 16.3B & 18.49 & 4.05 \\
 Harm-SE-RNX(32x4d) & 49.0M & 8.1B & 19.39 & 4.73 & 16.5B & 18.48 & 4.06 \\
 Harm-SE-RNX(64x4d) & 88.2M & 15.4B & \textbf{18.37} & \textbf{4.34} & 31.4B & \textbf{17.15} & \textbf{3.56} \\
 \hline
 {\bf Benchmarks}\\
 PolyNet~\cite{Hu19} & 92M & - & - & - & 34.7B & 18.71 & 4.25 \\
 DualPathNet-131~\cite{Hu19} & 79.5M & 16.0B & 19.93 & 5.12 & 32.0B & 18.55 & 4.16 \\
 SENet-154~\cite{Hu19} & 145.8M & 20.7B & \textbf{18.68} & \textbf{4.47} & 42.3B & 17.28 & 3.79 \\
 NASNet-A~\cite{Real19} & 88.9M & - & - & - & 23.8B & 17.3 & 3.8 \\
 AmoebaNet-A~\cite{Real19} & 86.7M & - & - & - & 23.1B & 17.2 & 3.9 \\
 PNASNet-5~\cite{Real19} & 86.1M & - & - & - & 25.0B & 17.1 & 3.8  \\
 EfficientNet-B7*~\cite{Tan19} & 66M & - & - & - & 37B & \textbf{15.6} & \textbf{2.9} \\
 \hline
\end{tabular}\.05cm]
*scores reported by~\cite{mmdet}.
\end{table}

The state-of-the-art detectors rely on a cascade of detection heads with progressively increasing IoU thresholds, which refines the bounding boxes and thus improves localization accuracy~\cite{Cai18}. In Table~\ref{tab:cascade},  we  report comparisons achieved with the Cascade R-CNN architecture, trained using the 20-epoch schedule suggested in~\cite{Cai18}. The use of our harmonic ResNet-101 provides a  1.0 AP improvement for object detection similar to Faster \& Mask R-CNNs, and it also improves instance segmentation AP by 0.7 (see Table~\ref{tab:cascade}). Moreover, a similar improvement of 1.1 AP is observed for   hybrid task cascade R-CNN~\cite{Chen19} that alters the mask refinement procedure and exploits semantic segmentation information to incorporate additional contextual information.

\begin{table}[h]
\caption{Mean average precision on Cascade R-CNN architecture on MS COCO 2017 validation set. All backbones are transformed to FPNs.} \label{tab:cascade}
\vspace{0.3\baselineskip}
\centering
\begin{tabular}{ lccc }
 \hline
 \textbf{Cascade R-CNN Backbone} & \textbf{Type} & \textbf{Box AP}  & \textbf{Mask AP}  \\
 \hline
 ResNet-101 & Faster & \hspace{.4ex} 42.5* & - \\
 Harm-ResNet-101 & Faster & 43.5 &  - \\
 \hline
 ResNet-101 & Mask & \hspace{.4ex} 43.3* & \hspace{.4ex} 37.6* \\
 Harm-ResNet-101 & Mask & 44.3 & 38.3 \\
 \hline
 ResNet-101 & Hybrid & \hspace{.4ex} 44.9* & \hspace{.4ex} 39.4* \\
 Harm-ResNet-101 & Hybrid & {\bf 46.0} & {\bf 40.2}  \\
 \hline
\end{tabular}\.05cm]
   \includegraphics[width=0.24\linewidth]{graphics/segmentations/351_image.png}
   \includegraphics[width=0.24\linewidth]{graphics/segmentations/351_target.png}
   \includegraphics[width=0.24\linewidth]{graphics/segmentations/351_overlay_base.png}
   \includegraphics[width=0.24\linewidth]{graphics/segmentations/351_overlay_harm.png}\.05cm]
   \includegraphics[width=0.24\linewidth]{graphics/segmentations/1173_image.png}
   \includegraphics[width=0.24\linewidth]{graphics/segmentations/1173_target.png}
   \includegraphics[width=0.24\linewidth]{graphics/segmentations/1173_overlay_base.png}
   \includegraphics[width=0.24\linewidth]{graphics/segmentations/1173_overlay_harm.png}\-.25cm]
   \setlength{\unitlength}{1cm}
   \begin{picture}(12,0.65)
     \put(0,0){Original}
     \put(3.2,0){Annotation}
     \put(6.9,0){DeepLabV3}
     \put(10.0,0){Harm-DeepLabV3}
   \end{picture}
\vspace{-.5\baselineskip}
   \caption{\small Examples of semantic segmentation on Pascal VOC 2012 validation images. The first 4 rows show where harmonic network is more successful than the baseline, while the last row displays case where it fails. DeepLabV3 with ResNet-101 backbone is used.}
\label{fig:segmentations}
\end{figure}

\section{Conclusion} \label{sec:conclusion}

We have presented a novel approach to explicitly incorporate spectral information extracted via DCT into CNN models. 
We have empirically evaluated the use of our harmonic blocks with the well-established state-of-the-art CNN architectures, and shown that our approach  improves results for a range of applications including image classification (0.7-1.2\% accuracy on ImageNet), object detection (0.7-1.1 AP on Pascal VOC and MS COCO) and semantic segmentation (1.1\% IoU on Pascal VOC). 
We further establish that the memory footprint of harmonic nets is similar and the computational complexity increases only slightly when compared to the standard convolutional baseline architectures.
We ascertain that harmonic networks can be efficiently set-up by converting the pretrained CNN baselines. 
The use of DCT allows one to order the harmonic block parameters by their significance from the most relevant low frequency to less important high frequencies. This enables efficient model compression by parameter truncation with only minor degradation in the model performance. Current efforts aim at investigating robustness of harmonic networks and at compressing weights according to correlations across filters in depth direction.


\section*{Acknowledgements}
This research was supported by the ADAPT Centre for Digital Content Technology funded under the SFI Research Centres Programme (Grant 13/RC/2106) and co-funded under the European Regional Development Fund. 
We gratefully acknowledge the support of NVIDIA Corporation with the donation of GPUs.

\bibliography{biblio}

\end{document}