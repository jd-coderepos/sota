\section{Experimental Results}
\label{sec:exp_results}

We implemented our algorithm on different hardware platforms being
connected via different communication channels. Thereby we had to deal
with several restrictions, from very limited memory to the lack of
access to the hardware, because the used OS did not provide such
functionality. Nevertheless, we got adequate results for our
application scenarios.

\subsection{Implementation}

We had two hardware platforms available for the implementation of our
algorithm. First, a tiny Atmel Atmega48~\cite{atmega48} with only 4 kB
of ROM and 512 bytes of RAM. It had also to run other applications, so
that there was only a very limited amount of memory available for the
synchronization process. Second, we used the iSense
platform~\cite{buschmann07isense} which is equipped with Jennic
microcontrollers~\cite{jennic}. These nodes provide a IEEE 802.15.4
compliant radio, and were already obtained with a running firmware
that was used for our implementation. It is an event-driven firmware,
and provides the registration of two types of callbacks: so-called
timeouts which run in interrupt context, and user tasks for
low-priority processing. User tasks can be only executed one after the
other---without the possibility of task switching, and without the
ability of dealing with different priorities. Timeouts, on the other
hand, can be executed while user tasks are running, because they run
in an interrupt service routine (ISR). Each time-critical part in the
synchronization process has been implemented using these
timeouts. However, since the platform does not allow that one ISR
interrupts another one, it is still possible that timeouts may be
delayed.

The Atmels were connected to iSense nodes via a wired connection, and
used SPI for communication. The iSense nodes in turn were able to
communicate over their radio. However, since we used the available
firmware we had no direct access to the MAC layer, and thus had to
implement the algorithm in the application layer---which obviously led
to a loss in accuracy.

Another issue were timer accuracies. On the Atmel platforms, we had to
use the internal oscillator, which led to timer interrupts of variable
length. The duration of such a timer event may vary from one call to
another---that means, running for a time of 2 milliseconds, for
example, may take +2s at the first call, but -2s at the
second call. We measured with an oscilloscope the exact period of such
events, and collected the minimal and maximal durations to obtain the
variance of the timer. To obviate influences during the test by other
tasks or interrupts on the Atmel, there was only the measurement
application running. The results for several periods are shown in
Table~\ref{sec:exp:atmel_clock}.

\begin{table}
  \caption{Timer variation on Atmel ATmega48 platform.}
  \center
  \begin{tabular}{ |c|c c c c| }
    \hline
    Period (ms) & Min (ms) & Max (ms) & Diff (s) & Diff (\%) \\
    \hline
    0.2 &  0.2045 &  0.205 & 0.5 & 0.25 \\
    2   &  2.043  &  2.047 & 4   & 0.2 \\
    20  & 20.439  & 20.479 & 40  & 0.2 \\
    40  & 40.881  & 40.959 & 78  & 0.195 \\
    60  & 61.578  & 61.658 & 100 & 0.167 \\
    \hline
  \end{tabular}
  \label{sec:exp:atmel_clock}
\end{table}

Due to limitations of the oscilloscope, we were only able to measure
periods of up to 60ms---however, we see that even at 60ms, there is a
variation of up to 100s. Projected on 500ms, this may result in a
variance of nearly 1ms.

Similar problems do also occur on the iSense platform. While iSense
nodes have a much more dependable clock than the Atmels, they run a
full firmware with message reception tasks, user tasks, and so
on. That means, even when we register a timer that is executed in
interrupt context, it may be delayed by other running interrupts in
the firmware. Table~\ref{sec:exp:isense_timer} shows results
measured with an oscilloscope.

\begin{table}
  \caption{Timer variation on iSense platform.}
  \center
  \begin{tabular}{ |c|c c c c| }
    \hline
    Timer (ms) & Min (ms) & Max (ms) & Diff (s) & Diff (\%) \\
    \hline
    2  &  2.000 &  2.002 &  2 & 0.1  \\
    4  &  4.000 &  4.002 &  2 & 0.05 \\
    20 & 19.938 & 20.000 & 62 & 0.31 \\
    40 & 40.000 & 40.000 &  0 & 0.0  \\
    \hline
  \end{tabular}
  \label{sec:exp:isense_timer}
\end{table}

Whereas most of the timer events were very accurate, there are also
outliers due to firmware activity. An example can be seen at the 20ms
timeout, where a deviation of 62s occurs. In addition, the iSense
firmware only offers timers with an accuracy of milliseconds, which
unfortunately makes an accurate synchronization in terms of
microseconds impossible.

\subsection{Experimental Setup}

The evaluation has been done with a small network of seven nodes---two
Atmels and five iSense nodes. One iSense node was set to the master,
and another three iSense nodes acted as passive slaves. In addition,
two Atmels were connected via wires to passive slaves. The setup is
shown in Fig.~\ref{sec:exp:exp_setup}.

\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{img/testbed.png}
  \caption{Experimental setup with six nodes building different kinds
    of slaves.}
  \label{sec:exp:exp_setup}
\end{figure}

All nodes---the four iSense nodes and the two Atmels---were connected
via wires to the interrupt lines of another microcontroller that
measured the exact points in time when the nodes fired their
events. Since the microcontroller was able to measure in terms of
microseconds, we were able to obtain correspondingly accurate
measurements.

\subsection{Results}

We ran several tests on our experimental setup. In each run, the
master synchronized the network spontaneously, and sent a start
message with different time intervals. We then measured the points in
time when the nodes executed their tasks.

Event though the algorithm would be able to deal with multiple
synchronization tasks at once---that is, a slave that synchronizes to
more than one master in parallel, or a slave that also acts as a
master---our experiments were only ran with one synchronization task
per experiment. The main reasons for this decision was a simplified
and more accurate measurement process, and a saving in code space,
which was especially important for the Atmels.

Fig.~\ref{sec:exp:sync_variation} shows the absolute errors
relative to the execution of the task at the master---as the average
over all six nodes, both iSense and Atmel ones. The start interval has
been increased consecutively from 50ms to 800ms.

\begin{figure}
  \center
  \includegraphics[width=\columnwidth]{img/abs_error}
  \caption{Absolute error in execution of events; start interval 50ms
    to 800ms.}
  \label{sec:exp:sync_variation}
\end{figure}

It can be seen that the average error is at approximately 1ms,
regardless of the selected start interval. However, the greater the
start interval becomes, the more outliers occur, and thus the maximal
error increases to more than 5ms when selecting a starting time of
800ms. The maximal deviation in mainly caused by the very
inaccurate Atmel ATmegas. This difference in accuracy between the
iSense nodes and Atmels is shown in detail in
Table~\ref{sec:exp:errors}, which shows the error rates of all
nodes in our network when the starting interval is set to 500ms.

\begin{table}
  \caption{Absolute Errors in ms on nodes with a start time of 500ms}
  \center
  \begin{tabular}{ |l|c c c c| }
    \hline
    Node            & Min Err & Max Err & Avg Err & Stddev \\
    \hline
    Active Slave    & 0.004   & 1.455   & 0.640   & 0.389 \\
    Passive Slave 1 & 0.007   & 1.499   & 0.678   & 0.392 \\
    Passive Slave 2 & 0.006   & 1.463   & 0.734   & 0.375 \\
    Passive Slave 3 & 0.006   & 1.453   & 0.707   & 0.389 \\
    Atmel at PS 1   & 0.573   & 2.458   & 1.476   & 0.352 \\
    Atmel at PS 2   & 1.011   & 3.518   & 2.480   & 0.445 \\
    \hline
  \end{tabular}
  \label{sec:exp:errors}
\end{table}

All four iSense nodes show very similar results. The minimal error is
at only a few microseconds, whereas the maximal one is at most
1.5ms. In average, the deviation from the master is at around
700s. In contrast to the iSense nodes, the Atmels show much worse
results. The deviations are between 500s and 3.5ms, with an
average of 2ms. This is basically due to the inaccurate internal
oscillator, which makes it impossible to calculate reliable clock
drifts. However, for application areas where an event synchronization
of only a few milliseconds is adequate, such as a synchronous
playback of sound files or the concurrent sensing of a global event,
the number of only five messages that are sent over the radio
outperforms the inaccuracy.

Next, we also measured the propagation time of messages, both between
the master and the active slave, and an iSense node connected to an
Atmel via SPI. The result is shown in
Fig.~\ref{sec:exp:sync}.

\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{img/sync_ppg}
  \caption{Propagation times over time.}
  \label{sec:exp:sync}
\end{figure}

The propagation time of the radio message varied between 2ms and
2.5ms, whereas the SPI communication was as expected constantly at
10us. The variance in wireless propagation time was mainly based on
the need for an application-layer implementation.





