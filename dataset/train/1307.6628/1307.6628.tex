\documentclass[12pt]{dalthesis}
\usepackage{amsmath,amssymb,latexsym,graphicx,fancyhdr}
\usepackage[mathscr]{euscript}
\usepackage{algorithm}
\usepackage[noend]{algorithmic}
\usepackage{tabulary}
\usepackage{colortbl}
\usepackage{calc}
\usepackage{url} 



\def\favoritefont{\bfseries \sffamily}
\makeatletter
\long\def\@makecaption#1#2{
   \vskip 10pt
   \setbox\@tempboxa\hbox{{\footnotesize {\favoritefont #1.} {\sffamily #2}}}
   \ifdim \wd\@tempboxa >\hsize         {\footnotesize {\favoritefont #1.} {\sffamily #2}\par}\else                              \hbox to\hsize{\hfil\box\@tempboxa\hfil}
   \fi}


\dbltextfloatsep 18pt plus 2pt minus 4pt   \textfloatsep 18pt plus 2pt minus 4pt      

\def\@begintheorem#1#2{\trivlist 
   \item[\hskip \labelsep{\favoritefont #1\ #2}]\itshape}

\def\@opargbegintheorem#1#2#3{\trivlist
   \item[\hskip \labelsep{\favoritefont #1\ #2}{\bf\ (#3)}]\itshape}

\def\QED{\ensuremath{{\Box}}}
\def\markatright#1{\leavevmode\unskip\nobreak\quad\hspace*{\fill}{#1}}
\newenvironment{proof}
	{\begin{trivlist}\item[\hskip\labelsep{\favoritefont Proof:}]}
	{\markatright{\QED}\end{trivlist}}






\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{obs}{Observation}
\newtheorem{alg}{Algorithm}
\newtheorem{definition}{Definition}
\newcommand{\qed}{}
\newcommand{\IR}{\ensuremath{\mathbb{R}}} 
\newcommand{\IZ}{\ensuremath{\mathbb{Z}}} 
\newcommand{\IN}{\ensuremath{\mathbb{N}}} 
\newcommand{\IS}{\ensuremath{\mathbb{S}}} 
\newcommand{\IC}{\ensuremath{\mathbb{C}}} 
\newcommand{\IB}{\ensuremath{\mathbb{B}}} 

\newcommand{\OPT}{\ensuremath{\mbox{\tt OPT}}}
\newcommand{\opt}{\ensuremath{\mbox{\tt opt}}}
\newcommand{\APX}{\ensuremath{\mbox{\tt APX}}}
\newcommand{\apx}{\ensuremath{\mbox{\tt apx}}}

\newcommand{\lee}{\leqslant}
\newcommand{\gee}{\geqslant}
\newcommand{\ceil}[1]{{\left\lceil{#1}\right\rceil}}
\newcommand{\floor}[1]{{\left\lfloor{#1}\right\rfloor}}
\newcommand{\prob}[1]{{\mbox{\tt Pr}[#1]}}
\newcommand{\set}[1]{{\{ #1 \}}}
\newcommand{\seq}[1]{{\left< #1 \right>}}

\newcommand{\eps}{\varepsilon}
\newcommand{\bslash}{\!\setminus\!}
\newcommand{\bigOmega}{{\rm\Omega}}
\newcommand{\etal}{{\em et~al.\/}}
\newcommand{\REM}[1]{}
\newcommand {\backspace}{\vspace{-3.2em}\\}



\newcommand{\eq}{{\ \leftarrow\ }}




\newcommand{\CF}{{\mathscr F}}
\newcommand{\CR}{{\mathscr R}}
\newcommand{\CI}{{\mathscr I}}
\newcommand{\CB}{{\mathscr B}}
\newcommand{\CP}{{\mathscr P}}
\newcommand{\CT}{{\mathscr T}}
\newcommand{\CS}{{\mathscr S}}
\newcommand{\CC}{{\mathscr C}}
\newcommand{\CV}{{\mathscr V}}
\newcommand{\CU}{{\mathscr U}}
\newcommand{\CH}{{\mathscr H}}
\newcommand{\CG}{{\mathscr G}}

\newcommand{\Frechet}{Fr\'echet }
\newcommand{\naive}{na\"{i}ve }

\newcommand{\distF}{\delta_F}
\newcommand{\distFS}{\delta_{\bar{F}}} \newcommand{\distWeakF}{\delta_{\bar{N}}} \newcommand{\distClosedF}{\delta_{\bar{C}}} \newcommand{\distPartialF}{\delta_{\bar{P}}} \newcommand{\distGrpahF}{\delta_{\bar{G}}} \newcommand{\distDisF}{\delta_{dF}} \newcommand{\distGeoF}{\delta_{\hat{F}}} \newcommand{\distHomF}{\delta_{h}} \newcommand{\distC}{\delta_C} \newcommand{\distSetF}{\delta_{\CF}} 




\newcommand{\SC}{slope-constrained }

\newcommand{\cell}[1]{{\CC_{#1}}}
\newcommand{\BNM}{\CB_{n \times m}}
\newcommand{\BNNM}{\CB_{2n \times m}}
\newcommand{\CO}{{\mathscr O}}
\newcommand{\COB}{{\bar{\CO}}}

\newcommand{\Feps}{\CF_\eps}
\newcommand{\Reps}{\CR_\eps}
\newcommand{\LF}{L^\CF}
\newcommand{\BF}{B^\CF}
\newcommand{\LR}{L^\CR}
\newcommand{\BR}{B^\CR}
\newcommand{\LT}{L^{T}}
\newcommand{\BT}{B^{T}}

\newcommand{\OP}{\CT}

\newcommand{\Xmin}[2]{{#1}_{\min}(#2)}
\newcommand{\Xmax}[2]{{#1}_{\max}(#2)}
\newcommand{\umin}[1]{\Xmin{\bar{v}}{#1}}
\newcommand{\umax}[1]{\Xmax{\bar{v}}{#1}}
\newcommand{\vmin}[1]{\Xmin{v}{#1}}
\newcommand{\vmax}[1]{\Xmax{v}{#1}}
\newcommand{\pmin}[1]{\Xmin{\pi}{#1}}
\newcommand{\pmax}[1]{\Xmax{\pi}{#1}}
\newcommand{\minS}[1]{\mbox{minSlope}_{#1}}
\newcommand{\maxS}[1]{\mbox{maxSlope}_{#1}}

\newcommand{\entry}[1]{\mbox{entry}(\cell{#1})}
\newcommand{\exit}[1]{\mbox{exit}(\cell{#1})}
\newcommand{\proj}[1]{\pi_{#1}}
\newcommand{\slope}{\mbox{slope}}
\newcommand{\Left}{\mbox{left}}
\newcommand{\Right}{\mbox{right}}
\newcommand{\domain}{\mbox{domain}}
\newcommand{\union}{\mbox{\sc U}}
\newcommand{\lei}{\prec}




\newcommand{\Po}{K}
\newcommand{\LeL}[1]{{\Upsilon^1_{#1}}} \newcommand{\RiL}[1]{{\Upsilon^2_{#1}}} \newcommand{\Ho}[2]{\CH_{\overline{#1},\overline{#2}}}
\newcommand{\But}[2]{\CB_{\overline{#1},\overline{#2}}}
\newcommand{\Ov}[1]{\overline{#1}}
\newcommand{\PP}{{F}}
\newcommand{\GSP}{{\mathscr D}} \newcommand{\SP}{\pi} \newcommand{\Lin}{\overleftrightarrow{cd}} \newcommand{\Dir}{\overrightarrow} \newcommand{\ButF}{{\mathscr B}}

\newcommand{\For}{{\bf for }}
\newcommand{\Foreach}{{\bf for each }}
\newcommand{\To}{{\bf to }}
\newcommand{\Do}{{\bf do }}
\newcommand{\If}{{\bf if }}
\newcommand{\Then}{{\bf then }}

\newcommand{\row}[1]{{\CR_{#1}}}
\newcommand{\RSet}[2]{{\mathscr RS}_{#1}^{#2}} 

\newcommand{\fs}{free-space }
\newcommand{\FD}{\mathscr {FD}}
\newcommand{\FS}{\mathscr {FS}}
\newcommand{\provided}{{\ | \ }}
\newcommand{\lr}{\mbox{\sc Leftmost-Reachable}}
\newcommand{\rl}{\mbox{\sc Rightmost-Take-Off}}
\newcommand{\topp}{\text{top}}
\newcommand{\up}{\text{up}}
\newcommand{\nil}{\mbox{null}}

\newcommand{\bigTheta}{{\rm\Theta}}

\newcommand{\CD}{{\mathscr D}}

\newcommand{\Next}{\mbox{next}}

\newcommand{\Prev}{\mbox{prev}}
\newcommand{\CL}{{\mathbb L}}

\newcommand{\F}{\CF}
\newcommand{\R}{\CR}
\newcommand{\RE}{\mbox{\sc R}}
\newcommand{\REE}{{\mathcal R}}
\newcommand{\Last}{\mbox{last}}
\newcommand{\reach}{\leadsto}

\newcommand{\lp}{\ell}
\newcommand{\rp}{r}


\newcommand{\gei}{\succ}
\newcommand{\lx}{\prec}
\newcommand{\lex}{\preceq}
\newcommand{\gx}{\succ}
\newcommand{\gex}{\succeq}
\newcommand{\projj}{\mbox{proj}}
\newcommand{\NULL}{{\sc null}}





\newcommand{\pset}{S}
\newcommand{\ap}{\oplus}
\newcommand{\gre}{{g}}
\newcommand{\sma}{{s}}

\newcommand{\Seg}[1]{{\overline{#1}}}
\newcommand{\ri}{r}

\newcommand{\CQ}{{\mathscr Q}}
\newcommand{\sq}{{\CS\CQ}}
\newcommand{\cfev}{{l}} 









\newcommand{\Rivals}{Rivals}	
\newcommand{\lme}[1]{{\lambda^{#1}}}
\newcommand{\see}{\leadsto}
\newcommand{\forw}{\rightarrow}
\newcommand{\Upper}{\Pol_u}
\newcommand{\Lower}{\Pol_\ell}

\newcommand{\Pol}{{\mathscr P}}

\newcommand{\Good}{\mbox{Type A}}
\newcommand{\SemiBad}{\mbox{Type B}}
\newcommand{\Bad}{\mbox{Type C}}


\newcommand{\PolSeg}{{P}}
\newcommand{\DoubleB}{Double-TypeB}
\newcommand{\TwiceB}{Twice-TypeB}
\newcommand{\ttt}[1]{\mbox{\scriptsize }}
\newcommand{\PCC}[1]{ \ttt{  \overset{ \curvearrowleft}{P_{#1}}   }}
\newcommand{\PC}[1]{  \ttt {\overset{ \curvearrowright}{P_{#1}}    }}
\newcommand{\reachC}[1]{{\mathscr SC_{#1}}}
\newcommand{\reachCC}[1]{{\overleftarrow{\mathscr R_{#1}}}}
\newcommand{\Qs}{x} \newcommand{\Ps}{x'} 



\newcommand{\ccyl}{sc}
\newcommand{\back}{\mapsto}
\newcommand{\nsee}{\not \leadsto}
\newcommand{\Special}{\mbox{special}}
\newcommand{\PST}{P_{st}}
\newcommand{\Enemy}{\mbox{rival}}
\newcommand{\ChUp}{Ch_u}
\newcommand{\ChLo}{Ch_l}

\newcommand{\bounC}{\sigma}

\newcommand{\cone}{\pi_a}
\newcommand{\ctwo}{\pi_b}

\newcommand{\Uone}{\pi_a}
\newcommand{\Utwo}{\pi_b}
\newcommand{\Lone}{\mu_a}
\newcommand{\Ltwo}{\mu_b}
\newcommand{\conc}[2]{{{#1} \oplus {#2}}}



\newcommand{\A}[1]{{A^{#1}}}
\newcommand{\B}[1]{{B^{#1}}}
\newcommand{\LP}{{lp}}



\newcommand{\PL}{\pi_1(P)} 
\newcommand{\PR}{\pi_2(P)} 
\newcommand{\NextU}{d} 












\setlength{\headheight}{15pt}
\begin{document}




\title{
Applied Similarity Problems Using \Frechet Distance 
        \\}
\author{Kaveh Shahbaz}
\submitdate{Feb 15, 2011} \copyrightyear{2011}

\frontmatter









\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\fancyhead[LE,RO]{\thepage}
\renewcommand{\chaptermark}[1]{\markboth{\chaptername \ \thechapter.\ #1}{}}
\lhead{\nouppercase{\leftmark}}





\clearpage{}\chapter {Introduction and Motivation}
\pagenumbering{arabic}
\setcounter{page}{1}
\label{ch:Background}





The problem of curve matching appears in a variety of different domains, like 
shape matching, GIS applications~\cite{AltERW03a, Buchin10, Appx-MM}, 
pattern recognition~\cite{FDRevisited,JiangXZ08}, 
computer vision~\cite{AltBook2009}, speech recognition~\cite{FDSpeech},  
time series analysis~\cite{FDTime},  
and signature verification~\cite{FDHandwriting,SriraghavendraKB07}.  The main questions
associated with curve matching in a specific domain
are: What is a good measure of similarity between curves? How can we compute it (or some approximation
of it) efficiently? Other questions that are often
of interest include: given a database of curves and a candidate
curve, can we find a nearest neighbor to this curve
in the database? Can we cluster curves with respect to
a given measure of similarity?

Curve matching has been studied extensively by computational 
geometers. 
The Hausdorff distance and the \Frechet distance are the most well-known distance measures 
to assess the resemblance of two curves
(see \cite{SomeOtherMetrics} for some other metrics such as 
the bottleneck distance, the volume of symmetric difference).
The Hausdorff distance between two curves  and  is the smallest ,
such that  is completely contained in the -neighborhood of , and vice
versa. 
Although the Hausdorff distance is arguably a  natural distance
measure between curves and/or compact sets, it is too ”static”,
in the sense that it neither considers 
direction nor any dynamics of the motion along the curves
(see Figure \ref{fig:Haus}). The \Frechet distance deals with
this problem. It takes the order between points along 
the curves into consideration, making it a better 
measure of similarity for curves than alternatives 
such as the Hausdorff distance. 

The \Frechet distance was first defined by Maurice \Frechet in 1906~\cite{FirstFD}. 
While known as a famous distance measure in the field of mathematics 
(more specifically, abstract spaces), 
it was Alt and Godau~\cite{AltG95} who first applied it in measuring the similarity of polygonal curves in early 1990s. 

An intuitive way to understand the \Frechet metric is as follows:
imagine a man is walking his
dog, he is walking on one curve, the dog on the other. Both are allowed to
control their speeds, but are not allowed to go backwards. Then, the \Frechet
distance of the curves is the minimal length of a leash that is necessary.







Alt and Godau~\cite{AltG95} proposed an  time 
algorithm to compute the \Frechet distance, 
where  is the total complexity of the curves. 
Since that time,
\Frechet metric has received much attention as a measure
of curve similarity and many variants have been studied. These include 
minimizing the \Frechet distance under various classes of transformations~\cite{AltTranslation,Mosig2005}, 
extending it to graphs~\cite{AltERW03a,VehicleTracking}, piecewise smooth curves~\cite{smoothFD}, simple polygons~\cite{Buchin2006}, surfaces~\cite{Alt2009Surface}, and
to more general metric spaces~\cite{WenkC08a,Chambers10,Cook2009},
in curve simplification~\cite{Agarwal2002}, 
protein structure alignment~\cite{JiangXZ08,FDRevisited} and morphing~\cite{GuibasNoCross}. 

















\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\columnwidth]{Pics/Haus3}
	\caption{ Hausdorff vs. \Frechet distance. Shows two curves  and  with small Hausdorff distance  having a large \Frechet distance .
	(a) The \Frechet distance is indicated by . The Hausdorff distance is the distance from vertex  to . A sample walk is also shown with
a sequence of the locations of the moving objects.
(b) The direction of  is reversed. The \Frechet distance is not same as before but the Hausdorff distance remains unchanged.
Applet of Pelletier~\cite{FDApplet} is used to compute \Frechet distance.
	}
	\label{fig:Haus}
\end{figure}





\section{Contributions of the Thesis}

The main contributions of this thesis are summarized below: 
\begin{itemize}
\item We introduce a generalization of the well-known \Frechet 
distance between two polygonal curves which incorporates speed limits. 
We provide efficient 
algorithms for computing that metric~\cite{oursCCCG2009,oursSpeedJournal}.

\item We present an algorithm which computes 
the speed-constrained \Frechet distance when the
input curves are restricted to be inside a simple polygon \cite{oursCCCG2010}.

\item We introduce a new data structure called  
the \emph{free-space map} which can be used to solve several variants of 
\Frechet distance problems efficiently.
We improve algorithms for partial curve matching and
closed curve matching  using free-space map. 
We also obtain an improved algorithm for
the map matching algorithm of Alt \etal~\cite{AltERW03a}
for the case when the map is a directed acyclic graph.
We also solve \emph{minimum/maximum walk} problem efficiently using
our data structure~\cite{oursESA2011,oursPartialAlgorithmica}. 

\item We introduce the \emph{curve-pointset matching} problem and present 
an efficient algorithm to solve it~\cite{oursCCCG2011}. 

\item We provide NP-completeness proof of \emph{all-points curve-pointset matching} problem.

\end{itemize}


\section{Organization of the Thesis}

This thesis is organized as follows. In the next chapter, 
we describe the algorithm due to Alt and Godau \cite{AltG95} 
for computing the \Frechet distance. In addition, we summarize different variants of \Frechet distance problem 
which have been studied and
describe briefly the techniques for solving them.


Next, in Chapter \ref{ch:speedFD},
we introduce a new generalization of 
\Frechet distance and provide an efficient algorithm for computing it. 
The classical \Frechet distance between two polygonal curves corresponds to the 
maximum distance between two point objects that traverse the curves with arbitrary non-negative speeds.
Here, we consider a problem instance in which the speed of traversal 
along each segment of the curves is restricted to be within a specified range. 
We provide an efficient algorithm that  
decides in  time whether the \Frechet distance with speed limits
between two polygonal curves is at most ,
where  is the number of segments in the curves, and
 is an input parameter. 
We then use our solution to this decision problem 
to find the exact \Frechet distance with speed limits
in  time. 






Given two polygonal curves inside a simple polygon,
in Chapter \ref{ch:speed-geodesic}, we study the problem of finding the \Frechet distance between the two curves
under the following two conditions
(i) the distance between two points on the curves is measured as the length of the shortest path
between them lying inside the simple polygon, and 
(ii) the traversal along each segment of the polygonal curves 
is restricted to be between a minimum and a maximum permissible speed
assigned to that segment.We provide an algorithm that decides in  time 
whether the speed-constrained geodesic \Frechet distance between two polygonal curves inside a 
simple polygon is within a given value , 
where  is the number of segments in the curves, and  is the complexity of the polygon. 


In Chapter \ref{ch:partial}, 
we propose a new data structure, \emph{free-space map}, 
that enables us to solve several variants of the \Frechet distance problem efficiently.
Our data structure encapsulates all the
information available in the 
free-space diagram of Alt and Godau~\cite{AltG95} to compute the
\Frechet distance. 
In addition, our data structure is capable of answering
more general type of queries than 
the free-space diagram. 
Given that the free-space map has the same size  and 
construction time 
(,  is the total complexity of the curves)
as the standard free-space diagram,
 it can be viewed as a powerful alternative.


Using our new data structure,
we present improved algorithms 
for several variants of
the \Frechet distance problem.
In particular, we improve the 
 time algorithm 
for computing the partial \Frechet distance in \cite{AltG95}, 
by a  factor. 
Also, we obtain improved algorithms 
for computing \Frechet distance between 
two closed curves, and the so-called \emph{minimum/maximum walk} problem. 
Our data structure leads to efficient 
algorithms for
the map matching algorithm of Alt \etal 
\cite{AltERW03a}
for the case when the map is a directed acyclic graph. 


In Chapter \ref{ch:StayClose},
we examine the following variant
of the \Frechet distance problem, 
which we refer to as the \emph{Curve-Pointset Matching (CPM)} problem. 
Given a pointset  of size  and a polygonal 
curve  of size  in ,
we study the problem of finding a polygonal curve  whose vertices are from  ,	
and has a minimum \Frechet distance to . 
In the decision version of that problem, 
given a distance , we 
present an  time algorithm 
to decide if exists a curve  through some points of 
in -\Frechet distance to curve , 
where vertices of  are from , 
and curve  need not contain all points of  
and may use a point of  multiple times. 
Also, we show that the
curve of minimum \Frechet distance can be computed in
time .
As a by-product of our result, 
we improve the map matching algorithm of Alt \etal\ \cite{AltERW03a}
by a  factor for the case when the map is a complete graph.
Finally, in Chapter \ref{ch:NP-Complete}, we 
study the same problem as in the previous chapter, 
under the new condition that 
curve  must visit every point in the pointset .
We refer to this problem 
as All-Points CPM problem and 
we show that it is NP-complete. 

\REM{
Finally, in Chapter \ref{ch:SpecialCase},
we study some special cases of  All-Points CPM problem, 
where  instead of a general curve, the input to the problem is 
a convex -monotone curve, 
convex -monotone curve (or convex -monotone curve) or
a convex polygon. 
}
	

\clearpage{}


\clearpage{}\chapter{Related Work}
\label{ch:related}




\section{Classical \Frechet Distance Problem }
\label{sec:classicalFD}
The \Frechet distance is a metric to measure the similarity of polygonal curves. It was first defined by a French mathematician,
Maurice \Frechet \cite{FirstFD}.
The \Frechet distance between two curves is 
often referred to as a dog-leash distance because
it can be interpreted as the minimum-length leash required for a person to walk a dog,
if the person and the dog, each travels from its respective starting position to its ending position, without ever letting go off the leash or backtracking.
The length of the leash determines how similar the two curves are to each other:
a short leash means the curves are similar,
and a long leash means that the curves are different from each other.




Two problem instances naturally arise:  decision and optimization.
In the {\em decision problem}, one wants to decide whether two polygonal curves   and 
are within  \Frechet distance from each other, i.e., if a leash of given length  suffices.
In the {\em optimization problem}, one wants to determine the minimum such .
In~\cite{AltG95}, Alt and Godau gave an  
time algorithm for the decision problem,
where  is the total number of segments in the curves.
They also solved the corresponding optimization problem in  time.
Here, we first describe their decision algorithm:


\paragraph{Polygonal Curve (or Polyline).}
A {\em polygonal curve\/} in  is  a continuous function 
 with , 
such that for each ,
the restriction of  to the interval  
is affine (i.e., forms a line segment).
The integer  is called the {\em length\/} of .
Moreover, the sequence  represents the set of {\em vertices\/} of .
For each , 
we denote the line segment  by .




\paragraph{\Frechet Distance.}

A {\em monotone parametrization} of  
is a continuous non-decreasing function 
with  and .
Given two polygonal curves  and  of lengths  and  respectively, 
the {\em \Frechet distance\/} between  and  is defined as

where  is the Euclidean  distance, and  and  range over all monotone parameterizations of 
 and , respectively.


\paragraph{Free-Space Diagram.}
To compute the \Frechet distance, a way of representing all possible 
person and dog walks is needed.
Let  be an  by  rectangle  in the plane.
Each point  uniquely represents a pair of points
 on the polygonal curves  and .
We decompose  into
 unit grid cells 
for ,
where each cell  corresponds to
a segment  on  and a segment  on .
Given a parameter ,
the {\em free space\/}  is defined as

We call any point  a {\em feasible\/} point.
An example of the free-space diagram for two curves  and  
is illustrated in Figure~\ref{fig:diagram}.a.
The free-space diagram was first used in~\cite{AltG95}
to find the standard \Frechet distance in near quadratic time.
Consider any segment  and  from polygonal curves  and , 
respectively. Then, the free space inside cell  is convex 
and can be determined in  time by computing the intersection of a unit square and an ellipse~\cite{AltG95}.


\begin{figure}[h]
	\centering
	\includegraphics[width=0.60\columnwidth]{Pics/FreeSpace}
	\caption{ (a) The free-space diagram for two polygonal curves  and ;
	(b) two segments  and  and their corresponding free space.
	The diagram was generated using a Java applet developed by S. Pelletier~\cite{FDApplet}.}
	\label{fig:diagram}
\end{figure}
 





	Here, we show how the function of such an ellipse is computed:
	Let the coordinates of the endpoints of  be: 
	and the coordinates of
	the endpoints of  be: . 
	Let  be defined by the function: 
	and  be defined by the function: . Then: 
	
	
	The points located in the 2-dimentional coordinate system of the parametrization of 
	and  satisfy: , thus the coordinate of points in  are :


\abovedisplayshortskip=0pt
\belowdisplayshortskip=0pt
\abovedisplayskip=0pt
\belowdisplayskip=0pt

	
	The coordinates of the points in  are: 
	
	Every point in the free space inside , corresponds to exactly two points, one from 
	the other from  where their distance is less than or equal parameter . Therefore, 
	
	by expanding the above inequality and considering the fact that :
	
	We derive the function of the ellipse as follows:
		
	Since an ellipse is a convex  shape and the unit 
	square in the free-space diagram is convex too, 
	the intersection of two convex objects is convex and therefore, 
the free space inside each cell is convex. 
In addition, Alt and Godau~\cite{AltG95} observed that any -monotone 
path from  to  in the free space corresponds to traversals of  and , 
where the traversing objects remain at a distance of at most  from each other.


Based on the above observations, 
Alt and Godau~\cite{AltG95} provided an algorithm
to solve the decision problem (i.e., decide if  for a given ) in quadratic time as follows:


Let  (resp., ) denote the left (bottom, resp.) line 
segment bounding  (see Figure~\ref{fig:diagram}.b).
As a preprocessing step, the free space, , is computed by the algorithm.
Let  and  
(see Figure~\ref{fig:diagram}.b).
Since  is convex within ,
each of  and  is a line segment. 
The preprocessing step therefore involves computing line segments
 and  for all feasible pairs , which can be done in  time.
A point  is called {\em reachable\/} 
if there is a monotone path from  to  in .
Let  be the set of reachable points in ,
and  be the set of reachable points in .
Observe that all non-empty sets  and  for each cell  forms line 
segment~\cite{AltG95}. The algorithm processes the cells in the row-wise order, from  to , 
and at each cell ,  and  are computed. 
Finally, at the last cell, if the top-right corner of  is reachable, 
``YES" is returned as the answer to the decision problem, otherwise ``NO" is returned.
Details are shown in Algorithm~\ref{alg:StandardFDec}. 
Given polygonal curves  and  with total complexity , 
Algorithm~\ref{alg:StandardFDec} decides in  time 
if ~\cite{AltG95}.






\begin{algorithm} [h]
\caption {\sc Standard \Frechet Decision Algorithm~\cite{AltG95} } \label{alg:StandardFDec}




\algsetup{indent=1.5em}
\begin{algorithmic}[1]
	\vspace{0.5em}
	\baselineskip=1\baselineskip

		\FOR { each cell  } 
 
 		\STATE Compute   and 
\ENDFOR

	\STATE Set , \ 
		 for , \ 
		 for   
	\FOR { to } 
	 	\FOR { to }
			\STATE Compute   and  from  , ,   and .
		\ENDFOR
	\ENDFOR
	\STATE\label{line:last} Return ``{\sc yes}" if , ``{\sc no}" otherwise. 

\end{algorithmic}
\end{algorithm}






The algorithm proposed by Alt and Godau for actually computing the \Frechet distance  
makes use of Algorithm \ref{alg:StandardFDec}, and the technique of parametric search of Megiddo~\cite{Megiddo83}, 
accompanied by a speedup technique due to Cole~\cite{Cole87}. 
The resulting algorithm has time complexity .

Let  and   (see Figure~\ref{fig:diagram}.b). 
Notice that the free space, , is an increasing function of , 
that is, for , we have .
Therefore, to find the exact value of ,
we can start from , and continuously increase  until
we reach the first point at which  contains a monotone path from  to .
This occurs at only one of the following ``critical values''~\cite{AltG95}:
\begin{itemize} \itemsep1pt
	\item[(A)] smallest  for which  or . 
	These are the distances between starting point and endpoints of  and .
	
	
	\item[(B)] smallest  at which  or   becomes non-empty for some
 	pair  (when a new passage opens between two adjacent cells in the diagram). 
	These are the distances between vertices of one curve and edges of the other (see Figure \ref{fig:TypeBC}a).
	
	\item[(C)] smallest  at which , or 
	, for some , and , 
	(when a new horizontal or vertical passage opens within the diagram). 
	A critical distance of type (C) corresponds to the common 
	distance of two vertices of one curve 
	to the intersection point of their bisector 
	with an edge of the other curve~\cite{AltG95} (see Figure \ref{fig:TypeBC}b).
\end{itemize}



\begin{figure}[t]
	\centering
	\includegraphics[width=0.90\columnwidth]{Pics/TypeBC}
	\caption{The geometric situations corresponding to Type (B) and Type (C)
 critical distances. 
(a) a new passage opens between two neighboring cells in the free-space diagram (b) a horizontal passage opens in the free-space diagram. }
	\label{fig:TypeBC}
\end{figure}

There are two critical values of type (A), 
 critical values of type (B), and  critical values of type (C),
each computable in  time.
Therefore, to find the exact value of ,
one can compute all these  values, sort them, 
and do a binary search (equipped with Algorithm~\ref{alg:StandardFDec})
to find the smallest  for which ,
in  total time.
However, as mentioned in~\cite{AltG95},
a parametric search method~\cite{Megiddo83,Cole87} can be applied
to the critical values of type (C) to get a faster algorithm.

The crucial observation made in~\cite{AltG95} is that
any comparison-based sorting algorithm that sorts
, and  (defined as functions of )
has critical values that include those of type (C).
This is because the critical values of type (C) occur if 
 or , 
for some , and . Thus, Algorithm ~\ref{alg:CompFD}, 
uses parametic search to find the exact value of \Frechet distance.

\begin{algorithm} [t]
\caption {\sc Standard \Frechet Computation Algorithm~\cite{AltG95} } \label{alg:CompFD}
\algsetup{indent=1.5em}
\begin{algorithmic}[1]
	\vspace{0.5em}
	\baselineskip=0.9\baselineskip

\STATE Compute all critical values of types (A) and (B), and sort them.
	
	\STATE Binary search to find two consecutive values   and  in  the sorted list
	such that .
	
	\STATE Let  be the set of endpoints ,  of intervals  
	 and  that are nonempty for .
	Use Cole's parametric search method~\cite{Cole87}  based on sorting the values in  
	to find the exact value of .

\end{algorithmic}
\end{algorithm}




Steps 1 and 2 together take  time. 
The parametric search in Step 3 takes  time,
where  is the number of values to be sorted, 
and  is the time needed by the decision algorithm.
In case of the standard \Frechet distance problem, , and .
We conclude that the exact \Frechet distance between two polygonal curves 
can be computed in  time~\cite{AltG95}. 







\section{Variants of \Frechet Distance}

In this section, we summarize different variants 
of \Frechet distance metric
which have been studied in the literature.



\subsection{Weak \Frechet Distance}

One of the variants of the \Frechet metric studied in~\cite{AltG95} is the weak \Frechet
distance or non-monotone \Frechet distance. Coming back to the man-dog illustration 
of the \Frechet metric, in this instance,  
both the man and the dog are allowed to 
backtrack on their respective curves.

Let  denote the weak \Frechet distance between two polygonal curves 
and . In order to solve the decision and optimization problems, 
the same -diagram 
can be used as in the previous section. 
Now the decision problem has a yes answer iff 
there exists a path from  to  in  which is not necessarily monotone~\cite{AltG95}. 
To solve the decision problem, an undirected labeled graph, , is constructed 
on top of  as follows:

For each cell in the diagram, one node is added to ; two additional nodes  and 
are added to the graph, where node  represents point 
and node  represents point .
Two nodes are connected via an edge in the graph 
if their corresponding cells are adjacent in the diagram.
Furthermore, one edge connects node  (resp., node )  
to the node which corresponds to cell  
(resp., cell ) as  depicted in Figure \ref{fig:weak}. 
The edge between two neighboring cells is labeled with a minimal 
for which there is a possible direct transition between the two cells within .
The edge  is labeled with the distance between starting points of the curves
and the edge   is labeled with the distance between ending points of the curves. 
Let the weight of a path within  be the largest weight of its edges. After constructing graph , the decision problem has a positive answer 
iff there exists a path of weight  between  and  within graph .
This can be done by removing all edges of weight greater than , 
and checking if  and  are in the same connected component, 
for example, by running BFS algorithm~\cite{AltG95}.



\begin{figure}[t]
	\centering
	\includegraphics[width=0.50\columnwidth]{Pics/Weak}
	\caption{ The graph with grey nodes is built on top of  to compute the weak \Frechet distance}
	\label{fig:weak}
\end{figure}



The computation of the exact value of  consists of 
determining the minimum weight path within graph  from  to .
This can be computed by using Prim's minimum spanning tree 
algorithm starting from  and running it until the minimum spanning tree 
containing  and  is found. 
After finding 
the MST, one can run breadth first search algorithm to find 
a path from  to  in MST.  
We conclude that 
given two polygonal curves  and  with total length  and a distance ,
one can decide in  time if  and 
the exact value of  can be found in ~\cite{AltG95}. 









\subsection{\Frechet Distance of a Set of Curves}
Dumitrescu \etal~\cite{SetofCurves} have extended the \Frechet distance 
notion between two curves to a set of curves and showed how to compute and approximate it .
The corresponding intuitive illustration is as follows. 
Suppose that points are moving, one on each of	given curves. 
The speed of each point may vary but no point is allowed to move backwards. 
Assume that all pairs of points are connected by strings of the same length. 
Then, the \Frechet distance of the set of curves is the minimum length of a connecting string that is necessary.

To compute the \Frechet distance of a set of  
curves  (with complexity , respectively), 
the approach of ~\cite{AltG95} can be adapted. 
First, a free-space diagram corresponding to each pair of curves is built. 
To answer the decision problem, one would
 check whether 
there exists a path from   to  in free-space
diagram in  which is monotone in all  coordinates.
This  takes  time and  using parametric search, the resulting final algorithm
has time complexity .
In~\cite{SetofCurves}, a simple algorithm 
is proposed which computes 
the \Frechet distance of set of curves (i.e., ) approximately. 
Let . Observe that 
~\cite{SetofCurves}.
Thus, one can compute all pairwise \Frechet distances and 
output   as
the \Frechet distance of a set of curves with the approximation ratio 2~\cite{SetofCurves}. The running time of this approach is  which is much better than that of the exact algorithm previously mentioned.



Alt \etal~\cite{AltTranslation} consider the problem of 
minimizing the \Frechet distance under translations:
Given two polygonal curves, search for a translation which, when
applied to the first curve, minimizes the \Frechet distance to the second one.
The decision algorithm decides whether there is a transformation
that, when applied to the first curve, results in a \Frechet 
distance less or equal than some given parameter .
The runtime of the decision algorithm is . 
The parametric search adds only a logarithmic overhead,
since Cole's technique for parametric search based on sorting~\cite{Cole87} can be applied, so
the optimization problem can be solved in  time. 
In~\cite{JiangXZ08}, the authors present  algorithms for matching two polygonal chains 
in two dimensions to minimize their discrete \Frechet distance under 
translation and rotation.








\subsection{Average \Frechet and Summed \Frechet Distance }



  
Notice that the \Frechet metric is a max measure; 
it is defined as the maximum pointwise distance minimized over all parametrizations. 
This dependence on the maximum value can often lead to non-robust behavior, where small variations in
the input can distort the distance function by a large
amount. 
Consider for example the curves shown in Figure \ref{fig:FD-sum}. 
Assume one wants to match
the curve  either to the curve  or . 
Intuitively, it seems that  is the better
match. 
This is however not reflected by the \Frechet distance which is equal for 
both pairs of curves  and .
An average \Frechet distance 
was suggested in~\cite{VehicleTracking} which averages over certain 
distances instead of taking the maximum.
Efrat \etal~\cite{SumFD}  has combined {\em dynamic time warping} to compute an integral  version of the \Frechet distance, 
which can “smooth out” the impact of some outliers.
Dynamic time warping measure (DTW) is a measure which was
first proposed in the 60s as a measure of speech signal similarity.  
In the dog-man setting,
the DTW distance between two curves (defined as sequences
of points) is the sum of the leash lengths measured
at each (discrete) position (minimized over all
trajectories). 











\begin{figure}[t]
	\centering
	\includegraphics[width=0.65\columnwidth]{Pics/Summ}
	\caption{ . But curve  is more matched to curve .	}
	\label{fig:FD-sum}
\end{figure}








\subsection{\Frechet Distance of Specific Families of Curves}

It has been an open problem to find a sub-quadratic algorithm 
for computing the \Frechet distance.
A lower bound of  is given by~\cite{LowerBound-FD}
for the problem of deciding whether the \Frechet 
distance between two curves is smaller 
or equal a given value. 
In~\cite{AltBook2009}, Alt conjectured that 
the decision problem may be 3SUM-hard~\cite{ClassOfN2}. 
In a very recent work~\cite{BuchinFasterFrechet},
Buchin~\etal~present an algorithm 
with total expected time

which is the first algorithm to achieve 
a running time of  for computing \Frechet distance.
Furthermore, they 
show that there exists an algebraic decision tree 
for the decision problem of depth , 
for some . This 
provides some insights that might suggest
that the decision problem may not be 3SUM-hard.


The only subquadratic algorithms known are for
quite restricted classes of curves such as 
for closed convex curves and for -bounded curves~\cite{Alt2003Comparison}, 
or discrete version of \Frechet distance \cite{DiscreteSUBQuadractic}. 
For a curve to be -bounded means that for any two points on the curve
the portion of the curve in between them cannot be further away from either point than 
times the distance between the two points.  For closed convex curves the \Frechet distance
equals the Hausdorff distance and for -bounded curves the \Frechet distance is at most
 times the Hausdorff distance, and hence the  algorithm for the Hausdorff
distance applies.

The \Frechet distance of another family of curves, {\em -packed} curves, 
is studied in a recent work by Driemel \etal~\cite{c-packedFD}.
A curve  is called -packed if the total length of  inside any 
circle is bounded by  times the radius of the circle. Intuitively, the constant 
measures how unrealistic the input curves are.


A -bounded curve might have arbitrary length while maintaining a finite diameter, 
and as such may not be -packed.
Unlike -bounded curves, the \Frechet
distance between two -packed curves might be arbitrarily 
larger than their Hausdorff distance. Indeed, -packed
curves are considerably more general and a more natural
family of curves. For example, a -packed curve might self cross and revisit the same location
several times, and the class of -packed curves is closed under concatenation, 
none of which is true for -bounded curves. Given two -packed curves  and 
with total complexity , a -approximation of the \Frechet distance between them 
can be computed in  time~\cite{c-packedFD}.

In standard \Frechet metric, the objects are piecewise linear.
Rote~\cite{smoothFD} explores the \Frechet distance between more general curves where
each input curve is given as a sequence of smooth curve pieces that are “sufficiently well-behaved”, 
such as circular arcs, parabolic arcs, or some class of spline curves. 
He has shown that the combinatorial complexity, i.e., the number of steps, for solving the decision
 problem is not larger than for polygonal paths,  ( is the total size of two given curves). 
Furthermore, under the assumption that the curves consist of algebraic pieces whose degree is bounded by a constant, 
the optimization problem can be solved in  time, which matches the running time for the polygonal case. 




\subsection{\Frechet Distance with no Leash Cross}
In the \Frechet metric, the leash is allowed to cross the two polylines.
A natural restriction to apply is to require that the leash not cross the polylines.
Efrat \etal~\cite{GuibasNoCross} has introduced two new metrics 
for measuring the distance between non-intersecting 
(not self-intersecting) polygonal curves:
Given two polylines with total complexity , they 
present algorithms to compute the geodesic 
width of the two polylines in  time 
using  space and the link width 
in  time using  working space
 where  is the total number of edges of the
 polylines. Their computation of these metrics relies on two 
closely-related combinatorial 
strutures: the shortest-path diagram and the link diagram of a simple polygon.
The shortest-path (resp., link) diagram encodes the
Euclidean (resp., link) shortest path distance between 
all pairs of points on the boundary of the polygon. 
Later, Bespamyatnikh~\cite{BesNoCross} obtained a faster
algorithm for computing the geodesic width in  time, using  space.





\subsection{Directional-based \Frechet Distance}
Notice that small deviations in one curve can disproportionately 
influence the similarity of two curves.
Furthermore, translations and scalings can affect the result, 
and it is very difficult to make the \Frechet distance invariant under these
types of transformations.
To address these issues, ~\cite{Dir-FD} has proposed the 
{\em direction-based } \Frechet distance. 
Like the standard \Frechet distance, this measure
optimizes over all parametrizations for a pair of curves. Unlike the \Frechet
distance, it is based on differences between the directions of movement along the
curves, rather than on positional differences. 
Therefore, the directional-based \Frechet distance 
is invariant under translations and scalings.
It measures the similarity of polygonal curves by integrating over 
the angular differences between pairs of vectors.
The direction-based \Frechet distance of two polygonal curves with  and  vertices
can be computed in  time, using  space~\cite{Dir-FD}.
Furthermore, the direction-based integral \Frechet distance is proposed
in \cite{Dir-FD} to ensure that small variations in one path do not disproportionately affect the similarity measure.













The measure most
closely related to the direction-based \Frechet 
distance is the turning angle distance~\cite{Arkin1990}. This distance measure
is essentially the same as the direction-based integral \Frechet distance, but
with the following important difference: the turning angle distance 
does not optimize over all possible one-to-one mappings between the two curves. 
Rather, the direction-based \Frechet distance optimizes over all possible one-to-one mappings between the two curves. 
The turning angle distance is 
easily  computed in  time for two
polygonal curves with  and  vertices~\cite{Arkin1990}. 








\subsection{\Frechet Distance of Closed Curves}
\label{sec:RelatedClosed}
Closed polygonal curves are curves with common starting and ending points. 
The man-dog illustration of \Frechet metric in this variant is as follows:  
the man and the dog 
are not only allowed to control their speeds, 
but also to choose optimal starting points on the closed curves to minimize 
the length of the leash.

Let  denote the \Frechet distance between two closed curves. 
Alt \etal~\cite{AltG95} proposed a polynomial time algorithm 
to solve the decision problem of  as follows.
First, a new diagram  is constructed by 
concatenating two copies of  ~\cite{AltG95}. 
Then, a data structure is built on top of  to check 
the following property in constant time:
  iff there exists
a   and a monotone curve from
 to  in the free space  of ~\cite{AltG95}.
Suppose diagram  is given and 
 and  are its bottom, top, left and right sides, respectively.
In the data structure, these sides are partitioned into some intervals 
where each interval is a connected subset of white points on the 
boundary of . There are three types of intervals: 



\begin{itemize}\itemsep1pt

	\item  is interval iff from no point on , 
	a point on   can be reached by a monotone path 
	in  of .
	
	\item  is interval iff from any two points in , the same set of points on   can be reached.
	
	
	\item  is interval iff from any point in  (resp., ), 
	the horizontal (resp., the vertical) line segment connecting that point with  (resp., ) lies 
	completely within .

\end{itemize} 

Two pointers  and  are attached
to each -interval :
pointer  points to the highest point in  that can be reached    
from  and pointer  points to
 the lowest point in   which is reachable from . In addition, 
an  pointer is assigned to each s-interval on , and
an  pointer is assigned to each  -interval on . Analogously, 
 is partitioned into n-,s-, and r intervals depending on their reachability from 
 and  and  pointers are attached to them. 

The data structure is constructed 
recursively by starting from diagram 
and splitting the diagram in half at its longer side into two diagrams 
 and . The recursion continues until 
 a - diagram, which is a cell, is reached.
For one cell, the partitioning and the pointers  can be found in  time. 

In order to merge the two solutions  and  
into one for , first the intervals on the
right side  of  are merged with the ones of the left side  of .
This causes a refinement of the partitions of  and . Each new 
interval inherits the type and pointers from the old interval of which it is 
subset. Then, the types and  pointers of the intervals on  and  are updated and the intervals and pointers on  and  remain unchanged.
Details of how intervals on  (or intervals on ) 
are updated, can be found in~\cite{AltG95}. 
It is shown that the total time for merging is proportional to 
the number of intervals in the partitioning of  and ; 
in the worst case, this number is 
 . Thus, the runtime of the merging step is 
and consequently, the whole divide-and-conquer algorithm has  running time.

Observe that given two points  and ,
there exists a monotone path from  to  in  	iff one of the 
following conditions (a) or (b) holds: 
(a)  is an -interval and  lies between  and  
(b) is type-s and  lies to the right of  and to the left of ~\cite{AltG95}.
Having constructed the data structure on , 
one can determine in  time by scanning intervals on the bottom and top 
side of  simultaneously, if there exists   and a monotone curve from
 to  in  of .
Given two closed curves  and  with total length , 
whether 
can be decided in  time. 
The exact value of 
 can be computed in  time using parametric search.


















 

















\section{Partial Curve Matching}
\label{sec:RelatedPartial}
In this section, we discuss the problem
of measuring partial similarity between curves.

 

\subsection{Partial Curve Matching}
\label{sec:RelatedPartialMain}
Alt and Godau~\cite{AltG95} considered one natural partial similarity 
measure by computing the \Frechet distance between a single 
consecutive piece of subcurve of  and another curve . 
Let  inf  where  is a subcurve of . 
The same technique for two closed curves 
 can be applied to solve the decision problem, i.e., to decide if . Let  
and  be two curves with length  and , respectively and a parameter  is given. Once we have constructed 
the data structure on top of , 
we only have to check the type of the intervals on the bottom side of 
. If all are of type , then the answer is ``NO", otherwise the 
answer is ``YES". Therefore, the decision problem can be solved in   time and the exact value of  
can be computed in  time using the 
parametric search~\cite{AltG95}.

The partial similarity measure introduced in~\cite{AltG95}  
only allows to have outliers in one of the input curve, and more importantly, 
it does not allow outliers
appearing in different (non-consecutive) locations along the input curve. 
In addition, the summed versions introduced in~\cite{SumFD} do 
not fully resolve the issue of partial similarity, especially when significant parts 
of the curves are dissimilar. 

Recently, Buchin \etal~\cite{ExactPartial} have
proposed a natural extension of the
\Frechet distance to measure the partial similarity between
curves. 
They introduce a continuous
partial curve similarity measure that allows general
types of outliers, and develop an exact algorithm to
compute it. The goal here is to maximize the total length of 
subcurves that are close to each other, where closeness is measured by 
the \Frechet distance. 

Specifically, given a distance threshold  and two polygonal 
curves  and , the partial \Frechet similarity between  and  is the total length
of longest subcurves of  and  that are matched with
\Frechet distance at most . The \Frechet distance 
can be measured under any  norm, and they consider the  and
 norms in~\cite{ExactPartial}.
The partial \Frechet similarity can be considered as
the length of the longest monotone path in a certain
polygonal domain with weighted regions, where the
weight is either 0 or 1. Hence computing that measure
bears similarity with the standard shortest path queries
in weighted regions. The algorithm in~\cite{ExactPartial} computes 
the partial \Frechet similarity measure in  time, by constructing a "shortest-path map" type decomposition.

In another recent work \cite{BuchinLocallyFrechet}, 
Buchin \etal~introduce locally correct \Frechet matchings. They introduce the local correctness criterion for \Frechet matchings and prove
that there always exists at least one locally correct \Frechet matching between any
two polygonal curves. They provide an 
 algorithm to compute
such matching, where
 is the total complexity of the two curves.


Although the \Frechet distance is considered to be a high quality metric to measure
the similarity between polygonal curves, it is very sensitive to the presence of outliers. 
In \cite{Jaywalking}, Driemel and Har-Peled
discuss a new notion of robust \Frechet distance, 
where they allow  shortcuts between vertices of one
of the two curves, where  
is a constant given as an input parameter.
They provide a constant factor
approximation algorithm for finding the minimum 
\Frechet distance among all possible -shortcuts.
However, their approach has this 
drawback that a shortcut is selected without considering the length of the ignored part. Therefore, such shortcuts may remove a significant portion of a curve.
Recently, in another work~\cite{SackAminPaper}, 
authors propose
an alternative \Frechet distance measure to tolerate outliers,
considering the length of portion of the curves that must 
be discarded. Roughly, their goal is to minimize the length of 
subcurves of two polygonal curves that need to be ignored to achieve a given  \Frechet distance.


\subsection{Map Matching}
\label{sec:RelatedMapMatching}

In GIS applications, the method of sampling the  movements of vehicles using GPS is affected 
by errors and consequently produces inaccurate trajectory data. To become useful, 
the data has to be related to the underlying road network by using map matching 
algorithms. A quality map matching algorithm utilizing the \Frechet distance is 
introduced in~\cite{AltERW03a}.

Given a planar graph  as a road network and a polygonal curve  as a 
trajectory of a vehicle, the objective is to find a path   
in graph  with minimum \Frechet distance to curve . To find such a path, 
Alt \etal ~\cite{AltERW03a} generalized  the definition of free space 
between two curves to the free space between a graph and a curve as follows.

The free space of graph   and  curve  is the union of all free spaces of edges of 
 with the polygonal curve . Observe that the free space of one node  with 
curve  is a one-dimensional free space (denoted by ), 
and the individual free spaces of all 	edges 
incident to node  with curve  share a one-dimensional free space at . 
Thus, we can 
glue together the two-dimensional free-space diagrams along the one-dimensional free space 
they have in common, according to the adjacency information of the graph. 
The resulting three-dimensional structure is called \emph{free-space surface} of graph  and curve  
in~\cite{AltERW03a} (see Figure \ref{fig:freespacesurface}). 

\begin{figure}[t]
	\centering
	\includegraphics[width=0.75\columnwidth]{figs/surface}
	\caption{Free-space surface consists of free-space diagrams glued
together according to the topology of graph . Grey dashed path is
a monotone path in the free space.}
	\label{fig:freespacesurface}
\end{figure}

Let  be an edge of graph . Furthermore,  
let  be an edge-curve free-space diagram 
corresponding to edge , curve , and distance .
  consists of one dimensional free-space ,
then  (size of curve ) cells in a row , 
and another one dimensional free-space (see Figure \ref{fig:freespacesurface}
and Figure \ref{fig:pointers}).


In~\cite{AltERW03a} it has been shown that, after constructing 
a free surface corresponding 
to a planar graph  and a polygonal curve ,  there exists a 
path  in  s.t.  
iff there is a monotone path 
in the free-space surface from a lower left corner of
some individual edge-curve free-space diagram to an upper
 right corner of some other individual edge-trajectory 
free-space diagram (e.g., see the gray dashed path 
in Figure \ref{fig:freespacesurface}).

For   a continuous interval of white points 
in , let the reachability pointers 
 and  be the leftmost 
and the rightmost white points, respectively, 
of  that can be reached from some point
in  by a monotonic path in 
(see Figure \ref{fig:pointers}).
As a first step of the decision algorithm in~\cite{AltERW03a}, 
all one-dimensional free-spaces  
(for every vertex ), and also reachability pointers
are computed.
Next, the algorithm sweeps a line from left to
right (in direction of ) over all free spaces
at the same time while maintaining the points on the
sweepline that are reachable by some monotone path in
the free space from some lower left corner. It then updates 
this reachability information (using the 
reachability pointers)  Dijkstra-style while
advancing the sweepline. 


\REM{
Let  denote a maximal white interval on the bottom side of a cell in .
For each  in , two pointers are computed:
 which points to the leftmost point reachable from 
on  and  which points to the rightmost point reachable from 
on .  
}








\REM{
 The decision algorithm in~\cite{AltERW03a} consists of three stages: 
a preprocessing stage which computes the free-space surface, a dynamic programming stage,
which decides if there exists a feasible path in the free-space surface,  
and a path reconstruction stage which constructs the path  in .
}


\REM{
Given graph , 
polygonal curve , and a distance ,
first all one-dimensional free-spaces  are constructed (for all ).
Let  and 
 denote the leftmost and the rightmost point on ,
respectively.
Let  be an edge of graph , then  is a 
two dimensional free space corresponding to edge , 
curve  and distance . 



For a vertex , let  be the set of all points
 in  for which there exists a  and a path
 from  to  in  such that there is a monotone feasible path from
}

\REM{

Next, to decide if a path  exits or not,  
the algorithm in~\cite{AltERW03a} sweeps a line 
from left to right (in the direction of curve ) over all free spaces at the same 
time while maintaining the points on the sweep-line that are reachable by a monotone 
path in the free space from some lower left corner. It then 
updates this reachability information while advancing the sweep-line.  



Let  be a priority queue.  At start , for all .
 is in form of chain of white intervals on  ~\cite{AltERW03a}.
Conceptually all  are swept at once by a vertical sweep line from left to right. 
Let  indicate the position of the sweep-line. For each 
, a set  of white points is stored  
which is computed in dynamic programming manner.
 consists of all reachable points , 
such that  is to the right of , 
and for which the last segment of their associated 
feasible monotone path crosses or ends at the sweep line.
In~\cite{AltERW03a}, it has been shown  that 
every , for , is a consecutive chain, for every value of .
 is initialized with all white . For all , if 
is white we set , otherwise . 


\renewcommand{\labelenumi}{\Roman{enumi}.}\itemsep1pt

\begin{enumerate}

\item Remove the leftmost  interval from 


\item Let  be the consecutive chain that contains , insert the next white interval of  which lies to the right of  into .

\item For each   adjacent to , update  to comply with 
the new value of . To do so,  must be merged 
with . Because  is a consecutive chain for every value of ,
merge can be done by simply checking the interval endpoints.
As soon as the left endpoint of  changes, the old 
interval in  is deleted and the new one is inserted. 

\item For each interval  that has been recently added to , store
a path pointer to the interval .

\end{enumerate}


The algorithm ends in one of the two cases:
Either  a  is found such that , then 
there exists a path  in  with .  
Or,  is empty, which means
that there is no path in  in  \Frechet distance to .
In the first case, the path pointers are used to 
construct a path  in  together with a feasible monotone path 
in the free-space surface.  More details of the algorithm can be found in ~\cite{AltERW03a}.

}
Given a planar graph  with  vertices, 
a polygonal curve  
with length  and a distance , 
the algorithm decides in  time whether there exists a path
 in  such that  
 . 
One can  use  parametric search equipped with the decision algorithm, 
to find a path a  in  which minimizes , 
by spending   time and using  space.
The decision algorithm in~\cite{AltERW03a}
is only a log-factor slower than the standard \Frechet distance decision problem, although 
it accomplishes a  more complicated task of comparing curve 
to all possible curves in graph .


\begin{figure}[t]
	\centering
	\includegraphics[width=0.7\columnwidth]{figs/pointers}
	\caption{Reachability pointers}
	\label{fig:pointers}
\end{figure}


Map Matching based on the weak \Frechet distance has been also studied
by Brakatsoulas~\etal~\cite{VehicleTracking}, who give an  algorithm, where  is the size of the curve and  is the size of the graph. 
As explained before, the decision problem for the weak \Frechet distance
between two curves can be solved by testing if there
exists any path in the free space of the two curves from
lower left corner to upper right corner. This
can be done using any graph traversal algorithm such
as depth-first search in  time.
In~\cite{VehicleTracking}, this approach 
is generalized to the map matching
problem by applying depth first search to
the free-space surface. They initialize the search with all
white lower left corners of individual edge-trajectory
free spaces, and stop the search if some upper
right white corner is found. Since the free-space surface
consists of  edge-segment cells, this algorithm runs
in  time, which is a log-factor faster than the
algorithm based on the normal \Frechet distance. Applying
parametric search for optimization, in the same way as
in~\cite{AltG95}, adds an additional log-factor to the runtime
for a total of  to solve the optimization
problem. A new result~\cite{fasterMM-Weak1}
improves this running time to . The method provided in that 
paper does not involve parametric search, 
and hence is also easier to implement. 
 Their algorithm also yields an  algorithm for computing 
 the weak \Frechet distance between polygonal curves, 
 where one curve has size  and the other has size  (which
improves the  result given by~\cite{AltG95}).











\subsection{Constrained Free-Space Diagram}


Spatio-temporal data is any information relating space and time. 
Recently, there has been considerable research 
in the area of analyzing and modeling spatio-temporal data~\cite{Cons-Free}. 
Movement patterns in such data refer to 
events and episodes expressed by a set of entities.
The problem of detecting movement patterns in spatio-temporal data has recently received considerable 
attention from several research communities, e.g., geographic information science, data mining, data bases and algorithms.

Buchin \etal~\cite{Cons-Free} propose a new and powerful tool, called constrained free space, 
for the analysis of trajectories, which, in  particular, allows for more temporally aware analyses. 

Their new tool provides an algorithm for detecting single file movement. 
A single file is a set of moving entities, which 
are following each other, one behind the other. 

Let a spatio-temporal trajectory  of a moving entity  be
given by  time-space positions. That is,  = , 
where  gives the position of entity  
at time  for .
Assume that in between time stamps  and  the
entity  moves with constant speed along a straight line
from  to  for  ~\cite{Cons-Free}. 

For detecting a single file behavior, we are given  spatio-temporal trajectories
 of entities .
The entities  are moving in single
file for a given time interval if during this time each entity
 is following behind entity  for .
For the definition of following, fix three parameters
, and  with . The parameters
 and  specify minimum and maximum offsets in time, 
respectively, 
and  specifies a maximum offset in space. 
One can detect whether one trajectory
is following behind another during a fixed time interval by
searching for a monotone path in the -strip of
the free-space diagram of the trajectories. Let 
and  denote the average and maximum number of
cells intersected by the -strip per row or column
of the free-space diagram. Then, for two trajectories of 
complexity  each, it can be determined in  time 
and  space during which time intervals one 
trajectory is following behind the other. 
Furthermore, for  trajectories of complexity  each, one can detect in  
time and  space all single file behaviors for a given time interval~\cite{Cons-Free} .

























\section{\Frechet Distance in Different Metric Spaces}

In the \Frechet distance problem,
when the two curves are embedded in a general metric space, 
the distance between two points on the curves 
(i.e., the length of the shortest leash joining them) 
is not necessary the Euclidean distance, but sometimes it is a geodesic distance
due to existence of obstacles in the space.


\subsection{Geodesic \Frechet Distance}
In~\cite{WenkC08a}, Cook and Wenk  described an algorithm for the geodesic
\Frechet distance between two polygonal curves  and  
inside a simple polygon . 
To solve the decision version, they used the free-space diagram 
structure introduced by Alt and Godau~\cite{AltG95}. 
The main observation here is that when two curves are located inside a 
simple polygon, the free space inside a cell is -monotone, -monotone, 
and connected~\cite{WenkC08a}. As such, only the boundaries of 
a cell need to be computed to propagate reachability 
in the free-space diagram.
There are  cells in the free-space diagram. 
Computing the boundary of each cell takes  time by the algorithm of Guibas 
and Hershberger~\cite{Guibas86}. 
Then, the reachability information is 
propagated through all cells in a dynamic programming manner as~\cite{AltG95}. 
Since the free space inside each cell is monotone, 
propagating reachability though each cell takes constant time. Therefore, 
if  and  have total complexity  and polygon  has complexity , 
after a one-time preprocessing step of  time, the geodesic \Frechet decision
problem can be solved for
any   in  time and  space.
The space bounds follow because  space is needed per cell
and dynamic programming only requires that two rows of cells reside
in memory at any one time. The  term comes from storing the
preprocessing structures of~\cite{Guibas86} throughout the algorithm's execution.
Using parametric search, the exact 
geodesic \Frechet distance can be computed in 
. 
Cook and Wenk~\cite{WenkC08a} proposed a randomized algorithm using 
a {\em red-blue } intersection approach which  
finds the exact geodesic \Frechet distance in 
 expected time and  worst case
time.




Although the exact standard \Frechet distance is normally found in
 time using parametric search, parametric search
is often regarded as impractical because it is difficult to implement and
involves large constant factors~\cite{Cole87}. 
The randomized algorithm in~\cite{WenkC08a} 
is the first practical alternative to parametric search
for solving the exact \Frechet optimization problem.
Using the red-blue intersection approach as ~\cite{WenkC08a}, 
one can compute the exact \Frechet distance in  expected
time and  space, where  is the larger of the complexities of 
and ~\cite{WenkC08a}.










\subsection{Homotopic \Frechet distance}


The definition of the classical \Frechet distance allows the leash to switch discontinuously, 
without penalty, from one side of an obstacle or a mountain to another.
Chambers  \etal~\cite{Chambers10} study the \Frechet distance between two 
polygonal curves  and , located in the punctuated plane  consisting of  
 points. They introduce a continuity requirement on the motion of the leash, i.e. the leash cannot switch, discontinuously, from one geodesic to another; in particular, the leash can not jump over obstacles  and can sweep over a mountain only if it is long enough
(see Figure~\ref{fig:Hom}).
This new similarity metric is called {\em homotopic} \Frechet distance.
It finds applications in morphing and robotics.
In spaces where shortest paths vary continuously
as their endpoints move, such as the Euclidean plane, the
\Frechet distance and homotopic \Frechet distance are
identical. In general, however, homotopic \Frechet distance
could be larger (but never smaller) than the classical
\Frechet distance.
Given two polygonal curves  and  with complexity  and , respectively 
and  points in the plane,
the homotopic \Frechet distance between  and  in the plane can be computed
in  time~\cite{Chambers10}.



The algorithm for computing the geodesic \Frechet distance between two curves within a simple
polygon due to Cook and Wenk~\cite{WenkC08a}, is faster than the homotopic \Frechet computation algorithm in~\cite{Chambers10} by roughly a factor of . This is because they use a randomized strategy in place of parametric search. 








\begin{figure}[t]
	\centering
	\includegraphics[width=0.45\columnwidth]{Pics/Hom}
	\caption{The dashed lines show the leash between two objects 
	while they are moving on their corresponding curves. 
	The leash can not jump over the obstacles.}
	\label{fig:Hom}
\end{figure}












Cook \etal~\cite{Cook2009} develop algorithms to compute the \Frechet distance of 
two curves  on convex and non-convex polyhedral surface.
Let  be the total complexity of a problem space that contains
a polyhedral surface and auxiliary objects on the surface such as points,
line segments, and polygonal curves.
Then, \Frechet distance can be computed in  time and  space in a convex polyhedral surface and 
 time and  space in a non-convex polyhedral surface.

Cheung \etal~\cite{Cheung2009} consider two versions of 
the \Frechet distance problem in weighted planar subdivisions. In the first one, the distance between two points is the weighted length of the line segment joining the points. In the second one, the distance between two points is the length of the shortest path between the points. In both cases they give algorithms for finding a -factor approximation of the \Frechet distance between two polygonal curves. 


\section{Approximate \Frechet Distance}
A considerable amount of work 
has been done to improve running time
of computing \Frechet distance. 
Since improving the quadratic-time solution for general curves seems
to be hard, many researchers investigated \Frechet distance in restricted class 
of curves, rather than general curves. 
Also many works have been done 
to compute approximate \Frechet distance. 


In~\cite{DisceteFD}, Eiter and Mannila 
introduced a 
close approximation and slightly simpler version of the \Frechet distance, called {\em discrete 
\Frechet distance}, which
only considers vertices of polygonal curves.
They showed that given two polygonal curves of  and  vertices, their discrete 
\Frechet distance can be computed  in  time by a dynamic programming algorithm. 
Figure \ref{fig:DistFig} demonstrated the relationship between discrete 
and continuous \Frechet distance. 
It has been shown in~\cite{DisceteFD} that the discrete \Frechet distance is an 
upper bound for the \Frechet distance and the difference between these measures 
is bounded by the length of the longest edge of the polygonal 
curves. 
\REM{


Given a polygonal curve  of  vertices, let
a -walk along  be a partitioning of  into   disjoint non-empty
subsets . 
Assume two polygonal curves   and  with 
the sequence of endpoints of  and , respectively. 
A paired walk along  and  is a -walk  along  and a 
-walk  s.t. for 
either  or  ( i.e., either  or  contains exactly one vertex). 
Consider again the scenario in which the person walks along 
and the dog walks along . Then, the definition of paired walk 
is based on the three following cases: 
\begin{flushleft}
(1)   : the dog moves forward and the person stays.

(2)   : the person moves forward and the dog stays.

(3)   : both the person and the dog move forward.
\end{flushleft}


The cost of a paired walk  along 
two curves  and  is defined as 


Then, the discrete \Frechet distance between two polygonal curves 
 and  :

}



In a very recent work, 
Agarwal \etal~\cite{DiscreteSUBQuadractic} 
show how to break the quadratic barrier for the discrete \Frechet distance. 
They propose sub-quadratic 
 time
algorithm for computing discrete \Frechet distance 
using  space, 
where  and  are the complexity of 
two polygonal curves. 





\begin{figure}[t]
	\centering
	\includegraphics[width=0.65\columnwidth]{Pics/DistFD}
	\caption{ (a) The discrete \Frechet distance could be arbitrarily larger than the continuous distance, e.g., , .  (b) If we
put enough sample points on the two polygonal chains, 
then the resulting discrete \Frechet
distance, that is, , closely approximates .
}
	\label{fig:DistFig}
\end{figure}













In~\cite{LowerBound-FD}, Buchin \etal~gave a lower bound of  time for the decision version of the \Frechet problem.
They also showed that
this bound holds for 
the discrete version of the problem as well.
The only subquadratic algorithms known are for 
restricted classes of curves such as for closed
convex curves and for -bounded curves~\cite{Alt2003Comparison}. 
A curve is
called -bounded when
for any two points on the curve, 
the portion of the curve in between them cannot be further
away from either point than  times the distance between the two points. For closed convex
curves the \Frechet distance equals the Hausdorff distance and for -bounded curves the \Frechet
distance is at most  times the Hausdorff distance, and hence the  algorithm for
the Hausdorff distance applies~\cite{Alt2003Comparison}.
Aronov et al.~\cite{FDRevisited}  proposed a near linear time 
-approximation algorithm for the
discrete \Frechet distance, which only considers distances between vertices of the curves. Their
algorithm works for backbone curves, which are used to model protein backbones in molecular
biology. Backbone curves are required to have, 
unit edge length and a minimal distance
between any pair of vertices. 


In~\cite{Agarwal2002}, Agarwal \etal~consider the problem of approximating a polygonal curve 
 under a given error criterion by another polygonal curve  whose vertices are a subset of the vertices of . 
The goal is to minimize the number of vertices of  while ensuring that the error between  and  is 
below a certain threshold. 


In another recent work~\cite{c-packedFD},
the \Frechet distance has been studied between 
\emph{-packed} curves. 
A curve  is -packed if the total length of  inside any ball is bounded by  times the radius of the ball. 
While not all curves are -packed,the most real life curves are -packed~\cite{c-packedFD}.
Given two polygonal -packed curves  and  
with a total of  vertices, and
a parameter , 
they show that one can -approximate the \Frechet distance between  and  in
 time.











\REM{
Guibas \etal ~\cite{Guibas91approximatingpolygons}  solved the line simplification 
problem under several optimization criteria including \Frechet distance. 
They give an  time algorithm for finding  an 
approximation that consists of a minimum number of links 
that has \Frechet distance at most  to the original 
polygonal curve. 

Neyer~\cite{C-oriented} studies the C-oriented line simplification problem. 
Given a polygonal chain  represented by an ordered set of vertices  in the 
plane, a set of orientations C, and a constant , a "C-oriented"  
polygonal chain  is found 
which consists of the minimum number of line segments that has \Frechet distance at
most  to . 

}


 

\REM{
Despite \Frechet distance is  a high quality similarity measure for polygonal curves, 
it is very sensitive to the presence of outliers. Consequently, researches have been carried out to formalize the notion of similarity among a set of curves that tolerate outliers. 
They are based on intersection of curves in local neighborhood \cite{Kreveld11}, topological features \cite{Buchin10}, or  adding flexibility 
to incorporate the existence of outliers \cite{Jaywalking}. In \cite{Jaywalking}, 
Driemel and Har-Peled discuss a new notion of robust Fr\'{e}chet distance, where they allow  shortcuts between vertices of one of the two curves, where  is a constant specified as an input parameter. 
They provide a constant factor approximation algorithm for finding the minimum \Frechet distance among all possible -shortcuts. 
One drawback of their approach is that a shortcut is selected without considering the length of the ignored part. Such shortcuts could remove, for example, 
90 percent of the curve. As a result, substantial information about the similarity of the original curves could be ignored. A second drawback of their approach is
that the shortcuts are only allowed to one of the curves. Since noise could be present in both curves, shortcuts may be required on both to achieve a good result. 
}













\clearpage{}



\clearpage{}\chapter{\Frechet Distance with Speed Limits}
\label{ch:speedFD}
In the classical \Frechet distance problem, 
the speed of motion on the two polygonal curves is unbounded.
 in which  motion speeds are bounded, both from below and from above. 
More precisely, associated to each segment of the curves, 
is a speed range
that specifies the minimum and the maximum speed allowed for travelling along that segment.
We say that a point object traverses a curve with \emph{permissible speed},
if it traverses the polygonal curve from start to end
so that the speed used on each segment falls within its permissible range.

The decision version of the \Frechet distance problem with speed limits is formulated as follows:
Let  and  be two polygonal curves with minimum and maximum permissible speeds
assigned to each segment of  and .
For a given , is there an assignment of speeds so that two point objects
can traverse  and  with permissible speed and, throughout the entire
traversal, remain at distance at most  from each other?
The objective in the optimization problem is to find the smallest such .

In this chapter, we present a new algorithm that solves the 
decision version of the \Frechet distance problem with speed limits in  time. 
Our main approach is to compute a free-space diagram 
similar to the one used in the standard \Frechet distance algorithm (Section \ref{sec:classicalFD}).
However, since the complexity of the free-space diagram  in our problem
is cubic, in contrast to the standard free-space diagram that has quadratic complexity,  
we use a ``lazy computation'' technique to
avoid computing unneeded portions of the free space, 
and still be able to solve the decision problem correctly.
We then use our algorithm for the decision problem to
solve the optimization problem exactly in  time.

The \Frechet distance with speed limits we consider here
is a natural generalization of the classical \Frechet distance.
It has potential applications in GIS, when the speed of moving objects is considered
in addition to the geometric structure of the trajectories.
For a practical application of this metric, 
consider the case where 
trajectory of a vehicle is given 
to us, and we want to find the closest path in the road network to that trajectory. The good thing about the standard \Frechet metric 
is that we can use it here and find the closest path in the road network to the trajectory. 
Using our metric however, we can consider speed limits in the road network as well, 
and find a path in the road network which is more realistic.

This chapter is organized as follows. 
The problem is formally defined in the next section.
In Section~\ref{sec:decisionSpeed}, we describe a simple algorithm that solves the decision problem in  time.
In Section~\ref{sec:improvedSpeed}, we provide an improved algorithm for the decision problem 
that runs in  time.
Section~\ref{sec:optimization} describes how the optimization problem can be solved efficiently.
Finally, we summarize in Section~\ref{sec:conclusion} and outline directions for future work.







\section{Preliminaries} \label{sec:preliminaries-Speed1}




\paragraph{\Frechet Distance with Speed Limits.}

Consider two point objects  and  that traverse  and , respectively 
from start to end.
If we think of the parameter  in the parametrizations  and 
as ``time'', then  and  
specify the positions of 
 and  on  and  respectively at time .
The preimages of  and  can be viewed as
two point objects  and  traversing
 and , respectively,
with their positions at time  being specified by  and 
( is the length of ,  is the length of ).

In the classical definition of \Frechet distance,
the parametrizations  and  are
arbitrary non-decreasing functions, 
meaning that  and  (and therefore,  and )
can move with arbitrary speeds in the range .
In our variant of the \Frechet distance with speed limits,
each segment  of the curves  and 
is assigned a pair of non-negative real numbers  
that specify the minimum and the maximum permissible speed for moving along .
The speed limits on each segment is independent of the limits of other segments.
When  moves along a segment  with speed , 
 moves along the preimage of  (which is a unit segment) with speed .
Therefore, the speed limit  on a segment ,
forces a speed limit on the preimage of  which is bounded by the following two values:


We define a {\em speed-constrained parametrization of \/}
to be a continuous surjective function  with 
such that for any ,
the slope
of  at all points  is within . 
Here, we define the slope of a function  at a point  to be 
, where  approaches 0 only from above (right).
By this definition, if  is a continuous function, 
then the slope of  at any point  in its domain is well-defined,
even if  is not differentiable at . 

Given two polygonal curves  and  of lengths  and , respectively 
with speed limits on their segments, 
the {\em speed-constrained \Frechet distance\/} between  and  
is defined as:

where  ranges over all speed-constrained parametrizations of  
and  ranges over all speed-constrained parametrizations of .
Note that this new formulation of \Frechet distance is similar to the classical one,
with the only difference that the parametrizations here are restricted to have
limited slopes, reflecting the speed limits on the segments of the input polygonal curves.






\paragraph{Notation.}
We introduce some notation used throughout this chapter.

Let  be an  by  rectangle  in the plane.
Each point  uniquely represents a pair of points
 on the polygonal curves  and .
We decompose  into
 unit grid cells 
for ,
where each cell  corresponds to
a segment  on  and a segment  on .
Given a parameter ,
the {\em free space\/}  is defined as

We call any point  a {\em feasible\/} point.
An example of the free-space diagram for two curves  and  
is given in Figure~\ref{fig:diagram}.a.





Each line segment bounding a cell in  is called an {\em edge\/} of .
We denote by  (resp., by ) the left (resp., bottom) line segment bounding .
For a cell , we define the {\em entry side\/} of  to be ,
and its {\em exit side\/} to be .
Throughout this chapter, we process the cells in a {\em cell-wise\/} order,
in which a cell  precedes a cell  if either 
or   and  (this corresponds to the row-wise order of the cells,
from the first cell, , to the last cell, ). 

For an easier manipulation of the points and intervals on the boundary of the cells,
we define the following orders:
Given two points  and  in the plane, we say that 
 is {\em before\/} , and denote it by , if either  or   and  .
For an interval  of points in the plane, the {\em left endpoint\/} of , denoted by ,
is a point  such that  for all , .
The {\em right endpoint\/} of , denoted by , is defined analogously.
Given two intervals  and  in the plane,
we say that  is {\em before\/} , and denote it by , if
 and .
Note that   implies that none of the intervals  and 
can be properly contained in the other.







\section{The Decision Problem} \label{sec:decisionSpeed}

In this section, we provide an algorithm for solving the following decision problem:
Given two polygonal curves  and  of lengths  and  respectively ()
with speed limits on their segments, 
and a parameter ,
decide whether .
We use a free-space diagram approach, similar to the one used in the standard \Frechet distance problem (Section \ref{sec:classicalFD}).
However, the complexity of the ``reachable portion'' on the cell boundaries is different 
in our problem; namely, each cell boundary in our problem has a complexity of ,
while in the original problem cell boundaries have  complexity. 
This calls for a more detailed construction of the free space. 


Consider two point objects,  and , traversing  and , with their preimages,  and , traversing  and , respectively.
When  and  traverse  and  from beginning to the end,
the trajectories of  and  on  and 
specify a path  in  from  to .
Suppose that  passes through a point .
The slope of  at point  is
equal to the ratio of the speed of  at point 
to the speed of  at point .
Therefore, the minimum slope at  is obtained 
when  moves with its minimum speed at point , 
and  moves with its maximum speed at point .
Similarly, the maximum slope is obtained 
when  moves with its maximum speed, 
and  moves with its minimum speed.
We define 

where  and  are the speed limits for  and  as
defined in Section~\ref{sec:preliminaries-Speed1}.
Indeed,  and  specify
the minimum and the maximum ``permissible\rq{}\rq{} slopes 
for  at any point inside .
A path  is called {\em slope-constrained\/}
if for any point ,
the slope of  at  is within .
A point  is called {\em reachable\/} 
if there is a slope-constrained path from  to  in .


\begin{lemma} \label{lemma:reachable}
	 iff  is reachable. 
\end{lemma}

\begin{proof}
	The  part is straightforward. 
	For ,
	we need to show that if  is reachable, then  there exist a speed-constrained parametrization
	 of  (for some ), 
	and  a speed-constrained parametrization 
	 of  such that
	 for all .
	If  is reachable, then by definition there is a
	slope-constrained path  from  to  in .
	We construct two parametrizations  and  from  as follows.
	Let  be the sequence of cells 
	that  passes through, where  and .
	We can assume w.l.o.g. that for any  (),
	the path portion 
	is a line segment. Otherwise, we could replace 
	 by a line segment connecting the two endpoints of 
	which lies completely inside  (because  is convex),
	and whose slope remains within .

	Let  and  be the two endpoints of .
	The sequence  uniquely represents 
	(see Figure~\ref{fig:parametrizations}.a).
	We incrementally construct two point sequences  and  from  to represent
	 and , respectively.
	Let , , and .
	We start with , and .
	At each subsequent step  from  to , we update  and  as follows.
	Let  be the slope of .
	Since ,
	there exist a 
	and a  
	such that .
	Let , and set .
	We add to  the point , and to  the point 
	(see Figure~\ref{fig:parametrizations}.b).
	The slope of  segment  is , and 
	the slope of segment  is .
	Therefore, both these newly created segments 
	satisfy the corresponding speed constraints in  and .
	Therefore, after the th step, we obtain two point sets  and  of size 
	that fully define the speed-constrained parametrizations  and , respectively.
\end{proof}


\begin{figure}[t]
	\centering
	\includegraphics[width=0.75\columnwidth]{Pics/Parameterizations}
	\caption{
	(a) A \SC path  in the free space of  and ;
	(b) Two speed-constrained parametrizations of  and ,
	corresponding to the path .}
	\label{fig:parametrizations}
\end{figure}





\paragraph{A Simple Algorithm.}
We now describe a simple algorithm for the decision problem.
As a preprocessing step, the free space, , is computed by the algorithm.
Let  and .
Since  is convex within (Section \ref{sec:classicalFD}),
each of  and  is a line segment. 
The preprocessing step therefore involves computing line segments
 and  for all feasible pairs , which can be done in  time.
We then compute the reachability information on the boundary of each cell.
Let  be the set of reachable points in ,
and  be the set of reachable points in .
We process the cells in cell-wise order, from  to ,
and at each cell , we propagate the reachability information 
from the entry side of the cell to its exit side, using the following projection function. 
Given a point , the {\em projection} of  onto the exit side of  is defined as

For a point set , we define 

(see Figure~\ref{fig:project}.a).
To compute the set of reachable points on the exit side of a cell ,
the algorithm first projects  to the exit side of ,
and takes its intersection with .
More precisely, the algorithm computes 
  and  from
, , , and , using the following formula:

(see Figure~\ref{fig:project}.b).
Details are provided in Algorithm \ref{alg:main}.


\begin{figure}[t]
	\centering
	\includegraphics[width=0.58\columnwidth]{Pics/Projection}
	\caption{ (a) Projecting a point  and an interval  onto the exit side of ;
	(b) Computing reachable intervals on the exit side of a cell .
	Dark gray areas represent infeasible (obstacles) regions.
	Reachable intervals are shown with bold line segments.
	}
	\label{fig:project}
\end{figure}




\vspace{0.5em}
\begin{algorithm} [h]
\caption {\sc Decision Algorithm} \label{alg:main}
\algsetup{indent=1.5em}
\begin{algorithmic}[1]
	\vspace{0.5em}
	\baselineskip=1\baselineskip

	\STATE Compute the free space,  \\
	\STATE Set , \ 
		 for , \ 
		 for   
	\FOR { to } 
	 	\FOR { to }
			\STATE\label{lp:1}   
			\STATE\label{lp:2}   
			\STATE\label{lp:3}  
			\STATE\label{lp:4}  
		\ENDFOR
	\ENDFOR
	\STATE\label{line:last} Return 
``{\sc yes}" if , 
``{\sc no}", otherwise. 

\end{algorithmic}
\end{algorithm}
\vspace{0.5em}




\begin{lemma} \label{lemma:cell-process}
After the execution of Algorithm~\ref{alg:main}, 
	a point  is reachable 	
	iff .
\end{lemma}

\begin{proof}
	We prove the lemma by induction on the cells in cell-wise order.
	 
	Let .
	Then, by our construction, there is a point 
	such that .
	By induction hypothesis,  is reachable, and therefore,
	there is a \SC path  in  connecting  to .
	Now,  concatenated with  is a slope-constrained path from  to , 
	implying that  is reachable.
	 
	We show that any point  which is not in  is unreachable.
	Suppose the contrary, i.e.,  is reachable.
	Then, there exists a \SC path  in  that connects  to .
	Because the slope of  cannot be negative,  must
	cross  at some point .
	Now,  is reachable from , because it is on a \SC path from  to .
	Therefore,  by induction.
	Consider two line segments  and  that connect  to 
	with slopes  and , respectively.
	Since ,
	the portion of  that lies between  and  must cross either  or .
	But, it implies that the slope of  at the cross point falls out of the permissible range ,
	and thus,  cannot be slope-constrained: a contradiction.
\end{proof}

\begin{corollary} \label{cor:correctness}
	Algorithm~\ref{alg:main} returns 
`` {\sc yes}" iff .
\end{corollary}
\begin{proof}
	This follows immediately from Lemmas~\ref{lemma:reachable} and \ref{lemma:cell-process}.
\end{proof}

We now show how Algorithm~1 can be implemented efficiently.
Let a {\em reachable interval\/} be a maximal contiguous subset of reachable points on 
the entry side (or the exit side) of a cell.
Therefore, each of  and  can be represented as a sequence of reachable intervals.
We make two observations:

\begin{obs} \label{obs:newInterval}
	For each cell , the number of reachable intervals on  is at most one more than
	the number of reachable intervals on .
\end{obs}

\begin{proof}
	\REM{We show that the projection of reachable intervals from the entry side of a cell 
	to its exit side can produce at most one new reachable interval.}
	Let  be the set of reachable points on ,
	and let  be the projection of  onto .
	Since the projection on each reachable interval on the exit side is contiguous,
	no reachable interval in  can contribute to more than one reachable interval in .
	Therefore, the number of intervals in  is at most equal to the number of intervals in .
	(Note that projected intervals can merge.)
	However, after splitting  between  and ,
	at most one of the intervals in  (the one containing ) may split into two, 
	which increases the number of intervals by at most one.
\end{proof}

\REM{
\begin{corollary} \label{cor:numIntervals}
	The number of reachable intervals on the entry side of each cell  is .
\end{corollary}

\begin{proof}
	Since there are at most  cells before  
	that can contribute to the number of intervals on ,
	and we start with one reachable interval (the one containing only (0,0))
	at the beginning, the number of intervals on  can be at most~,
	bu Observation~\ref{obs:newInterval}
\end{proof}
}

\begin{corollary} \label{cor:numIntervals}
	The number of reachable intervals on the entry side of each cell is .
\end{corollary}

The above upper bound of  is indeed tight as proved in Section~\ref{sec:improvedSpeed}.


\begin{obs} \label{obs:order}
	Let  be a sequence of intervals on the entry side of a cell . 
	If  then .
\end{obs}

\begin{proof}
	For all ,
	let  be the line segment connecting  to ,
	and  be the line segment connecting  to .
	The observation immediately follows from the fact that
	all segments in the set  have slope  (and thus are parallel),
	and all segments in  have slope .
	Note that this proof holds even if the intervals in the original sequence and/or
	intervals in the projected sequence overlap each other.
\end{proof}

\REM{
Note that for any two reachable intervals  and  on the entry side of a cell (),
we have either  or .
Therefore,  defines a total order
on the set of reachable intervals on the entry side (and the exit side) of a cell.
As a result, Observation~\ref{obs:order} is applicable to the sequence of reachable intervals as well.
}

\begin{theorem} \label{thm:naive}
	Algorithm~\ref{alg:main} solves the decision problem in  time.
\end{theorem}

\begin{proof}
	The correctness of the algorithm follows from Corollary~\ref{cor:correctness}.
	For the running time, we first compute the time needed for processing a cell .
	Let  be the number of reachable intervals on the entry side of .
	We use a simple data structure, like a linked list, 
	to store each  and  as a sequence of its reachable intervals (sorted in  order).
	We show that Lines~\ref{lp:1}--\ref{lp:4} can be performed in  time.
	In particular,  Line~\ref{lp:1} can be performed by a simple concatenation of two lists in O(1) time;
	and Lines \ref{lp:3} and \ref{lp:4} involve an easy intersection test for each of the intervals in , 
	which takes  time.
	The crucial part is Line~\ref{lp:2}
	at which reachable intervals are projected. 
	Computing the projection of each interval takes constant time.
	However, we need to merge intersecting intervals afterwards. 
	By Observation~\ref{obs:order}, the merge step can be performed via a linear scan, 
	which takes  time.
	The overall running time of the algorithm is therefore .

	Since  by Corollary~\ref{cor:numIntervals}, and there are  cells,
	a running time of  is immediately implied.
	We can obtain a tighter bound by computing  explicitly.
	Define , for .
	 denotes the number of reachable intervals on the 
	entry side of all cells  with .
	By Observation~\ref{obs:newInterval}, 
	each of the  cells contributing to  can produce at most 1 new interval.
	Therefore, . 
	Starting with , we get . 
	Thus,
	
\end{proof}






\section{An Improved Algorithm} \label{sec:improvedSpeed}

In the previous section,
we provided an algorithm that solves the decision problem in  time.
It is not difficult to see that any algorithm which is based on computing the reachability information on
all cells cannot be better than  time.
This is proved in the following lemma.


\begin{figure}[t]
	\centering
	\includegraphics[width=0.95\columnwidth]{Pics/LowerBound}  
	\caption{ A lower bound example.
	The small gray diamonds represent obstacles in the free-space diagram.
	Reachable intervals are shown with bold black line segments.
	The numbers shown at each row and column represent speed limits on the corresponding segment.} 
	\label{fig:lowerbd}
\end{figure}

\begin{lemma} \label{lem:lowerbd}
	For any , there exist two polygonal curves  and  of size  such that in the  free-space diagram corresponding to  and , 
	there are  cells each having  reachable intervals on its entry side.
\end{lemma}

\begin{proof}
	Let  be a polygonal curve consisting of  horizontal segments of unit length
	centered at ,
	and let  be a polygonal curve consisting of  vertical segments, 
	where each segment  to  has unit length centered at the origin,
	and  has length , for a sufficiently small .
	Let .
	The free-space diagram  for the two curves has a shape like 
	Figure~\ref{fig:lowerbd} (the gray diamond-shape regions show obstacles in the free space
	each having a width of  in  direction).
	We assign the following speed limits to the segments of  and .
	All segments of  have speed limits , 
	 has speed limits ,  to  have limits , and
	 has limits .
The number of reachable intervals on each horizontal line  is increased by  
	at each row , for  from 1 to , 
	yielding a total number of  reachable intervals on the line .
	Since all these reachable intervals are projected to the right side in the last row, 
	each cell  for  has  
	reachable intervals on its entry side.
\end{proof}

While the complexity of the free space is cubic by the previous lemma,
we show in this section that it is possible to
eliminate some of the unneeded computations, and
obtain an improved algorithm that solves the decision problem in  time.
The key idea behind our faster algorithm is to use a ``lazy computation'' technique: 
we delay the computation of reachable intervals until they are actually required.
In our new algorithm, instead of computing the projection of all reachable intervals 
one by one from the entry side of each cell to its exit side, 
we only keep a sorted order of projected intervals,
along with some minimal information
that enables us to compute the exact location of the intervals whenever necessary.

To this end, we distinguish between two types of reachable intervals.
Given a reachable interval  in , 
we call  an \emph{interior interval}
if there is a reachable interval  in  such that ,
and we call  a \emph{boundary interval} otherwise.
The main gain, as we see later in this section, is that the exact location of interior intervals
can be computed efficiently based on the location of the boundary intervals.
The following iterated projection is a main tool that we will use.

\paragraph{Iterated Projections.}
Let  be a reachable interval on the entry side of a cell ,
and  be an interval on the exit side of a cell .
We say that  is an \emph{iterated projection} of , if there is a sequence of cells 
and a sequence of intervals  such that for all ,
 and 
(see Figure~\ref{fig:projection}).
In the following, we show that  can be computed efficiently from .

Given two points  and ,
we say that  is the {\em min projection\/} of , if there is a polygonal path  from  to  passing through 
a sequence of cells  (),
such that , ,
and  is a line segment whose slope is ,
for all .
The {\em max projection\/} of a point  is defined analogously. 


\begin{figure}[t]
	\centering
	\includegraphics[width=0.35\columnwidth]{Pics/IteratedProjection}  
	\caption{  is an iterated projection of .}
	\label{fig:projection}
\end{figure}

\begin{lemma} \label{lemma:project}
	Using  preprocessing time and space, we can build a data structure 
	that for any point  and any edge  of ,
	determines in  time if the min (or the max) projection of  
	onto the line containing  lies before, after, or on ;
	and in the latter case, computes the exact projection of  onto  in constant time.
\end{lemma}

\begin{proof}
	Suppose, w.l.o.g., that  is a vertical edge of , 
	corresponding to a vertex  of  and 
	a segment  of Q.
	Then . 
	Let  be the min projection of  on the line .
	Let  and .
The path connecting  to  in the definition of the min projection
	has slope  in each cell  it passes through.
	Such a path corresponds to the traversals of two point objects
	 and , where  traverses 
	with its maximum permissible speed, and  traverses 
	with its minimum permissible speed.
	\REM{
	Since the length of  is known, and the 
	maximum permissible speed for   along each interval  is given as  (see Section~\ref{sec:preliminaries-Speed1}),
	we can easily compute the time  needed for  
	to traverse  with its maximum speed.
	Now, having time , and the minimum permissible speeds for ,
	we can easily compute the distance  that  walks in  time, 
	if it starts from  and always uses its minimum speed.
	We can then simply compute .
	If , then we conclude that 
	lies in  and report its exact location.
	Otherwise, we report that  is before or after ,
	depending on whether  or .
	An analogous method can be used when  is a horizontal edge and/or 
	when max projection is required.
	}Since each of the point objects  and  can traverse  segments,
	computing the min projection can be easily done in  time. 
	However, we can speedup the computation using a simple table lookup technique.
	For , we keep two arrays  and   of size ,
	where for each , 
	 (resp., ) represents the minimum (resp., maximum) time 
	needed for  to traverse the interval .
	Similarly, we keep two arrays  and   for . 
	These four tables can be easily constructed in  time.
To find time  needed for  
	to traverse  with its maximum speed, we do the following:
	we first lookup  and  in  time.
	Clearly,  is equal to the time needed for  to traverse  
	(note that  is an integer).
	We also compute the time  needed for  to traverse 
	directly from the length of the interval, 
	and the maximum speed of  in interval .
	Therefore,   can be computed in  time total.
	By similar table lookups, we compute the times  and 
	needed for  to traverse  and , respectively,
	with its minimum speed.
	If , then we conclude that  lies in , 
	and we can easily compute its exact location on  by computing the distance that
	 traverses in  time using its minimum speed on interval .
	Otherwise, we output that  is before or after ,
	depending on whether  or , all in  time.
\end{proof}


\begin{corollary} \label{cor:project}
	If  is an iterated projection of , 
	then  can be computed from  in  time, after  preprocessing time. 
\end{corollary}

\begin{proof}
	This is a direct corollary of Lemma~\ref{lemma:project}
	and the fact that if  is an iterated projection of ,
	then  is the max projection of , and  is the min projection of .
\end{proof}


\paragraph{The Data Structure.}
The main data structure that we need in our algorithm is a dictionary 
for storing a sorted sequence of intervals. 
A balanced binary search tree can be used for this purpose.
Let  be the data structure that stores a sequence 
 of intervals in  order.
We need the following operations to be supported by .

\begin{itemize}
	\item[] {\sc Search:} 
		Given a point , find the leftmost interval  in  such that .
	\item[] {\sc Insert:} 
		Insert a new interval  into , right before ,
		or at the end of  if  is to the right of all existing intervals in . In our algorithm, inserted intervals are not properly contained in any existing interval of , and therefore, the
		resulting sequence is always sorted.
	\item[] {\sc Delete:} 
		Delete an existing interval  from . 
	\item[] {\sc Split:} 
		Given an interval , , split  into 
		two data structures  and , containing  and  , respectively. 
	\item[] {\sc Join:} 
		Given two data structures with interval sequences  and ,
		where each interval in  is before any interval in ,
		join the two structures to obtain a single structure  
		containing the concatenated sequence .
\end{itemize}

It is straightforward to 
modify a standard balanced binary search tree
to perform all the above operations in  time
(for example, see Chapter 4 in \cite{Tarjan83}).
Note that the exact coordinates of the interior intervals are not explicitly stored in the data structure.
Rather, we compute the coordinates on the fly whenever a comparison is made, 
in  time per comparison,  using Corollary~\ref{cor:const}.


\paragraph{The Algorithm.}

Let  (resp., ) denote the balanced search tree
storing the sequence of reachable intervals on  (resp., on ).
The reachable intervals stored in the trees are not necessarily disjoint.
In particular, we allow interior intervals to have overlaps with each other, 
but not with boundary intervals.
Moreover, the exact locations of the interior intervals are not explicitly stored.
However, we maintain the invariant that 
each interior interval can be computed in  time, and that 
the union of the reachable intervals 
stored in  (resp., in ) 
at each time is equal to   (resp., ).

The overall structure of the algorithm is similar to that of Algorithm~1.
We process the cells in cell-wise order,
and propagate the reachability information through each cell
by projecting the reachable intervals from the entry side to the exit side.
However, to get a better performance, 
cells are processed in a slightly different manner, as presented in Algorithm~2.
In this algorithm,  is considered
as a single line segment whose points are ordered by  relation.
For a set  of intervals, we define .
Given a data structure  as defined in the previous subsection,
we use  to refer to both the data structure and the 
set of intervals stored in .
Given a point set  on a line, by an interval (or a segment) of  we mean 
a maximal continuous subset of points contained in .


\vspace{0.5em}
\begin{algorithm} [h]
\caption {\sc Improved Decision Algorithm} \label{alg:improved}
\algsetup{indent=1.5em}
\begin{algorithmic}[1]
	\vspace{0.5em}
	\baselineskip=1\baselineskip

	\STATE\label{l:0} Compute the free space, 
	\STATE\label{l:1} \For  \Do  \STATE\label{l:2} \For  \Do 
	\STATE\label{l:3}  where 
	\FOR { to } \label{l:loop}
	 	\FOR { to }
			\STATE\label{l:cat}   
			\STATE\label{l:cop} Project  to the exit side of 
\STATE\label{l:s} 
			\STATE\label{l:del} \Foreach  \Do 
			\STATE\label{l:spl} 
			\STATE\label{l:ins1} \Foreach  \Do  
			\STATE\label{l:ins2} \Foreach  \Do  
		\ENDFOR
	\ENDFOR
	\STATE\label{l:last} Return {\sc yes} if , {\sc no} otherwise. 

\end{algorithmic}
\end{algorithm}
\vspace{0.5em}


The algorithm works as follows.
We first compute  in Line~\ref{l:0}.
Lines~\ref{l:1}--\ref{l:3} initializes the data structures 
for the first row and the first column of .
Lines~\ref{l:loop}--\ref{l:ins2} process the cells in cell-wise order.
For each cell , Lines~\ref{l:cat}--\ref{l:ins2} 
propagate the reachability information through 
by creating data structures  and  on the exit side of , 
based on  and , and the feasible intervals  and .
In Line~\ref{l:cat}, a data structure  is obtained by joining the interval sequences in
 and .
We then project  to the exit side of  in Line~\ref{l:cop}
by (virtually) transforming each interval  to an interval  on .
Since the projection preserves the relative order of intervals,
 by Observation~\ref{obs:order},
and we do not need to explicitly update the location of interior intervals on the exit side,
the projection is simply done by copying  to the exit side of  
(boundary intervals will be fixed later in Lines~\ref{l:ins1}--\ref{l:ins2}).
Furthermore, since  and  are not needed afterwards in the algorithm,
we do not actually duplicate . 
Instead, we simply assign  to the exit side, without making a new copy.
In Line~\ref{l:s}, we determine a set 
of intervals that are not completely contained in  or in .
All such intervals are deleted from  in Line~\ref{l:del}
(see Figure~\ref{fig:cell-intervals} for an illustration).
The remaining intervals in  have no intersection with the corner point .
Therefore, we can easily split  in Line~\ref{l:spl} 
into two disjoint data structures,  and ,
each corresponding to one edge of the exit side.
In Lines~\ref{l:ins1}--\ref{l:ins2} we insert the boundary intervals
to  and ,
which are computed as those portions of  that lie inside .
Note that whenever a boundary interval  is inserted into a data structure,
its coordinates are stored along with the interval.
After processing all cells, the decision problem is easily answered in Line~\ref{l:last}
of the algorithm by checking if the target point  is reachable.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.35\columnwidth]{Pics/CellIntervals}  
	\caption{An example of the execution of Algorithm 2 on a cell . 
		The intervals of  are shown in gray. 
		The black intervals in  represent the interior intervals.
		The intervals in 	 are boundary intervals 
		which are inserted in Lines~\ref{l:ins1}--\ref{l:ins2}.
	}
	\label{fig:cell-intervals}
\end{figure}

\begin{lemma} \label{lemma:prop}
	After processing each cell , 
	the following statements hold true:
	\begin{enumerate}
		\item[\em (i)] any interval inserted into  in Lines~\ref{l:ins1}--\ref{l:ins2} is a boundary interval,
		\item[\em (ii)] each interior interval on 	can be expressed as an iterated projection of a boundary interval.
\end{enumerate}
\end{lemma}
\begin{proof}
	(i) This is easily shown by observing that no interior interval is added to  in Line~\ref{l:s},
	and therefore,  cannot completely contain any interior interval.
	(ii) The proof is by induction on the cells in cell-wise order.
	Let  be an interior interval on . 
	Then,  is a direct projection of an interval  obtained in  Line~\ref{l:cop}.
	If  is a boundary interval, then we are done.
	Otherwise,  is an interior interval, and therefore, 
	it is by induction an iterated projection of another boundary interval .
	Since  and ,
	 is in turn an iterated projection of~.
\end{proof}

\begin{corollary} \label{cor:const}
	After processing each cell , 
	the exact location of each reachable interval on  is accessible in  time.
\end{corollary}

\begin{proof}
	Fix a reachable interval  on .
	If  is a boundary interval, then by Lemma~\ref{lemma:prop}(i), 
	it is inserted into a data structure by Lines~\ref{l:ins1}--\ref{l:ins2},
	and hence, its coordinates are stored in the data structure upon insertion.
	If  is an interior interval, then by Lemma~\ref{lemma:prop}(ii),
	it is an iterated projection of a boundary interval, and hence, its location
	can be computed in  time using Corollary~\ref{cor:project}.
\end{proof}

\REM{
\begin{lemma} \label{lemma:prop}
	During processing each cell , 
	the following statements hold true:
	\begin{enumerate}
		\item[\em (i)]   consists of at most three segments,
		\item[\em (ii)] at most two intervals are inserted into each of  and .
\end{enumerate}
\end{lemma}

\begin{proof}
	(i) The set  in Line~\ref{l:a} is obtained by removing two line segments 
	 and 	from . 
	Therefore,  consists of at most 3 segments, one at the beginning, one at the end, 
	and one at the middle of . If the middle segment in  is nonempty, it includes the point .
Therefore, each interval in  (defined in Line~\ref{l:s}) 
	intersects at least one of the following three points: 
	, , and .
	As a result,  has at most three segments.
	(ii) is a direct corollary of (i).
\end{proof}


\begin{lemma} \label{lemma:invar}
	The following invariants are maintained by Algorithm~2:
	\begin{enumerate}
		\item[\em (i)] the interval sequences  stored in  and  are sorted,
		\item[\em (ii)] .
	\end{enumerate}
\end{lemma}

\begin{proof}
	(i) Suppose by induction that the interval sequences in  and  are sorted. 
	Since any interval in  is before any interval in ,
	the result of the join operation in Line~\ref{l:cat} is a sorted sequence.
	The sequence remains sorted after the projection in Line~\ref{l:cop} by Observation~\ref{obs:order}.
	Moreover, deleting intervals in Line~\ref{l:del}
	does not change the order of the remaining intervals. 
	Therefore, the resulting two sequences obtained from the split in Line~\ref{l:spl} are sorted.
	It only remains to check the sequences after the insertions in Lines~\ref{l:ins1} and \ref{l:ins2}.
	Let  and  be the two (possibly empty) intervals in . 
	By our construction, each of  and , if not empty,
	intersects at least one of the endpoints of .
	On the other hand, no interval in  can intersect the 
	endpoints of , as we have already removed all such intervals in Line~\ref{l:del}.
	Therefore, neither  nor  can be properly contained in an existing interval in .
	It means that inserting  and  into  results in a sorted sequence.
	By the same argument,   is sorted after insertions, and therefore, 
	invariant (i) holds for  and .
\end{proof}

}

\begin{lemma} \label{lemma:invar}
	After processing each cell ,
	.
\end{lemma}

\begin{proof}
	We prove the statement by induction on the cells in cell-wise order.
	Recall from Section~\ref{sec:decisionSpeed} (Algorithm~1) 
	that .
	Therefore, it satisfies to show that 
	.
	By Line~\ref{l:cat}, .
	Let  be the set of intervals in  right after the execution of Line~\ref{l:cop},
	 be the set of intervals deleted in Line~\ref{l:del},
	 be the set of new intervals inserted in Lines~\ref{l:ins1}--\ref{l:ins2},
	and .
	Fix a point , and let  be the set of intervals in  containing .
	We distinguish between two cases: 
	\begin{itemize}
		\item : There are two possibilities:	
		(1) :
			Here, there is an interval in  that remains in  after
			deletion of  in Line~\ref{l:del}. 
			Therefore, .
		(2) :
			Here, all intervals of  are removed in Line~\ref{l:del}.
			However, since , there is an interval  such that .
			Therefore, after insertion of  in Lines~\ref{l:ins1}--\ref{l:ins2}, we have
			.

		\item  : 
		In this case, ,
		and hence . 
		Moreover, no interval in  can contain .
		Therefore, .
	\end{itemize}
	The above two cases together show that .
	Note that,  (by Lines~\ref{l:cat} and \ref{l:cop}),
	and .
	Therefore, ,
	which completes the proof, because 
	by induction.
\end{proof}


\begin{theorem}
	Algorithm~\ref{alg:improved} solves the decision problem in  time.
\end{theorem}

\begin{proof}
	The correctness of the algorithm follows from Lemma~\ref{lemma:invar},
	combined with Lemma~\ref{lemma:cell-process}.
	For the running time, we compute the number of operations
	needed to process each cell  in Lines~\ref{l:cat}--\ref{l:ins2}.
	Let  denote the time needed for each data structure operation.
	Line~\ref{l:cat} needs one join operation that takes  time.
	Line~\ref{l:cop} consists of a simple assignment taking only  time.
	To compute the subset  in Line~\ref{l:s}, we start walking from 
	the two sides of , and add intervals to  until we reach 
	the first intervals from both sides that do not belong to .
	Moreover, we find the interval , 
	and start walking around  in both directions until we find all consecutive intervals around  
	that lie in  (see Figure~\ref{fig:cell-intervals}).
	To check if an interval lies in  or not, we need to compute the coordinates
	of the interval that can be done in  time.
	Therefore, computing  takes  time in total.
	Line~\ref{l:del} requires  delete operation that takes  time.
	Line~\ref{l:spl} consists of a split operation taking  time.
	The set  used in Lines~\ref{l:ins1}--\ref{l:ins2}
	can be computed in  time by a linear scan over the set .
	Since  consists of at most three segments (see Figure~\ref{fig:cell-intervals}),
	computing  in Lines~\ref{l:ins1}--\ref{l:ins2} takes constant time.
	Moreover, there are at most four insertion operations in Lines~\ref{l:ins1}--\ref{l:ins2}
	to insert boundary intervals.
	Therefore, Lines~\ref{l:ins1}--\ref{l:ins2} takes   time.
	Thus, letting ,
	processing each cell  takes  time in total.
	Since at most four new intervals are created at each cell,
	the total number of intervals created over all cells is .
	Note that any of these  intervals can be deleted at most once,
	meaning that . 
	Moreover, 	each comparison made in the data structures 
	takes  time by Corollary~\ref{cor:const},
	and hence, .
	Therefore, the total running time of the algorithm is 
	O(.
\end{proof}







\section{Optimization Problem} \label{sec:optimization}


In this section, we describe how our decision algorithm can be used to 
compute the exact value of the \Frechet distance with speed limits between two polygonal curves. 
Let  and  .
Notice that the free space, , is an increasing function of .
That is, for , we have .
It is not hard to see that:

\begin{obs}
\label{obs:criticaltypes}
To find the exact value of ,
we can start from , and continuously increase  until
we reach the first point at which  contains a \SC path from  to .
This occurs at only one of the following ``critical values'':
\begin{itemize}
	\item[(A)] smallest  for which  or ,
	\item[(B)] smallest  at which  or   becomes non-empty for some pair ,
	\item[(C)] smallest  at which  is the min projection of , or 
		 is the max projection of , for some , and  .
\end{itemize}

\end{obs}


\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\columnwidth]{Pics/TypeC-Final}  
	\caption{(a,c) Type (C) critical distances in the standard \Frechet distance problem vs. 
	(b,d) type (C) critical distances in our instance of the problem.}
	\label{fig:typeCCC}
\end{figure}

Notice that here
type (A) and (B) of critical values are similar to 
the type (A) and (B) critical values in the standard \Frechet 
distance problem
(see Section \ref{sec:classicalFD} on Page \pageref{alg:StandardFDec}).
There are two critical distances of type (A) and 
 critical distance of type (B). All of these critical values 
can be computed in    time.

Here, type (C) critical distances are slightly different from 
those distances in the standard 
\Frechet distance problem. 
Figure \ref{fig:typeCCC} illustrates that difference. 
In the standard \Frechet problem, a type (C) critical distance
corresponds to the common distance of two vertices of one curve 
to the intersection point of their bisector 
with an edge of the other curve (see Figure \ref{fig:typeCCC}a). This happens 
when a new horizontal or vertical passage opens within the diagram
(see Figure \ref{fig:typeCCC}c).
All  type (C) critical values in the standard \Frechet distance problem 
can be computed in  time. 

In our instance of the problem, computing type (C) critical distances
has further complications.  
Those distances arise when a new slope-constrained path opens within 
which consists of a sequence of min-slopes (or max-slopes)
of the cells through which the path goes.
If  is reduced, this path will seize to exist 
(for an instance, see Figure \ref{fig:typeCCC}d).

The geometric meaning of type (C) critical distances is as follows
(see Figure \ref{fig:typeCCC}b for an illustration).
Consider two vertices  and  from  and
let  denote the time it takes for 
to travel from  to  on  when the speed of  on each 
segment is its corresponding maximum allowed speed.
Furthermore, let  and 
be two vertices of  where 
 is the first vertex after 
where  ( walks always 
with minimum allowed speed assigned to the segments of ).
Now, let  and   be two points on ,
where: 

(a)  is before  on ,

(b) both are located between  and ,

(c) ,

(d) and the time of travel from  to  is equal to . 

Then, among all such pairs of points , 
let  be the one which has the smallest distance. Since we are looking for the smallest distance where 
slope-constrained path opens up in the free-space diagram, 
 is a critical distance of type (C).


Next, we show how to compute all type (C) critical distances.
We first introduce a function, called {\sc Compute-Potential-Chains}
provided in Algorithm \ref{alg:potentialChains}.
Input to that function consists of a curve  and a fixed time .
The function computes a set  which includes all 
the subcurves of  from vertex  to vertex , , where  
is the first vertex after  such that .
Algorithm \ref{alg:potentialChains} accomplishes this by using two pointers, 
called  and 
. At the start of the algorithm,  points to the 
first vertex and  points to the second vertex of . 
Then  is scanned once to report the set  as described in 
Algorithm \ref{alg:potentialChains}.
In this algorithm,  means the polygonal chain 
of  which starts at  and ends at .


In Algorithm \ref{alg:typeCFinal}, we use the function stated 
in Algorithm \ref{alg:potentialChains}
to compute all the critical distances of type (C), 
for two curves  and . 
For every pair of vertices  and  of ,
we call function {\sc Compute-Potential-Chains} 
to compute subcurves  of  which start
at some vertex  and end at some vertex ,
, such that  is the first vertex 
after  where .
Then, for each curve , 
we do the calculation in Line 4 to compute critical distances of type (C).
We repeat the above for each pair of vertices  and  of 
and curve , in Line \ref{l:reprep}.
See Algorithm \ref{alg:typeCFinal} for more details.




\begin{algorithm} [t]
\caption {\sc Compute-Potential-Chains } 
\label{alg:potentialChains}
\algsetup{indent=1.5em}
\begin{algorithmic}[1]
	\vspace{0.5em}
	\baselineskip=1\baselineskip
	\STATE 
	\STATE Let  be the vertices of 

	\IF{}

	\STATE\label{l:0} 
	
	\STATE\label{l:0} 
	\WHILE{} \label{l:loopPot}

	\IF{}
	\STATE  
	\STATE , \ELSE 
	\STATE , \ENDIF
	\ENDWHILE
	\ENDIF
	\STATE  return 
	
	
\end{algorithmic}
\end{algorithm}









 \begin{algorithm} [t]
\caption {\sc Compute type(c) critical distances} \label{alg:typeCFinal}
\algsetup{indent=1.5em}
\begin{algorithmic}[1]

\FOR { each pair ,  }
\STATE A = {\sc Compute-Potential-Chains}
\FOR{each curve  in A}
\STATE let  be the list of edges of , \\
 determine if there exists pairs of points , , \\
such that  and 
\\
among all such pairs, 

add  minimum of the distances  to the critical distances of type (C).
\ENDFOR	
\ENDFOR	


\FOR { each pair ,  }
\STATE A = {\sc Compute-Potential-Chains}
\STATE Repeat Lines 3 and 4 for each curve  in  \label{l:reprep} \ENDFOR	

\REM{
\FOR { each }
\STATE B = 
\FOR{each curve  in B}
\STATE determine if a point  exists on the first edge of , \\
and a point  exists on the last edge of , \\
such that . \\
if exists, add distance  to critical distance of type (C)

\ENDFOR	
\ENDFOR		
}

\end{algorithmic}
\end{algorithm}




\begin{lemma}
\label{TimeOfTypeC}
Algorithm \ref{alg:typeCFinal} computes all critical values of type (C) 
in  total time. 
\end{lemma}

\begin{proof}
The correctness of Algorithm~\ref{alg:typeCFinal} follows from 
 Observation~\ref{obs:criticaltypes} and 
the geometric nature of type (C) critical distances
as described above. 

Algorithm \ref{alg:typeCFinal}  calls the function stated as Algorithm
\ref{alg:potentialChains},  times
in Line 2.
Thus, to prove the lemma, it is sufficient to show that 
the running time of Algorithm  \ref{alg:potentialChains} is linear in the size 
of curve .

Notice that the speed of travel on curve  in Algorithm \ref{alg:potentialChains}
is equal to the minimum allowed speed assigned to each segment of .
Thus, using the same approach as 
in Lemma \ref{lemma:project}, 
after linear time preprocessing, 
we can compute, in constant time, the time 
of travel from a vertex to another one.


The loop in Line \ref{l:loopPot} terminates  
when pointer  reaches the last vertex of .
Notice that pointer  always moves forward in direction  and 
points to vertices of  one by one, in order. Also,
pointer   always moves forward in direction  and is never 
before . Therefore, with one linear scan, 
Algorithm \ref{alg:potentialChains} computes and returns set .

Next, we show that the computation in Line 4 of 
Algorithm \ref{alg:typeCFinal} can be 
done in  time.
Let 
 and  be the first 
and last edges of 
(see Figure \ref{fig:TimeOfTypeC}).
Suppose that the coordinate of the points in that figure are:

Then, any point  on segment  can be written as:


and any point  on segment  can be written as:




We are looking for pairs of points   and  such that:






Thus,











\REM{
Replacing  by  and  by , we get:










}

\vspace{0.2in}
Note that above equations can be solved in constant time. The following 
cases arise: (I) no such pair  is  found, or 
(II) only one pair  is found. In this case,  is a critical distance, or
(III) more than one pairs of point  are found. In this case, we determine, 
in constant time, the pair 
 which has the minimum distance  
and then,  is a critical distance of type (C).
Hence, the running  time of Algorithm \ref{alg:typeCFinal} is .


\end{proof}
 



\begin{figure}[t]
	\centering
	\includegraphics[width=0.4\columnwidth]{Pics/LastComputation}  
	\caption{Proof of Lemma \ref{TimeOfTypeC}}
	\label{fig:TimeOfTypeC}
\end{figure}








\begin{theorem}
	The exact \Frechet distance with speed limits can be computed in  time.
\end{theorem}
\begin{proof}
To find the exact value of ,
we first compute all  critical distances of type (A), (B) and (C), 
and then we sort them. After sorting these values,
we do a binary search
(equipped with our decision algorithm)
to find the smallest  for which .
In each search step, we solve the 
decision problem, if it has a positive answer, 
we continue with the half which contains 
smaller values. Otherwise, we continue with the half containing larger values.
The running time is dominated by the time of sorting  values, 
which is .
\end{proof}



In the standard \Frechet distance problem, 
parametric search based approach is used to compute the exact value of \Frechet distance. 
Next, we outline that approach and show that we cannot apply it to our instance of the problem.

Alt and Godau~\cite{AltG95} observed that
any comparison-based sorting algorithm that sorts
, and  
(defined as functions of )
has critical values that include those of type (C).
This is because the critical values of type (C) in the
standard \Frechet distance problem occur if 
 or ,
for some , and . 
Therefore, to compute type (C) critical values, 
they   
used parametric search technique as follows.
First, compute all critical values of types (A) and (B), sort them
and then, perform binary search, and find two consecutive values  
 and  such that .
Let  be the set of endpoints ,  of intervals  
 and  that are nonempty for .
Then, Alt and Godau~\cite{AltG95} used Cole's parametric search method~\cite{Cole87}  
based on sorting the values in  
to find the exact value of . 
Set  consists of  polynomial functions 
 
of . The values of these functions at 
 will be given to a sorting network 
consists of parallel processors to get sorted (see Figure \ref{fig:PSproblem}).  
The crucial  requirement here is 
that at each stage,  
the transitivity of comparisons must hold, 
i.e.,  
and , implies that
. 


That is not the case in our instance of the problem
because of the speed limit constraints.
Here, the critical values of type (C) occur if 
 or , 
for some , and . 
Although  or 
can be computed in  time
using Lemma \ref{lemma:project}, 
their value depends on   and . 

Suppose that we use parametric search here. 
Assume that in the first stage of
parallel sorting, 
a processor compares
\REM{
e.g.  with . 
Let . 
Furthermore, assume that another processor compares e.g.
 with .
Let . 
Then, assume in the next stage, 
 is compared with  and 
let .
Unlike in the case of standard \Frechet distance problem, 
we cannot conclude that  
}
e.g.  with . 
Let . 
Furthermore, assume that another processor compares e.g.
 with .
Let . 
Then, assume in the next stage, 
 is compared with  and 
let .
Unlike in the case of standard \Frechet distance problem, 
we cannot conclude that  
by transitivity since 
another  affects 
the comparison. Therefore, it seems unlikely that we can 
apply the parametric search technique
to compute , as pointed out by Alt~\cite{AltFinal}.


Recently, in~\cite{HarPeled11}, 
a  randomized algorithm is introduced that computes 
the \Frechet distance between two polygonal curves in  
time with high probability, without using parametric search.
The key observation used in their algorithm is that
given a distance interval , one can
find all type (C) critical distances in  in
 time, where  is number of these distances in range .
They use a sweep line algorithm to achieve that running time.
In our instance of the problem, we have additional speed constraints, 
which makes it  hard to adopt the approach in \cite{HarPeled11}
to get a faster running time.
To be more precise,  consider the following sub-problem:

Suppose a curve , a time , a distance interval  
and two vertices  and  from curve  are given. 
Also assume that the object on  always walks 
with minimum speed associated to each edge. 
Now find all pairs of points  and  on  which satisfy the conditions:

(I) ,  (II) , and 
(III) time of travel from  to  on  is .
It is unclear how to find such pairs efficiently. 

\REM{
The total preprocessing time must be less than  for all 
the vertices of .
If the above sub-problem can be solved in 
 time,  to compute ,
one can use the randomized approach in \cite{HarPeled11}
to achieve an algorithm with expected running time less than .
}

\begin{figure}[t]
	\centering
	\includegraphics[width=0.5\columnwidth]{Pics/Functions.pdf}  
	\caption{Transitivity of comparisons must be kept during stages of parallel sorting in parametric search}
	\label{fig:PSproblem}
\end{figure}




\section{Conclusions} \label{sec:conclusion}

In this chapter, we introduced a variant of the \Frechet distance between two polygonal curves
in which the speed of traversal along each segment of the curves is restricted to be within a specified range.
We presented an efficient algorithm to solve the decision problem
in  time.
This led to a  time algorithm for finding 
the exact value of the \Frechet distance with speed limits.



Several open problems arise from our work.
In particular, it is interesting to consider 
speed limits in
other variants of the \Frechet distance studied in the literature. In the next chapter, we will study the
same problem  in the case where 
two curves lie inside a simple polygon.
Our result can be also useful 
in matching planar maps, where the objective is 
to find a curve in a road network that is as close as possible to a vehicle trajectory. 
In~\cite{AltERW03a}, the traditional \Frechet metric is used to match 
a trajectory to a road network. 
If the road network is very congested,  
the \Frechet distance with speed limits introduced here seems to find a more realistic path in the road network, 
close to the trajectory of the vehicle.
It is also interesting to extend our variant of the \Frechet distance 
to the setting where the speed limits on the segments of the curves change as functions over time.



Preliminary results of this chapter 
are presented in the 21st Canadian Conference on 
Computational Geometry~\cite{oursCCCG2009}. 
The full version of the paper is published in 
the special issue of Computational Geometry - Theory and Application~\cite{oursSpeedJournal}.
Alt~\cite{AltFinal} pointed out 
that due to the restrictions imposed by speed constraints, 
parametric search is not applicable.
It remains open whether there exists an algorithm 
that can solve the optimization 
problem faster than  time.
\clearpage{}


\clearpage{}\chapter{Speed-constrained Geodesic \Frechet Distance }
\label{ch:speed-geodesic}

\REM{
Given two polygonal curves inside a simple polygon,
we study the problem of finding the \Frechet distance between the two curves
under the following two conditions
(i) the distance between two points on the curves is measured as the length of the shortest path
between them lying inside the simple polygon, and 
(ii) the traversal along each segment of the polygonal curves 
is restricted to be between a minimum and a maximum permissible speed
assigned to that segment.

We provide an algorithm that decides in  time 
whether the speed-constrained geodesic \Frechet distance between two polygonal curves inside a 
simple polygon is within a given value , 
where  is the number of segments in the curves, and  is the complexity of the polygon. 
This leads to an algorithm for solving this variant of the \Frechet distance exactly
in  time and  space.
}





\section{Introduction} \label{sec:intro}




Several variants of the \Frechet distance have been studied in the literature.
Cook and Wenk~\cite{WenkC08a} studied  
the geodesic \Frechet distance inside a simple polygon.
In this variant, the leash is constrained to the interior of a simple polygon.  
Therefore,
a \emph{geodesic} distance is used to measure the length of the leash, which is 
the length of the shortest path inside the polygon connecting the two endpoints of the leash.
In~\cite{WenkC08a}, it is shown that the geodesic \Frechet distance 
between two polygonal curves of size  inside a simple polygon of size 
can be computed in  expected time and  space. 

In Chapter \ref{ch:speedFD}, we
introduced a generalization of the \Frechet distance,
in which users are allowed to set speed limits on each segment.
We showed that
for two polygonal curves of size  with
speed limits assigned to their segments,
the speed-constrained \Frechet distance 
can be computed in  time and  space. 
Note that in the problem instance of that chapter, there is no restriction for the leash to stay inside a simple polygon 
and thus, the leash lengths are measured using  the Euclidean distance.


In this chapter, we study the speed-constrained geodesic \Frechet distance inside a simple polygon
which is a simultaneous generalization of both 
\Frechet distances studied in~\cite{WenkC08a} and in the previous
chapter.
The decision version of the problem is formulated as follows:
Let  and  be two polygonal curves inside a simple polygon, with minimum and maximum permissible speeds assigned to each segment of  and .
For a given , 
can two point objects traverse
 and  with permissible speeds (without backtracking) and, 
throughout the entire traversal, remain at geodesic distance at 
most  from each other? The objective in the 
optimization problem is to find the smallest such . 

We show that the decision version of the speed-constrained geodesic \Frechet distance problem 
can be solved in  time and  space,
where  is the number of segments in the curves,
and  is the complexity of the simple polygon.
This leads to a solution to the optimization problem
in  time.

Algorithms for computing various variants of the \Frechet distance
are typically based on computing a free-space diagram consisting of  cells,
as we have seen in Chapters \ref{ch:related} and 
\ref{ch:speedFD},
and then propagating the reachability information 
one by one through the cells. While we adopt this general approach, 
the construction of the free-space diagram is more challenging in our problem
as we need to compute the whole free space inside each cell.
This is in contrast to other variants that only need to compute the free space on the boundaries of the cells.
A main contribution of our work is thus to 
fully describe the structure of the free space inside a cell,
establish its complexity,
and show how it can be computed efficiently.
Propagating the reachability information through the cells is also
more challenging  in our problem compared to the previous ones in previous chapters, 
as here, the shape of the free space inside a cell can
substantially affect the projection of the reachable intervals on its boundaries.


\REM{
The rest of the paper is organized as follows.  
We defines the problem formally in Section~\ref{sec:preliminaries} along with some notations.
Section~\ref{sec:ComputingFreeSpace} describes the structure of the free space 
and presents an algorithm for computing it efficiently. 
In Section \ref{sec:decision}, 
we propose an algorithm to compute our variant of the \Frechet distance. 
}


\section{Preliminaries} 
\label{sec:preliminaries}


A {\em polygonal curve\/} in  is  a continuous function 
 with , 
such that for each ,
the restriction of  to the interval  
is affine (i.e., forms a line segment).
The integer  is called the {\em length\/} of .
Moreover, the sequence  represents the set of {\em vertices\/} of .
For each , 
we denote the line segment  by . 
Given a simple polygon  and two points ,
the \emph{geodesic distance} of  and  with respect to ,
denoted by ,
is defined as the length of the shortest path between  and 
that lies completely inside .


\paragraph{Speed-constrained geodesic \Frechet distance.}
Let  be a polygonal curve such that
assigned to each segment  of ,
there is a pair of non-negative real numbers  
specifying the minimum and the maximum permissible speed for moving along .
We define a {\em speed-constrained parametrization of \/}
to be a continuous surjective function  with 
such that for any ,
the slope of  at all points  is within , where
 and .

Given a simple polygon 
and two polygonal curves  and  inside 
of lengths  and  respectively 
with speed limits assigned to their segments, 
the {\em speed-constrained geodesic \Frechet distance\/} of  and  inside 
is defined as

where  ranges over all speed-constrained parametrizations of  
and  ranges over all speed-constrained parametrizations of .


\paragraph{Free-space diagram.}
Let  be a  by  rectangle  in the plane.
Each point  uniquely represents a pair of points
 on the polygonal curves  and .
We decompose  into
 unit grid cells 
for ,
where each cell  corresponds to
a segment  on  and a segment  on .
Given  two polygonal curves  and  inside a simple polygon 
and a parameter ,
the {\em free space\/}  is defined as

We denote by  (resp., by ) the left (resp., bottom) line segment bounding . 
The {\em entry side\/} of  is defined as ,
and its {\em exit side\/} as . 
Given two points  and  on the boundary of a cell, we say that 
 is {\em before\/} , denoted by , if either  or 
 and .



\paragraph{Hourglass data structure.}
Fix a simple polygon .
Given two points , 
we denote by  the shortest path 
between  and  that lies inside ,
and denote its length by  .
Let  and  
be two 
line segments inside .
The \emph{hourglass} 
is defined as the maximal region bounded by 
the segments  and , 
and the shortest path chains , ,  and .
Three examples of hourglasses are illustrated in Figure~\ref{fig:OpenH}.
(See~\cite{Guibas86} for applications of the hourglass.)
Note that for any two points  and ,
the shortest path  is contained in .
The intersection of  and the boundary of 
consists of at most four polygonal curves,
each of which is called a \emph{chain} of .



\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\columnwidth]{Pics/hourglass}
	\caption{ (a) An open hourglass (b) A closed hourglass (c) An intersecting hourglass.
	}
	\label{fig:OpenH}
\end{figure}

\REM{
If  and 
are disjoint, the hourglass is called open, otherwise it is called closed. If  and  are crossing,
 is defined as the region bounded by 
, ,  and .
}




\newcommand{\Sub}{{\sigma}}

\section{Computing the Free Space Inside a Cell} 
\label{sec:ComputingFreeSpace}

In the classical \Frechet distance problem
(Section \ref{sec:classicalFD}),
the free space inside each cell 
is convex and can be determined in  time. 
When distances are geodesic, 
the free space is not necessarily convex,
but it is still connected and -monotone 
(see~\cite{WenkC08a} for the proof).



Therefore, to solve the geodesic \Frechet distance (without speed limits),
one only needs to compute the free space on the boundaries of the cells.
In~\cite{WenkC08a}, A. Cook \etal ~show how to compute  
the boundary of a cell in  time after
 time preprocessing, 
based on the algorithm of Guibas and Hershberger~\cite{Guibas86}.  
Also, one could use Chambers \etal's approach in~\cite{Chambers10}, 
to compute the boundary of the cells in  time.
In contrast to above works, in our generalized version where motion speeds are limited,
we need to compute the full description of the free space in the
interior of the cells as well in order to propagate the reachability 
information correctly. 

\REM{
To compute the full description of the free space in the interior of cells,
one could use Chambers \etal's approach in \cite{Chambers10}. 
That leads to  time solution, 
where  is the total complexity of the curves and 
 is the complexity of the polygon. Here, we 
propose an algorithm which 
computes the interior of all cells in  total time. 
}

We use the hourglass data structure to compute the 
boundary of the free space inside a cell.
Consider an hourglass  
and two points  and .
The shortest path  is either a straight segment 
(in case  and  see each other),
or consists of two tangents from  and  to the chains of 
plus a subpath between the two tangent points.
We denote this subpath by .
Note that  consists of a sequence of vertices of ,
lying on at most two chains of the hourglass.


\begin{definition}
Consider an hourglass  and two intervals 
 and ,
so that for any  and any , 
 is the same.
The region bounded by the intervals   and   
and the paths  and  is called a butterfly,
and is denoted by  (see Figure~\ref{fig:but}).
\end{definition}




\begin{lemma} \label{lemma:ButFhyperbolic}
	Given a butterfly ,
	the function   over the domain  
	is a hyperbolic surface. 
\end{lemma}

\begin{proof}
	Fix a point  and a point .
	Let  and  be the two endpoints of .
	Then .
	By the butterfly property, , , and  are fixed 
	for all  and  in the domain.
	Therefore,   is the sum of two  distances plus a constant,
	which forms a hyperbolic surface.
\end{proof}

\begin{figure}[h]
	\centering
	\includegraphics[width=00.5\columnwidth]{Pics/i-points}
	\caption{ An hourglass  with a butterfly .}
	\label{fig:but}
\end{figure}



Consider an edge  on a chain of the hourglass . 
Extend  to a line and find its intersection with  and  (as shown in Figure~\ref{fig:but}). 
We call such an intersection point an \emph{-point}. 
Note that the number of -points on each of the segments  and  is .


\begin{obs} \label{obs:-pointbutt}
	Any two consecutive -points  
	and any two consecutive -points 
form a butterfly .
\end{obs}


Consider two polygonal curves  and  inside .
Let  be a segment of ,
and  be a segment of .
By dividing  and  at -points,
the corresponding cell   in the free-space diagram 
is decomposed into  subcells,
where each subcell corresponds to a butterfly
(see Figure~\ref{fig:c-pointschains}).


Let  be a function
defined over all .
The intersection of the plane  with the function  determines the 
boundary of  inside the cell .
The boundary of  crosses the boundary of each subcell 
in at most two points, each of which is called a \emph{-point}.
The following two lemmas describe the structure of the free space inside  .

\begin{lemma}
	Any two consecutive -points on the boundary of  
	are connected with a hyperbolic arc, 
	and the line segment connecting the two endpoints of the arc lies completely inside .
\end{lemma}
\begin{proof}
	This follows from Lemma~\ref{lemma:ButFhyperbolic}.
\end{proof}

\begin{lemma}
	The number of -points inside a cell is . 
\end{lemma}
\begin{proof}
	This follows from the fact that 
any -monotone curve intersecting an  (non-uniform) grid 
	can cross at most  cells of the grid.
\end{proof}


\begin{figure}[h]
	\centering
	\includegraphics[width=0.4\columnwidth]{Pics/c-points}
	\caption{ The free space inside a cell. }
	\label{fig:c-pointschains}
\end{figure}


\paragraph{Computing c-points.}
Let  denote the line as a result of 
extending line segment .
Our algorithm for computing -points is based on the following observation.

\begin{obs} \label{lemma:shrinkexpand}
	Consider an hourglass  and a fixed .
	Let  be a point moving on ,
	and let  be a point that moves on the 
	line   to maintain 
	geodesic distance  from .
When  moves monotonically from  to ,  
	 has at most one directional change along .
\end{obs}


Observation~\ref{lemma:shrinkexpand} enables us to compute all -points inside a cell
by two linear walks. Details are provided in Algorithm~\ref{alg:ComputeFD}.
In this algorithm,  refers to a point on  which is closest to ,
 means that 
 is before  in direction ,
and  refers to the unique point in the free-space diagram 
corresponding to a point  and .
The output of the algorithm is four connected -point chains
as depicted in Figure~\ref{fig:c-pointschains}.


\renewcommand{\algorithmicrequire}{\textbf{Input:}}

\begin{algorithm} [h]
\caption {\sc computing c-points inside a cell } \label{alg:ComputeFD}
\algsetup{indent=1.5em}
\begin{algorithmic}[1]
	\vspace{0.5em}
	\baselineskip=1\baselineskip
	\REQUIRE  An hourglass  corresponding to a cell  and a fixed .
	
	\STATE \label{lp:extend} Compute -points on  and .
	\STATE \label{lp:q1q2} Find  s.t. .
	\STATE \label{lp:initialization0} Set  and  , assuming that .
	\STATE \label{lp:initialization} Set .
	
	\WHILE {  has not reached  } 
		\STATE \label{lp:move} Move  in direction , and 
			move  on  s.t.  
			until either  or  reaches an -point.	
		\IF{}
		\STATE Insert  into  if  , 
			otherwise  insert  into .
		\ENDIF
	\ENDWHILE
	
	\STATE Repeat lines 4--8 with  instead of  to obtain  and .
	\RETURN , , , and .
\end{algorithmic}
\end{algorithm}









\section{The Decision Problem} \label{sec:decision}

In this section, we show how the decision version of 
our \Frechet distance problem can be solved efficiently.
We use the notation of Chapter \ref{ch:speedFD}.
A path  is called {\em slope-constrained\/}
if for any point ,
the slope of  at  is within 
 and .
A point  is called {\em reachable\/} 
if there is a slope-constrained path from  to  in .
As shown in previous chapter,  if and only if the point  is reachable.

Reachable points on the entry side of each cell
form a set of  disjoint intervals, 
each of which is called a \emph{reachable interval}(as in previous chapter).
To decide if   is reachable,
the general approach is to propagate the reachability information
one by one, in row-major order, 
from  to .
The propagation in each cell  involves
projecting the set of reachable intervals 
from the entry side of the cell to its exit side.


Since the free space inside a cell is not necessarily convex in our problem, the projection can be affected by the boundary of  inside a cell
(see Figure~\ref{fig:merging}). We use the -point information computed in the previous section 
to compute projections.
Indeed, only -points on the convex hull of  and  
are needed to compute correct projections. Since -points inside each chain are stored in a sorted  (and ) order,
the convex hull of the chains can be computed using a Graham scan in  time.
We call the convex hull of  (resp., )
the \emph{left chain} (resp., the \emph{right chain}) of .

Given a point , Algorithm~\ref{alg:projection} 
computes the projection of 
 onto  in  time.



\begin{lemma} \label{lemma:project-point}
	Given a point , Algorithm~\ref{alg:projection} 
	computes the projection of 
	 onto  in  time.
\end{lemma}


\begin{proof}
	Finding each of the two tangents in Line~1 takes  time using binary search.
	The rest of the algorithm takes constant time.
\end{proof}


\begin{algorithm} [h]
\caption {\sc projection function} \label{alg:projection}
\algsetup{indent=1.5em}
\begin{algorithmic}[1]
	\vspace{0.5em}
	\baselineskip=1\baselineskip
	
	\REQUIRE A point 
	\STATE Let  and  be tangents (if they exist) from  to the left and to the right chain of , respectively.
	\STATE Let  and  be the projection of  in directions  and , respectively.	
	\STATE Let  and  be the projection of  in directions  and , respectively.
	\RETURN 
\end{algorithmic}
\end{algorithm}



\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\columnwidth]{Pics/merging2}
	\caption{ 
Projecting reachable intervals inside cells with convex and non-convex interior. 
	}
	\label{fig:merging}
\end{figure}


\begin{lemma} \label{thm:naive}
	Given a cell  with  reachable intervals on its entry side, 
	Algorithm~\ref{alg:projection} projects all the reachable intervals onto the exit side of 
	in  time.
\end{lemma}

\begin{proof}
Let  be a line in direction  
tangent to the left chain of ,
and let  be a line in direction  
tangent to the right chain of .
Let  and  be the intersection points of  and 
with , respectively.
For any point 
that lies outside , the projection of  is empty. Therefore, we delete those portions of reachable intervals
that lie outside . 
Now, the projection of each of the remaining intervals can be simply computed 
by projecting its two endpoints.


To avoid spending  time for projecting each endpoint, 
we use a cross-ranking technique. This reduces the total time needed for computing the tangents in Algorithm~\ref{alg:projection}.
Let  be the list of all endpoints of the reachable intervals on  in  order.
We construct another list  as follows. 
Perform an edge traversal of the right chain, starting with the rightmost edge.
Each edge encountered is extended to a line until it intersects the entry side at a point
which is then added to .
We merge  and  (in  order) to create a list .
Each item in  has a pointer to its corresponding -point or reachable interval endpoint, and vice versa.
Moreover, each item in  which comes from 
keeps a pointer to its preceding item in  which comes from .
Now, given a reachable interval endpoint , to compute the tangent from  to the right chain,
we simply find the item  corresponding to , 
and then find the item in  preceding  in . This item
uniquely determines the -point at which the tangent from  to the right chain occurs.
We process the left chain in the same way.
This enables us to compute each tangent in constant time, after the cross-ranking step,
leading to  total time for projecting all endpoints.
\end{proof}

Combined with the fact that  as in Chapter \ref{ch:speedFD},
the decision problem can be solved in  time and  space.




\begin{figure}[t]
	\centering
	\includegraphics[width=0.6\columnwidth]{Pics/LastComputation2}  
	\caption{Proof of Theorem \ref{thm:naivePoly}}
	\label{fig:PolyLast}
\end{figure}

\newcommand{\Funn}{\CF}


\begin{theorem} \label{thm:naivePoly}
   The exact value of  between curves  and  inside polygon 
   can be computed in  time.
\end{theorem}
\begin{proof}
We use the same technique as in Section  \ref{sec:optimization}
to compute .
There are two critical distances of type (A) and 
 critical distances of type (B).
Geodesic distances inside a simple polygon 
are computed by the algorithms of Guibas and 
Hershberger~\cite{Guibas86, Hershberger91}.
These algorithms preprocess the polygon in 
so that 
the shortest path queries between two points  or
between a point and a line segment 
can be solved in  time. 
Thus, we can compute type (A) and type (B) distances 
in  time. 




As in previous chapter, 
there are  critical distances of type (C). 
To compute them, we use Algorithm~\ref{alg:typeCFinal} on Page
\pageref{alg:typeCFinal}, 
after modifying Line 4 of that algorithm.
For the case where  and  are in the plane
and distances are Euclidean, we showed 
that Line 4 can be done in  time in Lemma \ref{TimeOfTypeC}. 
Here, because distances are geodesic, the 
run-time is  as explained in the following. 

In the algorithm of Guibas and 
Hershberger, all shortest paths between a point  and a line segment  are represented by a funnel, denoted by  
(see Figure \ref{fig:PolyLast}). 
is the region bounded by the line segment 
and the shortest path chains  and 
. 
Extend all line segments in the shortest path 
chains  and  of funnel 
to a line, and find the intersection of those lines with 
 (see Figure \ref{fig:PolyLast}). Do the same in funnel  with 
respect to segment . Now, maintain
the list of points which starts at 
,  the intersection points on  in order, 
and ends at , 
in a list denoted by  . Similarly, compute .
Next, we create 
two lists  and  from lists  and  to apply 
the same technique in Algorithm \ref{alg:potentialChains} and then, compute
critical distances of type (C)  in Algorithm \ref{alg:typeCFinal}.

Let  and 
. 
For each point , 
compute distance  and
find point(s)  on  where
, and insert  in . 
Likewise, 
for each point , 
compute distance  and
find point(s)  on  where
, and insert  in .

The run-time to create these two lists is  because
the function which represent distances from a 
point to a line segment inside a polygon is a bitonic function. 
Therefore, distances from point  (resp., point )  to points in  (resp., to points in  )
are increasing or decreasing or bitonic. 
Thus,  and  can be computed 
 in  time using the cross-ranking technique. 





Having computed these two lists  and , 
we can then use two pointers as in Algorithm 
\ref{alg:potentialChains} and 
by the same  calculation 
described in Lemma \ref{TimeOfTypeC}, 
compute critical distances of type (C).
Therefore, the run-time of Line 4 of Algorithm~\ref{alg:typeCFinal} 
is  in this case. Since that line is executed 
 times, type (C) 
critical distances can be computed in  total time.









After computing all type (A), (B) and (C) critical distances, we sort them 
and then, we perform binary search equipped with our decision algorithm, 
to find the the exact value of 
speed-constrained geodesic \Frechet  distance. 
Hence, we obtain an  time algorithm to compute 
for two curves  and  inside a simple polygon.
\end{proof}





\section{Conclusion}
In this chapter, we introduced a variant of the \Frechet distance between two polygonal curves inside a 
simple polygon,
in which the speed of traversal along each segment of the curves is restricted to be within a specified range.


We presented an algorithm that decides in  
time whether the speed-constrained geodesic \Frechet distance between two polygonal curves inside a 
simple polygon is within a given value , 
where  is the number of segments in the curves, and  is the complexity of the polygon. 


Several open problems arise from our work.
In particular, it is interesting to consider speed limits in
other variants of the \Frechet distance studied in the literature,
such as the \Frechet distance between two curves lying 
on a convex polyhedron~\cite{AnilFrechet}, or on a polyhedral surface~\cite{Cook2009}. 



Results of this chapter 
are presented in 22nd Canadian Conference on Computational Geometry~\cite{oursCCCG2010}.
\clearpage{}



\clearpage{}\chapter{Improved Algorithms for Partial Curve Matching}
\label{ch:partial}

\section{Introduction} 
\label{sec:introduction}

\REM{
The \Frechet distance is a widely-used metric for measuring the similarity of the curves. 
It finds applications in morphing~\cite{EfratGHMM02},
handwriting recognition~\cite{SriraghavendraKB07}, protein structure alignment~\cite{JiangXZ08}, etc.
This measure is often illustrated as the minimum-length leash needed for a
person to walk a dog, while each of them is traversing
a pre-specified polygonal curve without backtracking.
}
As described in Section \ref{sec:classicalFD},
Alt and Godau~\cite{AltG95} showed how the 
\Frechet distance between two polygonal curves
with  and  vertices can be computed in  time.
For their solution, they introduced the \fs diagram.
\REM{
The \fs diagram and its variants have been proved to be useful in other applications
involving the \Frechet distance
(see e.g. \cite{AltERW03,BuchinBG10,WenkC10,HR11}).

Various extensions of the \Frechet distance have been studied in the literature,
including \Frechet distance between two curves 
inside a simple polygon~\cite{WenkC10}, on polyhedral surfaces~\cite{CookW09}, and on simplicial complexes~\cite{HR11}.

}

As discussed in Section
\ref{sec:RelatedPartial},
Alt and Godau~\cite{AltG95} 
in their seminal work, 
studied the partial curve matching problem.
Given two polygonal curves  and  of size  and , respectively, 
they presented an algorithm that decides in  time whether
there is a subcurve  of  whose \Frechet distance to  is at most ,
for a given . 
Using parametric search, they solved the optimization problem of finding the minimum such 
in  time.

Later, Alt \etal~\cite{AltERW03a} proposed a generalization of the partial curve matching problem 
to measure the similarity of a curve to some part of a graph.
Given a polygonal curve  and a graph , 
they presented an -time algorithm to decide whether there is a path  in  whose 
\Frechet distance to  is at most , 
with  and  being the size of  and , respectively.
A variant of the partial curve matching
in the presence of outliers is studied by Buchin \etal~\cite{ExactPartial},
leading to an algorithm with  running time.


\paragraph{\bf Our results.\ }
In this chapter, we present a simple data structure, which we call \emph{\fs map},
that enables us to solve several variants of the \Frechet distance problem efficiently.
The results we obtain using this data structure are summarized below.
In the following,  and  represent the size of 
the two given polygonal curves  and , respectively, 
and  is a fixed input parameter.

\begin{itemize}\setlength{\itemsep}{.3em}
\renewcommand{\labelitemi}{}

	\item \emph{Partial curve matching}. \ 
	Given two polygonal curves  and , 
	we present an algorithm to decide in  time whether
	there is a subcurve  whose \Frechet distance to  is at most .
	This improves the best previous algorithm for this decision problem 
	due to Alt and Godau~\cite{AltG95}
	(described in Section \ref{sec:RelatedPartial}),
	that requires  time.
	This also leads to an  faster algorithm for solving
	the optimization version of the problem, using parametric search.
	
	\item \emph{Closed \Frechet metric}. \ 
	As described in Section \ref{sec:RelatedClosed},	
	Alt and Godau showed that 
	for two closed curves  and , 	
	the decision problem of whether the closed \Frechet distance between 
	and  (as defined in Section~\ref{sec:appl})
	is at most  can be solved in  time. 
	We improve this long-standing result by giving an algorithm that runs in  time.
	As a result, we also improve by a -factor 
	the running time of the optimization algorithm for computing the minimum such .

	\item \emph{Minimum/Maximum walk}. \ 
	We introduce two new variants of the \Frechet distance
	as generalizations of the partial curve matching problem.
	Given two curves  and  and a fixed , 
	the \emph{maximum walk} problem asks for the
	maximum-length continuous subcurve of  whose \Frechet distance to  is at most .
	We show that this optimization problem can be solved efficiently in  time,
	without additional  factor.
	The \emph{minimum walk} problem is analogously defined, and can be solved efficiently
	within the same time bound.

	\item \emph{Graph matching}. \ 
	Given a directed acyclic graph  with a straight-line embedding in ,
	for fixed ,
	we present an algorithm to decide in  time whether
	a given curve  matches some part of 
	 under a \Frechet distance of~, 
	with  and  being the size of  and , respectively.
	This improves the map matching algorithm of Alt \etal~\cite{AltERW03a}
	(described in Section \ref{sec:RelatedMapMatching})
	by an  factor for the particular case in which  is a directed acyclic graph.
	 


\end{itemize}


\REM{
They also provided an
 time algorithm to compute the \Frechet distance between two
closed curves. Since then, different variants of the \Frechet distance have
been studied in the literature which are all based on constructing
a data structure called free space diagram, introduced by Alt and Godau~\cite{AltG95}.
We present a data structure on top of the free space diagram
that besides its simplicity, allows us to compute the \Frechet distance between
two closed curves,  time faster than the algorithm by Alt and
Godau. In addition, our data structure can be employed in several
applications related to partial curve matching.
}

The above improved results are obtained using a novel simple approach for
propagating the reachability information ``sequentially'' 
from bottom side to the top side of the \fs diagram.
Our approach is different from and simpler than the 
divide-and-conquer approach used by Alt and Godau~\cite{AltG95}
(explained in Section \ref{sec:RelatedPartial}),
and also, than the approach taken by Alt \etal~\cite{AltERW03a}
(explained in Section \ref{sec:RelatedPartial}) which is
a mixture of line sweep, dynamic programming, and Dijkstra's algorithm.


The \fs map introduced in this thesis
encapsulates all the information available in the
standard \fs diagram, yet
it is capable of answering a more general type of queries efficiently.
Namely, for any query point on the bottom side of the \fs diagram, 
our data structure can efficiently report all points on the top side of the diagram 
which are reachable from that query point.
Given that our data structure has the same
size and construction time as the standard \fs diagram, 
it can be viewed as a powerful alternative 
or generalization. 

\REM{
The current lower bound
for deciding whether the \Frechet distance
between two polygonal curves with total  vertices is at most a given value ,
is  \cite{LowerBound-FD}.
However, no subquadratic algorithm is known for this decision problem,
and hence, it is widely accepted that the actual lower bound 
for this problem is  (see e.g.~\cite{AltBook2009}).
If this holds, then the results
obtained in this thesis do not only represent improvements, 
but are also optimal.
}

The remainder of this chapter is organized as follows.
In Section~\ref{sec:preliminaries}, we provide basic definitions
and elementary algorithms, such as vertical ray shooting, 
which will be used in our construction. 
In Section~\ref{sec:main}, we define the \fs map and 
show how it can be efficiently constructed.
In Section~\ref{sec:appl}, we present some applications of the \fs map to problems
such as partial curve matching, maximum/minimum walk, and closed \Frechet metric.
In Section~\ref{sec:graph}, we provide an improved algorithm
for matching a curve in a DAG.
We conclude in Section~\ref{sec:concl} with some open problems.




\section{Preliminaries} 
\label{sec:preliminaries}

\REM{
A {\em polygonal curve\/} in  is  a continuous function 
 such that for each ,
the restriction of  to the interval  
is affine (i.e., forms a line segment).
The integer  is called the {\em size\/} of .
For each , 
we denote the line segment  by .  

A {\em monotone reparametrization} of  
is a continuous non-decreasing function 
with  and .
Given two polygonal curves  and  of size  and , respectively, 
the {\em \Frechet distance\/} between  and  is defined as

where  denotes the Euclidean metric, 
and  and  range over all monotone reparameterizations of 
 and , respectively.
}
Here, we borrow some notations from previous 
chapters.
Given a parameter ,
the {\em free space\/} of the two curves  and  is defined as


We call points in  \emph{feasible}.
The partition of the rectangle  
into regions formed by feasible and infeasible points
is called the \emph{\fs diagram} of  and , denoted by 
(see Figure~\ref{fig:free-space}.a).


\begin{figure}[t]
	\centering
\includegraphics[height=0.4\columnwidth]{figs/free-space}
	\caption{(a) An example of a \fs diagram.
	(b) Proof of the crossing lemma.}
	\label{fig:free-space}
	\vspace{-0.5em}	
\end{figure}

Let  and  be two polygonal curves of size  and , respectively,
and  be a fixed parameter.
Following the notation used by Alt~\etal~\cite{AltERW03a},
we denote by , for , 
the one-dimensional \fs diagram ,
corresponding to the curve  and the point . 
For each ,
the intersection of the free-space diagram with the square  
is called a \emph{cell} of the diagram. Likewise, we call the intersection of  with each interval  a cell 
(or more precisely, the -th cell) of .

A curve is called \emph{feasible} if it lies completely within ,
and is called {\em monotone} if it is monotone in both - and -coordinates.
Given two points  and  in the free space, we say that 
 is \emph{reachable} from~,
denoted by ,
if there is a monotone feasible curve in  from  to~.
Alt and Godau~\cite{AltG95} showed that  
if and only if .
Clearly, reachability is ``transitive'':
if  and , then .
Given two points  and  in the plane, 
we write  if ,
and write  if .

\begin{lemma}[Crossing Lemma] \label{lemma:cross}
	Let  and   such that  and .
	If  and , then  and .
\end{lemma}

\begin{proof}
	Let  be a monotone feasible curve that connects  to . 
	Since  and  are on different sides of ,
	any monotone curve that connects  to  in 
	intersects  at some point  (see Figure~\ref{fig:free-space}.b).
	The concatenation of the subcurve from  to  
	and the one from  to  gives a monotone feasible curve from 
	 to . Similarly,  is connected to  by a monotone feasible curve through .
	\qed
\end{proof}

\REM{
\begin{figure}[t]
	\centering
	\includegraphics[width=0.4\columnwidth]{figs/cross}
	\caption{Crossing Lemma.}
	\label{fig:cross}
\end{figure}
}

For , we denote by  the set of feasible points in . 
 consists of  feasible intervals,
where each feasible interval is a maximal continuous set of feasible points,
restricted to be within a cell.
For any feasible point set  in ,
we define the \emph{projection} of  on  as


For an interval  on ,
we define the \emph{left pointer} of  on  ,
denoted by , to be the leftmost point in .
Similarly, the \emph{right pointer} of  on , denoted by ,
is defined to be the rightmost point in .
If  is empty, both pointers  and  are set to NIL.
These pointers were previously used in \cite{AltERW03a,AltG95},
and form a main ingredient of our data structure.
For a single point , we simply use , , and 
instead of , , and , respectively. 
The following observation is an immediate corollary of Lemma~\ref{lemma:cross}.

\begin{obs} \label{obs:sorted}
	For any two points  with , and for any ,
	we have  and .	
\end{obs}


For an interval  on a horizontal line, we denote by  and  
the left and the right endpoint of , respectively.
The following simple lemma 
will be used frequently throughout this chapter.


\begin{lemma} \label{lemma:scan}
	Given two sequences  and  of points on a horizontal line sorted from left to right, 
	we can compute for each point ,  
	the leftmost point  with 
	in  total time.
\end{lemma}

\begin{proof}
	We scan the two sequences simultaneously from left to right using two pointers.
	Whenever we reach a point ,
	we advance our pointer on  until we reach the first point 
	with . We then make all points in  scanned during this step up to
	(not including)  to point to .
	We then advance our pointer on  by one, and repeat the above procedure.
	\qed
\end{proof}


\REM{
\begin{obs} \label{lemma:scan}
	Given two sequences  and  of points on a horizontal line sorted from left to right, 
	we can preprocess the two sequences into a data structure of size  in  time,
	such that for any query point , 
	the leftmost point  with 
	can be reported in  time,
	assuming random access to the elements of .
\end{obs}


\begin{proof}
	We scan the two sequences simultaneously from left to right
	We scan the points in  in order from left to right,
	and for each point  in , assign  to all points  to the right of 
	which are not yet processed (i.e., are not yet assigned with any point of ).
	At each time, we keep a pointer to the leftmost non-processed point of ,
	and move the pointer to the right linearly as points of  are processed.
	It is easy to verify that during this process, each point of  
	is assigned with the nearest point of  to its right,
	and that each point of  and  is visited only once.
	\qed
\end{proof}
}


\subsection{Vertical Ray Shooting}
\label{sec:shooting}

The following special case of the vertical ray shooting problem
appears as a subproblem in our construction.
Consider a vertical slab  (see Figure~\ref{fig:shooting}).
For each , 
there are two (possibly empty) segments 
in the slab at height~,
attached to the boundaries of the slab, one from left and the other from right.
Given a query point ,
the vertical ray shooting problem involves finding
the first segment in the slab directly above .
If the query points are restricted to be among 
the endpoints of the segments,
we show below that the vertical ray shooting queries can be answered in 
time, after  preprocessing time.



\begin{figure}[t]
	\centering
	\includegraphics[height=0.37\columnwidth]{figs/shooting}
	\caption{An example of the execution of Algorithm~\ref{alg:shooting}.
Segments in the queue at the end of each step are shown in bold.
	}
	\label{fig:shooting}
\end{figure}


\begin{lemma} \label{lemma:shooting}
	Let  be a set of segments
	, and 
	 be a set of segments 
	with , for . 
	We can find for each segment , the first segment in  
	directly above  in  total time.
\end{lemma}


\begin{proof}
	Algorithm~\ref{alg:shooting} assigns to each segment  of ,
	an \emph{up} pointer that points to the first segment directly above ,
	if such a segment exists. 
	The algorithm makes use of a double-ended queue  
	(a combination of a queue and a stack, commonly known as ``deque''),
	that supports the standard operations
	{\sc push}(), {\sc pop}(), and {\sc top}(),
	along with two additional operations
	{\sc bottom}() and {\sc bottom-pop}(), that are analogous to
	{\sc top}() and {\sc pop}(), respectively,
	but applied to the bottom of the queue.


\begin{algorithm} [h]
\caption {\sc Ray-Shooting} \label{alg:shooting}
\algsetup{indent=1.5em}
\begin{algorithmic}[1]
	\vspace{0.5em}
	\baselineskip=1\baselineskip
	\STATE 
	\STATE 
	\FOR { from 2 to } 
		\WHILE {}  \label{l:w1-1}
			\STATE  \label{l:w1-2}
		\ENDWHILE 
		\WHILE {}  \label{l:w2-1}
			\STATE  \label{l:w2-2}
		\ENDWHILE 
		\STATE 
	\ENDFOR 
\end{algorithmic}
\end{algorithm}
	
	We say that a segment 
	is \emph{covered} by a segment ,
	if a vertical ray from  intersects .	
	For  ,
	let  and .
	The following invariant is maintained by the algorithm:
	At the end of iteration~, 
	 contains a subset of segments from 
	that are not covered by any segment from ,
	in a decreasing order of their lengths from bottom to the top of the queue.
	The invariant clearly holds for .
	Suppose by induction that the invariant holds for .
	In the -th iteration,
	we first pop off from the top of the queue all segments
	covered by , in Lines~\ref{l:w1-1}--\ref{l:w1-2}.
	Then, we remove from the bottom of the queue all
	segments covered by , in Lines~\ref{l:w2-1}--\ref{l:w2-2}.
	Finally, we add  to the top of the queue.
	(See Figure~\ref{fig:shooting} for an illustration.)
	It is easy to verify that after the insertion of ,
	the segments of  are still sorted in a decreasing order of their lengths
	(because we have already removed segments smaller than  from ),
	and that, no segment of  is covered by a segment in 
	(because we have removed covered segments from ).
	Furthermore, it is clear that any segment  removed from 
	is assigned to the first segment that is directly above ,
	because we are processing segments in order from bottom to the top.
	The correctness of the algorithm therefore follows.
	Note that after the termination of the algorithm,
	 still contains some uncovered segments from , whose
	up pointers are assumed to be NIL, 
	as they are not covered by any segment in .
	Since each segment of  is inserted into and removed from the queue at most once,
	Lines~\ref{l:w1-2} and \ref{l:w2-2} of the algorithm are executed at most  times,
	and hence, the whole algorithm runs in  time.
	\qed
\end{proof}

Consider the vertical slab , 
and the two sets of segments  and  as defined above. 
We call a segment  {reachable} from a segment ,
if there is a monotone path from a point on  to a point on  
not intersecting any other segment in .
For a segment , the \emph{topmost reachable} segment in  is 
a reachable segment  with the maximum index . 
In Figure~\ref{fig:shooting}, for example, 
the topmost reachable segments for  and 
are  and , respectively.

\begin{lemma} \label{lemma:top-segment}
	Let  and  be the two sets of segments  defined in Lemma~\ref{lemma:shooting}.
	Then, for each segment , , 
	the topmost reachable segment in 
	can be computed in  total time.
\end{lemma}


\begin{algorithm} [h]
\caption {\sc Topmost-Reachable-Segments} \label{alg:top-segment}
\algsetup{indent=1.5em}
\begin{algorithmic}[1]
	\vspace{0.5em}
	\baselineskip=1\baselineskip
	\FOR { from  to } 
		\IF {}
			\STATE 
		\ELSIF {}
			\STATE 
		\ELSE
			\STATE 
		\ENDIF
	\ENDFOR 
\end{algorithmic}
\end{algorithm}

\begin{proof}
	Algorithm~\ref{alg:top-segment} scans all segments in  from top to bottom,
	and assigns to each segment  in 
	a \emph{top} pointer that points to the topmost segment in  reachable from .
	The algorithm works as follows.
	Suppose that the top pointers for all segments in  above  are computed.
	At -th iteration, if  is not covered by any other segment above it,
	(i.e.,  is ), then the topmost reachable segment of  is set to .
	If  is covered by a segment , 
	then the topmost reachable segment of  is .
	Otherwise, if  is covered by a segment ,
	then all segments in  above  that are reachable from  are also reachable from ,
	and hence, the topmost such segment can be obtained from  pointer,
	which is computed earlier.
	Therefore, computing all top pointers can be performed in  total time.
	\qed
\end{proof}

\noindent
Analogous to the previous lemma, 
a result can be stated for a horizontal slab.


\begin{figure}[t]
	\centering
	\includegraphics[height=0.18\columnwidth]{figs/horizontal-slab}
	\caption{A horizontal slab with vertical segments. 
	The rightmost segment reachable from  in this figure is .
	}
	\label{fig:horizontal}
\end{figure}

\begin{corollary} \label{cor:rightmost}
	Consider a horizontal slab . 
	Let  be a set of segments
	, and 
	 be a set of segments 
	with , for  (see Figure~\ref{fig:horizontal}).
	Then, for all segments , the rightmost segment in  reachable from 
	can be computed in  total time.
\end{corollary}




\REM{
It is easy to observe that . 
However, this is not the case that  (see Figure~\ref{fig:pointers}.b).
We define  to be the rightmost point  such that  is non-empty. 
Obviously, .
}

\REM{
\vspace{.5em}
\begin{obs} \label{obs:main}
	Let  be a feasible interval of , and  be an index . Then
	\addtolength\leftmargini{0.8em}
	\begin{enumerate}
		\item[\rm (i)] any point on  is reachable from ;
		\item[\rm (ii)] for any point  with non-empty , ;
		\item[\rm (iii)] for any two point  with , we have  and .
	\end{enumerate}		
\end{obs}

\begin{proof}
	(i) and (ii) follow from transitivity of reachability.
	(iii) follows from Lemma~\ref{lemma:cross}.
	\qed
\end{proof}
}

\REM{
\noindent
For , 
we define the \emph{reachable set}  recursively as follows: 
\begin{itemize}
	\item ,
	\item  for all .
\end{itemize}
}





\section{The Main Data Structure} 
\label{sec:main}

In this section, we describe our main data structure that yields improved algorithms for several variants of the \Frechet distance. 
For , 
we define the \emph{reachable set} 
to be the set of all points in  reachable from .  
We call each interval of ,
contained in a feasible interval of ,
a \emph{reachable interval}.
By our definition, .
The following observation is immediate by the transitivity of reachability.

\begin{obs} \label{obs:reachable}
	For , .
\end{obs}
An important property of the reachable sets is described in the following lemma.

\begin{lemma} \label{lemma:reach}
	For any two indices   and any point ,
	. 
\end{lemma}

\begin{proof}
	Let .
	By Observation~\ref{obs:reachable},
	.
	Thus, it is clear by the definition of pointers 
	that .
	Therefore, it remains to be shown that .
	Suppose, by way of contradiction, that there is a point 
	such that .
	Since , there exists some point  such that
	.
	If  is to the left (resp., to the right) of , then 
	the points , and  (resp., )
	satisfy the conditions of Lemma~\ref{lemma:cross}.
	Therefore, by Lemma~\ref{lemma:cross}, ,
	which implies that ; a contradiction.
	\qed
\end{proof}

Lemma~\ref{lemma:reach} provides an efficient method for storing the sets
, for all feasible intervals  on .
Namely, instead of storing each set  separately,
one set per feasible interval , 
which takes up to  space,
we only need to store a single set , 
along with the pointers  and ,
which takes only  space in total.
The set , for each interval  on ,
can be then obtained by .
For each interval  on ,
we call the set 
a \emph{compact representation} of .
The following lemma is a main ingredient of our fast computation of reachable sets.

\begin{lemma} \label{lemma:propagate}
	For , if  is given,
	then  can be computed in  time. 
\end{lemma}

	\begin{figure}[t]
		\centering
		\includegraphics[width=0.8\columnwidth]{figs/propagate}
		\caption{Computing  from .}
		\label{fig:propagate}
	\end{figure}
	
\begin{proof}
	Let  be the intersection of the \fs diagram
	with the rectangle .
	 is composed of  square cells, numbered from left to right by  to .
	For all reachable intervals  on , 
	we compute pointers  and 
	in  time as follows.
	For each cell  in , the intersection of 
	the right boundary of  with the infeasible part of the \fs diagram
	forms two (possibly empty) vertical segments, denoted by
	 and , respectively, as in Figure~\ref{fig:propagate}. 
	For each cell , 
	we denote the top-right corner of  by .
	We pre-compute for each point , ,
	a pointer  (resp., ) 
	that points to the first feasible point on or immediately
	after (resp., before)  in .
	Let  be the set of all left and right endpoints of feasible intervals on .
	Since for each point ,  and , if not , are
	included in , we can compute all next/prev pointers using two linear scans
	in  time by Lemma~\ref{lemma:scan}.
	After computing  pointers,
	we can compute  for any point  in constant time.
	
	Now, fix an interval  on .
	We compute  and  as follows.
	Let  be the cell containing ,
	let  be the vertical projection of  onto ,
	and let  be the rightmost segment reachable from ,
	computed by Corollary~\ref{cor:rightmost}
	(see Figure~\ref{fig:propagate}).
	We set  and .
	(If , we set .)
	It is easy to verify that no point before  and no point after  on 
	can be reachable from , and that, every feasible point on  between 
	 and  is reachable from . 
	Therefore,  and .
	As a result, computing  and  
	for each reachable interval  on 
	takes  time,
	after  preprocessing time for computing the next/prev pointers.
	Thus, we can compute  and  for all reachable intervals  on 
	in  total time.

	After computing the left and right pointers, 
	we can produce 
	by identifying those (portions of) intervals on 
	that lie in at least one interval .
	Since for all intervals  on  sorted from left to right, 
	's and 's are in sorted order 
	by Observation~\ref{obs:sorted},
	we can accomplish this step by a linear scan over the 
	left and right pointers in  time.
	\qed
\end{proof}


\REM{
\begin{algorithm} [h]
\caption {\sc Compute-Pointers} 
\label{alg:pointers}
\algsetup{indent=1.5em}
\begin{algorithmic}[1]
	\vspace{0.5em}
	\STATE let  orthogonal projection of  onto  
	\STATE 
	\STATE 
	\IF {}
		\STATE  
	\ENDIF
	\STATE set  
\end{algorithmic}
\end{algorithm}
}
\newpage
\subsection{Data Structure}

We now describe our main data structure, 
which we call \fs map.
The data structure maintains reachability information 
on each row of the \fs diagram, using some additional
pointers that help answering reachability queries efficiently. 
The \emph{\fs map} of two curves  and 
consists of the following:
\begin{itemize}
\item[(i)] the reachable sets , for ,
	\item[(ii)] the right pointer  for each reachable interval  on , ,
	\item[(iii)] the leftmost reachable point after each cell in , for , and
	\item[(iv)] the rightmost take-off point before each cell in , for ,
\end{itemize}
where a \emph{take-off} point on  is a reachable point in 
from which a point on  is reachable.
For example, in Figure~\ref{fig:query},  is the leftmost reachable point after ,
and  is the rightmost take-off point before .
For a cell  in , by \emph{after}  we mean after ,
and by \emph{before}  we mean before .

\begin{lemma} \label{lemma:map}
	Given two polygonal curves  and  of size  and , respectively,
	we can build the \fs map of  and  in  time.
\end{lemma}

\begin{proof}
	We start from , 
	and construct each  iteratively from , for  from 1 to ,
	using Lemma~\ref{lemma:propagate}.
	The total time needed for this step is .
	The construction of ,
	as seen in the proof of Lemma~\ref{lemma:propagate}, 
	involves computing all right (and left) pointers,
	for all reachable intervals on . 
	Therefore, item~(ii) of the data structure can be obtained at no additional cost.
	Item~(iii) is computed as follows.
	Let  be the set of all left pointers obtained upon constructing .
	For each cell  in , the leftmost reachable point after , if any, 
	is a member of . 
	We can therefore compute item~(iii) for each row 
	by a linear scan over the cells and the set  
	using Lemma~\ref{lemma:scan} in  time.
	For each row, item~(iv) can be computed analogous to item~(iii), but in a reverse order.
	Namely, given the set , we compute the set of points on 
	reachable from  in the \fs diagram rotated by 180 degrees.
	Let  be the set of all left pointers obtained in this reverse computation.
	For each cell  in , the rightmost take-off point before , if there is any, 
	is a member of . 
	We can therefore compute item~(iv) for each row 
	by a linear scan over the cells and the set  
	using Lemma~\ref{lemma:scan} in  time.
	The total time for constructing the \fs map is therefore .
	\qed
\end{proof}


In the following, we show how the reachability queries can be 
efficiently answered, using the \fs map.
For the sake of describing the query algorithm, 
we introduce two functions as follows.
Given a point ,
we denote by  the leftmost reachable point on or after  on .
Analogously, we denote by  the rightmost take-off point on or before  on .
Note that both these functions can be computed in 
time using the pointers stored in the \fs map.



\begin{algorithm} [t]
\caption {{\sc Query()}, where } 
\label{alg:query}
\algsetup{indent=1.5em}
\begin{algorithmic}[1]
	\vspace{0.5em}
	\baselineskip=1\baselineskip
	\STATE let  \label{l:init}
	\FOR { to } 
		\STATE let  be the orthogonal projection of  onto   \label{l:l1}
		\STATE    \label{l:l2}
		\STATE let 
		\IF { or } \label{l:c1}
			\STATE  \label{l:c2}
		\ELSE
			\STATE , for  being the reachable interval containing 
		\ENDIF 	
		\IF { or  is } 
			\STATE return 
		\ENDIF 
	\ENDFOR 
	\STATE return 

\end{algorithmic}
\end{algorithm}

\begin{lemma} \label{lemma:query}
	Let the \fs map of  and  be given.
	Then, for any query point ,  and 
	can be computed in  time.
\end{lemma}

\begin{proof}
	The procedure for computing  and 
	for a query point  is described in Algorithm~\ref{alg:query}.
	The following invariant holds during the execution of the algorithm:
	After the -th iteration,  and .
	We prove this by induction on .
	The base case, , trivially holds. Now, suppose inductively that  and .
	We show that after the -th iteration, the invariant holds for .
	We assume, w.l.o.g., that  is non-empty, i.e., .
	Otherwise, the last take-off point from  will be either , or 
	smaller than , which is then detected and handled 
	by Lines~\ref{l:c1}--\ref{l:c2}.
	
	\begin{figure}[b]
		\centering
		\includegraphics[width=0.7\columnwidth]{figs/query}
		\caption{Proof of Lemma~\ref{lemma:query}.}
		\label{fig:query}
	\end{figure}

	We first show that .
	Suppose by contradiction that .
	If , then we draw a vertical line
	from  to  (see Figure~\ref{fig:query}).
	This line crosses any monotone path from
	 to  at a point .
	The line segment  is completely in the free space,
	because otherwise, it must be cut by an obstacle, which 
	contradicts the fact that the free space inside a cell is convex~\cite{AltG95}.
	But then,  becomes reachable from  through ,
	contradicting the fact that  is the leftmost reachable point in .
	The case, , cannot arise, 
	because then,  is a reachable point after  and
	before , which contradicts
	our selection of  as the leftmost reachable point of  in line~\ref{l:l2}.

	We can similarly show that .
	Suppose by contradiction that .
	The case  is impossible,
	because otherwise,  is a point on 
	reachable from  which appears after .
	This contradicts the fact that  is the rightmost point on .
	If  (see Figure~\ref{fig:query}),
	then  is reachable from a point  with , 
	because  is the rightmost take-off point on or before .
	But then, by Lemma~\ref{lemma:cross},  is reachable from ,
	which contradicts the fact that  is the left pointer of the reachable interval 
	containing .
	\qed
\end{proof}

\REM{
The result of this section is summarized below.

\begin{theorem} \label{thm:mainFreeSpaceMap}
	Given two polygonal curves  and  of size  and , respectively,
	we can build in  time a data structure of size , such that
	for any query point , a compact representation of 
	can be reported in  time. \end{theorem}
}





\subsection{Improved Query Time} \label{sec:improved}

In this section, we show how the query time
in the \fs map can be improved
by keeping some additional information in our data structure,
without increasing either the preprocessing time or space complexity.
This improved query time is crucial for 
applications such as the minimum walk problem.

We use our vertical ray shooting data structure from Section~\ref{sec:shooting}.
For each feasible interval  on , 
we partition  into  subintervals, such that
for all points  in a subinterval, 
the first segment directly above  in the ray shooting data structure is the same.
Such a partitioning can be obtained by a simple scan on each column of
the \fs map from bottom to the top.
The total number of subintervals obtained this way is .
	
\begin{theorem} \label{thm:mainFreeSpaceMap}
	Given two polygonal curves  and  of size  and , respectively,
	we can build in  time a data structure of size , such that
	for any query point , 
	a compact representation of 
	can be reported in  time.
	Furthermore, if the subinterval containing  is given as part of the query,
	then a compact representation of  can be reported in  time.
\end{theorem}


\begin{proof}
	We first build the \fs map in  time as per Lemma~\ref{lemma:map}.
	Let  be a feasible interval on .
	For each , we have .
	Therefore, by storing  for all feasible intervals  on ,
	we can report  for each query point  in  time.
	Since there are  feasible intervals on ,
	and computing each right pointer takes  time by Lemma~\ref{lemma:query},
	this step takes  time in total.
	To report  quickly, we store for each reachable interval ,
	, the pointer  in the data structure.
	We can compute all these left pointers in  time as follows.
	We first preprocess each column of the \fs map
	for vertical ray shooting as in Lemma~\ref{lemma:shooting},
	by assuming horizontal segments 
	to be non-reachable intervals on each row . 
	To compute left pointers, we inductively process 
	the \fs map from top to bottom.
	Suppose that the left pointers are computed and stored for 
	all reachable intervals above ,
	and let  be a reachable interval on ,
	with .
	We can find the first non-reachable segment 
	above  using our ray shooting data structure in  time.
	If no such  exists,  is directly above  on .
	Otherwise, as in Algorithm~\ref{alg:query},
	we project  directly to a point , 
	and then, find the first reachable point  after .
	If such a point  exists, it should be the left endpoint of a reachable interval ,
	for which we have already stored the pointer .
	Therefore,  can be computed 
	in  time. As a result, finding all left pointers takes  time for each ,
	and  time for the whole \fs map.
	

	Now, for each subinterval  on ,
	we compute  in the same way described above 
	in  time. Namely, we find the unique segment  above ,
	find the first reachable point  after , 
	and take the pointer , which is stored in the data structure.
	The total time and space needed for this step is therefore .
	For any query point ,
	we first locate the subinterval  containing  in  time.
	Now,  and
	 for the feasible interval  containing subinterval ,
	both accessible in  time.
	Note that the only expensive operation in our query algorithm is
	to locate the subinterval containing the query point.
	If the subinterval is given, 
	then the query can be answered in  time.
	\qed
\end{proof}





\section{Applications} \label{sec:appl}

In this section, we provide some of the applications of our \fs map data structure.

\subsection{Partial Curve Matching\ }
Given two polygonal curves  and , and an ,
the partial curve matching problem involves
deciding whether there exists a subcurve  such that .
As noted in~\cite{AltG95}, 
this is equivalent to deciding whether 
there exists a monotone path in the free space from  to . 
This decision problem can be efficiently solved using the \fs map.
For each feasible interval  on ,
we obtain a compact representation of  using 
Theorem~\ref{thm:mainFreeSpaceMap} in  time.
Observe that  if and only if 
.
Therefore, we can decide in  time 
whether there exists a point on  reachable from .
Furthermore, we can use parametric search as in~\cite{AltG95}
to find the smallest  for which the answer to the above decision problem is ``YES" in 
 time.
Therefore, we obtain:

\begin{theorem} \label{thm:partial}
	Given two polygonal curves  and  of size  and , respectively,
	we can decide in  time whether there exists a subcurve  
	such that , for a given .
	A subcurve  minimizing  can be computed in  time.
\end{theorem}


\subsection{Closed Curves}
Given two closed curves  and ,
define

to be the closed \Frechet metric
between  and . 


Consider a diagram  of size 
obtained from concatenating two copies of the standard \fs diagram of  and .
Alt and Godau showed that  if and only if
there exists a monotone feasible path in  from  to ,
for a value .
We show how such a value , if any exists,
can be found efficiently using a \fs map built on top of .

\begin{obs} \label{obs:t}
	Let  be a fixed integer ,
	 be the feasible interval on the -th cell of , and 
	 be the feasible interval on the -th cell of .
	Then there exists a value  with  if and only if 
	 and .
\end{obs}


We  iterate on  from 1 to ,
and check for each  if a desired value  exists using Observation~\ref{obs:t}. 
Each iteration involves examining  and ,
which are accessible in  time using Theorem~\ref{thm:mainFreeSpaceMap}.
The total time is therefore , required for building the \fs map.

\begin{theorem} \label{thm:closed}
	Given two closed polygonal curves  and  of size  and , respectively,
	we can decide in  time whether , for a given .
	Furthermore,  can be computed in  time.
\end{theorem}


\subsection{Maximum Walk}

Another variant of the \Frechet distance problem is 
the following:
Given two curves  and  and a fixed , 
find a maximum-length continuous subcurve of  whose 
\Frechet distance to  does not exceed .
In the dog-person illustration, this problem
corresponds to finding the best starting point on , 
such that when the person walks the whole curve ,
his or her dog can walk the maximum length on ,
without exceeding a leash of length . 
We show that this optimization problem,
which is a generalized version of the partial curve matching problem,
can be solved efficiently in  time
using the \fs map. 
The following observation is the main ingredient.

\begin{obs} \label{obs:max}
	Let  be a maximum-length subcurve of  such that .
	The starting point of  corresponds to the left endpoint of a feasible interval  on ,
	and its ending point corresponds to . 
\end{obs}

By Observation~\ref{obs:max}, we only need to test 
feasible intervals on , and their right pointer on 
to find the best subcurve . 
If we keep the length of  from its beginning to each of its  segments in a table,
we can compute the length of each subcurve  of  
in  time using two table lookups as 
it is explained in Chapter \ref{ch:speedFD}.
Computing the maximum-length subcurve  will
therefore take  time for computing the lengths, 
plus  time for constructing the \fs map.

\begin{theorem} \label{thm:max}
	Given two polygonal curves  and  of size  and , respectively,
	and a parameter ,
	we can find in  time a maximum-length subcurve  such that 
	.
\end{theorem}


\subsection{Minimum Walk}

Given two curves  and  and a fixed , 
the \emph{minimum walk} problem asks for the minimum-length continuous subcurve of
 that a person can walk while his/her dog walks the whole curve 
without exceeding a leash of length~. 
This optimization problem can be again solved efficiently 
using our \fs map. 

\begin{theorem} \label{thm:min}
	Given two polygonal curves  and  of size  and , respectively,
	and a parameter ,
	we can find in  time a minimum-length subcurve  such that 
	.
\end{theorem}

\begin{proof}
	Let  be a minimum-length subcurve of  such that .
	Observe that the starting point of  corresponds to 
	the right endpoint of a subinterval  on ,
	and its ending point corresponds to . 
	Therefore, to find the best subcurve , 
	we only need to check the right endpoints of 
	subintervals on  and their corresponding left pointers.
	By Theorem~\ref{thm:mainFreeSpaceMap}, this takes  time per subinterval.
	The total time needed is therefore .
	\qed
\end{proof}




\section{Matching a Curve in a DAG} \label{sec:graph}

Let  be a polygonal curve of size , 
and  be a connected geometric graph with  straight-line edges.
Alt \etal~\cite{AltERW03a} presented an -time algorithm 
to decide whether
there is a path  in  with \Frechet distance at most  to , 
for a given .
In this section, 
we improve this result for the particular case when  is a directed acyclic graph (DAG), 
by giving an algorithm that runs in only  time.
The idea is to use a sequential reachability propagation approach 
similar to the one used in Section~\ref{sec:main}.
Our approach is structurally different from
the one used by Alt \etal~\cite{AltERW03a}.


We first borrow some notation from~\cite{AltERW03a}.
Let  be a connected DAG with  edges,
such that 
corresponds to points , for .
We assume, w.l.o.g., that the elements of  are numbered
according to a topological ordering of the vertices of .
Such a topological ordering can be computed in  time.
We embed each edge  as
an oriented line segment  from  to . 
Each  is continuously parametrized 
by values in  according to its natural parametrization,
namely, .

For each vertex , let  
be the one-dimensional \fs diagram corresponding 
to the path  and the vertex .
We denote by  and  the left endpoint and the right endpoint
of , respectively.
Moreover, we denote by  the set of feasible points on .
For each , let 
be a two-dimensional \fs diagram, which consists
of a row of  cells.
We glue together the two-dimensional \fs diagrams
according to the adjacency information of ,
as shown in Figure~\ref{fig:graph}.
The resulting structure is called the \emph{\fs surface} of  and ,
denoted by .
We denote the set of feasible points in  by . 

\begin{figure}[t]
	\centering
	\includegraphics[width=0.5\columnwidth]{figs/graph}
	\caption{An example of a \fs surface.}
	\label{fig:graph}
\end{figure}

Given two points , 
we say that  is \emph{reachable} from~,
denoted by ,
if there is a monotone feasible curve from  to~ in ,
where monotonicity in each cell of the surface
is with respect to the orientation of the edges of  and 
defining that cell.
Given a set of points ,
we define

Let .
For each , 
we define the \emph{reachable set} .
Observe that there is a path  in  with 
if and only if there is a vertex  with .


\begin{algorithm} [h]
\caption {\sc DAG-Matching-Decision} \label{alg:graph}
\algsetup{indent=1.5em}
\begin{algorithmic}[1]
	\vspace{0.5em}
	\baselineskip=1\baselineskip
	\FORALL { in a topological order} 
		\STATE   \label{l:main}
	\ENDFOR 
	\STATE let 
	\STATE return {\sc true} if , otherwise return {\sc false}
\end{algorithmic}
\end{algorithm}

\begin{theorem} \label{thm:graph}
	Given a polygonal curve  of size  and a directed acyclic graph  of size , 
	we can decide in  time whether there is a path  in  
	with , for a given .
	A path  in  minimizing  can be computed in  time.
\end{theorem}


\begin{proof}
	Algorithm~\ref{alg:graph} computes, for each vertex ,
	the reachable set  in a topological order.
	It then returns true only if there is a vertex  such that  is reachable
	which indicates the existence of a path  in  with .
	To prove the correctness, we only need to show that 
	for every vertex , the algorithm computes  correctly.
	We prove this by induction on .
	Suppose by induction that the set 
	for all  is computed correctly.
	Now consider a point .
	If , then there exists a vertex  such that
	 is connected to  by a monotone feasible curve  in .
	If , then  because
	 is added to  in line~\ref{l:main}.
	If , then the curve  must pass through a vertex  with .
	Since the vertices of  are sorted in a topological order,
	we have , and hence,  is computed correctly by the induction hypothesis.
	Hence, letting , we have .
	Furthermore, we know that  is connected to  using the curve .
	Therefore, the point  is in ,
	and hence, is added to  in Line~\ref{l:main}.
	Similarly, we can show that if ,
	then  is not added to  by the algorithm.
	Suppose by contradiction that  is added to  in line~\ref{l:main}.
	Then either  or
	, for some .
	But by the definition of reachability, both cases imply that 
	 is reachable from a point in ,
	which is a contradiction.
	
	For the time complexity, 
	note that each  in Line~\ref{l:main} can be computed in 
	 time using Lemma~\ref{lemma:propagate}. 
	Moreover, , for each , can be computed
	by finding the largest feasible interval on  containing 
	in  time.
	Therefore, processing each edge  takes  time,
	and hence, the whole computation takes  time.
	Once the algorithm finds a reachable left endpoint ,
	we can construct a feasible monotone path connecting a right endpoint  to 
	by keeping, for each reachable interval  on , a back pointer to a reachable interval  on , ,
	from which  is reachable. 
	The path  can be constructed 
	by following the back pointers from  to , in  time.
	For the optimization problem, we use parametric search as in~\cite{AltERW03a,AltG95}
	to find the value of  by an extra -factor,
	namely, in  time.
	\qed
\end{proof}
Note that Algorithm~\ref{alg:graph} only works if the input graph is a DAG,
because it needs a topological ordering on the vertices in order to 
sequentially propagate reachability information.  
By the way, it is straight-forward 
to modify the algorithm to allow paths in 
to start and end anywhere inside edges of the graph, 
not necessarily at the vertices. 
This can be easily done by allowing 
the feasible path found by our algorithm
to start and end at any feasible point 
on the left and right boundary of ,
for each edge .





\section{Conclusions} \label{sec:concl}

In this chapter, we presented improved algorithms
for several variants of the \Frechet distance problem.
Our improved results are based on a new data structure, called \fs map,
that might be applicable to other problems involving the \Frechet metric.
It remains open whether the same improvements obtained here
can be achieved for matching curves inside general graphs (see the next section where for 
complete graphs, we present some 
improvement).  
Proving a lower bound better than  
is another major problem left open.


Preliminary results of this chapter 
are presented in the 
19th Annual European Symposium on Algorithms (ESA 2011)~\cite{oursESA2011}.
The full version of the paper is accepted 
for publication in Algorithmica~\cite{oursPartialAlgorithmica}.


\clearpage{}

\clearpage{}\newcommand{\re}{\ell}


\chapter{Curve-Pointset Matching Problem (CPM) }
\label{ch:StayClose}

	Given a point set  and a polygonal curve  in ,
	we study the problem of finding a polygonal curve  whose vertices are from 
	and has minimum \Frechet distance to . 
	Not all points in  are required to be on 
	. Furthermore, a point in  may be present multiple times on  . 
	We refer to this problem as  
	Curve-Pointset Matching (CPM) Problem.
	We present an efficient algorithm to solve the decision version 
	of this problem in  time,
	where  and  represent the sizes of  and , respectively.
	Furthermore, if the answer to the decision problem is affirmative, 
	our algorithm can compute the curve with minimum number of segments 
	in -~\Frechet distance to .	
	In addition, we show that a curve minimizing the \Frechet distance can be computed in 
	 time.
	As a by-product, we improve the map matching algorithm of Alt \etal\ 
	by an  factor for the case when the map is a complete graph.




\section{Introduction}

\REM{
Matching two geometric patterns is a fundamental problem in pattern recognition,
protein structure prediction, computer vision, geographic information systems, etc.
Usually these patterns consist of line segments and polygonal curves. 

One of the most popular ways to measure the similarity of two curves is
to use the \Frechet distance. 
An intuitive way to illustrate the \Frechet distance is as follows.
Imagine a person walking his/her dog, where the person and the dog, 
each travels a pre-specified curve, from beginning to the end, 
without ever letting go of the leash or backtracking.
The \Frechet distance between the two curves is the minimum length of a leash which is necessary.
The leash length determines how similar the two curves are to each other:
a short leash means the curves are similar,
and a long leash means that the curves are different from each other.

Two problem instances naturally arise:  decision and optimization.
In the {\em decision problem}, one wants to decide whether two polygonal curves   and 
are within~ \Frechet distance to each other. In the {\em optimization problem}, one wishes to determine the minimum such~.
Alt and Godau~\cite{AltG95} presented an -time algorithm for the decision problem,
where  denotes the total number of segments in the curves.
They also solved the corresponding optimization problem in  time.
}
In this chapter, we address the following variant of the \Frechet distance problem.
Given a point set  and a polygonal curve  in  (,
find a polygonal curve , with its vertices chosen from , 
such that the \Frechet distance between  and  is minimum.
Note that in our problem definition, 
not all points in  need to be chosen as well as 
a point in  can appear more than 
once as a vertex  in . 
In the decision version of the problem,
we want to decide if there is polygonal curve  through 
whose \Frechet distance to  is at most , for a given .
An instance of the decision problem is illustrated in Figure~\ref{fig:instance}.

One can use the map matching algorithm of Alt \etal~\cite{AltERW03a} (described in 
Section \ref{sec:RelatedMapMatching})
to solve the decision version of this problem 
by constructing a complete graph  on top of ,
and then running Alt \etal's algorithm on  and .
If  and  represent the sizes of  and , respectively,
this leads to a running time of  
for solving the decision problem.

In this chapter, we present a simple algorithm to solve the decision version 
of the above problem in  time.
This improves upon the algorithm of Alt \etal~\cite{AltERW03a}
by a  factor for the case when a curve is matched in a complete graph.
Our approach is different from and simpler
than the approach taken by Alt \etal\ which is a mixture of line sweep, dynamic
programming, and Dijkstra's algorithm.


\begin{figure}[t]
	\centering
	\includegraphics[height=0.5\columnwidth]{figs/definition}
	\caption{A problem instance. The dashed curve is in -\Frechet distance to the solid curve. Point  is used multiple times in the dashed curve.}
	\label{fig:instance}
\end{figure}




\section{Preliminaries}
\label{sec:preliminariesCPM}

Let  be a real number, and  be a fixed integer.
For any point ,
we define 
to be a \emph{ball} of radius  centered at ,
where  denotes the Euclidean distance.
Given a line segment ,
we define 
to be a \emph{cylinder} of radius~ around 
(see Figure~\ref{fig:cylinder}).


A curve  in  can be represented as  a continuous function 
.
Given two points ,  
we write , if  is located before  on .
The relation~ is defined analogously.
For a subcurve ,
we denote by  and 
the first and the last point of  along , respectively.


\begin{figure}[h]
	\centering
\includegraphics[width=0.6\columnwidth]{figs/cylinder}
	\caption{A cylinder of radius  around segment .}
	\label{fig:cylinder}
\end{figure}

Given two curves ,
the {\em \Frechet distance\/} between  and  is defined as

where  
range over all continuous non-decreasing surjective functions.
The following two observations are immediate.

\begin{obs}\label{obs:simple}
	Given four points , if
	 and , then
	. 
\end{obs}

\begin{obs}\label{obs:concat}
	Let , , , and  
	be four curves 
	such that  and
	. 
	If the ending point of  (resp., ), 
	is the same as 
	the starting point of   (resp., ),
	then ,
	where  denotes the concatenation of two curves.
\end{obs}




\section{The Decision Algorithm}

Let  be a polygonal curve composed of  line segments ,
and let  be a set of  points in .
In this section, we provide an algorithm to
decide whether there exists a polygonal curve  whose vertices are chosen from ,
such that ,
for a given . 

We denote by  and  the starting and the ending point of , respectively.
For each segment  of ,
we denote by  the cylinder ,
and by  the set .
Furthermore, for each point ,
we denote by  the line segment .

We call a polygonal curve  \emph{feasible} if 
all its vertices are from , and
 for a subcurve  starting at .
If  ends at a point  and  ends at a point , 
we call the pair  a \emph{feasible pair}.
A point  is called \emph{reachable} (at cylinder )
if there is a feasible curve ending at  in .

Consider a feasible curve  starting at a point  and
ending at a point .
Since no backtracking is allowed in the definition of \Frechet distance,
 traverses all cylinders  to  in order, until it reaches .
Moreover, by our definition of reachability, 
each vertex of  is reachable at some cylinder , .

Our approach for solving the decision problem is to process the cylinders
one by one from  to , and identify at each cylinder 
all points of  which are reachable at .
The decision problem will be then reduced (by Observation~\ref{obs:concat}) 
to checking whether there is a reachable point in the ball .

To propagate the reachability information through the cylinders, 
we need a primitive operation described below.
Let  be a point reachable at cylinder , 
and let  be a feasible curve ending at .
For each point , 
we denote by  the index of the furthest cylinder 
we can reach by the curve .
In other words,
 is the largest index  such that 
 is reachable via .
If  is not feasible, we set .
The following lemma is a direct corollary of a similar one proved in~\cite{AltERW03a}  (Lemma~3)
for computing the so-called right pointers.


\begin{lemma}[\cite{AltERW03a}] \label{lemma:linear}
	Given two points ,
	we can compute  for all  in  total time.
\end{lemma}

We use the following lemma for our algorithm.

\begin{lemma} \label{lemma:cross}
	Let .
	For all ,  if , then  is reachable at .
\end{lemma}

\begin{proof}
	Let  be a feasible curve starting at a point  and ending at ,
	and let .
	Since  is reachable at  via ,
	there is a subcurve  of  starting at  and ending at a point 
	(see Figure~\ref{fig:cross}).
	Consider two point objects  and  
	traversing  and , respectively, from beginning to end,
	while keeping  distance to each other.
	Since  is reachable via ,
	 is at a point  when  is at .
	Fix a cylinder ,  , such that  .
	When  reaches the point , 
	 is at a point  such that .
	The subcurve of  from  to  has \Frechet distance at most 
	to the subcurve of  from  to ,
	and the segment  has \Frechet distance at most  to the point 
	by Observation~\ref{obs:simple}.
	Therefore, by Observation~\ref{obs:concat}, 
	the whole curve  has \Frechet distance at most 
	to the subcurve  from  to ,
	meaning that  is reachable at .
\end{proof}


\begin{figure}[t]
	\centering
	\includegraphics[width=0.6\columnwidth]{figs/cross}
	\vspace{0.5em}
	\caption{Proof of Lemma~\ref{lemma:cross}}
	\label{fig:cross}
\end{figure}

The above proof, not only shows that 
 is reachable at , 
but also that 
the pair  is feasible.
The following lemma is therefore immediate.

\begin{lemma} \label{lemma:left-point}
	If  and , ,
	then  is a feasible pair.
\end{lemma}





\begin{algorithm} [h]
\caption {{\sc Decision}} 
\label{alg:decCCCG11}
\algsetup{indent=1.5em}
\begin{algorithmic}[1]
	\vspace{0.5em}
	\baselineskip=1\baselineskip
\STATE {\bf Initialize:}  \label{l:init}
		\STATE \hspace{1.5em}compute  for all  and  \label{l:init-1} 
		\STATE \hspace{1.5em}set  for all  \label{l:init-2} 
		\STATE \hspace{1.5em}let  \label{l:R0} \label{l:init-3} 
		\STATE \hspace{1.5em}set  for all   \label{l:init-4} 
	\FOR { to }   \label{l:mainstart}
		\STATE let   \label{l:direct}
		\STATE let   \label{l:min}
		\FORALL {} \label{l:loop1start}
			\IF {} \label{l:cond}
				\STATE add  to  \label{l:reach}
			\ENDIF
		\ENDFOR \label{l:loop1end}
		\FORALL {}  \label{l:rel-1}
				\STATE   \label{l:rel-2}
		\ENDFOR
	\ENDFOR 
	\STATE {\bf return} {\sc yes} if  \label{l:final}

\end{algorithmic}
\end{algorithm}

\paragraph{The Algorithm}
Our algorithm for solving the decision problem is provided in Algorithm~\ref{alg:decCCCG11}.
It maintains,
for each cylinder , a set  of all points in  which are reachable at .
To handle the base case more easily,
we assume, w.l.o.g., that the curve  starts with a segment   
consisting of a single point .
Every point of  inside the cylinder  is reachable by definition.
Therefore, we initially set  (in line~\ref{l:R0}).

For each point , the algorithm maintains an index , 
whose value at the beginning of each iteration  is the following:
.
In other words,  points to the largest index  for which  is reachable at 
via a reachable point  in some earlier cylinder , .
Initially, we set  for all points in ,
because all points in  are also reachable in , as .
For all other points,  is set to 0 in the initialization step.
The following invariant holds during the execution of the algorithm.

\begin{lemma}\label{lemma:main}
	After the -th iteration of Algorithm~\ref{alg:decCCCG11}, 
	the set  consists of all points in  which are reachable at cylinder .
\end{lemma}


\begin{proof}
	We prove the lemma by induction on .
	The base case  trivially holds.
	Suppose by induction that, for each ,
	the set  is computed correctly.
	In the -th iteration,
	we first add to  (in Line~\ref{l:direct}) all points in 
	which are reachable through a point in a set , for .
	We call these points \emph{entry points} of cylinder .
	We then add to  in lines~\ref{l:min}--\ref{l:loop1end} all points in 
	which are reachable through the entry points of 
	(see Figure~\ref{fig:reach} for an example).

	We first show that all points added to  are reachable at .
	For each point  added to  in Line~\ref{l:direct},
	we have . 
	It means that there is a point , for some , such that . 
	Therefore, Lemma~\ref{lemma:cross} implies that  is reachable at .
	Now, consider a point  added to  in line~\ref{l:reach}.
	According to the condition in line~\ref{l:cond}, 
	there is an entry point  in  such that
	.
	By Observation~\ref{obs:simple}, the segment  is 
	within  \Frechet distance to the line segment
	from  to . 
	Moreover, by Lemma~\ref{lemma:left-point},  is a feasible pair.
	Therefore, by Observation~\ref{obs:concat},
	 is reachable.
	
	Next, we show that
	any reachable point at  is added to  by the algorithm.
	Suppose that there is 
	a point  which is reachable at ,
	but is not added to .
	Let  be a feasible curve ending at ,
	and  be the first point on  which is reachable at .
	By our definition,  is an entry point of .
	If , then  must be added to  in Line~\ref{l:direct},
	which is a contradiction.
	If  is before  on ,
	then we have .
	Now, by our selection of  in Line~\ref{l:min},
	we have ,
	and hence,  is added to  in line~\ref{l:reach},
	which is again a contradiction.
\end{proof}


\begin{figure}[t]
	\centering
	\includegraphics[width=0.9\columnwidth]{figs/reach}
	\caption{Point  is an entry point of .}
	\label{fig:reach}
\end{figure}


\begin{theorem} \label{thm:main}
	Given a polygonal curve  of  segments and a set  of  points in , 
	we can decide in  time whether there is a polygonal curve  through  
	such that , for a given .
	A polygonal curve  through  of size  minimizing  
	can be computed in  time.
\end{theorem}

\begin{proof}
	The correctness of the decision algorithm (Algorithm~\ref{alg:decCCCG11})
	directly follows from Lemma~\ref{lemma:main}.
	Line~\ref{l:init-1} of the algorithm takes  time by Lemma~\ref{lemma:linear}.
	The other three lines in the initialization step (lines~\ref{l:init-2}--\ref{l:init-4}) take only  time.
	In the main loop, lines~\ref{l:direct}--\ref{l:reach} take  time, and
	lines~\ref{l:rel-1}--\ref{l:rel-2} require  time.
	Therefore, the whole loop takes  time in total.

	Once the algorithm finds a reachable point ,
	we can construct a feasible curve  ending at  by keeping, 
	for each reachable point  at a cylinder , 
	a back-pointer to a reachable point  at , , 
	from which  is reachable. 
	The feasible curve  can be then constructed 
	by following the back pointers from  to a point in . Since at most two points from each cylinder are selected in this process,
	the curve  has  segments.
	For the optimization problem, we use parametric search as in~\cite{AltERW03a,AltG95}, 
	to find a curve minimizing  by an extra -factor
	in  time.
\end{proof}




\section{Conclusions}

In this chapter, we presented a simple efficient algorithm 
for finding a polygonal curve through a given point set  in 
such that its \Frechet distance to a given polygonal curve  is minimized.
Several interesting problems remain open.
For a fixed , one can easily modify the algorithm provided
here to find a curve with a minimum number of segments, 
having \Frechet distance at most  to .
It can be done by keeping reachable points in a priority queue,
and propagating the reachability information in a Dijkstra-like manner.
However, we cannot see any easy adaptation of our algorithm to 
find a curve passing through a maximum number of points for a fixed .


The algorithm presented in this chapter improves
the map matching algorithm of Alt \etal~\cite{AltERW03a} 
for the case of matching a curve in a complete graph.
The current lower bound available for the problem is 
due to Buchin \etal~\cite{LowerBound-FD}.
It is therefore open whether a better algorithm is available,
or whether the algorithm obtained in this chapter is optimal.



Results of this chapter 
are presented in 23rd Canadian Conference on 
Computational Geometry~\cite{oursCCCG2011}.

































\chapter{All-Points CPM Problem is NP-complete}
\label{ch:NP-Complete}

\section{Introduction}
In this chapter, we study 
a variant of the problem discussed in the previous chapter. 
We refer to this variant as the All-Points CPM problem. We address the following:
Consider a pointset  and a polygonal curve  in , 
for  being a fixed dimension.
The objective is to decide whether there exists a polygonal curve  in  -\Frechet
distance to  such that the vertices of  are all chosen from the 
pointset . Moreover, curve  has to visit every point of 
and it can visit a point multiple times. 
We  prove  that  this problem  is  NP-complete  by  reducing from 3CNF-SAT problem.
In an independent work~\cite{NPComplete-Pointset} (which is done after   
our NP-completeness result), the authors have shown that
the version of this problem where points in  has to 
be visited only once, is NP-complete too. 
Their proof is obtained via reduction
from a restricted version of the 3SAT problem, 
called (3,B2)-SAT problem,
where the input to formulas is restricted
in which each literal occurs exactly twice.
In \cite{DiscretelyFollowing},  
Wylie and Zhu studied 
All-points CPM problem from the 
perspective of discrete \Frechet distance
and they showed that it is solvable in 
 time ( is the size of curve  and  is the size of  pointset ). 
Furthermore, they showed that the version of the problem in which 
each point of  can only used once in  is  NP-complete.



\section{General Case is NP-complete}
\label{sec:NPComp}

\subsection{Preliminaries}
\noindent{\bf Notation.}
We denote by , a polygonal curve 
with vertices  in order 
and by  and , we denote 
the starting and ending point of , respectively.
For a curve  and a point , by , 
we mean connecting  to point .
We use the same notation  
to show the concatenation of 
two curves  and  (which means connecting  to ).
Let  denote the  midpoint of line segment . 
For a point  in the plane, let  and 
denote the  and  coordinate of , respectively.


For two intersecting line segments  and , let  denote the intersection point of them.
Let  denote the line as a result of 
extending line segment .
For a point  and a line segment ,
let  denote the point on
line ,
located on the perpendicular from  to .


\begin{definition} \label{def:curves}
Given a pointset  in the plane, let 
be a set of polygonal curves  where: 

\end{definition}

\begin{definition} \label{def:feasibleNPC}
Given a pointset , a polygonal curve  and a distance , 
a polygonal curve  is called {\em feasible} if: 
 and .
\end{definition}

We show that the problem of deciding whether a 
feasible curve exists or not  is NP-complete.
It is easy to see that this problem is in NP, since 
one can polynomially check whether 
and also , using the algorithm in \cite{AltG95} 
(explained in Section \ref{sec:classicalFD}).





\subsection{Reduction Algorithm}

We reduce in Algorithm~\ref{alg:reduction},
an instance of 3CNF-SAT formula  
to an instance of our problem.
The input is a boolean formula 
 with  clauses  and  variables  
and the output is a pointset ,
a polygonal curve  in the plane and 
a distance .


We construct the pointset  as follows.
For each clause , , in the formula , 
we place three points  in the plane, which are computed
in the -th iteration of Algorithm \ref{alg:reduction} (from Line \ref{l:makeSLoop} to Line \ref{l:EndLoopPointSet}).
We define  to be .
By , , we denote
a square in the plane, centered at , 
with diagonal . 
We refer to , , as
{\em c-squares}. 
For an example of a pointset  corresponding to a formula, 
see Figure \ref{fig:pathAExample}a.


Our reduction algorithm constructs the polygonal curve  
through  iterations. In  the -th iteration, ,
it builds a subcurve  corresponding to  a variable 
 in the formula  and appends that curve to .
In addition to those  subcurves, two curves 
 and  are appended to . 
We will later discus the reason we add those 
two curves. Every subcurve   of  starts at point  
and ends at point .
Furthermore, each   goes through
 to  in order, enters each c-square  from
the side   and exists that square from 
the side   (for an illustration, see Figure \ref{fig:pathAExample}a). 
Curve  itself is built incrementally  
through iterations of the loop at line \ref{l:looptoMakeL} 
of Algorithm \ref{alg:reduction}. 
In the -th iteration, when  goes through ,
three points, which are within  , are added to  
(these three points are computed through Lines 
\ref{l:makeclausestart} to \ref{l:makeclauseend}).
Next, before  reaches  ,
two points,  denoted by  and , are added to that curve 
(these two points are computed in Lines \ref{l:alpha} 
and \ref{l:beta}).


Each  corresponds to variable  in our approach.
We simulate  or  values of 
as follows.
Consider a point object  
traversing , from starting point  to ending point . 
Consider 
another point object  which wants to 
walk from  to 
on a path whose vertices are from points in  and it wants to stay in distance one 
to . We will show that 
by our construction, object  has two options, either taking 
the path  or the path  
(See Figure \ref{fig:pathAExample}a and \ref{fig:pathAExample}b for an illustration). 
Choosing path  by  means  and choosing path  means .
We first prove in Lemma \ref{lemma:PathA} that  and 
in Lemma  \ref{lemma:PathB} that .
Furthermore, in
Lemma \ref{lemma:NoSwitchFromAtoB}, we prove that as soon as  chooses 
path  at point  to walk towards , 
it can not switch to any vertex on path .
Analogously, we show that as soon as  chooses path  at point  to walk towards , 
it can not switch to any vertex on path .
In addition, in Lemmas \ref{lemma:ABCanSeeC} and \ref{lemma:NOTABCanSeeC}, we prove that 
if  appears in clause ,
 could visit point  via the path  and not . In contrast, 
when  appears in the clause ,
 could visit point  via the path  and not .
However, when none of   or  appear 
in ,  can take neither  nor  to visit .
Thus,  can be visited, 
if and only if there is 
an  such that 
either  or 
 are in clause .









\begin{algorithm} 
\caption {{\sc Reduction Algorithm}} 
\label{alg:reduction}
\algsetup{indent=1.5em}
\begin{algorithmic}[1]
	\baselineskip=0.5\baselineskip
	\REQUIRE  3SAT formula  with  clauses  and  variables 
	

	\vspace{0.1in}
		
	\hspace{-0.2in} {\bf Construct pointset :}  

	\STATE  \label{l:init}
	



 
	\STATE  \label{l:makeSStart}

	\FOR { to }   \label{l:makeSLoop}

	\STATE 
		 \STATE 
	

		\IF {( is odd)	}
	   
  
	\STATE , 

	\STATE       		\label{l:ComputeNextEven}
    
		\ELSE
	\STATE ,  
    
	\STATE       		\label{l:ComputeNextOdd}

  





	

	


	\ENDIF
	

  



\STATE 

    \STATE    \label{l:EndLoopPointSet}

	\ENDFOR






	\IF {( is odd)}  \label{l:ComputeV}
	  \STATE   
      \STATE   
		\ELSE
	   \STATE   
      \STATE   
	\ENDIF

	\STATE 

	\STATE 

    \STATE  \label{l:makeSEnd}



 	

\vspace{0.15in}

	\hspace{-0.25in} {\bf Construct polygonal curve :}  

	
	\STATE  \label{l:makeP}

		

	\STATE   


	\FOR {  to   }   \label{l:mainstart}

		\STATE   \label{l:startofL}

		\STATE   \STATE   \label{l:Adduh1toell}
		\FOR { to } \label{l:looptoMakeL}	

	

			\IF { ( and  is odd ) or ( and  is even ) } \label{l:makeclausestart}	
\STATE 
			\ELSIF {{ ( and  is odd ) or ( and  is even ) }}
\STATE 
			\ELSE		
			\STATE 
			\ENDIF \label{l:makeclauseend}


			\IF {}

			\STATE  \label{l:alpha}

			\STATE  \label{l:beta}
			
			\STATE 


			\ENDIF

		
		\ENDFOR
	
		\STATE  \label{l:subcurve}


		\STATE   
		\STATE  
		   
		
		

	\ENDFOR


	\vspace{0.05in}
\RETURN  pointset , polygonal curve  and distance 
	

\end{algorithmic}
\end{algorithm}






































\begin{table}[h]
\centering
\begin{tabular}{ r | l | l  }
if    & location of  & location of   
 \\
\hline
    
&   &   \\
&  				  s.t.   & \\

&   & 	      \\

\hline
if  
&   &   \\
&  				  s.t.   & \\

&  &  \\

\hline
if  &  &   \\
&  				  s.t.   & \\
&  &  \\

\end{tabular}
\vspace{0.2 in}
\caption{Proof of Lemma \ref{lemma:PathA}, the base case of induction}
\label{tab:BaseCasePathA}
\end{table}





\begin{lemma}\label{lemma:PathA}
Consider any subcurve , ,  
which is built through Lines \ref{l:mainstart} to \ref{l:subcurve} 
of Algorithm \ref{alg:reduction}. Let  be the polygonal curve  . 
Then, .
\end{lemma}


\begin{proof}

We prove the lemma by induction on the number of segments along . 
Consider two point objects  and  
traversing  and , respectively (Figure \ref{fig:pathAExample}a depicts an instance of  and ).
We show that  and  can walk
their respective curve, from the beginning to
 end, while keeping distance  to each other. 

The base case of induction trivially holds as follows 
(see Figure \ref{fig:PathAClause1} for an illustration).
Table \ref{tab:BaseCasePathA} lists  pairwise locations of 
 and , where the distance of each pair is at most .
Hence,  can walk from  to  on the 
first segment of  (segment ), 
while keeping distance  to .


Assume inductively that  and  have feasibly walked along 
their respective curves, until  reached .
Then, as the induction step, 
we 
show that
 can walk to  and then to , while keeping distance  to .
Table \ref{tab:PathA} lists pairwise locations
of  and  such that  could reach  .
One can easily check that the distance between the pair of points 
in that table is at most one.
 (For an illustration, see Figure \ref{fig:PathA}). 


\begin{table}[t]
\centering
\begin{tabular}{ r | l | l  }
  & location of  & location of   
 \\
\hline
   if   &  & \\
	&  & \\ 
	&  & \\ 

	&  &  \\





   if   &  &  \\
	&  &\\
	&  &\\
	& &\\
	&  &\\




   if   &  & \\
	&  & \\
	&  & \\

	& &\\
	& &\\
&  &  \\

\hline
	&   s.t.   & \\
	&  	 s.t.   & \\





\hline
if  &      & \\
&  & \\
&  & \\
&  &  \\
&   & \\




if  &  			  & \\
 &  &  \\
 &  &  \\
 &   &  \\






if  &  	  & \\
&  & \\
 & &  \\
 & &  \\
&   &  \\





\hline

	&   s.t.   & \\
	&  	 s.t.   & \\
\hline









 if   &  &  \\
   if   &  & \\
   if   &  & \\

\end{tabular}
\caption{Distance between pair of points is less or equal to one}
\label{tab:PathA}
\end{table}





Finally, if  is an odd number, then  
 is the last segment along , otherwise, 
 is the last one. In 
either case, 
that edge crosses  the circle , where  is the last vertex of 
 before  (point  is computed in line \ref{l:ComputeV} of 
Algorithm \ref{alg:reduction}). Therefore, 
  can walk to , while keeping distance  to . 


\qed
\end{proof}




\begin{figure}[t]
	\centering
	\includegraphics[width=1\columnwidth]{figs/samplePathAB}
	\caption{
Blue curve is an example of curve  which corresponds to variable  in  formula . The formula has four clauses  and ,	 where the occurrence of variable   in those clauses is:
, ,  and .  
For each clause , the reduction algorithm places three point  and  in the plane. (a) Red curve is curve . 
 (b) Red curve is curve .  }
	\label{fig:pathAExample}
\end{figure}









\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\columnwidth]{figs/PathAC1}
	\caption{Base case of induction in the proof of Lemma \ref{lemma:PathA}}
	\label{fig:PathAClause1}
\end{figure}






\begin{figure}
	\centering
	\includegraphics[width=0.9\columnwidth]{figs/parallelogramForPathA}
	\caption{Proof of Lemma \ref{lemma:PathA}}
	\label{fig:PathA}
\end{figure}
	



\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\columnwidth]{figs/PathBC1}
	\caption{Base case of induction in the proof of Lemma \ref{lemma:PathB} }
	\label{fig:PathBBaseCase}
\end{figure}



\begin{figure}[h]

	\centering
	\includegraphics[width=0.9\columnwidth]{figs/parallelogramForPathB}
	\caption{Proof of Lemma \ref{lemma:PathB}}
	\label{fig:PathB}
\end{figure}


\begin{lemma}\label{lemma:PathB}
Consider any subcurve , ,  
constructed through Lines \ref{l:mainstart} to \ref{l:subcurve} 
of Algorithm \ref{alg:reduction}. Let  be the polygonal curve  . Then, .
\end{lemma}

\begin{proof}



Consider two point objects  and  
traversing  and , respectively (Figure \ref{fig:pathAExample}b depicts an instance of  and ).
To prove the lemma, we show that  and  can walk along
their respective curves, from beginning to
the end, while keeping distance  to each other. 

The base case of induction holds as follows 
(see Figure \ref{fig:PathBBaseCase} for an illustration).
Table \ref{tab:BaseCasePathB} lists  pairwise locations of 
 and , where the distance of each pair is less or equal to .
Therefore,  can walk from  to  while
keep distance one to .

\begin{table}[h]
\centering
\begin{tabular}{ r | l | l  }
if    & location of  & location of   
 \\
\hline
    
&   &   \\
&  				  s.t.   & \\

				&     &    \\
&  				 			       &   \\
&     &   \\
&  				 		      &     \\
&   & 	      \\

\hline
if  
&   &   \\
&  				  s.t.   & \\
&  &  \\
&  &  \\
&  &  \\
&  &  \\

\hline
if  &  &   \\
&  				  s.t.   & \\
&  &  \\
&  &  \\
&  &  \\
&  &  \\
&   & 	      \\

\end{tabular}
\vspace{0.2 in}
\caption{Pairwise location of  and , to prove the base case of induction in Lemma \ref{lemma:PathB} }
\label{tab:BaseCasePathB}
\end{table}





Assume inductively that  and  have feasibly walked along 
their respective curves, until  reached .
Then, as the induction step, 
we 
show that
 can walk to  and then to  
, while keeping distance  to .
This is shown in Table \ref{tab:PathB}
 (see Figure \ref{fig:PathB} for an illustration). 


\begin{table}[h]
\centering
\begin{tabular}{ r | l | l  }
  & location of  & location of   
 \\
\hline
   if   &  &  \\
   if   &  & \\
   if   &  & \\

\hline
	&   s.t.   & \\
	&  	 s.t.   & \\

\hline
if  &  				   & \\
&  & \\
&  & \\

&   &  \\
&  & 
 \\




if  &  				   & \\

 &  &  \\
 &  &  \\


 &   &  \\






if  &  				   & \\
&  & \\
 & &  \\
 & &  \\
&   &  \\


\hline

	&   s.t.   & \\
	&  	 s.t.   & \\
\hline




if  &  		 		   & \\

 &  &  \\
 &  &  \\


 &   &  \\






if  &  				 		   &      \\
 &  &  \\
 &  &  \\


 &    &  \\







if  &  				
 		   &     \\
&  & \\
 & &  \\
 & &  \\
&   &  \\


\end{tabular}
\caption{Distance between pair of points is less or equal to one}
\label{tab:PathB}
\end{table}



Finally, if  is an odd number, then  
 is the last segment along , otherwise, 
 is the last one. In any case, 
that edge crosses  circle , where  is the last vertex of 
 before  (point  is computed after the condition checking 
in line \ref{l:ComputeV} of 
Algorithm \ref{alg:reduction}). Therefore, 
  can walk to , while keeping distance  to . 


\qed





\end{proof}




\begin{figure}
	\centering
	\includegraphics[width=0.9\columnwidth]{figs/NoSwitch}
	\caption{Proof of Lemma \ref{lemma:NoSwitchFromAtoB}}
	\label{fig:noswitch}
\end{figure}

	



\begin{lemma}\label{lemma:NoSwitchFromAtoB}
Consider any curve , . Imagine that  
a point object  is walking from  to  on . Furthermore, imagine
two point objects  and  which are walking on curves  and  
(from Lemmas \ref{lemma:PathA} and \ref{lemma:PathB}), respectively,
while keeping distance  to . 
If  goes to any vertex of  or  goes to any vertex of , 
then they loose distance  to .

\end{lemma}

\begin{proof}
Let 
 refer to 
points .
Notice that we have placed the  points far enough from 
the  points so that 
no curve can go to 
and come back to  and stay 
in \Frechet distance 1 to .
Therefore, to prove the lemma, 
we only focus on two consecutive c-squares.
We show that no subcurve  exists such 
that (for an illustration, see Figure \ref{fig:noswitch}) :


\begin{itemize}

\item  because:



for all , , point  is always a vertex of . 
A point on  at distance 1 
to  lies before  
in direction , 
while a point on  at distance 1 
to point  lies after  in direction .
Since , 
no subcurve  exists such that 
.




\item  or , because:



For all , , 
is a vertex of . 
A point on  at distance 1 
to  lies before  
in direction , 
while a point on  at distance 1 
to point  lies after  in direction .
Since  and 
,
no subcurve  exists such that 
.
Similarly,  no subcurve  exists such that 
.



\item  or   because:



Vertex  of 
guarantees the first part as , 
and vertex  of 
guarantees the second part, 
as .



\item ,  because 



\item , because  



\item  , because  



\item  , because  



\item  , because  
\end{itemize}


\end{proof}







\noindent To establish the correctness of
our reduction algorithm, 
from now on, we define:
,  
 when  is an odd number, 
and
, 
when  is an even number, for .


\begin{lemma}\label{lemma:ABCanSeeC}
Consider the curve  from Lemma \ref{lemma:PathA}. Let 
 be a subcurve of  which starts at  and ends at , .
Furthermore, let  be a subcurve of  which starts at  and ends at .
For any curve  , ,
if , 
. 
Similarly, consider the curve  from Lemma \ref{lemma:PathB}. Let 
 be a subcurve of  which starts at  and ends at , .
Furthermore, let  be a subcurve of  which starts at  and ends at .
For any curve  , ,
if ,   
. 
\end{lemma}

\begin{proof}
When  appears in clause , point  is 
a vertex of . 
Since  and  is the  midpoint of 
 ,
 can wait at  while  visits .
Therefore, as the lemma states, 
we can cut curve  at vertex ,
add two edges 
and then  to ,
and continue with the same 
curve 
from  to 's endpoint. 
For the 
modified , still  holds. 

When  appears in clause , point  is 
a vertex of . 
Since  and  is the  midpoint of 
 ,
 can wait at  while  visits 
and comes back to .
Therefore, as the lemma says, 
we can cut curve  at vertex ,
add two edges 
and then  to ,
and continue with the same 
curve 
from  to 's endpoint. 
For the 
modified , still  holds. 


\end{proof}



\begin{lemma}\label{lemma:NOTABCanSeeC}
Consider curve  (respectively, ) from previous lemma.
For any curve , ,
when  and ,   
curve  (resp., ) can not be modified to visit .
\end{lemma}
\begin{proof}
This holds because 
and .

\end{proof}










\vspace{0.1 in}

\begin{theorem}
Given a formula  with  clauses  and  variables ,
as input, let curve  and pointset  be the output of Algorithm \ref{alg:reduction}. 
Then,  is satisfiable iff a 
curve  exists such that 
.
\end{theorem}

\begin{proof}



For : 
Assume that  formula  is satisfiable. 
In Algorithm \ref{alg:buildQ}, we show that 
knowing the truth value of the literals in , 
we can build a curve  which 
visits every point in  and .



\begin{algorithm} [h]
\caption {{\sc Build a feasible curve  }} 
\label{alg:buildQ}
\algsetup{indent=1.5em}
\begin{algorithmic}[1]	
		\baselineskip=0.9\baselineskip
	\REQUIRE  Truth table of variables  in 

	\STATE 
	\STATE  \label{l:startPoint}
	 
	\FOR { to }   
	\IF {}
	\STATE 
	\FORALL { clauses, if  }
	\STATE let  be  subcurve of  from 	 to 
	\STATE let  be  subcurve of  from 	 to 
	\STATE   \label{l:visitCone}
	\ENDFOR
	\STATE  \label{l:x1}
	\ELSE 	
	\STATE 
	\FORALL { clauses, if  }
	\STATE let  be  subcurve of  from 	 to 
	\STATE let  be  subcurve of  from 	 to 
	\STATE  \label{l:visitCzero}
	\ENDFOR
	\STATE  \label{l:x0}

	\ENDIF
	\STATE 
\ENDFOR
	\STATE \label{l:nplusone}
	\STATE 

	\STATE \label{l:nplustwo}
	\STATE   \label{l:endPoint}

	\STATE {\bf return} {\sc Q}  
\end{algorithmic}
\end{algorithm}







First, we show , where 
is the output curve of Algorithm \ref{alg:buildQ}.
Recall that by Algorithm \ref{alg:reduction}, 
curve  includes  subcurves  each corresponds 
to a variable . 
Both curves  and  start and end at a same point .
For each curve  which is appended to  
in the -th iteration of Algorithm \ref{alg:buildQ} 
(Line \ref{l:x1} or Line \ref{l:x0}), 
  by Lemma \ref{lemma:ABCanSeeC}. 
Notice that  also includes two additional subcurves  and  
whereas there is no variable  and  in formula . 
These two curves are to resolve two special cases: 
when all variables  are 1,  no  appears in ,
and when all variables  are 0,  
no  appears in .
Because of these two curves, 
we added two additional curves in line \ref{l:nplusone}
and \ref{l:nplustwo} to . Finally, by  Observation 
\ref{obs:concat}, .


Next, we show that curve  visits every point in . First of 
all, by the curves added to  
in Line \ref{l:nplusone} and \ref{l:nplustwo}, 
all  and , , in  will be visited. 
It is sufficient to show that  will visit all  points in   as well.
Since  formula  is satisfied, every clause  in  must be satisfied 
too. Fix clause . At least one of the literals in 
must have a truth value . If  and , 
then by line \ref{l:visitCone}, curve  visits .
On the other hand, if  and , 
by Line \ref{l:visitCzero}, curve  visits . We conclude that 
curve  is feasible.
 

Now  part:

Let  be a feasible curve with respect to  and pointset .
Notice that curve  consists of  subcurves , 
, where each corresponds to one variable . 
From the configuration of each  in c-squares, 
one can easily construct formula  with 
all of its clauses and literals. 



 
Imagine two point objects  
and  walk on  and , respectively. 
We find the truth value of variable  in the formula
by looking at the path that  takes to stay in \Frechet distance 1 to , 
when  walks on curve  corresponding to .
If  takes path  from Lemma \ref{lemma:PathA} 
while  is walking on  , then . But if  takes path  from Lemma \ref{lemma:PathB} 
while  is walking on  , then . 
Object  decides between path  or ,  when both  and  are at point . 
Lemma \ref{lemma:NoSwitchFromAtoB} ensures that  
once they start walking, 
 can not change its path from  to  
or from  to . 
Therefore, the truth value of a variable  is consistent.


The only thing left to show is the reason that formula  is satisfiable. 
It is sufficient to show every clause of  is satisfiable. 
Consider any clause .
Since curve  is feasible, 
it uses every point in .  
Assume w.l.o.g. that  visits  
when  is walking along curve .  
By Lemmas 
\ref{lemma:NoSwitchFromAtoB} and \ref{lemma:ABCanSeeC},
this only happens when either ( appears in  and )
or ( appears in  and ). 
Therefore,  is satisfiable.
















 

The last ingredient of the NP-completeness proof is
to show that the reduction takes polynomial time.  
One can easily see that Algorithm \ref{alg:reduction}
has running time , 
where  is the number of variables in 
the input formula with  clauses.






\end{proof}







\subsection{Implementation Results}
To show the simplicity of our reduction algorithm, we have implemented it
in Java.  The figures in this chapter are all generated by our program. 
Our test case, as 
an input to the program, is a formula  with four clauses. The output is 
three sets ,  and  as follows.

Set  is a pointset computed by 
Algorithm \ref{alg:reduction}.
Since  has four clauses, 

contains the following points:

.


Set  is a set of curves, 
where each of it is a configuration of 
 in the reduction algorithm.
Choosing  a formula with four clauses as an input, 
enables us to check all possible configurations of curve  built by Algorithm \ref{alg:reduction}. 
Let   be a variable in  formula
.
Since  or  or none could appear in a clause, and the formula has four clauses,  set  contains 81 curves . 

Set  contains all possible curves , 
each built in this way: 
 starts from point , 
goes through arbitrary points from , 
then to arbitrary points in , next
to arbitrary points from , and lastly 
from 
and at the end, 
 ends at .
Therefore, set  has almost 1,000,000,000 polygonal curves.


Let  be any curve in  
and  be any curve in . 
We compute in our program, the \Frechet distance between every curve  and .
Notice that  has huge amounts of curve data. We implemented our 
program in an efficient way so 
that we could do this computation in 
a fair amount of time. First, 
all 81 curves  are computed and then, 
by computing each  in , 
we compute 81 \Frechet distances 
. Therefore, in total, 
almost  
\Frechet distances have been computed by our program. 
The experiment is 
performed on four machines in parallel, each 
has an Intel(R) Core(TM) i7 CPU 2.67GHz and 12GB RAM.


  
The results show that in all cases,
 
except for the following cases:
\vspace{0.1 in}

Case I:  , then 
, for any curve  in . 


Case II:  , then 
, for any curve  in .
 
Case III:  , then 
, for  corresponding to the case 
where  appeared in the 
first clause. 



Case IV: , 
then 
, for  corresponding to the case 
where  appeared in the 
first clause 
and so on for other occurrence of 
variable  in other clauses. 



\vspace{0.1 in}
Case I confirms Lemma \ref{lemma:PathA},
case II confirms Lemma \ref{lemma:PathB},
cases III and IV confirm Lemma \ref{lemma:ABCanSeeC},
and all together confirm Lemma \ref{lemma:NoSwitchFromAtoB}.




\section{Conclusions}
\label{sec:conc}
In this chapter, we investigated the problem of deciding whether a polygonal curve through a given pointset  exists, which 
visits every point in  and
 is in -\Frechet distance 
to a curve . We showed that this problem is NP-complete. 





\clearpage{}


\REM{
\include{NpComplete/NP}



\clearpage{}\chapter{Conclusions and Open Problems}
\label{ch:OpenProblems}

In the first part of 
this thesis, we introduced 
a new generalization of the well-known \Frechet distance between two polygonal
curves, and provided an efficient algorithm for computing it. In our  variant of the \Frechet problem, the speed of 
traversal along each segment of the curves is restricted to be within a specified range. This setting is more realistic than the classical \Frechet distance setting, specially in GIS applications.
We presented an efficient algorithm to solve the decision problem
in  time, which
led to an  time algorithm for finding 
the exact value of the \Frechet distance with speed limits.
Getting a better running time than   remains open. 

We also studied speed-constrained \Frechet distance in the case where the curves
are located inside a simple polygon.
Several open problems arise from our 
work.
It is interesting to consider speed limits in other variants of the \Frechet distance studied in the literature,
such as the \Frechet distance between two curves lying 
on a convex polyhedron~\cite{AnilFrechet}, or on a polyhedral surface~\cite{WenkC08a}. 

Another open problem, in the context of the first 
part of the thesis, is whether 
our results can be applied in matching planar maps, where the objective is 
to find a path in a given road network that is as close as possible to a vehicle trajectory. 
In~\cite{AltERW03a}, the traditional \Frechet metric is used to match 
a trajectory to a road network. 
If the road network is very congested,  
the \Frechet distance with speed limits introduced in this thesis seems to find a more realistic path in the road network, 
close to the trajectory of the vehicle.
It is also interesting to extend our variant of \Frechet distance 
to the setting where the speed limits on the segments of the curves change as functions over time.


In the second part of this thesis, 
we introduced a data structure, 
called the free space map, which can be used 
as an alternative to the free-space diagram 
in applications related to 
\Frechet distance. 
Our data structure has the same size and construction time as the standard
free-space diagram, and 
encapsulates all the information available in that diagram, 
yet it is capable of answering more general types of queries efficiently. 
One open problem in the 
context of the second part of the thesis
is to quickly answer dynamic queries. Such queries include:
removing  vertices from the input curves 
or adding new vertices to the curves. How fast 
 could we solve the corresponding decision problems or
recompute the \Frechet distance.
\REM{
In the following, we explain the difficulty of constructing such data structure: 



There are several interesting dynamic problems related to \Frechet metric
that to our knowledge, have not yet been addressed  in the literature:


Let   and  be 
two polygonal curves of length  and , respectively.
By spending   , one can compute the \Frechet distance between    and  (i.e. ). 
Now, we want to know how fast we can recompute , after:
  splitting some edges of  (resp., ),
  or deleting some vertices  of polyline  (resp., ),
  or merging some consecutive vertices of  (resp., ) into one vertex. 







Consider the free-space diagram  corresponding to curves  and , and input parameter .
Let . 
Notice that given an arbitrary point , the number of intervals in , , which are monotonically reachable from , 
is linear in the number of cells in one row. 
Let  denote the set of intervals in  which are reachable from 
every point . We observed that for any  and , , 
 has linear complexity (proportional to the number of cells in a row of ). 
We store the reachability information in  in a data structure 
called {\em free space tree} in order to quickly update that information 
after performing the above operations. 












The free space tree is a balanced binary search tree, denoted by , 
which we construct on the top 
of the free-space diagram (See Figure \ref{fig:freeSpaceTree}.a). 
Each leaf  in the tree corresponds to  and
stores  reachability set .
The tree is built bottom-up from the leaves to the root:
at an internal node , with leaf  as the left child
and leaf  as the right child, the reachability information 
is {\em merged} with  and consequently, set 
is stored at node .
The merge process is recursively continued at each internal node of the tree
by merging the reachability information stored at the left and right child of 
that node, until the root of the tree is reached.
Likewise, at the root of the tree, 
 (stored at the left child of the root) 
is  merged with  (stored at the right child of it),
and the reachability set  is stored  at the root. 
Having built the tree, one can report all reachable intervals in  from a point  spending  time ( is the number of those reachable intervals).
In fact, finding the leftmost and the rightmost point in  reachable from  can be done in constant time.  





In the following, we describe the difficulty of constructing  by showing the merge at 
the root of the tree as an example of the challenge in merge operation at internal nodes 
(see Figure \ref{fig:freeSpaceTree}.b for the illustration).
Let  a {\em feasible }interval be the maximal set of white points on the bottom side of a cell. 
Assume the free-space diagram is split in half 
at . Consider a feasible interval  and 
two pointers  and , where the pointers store the leftmost and 
the rightmost point in , reachable from some points in , respectively. 
Imagine another feasible interval 
where   and .
Now, if we could determine the leftmost point in  reachable from , then 
we would be able to determine  in constant time
and consequently, perform the merge at the root of the tree in linear time. 

Our target is to obtain a linear running time
(or near linear) for the merge operation at internal nodes. 
If we could achieve a linear merge, then we can exploit the tree for computing 
the \Frechet distance after different dynamic operations on curves. 
As an example, suppose that we delete a vertex 
from curve . This means that two rows are deleted from the free-space diagram. 
Using the free space tree, we update the reachability information 
in  time rather than  time. Therefore, 
we could decide whether the target point in  is monotonically reachable or not. 
}






\REM{
\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\columnwidth]{Pics/Freespacetree2}
	\caption{ The free space tree is built on the top of the free-space diagram}
	\label{fig:freeSpaceTree}
\end{figure}
}


\REM{
We would also want to investigate about 
computing \Frechet distance in the following setting.
Consider a polygonal curve  corresponding to the trajectory 
of a moving vehicle. Assume that to each edge of , a parameter {\em weight}
is associated, which shows the accuracy of the sampling around that edge.
Our goal is to compute the \Frechet distance between two curves 
taking into consideration the weights on the edges. 
In this setting, the free space inside each cell in the free-space diagram 
corresponding to the curves, shrinks. To solve the decision problem, 
one needs to first discover the properties of the free space inside each cell, 
whether it is convex or -monotone or if it is connected or not. 
Next, the boundary of the free space inside the cells must be computed.
Finally, the free-space diagram is searched to find a monotone path from the bottom-left corner to the top-right corner. 
}








In the third part of this thesis, 
we introduced a new variant of
\Frechet distance problem, 
called Curve-Pointset (CPM) Problem, and showed that
given a polygonal curve  of  segments and a set  of  points in , 
a polygonal curve  through  of size  minimizing  
can be computed in  time. 
Then, we proved that if curve 	is required to visit every point in the pointset, 
the problem becomes NP-complete. 
It is interesting to study special cases of 
this problem when the input is a specific 
type of curve, e.g., an -monotone convex curve, 
or a monotone curve or a non-intersecting curve. 
Also, it will be interesting to study special cases 
of the All-Points CPM problem  under the
condition that each point in the pointset 
can be visited only once.
	
	
\REM{	
	At the end, we studied a special case of the last problem  when the input is a convex polygon. 
Many open problems arise from this
work.	An open problem which we would like to mention is whether a polynomial time algorithm could be designed for the case where the input	
to the All-points CPM problem
is some other special type of curves or polygons, for instance, a non-intersecting curve, or a monotone polygon.  
It would be also interesting to study special cases of All-Points CPM problem  under the condition that each point in the pointset can be visited only once or a weight is 
assigned to each point and 
a curve with minimum or maximum weight should be constructed.
}	
\clearpage{}
}

\bibliographystyle{abbrv}
\bibliography{abbrv,Proposal}


\end{document}
