\synctex=1
\documentclass[10pt,a4paper]{article}




\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{wrapfig}



\newcommand{\igw}[1]{}
\newcommand{\anca}[1]{}





\usepackage{logic9}
\newtheorem{example}[theorem]{Example}

\newcommand{\CAS}{\textsf{CAS}}
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=1pt] (char) {\small #1};}}
\newcommand{\sgt}{\vartriangleright_\sig}
\newcommand{\run}{\mathit{run}}
\newcommand{\Sig}{\mathit{Sig}}
\newcommand{\Ccloc}{\Cc^{\dar_{loc}}}
\newcommand{\ts}{\mathit{ts}}
\newcommand{\Cor}{\mathit{Corr}}
\newcommand{\Parity}{\mathit{Parity}}
\newcommand{\sig}{\mathit{sig}}
\newcommand{\Bad}{\mathit{Bad}}
\newcommand{\rep}{\mathit{rep}}
\newcommand{\bhide}{\bar{\hide}}
\newcommand{\hide}{\mathit{hide}}
\newcommand{\reduce}{\mathit{reduce}}
\newcommand{\addbeg}{\color{blue}}
\newcommand{\addend}{\color{black}}
\newcommand{\added}[1]{\addbeg #1 \addend}
\newcommand{\red}[1]{#1^\triangledown}
\newcommand{\short}[1]{#1^\circledS}
\newcommand{\mem}[1]{#1^m}
\newcommand{\slow}{\mathit{slow}}
\newcommand{\Sloc}{\S^{loc}}




\newenvironment{sproof}{{\em Sketch of Proof. }}{\nopagebreak
  \hspace*{\fill}}




\pagestyle{plain}

\newcommand{\Sync}{\mathit{Sync}}
\newcommand{\CG}{\Cc\Gg}
\newcommand{\Aunc}{A_\mathit{unc}}
\newcommand{\rlp}{r_{l+1}}
\newcommand{\brlp}{\bar{\rlp}}
\newcommand{\cc}{\mathfrak{c}}
\newcommand{\ttest}{\mathit{test}}
\newcommand{\sskip}{\mathit{skip}}
\newcommand{\inctest}{\searrow}
\newcommand{\eqtest}{\downarrow}
\newcommand{\Tower}{\mathit{Tower}}
\newcommand{\state}{\mathit{state}}
\newcommand{\bd}{\bar{\d}}
\newcommand{\Spec}{\mathit{Spec}}
\newcommand{\loc}{\mathit{dom}}
\newcommand{\Plays}{\mathit{Plays}}
\newcommand{\view}{\mathit{view}}
\newcommand{\upa}{\uparrow}
\newcommand{\dar}{\downarrow}
\newcommand{\proj}[1]{_{|#1}}
\newcommand{\da}{\!\!\dar}
\newcommand{\Ssys}{\S^{sys}}
\newcommand{\Senv}{\S^{env}}
\newcommand{\bSsys}{{\bar{\S}^{sys}}}
\newcommand{\bSenv}{{\bar{\S}^{env}}}
\newcommand{\Qsys}{Q^{sys}}
\newcommand{\ES}{\mathit{ES}}
\newcommand{\st}{\mathit{state}}
\newcommand{\dom}{\mathit{dom}}
\newcommand{\bin}{\mathit{bin}}
\newcommand{\test}{\mathit{test}}
\newcommand{\edge}{-\!\!\!-\!\!\!-\!\!\!-\!\!\!-}
\newcommand{\ch}{\mathop{ch}}





\newenvironment{ignore}[1]{}











 





\title{Distributed synthesis for acyclic architectures}



\author{Anca Muscholl\\ Universit\'e de Bordeaux and Igor Walukiewicz\\CNRS, Universit\'e de Bordeaux}




\begin{document}

\maketitle

\begin{abstract}
  The distributed synthesis problem is about constructing correct
  distributed systems, i.e., systems that satisfy a given
  specification. We consider  a slightly more general problem of
  distributed control, where the goal is to restrict the behavior
  of a given distributed system in order to satisfy the
  specification. Our systems are finite state machines that
  communicate via rendez-vous (Zielonka automata). We show
  decidability of the synthesis problem for all -regular local
  specifications, under the restriction that the communication graph
  of the system is acyclic. This result extends a previous
  decidability result for a restricted form of local reachability 
  specifications.

\end{abstract}



\section{Introduction}

\igw{update Intro}
Synthesizing distributed systems from specifications is an attractive
objective, since distributed systems are notoriously difficult to get
right. Unfortunately, there are very few known decidable frameworks
for distributed synthesis. We study a framework for synthesis
of open systems that is based on rendez-vous communication and causal
memory. In particular, causal memory implies that specifications can talk about
when a communication takes place, but cannot limit information that is
transmitted during communication. This choice is both realistic and
avoids some pathological reasons for undecidability. We show
a decidability result for acyclic communication graphs and local
-regular specifications.


Instead of synthesis we actually work in the more general framework of
distributed control. Our setting is a direct adaptation of the
supervisory control framework of Ramadge and Wonham~\cite{RW89}. In
this framework we are given a plant (a finite automaton) where some of
the actions are uncontrollable, and a specification, and the goal is to
construct a controller (another finite automaton) such that its
product with the plant satisfies the specification. The controller is
not allowed to block uncontrollable actions, in other words, in every state there is a
transition on each uncontrollable action. The controlled plant has
less behaviors, resulting from restricting
controllable actions of the plant.  In our case the formulation is
exactly the same, but we consider Zielonka automata instead of finite
automata, as plants and controllers. Considering parallel devices, as
Zielonka automata, in the standard definition of control gives an
elegant formulation of the distributed control problem.








Zielonka automata~\cite{zie87,ms97} are by now a well-established
model of distributed computation. Such a device is an asynchronous
product of finite-state processes synchronizing on shared
actions. Asynchronicity means that processes can progress at different
speed. The synchronization on shared actions allows the synchronizing
processes to exchange information, in particular the controllers can
transfer control information with each synchronization. This model can
encode some common synchronization primitives available on modern
multi-core processors for implementing concurrent data structures, like compare-and-swap.

We show decidability of the control problem for Zielonka automata
where the communication graph is acyclic: a process can communicate
(synchronize) with its parent and its children. Our specifications are
conjunctions of -regular specifications for each of the component
processes. We allow uncontrollable communication actions -- the only
restriction is that all communication actions must be
binary. Uncontrollable communications give a big flexibility, for
instance it is possible to model asymmetric situations where
communication can be refused by one partner, but not by the other one.

Our result extends~\cite{GGMW13} that  showed decidability for a
restricted form of local reachability objectives (blocking final
states). We still get the same complexity as in~\cite{GGMW13}:
non-elementary in general, and EXPTIME for architectures of depth .
Covering all -regular objectives allows to express fairness
constraints but at the same time introduces important technical
obstacles. Indeed, for our construction to work it is essential that
we enrich the framework by uncontrollable synchronization actions. This makes a separation into
controllable and uncontrollable states impossible. In consequence, we are lead to abandon the game metaphor, to
invent new arguments, and to design a new proof structure.



Most research on distributed synthesis and control has been done in
the setting proposed by Pnueli and Rosner \cite{PR90}. This setting is also based
on shared-variable communication, however it does not allow
to pass additional information between processes. So their model leads
to partial information games, and decidability of synthesis holds
only for very restricted
architectures~\cite{KV01,MadThiag01,FinSch05}. While specifications leading to
undecidability are very artificial, no elegant solution to eliminate
them exists at present.
The synthesis setting is investigated
in~\cite{MadThiag01} for local specifications, meaning that each
process has its own, linear-time specification. For such
specifications, it is shown that an architecture has a decidable
synthesis problem if and only if it is a sub-architecture of a
pipeline with inputs at both endpoints. More relaxed variants of synthesis have been proposed, where the
specification does not fully describe the communication of the
synthesized system. One approach consists in adding communication in
order to combine local knowledge, as proposed for example
in~\cite{gpq12}.  Another approach is to use specifications only for
describing external communication, as done in~\cite{gs13tocl} on
strongly connected architectures where processes communicate via
signals.

Apart from~\cite{GGMW13}, two closely related decidability results for
synthesis with causal memory are known, both of different flavor than
ours. The first one \cite{GLZ04} restricts the alphabet of actions:
control with reachability condition is decidable for co-graph
alphabets. This restriction excludes among others client-server
architectures, which are captured by our setting. The second result
\cite{MTY05} shows decidability by restricting the plant: roughly
speaking, the restriction says that every process can have only
bounded missing knowledge about the other processes, unless they
diverge (see also \cite{ms13} that shows a doubly exponential upper
bound). The proof of \cite{MTY05} goes beyond the controller synthesis
problem, by coding it into monadic second-order theory of event
structures and showing that this theory is decidable when the
criterion on the plant holds. Unfortunately, very simple plants have a
decidable control problem but undecidable MSO-theory of the associated
event structure. Game semantics and
asynchronous games played on event structures are considered in~\cite{mel06}. More recent work
\cite{gw13} considers games on event structures and shows a Borel
determinacy result for such games under certain restrictions. 

\emph{Overview.} In Section~\ref{sec:defs} we state our control
problem, and in Section~\ref{sec:reduction} we give the main lines of
the proof, that works by a reduction of the number of processes. In
Section~\ref{sec:short} we show that we may assume for the process
that is eliminated that there is a bound on the number of local actions
it can perform between consecutive synchronizations with its
parent. In Section~\ref{sec:new} we present the reduction, and in
Sections~\ref{sec:C}, \ref{sec:D} we show the correctness of the
construction. 






\section{Control for Zielonka automata}\label{sec:defs}

In this section we introduce our control problem for Zielonka
automata, adapting  the definition of
supervisory control~\cite{RW89} to our model. 




A Zielonka automaton~\cite{zie87,ms97} is a simple
distributed finite-state devices. Such an automaton is a parallel
composition of several finite automata, called~\emph{processes},
synchronizing on shared actions. There is no global clock, so between
two synchronizations, two processes can do a different number of
actions. Because of this, Zielonka automata are also called
asynchronous automata.

A \emph{distributed action alphabet} on a finite set  of processes is a
pair , where  is a finite set of \emph{actions} and
 is a \emph{location
  function}. The location  of action  comprises all
processes  that need to synchronize in order to perform this
action. Actions from  are called \emph{-actions}. 
We write 
for the set of~\emph{local} actions of . 


A (deterministic) \emph{Zielonka automaton}
 is
given by:
\begin{itemize}
\item for every process  a finite set  of (local) states,
\item the initial state , 
\item for every action  a partial transition function
   on tuples of states of processes in .
\end{itemize}

\begin{example}\label{ex:cas}
  Boolean multi-threaded programs with shared
  variables can be modeled as Zielonka automata. As an example we
  describe the translation for the \emph{compare-and-swap} (CAS)
  instruction. This instruction has  parameters: \textsf{CAS}(:
  variable; \emph{old}, \emph{new}: int). Its effect is to return the
  value of  and at the same time set the value of  to
  \emph{new}, but only if the previous value of  was equal to
  \emph{old}. The compare-and-swap operation is a  widely used primitive
  in implementations of concurrent data structures, and has
  hardware support in most contemporary multiprocessor
  architectures.

  Suppose that we have a thread , and a shared variable  that is
  accessed by a CAS operation in  via . So  is a
  local variable of . In the Zielonka automaton we will have one
  process modeling thread  and one process for variable . The
  states of  will be valuations of local variables. The states of
   will be the values  can take. The  instruction above
  becomes a synchronization action. We have the following two types of
  transitions on this action:
  \begin{center}
    \includegraphics[scale=.4]{cas-zielonka.pdf}
  \end{center}
Notice that in state , we have , whereas in , we have .
\end{example}


For convenience, we abbreviate a tuple  of local
states by  ,  where . We also talk about 
as the set of \emph{-states}.

A Zielonka automaton can be seen as a sequential automaton with the
state set  and transitions  if
, and . So the states of this automaton
are the tuples of states of the processes of the Zielonka
automaton. For a process  we will talk about the
\emph{-component} of the state.  A run of  is a finite or
infinite sequence of transitions starting in . Since the
automaton is deterministic, a run is determined by the sequence of
labels of the transitions. We will write  for the run
determined by the sequence . Observe that 
may be undefined since the transition function of  is partial. We
will also talk about the projection of the run on component ,
denoted , that is the projection on component  of the
subsequence of the run containing the transitions involving . We
will assume that every local state of  occurs in some run. For
finite  let  be the last state in . By
 we denote the union of , for all 
occurring in .

We will be interested in maximal runs of Zielonka
automata. For parallel devices the notion of a maximal run is not that
evident, as one may want to impose some fairness conditions. We settle here
for a minimal sensible fairness requirement. It says that a run is
maximal if processes that have only finitely many actions in the run
cannot perform any additional action.

\begin{definition}[Maximal run]
For a word  such that  is
defined, we say that  is
\emph{maximal} if there is no 
decomposition , and no action
 such that  and  is defined. 
\end{definition}




Automata can be equipped with a \emph{correctness condition}. We prefer
to talk about correctness condition rather than acceptance condition
since we will be interested in the set of runs of an automaton rather
than in the set of words it accepts. We will consider local
regular correctness conditions: every process has its own correctness
condition . A run of  is
\emph{correct} if for every process , the projection of the run on
the transitions of  is in . Condition
 is 
specified by a set  of terminal states and an
-regular set . A sequence  satisfies
 if either: (i) 
it is finite and ends with a state from , or (ii)
it is infinite and belongs to .
At this stage the set of terminal states  may look unnecessary, but
it will simplify our constructions later. 

Finally, we will need the notion of \emph{synchronized product}
 of two Zielonka automata. For
 and
 let
 where there is
a transition from  to
 in  iff  and .

\medskip


To define the control problem for Zielonka automata we fix a
distributed alphabet . We partition  into the set of \emph{system actions}  and
\emph{environment actions} . Below we will introduce the notion of
controller, and require that it does not block environment
actions. For this reason we speak about
\emph{controllable/uncontrollable} actions when referring to system/environment
actions. We impose three simplifying assumptions: (1) All actions are
at most binary ( for every ); (2) every
process has some controllable action; (3) 
all controllable actions are local. 
Among the three conditions only the first one is indeed a restriction of
our setting. The other two are not true limitations, in particular controllable
shared actions can be simulated by a local controllable choice, followed by 
non-controllable local or shared actions (see
Proposition~\ref{prop:comm_controllable}).

\begin{definition}[Controller, Correct Controller]
  A \emph{controller} is a Zielonka automaton that cannot block
  environment (uncontrollable) actions. In other words, from every
state every environment action is possible: for every
  ,  is a total function.  We say that a controller
   \emph{is correct for} a plant  if all maximal runs of  satisfy the correctness condition of .
\end{definition}

Recall that an action is possible in   iff it is possible in both  and . By the above
  definition, environment actions
  are always possible in . The major difference between the
  controlled system  and
and  is that the states of  carry  the
additional information computed by , and that  may have less behaviors, resulting from disallowing controllable actions
  by .

The correctness of  means that all the runs of  that are
\emph{allowed} by  are correct. In particular,  does not have
a correctness condition by itself. Considering only maximal runs of
 imposes some minimal fairness conditions: for example
it implies that if a process can do a local action almost
always, then it will eventually do some action. 

\begin{definition}[Control problem]
  Given a distributed alphabet  together with a partition of actions , and
  given a Zielonka automaton  over this alphabet, find a controller  over the same alphabet such that  is
  correct for .
\end{definition}











The important point in our definition is that the controller has
the same distributed alphabet as the automaton it controls, in other
words the controller is  not allowed to introduce additional
synchronizations between processes.  

\begin{example}\label{ex:control}
  We give an example showing how causal memory works and helps to
  construct controllers. Consider an automaton  with  processes:
  , , . We would like to control it so that the only two
  possible runs of  are the following:
  \begin{center}
    \includegraphics[scale=.6]{example-contrl.pdf}
  \end{center}
 So  and  should synchronize on  when action  happened
 before , otherwise  and  should synchronize on
 . Communication actions are uncontrollable, but the
 transitions of  are such that there are local controllable
 actions  and  that enable communication on  and 
 respectively. So the controller should block either  or 
 depending on the order between  and . The transitions of 
 are as follows
 
 These transitions allow the two behaviors depicted above but also
 two unwanted ones, as say, when  happens before  and then we
 see .  Clearly, the specification of the desired behaviors can be
 formulated as a local 
 condition on . So by encoding some information in states of 
 this condition can be expressed by a set of terminal states . We
 will not do this for readability.

 The controller  for  will mimic the structure of : for
 every state of  there will be in  a state with over-line. So,
 for example, the states of  in  will be . Moreover  will have two new states 
 and . The transitions will be
 
Observe that  is blocked in , and so is  from . It is easy to verify that the runs of  are as
required, so  is a correct controller for . (Actually the definition of a controller forces us to make
 transitions of  total on uncontrollable actions. We can do it in
 arbitrary way as this will not add new behaviors to .)


This example shows several phenomena. The states of  are the
states of  coupled with some additional information. 
We formalize this later under a notion of covering controller.
We could also see above a case where a communication is decided by one
of the parties. Processes , thanks to a local action,
can decide if it wants to communicate via , but process  has
to accept  always. This shows the flexibility given by
uncontrollable communication actions. Finally, we could see
information passing during communication. In  process 
passes to  and  information about its local state (transitions
on  and on ).
\end{example}




We end the section by showing the assumption that controllable
actions are local, is not a restriction.

\begin{proposition}\label{prop:comm_controllable}
  The control problem for Zielonka automata where communication
  actions may be controllable, reduces to the setting where
  controllable actions are all local.
\end{proposition}

\begin{proof}
  We start with an automaton  over a distributed alphabet
   and a correct covering controller .  We
  define first a new automaton  over an extended distributed
  alphabet  with . All new actions
  are local:  if ; the
  domain of other actions do not change. What changes is that all old
  actions become uncontrollable, and the only controllable actions in
   are those of the form .

  \begin{itemize}
  \item The set of -states of  is the set of -states of ,
    plus some new states of the form  where  is a
    -state of  and . 
\item For every old -state  we delete all outgoing
  controllable transitions and add
   for every set  of
  controllable actions enabled in . From  we put in  
  transitions as follows. If  is local then we
  have  whenever
   in . If  and
   then we have  whenever  in .
\item The correctness condition of  is a straightforward
  modification of the one of . 

\end{itemize}

  Assume first that  is a correct covering controller for
  . From  we define the automaton  over the same sets
  of states, by modifying slightly the transitions as follows. Suppose
  that  is a (local) transition in . Since
   is covering we have a transition of the form  in . Let  be
  local. Since  is uncontrollable in  and  (for some ) we must also have  for
  some state  of , since  is covering. We delete  from  and replace  by . If  is shared by , let us consider some transition  with  in . Since  is
  uncontrollable in  we find again some transition
   in . We replace then  by  in . Of course, this is done
  in parallel for all transitions labeled by some . It is
  immediate that  is covering , by taking
  . Maximal runs of  map to maximal runs of  and
  thus satisfy the correctness condition for .

Conversely, given a correct covering controller  for  we
define  for . Local -states of  are
those of , plus additional states of the form , where  is
a -state of  and . Consider any -state
 of , and let  be the set of controllable actions enabled
in  (a communication action  with  is enabled
in  if there exists some -state  and an -transition from
). We replace all controllable transitions from  by one
(local) controllable transition , plus some uncontrollable
transitions. If  is local, then we add the 
uncontrollable transitions  whenever   in . If ,  in , and  is the set of controllable actions
enabled in the -state ,  then we replace  by . Extending  by 
shows that  is a covering controller for . Maximal runs of  satisfy the
acceptance condition as for .
\end{proof}



\section{Decidability  for acyclic architectures}\label{sec:reduction}
In this section we present the main result of the paper.  We show the
decidability of the control problem for Zielonka automata with acyclic
architecture. A \emph{communication architecture} of a distributed
alphabet is a graph where nodes are processes and edges link processes
that have common actions. An \emph{acyclic architecture} is one whose
communication graph is acyclic\igw{changed}. For example, the communication graph
of the alphabet from the example on
page~\pageref{ex:control}\igw{reference} is a tree with the root 
and two successors,  and .

\begin{theorem}\label{thm:main}
The control problem for Zielonka automata over distributed alphabets
  with acyclic architecture is decidable. If a controller exists, then
  it can be effectively constructed.
\end{theorem}

The remaining of this section is devoted to the outline of the proof
of Theorem~\ref{thm:main}. This proof works by induction on the number
 of processes in the automaton. A Zielonka automaton over a
single process is just a finite automaton, and the control problem is
then just the standard control problem as considered by Ramadge and
Wonham but extended to all -regular conditions~\cite{AVW02}. If
there are several processes that do not communicate, then we can solve
the problem for each process separately.

 \begin{figure}[htb]
\centerline{ \includegraphics[scale=.4]{schema.pdf}}
\caption{Eliminating process :  is glued with .}   
   \label{fig:schema}
 \end{figure}

Otherwise we choose a leaf process
 and its parent , and construct a new plant  over .We will show that the control
problem for  
has a solution iff the one for  does. Moreover, for
every solution for  we will be able to construct a solution
for . 


For the rest of this section let us fix the distributed alphabet
, 
the leaf process  and
its parent , and  a Zielonka automaton with a correctness
condition .


The first step in proving Theorem~\ref{thm:main} is to simplify the
problem. First,  we can restrict to controllers of a special form
called covering controllers. Next, we show that the component of 
to be eliminated, that is , can be assumed to have a particular property
(-short). After these preparatory results we will be able to present
the reduction of  to  (Section~\ref{sec:new}).

\subsection{Covering controllers}


The notion of a covering controller will simplify the presentation
because it will allow us to focus on the runs of the controller
instead of a product of the plant and the controller.\igw{refer to the
  example}

\begin{definition}[Covering controller]~\label{df:covering controller}
  Let  be a Zielonka automaton over the same alphabet as ;
  let  be the set of states of process  in . 
  Automaton  is a \emph{covering controller} for  if
  there is a function , mapping each  to  and satisfying two conditions:
  (i)  if  then
  ; (ii) for
  every uncontrollable action : if  is enabled from
   then it is also enabled from .
\end{definition}


\begin{remark} Strictly speaking, a covering controller  may not be a
controller since we  do not require that every uncontrollable action
is enabled in every state, but only those actions that are enabled
in . From  one can get a controller  by adding
self-loops for all missing uncontrollable transitions. 

Notice that thanks to the projection , a covering controller can
inherit the correctness condition of . Moreover, the sequences
labeling the maximal runs
of ,  and  are the same.
\end{remark}


\begin{lemma}\label{lemma:covering}
  There is a correct controller for  if and only if there is a
  covering controller  for  such that all the maximal runs
  of  satisfy the inherited correctness condition.
\end{lemma}

\begin{proof}
  If  is a covering
controller for  such that all its 
  maximal runs satisfy the inherited correctness condition then
   is a correct controller for . 
Conversely, if  is a correct controller for  then
   is a covering controller where all maximal runs
  satisfy the inherited correctness condition.
\end{proof}

We will refer to a covering controller with the
property that  all its
maximal runs satisfy the inherited correctness condition, as 
\emph{correct covering controller}.

\subsection{Short automata}\label{sec:short}

In this section we justify our restriction to plants  where the
-component  is short (see Definition~\ref{def:r-short}
below).  Recall that we have assumed that all controllable actions are
local and that we consider a tree architecture with a leaf process 
and its parent .

\begin{definition}[-short]\label{def:r-short}
 Automaton  is \emph{-short} if there
  is a bound on the number of actions that  can perform without
  doing a communication with . 
\end{definition}



\begin{theorem}\label{thm:short}
  For every automaton , we can construct an -short automaton
   such that there is a correct controller for  iff
  there is one for .
\end{theorem}
The rest of this subsection is devoted to the proof of the above theorem.
Theorem~\ref{thm:short} bears some resemblance with the fact that
every parity game can be transformed into a finite game: when a loop
is closed the winner is decided looking at the ranks on the loop. This
construction would do if  had no interaction with . Possible
interactions with  make the construction more involved. Moreover,
need to prove existence of some kind of memoryless strategies for
distributed controllers.


Observe that we can make two simplifying assumptions. First, we assume
that the correctness condition on  is a parity condition. That is,
it is given by a rank function  and the set of
terminal states . We can assume this since every regular language
of infinite sequences can be recognized by a deterministic parity
automaton. The second simplification is to assume that the automaton  is
\emph{-aware} with respect to the parity condition on . This
means that the state of  determines the biggest rank that
has been seen since the last communication of  with . It is easy
to transform an automaton to an -aware one.










Recall that if  is a covering controller for  (cf.\
Definition~\ref{df:covering controller}) then
there is a function , mapping each  to  and respecting
the transition relation: if  then
. 


\begin{definition}[-memoryless controller]
  A covering controller  for  is \emph{-memoryless} when
  for every pair of states  of : 
if there
  is a path on local -actions from  to  then
  .
\end{definition}


Intuitively, a controller can be seen as a strategy, and -memoryless
means that it does not allow the controlled automaton to go twice
through the same -state between two consecutive communication
actions of  and .


\begin{lemma}\label{lemma-r-memoryless}
  Fix an -aware automaton  with a parity correctness condition
  for process . 
  If there is a correct controller for  then there is
  also one that is covering and -memoryless.
\end{lemma}




The proof of Lemma~\ref{lemma-r-memoryless} uses the notion of
  signatures, that is classical in 2-player parity games, for defining
  a -memoryless controller  from . The idea is to use
  representative states of , defined in each strongly connected
  component according to a given signature and covering function
  .

By Lemma~\ref{lemma:covering} we can assume that we have a covering
controller for . Let us fix an arbitrary
linear order on the set  of states of the automaton . Let
 denote the graph obtained from  by taking  as
set of vertices and the transitions on local -actions as
edges. Since  is a covering controller, every sequence of actions
in  can be performed in the controlled plant. Since  is
correct for , every
infinite sequence of local -actions in the controlled plant
satisfies the parity condition. We can lift this parity condition
directly to  thanks to the fact that  is covering. We obtain
that every infinite path in  satisfies the parity condition.

  Before proceeding it will be convenient to recall some facts about
  parity games, in particular the notion of
  signature (or progress measure)~\cite{wal01ic}. We consider  as a
  parity game. Suppose that it uses priorities from
  . A signature is a -tuple of natural numbers,
  that is, an element of . We will be interested in
  assignments of signatures to states of , that is in
  functions . Signatures are ordered
  lexicographically. We write  if the signature
  assigned to  is lexicographically bigger or equal to that of
  . For  we write  if
  the signature of  truncated to the first  positions is
  lexicographically bigger or equal to the signature of  truncated
  to the first  positions.  For a fixed assignment of signatures
   and two states ,  of  we write  if
  
  We say that an assignment of signatures  is
  \emph{consistent} if for every edge  of  we have
  . We now recall a fact that holds for every finite
  parity game, but we specialize them to .

 \noindent
\textbf{Fact.} 
 Every path of  satisfies the parity
  condition iff there is a consistent assignment of signatures to
  states of .


  After these preparations we can define for every state  of
   its
  representative state in , denoted , as the unique
  state  satisfying the following conditions:
  \begin{enumerate}
\item  and  is reachable from ;
\item for every  with : if  is
  reachable from  then it belongs to the same SCC as
  ;
\item among all states satisfying points (1) and (2) consider those
  with the smallest signature; if there is more than one such state
  then pick the state that is the smallest in our fixed arbitrary ordering.
\end{enumerate}


  \begin{remark}\label{rem:rep} 
    For every  reachable in  from : if
     then . Indeed, by
    conditions (1) and (2) above  and  must be
    in the same SCC. But then, the representative is uniquely
    determined by signature and ordering. 
  \end{remark}
  

  We define now  from  by redirecting every
  transition on a local -action to representatives: if the transition
  goes to a state  we make it go to . Of course,
   is still covering and
  the above remark implies that it is -memoryless.


  \begin{remark}\label{rem:path}
    If we have a transition  in  then
    there is a sequence  of local -actions and
    some state  such that
     in .
  \end{remark}
 

  Remark~\ref{rem:path} allows to map paths in  into paths
  in . Consider a state  of  and a finite
  sequence  such that  labels some path
  from  in , say . Remark~\ref{rem:path} gives us a
  sequence , and a
  corresponding path in : , for some . In particular the two paths end in the same state. Of
  course  is defined similarly for infinite
  sequences .

\medskip

\textbf{Proof of Lemma~\ref{lemma-r-memoryless}.}
  We are ready to show that  obtained from  by replacing 
  with  satisfies the parity condition. For this take a
  maximal run and suppose towards a contradiction
  that it does not satisfy the parity condition.

  If on this run there are infinitely many communications between  and  
  then there is an equivalent run whose labeling has the form:
  
  where , , and . Here two runs are equivalent means that the
  projections of the two runs on every process are identical. In
  particular, if two runs are equivalent and one of them satisfies the
  correctness condition then so does the other. 

  Let  be the state of
   reached on the prefix of  up to . Let
  . We get that the sequence
  
  is a labeling of a maximal run in . The projections on processes other than  are
  the same for  and . It remains to see if the parity condition
  on  is satisfied. We have  in
   and  in . Since we
  lifted priorities to  and  (being both covering),  the
  -awareness of   lifts to  and , so the
  same maximal rank is seen when reading  and . This shows
  that the parity condition on  is satisfied on the run of
   on , since it is satisfied by the run of  on .


  Consider now a maximal run with finitely many communications between
   and . There is an equivalent one labeled by a sequence of the
  form: 
  
  where  and  are potentially infinite. Since we have only
  modified the -component of the controller, it must be  that
  does not satisfy the parity condition on . 

  Suppose first that  is infinite. Take the run
   in , where . We have a run
   in
  , where  and  is the accessibility path,
  as given by Remark~\ref{rem:path}. We have  for all
   because there is an edge from  to  in
  . Recall that . The definition of
  representatives implies that either  or
   is in a strictly lower SCC than . Since lowering a
  component can happen only finitely many times we have
   for all  bigger than some . We get
   for  which implies that  satisfies the
  parity condition. A contradiction. 

If  is finite then we define the sequence  in , as in the first case. Since  was maximal in ,
we have that  is maximal in  (if  can do an action in
, the same can be done in , since  and  end in the same
state). Thus the -state reached in  by   belongs to ,
since this holds already for . We get again a contradiction.
\medskip

We will use Lemma~\ref{lemma-r-memoryless} to reduce the control
problem to that for -short automata.

Given  we define a -short automaton . All its
components will be the same but for the component . The states  of
 will be sequences  of states of  without
repetitions, plus two new states . For a local transition
 in  we have in  
transitions:

There are also
communication transitions between  and :

Notice that  disappears in communication transitions. 
The  parity condition for  is also rather straightforward: it
is the same for the components other than , and for  it is
\begin{itemize}
\item ,
\item  .
\end{itemize}



\medskip

\textbf{Proof of Theorem~\ref{thm:short}:}
  Consider the implication from left to right.
  Let  be a correct covering controller for . 
  By Lemma~\ref{lemma-r-memoryless} we can assume that it is -memoryless. 
  We show that  is also a covering correct controller for
  . We will concentrate on correctness, since the covering part
  follows by examination of the definitions. 

  Let us take some maximal run  of , and suppose by contradiction that it does not satisfy the
  parity condition of .  By definition  is a run
  of , but it may not be maximal. We have by
  construction of  that  for
   and that  is the last element of
  . (Recall that 
  denote the state reached on  by 
   and , resp.)

  Suppose that  is not a maximal run of . We will
  extend it to a maximal run ). If  ended in  in the
  -component of  then we could extend  to a run of
   not satisfying the parity condition (here we use that
   is memoryless, so the odd loop in  exists also into one in ). So the only
  other possibility is that  ends in .  In this case it is
  possible to extend  to a complete run of  by adding
  the even loop in the -component. This makes 
  satisfy the parity condition. Let  be the resulting run.

  Now observe that if a parity condition for some process  is
  violated on  then on  the same condition is violated. If
  it is violated on  then the only remaining possibility is that
  there are finitely many -actions in , and the state reached on
   is  with . But then  is a maximal run
  of  and is not well terminated on  either, a
  contradiction.

  For implication from right to left we take a covering controller 
  for  and construct a controller  for . The
  controller  will be obtained by modifying the -component of
  .  The states of  will be sequences of states
  of . They will be of bounded length. We will have that
  if  is a state of  then
   is the state  of ,
  where  , for . Moreover, we define . The transitions of  are
  \begin{itemize}
  \item \quad if  in  and . 
  \item \quad if  in ,  and  is such that  is
     with   in . 
  \end{itemize}
  Notice that since  satisfies the parity condition 
  cannot be reached.

\medskip

\begin{remark}
The construction of  guarantees that
  every sequence of local -actions  of  has a corresponding
  (possibly shorter) sequence  of . If the sequence in
   starts in  and finishes in  then the sequence
  in  starts also in , but now considered as a sequence of
  length , and finishes in a sequence ending in . Since 
  is -aware and  and  are both covering, this
  means that the maximal rank seen on both sequences is the same.
  
\end{remark}

  We need to show that all maximal runs of  satisfy the
  parity condition. For contradiction suppose that  does not.

  If there are infinitely many communications between  and  on
   then we write it as
 
  where , , and . Now for every , Observation 1 gives 
  so that the maximal ranks on  and  are the same, so for
   
   is a maximal run of . This gives a run
  violating the parity condition of .

  If there are finitely many communications between  and  on
   then we write it as
   where  and  are potentially infinite. The
  only complicated case is when  is infinite. We need to show that
  the run of  on  satisfies the parity condition. Recall
  that the states of  are  sequences of states of
  . Moreover the length of this 
  sequences is bounded. Take the shortest sequence appearing infinitely
  often in . The biggest rank seen between consecutive appearances of this
  sequence is even, since the path can be decomposed into
  (several) even loops of .


\medskip

\begin{corollary}
  In the -short plant  the -controller may be chosen
  memoryless since there are no infinite local -plays.\igw{remove corollary?}
\end{corollary}


\begin{remark}
  We claim that the complexity of the reduction from  to  is
  polynomial in the size of  and simply exponential in the size
  of . The reason is as follows. States of  are
  simple paths  (i.e., without repetition of states) of . When going from
   to , the states of  contain -local
  strategies . Putting things together, in 
  we deal with paths of  (mapping them to ). But the latter
  can be written more succinctly as paths of  without repetitions.
\end{remark}






\subsection{The reduced automaton }\label{sec:new} 
Equipped with the notions of covering controller and -short strategy
we can now present the construction of the reduced automaton . We suppose that  is
-short and we define now the reduced automaton  that results
by eliminating process  (cf.\ Figure~\ref{fig:schema}).  Let
.  We construct
 where the
components are defined below.

All the processes  of  will be the same as in
. This means: , and . Moreover, all
transitions  with  are as in
. Finally, in  the  correctness condition of 
is the same as in .

Before defining process  in  let us introduce the notion
of -local strategy. An \emph{-local strategy from a state
  } is a partial function 
mapping sequences from  to actions from , such that
if  then  in .  Observe that since the
automaton  is -short, the domain of  is finite.

Given an -local strategy  from , a local action  is \emph{allowed by }
if , or  is uncontrollable. For  allowed by 
 we
denote by  the -local strategy defined by
; this is a strategy from , where . 






The states of process  in  are of one of the following types:

where ,  is a -local strategy from ,
and . The new initial state for  is 
. 
Recall that that since  is -short, any -local strategy in  is
necessarily finite, so  is a finite set. Recall also
  that controllable actions are local.

The transitions of  are presented in
Figure~\ref{fig:transitions}. Transition \circled{} chooses an
-local strategy . It is followed by transition \circled{}
that declares a controllable action  that is enabled from
. Transition \circled{} executes the chosen action ; we
require  in . Transition \circled{}
executes an uncontrollable local action ; provided
 in . Transition \circled{} executes a local action
, provided that  is allowed by  and .
Transition \circled{} simulates a synchronization  between  and
; provided  in . Finally, transition \circled{} simulates a synchronization
between  and . An example of a simulation of  and
 by  is presented in
Figure~\ref{fig:simulation}. The numbers below transitions refer to
the corresponding cases from the definition. 


















To summarize, in  we have all actions of  and ,
but they become uncontrollable. All the new actions of
process  in plant  are \emph{controllable}:
\begin{itemize}
\item action , for every local -strategy ,
\item action , for every .
\end{itemize}
\begin{figure}[tbp]
  \centering
\includegraphics[scale=1]{ared-transitions.pdf}
  \caption{Transitions of }\label{fig:transitions}
\end{figure}

\begin{figure}[tbp]
  \centering
\includegraphics[scale=.6]{simulation.pdf}
  \caption{Simulation of  and  by .}\label{fig:simulation}
\end{figure}
The correctness condition for process  in  is:
\begin{enumerate}
\item The correct infinite runs of  in  are those that have
  the projection on transitions of  correct with respect to , and
  either: \emph{(i)} the projection on transitions of  is infinite and
  correct with respect to ; or \emph{(ii)} the projection on
  transitions of  is finite and for  appearing in almost
  all states of  of the run we have that from  all sequences
  respecting strategy  end in a state from .
\item  contains states  such that
  , and .
\end{enumerate}
Item  in the  definition above captures the case where  progresses alone till infinity and blocks
, even though  could reach a terminal state in a couple of
moves. Clearly, item  can be expressed as an -regular
condition. \igw{added some explanations} The definition of correctness condition is one of the
principal places where the -short assumption is used. Without this
assumption we would need to cope with the situation where we have an
infinite execution of , and at the same time an infinite
execution of  that do not communicate with each other. In this
case  would need to fairly simulate both executions in some way.





The reduction is rather delicate since in concurrent systems there are
many different interactions that can happen.  For example, we need to
schedule actions of process , using  actions, before the
actions of process . The reason is the following. First, we need to
make all -actions uncontrollable, so that the environment could
choose any play respecting the chosen -local strategy. Now, if we
allowed controllable -actions to be eligible at the same time as
-actions, then the control strategy for automaton  would
be to propose nothing and force the environment to play the
-actions. \igw{added some explanations} This would allow the
controller of  to force the advancement of the simulation of
 and get information that is impossible to obtain by the controller
of .

Together with Theorem~\ref{thm:short}, the theorem below implies 
our main
Theorem~\ref{thm:main}. 

\begin{theorem}\label{thm:correctness}
  For every -short Zielonka automaton  and every local,
  -regular
  correctness conditions: there is a correct covering controller for
   iff there is a correct covering controller for . 
  The size of  is polynomial in the size of  and
  exponential in the size of .
\end{theorem}

We end with some notations used in the following sections. For a
Zielonka automaton  over  and  we will write  for the sequence of transitions of  when
  reading . For finite  we will write  for the last state in
  .



























\subsection{Proof of Theorem~\ref{thm:correctness}: from 
                                to }\label{sec:C}

By Lemma \ref{lemma:covering} we can assume that we have a
\emph{correct covering controller}   for . We show how to construct
a correct controller  for . This will give the left
to right implication of Theorem~\ref{thm:correctness}.

\begin{remark} Some simple observations about .
\begin{enumerate}
\item We may assume that from every state of  there is at most one
  transition on a local controllable action. If there were more than
  one, we could arbitrary remove one of them. This will reduce
  the number of maximal runs so the resulting controller with stay correct.

\item  determines for every state  of  a local
  -strategy  from : if ,  and  for all
  , then  where  is a (unique)
  controllable action possible from . This strategy
  may have memory, but all the (local) plays respecting
   are of bounded length, assuming that  is -short.
\end{enumerate}
\end{remark}


The components  for  are just , and the
initial state is the same. The
component  is described below. Its states are of the form
,  and  with ,
, , and local -strategy . Its
initial state is , with  initial
states of . 

The transitions of  ensure the right choice of a local
strategy and of a local action:

\begin{itemize}
\item Choice of -strategy:
   where  is the local
  -strategy from  determined by  in state .

\item Choice of a (local) controllable -action:
   For  unique such that
  , for some . If there is no such transition then we
  put some arbitrary fixed action .
\end{itemize}

The other transitions of  are on uncontrollable actions,
they just reflect the structure of :
\begin{itemize}
\item Execution of the chosen controllable -action:


\item Execution of an uncontrollable local -action:
  

\item Communication between  and :


\item Local move of :


\item Communication between  and 

\end{itemize}

\begin{lemma}\label{lemma:C is covering}
  If  is a covering controller for  then   is a
  covering controller for . The covering function is
  
\end{lemma}


For the correctness proof we will need one more definition:

\begin{definition}[]
  For  we let  be
  the sequence obtained by removing actions from .
\end{definition}

Observe that by construction of  if  is defined
then in  there can be at most two consecutive -actions from
.

\begin{lemma}\label{lemma:C invariant}
  Let . If  is defined then so is
  .  Moreover, letting  and
  , we have that
(i)   for all , and (ii) 
   is either , or , or
  ; where  and  are 
  determined by  and  as follows:
  \begin{itemize}
  \item  is the unique controllable -action from  in  (or
     if there is none).
  \item  is the local -strategy determined by 
    in .
  \end{itemize}
\end{lemma}
\begin{proof}
  The proof is by induction on the length of . It follows by direct
  examination of the rules.
\end{proof}

\begin{lemma}\label{lemma:projecting-runs}
  Assume that . For every process  we have
  . Concerning
  : if we project it on transitions of  we obtain
  ; if we project it  on transitions of
   we obtain .
\end{lemma}
\begin{proof}
  Directly from the previous lemma.
\end{proof}




\begin{lemma}\label{lemma:C correct}
  If  is a correct covering controller for  then 
  is a correct covering controller for .
\end{lemma}
\begin{proof}
  Since  is a correct covering controller we have that
  all maximal runs of  are correct w.r.t~.  By
  Lemma~\ref{lemma:C is covering} we 
  know that  is a covering controller,
  so it is enough to show that all maximal runs of  are
  correct w.r.t.~.

  Take a maximal run in , say on . The
  first obstacle is that  may be not maximal in
  . This can only happen when there are infinitely many
  -actions in , but only finitely many -actions. Then we have
   and there are no -actions in . Let
  . We have that  and  appear
  in all , for every prefix  of . The
  run  is not maximal when there is at least some
  local action of  enabled in . Let  be a maximal
  sequence of local -actions that is possible in  from state
  . Since  is -short, every such sequence is
  finite. Moreover we choose  in such a way that it brings 
  into a state not in  (if it is possible).  We get that
   also defines a maximal run of , but now the run
  on  is maximal in . Notice that 
  satisfies  iff  does: the difference is the
  sequence , and we have chosen, if possible, a losing sequence.

  We need to show that the run of  on  satisfies
   using the fact that the run on  satisfies
  .  For , Lemma~\ref{lemma:projecting-runs} tells us
  that  is the same as . Since
   and  are the same, we are done.

  It remains to consider . If there are finitely many
  -actions  in  then   with no
  -action in . Consider
  . We have that
   and . As there
  are no -actions in , and  satisfies
  , we must have  and . This shows that
   satisfies .

  If there are infinitely many -actions in , we
  still have two cases. The first is when there are infinitely many
  actions from  as well. Then 
  satisfies  if the corresponding runs 
  and  satisfy  and ,
  respectively. This is guaranteed by our assumption that 
  satisfies .

  The last case is when in  we have infinitely
  many -actions and only finitely many actions from . Then 
  with no actions from  in . We get 
  with both ,  appearing in all the further states of the
  run. Since  satisfies , we have that
  . But then, by the construction of , there is
  no -transition possible from  (and neither from
   in , since  is covering). This means that 
  satisfies .


\end{proof}




\subsection{Proof of Theorem~\ref{thm:correctness}: from 
                                to }\label{sec:D}
This subsection gives the
right-to-left direction of the proof. Given a correct controller  for
, we show how to construct a correct controller  for
. By Lemma~\ref{lemma:covering} we can assume that  is
covering.



The components  for  are the same as in
. So it remains to define
 and . 
The states of  and  are obtained from states of
. We need only certain states of ,
namely those  whose projection  in  has four
components, we call them \emph{true states} of :

Figure~\ref{fig:d-simulation}
presents an execution of  controlled by . We can see
that  is a true state, and  is not.

The set of states of  is just , while the states of
 are pairs  where  is a state from
 and  is a sequence of local
-actions  that is possible from  in , in
symbols . We will argue later that such sequences are
uniformly bounded. The
initial state of  is the state  reached from the initial state
of  by the (unique) transitions of the form
. The initial state of  is . 
The local transitions for  are 
, for every 
    and .


Before defining the transitions of  let us observe that if 
 is not in  then only one
controllable transition is possible from it. Indeed, as  is a
covering controller, if  is of the form  then
there can be only an outgoing transition on a letter of the form
. Similarly, if  is of the form 
then only a  transition is possible. Since both  and
 are controllable, we can assume that in  there is
no state with two outgoing transitions on a letter of this form. For a
state  not in  we will denote by
 the unique state of  reachable from 
by one or two transitions of the kind  or ,
depending on the cases discussed above. Going back to
Figure~\ref{fig:d-simulation}, we have . 

We now describe the -actions possible in .
\begin{itemize}
\item Local -action :  if
   in . For example, this gives a
  transition  in Figure~\ref{fig:d-simulation}.


\item Communication  between  and :  if  in .


\item Communication  of  and :
   
if  in ;
observe that  is a sequence of transitions. For example, this gives a
  transition on  in Figure~\ref{fig:d-simulation}.
\end{itemize}
In the last item the transition does not depend on  since,
informally,  has been reached from  by a sequence of
actions independent of . The condition  simulates the order of actions where all local -actions come
after the other actions of , then we add a communication between
 and .

\begin{figure}[tbp]
\includegraphics[scale=.7]{d-simulation.pdf}
  \caption{Decomposing controller  into  and
    .}\label{fig:d-simulation}
\end{figure}

The next lemma says that  is a covering controller for
. Since  is assumed to be -short, the lemma also gives a
bound on the length of sequences in the states of . 
\begin{lemma}\label{lem:Dcovering}
  If  is a covering controller for  then  is a
  covering controller for .
\end{lemma}

\begin{proof}
  We need to define the projection function  using the projection
  function . For  set . For 
  we define  where  is the state of  in
  .  For  and its state  we define
   where  and  is the state of  in
  .

  We need to check that the transitions defined above preserve this
  projection function; namely for every process : if  in  then  in ; and
  similarly for communication actions.  The statement is obvious if
  the move is in components other than  or . We are left with
  four cases:
  \begin{itemize}
  \item Local move of , namely . We have
     in  for some , since
    .  By the fact that
     covers  and the definition of moves of the
    latter automaton we
    have in :
    
    and by definition of  we know that  is in .
  \item Communication between  and  is similar.
  \item Local move of : . By definition we
    know that from  it is possible to do in  the sequence of actions
    , that is . \anca{old: We have
    , 
    and ;} 
    We have
    , 
    and ; since  is a sequence of
    local -actions the other components do not change. We have
     by definition of , and ,
    , as required.  
  \item Communication between  and :
    . By
    definition this is possible only  when  in
    . Since  is covering we get the following
    sequence of transitions in : \anca{changed f in f' below,
      f' in g}
    
  \end{itemize}
  So we have  in  and
  , , .
  We claim that , and for this
   we need to observe a property of the runs of
   (proved by induction on the length of the run). The intuition
  for the property below is that  was reached from  by
  actions that do not involve . \anca{added ``The intuition..''}

  \begin{quote}
    \textbf{Property (*)} If from the initial state  can reach a
  global state with  and  at the coordinates
  corresponding to  and , respectively, then the - and -components of the  projections of  and  are the same:
  and
  , for some .

  \end{quote}
  

  From Property (*) it follows that , hence
   since .

  It remains to check the controllability condition for . For
  components other than  and  this is obvious. 
  We have four cases to examine.

  First, let us take a state  of . Suppose that
   is a local, uncontrollable transition in
  . We need to show that  is possible
  in . Since  is a state of  we have
   in . Moreover,  is of the
  form  and . We get that
   \anca{changed 2nd f in f'}exists in .  Since
   satisfies the controllability condition, in  there must
  be a transition  for some . Hence, by
  definition,  exists in .

  For the next case we take a state  of  and suppose that
   is a local, uncontrollable transition in
  . We need to show that a -transition is possible from
   in . We get  is of the form , and
  . This means that the transition
   is in . Since
   is covering, we get  for some  in
  . But then  in  by
  definition.

  The case of communication of  with  is similar to the
  above.

  The last case is a communication between  and . So take
   and suppose
   in . We have that
   is of the form  and
   is of the form ; the - and
  -components are the same by Property (*). Moreover,
  by definition  holds. Let , thus
  . These observations allow us to
  obtain the following sequence of transitions in :
  \anca{changed 2nd f in f'}
  
  Since  satisfies the controllability condition   we must
  have transitions  in , 
  with . This means that we have transition
   in  and 
  , . 
\end{proof}

As  is covering, to prove that  is correct we need to show
that all its maximal runs satisfy the correctness condition. For this
we will construct for every run of  a corresponding run of . The following definition and lemma tells us that it is enough to
look at the runs of  of a special form. 
\begin{definition}[]\label{def:slow}
  We define  as the set of all 
  sequences labeling runs of  of the form  or , 
where , ,  , and 
\end{definition}

\begin{lemma}\label{lemma:reduciton-to-slow}
 A covering controller  is correct for  iff
  for all ,  satisfies the correctness condition
  inherited from .
\end{lemma}

\begin{proof}
  Observe first  is
  -short, since  is -short and  is covering. Thus
  every sequence labeling some run of   either has
  finitely many -actions or infinitely many communications of 
  with .  

  Secondly, note that every sequence  labeling
  some run of  can be rewritten into a sequence  from
   by repeatedly replacing factors  by , if
  . We have that  is also
  defined and  for every
  process . Therefore for
  correctness it will be enough to reason on sequences from
  .
\end{proof}


For every sequence  as in Definition~\ref{def:slow} we
define the sequence  by induction on the
length of . Let , where  and 
are determined by
    the initial -state of .  For  let

where  and  are determined by the state reached by  on
.   The next lemma
implies the correctness of the construction, and at the same time
confirms that the above definition makes sense, that is, the needed
runs of  are defined.









\begin{lemma}\label{lemma:D invariant}
  For every sequence  we have that
   is defined. If  is finite then the states
  reached by  on  and by  on  satisfy the following:
  \begin{enumerate}
  \item  for every
  .
\item Let , where , , and . Then  and , where
   and
  .
  \end{enumerate}
\end{lemma}

\begin{proof}
  Induction on the length of . If 
  then  and  where  in , which shows the claim. Let
  . If , then , ,
  ,
  . Moreover,
  , where
  . Finally, assuming
  that  defined, observe that this run can be extended by a
  -transition since it can be in  and the concerned states are
  the same.

We consider the remaining cases:
\begin{enumerate}
\item Let , then  and . We have
  .
 Moreover, , where
 . In
  there is a transition , which
 shows the claim about states. Finally we justify that the run on  
 in  can be extended by a .  We know that 
 and 
 in , and want to show that . This holds
 since  is covering and since Property (*) guarantees that
 the  and  components of  and  are
 the same.
\item Let , so  is either local on 
  or a communication with . We have  and
  . Assume that  is local on . We have
  , where  and  are such
  that  and  in . By induction,
  , and
  by definition of , .  Thus
   and the claim about states
  is shown. The run  on  in  exists by the definition
  of  from .

The case of a communication with  is similar to the above.
\item Let  be a communication between  and
  , thus  and . We have , where  are such that
  . Consider  and
  . By
  induction,  and .
  In  we have a transition  since  in . Thus,
   and
  , which shows the
  claim about states. The run on  in  exists by the
  definition of  from .
\end{enumerate}
\end{proof}



\begin{lemma}\label{D: maximal}
  If  and  is maximal in , then
   is maximal in .
\end{lemma}

\begin{proof}
  Recall first that  is not maximal only if for some
  finite prefix  of ,  can be extended by some
  action  (and the processes in  do not appear anymore in
  the remaining suffix of ). From the definition of 
  it follows that it suffices to consider prefixes of 
  of the form , where  with  finite. By
  Lemma \ref{lemma:D invariant} we note first that such an  cannot be on
  processes other than  or , since
   for all .

We consider the remaining cases, and assume :

\begin{enumerate}
\item Assume that  can be extended by some  in
  , and let ,
  , so  in .  By
  Lemma~\ref{lemma:D invariant} we have  and by
  Property (*), the - and -components of  and
   are the same. Since  is covering, this
  means that , hence there is a run on  in 
  so  was not maximal.
\item Assume that  can be extended by some  and recall from Lemma~\ref{lemma:D invariant} that
  , where . Consider 
   and assume that  is -local (the
  case of a communication with  is similar). We have  in  from some , and we want
  to show that  for some . But this holds since  is
  covering and the  components of  and
   are the same. So the run of  in  was not
  maximal, since there is a run on  in . 
\item Assume that  can be extended by some . Recall from Lemma~\ref{lemma:D invariant} that
   and , where
   and
  . We have that
   where , and
  . According to the definition of , there is a
  transition 
  in , so that the run on  was not maximal.
\end{enumerate}
Note that a run on 
cannot be extended by actions of the form  or , since
 is covering. So the above four cases exhaust all the possibilities.
\end{proof}


\begin{lemma}\label{lemma:D correct}
 If  is a correct covering controller for , then 
  is a correct covering controller for .
\end{lemma}

\begin{proof}
  By Lemma~\ref{lemma:reduciton-to-slow} it is enough to show that 
  for all ,  satisfies .
  By Lemmas~\ref{lemma:D invariant} and \ref{D: maximal} the run on
   exists and is 
  maximal. Since  is correct this run satisfies .

  Consider a maximal run in , labeled by some
  . It is of one of the forms
  
  where , , , and 

  By Lemma~\ref{lemma:D invariant}  and
   are the same for . Since for such
   also the
  correctness conditions of  and  are the same, and since
   satisfies , so does
  . 

  Considering , Lemma~\ref{lemma:D invariant} gives us
  
 for every
  . Moreover, the -component does not change when going from
   to
  . Thus,
   is equal to the projection on  of , so   satisfies
  . 

 
  It remains to consider . For this we can use Lemma~\ref{lemma:D
    invariant} obtaining
  with
  , for every
  . Recall that  was defined as the -component
  of , where  in . Assume
  first that  is of the form . Observe that  is equal to the
  projection on  of , thus
   satisfies  because  satisfies
  . Let now  be of the form . Since  is maximal we have that , again because  satisfies . 
\end{proof}





\section{Conclusion}

We have considered a model obtained by instantiating Zielonka automata
into the supervisory control framework of Ramadge and
Wonham~\cite{RW89}. The result is a distributed synthesis framework that
is both expressive and decidable in interesting cases. To
substantiate we have sketched how to encode threaded boolean programs
with compare-and-swap instructions. Our main decidability result
(Theorem~\ref{thm:main}) shows that the synthesis problem is decidable
for hierarchical architectures and for all
local omega-regular specifications. Recall that in the Pnueli and Rosner
setting essentially only pipeline architectures are decidable, with
an additional restriction that only the first and the last process in
the pipeline can handle environment inputs. In our case all the
process can interact with the environment.

The synthesis procedure presented here is in -\EXPTIME\ for
architectures of depth 
, in particular it is \EXPTIME\ for the case of a one server
communicating with clients who do not communicate between each
other. From~\cite{GGMW13} we know that these bounds are tight.


This paper essentially closes the case of tree architectures
introduced in~\cite{GGMW13}. The long standing open question is the
decidability of the synthesis problem for all
architectures~\cite{GLZ04}. 













\begin{thebibliography}{10}

\bibitem{AVW02}
A.~Arnold, A.~Vincent, and I.~Walukiewicz.
\newblock Games for synthesis of controllers with partial observation.
\newblock {\em Theoretical Computer Science}, 303(1):7--34, 2003.

\bibitem{FinSch05}
B.~Finkbeiner and S.~Schewe.
\newblock Uniform distributed synthesis.
\newblock In {\em Proc.~LICS} 2005.

\bibitem{GLZ04}
P.~Gastin, B.~Lerman, and M.~Zeitoun.
\newblock Distributed games with causal memory are decidable for
  series-parallel systems.
\newblock In {\em Proc.~FSTTCS} 2004.

\bibitem{gs13tocl}
P.~Gastin and N.~Sznajder.
\newblock Fair synthesis for asynchronous distributed systems.
\newblock {\em ACM Transactions on Computational Logic}, 14(2): 9, 2013.

\bibitem{GGMW13}
B.~Genest, H.~Gimbert, A.~Muscholl, and I.~Walukiewicz.
\newblock Asynchronous games over tree architectures.
\newblock In {\em Proc.~ICALP} 2013.

\bibitem{gpq12}
S.~Graf, D.~Peled, and S.~Quinton.
\newblock Achieving distributed control through model checking.
\newblock {\em Formal Methods in System Design}, 40(2):263--281, 2012.

\bibitem{gw13}
J.~Gutierrez and G.~Winskel.
\newblock Borel determinacy of concurrent games.
\newblock In {\em Proc.~CONCUR} 2013.

\bibitem{KV01}
O.~Kupferman and M.~Vardi.
\newblock Synthesizing distributed systems.
\newblock In {\em Proc.~LICS} 2001.

\bibitem{MadThiag01}
P.~Madhusudan and P.~Thiagarajan.
\newblock Distributed control and synthesis for local specifications.
\newblock In {\em Proc.~ICALP} 2001.

\bibitem{MTY05}
P.~Madhusudan, P.~S. Thiagarajan, and S.~Yang.
\newblock The {MSO} theory of connectedly communicating processes.
\newblock In {\em Proc.~FSTTCS} 2005.

\bibitem{mel06}
P.-A. Melli\`es.
\newblock Asynchronous games 2: {T}he true concurrency of innocence.
\newblock {\em TCS}, 358(2-3):200--228, 2006.


\bibitem{ms97}
M.~Mukund and M.~A. Sohoni.
\newblock {Keeping Track of the Latest Gossip in a Distributed System}.
\newblock {\em Distributed Computing}, 10(3):137--148, 1997.

\bibitem{ms13}
A.~Muscholl and S.~Schewe.
\newblock Unlimited decidability of distributed synthesis with limited missing
  knowledge.
\newblock In {\em Proc.~MFCS} 2013.

\bibitem{PR90}
A.~Pnueli and R.~Rosner.
\newblock Distributed reactive systems are hard to synthesize.
\newblock In {\em Proc.~FOCS} 1990.

\bibitem{RW89}
P.~J.~G. Ramadge and W.~M. Wonham.
\newblock The control of discrete event systems.
\newblock {\em Proc.~of the IEEE}, 77(2):81--98, 1989.

\bibitem{wal01ic}
I.~Walukiewicz.
\newblock Pushdown processes: Games and model checking.
\newblock {\em Inf.~Comput.}, 164(2):234--263, 2001.

\bibitem{zie87}
W.~Zielonka.
\newblock Notes on finite asynchronous automata.
\newblock {\em RAIRO--Theoretical Informatics and Applications}, 21:99--135,
  1987.

\end{thebibliography}

\newpage




\end{document}
