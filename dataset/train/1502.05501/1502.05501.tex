\documentclass[a4paper]{article}



\usepackage{paralist}
\usepackage{enumerate}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{latexsym}
\usepackage{stmaryrd}

\newcommand{\mGnd}{\operatorname{gnd}} \newcommand{\mLVar}{\operatorname{lvar}} \newcommand{\mRVar}{\operatorname{rvar}} \newcommand{\mDmn}{\operatorname{dom}} \newcommand{\mRng}{\operatorname{rng}} \newcommand{\mMGU}{\operatorname{mgu}} \newcommand{\mDef}{\operatorname{def}} \newcommand{\mDomain}{\mathcal{D}} \newcommand{\mVar}{\operatorname{var}} 
\newcommand{\mEPR}{Bernays-Sch\"onfinkel}
\newcommand{\mEPRs}{BS}

\usepackage{alltt}
\usepackage[ruled, lined, linesnumbered]{algorithm2e}

\newcommand{\startproof}{{\bf Proof:~}}
\newcommand{\finishproof}{{\bf Qed.}}
\newcommand{\leavesome}{\6 pt]}
\newtheorem{defi}{Definition}[section]
\newtheorem{remark}[defi]{Remark}
\newtheorem{theo}[defi]{Theorem}
\newtheorem{prop}[defi]{Proposition}
\newtheorem{coro}[defi]{Corollary}
\newtheorem{example}[defi]{Example}
\newtheorem{lemm}[defi]{Lemma}

\newcommand\exClauseNo[1]{C_{#1}} \newcommand{\rst}[1]{|_{#1}} 
\newcommand{\ie}{i.e.\ }
\newcommand{\eg}{e.g.\ }
\newcommand{\etc}{etc.\ }
\newcommand{\wrt}{w.r.t.\ }
% \usepackage{authblk}
\renewcommand\Affilfont{\normalfont\small}
\begin{document}
\title{NRCL - A Model Building Approach to\\ the {\mEPR} Fragment\\ (Full Paper)}
\setcounter{Maxaffil}{3}
\author[1,2,3]{G\'abor Alagi}
\author[3]{Christoph Weidenbach}
\affil[1]{
	Saarbr\"ucken Graduate School of Computer Science, Germany
}
\affil[2]{
	Saarland University, 
	Saarbr\"ucken, Germany
}
\affil[3]{
  Max-Planck-Institut f\"ur Informatik,
  Saarbr\"ucken, Germany
}
\affil[ ]{
	\textbf{\{galagi, weidenbach\}@mpi-inf.mpg.de}
}

\date{}

\clearpage

\maketitle

\begin{abstract}
We combine constrained literals for model representation 
with key concepts from first-order superposition
and propositional conflict-driven clause learning (CDCL)
to create the new calculus \emph{Non-Redundant Clause Learning} 
(NRCL) deciding the {\mEPR} fragment. 
Our calculus uses first-order literals constrained by disequations between tuples of terms 
for compact model representation.
From superposition, NRCL inherits the abstract redundancy criterion and 
the monotone model operator.
CDCL adds the dynamic, conflict-driven search for an 
atom ordering inducing a model. 
As a result, in NRCL a false clause can
be found effectively modulo the current model candidate. It guides
the derivation of a first-order ordered resolvent that is never redundant.
Similar to 1UIP-learning in CDCL, the learned resolvent induces
backtracking and, by blocking the previous conflict state via propagation, 
it enforces progress towards finding a model or a refutation.
The non-redundancy result also implies that only finitely many clauses
can be generated by NRCL on the {\mEPR} fragment, which 
serves as an argument for termination.
\end{abstract}
\section{Introduction}
The {\mEPR} fragment, also called Effectively Propositional Logic, or BS (or EPR) for short, 
is an important fragment of classic first-order logic, where only constants are allowed as
function symbols in the clause normal form. 

This decidable and NEXPTIME-complete fragment has many applications,
including knowledge representation~\cite{HustadtMS04} and ontological reasoning~\cite{SudaWeidenbachWischnewskiIJCAR10},
hardware verification~\cite{KhasidashviliKV09}\cite{PerezV07}\cite{EmmerKKV10}, logic programming~\cite{EiterFT05}, and planning~\cite{PerezV13}.

Over the years a number of calculi have attempted to provide an efficient 
solution for {\mEPRs} problems. 
These approaches range from the early \emph{SEM} and \emph{Mace} systems~\cite{Tammet03finitemodel} to the recent state-of-the-art solvers 
like \emph{iProver}~\cite{InstGen03} and \emph{Darwin}~\cite{ModelEvolution03}, but even general purpose first-order theorem provers 
provide specialized techniques for {\mEPRs} problems, 
like \emph{generalisation} in \emph{Vampire}~\cite{Generalization08}, or 
specialized splitting techniques for \emph{SPASS} introduced in~\cite{HillenbrandWeidenbach13} and \cite{FietzkeW09}. 

In this paper, we introduce a new calculus for solving {\mEPRs} problems with 
iterative model building.
Our approach builds first-order candidate models instead of approximations, uses 
constrained literals for model representation, and learns new non-redundant clauses to guide the search.

Our calculus, called NRCL or \emph{Non-Redundant Clause Learning}, 
shares many principles with propositional SAT solving and superposition.
For a detailed introduction to \emph{conflict-driven clause learning (CDCL)}, 
see the early article \cite{SilvaS96}, or the more recent handbook \cite{SATHandbook}.
The interested reader can get a thorough overview of superposition in the articles 
\cite{BachmairGLS92}\cite{BachmairGLS95}\cite{Weidenbach01}\cite{BachmairG01}\cite{NieuwenhuisR01}.

Compared to the existing approaches, we use a more expressive and implicit constraint language,
our search is guided by backjumping and learning non-redundant clauses, and 
our model representation is more compact, in general.
In addition, compared to all existing approaches, we can prove that all our learned clauses are non-redundant
and this way, for the first time, establish a calculus that combines the search with respect to a dynamically
changing (partial) model with an overall notion of redundancy. 
For a more detailed comparison, see Section 9.

In the rest of the paper, we first introduce some basic definitions and notions in Section 2, followed by 
a description of our calculus in Section 3.
Section 4 establishes its soundness, while, after introducing some regularity conditions in Section 5, we 
provide our key result, namely non-redundant clause learning, in Section 6. 
We then prove termination in Section 7.

In Section 8, we specify some details on handling constraints, and basic heuristics for a future implementation.
We compare our calculus to the existing literature in more details in Section 9.
Finally, Section 10 provides a summary and outlines future work.
% \section{Preliminaries}

\subsection{Basic Definitions}

We assume the reader is familiar with first-order logic, its syntax, and its semantics. 
In particular, we handle the {\mEPR} fragment, or {\mEPRs} for short
In this fragment the only functions allowed in the clause normal form are finitely many constants.
We denote the finite \emph{signature} by , the \emph{set of predicate symbols} by , 
and call the finite set of constants the \emph{domain}, denoted by .  



We denote the set of all first-order atoms over a signature  and a possibly infinite set of variables  by 
. 
In particular the set of ground atoms is denoted by , a short-hand for .
For a literal ,  denotes the atom contained by .
In general, we denote the ground instances of an \emph{expression} - a term, literal, or clause - 
 over the domain  by the notation . 

W.l.o.g., we assume that each independent expression is variable disjoint, and we call a variable \emph{fresh} if it does not occur in any expression - e.g.\ clause or clause set - of the current context. 

We consider \emph{substitutions} in the usual way, and for a substitution ,  denotes the \emph{domain} of , i.e.\
the finite set of variables with , and  denotes the \emph{range} of , i.e.\
the image of  w.r.t.\ .

We assume the reader is familiar with \emph{most general unifiers}, 
and  is used to denote the result of unifying two or more
expressions or substitutions.
We use the short-hand  to both state the existence of a most general unifier and bind 
 to one such substitution.



For expressions or substitutions , , we say  \emph{can be matched against} , or  \emph{is more general than} , and 
write , if and only if there is a substitution  such that . 

We represent a first-order interpretation  with the set .
We define \emph{satisfiability} and \emph{semantic consequence} as usual.

In particular, we consider the problem of deciding whether a finite clause set  over a {\mEPRs} language  without equality is satisfiable. 
This problem is known to be NEXPTIME-complete~\cite{Lewis80}.

\subsection{Constraints and Constrained Literals}
Next, we provide details about the constraint language we use. Our constraints are equivalent with \emph{implicit generalizations}, a constraint language 
for representing terms and models with exceptions. 
It has applications in inductive learning, logic programming and term rewriting. 
For more details see e.g.\ 
\cite{Comon91}\cite{LassezM87}.

The name \emph{dismatching constraints} was chosen in the spirit of \emph{iProver}\cite{InstaGen13}, although for our purposes checking satisfiability 
has to be carried out over the ground instances and thus, the linear-time algorithm of \emph{iProver} based on matching is not applicable.

While implicit generalizations maintain a list of literals with fresh variables representing exceptions for the literal constrained, 
dismatching constraints extract the arguments of the literals and represent the restrictions as conjunctions of disequations to 
allow more simplification and a more compact representation.
In particular, we maintain a strict normal form, which already assumes most inexpensive simplifications.

We chose dismatching constraints for a balance between expressiveness and simplicity, for the existing literature, and for compactness. 
However, NRCL is compatible with any constraint language allowing the operations discussed in the next subsection.

\begin{defi}[Dismatching Constraint]\label{dmcDef}
A \emph{dismatching constraint}  is of the form

where  is a finite set of indices, and for each ,  and  are tuples of terms of the same dimension. 

Furthermore, we assume that all the left-hand side variables in  differ from any right-hand side variable, 
and for each ,  and   are variable disjoint whenever  differs from .

We further extend the set of constraints with the constants ,  representing the tautological and the unsatisfiable constraint, respectively.

Finally, an \emph{atomic constraint}  occurring in  is also called \emph{a subconstraint of }.
\end{defi}
\noindent
To enforce a normal form, we make further assumptions below.
\begin{defi}[Normal Form]
We say a constraint  is \emph{in normal form} iff
the following conditions hold:
\begin{enumerate}[(1)]
	\item each  contains only variables
	\item no variable occurs more than once in any left-hand side 
\end{enumerate}
\end{defi}

A simple consequence of the normal form is that the two sides of any subconstraint  are 
always unifiable, and the \emph{induced substitution}  is always well-defined and 
matches the left-hand side against the right-hand side.

\begin{defi}[Induced Substitutions]
The \emph{set of induced substitutions} of a dismatching constraint  in normal form is the set given by

if . For , we define 
it as the set containing only the identity, and for  as the empty set.
\end{defi}

We define  and  as the set of the left-hand side and right-hand side variables of some dismatching constraint , respectively. 
Then the semantics for our constraints can be given as below.

\begin{defi}
A \emph{solution} of a constraint  over some variable set , which contains  but contains no variable from , 
is a ground substitution  such that 
no  can be matched against the respective , i.e.\
no  is an instance of the respective .

In particular, if , any such grounding substitution is a solution, and  has no solution at all.
\end{defi}

\noindent
As usual,  is called \emph{satisfiable} and \emph{unsatisfiable} if it has a solution or no solution, respectively. 
We note that the notion of satisfiability depends only on .

\begin{example} Consider the domain  and the constraint 

Then  is satisfiable and the ground substitution  
is the only solution of  (over ), since  can only be  and the first 
subconstraint represents .
\end{example}

\begin{remark}\label{a-inducedsubst-remark}
It can be shown that a ground substitution  with  
is not a solution of  
if and only if there is an induced substitution  which is more general than .
\end{remark}

\begin{defi}
Let  and  denote constraints for which both
\begin{itemize}
\item , and
\item  
\end{itemize}
hold.
Such constraints are called \emph{equivalent} iff their sets of solutions coincide for any  such that 
, and both
 and 
.
\end{defi}

\subsubsection*{Normal Form Transformation}
Next, we show that any dismatching constraint of the form  
can be normalized in polynomial time. This can be achieved with the rule set below, given as rewriting rules over the subconstraints.

\begin{enumerate}
	\item , 
		where 
	\item , 
		where 
	\item , 
		where , 
	\item 
	\item , 
		if 
	\item , 
		if 
	\item , 
		if  can be matched against 
	\item ,
		if , and  can be matched against  
		
\end{enumerate}
Where the last rule is considered modulo permutations of positions corresponding to the -partitionings.
\begin{example} Let us normalize the following constraint: 

For the first subconstraint we get

and for the second one

Thus, the normalized constraint is

\end{example}
Applying these rules together with the usual rules for conjunction and the constants 
\begin{enumerate}
	\item preserves the variable disjointness conditions of Definition~\ref{dmcDef}
	\item preserves solutions, i.e.\ the left-hand side and right-hand side constraints are equivalent
	\item transforms  into normal form in polynomial time \end{enumerate}
We note that the rules (7) and (8) are optional, and that (7) is a special case of (8).


Therefore, w.l.o.g. we assume that the constraints are always in normal form, and 
the result of any operation is transformed into normal form without explicitly expressing it. 
We also express it by using the notation  
for dismatching constraints in the rest of the paper.
\subsubsection*{Constrained Literals}
Next, we define literals constrained with dismatching constraints in normal form, and give their semantics as sets of 
ground literals.

\begin{defi}[Constrained Literal]
We call the pair  of a literal  and a dismatching constraint  such that both
 and 
 hold
a \emph{constrained literal}.

The semantics of constrained literals is given by the following definition of the \emph{set of covered literals}:

where .
A ground literal  is \emph{covered by} a constrained literal  iff .

We say that a constrained literal  is \emph{empty} if it covers no ground literals, i.e.\
 is empty.
\end{defi}

\indent
It is easy to see that  is empty if and only if  is unsatisfiable, and that given a solution  of  over 
, for any extension  of  to , 
 holds.

\begin{example} Let .
Then the set of covered literals over the domain  is

and if we take  instead, it is

\end{example}
\noindent
In the rest of the paper we make some further assumptions as common in automated reasoning:
\begin{enumerate} 
	\item Different constrained literals are variable disjoint, unless stated otherwise.
	\item Apart from normal form transformations, for any substitution  applied to a constrained literal ,
	the following always hold unless stated otherwise:
	\begin{itemize}
		\item 
		\item 
	\end{itemize}
\end{enumerate}
\subsubsection*{Constrained Clauses}
Occasionally, we have to represent a collection of ground clauses by a constrained clause . 
Extending the notations and semantics for constrained literals to constrained clauses is straightforward. 

Furthermore, we use the notation  for the constrained clause , whenever we 
wish to syntactically distinguish  and .

We only note that during resolving away literals from , we might get to a state where 
 contains variables not occurring in . See the constrained unit clause

from Example~\ref{freeVarEx} for a demonstration.

For semantic purposes, these \emph{free variables} are considered existential variables.
We assume that such variables are eliminated through instantiation, see Section 8 for further details. 

\subsection{Operations on Constrained Literals}
In the context of our calculus, three operations are of significance: conjunction, difference, 
and checking whether a constrained literal is empty. 



In the literature checking emptiness also relates to \emph{sufficient completeness} and 
\emph{negation elimination}
and it is known to be a co-NP-complete problem~\cite{LassezM87} in the case of finitely many function symbols and infinite Herbrand universe.

This complexity result also holds for our setting - 
one might take a binary domain with  and , and then each atomic constraint with constant right-hand side 
can be seen as clauses with the left-hand side variables as propositional variables, 
and the emptiness of the whole constraint as the unsatisfiability of this clause set.

In this section, we propose an enumeration-based algorithm to test emptiness as an alternative
to relying on external CSP and CDCL solvers.

\subsubsection*{Conjunction}

For two constrained literals ,  with the same polarity and predicate symbol, we look for a constrained literal  for which

holds. If the two literals are unifiable,   
such a literal exists. Otherwise, any empty constrained literal can be chosen.

\begin{defi}[Conjunction] 
Let as the define and denote \emph{the conjunction of two constrained literals , } as

if . If the literals are not unifiable, we define it as the empty .
\end{defi}

\noindent
This definition is sound, i.e.\

\begin{lemm} For any unifiable constrained literals , ,

holds, where .
\end{lemm}

\noindent
\startproof 

(): Consider a ground literal from , and w.l.o.g. assume it has the form . 
Then  holds for both .

Thus,  for some substitution .  Since ,  must be true ().
But then , and  both hold.

(): Now, assume that  is a literal from .
Then, since  is the most general unifier, we know that  hold for both .
Furthermore,  is true (), and thus,  and 
.
\finishproof\leaveabit\noindent
We note that the case when no unifier exists is trivial.

\begin{example} Consider the following constrained literals
	\begin{itemize}
		\item 
		\item 
	\end{itemize}
Then according to the definition above

which can be simplified to

This expression is empty over , and covers exactly the atom  over .
\end{example}

\subsubsection*{Difference}

The  \emph{difference}, or \emph{relative difference},  of two constrained literals ,  satisfies 


Again, if the two literals are unifiable, such a  does exist for any finite domain - in the worst case we just add ground constraints to rule out the disallowed atoms.
However, this operation might increase the size of  exponentially, as demonstrated by the example below.

\begin{example}\label{a-dmcDiffEx1}
Consider the difference 

where . 
If , we might get the still simple expression 

However, if , the best we can get is 

It is easy to see that in general, if  with , and , 
the size of the resulting constraint is .
\end{example}

Alternatively, one might take a set of disjoint constrained literals describing the difference as follows. 
First, take the simpler case when  and   are the same literal , and consider the difference . 
Assume , , 
and  is the set of induced substitutions for .
Then, the constrained literal set 

describes the difference, i.e.\

\begin{lemm}

\end{lemm}

\noindent
\startproof 

(): Assume . 
Since , a subconstraint  must be violated, i.e.\ 
for some , . 

Then, by the earlier Remark~\ref{a-inducedsubst-remark},  where  is the corresponding induced substitution. Thus,
 for some substitution . 
Finally, since ,  must hold.

(): Now, assume  
for some  and grounding substitution .
Then, we know that , and that  since .
Thus, .
\finishproof\\{ (L\sigma_i; \pi_1\sigma_i \land \eta_1\sigma_i \land \eta_2\sigma_i \land \dots \land \eta_{i-1}\sigma_i)~|~i = 1, \dots, l\}6 pt]
\indent
We also note that the above manipulations preserve the variable disjointness of the left-hand and right-hand sides.

\begin{example}
Carrying on with example~\ref{a-dmcDiffEx1} above, we have ,  and , which gives

as a result.
\end{example}

\indent
Let  denote the size of . 
Then, this operation introduces  atoms with a maximal constraint size of  in general. 
This gives a total size of  where .
Clearly, it is independent of the domain size.

\begin{lemm}
Finally, if , but  exists (otherwise the difference is ), and  denotes the argument of the top symbol in , we get the desired set by adding 

to the set  
where the variable renaming  introduces fresh variables for 
the variables in .
\end{lemm}

\startproof The literals in  can be divided into two disjoint group based on whether they are instances of  or not.

Those that are no instances of  are covered by the proposed constrained literal . Clearly, 
each such literal is in the difference.

The common instances are covered by . From these literals we have to remove those which are covered by  as well. 
Clearly, it is enough to compute the difference .

The resulting set together with  covers exactly the elements of the difference.
\finishproof\I_{\Gamma} = \bigcup_{(L;\pi) \in \Gamma^+}~\mGnd(L;\pi)\Phi_{\Gamma} = |\Gamma| = \{(|L|; \pi)~|~(L; \pi) \in \Gamma\}\mDef(P) = 
\left\{
	\begin{array}{ll}
		(L;\pi)  & \mbox{if } (L;\pi) \in \Gamma\text{~and~ defines } \\
		\bot & \mbox{if no such  exists }
	\end{array}
\right.
\Gamma = \Gamma_1, (L_1; \pi_1)^{\alpha_1}, \Gamma_2, (L_2; \pi_2)^{\alpha_2}, \Gamma_3\text{N} = \{ C: \neg P(x) \lor \neg P(y) \lor Q(x,y), \dots \}(\Gamma; \text{N}; \text{U}; k; s)(\epsilon; \text{N}; \emptyset; 0; \top)(\Gamma; \text{N}; \text{U}; k; \top) \Rightarrow
    (\Gamma, (L\cdot\sigma;\pi)^{C \lor L}; \text{N}; \text{U}; k; \top)(\Gamma; \text{N}; \text{U}; 1; \top)\Gamma = (P(x,x); \top)^{C_1}, (Q(a,x); \top)^{C_2}, (\neg P(x,y); (x,y) \ne (v,v))^1(\Gamma, (R(y)\cdot\{x \gets a\}; y \ne b)^C; \text{N}; \text{U}; 1; \top)(\Gamma; \text{N}; \text{U}; k; \top) \Rightarrow
    (\Gamma, (L; \pi)^{k+1}; \text{N}; \text{U}; k+1; \top)\text{N} = \{P(x,x), Q(x,a), \neg Q(x,y) \lor P(x,y) \lor P(x,y) \}(\neg Q(x,y) \lor P(x,y) \lor P(x,y); \{y \gets a\}; x \ne a)(\Gamma; \text{N}; \text{U}; k; \top) \Rightarrow
    (\Gamma; \text{N}; \text{U}; k; (C; \sigma; \pi))
	\text{N} =&~\{~\exClauseNo{1}: \neg P(c), \exClauseNo{2}: \neg P(x) \lor \neg P(y) \lor Q(x,y), \\
								   &~~~\exClauseNo{3}: \neg P(y) \lor \neg Q(a,y), \exClauseNo{4}: \neg Q(x,b)\lor\neg P(x)~\}\\
	\Gamma =&~(\neg P(c); \top)^{\exClauseNo{1}}, (P(x); x \ne c)^1, (\neg Q(a,y); y \ne c)^{\exClauseNo{3}}
(\Gamma; \text{N}; \emptyset; 1; \top) 
\stackrel{Conflict (\exClauseNo{2})}{\Rightarrow} 
(\Gamma; \text{N}; \emptyset; 1; (\neg P(x) \lor \neg P(y) \lor Q(x,y); \{x \gets a\}; y \ne c)) 
(\Gamma; \text{N}; \text{U}; k; \top) \Rightarrow
    (\Gamma; \text{N}; \text{U}; -1; \top)(\Gamma; \text{N}; \text{U}; k; \top) \Rightarrow
    (\Gamma; \text{N}; \text{U}; 0; \bot)(\Gamma, (L'\cdot\sigma'; \pi')^{C'}; \text{N}; \text{U}; k; (C; \sigma; \pi)) \Rightarrow
    (\Gamma; \text{N}; \text{U}; k; (C; \sigma; \pi))(\Gamma, \ell; \text{N}; \text{U}; k; (C \lor L_1 \lor L_2; \sigma; \pi)) \Rightarrow
    (\Gamma, \ell; \text{N}; \text{U}; k; ((C \lor L_1)\eta_0; \sigma^*; \pi\eta))(\Gamma_1, \Gamma_2; \text{N}; \text{U}; k; (C; \sigma; \pi)) \Rightarrow
    (\Gamma_1; \text{N}; \text{U} \cup \{C\}; k'; \top)\text{N} = \{ 
		\exClauseNo{1}:~R(x,x), 
		\exClauseNo{2}:~P(x) \lor \neg Q(x,y),
		\exClauseNo{3}:~R(x,y) \lor Q(x,y) \lor P(x) \lor P(y)
\}\Gamma' = (R(x,x); \top)^{\exClauseNo{1}}, (\neg R(x,y); (x,y) \ne (v,v))^1, (\neg P(x); \top)^2
(\Gamma; \text{N}; \emptyset; 2; (R(x,y) \lor Q(x,y) \lor P(x) \lor P(y); \emptyset; (x,y) \ne (v,v)))
\stackrel{Resolve}{\Rightarrow}

(\Gamma; \text{N}; \emptyset; 2; (R(x,y) \lor P(x) \lor P(x) \lor P(y); \emptyset; (x,y) \ne (v,v)))
\stackrel{Skip}{\Rightarrow}

(\Gamma'; \text{N}; \emptyset; 2; (R(x,y) \lor P(x) \lor P(x) \lor P(y); \emptyset; (x,y) \ne (v,v)))
\stackrel{Factorize}{\Rightarrow}

(\Gamma'; \text{N}; \emptyset; 2; (R(x,y) \lor P(x) \lor P(y); \emptyset; (x,y) \ne (v,v)))
\stackrel{Backjump(3)}{\Rightarrow}

((R(x,x); \top)^{\exClauseNo{1}}, (\neg R(x,y); (x,y) \ne (v,v))^1; \text{N}; \{R(x,y) \lor P(x) \lor P(y)\}; 1; \top)
\Gamma = (P(x,x); \top)^{P(x,x)}, (Q(x,a); \top)^{Q(x,a)}(\Gamma', \ell^{k}; \text{N'}; \text{U'}; k; (\neg Q(x,y) \lor P(x,y) \lor P(x',y); \{y \gets a\}; x \ne a \land x' \ne a))3 pt]\centerline{\begin{tabular}{rlll}
 & ,  & \\
& ,  &  \\
\end{tabular}}\3 pt]\centerline{}\3 pt]\centerline{}\3 pt]\centerline{}\3 pt]\centerline{}\3 pt]
Let .
\3 pt]\centerline{}\3 pt]\centerline{}\3 pt]\centerline{}\3 pt]\centerline{}\3 pt]\centerline{}\3 pt]\centerline{}\3 pt]\centerline{}\3 pt]\centerline{}
\end{example}  \section{Soundness}

Now, we show soundness. The following state invariant defines a consistency notion for states.

\begin{defi}\label{sndstatedef}
A state  is \emph{sound} if and only if the followings hold:
	\begin{enumerate}
		\item  is a consistent sequence of constrained literals
		\item  is \emph{well-formed}, i.e.\
			\begin{enumerate}
				\item if  then  contains exactly  decisions
				\item for each  from , there is a unique 
				\item the decisions occur in  in the order of their levels
				\item for each decomposition ;  satisfies the conditions of \emph{Decide} w.r.t.\
					, , and 
				\item for each decomposition ; 
								 is false under , 
								and  satisfies the conditions for \emph{Propagate} w.r.t.\
								 and 
			\end{enumerate}	
		\item 
		\item  implies 
		\item  implies 
		\item if  then 
			       is false under , , and  is not empty.
	\end{enumerate}
	A rule is called \emph{sound} iff it preserves the soundness of its left-hand side state.
\end{defi}

It is easy to see that the initial state  is always sound.
Furthermore, soundness is an invariant, since each rule preserves this property, as proven below.

\begin{theo}\label{sndrulesTheo}
The rules of NRCL are sound.
\end{theo}
\noindent\startproof
The soundness of \emph{Propagate}, \emph{Decide}, \emph{Conflict}, and 
the terminal rules \emph{Failure} and \emph{Success} is straightforward 
to prove from the definitions themselves, and therefore, we entrust it to the reader.

In the case of \emph{Skip}, dropping the right-most literal  from  does preserve 
the well-formedness and consistency properties of . 
 remains unchanged and the rest 
of the conditions are irrelevant in this case, except for the last one.

Now, assume the last property does not hold after applying \emph{Skip}. It is only possible if some 
ground clause  from  were false under , but is undefined
under . Thus,  must have made it false, and therefore, for some  and , 
 and  is true. 

Let  be the literal in  corresponding to . Then, the most general unifier  of  and  
must exist and , which is therefore not empty. This violates the 
preconditions of \emph{Skip}, a contradiction.

For \emph{Resolve}, it is enough to see that the new clause is a consequence of , and the new 
state indicator  is unsatisfiable under , using the notations of 
the definition for \emph{Resolve}.

The first claim follows from the soundness of the left-hand side and from the soundness of resolution.
As for the second claim, we make the following observations:
\begin{itemize}
  \item 
	\item Each instance from  is false under the current trail, as per the well-formedness conditions for derived literals.
	\item Each instance from  is false under the trail by the soundness of the left-hand side.
\end{itemize}
From these it follows that each ground clause from  is false under the current trail.

The soundness of \emph{Factorize} can be proven analogously, and the proof for \emph{Backjump} is straightforward. 
We entrust them to the reader.
\finishproof\leaveabit
\noindent
Next, we define \emph{runs}, i.e.\ sound derivations in our calculus.

\begin{defi}
A \emph{run} (from a clause set ) is a sequence of states such that each subsequent state is derived with a rule from the previous one, and the initial state is a
sound state (with  as the original clause set).
\end{defi}

A direct consequence of Theorem~\ref{sndrulesTheo} is that each state in a run is sound, and in particular, for each conflict resolution state 
, each ground clause from  is false w.r.t.\ .



\begin{theo}[Soundness]\label{sndRunTheo}
The calculus NRCL is sound, i.e.\ if a run terminates with the \emph{Failure}, or \emph{Success} rules, 
then the starting set  is unsatisfiable, and satisfiable, respectively.
Furthermore, in the latter case the trail upon termination defines a model of .
\end{theo}
\noindent\startproof
It follows immediately from the definitions and Theorem~\ref{sndrulesTheo}.
\finishproof
% \section{Regular Runs}
In this section, we define a strategy for NRCL in the form of \emph{regular runs}, which is sufficient to prove both
non-redundant clause learning, and termination in the later sections. 

\begin{defi}\label{regStateDef}
A sound state  is \emph{regular} iff the following hold:
	\begin{itemize}
		\item If , then no clause from  is false w.r.t.\ .
		\item For all decomposition  with decision , \emph{Propagate} is exhausted w.r.t.\
			 and .
	\end{itemize}
\end{defi}
We note that the last assignment on the trail might still make some clauses false, and the initial state  is always regular.
\begin{defi}\label{regRunDef}
We call a run \emph{regular} iff the following holds:
	\begin{itemize}
		\item The starting state is regular.
		\item During conflict search, rules are always applied in this order exhaustively: terminal rules, \emph{Conflict}, \emph{Propagate}, \emph{Decide}.
		(Or \emph{Failure}, \emph{Conflict}, \emph{Propagate}, \emph{Decide}, \emph{Success}, if we test success through exhausted conflict search.)
		\item In conflict resolution \emph{Backjump} is always applied as soon as possible, and it backtracks to a regular state.
	\end{itemize}
\end{defi}
\begin{lemm} Regular runs preserve regularity, i.e.\ every state in a regular run is regular.
\end{lemm}
\startproof
It follows from the definitions, we only note that backjumping to a state which is regular w.r.t.\
the new learned clause set as well is always possible.
If nothing else, the empty trail is always a valid choice. 
\finishproof\leaveabit
\noindent
The backtrack-level proposed in the proof above is not practical, of course.
For more details on a more accurate backjumping to a regular state see Section 8.\leaveabit\noindent
Below, we show some useful properties of regular runs.

\begin{lemm}\label{lemmRegProps} In a regular run the following hold:
  \begin{enumerate}[(1)]
		\item For any deduced literal  of level  on the trail with , each ground clause in  contains at least two literals of level .
		\item If  represents false clauses in some conflict state, then each ground clause in  contains at least two top-level literals, if 
		 the state is the result of an application of \emph{Conflict}, and at least one top-level literal otherwise.
		\item If a clause  is learned according to the case \emph{Backjump}-, then it blocks the former top-level decision.
  \end{enumerate}
\end{lemm}
\noindent
\startproof
First, assume  is a deduced literal and it was implied by  w.r.t.\ 
 which was the current trail before the corresponding application of \emph{Propagate}. 

Let  be the level of the right-most decision in , and  a ground clause from  
such that  corresponds to . 
Then  is of level , of course. 

Furthermore, if no other literal in  is of level ,  would have implied  
before the last decision, which contradicts the exhaustive application of \emph{Propagate}.
Thus,  must contain at least two literals of level .

Second, since conflicts are found immediately, any conflicting non-empty ground clause  must contain at least one top-level literal. 
A conflicting ground clause with a single top-level literal, however, would contradict the exhaustive application of \emph{Propagate}.
Thus, after applying \emph{Conflict}, all ground clause in the conflict-set contains at least two top-level literals. 
It only remains to show that the rules \emph{Resolve}, \emph{Skip}, and \emph{Factorize} 
preserve the weaker property of having at least one top-level literals. Obviously, e.g.\ \emph{Factorize} can break the stronger property.

We only prove this for \emph{Resolve}, the rest can be shown similarly. 
Assume that at an application of \emph{Resolve}   is the involved deduced literal, 
 represents the false clauses before, and
 after applying the rule, where 
,
, and  such that .

It is easy to see that for every ground clause 

there are corresponding ground clauses  and 
 
whose resolvent is exactly , 
and ,  correspond to  and , respectively, and .

Then, by the first claim of this lemma,  must contain at least one top-level literals, and so does .

Finally, assume  is learned when case  of \emph{Backjump} is applied to the state

Now, let  an arbitrary ground clause, 
where , \dots,  denotes the top-level literals of the clause.

By (2), , and, since  has no assertive clause, even  must hold. 
We also know that \emph{Factorize} was not applicable, thus, for any  from , 
 holds.
Thus,  blocks the decision  w.r.t.\
, as witnessed by the ground clause above.
\finishproof\leaveabit
\indent
It can be also shown that if there is an immediate conflict after a decision in a regular run, \emph{Factorize} is applied next.

\begin{lemm}\label{lemmImmConfFact} Assume 

is a valid subderivation in a regular run. 
Then \emph{Factorize}, and only \emph{Factorize}, is applicable to the conflict state .
\end{lemm}
\noindent\startproof
Obviously, \emph{Resolve} and \emph{Skip} cannot be applied. 
Furthermore, if case \emph{Backjump}- were applicable, 
there would be a ground clause in  
blocking the last decision, a contradiction. 

Also, there cannot be any ground clause in  with a single top-level literal, since otherwise \emph{Propagate} would not have been applied exhaustively 
before the decision. And  cannot hold either, as otherwise \emph{Failure} should have been applied earlier. 
Thus, the other cases of \emph{Backjump} do not apply either.

Finally, let  a ground clause from . 
This clause exists, and must contain at least two top-level literals, see Lemma~\ref{lemmRegProps}(2). 
These literals are falsified by the last decision, and do not block the decision. 

Let  two such literals and . 
Then these literals are equal, and the corresponding literals ,  in  
are unifiable. 

Then \emph{Factorize} is applicable unifying  and , and  can be used to prove the non-emptiness condition.
\finishproof
% \section{Redundancy}

We define redundancy w.r.t.\ 
the induced ordering  in the standard way:
\begin{defi}\label{a-redundancyDefs}
A ground clause  is \emph{redundant w.r.t.\
a ground clause set  (and )} iff

A first-order clause  is \emph{redundant w.r.t.\
the first-order clause set  (and )} iff

If redundancy does not hold, we call the corresponding clause \emph{non-redundant}, or \emph{irredundant}.
\end{defi}
\subsection{Learning Non-Redundant Clauses}
First, we show that each learned clause is non-redundant w.r.t.\
the current clause set and induced ordering.

The most important consequence of this theorem that checking the learned clauses for 
redundancy criterions which are independent of the concrete induced orderings can be spared. 

Such admissible criterions include subsumption, subsumption resolution and tautologies, as it is shown in the next subsection. 

\begin{theo}[Non-redundant Clause Learning]\label{freshnessTheo}
Let  denote the trail at a conflict in a regular run,  the induced ordering, and 
assume the clause  is learned via the \emph{Backjump} rule, and 
let  and  be the starting clause set and the set of learned clauses before the conflict, respectively.
\leaveabit
Then,  is not redundant w.r.t.\
 and .
\end{theo}
\noindent
\startproof
Assume the first and last state in conflict resolution is 

By soundness,  
and each  is false w.r.t.\
both  and .

Now let  and assume there is an 
 such that  and .
Because of , each  has a defined truth-value w.r.t.\
. If all  is true, then, by , so is , a contradiction.

Thus, let  arbitrary such that  is false under .
We distinguish two cases whether  is a strict subset of , or equal to it.

First, if , at least one \emph{Skip} had to be used,  and  contains no literal covered by the 
right-most literal of . Neither does , since . But then,  has a defined truth-value and it 
can only be true, as otherwise an earlier conflict detection would have been possible. A contradiction.

Second, assume . 
If the right-most literal is a decision, no false clause from  blocks this decision, and  
\emph{Factorize} had to be applied several times followed by an application of case  of \emph{Backjump}. 
(See also Lemma~\ref{lemmImmConfFact} on immediate conflicts.)

Let now  such that it contains only a single top-level literal. 
Since case  of \emph{Backjump} was used, such a clause from  
exists. Since  is false and it was undefined before, 
it contains some top-level literals. 

Since it was not a subject of \emph{Propagate} before the right-most decision, 
it has to contain at least two such literals. 
But  contains only one, and therefore  and  must hold, a contradiction.

Finally, if  and the right-most literal is not a decision, the last rule had to be \emph{Backjump} (case  or ),
and the same argumentation holds: 
If an assertive clause is learned, let  an instance from  such that it contains only a single top-level literal. However,  
must contain at least two top-level literals, which again leads to , a contradiction.
If  is learned, it is smaller than any non-empty clause, and due to regularity,  is a newly learned clause.
\finishproof
\subsection{Admissible Redundancies}
Next, we show that the classic redundancy criterions \emph{tautology}, \emph{strict subsumption}, and \emph{subsumption resolution} 
are \emph{admissible redundancies in NRCL}, i.e.\ 
the clauses these rules remove are indeed redundant w.r.t.\
any induced ordering.


\begin{prop}[Tautology] Let  a clause and  an arbitrary clause set.

\end{prop}
\noindent\startproof
Clearly, any ground instance of  is a ground tautology and redundant, since it follows from the empty set which "contains" only smaller clauses.
\finishproof\leaveabit
\indent
Furthermore,  we also note that removing  has no effect on any run of the calculus, 
since no instance of  can be ever a conflict clause or imply an assignment.

\begin{prop}[Strict Subsumption]\label{propSubs}
Let ,  be clauses,  a substitution, and  a set of clauses. 

\end{prop}
\noindent\startproof
Let  be a ground instance of . Then  and  holds, for any induced ordering . 
The latter holds, because  holds in the abstract ordering.

Thus,  is redundant w.r.t.\
, and so is  w.r.t.\
, and strict subsumption is admissible.
\finishproof\leaveabit
\indent
Similarly to tautology, removing a subsumed clause has little effect on the calculus, since whenever the subsumed clause is  a conflict or a reason clause, the subsuming clause is either a
conflict clause or implying the same assignment as well.

\begin{prop}[Subsumption Resolution] 
Let ,  clauses,  a literal,  a substitution, and  a clause set.

\end{prop}
\noindent\startproof
Redundancy clearly holds as  subsumes . 
Furthermore, we note that exchanging  with  in the presence of  is a sound step.
Thus, subsumption resolution as a rule for reducing a clause is admissible.
\finishproof
% \section{Termination and Completeness}

Just as most related calculi, NRCL is a decision procedure for {\mEPRs} as well, under the regularity conditions of Definition~\ref{regRunDef}.
Below, we show that regular runs never get stuck and eventually terminate.

\begin{prop}\label{noStuckProp}
A regular run is never stuck,  i.e.\ 
it terminates with the terminal rules, or one of the other rules is applicable.
\end{prop}
\noindent\startproof
It is enough to show that, unless we already terminated, a rule is always applicable. First, we show that conflict search cannot get stuck.

If  is already in one of the clause sets, \emph{Failure} is applicable and we terminate. Thus, w.l.o.g. assume .

Assume  is total, i.e.\ 
defines each ground atom. Then  defines all ground atom occurring in ,
 and it either satisfies  or there is a 
false ground clause from . 
In the first case, \emph{Success} is applicable, and \emph{Conflict} in the second case.

If  is not total, and some undefined ground literal is implied by some ground clause, \emph{Propagate} is applicable. Otherwise, 
if no ground literal is implied and there is an undefined ground atom, we can always apply \emph{Decide}. 
We note that decisions which define only a single ground atom are never blocked.

Second, assume we are resolving a conflict, i.e.\ 
the state indicator is  for some , , and . 
If the top literal in  is a decision and if  is assertive, then \emph{Backjump} is applicable.
If it is not assertive, then either \emph{Factorize}, or case  of \emph{Backjump} is applicable.

If the top literal is a deduced literal, 
and neither does  hold, nor is  assertive - in these cases \emph{Backjump} is applicable -, 
then we check the conditions of \emph{Skip}.
If \emph{Skip} is not applicable, it satisfies the conditions of \emph{Resolve}. 
Therefore, either \emph{Skip}, \emph{Factorize}, \emph{Resolve} must be applicable in this case.
\finishproof\leaveabit
\noindent
We show termination through a series of lemmas. First, we prove that both conflict search and conflict resolution always terminate:

\begin{lemm}\label{csTerminatesTheo} Assume ,  and  are all finite.
Then, a conflict search phase of a regular run always terminates, i.e.\ 
leads either to a conflict or to termination.
\end{lemm}
\noindent\startproof
By the finiteness of , we know that  is also finite. 
Since a regular run is a series of sound steps, we also know that each application of \emph{Propagate} and \emph{Decide} 
defines at least one formerly undefined ground atom. 

Thus, a regular run eventually exhausts these rules, and, since it cannot get stuck by Proposition~\ref{noStuckProp}, one of the rules 
\emph{Failure}, \emph{Success}, or \emph{Conflict} has to be applied. And thereby, the conflict search phase in question ends.
\finishproof

\begin{lemm}\label{crTerminatesTheo} Assume ,  and  are all finite.
Then, a conflict resolution phase of a regular run always terminates, i.e.\ 
leads to the application of 
\emph{Backjump} in finitely many steps.
\end{lemm}
\noindent\startproof
Let us assign to each intermediate state  in a conflict resolution 
the tuple  as a measure, where  denotes 
the number of elements in . 

Let us order these tuples with the lexicographical ordering  based on the canonical ordering over non-negative integers and  
where  denotes both the ordering induced by the trail 
after finding the conflict, and its multiset extension. 
This ordering is well-founded.

We note that conflict resolution cannot get stuck, see Proposition~\ref{noStuckProp}. 
Therefore, it is enough to show that each application of the rules \emph{Skip}, \emph{Resolve}, and \emph{Factorize} strictly 
decreases our measure.

\emph{Skip} strictly decreases the size of , and therefore our measure as well. 
In the case of \emph{Resolve} and \emph{Factorize}, 
it is enough to give a function satisfying the conditions of Proposition~\ref{orderPropProp} 
between the false instances on the two sides, i.e.\ 
a function 
which assigns ground clauses from the right-hand side conflict-set to 
larger ground clauses from the left-hand conflict-set.

First, assume we apply \emph{Resolve} to the state 
	
and we get
  
where , 
, and 
 such that . 
For the sake of readability, let us introduce the symbols  and .

Now, let  be a grounding substitution such that . Since it was derived via resolution, 
there is a corresponding valid ground resolution step with premises 
	\begin{itemize}
		\item 
		\item 
	\end{itemize}
where we assume  and  are the literals corresponding to  and , respectively. 
Since we apply resolution, we also know that , and .

By the definition of sound states and \emph{Propagate}, 
we know that  contains only literals which were defined before the last assignment, 
and thus, , and therefore . 
Then,  must hold, 
and thus, we shall define  as .

Since  can be defined over the whole  and  is a subset of 
, we can apply Proposition~\ref{orderPropProp}, and we get 

and our measure strictly decreases, as the size of the trail is unchanged.
The proof for \emph{Factorize} is analogous.
\finishproof\leaveabit
\noindent
Next, we show that only finitely many new clauses can be learned thanks to our non-redundancy results in Theorem~\ref{freshnessTheo}.
\begin{lemm}\label{finiteLearningTheo}
If ,  and  are finite, a regular run can only learn finitely many new clauses.
\end{lemm}
\noindent\startproof
We use Higman's Lemma~\cite{Higman52} to prove this claim.
The lemma states that given an infinite sequence  of words over a finite alphabet, there is always an index  and a subsequent index  such 
that the word  is \emph{embedded} into , i.e.\ after deleting some letters from  we can get .

Now, consider . Since  and  are finite, both the set of ground atoms and ground literals over  and  are finite.
The latter serves as the finite alphabet for our proof.

Since every learned clause is non-redundant at the time they are learned, by Theorem~\ref{freshnessTheo}, 
we can assign a non-redundant ground instance to any learned clause, by the definition of redundancy.

Assume we learn infinitely many clauses, and let us consider the assigned ground clauses , where
 is assigned to the clause learned at the first conflict,  to the clause learned at the second, and so on.

Now, take any term ordering , order the literals of the clauses, and assign this ordered sequence of literals to each clause. 
Let us denote this word over the alphabet of ground literals by  for every ground clause .

Then, by Higman's Lemma, there are indices  such that  is embedded in .
But it means that , i.e.\  is strictly subsumed by or equal to .

The admissibility of strict subsumption was proven in Proposition~\ref{propSubs}, and clearly 
an already present ground clause cannot be non-redundant either, for any induced ordering.
Thus,  cannot be redundant at the th conflict, a contradiction.
\finishproof\leaveabit
\noindent
Finally, we show termination, and state the main result as a corollary.
\begin{theo}[Termination]\label{termRunTheo}
A regular run always terminates if ,  and  are finite.
\end{theo}
\noindent\startproof 
First, we note that a run can be seen as a series of conflict search and conflict resolution phases, which ideally ends with a terminal rule.
By Lemma~\ref{csTerminatesTheo}, Lemma~\ref{crTerminatesTheo}, and Proposition~\ref{noStuckProp}, 
we know that each phase ends after finitely many steps without getting stuck. 

Thus, an infinite run must be an infinite series of conflict search and resolution sequences. Since each conflict resolution ends with 
\emph{Backjump}, it would imply that infinitely many new clauses are learned. But it contradicts Lemma~\ref{finiteLearningTheo}. 
\finishproof

\begin{coro}[Decision Procedure]Regular runs provide a decision procedure for the {\mEPR} fragment if ,  and  are finite.

I.e.\ every regular run terminates after finitely many steps with \emph{Failure}, or \emph{Success}, for an unsatisfiable, or satisfiable 
clause set , respectively.
\end{coro}
\noindent\startproof It follows from Proposition~\ref{noStuckProp} and the Theorems~\ref{sndRunTheo} and~\ref{termRunTheo}.
\finishproof
% \section{Towards Implementation}
This far we considered mostly our calculus in an abstract fashion, and it is enough to establish 
the results of the previous chapters.

Here, we elaborate some details regarding the constraints, 
and refine some steps to bring NRCL closer to practical application. 
In particular, we provide an abstract algorithm for exhaustive propagation, 
to highlight some important difficulties and expensive steps in the calculus.

However, this section does not aim to provide a complete abstract algorithm for regular runs, we 
only briefly address some challenges and propose some solutions and approaches, 
which provides us a starting point for later implementation and experimentation.
\subsection{Free Variables}
\newcommand\restr[2]{\ensuremath{\left.#1\right|_{#2}}}
The definition of normal form for constrained literals demands the left-hand side of a constraint to contain only variables 
occurring in the constrained literal. 
Our calculus derives new assignments, i.e.\ new constrained literals for , by applying 
resolution between the literals in  and the clauses in . 

However, even after normalization, the resulting candidate  might contain
free left-hand side variables, i.e.\ variables which occur in the reason clause instance , 
and still occur in , 
but do not occur in . 
The following example demonstrates this behavior.

\begin{example}\label{freeVarEx}
Let us take

And assume that after an application of \emph{Propagate} and \emph{Decide} we get the trail

Now, applying \emph{Propagate} between  and the clause , we get the constrained literal

Over , this constraint is satisfiable, 
the cover-set is , and after eliminating the free variable  we get the constrained literals

\end{example}

Semantically, these variables are to be treated as existential variables, of course. 
These variables cause two problems. 

First, in the presence of these existentially handled variables 
our constrained literal set for difference defined in Lemma~\ref{diffLemma2} is no longer valid. 
In particular disjointness is no longer guaranteed. 

A simple way to overcome this issue is to split the resulting literal into a set of literals by instantiating 
the free left-hand side variables with relevant constants, as seen in the example above. 
This elimination procedure results in a set of not necessarily disjoint constrained literals.

Second, while eliminating these variables is a solution, we still need to store the instantiating assignments.
This information is used 
when applying the rules \emph{Resolve} and \emph{Factorize} during conflict resolution.
This is already accomplished through using \emph{closures} as introduced in Section 3.
% \subsection{Indexing Scheme}
In the propositional setting, the watched literal scheme watches two literals in every non-unit clauses. 
These literals are assumed to be true or undefined under the current model assumption, or all literals but a single watched literal are false in the clause.

Whenever a new assignment makes a watched literal false, 
we attempt to find a new non-false literal. 
If it is not possible, the other watched literal is propagated resulting either in a new assignment or a new conflict clause.

This scheme enables efficient propagation at small computational costs as it cuts back the number of clauses we have to consider
after a new assignment and requires no additional bookkeeping during backtrack.

When lifting the scheme, we have to keep in mind that manipulating our constraints is more expensive.
Therefore, a direct lifting of the technique by exactly maintaining which literals are watched in the different instances of a clause would be 
too expensive for our purposes.

Here, we propose a lightweight approach which uses two levels of indexing the literals of the current clause set.
Every clause is indexed by one of these levels, but not both.

The first level attempts to mimic the two-watched-literal scheme, and indexes only two literals in the clauses. 
We can choose the interpretation of watching a literal  as an approximation of \emph{cannot be false} by selecting one of the following:
\begin{itemize}
	\item 
	\item 
	\item 
\end{itemize}
Obviously, the last choice is the most expensive and the first two should be preferred.

Whenever a new assignment is made, we first try to adjust the watched literals on level one. If a clause contains no longer two appropriate literals, we push it to the second level.
On this level we index all literals of the clauses, 
e.g.\ in a context tree with top-level symbol hashing. 

Putting clauses back to level one can be done either by maintaining an activity heuristics and time to time manually check for watchable literals, or managing lists of pointers for all clause-literals to relevant assignments 
on the trail.

This topology should make propagation cheaper, and in particular 
using level one should make it easier to ignore clauses irrelevant w.r.t.\ the recent assignments.
% \subsection{Finding Candidates}
Before we propose an abstract algorithm for exhaustive propagation, 
we introduce a simple derivation system for finding candidates. 
Of course, in the actual implementation this system will be replaced by more efficient algorithms on 
the indexing structures. 
\leaveabit\noindent
The rules work on tuples of the form  where
\begin{itemize}
	\item  is a clause, a subclause of some initial clause  from the current clause set
	\item  is a substitution over 
	\item  is a dismatching constraint 
	\item  is the number of application of the last assignment of the trail, which has relevance in the next section
\end{itemize}
The initial tuple for a clause  is  and we try to resolve each literal in  with the following rule:

Where there is a  such that
\begin{itemize}
	\item 
	\item  and normalized
	\item  is  if  is the last assignment in , and  otherwise
\end{itemize}
Applying this rule we can get candidates for the rules \emph{Conflict}, and \emph{Propagate} by deriving respectively tuples of the form
\begin{itemize}
	\item , or
	\item 
\end{itemize}
We note that non-emptiness is not checked fully, only a cheaper precondition of it. 
Free left-hand side variables and already defined instances are not removed either.
% \subsection{Exhaustive Propagation}
In this section, we propose the abstract algorithm \texttt{PROP} for exhaustive propagation with conflict detection.
It basically processes a queue \texttt{PQ} of candidates for new assignments. 
As an invariant, we assume each constrained literal in the queue 
\begin{enumerate}
	\item has a normalized non- constraint
	\item consistent with the current 
	\item contains no free left-hand side variable
\end{enumerate}
\subsubsection*{PROP}
Initially, this queue consists of the literals induced by the unit clauses. 
Unit clauses has to be checked for contradiction prior calling \texttt{PROP}.
When calling after decisions, \texttt{PQ} is assumed to contain the 
immediate consequences of the decision. 
Checking for blocking should generate this set anyway.

\texttt{PROP} processes the literals on \texttt{PQ}.
First, it removes already defined instances by calling the function \texttt{DIFF}.
This produces a set of disjoint and undefined constrained literals, each of which
is a valid subject of \emph{Propagate}.
See Section 2.3 for the definition of the difference operation "", and see below 
the abstract algorithm for \texttt{DIFF}.

These literals are then checked for emptiness, added to  and set to true.
Their consequences - conflicts and new candidates for \texttt{PQ} - 
are then generated by \texttt{addConsequences}.

We continue this process until \texttt{PQ} gets empty, or a conflict is found.
The first indicates the finished exhaustive application of \emph{Propagate}, and \emph{Decide} can be called. 
In this case we return . And in the latter case, we return , and the found conflict is 
stored in \texttt{conflictSet}.

On the course of this section, we might use the symbol  to denote annotated constrained literals, and the following 
auxiliary functions:
\begin{itemize}
	\item \texttt{pop}: removes an element of a queue, list, or set
	\item \texttt{notEmpty}: carries out a full non-emptiness check for a constraint or constrained literal
	\item \texttt{addAssignment}: adds a new assignment to  (and its indexing structures)
	\item \texttt{cUNIF(, )}: Finds the literals in  which are unifiable with , and returns an array of them and its size
	\item \texttt{NF}: normalizes a constraint, constrained literal, or a set of constrained literals, as described in Subsection 2.2. In the latter case, it removes resulting literals with -constraints.
	\item \texttt{freeLVars}: produces the set of free left-hand side variables of a constrained literal
	\item \texttt{selectOne}: randomly, or heuristically selects an element of a set, or a list
	\item \texttt{adjustLevel1}: adjusts the first index level for clauses after a new assignment given as parameter, as described in Section 6.2.
	\item \texttt{getCandidates}: provides the list of indexed clauses which contains a literal unifiable with the complement of a given literal
\end{itemize}
\begin{function}\SetKwData{PQ}{PQ}
  \SetKwData{N}{N}\SetKwData{U}{U}
	\SetKwFunction{pop}{pop}
	\SetKwFunction{DIFF}{DIFF}
	\SetKwFunction{notEmpty}{notEmpty}
	\SetKwFunction{Assign}{addAssignment}
	\SetKwFunction{Conseq}{addConsequences}
	
	\caption{PROP(N, U, , PQ)}
	\While{\PQ  }{
		  \pop{\PQ}\;
		  \DIFF{, }\;
		\ForEach{}{
			\If{\notEmpty{}}{
				\tcp{Applying Propagate:}
				\Assign{, }\;
				\lIf{\Conseq{\N,\U,,,\PQ} = false}{\KwRet{false}}
			}
		}
	}
	\KwRet{true}\;
\end{function}
% \subsubsection*{DIFF}
It iteratively removes the already defined instances from the proposed assignment. 
The result is a set of disjoint and undefined constrained literals with non- constraints.
\begin{function}\SetKwFunction{UNIF}{cUNIF}
	\SetKwFunction{NF}{NF}
	\SetKwData{k}{k}\SetKwData{i}{i}
	
	\caption{DIFF(, )}
	(, \k)  \UNIF{, }\;
	  \;
	\For{\i = , \dots, \k}{
  \;
	}	
	\KwRet{}\;
\end{function}
% \subsubsection*{elimFV}
An auxiliary function for finding new candidates. 
It iteratively removes the free left-hand side variables, and only keeps the 
literals with non- normalized constraints.
\begin{function}\SetKwFunction{pop}{pop}
	\SetKwFunction{FV}{freeLVars}
	\SetKwFunction{NF}{NF}
	\SetKwFunction{sel}{selectOne}
	
	\caption{elimFV()}
	\tcp{Prereq: }
	,   , \;
	\While{  }{
		  \pop{}\;
		\If{\FV{} = }{
			  \;
		}
		\Else{
			  \sel{\FV{}}\;
			\tcp{Instantiation with each constant from the domain:}
			\ForEach{}{
				  \NF{}\;
				\lIf{} {  }
			}
		}
	}
	\KwRet{}
\end{function}
% \subsubsection*{addConsequences}
Finally, \texttt{addConsequences} checks whether a new assignment produces a conflict and generates new 
candidates for \texttt{PQ}. It returns  if no conflict is found, and  otherwise. 
If a conflict is found, it is saved in \texttt{conflictSet}. 

We distinguish two types of conflicts.
It is easy to see, that if the new assignment is used only once in deriving a conflict, then 
\texttt{PQ} must already hold an unprocessed candidate which is falsified by the new assignment.
Thus, we check \texttt{PQ} first for a contradiction, and start generating new candidates with 
only afterwards.

We then use the derivation system of 6.3 to derive new constrained literals. We only consider derivations 
where the latest assignment has to be used at least once. If it is used only once we can be sure the new 
literal is not false. If it is not the case, we check for a possible conflict.

As stated before, in the actual implementation the proper retrieval algorithms will eliminate the inefficiency of considering all derivations.

Finally, the new candidates are tested for free variables, and they are removed if there are any.
\begin{function}\SetKwData{PQ}{PQ}
	\SetKwData{CS}{conflictSet}
	\SetKwFunction{notEmpty}{notEmpty}
	\SetKwFunction{NF}{NF}
	\SetKwFunction{FV}{freeLVars}
	\SetKwFunction{elimFV}{elimFV}
	\SetKwFunction{getCandidates}{getCandidates}
	\SetKwFunction{adjLvl}{adjustLevel1}
	
	\caption{addConsequences(N,U,,, PQ)}
  \;
	\tcp{Step 1: Check Type-1 Conflicts}
	\ForEach{  \PQ}{
		\If{ and \NF{} and \notEmpty{}}{
			\CS  \;
			\KwRet{false}\;
		}
	}
\tcp{Step 2: Adjust indexing level 1}
	\adjLvl{N,U,}\;
\tcp{Step 3: Generate consequences}
	\ForEach{  \getCandidates{, }}{
		\ForEach{derivation  with }{
			\tcp{Check Type-2 Conflicts}
			\If{}{
				\If{ such that
								 and
								\NF{}  and
								\notEmpty{}
						}
				{
					\CS  \;
					\KwRet{false}\;
				}
			}
			  \;
			\lIf{\FV{} = }{\PQ  \PQ, }
			\lElse{\PQ  \PQ, \elimFV{}}
		}
	}
	\KwRet{true}\;
\end{function}
%  \subsection{Picking the Next Decision}
When making a new decision, we a pick a candidate , 
remove all the already defined instances, and then 
test all immediate conflicts for blocking. 

If there is a blocking conflict, 
we might then either pick an entirely new decision candidate, or try to \emph{fix}  by instantiating some variables in , and thereby generating a new set of candidates.  

This can be achieved by picking a blocking ground instance  which contains  such that
both  and  holds. 
Now, choose a variable for which , and
split  into  and .
By instantiating further variables, we eventually get a decision which is not blocking, since a ground decision is always suitable.

A non-blocking decision is then added to , and whether we found a non-blocking conflict or not, we continue with conflict 
resolution or with calling \texttt{PROP} after generating the immediate propagation candidates in a similar way as in \texttt{addConsequences}.

Initially, the set of decision candidates are generated from the literals occurring in . 
This set can be later refined by the above steps, and individual candidates might be substituted with sets of new candidates.

Since removing defined instances is always relative to the current , it has to be guaranteed that the set of all possible candidates
covers the original set.
It can be ensured for example by keeping a trail for these refinement steps as well, and re-roll them in parallel with the backtracking procedure.
% \subsection{Ranking Literals}
Most current SAT solvers also employ variable selection schemes based on dynamic ranking of propositional variables. 
This technique rewards variables involved in recent conflicts, and proved itself efficient in the propositional context. 

Following the footsteps of the now classic \emph{decaying variable sum}, we reward the literals 
involved in the clause learning phase following the latest conflict. 

This is accomplished by maintaining a list of literals and scores. 
Whenever some literal  is added to the clause of the intermediate state, we add a pair  to this list.

To focus on recent conflicts, we increase  gradually, and occasionally we reset  to some initial value and normalize the list.
The latter can be triggered upon reaching some extreme value, automatically after a certain number conflicts, or 
at restarts. 

Restarts are commonly used in SAT solvers to redirect the focus of the search using the learned clauses and the current variable scores. 
Applying it only finitely many times does not violate completeness.

Then, whenever we need to choose a new decision, we rank the candidates by combining the scores belonging to literals which are unifiable with
the candidate in question. As an example we propose addition or maximum. We then choose the literal with the highest combined score.
% \subsection{Clause Learning and Backjumping}
As the conflicts are now discovered, every conflict-set uniquely assigns a -assignment to each literal of 
the conflict clause. This make detecting assertiveness easy and spares us a number of emptiness checks, as they 
are already done during conflict detection. 
This way, the only non-deterministic choice is the application of \emph{Factorize} versus \emph{Resolve}, when both is applicable. 

Once a new clause is learned, a suitable backtrack level is needed. 
Should we learn only the ground clauses in  when the last conflict-set  is , 
we could determine the backtrack position at ease, similarly to the propositional solvers. 

But we learn the more general , and the right backtrack position has to be computed from all the 
instances of .
We have to consider all conflicting instance of  w.r.t.\ , and for each instance, we have to determine a minimal backtrack position.
Then, we backjump to the minimum of these positions. 

Without providing more details, we only note that some instances produce new assignments after backtrack, some might block existing decisions, and some might even
be new conflicts after backjump. % \section{Related Work}
In this section, we briefly compare NRCL to existing solutions.
As \mEPR~problems can be successfully handled with finite model finders as well, 
we cover both \mEPRs-specific techniques and more general finite model building approaches.
In the case of the latter systems, we focus on their behavior on the \mEPR~fragment.

The first successful approaches to finite model building were \emph{Mace} and \emph{SEM}, see e.g.\ \cite{Tammet03finitemodel}.
The early version of \emph{Mace} flattens and grounds the given clause set, and passes it on to a CDCL-based SAT solver. 
This approach is developed further by \emph{Paradox}~\cite{ParadoxRef}. 

Compared to this approach, we work directly with the first-order clause set instead of the often exponentially larger set of ground instances.

The latest version of \emph{Mace}~\cite{Mace4Ref03} follows the approach of \emph{SEM}~\cite{SEMRef95} and \emph{FINDER}~\cite{FinderRef94}. 
Instead of generating the ground instances, 
it maintains the function and predicate tables, and fills them out using a sophisticated backtracking algorithm. 

Compared to this approach, we represent the model implicitly via constrained literals,  
and let the learned clauses guide our calculus.

Over the last decade several attempts were made to lift CDCL and its ancestor, DPLL - 
a calculus using backtracking instead of backjumping and clause learning. 
\emph{Model Evolution}~\cite{ModelEvolution03} and its implementation \emph{Darwin}~\cite{Darwin04}
represents a model with a set of first-order literals, called \emph{context}, and 
detects conflicts using syntactic concepts weaker then the full-fledged semantics based on
the induced interpretation.
This potentially leads to longer derivation before detecting a false clause.

It is refutationally complete over first-order clauses and provides a 
decision procedure for the {\mEPR} fragment. 
Its extension~\cite{ModelEvolutionLemma06} enriches the calculus with learning lemmas at conflicts, 
and uses backjumping instead of the original backtracking approach. 

Compared to \emph{Model Evolution}, NRCL relies on the full-fledged semantics,  
and we learn only non-redundant clauses.
It is not clear if the latter holds for \emph{Model Evolution}, 
especially the admissibility of the classic criterions
needs in-depth considerations.

Finally, it was shown in~\cite{FermullerCADE05} that using contexts might result in exponentially larger model representations.
We note that this result holds for the general case with function symbols, but in our setting \eg the constrained literal

whose size is , requires a representation of size at least  as a context.
Thus, at least a quadratic relation holds even for the {\mEPR} fragment.

\emph{DPLL(SX)}~\cite{DPLLSX10} attempts to lift CDCL to {\mEPRs} in the same manner as we do, 
has an almost identical rule set, 
and uses substitution sets represented by BDDs as constraints. 
Substitution sets provide an explicit way to represent models. 

It is well-known that in the general setting with function symbols implicit representations have stronger expressive power~\cite{Pichler03}\cite{LassezM87}.
In our setting, explicit representations have the potential to be exponentially larger 
then the corresponding implicit representations.

The following simple example demonstrates this claim.
Over , consider the constrained literal

Then it is easy to see that the corresponding explicit representation is made up of all the ground instances covered by this literal.

Therefore, while the size of the implicit representation increases linearly in , the size of the corresponding explicit representation
is , \ie increases exponentially in .

The authors of this paper are convinced that this exponential blow-up happens whenever in the implicit representation has 
no finite explicit representation (see \cite{Pichler03}\cite{LassezM87} for details) in the language enriched with a function symbol. 
However, this conjuncture needs further consideration, and we leave it for future work.

Furthermore, compared to \emph{DPLL(SX)} our approach is more modular 
as it allows the use of an arbitrary constraint language, restricted only by the operations we expect. 
Dismatching constraints can be extended beyond the {\mEPR} fragment easily, while in 
the case of BDD-encodings, it is not trivial.

DPLL(SX) also lacks the concept for blocking, and applies an explicit refine rule instead.
As a side effect, it learns nothing from conflicts which lead to blocking clauses, and 
in these cases it abandons conflict resolution and refines the last decision.
Finally, we also address redundancy, and exploit the non-redundancy result to show termination, which we consider a valuable addition.

The most recent calculus \emph{SGGS}, introduced in~\cite{SGGSExposition}, promises a semantically guided, goal sensitive, model-based proof system. 
It uses simple constraints, so-called \emph{standard forms}, conjunctions of negative atomic constraints 
of the form , or .

Then, a model is represented by a sequence of constrained clauses with selected literals. 
This sequence overrides a given initial interpretation , 
which serves both as initial model assumption and as semantic guidance for the calculus.

The procedure then keeps expanding this sequence in order to satisfy more and more clauses, and handles contradictions via resolution and splitting 
the constrained clauses to maintain an invariant - 
every literal in every clause in the sequence must have \emph{either only false, or only true instances} \wrt 
 and the constraints.

NRCL utilizes a more expressive constraint language, which allows tuples to be used.
This results in less fragmentation of the representation, \ie \emph{SGGS} might need several constraints in standard form
to express a single dismatching constraint of our calculus. 

This allows us to learn more general clauses, and also potentially decreases the size of the representation. 
Our model representation relies on constrained literals instead of clauses, and we consider it to be more
explicit than the approach of \emph{SGGS} which requires identifying the constrained instances of the clauses which are indeed
producing new assignments.

Finally, the resolution applied by \emph{SGGS} only repairs the model, it can be discarded later as the search progresses, and the splittings applied to maintain the invariants 
also forces the result of resolution to be more specific, more local. 
Compared to this, our calculus learns and saves new clauses, uses backjumping, and we proved these clauses are non-redundant.

We also mention \emph{geometric resolution}~\cite{GeoRes06} which uses a special normal form called \emph{geometric normal form}. In this calculus the formulas
themselves constitute the rules of a system based on backtracking. 
Through the inference \emph{geometric resolution} it also provides a way to learn new formulas.
The transformation to geometric normal form also includes flattening, 
which our approach avoids.

The calculus \emph{Inst-Gen}~\cite{InstGen03} and its implementation \emph{iProver}~\cite{iProver08} 
has been quite successful at solving {\mEPR} problems, and competitive even for the first-order fragment.
It generates a propositional approximation of the clause set by instantiating all the variables with constants, 
and passes it on to a CDCL-based SAT solver. 

Unsatisfiability of the approximation entails the unsatisfiability of the original problem.
On the other hand, if an abstract model is generated, it is used to guide the calculus to add 
proper instances of the original clauses, which refines the propositional abstraction.

This procedure is continued then, until either unsatisfiability is proven, or saturation is achieved, 
which implies that the abstract model can be lifted to a first-order model for the original clause set.

The algorithm is further enhanced by using dismatching constraints, and applying redundancy elimination based 
on generating first-order resolvents for subsumption with a theorem prover, and finding simplification candidates efficiently
with ground reasoning.

Compared to \emph{iProver}, our approach is fine-grained, 
as the evaluation and refinement of our abstraction happen interleaved with the other reasoning steps.
Furthermore, we work directly with the original clause set, and our trail always corresponds 
to a consistent first-order model candidate.

In addition to the theoretical comparison, we also ran a small experiment for models represented by literals of the form 

The clause set

  
	
  
	
  \newline
has a model where the positive atoms are represented by the constrained literals 

and . NRCL directly finds this model, \ie without backjumping even once, 
by exhaustively applying propagation, making a single decision on  and finally 
setting all undefined  literals to false. Furthermore, any regular run would find a similar model without 
backjumping even once.

We tested this clause set with the available state-of-the-art provers \emph{Darwin}
(1.4.5) and \emph{iProver} (0.8.1).
The experiments were carried out on a Debian Linux
(4.7.2-5) Intel (Xeon E5-2680, 2.7GHZ) computer with 256GB physical memory.
For  and , \emph{Darwin} needs  seconds to find a model, respectively.
For  and , \emph{Darwin} needs  seconds to find a model, respectively.
For  and , \emph{iProver} needs  seconds to find a model, 
respectively.

In the case of \emph{Darwin}, these results show an exponentially 
growing solution time \wrt  (the arity of ) or   (the domain size). 
\emph{iProver} is robust against increasing  but not against increasing
, where it also shows an exponential growth. 
 This shows that our model representation is not subsumed by either \emph{Darwin} or \emph{iProver}.


Finally, even general purpose first-order theorem provers implement specialized techniques to handle {\mEPR} problems.

\emph{Generalisation} introduced in~\cite{Generalization08} for \emph{Vampire} 
is an additional technique for resolution-based saturation. 
It infers  if  has been established for all relevant constant .
Coupled with efficient sort inference, it has the potential to exponentially speed up theorem proving.

The technique introduced in~\cite{HillenbrandWeidenbach13} for \emph{SPASS} employs 
a combination of restricted superposition on Horn clauses, and \emph{labelled splitting}~\cite{FietzkeW09} on non-Horn clauses.

Compared to these approaches, NRCL maintains a model candidate, it is restricted to learn clauses only at conflicts and only non-redundant ones, 
does not rely on Horn clauses, and the implicit branchings through decisions and backjumps are more elaborate and guided by the model search,
compared to the splitting techniques employed by first-order theorem provers.
However, we note that for some problem classes finite superposition saturation is still
superior to explicit model generation, see \eg superposition for knowledge bases in~\cite{SudaWeidenbachWischnewskiIJCAR10}.
% \section{Conclusion}
In this paper, we proposed the decision procedure NRCL for the {\mEPR}
fragment. 
Our approach represents a model candidate as a set of constrained literals, and 
derives a model or a proof of unsatisfiability through a series of decisions, 
propagations, and learning new clauses. 

Our work closely relates to \emph{DPLL(SX)}~\cite{DPLLSX10}, which introduces a similar calculus,
and the more recent calculus \emph{SGGS}~\cite{SGGSExposition}.
Compared to earlier work in this direction, we investigated the standard redundancy notion
w.r.t.\ the ordering induced by the current trail.

One of the main contributions of NRCL over existing work is that, by design, 
we can prove our learned clauses to be non-redundant, i.e., any learned clause makes progress 
towards finding a model or a refutation, because it eliminates at least one potential model. 
In general, we consider this a key property for automated reasoning calculi.

Projecting NRCL down to propositional logic proves this property for CDCL 
with respect to our notion of redundancy. 
Our notion also admits techniques like subsumption and subsumption resolution, 
which are important in both SAT solving and first-order theorem proving. 
We see this as a strong indication that a future implementation 
will also contribute to the state of the art.

In Section 8, we addressed some of the difficulties of this approach, and provided 
details for implementation.
Finally, we gave a brief comparison to the existing solutions in Section 9.

As future research, the immediate goal is to 
make an efficient implementation of NRCL.
This includes developing suitable and efficient term indexing structures, possibly revising the constraint language, and 
defining concrete and efficient heuristics for selecting decisions.

On the other hand, the long-term goal of our research is to extend this calculus beyond {\mEPR}.
The next step into this direction is to enrich our calculus with function symbols and sorts to handle the
\emph{non-cyclic fragment} introduced in~\cite{Noncyclic13}. 
This class still has the finite Herbrand model property, thus, our results will directly extend to this fragment.

The further goals are to consider other decidable fragments, to introduce equality into our calculus, and finally 
to extend our work to finite model finding.
% \bibliographystyle{mpiabbrv-mod}
\bibliography{alagi_refs}
\ifdefined\PRINTNOTES
\section{Notes and Design Decisions}
\subsection{Weak Regularity}
We note that the weaker definition for regularity, see below, is just as effective as the one we choose.
\begin{defi}
A \emph{run} is called \emph{weak-regular} iff the following holds:
	\begin{itemize}
		\item During conflict search, rules are always applied in this order exhaustively: terminal rules, \emph{Conflict}, \emph{Propagate}, \emph{Decide}.
		\item In conflict resolution \emph{Backjump} is always applied as soon as possible.
	\end{itemize}
\end{defi}
Some properties however won't hold, in particular the claims (1) and (2) in Lemma~\ref{lemmRegProps} no longer hold, as demonstrated 
by the example below.
\begin{example}
Let , and  the following clause set:
\begin{center}\begin{tabular}{rlll}
 &  &  & \\
       &  &  & \\
       &  &  &  \\
\end{tabular}\end{center}
Then, the next weak-regular derivation demonstrates both learning the same clause  twice, 
and deducing the literal  
contradicting the stronger regularity notion of Definition~\ref{regRunDef}.




Let .




Let .


And, since  is already assertive at this point, we learn it again and backjump.

Above, for any literal  and annotation ,  is a short-hand for .
\end{example}
Soundness and termination could still be proved, and we believe non-redundant learning would also hold
with the exception of immediate conflicts of the kind demonstrated above, i.e. when after an inaccurate 
backjump we end up with an assertive conflict clause and learn the clause itself again.

We could modify \emph{Backjump} to identify this situation and make a proper backjump when we 
would learn an already known clause again.
We believe however that Lemma~\ref{lemmRegProps} is a useful invariant and easy to take granted, thus, we 
decided to use a stronger notion of regular runs in Definition~\ref{regRunDef}.
%  \fi
\end{document}