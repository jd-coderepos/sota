\documentclass[11pt,envcountsame,letterpaper]{llncs}
\usepackage{amsmath} \usepackage{amssymb}
\usepackage[vlined]{algorithm2e} 
\usepackage{algorithmic}
\usepackage{enumitem}
\usepackage{url}
\usepackage{color}
\usepackage[margin=3.6cm]{geometry} 
\newcommand{\rev}[1]{{\color{blue}#1}}
\title{\large Deterministic Leader Election Takes  Bit Rounds
\thanks{This research has been partially supported by ANR projects DESCARTES and ESTATE (resp. ANR-16-CE40-0023 and ANR-16-CE25-0009-03). A preliminary subset of this work 
appeared in the proceedings of DISC 2016~\cite{CMRZ16a}.
}
}
\author{A. Casteigts, Y. M\'etivier, J.M. Robson, and A. Zemmari}
\institute{Universit\'e de Bordeaux - Bordeaux INP
 LaBRI, UMR CNRS 5800\\ 351 cours de la
  Lib\'eration, 33405 Talence, France\\ 
\{acasteig, metivier, robson, zemmari\}@labri.fr } 

\pagestyle{plain}

\begin{document}

\newcommand{\STT}{\ensuremath{{\cal STT}}\xspace}

\maketitle 
\date{today}
\begin{abstract}
  Leader election is, together with consensus, one of the most central
  problems in distributed computing. This paper presents a distributed
  algorithm, called \STT, for electing deterministically a leader in
  an arbitrary network, assuming processors have unique identifiers of
  size , where  is the number of processors. It elects a
  leader in  rounds, where  is the diameter of the
  network, with messages of size . Thus it has a bit round
  complexity of . This substantially improves upon the
  best known algorithm whose bit round complexity is . In
  fact, using the lower bound by Kutten et al. (2015) and a
  result of Dinitz and Solomon (2007), we show that the bit round
  complexity of \STT is optimal (up to a constant factor), which is a
  significant step forward in understanding the interplay between time
  and message optimality for the election problem. Our algorithm
  requires no knowledge on the graph such as  or , and the
  pipelining technique we introduce to break the  barrier
  is general.
\end{abstract}
\section{Introduction}
\label{sec:introduction}
The election problem in a network consists of distinguishing a unique node, the leader, which
 can subsequently act as coordinator, initiator, 
and more generally performs distinguished operations in the network
 (see \cite{Tanenbaum} p. 262). 
Indeed, once a leader is established, many problems become simple, making election a common building
block
in distributed computing. Election is probably the most studied task (together with consensus) in the distributed computing literature~\cite{DMR08},
starting with the works of Le Lann~\cite{LeLann} and Gallager~\cite{Gallager} in the late 70's. 

A distributed algorithm solves the
election problem if it always terminates and in the final
configuration exactly one process (or node) is in the \emph{elected} state 
and all
others are in the \emph{non-elected} state. It is also required that 
once a process becomes elected or non-elected, it remains so for the rest of the execution.
The vast body of literature on election (see~\cite{Attiya,Lynch,Santoro,Tel} and references therein) actually covers a number of different topics, which can be grouped according to three main directions: i) The feasibility of deterministic election in {\em anonymous} networks, starting with the seminal paper of Angluin~\cite{Angluin} and the key role of coverings (i.e. graph homomorphisms that prevent symmetry breaking, and thereby the uniqueness of a leader); ii) The complexity of deterministic election in {\em identified} networks (i.e. every processor has a unique identifier); and iii) The complexity of {\em probabilistic} election in anonymous or identified networks (identifiers play secondary roles here).



The present work is in the second category, that is, we assume that each node has a unique identifier which is a positive integer of size , where  is the number of nodes. The network is multi-hop and nodes communicate using messages in synchronous rounds.
The exact complexity of deterministic leader election in this setting has proven elusive for decades and even simple questions remain open~\cite{KPPRT15}. We review here the most relevant results and challenges around this problem (the reader is referred to the dedicated section for more content).
In the case of logarithmic-size messages (i.e. messages of size ), we know since Peleg~\cite{Peleg90} that  rounds are sufficient to elect a leader in arbitrary networks, where  is the diameter of the network.
This was recently proven optimal by Kutten et al.~\cite{KPPRT15}
using a very general  lower bound (that applies even in the probabilistic setting). Independently, Fusco and Pelc~\cite{FP15} showed that the 
time complexity
of leader election is
 where  is the smallest depth at which some node has a unique view, called the {\em level of symmetry} of the network. (The view at depth  from a node is the tree of all paths
of length  originating at this node.) If nodes have unique identifiers, then , which implies the same  bound as in~\cite{KPPRT15}.

Regarding message complexity, 
Gallager~\cite{Gallager} presents
 the first election 
algorithm for general graphs with  messages, 
where  is the number of edges, and a running time of .
On the negative side, Burns~\cite{burns1980} proves a  lower bound and Kutten et al.~\cite{KPPRT15} a  lower bound which applies even if  is known and the algorithm is randomized. Put together, both lower bounds yield a matching  number of messages. (Santoro~\cite{Santoro84} also proves a  lower bound for the more specific problem of finding the maximum ID, in a deterministic setting with  unknown.)

A few years after Gallager~\cite{Gallager}, Awerbuch~\cite{Awer87} presents an algorithm whose message complexity is again , but running time is taken down to .

A number of questions remain open for election. Peleg asks in~\cite{Peleg90}
whether an algorithm could be both optimal in time and in number of messages.
The answer depends on the setting, but remains essentially open~\cite{KPPRT15}.
In the conclusion of their paper, Fusco and Pelc \cite{FP15} also observe that
it would be interesting to investigate other complexity
measures for the leader election problem, such as {\em bit complexity}.
This measure can be viewed as a natural
extension of communication complexity (introduced by Yao \cite{Yao})
to the analysis of tasks in a distributed setting.

Following~\cite{KOSS}, the bit round complexity of an algorithm  is the total number of {\it bit rounds} it takes for  to terminate, where a bit round is a round with single bit messages. 
This measure has become popular recently, as it captures into {\em a single quantity} aspects that relate both to time and to the amount of information exchanged.
In this framework, the time-optimal algorithm of Peleg~\cite{Peleg90} results in a bit round complexity of  (i.e.  rounds with  message size), and the message-optimal algorithm of~\cite{Awer87} results in a  bit round complexity (i.e.  time with  message size). More recent approaches such as~\cite{FSW14} in the beeping models (therefore exchanging single bits per rounds) still remain at a  bit round complexity.

In this paper, we present the first algorithm whose bit round complexity breaks the  barrier, using essentially a new pipelining technique for spreading the identifiers. Our algorithm requires only  bit rounds and works in arbitrary synchronous networks. We show that this is optimal by combining a lower bound from~\cite{KPPRT15} and a recent communication complexity result by Dinitz and Solomon~\cite{DS07}.
This work is thus a step forward in understanding election, and a first (positive) answer to whether optimality can be
achieved
both in time and in the {\em amount} of information exchanged. (As opposed to measuring time on the one hand, and the number of messages {\em of a given size} on the other hand.) Incidentally, our results also
illustrate
the benefits of studying optimality under the unified lenses of bit round complexity.


\subsection{Contributions}

We present an election algorithm \STT, having time complexity of  with messages of size , where  is the diameter of the network.
Algorithm \STT solves the {\em explicit} (i.e. strong) variant of the problem defined in~\cite{KPPRT15}, namely, the identifier of the elected node is eventually known to all the nodes. It also fulfills requirements from~\cite{DS07}, such as ensuring that every non-leader node knows which local link is in direction of the leader, and these nodes learn the maximal id network-wide ({\em MaxF}), as a by-product of electing this specific node in the {\em explicit} variant.

The global architecture of our algorithm follows a (now) classical principle, similar to that used e.g. by Gallager~\cite{Gallager} or Peleg~\cite{Peleg90}. It consists of a competition of spanning tree constructions that works by extinction of those trees originating at nodes with lower identifiers (see also Algorithm~4 in~\cite{Attiya} and discussion therein). Eventually, a single spanning tree survives, whose root is the node with highest identifier. This node becomes elected when it detects termination (recursively from the leaves up the root). Here the difficulty (and thus main contribution) arises from designing such algorithms with the extra constraint that only constant size messages are used. Of course, one might simulate -size messages in the obvious way paying  bit rounds for each message. But then, the bit round complexity remains . In contrast, by introducing new pipelining techniques whose applicability extends the scope of the sole election problem, we take the complexity down to .

For ease of exposition, the  algorithm is split into three components, whose execution is joint in a specific way.

\begin{enumerate}
\item A spreading algorithm  which pipelines the maximal identifier bitwise to every node, in a mix of battles (comparisons), conquests (progress of locally higher prefixes), and correction waves of bounded amplitude;
\item A spanning tree algorithm that executes in parallel of  and whose union with  is denoted . It consists of updating the tree relations based on what neighbour brought the highest prefix so far;
\item A termination detection algorithm that executes in parallel of  and whose union with  is denoted . This component enables the node with highest identifier (and only this one) to detect termination of
the spanning tree construction of which it is itself the root.
\end{enumerate}

An extra component can be added to broadcast a (constant size) termination signal from the root down the tree, once election is complete. This component is trivial and therefore not described here.

\subsubsection{Lower Bound:}

Dinitz and Solomon~\cite{DS07} prove a lower bound (Theorem~1 below) on the leader election problem among two nodes.
\begin{theorem}[\cite{DS07}]
Let  be an integer such that .
Let  be the graph with two nodes linked by an edge, and suppose that each node
has a unique identifier taken from the set . The bit
round complexity
of the Leader task and of the MaxF version is exactly 
.
\end{theorem}
This theorem implies that  the time complexity of an election algorithm with
messages of size  (bit round complexity) is .


On the other hand, the lower bound by Kutten et al. in~\cite{KPPRT15}, establishing that  time is required with logarithmic size messages, obviously extends to constant size messages. Put together, these results imply that the bit  complexity of leader election
with messages of size  and identifiers of size  is , which makes our algorithm bit round optimal (up to a constant factor).

In fact, the lower bound holds for arbitrary sizes  of identifiers (necessarily larger than , though, since they must be unique). Likewise, the complexity of our algorithm is expressed relative to identifiers of arbitrary sizes (see Theorem~\ref{th:main}). Hence, the bit round complexity of the election problem is in fact .
Table~\ref{tab:result} summarises these elements, taking  as the most common (illustrative) value.

\begin{table}
\label{tab:result}
\centering
\begin{tabular}{|@{\,}l@{\,}|@{\,}c@{\,}|@{\,}c@{\,}|@{\,}c@{\,}|@{\,}c@{\,}|}
\hline
& Time & Number of messages & Message size & Bit round complexity \\
\hline
Awerbuch  \cite{Awer87}&   &   &  & 
\\
\hline
Peleg  \cite{Peleg90}&    &  &  &  \\
\hline
This paper &    &  &  & 
 \\\hline
\end{tabular}
\medskip
\caption{Best known solutions in terms of time and number of messages, compared to our algorithm.}
\end{table}

\subsubsection{Outline:} After general definitions in Section~\ref{sec:model}, we present the three components of the algorithm: the spreading algorithm 
(Section~\ref{sec:S}), its joint use with the spanning tree algorithm (, Section~\ref{sec:ST}), and the adjunction of termination detection (, Section~\ref{sec:STT}).
Further related works on the leader election problem are presented in Section~\ref{sec:related}.
We conclude in Section~\ref{sec:conclusion} with some remarks.

\section{Model and definitions}
\label{sec:model}

This section presents the network model (synchronous message passing, unique identifiers) and give the main definitions used throughout the paper regarding graph theory, language theory, and bit complexity.

\subsection{The Network}
We consider a failure-free message passing model
in a point-to-point
communication network described by a   connected graph 

where the nodes  represent network processes (or nodes) and the edges 
represent bidirectional communication channels. Processes communicate
by message passing: a process sends a message to another by depositing
the message in the corresponding channel. 

Let  be the size of .
We assume that each node   is identified by a unique
positive integer of  bits, called identifier and denoted 
(in fact,  denotes both the identifier and its {\em binary representation}).
 We do not assume any global knowledge on
the network, not even the size or an upper bound on the size, and the nodes do not require position or distance information. 
Every node is equipped with a port numbering function (i.e. a bijection between the set of incident edges  and the integers in ), which allows it to identify which channel a message was received from, or must be sent to.
Two nodes  and  are said to be neighbours if they can communicate
through a port.

Finally, we assume the system is
fully synchronous, namely, all processes start at the same time
and time proceeds in synchronised rounds composed of the following three
steps: 
\begin{enumerate}
\item Send messages to (some of) the neighbours, 
\item Receive
messages from (some of) the neighbours, 
\item Perform local
computation.
\end{enumerate}
  The time complexity of an algorithm is the number of such rounds needed to complete the execution in the worst case.

\subsection{Further definitions}



The paper uses a number of definitions from graph theory and formal language theory. Although most readers may be familiar with them, we recall the most important ones. Then we define the bit round complexity.

\paragraph{Definitions on graphs:}  These definitions are selected from~\cite{Rosenpress} (Chapter 8). A tree is a connected acyclic graph. A rooted tree is a tree with one
 distinguished node, called the root, in which all edges are implicitly 
directed away from the root. 
A spanning tree of a connected graph  is a tree  such that
.
A forest is an acyclic graph. A spanning forest of a graph  
is a forest whose node set is  and edge set is a subset of .
A rooted forest is a forest such that each tree of the forest is rooted.
A child of a node  in a rooted tree is an immediate
successor of  on a path from the root.
A descendant of a node  in a rooted tree is  itself or any node that
is a successor of  on a path from the root.
The parent of a node   in a rooted tree is a node that is the immediate
predecessor of  on a path to  from the root.

\paragraph{Definitions on languages:} These definitions are selected from~\cite{Rosenpress} (Chapter 16).
Let  be an alphabet,  is
 the set of all words over , the empty word is denoted by .
If  is a
non-empty
word of length  over the alphabet  then
 can be written as the concatenation of  letters, i.e.,
 with each  in .
If  and  is a positive integer then  is the 
 concatenation   times of  the letter .
For two words  and  over alphabet , 
is said to be a prefix ({\it resp.} proper prefix) of  if there exists a word ({\it resp.} non-empty word) 
such that .

\paragraph{Bit round complexity:}
The bit complexity in general may be viewed as a natural
extension of communication complexity (introduced by Yao \cite{Yao})
to the analysis of tasks in a distributed setting. An introduction to the area can be found in Kushilevitz and Nisan \cite{KN}. 
In this paper, we follow the definition from~\cite{KOSS}, that is, the bit round complexity of an algorithm  is the total number of {\it bit rounds} it takes for  to terminate, where a bit round is a synchronous round with single bit messages. 
This measure captures into a single quantity aspects that relate both to time and to the amount of information exchanged. Other definitions are considered in the literature, in~\cite{BNNN90,BMW,BT90,DMR08} the bit complexity is the total number of bits sent until global termination. In~\cite{sw11}, it is the maximum number of bits sent through a same channel.
In both variants, silences may convey
much information, which is why we consider the definition from~\cite{KOSS} in terms of {\em round} complexity as more comprehensive.





\section{A spreading algorithm}
\label{sec:S}
We present a distributed spreading
algorithm 
using only messages of size   which allows each node to know
the highest identifier among the set of all identifiers with a time
complexity of , where  is the diameter of . This algorithm is the main component of the \STT algorithm, standing for the  in the acronym.

\subsection{Preamble}
 
Given
the binary representation  of an identifier,
we define 
 as the word


For instance, for the integer 23,  and . This encoding has the nice property that it extends the natural order  of integers into a lexicographic order  on their -encoding.



  \label{rem:lexicographic}
If  and  are two nodes with identifiers  and
,


As a result, the order between two identifiers  and 
is the order induced by the first letter which differs in  and .
This property is key to our algorithm, in which the spreading of identifiers progresses bitwise based on prefix comparisons.

\subsection{The  algorithm }
We describe here the spreading component of the algorithm, {\it i.e.} the  in \STT, whose purpose is to spread the largest identifier network-wide. For simplicity, we present here the algorithm independently from termination detection, which is dealt with in a dedicated section (Section~\ref{sec:STT}).

\subsubsection{Variables:} Each node can be  or , depending on whether it is still a candidate for becoming the leader (i.e. no higher identifier was detected so far). Each node  also has variables ,  and
  (one for each neighbour  of ) which are words over the alphabet .  is a shorthand for , it is set initially and never changes afterwards.  is a prefix of , for some node  (possibly  itself). It indicates the highest prefix known so far by .
On each node, this variable will eventually converge to the -encoding of the highest identifier. Finally, for each neighbour  of , 
 is the latest value of  known to . 

\subsubsection{Initialisation:} Initially every node  is , all the  are set to the empty word , and the  are accordingly set to the empty word.

\subsubsection{Main loop:}  In each round, the algorithm executes the following actions.
\begin{enumerate}[leftmargin=3em]
\item update  based on information received in the previous round,
\item send to all neighbours a signal indicating how  was updated,
\item receive such signals from neighbours,
\item update all the  accordingly.
\end{enumerate}

\noindent
The main action is the update of  (step 1).
It depends on the values of   for all neighbours  and 
  itself at the end of the previous round. 
This update is done according to a number of rules. For instance, as long as  remains  and  is a proper prefix of , the update consists in appending the next bit of  to . Most updates are more complex and detailed further below. The three other actions (step , , and  above) only serve the purpose of informing the neighbours as to how  was updated, so that all   are correctly updated. In fact,  can only be updated in {\em seven} possible ways, each causing the sending of a (constant size) particular signal among , with following meaning:
\begin{itemize}
\item  or :  was updated by appending a single  or a single ;
\item , , or :  was updated by deleting one, two or three letters from the end;
\item :  was updated by changing the last letter from  to ;
\item :  was not modified.
\end{itemize}


By the end of each round, it holds that  for all neighbours  of .
Thus from now on,   is simply written . Another invariant is that, by the end of each round, if  and  are two neighbours, then  and  must have a common prefix followed, in each case, by at most six letters (see the proof of Lemma 6 below, second item).

We now describe the way  is updated by each node  ({\it i.e.} step 1).
 
\subsubsection{Update of  in each round:}

Let us denote the state of some variable  {\em at the end} of round~ by . For instance, we write , where round  corresponds to initialisation.
The computation of  at round  results from  being active or follower, and from the values of 
  and  for all neighbours  of . 
It is done according to the following rules given in order of 
priority, i.e.,  has a higher priority than 
. 
(This does not apply between the subrules  and , for which a different criterion is specified.)
Whenever a rule is applied, the subsequent rules are ignored.
\begin{itemize}
\item[-] (delete). The relationship between  and  
for any neighbour
 of  may mean that a delete operation is possible. This may be done according to the two following subrules; if both are applicable, possibly relative to various neighbors, the one deleting the greatest number of letters is chosen. (In case of ties, the choice does not matter.)
\begin{itemize} 
\item[-] If some  is a proper prefix of  and 's 
last action was a ,
 is obtained by deleting the last 
letters of .
\item[-] If  with  and some , 
 is obtained by deleting the last
 letters of ;
\end{itemize}
\item[-] (change). If  and some  then     and
's state becomes     if it is ;

\item[-] (append). If  for some , , then
 is obtained by appending  to ; 
\item[-] (append). If for some ,  , then
 is obtained by appending  to ;
\item[-] (append). If 's state is  and ,
 is obtained by
appending  to ;
\end{itemize}

If none of these actions apply, then  and a  signal is sent. Otherwise, a signal corresponding to the resulting action is sent.
We now prove some properties on Algorithm~ including Corollary \ref{cor:bound3}
which shows that when  is applied,  so that the signal to be sent
is within our set of 7 signals.


\begin{lemma}
\label{lem:delete}
For all , if a node  carries out a  operation at round ,
's operation at round  must be another  operation
or a change operation.
\end{lemma}

\begin{proof}
By induction on . For , it is trivially true since there can be no
delete operation at round .
Suppose  makes a delete at time .
The delete operation  carried out 
at round  on  was made
possible by one or more neighbours of  according to rule
. Let  be one such neighbour.


\begin{itemize}
\item
If  was applied at round  on :
\begin{itemize}
\item   is a proper prefix of ,
\item  did a delete at round .
\end{itemize}
Thus 
 (for some
non-empty ), and
 is obtained from   by erasing at most 
letters at the end, i.e.,  for some .

By induction, 's action at round  is another  operation
or a change.
\begin{itemize}
\item If it is a  operation, 
then   is again obtained 
by erasing some letters at the end of 
thus it is a proper prefix of    and 
a proper prefix
of  and  
applies again at  on .
\item 
If it is a change operation then  (for some ), 
 Finally, 
and  either  is a non empty word and  applies with 
on ,
or  is the empty word and
 applies with  on :  will do a change at round  unless another neighbour makes a delete possible.
\end{itemize}
\item
Otherwise  was applied at round  on : 
\begin{itemize}
\item   with ,
\item  for some , and 
\item  by the delete operation at round .
\end{itemize}
Then:
\begin{itemize}
\item If the operation at round  on  was a delete operation,
according to whether
at least  is deleted or not, the operation on  at round 
 is
a   or a 
\item If the operation at round  on  is a , an 
or , then the operation on  at round
 is also a change (again unless
another neighbour makes a delete possible.)
\qed
\end{itemize}
\end{itemize}
\end{proof}

Lemma~\ref{lem:delete} induces immediately:
\begin{corollary}\label{delete-change}
A sequence of delete operations on a node  ends with a 
change operation on .
\end{corollary}

\begin{remark}\label{rem:active}
While a node  remains active and has
not performed a delete,  cannot be a proper prefix of any .
If  does perform a delete, by Corollary \ref{delete-change}, this delete
will be followed, possibly after other deletes, by a change.
That is the first rules applied to  other than  must be a
(possibly empty) sequence of deletes followed by an . When this  is applied,
 ceases to be active.
\end{remark}


\begin{lemma}
\label{lem:prefix}
For all ,
for every vertex , there is a vertex  such that  is a prefix of
.
\end{lemma}


\begin{proof}
By induction on .

By Remark \ref{rem:active}, while  remains active,
 is a prefix of .
Whenever  changes by rules , ,  or  as a result 
of a neighbour ,  is a prefix of  or .
\qed
\end{proof} 

In the following lemma and its proof,  always stands for a single letter,
 or .
\begin{lemma}
\label{lem:voisins}
Let  and  be two neighbours. Let  be a round number.
The words  and 
will always take one of the following forms (up to renaming of  and )
where  and  are words.
\begin{enumerate}
\item  and ,
\item   and  with ,
\item   and ,
\item   and  and ,
\item  and  and  and  performed
a delete in round .
\end{enumerate}
\end{lemma}

\begin{proof}
By induction on .

At round ,  and .

Without loss of generality, we will always consider the form given in the
lemma and not the reverse.



We consider the five possible relations between   and 
and show that in each case   and   still have one of the five
forms.
\begin{enumerate}
\item .
Each node may carry out any operation. If each carries
 out the same  operation, we remain in case 1. 
\begin{itemize}
\item If  does a :  and .
\begin{itemize}
\item If   does a , the 
 of  may be  or . 
\begin{itemize}
\item If it is 
 and  is obtained by truncating 1, 2 or 3 letters from
, the same as truncating the same number of letters from .
Thus  is a proper prefix of  giving case 2 if 1 or 2 letters were
deleted and case 5 otherwise.
\item If it is  then
 and  for some neighbour  of  with
. 
It corresponds to case 4, and thus the induction implies that
 and .
Thus ,  and  is a prefix
of . Finally, 
and  are linked again by relation 2 or 5.
\end{itemize}
\item If  does  an  or  it is case 4.
\end{itemize}

\item If  does a .
\begin{itemize}
\item If   does a  then one word will be a prefix of 
the other as in case 1 or case 2.
\item If  does an  or  it is case 2 or case 5.
\end{itemize}
\item  In the remaining cases both do  or  it is either case 2 
or case 4.
\end{itemize}

\item  and . 
\begin{itemize}
\item
 If  does a  any operation on  leaves one
word prefix of the other (again case 1, 2 or 5). 
Now,  and  giving the claimed bounds of  and  in cases 2 and 5 respectively.
\item If  does a  and if   does a 
we are in case 2 or 4. 
If  does any other operation, then we are in case 4.
\item If  does an , it must be an  if the first bit 
of  is 1 (since  has priority over ).
If  does an   the result will be case 2
if  appended the first bit of  or case 4 otherwise (if the first bit of  is  and  appended ).
If  does  the result will be case 2 or 4.
If  does  the result will be case 1, 2, 4 or 5.
\end{itemize}

\item . The node  will do  or  giving
  or a prefix of  respectively, again leaving one word a prefix 
of the other for any operation carried out by .
This gives case 1, 2 or 5.

\item  and  . 
\begin{itemize}
\item If ,  will do a delete of at least  bits (). If  does a delete or  deletes more than  bits, then one word is a prefix
of the other, leading to cases 1, 2 or 5.
If  appended a bit and  deletes  bits, then we get case 3.
If  did null and  deletes  bits, then we get case 4.
\item Otherwise ,  will do a change 
or a delete leaving one word a prefix of the other. Again
this gives case 1, 2 or 5.


\end{itemize}
\item ,  
where  has just performed a delete.
Then  will apply  and do a , and  a  operation or
a  operation (Lemma \ref{delete-change}).
leaving case 1, 2 or 5, or case 4 if the last bit
of  is 0 and  does a change.
\qed
\end{enumerate}
\end{proof}

Item 4 of lemma \ref{lem:voisins} is the only one which allows rule  to be applied, leading to:
\begin{corollary}
\label{cor:bound3}
If  is applied then
 and .
\end{corollary}

Lemma \ref{lem:voisins} implies:
\begin{theorem}\label{th:complexity}
Let  be a graph of size  and diameter  such that each node 
is endowed with a unique identifier  which is a
non-negative
integer.
Let  be the highest identifier.
After at most  rounds,  algorithm  terminates
(that is, after this time no node does any operation other than null)
and for each node , .
\end{theorem}

\begin{proof}
Let  be the node endowed with the highest identifier. 
Let  be a non negative integer.
By induction on  we prove that after at most  rounds
each node at distance at most  from 
has .
If  ever does a change, let the first round at which this happens be .
Then by Corollary \ref{delete-change}  is lexicographically greater
than  but by Lemma \ref{lem:prefix}  is a prefix of some
 contradicting the fact that  is the highest identifier.
Hence
 can never cease to be active,
and so
as long as ,
 applies  at round .
It follows that the Theorem is true for .

For the inductive step,
we assume that each node at distance at most  from 
has .
Let  be a node at distance  from . Let  be a node
at distance  from  and neighbour of .
By induction, .
Once a node  has , it will never do any operation other than null
because that would lead, possibly after a sequence of deletes, to a 
lexicographically greater than  contradicting Lemma \ref{lem:prefix}.
From Lemma \ref{lem:voisins} and knowing
that   where  is the highest identifier,
we deduce that  words  and 
will always take one of the following forms 
at round  where  and
 are words and  is the bit  or the bit :
(In all cases except the first  must be the lexicographically greater of the two.)
\begin{enumerate}
\item  and ,
\item   and  with ,
\item   and ,
\item   and  and ,
\item  and  and  and  has just performed
a delete.
\end{enumerate}
The fifth form is impossible since it would lead to , possibly after a sequence
of deletes, doing a change resulting in .
The first form has  already equal to .
In the second and third forms, similarly  cannot do a delete (or in the second form
a change) because that would lead
eventually to , so  becomes equal to  after,
respectively,  appends or a change and an append (of ).
In the fourth form,  will do a delete of  letters followed by a change to arrive at
.

Hence, after at most  rounds  and the
result follows.
\qed
\end{proof}

\section{A Spanning Tree Algorithm}
\label{sec:ST}
This section explains how the computation of a spanning tree may be associated 
to the spreading algorithm  by selecting for each node 
the edge through which  was modified.

Let  be a node, we add for each neighbour ,  a variable 
 whose possible values are in , which indicates the status of neighbour  at node ; initially 
.
The computation of the spanning tree occurs

concurrently with the spreading algorithm  as follows. If , , or  is applied at round  relative to neighbour , then 

chooses  as parent (if not already the case).
 is chosen arbitrarily among those of 's neighbours justifying the rule applied.
Then, in addition to the signals of the spreading algorithm (indicating how  was updated),  sends a signal  to  and a signal  to its previous parent

(if different from ), and it sets  to other (so that it never has more than one parent). As a result,  sets  to 
and  sets  to .

After  receiving signals from neighbours,
in addition to the computation of the new value of  for each neighbour
 by Algorithm 
,  updates .
Algorithm  
denotes the algorithm obtained with Rules of the spreading
algorithm  and actions described just above.


\begin{remark}\label{rem9}
By Remark \ref{rem:active}, the first rules applied to  other than  must be a
(possibly empty) sequence of deletes followed by an . When this  is applied,
 ceases to be active and acquires a parent. Thus a
node has no parent if and only if it  is active.
\end{remark}
\begin{remark}\label{15}
A node has at most one parent.
\end{remark}



The next definition introduces for each node  a
pair
 that is
used to prove that the graph induced by all the  relations has no cycle.
\begin{definition}
Let  be a node, let  be a round number of the spreading
algorithm ;  is equal to the maximum of  for ,
 is the minimum  such that  and  is the pair
.
\end{definition}
Every change in  produces a  which is lexicographically greater than , except a delete which produces a  which is a proper prefix of .
Hence  unless  did a delete at round  when  is a
proper prefix of .

\begin{definition}
Let  and  be two pairs  and .
 iff  or  and .
\end{definition}
In this order,  is monotonic non-decreasing in .
The following establishes that any non-active node has a parent with a greater value of . 
\begin{lemma}\label{18}
Let  be a round number. Let 
 be a node. Then either  is active or there exist 
  nodes of 
such that: for   is parent of  and  
is active.
\end{lemma}
\begin{proof}
  If  becomes parent of  at round ,
  then  has done a {\it change} or an {\it append} at .
Inspecting rules  and  show that  .
 since  did not do a delete at  and  
by the definition of  as a maximum.
Hence  and round  is the first at which  has attained
this value
and so . Then  remains greater than  until  next
increases and a node  (possibly the same as ) becomes parent of .
Hence if  is parent of  at the end of round , .\qed
\end{proof}

\begin{definition}
We say that algorithm  terminates when algorithm  terminates,
that is no rules of algorithm  apply at any node.
We denote by  
the subgraph of  having  as node set and such that
there is an edge between the node  and the node  
if  is the parent of  or  is the parent of  when algorithm
 terminates.
\end{definition}

By Theorem \ref{th:complexity},
when Algorithm   terminates there is exactly one  node:
the node with highest identifier.
Now, from Remark \ref{rem9} and \ref{15}, and Lemma~\ref{18}:
\begin{proposition}\label{21}
Let  be a connected graph such that each node has a unique
identifier. Let  be the node with the highest identifier.
When algorithm  terminates,
the graph  is a spanning tree of  with  as root.
\end{proposition}

\section{Termination Detection of Algorithm }
\label{sec:STT}
This section presents some actions  which, added to algorithm
, enable  the node with the highest identifier to detect
termination of algorithm ; furthermore, as it is the only one,
when it detects the termination it becomes elected.
Our solution is a bitwise adaptation of the propagation process with feedback introduced in \cite{S} and further formalised and studied in Chapter~6 and~7
of~\cite{Tel}. 

\begin{definition}
Let  be a node. Let  be a round number of the spreading
algorithm. The variable  is said to be
well-formed if there exists an identifier 
 such that .
\end{definition}

To determine if  is well-formed, node  can check whether , where  is the number of 's before the first .
Each node  is equipped with a boolean variable 
 which is  iff  and all of its subtrees have terminated.
Whenever a rule of the spreading algorithm is applied to node 
or a node  becomes a child of ,
the variable  is set to , and a signal is sent to its 
neighbours to indicate that . Indeed, this variable can be updated
several times for a same node before stabilizing to . 

We describe an extra rule to be added to the 
 algorithm in order to allow the node
with highest identifier to learn that it is so by detecting
termination of the spanning tree  algorithm.
This rule is considered {\em after} those of algorithm  in each round.
Let us denote by  the set of neighbours of , and by  those which are 's children. Also recall that we omit the round number in the expression on variables when it is non-ambiguous.

\paragraph{The rule:} Given a node , if ( is follower) and ()
and ( is well-formed)
and ( ) and ( )
then .
Furthermore  sends to his parent a signal indicating that .


We denote by \STT
 the algorithm obtained  by putting  together the rules
 of Algorithm  and this extra rule for termination detection.

Whenever  changes, a rule of algorithm  has been applied to 
 and so  is set to false. Thus
if   then  has the same value  it had when 
became  the last time.

We say that algorithm \STT terminates when every node  other than the node 
with the greatest identifier has  and  and so
no node has any actions applicable.

From Theorem~\ref{th:complexity} and Proposition~\ref{21}, we know that ST will terminate, at which time all leaves of the constructed spanning tree will have , and a termination signal takes at most  rounds to propagate to the root. This implies:
\begin{proposition}
  \label{prop:STTterm}
Let  be a graph such that each node has a unique (integer) identifier. 
Algorithm \STT terminates within  rounds after the termination of . Furthermore,
if the node  has the highest identifier then,  after a run of 
algorithm \STT,  for each neighbour  of 
   and  and 
the node  receives from each node  in  the signal 
indicating that .
\end{proposition}

The next proposition
establishes
that only the node with highest identifier
can receive a termination signal from all neighbours.

\begin{proposition}\label{prop:term}
Let  be a graph such that each node has a unique identifier.
Let  be a node which has not the highest identifier and 
such that  and for each neighbour  of 
. Then there exists a neighbour  of  such that 
.
\end{proposition}

\begin{proof}
Suppose that some  which does not have the maximum identifier
does have in some round  and for each neighbour  of 
 and . We will deduce a contradiction.

Write  for .
Define  as the set of nodes  such that 
and the -parent of  as the node  which becomes
parent of  when  becomes  (say at round ).
Since no  is a prefix of another ,
we have  and
once , the next modification of  can only be a delete or a change,
which implies that  cannot become  a second time.
 is also in  and so following the chain of
-parents from  must end at .
Thus any node in  is a -descendant of .

Suppose a node  has  and sets  true at round . Then all
neighbours of  have  and so any -child 
of  has not changed
 since it became ; so  is still a child of .
Hence .
Repeating this argument, any -descendant of  had  and
set  at some time .

Since by supposition every neighbour  of  has  and , 
every node in 
has  and
sets  at some time . So any neighbour of a node
in  is also in . Since  is connected all nodes of 
are in .

In particular the node with highest identifier is in ,
implying that it has an A-parent and so became a follower during the execution
in contradiction with the fact that it is always active.

\qed
\end{proof}
If the node  with highest identifier, 
 becomes  as soon as, for each neighbour  of , 
  and  
and it receives 
from each child   the signal 
indicating that  we deduce:

\begin{theorem}
\label{th:main}
There exists an election algorithm for graphs 
in which each node has a unique integer identifier, using
messages of size  which terminates
after at most  rounds
where  is the node with the highest identifier.
\end{theorem}

The time bound follows from Theorem~\ref{th:complexity} and Proposition~\ref{prop:STTterm}.


\section{Further Related Work}
\label{sec:related}

We provide here a more detailed account of the literature on the leader election problem, which recounts and extends references mentioned in Section~\ref{sec:introduction}. The election problem is fundamental in distributed computing and, indeed, there exists
a vast body of literature on the topic -- see for instance the treatment of this problem in standard books~\cite{Tel,Attiya,Lynch,Santoro} and references therein.
This problem is close to that of spanning tree construction, and it seems that it was first formulated by LeLann~\cite{LeLann}. 
As indicated in \cite{KPPRT15}, some simple questions are still open and therefore this is still a problem which is much alive in the distributed computing community.
Usually, this problem is investigated in one of the following three directions:
\begin{enumerate}
\item Characterisation of (anonymous) graphs for which there  exists a 
deterministic election algorithm;
\item Lower and upper bounds of the time complexity and the message
complexity of deterministic election algorithms
depending on how much is initially known about the graph, 
it is assumed that each node has a unique identifier;
\item Randomised election algorithms for anonymous graphs 
depending on the knowledge on the graph such as the size, the diameter
or the topology (trees, complete graphs...).
\end{enumerate}

For the first item  the starting point is the seminal  work of Angluin
\cite{Angluin} which
 highlights, in particular, the key role of coverings: a graph  is a 
covering of a graph  if there is a surjective homomorphism
 from  to  which is locally bijective (the restriction of
 to incident edges of any node  is a bijection between
incident edges of  and incident edges of ).
 More general definitions may be found in \cite{BVfibrations}.
Characterisations of graphs for which there exists an election algorithm
depend on the model.
The first  characterisations were obtained in
\cite{BVelection,YKsolvable,MazurEnum}.
The fundamental tool in 
\cite{BVelection,YKsolvable} is the notion of view: the view from a node
 of a labelled graph  is an infinite labelled tree rooted in 
obtained by considering all labelled walks in  starting from .
The characterisation in \cite{MazurEnum} used non-ambiguous graphs:
a graph labelling is said to be locally bijective if vertices with the same
label are not in the same ball and 
have isomorphic labelled neighbourhoods. A graph  is   ambiguous 
if there exists a non-bijective
  labelling of  which is locally bijective.
In \cite{GMMrecog}, authors  prove that  the non-ambiguous graphs, as 
introduced by Mazurkiewicz, are exactly
the covering-minimal graphs.
The main ideas of the election algorithm developed in  
\cite{MazurEnum} were applied 
 to some other models in
\cite{CMasynj,CMsynchro,Csofsem} by adapting the notion of covering.
A characterisation of families of graphs which admit an election algorithm
(i.e., the same algorithm works on each graph of the family)
can be found in \cite{CGM12}.

Concerning the second item, lower bounds or upper bounds for deterministic algorithms
when nodes have a unique identifier which is a non negative
integer of size :
\begin{itemize}
\item {\it for the time complexity:}
Peleg presents in \cite{Peleg90} a simple time optimal election algorithm
for general graphs: its time complexity is ;
 the size of
messages is  thus its bit round complexity is
 and the message complexity is 
where  is the size of the edge set.
More recently, Kutten et al. \cite{KPPRT15}
prove the lower bound  for the time
complexity in a very general context which contains the deterministic case
studied in this paper. Fusco and Pelc \cite{FP15} show that the 
time complexity
of the election problem is
 where  is the level of symmetry
of the graph  (Let  be graph. 
The view at depth  from a node is the tree of all paths
of length  originating at this node. The symmetry of  is the
smallest depth at which some node has a unique view of ).
In our case, each node has  a unique identifier thus , and we obtain
the same bound as~\cite{KPPRT15}.
\item {\it for the message complexity:}
Gallager \cite{Gallager} presents the first election 
algorithm for general graphs with  messages, 
where  is the number of edges.
On the negative side, Burns~\cite{burns1980} prove a  lower bound and Kutten et al.~\cite{KPPRT15} a  lower bound which applies even if  is known and the algorithm is randomized. Put together, both lower bounds yield a matching  number of messages. (Santoro~\cite{Santoro84} also proves a  lower bound for the more specific problem of finding the maximum ID, in a deterministic setting with  unknown.)
The work presented in \cite{GHS83} had a
great influence on many papers, the time complexity of the algorithm 
is  and the message complexity is optimal  in the worst case.
Optimal message complexity in  has been obtained 
also in \cite{Awer87}, in this case the time complexity is , the size 
of message is  and the
bit round complexity is .
We can note that very efficient algorithms for both election
and spanning tree computation are presented in \cite{KKM90}.
\end{itemize}
This direction has also been subject to recent developments where the impact of particular knowledge is studied such as~\cite{DP16,GMP17,MP16}. Finally, the tradeoff between time and communication complexity in the case of leader election and spanning tree was considered in~\cite{KK13} in the case of ad hoc networks, when only the neighbors are known to nodes.


Regarding the third item, probabilistic algorithms, a Las Vegas algorithm is one which terminates
with a positive probability (in general ) and always produces
 a correct result.
A Monte Carlo algorithm is a probabilistic algorithm which always
terminates; nevertheless the result may be wrong with non-zero
probability.
Some results on graphs having
 vertices are expressed with high probability,
meaning with probability  (w.h.p. for short).
Chapter  of \cite{Tel} and \cite{lavault}
give a survey of what can be done and of
impossibility results in anonymous networks concerning the election problem.
  In particular, no
deterministic algorithm can elect (see Angluin \cite{Angluin}, Attiya
et al. \cite{ASW} and Yamashita and Kameda \cite{YK88}); furthermore,
with no knowledge on the network, there exists no Las Vegas election
algorithm \cite{IR90}. 
In~\cite{KuPPRT15}, Kutten et al. present a leader election algorithm to elect (implicitly) a leader (with high probability) that runs in  time using a sublinear amount of messages, namely .
Monte Carlo election algorithms for anonymous
graphs without knowledge are presented in \cite{IR90,AM94,SS94}.
They are correct
with probability , where  is fixed
and known to all vertices. M{\'e}tivier et al.~\cite{MRZ15} presents
 Monte Carlo algorithms
which solve the problems discussed above w.h.p. 
 and which ensure for each node  
an error probability bounded by  where  is
determined by  in a fully decentralised way. To be more precise,
these 
algorithms ensure an error probability bounded by 
where  
is the smallest value among the set of error probabilities
determined  independently by each node.
If the network size is known then Las Vegas election algorithms exist, e.g., in~\cite{IR90}.
Finally, recent works like~\cite{GRS18} explore the role played by other network parameters such as conductance and expansion, and some questions in the same spirit as the ones we addressed in this article regarding tradeoff between time complexity and communication complexity are still open.

\section{Conclusion}
\label{sec:conclusion}
This article focused on the problem of deterministic election in arbitrary networks with unique identifiers. Three complexity measures were discussed in general: time complexity, message complexity, and bit (round) complexity.
It was known that  is a lower bound for the number of messages and an algorithm with matching complexity exists.
In~\cite{KPPRT15}, Kutten et al. show that concerning the time
complexity  is a lower bound and~\cite{Peleg90} implies that
 is a tight upper bound. 
For bit (round) complexity, we deduced from~\cite{KPPRT15} and~\cite{DS07}
that   is a lower bound and we presented 
an algorithm that matches this bound with a running time of  bit rounds. This algorithm is the first whose bit round complexity breaks the  barrier, and furthermore, through its optimality in terms of bit rounds, it gives a positive answer to whether optimality can be
achieved
both in time and in the amount of communication, which question was thought to be settled due to the impossibility to satisfy both when messages are (as is frequently assumed) of size . As such, our results also make a case for studying the complexity of algorithms through the lenses of bit round complexity. Finally, it could be interesting to explore whether some of the techniques presented in this article are applicable when the size of messages is less constrained, e.g., logarithmic (CONGEST model).

\subsection*{Acknowledgment} We thank the anonymous referees for their many helpful comments on an earlier version of this article.

\bibliographystyle{plain}
\bibliography{election}

\end{document}
