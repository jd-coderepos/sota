
Our \crc system is designed to sustain a predefined level
of reliability, \textit{i.e.} of data redundancy, by recovering from
failures with a limited impact on performances. We assume that the
failure detection is performed by a monitoring system, the description of which is out of the scope of this paper. We also assume that this system 
triggers the repair process, assigning new nodes to replace the faulty ones,
in charge of recovering the lost data and store it.

The predefined reliability level  is set by the storage system 
operator. This reliability level then directly translates into the
redundancy factor to be applied to files to be stored, with parameters
$k$ (number of blocks sufficient to retrieve a file) and $n$ (total
number of redundant blocks for a file). A typical scenario for using
\crc is a storage cluster like in the Google File
System~\cite{gfs}, where files are streamed into extents of the same
size, for example 1GB as in Windows Azure Storage~\cite{azure}.
These extents are erasure coded in order to save storage space.

\subsection{A Cluster-based Approach}

To provide an efficient maintenance, \crc relies on \textit{(i)} hosting  all blocks related to a set of files on a single cluster of nodes, and \textit{(ii)} repairing multiple files simultaneously .  This is achieved by combining the use of random codes, network coding and a cluster-based placement strategy. This enables to repair several files simultaneously, without requiring computationally intensive decoding operations, thus factorizing the costs of repair across the several multiple files stored by the faulty node. To this end, the system is  partitioned into disjoint clusters of $n$ nodes,
 so that each node of the storage system belongs to one and only one cluster. 
Each file to be stored is encoded using random codes and is associated to a single cluster. All blocks of a given file are then stored on the $n$ nodes of the same cluster. In other words, \crc placement strategy consists in storing blocks of two different files belonging to the same cluster on the same set of nodes, as illustrated on Figure~\ref{clusterPlacement}.

In such a setup, the storage system manager (\textit{e.g.} the master
node in the Google File System~\cite{gfs}) only needs to maintain two
data structures: an index which maps each file to one cluster and an
index by cluster which contains the set of the identifier of nodes in
this cluster. This simple data placement scheme leads to 
 significant data transfer gains and better load balancing, by clustering operations
on encoded blocks, as explained in the remaining part of this section.

\begin{figure}[t]    
\vspace{-0.8cm}
  \begin{center}    
 \includegraphics[scale=0.34]{./Figures/ClusterPlacement.pdf} 
  \caption{Clustered placement for a $n=3$ redundant system}  
   \label{clusterPlacement}    
\end{center}     
   \end{figure}

\subsection{Maintenance of \crc}

When a node failure is declared, the maintenance operation must ensure that all the blocks hosted on the faulty node are repaired in order to preserve the redundancy factor and hence the predefined reliability level of the system. Repair is usually performed at the granularity of a file. Yet, a node failure typically leads to the loss of several blocks, involving several files. This is precisely this characteristic that \crc leverages. Typically, when a node fails,  multiple repairs are triggered, one for each particular block of one file that the failed node was storing.  Traditional approaches using erasure codes actually consider a failed node as the failure of all of its blocks.   \textbf{Instead, the novelty of \crc is to leverage network coding at the node level, \textit{i.e.} between different files on a particular cluster.} This is possible since \crc placement strategy clusters files so that all nodes of a cluster store the same files.  This technical shift enables to significantly reduce the data to be transferred during the maintenance process.

\begin{figure*}[t!] 
 \begin{center}    
 \includegraphics[scale=0.5]{./Figures/RepairMechanism.pdf} 
    \caption{Example of a \crc repair process, for the repair of a new node in a cluster of $4$ (with $k=2, n=4$).}   
    \label{repairMechanism}   
  \end{center}     
   \end{figure*}
   
\subsection{An Illustrating Example}
To provide the intuition of \crc, and before generalizing in the next
section, we now describe a simple example (see
Figure~\ref{repairMechanism}) involving  two files and a 4 node
cluster.  We consider two files X and Y of size $\mathcal{M}=1024$ MB, encoded with
random codes ($k=2$, $n=4$), stored on the 4 nodes of the same cluster
(\textit{i.e.} Nodes 1 to 4). File X is chunked into $k=2$ chunks $X_1$, $X_2$ as well as file Y into chunks $Y_1$ and $Y_2$. Each node stores two encoded blocks, one related to file X and the other to file Y which are respectively a random linear combination of $\lbrace X_1,X_2 \rbrace$ and $\lbrace Y_1,Y_2 \rbrace$. Each block has a size of $\frac{\mathcal{M}}{k}=512$ MB, thus each
node stores a total of $2\times512=1024$ MB.  We now consider the
failure of Node 4.

In a classical repair process, the new node asks to $k=2$ nodes their block corresponding to file X and Y and thus downloads 4 blocks, for a total of $4\times512=2048$ MB. This enables the new node to  decode the two files independently, and then re-encode each file to regenerate one block for file X and one for file Y and store them.  

Instead, \crc  leverages the fact that the encoded blocks related to files X and Y are stored on the same node and restored on the same new node to encode the files together rather than independently during the repair process. More precisely, if the nodes are able to compute a linear combination of their encoded blocks, we can prove that if $k=2$, only 3 blocks are sufficient to perform the repair of the two files X and Y. Thus the transfer of only $3$ blocks incurs the download of $3\times512=1536$ MB, instead of the $2048$ MB needed with the classical repair process.  In addition, this repair can be processed without decoding any of the two files. In practice, the new node has to contact the three remaining nodes to perform the repair. Each of the three nodes sends the new node a random linear combination of its two blocks with the associated coefficients. Note that the two files are now mixed, \textit{i.e.} encoded together. However, we want to be able to access each file independently after the repair. \textbf{The challenge is thus to create two new random blocks, with the restrictions that one is only a random linear combination of the X blocks, and the other of the Y blocks.}
In this example, finding the appropriate coefficients in order to cancel the $X_i$ or $Y_i$,  comes down to solve two independent systems of two equations with three unknowns as shown in Figure~\ref{repairMechanism}. The intuition is that, as coefficients of these equations are random, these two systems are always solvable \textit{w.h.p.}. The new node then makes two different linear combinations of the three received blocks according to the previously computed coefficients, $(A,B,C)$ and $(D,E,G)$ in the example. Thereby it creates two new independent random blocks, one related to file X and one to file Y. The repair is then performed, saving the bandwidth consumed by the transfer of one block \emph{i.e.}, $512$ MB in this example. 

\subsection{\crc: The General Case}
\label{generalCase}



We now generalize the previous example for any $k$. We first define a \textit{RepairBlock} object: a RepairBlock is a random linear combination of two encoded blocks of two different files stored on a given node. RepairBlocks are transient objects which only exist during the maintenance process \emph{i.e.}, RepairBlocks are never stored permanently.

We are now able to formulate the core technical result of this paper; the
following proposition applies in a context where different files are
encoded using random codes with the same $k$, and the encoded blocks
are placed according to the cluster placement described in the
previous section.

\begin{prop} 
\label{prop1}
In order to repair two different files, downloading $k+1$ RepairBlocks
from $k+1$ different nodes is a sufficient condition.
\end{prop}

Repairing two files jointly actually comes down to create one new
random block for each of the two files; the formal proof of this
proposition is given in Appendix. This proposition implies that
instead of having to download $2k$ blocks as with Reed-Solomon codes
when repairing, \crc decreases that need to
only $k+1$.  Other implications and analysis are detailed in the next section.

We shall notice that the encoded blocks of the two files do not need to have the same size. In case of different sizes, the smallest is simply zero-padded during the network coding operations as usually done in this context; padding is then removed at the end of the repair process.



\begin{figure}[t] 
\vspace{-0.5cm}
 \begin{center}    
 \includegraphics[trim = 1cm 0cm 1cm 1cm,scale=0.34]{./Figures/OurRepairProcess.pdf} 
    \caption{One iteration of the repair process, at the end of which two encoded blocks are repaired.}   
    \label{ourRepairProcess}   
  \end{center}     
   \end{figure}

Figure~\ref{ourRepairProcess} describes one iteration of the process at the end of which two encoded blocks are repaired. Each of the $k+1$ nodes sends a RepairBlock to the new node, which then combines them to restore the two lost encoded blocks. However nodes usually store far more than two blocks, implying multiple iterations of the process described in Figure~\ref{ourRepairProcess}.
More formally, to restore a failed node which was storing $x$ blocks, the repair process must be iterated $\frac{x}{2}$ times. In fact, as two new blocks are repaired during each iteration, the number of iteration is halved compared to the classical repair process.
Note that in case of an odd number of blocks stored, the repair process is iterated until only one block remains. The last block is repaired downloading $k$ blocks of the corresponding file which are then randomly combined to conclude the repair. The overhead related to the repair of the last block in case of an odd block number vanishes with a growing number of blocks stored. 



The fact that the repair process must be iterated several times can also be leveraged to balance the bandwidth load over all the nodes in the cluster.
Only $k+1$ nodes over the $n$ of the cluster are selected at each iteration of the repair process; as all nodes of the cluster have a symmetrical role, a different set of $k+1$ nodes can be selected at each iteration.
In order to leverage the whole available bandwidth of the cluster, \crc makes use of a random selection of these $k+1$ nodes at each iteration.
In other words, for each round of the repair process, the new node selects $k+1$ nodes over the $n$ cluster nodes randomly. 
Doing so, we show that every node is evenly loaded \emph{i.e.}, each node sends the same number of RepairBlocks in expectation. 

More formally, let N be the number of RepairBlocks sent by a given node. In a cluster where $n$ nodes participate in the maintenance operation, for $T$ iterations of the repair process, the average number of RepairBlocks sent by each node is : 
\begin{equation}
\label{meanLoad}
E(N) = T\frac{k+1}{n}
\end{equation} 

The proof is given in Appendix.
An example illustrating this proposition is provided in the next section.


