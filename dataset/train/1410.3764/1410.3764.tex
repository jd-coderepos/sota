 \documentclass[12pt]{amsart}
\usepackage[foot]{amsaddr}
\usepackage[a4paper,oneside,DIV12]{typearea}
\usepackage{amssymb}
\usepackage{xspace}
\usepackage{ifthen}
\usepackage{url}
\usepackage{enumerate}                     







\usepackage{soul}
\usepackage{tikz}
\usetikzlibrary{arrows,matrix,decorations,arrows,shapes}
\tikzstyle vertex=[circle, line width=0.2mm, draw, fill=black, inner sep=0mm, minimum width=1mm]\tikzstyle{edge} = [draw]

\usepackage[ruled,noline,titlenumbered,linesnumbered,noend,norelsize]{algorithm2e}
\DontPrintSemicolon
\SetNlSty{footnotesize}{}{}
\IncMargin{0.5em}
\SetNlSkip{1em}
\SetKwIF{If}{ElseIf}{Else}{if}{then}{else if}{else}{endif}
\SetKw{Return}{return}
\SetKw{Let}{let}


\newenvironment{algorithm-hbox}{\hbadness=10000\begin{algorithm}}{\end{algorithm}}

\renewcommand{\phi}{\varphi}
\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}




\usepackage{marginnote}

\newcommand{\note}[1]{{\bf\color{red}[[#1]]}}
\newcommand{\notem}[1]{{\bf\color{red}[[#1]]}\marginnote{{\footnotesize\bf\color{red} NOTE \color{black}}}}

\newcommand{\todo}[1]{{\bf\color{black!60!blue}[[#1]]}}
\newcommand{\todom}[1]{{\bf\color{black!60!blue}[[#1]]}\marginnote{{\footnotesize\bf\color{black!60!blue} TODO \color{black}}}}

\newcommand{\ins}[1]{{\color{black!60!green}[[#1]]}}
\newcommand{\insm}[1]{{\color{black!60!green}[[#1]]}\marginnote{{\color{black!60!green}\footnotesize\bf INSERT \color{black}}}}

\newcommand{\del}[1]{{\color{gray}[[#1]]}}
\newcommand{\delm}[1]{{\color{gray}[[#1]]}\marginnote{{\color{black}\footnotesize\bf DELETE}}}



\newtheorem{theorem}{Theorem}[section]
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{fact}[theorem]{Claim}
\newtheorem{lemma}[theorem]{Lemma}

\theoremstyle{definition}
\newtheorem{problem}{Problem}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{defn}[theorem]{Definition}






\newcommand{\abs}[1]{\left\vert#1\right\vert}





\newcommand{\Alg}[0]{\textsf{BALANCED}\xspace}
\newcommand{\Br}{Builder\xspace}
\newcommand{\Sr}{Scheduler\xspace}

\DeclareMathOperator{\Val}{val}
\DeclareMathOperator{\bal}{bal}

\newcommand{\eqA}{\Phi}
\newcommand{\eqB}{\Psi}

\newcommand{\vr}[1]{\mathbf{#1}}


\allowdisplaybreaks[1]
\begin{document}



\title{A lazy approach to on-line bipartite matching}

\author[J.\ Kozik]{Jakub Kozik} 
\email{Jakub.Kozik@tcs.uj.edu.pl}\thanks{Research of J.\ Kozik was supported by Polish National Science Center UMO-2011/03/D/ST6/01370.}

\author[G.\ Matecki]{Grzegorz Matecki}
\email{Grzegorz.Matecki@tcs.uj.edu.pl}\thanks{Research of G.\ Matecki was supported by Polish National Science Center 2011/03/B/ST6/01367.}
\address{
  Theoretical Computer Science\\
  Faculty of Mathematics and
  Computer Science\\Jagiellonian University in Krak\'{o}w\\
Poland}



\keywords{on-line, bipartite matching, adaptive algorithm}

\begin{abstract}
We present a new approach, called a lazy matching, to the problem of on-line matching on bipartite graphs.
Imagine that one side of a graph is given and the vertices of the other side are arriving on-line.
Originally, incoming vertex is either irrevocably matched to an another element or stays forever unmatched.
A lazy algorithm is allowed to match a new vertex to a group of elements (possibly empty) and afterwords, forced against next vertices, may give up parts of the group. 
The restriction is that all the time each element is in at most one group.
We present an optimal lazy algorithm (deterministic) and prove that its competitive ratio equals .
The lazy approach allows us to break the barrier of , which is the best  competitive ratio that can be guaranteed by any deterministic algorithm in the classical on-line matching.
\end{abstract}

\maketitle

\section{Introduction}
Many problems of task-server assignment can be modeled as finding a matching in a bipartite graph . 
Vertices of one part (set ) correspond to servers, and the vertices of the other (set ) -- to tasks. 
An edge between a task and a server indicates that the server is capable of performing the task. 
In a simple  setting, when one server can realize at most one task, the problem of maximization of the number of realized tasks reduces to finding a maximum matching.
In real-life applications it is very common that not all tasks are known a priori and some decisions about assignments have to be taken with no knowledge about future tasks. 
A simple model for this situation is on-line bipartite matching. 
In this setting servers are known from the beginning and tasks are revealed one by one. 
The decision about assignment of each task has to be made just after its arrival and cannot be changed in the future.   
Suppose that there are  servers,  tasks are going to be revealed, and capabilities of servers are such that it is possible to realize all the tasks.
(i.e.\ there exists a perfect matching in the tasks-servers graph). 
It is an easy exercise to show that even with these restrictions it is possible to present tasks in such a way, that the constructed assignment is at most . 
On the other hand, any greedy assignment strategy guarantees that at least half of the tasks will be assigned. 

In their classical contribution Karp, Vazirani, and Vazirani~\cite{KVV90} take other approach in which the graph to be presented is fixed before the first task is presented. 
In particular the presented graph does not depend on the decisions of the assigning algorithm. 
It does not make any difference for the worst-case analysis of the algorithm, but the approach provides a framework for analyzing randomized ones. 
The authors presented a randomized algorithm which on the average constructs a matching of size at least . 
They also argued that the result is asymptotically best possible for any randomized algorithm (the original paper~\cite{KVV90} contained a mistake, which has been corrected in~\cite{GM2008}, see also a simplified exposition~\cite{BM2008}). 
The approach of~\cite{KVV90} has been applied to many variants of the original problem, with various practical applications (switch routing problem~\cite{AC2006, AR2003}, on-line auctions~\cite{MGS2011}, Adwords problem~\cite{DH2009, GM2008, MSV2007} etc.) 
Recently a lot of interest is put into a problem of on-line stochastic matching~\cite{BK2010, FMMM2009, KMT2011, MGS2011, MP2012} where a competitive ratio can be  greater than .
A different approach (called -matching) is presented in~\cite{KalKir2000} where authors allow a server to realize up to  tasks at the same time. 
They showed an optimal deterministic algorithm with  competitive ratio  (which tends to  with ).


It is not hard to imagine a situation that the cost of a running server is roughly the same as the cost of an idle server. 
It might be profitable to start to realize some task on many servers simultaneously.
In this work, we allow our algorithm to assign more than one server to an incoming task, and later on gradually giving up its computations and switch some servers to yet another tasks.
Clearly, it is sufficient that at least one server completes the computations of a task.
This enables to postpone the decision about which server is going to accomplish a given task. 
With this settings we present an algorithm matching at least  vertices where  is the maximum size of a matching in the whole presented bipartite graph.


The lazy approach was first introduced by Felsner in~\cite{Fel97} 
as an adaptive generalization of the on-line chain partitioning problem. 
His adaptive on-line modification is in our terms a lazy approach to chain partitioning of posets (see also~\cite{Kloch07}).
It is still open and seems challenging to verify if adaptive (lazy) approach to chain partitioning allows more efficient on-line algorithms.

\subsection{Related Work}
The problem of -matching seems similar to lazy matching only the roles of servers and tasks are switched. 
However, in the lazy approach an algorithm always ends up with matching of type one to one, while a -matching algorithm can assign one server to many tasks.

Another similar approach was proposed by Feldman et al.\ ~\cite{FMMMa2009} as \emph{free disposal}.
They consider the weighted matching problem where each incoming vertex  may be assigned to one of its neighbors or left alone.
Each vertex  accepts at most  vertices from  with highest-weighted edges.
Here roles of servers and tasks are switched. 
All tasks are given at once and servers are incoming on-line. 
Each server has to be assigned to at most one task. 
In the end, each task chooses at most  servers from all the servers assigned to it  -- the ones with the highest-weighted edge.
The main difference from the lazy approach is that once a connection between a server and a task is established it cannot be changed till the very end.
There is no such restriction in the lazy approach -- a server may drop its task and take a new one during the on-line process.

The idea of dropping an edge from already constructed matching
is investigated in the \emph{preemptive model}. 
Here, edges with weights are incoming on-line and algorithm is allowed to remove previously accepted edges in order to add a new one.
A collection of results on preemptive matching can be found in~\cite{CTV2015,ELSW2013}.


\subsection{Problem definition}\label{sec:definition}


For a positive integer , the \emph{-lazy matching game} is played in rounds between \Sr and \Br. 
They play on a set of vertices , known in advance.
There is finite number of rounds and in each round:
\begin{enumerate}
	\item \Br presents a vertex  and reveals its neighbors .
	\item \Sr assigns to  a set  of size at most  \label{game:2}\\
	  and updates  for every vertex  presented before.
\end{enumerate}
Let  be the set of all vertices presented by \Br in the game and let  be an underlying bipartite graph with  when , for all .
Now, the \emph{size}  of the game is the maximum size of a matching in .
{If either  for all  or more generally  then the game is called \emph{-lazy matching} or simply \emph{lazy matching}.} We refer to this by writing .

The goal of \Sr is to maximize the number of nonempty sets  over all vertices . 
Intuitively, such vertex  is successfully matched with arbitrary chosen . 
We  refer to this number as \emph{the size of the matching constructed by Scheduler}.
The goal of \Br is just the opposite, he disturbs \Sr as much as he can.

The interpretation of -lazy game into servers-tasks assignment is clear:  is the set of servers,  is the set of incoming tasks
and algorithm assigns servers in  to an incoming  (possibly canceling previous computations on servers in ).
The quality of Scheduler is measured by the number (or the fraction) of tasks which are being realized at the end of the game. 
Note that for  the game reduces to the classical on-line bipartite matching.

Let  be an algorithm which assigns incoming tasks. 
We denote by  the worst case value of the matching constructed by  in all possible games of size . 
The value of the -lazy matching problem  is the maximum value of  among all -assigning algorithms . 
Since no algorithm produces matching larger that  we additionally use a \emph{competitive ratio} defined as
.
 
 

\subsection{Main results}
To solve the problem of -lazy on-line matching we consider a deterministic algorithm, called -\Alg{}.
The algorithm is described in Section~\ref{sect:best_alg}. 
It behaves greedy, i.e., no task is rejected if there is a possibility to run it, and tries to locally balance the sizes of all .
We prove -\Alg{} algorithm is the best possible one.
\begin{theorem}\label{thm:optimal-bal}
  -\Alg{} is an optimal strategy for \Sr in the -lazy matching game.
\end{theorem}

The next two sections are to prove the theorem.
The proof is split into two parts.
The following schema of system of inequalities is crucial for both arguments:



We are going to work with  and  fixed. 
Then, the schema is parametrized by a positive integer .
We say that a pair  satisfy system~\eqref{ineq:main-res} if  is an integer vector satisfying instance of the schema for this particular .

In Section~\ref{sect:worst_adapive}, we prove (Proposition~\ref{prop:spoiler_bound}) that for every solution  of~\eqref{ineq:main-res}, every -lazy algorithm  can be cheated by some \Br's strategy in a game of size  so that  matches at most  vertices.
On the other hand, in Section~\ref{sect:best_alg}, we show (Proposition~\ref{prop:balanced_bound}) that when -\Alg{} constructs a matching of size  in a game of size , then  for some  satisfying~\eqref{ineq:main-res}.
These two facts ensure -\Alg{} is the optimal strategy for \Sr.

In order to determine the competitive ratio of -\Alg{} we need to maximize the sum  over all feasible solutions  of~\eqref{ineq:main-res}.
In Section~\ref{sect:comp} we present the linear programming formulation of~\eqref{ineq:main-res} which, with the use of the Complementary Slackness Theorem, can be easily solved. Finally, we prove
\begin{theorem}\label{thm:ratio}
 The competitive ratio of -lazy on-line matching problem on bipartite graphs 
 (and the competitive ratio of 
 -\Alg{} algorithm)  equals
. For  it converges to .
\end{theorem}
The ratio converges fast and for  it is almost optimal, i.e.,  and , respectively.

\section{Worst case scenario for a lazy algorithm}
\label{sect:worst_adapive}
Inequalities~\eqref{ineq:main-res} allow  to be negative. 
We start with an observation
that in order to maximize the sum  it suffices 
to consider solutions of~\eqref{ineq:main-res} with .

\begin{prop}\label{prop:positiv:x0}
For any pair  satisfying~\eqref{ineq:main-res} there exists a pair  
satisfying~\eqref{ineq:main-res} such that  and .
\end{prop}
\begin{proof}
The case when  is easy: 
just put ,  and .
We assume that . 
The claim is proved by induction on .
The base, when , is obvious.
For the induction step, let us assume that .
Let  be the greatest index for which .
Consider the following sequence : ,  and  for all .
For  we have .
Therefore 

For   we get

Since  sequence  satisfies~\eqref{ineq:main-res}.
Finally, , so by the induction hypothesis 
there exists a solution of~\eqref{ineq:main-res} satisfying the claim.
\end{proof}



\begin{prop}\label{prop:spoiler_bound}
For any pair  
satisfying~\eqref{ineq:main-res} there exists a strategy for \Br in the -lazy matching game of size  such that any \Sr constructs a matching of size at most .
\end{prop}
\begin{proof}  
By Proposition~\ref{prop:positiv:x0} it is enough  to consider pairs with .
Without loss of generality we assume that  and describe a strategy for \Br, that does not allow \Sr to construct a matching larger than .
During the game \Br presents a bipartite graph  with  and maintains an auxiliary structure:
a partition of  and a partition of  such that

Observe that~\eqref{ineq:main-res} guarantees that  and thus 
.
Therefore .
It is straightforward that any bipartite graph which can be partitioned in such way contains a perfect matching.
  
 
The strategy of \Br is divided into  phases enumerated from  to .
{Figure~\ref{fig:attack} depicts the evaluation of the strategy described below for ,  and .}
In the beginning of the -th phase () sets  and , for , are already fixed. Next, during the -th phase, \Br presents  vertices, or  vertices when , which form  set  with neighborhoods defined by~\eqref{atack:neighbourU}. 
Most important, \Br chooses in the special way the set  of size  when  and of size  when .
This will conclude phase .
At the very end, within phase , \Br presets a set  of size  with vertices neighbouring with all vertices in .
  
It remains to define \Br's choice of .
For that, after each phase  () \Br maintains the following:
\begin{itemize}
    \item[()] 
    there are  distinct vertices  such that
     for all .
\end{itemize}
Observe that, for a fixed  and a fixed ,
once the condition  is satisfied, it will stay so to the end of the game
as  may only shrink later on in the game.
We prove by induction that choosing such  is possible in every phase by successively finding correct 's. 

For , \Br chooses\footnote{Let  for a set .} any  of size  and it is possible as 
 (because  for all , and by~\eqref{ineq:main-res}).
This way  for all  as required.

\begin{figure}[tbh]
\begin{center}
\begin{tikzpicture}\foreach \p in {1,...,18} {
  \coordinate (d\p) at (\p*0.7,-1);
  \fill (d\p) circle (1pt) node[below] {\footnotesize };
  }
  
 \foreach \q in {1,...,18} {
  \coordinate (u\q) at (\q*0.7,1);
 }
 \fill (u1) circle(1pt) node[above] {\footnotesize };
 \fill (u2) circle(1pt) node[above] {\footnotesize };
 \fill (u3) circle(1pt) node[above] {\footnotesize 11};
 \fill (u4) circle(1pt) node[above] {\footnotesize 13};
 \fill (u5) circle(1pt) node[above] {\footnotesize 15};
 \fill (u6) circle(1pt) node[above] {\footnotesize 17};
 \draw[rounded corners] (u1) ++ (-0.3,-0.2) rectangle  (6*0.7+0.3,1.8) ;
 \draw[rounded corners] (d1) ++ (-0.3,-0.6) rectangle  (6*0.7+0.3,0.2-1) ;
 
 \fill (u7) circle(1pt) node[above] {\footnotesize };
 \fill (u8) circle(1pt) node[above] {\footnotesize };
 \draw[rounded corners] (u7) ++ (-0.3,-0.2) rectangle  (8*0.7+0.3,1.5) ;
 \draw[rounded corners] (d7) ++ (-0.3,-0.6) rectangle  (8*0.7+0.3,0.2-1) ;
 
 \fill (u9) circle(1pt) node[above] {\footnotesize };
 \fill (u10) circle(1pt) node[above] {\footnotesize };
 \draw[rounded corners] (u9) ++ (-0.3,-0.2) rectangle  (10*0.7+0.3,1.5) ;
 \draw[rounded corners] (d9) ++ (-0.3,-0.6) rectangle  (10*0.7+0.3,0.2-1) ;
 
 \foreach \q in {11,...,18} {
   \fill (u\q) circle(1pt);
 }
 \draw[rounded corners] (u11) ++ (-0.3,-0.2) rectangle  (18*0.7+0.3,1.2) ;
 \draw[rounded corners] (d11) ++ (-0.3,-0.6) rectangle  (18*0.7+0.3,0.2-1) ;
 
 \path (u1) ++ (2,1.1) node {} ;
 \path (d1) ++ (2,-1) node {} ;
 
 \path (u7) ++ (0.4,0.8) node {} ;
 \path (d7) ++ (0.4,-1) node {} ;
 
 \path (u9) ++ (0.4,0.8) node {} ;
 \path (d9) ++ (0.4,-1) node {} ;
 
 \path (u11) ++ (2.4,0.5) node {} ;
 \path (d11) ++ (2.4,-1) node {} ;
 
 \draw (u1) ++ (-0.2,-0.2) rectangle (1*0.7+0.2,2) ;
 \path (0.8,2.2) node {};
 
 \draw (u2) ++ (-0.2,-0.2) rectangle (2*0.7+0.2,2) ;
 \path (2*0.7+0.1,2.2) node {};

 \foreach \q in {u1,u7,u9,u11}  {\path (\q) ++ (-.2,-.21) coordinate (p\q);}
 \foreach \q in {u6,u8,u10,u18} {\path (\q) ++ (.2,-.21) coordinate (p\q);}
 \foreach \q in {d1,d7,d9,d11}  {\path (\q) ++ (-.2,.21) coordinate (p\q);}
 \foreach \q in {d6,d8,d10,d18} {\path (\q) ++ (.2,.21) coordinate (p\q);}

 \filldraw[black!50!white] (pu11) -- (pd11) -- (pd18) -- (pu18) ;
 \filldraw[black!40!white] (pu9) -- (pu10) .. controls (10*.7+.2,.1) .. (pd18) -- (pd9);
 \filldraw[black!30!white] (pu7) -- (pu8) .. controls (8*.7+.2,.1) .. (pd18) -- (pd7);
 \filldraw[black!20!white] (pu1) -- (pu6) .. controls (6*.7+.2,.1) .. (pd18) -- (pd1);
 

\end{tikzpicture}
\caption{An example of the construction for solution  of~\eqref{ineq:main-res} with  and . 
Recall that , ,  and . 
The numbers under vertices in the bottom part represent vertices' names, 
while the numbers in the upper part correspond to sets  (e.g.\ ).
}\label{fig:attack}
\end{center}
\end{figure}

For , we assume that () holds with vertices  after -th phase.
Let  and .
First, note that  by the ()-property after -th phase.
We split vertices in  into two blocks:
, where  is simply the set of all unmatched vertices in .
Next, we give a lower bound on the average size of  for :

Clearly, there must be a vertex  with .
Since all values are integers we have .
\Br picks   to be any subset of  of size ,  to keep the property () satisfied after the -th phase.

By the condition () after the -th phase there is  such that   and  are disjoint for all .
Therefore, whenever ,  for , then either  or . 
It means that the number of such 's is at most . 
Consequently, the size of the matching produced by  \Sr is at most .
\end{proof}

\section{The best matching algorithm}
\label{sect:best_alg}


At any moment during a lazy matching game, we say that  is \emph{available} for  if  and  for any  presented earlier.
Also,  is \emph{strongly available} for  if it is available for  and  does not belong to any . 
Vertex  is \emph{ready} for  if  contains an  element which is available for .

We present an algorithm for \Sr called -\Alg{}. 
Suppose that vertex  has just been presented and let  be the set of vertices presented so far (including ). 
Each set  for  is already known and the algorithm has to construct set . 
The construction is described below --  is increased, one element at a time, until certain condition is satisfied.
During the process some other sets  may be decreased.

\begin{algorithm}
\label{alg}
\caption{}
\Let  \;
pick up at most  strongly available elements for  and put it into  \; 
\While {there exists a vertex  that is ready for  and satisfies 
    }
 { from the set of all such vertices pick  with maximal size of  \;
   move one vertex available for  from  to }
\end{algorithm}
The condition in line 2 guarantees that the size of  will be at most .
Note that -\Alg{} never leaves  empty if there exists an available element for , so in this respect -\Alg{} can be considered as greedy. 
For  the above algorithm is just a simple greedy construction of a bipartite matching.

The following proposition describes the performance of -\Alg{}. 
\begin{prop}\label{prop:balanced_bound}
 The size  of matching produced by -\Alg{} in a lazy matching game of size  equals  
 for some pair  satisfying~\eqref{ineq:main-res}.
\end{prop}
\begin{proof}
Consider an instance of the lazy matching game of size  in which \Br produced graph , and algorithm -\Alg{} constructed matching . 
Suppose that  rounds have been played in the game.
\emph{Presenting time} of element  is the index of the round in which  has been presented. 

We denote by , the (partial) matching constructed up to round . 
In particular, for  that is presented in round , we have  for  and then  is a weakly decreasing sequence of sets with . 

Let  be the set of all vertices in  such that  for each . 
The size of the matching produced be -\Alg{} is equal to the size of .
For the proof of the proposition we need the following claims. 
\begin{claim}
\label{claim:d1}
  Suppose that  ,  and , then . 
\end{claim}
\begin{proof}
It is sufficient to verify the claim for . 
It means that 
during round  algorithm -\Alg{} removed one element from  and inserted it into . 
Let  be the last such element (see Figure~\ref{fig:common-element}).
This happens only when the condition from the line 3 of the algorithm  is satisfied and   is a vertex with maximum size of assigned set among vertices ready for . 
Let  be the size of the set assigned to  at that moment  (in terms of listing~\ref{alg} it is ). 
Clearly , since  is the size of the set assigned to  in the beginning of round , and that set can only get smaller during the round. 
Also  since element  was the last one removed from .

The condition from the line 3 of -\Alg{} guarantees that the set that has just been increased has no more elements than the one that has been decreased. 
That property, and the fact that no vertex that was ready for  had assigned set greater than , gives . The claim follows.
\end{proof}

\usetikzlibrary{arrows,calc,shapes,decorations.pathreplacing}
\begin{figure}
\begin{center}
\begin{tikzpicture}

\coordinate (d) at (5,0);
\coordinate (x) at (4,2);
\coordinate (y) at (6,2);

\fill (d) circle (2pt) node[below] {};
\fill (x) circle (2pt) node[below] {};
\fill (y) circle (2pt) node[below] {};

\path[draw] (1,0) -- (9,0);
\path[draw,dashed] (2,0) -- (x) -- (6,0);
\path[draw,dashed] (4,0) -- (y) -- (8,0);

\draw (3.8,2.3) rectangle (4.2,4);
\draw[dashed] (3.8,4) rectangle (4.2,4.5);
\path (4,3.8) node {\st{}};
\path[draw] (3.8,3.6) -- (4.2,3.6);

\draw (5.8,2.3) rectangle (6.2,3);
\draw[dashed] (5.8,3) rectangle (6.2,3.6);
\path[draw] (5.8,2.6) -- (6.2,2.6);
\path (6,2.8) node {};

\draw[thick,->] (4.3,3.8) .. controls (5,3.8) and (4.5,2.8) .. (5.7,2.8);

\draw[decorate,decoration={brace,mirror,raise=6pt,amplitude=10pt}]    (3,4.5)--(3,2.3) ;
\draw[decorate,decoration={brace,mirror,raise=6pt,amplitude=10pt}]    (3.9,4)--(3.9,2.3);
\node at (3.2,3.2) {};
\node[left] at (2.5,3.5) {};

\draw[decorate,decoration={brace,raise=6pt,amplitude=10pt}]    (6.1,3.6)--(6.1,2.3);
\node[right] at (6.5,3) {};

\path[draw,dashed] (4.2,3.6) -- (5.8,3.6);

\end{tikzpicture}
\caption{The move of element  from  into .}
\label{fig:common-element}
\end{center}
\end{figure}


\begin{claim}\label{claim:els-above-X}
 If  is the presenting time of  and , then .
\end{claim}
\begin{proof}
 Let . By the definition of  element  is strongly available for  when  is presented. 
But  is not chosen in the line  of -\Alg{}. 
It means there were at least  other strongly available elements for  which were added to . 
Thus, indeed .
\end{proof}



\begin{claim}\label{claim:main-ineq}
For any subset   we have

where  and  is the set of all vertices  for which . 
\end{claim}
\begin{proof}
The claim is obvious for  since .
We assume that .
Let  and let  be the enumeration of  for which the sequence of corresponding presenting times  is strictly decreasing.
It means that  are in the reverse of the arrival order.
For each  we recursively define  set  
Observe that  and to finish the proof it suffices to show that , for all  (), and  for . We check two possibilities, either  or .
The first one is straightforward.
Set  can only get smaller, after  vertex  has been presented, therefore we have  for all . 
In particular, for every , we have , hence . That gives .


Suppose now, that  and let , where . 
Assume also that  since otherwise .
We consider two cases:

\textbf{Case 1: .}
By Claim~\ref{claim:els-above-X} and the definition of , inequality  implies that .
It  means that some element  was available for  at the time when  was presented. 
Element  must belong to  for some  presented earlier 
(otherwise the algorithm would put it in , but since after the game we have  , it would  imply that ). 
Thus, there are two elements (possibly the same)  and  such that  and obviously  is presented after .
While  is presented before  element  may be presented after .
Regardless of whether or not  and  are the same
by Claim~\ref{claim:d1} we deduce . 
On the other hand the algorithm in round   did not choose element  to be assigned to , which means that at the end of the round the inequality in the line 3 of the algorithm was not satisfied. 
That means that .

\textbf{Case 2: .} 
Let  be the smallest number (the first moment) for which  (it is a straightforward consequence of the definition that such  exists). 
Clearly  . 
Consider any  and note there is  such that  with . 
By Claim~\ref{claim:d1} it means that , thus . 
Straightforward induction (with Case 1 as basis) gives .
\end{proof}

We are ready to prove the proposition. 
Fix any optimal (maximum) matching in graph  and let  be the set of all elements in  outside the  matching. 
Consider an enumeration  of   such that, for  , we have . 
Let ,  and .
Observe that . 
It implies


To show that  satisfy~\eqref{ineq:main-res}, fix  and apply Claim~\ref{claim:main-ineq} for .  
Then  and  . 
Recall that in the chosen optimal matching each vertex in  has a unique match in .
Therefore,  
since ,
and then
 
which  can be  rewritten into

Let  be the set of all vertices  for which . 
Next, we define  as the set of all strong available elements assigned to  in the line  of the algorithm. 
Observe that  and  are disjoint for distinct . 
By Claim~\ref{claim:els-above-X} we get  for each . 
Thus,  since  and by~\eqref{eq:size:D-X}.
Also, since each element in  has a unique match in , we have .  Therefore



To finish the proof recall that .
Thus,  and consequently the size of the matching constructed by the algorithm equals .
Also, since  cannot be larger then  we have .
\end{proof}

Combining Proposition ~\ref{prop:spoiler_bound} and Proposition~\ref{prop:balanced_bound} we finally get Theorem~\ref{thm:optimal-bal}.

\section{Competitiveness of -\Alg{} algorithm}
\label{sect:comp}


Let  be the worst (minimum) size of matching constructed by -\Alg{} in any -lazy matching game of size .
Competitive ratio of -\Alg{} is defined as .
Propositions~\ref{prop:spoiler_bound} and~\ref{prop:balanced_bound} imply that in order to determine  it is enough to find a pair  satisfying~\eqref{ineq:main-res} which maximizes .
Moreover, by Proposition~\ref{prop:positiv:x0} we can assume that in the maximizing solution we have .
From now on we consider  in system~\eqref{ineq:main-res} as fixed together with  and .
Suppose that pair  satisfies~\eqref{ineq:main-res}.
Note that, for , if  then the -th inequality of system~\eqref{ineq:main-res} implies the -th inequality.
That suggests another representation of the solutions.
For a pair  satisfying~\eqref{ineq:main-res} with , let  be such that  and .
Then, for every  for which , inequality 

can be rewritten into 

where .
By the above discussion sequence  belongs to the image of  whenever it satisfies the following system of inequalities 

Moreover, since  then -th inequality in~\eqref{cond:prob:B} implies

On the other hand, having any  satisfying~\eqref{cond:m} and any solution  of~\eqref{cond:prob:B} one can easily
find (using the definition of 's) a solution  of~\eqref{ineq:main-res} such that .


The above considerations are summarized in the following
\begin{prop}
 The minimal size of the matching constructed by -\Alg{} in all -lazy matching games of size  is equal to
 
 where  and supreme is taken over all integers  such that  and over all vectors  of nonnegative integers that satisfy .
\end{prop}

\subsection{LP formulation.}
In order to maximize  we consider the following linear program. We present the primal and the dual formulation.
\begin{itemize}
 \item Primal:
 
 \begin{tabular}{rll}
  maximize    & \\
  subject to  &  , & for \\
  and         &  , & for 
 \end{tabular}

 \item Dual:
 
 \begin{tabular}{rll}
  minimize    & \\
  subject to  &  , & for \\
  and         &  , & for 
 \end{tabular}
\end{itemize}
Let  and . 
Observe that both systems  and  are quadratic and have unique solutions. 
By the Complementary Slackness Theorem these solutions are optimal if both are nonnegative vectors.

To solve the first system observe that . 
This, together with initial values for  and  gives 

By~\eqref{cond:m}  and thus all  are nonnegative.

For the second system observe that . Again, with the initial values for  and  we get

Therefore  and indeed the above vectors  and  are optimal solutions for the primal and the dual LP.

To calculate the target function  consider new variable  defined by the additional condition: .
Equation~\eqref{solution:yi} still works for . 
Also, after combining  with  we get .
Finally, using~\eqref{solution:yi} and~\eqref{solution:ym} and after some rearrangement we find 


 


\subsection{Lower bound.}
The solution for LP relaxation of~\eqref{cond:prob:B} may not be integer therefore with the solution~\eqref{solution:y0} we have only the following bound



Let . 
Then, for fixed , we get . 
Observe that function  is increasing with , for  and  increases indefinitely with .
Therefore for , we have

and for  (it happens when  the bound is


\subsection{Upper bound.}
Consider  assuming  is greater then  when ,
and let  be the optimal rational solution of .
Let  be such that .
Vector  contains only nonnegative, integer entries and . 
The shape of system  guarantees that  also satisfies .
Finally we have

By the definition of  we know that .
Therefore by Proposition~\ref{prop:spoiler_bound} we get

Hence, for  the bound is

and for  we have



\subsection{Competitive ratio.}
When  is finite, by~\eqref{eq:balLB} and~\eqref{eq:balUB} the ratio of -\Alg{} is equal to  .
For the case  note that .
Thus, by all~(\ref{eq:balLB}-\ref{eq:inftyUB}) we get .
This finally proves Theorem~\ref{thm:ratio}.


\section{Conclusion and remarks}\label{sec:remarks}


In the classical on-line matching problem, randomized approach has a big advantage over the deterministic one. 
This paper shows that the lazy method moves forward deterministic bounds. 
It is interesting to know what can be achieved with randomization of the lazy technique. 
\begin{problem}
 What is the competitive ratio of the randomized version of the lazy matching problem?
\end{problem}

The authors of~\cite{KalKir2000} consider a variant (called -matching) where each server can realize up to  tasks. 
Competitive ratio of their optimal algorithm approaches  with , which is a barrier for any randomized matching algorithm (see~\cite{KVV90}). 
We expect that the lazy method  is capable of breaking  limit in case of -matching.
\begin{problem}
 What is the competitive ratio of the lazy -matching problem?
\end{problem}


\bibliographystyle{plain} \bibliography{adaptm}


\end{document}
