\documentclass{article}
\usepackage{tcolorbox}
\usepackage[final]{neurips_2022}


\usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}    \usepackage{url}            \usepackage{booktabs}       \usepackage{amsfonts}       \usepackage{nicefrac}       \usepackage{microtype}      \usepackage{xcolor}         \usepackage{graphicx}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{subfig}
\usepackage{diagbox}
\usepackage{epsfig}
\usepackage{extpfeil}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{color,xcolor,colortbl}
\usepackage[pagebackref=false,breaklinks=true,colorlinks,bookmarks=false,citecolor=blue,linkcolor=blue]{hyperref}
\definecolor{lightgray}{gray}{0.95}
\definecolor{color3}{gray}{0.95}
\definecolor{rouse}{rgb}{0.981,0.961,0.941}
\newcommand{\tsp}{^{\mathsf{T}}}



\title{Degradation-Aware Unfolding Half-Shuffle Transformer  for  Spectral Compressive Imaging}



\author{Yuanhao Cai $^{1,2,*}$, Jing Lin $^{1,2,}$\thanks{Equal Contribution, $\dagger$ Corresponding Author} ~, Haoqian Wang $^{1,2,\dagger}$, Xin Yuan $^3$, \\ \textbf{Henghui Ding} $^4$, \textbf{Yulun Zhang} $^4$, \textbf{Radu Timofte} $^{4,5}$,  \textbf{Luc Van Gool} $^4$ \\
	$^{1}$ Shenzhen International Graduate School, Tsinghua University, \\ $^2$  Shenzhen Institute of Future Media Technology, \\ $^3$ Westlake University, $^4$ ETH Z\"{u}rich, $^5$ University of W\"urzburg
}


\begin{document}


\maketitle

\vspace{-5.5mm}
\begin{abstract}
	\vspace{-3mm}
	In coded aperture snapshot spectral compressive imaging (CASSI) systems, hyperspectral image (HSI) reconstruction methods are employed to recover the spatial-spectral signal from a compressed measurement. Among these algorithms, deep unfolding methods demonstrate promising performance but suffer from two issues. Firstly, they do not estimate the degradation patterns and ill-posedness degree from CASSI to guide the iterative learning. Secondly, they are mainly CNN-based, showing limitations in capturing long-range dependencies. In this paper, we propose a  principled Degradation-Aware Unfolding Framework (DAUF) that estimates parameters from the compressed image and physical mask, and then uses these parameters to control each iteration. Moreover,  we customize a novel Half-Shuffle Transformer (HST) that simultaneously captures local contents and non-local dependencies. By plugging HST into DAUF, we establish the first Transformer-based deep unfolding method, Degradation-Aware  Unfolding Half-Shuffle Transformer (DAUHST), for HSI reconstruction. Experiments show that DAUHST surpasses state-of-the-art methods while requiring cheaper computational and memory costs. Code and models are publicly available at   \url{https://github.com/caiyuanhao1998/MST}
\end{abstract}

\vspace{-1mm}
\section{Introduction}
\vspace{-3mm}
\begin{wrapfigure}{r}{0.37\textwidth}
	\vspace{-7mm}
	\begin{center} \hspace{-1.5mm}
		\includegraphics[width=0.37\textwidth]{img/teaser_fig_v6.pdf}
	\end{center}
	\vspace{-4mm}
	\caption{\small PSNR-FLOPS comparisons of DAUHST and SOTA unfolding methods.}
	\vspace{-2mm}
	\label{fig:teaser}
\end{wrapfigure} 
Hyperspectral images (HSIs) have more spectral bands than normal RGB images to store more detailed information. Thus, HSIs are widely applied in image recognition~\cite{fauvel2012advances,maggiori2017recurrent,zhang2015scene}, object detection~\cite{ot_1,ot_2,ot_3}, tracking~\cite{fu2016exploiting,uzkent2016real,uzkent2017aerial}, medical image processing~\cite{mi_1,mi_2,mi_3}, remote sensing~\cite{rs_1,rs_2,rs_3,rs_4}, \emph{etc.} To obtain HSIs,  traditional imaging systems use spectrometers to scan the scenes along the spectral or spatial dimensions, usually requiring a long time. These imaging systems fail to capture dynamic objects. Recently, snapshot compressive imaging~(SCI) systems~\cite{sci_1,sci_2,sci_3,sci_5,sci_6,yuan2015compressive,ma2021led} have been developed to capture HSIs at video rate. Among these SCI systems, coded aperture snapshot spectral imaging (CASSI)~\cite{sci_2,tsa_net,gehm2007single} stands out for its impressive performance. CASSI uses a coded aperture and a disperser to modulate the HSI signal at different wavelengths, and then mixes all modulated signal to generate a 2D compressed measurement. Subsequently, HSI restoration methods are employed to solve the CASSI inverse problem, \emph{i.e.}, restore the HSIs from the measurement. 
These methods are divided into four categories.

\textbf{(i)} Model-based  methods~\cite{sci_2,sparse_1,desci,non_local_1,non_local_2,gap_tv,tra_rela_1,gradient} rely on hand-crafted image priors, \emph{e.g.}, total variation~\cite{gap_tv}, sparsity~\cite{sci_2,sparse_1}, low-rank~\cite{desci}, \emph{etc.} These methods have theoretically proven properties and can be interpreted. Yet, these methods need manual parameter tweaking, which slows down  reconstruction. Also, they suffer from limited representation capacity and generalization ability. 

\textbf{(ii)}  Plug-and-play (PnP) algorithms~\cite{pnp_3,pnp_1,pnp_2,self,zheng2021deep,yuan2021plug} plug  pre-trained denoising networks into traditional model-based methods~\cite{pnp_2,qiao2020deep} to solve the HSI reconstruction problem. Nonetheless, the pre-trained networks in PnP methods are fixed without re-training, therefore limiting the  performance.

\textbf{(iii)} End-to-end (E2E) algorithms employ a powerful model, usually a convolutional neural network (CNN)~\cite{mi_3,tsa_net,hdnet,lambda},  to learn the E2E mapping function from a measurement to the desired HSIs. E2E methods enjoy the power of deep learning. However, they learn a brute-force mapping from the compressed measurement to the underlying spectral images, thereby ignoring the working principles of CASSI systems. They come without theoretically proven properties, interpretability~\cite{Yuan_review}, and flexibility because the imaging models widely  differ from each other for various hardware systems.

\textbf{(iv)} Deep unfolding methods~\cite{dnu,hssp,gapnet,admm-net,gsm,fu2021bidirectional,herosnet} adopt a multi-stage network to map the measurement into the HSI cube. Each stage usually includes two phases, \emph{i.e.}, linear projection followed by passing the signal through a single-stage network that learns the underlying denoiser prior. In deep unfolding methods, the network architecture is intuitively interpretable by explicitly characterizing the image priors and the system imaging model. Besides, these methods also enjoy the power of deep learning and thus have great potential. Yet, this potential has not been fully explored. 

Existing deep unfolding algorithms suffer from two issues. \textbf{(a)} The iterative learning is highly related to the CASSI system. 
However, current unfolding methods do not estimate CASSI degradation patterns and ill-posedness degree  to adjust the linear projection and denoising network in each iteration. 
\textbf{(b)} Existing deep unfolding methods are mainly CNN-based, therefore showing  limitations in capturing non-local self-similarity and long-range dependencies, both critical for HSI reconstruction.  

Recently, the emerging Transformer~\cite{vaswani2017attention} has provided a solution to tackle the drawbacks of CNN. Due to its strong capability in modeling the interactions of non-local spatial regions, Transformer has been widely applied in image classification~\cite{liu2021swin,arnab2021vivit,global_msa,tc_2,tc_3,xcit,crossvit}, object detection~\cite{de_detr,to_1,liu2021swin,DETR,dy_detr,to_2,to_5}, semantic segmentation~\cite{liu2021swin,tc_3,ts_1,cao2021swin,ts_2,ts_3,ts_4}, human pose estimation~\cite{tokenpose,transpose,rsn,prtr,th_1,th_2,th_3}, image restoration~\cite{ipt,swinir,uformer,vsrt,fgst,mst,mst_pp,cst,pngan,rformer}, \emph{etc.} Yet, the use of Transformer is confronted with two main issues. \textbf{(a)} The computational complexity of global Transformer~\cite{global_msa} is quadratic to the spatial dimensions. This nontrivial cost is sometimes unaffordable. \textbf{(b)} The receptive fields of local Transformer~\cite{liu2021swin} are limited within position-specific windows. As a result, some tokens with highly-related contents can not match each other when computing the self-attention.  

To address the above problems, in this paper, we firstly formulate a principled Degradation-Aware Unfolding Framework (DAUF) based on maximum \emph{a posteriori} (MAP) theory for HSI reconstruction. Different from previous deep unfolding methods, our DAUF implicitly estimates informative parameters from the degraded compressed measurement and the physical mask used in the modulation. Then DAUF feeds the parameters, which capture key cues of CASSI degradation patterns and ill-posedness  degree, into each iteration to adaptively scale the linear projection and provide the noise level information for the denoising network. Secondly, we design a novel Half-Shuffle Transformer (HST) as the denoiser prior in each iteration. Our HST can jointly extract local contextual information and model non-local dependencies, while requiring much cheaper computational costs than global Transformer. We achieve this by customizing a Half-Shuffle Multi-head Self-Attention (HS-MSA) mechanism that composes the basic unit of HST. More specifically, our HS-MSA has two branches, \emph{i.e.}, $local~branch$ and $non$-$local~branch$. The $local~branch$ calculates the self-attention within the local window while the $non$-$local~branch$ shuffles the tokens and captures cross-window interactions. We plug HST into DAUF to establish an  iterative architecture, Degradation-Aware Unfolding Half-Shuffle Transformer (DAUHST). With the proposed  techniques, DAUHST models dramatically outperform state-of-the-art (SOTA) deep unfolding methods  with the same number of stages by \textbf{over 4 dB}, as shown in Fig.~\ref{fig:teaser}.

In a nutshell, our contributions can be summarized as follows:

\textbf{(i)} We formulate a principled MAP-based  unfolding framework DAUF for HSI reconstruction. 

\textbf{(ii)} We propose a novel Transformer HST and plug it into DAUF to establish DAUHST. To the best of our knowledge, DAUHST is the first Transformer-based deep unfolding method for HSI restoration. 

\textbf{(iii)} DAUHST outperforms SOTA methods by a large margin  while requiring cheaper computational and memory costs. Besides, DAUHST yields more visually pleasant results in real HSI reconstruction. 



\begin{figure*}[t]
	\begin{center}
		\begin{tabular}[t]{c} \hspace{-2.4mm}
			\includegraphics[width=0.98\textwidth]{img/pipeline_v6.pdf}
		\end{tabular}
	\end{center}
	\vspace*{-3mm}
	\caption{\small The architecture of our DAUF with $K$ stages (iterations). $\mathcal{E}$ estimates informative parameters from the compressed  measurement $\mathbf{y}$ and sensing matrix $\mathbf{\Phi}$. The estimated parameters $\boldsymbol{\alpha}$ and $\boldsymbol{\beta}$ are fed into each stage of subsequent iterative learning.  $\mathcal{P}$ and $\mathcal{D}$ denote the linear projection and denoising network in each stage.}
	\label{fig:pipeline}
	\vspace{-3mm}
\end{figure*}

\vspace{-3mm}
\section{Proposed Method} \label{sec:method}
\vspace{-2mm}
\subsection{Degradation Model of CASSI}
\vspace{-1mm}
In CASSI, we denote the vectorized measurement as $\mathbf{y} \in \mathbb{R}^{n}$, where $n$ = $H(W+d(N_\lambda-1))$. $H$, $W$, $d$, and $N_\lambda$ denote the HSI's height, width, shifting step in dispersion, and total number of wavelengths. Given the vectorized shifted HSI signal $\mathbf{x} \in \mathbb{R}^{nN_\lambda}$ and the sensing matrix $\mathbf{\Phi} \in \mathbb{R}^{n \times nN_\lambda}$ that is determined by the physical mask, the degradation model of CASSI can be  formulated as
\begin{equation}
	\mathbf{y} = \mathbf{\Phi} \mathbf{x} + \mathbf{n},
\end{equation}
where $\mathbf{n} \in \mathbb{R}^{n}$ represents the vectorized imaging noise on the measurement. As analyzed in ~\cite{Tropp07ITT,Donoho06ITT,jalali2019snapshot}, $\mathbf{\Phi}$ is a fat, sparse, and highly structured matrix that is hard to handle. Please refer to the supplementary material for details about the mathematical model of CASSI.  Then the  task of HSI reconstruction is given $\mathbf{y}$ (captured by the  camera) and $\mathbf{\Phi}$ (calibrated based on pre-design), solving $\mathbf{x}$.

\vspace{-1mm}
\subsection{Degradation-Aware Unfolding Framework} \label{sec:dauf}
\vspace{-1mm}
Previous unfolding frameworks~\cite{dnu,hssp,gapnet,admm-net} do not estimate the CASSI degradation patterns to adjust the iterative learning.  To alleviate this limitation, we formulate a principled Degradation-Aware Unfolding Framework (DAUF) as depicted in Fig.~\ref{fig:pipeline}. DAUF starts from the MAP theory. In particular, the original HSI signal could be estimated by minimizing the following energy function as
\begin{equation}
\mathbf{\hat{x}} = \text{arg}~\underset{\mathbf{x}}{\text{min}}~~\frac{1}{2} || \mathbf{y} - \mathbf{\Phi} \mathbf{x} ||^2 + \tau R(\mathbf{x}), 
\label{eq:energy_1}
\end{equation}
where $\frac{1}{2} || \mathbf{y} - \mathbf{\Phi} \mathbf{x} ||^2$ is the data  fidelity term, $R(\mathbf{x})$ is the image prior term, and $\tau$ is a hyperparameter balancing the importance. By introducing an auxiliary variable $\mathbf{z}$, Eq.~\eqref{eq:energy_1} can be reformulated as 
\begin{equation}
\mathbf{\hat{x}} = \text{arg}~\underset{\mathbf{x}}{\text{min}}~~\frac{1}{2} || \mathbf{y} - \mathbf{\Phi} \mathbf{x} ||^2 + \tau R(\mathbf{z}), ~~~~ s.t.~~\mathbf{z} = \mathbf{x}.
\label{eq:energy_2}
\end{equation}
This is a constrained optimization problem. To obtain an unfolding inference, we adopt half-quadratic splitting (HQS) algorithm for its simplicity and fast convergence. Then Eq.~\eqref{eq:energy_2} is solved by minimizing 
\begin{equation}
\mathcal{L}_{\mu}(\mathbf{x}, \mathbf{z}) = \frac{1}{2} || \mathbf{y} - \mathbf{\Phi} \mathbf{x} ||^2 + \tau R(\mathbf{z}) + \frac{\mu}{2} || \mathbf{z} - \mathbf{x} ||^2,  
\label{eq:hqs_1}
\end{equation}
where $\mu$ is a penalty parameter that forces $\mathbf{x}$ and $\mathbf{z}$ to approach the same fixed point. Subsequently, Eq.~\eqref{eq:hqs_1} can be solved by decoupling $\mathbf{x}$ and $\mathbf{z}$  into the following two iterative sub-problems as
\begin{equation}
	\mathbf{x}_{k+1} = \text{arg}~\underset{\mathbf{x}}{\text{min}}~~|| \mathbf{y} - \mathbf{\Phi} \mathbf{x} ||^2 + \mu || \mathbf{x} - \mathbf{z}_{k} ||^2~,~~~\mathbf{z}_{k+1} = \text{arg}~\underset{\mathbf{z}}{\text{min}}~~\frac{\mu}{2} || \mathbf{z} - \mathbf{x}_{k+1} ||^2 +  \tau R(\mathbf{z}),
\label{eq:hqs_2}
\end{equation}
where $k = 0, 1,~...~, K-1$ indexes the iteration. Note that the data fidelity term  is associated with a quadratic regularized least-squares problem, \emph{i.e.}, $\mathbf{x}_{k+1}$ in Eq.~\eqref{eq:hqs_2}. It has a closed-form solution as 
\begin{equation}
	\mathbf{x}_{k+1} = (\mathbf{\Phi}\tsp \mathbf{\Phi} + \mu \mathbf{I})^{-1} (\mathbf{\Phi}\tsp \mathbf{y} + \mu \mathbf{z}_k),  
	\label{eq:closed}
\end{equation}
where $\mathbf{I}$ is an identity matrix. Since $\mathbf{\Phi}$ is a fat matrix, $(\mathbf{\Phi}\tsp \mathbf{\Phi} + \mu \mathbf{I})$ will be large and thus we simplify the computation of the inverse problem $(\mathbf{\Phi}\tsp \mathbf{\Phi} + \mu \mathbf{I})^{-1}$ by the matrix inversion formula as  
\begin{equation}
	(\mathbf{\Phi}\tsp \mathbf{\Phi} + \mu \mathbf{I})^{-1} = \mu^{-1} \mathbf{I} - \mu^{-1} \mathbf{\Phi}\tsp (\mathbf{I} + \mathbf{\Phi} \mu^{-1} \mathbf{\Phi}\tsp)^{-1} \mathbf{\Phi} \mu^{-1}.
	\label{eq:matrix_inverse}
\end{equation}
By plugging Eq.~\eqref{eq:matrix_inverse} into Eq.~\eqref{eq:closed}, we can reformulate Eq.~\eqref{eq:closed} as 
\begin{equation}
	\mathbf{x}_{k+1} = \frac{\mathbf{\Phi}\tsp \mathbf{y} + \mu \mathbf{z}_{k}}{\mu} - \frac{\mathbf{\Phi}\tsp (\mathbf{I} + \mathbf{\Phi} \mu^{-1} \mathbf{\Phi}\tsp)^{-1} \mathbf{\Phi} \mathbf{\Phi}\tsp \mathbf{y}}{\mu^2}  - \frac{\mathbf{\Phi}\tsp (\mathbf{I} + \mathbf{\Phi} \mu^{-1} \mathbf{\Phi}\tsp)^{-1} \mathbf{\Phi} \mathbf{z}_{k}}{\mu} ~.
	\label{eq:7}
\end{equation}
In CASSI systems, $\mathbf{\Phi} \mathbf{\Phi}\tsp$ is a diagonal matrix which can be defined as 
$\mathbf{\Phi} \mathbf{\Phi}\tsp \stackrel{\rm def}{=} {\rm diag}\{\psi_1, \dots, \psi_n\}$. By plugging $\mathbf{\Phi} \mathbf{\Phi}\tsp$ into $(\mathbf{I} + \mathbf{\Phi} \mu^{-1} \mathbf{\Phi}\tsp)^{-1}$ and $(\mathbf{I} + \mathbf{\Phi} \mu^{-1} \mathbf{\Phi}\tsp)^{-1} \mathbf{\Phi} \mathbf{\Phi}\tsp$, we obtain: 
\begin{equation}
\begin{aligned}
	(\mathbf{I} + \mathbf{\Phi} \mu^{-1} \mathbf{\Phi}\tsp)^{-1} &= \text{diag}\Big\{\frac{\mu}{\mu+\psi_1}, ...~,\frac{\mu}{\mu+\psi_n}\Big\}, \\ (\mathbf{I} + \mathbf{\Phi} \mu^{-1} \mathbf{\Phi}\tsp)^{-1} \mathbf{\Phi} \mathbf{\Phi}\tsp &= \text{diag}\Big\{\frac{\mu\psi_1}{\mu+\psi_1}, ...~,\frac{\mu\psi_n}{\mu+\psi_n}\Big\}.
	\label{eq:8}
\end{aligned}
\end{equation}
Let $\mathbf{y} \stackrel{\rm def}{=} [y_1,\dots,y_n]\tsp$ and $[\mathbf{\Phi} \mathbf{z}_k]_i$ denotes the $i$-th element of $\mathbf{\Phi}\mathbf{z}_k$. We plug Eq.~\eqref{eq:8} into Eq.~\eqref{eq:7} as
\begin{equation}
\begin{aligned}
	\mathbf{x}_{k+1} &= \frac{\mathbf{\Phi}\tsp \mathbf{y}}{\mu} + \mathbf{z}_{k} - \frac{1}{\mu} \mathbf{\Phi}\tsp \Big[\frac{y_1\psi_1+\mu [\mathbf{\Phi} \mathbf{z}_k]_1}{\mu+\psi_1}, ...~,\frac{y_n\psi_n+\mu [\mathbf{\Phi} \mathbf{z}_k]_n}{\mu+\psi_n}\Big]\tsp \\
	& = \mathbf{z}_{k} + \mathbf{\Phi}\tsp \Big[\frac{y_1 - [\mathbf{\Phi} \mathbf{z}_k]_1}{\mu+\psi_1}, ...~,\frac{y_n - [\mathbf{\Phi} \mathbf{z}_k]_n}{\mu+\psi_n}\Big]\tsp.
	\label{eq:9}
\end{aligned}
\end{equation}
Note that $\{y_i -[\mathbf{\Phi} \mathbf{z}_k]_i\}_{i=1}^n$ can be directly updated by $\mathbf{y} - \mathbf{\Phi} \mathbf{z}_k$, and $\{\psi_i\}_{i=1}^n$ is pre-calculated and stored in $\mathbf{\Phi} \mathbf{\Phi}\tsp$. Thus, by element-wise computation in Eq.~\eqref{eq:9}, $\mathbf{x}_{k+1}$ can be updated very efficiently.  According to Eq.~\eqref{eq:hqs_2}, the penalty parameter $\mu$ should be large enough so that $\mathbf{x}$ and $\mathbf{z}$ can approach approximately the same fixed point. This indicates that $\mu$ controls the convergence and output of each iteration.  Thus, instead of manually tweaking $\mu$, we set $\mu$ as a series of iteration-specific  parameters to be automatically estimated from the CASSI system. We denote $\mu$ in the $k$-th iteration as $\mu_k$. 

Returning to Eq.~\eqref{eq:hqs_2}, we also set $\tau$ as iteration-specific parameters and $\mathbf{z}_{k+1}$ can be reformulated as 
\begin{equation}
	\mathbf{z}_{k+1} = \text{arg}~\underset{\mathbf{z}}{\text{min}}~~\frac{1}{2(\sqrt{\tau_{k+1}/\mu_{k+1}})^2}~|| \mathbf{z} - \mathbf{x}_{k+1} ||^2 +  R(\mathbf{z}).
	\label{eq:10}
\end{equation}
From the perspective of Bayesian probability, Eq.~\eqref{eq:10} is equivalent to denoising image $\mathbf{x}_{k+1}$ with a Gaussian noise at level $\sqrt{\tau_{k+1}/\mu_{k+1}}$~\cite{pnp_3}. To conveniently solve Eq.~\eqref{eq:10}, we set $\frac{1}{(\sqrt{\tau_{k+1}/\mu_{k+1}})^2} = \mu_{k+1}/\tau_{k+1}$ as parameters to be estimated from CASSI. Let $\alpha_k \stackrel{\rm def}{=} \mu_k$, $\boldsymbol{\alpha} \stackrel{\rm def}{=} [\alpha_1, ... ,\alpha_K]$, $\beta_k \stackrel{\rm def}{=} \mu_k/\tau_k$, and $\boldsymbol{\beta} \stackrel{\rm def}{=} [\beta_1, ... ,\beta_K]$. Then we can formulate our DAUF as an iterative scheme: 
\begin{equation}
	(\boldsymbol{\alpha}, \boldsymbol{\beta}) =  \mathcal{E}(\mathbf{y}, \mathbf{\Phi}),~~~~\mathbf{x}_{k+1} = \mathcal{P}(\mathbf{y}, \mathbf{z}_k, \alpha_{k+1}, \mathbf{\Phi}),~~~~\mathbf{z}_{k+1} = \mathcal{D}(\mathbf{x}_{k+1}, \beta_{k+1}), 
	\label{eq:dauf}
\end{equation}
where $\mathcal{E}$ denotes the parameter estimator that takes the compressed measurement $\mathbf{y}$ and the sensing matrix $\mathbf{\Phi}$ of the CASSI system as inputs, $\mathcal{P}$ equivalent to  Eq.~\eqref{eq:9} denotes the linear projection, and $\mathcal{D}$ represents the Gaussian denoiser solving Eq.~\eqref{eq:10}. $\mathbf{z}_0$ is initialized by passing the shifted $\mathbf{y}$ concatenated with $\mathbf{\Phi}$ through a $conv1\times1$ (convolution with 1$\times$1 kernel).  Fig.~\ref{fig:pipeline} shows the  architecture of $\mathcal{E}$. It consists of a $conv1\times1$, a strided $conv3\times3$, a global average pooling, and three fully connected layers. Through $\mathcal{E}$, DAUF captures critical cues from CASSI by learning the degradation patterns and ill-posedness degree caused by the mask-modulation and dispersion-integration. Parameters $\boldsymbol{\alpha}$ and $\boldsymbol{\beta}$ estimated by $\mathcal{E}$ direct the iterative learning by adaptively scaling the linear projection in Eq.~\eqref{eq:9} and providing noise level information for the denoiser prior in Eq.~\eqref{eq:10}. 


\vspace{-1.5mm}
\subsection{Half-Shuffle Transformer}
\vspace{-1.5mm}
When designing the denoiser prior, previous deep unfolding methods~\cite{dnu,hssp,gapnet,admm-net} mainly adopt CNNs, showing limitations in capturing long-range dependencies. Directly applying local and global Transformers will encounter two problems, \emph{i.e.}, limited receptive fields and nontrivial computational costs. To address these challenges, we propose  Half-Shuffle Transformer  (HST) to play the role of $\mathcal{D}$.

\textbf{Network Architecture.}  As shown in Fig.~\ref{fig:hst} (a), HST adopts a three-level U-shaped structure  built by the basic unit Half-Shuffle Attention Block (HSAB). \textbf{Firstly}, HST uses a $conv3\times3$ to map reshaped $\mathbf{x}_k$ concatenated with stretched $\beta_k$ into feature $\mathbf{X}_0\in \mathbb{R}^{H\times \hat{W}\times C}$, where $\hat{W}$ = $W+d(N_\lambda-1)$. \textbf{Secondly}, $\mathbf{X}_0$ passes through the encoder, bottleneck, and decoder to be embedded into deep feature $\mathbf{X}_d\in \mathbb{R}^{H\times \hat{W}\times C}$. Each level of the encoder or decoder contains an HSAB and a resizing module.  In Fig.~\ref{fig:hst} (b), HSAB consists of two layer normalization (LN), an HS-MSA, and a Feed-Forward Network (FFN) that is detailed in Fig.~\ref{fig:hst} (c). The downsampling and upsampling modules are strided $conv4\times4$ and $deconv2\times2$. \textbf{Finally}, a $conv3\times3$ operates on $\mathbf{X}_d$ to generate a residual image  $\mathbf{R}\in \mathbb{R}^{H\times \hat{W}\times N_\lambda}$. The output denoised image $\mathbf{z}_k$ is obtained by the sum of $\mathbf{x}_k$ and reshaped $\mathbf{R}$.

\begin{figure*}[t]
	\begin{center}
		\begin{tabular}[t]{c} \hspace{-3.4mm}
			\includegraphics[width=0.99\textwidth]{img/HST_v6.pdf}
		\end{tabular}
	\end{center}
	\vspace*{-3mm}
	\caption{\small Diagram of HST. (a) HST adopts a U-shaped structure. (b) HSAB consists of an FFN, an HS-MSA, and two layer normalization. (c) Components of FFN. (d) HS-MSA contains $local~branch$ and $non$-$local~branch$.}
	\label{fig:hst}
	\vspace{-3mm}
\end{figure*}

\textbf{Half-Shuffle Multi-head Self-Attention.} The most important element of HSAB is the proposed Half-Shuffle Multi-head Self-Attention (HS-MSA) module. Fig.~\ref{fig:hst} (d) depicts the HS-MSA used in the first level. The input tokens of HS-MSA are denoted as $\mathbf{X}_{in}\in \mathbb{R}^{H\times \hat{W}\times C}$.  Subsequently,  $\mathbf{X}_{in}$ is linearly projected into $query$ $\mathbf{Q}\in \mathbb{R}^{H\times \hat{W}\times C}$, $key~\mathbf{K} \in \mathbb{R}^{H\times \hat{W}\times C}$, and $value$ $\mathbf{V}\in \mathbb{R}^{H\times \hat{W}\times C}$ as
\begin{equation}
	\mathbf{Q}=\mathbf{X}_{in}\mathbf{W^Q},
	~\mathbf{K}=\mathbf{X}_{in}\mathbf{W^K},
	~\mathbf{V}=\mathbf{X}_{in}\mathbf{W^V},
	\label{eq:linear_proj}
\end{equation}
where $\mathbf{W^Q},\mathbf{W^K},\mathbf{W^V}\in \mathbb{R}^{C\times C}$ are learnable parameters and biases are omitted for simplification. Our HS-MSA combines the advantages of global MSA~\cite{global_msa} and local window-based MSA~\cite{liu2021swin}, \emph{i.e.}, HS-MSA can jointly capture local contextual information through the \emph{local branch} and model long-range dependencies through the \emph{non-local branch}, all while being computationally cheaper than global MSA. Specifically,  $\mathbf{Q},\mathbf{K},\mathbf{V}$ are split into two equal parts along the channel dimension as
\begin{equation}
	\mathbf{Q} = [\mathbf{Q}_l, \mathbf{Q}_{nl}], 
	~\mathbf{K} = [\mathbf{K}_l, \mathbf{K}_{nl}], 
	~\mathbf{V} = [\mathbf{V}_l, \mathbf{V}_{nl}],
	\label{eq:half_split}
\end{equation}
where $\mathbf{Q}_l, \mathbf{K}_l, \mathbf{V}_l\in \mathbb{R}^{H\times \hat{W}\times \frac{C}{2}}$ are fed into the $local~branch$ to capture local contents, while  $\mathbf{Q}_{nl}, \mathbf{K}_{nl}, \mathbf{V}_{nl}\in \mathbb{R}^{H\times \hat{W}\times \frac{C}{2}}$ pass through the $non$-$local~branch$ to model non-local dependencies.

\textbf{Local Branch.} The $local~branch$ computes MSA within position-specific windows. As shown in the upper path of Fig.~\ref{fig:hst} (d), $\mathbf{Q}_l,\mathbf{K}_l,\mathbf{V}_l$ are partitioned into non-overlapping windows of size $M\times M$. Then they are reshaped into $\mathbb{R}^{\frac{H\hat{W}}{M^2}\times M^2\times \frac{C}{2}}$. Subsequently,  $\mathbf{Q}_l,\mathbf{K}_l,\mathbf{V}_l$ are split along the channel wise into $h$ heads: $\mathbf{Q}_l = [~\mathbf{Q}_{l}^1, \ldots, \mathbf{Q}_{l}^h~],~\mathbf{K}_l = [~\mathbf{K}_{l}^1, \ldots, \mathbf{K}_{l}^h~]$, and $\mathbf{V}_l = [~\mathbf{V}_{l}^1, \ldots, \mathbf{V}_{l}^h~]$. The dimension of each head is $d_h = \frac{C}{2h}$. Note that Fig.~\ref{fig:hst} (d) depicts the situation with $h$ = 1 and some details are omitted for simplification. The local self-attention $\mathbf{A}_{l}^i$ is calculated inside each head as
\begin{equation}
	\mathbf{A}_{l}^i=\text{softmax}(\frac{\mathbf{Q}_{l}^i~{\mathbf{K}_{l}^i}\tsp}{\sqrt{d_h}} + \mathbf{P}_{l}^i)~\mathbf{V}_{l}^i, ~~~ i=1, \ldots, h,
	\label{eq:attn_w}
\end{equation}
where $\mathbf{P}_{l}^i \in \mathbb{R}^{M^2 \times M^2}$ are learnable parameters embedding the position information. 

\textbf{Non-local Branch.} The $non$-$local~branch$ computes cross-window interactions through shuffle operations inspired by ShuffleNet~\cite{shufflenet}. In particular,  $\mathbf{Q}_{nl},\mathbf{K}_{nl},\mathbf{V}_{nl}\in \mathbb{R}^{H\times \hat{W}\times \frac{C}{2}}$ are firstly  partitioned into non-overlapping windows with  size  $M\times M$. Then their shapes are transposed from $\mathbb{R}^{\frac{H\hat{W}}{M^2}\times M^2\times \frac{C}{2}}$ to $\mathbb{R}^{M^2\times \frac{H\hat{W}}{M^2} \times \frac{C}{2}}$ to shuffle the positions of tokens and establish inter-window dependencies. $\mathbf{Q}_{nl},\mathbf{K}_{nl},\mathbf{V}_{nl}$ are split into $h$ heads: $\mathbf{Q}_{nl} = [~\mathbf{Q}_{nl}^1, \ldots, \mathbf{Q}_{nl}^h~],~ \mathbf{K}_{nl} = [~\mathbf{K}_{nl}^1, \ldots, \mathbf{K}_{nl}^h~],$ and $\mathbf{V}_{nl} =  [~\mathbf{V}_{nl}^1, \ldots, \mathbf{V}_{nl}^h~]$. Then  the non-local self-attention $\mathbf{A}_{nl}^i$ is computed in each head as 
\begin{equation}
	\mathbf{A}_{nl}^i=\text{softmax}(\frac{\mathbf{Q}_{nl}^i~{\mathbf{K}_{nl}^i}\tsp}{\sqrt{d_h}} + \mathbf{P}_{nl}^i)~\mathbf{V}_{nl}^i, ~~~ i=1, \ldots, h,
	\label{eq:attn_s}
\end{equation}
where $\mathbf{P}_{nl}^i \in \mathbb{R}^{\frac{H\hat{W}}{M^2} \times \frac{H\hat{W}}{M^2}}$ are learnable parameters representing the position embedding. Subsequently, $\mathbf{A}_{nl}^i \in \mathbb{R}^{M^2\times \frac{H\hat{W}}{M^2} \times d_h}$ is  unshuffled by being transposed to shape $\mathbb{R}^{\frac{H\hat{W}}{M^2}\times M^2 \times d_h}$. Then the outputs of $local~branch$ in Eq.~\eqref{eq:attn_w} and $non$-$local~branch$ in Eq.~\eqref{eq:attn_s} are aggregated by a linear projection as
\begin{equation}
	\text{HS-MSA}(\mathbf{X}_{in})=\sum\nolimits_{i=1}^{h} \mathbf{A}_{l}^i \mathbf{W}_{l}^i+
	\sum\nolimits_{i=1}^{h} \mathbf{A}_{nl}^i \mathbf{W}_{nl}^i,
	\label{eq:head_merge}
\end{equation}
where $\mathbf{W}_{l}^i,\mathbf{W}_{nl}^i \in \mathbb{R}^{d_h\times C}$ refer to learnable parameters. We reshape the result of Eq.~\eqref{eq:head_merge} to obtain the output  $\mathbf{X}_{out}\in\mathbb{R}^{H\times \hat{W}  \times C}$. 
Instead of globally sampling all tokens, HS-MSA builds inter-window correlations by shuffle operations. The self-attention is calculated in the local window but with tokens from non-local regions. Therefore, HS-MSA is much computationally cheaper than global MSA. 


\begin{table*}[t]
	\renewcommand{\arraystretch}{1.0}
	\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
\centering
	\resizebox{0.99\textwidth}{!}
	{
		\centering
\begin{tabular}{cccccccccccccc}
\toprule[0.2em]
			\rowcolor{lightgray}
			~~~~~Algorithms~~~~~
			&~~Params~~
			&~~GFLOPS~~
			& ~~~~~S1~~~~~
			& ~~~~~S2~~~~~
			& ~~~~~S3~~~~~
			& ~~~~~S4~~~~~
			& ~~~~~S5~~~~~
			& ~~~~~S6~~~~~
			& ~~~~~S7~~~~~
			& ~~~~~S8~~~~~
			& ~~~~~S9~~~~~
			& ~~~~~S10~~~~~
			& ~~~~Avg~~~~
			\\
			\midrule
			TwIST \cite{twist}
			& - 
			& -
			&\tabincell{c}{25.16\\0.700}
			&\tabincell{c}{23.02\\0.604}
			&\tabincell{c}{21.40\\0.711}
			&\tabincell{c}{30.19\\0.851}
			&\tabincell{c}{21.41\\0.635}
			&\tabincell{c}{20.95\\0.644}
			&\tabincell{c}{22.20\\0.643}
			&\tabincell{c}{21.82\\0.650}
			&\tabincell{c}{22.42\\0.690}
			&\tabincell{c}{22.67\\0.569}
			&\tabincell{c}{23.12\\0.669}
			\\
			\midrule
			GAP-TV \cite{gap_tv}
			& - 
			& -
			&\tabincell{c}{26.82\\0.754}
			&\tabincell{c}{22.89\\0.610}
			&\tabincell{c}{26.31\\0.802}
			&\tabincell{c}{30.65\\0.852}
			&\tabincell{c}{23.64\\0.703}
			&\tabincell{c}{21.85\\0.663}
			&\tabincell{c}{23.76\\0.688}
			&\tabincell{c}{21.98\\0.655}
			&\tabincell{c}{22.63\\0.682}
			&\tabincell{c}{23.10\\0.584}
			&\tabincell{c}{24.36\\0.669}
			\\
			\midrule
			DeSCI \cite{desci}
			& - 
			& -
			&\tabincell{c}{27.13\\0.748}
			&\tabincell{c}{23.04\\0.620}
			&\tabincell{c}{26.62\\0.818}
			&\tabincell{c}{34.96\\0.897}
			&\tabincell{c}{23.94\\0.706}
			&\tabincell{c}{22.38\\0.683}
			&\tabincell{c}{24.45\\0.743}
			&\tabincell{c}{22.03\\0.673}
			&\tabincell{c}{24.56\\0.732}
			&\tabincell{c}{23.59\\0.587}
			&\tabincell{c}{25.27\\0.721}
			\\
			\midrule
			$\lambda$-Net \cite{lambda}
			& 62.64M
			& 117.98
			&\tabincell{c}{30.10\\0.849}
			&\tabincell{c}{28.49\\0.805}
			&\tabincell{c}{27.73\\0.870}
			&\tabincell{c}{37.01\\0.934}
			&\tabincell{c}{26.19\\0.817}
			&\tabincell{c}{28.64\\0.853}
			&\tabincell{c}{26.47\\0.806}
			&\tabincell{c}{26.09\\0.831}
			&\tabincell{c}{27.50\\0.826}
			&\tabincell{c}{27.13\\0.816}
			&\tabincell{c}{28.53\\0.841}
			\\
			\midrule
			HSSP \cite{hssp}
			& - 
			& -
			&\tabincell{c}{31.48\\0.858}
			&\tabincell{c}{31.09\\0.842}
			&\tabincell{c}{28.96\\0.823}
			&\tabincell{c}{34.56\\0.902}
			&\tabincell{c}{28.53\\0.808}
			&\tabincell{c}{30.83\\0.877}
			&\tabincell{c}{28.71\\0.824}
			&\tabincell{c}{30.09\\0.881}
			&\tabincell{c}{30.43\\0.868}
			&\tabincell{c}{28.78\\0.842}
			&\tabincell{c}{30.35\\0.852}
			\\
			\midrule
			DNU \cite{dnu}
			& \bf 1.19M
			& 163.48
			&\tabincell{c}{31.72\\0.863}
			&\tabincell{c}{31.13\\0.846}
			&\tabincell{c}{29.99\\0.845}
			&\tabincell{c}{35.34\\0.908}
			&\tabincell{c}{29.03\\0.833}
			&\tabincell{c}{30.87\\0.887}
			&\tabincell{c}{28.99\\0.839}
			&\tabincell{c}{30.13\\0.885}
			&\tabincell{c}{31.03\\0.876}
			&\tabincell{c}{29.14\\0.849}
			&\tabincell{c}{30.74\\0.863}
			\\
			\midrule
			DIP-HSI \cite{self}
			& 33.85M
			& 64.42
			&\tabincell{c}{32.68\\0.890}
			&\tabincell{c}{27.26\\0.833}
			&\tabincell{c}{31.30\\0.914}
			&\tabincell{c}{40.54\\0.962}
			&\tabincell{c}{29.79\\0.900}
			&\tabincell{c}{30.39\\0.877}
			&\tabincell{c}{28.18\\0.913}
			&\tabincell{c}{29.44\\0.874}
			&\tabincell{c}{34.51\\0.927}
			&\tabincell{c}{28.51\\0.851}
			&\tabincell{c}{31.26\\0.894}
			\\
			\midrule
			TSA-Net \cite{tsa_net}
			& 44.25M
			& 110.06
			&\tabincell{c}{32.03\\0.892}
			&\tabincell{c}{31.00\\0.858}
			&\tabincell{c}{32.25\\0.915}
			&\tabincell{c}{39.19\\0.953}
			&\tabincell{c}{29.39\\0.884}
			&\tabincell{c}{31.44\\0.908}
			&\tabincell{c}{30.32\\0.878}
			&\tabincell{c}{29.35\\0.888}
			&\tabincell{c}{30.01\\0.890}
			&\tabincell{c}{29.59\\0.874}
			&\tabincell{c}{31.46\\0.894}
			\\
			\midrule
			DGSMP \cite{gsm}
			& 3.76M
			& 646.65
			&\tabincell{c}{33.26\\0.915}
			&\tabincell{c}{32.09\\0.898}
			&\tabincell{c}{33.06\\0.925}
			&\tabincell{c}{40.54\\0.964}
			&\tabincell{c}{28.86\\0.882}
			&\tabincell{c}{33.08\\0.937}
			&\tabincell{c}{30.74\\0.886}
			&\tabincell{c}{31.55\\0.923}
			&\tabincell{c}{31.66\\0.911}
			&\tabincell{c}{31.44\\0.925}
			&\tabincell{c}{32.63\\0.917}
			\\
			\midrule
			GAP-Net \cite{gapnet}
			& 4.27M
			& 78.58
			&\tabincell{c}{33.74\\0.911}
			&\tabincell{c}{33.26\\0.900}
			&\tabincell{c}{34.28\\0.929}
			&\tabincell{c}{41.03\\0.967}
			&\tabincell{c}{31.44\\0.919}
			&\tabincell{c}{32.40\\0.925}
			&\tabincell{c}{32.27\\0.902}
			&\tabincell{c}{30.46\\0.905}
			&\tabincell{c}{33.51\\0.915}
			&\tabincell{c}{30.24\\0.895}
			&\tabincell{c}{33.26\\0.917}
			\\
			\midrule
			ADMM-Net \cite{admm-net}
			& 4.27M
			& 78.58
			&\tabincell{c}{34.12\\0.918}
			&\tabincell{c}{33.62\\0.902}
			&\tabincell{c}{35.04\\0.931}
			&\tabincell{c}{41.15\\0.966}
			&\tabincell{c}{31.82\\0.922}
			&\tabincell{c}{32.54\\0.924}
			&\tabincell{c}{32.42\\0.896}
			&\tabincell{c}{30.74\\0.907}
			&\tabincell{c}{33.75\\0.915}
			&\tabincell{c}{30.68\\0.895}
			&\tabincell{c}{33.58\\0.918}
			\\
			\iffalse
			\midrule
			MST-S \cite{mst}
			& 0.93M
			& 12.96
			&\tabincell{c}{34.71\\0.930}
			&\tabincell{c}{34.45\\0.925}
			&\tabincell{c}{35.32\\0.943}
			&\tabincell{c}{41.50\\0.967}
			&\tabincell{c}{31.90\\0.933}
			&\tabincell{c}{33.85\\0.943}
			&\tabincell{c}{32.69\\0.911}
			&\tabincell{c}{31.69\\0.933}
			&\tabincell{c}{34.67\\0.939}
			&\tabincell{c}{31.82\\0.926}
			&\tabincell{c}{34.26\\0.935}
			\\
			\midrule
			MST-M \cite{mst}
			& 1.50M
			& 18.07
			&\tabincell{c}{35.15\\0.937}
			&\tabincell{c}{35.19\\0.935}
			&\tabincell{c}{36.26\\0.950}
			&\tabincell{c}{{42.48}\\0.973}
			&\tabincell{c}{32.49\\0.943}
			&\tabincell{c}{34.28\\0.948}
			&\tabincell{c}{33.29\\0.921}
			&\tabincell{c}{32.40\\0.943}
			&\tabincell{c}{35.35\\0.942}
			&\tabincell{c}{32.53\\0.935}
			&\tabincell{c}{34.94\\0.943}
			\\
			\fi
			\midrule
			HDNet \cite{hdnet}
			& 2.37M
			& 154.76
			&\tabincell{c}{35.14\\0.935}
			&\tabincell{c}{35.67\\0.940}
			&\tabincell{c}{36.03\\0.943}
			&\tabincell{c}{42.30\\0.969}
			&\tabincell{c}{32.69\\0.946}
			&\tabincell{c}{34.46\\0.952}
			&\tabincell{c}{33.67\\0.926}
			&\tabincell{c}{32.48\\0.941}
			&\tabincell{c}{34.89\\0.942}
			&\tabincell{c}{32.38\\0.937}
			&\tabincell{c}{34.97\\0.943}
			\\
			\midrule
			MST-L \cite{mst}
			& 2.03M
			& 28.15
			&\tabincell{c}{35.40\\0.941}
			&\tabincell{c}{35.87\\0.944}
			&\tabincell{c}{36.51\\0.953}
			&\tabincell{c}{42.27\\0.973}
			&\tabincell{c}{32.77\\0.947}
			&\tabincell{c}{34.80\\0.955}
			&\tabincell{c}{33.66\\0.925}
			&\tabincell{c}{32.67\\0.948}
			&\tabincell{c}{35.39\\0.949}
			&\tabincell{c}{32.50\\0.941}
			&\tabincell{c}{35.18\\0.948}
			\\
			\midrule
			MST++ \cite{mst_pp}
			& 1.33M
			& 19.42
			&\tabincell{c}{35.80\\0.943}
			&\tabincell{c}{36.23\\0.947}
			&\tabincell{c}{37.34\\0.957}
			&\tabincell{c}{42.63\\0.973}
			&\tabincell{c}{33.38\\0.952}
			&\tabincell{c}{35.38\\0.957}
			&\tabincell{c}{34.35\\0.934}
			&\tabincell{c}{33.71\\0.953}
			&\tabincell{c}{36.67\\0.953}
			&\tabincell{c}{33.38\\0.945}
			&\tabincell{c}{35.99\\0.951}
			\\
			\midrule
			CST-L \cite{mst_pp}
			& 3.00M
			& 40.01
			&\tabincell{c}{35.96\\0.949}
			&\tabincell{c}{36.84\\0.955}
			&\tabincell{c}{38.16\\0.962}
			&\tabincell{c}{42.44\\0.975}
			&\tabincell{c}{33.25\\0.955}
			&\tabincell{c}{35.72\\0.963}
			&\tabincell{c}{34.86\\0.944}
			&\tabincell{c}{34.34\\0.961}
			&\tabincell{c}{36.51\\0.957}
			&\tabincell{c}{33.09\\0.945}
			&\tabincell{c}{36.12\\0.957}
			\\
			\midrule
BIRNAT~\cite{birnat}
			& 4.40M
			& 2122.66
			&\tabincell{c}{36.79\\0.951}
			&\tabincell{c}{37.89\\0.957}
			&\tabincell{c}{40.61\\0.971}
			&\tabincell{c}{\bf{46.94}\\\bf{0.985}}
			&\tabincell{c}{35.42\\0.964}
			&\tabincell{c}{35.30\\0.959}
			&\tabincell{c}{36.58\\0.955}
			&\tabincell{c}{33.96\\0.956}
			&\tabincell{c}{39.47\\0.970}
			&\tabincell{c}{32.80\\0.938}
			&\tabincell{c}{37.58\\0.960}
			\\
			\midrule
			\rowcolor{rouse}
			\bf DAUHST-2stg 
			&  1.40M
			& \bf 18.44
			&\tabincell{c}{35.93\\0.943}
			&\tabincell{c}{36.70\\0.946}
			&\tabincell{c}{37.96\\0.959}
			&\tabincell{c}{44.38\\0.978}
			&\tabincell{c}{34.13\\0.954}
			&\tabincell{c}{35.43\\0.957}
			&\tabincell{c}{34.78\\0.940}
			&\tabincell{c}{33.65\\0.950}
			&\tabincell{c}{37.42\\0.955}
			&\tabincell{c}{33.07\\0.941}
			&\tabincell{c}{36.34\\0.952}
			\\
			\midrule
			\rowcolor{rouse}
			\bf DAUHST-3stg
			& 2.08M
			& 27.17
			&\tabincell{c}{36.59\\0.949}
			&\tabincell{c}{37.93\\0.958}
			&\tabincell{c}{39.32\\0.964}
			&\tabincell{c}{44.77\\0.980}
			&\tabincell{c}{34.82\\0.961}
			&\tabincell{c}{36.19\\0.963}
			&\tabincell{c}{36.02\\0.950}
			&\tabincell{c}{34.28\\0.956}
			&\tabincell{c}{38.54\\0.963}
			&\tabincell{c}{33.67\\0.947}
			&\tabincell{c}{37.21\\0.959}
			\\
			\midrule
\rowcolor{rouse}
			\bf DAUHST-5stg
			& 3.44M
			& 44.61
			&\tabincell{c}{36.92\\0.955}
			&\tabincell{c}{38.52\\0.962}
			&\tabincell{c}{40.51\\0.967}
			&\tabincell{c}{45.09\\0.980}
			&\tabincell{c}{35.33\\0.964}
			&\tabincell{c}{36.56\\0.965}
			&\tabincell{c}{36.82\\0.958}
			&\tabincell{c}{34.74\\0.959}
			&\tabincell{c}{38.71\\0.963}
			&\tabincell{c}{34.27\\0.952}
			&\tabincell{c}{37.75\\0.962}
			\\
			\midrule
			\rowcolor{rouse}
			\bf DAUHST-9stg
			& 6.15M
			& 79.50
			&\tabincell{c}{\bf{37.25}\\\bf{0.958}}
			&\tabincell{c}{\bf{39.02}\\\bf{0.967}}
			&\tabincell{c}{\bf{41.05}\\\bf{0.971}}
			&\tabincell{c}{{46.15}\\{0.983}}
			&\tabincell{c}{\bf{35.80}\\\bf{0.969}}
			&\tabincell{c}{\bf{37.08}\\\bf{0.970}}
			&\tabincell{c}{\bf{37.57}\\\bf{0.963}}
			&\tabincell{c}{\bf{35.10}\\\bf{0.966}}
			&\tabincell{c}{\bf{40.02}\\\bf{0.970}}
			&\tabincell{c}{\bf{34.59}\\\bf{0.956}}
			&\tabincell{c}{\bf{38.36}\\\bf{0.967}}
			\\
			\bottomrule[0.2em]
		\end{tabular}
	}
	\vspace{-1mm}
	\caption{Comparisons between DAUHST and SOTA methods on 10 simulation scenes (S1$\sim$S10). Params, FLOPS, PSNR (upper entry in each cell), and SSIM (lower entry in each cell) are reported.}
	\vspace{-3mm}
	\label{tab:simu}
\end{table*}


\begin{figure*}[t]
	\begin{center}
		\begin{tabular}[t]{c} \hspace{-3.4mm}
			\includegraphics[width=0.99\textwidth]{img/simulation_v2.pdf}
		\end{tabular}
	\end{center}
	\vspace*{-3mm}
	\caption{\small Simulation HSI reconstruction comparisons of  \emph{Scene} 2 with 4 (out of 28) spectral channels. The top-middle shows the spectral curves  corresponding to the two green boxes of the RGB image. The top-right depicts the enlarged patches corresponding to the yellow boxes in the bottom HSIs. Zoom in for a  better view.}
	\label{fig:simu}
	\vspace{-5mm}
\end{figure*}

\vspace{-1mm}
\section{Experiment} \label{sec:exp}
\vspace{-1.5mm}
\subsection{Experiment Setup}
\vspace{-0.5mm}
Similar to \cite{tsa_net,hdnet,gapnet,gsm,mst}, 28 wavelengths are selected from 450nm to 650nm and  derived by spectral interpolation manipulation for the HSI data. Simulation and real experiments are conducted. 

\textbf{Simulation Dataset.} We adopt two datasets, \emph{i.e.}, CAVE~\cite{cave} and KAIST~\cite{kaist} for simulation experiments. The CAVE  dataset consists of 32 HSIs with spatial size 512$\times$512. The KAIST dataset  contains 30 HSIs of spatial size 2704$\times$3376. Following the settings of \cite{tsa_net,hdnet,gapnet,gsm,mst}, the CAVE dataset is adopted as the training set while 10 scenes from the KAIST dataset are selected for testing. 

\textbf{Real Dataset.} Five real HSIs collected by the CASSI system developed in~\cite{tsa_net} are used for testing. 

\textbf{Implementation Details.} We implement DAUHST by Pytorch. All DAUHST models are trained with Adam~\cite{adam} optimizer ($\beta_1$ = 0.9 and $\beta_2$ = 0.999) using Cosine Annealing scheme~\cite{cosine} for 300 epochs on an RTX 3090 GPU. The initial learning rate is 4$\times$10$^{-4}$. Patches with spatial sizes 256$\times$256 and 660$\times$660 are randomly cropped from the 3D HSI cubes with 28 channels as training samples for the simulation and real experiments.  The shifting step $d$ in the dispersion is set to 2. 
The batch size is 5. We set the basic channel $C$ = $N_\lambda$ = 28 to store HSI information. The weights of $\mathcal{D}$ in different stages are unshared. Data augmentation includes  random  rotation and flipping. The training objective is to minimize the Root Mean Square Error (RMSE) between reconstructed and ground-truth HSIs.  

\vspace{-1.5mm}
\subsection{Quantitative Comparisons with State-of-the-Art Methods}
\vspace{-1.5mm}

Tab.~\ref{tab:simu} compares the results of DAUHST and 16 SOTA methods including three model-based methods (TwIST~\cite{twist}, GAP-TV~\cite{gap_tv}, and DeSCI~\cite{desci}), one PnP method (DIP-HSI~\cite{self}), seven E2E methods ($\lambda$-Net~\cite{lambda}, TSA-Net~\cite{tsa_net}, HDNet~\cite{hdnet}, MST~\cite{mst}, MST++~\cite{mst_pp}, CST~\cite{cst}, and BIRNAT~\cite{birnat}), and five deep unfolding methods (HSSP~\cite{hssp}, DNU~\cite{dnu}, DGSMP~\cite{gsm}, GAP-Net~\cite{gapnet}, and ADMM-Net~\cite{admm-net}) on 10 simulation scenes. All algorithms are tested with the same settings as \cite{gsm,mst}.

\textbf{(i)} Our best model DAUHST-9stg (9-stage DAUHST) yields very impressive results, \emph{i.e.}, 38.36 dB in PSNR and 0.967 in SSIM. DAUHST-9stg significantly outperforms two recent SOTA methods BIRNAT~\cite{birnat} and MST-L~\cite{mst} by 0.78 and 3.18 dB, suggesting the effectiveness of our method.  

\textbf{(ii)} Our DAUHST models dramatically surpass SOTA methods while requiring cheaper computational and memory costs. For instance, when compared with the only one Transformer-based E2E method MST, our DAUHST-2stg outperforms MST-L by 1.16 dB but only costs 68.9\% (1.40 / 2.03) Params and 65.5\% (18.44 / 28.15) FLOPS.  When compared with CNN-based E2E methods,  DAUHST-3stg  surpasses HDNet, TSA-Net, and $\lambda$-Net by 2.24, 5.75, and 8.68 dB while only requiring 87.8\%, 4.7\%, 3.3\% Params and 17.6\%, 24.7\%, 23.0\% FLOPS. When compared with RNN-based E2E method BIRNAT, our DAUHST-5stg is 0.17 dB higher but only costs  2.1\% FLOPS and 78.2\% Params. Fig.~\ref{fig:teaser}  plots the PSNR-FLOPS comparisons of DAUHST and SOTA unfolding methods.  DAUHST  outperforms other competitors with the same number of stages  by very large margins, \textbf{over 4 dB}.  


\vspace{-1.5mm}
\subsection{Qualitative Comparisons with State-of-the-Art Methods}
\vspace{-1.5mm}
\textbf{Simulation HSI Reconstruction.} Fig.~\ref{fig:simu} depicts the simulation HSI reconstruction comparisons between our DAUHST and other SOTA methods on \emph{Scene} 2 with 4 (out of 28) spectral channels. The top-right part shows the zoomed-in patches of the yellow boxes in the entire HSIs (bottom). As can be observed that our DAUHST-9stg is more favorable to reconstruct visually pleasant HSIs with more detailed contents, cleaner textures, and fewer  artifacts while  preserving the spatial smoothness of homogeneous regions. In contrast, previous methods either yield over-smooth results compromising fine-grained structures, or introduce undesired chromatic artifacts and blotchy textures that are absent in the ground truth (GT). The top-middle part illustrates the density-wavelength spectral curves corresponding to the green boxes identified as \emph{a} and \emph{b} in the RGB image (top-left). The spectral curves of DAUHST-9stg achieve the highest correlation and coincidence with the reference curves, showing the advantage of our proposed DAUHST in spectral-dimension
consistency reconstruction. 

\begin{figure*}[t]
	\begin{center}
		\begin{tabular}[t]{c} \hspace{-3.4mm}
			\includegraphics[width=1\textwidth]{img/real_v3.pdf}
		\end{tabular}
	\end{center}
	\vspace*{-4mm}
	\caption{\small Real HSI reconstruction results of DAUHST-3stg and 9 SOTA methods on  \emph{Scene} 1 with 4 (out of 28) spectra. Only our method can clearly reconstruct the picked flower at all wavelengths. 
		Zoom in for a better view. }
	\label{fig:real}
	\vspace{-5mm}
\end{figure*}

\textbf{Real HSI Reconstruction.} We further evaluate the effectiveness of DAUHST in real HSI reconstruction. Following the same settings as \cite{tsa_net,gsm,mst} for a fair comparison, we re-train  DAUHST-3stg with the real mask on the CAVE and KAIST datasets jointly. To simulate the real imaging situations, the training samples are also injected with 11-bit shot noise. 
Fig.~\ref{fig:real} shows the visual comparisons between our DAUHST-3stg and nine SOTA methods. In the top three rows, only our DAUHST-3stg can reconstruct the flower patch corresponding to the yellow box  at all wavelengths while other methods all fail to recover the entire patch. In the bottom row, DAUHST-3stg restores more HSI structural details and clearer contents with fewer artifacts. In contrast, other methods recover blurry images, generate incomplete responses, and are susceptible to the noise corruption. This evidence suggests that DAUHST is more robust to the noise distortion and more effective  in real HSI reconstruction.



\vspace{-1.5mm}
\subsection{Ablation Study}
\vspace{-1.5mm}

\textbf{Break-down Ablation.} We adopt baseline-1 that is derived by removing HS-MSA and DAUF from DAUHST-3stg to conduct the break-down ablation. Our goal is to study the effect of each component towards higher performance. Baseline-1 is cascaded end to end by three single-stage networks. As shown in Tab.~\ref{tab:breakdown}, baseline-1 achieves 33.05 dB. When we respectively apply DAUF and HS-MSA, the model achieves 2.32 and 2.44 dB improvements. When we exploit DAUF and HS-MSA jointly, the model gains by 4.16 dB.  These results demonstrate the effectiveness of our  DAUF and HS-MSA.

\textbf{Self-Attention Mechanism.} To compare HS-MSA with other MSAs, we adopt baseline-2 that is obtained by removing HS-MSA from DAUHST-1stg to conduct the ablation  in Tab.~\ref{tab:attention}. We remove different position embedding schemes to avoid their impacts and only compare  MSAs. For fairness, we keep the Params of MSAs the same by fixing the number of channels and heads. Baseline-2 yields 32.79 dB. We apply global MSA (G-MSA)~\cite{global_msa}, Swin MSA (SW-MSA)~\cite{liu2021swin}, Spectral-wise MSA (S-MSA)~\cite{mst}, and HS-MSA. Note that we downsample the input feature maps of G-MSA to avoid memory bottlenecks. As shown in Tab.~\ref{tab:attention}, HS-MSA yields the most significant improvement of 1.26 dB, which is 0.42, 0.30, and 0.23 dB higher than G-MSA, SW-MSA, and S-MSA. This superiority is mainly derived from HS-MSA's ability to jointly capture local contents and non-local dependencies. 

\begin{figure*}[t]
	\begin{center}
		\begin{tabular}[t]{c} \hspace{-3.8mm}
			\includegraphics[width=1.0\textwidth]{img/analysis_v5.pdf}
		\end{tabular}
	\end{center}
	\vspace*{-3mm}
	\caption{\small Visualization of $\mathbf{z}_k$ and $\mathbf{x}_k$ with 4 (out of 28) spectral channels on $Scene$ 1 in different iterations. The bottom-left corner plots the curves of $\boldsymbol{\alpha}$ and $\boldsymbol{\beta}$ changing with the iteration. Please zoom in for a better view.}
	\label{fig:analysis}
	\vspace{-0mm}
\end{figure*}

\begin{table*}[t]\vspace{-6mm}
\subfloat[\small Break-down ablation towards higher performance. \label{tab:breakdown}]{ 
		\scalebox{0.6}{
			\begin{tabular}{c c c  c c c c}
\toprule
				\rowcolor{color3} Baseline-1 &DAUF &HS-MSA   &PSNR &SSIM &Params (M) &FLOPS (G) \\
				\midrule
				\checkmark & & &33.05 &0.912 &1.06 &17.62 \\
				\checkmark  &\checkmark & &35.37 &0.938 &1.11 &18.55 \\
				\checkmark & &\checkmark &35.49 &0.941 &2.03 &26.23 \\
				\checkmark  &\checkmark &\checkmark &\bf 37.21 &\bf 0.959 &2.08 &27.17 \\
				\bottomrule
	\end{tabular}}}\hspace{2mm}\vspace{-1.5mm}
\subfloat[\small Ablation of various self-attention mechanisms.\label{tab:attention}]{
		\scalebox{0.6}{
			\begin{tabular}{l c c c c  c}
				\toprule
				\rowcolor{color3} Method &Baseline-2 &G-MSA &SW-MSA &S-MSA  &\bf HS-MSA\\
				\midrule
				PSNR &32.79 &33.63 &33.75 &33.82 &\bf 34.05 \\
				SSIM &0.904 &0.920 &0.924 &0.926  &\bf 0.930\\
				Params (M)  &0.40 &0.48 &0.48 &0.48  & 0.48\\
				FLOPS (G)  &6.85 &10.30 &9.41 &8.89 & 9.72\\
				\bottomrule
	\end{tabular}}}\vspace{-1.5mm}
\subfloat[\small Ablation of different unfolding frameworks. \label{tab:dauf_compare}]{
		\scalebox{0.63}{\begin{tabular}{l c c c c}
				\toprule
				\rowcolor{color3}Framework &~DNU~\cite{dnu}~ &~ADMM~\cite{admm-net}~ &~GAP~\cite{gapnet}~ &\bf ~DAUF~   \\
\midrule
				PSNR &34.62   &35.52 &35.58  &\bf 37.21  \\
				SSIM  &0.930    &0.942  &0.943 &\bf 0.959  \\
				Params (M)  &2.03    &2.03  &2.03  &2.08 \\
				FLOPS (G) &26.23    &26.23 &26.23   &27.17 \\
				\bottomrule
	\end{tabular}}}\hspace{2.5mm}\vspace{-3mm}
\subfloat[\small Ablation to study the effect of parameters  $\boldsymbol{\alpha}$ and $\boldsymbol{\beta}$.\label{tab:dauf_ablation}]{
		\scalebox{0.63}{
			\begin{tabular}{c c c c c c c}
				\toprule
				\rowcolor{color3} Baseline-3 &~~$\boldsymbol{\alpha}$~~ &~~$\boldsymbol{\beta}$~~  &~~PSNR~~ &~~SSIM~~ &Params (M) &FLOPS (G) \\
				\midrule
				\checkmark & & &36.49 &0.952 &2.03 &26.23 \\
				\checkmark  &\checkmark & &36.94 &0.957 &2.08 &27.10 \\
				\checkmark & &\checkmark &36.83 &0.956 &2.08 &27.17 \\
				\checkmark  &\checkmark &\checkmark &\bf 37.21 &\bf 0.959 &2.08 &27.17 \\
				\bottomrule
	\end{tabular}}}\hspace{4mm}\vspace{1mm}
	\caption{\small Ablation studies on simulation datasets~\cite{cave,kaist}. PSNR, SSIM, Params, and FLOPS are reported.}
	\label{tab:ablations}\vspace{-4mm}
\end{table*}







\textbf{Unfolding Framework.} We compare our DAUF with previous  unfolding frameworks including DNU~\cite{dnu}, ADMM-Net~\cite{admm-net}, and GAP-Net~\cite{gapnet}. For a fair comparison, we replace each single-stage network of DNU, ADMM-Net, and GAP-Net by our HST. 3-stage architecture is adopted to conduct ablations.  The results are shown in Tab.~\ref{tab:dauf_compare}. Our DAUF significantly outperforms DNU, ADMM, and GAP by 2.59, 1.69, and 1.63 dB while adding only 0.05M Params and 0.94G FLOPS. This is mainly because DAUF uses the parameters estimated from the compressed measurement and physical mask in the CASSI system to direct the iterative learning. These parameters capture critical information of CASSI degradation patterns and ill-posedness degree, providing key cues for HSI reconstruction.

To study the effect of the estimated parameters $\boldsymbol{\alpha}$ and $\boldsymbol{\beta}$, we perform a break-down ablation of DAUF. We adopt DAUHST-3stg as baseline-3 but $\boldsymbol{\alpha}$ is set as learnable parameters instead of being estimated by $\mathcal{E}$ in Eq.~\eqref{eq:dauf} and  $\boldsymbol{\beta}$ is not fed into $\mathcal{D}$. 
The results are shown in Tab.~\ref{tab:dauf_ablation}. Baseline-3 yields 36.49 dB. When $\boldsymbol{\alpha}$ is set to be estimated by $\mathcal{E}$, baseline-3 is improved by 0.45 dB. When $\boldsymbol{\beta}$ is fed into $\mathcal{D}$, baseline-3 gains by 0.34 dB. When $\boldsymbol{\alpha}$ and $\boldsymbol{\beta}$ are exploited jointly in the iterative learning, baseline-3 achieves a significant improvement of 0.72 dB. These results verify that the estimated parameters $\boldsymbol{\alpha}$ and $\boldsymbol{\beta}$ are beneficial for the linear projection and denoising network of deep unfolding methods.

To further analyze the roles of the estimated parameters, we visualize $\mathbf{z}_k$ and $\mathbf{x}_k$ of Eq.~\eqref{eq:dauf}, and plot the curves of $\boldsymbol{\alpha}$ and $\boldsymbol{\beta}$ as they change with the iteration in Fig.~\ref{fig:analysis}. We observe: \textbf{(i)} $\mathbf{z}_0$ and $\mathbf{x}_1$ yield either blurry or noisy images. There is a significant gap between them. Since  $\alpha_k = \mu_k$ in Eq.~\eqref{eq:hqs_2} penalizes the differences between $\mathbf{z}$ and $\mathbf{x}$, $\alpha_1$ is estimated to be a large value. From the linear projection of the second iteration ($\mathbf{z}_1 \rightarrow \mathbf{x}_2$) on, the gap between $\mathbf{z}$ and $\mathbf{x}$ decreases substantially. Therefore, $\alpha_{k}$ are estimated to be small values when $k\ge2$. This indicates that $\boldsymbol{\alpha}$ can adaptively scale the linear projection $\mathcal{P}$. \textbf{(ii)} The noise corruption is severe in the first iteration. Thus, $\beta_1$ = $\mu_1 / \tau_1$ = ${1/}{(\sqrt{\tau_1/\mu_1})^2}$, which is inversely proportional to the noise level, is estimated to be a small value. With further iterations, the noise level decreases, and thus the estimated   $\beta_k$ increases. These results demonstrate that $\boldsymbol{\beta}$ can provide the information about noise level  for the denoising network $\mathcal{D}$. 



\vspace{-2mm}
\section{Conclusion} 
\vspace{-2mm}
In this paper, we remedy two issues of previous deep unfolding methods, \emph{i.e.}, they do not estimate informative parameters from the CASSI system to direct the iterative learning and they are mainly CNN-based showing limitations in capturing long-range dependencies. To cope with  these challenges, we firstly formulate a principled MAP-based unfolding framework DAUF that estimates parameters from the compressed measurement and physical mask. Then the parameters, which capture critical cues of CASSI degradation patterns and ill-posedness degree, are fed into each iteration to contextually scale the linear projection and provide noise level information for the denoising network. Secondly, we propose a novel Transformer HST that can jointly extract local contents and model non-local dependencies. By plugging HST into DAUF, we derive the first Transformer-based unfolding method DAUHST for HSI reconstruction. Comprehensive experiments show that our DAUHST outperforms SOTA methods by a large margin while requiring much cheaper memory and computational costs. 

{
	\bibliographystyle{ieeetr}
	\bibliography{reference}
}

\end{document}