\def\year{2020}\relax
\documentclass[letterpaper]{article} \usepackage{aaai20}  \usepackage{times}  \usepackage{helvet} \usepackage{courier}  \usepackage[hyphens]{url}  \usepackage{graphicx} 

\urlstyle{rm} \def\UrlFont{\rm}  \usepackage{graphicx}  \usepackage{xcolor}
\usepackage[inline]{enumitem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}       \usepackage{multirow}
\usepackage{amsfonts}  
\usepackage{fontawesome}
\usepackage{stix}
\usepackage{nicefrac}
\usepackage{subcaption}
\usepackage{color, colortbl}
\definecolor{Gray}{gray}{0.9}

\frenchspacing  \setlength{\pdfpagewidth}{8.5in}  \setlength{\pdfpageheight}{11in}  

\pdfinfo{
/Title (SampleFix: Learning to Correct Programs by Sampling Diverse Fixes)
}




\setcounter{secnumdepth}{2} 

\setlength\titlebox{2.5in} \newcommand{\samplefix}{SampleFix}
\newcommand{\dssmaplefix}{DS-SampleFix}
\newcommand{\regularizer}{diversity-sensitive}
\newcommand{\figref}{Figure}
\newcommand{\figsref}{Figures}
\newcommand{\equref}{Equation}
\newcommand{\tableref}{Table}

\newcommand{\myparagraph}[1]{\vspace{0.0em}\noindent\textbf{#1.}}

\title{SampleFix: Learning to Correct Programs by Sampling Diverse Fixes }
\author{
Hossein Hajipour{\normalfont \textsuperscript{1}}, Apratim Bhattacharya {\normalfont \textsuperscript{2}}, Mario Fritz{\normalfont \textsuperscript{1}}  \vspace{0.1cm} \\
  \textsuperscript{1}CISPA Helmholtz Center for Information Security, Saarland Informatics Campus \\ \textsuperscript{2}  Max Planck Institute for Informatics, Saarland Informatics Campus
 \\
  \texttt{\{hossein.hajipour,fritz\}@cispa.saarland}, \\
  \texttt{abhattac@mpi-inf.mpg.de} \vspace{-.4cm}
}

\begin{document}

\maketitle

\begin{abstract}
Automatic program correction is an active topic of research, which holds the potential of dramatically improving productivity of programmers during the software development process and correctness of software in general. Recent advances in machine learning, deep learning and NLP have rekindled the hope to eventually fully automate the process of repairing programs. A key challenge is ambiguity, as multiple codes -- or fixes -- can implement the same functionality. In addition, datasets by nature fail to capture the variance introduced by such ambiguities. Therefore, we propose a deep generative model to automatically correct programming errors by learning a distribution of potential fixes. Our model is formulated as a deep conditional variational autoencoder that samples diverse fixes for the given erroneous programs. In order to account for ambiguity and inherent lack of representative datasets, we propose a novel regularizer to encourage the model to generate diverse fixes. Our evaluations on common programming errors show for the first time the generation of diverse fixes and strong improvements over the state-of-the-art approaches by fixing up to  of the mistakes. 
\end{abstract}


\section{Introduction}
\label{introduction}
Software development is a time-consuming and expensive process. Unfortunately, programs written by humans typically come with bugs, so that significant effort needs to be invested to obtain code that is only likely to be correct. 
Debugging is typically performed by humans and therefore tedious and can also contain mistakes. This is neither desirable nor acceptable in many critical applications. Therefore, automatically locating and correcting program errors offers the potential to increase productivity as well as improve correctness of software. 


Advances in machine learning, deep learning \cite{Lecun98gradient-basedlearning,ng11unsupervised,alexnet}, computer vision \cite{Girshick15fast,Simonyan15} and NLP \cite{sutskever14seq2seq,Bahdanau2015NeuralMT} has  dramatically boosted the machine's ability to automatically learn representations of natural data such as images and natural language contents for various tasks.  Deep learning models also have been successful in learning the distribution over continuous \cite{cvae15sohn,autoencodr14kingma} and discrete data \cite{Maddison2017TheCD,jang18gumbel}, to generate new and diverse data points \cite{three_pillars}. These advances in machine learning and the advent of large corpora of source code \cite{bigcode} provide new opportunities toward harnessing deep learning methods to understand, generate or debug programs.

\begin{figure}
\centering
    \includegraphics[width=0.90\linewidth]{figs/teaser4.png}
    \caption{An example highlighting inherent ambiguity of possible fixes of erroneous programs.}
\label{fig:teaser}
\end{figure}

There has been an increasing interest to carry over the success stories of deep learning in NLP and related techniques to  employed deep learning-based approaches to tackle the ``common programming errors'' problem \cite{Gupta2017DeepFixFC,gupta2019RLAssist}. Such investigations have included compile-time errors such as missing scope delimiters, adding extraneous symbols, using incompatible operators as ``common programming errors''. Novice programmers and even experienced developers often struggled with these type of errors \cite{seo2014programmers}, which is usually due to lack of attention to the details of programs and/or programmer's inexperience \cite{gupta2019RLAssist}.


Recently, \citeauthor{Gupta2017DeepFixFC} proposes a deep sequence to sequence model called Deepfix where, given an erroneous program, the model predicts the locations of the errors and a potential fix for each predicted location. The problem is formulated as a one-to-one mapping task, where the model is trained to predict a single fix for each location with an error. No ambiguity is taken into account. However, different codes -- and therefore also their fixes -- can express the same functionality  (\figref \,\ref{fig:teaser}). The inherent ambiguity argues for a one-to-many mapping in order to account for ambiguity as well as uncertainty of the model and limited training data.




Hence, we propose a deep generative framework to automatically correct programming errors by learning the distribution of potential fixes. At the core of our approach is a conditional variational autoencoder that is trained to sample accurate and diverse fixes for the given erroneous programs, and interacts with a compiler that evaluates the sampled candidate fixes in the context of the given programs. The interplay of sampler and compiler allows for an iterative refinement procedure. A key contribution of our approach is a novel regularizer which encourages diversity by penalizing the distance among candidate samples, which thereby significantly increases the effectiveness by producing more diverse samples. 



To summarize, the contributions of this paper are as follows,
\begin{enumerate*}
    \item We  propose a generative framework to automatically correct common programming errors by learning the distribution over potential fixes and interacting with a compiler in an iterative procedure.
    \item We propose a novel regularizer to encourage the model to generate diverse fixes.
    \item Our conditional generative model together with the diversity regularizer shows an increase in the diversity of samples and strong improvement over the state-of-the-art approaches on real world scenarios.
\end{enumerate*}

\section{Related Work}
\label{related_Work}

Our work builds on the general idea of sequence to sequence models as well as ideas from neural machine translation. We phrase our approach as a variational auto-encoder and compare it to prior work learning-based program repair. We review the related work in order below
\paragraph{Neural Machine Translation.}
\citeauthor{sutskever14seq2seq} introduces neural machine translation and casts it as a sequence to sequence learning problem. The popular encoder-decoder architecture is introduced to map the source sentences into target sentences. One the major drawback of this model is that the sequence encoder needs to compress all of the extracted information into a fixed length vector. \cite{Bahdanau2015NeuralMT} addresses this issue by using attention mechanism in the encoder-decoder architecture, where it focuses on the most relevant part of encoded information by learning to search over the encoded vector. In our work, we employ sequence to sequence model with attention to parameterize our generative model. This model gets an incorrect program as input, and maps it to many potential fixes by drawing samples on estimated distribution of the fixes.
\paragraph{Variational Autoencoders.}
\label{rw_variational_autoencoder}
The variational autoencoder \cite{autoencodr14kingma,variational15rezende} is a generative model designed to learn deep directed latent variable based graphical models of large datasets. The model is trained on the data distribution by maximizing the variational lower bound of the log-likelihood as the objective function. \citeauthor{gensen16bowman} extends this framework by introducing a RNN-based variational autoencoder to enable the learning of latent variable based generative models on text data. The proposed model is successful at generating diverse and coherent sentences. To model conditional distributions for the structured output representation \citeauthor{cvae15sohn} extended variational autoencoders by introducing an objective which maximizes the conditional data log-likelihood. In our approach, we use an RNN-based conditional variational autoencoder to model the distribution of the potential fixes given erroneous programs. 
\paragraph{Learning-based Program Repair.}
\label{rw_program_repair}
Recently there has been a growing interest in using learning-based approaches to automatically repair the programs \cite{monperrus2018automatic}. \citeauthor{long2016automatic} proposed a probabilistic model by explicitly designing code features to rank potential fixes for a given program. \citeauthor{pu2016sk_p} employ an encoder-decoder neural architecture to automatically correct programs, where they use beam search to generate candidate programs. In these works, and many learning-based programming repair approaches, enumerative search over programs is required to resolve all errors. However, our proposed framework is capable of predicting the location and potential fixes by passing the whole program to the model. Besides this, unlike our approach, which only generates fixes for the given erroneous program, \citeauthor{pu2016sk_p} need to predict whole program statements to resolve bugs.


DeepFix \cite{Gupta2017DeepFixFC} and RLAssist \cite{gupta2019RLAssist} uses neural representations to repair syntax errors in programs. In detail, DeepFix uses a sequence to sequence model to directly predict a fix for incorrect programs. In contrast, our generative framework is able to generate and evaluate multiple fixes by learning the distribution of potential correctness. Therefore, our model does not penalize, but rather encourages diverse fixes. RLAssist repairs the programs by employing a reinforcement learning approach. They train an agent which navigate over the program to locate and resolve the syntax errors. In this work, they only address the typographic errors, rely on a hand designed action space and meet problems due to the increasing size of the action space. In contrast, our method shows improved performance on typographic errors and also generalizes to issues with missing variable declaration errors. 


\citeauthor{harrer18learning-to-repair} use generative adversarial networks to repair software vulnerabilities. They propose an adversarial approach to map from bad code domain to the correct code domain in an unsupervised fashion. They propose an unsupervised approach to repair the programs, however, there is no guarantee that their outputs do not introduce more errors to the input programs. In contrast, our generative framework automatically reject the sampled fixes which are introducing more errors to the input programs by using a compiler during inference time and directly models the distribution over potential fixes. 

\section{SampleFix: Generative Model for Code Fixes} 


Repairing the common program errors is a challenging task due to ambiguity in potential corrections and lack of representative data. Given a single broken program, there are multiple ways to fix the program. Therefore, alternative correct solutions -- that do not appear in the training set --  should not be penalized during training but rather encouraged. Therefore, we propose a deep generative framework to automatically repair common programming errors by learning the distribution of potential fixes -- rather than a single fix -- given the broken program. In other words, we model the problem of repairing programs as a one-to-many problem, where, our model learns the distribution of potential fixes through a generative model conditioned on the erroneous input program.  

We model the distribution of fixes using a conditional latent variable model, where the latent variables are learned using pairs of erroneous programs and the corresponding fixes. As mentioned before, to resolve programming errors, the generation of diverse fixes is crucial. The main reason is that by nature programs and their potential fixes are redundant and ambiguous. In addition, datasets are deprived of the large diversity of potential mistakes that can occur in programs. Hence, we need to model and encourage diverse samples. In order to address this issue, we propose a novel regularizer which encourages the model to generate diverse samples by penalizing the distance among drawn fixes.

\figref \,\ref{fig:generative-model} provides an overview of our proposed approach. For a given errorous program, the generative model draws  candidate fixes  ( in \figref \,\ref{fig:generative-model}) from the learned conditional distribution. In order to select one out of  candidate fixes, we employ an compiler which evaluate the candidate fixes. The compiler evaluates each fix by compiling the updated program. Out of  drawn fixes, the compiler selects the fix which resolves the largest number of error messages. In \figref \,\ref{fig:generative-model}, compiler selects , as the best fix for the given program. After updating the program, to resolve the remaining error(s), we follow \citeauthor{Gupta2017DeepFixFC} and iteratively input the updated program to our generative model. In the following, we formulate our generative model using the Conditional Variational Autoencoder framework and describe in detail our proposed novel regularizer. Finally, we provide details of our training and inference process.  

\begin{figure*}[h] 
	\centering
	    \centering
		\includegraphics[width = 0.8\textwidth]{figs/gen-model-final-2.png}
	
	\caption{Overview of SampleFix at inference time, highlighting the generation of diverse fixes.}
	\label{fig:generative-model}
	\vspace{-.1cm}
\end{figure*}

\subsection{Conditional Variational Autoencoders for Generating Fixes}
Conditional Variational Autoencoders (CVAE) \cite{cvae15sohn}, model conditional distributions  using latent variables  . The conditioning introduced through  enables the modelling of complex multi-model distributions. As powerful transformations can be learned using neural networks,  itself can have a simple distribution which allows for efficient sampling. This model allows for sampling from  given an input sequence , by first sampling latent variables  from the prior distribution . During training, amortized variational inference is used and the latent variables  are learned using a recognition network , parametrized by .  In detail, the variational lower bound of the model (\equref \,\ref{eq:elbo}) is maximized,


Penalizing the divergence of  to the prior in \equref \,\ref{eq:elbo} allows for sampling from the prior  during inference. In practice, the variational lower bound is estimated using Monte-Carlo integration,


\iffalse

\fi

where, , and  is the number of samples. We cast our generative model for resolving program errors in the Conditional Variational Autoencoder framework. In our formulation, the input  is the erroneous program and  is the potential fix. Note that  are sequences in our formulation. However, the plain CVAE as described in \cite{cvae15sohn} suffers from diversity issues. Usually, the drawn samples do not reflect the true variance of the posterior . This would amount to the correct fix potentially missing from our candidate fixes. To mitigate this problem, next we introduce a novel objective that aims to enhance the diversity of our candidate fixes. 

\subsection{\dssmaplefix: Encouraging Diversity with a Diversity-sensitive Regularizer}
\label{subsec:ds}
Casting our model in the Conditional Variational Autoencoder framework would enable us to sample a set of candidate fixes for a given erroneous program. However as pointed out in \cite{bhattacharyya2018accurate}, the standard variational lower bound objective does not encourage diversity in the candidate fixes. This is because the average likelihood of the candidate fixes is considered. In detail, as the average likelihood is considered, all candidate fixes must explain the ``true'' fix in training set well. This discourages diversity and severely constrains the recognition network, which is already constrained to maintain a Gaussian latent variable distribution. In practice, the learned distribution is pushed to the mean and fails to fully capture the variance of the true distribution. To encourage diversity, we employ the lower bound proposed by \cite{bhattacharyya2018accurate} and further include a novel regularizer. Our novel regularizer further encourages diversity and does not require a large number of candidate fixes  to be drawn at training time. In practice, we observe considerable gains even with the use of only  candidate fixes,



In comparison to \equref \,\ref{eq:elbo}, this lower bound (\equref \,\ref{eq:elboBMS}) encourages diversity in the model by allowing for multiple chances to draw highly likely candidate fixes. This enables the model to generate diverse candidate fixes, while maintaining high likelihood. In practice, due to numerical stability issues, the -sum-exp on the right of (\equref \,\ref{eq:elboBMS}) is approximated using the  (\equref \,\ref{eq:bms}). This approximate objective retains the diversity enhancing nature of \equref \,\ref{eq:elboBMS} while being easy to train,




While prior work uses around  samples during training, this is computationally prohibitive especially for large models, as it requires  times the memory or  times the number of forward passes. If  is decreased, the objective behaves similarly to the standard CVAE objective as the recognition network has fewer and fewer chances to draw highly likely samples/candidate fixes, thus limiting diversity. Therefore, in order to encourage the model to generate diverse fixes even when high values of  are computationally prohibitive, we propose a novel regularizer which penalizes the distance of two closest candidate fixes (\equref \,\ref{eq:ds}), thus forcing the candidate fixes to be diverse. 



\myparagraph{Distance Metric}
\label{para:metric}
Here, we discuss the distance metric  in \equref \,\ref{eq:ds}. Note, that the samples  can be of different lengths. Therefore, we consider the distance over the maximum length of the two samples and pad the shorter sample to equalize lengths. Next, we assume that our predicted distributions are point masses over each token. Under this assumption, the Euclidean distance is equivalent to the Wasserstein distance between the distributions. We also experimented with the commonly used cosine similarity. However, our approach performed better using the Euclidean (Wasserstein) distance. This is mainly because, in practice, Euclidean distance is easier to optimize.

\subsection{Model Architecture and Implementation Details}
	

\begin{figure}
\centering
    \includegraphics[width=0.74\linewidth]{figs/net-arch4.png}
    \caption{Overview of network architecture.}
\label{fig:net}
\end{figure}


To ensure fair comparison, our generative model is based on the popular sequence to sequence architecture with attention, similar to \cite{Gupta2017DeepFixFC}.  We employ LSTMs encoders and decoders. \figref \,\ref{fig:net} shows the architecture of our model in detail. Note that the recognition network is available to encode the fixes to latent variables  only during training. Another LSTM encoder is used to encode the conditioning input erroneous program  to a code vector . The decoder is conditioned on the code vector  and a sample of distribution with latent variables .


All of the networks in our framework consists of 4-layers of LSTM cells with 300 units. We apply dropout at rate 0.2 for each of these layers. To process the program through the networks, we tokenize the programs similar to the setting which used by \citeauthor{Gupta2017DeepFixFC} and process them into 50-dimensional vectors using an embedding layer. The network is optimized using ADAM optimizer \cite{kingma15adam} with the default learning rate and weight decay. We train the network up to 20 epochs and select the model with best validation performance. For the evaluation and comparisons we train two models, one for repairing the typographic errors, and another one for missing variable declaration errors. We use  samples to train our models, and  samples during inference time. All of these experiments are conducted on a Nvidia Tesla P40 with 22GB memory.

During inference, the conditioning erroneous program  is input to the encoder, which encodes the program to the vector . To generate multiple fixes using our decoder, the code vector  along with a sample of  from the prior  is input to the decoder. For simplicity, we use a standard Gaussian   prior, although more complex priors can be easily leveraged. The decoder is unrolled in time and output logits (). To sample from these logits we use computationally efficient Gibbs sampling strategy. We approximate a Gumbel distribution over the predicted logits \cite{jang18gumbel,Maddison2017TheCD} and predict each token by sampling over this distribution. We additionally experiment with a Beam search decoding scheme \cite{deshpande2019fast} to further enhance performance.  

\subsection{Iterative Repair}
We adopt the iterative repair procedure \cite{Gupta2017DeepFixFC} in the context of our proposed generative model, where the iterative procedure now leverages multiple candidate fixes. Given an erroneous program, each of our  candidate fixes contain a line number and the corresponding fix for that line. To select the best fix, we take the candidate fixes and the input erroneous program, reconcile them to create  updated programs. Our oracle which is a compiler takes these programs and selects a fix out of  candidate fixes which have a lowest number of error messages. After applying a fix on the input program, we feed the updated program to the network to resolve the other errors. This procedure is shown in \figref \,\ref{fig:generative-model}. 
In order to allow for a fair comparison to the state-of-the-art methods, we use the same setting for applying iterative repair strategy as it is described in \citeauthor{Gupta2017DeepFixFC}.

\section{Experiments}
\label{experiments}

We evaluate our approach on the task of repairing common programming errors. We evaluate the diversity and accuracy of our sampled error corrections as well as 
     compare our proposed method with the state-of-the-art.

\myparagraph{Dataset Details} 
Unfortunately, the choice of dataset in this domain is still quite limited. We use the dataset published by \citeauthor{Gupta2017DeepFixFC} as it's sizable and also includes real-world data for test. It contains programs written in C. The dataset consists of 93 different tasks which were written by students in an introductory programming course. The programs were collected using a web-based tutoring system \cite{das16tutorin}. The collected programs have token lengths in the range , and contain typographic and missing variable declaration errors. To tokenize the programs and generate training and test data we follow the procedure which is used by \citeauthor{Gupta2017DeepFixFC}, where they tokenized programs by considering different type of tokens, such as types, keywords, special characters, functions, literals and variables. Furthermore, the dataset contains two sets of data which are called synthetic and real-world data. The synthetic data contains the erroneous program which are synthesized by mutating correct programs written by students. The real-world data contains the real-world erroneous programs written by students. In line with prior work, we use the synthetic data to train and test our model, and use real-world data to evaluate the performance of our model in repairing the real-world erroneous programs.

In order to stay comparable with prior work, we follow the same training and evaluation procedure as in \citeauthor{Gupta2017DeepFixFC}. The dataset is divided into 5 cross-validation folds. In each fold,  of the programming tasks are held out as the test set, and the training data is generated by mutating the correct programs from the remaining  of the programming tasks. To generate the training pairs, correct programs are mutated to introduce the errors. Mutated programs are then paired with the fix for the first incorrect line, where each fix contains the line number and the corrected line for that program. We refer the reader to \citeauthor{Gupta2017DeepFixFC} for more details about the dataset.


\subsection{Evaluation}
\label{subsec:eval}
\begin{table}[t]

\fontsize{8.5}{10.5}\selectfont
\begin{center}
\caption{Results of performance comparison of DeepFix, \samplefix \,and \dssmaplefix \,on synthetic data. Typo , Miss Dec and All refer to typographic, missing variable declarations, and all of the errors respectively.}
\label{table:seeded}
\end{center}

\begin{center}
\begin{tabular}{lccc}
\toprule
Models & Typo & Miss Dec & All\\
\cmidrule(lr){1-1} \cmidrule(lr){2-4} 
DeepFix &   86.5\% &    81.3\% & 84.1\%\\
Our \samplefix &    87.1\% &   90.8\% & 88.7\%\\
Our \dssmaplefix &  96.1\% &    85.6\% & 90.4\% \\
\bottomrule
\end{tabular}
\end{center}

\end{table}

\begin{table*}[t]

 \fontsize{8.5}{10.5}\selectfont
\begin{center}
\caption{Top: Results of performance comparison of DeepFix, RLAssist, \samplefix \, and \dssmaplefix. Bottom: Results of performance comparison of DeepFix and \dssmaplefix \, with beam search decoding. Typo, Miss Dec and All refer to, typographic, missing variable declarations, and all of the errors respectively. \faCheck and \raisebox{1pt}{}  denote completely fixed programs and partially fixed programs, while \faBug \,denote resolved error messages.}
\label{table:acc}
\end{center}
\begin{center}
\vspace{-0.5cm}
\begin{tabular}{lccccccccc}
\toprule
Models   &  \multicolumn{3}{c}{Typo }& \multicolumn{3}{c}{Miss Dec} & \multicolumn{3}{c}{All} \\ \cmidrule(lr){1-1}\cmidrule(lr){2-4}\cmidrule(lr){5-7}\cmidrule(lr){8-10}
             & \hspace{5pt}\faCheck & \hspace{5pt}\raisebox{1pt}{}    & \hspace{5pt}\faBug & \hspace{5pt}\faCheck & \hspace{5pt}\raisebox{1pt}{} & \hspace{5pt}\faBug & \hspace{5pt}\faCheck & \hspace{5pt}\raisebox{1pt}{}  & \hspace{5pt}\faBug \\
DeepFix \cite{Gupta2017DeepFixFC} &  23.3\% &   16.2\%     & 30.8\%       & 10.1\%         &  12.2\%        &    12.9\%     &      33.4\%  &   22.3\%     &    40.8\%    \\ 
\textit{RLAssist} \cite{gupta2019RLAssist} &  \textit{26.6}\%       &   \textit{20.4}\%     &   \textit{39.7}\%     &    -      &    -      &    -     &   -     &      -  &    -    \\ 
Our \samplefix  &     24.8\%     &  \textbf{22.3\%}      &   38.8\%     &  16.1\%        &   19.0\%       &    22.8\%     &     40.9\%   &    33.4\%    &     56.3\%   \\ 
Our \dssmaplefix &  \textbf{27.7\%}        &    21.5\%    &   \textbf{40.9\%}     &   \textbf{16.7\%}       &  \textbf{21.2\%}        &    \textbf{24.7\%}     &   \textbf{44.4\%}     &  \textbf{35.5\%}      &  \textbf{61.0\%}      \\

\midrule
Our DeepFix + Beam Search &  25.9\%        &    22.7\%    &   42.2\%     &   \textbf{20.3\%}       &  34.5\%        &    47.0\%     &   44.7\%     &  36.8\%      &  63.9\% \\
Our \dssmaplefix \, + Beam Search & \textbf{27.8\%}        &    \textbf{24.9}\%    &   \textbf{45.6\%}     &   19.2\%       &  \textbf{35.6\%}        &    \textbf{47.9\%}     &   \textbf{45.2\%}     &  \textbf{37.6\%}      &  \textbf{65.2\%} 
\\\bottomrule
\end{tabular}




\end{center}
\end{table*}
We evaluate our approach on synthetic and real-world erroneous programs. To evaluate our approach on the synthetic test set we randomly select 10k pairs of the data for resolving typographic and missing variable declaration errors. This data contains pairs of erroneous programs with the intended fixes for the first incorrect line in programs. To evaluate our approach on real-world data we use a real-world set of erroneous programs which contains 6975 erroneous programs with 16766 error messages. Unlike synthetic test set, we don't have access to intended fix(es) in the real-world data.

\myparagraph{Synthetic Data} 
\tableref \,\ref{table:seeded} shows the comparison of our proposed approaches, \samplefix \, and \dssmaplefix, with DeepFix \cite{Gupta2017DeepFixFC} on synthetic data in the first iteration. In this table (\tableref \,\ref{table:seeded}), we can see that our approaches outperform DeepFix in generating intended fixes for the typographic and missing variable declaration errors. \samplefix \, and \dssmaplefix \,generate 88.7\% and 90.4\% of the intended fixes for typographic and missing variable declaration errors respectively. This (\tableref \,\ref{table:seeded}) shows that \dssmaplefix\, outperforms \samplefix\, in generating fixes for typographic errors. However, \dssmaplefix\, is not as effective as \samplefix\, in correcting the missing variable declaration errors, this is mainly due to the lack of diversity of this dataset. In other words, DeepFix and \samplefix \, (without our diversity regularizer) memorizes the fixes from the training set. However, as we demonstrate in the following, this performance advantage does not translate to real world scenarios.




\myparagraph{Real-World Data} In \tableref \,\ref{table:acc} (top four rows) we show the comparison of our approaches, \samplefix \, and \dssmaplefix, with DeepFix \cite{Gupta2017DeepFixFC} and RLAssist \cite{gupta2019RLAssist} on the real-world test set . We also refer to the results of RLAssist, however, it has to be noted that it is not directly comparable as this approach relies on handcrafted actions. Furthermore, it has only been shown to resolve typographic errors.  

\tableref \,\ref{table:acc} (top four rows) shows that our approaches (with 100 samples obtained using Gumbel sampling) outperform DeepFix in resolving both typographic and missing variable declaration error messages. This shows that generating multiple diverse fixes can lead to substantial improvement in performance. \samplefix \, and \dssmaplefix \, resolve 38.8\% and 40.9\% of all of the typographic error messages and 22.8\%, and 24.7\% of missing variable declaration respectively. These results show that \dssmaplefix \,outperforms DeepFix by a large margin of \
32.7\% and 91.4\% (relative improvement) in resolving typographic and missing variable declaration errors -- almost double the performance of the latter. We also competitive with RLAssist approach while our approach does not require any additional supervision in term of actions. Overall, \dssmaplefix \, is able to fix  of all errors - a  improvement over DeepFix. Furthermore, the performance advantage of \dssmaplefix \, over \samplefix \, shows the effectiveness of our novel regularizer.

\myparagraph{Beam Search Decoding} 
So far we have considered only the Top-1 sample of DeepFix (as in \cite{Gupta2017DeepFixFC}). For fairness, in \tableref \,\ref{table:acc} we consider sampling multiple fixes also from DeepFix (this setting was not considered by \cite{Gupta2017DeepFixFC}). We use beam search to estimate the Top-100 (unique) samples from DeepFix with the highest posterior probability \cite{deshpande2019fast}. However, also note that beam search is computationally expensive algorithm and its significantly slower than generative models \cite{deshpande2019fast}. In \tableref \,\ref{table:acc} (bottom two rows) we show that our proposed approach (\dssmaplefix) can also employ beam search to improve performance. In order to employ beam search decoding with \dssmaplefix , we consider beam width of size 5 for each sample  and in total 20  samples. Again we see that \dssmaplefix \, outperforms DeepFix, showing that our \dssmaplefix \, not only samples diverse but also accurate fixes.

\myparagraph{Qualitative Examples} 
We provide qualitative examples in \figref  \,\ref{fig:qual:example}. We illustrate diverse fixes generated by our \dssmaplefix \, in \figref \,\ref{fig:example1} with a code example with typograhic errors, with the corresponding outputs of DeepFix and 5 output samples of 100 drawn samples of \dssmaplefix. We see that DS-SampleFix generates multiple correct fixes for the given program and in contrast to DeepFix - which only predicts a single fix - our model is able to generate multiple diverse fixes. This indicate that our approach is capable of handling inherent ambiguity and uncertainty in predicting fixes for the erroneous programs. Note that DeepFix and \dssmaplefix \, output a program location along with the corresponding fix, and these models output  \textit{\_eos\_} whenever they could not provide any fix for the given erroneous program. \figref \,\ref{fig:example2} shows a code example where DS-SampleFix repairs the typographic and missing variable declaration errors. In \figref \,\ref{fig:example2}, we can see that our approach resolves one missing variable declaration error, by defining variable  at line 3, and remove a bracket at line 11, and insert a bracket at line 15 to resolve typographic errors. More code examples can be found in the Appendix A.
\begin{figure*}[h] 
	\centering
	    \centering
	    
	    \begin{subfigure}[b]{0.49\textwidth}
	    \centering
		\includegraphics[width=\linewidth]{figs/prog41741.png}
		\caption{Diverse fixes generated by our DS-SampleFix. }
		\label{fig:example1}
    	\end{subfigure} \hfill
    	\begin{subfigure}[b]{0.49\textwidth}
    	    \centering
    		\includegraphics[width=\linewidth, ]{figs/prog2-example-final.png} 
    		\caption{Iterative repair.}
    		\label{fig:example2}
    	\end{subfigure} 
	
	\caption{(a) Left: Example program with a typographic error. The error is highlighted at line 19. (a) Right: Our DS-SampleFix generates multiple correct fixes (line number and fix), highlighting the ability of DS-SampleFix to generate diverse fixes (correct fixes with green tick). DeepFix is unable to generate any fix. (b) Examples of resolving typographic errors, and missing variable declaration errors using our approach (\dssmaplefix).}
	\label{fig:qual:example}
	\vspace{-.1cm}
\end{figure*}

\subsection{Effectiveness of Sampling Strategy}
\begin{figure*}[h] 
	\centering
	\begin{subfigure}[b]{0.49\textwidth}
	    \centering
		\includegraphics[height=3.5cm]{figs/freq-all-3.png}
		\caption{Sampling strategy.}
		\label{fig:freq}
	\end{subfigure} \hfill
	\begin{subfigure}[b]{0.49\textwidth}
	    \centering
		\includegraphics[height=3.5cm]{figs/itr-all3.png} 
		\caption{Iterative repair.}
		\label{fig:iterations}
	\end{subfigure} 
	\caption{(a) Number of resolved error messages with drawing 1, 10 and 100 samples for \samplefix \,, \dssmaplefix \,, \dssmaplefix\,+ beam search, and DeepFix + beam search in comparison to number of resolved error messages by DeepFix. (b) Number of error messages after each iterations for DeepFix, DeepFix + beam search,  \samplefix, \dssmaplefix, and \dssmaplefix\,+ beam search.}
	\label{fig:disc}
	\vspace{-0.3cm}
\end{figure*}

We further analyze the effectiveness of our proposed \dssmaplefix\, in drawing multiple diverse samples for a given incorrect program. \figref \,\ref{fig:freq} shows in detail the effectiveness of drawing multiple samples for repairing 1426 unseen programs from a held out fold of real-world data. In \figref \,\ref{fig:freq} x and y axis refer to number of drawn samples and number of resolved error messages respectively. These programs contain typographic and missing variable declaration errors. We see that although DeepFix outperforms \samplefix \, and \dssmaplefix \, when we only one sample is drawn to resolve each program, by drawing more samples \samplefix \, and \dssmaplefix \, are able to resolve larger number error messages, and both of our approaches outperform DeepFix after drawing 100 samples. Furthermore, \figref \,\ref{fig:freq} also further illustrates the effectiveness of our novel regularizer, as \dssmaplefix \, outperforms \samplefix \, at every step. \figref \,\ref{fig:freq} also shows the effectiveness of using beam search with DeepFix and \dssmaplefix \,. We see that using beam search on top the models improve the performance of DeepFix and \dssmaplefix \, by finding top and unique fixes. This figure shows that after drawing 100 fixes  \dssmaplefix \, with beam search outperforms DeepFix + beam search. This shows that our proposed regularizer not only enables the model to draw more diverse fixes but also more accurate fixes. 

\subsection{Effectiveness of Iterative Repair}
To resolve the multiple errors in a program we use the iterative repair strategy as introduced by \cite{Gupta2017DeepFixFC}. Here, we analyze the effectiveness of our proposed approaches in resolving multiple errors in a program using iterative repair strategy. \figref \,\ref{fig:iterations} show the number of remaining errors messages in 5 iterations for DeepFix, DeepFix with beam search, \samplefix \, , \dssmaplefix, and \dssmaplefix \,with beam search. This figure shows the original number of error messages for 1426 programs (a held out fold of real-world data) marked as iteration 0, and then shows the number of remaining error messages after end of every iteration for different approaches. We use up to 5 iterations to resolve multiple error messages. We can see that after 5 iterations, \samplefix \, and \dssmaplefix \, resolve more error messages than DeepFix, and \dssmaplefix \,with beam search outperforms all of the other approaches. One of the reason that our approaches outperform DeepFix over the different iterations is that, DeepFix is only capable of predicting one fix for a given program, and if the network fails to produce a fix for a program in an iteration, then feeding the same program into the network in the subsequent iterations will not change the outcome. However, our proposed approaches are capable of drawing multiple fixes in each iteration, which means that our methods can resolve more error messages in each iteration, and we will have larger number of programs to feed it to the network in next iteration. 


\section{Conclusion}
We propose a novel framework to correct common programming errors. We recognize and model the inherent ambiguity and uncertainty when predicting fixes. In contrast to previous approaches, our novel framework is able to learn the distribution of candidate fixes rather than the most likely fix. The key to our success is a novel diversity-sensitive regularizer. This helps us overcome the inherent limitations of supervised datasets in this challenging domain  and generalize to unseen real world test sets. Furthermore, our experiments show that the steady increase in discovery of correct programs as we draw more candidate fixes is a strong indication that our proposed model can be the basis of further advances in debugging by sampling based approaches.

\bibliography{arxiv}
\bibliographystyle{aaai.bst}

\newpage

\section*{Appendix A. Additional Qualitative Examples}
\label{sec:aditional}

\begin{figure}[b] 
	\centering
	\includegraphics[width=0.9\linewidth]{figs/prog1-example-final.png} 
	\caption{Additional example of resolving missing variable declaration errors using our approach (\dssmaplefix). }
	\label{fig:examples:missdec}
	\vspace{-.1cm}
\end{figure}


Here we provide additional examples of correcting erroneous programs using our proposed method.\,\figref \,\ref{fig:examples:missdec} shows a code example which indicate our approach is capable of resolving multiple missing variable declaration errors.\,\figsref \,\ref{fig:sup:example2} and \ref{fig:sup:example3} shows code examples with typographic errors and missing variable declaration errors, with the corresponding outputs of DeepFix and DS-SampleFix given these erroneous programs. In these examples, DeepFix fails to resolve these errors. However, our proposed approach (DS-SampleFix) is able to successfully resolve the errors by sampling diverse fixes. Here we show 5 samples out of 100 drawn samples. Note that each model outputs a program location along with the corresponding fix, and a model outputs  \textit{\_eos\_} whenever it could not provide any fix for the given erroneous program. \figref \,\ref{fig:sup:example2} shows an example of erroneous program with typographic errors, and the corresponding outputs of DeepFix and DS-SampleFix given that program.




\begin{figure}[b] 
	\centering
	    \centering
		\includegraphics[width = 0.48\textwidth]{sup/prog00218.png}
	
	\caption{Example program with a typographic error. The error is highlighted at line 5. Our DS-SampleFix generates multiple candidate fixes (line number and fix) which attempt the fix the correct bug (correct fix with green tick).}
	\label{fig:sup:example2}
	\vspace{-.1cm}
\end{figure}


\begin{figure*}[h]
	\begin{subfigure}[b]{0.49\textwidth}
	    \centering
		\includegraphics[width = 1.0\textwidth]{sup/prog03368.png}
		\caption{}
	\end{subfigure}
	\begin{subfigure}[b]{0.49\textwidth}
	    \centering
		\includegraphics[width = 1.0\textwidth]{sup/prog22202.png}
		\caption{}
	\end{subfigure}
	\caption{Example programs with missing variable declaration errors. The potential location of the error is highlighted. Our DS-SampleFix generates multiple candidate fixes which attempt to declare variables (correct fix with green tick). DeepFix is unable to generate any fix.}
	\label{fig:sup:example3}
	\vspace{-.1cm}
\end{figure*}

\figsref \, \ref{fig:sup:itr_typo} and \ref{fig:sup:itr_ids} show two examples of resolving multiple errors using itrerative repair strategy, here we show 5 samples out of 100 drawn samples. In \figref \, \ref{fig:sup:itr_typo_itr1} we can see that in the first iteration our approach resolves a typographic error at line 9, and in the second iteration (\figref \, \ref{fig:sup:itr_typo_itr2}), after updating the program, it resolves another typographic error at line 11. \figref \, \ref{fig:sup:itr_ids}, show an example of iteratively resolving multiple missing variable declaration errors. \figsref \, \ref{fig:sup:itr_ids_itr1} and \ref{fig:sup:itr_ids_itr2} show resolving multiple errors by defining variables  and  respectively. 




\begin{figure*}[h] 
	\centering
	\begin{subfigure}[b]{0.49\textwidth}
	    \centering
		\includegraphics[width=\linewidth]{sup/typo-itr1.png}
		\caption{ }
		\label{fig:sup:itr_typo_itr1}
	\end{subfigure} \hfill
	\begin{subfigure}[b]{0.49\textwidth}
	    \centering
		\includegraphics[width=\linewidth, ]{sup/typo-itr2.png} 
		\caption{}
		\label{fig:sup:itr_typo_itr2}
	\end{subfigure} 
	\caption{An example of iteratively resolving multiple typographic errors using our approach (\dssmaplefix).}
	\label{fig:sup:itr_typo}
	\vspace{-.1cm}
\end{figure*}



\begin{figure*}[h] 
	\centering
	\begin{subfigure}[b]{0.49\textwidth}
	    \centering
		\includegraphics[width=\linewidth]{sup/ids-itr1-2.png}
		\caption{ }
		\label{fig:sup:itr_ids_itr1}
	\end{subfigure} \hfill
	\begin{subfigure}[b]{0.49\textwidth}
	    \centering
		\includegraphics[width=\linewidth, ]{sup/ids-itr2.png} 
		\caption{}
		\label{fig:sup:itr_ids_itr2}
	\end{subfigure} 
	\caption{An example of iteratively resolving multiple missing variable declaration errors using our approach (\dssmaplefix).}
	\label{fig:sup:itr_ids}
	\vspace{-.1cm}
\end{figure*}


\end{document}
