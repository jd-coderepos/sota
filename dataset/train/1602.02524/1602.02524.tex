








\documentclass[twocolumn]{autart}    

\usepackage{graphicx}          
\usepackage{dsfont} \usepackage[cmex10]{amsmath} \usepackage{varwidth} \usepackage{hyperref}

\newcommand{\ve}[1]{{\boldsymbol{#1}}} \newcommand{\tr}{\mbox{tr}} \newcommand{\ex}{\mathds{E}} \newcommand{\va}{\mathds{V}} 

\pdfoptionpdfminorversion=4
\pdfminorversion=4

\begin{document}
	
\journal{Automatica}
\volume{67}
\issue{May 2016}
\firstpage{216}
\lastpage{223}
\setcounter{page}{1}

\begin{frontmatter}
\title{Mean and variance of the LQG cost function}

\author[DCSC]{Hildo Bijl}\ead{h.j.bijl@tudelft.nl},
\author[DCSC]{Jan-Willem van Wingerden}\ead{j.w.vanwingerden@tudelft.nl},
\author[ITUU]{Thomas B. Sch\"on}\ead{thomas.schon@it.uu.se},
\author[DCSC]{Michel Verhaegen}\ead{m.verhaegen@tudelft.nl}

\address[DCSC]{Delft Center for Systems and Control, Delft University of Technology, The Netherlands}                                    
\address[ITUU]{Department of Information Technology, Uppsala University, Sweden}

\vspace{0.9cm}

\begin{center}
	\begin{varwidth}{14cm}
	\normalsize 
	\textbf{Please cite this version:}\\
	Hildo Bijl, Jan-Willem van Wingerden, Thomas B. Sch\"on, Michel Verhaegen. 
	Mean and variance of the LQG cost function. In \textit{Automatica}, Volume 67, May 2016, Pages 216-â€“223.\\
	\url{http://dx.doi.org/10.1016/j.automatica.2016.01.030}
	\end{varwidth}
\end{center}

\vspace{0.1cm}

\begin{keyword}
Linear systems; Linear quadratic regulators; LQG control; Lyapunov equation; Probability density function; Matrix algebra.
\end{keyword}

\begin{abstract}
Linear Quadratic Gaussian (LQG) systems are well-understood and methods to minimize the expected cost are readily available. Less is known about the statistical properties of the resulting cost function. The contribution of this paper is a set of analytic expressions for the mean and variance of the LQG cost function. These expressions are derived using two different methods, one using solutions to Lyapunov equations and the other using only matrix exponentials. Both the discounted and the non-discounted cost function are considered, as well as the finite-time and the infinite-time cost function. The derived expressions are successfully applied to an example system to reduce the probability of the cost exceeding a given threshold.
\end{abstract}

\end{frontmatter}

\section{Introduction}

The Linear-Quadratic-Gaussian (LQG) control paradigm is generally well-understood in literature. (See for instance \cite{LQBook,MFCBook,DMCSBook,StochasticControlBook}.) There are many methods available of calculating and minimizing the expected cost . However, much less is known about the resulting distribution of the cost function . Yet in many cases (like in machine learning applications, in risk analysis and similar stochastic problems) knowledge of the full distribution of the cost function , or at least knowledge of its variance , is important. That is the focus of this paper. We derive analytical expressions for both the mean~ and the variance~ of the cost function distribution for a variety of cases. The expressions for the variance~ have not been published before, making that the main contribution of this paper.

The cost function~ is usually defined as an integral over a squared non-zero-mean Gaussian process, turning its distribution into a generalized noncentral ~distribution. This distribution does not have a known Probability Density Function (PDF), although its properties have been studied before in literature, for instance in~\cite{MathematicalAnalysisOfRandomNoise,DistributionOfTheTimeAveragePower,LQGCostPDFApproximation}, and methods to approximate it are discussed in~\cite{QFRVBook,ChiSquareDistribution}. No expressions for the variance of the LQG system cost function are given though.

In LQG control most methods focus on the expected cost , but not all. For instance, Minimum Variance Control (MVC) (see \cite{StochasticControlBook}) minimizes the variance of the output , while Variance Constrained LQG (VCLQG) (see \cite{FuzzyWeightsForVCLQG,LQGControllerWithVarianceConstraints}) minimizes the cost function subject to bounds on the variance of the state  and/or the input . Alternatively, in Minimal Cost Variance (MCV) control (see~\cite{ControlUsingCostCumulants,StatisticalControlBook}) the mean cost~ is fixed through an equality constraint and the cost variance~ (or alternatively the cost cumulant) is then minimized. However, expressions for the cost variance  are still not given.

This paper is set up as follows. We present the problem formulation in Section~\ref{s:ProblemSetUp} and derive the expressions that solve this problem in Section~\ref{s:PropertiesOfLQGCost}, also making use of the appendices. Section~\ref{s:ApplicationToAnLQGSetUp} then shows how the equations can be applied to LQG systems, which is subsequently done in Section~\ref{s:NumericalEvaluation}. Finally, Section~\ref{s:ConclusionsAndRecommendations} contains the conclusions.

\section{Problem formulation} \label{s:ProblemSetUp}

We consider continuous linear systems subject to stochastic process noise. Formally, we write these as

where  is a vector of Brownian motions. (Note that~\eqref{eq:OfficialSystemDefinition} is not an LQG system, because it is lacking input. The extension to LQG systems will be discussed in Section~\ref{s:ApplicationToAnLQGSetUp}.) As a result,  is a Gaussian random process with zero-mean and an (assumed constant) covariance of~. Within the field of control (see for instance \cite{MFCBook}) this system is generally rewritten according to

where~ is zero-mean Gaussian white noise with intensity~. That is, , with  the Kronecker delta function. From a formal mathematical perspective this simplification is incorrect, because  is not measurable with nonzero probability. However, since this notation is common in the control literature, and since it prevents us from having to evaluate the corresponding It\^o integrals, we will stick with it, although the reader is referred to~\cite{StochasticDEBook} for methods to properly deal with stochastic differential equations.

We assume that the initial state~ has a Gaussian distribution satisfying

Note that the variance of~ is \textit{not}~, but actually equals~\mbox{}. We will use two different cost functions in this paper: the infinite-time cost~ and the finite-time cost~, respectively defined as

where  is a user-defined symmetric weight matrix. The parameter~ can be positive or negative. If it is positive, it is known as the prescribed degree of stability (see \cite{LQBook} or \cite{DMCSBook}), while if it is negative (like in Reinforcement Learning applications) it is known as the discount exponent.

\section{Mean and variance of the LQG cost function} \label{s:PropertiesOfLQGCost}

In this section we derive expressions for , ,  and . An overview of derived theorems, as well as the corresponding requirements, is shown in Table~\ref{t:TheoremOverview}.

\begin{table}[!t]
	\renewcommand{\arraystretch}{1.2}
	\caption{The theorems with which the mean and variance of  and  can be found, as well as the requirements for these theorems.}
	\label{t:TheoremOverview}
	\centering
	\begin{tabular}{|r||c|c|l|}
		\hline
		& \hspace{-3pt}If \hspace{-3pt} & \hspace{-3pt}If \hspace{-3pt} & \hspace{-3pt}Requirements \\
		\hline
		\hspace{-5pt}  \hspace{-5pt} & Th.~\ref{th:FiniteTimeCostMean} & Th.~\ref{th:FiniteTimeCostMeanWithAlphaZero} & \hspace{-3pt} and  Sylvester \\
		\hline
		\hspace{-5pt}  \hspace{-5pt} & 
		\multicolumn{2}{|c|}{Th.~\ref{th:InfiniteTimeCostMean}} & \hspace{-3pt} and  stable\hspace{-3pt} \\
		\hline
		\hspace{-5pt}  \hspace{-5pt} & Th.~\ref{th:FiniteTimeCostVariance} & Th.~\ref{th:FiniteTimeCostVarianceWithAlphaZero} & \hspace{-3pt}, ,  and  Sylvester\hspace{-3pt} \\
		\hline
		\hspace{-5pt}  \hspace{-5pt} & 
		\multicolumn{2}{|c|}{Th.~\ref{th:InfiniteTimeCostVariance}} & \hspace{-3pt} and  stable\hspace{-3pt} \\
		\hline
	\end{tabular}
\end{table}

\subsection{Notation and terminology} \label{ss:NotationAndTerminology}

Concerning the evolution of the state, we define ,  and . These quantities can be found through the theorems of Appendix~\ref{s:StateEvolution}.

We define the matrices  and similarly \mbox{} for any number . We also define  and  to be the solutions of the Lyapunov equations

We often have . In this case  equals , and we similarly shorten  to . The structure inherent in the Lyapunov equation induces interesting properties in its solutions , which are outlined in Appendix~\ref{s:LyapunovTheorems}.

We define the time-dependent solution  as

This integral can be calculated efficiently by solving a Lyapunov equation. (See Theorem~\ref{th:FiniteIntegralToLyapunov}.) Often it happens that the lower limit  of  equals zero. To simplify notation, we then write . Another integral solution  is defined as

This quantity can be calculated (see \cite{MatrixExponentials}) through

Considering terminology, we say that a matrix  is \textit{stable} (Hurwitz) if and only if it has no eigenvalue  with a real part equal to or larger than zero. Similarly, we say that a matrix  is \textit{Sylvester} if and only if it has no two eigenvalues  and  (with possibly ) satisfying . This latter definition is new in literature, but to the best of our knowledge, no term for this matrix property has been defined earlier.

\subsection{The expected cost}

We now examine the expected costs  and . Expressions for these costs are already known for various special cases. (See for instance \cite{DMCSBook,StochasticControlBook}.) To provide a complete overview of the subject, we have included expressions which are as general as possible.

\begin{thm}\label{th:FiniteTimeCostMean}
Consider system~\eqref{eq:SystemDefinition}. Assume that  and that  and  are both Sylvester. The expected value  of the finite-time cost ~\eqref{eq:FiniteTimeCostFunction} then equals

\end{thm}
\begin{pf}
From~\eqref{eq:FiniteTimeCostFunction} follows directly that

where  is defined as the above integral. To find it, we multiply~\eqref{eq:StateProcessDerivative} by  and integrate it to get

The left part, through integration by parts, must equal

As a result,  must satisfy the Lyapunov equation

Using Theorem~\ref{th:AddingLyapunovSolutions}, we can now write  as

Combining this with~\eqref{eq:EJTIntermediateExpression} and applying Theorem~\ref{th:InterchangeLyapunovSolutions} (with ) completes the proof.
\end{pf}

\begin{thm}\label{th:InfiniteTimeCostMean}
Consider system~\eqref{eq:SystemDefinition}. Assume that  and that  is stable. The expected value  of the infinite-time cost ~\eqref{eq:InfiniteTimeCostFunction} is then given by

\end{thm}
\begin{pf}
If we examine~\eqref{eq:FiniteTimeCostMean} in the limit as , then this theorem directly follows. After all, Theorem~\ref{th:PropertiesOfStateProcess} implies that, for stable ,  as .
\end{pf}

\begin{thm}\label{th:FiniteTimeCostMeanWithAlphaZero}
Consider system~\eqref{eq:SystemDefinition}. Assume that  and that  is Sylvester. The expected value  of the finite-time cost ~\eqref{eq:FiniteTimeCostFunction} is then given by

\end{thm}
\begin{pf}
If we consider~\eqref{eq:FiniteTimeCostMean} from Theorem~\ref{th:FiniteTimeCostMean} as , then this theorem directly follows. After all, we know from l'H\^opital's rule that .
\end{pf}

\subsection{The cost variance}

Next, we derive expressions for the variances  and . These expressions are new and as such are our main contribution. If we define , then  and  can be found through the following theorems.

\begin{thm}\label{th:FiniteTimeCostVariance}
Consider system~\eqref{eq:SystemDefinition}. Assume that  and that , ,  and  are Sylvester. The variance  of the finite-time cost ~\eqref{eq:FiniteTimeCostFunction} is then given by

\end{thm}
\begin{pf}
We will start our proof by evaluating . If we write  as  and  as , then we have

Taking the trace and applying Theorem~\ref{th:ExpectationOfDifferentGaussianPowerFour} gives us

where  equals  (see Theorem~\ref{th:PropertiesOfStateProcess}) and similarly for . There are three terms in the above equation. We will denote them by ,  and , respectively. The first term  directly equals  (see Theorem~\ref{th:FiniteTimeCostMean}). This is convenient, because , which means that  equals the remaining two terms .

The third term  is, according to definition~\eqref{eq:XQTDefinition}, equal to

where  can be evaluated through Theorem~\ref{th:FiniteIntegralToLyapunov}. That leaves . To find it, we first have to adjust the integrals. We note that  is symmetric with respect to  and . That is, if we would interchange  and , the integrand would be the same. As a result, we do not have to integrate over all values of  and . We can also only consider all cases where , integrate over this area, and then multiply the final result by . This gives us

Now, with , we can apply Theorem~\ref{th:MultipleTimeStateProcess} to substitute for . If we subsequently expand the brackets, and use the fact that  and hence also  is symmetric (see Theorem~\ref{th:SymmetricLyapunovSolution}), then the above term turns into

This expression again has three terms. We call them ,  and , respectively. First we find . We can again note that the integrand is symmetric with respect to  and , meaning we can apply the opposite trick of the one we applied at~\eqref{eq:TrickOfUsingSymmetry}. This gives us

The next term, , is not symmetric in  and . To bring both integration bounds back to zero, we now substitute  for . Subsequently interchanging the integrals results in

That leaves , which is the most involved term. We can apply the same substitution and interchanging of integrals to find that  equals

Expanding  using Theorem~\ref{th:FiniteIntegralToLyapunov} turns this into

where the final term  can be found through~\eqref{eq:CalculatingXTilde}. If we now merge all terms together, we find the result which we wanted to prove.
\end{pf}

\begin{thm}\label{th:InfiniteTimeCostVariance}
Consider system~\eqref{eq:SystemDefinition}. Assume that  and that  is stable. The variance  of the infinite-time cost ~\eqref{eq:InfiniteTimeCostFunction} is then given by

\end{thm}
\begin{pf}
As ,  and  become zero,  becomes  and hence~\eqref{eq:FiniteTimeCostVariance} reduces to

Through an excessive amount of elementary rewritings, using both  and Theorem~\ref{th:DifferenceBetweenLyapunovSolutions}, the above can be rewritten to~\eqref{eq:InfiniteTimeCostVariance}, which is a slightly more elegant version of the above expression.
\end{pf}

\begin{thm}\label{th:FiniteTimeCostVarianceWithAlphaZero}
Consider system~\eqref{eq:SystemDefinition}. Assume that  and that  is Sylvester. The variance  of the finite-time cost ~\eqref{eq:FiniteTimeCostFunction} is then given by

\end{thm}
\begin{pf}
We can evaluate~\eqref{eq:FiniteTimeCostVariance} from Theorem~\ref{th:FiniteTimeCostVariance} as . While doing so, we may use the relation

which follows from combining Theorems~\ref{th:FiniteIntegralToLyapunov} and~\ref{th:DifferenceBetweenLyapunovSolutions}. From this, we find through application of l'H\^opital's rule that

By using the above relation, the theorem directly follows.
\end{pf}

\subsection{Finding  and  using matrix exponentials}

The method of using Lyapunov solutions to find  and  has a significant downside: if  or  is not Sylvester, the theorems do not hold. By solving integrals using matrix exponentials, according to the methods described in~\cite{MatrixExponentials}, we can work around that problem.

\begin{thm}\label{th:MatrixExponentialsForCostMeanAndVariance}
If we define the matrix  as

and write  as

then we can find  and  through

\end{thm}
\begin{pf}
We first prove the expression for . If we insert~\eqref{eq:SigmaTIntermediateExpression} into~\eqref{eq:EJTIntermediateExpression}, we find that

We know from~\cite{MatrixExponentials} that

From this~\eqref{eq:FiniteTimeMatrixExponentialCostMean} directly follows. Proving the expression for  is done similarly, but with more bookkeeping. First of all,  equals (see~\cite{MatrixExponentials})

with a similar expression for . Next, we will find the terms  (see~\eqref{eq:T3Expression}) and  (see~\eqref{eq:TrickOfUsingSymmetry}), which together equal . We can directly see from~\eqref{eq:T3Expression} that  equals

Then we consider  from~\eqref{eq:TrickOfUsingSymmetry}. Instead of applying~\eqref{eq:SigmaTIntermediateExpression}, we now use

which is derived in an identical way. For ease of notation, we write , with  and  the two parts in the above expression. Inserting  into~\eqref{eq:TrickOfUsingSymmetry} then gives

The first term  here equals

The second term  is given by

We want the integration order to be . If we note that the integration area is described by , we can reorder the integrals. That is,

We now have two integrals, but we can solve both. If we split up the first one and rewrite the second one, we get

Finally there is . We first concern ourselves with the integration order and limits. By rearranging integrals, and by using the symmetry between  and  as well as between  and , we can find that

After inserting the integrand, we can rewrite this to

By combining all the results, we wind up with~\eqref{eq:FiniteTimeMatrixExponentialCostVariance}.
\end{pf}

So now we have two methods of finding  and . But which one is better? This mainly depends on the time . Our experiments have shown that, for small times , using matrix exponentials results in a better numerical accuracy than using Lyapunov solutions, but for large  the situation is exactly the opposite, and the numerical accuracy of the matrix exponential method quickly deteriorates. Similar results have been obtained by \cite{LyapunovEquationSolutions}, which examines the numerical accuracy of both algorithms when finding .

\section{Application to an LQG system} \label{s:ApplicationToAnLQGSetUp}

So far we have only considered systems of the form~\eqref{eq:SystemDefinition}, but in LQG systems there are also input and output signals. However, in that case we can always rewrite the system on the form~\eqref{eq:SystemDefinition}. In this section we show how to do this. For more details we refer to \cite{LQBook,MFCBook,DMCSBook,StochasticControlBook}.

First, we consider a system  with input. Its corresponding cost function equals

It is well-known in literature (see for instance \cite{KalmanFilter}) that the optimal control law minimizing  is a linear control law . If we assume that  and , then the optimal gain matrix  equals

with  the solution to the algebraic Riccati equation

For this optimal gain matrix  (and for any other matrix ) the system and cost function can be written as 

where we have . This shows that the system is now in our original form~\eqref{eq:SystemDefinition}.

A similar reduction can be performed when we are dealing with a noisy output equation , where  is zero-mean Gaussian white noise with intensity . To deal with this output equation, we take a state estimate  and update it through

To minimize the state estimation error , we need to choose the observer gain  equal to

where  is the solution to

We need this state estimate in a new optimal control law . This reduces the system equations to

which is again of the form we have seen earlier, albeit with a somewhat larger state vector. Because of this, all the equations that were originally developed for system~\eqref{eq:SystemDefinition} are applicable to LQG systems as well.

\section{Numerical evaluation} \label{s:NumericalEvaluation}

In this section we look at an example of how to apply the derived equations. In literature, researchers almost always use the controller which minimizes the expected value of the cost. This is done irrespective of the variance of the cost. But if the goal is to keep the cost below a certain threshold, then this may not be the best approach.

Consider the two-state system

where we will apply ,  and  in the cost function. As control law we use . We assume that the state  is fully known, and hence only  needs to be chosen. In practice this is often not the case and only a noisy measurement  will be available. To solve this, we can apply the theory from Section~\ref{s:ApplicationToAnLQGSetUp} and subsequently choose the observer gain  along with . However, this process is identical to choosing . So for simplicity of presentation, we only consider selecting .

The optimal control matrix follows from~\eqref{eq:OptimalGainMatrix} as . It minimizes  at . However, we can also minimize  using a basic gradient descent method. This gives the minimum-variance control matrix  with mean cost . This mean cost is significantly larger than , making it seem as if this is a significantly worse control matrix.

However, now suppose that we do not care so much about the mean cost. All we want is to reduce the probability that the cost  is above a certain threshold . That is, we aim to minimize  where we use , which is roughly ten times the mean. Using  numerical simulations, with \mbox{ s} and \mbox{ s}, we have found that

Hence the optimal controller has more than half as many threshold-violating cases as the minimum-variance control law, which is a significantly worse result. 

\section{Conclusions} \label{s:ConclusionsAndRecommendations}

In this paper, equations have been derived for the mean and the variance of both the infinite-time cost  and the finite-time cost . We have seen a case in which the equations can support controller synthesis by reducing the number of extreme cases that occur.

The infinite-time cost  has a finite value if and only if  is stable and . In this case,  can be found through Theorem~\ref{th:InfiniteTimeCostMean} and  through Theorem~\ref{th:InfiniteTimeCostVariance}. The finite-time cost  always has a finite value. The theorems needed to find its mean and variance, as well as the requirements for using these theorems, have been summarized in Table~\ref{t:TheoremOverview}. Alternatively, when  is not too large, these two quantities can also be calculated through Theorem~\ref{th:MatrixExponentialsForCostMeanAndVariance} using matrix exponentials for any  and .

\begin{ack}
This research is supported by the Dutch Technology Foundation STW, which is part of the Netherlands Organisation for Scientific Research (NWO), and which is partly funded by the Ministry of Economic Affairs (Project number: 12173, SMART-WIND). The work was also supported by the Swedish research Council (VR) via the project \emph{Probabilistic modeling of dynamical systems} (Contract number: 621-2013-5524).
\end{ack}

\appendix

\section{Evolution of the state} \label{s:StateEvolution}

The way in which the state  evolves over time is described by~\eqref{eq:SystemDefinition}. Solving this equation for  results in

We use this to derive statistical properties for . These properties are well-known (see for instance \cite{DMCSBook}), but they are included to give a good overview of existing theory.

\begin{thm}\label{th:PropertiesOfStateProcess}
When  satisfies system~\eqref{eq:SystemDefinition}, with the corresponding assumptions on  and , then  is a Gaussian random variable satisfying

\end{thm}
\begin{pf}
Because  is the sum of Gaussian variables, it will have a Gaussian distribution at all times . From~\eqref{eq:StateSolution}, its mean equals

The expected squared value is found similarly through

(The reduction of  to  is formally an application of the It\^o isometry, as explained in~\cite{StochasticDEBook}.) Next, by substituting  by , we find that

where in the end we have also applied Theorem~\ref{th:FiniteIntegralToLyapunov}.
\end{pf}

\begin{thm}\label{th:StateProcessDerivative}
The expected squared value  satisfies

\end{thm}
\begin{pf}
The derivative of~\eqref{eq:StateExpectedSquaredValue} equals

Applying  completes the proof.
\end{pf}

\begin{thm}\label{th:MultipleTimeStateProcess}
For  we have

Furthermore,  and .
\end{thm}
\begin{pf}
The proof is identical to that of Theorem~\ref{th:PropertiesOfStateProcess}.
\end{pf}

\section{Properties of Lyapunov equation solutions} \label{s:LyapunovTheorems}

\begin{thm}\label{th:LyapunovEquationSolutionUniqueness}
There is a unique solution for , and identically for , if and only if the matrix  is Sylvester.
\end{thm}
\begin{pf}
In literature it is known (see~\cite{SylvesterEquation}) that the Sylvester Equation  has a unique solution if and only if  and  do not have a common eigenvalue. Substituting  directly proves the theorem.
\end{pf}

\begin{thm}\label{th:SymmetricLyapunovSolution}
Assume that  is Sylvester. In this case  is symmetric if and only if  is symmetric.
\end{thm}
\begin{pf}
If we take the Lyapunov equation  and subtract its transpose, we find that

This equation has a unique solution (Theorem~\ref{th:LyapunovEquationSolutionUniqueness}) directly implying that  if and only if .
\end{pf}

\begin{thm}\label{th:InfiniteIntegralToLyapunov}
Assume that  is stable. Then  is Sylvester and the Lyapunov equation  has a unique solution  which equals

\end{thm}
\begin{pf}
The assumption that  is stable directly implies that  is Sylvester and hence (Theorem~\ref{th:LyapunovEquationSolutionUniqueness}) that  exists and is unique. Now we only need to prove~\eqref{eq:LyapunovIntegral}. Because  is stable, we know that . We can hence write  as

The equation above is a Lyapunov equation with the quantity between brackets as its unique solution .
\end{pf}

\begin{thm}\label{th:FiniteIntegralToLyapunov}
When  is Sylvester,  can either be found by solving the Lyapunov equation

or by first finding  and then using

\end{thm}
\begin{pf}
We first prove~\eqref{eq:FiniteTimeLyapunovEquation} through

To prove~\eqref{eq:FiniteTimeLyapunovEquationPartTwo} too, we will use  and the matrix property  to find that

The above expression actually equals~\eqref{eq:FiniteTimeLyapunovEquation}, except that the part between brackets is replaced by . Because  is Sylvester, the expression has a unique solution , which must equal the part between brackets.
\end{pf}

\begin{thm}\label{th:AddingLyapunovSolutions}
Assume that  is Sylvester and that . For any  and  we then have

\end{thm}
\begin{pf}
Per definition,  and . Left-multiplying the first expression by  and adding it to the second gives us

This is a Lyapunov equation with  as its solution.
\end{pf}

\begin{thm}\label{th:InterchangeLyapunovSolutions}
Assume that  is Sylvester. For matrices  and  satisfying  and , and for any  and , we have

\end{thm}
\begin{pf}
This is directly proven by

\end{pf}

\begin{thm}\label{th:DifferenceBetweenLyapunovSolutions}
Assume that both  and  are Sylvester. For , ,  and  we have

\end{thm}
\begin{pf}
Per definition, we have

By subtracting the two equations, and by using , we can get either of two results

Next, we divide the above equations by . The resulting Lyapunov equations have~\eqref{eq:DifferenceBetweenLyapunovSolutions} as their solution.
\end{pf}

\section{Power forms of Gaussian random variables} \label{s:GaussianPowerForms}

\begin{thm}\label{th:ExpectationOfGaussianPowerFour}
Consider a Gaussian random variable  with mean  and expected squared value . For symmetric matrices  and  we have

\end{thm}
\begin{pf}
We know from \cite{SCEMBook} (Appendix F.3) that, for symmetric  and , and for a \emph{zero-mean} process  with covariance , we have

If we apply this result to the expansion of

and rewrite the result,~\eqref{eq:ExpectationOfGaussianPowerFour} follows.
\end{pf}

\begin{thm}\label{th:ExpectationOfDifferentGaussianPowerFour}
Consider Gaussian random variables  and  with joint distribution

Also define , where the subscripts  and  can be substituted for  and/or . For symmetric matrices  and  we now have

\end{thm}
\begin{pf}
This follows directly from Theorem~\ref{th:ExpectationOfGaussianPowerFour} with

\end{pf}

\bibliographystyle{plain}        
\bibliography{bibliography}

\end{document}