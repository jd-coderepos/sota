\documentclass{llncs}




\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[ruled,noend,linesnumbered]{algorithm2e}
\DontPrintSemicolon




\newcommand{\coeff}{\mathrm{coeff}}
\newcommand{\DFT}{\mathrm{DFT}}
\newcommand{\poly}{\mathrm{poly}}
\newcommand{\SP}{\mathrm{span}}
\newcommand{\FF}{\mathbb{F}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\FG}{{\FF[G]}}
\newcommand{\GF}{\mathrm{GF}}
\newcommand{\abs}[1]{\lvert #1 \rvert}


\newcommand{\barG}{\bar{G}}
\newcommand{\barV}{\bar{V}}
\newcommand{\barE}{\bar{E}}
\newcommand{\barW}{\bar{w}}
\newcommand{\barN}{\bar{n}}
\newcommand{\barC}{\bar{c}}
\newcommand{\barCC}{\bar{C}}
\newcommand{\term}{\mathrm{term}}
\newcommand{\sgn}{\mathrm{sgn}}
\newcommand{\weff}{w_{\mathrm{eff}}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}



\begin{document}
\title{Finding the Minimum-Weight -Path}



\author{Avinatan Hassidim\thanks{Research supported by ISF grant 1241/12 and by GIF Young.} \and Orgad Keller \and Moshe Lewenstein\thanks{Research supported by BSF grant 2010437, a Google Research Award and GIF grant 1147/2011.} \and Liam Roditty}


\institute{Department of Computer Science, Bar-Ilan
University, Ramat-Gan, Israel \email{\{avinatan,kellero,moshe,liamr\}@cs.biu.ac.il}}

\maketitle

\begin{abstract}
Given a weighted -vertex graph  with integer edge-weights taken from a range , we show that the minimum-weight simple path visiting  vertices can be found in time . If the weights are reals in , we provide a -approximation which has a running time of . For the more general problem of -tree, in which we wish to find a minimum-weight copy of a -node tree  in a given weighted graph , under the same restrictions on edge weights respectively, we give an exact solution of running time  and a -approximate solution of running time . All of the above algorithms are randomized with a polynomially-small error probability.
\end{abstract}



\section{Introduction}
Given an -vertex graph  and a parameter , in the \emph{-path} problem we wish to find a path in  consisting of  vertices, if such exists. 
The -path problem can be easily shown to be NP-complete: when , it is exactly the Hamiltonian path problem. While a trivial  solution\footnote{Here and throughout, the  notation discards all factors that are polynomial in , , and  from the running time. Similarly, the  expressions discard poly-logarithmic factors. 
} is to try all  combinations of  vertices, better can be obtained; Monien was the first to show an improvement~\cite{Monien85}, with an  algorithm. In their seminal result, Alon, Yuster, and Zwick~\cite{AYZ95}  introduced the \emph{color-coding} technique. They used it to present a randomized  algorithm for this problem, which can be derandomized, replacing the  term with a large constant. Their result thus shows that the \textsc{logpath} problem of determining whether a graph contains a path of length  can be solved in polynomial time.
Later, two independent results~\cite{KMRR06,CLSZ07} presented randomized  algorithms, again with larger constants when derandomized, having running times of ~\cite{KMRR06} and ~\cite{CLSZ07}.

While these results were combinatorial in nature, the next improvements used algebraic techniques: Koutis~\cite{Koutis08} presented an algorithm solving the problem in  time. His method was perfected by Williams~\cite{Williams09}, reducing the running time to . This had somewhat closed the gap between the -path problem and the best method known for the specific case of finding a Hamiltonian path in a directed graph, which is  (though the latter is combinatorial in nature). For undirected graphs, recent results presented ~\cite{Bjorklund10} and later ~\cite{BHKK10,AB13}
running times for Hamiltonian path and -path, respectively.

It is worthwhile to focus on Koutis' and Williams' techniques, as they are the basis to this paper. They reduce -path and other problems to the problem of determining whether a given -variable polynomial contains a -multilinear-monomial (that is, a term which is the multiplication of  distinct variables) in its sum-product expansion. The problem is then solved by (roughly) evaluating this polynomial over random values taken from an adequate choice of an algebraic structure. 
In a later result~\cite{KW09} they both show that, in the evaluation framework they use, their technique for finding a -multilinear-monomial is essentially optimal, as any choice of an algebraic structure for the polynomial evaluation would require that the elements in this structure have an -sized representation. 

One of the most natural generalizations coming to mind, is the \emph{minimum-weight -path} problem: in this scenario, the graph edges are weighted and we wish to find a -path having minimum weight in the graph. In~\cite{Williams09} this was referred to as the \emph{short cheap tour} problem and mentioned that while the  methods can be easily extended to accommodate for this version, the algebraic methods do not seem to support such extension, and left this as an open problem. We solve this problem for the specific case in which the edge weights are integers in the range , incurring a running time which also has a superlinear dependency on . If the weights are reals in  (or can be normalized to this range, as is the case if they are in the range  for ), we provide a -approximation which reduces this dependency to . Notice that by this we conform to the important line of research in recent years, of discussing variants of distance problems in which edge-weights are integers taken from a bounded range, see e.g.,~\cite{Zwick02,CGS12}.

Another problem that generalizes -path is presented in~\cite{KW09}: in the -tree problem, given an -vertex graph  and a -node tree , find a copy of  in . For a similar generalization of this problem to \emph{minimum-weight -tree}, and under similar restrictions on the edge weights, we show similar exact and approximate results.
\paragraph{Paper Organization.}
In Section~\ref{sec:method}, we first present an  algorithm for computing the weight of the minimum-weight -path when edge weights are integers in , where  stands for the matrix multiplication exponent~\cite{Williams12}. In Section~\ref{sec:actual}, we show how to find the path itself, incurring an  multiplicative overhead for the above algorithm. Finally, in Section~\ref{sec:approx}, for the case of real edge-weights in , we provide a -approximation algorithm that reduces the dependency on  to , by using a technique of careful adaptive scaling of the edge weights. The overall running time of this algorithm is . 

In Section~\ref{sec:tree} we turn to the -tree problem, and show similar results: we present an  algorithm for finding the minimum-weight -tree when edge weights are integers in , and for the case the edge-weights are reals in , provide a -approximation algorithm having running time . 


\section{Preliminaries}\label{sec:prelim}
We follow Williams' notation~\cite{Williams09}. Let  be a field and  be a multiplicative group. The group algebra  is defined over the set of elements of the form

where  for all , i.e., on the set of sums of elements from  with coefficients from . 
Addition is computed component-wise as

multiplication is defined in the form of a convolution:

(since  is a multiplicative group, the expression  here replaces the expression of the type  which is usually found in a convolution definition) and multiplication by a scalar  as


Let  be the addition and multiplication identities of , respectively. Let  be the identity of . It is easy to verify that  is a ring where the addition identity element  is the element having all coefficients taken as , and the multiplication identity element . For ease of notation, hereafter  and  will denote  and , respectively.

Let  be a symbolic variable. Our computations are done on the set  of univariate polynomials on  with coefficients in . Notice that the set of polynomials with coefficients in a ring is a ring by itself.

For our algorithm, we follow Williams and choose  to be  (i.e., the set of binary vectors of dimension ) with multiplication between elements of  defined as entry-wise addition modulo . It follows that  is the -dimensional all-zeros vector. Notice that for all ,  iff . We also choose  for . Notice that since  has characteristic , it holds that for all , , and therefore that for all , .

\section{Method}\label{sec:method}
Given a weighted, directed or undirected graph  on the vertex-set , with integer edge-weights in , we first show how to compute the weight of the minimum-weight -path with high probability. We can assume the edge weights are actually in , otherwise we re-define  for each  and then : as this process incurs a penalty of  for each -path, it maintains the order relation on -path weights.
Define a \emph{-walk} to be a walk in the graph comprised of  (not necessarily distinct) vertices, and let  be some arbitrary -walk in . With a slight abuse of notation, we will also use  to denote the set of edges participating in the walk.

We define a collection  of polynomial matrices  as follows: 
 
where each variable  shall be assigned with a randomly selected value from  and each  will be assigned with a value chosen from  by a method to be described shortly. Notice that each  corresponds to vertex . Assume the values  have already been chosen. Recall that  is a symbolic variable. We define the polynomial  as follows: , where  is the -dimensional all-ones vector and  is the vector . 
Re-writing  as its sum-product expansion we get:

that is,  is an aggregate sum over all -walks in , where each walk  is represented by the product of its corresponding components in , finally multiplied by  which corresponds to the final vertex of the walk. By substituting the 's for their values, and re-arranging the walk's product such that the  terms appear first, then the  terms, and finally the  term, it follows that

where , , and  is the weight of walk .
\subsection{Algorithm}
Given , randomly choose all values , and randomly pick  vectors  from . Now compute the polynomial . Let  be the -th degree term coefficient of , and let 0 (if such exists). If  exists, return it. Otherwise output ``no -path exists in ''.


\subsection{Proof of Correctness}
Let  be the minimum-weight -simple-path in , and notice that  is represented in  by the term  in the product corresponding to . Notice that while no degrees  occur in , it might be that the -th degree term of  was eliminated when (partially) evaluating . Our goal is to show that this happens with low probability. For a walk , notice that if  is simple, i.e., it visits every node at most once, then  is multilinear, or equivalently, square-free, since each variable  appears in it at most once. On the other hand, if  is non-simple, then  must contain some square . Therefore, in order to prove the algorithm correct, we need to show that w.h.p., (a) products corresponding to non-simple paths vanish, (b) products corresponding to simple--paths do not vanish by their evaluation, and that (c) products corresponding to simple--paths are not eliminated when they are summed with other (same-degree) products. 

These notions are captured by the following propositions, which are similar to the ones in~\cite{Williams09}. 
Due to lack of space and for completeness, proofs are detailed in the appendix.

\begin{proposition}\label{pro:vanish}
If  is non-multilinear, it vanishes.
\end{proposition}

Let  be the sum of all vectors from  (addition here is the addition of ).

\begin{proposition}\label{thr:independent}
Let  be a -walk. If  is multilinear (i.e.,  is a -path), then if the vectors  are linearly independent w.r.t.\ entry-wise addition modulo , then .
\end{proposition}

\begin{corollary}\label{cor:2}
Let  be a -walk. If  is multilinear (i.e.,  is a -path), then with probability at least  it does not vanish.
\end{corollary}

We have shown that with at least constant probability, multilinear terms do not vanish when they are assigned values as described. However, it still might happen that such multilinear terms will get eliminated when they are summed up with other multilinear terms. The next two propositions show that this can happen with at most constant probability.

\begin{proposition}\label{thr:dependent}
Let  be a -walk. If the variables  are linearly dependent w.r.t.\ entry-wise addition modulo , then  vanishes.
\end{proposition}

Recall that  is a polynomial in  and therefore can be viewed as

It is therefore easy to see that the minimum-degree term in  corresponds to minimum-weight -paths in . Let  be the minimum degree of  and let 

 be its corresponding coefficient.
Our goal is to show that with at least constant probability,  does not vanish when it is evaluated.
\begin{proposition}\label{pro:high-pro}
 does not vanish with probability at least .
\end{proposition}
\subsection{Running Time Analysis}
The running time of the algorithm is dominated by  matrix multiplications, where the basic arithmetic operations are done over the polynomial ring .  Therefore, we need to account for the the cost of each such operation. Notice that for any arithmetic operation in  performed by our algorithm, the maximum degree of the operand polynomials and resulting polynomial, is at most . 
We can therefore focus on the set  of polynomials in  with degree at most . By treating the polynomials in  as periodic with period  (since there will be no carry or overflow to greater degrees),  continues to be a ring. 
Let  be the upper-bound on the time required for an arithmetic operation in ; trivially, . It follows that the algorithm requires  time, and it remains to compute .

\paragraph{Addition.} Addition of two polynomials can be easily done component-wise in time . 
\paragraph{Multiplication.} Multiplication is trickier and is done by employing a multidimensional fast Fourier transform-type approach.\footnote{Here, as opposed to Williams~\cite{Williams09}, the Walsh-Hadamard transform is not an adequate choice anymore due to the existence of the variable  which can have a degree up to . } We now describe the multiplication process in more detail.

The multiplication process will be easier to describe on the ring  which is isomorphic to , as will be shown immediately. Given a vector  and an integer , let  denote the vector . A polynomial  can be uniquely described as a sum  of at most  summands, where each  is the coefficient of  appearing in  (i.e.,  if , then ). Our definition of multiplication over  can be naturally extended to : multiplication still corresponds to entry-wise addition, only that now addition is done modulo  for dimensions  and modulo  for dimension . With that in mind, our definitions of addition, multiplication, and identity elements for  are extended appropriately, thus forming the ring . The bottom line is that now any  can be viewed as a sum of elements with coefficients taken from a multidimensional array indexed by values from  and that multiplication is still a convolution, an important fact to be used later.

Moving to , being a finite field, all elements in  can be represented in the usual manner as a degree- polynomials with coefficients in  and operations that are done modulo some predefined irreducible polynomial of degree  (this irreducible polynomial can even be found na\"{\i}vely as ). For the purpose of using FFT,  we treat polynomials in  as if they were actually in , i.e., the set of univariate polynomials over the complex numbers. At the end of the multiplication process, we will appropriately convert polynomials in  back to  as will be described shortly.

By the above arguments, given two polynomials  to be multiplied, they can be taken as the sums  and , respectively, where  for each  and . As the multiplication corresponds to a convolution, by the convolution theorem, it holds that , where  denotes a convolution,  denotes point-wise multiplication, and  denotes the -dimensional discrete Fourier transform for values indexed by vectors of type . 
Let  denote the time required for an arithmetic operation on degree- polynomials in ---including converting them back to  by division by an irreducible polynomial---and notice that  as multiplication and division here are quadratic by nature.
Then the above DFT operations can be computed efficiently in time  by using the multidimensional FFT algorithm.
Once we have computed  and , thus obtaining for each of them  values in  (indexed as well by vectors in ), we point-wise multiply them, obtaining a sum , and compute , again by using FFT on multidimensional coefficients in . Finally, we reduce  terms (which are actually in , as convolution over integer values returns integer values) by dividing them by the irreducible polynomial used before and the appropriate modulo operations. 
 
We conclude that multiplication of polynomials in  can be performed in time , and therefore .



\section{Finding the Actual Path}\label{sec:actual}
Let  be a weighted graph with integer edge-weights in . Given the algorithm from the previous section, we show that it is possible to find the minimum-weight -path itself with only  multiplicative overhead w.r.t.\ the previous algorithm and with a polynomially small error probability. 
We denote by  the algorithm from the previous section, amplified by running  iterations of it and choosing the minimal result, such that its error probability is bounded by  for some constant . 
The algorithm for finding the actual path uses  as a sub-routine. Its pseudo-code is provided as Algorithm~\ref{alg:finding}. 
The rest of this section is deferred to Section~\ref{sec:actual:app} of the appendix due to lack of space.

\begin{algorithm}[t]\label{alg:finding}
\caption{Finding the minimum-weight -path.}
\;
\While{}{
\For{ times} 
	{
	 a copy of  in which each vertex is removed with probability \;
	\If{at least  were removed and }{
	\;
	Go to the while loop\;
	}
	
	}
	\Return{``Fail''}
}
\ForEach{remaining vertex  and until }{
	\tcc*{ is  with  and its incident edges removed}
	\lIf{}{}
}
\Return{}

\end{algorithm}





\section{Approximation}\label{sec:approx}
The main drawback of the previous algorithm is that its running time has a superlinear dependency in , the bound on an edge weight. If the weights are in  (or can be normalized to this range), we show that if we settle for a -approximation algorithm to the problem, this dependency can be brought down to , by using a technique of careful adaptive scaling of the edge weights, thus bringing the overall running time to . Our techniques are in the spirit of the FPTAS of Erg{\"u}n et al.~\cite{ESZ02} for the restricted shortest path problem.  
We start with the following proposition:

\begin{proposition}\label{lemma:bound}
Given a graph  with integer edge-weights in , a parameter , and a value , it is possible to find an exact solution to the minimum-weight -path problem of weight at most , if such exists, or to return that no such solution exists, in time  and polynomially-small error probability.\footnote{ does not have to be an integer, but the effect in this case is as if  is used.}
\end{proposition}
\begin{proof}
The algorithm is identical to the previous one, except that as a first step, edges of weight greater than  are deleted from the graph, and that when multiplying two polynomials in  of degree at most , we truncate from the resulting polynomial any term of degree greater than , thus keeping all polynomials throughout the algorithm at degree of at most . As every polynomial multiplication now takes  time, the running time analysis follows.
\qed\end{proof}
We denote with  the algorithm that finds an exact solution to the -path problem of weight at most , if such exists, or to returns that no such solution exists. We will use it as a sub-routine in our approximation algorithm.

Define  (the number of edges in a -path), and let  be the minimum-weight -path. Our approximation algorithm starts by defining an upper and a lower bound,  and , respectively, to the weight of . At first,  and . It then iteratively fine-tunes  and  to the point where the ratio  is less than or equal to , while maintaining the invariant that . This fine tuning is done as follows. 

At each iteration we let the value  be the geometric mean of  and , and define the value  which will serve as a scaling coefficient. Notice that  as . We then scale-down the edge weights by a factor of , thus defining a new weight  for each edge , and let  be the graph with the new weights. 
Ideally, we would like to test whether the weight of the optimal solution is less than or greater than  by calling ; here notice that the value  is the scaled-down equivalent of  in .
However, while the scaling guarantees that this test can be done without incurring a high running time cost, it also introduces a loss of precision due to the floor function in the scaling: define  as the effective weight  simulates, then we have that , and therefore for a -path , we have that . Therefore, in the case  we have that , but if  (and therefore ) then all we can assert is that .
Therefore, a -path returned by a call to  has weight at most  (and not ) w.r.t.\ the original graph. According to the outcome of the call to  , we redefine  and : if  returned a result, we set ; otherwise we set . 

When the main loop is done (convergence is shown to exist below), we again redefine a new weight function:  for each edge , the graph , and return the result of a call to . The full algorithm pseudo-code is given as Algorithm~\ref{alg:approx}.


\begin{algorithm}[t]\label{alg:approx}
\caption{Approximation algorithm.}
\;
\;
  \;
\While{}{
\;
\;
Define  such that \;
\;
\eIf{ returns a result}{\;}{\;}
}
Define  such that \;\label{line:weights-final}
\;
\Return{}\label{line:return}
\end{algorithm}


\paragraph{Running-Time.} 
We first show that the main loop performs  iterations. Let  be the respective values of  at the start of iteration ; we will show that . At the end of each iteration , we have that either  and , or that  and , where  and . In the former case we have that 

and in the latter

In both cases we have that . Therefore it converges to a constant after  iterations. Notice that an invocation of  costs  by Proposition~\ref{lemma:bound}, with the bound  which is , as . We conclude that the overall cost of the main loop is .

As for the final call to , we have that its running time is  by Proposition~\ref{lemma:bound}, with the bound  which is  since at this stage . We conclude that the overall running time of the approximation algorithm is .

\paragraph{Correctness.} 
Throughout the execution, the algorithm maintains the invariant that . That can be easily seen by substituting  and  for their values and observing that . 
Assume there exist a -path in , and let  be the minimum-weight -path. By the scaling arguments, and the fact that we have brought the loss of precision due to scaling into consideration when redefining  and , we have that the invariant  always holds. Due to the running-time argument, when the main loop is done we have . Let  be the result of the call to  
 
at line~\ref{line:return} of the pseudo-code, and notice the the weights defined at line~\ref{line:weights-final} incur an  loss of precision per edge, or equivalently  per -path. By the call to the exact algorithm, we have that  
and therefore also . Accounting for the loss of precision, we have that .



\section{-tree}\label{sec:tree}
In~\cite{KW09}, they provide a solution to the -tree problem: given an -vertex graph  and a -node tree , is there a (not necessarily induced) copy of  in . Again their solution is based on a reduction to the question of is there a -multilinear-monomial in the sum-product expansion of a given polynomial. We show how to handle the \emph{minimum-weight -tree} problem---in which we are given a weighted graph , and wish to find a minimum-weight copy of  in it, across all copies of  in it---again, when the weights are integers in a given range . 

\begin{theorem}\label{thr:tree}
Given a graph , if the edge-weights are integers in , the minimum-weight -tree can be found in  time. If the edge-weights are reals in , the problem can be approximated within  in  time.
\end{theorem}
Let  be the neighbor-set of vertex  in , and let  be a variable-set corresponding to . We use the following polynomial on , implemented as an arithmetic circuit:

Let  and . The polynomial  is defined as follows. If , then . Otherwise,  is defined recursively:  let  be the subtrees of  created by removing node  from , where  is the subtree containing . Then 

where as before,  is a symbolic variable, and the values  are random values drawn from .\footnote{In~\cite{KW09}, the -values are implicit and come from the multiplication of the output of each multiplication gate with a random value taken from .}
Finally, define the polynomial . Each  is a circuit containing at most  addition and multiplication gates and therefore  contains  such gates. 
 is a sum over all homomorphisms from  to subgraphs of  of size at most : specifically  aggregates over all homomorphisms that map  to  (proof can be found in~\cite{KW09}\footnote{Their arithmetic circuit is defined as , however, it seems to contain redundancy.}). Therefore, a monomial  appears in the sum-product expansion of  if an only if there is a homomorphism mapping  to  such that if , then . If such a monomial is multilinear, it corresponds to such a homomorphism in which  are distinct vertices, i.e., a vertex in  was not used more than once for the sake of a single mapping. From this point, the same algorithms given before follow (only this time, evaluating  over ), and propositions similar to Propositions~\ref{pro:vanish}--\ref{pro:high-pro} apply. Full proofs are deferred to the full version of the paper. We obtain that the minimum-weight -tree problem with integer edge-weights in  can be solved in  time and that if the edge-weights are reals in , it can be approximated within  in  time.
\section{Acknowledgments}
We would like to thank Ryan Williams and Danny Raz for helpful comments.




\bibliographystyle{abbrv}
\bibliography{range}

\section*{Appendix}

\paragraph{Proof of Proposition~\ref{pro:vanish}.}
Assume  contains some square . Since  was assigned with , it holds that  where the third equality holds since for all , , and the fifth equality holds since  has characteristic  and therefore for all , .\qed



\paragraph{Proof of Proposition~\ref{thr:independent}.}
If the  vectors  are linearly-independent, then they form a basis  for . Notice that , i.e.,  is the sum of every possible combination of vectors from , multiplied together. Hence, the sum covers all vectors in the span of , that is, .
\qed

\paragraph{Proof of Corollary~\ref{cor:2}.}
The values  were chosen randomly and independently. It is known that a random  matrix of values from  has full rank with probability at least ~\cite{BK95}.
\qed

\paragraph{Proof of Proposition~\ref{thr:dependent}.}
Recall that . If the  vectors  are linearly-dependent, then there exists a set  such that . Since, as mentioned, for  it holds that  iff , we get that for all , . It follows that every value  occurs twice in the sum, one time as , and one time as . Since  as  has characteristic , all terms are eliminated in the sum.
\qed

\paragraph{Proof of Proposition~\ref{pro:high-pro}.}
By Propositions~\ref{thr:independent} and~\ref{thr:dependent}, it holds that 

Let 
 is a degree- polynomial in the variables . With probability at least  at least one minimum-weight -path  had survived and therefore  is not identically zero. In this case, by the Schwartz-Zippel lemma~\cite{Schwartz80,Zippel79,DL78}, when assigning random values from  to the variable set ,  evaluates to zero with probability at most . Therefore  (and hence, ) does not vanish with probability at least .
\qed


\subsection{Finding the Actual Path}\label{sec:actual:app}
Let  be a weighted graph. We first run  on the graph. Let  be the value returned by it, i.e., the weight of the minimum-weight -path. 

If , repeat the following procedure  times:\footnote{For the sake of brevity, in this section we do not give full details of the underlying constants that are required.} remove each of the graph vertices with probability . If  vertices were removed, run  on the resulting graph and . If the algorithm had returned a result , then keep the vertices discarded indefinitely and stop, otherwise return them back to the graph. If after the  iterations no vertices were discarded indefinitely, output ``Fail''. 

The above procedure is repeated as long as . Once , we perform an ordinary self reduction: each time we remove a different vertex and query  with the resulting graph and ; if the result stays the same, we keep this vertex discarded, otherwise, we return it to the graph. Once , we return the edge-set  as the resulting path. This algorithm's pseudo-code is given as Algorithm~\ref{alg:finding}.


\paragraph{Error probability.} Let  be the minimum-weight -path in , and assume , otherwise the problem is trivial.
Let  be the set of vertices removed from  in an iteration of the for loop. 
The probability  does not include any of the vertices of  is . Now assume it does not, in that case it holds that , and that . According to Chebyshev's inequality,  with probability of at least a constant. It follows that the probability to pick  that does not hit any of the vertices in  and at the same time is  is at least a constant . 
We define this event as a ``success''. Since we perform at most  trials at each iteration of the while loop, the probability of failing in all of them is  which can be made at most   for some constant . By using the union-bound over the  iterations of the while loop, we get a polynomially-small error probability of at most . Since the probability to fail any invocation of  is less than , by a similar union-bound argument the probability to fail in any of the calls to  is  . We obtain an overall polynomially-small error probability.

\paragraph{Running time.} Each non-failed iteration of the while loop in Algorithm~\ref{alg:finding} discards  vertices and therefore reduces the number of vertices in the graph by a multiplicative factor of . As this happens until ,  iterations are enough for getting the number of vertices to .
As each iteration invoked  at most  times, the  multiplicative factor follows for this stage of the algorithm. As the for-each loop incurs only  calls to , the running-time analysis follows.




\end{document}
