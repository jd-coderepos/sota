We present in this section our new abstract domain \texttt{FPS}. In
Section~\ref{sec:floating-point-version-of-interval-slopes}, we adapt
the computation rules of interval slopes to take into account
floating-point arithmetic. Next in
Section~\ref{sec:arithmetic-operations}, we define an abstract
semantics of arithmetic expressions over \texttt{FPS} values taking
into account the behaviors of floating-point arithmetic. And in
Section~\ref{sec:order-structure}, we define the order structure of
the \texttt{FPS} domain.

\subsection{Floating-Point Version of Interval Slopes}
\label{sec:floating-point-version-of-interval-slopes}

The definition of interval slope expansion in
Section~\ref{sec:interval-arithmetic} manipulates real numbers. In
case of floating-point numbers, we have to take into account the
round-off function and the rounding-errors.

We show in Proposition~\ref{prop:sound-slope-round-nearest} that the
range of a non-linear function  of floating-point numbers can
be soundly over-approximated by a floating-point slope. The function
 must respect the correct rounding, \ie the property of
Equation~\eqref{eq:rounding-and-error-analysis} must hold. In other
words, the result of an operation over set of floating-point numbers
is over-approximated by the result of the same operation over
floating-point slopes by adding a small quantity depending on the
relative rounding error unit  and the absolute error .


\begin{proposition}
  \label{prop:sound-slope-round-nearest}
  Let  be an arithmetic
  operation of the form  with  or , \ie  respects the
  correct rounding. For all  and
  , we have: {\small
    
  }
  \begin{proof}
    {\small  
      \qed
    }
  \end{proof}
\end{proposition}

\begin{remark}
  As the floating-point version of slopes is based on  and
  , we can represent the floating-point behaviors depending of
  the hardware. For example, extended precision\footnote{In some
    hardware, \eg Intel x87, floating-point numbers may be encoded
    with  bits in registers, \ie the significand is  bits
    long.} is represented using the values  and
  . Furthermore following \cite{BN10}, we can
  compute the result of a double rounding\footnote{It may happen on
    hardware using extended precision. Results of computations are
    rounded in registers and they are rounded again, with a less
    precision, in memory.}  with  and
  . \end{remark}

Proposition~\ref{prop:sound-slope-round-nearest} shows that we can
compute the floating-point range of a function , respecting
the correct rounding, using interval slopes expansion. That is a set
of floating-point values can is represented by a pair:{\small
  
}The first element is a small interval rounding to the nearest around
 for which we have to take into account the
possible rounding errors. The second element is the interval slopes
which have to take account of relative errors. Note that this
adaptation adds a very little overhead of computations compared to the
definition of interval slopes by Krawczyk and Neumaier.

\subsection{Semantics of Arithmetic Operations}
\label{sec:arithmetic-operations}

In this section, we define the abstract semantics of arithmetic
operations over elements of floating-point slopes domain in order to
mimic the behaviors of the floating-point arithmetic. We denote by
 the set of intervals and by  the
set of slopes. An element  of  is represented by a pair
 where  is a
floating-point interval and  is a vector of
floating-point intervals. We denote by  the lattice of
intervals. First we define some auxiliary functions before presenting
the semantics of arithmetic expressions over \textsf{FPS}.

The function  defined in Equation~\eqref{eq:iota} computes the
interval value associated to a floating-point slopes . We assume that the values of independent variables
are kept in a separate interval vector . The
notation  stands for the
component-wise application of the function  on all the
components of the vector . Note that 
represents the scalar product. {\small

}The function  defined in Equation~\eqref{eq:kappa} transforms
an interval value  associated to the -th independent
variable into a floating-point slope. {\small
  
}This function  is used in two cases: \textit{i)}~To
initialize all the independent variables at the beginning of an
analysis. \textit{ii)}~In the meet operation, see
Section~\ref{sec:order-structure}.

We can detect overflows and generations of zero by using the function
 defined in Equation~\eqref{eq:fps-zero-overflow}. We have two
kinds or rules: \textit{total} rules when we are certain that a zero
or an overflow occur and \textit{partial} rules when a part of the set
described by a floating-point slope generates a zero or an
overflow. With the function  we can determine for an element
 if  represents an overflow or a zero. Hence we represent
the finite precision of the floating-point arithmetic. We denote by
 and by  the
interval vectors with all their components equal to
 and  respectively. We recall
that  is the smallest denormalized and  is the largest
floating-point numbers. {\small
  
}Equation~\eqref{eq:fps-zero-overflow} is an adaptation of the rule
defined in Equation~\eqref{eq:zero-overflow} to deal with \fps
values. Furthermore, the abstract values  and  represent the
special floating-point values  and  respectively. As
in floating-point arithmetic, the values  and  are absorbing
elements.

An interesting feature of interval slopes is that we can mimic the
absorption phenomenon by setting to zero the interval slope of the
absorbed operand. We define the function  for this
purpose. Indeed, an abstract value 
already supports partial absorption as  is computed with
a rounding to the nearest but  have to be
\textit{reduced} to represent the absence of the influence of
particular independent variables. The reduction of an abstract value
 compared to an abstract value
, denoted by , is
defined in Equation~\eqref{eq:slope-reduction}.  {\small
  
}Equation~\eqref{eq:slope-reduction} models the absorption phenomenon
by explicitly setting to zero the values of a slope. As mentioned in
Section~\ref{sec:interval-arithmetic}, a slope shows which variables
influence the computation of an arithmetic expression. But, absorption
phenomena induce that an operand does not influence the result of an
addition or a subtraction any more.

Using the functions ,  and , we inductively define
on the structure of arithmetic expressions the abstract semantics
 of floating-point slopes in
Figure~\ref{fig:arithmetic-operation-floating-point-slopes}. We denote
by  an abstract environment which associates to
each program variable a floating-point slope. For each arithmetic
operation, we component-wisely combine the elements of the abstract
operands  and . The element  is obtained using the
interval arithmetic with rounding to the nearest. The element
 is computed using the definition of the slope
arithmetic defined in Table~\ref{tab:automatic-differentiation-rules}.
We take into account of the possible rounding errors in the result
 following
Proposition~\ref{prop:sound-slope-round-nearest}. In case of addition
and subtraction, according to the
Equation~\eqref{eq:rounding-and-error-analysis}, we do not consider
absolute error  which is always zero. Moreover, in
case of addition or subtraction, we handle the absorption phenomena
using the function , defined in
Equation~\eqref{eq:slope-reduction}. Finally, we check if a zero or an
overflow is generated by applying the function  defined in
Equation~\eqref{eq:fps-zero-overflow}.

\begin{figure}[ht] {\small
    
          \text{with}
          \quad (\tilde{\interval{M}}_g,\tilde{\vinterval{S}}_g) = 
          \rho(g \mid h)
          \text{ and } (\tilde{\interval{M}}_h,\tilde{\vinterval{S}}_h)
          = \rho(h \mid g)
        
          \text{with}
          \quad \interval{M} = 
          (\interval{M}_g \times \interval{M}_h)(1 + [-\re,\re]) + 
          \left[\frac{\sigma}{2}, \frac{\sigma}{2}\right]
        
          \begin{split}
          \text{with}\quad
          \interval{M} & =  
          \frac{\interval{M}_g}{\interval{M}_h}(1 + [-\re,\re]) + 
          \left[\frac{\sigma}{2}, \frac{\sigma}{2}\right],
          \\
          0 & \not\in \iota(\interval{M}_h, \vinterval{S}_h) 
          \text{ and } 0 \not\in \interval{M}_h
        \end{split}
        
        \begin{split}
        \text{with}\quad 
        \interval{M} &= 
        \left(\sqrt{\interval{M}_g}\left(1+[-\re,\re]\right)\right)+
        \left[-\frac{\sigma}{2},\frac{\sigma}{2}\right],
        \\
        \interval{M}_g & \sqcap_\I [-\infty,0] = \bot_\I        
        \text{ and } \iota(\interval{M}_g, \vinterval{S}_g) 
         \sqcap_\I [-\infty,0] = \bot_\I
      \end{split}
      
}
\caption{Abstract semantics of arithmetic expressions on
  floating-point slopes}
\label{fig:arithmetic-operation-floating-point-slopes}
\end{figure}

\begin{remark}
  The functions  and  make the arithmetic operations on
  floating-point slopes non associative and non distributive as in
  floating-point arithmetic.
\end{remark}

\subsection{Order Structure}
\label{sec:order-structure}

In this section, we define the order structure of the set  of
floating-point slopes. In particular, this structure is based on the
lattice of intervals. We recall that the set of slopes  and an element  of  is a pair .

We define a partial order, the join and the meet operations between
elements of . All these operations are defined as a component-wise
application of the associated operations of the interval domain except
the meet operation which needs extra care. We denote by
 the component-wise application of the interval
order. We can define a partial order  between elements
of  with: {\small
  
}

The join operation  over floating-point slopes is defined
in Equation~\eqref{eq:join-operation}. We denote by 
the component-wise application of the operation .  {\small
  
}

There is no direct way to define the greatest lower bound of two
elements of . Indeed, two abstract values may represent the same
concrete value but without being comparable. Hence we only have a
join-semilattice structure. The meet operation  over
floating-point slopes is defined in
Equation~\eqref{eq:meet-operation}. It may require a conversion into
interval value. We consider that the result of the meet operation
introduces a new independent variable at index . We denote by
 the strict comparison of intervals and by  the
least element of . {\small
  
}

\subsubsection*{Note on the Widening Operator.}
\label{sec:acceleration-of-convergence}

In order to enforce the convergence of the fixpoint computation, we
can define a widening operation  over floating-point slopes
values. An advantage of our domain is that we can straightforwardly
use the widening operations defined for the interval domain denoted by
. We define the operator  in
Equation~\eqref{eq:widening-operation} using the widening operator
between intervals. The notation  represents the
component-wise application of  between the components of
the interval slopes vector. {\small
  
}

