\documentclass[11pt,letterpaper]{article}
\usepackage{authblk}
\usepackage{emnlp2017}

\usepackage{times}
\usepackage{latexsym}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{graphicx}
\usepackage{url}
\usepackage{subfigure}
\usepackage{enumitem}
\usepackage{arabtex}
\usepackage{utf8}
\setcode{utf8}
\emnlpfinalcopy

\setlength\titlebox{8cm} 
\newcommand\BibTeX{B{\sc ib}\TeX}
\newcommand\Mark[1]{\textsuperscript#1}
\usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\title{Arabic Multi-Dialect Segmentation: bi-LSTM-CRF vs. SVM}

\author[1]{\bf Mohamed Eldesouki}
\author[2]{\bf Younes Samih}
\author[1]{\\ \bf Ahmed Abdelali}
\author[3]{\bf Mohammed Attia}
\author[1]{\bf Hamdy Mubarak}
\author[1]{\bf Kareem Darwish}
\author[2]{\bf Laura Kallmeyer}

\affil[1]{Qatar Computing Research Institute, HBKU, Doha, Qatar}
\affil[2]{Dept. of Computational Linguistics,University of D\"usseldorf, D\"usseldorf, Germany}
\affil[3]{Google Inc., New York City, USA}

\affil[1]{\texttt{\{mohamohamed,hmubarak,aabdelali,kdarwish\}@hbku.edu.qa}}
\affil[2]{\texttt{\{samih,kallmeyer\}@phil.hhu.de} }
\affil[3]{\texttt{attia@google.com} }



\date{}
\begin{document}
\maketitle

\begin{abstractx}
Arabic word segmentation is essential for a variety of NLP applications such as machine translation and information retrieval. Segmentation entails breaking words into their constituent stems, affixes and clitics. In this paper, we compare two approaches for segmenting four major Arabic dialects using only several thousand training examples for each dialect.  The two approaches involve posing the problem as a ranking problem, where an SVM ranker picks the best segmentation, and as a sequence labeling problem, where a bi-LSTM RNN coupled with CRF determines where best to segment words. We are able to achieve solid segmentation results for all dialects using rather limited training data. We also show that employing Modern Standard Arabic data for domain adaptation and assuming context independence improve overall results.
\end{abstractx}

\section{Introduction}
Arabic has both complex morphology and orthography, where stems are typically derived from a closed set of roots to which affixes such as coordinating conjunctions, determiners, and pronouns are attached to form words. Segmenting Arabic words into their constituent parts is important for a variety of natural language processing applications. For example, segmentation has been shown to improve the effectiveness of information retrieval \cite{darwish2014arabic} and machine translation \cite{habash2006arabic}. Most previous work has mostly focused on segmenting Modern Standard Arabic (MSA) achieving segmentation accuracies of nearly 99\% \cite{abdelali2016farasa,pasha2014madamira}. MSA is the lingua franca of the Arab world, and it is typically used in written and formal communications. Dialectal Arabic (DA) segmentation on the other hand has received limited attention, with most of the work focusing on the Egyptian dialect \cite{habash2013morphological,samih2017neural}. Arabic dialects are typically spoken and are used in informal communications.  The advent of the social media and the ubiquity of smart phones has led to a greater need for dialectal processing such as dialect identification \cite{eldesouki2016qcri,khurana2016multi}, morphological analysis \cite{habash2013morphological} and machine translation \cite{sennrich-haddow-birch:2016:P16-12,Sajjad:2013ac}.  Yet, dialectal training corpora for a variety of NLP modules, including segmentation, continue to be limited and often nonexistent.

In this work, we focus on the segmentation of four major Arabic dialects, namely Egyptian, Levantine, Gulf, and Maghrebi.  We particularly focus on DA text from Twitter, a popular social media platform, from which we can obtain large amounts of text in different dialects written by ordinary social media users and exhibiting nonstandard orthography. We employ two machine learning approaches for building robust segmentation modules using limited training data (350 tweets containing several thousand words per dialect).  In one approach, we pose the segmentation as a ranking problem where all possible segmentations of a word are ranked using a Support Vector Machine (SVM) based ranker. In the second, we use bidirectional Long Short Term Memory (bi-LSTM) Recurrent Neural Network (RNN) with Conditional Random Fields (CRF) to perform sequence labeling over the characters in words.  For both, we adopt the simplifying assumption that word segmentation can be reliably performed independent of context.  Though the assumption is not always correct, it has been shown to be fairly robust for more than 99\% of word occurrences in Arabic text \cite{abdelali2016farasa}.  Lastly, given the large overlap between MSA and DA, we employ segmented MSA data to further improve dialectal segmentation.

The contribution of this paper are as follows:
\begin{itemize}[leftmargin=*]
\setlength\itemsep{-0.3em}
\item We present robust DA segmenters for four major Arabic dialects.  We plan to open-source all of them.
\item We provide an exposition of challenges associated with performing in situ DA segmentation including segmentation guidelines and the effect of orthographic standardization. 
\item We compare two machine learning approaches that can generalize well even when limited training data is available.
\end{itemize}





\section{Related Work}
Work on dialectal Arabic is fairly new compared to MSA. A number of research projects were devoted to dialect identification \cite{Biadsy:2009:SAD:1621774.1621784,Zbib:2012:MTA:2382029.2382037,zaidan2014arabic,eldesouki2016qcri}. There are five major dialects including Egyptian, Gulf, Iraqi, Levantine and Maghribi. Few resources for these dialects are available such as the CALLHOME Egyptian Arabic Transcripts (LDC97T19), which was made available for research as early as 1997. Newly developed resources include the corpus developed by \newcite{Bouamor14MultidialectalCorpus}, which contains 2,000 parallel sentences in multiple dialects and MSA as well as English translation.\\
For the segmentation,
\newcite{mohamed2012annotating} built a segmenter based on memory-based learning. The segmenter has been trained on a small corpus of Egyptian Arabic comprising 320 comments containing 20,022 words from \url{www.masrawy.com} that were segmented and annotated by two native speakers. They reported a 91.90\% accuracy on the task of segmentation. MADA-ARZ \cite{habash2013morphological} is an Egyptian Arabic extension of the Morphological Analysis and Disambiguation of Arabic (MADA). They trained and evaluated their system on both Penn Arabic Treebank (PATB) (parts 1-3) and the Egyptian Arabic Treebank (parts 1-5) \cite{maamouri2014developing} and they achieved 97.5\% accuracy. MADAMIRA\footnote{MADAMIRA release 20160516 2.1} \cite{pasha2014madamira} is a new version of MADA and includes functionality for analyzing dialectal Egyptian. \newcite{monroe2014word} used a single dialect-independent model for segmenting all Arabic dialects including MSA. They argue that their segmenter is better than other segmenters that use sophisticated linguistic analysis. They evaluated their model on three corpora, namely parts 1-3 of Penn Arabic Treebank (PATB), Broadcast News Arabic Treebank (BN), and parts 1-8 of the BOLT Phase 1 Egyptian Arabic Treebank (ARZ) reporting a 95.13\% F1 score. 
 
\section{Dialectal Arabic}
\subsection{DA Challenges}
DA shares many MSA challenges, such as having complex templatic derivational morphology and concatenative orthography. Most  nouns and verbs are typically derived from a closed set of roots, which are fitted into templates to generate stems. Templates may indicate morphological features such POS tag, gender, and number. Stems may accept prefixes, such as coordinating conjunction and prepositions, or suffixes, such as pronouns, to form words. While dialects mostly comply with the templatic nature of morphology\footnote{Minor exception exist such the Egyptian template ``AtfEl'' that occasionally replaces the MSA template ``AnfEl'' as in \<اتكسر> ``Atksr'' (broke)}, they diverge from MSA in other aspects such as:
\begin{itemize}[leftmargin=*]
\setlength\itemsep{-0.3em}
\item Lack of standard orthography, particularly for strictly dialectal words such as \<عشان> ``E\An'' or \<مشان> ``m\'', which behaves like the French ``ne-pas'' negation construct; the placement of present tense markers, such as ``b'' in Egyptian and Levantine; the use of different future markers such as ``H'', ``h'', and ``g'' instead of ``s'' for MSA; and the shortening of prepositions and fusing them with the words they precede such as the transformation of \<على> ``ElY'' (on) to \<ع> ``E''.
\item Letter substitution, where some letters are commonly substituted for others such as ``v'' which is replaced with ``t'' in Egyptian (as in \<كتير> ``ktyr'' (much)) or ``q'' which is replaced with ``j'' in Gulf (as in \<صدج> ``Sdj'' (really).  \item Syntactic differences, such as the use of masculine plural or singular noun forms instead dual and feminine plural, the dropping of some articles and preposition in some syntactic constructs, and the abandonment of some suffixes such as ``wn'' in favor of ``wA'' for verbs and ``yn'' for nouns.
\end{itemize}

Using raw text from social media introduces additional phenomena such as word elongation, such \<أخييييررا> ``KyyyyrrA'' (finally) instead of \<أخيرا> ``KyrA'', and the use of non-Arabic characters such as Urdu characters \cite{darwish2012language}.




\section{Dataset}
\label{sec:dataset}
  We constructed our dataset by obtaining 350 tweets that were authored for each of the following four dialects: Egyptian, Levantine, Gulf, and Maghrebi. For dialectal Egyptian tweets, we obtained the dataset described in \cite{darwish2014verifiably}, and we used the same methodology to construct the dataset for the remaining dialects. Initially, we obtained 175 million Arabic tweets by querying the Twitter API using the query ``lang:ar'' during March 2014.  Then, we identified tweets whose authors identified their location in countries where the dialects of interest are spoken (ex. Morocco, Algeria, and Tunisia for Maghrebi) using a large location gazetteer \cite{mubarak2014using}.  Then we filtered the tweets using a list containing 10 strong dialectal words per dialect, such as the Maghrebi word \<كيما> ``kymA'' (like/as in) and the Leventine word \<هيك> ``hyk'' (like this).  Given the filtered tweets, we randomly selected 2,000 unique tweets for each dialect, and we asked a native speaker of each dialect to manually select 350 tweets that are heavily dialectal.  Table \ref{table:annotatedData} lists the number of tweets that we obtained for each dialect and the number of words they contain.  




\begin{table}[h]
\begin{center}
\begin{tabular}{|l|l|}
\hline \bf Field & \bf Annotation \\ \hline
Orig. word & \<بيقولك> ``byqwlk''\\
Meaning & he is saying to you \\
In situ Segm. & \<ك>+\<يقول>+\<ب> ``b+yqwl+k''\\
CODA & \<بيقول لك> ``byqwl lk''\\
CODA Segm. & \<ك>+\<ل> \<يقول>+\<ب> ``b+yqwl l+k''\\
\hline
\end{tabular}
\end{center}
\caption{Egyptian annotation example}
\vspace{-1.5em}
\label{annotations}
\end{table}

\begin{table}[h]
\begin{center}
\begin{tabular}{c|c|c}
Dialect & No of Tweets & No of Tokens \\ \hline
Egyptian & 350 & 6,721 \\
Levantine & 350 &  6,648 \\
Gulf & 350 & 6,844 \\
Maghrebi & 350 & 5,495 \\ \hline
\end{tabular}
\label{table:annotatedData}
\caption{Dataset size for the different dialects}
\end{center}
\vspace{-.75em}
\end{table}


Segmentation of DA can be applied on the original raw text, or on the cleaned text after correcting spelling mistakes and applying conventional orthography rules, such as CODA \cite{habash2012conventional}.  In this work, we decided to segment the original raw text.   Though Egyptian CODA is a reasonably stable standard, CODA for other dialects are either immature or nonexistent. Also, CODA conversion tools are lacking for most dialects\footnote{except for Egyptian CODA tool that is embedded in MADAMIRA}. Building such tools requires the establishment of clear guidelines, is laborious, and may require large annotated corpora \cite{eskander2013processing}, such as the LDC Egyptian Treebank. 

To prepare the ground truth data for a dialect, we enlisted an annotator who is either a native speaker for the dialect or well versed in it and has background in natural language processing.  The authors along with another native speaker of the dialect made multiple review rounds on the work of the annotator to ensure consistency and quality.  
The annotation guidelines were fairly straightforward. Basically, we asked annotators to:
\begin{itemize}[leftmargin=*]
\setlength\itemsep{-0.3em}
\item segment words in a way that would maintain the correct number of part of speech tags
\item favor stems when repeated letters are dropped as Table \ref{annotations}
\item segment multiple concatenated words with pluses as in the ``merged words'' example in Table \ref{OriginalCODASegmentation}.
\item attach injected long vowels that trail prepositions or pronouns to the preposition or pronoun respectively (ex. \<ليكي> ``lyky'' (to you -- feminine)  ``ly+ky'')
\item treat dialectal words that originated as multiple fused words as single tokens (ex. \<علاش> ``ElA\>y\textquotesingle '')
\item do not segment name mentions and hashtags
\end{itemize}

In what follows, we discuss the advantages and disadvantages of segmenting raw text versus the CODA'fied text with some statistics obtained for the Egyptian tweets for which we have a CODA'fied version as exemplified in Table~\ref{annotations}.  The main advantage of segmenting raw text is that it doesn't need any preprocessing tool to generate CODA orthography, and the main advantage of CODA is that is regularizes text making it more uniform and easier to process. 
We manually compared the CODA version to the raw version of 2,000 words in our Egyptian dataset.  We found that in 75.4\% of the words, segmentation of original raw words is exactly the same as the their CODA'ifed equivalents (ex. \<و+من> ``w+mn'' (and from) and \<نعمل+ها>, ``nEml+hA'' (we do it)). Further, if we normalize some characters, namely \<أ،إ،آا، ى
ي، ةه>, and non-Arabic characters \<چج، ڤ ف، گ،کك، ےي>, and remove diacritics, the percentage of matching increases to 90.3\%. Table~\ref{OriginalCODASegmentation} showcases the remaining differences between raw and CODA segmentations and how often they appear.  The differences are divided into two groups.  In the first group (accounting for 6.8\% of the cases), the number of word segments remains the same and both the raw and CODA'fied segments would have the same POS tags.  

\begin{table}[h]
\begin{center}
\begin{tabular}{|l|l|l|}
\hline \bf Diff. & \textbf{\%} & \textbf{Examples} \\ \hline
\multicolumn{3}{|c|}{\textbf{Same no. of segments and same POS tags}} \\ \hline
variable	  & \multirow{2}{*}{2.4\%} & \<عشان  علشان> \\
spellings &      & ``E\An''\\ \hline
dropped & \multirow{2}{*}{2.3\%} & \<ب+ حترمب+أحترم> \\
letters &      & ``b+Htrm, b+AHtrm''\\\hline
merged & \multirow{2}{*}{1.4\%}  &   \<يا+عميا عم> \\
words  &      & ``yA+Em, yA Em''\\\hline
Shortened  & \multirow{2}{*}{0.4\%}  &   \<ععلى، ف في>\\
particles      &      &   ``E, ElA  f, fy''\\\hline
elongations & \multirow{1}{*}{0.3\%}  & \<لييييهليه> ``lyyyyh,lyh''             \\\hline
\multicolumn{3}{|c|}{\textbf{Different no. of segments or POS tags}} \\ \hline
spelling & \multirow{2}{*}{2.2\%}  &  \<اناان  ولاوإلا>\\
errors &      & ``ِAn, Ana   wlA, wAlA''\\
\hline
fused & \multirow{2}{*}{0.8\%} & \<قال+يقال ل+ي>\\
letters &      & ``qAl+y, qAl l+y'' \\\hline
\end{tabular}
\end{center}
\caption{Original vs CODA Segmentations}
\label{OriginalCODASegmentation}
\end{table}

In this group, the ``variable spelling'' class contains dialectal words that may have different common spellings with one ``standard'' spelling in CODA. The ``dropped letter'' and ``shortened particles'' classes typically involve the omission of letters such as the first person imperfect prefix \<أ> ``'' when preceded by the present tense marker \<ب> ``b'' or the future tense marker \<هـ> ``h'', and the ``A'' in negation particle \<ما>``mA'' which is often written as \<م>``m'' and attached to the following word, and the trailing letters in prepositions. ``Merged words'' and ``word elongations'' are common in social media, where users try to keep within limit by dropping the spaces between letters that do not connect or to stress words respectively.

Though some processing such as splitting of words or removing elongations is required to overcome the phenomena in this group, in situ segmentation of raw words would yield identical segments with the same POS tags as their CODA counterparts.  Thus, the segmentation of raw words could be sufficient for 97\% of words. 


In the second group (accounting for 3\% of the cases), both may have a different number of segments or POS tags, which would complicate downstream processing such as POS tagging.  They involve spelling errors and the fusion of two identical consecutive letters (gemmination). Correcting such errors may require a spell checker.  We opted to segment raw input without correction in our reference, and we kept stem, such as verbs and nouns, complete at the expense of other segments such as prepositions as in the example in Table \ref{annotations}.













\section{Segmentation Approaches}
\label{segmentationapproaches}
We present here two different systems for word segmentation. The first uses SVM-based ranking (SVM)\footnote{\url{https://www.cs.cornell.edu/people/tj/svm_light/svm_rank.html}} to rank different possible segmentations for a word using a variety of features. The second uses bi-LSTM-CRF, which performs sequence-to-sequence mapping to guess word segmentation.



\subsection{SVM Approach}
This approach is inspired by the work done by \newcite{abdelali2016farasa}, in which they used SVM based ranking to ascertain the best segmentation for Modern Standard Arabic (MSA), which they show to be fast and accurate. The approach involves generating all possible segmentations of a word and then ranking them. 

In training, we generate all possible segmentations of a word based on a closed set of prefixes and suffixes, and the correct segmentation is assigned rank 1 and all other incorrect segmentations are assigned rank 2. Our valid affixes include MSA prefixes and suffixes that we extracted from Farasa \cite{abdelali2016farasa} and additional dialectal prefixes and suffixes that we observed during training.  Since we are not mapping words into a standard spelling, such as CODA, prefixes and suffixes may have multiple different representations.  For example, given the dialectal Egyptian word for ``I do not play'', it could be spelled as ``m+b+lEb+\'', ``mA+b+AlEb+\y'', ``mA+b+AlEb+\'' or ``\'' (on the face), possible segmentations are: \{E+Al+w\\}, \{E+Al+w+\\}, \{EAlw+\\}.
\item Given the input word: \<باديكي> ``bAdyky'' (I give you (feminine)), possible segmentations are: \{b+Ady+ky\} (correct segmentation), \{b+Adyky\}, \{bAdy+ky\}, and \{bAdyky\}.
\end{itemize}



We use the following features in training the classifier:
\begin{itemize}[leftmargin=*]
\setlength\itemsep{-0.3em}
\item Conditional probability that a leading character sequence is a prefix.
\item Conditional probability that a trailing character sequence is a suffix.
\item probability of the prefix given the suffix.
\item probability of the suffix given the prefix.
\item unigram probability of the stem (more details about calculating this is showing below).
\item unigram probability of the stem with first suffix.
\item whether a valid stem template can be obtained from the stem.
\item whether the stem that has no trailing suffixes appears in a gazetteer of person and location names \cite{abdelali2016farasa}.
\item whether the stem is a function word, such as \<على> ``ElY'' (on), \<من> ``mn'' (from), and \<مش> ``m\^{Rank}x = (x_1, ..., x_n)y_tx_tt = 1nh_tWbfh_tx_t\sigmaifoc\overrightarrow{h}\overleftarrow{h}y{B, M, E, S, WB}0.9500.5^{Rank}^{Rank}^{Rank}^{Rank}^{Rank}|'' (don't make us angry) where the ranker chose to segment it as ``m+tqlq+yn+A\~$A'' (about us) is actually two tokens \<عن> En and \<نا> nA. The two \<ن> n letters are now merged into one. In the gold data, the disputed letter belongs to the first token while in the system output, it belongs to the second.
\item Like the SVM, the system often fails due to unconventional spelling. For example the word \<لاخويا> ``lAxwyA'' (to my brother) is a misspelling of \<لأخويا>. \item The majority of the remaining errors are simply mis-tokenization due to the system's inability to decide whether a substring (which out of context can be a valid token) is an independent token or part of a word, e.g. \<مستقبل+ك> ``mstqbl+k'' (your future), which is predicted by the system as ``m+staqbl+k'', where it correctly recognizes the genitive pronoun in the end, but mistakenly tags the first radical as a separate segment. \end{itemize}



\section{Conclusion}
In this paper we presented two approaches involving SVM-based ranking and bi-LSTM-CRF sequence labeling for segmenting Egyptian, Levantine, Gulf, and Maghrebi dialects. Both approaches yield strong comparable results that range between 91\% and 95\% accuracy for different dialects. To perform the work, we created training corpora containing naturally occurring text from social media for the aforementioned dialects.  We plan to release the data and the resulting segmenters to the research community. For future work, we want to perform domain adaptation using large MSA data, such as ATB, to improve segmentation results.  Further, we plan to investigate building a joint model capable of segmenting all the dialects with minimal loss in accuracy.


\bibliography{emnlp2017}
\bibliographystyle{emnlp_natbib}

\end{document}
