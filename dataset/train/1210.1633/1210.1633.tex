
\section {Experimental Study} \label{section_experiment}

In this section, our analysis is validated via experimenting with real-world traces. We first present the data source and experimental settings.  We then compare the experimental and analytical results.

\subsection{Requirements and the Dartmouth Traces}
There are serval publicly available traces online, including the Dartmouth traces \cite{Trace-Dartmouth-Data01}\cite{Trace-Dartmouth-Data02}\cite{Trace-Dartmouth-Data03}, the UCSD traces \cite{Trace-UCSD2}, the IBM-Watson traces \cite{Trace-IBMWatson}, and the Montreal traces \cite{Trace-Montreal}. To choose proper traces, we need to consider the following requirements.  \emph{First}, there should be a large amount of sample points to facilitate an estimation of the user distribution by relative frequency, which is to be compared with the distribution derived by the proposed analysis. Note that the support of the user distribution increases exponentially with the number of cells.  Most available traces do not have a large enough data set. \emph{Second}, the location of cells should be close enough so that there is enough handoff traffic among them to create strong dependency between channel holding times.  Data from already independently operated cells can be analyzed using exiting techniques and hence are not challenging enough to test our analytical model.
To the best of our knowledge, the Dartmouth traces are the most recent public traces satisfying both requirements.  They have been widely studied in the literature \cite{Trace-Dartmouth-Paper01}\cite{Trace-Dartmouth-Paper}\cite{Experiment2}\cite{Mobility-Core1}.
We use data from the academic area in the Dartmouth traces \cite{Trace-Dartmouth-Data03}, a comprehensive record of network activities in a large wireless
LAN (using 802.11b) in Dartmouth College.  The traces includes the data of 152 APs and more than 5000 users, during a 17-week period (Nov.~1, 2003 to Feb.~28, 2004). Most users are students walking on campus.
We focus on the  Simple Network Management Protocol (SNMP) logs of the traces, which are constructed every five minutes, when each AP polls all the users attached to it. Each polling message includes the information such as the name of AP, timestamp, the MAC and IP addresses of users attached to it, signal strength, and the number of packets transmitted.  By analyzing such data, we can derive the average arrival rate, average channel holding time, and the user distribution by relative frequency.

\subsection{Data Preprocessing} \label{sec:preproc}
\subsubsection{Data Extraction}
Since the behavior of users may change greatly between daytime and nighttime, or workdays and holidays, we focus on data accumulated from 9 am to 5 pm on Monday to Friday. We also discard the data accumulated during the periods of holiday breaks, including Thanksgiving (Nov. 26, 2003 to Nov. 30, 2003) and Christmas and New Year (Dec. 17, 2003 to Jan. 4, 2004).
In addition, for some APs, we observed periods when they are temporally power off.  If the total service time of an AP on a certain day is less than 1/3 of its average value, we discard the data for this day.



\subsubsection{Trace Gap Padding}
The session duration is defined as the period of time during which a user is continuously connected to the network. The user may move from one AP to another during a session. Occasionally, a user may disappear from the SNMP report and soon reappear. This may be caused by the user departing and then returning to the network, or due to the missing of an SNMP report. Following the solution proposed in \cite{Mobility-Core1}, we set a departure length threshold $T_d=10$ minutes. Only if a user disappears and reappears within $T_d$, it is regarded as staying in the network and the missing SNMP logs are padded.

\subsubsection{Multiple Association and Ping-Pong Effect}
We also observe that some users are simultaneously associated with multiple APs within a small time interval.  Some even ping-pong among multiple APs.  We use two methods to offset these effects. First, when multiple associations occur, we check the number of packets exchanged with the user. We deem the user is associated with the AP which has exchanged the largest number of packets with the user during its multiple association period.  In addition, if a user leaves one AP and then returns within $5$ minutes, it is regarded as having stayed in the AP.

\subsubsection{Open Users}
a fraction of the users may stay in the system during almost all working hours. These users are regarded as closed users.  Since our analytical model assumes an open network, the closed users are excluded in our experiment.  If a user stays for greater than or equal to $7.5$ hours during working hours on a valid day, it is regarded as a closed user. In our experiment, we observe that $9.91\%$ of all users are closed users.  An analytical model for accommodating closed users is provided in \cite{Mobility-Core1}, which can also be applied to our work.



\subsection{Trace Analysis}

\subsubsection{Poisson Arrivals} \label{section_arrival}

Analysis of the Dartmouth trace in \cite{Mobility-Core1} has shown that the overall \emph{new} session arrivals into the network are well modeled by a Poisson process.  In this work, we further test the arrival process of new sessions \emph{at each AP} against the Poisson assumption.  This is divided into two steps. In the first step, we run an \emph{independence test}, which indicates whether the numbers of arrivals in different time intervals are independent. Since it is not practical to account for all time intervals, we test the independence of arrivals in two consecutive hours at each AP. If the AP passes the test, we regard the arrivals at this AP to be sufficiently independent. Let $H_2$ denote the entropy in the number of new arrivals in two consecutive hours and $H_1$ denote the entropy in the number of arrivals in one hour. Let $\eta=\frac{2H_1-H_2}{H_2}$ be the normalized entropy gap. If $\eta<0.15$, we regard the AP as passing the independence test.  We observe that $144$ of the $152$ APs pass the independence test.

In the second step, we run a \emph{Poisson distribution test}, which indicates whether the number of arrivals is Poisson distributed in a fixed time interval. For each AP that passes the independence test, we count the number of new arrivals in each hour and calculate its real distribution.  Furthermore, by using the actual average arrival rate per hour, we can determine the corresponding theoretical  Poisson distribution. Then, we compute the Kullback-Leibler (KL) divergence $H_{0}$ between the real distribution and the theoretical distribution\footnote{Kullback-Leibler (KL) divergence is a standard approach to measure the difference between two probability distributions $X$ and $Y$. It can be regarded as a measure of the information lost (in bits) when $Y$ is used to represent $X$. When KL divergence is $0$, $Y$ is exactly the same with $X$. {If the KL divergence is small compared with the  entropy  of the distribution $X$, the distribution $Y$ is a close approximation of that of $X$.}}. Let $\theta=\frac{H_{0}}{H_1}$ be the normalized KL value. If $\theta<0.15$, we regard the AP as passing the Poisson distribution test.  We observe that $124$ of the $144$ APs pass the Poisson distribution test.

Those $124$ APs are referred to as \emph{valid APs}, as the new arrivals at these APs can be well approximated as Poisson.  The other $28$ APs are referred to as \emph{invalid APs}.  In our experiments, we study the effects of both including and excluding the non-Poisson new sessions.  We emphasize that the Poisson test is for new arrivals only.  Even for those APs that pass the Poisson test, the overall session arrival process includes both new arrivals and handoff arrivals and hence is non-Poisson.

From the SNMP logs, we observe that the invalid APs tend to have occasional bursty arrivals. Since they are within the academic area, we conjecture that they correspond to large classrooms, which experience periodic rushes a the beginning of lecture hours.  Even though such APs do not match our analytical model, their user distribution is likely easy to predict in practice.


\subsubsection{Number of Stages and Channel Holding Times}

\begin{table}[tbp]
\centering
\renewcommand{\arraystretch}{1.1}
\caption{Number of stages}
\label{table2}
\small
\begin{tabular}{|c|c|c|c|c|c| }
\hline
\bfseries Stages & $1$  &  $2$  & $3$ & $4$ & $\geq 5$   \\
\hline
\bfseries Observations    & $80448$  &  $15767$  & $7410$ &   $3553$ & $6107$    \\
\hline
\end{tabular}
\end{table}





We have collected the distributions of number of stages in each route, which is shown in Table \ref{table2}.  It can be seen that there is a large percentage of sessions staying for just one stage.  To rigorously test the analytical stationary user distribution, we will later present different cases where one-stage sessions are either included or excluded.

Note that if the channel holding times are independently exponentially distributed, our conclusions on the stationary user distribution trivially holds. Therefore, more challenging channel holding times (i.e., arbitrarily distributed and correlated) are necessary to test our analytical results. Fig.~\ref{servicetime} shows the real distributions of channel holding times in different stages. This figure illustrates that none of them are exponentially distributed.  Furthermore, we check the dependency of channel holding times in different stages. The entropies of the distributions of channel holding times at stages $1, 2, 3$ and $4$ are $4.0657$, $3.4172$, $3.3942$ and $2.9792$, respectively, in bits. The entropy of their joint distribution is $10.2998$ bits. Hence, the entropy gap is $4.0657+3.4172+3.3942+2.9792-10.2998=3.5565$ bits, much larger than $0$.  This shows that the channel holding times at different stages are dependent.


\subsubsection{AP Locations and Distance Constraint}
APs that are far away are likely to have little effect on each other, regardless of the mobility and session patterns.  Therefore, to rigorously test the joint distribution of multiple APs, we are more interested in selecting adjacent APs with spatial correlation.  We set a \emph{distance constraint}, under which APs are located pairwisely less than $500$ meters from each other. In the experiments, when we study the joint distribution over multiple APs, this distance constraint is enforced by default, unless otherwise stated. However, we will also present comparison results for
cases with and without it.


\begin{figure}[tbp]
\centering  \hspace{0pt}
\includegraphics[scale=0.47]{Pdfservicetime.eps}
\caption{The pdf of channel holding time in different stages.}
\label{servicetime}
\end{figure}





\subsection{Marginal User Distribution at a Single AP}

\begin{figure}[t]
\centering  \vspace*{0pt}
\includegraphics[scale=1.15]{show1.eps}
\caption{Comparison of distributions for single APs. Real distributions  are in solid lines; analytical distributions are in dashed lines.}
\label{SD1}
\end{figure}



We first show the marginal user distribution at individual APs.   For this test, we applied all data after the pre-processing described in Section \ref{sec:preproc}, without further exclusions.
We show a sampling of the $152$ APs. In order to avoid selection bias, we choose APs according to their numeric identity. For each building (with at least one AP), we select the AP with the smallest identity number (i.e., \emph{AP1} if it exists; otherwise, we select \emph{AP2} if it exists; and so forth). There are $32$ buildings with at least one AP, and thus $32$ APs are selected accordingly.

Fig.~\ref{SD1} shows a comparison between the real distributions and the analytical distributions of these APs.  Each subplot is labeled with \emph{Y} or \emph{N}, where \emph{Y} indicates that the AP passes the two-step Poisson test and \emph{N} indicates the opposite.
The figure illustrates that the real distributions and the analytical distributions agree well with each other for those APs that pass the Poisson test.




\subsection{KL Divergence and Entropy Gap for Multiple APs}


 In this paper,   we use KL  divergence $H_{kl}$ to compare the real and analytical joint distributions of multiple APs.
We also test the independence of the numbers of users in different cells by computing
the entropy gap $H_{gap}$, between  the sum of the entropies of real marginal distributions and the entropy of the real joint distribution. The entropy of the real joint distribution $H_{real}$ is also presented for reference. {Note that if $H_{kl}$ is much smaller than $H_{real}$, the analytical distribution  is a close approximation of the real distribution; if $H_{gap}$ is much smaller than $H_{real}$, the numbers of users of single APs are approximately independent.}


Given $n$, the number of APs we aim to study, we randomly choose $n$ different APs. Then we compute $H_{kl}$, $H_{gap}$, and $H_{real}$ with respect to these APs.  By running this procedure $100$ times, we obtain the sample mean and sample standard deviation of $H_{kl}$, $H_{gap}$, and $H_{real}$.   In subsequent studies, we plot the sample mean versus $n$, along with bars showing one sample standard deviation, in Fig. \ref{result1}-\ref{result4}.  Note that the plot points are slightly shifted to avoid overlaps. Because the sample space of user distribution increases exponentially with the number of cells, and the real user distribution is counted through its relative frequency, we limit $n\leq5$ in the experiment in order to ensure enough data are counted for each sample point.



\begin{figure}[tbp]
\centering
\includegraphics[scale=0.42]{fig1.eps}
\caption{$H_{kl}$ and $H_{real}$ under the influence of non-Poisson arrivals.}
\label{result1}
\end{figure}

\begin{figure}[tbp]
\centering
\includegraphics[scale=0.42]{fig2.eps}
\caption{$H_{gap}$ and $H_{real}$ under the influence of non-Poisson arrivals.}
\label{result2}
\end{figure}




\subsubsection{Influence of Non-Poisson Arrivals} \label{sec:EffectNon-Poisson}

Clearly, excluding non-Poisson arrivals could improve the accuracy of the analytical model.
We compare $H_{kl}$, $H_{gap}$, and $H_{real}$ under the conditions of either including or excluding non-Poisson arrivals.

A direct method to exclude non-Poisson session arrivals is to remove from the data set all sessions that are initiated at invalid APs.  However, this will reduce the number of handoff session arrivals even in valid APs, hence biasing the analysis.  An alternate approach is to simply remove the invalid APs from the data set, while allowing those non-Poisson sessions to be counted in the valid APs that they pass through. In this way, accurate average arrival rates at the valid APs are maintained.

Thus, we study the following three cases: 1) Excluding sessions initiating at invalid APs (i.e., invalid sessions); 2) Excluding invalid APs; and  3) Without exclusion.  Fig.~\ref{result1} illustrates $H_{kl}$ compared with $H_{real}$ for the three cases, and
Fig.~\ref{result2} illustrates $H_{gap}$ compared with $H_{real}$  for the three cases.
{We observe that both $H_{kl}$ and $H_{gap}$ are much smaller than $H_{real}$, when we either exclude invalid sessions or exclude invalid APs, illustrating that the real distributions are close to the analytical distributions,} and the numbers of users of single APs are approximately independent.
When we do not exclude invalid sessions or invalid APs, $H_{kl}$ and $H_{gap}$ become larger, showing that the analytical distribution is influenced by the non-Poisson arrivals. {However, $H_{kl}$ and $H_{gap}$ remain much smaller than $H_{real}$, illustrating that the analytical distribution is still valid to approximate the real distribution,}  even the arrivals are not strictly Poisson.

In addition, excluding invalid sessions only brings small decrements in $H_{kl}$ and $H_{gap}$ compared with excluding invalid APs. Note that when we exclude invalid sessions, both the one-stage and multiple-stage non-Poisson arrival sessions are excluded; when we exclude invalid APs, only the one-stage non-Poisson arrival sessions are excluded. This illustrates that multiple-stage non-Poisson arrival sessions have only weak influence on the modeling accuracy.




\begin{figure}[tbp]
\centering
\includegraphics[scale=0.42]{fig3.eps}
\caption{$H_{kl}$, $H_{gap}$ and $H_{real}$ under the influence of distance restriction.}
\label{result3}
\end{figure}


\subsubsection{Influence of Distance Constraint}
Fig.~\ref{result3} shows $H_{kl}$, $H_{gap}$, and $H_{real}$ with and without the distance constraint. For both cases, we exclude the invalid APs.  We observe that $H_{kl}$, $H_{gap}$, and $H_{real}$ are nearly unchanged with or without the distance constraint, confirming our expectation that the distance constraint does not influence the accuracy of the analytical model, since the analytical model predicts that the numbers of users of adjacent APs are independent.


\begin{figure}[tbp]
\centering
\includegraphics[scale=0.42]{fig4.eps}
\caption{$H_{kl}$, $H_{gap}$ and $H_{real}$ under the influence of one-stage sessions.}
\label{result4}
\end{figure}

\subsubsection{Influence of One-Stage Sessions}
Fig.~\ref{result4} shows $H_{kl}$, $H_{gap}$, and $H_{real}$ with and without the one-stage sessions. For both cases, we exclude the invalid APs.
We observe that when we exclude the one-stage sessions, $H_{kl}$ and $H_{gap}$ becomes smaller, suggesting that our model is even more accurate in this case.  This is an apparently counter-intuitive result, since the analytical distribution trivially holds for one-stage sessions.  An explanation for this is the following. Since one-stage sessions are more likely to be new sessions corresponding to attending lectures in a classroom, they are more likely to be non-Poisson.  Since not all non-Poisson arrivals can be excluded by removing the invalid APs, when we further exclude one-stage sessions, we obtain more accurate analytical results.



Note that one-stage sessions can be analyzed as a single-queue model \cite{Mobility-Core4}. Thus, in practice, one may separately analyze one-stage and multiple-stage sessions and combine the resultant user distributions.


