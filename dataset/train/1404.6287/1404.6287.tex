\documentclass[oribibl]{llncs}
 
\usepackage{microtype}\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{xcolor}


\bibliographystyle{plain}


\spnewtheorem{myclaim}{Claim}{\bfseries}{\itshape}
\spnewtheorem{fact}{Fact}{\bfseries}{\itshape}
\spnewtheorem{observation}{Observation}{\bfseries}{\itshape}

\title{Improved Approximation Algorithms for Earth-Mover
Distance in Data Streams}

\author{Arman Yousefi\and Rafail Ostrovsky}
\institute{University of California Los Angeles\\
\email{\{armany, rafail\}@cs.ucla.edu}}





\begin{document}

\maketitle

\begin{abstract}
For two multisets  and  of points in ,
such that ,
the \textit{earth-mover distance} (EMD) between  and  is the minimum cost
of a perfect bipartite matching with edges between points in  and , i.e., 
,
where  ranges over all one-to-one mappings. The sketching complexity of
approximating earth-mover distance in the two-dimensional grid is mentioned
as one of the open problems in \cite{openproblems1, openproblems2}. 
We give two algorithms for computing EMD between two multi-sets when
the number of distinct points in one set is a small value
.
Our first algorithm gives a -approximation using
 space and works only in the
insertion-only model.
The second algorithm gives a -approximation
using -space in the turnstile model. 
\end{abstract}

\section{Introduction}
For a metric space  endowed with distance function ,
the \textit{earth-mover distance} (EMD) between two multisets ,
where  is defined as

where  ranges over all bijections .
In this paper we mostly deal with earth-mover distance over .
Thus, when the metric  is  we omit the subscript and 
write .
Earth-mover distance over the two dimensional plane has received significant
interest in computer vision because it is a natural measure of
similarity between images \cite{tommasi, tommasi2, grayspace, thaper}.
Each image can be viewed as a set of features and the distance is the optimal
way to match various features of images, where the
cost of such a matching corresponds to the sum of distances between the features
that were matched.
Apart from being a popular
distance measure in graphics and vision, variants of earth-mover distance known
as \textit{transportation cost} are used as LP relaxations for
classification problems such as 0-extensions and metric labeling
\cite{classification_metric, metric_labeling, charikar}.

In this paper we study two-dimensional earth-mover distance in the
streaming scenario.
In the streaming scenario for earth-mover distance, the two multisets of input
points are revealed to the algorithm as a stream of labeled points. The
algorithm maintains a short ``sketch'' of the data that can later be used to 
estimate the cost of the optimal matching. Note that the algorithm
does not produce an approximately optimal matching but only estimates its cost. 
The stream can be viewed as a
sequence of  operations where each operation either adds a point to one of
the two multisets or removes a point from one of them. 
The streaming model in which insertion and deletion of
points are both allowed is referred to in the literature as the \textit{dynamic
data stream} model. It's also called the \textit{turnstile} model.
The alternative is a streaming model in which only insertions of points are
allowed, and such a data stream is referred to as \textit{insertion-only} model.

\subsubsection{Discrete geometric space}
In data stream scenario, we assume that points live in the discrete space
 (denoted by ) instead of the continuous
two-dimensional interval 
where  is an integer upper bound on the diameter of the point set.
This is not a common assumption in computational geometry where input points
commonly have real coordinates. However, in real-life computations and in data
stream algorithms, the discrete space is a common assumption because the input
is assumed to have a finite precision.

Note that the assumption that the points of the two input multisets  and 
live in the discrete space  implies that the distance between 
a point in  and a point in  is at least one. We assume that  and 
are multisets, so multiple points of  (or multiple points of )
can share a location on the plane. However, we assume
that no point of  shares location with a point of . 

\subsection{Previous Results.}
Computing the earth-mover distance is a fundamental geometric problem, and
there has been extensive body of work focused on designing efficient algorithms
for this problem \cite{lawler, vai89, charikar, thaper, av04, eps_matching}.
The challenge in designing efficient streaming algorithms for earth-mover
distance is to construct and maintain a small space representation (or sketch)
of both multisets from which earth-mover distance between them can be
approximated.  In one dimension, the EMD between two multisets
can be reduced to calculating  difference between two vectors
representing the point sets in . If the number of points in each
multiset is , the  difference between two vectors of size 
can be approximated within a factor of  for any  using
 (see Fact \ref{fact1}). Thus, the EMD between
two multiset of points in one dimensional space over a dynamic data stream can
be approximated within a factor of  using
 space.
This is a folklore result, and the interested reader is referred to
\cite{emdgraphmetrics} for a detailed explanation.

In \cite{ind04}, Indyk gives a -approximation
algorithm for estimating the EMD between two multisets in  in one
pass over the data that uses  space.
His algorithm uses a probabilistic embedding of the EMD into  that
has  distortion \cite{thaper, charikar}.
Later, Naor and Schechtman \cite{naor} showed that any embedding of EMD into
 must incur a distortion of at least , so 
it is not possible to approximate EMD over a data stream within a factor better
than  by embedding EMD into . 

In \cite{const-approx} Andoni et al. gave a -approximation
algorithm for estimating EMD in the two-dimensional grid  using space
 for any . 
Their algorithm uses the result of \cite{ind07}
which decomposes the cost EMD over  into a sum of closely related
metrics called EEMD, defined over . Each component of the
sum is a sub-matching between subsets of the two original multisets. 
In \cite{ind07} Indyk shows how to estimate the sum of sub-matchings by sampling
sub-matchings using a random distribution where the probability of choosing a
sub-matching is roughly proportional to its cost. In \cite{const-approx} the
authors show how to approximate the sum of sub-matchings over a data stream.

For earth-mover distance in high dimensions, Khot and Naor \cite{kn06} show
that any embedding of EMD over the -dimensional Hamming
cube into  must incur a distortion , thus practically
losing all distance information. Andoni et al. \cite{kraught08} circumvent this
roadblock by focusing on sets with cardinalities upper-bounded by a parameter
, and achieve a distortion of only .
As a result, they show a -approximation
streaming algorithm that uses  space.   

\subsection{Our Results}
In this paper we give two streaming algorithms for approximating
EMD in the two-dimensional grid  when the number of distinct points
in one of the multisets is polylogarithmic. This is an interesting case because
in applications the feature sets of images usually have bounded size.
A similar case for high dimensions has been studied before in \cite{kraught08},
but our constraint on the input is more relaxed than that of \cite{kraught08}
because we require a bound on the number of distinct
points in only one of the multisets while in \cite{kraught08}
they require a bound on the size of both sets.
The special case of EMD that we study
is also important because of its connections to the \textit{capacitated
-median problem} with hard constraints as we explain shortly.

Our first algorithm gives a -approximation for any 
using space . This algorithm uses coresets
for -median problem and it works in the insertion-only model.
Our second algorithm works in the turnstile model (or dynamic geometric streams)
and it gives a weaker approximation of  using
 space.
Both algorithms naturally extend to work for higher
dimensions. However, the second algorithm is better suited for higher dimensions
because its memory usage does not depend exponentially on dimension . 
The following table summarizes our results.

\begin{table}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Algorithm & Approximation & space & Model  \\
\hline
Algorithm 1 &  & & insertion-only\\
Algorithm 2 &  & & turnstile\\
\hline
\end{tabular}
\end{center}
\end{table}

\subsubsection{Connections to Capacitated -median Clustering}
The non-streaming version of Capacitated -median clustering
has been studied before (for example \cite{cap_kmedian1, cap_facil}),
and it is known to be harder than -median clustering with no capacities.
In capacitated -median clustering with uniform capacities over
a data stream, in addition to a parameter  and a point set
, we are given a parameter .
The goal is to find a set  of size  that minimizes
 where  is one of the  centers
that  is assigned to, and that the number of points
assigned to each of the  centers doesn't exceed its capacity .

Our algorithms for earth-mover distance can be extended to algorithms for
capacitated -median clustering with hard constraints.
The input point set of the capacitated -median clustering can be viewed
as one of the point sets in the earth-mover distance and any set
of  centers whose capacities add up to  can be viewed as
the other multiset of points.
The -median cost of a point set respect to a given set of centers
is the earth-mover distance between the input point set and the centers.
The streaming algorithm for earth-mover distance can be used
to keep a sketch of the input point set. At the end of the stream,
the algorithm exhaustively searches all possibilities for  center points and,
for each choice of  centers, all possible capacities of centers that do
not violate capacity constraints and add up to .
For each possibility the algorithm approximates the
earth-mover distance between the input point set and the capacitated centers
and reports the centers with minimum value. Thus, the algorithm
exhaustively searches all  possibilities using small space
and returns an approximate solution
to the capacitated -median problem with hard constraints.
Note that the above algorithm does not violate capacity constraints.
Thus, any of the algorithms in this paper can be turned into a streaming
algorithm for the capacitated -median clustering with hard constraints.

\section{First Algorithm}
 In this section we show how to use coresets for -median to give
a -approximation algorithm for EMD.
 
For a point set  and a point , both in ,
let  denote the distance of 
from .
For a weighted point set , with
an associated weight function 
and any point set  of  points, we define
 as the the \textit{price} of
-median clustering provided by . In the -median
problem, the goal is to find a set  of at most  points
in  such that  is minimized.
We also use 
to denote the price of the optimal -median clustering for .

\begin{definition}[Coreset]
For a weighted point set , a weighted set
 is a -coreset for the
-median problem if for every set  of  centers:
. 
\end{definition}

Har-Peled and Mazumdar \cite{kcoreset} prove the existence of small
coresets for the -median problem and show how to construct them.
They also show how to construct and maintain coresets over data streams
using polylogarithmic space when the points are only inserted into the
stream. We use the following fact from \cite{kcoreset}.

\begin{fact}[Theorem 7.2 from \cite{kcoreset}]\label{har-peled}
 Given an insertion-only stream  of  points in  and
, one can maintain a
-coreset of size  for -median.
The space used by the algorithm is  and the
amortized update time is .
\end{fact}

\subsection{Algorithm Description}
Let  be two multisets of points such that ,
where the number of distinct points in one of the sets is at most
. Assume without loss of generality that the
number of distinct points in  is .
The points of  and  are revealed to the algorithm in an insertion-only
stream, the following algorithm computes an estimate of  as follows.
The algorithm maintains a -coreset for -median
for the set  using Fact \ref{har-peled}. For  the space needed to
maintain the coreset is . Let  denote
the coreset of . The algorithm also
keeps the entire set  of points in its memory. At the end of
the stream the algorithm computes  using the
``Hungarian'' method \cite{lawler}.

We claim that  is a -approximation
of . An important property of the coresets constructed for 
-median in \cite{kcoreset} that allows us to extend the use of
coresets to earth-mover distance is the following. There is a
one-to-one correspondence between the points of  and .
If for any ,  denotes the image of  in ,
then the coreset construction guarantees that
.
Intuitively this means that each point of  is snapped to
a point of  such that the sum of movements of points
of  is at most . It's easy to
see from this property that for any set  of points
 is at most
.

We now show how this property of the -coreset
for -median can be used to bound .
If for every point
, its image in  is denoted by , we have: 



The last inequality above holds because
.
Thus we have shown that .
We can also show that 

using a similar argument. Thus we have:

\begin{theorem}
For any  and any two multisets , where
, the number of distinct points in one set is bounded by ,
and the points are revealed to the algorithm in an insertion-only stream,
there is a one-pass streaming algorithm that approximates
 within a factor of  and uses space
.
\end{theorem}

\subsubsection{Why do coresets for dynamic data streams fail for EMD?}
A natural question to ask is if coresets can also be used for dynamic data
streams where insertion and deletions are both allowed.
Frahling and Sohler \cite{coreset_dynamic}
proposed a method for constructing coresets that work for dynamic data streams.
Their coreset construction is based on sampling points from the
data stream, and it works for -median, but it cannot be
used for earth-mover distance.
For a given coreset  of , their algorithm constructs
a set  such that the point locations in  and
 are the same, but the weight of every point in 
differs from the corresponding point in  by a factor of
at most .
Thus, for any set  of  points,  and
 differ by at most a factor of 
and computing the -median cost for  approximates
the -median cost for  and .
However, this argument does not work for earth-mover distance because
 and  may differ 
significantly.
We mention a simple example to show that EMD is very sensitive to
the weight of points in , 
let  be a multiset containing two distinct points far from each other,
each with weight .
Let also  be a coreset for  that contains
exactly two weighted points, each with weight .
Each point of  is at distance one to a point in .
In this case , but changing the weights of points in
 by a factor of  may affect the cost of
 significantly.

\section{Second Algorithm}\label{algorithm2}
Our first algorithm gives a -approximation, but it doesn't work
in dynamic geometric streams, and its space requirement is
.
We next present our second algorithm that works on dynamic geometric streams
(when deletions are also allowed) and requires much less space specially for
higher dimensions, but these advantages come at the cost of a weaker
approximation ratio.
 
We start this section with some preliminaries and notations
used in our description of the second algorithm and its related proofs.
We use  to denote the set of edges of minimum-cost bipartite perfect
matching between points of the two input multisets  and . 
For an edge  that matches a point 
with , let  denote the  distance between 's
endpoints.
The cost of the matching  or the earth-mover
distance between multisets  and  is .

For a grid over , we use a grid's \textit{cell size}
to refer to the side length of cells in the grid.
Fix a grid 
over  whose cell size is a positive integer. For every
multiset , we define  to be the
\textit{characteristic vector} of  with respect to . Each coordinate of
 corresponds to a cell of  that intersects , and the
value of that coordinate is the number of points of  in the corresponding 
cell.
In the context of our algorithm, we avoid having points that live on the grid 
lines so that the number of points that fall into a cell of the grid is
defined without ambiguity. Since the points have integral coordinates,
we can ensure that the points are in the interior of the grid cells
by restricting the grid lines to have
half-integral coordinates .

Throughout this section, we talk about grids that are shifted by some random
-dimensional vectors with half-integral coordinates. 
We assume that each grid prior to shift is fixed at the origin .
Thus, after shifting a grid by vector , the grid point
at  is moved to , and the rest of the grid translates
accordingly. Thus, we ensure that the lines of the shifted grid have
half-integral coordinates.

To estimate the earth-mover distance over data streams, our algorithm maintains
sketches of characteristic vectors of the two input sets
with respect to different grids. These sketches enable us to estimate
the  and  norms of the characteristic vectors
\footnote{The  norm of a vector is
also referred to as the frequency moment  in the literature.}. 

Let  be an -dimensional vector whose coordinates are values in the set
. 
The  norm of  is 

and its  norm is .
We use the following two facts from \cite{stable} and \cite{bar_yossef}
to maintain a sketch for the  and  norm of vector  whose
coordinates are dynamically updated in a data stream. 
Each update in the stream is of the form  which adds  to the -th
coordinate of .

\begin{fact}[Theorem 2 of \cite{stable}]\label{fact1}
There is an algorithm that, for any , estimates the
 norm of  up to a factor of  with probability
 and uses 
bits of memory.
\end{fact}

\begin{fact}[Theorem 1 of \cite{bar_yossef}]\label{fact2}
There is an algorithm that, for any , estimates the 
norm of  up to a factor of  with probability 
using  bits of memory.
\end{fact}

\subsubsection{Our Technique}
Our second algorithm is a modification of the idea in \cite{ind04}
which uses an embedding of EMD into  that has a distortion of
 \cite{thaper, charikar}.
However, since any embedding of EMD into  must
incur  distortion \cite{naor}, we need additional
ideas to obtain a better approximation ratio.

The algorithm of \cite{ind04} uses nested grids
 over  where the cell size of
grid  is , and a cell in  contains  cells in
. The nested grids are shifted by a vector chosen uniformly at random.
The multiset  is mapped into 

in the  space where
 denotes the characteristic vector of multiset  with respect
to grid . In other words,  is obtained by concatenating vectors
.
Similarly, multiset  is mapped into , and 
to estimate , the value of  is computed.
The distortion of the above embedding is , so 
the above algorithm gives a -approximation streaming algorithm
for computing .

Instead of using one grid per level, our algorithm uses
 randomly shifted grids at each level
. At each level our algorithm maintains the
 norm of the difference of characteristic vectors of  and  with
respect to every grid at that level. At the end of the stream, we choose
the grid with minimum  difference at each level and compute our estimate.
This way our algorithm circumvents  lower bound
on the distortion of embedding EMD into  \cite{naor}.
The proof that the above modification gives a better approximation ratio is the
main technical part of this section.

\subsection{Algorithm Description}
For every , our algorithm builds 
 grids over  with cells of size 
that are randomly and independently shifted. 
As the points in the stream arrive, the algorithm maintains a sketch for
the  norm of the difference of characteristic vectors of  and 
with respect to every grid. At the end of the stream the algorithm chooses, for
each level, the grid with minimum  norm and reports

as the estimate of  where  is the estimate of
the minimum  norm at level  and  is an estimate
of the minimum of the number of distinct points in  and .
Thus, our algorithms maintains the following data structures:
\begin{enumerate}
 \item For each  and each
, let  be a grid of cell size
 that is shifted by a vector chosen independently and
uniformly at random
(recall that the coordinates of the shift vector are half-integral).
The algorithm maintains a sketch of vector
 under addition and deletion of points from
 and  to estimate its  norm,
, at the 
end of the stream. This can be done using Fact \ref{fact1}.
 \item The algorithm also maintains a sketch to determine the number of distinct
points in  and . This can be done using Fact \ref{fact2}
to estimate the  norm of  and  with respect to any grid
at level .
Note that all random shift vectors result in the same grid  at level , 
and there is at most one distinct point of  (or ) in each cell of
, so the  norm of  (or ) is the number of
distinct points of multiset  (or ).  
\end{enumerate}

Let  be minimum of the two estimates for the  norms of
 and . Then,  estimates ,
the minimum of the number of distinct points in  and . 
We define , and .
Let  denote the algorithm's estimate of  for all .
At every level  the algorithm chooses the grid  that minimizes
 and lets .
The output of the algorithm is 

This concludes our description of the algorithm.

\subsubsection{Space usage}
The above algorithm uses  grids at each level
, and maintains the  norm of the difference of
characteristic vectors of  and  with respect to each grid. Each vector
 has at most  coordinates and each
coordinate is in . By Fact \ref{fact1}, the sketch to maintain
 requires  bits of
storage where  is the probability of error in estimating the norm
with respect to each grid. If we want the total error probability in estimating
all  to be bounded by , we need to set .
With this value of  the space needed to maintain each  is

and the total space used to maintain the  norm of these vectors is
. 
Also the space needed to maintain the number of
distinct point in  and  is 
(by Fact \ref{fact2} from \cite{bar_yossef}). 
Thus the total space used by the algorithm is still
.

To show that the estimate  returned by the algorithm approximates ,
we will prove upper and lower bounds on the value of  in the next
section. 

\subsection{Bounding the Cost}\label{cost}
In this section we prove upper and lower bounds on the cost of the estimate
returned by the algorithm.
By Fact \ref{fact1} and Fact \ref{fact2}, the values of  and
 for all  can be estimated within a factor
of  for any parameter .
This increases the space usage by a multiplicative factor of 
which is ignored as we take  to be some small constant.
If  and ,
then:


For fixed , the factor  is a small constant.
Thus, it suffices to prove upper and lower bounds on the value of
 instead of

returned by the algorithm.
In fact, to further simplify the exposition, we prove our bounds on the value of 
 which is scaled
by a factor of . Specifically we show that 
 with very high probability.
In the next lemma we show a high probability upper bound on .

\begin{lemma}[Upper bound]\label{upperbound}
With high probability, the value

is at most .
\end{lemma}
\begin{proof}
Recall that  denotes the set of edges of the optimal matching
between points of  and . We say an edge  \textit{crosses} a
grid  if the two endpoints of  fall in different cells of .

\begin{definition}[Good Grid]
A grid  at level- is a \textit{good} grid if it is not
crossed by any edge  whose  norm is less than
-fraction of cell
size of  (i.e. ).
\end{definition}

To bound  in terms of , we show that with very high probability
at every level one of the  randomly shifted grids is
a good grid. If we consider the set of such good grids, one per level ,
then every  only crosses grids whose cell size is at
most . This allows us to charge the length of each edge  to
the grids that it crosses at different levels.

Let  be the event that  (i.e. the -th randomly shifted grid
at level ) is a good grid.
The following claim states that with very high probability, there is
a good grid  at every level .

\begin{myclaim}\label{crossing}
.
\end{myclaim}
\begin{proof}
We assume without loss of generality that  is the number of distinct points
in . Each edge in the optimal matching connects one of these  points to a
point in . 
Any edge  where  connects a point  to a
point in  which is in
a square of side length  centered at .
Grid  is shifted by a random vector, and it intersects one of the edges
whose  norm is  only if it intersects one of the 
squares of side length  centered at points in . 
The cell size of grid  is , and the side length of each square is
, so the probability that a square is intersected by a line of
grid  is . By union bound the probability that
any of the  squares intersect a line of grid  is at most . 
This also bounds the probability that grid  is crossed by an edge of
length . Thus, the probability over random shift vectors that
grid  is not a good grid is at most .
There are  shift vectors at level , and by independence of
shift vectors the probability that all grids  at level
 are not good is at most 
.
The claim is proved by applying the union bound for all  levels.
\end{proof}

We next show how to bound  from above using Claim \ref{crossing}.
Let's assume that there is a good grid at each level  denoted by ,
then:


It's easy to see that for every grid : 
 for the
following reason. For every square , let  and  be the
the number of points of multiset  and  in square  respectively. 
Then in every cell ,  is the minimum number of points
in cell  that cannot be matched with a point in that square. Thus, in any
matching the total number of points that are not matched within their square is
at least . Each
point that is not matched within its square is an endpoint of an edge that
crosses grid . Thus the number of edges in any matching that cross  is
at least . This combined with (\ref{eq1}) implies 
that:

Since  is a good grid, the above implies that:

Thus, 
if there is a good grid at each level  which
happens with probability  by Claim \ref{crossing}.
Hence, .
\end{proof}
Using the above result, we can also show an upper bound on the expected
value of , but we omit the straightforward details. Our next lemma
establishes the lower bound on the value returned by the algorithm.
\begin{lemma}[Lower bound]\label{lowerbound}
The value 
is at least .
\end{lemma}
\begin{proof}
The idea of the lower bound is to charge the cost of each edge  to
the grid levels whose cell size is at most . Thus at each level
only edges whose  norm is at least the cell size of
that level contribute to the cost.
Then, at each level  we bound from above the total number of
edges that contribute to that level in terms of
 where  is
\textit{a few} levels below . Therefore, we can bound 
from above in terms of .

For any , we use  to denote . 
Note that  for all  because there are a total of
 edges in .
We have:


The main tool in the proof of the lemma is the following claim which lower
bounds 
by the number of edges in the optimal matching  whose length is at least
.
 
\begin{myclaim}\label{cl2}
 For all :
.
\end{myclaim}
The idea of the proof is to view grid  at level  as a graph where the
grid cells are vertices of the graph and the edges crossing the grid are
directed edges of the graph. We then show how to decompose the edges of the
graph into a set of paths of length  where the start and end vertex of
each path contribute two to the value of . Thus the total number of
such paths is at most  and the total number of edges whose 
norm is  is at most . The detailed proof appears in
the appendix.

We next show how to use the above claim to prove Lemma \ref{lowerbound}.
From Inequality (\ref{eq3}) above we have:

The last inequality holds because .
This completes the proof of Lemma \ref{lowerbound}.
\end{proof}

Lemma \ref{upperbound} and \ref{lowerbound} together imply that our algorithm
gives a -approximation of the cost of EMD.
To ensure approximation ratio of , 
the algorithm holds an additional
data structure to maintain the sketch used by 
-approximation algorithm of \cite{ind04}. 
The two algorithms
maintain their own sketches and at the end of the stream, each
algorithm computes its estimate of EMD using its sketch and the minimum
of the two estimates is returned. Clearly this estimate is within 
 factor of the cost of EMD.
Thus, we have the following:

\begin{theorem}
There is a -approximation that uses 
 space to estimate the                                     
earth mover distance between two multiset  given over
a dynamic data stream, where  and minimum of the number of
distinct points in  and number of distinct points in  is bounded by . 
\end{theorem}

\section{Conclusion}\label{conclude}
We have obtained two approximation algorithm for earth-mover distance
between two multisets of points in  when the number of
distinct points in one set is small. Both algorithms use polylogarithmic space.
Our algorithms can be extended to give streaming algorithms for
capacitated -median clustering with hard constraints.
We conclude with some natural open questions: 1) Is there a -approximation
algorithm for EMD with no constraints on the input size using only polylogarithmic space?
2) Can one prove a lower bound on the best approximation possible for EMD
in polylogarithmic space?
3) Are there better streaming algorithms for the capacitated -median
with hard constraints? 
\bibliographystyle{alpha}
\bibliography{template}

\appendix
\section{Proof of Claim \ref{cl2}}
\begin{proof}
We prove that for \textit{any} grid  at level , the number of
edges of  with  norm at least  is at most ,
where .

For grid , we define the directed multigraph  as follows. Every
cell  of the grid that contains a point from  or  corresponds to a
vertex of .
Each edge of  corresponds to an edge of the matching  that crosses
the grid. Recall that an edge crosses the grid if its endpoints are in different
cells. Each edge in  has a \textit{length} which is equal to the
 norm of the corresponding edge in the matching .
Edges of  are directed from points in  to points in
. Note that  and  are multisets, and there might be multiple copies of
a point in  or in .
Thus, if  copies of a point in  are matched to
 copies of a point in , there are  copies of the same edge in the
matching , and if the endpoints of the edge are in different cells,
there are  edges between the corresponding vertices in . Hence,
 is in general a multigraph.

A few observations about graph  are in order:
\begin{observation}\label{obs1}
 The length of every simple cycle (or every simple path) in graph 
is at most .
\end{observation}
This holds because  is an upper bound on the number distinct points in 
and also the number of vertices of  with positive indegree.
\begin{observation}\label{obs2}
No cycle in  contains an edge of length . 
\end{observation}
If such a cycle exists, there are
matched pairs 
 such that
for every , points  and 
(we define ) are in the same cell in grid 
and the length of one of the edges is 
(see Figure \ref{cycle}).
Thus, the matching  costs at least .


\begin{figure}
\begin{center}
\scalebox{.7}
{
\begin{picture}(0,0)\includegraphics{./SAVE.pdf}\end{picture}\setlength{\unitlength}{4144sp}\begingroup\makeatletter\ifx\SetFigFont\undefined \gdef\SetFigFont#1#2#3#4#5{\reset@font\fontsize{#1}{#2pt}\fontfamily{#3}\fontseries{#4}\fontshape{#5}\selectfont}\fi\endgroup \begin{picture}(5424,4132)(1024,-4123)
\put(2926,-511){\makebox(0,0)[lb]{\smash{{\SetFigFont{20}{24.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(2026,-3841){\makebox(0,0)[lb]{\smash{{\SetFigFont{20}{24.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(5316,-1388){\makebox(0,0)[lb]{\smash{{\SetFigFont{20}{24.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(3568,-1138){\makebox(0,0)[lb]{\smash{{\SetFigFont{20}{24.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(5671,-2311){\makebox(0,0)[lb]{\smash{{\SetFigFont{20}{24.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(1186,-3281){\makebox(0,0)[lb]{\smash{{\SetFigFont{20}{24.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(1126,-2591){\makebox(0,0)[lb]{\smash{{\SetFigFont{20}{24.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(2321,-846){\makebox(0,0)[lb]{\smash{{\SetFigFont{20}{24.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(1925,-1248){\makebox(0,0)[lb]{\smash{{\SetFigFont{20}{24.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(1552,-1888){\makebox(0,0)[lb]{\smash{{\SetFigFont{20}{24.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(4201,-258){\makebox(0,0)[lb]{\smash{{\SetFigFont{20}{24.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\put(3715,-464){\makebox(0,0)[lb]{\smash{{\SetFigFont{20}{24.0}{\rmdefault}{\mddefault}{\updefault}{\color[rgb]{0,0,0}}}}}}
\end{picture} }
\caption{The solid edges show the matching of the pairs
. These edges form a cycle
in the corresponding graph . If there is an edge  with
length , there is an alternative matching
 (shown in dotted lines) with lesser cost.
\label{cycle}}
\end{center}
\end{figure}
However, there is an alternative matching

that costs at most  because the are at most 
pairs of points (by Observations \ref{obs1}),
and each pair is in the same cell of grid .
This contradicts the optimality of .

The next observation is a connection between the number of points of  and 
in a cell of the grid, and the indegree and outdegree of the corresponding cell
in graph . Let  be any cell in  and  be the corresponding
vertex in graph . Let  and  denote the
outdegree and indegree of  respectively, and let  and 
denote the number of points of  and  in the cell .
\begin{observation}
For every cell  and corresponding vertex  in :

.
\end{observation}
For every edge out of ,
there should be a point of  in cell , and for every edge into  there
should be a point of  in cell . The rest of the points of  and 
in cell  that are not an endpoint of an edge of  are matched within
the cell. The number of points of  that are matched within  should be
equal to the number of points of  that are matched within , so these
points don't contribute any value to .
Hence, . 

By summing over all cells  in the grid, this observation implies that:


We are now ready to prove claim \ref{cl2}. The idea is
to decompose the edges of graph  into a
set of paths where each path contains at least one of the edges of length
.
We show that the graph  can be decomposed into at most
 such paths and each path contains at most 
edges of length .

The decomposition works in a natural way as follows.
Let  be any edge such that .
We show how to construct a path that contains .
If ,  is the end of the path. Otherwise,
 and there is an edge  going out of . By
the same argument either  or there is an edge going
out of . This process can be repeated until a vertex  is reached such
that . We mark  to be the end of the path.
The original edge  can also be traced in the opposite direction to
reach a vertex  such that .
Note that by Observation \ref{obs2}
edge  is not in any cycle, so the start and end vertex of the path can't
be the same vertex. Removing all the edges of this path from graph 
reduces  by two because
the quantity  is reduced by one 
for the start and end vertices of the path, and for all
other vertices this quantity is unchanged.

After removing the edges of this path from graph ,
the remaining graph may still contain
edges of length . We can choose any one of these edges and
repeat the above process to find another path and remove it from the graph.
This process can be repeated until there are no edges of length
 in the graph. Each time a path is extracted the quantity
 reduces by two. Thus, the total
number of such paths is at most

which equals  by Equation (\ref{eq4}).
Each path contains at most  edges of length 
by Observation \ref{obs1}. Thus the total number of such edges is
bounded by . 
\end{proof}

\end{document}