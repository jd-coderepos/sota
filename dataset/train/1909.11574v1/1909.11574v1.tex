

\begin{algorithm}[t]
\label{alg:algorithm}
\caption{Training a model via MIC}

\SetKwFunction{Cluster}{Cluster}
\SetKwFunction{Embed}{Embed}
\SetKwFunction{Forward}{Forward}
\SetKwFunction{Split}{Split}
\SetKwFunction{Backward}{Backward}
\SetKwFunction{GetBatch}{GetBatch}
\SetKwFunction{Stand}{Stand}
\SetKwFunction{InterLoss}{ClassLoss}
\SetKwFunction{IntraLoss}{SharedLoss}
\SetKwFunction{Loss}{Loss}
\SetKwFunction{Disent}{Disent}
\SetKwFunction{Finetune}{Finetune}
\SetKwFunction{MSE}{MSE}
\SetKwInOut{Input}{input}
\SetKwInOut{Init}{initialization}
\SetKwInOut{Constants}{parameters}
\SetKwInOut{Output}{output}
\SetKwRepeat{Repeat}{repeat}{until}

\SetAlgoLined
\textbf{Input:} data , full encoder , inter-/intra class encoders , CNN , class targets ,  batchsize , clusternumber , update frequency , (adversarial) mutual information loss  and weight , projection network , gradient reversal op , metric learning loss functions for  
\newline

 \Cluster{\Stand{\Embed{, , }}, }

  0

\While{Not Converged}{
    \Repeat{end of epoch}{
    
          \GetBatch{, , , }
        
         \Embed{, , }
        


         (, )  (, R())
        
         \Backward{}
        
        
         \Embed{, , }
        
         (, ) (, R())
        


         \Backward{}
        
    }
    \If{epoch  }{
         \Cluster{\Embed{X,,}, }
    }
     
}
\end{algorithm}

