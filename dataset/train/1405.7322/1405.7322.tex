
\documentclass[Times, 10pt,twocolumn]{article} 
\usepackage{latex8}
\usepackage{times}
\usepackage{verbatim} 
\usepackage{cite}
\usepackage{clrscode3e}
\usepackage[pdftex]{graphicx}
\usepackage{setspace}
\usepackage[cmex10]{amsmath}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{float}

\usepackage{subfig}
\usepackage{graphicx}

\usepackage{caption}
\usepackage[compact]{titlesec}
\usepackage{fullpage}
\addtolength{\itemsep}{-0.05in}


\newcommand{\parlabel}[1]{\vspace{0.1in}\noindent\textbf{#1}\xspace}


\newtheorem{theorem}{\textbf{Theorem}}
\newtheorem{fact}{\textbf{Fact}}
\newtheorem{methodology}{\textbf{Methodology}}
\newtheorem{lemma}{\textbf{Lemma}}
\newtheorem{claim}{\textbf{Claim}}
\newtheorem{proposition}{\textbf{Proposition}}
\newtheorem{corollary}{\textbf{Corollary}}

\theoremstyle{definition}
\newtheorem{definition}{\textbf{Definition}}

\newenvironment{example}[1][Example]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{remark}[1][Remark]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}


\renewcommand{\rmdefault}{ptm}









\setlength{\textheight}{8.7in}
\setlength{\textwidth}{6.9in}
\setlength{\columnsep}{0.25in}
\setlength{\oddsidemargin}{-.14in}
\setlength{\evensidemargin}{-.25in}
\begin{comment}
\setlength{\topmargin}{-0.1in}
\setlength{\headheight}{0.1in}
\setlength{\headsep}{0in}
\setlength{\parindent}{1pc}


\renewcommand{\topfraction}{.98}
\renewcommand{\topfraction}{.98}
\renewcommand{\textfraction}{.02}
\renewcommand{\bottomfraction}{.7}
\renewcommand{\floatpagefraction}{.66}
\renewcommand{\dbltopfraction}{.98}
\renewcommand{\dblfloatpagefraction}{.66}
\end{comment}

\def\changemargin#1#2{\list{}{\rightmargin#2\leftmargin#1}\item[]}
\let\endchangemargin=\endlist








\def \tab {\space\space\space\space\space}


\hyphenation{op-tical net-works semi-conduc-tor}



\begin{document}  

\title{\protect\vspace{-.5in}{Supporting Soft Real-Time Sporadic Task Systems on Heterogeneous Multiprocessors with No Utilization Loss}\thanks{This work was supported by a start-up
grant from the University of Texas at Dallas.}}
\author{Guangmo Tong and Cong Liu\\
Department of Computer Science, University of Texas at Dallas}

\maketitle
\thispagestyle{empty}



\begin{abstract}

Heterogeneous multicore architectures are becoming increasingly popular due to their potential of achieving high performance and energy efficiency compared to the homogeneous multicore architectures. In such systems, the real-time scheduling problem becomes more challenging in that processors have different speeds. A job executing on a processor with speed  for  time units completes  units of execution. Prior research on heterogeneous multiprocessor real-time scheduling has focused on hard real-time systems, where, significant processing capacity may have to be sacrificed in the worst-case to ensure that all deadlines are met. As meeting hard deadlines is overkill for many soft real-time systems in practice, this paper shows that on soft real-time heterogeneous multiprocessors, bounded response times can be ensured for globally-scheduled sporadic task systems with no utilization loss. A GEDF-based scheduling algorithm, namely GEDF-H, is presented and response time bounds are established under both preemptive and non-preemptive GEDF-H scheduling. Extensive experiments show that  the magnitude of the derived response time bound is reasonable, often smaller than three task periods. To the best of our knowledge, this paper is the first to show that soft real-time sporadic task systems can be supported on heterogeneous multiprocessors without utilization loss, and with reasonable predicted response time.

\end{abstract}

\section{Introduction}
\label{sec:intro}

Given the need to achieve higher performance without driving up power consumption and heat dissipation, most chip manufacturers have shifted to multicore architectures. An important subcategory of such architectures are those that are heterogeneous in design. By integrating processors with different speeds, such architectures can provide high performance and power efficiency \cite{liu2012power}. Heterogeneous multicore architectures have been widely adopted in various computing domains, ranging from embedded systems to high performance computing systems. 

Most prior work on supporting real-time workloads on such heterogeneous multiprocessors has focused on hard real-time (HRT) systems. Unfortunately, if all task deadlines must be viewed as hard, significant processing capacity must be sacrificed in the worst-case, due to either inherent schedulability-related utilization loss---which is unavoidable under most scheduling schemes---or high runtime overheads---which typically arise in optimal schemes that avoid schedulability-related loss.\footnote{Such utilization loss may exist even in a homogeneous HRT multiprocessor system where all processors have the same speed \cite{baruah2007techniques, shin2012rtss, davis2011survey, bertogna2007response, davis2012optimal}.} In many systems where less stringent notions of real-time correctness suffice, such loss can be avoided by viewing deadlines as soft. In this paper, we consider the problem of scheduling soft real-time (SRT) sporadic task systems on a heterogeneous multiprocessor; the notion of SRT correctness we consider is that response time is bounded.



All multiprocessor scheduling algorithms follow either a \textit{partitioning} or \textit{globally-scheduling approach} (or some combination of the two). Under partitioning, tasks are statically mapped to processors, while under global scheduling, they may migrate. Under partitioning schemes, constraints on overall utilization are required to ensure timeliness even for SRT systems due to bin-packing-related loss. On the other hand, a variety of global schedulers including the widely studied global earliest-deadline-first (GEDF) scheduling algorithm are capable of ensuring bounded response times for sporadic task systems on a homogeneous multiprocessor, as long as the system is not over-utilized \cite{Devi}. Motivated by this optimal result, we investigate whether GEDF remains optimal in a heterogeneous multiprocessor SRT system.


\paragraph{Key observation.} Under GEDF, we select  highest-priority jobs at any time instant and execute them on  processors. The job prioritization rule is according to earliest-deadline-first. Regarding the processor selection rule (i.e., which processor should be selected for executing which job), it is typical to select processors in an arbitrary manner. On a homogeneous multiprocessor, such an arbitrary processor selection rule is reasonable since all processors have identical speeds. However, on a heterogeneous multiprocessor, this arbitrary strategy may fail to schedule a SRT sporadic task system that is actually feasible under GEDF. Consider a task system with two sporadic tasks  and  (notation  denotes that task  has an execution cost of  and a period of ) scheduled on a heterogeneous multiprocessor with two processors,  with speed of one unit execution per unit time and  with speed of two units execution per unit time. Assume in the example that task deadlines equal their periods and priority ties are broken in favor of . Fig.\ref{fig:simpleexample}(a) shows the corresponding GEDF schedule with an  arbitrary processor selection strategy for this task system. As seen in the figure, if we arbitrarily select processors for job executions, the response time of  grows unboundedly. However, if we define specific processor selection rules, for example always executing tasks with higher utilizations on processors with higher speeds, then this task system becomes schedulable as illustrated in Fig.\ref{fig:simpleexample}(b).

\begin{figure}[t]
	\begin{center}
	\includegraphics[width=2.8in]{images/f1.pdf} 
	\end{center}  
\vspace{-3mm}
\caption{Motivational example.}
\vspace{-3mm}
\label{fig:simpleexample}
\end{figure}



The above example suggests that \textit{on a heterogeneous multiprocessor, GEDF's processor selection strategy is critical to ensuring schedulability}. Motivated by this key observation, we consider in this paper whether it is possible to develop a GEDF-based scheduling algorithm with a specific processor selection rule, which can schedule SRT sporadic task systems on a heterogeneous multiprocessor with no utilization loss.

\paragraph{Overview of related work.} The real-time scheduling problem on heterogeneous multiprocessors has received much attention \cite{baruah2011partitioned, kumar2004single, andersson2010assigning, baruah2005partitioned, funk2005task, funk2001line, liu2012power}. Most such work has focused on HRT systems, which inevitably incur utilization loss. Partitioning approaches have been proposed in \cite{baruah2004feasibility, baruah2011partitioned, baruah2005partitioned, funk2005task, funk2001line, liu2012power, andersson2010assigning} and quantitative approximation ratios have been derived for quantifying the quality of these approaches. Unfortunately, such partitioning approaches inherently suffer from bin-packing-related utilization loss, which may be significant in many cases. The feasibility problem of globally scheduling HRT sporadic task systems on a heterogeneous multiprocessor has also been studied \cite{baruah2004feasibility}. In \cite{cong2012energy}, a global scheduling algorithm has been implemented on Intel's QuickIA heterogeneous prototype platform and experimental studies showed that this approach is effective in improving the system energy efficiency.



The SRT scheduling problem on a heterogeneous multiprocessor has also been studied  \cite{leontyev2007tardiness}. A semi-partitioned approach has been proposed in \cite{leontyev2007tardiness}, where tasks are categorized as either ``fixed'' or ``intergroup'' and processors are partitioned into groups according to their speeds. Tasks belonging to the fixed category are only allowed to migrate among processors within in the task's assigned group. Only tasks belonging to the migrating category are allowed to migrate among groups. Although this approach is quite effective in many cases, it yields utilization loss and requires several restricted assumptions (e.g., the system contains at least 4 processors and each processor group contains at least two processors). Different from this work, our focus in this paper is on designing GEDF-based global schedulers that ensure no utilization loss under both preemptive and non-preemptive scheduling.



\paragraph{Contribution.} 
In this paper, we design and analyze a GEDF-based scheduling algorithm GEDF-H (GEDF for Heterogeneous multiprocessors) for supporting SRT sporadic task systems on a heterogeneous multiprocessor that contains processors with different speeds. The derived schedulability test shows that any sporadic task system is schedulable under both preemptive and non-preemptive GEDF-H scheduling with bounded response times if  and Eq.(1) hold, where  is the total task utilization,  is the total system capacity, and Eq.(1) is an enforced requirement on the relationship between task parameters and processor parameters. We show via a counterexample that task systems that violate Eq.(1) may have unbounded response time under any scheduling algorithm. As demonstrated by experiments, the response time bound achieved under GEDF-H is reasonably low, often within three task periods. Thus, GEDF-H is able to guarantee schedulability with no utilization loss while providing low predicted response time.



\paragraph{Organization.} This paper is organized as follows. In Sec.2, we describe the system model. Then in Sec.3, we describe GEDF-H. In Sec.4, we present our schedulability analysis for GEDF-H and derive the resulting schedulability test. In Sec.5, we show experimental results. We conclude in Sec.6



\section{System Model}
\label{sec:model}

In this paper, we consider the problem of scheduling  sporadic SRT tasks on  heterogeneous processors. Let set  denote the  independent sporadic tasks and  denotes the set of  heterogeneous processors.

Assume there are  kinds of processors distinguished by their speeds. Let   and  denote the subset of the th kind of processors in  and the number of processors in  respectively. Thus,  and . We assume the processors in  have unit speed and processors in  have speed  (i.e.). For clarity, we use  to denote the maximum speed (i.e., ). Let . 

We define the unit workload to be the amount of work done under the unit speed within a unit time. We assume that each job of  executes for at most  workload which needs  time units under the unit speed. The  job of , denoted , is released at time  and has an absolute deadline at time .  Each task  has a period , which specifies the minimum time between two consecutive job releases of , and a deadline , which specifies the relative deadline of each such job, i.e., . The utilization of a task  is defined as , and the utilization of the task system  as . An sporadic task system  is said to be an \textit{implicit-deadline} system if  holds for each . Due to space limitation, we limit attention to implicit-deadline sporadic task systems in this paper.



\normalsize


Successive jobs of the same task are required to execute in sequence. If a job  completes at time , then its \textit{response time} is . A task's response time is the maximum response time of any of its jobs. Note that, when a job of a task misses its deadline, the release time of the next job of that task is not altered. We require , and , for otherwise the response time may grow unboundedly. 







Under GEDF, released jobs are prioritized by their absolute deadlines. We assume that ties are broken by task ID (lower IDs are favored). Thus, two jobs cannot have the same priority. In this paper, we use continuous time system and parameters are positive rational numbers.  

On a heterogeneous multiprocessor, the response time can still grow unboundedly, even if  and  hold. This is illustrated by the following counterexample.   

\begin{figure}[t]
	\begin{center}
	\includegraphics[width=3in]{images/COUNTER.pdf} 
	\end{center} 
\vspace{-5mm}
\caption{\small GEDF schedule of the tasks in counterexample.}
\vspace{-5mm}
\label{fig:counter}
\end{figure}

\paragraph{Counterexample.} Consider a sporadic task system with two tasks  and a heterogeneous multiprocessor with  processors where  has a speed of  and other  processors have unit speed. For this system,  and . The ratio of  may approximate to 0 when  is arbitrarily large. However, as seen in the GEDF schedule illustrated in Fig.\ref{fig:counter}, regardless of the value we choose for , the response time of  still grows unboundedly. Actually, we analytically prove that this task system cannot be scheduled under any global or partitioned schedule algorithm. This counterexample implies that a task system may not be feasible on a heterogeneous multiprocessor even provided . As seen in Fig.\ref{fig:counter}, adding more unit speed processors  does not help either because there are two tasks with utilization greater than  while only one processor with speed greater than . Motivated by this observation, we enforce the following requirement.

Let , , and  be the number tasks in . Let . Let , ,  and  be the number of processor in . Thus,  is the set of tasks that would fail their deadlines if run entirely on a processor of type i or lower, and  is the set of processors of type i+1 or higher. For each , we require

Intuitively, Eq.(\ref{eq:Restriction}) requires that if we have  processors with speed , then at most  tasks with utilization 
can be supported in the system, which is also a reasonable requirement in practice. Note that, other than , we do not place any restriction on .

\paragraph{Example 1.} Consider a task system with 4 tasks , and a heterogeneous multiprocessor consisting of 3 processors with 2 kinds of speeds where , . For this task system,  and we have , ,  , , and . Thus, we have . This system clearly meets the requirement stated in Eq.(\ref{eq:Restriction}). 

\paragraph{Model explanation.}
\label{sec:explanation}

In a real-time system with  identical processors, it is known that response time bound can be guaranteed under GEDF if  \cite{Devi}.
For such homogeneous multiprocessor systems, the number of processors is often used to denote the total capacity. However, on a heterogeneous multiprocessor, the number of processors can no longer accurately represent the total capacity because processors have different speeds. With heterogeneous processors, we have two factors, the number of processors and the speed of each individual processor, that affect the total capacity. Thus, the total capacity of the system naturally is given by  as defined above. In other words, the total capacity is represented by the sum of the processor speeds.

Now let us consider the task model. In our model, the utilization  is a quantity of speed because  is a quantity of workload and  is a quantity of time. In fact, using such speed to denote the utilization is intuitive because in order to meet deadlines, any task  is expected to execute  units workload within  time units. Hence,  represents that total speed required by the task system. 


\section{A GEDF-based Scheduling Algorithm for Heterogeneous Multiprocessor}
\label{sec:GEDF-H}
On a homogeneous multiprocessor, at any time instant, under GEDF,  when we assign  () of the  tasks to be executed on  processors, we can arbitrarily choose processors for tasks because processors have the same speed. However, on a heterogeneous multiprocessor, if we arbitrarily choose processors for tasks, the bounded response time cannot be guaranteed as discussed in Sec.1. Motivated by this key observation, we design a GEDF-based scheduling algorithm  GEDF-H to support SRT sporadic task systems on a heterogeneous multiprocessor. GEDF-H enforces the following specific processor selection rule.

\paragraph{GEDF-H description} At any time instant  under GEDF-H, when trying to assign a job (i.e.,  is among the  highest-priority jobs at ) to an available processor, we consider two cases. \textbf{Case 1.} If , we assign  to an arbitrary available processor. \textbf{Case 2.} . In this case, for some , . If there is an available processor  in , we assign  to . Otherwise, by Eq. (1), there must exist at least one task  with utilization  that has a job  executing on processor  in  at instant . We know that, at least one processor is available at  (since  has not been assigned yet). Then, we move job  to any available processor and assign  to . Note that, GEDF-H is still a job-level static-priority scheduler because we do not change a job's priority at runtime. GEDF-H gives us the following property.

\vspace{-1mm}
\begin{changemargin}{4mm}{4mm}
\textbf{(P0)} At any time instant , if a job  of task  is executing on a processor  with speed , we have . Let  be the slowest speed of processors on which jobs of  could execute under GEDF-H, which implies that  if . Thus, by GEDF-H, we have

\end{changemargin}
\vspace{-1mm}

\begin{figure}[t]
	\begin{center}
	\includegraphics[width=3in]{images/GEDFH.pdf} 
	\end{center} 
\vspace{-5mm}
\caption{\small GEDF-H schedule of the tasks in example 1.}
\vspace{-5mm}
\label{fig:GEDFH}
\end{figure}

Fig.\ref{fig:GEDFH} shows the GEDF-H schedule of the task system in example  in time interval . At time instant 1, under GEDF-H we move  from  to  in order to execute  on . 

Next, we derive a schedulability test for preemptive GEDF-H. For conciseness, we use GEDF-H to represent the preemptive scheduler in the following sections. Due to space constraints and the fact that the analysis for non-preemptive GEDF-H (NP-GEDF-H) is similar, we only provide a proof sketch for analyzing schedulability under NP-GEDF-H in an appendix.

\section{Schedulability Analysis for GEDF-H}
\label{sec:EDF}

We now present our preemptive GEDF-H schedulability analysis. Our analysis draws inspiration from the seminal work of Devi \cite{Devi}, and follows the same general framework. Here are the essential steps.

Let  be a job of task  in , , and  be a GEDF-H schedule for  with the following assumption.

\vspace{1.5mm}
\textbf{(A)} The response time of every job , where  has higher priority than , is at most  in , where .
\vspace{1.5mm}

Our objective is to find out that under which condition we could determine an  such that the response time of  is at most . If we can find such , by induction, this implies a response time of at most  for all jobs of every task , where . We assume that  finishes after , for otherwise, its response time is trivially equals to its period. The steps for determining the value for  are as follows.
\vspace{-1.5mm}
\begin{enumerate}
\item
Determine a lower bound on the amount of work pending for tasks in  that can compete with  after , required for the response time of  to exceed . This is dealt with in Lemma~\ref{lower_bound} in Sec.~\ref{sec:lower_bound}.
\item \vspace{-1.5mm}
Determine an upper bound on the work pending for tasks in  that can compete with  after . This is dealt with in Lemmas~\ref{lemma:Upper_lemma1} and \ref{lemma:Upper_lemma2} in Sec.~\ref{sec:upper_bound}.
\item \vspace{-1.5mm}
Determine the smallest  such that the response time of  is at most , using the above lower and upper bounds. This is dealt with in Theorem~\ref{theorem:SRTtest} in Sec.~\ref{sec:x}.
\end{enumerate} 
\vspace{-2.5mm}
\begin{definition}
\label{def:active}
A task  is \textit{active} at time  if there exists a job  such that .
\end{definition}

\begin{definition}
\label{def:enabled}
A job is considered to be \textit{completed} if it has finished its execution. We let  denote the completion time of job . Job  is \textit{tardy} if it completes after its deadline.
\end{definition}

\begin{definition}
\label{def:pending}
 Job  is \textit{pending} at time  if . Job  is \textit{enabled} at  if , and its predecessor (if any) has completed by .  \end{definition}





\begin{definition}
\label{preemption} If an enabled job  dose not execute at time , then it is \textit{preempted} at . 
\end{definition}

\begin{definition}
\label{def:d}
We categorize jobs based on the relationship between their priorities and those of :
\begin{center}
.
\end{center}
\end{definition}
Thus, \textbf{d} is the set of jobs with priority no less than that of , including .
\begin{definition}
\label{def:PS}
For any given sporadic task system , a \textit{processor share} (PS) schedule is an ideal schedule where each task  executes with a speed equal to  when it is active (which ensures that each of its jobs completes exactly at its deadline). A valid PS schedule exists for  if  holds. 

Fig.~\ref{fig:PSschedule} shows the PS schedule of the tasks in Example 1. Note that the PS schedules on a homogeneous multiprocessor and a heterogeneous multiprocessor are identical.
\end{definition}

\begin{figure}[t]
	\begin{center}
	\includegraphics[width=3in]{images/ps.pdf} 
	\end{center} 
\vspace{-5mm}
\caption{\small PS schedule of the tasks in example 1.}
\vspace{-5mm}
\label{fig:PSschedule}
\end{figure}


By Def.~\ref{def:d},  is in . Also jobs not in  have lower priority than those in  and thus do not affect the scheduling of jobs in . For simplicity, in the rest of the paper, we only consider jobs in  in either the GEDF-H schedule  or the corresponding PS schedule.

Our schedulability test is obtained by comparing the allocations to  in the GEDF schedule  and the corresponding PS schedule, both on  processors, and quantifying the difference between the two. We analyze task allocations task by task. Let  denote the total workload allocation to job  in  in . Then, the total workload done by all jobs of  in  in  is given by 



Let \textit{PS} denote the PS schedule that corresponds to the GEDF-H schedule  (i.e., the total allocation to any job of any task in \textit{PS} is identical to the total allocation of the job in ). 

The difference between the allocation to a job  up to time  in \textit{PS} and , denoted \textit{the lag of job  at time  in schedule }, is defined by

Similarly, the difference between the allocation to a task  up to time  in  \textit{PS} and , denoted \textit{the lag of task  at time  in schedule }, is defined by\small

\normalsize

The \textit{LAG} for  at time  in schedule  is defined as






\begin{definition}
A time instant  is \textit{busy} (resp. \textit{non-busy}) for a job set  if there exists (resp. does not exist) an  that all  processors execute jobs in  during . A time interval  is \textit{busy} (resp. \textit{non-busy}) for  if each (resp. \textit{not all}) instant within  is busy for . \end{definition}

The following properties follows from the definitions above.

\begin{changemargin}{4mm}{4mm}
\textbf{(P1)} If , where , then ) is non-busy for . In other words, \textit{LAG} for  can increase only throughout a non-busy interval for  . 
\end{changemargin}



\begin{changemargin}{4mm}{4mm}
\textbf{(P2)} At any non-busy time instant , at most  tasks can have pending jobs at , for otherwise  would have to become busy. 
\end{changemargin}







\subsection{Lower Bound}
\label{sec:lower_bound}

Lemma~\ref{lower_bound} below provides the lower bound on .





\begin{lemma}
\label{lower_bound}
If  and Assumption \textbf{(A)} holds, then the response time of  is at most ,
\end{lemma}
\begin{proof}
Let  be the amount of work  performs by time  in , . Define  as follows.


We consider two cases.

\vspace{1mm}
\textbf{Case 1.} \textit{ is a busy interval for} . In this case, the amount of work completed in  is exactly , as illustrated in Fig.4. Hence, the amount of work pending at  is at most . This remaining work will be completed(even on a slowest processor), no later than . Since this remaining work includes the work due for ,  thus completes by . The response time of  is thus not more than . 

\begin{figure}[t]
	\begin{center}
	\includegraphics[width=3in]{images/busy.pdf} 
	\end{center} 
\vspace{-2mm}
\caption{\small  is a busy interval.}
\vspace{-2mm}
\label{fig:busy}
\end{figure}



\vspace{1mm}
\textbf{Case 2.} \textit{ is a non-busy interval for} . Let  be the earliest non-busy instant in ), as illustrated in Fig.5. By Property \textbf{(P2)}, at most  tasks can have pending jobs in  at . Moreover, since no jobs in  can be released after , we have
\vspace{-3mm}
\begin{changemargin}{8mm}{8mm}
\textbf{(P3)} At most  tasks have pending jobs  in  at or after . This implies no job would be preempted at or after .
\end{changemargin}\vspace{-3mm}

\noindent If  is executing at , then, by property \textbf{(P3)} and \textbf{(P0)}, we have




Thus, the response time of  is not more than .

Else,  is not executing at  and , which means the predecessor job  has not completed by . Because  = , by Assumption \textbf{(A)}, . Thus, combined with property \textbf{(P3)} and \textbf{(P0)}, . The response time of  is thus not more than . \qedhere


\begin{figure}[t]
	\begin{center}
	\includegraphics[width=3in]{images/nonbusy.pdf} 
	\end{center} 
\vspace{-2mm}
\caption{\small  is a non-busy interval.}
\vspace{-2mm}
\label{fig:nonbusy}
\end{figure}

\end{proof}

























\subsection{Upper Bound}
\label{sec:upper_bound}

In this section, we determine an upper bound on .

\begin{definition}
Let  be the latest non-busy instant by  for \textbf{d}, if any; otherwise, .
\end{definition}

By the above definition and Property \textbf{(P1)}, we have 


\begin{lemma}
\label{lemma:Upper_lemma1}
For any task , if  has pending jobs at  in the schedule , then we have
\small
 \normalsize
where  is the deadline of the earliest released pending job of , , at time  in . 
\end{lemma}

\begin{proof}
Let be the amount of work  performs before .

By the selection of , we have . By the definition, . Thus,


By the definition of , , and . By the selection of , , and . By setting these values into (\ref{summinglemma2}), we have


There are two cases to consider.

\vspace{1mm}
\textbf{Case 1.} .
In this case, (\ref{lemma3case1-}) implies .

\vspace{2mm}
\textbf{Case 2.} . In this case, because  and ,  is not the job . Thus, by Assumption \textbf{(A)},  has a response time of at most . Since  is the earliest pending job of  at time , the earliest possible completion time of  is at  (executed on the fastest processor). Thus, we have , which gives . Setting this value into (\ref{lemma3case1-}), we have .
\end{proof}

\begin{definition}
\label{def:UE}
Let  be the sum of the  largest  values among tasks in . Let  be the largest value of the expression , where  denotes any set of  tasks in  and  denotes the set of speeds of  processors that are the  fastest processors in the system.
\end{definition}

Lemma~\ref{lemma:Upper_lemma2} below upper bounds .

\begin{lemma}
\label{lemma:Upper_lemma2}
With the Assumption \textbf{(A)}, .
\end{lemma}
\begin{proof}

By (\ref{eq:LAGincrease}), we have . By summing individual task lags at , we can bound . If , then , so assume .


Given that the instant  is non-busy, by Property \textbf{(P2)}, at most  tasks can have pending jobs at . Let  denote the set of such tasks. Therefore, by Eq.~(\ref{eq:LAGincrease}), we have


Since two jobs cannot be executed on the same processor at any time instant,  reaches its maximal value when the   tasks in  execute on the  fastest processors. Thus, \\

\end{proof}












\subsection{Determining }
\label{sec:x}

Setting the upper bound on  in Lemma~\ref{lemma:Upper_lemma2} to be at most the lower bound in Lemma~\ref{lower_bound} will ensure that the response time of  is at most . The resulting inequality can be used to determine a value for . By Lemmas~\ref{lower_bound} and \ref{lemma:Upper_lemma2}, this inequality is . Solving for , to make a  valid for all tasks, we have 
 \vspace{-1mm}
By  and Defs.\ref{def:UE},  clearly holds. Let
 \vspace{-1mm} 
then the response time of  will not exceed  in . 



By the above discussion, the theorem below follows.


\begin{theorem}
\label{theorem:SRTtest}
With  as defined in (\ref{xvalue}), the response time of any task  scheduled under GEDF-H is at most , provided .
\end{theorem}






\section{Experiment}
\label{sec:Experiment}

Although GEDF-H ensures SRT schedulability with no utilization loss, the magnitude of the resulting response time bound is also important. In this section, we describe experiments conducted using randomly-generated task sets to evaluate the applicability of the response time bound given in Theorem~\ref{theorem:SRTtest}. Our goal is to examine how large the magnitude of response time is.

\paragraph{Experimental setup.} We simulate the Intel's QuickIA heterogeneous prototype platform \cite{chitlur2012quickia} in our experiments. The QuickIA platform contains two kinds of processors and each kind contains two processors. We assume that two of the processors  and  have unit speed and the other two processors  and  have two-unit speed, i.e.,  and . The unit time is assumed to be .



By the definitions of  and , we have , , , . We generated tasks as follows. Task periods were uniformly distributed over . First, we generated tasks in . According to Eq.~\ref{eq:Restriction},   and the utilization of tasks in  is at most . We thus first randomly generated the number of tasks in  from  to , and task utilizations were generated using the uniform distribution . Task execution costs were calculated from periods and utilizations. Then, we generated tasks in . The utilization of tasks in  is not more than . These task utilizations were generated using three uniform distributions(light), (medium) and (heavy). For each experiment, 10,000 task sets were generated. Each such task set was generated by creating tasks until total utilization exceeded , and by then reducing the last task's utilization so that the total utilization equaled .

\begin{figure*}[!ht]
  \centering
  \subfloat[Heavy task utilization]{\label{fig:2}\includegraphics[width=0.47\textwidth]{images/f5heavy.pdf}} \hspace{3mm}
  \subfloat[Period = 100]{\label{fig:3}\includegraphics[width=0.47\textwidth]{images/f6p100.pdf}}\\
  \vspace{-2mm}
  \subfloat[Medium task utilization]{\label{fig:4}\includegraphics[width=0.47\textwidth]{images/f5medium.pdf}}  \hspace{3mm}           
  \subfloat[Period = 300]{\label{fig:6}\includegraphics[width=0.47\textwidth]{images/f6p300.pdf}}\\
  \vspace{-2mm}  \subfloat[Light task utilization]{\label{fig:7}\includegraphics[width=0.47\textwidth]{images/f5light.pdf}} \hspace{3mm}          
  \subfloat[Period = 600]{\label{fig:9}\includegraphics[width=0.47\textwidth]{images/f6p600.pdf}}
  \caption{\small Response time bounds. In all six graphs, the -axis denotes the response time bound value. Each graph gives three curves plotting the maximum, average, and minimum response time bound among tasks, respectively. In the first column of graphs, the -axis denotes the task periods. Light, medium, and heavy task utilizations are assumed in insets (a), (c), and (e), respectively. In the second column of graphs, the -axis denotes the average task utilization of the generated task system. Three specific period values, 100ms, 300ms, and 600ms, are assumed in insets (b), (d), and (f), respectively. Note that the average task utilization is at most 1 in these experiments. This is because according to our task generation strategy, the number of tasks with utilization no greater than 1 is much larger than the number of tasks with utilizations greater than 1.
  } \vspace{-2mm} \normalsize
  \label{fig:exp}
\end{figure*} 

\paragraph{Results.} The obtained results are shown in Fig.~\ref{fig:exp} (the organization of which is explained in the figure's caption). Each graph in Fig.~\ref{fig:exp} contains three curses, which plots the calculated maximum response time bound, average response time bound, and minimum response time bound among all tasks in the system, respectively. As seen in Figs.\ref{fig:exp}(a), (c), and (e), in all tested scenarios, the maximum response time bound is smaller than five task periods, while the average response time bound is slightly larger than three task periods (but smaller than four task periods). One observation herein is that when task utilizations become heavier, the response time bounds increase. This is intuitive because the denominator of Eq.~(\ref{xvalue}) becomes smaller when task utilizations are heavier. Moreover, as seen in Figs.~\ref{fig:exp}(b), (d), and (f), the response time bounds under GEDF-H  slightly increase along with the increase of the average task utilization of the system, under three fixed task period scenarios. Under these scenarios, the maximum response time bound is within three task periods and the average response time bound is within two task periods. To conclude, GEDF-H not only guarantees SRT schedulability with no utilization loss, but can provide such a guarantee with low predicted response time.




\section{Conclusion}
\label{sec:Conclusion}
We have shown that SRT sporadic task systems can be supported under GEDF-H on a heterogeneous multiprocessor with no utilization loss provided bounded response time is acceptable. GEDF-H is identical to GEDF except that it enforces a specific processor selection rule. As demonstrated by experiments presented herein, GEDF-H is able to guarantee schedulability with no utilization loss while providing low predicted response time. For the future work, we plan to design better algorithm that can reduce the job migration cost. Compared to GEDF, GEDF-H may incur more job migrations among processors due to the specific processor selection rule. Also it would be interesting to extent this work to hard-real systems and self-suspending task systems.


\begin{spacing}{0.1}
\bibliographystyle{plain} 
\bibliography{SRTHet}
\end{spacing}

\vspace{-1mm}
\section*{Appendix: Schedulability Analysis for NP-GEDF-H}
\label{sec:NP-EDF}

We now present our non-preemptive GEDF-H (NP-GEDF-H) schedulability analysis. Due to space constrains, we only provide the sketch of the proof.

\begin{definition}
\label{def:block job*}
For any time instant , if there exists an  such that during interval  there is an enabled job  in \textbf{d} is not executing while any job  not in \textbf{d} is executing on some processor during this interval, we say  is blocked by  at time .  is a blocked job;  is a blocking job.  is a blocking instant.
\end{definition}

\begin{definition}
\label{def:block interval*}
An interval  is a blocking interval if every instant in it is a blocking instant. A blocking interval is said to be a maximal blocking interval if for any ,  cannot be a blocking interval.
\end{definition}
 
\begin{definition}
\label{def:BIG B*}
Let  denote the set of jobs not in \textbf{d} that block one or more jobs in \textbf{d} at some instants before  and may continue to execute at  under NP-GEDF-H. Let  denote the total workload pending for jobs in  at . 
\end{definition}

\paragraph{Response time bound under NP-GEDF-H.} In the analysis of GEDF-H scheduling, only the workload pending for jobs in \textbf{d} can compete with . However, under NP-GEDF-H, jobs not in \textbf{d} are still able to compete with . Even though such jobs have lower priority, they cannot be preempted once they start execution before . Hence, the pending workload from blocking jobs should be taken into consideration. After accurately defining the pending work, we are able to follow the similar analysis for NP-GEDF-H. We make the following similar assumption.

\textbf{(A-NP)} The response time of every job , where  has higher priority than , is at most  in , where .

By the discussion above, the total pending work is presented by 
 \vspace{-1mm}
To derive the lower bound of , we have following parallel Lemma \ref{lemma:NP-Lower_lemma} for NP-EDFH. The proof is the same to the proof of Lemma \ref{lower_bound}

\begin{lemma}
\label{lemma:NP-Lower_lemma}
If  and the Assumption \textbf{(A-NP)} holds, then the response time of  is at most ,
\end{lemma}


To derive the upper bound of , we have the following parallel Lemma \ref{lemma:NP-upper_lemma} for NP-GEDF-H. The proof is slightly different from the proof of Lemma \ref{lemma:Upper_lemma2}. Let  be the largest value of the expression , where  denotes any set of  tasks in ,  denotes the set of speed of  processors those are the most  fastest,  is the execution of any  not in .

\begin{lemma}
\label{lemma:NP-upper_lemma}
With Assumption \textbf{(A-NP)}, . 
\end{lemma}
\begin{proof}
Let  be the latest non-busy instant before . For NP-GEDF-H, we consider following two cases. \textbf{Case 1.}  is not a blocking instant, we are able to do the analysis similar to Lemma 2. \textbf{Case 2.}  is a blocking instant. Let  be the maximal blocking interval. And we first derive the upper bound for ; then extend it to .
\end{proof}


\vspace{-1mm}
By the Lemma \ref{lemma:NP-Lower_lemma} and \ref{lemma:NP-upper_lemma}, the theorem below immediately follows.
\vspace{-1mm}

\begin{theorem}
\label{theorem:NPSRTtest}
With , the response time of any task  scheduled under NP-GEDF-H is at most , provided .
\end{theorem}

\end{document}
