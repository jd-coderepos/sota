\documentclass{article}



\usepackage{iclr2017_conference,times}
\iclrfinalcopy
\PassOptionsToPackage{numbers,comma,square}{natbib}



\usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}    \usepackage[bookmarks=false]{hyperref}       \usepackage{url}            \usepackage{booktabs}       \usepackage{amsfonts}       \usepackage{nicefrac}       \usepackage{microtype}      

\usepackage{graphicx}
\usepackage{caption}
\usepackage{url}
\usepackage{subfigure}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{colortbl}
\usepackage{booktabs}
\usepackage{stmaryrd}
\usepackage{float}
\usepackage{dsfont} \usepackage{upgreek} \usepackage[raggedright]{titlesec}
\usepackage{tabularx}
\usepackage{lipsum}
\renewcommand{\bibfont}{\small}
\bibpunct{[}{]}{,}{n}{,}{,}
\usepackage{adjustbox}
\usepackage{wrapfig}
\renewcommand{\topfraction}{0.99}
\renewcommand{\textfraction}{0.01}
\renewcommand{\bottomfraction}{0.99}
\renewcommand{\floatpagefraction}{0.99}

\usepackage{xcolor}
\definecolor{darkgreen}{rgb}{0,0.6,0}
\newcommand{\jcom}[1]{\textcolor{darkgreen}{[jascha: #1]}}
\newcommand{\ldcom}[1]{\textcolor{blue}{[laurent: #1]}}
\newcommand{\sbcom}[1]{\textcolor{red}{[samy: #1]}}
\newcommand{\mb}{\mathbf}


\setlength{\textfloatsep}{5pt}
\setlength{\intextsep}{5pt}


\DeclareMathOperator{\Span} {{Span}}
\DeclareMathOperator{\gap} {{gap}}
\DeclareMathOperator{\ddiv} {{div}}
\DeclareMathOperator{\argsup} {{argsup}}
\DeclareMathOperator{\dom} {{dom}}
\DeclareMathOperator{\diag} {diag}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator{\epi} {{epi}}
\DeclareMathOperator*{\sinc}{sinc}
\DeclareMathOperator*{\sincd}{sincd_N}
\DeclareMathOperator*{\Supp}{Supp}
\DeclareMathOperator{\Tr}{Tr}
\DeclareMathOperator{\Median}{Median}
\renewcommand{\cite}[1]{\citep{#1}}
\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\mat}[1]{\mathbf{#1}}
\newcommand{\T}[0]{\mathsf{T}}
\newcounter{lastromanpg}
\def\debutchapitres{\clearpage \setcounter{lastromanpg}{\value{page}}
          \pagenumbering{arabic}}


\def\E{{\mathbb{E}}}
\DeclareMathOperator{\Expct}{\E}
\def\Id{{\mathbb{I}}}
\def\R{{\mathbb{R}}}
\def\Pr{{\mathbb{P}}}
\def\Q{{\mathbb{Q}}}
\def\Nint{{\mathbb{N}}}
\def\B{{\mathcal{B}}}
\def\D{{\mathcal{D}}}
\def\H{{\mathcal{H}}}
\def\X{{\mathcal{X}}}
\def\Y{{\mathcal{Y}}}
\def\F{{\mathcal{F}}}
\def\M{{\mathcal{M}}}
\def\indic{{\mathbbm{1}}}
\def\N{{\mathcal{N}}}
\def\L{{\mathcal{L}}}
\def\U{{\mathcal{U}}}
\def\Z{{\mathcal{Z}}}
\def\Hlat{{\mathcal{H}}}



\title{Density estimation using Real NVP}



\author{
  Laurent Dinh\thanks{Work was done when author was at Google Brain.} \\
  Montreal Institute for Learning Algorithms\\
  University of Montreal\\
  Montreal, QC H3T1J4\\
  \AND
  Jascha Sohl-Dickstein\\
  Google Brain \\
  \And
  Samy Bengio\\
  Google Brain \\
}

\begin{document}


\maketitle

\begin{abstract}
Unsupervised learning of probabilistic models is a central yet challenging problem in machine learning.
Specifically, designing models with tractable learning, sampling,
  inference and evaluation is crucial in solving this task. We extend the space
  of such models using real-valued non-volume preserving (real NVP)
  transformations, a set of powerful, stably invertible, and learnable transformations,
  resulting in an unsupervised learning algorithm with exact log-likelihood computation,
  exact and efficient sampling, exact and efficient inference of latent variables,
  and an interpretable latent space. We
  demonstrate its ability to model natural images on four datasets through
  sampling, log-likelihood evaluation, and latent variable
  manipulations.
\end{abstract}
\section{Introduction}
The domain of representation learning has undergone tremendous advances due to improved supervised learning techniques. However, unsupervised learning has the potential to leverage large pools of unlabeled data, and extend these advances to modalities that are otherwise impractical or impossible.

One principled approach to unsupervised learning is generative probabilistic modeling. Not only do generative probabilistic models have the ability to create novel content, they also have a wide range of reconstruction related applications including inpainting \citep{theis2015generative, oord2016pixel, DBLP:conf/icml/Sohl-DicksteinW15}, denoising \citep{balle2015density}, colorization \citep{zhang2016colorful}, and super-resolution \citep{bruna2015super}.

As data of interest are generally high-dimensional and highly structured, the challenge in this domain is building models that are powerful enough to capture its complexity yet still trainable.
We address this challenge by introducing \emph{real-valued non-volume preserving (real NVP) transformations}, a tractable yet expressive approach to modeling high-dimensional data.

This model can perform {\em efficient and exact} inference, sampling and log-density estimation of data points. Moreover, the architecture presented in this paper enables {\em exact and efficient} reconstruction of input images from the hierarchical features extracted by this model.






\section{Related work}
\begin{figure}
\begin{center}
{\renewcommand{\arraystretch}{2}
\begin{tabular}{m{1.25in}ccc}
& Data space  & & Latent space 
\\
\parbox{1.25in}{
\textbf{Inference}

}
&
\raisebox{-.43\height}{
\includegraphics[width=1.5in]{example_x.pdf}
}
&
\parbox{.25in}{

}
&
\raisebox{-.43\height}{
\includegraphics[width=1.5in]{example_z.pdf}
}
\
p_{X}(x) = p_{Z}(z) \left\vert \det\left(\frac{\partial g(z)}{\partial z^T}\right)\right\vert^{-1}
.

p_{X}(x) &= p_{Z}\big(f(x)\big) \left|\det\left(\cfrac{\partial f(x)}{\partial x^T} \right)\right|
\label{eq:change-variables}\\
\log\left(p_{X}(x)\right) &= \log\Big(p_{Z}\big(f(x)\big)\Big) + \log\left(\left|\det\left(\frac{\partial f(x)}{\partial x^T}\right)\right|\right)
,

y_{1:d} &= x_{1:d}\\
y_{d+1:D} &= x_{d+1:D} \odot \exp\big(s(x_{1:d})\big) + t(x_{1:d})
,

\frac{\partial y}{\partial x^T} = \left[\begin{array}{cc}
\Id_{d} & 0 \\
\frac{\partial y_{d+1:D}}{\partial x_{1:d}^T} & \diag\big(\exp\left[s\left(x_{1:d}\right)\right]\big)
\end{array} \right]
,

\begin{cases}
y_{1:d} &= x_{1:d} \\
y_{d+1:D} &= x_{d+1:D} \odot \exp\big(s(x_{1:d})\big) + t(x_{1:d})
\end{cases}\\
\Leftrightarrow
\begin{cases}
x_{1:d} &= y_{1:d} \\
x_{d+1:D} &= \big(y_{d+1:D} - t(y_{1:d})\big) \odot \exp\big(-s(y_{1:d})\big),
\end{cases}

y = b \odot x + (1 - b) \odot \Big(x \odot \exp\big(s(b \odot x)\big) + t(b \odot x)\Big)
.

\cfrac{\partial (f_{b} \circ f_{a})}{\partial x_{a}^{T}}(x_{a}) &= \cfrac{\partial f_{a}}{\partial x_{a}^{T}}(x_{a}) \cdot \cfrac{\partial f_{b}}{\partial x_{b}^{T}}\big(x_{b}=f_{a}(x_{a})\big) \\
\det(A \cdot B) &= \det(A) \det(B).

(f_{b} \circ f_{a})^{-1} = f_{a}^{-1} \circ f_{b}^{-1}.

h^{(0)} &= x \\
(z^{(i + 1)}, h^{(i + 1)}) &= f^{(i + 1)}(h^{(i)})
\label{eq:factor_out} \\
z^{(L)} &= f^{(L)}(h^{(L - 1)})
\label{eq:final_factor}\\
z &= (z^{(1)}, \dots, z^{(L)})
\label{eq:concat_factors}
.

x \mapsto \frac{x - \tilde{\mu}}{\sqrt{\tilde{\sigma}^{2} + \epsilon}}

\left(\prod_{i}{(\tilde{\sigma}_{i}^{2} + \epsilon)}\right)^{-\frac{1}{2}}.

z = \cos(\phi) \left(\cos(\phi') z_{(1)} + \sin(\phi') z_{(2)}\right) + \sin(\phi) \left(\cos(\phi') z_{(3)} + \sin(\phi') z_{(4)}\right)
.
\label{eq:manifold}

\tilde{\mu}_{t+1} &= \rho \tilde{\mu}_{t} + (1 - \rho) \hat{\mu}_{t} \\
\tilde{\sigma}^2_{t+1} &= \rho \tilde{\sigma}^2_{t} + (1 - \rho) \hat{\sigma}^2_{t},

where  is the momentum.
When using , we only propagate gradient through the current batch statistics . We observe that using this lag helps the model train with very small minibatches.

We used batch normalization with a moving average for our results on CIFAR-10.

\section{Attribute change}\label{app attr change}
Additionally, we exploit the attribute information  in CelebA to build a conditional model, i.e. the invertible function  from image to latent variable uses the labels in  to define its parameters. In order to observe the information stored in the latent variables, we choose to encode a batch of images  with their original attribute  and decode them using a new set of attributes , build by shuffling the original attributes inside the batch. We obtain the new images .

We observe that, although the faces are changed as to respect the new attributes, several properties remain unchanged like position and background.

\begin{figure}[H]
\vspace{80pt}
    \centering \includegraphics[width=1.\textwidth]{celebattr_examples.png}
    \caption{Examples  from the \emph{CelebA} dataset.}
    \label{fig:transfer-original}
\end{figure}

\begin{figure}[H]
\vspace{80pt}
    \centering \includegraphics[width=1.\textwidth]{celebattr_transfer.png}
    \caption{From a model trained on pairs of images and attributes from the \emph{CelebA} dataset, we encode a batch of images with their original attributes before decoding them with a new set of attributes. We notice that the new images often share similar characteristics with those in Fig \ref{fig:transfer-original}, including position and background.}
\end{figure}
\fi
\end{document}
