\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{wacv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}



\newcommand{\argmax}{\mathop{\rm arg~max}\limits}
\newcommand{\argmin}{\mathop{\rm arg~min}\limits}
\newcommand{\org}[1]{{\color{green}#1}}
\newcommand{\oha}[1]{{\color{red}#1}}
\newcommand{\sinha}[1]{{\color{black}#1}}
\newcommand{\remove}[1]{{\color{magenta}#1}}




\def\wacvPaperID{320} 



\wacvfinalcopy 







\ifwacvfinal
\usepackage[breaklinks=true,bookmarks=false]{hyperref}
\else
\usepackage[pagebackref=true,breaklinks=true,colorlinks,bookmarks=false]{hyperref}
\fi

\pagestyle{empty}

\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}


\begin{document}

\title{Difficulty-Net: Learning to Predict Difficulty for Long-Tailed Recognition}

\author{Saptarshi Sinha\\
Hitachi Ltd.\\
Tokyo, Japan\\
{\tt\small saptarshi.sinha.hx@hitachi.com}
\and
Hiroki Ohashi\\
Hitachi Ltd.\\
Tokyo, Japan\\
{\tt\small hiroki.ohashi.uo@hitachi.com}
}

\maketitle
\thispagestyle{empty}

\begin{abstract}
   Long-tailed datasets, where head classes comprise much more training samples than tail classes, cause recognition models to get biased towards the head classes. 
Weighted loss is one of the most popular ways of mitigating this issue, and a recent work has suggested that class-difficulty might be a better clue than conventionally used class-frequency to decide the distribution of weights.
   A heuristic formulation was used in the previous work for quantifying the difficulty, but we empirically find that the optimal formulation varies depending on the characteristics of datasets.
   Therefore, we propose Difficulty-Net, which learns to predict the difficulty of classes using the model's performance in a meta-learning framework.
To make it learn reasonable difficulty of a class within the context of other classes, we newly introduce two key concepts, namely the relative difficulty and the driver loss. 
   The former helps Difficulty-Net take other classes into account when calculating difficulty of a class, while the latter is indispensable for guiding the learning to a meaningful direction.
   Extensive experiments on popular long-tailed datasets demonstrated the effectiveness of the proposed method, and it achieved state-of-the-art performance on multiple long-tailed datasets.
\end{abstract}

\section{Introduction}\label{sec:intro}

Despite the outstanding performance of the recent deep learning (DL) models on public datasets, deploying such models in the real world often leads to a performance drop. 
One of the causes is that the public datasets are usually almost perfectly class-balanced while real-world data are generally long-tailed, where a few classes (called \textit{head classes}) consist of a significantly larger number of training samples than the rest of the classes (called \textit{tail classes}).
The `long-tailed recognition' research domain particularly aims at addressing this issue.


\begin{figure}[t]
  \centering
\includegraphics[width=\linewidth]{Modified_fig1_2.eps}
  \caption{Different quantifications of class-difficulties perform better than others in different situations (imbalance ratios). The imbalance in the data is  calculated as the ratio of the frequency of the most frequent class to that of the least frequent class.
 We compute class-wise difficulty () using four different functions of class-wise accuracy () for the CDB-CE~\cite{cdb-ce} loss function and compare their performance on the CIFAR100-LT. 
 Interestingly, 
the alternate formulations work better than the originally proposed one () in many cases.
However, the best performing function changes with the imbalance values. This brings us to the question ``Which formulation to choose for my imbalanced dataset?" 
}
  \label{fig:class-wise difficulty}
\end{figure}

Amongst multiple possible strategies to tackle long-tailed recognition problems, cost-sensitive learning is one of the most popular and promising strategies.
Most cost-sensitive learning techniques modify the cost function to penalize the model differently for different samples. 
This modification is generally done by scaling the cost value using different weights, and the research direction is mainly aimed at finding an effective weight-assignment strategy. 
One simple and intuitive way is to assign weights using the inverse of the class-frequencies. 
Recently, more sophisticated approaches such as class-balanced loss~\cite{classbalancedloss} and equalization loss~\cite{eqlloss} have been proposed.
However, most of these approaches give more weights to the tail classes because they assume that tail classes are always the most difficult to learn. 
\sinha{Recently Sinha \etal~\cite{cdb-ce,sinha_ijcv}} empirically showed that the above assumption does not always hold true and further claimed that class-difficulty might be a better clue to decide weights. 

While they proposed an intuitive quantification of the class-level difficulties, 
this quantification is preliminarily determined regardless of the property of a given dataset, and thus may not be optimal in different situations.
In fact, we empirically found that multiple quantifications for class-wise difficulty gave comparable or even better results than~\cite{cdb-ce} as shown in Figure~\ref{fig:class-wise difficulty}. 
This adds the extra tedious task of selecting the appropriate formulation for a given imbalanced data. 


Motivated by recently proposed Meta-Weight-Net (MWN)~\cite{meta-weight-net}, our research aims to address the above issue by meta-learning a simple model, named Difficulty-Net, to predict class-level difficulty scores and then dynamically distribute the weights based on the scores.
Such a strategy removes dependence on any prior formulation for class-wise difficulty and lets the model learn any suitable function to compute it.
The key difference with MWN is three folds.
First, while MWN is a sample-level weighting method, ours is a class-level weighted approach, whose advantage in long-tailed recognition has been revealed in~\cite{cdb-ce} and also discussed in Sec.~\ref{sec: diff from mwn and cdb-ce} and Sec.~\ref{sec:ablation}. 
Second, we propose to use relative difficulties rather than absolute difficulties that are used in prior works~\cite{meta-weight-net,cdb-ce} so that the other classes' difficulties are also taken into account when determining the difficulty of a class.
Third, we propose a new loss function that drives the learning process of Difficulty-Net in a reasonable direction, without which the performance turned out to degrade.





To summarize, our key contributions are:
\vspace{-5pt}
\begin{itemize}\itemsep0em
    \item We propose Difficulty-Net, which learns to predict class-difficulty in a meta-learning framework.
    \item We argue that relative difficulty is more important and effective than absolute difficulty, and provide an empirical evidence for the argument.
    \item We propose a new loss function, called driver loss, that guides the learning process in a reasonable direction.
\item We conducted extensive experiments on multiple long-tail benchmark datasets and achieved state-of-the-art results. In addition, we provide in-depth analysis on the effect and property of the proposed method in comparison to previous works, which revealed the effectiveness of our method.
\end{itemize}




\section{Related works}\label{sec:related works}


Major strategies to tackle the long-tailed recognition can be broadly categorized as 
\sinha{data re-sampling methods~\cite{smote,borderline-smote,classbalancedsampling_1,oversampling_1,undersampling_1,sinha_ijcv}}, 
metric learning~\cite{tripletloss,contrastivelearning,liftedloss,m-sloss},
knowledge transfer~\cite{oltr,kt_1,kt_2}, 
mixture of experts~\cite{RIDE,LFME,TADE}, 
\sinha{cost-sensitive learning~\cite{ldam-drw,classbalancedloss,logitadjustment,meta-weight-net,sinha_ijcv}} and decoupled learning~\cite{decoupling,dro-lt,disalign,mislas}.


Data re-sampling techniques~\cite{smote,borderline-smote,classbalancedsampling_1,oversampling_1,undersampling_1} try to neutralize the long-tail by under-sampling from head classes or over-sampling from tail classes. 
Under-sampling~\cite{undersampling_1} generally results in poor representation of the head classes,
while a straight-forward over-sampling strategy of replicating tail-class samples causes the model to overfit on the repeated samples.
Another popular oversampling technique is synthetic data generation~\cite{smote,borderline-smote} for the tail classes. 
Certain class-balanced sampling approaches such as class-aware sampling~\cite{classbalancedsampling_1,decoupling,classbalancedsampling_2} and square-root sampling~\cite{decoupling} have been shown to be more effective than using over- or under-sampling.
They typically try to increase the sampling rate for the tail classes during training. 
However, they still result in overfitting due to the repeated sampling of the same samples from tail classes.

Metric learning methods~\cite{hingeloss,tripletloss,contrastivelearning,liftedloss,m-sloss,rangeloss} aim to learn a high-quality feature extractor that preserves inter-class and intra-class relationships in the feature space. 
They achieve this by learning from pairs~\cite{contrastivelearning,liftedloss,rangeloss} or triplets~\cite{hingeloss,tripletloss} of input samples. 
Metric learning has been used in long-tailed recognition~\cite{oltr,hybridnet} in hope that high-quality feature extractor will mitigate the imbalance between head and tail classes. 
An effective sampling of the sample groups is the key for efficient training in this scheme. 
However, such sampling strategies come with the risk of under-representation or overfitting, as explained above.


Knowledge transfer~\cite{featuretransfer2,oltr,kt_1,kt_2,featuretransfer} in long-tailed recognition tries to transfer knowledge gained from the head classes to the tail classes. They achieve this either by learning modular transformations from few-shot model parameters to many-shot models~\cite{kt_1,kt_2} or by designing external modules for feature transfer~\cite{oltr,featuretransfer}.
Designing such modules is usually computationally expensive in real-world usecases~\cite{decoupling}.

Mixture of experts (MoE)~\cite{RIDE,LFME,TADE,bbn} is an ensemble-based technique where the expert models are trained to gain diverse knowledge. The aggregated knowledge of the experts is either used directly to alleviate the long-tail~\cite{RIDE,TADE} or used to teach a student model for that purpose~\cite{LFME}. 
Despite the increasing popularity of this domain, our research focuses on the improvement of a single 
model 
as
it can then easily be combined with any mixture.

Cost-sensitive learning can be achieved by logit-adjustment loss~\cite{ldam-drw,logitadjustment,seesawloss} and weighted loss~\cite{classbalancedloss,hardmining,focalloss,l2rw,meta-weight-net,eqllossv2,eqlloss} approaches. 
Most prior methods distribute these adjustment or weight values on the basis of class-frequencies. 
Recently, \sinha{Sinha \etal~\cite{cdb-ce,sinha_ijcv}} showed that class-difficulty is a better metric for the purpose. 
However, finding an optimal formulation for calculating class-difficulty is not a trivial task as the optimal formulation usually varies depending on datasets as shown in Figure~\ref{fig:class-wise difficulty}.
Our research builds on the work of Sinha \etal~\cite{cdb-ce} and tries to remove the requirement of any prior formulation by using meta-learning. Meta-learning~\cite{metalearning_1} has previously been used in long-tailed recognition to learn~\cite{jamal,l2rw} or predict~\cite{meta-weight-net} sample weights. The closest to our research is Meta-Weight-Net (MWN)~\cite{meta-weight-net}, which learns a model to predict sample-level weights from training loss. 
Different from them, we use class-level weighting, which is known to be better than sample-level weighting in long-tailed recognition~\cite{cdb-ce}.


Recently, Kang \etal~\cite{decoupling} found that decoupling model learning into representation learning and classifier learning helps long-tailed recognition. Since this finding, most works have tried to improve either the data-representation~\cite{dro-lt,ssl} or the classifier~\cite{groupsoftmax,classifierbalancing,disalign,mislas}. 
We show that our method also benefits from this framework and achieves state-of-the-art results based on it.

\section{Proposed method}
\subsection{Background}
Generally, the prior assumption is that the tail classes are the most difficult to learn for the models. However, it has recently been empirically shown that the number of training instances of a class might not be the best clue to determine its difficulty because some classes are well-represented even with fewer training samples. On the basis of this finding, Sinha \etal~\cite{cdb-ce} came up with a simple formulation to directly calculate the difficulty of a class from the model's performance. The formulation says that if the model's classification accuracy on a class  is , then the difficulty of the class  can be computed as .


However, we found two lacking points in 
the formulation. 
First, as stated in Sec.~\ref{sec:intro}, we found multiple decreasing functions of accuracy  that outperformed the above formulation in multiple setups.
In the meantime, we also found that the best performing formulation varies inconsistently with the data imbalance and thus it is not possible to preliminarily define the best formulation for a given dataset. 
Second, while the above formulation helps to compute the absolute difficulty of a class, we believe it is more important to compute the difficulty of a class {\it relative} to the other classes because it is reasonable to assign a high difficulty score to a class with high accuracy (\ie easy class) {\it if} the other classes have even higher accuracies. 
For that purpose, all the classes need to be considered when computing the difficulty of a single class, which is not done in~\cite{cdb-ce}. 


To address these issues, we propose meta-learning the formulation that is most effective for a given dataset, taking relative difficulties into consideration.



\subsection{Meta-learning via Difficulty-Net}\label{sec:meta-learning_via_difficulty-net}
\paragraph{Difficulty-Net design.}\label{difficultynet design}
Given a dataset of  classes, we aim to learn a formulation that can compute the relative difficulty for each class. For this purpose, we design the formulation for class-wise difficulty as 

Note that both  and  change as the training progresses, but here we omit the notation of training steps for simplicity.
 is a neural network with parameters . 
In our implementation, we choose  to be a simple MLP model with two hidden layers.
The output layer dimension is kept same as the number of classes and
a sigmoid activation at the output ensures the difficulty scores to be in the range .
The input to  are the model's classification accuracies for all  classes. The design of  ensures that while estimating the difficulty for a class, the model's performance on the other classes is also taken into account. We refer to  as `Difficulty-Net'.



\paragraph{Meta-learning objective:}
Suppose a classification problem in which we are provided a training dataset , where  is the  training sample and  is its corresponding ground truth label. Given a classifier neural network  with learnable parameters , our primary objective is to learn the optimal parameters  so that  provides the minimum classification loss on the training set , \ie 

where  computes the loss corresponding to 's prediction for a given sample and is typically the cross-entropy loss.

In long-tailed recognition, the training dataset  is class-imbalanced.
In such cases, optimization using Eq.~\ref{typical optimization} leads to biased learning of . To compensate for the imbalance, we modify the learning objective as most weighted loss approaches do, \ie

where  is the weight assigned to the training sample . 
In our proposed approach,  is computed by 
Difficulty-Net
 as 

where  is the difficulty score for class  predicted by Difficulty-Net and  is the set of accuracies of  for all  classes, evaluated prior to this calculation. 
Therefore, the learning objective for  is modified as 



Since the optimization of our main classifier network depends on the effectiveness of Difficulty-Net, it is important to optimize the parameters  of  as well. 
Inspired by~\cite{meta-weight-net}, we use a small balanced meta-dataset  for optimizing the parameters  as follows.



However, we found that  alone is not enough for Difficulty-Net to learn to estimate difficulties from accuracy. 
Even for 2 classes with very different accuracy values, Difficulty-Net learned using Eq.~\ref{meta loss optimization} tends to give similar difficulty scores for both classes.
To address this issue, we add another loss component to drive the learning of Difficulty-Net in a practically correct direction. We call this loss `driver loss' and calculate it as

where  is the normalized accuracy of class .
The  is built on the motivation that Difficulty-Net should learn to give high difficulty scores to a class, if the accuracy of the class is relatively low.
Now the parameters  of Difficulty-Net  are optimized as 

where  is a hyper-parameter controlling the influence of . Note that too high value of  will simply cause  to always predict class difficulties as 
.
We ablate over various values of  in our experiments.


\paragraph{Learning method.}

Following~\cite{meta-weight-net}, our meta-learning method is a 3-step process. Given a classifier network  and Difficulty-Net  at time step , the first step aims to learn 
intermediate classifier parameter  by

where  is the step size for gradient descent and  is the number of samples in one mini-batch sampled from the training set . 
 is the classification accuracy of  on all the  classes at time step  and is computed on a validation dataset . 

The second step updates the parameters  of Difficulty-Net using the obtained intermediate classifier  on a mini-batch of size  sampled from the meta-dataset. The update is done by

where  is the step size for updating the parameters of Difficulty-Net.

Finally, the third step uses the updated parameters  to update the parameters of the classifier network  over the same mini-batch sampled in Eq.~\ref{step 1}. 

The above three steps are executed iteratively till convergence or the end of the training. 
The overall algorithm is presented in 
Algorithm~1
in the supplementary material.


For our experiments, we construct the  following exactly the same procedure as~\cite{jamal,meta-weight-net}. We also found that  is reusable as  for calculating . Therefore, we do not use any extra data compared to previous methods.
Also, although it is ideal to calculate  for every time step , we calculate the accuracy only after every epoch in our implementation for saving computational time.







\paragraph{Difference with MWN and CDB-CE.}\label{sec: diff from mwn and cdb-ce}
Although we share a similar meta-learning framework as MWN~\cite{meta-weight-net}, our approach is very different from theirs in more than one way.
One difference is that MWN is a sample-level weighting strategy while ours is a class-level weighting strategy. 
The advantages of class-level weighting over sample-level weighting in long-tailed learning is pointed out in~\cite{cdb-ce} and also reflected in our experimental results. 

Ours is not the straight-forward combination of MWN~\cite{meta-weight-net} and CDB-CE~\cite{cdb-ce}.
First, both MWN and CDB-CE use absolute difficulties of a sample or a class to determine the weights. 
We believe, however, the relative difficulty compared with other samples or classes is more important because it is reasonable to assign a high difficulty score to a class with high accuracy (\ie easy class) {\it if} the other classes have even higher accuracies. 
The proposed method estimates relative difficulties of each class amongst all the classes, and it turned out to be more effective as we will show in Sec.~\ref{sec:ablation}.
Second, the straight-forward combination of these prior works without the driver loss turns out to learn almost nothing and predicts almost identical difficulties for all the classes as we will show in Sec.~\ref{sec:ablation}. 
The newly proposed driver loss is essential to guide the training in a reasonable direction.

The empirical evidences of these arguments are provided in Sec.~\ref{sec:ablation} and~\ref{sec:further_analysis}.


\section{Experiments}
\subsection{Datasets}


\paragraph{\bf CIFAR100-LT.} 
CIFAR100~\cite{CIFAR} is an object-centric balanced classification data-set comprised of tiny images belonging to 100 different classes. Long-tailed versions of the dataset are artificially created by reducing the training samples per class according to an exponential function as given in~\cite{classbalancedloss}. Following~\cite{classbalancedloss}, we use CIFAR100-LT with imbalance varying in 10--200. 
\vspace{-11pt}
\paragraph{\bf ImageNet-LT.} 
ImageNet-LT is a long-tail version of ImageNet~\cite{imagenet} created by~\cite{oltr}. It contains 1000 object categories with heavy imbalance of 256.
We use the same \textit{train, val} and \textit{ test} splits as~\cite{oltr}. 
\vspace{-11pt}
\paragraph{\bf Places-LT.} 
Places-2~\cite{places} is a large-scale scene-centric image dataset,
used for scene recognition tasks. Places-LT is a long-tailed subset of Places-2 with 365 classes and imbalance of 996, created by~\cite{oltr}. 
We use the same splits as~\cite{oltr}. 


For constructing , we followed the setup of previous meta-learning based methods \cite{jamal,meta-weight-net} to ensure the fair comparison. Please see the supplementary material for the details.
The evaluation results are reported on balanced test sets.

\subsection{Implementation details}
Following previous long-tailed works~\cite{classbalancedloss,oltr,eqlloss}, we use ResNet-32~\cite{ResNet} for  CIFAR-100-LT experiments. 
On ImageNet-LT, we follow~\cite{decoupling,oltr,mislas} and use ResNet-10~\cite{ResNet}, ResNet-50~\cite{ResNet}. 
As in~\cite{mislas}, we use pretrained (on ImageNet~\cite{imagenet}) ResNet-152~\cite{ResNet} and finetune it on Places-LT. 
The basic architecture of Difficulty-Net is the same for all the datasets as explained in Sec.~\ref{difficultynet design}, \ie MLP with two hidden layers, but we change the dimension of hidden and output layers as different datasets have different number of classes.
We will explain a simple way to select the dimension of hidden layers in the supplementary material. 
We evaluate our method both in end-to-end (e2e) learning and decoupled learning~\cite{decoupling} settings.
For using Difficulty-Net in decoupled learning, we first train the respective model using Difficulty-Net based weighting. 
Then, following~\cite{decoupling}, we freeze the feature extractor and re-train the classifier without using Difficulty-Net.
We use  for all the experiments unless otherwise stated since we find it works reasonably well as we will show in Sec.~\ref{sec:ablation}. Further details are provided in the supplementary material.

\subsection{Compared methods}
For comparison, we use multiple SOTA methods including (1) data-resampling: class-balanced sampling (CB sampling)~\cite{decoupling}, (2) cost-sensitive learning: equalization loss (EQL)~\cite{eqlloss}, focal loss~\cite{focalloss}, class-balanced loss~\cite{classbalancedloss}, label-distribution-aware-margin (LDAM) loss~\cite{ldam-drw}, pre-formulated class-difficulty balanced loss (CDB-CE)~\cite{cdb-ce}, (3) metric learning: parametric contrastive learning (PaCo)~\cite{PaCo}, (4) decoupled learning: classifier normalization (-norm)~\cite{decoupling}, classifier re-training (cRT)~\cite{decoupling}, learnable weight scaling (LWS)~\cite{decoupling}, label-aware smoothing (LAS)~\cite{mislas}, balanced meta-softmax (BALMS)~\cite{BALMS}, distribution robustness loss (DRO-LT)~\cite{dro-lt}, (5) meta learning: Meta-Weight-Net (MWN)~\cite{meta-weight-net}, class-balancing as domain-adaptation (CB-DA)~\cite{jamal}. 
For the sake of fairness, we do not compare our method directly with MoE methods~\cite{RIDE,LFME} as they use ensemble of multiple expert models, while we focus on improving the learning for a single expert. 
However, we verified that the proposed method can exhibit significant performance gains by using simple ensembling techniques and can 
outperform SOTA MoE methods. The results are found in the supplementary
material.









\subsection{Main results}
\label{sec:main_results}
\paragraph{\bf CIFAR100-LT.} 

\begin{table}[t]
  \begin{center}
    {\small{
\begin{tabular}{llllll}
\toprule
&\multicolumn{5}{c}{Imbalance}\\
    \midrule
    Method &  200 & 100 & 50 & 20 & 10\\
    \midrule
    \textit{e2e training} \\
Focal Loss~\cite{focalloss} & 39.64 & 44.03 & 48.91 & 55.57 & 61.10  \\
    MWN~\cite{meta-weight-net} & 40.25 & 44.81 & 49.68 & 56.53 & 61.44\\
    Class-Balanced~\cite{classbalancedloss} &39.95 & 44.78 & 47.67 & 56.83 & 59.95\\
    CB-DA~\cite{jamal} & 40.89& 46.24 & 49.80 & 56.67 & 62.16\\
    LDAM~\cite{ldam-drw} & 41.42 & 46.14 & 49.19 & 55.90 & 62.08\\
EQL~\cite{eqlloss} & 43.46 & 46.47 & 51.34 & 56.82 & 60.13\\
    CDB-CE~\cite{cdb-ce} & 40.42 & 45.25 & 49.45 & 56.66 & 61.52 \\
PaCo~\cite{PaCo} & 43.09 & 47.26 & 52.14 & 58.37 & 63.12\\
    \hspace{1mm} + Bal.~Softmax~\cite{BALMS} & 46.72 & 51.47 & 55.88 & 60.32 & 64.10 \\
    \hspace{1mm} + Bal.~Softmax~\cite{BALMS} & -- & 52.00 & 56.00 & -- & 64.20\\
    Ours & 44.80 & 47.96 & 54.27 & 58.93 & 63.52 \\
    \hspace{1mm} + Bal.~Softmax & 47.53 & 52.14 & 56.86 & \textbf{61.72} & \textbf{65.67} \\
    \midrule
    \textit{decoupled learning}\\
cRT~\cite{decoupling} & 44.05 & 48.04 & 53.32 & 58.72 & 63.74 \\
     LWS~\cite{decoupling} & 44.42 & 48.13 & 53.44 & 59.10 & 63.97\\
     LAS~\cite{mislas} & 44.87& 48.68 & 53.85&59.36 & 64.18\\
     DRO-LT~\cite{dro-lt}  &-- & 47.31 & \textbf{57.57} & -- & 63.41 \\
BALMS~\cite{BALMS}  & 46.12 & 50.95 & 54.42 & 59.00 & 63.10\\
     MWN + cRT &44.56 & 48.34 &53.62 & 59.05 & 63.99 \\
     MWN + LWS &44.71& 48.65 & 53.77&59.22 & 64.15 \\
     MWN + LAS & 45.04& 49.12 &53.95 &59.38 & 64.24\\
Ours + cRT & 47.45 & 52.01 & 56.34 & 61.08& 64.80\\ 
     Ours + LWS & \underline{47.91} & \underline{52.62} & 56.61 & 61.38 & 65.08\\ 
     Ours + LAS & \textbf{48.32} &\textbf{52.96} & \underline{56.90} & \underline{61.46} & \underline{65.22}\\
\bottomrule
\end{tabular}
}}
\end{center}
\caption{Top-1 classification accuracy (\%) on CIFAR-100-LT. 
 denotes copied results from origin paper~\cite{PaCo,dro-lt}. The best results are made bold while the second best results are underlined, which applies for the other tables as well.}
  \label{tab:CIFAR-LT results}
\end{table}
Following~\cite{PaCo,eqlloss}, we use AutoAugment~\cite{AutoAugment} and Cutout~\cite{Cutout} for all our implementations on CIFAR100-LT. As explained in~\cite{eqlloss}, this achieves a higher baseline than other commonly followed ones. Therefore, to ensure the fairness of comparison, we re-implemented the compared methods in our training setup using their published codes. 
Results without using AutoAugment and Cutout are provided in the supplementary material.
We achieved better results than originally reported results for all the re-implemented methods except PaCo~\cite{PaCo}, which uses additional augmentation. 
Therefore, we list the original results of PaCo for reference in addition to the results in the fair setting.
PaCo uses an additional center learning rebalance step, for which they employ Balanced Softmax (Bal.~Softmax)~\cite{BALMS}. 
We report the results of PaCo both with and without the use of Bal.~Softmax.
For the fair comparison with PaCo + Bal.~Softmax, we tested Ours + Bal.~Softmax in addition to the vanilla variant (Ours). 





In e2e learning, our proposed approach without combining any other techniques (Ours) achieved better performance than all previous stand-alone methods as seen in Table~\ref{tab:CIFAR-LT results}. 
The margin of improvement is higher in high-imbalanced situations.
End-to-end learning with Ours + Bal.~Softmax turned out to be very effective and
created new SOTA for low imbalanced cases (\ie 10 and 20). 







In decoupled-learning, we find that when we use feature extractors trained using Difficulty-Net, any popular classifier learning method (\eg cRT, LWS, LAS) gives improved performance. 
This shows that our proposed method learns very powerful data representations. 
Ours + LAS achieved the best results in high imbalanced situations (\eg 200 and 100), while it achieved the second best in all other cases.


\paragraph{\bf ImageNet-LT.} 
Table~\ref{tab:ImageNet-LT results} shows the results on ImageNet-LT.
In e2e learning alone, irrespective of the model used, we achieved better overall accuracy than other e2e 
methods and comparable accuracy with multiple decoupled 
methods.

Furthermore, Difficulty-Net based representation learning with popular classifier re-training methods achieved state-of-the-art results. Using both ResNet-10 and ResNet-50, Ours + LAS achieved the best overall accuracy, which re-confirms the effectiveness of this method. More ImageNet-LT results with many-/med-/few-shot splits are available in the supplementary material.

\begin{table}
  \begin{center}
    {\small{
\begin{tabular}{llr}
\toprule
         Method & ResNet-10 & ResNet-50 \\
         \midrule
         \textit{e2e training} \\
         CE  & 34.8 & 41.6 \\
         Focal loss~\cite{focalloss} & 30.5 & -- \\
EQL~\cite{eqlloss}  & 36.4 & --\\
         CB-DA\cite{jamal} & 36.7 & 48.0\\
         CDB-CE~\cite{cdb-ce} & 38.5 & --\\
          Bal.~Softmax~\cite{BALMS} & 41.1 & --\\
         PaCo~\cite{PaCo}  & -- &  49.8\\
         \hspace{0.2mm} + Bal.~Softmax~\cite{BALMS} & -- & 53.5\\ 
         Ours & 41.4 & 51.2 \\
         \hspace{0.2mm} + Bal.~Softmax & 44.3 & \underline{53.7} \\
         \hline
         \textit{decoupled learning}\\


         cRT~\cite{decoupling}  & 41.8 & 47.3 \\
         LWS~\cite{decoupling}  & 41.4 & 47.7 \\
         MiSLAS~\cite{mislas}  & -- & 52.7 \\
         BALMS~\cite{BALMS}  & 41.8 & -- \\
         DRO-LT~\cite{dro-lt}  & -- & 53.5 \\
         Ours + cRT & 43.6 & 53.5 \\
         Ours + LWS & \underline{44.4} & \underline{53.7} \\
         Ours + LAS & \textbf{44.6} & \textbf{54.0}\\
         \bottomrule

\end{tabular}
}}
\end{center}
\caption{Top-1 classification accuracies (\%) on ImageNet-LT.  represents reproduced results using author's codes without using RandAugment~\cite{randaugment} for fair comparison. Other baseline results are copied from original papers. Results using RandAugment
are provided in the supplementary
material.
}
  \label{tab:ImageNet-LT results}
\end{table}






\paragraph{\bf Places-LT.} 
From Table~\ref{tab:CIFAR-LT results} and Table~\ref{tab:ImageNet-LT results}, it is evident that our Difficulty-Net based weighting is consistently effective when used for the representation learning in decoupled training methods. 
Therefore, for Places-LT, we only report the results of Ours + \{cRT, LWS, LAS\} and compare them with previous SOTA results in Table~\ref{tab:Places results}. 
The results verify that the representation learned using our method is very powerful and helps us achieve the best overall accuracy by simple classifier re-balancing. Our improvements in overall accuracy is majorly accounted for by significant gains in medium- and few-shot accuracies. 
Even though our representation learning is effective with any classifier re-training method, especially Ours + LAS significantly boosts results for the few-shot classes and achieved SOTA in overall accuracy. PaCo achieved the best results for the medium-shot classes, but it sacrificed the performance on the many-shot classes significantly, resulting in lower overall accuracy. 
\begin{table}
  \begin{center}
    {\small{
\begin{tabular}{llllr}
\toprule
Method &  Many & Med & Few & All\\
    \midrule
CE & \underline{45.7} & 27.3 & 8.2 & 30.2 \\
    CB sampling~\cite{decoupling} & -- & -- & -- & 30.3\\
    Focal Loss~\cite{focalloss} & 41.1 & 34.8 & 22.4 & 34.6 \\
cRT~\cite{decoupling} & 42.0 & 37.6  & 24.9 & 36.7 \\
     LWS~\cite{decoupling} & 40.6 & 39.1 & 28.6 & 37.6 \\
BALMS~\cite{BALMS} & 41.2 & 39.8 & 31.6 & 38.7\\
     LADE~\cite{lade} & 42.8& 39.0& 31.2& 38.8\\
     DisAlign~\cite{disalign} & 40.4 & 42.4 & 30.1 & 39.3 \\
     IEM~\cite{IEM} &\textbf{46.8}& 39.2& 28.0 & 39.7\\
     MiSLAS~\cite{mislas} & 39.6 & 43.3 & 36.1 & 40.4\\
     PaCo~\cite{PaCo} & 37.5 & \textbf{47.2} & 33.9 & 41.2 \\
     


Ours + cRT &43.0 & \underline{43.8} & 35.0& \textbf{41.7}\\ 
     Ours + LWS & 41.4 & 43.7 & \textbf{36.9} & \underline{41.5}\\ 
     Ours + LAS & 42.4 & 43.7 & \underline{36.6} & \textbf{41.7} \\
    \bottomrule

\end{tabular}
}}
\end{center}
\caption{Top-1 classification accuracies (\%) for Places-LT. }
  \label{tab:Places results}
\end{table}

\subsection{Ablation study}\label{sec:ablation}
In this sub-section, we first show the ablation study of our key components, namely relative difficulty and the driver loss.
Then we re-verify the effectiveness of the class-level weighting studied in~\cite{cdb-ce} in our meta-learning framework. Further, we verify the effectiveness of using the meta-learning loss in our method.
We conclude this sub-section with the effectiveness of the proposed method by comparing it with the straight-forward combination of CDB-CE~\cite{cdb-ce} and MWN~\cite{meta-weight-net}.

\begin{table*}[]
  \begin{center}
    {\small{
\begin{tabular}{lllllllr}
\toprule
  \# & Name & S vs.~C & A vs.~R & ML &  & Imb.=100 & Imb.=10\\
  \midrule
  1 & Focal loss~\cite{focalloss}   & S & A &               &  & 44.03 & 61.10\\
  2 & CDB-CE~\cite{cdb-ce}          & C & A &               &  & 45.25 & 61.52 \\
  3 & MWN~\cite{meta-weight-net}    & S & A & \checkmark    &  & 44.81 & 61.44 \\
  4 & CDB-CE + MWN                  & C & A & \checkmark    &  & 45.42 & 61.87\\
  5 & Ours w/o  and ML  & C & R &               &  & 45.51 & 62.44\\
  6 & Ours w/o          & C & R & \checkmark    &  & 46.40 & \underline{63.10}\\
  7 & Ours w/o relative difficulty  & C & A & \checkmark    &  \checkmark & \underline{46.81} & 62.32\\
  8 & Ours w/o class-level weighting& S & R & \checkmark & \checkmark & 45.76 & 62.51\\
  9 & Ours                          & C & R & \checkmark & \checkmark & \textbf{47.96} & \textbf{63.52}\\
  \bottomrule
\end{tabular}
}}
\end{center}
\caption{Classification accuracy on CIFAR100-LT with imbalance ratio (Imb.) 100 and 10. ``S vs.~C'' means Sample-level vs.~Class-level. ``A vs.~R'' means Absolute difficulty vs.~Relative difficulty. ML stands for Meta Learning. }
  \label{tab:ablation}
\end{table*}

\paragraph{\bf Absolute difficulty vs.~relative difficulty.} 
For predicting absolute difficulty, we modified Difficulty-Net from Eq.~\ref{difficultynet} to  and trained it in the same way as before. 
The comparison is provided in Table~\ref{tab:ablation} (\#7 vs.~\#9).
As can be seen, relative difficulty significantly outperforms absolute difficulty for both low and high imbalance. 
This verifies the effectiveness of relative difficulty. 




\paragraph{\bf Contribution of .} 
The value of  in Eq.~\ref{eq:lambda} controls the impact of . 
Here we analyse the effect of .
For that, we evaluate the performance of ResNet-32 trained end-to-end using different values of  and report the results in Table~\ref{tab:analysis for diff imbalance}.
\begin{table}
  \begin{center}
    {\small{
    \begin{tabular}{lllllr}
\toprule
     & 0 & 0.3  & 0.6  & 0.9  & 1.0 \\
    \midrule
    Imbalance=100 & 46.40 & \underline{47.96} & \textbf{48.03} & 47.35 & 46.66\\
    Imbalance=10 & 63.10 & \textbf{63.52} & \underline{63.44} & 62.62 & 62.24\\
     \bottomrule

\end{tabular}
}}
\end{center}
\caption{Accuracy (in e2e learning) for different values of  on CIFAR100-LT.  }
  \label{tab:analysis for diff imbalance}
\end{table}
It shows that , which is equivalent to \#6 in Table~\ref{tab:ablation}, works significantly poor especially in high imbalance case, which asserts the importance of using . We find that for higher imbalance, higher  works better. 
But, too high  leads to significant drop in performance.
Irrespective of  the imbalance,  works consistently well.


 To further analyse the usefulness of , we visualise the predicted difficulty by Difficulty-Net trained with and without . The results are shown in Figure~\ref{fig:difficulty-net}. 
 \begin{figure}[t]
\begin{center}
    \includegraphics[width=\linewidth ]{Modified_fig2_2.eps}
\end{center}
\caption{Difficulty scores for CIFAR100-LT (imbalance=100) classes predicted by Difficulty-Net learned with  and . The classes are sorted in increasing order of their accuracy. }
\label{fig:difficulty-net}
\end{figure}
It shows that using  with  provides a more meaningful learning of Difficulty-Net compared to when not using  ().
The latter predicts similar difficulty scores for all the classes inspite of the highly biased accuracy. 
However, using  helps Difficulty-Net to predict high difficulty for less accurate classes. 


\vspace{-8pt}
\paragraph{\bf Sample-level difficulty vs.~Class-level difficulty.}
We modified the Difficulty-Net to predict sample-level difficulties and compared it with the proposed method.
We modified the Difficulty-Net as  where  is the total number of samples in a single batch,  is the model's cross-entropy loss for samples , and  is the predicted difficulty for sample . 
Simply, we meta-learn the  to predict difficulty of each sample relative to other samples in the same training batch.
Note that this variant uses relative difficulty and the driver loss, and thus is different from MWN.


In Table~\ref{tab:ablation} (\#8 vs.~\#9), it is seen that class-level difficulty significantly outperforms the sample-level difficulty in overall performance. This proves the effectiveness of class-difficulty in our proposed method. 
We believe that this happens because the head classes have higher {\it absolute} number of hard samples than the tail classes simply because the head classes have much more training samples. 
In such case, as pointed out in~\cite{cdb-ce}, sample-level weighting gives higher weights to head classes in total, and therefore cause the model to get biased to the head classes. 
This is verified by the fact that class-level performs much better especially for the tail classes (med and few-shot) as shown in the supplementary material. 
Another interesting observation is that our sample-level Difficulty-Net even significantly outperforms MWN (\#3 vs.~\#8), which re-verifies the effectiveness of our newly proposed components, namely relative difficulty and the driver loss.
\paragraph{\bf Contribution of .}
Here we verify the usefulness of  in our Difficulty-Net training. In Table~\ref{tab:ablation} (\#5 vs. \#6), we see that using meta-learning loss gives a boost of 0.89\% (for imb. 100) which confirms the benefit of using ML.
\paragraph{\bf The straight-forward combination of CDB-CE and MWN does not work.}
As stated in Sec.~\ref{sec: diff from mwn and cdb-ce}, ours is not the straight-forward combination of the previous methods. Evidently from Table~\ref{tab:ablation} (\#4 vs.~\#9), such straight-forward combination does not work well, which verifies the contributions of our newly proposed components.


\subsection{Further analysis}\label{sec:further_analysis}




It is evident in Figure~\ref{fig:difficulty-net} that Difficulty-Net successfully learns to predict reasonable difficulty from the class-wise accuracies.
Here we further analyse how the predicted difficulties change as the training progresses.
For this purpose, we plot the entropy of the difficulty scores with the training steps in Figure~\ref{fig:weight_entropy}. 
We compute the entropy as . 
Figure~\ref{fig:weight_entropy} shows that the entropy 
decreases with the training steps. 
This suggests that the predicted difficulty scores gradually become more and more uniform, as the model's class-wise performance 
gradually gets balanced.
this result empirically supports the rationality of Difficulty-Net.




\begin{figure}[t]
\begin{center}
\includegraphics[width=\linewidth]{Modified_fig3_2.eps}
\end{center}
\caption{Plotting entropy () of difficulty scores predicted by Difficulty-Net against number of training steps. We used CIFAR100-LT (imbalance=100) for this plot. }
\label{fig:weight_entropy}
\end{figure}
Further, we analyse the characteristics of difficulties estimated by Difficulty-Net in comparison with those by~\cite{cdb-ce}. 
We pick three classes from the CIFAR100-LT classes (one from each of many-, medium- and few-shot classes) and show how the normalized weights of the classes change as the training progresses.
As shown in Figure~\ref{weight-analysis}, CDB-CE weighting~\cite{cdb-ce} leads to more fluctuations in the assigned weights, while Difficulty-Net based weighting is more smooth and stable. This suggests that Difficulty-Net has capability of `remembering' which class is difficult whereas CDB-CE weighting tends to be heavily affected by quick accuracy change at each time step. We believe this characteristic of Difficulty-Net encourages consistent and stable training of the model, ending up in better performance than CDB-CE weighting. Another interesting observation in Figure~\ref{weight-analysis} is that the difficulties of the three classes estimated by Difficulty-Net tend to converge as the training progresses 
,which is not observed in the case of CDB-CE. 
This observation is consistent with Figure~\ref{fig:weight_entropy}, which showed that the predicted difficulty scores gradually become more uniform as the 
model's performance gets balanced.

\begin{figure}[t]
  \begin{center}
      
  
  \begin{tabular}{cc}
\includegraphics[width=0.45\linewidth]{Modified_fig4a_1.eps}  \hfill
\includegraphics[width=0.45\linewidth,  ]{Modified_fig4b_1.eps} \end{tabular}
\caption{Assigned weights to three different classes during training with CDB-CE~\cite{cdb-ce} (Left) and our Difficulty-Net (Right). The vertical axis represents assigned weights and the horizontal axis represents training steps.}
  \label{weight-analysis}
  \end{center}
\end{figure}



\section{Conclusion}






This paper has proposed Difficulty-Net, a novel method for long-tailed recognition that learns to predict difficulty of classes in a meta-learning framework.~The proposed method has mainly three key features compared to prior works. First,  it removes any dependence on heuristic formulations thanks to its ability to learn any suitable difficulty formulation for a given dataset. Second, it estimates relative difficulty of a class compared to the other classes whereas prior works use only absolute difficulty of a class in question. Third, it employs a new driver loss function that helps to drive Difficulty-Net learning in a reasonable direction. We verified the effectiveness of the proposed method by conducting extensive experiments on multiple datasets. Further analysis also demonstrated the usefulness of relative difficulty and the newly proposed driver loss function.





{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
