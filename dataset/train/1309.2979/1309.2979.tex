\documentclass{article}
\usepackage{palatino,epsfig,latexsym,natbib}





\title{Fitness Probability Distribution of Bit-Flip Mutation}

\author{Francisco Chicano, Andrew M. Sutton, \\L. Darrell Whitley and Enrique Alba \\
\\
University of M\'alaga, M\'alaga, Spain\\
Colorado State University, CO, USA
}

\date{}



\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}

\usepackage{array}
\usepackage{subfigure}
\usepackage{latexsym}
\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{graphicx}



\newlength{\marg}
\setlength{\marg}{60mm}
\newlength{\margv}
\setlength{\margv}{50mm}

\setlength{\textwidth}{\paperwidth}
\addtolength{\textwidth}{-\marg}

\setlength{\oddsidemargin}{0.50\marg}
\setlength{\evensidemargin}{0.50\marg}

\addtolength{\oddsidemargin}{-1in}
\addtolength{\evensidemargin}{-1in}

\setlength{\textheight}{\paperheight}
\addtolength{\textheight}{-\margv}

\setlength{\topmargin}{0.50\margv}
\addtolength{\topmargin}{-1in}
\addtolength{\topmargin}{-\headsep}
\addtolength{\topmargin}{-\headheight}



\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}

\newcommand{\avg}[1]{\mathop{\mathrm{avg} \{f(y)\}}_{y \in #1}}
\newcommand{\avgz}[1]{\mathop{\mathrm{avg} \{f(y,z)\}}_{y \in #1}}
\newcommand{\avgf}[2]{\mathop{\mathrm{avg} \{#2(y)\}}_{y \in #1}}
\newcommand{\avgfz}[2]{\mathop{\mathrm{avg} \{#2(y,z)\}}_{y \in #1}}


\def\vec#1{\mathchoice{\mbox{\boldmath}}
  {\mbox{\boldmath}}
  {\mbox{\boldmath}}
  {\mbox{\boldmath}}}

\newcommand{\comb}[2]{\binom{#1}{#2}}


\newcommand{\Bo}[0]{\mathbb{B}}
\newcommand{\Na}[0]{\mathbb{N}}
\newcommand{\Za}[0]{\mathbb{Z}}
\newcommand{\Real}[0]{\mathbb{R}}
\newcommand{\Exp}[1]{E\{#1\}}

\newcommand{\NP}[0]{\mathsf{NP}}
\renewcommand{\P}[0]{\mathsf{P}}

\newcommand{\krawel}[3]{\mathcal{K}^{#1}_{#2,#3}}
\newcommand{\krawelt}[3]{\tilde{\mathcal{K}}^{#1}_{#2,#3}}
\newcommand{\kraw}[1]{\mathcal{K}^{#1}}
\newcommand{\krawt}[1]{\tilde{\mathcal{K}}^{#1}}

\newcommand{\Prob}[1]{\mathop{\mathrm{Pr}\{#1\}}}
\newcommand{\ProbCond}[2]{\mathop{\mathrm{Pr}\{#1|#2\}}}
\newcommand{\Diag}[1]{\mathop{\mathrm{diag}\left(#1\right)}}

\newcommand{\dotproduct}[2]{\left\langle #1,#2 \right\rangle}

\newcommand{\mask}[0]{V}

\newif\ifshowcomments
\newcommand{\comment}[1]{\ifshowcomments\textbf{(#1)}\fi}
\showcommentstrue 

\begin{document}

\maketitle

\begin{abstract}
Bit-flip mutation is a common mutation operator for evolutionary algorithms applied to optimize functions over binary strings. In this paper, we develop results from the theory of landscapes and Krawtchouk polynomials to exactly compute the probability distribution of fitness values of a binary string undergoing uniform bit-flip mutation. We prove that this probability distribution can be expressed as a polynomial in , the probability of flipping each bit. We analyze these polynomials and provide closed-form expressions for an easy linear problem (Onemax), and an -hard problem, MAX-SAT. We also discuss some implications of the results for runtime analysis.
\end{abstract}







\parskip=0.00in


\section{Introduction}
\label{sec:intro}

Evolutionary algorithms that operate on binary string representations commonly employ the \emph{bit-flip} mutation operator.  This operator acts independently on each bit in a solution and changes the value of the bit (from 0 to 1 and vice versa) with probability , where  is a parameter of the operator.  The most commonly recommended value for this parameter is  where  is the length of the binary string. For linear functions, this rate is provably optimal~\citep{Witt2013tight}. However, in the general case, very little is currently understood about the mutation operator and its influence on the optimization process.

In this paper we study the operator from the point of view of landscape theory. Using this approach, we provide closed-form formulas for the fitness probability distribution of the solutions obtained after the application of bit-flip mutation to a particular solution. Up to the best of our knowledge, these kind of general and closed-form formulas have not been presented before. We can find, however, some works in which mathematical expressions are provided for this probability distribution in the case of particular problems like Onemax~\citep{Garnier1999}. In this paper we want to be more general and provide a mathematical expression for the probability distribution that separate two elements: the mathematical entity related to the problem,  and another one related to the operator . This approach yields a general framework that provides an expression that is valid for any problem as far as we can provide the problem-dependent entity .











\cite{Sutton2011gecco} and \cite{Chicano2011gecco}, used landscape theory to provide a closed-form formula for the expectation after a bit-flip mutation (we repeat this result in Section~\ref{subsec:expectation}). In this work we generalize these results and the one by \cite{Sutton2011foga}, providing closed-form formulas to compute the fitness probability distribution. The new result provides a deeper understanding of the behavior of the mutation operator. We illustrate the approach by providing concrete expressions for the moments of the probability distribution for two well-known problems: Onemax and MAX-SAT. 

Many results coming from the field of fitness landscape analysis provide exact results for the expected fitness of solutions undergoing uniform transformations by evolutionary operators. However, they often cannot say anything about selection operators because the framework does not easily handle the probability of obtaining an improving mutation. This quantity is much harder to derive because it always depends on some instance-dependent structure that is ignored in such analyses. In this paper, we work out how to address the problem of selection by separating the instance-dependent structure from the instance-independent structure. This separation allows us to derive initial results on the probability of producing an improving offspring. As a consequence, we illustrate a way to use the theory of landscapes to derive the expected runtime of a  EA without crossover on Onemax.

The remainder of the paper is organized as follows. In the next section the mathematical tools required to understand the rest of the paper are presented. In Section~\ref{sec:mutation} we present our main contribution of this work: the landscape analysis of bit-flip mutation and the closed-form formulas for the fitness probability distribution. Section~\ref{sec:study} provides particular results for two well-known problems in the domain of combinatorial optimization: Onemax and MAX-SAT. Section~\ref{sec:applications} proves the connection between the results in this paper and the runtime analysis of a  EA. Finally, Section~\ref{sec:conclusions} presents the conclusions and future work.

\section{Background}
\label{sec:background}

In this section we present some fundamental results of landscape theory. We will only focus on the relevant information required to understand the rest of the paper. We refer the reader interested in a deeper exposition of this topic to the survey by \cite{Reidys2002}.

A \emph{landscape} for a combinatorial optimization problem is a triple , where  is a finite or countable solution set,  defines the objective function and  is a \emph{neighborhood function} that maps any solution  to the set  of points reachable from . If  then  is a neighbor of .
The pair  is called \emph{configuration space} and can be represented using a graph  in which  is the set of vertices and a directed edge  exists in  if  \citep{Biyikoglu2007}.  We can represent the neighborhood operator by its adjacency matrix


Any discrete function, , defined over the set of candidate solutions can be characterized as a vector in . Any  matrix can be interpreted as a linear map that acts on vectors in . For example, the adjacency matrix  acts on function  as follows


The component  of this matrix-vector product can thus be written
as:

which is the sum of the function value of all the neighbors of . In the case of binary strings, the minimal-change neighborhood at a point  is the set of Hamming neighbors of . The Hamming neighborhood induces a regular, connected graph , meaning that  is connected and  for a constant , for all . When a neighborhood is regular, the so-called \emph{Laplacian matrix} is defined as . This corresponds to the Laplacian of the graph . Stadler defines the class of \emph{elementary landscapes} where the function  is an eigenvector (or eigenfunction) of the Laplacian up to an additive constant~\citep{Stadler1995landscapes}. Formally, we have the following.

\begin{definition}
Let  be a landscape and  be the Laplacian matrix of the configuration space graph. The landscape is said to be elementary if there exists a constant  that we call the \emph{offset}, and an eigenvalue  of  such that . 
\end{definition}

We use eigenvalues of  instead of  to have positive eigenvalues~\citep{Biyikoglu2007}. In connected neighborhoods like the Hamming neighborhood, the offset  is the average value of the function  evaluated over the entire search space: . In elementary landscapes, the average value  can be usually computed in a very efficient way using the problem data. That is, it is not required to do a complete enumeration over the search space. For a concrete example on the TSP the reader is referred to~\cite{Whitley2008}.

Suppose  is elementary with eigenvalue . For any scalars  and , define the function  as . Clearly,  is also elementary with the same eigenvalue . Furthermore, in regular neighborhoods, if  is an eigenfunction of  with eigenvalue  then  is also an eigenfunction of  (the adjacency matrix of the configuration space graph ) with eigenvalue . The average value of the fitness function in the neighborhood of a solution can be computed using the expression:


If  is elementary with eigenvalue , then the average over the neighborhood is computed as:

which is sometimes referred to as Grover's wave equation~\citep{Grover1992local}. In the previous expression we used the fact that  is an eigenfunction of  with eigenvalue
.


The wave equation makes it possible to compute the average value of the fitness function  evaluated over all of the neighbors of  using only the value .
The previous average can be interpreted as the expected value of the objective function when a random neighbor of  is selected using a uniform distribution. This is exactly the behavior of the so-called \emph{1-bit-flip} mutation~\citep{Garnier1999}.


A landscape  is not always elementary, but even in this case it is possible to characterize the function  as the sum of elementary landscapes, called \emph{elementary components} of the landscape. The interested reader can find examples of elementary landscapes in~\cite{Whitley2008,WhitleySutton2009} and can find more on the elementary landscape decomposition in~\cite{Chicano2011ecj}.

\subsection{Binary Hypercube}
\label{subsec:binary}

The previous definitions are general concepts of landscape theory. Let us focus now on the binary configuration spaces with the Hamming neighborhood, the so-called \emph{binary hypercubes}, which are the configuration spaces we need in the analysis of bit-flip mutation. Let us first present the notation. In these spaces the solution set  is the set of all binary strings of size , formally, . The solution set form an Abelian group with the component-wise sum in  (exclusive OR), denoted with . Given an element , we will denote with  the number of ones of . Given a set of binary strings  and a binary string  we denote with  the set of binary strings that can be computed as the bitwise AND of a string in  and , that is, . For example, . We will denote with  the binary string with position  set to 1 (starting from the leftmost position) and the rest set to 0. We omit the length of the string  in the notation, but it will be clear from the context. For example, if we are considering binary strings in  we have  and .

It is convenient to characterize the neighborhood by a set of group elements  that generate the entire group. Here  is called a \emph{generating set}. The neighborhood of a solution  is just the set . In the binary hypercube, two solutions  and  are neighbors if one can be obtained from the other by flipping a single bit, that is, if the Hamming distance between the solutions, , is 1. Thus, the generating set is composed of every binary string with a single 1: .

We define the sphere of radius   around a solution  as the set of all solutions lying at Hamming distance  from ~\citep{Sutton2010}. We are also interested in these spheres since the probability of reaching a solution  from a solution  using the bit-flip mutation operator is the same for all the solutions in a sphere around . Now we can observe that the solutions in a sphere of radius  around  can be thought as the neighborhood  of  generated by an appropriate generating set . The generating set is composed of all the solutions having exactly  1s: . The notation  used before was selected to be a particular case of this more general neighborhood. We will use the notation . Another particular case is the one of  that generates the identity neighborhood . Each neighborhood has its corresponding adjacency matrix denoted with .



Let us consider the set of all the pseudo-Boolean functions defined over , . We can think of one pseudo-Boolean function as an array of  real numbers, each one being the function evaluation of a particular binary string of . Each pseudo-Boolean function is, thus, a particular vector in a vector space with  dimensions. Let us define the dot-product between two pseudo-Boolean functions as:


Now we introduce a set of functions that will be relevant for our purposes in the next sections: the \emph{Walsh functions}~\citep{Walsh1923}

\begin{definition}
The (non-normalized) Walsh function with parameter  is a pseudo-Boolean function defined over  as:

where the subindex in  and  denotes the -th component of the binary strings  and , respectively.
\end{definition}

We can observe that the Walsh functions map  to the set . We define the \emph{order} of a Walsh function  as the value . Some properties of the Walsh functions are given in the following proposition. A proof of these properties can be found in~\cite{Vose1999}.

\begin{proposition}
Let us consider the Walsh functions defined over . The following identities hold:

where  denotes the Kronecker delta.
\end{proposition}


There exist  Walsh functions in  and according to (\ref{eqn:walsh-dot}) they are orthogonal, so they form a basis of the set of pseudo-Boolean functions. Any arbitrary pseudo-Boolean function  can be expressed as a weighted sum of Walsh functions. We can represent  in the Walsh basis in the following way:

where the \emph{Walsh coefficients}  are defined as:

The previous expression is called the \emph{Walsh expansion} (or decomposition) of . The interested reader can refer to the text by \citet{Terras1999} for a deeper treatment of Walsh functions and their properties.

The reason why Walsh functions are so important for the mutation analysis is because they are eigenvectors of the adjacency matrices  defined above, as the next proposition proves.

\begin{proposition}
\label{prop:eigenvalue-walsh}
In , the Walsh function  defined in (\ref{eqn:walsh-def}) is an eigenvector of the adjacency matrix  based on the generating set  (sphere of radius ) with eigenvalue

where  is the  element of the so-called -th order Krawtchouk matrix , defined as:

for . We assume in the previous expression that  if  or . 
\end{proposition}
\begin{proof}
The Walsh function  is an eigenvector of  if  for some constant , which is the eigenvalue. Taking into account the definition of neighborhood based on the generating set  we can write:

where we used the property (\ref{eqn:sum-arg}) and we can identify the eigenvalue with the left hand side of (\ref{eqn:eigenvalue-walsh}). Let us now prove that this value is exactly . Using the definition of  we can write the series as:

and we can now change the index of the sum from  to . Written with the new index we only need to count for each  how many binary strings  have the property that , that is:


Now we can compute the cardinality of the inner set in (\ref{eqn:card}) using counting arguments. We need to count how many ways we can distribute the  1s in the string  such that they coincide with the 1s of  in exactly  positions. In order to do this, first let us put  1s in the positions where  has 1. We can do this in  different ways. Now, let us put the remaining  1s in the positions where  has 0. We can do this in  ways. Multiplying both numbers we have the desired cardinality:


We should notice here that the cardinality is zero in some cases. This happens when ,  or . However, in these cases we defined the binomial coefficient to be zero and we can keep the previous expression. If we use (\ref{eqn:card2}) in (\ref{eqn:card}) and take into account the definition (\ref{eqn:kra-def}) we get (\ref{eqn:eigenvalue-walsh}).
\end{proof}

In (\ref{eqn:eigenvalue-walsh}) we can observe that the eigenvalue depends only on the order  of the Walsh function. This means that there are at most  different eigenvalues in the considered adjacency matrices. As a consequence, we can decompose any arbitrary function  as a sum of  functions, called \emph{elementary components} of , where each one is an eigenvector of all the adjacency matrices. 

\begin{definition}
Let  be a pseudo-Boolean function with Walsh expansion , we define the order- elementary component of  as:

for . As a consequence of the Walsh expansion of  we can write:

\end{definition}

According to Proposition~\ref{prop:eigenvalue-walsh} the elementary component  is an eigenvector of  with eigenvalue .

\subsection{Krawtchouk Matrices}

Krawtchouk matrices play a relevant role in the mathematical developments of the next sections. For this reason we present here some of their properties. The reader interested in these matrices (also considered polynomials) can read~\cite{Feinsilver2005}. The -th order Krawtchouk matrix is an  integer matrix with indices between  and . In (\ref{eqn:kra-def}) we provided an explicit definition of the elements of a Krawtchouk matrix. But these elements can also be implicitly defined with the help of the following generating function:


From (\ref{eqn:kr-generating}) we deduce that . Observe that  is the constant coefficient in the polynomial. Other properties of the Krawtchouk matrices are presented in the next proposition.
\begin{proposition}
\label{prop:kraw-col}
We have the following identities between the elements of the Krawtchouk matrices:



\end{proposition}
\begin{proof}
With the help of the generating function (\ref{eqn:kr-generating}) we can write:

and identifying the coefficients of the first and last polynomials we have (\ref{eqn:kraw-col}). In order to prove (\ref{eqn:kraw-row}) we can write:

identifying again the coefficients of the first and last polynomials we have (\ref{eqn:kraw-row}).
\end{proof}

Krawtchouk matrices also appear when we sum Walsh functions. The following proposition provides an important result in this line.
\begin{proposition}
\label{prop:krawtchouk}
Let  be a binary string and . Then the following two identities hold for the sum of Walsh functions:

\end{proposition}
\begin{proof}
Given two binary strings , let us denote with  the binary string of length  composed of all the bits of  in the positions  where . The string  acts as a mask for . This notation allows us to simplify the sums in (\ref{eqn:sum-walsh-r}) and (\ref{eqn:sum-walsh}):



\end{proof}





\section{Analysis of the Mutation Operator}
\label{sec:mutation}

The bit-flip mutation operator transforms an arbitrary element  to  by changing the value of each bit of  with probability . In the literature it is common to use the value  that, in expectation, changes one bit in each solution. However, if , the mutation operator can transform  into any element of the search space with positive probability. In the following, we denote with  the random variable on  that represents the element in  reached after applying the bit-flip mutation operator with probability  to solution .

\begin{lemma}
\label{lem:prob-mut}
Given two solutions , the probability of obtaining  after a bit-flip mutation over  is

\end{lemma}
\begin{proof}
The solution  can only be obtained if all the bits that differ from the solution  are mutated and the other ones are kept unchanged. Since the number of differing bits is  and each bit is individually changed with probability  we obtain the claimed result.
\end{proof}

We are interested in , the objective function value after the mutation of a solution. This value is also a random variable and we want to analyze its probability distribution. 
Given a particular search space, directly enumerating this distribution by evaluating every solution is not tractable. However, the theory of landscapes provides tools for extracting information from this probability distribution in an efficient way. This information arises from the moments of the probability distribution. In the following sections we analyze these moments.

\subsection{Expectation}
\label{subsec:expectation}

Let us start by computing the expected value of . The expected value is easy to compute in the case of the elementary components of a function . The result of the next theorem was previously published by~\cite{Chicano2011gecco}. \cite{Sutton2011gecco} also studied the expected value after mutation and found that it must be a polynomial in . We, however, present here the result and its proof because the notation is slightly different from the one used in the previous works.

\begin{theorem}
\label{thm:mut-exp-elementary}
Let  be a binary string,  a function,  its order- elementary component and let us denote with  the random variable that represents the element in  reached after applying the bit-flip mutation operator with probability  to solution . The expected value of the random variable  is

\end{theorem}
\begin{proof}


Using the generating function for Krawtchouk matrices (\ref{eqn:kr-generating}) we can simplify the term within the parentheses in the following way:



The previous development is valid if . In the case  we cannot divide by , but even in this case the final result holds. To prove this we just have to consider that the term  is zero except for  and  is always 1. Then we can write

where we used (\ref{eqn:kraw-row}) and the fact that . We finally obtain the claimed result for all the possible values of .
\end{proof}

As a direct consequence of the previous theorem we can compute the expected value of  for an arbitrary function with the help of the decomposition of the function into elementary components.

\begin{corollary}
Let  be a binary string,  a function and  the solution reached after applying the bit-flip mutation operator with probability  to solution . The expected value of the random variable  is

where  is the order- elementary component of .
\end{corollary}
\begin{proof}
We can write  as the sum of its elementary components as . Then, we can compute the expected value as:

where we used the result of Theorem~\ref{thm:mut-exp-elementary}.
\end{proof}

\subsection{Higher Order Moments}
\label{subsec:higher-moments}

Equation (\ref{eqn:expectation-decomp}) can be used to compute the expected value of . We may also use it to extend to higher order moments, as in the following theorem. 
\begin{theorem}
Let  be a binary string,  a function and  the solution reached after applying the bit-flip mutation operator with probability  to solution . The -th moment of the random variable  is

where  is the order- elementary component of .\footnote{We use this notation instead of  to simplify the expressions, but  should not be confused with  to the power of .}
\end{theorem}
\begin{proof}
By definition,  can be expressed as the expectation of the random variable . Then, using (\ref{eqn:expectation-decomp}) we can write:

\end{proof}

We define the -th moment . We can observe from (\ref{eqn:cth-order}) that all the higher-order moments are polynomials in , just like the expectation (first order moment). 

Let us now introduce some new notation. Let us denote with  the vector of moments, that is, the -th component of this vector is the -th moment. We do not limit the number of components of this vector, we can consider it as an infinite-dimensional vector. Later we will see that only a finite number of elements of this vector would be required for our purposes. We define the matrix function  as  where  and . Let us also define the vector  as  for . 

Using the new notation we can write (\ref{eqn:cth-order}) in vector form as:

or in a compact way:

where  and  are multiplied using the matrix product. This new form of writing (\ref{eqn:cth-order}) has the property of expressing the vector of moments of  as the product of a matrix that depends on the objective function (and solution ) and a vector that depends on the mutation operator and its parameter . In some sense, we can claim that (\ref{eqn:muc-vector}) decomposes the moments in a problem-dependent part, , and an operator-dependent part, . This is the kind of equation we are looking for, since it can be applied to different problems provided that the problem-dependent part for each one is computed and we do not need to re-compute the operator-dependent part. In the same way, it can also be applied to any parameter of the operator (value of ) without recomputing the problem-dependent part. 

We should notice here that the first column of matrix  provides the statistical moments of the fitness distribution in the whole search space considering a uniform random distribution. Thus,  is the average value of the evaluation function in the search space,  is the second order moment, and so on. We can prove this by setting  in (\ref{eqn:muc-vector}) because a probability of  for bit-flip mutation is equivalent to a uniform random selection of a solution in the search space. All the elements but the first in  vanish and we get the claimed result.

\subsection{Computing the Matrix Function }
\label{subsec:computing-f}

The computation of the matrix function  is not efficient in general. \cite{Sutton2011tcs} provide an algorithm to compute the Walsh decomposition of . Using this Walsh decomposition it is possible to obtain the elementary components of , as required for the computation of . If the Walsh decomposition of  is:

then the Walsh decomposition of the -th power  is:


This procedure has the advantage that it is general and can be used with any function defined over bitstrings. The drawback, however, is its inefficiency when  is high. Thus, for each particular problem, we should analyze the objective function in order to find an efficient way of evaluating the matrix function  in an arbitrary solution . In Section~\ref{sec:study} we analyze two problems and provide an efficient computation of this matrix function for these problems.

In some cases, the efficient (polynomial time) evaluation of  can only be possible if . This happens for example in the SAT problem as the following theorem states.

\begin{proposition}
Let us consider the SAT problem and an evaluation function  that takes value 1 if  satisfies the propositional formula and 0 otherwise. If there exists a polynomial time algorithm for computing  then .
\end{proposition}
\begin{proof}
The value  is the average value of the objective function in the whole search space. Since  can only take values 0 and 1, if  then the formula is satisfiable. Thus, if we find a polynomial time algorithm to evaluate  we can solve the decision problem in polynomial time. But, as SAT is -complete then .
\end{proof}

As a consequence of the previous proposition we cannot ensure that an efficient evaluation of the matrix function  exists in general. The complexity of computing   depends on the problem.






\subsection{Fitness Probability Distribution}
\label{subsec:fitness-prob-distr}

With the help of the moments vector  we can compute the probability distribution of the values of  in a mutated solution. In order to do this we proceed in the same way as \cite{Sutton2011foga}. 

Let us call  to the  possible values that the function  can take in the search space. Since we are dealing with a finite search space,  is a finite number (perhaps very large). We are interested in computing  for . In order to simplify the notation in the following we define the vector of probabilities  as .

\begin{theorem}
Let us consider the binary hypercube and let us denote with  the possible values that the objective function  can take in the search space, where  for . Then, the vector of probabilities  can be computed as:

where the matrix function  is limited to the first  rows and  denotes the Vandermonde matrix for the  values, that is,  for .
\end{theorem}
\begin{proof}
We can compute the -th moment  using the following expression: 

We can write this in vector form as:

Using (\ref{eqn:muc-vector}) we can write:

and solving  we finally get (\ref{eqn:fitness-probdist}). The determinant of the Vandermonde matrix is ~\citep[pp. 17-18]{Mirsky1955} and the matrix is nonsingular if and only if all the  values are different. This is our case, so the Vandermonde matrices we use are invertible.
\end{proof}

Again we can observe that  is the product of a term that is problem-dependent and a vector that depends on the parameter of the mutation . From (\ref{eqn:fitness-probdist}) it is clear that each particular probability  is a polynomial in .


We can also compute the cumulative density function  defined by:


We can write the previous equation in vector form as:

where  is the lower triangular matrix defined by 


We can notice again that each element of  is a polynomial in . The component  is the probability of reaching a solution  with function value  after the mutation with parameter . If  has function value , then  is the probability of improving the function value of solution  in one application of bit-flip mutation. For problems in which the matrix  can be efficiently computed the expression  could be used as the base for a new mutation operator that tries to maximize the probability of an improving move. 


\section{Case Studies}
\label{sec:study}

In this section we present the elementary landscape decomposition of two well-known problems and their powers (the  matrix). With this decomposition we can compute the probability distribution of any solution after mutation. We start by analyzing a toy problem: Onemax. In Section~\ref{subsec:max-sat} we analyze MAX-SAT.

\subsection{Onemax}
\label{subsec:onemax}

Onemax is a linear pseudo-Boolean fitness function that is often used in the analysis of evolutionary algorithms. In our case, we consider the sum of all order-1 Walsh functions, which is related to Onemax by a simple linear transformation. That is:


The objective function in Onemax is  (the number of ones in ).
Maximizing the number of ones in  (original Onemax problem) is equivalent to minimizing .
We should notice here that  can take values in the range  by steps of~. That is, the range of  is the set . Although we study here the function  defined in~(\ref{eqn:f-onemax}) for the sake of simplicity, we will see at the end of this section that the probability distribution after mutation of the regular Onemax function is the same as .

The following lemma provides intermediate results that will be useful in the search for an expression for  .

\begin{lemma}
\label{lem:sum-walsh}
The sum of all the Walsh functions with the same order is related to the Krawtchouk matrices by means of the following identity:

\end{lemma}
\begin{proof}
The claim follows immediately from Eq. (\ref{eqn:sum-walsh-r}) when .\end{proof}

\begin{theorem}
\label{thm:fmatrix-onemax}
The matrix function  for the objective function  defined in (\ref{eqn:f-onemax}) depends only on  and its elements satisfy the following identity:

where  is the -th Krawtchouk matrix and  is the matrix defined as:

\end{theorem}

\begin{proof}
Let us write the Walsh decomposition of . Given a binary string , the Walsh coefficient  of  is

where we used the result of Lemma~\ref{lem:sum-walsh} and introduced the matrix  to simplify the notation. Now we can sum together all the Walsh functions of the same order  to find the elementary component :

where we used Lemma~\ref{lem:sum-walsh} in the last step.
\end{proof}

In the following proposition we provide a property of the  matrix that is useful to simplify the computation of the matrix.

\begin{proposition}
All the elements  in which  is odd are zero. 
\end{proposition}
\begin{proof}
We can develop (\ref{eqn:xi}) to write:

If  is odd all the terms in the sum are zero and, thus, .
\end{proof}

Theorem~\ref{thm:fmatrix-onemax} claims that  depends only on  and not on the solution itself. As a consequence, the vector of probabilities  depends only on . But, according to (\ref{eqn:f-onemax}),  is related to the fitness value of a solution by , and the vector of probabilities  depends only on the fitness level of the solution we are evaluating. We can then build a matrix, denoted with , where element  is the probability of generating a solution with fitness  using bit-flip mutation from a solution with fitness . This matrix depends on  (probability of mutation), but we omit  in the notation to make it simpler. The expression for  can be obtained using simple counting arguments, without the need of the mathematical framework developed in Section~\ref{sec:mutation}. However, in the next theorem we provide an expression for this matrix using our mathematical framework. The purpose of this result is twofold: it proves that   can be computed using our framework and, to the best of our knowledge, it provides a
previously unknown expression for  involving Krawtchouk matrices. 

\begin{theorem}
Given the objective function defined in (\ref{eqn:f-onemax}) over , the probability of reaching a solution with fitness  when bit-flip mutation with probability  is applied to a solution with fitness  is given by:

where .
\end{theorem}
\begin{proof}
First, we will express the matrix  as a product of two other matrices.

where we used the Vandermonde matrix and we introduced a new matrix . This is the Krawtchouk matrix of order  in which the rows are reversed. Then, we have . Let us now define the vector  as the -th column of the -th order Krawtchouk matrix. We can write the matrix function  defined in (\ref{eqn:fmatrix-onemax}) in a compact way as:

where the function  maps a vector into a matrix having the vector in the diagonal.
If we introduce this compact expression of  in (\ref{eqn:fitness-probdist}) we obtain:

where the symbol  denotes the Hadamard product\footnote{The Hadamard product of two matrices with the same dimension is the element-wise product of the matrices.} of matrices and we used the fact that . 

According to the definition of , it must be related to  by the following equation:


Since ,  if and only if  and using (\ref{eqn:pi-matrix}) we have:

and we get (\ref{eqn:varpi-onemax}) just considering that .
\end{proof}

In the following proposition we provide two properties of the  matrix that are useful to reduce the computational complexity of its computation.

\begin{proposition}
\label{prop:varpi}
The matrix  has the following properties:

where .
\end{proposition}
\begin{proof}
The first property is a consequence of an analogous property of the Krawtchouk matrices:  \cite[p. 179]{Terras1999}. We can write:


The second property is a consequence of Proposition~\ref{prop:kraw-col}:

\end{proof}

At this point we can discuss the utility of the  matrix. We can see  as a practical substitute for all the probability vectors  in the case of the objective function  defined in (\ref{eqn:f-onemax}). In general, the components of the previous vector depend on the solution . However, in the particular case of the Onemax-related function (\ref{eqn:f-onemax}) the components depend only on the fitness level  the solution has. This way we can forget the concrete solution  and focus only on the fitness levels . Furthermore, the number of fitness levels is  and the complexity of computing any element of  using (\ref{eqn:varpi-onemax}) is , where we assume that the Krawtchouk matrix  is precomputed\footnote{Krawtchouk matrix  can be precomputed in  using Proposition 2.1 of~\cite{Feinsilver2005}.}. This means that we can compute the probabilities of reaching any fitness level from any other one after bit-flip mutation in . That is, we obtain in polynomial time a practical piece of information that summarizes the behavior of bit-flip mutation in this problem. We will see in Section~\ref{sec:applications} how this information can be used.

We derived the  matrix for only one objective function. Now we wonder if similar  matrices can be derived for other objectives functions. The answer to this question is not easy in general, but the next results gives a first answer in this line. Let us first formally define the property that allows one to compute a matrix like .

\begin{definition}
Let  be an objective function and let us call  to the different values it can take. We say that the function  \emph{has a fitness-dependent distribution} for a unary operator if the probability distribution of the objective value after applying the operator to any solution does only depend on the objective value of the initial solution. In formal terms, if  is a random variable that represents the application of the unary  operator to , we have

for all the possible  values. If this happens, then we can define a matrix  whose elements are:

\end{definition}

There is a trivial family of functions having fitness-dependent distributions for any unary operator. It is the family of injective functions. In these functions each particular solution has a unique image and the fitness-dependency condition trivially holds. However, the probability matrix in this case has size  (the size of the search space squared), what makes this treatment impractical. Even simple linear pseudo-Boolean functions (such as BINVAL) can have this property. 
The next theorem claims that the property of having a fitness-dependent distribution can be kept even after some simple manipulations of the fitness function.

\begin{theorem}
\label{thm:transformation}
Let  be an objective function having a fitness-dependent distribution for the unary operator  and let us call  the associated probability matrix, where we used the name of the function as superindex.
Then, the function , which is a composition of  with another function, also has a fitness-dependent distribution for  under the following conditions:
\begin{itemize}
\item When  for  a strictly increasing function. The probability matrix does not change: .
\item When  for  a strictly decreasing function. The probability matrix flips its rows and columns: .
\item When  for  and  commute with the  operator: . The probability matrix does not change: .
\end{itemize}
\end{theorem}
\begin{proof}
First, we can observe that in the three cases the number of values that  can take is the same as the number of values that  can take, . Then, let us denote with  these values for the  function. We will use the notation  to refer to the corresponding values of .

Let us start with the first case:  and  strictly increasing. In this case  for all . And the property of having a fitness-dependent distribution trivially holds for  since if  then  and consequently , what implies . Regarding the probability matrix we have:


In the second case, in which  for  a strictly decreasing function, we can prove that  has a fitness-dependent distribution with an argument similar to the first case. However, the probability matrix is different due to the change in the order of the values . Since  is strictly decreasing we have . Thus, the elements of the probability matrix are given by:


Finally, let us prove the last case. The values that the function takes do not change, that is: . If  then , what implies  by hypothesis. But if  commutes with  then we have:

where we used the definition  in the last step and the fact that .

As a consequence we have  and  has a fitness-dependent distribution for . The elements of the probability matrix are:



\end{proof}

The only condition imposed to the unary operator in the previous theorem is the commutation with . Fortunately, the bit-flip mutation operator commutes with . Furthermore, we provide in the next proposition a result that generalizes that of the mutation operator.

\begin{proposition}
\label{prop:commutation}
If a unary operator  has the property  for a real function  then it commutes with the  operation.
\end{proposition}
\begin{proof}
For any  we can write:

and we have the commutation property.
\end{proof}

The bit-flip  mutation satisfies the hypothesis of the previous proposition, as Lemma~\ref{lem:prob-mut} states.
Now, we can combine the results of Theorem~\ref{thm:transformation} and Proposition~\ref{prop:commutation} to provide a concrete result for the Onemax-related functions.

\begin{proposition}
\label{prop:onemax-family}
All the objective functions of the form

where  is a strictly monotone function have a fitness-dependent distribution for the bit-flip mutation operator and the probability matrix is the one defined in (\ref{eqn:varpi-onemax}).
\end{proposition}
\begin{proof}
First, we observe that in the case of the sum of order-1 Walsh functions (\ref{eqn:f-onemax}) the probability matrix  does not change even in the case in which we compose the functions with a strictly decreasing function, since  and  according to Proposition~\ref{prop:varpi}. Then, based on the results of Theorem~\ref{thm:transformation} and Proposition~\ref{prop:commutation} we only need to express  as a strictly monotone function of the objective function  defined in (\ref{eqn:f-onemax}). This expression is:

\end{proof}

A direct consequence of the previous result is that even although we focused in this section on the objective function defined in (\ref{eqn:f-onemax}) instead of the Onemax objective function, the probability matrix  is valid also for the original Onemax function. Furthermore, it is also valid for any strictly monotone function composed with the Onemax function.




\subsection{MAX-SAT}
\label{subsec:max-sat}



The MAX-SAT problem is a well-known -hard problem related to the satisfiability of Boolean formulas. An instance of this problem is composed of a set of clauses . A clause is a disjunction of literals, each one being a decision variable  or a negated decision variable . The MAX-SAT problem consists in finding an assignment of Boolean values to the literals in such a way that the number of satisfied clauses is maximum. Let us assume that there exist  Boolean decision variables.
For each clause  we define the vectors  and  as follows \citep{Sutton2009}:


We will omit the argument of the vectors (the clause) when there is no confusion. According to this definition . We should note here that the previous notation allows us to express the empty clause, , with . But it is not possible to express the top clause . We will need a special treatment of the top clause in the following.

The objective function of MAX-SAT is defined as


A clause  is satisfied with  if at least one of the literals is true (we assume the usual identity true=1 and false=0). Using the vectors  and  we can say that  is satisfied by  if .

\cite{Sutton2009} provide the Walsh decomposition for the MAX-SAT problem. Let the function  evaluate one clause . 
The Walsh coefficients for  are:

If the clause  is  then the only nonzero Walsh coefficient is .

For the sake of simplicity in the mathematical development, instead of using  in the following, it is better to use . The Walsh coefficients for  are:


We will also focus on the fitness function  defined as:

Maximizing  is equivalent to minimizing .



The following lemma provides the elementary landscape decomposition of . 
\begin{lemma}
\label{lem:g-eld}
The -th elementary component of  is

\end{lemma}
\begin{proof}
With the help of (\ref{eqn:awm-g}) we can write

\end{proof}


The next two lemmas provide intermediate results related to the  functions that are required in the proof of the main theorem in this section.

\begin{lemma}
\label{lem:power-g}
The -th power of  for  is:

\end{lemma}
\begin{proof}
The function  takes only values 0 and 1. If  we have .
\end{proof}





\begin{lemma}
\label{lem:prod-g}
Given a family of clauses , the product of functions  is:

where  is the disjunction of the family of clauses. For the previous expression to be true even in the case in which the family of clauses is empty we define .
\end{lemma}
\begin{proof}
The function  is 0 when the clause  is satisfied. Thus, a product of  functions will be 0 when any of the clauses is satisfied and 1 if none of the clauses is. This behavior is the same as the function  associated with the disjunction of the clauses. This disjunction is also another clause. 
\end{proof}





The following theorem provides the expression for the matrix function  for  defined in (\ref{eqn:g-maxsat}). 

\begin{theorem}

The matrix function  for the objective function  defined in (\ref{eqn:g-maxsat}) is:

where the  matrix is defined by the following recurrence equations:

\end{theorem}
\begin{proof}
Let us number the clauses in  from  to  and let us denote with  the -th clause. We can write  as

where we defined  as 


Using (\ref{eqn:f-matrix-g-inter}) and (\ref{eqn:g-eld}) we obtain (\ref{eqn:matrix-f-maxsat}).

In order to complete the proof we only need to justify the equations (\ref{eqn:upsilon-base}) and (\ref{eqn:upsilon-rec}) based on the definition (\ref{eqn:upsilon-def}). 
In the following we will use the notation  to denote the set of numbers from  to .
When  the sum of the multinomial coefficients is:

In order to extend the previous sum to the value  we can just define  as in (\ref{eqn:upsilon-base}) and we obtain the recurrence equation in (\ref{eqn:upsilon-rec}). Now we can observe that (\ref{eqn:upsilon-rec}) is valid even in the case in which .
\end{proof}

By the definition of  in (\ref{eqn:upsilon-def}) it is clear that  if . As a consequence, the sum in (\ref{eqn:matrix-f-maxsat}) must consider only the subsets  of at most  elements if we are interested in the elementary landscape decomposition of the -th power of . The computation of the  and  vectors in (\ref{eqn:matrix-f-maxsat}) can be done in  at most, since we have to explore up to  bits of up to  clauses (it can be much less in practice if the number of literals per clause is low). Thus, the complexity of computing the elementary components of  is , where we assume that the matrices  and  are precomputed.



\section{Connection to Runtime Analysis}
\label{sec:applications}



The results we present in this section represent, to the best of our knowledge, the first connection between landscape theory and runtime analysis, and this is, in fact, the reason why we think they are relevant. They are an application of the results of Sections~\ref{sec:mutation} and~\ref{sec:study} to the computation of the first hitting time of a  EA. The results themselves are not new or significant for the runtime community. We use the Markov chain framework by \cite{He:Yao2003}, which has important limitations when the goal is to find asymptotic bounds for runtime. With this framework we are able to compute exact expressions for the expected runtime as a function of , the probability of flipping a bit in the mutation, but we are not able to find asymptotic expressions or make conclusions about the runtime when  is large, which is the main goal of the runtime analysis community.

When one is interested in computing bounds for the runtime required by an evolutionary algorithm to solve an optimization problem, it is quite common to analyze the probability of improving a solution in one iteration of the algorithm. This is the way, for example, in which an upper bound of  is derived for the Onemax problem solved with a  EA using bit-flip with probability  \citep[p. 39]{Neumann2010}. These probabilities of improvement are not usually exactly computed, but an asymptotic lower bound of the probability is used instead. Thus, an upper bound of the expected runtime is derived instead of a precise expression.

In Section~\ref{sec:mutation} we showed how we can compute the probability distribution of the objective values after mutation. In Section~\ref{sec:study} we found that for a family of functions that includes Onemax, the probability distribution only depends on the value of the fitness function in the current solution and, thus, we could define a matrix , that summarizes the behavior of the algorithm in one step. The question we want to answer in this section is, can we use the  matrix to provide an expression of the expected runtime of an evolutionary algorithm? In the next subsections we will show how a precise expression for the expected runtime of a  EA can be derived using the  matrix. In Algorithm~\ref{alg:1+lambda-EA} we show the pseudocode of a  EA, where (abusing notation slightly) we use  to denote a random solution that is the result of applying the bit-flip mutation operator to .

\begin{algorithm}[!ht]
\begin{algorithmic}
\STATE   RandomSolution();
\WHILE{ is not a global optimum}
\FOR{ to }
\STATE ;
\IF{}
\STATE ;
\ENDIF 
\ENDFOR
\ENDWHILE
\end{algorithmic}
\caption{Pseudocode of a  EA.}
\label{alg:1+lambda-EA}
\end{algorithm}



\subsection{Runtime analysis of -EAs}


Based on the probability matrix , that only assumes one single application of the mutation operator, we can define a new probability matrix  related to the generation of  offspring using bit-flip mutation and selecting the best one. This new probability matrix must reduce to  when . The element  is the probability of obtaining a solution with fitness value  after applying bit-flip mutation  times with probability  to a solution with fitness value  and taking the offspring with the highest fitness. The following proposition provides an expression for .

\begin{proposition}
The probability matrix  is defined as

\end{proposition}
\begin{proof}
The element  is exactly the probability of obtaining at least one solution with fitness value  and no solution with a higher fitness value in the  trials. This is exactly the probability of obtaining the  solutions with fitness value lower than or equal to  (first term) minus the probability of obtaining the solutions with fitness value lower than  (second term).
\end{proof}

We can observe in (\ref{eqn:varpi-lambda}) that . We must recall here that  is a polynomial in  because  is also a polynomial in . Now we analyze the runtime of the  EA with the help of the Markov chain framework presented by \cite{He:Yao2003}. The first step is to present the transition matrix (we assume maximization):

where . If the probability  of flipping a bit is , then the previous transition matrix will have only one absorbing state that corresponds to the solutions with the highest fitness value .

Now we can use some results from the Markov chain theory \citep{Iosifescu1980} to compute the expected runtime of the  EA. The  matrix can be written in the form:

where  is a column vector and  is a  submatrix with the transition probabilities of the transient states in the Markov chain. The fundamental matrix is , and the expected runtime (number of iterations) of the  EA starting in a solution with fitness value  and  is given by the -th component of the vector of mean absorption times . This vector is computed as . From a computational point of view, the vector can be efficiently computed by solving the following linear equation system:

since  is an upper triangular matrix and the system can be solved in . The components of  will be, in general, fractions of polynomials in . The vector  has only  components indexed by number from 0 to , but for the sake of completeness we can extend it with an additional component , which is the expected runtime of the algorithm when the initial solution is the global optimum.

Assuming that the algorithm starts from a random solution, the expected runtime is given by

where  is the set of solutions and  is the set of solutions with fitness .

The expected runtime (\ref{eqn:expected-1+l}) is not an approximation or bound, it is the exact expression of the expected runtime as a function of , the probability of flipping a bit. However, this expression will only be practical if 1) we can define the  matrix in the problem we are interested and 2) the evaluations of this matrix can be efficiently done in a computer. These conditions limit the number of problems whose runtime can be analyzed using this approach. However, we found in Section~\ref{subsec:onemax} that for any monotone function of Onemax we can efficiently construct and evaluate the  matrix. In the next subsection we focus on Onemax.

\subsection{Runtime of  EA for Onemax}

The Onemax problem has been studied in the literature on runtime analysis many times. \cite{Garnier1999} derived an expression for the transition probability matrix of the  EA for the Onemax function that was later reported by \cite{He:Yao2003}. Their expression is the same as (\ref{eqn:transition-matrix}) for . Tight upper and lower bounds have been derived for the  EA using different mutation rates. 
Recently, \citet{Witt2013tight} proved that the  EA optimizes all linear functions (including Onemax) in expected time , and the expected optimization time is polynomial as long as  and . \citet{Jansen2005} proved that using a  EA the expected number of iterations after reaching the global optimum is .
In summary, the Onemax problem is well-known and the content of this section adds not too much to the current knowledge on this problem. The goal of this section is, thus, to obtain the same results from a different perspective, that of landscape analysis. The advantage of this approach is that with an exact expression of the expected runtime we can find a precise answer to some concrete questions for some particular instances. The disadvantage is that the expression is quite complex to analyze and we need to use numerical methods, so it is not easy to generalize the answers obtained. 


Let us first start by studying the  EA. Taking into account the  matrix defined in (\ref{eqn:varpi-onemax}) for Onemax, the expected number of iterations can be exactly computed as a function of , the probability of flipping a bit. Just for illustration purposes, we present the expressions of such expectation for :


We can observe how the expressions grow very fast as  increases. The factor  is always present in the denominator for , what means that when  takes extreme values,  or , it is not possible to reach the global optimum from any solution, since the algorithm will keep the same solution if  or will alternate between two solutions if . However, when  the probability  is valid, furthermore, is optimal, because if the global solution is not present at the beginning we can reach it by alternating the only bit we have. In Figure~\ref{fig:onemax} we show the expected runtime as a function of the probability of flipping a bit for  to 7. We can observe how the optimal probability (the one obtaining the minimum expected runtime) decreases as  increases.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.95\textwidth]{exp-runtime1-eps-converted-to.pdf}
\caption{Expected runtime of the  EA for Onemax as a function of the probability of flipping a bit. Each line correspond to a different value of  from 1 to 7.}
\label{fig:onemax}
\end{figure}

Having the exact expressions we can compute the optimal mutation probability for each  by using classical optimization methods in one variable. In particular, for  the optimal value is  as we previously saw and for  we have to solve a cubic polynomial in order to obtain the exact expression. The result is:

which is slightly higher than the recommended value . Observe, however, that this result does not contradict the ones in~\cite{Witt2013tight}, since Witt's work provides asymptotic expressions and discards low-order terms, while we are working here with expressions for low  values. In accordance to Witt's work, we would expect the optimal probability of mutation  to approximate the  value, and this is what happens.
As we increase , analytical responses for the optimal probability are not possible and we have to apply numerical methods. In our case we used the Newton method in order to find a root of the equation . Some results up to  can be found in Table~\ref{tab:optimal-p}. A fast observation of the results reveals that the optimal probability is always a little bit higher than the recommended .








\begin{table}[!ht]
\begin{center}
\begin{tabular}{|cr@{.}lr@{.}l||cr@{.}lr@{.}l|}
\hline
 
& \multicolumn{2}{c}{} 
& \multicolumn{2}{c||}{} 
&  
& \multicolumn{2}{c}{} 
& \multicolumn{2}{c|}{}  \\
\hline
1 & 1&00000 & 0&500 & 20 & 0&06133 & 127&453 \\
2 & 0&56122 & 2&959 & 30 & 0&04046 & 222&079 \\
3 & 0&38585 & 6&488 & 40 & 0&03009 & 325&900 \\
4 & 0&29700 & 10&808 & 50 & 0&02391 & 436&580 \\
5 & 0&24147 & 15&758 & 60 & 0&01981 & 552&734 \\
6 & 0&20323 & 21&222 & 70 & 0&01690 & 673&445 \\
7 & 0&17526 & 27&120 & 80 & 0&01473 & 798&059 \\
8 & 0&15391 & 33&391 & 90 & 0&01304 & 926&088 \\
9 & 0&13710 & 39&990 & 100 & 0&01170 & 1057&151 \\
10 & 0&12352 & 46&882 &    &  \multicolumn{2}{c}{~} &      \multicolumn{2}{c|}{~}         \\
\hline 
\end{tabular}
\end{center}
\caption{Optimal probability values for an  EA solving Onemax.}
\label{tab:optimal-p}
\end{table}


Before we go further, we could question the use of an approximate method (the Newton method) over an exact expression to find the optimal probability for mutation. In particular, as we get approximate values anyway, why not directly run the  EA enough times to get an accurate enough approximated value for the optimal probability? Although in both cases we end with an approximated value, the approximation is done at a different level and using the Newton method, we get higher accuracy in less time. Let us explain this in detail. First, we have to say that given a probability of bit-flip  the computation of the first-hitting time using~(\ref{eqn:expected-1+l}) is very fast and the result we obtain is exact up to the machine precision. If we want to obtain the expected first-hitting time running the algorithm we need to run it several thousand times to get a good confidence interval and the final approximation will be coarser than using the exact formulas. Just as an illustration we run the algorithm 1,000 times for ,  and , and it took 193 s to find an expected runtime of  with 95\% confidence. On the other hand the evaluation of the exact expression was done in  s and found an expected runtime of  with 11 decimals precision\footnote{The experiments were done in a MacBook Pro with an Intel Core i7 processor running at 2.8~GHz and 4~GB of DDR3 RAM memory.}.
Second, if we want to obtain the optimal probability for mutation we have to apply a numerical method. Using the exact formulas, we applied the Newton method and after several steps we obtain an approximated optimal probability . In order to get an optimal mutation probability using the completely empirical approach we need to apply again a numerical method like the false position method (the Newton method cannot be applied now because we cannot compute derivatives). In order to evaluate each probability  we need to run the algorithm thousands of times and, in the end we can only obtain an approximated value for the expected runtime. As an illustration we can say that the execution of the Newton method for  stopped after ~s, which is the time required to run the  EA algorithm around  times in our machine. However, with 40 independent runs the precision of the expected runtime is very low. In summary, the completely empirical method requires much more time than the Newton method applied to the exact formulas for the same precision.


From previous work we know that the optimal probability is in the form  for a constant . We can use the results obtained by numerical analysis to find the value of  and check the dependency with . That is, using the optimal probability  shown in Table~\ref{tab:optimal-p} we can compute  in order to see what is the value of . In Figure~\ref{fig:constant} we plot  as a function of . We can observe that the optimal probability is not  for a fixed . The value of the constant  is higher than 1 and depends on . However, we can observe a clear trend  as  tends to . The maximum value for  is reached in  and the value is .

\begin{figure}[!ht]
\centering
\includegraphics[width=0.95\textwidth]{constant1-eps-converted-to.pdf}
\caption{The value of the constant  in the optimal probability  for Onemax instances from  to .}
\label{fig:constant}
\end{figure}

It is also well-known that for this optimal probability the expected runtime is . We can also check this using numerical analysis. We used the optimal expected runtime for this computation and found the best fit model including  and  terms. The result is:

where we can observe how the factor in front of the  term is near , which is the theoretically predicted factor for  and large values of ~\citep{Witt2013tight}.


Let us now study the expected runtime for different values of . In this case we fix the size of the problem to  and we analyze the expected runtime using  for  to 50. The results are shown in Figure~\ref{fig:lambda} in both, natural scale and log-log scale.

\begin{figure}[!ht]
\centering
\subfigure[Expected runtime as a function of ]{
\includegraphics[width=0.47\textwidth]{lambda1-eps-converted-to.pdf}}
\subfigure[Log-log plot of the expected runtime against ]{
\includegraphics[width=0.47\textwidth]{loglambda1-eps-converted-to.pdf}}
\caption{The expected runtime of a  EA with  and  for  to 50.}
\label{fig:lambda}
\end{figure}

The log-log plot is almost a straight line, what suggests that we can express the expected runtime as a potential function of . The best linear regression model for the log-log plot is:

or equivalently:


However, we cannot compare this model with the result of \cite{Jansen2005} of . Thus, we found the best fit model in the form  and we got:


The value of the constant  is small enough to say that the expected runtime is approximately divided by  when we generate  offspring. 





\section{Conclusions}
\label{sec:conclusions}

We analyzed the bit-flip mutation operator from the point of view of landscape theory. In particular, we derived closed-form formulas for all the statistical moments of the fitness distribution of a mutated solution. These moments can be expressed as a polynomial in , the probability of flipping a bit. Using the moments we derived an expression for the probability mass function of the fitness value after applying bit-flip mutation to a given solution. The expression takes an elegant matrix form in which we can distinguish a problem-dependent part and an operator-dependent part. The problem-dependent part can be obtained using the elementary landscape decomposition of the objective function of the problem and their powers. The operator-dependent part depends only on the probability .

We also derived the problem-dependent part for two well-known problems: Onemax and MAX-SAT. In the first case, the problem-dependent part is especially simple and efficient to compute. This allowed us to derive the exact expression for the runtime of an  EA for solving Onemax, finding a connection between landscape theory and runtime analysis. Using this expression we obtained the optimal probability for bit-flip mutation as a function of , the number of bits.

It is possible to analyze other operators in the same way we did with bit-flip mutation. Thus, we think that an interesting future line of research could be the application of similar ideas to find the probability mass function of the distribution after the application of several chained operators. In particular, recent developments in landscape theory suggest that it is possible to analyze the fitness distribution of the offspring of two parent solutions when the uniform crossover is applied~\citep{Chicano2012crossover}. These results together with the connection between landscape theory and runtime analysis shown in this paper could provide a natural way of introducing crossover in the runtime results. 


\section{Acknowledgements}

This work has been partially funded by the Spanish Ministry of Economy and Competitiveness and FEDER under contract TIN2011-28194 (the
roadME project), and by the Air Force Office of
Scientific Research, Air Force Materiel Command, USAF, under grant
number FA9550-08-1-0422. The U.S. Government is authorized to
reproduce and distribute reprints for Governmental purposes
notwithstanding any copyright notation thereon.

The authors would also like to thank the organizers and participants
of the seminars on Theory of Evolutionary Algorithms (10361 and 13271) at
Schlo\ss\ Dagstuhl - Leibniz-Zentrum f\"ur Informatik.


\bibliographystyle{apalike}
\bibliography{landscapes}
\end{document}
