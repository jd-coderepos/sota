\documentclass{article}
\usepackage[T1]{fontenc} 
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{fullpage}
\usepackage{url}
\usepackage{epsfig,xspace}
\usepackage[noend]{algorithmic}
\usepackage{color}
\usepackage{amsbsy,latexsym}
\usepackage{amsfonts,amsmath,amssymb}
\usepackage{url}
\usepackage{multirow, colortbl}
\usepackage[T1]{fontenc}
\usepackage{enumerate}
\usepackage[algoruled,vlined,english]{algorithm2e} \usepackage[utf8]{inputenc}
\usepackage{float}
\usepackage{makecell,pict2e}
\usepackage{amsthm}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}
\RequirePackage{fix-cm}

\newcommand{\ifConferenceVersion}{\iftrue}
\newcommand{\ifJournalVersion}{\iffalse}



\newcommand{\remove}[1]{}


\newcommand{\veps}{\varepsilon}




 \newtheorem{observation}{Observation}
 \newtheorem{mprop}{Proposition}




 \newtheorem{result}{Result}[section]



  \newenvironment{sproof} { \noindent \textbf{Sketch of the proof} : } { \qed \medskip}
 \newenvironment{proofof}[1]{\medskip\noindent {\bf Proof of #1 : }} { \qed \medskip }

\newcommand{\inst}[1]{}
\newtheorem{myclaim}{Claim} 
 
\newcommand{\ceil}[1]{\left\lceil #1\right\rceil}
\newcommand{\f}[2]{2^{#2\ceil{\log \log #1}} }
\newcommand{\dime}{\delta}
\newcommand{\spac}{\mathcal{F}}
\newcommand{\cp}{\pi}
\newcommand{\scp}{\Pi}
\newcommand{\cpd}{\gamma}
\newcommand{\scpd}{\Gamma}
\newcommand{\dist}[1]{\mathop{dist}(#1)}
\newcommand{\probleme}[3]{\medskip\noindent\textbf{#1 problem}\\ \noindent \emph{Instance: }#2\\ \noindent \emph{Question: }#3\medskip}
\newcommand{\cA}{\ensuremath{\mathcal{S}\xspace}}


\newcommand\X{X_{LR}^b\xspace}
\newcommand\Y{Y_{RL}^b\xspace}
\newcommand\rclr{Reach_{LR}^c\xspace}
\newcommand\rcrl{Reach_{RL}^c\xspace}
\newcommand\rblr{Reach_{LR}^b\xspace}
\newcommand\rbrl{Reach_{RL}^b\xspace}
\newcommand\acrl{Act_{RL}^c\xspace}
\newcommand\aclr{Act_{LR}^c\xspace}
\newcommand\abrl{Act_{RL}^b\xspace}
\newcommand\ablr{Act_{LR}^b\xspace}
\newcommand\tclr{TH_{LR}^c\xspace}
\newcommand\tcrl{TH_{RL}^c\xspace}
\newcommand\sclr{S_{LR}^c\xspace}
\newcommand\scrl{S_{RL}^c\xspace}
\newcommand\bigOh{\mathcal{O}}
\newcommand\TwoApr{\mbox{{\tt UnknownLine}}\xspace}
\newcommand\Optbc{\mbox{{\tt OptimalBroadcast}}\xspace}
\newcommand\FourApr{\mbox{{\tt UnknownTree}}\xspace}
\newcommand\TwoAprTree{\mbox{{\tt UnknownTree}}\xspace}
\newcommand\CompThLR{\mbox{{\tt ThresholdLR}}\xspace}
\newcommand\CompOptimal{\mbox{{\tt ComputeOptimal}}\xspace}
\newcommand\CompOptimalPos{{{\tt Optimal\-At\-Index}}\xspace}
\newcommand\CompThRL{\mbox{{\tt ThresholdRL}}\xspace}
\newcommand\STree{\mbox{{\tt KnownGraph}}\xspace}
\newcommand\Off{\mbox{{\tt KnownLine}}\xspace}
\newcommand\ST{\mbox{{\tt Stretch}}\xspace}
\newcommand\Fst{\mbox{{\tt Furthest}}\xspace}
\newcommand\OptPow{\mbox{{\tt OptPower}}\xspace}
\newcommand\Optchain{\mbox{{\tt Opt}}\xspace}
\newcommand\Threshold{\mbox{{\tt Threshold}}\xspace}


\newcommand\offgossip{Off-line gossip}
\newcommand\strat{\mbox{strategy}\xspace}
\newcommand\convergecast{convergecast\xspace}
\newcommand\broadcast{broadcast\xspace}
\newcommand\Broadcast{Broadcast\xspace}
\newcommand\Convergecast{Convergecast\xspace}
\newcommand\ccast{convergecast\xspace}
\newcommand\Ccast{Convergecast\xspace}
\newcommand\cccast{centralized convergecast\xspace}
\newcommand\Cccast{Centralized convergecast\xspace}
\newcommand\Cbcast{Centralized broadcast\xspace}
\newcommand\Dccast{Distributed convergecast\xspace}
\newcommand\dcast{Centralized convergecast decision problem\xspace}
\newcommand\mcast{Centralized convergecast optimization problem\xspace}
\newcommand\collect{collect\xspace}
\newcommand\Collect{Collect\xspace}

\newcommand\subproblem{carry\xspace}
\newcommand\cS{\ensuremath{\mathcal{S}\xspace}}



\begin{document}
\sloppy

\SetAlFnt{\small\tt}
\SetAlCapFnt{\tt}
\SetProcArgSty{texttt}


\title{\bf {Convergecast and Broadcast by Power-Aware Mobile Agents\thanks{A preliminary version of this paper appeared in Proc. 26th International Symposium of Distributed Computing (DISC 2012).}}}






\author{
Julian Anaya\inst{1},
J\'{e}r\'{e}mie Chalopin\inst{2},
Jurek Czyzowicz\inst{1},\\
Arnaud Labourel\inst{2},
Andrzej Pelc\inst{1}\footnote{{Partially supported by NSERC discovery grant and by the Research Chair in Distributed Computing at the Universit\'e du Qu\'{e}bec en Outaouais.}} ,
Yann Vax\`es\inst{2}\\
\inst{1}Universit\'{e} du Qu\'{e}bec en Outaouais,
C.P. 1250, Gatineau, Qc. J8X 3X7
Canada.\\
E-mails: \url{ingjuliananaya@gmail.com},  \url{jurek@uqo.ca}, \url{pelc@uqo.ca}\\
\inst{2} LIF, CNRS \& Aix-Marseille University,
13288 Marseille, France.\\
E-mails: \url{{jeremie.chalopin,arnaud.labourel,yann.vaxes}@lif.univ-mrs.fr}
}


\maketitle

\begin{abstract}
A set of identical, mobile agents is deployed in a weighted network. Each agent has a battery -- a power source allowing it to move along network edges. An agent uses its battery proportionally to the distance traveled. We consider two tasks : {\em \convergecast}, in which at the beginning, each agent has some initial piece of information, and information of all agents has to be collected by some agent; and {\em \broadcast} in which information of one specified agent has to be made available to all other agents. In both tasks, the agents exchange the currently possessed information when they meet.

The objective of this paper is to investigate what is the minimal value of power, initially available to all agents, so that {\convergecast} or {\broadcast} can be achieved. We study this question in the centralized and the distributed settings. In the centralized setting, there is a central monitor that schedules the moves of all agents. In the distributed setting every agent has to perform an algorithm being unaware of the network. 

In the centralized setting, we give a linear-time algorithm to compute the optimal battery power and the strategy using it, both for \convergecast and for \broadcast, when agents are on the line. We also show that finding the optimal battery power for \convergecast or for \broadcast is NP-hard for the class of trees. On the other hand, we give a polynomial algorithm that finds a 2-approximation for \convergecast and a 4-approximation for \broadcast, for arbitrary graphs.

In the distributed setting, we give a 2-competitive 
algorithm for {\convergecast} in trees and a 4-competitive algorithm for \broadcast in trees. The competitive ratio of 2 is proved to be the best for the problem of \convergecast, even if we only consider line networks. Indeed, we show that there is no ()-competitive algorithm for \convergecast or for \broadcast in the class of lines, for any .
\end{abstract}


\section{Introduction}\label{sect:intro}

\subsection{The model and the problem}

A set of agents is deployed in a network represented by a weighted graph . An edge weight is a positive real representing the length of the edge, i.e., the distance between its endpoints along the edge. The agents start simultaneously at different nodes of .  Every agent has a battery: a power source allowing it to move in a continuous way along the network edges. An agent may stop at any point of a network edge (i.e. at any distance from the edge endpoints, up to the edge weight). The movements of an agent use its battery proportionally to the distance traveled. We assume that all agents move at the same speed that is equal to one, i.e., we can interchange the notions of the distance traveled and the time spent while traveling. In the beginning, the agents start with the same amount of power noted , allowing all agents to travel the same distance . 

We consider two tasks: {\em \convergecast}, in which at the beginning, each agent has some initial piece of information, and information of all agents has to be collected by some agent, not necessarily predetermined; and {\em \broadcast} in which information of one specified agent has to be made available to all other agents. In both tasks, agents notice when they meet (at a node or inside an edge) and they exchange the currently held information at every meeting.

 The task of \convergecast is important, e.g., when agents have partial information about the topology of the network and
the aggregate information can be used to construct a map of it, or when individual agents hold measurements
performed by sensors located at their initial positions and collected information serves to make some global decision  based on all measurements. The task of \broadcast is used, e.g., when a preselected leader has to share some information with others agents in order to organize their collaboration in future tasks.

Agents try to cooperate so that {\convergecast} (respectively \broadcast) is achieved with the smallest possible agent's initial battery power  (respectively ), i.e., minimizing the maximum distance traveled by an agent. We investigate these two problems in two possible settings, centralized and distributed. 

In the centralized setting, the optimization problems must be solved by a central authority knowing the network and the initial positions of all the agents. We call \emph{\strat} a finite sequence of movements executed by the agents. During each movement, starting at a specific time, an agent walks between two points belonging to the same network edge. A {\strat} is a {\convergecast} {\strat} if the sequence of movements results in one agent getting the initial information of every agent. 
A {\strat} is a {\broadcast} {\strat} if the sequence of movements results in all agents getting the initial information of the source agent. We consider two different versions of the problem : the decision problem, i.e., deciding if there exists a   {\convergecast} {\strat} or a broadcast \strat using power  (where  is the input of the problem) and the optimization problem, i.e., computing the smallest amount of power that is sufficient to achieve \convergecast or \broadcast. 

In the distributed setting, the task of \convergecast or broadcast must be approached individually by each agent.
Each agent is unaware of the network, of its position in the network and of the positions (or even the presence) of any other agents. The agents are anonymous and they execute the same deterministic algorithm. Each agent has a very simple sensing device allowing it to detect the presence of other agents at its current location in the network. Each agent is also aware of the degree of the node at which it is located, as well as the port through which it enters a node, called an \emph{entry port}. We assume that the ports of a node of degree  are represented by integers . Agents can meet at a node or inside an edge. When two or more agents meet at a node, each of them is aware of the direction from which the other agent is coming, i.e., the last entry port of each agent.

Since the measure of efficiency in this paper is the battery power (or the maximum distance traveled by an agent, which is proportional to the battery power used) we do not try to optimize the other resources (e.g. global execution time, local computation time, memory size of the agents, communication bandwidth, etc.). In particular, we conservatively suppose that, whenever two agents meet, they automatically exchange the entire information they hold (rather than the new information only). This information exchange procedure is never explicitly mentioned in our algorithms, supposing, by default, that it always takes place when a meeting occurs. The efficiency of a distributed solution is expressed by the {\em competitive ratio}, which is the worst-case ratio of the amount of power necessary to solve the {\convergecast} or the broadcast problem by the distributed algorithm with respect to the amount of power computed by the optimal centralized algorithm, which is executed for the same agents' initial positions. 

It is easy to see, that in the optimal centralized solution for the case of the line and the tree, the original network may be truncated by removing some portions and leaving only the connected part of it containing all the agents (this way all leaves of the remaining tree contain initial positions of agents). We make this assumption also in the distributed setting, since no finite competitive ratio is achievable if this condition is dropped. Indeed, two nearby anonymous agents inside a long line need to travel, in the worst case, a long distance to one of its endpoints in order to meet.

\subsection{Related work}\label{s:related}

Rapidly developing network and computer industry fueled the research interest in mobile agents computing. Mobile agents are often interpreted as 
software agents, i.e., programs migrating from host to host in a network, performing some specific tasks. However, the recent developments in computer technology bring up problems related to physical mobile devices. These include robots or motor vehicles and various wireless gadgets.
Examples of agents also include living beings: humans (e.g. soldiers in the battlefield or disaster relief personnel) or animals (e.g. birds, swarms of insects). 

In many applications the involved mobile agents are small and have to be produced at low cost in massive numbers. Consequently, in many papers, the computational power of mobile agents is assumed to be very limited and feasibility of some important distributed tasks for such collections of agents is investigated. For example \cite{AA06} introduced {\em population protocols}, modeling wireless sensor networks by extremely limited finite-state computational devices. The agents of population protocols move according to some mobility pattern totally out of their control and they interact randomly in pairs. This is called {\em passive mobility}, intended to model, e.g., some unstable environment, like a flow of water, chemical solution, human blood, wind or unpredictable mobility of agents' carriers (e.g. vehicles or flocks of birds). On the other hand,
\cite{SY} introduced anonymous, oblivious, asynchronous, mobile agents which cannot directly communicate, but they can occasionally observe the environment. Gathering and convergence  \cite{AOSY,CFPS,CP,C15}, as well as pattern formation \cite{DFSY,FPSW,SY,YS} were studied for such agents.

Apart from the feasibility questions for limited agents, the optimization problems related to the efficient usage of agents' resources have been also investigated. Energy management of (not necessarily mobile) computational devices has been a major concern in recent research papers (cf. \cite{Albers}). Fundamental techniques proposed to reduce power consumption of computer systems include power-down strategies (see \cite{Albers,AIS,ISG}) and speed scaling (introduced in \cite{YDS}). Several papers proposed centralized \cite{Bunde,SL,YDS} or distributed  \cite{Albers,Ambuhl,AIS,ISG} algorithms. However, most of this research on power efficiency concerned optimization of overall power used. Similar to our setting, assignment of charges to the system components in order to minimize the maximal charge has a flavor of another important optimization problem which is load balancing (cf. \cite{Azar}).

In wireless sensor and ad hoc networks the power awareness has been often related to the data communication via efficient routing protocols (e.g. \cite{Ambuhl,SL}. However in many applications of mobile agents (e.g. those involving actively mobile, physical agents) the agent's energy is mostly used for it's mobility purpose rather than communication, since active moving often requires running some mechanical components, while communication mostly involves (less energy-prone) electronic devices.
Consequently, in most tasks involving moving agents, like exploration, searching or pattern formation, the distance traveled is the main optimization criterion (cf. \cite{AH,AG,ABRS,BCR,BeRS,BlRS,DP,DKS,FGKP,MMS}). Single agent exploration of an unknown environment has been studied for graphs, e.g. \cite{AH,DP}, or geometric terrains, \cite{BCR,BlRS}. 

While a single agent cannot explore a graph of unknown size unless pebble (landmark) usage is permitted (see \cite{BFRSV}), a pair of robots are able to explore and map a directed graph of maximal degree  in  time with high probability (cf. \cite{BS}). In the case of a team of collaborating mobile agents, the challenge is to balance the workload among the agents so that the time to achieve the required goal is minimized. However this task is often hard (cf. \cite{FHK}), even in the case of two agents in a tree, \cite{AB}. On the other hand, the authors of \cite{FGKP} study the problem of agents exploring a tree, showing  competitive ratio of their distributed algorithm provided that writing (and reading) at tree nodes is permitted. 

Assumptions similar to our paper have been made in \cite{ABRS,BlRS,DKS} where the mobile agents are constrained to travel a fixed distance to explore an unknown graph \cite{ABRS,BlRS}, or tree \cite{DKS}. In \cite{ABRS,BlRS} a mobile agent has to return to its home base to refuel (or recharge its battery) so that the same maximal distance may repeatedly be traversed. \cite{DKS} gives an 8-competitive distributed algorithm for a set of agents  with the same amount of power exploring the tree starting at the same node.

The {\convergecast} problem is sometimes viewed as a special case of the data aggregation question (e.g. \cite{KEW,RV}) and it has been studied mainly for wireless and sensor networks, where the battery power usage is an important issue (cf. \cite{KK,AGS}). Recently \cite{CJABL} considered the online and offline settings of the scheduling problem when data has to be delivered to mobile clients while they travel within the communication range of wireless stations. \cite{KK} presents a randomized distributed {\convergecast} algorithm for geometric ad-hoc networks and study the trade-off between the energy used and the latency of {\convergecast}. The \broadcast problem for stationary processors has been extensively studied both for the message passing model, see e.g. \cite{AGP}, and for the wireless model, see e.g. \cite{BGI}. To the best of our knowledge, the problem of the present paper, when the mobile agents perform {\convergecast} or broadcast by exchanging the held information when meeting, while optimizing the maximal power used by a mobile agent, has never been investigated before. 


\subsection{Our results}\label{s:results}


In the centralized setting, we give a linear-time algorithm to compute the optimal battery power and the strategy using it, both for \convergecast and for \broadcast, when agents are on the line. We also show that finding the optimal battery power for \convergecast or for \broadcast is NP-hard for the class of trees. In fact, the respective decision problem is strongly NP-complete. On the other hand, we give a polynomial algorithm that finds a 2-approximation for \convergecast and a 4-approximation for \broadcast, for arbitrary graphs.

In the distributed setting, we give a 2-competitive 
algorithm for {\convergecast} in trees and a 4-competitive algorithm for \broadcast in trees. The competitive ratio of 2 is proved to be the best for the problem of \convergecast, even if we only consider line networks. Indeed, we show that there is no ()-competitive algorithm for \convergecast or for \broadcast in the class of lines, for any .

The following table gives the summary of our results.

\begin{table}[h]
\centering
\begin{tabular}{|c|m{6cm}|m{6cm}|}\hline
\diaghead{Problems Setting}{\large Setting}{\large Problems}&
\multicolumn{1}{c|}{Convergecast}&\multicolumn{1}{c|}{Broadcast}\\
\hline
\multirow{3}{*}[-0.22cm]{Centralized}&\multicolumn{2}{m{12cm}|}{ linear-time algorithm to compute optimal battery power and strategy on lines}\\
&\multicolumn{2}{l|}{ proof that the above problem is NP-hard on trees}\\\cline{2-3}
& polynomial 2-approximation on arbitrary graphs& polynomial 4-approximation on arbitrary graphs\\\hline
\multirow{3}{*}[0.22cm]{Distributed}& 2-competitive algorithm for trees& 4-competitive algorithm for trees\\\cline{2-3}
&\multicolumn{2}{m{8cm}|}{ proof that there is no -competitive algorithm on lines, for any }\\\hline
\end{tabular}
\caption{Summary of our results}
\end{table}

\noindent\textbf{Roadmap}

In Section 2, we show that we can restrict the search for the optimal strategy for convergecast or broadcast on the line to some smaller subclass of strategies called regular strategies. In Section 3, we present our centralized algorithms for convergecast and broadcast on lines. Section 4 is devoted to centralized convergecast and broadcast on trees and graphs. In Section 5, we investigate convergecast and broadcast in the distributed setting. Section 6 contains conclusions and open problems.

\section{Regular strategies for convergecast and broadcast on lines}

In this section, we show that if we are given a {\convergecast} (respectively \broadcast) strategy for some initial positions of agents in the line, then we can always modify it in order to get another {\convergecast} (respectively \broadcast) strategy, using the same amount of maximal power for every agent, satisfying some simple properties. Such strategies will be called \emph{regular}. These observations permit to restrict the search for the optimal strategy to some smaller and easier to handle subclass of
strategies.

We order agents according to their positions on the line. Hence we can assume w.l.o.g., that agent , for  is initially positioned at point  of the line of length  and that . 
The set  will be called a \emph{configuration} for the line of length .


\subsection{Regular {\subproblem} strategies}

Given a configuration , a starting point , a
target point  (), and an amount of power , we want to know if there
exists a strategy  for the agents enabling them to move the
information from  to  so that the amount of power spent by
each agent is at most . Strategies that move information from point  to point  will be called \emph{carry} strategies for . We restrict attention to configurations  such that  and  because otherwise either  (respectively ) is useless or it is impossible to carry information from  to . A \emph{regular} carry strategy for  is the set of moves for agents  defined as follows: agent  first goes back to a point , getting there the information
from the previous agent (except  that has to go to ), then it goes forward to a point . Moreover, we require
that each agent travels the maximal possible
distance, i.e., it spends all its power.


\begin{lemma}\label{lem-subproblem}
If there exists a \subproblem strategy for  , then there exist the following two regular \subproblem strategies. 

The pull strategy that can be computed iteratively (in linear time) starting with the
last agent:
\begin{enumerate}
\item , ,
\item ,
\item .
\end{enumerate}

The push strategy that can be computed iteratively (in linear time)  starting with the
first agent:
\begin{enumerate}
\item , ,
\item ,
\item .
\end{enumerate}
\end{lemma}

\begin{proof}
We first show that there exists a pull strategy. 
Consider  with the minimum number of
agents such that there exists a \subproblem strategy, but no
pull strategy. We consider the smallest value  such that 
admits a \subproblem strategy but no pull strategy.

If , then either , or . In the
first case,  cannot move the information between  and , and
then  admits a carry strategy but not a pull strategy and has fewer agents. In the
second case,  is also a \subproblem strategy for  and there is no pull strategy for ,
contradicting our choice of .

Hence, we may suppose that . Since there exists a carry strategy , let  be the first agent that
reaches .  The rightmost point where  can move the information
from  is . Since  is a \subproblem strategy,
when considering all the agents except ,  is a \subproblem
strategy for . By minimality of the
number of agents, the pull strategy solves the subproblem on
.  Consequently, we can assume that
 is a pull strategy on .  If , by minimality of , we have  and thus  is a pull
strategy which is a contradiction. Hence, suppose that . Note that if , we can exchange the roles of
 and  and we are in the previous case.
Hence, suppose that  and let  be the interval
that  traverses with the information when  is applied; by
minimality of ,  and consequently we have , and thus .
Consider now the strategy where we exchange the roles of  and
:  gets the information from , gives it to , and
 goes to . More formally, let , ,  and . From
our definition of  and  and the first part of the proof,
there exists a \subproblem strategy for
. However, , contradicting the minimality of .

Consequently, if there exists a carry strategy  for , then there exists
a pull strategy on
. 

\medskip

Now suppose that  admits a \subproblem strategy. 
From the first part of the proof, we know that it admits a pull strategy.
The push strategy for  can
be obtained inductively from the pull strategy. 
Let  for  be the set 
of intervals that induces the pull strategy for 
 Notice that  for  
induces the pull strategy for  
By induction, there exists a set of intervals  that 
induces a push strategy for  
with  We define  
and  Since  
we deduce that  and therefore the set of intervals
 induces a push strategy for 
.  
\end{proof}

\begin{remark}\label{rem-pull-push}
Note that the pull strategy is uniquely defined by a configuration
, a target point , and an amount of power  and enables
to compute the smallest  such that  admits a
\subproblem strategy.

Similarly, the push strategy is uniquely defined by a configuration
, a starting point , and an amount of power  and enables
to compute the largest  such that  admits a
\subproblem strategy.
\end{remark}

Note that carry strategies are defined for the target  larger than the starting point . A carry strategy will be called \emph{reverse} if the target  is smaller than  and all moves to the right are replaced by moves to the left and vice-versa.


\subsection{Regular convergecast strategies}

We now define the notion of a regular convergecast strategy for  on the segment , using power at most . 
Without loss of generality, we suppose that  and . Intuitively, a regular convergecast strategy divides the set of all agents into the set of left agents and the set of right agents such that left agents execute a push strategy from  and right agents execute a reverse push strategy from .

More formally, a \emph{regular} convergecast strategy is given by a partition of the agents into two sets  and  for some , and by two points  of segment 
for each
agent ,
such that
\begin{enumerate}[(1)]
\item if ,  and
  ,
\item if ,  and , 
\item .
\end{enumerate}



Suppose that we are given a partition of the agents into two
disjoint sets  and  and values  for each
agent  satisfying conditions (1)-(3). Then the following moves define a regular convergecast strategy: first, every agent  moves to ;
subsequently, every agent in  moves to  once it learns the initial
information of ; then, every agent in  moves to  once
it learns the initial information of .  Let  be an agent from 
such that  is maximum. Once  has moved to , it knows
the initial information of all the agents  such that . If , {\convergecast} is achieved. Otherwise,
since , we know that there exists an agent  such that .  When  reaches  it knows the initial
information of all the agents such that  and thus, 
and  know the initial information of all agents, which accomplishes convergecast.

The following lemma shows that we can restrict attention to regular convergecast strategies.


\begin{lemma}\label{lem:regconv}
If there exists a {\convergecast} strategy for a configuration
 using power at most  then there exists a regular convergecast strategy for the configuration
 using power at most .
\end{lemma}

\begin{proof}
Consider a {\convergecast} strategy  for a configuration
 using power at most . Suppose that convergecast occurred at time  at some point .
If an agent  does not get the initial information of , then at time  it must have been in the segment 
. Hence, by time , it must have learned the initial information of . It follows that every
agent , for , must learn either the initial
information of agent  or of . Therefore, we can partition the
set of agents performing a {\convergecast} strategy into two subsets
 and , such that each agent  learns the initial
information of agent  before learning the initial information of
agent  (or not learning at all the information of ). All
other agents belong to . We denote by  the interval of
all points visited by  and by  the interval of points
visited by .

Let  and . Since  is a convergecast strategy, we have . Observe that the agents in  move the initial information of  from
 to  and that the agents in  move the initial information of 
from  to . From Lemma~\ref{lem-subproblem}, we can
assume that the agents in  (resp. ) execute a push strategy (resp. a reverse push strategy)
and thus conditions (1)-(3) hold.


Suppose now that there exists an agent  such that .  Let  and
; note that  and . Consider the strategy where we exchange the roles of
 and , i.e., we put  and . Let , ,  and .

If , then . If , then . In both cases, we still have a
{\convergecast} strategy.

If  and , then ,
and . Consequently, we still have a {\convergecast} strategy.

Applying this exchange a finite number of times, we get a regular convergecast
strategy. 
\end{proof}

\subsection{Regular {\broadcast} strategies}

We now define the notion of a regular broadcast strategy for  where the source agent is , on the segment , using power at most . Without loss of generality, we suppose that  and . Intuitively, a regular broadcast strategy divides the set of all agents into the set of left agents and the set of right agents such that left agents execute a reverse pull strategy from  and right agents execute a pull strategy from .

More formally, a \emph{regular} broadcast strategy is given by points  of segment  defined for each agent  such that
\begin{enumerate}
\item , ,
\item if ,  and ,
\item if ,  and ,
\item  and  
\end{enumerate}
Suppose that we are given points  for each agent , satisfying conditions (1)-(4).
Then the following moves define a regular broadcast strategy:
 initially every agent
 moves to . Once  learns the source information,  moves to . Since (1)-(4) hold, this is a broadcast strategy and the maximum amount of power spent is at most . 

Before proving that it is enough to only consider regular broadcast strategies, we need to prove the following technical lemma. 

\begin{lemma}\label{lem-strat1-broadcast}
There exists a broadcast strategy  for a configuration
 if and only if for every , there exist positions
 such that
\begin{enumerate}[(1)]
\item  for each ,  
\item ;
\item for each , .
\item for each , if  (resp. ), there
  exists  such that  and  (resp. ).
\end{enumerate}
\end{lemma}

\begin{proof}
Consider a broadcast strategy  where the maximum amount of power
spent is .  For every agent , let  be the position where
 learns the information that has to be broadcast, and let 
(resp. ) be the leftmost (resp. rightmost) position reached by
 once it got the information.  By definition of ,
(1) and (2) hold. Since the maximum amount of power spent by an agent
is at most , and since the agent has to go from  to 
and then to  and , (3) holds.  Since every agent learns the
information, for every agent , either , or  meets
an agent  in  such that  already has the information.
Assume that  (the other case is symmetric). If , then (4) holds for .  Suppose now that  and let  be the non-empty set of agents  such that
 and  learns the information before . Let  be the agent that is first to learn the information. Since ,  learns the information from an agent 
that does not belong to . Consequently,  and
thus . Thus (4) holds
for . 

Conversely, if we are given values  satisfying (1)-(4),
we can exhibit a strategy for broadcast: initially every agent
 moves to . Once  learns the information, if
, then  moves to  and to
 and if , then  moves to  and
to . Since (4) holds, this is a broadcast strategy and since (3) holds, the maximum amount of power spent is at most . 
\end{proof}

\medskip

The following lemma shows that we can restrict attention to regular broadcast strategies.

\begin{lemma}\label{lem-shape-algo-b}
If there exists a broadcast strategy for a configuration
 with source agent , using power at most , then there exists a regular broadcast strategy for the configuration
 with source agent , using power at most .
\end{lemma} 

\begin{proof}
Suppose that there exists a \broadcast strategy for
.  For every agent ,  we define  as in the definition of a regular broadcast strategy. Note that the agents 
execute a reverse pull strategy between  and
. Similarly, the agents  execute a
pull strategy between  and .  By
Remark~\ref{rem-pull-push}, it means that there exists 
(resp. ) such that  reaches  (resp. )
with the information from .  Moreover, since the agents execute either a reverse pull 
strategy or a pull strategy, we have , and .

Suppose the lemma does not hold. This means that , and . Consequently,
 cannot reach both  and , i.e., there exists  such that  reaches , or there exists  such
that  reaches . If , it implies
that , and consequently, there cannot exist a
{\broadcast} strategy since there is no \subproblem strategy on
. Consequently, we can assume that
. Using a similar argument we can also assume that . 



Among all {\broadcast} strategies, consider the strategy that
minimizes the size of . Without loss of generality, assume that 
does not reach , and let  such that  reaches
. For each agent , let  be defined as in
Lemma~\ref{lem-strat1-broadcast}. Note that  and
. Moreover, .

Consider the new strategy defined as follows: for each agent , let  and ; let ,  and ; let  and . Note that
 and .  Since
, this is still a {\broadcast} strategy, in view of
Lemma~\ref{lem-strat1-broadcast}. However, in this new strategy, there
is one agent less in  than in , contradicting the choice of our
strategy. 

Consequently, either , or  and the lemma holds. 
\end{proof}

\section{{\Cccast} and broadcast on lines}\label{s:line}

\subsection{{\Cccast} on lines}\label{s:line}

In this section we consider the centralized {\convergecast} problem
for lines. We give an optimal, linear-time, deterministic centralized
algorithm, computing the optimal amount of power needed to solve
{\convergecast} for line networks and we provide a regular convergecast strategy for this amount of power. As the algorithm is quite involved,
we start by observing some properties of the optimal
strategies. 




\subsubsection{Properties of a {\convergecast} strategy}\label{sec-properties}

In the following, we only consider regular convergecast strategies. Note that a
regular convergecast strategy is fully determined by the value of  and by the
partition of the agents into the two sets  and . For each
agent  (resp.  ), we denote  by
 (resp. ). Observe that
 is the rightmost point on the line to which the set
of  agents at initial positions , each having power ,
may transport their total information. Similarly,
 is the leftmost such point for agents at positions
.
 
Lemma~\ref{lem:regconv} permits to construct a linear-time decision
procedure verifying if a given amount  of battery power is
sufficient to design a convergecast strategy for a given configuration
 of agents.  We first compute two lists ,
for  and , for . Then we scan them to determine if there exists an index , such
that . In such a case, we set
 and  and we apply
Lemma~\ref{lem:regconv} to obtain a regular \convergecast strategy where
agents  and  meet and exchange their information which
at this time is the entire initial information of the set of agents. If
there is no such index , no {\convergecast} strategy is
possible. This implies

\begin{corollary}
In  time we can decide if a configuration of  agents on the
line, each having a given maximal power , can perform
{\convergecast}.
\end{corollary}

The remaining lemmas of this subsection bring up observations needed 
to construct an algorithm finding the optimal power  and designing an optimal {\convergecast} strategy.

Note that if the agents are not given enough power, then it can happen
that some agent  may never learn the information from  (resp.
from ). In this case,  cannot belong to 
(resp. ). We denote by  the minimum amount of power
needed to ensure that  can learn the
information from : if , . Similarly, we have .

Given a strategy using power , for each agent , we have
 and either , or
. In the first case, , while in the second case, . 

We define threshold functions  and  that compute, for
each index , the minimal amount of power ensuring that agent  
does not go back when 
(respectively ), i.e., such that  (respectively ).  
For each , let  and . Clearly, .


The next lemma shows how to compute  and 
if we know  and  for every agent .

\begin{lemma}\label{lem-eqn-reach}
Consider an amount of power  and an index . If , then . Similarly, if , then .
\end{lemma}



\begin{proof}
We prove the first statement of the lemma; the proof of the other statement is similar.  We
first show the following claim.
 
\noindent \textbf{Claim.}
If for every , , then 

We prove the claim by induction on .
Note that since , .  Thus if , the statement holds.
Suppose now that .  Since , by the induction hypothesis,
we have

  

Consequently, we have 

This concludes the proof of the claim.

If , then for each ,  and . Consequently, 


\end{proof}










In the following, we denote  and .

\begin{remark}\label{rem-SLR}
For every , we have .
\end{remark}


We now show that for an optimal {\convergecast} strategy, the last agent
of  and the first agent of  meet at some point between their initial
positions and that they need to use all the available power  to
meet. 

\begin{lemma}\label{lem-egalite-reach}
Suppose there exists an optimal {\convergecast} strategy for a
configuration , where the maximum power used by an agent is
.  Then, there exists an integer  such that 

Moreover, ,  and
, .
\end{lemma}

\begin{proof}
In the proof we need the following claim. 

\medskip

\noindent\textbf{Claim. }
For every , the function  which assigns the value  for any argument , is an increasing, continuous, piecewise linear function with at most  pieces on .

For every , the function  which assigns the value  for any argument , is a decreasing continuous piecewise linear function with at most  pieces on .

\medskip

We prove the first statement of the claim by induction on . For
,  and the claim holds. Suppose that
 is a continuous piecewise linear function on
 and consider .

First note that . Since
 is a continuous, increasing function, there
exists a unique  such that  and for every , . Consequently,  is well defined
on . 

Since  is a continuous, increasing function, there
exists a unique  such that . If ,
 and thus
 is an increasing, continuous, piecewise linear
function on  with at most  pieces. If ,
 and thus,  is an
increasing, continuous, linear function on . Since , the function  is an
  increasing, continuous, piecewise linear function on  with at most  pieces. 

One can show the second statement of the claim using similar
arguments. This ends the proof of the claim.



Suppose we are given  and consider the partition of the agents into
 and . Consider a regular
{\convergecast} strategy for this partition and where the maximum
amount of power  used by an agent is minimized. We first show that
.

Let .  Since
 is an increasing continuous function on
 and  is a decreasing
continuous function on , the difference
 is a continuous
increasing function on .

Consider the case where  (the
other case is similar). Since ,  and thus, .  By definition of a regular convergecast strategy, there exists  such that
. Consequently, since the difference  is a continuous
increasing function on , there
exists a unique  such that .

Consider an optimal regular {\convergecast} strategy and let  be the
maximum amount of power used by any agent. By definition of a regular convergecast strategy,
there
exists an index  such that . 

Suppose that . In this case, we have
 since . Consequently, according to  what we have shown above, there
exists  such that  and
 is not the optimal value needed to solve {\convergecast}.
This contradiction shows that .


For similar reasons, if ,  is not the
optimal value needed to solve {\convergecast}. This contradiction shows that
.

\medskip
We now prove that for each , . This
follows from the fact that for each  such that , we
have . Consequently, for each , . Moreover, if 
is defined, then . If ,
then  and thus, . This contradicts the
first statement of the lemma. Hence, we have .

For similar reasons, for each , . 

\medskip
We finally prove that for each , . Suppose
there exists  such that  and consider 
and . Since ,
 and consequently,
the first statement of the lemma implies that  there exists  such that . This
implies that  is not the optimal value needed to solve convergecast. 
This contradiction implies that for each , .

For similar reasons, for each , . 
\end{proof}



\subsubsection{A linear algorithm to compute the optimal power needed for
  {\convergecast}}  

We first sketch a suboptimal but much easier algorithm and later present and analyze in detail
a more involved linear-time solution to our problem.
First, we need to compute the functions  and  for all  such that . By Lemma~\ref{lem-eqn-reach}, the function  can be computed from the values  for all  such that . Starting from , one can compute all these functions , since each value  can be deduced from 
. The computation at step  has a time complexity in  and so the computation of all the functions  takes time . Similarly, it is possible to compute all the functions , for all  such that , in time .  Since  and  are increasing, continuous, piecewise linear functions with at most  pieces, by the claim from the proof of Lemma~\ref{lem-egalite-reach}, it is possible to compute the value  such that  in time . Hence the optimal value of power needed to achieve {\convergecast} on lines, which is  by Lemma~\ref{lem-egalite-reach}, can be computed in time . 

\medskip

The following result shows that the optimal power needed for convergecast on the line can in fact be computed in linear time.

\begin{theorem}\label{thm:OptPower}
In  time it is possible to compute  the optimal power needed to achieve
{\convergecast} on the line for configuration   and to compute the optimal convergecast strategy.
\end{theorem}

We first explain how to compute a stack of couples 
that we can subsequently use to calculate  for any
given .
Then, we present a linear algorithm that computes the value needed to
solve {\convergecast} when the last index  is provided:
given an index , we compute the optimal power needed to solve
{\convergecast} assuming that  and .
Finally, we explain how to use techniques introduced in the two
previous algorithms in order to compute the optimal power needed to
solve {\convergecast}. 

\paragraph{Computing the threshold values.}

In order to describe explicitly the function ,
we need to identify the indices  such that for every , we have . They correspond to the
breakpoints at which the slopes of the piecewise linear function
 change. Indeed, if we are given such an index
, then for every  comprised between  and , we have . We denote by
 this set of indices .

In particular, if we want to compute , we just need to
find ,
and then  is the value of power  such that
.  Moreover,
by the choice of , we have .

Using these remarks, the function \CompThLR, with an input index  of an agent, returns a stack  containing
couples  such that  and .  
Note that in the stack , the elements  are sorted
along both components, the largest being on the top of the stack.

The function is described as follows.  Initially, the stack
 contains only the couple .  At
each iteration, given the stack corresponding to the index , in
order to compute the stack for the index , we first pop out all
elements  such that . After that,
the integer  needed to compute  is located on the top
of the stack.  Finally, the couple  is pushed on
the stack before we proceed with the subsequent index 
 The function returns the stack  corresponding
to the index .

Below, we give the pseudo-code of the function.

\begin{function}[H]
\caption{ThresholdLR(array {} of real; :integer):stack}\label{algo:cmptTH-s}  
\SetKwData{MyTrue}{true} \SetKwData{MyFasle}{false} 
\SetKw{Not}{not} \SetKw{MyAnd}{and}
\SetKw{Pop}{pop}
\SetKw{Push}{push}
\SetKw{KwDownTo}{down to}
\SetKw{EmptyStack}{empty\_stack}

\;
\Push(,)\;
\For{ \KwTo }
{
  \tcc*{ and }
  \While{} 
        {\;}
  \tcp{while  we consider the next
    element in }
  \Push(,)\;
  \;
  \tcc{ is the solution of }
  \Push(,)\;
}
\Return()\;
\end{function}

The number of stack operations performed during the execution of this
function is . However, in order to obtain a linear number of
arithmetic operations, we need to be able to compute  and
 in constant time.

In order to compute  efficiently, we can store the values of
,  in an auxiliary array, that we have precomputed
in  time. We cannot precompute all values of  since
this requires calculating  values. However, from
Remark~\ref{rem-SLR}, we know that . Consequently, it is enough to precompute
 for each . Since , this can be done using  arithmetic
operations.




Similarly, we can define the function \CompThRL(\texttt{array}
 \texttt{of real}, \texttt{:integer):stack} that returns
a stack  containing all pairs  such
that for every , we have .


\paragraph{Computing the optimal power when  and  are known.} 

To facilitate further reading, we first show how to compute the optimal power ,
if the sets  and  are known. This will be done by function \CompOptimalPos which will be not used in our final algorithm to compute optimal power but whose role is to explain some of the techniques under these additional assumptions.

Suppose that we are given an agent index  and we want to
compute the optimal power needed to solve {\convergecast} when  and . From
Lemma~\ref{lem-egalite-reach}, we know that there exists a unique value
 such that .

As previously, by Lemma~\ref{lem-eqn-reach}, we know that the value
of  depends on . Similarly,  depends
on .  If we are
given the values of  and , then  is the unique value of 
such that
 

In Function \CompOptimalPos, we first use functions \CompThLR and \CompThRL to
compute the two stacks  and 
containing respectively  and
.  Then at each iteration,
we consider the two elements  and  that are
on top of both stacks. If  (the other case is
symmetric), we check whether .  In this case, we have , so we
remove  from the stack  and we proceed
to the next iteration.  If , we know that  and we can compute the value of  using
Lemma~\ref{lem-eqn-reach}.




Let  denote  and .

\begin{remark}\label{rem-atpos}
At the end of the execution of Function \CompOptimalPos,
 and  contain respectively
 and .

Moreover, if initially the two stacks  and
 contain respectively  and
 for some , then the value computed by
the function is also  .
\end{remark}

The pseudo-code of the of Function \CompOptimalPos is given below. 



\begin{function}[h!]
\caption{OptimalAtIndex (array {} of real;
  r:integer):stack \label{algo:cmptTH}}   
\SetKwData{MyTrue}{true} \SetKwData{MyFasle}{false} 
\SetKw{Not}{not} \SetKw{MyAnd}{and}
\SetKw{Pop}{pop}
\SetKw{Push}{push}
\SetKw{KwDownTo}{down to}
\SetKw{EmptyStack}{empty\_stack}

; \; 


; ;
\;
\tcc{, , , .}

\While(\\ \tcc*[h]{While  do}){}  
      {
        \lIf{}
            {
              }
        \lElse{
              }
        \;    
      }      
      \; 
\tcc{ is the solution of }  
\Return()\; 
\end{function}


\paragraph{Computing the optimal power for \convergecast.}

We now explain how to compute the optimal amount of power needed to
achieve {\convergecast} using a linear number of operations. Notice that
Function \CompOptimalPos does it only provided the partition of the agents
in  and .





Let  be the optimal value needed to solve convergecast when
, i.e., when the two agents whose
meeting results in merging the entire information are  and 
for some . If , then
. However, if , then  and  is
the unique value of  such that . This corresponds to the value returned by function
\CompOptimalPos().

The general idea of Function \CompOptimal is to iteratively compute
the value of . If we need a linear time algorithm, we cannot
call repeatedly the function \CompOptimalPos. However, from
Remark~\ref{rem-atpos}, in order to compute  when , it is enough to know  and
.  If we know  and
, then we can use the same algorithm as in
\CompOptimalPos in order to compute . Moreover, from
Remark~\ref{rem-atpos}, we also get  and
 when we compute .

Before proceeding to the next iteration, we need to compute
 and  from
 and . Note that if
, then . If , we can use the
same function as in \CompThLR to compute  from .
Consider now . If ,
then , and
. If , then either  if , or 
 if . In both cases, it
implies that .  Therefore,
by Lemma~\ref{lem-egalite-reach},  for every  and we can return the value of .

In Function \CompOptimal, at each iteration, the stack
 contains  (except its top
element) and the stack  contains
 (except its top element). Initially,
 is empty and  contains 
elements. In each iteration, at most one element is pushed into the
stack  and no element is pushed into the stack
. Consequently, the number of stack operations
performed by Function \CompOptimal is linear. 



\begin{function}[h]
\caption{ComputeOptimal (array  of real):real\label{algo:opt}}
\SetKwData{MyTrue}{true} \SetKwData{MyFasle}{false} 
\SetKw{Not}{not} \SetKw{MyAnd}{and}
\SetKw{Pop}{pop}
\SetKw{Push}{push}
\SetKw{EmptyStack}{empty\_stack}


; \; 

; \; 
\tcc{, }
; 
;\;
\For{ \KwTo }
{
  \tcc{
  }
  \If{} 
     {
       \tcc{If  then 
          is larger than the value needed to solve
         {\convergecast} at position . We apply now the same algorithm
         as in function \CompOptimalPos. 
       }
        \;    
       \While{}  
             {
               \lIf{}
                   {
                     }
                   \lElse{
                     }
                   \;    
             }      
             \;  
             \tcc{ is the solution of }  
     }

     \lIf{} 
         {
           \Return }
         \tcc{In this case,  and thus
           : for any , }
     \If{}
         {
           \tcc{If  then
              and we update
             , using the same 
             algorithm as in function \CompThLR. }
           \While{}
           {\;}
           \Push(,())\;      
           \;
           \; 
         }     
}
\end{function}

Notice that the partition of agents into sets  and  is given by the value of index  when  is returned by Function
\CompOptimal.
Since an optimal regular convergecast strategy is fully determined by the value of  and by the partition of the agents into the sets  and , Function \CompOptimal also yields an optimal convergecast strategy. Hence, this concludes the proof of Theorem~\ref{thm:OptPower}.
\vspace{-0.2cm}


\subsection{{\Cbcast} on lines}\label{s:line-b}

In this section we consider the centralized {\broadcast} problem
for lines. We give an optimal, linear-time, deterministic centralized
algorithm, computing the optimal amount of power needed to solve
{\broadcast} for line networks and computing an optimal broadcast strategy. 






\subsubsection{Properties of a {\broadcast} strategy}\label{sec-properties-b}

In the following, we only consider regular broadcast strategies. Note that a
regular broadcast strategy is fully determined by the value of  and by 
the two possible values of  for the source agent  ( or ). 

Let  and . (Note that we slightly abuse notation by using the same names  and  for subsets of agents as in convergecast.)
For each agent   (resp.  ), we denote  by
 (resp. ). Observe that
 is the rightmost point on the line from which the set
of  agents at initial positions , each having power ,
may pick the information and bring it back to . Similarly,
 is the leftmost point from which the agents at positions
 may pick the information and bring it back to .







Lemma~\ref{lem-shape-algo-b} permits to construct a linear-time decision
procedure verifying if a given amount  of battery power is
sufficient to design a broadcast strategy for a given configuration
 of agents and a specified source agent .  We first compute  and . 
Then we test if  or   are less or equal than .
If one of the inequalities is true then there is a broadcast strategy. Otherwise, broadcast is not possible. This implies

\begin{corollary}
In  time we can decide if a configuration  of  agents on the
line, each having a given maximal power , can perform
{\broadcast} for a given source agent.
\end{corollary}



Note that if the agents are not given enough power, then it can happen
that some agent   (resp. ) cannot reach the
point  (resp. ). We denote by
 (resp. ) the minimum amount of power  we have to give the agents
to ensure that  (resp. ) can reach  (resp. ). We have :  and if 
. 
Similarly, if  we have .


In a regular broadcast strategy using power , for each agent  such that  we have .
Similarly, for each agent  such that  we have .
The next lemma shows how to compute  on the interval 
 for every  and
 on the interval  for every 

\begin{lemma}\label{lem-eqn-reach-b}
Consider an index  and an amount of power 
 then 
Analogously, for an index  and an amount of 
power  we have 
\end{lemma}

\begin{proof}
First, we show by induction on  that for any  and an amount of power , we have 
This is true for  since ,  and .
Now, assume by induction that .
By definition of a regular broadcast strategy, we have for all :



Observe that for , we have: 

Hence we have:


This concludes the proof by induction.

Similarly, we can show by induction on  that for any  and an amount of power , we have 
\end{proof}

\subsubsection{A linear algorithm to compute the optimal power needed for
  {\broadcast}}  

In this section, we prove the following theorem. 

\begin{theorem}\label{thm:OptPower-b}
In  time it is possible to compute the optimal power needed to achieve broadcast for a configuration  of  agents on the line for any source agent and to compute an optimal broadcast strategy.
\end{theorem}

\begin{proof}
We formulate Function \Optbc which computes in linear time the optimal power for the broadcast in the line. 

\begin{function}[h!]
\caption{OptimalBroadcast (array {} of real;
  r:integer):real \label{algo:optimalBroadcast}}   
\SetKwData{MyTrue}{true} \SetKwData{MyFasle}{false} 
\SetKw{Not}{not} \SetKw{MyAnd}{and} \SetKw{MyOr}{or}
\SetKw{Pop}{pop}
\SetKw{Push}{push}
\SetKw{KwDownTo}{down to}
\SetKw{EmptyStack}{empty\_stack}


\;
\While{}  
      {
        \While{ \MyAnd }
            {
                \;
                \;
			\;
            }
        \If{}
		{
		\;
		\;
				\;
		\;
	        }
	        
	        
	        }
	        
       
\;        
       \While{}  {
                \While{ \MyAnd }
            {
                          \;
              \;
              \;
            }
        \If{ \MyAnd  \MyOr }{
               	\;
	        \;
				\;
	        		\;
	      }
        }
       
 \; 
\If{}{
 \;
  \;
 }
 \Else{
  \;
  \; 
 }
         
 \If{}
     {\;}
 \If{}
     {\;}
 \If{}
     {\;}
 \Return 
\end{function}


In order to compute this value, Function \Optbc first computes the minimal amount of power  such that all agents in  are activated, i.e., . In order to compute , the function iteratively increases the power sufficient to activate all agents in . Then, it does the same with agents in . The function computes iteratively for each agent  from  to  in  (respectively from  to  in ), the value  (respectively ) and the value  (respectively ). Once  is known, the function computes the minimal amount of power  that enables the agent  to reach  and .
This will be proved to be the minimal power to accomplish broadcast.


Notice that in order to accomplish broadcast, agent  must be able to reach . Hence the optimal value  of power sufficient to accomplish broadcast  must be at least . Similarly,  must be at least . Hence, we will first prove that the values of , ,  and  are correctly computed for  and . 

We only prove that the values of  and  
are correctly computed for , as the proof that  and  are correctly computed for  is similar. The proof is by induction on . For , the values of  and  
are correctly computed since  and . Suppose that the values of  and  are correctly computed. If , then . By Lemma~\ref{lem-eqn-reach-b}, all functions  are linear with coefficient 1 on . Hence, if , we have . This shows that  is correctly computed. It remains to show that  is correctly computed. By definition of a regular broadcast strategy, we have 
. If , then 
 is correctly computed as the above formula is used by the function. Otherwise, we have :
. Using the notation , ,
,  we have :



This completes the proof by induction.

Again, using the fact that all functions  are linear with coefficient 1 on , the function \Optbc computes correctly the value . The same is true for . Finally, we consider three cases : ,  or  to compute the additional power  that has to be used.
By definition of  and , we conclude that  is the optimal value of power to achieve broadcast by a regular strategy. In view of Lemma~\ref{lem-shape-algo-b}, this concludes the proof that  is the optimal value of power to achieve broadcast. The complexity  of the function is straightforward by its formulation. 

Since a regular broadcast strategy is fully determined by the value of  and by 
the two possible values of  for the source agent  ( or ), computing the optimal power  yields an optimal broadcast strategy. This concludes the proof of Theorem~\ref{thm:OptPower-b}.
\end{proof}




\section{{\Cccast} and broadcast on trees  and graphs}\label{s:tree}

We start the section by showing that for arbitrary trees the {\cccast} problem and the centralized  broadcast problem are substantially harder than on lines.

A configuration for {\ccast} on arbitrary graphs is a couple  where  is a -node weighted graph representing the network and  of size  is the set of the starting nodes of the agents. A configuration for broadcast additionally specifies the starting node of the source agent. 
We consider the {\cccast} decision problem and the broadcast decision problem formalized as follows. 

\probleme{Centralized {\convergecast} decision}{a configuration  and a real .}{Is there a convergecast {\strat} for , in which each agent uses at most  battery power~?}

\probleme{Centralized {\broadcast} decision}{a configuration  with a specified source agent and a real .}{Is there a broadcast {\strat} for  with the specified source agent, in which each agent uses at most  battery power ?}

We will prove that both these problems are strongly NP-complete.
In order to do this, we consider \emph{star configurations}, i.e., configurations  in which  is a star, i.e., a tree of diameter 2. We define a class of strategies in a star 
called \emph{simple} that consist of the following two phases :

\begin{itemize}
\item The strategy starts with a gathering phase lasting time ,
in which each agent uses all its available power to move towards the center of the star and then waits until time . The agents that have used all their power during this phase without reaching the center are called \emph{depleted}.
\item In the second phase, the agents does not move past depleted agents, i.e., never enter the segment between a leaf and a depleted agent.
\end{itemize}
The following lemma shows that it is enough to consider simple strategies for convergecast and broadcast.

\begin{lemma}\label{cl:simpl}
If there exists a {\ccast} {\strat} (respectively a broadcast strategy) in a star using power , then there exists a simple {\ccast} {\strat} (respectively a simple broadcast strategy) using power .
\end{lemma}

\begin{proof}
Let  be a convergecast or a broadcast {\strat}. We construct a simple {\strat}  as follows. In , each agent 
moves towards the center of the star until it has used all its battery power or has reached the center of the star. This gathering phase lasts from time  to time . If an agent has not reached the center in strategy , then it stops forever in .
Otherwise, consider time  at which it arrives at the center in . Then, in strategy , the agent executes at time  each movement performed at time  in {\strat} . However, if a movement of an agent would result in the agent moving past a depleted agent from time  to  in , then in strategy  the agent waits at the position of the depleted agent instead of moving past it.  By construction,  is a simple {\strat}. Observe that in {\strat} , the non-depleted agents share all their information at the center of the star at time . 
Since two depleted agents cannot meet, it remains to show that when a non-depleted agent  meets a depleted agent  at time  in {\strat} , they meet at time  in . The final position of agent  is not farther from the center in  than in . Hence, any agent  that meets agent  at time  is at the new position of  in  at time . Hence, the meeting between  and  occurs in  as well. If  was a convergecast strategy (respectively a broadcast strategy) then  is a simple convergecast strategy (respectively a simple broadcast strategy).
\end{proof}

\begin{theorem}\label{th:NP-graph}
The {\cccast} decision problem and the centralized broadcast decision problem are strongly NP-complete for trees.  
\end{theorem}

The proof of Theorem \ref{th:NP-graph} is split into three lemmas. We first show that the {\cccast} decision problem is strongly NP-hard, then that the centralized broadcast decision problem is strongly NP-hard, and finally that both problems are in NP.

\begin{lemma}\label{th:NP-hard-graph}
The {\cccast} decision problem is strongly NP-hard for trees.  
\end{lemma}

\begin{proof}
We construct a polynomial-time many to one reduction from the following strongly NP-Complete problem \cite{GJ79}.

\probleme{3-Partition}{a multiset  of  positive integers 
  such that for  with
  .}{Can  be partitioned into 
  disjoint sets  of size 3, such that  for
   ?}

We construct an instance  of the {\cccast} problem from an instance of 3-Partition as follows. The graph  is a star with  leaves and  is the set of leaves of . Hence, there are  agents, each located at a leaf of the star.
We consider a partition of the set of agents into three subsets: ,  and . The subset  contains  agents. The leaves containing these agents are incident to an edge of weight . The subset  contains  agents. For  , the weight of the edge incident to the leaf containing agent  is . The subset  contains one agent. The leaf containing agent  is incident to an edge of weight . Figure~\ref{fig:reduc} depicts the star obtained in this way. The battery power  allocated to each agent is equal to . The construction can be done in polynomial time. We show that the constructed instance of the {\cccast} problem gives answer yes if and only if the original instance of 3-partition gives answer yes.

\begin{figure}[h]
\centering
\includegraphics[width=10cm]{smallfig.pdf}
\caption{Instance of the {\cccast} decision problem constructed from an instance of 3-partition.}
\label{fig:reduc}
\end{figure}

First, assume that there exists a solution  for the instance of the 3-partition problem. We show that the agents can solve the corresponding instance of the centralized {\convergecast} problem using the following {\strat}. Agent  moves at distance  from the center and for each , agent  moves at distance  from the center. At this point, all these agents have used all their battery power. Each agent in  moves to the center of the star. For  and for each of the three agents  such that , agent  moves to meet  and goes back to the center of the star. The cost of this movement is , which is exactly the remaining battery power of agent . Observe that since agents in  have met all agents in , agents in , located at the center of the star, have the information of all agents except agent . Then agent  moves to meet agent . 
Agents  and  have the information of all the agents. Hence, this is a solution of the instance of the {\cccast} problem.

\medskip

Now assume that there exists a solution (strategy) to the convergecast problem.
By Lemma~\ref{cl:simpl}, we can assume that the {\ccast} {\strat} is simple. Consider the star  after the gathering phase of the simple {\strat}. Each agent in  is at the center of the star. For , the agent  has the remaining power of . For , the agent  is at distance  from the center of the star and agent  is at distance  from the center. Since the agents in  are the only agents with remaining battery power, they must move to collect the information of agents in . We call this phase the collecting phase. Observe that since agent  is at distance  from the center, it is impossible for agents in  to transport this information. Indeed, when an agent reaches , it has used all its battery power. Hence, the entire information must be collected at the position of . In order to collect the information, agents in  must go to the position of each agent in  and transport the information of these agents to the center. The total cost to move these information is at least twice the sum of the distances between each agent in  and the center. This is equal to . Then, this information must be moved to the position of . This costs at least . Hence, the total cost of collecting information after the gathering phase is at least . The amount of power available to the agents for the collecting phase is equal to the amount of power needed to collect the information, since there are  agents each having power . This means that during the collecting phase, for , agents cannot collectively use a power larger than  to collect the information of . 

Suppose by contradiction that during the collecting phase, more than one agent in  enters an edge  to collect the information of agent  at distance  from the center, for some  such that .
Let  be the agent that has reached the position of . If  comes back to the center, it has used at least power  . Since at least one other agent has used some power to enter edge , these agents have used more than  battery power to collect information of agent . If  does not come back to the center, then some other agent has to move the information to the center. If the agent  stops at distance  from the center, then at least one other agent has to go to this position (at distance  from the center) and come back. Thus, the cost is at least . In both cases, the agents have used more power than , which leads to a contradiction. Hence, for each , there is only one agent that collects the information of agent  and enters the corresponding edge. 

We can assume, without loss of generality, that agent  is the agent that transports the information to . Observe that  cannot collect information from other nodes since moving to  uses exactly all its remaining power. Hence, only agents in  can collect the information of agents in . Let  be the partition of  defined by b_ja_i, for each . We have  since each agent from  has battery power at most . The power needed to collect information of agents in  is  which is exactly equal to the combined power available to agents in  . This means that each agent in   must use all its power to collect information and . Hence,  is a solution to the instance of 3-partition. 
\end{proof}


\begin{lemma}\label{th:NP-hard-graph-b}
The centralized broadcast decision problem is strongly NP-hard for trees.  
\end{lemma}

\begin{proof}
Again, we construct a polynomial-time many to one reduction from 3-Partition. The general structure of the proof is similar as in Lemma~\ref{th:NP-hard-graph} but details differ.

We construct an instance  of the centralized broadcast problem from an instance of 3-Partition as follows. The graph  is a star with  leaves and  is the set of leaves of . Hence, there are  agents, each located at a leaf of the star.
We consider a partition of the set of agents into three subsets: ,  and . The subset  contains  agents. The leaves containing these agents are incident to an edge of weight . The subset  contains  agents. For  , the weight of the edge incident to the leaf containing agent  is . The subset  contains  agents. All leaves containing an agent in 
are incident to an edge of weight . Figure~\ref{fig:reducb} depicts the star obtained in this way. The battery power  allocated to each agent is equal to  and agent  is the source agent. The construction can be done in polynomial time. We show that the constructed instance of the centralized broadcast problem gives answer yes if and only if the original instance of 3-partition gives answer yes.

\begin{figure}[h]
\centering
\includegraphics[width=14cm]{broadcastNP.pdf}
\caption{Instance of centralized broadcast problem from an instance of 3-partition.}
\label{fig:reducb}
\end{figure}

First, assume that there exists a solution  for the instance of the 3-partition problem. We show that the agents can solve the corresponding instance of the centralized broadcast problem using the following {\strat}. For each , agent  moves at distance  from the center and for each , agent  moves at distance  from the center. At this point, all these agents have used all their battery power. Each agent in  moves to the center of the star.
Hence, each agent  obtains the information of . For  and each of the three agents  such that , agent  moves to meet  and goes back to the center of the star. The cost of this movement is . Observe that since agents in  have met all agents in , all agents except those in  have the information of . Each agent  moves to meet agent . 
Each agent  obtains the information of . Hence, this is a solution to the instance of the centralized broadcast problem.

\medskip

Now assume that there is a solution (strategy) to the broadcast problem.
By Lemma~\ref{cl:simpl}, we can assume that the centralized broadcast {\strat} is simple. Consider the star  after the gathering phase of the simple {\strat}. Each agent in  is at the center of the star. For , the agent  has the remaining power of . For , the agent  is at distance  from the center of the star. For , agent  is at distance  from the center. Since the agents in  are the only agents with remaining battery power, they must move to give the information to agents in . Observe that since each agent  is at distance  from the center, an agent in  that moves to meet an agent  has not enough power to meet another depleted 
agent afterwards. Hence, each agent  must meet exactly one agent . Without loss of generality, we can assume that each agent  meets . Before agents in  meet agents in , they must meet agents in . The total cost to give the information to all agents in  is at least twice the sum of the distances between each agent in  and the center. This is equal to . The total cost to give the information to agents in  is 
. The amount of power available to the agents in  is , which is exactly the power needed for broadcast.
Assume for the sake of contradiction that two or more agents in  enter the same edge incident to the leaf of an agent . In this case, one of the agents must meet . This costs the agent  and other agents have used some power to enter this edge. This gives a contradiction because the total cost is more than the available power. Thus, we can assume that each agent  meets exactly one agent . Let  be the partition of  defined by b_ja_i, for each . We have  since the total power that agents  in  can use to meet agents in  is at most . The power needed to give information to agents in  is  which is exactly equal to the combined power available to agents in . This means that each agent in  must use all its power to meet agents in  and . Hence,  is a solution to the instance of 3-partition.
\end{proof}

\begin{lemma}\label{lem:NP-graph}
The {\cccast} decision problem and the centralized broadcast decision problem are in NP.  
\end{lemma}

\begin{proof}
We consider the verifier-based definition of NP. Consider the {\strat}  of the agents for an instance of the {\cccast} or centralized broadcast problems. We construct the certificate for the instance as follows. We say that a meeting of two or more agents is \emph{useful} if at least one of the agents received a new piece of information during this meeting. Each agent participates in at most  useful meetings where  is the number of agents. Hence, there are at most  useful meetings. The certificate contains the list of all useful meetings in chronological order. For the -th meeting, the certificate encodes the identities of the meeting agents and the location of the meeting: a node   or an edge  of the graph . If the meeting has occurred on an edge, the certificate encodes a variable . The variable   represents the distance between  and the meeting point . If a previous meeting of number  has occurred on the same edge, the certificate encodes if , or  or . For each of the meeting agents, the certificate also encodes the node from which it has entered the edge ( or ) just before the meeting and the node from which it exits the edge just after the meeting. We consider the {\strat}  defined as follows. For each useful meeting in chronological order, the meeting agents move to the meeting location following a shortest path from their previous position. If the meeting occurs on an edge, the meeting agents enter and exit the edge using the node encoded in the certificate.  is a {\ccast} {\strat} since each time an agent has collected a new piece of information in , it collects the same information during the corresponding meeting in . Moreover, the agents use at most as much power in  as in  since they move to the same meeting points using shortest paths. The verifier simulates the {\strat}  defined by the certificate. The verifier first checks that all the agents possess the entire information at the end of the algorithm. This can be done in polynomial time. Then, the verifier computes the distance traveled by each agent. These distances are linear sums of variables  with  and of a constant. Finding an assignment of the variables, such that the distance traveled by each agent is less or equal than , can be done in polynomial time using linear programming. Thus, the certificate can be verified in polynomial time.
\end{proof}

Theorem \ref{th:NP-graph} is a direct consequence of Lemmas \ref{th:NP-hard-graph}, \ref{th:NP-hard-graph-b} and \ref{lem:NP-graph}.

Since both decision problems concerning convergecast and broadcast are NP-hard for the class of trees, the same is true for their optimization counterparts, i.e., computing the smallest amount of power that is sufficient to achieve convergecast or broadcast.
In spite of that, we will show how to obtain, in polynomial time, a 2-approximation of the power needed to achieve {\cccast} on arbitrary graphs and a 4-approximation of the power needed to achieve centralized broadcast on arbitrary graphs. 

Let , where  is the distance between  and  in . The following proposition shows a relation between  and the above optimal power values.

\begin{proposition}\label{lem:twice-p}
Consider a configuration  for convergecast and a configuration  with a specified source agent for broadcast. Then  and  for any source agent in .
\end{proposition}

\begin{proof}
We prove the proposition for the case of convergecast. The proof for broadcast is similar.
Suppose, by contradiction, that there is a partition of  into  and  such that for each  and  the distance between  and  is greater than . It means that no agents in  can meet an agent in  using power . This contradicts the fact that there is a {\ccast} {\strat} in  using battery power . Hence, for every partition of  into  and , there exist agents  and  that are at distance at most .
\end{proof}

In view of Proposition \ref{lem:twice-p}, the following theorem shows that the convergecast problem has a polynomial-time 2-approximation.

\begin{theorem}\label{cor:FourApr}
Consider a configuration . There is a polynomial algorithm computing a {\ccast} strategy in which each agent uses power .
\end{theorem}

\begin{proof}
We formulate algorithm  which produces the desired convergecast strategy.
The parameters of the algorithm are the graph  and the nodes corresponding to the initial positions of agents (stored in ). 

\medskip

\begin{algorithm}[H]
\SetKw{EmptyStack}{empty\_stack}
\caption{KnownGraph(a weighted graph G, an array A{[1:k]} of nodes) \label{algo:graph}}
\SetKwData{MyTrue}{true} \SetKwData{MyFalse}{false} 
\SetKw{Not}{not} 
\SetKw{MyAnd}{and}
\SetKw{Wait}{Wait}
\SetKw{Move}{Move}
\SetKw{Push}{push}
\SetKw{Pop}{pop}
\;
\;
\;
\Repeat{}
{
	choose a couple  such that  is minimal\;
	\;
	 shortest path between  and \;
	\;
	\;
}
\Repeat{}
{
	\;
	agent starting in  moves to  following path \;
}
\end{algorithm}


\medskip
Let  be the nodes chosen at the -th iteration of the first loop and let  be the value of  at the end of the -th iteration. We set  and . We show, by induction, that at the start of the -th iteration of the second loop, agents that started in  hold collectively all the information. It is clearly true for . Assume by induction that it is true for . The agent that started at  moves to node  for some , during the -th iteration of the second loop. After this move, the agent that started at  has the information of the agent that started at . Agents in  collectively hold all the information. Hence, the property is true for  and this concludes the argument by induction. At the end of the algorithm, the agent at  has all the information since .

Let  be the set of agents. Consider the partition of  into sets  and . We have  since  is the couple 
 such that  is minimal. Hence, no agent will traverse distance larger than  by Proposition~\ref{lem:twice-p}.

In  time, it is possible to precompute all shortest paths between  and  for all . Each iteration of the first repeat loop can be computed in  time and there are  such iterations where  is the number of agents. Hence, executing the first repeat loop takes time . The execution the second repeat loop takes time . Hence, the overall complexity of the algorithm is .
\end{proof}

\medskip

The above theorem gives the following corollary for the broadcast problem on arbitrary graphs.

\begin{corollary}
The broadcast problem on arbitrary graphs has a polynomial-time 4-approximation.
\end{corollary}

\begin{proof}
Let  be a configuration with an arbitrary source agent . By Theorem \ref{cor:FourApr}, there is a convergecast strategy  for  using power at most  that can be computed in polynomial time. Let  be the agent that collects all information upon completion of this strategy. Consider the strategy  which consists of performing the reverse of all moves of  in the reverse order. The strategy  is a broadcast strategy for source agent . Hence, the strategy  followed by  is a broadcast strategy for source agent . The required power is at most  which gives a 4-approximation of the broadcast problem in view of Proposition~\ref{lem:twice-p}.
\end{proof}

\section{{\Dccast} and broadcast on trees}\label{s:online}

In this section, we consider the convergecast and the broadcast problem in the distributed setting. 
As explained in the introduction, we consider weighted trees with agents at every leaf. In view of Proposition~\ref{lem:twice-p}, the following theorem implies that there exists a 2-competitive distributed algorithm for the {\ccast} problem on trees.

\begin{theorem}\label{thm:FourComp}
Consider a configuration  where  is a tree and  contains all the leaves of . There exists a distributed {\ccast} algorithm in which each agent uses power at most .
\end{theorem}

\begin{proof}
The idea behind the algorithm is similar to the saturation technique used for message passing systems (see chapter 2.6.1 of \cite{San}). Each agent starting at a leaf moves until it reaches the neighbor of its starting position. When an agent reaches a node, it waits until an agent has arrived from each incident edge except one. When this happens, the agent with the most remaining power moves via the edge from which no agent has arrived. One can show that each agent will not move more than  and thus twice  by Proposition~\ref{lem:twice-p}. At some point, the saturation occurs, i.e., two agents meet inside an edge or agents meet at a node coming from all incident edges. At this point, the convergecast is achieved.

The pseudocode of the algorithm (executed distributedly by all agents) is the following.

\begin{algorithm}[H]
\caption{UnknownTree \label{algo:2appr}}
\SetKwData{MyTrue}{true}
 \SetKwData{MyFalse}{false} 
\SetKw{Not}{not} 
\SetKw{MyAnd}{and}
\SetKw{Wait}{Wait}
\SetKw{Move}{Move}
 \;
 \While{}
 {\Wait{\emph{}until there is at most one port unused by an agent incoming at the current node}\;
 	\uIf{all ports of the current node were used by incoming agents}
	{}
	  	\uIf{the agent has used less power than any other agent present at the node \MyAnd }
	{\Move{\emph{}through the unused incoming port until you meet another agent or reach a node}\;
	}
	\lElse
	{} 
	\lIf{the agent is inside an edge}{}
 }
\end{algorithm}


 First, we show that if each agent executes Algorithm~\ref{algo:2appr} then, eventually, one agent will hold all the information. Consider an agent  executing the algorithm. Let  be the subtree rooted at the last visited node and containing all nodes accessible from the current position of  by shortest paths containing a non-null part of the last edge traversed by agent . Hence, when  enters a new node ,  is added to . We show by induction on the number of nodes of  that  has the initial information of every agent that started at a node of . For , this is true since  is the only agent that started in . The size of  grows only when  enters or exits some node . When  enters a new node , we show that any agent that started at  did not move yet. Assume by contradiction that there is an agent  that started at  and has moved before the arrival of . It means that agents have arrived from all but one edge incident to . In that case, agent  follows the edge from which no agent has arrived. Hence, the only possible edge that agent  can follow is the edge taken by agent  to arrive at . This leads to a contradiction since agents  and  must have met inside the edge and agent  would have stopped before reaching .
 
  When an agent  moves from a node  of degree , there were  agents  that have arrived at  before. By the induction hypothesis, each agent , for , has collected all the information from agents starting inside the subtree . Since agent  moves in the only direction from which no agent has arrived, it has the information of every agent that started in . This concludes the proof by induction.

Observe that for each   the tree  grows until either  meets agents that have arrived from all incoming ports of its current position, or another agent  with more power moves in a yet unexplored direction. In the latter case,  and the tree  will grow under the same conditions. Thus,  will eventually be equal to . This happens when either two agents  meet inside an edge or  agents  meet at a node of degree . These agents have the entire information since   ( if the meeting occurs on an edge). 

It remains to show that the agents do not use more battery power than . 
Let  be the point where some agent  has finished the execution of the algorithm (when the value of  becomes true for this agent) and let  be the last node visited by  before reaching . Consider  when  exited . Agent  is the agent starting in  for which the distance between its initial position and the node  was the smallest, since it was the agent that has used the least power when it arrived at .  Thus, the distance between the initial position of an agent in  and an agent in  is less or equal than . Hence we conclude that . By Property~\ref{lem:twice-p}, we have that  and hence the algorithm is 2-competitive.
\end{proof}

Again in view of Proposition~\ref{lem:twice-p}, the following corollary implies that there exists 	a 4-competitive distributed algorithm for the broadcast problem on trees.

\begin{corollary}\label{cor:FourComp}
Consider a configuration  with a specified source agent, where  is a tree and  contains all the leaves of . There exists a distributed broadcast algorithm in which each agent uses power at most .
\end{corollary}

\begin{proof}
Let  be a configuration with a specified source agent . All agents execute the following algorithm consisting of two phases.
In the first phase, each agent executes algorithm \TwoAprTree from the proof of Theorem \ref{thm:FourComp} to achieve convergecast. Suppose that  is the set of agents that get the total information at the end of the execution of this phase. All agents in  are aware of this fact. Agents in  start the second phase. We call them \emph{active} agents. 
Each active agent backtracks to its initial position, by walking along the path reverse to the one used in phase 1. On its way, it 
activates all agents it meets and conveys all the information to each of them. The process continues until each agent is activated and is back at its initial position. At this time, all information and in particular information of the source agent  is known to all agents. The energy spent is at most .
\end{proof}

The following theorem shows that no distributed algorithm may offer a
better competitive ratio than  for convergecast or for broadcast, even if we only consider line networks. 

\begin{theorem}\label{thm:TwoAprOpt}
Consider any , and any value of power . There exists an
integer  and a configuration  of  agents on the line
such that  :
\begin{itemize}
\item there exists a centralized {\convergecast} strategy using power  and
there is no deterministic distributed strategy allowing the
agents to solve {\convergecast} when the amount of power given to each
agent is .
\item there exists a centralized {\broadcast} strategy using power  for source agent starting at  
and there is no deterministic distributed strategy for source agent starting at   allowing the
agents to solve {\broadcast} when the amount of power given to each
agent is .
\end{itemize}
\end{theorem}

Before proving Theorem~\ref{thm:TwoAprOpt}, we prove two technical lemmas.  

\begin{lemma}\label{lem-offline-group}
Consider any , an amount of power , and a
set   of  agents located at
positions .  If ,
and if , there exists  such
that .
\end{lemma}


\begin{proof}
Suppose, by contradiction, that the lemma does not hold. It means that
for each , . Therefore, in view of the claim from the proof of Lemma~\ref{lem-eqn-reach}, we have


Consequently, if , we have 
, 
a contradiction.
\end{proof}

\begin{lemma}\label{lem-online-gap}
Consider an amount of power , a distance , and a set
 of  agents located at positions
.  Let  be the closest point from  that 
reached. Assume that .

Suppose that all the agents execute the same distributed deterministic algorithm
and do not know their initial position, and assume that some agent  meets agent  before any couple of agents 
in  meet. Then, 
and when  meets , for each , agent  is
located on .

Moreover, if  is the rightmost point reached by
some agent knowing the initial information of agent , then
.
\end{lemma}


\begin{proof}
Since all agents are executing the same distributed deterministic algorithm, let
us consider the execution of the algorithm until some agent meets
agent . During this period, all the agents perform exactly the
same moves. Since they started simultaneously, no agent meets another agent before agent 
meets  at point  or to the left of . When agent 
meets , it has moved at least a distance of . Until this
meeting between  and , every other agent has also moved a
distance of at least , and is located at distance  to the left
of its starting position. Consequently, no agent can go further than
 to the right of .
\end{proof}


\begin{proofof}{Theorem \ref{thm:TwoAprOpt}}
Let  and . Let ,  and .


Consider a set of  agents positioned on a line as follows (See
Figure~\ref{fig-2-comp}).  There is an agent 
(resp. ) on the left (resp. right) end of the line on
position  (resp. ). For each ,
there is a set  of  agents that start on distinct positions
within a segment  of length  such that for each , the distance between  and  is
. In other words, for each ,  and .

\begin{figure}
\centering
\includegraphics[width=16cm]{fig-2-comp.pdf}\caption{The configuration in the proof of Theorem~\ref{thm:TwoAprOpt}.}
\label{fig-2-comp}
\end{figure}

First, let us consider the execution of the optimal convergecast centralized algorithm for this
configuration. We claim that if the amount of power given to each
agent is , then {\convergecast} is achievable. We show by induction on
 that for every , . For , . Suppose that . Consider the agents in , i.e., the agents ,
. Since , and since ,
we know by Lemma~\ref{lem-offline-group} that
. Since , it
follows that . Consequently, this concludes the proof by induction. Since ,  is sufficient to solve
{\convergecast}. Notice that the same strategy guarantees broadcast for source agent  for configuration 
 and power .

\medskip


Consider any distributed deterministic algorithm where the amount of power
given to each agent is , yielding a strategy  of the agents. 
 A \emph{step} in  is a moment when two
agents meet.  Let  (resp. ) be the first step where an
agent from  meets an agent from  with  (resp. ).  Let  (resp. ) be the rightmost point
(resp. the leftmost point) reached by any agent from  after some agent in
 has met an agent from  with  (resp. ). For any , let .


We show by induction on time  that for each  such that
 and for each  such that , the following properties hold:
\begin{enumerate}[]
\item  for each  and 
  for each , 
\item for each , if  then , and
  for each , if  then  
\item  and  ,
\item no agent in ,  meets
  any agent from  and no agent in , 
  meets any agent from .
\end{enumerate}

First, consider .
Clearly,  and . Since all agents in  execute the
same algorithm, they all perform the same moves until either the
leftmost agent of  meets  (at step ), or the rightmost
agent of  meets  (at step ). In the
first case, it shows that  and  for any .
By Lemma~\ref{lem-online-gap}, .  By symmetry, in the second case,
 and  for any  and . In both cases, properties for  hold for .
Notice that for any , no agent in  has met an agent of .
Hence, property  hold for .


Suppose that the induction hypothesis holds for all  and let  and . Note that by , we have  and .
By  and , before step , no agent in ,  has met any other agent from a set , . Thus, since all agents in  execute the same deterministic distributed algorithm starting simutaneously,
they have performed exactly the same moves and they have not met any
other agent before step .  Suppose that an agent from 
meets another agent at step . Then, either the leftmost agent 
from  meets an agent  from  with , or the
rightmost agent from  meets an agent from  with .

By symmetry, it is enough to consider only one case. In the following,
we assume that  meets an agent  with
 at step .  In this case,  and thus  and  for each ; consequently, properties  and
 hold for .  Moreover, by induction hypothesis, the meeting between
 and  occurs at a point . First suppose that .  By
Lemma~\ref{lem-online-gap}, we have , and thus property  and  holds for . Then suppose that . We have . But this is impossible
since the initial position of the leftmost agent  of  is
 and the power available to  is .
This concludes the proof by induction. In particular, no agent from  ever meets any agent from
 and consequently,  is neither a distributed
{\convergecast} strategy nor a distributed
{\broadcast} strategy for any source agent.
\end{proofof}






Theorems~\ref{thm:FourComp} and \ref{thm:TwoAprOpt} show that for the distributed convergecast problem on the class of trees, the competitive ratio 2 is optimal. 

\section{Conclusion and open problems}\label{s:open}



In the centralized setting, we showed that the breaking point in complexity between polynomial and NP-hard, both for the convergecast and for the broadcast problem, is already present inside the class of trees. Namely, agents' optimal power and the strategy using it can be found in polynomial time for the class of lines but it is NP-hard for the class of arbitrary trees. Nevertheless, we found polynomial approximation algorithms for both these problems. It remains open if better approximation constants can be found.

The problem of a single {\em information transfer} by mobile agents between two stationary points of the network, which we called \emph{carry} in the case of lines, is also interesting. In particular, it is an open question whether the problem of finding optimal power for this task is NP-hard for arbitrary tree networks or if a polynomial-time algorithm is possible in this case. Our reduction from 3-partition is no longer valid for this problem. 

In the distributed setting, we showed that 2 is the best competitive ratio for the problem of convergecast. However, our distributed algorithm for the broadcast problem is only 4-competitive. It remains open to find the best competitive ratio for the broadcast problem.

Additional natural questions related to our research include
other variations of the agent model, e.g., agents with unequal power, agents with non-zero visibility, labeled agents in the distributed setting, as well as fault-tolerant issues, such as unreliable agents or networks with possibly faulty components.




\begin{thebibliography}{10}

\bibitem{Albers}
S.~Albers.
\newblock Energy-efficient algorithms.
\newblock {\em Communications of the ACM}, 53(5):86--96, 2010.

\bibitem{AH}
S.~Albers and M.~R. Henzinger.
\newblock Exploring unknown environments.
\newblock In {\em Proceedings of the 29th Annual ACM Symposium on
  Theory of Computing (STOC)}, pages 416--425, 1997.

\bibitem{AG}
S.~Alpern and S.~Gal.
\newblock {\em The theory of search games and rendezvous}, volume~55,
\newblock Springer, 2003.

\bibitem{Ambuhl}
C.~Ambühl.
\newblock An optimal bound for the mst algorithm to compute energy efficient
  broadcast trees in wireless networks.
\newblock In {\em Proceedings of the International Colloquium on Automata, Languages, and
  Programming (ICALP)}, volume 3580 of {\em Lecture Notes in Computer Science},
  pages 1139--1150, 2005.

\bibitem{AOSY}
H.~Ando, Y.~Oasa, I.~Suzuki, and M.~Yamashita.
\newblock Distributed memoryless point convergence algorithm for mobile robots
  with limited visibility.
\newblock {\em IEEE Transactions on Robotics and Automation}, 15(5):818--828,
  1999.

\bibitem{AA06}
D.~Angluin, J.~Aspnes, Z.~Diamadi, M.~Fischer, and R.~Peralta.
\newblock Computation in networks of passively mobile finite-state sensors.
\newblock {\em Distributed Computing}, 18(4):235--253, 2006.

\bibitem{AGS}
V.~Annamalai, S.~Gupta, and L.~Schwiebert.
\newblock On tree-based convergecasting in wireless sensor networks.
\newblock In {\em IEEE Wireless Communications and Networking}, volume~3, pages 1942--1947, 2003.

\bibitem{AIS}
J.~Augustine, S.~Irani, and C.~Swamy.
\newblock Optimal power-down strategies.
\newblock In {\em Proceedings of the 45th
  Annual IEEE Symposium on Foundations of Computer Science (FOCS)}, pages 530--539, 2004.

\bibitem{AB}
I.~Averbakh and O.~Berman.
\newblock A heuristic with worst-case analysis for minimax routing of two
  travelling salesmen on a tree.
\newblock {\em Discrete Applied Mathematics}, 68(1–2):17 -- 32, 1996.

\bibitem{ABRS}
B.~Awerbuch, M.~Betke, R.~L. Rivest, and M.~Singh.
\newblock Piecemeal graph exploration by a mobile robot.
\newblock {\em Information and Computation}, 152(2):155 -- 172, 1999.

\bibitem{AGP}
B.~Awerbuch, O.~Goldreich, R.~Vainish, and D.~Peleg.
\newblock A trade-off between information and communication in broadcast
  protocols.
\newblock {\em Journal of the ACM}, 37(2):238--256, 1990.

\bibitem{Azar}
Y.~Azar.
\newblock On-line load balancing.
\newblock {\em A. Fiat and G.Woeginger, Online Algorithms: The State of the
  Art, Lecture notes in computer science}, 1442:178--195, 1998.

\bibitem{BCR}
R.~Baezayates, J.~Culberson, and G.~Rawlins.
\newblock Searching in the plane.
\newblock {\em Information and Computation}, 106(2):234 -- 252, 1993.

\bibitem{BGI}
R.~Bar-Yehuda, O.~Goldreich, and A.~Itai.
\newblock On the time-complexity of broadcast in multi-hop radio networks: An
  exponential gap between determinism and randomization.
\newblock {\em Journal of Computer and System Sciences}, 45(1):104 -- 126,
  1992.

\bibitem{BS}
M.~Bender and D.~Slonim.
\newblock The power of team exploration: two robots can learn unlabeled
  directed graphs.
\newblock In {\em Proceedings of the 35th
  Annual Symposium on Foundations of Computer Science (FOCS)}, pages 75--85, 1994.

\bibitem{BFRSV}
M.~A. Bender, A.~Fernández, D.~Ron, A.~Sahai, and S.~Vadhan.
\newblock The power of a pebble: Exploring and mapping directed graphs.
\newblock {\em Information and Computation}, 176(1):1 -- 21, 2002.

\bibitem{BeRS}
M.~Betke, R.~Rivest, and M.~Singh.
\newblock Piecemeal learning of an unknown environment.
\newblock {\em Machine Learning}, 18(2-3):231--254, 1995.

\bibitem{BlRS}
A.~Blum, P.~Raghavan, and B.~Schieber.
\newblock Navigating in unfamiliar geometric terrain.
\newblock {\em SIAM Journal on Computing}, 26(1):110--137, 1997.

\bibitem{Bunde}
D.~Bunde.
\newblock Power-aware scheduling for makespan and flow.
\newblock {\em Journal of Scheduling}, 12(5):489--500, 2009.

\bibitem{CJABL}
F.~Chen, M.~Johnson, Y.~Alayev, A.~Bar-Noy, and T.~La~Porta.
\newblock Who, when, where: Timeslot assignment to mobile clients.
\newblock {\em IEEE Transactions on Mobile Computing}, 11(1):73--85, 2012.

\bibitem{CFPS}
M.~Cieliebak, P.~Flocchini, G.~Prencipe, and N.~Santoro.
\newblock Solving the robots gathering problem.
\newblock In {\em Proceedings of the International Colloquium of Automata, Languages and Programming (ICALP)},
  volume 2719 of {\em Lecture Notes in Computer Science}, pages 1181--1196.
  Springer Berlin Heidelberg, 2003.

\bibitem{CP}
R.~Cohen and D.~Peleg.
\newblock Convergence properties of the gravitational algorithm in asynchronous
  robot systems.
\newblock {\em SIAM Journal on Computing}, 34(6):1516--1528, 2005.

\bibitem{C15}
A.~Cord-Landwehr, B.~Degener, M.~Fischer, M.~Hüllmann, B.~Kempkes, A.~Klaas,
  P.~Kling, S.~Kurras, M.~Märtens, F.~Meyer auf~der Heide, C.~Raupach,
  K.~Swierkot, D.~Warner, C.~Weddemann, and D.~Wonisch.
\newblock A new approach for analyzing convergence algorithms for mobile
  robots.
\newblock In L.~Aceto, M.~Henzinger, and J.~Sgall, editors, In {\em Proceedings of the International
  Colloquium of Automata, Languages and Programming (ICALP)}, volume 6756 of
  {\em Lecture Notes in Computer Science}, pages 650--661, 2011.

\bibitem{DFSY}
S.~Das, P.~Flocchini, N.~Santoro, and M.~Yamashita.
\newblock On the computational power of oblivious robots: Forming a series of
  geometric patterns.
\newblock In {\em Proceedings of the 29th ACM SIGACT-SIGOPS Symposium on
  Principles of Distributed Computing (PODC)}, pages 267--276, 2010.

\bibitem{DP}
X.~Deng and C.~H. Papadimitriou.
\newblock Exploring an unknown graph.
\newblock {\em Journal of Graph Theory}, 32(3):265--297, 1999.


\bibitem{DKS}
M.~Dynia, M.~Korzeniowski, and C.~Schindelhauer.
\newblock Power-aware collective tree exploration.
\newblock In {\em Architecture of Computing Systems (ARCS)}, volume 3894 of {\em Lecture Notes in
  Computer Science}, pages 341--351, 2006.

\bibitem{FPSW}
P.~Flocchini, G.~Prencipe, N.~Santoro, and P.~Widmayer.
\newblock Gathering of asynchronous robots with limited visibility.
\newblock {\em Theoretical Computer Science}, 337(1–3):147 -- 168, 2005.

\bibitem{FGKP}
P.~Fraigniaud, L.~Gasieniec, D.~R. Kowalski, and A.~Pelc.
\newblock Collective tree exploration.
\newblock {\em Networks}, 48(3):166--177, 2006.

\bibitem{FHK}
G.~Frederickson, M.~Hecht, and C.~Kim.
\newblock Approximation algorithms for some routing problems.
\newblock {\em SIAM Journal on Computing}, 7(2):178--193, 1978.

\bibitem{GJ79}
M.~R. Garey and D.~S. Johnson.
\newblock {\em Computers and Intractability: A Guide to the Theory of
  NP-Completeness}.
\newblock W. H. Freeman \& Co., New York, NY, USA, 1979.

\bibitem{ISG}
S.~Irani, S.~Shukla, and R.~Gupta.
\newblock Algorithms for power savings.
\newblock {\em ACM Transactions on Algorithms}, 3(4), 2007.

\bibitem{KK}
A.~Kesselman and D.~R. Kowalski.
\newblock Fast distributed algorithm for convergecast in ad hoc geometric radio
  networks.
\newblock {\em Journal of Parallel and Distributed Computing}, 66(4):578 --
  585, 2006.
\newblock Algorithms for Wireless and Ad-Hoc Networks.

\bibitem{KEW}
B.~Krishnamachari, D.~Estrin, and S.~Wicker.
\newblock The impact of data aggregation in wireless sensor networks.
\newblock In {\em Proceedings of the 22nd International Conference on Distributed Computing Systems Workshops}, pages 575--578, 2002.

\bibitem{MMS}
N.~Megow, K.~Mehlhorn, and P.~Schweitzer.
\newblock Online graph exploration: New results on old and new algorithms.
\newblock {\em Theoretical Computer Science}, 463:62--72, 2012.

\bibitem{RV}
R.~Rajagopalan and P.~Varshney.
\newblock Data-aggregation techniques in sensor networks: a survey.
\newblock {\em IEEE Communications Surveys \& Tutorials}, 8(4):48--63, 2006.

\bibitem{San}
N.~Santoro.
\newblock {\em Design and analysis of distributed algorithms}, volume~56.
\newblock John Wiley \& Sons, 2006.

\bibitem{SL}
I.~Stojmenovic and X.~Lin.
\newblock Power-aware localized routing in wireless networks.
\newblock {\em IEEE Transactions on Parallel and Distributed Systems},
  12(11):1122--1133, 2001.

\bibitem{SY}
I.~Suzuki and M.~Yamashita.
\newblock Distributed anonymous mobile robots: Formation of geometric patterns.
\newblock {\em SIAM Journal on Computing}, 28(4):1347--1363, 1999.

\bibitem{YS}
M.~Yamashita and I.~Suzuki.
\newblock Characterizing geometric patterns formable by oblivious anonymous
  mobile robots.
\newblock {\em Theoretical Computer Science}, 411(26–28):2433 -- 2453, 2010.

\bibitem{YDS}
F.~Yao, A.~Demers, and S.~Shenker.
\newblock A scheduling model for reduced cpu energy.
\newblock In {\em Proceedings of the 36th Annual Symposium on Foundations of Computer Science}, pages 374--382, 1995.

\end{thebibliography}







\end{document}
