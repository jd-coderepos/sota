\documentclass[11pt]{myclass}
\usepackage{euscript}
\usepackage{wrapfig}
\usepackage{amssymb}
\usepackage{epsfig}
\usepackage{xspace}
\usepackage{color}

\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{color}
\usepackage{url}



\newcommand{\jeff}[1]{{\color{blue} \sffamily #1}}
\newcommand{\amir}[1]{{\color{green} \sffamily #1}}
\newcommand{\samira}[1]{{\color{red} \sffamily #1}}

\newcommand{\eps}{\varepsilon}
\renewcommand{\c}[1]{\ensuremath{\EuScript{#1}}}
\newcommand{\Eu}[1]{\ensuremath{\EuScript{#1}}}
\renewcommand{\b}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\bl}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\s}[1]{\textsf{#1}}
\newcommand{\E}{\textbf{\textsf{E}}}
\newcommand{\Var}{\textbf{\textsf{Var}}}
\renewcommand{\Pr}{\textbf{\textsf{Pr}}}
\newcommand{\disc}{\textsf{disc}}
\newcommand{\cert}{\textsf{cert}}

\newcommand{\RR}{\textsf{RR}\xspace}
\newcommand{\RC}{\textsf{RC}\xspace}
\newcommand{\RE}{\textsf{RE}\xspace}
\newcommand{\RQ}{\textsf{RQ}\xspace}

\newcommand{\REd}{\RE\text{-}\disc}

\newcommand{\denselist}{\vspace{-.1in} \itemsep -2pt\parsep=-1pt\partopsep -2pt}

\newcommand{\Paragraph}[1]{\paragraph{\sffamily\textbf{#1.}}}

\title{Range Counting Coresets for Uncertain Data} 

\author{Amirali Abdullah \\ {\small University of Utah} \\ {\small \texttt{amirali@cs.utah.edu}}
\and 
Samira Daruki \\ {\small University of Utah} \\ {\small \texttt{daruki@cs.utah.edu}}
\and 
Jeff M. Phillips \\ {\small University of Utah} \\ {\small \texttt{jeffp@cs.utah.edu}}}

\begin{document}
\maketitle

\begin{abstract}
We study coresets for various types of range counting queries on uncertain data.  In our model each uncertain point has a probability density describing its location, sometimes defined as  distinct locations.  Our goal is to construct a subset of the uncertain points, including their locational uncertainty, so that range counting queries can be answered by just examining this subset.  
We study three distinct types of queries.
\RE queries return the expected number of points in a query range.  
\RC queries return the number of points in the range with probability at least a threshold.
\RQ queries returns the probability that fewer than some threshold fraction of the points are in the range.
In both \RC and \RQ coresets the threshold is provided as part of the query.  
And for each type of query we provide coreset constructions with approximation-size tradeoffs.  
We show that random sampling can be used to construct each type of coreset, and we also provide significantly improved bounds using discrepancy-based approaches on axis-aligned range queries.  
\end{abstract}

\keywords{uncertain data, coresets, discrepancy}

\section{Introduction}
A powerful notion in computational geometry is the \emph{coreset}~\cite{AHV04,AHV07,BC03,VC71}.  Given a large data set  and a family of queries , then an \emph{-coreset} is a subset  such that for all  that  (note the notion of distance  between query results is problem specific and is intentionally left ambiguous for now).  Initially used for smallest enclosing ball queries~\cite{BC03} and perhaps most famous in geometry for extent queries as -kernels~\cite{AHV04,AHV07}, the coreset is now employed in many other problems such as clustering~\cite{BHP02} and density estimation~\cite{VC71}.  
Techniques for constructing coresets are becoming more relevant in the era of big data; they summarize a large data set  with a proxy set  of potentially much smaller size that can guarantee error for certain classes of queries.  They also shed light onto the limits of how much information can possibly be represented in a small set of data.  

In this paper we focus on a specific type of coreset called an -sample~\cite{VC71,peled,CM96} that can be thought of as preserving density queries and that has deep ties to the basis of learning theory~\cite{AB99}.  Given a set of objects  (often  is a point set) and a family of subsets  of , then the pair  is called an \emph{range space}.  Often  are specified by containment in geometric shapes, for instance as all subsets of  defined by inclusion in any ball, any half space, or any axis-aligned rectangle.  Now an -sample of  is a single subset  such that 

For any query range , subset  approximates the relative density of  in  with error at most .  

\Paragraph{Uncertain points}
Another emerging notion in data analysis is modeling uncertainty in points.  There are several formulations of these problems where each point  has an \emph{independent} probability distribution  describing its location and such a point is said to have \emph{locational uncertainty}.  
\emph{Imprecise points} (also called \emph{deterministic uncertainty}) model where a data point  could be anywhere within a fixed continuous range and were originally used for analyzing precision errors. The worst case properties of a point set  under the imprecise model have been
well-studied~\cite{gss-egbra-89,gss-cscah-93,bs-ads-04,hm-ticpps-08,ls-dtip-08,nt-teb-00,obj-ue-05,kl-lbbsd-10,k-bmips-08}.
\emph{Indecisive points}  (or \emph{attribute uncertainty} in database literature~\cite{1644250}) model each  as being able to take one of  distinct locations  with possibly different probabilities, modeling when multiple readings of the same object have been made~\cite{JLP11,MDFW00,CLY09,CG09,ACTY09,ABSHNSW06}.  

We also note another common model of \emph{existential uncertainty} (similar to \emph{tuple uncertainty} in database literature~\cite{1644250} but a bit less general) where the location or value of each  is fixed, but the point may not exist with some probability, modeling false readings~\cite{KCS11a,KCS11b,1644250,CLY09}.


We will focus mainly on the indecisive model of locational uncertainty since it comes up frequently in real-world applications~\cite{MDFW00,ABSHNSW06} (when multiple readings of the same object are made, and typically  is small) and can be used to approximately represent more general continuous representations~\cite{JLP12,Phi08}.  

\subsection{Problem Statement}
Combining these two notions leads to the question: can we create a coreset (specifically for -samples) of uncertain input data?  A few more definitions are required to rigorously state this question.  In fact, we develop three distinct notions of how to define the coreset error in uncertain points.  One corresponds to range counting queries, another to querying the mean, and the third to querying the median (actually it approximates the rank for all quantiles).  

For an uncertain point set  with each  we say that  is a \emph{transversal} if .  I.e.,  is an instantiation of the uncertain data  and can be treated as a ``certain'' point set, where each  corresponds to the location of .   
, (resp. ) represents the probability (resp. expected value) of an event  where  is instantiated from  according to the probability distribution on the uncertainty in .  

As stated, our goal is to construct a subset of uncertain points  (including the distribution of each point 's location, ) that preserves specific properties over a family of subsets .  For completeness, the first variation we list cannot be accomplished purely with a coreset as it requires  space.  

\begin{itemize}  \denselist
\item \emph{Range Reporting (\RR) Queries} support queries of a range  and a threshold , and return all  such that . Note that the fate of each  depends on no other  where , so they can be considered independently. Building indexes for this model have been studied~\cite{threshquery,efficientquery,TCXNKP05,ZLTZW12} and effectively solved in ~\cite{ACTY09}.  
\item \emph{Range Expectation (\RE) Queries} consider a range  and report the expected number of uncertain points in , . The linearity of expectation allows summing the individual expectations each point  is in . Single queries in this model have also been studied~\cite{JKV07,BDJRV05,JMMV07}.
\item \emph{Range Counting (\RC) Queries} support queries of a range  and a threshold , but only return the number of  which satisfy .  
The effect of each  on the query is separate from that of any other  where .  A random sampling heuristic~\cite{aggregate} has been suggested without proof of accuracy.  
\item \emph{Range Quantile (\RQ) Queries} take a query range , and report the full cumulative density function on the number of points in the range .  Thus for a query range , this returned structure can produce for any value  the probability that  or fewer points are in .  
Since this is no longer an expectation, the linearity of expectation cannot be used to decompose this query along individual uncertain points.  
\end{itemize}
\vspace{-2mm}
Across all queries we consider, there are two main ways we can approximate the answers.  The first and most standard way is to allow an -error (for ) in the returned answer for \RQ, \RE, and \RC. 
The second way is to allow an -error in the \emph{threshold} associated with the query itself.  As will be shown, this is not necessary for \RR, \RE, or \RC, but is required to get useful bounds for \RQ.  
Finally, we will also consider probabilistic error , demarcating the probability of failure in a randomized algorithm (such as random sampling).  
We strive to achieve these approximation factors with a small size coreset  as follows: 
\begin{itemize}\denselist
\item [\RE:]
For a given range , let , and let 

 is an \emph{-\RE coreset} of  if for all queries   we have

\item [\RC:]
For a range , let 

be the fraction of points in  that are in  with probability at least some threshold .  
Then  is an \emph{-\RC coreset} of  if for all queries  and all  we have

\item [\RQ:]
For a range , let 

be the probability that at most a  fraction of  is in .  
Now  is an \emph{()-\RQ coreset} of  if for all   and  there exists a  such that 

In such a situation, we also say that  is an \emph{-quantization} of .  
\end{itemize}

\vspace{-0mm}
A natural question is whether we can construct a ()-\RQ coreset where there is not a secondary -error term on .  We demonstrate that there are no useful non-trivial bounds on the size of such a coreset.    

When the -quantization  need not be explicitly represented by a coreset , then L\"offler and Phillips~\cite{LP09,JLP11} show a different small space representation that can replace it in the above definition of an -\RQ coreset with probability at least .  First randomly create  transversals , and for each transversal  create an -sample  of .  Then to satisfy the requirements of , there exists some  such that we can return , and it will be within  of .  
However, this is subverting the attempt to construct and understand a coreset to answer these questions.  A coreset  (our goal) can be used as proxy for  as opposed to querying  distinct point sets.  This alternate approach also does not shed light into how much information can be captured by a small size point set, which is provided by bounds on the size of a coreset.  

\Paragraph{Simple example}
We illustrate a simple example with  and , where  and the  possible locations of the  uncertain points are laid out in order:


We consider a coreset  that consists of the uncertain points . 
Now consider a specific range , a one-sided interval that contains  and smaller points, but not  and larger points.  
We can now see that  is an -quantization of  in Figure \ref{fig:cdf-10}; this follows since at  either  is at most  for  and is at least  for .  
Also observe that 
  
When these errors (the -quantization and -error) hold for \emph{all} ranges in some range space, then  is an -\RQ coreset or -\RC coreset, respectively.  

To understand the error associated with an \RC coreset, also consider the threshold  with respect to the range .  Then in range ,  of the uncertain points from  are in  with probability at least  (points  and ).  Also  of the uncertain points from  are in  with probability at least  (only point ).  So there is  \RC error for this range and threshold.  


\begin{figure}[t]
\centering
\includegraphics[width=0.6\linewidth]{cdf-10}
\caption{Example cumulative density functions  (, in red with fewer steps, and , in blue with more steps) on uncertain point set  and a coreset  for a specific range.}
\label{fig:cdf-10}
\end{figure}

\subsection{Our Results}

We provide the first results for \RE-, \RC-, and \RQ-coresets with guarantees.  In particular we show that a random sample  of size  with probability  is an -\RC coreset for any family of ranges  whose associated range space has VC-dimension .  
Otherwise we enforce that each uncertain point has  possible locations, then a sample  of size  suffices for an -\RE coreset.  

Then we leverage discrepancy-based techniques~\cite{Mat99,Cha01} for some specific families of ranges , to improve these bounds to .  This is an important improvement since  can be quite large (say  or more), while , interpreted as the number of readings of a data point, is small for many applications (say ).  
In , for one-sided ranges we construct -\RE and -\RC coresets of size .
For axis-aligned rectangles in  we construct -\RE coresets of size  and -\RC coresets of size .  
Finally, we show that any -\RE coreset of size  is also an -\RQ coreset with value .  

These results leverage new connections between uncertain points and both discrepancy of permutations and colored range searching that may be of independent interest.  

\section{Discrepancy and Permutations}

The key tools we will use to construct small coresets for uncertain data is discrepancy of range spaces, and specifically those defined on permutations.  
Consider a set , a range space , and a coloring .  
Then for some range , the discrepancy is defined 
.  We can then extend this to be over all ranges  and over all colorings .  

Consider a ground set  where  is a set of  objects, and  is a set of  permutations over  so each .  We can also consider a family of ranges  as a set of intervals defined on \emph{one} of the  permutations so  is defined so  for  and . The pair  is then a range space, defining a set of subsets of .  

A canonical way to obtain  permutations from an uncertain point set  is as follows.  
Define the \emph{th canonical traversal} of  as the set . When each , the sorted order of each canonical traversal  defines a permutation on  as , that is  describes how many locations (including ) in the traversal  have value less than or equal to .  In other words,  describes the sorted order of the th point among all uncertain points.  Then, given an uncertain point set, let the canonical traversals define the \emph{canonical -permutation} as .  

A geometric view of the permutation range space embeds  as  fixed points in  and considers ranges which are defined by inclusion in -dimensional slabs, defined by two parallel half spaces with normals aligned along one of the coordinate axes.  Specifically, the th coordinate of the th point is , and if the range is on the th permutation, then the slab is orthogonal to the th coordinate axis.  

Another useful construction from an uncertain point set  is the set  of all locations any point in  might occur.  
Specifically, for every uncertain point set  we can define the corresponding certain point set . 
We can also extend any coloring  on  to a coloring in  by letting , for  and .  
Now we can naturally define the discrepancy induced on  by any coloring  of  as 
.

\Paragraph{From low-discrepancy to -samples}
There is a well-studied relationship between range spaces that admit low-discrepancy colorings, and creating -samples of those range spaces~\cite{CM96,Mat99,Cha01,Bec81a}.  The key relationship states that if , then there exists an -sample of  of size ~\cite{Phi08}, for values  independent of  or .  
Construct the coloring, and with equal probability discard either all points colored 
either  or those colored .  This roughly halves the point set size, and also implies zero over-count in expectation for any fixed range.  Repeat this coloring and reduction of points until the desired size is achieved.  This can be done efficiently in a distributed manner through a merge-reduce framework~\cite{CM96};   
The take-away is that a method for a low-discrepancy coloring directly implies a method to create an -sample, where the counting error is in expectation zero for any fixed range.  
We describe and extend these results in much more detail in Appendix \ref{app:MR}.  

\section{\RE Coresets}\label{sec:rec}
First we will analyze -\RE coresets through the  interpretation of uncertain point set .  The canonical transversals  of  will also be useful.  In Section \ref{sec:RE-disc} we will relate these results to a form of discrepancy.  

\begin{lemma}\label{lem:certtocomp}
  is an -\RE coreset for  if and only if  is an -sample for .  
\end{lemma}
\begin{proof}
First note that since  , hence by linearity of expectations we have that 
. 
Now, direct computation gives us:

\end{proof}

The next implication enables us to determine an -\RE coreset on  from -samples on each .  Recall  is the th canonical transversal of  for , and is defined similarly for a subset  as .
 

\begin{lemma}\label{lem:eachcomp}
Given a range space , if we have  such that  is an -sample for  for all , then  is an -\RE coreset for . 
\end{lemma}

\begin{proof} Consider an arbitrary range , and compute directly  
 .
Recalling that 
and observing that , we get that:

\end{proof}


\subsection{Random Sampling}
 We show that a simple random sampling gives us an -\RE coreset of .
  
\begin{theorem}
For an uncertain points set  and range space  with VC-dimension ,  a random sample  of size  is an -\RE coreset of ) with probability at least .
\label{thm:RE-samp}
\end{theorem}

\begin{proof} 
A random sample  of size  is an -sample of any  with probability at least  ~\cite{LLS01}.  Now assuming  resulted from a random sample on , it induces the  disjoint canonical transversals  on , such that  and  for .  
Each  is an -sample of  for any single  with probability at least . 
Following Lemma \ref{lem:eachcomp} and using union bound, we conclude that  is an -\RE coreset for uncertain point set  with probability at least .  Setting  proves the theorem.  
\end{proof}
 

\subsection{\RE-Discrepancy and its Properties}
\label{sec:RE-disc}
Next we extend the well-studied relationship between geometric discrepancy and -samples on certain data towards -\RE coresets on uncertain data.  

We first require precise and slightly non-standard definitions.
 
We introduce a new type of discrepancy based on the expected value of uncertain points called \emph{\RE-discrepancy}.  Let  and  denote the sets of uncertain points from  colored  or , respectively, by .  
Then  for any . 
The usual extensions then follow:
 and
.  
Note that  is technically not a range space, since  defines subsets of  in this case, not of .  


\begin{lemma}\label{lem:REcolor}
Consider a coloring  such that  and .  
Then the set  is an -\RE coreset of  with .

Furthermore, if a subset  has size  and is an -\RE coreset, then it defines a coloring  (where  for ) that has .  
\end{lemma}


\begin{proof}
We prove the second statement, the first follows symmetrically.  
We refer to the subset  as .  
Let  .  This implies  

\end{proof}

We can now recast \RE-discrepancy to discrepancy on . From  Lemma \ref{lem:certtocomp} 
 and
after some basic substitutions we obtain the following.  

\begin{lemma}\label{lem:pcerttoexp}
.
\end{lemma}


This does not immediately solve -\RE coresets by standard discrepancy  techniques on  because we need to find a coloring  on .  A coloring  on  may not be consistent across all .
The following lemma allows us to reduce this to a problem of coloring each canonical transversal .  



\begin{lemma}\label{lem:jointdisc}

\end{lemma} 
\begin{proof}
For any  and any coloring  (and the corresponding ), we can write  as a union of disjoint transversals  to obtain 

Since this holds for every , hence (using Lemma \ref{lem:pcerttoexp})

\end{proof}


\subsection{-\RE Coresets in }
\label{subsec:1dre}
\begin{lemma}\label{lowdis}
Consider uncertain point set  with  and the range space  with ranges defined by one-sided intervals of the form , then .
 \end{lemma}
\begin{proof}
 Spencer et. al.~\cite{spencer} show that  is .   Since we obtain the  from the canonical transversals  through , by definition this results in upper bounds on the the discrepancy over all  (it bounds the max). Lemma \ref{lem:jointdisc} then gives us the bound on .
\end{proof} 

As we discussed in Appendix \ref{app:MR} the low \RE-discrepancy coloring can be iterated in a merge-reduce framework as developed by Chazelle and Matousek~\cite{CM96}.   With Theorem \ref{thm:RE-disc2samp} we can prove the following theorem.  

\begin{theorem}\label{thm:1deps-RE}
Consider uncertain point set  and range space  with ranges defined by one-sided intervals of the form , 
then an -\RE coreset can be constructed of size .
 \end{theorem}

Since expected value is linear, \RE- \RE- \RE- for  and the above result also holds for the family of two-sided ranges .  



\subsection{-\RE Coresets for Rectangles in }
\label{subsec:highdre}
Here let  be a set of  uncertain points where each possible location of a point .  We consider a range space  defined by -dimensional axis-aligned rectangles.  

Each canonical transversal  for  no longer implies a unique permutation on the points (for ).  But, for any rectangle , we can represent any   as the disjoint union of points  contained in intervals on a predefined set of  permutations~\cite{bohus}. 
Spencer \etal~\cite{spencer} showed there exists a coloring  such that 
 
where  is the number of defined permutations and  is the discrepancy of  permutations over  points and ranges defined as intervals on each permutation.  Furthermore, they showed .  


To get the -discrepancy bound for , we first decompose  into the  point sets  of size .
We then obtain  permutations over points in each , and hence obtain a family  of  permutations over all .  yields 

Now each set  for , can be written as the disjoint union of  intervals of .  Summing up over each interval, we get that 
 for each .  
By Lemma \ref{lem:jointdisc} this bounds the -discrepancy as well.
Finally, we can again apply the merge-reduce framework of Chazelle and Matousek~\cite{CM96} (via Theorem \ref{thm:RE-disc2samp}) to achieve an -\RE coreset.  


\begin{theorem}\label{thm:highdeps-RE}
Consider uncertain point set  and range space  (for ) with ranges defined by axis-aligned rectangles in . 
Then an -\RE coreset can be constructed of size .
 \end{theorem}



\section{\RC Coresets}
\label{sec:RC}

Recall that an -\RC coreset  of a set  of  uncertain points satisfies that for all queries  and all thresholds  we have , where  represents the fraction of points from  that are in range  with probability at least .  

In this setting, given a range  and a threshold  we can let the pair  define a range  such that each  is either in or not in .  Let  denote this range space.   If  has VC-dimension , then  has VC-dimension ;  see Corollary 5.23 in \cite{peled}.  This implies that random sampling works to construct -RC coresets.  

\begin{theorem}
\label{thm:RC-sample}
For uncertain point set  and range space  with VC-dimension , a random sample  of size  is an -RC coreset of  with probability at least .  
\end{theorem}

Yang \etal propose a similar result~\cite{aggregate} as above, without proof.

\subsection{\RC Coresets in }
Constructing -\RC coresets when the family of ranges  represents one-sided, one-dimensional intervals is much easier than other cases.  It relies heavily on the ordered structure of the canonical permutations, and thus discrepancy results do not need to decompose and then re-compose the ranges.  


\begin{lemma} \label{lem:rc-query}
A point  is in range  with probability at least  if and only if .
\end{lemma}

\begin{proof}
By the canonical permutations, since for all , we require , then if , it follows that  for .  
Similarly if , then all  for .  
\end{proof}

Thus when each canonical permutation is represented upto an error  by a coreset , then each threshold  is represented within .  Hence, as with -\RE coresets, we invoke the low-discrepancy coloring of Bohus~\cite{bohus} and Spencer \etal~\cite{spencer}, and then iterate them (invoking Theorem \ref{thm:disc2samp}) to achieve a small size -\RC coreset.  





\begin{theorem}\label{thm:1deps-RC}
For uncertain point set  and range space  with ranges defined by one-sided intervals of the form .  
An -\RC coreset of  can be constructed of size .
\end{theorem}

Extending Lemma \ref{lem:rc-query} from one-sided intervals of the form  to intervals of the form  turns out to be non-trivial.  It is \emph{not} true that , hence the two queries cannot simply be subtracted.  Also, while the set of points corresponding to the
query  are a contiguous interval in the th permutation we construct in Lemma \ref{lem:rc-query}, the same need not be true of points corresponding to .
This is a similar difficulty in spirit as noted by Kaplan \etal~\cite{colors} in the problem of counting the number of points of distinct colors in a box where one cannot take a naive decomposition and add up the numbers returned by each subproblem. 

We give now a construction to solve this two-sided problem for uncertain points in  inspired by that of Kaplan \etal~\cite{colors}, but we require specifying a fixed value of .  Given an uncertain point  assume w.l.o.g that .  Also pretend there is a point  where  is larger than any  from a query range  (essentially ).  
Given a range , we consider the right-most set of  locations of  (here ) that are in the range.  This satisfies 
(i) , 
(ii) , and 
(iii) to ensure that it is the right-most such set, .  

To satisfy these three constraints we re-pose the problem in  to designate each contiguous set of  possible locations of  as a single point.  So for , we map  to .  
Correspondingly, a range  is mapped to a range ;  
see Figure \ref{fig:queryreduction}.
Let  denote the set of all , and let  represent .  
 
\begin{figure}[t]
\centering
\includegraphics[width=0.8\linewidth]{lifting}
\vspace{-4mm}
\caption{\small Uncertain point  queried by range .  Lifting shown to  along dimensions 1 and 2 (left) and along dimensions 2 and 3 (right).
\vspace{-4mm}
}  

\label{fig:queryreduction}
\end{figure} 
 
\begin{lemma}
 is in interval  with threshold at least  if and only if .
Furthermore, no two points  can map to points  such that both are in a range .  
\end{lemma}
 
\begin{proof}
Since , then if  it implies all  for , and similarly, if  then all  for all .  Hence if  satisfies the first two dimensional constraints of the range , it implies  points  are in the range .  
Satisfying the constraint of  in the third coordinate indicates that .  There can only be one point  which satisfies the constraint of the last two coordinates that .  And for any range which contains at least  possible locations, there must be at least one such set (and only one) of  consecutive points which has this satisfying .  
\end{proof}

\begin{corollary}
Any uncertain point set  of size  and range  has .  
\end{corollary}

This presents an alternative view of each uncertain point in  with  possible locations as an uncertain point in  with  possible locations (since for now we only consider a threshold ).  Where  represents the family of ranges defined by two-sided intervals, let  be the corresponding family of ranges in  of the form  corresponding to an interval .  Under the assumption (valid under the lifting defined above) that each uncertain point can have at most one location fall in each range, we can now decompose the ranges and count the number of points that fall in each sub-range and add them together.  
Using the techniques (described in detail in Section \ref{subsec:highdre}) of Bohus~\cite{bohus} and Spencer \etal~\cite{spencer} we can consider  permutations of  such that each range  can be written as the points in a disjoint union of intervals from these permutations.  
To extend low discrepancy to \emph{each} of the  distinct values of threshold , there are  such liftings and  such permutations we need to consider.   We can construct a coloring  such that intervals on each permutation has discrepancy . Recall that for any fixed threshold  we only need to consider the corresponding  permutations, hence the total discrepancy for any such range is at most the sum of discrepancy from all corresponding 
 permutations or .  
Finally, this low-discrepancy coloring can be iterated (via Theorem \ref{thm:disc2samp}) to achieve the following theorem.  

\begin{theorem}\label{thm:rcsample1d}
Consider an uncertain point set  along with ranges  of two-sided intervals.  We can construct an -RC coreset  for  of size .  
\end{theorem}
 


\subsection{\RC Coresets for Rectangles in }

The approach for  can be further extended to , axis-aligned rectangles in . Again the key idea
is to define a proxy point set  such that  equals the number of uncertain points in  with
at least threshold . This requires a suitable lifting map and decomposition of space to prevent over or under counting;
we employ techniques from Kaplan \etal~\cite{colors}.

First we transform queries on axis-aligned rectangles in  to the semi-bounded case in .  Denote the -coordinate of a point  as , we double all the coordinates of each point  to obtain point  in . 
Now answering range counting query  is equivalent to solving the query  
on the lifted point set.

Based on this reduction we can focus on queries of \emph{negative orthants} of the form  and represent each orthant by its apex  as .  Similarly, we can define  as \emph{positive orthants} in the form . For any point set  define .

A \emph{tight} orthant has \emph{a} location of  incident to every bounding facet.    
Let  be the set of all apexes representing tight negative orthants that contain exactly  locations of ; see Figure \ref{fig:rc123}(a).   An important observation is that query orthant  contains  with threshold at least  if and only if it contains at least one point from .
 
Let  be the locus of all negative orthant query apexes that contain at least  locations of ; see Figure \ref{fig:rc123}(b).  
Notice that .
 
\begin{figure}[t]
\centering
\includegraphics[width=0.3\linewidth]{rc-left}
\hspace{2mm}
\includegraphics[width=0.3\linewidth]{rc-middle}
\hspace{2mm}
\includegraphics[width=0.3\linewidth]{rc-right}

\vspace{-1mm}
(a)  \hspace{1.85in} (b) \hspace{1.85in} (c)

\vspace{-3mm}
\caption{\small Illustration of uncertain point  with  and . 
(a) All tight negative orthants containing exactly  locations of , their apexes are . 
(b):  is shaded and query .
(c): , the maximal negative orthants of  that are also bounded in the -direction.  
\vspace{-4mm}}

\label{fig:rc123}
\end{figure}


\begin{lemma}
For any point set  of  points and some threshold , we can decompose  into  pairwise disjoint boxes, .
\end{lemma}
 
\begin{proof}
Let  be the set of maximal empty negative orthants for a point set , such that any  is also bounded in the positive direction 
along the st coordinate axis.  
Kaplan \etal~\cite{colors} show (within Lemma 3.1) that  and provide a specific construction of the boxes .  Thus we only need to bound  to complete the proof; see  in Figure \ref{fig:rc123}(c).  
We note that each coordinate of each  must be the same as some .  Thus for each coordinate, among all  there are at most  values.  And each maximal empty tight orthant  is uniquely defined by the  coordinates along the axis direction each facet is orthogonal to.  Thus , completing the proof.  
\end{proof}
 
Note that as we are working in a lifted space , this corresponds to  being decomposed into  pairwise \emph{disjoint} boxes in which  is the dimensionality of our original point set.

 
\begin{lemma}
For negative orthant queries  with apex  on uncertain point set , a point  is in  with probability at least  if  is in some box in , and  will lie in at most one box from .  
 \end{lemma}
\begin{proof}
The query orthant  contains point  with threshold at least  if and only if  contains at least one point from  and this happens only when . Since the union of constructed boxes in  is equivalent to  and they are disjoint, the result follows.
\end{proof} 
 
\begin{corollary}
The number of uncertain points from  in query range  with probability at least  is exactly the number of boxes in  that contain .  
 \end{corollary}
 
Thus for a set of boxes representing , we need to perform count stabbing queries with apex  and show a low-discrepancy coloring of boxes.  

We do a second lifting by transforming each point  to a semi-bounded box  and each box   of the form  to a point  in . It is easy to verify that  if and only if .

 
Since this is our second doubling of dimension, we are now dealing with points in . Lifting  to  in  now presents an alternative view of each uncertain point  as an uncertain point  in  with  possible locations with the query boxes represented as  in .

 We now proceed similarly to the proof of Theorem \ref{thm:rcsample1d}. For a fixed threshold , obtain  disjoint permutations of  such that each range  can be written as the points in a disjoint union of intervals from these permutations. 
 For the  distinct values of , there are  such liftings and  such permutations we need to consider, and we can construct a coloring  so that intervals on each permutation have discrepancy  
  Hence for any such range and specific threshold , the total discrepancy is the sum of discrepancy from all corresponding  permutations, or .  
By applying the iterated low-discrepancy coloring (Theorem \ref{thm:disc2samp}), we achieve the following result.

\begin{theorem}
\label{thm:RC-Rd}
Consider an uncertain point set  and range space  with ranges defined by axis-aligned rectangles in . 
Then an -\RC coreset can be constructed of size .
\end{theorem}



\section{\RQ Coresets}



In this section, given an uncertain point set  and its -\RE coreset , we want to determine values  and  so  is an -\RQ coreset.  
That is for any  and threshold  there exists a  such that 


At a high level, our tack will be to realize that both  and  behave like Binomial random variables.  By  being an -\RE coreset of , then after normalizing, its mean is at most -far from that of .  Furthermore, Binomial random variables tend to concentrate around their mean--and more so for those with more trials.  This allows us to say  is either -close to the expected value of  or is -close to  or .  Since  has the same behavior, but with more concentration, we can bound their distance by the  and  bounds noted before.  We now work out the details.  
  
\begin{theorem}
If  is an -\RE coreset of  for , 
then   is an -\RQ coreset for  for  and satisfying
.  
\label{thm:RQ-CLM}
\end{theorem}
\begin{proof}
We start by examining a Chernoff-Hoeffding bound on a set of independent random variables   so that each  with .  Then for some parameter  


Consider any .  
We now identify each random variable  (that is,  if  and  otherwise) where  is the random instantiation of some .  So  and .  
Thus by equating 

Thus by solving for  (and equating )

Now by  being an -\RE coreset of  then 

Combining these two we have

for .  



Combining these statements, for any  
we have 
 and  (and symmetrically for .  
It follows that  is an -quantization of .  

Since this holds for any , by  being an -\RE coreset of , it follows that  is also an -\RQ coreset of .  
\end{proof}



We can now combine this result with specific results for -\RE coresets to get size bounds for -\RQ coresets.  To achieve the below bounds we set .  


\begin{corollary}
For uncertain point set  with range space , there exists a -RQ coreset of  of size 
\begin{itemize} \denselist
\item  when  has VC-dimension , with probability  (Theorem \ref{thm:RE-samp}),
\item  when  (Theorem \ref{thm:1deps-RE}), and
\item  when  (Theorem \ref{thm:highdeps-RE}).
\end{itemize}
\end{corollary}


Finally we discuss why the  term in the -\RQ coreset  is needed.  
Recall from Section \ref{sec:rec} that approximating the value of   with  for all  corresponds to a low-discrepancy sample of . Discrepancy error immediately implies we will have at least the  horizontal shift between the two distributions and their means, unless we could obtain a zero discrepancy sample of .  Note this -horizontal error corresponds to the  term in an -\RQ coreset.  
When  is very large, then due to the central limit theorem,  will grow very sharply around .  
In the worst case  may be  vertically away from  on either side of , so no reasonable amount of  vertical tolerance will make up for this gap.  

On the other hand, the  vertical component is necessary since for very small probability events (that is for a fixed range  and small threshold ) on , we may need a much smaller value of  (smaller by ) to get the same probability on , requiring a very large horizontal shift.  But since it is a very small probability event, only a small vertical  shift is required.  

The main result of this section then is showing that there exist pairs  which are both small.  



\section{Conclusion and Open Questions}
This paper defines and provides the first results for coresets on uncertain data.  These can be essential tools for monitoring a subset of a large noisy data set, as a way to approximately monitor the full uncertainty.  

There are many future directions on this topic, in addition to tightening the provided bounds especially for other range spaces.  Can we remove the dependence on  without random sampling?   Can coresets be constructed over uncertain data for other queries such as minimum enclosing ball, clustering, and extents?  

 \bibliography{uncertain}
\bibliographystyle{acm}

\appendix
\section{Low Discrepancy to -Coreset}
\label{app:MR}

Mainly in the 90s Chazelle and Matousek~\cite{CW89,CM96,divide,Mat99,Cha01} led the development of method to convert from a low-discrepancy coloring to a coreset that allowed for approximate range queries.  Here we summarize and generalize these results.  


We start by restating a results of Phillips~\cite{Phi08,Phi09} which generalizes these results, here we state it a bit more specifically for our setting.  

\begin{theorem}[Phillips~\cite{Phi08,Phi09}]
Consider a point set  of size  and a family of subsets .
Assume an  time algorithm to construct a coloring  so  where , , and  are constant algorithm parameters dependent on , but not  (or ).  
There exists an algorithm to construct an -sample of  of size  in time 
.  
\label{thm:disc2samp}
\end{theorem}

Note that we ignored non-exponential dependence on  and  since in our setting they are data and problem independent constants.  But we are more careful with  terms since they depend on , the number of locations of each uncertain point.  

We restate the algorithm and analysis here for completeness, using  for shorthand.  
Divide  into  parts  of size .  Assume this divides evenly and  is a power of two, otherwise pad  and adjust  by a constant.  
Until there is a single set, repeat the following two stages.  
In stage 1, for  steps, pair up all remaining sets, and for all pairs (e.g.  and ) construct a low-discrepancy coloring  on  and discard all points colored  (or  at random).  In the rd step pair up all sets, but do not construct a coloring and halve.  
That is every epoch ( steps) the size of remaining sets double, otherwise they remain the same size.  
When a single set remains, stage 2 begins; it performs the color-halve part of the above procedure until  as desired.  

We begin analyzing the error on a single coloring.  
\begin{lemma}
The set  is an -sample of .  
\label{lem:1round}
\end{lemma}
\begin{proof}

\end{proof}
We also note two simple facts~\cite{Cha01,Mat99}:
\begin{itemize}
\item[(S1)] If  is an -sample of  and  is an -sample of , then  is an -sample of .  
\item[(S2)] If  is an -sample of  and  is an  sample of , then  is an -sample of .  
\end{itemize}
Note that (S1) (along with Lemma \ref{lem:1round}) implies the arbitrarily decomposing  into  sets and constructing colorings of each achieves the same error bound as doing so on just one.  And (S2) implies that chaining together rounds adds the error in each round.  
It follows that if we ignore the rd step in each epoch, then there is  set remaining after  steps.  The error caused by each step is  so the total error is .  Solving for  yields
.  

Thus to achieve the result stated in the theorem the rd step skip of a reduce needs to remove the  term from the error.  This works!  After  steps, the size of each set is  and the discrepancy error is .  This is just more than half of what it was before, so the total error is now:
  Solving for  yields  as desired.  
Stage 2 can be shown not to asymptotically increase the error.  

To achieve the runtime we again start with the form of the algorithm without the halve-skip on every rd step.  Then the first step takes  time.  And each th step takes  time.  Since each subsequent step takes half as much time, the runtime is dominated by the first  time step.  

For the full algorithm, the first epoch ( steps, including a skipped halve) takes  time, and the th epoch takes  time.  Thus the time is still dominated by the first epoch.  Again, stage 2 can be shown not to affect this runtime, and the total runtime bound is achieved as desired, and completes the proof.  

Finally, we state a useful corollary about the expected error being .  This holds specifically when we choose to discard the set  or  at random on each halving.  

\begin{corollary}
\label{cor:E0}
The expected error for any range  on the -sample  created by Theorem \ref{thm:disc2samp} is 
  
\end{corollary}
Note that there is no absolute value taken inside , so technically this measures the expected undercount. 


\Paragraph{\RE-discrepancy}
We are also interested in achieving these same results for \RE-discrepancy.  To this end, the algorithms are identical.  Lemma \ref{lem:REcolor} replaces Lemma \ref{lem:1round}.  (S1) and (S2) still hold.  Nothing else about the analysis depends on properties of  or \RE-, so Theorem \ref{thm:disc2samp} can be restated for \RE-discrepancy.  


\begin{theorem}
Consider an uncertain point set  of size  and a family of subsets  of .
Assume an  time algorithm to construct a coloring  so \RE- where , , and  are constant algorithm parameters dependent on , but not  (or ).  
There exists an algorithm to construct an -\RE coreset of  of size  in time 
.  
\label{thm:RE-disc2samp}
\end{theorem}



\end{document}
