\documentclass[11pt]{amsart}
\usepackage{fullpage}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{fullpage}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{mydefs}


\newcommand{\prob}[1]{\textsf{#1}}  \newcommand{\myparagraph}[1]{\smallskip\noindent\textbf{#1}\quad}


\newcommand{\alg}[1]{\textbf{#1}}   

\def\calP{{\mathcal P}}   \def\calM{{\mathcal M}}   \def\calU{{\mathcal U}}   \newcommand{\PCopt}{\overline{OPT}}
\def\affm{\mathbf{A}}
\newcommand{\trace}{{Se}}

\newlength{\tablength}
\newlength{\spacelength}
\settowidth{\tablength}{\mbox{\ \ \ \ \ \ \ \ }}
\settowidth{\spacelength}{\mbox{\ }}
\newcommand{\tab}{\hspace{\tablength}}
\newcommand{\tabstar}{\hspace*{\tablength}}
\newcommand{\spacestar}{\hspace*{\spacelength}}
\def\obeytabs{\catcode`\^^I=\active}
{\obeytabs\global\let^^I=\tabstar}
{\obeyspaces\global\let =\spacestar}

\newenvironment{display}{\begingroup\obeylines\obeyspaces\obeytabs}{\endgroup}
\newenvironment{prog}{\begin{display}\parskip0pt\sf}{\end{display}}
\newenvironment{pseudocode}{\smallskip\begin{quote}\begin{prog}}{\end{prog}\end{quote}\smallskip}
\newenvironment{pseudo}{\begin{quote}\begin{prog}}{\end{prog}\end{quote}}



\newcommand{\biopt}{OPT^B}
\newcommand{\bipcopt}{\PCopt^B}
\def\hi{{1}}
\def\hj{{\hat{j}}}




\begin{document}
\title[Wireless Capacity With Arbitrary Gain Matrix]{Wireless Capacity With Arbitrary Gain Matrix}


\author[M. Halld\'orsson]{Magn\'us M. Halld\'orsson}
\address[M. Halld\'orsson]{School of Computer Science\\
Reykjavik University\\
Reykjavik 101, Iceland}
\email{mmh@ru.is}

\author[P. Mitra]{Pradipta Mitra}
\address[P. Mitra]{School of Computer Science\\
Reykjavik University\\
Reykjavik 101, Iceland}
\email{ppmitra@gmail.com}



\begin{abstract}
Given a set of wireless links, a fundamental problem is to find the largest subset that can transmit simultaneously, within the SINR model of interference. Significant progress on this problem has been made in recent years. In this note, we study the problem in the setting where we are given a fixed set of arbitrary powers each sender must use, and an arbitrary gain matrix defining how signals fade. This variation of the problem
appears immune to most algorithmic approaches studied in the literature. Indeed it is very hard to approximate since 
it generalizes the max independent set problem.
Here, we propose a simple semi-definite programming approach to the problem that yields constant factor approximation, if the optimal solution is  strictly larger than half of the input size.
\keywords{Wireless Networks, Capacity, SINR Model, Semidefinite programming.}
\end{abstract}

\maketitle

\section{Introduction}
We consider the fundamental problem of wireless network capacity.
Given is a set
 of links, where
each link  represents a communication request from a sender
 to a receiver .  We are also given,
for every , a transmission power . 
The powers received from senders to receivers are defined by an  dimensional gain matrix  with positive entries. Specifically, the signal received from  at  is . Thus an instance in this model
can be described by the tuple  where  is the vector of the power assignments  for all .

 Simultaneously communicating links interfere with each other,
following the  physical model or ``SINR model" of interference.
Due to its higher fidelity to reality~\cite{GronkMibiHoc01,MaheshwariJD08,Moscibroda2006Protocol},
this model of interference has recently gained substantial  attention in the analysis of wireless networks.
In this model, a receiver 
successfully receives a message from a sender  if and only if the
following condition holds:

where  is a universal constant denoting the ambient noise,  denotes the minimum
SINR (signal-to-interference-noise-ratio) required for a message to be successfully received,
and  is the set of concurrently scheduled links in the same \emph{slot}. We say that a link  is feasible in  if Eqn. \ref{eq:sinr} is satisfied for .
A set  is feasible if each of its link is feasible.  

Note that what we described above is the abstract SINR model.
In the more commonly studied geometric SINR model,  is a polynomial function of ,
where  is the distance between two points  and . Our results naturally apply to that model
as well. Given that the geometric SINR model does not capture obstacles, reflections and other real life distortions, 
it is interesting to see what can be proven in the abstract model.

Our setting where the powers are given as part of the input is often called the \emph{fixed} power case,
as opposed to the \emph{power control} case where the algorithm can choose the power assignment.
So far, research on fixed power
has focused on \emph{oblivious} power assignments, where the power
of a link is a (usually simple) function of the length of the link \cite{HW09,FKRV09,KV10,SODA11}.
Recently, a constant factor approximation algorithm to find the capacity in the power control case 
has also been achieved \cite{KesselheimSoda11}. Unfortunately, none 
of these techniques appear to extend to the case of arbitrary fixed powers (for either arbitrary or geometric gain matrices). Yet, the problem of arbitrary fixed powers
is not only natural, but has practical relevance, as commercial hardware often do not 
have the capacity of choosing precise powers to implement either an arbitrary assignment \emph{\`{a} la} \cite{KesselheimSoda11}, or to implement many of the oblivious power assignments found in literature.

In this paper, we prove the following theorem.
\begin{theorem}
Assume  is an instance of the capacity problem in the abstract SINR model, such that  for some , where  is the maximum feasible subset of  using . Then there is a polynomial time randomized algorithm to find a feasible set of size , with probability .
\label{mainth1}
\end{theorem}


We do this by means of a semi-definite programming relaxation, which we show how to successfully round if the condition 
   holds. In addition, we discuss numerical experiments we have performed. These experiments show that the algorithm appears to work quite well on random instances, even better than the guarantees of
 Thm. \ref{mainth1}.
 
 Semi-definite programming has been a staple in designing approximation algorithms for NP-hard problems ever
 since the seminal work of Goemans and Williams on the Max-CUT problem \cite{Goemans:1995:IAA:227683.227684}. 
 It is interesting to note that the discrete ``classical" problems closest to wireless capacity, namely the independent set
 problem and the graph coloring problem, have been  fruitfully studied using semi-definite programming \cite{Halperin:2002:CK-:606216.606221,Karger:1998:AGC:274787.274791}. The vertex cover problem, also relevant via its connection
 to the independent set problem,  also has
SDP-based approximation algorithms 
\cite{Halperin:2000:IAA:338219.338269,Karakostas:2009:BAR:1597036.1597045}. Given this background, one may expect some of the techniques to easily carry over to the capacity
 problem. Yet that does not appear to be the case, at least not in a straightforward manner. A study of the aforementioned
 papers reveal that the discreteness of the problem plays an important role in the bounds. For example, in 
\cite{Karger:1998:AGC:274787.274791}, the analysis proceeds by bounding the probability of vectors representing edges not being cut by a random hyperplane. Given the additive nature of the SINR model, it is not obvious
how to extend that analysis to this case. There  have also been a number of results for these problems on hypergraphs \cite{Krivelevich:2001:ACM:365411.365469,DBLP:conf/focs/Chlamtac07,DBLP:conf/approx/ChlamtacS08}. Though hypergraphs appear to be closer in spirit to the additive wireless model, they
are still different, because the effect of each node on 
any other node doesn't change in the SINR model (as opposed to in a hypergraph, where it can be different based on which edge they are in). Thus, the (sophisticated) methods on hypergraphs 
do not appear to  translate immediately to the SINR model either. Our SDP relaxation and rounding algorithms are
quite simple in contrast to some of the previously mentioned work. Whether or not advanced techniques can be extended to the SINR model remains to be seen. 

 


\subsection{Related Work.}

Moscibroda and Wattenhofer \cite{MoWa06} were the first to
study of the \emph{scheduling complexity} of arbitrary set
of wireless links. 
Early work on approximation algorithms
 produced approximation
factors that grew with structural properties of the network \cite{moscibroda06b,MoscibrodaOW07,chafekar07}.


The first constant factor approximation algorithm was obtained for
capacity problem for uniform power in \cite{GHWW09} (see also
\cite{HW09}) in  with .
Fangh\"anel, Kesselheim and V\"ocking \cite{FKV09} gave an algorithm
that uses at most  slots for the scheduling problem
with \emph{linear} power assignment ,
that holds in general distance metrics.


Kesselheim obtained 
a -approximation algorithm
for the capacity problem with power control for doubling metrics \cite{KesselheimSoda11}. Around the same time,
the first constant factor algorithm for all sub-linear, length monotone power assignments
was achieved on general metrics \cite{SODA11}. Other recent studies in the SINR model
include work on topological maps \cite{stoc_topology11}, distributed algorithms for scheduling \cite{icalp11},
distributed power control \cite{damsicalp11} and auction based spectrum allocation \cite{hoeferspaa11}.







\section{SDP-based algorithm.}

First, some notation. Vectors are denoted by  etc. The standard -norm of the vector  is . The 
entry of  is .
The inner product of vectors  and  is denoted . Define  and  for . 
Note that we can assume without loss of generality that .
Let  be a feasible subset of 
of maximum size. Note that .

Consider the following program.


where . Each link  has a vector variable  associated
with it. The dot product of  with a vector  denotes  the (fractional) extent to which  is
selected in the solution. 

Since the objective function and constraints are all linear functions of vector inner products, this
problem is a SDP. Thus the program can be solved up to an additive error of  in time that is polynomial in 
 and  \cite{Vandenberghe94semidefiniteprogramming}. Since  can be made small enough to not matter, we will simply
assume that the problem can be solved exactly.

We can rotate the vectors to fix , thus the above program is equivalent to:




Let us verify that this program is a relaxation of the maximum capacity problem. 
\begin{lemma}
The SDP is a relaxation of the original problem.
\end{lemma}
\begin{proof}
Consider any optimal solution  to the capacity problem.
For all , set . 
If  
set 

In other words, we make sure that each unselected link chooses a different position
for the single  in the vector. 

Given these assignments, Equations \ref{sdp:o1}, \ref{sdp:o2} and \ref{sdp:o3} can easily seen to hold.

To show that Eqn. \ref{sdp:eqSINR} is satisfied, first assume . The following observation is immediate:
\begin{claim}
If  then . If 
then  and  for any .
\end{claim}

Since ,

And,

where the second equality follows from the claim above.

Now, since ,  (by Eqn \ref{eq:sinr}). Thus, the above two equations show that Eqn. \ref{sdp:eqSINR} is satisfied when . The
case where  is similar.

For Eqn. \ref{sdp:eqSp}, the following observations suffice:
\begin{itemize}
\item If ,   
\item If , they have s in different positions and   
\item If , they have 1s in different positions and   
\end{itemize}
\qed
\end{proof}



Now we present our algorithm and the proof of Thm. \ref{mainth1}. We need two related definitions.
Let  for all . Further, define . The algorithm is as follows.


\begin{algorithm}                      \caption{Capacity1}          \label{alg1}                           \begin{algorithmic}[1]                    \STATE Solve the SDP
     \STATE Select each link  with probability  in to a set  
     \STATE Output 
\end{algorithmic}
\end{algorithm}

\begin{lemma}
\label{sumdelta}
If , then
.
\label{lemma1}
\end{lemma}
\begin{proof}
Since , it follows that  (since the SDP is a 
relaxation of the original problem). Now by definition of , .
Thus, 


Observing that  for  completes the proof. \qed
\end{proof}

\noindent We can now prove the main Theorem.

\begin{proof}{of Thm. \ref{mainth1}}





 Assume  that the random binary variable  describes whether or not  is chosen into . We observe that
 , according to the algorithm.
 
 Then for any ,
 
 
Now, by Eqn. \ref{sdp:eqSINR},

Since  for  and  is always non-negative, we get for ,

where the second inequality follows from Eqn. \ref{sdp:eqSp}, and the first equality follows from observing that  for .
 
 Then, for ,

The first equality is the definition of infeasiblity. The first inequality is Markov's inequality. The last inequality
follows from Equations \ref{infeasibprob1} and \ref{infeasibprob2}.

Now the expected size of the output is


The second equality follows from the independence of the events concerned. 
The first inequality follows from Eqn. \ref{eqn:infeasibbound}.
The last
inequality follows from Lemma \ref{lemma1}.
Thus the expected size of the feasible output is .
It is not difficult to boost the probability of getting a  size subset to complete
the proof of the theorem. \qed
\end{proof}

\section{Numerical Experiments}
We ran  simulations to test how well the algorithm does in practice. We used \texttt{CVX}, a package for specifying and solving convex programs using MATLAB \cite{cvx}. We ran it on version 7.8 of MATLAB running on a Macbook with a 2 GHz Intel Core 2 Duo Processor and 2 GB of RAM. 

We generated a number of problem instances where  and  and . The instances
were generated as follows. To generate the feasible subset a large random instance  of links on the 2d plane was generated. Each sender  is a random point in a  box. The receiver  is defined by  where  and  are sampled uniformly at random from . We generated  corresponding gain matrices using the geometric SINR model setting  (thus ). We used both uniform ( is a constant) and mean power assignments () to generate the gain matrix. We set the noise  throughout the experiments.

To generate the input instance  (which is a  matrix), we combined a subset of  with random entries.
More specifically, first we retrieved a random feasible subset  of  (found greedily). This defined a
 submatrix of . The remaining entries were chosen iid randomly from , where
 was chosen large enough so that the remaining  links would not contain a large feasible subset, thus  would be  for the instance.

Though computationally slow (for  the SDP took a few minutes to be solved), the algorithm performed extremely well. Indeed, it took some time to come up with instances where the algorithm didn't have a perfectly integral solution. If the random entries of  corresponding to  were too large (corresponding to a large , meaning that  contained only very small subsets that were feasible) or if  was too \emph{loosely} feasible (ie, Eqn. \ref{sdp:eqSINR} was far from being tight for most of the links), the algorithm did exceedingly well.



\begin{figure}
\begin{center}
\includegraphics[height=2.7in]{figU}
\caption{ vs the average size of the set found by the SDP algorithm. In each case .} \label{fig:uniform}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[height=2.7in]{figM}
\caption{ vs the average size of the set found by the SDP algorithm. In each case  and the links in  were generated using mean power. The labels in the -axis describe the configuration of the instances. Thus, in the first case, the instance is an union of  feasible sets of size 21, 20 and 20, respectively, where the latter two are copies of subsets of the first one.} \label{fig:mean}
\end{center}
\end{figure}


Even after trying to make the problem more difficult, the algorithm did quite well, only degrading when , for which we claim no theoretical guarantee anyway, though even in these cases the output was not unsatisfactory. Indeed,
in all these cases, using the simple filtering  identified  almost exactly. Our sampling algorithm, by design cannot achieve better than a factor  approximation in general, and that is almost what we achieved in all cases, as illustrated in Figure \ref{fig:uniform} for uniform power (the results for mean power were essentially identical).

As we have mentioned, in the above experiments, the algorithm sharply identified . To create more
ambiguous instances, we also tried the following. In this setting, we took a feasible set, and added copies of subsets of
it. Thus the instance would be of the form  or  where  is feasible, and
 are copies of subsets of . One expects the solution to be more ``spread out" in this case, and that is exactly what we found.
The algorithm still performed rather well, even below theoretically guaranteed levels, though the behavior is somewhat different. Figure \ref{fig:mean} demonstrates the case for mean power.




\section{Conclusion}
We have shown how to use semi-definite programming to approximate the wireless capacity problem in cases where the capacity is known to be large. It is an interesting question whether or not these results can be further improved, potentially using the power of geometric SINR model. Questions about the integrality gap and hardness of the problem (apart from what is known via the fact that the problem generalizes max independent set) also deserve attention. Though we have performed some preliminary numerical experiments, the efficacy of this method both in terms of accuracy and computational efficiency also is an interesting avenue of further investigation.

\bibliographystyle{plain}
\bibliography{references}		


\end{document}
