\documentclass{llncs}

\usepackage{xspace,amsmath,url}

\newcommand{\ceil}[1]{\lceil #1 \rceil}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}

\def \bxor{\textsf{xor}\xspace}
\def \band{\textsf{and}\xspace}

\newcommand{\uxor}{\mathrel{^\wedge}}
\newcommand{\uand}{\mathrel{\&}}
\newcommand{\uor}{\mathrel{|}}
\newcommand{\unot}{\mathop{\sim}}
\newcommand{\fsize}{f}
\newcommand{\bsize}{b}
\newcommand{\len}{r}
\newcommand{\word}[1]{#1}
\newcommand{\sabound}{\xspace}
\newcommand{\acbound}{\xspace}
\newcommand{\wrbound}{\xspace}
\newcommand{\fword}[1]{-word}

\sloppy

\begin{document}

\title{Approximate pattern matching with -mismatches in packed text\thanks{This paper is an extended version of the article that appeared in \emph{Information Processing Letters} 113(19-21):693-697 (2013), http://dx.doi.org/10.1016/j.ipl.2013.07.002}}

\author{Emanuele Giaquinta\inst{1} \and Szymon Grabowski\inst{2} \and Kimmo Fredriksson\inst{3}}

\institute{Department of Computer Science, University of Helsinki, Finland
	  \email{emanuele.giaquinta@cs.helsinki.fi} \and
	  Lodz University of Technology, Institute of Applied Computer Science, Al.\ Politechniki 11, 90--924 {\L}\'od\'z, Poland
	  \email{sgrabow@kis.p.lodz.pl} \and
          School of Computing, University of Eastern Finland, P.O. Box\ 1627, FI-70211 Kuopio, Finland
          \email{kimmo.fredriksson@uef.fi}
}

\maketitle

\begin{abstract}
Given strings  of length  and  of length  over an alphabet
of size , the string matching with -mismatches problem is
to find the positions of all the substrings in  that are at Hamming
distance at most  from . If  can be read only one character
at the time the best known bounds are  and  in the word-RAM model with word length .
In the RAM models (including  and word-RAM)
it is possible to read up
to  characters in constant time if the
characters of  are encoded using  bits. The
only solution for -mismatches in packed text works in \sabound
time, for any . We present an algorithm that runs in
time \acbound in the  model if  and  is
given packed. We also describe a simpler variant that runs in time
\wrbound in the word-RAM model. The algorithms improve the existing
bound for , for any . Based on the introduced technique, we present
algorithms for several other approximate matching problems.
\end{abstract}

\section{Introduction}
\noindent
The string matching problem consists in reporting all the occurrences
of a pattern  of length  in a text  of length , both strings over a common alphabet. The
occurrences may be exact or approximate according to a specified
matching model.
For most matching problems, all the characters from the text and the
pattern need to be read at least once in the worst case; hence, if
they are read one at a time, the worst-case lower bound is
.
Interestingly, for some standard problems (e.g., exact pattern
matching) it is possible to achieve a sublinear search time, for short
patterns, even in the worst case, if the word-RAM computational model
is assumed and the text is {\em packed}. In a packed encoding, the
characters of a string are stored adjacently in memory and each
character is encoded using 
bits\footnote{Throughout the paper, all logarithms are in base 2.
  W.l.o.g. we also assume that  is a power of two.}, where
 is the alphabet size. A single machine word, of size  bits, thus contains up to 
characters.
While the word size of current architectures is  (which, for
example, permits up to  DNA symbols to be encoded in a word), there are also
vector instruction sets where the word size is larger, such as SSE and
AVX ( and  bits) or the Intel Xeon Phi coprocessor (
bits).


For this setting and the exact string matching problem, several
sublinear-time algorithms have been given in recent
years~\cite{Fredriksson2002,Bille2011,Belazzougui2012jda,Ben-KikiBBGGW2011,BreslauerGG2012}.

In this paper we study the string matching with -mismatches problem
in the packed scenario. This problem is to find
the positions of all the substrings in  that are at Hamming
distance at most  from , i.e., that match  with at most 
mismatches. For this problem, the best known bounds in the worst-case
are  time for the algorithm by Amir et
al.~\cite{DBLP:journals/jal/AmirLP04} and 
time for its implementation based on word-level
parallelism~\cite{DBLP:journals/ejc/FredrikssonG13}. One classical
result in the word-RAM model that is also practical is Shift-Add~\cite{DBLP:journals/cacm/Baeza-YatesG92}.
The best worst-case bound of this algorithm, based on the Matryoshka counters
technique~\cite{DBLP:journals/ipl/GrabowskiF08}, is .

In~\cite{Fredriksson2002} Fredriksson presented a Shift-Add variant,
based on the super-alphabet technique, that works in \sabound time,
for any . To our knowledge, this is the only solution
for the -mismatches problem that works on packed text and that
achieves sublinear time complexity when  and  are sufficiently
small.

In this work, we present an algorithm for the -mismatches problem
that runs in time \acbound in the  model for  if
 is given packed. We also describe a simpler variant that runs in
time \wrbound in the word-RAM model. In particular, it achieves
sublinear worst-case time when . Note that for  Fredriksson's solution is
better, but our algorithm dominates if , for any , or, more precisely, if .


\section{Basic notions and definitions}
\noindent
Let  denote an integer alphabet
and  the set of all possible
sequences of length  over .
, denotes the -th character of string , and
 its substring between the -st and the
-st characters (inclusive).

The -mismatches problem consists in, given a pattern (string) 
of length  and a text (string)  of length , reporting all the
positions  such that , i.e., such that the Hamming distance between
 and the substring 
is at most .

The word-RAM model is assumed, with machine word size . We use some bitwise operations following the standard notation as
in C language: , , , , ,  for
\texttt{and}, \texttt{or}, \texttt{xor}, \texttt{not}, \texttt{left
  shift} and \texttt{right shift}, respectively.

\section{Operations on words}

We define a \fword{f} as a machine word logically divided into
 fields of  bits. Given a \fword{f} ,
we denote with  its -th field, for
. The most significant bit in a field is
called the \emph{top} bit.
A field where only the top bit is set is thus equal to .
We also define, for a given field size
, the \emph{mask}  where , for . We define the following
primitives on words:

\medskip
\noindent\emph{find non-zero fields} (\textsf{fnf}()): given a
\fword{\fsize} , return a \fword{\fsize} 
such that  is equal to  if
, and to  otherwise, for
.
\smallskip

\noindent How to implement this primitive in  time was presented
in~\cite[Sect.~4]{BreslauerGG2012}, but we give a simpler method, in
three simple steps and in constant time.
\begin{enumerate}
\item 
\item 
\item 
\end{enumerate}
The first two steps generate a \fword{\log\sigma}  such
that  if  with the
top-bit masked is zero, and  otherwise. It is
then not hard to see that  is non-zero iff either
 or , from which follows the correctness of the last
step.

\medskip
\noindent\emph{sideways addition} (\textsf{sa}()): given a word ,
return the number of bits set in .
\smallskip

\noindent This primitive is a well-known bitwise operation, also known
as popcount. The folklore
method~\cite{DBLP:conf/wea/Vigna08}
to compute it in the word-RAM model has  time complexity.

\medskip
\noindent\emph{interleaved blockwise sideways addition} (\textsf{ibsa}()):
Given a \fword{\fsize} , such that  divides  and
only the top bit of each field may be set, and a power of two ,
return a \fword{\fsize}  such that  is equal to

where , i.e., the -th field contains the
number of bits set in the sequence of 
fields in  spaced by  bits ending at .
\smallskip

\noindent This operation is a variant of the parallel prefix-sum operation
described in~\cite{HS1986} and can be implemented in 
steps, where the -th step computes

Since  does not necessarily hold, the top
bits of all the fields are masked out before each addition and
restored afterwards. In this way, if a sum is , its
encoded value is  but the exact value is
undetermined.

\medskip
\noindent\emph{blockwise sideways addition} (\textsf{bsa}(): Given a \fword{\fsize} , such that only
the top bit of each field may be set, and a power of two ,
return a \fword{b\fsize}  such that  is equal to

where , i.e., the
-th field contains the number of bits set in the block of
 fields in  ending at .
\smallskip

\noindent This operation can be implemented in time  in word-RAM and in time  in
 using the following method. We assume that the word size  is
a power of two.
Let  be the smallest power of two greater than or equal to
. The first step consists in computing a word logically
divided into fields of  bits, such that each
field contains the number of bits set in the corresponding
 fields in the original word. This widening
operation can be performed in  steps using simple bitwise operations and  masks.

Since both  and  are a power of two, each block of  bits spans an
integral number of fields of  bits. Observe
that there can be at most  bits set in a word, so  bits
are enough to encode the total number of bits. If ,
then since  is a power of two after the last widening step we
have a word divided into fields of  bits, each one
containing the desired number of ones. Otherwise, if ,
we compute the prefix sum of the sequence of numbers given by the
fields, i.e., we store into each field the sum of the previous fields
including itself. In word-RAM we do this by performing a
multiplication (which is ), with the mask . Instead, in  we use again the
parallel prefix-sum algorithm described in~\cite{HS1986}, which is
. It is not hard to see that, after this operation, the
number of bits in a block is equal to the last field of the block
minus the last field of the previous block. This operation can be
implemented in parallel for all the blocks with a shift and a subtraction.
Finally, to obtain the desired output word we reset to zero all the
fields but the last of each block, using an \band with the mask
,
and shift the word to the right by  bits.

The pseudocode of \textsf{bsa} in word-RAM is the following:
\begin{enumerate}
\item 
\item 
\item \textbf{for}  \textbf{to}  \textbf{do}
\item \qquad 
\item \qquad 
\item \qquad 
\item \textbf{if}  \textbf{then}
\item \qquad 
\item \qquad 
\item \qquad 
\end{enumerate}



\medskip
\noindent\emph{parallel minima (maxima)~\cite{PS1980}} (\textsf{pmin
  (pmax)}()): Given two \fword{f}s  and , return a
\fword{f}  such that  is equal to 
if  (), and to
 otherwise, for . \textsf{pvmin}
(\textsf{pvmax}) is similar, but  is equal to
 ().
\smallskip

\noindent These operations can be implemented in constant time, as demonstrated by the following code
(\textsf{pmin}):

\begin{enumerate}
\item 
\item 
\item 
\item 
\item 
\item 
\item 
\end{enumerate}

All the given bounds do not include the time to compute the used masks, if any.

\section{The algorithm}
\label{sec:the_algorithm}


\noindent
We start the presentation with a simple idea, which is then extended
and modified in some ways. Consider two
\fword{\log\sigma}s  and , each containing a
packed string of length  in its  least significant
bits (i.e., each field of  bits encodes a character). The
higher bits in both words, if any, are all 0s
We perform the \bxor operation of  and  and the
number of non-zero fields in the result is exactly the Hamming
distance between the two strings. To count the number of such fields,
we first convert, using the \textsf{fnf} operation, each non-zero
field into a field with only the top-bit set, and then count the number
of bits set using the \textsf{sa} operation.
The procedure to compute the Hamming distance of  and
 can thus be implemented in time  with the
following operations:
\begin{enumerate}
\item 
\item 
\item \textbf{return} 
\end{enumerate}
For arbitrary , observe that the packed encoding of a string of
length  requires  words, and the Hamming
distance between two such strings can be computed by running the above
procedure for each word and summing the outputs.

Using this method, we can obtain an algorithm for the string matching
with -mismatches problem that runs in  time for any . Note that the resulting algorithm
is also practical and compares favorably with the classical Shift-Add~\cite{DBLP:journals/cacm/Baeza-YatesG92}
for small alphabets
and large , although it is less flexible (no support for classes of
characters). It is also worth noting that recent processors include a
\textsc{POPCNT} instruction to compute the sideways addition of a
word, so the  term disappears in practice.

We now show how to apply the described ideas in an (improved)
algorithm for the -mismatches problem on packed text for short
patterns. In the following, we shall assume . Our method
exploits a general technique~\cite{DBLP:journals/jea/HyyroFN05} to
increase the parallelism in string matching algorithms based on
word-level parallelism. We present a solution in the 
model and a simpler variant in the word-RAM model.
We start with the word-RAM algorithm.
Let  be the smallest power of two greater than
or equal to  and let . We
first preprocess the pattern  to create a word  with
 copies of  of length  starting from the
least significant bit. The last  fields of each copy are
set to zero. We perform this padding because the \textsf{bsa} and
\textsf{ibsa} operations which we shall use require the size of the
blocks to be a power of two. Let
 be the word containing the packed encoding of the
substrings , for
, where , with
 zero (padding) fields every  fields (i.e., at the end
of each substring). For example, if
, ,  and , then we have
 and , where  denotes a padding field.
Note that because of this partitioning we do not process all the text
substrings in linear order. The word  can be computed in constant
time by extracting the substring  from
the packed text and clearing the padding fields with a mask.
Our search algorithm performs the following main steps, for each :
\begin{enumerate}
\item 
\item 
\item 
\item 
\end{enumerate}
where  and  is a
\fword{\fsize} with a copy of the integer  in each field.
At each iteration, our algorithm processes 
substrings of  in parallel using the technique to compute the
Hamming distance of two words described before. First, we perform the
\bxor and \textsf{fnf} operations to identify the mismatches for the
 substrings encoded in .
\begin{figure}[!t]
\begin{center}
\begin{scriptsize}
\renewcommand{\tabcolsep}{0.09cm}
\begin{tabular}{|rll|}
\hline
 &  &  \\
 &  &  \\
 &  &  \\
\hline
 \textsf{fnf}() & & \\
\hline
 &  &  \\
 &  &  \\
  &  &  \\
 &  &  \\
 &  &  \\
\hline
 &  &  \\
 &  &  \\
 &  &  \\
\hline
\end{tabular}
\end{scriptsize}
\end{center}
\caption{Example of the algorithm and of the \textsf{fnf} operation for , , ,  and . The word  encodes two pattern copies while the word  encodes the text substrings  and . Padding fields are underlined. The pattern matches the first and second substring with  and  mismatches, respectively. Since , only the first field is nonzero in the \textsf{pmin} output word.}
\label{fig:example}
\end{figure}
Then, we use the \textsf{bsa} operation to count the number of mismatches for each substring, i.e., we
compute a \fword{f} such that each field of
 bits contains the number of bits set
(mismatches) in the corresponding block of  fields of .
Observe that in this setting \textsf{bsa} has  time complexity. Then, to find all the occurrences with
at most  mismatches we use the \textsf{pmin} operation with the
word  to identify the blocks with a bit count less than or equal to
. Finally, to iterate over all the occurrences we use the
well-known bitwise operation that computes the position of the highest
bit set in a word. Observe that this operation is in  and takes
constant time~\cite{DBLP:journals/tcs/AnderssonMT99}. Hence, our
algorithm has \wrbound time complexity, and it obtains the
 bound, corresponding to no
overhead for the bitwise operations, for  or constant .
An example of the algorithm is depicted in Figure~\ref{fig:example}.

We now present the algorithm in the  model. Let  be the
smallest power of two greater than . We distinguish two cases: if
 we simply run the word-RAM solution. In
 \textsf{bsa} has  time complexity and so the
algorithm runs in  time.
Otherwise, the algorithm performs the following main steps, for each
:
\begin{enumerate}
\item 
\item 
\item 
\item \textbf{if}  and 
\item \qquad 
\item \qquad 
\item \qquad 
\end{enumerate}
where in this case  and  is a word initialized to .
The main difference in this algorithm is that we
report the occurrences every  iterations,
so as to reduce the overhead due to counting the number of mismatches when . To this end, we
compact the fields in the word 
into fields of size  in the word . If  and
, i.e., every
 processed substrings, we report the
occurrences as follows. First, observe that the word  contains
 fields of  bits,
encoding the mismatches for the substrings of  of length 
corresponding to the words , for
. More precisely, the -th
sequence of  spans the
fields

where , for
. Using a suitable algorithm, i.e, the \textsf{ibsa}
operation, we compute a word such that the last field of each sequence
has value equal to the number of bits set (mismatches) in all the
fields of the sequence if the number of mismatches is less than
 and to a value  otherwise. Then, we proceed as in the word-RAM algorithm.
We assumed for simplicity that  divides  so that
 is a \fword{\fsize}. In general, we have 
unused bits every  fields in . The
algorithm works correctly also in this case, by suitably honoring this
layout in , \textsf{ibsa} and \textsf{pmin}.
The time complexity of this algorithm is \acbound. It obtains the
 bound if .

Finally, we give a variant useful for two extreme cases:
either  or  is very small.
More precisely, it is competitive when  or .
It uses only  instructions.
In this variant, first presented for the case of small , we compute  and  using .
Each block in  and  has
thus one padding field and  associated bits. The most significant bit
of the padding field is a sentinel that will signal that there
are more than  mismatches, as
will be shown shortly.
The idea is to parallelize the well-known
sideways addition implementation in which the least significant bit
set is cleared in a
loop\footnote{\url{http://graphics.stanford.edu/~seander/bithacks.html#CountBitsSetKernighan}}.
To this end, we perform the following procedure:
\begin{enumerate}
\item 
\item 
\item \textbf{for}  \textbf{to} 
\item \qquad 
\item \qquad 
\item 
\item 
\end{enumerate}
At each iteration of the loop we add the value 
(corresponding to the sentinel bit) to each block in  and clear
the least significant bit set. In this way, after  iterations,
the sentinel bit of any block is set iff the number of mismatches
is at least . We then replace the value of each block with 
if the sentinel bit is not set and with  otherwise.
The complexity of the described operation is . The time complexity
of this algorithm is .
A twin solution handles the case of small . The idea is to
find the blocks where the number of matching symbols is at least ,
which basically consists in using the same method on the bitwise complement of the top bits of
.

\section{Applications}


\noindent
The presented technique can be used for several other string matching problems.
We show how to adapt it for particular models in the following subsections.

\subsection{Matching with -mismatches and wildcards}
Assume that the integer alphabet , of size , contains a
wildcard symbol  , i.e., a special symbol that matches any other
symbol of the alphabet. We consider the -mismatches problem with
wildcards~\cite{DBLP:conf/soda/CliffordEPR09}, which consists in reporting all the positions  such that
.
Let  and  be defined as in Sect.~\ref{sec:the_algorithm}.
The idea is to modify our algorithm so as to reset to zero all the
fields  in  such that  or
, since there can be no mismatch in a position where
either a pattern or text wildcard occurs.

In the preprocessing we create two \fword{\log\sigma}s  and .
A field  in  is equal to  if  or
, to  otherwise. A field
 in  is equal to  if ,
to  otherwise.

At each iteration  of the searching phase, we compute the word .
Analogously to , a field  in  is equal to  if
 or , to  otherwise.

Then, we \band the result of operation  of the algorithm with
 (i.e., . The rest of
the procedure is unchanged. The overall time complexity is also
unchanged.

\subsection{-matching with -mismatches and -matching}

We consider the problem of -matching~\cite{CCIMPijcm02,DBLP:conf/cpm/CliffordCI05} with -mismatches.
In this problem we want to report, given an integer , all the positions  such
that .
In the exact case, i.e., when , this is equivalent to matching under the  distance~\cite{DBLP:conf/cpm/CliffordCI05}.
In -matching any two characters  and  are defined to match iff .
Note that in the algorithm to be presented in this section we can allow  to be different for each pattern position ,
while usually in -matching the allowed error  is the same for each character.
This also yields an alternate solution to matching with wildcards in the pattern, by simply
using  for pattern positions  corresponding to wildcards, and  elsewhere.

The idea is to compute the absolute difference  for
each field  using \textsf{pvmax} and \textsf{pvmin},
i.e., we compute a \fword{\log\sigma}  such that . Then we
replace each difference with  if it is greater than
 and with  otherwise, using \textsf{pmin} and a
\bxor operation. In this way we can count the number of symbols that do not -match using \textsf{ibsa} or \textsf{bsa}.
In the preprocessing phase we compute  and construct
its packed representation , a \fword{\log\sigma} holding  copies of .
Let  be a \fword{\log\sigma} such that  is equal to
 if , to  otherwise.
Then at iteration  of the searching phase we compute
\begin{enumerate}
\item 
\item 
\end{enumerate}
The result is that each field of  is equal to  iff the corresponding
pattern and text characters do not -match.
The rest of the algorithm is as before, only the steps 1--2 of either
of the main algorithms (for  and word-RAM models) are replaced
with the two steps above. The time complexities remain the same.

If we are interested in the (more conventional) exact -matching variant
(i.e.\ assume that ), we can improve
the time to  using the following algorithm:
\begin{enumerate}
\item 
\item 
\item 
\item 
\end{enumerate}

The \textsf{fnf} operation interprets the word  as a
\fword{m\log\sigma}, and returns a \fword{m\log\sigma} where
the -th field is equal to  if at least one character of
the -th pattern copy did not -match, and to  otherwise.
The \bxor operation then inverts the fields' values, so that a field is
equal to  if all the characters of the
corresponding pattern copy did -match.

We note that a close relative to -matching is less-than matching, where characters
 and  match if .
This model has applications in other pattern matching problems, see e.g.\
\cite{DBLP:conf/focs/AmirALLL97}.
The less-than matching problem can be easily solved with our methods in the same way as
-matching, that is,
the first two lines are simply replaced with
. It is also possible to solve
-matching, with the same time complexity, by combining less-than and greater-than matching.

The -matching problem consists in, given an integer
, finding all the positions  such that . If both  and 
conditions must hold, we speak of -matching. There
are many algorithms devoted to this model, see
e.g.\ \cite{CINPSjda04}. In order to solve -matching
we need to sum the fields of each pattern copy in  and
compare each value against  (note that we need to check also
the  condition). If we do not use field compaction and
deferred reporting of occurrences, this is easiest to do in the same
way as the first widening phase of \textsf{bsa} operation, i.e.\ by
simply shifting and adding the fields in parallel in

time, giving

total time in .
This result can be improved in both  and word-RAM models.
We first define one more operation:

\medskip
\noindent \emph{interleave two words}
(\textsf{interleave}): given three \fword{f}s ,
 and , return a \fword{f}  such that  is
equal to  if , and to  otherwise. This can be
implemented in  time as follows:
\begin{enumerate}
\item 
\item 
\item 
\end{enumerate}
The idea is to first find all the pattern copies with at least one
difference greater than , by computing the
\fword{\bar{m}\log\sigma} , as in the algorithm described before for
-matching. Then, we prevent all these pattern copies from
-matching by replacing all the corresponding differences in
 with . The effect is that the sum of the fields for a
pattern copy with at least one difference greater than  is
equal to  instead of the exact sum. This works because in
-matching it always holds that , as
otherwise the  condition does not prune anything. To this end,
using  and \textsf{interleave}, we interleave the words  and
, interpreted as \fword{m\log\sigma}s, into the \fword{\log\sigma}
. In this way, a field  is equal to  if no difference
is greater than  for the corresponding pattern copy (i.e., if
), and to  otherwise.


In word-RAM we then use \textsf{bsa} and \textsf{pmin} to accumulate
the absolute differences in  and compare the sums against the
threshold value  in parallel. Note that we need to adjust
\textsf{bsa} to use as  the smallest power of two greater than or
equal to , so as to not cause overflows.
The algorithm is
\begin{enumerate}
\item 
\item 
\item 
\item 
\item 
\item 
\end{enumerate}
where  and  is a \fword{\fsize}
containing a copy of the integer  in each field.
The time complexity is
 which again obtains
 time for  or constant .

\medskip

Consider now the  model. We use an approach similar to the one
used in the -mismatches case, the only difference is that we need
more bits to represent the accumulated sums. That is, we replace
 with  (the
smallest power of two greater than ), and use . The \textsf{ibsa} operation then works correctly,
i.e.\ accumulates the absolute differences without overflowing the
sums, provided that all characters -match, as otherwise the
corresponding absolute difference may be , which in turn can
be larger than .
This holds because no difference is greater than  in .
The complete pseudocode follows.
\begin{enumerate}
\item 
\item 
\item 
\item 
\item 
\item \textbf{if}  and 
\item \qquad 
\item \qquad 
\item \qquad 
\end{enumerate}
The total time is ,
This becomes  for .

We can also combine the two models, -matching with
-mismatches and -matching, to obtain
-matching. In this model we limit the number of
characters not -matching by , and the accumulated sum of
the absolute differences by . The basic idea is to compute two
match vectors,  and , take their bitwise \band as
 and then report the occurrences
with respect to . The vector  can be computed as was
already shown. To compute  we just skip the
\textsf{interleave} operation to take the absolute differences
raw without saturating them with . In  we can use the
basic algorithm to compute  in
 time, which dominates
the total time. However, since the sums need more bits now, there is a
significant overhead in the case of the word-RAM algorithm and of the
improved  algorithm. In particular, in the case of the word-RAM
algorithm, the time complexity becomes
, i.e., slightly worse. Instead, in the
case of the improved  algorithm, the overhead makes the
algorithm useless. However, we can still manage to obtain
 time by modifying the model so that we accumulate the
absolute differences only on -matching character positions.
This can be easily done with the tools already presented, namely using
the \textsf{interleave} operation to set non--matching
character positions to 0 in word .










\section{Conclusion}
\noindent
We presented a novel technique for approximate pattern matching with
-mismatches when the text is given in packed form. Assuming the
pattern is short enough, it is possible to achieve a sublinear search
time, if several pattern copies are matched against different text
substrings at the same time. We described variants of our simple
method in the  and word-RAM models and also considered the case
when the number  of allowed errors is small. Moreover, we showed
how to adapt our algorithms to other matching models, including
approximate matching with wildcard (don't-care) symbols,
-matching with -mismatches and -matching.

\section{Acknowledgments}

We thank two anonymous reviewers and Djamal Belazzougui for helpful comments.

\bibliographystyle{abbrv}
\bibliography{hamming}

\end{document}
