







\documentclass[10pt, conference, compsocconf]{IEEEtran}




\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{mathrsfs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{color}
\usepackage{balance}
\usepackage{enumerate}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[english, greek]{babel}


\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}
\newtheorem{definition}{Definition}
\newtheorem{observation}{Observation}
\newtheorem{example}{Example}















































































\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document} 
\IEEEoverridecommandlockouts
\selectlanguage{english}

\title{Energy-Efficient Flow Scheduling and Routing with Hard Deadlines in Data Center Networks
}









\author{
\IEEEauthorblockN{
Lin Wang\IEEEauthorrefmark{1}\IEEEauthorrefmark{2}\IEEEauthorrefmark{6},
Fa Zhang\IEEEauthorrefmark{1}\IEEEauthorrefmark{2},
Kai Zheng\IEEEauthorrefmark{3},
Athanasios V. Vasilakos\IEEEauthorrefmark{4},
Shaolei Ren\IEEEauthorrefmark{5},
Zhiyong Liu\IEEEauthorrefmark{2}\IEEEauthorrefmark{7}
}
\IEEEauthorblockA{
\IEEEauthorrefmark{1}Key Laboratory of Intelligent Information Processing, Chinese Academy of Sciences} 
\IEEEauthorblockA{
\IEEEauthorrefmark{2}Institute of Computing Technology, Chinese Academy of Sciences, China} 
\IEEEauthorblockA{
\IEEEauthorrefmark{3}IBM China Research Lab, China} 
\IEEEauthorblockA{
\IEEEauthorrefmark{4}University of Western Macedonia, Greece} 
\IEEEauthorblockA{
\IEEEauthorrefmark{5}Florida International University, USA} 
\IEEEauthorblockA{
\IEEEauthorrefmark{6}University of Chinese Academy of Sciences, China}
\IEEEauthorblockA{
\IEEEauthorrefmark{7}State Key Laboratory for Computer Architecture, ICT, CAS, China}
}

\iffalse
\author{
\IEEEauthorblockN{
Lin Wang, Fa Zhang, Kai Zheng, Athanasios V. Vasilakos, Shaolei Ren, and Zhiyong Liu
}
\normalsize
Key Laboratory of Intelligent Information Processing, Chinese Academy of Sciences\\
Institute of Computing Technology, Chinese Academy of Sciences \\
IBM China Research Lab~~~~University of Western Macedonia, Greece\\
Florida International University, USA~~~~University of Chinese Academy of Sciences\\
State Key Laboratory for Computer Architecture, Institute of Computing Technology, CAS
}
\fi







\maketitle


\begin{abstract}
The power consumption of enormous network devices in data centers has emerged as a big concern to data center operators. Despite many traffic-engineering-based solutions, very little attention has been paid on performance-guaranteed energy saving schemes. In this paper, we propose a novel energy-saving model for data center networks by scheduling and routing ``deadline-constrained flows'' where the transmission of every flow has to be accomplished before a rigorous deadline, being the most critical requirement in production data center networks. Based on speed scaling and power-down energy saving strategies for network devices, we aim to explore the most energy efficient way of scheduling and routing flows on the network, as well as determining the transmission speed for every flow. We consider two general versions of the problem. For the version of only flow scheduling where routes of flows are pre-given, we show that it can be solved polynomially and we develop an optimal combinatorial algorithm for it. For the version of joint flow scheduling and routing, we prove that it is strongly NP-hard and cannot have a Fully Polynomial-Time Approximation Scheme (FPTAS) unless P=NP. Based on a relaxation and randomized rounding technique, we provide an efficient approximation algorithm which can guarantee a provable performance ratio with respect to a polynomial of the total number of flows. 

\end{abstract}























\section{Introduction}
\label{sec:intro}

Cloud computing has become a fundamental service model for the industry. In order to provide sufficient computing resources in clouds, large-scale data centers have been extensively deployed by many companies such as Google, Amazon and Microsoft. While providing powerful computing ability, those data centers are bringing a significant level of energy waste due to the inefficient use of hardware resources, resulting in both high expenditure and environmental concern.

Obviously, the servers should be the first target for energy reduction as they are the most energy-consuming component in a data center.   
By involving techniques such as Dynamic Voltage Frequency Scaling (DVFS) or hardware virtualization, the energy efficiency of servers has been improved to a large extent. As a result, the network device, as the second-place energy consumer, has taken a large portion in the total energy expenditure of a data center, bringing about urgent economic concerns over data center operators.



The problem of improving the network energy efficiency in data centers has been extensively explored (e.g., \cite{Heller_Seetharaman, Shang_Li, Wang_Yao,  Vasic_Bhurat-2011, Wang_Zhang-JSAC-2013}). Despite some energy-efficient network topologies for data centers, most of the solutions are concentrated on traffic engineering which aims to consolidate network flows and turn off unused network devices. The essential principle underlying this approach is that data center networks are usually designed with a high level of connectivity redundancy to handle traffic peak and that the traffic load in a data center network varies significantly over time. Due to the fact that the idle power consumed by the chassis usually takes more than half of a switch's total power consumption \cite{Mahadevan_Sharma}, turning off the switch during idle period should give the most power reduction in theory.

However, the practicality of these aforementioned solutions are quite limited because of the following two aspects:  Most of the traffic-engineering-based approaches are ineluctably dependent on traffic prediction which seems not feasible or not precise enough \cite{Benson_Anand}. This is because the traffic pattern in a data center network largely depends on the applications running in the data center. Without precise traffic prediction, the network configuration generated by the energy-saving unit has to be updated frequently. Consequently, the network will be suffering from oscillation;  Saving energy leads to performance degradation. Most of the solutions only focus on energy efficiency without considering the network performance (e.g. throughput, delay). This will dramatically bring down the reliability of the network, which is not acceptable in practice as providing high performance is the primary goal in a network.



In order to overcome the above two limitations, we propose to view the network traffic from the application-level aspect instead of making use of the static network status (loads on links) that is rapidly monitored from the network or predicted (e.g. \cite{Heller_Seetharaman}). We observe that while the aggregate traffic load varies over time, the most critical factor that conditions the performance of many data exchanges in data centers is meeting flow deadlines  (\cite{Wilson_Ballani, Vamanan_Hasan, Hong_Caesar, Zats_Das, Alizadeh_Yang}). This is due to the fact that representative data center applications such as search and social networking usually generate a large number of small requests and responses across the data center that are combined together to perform a user-requested computation. As user-percieved performance is evaluated by the speed at which the responses to all the requests are collected and delivered to users, short or guaranteed latency for each of the short request/response flow is strongly required. Given a threshold for tolerable response latency, the system efficiency will be definitely conditioned by the number of flows whose deadlines are met (that are completed within the time threshold).


Inspired by this observation, we consider to represent the networking requirements of applications as a set of deadline-constrained flows\footnote{If not specified, ``flow'' in this paper refers to a certain amount of data that has to be transmitted from a source to a destination on the network.} and we aim to design particular energy-efficient scheduling and routing schemes for them. Although the job scheduling on single or parallel processors with deadline constrains has been extensively studied, little attention has been paid on the job scheduling problem on a multi-hop network \cite{Mao_Koksal}, especially with the objective of optimizing the energy consumption. To the best of our knowledge, this is the first solution that theoretically explores energy-efficient schemes by scheduling and routing deadline-constrained flows in data center networks.


To summarize our main contributions in this paper:

\iffalse
\begin{itemize}
\item We describe the deadline-constrained network energy saving problem in a comprehensive way and provide models for two general versions of this problem -- Deadline-Constrained Flow Scheduling (DCFS) and Deadline-Constrained Flow Scheduling and Routing (DCFSR);
\item We show that DCFS can be optimally solved in polynomial time and we propose an optimal combinatorial algorithm for it;
\item We show by in-depth analysis that solving DCFSR is strongly NP-hard and cannot have a Polynomial-Time Approximation Scheme (PTAS); and
\item We provide an efficient approximation algorithm which solves the problem with a provable performance ratio.
\end{itemize}
\fi
 We describe the deadline-constrained network energy saving problem and provide comprehensive models for two general versions of this problem -- Deadline-Constrained Flow Scheduling (DCFS) and Deadline-Constrained Flow Scheduling and Routing (DCFSR);  We show that DCFS can be optimally solved in polynomial time and we propose an optimal combinatorial algorithm for it;  We show by in-depth analysis that solving DCFSR is strongly NP-hard and cannot have a fully Polynomial-Time Approximation Scheme (FPTAS) unless P=NP;  We provide an efficient approximation algorithm which solves the problem with a provable performance ratio.

The remainder of this paper is organized as follows. Section~\ref{sec:model} presents the modeling for the deadline-constrained network energy saving problem where two versions of the problem are introduced. Section~\ref{sec:dts} discusses the DCFS problem where an optimal combinatorial algorithm is provided to solve it. Section~\ref{sec:dtsr} discusses the DCFSR problem and presents some complexity and hardness analysis. Section~\ref{sec:approx} presents an approximation algorithm with guaranteed performance ratio for DCFSR where some numerical results are also provided. Section~\ref{sec:related} summarizes related work and section~\ref{sec:conc} concludes the paper.


\section{The Model}
\label{sec:model}

Based on some preliminary definition, we provide the general modeling for the deadline-constrained network energy saving problem in this section. 

\subsection{The Data Center}

We model a data center as a distributed computing system where a set of servers is connected with a network  where  is the set of nodes (switches and hosts) and  is the set of network links. We assume all the switches, as well as all the links, in  are identical which is reasonable because advanced data center networks such as fat-tree \cite{Al-Fares_Loukissas-FatTree-2008} or BCube \cite{Guo_Lu-BCube-2009} are usually conducted on identical commodity switches. We use the classical queueing model for links, that is, a link is modeled as a forwarding unit with buffers at its two ends. When the switch finishes processing a data packet, the egress port for this packet will be determined and this packet will be injected into the buffer of the egress link. The packets that queue in the buffer will be transmitted in order according to some preset packet scheduling policy.

We consider the power consumption of network components such as ports and links which are the main power consumers that can be manipulated for energy conservation.\footnote{The biggest power consumer in a switch, the chassis, cannot achieve power proportionality easily due to drastic performance degradation. Nevertheless, our approach is a complement and can be incorporated with switch-level power-down based solutions.} With a slight abuse of notation, the power consumption of the ports at the ends of a link is also abstracted into the power consumption of the link for the ease of exposition. For the power consumption model, we adopt the power function from \cite{Andrews_Fernandez-SS-2010} which is an integration of the power-down and the speed scaling model that has been widely used in the literature. For each link , a power consumption function  is given to characterize the manner in which energy is being consumed with respect to the transmission rate  of link . We assume uniform power functions as the network is composed of identical switches and links. Formally, for every link we are given a function  which is expressed by

where  and  are constants associated with the link type. Constant  is known as the idle power for maintaining link states, while  is the maximum transmission rate of a link.
Normally, the power function  is superadditive, i.e., . In order to get rid of the network stability problem introduced by frequently togging on and off links, we assume that a link can be turned off only when it carries no traffic during the whole given period of time. Making this assumption also helps reduce the considerable power incurred by changing the state of a link, as well as the wear-and-tear cost.

\subsection{Applications}

We model an application as a set of deadline-constrained flows each of which consists of a certain amount of data that has to be routed from a source to a destination on the network within a given period of time. In order to avoid packet reordering at the destination end, we assume that each flow can only follow a single path. Nevertheless, multi-path routing protocols can be incorporated in our model by splitting a big flow into many small flows with the same release time and deadline at the source end and each of the small flows will follow a single path.


Let  be a fixed time interval, during which a set  of flows has to be routed on the network. Associated with each flow  are the following parameters:
\begin{itemize}
\item  amount of data that needs to be routed,
\item ,  its release time and deadline respectively, and
\item ,  its source and destination respectively.
\end{itemize}

Without loss of generality, we assume  and . In our setting, we allow preemption, i.e., each flow can be suspended at any time and recovered later. We define  as the \emph{span} of flow  and we say that  is active at time  if . The \emph{density} of flow  is defined as . A schedule is a set 

where  is the transmission rate chosen for flow  at time  and  is the set of links that are on the chosen path for carrying the traffic from this flow. A schedule is called feasible if every flow can be accomplished within its deadline following this schedule, i.e.,  satisfies

We define  as the set of active links where

Consequently, the total energy consumed by all the links during  in a schedule  can be expressed by

where  is the transmission rate of link  at time  and  if flow  is being transmitted on link  at time . Our objective is to find a feasible schedule that minimizes . Depending on whether the routing protocol is given or not, we have two versions of this problem which we call DCFS (Deadline-Constrained Flow Scheduling) and DCFSR (Deadline-Constrained Flow Scheduling and Routing). We will discuss them separately in the following sections. 

\section{Deadline-Constrained Flow Scheduling}
\label{sec:dts}

In this section, we discuss the DCFS problem. Specifically, we model this problem as a convex program and show that it can be optimally solved. We then provide an optimal combinatorial algorithm for it.

\subsection{Preliminaries}

In DCFS, the routing paths for all the flows are provided. Routing the flows with these paths, each link will be assigned with a set of flows .
We omit those inactive links that satisfy  since they will never be used for transmitting data. Thus the set of active links is . As all the links in  will be used, we simplify the problem by replacing the power consumption function with . Consequently, the objective of the problem becomes to find a feasible schedule  such that

is minimized. For the sake of tractability, we first consider the case where the routing path for each flow is a virtual circuit. That is, when a flow is being routed, all the links on the routing path of this flow will be totally occupied by the packets from this flow. Nevertheless, we will show that this assumption is generally true in the optimal solution and it can be realized by assigning priorities to the packets from each flow in a packet-switching network. 

We define the \emph{minimum-energy schedule} as the schedule that minimizes the total power consumption but may not satisfy the maximum transmission rate constraint on each link. Then, we introduce the following lemmas.
\begin{lemma}
\label{lm:unique}
The minimum-energy schedule will use a single transmission rate for every flow.
\end{lemma}

\begin{proof}
We prove it by contradiction. Suppose we are given an instance of DCFS and a minimum-energy schedule  for this instance where we have two different transmission rates for only one of the flows. For the ease of exposition, we assume that the time interval\footnote{It can also be extended to the case where we have more than one interval for routing this flow as we only focus on this flow.} that this flow is being routed on the network is  in  and there is a time point  () such that the transmission rate is  in interval  and  in interval , respectively. Now, instead of using  and  in the two different intervals, we propose another schedule  where we use a single rate  through the whole interval . Due to the convex property of , it is easy to verify that

The above inequality is equivalent to , which contradicts the assumption that  is optimal. This completes the proof.
\end{proof}

\begin{lemma}
\label{lm:minimum}
The minimum-energy schedule will choose an as small as possible transmission rate for each flow such that the deadlines of flows can be guaranteed.
\end{lemma}
\begin{proof}
We focus on one flow with an amount  of data that has to be routed in time interval . The routing path for this flow is denoted by  and the number of links in  is given by . Using Lemma~\ref{lm:unique}, we assume a single transmission rate  is given to process this flow. The total energy consumed by the links for routing this flow can be expressed by . As long as ,  is minimized when we have the minimum transmission rate  for this flow such that the deadlines of all the flows can be satisfied. In this sense, the minimum-energy schedule will use the minimized transmission rate for each flow.
\end{proof}

Following the above lemma, we observe that as long as there are feasible schedules, the minimum-energy schedule is feasible. In other words, the minimum-energy schedule is also the optimal schedule for DCFS. Equivalently, the maximum transmission rate constraint  can be relaxed in DCFS. In the remainder of this section, we will omit that constraint.

\subsection{Problem Formulation}
We denote the transmission rate for flow  as  according to Lemma~\ref{lm:unique}.
The DCFS problem can be formulated as the following convex program.

The total transmission time and the total energy consumption of flow  are  and , respectively. The first constraint forces that for an arbitrary link , all the flows in any subset of  has to be processed before the last deadline of the flows in that subset. The second constraint represents that the transmission rate for each flows has to be larger than 0. It is easy to verify that program () is convex because the objective function is convex (as we assume ) while all the constraints are linear. As a result, the DCFS problem can be solved optimally in polynomial time by applying the Ellipsoid Algorithm \cite{Nesterov-Ellipsoid-1994}. However, as the Ellipsoid Algorithm is not practically used due to its high complexity in typical instances, we aim to construct an efficient combinatorial algorithm by exploring the characteristics of the minimum-energy schedule.

\subsection{An Optimal Combinatorial Algorithm}

We now provide a combinatorial algorithm which can always find the optimal schedule for DCFS. Before presenting the algorithm, we first give a characterization of the optimal schedule through the following example.
\begin{example}
Consider a line network whose topology is given in Fig.~\ref{fig:example_1}. The power consumption of the links is characterized by function . On this network we have two flows  and  that need to be routed. The details of the two flows are given by the following multi-tuples

\end{example}
\begin{figure}[t!]
\centering
\includegraphics[scale=0.5]{./example.pdf}
\caption{\label{fig:example_1} A line network consisting of three nodes connected by two links. }
\end{figure}
According to Lemma~\ref{lm:unique}, we denote the transmission rates for  and  as  and , respectively. Consequently, we have the following three constraints ,  and , while the objective function is . It is easy to check that in the optimal schedule, . We then construct an instance of the speed scaling problem on single processor (SS-SP) raised by Yao \emph{et al.} \cite{Yao_Demers_Shenker-YDS-1995}. Consider we have two jobs with required numbers of CPU cycles of  and  respectively, while the release times and deadlines are exactly the same as the two flows. Using the \textbf{Optimal-Schedule} algorithm (known as the \textbf{YDS} algorithm according to the authors' initials), the two jobs will be processed at the same speed of  in time interval . As a result, the objective value in the optimal schedule for this instance is exactly the same as the minimum  in our problem while the structure of the solution is also the same. Using this observation, we provide an optimal algorithm for solving the DCFS problem based on the \textbf{YDS} algorithm. 

We first construct from the DCFS problem a variant of the SS-SP problem by introducing a virtual weight  for each flow . First of all, we present some definitions which are extended from \cite{Yao_Demers_Shenker-YDS-1995}.
\begin{definition}
The intensity of an interval  on a link  is defined by

where  denotes the available time in interval .
\end{definition}
Intuitively, the following inequality has to be satisfied,

which means that  is a lower bound on the average transmission rate of link  in any feasible schedule over the interval .
\begin{definition}
If an interval  maximizes  for any , we call  a critical interval and  is the corresponding critical link.
\end{definition}
Now we present the main algorithm that generates optimal schedules greedily by computing critical intervals iteratively. The pseudo-code of the algorithm \textbf{Most-Critical-First} is shown in Algorithm~\ref{alg:greedy}.
\begin{algorithm}[!t]
\caption{\label{alg:greedy} \textbf{Most-Critical-First}}
\textbf{Input:} data center network , set of flows  for  and virtual weights  for each flow\\
\textbf{Output:} transmission rate  and transmission time interval  for each flow 

\begin{algorithmic}[1]
\WHILE{}
	\STATE Find the critical interval  and the critical link . The flows in this interval can be represented by  and without loss of generality, 
	
	\STATE Schedule the flows in  with the Earliest Deadline First (EDF) policy using transmission rate 
	
	for each flow . The transmission time interval  is also determined.
	\FOR{}
		\STATE  for .
		\STATE For , mark the time interval  as unavailable on link .
	\ENDFOR
\ENDWHILE
\end{algorithmic}
\end{algorithm}

The following theorem proves that a critical interval will determine a segment of the optimal schedule.
\begin{theorem}
\label{thm:interval-opt}
Let  be a critical interval and  be the corresponding critical link, algorithm \textbf{Most-Critical-First} can guarantee that the energy consumed by routing the flows in  is optimal.
\end{theorem}
\begin{proof}
Denoting the transmission rate for each flow  as , the total energy consumed by routing the flows in  is expressed by

According to the second constraint in program  we have

It is clear that in the optimal schedule, the above inequality is exactly an equality because of Lemma~\ref{lm:minimum}. Then,  can be minimized by using the method of Lagrange multipliers. By introducing a Lagrange multiple , we construct a function

By setting , we have

This is equivalent to solving an instance of the SS-SP problem as we explained in Example~\ref{fig:example_1}, where we treat each flow as a job with weight . Using Theorem~ provided in \cite{Yao_Demers_Shenker-YDS-1995}, we set the processing speed of all the jobs to the same value of , which will give the optimal energy consumption for the SS-SP problem, as well as our problem. That is,  is minimized by setting

which is reflected in the algorithm.
\end{proof}
Actually, algorithm \textbf{Most-Critical-First} solves a variant of the SS-SP problem based on the YDS algorithm. Consequently, the following result follows quickly from Theorem~\ref{thm:interval-opt}.
\begin{corollary}
The schedule produced by algorithm \textbf{Most-Critical-First} is optimal to the DCFS problem.
\end{corollary}

The time complexity of algorithm \textbf{Most-Critical-First} is bounded by . Note that the optimality of this algorithm is maintained based on the assumption that data in flows is routed exclusively through virtual circuits. We now show how to extend it to a packet-switching network: we assign a unique priority for all the packets from each flow according to the flow's starting time . That is, a flow  with a smaller  will have a higher priority. This priority information can be encapsulated into the header of each packet and links will schedule those packets according to their priorities. 

\section{Deadline-Constrained Flow Scheduling and Routing}
\label{sec:dtsr}

In this section, we discuss the DCFSR problem. We aim at exploring the most energy-efficient scheduling and routing scheme for a given collection of flows. This problem is much harder than DCFS as we have to decide also the routing path for each flow, as well as the transmission rate. 

\subsection{Problem Formulation}

We observe that once we have the routing paths for all flows determined, finding the transmission rate for each flow is then the DCFS problem which can be optimally solved by algorithm \textbf{Most-Critical-First}. Let  denote the routing path for flow . Keeping the notation we used before, the DCFSR problem can be formalized by the following program.

The first constraint represents that each flow has to be finished before its deadline. The second constraint means that the transmission rate of the flow that is being processed on a link  cannot exceed the operation rate of that link, while the third one represents that the operation rate of a link has to be larger than zero and no larger than the maximum operation rate . The flow conservation in the last constraint forces that  is a path connecting source  and destination  of flow .


\subsection{Complexity and Hardness Results}

First, we provide the following definition and lemma as preliminaries based on our power consumption model. 
\begin{definition}
The \textbf{power rate} of a link  () is defined as the power consumed by each unit of traffic, i.e., .
\end{definition}
It can be observed that as long as the power rate of every link is minimized, the total power consumption of the network will be optimal. To minimize the power rate of a link, we show the following lemma.
\begin{lemma}
\label{lm:opt_rate}
Ideally, the optimal operation rate  for a link is given by .
\end{lemma}
Note that this operation rate is optimal in theory but is not always achievable in practice, as it can happen that . In general, we can prove that the decision version of DCFSR is NP-complete by providing the following theorem.
\begin{theorem}
Given a certain amount of energy , finding a schedule  for DCFSR such that  is NP-complete.
\end{theorem}


\begin{proof}
This can be proved by a simple reduction from the -partition problem which is NP-complete \cite{Garey_Johnson-1990}. Suppose we are given an instance of the -partition problem with a set  of  integers  where  and . The problem is to decide whether  can be partitioned into  disjoint subsets, i.e.,  and  for any , such that every subset  consists of  integers and . Based on this -partition instance, we construct an instance of DCFSR as follows: we are given a network where two nodes (denoted as \emph{src} and \emph{dst}) are connected in parallel by  () links. Assume we are given a set  of  flows each of which has an amount  () of data needed to be transmitted from \emph{src} to \emph{dst} on the network. All the flows arrive at the same time and the data transmission has to be finished in one unit of time. We assume  and , i.e.,  and we set . We will show that there is a schedule  such that  if and only if  can be partitioned in the way as in the optimal solution of the -partition instance.

On the one hand, if there exists a partition for the -partition instance, we have a solution  for the DCFSR instance where the flows are transmitted by  links each with an operation rate  according to the partition and the energy consumption in this solution is . According to Lemma~\ref{lm:opt_rate}, this solution is optimal since the power rate for each link in this solution is optimal. Hence, it satisfies that . On the other hand, if we obtain a solution  for the DCFSR instance such that . It can then be derived that exactly  links will be used and each link will use an operation rate . Otherwise, the total energy consumption  will be larger than  as the average power rate of the used links is larger than , so . Accordingly, we can construct a partition for the -partition instance. In a nutshell, finding a partition for -partition is equivalent to finding a solution  for DCFSR such that . 

The above reduction is based on the assumption that , which is not necessarily true in reality. However, in the case , we just set  and , and the same reduction can be built in a similar way.
\end{proof}
Then, it follows directly that
\begin{corollary}
Solving the DCFSR problem is strongly NP-hard.
\end{corollary}
As a result, the DCFSR problem can only be solved by approximating the optimum. When we say that an algorithm approximates DCFSR with performance ratio , it means that the energy consumption in the solution produced by this algorithm is at most  times the minimum energy consumption. Given these, we aim at designing an algorithm to approximate the optimum with ratio  as small as possible. Unfortunately, for the case , which is likely to be the real situation as justified in \cite{Wang_Zhang-JSAC-2013}, the following theorem shows that  cannot be as small as we want since there is a lower bound for it.

\begin{theorem}
There exists an instance of problem DCFSR such that no approximation algorithm can guarantee a performance ratio smaller than  unless P=NP.
\end{theorem}

\begin{proof}
We prove this theorem by showing a gap-preserving reduction from the partition problem which is NP-complete. Suppose we are given an instance of the partition problem with a set  of  integers. Assuming , the problem is whether it is possible to find a subset  such that .  We now construct an instance of the DCFSR problem as follows:  we consider also the same network as the one in the previous proof where we assume  and the capacity of each link is given by . We are also given a set  of flows each of which requires to route an amount  of data from \emph{src} to \emph{dst} and  for . These flows arrive at the system at the same moment and have to be accomplished in one unit time. We denote by  the optimal solution of the DCFSR instance, which represents the total energy consumed by the active links for tranmisstting the flows. Then, the following properties are preserved.
	
	Comparing both optimal solutions, we obtain a ratio  where
	
where the inequality is obtained by applying .
Combining with the two properties we derived, it is easy to conclude that as long as there is an approximation algorithm solving DCFSR with a performance ratio better than , a subset  in the partition problem can be found such that . However, it is well known that the partition problem is NP-complete and cannot be solved by any polynomial time algorithm optimally. As a result, no algorithm can approximate DCFSR with a performance ratio better than  unless P=NP.
\end{proof}
This directly implies that the DCFSR cannot have Fully Polynomial-Time Approximation Schemes (FPTAS) under the conventional assumption that PNP \cite{Vazirani-2004}. In the next section, we will provide an efficient approximation algorithm.

\section{An Approximation Algorithm for DCFSR}
\label{sec:approx}

We present an approximation algorithm for DCFSR in this section. This algorithm is based on a relaxation and randomized rounding based process. We show by both analysis and numerical results that this approximation algorithm can guarantee a provable performance ratio.

\subsection{The Algorithm}

We first provide the following preliminaries. We define  to be the set of release times and deadlines of all the flows such that  for any . It is clear that  and . We denote by  the time interval  for , by  the length of interval  and by  the fraction of time that interval  takes from the whole time of interest. We also define .

We first relax the problem by making the following transformations such that the resulted problem can be optimally solved.
\begin{itemize}
\item The traffic load of flow  is given by its density . Flows can be routed simultaneously on any link;
\item Each flow can be routed through multiple paths;
\item The links in the network can be flexibly turned on and off at any moment.
\end{itemize}
We observe that the resulted problem can be decomposed into a set of subproblems in each interval  as in each interval , the traffic flows on the network are invariable. Actually, each such subproblem in an interval is a fractional multi-commodity flow (F-MCF) problem that is precisely defined as follows.
\begin{definition}[F-MCF]
For every active flow  that satisfies , a flow of traffic load  has to be routed from  to . The objective is to route these flows on the network such that the total cost on the links is minimized, given cost function  for every link.
\end{definition}

It is known that the F-MCF problem can be optimally solved by convex programming. Consequently, we obtain the fractional solution  which represents the proportion of the amount of the flow  that goes through link  in interval . Absolutely, this solution is not feasible to the original DCFSR problem. Now we aim to transform this infeasible solution into a feasible one.

The transformation is accomplished by a randomized rounding process. Before that, we extract candidate routing paths for each flow following the Raghavan-Tompson \cite{Raghavan_Tompson} manner as follows. For each interval  (), we decompose the fractional solution  into weighted flow paths for each flow  via the following procedure. We repeatedly extract paths connecting the source and destination of each flow  from the subgraph defined by links  for which . For each extracted path , we assign a weight  for  and the value of  on every link in  is reduced by . This path extracting process will terminate when every  becomes zero, which is guaranteed by the flow conservation constraint. As a result, we obtain a set  of paths for flow  in interval . We repeat this process for every interval and denote  as the set of all the candidate paths for flow  without duplication. Note that a path  may be used in more than one interval. We denote by  the corresponding weights of  in different intervals. If  is not used in interval , then .

Now we show how to choose a single path for each flow  from the candidate paths . For each path , we assign a new weight  where . The routing path  for flow  is then determined by randomly choosing a path  from  using weight  as the probability at which path  will be chosen. This path choosing process will be repeated for every flow. Consequently, a single path  will be determined for each flow  and the packets from this flow will be routed through only this path.

Finally, we choose a transmission rate for each flow in every interval . Denoting also  the flow that will be transmitted on link  in interval , the transmission rate for every flow  will be set to  and data packets from each flow in  will be forwarded on  using the EDF policy which we have introduced before.

\begin{algorithm}[!t]
\caption{\label{alg:approx} \textbf{Random-Schedule}}
\textbf{Input:} data center network , set of flows \\
\textbf{Output:} Routing path  for flows  and transmission rate  for 

\begin{algorithmic}[1]
\STATE Transform the DCFSR problem into a multi-step fractional multi-commodity flow problem by relaxing the constraints
\FOR{}
	\STATE Solve the fractional multi-commodity flow problems by convex programming, obtaining 
	\STATE Extract candidate paths for each flow, denote as  and a weight  for each 
\ENDFOR
\STATE  for 
\STATE  for  
\FOR{}
\STATE Randomly choose a path  from  using weight  as the probability
\ENDFOR
\STATE Route the packets from all the flows on link  in interval  using the EDF policy. The transmission rate for flow  on link  in interval  is .
\end{algorithmic}
\end{algorithm}

The whole process of the algorithm is shown in Algorithm~\ref{alg:approx}. We have to mention that the proposed algorithm does not guarantee the maximum operation rate constraint. However, we observe that the probability that many flows are simultaneously requested to be forwarded on a designated link in the proposed algorithm is very low as the probability for choosing a link for a flow is derived from the fractional solution which has the maximum operation rate constraint considered. Nevertheless, we can always repeat the randomized rounding process until we obtain a feasible solution. Now we show that 
\begin{theorem}
The deadline of every flow  can be met in the solution produced by algorithm \textbf{Random-Schedule}. 
\end{theorem}
\begin{proof}
As we allow preemption for each flow, it suffices to show that all the data that arrives on a link  in every interval  can be transmitted by the end of this interval. Let us focus on one arbitrary link  and an arbitrary interval . The total amount of data that has to be transmitted through  in this interval is given by . As the transmission rate for every flow in  is , the total time that is needed for accomplishing all the flows is equal to . As a result, all the data in this interval can always be transmitted no matter what kind of scheduling policy is used. However, we use the EDF policy because it can significantly reduce the frequency of changing the transmission rates of links.
\end{proof}

\subsection{Performance Analysis}

We now analyze the approximation performance of the proposed algorithm. Our results are based on the main results in \cite{Andrews_Fernandez-SS-2010} where the authors also used a rounding process to approximate the multi-commodity flow problem with . The biggest difference compared with that work is that the rounding process we propose in this paper is responsible for minimizing the number of used links and thus has to guarantee the same path for each flow in every interval. That is, we aim at solving a multi-step MCF problem. We base our proof on the following result and we only show the difference from it.

\begin{theorem}[\cite{Andrews_Fernandez-SS-2010}]
\label{thm:mcf}
For nonuniform demands, randomized rounding can be used to achieve a  for MCF with cost function , where  is the total number of demands and  is the maximum demand among all the demands.
\end{theorem}

\begin{theorem}
 Algorithm~\textbf{Random-Schedule} can achieve a -approximation for the DCFSR problem with power function , where .
\end{theorem}

\begin{proof}
We follow the process of the proof for Theorem~\ref{thm:mcf}. First, we assume unit flows, i.e.,  and we use power consumption function . Note here that we have  for any . We then consider the following two cases:\\
Case : , we have,

where the first inequality follows from the result in \cite{Andrews_Fernandez-SS-2010}.\\
Case : , we have,

where the first inequality follows also from the result in \cite{Andrews_Fernandez-SS-2010}. The second inequality and the last inequality follow from the property that  while in the last inequality, we also apply . The third inequality follows due to  for . 

It can be observed that when the power consumption function is given by ,  is a lower bound for the optimal energy consumption as it is the total energy consumed when the smallest transmission rate for each flow is used and also each flow can be routed through multiple paths. Consequently, we have

where the expression on the left side is the expectation of the energy consumption in the solution produced by Algorithm~\textbf{Random-Schedule}. Using Markov's inequality, the probability that the energy consumption is more than  is no more than . This result then can be extended to nonuniform flows by introducing an extra factor , which has also been shown in \cite{Andrews_Fernandez-SS-2010}.
\end{proof}

\begin{theorem}
Algorithm~\textbf{Random-Schedule} can solve the DCFSR problem with the power function given in Eq.~\ref{eqn:power_func} while guaranteeing an approximation ratio  of .
\end{theorem}
\begin{proof}
We also assume power consumption function  for the DCFSR problem and solve it with the proposed algorithm \textbf{Random-Schedule}. In the obtained fractional solution for the multi-step F-MCF problem, we use  to indicate whether a link  is chosen or not in interval . We denote by  an indicator in the produced solution where  if  is used in at least one of the intervals;  otherwise. Then, we have

where the third inequality follows from  and the last inequality follows from  for any . It can be observed that  is a lower bound for the optimal idle energy consumption by link  since  is derived from the M-MCF problem which allows the links to be turned on and off freely at any moment. Combining all these together, we conclude that algorithm \textbf{Random-Schedule} can produce a -approximation for the DCFSR problem.
\end{proof}


\subsection{Numerical Results}

We now briefly describe simulation results that illustrate the approximation performance of the proposed algorithm. We build a simulator with the \textbf{Random-Schedule} implemented in Python. We use the power consumption functions  or  and we choose a data center network topology which consists of  switches (with  servers connected). We consider [1, 100] as the time period of interest and as we assume no prior knowledge on the flows, we select release times and deadlines of flows randomly following a uniform distribution in [1,100].
The number of flows ranges from  to  and the amount of data from each flow is given by a random rational number following normal distribution . We compare three values of interest: lower bound (LB) for the optimum (solution given by ), \textbf{Shortest-Path} (SP) routing plus \textbf{Most-Critical-First} (MCF), and \textbf{Random-Schedule} (RS). As SP is usually adopted, SP+MCF can give the lower bound of the energy consumption by SP routing, which represents the normal energy consumption in data centers. All of the values are normalized by the lower bound for the optimum and are averaged among  independent runs. The simulation results are illustrated in Fig.~\ref{fig:sim}. As expected, RS outperforms SP+MCF to a large extent. Moreover, we notice that with the increase of the number of flows, the approximation ratio of RS converges while the approximation ratio of SP+MCF keeps an increasing trend. This confirms that combining routing and scheduling for flows can provide substantial improvements on the energy efficiency in data center networks.

This simulation serves merely as a primitive validation of the performance of the algorithm. Due to the space limit, we leave more exhaustive evaluation and further implementation as future work.

\begin{figure}[!t]
	\centering
	\subfigure{
 	\label{fig:sim-1} 
	\includegraphics[scale=0.67]{sim1.pdf}}
	\hspace{0in}
	\subfigure{
	\label{fig:sim-2} 
	\includegraphics[scale=0.67]{sim2.pdf}}
	\caption{The approximation performance of \textbf{Random-Schedule}.}
	\label{fig:sim} 
	\vspace{-0.45cm}
\end{figure}

\section{Related Work}
\label{sec:related}

This section summarizes some related work on the problem of improving the energy efficiency of DCNs, as well as the network scheduling and routing problem.

\subsection{Energy-Efficient Data Center Networks}

There has been a large body of work on improving the energy efficiency in DCNs. In general, they can be classified into two categories: The first line of work is designing new topologies that use fewer network devices while aiming to guarantee similar connectivity thus performance, such as the flatted butterfly proposed by Abts \emph{et al.} \cite{Abts_Marty-2010} or PCube \cite{Huang_Jia-2011}, a server-centric network topology for data centers, which can vary the bandwidth availability according to traffic demands. The second line of work is optimizing the energy efficiency by traffic engineering, i.e., consolidating flows and switching off unnecessary network devices. The most representative work in this category is ElasticTree \cite{Heller_Seetharaman}, which is a network-wide power manager that can dynamically adjust a set of active network elements to satisfy variable data center traffic loads. Shang \emph{et al.} \cite{Shang_Li} considered saving energy from a routing perspective, routing flows with as few network devices as possible. Mahadevan \emph{et al.} \cite{Mahadevan_banerjee-2011} discussed how to reduce the network operational power in large-scale systems and data centers. The first rate-adaptation based solution to achieve energy efficiency for future data center networks was provided by \cite{Wang_Zhang-2013}. Vasic \emph{et al.} \cite{Vasic_Bhurat-2011} developed a new energy saving scheme that is based on identifying and using energy-critical paths. Recently, Wang \emph{et al.} \cite{Wang_Yao} proposed CARPO, a correlation-aware power optimization algorithm that dynamically consolidates traffic flows onto a small set of links and switches and shuts down unused network devices. Zhang \emph{et al.} \cite{Zhang_Ansari-2012} proposed a hierarchical model to optimize the power in DCNs and proposed some simple heuristics for the model. In \cite{Wang_Zhang-2013-ICCCN}, the authors explored the problem of improving the network energy efficiency in MapReduce systems and afterwards in \cite{Wang_Zhang-PER-2013} they proposed to improve the network energy efficiency by joint optimizing virtual machine assignment and traffic engineering in data centers. Then, this method was extended to a general framework for achieving network energy efficiency in data centers  \cite{Wang_Zhang-JSAC-2013}. In \cite{Shang_li-2013}, the authors proposed to combine preemptive flow scheduling and energy-aware routing to achieve better energy efficiency. But performance guarantee was not considered. In a following work \cite{Xu_Shang-2013}, they considered greening data center networks by using a throughput-guaranteed power-aware routing scheme. To the best of our knowledge, the present paper is among the first to address the energy efficiency of DCNs from the aspect of scheduling and routing while guaranteeing the most critical performance criterion in DCNs - meeting flow deadlines. 

\subsection{Network Scheduling and Routing}

There have been a few works that have investigated the problem of job scheduling with deadlines in a multi-hop network. With known injection rate, a given deadline and fixed routes, the problem of online scheduling of sessions has been investigated by \cite{Andrews_Zhang-1999}, where they first gave a necessary condition for feasibility of sessions and gave an algorithm under which with high probability, most sessions are scheduled without violating the deadline when the necessary condition for feasibility is satisfied. In \cite{Mao_Koksal-2013}, the authors studied online packet scheduling with hard deadlines in general multihop communication networks. The algorithm they proposed gives the first provable competitive ratio, subject to hard deadline constraints for general network topologies. However, they didn't consider optimizing for energy efficiency.

Packet scheduling and routing for energy efficiency in general networks has also been well studied. In \cite{Andrews_Fernandez-SS-2010} and \cite{Andrews_Anta-pd}, the authors investigated to optimize the network energy efficiency from the aspect of routing and scheduling under continuous flow (transmission speed for each flow is given by a constant), by exploiting speed scaling and power-down strategy, respectively. Andrews \emph{et al.} \cite{Andrews_Antonakopoulos-2011} then proposed efficient packet scheduling algorithms for achieving energy efficiency while guaranteeing network stability. In \cite{Andrews_Zhang-2012}, they also provided efficient packet scheduling algorithms for optimizing the tradeoffs between delay, queue size and energy. 

Our approach has some fundamental differences with all the aforementioned solutions. Firstly, we combine speed scaling and power-down strategies for network devices in a unified model. Secondly, we carry out optimization from the granularity of flow instead of the granularity of packet and we aim at guaranteeing flow deadlines. Lastly, we investigate the problem of achieving energy efficiency by combining both flow scheduling and routing where we have to decide not only the routing path and schedule, but also the transmission rate for each flow. 



\section{Conclusions}
\label{sec:conc}

In this paper, we studied flow scheduling and routing problem in data center networks where the deadlines of flows were strictly constrained and the objective was to minimize the energy consumption for transmitting all of the flows. The key observation in this work was that energy efficiency cannot be separately considered regardless of network performance being meeting flow deadlines the most critical requirement for it. We focused on two general versions of this problem with only scheduling and both routing and scheduling respectively. We introduced an optimal combinatorial algorithm for the version with only flow scheduling and devised an efficient approximation algorithm for the version with both routing and scheduling for flows, obtaining a provable performance ratio. With the proposed algorithms, we were able to achieve the aforementioned objective.







\section*{Acknowledgment}

This research was partially supported by National Science Foundation of China (NSFC) Major International Collaboration Project 61020106002, NSFC \& Hong Kong RGC Joint Project 61161160566, NSFC Project for Innovation Groups 61221062, NSFC Project grant 61202059 and 61202210, the Comunidad de Madrid grant S2009TIC-1692, and Spanish MICINN/MINECO grant TEC2011-29688-C02-01. 














\balance

\begin{thebibliography}{1}

\bibitem{Heller_Seetharaman}
B.~Heller, S.~Seetharaman, P.~Mahadevan, Y.~Yiakoumis, P.~Sharma, S.~Banerjee,
  and N.~McKeown, ``Elastictree: Saving energy in data center networks,'' in
  \emph{NSDI}, 2010, pp. 249--264.

\bibitem{Shang_Li}
Y.~Shang, D.~Li, and M.~Xu, ``Energy-aware routing in data center network,'' in
  \emph{Green Networking}, 2010, pp. 1--8.

\bibitem{Wang_Yao}
X.~Wang, Y.~Yao, X.~Wang, K.~Lu, and Q.~Cao, ``Carpo: Correlation-aware power
  optimization in data center networks,'' in \emph{INFOCOM}, 2012, pp.
  1125--1133.

\bibitem{Vasic_Bhurat-2011}
N.~Vasic, P.~Bhurat, D.~M. Novakovic, M.~Canini, S.~Shekhar, and D.~Kostic,
  ``Identifying and using energy-critical paths,'' in \emph{CoNEXT}, 2011,
  p.~18.

\bibitem{Wang_Zhang-JSAC-2013}
L.~Wang, F.~Zhang, J.~A. Aroca, A.~V. Vasilakos, K.~Zheng, C.~Hou, D.~Li, and
  Z.~Liu, ``Greendcn: A general framework for achieving energy efficiency in
  data center networks,'' \emph{IEEE Journal on Selected Areas in
  Communications}, vol.~32, no.~1, pp. 4--15, 2014.

\bibitem{Mahadevan_Sharma}
P.~Mahadevan, P.~Sharma, S.~Banerjee, and P.~Ranganathan, ``A power
  benchmarking framework for network devices,'' in \emph{Networking}, 2009, pp.
  795--808.

\bibitem{Benson_Anand}
T.~Benson, A.~Anand, A.~Akella, and M.~Zhang, ``Understanding data center
  traffic characteristics,'' \emph{Computer Communication Review}, vol.~40,
  no.~1, pp. 92--99, 2010.

\bibitem{Wilson_Ballani}
C.~Wilson, H.~Ballani, T.~Karagiannis, and A.~I.~T. Rowstron, ``Better never
  than late: meeting deadlines in datacenter networks,'' in \emph{SIGCOMM},
  2011, pp. 50--61.

\bibitem{Vamanan_Hasan}
B.~Vamanan, J.~Hasan, and T.~N. Vijaykumar, ``Deadline-aware datacenter tcp
  (d2tcp),'' in \emph{SIGCOMM}, 2012, pp. 115--126.

\bibitem{Hong_Caesar}
C.-Y. Hong, M.~Caesar, and B.~Godfrey, ``Finishing flows quickly with
  preemptive scheduling,'' in \emph{SIGCOMM}, 2012, pp. 127--138.

\bibitem{Zats_Das}
D.~Zats, T.~Das, P.~Mohan, D.~Borthakur, and R.~H. Katz, ``Detail: reducing the
  flow completion time tail in datacenter networks,'' in \emph{SIGCOMM}, 2012,
  pp. 139--150.

\bibitem{Alizadeh_Yang}
M.~Alizadeh, S.~Yang, M.~Sharif, S.~Katti, N.~McKeown, B.~Prabhakar, and
  S.~Shenker, ``pfabric: Minimal near-optimal datacenter transport,'' in
  \emph{SIGCOMM}, 2013.

\bibitem{Mao_Koksal}
Z.~Mao, C.~E. Koksal, and N.~B. Shroff, ``Online packet scheduling with hard
  deadlines in multihop communication networks,'' in \emph{INFOCOM}, 2013.

\bibitem{Al-Fares_Loukissas-FatTree-2008}
M.~Al-Fares, A.~Loukissas, and A.~Vahdat, ``A scalable, commodity data center
  network architecture,'' in \emph{SIGCOMM}, 2008.

\bibitem{Guo_Lu-BCube-2009}
C.~Guo, G.~Lu, D.~Li, H.~Wu, X.~Zhang, Y.~Shi, C.~Tian, Y.~Zhang, and S.~Lu,
  ``Bcube: a high performance, server-centric network architecture for modular
  data centers,'' in \emph{SIGCOMM}, 2009, pp. 63--74.

\bibitem{Andrews_Fernandez-SS-2010}
M.~Andrews, A.~F. Anta, L.~Zhang, and W.~Zhao, ``Routing for power minimization
  in the speed scaling model,'' \emph{IEEE/ACM Trans. Netw.}, vol.~20, no.~1,
  pp. 285--294, 2012.

\bibitem{Nesterov-Ellipsoid-1994}
Y.~Nesterov and A.~Nemirovskii, \emph{Interior Point Polynomial Algorithms in
  Convex Programming}, ser. SIAM studies in applied and numerical mathematics:
  Society for Industrial and Applied Mathematics.\hskip 1em plus 0.5em minus
  0.4em\relax Society for Industrial and Applied Mathematics, 1994.

\bibitem{Yao_Demers_Shenker-YDS-1995}
F.~F. Yao, A.~J. Demers, and S.~Shenker, ``A scheduling model for reduced cpu
  energy,'' in \emph{FOCS}, 1995, pp. 374--382.

\bibitem{Garey_Johnson-1990}
M.~R. Garey and D.~S. Johnson, \emph{Computers and Intractability; A Guide to
  the Theory of NP-Completeness}.\hskip 1em plus 0.5em minus 0.4em\relax New
  York, NY, USA: W. H. Freeman \& Co., 1990.

\bibitem{Vazirani-2004}
V.~V. Vazirani, \emph{Approximation Algorithms}.\hskip 1em plus 0.5em minus
  0.4em\relax Springer, March 2004.

\bibitem{Raghavan_Tompson}
P.~Raghavan and C.~D. Tompson, ``Randomized rounding: a technique for provably
  good algorithms and algorithmic proofs,'' \emph{Combinatorica}, vol.~7,
  no.~4, pp. 365--374, Dec. 1987.

\bibitem{Abts_Marty-2010}
D.~Abts, M.~R. Marty, P.~M. Wells, P.~Klausler, and H.~Liu, ``Energy
  proportional datacenter networks,'' in \emph{ISCA}, 2010, pp. 338--347.

\bibitem{Huang_Jia-2011}
L.~Huang, Q.~Jia, X.~Wang, S.~Yang, and B.~Li, ``Pcube: Improving power
  efficiency in data center networks,'' in \emph{IEEE CLOUD}, 2011, pp. 65--72.

\bibitem{Mahadevan_banerjee-2011}
P.~Mahadevan, S.~Banerjee, P.~Sharma, A.~Shah, and P.~Ranganathan, ``On energy
  efficiency for enterprise and data center networks,'' \emph{IEEE
  Communications Magazine}, vol.~49, no.~8, pp. 94--100, 2011.

\bibitem{Wang_Zhang-2013}
L.~Wang, F.~Zhang, C.~Hou, J.~A. Aroca, and Z.~Liu, ``Incorporating rate
  adaptation into green networking for future data centers,'' in \emph{NCA},
  2013, pp. 106--109.

\bibitem{Zhang_Ansari-2012}
Y.~Zhang and N.~Ansari, ``Hero: Hierarchical energy optimization for data
  center networks,'' in \emph{ICC}, 2012, pp. 2924--2928.

\bibitem{Wang_Zhang-2013-ICCCN}
L.~Wang, F.~Zhang, and Z.~Liu, ``Improving the network energy efficiency in
  mapreduce systems,'' in \emph{ICCCN}, 2013, pp. 1--7.

\bibitem{Wang_Zhang-PER-2013}
L.~Wang, F.~Zhang, A.~V. Vasilakos, C.~Hou, and Z.~Liu, ``Joint virtual machine
  assignment and traffic engineering for green data center networks,''
  \emph{SIGMETRICS Performance Evaluation Review}, vol.~41, no.~3, pp.
  107--112, 2013.

\bibitem{Shang_li-2013}
Y.~Shang, D.~Li, and M.~Xu, ``Greening data center networks with flow
  preemption and energy-aware routing,'' in \emph{Local Metropolitan Area
  Networks (LANMAN), 2013 19th IEEE Workshop on}, 2013, pp. 1--6.

\bibitem{Xu_Shang-2013}
M.~Xu, Y.~Shang, D.~Li, and X.~Wang, ``Greening data center networks with
  throughput-guaranteed power-aware routing,'' \emph{Computer Networks},
  vol.~57, no.~15, pp. 2880--2899, 2013.

\bibitem{Andrews_Zhang-1999}
M.~Andrews and L.~Zhang, ``Packet routing with arbitrary end-to-end delay
  requirements,'' in \emph{STOC}, 1999, pp. 557--565.

\bibitem{Mao_Koksal-2013}
Z.~Mao, C.~E. Koksal, and N.~B. Shroff, ``Online packet scheduling with hard
  deadlines in multihop communication networks,'' in \emph{INFOCOM}, 2013, pp.
  2463--2471.

\bibitem{Andrews_Anta-pd}
M.~Andrews, A.~F. Anta, L.~Zhang, and W.~Zhao, ``Routing and scheduling for
  energy and delay minimization in the powerdown model,'' \emph{Networks},
  vol.~61, no.~3, pp. 226--237, 2013.

\bibitem{Andrews_Antonakopoulos-2011}
M.~Andrews, S.~Antonakopoulos, and L.~Zhang, ``Energy-aware scheduling
  algorithms for network stability,'' in \emph{INFOCOM}, 2011, pp. 1359--1367.

\bibitem{Andrews_Zhang-2012}
M.~Andrews and L.~Zhang, ``Scheduling algorithms for optimizing the tradeoffs
  between delay, queue size and energy,'' in \emph{CISS}, 2012, pp. 1--6.

\end{thebibliography}



\end{document}
