






\section{Experiments}
\label{sec:experiments}

In this section, extensive experiments are conducted to evaluate the proposed method,
compared with a comprehensive collection of SOTA methods \citep{roth2022towards,
zavrtanik2021draem, deng2022anomaly}, \citep{ristea2022self, liu2023diversity,
Liu_2023_CVPR, zhang2023destseg, lei2023pyramidflow, gudovskiy2022cflow, Tien_2023_CVPR,
zhang2022prototypical, yao2022explicit, pang2021explainable, ding2022catching}, on three
well-acknowledged benchmarks, namely, the MVTec-AD \citep{bergmann2019mvtec} dataset, the BTAD
\citep{mishra2021vt} dataset and the KolektorSDD2 dataset
\citep{bovzivc2021mixed-KolektorSDD2}, respectively.

\subsection{Three levels of supervision}
\label{subsec:Experimental_settings}

First of all, let us clarify the experiment settings for the three kinds of supervision. 

\subsubsection{Unsupervised (Un) setting} 
The unsupervised setting is the mainstream in the AD literature, where only normal data
can be accessed during training. However, discriminative models can be learned by
generating synthetic anomalies. The involved algorithms are evaluated on the entire test
set, including both normal and anomalous images. 

\subsubsection{Supervised (Sup) setting} 
In this scenario, a few anomaly training samples are available to improve the
discriminative power of the algorithm. Following the popular setting described in
\citep{zhang2022prototypical}, we randomly draw  anomalous images with
block-wise annotations from various types of defects to the train set and remove them from
the test set. Note that synthetic anomalies can usually be used here for higher
performance. 

\subsubsection{Semi-supervised (Semi) setting} 
The semi-supervised setting is the newly proposed supervision and is thus employed in this
work only. The same  anomalous images are used as training samples while the block
labels of them are determined by the bounding-boxes which are defined in
Equation~\ref{equ:block_label_semi}. Note that in this case, all the blocks are annotated as
either unknown or normal. 

\subsection{Implementation details}
\subsubsection{Hyper parameters}
The layer- and layer- feature maps of the
Wide\-Resnet- model
\citep{zagoruyko2016wide} (pre-trained on ImageNet-1K) are concatenated with a proper scale
adaptation and the yielded  ``hyper-columns'' are smoothed via average
pooling in the  neighborhoods. We set  to
generate PCFs. 
For MVTec-AD \citep{bergmann2019mvtec} and BTAD \citep{mishra2021vt} datasets, we subsample
 of the PCFs to get the memory banks , while the
subsampling ratio for KolektorSDD2 \citep{bovzivc2021mixed-KolektorSDD2} is 
considering the much larger training set of normal images. 
Our Swin Transformer model  consists of  blocks with patch
size , the window size is  and the number of heads is set to . 
The parameters of the focal loss , ,  and 
are set to , ,  and  respectively. 
The sliding window  slides over the PCR tensor with a step  and the
window size is .  and  are set to  and  respectively.  To
speed up training, we sample  of sliding windows in  normal images, 
simulated defective images, and  true anomalous images at each training iteration. 
To compare the final prediction map  with the ground-truth label map, it is
firstly upscaled to the same size as the ground-truth via bilinear interpolation and then
smoothed using a Gaussian of kernel with , as it is done in
\citep{roth2022towards}. 

The values of , , , , ,  and  vary among
different supervision conditions:
\begin{itemize}
    \item Unsupervised setting: , , ,
      , ,  (, ,
      ,  for BTAD \citep{mishra2021vt}). 
    \item Supervised setting: , , ,
      , ,  and .
    \item Semi-supervised setting: , , ,
      ,  ,  and  (,
      , ,  for BTAD \citep{mishra2021vt}). 
\end{itemize}

As to the semi-supervised learning, the hyperparameters , ,  and 
are set to , ,  and  respectively. The random noise for agumentation
is set to .
Following the MixMatch algorithm \citep{berthelot2019mixmatch}, we linearly ramp up the
unlabeled loss weight to  ( for BTAD) over the first  steps
of training. 

\subsubsection{Train and inference time} 
The proposed method requires around  ms to predict anomaly on a  image.
It takes , , and  minutes to train the Swin Transformer model on MVTec-AD
\citep{bergmann2019mvtec} with the unsupervised, semi-supervised, and supervised settings
respectively.

\subsection{Evaluation methods}
\label{subsec:Datasets_and_evaluation_methods}

In this work, the involved AD algorithms are measured comprehensively by three popular threshold-inde\-endent metrics: Pixel-AUROC, PRO \citep{bergmann2020uninformed} (per region overlap) and AP \citep{zavrtanik2021draem} (average precision). In specific, Pixel-AUROC is the area under the receiver operating characteristic curve at the pixel
level. It is the most popular AD measuring method while fails to reflect the real performance difference between algorithms when a serious class imbalance exists. The PRO score, on the contrary, focuses on the anomaly pixels and treats the AD performance on each individual anomaly region equally. Consequently, the PRO metric is more robust to the class imbalance which is actually a common situation in most AD benchmarks. The AP (average precision) metric \citep{zavrtanik2021draem}, as a conventional metric for semantic segmentation, is frequently adopted in recently proposed AD algorithms \citep{zavrtanik2021draem, zhang2022prototypical}. It reflects the anomaly detection performance from a pixel-level perspective. 



\subsection{Results on MVTec-AD}
\label{subsec:Results_on_MVTec_AD}

MVTec-AD \citep{bergmann2019mvtec} is the most popular AD dataset with 
high-resolution color images belonging to  texture categories and  object categories.
Each category contains a train set with only normal images and a test set with various kinds of
defects as well as defect-free images. We conduct the experiments on this dataset within all three supervision conditions.

The unsupervised AD results of the comparing algorithms on MVTec-AD \citep{bergmann2019mvtec} are shown in Table~\ref{tab:unsupervised_results_on_MVTec}. As shown in the table, our method
achieves the highest average AP, average PRO and average pixel AUROC, for both texture and
object categories and outperforms the unsupervised SOTA by ,
 and  respectively. In specific, Semi\-REST ranks the first on  ( out of ) categories with AP metric and the ``first-ranking'' ratios for the PRO and Pixel-AUROC are  and . 

In addition, Table~\ref{tab:supervised_results_on_MVTec} illustrates that with full supervision, SemiREST
still ranks first for the average AD performance evaluated by using all three metrics. In particular, our method outperforms the supervised SOTAs by  on AP,  on PRO and  on Pixel-AUROC. The ``first-ranking'' ratios of SemiREST in the supervised scenario are ,  and  one AP, PRO and Pixel-AUROC respectively. 

Table~\ref{tab:supervised_results_on_MVTec} also reports the performances of our method with the bounding-box-determined semi-supervisions. It can be seen that the semi-supervised SemiREST performs very similarly to the fully-supervised Semi\-REST, thanks to the effective usage of the unlabeled blocks. In addition, even with much less annotation information, the semi-supervised SemiREST still beats the fully-supervised SOTA methods by large margins ( for AP,  for PRO and  for Pixel-AUROC). 

It is interesting to see that, with only synthetic defective samples, the unsupervised SemiREST remains the superiority to the supervised SOTA, with the AP and Pixel-AUROC metrics (see Table~\ref{tab:unsupervised_results_on_MVTec} and see Table~\ref{tab:supervised_results_on_MVTec}). The proposed  algorithm illustrates remarkably high generalization capacities.  

Readers can also find the qualitative results of the proposed method compared with other SOTA algorithms in Figure~\ref{fig:qualitative}.

\begin{table*}
 \centering
	\resizebox{\linewidth}{!}{
\begin{tabular}{@{}lccccccccccc}
\toprule
\multirow{2}{*}{Category}& PatchCore&  DRAEM& RD & SSPCAB  & NFAD& DMAD & SimpleNet& DeSTSeg& PyramidFlow& RD++ & \multirow{2}{*}{Ours (Un)}           \\
&\citep{roth2022towards}&  \citep{zavrtanik2021draem}& \citep{deng2022anomaly} & \citep{ristea2022self}   & \citep{yao2022explicit} & \citep{liu2023diversity} & \citep{Liu_2023_CVPR}& \citep{zhang2023destseg}& \citep{lei2023pyramidflow}&\citep{Tien_2023_CVPR}&
 \\ \midrule
Carpet        & 64.1/95.1/99.1        & 53.5/92.9/95.5   & 56.5/95.4/98.9 & 48.6/86.4/92.6    & {\color{blue}{\textbf{74.1/98.2/99.4}}}  & 63.8/95.9/99.0  & 44.1/92.0/97.7       & 72.8//96.1      & /97.2/97.4        
&/97.7/99.2  &  {\color{red}{\textbf{84.2/98.7/99.6}}}\\
Grid          & 30.9/93.6/98.8       & {\color{red}{\textbf{65.7/98.3/99.7}}}   & 15.8/94.2/98.3 & 57.9/{\color{blue}{\textbf{98.0/99.5}}}     & 51.9/97.9/99.3  & 47.0/97.3/99.2  & 39.6/94.6/98.7       & 61.5//99.1      & /94.3/95.7           
&/97.7/99.3
& {\color{blue}{\textbf{65.5}}}/97.9/{\color{blue}{\textbf{99.5}}} \\

Leather       & 45.9/97.2/99.3       & 75.3/97.4/98.6   & 47.6/98.2/99.4 & 60.7/94.0/96.3     & 70.1/{\color{red}{\textbf{99.4}}}/99.7  & 53.1/98.0/99.4  & 48.0/97.5/99.2       & {\color{blue}{\textbf{75.6}}}//{\color{blue}{\textbf{99.7}}}      & /{\color{blue}{\textbf{99.2}}}/98.7      
&/{\color{blue}{\textbf{99.2}}}/99.4    & {\color{red}{\textbf{79.3/99.4/99.8}}}\\

Tile          & 54.9/80.2/95.7       & 92.3/{\color{blue}{\textbf{98.2}}}/99.2   & 54.1/85.6/95.7 & {\color{blue}{\textbf{96.1}}}/98.1/{\color{blue}{\textbf{99.4}}}     & 63.0/91.8/96.7  & 56.5/84.3/95.8  & 63.5/78.3/93.9       & 90.0//98.0      & /97.2/97.1 
&/92.4/96.6        & {\color{red}{\textbf{96.4/98.5/99.7}}} \\

Wood          & 50.0/88.3/95.0        & 77.7/90.3/96.4   & 48.3/91.4/95.8 & 78.9/92.8/96.5      & 62.9/95.6/96.9  & 45.5/89.3/94.8  & 48.8/83.9/93.9       & {\color{red}{\textbf{81.9}}}//{\color{red}{\textbf{97.7}}}      & /{\color{red}{\textbf{97.9}}}/{\color{blue}{\textbf{97.0}}}  
&/93.3/95.8    &{\color{blue}{\textbf{79.4/96.5}}}/{\color{red}{\textbf{97.7}}}      \\\midrule
Average       & 49.2/90.9/97.6        & 72.9/95.4/97.9   & 44.5/93.0/97.6 & 68.4/93.9/96.9     & 64.4/96.6/{\color{blue}{\textbf{98.4}}}  & 53.2/93.0/97.6  & 48.8/89.3/96.7       & {\color{blue}{\textbf{76.4}}}//98.1      & /{\color{blue}{\textbf{97.2}}}/97.2        
&/96.1/98.1 & {\color{red}{\textbf{81.0/98.2/99.3}}} \\\midrule
Bottle        & 77.7/94.7/98.5       & 86.5/96.8/99.1   & 78.0/96.3/98.8 & 89.4/96.3/{\color{blue}{\textbf{99.2}}}    &  77.9/96.6/98.9  & 79.6/96.4/98.8  & 73.0/91.5/98.0       & {\color{blue}{\textbf{90.3}}}//{\color{blue}{\textbf{99.2}}}      & /95.5/97.8         
&/{\color{blue}{\textbf{97.0}}}/98.8 & {\color{red}{\textbf{94.1/98.6/99.6}}} \\

Cable         & 66.3/93.2/{\color{blue}{\textbf{98.4}}}      & 52.4/81.0/94.7   & 52.6/94.1/97.2 & 52.0/80.4/95.1      & 65.7/{\color{red}{\textbf{95.9}}}/98.0  & 58.9/92.2/97.9  & {\color{blue}{\textbf{69.3}}}/89.7/97.5       & 60.4//97.3      & /90.3/91.8    
&/93.9/{\color{blue}{\textbf{98.4}}}     & {\color{red}{\textbf{81.1}}}/{\color{blue}{\textbf{95.3}}}/{\color{red}{\textbf{99.1}}} \\
Capsule       & 44.7/94.8/99.0       & 49.4/82.7/94.3   & 47.2/95.5/98.7 & 46.4/92.5/90.2    & {\color{red}{\textbf{58.7}}}/96.0/{\color{red}{\textbf{99.2}}}  & 42.2/91.6/98.1  & 44.7/92.8/98.9       & 56.3//{\color{blue}{\textbf{99.1}}}      & /{\color{red}{\textbf{98.3}}}/98.6
&/96.4/98.8        & {\color{blue}{\textbf{57.2/96.9}}}/98.8 \\
Hazelnut      & 53.5/95.2/98.7       & {\color{blue}{\textbf{92.9}}}/{\color{red}{\textbf{98.5/99.7}}}   &  {\color{red}{\textbf{93.4}}}/{\color{blue}{\textbf{98.2}}}/{\color{red}{\textbf{99.7}}}    & 60.0/95.2/98.6   & 65.3/97.6/98.6  & 63.4/95.9/99.1  & 48.3/92.2/97.6       & 88.4//{\color{blue}{\textbf{99.6}}}      & /98.1/98.1 
&/96.3/99.2        & 87.8/96.1/{\color{blue}{\textbf{99.6}}} \\

Metal nut     & 86.9/94.0/98.3        & {\color{blue}{\textbf{96.3}}}/97.0/{\color{red}{\textbf{99.5}}}   & 78.6/94.9/97.3 & 94.7/{\color{red}{\textbf{97.7}}}/{\color{blue}{\textbf{99.4}}}     & 76.6/94.9/97.7  & 79.0/94.2/97.1  & 92.6/91.3/98.7       & 93.5//98.6      & /91.4/97.2    
&/93.0/98.1   & {\color{red}{\textbf{96.6}}}/{\color{blue}{\textbf{97.5}}}/{\color{red}{\textbf{99.5}}} \\
Pill          & 77.9/95.0/97.8       & 48.5/88.4/97.6   & 76.5/96.7/98.1 & 48.3/89.6/97.2     & 72.6/{\color{blue}{\textbf{98.1}}}/98.0  & 79.7/96.9/98.5  & 80.1/93.9/98.5       & {\color{blue}{\textbf{83.1}}}//{\color{blue}{\textbf{98.7}}}      & /96.1/96.1
&/97.0/98.3          & {\color{red}{\textbf{85.9/98.4/99.2}}}\\
Screw         & 36.1/97.1/{\color{blue}{\textbf{99.5}}}  & 58.2/95.0/97.6   & 52.1/ {\color{blue}{\textbf{98.5}}}/{\color{red}{\textbf{99.7}}} & {\color{blue}{\textbf{61.7}}}/95.2/99.0      & 47.4/96.3/99.2  & 47.9/96.5/99.3  & 38.8/95.2/99.2       & 58.7//98.5      & /94.7/94.6  
&/{\color{red}{\textbf{98.6/99.7}}}        & {\color{red}{\textbf{65.9}}}/97.9/{\color{red}{\textbf{99.7}}} \\
Toothbrush    & 38.3/89.4/98.6       & 44.7/85.6/98.1   & 51.1/92.3/99.1 & 39.3/85.5/97.3     & 38.8/92.3/98.7  & 71.4/91.5/99.3  & 51.7/88.7/98.6       & {\color{red}{\textbf{75.2}}}//{\color{blue}{\textbf{99.3}}}      & /{\color{red}{\textbf{97.9}}}/98.5  
&/94.2/99.1       & {\color{blue}{\textbf{74.5/96.2}}}/{\color{red}{\textbf{99.5}}} \\
Transistor    & 66.4/92.4/96.3       & 50.7/70.4/90.9   & 54.1/83.3/92.3 & 38.1/62.5/84.8    & 56.0/82.0/94.0  & 58.5/85.2/94.1  & {\color{blue}{\textbf{69.0}}}/93.2/96.8       & 64.8//89.1      & /{\color{blue}{\textbf{94.7}}}/{\color{blue}{\textbf{96.9}}}
&/81.8/94.3 & {\color{red}{\textbf{79.4/96.0/98.0}}} \\
Zipper        & 62.8/95.8/98.9      & 81.5/{\color{blue}{\textbf{96.8}}}/98.8   & 57.5/95.3/98.3 & 76.4/95.2/98.4       & 56.0/95.7/98.6  & 50.1/93.8/97.9  & 60.0/91.2/97.8       & {\color{blue}{\textbf{85.2}}}//{\color{blue}{\textbf{99.1}}}      & /95.4/96.6 
&/96.3/98.8       & {\color{red}{\textbf{90.2/98.9/99.7}}} \\\midrule
Average       & 61.1/94.2/{\color{blue}{\textbf{98.4}}}    & 66.1/89.2/97.0   & 60.8/94.4/97.9 & 64.0/89.3/96.0    & 61.5/94.5/98.1  & 63.1/93.4/98.0  & 62.7/92.0/98.2       & {\color{blue}{\textbf{75.6}}}//97.9      & /{\color{blue}{\textbf{95.2}}}/96.6     
&/94.5/98.4 & {\color{red}{\textbf{81.3/97.2/99.3}}} \\\midrule
Total Average & 57.1/93.1/98.1      & 68.4/91.3/97.3   & 55.4/93.9/97.8 & 65.5/90.8/96.3     & 62.5/95.2/98.2  & 59.8/93.3/97.9  & 58.1/91.1/97.7       & {\color{blue}{\textbf{75.8}}}//97.9      & /{\color{blue}{\textbf{95.9}}}/96.8   
&/95.0/{\color{blue}{\textbf{98.3}}}      & {\color{red}{\textbf{81.2/97.5/99.3}}} \\ \bottomrule
\end{tabular}
	}
	\caption{
    The comparison on the Average Precision (AP), Per-Region Overlap (PRO) and pixel AUROC
    metrics for zero-shot anomaly localization on the MVTec-AD dataset. The best accuracy
    in one comparison with the same data and metric condition is shown in red while the second one is shown in blue.
  }
\label{tab:unsupervised_results_on_MVTec}
\end{table*}


\begin{table*}
    \centering
       \resizebox{\textwidth}{!}{
    \begin{tabular}{lcccccc}
     \toprule
           \multirow{2}{*}{Category} & PRN& BGAD & DevNet& DRA & \multirow{2}{*}{Ours (Sup)}  & \multirow{2}{*}{Ours (Semi)}\\ 
    &\citep{zhang2022prototypical} & \citep{yao2022explicit} & \citep{pang2021explainable} & \citep{ding2022catching} & \\ 
    \midrule
Carpet        & 82.0/97.0/99.0  & 83.2/{\color{blue}{\textbf{98.9/99.6}}}  & 45.7/85.8/97.2     & 52.3/92.2/98.2 & {\color{red}{\textbf{89.1/99.1/99.7}}} & {\color{blue}{\textbf{88.9}}}/{\color{red}{\textbf{99.1/99.7}}}\\
Grid          & 45.7/95.9/98.4
& 59.2/{\color{red}{\textbf{98.7}}}/98.4 & 25.5/79.8/87.9 & 26.8/71.5/86.0 
& {\color{blue}{\textbf{66.4}}}/97.0/{\color{blue}{\textbf{99.4}}}   & {\color{red}{\textbf{71.5}}}/{\color{blue}{\textbf{98.5}}}/{\color{red}{\textbf{99.7}}} \\

Leather       & 69.7/99.2/99.7  & 75.5/99.5/{\color{blue}{\textbf{99.8}}}  & 8.1/88.5/94.2      & 5.6/84.0/93.8  & {\color{blue}{\textbf{81.7}}}/{\color{red}{\textbf{99.7/99.9}}} & {\color{red}{\textbf{82.0}}}/{\color{blue}{\textbf{99.6}}}/{\color{red}{\textbf{99.9}}} \\

Tile          & 96.5/98.2/{\color{blue}{\textbf{99.6}}} & 94.0/97.9/99.3  & 52.3/78.9/92.7     & 57.6/81.5/92.3 & {\color{red}{\textbf{96.9/98.9/99.7}}}  & {\color{blue}{\textbf{96.6/98.7}}}/{\color{red}{\textbf{99.7}}}  \\

Wood          & 82.6/95.9/97.8  & 78.7/96.8/98.0  & 25.1/75.4/86.4     & 22.7/69.7/82.9 & {\color{red}{\textbf{88.7/97.9/99.2}}} & {\color{blue}{\textbf{86.2/97.1/98.6}}}\\\midrule
Average       & 75.3/97.2/98.9  & 78.1/98.4/{\color{blue}{\textbf{99.2}}}  & 31.3/81.7/91.7     & 33.0/79.8/90.6 & {\color{blue}{\textbf{84.7/98.5}}}/{\color{red}{\textbf{99.5}}} &  {\color{red}{\textbf{85.0/98.6/99.5}}}\\\midrule
Bottle        & {\color{blue}{\textbf{92.3}}}/97.0/{\color{blue}{\textbf{99.4}}}  & 87.1/97.1/99.3 & 51.5/83.5/93.9     & 41.2/77.6/91.3 & {\color{red}{\textbf{93.6/98.5/99.5}}} & {\color{red}{\textbf{93.6}}}/{\color{blue}{\textbf{98.4}}}/{\color{red}{\textbf{99.5}}} \\
Cable         & 78.9/{\color{blue}{\textbf{97.2}}}/98.8  & 81.4/{\color{red}{\textbf{97.7}}}/98.5  & 36.0/80.9/88.8     & 34.7/77.7/86.6 & {\color{red}{\textbf{89.5}}}/95.9/{\color{blue}{\textbf{99.2}}}  & {\color{blue}{\textbf{86.5}}}/96.3/{\color{red}{\textbf{99.3}}} \\
Capsule       & {\color{red}{\textbf{62.2}}}/92.5/98.5  & 58.3/96.8/{\color{blue}{\textbf{98.8}}}  & 15.5/83.6/91.8     & 11.7/79.1/89.3 & {\color{blue}{\textbf{60.0/97.0/98.8}}}  & 58.4/{\color{red}{\textbf{97.6/99.1}}} \\
Hazelnut      & {\color{red}{\textbf{93.8}}}/97.4/{\color{blue}{\textbf{99.7}}}  & 82.4/{\color{red}{\textbf{98.6}}}/99.4  & 22.1/83.6/91.1     & 22.5/86.9/89.6 & {\color{blue}{\textbf{92.2/98.3}}}/{\color{red}{\textbf{99.8}}} & 86.0/97.3/{\color{blue}{\textbf{99.7}}} \\
Metal nut     & 98.0/95.8/99.7  & 97.3/96.8/99.6  & 35.6/76.9/77.8     & 29.9/76.7/79.5 & {\color{red}{\textbf{99.1/98.2/99.9}}}  & {\color{blue}{\textbf{98.3/98.1/99.8}}}\\
Pill          & {\color{blue}{\textbf{91.3}}}/97.2/{\color{red}{\textbf{99.5}}}  & {\color{red}{\textbf{92.1}}}/{\color{blue}{\textbf{98.7}}}/{\color{red}{\textbf{99.5}}}   & 14.6/69.2/82.6     & 21.6/77.0/84.5 & 86.1/{\color{red}{\textbf{98.9}}}/{\color{blue}{\textbf{99.3}}}  & 89.6/{\color{red}{\textbf{98.9/99.5}}} \\
Screw         & 44.9/92.4/97.5 & 55.3/96.8/{\color{blue}{\textbf{99.3}}} & 1.4/31.1/60.3      & 5.0/30.1/54.0  & {\color{red}{\textbf{72.1/98.8/99.8}}}&{\color{blue}{\textbf{67.9/98.6}}}/{\color{red}{\textbf{99.8}}} \\
Toothbrush    & {\color{red}{\textbf{78.1}}}/95.6/{\color{red}{\textbf{99.6}}} & 71.3/96.4/{\color{blue}{\textbf{99.5}}}  & 6.7/33.5/84.6      & 4.5/56.1/75.5  & {\color{blue}{\textbf{74.2}}}/{\color{red}{\textbf{97.1/99.6}}} & 73.3/{\color{blue}{\textbf{96.7}}}/{\color{red}{\textbf{99.6}}} \\
Transistor    & {\color{blue}{\textbf{85.6}}}/94.8/{\color{blue}{\textbf{98.4}}}  & 82.3/97.1/97.9  & 6.4/39.1/56.0      & 11.0/49.0/79.1 & 85.5/{\color{blue}{\textbf{97.8}}}/{\color{red}{\textbf{98.6}}} & {\color{red}{\textbf{86.4/97.9/98.6}}} \\
Zipper        & 77.6/95.5/98.8 & 78.2/{\color{blue}{\textbf{97.7}}}/99.3   & 19.6/81.3/93.7     & 42.9/91.0/96.9 & {\color{blue}{\textbf{91.0}}}/{\color{red}{\textbf{99.2}}}/{\color{blue}{\textbf{99.7}}}  & {\color{red}{\textbf{91.3/99.2/99.8}}} \\\midrule
Average       & 80.3/95.5/99.0  & 78.6/97.4/99.1  & 20.9/66.3/82.1     & 22.5/70.1/82.6 & {\color{red}{\textbf{84.3/98.0}}}/{\color{blue}{\textbf{99.4}}}  & {\color{blue}{\textbf{83.2/97.9}}}/{\color{red}{\textbf{99.5}}} \\\midrule
Total Average & 78.6/96.1/99.0  & 78.4/{\color{blue}{\textbf{97.7/99.2}}}  & 24.4/71.4/85.3     & 26.0/73.3/85.3 & {\color{red}{\textbf{84.4/98.1/99.5}}}  & {\color{blue}{\textbf{83.8}}}/{\color{red}{\textbf{98.1/99.5}}}\\ \bottomrule
 
    \end{tabular}
    }
    \caption{
      The comparison on the Average Precision (AP), Per-Region Overlap (PRO) and pixel
      AUROC metrics for few-shot anomaly localization on the MVTec-AD dataset. The best accuracy
    in one comparison with the same data and metric condition is shown in red while the second one is shown in blue.
    }
\label{tab:supervised_results_on_MVTec}
\end{table*}



\subsection{Results on BTAD}
\label{subsec:Results_on_BTAD}
As a more challenging alternative to MVTec-AD, BTAD \citep{mishra2021vt} (beanTech Anomaly Detection) contains  high-resolution color images of three industrial products. Each product includes normal images
in the train set and the corresponding test set consists of both defective and defect-free images. 

We further evaluate our algorithm on the BTAD dataset with those SOTA methods also reporting their results on this dataset. Table~\ref{tab:unsupervised_BTAD} shows that SemiREST achieves comparable performances to the unsupervised SOTA. Furthermore, as shown in Table~\ref{tab:supervised_BTAD}, with full supervision, the proposed method surpasses SOTA methods by a large margin (,  and ) for all three metrics. Similarly to the situation of MVTec-AD, the semi-supervised SemiREST also obtains higher average performances than the supervised SOTA algorithms.

 \begin{table*}\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{@{}lccccccccc@{}}
\toprule
\multirow{2}{*}{Category}  & PatchCore      & DRAEM       & SSPCAB     & CFLOW & RD & PyramidFlow    & NFAD   &RD++  & \multirow{2}{*}{Ours (Un)} \\
&\citep{roth2022towards}      & \citep{zavrtanik2021draem}          & \citep{ristea2022self}         & \citep{gudovskiy2022cflow}          & \citep{deng2022anomaly}             & \citep{lei2023pyramidflow}        & \citep{yao2022explicit}   &\citep{Tien_2023_CVPR}   \\ \midrule
01         & 47.1/78.4/96.5 & 17.0/61.4/91.5 & 18.1/62.8/92.4 & 39.6/60.1/94.8 &
  {\color{blue}{\textbf{49.3}}}/72.8/95.7 & //{\color{blue}{\textbf{97.4}}} &
  46.7/{\color{blue}{\textbf{76.6}}}/96.7
 & /73.2/96.2  & {\color{red}{\textbf{52.4/83.9/97.5 }}}\\
02         & 56.3/54.0/94.9 & 23.3/39.0/73.4 & 15.8/28.6/65.6 &
  {\color{blue}{\textbf{65.5}}}/56.9/93.9 & {\color{red}{\textbf{66.1}}}/55.8/96.0 &
  //{\color{red}{\textbf{97.6}}} & 59.2/57.9/96.4 
  & /{\color{red}{\textbf{71.3}}}/96.4&
  63.1/{\color{blue}{\textbf{61.5/96.5}}} \\
03         & 51.2/96.4/99.2 & 17.2/84.3/96.3 & 5.0/71.0/92.4  &
  {\color{blue}{\textbf{56.8/97.9/99.5}}} &
  45.1/{\color{red}{\textbf{98.8}}}/99.0 & //98.1 &
  {\color{red}{\textbf{62.8/98.8/99.7}}}
  & /87.4/{\color{red}{\textbf{99.7}}} & 50.9/{\color{red}{\textbf{98.8}}}/{\color{red}{\textbf{99.7}}} \\\midrule
Average    & 51.5/76.3/96.9 & 19.2/61.6/87.1 & 13.0/54.1/83.5 & 54.0/71.6/96.1 &
  53.5/75.8/96.9 & //97.7
  &  {\color{red}{\textbf{56.2}}}/{\color{blue}{\textbf{77.8}}}/{\color{blue}{\textbf{97.6}}} & /77.3/97.4 &
  {\color{blue}{\textbf{55.5}}}/{\color{red}{\textbf{81.4/97.9}}} \\ \bottomrule
\end{tabular}}
\caption{
  Results of the AP, PRO and pixel AUROC metrics for unsupervised anomaly localization
  performance on BTAD. The best accuracy
   in one comparison with the same data and metric condition is shown in red while the second one is shown in blue.
}
\label{tab:unsupervised_BTAD}
\end{table*}


\begin{table*}\centering
{
\begin{tabular}{@{}lcccc@{}}
\toprule
  \multirow{2}{*}{Category}& BGAD        & PRN          & \multirow{2}{*}{Ours (Sup)}        & \multirow{2}{*}{Ours (Semi)}\\
&\citep{yao2022explicit}   &\citep{zhang2022prototypical}    \\ \midrule
01         & 64.0/{\color{blue}{\textbf{86.6/98.4}}} & 38.8/81.4/96.6 & {\color{red}{\textbf{81.3/93.1/99.0}}} & {\color{blue}{\textbf{69.8}}}/86.2/98.2 \\
02         & {\color{blue}{\textbf{83.4}}}/66.5/{\color{blue}{\textbf{97.9}}} & 65.7/54.4/95.1 & {\color{red}{\textbf{84.7/81.4/98.1}}} & 81.2/{\color{blue}{\textbf{69.0/97.9}}} \\
03         & {\color{blue}{\textbf{77.4}}}/{\color{blue}{\textbf{99.5}}}/{\color{red}{\textbf{99.9}}} & 57.4/98.3/{\color{blue}{\textbf{99.6}}} & {\color{red}{\textbf{79.9}}}/99.4/{\color{red}{\textbf{99.9}}} & 75.6/{\color{red}{\textbf{99.6/99.9}}} \\
Average    & 74.9/84.2/{\color{blue}{\textbf{98.7}}} & 54.0/78.0/97.1 & {\color{red}{\textbf{82.0/91.3/99.0}}} & {\color{blue}{\textbf{75.5/84.9/98.7}}} \\ \bottomrule
\end{tabular}}
\caption{
  Results of the AP, PRO and pixel AUROC metrics for supervised and semi-supervised
  anomaly localization performance on BTAD. The best accuracy
    in one comparison with the same data and metric condition is shown in red while the second one is shown in blue.
}
\label{tab:supervised_BTAD}
\end{table*}


\subsection{Results on KolektorSDD2}
\label{subsec:Results_on_KolektorSDD2}
KolektorSDD2 \citep{bovzivc2021mixed-KolektorSDD2} dataset is designed for surface defect
detection and includes various types of defects, such as scratches, minor spots, and
surface imperfections. It comprises a training set with  positive (defective) and  negative (defect-free) images, as well as a test set with  positive and  negative images. We compare the performances of SemiREST with the SOTA results that are available in the literature. In the unsupervised setting, the algorithms are tested on the original test set. For the supervised and semi-supervised settings, a new training set is generated by combining all the normal training images and  defective images which are randomly selected from the original training set. 

As shown in Table~\ref{tab:supervised_KSDD2}, Our unsupervised performances beat those of SOTA methods by a
large margin (,  and  for AP, PRO and Pixel-AUROC, respectively). Under
supervised and semi-supervised settings, our method also achieves better results. It is worth noting that the unsupervised SemiREST performs better than itself with full supervision and semi-supervision. This over-fitting phenomenon might be caused by the (unnecessarily) low sampling rate of defective images in training.   

\begin{table}\centering
\begin{tabular}{@{}lccc@{}}
\toprule
Method                & AP   & PRO  & AUROC \\ \midrule
PatchCore\citep{roth2022towards}             & 64.1 & 88.8 & 97.1         \\
DRAEM\citep{zavrtanik2021draem}                 & 39.1 & 67.9 & 85.6         \\
SSPCAB\citep{ristea2022self}                & 44.5 & 66.1 & 86.2         \\
CFLOW\citep{gudovskiy2022cflow}                 & 46.0   & 93.8 & 97.4         \\
RD\citep{deng2022anomaly}                    & 43.5 & 94.7 & 97.6         \\
Ours(Un)    & {\color{red}{\textbf{72.8}}} & {\color{red}{\textbf{98.1}}} & {\color{red}{\textbf{99.4}}}         \\\midrule
PRN\citep{zhang2022prototypical}       & {\color{blue}{\textbf{72.5}}}& 94.9 & 97.6         \\
Ours(Sup)      & {\color{red}{\textbf{73.6}}} & {\color{blue}{\textbf{96.7}}} & {\color{blue}{\textbf{98.0}}}         \\
Ours(Semi) & 72.1 & {\color{red}{\textbf{97.5}}} & {\color{red}{\textbf{99.1}}}         \\ \bottomrule
\end{tabular}
\caption{Results of anomaly localization performance on KolektorSDD2. The best accuracy
    in one comparison with the same data and metric condition is shown in red while the second one is shown in blue. Note that the upper sub-table shows the results obtained in the unsupervised condition and the lower part reports those with full-supervision or semi-supervision (only for SemiREST).}
\label{tab:supervised_KSDD2}
\end{table}

\subsection{Analysis on weak labels}
\label{subsec:Analysis_on_weak_labels}
Recall that the main motivation of this paper is to reduce the labeling cost of AD
tasks, we report the annotation time-consumption of the proposed two weak labels compared
with pixel-level annotations. 

To obtain the labeling time, the pixel labels, block labels and the bounding boxes of anomaly regions on a subset of MVTec-AD ( defective image for each sub-category) are all manually annotated. Four master students majoring in computer vision complete the labeling task using a self-developed labeling tool, as shown in Figure~\ref{fig:gui}. The annotators are asked to mimic the ground truth annotations shown in a sub-window of the GUI and the annotating time for each image is recorded. 

\begin{figure}
  \begin{center}
\includegraphics [scale=0.4]{annotation_gui.pdf}
\caption{
    Our labeling tool and the yielded annotation maps. The upper part is the GUI window with the pixel-wise label map (red) displayed in the top-left corner. The lower part illustrates the annotations with three levels of fineness. They are, from left to right, pixel-wise labels, block-wise labels, and bounding-box labels, respectively.     
}
  \label{fig:gui}
  \end{center}  
\end{figure}

The average annotation times of three kinds of labels are illustrated in Figure~\ref{fig:label_time}, along with the corresponding best AD performances (Pixel-AUROC, PRO, AP). According to the figure, one requires only around  seconds for labeling bounding boxes and around  seconds for generating block-wise labels, on one image. In contrast, the pixel-label consumes more than  seconds for one image, while with consistently lower accuracy. 

\begin{figure}
  \begin{center}
\includegraphics [scale=0.45]{annotation_time.pdf}
\caption{
    The per-image annotation costs (x-axis) of the three levels of anomaly labels, are shown as the pentagram (bounding-box label), pentagon (block-wise label) and circle (pixel-wise label) shapes. The y-axis stands for the AD performances with the three metrics, shown as blue-dot (Pixel-AUROC), orange-solid (PRO) and green-dashed (AP) lines.      
}
  \label{fig:label_time}
  \end{center}  
\end{figure}

\subsection{Ablation study}
\label{subsec:Ablation_study}
In this section, the most influential modules of Semi\-REST are evaluated in the manner of
an ablation study. The involved modules include: the usage of the \emph{PCF}
Section~\ref{subsubsec:pcf}, the \emph{Bagging} prediction of Swin Transformers
Section~\ref{subsubsec:bagging}, the \emph{-NN augmentation} of PCRs Section~\ref{subsubsec:knn}, the
customized \emph{MixMatch} algorithm Section~\ref{subsec:mixmatch} and the \emph{random dropout}
scheme Section~\ref{subsubsec:dropout}, respectively. From Table~\ref{tab:ablation} one can observe a consistent increase in the AD performance as more modules are added to the SemiREST model.

In addition, two element-wise distance functions (see Section~\ref{subsubsec:pcf}), \emph{i.e.}, the absolute value of the difference (ABS) and the difference square (Square) are also compared in Table~\ref{tab:ablation}. According to the table, the square function outperforms the ABS function within unsupervised and semi-supervised settings where no real defective pixels are seen or labeled. The performance gain might be related to the ``feature-selection'' property of the square operation, which only focuses on the significant components of the residual vector. On the contrary, when the real defective samples are given for generating PCRs, more useful information can be maintained via the conservative ABS function.     


\begin{table*}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{@{}ccccccccc@{}}
\toprule
\multicolumn{6}{c}{Module} & \multicolumn{3}{c}{Performance} \\ 
\cmidrule(lr){1-6}\cmidrule(lr){7-9}
  & PCF & Bagging & -NN Augmentation & MixMatch & Random Dropout & Unsupervised   & Supervised & Semi-supervised \\
  \midrule 
Square & & &  & &  & 70.5/95.4/98.4 & 75.1/96.6/98.9 & -- \\ 
ABS & & &  & &  & 69.3/94.8/98.3 & 76.8/96.9/99.0 & -- \\   
Square &   & & & & & 72.4/95.8/98.9 & 76.4/96.6/99.0 & -- \\ 
Square &   &  & & & & 79.3/96.9/98.8 & 83.4/98.2/99.4 & -- \\ 
Square &   &  &  & & & {\color{red}{\textbf{81.2/97.5/99.3}}} & 84.4/98.2/{\color{red}{\textbf{99.5}}} & 80.7/97.5/99.3 \\
Square &   &  &  &  & & {\color{red}{\textbf{81.2/97.5/99.3}}} & 84.4/98.2/{\color{red}{\textbf{99.5}}}   & 82.1/97.8/99.4 \\
Square &   &  &  &  &  & {\color{red}{\textbf{81.2/97.5/99.3}}} & 84.4/98.2/{\color{red}{\textbf{99.5}}}   & {\color{red}{\textbf{83.8/98.1/99.5}}} \\ 
ABS &   &  &  &  &  & 76.4/96.3/98.7 & {\color{red}{\textbf{84.9/98.3/99.5}}} & 83.2/98.0/99.3 \\
  \bottomrule
\end{tabular}}
\caption{
    Ablation study results on MVTec-AD. Note that the semi-supervised SemiREST inherits the PCF feature, the bagging of swin transformer and -NN augmentation modules from the fully-supervised version.
}
\label{tab:ablation}
\end{table*}

\begin{figure*} 
\begin{center}
  \includegraphics [width=0.75\textwidth]{semiRest_results.pdf}

\caption{
Qualitative results of our SemiREST on MVTec-AD, with the three levels of supervision: Un (unsupervised), Sup (supervised), and Semi (semi-supervised). Two unsupervised SOTA methods (PatchCore \citep{roth2022towards} and DRAEM \citep{zavrtanik2021draem}) and two SOTA methods with full supervision (DevNet \citep{pang2021explainable} and BGAD \citep{yao2022explicit}) are also involved in the comparison.
}
\label{fig:qualitative}
\end{center}  
\end{figure*}




