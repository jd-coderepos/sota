\vspace{-7mm}
\section{Experimental Results} \label{sec:exp}
\subsection{Experimental Setup}
\noindent \textbf{Dataset.} We evaluate our proposed method on the Math23K dataset~\cite{wang-etal-2017-deep}. It contains 23,161 math word problems annotated with solution expressions and answers. For the weakly-supervised setting, we only use the problems and final answers and discard the expressions. We do cross-validation following the setting of \citet{Xie2019AGT}.




\noindent \textbf{Evaluation Metric.} We evaluate the model performance by answer accuracy, where the generated solution is considered correct if it executes to the ground-truth answer. Specifically, we report answer accuracies of all the top-$1/3/5$ predictions using beam search. It evaluates the model's ability to generate multiple possible solutions. 

\noindent \textbf{Models.} We conduct experiments by comparing our methods with variants of weakly-supervised learning methods. Specifically, we experiment with two inference models: Seq2Seq with bidirectional Long Short Memory network (BiLSTM)~\cite{Wu2016GooglesNM} and GTS~\cite{Xie2019AGT}, and train with four learning strategies: REINFORCE, MAPO~\cite{Liang2018MemoryAP}, LBF, LBF-w/o-M (without memory buffer). MAPO is a state-of-the-art method in semantic parsing task that extends the REINFORCE with augmented memory. Both models are also trained with the tree regularization algorithm. We also compare with the fully-supervised learning methods to demonstrate our superiority in generating diverse solutions. In the ablative studies, we analyze the effect of the proposed tree regularization and the length of search steps in fixing mechanism. 





\subsection{Comparisons with State-of-the-art}
\autoref{tab:acc} summarizes the answer accuracy of different weakly-supervised learning methods and the state-of-the-art fully-supervised approaches. The proposed learning-by-fixing framework significantly outperforms the policy gradient baselines like REINFORCE and MAPO, on both the Seq2seq and the GTS models. It demonstrates the strength of our proposed LBF method in weakly-supervised learning.  The GTS-LBF-fully model is trained by initializing the memory buffer with all the ground-truth expressions. It demonstrates that by extending to the fully-supervised setting, our model maintains the top-1 accuracy while significantly improving solutions' diversity. We believe that learning MWPs with weak supervision is a promising direction. It requires fewer annotations and allows us to build larger datasets with less cost.

\begin{table}[h]
    \centering
    \small
    \scalebox{0.75}{
    \begin{tabular}{c|c|c}
        \hline
        \multicolumn{2}{c|}
        {\textbf{Model}} & \textbf{Accuracy}(\%) \\
        \hline
        \multicolumn{3}{c}{\textit{Fully-Supervised}} \\
        \hline
        \multicolumn{2}{c|}{{Retrieval}~\cite{Robaidek2018DataDrivenMF}}  & 47.2\\
        \multicolumn{2}{c|} {Classification~\cite{Robaidek2018DataDrivenMF}} & 57.9\\
        
        \multicolumn{2}{c|}{ LSTM~\cite{Robaidek2018DataDrivenMF}} & 51.9\\
        
        \multicolumn{2}{c|}{
        CNN~\cite{Robaidek2018DataDrivenMF}} & 42.3\\
        
        \multicolumn{2}{c|}{
        DNS~\cite{wang-etal-2017-deep}} & 58.1\\
        
         \multicolumn{2}{c|} {Seq2seqET~\cite{Wang2018TranslatingMW}} & 66.7\\
        
         \multicolumn{2}{c|}
         {Stack-Decoder~\cite{Chiang2019SemanticallyAlignedEG}} & 65.8\\
         
          \multicolumn{2}{c|}
         {T-RNN~\cite{Wang_Zhang_Zhang_Xu_Gao_Dai_Shen_2019}} & 66.9\\
         
          \multicolumn{2}{c|}
         {GTS~\cite{Xie2019AGT}} & 74.3 \\
         \multicolumn{2}{c|}
         {Graph2Tree~\cite{zhang2020graph2tree}} & \textbf{74.8} \footnotemark\\
         \multicolumn{2}{c|}
         {GTS-LBF-fully}  & 74.1 \\
        \hline

        \multicolumn{3}{c}{\textit{Weakly-Supervised}} \\
        \hline
        \multirow{4}{*}{Seq2seq} & REINFORCE & 1.2\\
        & MAPO & 10.7\\
        & LBF-w/o-M & 44.7\\
        & LBF & 43.6\\
        \hline
        \multirow{4}{*}{GTS} & REINFORCE & 15.8\\
         & MAPO & 20.8 \\
         & LBF-w/o-M & 58.3 \\
         & LBF  & \textbf{59.4}\\
         \hline
    \end{tabular}}
    \caption{Answer accuracy on the Math23K dataset. We compare variants of models with our LBF method.}
    \label{tab:acc}
    \vspace{-5mm}
\end{table}

\footnotetext{
We run the code using the same setting as GTS for three times and compute the average accuracy.}
\subsection{Convergence Speed}
\autoref{fig:curve} shows the learning curves of different weakly-supervised learning methods for the GTS model. The proposed LBF method converges significantly faster and achieves higher accuracy compared with other methods. Both the REINFORCE and MAPO take a long time to start improving, which indicates the policy gradient methods suffer from the cold-start and need time to accumulate rewarding samples. 


\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{Figures/test_accuracy.pdf}
    \caption{The learning curves of the GTS model using different weakly-supervised learning methods.}
    \label{fig:curve}
    \vspace{-5mm}
\end{figure}
\subsection{Diverse Solutions with Memory Buffer}
To evaluate the ability to generate diverse solutions, we report the answer accuracies of all the top-1/3/5 solutions on the test set using beam search, denoted as Acc@1/3/5, as shown in \autoref{tab:beam}. In the weakly-supervised scenario, GTS-LBF achieves slightly better Acc@1 accuracy and much better Acc@3/5 accuracy than GTS-LBF-w/o-M. In the fully supervised scenario, GTS-LBF-fully achieves comparable Acc@1 accuracy and much better Acc@3/5 accuracy than the original GTS model. Particularly, GTS-LBF-fully outperforms GTS by 21\% and 26\% in terms of Acc@3/5 accuracy. It reveals the efficacy of the memory buffer in encouraging diverse solutions in both weakly-supervised learning and fully-supervised learning.

\begin{table}[!htbp]
    \centering
    \small
    \begin{tabular}{c|l|rrr}
        \hline
        \textbf{Model} & \textbf{Tree Size} &\textbf{Acc@1} &\textbf{Acc@3} & \textbf{Acc@5} \\
        \hline
        \multicolumn{5}{c}{\textit{Fully Supervised}}\\
        \hline
\multicolumn{2}{c|}{GTS}  & \textbf{74.3} & 42.2 & 30.0\\
        \hline
        \multicolumn{2}{c|} {GTS-LBF-fully} & 74.1 & \textbf{63.4} & \textbf{56.3} \\
        \hline
        \multicolumn{5}{c}{\textit{Weakly Supervised}}\\
        \hline
\multirow{4}{*}{\shortstack{GTS-LBF-\\w/o-M}} 
        & [1,$+\infty$) & $\sim$0 & $\sim$0 & $\sim$0\\
        & [2n-1,2n+1] & 55.3 & 26.2 & 19.3\\
        & [2n-1,2n+3] & 58.3 & 27.7 & 20.3\\
        & [2n-3,2n+5] & 56.7 & 27.7 & 20.6\\
        \hline
        \multirow{4}{*}{GTS-LBF} 
        & [1,$+\infty$) & $\sim$0 & $\sim$0 & $\sim$0\\
        & [2n-1,2n+1] & 56.7 & 45.3 & 39.1\\
        & [2n-1,2n+3] & \textbf{59.4} & \textbf{49.6} & \textbf{45.2}\\
        & [2n-3,2n+5] & 57.6 & 49.3 & 45.2\\
        \hline
    \end{tabular}
    \caption{Answer accuracies of all the top-1/3/5 solutions decoded using beam search, denoted as Acc@1/3/5.}
    \label{tab:beam}
\vspace{-5mm}

    
\end{table}

\begin{figure*}[htbp]
    \vspace{-0.5cm}
    \centering
    \includegraphics[width=\textwidth, page=1]{Figures/qualitative_examples.pdf}
    \vspace{-0.5cm}
    \caption{Qualitative results on the Math23K dataset. We visualize the solution trees generated by our method.}
    \vspace{-0.5cm}

    \label{fig:qualitative}
\end{figure*}


\subsection{Qualitative Analysis} \label{sec_QS}
We visualize several examples of the top-5 predictions of GTS-LBF in \autoref{fig:qualitative}. In the first example, the first solution generated by our model is to sum up the prices of a table and a chair first, and then multiply it by the number of pairs of tables and chairs. Our model can also produce another reasonable solution (the fifth column) by deriving the prices of tables and chairs separately and then summing them up. 




One caveat for the multiple solutions is that some solutions have different solution trees but are equivalent by switching the order of numeric values or subtrees, as shown in the first four solutions of the first problem in \autoref{fig:qualitative}. In particular, multiplication and addition are commutative, and our model learns and exploits this property to generate equivalent solutions with different tree structures. 
\begin{table}[]
    \centering
    \small
    \begin{tabular}{c|ccc}
        \hline
         & Right & Wrong & Spurious \\
         \hline
        Acc@1 & 58.6 & 40.6 & 0.56\\
        Acc@3 & 49.3 & 50.4 & 0.27\\
        Acc@5 & 44.9 & 54.8 & 0.32\\
        \hline
    \end{tabular}
    \caption{Human evaluation on the generated solutions (\%). }
    \label{tab:spurious}
    \vspace{-5mm}
\end{table}


The first solution to the fourth problem in \autoref{fig:qualitative} is a typical error case of our model due to the wrong prediction of the problem goal. Another failure type is the spurious solutions, which are correct but not meaningful answers, such as the second solution of the third problem in \autoref{fig:qualitative}. To test how frequent the spurious solutions appear, we randomly select 500 examples from the test set, and ask three human annotators to determine whether each generated expression is right, wrong, or spurious. \autoref{tab:spurious} provides the human evaluation results, and it shows that spurious solutions are rare in our model. 


\subsection{Ablative Analyses}
\paragraph{Tree Regularization.}
We test different choices of the hyperparameters defined by \autoref{eq_tree_reg} in tree regularization. As shown in \autoref{tab:beam}, the model without tree regularization, \ie, tree size $\in [1, +\infty)$, fails to converge and gets nearly 0 accuracy. The best range for the solution tree size is $[2n-1, 2n+3]$, where $n = \text{len}(V^{num})$.  We provide an intuitive interpretation of this range: for a problem with $n$ quantities, (1) $n-1$ operators are needed to connect $n$ quantities, which leads to the lower bound of tree size to $2n-1$; (2) in certain cases, the constants or quantities are used more than once, leading to a rough upper bound of $2n+3$. Therefore, we use $[2n-1, 2n+3]$ as the default range in our implementations.
Empirically, this range covers 88\% of the lengths of the given ground-truth expressions in the Math23K dataset, providing an efficient prior for tree size.

\vspace{-3mm}

\paragraph{Number of Search Steps} 
\autoref{tab:step} shows the comparison of various step lengths in the m-FIX algorithm. In most cases, increasing the step length improves the chances of correcting wrong solutions, thus improving the performance.
\begin{table}[H]
    \centering
    \vspace{-3mm}
    \small{
    \begin{tabular}{c|cccc}
        \hline
        \backslashbox[33mm]{\textbf{Models}}{\textbf{Steps}} & \textbf{1} & \textbf{10} & \textbf{50 (default)} & \textbf{100}\\
        \hline
        Seq2seq-LBF-w/o-M & 41.9 & 43.4 & {44.7} & \textbf{47.8}\\
        Seq2seq-LBF &43.9 &\textbf{45.7}&43.6 & 44.6\\
        \hline
        GTS-LBF-w/o-M & 51.2 & 54.6 & \textbf{58.3} & 57.8\\
        GTS-LBF &52.5 & 55.8  & 59.4 & \textbf{59.6}\\
        \hline
    \end{tabular}
    }
    \caption{Accuracy (\%) using various search steps.}
    \label{tab:step}
 \vspace{-3mm}
   
\end{table}







