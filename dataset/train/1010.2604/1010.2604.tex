\documentclass[preprint]{sigplanconf}
\usepackage{amsmath}
\usepackage{graphicx}


\pdfpagewidth=8.5in
\pdfpageheight=11in



\newcommand{\true}{\mathit{true}}
\newcommand{\false}{\mathit{false}}
\newcommand{\varoast}{\star}
\renewcommand{\labelitemi}{\labelitemiii}
\newcommand{\Le}[1]{L(#1)}
\newcommand{\Lp}[1]{L_p(#1)}
\newcommand{\der}[2]{\ensuremath{\partial_{#1}(#2)}}
\newcommand{\nul}[1]{\ensuremath{\nu(#1)}}
\newcommand{\dnf}{\mathit{nf}}
\newcommand{\nf}{\mathit{nf}_{\!\mathbf{\epsilon}}}
\newcounter{item}
\newtheorem{theorem}[item]{Theorem}
\newtheorem{lemma}[item]{Lemma}
\newtheorem{definition}[item]{Definition}
\newtheorem{example}[item]{Example}
\newtheorem{remark}[item]{Remark}
\newtheorem{corollary}[item]{Corollary}
\newenvironment{proof}{\begin{trivlist}\item[]{\em Proof.}}{\end{trivlist}}

\begin{document}



\titlebanner{}\preprintfooter{short description of paper}   

\title{Regular Expressions, {\em au point}\\}

\authorinfo{Andrea Asperti}
           {Department of Computer Science, \\
            University of Bologna\\
            Mura Anteo Zamboni 7, 40127, Bologna, ITALY}
           {asperti@cs.unibo.it}

\authorinfo{Claudio Sacerdoti Coen}
           {Department of Computer Science,\\
	   University of Bologna\\
            Mura Anteo Zamboni 7, 40127, Bologna, ITALY}
           {sacerdot@cs.unibo.it}

\authorinfo{Enrico Tassi}
           {Microsoft Research-INRIA Joint Center}
           {enrico.tassi@inria.fr}



\maketitle

\begin{abstract}
We introduce a new technique for constructing a finite state 
deterministic automaton from a regular expression, based on the idea 
of marking a suitable set of positions {\em inside} the expression,
intuitively representing the possible points reached after the 
processing of an initial prefix of the 
input string. {\em Pointed} regular expressions
join the elegance and the symbolic appealingness of Brzozowski's
derivatives, with the effectiveness of McNaughton and Yamada's
labelling technique, essentially combining the best of the two 
approaches. 
\end{abstract}

\category{F.1.1}{Models of Computation}{}


\terms{Theory}
\keywords{Regular expressions, Finite States Automata, Derivatives}

\section{Introduction}
There is hardly a subject in Theoretical Computer Science 
that, in view of its relevance and elegance, has been so thoroughly
investigated as the notion of {\em regular expression} and its relation
with {\em finite state automata} (see e.g. \cite{RS97,EllulKSW05} for
some recent surveys). All the studies in this area
have been traditionally inspired by two precursory, basilar works:
Brzozowski's theory of {\em derivatives} \cite{Brzozowski64}, and McNaughton and Yamada's
algorithm \cite{McNY60}. The main advantages of derivatives are that they are
syntactically appealing, easy to grasp and to prove correct (see 
\cite{OwensRT09} for a recent revisitation). 
On the other side, McNaughton and Yamada's approach
results in a particularly efficient algorithm, still used by
most pattern matchers like the popular grep and egrep utilities. 
The relation between the two approaches has been deeply investigated
too, starting from the seminal work by Berry and Sethi \cite{BS86} where it
is shown how to refine Brzozowski's method to get to the efficient
algorithm (Berry and Sethi' algorithm has been further improved by
later authors \cite{Bruggemann-Klein93,ChangP92}).

Regular expressions are such small world that it is much at no one's surprise
that all different approaches, at the end, turn out to be equivalent;
still, their philosophy, their underlying intuition, and the techniques
to be deployed can be sensibly different. Without having the
pretension to say anything really original on the subject, we introduce
in this paper a notion of {\em pointed} regular expression, that 
provides a cheap palliative for derivatives and allows a simple, direct 
and efficient construction of the deterministic finite automaton. 
Remarkably, the formal correspondence between pointed 
expressions and Brzozowski's derivatives is unexpectedly entangled 
(see Section~\ref{relation}) testifying the novelty and the not-so-trivial 
nature of the notion.



The idea of pointed expressions was suggested 
by an attempt of formalizing the theory
of regular languages by means of an interactive prover\footnote{The rule
of the game was to avoid overkilling, i.e. not make it more complex
than deserved.}. At first,
we started considering derivatives, since they looked more suitable
to the kind of symbolic manipulations that can be easily dealt with 
by means of these tools. However, the need to consider {\em sets} of
derivatives and, especially, to reason modulo associativity, commutativity
and idempotence of sum, prompted us to look for an alternative notion.
Now, it is clear that, in some sense, the derivative of a regular expression
 is a set of  ``subexpressions'' of \footnote{This is also the reason why, at
the end, we only have a finite number of derivatives.}: the only, 
crucial, difference is that we cannot forget their context. So, the natural 
solution is to {\em point} at subexpressions {\em inside} the original term.
This immediately leads to the notion of {\em pointed} regular expression
(pre), that is just a normal regular expression where some positions
(it is enough to consider individual characters) have been pointed
out. Intuitively, the points mark the positions inside the regular
expression which have been reached after reading some prefix of
the input string, or better the positions where the processing
of the remaining string has to be started. Each pointed expression
for  represents a state of the {\em deterministic} automaton associated
with ; since we obviously have only a finite number of possible
labellings, the number of states of the automaton is finite.

Pointed regular expressions allow the {\em direct} construction of 
the DFA \cite{Kleene56}
associated with a regular expression, in a way that is
simple, intuitive, and efficient (the task is traditionally 
considered as {\em very involved} in the literature: see e.g
\cite{RS97}, pag.71).

In the imposing
bibliography on regular expressions - as far as we could discover -
the only author mentioning a notion close to ours is Watson \cite{Watson01,Watson02}. 
However, he only deals with single points, while the most 
interesting properties
of {\em pre} derive by their implicit additive nature (such as the
possibility to compute the {\em move} operation by a single pass on
the marked expression: see definition~\ref{move}).

\section{Regular expressions}

\begin{definition}
A regular expression over the alphabet  is 
an expression  generated by the following grammar:

with 
\end{definition}

\begin{definition}
The language  associated with the regular expression  
is defined by the following rules:

where  is the empty string, 
 is the
concatenation of  and 
and  is the so called Kleene's closure of : , with  and .
\end{definition}

\begin{definition}[nullable]~\\
A regular expression  is said to be nullable if .
\end{definition}

\noindent
The fact of being  nullable is decidable; it is easy to prove that the 
characteristic function  can be computed by the following 
rules:


\begin{definition}
A deterministic finite automaton (DFA) is a quintuple  
where
\begin{itemize}
\item  is a finite set of states;
\item  is the input alphabet;
\item  is the initial state;
\item  is the state transition function;
\item  is the set of final states.
\end{itemize}
\end{definition}

\noindent
The transition function  is extended to strings in the following way:

\begin{definition}Given a function , 
the function  is defined as follows:

\end{definition}

\begin{definition}
Let  be a DFA; the language recognized 
 is defined as follows:

\end{definition}

\section{Pointed regular expressions}

\begin{definition}\ \label{def:pre}
\begin{enumerate}
\item A {\em pointed item} over the alphabet  is 
an expression  generated by following grammar:

with ;
\item A {\em pointed regular expression} (pre) is a pair 
 where  is a boolean and  is a 
pointed item.
\end{enumerate}
\end{definition}
The term  is used to point to a position inside the regular
expression, preceding the given occurrence of . 
In a pointed regular expression, 
the boolean must be intuitively understood as the possibility to have
a trailing point at the end of the expression. 

\begin{definition} \label{def:carrier}
The {\em carrier}  of an item 
is the regular expression obtained from  by removing all the points.
Similarly, the {\em carrier} of a pointed regular expression is the 
carrier of its item.
\end{definition}
In the sequel, we shall often use the same notation for functions
defined over items or pres, leaving to the reader the simple 
disambiguation task. Moreover, we use the notation , where  
is a boolean, with the following meaning:


\begin{definition}\ \label{def:Lp}
\begin{enumerate}
\item The language  associated with the item  is defined by the
following rules:

\item For a pointed regular expression  we define

\end{enumerate}
\end{definition}

\begin{example}
\label{ex:compact}

Indeed,

\end{example}
Let us incidentally observe that, as shown by the previous
example, pointed regular expressions can provide a more compact 
syntax for denoting languages than traditional regular expressions. 
This may have important applications to 
the investigation
of the descriptional complexity (succinctness) of regular languages
(see e.g. \cite{Gelade10, GruberH08, HolzerK09}). 




\begin{example}
If  contains no point (i.e. ) then 
\end{example}

\begin{lemma}
\label{lemma:epsilon}
If  is a pointed item then . 
Hence,  if and only if 
.
\end{lemma}
\begin{proof}
A trivial structural induction on .
\end{proof}

\subsection{Broadcasting points}
Intuitively, a regular expression  must be understood as a pointed
expression with a single point in front of it. Since however we only
allow points over symbols, we must broadcast this initial point
inside the expression, 
that essentially corresponds to the -closure operation on
automata. We use the notation  to denote such an operation.

The broadcasting operator is also required to lift the item constructors 
(choice, concatenation and Kleene's star) from items to pres: for example,
to concatenate a pre  
with another pre , we must first
broadcast the trailing point of the first expression inside  and then
pre-pend ; similarly for the star operation.
We could define first the broadcasting
function  and then the lifted constructors; however, 
both the definition and the theory of the 
broadcasting function are simplified by making it
co-recursive with the lifted constructors.

\begin{definition}\ \label{def:bullet}
\begin{enumerate}
\item The function  from pointed item to pres is defined as
follows:

\item The lifted constructors are defined as follows

\end{enumerate}
\end{definition}

\noindent 
The apparent complexity of the previous definition should not 
hide the extreme simplicity of the broadcasting operation: on a sum we
proceed in parallel; on a concatenation , we first work on
 and in case we reach its end we pursue broadcasting inside
; in case of  we broadcast the point inside  recalling
that we shall eventually have a trailing point. 

\begin{example}
Suppose to broadcast a point inside 

We start working in parallel on the first 
occurrence of  (where the point stops), and on  that
gets traversed. We have hence reached the end of  and
we must pursue broadcasting inside . Again, we work
in parallel on the two additive subterms  and ; the first
point is allowed to both enter the star, and to traverse it,
stopping in front of ; the second point just stops in front of
. No point reached that end of  hence no further 
propagation is possible.
In conclusion:

\end{example}

\begin{definition} The broadcasting function is extended to pres 
in the obvious way:

\end{definition}

\noindent
As we shall prove in Corollary \ref{nullable}, broadcasting an initial 
point may reach the end of an expression  if and only if  
is nullable.



\noindent



\noindent
The following theorem characterizes the broadcasting function and also
shows that the semantics of the lifted constructors on
pres is coherent with the corresponding constructors on items.

\begin{theorem}
\label{theo:broadcast}~
\begin{enumerate}
\item .
\item 
\item 
\item 
\end{enumerate}
\end{theorem}
We do first the proof of 2., followed by the simultaneous proof of 1. and 3.,
and we conclude with the proof of 4.
\begin{proof}[of 2.]
We need to prove .

\end{proof}
\begin{proof}[of 1. and 3.]
We prove 1. () by induction on the structure
of , assuming that 3. holds on terms structurally smaller than .
\begin{itemize}
\item .
\item .
\item .
\item .
\item Let . By induction hypothesis we know that 

Thus, by 2., we have

\item Let . By induction hypothesis we know that 

Thus, by 3. over the structurally smaller terms  and 

\item Let . By induction hypothesis we know that 

and in particular, since by Lemma \ref{lemma:epsilon} , 

Then,

\end{itemize}

\noindent
Having proved 1. for  assuming that 3. holds on terms structurally smaller
than , we now assume that 1. holds for  and  in order to
prove 3.:


We distinguish the two cases of the definition of :


\end{proof}
\begin{proof}[of 4.]
We need to prove
.
We distinguish the two cases of the definition of :

\end{proof}

\begin{corollary}
\label{corollary:Lpbullet}
For any regular expression , .
\end{corollary}

Another important corollary is that an initial point reaches 
the end of a (pointed) expression
 if and only if  is able to generate the empty
string.

\begin{corollary}
\label{nullable}
 if and only if
.
\end{corollary}
\begin{proof}
By theorem \ref{theo:broadcast} we know
that . So, if 
, since by Lemma \ref{lemma:epsilon} 
, it must be .
Conversely, if  then ; if
, this is possible only 
provided .
\end{proof}

To conclude this section, let us prove the idempotence
of the  function (it will only be used
in Section \ref{merging}, and can be skipped at a first reading). 
To this aim we need a technical lemma whose straightforward proof by
case analysis is omitted.



\begin{lemma}
~\vspace{-0.45cm}

\end{lemma}






\begin{theorem}\label{bullid}
 ~\quad
\end{theorem}
\begin{proof}
The proof is by induction on .
\begin{itemize}
\item 
\item 
\item 
\item 
\item If  is  then

\item If  is  then

\item If  is , let  and
let .
By induction hypothesis,

and thus . Finally

\end{itemize}
\end{proof}

\subsection{The move operation}
We now define the move operation, that corresponds to the 
advancement of the state in response to the processing of
an input character . The intuition is clear: we have to
look at points inside  preceding the given character ,
let the point traverse the character, and broadcast it. 
All other points must be removed.

\begin{definition}\label{move}\
\begin{enumerate}
\item The function  taking in input a pointed item 
, a character  and giving back a pointer regular
expression is defined as follow, by induction on the structure of
: 

\item The move function is extended to pres by just ignoring the trailing
point: 

\end{enumerate}
\end{definition}

\begin{example}
Let us consider the pre 

and the two moves w.r.t. the characters
 and . For , we have two possible positions (all other
points gets erased); the innermost point stops in front of the final ,
the other one broadcast inside  , so 

For , we have two positions too. The innermost point still
stops in front of the final , while the other point reaches the end
of  and must go back through  :

\end{example}

\begin{theorem} 
\label{theo:move}
For any pointed regular expression  and string
, 

\end{theorem}

\begin{proof}
The proof is by induction on the structure of . 
\begin{itemize}
\item if  is atomic, and  is not a pointed symbol, then
both  and  are empty, and hence both
sides are false for any ;
\item if  then 

and ; 
\item if  with  then 

and ; hence for any string , both sides 
are false; 
\item if 
by induction hypothesis
,
hence, 


\item suppose ,
by induction hypothesis
,
hence, 


\item suppose ,
by induction hypothesis
,
hence, 

\end{itemize}
\end{proof}

We extend the move operations to strings as usual.
\begin{definition}

\end{definition}

\begin{theorem} 
\label{theo:move*}
For any pointed regular expression  and all strings
, 

\end{theorem}
\begin{proof}
A trivial induction on the length of , using theorem \ref{theo:move}.
\end{proof}

\begin{corollary}
For any pointed regular expression  and any string
, 

\end{corollary}
\begin{proof}
By Theorems \ref{theo:move*} and Lemma \ref{lemma:epsilon}.
\end{proof}

\subsection{From regular expressions to DFAs}

\begin{definition}
To any regular expression  we may associate a DFA 
 
defined in the following way:
\begin{itemize}
\item  is the set of all possible pointed expressions having  as
carrier;
\item  is the alphabet of the regular expression
\item  is ;
\item  is the move operation of definition \ref{move};
\item  is the subset of pointed expressions  
with .
\end{itemize}
\end{definition}

\begin{theorem} 
\label{theo:main}

\end{theorem}
 \begin{proof}
By definition, 

for some . By the previous theorem, this is possible if an only if
, and by corollary \ref{corollary:Lpbullet}, 
.
\end{proof}


\begin{remark}\label{card}The fact that the set  of states of  
is finite is obvious: its cardinality is at most  where  is 
the number of symbols in . This is one of the advantages
of pointed regular expressions w.r.t. derivatives, whose finite
nature only holds after a suitable quotient, and is a relatively
complex property to prove (see~\cite{Brzozowski64}).
\end{remark} 

\noindent
The automaton  just defined may have many inaccessible states. We can
provide another algorithmic and direct construction that yields the same
automaton restricted to the accessible states only.

\begin{definition}\label{algorithmic1}
Let  be a regular expression and let  be .
Let also
 
 Since every  is a subset of the finite set of pointed regular expressions, there is an  such that .
We associate to  the DFA  where  and 
are defined as for the previous construction.
\end{definition}

\begin{figure}[htp]
\begin{center}
\includegraphics[width=.5\textwidth]{automaton.pdf}
\caption{DFA for \label{automaton}}
\end{center}
\end{figure}

In Figure \ref{automaton} we describe the DFA
associated with the regular expression .
The graphical description of the automaton is the traditional one,
with nodes for states and labelled arcs for transitions. 
Unreachable states are not shown.
Final states are emphasized by a double circle: since a state
 is final if and only if  is true, we
may just label nodes with the item (for instance, the pair of
states  and  only differ for the fact that  and  
are final, while  and  are not).  



\subsection{Admissible relations and minimization}
The automaton in Figure \ref{automaton} is minimal. This is
not always the case. For instance, for the expression 
 we obtain the automaton of Figure \ref{acUbc}, and 
it is easy to see that the two states corresponding to the
pres  and  are equivalent
(a way to prove it is to observe that they define the same
language). 

\begin{figure}[tp]
\begin{center}
\includegraphics[width=.5\textwidth]{acUbc.pdf}
\caption{DFA for \label{acUbc}}
\end{center}
\end{figure}



\noindent
The latter remark, motivates the following definition.

\begin{definition}
An equivalence relation  over pres having the same carrier is admissible when for all  and 
\begin{itemize}
\item if  then 
\item if  then for all a 
\end{itemize}
\end{definition}

\begin{definition}\label{nonalgorithmic2}
To any regular expression  and admissible equivalence relation over pres over
, we can directly associate the DFA
 where  is the  operation lifted to equivalence classes
thanks to the second admissibility condition.
\end{definition}

In place of working with equivalence classes, for formalization and implementation purposes it is simpler to work on representative of equivalence classes.
Instead of choosing a priori a representative of each equivalence class, we can slightly modify the algorithmic construction of definition~\ref{algorithmic1} so
that it dynamically identifies the representative of the equivalence classes.
It is sufficient to read each element of  as a representative of its
equivalence class and to change the test  so that the new
state  is compared to the representatives in  up to :

\begin{definition}\label{algorithmic2}
In definition~\ref{algorithmic1} change the definition of  as follows:
 
The transition function  is defined as  where
 and  is the unique state of  such that
.
\end{definition}
In an actual implementation, the transition function  is computed together
with the sets  at no additional cost.

\begin{theorem}
Replacing each state  of the automaton of definition~\ref{algorithmic2}
with , we obtain the restriction of the automaton of
definition~\ref{nonalgorithmic2} to the accessible states.
\end{theorem}

We still need to prove that quotienting over  does not change the
language recognized by the automaton.

\begin{theorem}

\end{theorem}
\begin{proof}
By theorem~\ref{theo:main}, it is sufficient to prove
 or, equivalently, that for all ,
. We show this to hold by proving
by induction over  that for all 


\noindent
Base case:


\noindent
Inductive step:
by condition (2) of admissibility, for all\\ ,
we have  and thus


\end{proof}

The set of admissible equivalence relations over  is a bounded lattice,
ordered by refinement, whose bottom element is syntactic identity and whose
top element is  iff . Moreover, if
 (the first relation is a strict refinement of the
second one), the number of states of  is strictly larger
than the number of states of .

\begin{theorem}
If  is the top element of the lattice, than  is the
minimal automaton that recognizes .
\end{theorem}
\begin{proof}
By the previous theorem,  recognizes  and has no
unreachable states. By absurd, let
 be another smaller automaton that recognizes
. Since the two automata are different, recognize the same languages and
have no unreachable states, there exists two words  such
 but
 where  and 
are any two representatives of their equivalence classes and thus . By definition of , . Without loss
of generality, let . We have
 and  because  recognizes , which is absurd since
 and  also recognizes .
\end{proof}

The previous theorem tells us that it is possible to associate to each state
of an automaton for  (and in particular to the minimal automaton) 
a pre  over  so that the language recognized by the automaton 
in the state  is , that provides a very suggestive labelling
of states. 



The characterization of the minimal automaton we just gave does not
seem to entail an original algorithmic construction, since does
not suggest any new effective way for computing . However,
similarly to what has been done for derivatives (where we have similar
problems), it is interesting to investigate
admissible relations that are easier to compute and tend 
to produce small automata in most practical cases. 
In particular, in the next section, we shall investigate one important
relation providing a common quotient between the automata built
with pres and with Brzozowski's derivatives.

\section{Read back}
Intuitively, a pointed regular expression corresponds to a set
of regular expressions. In this section we shall formally investigate
this ``read back'' function; this will allow us to establish a more
syntactic relation between traditional regular expressions 
and their pointed version, and to compare our technique for building 
a DFA with that based on derivatives.

In the following sections we shall frequently deal with {\em sets} of
regular expressions (to be understood additively), that we prefer to 
the treatment of regular expressions up to associativity, 
commutativity and idempotence of the sum (ACI) that is for instance typical
of the traditional theory of derivatives (this also clarifies that 
ACI-rewriting is only used at the top level). 

It is hence useful to extend some syntactic operations, and 
especially concatenation, to sets of regular expressions, with 
the usual distributive meaning: 
if  is a regular expression and  is a set of regular 
expressions, then 

We define  and  in a similar way. Moreover, every function
on regular expressions is implicitly lifted to sets of regular expressions by
taking its image. For example, 

\begin{definition}
We associate to each item  a set of regular expressions 
 defined by the
following rules:

 is extended to a pointed regular expression  as
follows

\end{definition}
Note that, for any item , no regular expression in  is nullable.

\begin{example}
Since

we have

\end{example}

The parallel between the syntactic read-back function  and the semantics
 of definition~\ref{def:Lp} is clear by inspection of the rules. Hence
the following lemma can be proved by a trivial induction over .

\begin{lemma}\label{techx}

\end{lemma}

\begin{corollary}
For any regular expression ,

\end{corollary}

The previous corollary states that  and  are semantically
inverse functions. Syntactically, they associate to each expression 
an interesting ``look-ahead'' normal form, constituted (up to associativity
of concatenation) by a set of expressions of the kind  
(plus  if  is nullable), where
 is a derivative of  w.r.t.  (although syntactically different
from Brzozowski's derivatives, defined in the next section).
 
This look-ahead normal form () has an interest in its own, and can be 
simply defined by structural induction over .

\begin{definition}

\end{definition}

\begin{remark}\label{not_nullable}
It is easy to prove that, for each , 
the set  is made, up to associativity of concatenation,
only of expressions of the form  or . In particular
no expression in  is nullable!
\end{remark}

\noindent
The previous remark motivates the following definition.

\begin{definition}

\end{definition}
The main properties of  are expressed by the following
two lemmas, whose simple proof is left to the reader.
\begin{lemma}\label{lemma:nf}

\end{lemma}


\begin{theorem}\label{techz}
 
\end{theorem}

\begin{theorem}
For any pointed regular expression ,

\end{theorem}
\begin{proof}
Let ; then 
iff , iff . Hence the goal reduces to prove
that . 
We proceed by induction on the structure of . 
\begin{itemize}
\item , 
and 

\item , 
and 
\item :  and

\item :  and

\item : let ;
then
 
\item .
Let . If  then
; moreover we
know that  is not nullable. We have then:
 
If  then
; moreover we
know that  is nullable.
 
\item . Let ;
then ;
 
\end{itemize}
\end{proof}
\begin{corollary}\label{R-bullet}
For all regular expression ,

\end{corollary}

\noindent
To conclude this section, in analogy with what we did for the 
semantic function in Theorem~\ref{theo:broadcast}, we express the 
behaviour of  in terms of the {\em lifted} algebraic 
constructors. This will be useful in Theorem \ref{techy}.

\begin{lemma}\ 
\begin{enumerate}
\item 
\item 
\item 
\item 
\item 
\end{enumerate}
\end{lemma}
\begin{proof}
Let : 
\begin{enumerate}
\item 

\item 

\item let 

\item 

\item let ; then
, and . 

\end{enumerate}
\end{proof}

\subsection{Relation with Brzozowski's Derivatives}
\label{relation}
We are now ready to formally investigate the relation
between pointed expressions and Brzozowski's derivatives.
As we shall see, they give rise to quite different constructions
and the relation is less obvious than expected.\\
Let's start with recalling the formal definition.
\begin{definition}

\end{definition}
\begin{definition}

\end{definition}

In general, given a regular expression  over the alphabet , 
the set 
of all its derivatives {\em is not} finite. In order to get a finite
set we must suitably quotient derivatives according to algebraic 
equalities between regular expressions. The choice of different 
set of equations gives rise
to different quotients, and hence to different automata. Since
for finiteness it is enough to consider associativity,
commutativity and idempotence of the sum (ACI), the traditional
theory of Brzozowski's derivatives is defined according to
these laws (although this is probably not the best choice from 
a practical point of view).

As a practical example, in Figure \ref{acUbc1} we describe 
the automata obtained using derivatives relative to the 
expression  (compare it
with the automata of Figure \ref{acUbc}). Also, note that the
vertically aligned states are equivalent.

\begin{figure}[htp]
\begin{center}
\includegraphics[width=.5\textwidth]{brzozowsky.pdf}
\caption{Automaton with Brzozowski's derivatives\label{acUbc1}}
\end{center}
\end{figure}

\noindent
Let us remark, first of all, the heavy use of . For instance 

while
 
and they can be assimilated only up to commutativity of the sum. 
As another example,

and the latter expression can be reduce to
 
only using associativity and idempotence of the sum.

The second important remark is that, in general, it is not true that we may 
obtain the pre-automata by quotienting the derivative one (nor the other way
round). For instance, from the initial state, the two arcs labelled  and
 lead to a single state in the automata of Figure~\ref{acUbc1}, but in different
states in the automata of Figure~\ref{acUbc}. 

A natural question is hence to
understand if there exists a common {\em algebraic} quotient between the two 
constructions (not exploiting minimization). 

As we shall see, this can be achieved by identifying states with a same
readback in the case of pres, and states with similar look-ahead normal
form in the case of derivatives.

For instance, in the case of the two automata of Figures~\ref{acUbc} and
\ref{acUbc1}, we would obtain the common quotient of Figure~\ref{quotient}.

\begin{figure}[htp]
\begin{center}
\includegraphics[width=.5\textwidth]{quotient.pdf}
\caption{A quotient of the two automatons\label{quotient}}
\end{center}
\end{figure}

The general picture is described by the commuting diagram
of Figure~\ref{commute}, whose proof will be the object of the 
next section (in Figure~\ref{commute},  obviously stands for
the string ).

\begin{figure}[htp]
\begin{center}
\includegraphics[width=.5\textwidth]{commute.pdf}
\caption{Pointed regular expressions and Brzozowski's derivatives\label{commute}}
\end{center}
\end{figure}

\subsection{Formal proof of the commuting diagram in Figure \ref{commute}}

Part of the diagram has been already proved: the leftmost triangle, used to
relate the initial state of the two automata, is
Corollary~\ref{R-bullet}; the two triangles at the right, used to
relate the final states, just states the trivial properties that 
 iff and only if  (since
no expression in  is nullable), and
 if and only if  is nullable (see
Remark~\ref{not_nullable}).

We start proving the upper part. We prove it for a pointed item 
and leave the obvious generalization to a pointed expression to the reader
(the move operation does not depend from the presence of a trailing
point, and similarly the derivative of  is empty).

\begin{theorem}\label{techy}For any pointed item ,
  
\end{theorem}
\begin{proof}
By induction on the structure of :
\begin{itemize}
\item the cases , ,  and  are trivial
\item if  then 
and  . On the other side, 
.
\item if , then

\item let , and let us suppose that  and thus 
and . Then

If  then
. In particular
 and .
We have then:

\item let , and let us suppose that . Thus .
Then

If  then
.
In particular
 and  since
.
We have then:

\end{itemize}
\end{proof}




We pass now to prove the lower part of the diagram in Figure~\ref{commute},
namely that for any regular expression , 
 
Since however, 
 (the derivative of 
is empty), this is equivalent to prove the following
result.





\begin{theorem}\label{techw}

\end{theorem}
\begin{proof}
The proof is by induction on .
Any induction hypothesis over a regular
expression  can be strengthened to
 for all  since

(observe that  since the languages denoted by  and  are equal).\\
We must consider the following cases.
\begin{itemize}
\item If  is ,  or a symbol  different from
 then both sides of the equation are empty
\item If  is ,
 
\item If  is ,

\item If  is  and ,

\item If  is  and ,

\item If  is ,

\end{itemize}
\end{proof}

\begin{lemma}

\end{lemma}
\begin{proof}
We proceed by induction over :
\begin{itemize}
\item 

\item

\item 
\item 
\item 
\item 
\item 
\end{itemize}
\end{proof}

We are now ready to prove the commutation of the outermost diagram.

\begin{theorem}For any pointed item ,
  
\end{theorem}
\begin{proof}
The proof is by induction on the structure of .
In the base case, . In the inductive step, by Theorem~\ref{techw},

\end{proof}
\begin{corollary}\label{corollary1}
For any regular expression ,

\end{corollary}
\begin{proof}

\end{proof}

Another important consequence of Lemmas \ref{techy} and \ref{techw}
is that  and  are admissible relations (respectively, over
pres and over derivatives).

\begin{theorem}\label{admissible1}
 (the kernel of ) is an admissible
equivalence relation over pres.
\end{theorem}
\begin{proof}
By Lemma~\ref{techx} we derive that for all pres ,
if  then .
We also need to prove that for all pres  and all symbol ,
if  then
. By Theorem~\ref{techy}

\end{proof}

\begin{theorem}\label{admissible2}
 is an admissible equivalence relation over regular
expressions
\end{theorem}
\begin{proof}
By Lemma~\ref{techz} we derive that for all regular expressions ,
if  then .
We also need to prove that for all regular expressions 
and all symbol , if  then
.\\ By Theorem~\ref{techw}

\end{proof}

\begin{theorem}\label{thesame}~\\
For each regular expression , let

be the automaton
for  built according to Definition~\ref{algorithmic1} and let
 the automaton for
 obtained with derivatives. Let  and  be the kernels of 
and  respectively. Then
.
\end{theorem}
\begin{proof}
The results holds by commutation of Figure~\ref{commute}, that is granted
by the previous results, in particular by Corollary~\ref{corollary1},
Theorem~\ref{admissible1}, Theorem~\ref{admissible2}, and the commutation
of the triangles relative to the initial and final states.
\end{proof}

Theorem~\ref{thesame} relates our finite automata with the infinite states ones
obtained via Brzozowski's derivatives before quotienting the automata states
by means of  to make them finite. The following easy lemma shows that
 is an equivalence relation finer than  and thus
Theorem~\ref{thesame} also holds for the standard finite Brzozowski's automata
since we can quotient with  first.
\begin{lemma}
Let  and  be regular expressions.
If  then .
\end{lemma}

\section{Merging}\label{merging}
By Theorem~\ref{theo:broadcast}, .
A more syntactic way to look at this result is to observe that 
 can be obtained by ``merging'' together the points in  and 
, and that the language defined by merging two pointed
expressions  and  is just the union of the two languages 
 and . The merging operation, that we shall denote
with a , does also provide the relation between deterministic 
and nondeterministic automata where, as in Watson \cite{Watson01, Watson02}, 
we may label states with expressions with a single point (for lack of space,
we shall not explicitly address the latter issue in this paper, that 
is however a simple consequence of Theorem~\ref{theo:move_dag}).
Finally, the merging operation will allow us to explain why the
technique of pointed expressions cannot be (naively) generalized 
to intersection and complement (see Section~\ref{sec:intersection}).



\begin{definition}
Let  and  be two items on the same carrier . The merge of 
and  is defined by the following rules by recursion over the structure of
:

The definition is extended to pres as follows:

\end{definition}

\begin{theorem} is commutative, associative and idempotent
\end{theorem}
\begin{proof}
Trivial by induction over the structure of the carrier of the arguments.
\end{proof}

\begin{theorem}

\end{theorem}
\begin{proof}
Trivial by induction on the common carrier of the items of  and .
\end{proof}

All the constructions we presented so far commute with the merge operation.
Since merging essentially corresponds to the subset construction over automata,
the following theorems constitute the proof of correctness of the subset
construction.

\begin{theorem}

\end{theorem}
\begin{proof}
Trivial by expansion of definitions.
\end{proof}

\begin{theorem}~

\begin{enumerate}
\item for  and  items on the same carrier,

\item for  and  pres on the same carrier,

\item

\end{enumerate}
\begin{corollary}

\end{corollary}
\begin{proof}[of the corollary]
The corollary is a simple consequence of commutativity of  and
idempotence of :


\end{proof}
\end{theorem}
\begin{proof}[of 1.]
We first prove  by
induction over the structure of the common carrier of  and , assuming
that 3. holds on terms whose carrier is structurally smaller than .

\begin{itemize}
\item If  is , , ,  then trivial
\item If  is  and  is :

\item If  is  and  is  then, using 3.
on items whose carrier is structurally smaller than ,

\item If  is  and  is ,
let  and
. By induction hypothesis,

Then\\

\end{itemize}
\end{proof}
\begin{proof}[Of 2.]
Let .
By definition of , we have

For all  and , let b = \false\\
Thus for all , letting
, the following holds:

Let . By property 1. we have: 

Thus

\end{proof}

\begin{theorem}

\end{theorem}
\begin{proof}
Let  and .
Thus


Let define ,  and  by cases on  and  with
the property that :
\begin{itemize}
 \item If  then let  and
  . Obviously .
 \item If  and  then
   let , let
    and let . Hence .
 \item The case  and  is handled dually to the
   previous one.
 \item If  and  then
   let 
   and let . Hence .
\end{itemize}

In all cases,

\end{proof}

\begin{theorem}
\label{theo:move_dag}

\end{theorem}
\begin{proof}
The proof is by induction on the structure of .
\begin{itemize}
\item the cases ,  and  are trivial by
      computation
\item the case  has four sub-cases: if  and  are both ,
      then ;
      otherwise
      at least one in  or  is  and
      
\item if  is  then

\item if  is  then

\item if  is  then

      
\end{itemize}
\end{proof}

\subsection{Intersection and complement}
\label{sec:intersection}
Pointed expressions cannot be generalized in a trivial way to
the operations of intersection and complement. Suppose to 
extend the definition of the language in the obvious way, letting
 and 
. The problem is that merging
is no longer additive, and Theorem~\ref{theo:broadcast} does not
hold any more.
For instance, consider the two expressions  and
. Clearly , but
.
To better understand the problem, 
let , and let us 
consider the result of . 
Since , we should
broadcast a new point inside , 
hence ,
that is obviously wrong.

The problems in extending the technique to intersection and complement are
not due to some easily avoidable deficiency of the approach but 
have a deep theoretical reason: indeed, even if these operators do not increase
the expressive power of regular expressions they can have a drastic
impact on succinctness, making them much harder to handle.
For instance it is well known that expressions with
complements can provide descriptions of certain languages which are
non-elementary more compact than standard regular expression \cite{MeyerS72}.
Gelade \cite{Gelade10} has recently proved that for any natural 
number  there exists a regular expression with intersection
of size  such that any DFA accepting its language has
a double-exponential size, i.e. it contains at least  states
(see also \cite{GruberH08}).
Hence, marking positions with points is not enough, just because we 
would not have enough states. 

Since the problem is due to a loss of information
during merging, we are currently investigating the possibility
to exploit {\em colored} points. An important goal of this
approach would be to provide simple, completely
syntactic explanations for space bounds of different classes
of languages.

\section{Conclusions}
We introduced in this paper the notion of pointed regular
expression, investigated its main properties, and its 
relation with Brzozowski's derivatives. 
Points are used to mark the positions inside the regular
expression which have been reached after reading some prefix of
the input string, and where the processing
of the remaining string should start. In particular,
each pointed expression has a clear semantics. Since
each pointed expression for  represents a state of 
the {\em deterministic} automaton associated
with , this means we may associate a semantics to each
state in terms of the specification  
and not of the behaviour of the automaton. 
This allows a {\em direct}, {\em intuitive} and 
{\em easily verifiable} construction of the deterministic 
automaton for . 

A major advantage of pointed expressions 
is from the didactical point of view. Relying on 
an electronic device, it is a real pleasure to see
points moving inside the regular expression in response to
an input symbol. Students immediately grasp the idea, and 
are able to manually build the automata, and to understand the
meaning of its states, after a single lesson. Moreover, if you 
have a really short time, you can altogether skip the notion of 
nondeterministic automata.

Regular expression received a renewed interest in recent 
years, mostly due to their use in XML-languages. 
Pointed expressions seem to open a huge range of novel 
perspectives and original approaches in the field, starting
from the {\em challenging} generalization of the approach to
different operators such as counting, intersection, 
and interleaving (e.g. exploiting colors for points, 
see Section \ref{sec:intersection}). A large amount
of research has been recently devoted to the so called
succinteness problem, namely the investigation
of the descriptional complexity of regular languages
(see e.g. \cite{Gelade10, GruberH08, HolzerK09}). Since,
as observed in Example\ref{ex:compact}, pointed expression
can provide a more compact description for regular languages
than traditional regular expression, it looks interesting to better 
investigated this issue (that seems to be related to the so called
star-height \cite{eggan63} of the language).




It could also be worth to investigate variants of the
notion of pointed expression, allowing different
positioning of points inside the expressions. 
Merging must be better investigated, and the whole equational
theory of pointed expressions, both with different and
(especially) fixed carriers must be entirely developed.

As explained in the introduction, the notion of pointed 
expression was suggested by an attempt of formalizing the theory
of regular languages by means of an interactive prover.
This testify the relevance of the choice of good data structures 
not just for the design of algorithms but also for the formal 
investigation of a given field, and is a 
nice example of the kind of interesting feedback one may expect 
by the interplay with automated devices for proof development. 




\bibliographystyle{ieeetr}
\bibliography{../BIBTEX/helm}

\end{document}
