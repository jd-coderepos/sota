\documentclass{article}


\usepackage{iclr2022_conference,times}
\iclrfinalcopy

\usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}    \usepackage{hyperref}       \usepackage{url}            \usepackage{booktabs}       \usepackage{amsfonts}       \usepackage{nicefrac}       \usepackage{microtype}      \usepackage{xcolor}         





\usepackage{amsmath,amsfonts,bm}

\newcommand{\figleft}{{\em (Left)}}
\newcommand{\figcenter}{{\em (Center)}}
\newcommand{\figright}{{\em (Right)}}
\newcommand{\figtop}{{\em (Top)}}
\newcommand{\figbottom}{{\em (Bottom)}}
\newcommand{\captiona}{{\em (a)}}
\newcommand{\captionb}{{\em (b)}}
\newcommand{\captionc}{{\em (c)}}
\newcommand{\captiond}{{\em (d)}}

\newcommand{\newterm}[1]{{\bf #1}}


\def\figref#1{figure~\ref{#1}}
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
\def\secref#1{section~\ref{#1}}
\def\Secref#1{Section~\ref{#1}}
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
\def\eqref#1{(\ref{#1})}
\def\Eqref#1{Equation~\ref{#1}}
\def\plaineqref#1{\ref{#1}}
\def\chapref#1{chapter~\ref{#1}}
\def\Chapref#1{Chapter~\ref{#1}}
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
\def\algref#1{algorithm~\ref{#1}}
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
\def\partref#1{part~\ref{#1}}
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}

\def\eps{{\epsilon}}


\def\reta{{\textnormal{$\eta$}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvX{{\mathbf{X}}}
\def\rvy{{\mathbf{y}}}
\def\rvY{{\mathbf{Y}}}
\def\rvz{{\mathbf{z}}}
\def\rvZ{{\mathbf{Z}}}

\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

\newcommand{\pdata}{p_{\rm{data}}}
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}

\newcommand{\laplace}{\mathrm{Laplace}} 

\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Proj}{\mathrm{Proj}}
\newcommand{\Alg}{\mathrm{Alg}}
\newcommand{\vectorize}{\mathrm{vec}}

\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}

\newcommand{\parents}{Pa} 

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Tr}{Tr}
\let\ab\allowbreak
 
\def\comma{{ \text{ ,} }}
\def\period{{ \text{ .} }}

\def\intT{{ \int_{t_0}^{t_1} }}
\def\rintT{{ \int^{t_0}_{t_1} }}
\def\wt{{ \mathbf{W}_t }}
\def\ws{{ \mathbf{W}_s }}
\def\dwt{{ \mathrm{d} \wt }}
\def\dws{{ \mathrm{d} \ws }}


\def\hvx{{ \bar{\vx} }}
\def\hvu{{ \bar{\vu} }}
\def\hrvx{{ \bar{\rvx} }}
\def\hrvu{{ \bar{\rvu} }}
\def\hrvxt{{ \bar{\rvx}_t }}
\def\hrvut{{ \bar{\rvu}_t }}


\def\hWt{{ \overline{\mathbf{W}}_t }}
\def\drvx{{\delta \rvx}}
\def\drvu{{\delta \rvu}}
\def\drvxt{{\delta \rvx_t}}
\def\drvut{{\delta \rvu_t}}
\def\Lx{{\ell_{\hvx} }}
\def\Lu{{\ell_{\hvu} }}
\def\Lxx{{{\ell}_{\hvx \hvx}}}
\def\Luu{{{\ell}_{\hvu \hvu}}}
\def\Lux{{{\ell}_{\hvu \hvx}}}
\def\Lxu{{{\ell}_{\hvx \hvu}}}
\def\Vx{{V_{\rvx} }}
\def\Vxx{{V_{\rvx\rvx} }}


\def\hS{{\bar{\sigma}}}
\def\hSu{{\bar{\sigma}_\rvu}}
\def\hSx{{\bar{\sigma}_\rvx}}
\def\hST{{\bar{\sigma}^\T}}
\def\hSuT{{\bar{\sigma}^\T_\rvu}}
\def\hSxT{{\bar{\sigma}^\T_\rvx}}
\def\hF{{\bar{F}}}
\def\hFu{{\bar{F}_\rvu}}
\def\hFx{{\bar{F}_\rvx}}
\def\Fu{{{F}_\hvu}}
\def\Fx{{{F}_\hvx}}
\def\FxT{{{F}_\hvx^\T}}
\def\FuT{{{F}_\hvu^\T}}

\def\Gu{{{G}_\rvu}}
\def\Gx{{{G}_\rvx}}
\def\hG{{\bar{G}}}
\def\hGu{{\bar{G}_\rvu}}
\def\hGx{{\bar{G}_\rvx}}
\def\hGT{{\bar{G}^\T}}
\def\hGuT{{\bar{G}^\T_\rvu}}
\def\hGxT{{\bar{G}^\T_\rvx}}

\def\Su{{{\sigma}_\rvu}}
\def\Sx{{{\sigma}_\rvx}}
\def\SxT{{{\sigma}_\rvx^\T}}
\def\SuT{{{\sigma}_\rvu^\T}}

\def\QxT{{Q^\T_{\hvx}}}
\def\QuT{{Q^\T_{\hvu}}}
\def\Qx{{Q_{\hvx}}}
\def\Qu{{Q_{\hvu}}}
\def\Qxu{{Q_{\hvx \hvu}}}
\def\Qxx{{Q_{\hvx \hvx}}}
\def\Quu{{Q_{\hvu \hvu}}}
\def\Qux{{Q_{\hvu \hvx}}}
\def\srd{{\circ\rd}}
\newcommand{\sfracdiff}[2]{\frac{\srd #1}{\rd  #2}}
\def\htheta{{\hat{\theta}}}


\newcommand{\norm}[1]{\lVert#1\rVert}

\DeclareMathOperator{\Linear}{Linear}
\DeclareMathOperator{\ReLU}{ReLU}
\DeclareMathOperator{\Tanh}{Tanh}
\DeclareMathOperator{\Sigmoid}{Sigmoid}
\DeclareMathOperator{\CurvApprox}{CurvApprox}
\DeclareMathOperator{\EKFACDDP}{EKFAC-DDP}
\DeclareMathOperator{\KFACDDP}{KFAC-DDP}
\DeclareMathOperator{\diag}{diag}

\def\ttranspose{{t \text{ } \transpose}}
\def\vxr{{\vx_r}}

\def\kt{{\vk}}
\def\Kt{{\mK}}
\def\Gt{{\mathbf{G}_t}}

\def\KtT{{\mathbf{K}_t^\transpose}}
\def\GtT{{\mathbf{G}_t^\transpose}}


\def\It{{\mathbf{I}_t}}
\def\Lt{{\mathbf{L}_t}}
\def\Ht{{\mathbf{H}_t}}

\def\kut{{\tilde{\mathbf{k}}_t}}
\def\Kut{{\tilde{\mathbf{K}}_t}}
\def\Gut{{\tilde{\mathbf{G}}_t}}

\def\Ivt{{\tilde{\mathbf{I}}_t}}
\def\Lvt{{\tilde{\mathbf{L}}_t}}
\def\Hvt{{\tilde{\mathbf{H}}_t}}

\def\QuuC{{\tilde{Q}_{\vu \vu}}}
\def\QvvC{{\tilde{Q}_{\vv \vv}}}
\def\QuutC{{\tilde{Q}^t_{\vu \vu}}}
\def\QvvtC{{\tilde{Q}^t_{\vv \vv}}}
\def\QuuCInv{{\tilde{Q}^{-1}_{\vu \vu}}}
\def\QvvCInv{{\tilde{Q}^{-1}_{\vv \vv}}}
\def\QA{{Q_{\vu \vx_r}}}
\def\QB{{Q_{\vv \vx}}}
\def\QAt{{Q^t_{\vu \vx_r}}}
\def\QBt{{Q^t_{\vv \vx}}}

\def\Axx{{\E[\vx_{\vu}\vx_{\vu}^\transpose]}}
\def\Axy{{\E[\vx_{\vu}\vx_{\vv}^\transpose]}}
\def\Ayy{{\E[\vx_{\vv}\vx_{\vv}^\transpose]}}
\def\Ayx{{\E[\vx_{\vv}\vx_{\vu}^\transpose]}}
\def\Bxx{{\E[\vg_{\vu}\vg_{\vu}^\transpose]}}
\def\Bxy{{\E[\vg_{\vu}\vg_{\vv}^\transpose]}}
\def\Byy{{\E[\vg_{\vv}\vg_{\vv}^\transpose]}}
\def\Byx{{\E[\vg_{\vv}\vg_{\vu}^\transpose]}}

\def\Auu{{A_{\vu\vu}}}
\def\Auv{{A_{\vu\vv}}}
\def\Avu{{A_{\vv\vu}}}
\def\Avv{{A_{\vv\vv}}}
\def\Buu{{B_{\vu\vu}}}
\def\Buv{{B_{\vu\vv}}}
\def\Bvu{{B_{\vv\vu}}}
\def\Bvv{{B_{\vv\vv}}}
\def\AuvT{{A^\transpose_{\vu\vv}}}
\def\BuvT{{B^\transpose_{\vu\vv}}}
\def\AvuT{{A^\transpose_{\vv\vu}}}
\def\BvuT{{B^\transpose_{\vv\vu}}}
\def\AuuInv{{A^{-1}_{\vu\vu}}}
\def\AvvInv{{A^{-1}_{\vv\vv}}}
\def\BuuInv{{B^{-1}_{\vu\vu}}}
\def\BvvInv{{B^{-1}_{\vv\vv}}}
\def\AuuCInv{{\tilde{A}^{-1}_{\vu\vu}}}
\def\BuuCInv{{\tilde{B}^{-1}_{\vu\vu}}}
\def\AvvCInv{{\tilde{A}^{-1}_{\vv\vv}}}
\def\BvvCInv{{\tilde{B}^{-1}_{\vv\vv}}}
\def\AvvInvT{{A^{-\transpose}_{\vv\vv}}}
\def\AuuCInvT{{\tilde{A}^{-\transpose}_{\vu\vu}}}

\def\VxN{{\mathbf{V}_\mX^T}}
\def\VxxN{{\mathbf{V}_{\mX\mX}^T}}

\def\VX{{\mathbf{V}_{\mX}}}
\def\VXX{{\mathbf{V}_{\mX\mX}}}

\def\QQXt{{\mathbf{Q}^t_\mX}}
\def\QQut{{\mathbf{Q}^t_\vu}}
\def\QQXXt{{\mathbf{Q}^t_{\mX\mX}}}
\def\QQuut{{\mathbf{Q}^t_{\vu\vu}}}
\def\QQuXt{{\mathbf{Q}^t_{\vu\mX}}}
\def\QQuuInvt{{[\mathbf{Q}^{t}_{\vu\vu}]^{-1}}}
\def\VXt{{\mathbf{V}^t_{\mX}}}
\def\VXXt{{\mathbf{V}^t_{\mX\mX}}}


\def\xxi{{\vx_t^{(i)}}}

\def\dvx{{\delta\vx}}
\def\dvu{{\delta\vu}}
\def\dvv{{\delta\vv}}
\def\vxTraj{{\bar{\vx}}}
\def\vuTraj{{\bar{\vu}}}

\def\Inv{{-1}}

\def\ConvT{{\text{ } \hat{*} \text{ }}}
\def\eqConv{{\text{ }\text{ } \stackrel{\mathclap{\tiny\mbox{conv}}}{=}\text{ }\text{ } }}

\def\Vh{{V_{\vh}}}
\def\Vht{{V^{t}_{\vh}}}
\def\Vhht{{V^{t}_{\vh\vh}}}



\def\fx{{{f}_{\vx}}}
\def\fu{{{f}_{\vu}}}
\def\fxt{{{f}^t_{\vx}}}
\def\fut{{{f}^t_{\vu}}}
\def\fuT{{{f}_{\vu}^\transpose}}
\def\fxT{{{f}_{\vx}^\transpose}}
\def\futT{{{{f}^t_{\vu}}^\transpose}}
\def\fxtT{{{{f}^t_{\vx}}^\transpose}}
\def\fxx{{{f}_{\vx \vx}}}
\def\fuu{{{f}_{\vu \vu}}}
\def\fux{{{f}_{\vu \vx}}}
\def\fxu{{{f}_{\vx \vu}}}
\def\fxxt{{{f}^t_{\vx \vx}}}
\def\fuut{{{f}^t_{\vu \vu}}}
\def\fuxt{{{f}^t_{\vu \vx}}}
\def\fxut{{{f}^t_{\vx \vu}}}

\def\gutT{{{g}^{t \text{ }\transpose}_{\vu}}}
\def\gxtT{{{g}^{t \text{ }\transpose}_{\vx}}}
\def\gut{{{g}^{t}_{\vu}}}
\def\gxt{{{g}^{t}_{\vx}}}
\def\sht{{{\sigma}^{t}_{\vh}}}
\def\shtT{{{\sigma}^{t \text{ }\transpose}_{\vh}}}

\def\lxt{{{\ell}^t_{\vx}}}
\def\lut{{{\ell}^t_{\vu}}}
\def\lxxt{{{\ell}^t_{\vx \vx}}}
\def\luut{{{\ell}^t_{\vu \vu}}}
\def\luxt{{{\ell}^t_{\vu \vx}}}
\def\lxut{{{\ell}^t_{\vx \vu}}}


\def\lx{{{\ell}_{\vx}}}
\def\lu{{{\ell}_{\vu}}}
\def\lxx{{{\ell}_{\vx \vx}}}
\def\luu{{{\ell}_{\vu \vu}}}
\def\lux{{{\ell}_{\vu \vx}}}
\def\lxu{{{\ell}_{\vx \vu}}}

\def\gx{{{g}_{\vx}}}
\def\gu{{{g}_{\vu}}}
\def\gxx{{{g}_{\vx \vx}}}
\def\guu{{{g}_{\vu \vu}}}
\def\gux{{{g}_{\vu \vx}}}
\def\gxu{{{g}_{\vx \vu}}}

\def\gxxt{{{g}^t_{\vx \vx}}}
\def\guut{{{g}^t_{\vu \vu}}}
\def\guxt{{{g}^t_{\vu \vx}}}
\def\gxut{{{g}^t_{\vx \vu}}}


\def\Dxu{{\nabla_{\vu \vx}}}
\def\llxu{{{\ell}(\vx^{(i)},\vu)}}
\def\ffxu{{{f}(\vx^{(i)},\vu)}}



\def\VH{{\mathbf{V}^t_{\mH}}}
\def\VhN{{\mathbf{V}_\mH^T}}
\def\VhhN{{\mathbf{V}_{\mH\mH}^T}}
\def\VHNxt{{\mathbf{V}^\prime_{\mH^\prime}}}
\def\VHHNxt{{\mathbf{V}^t_{\mH\mH}}}


\def\QQX{{\mathbf{Q}_\mX^t}}
\def\QQu{{\mathbf{Q}_\vu^t}}
\def\QQXX{{\mathbf{Q}^t_{\mX\mX}}}
\def\QQuu{{\mathbf{Q}^t_{\vu\vu}}}
\def\QQuX{{\mathbf{Q}^t_{\vu\mX}}}
\def\QQuuInv{{\mathbf{Q}^{-1}_{\vu\vu}}}
\def\QQuuInvApprox{{\mathbf{\widetilde{Q}}^{-1}_{\vu\vu}}}
\def\QQuXT{{{\mathbf{Q}^{t\transpose}_{\vu\mX}}}}
\def\VXNxt{{\mathbf{V}^\prime_{\mX^\prime}}}
\def\VXXNxt{{\mathbf{V}^\prime_{\mX^\prime\mX^\prime}}}

\def\QQXprevT{{\mathbf{Q}_\mX^{T-1}}}
\def\QQuprevT{{\mathbf{Q}_\vu^{T-1}}}
\def\QQXXprevT{{\mathbf{Q}^{T-1}_{\mX\mX}}}
\def\QQuuprevT{{\mathbf{Q}^{T-1}_{\vu\vu}}}
\def\QQuXprevT{{\mathbf{Q}^{T-1}_{\vu\mX}}}

\def\VX{{\mathbf{V}_{\mX}}}
\def\VXX{{\mathbf{V}_{\mX\mX}}}

\def\QQXt{{\mathbf{Q}^t_\mX}}
\def\QQut{{\mathbf{Q}^t_\vu}}
\def\QQXXt{{\mathbf{Q}^t_{\mX\mX}}}
\def\QQuut{{\mathbf{Q}^t_{\vu\vu}}}
\def\QQuXt{{\mathbf{Q}^t_{\vu\mX}}}
\def\QQuuInvt{{(\mathbf{Q}^{t}_{\vu\vu})^{-1}}}
\def\VXt{{\mathbf{V}^t_{\mX}}}
\def\VXXt{{\mathbf{V}^t_{\mX\mX}}}

\def\idxFu{{(B_{n_{t^\prime}}^{(i)},:)}}
\def\idxFuu{{(B_{n_{t^\prime}}^{(i)},:,:)}}
\def\idxFx{{(B_{n_{t^\prime}}^{(i)},B_{n_{t}}^{(j)})}}
\def\idxFux{{(B_{n_{t^\prime}}^{(i)},:,B_{n_{t}}^{(j)})}}
\def\idxFxx{{(B_{n_{t^\prime}}^{(i)},B_{n_{t}}^{(j)},B_{n_{t}}^{(k)})}}


\def\cspace{{\mathbb{R}^{m}}}
\def\Cspace{{\mathbb{R}^{\bar{m}}}}
\def\Xspace{{\mathbb{R}^{n}}}
\def\xyspace{{\mathbb{R}^{n+d}}}
\def\yspace{{\mathbb{R}^{d}}}
\def\expdnn{{\mathbb{E}_{\substack{ (\rvx_t, \rvy) \sim \mu_t \\ \text{subject to (\ref{eq:fc-dnn-dynamics})}}}}}

\def\transpose{{\mathsf{T}}}


\def\gradsampleeq{{
    \nabla_\vtheta l ( f ( \rvx^{(i)}, \vtheta ), \rvy^{(i)} )
}}
\def\gradsample{{ g^{i}(\vtheta) }}
\def\gradmb{{ g^{mb}(\vtheta) }}
\def\gradfull{{ g^{}(\vtheta) }}
\def\gradmbt{{   g^{mb}(\vtheta_{t}) }}
\def\gradfullt{{ g^{}(\vtheta_{t}) }}
\def\diffusionmatrixx{{ \mathbf{\Sigma}_{\mathcal{D}} }}
\def\diffusionmatrix{{ \mathbf{\Sigma}_{\mathcal{D}}(\vtheta) }}
\def\diffusionmatrixt{{ \mathbf{\Sigma}_{\mathcal{D}}(\vtheta_{t}) }}
\def\diffusionmatrixthaft{{ \mathbf{\Sigma}^{\frac{1}{2}}_{\mathcal{D}}(\vtheta_{t}) }}
\def\diffusionmatrixthaftt{{ \mathbf{\Sigma}^{\frac{1}{2}}_{\mathcal{D}} }}
\def\diffusionmatrixthafttt{{ \tilde{\mathbf{\Sigma}}^{\frac{1}{2}}_{\mathcal{D}} }}
\def\diffusionmatrixttt{{ \tilde{\mathbf{\Sigma}}_{\mathcal{D}} }}
\def\diffusionmatrixbatch{{ \tilde{\mathbf{\Sigma}}_{\mathcal{B}} }}
\def\absB{{ \mid \mathcal{B} \mid }}
\def\absD{{ \mid \mathcal{D} \mid }}
\def\drift{{ b(\vtheta_{t}) }}
\def\diffusion{{ \sigma(\vtheta_{t}) }}
\def\dt{{ \mathrm{d} t }}
\def\ds{{ \mathrm{d} s }}

\def\dLat{{ \mathrm{d} L_t^{\alpha} }}
\def\tt{{ \vtheta_{t} }}

\def\pss{{ \rho^{\mathrm{ss}} }}
\def\psss{{ \rho^{\mathrm{ss}}(\vtheta) }}

\def\Dk{{ \mathrm{D}^k }}
\def\gmbupdate{{ \vtheta^{\prime} - \eta g^{mb}(\vtheta^{\prime}) }}
\def\gmbupdatee{{ \vtheta - \eta g^{mb}(\vtheta) }}
\def\deltaa{{ \delta\left\{ \vtheta - \left[\gmbupdate\right] \right\} }}
\def\thprime{{ \vtheta^{\prime} }}
\def\dthprime{{ \mathrm{d} \thprime }}
\def\dth{{ \mathrm{d} \vtheta }}
\def\expB{{   \mathbb{E}_{\mathcal{B}} }}
\def\expPss{{ \mathbb{E}_{\pss} }}
\def\smallint{ \int}
\def\smallsum{\begingroup\textstyle \sum \endgroup}

\def\expBof#1{ \expB \left[ {#1} \right]}
\def\expPssof#1{ \expPss \left[ {#1} \right]}
\def\Phigmd{{ \Phi \left(\gmbupdatee\right) }}

\def\itoarg{{\left( X_t, t \right) }}



\def\thetap{{ \vtheta^{\prime} }}
\def\LocalEntropy{{ - \log \int_{\thetap \in \cspace} \exp (-\Phi (\thetap)-\frac{\gamma}{2}\|\vtheta-\thetap\|_{2}^{2}) \mathrm{d} \thetap }}
\def\LocalEntropyy{{ - \log \int_{\thetap} \exp \left(-\Phi (\thetap)-\frac{\gamma}{2}\|\vtheta-\thetap\|_{2}^{2}\right) \mathrm{d} \thetap }}
\def\ExpOf#1{ \mathbb{E} \left[ {#1} \right]}
\def\ExpOfXi#1{ \mathbb{E}_\xi \left[ {#1} \right]}
\def\ExpOfGibbs#1{ \mathbb{E}_{ \mathcal{P}_\gamma} \left[ {#1} \right]}
\def\fracK {{\frac{1}{k}}}

\def\metanext{{ \vtheta_{\text{adapt}}^{n+1} }}
\def\metacurr{{ \vtheta_{\text{adapt}}^{n}   }}


\def\calA{{\cal A}}
\def\calB{{\cal B}}
\def\calC{{\cal C}}
\def\calD{{\cal D}}
\def\calE{{\cal E}}
\def\calF{{\cal F}}
\def\calG{{\cal G}}
\def\calH{{\cal H}}
\def\calI{{\cal I}}
\def\calJ{{\cal J}}
\def\calK{{\cal K}}
\def\calL{{\cal L}}
\def\calM{{\cal M}}
\def\calN{{\cal N}}
\def\calO{{\cal O}}
\def\calP{{\cal P}}
\def\calQ{{\cal Q}}
\def\calR{{\cal R}}
\def\calS{{\cal S}}
\def\calT{{\cal T}}
\def\calU{{\cal U}}
\def\calV{{\cal V}}
\def\calW{{\cal W}}
\def\calX{{\cal X}}
\def\calY{{\cal Y}}
\def\calZ{{\cal Z}}

\newcommand{\nicefracpartial}[2]{\nicefrac{\partial #1}{\partial  #2}}
\newcommand{\nicefracdiff}[2]{\nicefrac{\rd #1}{\rd  #2}}
\newcommand{\fracpartial}[2]{\frac{\partial #1}{\partial  #2}}
\newcommand{\fracdiff}[2]{\frac{\rd #1}{\rd  #2}}
\newcommand{\br}[1]{\left[#1\right]}
\newcommand{\pr}[1]{\left(#1\right)}
\newcommand{\T}{\mathsf{T}}
\newcommand*\bvec[1]{\begin{bmatrix}#1\end{bmatrix}}
\newcommand{\bmat}[4]{\begin{bmatrix} #1 & #2 \\ #3 & #4\end{bmatrix}}
\def\vec{{\mathrm{vec}}}
\def\Hess{{\mathrm{Hess}}}
 \newcommand{\eq}[1]{{Eq.~(#1)}}
\newcommand{\eg}{{\ignorespaces\emph{e.g.}}{ }}
\newcommand{\ie}{{\ignorespaces\emph{i.e.}}{ }}
\newcommand{\wlg}{{\ignorespaces\emph{w.l.o.g.}}{ }}
\newcommand{\cf}{{\ignorespaces\emph{c.f.}}{ }}
\newcommand{\tmp}{{\ignorespaces(x)}{ }}
\newcommand{\resp}{{\ignorespaces\emph{resp.}}{ }}

\usepackage{mathtools}
\usepackage{tabularx}
\usepackage{framed}

\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{multirow}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}



\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\usepackage{cancel}
\usepackage{lipsum}


\newcommand{\todo}[1]{{\tiny \color{red} TODO: #1}}






\usepackage{capt-of}
\usepackage{wrapfig}

\usepackage{xcolor}
\usepackage{color,soul}
\colorlet{color1}{green!50!black}
\colorlet{color2}{orange!95!black}
\colorlet{color3}{red!80!black}
\colorlet{color4}{red!65!black}
\colorlet{color5}{blue!75!green}
\colorlet{blueee}{blue!50!black}

\definecolor{label1}{HTML}{99292A}
\definecolor{label2}{HTML}{D89A3C}
\definecolor{label3}{HTML}{417481}
\colorlet{label22}{label2!80!black}

\definecolor{amaranth}{rgb}{0.9, 0.17, 0.31}

\newcommand{\markgreen}[1]{{\ignorespaces\color{color1} #1}}

\newcommand{\markblue}[1]{{\ignorespaces\color{color5} #1}}
\newcommand{\markred}[1]{\ignorespaces{\color{color3} #1}}

\newcommand{\markgray}[1]{\ignorespaces{\color{gray} #1}}

\newcommand{\markaa}[1]{\ignorespaces{\color{label1} #1}}
\newcommand{\markbb}[1]{\ignorespaces{\color{label22} #1}}
\newcommand{\markcc}[1]{\ignorespaces{\color{label3} #1}}


\let\svthefootnote\thefootnote
\usepackage{footnote}


\usepackage{pifont}
\usepackage{ifsym}
\newcommand{\cmark}{{\ding{51}}}\newcommand{\xmark}{{\ding{55}}}




\let\oldsqrt\sqrt
\def\sqrt{\mathpalette\DHLhksqrt}
\def\DHLhksqrt#1#2{\setbox0=\hbox{$#1\oldsqrt{#2\,}$}\dimen0=\ht0
\advance\dimen0-0.2\ht0
\setbox2=\hbox{\vrule height\ht0 depth -\dimen0}{\box0\lower0.4pt\box2}}

\newcommand{\specialcell}[2][c]{\begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}

\newcommand{\specialcellr}[2][r]{\begin{tabular}[#1]{@{}r@{}}#2\end{tabular}}

\newcommand{\specialcelll}[2][l]{\begin{tabular}[#1]{@{}l@{}}#2\end{tabular}}

\usepackage{enumitem}
\usepackage[position=top]{subfig}
\usepackage{arydshln}

\usepackage{algorithm}
\usepackage{algorithmic}
\newcommand*\mystrut[1]{\vrule width0pt height0pt depth#1\relax}

\usepackage{booktabs}       

\usepackage{enumitem}
\usepackage{tikz}
\newcommand*\numcircledmod[1]{\raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {#1}}}}
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=2pt] (char) {#1};}}

\usepackage{empheq}
\newcommand*\widefbox[1]{\fbox{\hspace{1em}#1\hspace{1em}}}
\usepackage{tablefootnote}

\usepackage{textcomp}
\usepackage{colortbl}

\newcommand{\corcmidrule}[1][1pt]{\\[\dimexpr-\normalbaselineskip-\belowrulesep-\aboverulesep-#1\relax]}

\setul{2pt}{.4pt}



\makeatletter
\newtheorem*{rep@theorem}{\rep@title}
\newcommand{\newreptheorem}[2]{\newenvironment{rep#1}[1]{\def\rep@title{#2 \ref{##1}}\begin{rep@theorem}}{\end{rep@theorem}}}
\makeatother


\newreptheorem{theorem}{Theorem}

\usepackage{aligned-overset}
\usepackage{cases}
 
\usepackage[bottom]{footmisc}

\hypersetup{
    colorlinks,
    linkcolor={blue!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

\title{Likelihood Training of Schr{\"o}dinger Bridge \\ using Forward-Backward SDEs Theory}


\author{Tianrong Chen$^{*}\text{,}$~Guan-Horng Liu\thanks{
    Equal contribution. Order determined by coin flip. See \nameref{sec:author} section.}~~,~Evangelos A. Theodorou\\
  Georgia Institute of Technology, USA\\
  \texttt{\{tianrong.chen, ghliu, evangelos.theodorou\}@gatech.edu}\\
}

\begin{document}

\maketitle

\begin{abstract} 


  Schr{\"o}dinger Bridge (SB) is an {entropy-regularized} optimal transport problem that
  has received increasing attention in deep generative modeling
  for its mathematical flexibility
  compared to the Scored-based Generative Model (SGM).
  However, it remains unclear
  whether the optimization principle of SB relates to the modern training of deep generative models,
  which often rely on constructing log-likelihood objectives.{This raises questions on the suitability of SB models as a principled alternative for generative applications.}
  In this work, we present a novel computational framework
  for likelihood training of SB models
  grounded on \textit{Forward-Backward Stochastic Differential Equations Theory}
  -- {a mathematical methodology appeared in stochastic optimal control}
  that transforms the optimality condition of SB into a set of SDEs.
  Crucially, these SDEs can be used to
  construct the likelihood objectives for SB that, surprisingly,
  generalizes the ones for SGM as special cases.
  This leads to a new optimization principle that
    inherits the same SB optimality
    yet without losing applications of modern generative training techniques,
  and we show that the resulting training algorithm
  achieves {comparable}
  results on generating realistic images on MNIST, CelebA, and CIFAR10.
  Our code is available at \url{https://github.com/ghliu/SB-FBSDE}.


\end{abstract}

\vspace{-5pt}
\section{Introduction} \label{sec:1}




\vspace{-1pt}

\begin{wrapfigure}[17]{r}{0.28\textwidth}
  \vspace{-22pt}
  \begin{center}
    \includegraphics[width=0.28\textwidth]{fig/sb1-crop.png}
  \end{center}
  \vskip -0.15in
  \caption{
    Both Score-based Generative Model (SGM) and Schr{\"o}dinger Bridge (SB)
    transform between two distributions.
    While SGM requires pre-specifying the data-to-noise diffusion,
    SB instead \textit{learns} the process.
  }
  \label{fig:1}
\end{wrapfigure}
Score-based Generative Model (SGM; \citet{song2020score})
is an emerging generative model class that has achieved
remarkable results in synthesizing high-fidelity data
\citep{song2020improved,kong2020hifi,kong2020diffwave}.
{Like many deep generative models},
SGM seeks to find nonlinear functions that transform simple distributions (typically Gaussian)
into complex, often intractable, data distributions.
In SGM, this is done by
first diffusing data to noise through a stochastic differential equation (SDE);
then learning to \textit{reverse} this diffusion process by regressing a network to the
{score} function (\ie the gradient of the log probability density) at each time step
\citep{hyvarinen2005estimation}.
This reversed process thereby defines the generation (see Fig.~\ref{fig:1}).





Despite its empirical successes,
SGM admits few limitations. First, the diffusion process has to obey a simple form (\eg~linear or degenerate drift)
in order to compute the analytic score function for the regression purpose.
{Secondly, the diffusion process needs to run to sufficiently large time steps} so that the end distribution is approximate Gaussian \citep{kong2021fast}.
For these reasons, SGM often takes a notoriously long time in
generating data \citep{jolicoeur2021gotta},
thereby limiting their practical usages compared to \eg GANs or flow-based models
\citep{ping2020waveflow,karras2020analyzing}.




In the attempt to lift these restrictions,
a line of recent works
inspired by Schr{\"o}dinger Bridge (SB; \citet{schrodinger1932theorie})
has been proposed \citep{de2021diffusion,wang2021deep,vargas2021solving}.
SB -- as an {entropy-regularized} optimal transport problem --
seeks two optimal policies that transform back-and-forth between two \textit{arbitrary} distributions in a \textit{finite} horizon.
The similarity between the two problems (\ie both involve transforming distributions) is evident,
and the additional flexibility from SB
{is also attractive}.
To enable SB-inspired generative training,
however,
previous works
require either {ad-hoc} multi-stage optimization
or retreat to traditional SB algorithms, \eg Iterative Proportional Fitting
(IPF; \citet{kullback1968probability}).
The underlying relation between the optimization principle of SB and modern generative training,
in particular SGM,
remains relatively unexplored, despite their intimately related problem formulations.
More importantly, with
the recent connection between SGM and log-likelihood computation
\citep{song2021maximum},
it is crucial to explore whether there exists an alternative way of training SB that
better respects, or perhaps generalizes, modern training of SGM,
so as to solidify the suitability of SB as a principled generative model.


In this work, we present a
fundamental connection between solving SB and training SGM.
The difficulty arises immediately as one notices that
the optimality condition of SB and the likelihood objective of SGM
are represented by merely two distinct mathematical objects.
While the former is characterized by two coupled partial differential equations (PDEs)
\citep{leonard2013survey},
the latter integrates over a notably complex SDE that resembles neither its diffusion nor reversed process
\citep{song2021maximum}.
Nevertheless,
inspired by the recent advance on understanding deep learning through the optimal control perspective \citep{li2018optimal,liu2021differential,liu2021dynamic},
we show that \textit{Forward-Backward SDEs} --
a mathematical methodology appearing in stochastic optimal control
for solving nonlinear PDEs \citep{han2018solving}
-- paves an elegant way to connect the two objectives.
The implication of our findings is nontrivial:
{
  It yields an exact log-likelihood expression of SB
  that precisely generalizes the one of SGM \citep{song2021maximum} to fully nonlinear diffusion,
  thereby providing novel theoretical connections between the two model classes.
  Algorithmically, our framework suggests rich training procedures that resemble
  the joint optimization for diffusion flow-based models \citep{zhang2021diffusion}
  or more traditional IPF approaches \citep{kullback1968probability,de2021diffusion}.
  This allows one to marry the best of both worlds by improving the SB training with
  \eg a SGM-inspired Langevin corrector \citep{song2019generative}.}
The resulting method, \textbf{SB-FBSDE},
generates encouraging images on MNIST, CelebA, and CIFAR10
and outperforms prior optimal transport models by a large margin.


{
  Our method differs from the concurrent SB methods \citep{de2021diffusion,vargas2021solving} in various aspects.
  First, while both prior methods rely on solving SB with
  \textit{mean-matching} regression,
  our {SB-FBSDE} instead utilizes a \textit{divergence-based} objectives
  (see $\S$\ref{sec:3.2}).
  Secondly, neither of the prior methods focuses on log-likelihood training,
  which is the key finding in {SB-FBSDE} to bridge connections to SGM and adopt modern training improvements.
  Indeed, due to the difference in the underlying SDE classes,\footnote{{
    We adopt the recent advance in SB theory \citep{caluya2021wasserstein} that extends classical SB models (used in prior works) to the exact SDE class appearing in SGM. See Appendices~\ref{app:d1} and \ref{app:d2} for more details.
  }}
  their connections to SGM can only be made after time discretization by carefully choosing each step size \citep{de2021diffusion}.
  In contrast, our theoretical connection is derived readily in continuous-time; hence unaffected by the choice of numerical discretization.

  
}


In summary, we present the following contributions.
\vspace{-6pt}
\begin{itemize}[leftmargin=13pt]
    \item We present a novel computational framework,
    grounded on \textit{Forward-Backward SDEs} theory,
    for computing the log-likelihood objectives of
    Schr{\"o}dinger Bridge (SB) and solidifying their theoretical connections to Score-based Generative Model (SGM).

    \item {Our framework suggests a new training principle that retains the mathematical flexibility from SB while enjoying advanced techniques from the modern generative training of SGM.}

    \item {We show that the resulting method -- named \textbf{SB-FBSDE} --
        outperforms previous optimal transport-inspired baselines on
        synthesizing high-fidelity images and is comparable to other existing models.}
\end{itemize}

\vspace{-10pt}

\paragraph*{Notation.}
We denote $p_{t}^{\mathrm{SDE}}(\rvX_t)$ as the marginal density driven by some $\mathrm{SDE}$ process $\rvX(t)\equiv \rvX_t$ until the time step $t\in[0,T]$.
The time direction is aligned throughout this article such that
$p_0$ and $p_T$ respectively correspond to the data and
prior distributions.
{
    The gradient, divergence, and Hessian of a function $f(\vx)$, where $\vx \in \mathbb{R}^n$, will be denoted as
    $\nabla_\vx f \in \mathbb{R}^n $, $\nabla_\vx \cdot f \in \mathbb{R}$, and $\nabla^2_{\vx} f \in \mathbb{R}^{n\times n}$.
}



















 
\vspace{-4pt}
\section{Preliminaries} \label{sec:2}



\newcommand{\score}[2]{\nabla \log p_{#1}(#2)}
\def\pdata{{ p_\text{\normalfont{data}} }}
\def\prior{{ p_\text{\normalfont{prior}} }}
\newcommand{\pp}[2]{p_{#1}^{\text{\normalfont{#2}}}}



\vspace{-4pt}

\subsection{Score-based Generative Model (SGM)}

\vspace{-4pt}

Given a data point $\rvX_0 \in \mathbb{R}^n$ sampled from an unknown data distribution $\pdata$,
SGM first progressively diffuses the data towards random noise with the following {forward SDE}:
  \begin{align}
    \rd \rvX_t = f(t, \rvX_t) \dt + g(t) \dwt, \quad \rvX_0 \sim \pdata,
    \label{eq:fsde}
  \end{align}
where $f(\cdot,t): \mathbb{R}^n \rightarrow \mathbb{R}^n $,
$g(t)\in \mathbb{R}$, and $\wt \in \mathbb{R}^n$
are the drift, diffusion, and standard Wiener process.
Typically, $g(\cdot)$ is
some monotonically increasing function
such that for sufficiently large time steps, we have $\pp{T}{\eqref{eq:fsde}} \approx \prior$ resemble some prior distribution (\eg Gaussian)
at the terminal horizon $T$.
Reversing \eqref{eq:fsde} yields another {SDE}\footnote{
    Hereafter, we will sometimes drop $f \equiv f(t,\rvX_t)$ and $g \equiv g(t)$ for brevity.
} that traverses backward in time \citep{anderson1982reverse}:
\begin{align}
\rd \rvX_t = [f - g^2~\nabla_\vx \log \pp{t}{\eqref{eq:fsde}}(\rvX_t) ] \dt + g~\dwt,
\quad \rvX_T \sim \pp{T}{\eqref{eq:fsde}},
\label{eq:rsde}
\end{align}
where {$p_{t}^\text{\eqref{eq:fsde}}$ corresponds to the marginal density of SDE \eqref{eq:fsde} at time $t$,}
and $\nabla_\vx \log \pp{t}{\eqref{eq:fsde}}$ is
known as the \textit{score} function.
These two stochastic processes
are equivalent in the sense that their marginal densities are equal to each other throughout $t\in[0,T]$;
in other words,
$\pp{t}{\eqref{eq:fsde}} \equiv \pp{t}{\eqref{eq:rsde}}$.


\def\condscore{{ \nabla_\vx\log p_{t|\vx_0} }}


When the drift $f$ is of simple structure,
for instance linear \citep{ho2020denoising} or simply degenerate \citep{song2019generative},
the conditional score function
$\nabla_\vx\log p_t^{\text{\eqref{eq:fsde}}}(\rvX_t| \rvX_0=\vx_0) \equiv \nabla_\vx\log p_{t|\vx_0}$
 admits an analytic solution at any time $t$.
Hence,
SGM proposes to train a parameterized score network $\rvs(t,\vx; \theta)$
by regressing its outputs to the ground-truth values, \ie
$\E[ \lambda(t) \norm{\rvs(t,\rvX_t; \theta) - \condscore}^2 ]$,
where {the expectation is taken over the SDE \eqref{eq:fsde}}.
In practice, $\lambda(t)$ is some hand-designed weighting function that largely affects the performance.
Recent works \citep{song2021maximum,huang2021variational} have shown that
the log-likelihood of SGM, despite being complex, can be lower-bounded as follows:
\begin{align*}
    &{\log \pp{0}{SGM}(\vx_0) \ge }\calL^{\text{}}_{\text{SGM}}(\vx_0; \theta)
    =          \E\br{\log p_T(\rvX_T)} - \int_0^T \E \br{
       \frac{1}{2}g^2\norm{\rvs_t}^2 + \nabla_\vx \cdot \pr{g^2\rvs_t - f}
    } \dt, \numberthis \label{eq:sgm-nll} \\
    &\qquad= \E\br{\log p_T(\rvX_T)} - \int_0^T \E \br{
       \frac{1}{2}g^2\norm{\rvs_t - \condscore}^2 - \frac{1}{2}\norm{g\condscore}^2 - \nabla_\vx \cdot f
    } \dt,
\end{align*}
    where $\rvs_t\equiv\rvs(t,\vx; \theta)$  and the expectation is taken over the SDE \eqref{eq:fsde} given
    a data point $\rvX_0 = \vx_0$.
This objective \eqref{eq:sgm-nll}
suggests a principled choice of $\lambda(t) := g(t)^2$.
After training, SGM simply substitutes the score function with the learned score network $\rvs(t,\vx; \theta)$
to generate data from $\prior$,
\begin{align}
\rd \rvX_t = [f - g^2~\rvs(t,\rvX_t; \theta) ] \dt + g~\dwt,
\quad \rvX_T \sim \prior.
\label{eq:sample-sgm}
\end{align}
It is important to notice that $\prior$ needs \emph{not} equal $\pp{T}{\eqref{eq:fsde}}$ in practice,
and the approximation is close only through a careful design of \eqref{eq:fsde}.
Notably,
designing the diffusion $g(t)$ can be particularly problematic
as it affects both the approximation $\pp{T}{\eqref{eq:fsde}} \approx \prior$ and the training via the weighting $\lambda(t)$;
hence can lead to unstable training \citep{nichol2021improved}.
    In contrast, Schr{\"o}dinger Bridge considers a more flexible framework for designing the forward diffusion
    that requires minimal manipulation.




\subsection{Schr{\"o}dinger Bridge (SB)} \label{sec:2.2}

\def\QQ{{\mathbb{Q}}}
\def\PP{{\mathbb{P}}}
\def\zz{{\nabla_\vx \log {\Psi}}}
\def\zzhat{{\nabla_\vx \log \widehat{\Psi}}}


Following the dynamic expression of SB \citep{pavon1991free,dai1991stochastic},
consider \begin{align}
    \min_{\QQ \in \calP(\pdata, \prior)}
    \KL(\QQ~||~\PP),
    \label{eq:sb}
\end{align}
where $\QQ \in \calP(\pdata, \prior)$ belongs to a set of {path}
measure with $\pdata$ and $\prior$ as its marginal densities at $t=0$ and $T$.
On the other hand, $\PP$ denotes a reference measure, which we will set to the path measure of
\eqref{eq:fsde} for later convenience.
The optimality condition to \eqref{eq:sb} is characterized by two PDEs that are coupled through their boundary conditions. We summarize the related result below. \begin{theorem}[SB optimality; \citet{chen2021stochastic,pavon1991free,caluya2021wasserstein}] \label{thm:1}
    Let $\Psi(t,\vx)$ and $\widehat{\Psi}(t,\vx)$ be
    the solutions to the following PDEs:
    \begin{align}
        \begin{cases}
        \fracpartial{\Psi}{t} = - \nabla_\vx \Psi^\T f {-} \frac{1}{2} \Tr(g^2\nabla^2_{\vx}\Psi) \\[3pt]
        \fracpartial{\widehat{\Psi}}{t} = - \nabla_\vx \cdot (\widehat{\Psi} f) {+} \frac{1}{2} \Tr(g^2\nabla^2_{\vx}\widehat{\Psi})
        \end{cases}
        \text{s.t. } \Psi(0,\cdot) \widehat{\Psi}(0,\cdot) = \pdata,~\Psi(T,\cdot) \widehat{\Psi}(T,\cdot) = \prior
        \label{eq:sb-pde}
    \end{align}
    Then, the solution to the optimization \eqref{eq:sb}
    can be expressed by the path measure of the following
    forward \eqref{eq:fsb}, or equivalently backward \eqref{eq:bsb}, SDE:
    \begin{subequations}
    \begin{align}
        \rd \rvX_t &= [f + g^2~\nabla_\vx \log {\Psi}(t,\rvX_t) ] \dt + g~\dwt,
        \quad \rvX_0 \sim \pdata,
        \label{eq:fsb}
        \\
        \rd \rvX_t &= [f - g^2~\nabla_\vx \log \widehat{\Psi}(t,\rvX_t) ] \dt + g~\dwt,
        \quad \rvX_T \sim \prior,
        \label{eq:bsb}
    \end{align} \label{eq:sb-sde}\end{subequations}
    where $\nabla_\vx \log {\Psi}(t,\rvX_t)$ and $\nabla_\vx \log \widehat{\Psi}(t,\rvX_t)$
    are the optimal forward and backward drifts for SB.
\end{theorem}
Similar to the forward/backward processes in SGM,
the stochastic processes of SB in \eqref{eq:fsb} and \eqref{eq:bsb}
are also equivalent in the sense that
$\forall t\in[0,T],~\pp{t}{\eqref{eq:fsb}} \equiv \pp{t}{\eqref{eq:bsb}} \equiv \pp{t}{SB}$.
In fact, its marginal density obeys a factorization principle:
$\pp{t}{SB}(\rvX_t) = {\Psi}(t,\rvX_t)\widehat{\Psi}(t,\rvX_t)$.


To construct the generative pipeline from \eqref{eq:bsb},
one requires solving the PDEs in \eqref{eq:sb-pde}
to obtain $\widehat{\Psi}$.
Unfortunately, these PDEs are hard to solve even for low-dimensional systems \citep{renardy2006introduction};
let alone for generative applications.
Indeed, previous works either have to replace the original Schr{\"o}dinger Bridge ($\pdata\leftrightarrows\prior$)
with multiple stages, $\pdata\leftrightarrows\pp{\text{middle}}{}\leftrightarrows\prior$,
so that each segment admits an analytic solution \citep{wang2021deep},
or consider the following half-bridge ($\pdata\leftarrow\prior$ \textit{vs.} $\pdata\rightarrow\prior$) optimization \citep{de2021diffusion,vargas2021solving},
\begin{align*}
    \QQ^{(1)} := \argmin_{\QQ\in\calP(\cdot, \prior)} \KL(\QQ~||~\QQ^{(0)}), \quad
    \QQ^{(0)}   := \argmin_{\QQ\in\calP(\pdata, \cdot)} \KL(\QQ~||~\QQ^{(1)})
\end{align*}
which can be solved with IPF algorithm \citep{kullback1968probability}
starting from $\QQ^{(0)} := \PP$.
In the following section,
we will present a scalable computational framework for
solving the optimality PDEs in \eqref{eq:sb-pde}
and show that it paves an elegant way connecting the optimality principle of SB \eqref{eq:sb-pde} to
the parameterized log-likelihood of SGM \eqref{eq:sgm-nll}.


 
\vspace{-1pt}
\section{Approach} \label{sec:3}
\vspace{-1pt}


\begin{figure}
  \vskip -0.2in
  \centering
  \includegraphics[width=\textwidth]{fig/sb3-crop.pdf}
  \caption{
    Schematic diagram of the our stochastic optimal control interpretation,
    and how it connects the objective of SGM \eqref{eq:sgm-nll}
    and optimality of SB \eqref{eq:sb-pde} through Forward-Backward SDEs theory.
  }
  \label{fig:2}
  \vskip -0.05in
\end{figure}


We motivate our approach starting from some control-theoretic observation (see Fig.~\ref{fig:2}).
Notice that both SGM and SB consist of forward and backward SDEs with similar structures.
From the stochastic control perspective, these SDEs belong to the class of
\emph{control-affine} SDEs with {additive} noise:
\begin{align}
    \rd \rvX_t = \mA(t,\rvX_t) \dt + \mB(t,\rvX_t) \rvu(t,\rvX_t) \dt + \mC(t)~\dwt.
    \label{eq:control-affine}
\end{align}
It is clear that the
control-affine SDE \eqref{eq:control-affine} includes all SDEs (\ref{eq:fsde},\ref{eq:rsde},\ref{eq:sample-sgm},\ref{eq:sb-sde}) appearing in $\S$\ref{sec:2}
by considering $(\mA,\mB,\mC) := (f,\mI,g)$ and different interpretations of the \emph{control} variables $\rvu(t,\rvX_t)$.
This implies that
the optimization processes of
both SGM and SB can be aligned through the lens of \textit{{stochastic optimal control}} (SOC).
Indeed,
both problems can be interpreted as seeking some time-varying control policy,
either the score function $\condscore$ in SGM or $\zzhat$ in SB,
that minimizes some objectives, \eqref{eq:sgm-nll} \textit{vs.} \eqref{eq:sb},
while subjected to some control-affine SDEs, (\ref{eq:fsde},\ref{eq:rsde}) \textit{vs.} \eqref{eq:sb-sde}.
In what follows, we will show that
a specific mathematical methodology in nonlinear SOC literature
--
called \textit{Forward-Backward SDEs} theory (FBSDEs; see \citet{ma1999forward}) --
links the optimality condition of SB~\eqref{eq:sb-pde}
to the log-likelihood objectives of SGM~\eqref{eq:sgm-nll}.
All proofs are left to Appendix~\ref{app:a}.

\vspace{-1pt}
\subsection{Forward-Backward SDEs (FBSDEs) Representation for SB} \label{sec:3.1}
\vspace{-1pt}

The theory of FBSDEs establishes an innate connection between
different classes of PDEs and forward-backward SDEs.
Below we introduce the following connection related to our problem.{
\begin{lemma}[Nonlinear Feynman-Kac;\footnote{
  Lemma~\ref{lemma:non-fc} can be viewed as the nonlinear extension of the celebrated Feynman-Kac formula \citep{karatzas2012brownian},
  which characterizes the connection between linear PDEs and forward SDEs.
} \citet{exarchos2018stochastic}]\label{lemma:non-fc}Consider the coupled SDEs
  \begin{subequations}
  \begin{empheq}[left={\empheqlbrace}]{align}
        \rd\rvX_t &=  f(t,\rvX_t) \dt + G(t,\rvX_t) \dwt, \qquad\qquad\quad\text{ }\text{ } \rvX_0 = \vx_0 \label{eq:fbsde-f} \\
        \rd\rvY_t &=  - h(t, \rvX_t, \rvY_t, \rvZ_t) \dt + \rvZ(t,\rvX_t)^\T \dwt, \quad \rvY_T = \varphi(\rvX_T) \label{eq:fbsde-b}
  \end{empheq} \label{eq:fbsde}\end{subequations}
where the functions $f$, $G$, $h$, and ${\varphi}$ satisfy proper regularity conditions\footnote{{
  \citet{yong1999stochastic,kobylanski2000backward} require
  $f$, $G$, $h$, and ${\varphi}$ to be continuous, $f$ and $G$ to be uniformly Lipschitz in $\vx$,
  and $h$ to satisfy quadratic growth condition in $\vz$.
  \label{ft:cond}}
}
so that there exists a pair of unique strong solutions satisfying \eqref{eq:fbsde}.
Now, consider the following second-order parabolic PDE and suppose $v(t,\vx)\equiv v$ is once continuously differentiable in $t$ and twice in $\vx$, \ie $ v \in C^{1,2}$,
\begin{align}
  \fracpartial{v}{t} +
  \frac{1}{2}\Tr(\nabla^2_{\vx} v~GG^\T) + \nabla_\vx v^\T f + h(t,\vx,v,G^\T \nabla_\vx v)  = 0,
  \quad v(T,\vx) = \varphi(\vx),
  \label{eq:hjb}
\end{align}
then the solution to \eqref{eq:fbsde} coincides with the solution to \eqref{eq:hjb} along paths generated by the forward SDE \eqref{eq:fbsde-f} almost surely, i.e.,
the following stochastic representation (known as the nonlinear Feynman-Kac relation) is valid:
\begin{align}
  v(t,\rvX_t) = \rvY_t
  \qquad\text{and}\qquad
  G(t,\rvX_t)^\T \nabla_\vx v(t,\rvX_t) = \rvZ_t.
  \label{eq:hjb-fbsde}
\end{align}
\end{lemma}}
Lemma~\ref{lemma:non-fc} states that
solutions to a certain class of nonlinear (via the function $h$ in \eqref{eq:hjb}) PDEs
can be represented by solutions to a set of forward-backward SDEs \eqref{eq:fbsde}
through the transformation \eqref{eq:hjb-fbsde},
  and this relation can be extended to the viscosity case (\citet{pardoux1992backward}; see also {Appendix~\ref{app:a}}).
  Note that
  $\rvY_t$ is the solution to the backward SDE \eqref{eq:fbsde-b} whose
  randomness is driven by the forward SDE \eqref{eq:fbsde-f}.
  Indeed, it is clear from \eqref{eq:hjb-fbsde} that $\rvY_t$ (hence also $\rvZ_t$)
  is a time-varying function of  $\rvX_t$.
  Since the $v$ appearing in the nonlinear Feynman-Kac relation \eqref{eq:hjb-fbsde}
  takes the random vector $\rvX_t$ as its argument,
  $v(t,\rvX_t)$ shall also be understood as a random variable.
  Finally, it is known that the original (deterministic) PDE solution $v(t,\vx)$ can be recovered by taking conditional expectation, \ie
  \begin{align}
    v(t,\vx) = \E_{\rvX_t\sim\text{\eqref{eq:fbsde-f}}}[\rvY_t | \rvX_t = \vx]
    \quad\text{and}\quad
    G(t,\vx)^\T \nabla_\vx v(t,\vx) = \E_{\rvX_t\sim\text{\eqref{eq:fbsde-f}}}[\rvZ_t | \rvX_t = \vx].
  \end{align}Since it is often computationally favorable to solve SDEs rather than PDEs,
Lemma~\ref{lemma:non-fc} has been widely used as a scalable method for solving high-dimensional PDEs \citep{han2018solving,pereira2019neural}.
Take SOC applications for instance,
their PDE optimality condition
can be characterized by \eqref{eq:hjb-fbsde} under proper conditions,
with the optimal control given in the form of $\rvZ_t$.
Hence,
one can adopt Lemma~\ref{lemma:non-fc} to solve the underlying FBSDEs, rather than the original PDE optimality, for the optimal control.
Despite seemingly attractive,
whether these principles can be extended to SB,
whose optimality conditions are given by \textit{two coupled PDEs} in \eqref{eq:sb-pde},
remains unclear.
Below we derive a similar FBSDEs representation for SB.
\begin{theorem}[FBSDEs to SB optimality \eqref{eq:sb-pde}] \label{thm:3}
  Consider the following set of coupled SDEs,
  \begin{subequations}
  \begin{empheq}[left={\empheqlbrace}]{align}
      \rd \rvX_t &= \pr{f + g \rvZ_t} \dt + g \dwt \label{eq:fsde-is} \\
      \rd \rvY_t &= \frac{1}{2} \rvZ_t^\T\rvZ_t \dt + \rvZ_t^\T \dwt \label{eq:psi-bsde-is} \\
      \rd \widehat{\rvY}_t &= \pr{\frac{1}{2} \widehat{\rvZ}_t^\T\widehat{\rvZ}_t + \nabla_\vx \cdot (g\widehat{\rvZ}_t -f) + \widehat{\rvZ}_t^\T\rvZ_t } \dt + \widehat{\rvZ}_t^\T \dwt \label{eq:psi-hat-bsde-is}
  \end{empheq} \label{eq:psi-hat-fbsde-is}\end{subequations}
  where $f$ and $g$ satisfy the same regularity conditions in Lemma~\ref{lemma:non-fc} (see Footnote~\ref{ft:cond}), and
  the boundary conditions are given by $\rvX(0)=\vx_0$ and
  $\rvY_T + \widehat{\rvY}_T = \log \prior(\rvX_T)$.
  Suppose $\Psi, \widehat{\Psi} \in C^{1,2}$,
  then the nonlinear Feynman-Kac relations between the FBSDEs \eqref{eq:psi-hat-fbsde-is} and PDEs \eqref{eq:sb-pde} are given by
  \begin{equation}
  \begin{alignedat}{2}
    \rvY_t &\equiv  \rvY(t,\rvX_t) = \log \Psi(t,\rvX_t), \qquad
    \rvZ_t &&\equiv \rvZ(t,\rvX_t) = g \nabla_\vx \log \Psi(t,\rvX_t), \\
    \widehat{\rvY}_t &\equiv  \widehat{\rvY}(t,\rvX_t) =          \log \widehat{\Psi}(t,\rvX_t), \qquad
    \widehat{\rvZ}_t &&\equiv \widehat{\rvZ}(t,\rvX_t) = g \nabla_\vx \log \widehat{\Psi}(t,\rvX_t).
  \end{alignedat} \label{eq:sb-yz}
  \end{equation}
  Furthermore, $(\rvY_t, \widehat{\rvY}_t)$
  obey the following relation:
  \begin{align*}
    {\rvY_t + \widehat{\rvY}_t} = \log \pp{t}{SB}(\rvX_t).
  \end{align*}
\end{theorem}
The FBSDEs for SB \eqref{eq:psi-hat-fbsde-is}
share a similar forward-backward structure as in \eqref{eq:fbsde},
where \eqref{eq:fsde-is} and (\ref{eq:psi-bsde-is},\ref{eq:psi-hat-bsde-is})
respectively represent the forward and backward SDEs.
One can verify that the forward SDE \eqref{eq:fsde-is} coincides with the \textit{optimal} forward SDE~\eqref{eq:fsb} with the substitution $\rvZ_t = g \nabla_\vx \log \Psi$.
In other words,
these FBSDEs provide a \textit{local} representation of $\log\Psi$ and $\log\widehat{\Psi}$
evaluated on the optimal path governed by \eqref{eq:fsb}.
  Since $\rvZ_t$ and $\widehat{\rvZ}_t$ can be understood as the forward/backward policies,
  in a similar spirit of policy-based methods \citep{pereira2020feynman,schulman2015trust},
  that guide the SDE processes of SB,
  they sufficiently characterize the SB model.
  Hence, our next step is to derive a proper training objective to optimize these policies.



\vspace{-2pt}
\subsection{Log-likelihood Computation of SB} \label{sec:3.2}
\vspace{-2pt}


\def\LSGM{{\calL^{\text{}}_{\text{\normalfont{SGM}}}}}
\def\LSB{{\calL^{\text{}}_{\text{\normalfont{SB}}}}}
\def\LSBB{{\widetilde{\calL}^{\text{}}_{\text{\normalfont{SB}}}}}

Theorem~\ref{thm:3} has an important implication:
It suggests that
given a path sampled from the forward SDE~\eqref{eq:fsde-is},
the solutions to the backward SDEs (\ref{eq:psi-bsde-is},\ref{eq:psi-hat-bsde-is}) at $t=0$
provide an unbiased estimation of the log-likelihood of the data point $\vx_0$,
\ie $\E\br{\rvY_0 + \widehat{\rvY}_0 | \rvX_0=\vx_0} = \log \pp{0}{SB}(\vx_0) = \log \pdata(\vx_0)$,
where $\rvX_t$ is sampled from \eqref{eq:fsde-is}.
We now state our main result, which makes this observation formal:\begin{theorem}[Log-likelihood of SB model] \label{thm:4}
    Given the solution satisfying the FBSDE system in \eqref{eq:psi-hat-fbsde-is},
    the log-likelihood of the SB model $(\rvZ_t, \widehat{\rvZ}_t)$, at a data point $\vx_0$, can be expressed as
  \begin{align}
      \log \pp{0}{SB}(\vx_0) &= \E\br{\log p_T(\rvX_T)} {-} \int_0^T \E\left[ \frac{1}{2} \norm{\rvZ_t}^2 {+} \frac{1}{2} \norm{\widehat{\rvZ}_t - g\nabla_\vx \log \pp{t}{SB} + \rvZ_t}^2 \right. \nonumber \\
      & \qquad \qquad \qquad \qquad \qquad \quad \qquad \qquad \left.  {-} \frac{1}{2} \norm{g\nabla_\vx \log \pp{t}{SB} - \rvZ_t}^2 {-} \nabla_\vx \cdot f \right] \dt \label{eq:sb-nll-bad} \\
      &= \E\br{\log p_T(\rvX_T)} - \int_0^T \E\br{ \frac{1}{2} \norm{\rvZ_t}^2 {+} \frac{1}{2} \norm{\widehat{\rvZ}_t}^2  + \nabla_\vx \cdot (g\widehat{\rvZ}_t -f) + \widehat{\rvZ}_t^\T{\rvZ}_t } \dt, \label{eq:sb-nll}
  \end{align}
  where the expectation is taken over the forward SDE \eqref{eq:fsde-is} with the initial condition $\rvX_0 = \vx_0$.
\end{theorem}
  Similar to \eqref{eq:sgm-nll}, Theorem~\ref{thm:4} suggests a parameterized lower bound to the log-likelihoods, \ie $\log \pp{0}{SB}(\vx_0) \ge \LSB(\vx_0; \theta, \phi)$ where $\LSB(\vx_0; \theta, \phi)$ shares the same expression in \eqref{eq:sb-nll} except that
  $\rvZ_t \approx \rvZ(t,\vx; \theta)$ and $\widehat{\rvZ}_t \approx \widehat{\rvZ}(t,\vx; \phi)$ are approximated with some parameterized models (\eg DNNs).
  Note that $\nabla_\vx \log \pp{t}{SB}$ is \emph{intractable} in practice for any nontrivial $(\rvZ_t, \widehat{\rvZ}_t)$.
  Hence, we use the divergence-based objective in \eqref{eq:sb-nll} as our training objective of both policies.

\textbf{Connection to score-based models.}
Recall Fig.~\ref{fig:2} and compare the parameterized log-likelihoods of SB \eqref{eq:sb-nll} to SGM \eqref{eq:sgm-nll};
one can verify that $\LSB$ collapses to $\LSGM$ when
$(\rvZ_t, \widehat{\rvZ}_t) := (\mathbf{0}, g~\rvs_t)$.
From the SB perspective, this occurs only when $\pp{T}{\eqref{eq:fsde}} = \prior$.
Since no effort is required in the forward process to reach $\prior$,
the optimal forward control $\rvZ_t$, by definition, degenerates;
thereby making the backward control $\widehat{\rvZ}_t$
collapses to the score function.
However, in any case when $\pp{T}{\eqref{eq:fsde}} \neq \prior$,
{for instance when the diffusion SDEs are improperly designed,}
the forward policy $\rvZ_t$ steers the diffusion process
back to $\prior$,
while its backward counterpart $\widehat{\rvZ}_t$ compensates the reversed process accordingly.
From this view,
SB
alleviates the problematic design in SGM by
enlarging the class of diffusion processes to accept \textit{nonlinear} drifts and
providing an optimization principle on learning these processes.
Moreover, Theorem~\ref{thm:4}
generalizes the log-likelihood training from SGM to SB.


\textbf{Connection to flow-based models.}
Interestingly,
the log-likelihood computation in Theorem~\ref{thm:4},
where we use a path $\{\rvX_t\}_{t\in[0,T]}$ sampled from a data point $\rvX_0$ to parameterize its log-likelihood,
resembles modern training of (deterministic) flow-based models \citep{grathwohl2018ffjord}, which have recently been shown to admit a close relation to SGM \citep{song2020score,gong2021interpreting}.
The connection is built on the concept of \textit{probability flow}
-- which suggests that
the marginal density of an SDE can be evaluated through an
ordinary differential equation (ODE).
Below, we provide a similar flow representation for SB,
further strengthening their connection to modern generative models.
\begin{corollary}[Probability flow for SB] \label{coro:5}
  The following ODE
  characterizes the probability flow of the optimal processes of SB \eqref{eq:sb-sde}
  in the sense that $\forall t,~\pp{t}{\eqref{eq-sb-prob}} \equiv \pp{t}{\eqref{eq:sb-sde}} \equiv \pp{t}{SB}$.
  \begin{align}
    \rd \rvX_t = \br{f + g\rvZ(t, \rvX_t) -\frac{1}{2}g~(\rvZ(t, \rvX_t) + \widehat{\rvZ}(t, \rvX_t))} \dt
    \label{eq-sb-prob}
  \end{align}
\end{corollary}
One can verify (see Remark~\ref{remark:app-5} in $\S$\ref{app:a}) that computing the log-likelihood of this ODE model \eqref{eq-sb-prob}
using flow-based training techniques indeed recovers the training objective of SB derived in \eqref{eq:sb-nll}.

{
\vspace{-2pt}
\subsection{Practical Implementation} \label{sec:3.3}
\vspace{-2pt}

In this section, we detail the implementation of our FBSDE-inspired SB model, named \textbf{SB-FBSDE}.

\textbf{Training process.}
We treat the log-likelihood in \eqref{eq:sb-nll} as our training objective,
where the divergence can be can be estimated efficiently following \citet{hutchinson1989stochastic}.
This immediately distinguishes SB-FBSDE from prior SB models \citep{de2021diffusion,vargas2021solving}, which instead rely on regression-based objectives.\footnote{
  In fact, their regression targets may be recovered from \eqref{eq:sb-nll-bad} under proper transformation; see Appendix~\ref{app:d2}.
}
For low-dimensional datasets, we simply perform joint optimization, $\max \LSB(\vx_0; \theta, \phi)$, to train the parameterized policies $\rvZ(\cdot,\cdot; \theta)$ and $\widehat{\rvZ}(\cdot,\cdot; \phi)$.
For higher-dimensional (\eg image) datasets, however, it can be prohibitively expensive to keep the entire computational graph.
In these cases, we follow \citet{de2021diffusion} by caching the sampled trajectories in a reply buffer and refreshing them
in a lower frequency basis (around 1500 iterations).
Although this implies that the gradient path w.r.t. $\theta$ will be discarded,
we can leverage the symmetric structure of SB
and re-derive the log-likelihood for the sampled noise, \ie $\LSB(\vx_T)$, based on the backward trajectories sampled from~\eqref{eq:bsb}.
We leave the derivation to Theorem~\ref{thm:9} in $\S$\ref{app:a} due to space constraint.
This results in an alternate training between the following two objectives after dropping all unrelated terms,
  \begin{align}
      &\LSBB(\vx_0; \phi)
      = - \int_0^T \E_{\rvX_t\sim\text{\eqref{eq:fsb}}}\br{\frac{1}{2} \norm{\widehat{\rvZ}(t,\rvX_t;\phi)}^2  + g \nabla_\vx \cdot \widehat{\rvZ}(t,\rvX_t;\phi) + {\rvZ}_t^\T\widehat{\rvZ}(t,\rvX_t;\phi) } \dt, \label{eq:high-dim-loss} \\
      &\LSBB(\vx_T; \theta)
      = - \int_0^T \E_{\rvX_t\sim\text{\eqref{eq:bsb}}}\br{\frac{1}{2} \norm{\rvZ(t,\rvX_t;\theta)}^2 + g \nabla_\vx \cdot {\rvZ}(t,\rvX_t;\theta) + \widehat{\rvZ}^\T_t{\rvZ}(t,\rvX_t;\theta)} \dt. \label{eq:high-dim-loss2}
  \end{align}
Our training process is summarized in Alg.~\ref{alg:train}.
While the joint training scheme in Alg.~\ref{alg:train2} resembles recent {diffusion} flow-based models \citep{zhang2021diffusion},
the alternate training in Alg.~\ref{alg:train3} relates to the classical IPF \citep{de2021diffusion}, despite differing in the underlying objectives.
Empirically, the joint training scheme can converge faster yet at the cost of introducing memory complexity.
We highlight these flexible training procedures arising from the unified viewpoint provided in Theorem~\ref{thm:4}.
Hereafter, we refer to
each cycle, \ie $2K$ training steps, in Alg.~\ref{alg:train3} as a \textit{training stage} of SB-FBSDE.

\begin{figure}[t]
\vskip -0.15in
\begin{minipage}[t]{0.48\textwidth}
\begin{algorithm}[H]
\small
     \caption{\small Likelihood training of SB-FBSDE}
     \label{alg:train}
  \begin{algorithmic}
   \STATE {\bfseries Input:}
      boundary distributions $\pdata$ and $\prior$,  \\
      $\quad$ parameterized policies $\rvZ(\cdot,\cdot; \theta)$ and $\widehat{\rvZ}(\cdot,\cdot; \phi)$
   \REPEAT
     \IF{ memory resource is affordable }
       \STATE {\bfseries run} Algorithm~\ref{alg:train2}.
     \ELSE
       \STATE {\bfseries run} Algorithm~\ref{alg:train3}.
     \ENDIF
   \UNTIL{ converges }
  \end{algorithmic}
\end{algorithm}
\vskip -0.25in
\begin{algorithm}[H]
  \small
     \caption{\small Joint (diffusion flow-based) training}
     \label{alg:train2}
  \begin{algorithmic}
      \FOR{$k=1$ {\bfseries to} $K$ }
         \STATE Sample $\rvX_{t\in[0,T]}$ from \eqref{eq:fsde-is} where $\vx_0 \sim \pdata$ (computational graph retained).
         \STATE Compute $\LSB(\vx_0; \theta, \phi)$ with \eqref{eq:sb-nll}.
         \STATE Update $(\theta,\phi)$ with $\nabla_{\theta,\phi} \LSB(\vx_0; \theta, \phi)$.
      \ENDFOR
  \end{algorithmic}
\end{algorithm}
\end{minipage}
\hfill
\begin{minipage}[t]{0.50\textwidth}
\begin{algorithm}[H]
\small
     \caption{\small Alternate (IPF-based) training}
     \label{alg:train3}
  \begin{algorithmic}
   \STATE {\bfseries Input:}
      Caching frequency $M$
     \FOR{$k=1$ {\bfseries to} $K$ }
       \IF{ $k\%M$ == 0 }
         \STATE Sample $\rvX_{t\in[0,T]}$ from \eqref{eq:fsde-is} where $\vx_0 \sim \pdata$ (computational graph discarded).
       \ENDIF
       \STATE Compute $\LSBB(\vx_0; \phi)$ with \eqref{eq:high-dim-loss}.
       \STATE Update $\phi$ with gradient $\nabla_\phi \LSBB(\vx_0; \phi)$.
     \ENDFOR
     \FOR{$k=1$ {\bfseries to} $K$ }
       \IF{ $k\%M$ == 0 }
         \STATE Sample $\rvX_{t\in[0,T]}$ from \eqref{eq:bsb} where $\vx_T \sim \prior$ (computational graph discarded).
       \ENDIF
       \STATE Compute $\LSB(\vx_T; \theta)$ with \eqref{eq:high-dim-loss2}.
       \STATE Update $\theta$ with gradient $\nabla_\theta \LSBB(\vx_T; \theta)$.
     \ENDFOR
  \end{algorithmic}
\end{algorithm}
\end{minipage}
\vskip -0.15in
\end{figure}
}

\textbf{Generative process.}
While the generative processes for SB can be performed as simply as
propagating \eqref{eq:bsb} given the trained policy $\widehat{\rvZ}(\cdot,\cdot; \phi)$,
it has been constantly observed
that adopting Langevin sampling to the generative process greatly improves performance \citep{song2020score}.
This procedure, often referred to as the \textit{Langevin corrector}, requires knowing
the score function $\nabla_\vx \log \pp{t}{}$.
For SB, we can estimate its value by recalling (see $\S$\ref{sec:2.2}) that
$\rvZ_t + \widehat{\rvZ}_t = g\nabla_\vx \log \pp{t}{SB}$.
This results in the following predictor-corrector sampling procedure (see Alg.~\ref{alg:sample} in Appendix~\ref{Appendix:Exp_detals} for more details).
\begin{align}
    \text{Predict step:}\quad \rvX_t &\leftarrow \rvX_t + g~\widehat{\rvZ}_t \Delta t + \sqrt{g \Delta t} \eps \\
    \text{Correct step:}\quad \rvX_t &\leftarrow \rvX_{t} + \textstyle\frac{\sigma_t}{g}({\rvZ}_t + \widehat{\rvZ}_t) + \sqrt{2\sigma_t} \eps
\end{align}
where $\eps \sim \calN(\mathbf{0},\mI)$ and $\sigma_t$ is the pre-specified noise scales (see \eqref{eq:noise-scale} in Appendix~\ref{Appendix:Exp_detals}).

\vspace{-1pt}

\textbf{Limitations \& efficiency.}
The main computational burden of our method comes from the computation of the divergence and maintaining two distinct networks.
Despite it typically increases the memory by 2$\sim$2.5 times compared to SGM,
we empirically observe that the divergence-based training converges much faster per iteration than standard regression.
As a result, SB-FBSDE admits comparable training time (+6.8\% in our CIFAR10 experiment) compared to SGM, yet with a substantially fewer sampling time (-80\%) due to adopting nonlinear SDEs.




 
\section{Experiments} \label{sec:4}


\begin{figure}[H]
  \vskip -0.28in
  \begin{minipage}{\textwidth}
    \centering
    \captionsetup[subfloat]{captionskip=1pt}
    \subfloat[GMM]{\includegraphics[width=0.5\textwidth]{fig/gmm.pdf}}
    \hfill
    \subfloat[Checkerboard]{\includegraphics[width=0.5\textwidth]{fig/check.pdf}}
    \vskip -0.1in
    \caption{
      Validation of our SB-FBSDE model on two synthetic toy datasets that represent continuous and discontinuous distributions.
      \textit{Upper}:
      \markblue{Generation ($\color{color5} \pdata \leftarrow \prior$)} process with the
      \markblue{backward vector field $\color{color5} \widehat{\rvZ}(\cdot,\cdot;\phi)$}.
      \textit{Bottom}:
      \markred{Diffusion ($\color{color3} \pdata \rightarrow \prior$)} process with the
      \markred{forward vector field $\color{color3} {\rvZ}(\cdot,\cdot;\theta)$}.
    }\label{fig:toy}\end{minipage}
  \vskip 0.05in
  \begin{minipage}{\textwidth}
    \centering
    \includegraphics[width=\textwidth]{fig/datasets_samples_new.pdf}
    \vskip -0.1in
    \caption{
        Uncurated samples from our SB-FBSDE models trained on MNIST (left), resized CelebA (middle) and CIFAR10 (right).
        More images can be found in Appendix~\ref{appendix:addtional_fig}.
    }
    \label{fig:all_datasets}
  \end{minipage}
  \vskip -0.1in
\end{figure}


\textbf{Setups.}
We testify SB-FBSDE on
two toy datasets and three image datasets, \ie
MNIST, CelebA,\footnote{
  We follow a similar setup of prior SB models \citep{de2021diffusion} and resize the image size to 32.
} and CIFAR10.
$\prior$ is set to a zero-mean Gaussian whose variance varies for each task and can be computed according to \citet{song2020improved}.
We parameterize ${\rvZ}(\cdot,\cdot;\theta)$ and $\widehat{\rvZ}(\cdot,\cdot;\phi)$ with residual-based networks for toy datasets and consider
Unet \citep{ronneberger2015u} and NCSN++ \citep{song2020score} respectively for MNIST/CelebA and CIFAR10.
All networks adopt position encoding and are trained with AdamW \citep{loshchilov2017decoupled} on a TITAN RTX.
We adopt VE-SDE (\ie $f:=\mathbf{0}$; see \citet{song2020score})
as our SDE backbone,
which implies that in order to achieve reasonable performance,
SB must \textit{learn} a proper data-to-noise diffusion process.
On all datasets,
we set the horizon $T=$1.0
and solve the SDEs via the Euler-Maruyama method.
The interval $[0,T]$ is discretized into 200 steps for CIFAR10 and 100 steps for all other datasets,
which are much fewer than the ones in SGM ($\ge$1000 steps).
Other details are left in Appendix~\ref{Appendix:Exp_detals}.

\textbf{Toy datasets.}
We first validate our joint optimization (\ie Alg~\ref{alg:train2}) on generating a mixture of Gaussian and checkerboard (adopted from \citet{grathwohl2018ffjord})
as the representatives of continuous and discontinuous distributions.
Figure~\ref{fig:toy}
shows how the learned policies, \ie $\color{color3} {\rvZ}(\cdot,\cdot;\theta)$ and $\color{color5} \widehat{\rvZ}(\cdot,\cdot;\phi)$,
construct the vector fields that progressively transport
samples back-and-forth between $\prior$ and $\pdata$.
The vector fields can be highly nonlinear and dissimilar to each other.
This resembles neither SGMs, whose forward vector field must obey linear structure,
nor flow-based models, whose vector fields are simply with opposite directions.
We highlight this as a distinct feature arising from SB models.



\textbf{Image datasets.}
Next, we validate our alternate training (\ie Alg~\ref{alg:train3}) on high-dimensional image generation.
The generated images for MNIST, CelebA, and CIFAR10 are presented in Fig.~\ref{fig:all_datasets},
which clearly suggest that our SB-FBSDE is able to synthesize high-fidelity images.
More uncurated images can be founded in Appendix~\ref{appendix:addtional_fig}.
Regarding the quantitative evaluation, Table~\ref{table:NLL_FID} summarizes
the negative log-likelihood (NLL; measured in bits/dim) and the
Fr\'echet Inception Distance score (FID; \citet{heusel2017gans}) on CIFAR10.
For our SB-FBSDE, we compute the NLL on the test set using Corollary~\ref{coro:5},
in a similar vein to SGMs and flow-based models,
and report the FID over 50k samples w.r.t the training set.
Notably, our SB-FBSDE achieves 2.98 bits/dim and 3.18 FID score on CIFAR10,
which is comparable to the top existing methods from other model classes (\eg SGMs) and
outperforms prior Optimal Transport (OT) methods \citep{wang2021deep,tanaka2019discriminator}
by a large margin in terms of the sample quality.
More importantly, it enables log-likelihood computations that are otherwise infeasible in prior OT methods.
We note that the quantitative comparisons on MNIST and CelebA are omitted
as the scores on these two datasets are not widely reported and different pre-processing (\eg resizing of CelebA) can lead to values that are not directly comparable.


\begin{figure}[t]
  \vskip -0.15in
  \begin{minipage}{\textwidth}
    \centering
    \captionsetup{type=table}
    \caption{
      CIFAR10 evaluation using negative log-likelihood (NLL; bits/dim) on the test set and sample quality (FID score) w.r.t. the training set.
      Our \textbf{SB-FBSDE} outperforms other optimal transport baselines by a large margin
      and is comparable to existing generative models.
    }
      \vskip -0.05in
      \begin{tabular}{llcccccccc}
        \toprule
        {Model Class} & {Method}  & {NLL $\downarrow$} & {FID $\downarrow$} \\

        \midrule

        \multirow{4}{*}{\specialcelll[l]{Optimal Transport }}
        & \textbf{SB-FBSDE (ours)}             & {2.96} &  3.01 \\[1pt]
        & DOT \citep{tanaka2019discriminator}  &  -     & 15.78 \\[1pt]
        & Multi-stage SB \citep{wang2021deep}  &  -     & 12.32 \\[1pt]
        & DGflow \citep{ansari2020refining}    &  -     &  9.63 \\[1pt]

        \midrule

        \multirow{5}{*}{\specialcelll[l]{SGMs}}
        & SDE (deep, sub-VP; \citet{song2020score})                  & 2.99         & 2.92  \\[1pt]
        & ScoreFlow \citep{song2021maximum}             &2.74 & 5.7  \\[1pt]
        & VDM \citep{kingma2021variational}             &\textbf{2.49} & 4.00  \\[1pt]
        & LSGM\citep{vahdat2021score}                   & 3.43         &\textbf{2.10} \\[1pt]







        \bottomrule
      \end{tabular} \label{table:NLL_FID}
  \end{minipage}
\end{figure}






\begin{figure}[t]
  \vskip -0.1in
  \begin{minipage}{0.43\textwidth}
    \centering
    \includegraphics[height=2.25cm]{fig/mnist-kl.pdf}
    \vskip -0.1in
    \caption{
      Validation of our SB-FBSDE on \textit{learning} forward diffusions
      that are closer (in KL sense) to $\prior$ compared to SGM.
    }
    \label{fig:mnist-kl}
  \end{minipage}
  \hfill
  \begin{minipage}{0.55\textwidth}
    \centering
    \includegraphics[height=2.25cm]{fig/FID-both.pdf}
    \vskip -0.1in
    \caption{
        Ablation analysis where we show that adding Langevin corrector to SB-FBSDE
        uniformly improves the FID scores on both CelebA and CIFAR10 training.
    }
    \label{fig:fid}
  \end{minipage}
\vskip -0.1in
\end{figure}


\textbf{Validity of SB forward diffusion.}
Our theoretical analysis in $\S$\ref{sec:3.2}
suggests that the forward policy ${\rvZ}(\cdot,\cdot;\theta)\equiv\rvZ_\theta$ plays
an essential role in governing samples towards $\prior$.
Here, we validate this conjecture by computing the KL divergence between
the terminal distribution induced by $\rvZ_\theta$,
\ie $\pp{T}{\eqref{eq:fsde-is}}$,
and the designated prior $\prior$.
We refer readers to Appendix~\ref{Appendix:Exp_detals} for the actual computation.
Figure~\ref{fig:mnist-kl} reports these values over MNIST training.
For both degenerate ($f:=\mathbf{0}$) and linear ($f:=\alpha_t\rvX_t$) base drifts,
our SB-FBSDE generates terminal distributions that are much closer to $\prior$.
Note that the values of SGM remain unchanged throughout training since SGM relies on \textit{pre-specified} diffusion.
This is in contrast to our SB-FBSDE whose forward policy $\rvZ_\theta$
gradually shortens the KL gap to $\prior$,
thereby providing a better forward diffusion for training the backward policy.




\textbf{Effect of Langevin corrector.}
In practice,
we observe that the Langevin corrector greatly affects the generative performance.
As shown in Fig.~\ref{fig:fid},
including these corrector steps uniformly improves the sample quality (FID) on both CelebA and CIFAR10 throughout training.
Since the SDEs are often solved via the Euler-Maruyama method,
their propagation can be subjected to discretization errors accumulated over time.
These Langevin steps thereby help
re-distributing the samples at each time step $t$ towards the desired density $\pp{t}{SB}$.
We emphasize
this improvement
as the benefit gained from
applying modern generative training techniques based on
the solid connection between SB and SGM.














 

\vspace{-5pt}
\section{Conclusion}
\vspace{-5pt}
In this work, we present a novel computational framework, grounded on Forward-Backward SDEs theory,
for computing the log-likelihood of Schr{\"o}dinger Bridge (SB) --
a recently emerging model that adopts entropy-regularized optimal transport for generative modeling.
Our findings
provide new theoretical insights by generalizing previous theoretical results for Score-based Generative Model,
and facilitate applications of modern generative training for SB.
We validate our method on various image generative tasks, \eg MNIST, CelebA, and CIFAR10,
showing encouraging results in synthesizing high-fidelity samples
while retaining the rigorous mathematical framework.


\newpage

\section*{Acknowledgments}
The authors would like to thank Ioannis Exarchos and Oswin So for their generous involvement and helpful supports during the rebuttal. The authors would also like to thank Marcus A Pereira and Ethan N Evans for their participation and kind discussion in the early stage of project exploration.
This research was supported by the ARO Award \# W911NF2010151.

\section*{Author Contributions} \label{sec:author}
The original idea of solving the PDE optimality of SB with FBSDEs theory was initiated by Tianrong.
Later, Guan derived the main theories (\ie Theorem~\ref{thm:3},~\ref{thm:4},~\ref{thm:9}, and Corollary~\ref{coro:5})
presented in Section~\ref{sec:3.1}, \ref{sec:3.2} and Appendix~\ref{app:a} with few helps from Tianrong.
Tianrong designed the practical algorithms (\eg stage-wise optimization and Langevin-corrector) in Section~\ref{sec:3.3} and
conducted most experiments with few helps from Guan.
Guan wrote the main paper except for Section~\ref{sec:4},
which were written by both Tianrong and Guan.
Both Guan and Tianrong contributed to code development.


\section*{Reproducibility Statement}

Our training algorithms are detailed in Alg.~\ref{alg:train}, \ref{alg:train2}, and \ref{alg:train3}, with the training objectives given in the same section (see (\ref{eq:sb-nll}, \ref{eq:high-dim-loss}, \ref{eq:high-dim-loss2})). Other implementation details (\eg data pre-processing) are left in Appendix~\ref{Appendix:Exp_detals}. This shall provide sufficient information for readers of interests to reproduce our results. As we strongly believe in the merit of open sourcing, we intend to release our implementation upon publication. On the theoretical side, all proofs are left to Appendix~\ref{app:a} due to space constraint. We provide the assumptions in the same section.





\bibliographystyle{iclr2022_conference}
\bibliography{reference.bib}

\newpage
\appendix


\def\dWt{{\dwt}}


\section{Introduction of Schr{\"o}dinger Bridge}\label{app:d1}

    In this subsection, we provide a brief review for Schr{\"o}dinger Bridge (SB) and some reasonings for Theorem~\ref{thm:1}.
    The SB problem, at its classical form, considers the following optimization \citep{dai1991stochastic,pavon1991free},
    \begin{equation}
        \begin{split}
            &\quad\min_{\rvu \in \calU}
            \E\br{\int_0^T \frac{1}{2} \norm{\rvu(t, \rvX_t)}^2} \\
            \text{s.t. }&
            \begin{cases}
                \rd \rvX_t = \rvu(t, \rvX_t) \dt + \sqrt{2\epsilon}~\dwt \\
                \rvX_0\sim p_0(\rvX), \quad \rvX_T\sim p_T(\rvX)
            \end{cases},
        \end{split} \label{eq:app-sb}
    \end{equation}
    where $\calU := \{ \rvu: [0,T]\times\mathbb{R}^n \mapsto \mathbb{R}^n | \langle \rvu , \rvu \rangle < \infty \}$.
    The optimization \eqref{eq:app-sb} characterizes a standard stochastic optimal control (SOC) programming with energy
    (\ie $\frac{1}{2} \norm{\rvu}^2$) minimization except with an additional terminal boundary condition.
    The optimality conditions to \eqref{eq:app-sb} are given by
      \begin{subequations}
      \begin{empheq}[left={\empheqlbrace}]{align}
          \fracpartial{\psi}{t} &= - \frac{1}{2} \norm{\nabla_\vx\psi}^2 - \epsilon~\Delta\psi, \label{eq:app-sb2a} \\
          \fracpartial{p^*}{t} &= \nabla_\vx \cdot \pr{p^* \nabla_\vx \psi} + \epsilon~\Delta p^*, \label{eq:app-sb2b}
      \end{empheq} \label{eq:app-sb2}\end{subequations}
    where $\psi(t,\vx) \in C^{1,2}$ is known as the \textit{value} function in SOC literature
    and $p^*(t,\vx) \in C^{1,2}$ is the associated optimal marginal density. $\Delta$ denotes the Laplace operator.
    Equations \eqref{eq:app-sb2a} and \eqref{eq:app-sb2b}
    are respectively the Kolmogorov’s backward and forward PDEs,
    also known as Hamilton-Jacobi-Bellman and Fokker-Planck equations.
    The SB system can be obtained by applying the Hopf-Cole \citep{hopf1950partial,cole1951quasi} transformation $(\psi, p^*) \mapsto (\Psi, \widehat{\Psi})$,
        \begin{align}
            \begin{cases}
            \fracpartial{\Psi}{t} = - \epsilon~\Delta\Psi \\[3pt]
            \fracpartial{\widehat{\Psi}}{t} = \epsilon~\Delta\widehat{\Psi}
            \end{cases}
            \text{s.t. } \Psi(0,\cdot) \widehat{\Psi}(0,\cdot) = p_0,~\Psi(T,\cdot) \widehat{\Psi}(T,\cdot) = p_T.
            \label{eq:app-sb-pde2}
        \end{align}

    In this work, we consider a recent generalization of \eqref{eq:app-sb} and \eqref{eq:app-sb-pde2} to
    an SDE class with nonlinear drift, affine control, and time-varying diffusion.
    We synthesize their results below.
    \begin{theorem}[SB optimality; \citet{caluya2021wasserstein}] \label{thm:10}
        Consider the following optimization
        \begin{equation}
            \begin{split}
                &\qquad\quad\min_{\rvu}
                \E\br{\int_0^T \frac{1}{2} \norm{\rvu(t, \rvX_t)}^2} \\
                \text{s.t. }&
                \begin{cases}
                    \rd \rvX_t = [f(t, \rvX_t) + g(t)~\rvu(t, \rvX_t)] \dt + \sqrt{2\epsilon}g(t)~\dwt \\
                    \rvX_0\sim p_0(\rvX), \quad \rvX_T\sim p_T(\rvX)
                \end{cases},
            \end{split} \label{eq:app-sb3}
        \end{equation}
        where $g(t)$ is uniformly lower-bounded and
        $f(t, \rvX_t)$ satisfies Lipschitz conditions with at most linear growth in $\vx$.
        Then, the Hopf-Cole transformation to \eqref{eq:app-sb3} becomes
        \begin{align}
            \begin{cases}
            \fracpartial{\Psi}{t} = - \nabla_\vx \Psi^\T f {-} \epsilon \Tr(g^2\nabla^2_{\vx}\Psi) \\[3pt]
            \fracpartial{\widehat{\Psi}}{t} = - \nabla_\vx \cdot (\widehat{\Psi} f) {+} \epsilon \Tr(g^2\nabla^2_{\vx}\widehat{\Psi})
            \end{cases},
            \label{eq:app-sb-pde3}
        \end{align}
        with the same boundary conditions $\Psi(0,\cdot) \widehat{\Psi}(0,\cdot) = p_0,~\Psi(T,\cdot) \widehat{\Psi}(T,\cdot) = p_T$.
        The optimal control to \eqref{eq:app-sb3} is thereby given by
        \begin{align}
            \rvu^*(t,\rvX_t) = 2\epsilon g(t) \nabla_\vx \log \Psi(t,\rvX_t).
            \label{eq:app-sb-opt}
        \end{align}
    \end{theorem}
    \begin{proof}
        See Section III and Theorem 2 inf \citet{caluya2021wasserstein}.
    \end{proof}

    Theorem~\ref{thm:10} is particularly attractive to us since its SDE corresponds exactly to the one appearing in score-based generative models.
    One can recover Theorem~\ref{thm:1} by
    \begin{enumerate}[leftmargin=20pt]
        \item[\textit{(i)}] Following \citet{pavon1991free}, we know that the objective in \eqref{eq:app-sb3} is equivalent to $\KL(\QQ~||~\PP)$ by an application of Girsanov’s Theorem.
        \item[\textit{(ii)}] Equation \eqref{eq:app-sb-pde3} is exactly \eqref{eq:sb-pde} with $\epsilon=\frac{1}{2}$. Furthermore, substituting the optimal control \eqref{eq:app-sb-opt} to the stochastic process in \eqref{eq:app-sb3} yields the optimal forward SDE in \eqref{eq:fsb}.
        \item[\textit{(iii)}] Finally, reversing the SDE \eqref{eq:fsb} from forward to backward following \citet{anderson1982reverse},
        \begin{align}
            \rd \rvX_t &= [f + g^2~\nabla_\vx \log {\Psi}(t,\rvX_t) - g^2~\nabla_\vx \log \pp{t}{SB} ] \dt + g~\dwt,
        \end{align}
        and recalling the factorization principle,
        $\log \pp{t}{SB}(\cdot) = \log\Psi(t,\cdot) + \log\widehat{\Psi}(t,\cdot)$,
        from Equation (4.15) in \citet{chen2021stochastic} yield the optimal backward SDE in \eqref{eq:bsb}.
    \end{enumerate}




\section{Proofs and Remarks in Section~\ref{sec:3}} \label{app:a}

In this section, we provide proofs for all of our theorems.
We following the same notation by denoting $p_{t}^{\mathrm{SDE}}(\rvX_t)$ as the marginal density driven by some $\mathrm{SDE}$ process $\rvX(t)\equiv \rvX_t$ until the time step $t\in[0,T]$.
Gradient and Hessian of a function $f(\vx)$, where $\vx \in \mathbb{R}^n$, will respectively be denoted as
$\nabla_\vx f \in \mathbb{R}^n $ and $\nabla^2_{\vx} f \in \mathbb{R}^{n\times n}$.
Divergence and Laplace operators will respectively be denoted as
$\nabla \cdot$ and $\Delta$.
Note that $\Delta = \nabla \cdot \nabla$.
For notational brevity, we will only keep the subscript $\vx$ for multivariate functions.
Finally,
$\Tr(\mA)$ denotes the trace of a square matrix $\mA$.

We first restate the celebrated It{\^o} lemma, which is known as the extension of the chain rule of ordinary calculus to the stochastic setting. It relies on the fact that $\dwt^2$ and $\dt$ are of the same scale and
keeps the expansion up to $\calO(\dt)$.
\begin{lemma}[It{\^o} formula; \citet{ito1951stochastic}] \label{lemma:ito}
  Let $v \in C^{1,2}$ and let $\rvX_t$ be the stochastic process satisfying
  \begin{align*}
    \rd \rvX_t = f(t, \rvX_t) \dt + G(t, \rvX_t) \dwt.
  \end{align*}
  Then, the stochastic process $v(t,\rvX_t)$ is also an It{\^o} process satisfying
  \begin{align*}
    \rd v(t,\rvX_t) =
      \fracpartial{v(t,\rvX_t)}{t}\dt
      &+ \br{ \nabla_\vx v(t,\rvX_t)^\T f + \frac{1}{2}\Tr\br{G^\T \nabla_\vx^2v(t,\rvX_t) G} } \dt \\
      &+ \br{ \nabla_\vx v(t,\rvX_t)^\T G(t, \rvX_t) } \dwt.
      \numberthis \label{eq:ito}
  \end{align*}
\end{lemma}

Next, the following lemma will be useful in proving Theorem~\ref{thm:3}.
\begin{lemma} \label{lemma:sbp}
  The following equality holds at any point $\vx \in \mathbb{R}^n$ such that $p(\vx)\neq 0$.
  \begin{align*}
    \frac{1}{p(\vx)} \Tr\pr{\nabla^2p(\vx)} = \norm{\nabla \log p(\vx)}^2 + \Delta \log p(\vx)
  \end{align*}
\end{lemma}
\begin{proof}
  \begin{align*}
       \Tr\pr{\nabla^2p(\vx)}
    &= \Delta p(\vx)
    = \nabla \cdot \nabla p(\vx) \\
    &= \nabla \cdot \pr{ p(\vx) \nabla \log p(\vx) } \\
    &= \nabla p(\vx)^\T \nabla \log p(\vx) + p(\vx) \Delta \log p(\vx) \\
    &= p(\vx) \nabla \log p(\vx)^\T \nabla \log p(\vx) + p(\vx) \Delta \log p(\vx) \\
    &= p(\vx) \pr{\norm{\nabla \log p(\vx)}^2 + \Delta \log p(\vx)}
  \end{align*}
\end{proof}


{
\paragraph*{Assumptions}
Before stating our proofs, we provide the assumptions used throughout the paper.
These assumptions are adopted from stochastic analysis for SGM \citep{song2021maximum,yong1999stochastic,anderson1982reverse}, SB \citep{caluya2021wasserstein}, and FBSDE \citep{exarchos2018stochastic,gorodetsky2015efficient}.
\begin{enumerate}[label=(\roman*)]
  \item $\prior, \pdata \in C^{2}$ with finite second-order moment. \label{assum:i}

  \item $f$ and $g$ are continuous functions, and $|g(t)|^2>0$ is uniformly lower-bounded w.r.t. $t$.

  \item $\forall t\in[0,T]$, we have
        $f(t,\vx), \nabla_\vx \log \pp{t}{}(\vx), \nabla_\vx \log \Psi(t,\vx), \nabla_\vx \log \widehat{\Psi}(t,\vx), \rvZ(t,\vx;\theta)$, and $\widehat{\rvZ}(t,\vx;\phi)$
        Lipschitz and at most linear growth w.r.t. $\vx$.

  \item $\Psi, \widehat{\Psi} \in C^{1,2}$. $h$, and $\varphi$ are continuous functions. $h$ satisfies quadratic growth w.r.t. $\vx$ uniformly in $t$.


  \item $\exists k>0: \pp{t}{SB}(\vx) = \calO(\exp^{-\norm{\vx}_k^2})$ as $\vx \rightarrow \infty$. \label{assum:v}

\end{enumerate}
Assumptions (i) (ii) (iii) are standard conditions in stochastic analysis to ensure the existence-uniqueness of the SDEs; hence also appear in SGM analysis \citep{song2021maximum}.
Assumption (iv) allows applications of It{\^o} formula and properly defines the backward SDE in FBSDE theory.
Finally, assumption (v) assures the exponential limiting behavior when performing integration by parts.
}

Now, let us begin the proofs of Theorem~\ref{thm:3}, \ref{thm:4}, and Corollary~\ref{coro:5}.
\begin{reptheorem}{thm:3}[FBSDEs to SB optimality \eqref{eq:sb-pde}]
  Consider the following set of coupled SDEs,
  \begin{subequations}
  \begin{empheq}[left={\empheqlbrace}]{align}
      \rd \rvX_t &= \pr{f + g \rvZ_t} \dt + g \dwt  \\
      \rd \rvY_t &= \frac{1}{2} \rvZ_t^\T\rvZ_t \dt + \rvZ_t^\T \dwt  \\
      \rd \widehat{\rvY}_t &= \pr{\frac{1}{2} \widehat{\rvZ}_t^\T\widehat{\rvZ}_t + \nabla_\vx \cdot (g\widehat{\rvZ}_t -f) + \widehat{\rvZ}_t^\T\rvZ_t } \dt + \widehat{\rvZ}_t^\T \dwt
  \end{empheq} \label{eq:psi-hat-fbsde-is2}\end{subequations}
  where $f$ and $g$ satisfy the same regularity conditions in Lemma~\ref{lemma:non-fc} (see Footnote~\ref{ft:cond}), and
  the boundary conditions are given by $\rvX(0)=\vx_0$ and
  $\rvY_T + \widehat{\rvY}_T = \log \prior(\rvX_T)$.
  Suppose $\Psi, \widehat{\Psi} \in C^{1,2}$,
  then nonlinear Feynman-Kac relations between the FBSDEs \eqref{eq:psi-hat-fbsde-is} and PDEs \eqref{eq:sb-pde} are given by
  \begin{equation}
  \begin{alignedat}{2}
    \rvY_t &\equiv  \rvY(t,\rvX_t) = \log \Psi(t,\rvX_t), \qquad
    \rvZ_t &&\equiv \rvZ(t,\rvX_t) = g \nabla_\vx \log \Psi(t,\rvX_t), \\
    \widehat{\rvY}_t &\equiv  \widehat{\rvY}(t,\rvX_t) =          \log \widehat{\Psi}(t,\rvX_t), \qquad
    \widehat{\rvZ}_t &&\equiv \widehat{\rvZ}(t,\rvX_t) = g \nabla_\vx \log \widehat{\Psi}(t,\rvX_t).
    \label{eq:app-non-fc}
  \end{alignedat}
  \end{equation}
  Furthermore, $(\rvY_t, \widehat{\rvY}_t)$
  obey the following relation:
  \begin{align*}
    {\rvY_t + \widehat{\rvY}_t} = \log \pp{t}{SB}(\rvX_t).
  \end{align*}
\end{reptheorem}
\begin{proof}
  Similar to how the original nonlinear Feynman-Kac (\ie Lemma~\ref{lemma:non-fc})
  can be carried out by an application of It{\^o} lemma \citep{ma1999forward}.
  We can apply It{\^o} lemma \ref{lemma:ito} to the stochastic process $\log \Psi(t,\rvX_t)$ w.r.t.
  the optimal forward SDE \eqref{eq:fsb}.
        \begin{equation}
        \begin{split}
          \rd \log \Psi
            = \fracpartial{\log \Psi}{t}\dt
            &+ \br{\markgreen{\nabla_\vx \log \Psi^\T} (\markgreen{f} + g^2 \nabla_\vx \log \Psi) + \frac{1}{2}g^2\Tr\br{\nabla_\vx^2\log \Psi}} \dt
            + \br{g\nabla_\vx \log \Psi^\T } \dwt.
            \label{eq:ito-psi}
        \end{split}
        \end{equation}
  From the PDE dynamics \eqref{eq:sb-pde}, we know that
        \begin{align*}
          \fracpartial{\log \Psi}{t}
            &= \frac{1}{\Psi} \pr{ - \nabla_\vx \Psi^\T f - \frac{1}{2} \Tr(g^2\nabla^2_{\vx}\Psi)} \\
            &= - \markgreen{\nabla_\vx \log \Psi^\T f } - \markaa{\frac{1}{2} g^2 \Tr(\frac{1}{\Psi} \nabla^2_{\vx}\Psi)}.
        \end{align*}
  The \markgreen{first term} in the RHS can be readily canceled out with the related $f$-term in \eqref{eq:ito-psi}. The \markaa{second term} can also be canceled out using the fact that
  $\nabla_\vx^2\log \Psi = \markaa{\frac{1}{\Psi}\nabla_\vx^2\Psi} - \frac{1}{\Psi^2}\nabla_\vx\Psi\nabla_\vx\Psi^\T$.
  Hence, we are left with
        \begin{align*}
          \rd \log \Psi
          &= \br{\norm{g\nabla_\vx \log \Psi}^2 - \frac{1}{2}g^2\Tr\br{\frac{1}{\Psi^2}\nabla_\vx\Psi\nabla_\vx\Psi^\T}} \dt + g \nabla_\vx \log \Psi^\T \dWt\\
          &= \frac{1}{2} \norm{g \nabla_\vx \log \Psi}^2 \dt + g \nabla_\vx \log \Psi^\T \dWt. \numberthis \label{eq:thm3-Y}
        \end{align*}
  Likewise, applying It{\^o} lemma to $\log \widehat{\Psi}(t,\rvX_t)$, where $\rvX_t$ follows the SDE in \eqref{eq:fsb},
        \begin{equation}
        \begin{split}
          \rd \log \widehat{\Psi}
            = \fracpartial{\log \widehat{\Psi}}{t}\dt
            + \br{\markbb{\nabla_\vx \log \widehat{\Psi}^\T} (\markbb{f} + g^2 \nabla_\vx \log {\Psi}) + \frac{1}{2}g^2\Tr\br{\nabla_\vx^2\log \widehat{\Psi}}} \dt
            + \br{g\nabla_\vx \log \widehat{\Psi}^\T } \dwt,
            \label{eq:ito-psi2}
        \end{split}
        \end{equation}
  but now noticing that the dynamics of $\fracpartial{\log \widehat{\Psi}}{t}$ become
        \begin{align*}
          \fracpartial{\log \widehat{\Psi}}{t}
            &= \frac{1}{\widehat{\Psi}} \pr{ - \nabla_\vx \cdot (\widehat{\Psi}f) + \frac{1}{2} \Tr(g^2\nabla^2_{\vx}\widehat{\Psi})} \\
            &= - \markbb{\nabla_\vx \log \widehat{\Psi}^\T f} - \nabla_\vx \cdot f + \frac{1}{2} g^2 \Tr(\frac{1}{\widehat{\Psi}} \nabla^2_{\vx}\widehat{\Psi}).
        \end{align*}
  Only the \markbb{first term} in the RHS will be canceled out in \eqref{eq:ito-psi2}. Hence, we are left with
        \begin{equation}
        \begin{split}
          \rd \log \widehat{\Psi}
          &= \br { - \nabla_\vx \cdot f + \frac{1}{2} g^2 \Tr\br{\frac{1}{\widehat{\Psi}} \nabla^2_{\vx}\widehat{\Psi}} } \dt \\
          &\quad+ \br{g^2 \nabla_\vx \log \widehat{\Psi}^\T \nabla_\vx \log{\Psi} + \frac{1}{2}g^2\Tr\br{\nabla_\vx^2\log \widehat{\Psi}}} \dt + g \nabla_\vx \log \widehat{\Psi}^\T \dWt.
            \label{eq:ito-psi22}
        \end{split}
        \end{equation}
  Notice that the trace terms above can be simplified to
        \begin{align*}
          \frac{1}{2}\Tr\br{\frac{1}{\widehat{\Psi}} \nabla^2_{\vx}\widehat{\Psi} + \nabla_\vx^2\log \widehat{\Psi}}
          &= \Tr\br{\frac{1}{\widehat{\Psi}} \nabla^2_{\vx}\widehat{\Psi}} - \frac{1}{2}\norm{\nabla_\vx \log \widehat{\Psi}}^2 \\
          &= \frac{1}{2}\norm{\nabla_\vx \log \widehat{\Psi}}^2 + \Delta_\vx \log \widehat{\Psi},
        \end{align*}
    where the last equality follows by Lemma~\ref{lemma:sbp}. Substituting this result back to \eqref{eq:ito-psi22}, we get
        \begin{equation}
        \begin{split}
          \rd \log \widehat{\Psi}
          &= \br{
                - \nabla_\vx \cdot f
                + \frac{1}{2}\norm{g\nabla_\vx \log \widehat{\Psi}}^2 + g^2\Delta_\vx \log \widehat{\Psi}
                + g^2 \nabla_\vx \log \widehat{\Psi}^\T \nabla_\vx \log{\Psi}
              }\dt + g \nabla_\vx \log \widehat{\Psi}^\T \dWt \\
          &= \br{
                \nabla_\vx  \cdot \pr{ g^2\nabla_\vx \log \widehat{\Psi} {-} f }
                + \frac{1}{2}\norm{g\nabla_\vx \log \widehat{\Psi}}^2
                + g^2 \nabla_\vx \log \widehat{\Psi}^\T \nabla_\vx \log{\Psi}
              }\dt + g \nabla_\vx \log \widehat{\Psi}^\T \dWt
            \label{eq:ito-psi222}
        \end{split}
        \end{equation}
  Finally, by rewriting \eqref{eq:thm3-Y} and \eqref{eq:ito-psi222} with the nonlinear Feynman-Kac in \eqref{eq:app-non-fc} yields
        \begin{subequations}
        \begin{empheq}[box=\widefbox]{align*}
          \rd \rvX_t &= \pr{f + g \rvZ_t} \dt + g \dwt  \\
          \rd \rvY_t &= \frac{1}{2} \rvZ_t^\T\rvZ_t \dt + \rvZ_t^\T \dwt  \\
          \rd \widehat{\rvY}_t &= \pr{\frac{1}{2} \widehat{\rvZ}_t^\T\widehat{\rvZ}_t + \nabla_\vx \cdot (g\widehat{\rvZ}_t -f) + \widehat{\rvZ}_t^\T\rvZ_t } \dt + \widehat{\rvZ}_t^\T \dwt
        \end{empheq} \end{subequations}
  This concludes the proof.
\end{proof}

\begin{remark}[Viscosity solutions]\normalfont
  These FBSDE results can be extended to viscosity solutions in the case when the classical solution does not exist \citep{pardoux1992backward}. For the completeness, one shall understand them in the sense of $v(t,\vx) = \lim_{\epsilon\rightarrow\infty} v_{\epsilon}(t,\vx)$ uniformly in $(t,\vx)$ over a compact set. Here $v^{\epsilon}(t,\vx)$ is the classical solution to \eqref{eq:hjb} with $(f_{\epsilon},G_{\epsilon},h_{\epsilon},\varphi_{\epsilon})$ converge uniformly toward $(f,G,h,\varphi)$ over the compact set. We refer readers of interests to \citet{exarchos2018stochastic,negyesi2021one}, and their references therein.
\end{remark}

\begin{reptheorem}{thm:4}[Log-likelihood for SB models]
    Given the solution satisfying the FBSDE system in \eqref{eq:psi-hat-fbsde-is},
    the log-likelihood of the SB model $(\rvZ_t, \widehat{\rvZ}_t)$, at a data point $\vx_0$, can be expressed as
  \begin{align}
      \LSB(\vx_0) &= \E\br{\log p_T(\rvX_T)} {-} \int_0^T \E\left[ \frac{1}{2} \norm{\rvZ_t}^2 {+} \frac{1}{2} \norm{\widehat{\rvZ}_t - g\nabla_\vx \log \pp{t}{SB} + \rvZ_t}^2 \right. \nonumber \\
      & \qquad \qquad \qquad \qquad \qquad \quad \qquad \qquad \left.  {-} \frac{1}{2} \norm{g\nabla_\vx \log \pp{t}{SB} - \rvZ_t}^2 {-} \nabla_\vx \cdot f \right] \dt \label{eq:app-sb-nll-bad} \\
      &= \E\br{\log p_T(\rvX_T)} - \int_0^T \E\br{ \frac{1}{2} \norm{\rvZ_t}^2 {+} \frac{1}{2} \norm{\widehat{\rvZ}_t}^2  + \nabla_\vx \cdot (g\widehat{\rvZ}_t -f) + \widehat{\rvZ}_t^\T{\rvZ}_t } \dt, \label{eq:app-sb-nll}
  \end{align}
  where the expectation is taken over the forward SDE \eqref{eq:fsde-is} with the initial condition $\rvX_0 = \vx_0$.
\end{reptheorem}
\begin{proof}
    \begin{align*}
        &\LSB(\vx_0) \\
        =& \E \br{\rvY_0 + \widehat{\rvY}_0 | \rvX_0=\vx_0} \\
        =& \E\br{{\rvY}_T - \int_0^T \pr{\frac{1}{2} \norm{\rvZ_t}^2}\dt +
         \widehat{\rvY}_T - \int_0^T \pr{\frac{1}{2} \norm{\widehat{\rvZ}_t}^2 + \nabla \cdot (g\widehat{\rvZ}_t -f) + \widehat{\rvZ}_t^\T\rvZ_t } \dt \Big| \rvX_0=\vx_0} \\
        =& \E \br{\rvY_T + \widehat{\rvY}_T | \rvX_0=\vx_0}
         - \int_0^T \E\br{ \frac{1}{2} \norm{\rvZ_t}^2 + \frac{1}{2} \norm{\widehat{\rvZ}_t}^2 + \nabla \cdot (g\widehat{\rvZ}_t -f) + \widehat{\rvZ}_t^\T\rvZ_t \Big| \rvX_0=\vx_0} \dt  \\
        =& \E [\log p_T(\rvX_T)]
         - \int_0^T {\E\br{ \frac{1}{2} \norm{\rvZ_t}^2 + \frac{1}{2} \norm{\widehat{\rvZ}_t}^2 + \nabla \cdot (g\widehat{\rvZ}_t -f) + \widehat{\rvZ}_t^\T\rvZ_t}} \dt, \numberthis \label{eq:coro-proof1}
    \end{align*}
    which recovers \eqref{eq:app-sb-nll}. Finally, notice that with integration by part, we have
    \begin{equation}
    \begin{split}
        \E_{\rvX_t\sim\pp{t}{SB}}\br{g \nabla \cdot \widehat{\rvZ}_t}
          &= \int \pr{  g \nabla \cdot \widehat{\rvZ}_t} \pp{t}{SB}~\rd\rvX_t \\
          &=-\int g \widehat{\rvZ}_t^\T \nabla_\vx \pp{t}{SB}~\rd\rvX_t \\
          &=-\int \pr{  g \widehat{\rvZ}_t^\T\nabla_\vx \log\pp{t}{SB}} \pp{t}{SB}~\rd\rvX_t \\
          &=\E_{\rvX_t\sim\pp{t}{SB}}\br{- g \widehat{\rvZ}_t^\T\nabla_\vx \log\pp{t}{SB}},
        \label{eq:app-coro-proof2}
    \end{split}
    \end{equation}
    where we adopt common practice and assume the limiting behavior of $\pp{t}{SB}$; in other words,
    $\exists k>0: \pp{t}{SB}(\vx) = \calO(\exp^{-\norm{\vx}_k^2})$ as $\vx \rightarrow \infty$.
    With \eqref{eq:app-coro-proof2}, we can rewrite the related parts in \eqref{eq:coro-proof1} as
    \begin{align*}
        &\E\br{ \frac{1}{2} \norm{\widehat{\rvZ}_t}^2 + g \nabla \cdot \widehat{\rvZ}_t + \widehat{\rvZ}_t^\T\rvZ_t} \\
        =& \E\br{ \frac{1}{2} \norm{\widehat{\rvZ}_t}^2 - \widehat{\rvZ}_t^\T\pr{g\nabla \log \pp{t}{SB}} + \widehat{\rvZ}_t^\T\rvZ_t} \\
        =& \E\br{ \frac{1}{2} \norm{\widehat{\rvZ}_t - g\nabla \log \pp{t}{SB} + \rvZ_t}^2 - \frac{1}{2} \norm{g\nabla \log \pp{t}{SB} - \rvZ_t}^2 }. \numberthis
        \label{eq:app-coro-proof3}
    \end{align*}
    Hence, we also recover \eqref{eq:app-sb-nll-bad}.
\end{proof}




 
\textbf{Corollary~\ref{coro:5}} (Probability flow for SB)\textbf{.}
  \textit{
  The following ODE
  characterizes the probability flow of the optimal processes of SB \eqref{eq:sb-sde}
  in the sense that $\forall t,~\pp{t}{\eqref{eq-sb-prob}} \equiv \pp{t}{\eqref{eq:sb-sde}} \equiv \pp{t}{SB}$.}
  \begin{align}
    {\rd \rvX_t = \br{f + g\rvZ(t, \rvX_t) -\frac{1}{2}g~(\rvZ(t, \rvX_t) + \widehat{\rvZ}(t, \rvX_t))} \dt}
    \label{eq:app-sb-prob2}
  \end{align}
\begin{proof}
  The probability ODE flow \citep{song2020score,maoutsa2020interacting} suggests that
  the equivalent ODE model for the SDE \eqref{eq:fsde} is given by
  \begin{align*}
    \rd \rvX_t = \br{f - \frac{1}{2} g^2 \nabla_\vx \log \pp{t}{\eqref{eq:fsde}} } \dt.
  \end{align*}
  We can adopt this result to the SDEs of SB \eqref{eq:fsb} by considering
  $f \leftarrow f + g \rvZ_t$ and $\pp{t}{\eqref{eq:fsde}} \leftarrow \pp{t}{SB}$.
  This yields
  \begin{align}
    \rd \rvX_t = \br{f + g \rvZ_t - \frac{1}{2} g^2\nabla_\vx \log\pp{t}{SB}} \dt.
    \label{eq:app-ode}
  \end{align}
  Applying the the factorization principle \citep{chen2021stochastic} with
  $g\log\pp{t}{SB} = \rvZ_t + \widehat{\rvZ}_t$ concludes the proof.
\end{proof}


\begin{remark}[Connection between SB-FBSDE and flow-based models]\label{remark:app-5}\normalfont
  To demonstrate how applying flow-based training techniques to the probability ODE flow of SB \eqref{eq:app-sb-prob2} recovers the same log-likelihood objective in \eqref{eq:app-sb-nll},
  recall that given an ODE $\rd \rvX_t = F(t,\rvX_t) \dt$ with $\rvX_0 = \vx_0 \sim \pdata$,
  flow-based models compute the change in log-density using the instantaneous change of variables formula \citep{chen2018neural}:
  \begin{align*}
    \fracpartial{\log p(\rvX_t)}{t} = - \nabla_\vx \cdot F,
  \end{align*}
  which implies that the log-likelihood of $\vx_0$ can be computed as
  \begin{align}
    \log p(\rvX_T) = \log p(\vx_0) - \int_0^T {\nabla_\vx \cdot F}~\dt.
    \label{eq:cnf}
  \end{align}
  Now, consider the probability ODE flow of SB in \eqref{eq:app-ode},
  \begin{align*}
    F_{\text{SB}} := f + g\rvZ_t -\frac{1}{2}g(\rvZ_t + \widehat{\rvZ}_t) = f + \frac{1}{2}g(\rvZ_t - \widehat{\rvZ}_t).
  \end{align*}
  Substituting this vector field $F_{\text{SB}}$ to \eqref{eq:cnf} yields
  \begin{align*}
    \log p_T(\rvX_T) &= \log p_0(\vx_0) - \int_0^T {\nabla_\vx \cdot \pr{f + \frac{1}{2}g(\rvZ_t - \widehat{\rvZ}_t)} }\dt \\
  \Rightarrow
    \E\br{\log p_0(\vx_0)} &=~\E\br{\log p_T(\rvX_T)} + \int_0^T \E\br{\nabla_\vx \cdot \pr{f + \frac{1}{2}g(\rvZ_t - \widehat{\rvZ}_t)}}\dt \\
  &=~\E\br{\log p_T(\rvX_T)} - \int_0^T
    \E\br{\nabla_\vx \cdot (g\widehat{\rvZ}_t -f) - \frac{1}{2} g \nabla_\vx \cdot (\rvZ_t + \widehat{\rvZ}_t) } \dt \\
  \overset{(*)}&{=}~\E\br{\log p_T(\rvX_T)} - \int_0^T
    \E\br{\nabla_\vx \cdot (g\widehat{\rvZ}_t -f) + \frac{1}{2}g(\rvZ_t + \widehat{\rvZ}_t)^\T \pr{\nabla_\vx \log \pp{t}{SB} }} \dt \\
  \overset{(**)}&{=}~\E\br{\log p_T(\rvX_T)} - \int_0^T
    \E\br{\nabla_\vx \cdot (g\widehat{\rvZ}_t -f) + \frac{1}{2}(\rvZ_t + \widehat{\rvZ}_t)^2 } \dt,
    \numberthis \label{eq:sb-nll-ode}
  \end{align*}
  where (*) is due to integration by parts (recall \eqref{eq:app-coro-proof2}) and (**) again uses the factorization principle $\rvZ_t + \widehat{\rvZ}_t = g\nabla_\vx \log \pp{t}{SB}$.
  One can verify that \eqref{eq:sb-nll-ode} indeed recovers \eqref{eq:app-sb-nll}.
\end{remark}


\begin{theorem}[FBSDE computation for $\LSB(\vx_T)$ in SB models] \label{thm:9}
  With the same regularity conditions in Theorem~\ref{thm:3},
  the following FBSDEs also satisfy the nonlinear Feynman-Kac relations in \eqref{eq:app-non-fc}.
  \begin{subequations}
  \begin{empheq}[left={\empheqlbrace}]{align}
      \rd \rvX_t &= \pr{f - g \widehat{\rvZ}_t} \dt + g \dwt \label{eq:psi-hat-fbsde-is3a} \\
      \rd \rvY_t &= -\pr{\frac{1}{2} {\rvZ}_t^\T{\rvZ}_t + \nabla_\vx \cdot (g{\rvZ}_t +f) + {\rvZ}_t^\T\widehat{\rvZ}_t } \dt + {\rvZ}_t^\T \dwt \\
      \rd \widehat{\rvY}_t &= -\frac{1}{2} \widehat{\rvZ}_t^\T\widehat{\rvZ}_t \dt + \widehat{\rvZ}_t^\T \dwt
  \end{empheq} \label{eq:psi-hat-fbsde-is3}\end{subequations}
  Given a backward trajectory sampled from \eqref{eq:psi-hat-fbsde-is3a},
  where $\rvX_T=\vx_T$ and $\vx_T \sim \prior$,
  the log-likelihood of $\vx_T$ is given by
  $\log \prior(\vx_T) = \E\br{\rvY_T + \widehat{\rvY}_T | \rvX_T=\vx_T} := \LSB(\vx_T)$. In particular,
  \begin{align}
      \LSB(\vx_T)
      &= \E\br{\log p_T(\rvX_0)} - \int_0^T \E\br{ \frac{1}{2} \norm{\widehat{\rvZ}_t}^2 {+} \frac{1}{2} \norm{{\rvZ}_t}^2  + \nabla_\vx \cdot (g{\rvZ}_t +f) + {\rvZ}_t^\T\widehat{\rvZ}_t } \dt, \label{eq:app-sb-nll2}
  \end{align}
\end{theorem}
\begin{proof}
  Due to the symmetric structure of SB, we can consider a new time coordinate
  \begin{align*}
    s \triangleq T - t.
  \end{align*}
  Under this transformation, the base reference $\PP$ appearing in \eqref{eq:sb} is equivalent to
  \begin{align*}
    \rd \rvX_s &= - f(s, \rvX_s) \ds + g~\dws.
  \end{align*}
  The corresponding PDE optimality becomes
  \begin{align}
      \begin{cases}
      \fracpartial{\Phi}{s} = \nabla_\vx \Phi^\T f {-} \frac{1}{2} \Tr(g^2\nabla^2_{\vx}\Phi) \\[3pt]
      \fracpartial{\widehat{\Phi}}{s} = \nabla_\vx \cdot (\widehat{\Phi} f) {+} \frac{1}{2} \Tr(g^2\nabla^2_{\vx}\widehat{\Phi})
      \end{cases}
      \text{s.t. } \Phi(0,\cdot) \widehat{\Phi}(0,\cdot) = \prior,~\Phi(T,\cdot) \widehat{\Phi}(T,\cdot) = \pdata,
  \end{align}
  and the optimal forward/backward policies are given by
  \begin{subequations}
  \begin{align}
      \rd \rvX_s &= [-f + g^2~\nabla_\vx \log {\Phi}(s,\rvX_s)] \ds + g~\dws,
      \quad \rvX_0 \sim \prior,
      \label{eq:app-fsb}
      \\
      \rd \rvX_s &= [- f - g^2~\nabla_\vx \log \widehat{\Phi}(s,\rvX_s)] \ds + g~\dws,
      \quad \rvX_T \sim \pdata.
      \label{eq:app-bsb}
  \end{align} \label{eq:app-sb-sde}\end{subequations}
  By comparing \eqref{eq:app-sb-sde} with \eqref{eq:sb-sde},
  one can notice that the new SB system $(\Phi, \widehat{\Phi})_s$ corresponds to the original system
  $(\Psi, \widehat{\Psi})_t$ via
  \begin{align}
    \Phi(s, \rvX_s) = \widehat{\Psi}(T-t, \rvX_{T-t}) \qquad \text{and} \qquad
    \widehat{\Phi}(s, \rvX_s) = {\Psi}(T-t, \rvX_{T-t}).
    \label{eq:phi-to-psi}
  \end{align}
  Equation \eqref{eq:phi-to-psi} shall be understood as the forward policy in $t$-coordinate system corresponds to
  the backward policy in $s$-coordinate system, and vise versa.
  Following similar derivations in the proof of Theorem~\ref{thm:3},
  we can apply It{\^o} lemma to expend the stochastic processes $\rd \log \Phi$ and $\rd \log \widehat{\Phi}$ w.r.t. \eqref{eq:app-fsb}. This yields the following FBSDE system.
  \begin{subequations}
  \begin{align}
      \rd \rvX_s &= \pr{g \rvZ^\prime_s - f} \ds + g \dws  \\
      \rd {\rvY}^\prime_s &= \frac{1}{2} \norm{\rvZ^\prime_s}^2 \ds + \rvZ_s^{\prime~\T} \dws  \\
      \rd \widehat{\rvY}^\prime_s &= \pr{\frac{1}{2} \norm{\widehat{\rvZ}^\prime_s}^2 + \nabla_\vx \cdot (g\widehat{\rvZ}^\prime_s +f) + \widehat{\rvZ}_s^{\prime~\T}\rvZ^\prime_s } \ds + \widehat{\rvZ}_s^{\prime~\T} \dws
  \end{align}
  \end{subequations}
  Similar to \eqref{eq:phi-to-psi}, $({\rvY}^\prime_s, \widehat{\rvY}^\prime_s, \rvZ^\prime_s, \widehat{\rvZ}^\prime_s)$ relate to the original FBSDE system \eqref{eq:psi-hat-fbsde-is2} by
  \begin{align}
    ({\rvY}^\prime_s, \widehat{\rvY}^\prime_s, \rvZ^\prime_s, \widehat{\rvZ}^\prime_s)
    = (\widehat{\rvY}^\prime_{T-t}, {\rvY}^\prime_{T-t}, \widehat{\rvZ}^\prime_{T-t}, \rvZ^\prime_{T-t}).
    \label{eq:phi-to-psi2}
  \end{align}
  Changing the coordinate from $s$ to $t$ and applying \eqref{eq:phi-to-psi2} readily
  yield \eqref{eq:psi-hat-fbsde-is3}.
  Finally, the expression in \eqref{eq:app-sb-nll2} can be carried out similar to \eqref{eq:coro-proof1}:
    \begin{align*}
        &\LSB(\vx_T) \\
        =& \E \br{\rvY_T + \widehat{\rvY}_T | \rvX_T=\vx_T} \\
        =& \E\br{{\rvY}_0 - \int_0^T \pr{\frac{1}{2} \norm{\widehat{\rvZ}_t}^2}\dt +
         \widehat{\rvY}_0 - \int_0^T \pr{\frac{1}{2} \norm{{\rvZ}_t}^2 + \nabla \cdot (g{\rvZ}_t +f) + {\rvZ}_t^\T\widehat{\rvZ}_t } \dt \Big| \rvX_T=\vx_T} \\
        =& \E \br{\rvY_0 + \widehat{\rvY}_0 | \rvX_T=\vx_T}
         - \int_0^T \E\br{ \frac{1}{2} \norm{\widehat{\rvZ}_t}^2 + \frac{1}{2} \norm{{\rvZ}_t}^2 + \nabla \cdot (g{\rvZ}_t +f) + {\rvZ}_t^\T\widehat{\rvZ}_t \Big| \rvX_T=\vx_T} \dt  \\
        =& \E [\log p_0(\rvX_0)]
         - \int_0^T {\E\br{ \frac{1}{2} \norm{\widehat{\rvZ}_t}^2 + \frac{1}{2} \norm{{\rvZ}_t}^2 + \nabla \cdot (g{\rvZ}_t +f) + {\rvZ}_t^\T\widehat{\rvZ}_t}} \dt. \numberthis \label{eq:coro-proof2}
    \end{align*}
  We conclude the proof.
\end{proof}












 
\section{Comparison with prior SB works}\label{app:d2}

Our method is closely related to two concurrent SB models \citep{de2021diffusion,vargas2021solving},
yet differs in various aspects. Below we enumerate some of the differences.

\textbf{Training loss.}
  Both concurrent methods rely on solving SB \textit{mean-matching} regression between the current drift and (estimated) optimal drift.
  This is in contrast to our {SB-FBSDE}, which instead utilizes a \textit{divergence-based} objective \eqref{eq:sb-nll}.
  However, the regression objectives are in fact captured by Theorem~\ref{thm:4}.
  To see that, recall the forward and backward transition models considered in \citet{de2021diffusion},
    \begin{align*}
        \rvX_{k+1}\sim\calN(F_k(\rvX_k), 2\gamma_{k+1}\mI), \quad \text{and} \quad
        \rvX_{k}\sim\calN(B_{k+1}(\rvX_{k+1}), 2\gamma_{k+1}\mI),
    \end{align*}
  where $F_k(\vx) := \vx + \gamma_{k+1}f_k(\vx)$ and
    $B_{k+1}(\vx) := \vx + \gamma_{k+1}b_{k+1}(\vx)$
  are solved alternately via
  \begin{subequations}
  \begin{align}
       B_{k+1} \leftarrow &\argmin_{B_{k+1}}~\E\br{ \norm{
            B_{k+1}(\rvX_{k+1}) - (\rvX_{k+1} + F_k(\rvX_k) - F_{k}(\rvX_{k+1}) )
       }^2 } \label{eq:dsm-loss-b} \\
       F_{k}   \leftarrow &\argmin_{F_{k}}~\E\br{ \norm{
            F_{k}(\rvX_{k+1}) - (\rvX_{k} + B_{k+1}(\rvX_k) - B_{k+1}(\rvX_{k}) )
       }^2 }. \label{eq:dsm-loss-f}
  \end{align} \label{eq:dsm-loss}\end{subequations}
  In what follows, we focus mainly on the connection between \eqref{eq:dsm-loss-b} and Theorem~\ref{thm:4}, yet similar analysis can be applied to \eqref{eq:dsm-loss-f}.
  Now, expanding \eqref{eq:dsm-loss-b} with the definition of $(B_{k+1},F_{k})$
    \begin{align*}
         & \norm{B_{k+1}(\rvX_{k+1}) - (\rvX_{k+1} + F_k(\rvX_k) - F_{k}(\rvX_{k+1})}^2 \\
        =& \norm{\pr{\rvX_{k+1} + \gamma_{k+1}b_{k+1}(\rvX_{k+1})}
                 - \pr{\rvX_{k+1} + \rvX_k + \gamma_{k+1}f_k(\rvX_k) - \rvX_{k+1} - \gamma_{k+1}f_k(\rvX_{k+1})}}^2\\
        =& \norm{
            \underbrace{\gamma_{k+1}f_k(\rvX_{k+1})}_{\numcircledmod{1}}
          + \underbrace{\gamma_{k+1}b_{k+1}(\rvX_{k+1})}_{\numcircledmod{2}}
          - \underbrace{\pr{\rvX_k + \gamma_{k+1}f_k(\rvX_k) - \rvX_{k+1}}}_{\numcircledmod{3}}
          }^2, \numberthis
    \end{align*}
    which resembles the term
    $\norm{\rvZ_t + \widehat{\rvZ}_t - g\nabla_\vx \log \pp{t}{SB}}^2$ in \eqref{eq:sb-nll-bad}.
    While \numcircledmod{2} indeed corresponds to our backward policy $\widehat{\rvZ}(k{+}1,\rvX_{k+1})$ after time discretization, \numcircledmod{1} slightly differs from $\rvZ(k{+}1,\rvX_{k+1})$ in how time is integrated, $\gamma_{k+1}f(k, \rvX_{k+1})$ \textit{vs.} ${\rvZ}(k{+}1,\rvX_{k+1})$.
    On the other hand, \numcircledmod{3} may be seen as an approximation of
    $g\nabla_\vx \log \pp{t}{SB}$, which, crucially, is \emph{not} utilized in SB-FBSDE training.
    Since $\nabla_\vx \log \pp{t}{SB}$ is often intractable (nor does SB-FBSDE try to approximate it), SB-FBSDE instead uses the \textit{divergence-based} objective \eqref{eq:sb-nll},
    which does not appear in their practical training.

\textbf{SDE model class.}
    It is important to recognize that both concurrent methods are rooted in
    the \emph{classical} SB formulation with the following SDE model,
    \begin{align*}
        \rd \rvX_t = f(t, \rvX_t) \dt + \sqrt{2\gamma}~\dwt,
    \end{align*}
    which, crucially, differs from the SDE concerned by both our SB-FBSDE and SGM,
    \begin{align}
        \rd \rvX_t = f(t, \rvX_t) \dt + g(t) \dwt,
        \label{eq:sgm-dyn}
    \end{align}
    in that the diffusion $g(t)$ is a \emph{time-varying} function.
    This implies that the connection between classical SB models and SGM can only be made in discrete-time after choosing proper step sizes.
    For instance, \citet{de2021diffusion} considers the Euler-Maruyama discretization (see their $\S$C.3),
    \begin{align}
        \rvX_{k+1} = \rvX_k + \gamma_{k+1} f(k, \rvX_k) + \sqrt{2\gamma_{k+1}}~\epsilon,
        \label{eq:dsb-dyn}
    \end{align}
    where $\epsilon\sim\calN(\mathbf{0}, \mI)$.
    In order for \eqref{eq:dsb-dyn} to match the discretization of \eqref{eq:sgm-dyn},
    where $g(t)$ is often a monotonically increasing function,
    the step sizes $\{\gamma_{k}\}_{k=1}^N$ must also increase monotonically.
    However, since $\nabla_\vx \log \pp{t}{SB}$ is approximated in \citet{de2021diffusion} using the states from two consecutive steps (see \eqref{eq:dsm-loss}), this may also affect the accuracy of the regression targets.

    In contrast, our SB-FBSDE is grounded on the recent SB theory \citep{caluya2021wasserstein}, which considers the \emph{same} SDE model as in \eqref{eq:sgm-dyn}.
    As such,
    connection between SB-FBSDE and SGM is made directly in continuous-time
    (and can be extended to discrete-time flawlessly);
    hence unaffected by the choice of numerical discretization or step sizes.

\textbf{Model parametrization.}
    While \citet{vargas2021solving} utilizes non-parametric models, \eg Gaussian processes (hence are not directly comparable), both \citet{de2021diffusion} and SB-FBSDE use DNNs to approximate the SB policies.




\textbf{Training algorithm and convergence.}
    Both concurrent methods rely on solving SB with IPF algorithm,
    which performs alternate training between the forward/backward policies.
    While SB-FBSDE can also be trained with IPF (see Alg.~\ref{alg:train3}),
    we stress that it is also possible to train \textit{both policies jointly}
    whenever the computational budget permits.
    Interestingly, this joint optimization -- which is not presented in concurrent methods -- resembles the training scheme of the recently-proposed diffusion flow-based model \citep{zhang2021diffusion}.
    We highlight these flexible training procedures arising from the unified viewpoint provided in Theorem~\ref{thm:4}.
    Finally, with the close relation between Alg.~\ref{alg:train3} and IPF
    (despite with different objectives and SDE model classes),
    convergence analysis from classical IPF can be applied with few efforts. We leave it as a promising future work.

\textbf{Corrector Sampling.}
    While both \citet{de2021diffusion} and SB-FBSDE implement corrector sampling, they corresponds to different quantities. Specifically, our SB-FBSDE relies on the same predictor-corrector scheme proposed in SGM (see Sec 4.2 in \citet{song2020score}), where the ``\emph{corrector}'' part is made with a Langevin sampling using the desired optimal density ``$\nabla \log p_t$''. In SB, this term corresponds \emph{exactly} to adding the outputs of our networks "$\mathbf{Z}+\widehat{\mathbf{Z}}$". This computation differs from the corrector sampling appearing in \citet{de2021diffusion}, which relies on single network (\ie either $\mathbf{Z}$ or $\widehat{\mathbf{Z}}$). Crucially, this implies that the two methods is approaching different target distributions; hence leading to different training results. Notably, it has been reported in \citet{de2021diffusion} that corrector sampling only gives negligible improvement (see $\S$J.2 in \citet{de2021diffusion}), yet in our case we observe major quantitative improvement (up to 4 FID).




\section{Experiment Details}
\label{Appendix:Exp_detals}

\textbf{Table~\ref{table:NLL_FID} with other models.}

\begin{figure}[H]
  \vskip -0.15in
  \begin{minipage}{\textwidth}
    \centering
    \captionsetup{type=table}
    \caption{
      CIFAR10 evaluation.
    }
      \vskip -0.05in
      \begin{tabular}{llcccccccc}
        \toprule
        {Model Class} & {Method}  & {NLL $\downarrow$} & {FID $\downarrow$} \\

        \midrule

        \multirow{4}{*}{\specialcelll[l]{Optimal Transport }}
        & \textbf{SB-FBSDE (ours)}             & {2.96} &  3.01 \\[1pt]
        & DOT \citep{tanaka2019discriminator}  &  -     & 15.78 \\[1pt]
        & Multi-stage SB \citep{wang2021deep}  &  -     & 12.32 \\[1pt]
        & DGflow \citep{ansari2020refining}    &  -     &  9.63 \\[1pt]

        \midrule

        \multirow{5}{*}{\specialcelll[l]{SGMs}}
        & SDE (deep, sub-VP; \citet{song2020score})                  & 2.99         & 2.92  \\[1pt]
        & ScoreFlow \citep{song2021maximum}             &2.74 & 5.7  \\[1pt]
        & VDM \citep{kingma2021variational}             &\textbf{2.49} & 4.00  \\[1pt]
        & LSGM\citep{vahdat2021score}                   & 3.43         &\textbf{2.10} \\[1pt]

        \midrule

        \multirow{4}{*}{\specialcelll[l]{VAEs}}
        & VDVAE \citep{child2020very}                   & 2.87         & -     \\[1pt]
        & NVAE \citep{vahdat2020nvae}                   & 2.91         & 23.49 \\[1pt]
        & BIVA \citep{maaloe2019biva}                   & 3.08         & -     \\[1pt]

        \midrule

        \multirow{3}{*}{\specialcelll[l]{Flows}}
        & FFJORD \citep{grathwohl2018ffjord}            &  3.40        & - \\[1pt]
        & VFlow \citep{chen2020vflow}                   &  2.98        & - \\[1pt]
        & ANF  \citep{huang2020augmented}               &  3.05        & - \\[1pt]

        \midrule

        \multirow{3}{*}{\specialcelll[l]{GANs}}
        & AutoGAN \citep{gong2019autogan}               &   -          & 12.42 \\[1pt]
        & StyleGAN2-ADA  \citep{karras2020training}     &   -          &  2.92 \\[1pt]
        & LeCAM \citep{park2021styleformer}             &   -          &  2.47 \\[1pt]

        \bottomrule
      \end{tabular} \label{table:app-NLL_FID}
  \end{minipage}
\end{figure}

\begin{figure}[H]
  \vskip -0.1in
  \begin{minipage}{\textwidth}
    \captionsetup{type=table}
    \caption{Training Hyper-parameters}
    \label{table:hyperparam}
      \centering
      \vskip -0.1in
      \centering
      \begin{tabular}{r|rrrr}
        \toprule
        Dataset & learning rate & time steps & batch size & variance of $\prior$ \\
        \midrule
        Toy                             &2e-4           &100                 & 400 & 1.0\\[1pt]
        Mnist                           &2e-4           &100                & 200 & 1.0\\[1pt]
        CelebA                          &2e-4           &100                 & 200 & 900.0\\[1pt]
        CIFAR10                         &1e-5           &200                  & 64 & 2500.0\\
        \bottomrule
      \end{tabular}
  \end{minipage}
  \vskip 0.15in
  \begin{minipage}{\textwidth}
    \captionsetup{type=table}
    \caption{Network Architectures}
    \label{table:network_arch}
      \centering
      \vskip -0.1in
      \centering
      \begin{tabular}{rcc}
        \toprule
        Dataset &
        ${\rvZ}_t(\cdot,\cdot;\theta)$ and \# of parameters &
        $\widehat{\rvZ}_t(\cdot,\cdot;\phi)$  and \# of parameters \\
        \midrule
        Toy       &FC-ResNet (0.76M)    &  FC-ResNet (0.76M)       \\[1pt]
        Mnist     &reduced Unet (1.95M) &  reduced Unet (1.95M)    \\[1pt]
        CelebA    &Unet      (39.63M)    &  Unet (39.63M)           \\[1pt]
        CIFAR10   & Unet (39.63M)   & NCSN++    (62.69M)           \\
        \bottomrule
      \end{tabular}
  \end{minipage}
\end{figure}

\textbf{Training.}
We use Exponential Moving Average (EMA) with the decay rate of 0.99.
Table~\ref{table:hyperparam} details the hyper-parameters used for each dataset.
{As mentioned in \citet{de2021diffusion},
the alternate training scheme may substantially accelerate the convergence
under proper initialization.
Specifically, when $\rvZ_t$ is initialized with degenerate outputs (\eg by zeroing out its last layer),
training $\widehat{\rvZ}_t$ at the first $K$ steps can be made in a similar SGM fashion
{since $\pp{t}{SB}$ now admits analytical expression}.}
As for the proceeding stages, we resume to use (\ref{eq:high-dim-loss}, \ref{eq:high-dim-loss2}) since $(\rvZ_t, \widehat{\rvZ}_t)$
no longer have trivial outputs.


\textbf{Data pre-processing.}
MNIST is padded from 28$\times$28 to 32$\times$32 to prevent degenerate feature maps through Unet.
CelebA is resized to 3$\times$32$\times$32 to accelerate training.
Both CelebA and CIFAR10 are augmented with random horizontal flips to enhance the diversity.


\begin{wrapfigure}[14]{r}{0.57\textwidth}
  \vspace{-10pt}
  \begin{minipage}{0.57\textwidth}
  \begin{algorithm}[H]
    \small
       \caption{\small Generative Process of SB-FBSDE}
       \label{alg:sample}
    \begin{algorithmic}
     \STATE {\bfseries Input:}
        $\prior$, policies $\rvZ(\cdot,\cdot; \theta)$ and $\widehat{\rvZ}(\cdot,\cdot; \phi)$ \\
       \STATE Sample $\rvX_T \sim \prior$.
       \FOR{$t=T$ {\bfseries to} $\Delta t$ }
         \STATE Sample $\eps \sim \calN(\mathbf{0},\mI)$.
         \STATE Predict $\rvX_{t,1} \leftarrow \rvX_t + g~\widehat{\rvZ}_t \Delta t + \sqrt{g \Delta t} \eps$.
         \FOR{$i=1$ {\bfseries to} $N$ }
           \STATE Sample $\eps_i \sim \calN(\mathbf{0},\mI)$.
           \STATE Compute $\nabla_\vx \log \pp{t,i}{SB} \approx [{\rvZ(t, \rvX_{t,i}) {+} \widehat{\rvZ}(t, \rvX_{t,i})}]/g$.
           \STATE Compute $\sigma_{t,i}$ with \eqref{eq:noise-scale}.
           \STATE Correct $\rvX_{t,i{+}1} \leftarrow \rvX_{t,i} + \sigma_{t,i}\nabla_\vx \log \pp{t,i}{SB} + \sqrt{2\sigma_{t,i}} \eps_i$.
         \ENDFOR
         \STATE Propagate $\rvX_{t-\Delta t} \leftarrow \rvX_{t,N}$.
       \ENDFOR
       \STATE {\bfseries return} $\rvX_0$
    \end{algorithmic}
  \end{algorithm}
  \end{minipage}
\end{wrapfigure}
\textbf{Sampling.}
The sampling procedure is summarized in Alg.~\ref{alg:sample}.
Given some pre-defined signal-to-noise ratio $r$ (we set $r=$0.05 for all experiments), the Langevin noise scale $\sigma_{t,i}$ at each time step $t$ and each corrector step $i$ is computed by
\begin{align}
  \sigma_{t,i} = \frac{2r^2g^2\norm{\epsilon_i}^2}{ \norm{({\rvZ}(t, \rvX_{t,i}) + \widehat{\rvZ}(t, \rvX_{t,i}))}^2},
  \label{eq:noise-scale}
\end{align}


\begin{figure}[t]
  \vskip -0.1in
  \begin{minipage}{\textwidth}
      \centering
      \includegraphics[height=0.15\textwidth]{fig/toy_arch.png}
      \vskip -0.1in
      \caption{
          Network architecture for toy datasets.
      }
      \label{fig:toy_arch}
  \end{minipage}
\end{figure}



\textbf{Network architectures.}
Table~\ref{table:network_arch} summarizes the network architecture used for each dataset.
For toy datasets, we parameterize $\rvZ(\cdot,\cdot;\theta)$ and $\widehat{\rvZ}(\cdot,\cdot;\phi)$ with the architectures shown in Fig.~\ref{fig:toy_arch}.
Specifically, \textit{FCBlock} represents a fully connected layer followed by a swish nonlinear activation \citep{ramachandran2017searching}.
As for MNIST, we consider a smaller version of Unet \citep{ho2020denoising} by reducing
the numbers of residual block, attention heads, and channels respectively to 1, 2, and 32.
Unet and NCSN++ respectively correspond to the architectures appeared in \citet{ho2020denoising} and \citet{song2020score}.

\textbf{Remarks on Table~\ref{table:NLL_FID}.}
We note that the values of our SB-FBSDE reported in Table~\ref{table:NLL_FID} are computed \textit{without} the Langevin corrector due to the computational constraint.
For all other experiments, we adopt the Langevin corrector
as it generally improves the performance (see Fig.~\ref{fig:fid}).
This implies that our results on CIFAR10, despite already being encouraging, may be further improved with the Langevin corrector.


\textbf{Remarks on Fig.~\ref{fig:mnist-kl}.}
To estimating $\mathrm{KL}(\pp{T}{}, \prior)$,
we first compute the pixel-wise first and second moments given the generated samples $\rvX_T$ at the end of the forward diffusion.
After fitting a diagonal Gaussian to $\{\rvX_T\}$,
we can apply the analytic formula for computing the KL divergence between two multivariate Gaussians.

\textbf{Remarks on Fig.~\ref{fig:fid}.}
To accelerate the sampling process with the Langevin corrector,
for this experiment
we consider a reduced Unet (see Table~\ref{table:network_arch}) for CelebA.
The FID scores on both datasets are computed with 10k samples.
We stress, however, that the performance improvement using the Langevin corrector remains consistent across other (larger) architectures and if one increases the FID samples.







\section{Additional Experiments}
\label{appendix:addtional_fig}


\paragraph{Comparison to \citet{de2021diffusion} under same setup.}


To demonstrate the superior performance of our model, we conduct experiments with the exact same setup implemented in \citet{de2021diffusion}. Specifically, we adopt the same network architecture (reduced U-net), image pre-processing (center-cropping 140 pixel and resizing to 32 $\times$ 32), step sizes ($N$=50), and horizon (0.5 second) for fair comparison.
Comparing our Fig.~\ref{fig:DSB_compare-b} to \citet{de2021diffusion} (see their Fig.~6), it is clear that images generated by our model have higher diversity (\eg color skin, facing angle, background, etc) and better visual quality. We conjecture that our performance difference may come from \textit{(i)} the (in)sensitivity to numerical discretization between our divergence objectives and their mean-matching regression, and \textit{(ii)} the foundational differences in how diffusion coefficients are designed.


\begin{figure}[H]\centering
  \subfloat[Ground Truth]{\includegraphics[width=5cm]{fig/ground_truth2.png} \label{fig:DSB_compare-a}}
  \qquad
  \subfloat[SB-FBSDE Generated Image]{\includegraphics[width=5cm]{fig/small_net_sample_stage9.png} \label{fig:DSB_compare-b}}\caption{Comparison between images generated by ground truth and SB-FBSDE on reduced CelebA. Our SB-FBSDE is trained under the same data pre-processing, network architecture and stepsizes implemented in \citet{de2021diffusion}. }\label{fig:DSB_compare}\end{figure}

\begin{figure}[H]
  \vskip -0.3in
  \centering
  \subfloat[SGM/50k]{\includegraphics[width=5cm]{fig/sample_stage50000.png} \label{fig:DSM-vs-SB-a} }\qquad
  \subfloat[SGM/50k + SB/b/5k]
  {\includegraphics[width=5cm]{fig/sample_stage1.png} \label{fig:DSM-vs-SB-b} }\qquad
  \subfloat[SGM/50k + SB/f/5k + SB/b/5k]
  {\includegraphics[width=5cm]{fig/sample_stage2.png} \label{fig:DSM-vs-SB-c} }\caption{
      Qualitative results at the different stages of training.
      \textit{(a)} Results after 50k training iterations using SGM's regression loss.
      \textit{(b)} Refine the results of Fig.~\ref{fig:DSM-vs-SB-a} by training the backward policy using \eqref{eq:high-dim-loss} with 5k iterations.
      \textit{(c)} Refine the results of Fig.~\ref{fig:DSM-vs-SB-a} with a full SB-FBSDE stage using (\ref{eq:high-dim-loss},\ref{eq:high-dim-loss2}).
  }\label{fig:DSM-vs-SB}\end{figure}

\paragraph{SGM regression training + SB divergence-based training.}

Table~\ref{table:SB-refine} reports the FID (using 10k samples, without corrector steps) at different stages of CIFAR10 training. We first train the backward policy with SGM's regression loss for a sufficient long iterations (50k) until the FID roughly converges. Then, we switch to our alternate training (Alg.~\ref{alg:train3}) using the divergence-based objectives.
Crucially, with only 5k iterations of our divergence-based training, we drop the FID dramatically down to 13.35 from 33.68. With a full stage of training (last column), the FID decreases even lower to 11.85.
The qualitative results are provided in Fig.~\ref{fig:DSM-vs-SB}. Comparing Fig.~\ref{fig:DSM-vs-SB-a} (corresponds to ``SGM/50k'' in Table~\ref{table:SB-refine}) and Fig.~\ref{fig:DSM-vs-SB-b} (corresponds to ``SGM/50k + SB/b/5k'' in Table~\ref{table:SB-refine}), it can be seen that the visible flaw and noise have been substantially improved.

\vspace{20pt}

\textbf{Additional Figures}





\begin{figure}[t]
  \vskip 0.1in
  \begin{minipage}{\textwidth}
      \centering
      \captionsetup{type=table}
      \caption{SGM regression training + SB divergence-based training. We denote ``SGM/50k'' as ``training 50k steps using SGM loss'', and ``SB/\{f,b\}/5k'' as ``training forward/backward policy with 5k steps using our divergence loss'', and etc.}
      \vskip -0.1in
      \centering
      \begin{tabular}{r|cccccc}
        \toprule
        & initialization & SGM/10k & SGM/20k & SGM/50k &
        \specialcell[c]{SGM/50k \\ + SB/b/5k} &
        \specialcell[c]{SGM/50k \\ + SB/f/5k + SB/b/5k} \\
        \midrule
         FID & 448 & 41.37 & 35.47 & 33.68 & 13.35 & 11.85 \\
        \bottomrule
      \end{tabular}
      \label{table:SB-refine}
  \end{minipage}
\end{figure}




\begin{figure}[h]
\begin{center}
\includegraphics[width=0.9\textwidth]{fig/mnist-large.png}
\vskip -0.05in
\caption{
    Uncurated samples generated by our SB-FBSDE on MNIST.
}
\end{center}
\end{figure}

\newpage

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.9\textwidth]{fig/celebA-large.png}
\vskip -0.05in
\caption{
    Uncurated samples generated by our SB-FBSDE on resized CelebA.
}
\end{center}
\end{figure}

\newpage

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.9\textwidth]{fig/cifar10-large.png}
\vskip -0.05in
\caption{
    Uncurated samples generated by our SB-FBSDE on CIFAR10.
}
\end{center}
\end{figure}
 


\end{document}
