\documentclass[11pt]{article}

\usepackage{times}
\usepackage{latexsym}
\usepackage{amsfonts,amsthm,amssymb}
\usepackage{euscript}
\usepackage{amstext}
\usepackage{graphicx}
\usepackage{color}
\usepackage{url,hyperref}

\setlength{\textwidth}{6.5in}
\setlength{\topmargin}{0.0in}
\setlength{\headheight}{0in}
\setlength{\headsep}{0.0in}
\setlength{\textheight}{9in}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}


\newtheorem{fact}{Fact}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{theorem}[lemma]{Theorem}
\newtheorem{assumption}[lemma]{Assumption}
\newtheorem{definition}[lemma]{Definition}
\newtheorem{corollary}[lemma]{Corollary}
\newtheorem{proposition}[lemma]{Proposition}
\newtheorem{claim}[lemma]{Claim}
\newtheorem{remark}[lemma]{Remark}
\newtheorem{prob}{Problem}
\newtheorem{conjecture}{Conjecture}
\newtheorem{observation}{Observation}

\renewcommand{\proofname}{\textbf{Proof}}
\newenvironment{proofof}[1]{\smallskip\noindent{\bf Proof of #1:}}{\hspace*{\fill}\par}

\newcommand{\Eqref}[1]{Eq.~(\ref{equation:#1})}
\newcommand{\obsref}[1]{Observation~\ref{observation:#1}}
\newcommand{\lemref}[1]{Lemma~\ref{lemma:#1}}
\newcommand{\clmref}[1]{Claim~\ref{claim:#1}}
\newcommand{\exmref}[1]{Example~\ref{example:#1}}
\providecommand{\conref}[1]{Conjecture~\ref{conj:#1}}
\newcommand{\algref}[1]{Algorithm~\ref{alg:#1}}
\newcommand{\factref}[1]{Fact~\ref{fact:#1}}
\newcommand{\proref}[1]{Proposition~\ref{prop:#1}}
\newcommand{\propref}[1]{Proposition~\ref{prop:#1}}
\newcommand{\exeref}[1]{Exercise~\ref{exer:#1}}
\newcommand{\probref}[1]{Problem~\ref{prob:#1}}
\newcommand{\theoref}[1]{Theorem~\ref{theo:#1}}
\newcommand{\theref}[1]{Theorem~\ref{theo:#1}}
\newcommand{\corref}[1]{Corollary~\ref{cor:#1}}
\newcommand{\figref}[1]{Figure~\ref{fig:#1}}
\newcommand{\tabref}[1]{Table~\ref{tab:#1}}
\newcommand{\Figref}[1]{Figure~\ref{fig:#1}}
\newcommand{\chapref}[1]{Chapter~\ref{chap:#1}}
\newcommand{\secref}[1]{Section~\ref{sec:#1}}
\newcommand{\apndref}[1]{Appendix~\ref{apnd:#1}}

\newcommand{\subsecref}[1]{Section~\ref{subsec:#1}}
\newcommand{\remref}[1]{Remark~\ref{rem:#1}}
\newcommand{\defref}[1]{Definition~\ref{def:#1}}
\newcommand{\mchapref}[1]{\ref{chap:#1}}
\newcommand{\msecref}[1]{\ref{sec:#1}}
\newcommand{\msubsecref}[1]{\ref{subsec:#1}}
\newcommand{\mtheoref}[1]{\ref{theo:#1}}
\newcommand{\mfigref}[1]{\ref{fig:#1}}
\newcommand{\eqnref}[1]{(\ref{eqn:#1})}

\providecommand{\conlab}[1]{\label{conj:#1}}
\newcommand{\remlab}[1]{\label{rem:#1}}
\newcommand{\obslab}[1]{\label{observation:#1}}
\newcommand{\alglab}[1]{\label{alg:#1}}
\newcommand{\eqlab}[1]{\label{equation:#1}}
\newcommand{\exmlab}[1]{\label{example:#1}}
\newcommand{\lemlab}[1]{\label{lemma:#1}}
\newcommand{\clmlab}[1]{\label{claim:#1}}
\providecommand{\deflab}[1]{\label{def:#1}}
\newcommand{\factlab}[1]{\label{fact:#1}}
\newcommand{\prolab}[1]{\label{prop:#1}}
\newcommand{\proplab}[1]{\label{prop:#1}}
\newcommand{\exelab}[1]{\label{exer:#1}}
\newcommand{\theolab}[1]{\label{theo:#1}}
\newcommand{\problab}[1]{\label{prob:#1}}
\newcommand{\thelab}[1]{\label{theo:#1}}
\newcommand{\chaplab}[1]{\label{chap:#1}}
\newcommand{\eqnlab}[1]{\label{eqn:#1}}
\newcommand{\corlab}[1]{\label{cor:#1}}
\newcommand{\figlab}[1]{\label{fig:#1}}
\newcommand{\tablab}[1]{\label{tab:#1}}
\newcommand{\seclab}[1]{\label{sec:#1}}
\newcommand{\apndlab}[1]{\label{apnd:#1}}
\newcommand{\subseclab}[1]{\label{subsec:#1}}

\newcommand{\opt}{\textrm{\sc OPT}}
\newcommand{\etal}{et al.\ }
\newcommand{\eps}{\epsilon}
\newcommand{\st}{S} \newcommand{\Algorithm}[1]{{\texttt{\bf{#1}}}} \newcommand{\sbg}{\Algorithm{SSF-W}} \newcommand{\sug}{\Algorithm{SSF}} \newcommand{\mmug}{\Algorithm{SSF-ID}} 


\begin{document}
\title{Online Scheduling to Minimize the Maximum Delay Factor}
\author{
Chandra Chekuri\thanks{Department of Computer Science,
University of Illinois, 201 N.\ Goodwin Ave.,
Urbana, IL 61801. {\tt chekuri@cs.uiuc.edu}.
Partially supported by NSF grants CCF 0728782
 and CNS 0721899. }
\and
Benjamin Moseley\thanks{Department of Computer Science,
University of Illinois, 201 N.\ Goodwin Ave.,
Urbana, IL 61801. {\tt bmosele2@uiuc.edu}.
}
}
\date{\today}
\maketitle


\begin{abstract}
  In this paper two scheduling models are addressed. First is the
  standard model (unicast) where requests (or jobs) are
  independent. The other is the broadcast model where broadcasting a
  page can satisfy multiple outstanding requests for that page. We
  consider online scheduling of requests when they have deadlines.
  Unlike previous models, which mainly consider the objective of
  maximizing throughput while respecting deadlines, here we focus on
  scheduling all the given requests with the goal of minimizing the
  maximum {\em delay factor}. The delay factor of a schedule is
  defined to be the minimum  such that each request 
  is completed by time  where  is the
  arrival time of request  and  is its deadline. Delay factor
  generalizes the previously defined measure of maximum stretch which
  is based only the processing times of requests
  \cite{BenderCM98,BenderMR02}.

  We prove strong lower bounds on the achievable competitive ratios
  for delay factor scheduling even with unit-time requests. Motivated
  by this, we then consider resource augmentation analysis
  \cite{KalyanasundaramP95} and prove the following positive results.
  For the unicast model we give algorithms that are -speed
  -competitive in both the single machine and
  multiple machine settings. In the broadcast model we give an
  algorithm for similar-sized pages that is -speed -competitive. For arbitrary page sizes we give an
  algorithm that is -speed -competitive.
\end{abstract}

\setcounter{page}{0}
\thispagestyle{empty}
\clearpage

\section{Introduction}
Scheduling requests (or jobs\footnote{In this paper we use requests
  instead of jobs since we also address the broadcast scheduling
  problem where a request for a page is more appropriate terminology
  than a job.}) that arrive online is a fundamental problem faced by
many systems and consequently there is a vast literature on this
topic. A variety of models and performance metrics are studied in
order to capture the requirements of a system. In this work, we
consider a recently suggested performance measure called {\em delay
  factor} \cite{ChangEGK08} when each request has an {\em arrival
  time} (also referred to as release time) and a {\em deadline}. We
consider both the traditional setting where requests are independent,
and also the more recent setting of broadcast scheduling when
different requests may ask for the same page (or data) and can be
simultaneously satisfied by a single transmission of the page. We
first describe the traditional setting, which we refer to as the {\em
  unicast} setting, to illustrate the definitions and and then
describe the extension to the {\em broadcast} setting.

We assume that requests arrive {\em online}. The arrival time ,
the deadline , and the processing time  of a request
 are known only when  arrives. We refer to the quantity  as the {\em slack} of request . There may be a single
machine or  identical machines available to process the
requests. Consider an online scheduling algorithm . Let 
denote the completion time or finish time of  under . Then the
delay factor of  on a given sequence of requests  is
defined as . In other words  measures the
factor by which  has delayed jobs in {\em proportion} to their
slack. The goal of the
scheduler is to minimize the (maximum) delay factor. We consider
worst-case competitive analysis. An online algorithm  is
-competitive if for all request sequences ,
 where  is
the delay factor of an optimal offline algorithm.  Delay factor
generalizes the previously studied maximum stretch measure introduced
by Bender, Chakraborty and Muthukrishnan \cite{BenderCM98}. The
maximum stretch of a schedule  is  where  is the length or processing time of
. By setting  for each request  it can be
seen that delay factor generalizes maximum stretch.

In the broadcast setting, multiple requests can be satisfied by the
same transmission. This model is inspired by a number of recent
applications --- see \cite{BarnoyBNS98, AksoyF98, AcharyaFZ95,
  BartalM00} for the motivating applications and the growing
literature on this topic. More formally, there are  distinct pages
or pieces of data that are available in the system, and clients can
request a specific page at any time. This is called the {\em
  pull-model} since the clients initiate the request and we focus on
this model in this paper (in the push-model the server transmits the
pages according to some frequency). Multiple outstanding requests for
the same page are satisfied by a single transmission of the page. We
use  to denote 'th request for a page . We let  and  denote the arrival
time and deadline of the request . The finish time
 of a request  is defined to be the earliest time after
 when the page  is sequentially transmitted by the
scheduler. Note that multiple requests for the same page can have the
same finish time. The delay factor  for an algorithm  over
a sequence of requests  is now defined as .

\medskip
\noindent {\bf Motivation:} There are a variety of metrics in the
scheduling literature and some of the well-known and widely used ones
are makespan and average response time (or flowtime). More recently,
other metrics such as maximum and average stretch, which measure the
waiting time in proportion to the size of a request, have been
proposed \cite{BenderCM98, Karger99, Sgall98}; these measures were
motivated by applications in databases and web server systems. Related
metrics include  norms of response times and stretch
\cite{BansalP03, AvrahamiA03, ChekuriGKK04} for . In
a variety of applications such as real-time systems and data gathering
systems, requests have deadlines by which they desire to be
fulfilled. In real-time systems, a {\em hard} deadline implies that it
cannot be missed, while a {\em soft} deadline implies some flexibility
in violating it. In online settings it is difficult to respect hard
deadlines. Previous work has addressed hard deadlines by either
considering periodic tasks or other restrictions \cite{Burnsb08}, or
by focusing on maximizing throughput (the number of jobs completed by
their deadline) \cite{Kimc04, ChanLTW04, ZhengFCCPW06}. It was
recently suggested by Chang \etal \cite{ChangEGK08} that delay factor
is a useful and natural relaxation to consider in situations with soft
deadlines where we desire all requests to be satisfied. In addition,
as we mentioned already, delay factor generalizes maximum stretch
which has been previously motivated and studied in
\cite{BenderCM98,BenderMR02}.

\medskip
\noindent {\bf Results:} We give the first results for {\em online}
scheduling for minimizing delay factor in both the unicast and
broadcast settings. Throughout we assume that requests are allowed to
be {\em preempted} if they have varying processing times. We first
prove strong lower bounds on online competitiveness.
\begin{itemize}
\item For unicast setting no online algorithm is
  -competitive where  is the ratio between
  the maximum and minimum slacks.
\item For broadcast scheduling with  unit-sized pages there is no
-competitive algorithm.
\end{itemize}
We resort to resource augmentation analysis, introduced by of
Kalyanasundaram and Pruhs \cite{KalyanasundaramP95}, to overcome the
above lower bounds. In this analysis the online algorithm is given
faster machines than the optimal offline algorithm. For , an
algorithm  is -speed -competitive if  when given -speed
machine(s) achieves a competitive ratio of . We prove the
following.
\begin{itemize}
\item For unicast setting, for any , there are -speed
  -competitive algorithms in both single and multiple machine
  cases. Moreover, the algorithm for the multiple machine case immediately
  dispatches an arriving request to a machine and is non-migratory.
\item For broadcast setting, for any , there is a
  -speed -competitive algorithm for unit-sized
  (or similar sized) pages.  If pages can have varying length, then
  for any , there is a -speed
  -competitive algorithm.
\end{itemize}

Our results for the unicast setting are related to, and borrow
ideas from, previous work on minimizing  norms of response
time and stretch \cite{BansalP03} in the single machine and
parallel machine settings \cite{AvrahamiA03,ChekuriGKK04}.

Our main result is for broadcast scheduling. Broadcast scheduling has
posed considerable difficulties for algorithm design. In fact most of
the known results are for the {\em offline} setting
\cite{KalyanasundaramPV00,ErlebachH02,GandhiKKW04,GandhiKPS06,BansalCS06,BansalCKN05}
and several of these use resource augmentation! The difficulty in
broadcast scheduling arises from the fact that the online algorithm
may transmit a page multiple times to satisfy distinct requests for
the same page, while the offline optimum, which knows the sequence in
advance, can {\em save work} by gathering them into a single
transmission. Online algorithms that maximize throughput
\cite{Kimc04,ChanLTW04,ZhengFCCPW06,ChrobakDJKK06} get around this by
eliminating requests. Few positive results are known in the online
setting where all requests need to be scheduled
\cite{BartalM00,EdmondsP03,EdmondsP04} and the analysis in all of
these is quite non-trivial.
\iffalse
Only two online results are of known for metrics
that require all requests to be scheduled. One is for maximum response
time where a factor of  is shown for FIFO (first-in first-out)
\cite{BartalM00,ChangEGK08}. The other is a -speed
-competitive algorithm for average response time by Edmonds
and Pruhs \cite{EdmondsP03}; their algorithm is an indirect reduction
to a complicated algorithm of Edmonds \cite{Edmonds00} for
non-clairvoyant scheduling.
\fi
In contrast, our algorithm and analysis
are direct and explicitly demonstrate the value of making requests
wait for some duration so as to take advantage of potential future
requests for the same page. We hope this idea can be further exploited
in other broadcast scheduling contexts. We mention that even in the
{\em offline} setting, only an LP-based -speed algorithm is known
for delay factor with unit-sized pages \cite{ChangEGK08}.

\medskip
\noindent {\bf Related Work:} We refer the reader to the survey on
online scheduling by Pruhs, Sgall and Torng \cite{PruhsST} for a
comprehensive overview of results and algorithms (see also
\cite{Pruhs07}). For jobs with deadlines, the well-known
earliest-deadline-first (EDF) algorithm can be used in the offline
setting to check if all the jobs can be completed before their
deadline. A substantial amount of literature exists in the real-time
systems community in understanding and characterizing restrictions on
the job sequence that allow for schedulability of jobs with deadlines
when they arrive online or periodically. Previous work on soft
deadlines is also concerned with characterizing inputs that allow for
bounded tardiness. We refer the reader to
\cite{RealtimeHandbook} for the extensive literature
scheduling issues in real-time systems.

Closely related to our work is that on max stretch \cite{BenderCM98}
where it is shown that no online algorithm is  competitive
even in the preemptive setting where  is ratio of the largest job
size to the smallest job size. \cite{BenderCM98} also gives an
 competitive algorithm which was further refined in
\cite{BenderMR02}. Resource augmentation analysis for  norms of
response time and stretch from the work of Bansal and Pruhs
\cite{BansalP03} implicitly shows that the shortest job first (SJF)
algorithm is a -speed -competitive algorithm for
max stretch. Our work shows that this analysis can be generalized for
the delay factor metric. For multiple processors our analysis is
inspired by the ideas from \cite{AvrahamiA03,ChekuriGKK04}.

Broadcast scheduling has seen a substantial amount of research in
recent years; apart from the work that we have already cited we refer
the reader to \cite{CharikarK06,KhullerK04}, the recent paper of Chang
\etal \cite{ChangEGK08}, and the surveys \cite{PruhsST,Pruhs07} for
several pointers to known results. Our work on delay factor is
inspired by \cite{ChangEGK08}.  As we mentioned already, a good
amount of the work on broadcast scheduling has been on offline
algorithms including NP-hardness results and approximation algorithms
(often with resource augmentation). For delay factor there is a
-speed optimal algorithm in the {\em offline} setting and it is
also known that unless  there is no  approximation
\cite{ChangEGK08}. In the online setting the following results are
known.  For maximum response time, it is shown in
\cite{BartalM00,ChangEGK08} that first-in-first-out (FIFO) is
-competitive.  For average response time,
Edmonds and Pruhs \cite{EdmondsP03} give a -speed
-competitive algorithm; their algorithm is an indirect
reduction to a complicated algorithm of Edmonds \cite{Edmonds00} for
non-clairvoyant scheduling. They also show in \cite{EdmondsP04} that
longest-wait-first (LWF) is a -speed -competitive algorithm
for average response time.  Constant competitive online
algorithms for maximizing throughput
\cite{Kimc04,ChanLTW04,ZhengFCCPW06,ChrobakDJKK06} for unit-sized
pages.

\medskip
\noindent
We describe our results for the unicast setting
in Section~\ref{sec:unicast} and for the broadcast settings in
Section~\ref{sec:broadcast}.

\medskip
\noindent
{\bf Notation:}
We let  denote the slack of  in the unicast
setting. When requests have varying processing times (or lengths) we
use  to denote the length of . We assume without loss
of generality that .
In the broadcast setting,  denotes the 'th request for
page . We assume that the requests for a page are ordered by time
and hence  for .
In both settings we use  to denote the ratio of maximum slack
to the minimum slack in a given request sequence.

\section{Unicast Scheduling}
\label{sec:unicast}
In this section we address the unicast case where requests are
independent. We may thus view requests as jobs although we stick with
the use of requests. For a request , recall that
 denote the arrival time, deadline, length, and
finish time respectively. An instance with all  (or more
generally the processing times are the same) is referred to as a
unit-time instance. It is easy to see that preemption does not help
much for unit-sized instances. Assuming that the processing times are
integer valued then in the single machine setting one can reduce an
instance with varying processing time to an instance with unit-times
as follows. Replace , with length , by 
unit-sized requests with the same arrival and deadline as that of
.

As we had remarked earlier, scheduling to minimize the maximum stretch
is a special case of scheduling to minimize the maximum delay factor.
In \cite{BenderCM98} a lower bound of  is shown for online
maximum stretch on a -speed machine where  is the ratio of the
maximum processing time to the minimum processing time. They show that
this bounds holds even when  is known to the algorithm.  This
implies a lower bound of  for minimizing the maximum delay
factor. Here we improve the lower bound for maximum stretch to
 when the online algorithm is not aware of . A proof
can be found in the appendix.

\begin{theorem}
  \label{thm:unicast_lb}
  There is no -speed -competitive algorithm
  for online maximum stretch when  is not known in advance to
  the algorithm.
\end{theorem}

\begin{corollary}
\label{delayonlylower}
There is no -speed -competitive algorithm
for delay factor scheduling when  is not known in advance with unit-time requests.
\end{corollary}

In the next two subsections we show that with  resource
augmentation simple algorithms achieve an  competitive
ratio.

\subsection{Single Machine Scheduling}
\label{unicast-single}

We analyze the simple shortest-slack-first () algorithm
which at any time  schedules the request with the shortest slack.

\begin{center}
\begin{tabular}[r]{|c|}
\hline
\textbf{Algorithm}: \sug \\

\begin{minipage}{13cm}
\begin{itemize}
\item At any time  schedule the request with with the minimum stretch
which has not been satisfied.
\end{itemize}
\end{minipage}\\\\

\hline
\end{tabular}
\end{center}


\begin{theorem}
\label{thm:ssf-single-machine}
The algorithm  is -speed -competitive
for minimizing the maximum delay factor in unicast scheduling.
\end{theorem}
\begin{proof}
  Consider an arbitrary request sequence  and let  be
  the maximum delay factor achieved by  on . If  there is nothing to prove, so assume that .  Let
   be the request that witnesses , that is . Note that  does not process any request with slack
  more than  in the interval . Let  be the largest
  value less than or equal to  such that  processed only
  requests with slack at most  in the interval . It
  follows that  had no requests with slack  just before
  . The total work that  processed in  on requests
  with slack less than equal to  is  and all
  these requests arrive in the interval . An optimal offline
  algorithm with -speed can do total work of at most  in
  the interval  and hence the earliest time by which it can
  finish these requests is . Since all these requests have slack at most  and have
  arrived before , it follows that  where  is the maximum delay factor of the
  optimal offline algorithm with -speed machine. Therefore, we have
  that .
\end{proof}

\begin{remark}
  For unit-time requests, the algorithm that {\em non-preemptively}
  schedules requests with the shortest slack is a -speed -competitive for maximum delay factor.
\end{remark}

\subsection{Multiple Machine Scheduling}
\label{unicast-multi}

We now consider delay factor scheduling when there are 
machines. To adapt  to this setting we take intuition from
previous work on minimizing  norms of flow time and stretch
\cite{BansalP03,AvrahamiA03,ChekuriGKK04}. We develop an algorithm
that immediately dispatches an arriving request to a machine, and
further does not migrate an assigned request to a different
machine once it is assigned. Each machine essentially runs the
single machine  algorithm and thus the only remaining
ingredient to describe is the dispatching rule. For this purpose
the algorithm groups requests into classes based on their slack. A
request  is said to be in class  if . The algorithm maintains the total processing time of
requests (referred to as {\em volume}) that have been assigned to
machine  in each class . Let  denote the total
processing time of requests assigned to machine  by time  of class .
With this notation, the algorithm  (for  with
immediate dispatch) can be described.

\begin{center}
\begin{tabular}[r]{|c|}
\hline
\textbf{Algorithm}: \mmug \\

\\

\begin{minipage}{13cm}
\begin{itemize}
\item When a new request  of class  arrives at time ,
assign it to a machine  where .
\item Use  on each machine separately.
\end{itemize}
\end{minipage}\\\\

\hline
\end{tabular}
\end{center}

The rest of this section is devoted to the proof of the following
theorem.
\begin{theorem}
\label{thm:multiple}
 is a -speed -competitive algorithm for online delay factor
scheduling on  machines.
\end{theorem}

We need a fair amount of notation. For each time , machine , and
class  we define several quantities. For example  is
the total volume assigned to machine  in class  by time . We
use the predicate ``'' to indicate classes  to .  Thus  is the total volume assigned to machine  in classes  to
. We let  to denote the remaining processing time on
machine  at time  and let  denote the total volume
that  has finished on requests in class  by time . Note that
. All these quantities refer
to the algorithm . We use  and  to
denote the remaining volume of requests in class  in an optimal
offline algorithm with speed  and  with speed ,
respectively. Observe that .  The
quantities  and  are defined
analogously.

The algorithm  balances the amount of processing time for
requests with similar slack.  Note that the assignment of requests
is not based on the current volume of unfinished requests on the
machines, rather the assignment is based on the volume of requests
that were assigned in the past to different machines.  We begin
our proof by showing that the volume of processing time of
requests less than or equal to some slack class is almost
the same on the different machines at any time. Several of these
lemmas are essentially the same as in \cite{AvrahamiA03}.

\begin{observation}
\label{observation} For any time  and two machines  and ,
.  This also implies that
.
\end{observation}
\begin{proof}
  The first inequality holds since all of the requests of class 
  are of size .  The second inequality follows easily
  form the first.
\end{proof}

Proofs of the next two lemmas can be found in the appendix.


\begin{lemma}
  \lemlab{processbound} Consider any two machines  and .  The
  difference in volume of requests that have already have been
  processed is bounded as .
\end{lemma}

\begin{lemma}
  \lemlab{closebound} At any time  the difference between the
  residual volume of requests that needs to be processed, on any two
  different machines,  and  is bounded as .
\end{lemma}


\begin{corollary}
  \corlab{optarrival} At any time , .
\end{corollary}




Now we get to the proof of the upper bound on \mmug, when given -speed, in a similar fashion to the single machine
case. Consider an arbitrary request sequence  and let  be
the request that witnesses the delay factor  of  on .
Let  be the class of . Therefore .
Also, let  be the machine on which  was processed by .
We use  to denote the delay factor of some fixed optimal
offline algorithm that uses  machines of speed .

Let  be the last time before  when machine  processed a request
of class . Note that  since  does not process any
request of class  in the interval . At time  we
know by \corref{optarrival} that . If  then 
achieves a competitive ratio of  since  is in class
. Thus we will assume from now on that .

In the interval ,  completes a total volume of of
 on machine . Using \lemref{processbound}, any
other machine  also processes a volume of  in . Thus the total volume processed by  during 
in requests of classes  is at least .  During , the optimal algorithm finishes at most
 volume in classes .  Combining this with
\corref{optarrival}, we see that

In the penultimate inequality we use the fact that . Without loss of generality assume that no
requests arrive exactly at . Therefore  is the
total volume of requests in classes  to  that the optimal
algorithm has left to finish at time  and all these requests have
arrived before . The earliest time that the optimal algorithm can
finish all these requests is by  and therefore it
follows that . Since  and , it follows that .

Thus  which finishes the proof
of Theorem~\ref{thm:multiple}.

\section{Broadcast Scheduling}
\label{sec:broadcast} We now move our attention to the broadcast
model where multiple requests can be satisfied by the transmission
of a single page.
Most of the literature in broadcast scheduling is concerned with the
case where all pages have the same size which is assumed to be unit. A
notable exception is the work of Edmonds and Pruhs
\cite{EdmondsP03}. Here we consider both the unit-sized as well as
arbitrary sized pages.

We start by showing that no -speed online algorithm can be -competitive for delay factor
where  is the total number of unit-sized pages. We then show in
Section~\ref{broadcast-single} that there is a -speed
-competitive algorithm for unit-sized pages. We prove
this for the single machine setting and it readily extends to the
multiple machine case. Finally,  we extend our algorithm and analysis to
the case of different page sizes to obtain a -speed
-competitive algorithm in Section~\ref{subsec:varying}.
We believe that this can be extended to the multiple machine setting
but leave it for future work.



\begin{theorem}
  \label{broadcast-lower} Every -speed online algorithm for broadcast
  scheduling to minimize the maximum delay factor is -competitive
  where  is number of unit-sized pages.
\end{theorem}

The proof of Theorem~\ref{broadcast-lower} can be found in the appendix.

\subsection{A Competitive Algorithm for Unit-sized Pages}
\label{broadcast-single}

We now develop an online algorithm, for unit-sized pages, that is
competitive given extra speed. It is easy to check that unlike in the
unicast setting, simple algorithms such as  fail to be constant
competitive in the broadcast setting even with extra speed. The reason
for this is that any simple algorithm can be made to do an arbitrary
amount of ``extra'' work by repeatedly requesting the same page while
the adversary can wait and finish all these requests with a single
transmission. We use this intuition to develop a variant of 
that {\em adaptively} introduces waiting time for requests.  The
algorithm uses a single real-valued parameter  to control the
waiting period. The algorithm  ( with waiting) is formally
defined below. We note that the algorithm is non-preemptive in that a
request once scheduled is not preempted. As we mentioned earlier, for
unit-sized requests, preemption is not very helpful. The algorithm
keeps track of the maximum delay factor it has seen so far,
, and this depends on requests that are yet to be completed
(we set ). The important feature of the algorithm is
that it considers requests for scheduling only after they have waited
sufficiently long when compared to their {\em adaptive} slack.

\begin{center}
\begin{tabular}[r]{|c|}

\hline

\textbf{Algorithm}: \sbg \\

\\

\begin{minipage}{16cm}
\begin{itemize}
\item Let  be the maximum delay factor  has at
time .

\item At time ,  let J_{(p,i)}{{t - a_{(p,i)} \over {\st_{p,i}}} } \geq c \alpha_t \st_{(p,i)}.

\item If the machine is free at , schedule the request in
 with the smallest slack {\em non-preemptively}.
\end{itemize}
\end{minipage}\\

\hline
\end{tabular}
\end{center}
\vspace{4mm}

We now analyze  when it is given a -speed
machine. Let  be an arbitrary sequence of requests. Consider
the \emph{first} time  where  achieves the maximum delay
factor . At time ,  must have finished a
request  which caused  to have this delay
factor. Hence,  has a maximum delay factor of  where  is the time  satisfies
request . We let  denote some fixed offline optimum
algorithm and let  denote the optimum delay factor.

We now prove the most interesting difference between unicast and
broadcast scheduling. The following lemma shows that forcing a request
to wait in the queue, for a small period of time, can guarantee that
our algorithm is satisfying as many requests as  by a single
broadcast unless  has a similar delay factor.

Since  defines , we observe that from time
, the request
 is ready to be scheduled and hence the algorithm is
continuously busy in the interval  processing
requests of slack no more than that of .

\begin{lemma}
  \label{lem:main}
  Consider the interval . Suppose two distinct
  requests  and  for the same page  were
  satisfied by  during  at different times. If 
  satisfies both of these requests by a single broadcast then
  .
\end{lemma}

\begin{proof}
  Without loss of generality assume that ; therefore . Request  must have arrived during ,
  otherwise  would have satisfied  when it satisfied
  . We observe that  since  is
  still alive at .

  Since  was scheduled after , it follows that  would
  have made it wait at least  which implies
  that
  
  Note that  satisfies  by a separate broadcast from
   which implies that . However, 
  satisfies both requests by the same transmission which implies
  that  finishes  no earlier than . Therefore
  the delay factor of  is at least the delay factor for  in
   which implies that

\end{proof}

Note that previous lemma holds for any two requests scheduled by
 during interval  regardless of when  schedules them,
perhaps even after .

\begin{lemma}
  \label{lem:arrivaltime}
  Consider the interval . Any request which
   scheduled during  must have arrived after time .
\end{lemma}

\begin{proof}
  For sake of contradiction, assume that a request 
  scheduled by  on the interval  has arrival time less than
  . Since  finishes
  this request during , .
  Also, as we observed before, all requests scheduled during  by
   have slack no more than that of  which implies
  that . However this implies that
  the delay factor of  is at least
    

      This is a contradiction to the fact that  is the
      first request that witnessed the maximum delay factor of \sbg.
\end{proof}

\medskip

Now we are ready to prove the competitiveness of .

\begin{lemma}
  \lemlab{eps-ceps-c-competitive} The algorithm  when given a
  -speed machines satisfies .
\end{lemma}

\begin{proof}
The number of broadcasts which  transmits during the
interval  is


From Lemma~\ref{lem:arrivaltime}, all the requests processed during
 have arrived no earlier than . Also, each of these requests has slack no more than
. We restrict attention to the requests satisfied by 
during . We consider two cases

First, if there are two requests for the same page that  satisfies
via distinct broadcasts but  satisfies using one broadcast, then
by Lemma~\ref{lem:main},  and we
are done.

Second, we assume that  does not merge two requests for the same
page whenever  does not do so. It follows that  also has
to broadcast  pages to satisfy
the requests that  did during . Since these
requests arrived no earlier than ,
, which has a -speed machine, can finish them at the earliest
by


Since each of these requests has slack at most  and arrived
no later than , we have that

\end{proof}

The previous lemma yields the following theorem.

\begin{theorem}
  With ,  is a -speed -competitive algorithm for minimizing the maximum delay
  factor in broadcast scheduling with unit-sized pages.
\end{theorem}

It may appear that  needs knowledge of . However, another
way to interpret \lemref{eps-ceps-c-competitive} is that for any fixed
constant ,  with parameter  is constant competitive in all
settings where its machine is at least  times the speed
of the optimal algorithm. Of course, it would be ideal to have an
algorithm scales with  without any knowledge of . We leave
the existence of such an algorithm for future work.

Now consider having  machines where we have -speed.
Since we are using unit time requests, this is analogous to 
having one -speed machine and  having a -speed machine.  Thus, one can extend the above analysis to
the multiple machine setting with unit-sized pages in a
straight forward fashion.

\iffalse
\begin{theorem}
For some constant ,  is a -speed -competitive algorithm for minimizing the maximum
delay factor in broadcast scheduling with unit-time requests with
 machines.
\end{theorem}
\fi

\subsection{Varying Page Sizes}
\label{subsec:varying}
In this section we generalize our algorithm for unit-sized pages to
the setting where each page has potentially a different page size. We
let  denote the length of page . In this setting we allow
preemption of transmissions. Suppose the transmission of a page  is
started at time  and ends at time ;  may be preempted for
other transmissions and hence .  A request for a page
 is satisfied by the transmission of  during the interval  only if the request arrives before . It is possible that
the transmission of a page  is abandoned and {\em restarted} due to
the arrival of a new request for  with a smaller slack.  This may
lead to further wasted work by the algorithm and increases the
complexity of the analysis. Here we show that a natural adaptation of
 is competitive even in this more general setting if it is given -speed.

We outline the details of modifications to . As before, at any time , the algorithm considers broadcasting a
request  if ; these are requests that have waited long
enough.  Among these requests, the one with the smallest slack is
scheduled. Note that the waiting is only for requests that have not
yet been started; any request that has already started transmission is
available to be scheduled.  The algorithm breaks ties arbitrarily, yet
ensures that if a request  is started before a request
 then  will be finished before request
. Note that the algorithm may preempt a request
 by another request  for the same page  even
though  if . In this case the
transmission of  is effectively abandoned. Note that
transmission of a page  may be repeatedly abandoned.

We now analyze the algorithm assuming that it has a -speed
advantage over the optimal offline algorithm. The extra factor in
speed is needed in our analysis to handle the extra wasted work due to
potential retransmission of a page  after a large portion of it has
already been transmitted.  As before, let  be a sequence of
requests and let  be the \emph{first} time  achieves the
maximum delay factor .  At time , it must be the
case that a request  was finished which caused  to
have his maximum delay factor.  Hence,  has a maximum delay
factor of  where  is
the time  satisfied request .

As with the case with unit time requests, at time  the request  is ready to be
scheduled and the algorithm is busy on the interval  processing requests of slack at most .

We say that a request  is {\em started} at time  if 
is the first time at which the algorithm picked  to
transmit its page. Multiple requests may be waiting for the same page
 but only the request with the smallest slack that is picked by the
algorithm is said to be started. Thus a request may be satisfied
although it is technically not started. Also, a request 
that is started may be abandoned by the start of another request for
the same page.

The lemma below is analogous to Lemma~\ref{lem:main} but requires
a more careful statement since requests may now be started and
abandoned.

\begin{lemma}
  \label{mainvarying} Consider two distinct requests  and
   for the same page  where  such that they are
  both satisfied by  via the same transmission. If  starts
   in  before the arrival of ,
  then  .
\end{lemma}

Observe that the request  may be satisfied together with
 even though it starts before the arrival of .

\begin{proof}
  As before,  since  is
  still alive at . Since  is started after , it
  follows that  would have made it wait at least . Let  be the start time of
  . Therefore . By our assumption,  and therefore
  .

  Since  satisfies these two requests by the same transmission,
  the finish time of  in  is at least .
  Therefore,


\end{proof}


\iffalse
\begin{lemma}
\label{lem:varyingwork} Assume  does not satisfy any two
requests in a single broadcast which  started satisfying in
separate broadcasts in .  must complete at least
 the volume of work  completes on the interval
.
\end{lemma}
\begin{proof}
  First, note that any request started in  by , must
  also be finished by .  This holds for all requests, even if
  the request is partially satisfied by  by time .
  Consider a sequence of requests  such that 's started being satisfied
  before time , , and each of the other
  requests started being satisfied in  by separate
  broadcasts. By assumption, all of the requests  are satisfied by different broadcasts
  by . Therefore,  can only satisfy  and
   by a single broadcast and the lemma follows.

\end{proof}
\fi

The proof of the lemma below is very similar to that
of Lemma~\ref{lem:arrivaltime}.
\begin{lemma}
  \label{lem:arrivaltimevarying}
  Consider the interval . Any request which is
  alive with slack , but unsatisfied by  at time  must have arrived after
  time .
\end{lemma}

\iffalse
\begin{proof}
  For sake of contradiction, assume that a request 
  scheduled by  on the interval  has arrival time less than
  . Since  has not finished
  this request by , .
  Also, as we observed before, all requests scheduled during  by
   have slack no more than that of  which implies
  that . However, this implies that
  the delay factor of  is at least
    

      This is a contradiction to the fact that  is the
      first request that witnessed the maximum delay factor of \sbg.
\end{proof}

\fi


Now we are ready to prove the competitiveness of .
Although the outline of the proof is similar to that of
\lemref{eps-ceps-c-competitive}, it requires more careful reasoning
to handle the impact of abandoned transmissions
of pages. Here is where we crucially rely on the speed of .

\begin{lemma}
  \lemlab{eps-ceps-c-competitivevarying}
  The algorithm  when given a -speed machine
  satisfies .
\end{lemma}

\begin{proof}
  We consider the set of requests satisfied by  during the
  interval . All of these requests have slack at
  most , and from Lemma~\ref{lem:arrivaltimevarying} and
  the property of the algorithm, have arrived no earlier than
  . Since  is busy throughout
  , the volume of broadcasts it transmits during 
  is .

  We now argue that either Lemma~\ref{mainvarying} applies in which
  case , or  has to transmit
  a comparable amount of volume to that of .

  Fix a page  and consider the transmissions for  that 
  does during . Let 
  be distinct requests for  which cause these
  transmissions. Amongst these, only  may have started
  before , the rest start during .  Note that we are not
  claiming that these transmissions are satisfied separately; some of
  them may be preempted and then satisfied together. Observe that if
   starts at some time  then it implies that no
  request  for  has arrived by time .
  Therefore by Lemma~\ref{mainvarying}, if  satisfies any two of
  these requests that  started in  by the same transmission,
   and we are done.

  Otherwise,  satisfies each of  by separate transmissions. (If  was
  started by  before ,  could satisfy 
  and  together and we would not be able to invoke
  Lemma~\ref{mainvarying}). Therefore if  then the total
  volume of transmissions that  does to satisfy these requests
  for page  is at least  while  does at most
  .  If  then both  and  transmit page  once for its entire page length. In either case, the total volume of transmissions
  that  does is at least half those of . Since  was
  arbitrary, it follows that the total number of transmissions that
   does to satisfy requests that  satisfies during 
  is at least .

  From Lemma~\ref{lem:arrivaltimevarying}, all the requests that
   processes during  arrived no earlier than . Since  has a -speed machine,
  it follows that  can finish these requests only by time
  
  Since each of these requests have slack at most  and arrive
  no later than ,


\end{proof}

We thus obtain the following.


\begin{theorem}
  With ,  is a -speed -competitive algorithm for minimizing the maximum delay
  factor in broadcast scheduling with arbitrary page sizes.
\end{theorem}


\section{Concluding Remarks}
In this paper we have initiated the study of online algorithms for
minimizing delay factor when requests have deadlines.  Our main result
is broadcast scheduling where the algorithm and analysis demonstrates
the utility of making requests wait. We hope that this and related
ideas are helpful in understanding other performance measures in the
broadcast setting. Particularly, can `waiting' combined with some
known algorithm, like most requests first, be used to improve the
current best known online algorithm for minimizing the average
response time? Another interesting problem is whether there is a
-speed -competitive algorithm for delay factor.  Our
algorithm has a parameter that controls the waiting time. Is there an
algorithm that avoids taking an explicit parameter and ``learns'' it
along the way?

\bigskip
\noindent
{\bf Acknowledgments:} We thank Samir Khuller for
clarifications on previous work and for his encouragement.

\bibliographystyle{alpha}
\bibliography{DelayFactor}


\appendix

\section{Omitted Proofs}

\subsection{Proof of Theorem~\ref{thm:unicast_lb}}

\begin{proof}
For sake of contradiction, assume that some algorithm that
achieves a competitive ratio better than   exists. Now consider the following example.

\begin{quotation}
\noindent \texttt{Type 1}:  At time  let the client request a
page with processing time and deadline .  This request
has slack .
\end{quotation}

\begin{quotation}
\noindent \texttt{Type 2}:  At times 
let the client request a page with processing time 
and a deadline  time units after its arrival time.
These requests have slack . \noindent
\end{quotation}


Consider time   Assume that this is all of the
requests which the client makes.  The optimal solution schedules
these requests in a first in first out fashion.  The optimal
schedule finishes request type 1 by its deadline.  The requests of
type 2 then finish at  time units after their
deadline. Thus, the delay factor for the optimal schedule is
.

The maximum ratio of maximum to minimum slack values seen so far
is .  Thus, the maximum
delay factor our algorithm can have is . Consider having the request of type 1 still in
the deterministic algorithms queue.  At time , the
algorithm has achieved a delay factor of at least .  Thus, the algorithm has a
competitive ratio of at least , a
contradiction. Therefore, at time  the algorithm
must have finished the request of type 1.  Now, immediately after
this time, requests of type 3 arrive.

\begin{quotation}
\noindent \texttt{Type 3}: Starting at time  the
client requests  unit processing time
requests each with a deadline one time unit after their arrival
time. These requests arrive one after another, each time unit. The
slack of these requests is 1.
\end{quotation}

These are all of the requests which are sent.  The optimal
solution schedules the request of type 1 until time ,
thus has  processing time left to finish this
request. Then the optimal solution schedules the type 2 and type 3
requests as they arrive, giving them a delay factor of 1.  At time
 the optimal solution
schedules the request of type 1 to completion.  Thus delay factor
of this solution is .

Our algorithm must have scheduled the request of type 1 by time
.  Thus the last request it finishes is either of
type 2 or type 3.  If the request is of type 2 then this request
must have waited for all requests of type 3 to finish along with
its processing time, thus the delay factor is at least
.  If the last request satisfied by the algorithm is
of type 3, then this request must have waited for a request of
type 2 to finish, so the delay factor is at least .
In either case, the competitive ratio of the algorithm is at least
, a contradiction.

\end{proof}

\subsection{Proof of \lemref{processbound}}
\begin{proof}
  Suppose the lemma is false. Then there is a first time  when
   and small
  constant  such that . Let .
  For this to occur,  processes a request of class  during
  the interval  while  processes a request of class
  . Since each machine uses , it must be that  had no
  requests in classes  during  which implies that . Therefore,


since . However, this implies
that

a contradiction to Observation \ref{observation}.
\end{proof}

\subsection{Proof of \lemref{closebound}}

\begin{proof}
Combining Observation \ref{observation}, \lemref{processbound},
and the fact that  by definition then,


\end{proof}


\subsection{Proof of Theorem~\ref{broadcast-lower}}
\begin{proof}
  Let  be any online -speed algorithm. We consider the following
  adversary. At time , the adversary requests pages , all which have a deadline of . Between time
   and  the client requests whatever page the online
  algorithm  broadcasts immediately after that request is
  broadcast; this new request also has a deadline of . It
  follows that at time  the online algorithm  has
   requests for distinct pages in its queue. However, the
  adversary can finish all these requests by time . Then
  starting at time  the adversary requests 
  new pages, say .  These new pages are
  requested, one at each time step, in a cyclic fashion for 
  cycles.  More formally, for , page  is requested at times  for . Each of these requests has a slack of one which means
  that their deadline is one unit after their arrival.  The adversary
  can satisfy these requests with delay since it has no queue at any
  time; thus its maximum delay factor is .  However, the online
  algorithm  has  requests in its queue at time ; each of these has a slack of . We now argue that the
  delay factor of  is . If the algorithm satisfies two
  slack  requests for the same page by a single transmission, then
  its delay factor is ; this follows since the requests for the
  same page are  time units apart. Otherwise, the algorithm does
  not merge any requests for the same page and hence finishes the
  the last request by time . If the
  last request to be finished is a slack  request, then its delay
  factor is at least  since the last slack  requests is released
  at time . If the last request to be finished is
  one of the requests with slack , then its delay factor
  is at least .
\end{proof}
\end{document}
