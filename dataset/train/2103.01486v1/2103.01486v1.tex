\section*{Overview}
The Supplementary Material is structured as follows. In Section~\ref{sec:resultscondition}, we show results obtained on the RobotCar Seasons v2 and Extended CMU Seasons datasets split by query condition. Section~\ref{sec:quantitative} contains additional quantitative results on the Pittsburgh 30k and Tokyo 24/7 datasets, as well as additional results on the computation time split across the feature extraction and feature matching processes. Section~\ref{sec:ablation} contains a variety of additional ablation studies, some of them further demonstrating the robustness of our method, while others detail experiments that might logically be expected and were conducted, but that were not fruitful. Section~\ref{sec:qualitative} contains various qualitative results, showcasing both challenging success cases of Patch-NetVLAD and some failure cases. This section also contains examples of incorrect dataset annotations, where Patch-NetVLAD actually found the correct match but this match was not within the ground-truth matches due to errors in the ground-truth. Finally, in Section~\ref{sec:datasets} we describe in detail the six key benchmark datasets on which we evaluate Patch-NetVLAD.

\section{Results Split by Condition on RobotCar Seasons v2 and Extended CMU Seasons}
\label{sec:resultscondition}


\textbf{RobotCar Seasons v2:} 
Suppl.~Table~\ref{tab:results_robotcar} contains results obtained on the RobotCar Seasons v2 dataset split by query condition. The results for RobotCar Seasons v2 stated in Tables 1 and 2 of the main paper are summary statistics, where the different conditions are weighted by the number of images contained within each condition.

Patch-NetVLAD outperforms SuperGlue~\cite{sarlin20superglue} by 1.3\% absolute recall on the tightest error thresholds (.25m translational error and 2 degrees orientation error) when considering the summary statistic. There are some conditions where SuperGlue has a slight performance advantage for the looser error thresholds, in particular the night traverses. As stated in the Conclusions section of the main paper, it would be interesting to train a neural network-based feature matcher similar to SuperGlue that uses our proposed Patch-NetVLAD features instead of the original SuperPoint~\cite{detone2018superpoint} features. This approach would likely yield more robust matching than a standard mutual nearest neighbors matching technique, which combined with outlier rejection will likely yield a significant performance improvement.

\newcommand{\NetvladRSDawnRone}{3.3}
\newcommand{\NetvladRSDawnRfive}{55.4}
\newcommand{\NetvladRSDawnRten}{72.8}

\newcommand{\DensevladRSDawnRone}{3.8}
\newcommand{\DensevladRSDawnRfive}{65.4}
\newcommand{\DensevladRSDawnRten}{81.9}

\newcommand{\ApgemRSDawnRone}{1.4}
\newcommand{\ApgemRSDawnRfive}{42.8}
\newcommand{\ApgemRSDawnRten}{61.3}

\newcommand{\SuperglueRSDawnRone}{4.3}
\newcommand{\SuperglueRSDawnRfive}{69.0}
\newcommand{\SuperglueRSDawnRten}{84.8}

\newcommand{\OursRSDawnRone}{\textbf{4.8}}
\newcommand{\OursRSDawnRfive}{70.6}
\newcommand{\OursRSDawnRten}{85.5}

\newcommand{\OursThreeRSDawnRone}{\textbf{4.8}}
\newcommand{\OursThreeRSDawnRfive}{\textbf{72.5}}
\newcommand{\OursThreeRSDawnRten}{\textbf{86.2}}

\newcommand{\OursAppearanceRSDawnRone}{}
\newcommand{\OursAppearanceRSDawnRfive}{}
\newcommand{\OursAppearanceRSDawnRten}{}

\newcommand{\OursRansacOnlyRSDawnRone}{}
\newcommand{\OursRansacOnlyRSDawnRfive}{}
\newcommand{\OursRansacOnlyRSDawnRten}{}

\newcommand{\OursSpatialApproxRSDawnRone}{}
\newcommand{\OursSpatialApproxRSDawnRfive}{}
\newcommand{\OursSpatialApproxRSDawnRten}{}



\newcommand{\NetvladRSDuskRone}{10.7}
\newcommand{\NetvladRSDuskRfive}{65.2}
\newcommand{\NetvladRSDuskRten}{85.2}

\newcommand{\DensevladRSDuskRone}{\textbf{13.7}}
\newcommand{\DensevladRSDuskRfive}{68.6}
\newcommand{\DensevladRSDuskRten}{88.4}

\newcommand{\ApgemRSDuskRone}{\ 9.1}
\newcommand{\ApgemRSDuskRfive}{60.2}
\newcommand{\ApgemRSDuskRten}{83.1}

\newcommand{\SuperglueRSDuskRone}{12.7}
\newcommand{\SuperglueRSDuskRfive}{69.5}
\newcommand{\SuperglueRSDuskRten}{88.6}

\newcommand{\OursRSDuskRone}{13.0}
\newcommand{\OursRSDuskRfive}{71.7}
\newcommand{\OursRSDuskRten}{89.7}

\newcommand{\OursThreeRSDuskRone}{13.5}
\newcommand{\OursThreeRSDuskRfive}{\textbf{72.0}}
\newcommand{\OursThreeRSDuskRten}{\textbf{89.5}}

\newcommand{\OursAppearanceRSDuskRone}{}
\newcommand{\OursAppearanceRSDuskRfive}{}
\newcommand{\OursAppearanceRSDuskRten}{}

\newcommand{\OursRansacOnlyRSDuskRone}{}
\newcommand{\OursRansacOnlyRSDuskRfive}{}
\newcommand{\OursRansacOnlyRSDuskRten}{}

\newcommand{\OursSpatialApproxRSDuskRone}{}
\newcommand{\OursSpatialApproxRSDuskRfive}{}
\newcommand{\OursSpatialApproxRSDuskRten}{}


\newcommand{\NetvladRSOCSummerRone}{2.9}
\newcommand{\NetvladRSOCSummerRfive}{70.5}
\newcommand{\NetvladRSOCSummerRten}{88.2}

\newcommand{\DensevladRSOCSummerRone}{4.2}
\newcommand{\DensevladRSOCSummerRfive}{75.0}
\newcommand{\DensevladRSOCSummerRten}{90.9}

\newcommand{\ApgemRSOCSummerRone}{2.3}
\newcommand{\ApgemRSOCSummerRfive}{55.8}
\newcommand{\ApgemRSOCSummerRten}{79.4}

\newcommand{\SuperglueRSOCSummerRone}{5.0}
\newcommand{\SuperglueRSOCSummerRfive}{79.4}
\newcommand{\SuperglueRSOCSummerRten}{\textbf{95.0}}

\newcommand{\OursRSOCSummerRone}{4.8}
\newcommand{\OursRSOCSummerRfive}{80.5}
\newcommand{\OursRSOCSummerRten}{94.1}

\newcommand{\OursThreeRSOCSummerRone}{\textbf{5.3}}
\newcommand{\OursThreeRSOCSummerRfive}{\textbf{80.9}}
\newcommand{\OursThreeRSOCSummerRten}{94.5}

\newcommand{\OursAppearanceRSOCSummerRone}{}
\newcommand{\OursAppearanceRSOCSummerRfive}{}
\newcommand{\OursAppearanceRSOCSummerRten}{}

\newcommand{\OursRansacOnlyRSOCSummerRone}{}
\newcommand{\OursRansacOnlyRSOCSummerRfive}{}
\newcommand{\OursRansacOnlyRSOCSummerRten}{}

\newcommand{\OursSpatialApproxRSOCSummerRone}{}
\newcommand{\OursSpatialApproxRSOCSummerRfive}{}
\newcommand{\OursSpatialApproxRSOCSummerRten}{}


\newcommand{\NetvladRSOCWinterRone}{2.3}
\newcommand{\NetvladRSOCWinterRfive}{56.9}
\newcommand{\NetvladRSOCWinterRten}{80.5}

\newcommand{\DensevladRSOCWinterRone}{4.3}
\newcommand{\DensevladRSOCWinterRfive}{66.3}
\newcommand{\DensevladRSOCWinterRten}{86.3}

\newcommand{\ApgemRSOCWinterRone}{3.1}
\newcommand{\ApgemRSOCWinterRfive}{50.3}
\newcommand{\ApgemRSOCWinterRten}{76.1}

\newcommand{\SuperglueRSOCWinterRone}{4.5}
\newcommand{\SuperglueRSOCWinterRfive}{69.1}
\newcommand{\SuperglueRSOCWinterRten}{88.6}

\newcommand{\OursRSOCWinterRone}{5.8}
\newcommand{\OursRSOCWinterRfive}{\textbf{71.3}}
\newcommand{\OursRSOCWinterRten}{89.6}

\newcommand{\OursThreeRSOCWinterRone}{\textbf{6.3}}
\newcommand{\OursThreeRSOCWinterRfive}{\textbf{71.3}}
\newcommand{\OursThreeRSOCWinterRten}{\textbf{89.8}}

\newcommand{\OursAppearanceRSOCWinterRone}{}
\newcommand{\OursAppearanceRSOCWinterRfive}{}
\newcommand{\OursAppearanceRSOCWinterRten}{}

\newcommand{\OursRansacOnlyRSOCWinterRone}{}
\newcommand{\OursRansacOnlyRSOCWinterRfive}{}
\newcommand{\OursRansacOnlyRSOCWinterRten}{}

\newcommand{\OursSpatialApproxRSOCWinterRone}{}
\newcommand{\OursSpatialApproxRSOCWinterRfive}{}
\newcommand{\OursSpatialApproxRSOCWinterRten}{}


\newcommand{\NetvladRSRainRone}{4.2}
\newcommand{\NetvladRSRainRfive}{71.9}
\newcommand{\NetvladRSRainRten}{88.9}

\newcommand{\DensevladRSRainRone}{5.4}
\newcommand{\DensevladRSRainRfive}{76.8}
\newcommand{\DensevladRSRainRten}{92.1}

\newcommand{\ApgemRSRainRone}{4.4}
\newcommand{\ApgemRSRainRfive}{67.2}
\newcommand{\ApgemRSRainRten}{87.0}

\newcommand{\SuperglueRSRainRone}{\textbf{5.9}}
\newcommand{\SuperglueRSRainRfive}{76.4}
\newcommand{\SuperglueRSRainRten}{91.8}

\newcommand{\OursRSRainRone}{\textbf{5.9}}
\newcommand{\OursRSRainRfive}{79.0}
\newcommand{\OursRSRainRten}{\textbf{92.3}}

\newcommand{\OursThreeRSRainRone}{\textbf{5.9}}
\newcommand{\OursThreeRSRainRfive}{\textbf{79.3}}
\newcommand{\OursThreeRSRainRten}{92.1}

\newcommand{\OursAppearanceRSRainRone}{}
\newcommand{\OursAppearanceRSRainRfive}{}
\newcommand{\OursAppearanceRSRainRten}{}

\newcommand{\OursRansacOnlyRSRainRone}{}
\newcommand{\OursRansacOnlyRSRainRfive}{}
\newcommand{\OursRansacOnlyRSRainRten}{}

\newcommand{\OursSpatialApproxRSRainRone}{}
\newcommand{\OursSpatialApproxRSRainRfive}{}
\newcommand{\OursSpatialApproxRSRainRten}{}


\newcommand{\NetvladRSSnowRone}{4.5}
\newcommand{\NetvladRSSnowRfive}{63.7}
\newcommand{\NetvladRSSnowRten}{80.1}

\newcommand{\DensevladRSSnowRone}{7.3}
\newcommand{\DensevladRSSnowRfive}{72.4}
\newcommand{\DensevladRSSnowRten}{85.1}

\newcommand{\ApgemRSSnowRone}{2.1}
\newcommand{\ApgemRSSnowRfive}{51.9}
\newcommand{\ApgemRSSnowRten}{70.0}

\newcommand{\SuperglueRSSnowRone}{7.0}
\newcommand{\SuperglueRSSnowRfive}{73.2}
\newcommand{\SuperglueRSSnowRten}{87.2}

\newcommand{\OursRSSnowRone}{7.4}
\newcommand{\OursRSSnowRfive}{74.2}
\newcommand{\OursRSSnowRten}{87.0}

\newcommand{\OursThreeRSSnowRone}{\textbf{7.8}}
\newcommand{\OursThreeRSSnowRfive}{\textbf{75.9}}
\newcommand{\OursThreeRSSnowRten}{\textbf{87.9}}

\newcommand{\OursAppearanceRSSnowRone}{}
\newcommand{\OursAppearanceRSSnowRfive}{}
\newcommand{\OursAppearanceRSSnowRten}{}

\newcommand{\OursRansacOnlyRSSnowRone}{}
\newcommand{\OursRansacOnlyRSSnowRfive}{}
\newcommand{\OursRansacOnlyRSSnowRten}{}

\newcommand{\OursSpatialApproxRSSnowRone}{}
\newcommand{\OursSpatialApproxRSSnowRfive}{}
\newcommand{\OursSpatialApproxRSSnowRten}{}


\newcommand{\NetvladRSSunRone}{2.2}
\newcommand{\NetvladRSSunRfive}{48.2}
\newcommand{\NetvladRSSunRten}{70.3}

\newcommand{\DensevladRSSunRone}{3.0}
\newcommand{\DensevladRSSunRfive}{55.5}
\newcommand{\DensevladRSSunRten}{71.6}

\newcommand{\ApgemRSSunRone}{0.8}
\newcommand{\ApgemRSSunRfive}{29.3}
\newcommand{\ApgemRSSunRten}{53.1}

\newcommand{\SuperglueRSSunRone}{3.3}
\newcommand{\SuperglueRSSunRfive}{66.5}
\newcommand{\SuperglueRSSunRten}{\textbf{83.9}}

\newcommand{\OursRSSunRone}{4.0}
\newcommand{\OursRSSunRfive}{66.0}
\newcommand{\OursRSSunRten}{82.3}

\newcommand{\OursThreeRSSunRone}{\textbf{4.8}}
\newcommand{\OursThreeRSSunRfive}{\textbf{67.3}}
\newcommand{\OursThreeRSSunRten}{83.4}

\newcommand{\OursAppearanceRSSunRone}{}
\newcommand{\OursAppearanceRSSunRfive}{}
\newcommand{\OursAppearanceRSSunRten}{}

\newcommand{\OursRansacOnlyRSSunRone}{}
\newcommand{\OursRansacOnlyRSSunRfive}{}
\newcommand{\OursRansacOnlyRSSunRten}{}

\newcommand{\OursSpatialApproxRSSunRone}{}
\newcommand{\OursSpatialApproxRSSunRfive}{}
\newcommand{\OursSpatialApproxRSSunRten}{}


\newcommand{\NetvladRSNightRone}{0.2}
\newcommand{\NetvladRSNightRfive}{2.5}
\newcommand{\NetvladRSNightRten}{5.4\ }

\newcommand{\DensevladRSNightRone}{0.5}
\newcommand{\DensevladRSNightRfive}{9.8}
\newcommand{\DensevladRSNightRten}{17.3}

\newcommand{\ApgemRSNightRone}{0.2}
\newcommand{\ApgemRSNightRfive}{1.7}
\newcommand{\ApgemRSNightRten}{3.4\ }

\newcommand{\SuperglueRSNightRone}{\textbf{0.5}}
\newcommand{\SuperglueRSNightRfive}{\textbf{13.4}}
\newcommand{\SuperglueRSNightRten}{\textbf{27.9}}

\newcommand{\OursRSNightRone}{0.3}
\newcommand{\OursRSNightRfive}{10.0}
\newcommand{\OursRSNightRten}{21.7}

\newcommand{\OursThreeRSNightRone}{\textbf{0.5}}
\newcommand{\OursThreeRSNightRfive}{12.4}
\newcommand{\OursThreeRSNightRten}{24.9}

\newcommand{\OursAppearanceRSNightRone}{}
\newcommand{\OursAppearanceRSNightRfive}{}
\newcommand{\OursAppearanceRSNightRten}{}

\newcommand{\OursRansacOnlyRSNightRone}{}
\newcommand{\OursRansacOnlyRSNightRfive}{}
\newcommand{\OursRansacOnlyRSNightRten}{}

\newcommand{\OursSpatialApproxRSNightRone}{}
\newcommand{\OursSpatialApproxRSNightRfive}{}
\newcommand{\OursSpatialApproxRSNightRten}{}


\newcommand{\NetvladRSNightRainRone}{0.1\ }
\newcommand{\NetvladRSNightRainRfive}{2.4\ }
\newcommand{\NetvladRSNightRainRten}{5.5\ }

\newcommand{\DensevladRSNightRainRone}{0.6}
\newcommand{\DensevladRSNightRainRfive}{17.9}
\newcommand{\DensevladRSNightRainRten}{29.6}

\newcommand{\ApgemRSNightRainRone}{0.0\,}
\newcommand{\ApgemRSNightRainRfive}{\,1.6\ }
\newcommand{\ApgemRSNightRainRten}{7.3\ }

\newcommand{\SuperglueRSNightRainRone}{0.9}
\newcommand{\SuperglueRSNightRainRfive}{\textbf{20.5}}
\newcommand{\SuperglueRSNightRainRten}{\textbf{31.8}}

\newcommand{\OursRSNightRainRone}{0.4}
\newcommand{\OursRSNightRainRfive}{17.0}
\newcommand{\OursRSNightRainRten}{27.7}

\newcommand{\OursThreeRSNightRainRone}{\textbf{1.0}}
\newcommand{\OursThreeRSNightRainRfive}{19.0}
\newcommand{\OursThreeRSNightRainRten}{30.8}

\newcommand{\OursAppearanceRSNightRainRone}{}
\newcommand{\OursAppearanceRSNightRainRfive}{}
\newcommand{\OursAppearanceRSNightRainRten}{}

\newcommand{\OursRansacOnlyRSNightRainRone}{}
\newcommand{\OursRansacOnlyRSNightRainRfive}{}
\newcommand{\OursRansacOnlyRSNightRainRten}{}

\newcommand{\OursSpatialApproxRSNightRainRone}{}
\newcommand{\OursSpatialApproxRSNightRainRfive}{}
\newcommand{\OursSpatialApproxRSNightRainRten}{}
 \begin{table*}[!t]
  \renewcommand{\arraystretch}{1.2}
  \centering
  \caption{Performance comparison RobotCar Seasons v2}
\resizebox{0.99\linewidth}{!}{
    \begin{tabular}{c|c|c|c|c|c|c|c|c|c}
& \multicolumn{7}{c|}{\textbf{day conditions}} & \multicolumn{2}{c}{\textbf{night conditions}}\\
     & dawn & dusk & OC-summer & OC-winter & rain & snow & sun & night & night-rain \\
     \cline{2-10}
     \multicolumn{1}{r|}{m} & .25 / .50 / 5.0 & .25 / .50 / 5.0 & .25 / .50 / 5.0 & .25 / .50 / 5.0 & .25 / .50 / 5.0 & .25 / .50 / 5.0 & .25 / .50 / 5.0 & .25 / .50 / 5.0 & .25 / .50 / 5.0\\
     \multicolumn{1}{r|}{deg}  & 2 / 5 / 10 & 2 / 5 / 10 & 2 / 5 / 10 & 2 / 5 / 10 & 2 / 5 / 10 & 2 / 5 / 10 & 2 / 5 / 10 & 2 / 5 / 10 & 2 / 5 / 10\\
    \cline{1-10}
    \noalign{\vskip\doublerulesep\vskip-\arrayrulewidth}
    \cline{1-10}
    AP-GEM~\cite{revaud2019learning} & \ApgemRSDawnRone\ / \ApgemRSDawnRfive\ / \ApgemRSDawnRten & \ApgemRSDuskRone\ / \ApgemRSDuskRfive\ / \ApgemRSDuskRten & \ApgemRSOCSummerRone\ / \ApgemRSOCSummerRfive\ / \ApgemRSOCSummerRten & \ApgemRSOCWinterRone\ / \ApgemRSOCWinterRfive\ / \ApgemRSOCWinterRten & \ApgemRSRainRone\ / \ApgemRSRainRfive\ / \ApgemRSRainRten & \ApgemRSSnowRone\ / \ApgemRSSnowRfive\ / \ApgemRSSnowRten & \ApgemRSSunRone\ / \ApgemRSSunRfive\ / \ApgemRSSunRten & \ApgemRSNightRone\ / \ApgemRSNightRfive\ / \ApgemRSNightRten & \ApgemRSNightRainRone\ / \ApgemRSNightRainRfive\ / \ApgemRSNightRainRten\\
    DenseVLAD~\cite{Torii2018} & \DensevladRSDawnRone\ / \DensevladRSDawnRfive\ / \DensevladRSDawnRten & \DensevladRSDuskRone\ / \DensevladRSDuskRfive\ / \DensevladRSDuskRten & \DensevladRSOCSummerRone\ / \DensevladRSOCSummerRfive\ / \DensevladRSOCSummerRten & \DensevladRSOCWinterRone\ / \DensevladRSOCWinterRfive\ / \DensevladRSOCWinterRten & \DensevladRSRainRone\ / \DensevladRSRainRfive\ / \DensevladRSRainRten & \DensevladRSSnowRone\ / \DensevladRSSnowRfive\ / \DensevladRSSnowRten & \DensevladRSSunRone\ / \DensevladRSSunRfive\ / \DensevladRSSunRten & \DensevladRSNightRone\ / \DensevladRSNightRfive\ / \DensevladRSNightRten & \DensevladRSNightRainRone\ / \DensevladRSNightRainRfive\ / \DensevladRSNightRainRten\\
    NetVLAD~\cite{AR2018} & \NetvladRSDawnRone\ / \NetvladRSDawnRfive\ / \NetvladRSDawnRten & \NetvladRSDuskRone\ / \NetvladRSDuskRfive\ / \NetvladRSDuskRten & \NetvladRSOCSummerRone\ / \NetvladRSOCSummerRfive\ / \NetvladRSOCSummerRten & \NetvladRSOCWinterRone\ / \NetvladRSOCWinterRfive\ / \NetvladRSOCWinterRten & \NetvladRSRainRone\ / \NetvladRSRainRfive\ / \NetvladRSRainRten & \NetvladRSSnowRone\ / \NetvladRSSnowRfive\ / \NetvladRSSnowRten & \NetvladRSSunRone\ / \NetvladRSSunRfive\ / \NetvladRSSunRten & \NetvladRSNightRone\ / \NetvladRSNightRfive\ / \NetvladRSNightRten & \NetvladRSNightRainRone\ / \NetvladRSNightRainRfive\ / \NetvladRSNightRainRten\\
    SuperGlue~\cite{sarlin20superglue} & \SuperglueRSDawnRone\ / \SuperglueRSDawnRfive\ / \SuperglueRSDawnRten & \SuperglueRSDuskRone\ / \SuperglueRSDuskRfive\ / \SuperglueRSDuskRten & \SuperglueRSOCSummerRone\ / \SuperglueRSOCSummerRfive\ / \SuperglueRSOCSummerRten & \SuperglueRSOCWinterRone\ / \SuperglueRSOCWinterRfive\ / \SuperglueRSOCWinterRten & \SuperglueRSRainRone\ / \SuperglueRSRainRfive\ / \SuperglueRSRainRten & \SuperglueRSSnowRone\ / \SuperglueRSSnowRfive\ / \SuperglueRSSnowRten & \SuperglueRSSunRone\ / \SuperglueRSSunRfive\ / \SuperglueRSSunRten & \SuperglueRSNightRone\ / \SuperglueRSNightRfive\ / \SuperglueRSNightRten & \SuperglueRSNightRainRone\ / \SuperglueRSNightRainRfive\ / \SuperglueRSNightRainRten\\
    \cline{1-10}
    \noalign{\vskip\doublerulesep\vskip-\arrayrulewidth}
    \cline{1-10}
    \textbf{Ours} & \OursThreeRSDawnRone\ / \OursThreeRSDawnRfive\ / \OursThreeRSDawnRten & \OursThreeRSDuskRone\ / \OursThreeRSDuskRfive\ / \OursThreeRSDuskRten & \OursThreeRSOCSummerRone\ / \OursThreeRSOCSummerRfive\ / \OursThreeRSOCSummerRten & \OursThreeRSOCWinterRone\ / \OursThreeRSOCWinterRfive\ / \OursThreeRSOCWinterRten & \OursThreeRSRainRone\ / \OursThreeRSRainRfive\ / \textbf{\OursThreeRSRainRten} & \OursThreeRSSnowRone\ / \OursThreeRSSnowRfive\ / \OursThreeRSSnowRten & \OursThreeRSSunRone\ / \OursThreeRSSunRfive\ / \OursThreeRSSunRten & \OursThreeRSNightRone\ / \OursThreeRSNightRfive\ / \OursThreeRSNightRten & \OursThreeRSNightRainRone\ / \OursThreeRSNightRainRfive\ / \OursThreeRSNightRainRten
    \end{tabular}}
  \label{tab:results_robotcar}\end{table*} 

\textbf{Extended CMU Seasons:} 
In Suppl.~Table~\ref{tab:results_cmu} we similarly show detailed results for the Extended CMU Seasons dataset, split by Urban, Suburban and Park environments. Patch-NetVLAD consistently outperforms all comparison methods, including our competitive SuperGlue baseline, on all conditions and all error thresholds by relatively large margins, with a single exception being the park condition where SuperGlue performs slightly better for the largest error threshold.

\newcommand{\NetvladCMUUrbanRone}{12.0}
\newcommand{\NetvladCMUUrbanRfive}{30.5}
\newcommand{\NetvladCMUUrbanRten}{91.4}

\newcommand{\DensevladCMUUrbanRone}{15.0}
\newcommand{\DensevladCMUUrbanRfive}{37.2}
\newcommand{\DensevladCMUUrbanRten}{88.8}

\newcommand{\ApgemCMUUrbanRone}{\ 8.1}
\newcommand{\ApgemCMUUrbanRfive}{21.5}
\newcommand{\ApgemCMUUrbanRten}{81.3}

\newcommand{\SuperglueCMUUrbanRone}{17.1}
\newcommand{\SuperglueCMUUrbanRfive}{43.6}
\newcommand{\SuperglueCMUUrbanRten}{96.9}

\newcommand{\OursThreeCMUUrbanRone}{\textbf{19.2}}
\newcommand{\OursThreeCMUUrbanRfive}{\textbf{48.0}}
\newcommand{\OursThreeCMUUrbanRten}{\textbf{97.2}}



\newcommand{\NetvladCMUSuburbanRone}{3.9}
\newcommand{\NetvladCMUSuburbanRfive}{14.2}
\newcommand{\NetvladCMUSuburbanRten}{79.8}

\newcommand{\DensevladCMUSuburbanRone}{5.5}
\newcommand{\DensevladCMUSuburbanRfive}{20.2}
\newcommand{\DensevladCMUSuburbanRten}{84.3}

\newcommand{\ApgemCMUSuburbanRone}{2.4}
\newcommand{\ApgemCMUSuburbanRfive}{\,9.1\,}
\newcommand{\ApgemCMUSuburbanRten}{63.6}

\newcommand{\SuperglueCMUSuburbanRone}{5.6}
\newcommand{\SuperglueCMUSuburbanRfive}{21.6}
\newcommand{\SuperglueCMUSuburbanRten}{96.7}

\newcommand{\OursThreeCMUSuburbanRone}{\textbf{8.2}}
\newcommand{\OursThreeCMUSuburbanRfive}{\textbf{28.8}}
\newcommand{\OursThreeCMUSuburbanRten}{\textbf{97.0}}



\newcommand{\NetvladCMUParkRone}{2.7}
\newcommand{\NetvladCMUParkRfive}{11.2}
\newcommand{\NetvladCMUParkRten}{64.6}

\newcommand{\DensevladCMUParkRone}{5.5}
\newcommand{\DensevladCMUParkRfive}{21.3}
\newcommand{\DensevladCMUParkRten}{74.6}

\newcommand{\ApgemCMUParkRone}{1.7}
\newcommand{\ApgemCMUParkRfive}{6.6}
\newcommand{\ApgemCMUParkRten}{45.3}

\newcommand{\SuperglueCMUParkRone}{7.5}
\newcommand{\SuperglueCMUParkRfive}{30.5}
\newcommand{\SuperglueCMUParkRten}{\textbf{96.5}}

\newcommand{\OursThreeCMUParkRone}{\textbf{9.5}}
\newcommand{\OursThreeCMUParkRfive}{\textbf{34.9}}
\newcommand{\OursThreeCMUParkRten}{94.3}
 \begin{table}[!t]
  \renewcommand{\arraystretch}{1.2}
  \centering
  \caption{Performance comparison Extended CMU Seasons}
\resizebox{0.99\linewidth}{!}{
    \begin{tabular}{c|c|c|c}
& Urban & Suburban & Park \\
     \cline{2-4}
     \multicolumn{1}{r|}{m} & .25 / .50 / 5.0 & .25 / .50 / 5.0 & .25 / .50 / 5.0\\
     \multicolumn{1}{r|}{deg}  & 2 / 5 / 10 & 2 / 5 / 10 & 2 / 5 / 10\\
    \cline{1-4}
    \noalign{\vskip\doublerulesep\vskip-\arrayrulewidth}
    \cline{1-4}
    AP-GEM~\cite{revaud2019learning} & \ApgemCMUUrbanRone\ / \ApgemCMUUrbanRfive\ / \ApgemCMUUrbanRten & \ApgemCMUSuburbanRone\ / \ApgemCMUSuburbanRfive\ / \ApgemCMUSuburbanRten & \ApgemCMUParkRone\ / \ApgemCMUParkRfive\ / \ApgemCMUParkRten\\
    DenseVLAD~\cite{Torii2018} & \DensevladCMUUrbanRone\ / \DensevladCMUUrbanRfive\ / \DensevladCMUUrbanRten & \DensevladCMUSuburbanRone\ / \DensevladCMUSuburbanRfive\ / \DensevladCMUSuburbanRten & \DensevladCMUParkRone\ / \DensevladCMUParkRfive\ / \DensevladCMUParkRten\\
    NetVLAD~\cite{AR2018} & \NetvladCMUUrbanRone\ / \NetvladCMUUrbanRfive\ / \NetvladCMUUrbanRten & \NetvladCMUSuburbanRone\ / \NetvladCMUSuburbanRfive\ / \NetvladCMUSuburbanRten & \NetvladCMUParkRone\ / \NetvladCMUParkRfive\ / \NetvladCMUParkRten\\
    SuperGlue~\cite{sarlin20superglue} & \SuperglueCMUUrbanRone\ / \SuperglueCMUUrbanRfive\ / \SuperglueCMUUrbanRten & \SuperglueCMUSuburbanRone\ / \SuperglueCMUSuburbanRfive\ / \SuperglueCMUSuburbanRten & \SuperglueCMUParkRone\ / \SuperglueCMUParkRfive\ / \SuperglueCMUParkRten\\
    \cline{1-4}
    \noalign{\vskip\doublerulesep\vskip-\arrayrulewidth}
    \cline{1-4}
    \textbf{Ours} & \OursThreeCMUUrbanRone\ / \OursThreeCMUUrbanRfive\ / \OursThreeCMUUrbanRten & \OursThreeCMUSuburbanRone\ / \OursThreeCMUSuburbanRfive\ / \OursThreeCMUSuburbanRten & \OursThreeCMUParkRone\ / \OursThreeCMUParkRfive\ / \OursThreeCMUParkRten
    \end{tabular}}
  \label{tab:results_cmu}\end{table}% 
\section{Additional Quantitative Results}
\label{sec:quantitative}
\textbf{Additional Recall Plots:}
Fig.~3 in the main paper shows the recall@N performance on the Mapillary validation set. Similarly, Suppl.~Fig.~\ref{fig:recalltokyopitts} shows the recall@N performance for the Pittsburgh 30k and Tokyo 24/7 datasets.

\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.45\linewidth]{figs/recall_at_N_pitts.pdf}
    \hfil
    \includegraphics[width=0.45\linewidth]{figs/recall_at_N_tokyo.pdf}
    \caption{\textbf{Comparison with state-of-the-art.} We show the Recall performance of Ours (Multi-RANSAC-Patch-NetVLAD) compared to AP-GEM~\cite{revaud2019learning}, DenseVLAD~\cite{Torii2018}, NetVLAD~\cite{AR2018} and SuperGlue~\cite{sarlin20superglue}, on the Pittsburgh (left) and Tokyo 24/7 (right) datasets.}
    \label{fig:recalltokyopitts}
\end{figure*}


\textbf{Computational Time Requirements:}
Fig.~4 of the main paper shows the number of seconds required to process each query by a variety of our system configurations, as well as SuperGlue. The processing times presented in Fig.~4 of the main paper show the \textit{accumulated} times of feature extraction and feature matching. In Suppl.~Fig.~\ref{fig:compute_ablation} we show the compute times \textit{split} into feature extraction time only and feature matching time only; as well as the accumulated time.

\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.22\textwidth]{figs/speed_performance_plot_featextract.pdf}\hfill
    \includegraphics[width=0.22\textwidth]{figs/speed_performance_plot_matching.pdf}\hfill
    \includegraphics[width=0.22\textwidth]{figs/speed_performance_plot_combined.pdf}\hfill
    \raisebox{0.6cm}{\includegraphics[width=0.33\textwidth]{figs/speed_performance_plot_legend.pdf}}\\
    \makebox[0.012\textwidth][c]{}
    \makebox[0.22\textwidth][c]{\small (a) Feature extraction}
    \hfill
    \makebox[0.22\textwidth][c]{\small (b) Feature matching}
    \hfill
    \makebox[0.205\textwidth][c]{\small (c) Combined}
    \hfill
    \makebox[0.315\textwidth][c]{}\0.2cm]
    \caption{\textbf{Computational time requirements.} The number of seconds required to process each query are shown on the -axis, with the resulting R@1 shown on the -axis, for the Mapillary dataset. (a) indicates the times taken for feature extraction only, while (b) shows the feature matching time. In (c) we show the combined time (as in Fig~4 in the main paper). Triangles indicate single-scale Patch-NetVLAD, while stars indicate multi-scale Patch-NetVLAD. Filled symbols are used for RANSAC matching, while hollow symbols are used for the rapid spatial verification. The color indicates varying PCA dimensions.
    }
    \label{fig:compute_ablation}
\end{figure*}

\section{Further Ablation Studies}
\label{sec:ablation}

\textbf{Ablation of Multi-Scale Fusion Weights and Patch Sizes:} 
In Fig.~6 of the main paper, we demonstrated that Patch-NetVLAD is robust to the choice of particular patch sizes that are fused in our multi-scale approach. In Suppl.~Table~\ref{tab:fusionweights}, we further validate that our proposed multi-scale fusion of spatial scores across several patch sizes is robust to changes in patch size \emph{and} weightings by presenting results for the Mapillary dataset. Note that, as stated in the main paper, the set of weights used \emph{across all experiments and all datasets} was determined using a grid-search on the training set of the RobotCar Seasons v2 dataset.

While we fuse three patch sizes in the main paper, our method is not constrained to fusing any particular number of patch sizes. An investigation regarding this is shown in Suppl.~Table~\ref{tab:fusionnumber} -- there all patch sizes are fused with equal weights for simplicity. An interesting observation is that increasing the number of different patch sizes used (from three up to five) does not improve the recall performance beyond the best combination of three patch sizes. We can infer that the span of patch sizes (the difference between the smallest size and the largest size) is more important than the number of patch sizes used.

\textbf{Early Match Fusion:}
In Section 3.5 of the main paper, we describe our multi-scale fusion approach that merges the spatial scores obtained from different patch sizes. An alternative to this post-processing fusion is an early fusion where mutual nearest neighbors (Section 3.3 of the main paper) are found across patches of different scales, and a joint spatial score is calculated from all these mutual nearest neighbors.

However, we found that this early fusion approach does not work as well as the proposed post-processing fusion. Specifically, on the Mapillary validation set, we find that the early fusion results in R@1: 77.2\%, R@5: 85.3\%, and R@10: 87.3\%. This compares to R@1: 79.5\%, R@5: 86.2\% and R@10: 87.7\% using our proposed post-processing fusion.



\begin{table}[t]
  \renewcommand{\arraystretch}{1.2}
  \centering
  \caption{Ablation of Multi-Scale Fusion Weights (R@1)}
  \vspace{0.1cm}
      \footnotesize
    \begin{tabular}{ c|c|c|c } 
Weights / Patch sizes & 2 / 5 / 8 & 2 / 4 / 6 & 2 / 6 / 10 \\
    \hline
     0.33 / 0.33 / 0.33 & \textbf{79.7} & 78.6 &78.8  \\ 
     0.2 / 0.6 / 0.2 & 79.1  & 78.5  & 78.4 \\ 
     0.45 / 0.15 / 0.4 & 79.5  & 78.9  & 78.8  \\ 
     0.45 / 0.35 / 0.2 & 78.8  & 78.1  & 79.1  \\ 
\end{tabular}
    \label{tab:fusionweights}
\end{table}

\begin{table}[t]
  \renewcommand{\arraystretch}{1.2}
  \centering
  \caption{Ablation of the Number of Fused Patch Sizes}
  \vspace{0.1cm}
      \footnotesize
    \begin{tabular}{ c|c } 
Patch sizes & Recall@1 \\
    \hline
     1 / 3 / 5 & 78.0 \\
     2 / 5 / 8 & \textbf{79.7}  \\ 
     3 / 5 / 7 & 79.3  \\ 
     4 / 5 / 6 & 78.2  \\ 
    \hline
     1 / 2 / 3 / 4 & 77.3  \\
     1 / 3 / 5 / 7 & 78.5  \\
     2 / 4 / 6 / 8 & 78.9  \\
    \hline
     1 / 3 / 5 / 7 / 9 & 79.5 \\
     2 / 4 / 6 / 8 / 10 & 78.8 \\
\end{tabular}
\label{tab:fusionnumber}
\end{table}

\textbf{Other Pooling Strategies:}
We use NetVLAD pooling to aggregate patch features into a single patch descriptor in our proposed approach. Instead of NetVLAD pooling, other pooling strategies such as max-pooling~\cite{tolias2015particular} and sum-pooling~\cite{babenko2015aggregating} have been proposed in the literature. Our spatial scoring system based on patch-based matching is in principle applicable with alternative pooling strategies. However, we found that patch-based aggregation does not perform well when applied to these pooling strategies: patch-level average pooling of VGG's Conv-5 layer (all else being equal)  improves performance from 60.8\% R@1 (vanilla NetVLAD on Mapillary dataset) to 73.6\%, which compares to 79.5\% using patch-level VLAD pooling (Patch-NetVLAD). Patch-level max-pooling similarly leads to decreased performance when compared to Patch-NetVLAD (R@1: 74.5\%). In summary, our Patch-NetVLAD description significantly outperforms those alternative pooling strategies. Further investigation will be required to gain a deeper understanding of the complementary nature of the underlying pooling strategies and our proposed patch-based aggregation.

\textbf{Patch Crops in the Image Space Instead of Feature Space:} In Patch-NetVLAD, pooling is performed from a set of patches in the \emph{feature space} of an image. One could instead perform forward passes on patch-crops in the \emph{image space}. The main problem with this approach is that processing overlapping patches is prohibitive in terms of compute and storage (as each patch needs to be separately passed through VGG). However, overlapping patches are crucial for achieving high task performance -- we found that overlapping patches are key to achieving viewpoint invariance. Therefore, performing forward passes on patch-crops in the image space is not a viable alternative to our proposed pooling of patches in the feature space.

\textbf{Matching Across Different Patch Sizes:}
In the proposed method we match patches with other patches of the same size, but there is the possibility to match between patches of different sizes. For instance, a patch of size 2x2 could find a nearest neighbor match to a patch of size 5x5. Experiments revealed that such a cross-patch-size matching leads to sub-optimal performance: R@1 reduces from 79.5\% to 78.1\%. In future works, we would like to explore other matching strategies such as a coarse-to-fine matching scheme. We would also note that, conceptually, images of different zoom levels should not be matched, as they could have been taken from different places.

\textbf{Complementarity of Patch Sizes:}
Suppl.~Fig.~\ref{fig:differentpatchsizes} shows examples of correspondences split by patch size. We randomly sampled 10 correspondences per patch size and indicate the area covered by each patch. We include examples where small/medium/large patch sizes (\ie ) result in particularly good matches, as well as one example (the bottom row) where all patch sizes work well for the same image pair but in distinct areas of the image.

\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.99\textwidth]{figs/Supplementary/differentpatchsizes_compressed.pdf}
    \caption{\textbf{Complementarity of Patch Sizes.} The three columns indicate different patch sizes, from small (\ie ) over medium (\ie ) to large (\ie ). It can be observed that a small patch size is able to find matches where smaller spatial context is more intuitive, for example, near boundaries between sky and buildings (first row, left column) or between sky and power lines (third row, left column). On the other hand, a larger patch size provides complementary cues by spanning over large building surfaces, enabling matching despite significant illumination variations (second row, right column). Note that the size of the squares does not reflect the receptive field sizes of the underlying features; different sizes are used for visualization purposes only.}
    \label{fig:differentpatchsizes}
\end{figure*}

\section{Additional Qualitative Results}
\label{sec:qualitative}
Suppl.~Figs.~\ref{fig:qualitative_mapillary}, \ref{fig:qualitative_nordland}, \ref{fig:qualitative_pittsburgh} and \ref{fig:qualitative_tokyo} contain additional qualitative results on the Mapillary, Nordland, Pittsburgh and Tokyo 24/7 datasets respectively. For all these results, correct matches are represented with green borders, and incorrect matches with red borders. We show success cases of Patch-NetVLAD where all other methods failed to retrieve a correct match. Besides success cases, we also include failure cases where our proposed competitive SuperGlue baseline finds the correct match, but Patch-NetVLAD does not localize correctly. Many of these matches are challenging to recognize as the same place, even for a human observer.

These match example visualizations lead to interesting observations. For example, in Fig.~\ref{fig:qualitative_pittsburgh} on the Pittsburgh dataset, we note that a large proportion of cases where Patch-NetVLAD succeeds and Superglue fails are for images containing a large proportion of sky. We notice that SuperGlue is attempting to find correspondences between points corresponding to clouds in these images. Patch-NetVLAD, on the other hand, uses larger patch-level features which typically include clouds \textit{and} a ground level feature. Suppl. Fig~\ref{fig:differentpatchsizes} illustrates this effect by showing the corresponding patch sizes at multiple scales superimposed onto the original image.

In Suppl.~Fig.~\ref{fig:allfail}, we showcase some examples where \emph{all} methods fail to localize correctly -- those examples may guide future research to address these open challenges.

Finally, Suppl.~Fig.~\ref{fig:wrongGT} provides some examples of the Pittsburgh and Mapillary datasets where a manual inspection of Patch-NetVLAD's \emph{failure cases} has shown that Patch-NetVLAD \emph{actually found a correct place match}, which indicates that either the error tolerances are too tight, or that some ground-truth locations are incorrectly annotated.

\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.95\textwidth]{figs/Supplementary/Mapillary_compressed.pdf}
    \caption{\textbf{Feature correspondences for the Mapillary dataset. 
}}
    \label{fig:qualitative_mapillary}
\end{figure*}

\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.95\textwidth]{figs/Supplementary/Nordland_compressed.pdf}
    \caption{\textbf{Feature correspondences for the Nordland dataset.}}
    \label{fig:qualitative_nordland}
\end{figure*}

\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.95\textwidth]{figs/Supplementary/Pittsburgh_compressed.pdf}
    \caption{\textbf{Feature correspondences for the Pittsburgh dataset.}}
    \label{fig:qualitative_pittsburgh}
\end{figure*}

\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.95\textwidth]{figs/Supplementary/Tokyo_compressed.pdf}
    \caption{\textbf{Feature correspondences for the Tokyo 24/7 dataset.}}
    \label{fig:qualitative_tokyo}
\end{figure*}

\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.99\textwidth]{figs/Supplementary/AllFail_compressed.pdf}
    \caption{\textbf{Cases where \emph{all} methods fail.} We hope that these cases inform future research in VPR. Failure cases on Nordland (top left block) are mainly due to an unseen environment (for learning-based methods) and significant perceptual aliasing, \ie different places look very similar. Similarly, on the Mapillary dataset (bottom left block) both SuperGlue and Patch-NetVLAD retrieve places that have a very similar structure to the query -- consider for example the second last row where both the query and retrieved image from Patch-NetVLAD have a light pole on the left and sparse trees on right. On the Pittsburgh dataset (top right block), an additional challenge are the extreme viewpoint variations. Failures on Tokyo 24/7 (bottom right block) are mainly due to extreme viewpoint and appearance changes, as the query images are captured at night-time while reference images are captured at day-time. As mentioned in the Conclusions, we think that adding semantic information might aid Patch-NetVLAD in these extremely challenging cases.}
    \label{fig:allfail}
\end{figure*}

\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.99\textwidth]{figs/Supplementary/WrongAnnotation.pdf}
    \caption{\textbf{Cases where Patch-NetVLAD retrieved a correct match}, but this match was deemed outside the error tolerance, suggesting either that the error tolerances are too tight (compared to what a human would consider as the same place), or the possibility of slight ground truth errors. The left columns contain examples from the Mapillary dataset, while the right columns contain examples from the Pittsburgh dataset.}
    \label{fig:wrongGT}
\end{figure*}


